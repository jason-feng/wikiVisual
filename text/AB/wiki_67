<doc id="21757" url="http://en.wikipedia.org/wiki?curid=21757" title="New York Giants">
New York Giants

The New York Giants are a professional American football team located in the New York metropolitan area. The Giants are currently members of the East Division of the National Football Conference (NFC) in the National Football League (NFL). The team plays its home games in East Rutherford, New Jersey at MetLife Stadium, which it shares with the New York Jets in a unique arrangement. The Giants hold their summer training camp at the Quest Diagnostics Training Center at the Meadowlands Sports Complex.
The Giants were one of five teams that joined the NFL in 1925, and is the only one of that group still existing, as well as the league's longest-established team in the Northeastern United States. The team ranks third among all NFL franchises with eight NFL titles: four in the pre–Super Bowl era (1927, 1934, 1938, 1956) and four since the advent of the Super Bowl (Super Bowls XXI (1986), XXV (1990), XLII (2007), and XLVI (2011)), along with more championship appearances than any other team, with 19 overall appearances. Their championship tally is surpassed only by the Green Bay Packers (13) and Chicago Bears (9). During their history, the Giants have featured 15 Hall of Fame players, including NFL Most Valuable Player (MVP) award winners Mel Hein, Frank Gifford, Y. A. Tittle, and Lawrence Taylor.
To distinguish themselves from the professional baseball team of the same name, the football team was incorporated as the "New York National League Football Company, Inc." in 1929 and changed to "New York Football Giants, Inc." in 1937. Although the baseball team moved to San Francisco after the 1957 season, the football team continues to use "New York Football Giants, Inc." as its legal corporate name, and is often referred to by fans and sportscasters as the "New York Football Giants". The team has also gained several nicknames, including "Big Blue", the "G-Men", and the "Jints", an intentionally mangled contraction seen frequently in the "New York Post" and "New York Daily News", originating from the baseball team when they were based in New York. Additionally the team as a whole is occasionally referred to as the "Big Blue Wrecking Crew", even though this moniker primarily and originally refers to the Giants defensive unit during the 80s and early 90s.
The team's heated rivalry with the Philadelphia Eagles is the oldest of the NFC East rivalries, dating all the way back to 1933, and has been called the best rivalry in the NFL in the 21st century.
Team history.
1925–32.
The Giants played their first game as an away game against All New Britain in New Britain, Connecticut, on October 4, 1925. They defeated New Britain 26–0 in front of a crowd of 10,000. The Giants were successful in their first season, finishing with an 8–4 record.
In its third season, the team finished with the best record in the league at 11–1–1 and was awarded the NFL title. After a disappointing fourth season (1928) owner Mara bought the entire squad of the Detroit Wolverines, principally to acquire star quarterback Benny Friedman, and merged the two teams under the Giants name.
In 1930, there were still many who questioned the quality of the professional game, claiming the college "amateurs" played with more intensity than professionals. In December 1930, the Giants played a team of Notre Dame All Stars at the Polo Grounds to raise money for the unemployed of New York City. It was also an opportunity to establish the skill and prestige of the pro game. Knute Rockne reassembled his Four Horsemen along with the stars of his 1924 Championship squad and told them to score early, then defend. Rockne, like much of the public, thought little of pro football and expected an easy win. But from the beginning it was a one-way contest, with Friedman running for two Giant touchdowns and Hap Moran passing for another. Notre Dame failed to score. When it was all over, Coach Rockne told his team, "That was the greatest football machine I ever saw. I am glad none of you got hurt." The game raised $100,000 for the homeless, and is often credited with establishing the legitimacy of the professional game for those who were critical.
1933–46.
In a fourteen-year span from 1933 to 1947, the Giants qualified to play in the NFL championship game 8 times, winning twice. During the period the Giants were led by Hall of Fame coach Steve Owen, and Hall of Fame players Mel Hein, Red Badgro, and Tuffy Leemans. This period also included the famous "Sneakers Game", where they defeated the Chicago Bears on an icy field in the 1934 NFL Championship Game, while wearing sneakers for better traction. The Giants were particularly successful from the latter half of the 1930s until the United States entry into World War II. They added their third NFL championship in 1938 with a 23–17 win over the Green Bay Packers.
Fourth NFL Championship and "The Greatest Game Ever Played" (1947–1963).
They did not win another league title until 1956, aided by a number of future Pro Football Hall of Fame players such as running back Frank Gifford, linebacker Sam Huff, and offensive tackle Roosevelt Brown, as well as all-pro running back Alex Webster. The Giants' 1956 championship team not only included players who would eventually find their way to the Pro Football Hall of Fame, but a Hall of Fame coaching staff, as well. Head coach Jim Lee Howell's staff had Vince Lombardi coaching the offense and Tom Landry coaching the defense. From 1958 to 1963, the Giants played in the NFL Championship Game five times, but failed to win. Most significantly, the Giants played the Colts in the 1958 NFL Championship Game that is considered a event in the history of the NFL. The game, which the Giants lost in overtime 23–17, is often called "The Greatest Game Ever Played" and is considered one of the most important events in furthering the NFL's popularity. The following year, they lost the championship to the Colts again, giving up a 9-7 4th quarter lead en route to a 31–16 loss. In 1963 led by league MVP quarterback Y.A. Tittle, who threw a then-NFL record 36 touchdown passes, the Giants advanced to the NFL Championship Game, where they lost to the Bears 14–10.
Postseason Drought and Resurgence (1964–1982).
From 1964 to 1978, the Giants registered only two winning seasons and no playoff appearances. With players such as Tittle and Gifford approaching their mid 30s, the team declined rapidly, finishing 2–10–2 in 1964. They rebounded with a 7–7 record in 1965, before compiling a league-worst 1–12–1 record, and allowing more than 500 points on defense in 1966. During the 1969 preseason, the Giants lost their first meeting with the New York Jets, 37–14, in front of 70,874 fans at the Yale Bowl in New Haven, Connecticut. Following the game, Wellington Mara fired coach Allie Sherman, and replaced him with former Giants fullback Alex Webster.
In 1967, the team acquired quarterback Fran Tarkenton from the Minnesota Vikings. Despite having several respectable seasons with Tarkenton at quarterback, including a 7–7 finish in 1967 and 9–5 in 1970, the Giants traded him back to the Vikings after a 4–10 finish in 1971 . Tarkenton would go on to lead the Vikings to three Super Bowls and earn a place in the Hall of Fame, while the Giants suffered through one of the worst stretches in their history, winning only 23 games from 1973–79. Before the 1976 season, the Giants tried to revive a weak offense by replacing retired RB Ron Johnson with future HOF fullback Larry Csonka, but Csonka was often injured and ineffective during his 3 years in New York. The 1977 season featured a roster that included three rookie quarterbacks.
The Giants were allowed to play their home games at the Yale Bowl in New Haven, Connecticut in 1973–74, and at Shea Stadium (home of the Mets and Jets) in 1975, due to the renovation of Yankee Stadium. They finally moved into their own dedicated state-of-the-art stadium in 1976, when they moved into Giants Stadium at the Meadowlands in East Rutherford, New Jersey. One of the low points during this period was the play known as the "Miracle at the Meadowlands", which occurred in 1978. With the Giants trying to kill the clock and secure a win against the Philadelphia Eagles, offensive coordinator Bob Gibson chose to call a running play. This resulted in "The Fumble" by QB Joe Pisarcik that was returned for a game-winning touchdown by the Eagles' Herman Edwards.
The Giants' front office operations were complicated by a long-standing feud between Wellington Mara and his nephew, Tim Mara. Jack Mara had died in 1965, leaving his share of the club to his son Tim. Wellington and Tim's personal styles and their visions for the club clashed, and eventually they stopped talking to each other. Commissioner Rozelle intervened and appointed a neutral general manager, George Young, allowing the club to operate more smoothly. The feud became moot on February 20, 1991, when Tim Mara sold his shares in the club to Preston Robert Tisch.
In 1979, the Giants began the steps that would, in time, return them to the pinnacle of the NFL. These included the drafting of quarterback Phil Simms in 1979, and linebacker Lawrence Taylor in 1981. In 1981, Taylor won the NFL's Defensive Rookie of the Year and Defensive Player of the Year awards and the Giants made the playoffs for the first time since 1963. One of the few bright spots during this time was the team's excellent linebackers, who were known as the Crunch Bunch. After the strike-shortened 1982 season, in which they finished 4–5, head coach Ray Perkins resigned to take over the same position at the University of Alabama. In a change that would prove crucial in the coming years, he was replaced by the team's defensive coordinator, Bill Parcells.
Bill Parcells Era (1983–1990).
In 1983, Bill Parcells was promoted to head coach from defensive coordinator. One of his first moves was to change his starting quarterback, sitting the injury-prone and struggling Phil Simms (who had missed the entire 1982 season with an injury) and electing instead to go with Scott Brunner, who had gone 4-5 as the starter in place of Simms in the strike-shortened previous season. Parcells went as far as to demote Simms to the third string position, promoting Jeff Rutledge over Simms to be Brunner's backup. Parcells later said the move was a mistake and one he "nearly paid for dearly" as the team finished with a 3–12–1 record and his job security was called into question. 
In the offseason the Giants released Brunner and named Simms the starter. The move paid off as the team won nine games and returned to the playoffs. After beating the Los Angeles Rams in the Wild Card Round, the Giants prepared for a showdown against top-seeded San Francisco. The 49ers defeated the Giants 21–10 in the Divisional Round.
The 1985 Giants compiled a 10–6 record and avenged their loss against San Francisco by beating them in the Wild Card round 17–3. However, they again lost in the Divisional Round, this time to the Chicago Bears, by a score of 21–0. However, the following season would end with the Giants winning their first Super Bowl championship.
First Super Bowl Championship (1986 season).
After 9–7 and 10–6 finishes in 1984 and 1985 respectively, the Giants compiled a 14–2 record in 1986 led by league MVP and Defensive Player of the Year Lawrence Taylor and the Big Blue Wrecking Crew defense. As of 2012, this is the Giants' best regular season record since the NFL began playing sixteen-game seasons in 1978. After clinching the top seed in the NFC, the Giants defeated the 49ers 49–3 in the divisional round of the NFC playoffs and the Redskins 17–0 in the NFC championship game, advancing to their first Super Bowl, Super Bowl XXI, against the Denver Broncos at the Rose Bowl in Pasadena. Led by MVP Simms who completed 22 of 25 passes for a Super Bowl record 88% completion percentage, they defeated the Broncos 39–20, to win their first championship since 1956. In addition to Phil Simms and Lawrence Taylor, the team was led during this period by head coach Bill Parcells, tight end Mark Bavaro, running back Joe Morris, and Hall of Fame linebacker Harry Carson.
The Giants struggled to a 6–9 record in the strike-marred 1987 season, due largely to a decline in the running game, as Morris managed only 658 yards behind an injury-riddled offensive line. The early portion of the 1988 season was marred by a scandal involving Lawrence Taylor. Taylor had abused cocaine and was suspended for the first four games of the season for his second violation of the league's substance abuse policy. Despite the controversy, the Giants finished 10–6, and Taylor recorded 15.5 sacks after his return from the suspension. They surged to a 12–4 record in 1989, but lost to the Los Angeles Rams in their opening playoff game when Flipper Anderson caught a 47-yard touchdown pass to give the Rams a 19–13 overtime win.
Second Super Bowl Championship (1990 season).
In 1990, the Giants went 13–3 and set an NFL record for fewest turnovers in a season (14). They defeated the San Francisco 49ers, who were attempting to win the Super Bowl for an unprecedented third straight year, 15–13 at San Francisco and then defeated the Buffalo Bills 20–19 in Super Bowl XXV.
Post-Parcells Era (1991–1996).
Following the 1990 season, Parcells resigned as head coach and was replaced by the team's offensive coordinator, Ray Handley. Handley served as coach for two disappointing seasons (1991–92), which saw the Giants fall from Super Bowl champions to an 8–8 record in 1991 and a 6–10 record in 1992. He was fired following the 1992 season, and replaced by former Denver Broncos' coach Dan Reeves. In the early 1990s, Simms and Taylor, two of the stars of the 1980s, played out the last seasons of their careers with steadily declining production. The Giants experienced a resurgent season with Reeves at the helm in 1993 however, and Simms and Taylor ended their careers as members of a playoff team.
The Giants initially struggled in the post Simms-Taylor era. After starting 3–7 in 1994, the Giants won their final six games to finish 9–7 but missed the playoffs. Quarterback Dave Brown received heavy criticism throughout the season. Brown performed poorly the following two seasons, and the Giants struggled to 5–11 and 6–10 records. Reeves was fired following the 1996 season.
Jim Fassel Era (1997–2003).
In 1997, the Giants named Jim Fassel, who had spent the previous season as offensive coordinator of the Arizona Cardinals, as their sixteenth head coach. Fassel named Danny Kanell the team's starting quarterback. The Giants finished the 1997 season with a record of 10–5–1 and qualified for the playoffs for the first time in four years. However, they lost in the Wild Card round to the Vikings at home. The following year, the Giants began the season 4–8 before rallying to finish the season 8–8. One of the notable games of that season was a win over the eventual Super Bowl champion Denver Broncos in week 15, giving the Broncos their first loss of the season after starting 13–0.
Before the 1999 season, the Giants signed ex-Carolina Panthers quarterback Kerry Collins. Collins was the first–ever draft choice of the expansion Carolina Panthers in 1995, and led the Panthers to the NFC Championship game in his second season. However, problems with alcohol, conflicts with his teammates and questions about his character led to his release from the Panthers. The Giants finished the season with a 7–9 record, Fassel's first losing season as head coach.
NFC Champions (2000 season).
In 2000, the Giants were looking to make the playoffs for the first time in three seasons. The Giants started the season 7–2, but suffered back-to-back home losses to St. Louis and Detroit to make their record 7–4 and call their playoff prospects into question. At a press conference following the Giants' loss to Detroit, Fassel guaranteed that "this team is going to the playoffs". The Giants responded, winning the rest of their regular season games to finish the season 12–4 and clinch the top seed in the NFC. In the Divisional Round, the Giants beat the Philadelphia Eagles 20–10 at home to qualify for the NFC Championship Game, in which they defeated the Minnesota Vikings 41–0. They advanced to play the Baltimore Ravens in Super Bowl XXXV. Though the Giants went into halftime down only 10–0, the Ravens dominated the second half. Their defense harassed Kerry Collins all game long, resulting in Collins completing only 15 of 39 passes for 112 yards and 4 interceptions. The Ravens won the game 34–7.
After a disappointing 7–9 record in 2001, the Giants finished the 2002 season with a record of 10–6, qualifying for the playoffs as a wild card. This set up a meeting with the San Francisco 49ers in Candlestick Park in the Wild Card round. The Giants built up a sizable lead throughout the game, and led 38–14 with 4:27 left in the third quarter. However, San Francisco rallied to win the game by one point, with the final score as 39–38.
After a dismal 2003 season in which the Giants finished with a 4–12 record, Jim Fassel was released by the Giants. His head coaching record with the Giants during this time was 58–53–1.
Tom Coughlin/Eli Manning Era (2004–present).
In 2004, three years after their last Super Bowl appearance, Fassel was replaced by current coach Tom Coughlin. Although Collins had several solid seasons as the Giants quarterback, he experienced his share of struggles. In 2004, the Giants completed a draft day trade for University of Mississippi quarterback Eli Manning. Manning became the team's starting quarterback in the middle of the 2004 season, taking over for Kurt Warner. During the three-year period from 2004–2006, Tom Coughlin's Giants compiled a 25–23 regular season record and two appearances in the Wild Card Round — both losses (to the Carolina Panthers in 2005 and to the Philadelphia Eagles in 2006.) and spawned intense media scrutiny concerning the direction of the team. During this period in their history, standout players included defensive end Michael Strahan, who set the NFL single season record in sacks in 2001, and running back Tiki Barber, who set a team record for rushing yards in a season in 2005. Barber retired at the end of the 2006 season.
Third Super Bowl Championship (2007 season).
Going into 2007, the Giants had made the playoffs in back-to-back seasons. In 2007, the Giants became the third NFL franchise to win at least 600 games when they defeated the Atlanta Falcons 31–10 on "Monday Night Football". For the 2007 season, the NFL scheduled the Giants' road game against the Miami Dolphins on October 28 in London's Wembley Stadium; this was the first NFL regular-season game to be played outside of North America. The Giants defeated the Dolphins, 13–10. The Giants finished 10–6, and became NFC Champions after defeating the Tampa Bay Buccaneers, Dallas Cowboys, and Green Bay Packers in the NFC Playoffs. They set a record for most consecutive road wins in a single season with 10 (a streak which ended with a loss to the Cleveland Browns during week 6 of the 2008 season).
The Patriots (18–0) entered the Super Bowl undefeated and were 12 point favorites going into game weekend. The Giants defeated the Patriots 17–14 in Super Bowl XLII, capped by the famous "Manning to Tyree" pass. It was the third biggest upset by betting line in Super Bowl history (The Baltimore Colts were favored by 17 over the New York Jets in Super Bowl III, and the St. Louis Rams were favored by 14 over the New England Patriots in Super Bowl XXXVI.). Co-owner John Mara described it as "the greatest victory in the history of this franchise, without question".
Late Season Collapses (2008–2010).
The Giants began the 2008 NFL season with a record of 11–1, but lost three of their last four regular season games partially due to a self-inflicted gunshot wound to wide receiver Plaxico Burress. However, the Giants still won the NFC East with a record of 12–4, and clinched the number one seed in the NFC after beating the Carolina Panthers for home field advantage and a first-round bye. In the Divisional Round of the playoffs, the Giants lost 23–11 to the Philadelphia Eagles at home.
In 2009, the Giants opened a new training complex, the Timex Performance Center, also located in the Meadowlands. After starting 5–0 in the 2009 season, New York lost to the likewise undefeated New Orleans Saints at the Superdome 48–27, beginning a four-game losing streak, in which they lost to the Arizona Cardinals 24–17, the San Diego Chargers 21–20 and the Philadelphia Eagles 40–17. The streak was broken with a 34–31 overtime victory against the Falcons. On Thanksgiving night, they lost to the Denver Broncos 26–6. The Giants next beat the division leading Cowboys. A week later, with a record of 7–5, they lost to the Philadelphia Eagles, 45–38. On December 27, the Giants lost to the Carolina Panthers 41–9 in their final game at Giants Stadium, and were eliminated from playoff eligibility. The Giants finished the season 8–8.
Following the season, the Giants fired first-year defensive coordinator Bill Sheridan, and replaced him with the former Buffalo Bills interim head coach, Perry Fewell. The Giants defense finished 13th overall under Sheridan, giving up 324.9 yards per game, and the final two losses of the season against Carolina and Minnesota, in which the Giants gave up 85 points, ultimately led to the firing.
In 2010, the Giants moved from Giants Stadium into MetLife Stadium, then known as the "New Meadowlands Stadium". They won against the Panthers in the very first game at the New Meadowlands, but then lost to the Colts in the second "Manning Bowl", so-called due to Eli Manning's brother Peyton playing for the Colts. The Giants dropped one game to the Tennessee Titans before going on a five-game winning streak, beating the Chicago Bears, Houston Texans, Detroit Lions, Dallas Cowboys, and Seattle Seahawks. Before long, the Giants were 6–2, but lost two straight to division foes: to the Cowboys 33–20 at home, and to the Eagles on the road, putting the G-Men in 2nd place in the NFC East at 6–4. In first place was the Eagles, but at December 19 they were both tied for first place at 8–4, setting up a match for first place. The Giants were at home, and led 24–3 over the Eagles at halftime. The score was 31–10 with 5:40 left in the game, but Michael Vick led the Eagles to three touchdown drives to tie the game up at 31 with 40 seconds left. After a Giants three-and-outs, Matt Dodge punted the ball to Desean Jackson, who returned it for a touchdown, concluding the Giants' epic collapse. The next game, the Giants lost to the eventual Super Bowl Champion Green Bay Packers 45–17, and at 9–6, they faced the Redskins. They had to win and have the Packers lose in order to get into the playoffs. The Giants won 17–14, but the Packers beat the Bears 10–3, so the Giants missed out on the playoffs again, ending a collapse in which the Giants went 4–4 in their last eight games.
Fourth Super Bowl Championship (2011 season).
During the 2011 preseason, the Giants lost Kevin Boss, Steve Smith, Rich Seubert, Keith Bulluck, Derek Hagan, and pro-bowl center Shaun O'Hara to free agency. However, the season also saw the emergence of second-year wide receiver Victor Cruz and second-year tight end Jake Ballard. The Giants opened their season with a 28–14 loss to the Washington Redskins at FedEx Field on the 10th anniversary of the September 11th attacks. However, the Giants secured a 6–2 record by the midpoint of the season, including road victories over the Philadelphia Eagles and the New England Patriots. The latter victory ended the Patriots' NFL record home-game winning streak, after a touchdown pass from Manning to Jake Ballard with 15 seconds left in the game. 
However, the Giants then suffered a four-game losing streak, including road losses against the resurgent San Francisco 49ers and the New Orleans Saints and home losses to the Eagles and the then-undefeated Green Bay Packers, to make their record 6–6 entering December. The Giants broke their losing streak with a tightly contested 37–34 road victory over the Cowboys on December 11. but lost at home to the Washington Redskins the following week to make their record 7–7 with a Christmas Eve showdown against their crosstown rival New York Jets the following week. The Giants won, 29–14, and knocked the Eagles out of playoff contention, to set up a Week 17 home game against the Cowboys in which the winner would clinch the NFC East while the loser would be eliminated from playoff contention. The game was flexed into Sunday Night Football. The Giants defeated the Cowboys, 31–14, and clinched the NFC East title and the fourth seed in the playoffs. Wide receiver Victor Cruz finished the regular season with 1,536 receiving yards, breaking the Giants franchise record previously held by Amani Toomer.
On January 8, 2012 in the first round of the playoffs the Giants defeated the Atlanta Falcons 24–2. After giving up an early safety in the first half, QB Eli Manning threw for three consecutive touchdowns. RBs Ahmad Bradshaw and Brandon Jacobs combined for 172 yards rushing, a season-high for the Giants. With the victory, the Giants advanced to the second round against the top-ranked Green Bay Packers.
On January 15, 2012, the Giants defeated the Green Bay Packers 37–20. Eli Manning threw for 330 yards and 3 touchdowns, two of which to wide receiver Hakeem Nicks. This earned the Giants a spot in the NFC Championship Game on January 22, 2012, against the San Francisco 49ers. They won this game 20–17, in overtime, with Tynes scoring the winning field goal as he did four years earlier in the same game against the Packers.
The New York Giants won Super Bowl XLVI against the New England Patriots with a score of 21–17. The winning touchdown was preceded by a 38-yard reception by receiver Mario Manningham. As in Super Bowl XLII, Eli Manning was Super Bowl MVP, defeating the New England Patriots for a second time in the Super Bowl.
Ahmad Bradshaw scored the game winning touchdown by falling into the end zone. The Patriots were allowing Bradshaw to get the touchdown so they would get the ball with some time remaining. When Eli Manning handed the ball to Bradshaw, he told him not to score. Bradshaw was about to fall down at the 1-yard line but his momentum carried him in, thus the "reluctant touchdown".
As was the case in each of their four previous Super Bowl appearances, the Giants trailed at halftime. They are the only team in NFL history to have more than two second half, come from behind, Super Bowl victories (4). (The Pittsburgh Steelers, who accomplished the feat in Super Bowl X and Super Bowl XIV, are the only other team to do it more than once.)
Post-Super Bowl Struggles (2012–present).
The Giants began the 2012 season with a home loss to the Cowboys, but rebounded to finish October with a 6-2 record and on a four-game winning streak that included a 26-3 road victory against the eventual NFC champion San Francisco 49ers. Following the arrival of Hurricane Sandy in the Northeastern United States, the Giants lost back-to-back games against the Steelers and Bengals to fall to 6-4. Despite impressive blowout home victories over the Packers, Saints and Eagles, the Giants finished the season 9-7 and out of the playoffs. The Redskins won the division with a 10–6 record only to lose to the Seahawks 24–14 in Wild Card Weekend. QB Eli Manning, DE Jason Pierre-Paul, WR Victor Cruz, and G Chris Snee represented the Giants at the Pro Bowl.
The 2013 New York Giants season began with hope that the Giants could become the first team to play in the Super Bowl in their home stadium, as MetLife Stadium was scheduled to host Super Bowl XLVIII that February. However, the Giants' playoff hopes took a massive hit when they lost the first six games of the season. They rebounded to win the next four games in a row to improve to 4-6, but lost a critical home game to the Cowboys on a last-minute field goal. They finished the season 7-9 and with a losing record for the first time since 2004.
Championships.
League Championships.
The Giants have won a total of eight League Championships: 1927, 1934, 1938, 1956, 1986, 1990, 2007 and 2011. The first four of those championships came in the pre-Super Bowl era. New York's eight championships puts them third among all currently active and defunct NFL teams, trailing only the Green Bay Packers (13) and the Chicago Bears (9).
Pre Super Bowl NFL Championships.
Before the Super Bowl was instituted, the Giants won four officially recognized NFL Championships.
Super Bowl Championships.
The Giants have won four Super Bowls, the fourth most behind only Dallas, San Francisco and Pittsburgh.
NFC Championships.
The Giants have won five NFC Championship Games, including two in overtime in 2007 and 2011.
Logos and uniforms.
With over 80 years of team history, the Giants have used numerous uniforms and logos, while maintaining a consistent identity. The Giants' logos include several incarnations of a giant quarterback preparing to throw a football, a lowercase "ny", and stylized versions of the team nickname.
Giants' jerseys are traditionally blue or red (or white with blue or red accents), and their pants alternate between white and gray. Currently, the Giants wear home jerseys that are solid blue with white block numbering, gray pants with three thin non-contiguous red/blue/red stripes on the pant legs, and solid blue socks. For this they gained their most renown nickname, "Big Blue". For road uniforms, they wear a white jersey with red block numbering and red "Northwestern" stripes on the sleeves, gray pants with three thin non-contiguous red/blue/red stripes on the pant legs, and solid red socks. The Giants' current helmet is metallic blue with white block numbers, frontally mounted and base mounted on either side of a red stripe running down the center. (The Giants, along with the Pittsburgh Steelers, are one of only two teams in the National Football League to have the players' uniform numbers on the front and back of the helmets.) The helmet is adorned on both sides with the stylized white lower case "ny" logo and features a gray facemask. These uniforms are essentially a modernization of the uniforms the team wore from 1954–1963. Additionally, the Giants had until the '09–'10 season a third jersey which recalled the Giants' solid red home jerseys from the early 50's: a solid red alternate with white block numbers. These jerseys were used a total of four times, but have since been retired. They were used once in 2004 against the Philadelphia Eagles and in three consecutive years – 2005, 2006, and 2007 – against the Dallas Cowboys.
Ownerships, financial history and fan base.
The Giants have had a long and, at times, turbulent financial history. The Giants were founded by Tim Mara with an investment of US$500 in 1925 and became one of the first teams in the then five-year-old NFL. To differentiate themselves from the baseball team of the same name, they took the name "New York Football Giants", which they still use as their legal corporate name.
Although the Giants were successful on the field in their initial seasons, their financial status was a different story. Overshadowed by baseball, boxing, and college football, professional football was not a popular sport in 1925. The Giants were in dire financial straits until the 11th game of the season when Red Grange and the Chicago Bears came to town, attracting over 73,000 fans. This gave the Giants a much needed influx of revenue, and perhaps altered the history of the franchise. The following year, Grange and his agent formed a rival league and stationed a competing team, led by Grange, in New York. Though the Giants lost $50,000 that season, the rival league folded and was subsumed into the NFL. Following the 1930 season, Mara transferred ownership of the team over to his two sons to insulate the team from creditors, and by 1946, he had given over complete control of the team to them. Jack, the older son, controlled the business aspects, while Wellington controlled the on-field operations. After their initial struggles the Giants financial status stabilized, and they led the league in attendance several times in the 1930s and 1940s.
By the early 1960s, the Giants had firmly established themselves as one of the league's biggest attractions. However, rather than continuing to receive their higher share of the league television revenue, the Mara sons pushed for equal sharing of revenue for the benefit of the entire league. Revenue sharing is still practiced in the NFL today, and is credited with strengthening the league. After their struggles in the latter half of the 1960s and the entire 1970s, the Giants hired an outsider, George Young, to run the football operations for the first time in franchise history. The Giants' on-field product and business aspects improved rapidly following the move.
In 1991, Tim Mara, struggling with cancer at the time, sold his half of the team to Bob Tisch for a reported $80 million. This marked the first time in franchise history the team had not been solely owned by the Mara family. In 2005, Wellington Mara, who had been with the team since its inception in 1925 when he worked as a ball boy, died at the age of 89. His death was followed two weeks later by the death of Tisch. In 2015, Wellington's widow and Giants co-owner Ann died due to complications from a head injury suffered in a fall. She was 85 years old.
In 2010, MetLife Stadium opened, replacing Giants Stadium. The new stadium is a 50/50 partnership between the Giants and Jets, and while the stadium is owned by the New Jersey Sports and Exposition Authority on paper, the two teams jointly built the stadium using private funds, and administer it jointly through New Meadowlands Stadium Corporation. The Giants had previously planned a $300 million renovation to the Meadowlands, before deciding in favor of the new stadium which was originally estimated to cost approximately $600 million, before rising to an estimated cost of one billion dollars. One advantage gained by owning the stadium is that the teams saved considerable money in tax payments. The teams leased the land from the state at a cost of $6.3 million per year. The state paid for all utilities, including the $30 million needed to install them.
The Giants are currently owned and operated by John Mara and Steve Tisch. "Forbes" magazine estimated the value of the team in 2012 to be $1.3 billion. This ranks the New York Giants as the fourth most valuable franchise in the NFL and the ninth most valuable professional sports franchise in the world. The value has steadily increased from $288 million in 1998, to their current value. The magazine estimated their revenue in 2006 at $182 million, of which $46 million came from gate receipts. Operating income was $26.9 million, and player salary was $102 million. Current major sponsors include Gatorade, Anheuser Busch, Toyota, and Verizon Wireless. Recent former sponsors include Miller Brewing and North Fork Bank. Luxury suites, retail and game day concessions at the new stadium are provisioned and operated by global hospitality giant Delaware North Companies. Giants average ticket price is $72.
The Giants draw their fans from the New York metropolitan area. Since their move to New Jersey in 1976, fans from each state have claimed the team as their own. In January 1987, shortly before the team won Super Bowl XXI, then New York City mayor Ed Koch labeled the team "foreigners" and said they were not entitled to a ticker-tape parade in New York City. On February 5, 2008, the city, under mayor Michael Bloomberg, threw a ticker tape parade in honor of the Giants' Super Bowl XLII victory at the Canyon of Heroes in lower Manhattan. New York City held another ticker tape parade on February 7, 2012, in honor of the Giants' Super Bowl XLVI victory. According to a team spokesman, in 2001, 52 percent of the Giants' season ticket-holders lived in New Jersey. Most of the remaining ticket holders lived in New York State with some coming from other states.
Through the lean years of the 1960s and 1970s the Giants, in spite of a 17-year-long playoff drought, still accumulated a 20-year-long waiting list for season tickets. It has been estimated that the Giants have a waiting list of 135,000 people, the largest of any franchise.
Rivalries.
Philadelphia Eagles.
The rivalry between the New York Giants and the Philadelphia Eagles is one of the oldest in the NFL, dating back to 1933. The two teams have frequently fought for playoff contention, NFC East titles, and respect. While the Giants have dominated this rivalry throughout most of its history, the series began to even in the 1980s, with the series lead to the Eagles 22–21 through the 1990s and 2000s. The Giants currently lead the series 81–72–2. The two teams have met four times in the postseason, with each team winning two games. Three of those four playoff meetings were held in the 2000s decade. New York City and Philadelphia have a strong geographic rivalry, as seen in other professional sports such as the Mets-Phillies rivalry in Major League Baseball, and the Flyers-Rangers and Devils-Flyers rivalries in the National Hockey League.
Washington Redskins.
The Giants have an old and storied rivalry with the Redskins, dating back to 1932. While this rivalry is typically given less significance than the rivalries with the Eagles and Cowboys, there have been periods of great competition between the two. In the 1980s the Giants and Redskins clashed as both struggled against each other for division titles and even Super Bowl Championships. Most notable among these is the 1986 NFC Championship game in which the Giants defeated the Redskins 17–0 to earn their first ever trip to the Super Bowl. Wellington Mara always felt this was the Giants oldest and truest rival, and after passing away in 2005, the Giants honored their longtime owner by defeating the Redskins 36–0 at home. The Giants lead this series 91–63–4.
Dallas Cowboys.
The Giants have maintained a fierce divisional rivalry with the Dallas Cowboys since the Cowboys first began play in 1960. The two teams have a combined nine Super Bowl victories between them, and have played many games in which the NFC East title was at stake. The rivalry is unique among professional sports as it is the only divisional rivalry between sports teams from New York City and Dallas, partially due to the large distance between the two cities. The Cowboys currently lead the regular season series 51–43–2, while the Giants hold the lone playoff victory between the two teams, held at the conclusion of the 2007 season.
San Francisco 49ers.
Despite never being in the same division, the Giants and 49ers have developed a heated rivalry over the years. The two teams have met eight times in the playoffs (including two NFC Championship Games, both won by New York) since 1982, which is the most of any two teams in that span. The Giants lead the overall series 19–18, but the postseason series is tied, 4–4.
New York Jets.
The Giants and Jets have the only intracity rivalry in the NFL, made even more unusual by sharing a stadium. They have met annually in the preseason since 1969. Since 2011, this meeting has been known as the "MetLife Bowl", after the naming sponsor of the teams' stadium. Regular season matchups between the teams occur once every four years, as they follow the NFL scheduling formula for interconference games. Since the two teams play each other so infrequently in the regular season, some, including players on both teams, have questioned whether the Giants and Jets have a real rivalry. A memorable regular season game was in 1988, when the Giants faced off against the Jets in the last game of the season, needing a victory to make the playoffs. The Jets played spoiler, however, beating the Giants 27–21 and ruining the latter's playoff hopes. A different scenario unfolded during the penultimate regular season game of 2011 as the "visiting" Giants defeated the Jets 29–14. The victory simultaneously helped eliminate the Jets from playoff contention and propel the Giants to their own playoff run and eventual win in Super Bowl XLVI. The Giants led the overall regular season series 8–4 and have won the last five meetings.
Players of note.
Pro Football Hall of Famers.
In the Pro Football Hall of Fame, the Giants boast the second-most enshrined members with twenty-nine. Tim Mara, Mel Hein, Pete Henry, Cal Hubbard and Jim Thorpe were a part of the original class of inductees in 1963, while Defensive End Michael Strahan, the most recent Giant inducted, was a part of the Class of 2014. Numerous members, including Larry Csonka, Ray Flaherty, Joe Guyon, Pete Henry, Arnie Herber, Cal Hubbard, Tom Landry, Don Maynard, Hugh McElhenny, and Jim Thorpe were at one time associated with the New York Giants, but they were inducted largely based on their careers with other teams.
Ring of Honor.
The New York Giants unveiled their own Ring of Honor on October 3, 2010 during halftime of their . John Mara had long wished to create a Giants Ring of Honor and Hall of Fame to honor Giants who helped the franchise achieve each of their championships, and the building of MetLife Stadium resulted in the realization of that ambition. The organization had an inaugural induction class of 30 including players, coaches, owners and executives that have had a great impact on the organization. While the entire list of inductees was not revealed until the actual induction, the organization did confirm about a week before the ceremony that Phil Simms, Bill Parcells, Michael Strahan, Tiki Barber, Frank Gifford and Pete Gogolak would all be inducted.
Media, radio and television.
As of 2010, the Giants' flagship radio station is WFAN, with games simulcasted on WFAN-FM as of November 2012. Beginning in 2012, the Giants became WFAN's top priority during the entire football season; prior to that, games that conflicted with late season New York Mets baseball games in September and early October were moved to other CBS Radio owned stations. This arrangement only lasted for 2012, and the Mets received priority again in 2013. WFAN acquired the rights to New York Yankees games for 2014, and thus the Giants' schedule will be in conflict with them for the foreseeable future. Games that do conflict will air on the Yankees' former flagship, WCBS, for 2014.
Bob Papa on play-by-play and Carl Banks on color commentary are the Giants' radio broadcast team, with Howard Cross as the sideline reporter. When Papa is unavailable to call games Chris Carrino, WFAN's lead broadcaster for the Brooklyn Nets, substitutes for him. Games are carried over the New York Giants Radio Network over various stations in New York, Pennsylvania, Connecticut, and (as of 2010) Mississippi.
Preseason telecasts not seen nationally air in the area on WNBC, with WWOR-TV serving as an overflow station for when WNBC is airing other programming such as the Summer Olympic Games. Papa and Banks call these games on television, with studio host Paul Dottino as Papa's substitute. WWOR will also air any Giants broadcast that is carried by ESPN, as per the local carriage rules. When the Giants play on NFL Network, those games will be carried by WPIX-TV unless they fall within CBS' broadcast window for Thursday night games, with those games airing locally on WCBS-TV.
The Giants' public address announcer at MetLife Stadium is Jim Hall, who for years was Bob Sheppard's substitute at Yankee Stadium due to their very similar voices. Hall took over the Giants PA job after Sheppard elected to leave the position in 2005 to focus solely on his Yankee Stadium duties.
Past.
WFAN has produced the Giants' radio broadcasts since 1995, but has not always aired them on the station. For 1995, then-Giants flagship WOR continued to carry the games as they had for the previous two seasons. In 1996 the games were simulcast on WFAN and WOR, which caused some conflict as at the time, WFAN was the radio flagship of the New York Jets as well. To remedy the situation, beginning the next year WFAN moved the Giants' radio broadcasts to the FM dial and sister station WNEW-FM, where they remained until the end of the 1999 season. In 2000 WFAN lost the Jets' radio contract to WABC and the Giants moved back to WFAN where they have been ever since.
The Giants' longtime radio home was WNEW, where games aired from the mid-1950s until 1993 when the station was bought by Bloomberg L.P. and changed its format. Marty Glickman teamed with Al DeRogatis for a long stretch beginning in the early 1960s on WNEW. Chip Cipolla and later Sam Huff joined Glickman after DeRogatis left to join Curt Gowdy on NBC. After the WNEW split, games began airing on WOR. Glickman moved to the crosstown Jets in 1973 and was succeeded by Marv Albert. Jim Gordon succeeded Albert in 1977, beginning an 18-year tenure as the Giants' play-by-play voice. Meanwhile, Dick Lynch took over as color analyst in 1976 and continued in that role through 2007, with his last game being Super Bowl XLII, and retired following the season due to his advancing leukemia, which took his life in September 2008.
Eventually Gordon and Lynch were joined by Karl Nelson, a former lineman for the Giants. Gordon and Nelson were fired after the 1994 season, after which Papa took over the play-by-play (after being studio host) and led a two-man booth with Lynch. Dave Jennings joined the broadcast team in 2002 following his firing by the Jets, with whom he had worked since his 1987 retirement from the NFL. Jennings was moved to the pregame show after the 2006 season and was replaced by Carl Banks, leaving broadcasting altogether in 2008 due to his ongoing battle with Parkinson's disease that he lost in 2013.
After WFAN began airing games Richard Neer served as pregame and postgame host. He was replaced by Sid Rosenberg, who was in turn fired by the station due to troubles and replaced by Chris Carlin. Carlin left in 2008 to focus full-time on his duties as SNY studio host and Rutgers athletics radio voice and was replaced by WWOR sports reporter and former WFAN host Russ Salzberg, who cohosted with Roman Oben after Jennings left. WEPN Giants beat reporter Paul Dottino was hired by WFAN to host the pregame show for 2009 and continues to be a part of the program. Anita Marks has hosted the pre- and post- game shows since 2010, co-hosting with Dottino for home games and Oben for away games.
The Giants were carried on the DuMont Network, then CBS (New York's Channel 2) in the early TV days of the NFL, when home games were blacked out within a 75-mile radius of New York City. Chris Schenkel was their play-by-play announcer in that early era when each team was assigned its own network voice on its regional telecasts. At the time, there were few if any true national telecasts until the NFL championship game, which was carried by NBC. Schenkel was joined by Jim McKay, later Johnny Lujack through the 1950s and the early 1960s. As Giants players retired to the broadcast booth in the early and 1960s, first Pat Summerall, then Frank Gifford took the color analyst slot next to Schenkel. As the 1970 merger of the NFL and AFL approached, CBS moved to a more generic announcer approach and Schenkel was off the broadcasts.
Giants regular-season Sunday telecasts moved to Fox when that network took over NFC telecasts in 1994 and are carried locally by WNYW.
WCBS-TV and WPIX were previously home to Giants preseason telecasts in the 1990s, with WPIX serving as the Giants' (and Jets') long time preseason home. After the NFC rights were lost by CBS, the Giants followed the conference's broadcast rights to WNYW. WWOR became the Giants' flagship TV station in the late '90s, and stayed so up until WNBC took over rights in 2005.
When the Giants first moved to WNYW, Mike Breen was their preseason play-by-play man. Sam Rosen was the television voice for some time afterward, except for two years when Curt Menefee (then of WNYW) was the voice. When the games moved to WWOR, Rosen regained the position and held it until 2004. Former Giant receiver Phil McConkey became the early season analyst after his retirement and stayed in the booth for many years.
Bibliography.
</dl>

</doc>
<doc id="21758" url="http://en.wikipedia.org/wiki?curid=21758" title="November 6">
November 6

November 6 is the day of the year in the Gregorian calendar.

</doc>
<doc id="21759" url="http://en.wikipedia.org/wiki?curid=21759" title="November 8">
November 8

November 8 is the day of the year in the Gregorian calendar.

</doc>
<doc id="21760" url="http://en.wikipedia.org/wiki?curid=21760" title="November 10">
November 10

November 10 is the day of the year in the Gregorian calendar.

</doc>
<doc id="21761" url="http://en.wikipedia.org/wiki?curid=21761" title="November 13">
November 13


</doc>
<doc id="21762" url="http://en.wikipedia.org/wiki?curid=21762" title="November 14">
November 14

November 14 is the day of the year in the Gregorian calendar.

</doc>
<doc id="21763" url="http://en.wikipedia.org/wiki?curid=21763" title="November 15">
November 15

November 15 is the day of the year in the Gregorian calendar.

</doc>
<doc id="21764" url="http://en.wikipedia.org/wiki?curid=21764" title="November 3">
November 3

November 3 is the day of the year in the Gregorian calendar.

</doc>
<doc id="21765" url="http://en.wikipedia.org/wiki?curid=21765" title="New Malden">
New Malden

New Malden is a suburb in south-west London, in the boroughs of Kingston and Merton, and is 9.4 mi from Charing Cross. Neighbouring localities are Kingston upon Thames, Raynes Park, Surbiton, Tolworth, Wimbledon and Worcester Park.
History.
New Malden was established entirely as a result of the arrival of the railway when what is now called New Malden railway station was opened on 1 December 1846 on the main line from Waterloo. However, when Queen Victoria visited distinguished residents in the Coombe Hill area, the royal train always continued to Norbiton station where the platform was at ground level.
Building started slowly in the area just to the north of the station, gathering pace in the late nineteenth and early twentieth centuries with two- and three-bedroom terraced houses. Further out are larger detached and semi-detached houses from the 1930s. The name of the road up the hill to Coombe, Traps Lane, is thought to derive from a farm owned by a Mrs Trap.
Two miles (3 km) to the south is the former village of Old Malden (from which New Malden gets its name) whose origins go back to Anglo-Saxon times, the name being Old English for "Mæl" + "duna" = "the cross on the hill".
Under the District Councils Act 1895, The Maldens & Coombe Urban District Council was created (the plural relating to Old Malden and New Malden). In 1936 Malden and Coombe was granted full Borough status, with its own Mayor, and had the rare distinction of a civic mace bearing the royal insignia of King Edward VIII. In 1965, the London Government Act 1963 came into force merging the boroughs of Malden & Coombe and Surbiton with Kingston upon Thames to form the Royal Borough of Kingston upon Thames.
New Malden is home to the offices of many large organisations, including Nestle Purina and Northrop Grumman.
Description.
New Malden is bounded to the north by the affluent Coombe Hill and to the south and east by Raynes Park, Worcester Park and Tolworth. New Malden includes Motspur Park, home to the training ground of Fulham Football Club and also the King's College London sports ground, home to the training ground of AFC Wimbledon.
The busy A3 trunk road runs through part of New Malden. A minor tributary of the River Thames, Beverley Brook, flows through the east of the town, while its western boundary is along the Hogsmill, another Thames tributary.
The first parking meters were made in New Malden at Venners Ltd.
Korean culture and presence in the Royal Borough of Kingston upon Thames.
The Royal Borough of Kingston upon Thames has one of the largest expatriate communities of South Koreans in Europe, and is said to be one of the most densely populated area of Koreans outside South Korea. According to different sources, the Korean population in the Royal Borough of Kingston upon Thames is around 20,000. In the 2001 census, some small areas of New Malden had "Other Asian" (i.e., other than of Indian sub-continental origin, which also included Chinese) populations of "over 25%", though no whole ward reached over 20%. New Malden functions as the shopping and cultural centre for a Korean population spread more widely across South-West London and the neighbouring counties. The area has around fifteen Korean cafes and restaurants, a state-of-the-art Karaoke bar and many supermarkets and other shops. Churches of several denominations in the area have regular Korean services with associated Korean clergy.
The size of this community has been attributed to the former residence of the South Korean ambassador in Lord Chancellor's Walk off Coombe Lane West. During the 1970s many Koreans came to the area following his example, but when house prices rose in Wimbledon, they moved to nearby New Malden. Others point to a joint-venture between what was then Decca, later Racal Avionics, now part of Thales Group, at Shannon Corner and a Korean chaebol in the 1950s as the start of the community. Samsung Electronics' UK division used to be based in New Malden, although it has now relocated its European headquarters to nearby Chertsey. A high proportion of the community are expatriate workers for Korean companies, who remain in the UK for a number of years before returning to Korea. Many work in finance and banking in the City of London.
Amenities.
New Malden has its own sports centre, the Malden Centre, which includes a swimming pool, gym and community facilities. It also runs several adult learning courses.
Beverley Park provides a football pitch, tennis courts, children's playground, allotments and open space.
Tudor Williams Ltd, established in 1913, is a family run department store in the High Street. The company also has shops in Cobham and Dorking and expanded by acquiring department stores Elphicks of Farnham in October 2004, and Knights of Reigate in September 2006. A branch of Waitrose is one of a number of other well known stores in the High Street.
The local newspapers are the Surrey Comet which has been in print since 1854, and the Kingston Guardian.
A monthly publication, The Village Voice, covers local history, news, topical articles and advertisements for businesses serving the community.
There is an annual Malden Fortnight, which is a parade showcasing all the local schools and community groups and various other activities.
Each Christmas the High Street is festooned with Christmas lights with its own switching-on ceremony. The choir from Christ Church School, in New Malden sing Christmas carols to the townsfolk.
For a small town it is more than proportionately blessed with winners of the Victoria Cross. Research recently published in the Village Voice revealed the existence of a previously unknown third medal winner – see Notable Residents below.
New Malden has its own youth theatre, the Green Theatre Company, established in 1986 in a converted cricket pavilion at Barton Green. 
The area's last cinema, the Odeon at Shannon Corner on the A3 has closed and been replaced by a large retail area including several large stores. The other cinema in the High Street (corner of Sussex Road) burnt down on Boxing Day 1936. There was also a silent cinema on Coombe Road by the station, which became the New Malden Gentlemen's Club in 1923; this closed in August 2010, and is now a Korean karaoke and pool bar.
New Malden also has its own "Dino-Golf" course, 18 holes of dinosaur themed crazy golf overlooking the A3. As well as a floodlit golf driving range.
In recent times New Malden played host to the biggest B&Q, Tesco and Currys. This Currys is the biggest electrical store in London. These are situated away from the High Street, which focuses more on smaller, more upmarket shops and restaurants. 
Transport.
Rail.
New Malden railway station has services provided by South West Trains to London Waterloo, Hampton Court, Kingston upon Thames, Richmond and Shepperton. It is in London Zone 4. The Old Malden area is well served by trains from Malden Manor railway station, travelling north to London and south to Chessington. Motspur Park railway station on the New Malden/Raynes Park borders also has rail connections to Chessington South, Epsom, Dorking and Guildford.
Bus.
There are many bus routes going through New Malden, including the 213 route going from Kingston towards Sutton, the 131 and N87 routes going through Kingston Town Centre and Tooting Broadway (and Aldwych for the night bus) along with the X26 express bus to Croydon and Heathrow Airport and the 152 route going from New Malden towards Pollards Hill. The town also has a series of local bus routes, including the K1 which goes to Kingston and New Malden Station and the K5 to Ham and Morden.
Notable residents.
Notable former or current residents include:
New Malden also has links to a third recipient of the Victoria Cross, Humphrey Osbaldston Brooke Firman VC, whose parents lived in Coombe at the time of his death. A plaque bearing his name was unveiled on the war memorial in the High Street during April 2008 and a road in a new housing development near the High Street has been named Firman Close.

</doc>
<doc id="21768" url="http://en.wikipedia.org/wiki?curid=21768" title="Air Force Space Surveillance System">
Air Force Space Surveillance System

The AN/FPS-133 Air Force Space Surveillance System, colloquially known as the Space Fence, was a U.S. government multistatic radar system built to detect orbital objects passing over America. It is a component of the US space surveillance network, and according to the US Navy was able to detect basketball sized (29.5 in) objects at heights up to 30,000 km (15,000 nautical miles.)
The system ceased operation in September 2013. Plans for a new space fence are underway with sites at the Kwajalein Atoll in the Marshall Islands, along with an option for another radar site in Western Australia.
The operation's headquarters were at Dahlgren, Virginia, and radar stations were spread out across the continental United States at roughly the level of the 33rd parallel north.
Description.
There were three transmitter sites in the system:
The master transmitter at Lake Kickapoo was said to be the most powerful continuous wave (CW) station in the world, at 768 kW radiated power on 216.97927 MHz.
When the system became operational in 1961, the original frequency was 108.50 MHz (just above the FM broadcast band). In 1965 the "Fence" system was modernized with the operating frequency doubled to 216.98 MHz (just above Channel 13 in the VHF TV broadcast band) to obtain higher resolution and to locate smaller objects. This frequency was used until the Fence was decommissioned in 2013. Fill-in transmitter sites at Gila River and Jordan Lake used offset frequencies listed above from the early 1990s to 2013 to help better detect which transmitter "illuminated" an object in space, as multiple transmitters could have illuminated the same object at the same time. Overhead imagery (see coordinates given above) of the Gila River and Jordan Lake sites shows the original design at the lower frequency.
There were six receiving stations:
The following receiving stations were placed in cold storage in April 2013:
The receiving stations at Elephant Butte and Hawkinsville were considered to be "High Altitude" stations with longer and more complex antenna systems that are designed to see targets at higher altitudes than the other four receiving stations.
History.
Author Curtis Peebles notes that the original Space Fence or Space Surveillance System began operations in 1959. The system predated the formation of NORAD and was known as the U.S. Navy Space Surveillance System or SPASUR but also as NAVSPASUR (Naval Space Surveillance System). From 1960 until the early 1990s the system was used in conjunction with a network of with Baker-Nunn cameras that could see "an object the size of a basketball at 25,000 miles." Although formerly operated by the U.S. Navy for NORAD from 1961 until October 2004, command passed to the Air Force 20th Space Control Squadron on October 1, 2004.
In 2009, the operations and maintenance contract for the day-to-day management and operation of the Fence was awarded to Five Rivers Services, LLC, based out of Colorado Springs, Colorado. On September 30, 2011, Five Rivers Services was awarded a $7,022,503 firm fixed price with cost reimbursable line items contract modification to manage, operate, maintain, and logistically support the nine Air Force Space Surveillance System field stations, presumably for Fiscal Year 2012.
Plans for system upgrade: 2009 — 2012.
The 850th Electronic Systems Group, Electronic Systems Center awarded 3 $30-million contracts to Lockheed Martin, Northrop Grumman and Raytheon on 11 June 2009.
A new Space Fence is envisioned to be a system of two or three S-band ground-based radars designed to perform uncued detection, tracking and accurate measurement of orbiting space objects. The Space Fence is intended to replace the Air Force Space Surveillance System, or VHF Fence, that was transferred from the Navy to the Air Force in 2004. The shorter wavelength of the S-band Space Fence allows for detection of much smaller satellites and debris.
The February 10, 2009, collision of a U.S. Iridium communications satellite (Iridium 33) and a Russian Cosmos 2251 communications satellite, which added hundreds more pieces of debris to the atmosphere, highlighted the need for more precise tracking of space objects.
Data collected from a new Space Fence's sensors would potentially feed into the Joint Space Operations Center Mission System, which is used to track objects orbiting the Earth, monitor space weather and assess foreign launches. Used by operators at the 614th Air and Space Operations Center at Vandenberg Air Force Base, Calif., the 614 AOC's 24-hour-a-day, seven-day-a-week support provides vigilance of global and theater operations and equips the Joint Functional Component Command for space operations with the tools to conduct command and control of space forces.
Plans to award the final contract had been stalled by U.S. budget sequestration in early 2013 and the AFSSS system was scheduled to be discontinued in October 2013 due to budget cuts.
2013 Shutdown.
On August 1, 2013, General William L. Shelton, commander of Air Force Space Command, directed that the Air Force Space Surveillance System (AFSSS) be closed and all sites vacated effective October 1, 2013. The main advantage of the system was its ability to provide uncued data on new objects as opposed to tracking objects based on existing information. However, the system was also said to be inherently inaccurate due to its dated design. Alternate operating modes for radars at Cavalier AFS and Eglin AFB were devised to fulfill the mission to provide uncued data for new objects. Shelton also noted the confusion between the planned new S-band space fence and the old UHF AFSSS, which was commonly called the "space fence". The AFSSS was turned off September first. "It appears they pulled the plug at 00:00 UT (6 am Local MDT) on September 1st," reports engineer Stan Nelson, who was monitoring the radar using an antenna in Roswell. The radar's final echoes came from a Russian satellite and a sporadic meteor." The shutdown only affects the original Space Fence, not the new one contracted to be built by Lockheed Martin for deployment in Australia and the Marshall Islands.
New space fence.
Plans for new space fence are underway with sites at Kwajalein Atoll in the Marshall Islands and an option for another radar site in Western Australia. In 2014 Lockheed Martin won a contract to build a new S band space fence system.
External links.
</dl>

</doc>
<doc id="21770" url="http://en.wikipedia.org/wiki?curid=21770" title="National Film Preservation Board">
National Film Preservation Board

The United States National Film Preservation Board (NFPB) is the board selecting films for preservation in the Library of Congress' National Film Registry. It was established by the National Film Preservation Act of 1988. The National Film Registry is meant to preserve up to 25 "culturally, historically or aesthetically significant films" each year; to be eligible, films must be at least 10 years old. Members of the Board also advise the Librarian of Congress on ongoing development and implementation of the national film preservation plan.
The NFPB is a federal agency located within the Library of Congress. The NFPB was established by the National Film Preservation Act of 1988, and reauthorized in 1992, 1996 and 2005. The 1996 reauthorization also created the non-profit National Film Preservation Foundation, which is loosely affiliated with the National Film Preservation Board, but the private-sector Foundation (NFPF) and federal Board (NFPB) are separate, legally distinct entities.
Organization.
The board is appointed by the Librarian of Congress and is composed of representatives from professional organizations representing the film industry, archives, scholars, filmmakers and others who comprise the diverse American motion picture community. Explicitly it is composed of up to 5 "at-large" members (with 5 alternates) and 17 member/alternate pairs from the following 18 organizations:
Relationship with National Film Preservation Foundation.
The National Film Preservation Foundation was created by the U.S. Congress in 1996, at the recommendation of the Library of Congress, following four years of hearings and research conducted by the National Film Preservation Board. The National Film Preservation Act of 1996 (Public Law 104-285, Title II), signed into law on October 11, 1996 by President Bill Clinton, charged the NFPF to "encourage, accept, and administer private gifts to promote and ensure the preservation and public accessibility of the nation's film heritage" and authorized federal funds to advance this work. The NFPF started operations a year later in 1997 as an independent federally chartered grant-giving public charity and the nonprofit charitable affiliate of the Library of Congress's National Film Preservation Board. Since 1996 Congress has increased the NFPF’s authorization twice, in 2005 via the "Family Entertainment and Copyright Act of 2005" (Public Law 109-9) and in 2008 via the "Library of Congress Sound Recording and Film Preservation Programs Reauthorization Act of 2008" (Public Law 110-336). Funding received through the NFPF’s authorization is secured through the Library of Congress and goes directly to the field for film preservation projects.

</doc>
<doc id="21774" url="http://en.wikipedia.org/wiki?curid=21774" title="Nominative case">
Nominative case

The nominative case (abbreviated NOM) is one of the grammatical cases of a noun or other part of speech, which generally marks the subject of a verb or the predicate noun or predicate adjective, as opposed to its object or other verb arguments. Generally, the noun "that is doing something" is in the nominative, and the nominative is the dictionary form of the noun.
Etymology.
Nominative comes from Latin "cāsus nominātīvus" "case for naming", which was translated from Ancient Greek ὀνομαστικὴ πτῶσις, "onomastikḗ ptôsis" "inflection for naming", from "onomázō" "call by name", from "ónoma" "name". Dionysius Thrax in his Art of Grammar refers to it as "orthḗ" or "eutheîa" "straight", in contrast to the oblique or "bent" cases.
Linguistic characteristics.
The reference form (more technically, the "least marked") of certain parts of speech is normally in the nominative case, but this is often not a complete specification of the reference form, as it may also be necessary to specify the number and gender. Thus the reference or least marked form of an adjective might be the nominative masculine singular. The parts of speech which are often declined and therefore may have a nominative case are nouns, adjectives, pronouns and less frequently numerals and participles. The nominative case often indicates the subject of a verb but sometimes does not indicate any particular relationship with other parts of a sentence. In some languages the nominative case is unmarked, it may be said to be marked by a zero morpheme. Moreover, in most languages with a nominative case, the nominative form is the lemma; that is, it is the reference form used to cite a word, to list it as a dictionary entry, etc.
Nominative cases are found in Estonian, Slovak, Ukrainian, Hungarian, Lithuanian, Georgian, German, Latin, Greek, Icelandic, Old English, Old French, Polish, Serbian, Czech, Romanian, Russian, and Pashto, among other languages. English still retains some nominative pronouns, which are contrasted with the accusative (comparable to the oblique or disjunctive in some other languages): "I" (accusative, "me"), "we" (accusative, "us"), "he" (accusative, "him"), "she" (accusative, "her"), "they" (accusative, "them") and "who" (accusative, "whom"). A usage that is archaic in most, but not all, current English dialects is the singular second-person pronoun "thou" (accusative "thee"). A special case is the word "you": Originally, "ye" was its nominative form and "you" the accusative, but over time "you" has come to be used for the nominative as well.
The term "nominative case" is most properly used in the discussion of nominative–accusative languages, such as Latin, Greek, and most modern Western European languages.
In active–stative languages there is a case sometimes called nominative which is the "most" marked case and is used for the subject of a transitive verb or a voluntary subject of an intransitive verb but not for an involuntary subject of an intransitive verb; since such languages are a relatively new field of study, there is no standard name for this case.
Subjective case.
Some writers on English grammar employ the term subjective case instead of nominative to draw attention to the differences between the "standard" generic nominative and the way it is used in English.
Generally, when the term "subjective case" is used, the term "objective" is used for the oblique case, which covers the roles of accusative, dative, and objects of a preposition. The genitive case is then usually called the "possessive" form and often is not considered as a noun case per se; English is then said to have two cases, the subjective and the objective. This view is an oversimplification, but it is didactically useful.
Examples.
Subject.
The nominative case marks the subject of a verb. When the verb is active, the nominative is the person or thing doing the action (agent); when the verb is passive, the nominative is the person or thing receiving the action.
Predicate noun or adjective.
The nominative also marks things equal to the subject (that is, a predicate noun or adjective).

</doc>
<doc id="21777" url="http://en.wikipedia.org/wiki?curid=21777" title="Neapolitan sauce">
Neapolitan sauce

Neapolitan sauce, also called Napoli sauce or Napoletana sauce is the collective name given (outside Italy) to various basic tomato-based sauces derived from Italian cuisine, often served over or alongside pasta.
In Naples, Neapolitan sauce is simply referred to as la salsa, which literally translates to the sauce. Basil, bay leaf, thyme, oregano, peppercorns, cloves, olives, and mushrooms may be included depending on taste preferences. Some variants include carrots and celery. The basic sauce is vegetarian, although meat such as ground beef or sausage can be added. Italians refer to Neapolitan sauce only in association with other recipes, for instance, 'spaghetti napolitana'.
The sauce is a mainstay of Southern Italy as meat was traditionally scarce, with Bolognese sauce being attributed to Northern Italy. This sauce is also widely used in Italian-American cuisine, which has diverged from its Old World origins.
Origin.
Historically, the first Italian cookbook to include a tomato based sauce, "Lo Scalco alla Moderna" ("The Modern Steward"), was written by Italian chef Antonio Latini and was published in two volumes in 1696 and 1697. Latini served as the Steward of the First Minister to the Spanish Viceroy of Naples.

</doc>
<doc id="21780" url="http://en.wikipedia.org/wiki?curid=21780" title="NBC">
NBC

The National Broadcasting Company (NBC) is an American commercial broadcast television and radio network that is the flagship property of NBCUniversal, a subsidiary of Comcast. The network is headquartered in the Comcast Building (formerly known as the GE Building) at Rockefeller Center in New York City, with additional major offices near Los Angeles (at Universal City Plaza) and in Chicago (at the NBC Tower). NBC is sometimes referred to as the "Peacock Network", in reference to its stylized peacock logo, which was originally created in 1956 for its then-new color broadcasts and became the network's official emblem in 1979.
Founded in 1926 by the Radio Corporation of America (RCA), NBC is the oldest major broadcast network in the United States. In 1986, control of NBC passed to General Electric (GE) – which previously owned RCA and NBC until 1930, when it was forced to sell the companies as a result of antitrust charges – through its $6.4 billion purchase of RCA. Following the acquisition by GE (which later sold RCA), Bob Wright served as chief executive officer of NBC, remaining in that position until his retirement in 2007, when he was succeeded by Jeff Zucker. In 2003, French media company Vivendi merged its entertainment assets with GE, forming NBC Universal. Comcast purchased a controlling interest in the company in 2011, and acquired General Electric's remaining stake in 2013. Following the Comcast merger, Zucker left NBCUniversal and was replaced as CEO by Comcast executive Steve Burke.
NBC has eleven owned-and-operated stations and nearly 200 affiliates throughout the United States and its territories, some of which are also available in Canada via pay television providers or in border areas over-the-air; NBC also maintains brand licensing agreements for international channels in South Korea and Germany.
History.
Radio.
Earliest stations: WEAF and WJZ.
During a period of early broadcast business consolidation, radio manufacturer Radio Corporation of America (RCA) had acquired New York City radio station WEAF from American Telephone & Telegraph (AT&T). Westinghouse, a shareholder in RCA, had a competing outlet in Newark, New Jersey pioneer station WJZ (no relation to the radio and television station in Baltimore currently using those call letters), which also served as the flagship for a loosely structured network. This station was transferred from Westinghouse to RCA in 1923, and moved to New York City.
WEAF acted as a laboratory for AT&T's manufacturing and supply outlet Western Electric, whose products included transmitters and antennas. The Bell System, AT&T's telephone utility, was developing technologies to transmit voice- and music-grade audio over short and long distances, using both wireless and wired methods. The 1922 creation of WEAF offered a research-and-development center for those activities. WEAF maintained a regular schedule of radio programs, including some of the first commercially sponsored programs, and was an immediate success. In an early example of "chain" or "networking" broadcasting, the station linked with Outlet Company-owned WJAR in Providence, Rhode Island; and with AT&T's station in Washington, D.C., WCAP.
New parent RCA saw an advantage in sharing programming, and after getting a license for radio station WRC in Washington, D.C., in 1923, attempted to transmit audio between cities via low-quality telegraph lines. AT&T refused outside companies access to its high-quality phone lines. The early effort fared poorly, since the uninsulated telegraph lines were susceptible to atmospheric and other electrical interference.
In 1925, AT&T decided that WEAF and its embryonic network were incompatible with the company's primary goal of providing a telephone service. AT&T offered to sell the station to RCA in a deal that included the right to lease AT&T's phone lines for network transmission.
Red and Blue Networks.
RCA spent $1 million to purchase WEAF and Washington sister station WCAP, shut down the latter station and merged its facilities with surviving station WRC; in late 1926, it subsequently announced the creation of a new division known as the National Broadcasting Company. The division's ownership was split among RCA (a majority partner at 50%), its founding corporate parent General Electric (which owned 30%) and Westinghouse (which owned the remaining 20%). NBC officially started broadcasting on November 15, 1926.
WEAF and WJZ, the flagships of the two earlier networks, were operated side-by-side for about a year as part of the new NBC. On January 1, 1927, NBC formally divided their respective marketing strategies: the "Red Network" offered commercially sponsored entertainment and music programming; the "Blue Network" mostly carried sustaining – or non-sponsored – broadcasts, especially news and cultural programs. Various histories of NBC suggest the color designations for the two networks came from the color of the pushpins NBC engineers used to designate affiliates of WEAF (red) and WJZ (blue), or from the use of double-ended red and blue colored pencils. A similar two-part/two-color strategy was utilized in the recording industry, dividing the market between classical ("cf." RCA Red Seal) and popular offerings.
On April 5, 1927, NBC expanded to the West Coast with the launch of the NBC Orange Network, also known as the Pacific Coast Network. This was followed by the debut of the NBC Gold Network, also known as the Pacific Gold Network, on October 18, 1931. The Orange Network carried Red Network programming, and the Gold Network carried programming from the Blue Network. Initially, the Orange Network recreated Eastern Red Network programming for West Coast stations at KPO in San Francisco. The Orange Network name was removed from use in 1936, and the network's affiliate stations became part of the Red Network. At the same time, the Gold Network became part of the Blue Network. In the 1930s, NBC also developed a network for shortwave radio stations, called the NBC White Network.
In 1927, NBC moved its operations to 711 Fifth Avenue in Manhattan, occupying the upper floors of a building designed by architect Floyd Brown. The space that NBC occupied was designed by Raymond Hood, who based the appearance of its multiple studio facilities on "a Gothic church, the Roman forum, a Louis XIV room and, in a space devoted to jazz, something 'wildly futuristic, with plenty of color in bizarre designs.'" NBC outgrew the Fifth Avenue facilities in 1933.
In 1930, General Electric was charged with antitrust violations, resulting in the company's decision to divest itself of RCA. The newly separate company signed leases to move its corporate headquarters into the new Rockefeller Center in 1931. John D. Rockefeller, Jr., founder and financier of Rockefeller Center, arranged the deal with GE chairman Owen D. Young and RCA president David Sarnoff. When it moved into the complex in 1933, RCA became the lead tenant at 30 Rockefeller Plaza, known as the "RCA Building" (now the GE Building), which housed NBC's production studios as well as theaters for RCA-owned RKO Pictures.
Chimes.
The iconic three-note NBC chimes came about after several years of development. The three-note sequence, G-E'-C', was first heard over Red Network affiliate WSB in Atlanta, with a second inversion C Major triad as its outline. An executive at NBC's New York headquarters heard the WSB version of the notes during the networked broadcast of a Georgia Tech football game and asked permission to use it on the national network. NBC started to use the chimes sequence in 1931, and it eventually became the first audio trademark to be accepted by the U.S. Patent and Trademark Office.
A variant sequence with an additional note, G-E'-C'-G, known as "the fourth chime", was used during significant events of extreme urgency (including during World War II, especially in the wake of the December 1941 attack on Pearl Harbor; on D-Day and during disasters). The NBC chimes were mechanized in 1932 by Rangertone founder Richard H. Ranger; their purpose was to send a low-level signal of constant amplitude that would be heard by the various switching stations manned by NBC and AT&T engineers, and to be used as a system cue for switching individual stations between the Red and Blue network feeds. Contrary to popular legend, the G-E'-C' notes were not originally intended to reference to the General Electric Company (an early shareholder in NBC's founding parent RCA and whose Schenectady, New York radio station, WGY, was an early affiliate of NBC Red). The three-note sequence remains in use by the NBC television network, most notably incorporated into the John Williams-composed theme music used by NBC News, "The Mission" (first composed in 1985 for "NBC Nightly News").
New beginnings: The Blue Network becomes ABC.
In 1934, following the government agency's creation, the Mutual Broadcasting System filed a complaint to the Federal Communications Commission (FCC), claiming it ran into difficulties trying to establish new radio stations in a market largely controlled by NBC and the Columbia Broadcasting System (CBS). In 1938, the FCC began a series of investigations into the monopolistic effects of network broadcasting. A report published by Commission in 1939 found that NBC's two networks and its owned-and-operated stations dominated audiences, affiliates and advertising in American radio; this led the Commission to file an order to RCA to divest itself of either NBC Red or NBC Blue. 
After Mutual's appeals were rejected by the FCC, RCA filed its own appeal to overturn the divestiture order. However in 1941, the company decided to sell NBC Blue in the event its appeal was denied. The Blue Network was formally named NBC Blue Network, Inc. and NBC Red became NBC Red Network, Inc. for corporate purposes. Both networks formally divorced their operations on January 8, 1942, with the Blue Network being referred to on-air as either "Blue" or "Blue Network", and Blue Network Company, Inc. serving as its official corporate name. NBC Red, meanwhile, became known on-air as simply "NBC". Investment firm Dillon, Read & Co. placed a $7.5 million bid for NBC Blue, an offer that was rejected by NBC executive Mark Woods and RCA president David Sarnoff.
After losing on final appeal before the U.S. Supreme Court in May 1943, RCA sold Blue Network Company, Inc., for $8 million to the American Broadcasting System, a recently founded company owned by Life Savers magnate Edward J. Noble. After the sale was completed on October 12, 1943, Noble acquired the rights to the Blue Network name, leases on landlines, the New York studios, two-and-a-half radio stations (WJZ in Newark/New York City; KGO in San Francisco and WENR in Chicago, which shared a frequency with Prairie Farmer station WLS); contracts with actors; and agreements with around 60 affiliates. In turn, to comply with FCC radio station ownership limits of the time, Noble sold off his existing New York City radio station WMCA. Noble, who wanted a better name for the network, acquired the branding rights to the "American Broadcasting Company" name from George B. Storer in 1944. The Blue Network became ABC officially on June 15, 1945, after the sale was completed.
Defining radio's golden age.
NBC became home to many of the most popular performers and programs on the air. Al Jolson, Jack Benny, Edgar Bergen, Bob Hope, Fred Allen, and Burns and Allen called NBC home, as did Arturo Toscanini's NBC Symphony Orchestra, which the network helped him create. Other programs featured on the network included "Vic and Sade", "Fibber McGee and Molly", "The Great Gildersleeve" (arguably broadcasting's first spin-off program, from "Fibber McGee"), "One Man's Family", "Ma Perkins" and "Death Valley Days". NBC stations were often the most powerful, and some occupied unique clear-channel national frequencies, reaching hundreds or thousands of miles at night.
In the late 1940s, rival CBS gained ground by allowing radio stars to use their own production companies to produce programs, which became a profitable move for much of its talent. In the early years of radio, stars and programs commonly hopped between networks when their short-term contracts expired. During 1948 and 1949, beginning with the nation's top radio star, Jack Benny, many NBC performers – including Edgar Bergen and Charlie McCarthy, Burns and Allen and Frank Sinatra – jumped to CBS.
In addition, NBC stars began migrating to television, including comedian Milton Berle, whose "Texaco Star Theater" on the network became television's first major hit. Conductor Arturo Toscanini conducted ten television concerts on NBC between 1948 and 1952. The concerts were broadcast on both television and radio, in what perhaps was the first such instance of simulcasting. Two of the concerts were historic firsts – the first complete telecast of Beethoven's Symphony No. 9, and the first complete telecast of Verdi's "Aida" (starring Herva Nelli and Richard Tucker), performed in concert rather than with scenery and costumes.
Aiming to keep classic radio alive as television matured, and to challenge CBS's Sunday night radio lineup, which featured much of the programs and talent that had to moved that network following the defection of Jack Benny to CBS, NBC launched "The Big Show" in November 1950. This 90-minute variety show updated radio's earliest musical variety style with sophisticated comedy and dramatic presentations. Featuring stage legend Tallulah Bankhead as hostess, it lured prestigious entertainers, including Fred Allen, Groucho Marx, Lauritz Melchior, Ethel Barrymore, Louis Armstrong, Ethel Merman, Bob Hope, Danny Thomas, Douglas Fairbanks, Jr. and Ella Fitzgerald. However, "The Big Show"‍ '​s initial success did not last despite critical praise, as most of its potential listeners were increasingly becoming television viewers. The show lasted two years, with NBC losing around $1 million on the project (the network was only able to sell advertising time during the middle half-hour of the program each week).
NBC's last major radio programming push, beginning on June 12, 1955, was "Monitor", a creation of NBC President Sylvester "Pat" Weaver, who also created the innovative programs "Today", "The Tonight Show" and "Home" for the companion television network. "Monitor" was a continuous all-weekend mixture of music, news, interviews and features, with a variety of hosts including well-known television personalities Dave Garroway, Hugh Downs, Ed McMahon, Joe Garagiola and Gene Rayburn. The potpourri show tried to keep vintage radio alive by featuring segments from Jim and Marian Jordan (in character as Fibber McGee and Molly); Peg Lynch's dialog comedy "Ethel and Albert" (with Alan Bunce); and iconoclastic satirist Henry Morgan. "Monitor" was a success for a number of years, but after the mid-1960s, local stations, especially those in larger markets, were reluctant to break from their established formats to run non-conforming network programming. One exception was "Toscanini: The Man Behind the Legend", a weekly series commemorating the great conductor's NBC broadcasts and recordings which ran for several years beginning in 1963. After "Monitor" ended its 20-year run on January 26, 1975, little remained of NBC network radio beyond hourly newscasts and news features, and Sunday morning religious program "The Eternal Light".
Decline.
On June 18, 1975, NBC launched the NBC News and Information Service (NIS), which provided up to 55 minutes of news per hour around the clock to local stations that wanted to adopt an all-news radio format. NBC carried the service on WRC in Washington, and on its owned-and-operated FM stations in New York City, Chicago and San Francisco. NIS attracted several dozen subscribing stations, but by the fall of 1976, NBC determined that it could not project that the service would ever become profitable and gave its affiliates six months' notice that it would be discontinued. NIS ended operations on May 29, 1977. In 1979, NBC launched The Source, a modestly successful secondary network providing news and short features to FM rock stations.
The NBC Radio Network also pioneered personal advice call-in national talk radio with a satellite-distributed evening talk show, TalkNet; the program featured Bruce Williams (providing personal financial advice), Bernard Meltzer (personal and financial advice) and Sally Jessy Raphael (personal and romantic advice). While never much of a ratings success, TalkNet nonetheless helped further the national talk radio format. For affiliates, many of them struggling AM stations, TalkNet helped fill evening time slots with free programming, allowing the stations to sell local advertising in a dynamic format without the cost associated with producing local programming. Some in the industry feared this trend would lead to increasing control of radio content by networks and syndicators.
General Electric acquired RCA in 1986, and with it NBC, signaling the beginning of the end of NBC Radio. Three factors led to the radio division's demise: GE decided that radio did not fit its strategy, while the radio division had not been profitable for many years. In addition, FCC ownership rules at the time prevented companies acquiring broadcast properties from owning both a radio and television division. In the summer of 1987, GE sold NBC Radio's network operations to Westwood One, and sold off the NBC-owned stations to various buyers. By 1990, the NBC Radio Network as an independent programming service was pretty much dissolved, becoming a brand name for content produced by Westwood One, and ultimately by, ironically, CBS Radio. The Mutual Broadcasting System, which Westwood One had acquired two years earlier, met the same fate, and essentially merged with NBC Radio.
GE's divestiture of NBC's entire radio division was the first cannon shot of what would play out in the national broadcast media, as each of the Big Three broadcast networks were soon acquired by other corporate entities. NBC was a particularly noteworthy case in that it was the first to be acquired – and was bought by a conglomerate "outside" the broadcast industry as GE otherwise primarily served as a manufacturing company. Prior to the GE acquisition, NBC operated its radio division partly out of tradition, and partly to meet its then-FCC-mandated requirement to distribute programming for the public good (the broadcast airwaves are owned by the public; as that broadcast spectrum is limited and only so many broadcast stations existed, this served as the basis for government regulation requiring broadcasters to provide certain content that meets the needs of the public). Syndicators such as Westwood One were not subject to such rules as they did not own any stations. GE's divestiture of NBC Radio – known as "America's First Network" – in many ways marked the "beginning of the end" of the old era of regulated broadcasting and the ushering in of the new, largely unregulated industry that is present today.
By the late 1990s, Westwood One was producing NBC Radio-branded newscasts on weekday mornings. These were discontinued in 1999, and the few remaining NBC Radio Network affiliates became affiliates of CNN Radio, carrying the Westwood-owned service's hourly newscasts 24 hours a day. In 2003, Westwood One began distributing NBC News Radio, a new service featuring minute-long news updates read by television anchors and reporters from NBC News and MSNBC, with content written by Westwood One employees.
Restoration.
On March 1, 2012, Dial Global announced that it would discontinue CNN Radio, and replace it with an expansion of NBC News Radio on April 1, 2012. This marked the first time since Westwood One's purchase of NBC Radio and its properties that NBC would have a 24-hour presence on radio. A previous program, "First Light", placed new emphasis on the NBC brand after diminishing it over the years. With the change, NBC News Radio expanded its offerings from 60-second news updates airing only on weekdays to feature two hourly full-length newscasts 24 hours a day. Subsequently, on September 4, 2012, Dial Global launched a sports-talk radio service, NBC Sports Radio.
Television.
For many years, NBC was closely identified with David Sarnoff, who used it as a vehicle to sell consumer electronics. RCA and Sarnoff had captured the spotlight by introducing all-electronic television to the public at the 1939–40 New York World's Fair, simultaneously initiating a regular schedule of programs on the NBC-RCA television station in New York City. President Franklin D. Roosevelt appeared at the fair, before the NBC cameras, becoming the first U.S. president to appear on television on April 30, 1939 ( of the FDR telecast is available at the David Sarnoff Library). The broadcast was transmitted by NBC's New York television station W2XBS Channel 1 (later WNBC-TV; now WNBC, channel 4) and was seen by about 1,000 viewers within the station's roughly 40 mi coverage area from its transmitter at the Empire State Building.
The following day (May 1), four models of RCA television sets went on sale to the general public in various department stores around New York City, which were promoted in a series of splashy newspaper ads. DuMont Laboratories (and others) had actually offered the first home sets in 1938 in anticipation of NBC's announced April 1939 television launch. Later in 1939, NBC took its cameras to professional football and baseball games in the New York City area, establishing many "firsts" in television broadcasting.
Reportedly, the first NBC Television "network" program was broadcast on January 12, 1940, when a play titled "Meet The Wife" was originated at the W2XBS studios at Rockefeller Center and rebroadcast by W2XB/W2XAF (now WRGB) in Schenectady, which received the New York station directly off-air from a tower atop a mountain and relayed the live signal to the Capital District. About this time, occasional special events were also broadcast in Philadelphia (over W3XE, later called WPTZ, now known as KYW-TV) as well as Schenectady. The most ambitious NBC television "network" program of the pre-war era was the telecast of the Republican National Convention held in Philadelphia in the summer of 1940, which was fed live to the New York City and Schenectady stations. However, despite major promotion by RCA, television sales in New York during 1939 and 1940 were disappointing, primarily due to the high cost of the sets, and the lack of compelling regularly schedule programming. Most sets were sold to bars, hotels and other public places, where the general public viewed special sports and news events.
Television's experimental period ended, as the FCC allowed full-fledged commercial television broadcasts to begin on July 1, 1941. NBC station W2XBS in New York City received the first commercial license, adopting the call letters WNBT. The first official, paid television advertisement broadcast by any U.S. station was for watch manufacturer Bulova, which aired that day, just before the start of a Brooklyn Dodgers baseball telecast on WNBT. The ad consisted of test pattern, featuring the newly assigned WNBT call letters, which was modified to resemble a clock – complete with functioning hands – with the Bulova logo (featuring the phrase "Bulova Watch Time") in the lower right-hand quadrant of the test pattern (a photograph of the NBC camera filming the test pattern-advertisement for that ad can be seen at ). Among the programs that aired during the first week of WNBT's new, commercial schedule was "The Sunoco News", a simulcast of the Sun Oil-sponsored NBC Radio program anchored by Lowell Thomas; amateur boxing at Jamaica Arena; the Eastern Clay Courts tennis championships; programming from the USO; the spelling bee-type game show "Words on the Wing"; a few feature films; and a one-time-only, test broadcast of the game show "Truth or Consequences", sponsored by Lever Brothers.
Prior to the first commercial television broadcasts and paid advertisements on WNBT, non-paid television advertising existed on an experimental basis dating back to 1930. NBC's earliest non-paid television commercials may have been those seen during the first Major League Baseball game ever telecast, between the Brooklyn Dodgers and Cincinnati Reds, on August 26, 1939 over W2XBS. In order to secure the rights to televise the game, NBC allowed each of the Dodgers' regular radio sponsors at the time to have one commercial during the telecast. The ads were conducted by Dodgers announcer Red Barber: for Ivory Soap, he held up a bar of the product; for Mobilgas he put on a filling station attendant's cap while giving his spiel; and for Wheaties he poured a bowl of the product, added milk and bananas, and took a big spoonful.
Limited, commercial programming continued until the U.S. entered World War II. Telecasts were curtailed in the early years of the war, then expanded as NBC began to prepare for full-time service upon the end of the war. Even before the war concluded, a few programs were sent from New York City to affiliated stations in Philadelphia (WPTZ) and Albany/Schenectady (WRGB) on a regular weekly schedule beginning in 1944, the first of which is generally considered to be the pioneering special interest/documentary show "The Voice of Firestone Televues", a television offshoot of "The Voice of Firestone", a mainstay on NBC radio since 1928, which was transmitted from New York City to Philadelphia and Schenectady on a regular, weekly basis beginning on April 10, 1944. The series is considered to be the NBC television network's first regularly scheduled program.
On V-E Day, May 8, 1945, WNBT broadcast several hours of news coverage, and remotes from around New York City. This event was promoted in advance by NBC with a direct-mail card sent to television set owners in the New York area. At one point, a WNBT camera placed atop the marquee of the Hotel Astor panned the crowd below celebrating the end of the war in Europe. The vivid coverage was a prelude to television's rapid growth after the war ended.
The NBC television network grew from its initial post-war lineup of four stations. The 1947 World Series featured two New York City area teams (the Yankees and the Dodgers), and television sales boomed locally, since the games were being telecast in the New York market. Additional stations along the East Coast and in the Midwest were connected by coaxial cable through the late 1940s, and in September 1951 the first transcontinental telecasts took place.
The post-war 1940s and early 1950s brought success for NBC in the new medium. Television's first major star, Milton Berle, whose "Texaco Star Theatre" began in June 1948, drew the first large audiences to NBC Television. Under its innovative president, Sylvester "Pat" Weaver, the network launched "Today" and "The Tonight Show", which would bookend the broadcast day for over 50 years, and which still lead their competitors. Weaver, who also launched the genre of periodic 90-minute network "spectaculars", network-produced motion pictures and the live 90-minute Sunday afternoon series "Wide Wide World", left the network in 1955 in a dispute with its chairman David Sarnoff, who subsequently named his son Robert Sarnoff as president.
In 1951, NBC commissioned Italian-American composer Gian Carlo Menotti to compose the first opera ever written for television; Menotti came up with "Amahl and the Night Visitors", a 45-minute work for which he wrote both music and libretto, about a disabled shepherd boy who meets the Three Wise Men and is miraculously cured when he offers his crutch to the newborn Christ Child. It was such a stunning success that it was repeated every year on NBC from 1951 to 1966, when a dispute between Menotti and NBC ended the broadcasts. However, by 1978, Menotti and NBC had patched things up, and an all-new production of the opera, filmed partly on location in the Middle East, was telecast that year.
Color television.
While rivals CBS and the DuMont Television Network also had plans to begin offering color television broadcasts, RCA convinced the FCC to approve its color system in December 1953. NBC was ready with color programming within days of the Commission's decision. NBC began the transition with a few shows in 1954, and broadcast its first program to air all episodes in color beginning that summer, "The Marriage".
In 1955, NBC broadcast a live production in color of "Peter Pan", a new Broadway musical adaptation of J. M. Barrie's beloved play, on the "Producers' Showcase" anthology series, The first such telecast of its kind, the broadcast starred the musical's entire original cast, led by Mary Martin as Peter and Cyril Ritchard in a dual role as Mr. Darling and Captain Hook. The broadcast drew the highest ratings for a television program for that period. It was so successful that NBC restaged it as a live broadcast a mere ten months later; in 1960, long after "Producers' Showcase" had ended its run, "Peter Pan", with most of the 1955 cast, was restaged again, this time as a standalone special, and was videotaped so that it would no longer have to be performed live on television.
During a National Association of Broadcasters meeting in Chicago in 1956, NBC announced that its owned-and-operated station in that market, WNBQ (now WMAQ-TV), had become the first television station in the country to broadcast its programming in color (airing at least six hours of color broadcasts each day). In 1959, NBC premiered a televised version of the radio program "The Bell Telephone Hour", which aired in color from its debut; the program would continue on the NBC television network for nine more years until it ended in 1968.
In 1961, NBC approached Walt Disney about acquiring the rights to his anthology series, offering to produce the program in color. Disney was in the midst of negotiating a new contract to keep the program (then known as "Walt Disney Presents") on ABC, however ABC president Leonard Goldenson said that it could not counter the offer, as the network did not have the technical and financial resources to carry the program in color. Disney subsequently struck a deal with NBC, which began airing the anthology series in the format in September 1961 (as "Walt Disney's Wonderful World of Color"). As many of the Disney programs that aired in black-and-white on ABC were actually filmed in color, they could easily be re-aired in the format on the NBC broadcasts. In January 1962, NBC's telecast of the Rose Bowl became the first college football game ever to be telecast in color.
By 1963, much of NBC's prime time schedule was presented in color, although some popular series (such as "The Man from U.N.C.L.E.", which premiered in late 1964) were broadcast in black-and-white for their entire first season. In the fall of 1965, NBC was broadcasting 95% of its prime time schedule in color (with the exceptions of "I Dream of Jeannie" and "Convoy"), and began billing itself as "The Full Color Network." Without television sets to sell, rival networks followed more slowly, finally committing to an all-color lineup in prime time in the 1966–67 season. "Days of Our Lives" became the first soap opera to premiere in color, when it debuted in November 1965.
NBC contracted with Universal Studios in 1964 to produce the first feature-length film produced for television, "See How They Run", which first aired on October 17, 1964; its second television movie, "The Hanged Man", aired six weeks later on November 28. Even while the presentations performed well in the ratings, NBC did not broadcast another made-for-TV film for two years.
In 1967, NBC reached a deal with Metro-Goldwyn-Mayer (MGM) to acquire the broadcast rights to the classic 1939 film "The Wizard of Oz". CBS, which had televised the film annually since 1956, refused to meet MGM's increased fee to renew its television rights. "Oz" had been, up to then, one of the few programs that CBS had telecast in color. However by 1967, color broadcasts had become standard on television, and the film simply became another title in the list of specials that NBC telecast in the format. The film's showings on NBC were distinctive as it televised "The Wizard of Oz" without a hosted introduction, as CBS had long done; it was also slightly edited for time in order to make room to air more commercials. Despite the cuts, however, it continued to score excellent television ratings in those pre-VCR days, as audiences were generally unable to see the film any other way at that time. NBC aired "The Wizard of Oz" each year from 1968 to 1976, when CBS, realizing that they may have committed a colossal blunder by letting a huge ratings success like "Oz" go to another network, agreed to pay MGM more money to re-acquire the rights to show the film.
The late 1960s brought big changes in the programming practices of the major television networks. As baby boomers reached adulthood, NBC, CBS and ABC began to realize that much of their existing programming had not only been running for years, but had audiences that skewed older. In order to attract the large youth population that was highly attractive to advertisers, the networks moved to clean house of a number of veteran shows. In NBC's case, this included programs like "The Bell Telephone Hour" and "Sing Along With Mitch", which both had an average viewer age of 50. During this period, the networks came to define adults between the ages of 18 and 49 as their main target audience, although depending on the show, this could be subdivided into other age demos: 35–45, 18–25 or 18–35. Regardless of the exact target demographic, the general idea was to appeal to viewers who were not close to retirement age and to modernize television programming, which the networks felt overall were stuck in a 1950s mentality, to closely resemble contemporary American society.
1970s doldrums.
The 1970s started strongly for NBC thanks to hits like "Adam-12", "Rowan & Martin's Laugh-In", "Ironside", "The Dean Martin Show" and "The Flip Wilson Show". However, despite of the success of such new shows as the "NBC Mystery Movie", "Sanford and Son", "Chico and the Man", "Little House on the Prairie", "The Midnight Special", "The Rockford Files", "Police Woman" and "Emergency!", as well as continued success from veterans like "The Tonight Show Starring Johnny Carson" and "The Wonderful World of Disney", the network entered a slump in the middle of the decade. "Disney", in particular, saw its ratings nosedive once CBS put "60 Minutes" up against the program in the Sunday 7:00 p.m. time slot in the 1975–76 season.
In 1974, under new president Herb Schlosser, the network tried to attract younger viewers with a series of costly movies, miniseries and specials. This failed to attract the desirable 18–34 demographic, and simultaneously alienated older viewers. None of the new prime-time shows that NBC introduced in the fall of 1975 earned a second season renewal, all failing in the face of established competition. The network's lone breakout success that season was the groundbreaking late-night comedy/variety show, "NBC's Saturday Night" – which would be renamed "Saturday Night Live" in 1976, after the cancellation of a Howard Cosell-hosted program of the same title on ABC – which replaced reruns of "The Tonight Show" that previously aired in its Saturday time slot.
In 1978, Schlosser was promoted to executive vice presidency at RCA, and a desperate NBC lured Fred Silverman away from top-rated ABC to turn its fortunes around. With the notable exceptions of "Diff'rent Strokes" and its spin-off "The Facts of Life", "Real People" and the miniseries "Shōgun", Silverman was unable to pull out a hit. Failures accumulated rapidly under his watch (such as "Hello, Larry", "Supertrain", "Pink Lady and Jeff", "The Krofft Superstar Hour" and "The Waverly Wonders"). Ironically, many of them were beaten in the ratings by shows that Silverman had greenlit during his previous tenures at CBS and ABC.
During this time, several longtime affiliates also defected from NBC in markets such as Atlanta (WSB-TV), Baltimore (WBAL-TV), Baton Rouge (WBRZ-TV), Charlotte (WSOC-TV), Dayton (WDTN), Indianapolis (WRTV), Jacksonville (WTLV), Minneapolis-St. Paul (KSTP-TV), San Diego (KGTV), Schenectady (WRGB) and Wheeling (WTRF-TV). Most were wooed away by ABC, which had lifted out of last place to become the #1 network during the late 1970s and early 1980s, while WBAL-TV, WRGB and WTRF-TV went to CBS. In the case of WSB-TV and WSOC-TV, which have both since become ABC affiliates, both stations were (and remain) under common ownership with Cox Enterprises, with its other NBC affiliate at the time, WIIC-TV in Pittsburgh (which would become WPXI in 1981 and also remains owned by Cox), only staying with the network because WIIC-TV itself was in a distant third to CBS-affiliated powerhouse KDKA-TV and ABC affiliate WTAE-TV (KDKA-TV, owned at the time by Group W and now owned by CBS, infamously passed up affiliating with NBC after Westinghouse bought the station from DuMont in 1954, leading to an acrimonious relationship between NBC and Westinghouse that lasted for years afterward). In markets such as San Diego, Charlotte and Jacksonville, NBC had little choice but to affiliate with a UHF station, with the San Diego station (KNSD) eventually becoming an NBC O&O. In Wheeling, NBC ultimately upgraded its affiliation when it partnered with WTOV-TV in nearby Steubenville, Ohio, overtaking former affiliate WTRF-TV in the ratings by a large margin. Other smaller television markets like Yuma, Arizona waited many years to get another local NBC affiliate (first with KIVA, and later KYMA). The stations in Baltimore, Dayton and Jacksonville, however, have since rejoined the network.
After President Jimmy Carter pulled the U.S. team out of the 1980 Summer Olympics, NBC canceled a planned 150 hours of coverage (which had cost $87 million for the broadcast rights), placing the network's future in doubt. It had been counting on the broadcasts to help promote its new fall shows, and had been estimated to pull in $170 million in advertising revenue.
The press was merciless towards Silverman, but the two most savage attacks on his leadership came from within the network. The company that composed the promotional theme for NBC's "Proud as a Peacock" image campaign created a parody song called "Loud as a Peacock", which was broadcast on Don Imus' program on WNBC radio in New York played. An angered Silverman ordered all remaining copies of the spoof destroyed, although some copies remain in circulation. "Saturday Night Live" writer and occasional performer Al Franken satirized Silverman in a sketch on the program titled "Limo for a Lame-O". Silverman later admitted he "never liked Al Franken to begin with," and the sketch ruined Franken's chance of succeeding Lorne Michaels as executive producer of "SNL" following his 1981 departure (with the position going to Jean Doumanian, who was fired after one season following declining ratings and negative critical reviews. Michaels would later return to the show in 1985).
Tartikoff's turnaround.
Fred Silverman resigned as entertainment president in the summer of 1981. Grant Tinker, a highly regarded producer who co-founded MTM Enterprises with then-wife Mary Tyler Moore, became president of the network and Brandon Tartikoff became president of the entertainment division. Tartikoff inherited a schedule full of aging dramas and very few sitcoms, but showed patience with promising programs. One such show was the critically acclaimed "Hill Street Blues", which suffered from poor ratings during its first season. Rather than canceling the show, he moved it Emmy Award-winning police drama from Steven Bochco to Thursdays, where its ratings improved dramatically. He used the same tactics with "St. Elsewhere" and "Cheers". Shows like these were able to get the same ad revenue as their higher-rated competition because of their desirable demographics, upscale adults ages 18–34. While the network claimed moderate successes with "Gimme a Break!", "Silver Spoons", "Knight Rider" and "Remington Steele", its biggest hit during this period was "The A-Team", which, at 10th place, was the network's only program to rank in the Nielsen Top-20 for the 1982–83 season, and ascended to third place the following year. These shows helped NBC through the disastrous 1983–84 season, which saw none of its nine new fall shows gaining a second year.
In February 1982, NBC canceled Tom Snyder's "The Tomorrow Show" and gave the 12:35 a.m. time slot to 34-year-old comedian David Letterman. Though Letterman was unsuccessful with his weekday morning talk show effort for the network (which debuted on June 23, 1980), "Late Night with David Letterman" proved much more successful, lasting for 11 years and serving as the launching pad for another late-night talk franchise that continues to this day.
In 1984, the huge success of "The Cosby Show" led to a renewed interest in sitcoms, while "Family Ties" and "Cheers", both of which premiered in 1982 to mediocre ratings (the latter ranking at near dead last among all network shows during the 1982–83 season), saw their viewership increase from having "Cosby" as a lead-in. The network rose from third place to second in the ratings during the 1984–85 season and reached first place in 1985–86, with hits "The Golden Girls", "Miami Vice", "227", "Night Court", "Highway to Heaven" and "Hunter". The network's upswing continued late into the decade with "ALF", "Amen", "Matlock", "L.A. Law", "The Hogan Family", "A Different World", "Empty Nest" and "In the Heat of the Night". In 1986, Bob Wright was appointed as chairman of NBC.
In the fall of 1987, NBC conceived a syndication package for its owned-and-operated stations, under the brand "Prime Time Begins at 7:30", consisting of five sitcoms that each aired once a week, and were produced by various production companies contracted by NBC. The series included "Marblehead Manor" (from Paramount Television, airing Mondays), centering around a mansion owner and the people who live with him; "She's the Sheriff" (from Lorimar-Telepictures and airing Tuesdays), a comeback vehicle for Suzanne Somers which cast her as a widowed county sheriff; a series adapted from the George S. Kaufman play "You Can't Take It With You" (airing Wednesdays), starring Harry Morgan; "Out of This World" (from MCA Television and airing Thursdays), which starred Maureen Flannigan as a teenager born to an alien father and human mother that develops supernatural abilities on her 15th birthday; and a revival of the short-lived 1983 NBC series "We Got It Made" (produced by Fred Silverman for MGM Television and closing out the week on Fridays), as part of an ongoing trend at the time in which former network series were revived in first-run syndication.
The package was aimed at attracting viewers to NBC stations in the half-hour preceding prime time (8:00 p.m. in the Eastern and Pacific Time Zone, 7:00 p.m. elsewhere), and was conceived as a result of the FCC's loosening of the Prime Time Access Rule, legislation passed in 1971 that required networks to turn over the 7:30 p.m. (Eastern) time slot to local stations to program local or syndicated content; and the relaxation of the Financial Interest and Syndication Rules, which had prevented networks from producing content from their own syndication units to fill the void. The shows that were part of the package were regularly outrated in many markets by such syndicated game shows as "Wheel of Fortune", "Jeopardy!" and "Hollywood Squares". "Marblehead Manor", "We Got It Made" and "You Can't Take It With You" were cancelled at the end of the 1987–88 season, with "She's the Sheriff" lasting one more season in weekend syndication before its cancellation. "Out of This World" ran for three additional seasons, airing mainly on weekends, and was the most successful of the five series.
NBC aired the first of seven consecutive Summer Olympic Games broadcasts when it covered the 1988 Games in Seoul, South Korea. The 1988–89 season saw NBC have an astonishing 18 series in Nielsen's year-end Top 30 most-watched network programs; it also ranked at first place in the weekly ratings for more than 12 months, an unprecedented achievement that has not been duplicated since. The network continued its hot streak into the early 1990s with new hits such as "The Fresh Prince of Bel-Air", "Blossom" and "Law & Order".
"Must See TV".
In 1991, Tartikoff left his role as NBC's President of Entertainment to take an executive position at Paramount Pictures. In the course of a decade, he had taken control of a network with no shows in the Nielsen Top 10 and left it with five. Tartikoff was succeeded by Warren Littlefield, whose first years as entertainment president proved shaky as a result of most of the Tartikoff-era hits ending their runs. Some blamed Littlefield for losing David Letterman to CBS after naming Jay Leno as the successor to Johnny Carson on "The Tonight Show", following the latter's retirement as host in May 1992. Things turned around with the launches of new hit series such as "Mad About You", "Wings", "Sisters", "Frasier", "Friends", "ER" and "Will & Grace".
One of Tartikoff's late acquisitions, "Seinfeld" initially struggled from its debut in 1989 as a summer series, but grew to become one of NBC's top-rated shows after it was moved to Thursdays in the timeslot following "Cheers". "Seinfeld" ended its run in 1998, becoming the latest overall television program in the U.S. to end its final season at the leading rank in the Nielsen ratings for a single television season. Consequently, "Friends" emerged as NBC's biggest television show after the 1998 "Seinfeld" final broadcast. It dominated the ratings, never leaving the top five watched shows of the year from its second through tenth seasons and landing on the number-one spot during season eight in the 2001–02 season as the latest sitcom in the U.S. to lead the annual Nielsen primetime television ratings. "Cheers" spinoff "Frasier" became a critical and commercial success, usually landing in the Nielsen Top 20 – although its ratings were overshadowed to a minor extent by "Friends" – and went on to win numerous Emmy Awards (eventually setting a record for a sitcom that lasted until it was overtaken by "Modern Family" in 2014). In 1994, the network began branding its strong Thursday night lineup, mainly in reference to the comedies airing in the first two hours, under the "Must See TV" tagline (which during the mid- and late 1990s, was also applied to NBC's comedy blocks on other nights, particularly on Tuesdays).
By the mid-1990s, NBC's sports division, headed by Dick Ebersol, had rights to three of the four major professional sports leagues (the NFL, Major League Baseball and the NBA), the Olympics, and the national powerhouse Notre Dame Fighting Irish football team. The "NBA on NBC" enjoyed great success in the 1990s due in large part to the Chicago Bulls' run of six championships at the hands of superstar Michael Jordan. However, NBC Sports would suffer a major blow in 1998, when it lost the rights to the American Football Conference (AFC) to CBS, which itself had lost rights to the National Football Conference (NFC) to Fox four years earlier; the deal stripped NBC of National Football League (NFL) game telecasts after 59 years and AFC games after 36 years (dating back to its existence as the American Football League prior to its 1970 merger with the NFL).
Littlefield left NBC in 1998 to pursue a career as a television and film producer, with the network subsequently going through three entertainment presidents in three years. Littlefield was replaced as president of NBC Entertainment by Scott Sassa, who oversaw the development of such shows as "The West Wing", "" and "Fear Factor". After Sassa was reassigned to NBC's West Coast Division, Garth Ancier was named as his replacement in 1999. Jeff Zucker then succeeded Ancier as president of NBC Entertainment in 2000.
New century, new problems.
At the start of the 2000s, NBC's fortunes started to take a rapid turn for the worse. The network had already lost many viewers in the late 1990s who boycotted NBC and its programming after the cancellation of the long-running soap opera "Another World" in 1999. That year, CBS (which had languished in the ratings after losing the NFL) longstanding ratings lead ended as CBS overtook it for first place. In 2001, CBS chose to move its hit reality series "Survivor" to serve as the anchor of its Thursday night lineup. Its success was taken as a suggestion that NBC's nearly two decades of dominance on Thursday nights could be broken; even so, the strength of "Friends", "Will & Grace", "ER" and "Just Shoot Me!" (the latter of which saw its highest viewership following its move to that night in the 2000–01 season) helped the network continue to lead the Thursday ratings. Overall, NBC retook its first place lead that year, and spent much of the next four years (with the exception of the 2002–03 season, when it was briefly jumped again by CBS for first) in the top spot.
On the other hand, NBC was stripped of the broadcast rights to two other major sports leagues: it lost Major League Baseball to Fox after the 2000 season (by that point, NBC only had alternating rights to the All-Star Game, League Championship Series and World Series); and, later, the NBA to ABC after the 2001–02 season. After losing the NBA rights, NBC's major sports offerings were reduced to the Olympics (which in 2002, expanded to include rights to the Winter Olympics, as part of a contract that gave it the U.S. television rights to both the Summer and Winter Olympics through 2012), PGA Tour golf events and a floundering Notre Dame football program.
In October 2001, NBC acquired Spanish-language network Telemundo from Liberty Media and Sony Pictures Entertainment for $2.7 billion, beating out other bidders including CBS/Viacom. The deal was finalized in 2002.
In 2003, French entertainment conglomerate Vivendi acquired a 49% interest in NBC from General Electric, integrating the company with Vivendi's various film, television and amusement properties (including Universal Pictures), under the integrated NBC Universal. In 2004, Zucker was promoted to the newly created position of president of NBC Universal Television Group. Kevin Reilly became the new president of NBC Entertainment.
After "Friends" and "Frasier" both ended their runs in 2004, NBC was left with several moderately rated shows and few true hits. In particular, "Friends" spin-off "Joey", despite a relatively strong start, started to falter in the ratings during its second season. The 2004–05 season saw NBC become the first major network to air select dramas in letterbox over its analog broadcast feed; the move was done in the hopes of attracting new viewers, although the network saw only a slight boost.
In December 2005, NBC began its first week-long primetime game show event, "Deal or No Deal"'; the series garnered high ratings, and returning as a weekly series in March 2006. Otherwise, the 2005–06 season was one of the worst for NBC in three decades, with only one fall series, the sitcom "My Name Is Earl", surviving for a second season; the sole remaining anchor of the "Must See TV" lineup, "Will & Grace" also saw its ratings decline. That season, NBC's ratings freefalled to fourth place, behind a resurgent ABC, Fox (which would eventually become the most-watched U.S. broadcast network in the 2007–08 season) and top-rated CBS (which led for much of the remainder of the decade). During this time, all of the networks faced audience erosion from increased competition by cable television, home video, video games and the Internet, with NBC being the hardest hit.
The 2006–07 season was a mixed bag for the network, with "Deal or No Deal" remaining strong and "Heroes" becoming a surprise hit on Monday nights, while the highly touted "Studio 60 on the Sunset Strip" (from "West Wing" creator Aaron Sorkin) lost a third of its premiere-night viewers by Week 6 and was eventually cancelled; two critically acclaimed sitcoms, "The Office" and "30 Rock", also pulled in modest successes and went on to win the Emmy Award for Outstanding Comedy Series for four consecutive years. The network also regained the rights to the NFL after eight years that season when it acquired the "Sunday Night Football" package from ESPN (as part of a deal that also saw "Monday Night Football" move to ESPN from ABC). However, despite this, NBC remained at a very distant fourth place, barely ranking ahead of The CW.
However, NBC did experience success with its summer schedule, despite its declining ratings during the main broadcast season. "America's Got Talent", a reality talent competition series that premiered in 2006, earned a 4.6 rating in the 18-49 demographic, higher than that earned by the 2002 premiere of Fox's "American Idol". "Got Talent" (which is the flagship of a international talent competition franchise) would continue to garner unusually high ratings throughout its summer run. However, NBC decided not to place it in the spring season, and instead use it as a platform to promote their upcoming fall shows. Originally hosted by Regis Philbin, as of 2013[ [update]] the series is currently hosted by Nick Cannon, and continues to garner strong ratings throughout its summer seasons. In March 2007, NBC announced that it would begin offering full-length episodes of its prime time series for streaming on mobile devices, becoming the first U.S. broadcast network to offer on-demand mobile episode content, as the market began shifting away from traditional television.
Following the unexpected termination of Kevin Reilly, in 2007, Ben Silverman was appoined president of NBC Entertainment, while Jeff Zucker was promoted to succeed Bob Wright as CEO of NBC. The network failed to generate any new primetime hits emerged during the 2008–09 season (despite the rare good fortune of having the rights to both the Super Bowl and the Summer Olympics in which to promote their new programming slate), while "Heroes" and "Deal or No Deal" both collapsed in the ratings and were later cancelled (with a revamped "Deal or No Deal" being revived for one additional season in syndication). In a March 2009 interview, Zucker had stated that he no longer believed it would be possible for NBC to become #1 in prime time. Ben Silverman left the network in 2009, with Jeff Gaspin replacing him as president of NBC Entertainment.
Comcast takes over.
On December 3, 2009, Comcast announced that would purchase a 51% controlling stake in NBC Universal from General Electric (which would retain the remaining 49%) for $6.5 billion in cash. GE used $5.8 billion from the deal to buy out Vivendi's 20% interest in NBC Universal.
NBC's broadcast of the 2010 Winter Olympics in Vancouver, in February of that year, generated a ratings increase of 21% over its broadcast of the 2006 Winter Games in Torino. The network was criticized for repeatedly showing footage of a crash occurring during practice for an Olympic luge competition that killed Georgian luger Nodar Kumaritashvili. NBC News president Steve Capus ordered the footage not to be shown without his permission and Olympics prime time host Bob Costas promised on-air that the video would not be shown again during the Games. NBC Universal was on track to lose $250 million in advertising revenue on that year's Winter Olympics, failing to make up the $820 million it paid for the U.S. television rights. Even so, with its continuing position in fourth place (although it virtually tied with ABC in many demographics on the strength of NBC's sports broadcasts that year), the 2009–10 season ended with only two scripted shows – "Community" and "Parenthood", as well as three unscripted shows – "The Marriage Ref", "Who Do You Think You Are?" and "Minute to Win It" – being renewed for second seasons, while other series such as "Heroes" and veteran crime drama "Law & Order" (the latter of which ended after 20 seasons, tying it with "Gunsmoke" as the longest-running prime time drama in U.S. television history) were cancelled.
After Conan O'Brien succeeded Jay Leno as host of "The Tonight Show" in 2009, the network gave Leno a new prime time talk show, committing to air it every weeknight at 10:00 p.m. Eastern and Pacific as an inexpensive comedic alternative to the police procedurals and other hour-long dramas typically aired in that time slot. In doing so, NBC became the first major U.S. broadcast network in decades, if ever, to broadcast the same program in a weekdaily prime time strip. Its executives called the decision "a transformational moment in the history of broadcasting" and "in effect, launching five shows." Conversely, industry executives criticized the network for abandoning a history of airing quality dramas in the 10:00 hour, and expressed concern that it would hurt NBC by undermining a reputation built on successful scripted series. Citing complaints from many affiliates, which saw their late-evening newscasts drop significantly in the local ratings during "The Jay Leno Show"‍ '​s run, NBC announced on January 10, 2010 that it would drop Leno's show from the 10:00 p.m. slot – with Zucker announcing plans to shift the program (which would have been reduced to a half-hour) into the 11:35 p.m. slot and shift its existing late night lineup (including "The Tonight Show") by 30 minutes. O'Brien – whose contract guaranteed him a minimum of three years as host of "The Tonight Show", with the majority of his former "Late Night" staff relocating with him from New York to California less than a year before he became host – had not been given any choice regarding or any prior notification of the move. The network's planned late night realignment led a disgruntled O'Brien, who gained tremendous support from viewers and entertainers as a result of the implications, to enter negotiations to terminate his contract with NBC. Leno, Zucker and NBC as a whole experienced considerable public backlash against them for their involvement. Leno would end up returning as host of "The Tonight Show" on March 1, 2010, while O'Brien accepted a buyout from his contract. O'Brien later signed a deal with cable network TBS to host a new talk show, "Conan", which debuted in November 2010.
The removal of "The Jay Leno Show" from its prime time schedule had almost no impact on the network's ratings. The increases NBC experienced in the 2010–11 season compared to 2009–10 were almost entirely attributable to the rising viewership of "NBC Sunday Night Football". By 2012, the shows that occupied the 10:00 p.m. time slot drew lower numbers than "The Jay Leno Show" did when it aired in that hour two years before. In the spring of 2010, cable provider and multimedia firm Comcast announced it would acquire a majority interest in NBC Universal from General Electric, which would retain a minority stake in the company in the interim.
On September 24, 2010, Jeff Zucker announced that he would step down as NBC Universal's CEO once the company's merger with Comcast was completed at the end of the year. After the deal was finalized, Steve Burke was named CEO of NBCUniversal and Robert Greenblatt replaced Jeff Gaspin as chairman of NBC Entertainment. In 2011, NBC was finally able to find a breakout hit in the midseason reality singing competition series "The Voice". Otherwise, NBC had another tough season, with the midseason legal drama "Harry's Law" being its only freshman scripted series to be renewed for the 2011–12 season. The network nearly completed its full conversion to an all-HD schedule (outside of the Saturday morning timeslot leased by the Qubo consortium, which NBCUniversal would rescind its stake in the following year) on September 20, 2011, when "Last Call with Carson Daly" converted to the format with the premiere of its 11th season.
Buoyed by its broadcast of Super Bowl XLVI (which became the most-watched program in U.S. television history at the time) and the success of its Monday night midseason lineup of "The Voice" and musical-drama "Smash", the network managed to lift itself into third place in the 18-49 demographic in the 2011–12 season, breaking the network's eight-year streak in fourth place. NBC experienced better fortunes overall with that season's schedule, as several shows survived for a second season, although none were unqualified ratings successes. The network completed its conversion to high definition in September 2012, with the launch of NBC Kids, a new Saturday morning children's block programmed by new partial sister network PBS Kids Sprout, which also became the second Saturday morning children's block with an entirely HD schedule (after the ABC-syndicated "Litton's Weekend Adventure").
In the fall of 2012, NBC greatly expanded its sitcom roster, with eight comedy series airing on Tuesday, Wednesday and Thursday nights. NBC bounced back to first place network in adults 18-49 that fall, boosted by the new season of "The Voice", the initial success of freshman drama "Revolution" and sitcom "Go On", and the continued strength of "Sunday Night Football". However, withholding the new season of "The Voice" and benching "Revolution" until late March, the network's midseason ratings suffered, falling to fifth place behind Spanish-language network Univision during the February sweeps period. The 2012–13 season ended with NBC finishing in third place overall, albeit by a narrow margin, with only three new shows, all dramas, surviving for a second season ("Revolution", "Chicago Fire" and "Hannibal").
In 2013, NBC Sports migrated its business and production operations (including NBCSN) to new facilities in Stamford, Connecticut. Production of the network's NFL pre-game show "Football Night in America" remained at the NBC Studios at Rockefeller Center (with production operations based in Studio 8G, while the program itself was broadcast in Studio 8H, the longtime home of "Saturday Night Live"), until it migrated to the Stamford facility in September 2014.
Despite the failure of another highly-advertised game show event, "The Million Second Quiz", the 2013–14 season was mostly successful for NBC due to the continued success of "The Voice", "Chicago Fire", "Revolution", "Sunday Night Football" and "Grimm". Along with new hits including "The Blacklist" and "Chicago PD" and a significant ratings boost from its broadcast of the 2014 Winter Olympics, NBC became the #1 network in the coveted 18-49 demographic that season for the first time since 2003–04. NBC also improved considerably in total viewership, finishing behind CBS in second place for the season.
Programming.
s of 2013[ [update]], NBC provides 87 hours of regularly scheduled network programming each week. The network provides 22 hours of prime time programming to affiliated stations Monday through Saturdays from 8:00–11:00 p.m. (7:00–10:00 p.m. in all other U.S. time zones) and Sundays from 7:00–11:00 p.m. Eastern and Pacific Time (6:00–10:00 p.m. in all other time zones).
Daytime programming is also provided weekdays between 12:00 and 3:00 p.m. in the form of the one-hour weekday soap opera "Days of Our Lives" (the scheduling of the program varies depending on the station, although it is initially fed to affiliates at 1:00 p.m. Eastern). NBC News programming includes the morning news/interview program "Today" from 7:00–11:00 a.m. weekdays, 7:00–9:00 on Saturdays and 7:00–8:00 on Sundays; nightly editions of "NBC Nightly News" (whose weekend editions are occasionally subject to abbreviation or preemption due to sports telecasts overrunning into the program's timeslot), the Sunday political talk show "Meet the Press", weekday early-morning news program "Early Today" and newsmagazine "Dateline NBC". Late nights feature the weeknight talk shows "The Tonight Show Starring Jimmy Fallon", "Late Night with Seth Meyers" and "Last Call with Carson Daly", weeknight replays of the fourth hour of "Today" and CNBC program "Mad Money", and the sketch comedy show "Saturday Night Live", and the LXTV-produced "1st Look" and "Open House NYC" on Saturdays (replays of the previous week's "1st Look" also air on Friday late nights on most stations).
The network's Saturday morning children's programming timeslot is programmed by sister cable channel Sprout, which produces the three-hour live-action/animation block for preschoolers, NBC Kids, under a time-lease agreement.
Sports programming is also provided weekend afternoons at any time between 12:00 and 6:00 p.m. (9:00 a.m.-3:00 p.m., or tape-delayed in the Pacific Time Zone). Due to the unpredictable length of sporting events, NBC will occasionally pre-empt scheduled programs (more common with the weekend editions of "NBC Nightly News", and local and syndicated programs carried by its owned-and-operated stations and affiliates).
NBC News.
News coverage has long been an important part of NBC's operations and public image, dating to the network's radio days. Notable NBC News productions past and present include "Today", "NBC Nightly News" (and its immediate predecessor, the "Huntley-Brinkley Report"), "Meet the Press" (which has the distinction of the longest continuously running program in the history of American television), "Dateline NBC", "Early Today", "NBC News at Sunrise", "NBC Nightside" and "Rock Center with Brian Williams".
In 1989, the news division began its expansion to cable with the launch of business news channel CNBC. The company eventually formed other cable news services including MSNBC (created in 1996 originally as a joint venture with Microsoft, which now features a mix of general news and political discussion programs with a liberal stance), and the 2008 acquisition of the The Weather Channel in conjunction with Blackstone Group and Bain Capital. In addition, NBCSN (operated as part of the NBC Sports Group, and which became an NBC property through Comcast's acquisition of NBCUniversal) carries sports news content alongside sports event telecasts. Key anchors from NBC News are also used during NBC Sports coverage of the Olympic Games.
Daytime programming.
NBC is currently the home to only one daytime program, the hour-long soap opera "Days of Our Lives", which has been broadcast on the network since 1965. Since NBC turned over an hour of its then two-hour daytime schedule back to its affiliates as a result of the September 2007 expansion of "Today" to four hours, the network currently ties with The CW for the fewest daytime programming hours of any major broadcast television network.
Long-running daytime dramas seen on NBC in the past include "The Doctors" (1963–1982), "Another World" (1964–1999), "Santa Barbara" (1984–1993), and "Passions" (1999–2007, later moving to The 101). NBC also aired the final 4½ years of "Search for Tomorrow" (1982–1986) after that series was initially cancelled by CBS, although many NBC affiliates did not clear the show during its tenure on the network. NBC has also aired numerous short-lived soaps, including "Generations" (1989–1991), "Sunset Beach" (1997–1999), and the two "Another World" spin-offs, "Somerset" (1970–1976) and "Texas" (1980–1982).
Notable daytime game shows that once aired on NBC include "The Price Is Right" (1956–1963), "Concentration" (1958–1973 and 1987–1991 as "Classic Concentration"), "The Match Game" (1962–1969), "Let's Make a Deal" (1963–1968 and 1990–1991, as well as a short-lived primetime revival in 2002), "Jeopardy!" (1964–1975 and 1978–1979), "The Hollywood Squares" (1966–1980), "Wheel of Fortune" (1975–1989 and 1991), "Password Plus/Super Password" (1979–1982 and 1984–1989), "Sale of the Century" (1969–1973 and 1983–1989) and "Scrabble" (1984–1990 and 1993). The last game show ever to air as part of NBC's daytime schedule was the short-lived "Caesars Challenge", which ended in January 1994.
Notable past daytime talk shows that have aired on NBC have included "Home" (1954–1957), "The Ernie Kovacs Show" (1955–1956), "The Merv Griffin Show" (1962–1963), "Leeza" (1994–1999) and "Later Today" (1999–2000).
Children's programming.
Children's programming has played a part in NBC's programming since its initial roots in television. NBC's first major children's series, "Howdy Doody", which debuted in 1947 and was one of the era's first breakthrough television shows. Running for 13 years and hosted by "Buffalo" Bob Smith, the series featured a freckle-faced marionette and a myriad of other characters. "Howdy Doody" spent most of its run on weekday afternoons until 1956, when NBC relegated its children's programming exclusively to Saturday mornings with "Howdy Doody" serving as its marquee franchise for the series' remaining four years.
From the mid-1960s until 1992, the bulk of NBC's children's programming was derived of mainly animated programming including classic "Looney Tunes" and "Woody Woodpecker" shorts; reruns of primetime animated sitcoms such as "The Flintstones" and "The Jetsons"; foreign acquisitions like "Astro Boy" and "Kimba the White Lion"; animated adaptions of "Punky Brewster", "ALF" and "Star Trek" as well as animated vehicles for Gary Coleman and Mr. T; live-action programs like "The Banana Splits", "The Bugaloos" and "H.R. Pufnstuf"; and the original broadcasts of "Gumby", "The Rocky and Bullwinkle Show", "Underdog", "The Smurfs", "Alvin and the Chipmunks" and "Disney's Adventures of the Gummi Bears". From 1984 to 1989, the network aired a series of public service announcements called "One to Grow On", which aired after the end credits of every program or every other children's program.
In 1989, NBC premiered "Saved by the Bell", a live-action teen sitcom which originated on The Disney Channel the previous year as "Good Morning, Miss Bliss" (which served as a starring vehicle for Hayley Mills; four cast members from that show were cast in the NBC series as the characters they originally played on "Miss Bliss"). "Saved by the Bell", despite being given bad reviews from television critics, would become one of the most popular teen series in television history as well as the top-rated series on Saturday mornings, dethroning ABC's "The Bugs Bunny and Tweety Show" in its first season.
The success of "Saved by the Bell" led NBC to remove animated series from its Saturday morning lineup in August 1992 in favor of additional live-action series as part of a new block called TNBC, along with the debut of a Saturday edition of "Today". Most of the series featured on the TNBC lineup were executive produced by Peter Engel (such as "City Guys", "Hang Time", "California Dreams", "One World" and the "Saved by the Bell" spinoff, ""), with the lineup being designed from the start to meet the earliest form of the FCC's educational programming guidelines under the Children's Television Act. "NBA Inside Stuff", an analysis and interview program aimed at teens that was hosted for most of its run by Ahmad Rashad, was also a part of the TNBC lineup during the NBA season until 2002 (when the program moved to ABC as a result of that network taking the NBA rights from NBC).
In 2002, NBC entered into an agreement with Discovery Communications to carry educational children's programs from the Discovery Kids cable channel. Debuting that September, the Discovery Kids on NBC block originally consisted exclusively of live-action series, including reality series "Trading Spaces: Boys vs. Girls" (a kid-themed version of the TLC series "Trading Spaces"); the Emmy-nominated reality game show "Endurance", hosted and produced by J. D. Roth (whose production company, 3-Ball Productions, would also produce reality series "The Biggest Loser" for NBC beginning in 2003); and scripted series such as "Strange Days at Blake Holsey High" and "Scout's Safari". The block later expanded to include some animated series such as "Kenny the Shark", "Tutenstein" and "Time Warp Trio".
In May 2006, NBC announced plans to launch a new Saturday morning children's block under the Qubo brand in September 2006. An endeavor originally operated as a joint venture between NBC Universal, Ion Media Networks, Scholastic Press, Classic Media and Corus Entertainment's Nelvana unit (Ion acquired the other partners' shares in 2013), the Qubo venture also encompassed weekly blocks on Telemundo and Ion Television, a 24-hour digital multicast network on Ion's owned-and-operated and affiliated stations, as well as video on demand services and a branded website. Qubo launched on NBC on September 9, 2006 with six programs ("VeggieTales", "Dragon", "VeggieTales Presents: 3-2-1 Penguins!", "Babar", "Jane and the Dragon" and "Jacob Two-Two").
On March 28, 2012, it was announced that NBC would launch a new Saturday morning preschool block programmed by PBS Kids Sprout (originally jointly owned by NBCUniversal, PBS, Sesame Workshop and Apax Partners, with the former acquiring the other's interests later that year). The block, NBC Kids, premiered on July 7, 2012, replacing the "Qubo on NBC" block.
Specials.
NBC holds the broadcast rights to several annual specials and award show telecasts including the Golden Globe Awards, the Emmy Awards (which is rotated across all four major networks each year), and two of the three pageants organized by the Miss Universe Organization: the Miss Universe and Miss USA pageants (NBC also held rights to the Miss Teen USA pageant from 2003, when NBC also assumed rights to the Miss USA and Miss Universe pageants as part of a deal brokered by Miss Universe Organization owner Donald Trump that gave the network half-ownership of the pageants, until 2007, when NBC declined to renew its contract to carry Miss Teen USA, effectively discontinuing televised broadcasts of that event).
Since 1952, NBC has served as the official U.S. broadcaster of the Macy's Thanksgiving Day Parade. CBS also carries unauthorized coverage of the Macy's parade as part of "The Thanksgiving Day Parade on CBS"; However as NBC holds rights to the parade, it has exclusivity over the broadcast of Broadway and music performances appearing in the parade (CBS airs pre-recorded performances separate from those seen in the parade as a result), and Macy's chose to reroute the parade in 2012 out of the view of CBS' cameras, although it continues to cover the parade. NBC began airing a same-day rebroadcast of the parade telecast in 2009 (replacing its annual Thanksgiving afternoon airing of "Miracle on 34th Street"). In 2007, NBC acquired the rights to the National Dog Show, which airs following the Macy's Thanksgiving Day Parade each year.
The network also broadcasts several live-action and animated specials during the Christmas holiday season, including the 2014 debuts "How Murray Saved Christmas" (an animated musical adaptation of the children's book of the same name) and "" (a stop-motion animated specials based on the 2003 live-action film "Elf".
Programming library.
Through the years, NBC has produced many in-house programs, in addition to airing content from other producers such as Revue Studios and its successor Universal Television. Notable in-house productions by NBC have included "Get Smart", "Bonanza", "Little House on the Prairie", "Las Vegas" and "Crossing Jordan".
NBC sold the distribution rights to programs it produced prior up to that year to National Telefilm Associates in 1973; those rights are currently owned by CBS Television Distribution, although NBC still owns the copyrights to the episodes. As a result, NBC, in a way, now owns several other series aired on the network prior to 1973, such as "Wagon Train". NBC continues to own its entire library of programs produced after 1973, through corporate sister NBCUniversal Television Group (the successor to Universal Television).
Stations.
s of March 2015[ [update]], NBC has eleven owned-and-operated stations and current and pending affiliation agreements with 221 additional television stations encompassing 48 states, the District of Columbia, six U.S. possessions and two non-U.S. territories (Aruba and Greenland). The network has a national reach of 95.92% of all households in the United States (or 299,732,600 Americans with at least one television set).
Currently, New Hampshire and New Jersey are the only U.S. states where NBC does not have a locally licensed affiliate (New Hampshire is served by Boston affiliate WHDH and Hartford, Vermont affiliate WNNE, while New Jersey is served by New York City O&O WNBC-TV and Philadelphia O&O WCAU; New Jersey formerly had an in-state affiliate in Atlantic City-based WMGM-TV, which was affiliated with the network from 1955 to 2014). NBC maintains affiliations with low-power stations (broadcasting either in analog or digital) in a few smaller markets, such as Binghamton, New York (WBGH-CA), Jackson, Tennessee (WNBJ-LD) and Juneau, Alaska (KATH-LD), that do not have enough full-power stations to support a standalone affiliate. In some markets, these stations also maintain digital simulcasts on a subchannel of a co-owned/co-managed full-power television station.
Currently outside of the NBC Owned Television Stations-operated O&O group, the Gannett Company is the largest operator of NBC stations in terms of overall market reach, owning or providing services to 20 NBC affiliates (including those in larger markets such as Denver, St. Louis, Seattle and Cleveland); Gray Television is the largest operator of NBC stations by numerical total, owning 23 NBC-affiliated stations.
NBCi.
In 1999, NBC launched NBCi (briefly changing its web address to "www.nbci.com"), a heavily advertised online venture serving as an attempt to launch an Internet portal and homepage. This move saw NBC partner with XOOM.com, e-mail.com, AllBusiness.com, and Snap.com (eventually acquiring all four companies outright) to launch a multi-faceted internet portal with e-mail, webhosting, community, chat and personalization capabilities, and news content. Subsequently in April 2000, NBC purchased GlobalBrain, a company specializing in search engines that learned from searches initiated by its users, for $32 million.
The experiment lasted roughly one season; after its failure, NBCi's operations were folded back into NBC. The NBC Television portion of the website reverted to NBC.com. However, the NBCi website continued in operation as a portal for NBC-branded content (NBCi.com would be redirected to NBCi.msnbc.com), using a co-branded version of InfoSpace to deliver minimal portal content. In mid-2007, NBCi.com began to mirror the main NBC.com website; NBCi.com was eventually redirected to the NBC.com domain in 2010.
Evolution of the NBC logo.
NBC has used a number of logos throughout its history; early logos used by the television and radio networks were similar to the logo of its then parent company, RCA. Logos used later in NBC's existence incorporated stylized peacock designs, including the current version that has been in use since 1986.
International broadcasts.
Canada.
NBC network programs can be received throughout most of Canada on cable, satellite and IPTV providers through certain U.S.-based affiliates of the network (such as WHDH/Boston, KING-TV/Seattle, KBJR-TV/Duluth, Minnesota, WGRZ/Buffalo, New York and WDIV-TV/Detroit). Some programs carried on these stations are subject to simultaneous substitutions, a practice imposed by the Canadian Radio-television and Telecommunications Commission in which a pay television provider supplants an American station's signal with a feed from a Canadian station/network airing a particular program in the same time slot to protect domestic advertising revenue. Some of these affiliates are also receivable over-the-air in southern areas of the country located near the Canada–United States border (signal coverage was somewhat reduced after the digital television transition in 2009 due to the lower radiated power required to transmit digital signals).
Europe and the Middle East.
NBC no longer exists outside the Americas as a channel in its own right. However, NBC News and MSNBC programs are broadcast for a few hours a day on Orbit News in Europe, Africa and the Middle East. Sister network CNBC Europe also broadcasts occasional breaking news coverage from MSNBC as well as "The Tonight Show Starring Jimmy Fallon" (until 2010, the channel formerly broadcast daily airings of "NBC Nightly News").
NBC Super Channel becomes NBC Europe.
In 1993, then-NBC parent General Electric acquired Super Channel, relaunching the Pan-European cable network as NBC Super Channel. In 1996, the channel was renamed NBC Europe, but was, from then on, almost always referred to on-air as simply "NBC".
Most of NBC Europe's prime time programming was produced in Europe due to rights restrictions associated with U.S. primetime shows; the channel's weekday late night schedule after 11:00 p.m. Central European Time, however, featured "The Tonight Show", "Late Night with Conan O'Brien" and "Later", which the channel's slogan "Where the Stars Come Out at Night" was based around. Many NBC News programs were broadcast on NBC Europe, including "Dateline NBC", "Meet the Press" and "NBC Nightly News", the latter of which was broadcast simultaneously with the initial U.S. telecast. "Today" was also initially aired live in the afternoons, but was later broadcast instead the following morning on a more than half-day delay.
In 1999, NBC Europe ceased broadcasting in most of Europe outside of Germany; the network was concurrently relaunched as a German-language technology channel aimed at a younger demographic, with the new series "NBC GIGA" as its flagship program. In 2005, the channel was relaunched again as the free-to-air movie channel Das Vierte. GIGA Television was subsequently spun off as a separate digital channel, available on satellite and cable providers in Germany, Austria and Switzerland.
Latin America and the Caribbean.
Mexico.
NBC programming is available in Mexico through affiliates in markets located within proximity to the Mexico–United States border (such as KYMA-DT/Yuma, Arizona; KGNS-TV/Laredo, Texas; KTSM/El Paso, Texas; KVEO/Brownsville, Texas; and KNSD/San Diego), whose signals are readily receivable over-the-air in border areas of northern Mexico. Some U.S.-based border affiliates are also available on domestic cable and satellite providers throughout the country, including in the Mexico City area.
Canal de Noticias.
In 1993, NBC launched a 24-hour Spanish language news channel serving Latin America (the second news channel serving that region overall, after Noticias ECO, and the first to broadcast 24 hours a day), Canal de Noticias NBC, which based its news schedule around the "wheel" format conceived at CNN. The channel, which was headquartered out of the offices of the NBC News Channel affiliate news service in Charlotte, North Carolina, employed over 50 journalists to produce, write, anchor and provide technical services. Canal de Noticias NBC shut down in 1997 due to the channel's inability to generate substainable advertising revenue.
Caribbean.
In the Caribbean, many cable and satellite providers carry either select U.S.-based NBC affiliated stations or the main network feed from NBC O&Os WNBC in New York City or WTVJ in Miami. In addition, the network's programming has been available in the U.S. Virgin Islands since 2004 on WVGN-LD in Charlotte Amalie (owned by LKK Group), while Telemundo owned-and-operated station WKAQ-TV in San Juan, Puerto Rico carries the WNBC feed on a digital subchannel. In these areas, NBC programs are available in English and in Spanish via second audio program.
Bahamas.
In the Bahamas, NBC programming is available via U.S.-based affiliate stations on domestic cable providers.
Bermuda.
NBC's entire program lineup is carried by local affiliate VSB-TV via from the network's East Coast satellite feed and carried one-hour tape delay due to the island nation residing in the Atlantic Time Zone (one hour behind the Eastern Time Zone).
Netherlands Antilles.
In Aruba, NBC maintains an affiliation with Oranjestad station PJA-TV (which brands on-air as "ATV").
Asia Pacific.
Guam.
In Guam, the entire NBC programming lineup is carried by Hagåtña affiliate KUAM-TV (which has been an NBC affiliate since 1956) via the network's East Coast satellite feed. Entertainment and news programming is broadcast day and date on a one-day tape delay as Guam is on the west side of the International Date Line (for example, the network's Thursday prime time lineup airs Friday evenings on KUAM, and is advertised by the station as airing on the latter night in on-air promotions). Live programming, including breaking news and sporting events, airs as scheduled; because of the time difference with the six U.S. time zones, live sports coverage often airs on the station early in the morning. KUAM's programming is relayed to the Northern Mariana Islands via satellite station WSZE in Saipan.
American Samoa.
In American Samoa, NBC has been affiliated with KKHJ-LP in Pago Pago since 2005. Cable television providers on the islands also carry the network's programming via Seattle affiliate KING-TV.
Federated States of Micronesia.
In the Federated States of Micronesia, NBC programming is available on domestic cable providers via Honolulu affiliate KHNL.
NBC Asia and CNBC Asia.
NBC Asia launched in 1994, distributed to Nepal, Japan, Malaysia, South Korea, Republic of China, Thailand, Pakistan and the Republic of the Philippines. Like with NBC Europe, NBC Asia featured most of NBC's news programs as well as "The Tonight Show" and "Late Night". Like its European counterpart, it was not allowed to broadcast American-produced primetime shows due to existing broadcast agreements with other domestic broadcasters. NBC Asia produced a regional evening news program that aired each weeknight, and occasionally simulcast some programs from CNBC Asia and MSNBC. NBC also operated NBC Super Sports, a 24-hour channel devoted to televising sporting events.
In July 1998, NBC Asia was replaced by a regional version of the National Geographic Channel. As is the case with NBC Europe, CNBC Asia broadcasts select episodes of "The Tonight Show" and "Late Night" as well as "Meet the Press" are as part of its weekend schedule, and airs NFL games under the "Sunday Night Football" brand.
Regional partners.
Through regional partners, NBC-produced programs are seen in some countries in the continent. In the Philippines, Jack TV (owned by Solar Entertainment) airs "Will & Grace" and "Saturday Night Live", while TalkTV airs "The Tonight Show" and NBC News programs including the weekday and weekend editions of "Today", "Early Today", "Dateline NBC" and "NBC Nightly News". Solar TV formerly broadcast "The Jay Leno Show" from 2009 to 2010. In Hong Kong, English language free-to-air channel TVB Pearl (operated by TVB) airs live broadcasts of "NBC Nightly News", as well as other select NBC programs.
Australia.
In Australia, the Seven Network has maintained close ties with NBC and has used a majority of the U.S. network's image campaigns and slogans since the 1970s (conversely, in 2009, NBC and Seven both used the Guy Sebastian single "Like it Like That" in image promos for their respective summer schedules). The network's "Seven News" division has used John Williams-composed "The Mission" (the proprietary theme music for NBC News' flagship programs since 1985) as the theme music for its local and national news programs since the mid-1980s. Local newscasts were also titled "Seven Nightly News" from the mid-1980s until c. 2000. NBC News and Seven News often share news resources, with the former division using Seven's reporters for breaking news coverage and select taped story packages relating to Australian stories and the latter sometimes incorporating NBC News reports into its national bulletins.
Seven also rebroadcasts some of NBC's news and current affairs programming during the early morning hours (usually from 3:00 to 5:00 a.m. local time), including the weekday and weekend editions of "Today" (which it brands as "NBC Today" to differentiate it from the unrelated morning program on the Nine Network), "Dateline NBC" and "Meet the Press".
Criticism and controversies.
Selective editing of George Zimmerman 911 call.
In February 2012, "Today" aired a story package that included an edited version of a 9-1-1 call made by George Zimmerman minutes prior to his confrontation with Trayvon Martin that resulted in the unarmed Florida teenager being shot and killed, which (as described in a "Washington Post" article criticizing the editing of the tape) had the effect of "readily paint[ing] Zimmerman as a racial profiler". In the edited recording, Zimmerman (who claimed he shot Martin in self defense; a grand jury later acquitted him on murder charges while on trial in August 2013) is heard saying, "This guy looks like he's up to no good. He looks black." A portion of the tape in which Zimmerman was describing Martin to the 911 operator was removed in its broadcast version; in the unedited version, Zimmerman said, "This guy looks like he's up to no good. Or he's on drugs or something. It's raining and he's just walking around, looking about." The operator then asked, "OK, and this guy – is he black, white or Hispanic?," to which Zimmerman answered, "He looks black."
Following an internal investigation into the production of the segment, NBC News fired two employees involved with the piece, including a producer based at the division's Miami bureau, and NBC News executive Lilia Luciano. In a statement, NBC News' president at the time Steve Capus apologized, calling the editing "a mistake and not a deliberate act to misrepresent the phone call."
On December 6, 2012, George Zimmerman filed a defamation lawsuit against NBC, alleging that the phone call was edited intentionally to give the impression that he targeted Martin because he was black and to "create the myth that George Zimmerman was a racist and predatory villain". Florida Circuit Court Judge Debra Nelson dismissed the suit on June 30, 2014, citing that there were "no genuine issues" determinable by a jury that any "actual malice" was acted upon.

</doc>
<doc id="21781" url="http://en.wikipedia.org/wiki?curid=21781" title="Nociception">
Nociception

Nociception (also nocioception or nociperception) is the encoding and processing of harmful stimuli in the nervous system, and, therefore, the ability of a body to sense potential harm. It is the afferent activity in the peripheral and central nervous systems produced by stimulation of specialized free nerve endings called nociceptors or "pain receptors" that only respond to tissue damage caused by intense chemical (e.g., chilli powder in the eyes), mechanical (e.g., pinching, crushing) or thermal (heat and cold) stimulation. Once stimulated, a nociceptor sends a signal along a chain of nerve fibers via the spinal cord to the brain. Nociception triggers a variety of autonomic responses and may also result in a subjective experience of pain in sentient beings. Nociceptive neurons generate trains of action potentials in response to intense stimuli, and the frequency of firing determines the intensity of the pain.
The three types of pain receptors are cutaneous (skin), somatic (joints and bones), and visceral (body organs). It was previously believed that pain was simply the overloading of sensory receptors, but research in the first half of the 20th century indicated that pain is a distinct phenomenon that intertwines with all of the other senses, including touch. Pain was once considered a non-material experience, but recent studies show that pain is registered in specific parts of the brain. The main function of pain is to attract our attention to dangers and motivate us to avoid them.
Detection of noxious stimuli.
Potentially damaging mechanical, thermal, and chemical stimuli are detected by nerve endings called nociceptors, which are found in the skin, on internal surfaces such as the periosteum, joint surfaces, and in some internal organs. The concentration of nociceptors varies throughout the body; they are found in greater numbers in the skin than in deep internal surfaces.
The nociceptors are unspecialized free nerve endings that have their cell bodies outside the spinal column in the dorsal root ganglia. Nociceptors are categorized according to the axons which travel from the receptors to the spinal cord or brain.
Nociceptors have a certain threshold; that is, they require a minimum intensity of stimulation before they trigger a signal. Once this threshold is reached a signal is passed along the axon of the neuron into the spinal cord.
Nociceptive threshold testing deliberately applies a noxious stimulus to a human or animal subject in order to study pain. In animals, the technique is often used to study the efficacy of analgesic drugs and to establish dosing levels and period of effect. After establishing a baseline, the drug under test is given and the elevation in threshold recorded at specified time points. When the drug wears off, the threshold should return to the baseline (pre-treatment) value. 
In some conditions, excitation of pain fibers becomes greater as the pain stimulus continues, leading to a condition called hyperalgesia.
Transmission through the central nervous system.
Spinothalamic tract.
Before reaching the brain, the spinothalamic tract splits into the lateral, "neospinothalamic" tract and the medial, "paleospinothalamic" tract.
Neospinothalamic tract.
Fast pain travels via type Aδ fibers to terminate in the dorsal horn of the spinal cord where they synapse on dendrites of the neospinothalamic tract. The axons of these neurons cross the midline (decussate) through the anterior white commissure and ascend contralaterally along the anterolateral system. These fibres terminate on the ventrobasal complex of the thalamus and synapse with the dendrites of the somatosensory cortex. Fast pain is felt within a tenth of a second of application of the pain stimulus and is a sharp, acute, prickling pain felt in response to mechanical and thermal stimulation. It can be localised easily if Aδ fibres are stimulated together with tactile receptors. 
Paleospinothalamic tract.
Slow pain is transmitted via slower type C fibers to laminae II and III of the dorsal horns, together known as the substantia gelatinosa. Impulses are then transmitted to nerve fibers that terminate in lamina V, also in the dorsal horn, synapsing with neurons that join fibers from the fast pathway, crossing to the opposite side via the anterior white commissure, and traveling upwards through the anterolateral pathway. These neurons terminate throughout the brain stem, with one tenth of fibres stopping in the thalamus and the rest stopping in the medulla, pons and periaqueductal grey of the midbrain tectum.
Regulation.
The body possesses an endogenous analgesia system, which can be supplemented with analgesic drugs to regulate nociception and pain. There is both an analgesia system in the central nervous system and peripheral receptors that decreases the grade in which nociception reaches the higher brain areas. The degree of pain can be modified by the periaqueductal gray before it reaches the thalamus and consciousness. According to gate control theory of pain, this area can also reduce pain when non-painful stimuli are received in conjunction with nociception.
Central.
The central analgesia system is mediated by three major components: the periaqueductal grey matter, the nucleus raphes magnus and the nociception inhibitory neurons within the dorsal horns of the spinal cord, which act to inhibit nociception-transmitting neurons also located in the spinal dorsal horn.
Peripheral.
The peripheral regulation consists of several different types of opioid receptors that are activated in response to the binding of the body's endorphins. These receptors, which exist in a variety of areas in the body, inhibit firing of neurons that would otherwise be stimulated to do so by nociceptors.
Factors.
The gate control theory of pain, proposed by Patrick David Wall and Ronald Melzack, postulates that nociception (pain) is "gated" by non-nociception stimuli such as vibration. Thus, rubbing a bumped knee seems to relieve pain by preventing its transmission to the brain. Pain is also "gated" by signals that descend from the brain to the spinal cord to suppress (and in other cases enhance) incoming nociception (pain) information.
Nociception response.
When nociceptors are stimulated they transmit signals through sensory neurons in the spinal cord. These neurons release the excitatory neurotransmitter glutamate at their synapses.
If the signals are sent to the reticular formation and thalamus, the sensation of pain enters consciousness in a dull poorly localized manner. From the thalamus, the signal can travel to the somatosensory cortex in the cerebrum, when the pain is experienced as localized and having more specific qualities.
Nociception can also cause generalized autonomic responses before or without reaching consciousness to cause pallor, diaphoresis, tachycardia, hypertension, lightheadedness, nausea and fainting.
Nociception in non-mammalian animals.
Nociception has been documented in non-mammalian animals, including fish and a wide range of invertebrates, including leeches, nematode worms, sea slugs, and fruit flies. As in mammals, nociceptive neurons in these species are typically characterized by responding preferentially to high temperature (40º Celsius or more), low pH, capsaicin, and tissue damage.
History of term.
The term "nociception" was coined by Charles Scott Sherrington to distinguish the physiological process (nervous activity) from pain (a subjective experience). It is derived from the Latin verb "nocēre", which means "to harm".

</doc>
<doc id="21784" url="http://en.wikipedia.org/wiki?curid=21784" title="Nova">
Nova

A nova (plural "novae" or "novas") is a cataclysmic nuclear explosion on a white dwarf, which causes a sudden brightening of the star. Novae are not to be confused with other brightening phenomena such as supernovae or luminous red novae. Novae are thought to occur on the surface of a white dwarf in a binary system. If the two stars of the system are sufficiently near to one another, material can be pulled from the companion star's surface onto the white dwarf. A nova is caused by the accretion of hydrogen onto the surface of the star, commencing a runaway fusion reaction.
Development.
If a white dwarf has a close companion star that overflows its Roche lobe, the white dwarf will steadily accrete matter from the companion's outer atmosphere. The companion may be a main sequence star, or one that is aging and expanding into a red giant. The captured gases build up on the white dwarf's surface and begin burning via the CNO cycle.
While hydrogen fusion can occur in a stable manner on the surface of the white dwarf for a narrow range of accretion rates, for most binary system parameters the hydrogen burning is thermally unstable and rapidly converts a large amount of the hydrogen into other heavier elements in a runaway reaction, liberating an enormous amount of energy, blowing the remaining gases away from the white dwarf's surface and producing an extremely bright outburst of light. The rise to peak brightness can be very rapid or gradual and is related to the speed class of the nova; after the peak, the brightness declines steadily. The time taken for a nova to decay by 2 or 3 magnitudes from maximum optical brightness is used to classify a nova via its speed class. A fast nova will typically take less than 25 days to decay by 2 magnitudes and a slow nova will take over 80 days.
In spite of their violence, the amount of material ejected in novae is usually only about 1⁄10,000 of a solar mass, quite small relative to the mass of the white dwarf. Furthermore, only five percent of the accreted mass is fused during the power outburst. Nonetheless, this is enough energy to accelerate nova ejecta to velocities as high as several thousand kilometers per second—higher for fast novae than slow ones—with a concurrent rise in luminosity from a few times solar to 50,000–100,000 times solar. In 2010 scientists using NASA's Fermi Gamma-ray Space Telescope were surprised to discover, for the first time, that a nova can also emit gamma-rays (>100 MeV).
A white dwarf can potentially generate multiple novae over time as additional hydrogen continues to accrete onto its surface from its companion star. An example is RS Ophiuchi, which is known to have flared six times (in 1898, 1933, 1958, 1967, 1985, and 2006). Eventually, the white dwarf could explode as a type Ia supernova if it approaches the Chandrasekhar limit.
Occasionally a nova is bright enough and close enough to be conspicuous to the unaided eye. The brightest recent example was Nova Cygni 1975. This nova appeared on 29 August 1975, in the constellation Cygnus about five degrees north of Deneb and reached magnitude 2.0 (nearly as bright as Deneb). The most recent were V1280 Scorpii, which reached magnitude 3.7 on 17 February 2007, and Nova Delphini 2013. Nova Centauri 2013 was discovered 2 December 2013 and is so far the brightest nova of this millennium reaching magnitude 3.3.
Helium novae.
A helium nova (or helium flash) is a proposed category of nova explosion that lacks hydrogen lines in the spectrum. This may be caused by the explosion of a helium shell on a white dwarf. It was proposed by Kato, Saio and Hachisu in 1989. The first candidate helium nova to be observed was V445 Puppis in 2000. Since then, four other novae explosions have been proposed as helium novae.
Occurrence rate and astrophysical significance.
Astronomers estimate that the Milky Way experiences roughly 30 to 60 novae per year, with a likely rate of about 40. The number of novae discovered in the Milky Way each year is much lower, about 10. Roughly 25 novae brighter than about magnitude 20 are discovered in the Andromeda Galaxy each year and smaller numbers are seen in other nearby galaxies.
Spectroscopic observation of nova ejecta nebulae has shown that they are enriched in elements such as helium, carbon, nitrogen, oxygen, neon, and magnesium. The contribution of novae to the interstellar medium is not great; novae supply only 1⁄50 as much material to the Galaxy as supernovae, and only 1⁄200 as much as red giant and supergiant stars.
Recurrent novae like RS Ophiuchi (those with periods on the order of decades) are rare. Astronomers theorize however that most, if not all, novae are recurrent, albeit on time scales ranging from 1,000 to 100,000 years. The recurrence interval for a nova is less dependent on the white dwarf's accretion rate than on its mass; with their powerful gravity, massive white dwarfs require less accretion to fuel an outburst than lower-mass ones. Consequently, the interval is shorter for high-mass white dwarfs.
Subtypes.
Novae are classified according to the light curve development speed, so in 
Etymology.
During the 16th century, astronomer Tycho Brahe observed the supernova SN 1572 in the constellation Cassiopeia. He described it in his book "De stella nova" (Latin for "concerning the new star"), giving rise to the name "nova". In this work he argued that a nearby object should be seen to move relative to the fixed stars, and that the nova had to be very far away. Though this was a supernova and not a classical nova, the terms were considered interchangeable until the 1930s.
Novae as distance indicators.
Novae have some promise for use as standard candle measurements of distances. For instance, the distribution of their absolute magnitude is bimodal, with a main peak at magnitude −8.8, and a lesser one at −7.5. Novae also have roughly the same absolute magnitude 15 days after their peak (−5.5). Comparisons of nova-based distance estimates to various nearby galaxies and galaxy clusters with those done with Cepheid variable stars have shown them to be of comparable accuracy.
Bright novae since 1890.
Over 53 novae have been registered since 1890.
Recurrent novae.
There are ten known galactic recurrent novae. The recurrent nova typically brightens by about 8.6 magnitude, whereas a classic nova brightens by more than 12 magnitude. Some of the better known and more easily observed recurrent novae are listed below.
Extragalactic novae.
Novae in M31 are relatively common. There are roughly a couple dozen novae discovered (brighter than about apparent magnitude 20) in M31 each year. The Central Bureau for Astronomical Telegrams (CBAT) tracks novae in M31, M33, and M81.

</doc>
<doc id="21785" url="http://en.wikipedia.org/wiki?curid=21785" title="Nuclear weapon">
Nuclear weapon

A nuclear weapon is an explosive device that derives its destructive force from nuclear reactions, either fission (fission bomb) or a combination of fission and fusion (thermonuclear weapon). Both reactions release vast quantities of energy from relatively small amounts of matter. The first fission ("atomic") bomb test released the same amount of energy as approximately 20,000 tons of TNT (see Trinity (nuclear test)). The first thermonuclear ("hydrogen") bomb test released the same amount of energy as approximately 10,000,000 tons of TNT.
A thermonuclear weapon weighing little more than 2400 lb can produce an explosive force comparable to the detonation of more than 1.2 million tons (1.1 million tonnes) of TNT. A nuclear device no larger than traditional bombs can devastate an entire city by blast, fire, and radiation. Nuclear weapons are considered weapons of mass destruction, and their use and control have been a major focus of international relations policy since their debut.
Nuclear weapons have been used twice in nuclear warfare, both times by the United States against Japan near the end of World War II. On 6 August 1945, the US detonated a uranium gun-type fission bomb codenamed "Little Boy" over the Japanese city of Hiroshima; three days later, on 9 August, the US detonated a plutonium implosion-type fission bomb codenamed "Fat Man" over the Nagasaki. The bombings resulted in the deaths of approximately 200,000 civilians and military personnel from acute injuries sustained from the explosions. The ethics of the bombings and their role in Japan's surrender remain the subject of scholarly and popular debate.
Since the atomic bombings of Hiroshima and Nagasaki, nuclear weapons have been detonated on over two thousand occasions for the purposes of testing and demonstration. Only a few nations possess such weapons or are suspected of seeking them. The only countries known to have detonated nuclear weapons—and acknowledge possessing them—are (chronologically by date of first test) the United States, the Soviet Union (succeeded as a nuclear power by Russia), the United Kingdom, France, the People's Republic of China, India, Pakistan, and North Korea. Israel is also believed to possess nuclear weapons, though it does not acknowledge having them. One state, South Africa, fabricated nuclear weapons in the past, but as its apartheid regime was coming to an end, it disassembled its arsenal, acceded to the Nuclear Non-Proliferation Treaty, and accepted full-scope international safeguards. The Federation of American Scientists estimated there were more than 17,000 nuclear warheads worldwide as of 2012, with around 4,300 of them considered "operational", ready for use.
Types.
There are two basic types of nuclear weapons: those that derive the majority of their energy from nuclear fission reactions alone, and those that use fission reactions to begin nuclear fusion reactions that produce a large amount of the total energy output.
Fission weapons.
All existing nuclear weapons derive some of their explosive energy from nuclear fission reactions. Weapons whose explosive output is exclusively from fission reactions are commonly referred to as atomic bombs or atom bombs (abbreviated as A-bombs). This has long been noted as something of a misnomer, as their energy comes from the nucleus of the atom, just as it does with fusion weapons.
In fission weapons, a mass of fissile material (enriched uranium or plutonium) is assembled into a supercritical mass—the amount of material needed to start an exponentially growing nuclear chain reaction—either by shooting one piece of sub-critical material into another (the "gun" method) or by compressing using explosive lenses a sub-critical sphere of material using chemical explosives to many times its original density (the "implosion" method). The latter approach is considered more sophisticated than the former and only the latter approach can be used if the fissile material is plutonium.
A major challenge in all nuclear weapon designs is to ensure that a significant fraction of the fuel is consumed before the weapon destroys itself. The amount of energy released by fission bombs can range from the equivalent of just under a ton of TNT, to upwards of 500,000 tons (500 kilotons) of TNT.
All fission reactions necessarily generate fission products, the radioactive remains of the atomic nuclei split by the fission reactions. Many fission products are either highly radioactive (but short-lived) or moderately radioactive (but long-lived), and as such are a serious form of radioactive contamination if not fully contained. Fission products are the principal radioactive component of nuclear fallout.
The most commonly used fissile materials for nuclear weapons applications have been uranium-235 and plutonium-239. Less commonly used has been uranium-233. Neptunium-237 and some isotopes of americium may be usable for nuclear explosives as well, but it is not clear that this has ever been implemented, and even their plausible use in nuclear weapons is a matter of scientific dispute.
Fusion weapons.
The other basic type of nuclear weapon produces a large proportion of its energy in nuclear fusion reactions. Such fusion weapons are generally referred to as thermonuclear weapons or more colloquially as hydrogen bombs (abbreviated as H-bombs), as they rely on fusion reactions between isotopes of hydrogen (deuterium and tritium). All such weapons derive a significant portion, and sometimes a majority, of their energy from fission. This is because a fission weapon is required as a "trigger" for the fusion reactions, and the fusion reactions can themselves trigger additional fission reactions.
Only six countries—United States, Russia, United Kingdom, People's Republic of China, France and India—have conducted thermonuclear weapon tests. (Whether India has detonated a "true", multi-staged thermonuclear weapon is controversial.) Thermonuclear weapons are considered much more difficult to successfully design and execute than primitive fission weapons. Almost all of the nuclear weapons deployed today use the thermonuclear design because it is more efficient.
Thermonuclear bombs work by using the energy of a fission bomb to compress and heat fusion fuel. In the Teller-Ulam design, which accounts for all multi-megaton yield hydrogen bombs, this is accomplished by placing a fission bomb and fusion fuel (tritium, deuterium, or lithium deuteride) in proximity within a special, radiation-reflecting container. When the fission bomb is detonated, gamma rays and X-rays emitted first compress the fusion fuel, then heat it to thermonuclear temperatures. The ensuing fusion reaction creates enormous numbers of high-speed neutrons, which can then induce fission in materials not normally prone to it, such as depleted uranium. Each of these components is known as a "stage", with the fission bomb as the "primary" and the fusion capsule as the "secondary". In large, megaton-range hydrogen bombs, about half of the yield comes from the final fissioning of depleted uranium.
Virtually all thermonuclear weapons deployed today use the "two-stage" design described above, but it is possible to add additional fusion stages—each stage igniting a larger amount of fusion fuel in the next stage. This technique can be used to construct thermonuclear weapons of arbitrarily large yield, in contrast to fission bombs, which are limited in their explosive force. The largest nuclear weapon ever detonated—the Tsar Bomba of the USSR, which released an energy equivalent of over 50 million tons (50 megatons) of TNT—was a three-stage weapon. Most thermonuclear weapons are considerably smaller than this, due to practical constraints from missile warhead space and weight requirements.
Fusion reactions do not create fission products, and thus contribute far less to the creation of nuclear fallout than fission reactions, but because all thermonuclear weapons contain at least one fission stage, and many high-yield thermonuclear devices have a final fission stage, thermonuclear weapons can generate at least as much nuclear fallout as fission-only weapons.
Other types.
There are other types of nuclear weapons as well. For example, a boosted fission weapon is a fission bomb that increases its explosive yield through a small amount of fusion reactions, but it is not a fusion bomb. In the boosted bomb, the neutrons produced by the fusion reactions serve primarily to increase the efficiency of the fission bomb.
Some weapons are designed for special purposes; a neutron bomb is a thermonuclear weapon that yields a relatively small explosion but a relatively large amount of neutron radiation; such a device could theoretically be used to cause massive casualties while leaving infrastructure mostly intact and creating a minimal amount of fallout. The detonation of any nuclear weapon is accompanied by a blast of neutron radiation. Surrounding a nuclear weapon with suitable materials (such as cobalt or gold) creates a weapon known as a salted bomb. This device can produce exceptionally large quantities of radioactive contamination.
Research has been done into the possibility of pure fusion bombs: nuclear weapons that consist of fusion reactions without requiring a fission bomb to initiate them. Such a device might provide a simpler path to thermonuclear weapons than one that required development of fission weapons first, and pure fusion weapons would create significantly less nuclear fallout than other thermonuclear weapons, because they would not disperse fission products. In 1998, the United States Department of Energy divulged that the United States had, "...made a substantial investment" in the past to develop pure fusion weapons, but that, "The U.S. does not have and is not developing a pure fusion weapon", and that, "No credible design for a pure fusion weapon resulted from the DOE investment".
Most variation in nuclear weapon design is for the purpose of achieving different yields for different situations, and in manipulating design elements to attempt to minimize weapon size.
Antimatter, which consists of particles resembling ordinary matter particles in most of their properties but having opposite electric charge, has been considered as a trigger mechanism for nuclear weapons. A major obstacle is the difficulty of producing antimatter in large enough quantities, and there is no evidence that it is feasible beyond the military domain. However, the U.S. Air Force funded studies of the physics of antimatter in the Cold War, and began considering its possible use in weapons, not just as a trigger, but as the explosive itself. A fourth generation nuclear weapon design is related to, and relies upon, the same principle as Antimatter-catalyzed nuclear pulse propulsion.
Weapons delivery.
Nuclear weapons delivery—the technology and systems used to bring a nuclear weapon to its target—is an important aspect of nuclear weapons relating both to nuclear weapon design and nuclear strategy. Additionally, development and maintenance of delivery options is among the most resource-intensive aspects of a nuclear weapons program: according to one estimate, deployment costs accounted for 57% of the total financial resources spent by the United States in relation to nuclear weapons since 1940.
Historically the first method of delivery, and the method used in the two nuclear weapons used in warfare, was as a gravity bomb, dropped from bomber aircraft. This is usually the first method that countries developed, as it does not place many restrictions on the size of the weapon and "weapon miniaturization" requires considerable weapons design knowledge. It does, however, limit attack range, response time to an impending attack, and the number of weapons that a country can field at the same time.
With the advent of miniaturization, nuclear bombs can be delivered by both strategic bombers and tactical fighter-bombers, allowing an air force to use its current fleet with little or no modification. This method may still be considered the primary means of nuclear weapons delivery; the majority of U.S. nuclear warheads, for example, are free-fall gravity bombs, namely the B61.
More preferable from a strategic point of view is a nuclear weapon mounted onto a missile, which can use a ballistic trajectory to deliver the warhead over the horizon. Although even short-range missiles allow for a faster and less vulnerable attack, the development of long-range intercontinental ballistic missiles (ICBMs) and submarine-launched ballistic missiles (SLBMs) has given some nations the ability to plausibly deliver missiles anywhere on the globe with a high likelihood of success.
More advanced systems, such as multiple independently targetable reentry vehicles (MIRVs), can launch multiple warheads at different targets from one missile, reducing the chance of a successful missile defense. Today, missiles are most common among systems designed for delivery of nuclear weapons. Making a warhead small enough to fit onto a missile, though, can be difficult.
Tactical weapons have involved the most variety of delivery types, including not only gravity bombs and missiles but also artillery shells, land mines, and nuclear depth charges and torpedoes for anti-submarine warfare. An atomic mortar was also tested at one time by the United States. Small, two-man portable tactical weapons (somewhat misleadingly referred to as suitcase bombs), such as the Special Atomic Demolition Munition, have been developed, although the difficulty of combining sufficient yield with portability limits their military utility.
Nuclear strategy.
Nuclear warfare strategy is a set of policies that deal with preventing or fighting a nuclear war. The policy of trying to prevent an attack by a nuclear weapon from another country by threatening nuclear retaliation is known as the strategy of nuclear deterrence. The goal in deterrence is to always maintain a second strike capability (the ability of a country to respond to a nuclear attack with one of its own) and potentially to strive for first strike status (the ability to completely destroy an enemy's nuclear forces before they could retaliate). During the Cold War, policy and military theorists in nuclear-enabled countries worked out models of what sorts of policies could prevent one from ever being attacked by a nuclear weapon, and developed weapon game theory models that create the greatest and most stable deterrence conditions.
Different forms of nuclear weapons delivery (see above) allow for different types of nuclear strategies. The goals of any strategy are generally to make it difficult for an enemy to launch a pre-emptive strike against the weapon system and difficult to defend against the delivery of the weapon during a potential conflict. Sometimes this has meant keeping the weapon locations hidden, such as deploying them on submarines or land mobile transporter erector launchers whose locations are very hard for an enemy to track, and other times, this means protecting them by burying them in hardened missile silo bunkers.
Other components of nuclear strategies have included using missile defense (to destroy the missiles before they land) or implementation of civil defense measures (using early-warning systems to evacuate citizens to safe areas before an attack).
Note that weapons designed to threaten large populations, or to generally deter attacks are known as "strategic weapons." Weapons designed for use on a battlefield in military situations are called "tactical weapons."
There are critics of the very idea of nuclear strategy for waging nuclear war who have suggested that a nuclear war between two nuclear powers would result in mutual annihilation. From this point of view, the significance of nuclear weapons is purely to deter war because any nuclear war would immediately escalate out of mutual distrust and fear, resulting in mutually assured destruction. This threat of national, if not global, destruction has been a strong motivation for anti-nuclear weapons activism.
Critics from the peace movement and within the military establishment have questioned the usefulness of such weapons in the current military climate. According to an advisory opinion issued by the International Court of Justice in 1996, the use of (or threat of use of) such weapons would generally be contrary to the rules of international law applicable in armed conflict, but the court did not reach an opinion as to whether or not the threat or use would be lawful in specific extreme circumstances such as if the survival of the state were at stake.
Another deterrence position in nuclear strategy is that nuclear proliferation can be desirable. This view argues that, unlike conventional weapons, nuclear weapons successfully deter all-out war between states, and they succeeded in doing this during the Cold War between the U.S. and the Soviet Union. In the late 1950s and early 1960s, Gen. Pierre Marie Gallois of France, an adviser to Charles DeGaulle, argued in books like "The Balance of Terror: Strategy for the Nuclear Age" (1961) that mere possession of a nuclear arsenal, what the French called the "force de frappe", was enough to ensure deterrence, and thus concluded that the spread of nuclear weapons could increase international stability. Some very prominent neo-realist scholars, such as the late Kenneth Waltz, formerly a Political Science at UC Berkeley and Adjunct Senior Research Scholar at Columbia University, and John Mearsheimer of University of Chicago, have also argued along the lines of Gallois. Specifically, these scholars have advocated some forms of nuclear proliferation, arguing that it would decrease the likelihood of total war, especially in troubled regions of the world where there exists a unipolar nuclear weapon state. Aside from the public opinion that opposes proliferation in any form, there are two schools of thought on the matter: those, like Mearsheimer, who favor selective proliferation, and those of Kenneth Waltz, who was somewhat more non-interventionist.
The threat of potentially suicidal terrorists possessing nuclear weapons (a form of nuclear terrorism) complicates the decision process. The prospect of mutually assured destruction may not deter an enemy who expects to die in the confrontation. Further, if the initial act is from a stateless terrorist instead of a sovereign nation, there is no fixed nation or fixed military targets to retaliate against. It has been argued by the New York Times, especially after the September 11, 2001 attacks, that this complication is the sign of the next age of nuclear strategy, distinct from the relative stability of the Cold War. In 1996, the United States adopted a policy of allowing the targeting of its nuclear weapons at terrorists armed with weapons of mass destruction.
Robert Gallucci, president of the John D. and Catherine T. MacArthur Foundation, argues that although traditional deterrence is not an effective approach toward terrorist groups bent on causing a nuclear catastrophe, Gallucci believes that “the United States should instead consider a policy of expanded deterrence, which focuses not solely on the would-be nuclear terrorists but on those states that may deliberately transfer or inadvertently lead nuclear weapons and materials to them. By threatening retaliation against those states, the United States may be able to deter that which it cannot physically prevent.”.
Graham Allison makes a similar case, arguing that the key to expanded deterrence is coming up with ways of tracing nuclear material to the country that forged the fissile material. “After a nuclear bomb detonates, nuclear forensics cops would collect debris samples and send them to a laboratory for radiological analysis. By identifying unique attributes of the fissile material, including its impurities and contaminants, one could trace the path back to its origin.” The process is analogous to identifying a criminal by fingerprints. “The goal would be twofold: first, to deter leaders of nuclear states from selling weapons to terrorists by holding them accountable for any use of their own weapons; second, to give leader every incentive to tightly secure their nuclear weapons and materials.”
Governance, control, and law.
Because of the immense military power they can confer, the political control of nuclear weapons has been a key issue for as long as they have existed; in most countries the use of nuclear force can only be authorized by the head of government or head of state.
In the late 1940s, lack of mutual trust was preventing the United States and the Soviet Union from making ground towards international arms control agreements. The Russell–Einstein Manifesto was issued in London on July 9, 1955 by Bertrand Russell in the midst of the Cold War. It highlighted the dangers posed by nuclear weapons and called for world leaders to seek peaceful resolutions to international conflict. The signatories included eleven pre-eminent intellectuals and scientists, including Albert Einstein, who signed it just days before his death on April 18, 1955. A few days after the release, philanthropist Cyrus S. Eaton offered to sponsor a conference—called for in the manifesto—in Pugwash, Nova Scotia, Eaton's birthplace. This conference was to be the first of the Pugwash Conferences on Science and World Affairs, held in July 1957.
By the 1960s steps were being taken to limit both the proliferation of nuclear weapons to other countries and the environmental effects of nuclear testing. The Partial Test Ban Treaty (1963) restricted all nuclear testing to underground nuclear testing, to prevent contamination from nuclear fallout, whereas the Nuclear Non-Proliferation Treaty (1968) attempted to place restrictions on the types of activities signatories could participate in, with the goal of allowing the transference of non-military nuclear technology to member countries without fear of proliferation.
In 1957, the International Atomic Energy Agency (IAEA) was established under the mandate of the United Nations to encourage development of peaceful applications for nuclear technology, provide international safeguards against its misuse, and facilitate the application of safety measures in its use. In 1996, many nations signed the Comprehensive Test Ban Treaty, which prohibits all testing of nuclear weapons. A testing ban imposes a significant hindrance to nuclear arms development by any complying country. The Treaty requires the ratification by 44 specific states before it can go into force; as of 2012, the ratification of eight of these states is still required.
Additional treaties and agreements have governed nuclear weapons stockpiles between the countries with the two largest stockpiles, the United States and the Soviet Union, and later between the United States and Russia. These include treaties such as SALT II (never ratified), START I (expired), INF, START II (never ratified), SORT, and New START, as well as non-binding agreements such as SALT I and the Presidential Nuclear Initiatives of 1991. Even when they did not enter into force, these agreements helped limit and later reduce the numbers and types of nuclear weapons between the United States and the Soviet Union/Russia.
Nuclear weapons have also been opposed by agreements between countries. Many nations have been declared Nuclear-Weapon-Free Zones, areas where nuclear weapons production and deployment are prohibited, through the use of treaties. The Treaty of Tlatelolco (1967) prohibited any production or deployment of nuclear weapons in Latin America and the Caribbean, and the Treaty of Pelindaba (1964) prohibits nuclear weapons in many African countries. As recently as 2006 a Central Asian Nuclear Weapon Free Zone was established amongst the former Soviet republics of Central Asia prohibiting nuclear weapons.
In the middle of 1996, the International Court of Justice, the highest court of the United Nations, issued an Advisory Opinion concerned with the "Legality of the Threat or Use of Nuclear Weapons". The court ruled that the use or threat of use of nuclear weapons would violate various articles of international law, including the Geneva Conventions, the Hague Conventions, the UN Charter, and the Universal Declaration of Human Rights. In view of the unique, destructive characteristics of nuclear weapons, the International Committee of the Red Cross calls on States to ensure that these weapons are never used, irrespective of whether they consider them lawful or not.
Additionally, there have been other, specific actions meant to discourage countries from developing nuclear arms. In the wake of the tests by India and Pakistan in 1998, economic sanctions were (temporarily) levied against both countries, though neither were signatories with the Nuclear Non-Proliferation Treaty. One of the stated "casus belli" for the initiation of the 2003 Iraq War was an accusation by the United States that Iraq was actively pursuing nuclear arms (though this was soon discovered not to be the case as the program had been discontinued). In 1981, Israel had bombed a nuclear reactor being constructed in Osirak, Iraq, in what it called an attempt to halt Iraq's previous nuclear arms ambitions; in 2007, Israel bombed another reactor being constructed in Syria.
In 2013, Mark Diesendorf says that governments of France, India, North Korea, Pakistan, UK, and South Africa have used nuclear power and/or research reactors to assist nuclear weapons development or to contribute to their supplies of nuclear explosives from military reactors.
Disarmament.
Nuclear disarmament refers to both the act of reducing or eliminating nuclear weapons and to the end state of a nuclear-free world, in which nuclear weapons are completely eliminated.
Beginning with the 1963 Partial Test Ban Treaty and continuing through the 1996 Comprehensive Test Ban Treaty, there have been many treaties to limit or reduce nuclear weapons testing and stockpiles. The 1968 Nuclear Non-Proliferation Treaty has as one of its explicit conditions that all signatories must "pursue negotiations in good faith" towards the long-term goal of "complete disarmament". The nuclear weapon states have largely treated that aspect of the agreement as "decorative" and without force.
Only one country—South Africa—has ever fully renounced nuclear weapons they had independently developed. The former Soviet republics of Belarus, Kazakhstan, and Ukraine returned Soviet nuclear arms stationed in their countries to Russia after the collapse of the USSR.
Proponents of nuclear disarmament say that it would lessen the probability of nuclear war occurring, especially accidentally. Critics of nuclear disarmament say that it would undermine the present nuclear peace and deterrence and would lead to increased global instability. Various American elder statesmen, who were in office during the Cold War period, have been advocating the elimination of nuclear weapons. These officials include Henry Kissinger, George Shultz, Sam Nunn, and William Perry. In January 2010, Lawrence M. Krauss stated that "no issue carries more importance to the long-term health and security of humanity than the effort to reduce, and perhaps one day, rid the world of nuclear weapons".
In the years after the end of the Cold War, there have been numerous campaigns to urge the abolition of nuclear weapons, such as that organized by the Global Zero movement, and the goal of a "world without nuclear weapons" was advocated by United States President Barack Obama in an April 2009 speech in Prague. A CNN poll from April 2010 indicated that the American public was nearly evenly split on the issue.
Some analysts have argued that nuclear weapons have made the world relatively safer, with peace through deterrence and through the stability–instability paradox, including in south Asia. Kenneth Waltz has argued that nuclear weapons have helped keep an uneasy peace, and further nuclear weapon proliferation might even help avoid the large scale conventional wars that were so common prior to their invention at the end of World War II. But former Secretary Henry Kissinger says there is a new danger, which cannot be addressed by deterrence: "The classical notion of deterrence was that there was some consequences before which aggressors and evildoers would recoil. In a world of suicide bombers, that calculation doesn’t operate in any comparable way". George Shultz has said, "If you think of the people who are doing suicide attacks, and people like that get a nuclear weapon, they are almost by definition not deterrable".
United Nations.
The UN Office for Disarmament Affairs (UNODA) is a department of the United Nations Secretariat established in January 1998 as part of the United Nations Secretary-General Kofi Annan's plan to reform the UN as presented in his report to the General Assembly in July 1997.
Its goal is to promote nuclear disarmament and non-proliferation and the strengthening of the disarmament regimes in respect to other weapons of mass destruction, chemical and biological weapons. It also promotes disarmament efforts in the area of conventional weapons, especially land mines and small arms, which are often the weapons of choice in contemporary conflicts.
Controversy.
Ethics.
Even before the first nuclear weapons had been developed, scientists involved with the Manhattan Project were divided over the use of the weapon. The role of the two atomic bombings of the country in Japan's surrender and the U.S.'s ethical justification for them has been the subject of scholarly and popular debate for decades. The question of whether nations should have nuclear weapons, or test them, has been continually and nearly universally controversial.
Nuclear fallout.
Over 500 atmospheric nuclear weapons tests were conducted at various sites around the world from 1945 to 1980. Radioactive fallout from nuclear weapons testing was first drawn to public attention in 1954 when the Castle Bravo hydrogen bomb test at the Pacific Proving Grounds contaminated the crew and catch of the Japanese fishing boat "Lucky Dragon". One of the fishermen died in Japan seven months later, and the fear of contaminated tuna led to a temporary boycotting of the popular staple in Japan. The incident caused widespread concern around the world, especially regarding the effects of nuclear fallout and atmospheric nuclear testing, and "provided a decisive impetus for the emergence of the anti-nuclear weapons movement in many countries".
As public awareness and concern mounted over the possible health hazards associated with exposure to the nuclear fallout, various studies were done to assess the extent of the hazard. A Centers for Disease Control and Prevention/ National Cancer Institute study claims that fallout from atmospheric nuclear tests would lead to perhaps 11,000 excess deaths amongst people alive during atmospheric testing in the United States from all forms of cancer, including leukemia, from 1951 to well into the 21st century.
As of March 2009, the U.S. is the only nation that compensates nuclear test victims. Since the Radiation Exposure Compensation Act of 1990, more than $1.38 billion in compensation has been approved. The money is going to people who took part in the tests, notably at the Nevada Test Site, and to others exposed to the radiation.
Public opposition.
Peace movements emerged in Japan and in 1954 they converged to form a unified "Japanese Council Against Atomic and Hydrogen Bombs". Japanese opposition to nuclear weapons tests in the Pacific Ocean was widespread, and "an estimated 35 million signatures were collected on petitions calling for bans on nuclear weapons".
In the United Kingdom, the first Aldermaston March organised by the Campaign for Nuclear Disarmament(CND) took place at Easter 1958, when, according to the CND, several thousand people marched for four days from Trafalgar Square, London, to the Atomic Weapons Research Establishment close to Aldermaston in Berkshire, England, to demonstrate their opposition to nuclear weapons. The Aldermaston marches continued into the late 1960s when tens of thousands of people took part in the four-day marches.
In 1959, a letter in the "Bulletin of Atomic Scientists" was the start of a successful campaign to stop the Atomic Energy Commission dumping radioactive waste in the sea 19 kilometres from Boston. In 1962, Linus Pauling won the Nobel Peace Prize for his work to stop the atmospheric testing of nuclear weapons, and the "Ban the Bomb" movement spread.
In 1963, many countries ratified the Partial Test Ban Treaty prohibiting atmospheric nuclear testing. Radioactive fallout became less of an issue and the anti-nuclear weapons movement went into decline for some years. A resurgence of interest occurred amid European and American fears of nuclear war in the 1980s.
Costs and technology spin-offs.
According to an audit by the Brookings Institution, between 1940 and 1996, the U.S. spent $ in present day terms on nuclear weapons programs. 57 percent of which was spent on building nuclear weapons delivery systems. 6.3 percent of the total, $ in present day terms, was spent on environmental remediation and nuclear waste management, for example cleaning up the Hanford site, and 7 percent of the total, $ was spent on making nuclear weapons themselves.
Non-weapons uses.
Civil engineering and energy production.
Apart from their use as weapons, nuclear explosives have been tested and used for various non-military uses. These have included large-scale earth moving and the creation of artificial bays. Due to the inability of the physicists to reduce the fission fraction of small, approximately 1 kiloton, yield nuclear devices that would have been required for many civil engineering projects, when long term health and clean-up costs from fission products were included in the cost, there was virtually no economic advantage over conventional explosives, except for potentially the very largest of projects.
At the peak of the Atomic Age, the United States Federal government initiated Operation Plowshare, involving "peaceful nuclear explosions". The United States Atomic Energy Commission chairman announced that the Plowshares project was intended to "highlight the peaceful applications of nuclear explosive devices and thereby create a climate of world opinion that is more favorable to weapons development and tests". The Operation Plowshare program included 27 nuclear tests designed towards investigating these non-weapons uses from 1961 through 1973.
The Qattara Depression Project, as developed by Professor Friedrich Bassler who during his appointment to the West German ministry of economics in 1968 put forth a plan to create a Saharan lake and hydroelectric power station by blasting a tunnel between the Mediterranean sea and the Qattara Depression in Egypt, an area that lies below sea level. The core problem of the entire project was the water supply to the depression. Calculations by Bassler showed that digging a canal or tunnel would be too expensive, therefore Bassler determined that the use of nuclear explosive devices, to excavate the canal or tunnel, would be the most economical. The Egyptian government declined to pursue the idea.
The Soviet Union's Nuclear Explosions for the National Economy was a program in the Soviet Union that investigated non-weapons uses of nuclear explosions. These included one 30 kiloton explosion being used to close the Uzbekistani "Urtabulak" gas well in 1966 that had been blowing since 1963, and a few months later a 47 kiloton explosive was used to seal a higher pressure blowout at the nearby "Pamuk" gas field.
The public records for devices that produced the highest proportion of their yield via fusion-only reactions are possibly the Soviet peaceful nuclear explosions of the 1970s, with 98% of their 15 kiloton explosive yield being derived from fusion reactions, a total fission fraction of 0.3 kilotons in a 15 kt device.
The repeated detonation of nuclear devices underground in salt domes, in a somewhat analogous manner to the explosions that power a car internal combustion engine(in that it would be a heat engine) has also been proposed as a means of fusion power, in what is termed PACER. Other investigated uses for peaceful nuclear explosions were underground detonations to stimulate, by a process analogous to fracking, the flow of petroleum and natural gas in tight formations, this was most developed in the Soviet Union, with an increase in the production of many well heads being reported.
Physics.
The discovery and synthesis of new chemical elements by nuclear transmutation, and their production in the necessary quantities to allow the studying of their properties, was carried out in nuclear explosive device testing. For example, the discovery of the short lived einsteinium and fermium, both created under the intense neutron flux environment within thermonuclear explosions, followed the first Teller-Ulam thermonuclear device test – Ivy Mike. The rapid capture of so many neutrons required in the synthesis of einsteinium would provide the needed direct experimental confirmation of the so-called r-process, the multiple neutron absorptions needed to explain the cosmic nucleosynthesis (production) of all heavy chemical elements heavier than nickel on the periodic table, in supernova explosions, before beta decay, with the r-process explaining the existence of many stable elements in the universe.
The worldwide presence of new isotopes from atmospheric testing beginning in the 1950s led to the 2008 development of a reliable way to detect art forgeries. Paintings created after that period may contain traces of caesium-137 and strontium-90, isotopes that did not exist in nature before 1945. (Fission products were produced in the natural nuclear fission reactor at Oklo about 1.7 billion years ago, but these decayed away before the earliest known human painting.)
Both climatology and particularly aerosol science, a subfield of atmospheric science, were largely created to answer the question of how far and wide fallout would travel. Similar to radioactive tracers used in hydrology and materials testing, fallout and the neutron activation of nitrogen gas served as a radioactive tracer that was used to measure and then help model global circulations in the atmosphere by following the movements of fallout aerosols.
After the Van Allen Belts surrounding Earth were published about in 1958, James Van Allen suggested that a nuclear detonation would be one way of probing the magnetic phenomenon, data obtained from the August 1958 Project Argus test shots, a high altitude nuclear explosion investigation, were vital to the early understanding of Earth's magnetosphere.
Soviet nuclear physicist and Nobel peace prize recipient Andrei Sakharov also proposed the idea that earthquakes could be mitigated and particle accelerators could be made by utilizing nuclear explosions, with the latter created by connecting a nuclear explosive device with another of his inventions, the explosively pumped flux compression generator, to accelerate protons to collide with each other to probe their inner workings, an endeavor that is now done at much lower energy levels with non-explosive superconducting magnets in CERN. Sakharov suggested to replace the copper coil in his MK generators by a big superconductor solenoid to magnetically compress and focus underground nuclear explosions into a shaped charge effect. He theorized this could focus 1023 positively charged protons per second on a 1 mm2 surface, then envisaged making two such beams collide in the form of a supercollider.
Underground nuclear explosive data from peaceful nuclear explosion test shots have been used to investigate the composition of Earth's mantle, analogous to the exploration geophysics practice of mineral prospecting with chemical explosives in "deep seismic sounding" reflection seismology.
Project A119, proposed in the 1960s, which as Apollo scientist Gary Latham explained, would have been the detonating of a "smallish" nuclear device on the Moon in order to facilitate research into its geologic make-up. Analogous in concept to the comparatively low yield explosion created by the water prospecting (LCROSS)Lunar Crater Observation and Sensing Satellite mission, which launched in 2009 and released the "Centaur" kinetic energy impactor, an impactor with a mass of 2,305 kg (5,081 lb), and an impact velocity of about 9000 km/h, releasing the kinetic energy equivalent of detonating approximately 2 tons of TNT (8.86 GJ).
Propulsion use.
Although likely never achieving orbit due to aerodynamic drag, the first macroscopic object to obtain Earth orbital velocity was a "manhole cover" propelled by the detonation of test shot Pascal-B, before sputnik obtained orbital velocity, and also successfully became the first satellite, in October 1957. The use of a subterranean shaft and nuclear device to propel an object to escape velocity has since been termed a "thunder well".
The direct use of nuclear explosives, by using the impact of propellant plasma from a nuclear shaped charge acting on a pusher plate, has also been seriously studied as a potential propulsion mechanism for space travel (see Project Orion).
Edward Teller, in the United States, proposed the use of a nuclear detonation to power an explosively pumped "soft" X-ray laser as a component of a ballistic missile defense shield, this would destroy missile components by transferring momentum to the vehicles surface by laser ablation. This ablation process is one of the damage mechanisms of a laser weapon, but it is also the basis of pulsed laser propulsion for spacecraft.
Ground flight testing by Professor Leik Myrabo, using a non-nuclear, conventionally powered pulsed laser test-bed, successfully lifted a lightcraft 72 meters in altitude by a method similar to ablative laser propulsion in 2000.
A powerful solar system based "soft" X-ray, to ultraviolet, laser system has been calculated to be capable of propelling an interstellar spacecraft, by the light sail principle, to 11% of the speed of light. In 1972 it was also calculated that a 1 Terawatt, 1-km diameter x-ray laser with 1 angstrom wavelength impinging on a 1-km diameter sail, could propel a spacecraft to Alpha Centauri in 10 years.
Asteroid impact avoidance.
A proposed means of averting an asteroid impacting with Earth, assuming low lead times between detection and Earth impact, is to detonate one, or a series, of nuclear explosive devices, on, in, or in a stand-off proximity orientation with the asteroid, with the latter method occurring far enough away from the incoming threat to prevent the potential fracturing of the near-Earth object, but still close enough to generate a high thrust laser ablation effect.
A 2007 NASA analysis of impact avoidance strategies using various technologies stated:
Nuclear stand-off explosions are assessed to be 10–100 times more effective than the non-nuclear alternatives analyzed in this study. Other techniques involving the surface or subsurface use of nuclear explosives may be more efficient, but they run an increased risk of fracturing the target near-Earth object. They also carry higher development and operations risks.
Analysis of the uncertainty involved in nuclear device asteroid deflection shows that the ability to protect the planet does not imply the ability to also target the planet, which is the case with all non-nuclear alternatives, such as the controversial gravity tractor technology. A nuclear explosion that changed an asteroid's velocity by 10 m/s (±20%) would be adequate to push it out of an Earth-impacting orbit. However, if the uncertainty of the velocity change is more than a few plus or minus percent, there would be no chance of directing the asteroid to a particular target.
However, if the need arises to use nuclear explosive devices to prevent an asteroid impact event, it may face the legal issue that the United Nations Committee on the Peaceful Uses of Outer Space and the 1996 Comprehensive Nuclear-Test-Ban Treaty ban nuclear weapons in space.
Bibliography.
</dl>
External links.
Listen to this article ()
This audio file was created from a revision of the "Nuclear weapon" article dated 2005-12-01, and does not reflect subsequent edits to the article. ()
More spoken articles

</doc>
<doc id="21787" url="http://en.wikipedia.org/wiki?curid=21787" title="Nathaniel Hawthorne">
Nathaniel Hawthorne

Nathaniel Hawthorne (; born Nathaniel Hathorne; July 4, 1804 – May 19, 1864) was an American novelist and short story writer.
He was born in 1804 in Salem, Massachusetts, to Nathaniel Hathorne and the former Elizabeth Clarke Manning. His ancestors include John Hathorne, the only judge involved in the Salem witch trials who never repented of his actions. Nathaniel later added a "w" to make his name "Hawthorne" in order to hide this relation. He entered Bowdoin College in 1821, was elected to Phi Beta Kappa in 1824, and graduated in 1825. Hawthorne published his first work, a novel titled "Fanshawe", in 1828; he later tried to suppress it, feeling it was not equal to the standard of his later work. He published several short stories in various periodicals, which he collected in 1837 as "Twice-Told Tales". The next year, he became engaged to Sophia Peabody. He worked at a Custom House and joined Brook Farm, a transcendentalist community, before marrying Peabody in 1842. The couple moved to The Old Manse in Concord, Massachusetts, later moving to Salem, the Berkshires, then to The Wayside in Concord. "The Scarlet Letter" was published in 1850, followed by a succession of other novels. A political appointment took Hawthorne and family to Europe before their return to The Wayside in 1860. Hawthorne died on May 19, 1864, and was survived by his wife and their three children.
Much of Hawthorne's writing centers on New England, many works featuring moral allegories with a Puritan inspiration. His fiction works are considered part of the Romantic movement and, more specifically, Dark romanticism. His themes often center on the inherent evil and sin of humanity, and his works often have moral messages and deep psychological complexity. His published works include novels, short stories, and a biography of his friend Franklin Pierce.
Biography.
Early life.
Nathaniel Hawthorne was born on July 4, 1804, in Salem, Massachusetts; his birthplace is preserved and open to the public. William Hathorne, the author's great-great-great-grandfather, a Puritan, was the first of the family to emigrate from England, first settling in Dorchester, Massachusetts before moving to Salem. There he became an important member of the Massachusetts Bay Colony and held many political positions including magistrate and judge, becoming infamous for his harsh sentencing. William's son and the author's great-great-grandfather, John Hathorne, was one of the judges who oversaw the Salem witch trials. Having learned about this, the author probably added the "w" to his surname in his early twenties, shortly after graduating from college, in an effort to dissociate himself from his notorious forebears. Hawthorne's father, Nathaniel Hathorne, Sr., was a sea captain who died in 1808 of yellow fever in Suriname; he had been a member of the East India Marine Society. After his death, young Nathaniel, his mother and two sisters moved in with maternal relatives, the Mannings, in Salem, where they lived for 10 years. During this time, on November 10, 1813, young Hawthorne was hit on the leg while playing "bat and ball" and became lame and bedridden for a year, though several physicians could find nothing wrong with him.
 In the summer of 1816, the family lived as boarders with farmers before moving to a home recently built specifically for them by Hawthorne's uncles Richard and Robert Manning in Raymond, Maine, near Sebago Lake. Years later, Hawthorne looked back at his time in Maine fondly: "Those were delightful days, for that part of the country was wild then, with only scattered clearings, and nine tenths of it primeval woods." In 1819, he was sent back to Salem for school and soon complained of homesickness and being too far from his mother and sisters. In spite of his homesickness, for the sake of having fun, he distributed seven issues of "The Spectator" to his family in August and September 1820. The homemade newspaper was written by hand. It included essays, poems, and news utilizing the young author's developing adolescent humor.
Hawthorne's uncle Robert Manning insisted, despite Hawthorne's protests, that the boy attend college. With the financial support of his uncle, Hawthorne was sent to Bowdoin College in 1821, partly because of family connections in the area, and also because of its relatively inexpensive tuition rate. On the way to Bowdoin, at the stage stop in Portland, Hawthorne met future president Franklin Pierce and the two became fast friends. Once at the school, he also met the future poet Henry Wadsworth Longfellow, future congressman Jonathan Cilley, and future naval reformer Horatio Bridge. Years after his graduation with the class of 1825, he would describe his college experience to Richard Henry Stoddard: I was educated (as the phrase is) at Bowdoin College. I was an idle student, negligent of college rules and the Procrustean details of academic life, rather choosing to nurse my own fancies than to dig into Greek roots and be numbered among the learned Thebans.
Early career.
In 1836 Hawthorne served as the editor of the "American Magazine of Useful and Entertaining Knowledge". During this time he boarded with the poet Thomas Green Fessenden on Hancock Street in Beacon Hill in Boston. He was offered an appointment as weigher and gauger at the Boston Custom House at a salary of $1,500 a year, which he accepted on January 17, 1839. During his time there, he rented a room from George Stillman Hillard, business partner of Charles Sumner. Hawthorne wrote in the comparative obscurity of what he called his "owl's nest" in the family home. As he looked back on this period of his life, he wrote: "I have not lived, but only dreamed about living." He contributed short stories, including "Young Goodman Brown" and "The Minister's Black Veil", to various magazines and annuals, though none drew major attention to the author. Horatio Bridge offered to cover the risk of collecting these stories in the spring of 1837 into one volume, "Twice-Told Tales", which made Hawthorne known locally.
Marriage and family.
While at Bowdoin, Hawthorne bet his friend Jonathan Cilley a bottle of Madeira wine that Cilley would get married before he did. By 1836 he had won the wager, but did not remain a bachelor for life. After public flirtations with local women Mary Silsbee and Elizabeth Peabody, he began pursuing the latter's sister, illustrator and transcendentalist Sophia Peabody. Seeking a possible home for himself and Sophia, he joined the transcendentalist Utopian community at Brook Farm in 1841 not because he agreed with the experiment but because it helped him save money to marry Sophia. He paid a $1,000 deposit and was put in charge of shoveling the hill of manure referred to as "the Gold Mine". He left later that year, though his Brook Farm adventure would prove an inspiration for his novel "The Blithedale Romance". Hawthorne married Sophia Peabody on July 9, 1842, at a ceremony in the Peabody parlor on West Street in Boston. The couple moved to The Old Manse in Concord, Massachusetts, where they lived for three years. His neighbor, Ralph Waldo Emerson, invited him into his social circle, but Hawthorne was almost pathologically shy and stayed silent when at gatherings. At the Old Manse, Hawthorne wrote most of the tales collected in "Mosses from an Old Manse".
Like Hawthorne, Sophia was a reclusive person. Throughout her early life, she had frequent migraines and underwent several experimental medical treatments. She was mostly bedridden until her sister introduced her to Hawthorne, after which her headaches seem to have abated. The Hawthornes enjoyed a long and happy marriage. Of his wife, whom he referred to as his "Dove", Hawthorne wrote that she "is, in the strictest sense, my sole companion; and I need no other—there is no vacancy in my mind, any more than in my heart... Thank God that I suffice for her boundless heart!" Sophia greatly admired her husband's work. In one of her journals, she wrote: I am always so dazzled and bewildered with the richness, the depth, the ... jewels of beauty in his productions that I am always looking forward to a second reading where I can ponder and muse and fully take in the miraculous wealth of thoughts.
On the first anniversary of the Hawthornes' marriage, the poet Ellery Channing came to the Old Manse for help. A local teenager named Martha Hunt had drowned herself in the river and Hawthorne's boat, "Pond Lily", was needed to find her body. Hawthorne helped recover the corpse, which he described as "a spectacle of such perfect horror... She was the very image of death-agony". The incident later inspired a scene in his novel "The Blithedale Romance".
Nathaniel and Sophia Hawthorne had three children. Their first, a daughter, was born March 3, 1844. She was named Una, a reference to "The Faerie Queene", to the displeasure of family members. Hawthorne wrote to a friend, "I find it a very sober and serious kind of happiness that springs from the birth of a child... There is no escaping it any longer. I have business on earth now, and must look about me for the means of doing it." In 1846, their son Julian was born. Hawthorne wrote to his sister Louisa on June 22, 1846, with the news: "A small troglodyte made his appearance here at ten minutes to six o'clock this morning, who claimed to be your nephew." Their final child, Rose, was born in May 1851. Hawthorne called her "my autumnal flower".
Middle years.
In April 1846, Hawthorne was officially appointed as the "Surveyor for the District of Salem and Beverly and Inspector of the Revenue for the Port of Salem" at an annual salary of $1,200. He had difficulty writing during this period, as he admitted to Longfellow: I am trying to resume my pen... Whenever I sit alone, or walk alone, I find myself dreaming about stories, as of old; but these forenoons in the Custom House undo all that the afternoons and evenings have done. I should be happier if I could write. Like his earlier appointment to the custom house in Boston, this employment was vulnerable to the politics of the spoils system. A Democrat, Hawthorne lost this job due to the change of administration in Washington after the presidential election of 1848. Hawthorne wrote a letter of protest to the "Boston Daily Advertiser", which was attacked by the Whigs and supported by the Democrats, making Hawthorne's dismissal a much-talked about event in New England. Hawthorne was deeply affected by the death of his mother shortly thereafter in late July, calling it, "the darkest hour I ever lived". Hawthorne was appointed the corresponding secretary of the Salem Lyceum in 1848. Guests that came to speak that season included Emerson, Thoreau, Louis Agassiz and Theodore Parker.
Hawthorne returned to writing and published "The Scarlet Letter" in mid-March 1850, including a preface that refers to his three-year tenure in the Custom House and makes several allusions to local politicians, who did not appreciate their treatment. One of the first mass-produced books in America, it sold 2,500 volumes within ten days and earned Hawthorne $1,500 over 14 years. The book was immediately pirated by booksellers in London and became an immediate best-seller in the United States; it initiated his most lucrative period as a writer. One of Hawthorne's friends, the critic Edwin Percy Whipple, objected to the novel's "morbid intensity" and its dense psychological details, writing that the book "is therefore apt to become, like Hawthorne, too painfully anatomical in his exhibition of them", though 20th-century writer D. H. Lawrence said that there could be no more perfect work of the American imagination than "The Scarlet Letter".
Hawthorne and his family moved to a small red farmhouse near Lenox, Massachusetts at the end of March 1850. Hawthorne became friends with Herman Melville beginning on August 5, 1850, when the authors met at a picnic hosted by a mutual friend. Melville had just read Hawthorne's short story collection "Mosses from an Old Manse", and his unsigned review of the collection, titled "Hawthorne and His Mosses", was printed in "The Literary World" on August 17 and August 24. Melville, who was composing "Moby-Dick" at the time, wrote that these stories revealed a dark side to Hawthorne, "shrouded in blackness, ten times black". Melville dedicated "Moby-Dick" (1851) to Hawthorne: "In token of my admiration for his genius, this book is inscribed to Nathaniel Hawthorne."
Hawthorne's time in The Berkshires was very productive. "The House of the Seven Gables" (1851), which poet and critic James Russell Lowell said was better than "The Scarlet Letter" and called "the most valuable contribution to New England history that has been made" and "The Blithedale Romance" (1852), his only work written in the first person, were written here. He also published in 1851 a collection of short stories retelling myths, "A Wonder-Book for Girls and Boys", a book he had been thinking about writing since 1846. Nevertheless, the poet Ellery Channing reported that Hawthorne "has suffered much living in this place". Though the family enjoyed the scenery of The Berkshires, Hawthorne did not enjoy the winters in their small red house. They left on November 21, 1851. Hawthorne noted, "I am sick to death of Berkshire... I have felt languid and dispirited, during almost my whole residence."
The Wayside and Europe.
In 1852, the Hawthornes returned to Concord. In February, they bought The Hillside, a home previously inhabited by Amos Bronson Alcott and his family, and renamed it The Wayside. Their neighbors in Concord included Emerson and Henry David Thoreau. That year Hawthorne wrote the campaign biography of his friend Franklin Pierce, depicting him as "a man of peaceful pursuits" in the book, which he titled "The Life of Franklin Pierce". Horace Mann said, "If he makes out Pierce to be a great man or a brave man, it will be the greatest work of fiction he ever wrote." In the biography, Hawthorne depicted Pierce as a statesman and soldier who had accomplished no great feats because of his need to make "little noise" and so "withdrew into the background". He also left out Pierce's drinking habits despite rumors of his alcoholism and emphasized Pierce's belief that slavery could not "be remedied by human contrivances" but would, over time, "vanish like a dream". With Pierce's election as President, Hawthorne was rewarded in 1853 with the position of United States consul in Liverpool shortly after the publication of "Tanglewood Tales". The role, considered the most lucrative foreign service position at the time, was described by Hawthorne's wife as "second in dignity to the Embassy in London". In 1857, his appointment ended at the close of the Pierce administration and the Hawthorne family toured France and Italy. During his time in Italy, the previously clean-shaven Hawthorne grew a bushy mustache.
The family returned to The Wayside in 1860, and that year saw the publication of "The Marble Faun", his first new book in seven years. Hawthorne admitted he had aged considerably, referring to himself as "wrinkled with time and trouble".
Later years and death.
At the outset of the American Civil War, Hawthorne traveled with William D. Ticknor to Washington, D.C.. There, he met Abraham Lincoln and other notable figures. He wrote about his experiences in the essay "Chiefly About War Matters" in 1862.
Failing health prevented him from completing several more romances. Suffering from pain in his stomach, Hawthorne insisted on a recuperative trip with his friend Franklin Pierce, though his neighbor Bronson Alcott was concerned Hawthorne was too ill. While on a tour of the White Mountains, Hawthorne died in his sleep on May 19, 1864, in Plymouth, New Hampshire. Pierce sent a telegram to Elizabeth Peabody to inform Hawthorne's wife in person; she was too saddened by the news to handle the funeral arrangements herself. Hawthorne's son Julian, at the time a freshman at Harvard College, learned of his father's death the next day; coincidentally, it was the same day he was initiated into the Delta Kappa Epsilon fraternity by being placed blindfolded into a coffin. Longfellow wrote a tribute poem to Hawthorne, published in 1866, called "". Hawthorne was buried on what is now known as "Authors' Ridge" in Sleepy Hollow Cemetery, Concord, Massachusetts. Pallbearers included Longfellow, Emerson, Alcott, Oliver Wendell Holmes, Sr., James Thomas Fields, and Edwin Percy Whipple. Emerson wrote of the funeral: "I thought there was a tragic element in the event, that might be more fully rendered,—in the painful solitude of the man, which, I suppose, could no longer be endured, & he died of it."
His wife Sophia and daughter Una were originally buried in England. However, in June 2006, they were re-interred in plots adjacent to Hawthorne.
Writings.
Hawthorne had a particularly close relationship with his publishers William Ticknor and James Thomas Fields. Hawthorne once told Fields, "I care more for your good opinion than for that of a host of critics." In fact, it was Fields who convinced Hawthorne to turn "The Scarlet Letter" into a novel rather than a short story. Ticknor handled many of Hawthorne's personal matters, including the purchase of cigars, overseeing financial accounts, and even purchasing clothes. Ticknor died with Hawthorne at his side in Philadelphia in 1864; according to a friend, Hawthorne was left "apparently dazed".
Literary style and themes.
Hawthorne's works belong to romanticism or, more specifically, dark romanticism, cautionary tales that suggest that guilt, sin, and evil are the most inherent natural qualities of humanity. Many of his works are inspired by Puritan New England, combining historical romance loaded with symbolism and deep psychological themes, bordering on surrealism. His depictions of the past are a version of historical fiction used only as a vehicle to express common themes of ancestral sin, guilt and retribution. His later writings also reflect his negative view of the Transcendentalism movement.
Hawthorne was predominantly a short story writer in his early career. Upon publishing "Twice-Told Tales", however, he noted, "I do not think much of them," and he expected little response from the public. His four major romances were written between 1850 and 1860: "The Scarlet Letter" (1850), "The House of the Seven Gables" (1851), "The Blithedale Romance" (1852) and "The Marble Faun" (1860). Another novel-length romance, "Fanshawe" was published anonymously in 1828. Hawthorne defined a romance as being radically different from a novel by not being concerned with the possible or probable course of ordinary experience. In the preface to "The House of the Seven Gables", Hawthorne describes his romance-writing as using "atmospherical medium as to bring out or mellow the lights and deepen and enrich the shadows of the picture".
Feminists and historicists have in recent years revalued Hawthorne's thematic depictions of women as figurations of transformative potential. These scholars are interested particularly in stalwart Hester Prynne, in her own forward-looking words the "destined prophetess, . . . angel and apostle of the coming revelation". Camille Paglia saw Hester as mystical, "a wandering goddess still bearing the mark of her Asiatic origins ... moving serenely in the magic circle of her sexual nature". Lauren Berlant termed take-charge but caring Hester "the citizen as woman [personifying] love as a quality of the body that contains the purest light of nature," her resulting "traitorous political theory" a "Female Symbolic" literalization of futile Puritan metaphors. Historicists view Hester as a protofeminist and avatar of the self-reliance and responsibility that led to women's suffrage and reproductive emancipation. Anthony Splendora found her likely literary genealogy among other archetypally fallen but redeemed women, both historic and mythic, who stood up for their meritorious rights: to wit, Psyche of ancient legend, Heloise of twelfth-century France's tragedy involving world-renowned philosopher Peter Abelard, Anne Hutchinson (America's first heretic, circa 1636), and Hawthorne family friend Margaret Fuller. In Hester's first "Scarlet Letter" appearance, Hawthorne likens her, "infant at her bosom", to Mary, Mother of Jesus, "the image of Divine Maternity". Her potentiality as agency of transformation is thus immediate and specific. In her study of Victorian literature, in which such "galvanic outcasts" as Hester feature prominently, Nina Auerbach went so far as to name Hester's fall and subsequent redemption "the novel's one unequivocally religious activity". Regarding Hester as a deity figure, Meredith A. Powers found in Hester's characterization "the earliest in American fiction that the archetypal Goddess appears quite graphically," like a Goddess "not the wife of traditional marriage, permanently subject to a male overlord"; Powers noted "her syncretism, her flexibility, her inherent ability to alter and so avoid the defeat of secondary status in a goal-oriented civilization" Aside from Hester Prynne, the cynosural women of Hawthorne's other novels — from Ellen Langton of "Fanshawe" to Zenobia and Priscilla of "The Blithedale Romance," Hilda and Miriam of "The Marble Faun" and Phoebe and Hepzibah of "The House of the Seven Gables" — are more fully realized than his male characters, who merely orbit them. This observation is equally true of his short-story protagonistas, central females who serve as unambiguous allegorical foci: Rappaccini's beautiful but life-altering, garden-bound, Eve-like daughter; provocatively almost-perfect Georgiana of "The Birthmark"; the unpardonably sinned-against (abandoned) Ester of "Ethan Brand"; and goodwife Faith Brown, linchpin of Young Goodman Brown's very belief in God. "My Faith is gone!" Brown exclaims in despair upon seeing his wife at the Witches' Sabbath. Hawthorne could not have been more explicit in illuminating his view of the significance of, and his hopeful sympathies with, women.
Hawthorne also wrote nonfiction. In 2008, The Library of America selected Hawthorne's "A Collection of Wax Figures" for inclusion in its two-century retrospective of American True Crime.
Criticism.
Edgar Allan Poe wrote important and somewhat unflattering reviews of both "Twice-Told Tales" and "Mosses from an Old Manse". Poe's negative assessment was partly due to his own contempt of allegory and moral tales, and his chronic accusations of plagiarism, though he admitted, The style of Hawthorne is purity itself. His tone is singularly effective—wild, plaintive, thoughtful, and in full accordance with his themes... We look upon him as one of the few men of indisputable genius to whom our country has as yet given birth. Ralph Waldo Emerson wrote, "Nathaniel Hawthorne's reputation as a writer is a very pleasing fact, because his writing is not good for anything, and this is a tribute to the man." Henry James praised Hawthorne, saying, "The fine thing in Hawthorne is that he cared for the deeper psychology, and that, in his way, he tried to become familiar with it." Poet John Greenleaf Whittier wrote that he admired the "weird and subtle beauty" in Hawthorne's tales. Evert Augustus Duyckinck said of Hawthorne, "Of the American writers destined to live, he is the most original, the one least indebted to foreign models or literary precedents of any kind."
Contemporary response to Hawthorne's work praised his sentimentality and moral purity while more modern evaluations focus on the dark psychological complexity. Beginning in the 1950s, critics have focused on symbolism and didacticism.
The critic Harold Bloom has opined that only Henry James and William Faulkner challenge Hawthorne's position as the greatest American novelist, although he admits that he favors James as the greatest American novelist. Bloom sees Hawthorne's greatest works to be principally "The Scarlet Letter" followed by "The Marble Faun" and certain short stories including "My Kinsman, Major Molineux", "Young Goodman Brown", "Wakefield" and "Feathertop".
References.
</dl>

</doc>
<doc id="21790" url="http://en.wikipedia.org/wiki?curid=21790" title="Nagasaki">
Nagasaki

Nagasaki (長崎市, Nagasaki-shi) (  ) is the capital and the largest city of Nagasaki Prefecture on the island of Kyushu in Japan. It became a center of Portuguese and other European influence in the 16th through 19th centuries, and the Churches and Christian Sites in Nagasaki have been proposed for inscription on the UNESCO World Heritage List. Part of Nagasaki was home to a major Imperial Japanese Navy base during the First Sino-Japanese War and Russo-Japanese War. Its name means "long cape".
During World War II, the atomic bombings of Hiroshima and Nagasaki made Nagasaki the second and, to date, last city in the world to experience a nuclear attack.
As of January 1, 2009, the city has an estimated population of 446,007 and a population density of 1,100 persons per km². The total area is 406.35 km².
History.
Medieval and early modern history.
A small fishing village secluded by harbours, Nagasaki had little historical significance until contact with Portuguese explorers in 1543. An early visitor was Fernão Mendes Pinto, who came on a Portuguese ship which landed nearby in Tanegashima.
Soon after Portuguese ships started sailing to Japan as regular trade freighters, thus increasing the contact and trade relations between Japan and the rest of the world, and particularly with mainland China, with whom Japan had previously severed its commercial and political ties, mainly due to a number of incidents involving Wokou piracy in the South China Sea, with the Portuguese now serving as intermediaries between the two Asian countries.
Despite the mutual advantages derived from these trading contacts, which would soon be acknowledged by all parties involved, the lack of a proper seaport in Kyūshū for the purpose of harboring foreign ships posed a major problem for both merchants and the Kyushu daimyo (feudal lords) who expected to collect great advantages from these intercourse with the Portuguese.
In the meantime, Navarrese Jesuit missionary St. Francis Xavier arrived in Kagoshima, South Kyūshū, in 1549, and soon initiated a thorough campaign of evangelization throughout Japan, but left for China in 1551 and died soon afterwards. His followers who remained behind converted a number of daimyo. The most notable among them was Ōmura Sumitada, who greatly profited from his conversion to the "Kirishitan" religion through an accompanying deal to receive a portion of the trade from Portuguese ships. In 1569, Ōmura granted a permit for the establishment of a port with the purpose of harboring Portuguese ships in Nagasaki, which was finally set in 1571, under the supervision of the Jesuit missionary Gaspar Vilela and Portuguese Captain-Major Tristão Vaz de Veiga, with Ōmura's personal assistance.
The little harbor village quickly grew into a diverse port city , and Portuguese products imported through Nagasaki (such as tobacco, bread, textiles and a Portuguese sponge-cake called "castellas") were assimilated into popular Japanese culture. Tempura derived from a popular Portuguese recipe originally known as "peixinho-da-horta", and takes its name from the Portuguese word, 'tempero' another example of the enduring effects of this cultural exchange. The Portuguese also brought with them many goods from China.
Due to the instability during the Sengoku period, Sumitada and Jesuit leader Alexandro Valignano conceived a plan to pass administrative control over to the Society of Jesus rather than see the Catholic city taken over by a non-Catholic daimyo. Thus, for a brief period after 1580, the city of Nagasaki was a Jesuit colony, under their administrative and military control. It became a refuge for Christians escaping maltreatment in other regions of Japan. In 1587, however, Toyotomi Hideyoshi's campaign to unify the country arrived in Kyūshū. Concerned with the large Christian influence in southern Japan, as well as the active and what was perceived as the arrogant role the Jesuits were playing in the Japanese political arena, Hideyoshi ordered the expulsion of all missionaries, and placed the city under his direct control. However, the expulsion order went largely unenforced, and the fact remained that most of Nagasaki's population remained openly practicing Catholic.
In 1596, the Spanish ship "San Felipe" was wrecked off the coast of Shikoku, and Hideyoshi learned from its pilot that the Spanish Franciscans were the vanguard of an Iberian invasion of Japan. In response, Hideyoshi ordered the crucifixions of twenty-six Catholics in Nagasaki on February 5 of that year (i.e. the "Twenty-six Martyrs of Japan"). Portuguese traders were not ostracized, however, and so the city continued to thrive.
In 1602, Augustinian missionaries also arrived in Japan, and when Tokugawa Ieyasu took power in 1603, Catholicism was still tolerated. Many Catholic daimyo had been critical allies at the Battle of Sekigahara, and the Tokugawa position was not strong enough to move against them. Once Osaka Castle had been taken and Toyotomi Hideyoshi's offspring killed, though, the Tokugawa dominance was assured. In addition, the Dutch and English presence allowed trade without religious strings attached. Thus, in 1614, Catholicism was officially banned and all missionaries ordered to leave. Most Catholic daimyo apostatized, and forced their subjects to do so, although a few would not renounce the religion and left the country for Macau, Luzon and Japantowns in Southeast Asia. A brutal campaign of persecution followed, with thousands of converts across Kyūshū and other parts of Japan killed, tortured, or forced to renounce their religion.
Catholicism's last gasp as an open religion, and the last major military action in Japan until the Meiji Restoration, was the Shimabara Rebellion of 1637. While there is no evidence that Europeans directly incited the rebellion, Shimabara Domain had been a Christian "han" for several decades, and the rebels adopted many Portuguese motifs and Christian icons. Consequently, in Tokugawa society the word "Shimabara" solidified the connection between Christianity and disloyalty, constantly used again and again in Tokugawa propaganda.
The Shimabara Rebellion also convinced many policy-makers that foreign influences were more trouble than they were worth, leading to the national isolation policy. The Portuguese, who had been previously living on a specially constructed island-prison in Nagasaki harbour called Dejima, were expelled from the archipelago altogether, and the Dutch were moved from their base at Hirado into the trading island. In 1720 the ban on Dutch books was lifted, causing hundreds of scholars to flood into Nagasaki to study European science and art. Consequently, Nagasaki became a major center of "rangaku", or "Dutch Learning". During the Edo period, the Tokugawa shogunate governed the city, appointing a "hatamoto", the "Nagasaki bugyō", as its chief administrator.
Consensus among historians was once that Nagasaki was Japan's only window on the world during its time as a closed country in the Tokugawa era. However, nowadays it is generally accepted that this was not the case, since Japan interacted and traded with the Ryūkyū Kingdom, Korea and Russia through Satsuma, Tsushima and Matsumae respectively. Nevertheless, Nagasaki was depicted in contemporary art and literature as a cosmopolitan port brimming with exotic curiosities from the Western World.
In 1808, during the Napoleonic Wars the Royal Navy frigate HMS "Phaeton" entered Nagasaki Harbor in search of Dutch trading ships. The local magistrate was unable to resist the British demand for food, fuel, and water, later committing "seppuku" as a result. Laws were passed in the wake of this incident strengthening coastal defenses, threatening death to intruding foreigners, and prompting the training of English and Russian translators.
The "Tōjinyashiki" (唐人屋敷) or Chinese Factory in Nagasaki was also an important conduit for Chinese goods and information for the Japanese market. Various colourful Chinese merchants and artists sailed between the Chinese mainland and Nagasaki. Some actually combined the roles of merchant and artist such as 18th century Yi Hai. It is believed that as much as one-third of the population of Nagasaki at this time may have been Chinese.
Modern history.
With the Meiji Restoration, Japan opened its doors once again to foreign trade and diplomatic relations. Nagasaki became a free port in 1859 and modernization began in earnest in 1868. Nagasaki was officially proclaimed a city on April 1, 1889. With Christianity legalized and the Kakure Kirishitan coming out of hiding, Nagasaki regained its earlier role as a center for Roman Catholicism in Japan.
During the Meiji period, Nagasaki became a center of heavy industry. Its main industry was ship-building, with the dockyards under control of Mitsubishi Heavy Industries becoming one of the prime contractors for the Imperial Japanese Navy, and with Nagasaki harbor used as an anchorage under the control of nearby Sasebo Naval District. During World War II, at the time of the nuclear attack on August 9, 1945, Nagasaki was an important industrial city, containing both plants of the Mitsubishi Steel and Arms Works, the Akunoura Engine Works, Mitsubishi Arms Plant, Mitsubishi Electric Shipyards, Mitsubishi Steel and Arms Works, Mitsubishi-Urakami Ordnance Works, several other small factories, and most of the ports storage and trans-shipment facilities, which employed about 90% of the city's labor force, and accounted for 90% of the city's industry. These connections with the Japanese war effort made Nagasaki a major target for bombing by the Allies during the war.
Atomic bombing of Nagasaki during World War II.
For 12 months prior to the nuclear attack, Nagasaki had experienced five small-scale air attacks by an aggregate of 136 planes which dropped a total of 270 tons of high explosive, 53 tons of incendiary, and 20 tons of fragmentation bombs. Of these, a raid of August 1, 1945, was most effective, with few of the bombs hitting the shipyards and dock areas in the southwest portion of the city, several hitting the Mitsubishi Steel and Arms Works, and six bombs landing at the Nagasaki Medical School and Hospital, with three direct hits on buildings there. While the damage from these few bombs was relatively small, it created considerable concern in Nagasaki and a number of people, principally school children, were evacuated to rural areas for safety, thus reducing the population in the city at the time of the atomic attack.
On the day of the nuclear strike on Thursday, August 9, 1945, the population in Nagasaki was estimated to be 263,000, which consisted of 240,000 Japanese residents, 10,000 Korean residents, 2,500 conscripted Korean workers, 9,000 Japanese soldiers, 600 conscripted Chinese workers, and 400 Allied POWs. That day, the Boeing B-29 Superfortress "Bockscar", commanded by Major Charles Sweeney, departed from Tinian's North Field just before dawn, this time carrying a plutonium bomb code named "Fat Man". The primary target for the bomb was Kokura, with the secondary target, Nagasaki, if the primary target was too cloudy to make a visual sighting. When the plane reached Kokura at 9:44 a.m. (10:44 a.m. Tinian Time), the city was obscured by clouds and smoke, as the nearby city of Yawata had been firebombed on the previous day. Unable to make a bombing attack on visual due to the clouds and smoke and with limited fuel, the plane left the city at 10:30 a.m. for the secondary target. After 20 minutes, the plane arrived at 10:50 a.m. over Nagasaki, but the city was also concealed by clouds. Desperately short of fuel and after making a couple of bombing runs without obtaining any visual target, the crew was forced to use radar in order to drop the bomb. At the last minute, the opening of the clouds allowed them to make visual contact with a racetrack in Nagasaki, and they dropped the bomb on the city's Urakami Valley midway between the Mitsubishi Steel and Arms Works in the south, and the Mitsubishi-Urakami Ordnance Works in the north. After 53 seconds of its release, the bomb exploded at 11:02 a.m. at an approximate altitude of 1,800 feet. This was the second and, to date, the last use of nuclear weaponry in combat, and also the second detonation of a plutonium bomb. The first was tested in central New Mexico, USA.
Within less than a second after the detonation, the north of the city was destroyed. Roughly 39,000–80,000 people were killed. About half of these died immediately, while the other half suffered lingering deaths. Among the deaths were 6,200 out of the 7,500 employees of the Mitsubishi Munitions plant, and thousands of others (including 2,000 Koreans) who worked in other war plants and factories in the city, as well as 150 Japanese soldiers. The industrial damage in Nagasaki was high, partly owing to the inadvertent targeting of the industrial zone, leaving 68-80 percent of the non-dock industrial production destroyed. The bomb was somewhat more powerful than the "Little Boy" bomb dropped over Hiroshima, but because of Nagasaki's more uneven terrain, there was less damage.
After the war.
The city was rebuilt after the war, albeit dramatically changed. The pace of reconstruction was slow. The first simple emergency dwellings were not provided until 1946. The focus on redevelopment was the replacement of war industries with foreign trade, shipbuilding and fishing. This was formally declared when the Nagasaki International Culture City Reconstruction Law was passed in May 1949. New temples were built, as well as new churches owing to an increase in the presence of Christianity. Some of the rubble was left as a memorial, such as a one-legged "torii" at Sannō Shrine and an arch near ground zero. New structures were also raised as memorials, such as the Atomic Bomb Museum. Nagasaki remains first and foremost a port city, supporting a rich ship building industry and setting a strong example of perseverance and peace.
On January 4, 2005, the towns of Iōjima, Kōyagi, Nomozaki, Sanwa, Sotome and Takashima (all from Nishisonogi District) were merged into Nagasaki.
Geography and climate.
Nagasaki and Nishisonogi Peninsulas are located within the city limits. The city is surrounded by the cities of Isahaya and Saikai, and the towns of Togitsu and Nagayo in Nishisonogi District.
Nagasaki lies at the head of a long bay which forms the best natural harbor on the island of Kyūshū. The main commercial and residential area of the city lies on a small plain near the end of the bay. Two rivers divided by a mountain spur form the two main valleys in which the city lies. The heavily built-up area of the city is confined by the terrain to less than 4 sqmi.
Nagasaki has the typical humid subtropical climate of Kyūshū and Honshū, characterized by mild winters and long, hot, and humid summers. Apart from Kanazawa and Shizuoka it is the wettest sizeable city in Japan and indeed all of temperate Eurasia. In the summer, the combination of persistent heat and high humidity results in unpleasant conditions, with wet-bulb temperatures sometimes reaching 26 C. In the winter, however, Nagasaki is drier and sunnier than Gotō to the west, and temperatures are slightly milder than further inland in Kyūshū. Since records began in 1878 the wettest month has been July 1982 with 1178 mm including 555 mm in a single day, whilst the driest month has been September 1967 with 1.8 mm. Precipitation occurs year-round, though winter is the driest season; rainfall peaks sharply in June & July. August is the warmest month of the year.
Nagasaki in Western literature and music.
David Mitchell's 2010 novel "The Thousand Autumns of Jacob de Zoet" is set in the Dutch trading post at Dejima, Nagasaki at the turn of the 19th Century.
"Nagasaki" is the title and subject of a 1928 song with music by Harry Warren and lyrics by Mort Dixon.
Puccini’s opera "Madama Butterfly" takes place in Nagasaki.
"Nagasaki" is also the name of a 1987 guitar solo track by the Christian glam metal band Whitecross from their self-titled first album.
"Nagasaki Nightmare" is the title of a 1981 song by Crass.
Nagasaki in 1690 is the setting of Laura Joh Rowland's 1997 Sano Ichiro mystery novel "The Way of the Traitor".
Kazuo Ishiguro's "A Pale View of Hills" is partly set in post-war Nagasaki, where Ishiguro himself was born, before moving to England.
Transportation.
The nearest airport is Nagasaki Airport in the nearby city of Ōmura. The Kyushu Railway Company (JR Kyushu) provides rail transportation on the Nagasaki Main Line, whose terminal is at Nagasaki Station. In addition, the Nagasaki Electric Tramway operates five routes in the city. The Nagasaki Expressway serves vehicular traffic with interchanges at Nagasaki and Susukizuka. In addition, six national highways crisscross the city: Routes 34, 202, 251, 324, and 499.
Sports.
Nagasaki is represented in the J. League of football with its local club, V-Varen Nagasaki.
Main sights.
Panorama of Nagasaki
Events.
The Prince Takamatsu Cup Nishinippon Round-Kyūshū Ekiden, the world's longest relay race, begins in Nagasaki each November.
Kunchi, the most famous festival in Nagasaki, is held from 7–9 October.
The Nagasaki Lantern Festival, celebrating the Chinese New Year, is celebrated from February 18 to March 4.
Twin towns.
The city of Nagasaki maintains sister cities or friendship relations with other cities worldwide.
 Santos, Brazil, since 1972
 Vaux-sur-Aure, France, since 2005; sister city of Sotome since 1978

</doc>
<doc id="21791" url="http://en.wikipedia.org/wiki?curid=21791" title="Nanjing">
Nanjing

Nanjing ( ; ) is the capital of Jiangsu province in Eastern China. It has a prominent place in Chinese history and culture, having been the capital of China for several periods. Its present name means "Southern Capital" and was widely romanized as Nankin and Nanking until the pinyin language reform, after which Nanjing was gradually adopted as the standard spelling of the city's name in most languages that use the Roman alphabet.
Located in the lower Yangtze River drainage basin and Yangtze River Delta economic zone, Nanjing has long been one of China's most important cities. Having been the capital city of six different dynasties since 3 A.D., it is recognized as one of the Four Great Ancient Capitals of China. It was the capital of Wu during the Three Kingdoms Period, and the capital of the Republic of China prior to its flight to Taiwan during the Chinese Civil War. Nanjing is also one of the fifteen sub-provincial cities in the People's Republic of China's administrative structure, enjoying jurisdictional and economic autonomy only slightly less than that of a province. Nanjing has long been a national centre of education, research, transport networks and tourism. It was the host city of the 2014 Summer Youth Olympics.
With a total population of 8.16 million and a urban population of 6.55 million, Nanjing is the second-largest commercial centre in the East China region after Shanghai. It has been ranked seventh in the evaluation of "Cities with Strongest Comprehensive Strength" issued by the National Statistics Bureau, and second in the evaluation of cities with most sustainable development potential in the Yangtze River Delta. It has also been awarded the title of 2008 Habitat Scroll of Honour of China, Special UN Habitat Scroll of Honour Award and National Civilized City.
History.
Early history.
Nanjing was one of the earliest established cities in what is now China. According to legend, Fuchai, King of the State of Wu, founded a fort named Yecheng (冶城) in today's Nanjing area in 495 BCE. Later in 473 BCE, the State of Yue conquered Wu and constructed the fort of Yuecheng (越城) on the outskirts of the present-day Zhonghua Gate. In 333 BCE, after eliminating the State of Yue, the State of Chu built Jinling Yi (金陵邑) in the western part of present-day Nanjing. Under the Qin and Han dynasties, it was called Moling (秣陵). Since then, the city had experienced destruction and renewal many times.
Capital of the Six Dynasties.
Nanjing first became a capital in 229 CE, where Sun Quan of the Wu Kingdom during the Three Kingdoms Period relocated its capital to Jianye (建業), a city he extended on the basis of Jinling Yi in 211 CE. Although conquered by the Western Jin dynasty in 280, Nanjing and its neighbouring areas had been well cultivated and developed into one of the commercial, cultural and political centers of China during the rule of East Wu. This city would soon play a vital role in the following centuries.
Shortly after the unification of the region, the Western Jin dynasty collapsed. First the rebellions by eight Jin princes for the throne and later rebellions and invasion from Xiongnu and other nomadic peoples that destroyed the rule of Jin in the north. In 317, remnants of the Jin court, as well as nobles and wealthy families, fled from the north to the south and reestablished the Jin court in Nanjing, which was then called Jiankang (建康).
During the period of North–South division, Nanjing remained the capital of the Southern dynasties for more than two and a half centuries. During this time, Nanjing was the international hub of East Asia and one of the largest cities in the world. Based on historical documents, the city had 280,000 registered households. Assuming an average Nanjing household had about 5.1 people at that time, the city had more than 1.4 million residents.
A number of sculptural ensembles of that era, erected at the tombs of royals and other dignitaries, have survived (in various degrees of preservation) in Nanjing's northeastern and eastern suburbs, primarily in Qixia and Jiangning District. Possibly the best preserved of them is the ensemble of the Tomb of Xiao Xiu (475–518), a brother of Emperor Wu of Liang. The period of division ended when the Sui Dynasty reunified China and almost destroyed the entire city, turning it into a small town.
Sui.
The city of Nanjing was razed after the Sui took over it. It was reconstructed during the late Tang dynasty. It was chosen as the capital and called Jinling (金陵) during the Southern Tang (937–976), a state that succeeded the Wu. Jiankang's textile industry burgeoned and thrived during the Song dynasty despite the constant threat of foreign invasions from the north by the Jurchen Jin dynasty. Nanjing was the capital of Da Chu, a puppet state established by the Jurchens. Da Chu came to an end scarcely a month after its creation.
Yuan.
The Mongol Empire eventually occupied much of the territory that now constitutes China and further consolidated the city's status as a hub of the textile industry under what became known in China as the Yuan dynasty.
Ming Dynasty—capital.
The first emperor of the Ming dynasty Zhu Yuanzhang, the Hongwu Emperor, who overthrew the Yuan dynasty renamed the city Yingtian, rebuilt it, and made it the dynastic capital in 1368. He constructed a 48 km long city wall around Yingtian, as well as a new Ming Palace complex, and government halls. It took 200,000 laborers 21 years to finish the project. The present-day City Wall of Nanjing was mainly built during that time and today it remains in good condition and has been well preserved. It is among the longest surviving city walls in China. The Jianwen Emperor ruled from 1398 to 1402.
It is believed that Nanjing was the largest city in the world from 1358 to 1425 with a population of 487,000 in 1400. Nanjing remained the capital of the Ming Empire until 1421, when the third emperor of the Ming Dynasty, Zhu Di the Yongle Emperor, relocated the capital to Beijing.
Besides the city wall, other famous Ming-era structures in the city included the famous Ming Xiaoling Mausoleum and Porcelain Tower, although the latter was destroyed by the Taipings in the 19th century either in order to prevent a hostile faction from using it to observe and shell the city or from superstitious fear of its geomantic properties.
A monument to the huge human cost of some of the gigantic construction projects of the early Ming is the Yangshan Quarry (located some 15-20 km east of the walled city and Ming Xiaoling mausoleum), where a gigantic stele, cut on the orders of the Yongle Emperor, lies abandoned, just as it was left 600 years ago when it was understood it was impossible to move or complete it.
As the center of the empire, early-Ming Nanjing had worldwide connections. It was home of the admiral Zheng He, who went to sail the Pacific and Indian Oceans, and it was visited by foreign dignitaries, such as a king from Borneo (Boni 渤泥), who died during his visit to China in 1408. The Tomb of the King of Boni, with a spirit way and "a "tortoise stele, was discovered in Yuhuatai District (south of the walled city) in 1958, and has been restored."
Southern Ming Dynasty.
Over two centuries after the removal of the capital to Beijing, Nanjing was destined to become the capital of a Ming emperor one more time. After the fall of Beijing to the Li Zicheng's rebels and then to Manchu Qing invaders, and the suicide of the last legitimate Ming emperor Zhu Youjian (the Chongzhen Emperor) in the spring 1644, the Ming Zhu Yousong, Prince of Fu was enthroned in Nanjing in June 1644 as the Hongguang Emperor. His short reign was described by later historians as the first reign of the so-called Southern Ming dynasty.
Zhu Yousong, however, fared a lot worse than his ancestor Zhu Yuanzhang three centuries earlier. Beset by factional conflicts, his regime could not offer effective resistance to Manchu troops, when the Manchu army, led by Prince Dodo approached Jiangnan the next spring. Days after Yangzhou fell to the Manchus in late May 1645, the Hongguang Emperor fled Nanjing, and the imperial Ming Palace was looted by local residents. On June 6, Dodo's troops approached Nanjing, and the commander of the city's garrison, Zhao the Earl of Xincheng, promptly surrendered the city to them. The Manchus soon ordered all male residents of the city to shave their heads in the Manchu queue way. They requisitioned a large section of the city for the bannermen's cantonment, and destroyed the former imperial Ming Palace, but otherwise the city was spared the mass murders and destruction that befell Yangzhou.
Qing Dynasty.
Under the Qing dynasty (1644–1911), the Nanjing area was known as Jiangning (江寧) and served as the seat of government for the Liangjiang Viceroy. It had been visited by the Kangxi and Qianlong Emperors a number of times on their tours of the southern provinces. Nanjing was invaded by British troops during the close of the First Opium War, which was ended by the Treaty of Nanking in 1842. As the capital of the brief-lived Taiping Kingdom in the mid-19th century, Nanjing was known as Tianjing (天京, "Heavenly Capital" or "Capital of Heaven"). 
Both the Qing Viceroy and the Taiping king resided in buildings that would later be known as the Presidential Palace. When the Qing under Zeng Guofan retook the city in 1864, a massive slaughter occurred in the city with over 100,000 estimated to have committed suicide or fought to the death. Since the rebellion began, Imperial forces allowed no rebels speaking its dialect to surrender. This policy of mass murder of civilians occurred in Nanjing.
Capital of the Republic.
The Xinhai Revolution led to the founding of the Republic of China in January 1912 with Dr. Sun Yat-sen as the first provisional president and Nanking was selected as its new capital. However, the Qing Empire controlled large regions to the North, so revolutionaries asked Yuan Shikai to replace Sun as president in exchange for the last-Qing Emperor's abdication. Yuan demanded the capital be Beijing (closer to his power base).
In 1927, the Kuomintang (KMT) under Generalissimo Chiang Kai-shek again established Nanking as the capital of the Republic of China, and this became internationally recognized once KMT forces took Beijing in 1928. The following decade is known as the Nanking decade.
In 1937, Japan started a full-scale invasion of China after invading Manchuria in 1931, beginning the Second Sino-Japanese War (often considered a theatre of World War II). Their troops occupied Nanjing in December and carried out the systematic and brutal Nanking massacre (the "Rape of Nanking"). Even children, the elderly, and nuns are reported to have suffered at the hands of the Imperial Japanese army. The total death toll, including estimates made by the International Military Tribunal for the Far East and the Nanjing War Crimes Tribunal, was between 300,000 and 350,000. The city itself was also severely damaged during the massacre. The Nanjing Massacre Memorial Hall was built in 1985 to commemorate this event.
A few days before the fall of the city, the National Government of China was relocated to the southwestern city Chungking (now Chongqing) and resumed Chinese resistance. In 1940, a Japanese-collaborationist government known as the "Nanjing Regime" or "Reorganized National Government of China" led by Wang Jingwei was established in Nanjing as a rival to Chiang Kai-Shek's government in Chongqing. In 1946, after the Surrender of Japan, the KMT relocated its central government back to Nanjing.
People's Republic of China.
On 21 April, Communist forces crossed the Yangtze River. On April 23, 1949, the People's Liberation Army captured Nanjing. The KMT government retreated to Canton (Guangzhou) until October 15, Chongqing until November 25, and then Chengdu before retreating to Taiwan on December 10. By late 1949, the People's Liberation Army was pursuing remnants of KMT forces southwards in southern China, and only Tibet was left. After the establishment of the People's Republic of China in October 1949, Nanjing was initially a province-level municipality, but it soon became the provincial capital of Jiangsu, and retains that status to this day.
Geography.
Nanjing, with a total land area of 6598 km2, is situated in one of the largest economic zones of China, the Yangtze River Delta, which is part of the downstream Yangtze River drainage basin. The Yangtze River flows past the west side of Nanjing City, while the Ningzheng Ridge surrounds the north, east and south side of the city. The city is 300 km west-northwest of Shanghai, 1200 km south-southeast of Beijing, and 1400 km east-northeast of Chongqing.
Nanjing borders Yangzhou to the northeast, one town downstream when following the north bank of the Yangtze, Zhenjiang to the east, one town downstream when following the south bank of the Yangtze, and Changzhou to the southeast. On its western boundary is Anhui province, where Nanjing borders five prefecture-level cities.
Nanjing is the intersection of Yangtze River—an east-west water transport artery and Nanjing–Beijing railway—a south-north land transport artery, hence the name “door of the east and west, throat of the south and north”. Furthermore, the west part of the Ningzhen range is in Nanjing; the Loong-like Zhong Mountain is curling in the east of the city; the tiger-like Stone Mountain is crouching in the west of the city, hence the name “the Zhong Mountain, a dragon curling, and the Stone Mountain, a tiger crouching”. Mr. Sun Yet-sen spoke highly of Nanjing in the “Constructive Scheme for Our Country”, “The position of Nanjing is wonderful since mountains, lakes and plains all integrated in it. It is hardly ["sic"] to find another city like this.”
Climate and environment.
Nanjing has a humid subtropical climate (Köppen "Cfa") and is under the influence of the East Asian monsoon. The four seasons are distinct here, with damp conditions seen throughout the year, very hot and muggy summers, cold, damp winters, and in between, spring and autumn are of reasonable length. Along with Chongqing and Wuhan, Nanjing is traditionally referred to as one of the "Three Furnacelike Cities" along the Yangtze River (长江流域三大火炉) for the perennially high temperatures in the summertime. However, the time from mid-June to the end of July is the plum blossom blooming season in which the "meiyu" (rainy season of East Asia; literally "plum rain") occurs, during which the city experiences a period of mild rain as well as dampness. Typhoons are uncommon but possible in the late stages of summer and early part of autumn. The annual mean temperature is around 15.46 °C, with the monthly 24-hour average temperature ranging from 2.4 °C in January to 27.8 °C in July. The highest recorded temperature is 40.7 °C, and the lowest −16.9 °C. On average precipitation falls 115 days out of the year, and the average annual rainfall is 1062 mm. With monthly percent possible sunshine ranging from 37 percent in March to 52 percent in August, the city receives 1,983 hours of bright sunshine annually.
Nanjing is endowed with rich natural resources, which include more than 40 kinds of minerals. Among them, iron and sulfur reserves make up 40 percent of those of Jiangsu province. Its reserves of strontium rank first in East Asia and the South East Asia region. Nanjing also possesses abundant water resources, both from the Yangtze River and groundwater. In addition, it has several natural hot springs such as Tangshan Hot Spring in Jiangning and Tangquan Hot Spring in Pukou.
Surrounded by the Yangtze River and mountains, Nanjing also enjoys beautiful natural scenery. Natural lakes such as Xuanwu Lake and Mochou Lake are located in the centre of the city and are easily accessible to the public, while hills like Purple Mountain are covered with evergreens and oaks and host various historical and cultural sites. Sun Quan relocated his capital to Nanjing after Liu Bei's suggestion as Liu Bei was impressed by Nanjing's impeccable geographic position when negotiating an alliance with Sun Quan. Sun Quan then renamed the city from Moling (秣陵) to Jianye (建鄴) shortly thereafter.
Cityscape.
Nanjing skyline, taken in 2012.
Environmental issues.
Air pollution in 2013.
A dense wave of smog began in the Central and Eastern part of China on 2 December 2013 across a distance of around 1200 km, including Tianjin, Hebei, Shandong, Jiangsu, Anhui, Shanghai and Zhejiang. A lack of cold air flow, combined with slow-moving air masses carrying industrial emissions, collected airborne pollutants to form a thick layer of smog over the region. The heavy smog heavily polluted central and southern Jiangsu Province, especially in and around Nanjing, with its AQI pollution Index at "severely polluted" for five straight days and "heavily polluted" for nine. On 3 December 2013, levels of PM2.5 particulate matter average over 943 micrograms per cubic metre, falling to over 338 micrograms per cubic metre on 4 December 2013. Between 3:00 pm, 3 December and 2:00pm, 4 December local time, several expressways from Nanjing to other Jiangsu cities were closed, stranding dozens of passenger buses in Zhongyangmen bus station. From 5 to 6 December, Nanjing issued a red alert for air pollution and closed down all kindergarten through middle schools. Children's Hospital outpatient services increased by 33 percent; general incidence of bronchitis, pneumonia, upper respiratory tract infections significantly increased. The smog dissipated 12 December. Officials blamed the dense pollution on lack of wind, automobile exhaust emissions under low air pressure, and coal-powered district heating system in North China region. Prevailing winds blew low-hanging air masses of factory emissions (mostly SO2) towards China's east coast.
Government.
The full name of the government of Nanjing is "People's Government of Nanjing City". The city is under the one-party rule of the CPC, with the CPC Nanjing Committee Secretary as the "de facto" governor of the city and the mayor as the executive head of the government working under the secretary.
Administrative divisions.
The sub-provincial city of Nanjing is divided into 11 districts.
Demographics.
According to the "Sixth China Census", the total population of the City of Nanjing reached 8.005 million in 2010. The statistics in 2011 estimated the total population to be 8.11 million. The birth rate was 8.86 percent and the death rate was 6.88 percent. The urban area had a population of 6.47 million people. The sex ratio of the city population was 107.31 males to 100 females.
As in most of eastern China the ethnic makeup of Nanjing is predominantly Han nationality (98.56 percent), with 50 other minority nationalities. In 1999, 77,394 residents belonged to minority nationalities, among which the vast majority (64,832) were Hui nationalities, contributing 83.76 percent to the minority population. The second and third largest minority groups were Manchu (2,311) and Zhuang (533) nationalities. Most of the minority nationalities resided in Jianye District, comprising 9.13 percent of the district's population.
Economy.
Earlier development.
Since the Three Kingdoms period, Nanjing has been an industrial centre for textiles and minting owing to its strategic geographical location and convenient transportation. During the Ming dynasty, Nanjing's industry was further expanded, and the city became one of the most prosperous cities in China and the world. It led in textiles, minting, printing, shipbuilding and many other industries, and was the busiest business center in the Far East.
Into the first half of the twentieth century, Nanjing gradually shifted from being a production hub towards being a heavy consumption city, mainly because of the rapid expansion of its wealthy population after Nanjing once again regained the political spotlight of China. A number of huge department stores such as Zhongyang Shangchang sprouted up, attracting merchants from all over China to sell their products in Nanjing. In 1933, the revenue generated by the food and entertainment industry in the city exceeded the sum of the output of the manufacturing and agriculture industry. One third of the city population worked in the service industry, while prostitution, drugs and gambling also thrived.
In the 1950s, the CPC invested heavily in Nanjing to build a series of state-owned heavy industries, as part of the national plan of rapid industrialization. Electrical, mechanical, chemical and steel factories were established successively, converting Nanjing into a heavy industry production centre of East China. Overenthusiastic in building a “world-class” industrial city, leaders of Nanjing also made many disastrous mistakes during development, such as spending hundreds of millions of yuan to mine for non-existent coal, resulting in negative economic growth in the late 1960s.
Today.
The current industry of the city basically inherited the characteristics of the 1960s, with electronics, cars, petrochemical, iron and steel, and power as the "Five Pillar Industries". Some representative big state-owned firms are Panda Electronics, Jincheng Motors and Nanjing Steel. The tertiary industry also regained prominence, accounting for 44 percent of the GDP of the city. The city is also vying for foreign investment against neighboring cities in the Yangtze River Delta, and so far a number of famous multinational firms, such as Volkswagen Group, Iveco, A.O. Smith, and Sharp, have established their lines there. Since China's entry into the WTO, Nanjing has received increasing attention from foreign investors, and on average two new foreign firms establish offices in the city every day.
The city government is further improving the desirability of the city to investors by building large industrial parks, which now total four: Gaoxin, Xingang, Huagong and Jiangning. Despite the effort, Nanjing's Gross Domestic Product is still falling behind that of other neighbouring cities such as Suzhou, Wuxi and Hangzhou, which have an edge in attracting foreign investment and local innovation. In addition, the traditional state-owned enterprises find themselves incapable of competing with efficient multinational firms, and hence are either mired in heavy debt or forced into bankruptcy or privatization. This has resulted in large numbers of layoff workers who are technically not unemployed but effectively jobless.
In recent years, Nanjing has been developing its economy, commerce, industry, as well as city construction. In 2013 the city's GDP was RMB 801 billion (3rd in Jiangsu), and GDP per capita(current price) was RMB 98,174(US$16041), a 11 percent increase from 2012. The average urban resident's disposable income was RMB 36,200, while the average rural resident's net income was RMB 14,513. The registered urban unemployment rate was 3.02 percent, lower than the national average (4.3 percent). Nanjing's Gross Domestic Product ranked 12th in 2013 in China, and its overall competence ranked 6th in mainland and 8th including Taiwan and Hong Kong in 2009.
A panoramic view of Nanjing in 2005
Industrial zones.
Nanjing Baixia Hi-Tech Industrial Zone is a national hi-tech industrial zone with 16.5 km2 planned area. The zone is only 13.5 km away from Nanjing downtown and 50 km away from Nanjing Lukou Airport. Several expressways pass through here. It is well equipped with comprehensive facilities, and it provides a good investment environment for high-tech industries. Electronic industry, automobile, chemical, machinery, instruments and building materials are the encouraged industries in the zone.
Established in 1992, Nanjing Economic and Technological Development Zone is a national level zone surrounded by convenient transportation network. It is only 20 km away from Nanjing Port and 40 km away from Nanjing Lukou Airport. It is well equipped with basic facilities like electricity, water, communication, gas, steam and so on. It has formed four specialized industries, which are electronic information, bio-pharmaceutical, machinery and new materials industry.
On March 10, 2003 the State Council approved the establishment of this Export Processing Zone (EPZ) in Nanjing's Southern District. This EPZ is free from import/export duty area and provides 24-hour customs-bonded conditions. It has a planned area of 3 km2. The Central Government has given the special economic region preferential policies to attract more enterprises engaged in processing trade investment in the region. It is only 20 km from Nanjing Port and several expressways pass through here.
Nanjing New and High-Tech Industry Development Zone was jointly founded by Jiangsu Provincial People's Government and Nanjing Municipal People's Government, and started to break ground of construction on September 1, 1988. It was established as a national new and high-tech industry development zone by the State Council on March 6, 1991. The zone is next to National Highway 104 and 312. Its pillar industries include electronic information, bio-engineering and pharmaceutical industry.
Transportation.
Nanjing is the transportation hub in eastern China and the downstream Yangtze River area. Different means of transportation constitute a three-dimensional transport system that includes land, water and air. As in most other Chinese cities, public transportation is the dominant mode of travel of the majority of the citizens. As of October 2014, Nanjing had five bridges and two tunnels over the Yangtze River, which are tying districts north of the river with the city centre on the south bank.
Rail.
Nanjing is an important railway hub in eastern China. It serves as rail junction for the Beijing-Shanghai (Jinghu) (which is itself composed of the old Jinpu and Huning Railways), Nanjing–Tongling Railway (Ningtong), Nanjing–Qidong (Ningqi), and the Nanjing-Xian (Ningxi) which encompasses the Hefei–Nanjing Railway.
Nanjing is connected to the national high-speed railway network by Beijing–Shanghai High-Speed Railway and Shanghai–Wuhan–Chengdu Passenger Dedicated Line, with several more high-speed rail lines under construction.
Among all 17 railway stations in Nanjing, passenger rail service is mainly provided by Nanjing Railway Station and Nanjing South Railway Station, while other stations like Nanjing West Railway Station, Zhonghuamen Railway Station and Xianlin Railway Station serve minor roles. Nanjing Railway Station was first built in 1968. In 1999, On November 12, 1999, the station was burnt in a serious fire. Reconstruction of the station was finished on September 1, 2005. Nanjing South Railway Station, which is one of the 5 hub stations on Beijing–Shanghai High-Speed Railway, has officially been claimed as the largest railway station in Asia and the second largest in the world in terms of GFA (Gross Floor Area). Construction of Nanjing South Station began on 10 January 2008. The station was opened for public service in 2011.
Road.
As an important regional hub in the Yangtze River Delta, Nanjing is well-connected by over 60 state and provincial highways to all parts of China.
Express highways such as Hu–Ning, Ning–He, Ning–Hang enable commuters to travel to Shanghai, Hefei, Hangzhou, and other important cities quickly and conveniently. Inside the city of Nanjing, there are 230 km of highways, with a highway coverage density of 3.38 kilometres per hundred square kilometrs (5.44 mi/100 sq mi). The total road coverage density of the city is 112.56 kilometres per hundred square kilometres (181.15 mi/100 sq mi). The two artery roads in Nanjing are Zhongshan Road and Hanzhong. The two roads cross in the city centre, Xinjiekou.
Expressways:
National Highway (GXXX):
Public transportation.
The city also boasts an efficient network of public transportation, which mainly consists of bus, taxi and metro systems. The bus network, which is currently run by 3 companies since 2011, provides more than 370 routes covering all parts of the city and suburban areas. Nanjing Metro Line 1, started service on September 3, 2005, with 16 stations and a length of 21.72 km. Line 2 and the 24.5 km-long south extension of Line 1 officially opened to passenger service on May 28, 2010. The city is planning to complete a 17-line Metro and light-rail system by 2030. The expansion of the Metro network will greatly facilitate the intracity transportation and reduce the currently heavy traffic congestion.
Air.
Nanjing's airport, Lukou International Airport, serves both national and international flights. In 2013, Nanjing airport handled 15,011,792 passengers and 255,788.6 tonnes of freight. The airport currently has 85 routes to national and international destinations, which include Japan, Korea, Thailand, Malaysia, Singapore and Germany. The airport is connected by a 29-kilometre (18 mi) highway directly to the city center, and is also linked to various intercity highways, making it accessible to the passengers from the surrounding cities. A railway Ninggao Intercity Line is being built to link the airport with Nanjing South Railway Station. Lukou Airport was opened on 28 June 1997, replacing Nanjing Dajiaochang Airport as the main airport serving Nanjing. Dajiaochang Airport is still used as a military air base.
Water.
Port of Nanjing is the largest inland port in China, with annual cargo tonnage reached 191,970,000 t in 2012. The port area is 98 km in length and has 64 berths including 16 berths for ships with a tonnage of more than 10,000. Nanjing is also the biggest container port along the Yangtze River; in March 2004, the one million container-capacity base, Longtan Containers Port Area opened, further consolidating Nanjing as the leading port in the region. As of 2010, it operated six public ports and three industrial ports.
Yangtze River crossings.
In the 1960s, the first Nanjing Yangtze River Bridge was completed, and served as the only bridge crossing over the Lower Yangtze in eastern China at that time. The bridge was a source of pride and an important symbol of modern China, having been built and designed by the Chinese themselves following failed surveys by other nations and the reliance on and then rejection of Soviet expertise. Begun in 1960 and opened to traffic in 1968, the bridge is a two-tiered road and rail design spanning 4,600 metres on the upper deck, with approximately 1,580 metres spanning the river itself. Since then four more bridges and two tunnels have been built. Going in the downstream direction, the Yangtze crossings in Nanjing are: Dashengguan Bridge, Line 10 Metro Tunnel, Third Bridge, Nanjing Yangtze River Tunnel, First Bridge, Second Bridge and Fourth Bridge.
Culture and art.
Being one of the four ancient capitals of China, Nanjing has always been a cultural centre attracting intellectuals from all over the country. In the Tang and Song dynasties, Nanjing was a place where poets gathered and composed poems reminiscent of its luxurious past; during the Ming and Qing dynasties, the city was the official imperial examination centre (Jiangnan Examination Hall) for the Jiangnan region, again acting as a hub where different thoughts and opinions converged and thrived.
Today, with a long cultural tradition and strong support from local educational institutions, Nanjing is commonly viewed as a “city of culture” and one of the more pleasant cities to live in China.
Art.
Some of the leading art groups of China are based in Nanjing; they include the Qianxian Dance Company, Nanjing Dance Company, Jiangsu Peking Opera Institute and Nanjing Xiaohonghua Art Company among others.
Jiangsu Province Kun Opera is one of the best theatres for Kunqu, China's oldest stage art.
It is considered a conservative and traditional troupe. Nanjing also has professional opera troupes for the Yang, Yue (shaoxing), Xi and Jing (Chinese opera varieties) as well as Suzhou pingtan, spoken theatre and puppet theatre.
Jiangsu Art Gallery is the largest gallery in Jiangsu Province, presenting some of the best traditional and contemporary art pieces of China; many other smaller-scale galleries, such as Red Chamber Art Garden and Jinling Stone Gallery, also have their own special exhibitions.
Festivals.
Many traditional festivals and customs were observed in the old times, which included climbing the City Wall on January 16, bathing in Qing Xi on March 3, hill hiking on September 9 and others (the dates are in Chinese lunar calendar). Almost none of them, however, are still celebrated by modern Nanjingese.
Instead, Nanjing, as a popular tourist destination, hosts a series of government-organised events throughout the year. The annual International Plum Blossom Festival held in Plum Blossom Hill, the largest plum collection in China, attracts thousands of tourists both domestically and internationally. Other events include Nanjing Baima Peach Blossom and Kite Festival, Jiangxin Zhou Fruit Festival and Linggu Temple Sweet Osmanthus Festival.
Libraries.
Nanjing Library, founded in 1907, houses more than 7 million volumes of printed materials and is the third largest library in China, after the National Library in Beijing and Shanghai Library. Other libraries, such as city-owned Jinling Library and various district libraries, also provide considerable amount of information to citizens. Nanjing University Library, owned by Nanjing University, with a collection of 4.2 million volumes, is the second largest university libraries in China after Peking University Library. More than 100 multimedia networked-computers are available to readers.
Museums.
Nanjing has some of the oldest and finest museums in China. Nanjing Museum, formerly known as National Central Museum under KMT rule, is the first modern museum and remains as one of the leading museums in China having 400,000 items in its permanent collection. The museum is notable for enormous collections of Ming and Qing imperial porcelain, which is among the largest in the world.
Other museums include the China Modern History Museum in the Presidential Palace, the Nanjing Massacre Memorial Hall, the City Museum of Nanjing, the Taiping Kingdom History Museum, the Nanjing Customs Museum, the Nanjing City Wall Cultural Museum, and a small museum and tomb honoring the 15th century seafaring admiral Zheng He although his body was buried at sea off the Malabar Coast near Calicut in western India.
Theatre.
Most of Nanjing's major theatres are multi-purpose, used as convention halls, cinemas, musical halls and theatres on different occasions. The major theatres include the People's Convention Hall and the Nanjing Arts and Culture Center.
Night life.
Traditionally Nanjing's nightlife was mostly centered around Nanjing Fuzimiao (Confucius Temple) area along the Qinhuai River, where night markets, restaurants and pubs thrived. Boating at night in the river was a main attraction of the city. Thus, one can see the statues of the famous teachers and educators of the past not too far from those of the courtesans who educated the young men in the other arts.
In the past 20 years, several commercial streets have been developed, hence the nightlife has become more diverse: there are shopping malls opening late in the Xinjiekou CBD and Hunan Road. The well-established "Nanjing 1912" district hosts a wide variety of pastime facilities ranging from traditional restaurants and western pubs to dance clubs. There are two major areas where bars are densely located; one is in 1912 block; the other is along Shanghai road and its neighbourhood. Both are popular with international residents of the city.
These days, the most comprehensive source of nightlife information (in English) can be found on and .
Local people still very much enjoy street food, such as Turkish Kebab. As elsewhere in Asia, Karaoke is popular with both young and old crowds.
Food and symbolism.
Many of the city's local favorite dishes are based on ducks, including nanjing salted duck, duck blood and vermicelli soup, and duck oil pancake.
The radish is also a typical food representing people of Nanjing, which has been spread through word of mouth as an interesting fact for many years in China. According to Nanjing.GOV.cn, "There is a long history of growing radish in Nanjing especially the southern suburb. In the spring, the radish tastes very juicy and sweet. It is well-known that people in Nanjing like eating radish. And the people are even addressed as 'Nanjing big radish', which means they are unsophisticated, passionate and conservative. From health perspective, eating radish can help to offset the stodgy food that people take during the Spring Festival".
Sports and stadiums.
As a major Chinese city, Nanjing is home to many professional sports teams. Jiangsu Sainty, the football club currently staying in Chinese Super League, is a long-term tenant of Nanjing Olympic Sports Center. Jiangsu Nangang Basketball Club is a competitive team which has long been one of the major clubs fighting for the title in China top level league, CBA. Jiangsu Volleyball men and women teams are also traditionally considered as at top level in China volleyball league.
There are two major sports centers in Nanjing, Wutaishan Sports Center and Nanjing Olympic Sports Center. Both of these two are comprehensive sports centers, including stadium, gymnasium, natatorium, tennis court, etc. Wutaishan Sports Center was established in 1952 and it was one of the oldest and most advanced stadiums in early time of People's Republic of China.
Nanjing hosted the 10th National Games of P.R.C. in 2005 and hosted the 2nd summer Youth Olympic Games in 2014.
In 2005, in order to host The 10th National Game of People's Republic of China, there was a new stadium, Nanjing Olympic Sports Center, constructed in Nanjing. Compared to Wutaishan Sports Center, which the major stadium's capacity is 18,500, Nanjing Olympic Sports Center has a more advanced stadium which is big enough to seat 60,000 spectators. Its gymnasium has capacity of 13,000, and natatorium of capacity 3,000.
On 10 February 2010, the 122nd IOC session at Vancouver announced Nanjing as the host city for the 2nd Summer Youth Olympic Games.The slogan of the is “Share the Games, Share our Dreams”. The Nanjing 2014 Youth Olympic Games featured all 28 sports on the Olympic programme and held from 16 to 28 August. The Nanjing Youth Olympic Games Organising Committee (NYOGOC) worked together with the International Olympic Committee (IOC) to attract the best young athletes from around the world to compete at the highest level. Off the competition fields, an integrated culture and education programme focused on discussions about education, Olympic values, social challenges, and cultural diversity. The YOG aims to spread the Olympic spirit and encourage sports participation.
Tourism.
Nanjing is one of the most beautiful cities of mainland China with lush green parks, natural scenic lakes, small mountains, historical buildings and monuments, relics and much more, which attracts thousands of tourists every year.
Buildings and monuments.
Republic of China period.
Because it was designated as the national capital, many structures were built around that time. Even today, some of them still remain which are open to tourists.
Education.
Nanjing has been the educational centre in southern China for more than 1700 years. Currently, it boasts of some of the most prominent educational institutions in the region, which are listed as follows:
National universities and colleges.
Operated by Ministry of Education
Operated by Ministry of Industry and Information Technology
Operated by the joint Commission of the State Forest Administration and Public Order Ministry
Operated by the general sport Administration

</doc>
<doc id="21793" url="http://en.wikipedia.org/wiki?curid=21793" title="Ninth Fort">
Ninth Fort

The Ninth Fort (Lithuanian: "Devintas Fortas") is a stronghold in the northern part of Šilainiai elderate, Kaunas, Lithuania. It is a part of the Kaunas Fortress, which was constructed in the late 19th century. During the occupation of Kaunas and the rest of Lithuania by the Soviet Union, the fort was used as a prison and way-station for prisoners being transported to labour camps. After the occupation of Lithuania by Nazi Germany, the fort was used as a place of execution for Jews, captured Soviets, and others.
History.
At the end of the 19th century the city of Kaunas was fortified and by 1890 was encircled by eight forts and nine gun batteries. Construction of the Ninth Fort (its numerical designation having become its name) began in 1902 and was completed on the eve of World War I. From 1924 on, the Ninth Fort was used as the Kaunas City prison.
During the years of Soviet occupation, 1940-1941, the Ninth Fort was used by the NKVD to house political prisoners pending transfer to Gulag forced labor camps.
During the years of Nazi occupation, the Ninth Fort was put to use as a place of mass murder. At least 10,000 Jews, most from Kaunas and largely taken from the Kovno Ghetto, were transported to the Ninth Fort and killed by Nazis with the collaboration of some Lithuanians in what became known as the Kaunas massacre.
Notable among the victims was Rabbi Elchonon Wasserman of Baranovitch. In addition, Jews from as far as France, Austria and Germany were brought to Kaunas during the course of Nazi occupation and executed in the Ninth Fort. In 1943, the Germans operated special Jewish squads to dig mass graves and burn the remaining corpses. One squad of 62 people managed to escape the fortress on the eve of 1944. That year, as the Soviets moved in, the Germans liquidated the ghetto and what had by then come to be known as the "Fort of Death". The prisoners were dispersed to other camps. After World War II, the Soviets again used the Ninth Fort as a prison for several years. From 1948 to 1958, farm organizations were managed from the Ninth Fort.
In 1958, a museum was established in the Ninth Fort. In 1959, an exhibition was prepared in four cells, telling of the Nazi war crimes carried out in Lithuania. In 1960, the discovery, cataloguing, and forensic investigation of local mass murder sites began in an effort to gain knowledge regarding the scope of these crimes.
Museum.
The Ninth Fort museum contains collections of historical artifacts related both to Soviet atrocities and the Nazi genocide, as well as materials related to the earlier history of Kaunas and Ninth Fort. Most exhibits are labelled in English.
The memorial to the victims of Nazism at the Ninth Fort in Kaunas, Lithuania, was designed by sculptor A. Ambraziunas. Erected in 1984, the monument is 105 feet (32 m) high. The mass burial place of the victims of the massacres carried out in the fort is a grass field, marked by a simple yet frankly worded memorial written in several languages. It reads, "This is the place where Nazis and their assistants killed more than 30,000 Jews from Lithuania and other European countries."
On April 11, 2011, the memorial to the victims of Nazism was vandalized — the memorial tombstones were knocked down, and white swastikas were spray-painted on the memorial. On the adjacent sidewalk, the words “Juden raus” (German: Jews Out) were inscribed.

</doc>
<doc id="21794" url="http://en.wikipedia.org/wiki?curid=21794" title="Nostratic languages">
Nostratic languages

Nostratic is a macrofamily, or hypothetical large-scale language family, that includes many of the indigenous language families of Eurasia, although its exact composition and structure vary among proponents. In its more restricted, current form, it includes the Indo-European, Uralic, Altaic and Kartvelian languages. Often also included are the Afroasiatic languages native to North Africa, the Horn of Africa, the Arabian Peninsula and the Near East, and the Dravidian languages of the Indian Subcontinent (sometimes extended to Elamo-Dravidian, connecting India and the Iranian Plateau). 
The hypothetical ancestral language of the Nostratic family is called Proto-Nostratic. Proto-Nostratic would have been spoken between 15,000 and 12,000 BCE, in the Epipaleolithic period, close to the end of the last glacial period.
The Nostratic hypothesis originates with Holger Pedersen in the early 20th century. The name "Nostratic" is due to Pedersen (1903), derived from the Latin "nostrates" "fellow countrymen". The hypothesis was significantly expanded in the 1960s by Soviet linguists, notably Vladislav Illich-Svitych and Aharon Dolgopolsky, termed the "Moscovite school" by Bomhard (2008, 2011, and 2014), and it has received renewed attention in English-speaking academia since the 1990s.
The hypothesis is controversial and has varying degrees of acceptance amongst linguists worldwide. In Russia, it is endorsed by a minority of linguists, such as Vladimir Dybo, but is not a generally accepted hypothesis. Allan Bomhard is a supporter, Lyle Campbell a critic. Some linguists take an agnostic view. Eurasiatic, a similar but not identical grouping, was proposed by Joseph Greenberg (2000) and endorsed by Merritt Ruhlen: it is taken as a subfamily of Nostratic by Bomhard (2008).
History of research.
Origin of the Nostratic hypothesis.
The last quarter of the 19th century saw various linguists putting forward proposals linking the Indo-European languages to other language families, such as Finno-Ugric and Altaic.
These proposals were taken much further in 1903 when Holger Pedersen proposed "Nostratic", a common ancestor for the Indo-European, Finno-Ugric, Samoyed, Turkish, Mongolian, Manchu, Yukaghir, Eskimo, Semitic, and Hamitic languages, with the door left open to the eventual inclusion of others.
The name "Nostratic" derives from the Latin word "nostrās", meaning 'our fellow-countryman' (plural: "nostrates") and has been defined, since Pedersen, as consisting of those language families that are related to Indo-European. Merritt Ruhlen notes that this definition is not properly taxonomic but amorphous, since there are broader and narrower degrees of relatedness, and moreover, some linguists who broadly accept the concept (such as Greenberg and Ruhlen himself) have criticised the name as reflecting the ethnocentrism frequent among Europeans at the time. Martin Bernal has described the term as distasteful because it implies that speakers of other language families are excluded from academic discussion. Even so, the concept arguably transcends ethnocentric associations. (Indeed, Pedersen's older contemporary Henry Sweet attributed some of the resistance by Indo-European specialists to hypotheses of wider genetic relationships as "prejudice against dethroning [Indo-European] from its proud isolation and affiliating it to the languages of yellow races".) Proposed alternative names such as "Mitian", formed from the characteristic Nostratic first- and second-person pronouns "mi" 'I' and "ti" 'you' (exactly 'thou'), have not attained the same currency.
An early supporter was the French linguist Albert Cuny—better known for his role in the development of the laryngeal theory—who published his "Recherches sur le vocalisme, le consonantisme et la formation des racines en « nostratique », ancêtre de l'indo-européen et du chamito-sémitique" ('Researches on the Vocalism, Consonantism, and Formation of Roots in "Nostratic", Ancestor of Indo-European and Hamito-Semitic') in 1943. Although Cuny enjoyed a high reputation as a linguist, the work was coldly received.
Muscovite school.
While Pedersen's Nostratic hypothesis did not make much headway in the West, it became quite popular in what was then the Soviet Union. Working independently at first, Vladislav Illich-Svitych and Aharon Dolgopolsky elaborated the first version of the contemporary form of the hypothesis during the 1960s. They expanded it to include additional language families. Illich-Svitych also prepared the first dictionary of the hypothetical language.
A principal source for the items in Illich-Svitych’s dictionary was the earlier work of Alfredo Trombetti (1866–1929), an Italian linguist who had developed a classification scheme for all the world’s languages, widely reviled at the time and subsequently ignored by almost all linguists. In Trombetti’s time, a widely held view on classifying languages was that similarity in inflections is the surest proof of genetic relationship. In the interim, the view had taken hold that the comparative method—previously used as a means of studying languages already known to be related and without any thought of classification—is the most effective means to establish genetic relationship, eventually hardening into the conviction that it is the only legitimate means to do so. This view was basic to the outlook of the new Nostraticists. Although Illich-Svitych adopted many of Trombetti’s etymologies, he sought to validate them by a systematic comparison of the sound systems of the languages concerned.
21st century.
The chief events in Nostratic studies in 2008 were the posting online of the latest version of Dolgopolsky's "Nostratic Dictionary" and the publication of Allan Bomhard's comprehensive treatment of the subject, "Reconstructing Proto-Nostratic", in 2 volumes. 2008 also saw the opening of a website, "Nostratica", devoted to providing important texts in Nostratic studies online, which is now offline. Also significant was Bomhard's partly critical review of Dolgopolsky's dictionary, in which he argued that only those Nostratic etymologies that are strongest should be included, in contrast to Dolgopolsky's more expansive approach, which includes many etymologies that are possible but not secure.
In early 2014, Allan Bomhard published his latest monograph on Nostratic, "A Comprehensive Introduction to Nostratic Comparative Linguistics".
Constituent language families.
The language families proposed for inclusion in Nostratic vary, but all Nostraticists agree on a common core of language families, with differences of opinion appearing over the inclusion of additional families.
The three groups universally accepted among Nostraticists are Indo-European, Uralic, and Altaic; the validity of the Altaic family, while itself controversial, is taken for granted by Nostraticists. Nearly all also include the Dravidian and Kartvelian language families.
Following Pedersen, Illich-Svitych, and Dolgopolsky, most advocates of the theory have included Afroasiatic, though criticisms by Joseph Greenberg and others from the late 1980s onward suggested a reassessment of this position.
A fairly representative grouping, arranged in rough geographical order (and probable order of phylogenetic branching, following Starostin), would include:
The Sumerian and Etruscan languages, usually regarded as language isolates, are thought by some to be Nostratic languages as well. Others, however, consider one or both to be members of another macrofamily called Dené–Caucasian. Another notional isolate, the Elamite language, also figures in a number of Nostratic classifications. It is frequently grouped with Dravidian as Elamo-Dravidian.
In 1987 Joseph Greenberg proposed a similar macrofamily which he called Eurasiatic. It included the same "Euraltaic" core (Indo-European, Uralic, and Altaic), but excluded some of the above-listed families, most notably Afroasiatic. At about this time Russian Nostraticists, notably Sergei Starostin, constructed a revised version of Nostratic which was slightly broader than Greenberg's grouping but which similarly left out Afroasiatic.
Recently, a consensus has been emerging among proponents of the Nostratic hypothesis. Greenberg basically agreed with the Nostratic concept, though he stressed a deep internal division between its northern 'tier' (his Eurasiatic) and a southern 'tier' (principally Afroasiatic and Dravidian).The American Nostraticist Allan Bomhard considers Eurasiatic a branch of Nostratic alongside other branches: Afroasiatic, Elamo-Dravidian, and Kartvelian. Similarly, Georgiy Starostin (2002) arrives at a tripartite overall grouping: he considers Afroasiatic, Nostratic and Elamite to be roughly equidistant and more closely related to each other than to anything else. Sergei Starostin's school has now re-included Afroasiatic in a broadly defined Nostratic, while reserving the term Eurasiatic to designate the narrower subgrouping which comprises the rest of the macrofamily. Recent proposals thus differ mainly on the precise placement of Dravidian and Kartvelian.
According to Greenberg, Eurasiatic and Amerind form a genetic node, being more closely related to each other than either is to "the other families of the Old World".There are a number of hypotheses incorporating Nostratic into an even broader linguistic 'mega-phylum', sometimes called Borean, which would also include at least the Dené–Caucasian and perhaps the Amerind and Austric superfamilies. The term SCAN has been used for a group that would include Sino-Caucasian, Amerind, and Nostratic.
Urheimat and differentiation.
Allan Bomhard and Colin Renfrew are in broad agreement with the earlier conclusions of Illich-Svitych and Dolgopolsky in seeking the Nostratic Urheimat (original homeland) within the Mesolithic (or Epipaleolithic) in the Fertile Crescent, the stage which directly preceded the Neolithic and was transitional to it.
Looking at the cultural assemblages of this period, two sequences in particular stand out as possible archeological correlates of the earliest Nostratians or their immediate precursors. Both hypotheses place Proto-Nostratic within the Fertile Crescent at around the end of the last glacial period.
It has been proposed that the broad spectrum revolution of Kent Flannery (1969), associated with microliths, the use of the bow and arrow, and the domestication of the dog, all of which are associated with these cultures, may have been the cultural "motor" that led to their expansion.
Certainly cultures which appeared at Franchthi Cave in the Aegean and Lepenski Vir in the Balkans, and the Murzak-Koba (9100–8000 BCE) and Grebenki (8500–7000 BCE) cultures of the Ukrainian steppe, all displayed these adaptations.
Bomhard (2008) suggests a differentiation of Proto-Nostratic by 8,000 BCE, the beginning of the Neolithic Revolution in the Levant, over a territory spanning the entire Fertile Crescent and beyond into the Caucasus (Proto-Kartvelian), Egypt and along the Red Sea to the Horn of Africa (Proto-Afroasiatic), the Iranian Plateau (Proto-Elamo-Dravidian) and into Central Asia (Proto-Eurasiatic, to be further subdivided by 5,000 BCE into Proto-Indo-European, Proto-Uralic and Proto-Altaic).
According to scholarly opinion the Kebaran is derived from the Levantine Upper Palaeolithic in which the microlithic component originated.
Ouchtata retouch is also a characteristic of the Late Ahmarian Upper Palaeolithic culture of the Levant and does not indicate African influence.
Varga Csaba, a Hungarian linguist believes Hungary to be the Urheimat of Nostratic.
Reconstruction of Proto-Nostratic.
The following data is taken from Kaiser and Shevoroshkin (1988) and Bengtson (1998) and transcribed into the .
Phonology.
The phonemes tabulated below are commonly reconstructed for the Proto-Nostratic language (Kaiser and Shevoroshkin 1988). Allan Bomhard (2008), who relies more heavily on Afroasiatic and Dravidian than on Uralic, as do members of the "Moscow School", reconstructs a different vowel system, with three pairs of vowels represented as: /a/~/ə/, /e/~/i/, /o/~/u/, as well as independent /i/, /o/, and /u/. In the first three pairs of vowels, Bomhard is attempting to specify the subphonemic variation involved, inasmuch as that variation led to some of the vowel gradation (ablaut) and vowel harmony patterning found in various daughter languages.
Sound correspondences.
The following table is compiled from data given by Kaiser and Shevoroshkin (1988) and Starostin. They follow Illich-Svitych's correspondences in which Nostratic voiceless stops give (traditional) PIE voiced ones, and Nostratic glottalized stops give (traditional) PIE voiceless stops, in contradiction with the PIE glottalic theory, which makes traditional PIE voiced stops appeared like glottalized ones. To correct this anomaly, linguists such as Manaster Ramer and Bomhard have proposed to correlate Nostratic voiceless and glottalized stops with PIE ones, so this is done in the table.
Because linguists working on Proto-Indo-European, Proto-Uralic, and Proto-Dravidian do not usually use the IPA, the transcriptions used in those fields are also given where the letters differ from the IPA symbols. The IPA symbols are between slashes because this is a phonemic transcription. The exact values of the phoneme "*p₁" in Proto-Afroasiatic and Proto-Dravidian are unknown. "∅" indicates disappearance without a trace. Hyphens indicate different developments at the beginning and in the interior of words; no consonants ever occurred at the ends of word roots. (Starostin's list of affricate and fricative correspondences does not mention Afroasiatic or Dravidian, and Kaiser and Shevoroshkin don't mention these sounds much; hence the holes in the table.)
Note that, due to lack of research, there are at present several different mutually incompatible reconstructions of Proto-Afroasiatic (see for two recent ones). The one used here has been said to be based too strongly on Proto-Semitic (Yakubovich 1998).
Similarly, the paper by Kaiser and Shevoroshkin is much older than the newest "Altaic Etymological Dictionary" (2003; see Altaic languages article) and therefore assumes a somewhat different phonological system for Proto-Altaic. 
Morphology.
Because grammar is less easily borrowed than words, grammar is usually considered stronger evidence for language relationships than vocabulary. The following correspondences (slightly modified to account for the reconstruction of Proto-Altaic by Starostin et al. [2003]) have been suggested by Kaiser and Shevoroshkin (1988). /N/ could be any nasal consonant. /V/ could be any vowel. (The above cautionary notes on Afroasiatic and Dravidian apply.)
In addition, Kaiser and Shevoroshkin write the following about Proto-Nostratic grammar (two asterisks are used for reconstructions based on reconstructions; citation format changed):
The verb stood at the end of the sentence (SV and SOV type). The 1st p[er]s[on] was formed by adding the 1st ps. pronoun **mi to the verb; similarly, the 2nd ps. was formed by adding **ti. There were no endings for the 3rd ps. present ["or at least none can be reconstructed"], while the 3rd ps. preterit ending was **-di (Illich-Svitych 1971, pp. 218–19). Verbs could be active and passive, causative, desiderative, and reflective; and there were special markers for most of these categories. Nouns could be animate or inanimate, and plural markers differed for each category. There were subject and object markers, locative and lative enclitic particles, etc. Pronouns distinguished direct and oblique forms, animate and inanimate categories, notions of the type 'near':'far', inclusive:exclusive […], etc. Apparently there were no prefixes. Nostratic words were either equal to roots or built by adding endings or suffixes. There are some cases of word composition...
Lexicon.
According to Dolgopolsky Proto-Nostratic language had analytic structure, which he argues by diverging of post- and prepositions of auxiliary words in descendant languages.
Dolgopolsky states three lexical categories to be in Proto-Nostratic language:
Word order was subject–object–verb when the subject was a noun, and object–verb–subject when it was a pronoun. Attributive (expressed by a lexical word) preceded its head. Pronominal attributive ('my', 'this') might follow the noun. Auxiliary words are considered to be postpositions.
Core vocabulary.
The list of etymologies of lexical words reconstructed by Dolgopolsky that are considered by Bomhard to be strong is as follows:
Personal pronouns.
Personal pronouns are seldom borrowed between languages. Therefore the many correspondences between Nostratic pronouns are rather strong evidence for the existence of a Proto-Nostratic language. The difficulty of finding Afroasiatic cognates is, however, taken by some as evidence that Nostratic has two or three branches, Afroasiatic and Eurasiatic (and possibly Dravidian), and that most or all of the pronouns in the following table can only be traced to Proto-Eurasiatic.
Nivkh is a living (if moribund) language with an orthography, which is given here. /V/ means that it is not clear which vowel should be reconstructed.
For space reasons, Etruscan is not included, but the fact that it had /mi/ 'I' and /mini/ 'me' seems to fit the pattern reconstructed for Proto-Nostratic ideally, leading some to argue that the Aegean or Tyrsenian languages were yet another Nostratic branch.
There is no reconstruction of Proto-Eskimo–Aleut, although the existence of the Eskimo–Aleut family is generally accepted.
Other words.
Below are selected reconstructed etymologies from Kaiser and Shevoroshkin (1988) and Bengtson (1998). Reconstructed ( = unattested) forms are marked with an asterisk. /V/ means that it is not clear which vowel should be reconstructed. Likewise, /E/ could have been any front vowel and /N/ any nasal consonant. Only the consonants are given of Proto-Afroasiatic roots (see above).
Sample text.
Vladislav Illich-Svitych using his version of Proto-Nostratic composed a brief poem. (Compare Schleicher's fable for similar attempts with several different reconstructions of Proto-Indo-European.)
The value of K̥ or K̕ is uncertain—it could be /k̕/ or /q̕/. H could similarly be at least /h/ or /ħ/. V or ʌ is an uncertain vowel.
Status within comparative linguistics.
While the Nostratic hypothesis is not endorsed by the mainstream of comparative linguistics, Nostratic studies by nature of being based on the comparative method remain within the mainstream of contemporary linguistics from a methodological point of view; it is the scope with which the comparative method is applied rather than the methodology itself that raises eyebrows.
Nostraticists tend to refuse to include in their schema language families for which no proto-language has yet been reconstructed. This approach was criticized by Joseph Greenberg on the ground that genetic classification is necessarily prior to linguistic reconstruction but this criticism has so far had no effect on Nostraticist theory and practice.
Certain critiques have pointed out that the data from individual, established language families that is cited in Nostratic comparisons often involves a high degree of errors; Campbell (1998) demonstrates this for Uralic data. Defenders of the Nostratic theory argue that were this to be true, it would remain that in classifying languages genetically, positives count for vastly more than negatives (Ruhlen 1994). The reason for this is that, above a certain threshold, resemblances in sound/meaning correspondences are highly improbable mathematically.
The technique of comparing grammatical structures (as opposed to words) has suggested to some that the Nostratic candidates lack interrelatedness. However, Pedersen's original Nostratic proposal synthesized earlier macrofamilies, some of which, including Indo-Uralic, involved extensive comparison of inflections. It is true the Russian Nostraticists and Bomhard initially emphasized lexical comparisons. Bomhard recognized the necessity to explore morphological comparisons and has since published extensive work in this area (see especially Bomhard 2008:1.273–386). According to him the breakthrough came with the publication of the first volume of Joseph Greenberg's Eurasiatic work, which provided a massive list of possible morphemic correspondences that has proved fruitful to explore. Other important contributions on Nostratic morphology have been published by John C. Kerns and Vladimir Dybo.
Critics argue that were one to collect all the words from the various known Indo-European languages and dialects which have at least one of any 4 meanings, one could easily form a list that would cover any conceivable combination of two consonants and a vowel (of which there are only about 20*20*5=2000). Nostraticists respond that they do not compare isolated lexical items but reconstructed proto-languages. To include a word for a proto-language it must be found in a number of languages and the forms must be relatable by regular sound changes. In addition, many languages have restrictions on root structure, reducing the number of possible root-forms far below its mathematical maximum. These languages include, among others, Indo-European, Uralic, and Altaic—all the core languages of the Nostratic hypothesis. To understand how the root structures of one language relate to those of another has long been a focus of Nostratic studies. For a highly critical assessment of the work of the Moscow School, especially the work of Illich-Svitych, cf. Campbell and Poser 2008:243-264.
It has also been argued that Nostratic comparisons mistake Wanderwörter and cross-borrowings between branches for true cognates.

</doc>
<doc id="21796" url="http://en.wikipedia.org/wiki?curid=21796" title="Namespace">
Namespace

A namespace is a set of named symbols, usually variables. Names or "identifiers" are keys allowing access to symbol values. 
Namespaces provide a level of direction to specific identifiers, thus making it possible to distinguish between identical identifiers. This is similar to people names, where a surname could be thought of as a namespace that makes it possible to distinguish people who have the same given name.
In computer programming, namespaces are typically employed for the purpose of grouping symbols and identifiers around a particular behavior.
For Starters.
Name conflicts.
Element names are defined by the developer. This often results in a conflict when trying to mix XML documents from different XML applications.
This XML carries HTML table information:
This XML carries information about a table (i.e. a piece of furniture):
If these XML fragments were added together, there would be a name conflict. Both contain a <table> element, but the elements have different content and meaning.
An XML parser will not know how to handle these differences.
Solution via prefix.
Name conflicts in XML can easily be avoided using a name prefix.
The following XML distinguishes between information about the HTML table and furniture by prefixing "h" and "f" at the beginning xml/xml_namespaces.asp 
Naming system.
A name in a namespace consists of a namespace identifier and a local name. The namespace name is usually applied as a prefix to the local name.
In Augmented Backus-Naur Form:
 name = <namespace identifier> separator <local name>
When local names are used by themselves, name resolution is used to decide which (if any) particular item is alluded to by some particular local name.
Delegation.
Delegation of responsibilities between parties is important in real-world applications, such as the structure of the World Wide Web. Namespaces allow delegation of identifier assignment to multiple name issuing organisations whilst retaining global uniqueness. A central Registration authority registers the assigned namespace identifiers allocated. Each namespace identifier is allocated to an organisation which is subsequently responsible for the assignment of names in their allocated namespace. This organisation may be a name issuing organisation that assign the names themselves, or another Registration authority which further delegates parts of their namespace to different organisations.
Hierarchy.
A naming scheme that allows subdelegation of namespaces to third parties is a hierarchical namespace
A hierarchy is recursive if the syntax for the namespace identifiers is the same for each subdelegation. An example of a recursive hierarchy is the Domain name system.
An example of a non-recursive hierarchy are Uniform resource name representing an Internet Assigned Numbers Authority (ISBN) number.
Namespace versus scope.
A namespace identifier may provide context ("Scope" in computer science) to a name, and the terms are sometimes used interchangeably. However, the context of a name may also be provided by other factors, such as the location where it occurs or the syntax of the name.
In programming languages.
For many programming languages, namespace is a context for their identifiers. In an operating system, an example of namespace is a directory. Each name in a directory uniquely identifies one file or subdirectory, but one file may have the same name multiple times.
As a rule, names in a namespace cannot have more than one meaning; that is, different meanings cannot share the same name in the same namespace. A namespace is also called a context, because the same name in different namespaces can have different meanings, each one appropriate for its namespace.
Following are other characteristics of namespaces:
Below is an example of a namespace in C++:
Computer science considerations.
A namespace in computer science (sometimes also called a name scope), is an abstract container or environment created to hold a logical grouping of unique identifiers or symbols (i.e., names). An identifier defined in a namespace is associated only with that namespace. The same identifier can be independently defined in multiple namespaces. That is, the meaning associated with an identifier defined in one namespace may or may not have the same meaning as the same identifier defined in another namespace. Languages that support namespaces specify the rules that determine to which namespace an identifier (not its definition) belongs.
This concept can be illustrated with an analogy. Imagine that two companies, X and Y, each assign ID numbers to their employees. X should not have two employees with the same ID number, and likewise for Y; but it is not a problem for the same ID number to be used at both companies. For example, if Bill works for company X and Jane works for company Y, then it is not a problem for each of them to be employee #123. In this analogy, the ID number is the identifier, and the company serves as the namespace. It does not cause problems for the same identifier to identify a different person in each namespace.
In large computer programs or documents it is not uncommon to have hundreds or thousands of identifiers. Namespaces (or a similar technique, see Emulating namespaces) provide a mechanism for hiding local identifiers. They provide a means of grouping logically related identifiers into corresponding namespaces, thereby making the system more modular.
Data storage devices and many modern programming languages support namespaces. Storage devices use directories (or folders) as namespaces. This allows two files with the same name to be stored on the device so long as they are stored in different directories. In some programming languages (e.g. C++, Python), the identifiers naming namespaces are themselves associated with an enclosing namespace. Thus, in these languages namespaces can nest, forming a namespace tree. At the root of this tree is the unnamed global namespace.
Use in common languages.
In C++, a namespace is defined with a namespace block.
Within this block, identifiers can be used exactly as they are declared. Outside of this block, the namespace specifier must be prefixed. For example, outside of codice_1, codice_2 must be written codice_3 to be accessed. C++ includes another construct that makes this verbosity unnecessary. By adding the line
to a piece of code, the prefix codice_4 is no longer needed.
Code that is not explicitly declared within a namespace is considered to be in the global namespace.
Namespace resolution in C++ is hierarchical. This means that within the hypothetical namespace codice_5, the identifier codice_6 refers to codice_7. If codice_7 doesn't exist, it then refers to codice_9. If neither codice_7 nor codice_9 exist, codice_6 refers to codice_13, an identifier in the global namespace.
Namespaces in C++ are most often used to avoid naming collisions. Although namespaces are used extensively in recent C++ code, most older code does not use this facility. For example, the entire C++ standard library is defined within codice_14, but before standardization many components were originally in the global namespace. However, when namespaces are used, it is considered to be against good code practices. Bjarne Stroustrup, designer of C++, has said himself that using namespaces is unsafe and wished he had not included it in the language.
In Java, the idea of a namespace is embodied in Java packages. All code belongs to a package, although that package need not be explicitly named. Code from other packages is accessed by prefixing the package name before the appropriate identifier, for example codice_15 in codice_16 can be referred to as codice_17 (this is known as the fully qualified class name). Like C++, Java offers a construct that makes it unnecessary to type the package name (codice_18). However, certain features (such as reflection) require the programmer to use the fully qualified name.
Unlike C++, namespaces in Java are not hierarchical as far as the syntax of the language is concerned. However, packages are named in a hierarchical manner. For example, all packages beginning with codice_19 are a part of the Java platform—the package contains classes core to the language, and contains core classes specifically relating to reflection.
In Java (and Ada, C#, and others), namespaces/packages express semantic categories of code. For example, in C#, codice_20 contains code provided by the system (the .NET Framework). How specific these categories are and how deep the hierarchies go differ from language to language.
Function and class scopes can be viewed as implicit namespaces that are inextricably linked with visibility, accessibility, and object lifetime.
Namespaces are heavily used in C# language. All .NET Framework classes are organized in namespaces, to be used more clearly and to avoid chaos. Furthermore, custom namespaces are extensively used by programmers, both to organize their work and to avoid naming collisions.
When referencing a class, one should specify either its fully qualified name, which means namespace followed by the class name,
or add a using statement. This, eliminates the need to mention the complete name of all classes in that namespace.
In the above examples, System is a namespace, and Console and Convert are classes defined within System.
In Python, namespaces are defined by the individual modules, and since modules can be contained in hierarchical packages, then name spaces are hierarchical too.
In general when a module is imported then the names defined in the module are defined via that module's name space, and are accessed in from the calling modules by using the fully qualified name.
The "from ... import ..." can be used to insert the relevant names directly into the calling module's namespace, and those names can be accessed from the calling module without the qualified name :
Since this directly imports names (without qualification) it can overwrite existing names with no warnings.
A special form is "from ... import *", which imports all names defined in the named package directly in the calling modules namespace. Use of this form of import, although supported within the language, is generally discouraged as it pollutes the namespace of the calling module and will cause already defined names to be overwritten in the case of name clashes.
Python also supports "import x as y" as a way of providing an alias or alternative name for use by the calling module:
In XML, the XML namespace specification enables the names of elements and attributes in an XML document to be unique, similar to the role of namespaces in programming languages. Using XML namespaces, XML documents may contain element or attribute names from more than one XML vocabulary.
Namespaces were introduced into PHP from version 5.3 onwards. Naming collision of classes, functions and variables can be avoided.
In PHP, a namespace is defined with a namespace block.
We can reference a PHP namespace with the following different ways:
Emulating namespaces.
In programming languages lacking language support for namespaces, namespaces can be emulated to some extent by using an identifier naming convention. For example, C libraries such as Libpng often use a fixed prefix for all functions and variables that are part of their exposed interface. Libpng exposes identifiers such as:
 png_create_write_struct
 png_get_signature
 png_read_row
 png_set_invalid
This naming convention provides reasonable assurance that the identifiers are unique and can therefore be used in larger programs without fear of identifier naming collisions. Likewise, many packages originally written in Fortran (e.g., BLAS, LAPACK) reserve the first few letters of a function's name to indicate which group it belongs to.
Unfortunately, this technique has several drawbacks:

</doc>
<doc id="21797" url="http://en.wikipedia.org/wiki?curid=21797" title="Nahum">
Nahum

Nahum ( or ; Hebrew: נַחוּם "Naḥūm"‎) was a minor prophet whose prophecy is recorded in the Hebrew Bible. His book comes in chronological order between Micah and Habakkuk in the Bible. He wrote about the end of the Assyrian Empire, and its capital city, Nineveh, in a vivid poetic style.
Life.
Little is known about Nahum’s personal history. His name means "comforter," and he was from the town of Alqosh, (Nah 1:1) which scholars have attempted to identify with several cities, including the modern `Alqush of Assyria and Capharnaum of northern Galilee. He was a very nationalistic Hebrew however and lived amongst the Elkoshites in peace. Nahum, called "the Elkoshite," is the seventh in order of the minor prophets.
Works.
Nahum's writings could be taken as prophecy or as history. One account suggests that his writings are a prophecy written in about 615 BC, just before the downfall of Assyria, while another account suggests that he wrote this passage as liturgy just after its downfall in 612 BC.
The book was introduced in Calvin's Commentary as a complete and finished poem:
No one of the minor Prophets seems to equal the sublimity, the vehemence and the boldness of Nahum: besides, his Prophecy is a complete and finished poem; his exordium is magnificent, and indeed majestic; the preparation for the destruction of Nineveh, and the description of its ruin, and its greatness, are expressed in most vivid colors, and possess admirable perspicuity and fulness.—Rev. John Owen, translator, Calvin's Commentary on Jonah, Micah, Nahum
Nahum, taking words from Moses himself, has shown in a general way what sort of "Being God is". The Reformation theologian Calvin argued, Nahum painted God by which his nature must be seen, and "it is from that most memorable vision, when God appeared to Moses after the breaking of the tables."
Tomb.
The tomb of Nahum is supposedly inside the synagogue at Alqosh, although there are other places outside Iraq that lay claim also to being the original “Elkosh” from which Nahum hailed. Alquosh was abandoned by its Jewish population in 1948, when they were expelled, and the synagogue that purportedly houses the tomb is in a poor structural state, to the extent that the tomb itself is in danger of destruction. The tomb underwent basic repairs in 1796. When all Jews were compelled to flee Alqosh in 1948, the iron keys to the tomb were handed to a Assyrian man by the name of Sami Jajouhana. Few Jews visit the historic site, yet Jajouhana continues to keep the promise he made with his Jewish friends, and looks after the tomb. A team of US/UK construction engineers, led by Huw Thomas, is currently planning ways to save the building and the tomb. Money had been allocated for proposed renovation in 2008. The tomb is currently is disrepair and may be threatened by the rise of ISIS in Iraq.
Liturgical commemoration.
The Prophet Nahum is venerated as a saint in Eastern Christianity. On the Eastern Orthodox liturgical calendar, his feast day is December 1(for those churches which follow the traditional Julian Calendar, December 1 currently falls on December 14 of the modern Gregorian Calendar). He is commemorated with the other minor prophets in the Calendar of saints of the Armenian Apostolic Church on July 31.

</doc>
<doc id="21798" url="http://en.wikipedia.org/wiki?curid=21798" title="November 17">
November 17

November 17 is the day of the year in the Gregorian calendar.

</doc>
<doc id="21803" url="http://en.wikipedia.org/wiki?curid=21803" title="Newfoundland English">
Newfoundland English

Newfoundland English is a name for several accents and dialects of English found in the province of Newfoundland and Labrador. Most of these differ substantially from the English commonly spoken elsewhere in neighbouring Canada and the North Atlantic. Many Newfoundland dialects are similar to the West Country dialects of the West Country in England, particularly the city of Bristol and counties Cornwall, Devon, Dorset, Hampshire and Somerset, while others resemble dialects of Ireland's southeast, particularly Waterford, Wexford, Kilkenny and Cork. Still others blend elements of both and there is also a Scottish influence on the dialects - while the Scottish came in smaller numbers than the English and Irish, they had a large influence on Newfoundland society. One estimate claims 80 to 85 percent of Newfoundland's English heritage came from the southwest of the country.
The dialects that comprise Newfoundland English developed because of Newfoundland's history as well as its geography. Newfoundland was one of the first areas settled by England in North America, beginning in small numbers in the early 17th century before peaking in the early 19th century. Newfoundland was a British colony until 1907 when it became an independent Dominion within the British Empire. It became a part of Canada in 1949. Newfoundland is an island in the Atlantic Ocean, separated by the Strait of Belle Isle from Labrador, the sparsely populated mainland part of the province. Most of the population remained rather isolated on the island, allowing the dialects time to develop independently of those on the North American continent. Today, some words from Newfoundland English have been adopted through popular culture in other places in Canada (especially Ontario and eastward).
Historically, Newfoundland English was first recognized as a separate dialect by the late 18th century when George Cartwright published a glossary of Newfoundland words.
Other names for Newfoundland English.
Newfoundland English is often humorously called "Newfinese". The term "Newfie" is also sometimes used though it is sometimes considered pejorative when used by people from outside of Newfoundland.
Other languages and dialects that have influenced Newfoundland English.
There is also a dialect of French centred mainly on the Port au Port Peninsula on the west coast of the island which has had an impact on the syntax of English in the area. One example of these constructs found in Newfoundland is "Throw grandpa down the stairs his hat", a dative construction in which the hat makes the trip, not the grandfather. Another is the use of French reflexive constructions in sentences such as the reply to a question like "Where are you going?", reply: "Me I'm goin' downtown" (this reflexive form of grammar also exists in Irish Gaelic and Jerriais).
Newfoundland French was deliberately discouraged by the Newfoundland government through the public schools during the mid-20th-century, and only a small handful of mainly elderly people are still fluent in the French-Newfoundland dialect. In the last couple of decades, many parents in the region have demanded and obtained French education for their children, but this would be Standard French education and does not represent a continuation of the old dialect per se. Some people living in the Codroy Valley on the south-west tip of the island are also ancestrally Francophone, but represent Acadian settlers from the Maritime Provinces of Canada who arrived during the 19th century. This population has also lost the French language.
The greatest distinction between Newfoundland English and General Canadian English is its vocabulary. It includes some Inuit and First Nations words (for example "tabanask", a kind of sled), preserved archaic English words no longer found in other English dialects (for example "pook", a mound of hay), Irish language survivals like "sleveen" and "angishore", compound words created from English words to describe things unique to Newfoundland (for example "stun breeze", a wind of at least 20 knots (37 km/h)), English words which have undergone a semantic shift (for example "rind", the bark of a tree), and unique words whose origins are unknown (for example "diddies", a nightmare).
Newfoundland English expressions.
In recent years, the most commonly noted Newfoundland English expression might be "Whadd'ya at?" ("What are you at?"), loosely translated to "How's it going?" or "What are you doing?" Coming in a close second might be "You're stunned as me arse, b'y," inferring incredible stupidity or foolishness to the person being spoken to.
Other local expressions include:
Also of note is the widespread use of the term "b'y" as a common form of address. It is shorthand for "boy", (and is a turn of phrase particularly pronounced with the Waterford dialect of Hiberno-Irish) but is used variably to address members of either sex. Another term of endearment, often spoken by older generations, is "me ducky", used when addressing a female in an informal manner, and usually placed at the end of a sentence which is often a question (Example: "How's she goin', me ducky?") -- a phrase also found in East Midlands British English. Also pervasive as a sentence ending is "right" used in the same manner as the Canadian "eh" or the American "huh" or "y'know". Even if the sentence would otherwise be a non-question, the pronunciation of "right" can sometimes make it seem like affirmation is being requested.
Certain words have also gained prominence amongst the speakers of Newfoundland English. For instance, a large body of water that may be referred to as a "lake" elsewhere, can often (but not uniformly) be referred to as a pond. In addition, a large landmass that rises high out of the ground, regardless of elevation, is referred to unwaveringly as a "hill". Yet there is a difference between a hill and a big hill.
Another major characteristic of some variants of Newfoundland English is adding the letter 'h' to words that begin with vowel sounds, or removing 'h' from words that begin with it. In some districts, the term house commonly is referred to as the "ouse," for example, while "even" might be said "h'even." The idiom "'E drops 'is h in 'Olyrood and picks en up in H'Avondale." is often used to describe this using the eastern towns Holyrood and Avondale as examples. There are many different variations of the Newfoundland dialect depending on geographical location within the province. It is also important to note that Labrador has a very distinct culture and dialect within its region.
Other.
Although it is referred to as "Newfoundland English" or "Newfinese", Newfoundland is not the only place which uses this dialect. The southern coast of Labrador (the nearest point of Labrador to Newfoundland) and an area near the Labrador border, the Basse-Côte-Nord of Quebec, also use this form of speaking. Younger generations of this area have adapted the way of speaking, and created some of their own expressions. Some older generations speak Newfoundland English, but it is more commonly used by the younger generations. "B'y" is one of the most common terms used in this area.
It is also common to hear Newfoundland English in Yellowknife, Southern Alberta and Fort McMurray, Alberta, places to which many Newfoundlanders have moved or commute regularly for employment.
Newfoundland English is also used frequently in the city of Cambridge ON. This is due the high Newfoundland (mostly from Bell Island) population. There are even counties in the Southern Appalachian Mountains of Tennessee (of Scottish-Irish-English descendants) who have similar dialects, and also in both Prince Edward Island and Nova Scotia as well, but these dialects are dying out fast.
Similarities to Australian English.
Some of the features of Newfoundland English here can be or were also found in Australian English, especially among speakers of the "Broad Australian" variant and in rural areas.
Such features can be seen in older popular literature, such as C. J. Dennis's "The Sentimental Bloke" and Henry Lawson's writings.
These include forms that have their origins in Irish-English and Irish-Gaelic..

</doc>
<doc id="21804" url="http://en.wikipedia.org/wiki?curid=21804" title="National flag">
National flag

A national flag is a flag that symbolises a country. The flag is flown by the government, but usually can also be flown by citizens of the country.
Both public and private buildings such as schools and courthouses may fly the national flag. In some countries, the national flags are only flown from non-military buildings on certain flag days.
History.
Historically, flags originate as military standards, used as field signs. The practice of flying flags indicating the country of origin outside of the context of warfare emerges with the maritime flag, introduced during the age of sail, in the early 17th century. The origins of the Union Jack flag date back to 1603, when James VI of Scotland inherited the English and Irish thrones (as James I), thereby uniting the crowns of England, Scotland and Ireland in a personal union (which remained separate states). On 12 April 1606, a new flag to represent this regal union between England and Scotland was specified in a royal decree, according to which the flag of England (a red cross on a white background, known as St George's Cross), and the flag of Scotland (a white saltire on a blue background, known as the Saltire or St Andrew's Cross), would be joined together, forming the flag of Great Britain and first Union Flag.
With the emergence of nationalist sentiment from the late 18th century the desire was felt to display national flags also in civilian contexts, notably the US flag, in origin adopted as a naval ensign in 1777, which after the American Revolution began to be displayed as a generic symbol of the United States, and the French Tricolore which became a symbol of the Republic in the 1790s.
Most countries of Europe adopted a national flag in the course of the 19th and early 20th centuries, often based on older (medieval) war flags. The specifications of the flag of Denmark were codified in 1748, based on a 14th-century design. The flag of Switzerland was introduced in 1889, also based on medieval war flags. The Netherlands introduced two national flags in 1813 (either an orange-white-blue or a red-white-blue tricolour; the final decision in favour of red was made in 1937). The non-European powers followed the trend in the late 19th century, the flag of Japan being introduced in 1870, that of Qing China in 1890. Also in the 19th century, most countries of South America introduced a flag as they became independent (Peru in 1820, Bolivia in 1851, Colombia in 1860, Brazil in 1822, etc.) Afghanistan had more changes of its national flag during the 20th and 21st centuries than any other country in the world, having 21 flags from 1901 to the present.
Process of adoption.
The national flag is often, but not always, mentioned or described in a country's constitution, but its detailed description may be delegated to a flag law passed by the legislative, or even secondary legislation or in monarches a decree.
Thus, the national flag is mentioned briefly in the Basic Law for the Federal Republic of Germany of 1949 "the federal flag is black-red-gold" (art. 22.2 "Die Bundesflagge ist schwarz-rot-gold"), but its proportions were regulated in a document passed by the government in the following year. The Flag of the United States is not defined in the constitution but rather in a separate Flag Resolution passed in 1777.
Minor design changes of national flags are often passed on a legislative or executive level, while substantial changes have constitutional character. The design of the flag of Serbia omitting the communist star of the flag of Yugoslavia was a decision made in the 1992 Serbian constitutional referendum, but the adoption of a coat of arms within the flag was based on a government "recommendation" in 2003, adopted legislatively in 2009 and again subject ot a minor design change in 2010. The Flag of the United States underwent numerous changes because the number of stars represents the number of states, proactively defined in a Flag Act of 1818 to the effect that "on the admission of every new state into the Union, one star be added to the union of the flag"; it was changed for the last time in 1960 with the accession of Hawaii.
A change in national flag is often due to a change of regime, especially following a civil war or revolution. In such cases, the military origins of the national flag and its connection to political ideology (form of government, monarchy vs. republic vs. theocracy, etc.) remains visible. In such cases national flags acquire the status of a political symbols. 
The flag of Germany, for instance, was a tricolour of black-white-red under the German Empire, inherited from the North German Confederation (1866). The Weimar Republic that followed adopted a black-red-gold tricolour. Nazi Germany went back to black-white-red in 1933, and black-red-gold was reinstituted by the two successor states, the West Germany and East Germany following World War II. Similarly the flag of Libya introduced with the creation of the Kingdom of Libya in 1951 was abandoned in 1969 with the coup d'état led by Muammar Gaddafi. It was used again by National Transitional Council and by anti-Gaddafi forces during the Libyan Civil War in 2011 and officially adopted by the Libyan interim Constitutional Declaration.
Usage.
There are three distinct types of national flag for use on land, and three for use at sea, though many countries use identical designs for several (and sometimes all) of these types of flag.
On land.
On land, there is a distinction between civil flags (FIAV symbol ), state flags (), and war or military flags (). State flags are those used officially by government agencies, whereas civil flags may be flown by anyone regardless of whether he/she is linked to government. War flags (also called military flags) are used by military organisations such as Armies, Marine Corps, or Air Forces.
In practice, many countries (such as the United States and the United Kingdom) have identical flags for these three purposes; national flag is sometimes used as a vexillological term to refer to such a three-purpose flag (). In a number of countries, however, and notably those in Latin America, there is a distinct difference between civil and state flags. In most cases, the civil flag is a simplified version of the state flag, with the difference often being the presence of a coat of arms on the state flag that is absent from the civil flag.
Very few countries use a war flag that differs from the state flag. The People's Republic of China, the Republic of China (Taiwan), and Japan are notable examples of this. Swallow-tailed flags are used as war flags and naval ensigns in Nordic countries and charged versions as presidential or royal standards. The Philippines does not have a distinctive war flag in this usual sense, but the flag of the Philippines is legally unique in that it is flown with the red stripe on top when the country is in a state of war, rather than the conventional blue.
At sea.
The flag that indicates nationality on a ship is called an ensign. As with the national flags, there are three varieties: the civil ensign (), flown by private vessels; state ensigns (also called government ensigns; ), flown by government ships; and war ensigns (also called naval ensigns; ), flown by naval vessels. The ensign is flown from an ensign-staff at the stern of the ship, or from a gaff when underway. Both these positions are superior to any other on the ship, even though the masthead is higher. In the absence of a gaff the ensign may be flown from the yardarm. (See Maritime flags.) National flags may also be flown by aircraft and the land vehicles of important officials. In the case of aircraft, those flags are usually painted on, and those are usually to be painted on in the position as if they were blowing in the wind.
In some countries, such as the United States and Canada (except for the Royal Canadian Navy's Ensign), the national ensign is identical to the national flag, while in others, such as the United Kingdom and Japan, there are specific ensigns for maritime use. Most countries do not have a separate state ensign, although the United Kingdom is a rare exception, in having a red ensign for civil use, a white ensign as its naval ensign, and a blue ensign for government non-military vessels.
Protocol.
There is a great deal of protocol involved in the proper display of national flags. A general rule is that the national flag should be flown in the position of honour, and not in an inferior position to any other flag (although some countries make an exception for royal standards). The following rules are typical of the conventions when flags are flown on land:
Hanging a flag vertically.
Most flags are hung vertically by rotating the flag pole. However, some countries have specific protocols for this purpose or even have special flags for vertical hanging; usually rotating some elements of the flag — such as the coat of arms — so that they are seen in an upright position.
Examples of countries that have special protocol for vertical hanging are: Canada, Czech Republic, Greece, Israel, the Philippines, Saudi Arabia, South Africa, and the United States (reverse always showing); and the United Kingdom (obverse always showing).
Examples of countries that have special designs for vertical hanging are: Austria, Germany, Hungary, Mexico, Poland, Montenegro, and Slovakia (coat of arms must be rotated to normal position); Cambodia (coat of arms must be rotated and blue strips are narrowed); Dominica (coat of arms must be rotated and reverse always showing); Liechtenstein (crown must be rotated).
Design.
The art and practice of designing flags is known as vexillography. The design of national flags has seen a number of customs become apparent.
All national flags are rectangular, except for the flag of Nepal. The ratios of height to width vary among national flags, but none is taller than it is wide, again except for the flag of Nepal. The flags of Switzerland and the Vatican City are the only national flags which are exact squares.
The obverse and reverse of all national flags are either identical or mirrored, except for the flag of Paraguay. See Flags whose reverse differs from the obverse for a list of exceptions including non-national flags.
As of 2011, all national flags consist of at least two different colours. In many cases, the different colours are presented in either horizontal or vertical bands. It is particularly common for colours to be presented in bands of three.
It is common for many flags to feature national symbols, such as coats of arms. National patterns are present in some flags. Variations in design within a national flag can be common in the flag's upper left quarter, or canton.
Colours.
 The most popular colours in national flags are red, white, green, dark blue, yellow, light blue, and black. The on the right shows the proportion of the surface colour across all national flags. The occurrence of each colour in all the flags is listed in detail in the table below. The table shows that the colours light brown, dark brown and grey only occur in very small quantities. In fact, they only occur in the symbols of flags, such as in the Spanish flag.
Similarities.
Although the national flag is meant to be a unique symbol for a country, many pairs of countries have highly similar flags. Examples include the flags of Monaco and Indonesia, which differ only slightly in proportion; the flags of the Netherlands and Luxembourg, which differ in proportion as well as in the tint of blue used; and the flags of Romania and Chad, which differ only in the tint of blue.
The flags of Ireland and Côte d'Ivoire and the flags of Mali and Guinea are (aside from shade or ratio differences) vertically mirrored versions from each other. This means that the reverse of one flag matches the obverse of the other. Other than horizontal mirrored flags (like Poland and Indonesia) the direction in which these flags fly are crucial to identify them.
There are three colour combinations that are used on several flags in certain regions. Blue, white, and red is a common combination in Slavic countries such as the Czech Republic, Slovakia, Russia, Serbia, Slovenia, and Croatia as well as among Western nations including Australia, France, Iceland, Norway, New Zealand, the United Kingdom, the Netherlands and the United States of America. Many African nations use the Pan-African colours of red, yellow, and green, including Ghana, Cameroon, Mali and Senegal. Flags containing red, white, and black (a subset of the Pan-Arab colours) can be found particularly among the Arab nations such as Egypt, Iraq and Yemen.
While some similarities are coincidental, others are rooted in shared histories. For example, the flags of Colombia, of Ecuador, and of Venezuela all use variants of the flag of Gran Colombia, the country they composed upon their independence from Spain, created by the Venezuelan independence hero Francisco de Miranda; and the flags of Kuwait, of Jordan, and of Palestine are all highly similar variants of the flag of the Arab revolt of 1916–1918. The flags of Romania and Moldova are virtually the same, because of the common history and heritage. Moldova adopted the Romanian flag during the declaration of independence from the USSR in 1991 (and was used in various demonstrations and revolts by the population) and later the Moldovan coat of arms (which is part of the Romanian coat of arms) was placed in the centre of the flag. The Nordic countries all use the Nordic Cross design (Iceland, Denmark, Norway, Sweden, Finland, in addition to the autonomous regions of the Faroe Islands and Åland), a horizontal cross shifted to the left on a single-coloured background. The United States and United Kingdom both have red, white, and blue. This similarity is due to the fact that the first 13 states of the U.S. were former colonies of the United Kingdom. Also, Australia and New Zealand share a very similar flag, which stems from their joint British heritage. Both of these flags feature the Union Jack in one corner, both have royal blue background, and both have the Southern Cross as a prominent feature. The only differences between these flags is that the Australian flag has the Commonwealth Star below the canton, and that on the New Zealand flag, just four stars in the Southern Cross are presented, and they are five-pointed red stars with white borders. On the other hand, all five stars of the Southern Cross are presented on the Australian flag, and they are white with seven points, except for the additional smaller fifth star in the Southern Cross which has only five points on this flag. Some similarities to the United States flag with the red and white stripes are noted as well such as the flag of Malaysia and the flag of Liberia, the latter of which was an American resettlement colony.
Many other similarities may be found among current national flags, particularly if inversions of colour schemes are considered (e.g., compare the flag of Senegal to that of Cameroon and Indonesia to Poland.

</doc>
<doc id="21805" url="http://en.wikipedia.org/wiki?curid=21805" title="November 4">
November 4

November 4 is the day of the year in the Gregorian calendar.

</doc>
<doc id="21806" url="http://en.wikipedia.org/wiki?curid=21806" title="November 23">
November 23

November 23 is the day of the year in the Gregorian calendar.

</doc>
<doc id="21809" url="http://en.wikipedia.org/wiki?curid=21809" title="National Hockey League">
National Hockey League

The National Hockey League (NHL; French: "Ligue nationale de hockey—LNH") is a professional ice hockey league composed of 30 member clubs: 23 in the United States and 7 in Canada. Headquartered in New York City, the NHL is widely considered to be the premier professional ice hockey league in the world, and one of the major professional sports leagues in the United States and Canada. The Stanley Cup, the oldest professional sports trophy in North America, is awarded annually to the league playoff champion at the end of each season.
The National Hockey League was organized on November 26, 1917, in Montreal, Quebec, after the suspension of operations of its predecessor organization, the National Hockey Association (NHA), which had been founded in 1909 in Renfrew Ontario. It started with four teams (all based in Canada) and, through a series of expansions, contractions, and relocations, is now composed of thirty active franchises. The "nation" referred to by the league's name was Canada, although the league has now been binational since 1924 when its first team in the United States, the Boston Bruins, began play. After a labour-management dispute that led to the cancellation of the entire 2004–05 season, the league resumed play under a new collective agreement that included a salary cap. In 2009, the NHL enjoyed record highs in terms of sponsorships, attendance, and television audiences.
The league draws many highly skilled players from all over the world and currently has players from approximately 20 different countries. Canadians have historically constituted the majority of the players in the league, with a dramatically increasing percentage of American and European players in recent years.
History.
Early years.
 We didn't throw [Toronto Blueshirts owner] Eddie Livingstone out. Perish the thought. That would have been illegal and unfair. Also, it wouldn't have been sporting. We just resigned, and wished him a fine future with his National Association franchise.
 — Montreal Wanderers owner Sam Lichtenhein, as told to sports journalist Elmer Ferguson
The National Hockey League was established in 1917 as the successor to the National Hockey Association (NHA), officially called the National Hockey Association of Canada Limited. Founded by Ambrose O'Brien in 1909, the NHA began play one year later with seven teams in Ontario and Quebec, and was one of the first major leagues in professional ice hockey. But by the NHA's eighth season, a series of disputes with Toronto Blueshirts owner Eddie Livingstone led the other team owners, representing the Montreal Canadiens, Montreal Wanderers, Ottawa Senators, and Quebec Bulldogs to meet at the Windsor Hotel in Montreal to talk about the league's future. Realizing the league constitution left them unable to force Livingstone out, the four teams voted instead to suspend the NHA, and on November 26, 1917, formed the National Hockey League. While a full member of the new league, the Bulldogs were unable to play, and the remaining owners created a new team in Toronto, the Arenas, to compete with the Canadiens, Wanderers and Senators. The first games were played three weeks later on December 19. Joe Malone scored five goals in a 7–4 victory for the Canadiens over the Senators on opening night; he finished the 1917–18 season with 44 goals in 20 games. The league nearly collapsed in January 1918 when the Montreal Arena burned down, causing the Wanderers to cease operations and forcing the Canadiens to hastily find a new arena. The NHL continued on as a three-team league until the Bulldogs returned in 1919.
The NHL replaced the NHA as one of the leagues that competed for the Stanley Cup, which was an interleague competition back then. Toronto won the first NHL title, then defeated the Pacific Coast Hockey Association's Vancouver Millionaires to win the 1918 Stanley Cup The Canadiens won the league title in 1919; however their Stanley Cup Final against the Seattle Metropolitans was abandoned with the series tied after several players became ill as a result of the Spanish Flu epidemic that resulted in Montreal defenceman Joe Hall's death. Montreal defeated the Calgary Tigers of the Western Canada Hockey League (WCHL) in 1924 to win their first Stanley Cup as a member of the NHL. The Hamilton Tigers, who had relocated from Quebec in 1920, won the regular season title in 1924–25 but refused to play in the championship series unless they were given a C$200 bonus. The league refused and declared the Canadiens the league champion after they defeated the Toronto St. Patricks (formerly the Arenas) in the semi-final. Montreal was then defeated by the Victoria Cougars for the 1925 Stanley Cup. It was the last time a non-NHL team won the trophy, as the Stanley Cup became the "de facto" NHL championship in 1926 after the WCHL ceased operation.
Expansion into the United States and the Original Six.
The National Hockey League embarked on rapid expansion in the 1920s, adding the Montreal Maroons and Boston Bruins in 1924. The Bruins were the first American team in the league, while the Maroons played in the newly completed Montreal Forum that the Canadiens made famous in later decades. The New York Americans began play in 1925 after purchasing the assets of the Hamilton Tigers, and were joined by the Pittsburgh Pirates. Tex Rickard, owner of Madison Square Garden, was so impressed with the popularity of the Americans that he added the New York Rangers in 1926. The Chicago Black Hawks and Detroit Cougars (later Red Wings) were also added after the league purchased the assets of the defunct WCHL. A group headed by Conn Smythe purchased the Toronto St. Patricks in 1927, immediately renamed them the Maple Leafs, and built Maple Leaf Gardens in 1931.
The Great Depression and the onset of World War II took a toll on the league. The Pirates became the Philadelphia Quakers in 1930, then folded one year later. The Senators likewise became the St. Louis Eagles in 1934, also lasting only one year. The Canadiens were nearly sold and relocated to Cleveland, Ohio in 1936 before a trio of local owners purchased the team and kept them in Montreal. The Maroons did not survive, however, as they suspended operations in 1938. The Americans were suspended in 1942 due to a lack of players, and never revived. The league was reduced to six teams for the 1942–43 NHL season: the Boston Bruins, Chicago Black Hawks, Detroit Red Wings, Montreal Canadiens, New York Rangers and Toronto Maple Leafs. These six teams remained constant for 25 years, a period known as the Original Six. The league then reached an agreement with the Stanley Cup trustees in 1947 to take full control of the trophy, allowing the NHL to reject challenges from other leagues that may have wished to play for the Cup.
The first NHL All-Star Game was held in 1934 to benefit Ace Bailey, whose career ended on a vicious hit by Eddie Shore. The second was held in 1937 in support of Howie Morenz's family when he died of a coronary embolism after breaking his leg during a game. His teammate Aurel Joliat said that Morenz "died of a broken heart" when he learned he would never play hockey again. Maurice "Rocket" Richard became the first player to score 50 goals, doing so in a 50 game season. Ten years later he was suspended for the 1955 Stanley Cup playoffs for punching a linesman, an incident that led to the Richard Riot. He returned to lead the Canadiens to five consecutive titles between 1956 and 1960, a record no team has matched. Willie O'Ree broke the league's colour barrier on January 18, 1958 when he made his debut with the Boston Bruins and became the first black player in league history.
Post-Original Six expansion.
By the mid-1960s, the desire for a network television contract in the U.S., and concerns that the Western Hockey League was planning to declare itself a major league and challenge for the Stanley Cup, spurred the league to undertake its first expansion since the 1920s. The league doubled in size for the 1967–68 season, adding the Los Angeles Kings, Minnesota North Stars, Philadelphia Flyers, Pittsburgh Penguins, California Seals and St. Louis Blues. Canadian fans were outraged that all six teams were placed in the United States, and the league responded by adding the Vancouver Canucks in 1970 along with the Buffalo Sabres, who are located on the U.S.-Canadian border. Two years later, the emergence of the newly founded World Hockey Association (WHA) led the league to add the New York Islanders and Atlanta Flames to keep the rival league out of those markets. In 1974, the Washington Capitals and Kansas City Scouts were added, bringing the league up to 18 teams.
The National Hockey League fought the WHA for players, losing 67 to the new league in its first season of 1972–73, including Bobby Hull, who signed a ten-year, $2.5 million contract with the Winnipeg Jets, the largest in hockey history at the time. The league attempted to block the defections in court, but a counter-suit by the WHA led to a Philadelphia judge ruling the NHL's reserve clause to be illegal, thus eliminating the elder league's monopoly over the players. Seven years of battling for players and markets financially damaged both leagues, leading to a 1979 merger agreement that saw the WHA cease operations while the NHL absorbed the Winnipeg Jets, Edmonton Oilers, Hartford Whalers and Quebec Nordiques. The owners initially rejected this merger agreement by one vote, but a massive boycott of Molson Brewery products by fans in Canada caused the Montreal Canadiens, which was owned by Molson, to reverse its position, along with the Vancouver Canucks. In a second vote the plan was approved.
Wayne Gretzky played one season in the WHA for the Indianapolis Racers (eight games) and the Edmonton Oilers (72 games) before the Oilers joined the National Hockey League for the 1979–80 season. Gretzky went on to lead the Oilers to four Stanley Cup championships in 1984, 1985, 1987 and 1988, and set single season records for goals (92 in 1981–82), assists (163 in 1985–86) and points (215 in 1985–86), as well as career records for goals (894), assists (1,963) and points (2,857). He was traded to the Kings in 1988, a deal that dramatically improved the league's popularity in the United States, and provided the impetus for the 1990s expansion cycles that saw the addition of nine teams: the San Jose Sharks, Tampa Bay Lightning, Ottawa Senators, Mighty Ducks of Anaheim, Florida Panthers, Nashville Predators, Atlanta Thrashers, and in 2000 the Minnesota Wild and Columbus Blue Jackets.
Labour issues.
There have been four league-wide work stoppages in league history, all happening since 1992.
The first was a strike by the National Hockey League Players' Association in April 1992 which lasted for ten days, but the strike was settled quickly and all affected games were rescheduled. A lockout at the start of the 1994–95 season forced the league to reduce the schedule from 84 games to just 48, with the teams playing only intra-conference games during the reduced season. The resulting collective bargaining agreement (CBA) was set for renegotiation in 1998 and extended to September 15, 2004.
With no new agreement in hand when the contract expired on September 15, 2004, league commissioner Gary Bettman announced a lockout of the players union and closed the league's head office. The league vowed to install what it dubbed "cost certainty" for its teams, but the Players' Association countered that the move was little more than a euphemism for a salary cap, which the union initially said it would not accept. The lockout shut down the league for 310 days, the longest in sports history. The NHL became the first professional sports league to lose an entire season. A new collective bargaining agreement was eventually ratified in July 2005, including a salary cap. The agreement had a term of six years with an option of extending the collective bargaining agreement for an additional year at the end of the term, allowing the league to resume as of the 2005–06 season.
On October 5, 2005, the first post-lockout season took to the ice with 15 games, and consequently all 30 teams. Of those 15 games, 11 were in front of sell-out crowds. The NHL received record attendance in the 2005–06 season: 20,854,169 fans, an average of 16,955 per game, a 1.2% increase over the previous mark held in the 2001–02 season. Also, the Montreal Canadiens, Calgary Flames, Colorado Avalanche, Minnesota Wild, Tampa Bay Lightning, and the Vancouver Canucks sold out all of their home games; all six Canadian teams played to 98% capacity or better at every home game. 24 of the 30 clubs finished even or ahead of their 2003–04 mark. The Pittsburgh Penguins had the highest increase at 33%, mainly because of 18-year-old first overall draft pick Sidney Crosby. After losing a season to a labour dispute in 2005, attendance figures for league teams returned to solid ground; the League's TV audience was slower to rebound because of American cable broadcaster ESPN's decision to drop the sport from its schedule. The league's post-lockout agreement with NBC gave the league a share of revenue from each game's advertising sales, rather than the usual lump sum paid up front for game rights. The league's annual revenues were estimated at approximately $2.27 billion.
At midnight September 16, 2012, the labour pact expired, and the league again locked out the players. The owners proposed reducing the players' share of hockey-related revenues from 57 percent to 47 percent. All games were cancelled up to January 14, 2013, as well as the 2013 NHL Winter Classic and the 2013 NHL All-Star Weekend. A tentative agreement was reached on January 6, 2013, on a ten-year deal. On January 12, the league and the Players' Association signed a memorandum of understanding on the new deal, allowing teams to begin their training camps on January 13, with a shortened 48-game season schedule that began on January 19.
Player safety issues.
Player safety has become a major issue within the past five years and concussions, which result from a hard hit to the head, have been the biggest cause. With recent studies showing how concussions can affect retired players and how it has decreased their quality of life after retirement, concussions have become a very important topic of debate when it comes to player safety issues. This had significant effects on the league as elite players were being taken out of the game, such as Sidney Crosby being sidelined for approximately 10 and a half months, which adversely affected the league's marketability. As a result, in December 2009, Brendan Shanahan was hired to replace Colin Campbell and given the role of Senior Vice-President of Player Safety. Shanahan began to hand out suspensions on high profile perpetrators responsible for dangerous hits, such as Raffi Torres receiving 25 games for his hit on Marian Hossa.
To aid with removing high speed collisions on icing, which had led to several potential career ending injuries such as Hurricanes' Defencemen Joni Pitkanen, the league mandated hybrid no-touch icing for the 2013–14 NHL season.
On November 25, 2013, ten former players, Gary Leeman, Rick Vaive, Brad Aitken, Darren Banks, Curt Bennett, Richie Dunn, Warren Holmes, Bob Manno, Blair Stewart and Morris Titanic sued the league for negligence on protecting players from concussions. The suit came three months after the NFL agreed to pay former players US$765 million due to a player safety lawsuit.
Organizational structure.
The Board of Governors is the ruling and governing body of the league. In this context, each team is a member of the league, and each member appoints a Governor (usually the owner of the club), and two alternates to the Board. The current chairman of the Board is Boston Bruins owner, Jeremy Jacobs. The Board of Governors exists to establish the policies of the league, and to uphold its constitution. Some of the responsibilities of the Board of Governors include:
The Board of Governors meets twice per year, in June and December, with the exact date and place to be fixed by the Commissioner.
Executives.
The chief executive of the league is Commissioner Gary Bettman. Some of the principal decision makers who serve under the authority of the commissioner include:
Teams.
Devils 
Islanders 
Rangers 
Flyers 
Penguins 
Bruins 
Sabres 
Canadiens 
Senators 
Maple Leafs 
Jets 
Hurricanes 
Panthers 
Lightning 
Capitals 
Blackhawks 
Blue Jackets 
Red Wings 
Predators 
Blues 
Flames 
Avalanche 
Oilers 
Wild 
Canucks 
Ducks 
Stars 
Kings 
Coyotes 
Sharks 
The National Hockey League originated in 1917 with four Canadian teams, which after a tumultuous first quarter century, found stability in the Original Six era spanning 1942–67 with four franchises in the United States joining two Canadian clubs. Through a sequence of team expansions, reductions, and relocations the NHL currently consists of 30 teams, 23 of which are based in the United States and seven in Canada. The Montreal Canadiens are the most successful franchise with 24 Stanley Cup championships (23 as an NHL team, 1 as an NHA team). Of the four major professional sports leagues in North America, the Montreal Canadiens are surpassed in the number of championships only by the New York Yankees of Major League Baseball, who have three more. The next most successful franchise is the Toronto Maple Leafs with 13 Stanley Cup championships, but they have not won one since 1967. The Detroit Red Wings, with 11 Stanley Cup championships, are the most successful American franchise. The longest streak of winning the Stanley Cup in consecutive years is five, held by the Montreal Canadiens from 1955–56 to 1959–60; the New York Islanders (1980–1983) and the Montreal Canadiens (1976–1979) have four-year championship streaks. The 1977 edition of the Montreal Canadiens, the second of four straight Stanley Cup champions, was named by ESPN as the second greatest sports team of all-time.
Of all the major leagues in North America, the NHL is the only league to field teams that play in two countries' capital cities, Ottawa, Ontario and Washington, D.C.
The current 30-team NHL organization divides the teams into two conferences: the Eastern Conference and the Western Conference. Each conference is split into two divisions: the Eastern Conference contains 16 teams (eight per division), while the Western Conference has 14 teams (seven per division). The current organization had roots in the 1998–99 season when a league realignment added two divisions to bring the total number of divisions to six; the former team alignment began with the 2000–01 season when the Minnesota Wild and the Columbus Blue Jackets joined the league as expansion teams.
Sixteen of the league's thirty teams (the entire Eastern Conference) are located in the Eastern Time Zone. On the other hand, the Western Conference has six teams in the Central Time Zone, and 4 each in the Mountain and Pacific Time Zones. Up until the 2012–13 season, the Detroit Red Wings and Columbus Blue Jackets were the only Eastern Time teams in the Western Conference, and Winnipeg Jets was the only non-Eastern Time team in the Eastern Conference (a temporary alignment resulting from the franchise's move out of Atlanta in 2011).
Realignment.
The relocation of the former Atlanta Thrashers franchise to become the current Winnipeg Jets in 2011 prompted the league to discuss realignment. On December 5, 2011, the Board of Governors approved a conference realignment plan that would eliminate the current six-division setup and move into a four-conference structure.<ref name="http://www.nhl.com/ice/news.htm?id=604852"></ref> Under the plan, which was designed to better accommodate the effects of time zone differences, each team would have played 36 or 38 intra-conference games, depending on whether it is in a seven- or eight-team conference, and two games (home and road) against each non-conference team. On January 6, 2012, the league announced that the NHL Player's Association had rejected the proposed realignment, citing concerns about fairness, travel and the inability to see a draft schedule before approving, and that as a result, it would not implement the realignment until at least 2013–14.
Upon NHLPA rejection of the previous realignment, a new joint NHL-NHLPA plan was proposed in February 2013 as a modification of the previous plan with both the Columbus Blue Jackets and Detroit Red Wings moving to the East and the Winnipeg Jets moving to the West. This revised plan also adjusted the previously proposed four-conference system to a four-division, two-conference system, with the Eastern Conference consisting of two eight-team divisions, and the Western Conference consisting of two seven-team divisions. A new playoff format was also introduced to accommodate the new proposal, with the top three teams in each division making the playoffs along with two wild-cards in each conference (for a total of 16 playoff teams). The NHLPA officially gave its consent to the NHL's proposed realignment plan on March 7, and then the NHL's Board of Governors approved the realignment and the new playoff format on March 14, to be implemented prior to the 2013–14 season. The league then announced the names of the divisions on July 19: the two eight-team divisions in the Eastern Conference are the Atlantic Division and the Metropolitan Division, and the two seven-team divisions in the Western Conference are the Central Division and the Pacific Division.
List of teams.
</dl>
Defunct and relocated teams.
Nineteen NHL teams have either folded or relocated. The first team to disband was the Montreal Wanderers in 1918, following the destruction of their arena by fire just four games into the season. The blaze destroyed all the team's equipment, and as a consequence the players were dispersed among the three remaining teams. The first team to relocate was the Quebec Athletic Club, who relocated to Hamilton, Ontario in 1920 to become the Hamilton Tigers. NHL president Frank Calder stripped the franchise from owner Mike Quinn and sold it to a Hamilton-based company. Three franchises succumbed to the economic pressures of the Great Depression: the Philadelphia Quakers, St. Louis Eagles, and Montreal Maroons. The Brooklyn Americans were the last team to fold in the NHL. In the early 1940s, the franchise was struggling financially, and was suspended prior to the #redirect due to a lack of players during World War II. The franchise formally ceased operations in 1946, and their demise began a period in the league's history known as the "Original Six" that would last for the next twenty-one seasons.
The 1967 NHL expansion added six teams, but one of those teams, the California Golden Seals, moved to Cleveland, becoming the Cleveland Barons, before merging with the Minnesota North Stars in 1978 when both clubs were on the verge of folding. Kansas City relocated to Denver after only 2 years, becoming the Colorado Rockies, who subsequently moved to New Jersey (Devils) in 1982. With six more expansion teams in the 1970s, and the 1979 NHL–WHA merger, the league had 21 teams at the end of the decade. Three of the four teams from the merger have since relocated to other cities: the Quebec Nordiques, the original Winnipeg Jets, and the Hartford Whalers. The Quebec Nordiques moved to Denver becoming the Colorado Avalanche in 1995, the Winnipeg Jets moved to Phoenix becoming the Coyotes in 1996, and the Hartford Whalers moved to Greensboro, North Carolina, becoming the Carolina Hurricanes in 1997. The Atlanta Flames moved to Calgary in 1980.
During the 2011 playoffs, the Atlanta Thrashers franchise was acquired by True North Sports and Entertainment, who moved the team to Winnipeg for 2011–12, giving the team the revived name Winnipeg Jets.
Game.
Each National Hockey League regulation game is played between two teams and is 60 minutes long. The game is composed of three 20-minute periods with an intermission of either 15½ or 17 minutes (if nationally televised) between periods. Television timeouts are taken at the first stoppage of play after 6, 10, and 14 minutes of elapsed time of each of the three regulation periods, unless a power play is in session at the time or the first stoppage is the result of a goal scored. In these cases, the timeout will occur at the first stoppage after the penalty expires or the next stoppage after the goal, respectively. A rule that was introduced in the 2007–08 season was that if the first stoppage of play after said time periods is an icing call, the TV timeout will not occur. This rule was added shortly after the league instituted a rule that disallows the team who ices the puck to substitute their players on the ice at the time of the icing. The rule was added so that a TV timeout would not compromise the inability to be substituted. At the end of the 60-minute regulation time, the team with the most goals wins the game. If a game is tied after regulation time, overtime ensues. During the regular season, overtime is a five-minute, four-player on four-player sudden-death period, in which the first team to score a goal wins the game.
Beginning in the 2005–06 season, if the game is still tied at the end of overtime, the game enters a shootout. Three players for each team in turn take a penalty shot. The team with the most goals during the three-round shootout wins the game. If the game is still tied after the three shootout rounds, the shootout continues but becomes sudden-death. Whichever team ultimately wins the shootout is awarded a goal in the game score and thus awarded two points in the standings. The losing team in overtime or shootout is awarded only one. Shootout goals and saves are not tracked in hockey statistics; shootout statistics are tracked separately.
There are no shootouts during the Playoffs. Instead, multiple sudden-death, 20-minute five-on-five periods are played until one team scores. While in theory a game could continue indefinitely, only four games have reached five overtime periods, two of those have reached six, and none have gone beyond six. There are no television time-outs during playoff overtime periods; the only break is to clean the loose ice at the first stoppage after the period is halfway finished.
Hockey rink.
National Hockey League games are played on a rectangular hockey rink with rounded corners surrounded by walls and Plexiglas. It measures 200 ft by 85 ft in the NHL, approximately the same length but much narrower than International Ice Hockey Federation standards. The centre line divides the ice in half, and is used to judge icing violations. There are two blue lines that divide the rink roughly into thirds, delineating one neutral and two attacking zones. Near the end of both ends of the rink, there is a thin red "goal line" spanning the width of the ice, which is used to judge goals and icing calls.
Starting in the 2005–2006 season, after testing in the American Hockey League, a trapezoidal area behind each goal net has been introduced. The goaltender can play the puck only within the trapezoid or in front of the goal line; if the goaltender plays the puck behind the goal line and outside the trapezoidal area, a two-minute minor penalty for delay of game is assessed by the referees. The rule is unofficially nicknamed the "Martin Brodeur rule".
Since the 2013–2014 season, the league trimmed the goal frames by 4 in on each side and reduced the size of the goalies' leg pads.
Rules.
The National Hockey League's rules are one of the two standard sets of rules in the world. The rules themselves have evolved directly from the first organized indoor ice hockey game in Montreal in 1875, updated by subsequent leagues up to 1917, when the NHL adopted the existing NHA set of rules. The NHL's rules are the basis for rules governing most ice hockey leagues in North America. Infractions of the rules, such as offside and icing, lead to a stoppage of play and subsequent face-offs, while more serious infractions leading to penalties to the offending teams. The league also determines the specifications for playing equipment used in its games.
The league has regularly modified its rules to counter perceived imperfections in the game. The penalty shot was adopted from the Pacific Coast Hockey Association to ensure players were not being blocked from opportunities to score. For the 2005–06 season, the league changed some of the rules regarding being offside. First, the league removed the "offside pass" or "two-line pass" rule, which required a stoppage in play if a pass originating from inside a team's defending zone was completed on the offensive side of the centre line, unless the puck crossed the line before the player. Furthermore, the league reinstated the "tag-up offside" which allows an attacking player a chance to get back onside by returning to the neutral zone. The changes to the offside rule were among several rule changes intended to increase overall scoring, which had been in decline since the expansion years of the mid-nineties and the increased prevalence of the neutral zone trap. Since 2005, when a team is guilty of icing the puck they are not allowed to make a line change or skater substitution of any sort before the following face-off (except to replace an injured player or re-install a pulled goaltender). Since 2013, the league has used "hybrid icing", where a linesman stops play due to icing if a defending player (other than the goaltender) crosses the imaginary line that connects the two face-off dots in their defensive zone before an attacking player is able to. This was done to counter a trend of player injury in races to the puck.
The league's rules differ from the rules of the International Ice Hockey Federation (IIHF), as used in tournaments such as the Olympics, which were themselves derived from the Canadian amateur ice hockey rules of the early 20th century. In the NHL, fighting leads to "major penalties" while IIHF rules, and most amateur rules, call for the ejection of fighting players. Usually a penalized team cannot replace a player that is penalized on the ice and is thus short-handed for the duration of the penalty, but if the penalties are coincidental, for example when two players fight, both teams remain at full strength. Also, unlike minor penalties, major penalties must be served to their full completion, regardless of number of goals scored during the power play. The NHL and IIHF differ also in playing rules, such as icing, the areas of play for goaltenders, helmet rules, officiating rules, timeouts and play reviews.
The league also imposes a conduct policy on its players. Players are banned from gambling and criminal activities have led to the suspension of players. The league and the Players' Association agreed to a stringent anti-doping policy in the 2005 bargaining agreement. The policy provides for a twenty-game suspension for a first positive test, a sixty-game suspension for a second positive test, and a lifetime suspension for a third positive test.
Season structure.
The National Hockey League season is divided into an exhibition season (September), a regular season (from the first week in October through early to mid April) and a postseason (the Stanley Cup playoffs). During the exhibition season, teams may play other teams from the league. They also often compete against European clubs, such as clubs from the Russian Kontinental Hockey League (KHL). During the regular season, clubs play each other in a predefined schedule. The Stanley Cup playoffs, which go from April to the beginning of June, is an elimination tournament where two teams play against each other to win a best-of-seven series in order to advance to the next round. The final remaining team is crowned the Stanley Cup champion. Since 2007, the NHL regular season has begun in Europe while teams not involved complete their pre-season exhibition schedule.
In the regular season, each team plays 82 games: 41 games each of home and road. Eastern teams play 30 games in its own geographic division— four or five against each one of their seven other divisional opponents—and 24 games against the eight remaining non-divisional intra-conference opponents—three games against every team in the other division of its conference. Western teams play 28 or 29 games in its own geographic division-four or five against each one of their six other divisional opponents-and 21 or 22 games against the seven remaining non-divisional intra-conference opponents-three games against every team in the other division of its conference, with one cross-division intra-conference match-up occurring in four games (one team from each division plays only 28 intra-division games in a given season, and rotates every season). All teams play every team in the other conference twice-home and road. For three seasons between 2005 and 2008, teams played 32 games within their division—eight games against each team in the division—and 10 inter-conference games—one game against each team in two of the three divisions in the opposite conference. The two divisions faced from the opposite conference were rotated every year, much like interleague play in Major League Baseball. As with the former system, each team played four games against each one of the other ten teams in its conference outside of its division.
The league's regular season standings are based on a point system instead of winning percentages. Points are awarded for each game, where two points are awarded for a win, one point for losing in overtime or a shootout, and zero points for a loss in regulation. At the end of the regular season, the team that finishes with the most points in each division is crowned the division champion. The league's overall leader is awarded the Presidents' Trophy.
Since 2014 the top three teams in each division plus the two wild-card teams in the conference with the next highest number of points, for a total of eight teams in each conference, qualify for the playoffs. The division winner with the best record in the conference plays the lowest-seeded wild-card team and the other division winner plays the highest-seeded wild-card (wild-card teams may cross over to another division within the conference), and the next two teams with the next best records in each division are seeded 2nd and 3rd. The Stanley Cup playoffs is an elimination tournament, where the teams are grouped in pairs to play best-of-seven series, the winners moving on to the next round. The first round of the playoffs, or conference quarterfinals, consists of the first seed playing the fourth seed, and the second playing the third, division-wise. In the second round, or conference semifinals, the four remaining teams in the conference play each other. In the third round, the conference finals, the two remaining teams play each other, with the conference champions proceeding to the Stanley Cup Final.
In all rounds the higher-ranked team is awarded home-ice advantage. Four of the seven games are played at this team's home venue—the first and second, and, when necessary, the fifth and seventh games—with the other games played at the lower-ranked team's home venue. In the Stanley Cup Final, the team with the most points (or in case of a tie, most wins) during the regular season is given home-ice advantage, regardless of where each team ranks in their own conference.
Entry Draft.
The annual NHL Entry Draft consists of a seven-round off-season draft held in late June. Amateur players from junior, collegiate, or European leagues are eligible to enter the Entry Draft. The selection order is determined by a combination of the standings at the end of the regular season, playoff results, and a draft lottery. The 14 teams that did not qualify for the playoffs are entered in a weighted lottery to determine the initial draft picks in the first round, with the 30th-place team having the best chance of winning the lottery. Once the lottery determines the initial draft picks, the order for the remaining non-playoff teams is determined by the standings at the end of the regular season. For those teams that did qualify for the playoffs, the draft order is then determined by the order in which they were eliminated, with the Stanley Cup winner getting the 30th and last pick, and the runner-up is given the 29th pick.
Trophies and awards.
The National Hockey League presents a number of trophies each year. The most prestigious team award is the Stanley Cup, which is awarded to the league champion at the end of the Stanley Cup playoffs. The team that has the most points in the regular season is awarded the Presidents' Trophy. There are also numerous trophies that are awarded to players based on their statistics during the regular season; they include, among others, the Art Ross Trophy for the league scoring champion (goals and assists), the Maurice "Rocket" Richard Trophy for the goal-scoring leader, and the William M. Jennings Trophy for the goalkeeper(s) for the team with the fewest goals against them.
The other player trophies are voted on by the Professional Hockey Writers' Association or the team general managers. These individual awards are presented at a formal ceremony held in late June after the playoffs have concluded. The most prestigious individual award is the Hart Memorial Trophy which is awarded annually to the Most Valuable Player; the voting is conducted by members of the Professional Hockey Writers Association to judge the player who is the most valuable to his team during the regular season. The Vezina Trophy is awarded annually to the person deemed the best goalkeeper as voted on by the general managers of the teams in the NHL. The James Norris Memorial Trophy is awarded annually to the National Hockey League's top defenceman, the Calder Memorial Trophy is awarded annually to the top rookie, and the Lady Byng Memorial Trophy is awarded to the player deemed to combine the highest degree of skill and sportsmanship; all three of these awards are voted on by members of the Professional Hockey Writers Association.
In addition to the regular season awards, the Conn Smythe Trophy is awarded annually to the most valuable player during the NHL's Stanley Cup playoffs. Furthermore, the top coach in the league wins the Jack Adams Award as selected by a poll of the National Hockey League Broadcasters Association. The National Hockey League publishes the names of the top three vote getters for all awards, and then names the award winner during the NHL Awards Ceremony.
One interesting aspect for the trophies in the NHL is that the same trophy is reused every year for each of its awards. The Stanley Cup, much like its CFL counterpart, is unique in this aspect, as opposed to the Vince Lombardi Trophy, Larry O'Brien Trophy, and Commissioner's Trophy, which have new ones made every year for that year's champion. Despite only one trophy being used, the names of the teams winning and the players are engraved every year on the Stanley Cup. The same can also be said for the other trophies reissued every year.
Players, coaches, officials, and team builders who have had notable careers are eligible to be voted into the Hockey Hall of Fame. Players cannot enter until three years have passed since their last professional game, the shortest such time period of any major sport. One unique consequence has been Hall of Fame members (specifically, Gordie Howe, Guy Lafleur, and Mario Lemieux) coming out of retirement to play once more. If a player was deemed significant enough, the three-year wait would be waived; only ten individuals have been honoured in this manner. In 1999, Wayne Gretzky joined the Hall and became the last player to have the three-year restriction waived. After his induction, the Hall of Fame announced that Gretzky would be the last to have the waiting period waived.
Current season leaders.
The top five point scorers in the 2014–15 season were Jamie Benn (87), John Tavares (86), Sidney Crosby (84), Alex Ovechkin and Jakub Voracek (81 each). The top goal scorers were Ovechkin (53), Steven Stamkos (43), Rick Nash (42), Tavares (38), Max Pacioretty, Joe Pavelski, Tyler Seguin and Vladimir Tarasenko (37 each). The top five scoring defencemen were Erik Karlsson (66), Brent Burns and P.K. Subban (60 each), Dennis Wideman (56), John Carlson and Roman Josi (55 each). The top goaltenders (by wins) were Carey Price (44), Braden Holtby and Pekka Rinne (41 each), Ben Bishop (40), and Jaroslav Halak (38).
Origin of players.
In addition to Canadian and American born and trained players, who have historically composed a large majority of NHL rosters, the NHL also draws players from an expanding pool of other nations where organized and professional hockey is played. A steady stream of European players began entering the league in the 1970s, continuing into the 1980s. Most of the first wave of Europeans came from Sweden and Finland, with a small number of defectors from the Soviet Bloc. Since the collapse of the Soviet Bloc, political/ideological restrictions on the movement of hockey players from this region have disappeared, leading to a large influx of players mostly from Czech Republic, Slovakia and Russia into the NHL. Swedes, Finns, and other Western Europeans, who were always free to move to North America, came to the league in greater numbers than before. Many of the league's top players today come from these European countries, including: Daniel Alfredsson, Erik Karlsson, Henrik Sedin, Daniel Sedin, Henrik Lundqvist, Jaromir Jagr, Patrik Elias, Zdeno Chara, Pavel Datsyuk, Evgeni Malkin, and Alexander Ovechkin. European players were drafted and signed by NHL teams in an effort to bring in more "skilled offensive players", although recently there has been a decline in European players as more American players enter the league. The addition of European players changed the style of play in the NHL and European style hockey has been integrated into the NHL game. Conversely Canadian coaches and the Canadian style of play have been embraced by many European countries. Because of the continued success of Canadian teams in world tournaments many other countries are trying to model their development programs after Hockey Canada's.
Since 1998, the league has voluntarily suspended its all star game and expanded the traditional all star break during Winter Olympic years to allow NHL players an opportunity to represent their respective countries. The 2010 Winter Olympics were held in Vancouver, an NHL city. Conversely, the IIHF World Championships are held at the same time as the Stanley Cup Playoffs. Thus, NHL players generally only join their respective country's team in the World Championships if their respective NHL team has been eliminated from Stanley Cup contention.
The NHL has players from 18 different countries, with the majority (52.0 percent during the 2007–08 NHL season) coming from Canada. The following table shows the origins of every player (skaters and goaltenders) who played an NHL regular season game in the given year. The table follows the Hockey Hall of Fame convention of classifying players by the currently existing countries in which their birthplaces are located, without regard to their citizenship or where they were trained.
Television and radio.
Canada.
Broadcasting rights in Canada have historically included the CBC's "Hockey Night in Canada" ("HNIC"), a long-standing Canadian tradition dating to 1952, and even prior to that on radio since the 1920s. Other previous Canadian broadcasters have included CTV, Global, TSN, Sportsnet; and French-language broadcasts on SRC, RDS and TVA Sports.
The current national television and digital rightsholder is Rogers Communications, under a 12-year deal valued at C$5.2 billion which began in the 2014–15 season, and replaced both CBC and Bell Media as the national broadcast and cable television rightsholders respectively. National English-language coverage of the NHL is carried primarily by Rogers' Sportsnet group of specialty channels; Sportsnet holds an exclusive window for games played on Wednesday nights. "Hockey Night in Canada" was maintained and expanded under the deal, airing up to seven games nationally on Saturday nights throughout the regular season across CBC, the Sportsnet networks, Rogers-owned television network City, and FX Canada. While CBC maintains Rogers-produced NHL coverage during the regular season and playoffs through a time-brokerage agreement with the company, Rogers assumes editorial control and the ownership of any advertising revenue from the telecasts. City also airs a Sunday night game of the week, "Rogers Hometown Hockey", which features a pre-game show originating from various Canadian communities. Sportsnet's networks also air occasional games involving all-U.S. matchups.
Under a sub-licensing agreement with Rogers, Quebecor Media holds national French-language rights to the NHL, with all coverage airing on its specialty channel TVA Sports. TVA Sports' flagship broadcasts on Saturday nights focus primarily on the Montreal Canadiens.
Games that are not broadcast as part of the national rights deal are broadcast regionally by Sportsnet's regional networks, TSN, and RDS; Sportsnet holds regional rights to the Montreal Canadiens (English only), Toronto Maple Leafs (split with TSN), Calgary Flames, Edmonton Oilers, and Vancouver Canucks, while TSN holds rights to the Ottawa Senators, Winnipeg Jets, and Toronto Maple Leafs (split with Sportsnet). RDS holds regional French-language rights to the Canadiens and Senators. Regional games are subject to blackout for viewers outside of each team's designated market.
United States.
Historically, the NHL has never fared well on American television in comparison to the other American professional leagues. The league's American broadcast partners have been in flux for decades, ranging from such networks as CBS, SportsChannel America, the USA Network, Fox, ABC, and ESPN.
National U.S. television rights are currently held by NBCUniversal; its current 10-year, US$2 billion contract, which began in the 2011-12 season, extended and unified rights deals that were first established in the 2005-06 season, when Comcast acquired cable rights to the league for Outdoor Life Network (later known as Versus), and NBC Sports acquired broadcast television rights to the league under a revenue-sharing agreement. In January 2011, Comcast acquired NBC's parent company NBC Universal, and later negotiated a new 10-year deal with the NHL, worth nearly US$2 billion. Comcast also announced the re-branding of Versus as the NBC Sports Network (NBCSN). Under this contract, NBCSN usually airs at least two regular season games per week, while NBC airs afternoon games on selected weekends. NBCUniversal holds exclusive rights to Wednesday night games, all games televised by the NBC network, and every game in the Stanley Cup Playoffs beginning in the second round. Coverage of the playoffs and the Finals is split between the two networks, with other games shown on CNBC, USA Network, and NHL Network.
As in Canada, games not broadcast nationally are aired regionally within a team's home market, and are subject to blackout outside of them. These broadcasters include regional sports network chains such as Comcast SportsNet, Fox Sports Networks, MSG Network, and Root Sports. Certain national telecasts on NBCSN, such as certain regular season games and first round playoff games, are non-exclusive, and may also air in tandem with telecasts of the game by local broadcasters. However, national telecasts of these games are blacked out in the participating teams' markets to protect the local broadcaster.
XM Satellite Radio is the official satellite radio broadcaster of the NHL, as of July 1, 2007. Between September 2005 and June 2007, the NHL's broadcasting rights were shared with both XM and Sirius Satellite Radio and were broadcast on just Sirius before the NHL lockout. XM used to broadcast more than 80% of NHL games, including all the playoffs and finals. Starting with the 2007–08 season, XM broadcasts every game.
NHL Network.
The league co-owns the NHL Network, a television specialty channel devoted to the NHL. There are two versions, one for Canadian viewers and a separate one for those in the United States. The NHL Network is a joint venture with other media companies. CTV Specialty Television and Insight Sports are both minority owners of the Canadian version, while NBCUniversal is a minority owner of the American version.
The NHL Network's signature show is "NHL Tonight" (formerly "NHL on the Fly"), which covers NHL news, highlights, interviews, and analysis. The NHL Network also airs live games, with the Canadian version primarily focusing on those featuring Canadian teams and the American version focusing on American teams. These are usually simulcasts of one of the team's regional broadcaster. The American NHL Network may also simulcast a CBC game televised nationally in Canada, and the Canadian NHL network may also simulcast an NBC game televised nationally in the U.S.
Out-of-market sports packages.
The NHL operates two subscription-based services allowing access to live, out-of-market games; NHL Centre Ice in Canada and NHL Center Ice in the United States offer access to out-of-market feeds of games through a cable or satellite television provider.
The league also offers "NHL GameCenter Live" (branded as "Rogers NHL GameCentre Live" in Canada), which allows the streaming of out-of-market games over the internet, either through the NHL website, smartphones and tablets, digital media players, smart TVs, and video game consoles. In the United States, GameCenter Live does not carry national games (which are offered through the NBC Sports Live Extra service to authenticated pay television subscribers) or in-market games (online availability varies by broadcaster).
Per its exclusive national television and digital rights contract, Rogers Communications took over Canadian distribution and marketing of both the out-of-market TV and the internet services in Canada as of the 2014–15 season. A number of changes were made to the internet service, which was re-branded as "Rogers NHL GameCentre Live". Canadian users access the service using a "MyRogers" login account instead of one directly on NHL.com. It now also offers access to national games, along with in-market streaming of regional games for teams that Sportsnet holds broadcast rights to; as of the 2014–15 season, these include almost all NHL teams in Canada, aside from the Ottawa Senators and Winnipeg Jets, whose broadcast rights are held by TSN. As part of the transition, Rogers also issued a free trial of the service, lasting through the start of 2015, to all Rogers cable and mobile internet subscribers. The service offers "GamePlus", a component featuring alternate camera angles, such as net cams, point-of-view cams, and sky cams. The sky cam are currently only available for Air Canada Centre games, but the remaining Canadian arenas will be equipped for it in the future. GamePlus features are only available to GameCentre Live subscribers who are subscribed to Rogers' cable, internet, or wireless services.
International.
Outside of Canada and the United States, NHL games are broadcast across Europe (excluding the UK and Scandinavia) and the Middle East on ESPN America, which takes feeds from NBC, Rogers, and teams' regional broadcasts. In the UK Premier Sports has the rights to the NHL and show 15 games per week. Fox Sports in Australia, on Viasat Sport in Norway, Finland, and Denmark on Viasat Hockey in Sweden, in the Czech Republic on NovaSport or FandaTV and in Portugal on SportTV. In the Americas, NHL games are broadcast across Mexico, Central America and Dominican Republic on SKY México. Stanley Cup games can also be viewed in New Zealand on Sky Sport. In Brazil (South America starting in the 2015–16 season, the games are broadcast on ESPN International.
The aforementioned NHL Gamecenter Live on NHL.com is also available for people outside Canada and the United States to watch games online, but blackout restrictions apply for example in the UK where they are not allowed to show live games that are being shown on Premier Sports.
Popularity.
The NHL is considered one of the four major professional sports leagues in North America, along with Major League Baseball, the National Football League, and the National Basketball Association. The league is very prominent in Canada, where hockey is the most popular of these four major sports as alongside CFL. Overall, hockey has the smallest total fan base of the four leagues, the smallest revenue from television, and the least sponsorship.
While the NHL does not hold one of the largest fan bases in North America, it does hold one of the most affluent fan bases. Studies by the Sports Marketing Group conducted from 1998 to 2004 show that the NHL's fan base is much more affluent than that of the PGA Tour. A study done by the Stanford Graduate School of Business in 2004, found that NHL fans in America were the most educated and affluent of the four major leagues. They were also found to be substantially more computer literate than the other fans. Further it noted that season-ticket sales were more prominent in the NHL than the other three because of the ability of the NHL fan to purchase them, something more out of reach for fans of the other leagues. According to Reuters in 2010, the largest demographic of NHL fans was highly sought after group males aged 18–34, who were also shown to be more "tech savvy" than most fans.
The NHL estimates that fully half of its fan base roots for teams in outside markets. Beginning in 2008, under the direction of Chief Operating Officer John Collins, the NHL began a shift toward using digital technology to market to fans to capitalize on this.
The debut of the Winter Classic, an outdoor regular season NHL game held on New Year's Day 2008, was a major success for the league. The game has since become a permanent staple of the NHL schedule. This, along with the transition to a national "Game of the Week" and an annual "Hockey Day in America" regional coverage, all televised on NBC, has helped increase the NHL's regular season television viewership in the United States. These improvements led NBC and the cable channel Versus to sign a shared ten-year broadcast deal (as their parent companies were merging), paying US$200 million per year for both American cable and broadcast rights; the deal will lead to further increases in television coverage on the NBC channels.
This has boosted viewership metrics for the NHL. The 2010 Stanley Cup playoffs saw the largest audience in the history of the sport "after a regular season that saw record-breaking business success, propelled in large part by the NHL's strategy of engaging fans through big events and robust digital offerings." This success has resulted in a 66 percent rise in NHL advertising and sponsorship revenue. Collins said "It was a great Stanley Cup run, really across every possible metric ... Our fans are consuming more hockey." Merchandise sales were up 22 percent and the number of unique visitors on the NHL.com website were up 17 percent during the playoffs after rising 29 percent in the regular season.
Charitable causes.
The NHL advocates for a number of causes throughout the season. During the days leading up to Remembrance Day (November 11, known as Veterans Day in the United States), in respect of the day, coaches and other NHL officials wear red poppy lapel pins. Hockey Fights Cancer is a joint initiative founded in December 1998 by the National Hockey League and the National Hockey League Players' Association to raise money and awareness for hockey's most important fight. It is supported by NHL Member Clubs, NHL Alumni, the NHL Officials' Association, Professional Hockey Trainers and Equipment Managers, corporate marketing partners, broadcast partners and fans.
References.
</dl>
Further reading.
</dl>

</doc>
<doc id="21810" url="http://en.wikipedia.org/wiki?curid=21810" title="Northern Michigan University">
Northern Michigan University

Northern Michigan University (NMU) is a four-year college public university established in 1899 and located in Marquette, in the Upper Peninsula of the U.S. state of Michigan. With enrollment of about 9,000 undergraduate and graduate students, Northern Michigan University is the Upper Peninsula's largest university. The university is known for its extensive wireless system that covers not only the campus, but the city of Marquette and the surrounding communities and its laptop program that issues laptops to all full-time students and faculty members The university is the alma mater of many prominent persons: Starbucks founder Howard Schultz; the Chief Financial Officer of Kraft Foods Teri List-Stoll; and championship winning College basketball coach Tom Izzo. Northern Michigan University is consistently listed as being among the most affordable universities in Michigan in terms of tuition, normally with only community colleges listing a lower rate.
History.
Northern Michigan University was established in 1899 by the Michigan Legislature as Northern State Normal School with the original purpose of providing teacher preparation programs in Michigan's then-wild and sparsely populated Upper Peninsula. When it opened its doors in 1899, NMU enrolled thirty-two students who were taught by six faculty members utilizing rented rooms in Marquette city hall. The original 20 acre campus-site at the corner of Presque Isle and Kaye Avenues was on land donated by local businessman and philanthropist John M. Longyear, whose namesake academic building, Longyear Hall, opened its doors to students in 1900.
Throughout the school's first half-century, education and teacher training was the primary focus of the small regional school. During this time, the school built the native sandstone buildings Kaye and Peter White Halls, as well as a manual training school adjacent to the campus buildings, J.D. Pierce School. Modest increases in enrollment resulted in several name changes throughout the years:
In 1963, through the adoption of a new state constitution in Michigan, Northern Michigan was designated a comprehensive university serving the diverse educational needs of Upper Michigan. During this time, enrollment at the small state school swelled (due in large part to the 1957 opening of the Mackinac Bridge, linking vehicle traffic between the Upper and Lower Peninsulas); and as a result, the campus expanded rapidly, roughly to the size it remains to this day. Accredited undergraduate and graduate degree programs are offered by the College of Arts and Sciences, the College of Business, the College of Health Sciences and Professional Studies.
Graduate education was inaugurated in 1928 when courses at the master’s degree level were offered in cooperation with the University of Michigan.
Academic profile.
NMU has four academic divisions:
Within these four academic divisions 180 undergraduate and graduate degree programs are offered.
Placement Data
Facilities.
NMU is a tobacco-free campus.
Instructional Spaces
In the 10 buildings where classes are held, there are at least 210 instructional spaces, each having a Wi-Fi signal strong enough to accommodate not only the instructor(s) but every student. 112 of these rooms seat at least 30 students. There are 63 general use classrooms which can be scheduled for multiple disciplines. All but 4 general-purpose rooms are smart classrooms fitted with technology for projecting images and sound from one’s laptop computer. There are 14 tiered classrooms, 10 of which are considered lecture halls with a seat-count of at least 90. The largest lecture hall, Jamrich 102, seats 501. There are 58 labs covering the gamut of arts and sciences. There are 28 departmental classrooms, 16 of which are “smart”. There are 3 distance learning facilities, the largest of which is Mead Auditorium which seats 100.
Art and Design
Berry Events Center
Cohodas Hall
Forest Roberts Theatre
Gries Hall
CB Hedgcock Building
Jamrich Hall
Lydia M. Olson Library
McClintock Hall
Physical Education Instructional Facility
Seaborg Science Complex
Superior Dome
The Jacobetti Center
Whitman Hall
Accreditation.
Northern Michigan University is accredited by the Commission on Institutions of Higher Education of the North Central Association of Colleges and Secondary Schools.
The Higher Learning Commission of the North Central Association of Colleges and Secondary Schools
All education programs are accredited by the Teacher Education Accreditation Council (TEAC). Other accreditations include the Accreditation Board for Engineering and Technology; American Alliance for Health, Physical Education, Recreation and Dance; American Chemical Society; American Society of Cytology; Commission on Accreditation of Allied Health Education Professionals (Surgical Technology); Committee on Accreditation for Respiratory Care of the Commission on Accreditation of Allied Health Education Programs; Council on Social Work Education; Department of Transportation Federal Aviation Administration Certification; International Association of Counseling Services, Inc.; Joint Review Committee on Education in Radiologic Technology; Michigan Department of Licensing and Regulation, State Board of Nursing; National Accrediting Agency for Clinical Laboratory Sciences; and the National Association of Schools of Music.
In addition, the nursing programs (practical nursing, baccalaureate, and master’s degrees) are fully approved by the Michigan Department of Licensing and Regulation, State Board of Nursing and the baccalaureate and master’s degrees are fully accredited by the Commission on Collegiate Nursing Education (CCNE).
The baccalaureate degree programs of the Walker L. Cisler College of Business are accredited by the Association to Advance Collegiate Schools of Business.
Technology.
The Teaching, Learning, and Communication (TLC) initiative places a notebook computer in the hands of every full-time undergraduate student and faculty. This initiative makes NMU one of the largest public university laptop programs in the world. Laptop program participants receive a new notebook computer every four years. Northern’s campus-wide effort for technological mastery helps NMU students compete in the high-tech global marketplace after they graduate. The university has national and international awards for its innovative work in the area of technology in higher education.
Vision of technology initiative.
Northern Michigan University's vision for education in the 21st century is a learning environment that embraces technology to enhance student access, promote the development of independent learners and encourage greater student-faculty communication and collaboration. To help achieve this vision, the university implemented a laptop program in the fall of 2000 that ensures students and faculty have a standard set of tools (hardware and software) that meet a majority of their computing and telecommunications needs, promotes communication and enables quality support. NMU is the first public university in Michigan — but one of many nationwide — to pursue the idea of a "laptop" campus.
Since 2002, most of the campus and surrounding city is covered by a wireless network. Although electronic documents are encouraged, networked printers are installed in various campus locations for hard copy documents.
In the fall of 2009 the university initiated a WiMAX connection initiative. This far-reaching technology has brought Internet access to students off and on campus. It was the first educational facility to create such an initiative and an example of Northern's vision for the future. Because of its popularity and recognition, the campus was visited by President Barack Obama on February 10, 2011, where he praised the development in wireless technology and promoted a National Wireless Initiative to bring high-speed Internet to 98% of the U.S. by 2016.
The university has a help desk and walk-in service center to handle laptop maintenance problems.
Cost to students.
NMU leases the laptop computers and issues them to full-time students on a three-year replacement cycle (a student will never have a computer more than three years old). Continuing students who pre-register for the following fall will be able to use the laptop through the summer at no additional charge.
Part-time students have the option to participate in the program. For a fee, part-time students may also check out the laptops from the library on a daily basis.
Additional aspects.
NMU continues to support and improve "specialty labs" as a function of need and resource availability. These are labs designed to meet the needs of specific academic programs that have special equipment and software needs (e.g., graphic design, computer science, GIS, CAD among others). The Center for Instructional Technology in Education (CITE) in the LRC supports faculty use of technology in instruction.
Athletics.
NMU’s Wildcats compete in the NCAA's Division II Great Lakes Intercollegiate Athletic Conference in basketball, football, golf, skiing, cross country, soccer, volleyball, track & field, and swimming/diving. The hockey program competes in Division I as a member of the Western Collegiate Hockey Association. The Division II football team plays in the world's largest wooden dome, the Superior Dome. Lloyd Carr, former head coach at the University of Michigan, former NFL coach Jerry Glanville, and Steve Mariucci, former head coach of the Detroit Lions and San Francisco 49ers, played football for NMU, and current Michigan State coach Tom Izzo played basketball at NMU. Northern Michigan's rivals in sports action are the two other major schools in the upper peninsula: Michigan Technological University, and Lake Superior State University.
The winner of the annual football game between NMU and Michigan Tech is awarded the Miner's Cup.
National Championships (4):
National Runners-up (4):
Basketball Final Four (1):
OTS.
The United States Olympic Training Site on the campus of Northern Michigan University is one of 16 Olympic training sites in the country. The NMU-OTS provides secondary and post-secondary educational opportunities for athletes while offering world-class training.
With more than 70 resident athletes and coaches, the NMU-OTS is the second-largest Olympic training center in the United States, in terms of residents, behind Colorado Springs. The USOEC has more residential athletes than the Lake Placid and Chula Vista sites combined. Over the years, it has grown into a major contributor to the U.S. Olympic movement.
Current resident training programs include Greco-Roman wrestling, weightlifting and women’s freestyle wrestling. Athletes must be approved by the NMU-OTS, their national governing body and NMU to be admitted into the program.
NMU-OTS athletes attend NMU or Marquette Senior High School, Marquette, Michigan while training in their respective sports. The student athletes receive free or reduced room and board, access to world-class training facilities as well as sports medicine and sports science services, academic tutoring, and a waiver of out-of-state tuition fees by NMU. Although athletes are responsible for tuition at the in-state rate, they may receive the B.J. Stupak Scholarship to help cover expenses.
On-campus NMU-OTS athletes live in NMU’s Meyland Hall, eat in campus dining halls, and train at the university’s Berry Events Center and Superior Dome.
The NMU-OTS also offers a variety of short-term training camps; regional, national, and international competitions; coaches and officials education clinics; and an educational program for retired Olympians.
Student life.
Residential life.
Residence hall government is an important facet of student life and NMU. Ten to twenty students from each of the ten residence halls are elected and/or appointed to meet with the staff from their hall on a weekly basis. They represent their peers on a variety of matters pertaining to their residence hall community and campus life.
Students who participate in hall government have the option of participating in various leadership training activities.
One student from up campus (2 halls) and two from down campus (8 halls) are elected to serve on ASNMU, NMU's Student Government.
The 10 residence halls are:
In addition to the residence halls, NMU operates and maintains seven apartment buildings on campus.
The apartments are 
Many halls that have been listed above contain "houses", smaller communities within each residence hall, which participate in campus events and socialize. Many have long-running traditions. For instance, Arctic House in Hunt Hall takes a swim in Lake Superior in the middle of winter. This is known as the Arctic plunge. Many houses in Payne Hall are noted for their volunteer involvement in projects during the school year. Northern Michigan Hall traditions are numerous and involve the students, letting them bond as a community.
Groups and activities.
Student organizations.
NMU hosts a large number of student organizations which are governmental, academic, programming, social, religious, and athletic, as well as residence hall-related, in nature. There are over 300 registered student organizations that provide programs and activities for the campus community. 
Army ROTC.
NMU is the proud host of the United States Army Cadet Command's "Wildcat Battalion". Roughly 70 Cadets train to earn their commissions as United States Army Officers in both the Active Duty and Reserve components. NMU ROTC also trains a specially selected group of Cadets to compete in the annual Ranger Challenge competition held in Fort McCoy, Wisc.
Greek life.
Fraternities
Sororities
Student Leader Fellowship Program.
The Student Leader Fellowship Program (SLFP) is committed to developing competent, ethical, and community-centered leaders. Over a two-year period, students participate in six component areas (Fall Retreat, Mentors, Leadership Theory and Practice Course, Skill Builders! Leadership Workshops, Community Service Internship, and Special Occasions) focusing on self-development and community development.
The Volunteer Center.
The NMU Volunteer Center is designed to assist students, both individuals and in student organizations, as well as faculty and staff at the university with finding ways in which they can contribute to the Marquette community.
Superior Edge.
Unique to Northern, this citizen-leader development program is open to all NMU students, regardless of GPA, major or year in school. Participants can work on any or all of the edges; citizenship, diversity awareness, leadership and real-world experience. Students log a minimum of 100 hours of volunteer, contact, classroom or work time for each edge and write a reflection paper. Achievement of edges is recorded on a student development transcript that is issued alongside a student's academic transcript.
The Superior Edge was developed in 2004-05 by a task force that included students, faculty, and staff. The Superior Edge encompasses a wide range of in- and out-of-classroom experiences that will provide Northern Michigan University students with a distinct advantage by better preparing them for careers, lifelong learning, graduate school, and life as engaged citizens.
Honors Program.
The Honors Program provides talented undergraduates the opportunity to take rigorous coursework that leads to the designation of Lower Division Honors, Upper Division Honors, or Full Honors on their academic transcript. For Full Honors, students must complete two years (16–20 credits) of lower division honors courses, two years of a foreign language, mathematics at the pre-calculus level or higher, 12 credits of upper division coursework in their major or minor that have been "honorized", and a capstone project in the final semester before graduation. To qualify for acceptance to the program, students must have a recalculated GPA of 3.5 or higher (on a 4.0 scale), an ACT score of 27 or above and submit two letters of recommendation. About 40 freshmen are admitted to the program annually.
The North Wind.
 began in 1972 as Northern Michigan University's first independent, student newspaper. The weekly paper covers news from the university and community alike and prints on most Thursdays during the school year.
WUPX.
WUPX is Northern Michigan University's non-commercial, student run, radio station broadcasting at 91.5 FM. WUPX provides NMU Students and the Marquette area with a wide variety of music, event announcements, and activities.
Student government.
The Associated Students of Northern Michigan University (ASNMU) is made up of three distinct branches: Executive, Legislative and Judicial. Representatives elected to represent Student Affairs groups and Academic Affairs comprise the Legislative Branch with a member of the Legislative Branch elected as Chair of the Assembly. The All Student Judiciary (ASJ), the judicial branch of ASNMU, is a panel composed of 16 students who hear cases involving students who violate the regulations of the University Student Code. The Student Finance Committee (SFC) a sub-committee oversees the collection and disbursement of Student Activity Fee and govern the disbursement of funds to registered student organizations. 
Charter schools.
NMU operates seven charter schools throughout Michigan.
As of July 1, 2014, NMU will add three more charter schools: Frances Reh Academy in Saginaw, George Crockett Academy in Detroit, and Universal Leadership Academy in Port Huron

</doc>
<doc id="21811" url="http://en.wikipedia.org/wiki?curid=21811" title="Nemo">
Nemo

Nemo is a Latin word meaning "no man" or "no one".
Nemo may also refer to:

</doc>
<doc id="21813" url="http://en.wikipedia.org/wiki?curid=21813" title="Naked News">
Naked News

Naked News, billing itself as "the program with nothing to hide", is a subscription website featuring a real television newscast. The show is prepared in Toronto and runs daily, with 25-minute episodes 6 days per week. The female anchors read the news fully nude or strip as they present their news segments. Naked News TV is its offshoot pay-per-view or subscription service. Naked News also aired briefly as a late night television series on Citytv Toronto.
Alongside the English language version, there is also Naked News Japan. An Italian version existed but closed after a few years. Naked News en Español was briefly trialled. A male version in English was also launched but ceased production on 31 October 2007.
Most of the show's announcers have been recruited through classified ads in alternative newspapers in Toronto. As such, most of the show's crew comes from the Toronto area. The show features occasional on-the-street interviews by topless newscasters, which are made possible by Ontario's Topfree equality laws. Since the show's inception in 1999, there has been much turnover among the newscasters, and many guest anchors. The female announcers have been featured in almost every medium including television ("CBS Sunday Morning", "The Today Show", "The View", "Sally Jessy Raphaël", and numerous appearances on "Entertainment Tonight" and "ET Insider") newspapers and magazines, ("TV Guide", "Playboy") and as guests on multiple radio shows including Howard Stern.
History.
Naked News was conceived by Fernando Pereira and Kirby Stasyna and debuted in December 1999 as a web-based news service featuring an all-female cast. It began with only one anchor, Victoria Sinclair (who left the program in 2014), and has currently grown to eight female anchors, plus guest anchors. The website was popularized entirely by word of mouth, and quickly became a popular web destination. During the height of its popularity, the website was receiving over 6 million hits per month. Part of the large amounts of web traffic in the site's early days was because the entire newscast could be viewed for free and supported by advertising. By 2002, after the crash of Internet advertising, only one news segment could be viewed freely, and by 2004, no free content remained on the website. Beginning in 2005, a nudity-free version of Naked News was available to non-subscribers. Beginning in June 2008, two news segments could be viewed freely. However, this ended in December 2009. The British channel Sumo TV briefly showed episodes of Naked News, while the free-to-view Playboy One broadcast the show at 9:30pm Mondays-Fridays until its closure in 2008.
A male version of the show was created in 2001 to parallel the female version, but has ceased production as it did not enjoy the female version's popularity and fame. Although it was originally targeted towards female viewers (at one point said to be 30% of the website's audience), the male show later promoted itself as news from a gay perspective.
Similar shows.
A comedic "precursor" to this concept occurred in an episode of "Monty Python's Flying Circus", in which Terry Jones began performing a striptease while giving a fast-paced rundown of economic news.
In the late 1990s, British cable television channel L!VE TV broadcast "Tiffany's Big City Tips", in which model Tiffany Banister gave the financial news while stripping to her underwear.

</doc>
<doc id="21814" url="http://en.wikipedia.org/wiki?curid=21814" title="Nitrogen Oxide Protocol">
Nitrogen Oxide Protocol

Protocol to the 1979 Convention on Long-Range Transboundary Air Pollution Concerning the Control of Emissions of Nitrogen Oxides or Their Transboundary Fluxes, opened for signature on 31 October 1988 and entered into force on 14 February 1991, was to provide for the control or reduction of nitrogen oxides and their transboundary fluxes. It was concluded in Sofia, Bulgaria.
Parties (as of May 2013): (34) Albania, Austria, Belarus, Belgium, Bulgaria, Canada, Croatia, Cyprus, Czech Republic, Denmark, Estonia, European Union, Finland, France, Germany, Greece, Hungary, Ireland, Italy, Liechtenstein, Lithuania, Luxembourg, Republic of Macedonia, Netherlands, Norway, Russia, Slovakia, Slovenia. Spain, Sweden, Switzerland, Ukraine, United Kingdom, United States.
Countries that have signed the protocol but not yet ratified it: Poland.
References.
 This article incorporates public domain material from the document .

</doc>
<doc id="21815" url="http://en.wikipedia.org/wiki?curid=21815" title="Noble Eightfold Path">
Noble Eightfold Path

The Noble Eightfold Path (Pali: "ariyo aṭṭhaṅgiko maggo", Sanskrit: "āryāṣṭāṅgamārga") is one of the principal teachings of the Buddha, who described it as the way leading to the cessation of suffering ("dukkha") and the achievement of self-awakening. It is used to develop insight into the true nature of phenomena (or reality) and to eradicate greed, hatred, and delusion. The Noble Eightfold Path is the fourth of the Buddha's Four Noble Truths; the first element of the Noble Eightfold Path is, in turn, an understanding of the Four Noble Truths. It is also known as the "Middle Path" or "Middle Way".
All eight elements of the Path begin with the word "right", which translates the word "samyañc" (in Sanskrit) or "sammā" (in Pāli). These denote completion, togetherness, and coherence, and can also suggest the senses of "perfect" or "ideal". 'Samma' is also translated as "wholesome", "wise" and "skillful".
In Buddhist symbolism, the Noble Eightfold Path is often represented by means of the dharma wheel (dharmachakra), whose eight spokes represent the eight elements of the path.
Origin.
According to the Buddhist tradition.
According to discourses found in both the Theravada school's Pali canon, and some of the Āgamas in the Chinese Buddhist canon, the Noble Eightfold Path was rediscovered by Gautama Buddha during his quest for enlightenment. The scriptures describe an ancient path which has been followed and practiced by all the previous Buddhas. The Noble Eightfold Path is a practice said to lead its practitioner toward self-awakening and liberation. The path was taught by the Buddha to his disciples so that they, too, could follow it.
In the same way I saw an ancient path, an ancient road, traveled by the Rightly Self-awakened Ones of former times. And what is that ancient path, that ancient road, traveled by the Rightly Self-awakened Ones of former times? Just this noble eightfold path: right view, right aspiration, right speech, right action, right livelihood, right effort, right mindfulness, right concentration...I followed that path. Following it, I came to direct knowledge of aging & death, direct knowledge of the origination of aging & death, direct knowledge of the cessation of aging & death, direct knowledge of the path leading to the cessation of aging & death...Knowing that directly, I have revealed it to monks, nuns, male lay followers & female lay followers...—Nagara Sutta
Additionally, some sources give alternate definitions for the Noble Eightfold Path. The Ekottara Āgama in particular contains variant teachings of basic doctrines such as the Noble Eightfold Path, which are different from those found in the Pali Canon.
Historical.
According to Vetter, the description of the Buddhist path may initially have been as simple as the term "the middle way". In time, this short description was elaborated, resulting in the description of the eightfold path. Vetter and Bucknell both note that longer descriptions of "the path" can be found, which can be condensed into the eightfold path. One of those longer sequences, from the "CulaHatthipadopama-sutta", the "Lesser Discourse on the Simile of the Elephant's Footprints", is as follows:
Threefold division.
The Noble Eightfold Path is sometimes divided into three basic divisions, as follows:
This presentation is called the "Three Higher Trainings" in Mahāyāna Buddhism: higher moral discipline, higher concentration and higher wisdom. "Higher" here refers to the fact that these trainings that lead to liberation and enlightenment are engaged in with the motivation of renunciation or bodhicitta.
Practice.
According to the "bhikkhu" (monk) and scholar Walpola Rahula, the divisions of the noble eightfold path "are to be developed more or less simultaneously, as far as possible according to the capacity of each individual. They are all linked together and each helps the cultivation of the others." Bhikkhu Bodhi explains that "with a certain degree of progress all eight factors can be present simultaneously, each supporting the others. However, until that point is reached, some sequence in the unfolding of the path is inevitable."
According to the discourses in the Pali and Chinese canons, right view, right intention, right speech, right action, right livelihood, right effort, and right mindfulness are used as the support and requisite conditions for the practice of right concentration. Understanding of the right view is the preliminary role, and is also the forerunner of the entire Noble Eightfold Path. The practitioner should first try to understand the concepts of right view. Once right view has been understood, it will inspire and encourage the arising of right intention within the practitioner. Right intention will lead to the arising of right speech. Right speech will lead to the arising of right action. Right action will lead to the arising of right livelihood. Right livelihood will lead to the arising of right effort. Right effort will lead to the arising of right mindfulness. The practitioner must make the right effort to abandon the wrong view and to enter into the right view. Right mindfulness is used to constantly remain in the right view. This will help the practitioner restrain greed, hatred and delusion.
Once these support and requisite conditions have been established, a practitioner can then practice right concentration more easily. During the practice of right concentration, one will need to use right effort and right mindfulness to aid concentration practice. In the state of concentration, one will need to investigate and verify his or her understanding of right view. This will then result in the arising of right knowledge, which will eliminate greed, hatred and delusion. The last and final factor to arise is right liberation.
Wisdom.
"Wisdom" ("prajñā" / "paññā"), sometimes translated as "discernment" at its preparatory role, provides the sense of direction with its conceptual understanding of reality. It is designed to awaken the faculty of penetrative understanding to see things as they really are. At a later stage, when the mind has been refined by training in moral discipline and concentration, and with the gradual arising of right knowledge, it will arrive at a superior right view and right intention.
Right view.
Right view ("samyag-dṛṣṭi" / "sammā-diṭṭhi") can also be translated as "right perspective", "right outlook" or "right understanding".
According to Paul Fuller, right-view is a way of seeing which transcends all views. It is a detached way of seeing, different from the attitude of holding to any view, wrong or right.
According to contemporary Theravada Buddhism, it is the right way of looking at life, nature, and the world as they really are for us. It is to understand how our reality works. It acts as the reasoning with which someone starts practicing the path. It explains the reasons for our human existence, suffering, sickness, aging, death, the existence of greed, hatred, and delusion. Right view gives direction and efficacy to the other seven path factors. It begins with concepts and propositional knowledge, but through the practice of right concentration, it gradually becomes transmuted into wisdom, which can eradicate the fetters of the mind. An understanding of right view will inspire the person to lead a virtuous life in line with right view. In the Pāli and Chinese canons, it is explained thus:
And what is right view? Knowledge with reference to suffering, knowledge with reference to the origination of suffering, knowledge with reference to the cessation of suffering, knowledge with reference to the way of practice leading to the cessation of suffering: This is called right view.
There are two types of right view:
Right view has many facets; its elementary form is suitable for lay followers, while the other form, which requires deeper understanding, is suitable for monastics. Usually, it involves understanding the following reality:
Right view for monastics is explained in detail in the "Sammādiṭṭhi Sutta" ("Right View Discourse"), in which Ven. Sariputta instructs that right view can alternately be attained by the thorough understanding of the unwholesome and the wholesome, the four nutriments, the twelve "nidanas" or the three taints.
"Wrong view" arising from ignorance ("avijja"), is the precondition for wrong intention, wrong speech, wrong action, wrong livelihood, wrong effort, wrong mindfulness and wrong concentration. The practitioner should use right effort to abandon the wrong view and to enter into right view. Right mindfulness is used to constantly remain in right view.
The purpose of right view is to clear one's path of the majority of confusion, misunderstanding, and deluded thinking. It is a means to gain right understanding of reality. Right view should be held with a flexible, open mind, without clinging to that view as a dogmatic position. In this way, right view becomes a route to liberation rather than an obstacle.
Right intention.
Right intention ("samyak-saṃkalpa" / "sammā sankappa") can also be known as "right thought", "right resolve", "right conception", "right aspiration" or "the exertion of our own will to change". In this factor, the practitioner should constantly aspire to rid themselves of whatever qualities they know to be wrong and immoral. Correct understanding of right view will help the practitioner to discern the differences between right intention and wrong intention. In the Chinese and Pali Canon, it is explained thus:
And what is right resolve? Being resolved on renunciation, on freedom from ill will, on harmlessness: This is called right resolve.
It means the renunciation of the worldly things and an accordant greater commitment to the spiritual path; good will; and a commitment to non-violence, or harmlessness, towards other living beings.
Ethical conduct.
For the mind to be unified in concentration, it is necessary to refrain from unwholesome deeds of body and speech to prevent the faculties of bodily action and speech from becoming tools of the defilements. Ethical conduct ("Śīla" / "Sīla") is used primarily to facilitate mental purification.
Right speech.
Right speech ("samyag-vāc" / "sammā-vācā"), deals with the way in which a Buddhist practitioner would best make use of their words. In the Pali Canon, it is explained thus:
And what is right speech? Abstaining from lying, from divisive speech, from abusive speech, and from idle chatter: This is called right speech.
The "Samaññaphala Sutta", "Kevatta Sutta" and "Cunda Kammaraputta Sutta" elaborate:
Abandoning false speech... He speaks the truth, holds to the truth, is firm, reliable, no deceiver of the world...
Abandoning divisive speech... What he has heard here he does not tell there to break those people apart from these people here...Thus reconciling those who have broken apart or cementing those who are united, he loves concord, delights in concord, enjoys concord, speaks things that create concord...
Abandoning abusive speech... He speaks words that are soothing to the ear, that are affectionate, that go to the heart, that are polite, appealing and pleasing to people at large...
Abandoning idle chatter... He speaks in season, speaks what is factual, what is in accordance with the goal, the Dhamma, and the Vinaya. He speaks words worth treasuring, seasonable, reasonable, circumscribed, connected with the goal...
The "Abhaya Sutta" elaborates:
In the case of words that the Tathagata knows to be unfactual, untrue, unbeneficial, unendearing and disagreeable to others, he does not say them.
In the case of words that the Tathagata knows to be factual, true, yet unbeneficial, unendearing and disagreeable to others, he does not say them.
In the case of words that the Tathagata knows to be factual, true, beneficial, yet unendearing and disagreeable to others, he has a sense of the proper time for saying them.
In the case of words that the Tathagata knows to be unfactual, untrue, unbeneficial, yet endearing and agreeable to others, he does not say them.
In the case of words that the Tathagata knows to be factual, true, but unbeneficial, yet endearing and agreeable to others, he does not say them.
In the case of words that the Tathagata knows to be factual, true, beneficial, and endearing and agreeable to others, he has a sense of the proper time for saying them. Why is that? Because the Tathagata has sympathy for living beings.
In every case, if it is not true, beneficial nor timely, one is not to say it. The Buddha followed this, for example, when asked questions of a purely "meta"physical nature, unrelated to the goal, path or discipline that he taught. When asked a question such as "Is the universe eternal?", the Buddha dismissed the topic with the response: "It does not further." (or: "The personal possibilities (goals) assigned you are not furthered by an answer to an ultimate question about the universe's fate.")
Right action.
Right action ("samyak-karmānta" / "sammā-kammanta") can also be translated as "right conduct". As such, the practitioner should train oneself to be morally upright in one's activities, not acting in ways that would be corrupt or bring harm to oneself or to others. In the Chinese and Pali Canon, it is explained as:
And what is right action? Abstaining from taking life, from stealing, and from illicit sex [or sexual misconduct]. This is called right action.—Saccavibhanga Sutta
And what, monks, is right action? Abstaining from taking life, abstaining from stealing, abstaining from unchastity: This, monks, is called right action.—Magga-vibhanga Sutta
For the lay follower, the "Cunda Kammaraputta Sutta" elaborates:
And how is one made pure in three ways by bodily action? There is the case where a certain person, abandoning the taking of life, abstains from the taking of life. He dwells with his... knife laid down, scrupulous, merciful, compassionate for the welfare of all living beings. Abandoning the taking of what is not given, he abstains from taking what is not given. He does not take, in the manner of a thief, things in a village or a wilderness that belong to others and have not been given by them. Abandoning sensual misconduct, he abstains from sensual misconduct. He does not get sexually involved with those who are protected by their mothers, their fathers, their brothers, their sisters, their relatives, or their Dhamma; those with husbands, those who entail punishments, or even those crowned with flowers by another man. This is how one is made pure in three ways by bodily action.
For the monastic, the "Samaññaphala Sutta" adds:
Abandoning uncelibacy, he lives a celibate life, aloof, refraining from the sexual act that is the villager's way.
Right livelihood.
Right livelihood ("samyag-ājīva" / "sammā-ājīva"). This means that practitioners ought not to engage in trades or occupations which, either directly or indirectly, result in harm for other living beings. In the Chinese and Pali Canon, it is explained thus:
And what is right livelihood? There is the case where a disciple of the noble ones, having abandoned dishonest livelihood, keeps his life going with right livelihood: This is called right livelihood.
More concretely today interpretations include "work and career need to be integrated into life as a Buddhist," it is also an ethical livelihood, "wealth obtained through rightful means" (Bhikku Basnagoda Rahula) - that means being honest and ethical in business dealings, not to cheat, lie or steal. As people are spending most of their time at work, it’s important to assess how our work affects our mind and heart. So important questions include "How can work become meaningful? How can it be a support, not a hindrance, to spiritual practice — a place to deepen our awareness and kindness?"
The five types of businesses that should not be undertaken:
Concentration.
Concentration ("samadhi") is achieved through concentrating the attention on a single meditation object. This brings the calm and collectedness needed to develop true wisdom by direct experience.
Right effort.
Right effort ("samyag-vyāyāma" / "sammā-vāyāma") can also be translated as "right endeavor" or "right diligence". In this factor, the practitioners should make a persisting effort to abandon all the wrong and harmful thoughts, words, and deeds. The practitioner should instead be persisting in giving rise to what would be good and useful to themselves and others in their thoughts, words, and deeds, without a thought for the difficulty or weariness involved. In both the Chinese and the Pali Canon, it is explained thus:
And what, monks, is right effort?
(i) There is the case where a monk generates desire, endeavors, activates persistence, upholds and exerts his intent for the sake of the non-arising of evil, unskillful qualities that have not yet arisen.
(ii) He generates desire, endeavors, activates persistence, upholds and exerts his intent for the sake of the abandonment of evil, unskillful qualities that have arisen.
(iii) He generates desire, endeavors, activates persistence, upholds and exerts his intent for the sake of the arising of skillful qualities that have not yet arisen.
(iv) He generates desire, endeavors, activates persistence, upholds and exerts his intent for the maintenance, non-confusion, increase, plenitude, development, and culmination of skillful qualities that have arisen:
This, monks, is called right effort.
Although the above instruction is given to the male monastic order, it is also meant for the female monastic order and can be practiced by lay followers of both genders.
The above four phases of right effort mean to:
Right mindfulness.
Right mindfulness ("samyak-smṛti" / "sammā-sati"), also translated as "right memory", "right awareness" or "right attention". Here, practitioners should constantly keep their minds alert to phenomena that affect the body and mind. They should be mindful and deliberate, making sure not to act or speak due to inattention or forgetfulness. In the Pali Canon, it is explained thus:
And what, monks, is right mindfulness?
(i) There is the case where a monk remains focused on the body in and of itself—ardent, aware, and mindful—putting away greed and distress with reference to the world.
(ii) He remains focused on feelings in and of themselves—ardent, aware, and mindful—putting away greed and distress with reference to the world.
(iii) He remains focused on the mind in and of itself—ardent, aware, and mindful—putting away greed and distress with reference to the world.
(iv) He remains focused on mental qualities ("dhammesu") in and of themselves—ardent, aware, and mindful—putting away greed and distress with reference to the world.
This, monks, is called right mindfulness.
Although the above instruction is given to the male monastic order, it is also meant for the female monastic order and can be practiced by lay followers from both genders.
Bhikkhu Bodhi, a monk of the Theravada tradition, further explains the concept of mindfulness as follows:
The mind is deliberately kept at the level of "bare attention", a detached observation of what is happening within us and around us in the present moment. In the practice of right mindfulness the mind is trained to remain in the present, open, quiet, and alert, contemplating the present event. All judgments and interpretations have to be suspended, or if they occur, just registered and dropped.
The Maha Satipatthana Sutta also teaches that by mindfully observing these phenomena, we begin to discern its arising and subsiding and the Three Characteristics of Dharma in direct experience, which leads to the arising of insight and the qualities of dispassion, non-clinging, and release.
Right concentration.
Right concentration ("samyak-samādhi" / "sammā-samādhi"), as its Sanskrit and Pali names indicate, is the practice of concentration ("samadhi"). It is also known as right meditation. As such, the practitioner concentrates on an object of attention until reaching full concentration and a state of meditative absorption ("jhana"). Traditionally, the practice of samadhi can be developed through mindfulness of breathing ("anapanasati"), through visual objects ("kasina"), and through repetition of phrases ("mantra"). Jhana is used to suppress the five hindrances in order to enter into Samadhi. Jhana is an instrument used for developing wisdom by cultivating insight and using it to examine true nature of phenomena with direct cognition. This leads to cutting off the defilements, realizing the dhamma and, finally, self-awakening.
During the practice of right concentration, the practitioner will need to investigate and verify their right view. In the process right knowledge will arise, followed by right liberation. In the Pali Canon, it is explained thus:
And what is right concentration?
(i) Herein a monk aloof from sense desires, aloof from unwholesome thoughts, attains to and abides in the first meditative absorption [jhana], which is detachment-born and accompanied by applied thought, sustained thought, joy, and bliss.
(ii) By allaying applied and sustained thought he attains to, and abides in the second jhana, which is inner tranquillity, which is unification (of the mind), devoid of applied and sustained thought, and which has joy and bliss.
(iii) By detachment from joy he dwells in equanimity, mindful, and with clear comprehension and enjoys bliss in body, and attains to and abides in the third jhana, which the noble ones [ariyas] call "dwelling in equanimity, mindfulness, and bliss".
(iv) By giving up of bliss and suffering, by the disappearance already of joy and sorrow, he attains to, and abides in the fourth jhana, which is neither suffering nor bliss, and which is the purity of equanimity — mindfulness.
This is called right concentration.
Although this instruction is given to the male monastic order, it is also meant for the female monastic order and can be practiced by lay followers from both genders.
According to the Pali and Chinese canon, right concentration is dependent on the development of preceding path factors:
The Blessed One said: "Now what, monks, is noble right concentration with its supports and requisite conditions? Any singleness of mind equipped with these seven factors — right view, right resolve, right speech, right action, right livelihood, right effort, and right mindfulness — is called noble right concentration with its supports and requisite conditions.—Maha-cattarisaka Sutta
Acquired factors.
In the "Mahācattārīsaka Sutta" which appears in the Chinese and Pali canons, the Buddha explains that cultivation of the noble eightfold path leads to the development of two further factors, which are right knowledge, or insight ("sammā-ñāṇa"), and right liberation, or release ("sammā-vimutti"). These two factors fall under the category of wisdom ("paññā").
Right knowledge and right liberation.
Right knowledge is seeing things as they really are by direct experience, not as they appear to be, nor as the practitioner wants them to be, but as they truly are. A result of Right Knowledge is the tenth factor - Right liberation.
These two factors are the end result of correctly practicing the noble eightfold path, which arise during the practice of right concentration. The first to arise is right knowledge: this is where deep insight into the ultimate reality arises. The last to arise is right liberation: this is where self-awakening occurs and the practitioner has reached the pinnacle of their practice.
Cognitive psychology.
In the essay "Buddhism Meets Western Science", Gay Watson explains:
Buddhism has always been concerned with feelings, emotions, sensations, and cognition. The Buddha points both to cognitive and emotional causes of suffering. The emotional cause is desire and its negative opposite, aversion. The cognitive cause is ignorance of the way things truly occur, or of three marks of existence: that all things are unsatisfactory, impermanent, and without essential self.
The noble eightfold path is, from this psychological viewpoint, an attempt to change patterns of thought and behavior. It is for this reason that the first element of the path is right understanding ("sammā-diṭṭhi"), which is how one's mind views the world. Under the wisdom ("paññā") subdivision of the noble eightfold path, this worldview is intimately connected with the second element, right thought ("sammā-saṅkappa"), which concerns the patterns of thought and intention that controls one's actions. These elements can be seen at work, for example, in the opening verses of the "Dhammapada": The noble eightfold path is also the fourth noble truth.
All experience is preceded by mind,
 Led by mind,
 Made by mind.
Speak or act with a corrupted mind,
 And suffering follows
As the wagon wheel follows the hoof of the ox.
All experience is preceded by mind,
 Led by mind,
 Made by mind.
Speak or act with a peaceful mind,
 And happiness follows
Like a never-departing shadow.
Thus, by altering one's distorted worldview, bringing out "tranquil perception" in the place of "perception polluted", one is able to ease suffering. Watson points this out from a psychological standpoint:
Research has shown that repeated action, learning, and memory can actually change the nervous system physically, altering both synaptic strength and connections. Such changes may be brought about by cultivated change in emotion and action; they will, in turn, change subsequent experience.
Sources.
</dl>

</doc>
<doc id="21818" url="http://en.wikipedia.org/wiki?curid=21818" title="National park">
National park

A national park is a park in use for conservation purposes. Often it is a reserve of natural, semi-natural, or developed land that a sovereign state declares or owns. Although individual nations designate their own national parks differently, there is a common idea: the conservation of 'wild nature' for posterity and as a symbol of national pride. An international organization, the International Union for Conservation of Nature (IUCN), and its World Commission on Protected Areas, has defined "National Park" as its "Category II" type of protected areas.
While this type of national park had been proposed previously, the United States established the first "public park or pleasuring-ground for the benefit and enjoyment of the people", Yellowstone National Park, in 1872. Although Yellowstone was not officially termed a "national park" in its establishing law, it was always termed such in practice and is widely held to be the first and oldest national park in the world. Some would say that the first official national park to be designated as such at its creation was Mackinac Island, legislated in 1875. Australia's Royal National Park, established in 1879, was the world's third official national park. In 1895 ownership of Mackinac Island was transferred to the State of Michigan as a state park and national park status was consequently lost. As a result Australia's Royal National Park is by some considerations the second oldest national park now in existence.
The largest national park in the world meeting the IUCN definition is the Northeast Greenland National Park, which was established in 1974. According to the IUCN, 6,555 national parks worldwide met its criteria in 2006. IUCN is still discussing the parameters of defining a national park.
National parks are almost always open to visitors. Most national parks provide outdoor recreation and camping opportunities as well as classes designed to educate the public on the importance of conservation and the natural wonders of the land in which the national park is located.
Definitions.
In 1969, the IUCN declared a national park to be a relatively large area with the following defining characteristics:
In 1971, these criteria were further expanded upon leading to more clear and defined benchmarks to evaluate a national park. These include:
While the term national park is now defined by the IUCN, many protected areas in many countries are called national park even when they correspond to other categories of the IUCN Protected Area Management Definition, for example:
While national parks are generally understood to be administered by national governments (hence the name), in Australia national parks are run by state governments and predate the Federation of Australia; similarly, national parks in the Netherlands are administered by the provinces.
In many countries, including Indonesia, the Netherlands, and the United Kingdom, national parks do not adhere to the IUCN definition, while some areas which adhere to the IUCN definition are not designated as national parks.
History.
In 1810, the English poet William Wordsworth described the Lake District as a sort of national property, in which every man has a right and interest who has an eye to perceive and a heart to enjoy.
 The painter George Catlin, in his travels through the American West, wrote during the 1830s that the Native Americans in the United States might be preserved (by some great protecting policy of government) ...in a "magnificent park" ...A "nation's Park", containing man and beast, in all the wild and freshness of their nature's beauty!
The first effort by any government to set aside such protected lands was in the United States, on April 20, 1832, when President Andrew Jackson signed legislation that the 22nd United States Congress had enacted to set aside four sections of land around what is now Hot Springs, Arkansas, to protect the natural, thermal springs and adjoining mountainsides for the future disposal of the U.S. government. It was known as Hot Springs Reservation, but no legal authority was established. Federal control of the area was not clearly established until 1877.
John Muir is today referred to as the "Father of the National Parks" due to his work in Yosemite. He published two influential articles in The Century Magazine, which formed the base for the subsequent legislation.
President Abraham Lincoln signed an Act of Congress on July 1, 1864, ceding the Yosemite Valley and the Mariposa Grove of Giant Sequoias (later becoming Yosemite National Park) to the state of California. According to this bill, private ownership of the land in this area was no longer possible. The state of California was designated to manage the park for "public use, resort, and recreation". Leases were permitted for up to ten years and the proceeds were to be used for conservation and improvement. A public discussion followed this first legislation of its kind and there was a heated debate over whether the government had the right to create parks. The perceived mismanagement of Yosemite by the Californian state was the reason why Yellowstone at its establishment six years later was put under national control.
In 1872, Yellowstone National Park was established as the United States' first national park, being also the world's first national park. In some European countries, however, national protection and nature reserves already existed, such as Drachenfels (Germany, 1822) and a part of Forest of Fontainebleau (France, 1861).
Yellowstone was part of a federally governed territory. With no state government that could assume stewardship of the land so the federal government took on direct responsibility for the park, the official first national park of the United States. The combined effort and interest of conservationists, politicians and the Northern Pacific Railroad ensured the passage of enabling legislation by the United States Congress to create Yellowstone National Park. Theodore Roosevelt, already an active campaigner and so influential, as good stump speakers were highly necessary in the pre-telecommunications era, was highly influential in convincing fellow Republicans and big business to back the bill.
American Pulitzer Prize-winning author Wallace Stegner wrote:
National parks are the best idea we ever had. Absolutely American, absolutely democratic, they reflect us at our best rather than our worst.
In his book "Dispossessing the Wilderness: Indian Removal and the Making of the National Parks", Mark David Spence made the point that in order to create these uninhabited spaces, the United States first had to disposess the Indians who were living in them.
Even with the creation of Yellowstone, Yosemite, and nearly 37 other national parks and monuments, another 44 years passed before an agency was created in the United States to administer these units in a comprehensive way – the U.S. National Park Service (NPS). The 64th United States Congress passed the National Park Service Organic Act, which President Woodrow Wilson signed into law on August 25, 1916. Of the 407 sites managed by the National Park Service of the United States, only 59 carry the designation of National Park. 
Following the idea established in Yellowstone, there soon followed parks in other nations. In Australia, the Royal National Park was established just south of Sydney in 1879, becoming the world's second official national park (actually the 3rd: Mackinac National Park in Michigan was created in 1875 as a national park but was later transferred to the state's authority, thus losing its official "national park" status). Rocky Mountain National Park became Canada's first national park in 1885. New Zealand established Tongariro National Park in 1887. In Europe, the first national parks were a set of nine parks in Sweden in 1909, followed by the Swiss National Park in 1914. Europe has some 359 national parks as of 2010. Africa's first national park was established in 1925 when Albert I of Belgium designated an area of what is now Democratic Republic of Congo centred on the Virunga Mountains as the Albert National Park (since renamed Virunga National Park). In 1973, Mount Kilimanjaro was classified as a National Park and was opened to public access in 1977. In 1926, the government of South Africa designated Kruger National Park as the nation's first national park, although it was an expansion of the earlier Sabie Game Reserve established in 1898 by President Paul Kruger of the old South African Republic, after whom the park was named. After World War II, national parks were founded all over the world. The Vanoise National Park in the Alps was the first French national park, created in 1963 after public mobilization against a touristic project.
The world's first national park service was established May 19, 1911, in Canada. The Dominion Forest Reserves and Parks Act placed the dominion parks under the administration of the Dominion Park Branch (now Parks Canada). The branch was established to "protect sites of natural wonder" to provide a recreational experience, centered on the idea of the natural world providing rest and spiritual renewal from the urban setting. Canada now has the largest protected area in the world with 377,000 km² of national park space. In 1989, the Qomolangma National Nature Preserve (QNNP) was created to protect 3.381 million hectares on the north slope of Mount Everest in the Tibet Autonomous Region of China. This national park is the first major global park to have no separate warden and protection staff—all of its management being done through existing local authorities, allowing a lower cost basis and a larger geographical coverage (in 1989 when created, it was the largest protected area in Asia). It includes four of the six highest mountains Everest, Lhotse, Makalu, and Cho Oyu. The QNNP is contiguous to four Nepali national parks, creating a transborder conservation area equal in size to Switzerland.
Economic ramifications.
Countries with a large nature-based tourism industry, such as Costa Rica, often experience a huge economic effect on park management as well as the economy of the country as a whole.
Tourism.
Tourism to national parks has increased considerably over time. In Costa Rica for example, a megadiverse country, tourism to parks has increased by 400% from 1985 to 1999. The term "national park" is perceived as a brand name that is associated with nature-based tourism and it symbolizes "high quality natural environment and well-design tourism infrastructure".
Staff.
The duties of a park ranger are to supervise, manage, and/or perform work in the conservation and use of Federal park resources. This involves functions such as park conservation; natural, historical, and cultural resource management; and the development and operation of interpretive and recreational programs for the benefit of the visiting public. Park rangers also have fire fighting responsibilities and execute search and rescue missions. Activities also include heritage interpretation to disseminate information to visitors of general, historical, or scientific information. Management of resources such as wildlife, lakeshores, seashores, forests, historic buildings, battlefields, archeological properties, and recreation areas are also part of the job of a park ranger. Since the establishment of the National Park Service in the US in 1916, the role of the park ranger has shifted from merely being a custodian of natural resources to include several activities that are associated with law enforcement. They control traffic and investigate violations, complaints, trespass/encroachment, and accidents.

</doc>
<doc id="21819" url="http://en.wikipedia.org/wiki?curid=21819" title="Nuncio">
Nuncio

Nuncio (officially known as an Apostolic nuncio and also known as a papal nuncio) is the title for an ecclesiastical diplomat, being an envoy or permanent diplomatic representative of the Holy See to a state or international organization. A nuncio is appointed by and represents the Holy See, and is the head of the diplomatic mission, called an Apostolic Nunciature, which is the equivalent of an embassy. The Holy See is legally distinct from the Vatican City or the Catholic Church. A nuncio is usually an archbishop. 
A papal nuncio is generally equivalent in rank to that of ambassador extraordinary and plenipotentiary, although in Catholic countries the nuncio often ranks above ambassadors in diplomatic protocol. A nuncio performs the same functions as an ambassador and has the same diplomatic privileges. Under the 1961 Vienna Convention on Diplomatic Relations, to which the Holy See is a party, a nuncio is an ambassador like those from any other country. The Vienna Convention allows the host state to grant seniority of precedence to the nuncio over others of ambassadorial rank accredited to the same country, and may grant the deanship of that country's diplomatic corps to the nuncio regardless of seniority. The representative of the Holy See in some situations is called a Delegate or, in the case of the United Nations, Permanent Observer. In the Holy See hierarchy, these usually rank equally to a nuncio, but they do not have formal diplomatic status, though in some countries they have some diplomatic privileges. 
In addition, the nuncio serves as the liaison between the Holy See and the Church in that particular nation, supervising the diocesan episcopate (usually a national conference of bishops which has its own chairman, usually the highest-ranking bishop or archbishop, especially if his seat carries the title of primate or he has individually been created a cardinal) and has an important role in the selection of bishops.
Terminology and history.
The name nuncio is derived from the ancient Latin word, "nuntius", meaning "envoy" or "messenger".
Formerly, the title "Internuncio" denoted a papal diplomatic representative of the second class, corresponding to Envoy Extraordinary and Minister Plenipotentiary as a title for diplomatic representatives of states (cf. Article 14, par. 2 of the Vienna Convention). Before 1829, internuncio was the title applied instead to the interim head of a mission when one Nuncio had left office and his replacement had not yet assumed it.
A legate a latere is a temporary papal representative or a representative for a special purpose.
Historically, the most important type of apocrisiary (a title also applying to representatives exchanged by a high prelate with a Patriarch) was the equivalent of a nuncio, sent by the Pope to the Byzantine Empire; during the fifth and sixth centuries, when much of Italy remained under Byzantine control, several Popes were former apocrisiaries.
Pro-nuncio was a term used from 1965 to 1991 for a papal diplomatic representative of full ambassadorial rank accredited to a country that did not accord him precedence over other ambassadors and "de jure" deanship of the Diplomatic Corps. In those countries, the papal representative's precedence within the corps is exactly on a par with that of the other members of ambassadorial rank, so that he becomes dean only on becoming the senior member of the corps.
In countries with whom the Holy See does not have diplomatic ties, an Apostolic Delegate may be sent to act as a liaison with the Roman Catholic Church in that country, though not accredited to its government. Apostolic delegates have the same ecclesiastical rank as nuncios, but have no formal diplomatic status, though in some countries they have some diplomatic privileges. For example, an apostolic delegate served as the Holy See's "de facto" diplomatic representative to the United States and the United Kingdom, until both major Anglo-Saxon states with a predominantly Protestant tradition established full-fledged relations with the Holy See in the late twentieth century, allowing for the appointment of a Papal Nuncio (see the list of British Ambassadors to the Holy See). Archbishop Pio Laghi, for example, was first apostolic delegate, then pro-nuncio, to the United States during the Jimmy Carter, Ronald Reagan, and George H. W. Bush presidencies.
Apostolic delegates are also sent to regions such as the West Indies and the islands of the Pacific. These delegates are also appointed nuncio to at least some of the many states covered by their delegation, but the area entrusted to them also contains one or more territories that either are not independent states or are states that do not have diplomatic relations with the Holy See.
In accordance with this article, many states (even not predominantly Catholic ones such as Germany and Switzerland and including the great majority in central and western Europe and in the Americas) give precedence to the Nuncio over other diplomatic representatives, according him the position of Dean of the Diplomatic Corps reserved in other countries for the longest-serving resident ambassador.

</doc>
<doc id="21820" url="http://en.wikipedia.org/wiki?curid=21820" title="Newlyn School">
Newlyn School

The Newlyn School was an art colony of artists based in or near Newlyn, a fishing village adjacent to Penzance, Cornwall, from the 1880s until the early twentieth century. The establishment of the Newlyn School was reminiscent of the Barbizon School in France, where artists fled Paris to paint in a more pure setting emphasizing natural light. These schools along with a related California movement were also known as En plein air.
Newlyn had a number of things guaranteed to attract artists: fantastic light, cheap living, and the availability of inexpensive models. The artists were fascinated by the fishermen's working life at sea and the everyday life in the harbour and nearby villages. Some paintings showed the hazards and tragedy of the community's life, such as women anxiously looking out to sea as the boats go out, or a young woman crying on hearing news of a disaster. Lamorna Birch was the prime mover behind the colony and the work done there. The later Forbes School of Painting, founded by Stanhope Forbes and his wife Elizabeth in 1899, promoted the study of figure painting. A present day Newlyn School of Art was formed in 2011 with Arts Council funding providing art courses taught by many of the best-known artists working in Cornwall today.
In the late nineteenth and early twentieth centuries, Lamorna, a nearby fishing village to the south, became popular with artists of the Newlyn School and is particularly associated with the artist S. J. "Lamorna" Birch who lived there from 1908.
Member artists.
Newlyn School painters include:
For a full list see: George Bednar. "Every Corner was a Picture: A checklist compiled for the West Cornwall Art Archive of 50 artists from the early Newlyn School painters through to the present." ISBN 1-872229-36-0

</doc>
<doc id="21822" url="http://en.wikipedia.org/wiki?curid=21822" title="Natural Law Party">
Natural Law Party

The Natural Law Party (NLP) was a transnational party founded in 1992 on "the principles of Transcendental Meditation",<ref name="Cowan/Bromley"></ref> the laws of nature, and their application to all levels of government. It was active in up to 74 countries. It continues in India and some parts of the United States. The party defined "natural law" as the organizing intelligence which governs the natural universe. The Natural Law Party advocated using the Transcendental Meditation technique and the TM-Sidhi program as tools to enliven natural law and reduce or eliminate problems in society.
Prominent candidates included John Hagelin for U.S. president and Doug Henning as representative of Rosedale, Toronto, Canada. George Harrison performed a benefit concert in support of the party in 1992. Electoral success was achieved by the Ajeya Bharat Party in India, which elected a legislator to the state assembly, and the Croatian NLP, which elected a member of their regional assembly in 1993. In the USA its organization was reported to rival that of other "established third parties".
History and platform.
According to the Maharishi, the Natural Law Party (NLP) was first founded in the United Kingdom in March 1992 and was later established in the United States, France, Austria, Germany, Croatia, Israel, Japan, Spain, the Netherlands, Italy, Australia, Norway, Sweden, New Zealand, Chile, Thailand and Canada. The American branch of the party was founded later that year in Fairfield, Iowa U.S.A. by educators, business leaders, lawyers and other supporters of the Transcendental Meditation movement. The party was active in many countries and delegates from 60 countries attended an international convention in Bonn, Germany in 1998. The party became largely inactive in the United States in 2004 and was discontinued in the Netherlands in 2007.
The party had its foundation in the principles of Transcendental Meditation and was committed to "prevention oriented government and conflict free politics" through holistic health programs and the practice of the Transcendental Meditation technique. In Scotland and Wales, party advertisements proclaimed that "natural law which silently governs the whole universe in perfect order and without a problem." The Scotland and Wales branch of the party promised reduced pollution, the elimination of genetically modified crops and an increase in sustainable agriculture. They also supported free college education and the use of the Transcendental Meditation technique in the school system. In the UK, NLP candidate Geoffry Clements advocated the use of Transcendental Meditation and the TM-Sidhi program's yogic flying practice to reduce crime and war deaths. In the U.S.A. its platform included clean energy, labeling of genetically modified foods, a ban on the construction of nuclear energy plants, and an end to political action committees.
National branches.
The Natural Law Party was reported to be active in 74 countries including Australia, Belgium, Canada, Croatia, Finland, France, India, Ireland, Israel, Italy, New Zealand, the Netherlands, Trinidad and Tobago, the United Kingdom and the United States.
Australia.
In 1993, Bevan Morris campaigned for a seat in a district in suburban Adelaide for the Australian House of Representatives on the NLP ticket. The party contested several federal and state elections between 1990 and 1997.
Canada.
The Natural Law Party was active in the Canadian federal elections of 1993, 1997 and 2000 and in provincial elections in Ontario and Quebec during this period, before it was deregistered in 2003.
Croatia.
In Croatia a party member was elected to a regional assembly in 1993.
France.
Benoît Frappé of France was the party's candidate for the European Parliament.
India.
The Natural Law Party in India is known as the Ajeya Bharat Party (AJBP) or Invincible India Party. It promotes a Vedic way of life. It was formed in late 1998 as the political wing of the Maharishi Vedic Vishwa Prashasan (MVVP (Maharishi Global Administration Through Natural Law)), which had nominated thirty-four candidates in the February 1998 parliamentary election from Madhya Pradesh. The Maharishi was said to be "keenly interested" in building a political base in his native province. The MVVP received 0.28% of the vote in its first election. Mukesh Nayak left the cabinet and the Congress Party to assume the leadership of the Madhya Pradesh MVVP. For the November 1998 election, the Ajeya Bharat had a list of 100 candidates for the Assembly. It received 0.5% of the vote and won one seat in the 320-member state assembly. The following year, that member switched parties, leaving the Ajeya Bharat with no representation. In 2008, Nayak left the party to rejoin the Congress Party. In 2009, the Ajeya Bharat Party president, Ambati Krishnamurthy, filed a complaint against another party for using a flag similar to its own.
Ireland.
The Natural Law Party became active in Republic of Ireland in 1994 and was based in Dublin. The party leader was John Burns, who was one of nine Natural Law Party candidates in the 1997 general election. In addition, there were four candidates in the European elections of 1999. Burns endorsed the alternative health system of Maharishi Vedic Approach to Health and the five European candidates gained about 0.5% of first-preference votes cast. Burns, who also contested the 1999 Dublin South Central by-election, spent only £163 on his campaign. After 1999, the party ceased to field candidates in Ireland. The amount of corporate political donations in 2000 was nil.
Israel.
The Natural Law Party of Israel (Hebrew: מפלגת חוק הטבע של ישראל‎, "Mifleget Hok HaTeva Shel Yisrael") was a minor political party in Israel. Its leader was Amihai Rokah. In the 1992 elections the Natural Law Party won 1,734 votes (0.06%), and in the 1999 elections, won 2,924 votes (0.09%), both below the then 1.5% electoral threshold required to enter the Knesset. It has not run in an election since and its website states it has ceased political activity, but as of 2011 it is still registered as a party in Israel.
Italy.
The Natural Law Party in Italy ("Partito della Legge Naturale", PLN) took place to several (both general and local) elections in the nineties. In the 1994 general elections it won 24,897 votes (0.06%) for the Chamber of Deputies and 86,588 votes (0.26%) for the Senate. The list was on ballot in a few constituencies only. In the 1996 general elections the Natural Law Party ran candidates only in the Trentino-Alto Adige/Südtirol region, who won 8,298 votes for the Chamber of Deputies and 5,842 for the Senate (about 1% on a regional basis, 0.2% in the whole country).
New Zealand.
The Natural Law Party of New Zealand was formed in 1995. The Natural Law Party never won any seats in Parliament, and was removed from the register of official political parties in February 2001.
Trinidad and Tobago.
The Natural Law Party in Trinidad and Tobago contested the 1995 general elections. It received 1,590 votes, but failed to win a seat.
United Kingdom.
The Natural Law Party was founded in the United Kingdom in March 1992. Geoffrey Clements was its leader.
The UK manifesto, as published on its website, listed 5 key aspects of a successful government including 
In the 1992 general election, held on 9 April, the NLP contested 310 seats in the UK, garnering 0.19% of the vote, with every candidate losing their deposit for failing to receive at least 5% of the vote. The group announced that they had budgeted nearly 1 million pounds for the campaign. A significant number of constituencies were contested by nationals of countries outside the UK, including Canada, Australia, New Zealand, and India, as British electoral law allows any member of a Commonwealth country to stand for Parliament. Among them was Canadian-born magician Doug Henning. Despite the "dismal" amount of votes, an article in the The Herald of Scotland reported that it could be considered a "reasonable return for a campaign which began only three weeks before polling day." In addition the NLP "notched up" a "headline-grabbing record" when it put forward candidates for all 87 British seats in the 1994 European Parliament – the first party to do so.
George Harrison performed a fund-raising concert at the Royal Albert Hall in London for the NLP on 6 April 1992, his first full concert in the UK since 1969. According to Harrison, a week before the general election, Maharishi Mahesh Yogi suggested to Harrison that he, Paul McCartney and Ringo Starr stand for election as MPs for Liverpool as NLP candidates, but they declined.
In the 1997 general election, the NLP ran 197 candidates for Parliament in the UK, garnering 0.10% of the vote, with every candidate losing their deposit.
The NLP ran 16 candidates in the 20 by-elections held between 1992 and 1997, with every candidate losing their deposit. The NLP ran 8 candidates for the 16 by-elections held between 1997 and 2001, averaging 0.10% of the vote, with every candidate losing their deposit. The NLP did not run any candidates for Parliament in the 2001 general election or in the succeeding by-elections. The party, along with its Northern Ireland wing, voluntarily deregistered with the Electoral Commission at the end of 2003.
Northern Ireland.
According to the NLP, they prepared a 70-page report in response to the "1996 Framework Document of the British and Irish governments." The report was presented to leaders in Ireland, Northern Ireland and the U.S. Afterwards, NLP representatives participated in the "special elections to the Northern Ireland Forum", but withdrew before the election.
United States.
The Natural Law Party (United States) ran John Hagelin as its presidential candidate in 1992, 1996, and 2000. He was on ballots in 48 states and received 110,000 votes (0.12%) in 1996. The party also ran congressional and local candidates. In California, psychiatrist Harold H. Bloomfield ran as candidate for Governor in 1998. It attempted to merge with the Reform Party in 2000. The NLP in the United States was largely disbanded in 2004. However, some state affiliates, such as Michigan, have kept their ballot positions and allied with other small parties.

</doc>
<doc id="21826" url="http://en.wikipedia.org/wiki?curid=21826" title="Naturalistic fallacy">
Naturalistic fallacy

In philosophical ethics, the term "naturalistic fallacy" was introduced by British philosopher G. E. Moore in his 1903 book "Principia Ethica". Moore argues it would be fallacious to explain that which is "good" reductively in terms of natural properties such as "pleasant" or "desirable".
Moore's naturalistic fallacy is closely related to the is–ought problem, which comes from Hume's "Treatise". However, unlike Hume's view of the is–ought problem, Moore (and other proponents of ethical non-naturalism) did not consider the naturalistic fallacy to be at odds with moral realism.
The naturalistic fallacy should not be confused with a fallacious appeal to nature, a mistaken claim that something is good or right because it is natural (or bad or wrong because it is unnatural).
Different common uses.
The is–ought problem.
The term "naturalistic fallacy" is sometimes used to describe the deduction of an "ought" from an "is" (the Is–ought problem).
In using his categorical imperative Kant deduced that experience was necessary for their application. But experience on its own or the imperative on its own could not possibly identify an act as being moral or immoral. We can have no certain knowledge of morality from them, being incapable of deducing how things ought to be from the fact that they happen to be arranged in a particular manner in experience.
Bentham, in discussing the relations of law and morality, found that when people discuss problems and issues they talk about how they wish it would be as opposed to how it actually is. This can be seen in discussions of natural law and positive law. Bentham criticized natural law theory because in his view it was a naturalistic fallacy, claiming that it described how things ought to be instead of how things are.
Moore's discussion.
According to G. E. Moore's "Principia Ethica", when philosophers try to define "good" reductively in terms of natural properties like "pleasant" or "desirable", they are committing the naturalistic fallacy.
...the assumption that because some quality or combination of qualities invariably and necessarily accompanies the quality of goodness, or is invariably and necessarily accompanied by it, or both, this quality or combination of qualities is identical with goodness. If, for example, it is believed that whatever is pleasant is and must be good, or that whatever is good is and must be pleasant, or both, it is committing the naturalistic fallacy to infer from this that goodness and pleasantness are one and the same quality. The naturalistic fallacy is the assumption that because the words 'good' and, say, 'pleasant' necessarily describe the same objects, they must attribute the same quality to them.—Arthur N. Prior, "Logic And The Basis Of Ethics"
In defense of ethical non-naturalism, Moore's argument is concerned with the semantic and metaphysical underpinnings of ethics. In general, opponents of ethical naturalism reject ethical conclusions drawn from natural facts.
Moore argues that good, in the sense of intrinsic value, is simply ineffable: it cannot be defined because it is not a natural property, being "one of those innumerable objects of thought which are themselves incapable of definition, because they are the ultimate terms by reference to which whatever "is" capable of definition must be defined". On the other hand, ethical naturalists eschew such principles in favor of a more empirically accessible analysis of what it means to be good: for example, in terms of pleasure in the context of hedonism.
 That "pleased" does not mean "having the sensation of red", or anything else whatever, does not prevent us from understanding what it does mean. It is enough for us to know that "pleased" does mean "having the sensation of pleasure", and though pleasure is absolutely indefinable, though pleasure is pleasure and nothing else whatever, yet we feel no difficulty in saying that we are pleased. The reason is, of course, that when I say "I am pleased", I do not mean that "I" am the same thing as "having pleasure". And similarly no difficulty need be found in my saying that "pleasure is good" and yet not meaning that "pleasure" is the same thing as "good", that pleasure "means" good, and that good "means" pleasure. If I were to imagine that when I said "I am pleased", I meant that I was exactly the same thing as "pleased", I should not indeed call that a naturalistic fallacy, although it would be the same fallacy as I have called naturalistic with reference to Ethics.
 — G. E. Moore, ""
In , Moore argues that a property is either a complex of simple properties, or else it is irreducibly simple. Complex properties can be defined in terms of their constituent parts but a simple property has no parts. In addition to "good" and "pleasure", Moore suggests that colour qualia are undefined: if one wants to understand yellow, one must see examples of it. It will do no good to read the dictionary and learn that "yellow" names the colour of egg yolks and ripe lemons, or that "yellow" names the primary colour between green and orange on the spectrum, or that the perception of yellow is stimulated by electromagnetic radiation with a wavelength of between 570 and 590 nanometers, because yellow is all that and more, by the open question argument.
Bernard Williams called Moore's use of the term 'naturalistic fallacy' a "spectacular misnomer", the question being metaphysical, as opposed to rational.
Appeal to nature.
Some people use the phrase "naturalistic fallacy" or "appeal to nature" to characterize inferences of the form "This behaviour is natural; therefore, this behaviour is morally acceptable" or "This property is unnatural; therefore, this property is undesireable." Such inferences are common in discussions of homosexuality, environmentalism and veganism.
The naturalistic fallacy is the idea that what is found in nature is good. It was the basis for Social Darwinism, the belief that helping the poor and sick would get in the way of evolution, which depends on the survival of the fittest. Today, biologists denounce the Naturalistic Fallacy because they want to describe the natural world honestly, without people deriving morals about how we ought to behave (as in: If birds and beasts engage in adultery, infanticide, cannibalism, it must be OK).
 --Professor Steven Pinker
Criticism.
Some philosophers reject the naturalistic fallacy and/or suggest solutions for the proposed is-ought problem.
Sam Harris argues that it is possible to derive "ought" from "is", and even that it has already been done to some extent. He sees morality as a budding science. This view is critical of Moore's "simple indefinable terms" (which amount to qualia), arguing instead that such terms actually can be broken down into constituents.
Ralph McInerny suggests that "ought" is already bound up in "is", in so far as the very nature of things have ends/goals within them. For example, a clock is a device used to keep time. When one understands the function of a clock, then a standard of evaluation is implicit in the very description of the clock, i.e., because it "is" a clock, it "ought" to keep the time. Thus, if one cannot pick a good clock from a bad clock, then one does not really know what a clock is. In like manner, if one cannot determine good human action from bad, then one does not really know what the human person is.
Certain uses of the naturalistic fallacy refutation (a scheme of reasoning that declares an inference invalid because it incorporates an instance of the naturalistic fallacy) have been criticised as lacking rational bases, and labelled anti-naturalistic fallacy. For instance, Alex Walter wrote:
The refutations from naturalistic fallacy defined as inferring evaluative conclusions from purely factual premises do assert, implicitly, that there is no connection between the facts and the norms (in particular, between the facts and the mental process that led to adoption of the norms).

</doc>
<doc id="21828" url="http://en.wikipedia.org/wiki?curid=21828" title="Neapolitan ice cream">
Neapolitan ice cream

Neapolitan ice cream, sometimes known as harlequin ice cream, is made up of blocks of vanilla, chocolate, and strawberry ice cream side by side in the same container (typically with no packaging in between). Some brands intermix the flavors more, though the separate flavors are still clearly visible. 
Neapolitan ice cream was named in the late 19th century as a reflection of its presumed origins in the cuisine of the Italian city of Naples, and the many Neapolitan immigrants who brought their expertise in frozen desserts with them to the United States. Spumoni was introduced to the United States in the 1870s as Neapolitan-style ice cream. Early recipes used a variety of flavors; however, the number of three molded together was a common denominator, to resemble the Italian flag (cf. insalata tricolore). More than likely, chocolate, vanilla, and strawberry became the standard for the reason that they were the most popular flavors in the United States at the time of introduction.
Quotes from food historians.
"Cosmopolitan slice. A slice of ice-cream cake made with mousse mixture and ordinary ice cream, presented in a small pleated paper case. Neapolitan ice cream consists of three layers, each of a different colour and flavour (chocolate, strawberry, and vanilla), moulded into a block and cut into slices.
Neapolitan ice-cream makers were famous in Paris at the beginning of the 19th century, especially Tortoni, creator of numerous ice-cream cakes."
"Eighteenth century... confectioners' shops [were] very often run by Italians. Consequently ice creams were often called "Italian ice creams" or "Neapolitan ice creams" throughout the nineteenth century, and the purveying of such confections became associated with Italian immigrants."
"Neapolitan ice cream, different flavoured layers frozen together...[was] being first being talked about in the 1870s."
A cultural reference from "The New York Times" in 1887:"...in a dress of pink and white stripes, strongly resembling Neapolitan ice cream."
19th century descriptions.
1885 – "Neapolitan box" 
"You must have a Neapolitan box for this ice and fill it up in three or four layers with different coloured and flavoured ice creams (a water ice may be used with the custards); for instance, lemon, vanilla, chocolate and pistachio. Mould in the patent ice cave for about 1½ to 2 hours, turn it out, cut it in slices, and arrange neatly on the dish, on a napkin or dish-paper."
1894 – "Neapolitan Icey Cones"
"These are prepared by putting ices of various kinds and colors into a mold known as a Neapolitan ice box, which, when set and turned out, is cut into slices suitable for serving. However small the pieces, the block should be cut so that each person gets some of each kind. They are generally laid on a lace paper on an ice plate. Four or five kinds are usually put in the mold, though three sorts will do. The following will serve as a guide in arranging: First, vanilla cream, then raspberry or cherry or currant water; coffee or chocolate in the middle; the strawberry cream, with lemon or orange or pineapple water to finish. A cream ice flavored with any liqueur, a brown bread cream flavored with brandy, with a couple of bright-colored water ices, form another agreeable mixture. Tea cream may be introduced into almost any combination unless coffee were used. Banana cream, pistachio, or almond cream with cherry water and damson or strawberry water are other options.
The Neapolitan Ice Spoon has a double use; ice bowl is for putting the mixture into the mold, and the handle is for leveling it. The boxes may be made of tin, which is less expensive than pewter. They are generally sold small enough to make single ices, but these are much more troublesome to prepare. After filling the molds, if there is no cave, "bed" the ice in the usual way.
Cake.
In Australia there is a popular cake known as Neapolitan cake or marble cake, made with the same three colors of Neapolitan ice cream swirled through in a marble pattern, usually topped with pink icing.

</doc>
<doc id="21830" url="http://en.wikipedia.org/wiki?curid=21830" title="Nature">
Nature

Nature, in the broadest sense, is equivalent to the natural, physical, or material world or universe. "Nature" refers to the phenomena of the physical world, and also to life in general. It ranges in scale from the subatomic to the cosmic. The study of nature is a large part of science. Although humans are part of nature, human activity is often understood as a separate category from other natural phenomena.
The word "nature" is derived from the Latin word "natura", or "essential qualities, innate disposition", and in ancient times, literally meant "birth". "Natura" was a Latin translation of the Greek word "physis" (φύσις), which originally related to the intrinsic characteristics that plants, animals, and other features of the world develop of their own accord. The concept of nature as a whole, the physical universe, is one of several expansions of the original notion; it began with certain core applications of the word φύσις by pre-Socratic philosophers, and has steadily gained currency ever since. This usage continued during the advent of modern scientific method in the last several centuries.
Within the various uses of the word today, "nature" often refers to geology and wildlife. Nature may refer to the general realm of various types of living plants and animals, and in some cases to the processes associated with inanimate objects – the way that particular types of things exist and change of their own accord, such as the weather and geology of the Earth, and the matter and energy of which all these things are composed. It is often taken to mean the "natural environment" or wilderness–wild animals, rocks, forest, beaches, and in general those things that have not been substantially altered by human intervention, or which persist despite human intervention. For example, manufactured objects and human interaction generally are not considered part of nature, unless qualified as, for example, "human nature" or "the whole of nature". This more traditional concept of natural things which can still be found today implies a distinction between the natural and the artificial, with the artificial being understood as that which has been brought into being by a human consciousness or a human mind. Depending on the particular context, the term "natural" might also be distinguished from the or the supernatural.
Earth.
Earth (or, "the earth") is the only planet known to support life, and its natural features are the subject of many fields of scientific research. Within the solar system, it is third closest to the sun; it is the largest terrestrial planet and the fifth largest overall. Its most prominent climatic features are its two large polar regions, two relatively narrow temperate zones, and a wide equatorial tropical to subtropical region. Precipitation varies widely with location, from several metres of water per year to less than a millimetre. 71 percent of the Earth's surface is covered by salt-water oceans. The remainder consists of continents and islands, with most of the inhabited land in the Northern Hemisphere.
Earth has evolved through geological and biological processes that have left traces of the original conditions. The outer surface is divided into several gradually migrating tectonic plates. The interior remains active, with a thick layer of plastic mantle and an iron-filled core that generates a magnetic field. This iron core is composed of a solid inner phase, and a fluid outer phase. It is the rotation of the outer, fluid iron core that generates an electrical current through dynamo action, which in turn generates a strong magnetic field.
The atmospheric conditions have been significantly altered from the original conditions by the presence of life-forms, which create an ecological balance that stabilizes the surface conditions. Despite the wide regional variations in climate by latitude and other geographic factors, the long-term average global climate is quite stable during interglacial periods, and variations of a degree or two of average global temperature have historically had major effects on the ecological balance, and on the actual geography of the Earth.
Geology.
Geology is the science and study of the solid and liquid matter that constitutes the Earth. The field of geology encompasses the study of the composition, structure, physical properties, dynamics, and history of Earth materials, and the processes by which they are formed, moved, and changed. The field is a major academic discipline, and is also important for mineral and hydrocarbon extraction, knowledge about and mitigation of natural hazards, some Geotechnical engineering fields, and understanding past climates and environments.
Geological evolution.
The geology of an area evolves through time as rock units are deposited and inserted and deformational processes change their shapes and locations.
Rock units are first emplaced either by deposition onto the surface or intrude into the overlying rock. Deposition can occur when sediments settle onto the surface of the Earth and later lithify into sedimentary rock, or when as volcanic material such as volcanic ash or lava flows, blanket the surface. Igneous intrusions such as batholiths, laccoliths, dikes, and sills, push upwards into the overlying rock, and crystallize as they intrude.
After the initial sequence of rocks has been deposited, the rock units can be deformed and/or metamorphosed. Deformation typically occurs as a result of horizontal shortening, horizontal extension, or side-to-side (strike-slip) motion. These structural regimes broadly relate to convergent boundaries, divergent boundaries, and transform boundaries, respectively, between tectonic plates.
Historical perspective.
Earth is estimated to have formed 4.54 billion years ago from the solar nebula, along with the Sun and other planets. The moon formed roughly 20 million years later. Initially molten, the outer layer of the Earth cooled, resulting in the solid crust. Outgassing and volcanic activity produced the primordial atmosphere. Condensing water vapor, most or all of which came from ice delivered by comets, produced the oceans and other water sources. The highly energetic chemistry is believed to have produced a self-replicating molecule around 4 billion years ago.
Continents formed, then broke up and reformed as the surface of Earth reshaped over hundreds of millions of years, occasionally combining to make a supercontinent. Roughly 750 million years ago, the earliest known supercontinent Rodinia, began to break apart. The continents later recombined to form Pannotia which broke apart about 540 million years ago, then finally Pangaea, which broke apart about 180 million years ago.
During the Neoproterozoic era covered much of the Earth in glaciers and ice sheets. This hypothesis has been termed the "Snowball Earth", and it is of particular interest as it precedes the Cambrian explosion in which multicellular life forms began to proliferate about 530–540 million years ago.
Since the Cambrian explosion there have been five distinctly identifiable mass extinctions. The last mass extinction occurred some 66 million years ago, when a meteorite collision probably triggered the extinction of the non-avian dinosaurs and other large reptiles, but spared small animals such as mammals. Over the past 66 million years, mammalian life diversified.
Several million years ago, a species of small African ape gained the ability to stand upright. The subsequent advent of human life, and the development of agriculture and further civilization allowed humans to affect the Earth more rapidly than any previous life form, affecting both the nature and quantity of other organisms as well as global climate. By comparison, the Great Oxygenation Event, produced by the proliferation of algae during the Siderian period, required about 300 million years to culminate.
The present era is classified as part of a mass extinction event, the Holocene extinction event, the fastest ever to have occurred. Some, such as E. O. Wilson of Harvard University, predict that human destruction of the biosphere could cause the extinction of one-half of all species in the next 100 years. The extent of the current extinction event is still being researched, debated and calculated by biologists.
Atmosphere, climate, and weather.
The Earth's atmosphere is a key factor in sustaining the ecosystem. The thin layer of gases that envelops the Earth is held in place by gravity. Air is mostly nitrogen, oxygen, water vapor, with much smaller amounts of carbon dioxide, argon, etc. The atmospheric pressure declines steadily with altitude. The ozone layer plays an important role in depleting the amount of ultraviolet (UV) radiation that reaches the surface. As DNA is readily damaged by UV light, this serves to protect life at the surface. The atmosphere also retains heat during the night, thereby reducing the daily temperature extremes.
Terrestrial weather occurs almost exclusively in the lower part of the atmosphere, and serves as a convective system for redistributing heat. Ocean currents are another important factor in determining climate, particularly the major underwater thermohaline circulation which distributes heat energy from the equatorial oceans to the polar regions. These currents help to moderate the differences in temperature between winter and summer in the temperate zones. Also, without the redistributions of heat energy by the ocean currents and atmosphere, the tropics would be much hotter, and the polar regions much colder.
Weather can have both beneficial and harmful effects. Extremes in weather, such as tornadoes or hurricanes and cyclones, can expend large amounts of energy along their paths, and produce devastation. Surface vegetation has evolved a dependence on the seasonal variation of the weather, and sudden changes lasting only a few years can have a dramatic effect, both on the vegetation and on the animals which depend on its growth for their food.
Climate is a measure of the long-term trends in the weather. Various factors are known to influence the climate, including ocean currents, surface albedo, greenhouse gases, variations in the solar luminosity, and changes to the Earth's orbit. Based on historical records, the Earth is known to have undergone drastic climate changes in the past, including ice ages.
The climate of a region depends on a number of factors, especially latitude. A latitudinal band of the surface with similar climatic attributes forms a climate region. There are a number of such regions, ranging from the tropical climate at the equator to the polar climate in the northern and southern extremes. Weather is also influenced by the seasons, which result from the Earth's axis being tilted relative to its orbital plane. Thus, at any given time during the summer or winter, one part of the Earth is more directly exposed to the rays of the sun. This exposure alternates as the Earth revolves in its orbit. At any given time, regardless of season, the northern and southern hemispheres experience opposite seasons.
Weather is a chaotic system that is readily modified by small changes to the environment, so accurate weather forecasting is limited to only a few days. Overall, two things are happening worldwide: (1) temperature is increasing on the average; and (2) regional climates have been undergoing noticeable changes.
Water on Earth.
Water is a chemical substance that is composed of hydrogen and oxygen and is vital for all known forms of life. In typical usage, "water" refers only to its liquid form or state, but the substance also has a solid state, ice, and a gaseous state, water vapor or steam. Water covers 71% of the Earth's surface. On Earth, it is found mostly in oceans and other large water bodies, with 1.6% of water below ground in aquifers and 0.001% in the air as vapor, clouds, and precipitation. Oceans hold 97% of surface water, glaciers and polar ice caps 2.4%, and other land surface water such as rivers, lakes and ponds 0.6%. Additionally, a minute amount of the Earth's water is contained within biological bodies and manufactured products.
Oceans.
An ocean is a major body of saline water, and a principal component of the hydrosphere. Approximately 71% of the Earth's surface (an area of some 361 million square kilometers) is covered by ocean, a continuous body of water that is customarily divided into several principal oceans and smaller seas. More than half of this area is over 3,000 m deep. Average oceanic salinity is around 35 parts per thousand (ppt) (3.5%), and nearly all seawater has a salinity in the range of 30 to 38 ppt. Though generally recognized as several 'separate' oceans, these waters comprise one global, interconnected body of salt water often referred to as the World Ocean or global ocean. This concept of a global ocean as a continuous body of water with relatively free interchange among its parts is of fundamental importance to oceanography.
The major oceanic divisions are defined in part by the continents, various archipelagos, and other criteria: these divisions are (in descending order of size) the Pacific Ocean, the Atlantic Ocean, the Indian Ocean, the Southern Ocean and the Arctic Ocean. Smaller regions of the oceans are called seas, gulfs, bays and other names. There are also salt lakes, which are smaller bodies of landlocked saltwater that are not interconnected with the World Ocean. Two notable examples of salt lakes are the Aral Sea and the Great Salt Lake.
Lakes.
A lake (from Latin "lacus") is a terrain feature (or physical feature), a body of liquid on the surface of a world that is localized to the bottom of basin (another type of landform or terrain feature; that is, it is not global) and moves slowly if it moves at all. On Earth, a body of water is considered a lake when it is inland, not part of the ocean, is larger and deeper than a pond, and is fed by a river. The only world other than Earth known to harbor lakes is Titan, Saturn's largest moon, which has lakes of ethane, most likely mixed with methane. It is not known if Titan's lakes are fed by rivers, though Titan's surface is carved by numerous river beds. Natural lakes on Earth are generally found in mountainous areas, rift zones, and areas with ongoing or recent glaciation. Other lakes are found in endorheic basins or along the courses of mature rivers. In some parts of the world, there are many lakes because of chaotic drainage patterns left over from the last Ice Age. All lakes are temporary over geologic time scales, as they will slowly fill in with sediments or spill out of the basin containing them.
Ponds.
A pond is a body of standing water, either natural or man-made, that is usually smaller than a lake. A wide variety of man-made bodies of water are classified as ponds, including water gardens designed for aesthetic ornamentation, fish ponds designed for commercial fish breeding, and solar ponds designed to store thermal energy. Ponds and lakes are distinguished from streams via current speed. While currents in streams are easily observed, ponds and lakes possess thermally driven microcurrents and moderate wind driven currents. These features distinguish a pond from many other aquatic terrain features, such as stream pools and tide pools.
Rivers.
A river is a natural watercourse, usually freshwater, flowing toward an ocean, a lake, a sea or another river. In a few cases, a river simply flows into the ground or dries up completely before reaching another body of water. Small rivers may also be called by several other names, including stream, creek, brook, rivulet, and rill; there is no general rule that defines what can be called a river. Many names for small rivers are specific to geographic location; one example is "Burn" in Scotland and North-east England. Sometimes a river is said to be larger than a creek, but this is not always the case, due to vagueness in the language. A river is part of the hydrological cycle. Water within a river is generally collected from precipitation through surface runoff, groundwater recharge, springs, and the release of stored water in natural ice and snowpacks (i.e., from glaciers).
Streams.
A stream is a flowing body of water with a current, confined within a bed and stream banks. In the United States a stream is classified as a watercourse less than 60 ft wide. Streams are important as conduits in the water cycle, instruments in groundwater recharge, and they serve as corridors for fish and wildlife migration. The biological habitat in the immediate vicinity of a stream is called a riparian zone. Given the status of the ongoing Holocene extinction, streams play an important corridor role in connecting fragmented habitats and thus in conserving biodiversity. The study of streams and waterways in general involves many branches of inter-disciplinary natural science and engineering, including hydrology, fluvial geomorphology, aquatic ecology, fish biology, riparian ecology and others.
Ecosystems.
Ecosystems are composed of a variety of abiotic and biotic components that function in an interrelated way. The structure and composition is determined by various environmental factors that are interrelated. Variations of these factors will initiate dynamic modifications to the ecosystem. Some of the more important components are: soil, atmosphere, radiation from the sun, water, and living organisms.
Central to the ecosystem concept is the idea that living organisms interact with every other element in their local environment. Eugene Odum, a founder of ecology, stated: "Any unit that includes all of the organisms (ie: the "community") in a given area interacting with the physical environment so that a flow of energy leads to clearly defined trophic structure, biotic diversity, and material cycles (i.e.: exchange of materials between living and nonliving parts) within the system is an ecosystem." Within the ecosystem, species are connected and dependent upon one another in the food chain, and exchange energy and matter between themselves as well as with their environment. The human ecosystem concept is grounded in the deconstruction of the human/nature dichotomy and the premise that all species are ecologically integrated with each other, as well as with the abiotic constituents of their biotope.
A smaller unit of size is called a microecosystem. For example, a microsystem can be a stone and all the life under it. A "macroecosystem" might involve a whole ecoregion, with its drainage basin.
Wilderness.
Wilderness is generally defined as areas that have not been significantly modified by human activity. Wilderness areas can be found in preserves, estates, farms, conservation preserves, ranches, , national parks and even in urban areas along rivers, gulches or otherwise undeveloped areas. and protected parks are considered important for the survival of certain species, ecological studies, conservation, solitude, and recreation. Some nature writers believe wilderness areas are vital for the human spirit and creativity, and some Ecologists consider wilderness areas to be an integral part of the Earth's self-sustaining natural ecosystem (the biosphere). They may also preserve historic genetic traits and that they provide habitat for wild flora and fauna that may be difficult to recreate in zoos, arboretums or laboratories.
Life.
Although there is no universal agreement on the definition of life, scientists generally accept that the biological manifestation of life is characterized by organization, metabolism, growth, adaptation, response to stimuli and reproduction. Life may also be said to be simply the characteristic state of organisms.
Properties common to terrestrial organisms (plants, animals, fungi, protists, archaea and bacteria) are that they are cellular, carbon-and-water-based with complex organization, having a metabolism, a capacity to grow, respond to stimuli, and reproduce. An entity with these properties is generally considered life. However, not every definition of life considers all of these properties to be essential. Human-made analogs of life may also be considered to be life.
The biosphere is the part of Earth's outer shell – including land, surface rocks, water, air and the atmosphere – within which life occurs, and which biotic processes in turn alter or transform. From the broadest geophysiological point of view, the biosphere is the global ecological system integrating all living beings and their relationships, including their interaction with the elements of the lithosphere (rocks), hydrosphere (water), and atmosphere (air). The entire Earth contains over 75 billion tons (150 "trillion" pounds or about 6.8×1013 kilograms) of biomass (life), which lives within various environments within the biosphere.
Over nine-tenths of the total biomass on Earth is plant life, on which animal life depends very heavily for its existence. More than 2 million species of plant and animal life have been identified to date, and estimates of the actual number of existing species range from several million to well over 50 million. The number of individual species of life is constantly in some degree of flux, with new species appearing and others ceasing to exist on a continual basis. The total number of species is in rapid decline.
Evolution.
The origin of life on Earth is not well understood, but it is known to have occurred at least 3.5 billion years ago, during the hadean or archean eons on a primordial Earth that had a substantially different environment than is found at present. These life forms possessed the basic traits of self-replication and inheritable traits. Once life had appeared, the process of evolution by natural selection resulted in the development of ever-more diverse life forms.
Species that were unable to adapt to the changing environment and competition from other life forms became extinct. However, the fossil record retains evidence of many of these older species. Current fossil and DNA evidence shows that all existing species can trace a continual ancestry back to the first primitive life forms.
The advent of photosynthesis in very basic forms of plant life worldwide allowed the sun's energy to be harvested to create conditions allowing for more complex life. The resultant oxygen accumulated in the atmosphere and gave rise to the ozone layer. The incorporation of smaller cells within larger ones resulted in the development of yet more complex cells called eukaryotes. Cells within colonies became increasingly specialized, resulting in true multicellular organisms. With the ozone layer absorbing harmful ultraviolet radiation, life colonized the surface of Earth.
Microbes.
The first form of life to develop on the Earth were microbes, and they remained the only form of life until about a billion years ago when multi-cellular organisms began to appear. Microorganisms are single-celled organisms that are generally microscopic, and smaller than the human eye can see. They include Bacteria, Fungi, Archaea and Protista.
These life forms are found in almost every location on the Earth where there is liquid water, including in the Earth's interior.
Their reproduction is both rapid and profuse. The combination of a high mutation rate and a horizontal gene transfer ability makes them highly adaptable, and able to survive in new environments, including outer space. They form an essential part of the planetary ecosystem. However, some microorganisms are pathogenic and can post health risk to other organisms.
Plants and Animals.
Originally Aristotle divided all living things between plants, which generally do not move fast enough for humans to notice, and animals. In Linnaeus' system, these became the kingdoms Vegetabilia (later Plantae) and Animalia. Since then, it has become clear that the Plantae as originally defined included several unrelated groups, and the fungi and several groups of algae were removed to new kingdoms. However, these are still often considered plants in many contexts. Bacterial life is sometimes included in flora, and some classifications use the term "bacterial flora" separately from "plant flora".
Among the many ways of classifying plants are by regional floras, which, depending on the purpose of study, can also include "fossil flora", remnants<br> of plant life from a previous era. People in many regions and countries take great pride in their individual arrays of characteristic flora, which can vary widely across the globe due to differences in climate and terrain.
Regional floras commonly are divided into categories such as "native flora" and "agricultural and garden flora", the lastly mentioned of which are intentionally grown and cultivated. Some types of "native flora" actually have been introduced centuries ago by people migrating from one region or continent to another, and become an integral part of the native, or natural flora of the place to which they were introduced. This is an example of how human interaction with nature can blur the boundary of what is considered nature.
Another category of plant has historically been carved out for "weeds". Though the term has fallen into disfavor among botanists as a formal way to categorize "useless" plants, the informal use of the word "weeds" to describe those plants that are deemed worthy of elimination is illustrative of the general tendency of people and societies to seek to alter or shape the course of nature. Similarly, animals are often categorized in ways such as "domestic", "farm animals", "wild animals", "pests", etc. according to their relationship to human life.
Animals as a category have several characteristics that generally set them apart from other living things. Animals are eukaryotic and usually multicellular (although see Myxozoa), which separates them from bacteria, archaea and most protists. They are heterotrophic, generally digesting food in an internal chamber, which separates them from plants and algae. They are also distinguished from plants, algae, and fungi by lacking cell walls.
With a few exceptions, most notably the sponges (Phylum Porifera), animals have bodies differentiated into separate tissues. These include muscles, which are able to contract and control locomotion, and a nervous system, which sends and processes signals. There is also typically an internal digestive chamber. The eukaryotic cells possessed by all animals are surrounded by a characteristic extracellular matrix composed of collagen and elastic glycoproteins. This may be calcified to form structures like shells, bones, and spicules, a framework upon which cells can move about and be reorganized during development and maturation, and which supports the complex anatomy required for mobility.
Human interrelationship.
Although humans comprise only a minuscule proportion of the total living biomass on Earth, the human effect on nature is disproportionately large. Because of the extent of human influence, the boundaries between what humans regard as nature and "made environments" is not clear cut except at the extremes. Even at the extremes, the amount of natural environment that is free of discernible human influence is diminishing at an increasingly rapid pace.
The development of technology by the human race has allowed the greater exploitation of natural resources and has helped to alleviate some of the risk from natural hazards. In spite of this progress, however, the fate of human civilization remains closely linked to changes in the environment. There exists a highly complex feedback loop between the use of advanced technology and changes to the environment that are only slowly becoming understood. Man-made threats to the Earth's natural environment include pollution, deforestation, and disasters such as oil spills. Humans have contributed to the extinction of many plants and animals.
Humans employ nature for both leisure and economic activities. The acquisition of natural resources for industrial use remains the primary component of the world's economic system. Some activities, such as hunting and fishing, are used for both sustenance and leisure, often by different people. Agriculture was first adopted around the 9th millennium BCE. Ranging from food production to energy, nature influences economic wealth.
Although early humans gathered uncultivated plant materials for food and employed the medicinal properties of vegetation for healing, most modern human use of plants is through agriculture. The clearance of large tracts of land for crop growth has led to a significant reduction in the amount available of forestation and wetlands, resulting in the loss of habitat for many plant and animal species as well as increased erosion.
Aesthetics and beauty.
Beauty in nature has historically been a prevalent theme in art and books, filling large sections of libraries and bookstores. That nature has been depicted and celebrated by so much art, photography, poetry and other literature shows the strength with which many people associate nature and beauty. Reasons why this association exists, and what the association consists of, are studied by the branch of philosophy called aesthetics. Beyond certain basic characteristics that many philosophers agree about to explain what is seen as beautiful, the opinions are virtually endless. Nature and wildness have been important subjects in various eras of world history. An early tradition of landscape art began in China during the Tang Dynasty (618–907). The tradition of representing nature "as it is" became one of the aims of Chinese painting and was a significant influence in Asian art.
Although natural wonders are celebrated in the Psalms and the Book of Job, wilderness portrayals in art became more prevalent in the 1800s, especially in the works of the Romantic movement. British artists John Constable and J. M. W. Turner turned their attention to capturing the beauty of the natural world in their paintings. Before that, paintings had been primarily of religious scenes or of human beings. William Wordsworth's poetry described the wonder of the natural world, which had formerly been viewed as a threatening place. Increasingly the valuing of nature became an aspect of Western culture. This artistic movement also coincided with the Transcendentalist movement in the Western world. A common classical idea of beautiful art involves the word mimesis, the imitation of nature. Also in the realm of ideas about beauty in nature is that the perfect is implied through perfect mathematical forms and more generally by patterns in nature. As David Rothenburg writes, "The beautiful is the root of science and the goal of art, the highest possibility that humanity can ever hope to see".:281
Value of Nature.
In her 1988 book "If Women Counted", Marilyn Waring points to how the value of Nature is not measured in human economic activity, leading to destruction of Nature.
Matter and energy.
Some fields of science see nature as matter in motion, obeying certain laws of nature which science seeks to understand. For this reason the most fundamental science is generally understood to be "physics" – the name for which is still recognizable as meaning that it is the study of nature.
Matter is commonly defined as the substance of which physical objects are composed. It constitutes the observable universe. The visible components of the universe are now believed to compose only 4.9 percent of the total mass. The remainder is believed to consist of 26.8 percent cold dark matter and 68.3 percent dark energy. The exact nature of these components is still unknown and is under intensive investigation by physicists.
The behavior of matter and energy throughout the observable universe appears to follow well-defined physical laws. These laws have been employed to produce cosmological models that successfully explain the structure and the evolution of the universe we can observe. The mathematical expressions of the laws of physics employ a set of twenty physical constants that appear to be static across the observable universe. The values of these constants have been carefully measured, but the reason for their specific values remains a mystery.
Beyond Earth.
Outer space, also simply called "space", refers to the relatively empty regions of the universe outside the atmospheres of celestial bodies. "Outer" space is used to distinguish it from airspace (and terrestrial locations). There is no discrete boundary between the Earth's atmosphere and space, as the atmosphere gradually attenuates with increasing altitude. Outer space within the Solar System is called interplanetary space, which passes over into interstellar space at what is known as the heliopause.
Outer space is sparsely filled with several dozen types of organic molecules discovered to date by microwave spectroscopy, blackbody radiation left over from the big bang and the origin of the universe, and cosmic rays, which include ionized atomic nuclei and various subatomic particles. There is also some gas, plasma and dust, and small meteors. Additionally, there are signs of human life in outer space today, such as material left over from previous manned and unmanned launches which are a potential hazard to spacecraft. Some of this debris re-enters the atmosphere periodically.
Although the Earth is the only body within the solar system known to support life, evidence suggests that in the distant past the planet Mars possessed bodies of liquid water on the surface. For a brief period in Mars' history, it may have also been capable of forming life. At present though, most of the water remaining on Mars is frozen.
If life exists at all on Mars, it is most likely to be located underground where liquid water can still exist.
Conditions on the other terrestrial planets, Mercury and Venus, appear to be too harsh to support life as we know it. But it has been conjectured that Europa, the fourth-largest moon of Jupiter, may possess a sub-surface ocean of liquid water and could potentially host life.
Astronomers have started to discover extrasolar Earth analogs – planets that lie in the habitable zone of space surrounding a star, and therefore could possibly host life as we know it.
See also.
Media:
Organizations:
Science:
Philosophy:

</doc>
<doc id="21833" url="http://en.wikipedia.org/wiki?curid=21833" title="New moon">
New moon

In astronomy, new moon is the first phase of the Moon, when it orbits as seen from the Earth, the moment when the Moon and the Sun have the same ecliptical longitude.
The Moon is not visible at this time except when it is seen in silhouette during a solar eclipse or illuminated by earthshine. See the article on phases of the Moon for further details.
A lunation or synodic month is the mean (average) time for from one new moon to the next. 
In the J2000.0 epoch, the average length of a lunation is 29.530588 days (or 29 days, 12 hours, 44 minutes, and 3 seconds). However, the length of any one synodic month can vary from 29.26 to 29.80 days due to the perturbing effects of the Sun's gravity on the Moon's eccentric orbit. 
In a lunar calendar, each month corresponds to a lunation. Each lunar cycle can be assigned a unique Lunation Number to identify it.
Determining new moons: an approximate formula.
The length of a lunation is about 29.53 days. Its precise duration is linked to many phenomena in nature, such as the variation between (the extreme highest and lowest tides, respectively).
An approximate formula to compute the mean moments of new moon (conjunction between Sun and Moon) for successive months is:
where N is an integer, starting with 0 for the first new moon in the year 2000, and that is incremented by 1 for each successive synodic month; and the result d is the number of days (and fractions) since 2000-01-01 00:00:00 reckoned in the time scale known as Terrestrial Time (TT) used in ephemerides.
To obtain this moment expressed in Universal Time (UT, world clock time), add the result of following approximate correction to the result d obtained above:
Periodic perturbations change the time of true conjunction from these mean values. For all new moons between 1601 and 2401, the maximum difference is 0.592 days = 14h13m in either direction. The duration of a lunation ("i.e." the time from new moon to the next new moon) varies in this period between 29.272 and 29.833 days, i.e. −0.259d = 6h12m shorter, or +0.302d = 7h15m longer than average. This range is smaller than the difference between mean and true conjunction, because during one lunation the periodic terms cannot all change to their maximum opposite value.
See the article on the full moon cycle for a fairly simple method to compute the moment of new moon more accurately.
The long-term error of the formula is approximately: 1 cy2 seconds in TT, and 11 cy2 seconds in UT ("cy" is centuries since 2000; see section "Explanation of the formulae" for details.)
Explanation of the formula.
The moment of mean conjunction can easily be computed from an expression for the mean ecliptical longitude of the Moon minus the mean ecliptical longitude of the Sun (Delauney parameter D). Jean Meeus gave formulae to compute this in his popular "Astronomical Formulae for Calculators" based on the ephemerides of Brown and Newcomb (ca. 1900); and in his 1st edition of "Astronomical Algorithms" based on the ELP2000-85 (the 2nd edition uses ELP2000-82 with improved expressions from Chapront "et al." in 1998). These are now outdated: Chapront "et al." (2002) published improved parameters. Also Meeus's formula uses a fractional variable to allow computation of the four main phases, and uses a second variable for the secular terms. For the convenience of the reader, the formula given above is based on Chapront's latest parameters and expressed with a single integer variable, and the following additional terms have been added:
constant term:
quadratic term:
The theoretical tidal contribution to ΔT is about +42 s/cy2 the smaller observed value is thought to be mostly due to changes in the shape of the Earth. Because the discrepancy is not fully explained, uncertainty of our prediction of UT (rotation angle of the Earth) may be as large as the difference between these values: 11 s/cy2. The error in the position of the Moon itself is only maybe 0.5"/cy2, or (because the apparent mean angular velocity of the Moon is about 0.5"/s), 1 s/cy2 in the time of conjunction with the Sun.
Lunation Number.
The Lunation Number or Lunation Cycle is a number given to each lunation beginning from a certain one in history. Several conventions are in use.
The most commonly used is the Brown Lunation Number (BLN), which defines lunation 1 as beginning at the first new moon of 1923, the year when Ernest William Brown's lunar theory was introduced in the major national astronomical almanacs. Lunation 1 occurred at approximately 02:41 UTC, January 17, 1923. New moons occur on Julian Dates
formula_3, with the given uncertainty due to varying torques from the sun.
Another increasingly popular lunation number (simply called the Lunation Number), introduced by Jean Meeus, defines lunation 0 as beginning on the first new moon of 2000 (this occurred at approximately 18:14 UTC, January 6, 2000). The formula relating this Lunation Number with the Brown Lunation Number is: BLN = LN + 953.
The Goldstine Lunation Number refers to the lunation numbering used by Herman Goldstine in his 1973 book "New and Full Moons: 1001 B.C. to A.D. 1651", with lunation 0 beginning on January 11, 1001 BC, and can be calculated using GLN = LN + 37105.
The Hebrew Lunation Number is the count of lunations in the Hebrew calendar with lunation 1 beginning on October 7, 3761 BC. It can be calculated using HLN = LN + 71234.
The Islamic Lunation Number is the count of lunations in the Islamic calendar with lunation 1 as beginning on July 16, 622. It can be calculated using ILN = LN + 17038.
The Thai Lunation Number is called "มาสเกณฑ์" (Maasa-Kendha), defines lunation 0 as beginning of the SouthEast-Asian Calendar on Sunday March 22, 638 (Julian Calendar). It can be calculated using TLN = LN + 16843.
Lunar calendars.
In non-astronomical contexts, "new moon" refers to the first visible crescent of the Moon, after conjunction with the Sun. This takes place over the western horizon in a brief period between sunset and moonset, and therefore the precise time and even the date of the appearance of the new moon by this definition will be influenced by the geographical location of the observer. The astronomical new moon, sometimes known as the "dark moon" to avoid confusion, occurs by definition at the moment of conjunction in ecliptical longitude with the Sun, when the Moon is invisible from the Earth. This moment is unique and does not depend on location, and in certain circumstances it coincides with a solar eclipse.
In the above meaning , the first crescent marks the beginning of the month in lunar calendars such as the Muslim calendar, and in lunisolar calendars such as the Hebrew calendar, Hindu calendars, and Buddhist calendar. In the Chinese calendar, the beginning of the month is marked by the dark moon.

</doc>
<doc id="21834" url="http://en.wikipedia.org/wiki?curid=21834" title="B-spline">
B-spline

In the mathematical subfield of numerical analysis, a B-spline, or basis spline, is a spline function that has minimal support with respect to a given degree, smoothness, and domain partition. Any spline function of given degree can be expressed as a linear combination of B-splines of that degree. Cardinal B-splines have knots that are equidistant from each other. B-splines can be used for curve-fitting and numerical differentiation of experimental data.
In the computer-aided design and computer graphics, spline functions are constructed as linear combinations of B-splines with a set of control points.
Introduction.
B-splines were investigated as early as the nineteenth century by Nikolai Lobachevsky. The term "B-spline" was coined by Isaac Jacob Schoenberg and is short for basis spline. A spline function is a piecewise polynomial function of degree <"k" in a variable "x". The places where the pieces meet are known as knots. The number of internal knots must be equal to, or greater than "k"-1. Thus the spline function has limited support. The key property of spline functions is that they are continuous at the knots. Some derivatives of the spline function may also be continuous, depending on whether the knots are distinct or not. A fundamental theorem states that every spline function of a given degree, smoothness, and domain partition, can be uniquely represented as a linear combination of B-splines of that same degree and smoothness, and over that same partition.
Definition.
A B-spline is a piecewise polynomial function of degree <"n" in a variable "x". It is defined over a domain "t" 0 ≤ "x" ≤ "t"m, m = n. The points where "x" = "t" j are known as knots or break-points. The number of internal knots is equal to the degree of the polynomial if there are no knot multiplicities. The knots must be in ascending order. The number of knots is the minimum for the degree of the B-spline, which has a non-zero value only in the range between the first and last knot. Each piece of the function is a polynomial of degree "<n" between and including adjacent knots. A B-spline is a continuous function at the knots. When all internal knots are distinct its derivatives are also continuous up to the derivative of degree "n"-1. If internal knots are coincident at a given value of "x", the continuity of derivative order is reduced by 1 for each additional knot.
For any given set of knots, the B-spline is unique, hence the name, B being short for Basis. The usefulness of B-splines lies in the fact that any spline function of order "n" on a given set of knots can be expressed as a linear combination of B-splines.
This follows from the fact that all pieces have the same continuity properties, within their individual range of support, at the knots.
Expressions for the polynomial pieces can be derived by means of a recursion formula
That is, formula_4 is piecewise constant one or zero indicating which knot span "x" is in (zero if knot span "j" is repeated). The recursion equation is in two parts: 
ramps from zero to one as "x" goes from formula_6 to formula_7 and
ramps from one to zero as "x" goes from formula_9 to formula_10. The corresponding "B"s are zero outside those respective ranges. For example, formula_11 is a triangular function that is zero below formula_12, ramps to one at formula_13 and back to zero at and beyond formula_14. However, because B-spline basis functions have local support, B-splines are typically computed by algorithms that do not need to evaluate basis functions where they are zero, such as de Boor's algorithm.
This relation leads directly to the FORTRAN-coded algorithm BSPLV which generates values of the B-splines of order "n" at "x". The following scheme illustrates how each piece of degree "n" is a linear combination of the pieces of B-splines of degree "n"-1 to its left.
Application of the recursion formula with the knots at 0, 1, 2, and 3 gives the pieces of the uniform B-spline of degree 2 
These pieces are shown in the diagram. The continuity property of a quadratic spline function and its first derivative at the internal knots are illustrated, as follows
The second derivative of a spline function of degree 2 is discontinuous at the knots.
Faster variants of the de Boor algorithm have been proposed but they suffer from comparatively lower stability.
Cardinal B-spline.
A cardinal B-spline has a constant separation, "h", between knots. The cardinal B-splines for a given degree "n" are just shifted copies of each other. They can be obtained from the simpler definition.
The "placeholder" notation is used to indicate that the "n"th divided difference of the function formula_23 of the two variables "t" and "x" is to be taken by fixing "x" and considering formula_24 as a function of "t" alone.
A cardinal B-spline has uniform spaced knots, therefore interpolation between the knots equals convolution with a smoothing kernel.
Example, if we want to interpolate three values inbetween B-spline nodes (formula_25), we can write the signal as:
formula_26
Convolution of the signal formula_27 with a rectangle function formula_28 gives first order interpolated b-spline values. Second-order B-spline interpolation is convolution with a rectangle function twiceformula_29, by iterative filtering with a rectangle function higher order interpolation is obtained.
Fast b-spline interpolation on a uniform sample domain can be done by iterative mean-filtering. Alternative, a rectangle function equals Sinc in Fourier domain. Therefore cubic spline interpolation equals multiplying the signal in Fourier domain with Sinc^4.
See Irwin–Hall distribution#Special cases for algebraic expressions for the cardinal B-splines of degree 1-4.
P-spline.
The term P-spline stands for "penalized B-spline". It refers to using the B-spline representation where the coefficients are determined partly by the data to be fitted, and partly by an additional penalty function that aims to impose smoothness to avoid overfitting.
Derivative expressions.
The derivative of a B-spline of degree "k" is simply a function of B-splines of degree "k"-1.
This implies that
which shows that there is a simple relationship between the derivative of a spline function and the B-splines of degree one less.
Relationship to piecewise/composite Bézier.
A piecewise/composite Bézier curve is a series of Bézier curves joined with at least C0 continuity (the last point of one curve coincides with the starting point of the next curve). Depending on the application, additional smoothness requirements (such as C1 or C2 continuity) may be added. C1 continuous curves have identical tangents at the breakpoint (where the two curves meet). C2 continuous curves have identical curvature at the breakpoint. 
To gain C2 continuity the Bézier Curve loses local control, because to enforce C2 continuity the control points are dependent on each other. If a single control point moves, the whole spline needs to be re-evaluated. B-Splines have both C2 continuity and local control, but they lose the interpolation property of a piecewise Bézier. 
Curve fitting.
Usually in curve fitting, a set of data points is fitted with a curve defined by some mathematical function. For example common types of curve fitting use a polynomial or a set of exponential functions. When there is no theoretical basis for choosing a fitting function, the curve may be fitted with a spline function composed of a sum of B-splines, using the method of least squares. Thus, the objective function for least squares minimization is, for a spline function of degree "k",
"W(x)" is a weight and "y(x)" is the datum value at "x". The coefficients formula_33 are the parameters to be determined. The knot values may be fixed or they too may be treated as parameters.
The main difficulty in applying this process is in determining the number of knots to use and where they should be placed. de Boor suggests various strategies to address this problem. For instance, the spacing between knots is decreased in proportion to the curvature (2nd. derivative) of the data. A few applications have been published. For instance, the use of B-splines for fitting single Lorentzian and Gaussian curves has been investigated. Optimal spline functions of degrees 3-7 inclusive, based on symmetric arrangements of 5, 6, and 7 knots, have been computed and the method was applied for smoothing and differentiation of spectroscopic curves. In a comparable study, the two-dimensional version of the Savitzky-Golay filtering and the spline method produced better results than moving average or Chebyshev filtering.
NURBS.
In computer aided design, computer aided manufacturing, and computer graphics, a powerful extension of B-splines is non-uniform rational B-splines (NURBS). NURBS are essentially B-splines in homogeneous coordinates. Like B-splines, they are defined by their order, and a knot vector, and a set of control points, but unlike simple B-splines, the control points each have a weight. When the weight is equal to 1, a NURBS is simply a B-spline and as such NURBS generalizes both B-splines and Bézier curves and surfaces, the primary difference being the weighting of the control points which makes NURBS curves "rational".
By evaluating a NURBS at various values of the parameter, the curve can be traced through space; likewise, by evaluating a NURBS surface at various values of the two parameters, the surface can be represented in Cartesian space.
Like B-splines, NURBS control points determine the shape of the curve. Each point of the curve is computed by taking a weighted sum of a number of control points. The weight of each point varies according to the governing parameter. For a curve of degree "d", the influence of any control point is only nonzero in "d"+1 intervals (knot spans) of the parameter space. Within those intervals, the weight changes according to a polynomial function (basis functions) of degree "d". At the boundaries of the intervals, the basis functions go smoothly to zero, the smoothness being determined by the degree of the polynomial.
The knot vector is a sequence of parameter values that determines where and how the control points affect the NURBS curve. The number of knots is always equal to the number of control points plus curve degree plus one. Each time the parameter value enters a new knot span, a new control point becomes active, while an old control point is discarded.
A NURBS curve takes the following form:
Here the notation is as follows. "u" is the independent variable (instead of "x"), "k" is the number of control points, "N" is a B-spline (used instead of "B"), "n" is the polynomial degree, "P" is a control point and "w" is a weight. The denominator is a normalizing factor that evaluates to one if all weights are one.
It is customary to write this as
in which the functions
are known as the rational basis functions.
A NURBS surface is obtained as the tensor product of two NURBS curves, thus using two independent parameters "u" and "v" (with indices "i" and "j" respectively):
with
as rational basis functions.

</doc>
<doc id="21836" url="http://en.wikipedia.org/wiki?curid=21836" title="North Pole">
North Pole

The North Pole, also known as the Geographic North Pole or Terrestrial North Pole, is, subject to the caveats explained below, defined as the point in the Northern Hemisphere where the Earth's axis of rotation meets its surface. It should not be confused with the North Magnetic Pole.
The North Pole is the northernmost point on the Earth, lying diametrically opposite the South Pole. It defines geodetic latitude 90° North, as well as the direction of true north. At the North Pole all directions point south; all lines of longitude converge there, so its longitude can be defined as any degree value.
While the South Pole lies on a continental land mass, the North Pole is located in the middle of the Arctic Ocean amid waters that are almost permanently covered with constantly shifting sea ice. This makes it impractical to construct a permanent station at the North Pole (unlike the South Pole). However, the Soviet Union, and later Russia, constructed a number of manned drifting stations on a generally annual basis since 1937, some of which have passed over or very close to the Pole. Since 2002, the Russians have also annually established a base, Barneo, close to the Pole. This operates for a few weeks during early spring. Studies in the 2000s predicted that the North Pole may become seasonally ice-free due to Arctic ice shrinkage, with timescales varying from 2016 to the late 21st century or later.
The sea depth at the North Pole has been measured at 4261 m by the Russian Mir submersible in 2007 and at 4,087 m (13,410 ft) by USS "Nautilus" in 1958. The nearest land is usually said to be Kaffeklubben Island, off the northern coast of Greenland about 700 km away, though some perhaps non-permanent gravel banks lie slightly closer. The nearest permanently inhabited place is Alert in the Qikiqtaaluk Region, Nunavut, Canada, which is located 817 km from the Pole.
Precise definition.
The Earth's axis of rotation – and hence the position of the North Pole – was commonly believed to be fixed (relative to the surface of the Earth) until, in the 18th century, the mathematician Leonhard Euler predicted that the axis might "wobble" slightly. Around the beginning of the 20th century astronomers noticed a small apparent "variation of latitude," as determined for a fixed point on Earth from the observation of stars. Part of this variation could be attributed to a wandering of the Pole across the Earth's surface, by a range of a few meters. The wandering has several periodic components and an irregular component. The component with a period of about 435 days is identified with the 8 month wandering predicted by Euler and is now called the Chandler wobble after its discoverer. The exact point of intersection of the Earth's axis and the Earth's surface, at any given moment, is called the "instantaneous pole", but because of the "wobble" this cannot be used as a definition of a fixed North Pole (or South Pole) when metre-scale precision is required.
It is desirable to tie the system of Earth coordinates (latitude, longitude, and elevations or orography) to fixed landforms. Of course, given plate tectonics and isostasy, there is no system in which all geographic features are fixed. Yet the International Earth Rotation and Reference Systems Service and the International Astronomical Union have defined a framework called the International Terrestrial Reference System.
Exploration.
Pre-1900.
As early as the 16th century, many eminent people correctly believed that the North Pole was in a sea, which in the 19th century was called the Polynya or Open Polar Sea. It was therefore hoped that passage could be found through ice floes at favorable times of the year. Several expeditions set out to find the way, generally with whaling ships, already commonly used in the cold northern latitudes.
One of the earliest expeditions to set out with the explicit intention of reaching the North Pole was that of British naval officer William Edward Parry, who in 1827 reached latitude 82°45′ North. In 1871 the Polaris expedition, a US attempt on the Pole led by Charles Francis Hall, ended in disaster. Another British Royal Navy attempt on the pole, part of the British Arctic Expedition, by Commander Albert H. Markham reached a then-record 83°20'26" North in May 1876 before turning back. An 1879–1881 expedition commanded by US naval officer George W. DeLong ended tragically when their ship the USS "Jeanette", was crushed by ice. Over half the crew, including DeLong, were lost.
In April 1895 the Norwegian explorers Fridtjof Nansen and Hjalmar Johansen struck out for the Pole on skis after leaving Nansen's icebound ship "Fram". The pair reached latitude 86°14′ North before they abandoned the attempt and turned southwards, eventually reaching Franz Josef Land.
In 1897 Swedish engineer Salomon August Andrée and two companions tried to reach the North Pole in the hydrogen balloon "Örnen" ("Eagle"), but came down 300 km north of Kvitøya, the northeasternmost part of the Svalbard archipelago. They trekked to Kvitøya but died there three months later. In 1930 the remains of this expedition were found by the Norwegian Bratvaag Expedition.
The Italian explorer Luigi Amedeo, Duke of the Abruzzi and Captain Umberto Cagni of the Italian Royal Navy (Regia Marina) sailed the converted whaler "Stella Polare" ("Pole Star") from Norway in 1899. On 11 March 1900 Cagni led a party over the ice and reached latitude 86° 34’ on 25 April, setting a new record by beating Nansen's result of 1895 by 35 to. Cagni barely managed to return to the camp, remaining there until 23 June. On 16 August the "Stella Polare" left Rudolf Island heading south and the expedition returned to Norway.
1900–1940.
The US explorer Frederick Cook claimed to have reached the North Pole on 21 April 1908 with two Inuit men, Ahwelah and Etukishook, but he was unable to produce convincing proof and his claim is not widely accepted.
The conquest of the North Pole was for many years credited to US Navy engineer Robert Peary, who claimed to have reached the Pole on 6 April 1909, accompanied by Matthew Henson and four Inuit men, Ootah, Seeglo, Egingwah, and Ooqueah. However, Peary's claim remains highly disputed and controversial. Those who accompanied Peary on the final stage of the journey were not trained in navigation, and thus could not independently confirm his navigational work, which some claim to have been particularly sloppy as he approached the Pole.
The distances and speeds that Peary claimed to have achieved once the last support party turned back seem incredible to many people, almost three times that which he had accomplished up to that point. Peary's account of a journey to the Pole and back while traveling along the direct line – the only strategy that is consistent with the time constraints that he was facing – is contradicted by Henson's account of tortuous detours to avoid pressure ridges and open leads.
The British explorer Wally Herbert, initially a supporter of Peary, researched Peary's records in 1989 and found that there were significant discrepancies in the explorer's navigational records. He concluded that Peary had not reached the Pole. Support for Peary came again in 2005, however, when British explorer Tom Avery and four companions recreated the outward portion of Peary's journey with replica wooden sleds and Canadian Eskimo Dog teams, reaching the North Pole in 36 days, 22 hours – nearly five hours faster than Peary. However, Avery's fastest 5-day march was 90 nautical miles, significantly short of the 135 claimed by Peary. Avery writes on his web site that "The admiration and respect which I hold for Robert Peary, Matthew Henson and the four Inuit men who ventured North in 1909, has grown enormously since we set out from Cape Columbia. Having now seen for myself how he travelled across the pack ice, I am more convinced than ever that Peary did indeed discover the North Pole."
Another rejection of Peary's claim arrived in 2009, when E. Myles Standish of the California Institute of Technology, an experienced referee of scientific claims, reported numerous alleged lacunae and inconsistencies.
The first claimed flight over the Pole was made on 9 May 1926 by US naval officer Richard E. Byrd and pilot Floyd Bennett in a Fokker tri-motor aircraft. Although verified at the time by a committee of the National Geographic Society, this claim has since been undermined by the 1996 revelation that Byrd's long-hidden diary's solar sextant data (which the NGS never checked) consistently contradict his June 1926 report's parallel data by over 100 mi. The secret report's alleged en-route solar sextant data were inadvertently so impossibly overprecise that he excised all these alleged raw solar observations out of the version of the report finally sent to geographical societies five months later (while the original version was hidden for 70 years), a realization first published in 2000 by the University of Cambridge after scrupulous refereeing.
According to Standish, "Anyone who is acquainted with the facts and has any amount of logical reasoning can not avoid the conclusion that neither Cook, nor Peary, nor Byrd reached the North Pole; and they all knew it."
The first consistent, verified, and scientifically convincing attainment of the Pole was on 12 May 1926, by Norwegian explorer Roald Amundsen and his US sponsor Lincoln Ellsworth from the airship "Norge". "Norge", though Norwegian-owned, was designed and piloted by the Italian Umberto Nobile. The flight started from Svalbard in Norway, and crossed the Arctic Ocean to Alaska. Nobile, with several scientists and crew from the "Norge", overflew the Pole a second time on 24 May 1928, in the airship "Italia". The "Italia" crashed on its return from the Pole, with the loss of half the crew.
In May 1937 the world's first North Pole ice station, North Pole-1, was established by Soviet scientists by air 20 kilometres (13 mi) from the North Pole. The expedition members: oceanographer Pyotr Shirshov, meteorologist Yevgeny Fyodorov, radio operator Ernst Krenkel, and the leader Ivan Papanin conducted scientific research at the station for the next nine months. By 19 February 1938, when the group was picked up by the ice breakers "Taimyr" and "Murman", their station had drifted 2850 km to the eastern coast of Greenland.
1940–2000.
In May 1945 an RAF Lancaster of the "Aries" expedition became the first Commonwealth aircraft to overfly the North Geographic and North Magnetic Poles. The plane was piloted by David Cecil McKinley of the Royal Air Force. It carried an 11-man crew, with Kenneth C. Maclure of the Royal Canadian Air Force in charge of all scientific observations. In 2006, Maclure was honoured with a spot in Canada's Aviation Hall of Fame.
Discounting Peary's disputed claim, the first men to set foot at the North Pole were a Soviet party including geophysicists Mikhail Ostrekin and Pavel Senko, oceanographers Mikhail Somov and Pavel Gordienko, and other scientists and flight crew (24 people in total) of Aleksandr Kuznetsov's "Sever-2" expedition (March–May 1948). It was organized by the Chief Directorate of the Northern Sea Route. The party flew on three planes (pilots Ivan Cherevichnyy, Vitaly Maslennikov and Ilya Kotov) from Kotelny Island to the North Pole and landed there at 4:44pm (Moscow Time, ) on 23 April 1948. They established a temporary camp and for the next two days conducted scientific observations. On 26 April the expedition flew back to the continent.
Next year, on 9 May 1949, two other Soviet scientists (Vitali Volovich and Andrei Medvedev) became the first people to parachute onto the North Pole. They jumped from a Douglas C-47 Skytrain, registered CCCP H-369.
On 3 May 1952, U.S. Air Force Lieutenant Colonel Joseph O. Fletcher and Lieutenant William Pershing Benedict, along with scientist Albert P. Crary, landed a modified Douglas C-47 Skytrain at the North Pole. Some Western sources considered this to be the first landing at the Pole until the Soviet landings became widely known.
The United States Navy submarine "USS Nautilus" (SSN-571) crossed the North Pole on 3 August 1958. On 17 March 1959 "USS Skate" (SSN-578) surfaced at the Pole, breaking through the ice above it, becoming the first naval vessel to do so.
Setting aside Peary's claim, the first confirmed surface conquest of the North Pole was that of Ralph Plaisted, Walt Pederson, Gerry Pitzl and Jean Luc Bombardier, who traveled over the ice by snowmobile and arrived on 19 April 1968. The United States Air Force independently confirmed their position.
On 6 April 1969, Wally Herbert and companions Allan Gill, Roy Koerner and Kenneth Hedges of the British Trans-Arctic Expedition became the first men to reach the North Pole on foot (albeit with the aid of dog teams and airdrops). They continued on to complete the first surface crossing of the Arctic Ocean – and by its longest axis, Barrow, Alaska to Svalbard – a feat that has never been repeated. Because of suggestions (later proven false) of Plaisted's use of air transport, some sources classify Herbert's expedition as the first confirmed to reach the North Pole over the ice surface by any means. In the 1980s, Plaisted's pilots Weldy Phipps and Ken Lee signed affidavits asserting that no such airlift was provided. It is also said that Herbert was the first person to reach the pole of inaccessibility.
On 17 August 1977, the Soviet nuclear-powered icebreaker "Arktika" completed the first surface vessel journey to the North Pole.
In 1982 Ranulph Fiennes and Charles R. Burton became the first people to cross the Arctic Ocean in a single season. They departed from Cape Crozier, Ellesmere Island, on 17 February 1982 and arrived at the geographic North Pole on 10 April 1982. They travelled on foot and snowmobile. From the Pole, they travelled towards Svalbard but, due to the unstable nature of the ice, ended their crossing at the ice edge after drifting south on an ice floe for 99 days. They were eventually able to walk to their expedition ship "MV Benjamin Bowring" and boarded it on 4 August 1982 at position 80:31N 00:59W. As a result of this journey, which formed a section of the three-year Transglobe Expedition 1979–1982, Fiennes and Burton became the first people to complete a circumnavigation of the world via both North and South Poles, by surface travel alone. This achievement remains unchallenged to this day.
In 1985, Sir Edmund Hillary (the first man to stand on the summit of Mount Everest) and Neil Armstrong (the first man to stand on the moon) landed at the North Pole in a small twin-engined ski plane. Hillary thus became the first man to stand at both poles and on the summit of Everest.
In 1986, Will Steger, with seven teammates, became the first to be confirmed as reaching the Pole by dogsled and without resupply.
On 6 May 1986, USS "Archerfish" (SSN 678), USS "Ray" (SSN 653) and USS Hawkbill (SSN 666) surfaced at the North Pole, the first tri-submarine surfacing at the North Pole.
On 21 April 1987, Shinji Kazama of Japan became the first person to reach the North Pole on a motorcycle.
On 18 May 1987, USS "Billfish" (SSN 676), USS "Sea Devil" (SSN 664) and HMS "Superb" (S 109) surfaced at the North Pole, the first international surfacing at the North Pole.
In 1988, a 13-man strong team (9 Soviets, 4 Canadians) skied across the arctic from Siberia to northern Canada. One of the Canadians, Richard Weber became the first person to reach the Pole from both sides of the Arctic Ocean.
On 4 May 1990, Børge Ousland and Erling Kagge became the first explorers ever to reach the North Pole unsupported, after a 58-day ski trek from Ellesmere Island in Canada, a distance of 800 km.
On 7 September 1991, the German research vessel "Polarstern" and the Swedish icebreaker "Oden" reached the North Pole as the first conventional powered vessels. Both scientific parties and crew took oceanographic and geological samples and had a common tug of war and a football game on an ice floe. Polarstern again reached the pole exactly 10 years later with the "Healy".
In 1998, 1999, and 2000 Lada Niva Marshs (special very large wheeled versions made by BRONTO, Lada/Vaz's experimental product division) were driven to the North Pole. The 1998 expedition was dropped by parachute and completed the track to the North Pole. The 2000 expedition departed from a Russian research base around 114 km from the Pole and claimed an average speed of 20–15 km/h in an average temperature of −30 degrees.
21st century.
In recent years, journeys to the North Pole by air (landing by helicopter or on a runway prepared on the ice) or by icebreaker have become relatively routine, and are even available to small groups of tourists through adventure holiday companies. Parachute jumps have frequently been made onto the North Pole in recent years. The temporary seasonal Russian camp of Barneo has been established by air a short distance from the Pole annually since 2002, and caters for scientific researchers as well as tourist parties. Trips from the camp to the Pole itself may be arranged overland or by helicopter.
The first attempt at underwater exploration of the North Pole was made on 22 April 1998 by Russian firefighter and diver Andrei Rozhkov with the support of the Diving Club of Moscow State University, but ended in fatality. The next attempted dive at the North Pole was organized the next year by the same diving club, and ended in success on 24 April 1999. The divers were Michael Wolff (Austria), Brett Cormick (UK), and Bob Wass (USA).
In 2005, the United States Navy submarine USS "Charlotte" (SSN-766) surfaced through 155 cm of ice at the North Pole and spent 18 hours there.
In July 2007, British endurance swimmer Lewis Gordon Pugh completed a 1 km swim at the North Pole. His feat, undertaken to highlight the effects of global warming, took place in clear water that had opened up between the ice floes. His later attempt to paddle a kayak to the North Pole in late 2008, following the erroneous prediction of clear water to the Pole, was stymied when his expedition found itself stuck in thick ice after only three days. The expedition was then abandoned.
By September 2007 the North Pole had been visited 66 times by different surface ships: 54 times by Soviet and Russian icebreakers, 4 times by Swedish "Oden", 3 times by German "Polarstern", 3 times by USCGC "Healy" and USCGC "Polar Sea", and once by CCGS "Louis S. St-Laurent" and by Swedish "Vidar Viking".
2007 descent to the North Pole seabed.
On 2 August 2007, a Russian scientific expedition Arktika 2007 made the first ever manned descent to the ocean floor at the North Pole, to a depth of 4.3 km, as part of the research programme in support of Russia's 2001 extended continental shelf claim to a large swathe of the Arctic Ocean floor. The descent took place in two MIR submersibles and was led by Soviet and Russian polar explorer Artur Chilingarov. In a symbolic act of visitation, the Russian flag was placed on the ocean floor exactly under the Pole.
The expedition was the latest in a series of efforts intended to give Russia a dominant influence in the Arctic according to the New York Times. The warming Arctic climate and summer shrinkage of the iced area has attracted the attention of many countries, such as China and the United States, toward the top of the world, where resources and shipping routes may soon be exploitable.
MLAE 2009 Expedition.
In 2009, the Russian Marine Live-Ice Automobile Expedition—MLAE 2009 (Vasily Elagin as a leader, and a team of Sergey Larin, Afanasy Makovnev, Vladimir Obikhod, Alexey Ushakov, Alexey Shkrabkin, and Nikolay Nikulshin) reached the North Pole on two custom-built 6 x 6 low-pressure-tire ATVs—Yemelya 1 and Yemelya 2—designed by Vasily Elagin, a known Russian mountain climber, explorer, and engineer. The vehicles reached the North Pole on 26 April 2009, 17:30 (Moscow time). The expedition was supported by the Russian Geographical Society. The Russian Book of Records recognized it as the first successful vehicle trip to the Geographical North Pole.
MLAE 2013 Expedition.
On 1 March 2013, the Russian Marine Live-Ice Automobile Expedition — MLAE 2013 (Vasily Elagin as a leader, and a team of Andrey Vankov, Sergey Isayev, Nikolay Kozlov, Afanasy Makovnev, Vladimir Obikhod, and Alexey Shkrabkin) on two custom-built 6 x 6 low-pressure-tire ATVs—Yemelya 3 and Yemelya 4—started from Golomyanny Island (the Severnaya Zemlya Archipelago) to the North Pole across drifting ice of the Arctic Ocean. The vehicles reached the Pole on 6 April and then continued to the Canadian coast. The coast was reached on 30 April 2013 (83°08N, 075°59W), and on 5 May 2013, the expedition finished in Resolute Bay, NU. The way between the Russian borderland (Machtovyi Island of the Severnaya Zemlya Archipelago, 80°15N, 097°27E) and the Canadian coast (83°08N, 075°59W) took 55 days; it was ~2300 km across drifting ice and about 4000 km in total. The expedition was totally self-dependent and used no external supplies. The expedition was supported by the Russian Geographical Society.
Day and night.
The sun at the North Pole is continuously above the horizon during the summer and continuously below the horizon during the winter. Sunrise is just before the March equinox (around 20 March); the sun then takes three months to reach its highest point of near 23½° elevation at the summer solstice (around 21 June), after which time it begins to sink, reaching sunset just after the September equinox (around 23 September). When the sun is visible in the polar sky, it appears to move in a horizontal circle above the horizon. This circle gradually rises from near the horizon just after the vernal equinox to its maximum elevation (in degrees) above the horizon at summer solstice and then sinks back toward the horizon before sinking below it at the autumnal equinox.
A civil twilight period of about two weeks occurs before sunrise and after sunset, a nautical twilight period of about five weeks occurs before sunrise and after sunset and an astronomical twilight period of about seven weeks occurs before sunrise and after sunset.
These effects are caused by a combination of the Earth's axial tilt and its revolution around the sun. The direction of the Earth's axial tilt, as well as its angle relative to the plane of the Earth's orbit around the sun, remains very nearly constant over the course of a year (both change very slowly over long time periods). At northern midsummer the North Pole is facing towards the sun to its maximum extent. As the year progresses and the Earth moves around the sun, the North Pole gradually turns away from the sun until at midwinter it is facing away from the Sun to its maximum extent. A similar sequence is observed at the South Pole, with a six-month time difference.
Time.
In most places on Earth, local time is determined by longitude, such that the time of day is more-or-less synchronised to the position of the sun in the sky (for example, at midday the sun is roughly at its highest). This line of reasoning fails at the North Pole, where the sun rises and sets only once per year, and all lines of longitude, and hence all time zones, converge. There is no permanent human presence at the North Pole and no particular time zone has been assigned. Polar expeditions may use any time zone that is convenient, such as Greenwich Mean Time, or the time zone of the country from which they departed.
Climate.
The North Pole is substantially warmer than the South Pole because it lies at sea level in the middle of an ocean (which acts as a reservoir of heat), rather than at altitude on a continental land mass.
Winter (January) temperatures at the North Pole can range from about -43 C to -26 C, perhaps averaging around -34 C. Summer temperatures (June, July and August) average around the freezing point (0 C). The highest temperature yet recorded is 5 C, much warmer than the South Pole's record high of only -12.3 C.
The sea ice at the North Pole is typically around 2 to thick, although ice thickness, its spatial extent, and the fraction of open water within the ice pack can vary rapidly and profoundly in response to weather and climate. Studies have shown that the average ice thickness has decreased in recent years. It is likely that global warming has contributed to this, but it is not possible to attribute the recent abrupt decrease in thickness entirely to the observed warming in the Arctic. Reports have also predicted that within a few decades the Arctic Ocean will be entirely free of ice in the summer. This may have significant commercial implications; see "Territorial Claims," below.
The retreat of the Arctic sea ice will accelerate global warming, as less ice cover reflects less solar radiation, and may have serious climate implications by contributing to Arctic cyclone generation.
Flora and fauna.
Polar bears are believed rarely to travel beyond about 82° North owing to the scarcity of food, though tracks have been seen in the vicinity of the North Pole, and a 2006 expedition reported sighting a polar bear just 1 mi from the Pole. The ringed seal has also been seen at the Pole, and Arctic foxes have been observed less than 60 km away at 89°40′ N.
Birds seen at or very near the Pole include the snow bunting, northern fulmar and black-legged kittiwake, though some bird sightings may be distorted by the tendency of birds to follow ships and expeditions.
Fish have been seen in the waters at the North Pole, but these are probably few in number. A member of the Russian team that descended to the North Pole seabed in August 2007 reported seeing no sea creatures living there. However, it was later reported that a sea anemone had been scooped up from the seabed mud by the Russian team and that video footage from the dive showed unidentified shrimps and amphipods.
Territorial claims to the North Pole and Arctic regions.
Currently, under international law, no country owns the North Pole or the region of the Arctic Ocean surrounding it. The five surrounding Arctic countries, Russian Federation (the biggest country), Canada, Norway, Denmark (via Greenland), and the United States, are limited to a 200 nmi exclusive economic zone around their coasts, and the area beyond that is administered by the International Seabed Authority.
Upon ratification of the United Nations Convention on the Law of the Sea, a country has 10 years to make claims to an extended continental shelf beyond its 200-mile exclusive economic zone. If validated, such a claim gives the claimant state rights to what may be on or beneath the sea bottom within the claimed zone. Norway (ratified the convention in 1996), Russia (ratified in 1997), Canada (ratified in 2003) and Denmark (ratified in 2004) have all launched projects to base claims that certain areas of Arctic continental shelves should be subject to their sole sovereign exploitation.
In 1907 Canada invoked a "sector principle" to claim sovereignty over a sector stretching from its coasts to the North Pole. This claim has not been relinquished, but was not consistently pressed until 2013.
However, in 2014, Denmark claimed part of the sea bed, including the North Pole.
Cultural associations.
In some Western cultures, the geographic North Pole is described as the location of Santa Claus' workshop and residence, although the depictions have been inconsistent between the geographic and magnetic North Pole. Canada Post has assigned postal code H0H 0H0 to the North Pole (referring to Santa's traditional exclamation of "Ho ho ho!").
This association reflects an age-old esoteric mythology of Hyperborea that posits the North Pole, the otherworldly world-axis, as the abode of God and superhuman beings. The popular figure of the pole-dwelling Santa Claus thus functions as an archetype of spiritual purity and transcendence.
As Henry Corbin has documented, the North Pole plays a key part in the cultural worldview of Sufism and Iranian mysticism. "The Orient sought by the mystic, the Orient that cannot be located on our maps, is in the direction of the north, beyond the north."
Owing to its remoteness, the Pole is sometimes identified with a mysterious mountain of ancient Islamic tradition called Mount Qaf (Jabal Qaf), the "farthest point of the earth". According to certain authors, the Jabal Qaf of Muslim cosmology is a version of Rupes Nigra, a mountain whose ascent, like Dante's climbing of the Mountain of Purgatory, represents the pilgrim's progress through spiritual states. In Iranian theosophy, the heavenly Pole, the focal point of the spiritual ascent, acts as a magnet to draw beings to its "palaces ablaze with immaterial matter." 
Further reading.
</dl>

</doc>
<doc id="21837" url="http://en.wikipedia.org/wiki?curid=21837" title="Nanometre">
Nanometre

The nanometre (International spelling as used by the International Bureau of Weights and Measures; SI symbol: nm) or nanometer (American spelling) is a unit of length in the metric system, equal to one billionth of a metre. The name combines the SI prefix "nano-" (from the Ancient Greek νάνος, "nanos", "dwarf") with the parent unit name "metre" (from Greek μέτρον, "metrοn", "unit of measurement"). It can be written in scientific notation as , in engineering notation as 1 E−9 m, and is simply 1/1,000,000,000 m. One nanometre equals ten ångströms.
Use.
The nanometre is often used to express dimensions on an atomic scale: the diameter of a helium atom, for example, is about 0.1 nm, and that of a ribosome is about 20 nm. The nanometre is also commonly used to specify the wavelength of electromagnetic radiation near the visible part of the spectrum: visible light ranges from around 400 to 800 nm. The angstrom, which is equal to 0.1 nm, was formerly used for these purposes.
History.
The nanometre was formerly known as the millimicrometre – or, more commonly, the millimicron for short – since it is 1/1000 of a micron (micrometre), and was often denoted by the symbol mµ or (more rarely) µµ. In 1960, the U.S. National Bureau of Standards adopted the prefix "nano-" for "a billionth". The nanometre is often associated with the field of nanotechnology. Since the late 1980s, it has also been used to describe generations of the manufacturing technology in the semiconductor industry.

</doc>
<doc id="21840" url="http://en.wikipedia.org/wiki?curid=21840" title="National Transportation Safety Board">
National Transportation Safety Board

The National Transportation Safety Board (NTSB) is an independent U.S. government investigative agency responsible for civil transportation accident investigation. In this role, the NTSB investigates and reports on aviation accidents and incidents, certain types of highway crashes, ship and marine accidents, pipeline incidents and railroad accidents. When requested, the NTSB will assist the military and foreign governments with accident investigation. The NTSB is also in charge of investigating cases of hazardous materials releases that occur during transportation. Deborah Hersman was appointed as NTSB Chairman in July 2009. Christopher A. Hart was designated Vice Chairman on August 18, 2009 for a two-year term. He then became Acting Chairman after Hersman stepped down. The agency is based in Washington, D.C. As of 2013, it has four regional offices around the country and runs a training center in Ashburn, Virginia.
History.
The origin of the NTSB was in the Air Commerce Act of 1926. The NTSB was established in 1967 as the federal government's primary accident investigation agency for all modes of transportation – aviation, highway, rail, marine and pipeline. The core of the new agency was composed of the Civil Aeronautics Board's Bureau of Safety (The CAB retained its economic regulation of the airline industry until it was closed on December 31, 1984, due to the Airline Deregulation Act of 1978). Originally established with strong ties to the Department of Transportation, these ties were later severed under the Independent Safety Board Act of 1974. The organization receives its authority from Chapter 11, Title 49 of the United States Code. It has investigated over 140,000 aviation incidents since its establishment.
Organization.
The board has five members nominated by the President and confirmed by the Senate for five-year terms, one of whom is nominated as the Chairman by the President and then approved by the Senate for a fixed 2-year term. Another member is designated as vice-chairman and becomes acting chairman when there is no formal chairman.
No more than three of the five members can be from the same political party.
Organization within the Board is composed of separate sub-offices for highway safety, maritime safety, aviation safety, railroad, pipeline, and hazardous materials investigations, research and engineering, communications, and administrative law judges. These sub-offices report to the Office of the Managing Director.
Investigations.
The NTSB is normally the lead organization in the investigation of a transportation accident within its sphere. However, this power can be surrendered to other organizations if the Attorney General declares the case to be linked to an intentional criminal act, although the NTSB would still provide technical support in such investigations. This occurred during the investigation of the September 11, 2001, attacks when the Department of Justice took over the investigation.
An investigation of a major accident within the United States typically starts with the creation of a "go team," composed of specialists in fields relating to the occurrence. This is followed by the designation of other organizations or corporations as parties to the investigation. The Board may then choose to hold public hearings on the issue. Ultimately, it will publish a final report and may issue safety recommendations. The Board has no legal authority to implement, or impose, its recommendations. That burden falls upon regulators at either the federal or state level or individual transportation companies.
The NTSB has primacy in investigating every civil aviation accident in the United States (the Federal Aviation Administration (FAA) is always a party to these investigations, but the NTSB is the investigating agency). For certain accidents, due to resource limitations, the Board will ask the FAA to collect the factual information at the scene of the accident; the NTSB bases its report on that information.
The NTSB may assist in incident or accident investigations occurring outside the United States under certain circumstances. These may include accidents or incidents involving American-registered or American-owned civil aircraft or aircraft with U.S. manufactured components in foreign air space.
The NTSB will also on occasion provide technical and other advice to transportation investigative boards in countries that do not have the equipment or specialized technicians available to undertake all aspects of a complex investigation.
The NTSB's authority to investigate other transportation accidents varies by mode. For example, it investigates highway accidents "in cooperation with the States." For marine investigations, jurisdiction between the NTSB and the U.S. Coast Guard is prescribed in a detailed Memorandum of Understanding between the two agencies. For those railroad and pipeline accidents it chooses to investigate, it has primacy.
A little-known responsibility of the NTSB is that it serves as a court of appeals for airmen, aircraft mechanics, certificated aviation-related companies and mariners who have their licenses suspended or revoked by the federal government. The Board's determinations may be appealed to the federal court system by the losing party, whether it is the individual or company, on the one hand, or the FAA or the Coast Guard, on the other.
The Safety Board maintains a training academy in Ashburn, Virginia, where it conducts courses for its employees and professionals in other government agencies, foreign governments or private companies, in areas such as general accident investigation, specific elements of investigations like survival factors or human performance, or related matters like family affairs or media relations. The facility houses for training purposes the reconstruction of more than 90 feet of the TWA Flight 800 Boeing 747, which was recovered from the Atlantic Ocean after it crashed on July 17, 1996, following a fuel tank explosion.
Recommendations.
The Board's most important product is the safety recommendation. The NTSB has issued about 13,000 safety recommendations in its history, the vast majority of which have been adopted in whole or in part by the entities to which they were directed.
Among transportation safety improvements brought about or inspired by NTSB recommendations:
Since 1990 the NTSB has maintained a Most Wanted List of Transportation Safety Improvements, in which it highlights those recommendations that would provide the most significant — and sometimes immediate — benefit to the traveling public. The Board conducts a press conference every year to announce changes to that list.
Significant investigations conducted by the NTSB in all modes of transportation in recent years include the collapse of the I-35 highway bridge in Minneapolis, Minnesota; the collision between two transit trains in Washington, D.C.; the pipeline explosion that destroyed much of a neighborhood in San Bruno, California; the sinking of an amphibious vessel in Philadelphia; and the crash of a regional airliner near Buffalo, New York.
In addition, the NTSB has assisted the National Aeronautics and Space Administration (NASA) in its investigations of both the Challenger and the Columbia space shuttle disasters; assisted the Department of Justice during the September 11, 2001, terrorist attack investigations; and assisted the U.S. military in its investigation of the aircraft that crashed in the former Yugoslavia that took the lives of more than 30 Americans, including Commerce Secretary Ron Brown.

</doc>
<doc id="21843" url="http://en.wikipedia.org/wiki?curid=21843" title="Nucleosome">
Nucleosome

A nucleosome is a basic unit of DNA packaging in eukaryotes, consisting of a segment of DNA wound in sequence around eight histone protein cores. This structure is often compared to thread wrapped around a spool.
Nucleosomes form the fundamental repeating units of eukaryotic chromatin, which is used to pack the large eukaryotic genomes into the nucleus while still ensuring appropriate access to it (in mammalian cells approximately 2 m of linear DNA have to be packed into a nucleus of roughly 10 µm diameter). Nucleosomes are folded through a series of successively higher order structures to eventually form a chromosome; this both compacts DNA and creates an added layer of regulatory control, which ensures correct gene expression. Nucleosomes are thought to carry epigenetically inherited information in the form of covalent modifications of their core histones.
Nucleosomes were observed as particles in the electron microscope by Don and Ada Olins and their existence and structure (as histone octamers surrounded by approximately 200 base pairs of DNA) were proposed by Roger Kornberg. The role of the nucleosome as a general gene repressor was demonstrated by Lorch et al. in vitro and by Han and Grunstein in vivo.
The nucleosome core particle consists of approximately 147 base pairs of DNA wrapped in 1.67 left-handed superhelical turns around a histone octamer consisting of 2 copies each of the core histones H2A, H2B, H3, and H4. Core particles are connected by stretches of "linker DNA", which can be up to about 80 bp long. Technically, a nucleosome is defined as the core particle plus one of these linker regions; however the word is often synonymous with the core particle. Genome-wide nucleosome positioning maps are now available for many model organisms including mouse liver and brain.
Linker histones such as H1 and its isoforms are involved in chromatin compaction and sit at the base of the nucleosome near the DNA entry and exit binding to the linker region of the DNA. Non-condensed nucleosomes without the linker histone resemble "beads on a string of DNA" under an electron microscope.
In contrast to most eukaryotic cells, mature sperm cells largely use protamines to package their genomic DNA, most likely to achieve an even higher packaging ratio. Histone equivalents and a simplified chromatin structure have also been found in Archea, suggesting that eukaryotes are not the only organisms that use nucleosomes.
Structure.
Structure of the core particle.
Overview.
Pioneering structural studies in the 1980s by Aaron Klug's group provided the first evidence that an octamer of histone proteins wraps DNA around itself in about two turns of a left-handed superhelix. In 1997 the first near atomic resolution crystal structure of the nucleosome was solved by the Richmond group, showing the most important details of the particle. The human alpha-satellite palindromic DNA critical to achieving the 1997 nucleosome crystal structure was developed by the Bunick group at Oak Ridge National Laboratory in Tennessee. The structures of over 20 different nucleosome core particles have been solved to date, including those containing histone variants and histones from different species. The structure of the nucleosome core particle is remarkably conserved, and even a change of over 100 residues between frog and yeast histones results in electron density maps with an overall root mean square deviation of only 1.6Å.
The nucleosome core particle (NCP).
The nucleosome core particle (shown in the figure) consists of about 146 bp of DNA wrapped in 1.67 left-handed superhelical turns around the histone octamer, consisting of 2 copies each of the core histones H2A, H2B, H3, and H4. Adjacent nucleosomes are joined by a stretch of free DNA termed "linker DNA" (which varies from 10 - 80 bp in length depending on species and tissue type).
Nucleosome core particles are observed when chromatin in interphase is treated to cause the chromatin to unfold partially. The resulting image, via an electron microscope, is "beads on a string". The string is the DNA, while each bead in the nucleosome is a core particle. The nucleosome core particle is composed of DNA and histone proteins.
Partial DNAse digestion of chromatin reveals its nucleosome structure. Because DNA portions of nucleosome core particles are less accessible for DNAse than linking sections, DNA gets digested into fragments of lengths equal to multiplicity of distance between nucleosomes (180, 360, 540 base pairs etc.). Hence very characteristic pattern similar to ladder is visible during gel electrophoresis of that DNA. Such digestion can occur also under natural conditions during apoptosis ("cell suicide" or programmed cell death), because autodestruction of DNA typically is its part.
Protein interactions within the nucleosome.
The core histone proteins contain a characteristic structural motif termed the "histone fold," which consists of three alpha-helices (α1-3) separated by two loops (L1-2). In solution, the histones form H2A-H2B heterodimers and H3-H4 heterotetramers. Histones dimerise about their long α2 helices in an anti-parallel orientation, and, in the case of H3 and H4, two such dimers form a 4-helix bundle stabilised by extensive H3-H3’ interaction. The H2A/H2B dimer binds onto the H3/H4 tetramer due to interactions between H4 and H2B, which include the formation of a hydrophobic cluster. 
The histone octamer is formed by a central H3/H4 tetramer sandwiched between two H2A/H2B dimers. Due to the highly basic charge of all four core histones, the histone octamer is stable only in the presence of DNA or very high salt concentrations.
Histone - DNA interactions.
The nucleosome contains over 120 direct protein-DNA interactions and several hundred water-mediated ones. Direct protein - DNA interactions are not spread evenly about the octamer surface but rather located at discrete sites. These are due to the formation of two types of DNA binding sites within the octamer; the α1α1 site, which uses the α1 helix from two adjacent histones, and the L1L2 site formed by the L1 and L2 loops. Salt links and hydrogen bonding between both side-chain basic and hydroxyl groups and main-chain amides with the DNA backbone phosphates form the bulk of interactions with the DNA. This is important, given that the ubiquitous distribution of nucleosomes along genomes requires it to be a non-sequence-specific DNA-binding factor. Although nucleosomes tend to prefer some DNA sequences over others, they are capable of binding practically to any sequence, which is thought to be due to the flexibility in the formation of these water-mediated interactions. In addition, non-polar interactions are made between protein side-chains and the deoxyribose groups, and an arginine side-chain intercalates into the DNA minor groove at all 14 sites where it faces the octamer surface.
The distribution and strength of DNA-binding sites about the octamer surface distorts the DNA within the nucleosome core. The DNA is non-uniformly bent and also contains twist defects. The twist of free B-form DNA in solution is 10.5 bp per turn. However, the overall twist of nucleosomal DNA is only 10.2 bp per turn, varying from a value of 9.4 to 10.9 bp per turn.
Histone tail domains.
The histone tail extensions constitute up to 30% by mass of histones, but are not visible in the crystal structures of nucleosomes due to their high intrinsic flexibility, and have been thought to be largely unstructured. The N-terminal tails of histones H3 and H2B pass through a channel formed by the minor grooves of the two DNA strands, protruding from the DNA every 20 bp. The N-terminal tail of histone H4, on the other hand, has a region of highly basic amino acids (16-25), which, in the crystal structure, forms an interaction with the highly acidic surface region of a H2A-H2B dimer of another nucleosome, being potentially relevant for the higher-order structure of nucleosomes. This interaction is thought to occur under physiological conditions also, and suggests that acetylation of the H4 tail distorts the higher-order structure of chromatin.
Higher order structure.
The organization of the DNA that is achieved by the nucleosome cannot fully explain the packaging of DNA observed in the cell nucleus. Further compaction of chromatin into the cell nucleus is necessary, but is not yet well understood. The current understanding is that repeating nucleosomes with intervening "linker" DNA form a "10-nm-fiber", described as "beads on a string", and have a packing ratio of about five to ten. A chain of nucleosomes can be arranged in a "30 nm fiber", a compacted structure with a packing ratio of ~50 and whose formation is dependent on the presence of the H1 histone.
A crystal structure of a tetranucleosome has been presented and used to build up a proposed structure of the 30 nm fiber as a two-start helix. 
There is still a certain amount of contention regarding this model, as it is incompatible with recent electron microscopy data. Beyond this, the structure of chromatin is poorly understood, but it is classically suggested that the 30 nm fiber is arranged into loops along a central protein scaffold to form transcriptionally active euchromatin. Further compaction leads to transcriptionally inactive heterochromatin.
Nucleosome dynamics.
Although the nucleosome is a very stable protein-DNA complex, it is not static and has been shown to undergo a number of different structural re-arrangements including nucleosome sliding and DNA site exposure. Depending on the context, nucleosomes can inhibit or facilitate transcription factor binding. Nucleosome positions are controlled by three major contributions: First, the intrinsic binding affinity of the histone octamer depends on the DNA sequence. Second, the nucleosome can be displaced or recruited by the competitive or cooperative binding of other protein factors. Third, the nucleosome may be actively translocated by ATP-dependent remodeling complexes.
Nucleosome sliding.
Work performed in the Bradbury laboratory showed that nucleosomes reconstituted onto the 5S DNA positioning sequence were able to reposition themselves translationally onto adjacent sequences when incubated thermally. Later work showed that this repositioning did not require disruption of the histone octamer but was consistent with nucleosomes being able to “slide” along the DNA "in cis". In 2008, It was further revealed that CTCF binding sites act as nucleosome positioning anchors so that, when used to align various genomic signals, multiple flanking nucleosomes can be readily identified. Although nucleosomes are intrinsically mobile, eukaryotes have evolved a large family of ATP-dependent chromatin remodelling enzymes to alter chromatin structure, many of which do so via nucleosome sliding. In 2012, Beena Pillai's laboratory has demonstrated that nucleosome sliding is one of the possible mechanism for large scale tissue specific expression of genes. The work shows that the transcription start site for genes expressed in a particular tissue, are nucleosome depleted while, the same set of genes in other tissue where they are not expressed, are nucleosome bound.
DNA site exposure.
Work from the Widom laboratory has shown that nucleosomal DNA is in equilibrium between a wrapped and unwrapped state. Measurements of these rates using time-resolved FRET revealed that DNA within the nucleosome remains fully wrapped for only 250 ms before it is unwrapped for 10-50 ms and then rapidly rewrapped. This implies that DNA does not need to be actively dissociated from the nucleosome but that there is a significant fraction of time during which it is fully accessible. Indeed, this can be extended to the observation that introducing a DNA-binding sequence within the nucleosome increases the accessibility of adjacent regions of DNA when bound. This propensity for DNA within the nucleosome to “breathe” is predicted to have important functional consequences for all DNA-binding proteins that operate in a chromatin environment.
Modulating nucleosome structure.
Eukaryotic genomes are ubiquitously associated into chromatin; however, cells must spatially and temporally regulate specific loci independently of bulk chromatin. In order to achieve the high level of control required to co-ordinate nuclear processes such as DNA replication, repair, and transcription, cells have developed a variety of means to locally and specifically modulate chromatin structure and function. This can involve covalent modification of histones, the incorporation of histone variants, and non-covalent remodelling by ATP-dependent remodeling enzymes.
Histone post-translational modifications.
Since they were discovered in the mid-1960s, histone modifications have been predicted to affect transcription. The fact that most of the early post-translational modifications found were concentrated within the tail extensions that protrude from the nucleosome core lead to two main theories regarding the mechanism of histone modification. The first of the theories suggested that they may affect electrostatic interactions between the histone tails and DNA to “loosen” chromatin structure. Later it was proposed that combinations of these modifications may create binding epitopes with which to recruit other proteins. Recently, given that more modifications have been found in the structured regions of histones, it has been put forward that these modifications may affect histone-DNA and histone-histone interactions within the nucleosome core. Modifications (such as acetylation or phosphorylation) that lower the charge of the globular histone core are predicted to "loosen" core-DNA association; the strength of the effect depends on location of the modification within the core.
Some modifications have been shown to be correlated with gene silencing; others seem to be correlated with gene activation. Common modifications include acetylation, methylation, or ubiquitination of lysine; methylation of arginine; and phosphorylation of serine. The information stored in this way is considered epigenetic, since it is not encoded in the DNA but is still inherited to daughter cells. The maintenance of a repressed or activated status of a gene is often necessary for cellular differentiation.
Histone variants.
Although histones are remarkably conserved throughout evolution, several variant forms have been identified. It is interesting to note that this diversification of histone function is restricted to H2A and H3, with H2B and H4 being mostly invariant. H2A can be replaced by H2AZ (which leads to reduced nucleosome stability) or H2AX (which is associated with DNA repair and T cell differentiation), whereas the inactive X chromosomes in mammals are enriched in macroH2A. H3 can be replaced by H3.3 (which correlates with activate genes and regulatory elements) and in centromeres H3 is replaced by CENPA.
ATP-dependent nucleosome remodeling.
A number of distinct reactions are associated with the term ATP-dependent chromatin remodeling. Remodeling enzymes have been shown to slide nucleosomes along DNA, disrupt histone-DNA contacts to the extent of destabilising the H2A/H2B dimer and to generate negative superhelical torsion in DNA and chromatin. Recently, the Swr1 remodeling enzyme has been shown to introduce the variant histone H2A.Z into nucleosomes. At present, it is not clear if all of these represent distinct reactions or merely alternative outcomes of a common mechanism. What is shared between all, and indeed the hallmark of ATP-dependent chromatin remodeling, is that they all result in altered DNA accessibility. 
Studies looking at gene activation "in vivo" and, more astonishingly, remodelling "in vitro" have revealed that chromatin remodeling events and transcription-factor binding are cyclical and periodic in nature. While the consequences of this for the reaction mechanism of chromatin remodeling are not known, the dynamic nature of the system may allow it to respond faster to external stimuli. A recent study indicates that nucleosome positions change significantly during mouse embryonic stem cell development, and these changes are related to binding of developmental transcription factors.
Dynamic nucleosome remodelling across the Yeast genome.
Studies in 2007 have catalogued nucleosome positions in yeast and shown that nucleosomes are depleted in promoter regions and origins of replication.
About 80% of the yeast genome appears to be covered by nucleosomes and the pattern of nucleosome positioning clearly relates to DNA regions that regulate transcription, regions that are transcribed and regions that initiate DNA replication. Most recently, a new study examined ‘’dynamic changes’’ in nucleosome repositioning during a global transcriptional reprogramming event to elucidate the effects on nucleosome displacement during genome-wide transcriptional changes in yeast ("Saccharomyces cerevisiae"). The results suggested that nucleosomes that were localized to promoter regions are displaced in response to stress (like heat shock). In addition, the removal of nucleosomes usually corresponded to transcriptional activation and the replacement of nucleosomes usually corresponded to transcriptional repression, presumably because transcription factor binding sites became more or less accessible, respectively. In general, only one or two nucleosomes were repositioned at the promoter to effect these transcriptional changes. However, even in chromosomal regions that were not associated with transcriptional changes, nucleosome repositioning was observed, suggesting that the covering and uncovering of transcriptional DNA does not necessarily produce a transcriptional event.
Nucleosome assembly "in vitro".
Nucleosomes can be assembled "in vitro" by either using purified native or recombinant histones. One standard technique of loading the DNA around the histones involves the use of salt dialysis. A reaction consisting of the histone octamers and a naked DNA template can be incubated together at a salt concentration of 2 M. By steadily decreasing the salt concentration, the DNA will equilibrate to a position where it is wrapped around the histone octamers, forming nucleosomes. In appropriate conditions, this reconstitution process allows for the nucleosome positioning affinity of a given sequence to be mapped experimentally.
Gallery.
The crystal structure of the nucleosome core particle (PDB ID: 1EQZ ) - different views showing details of histone folding and organization. Histones H2A, H2B, H3, H4 and DNA are coloured.

</doc>
<doc id="21847" url="http://en.wikipedia.org/wiki?curid=21847" title="Nordic">
Nordic

Nordic commonly refers to:
Nordic may also refer to:

</doc>
<doc id="21848" url="http://en.wikipedia.org/wiki?curid=21848" title="Neurosurgery">
Neurosurgery

Neurosurgery (or neurological surgery) is the medical specialty concerned with the prevention, diagnosis, treatment, and rehabilitation of disorders which affect any portion of the nervous system including the brain, spinal cord, peripheral nerves, and extra-cranial cerebrovascular system.
Education and training.
In different countries, there are different requirements for an individual to legally practice neurosurgery, and there are varying methods through which they must be educated. In most countries neurosurgeon training is a minimum period of 7 years after graduating from medical school.
United States.
In the United States, a neurosurgeon must generally complete four years of college, four years of medical school, and seven years of residency (PGY-1-7). Most, but not all, residency programs have some component of basic science or clinical research. Neurosurgeons may pursue an additional training in a fellowship, after residency or in some cases, as a senior resident. These fellowships include pediatric neurosurgery, trauma/neurocritical care, functional and stereotactic surgery, surgical neuro-oncology, radiosurgery, neurovascular surgery, Skull-Base Surgery, peripheral nerve and spine surgery. In the U.S., neurosurgery is considered a highly competitive specialty composed of 0.6% of all practicing physicians.
United Kingdom.
In the United Kingdom, students must gain entry into medical school. MBBS qualification (Bachelor of Medicine, Bachelor of Surgery) takes 4–6 years depending on the student's route. The newly qualified physician must then complete foundation training lasting two years; this is a paid training program in a hospital or clinical setting covering a range of medical specialties including surgery. Junior doctors then apply to enter the neurosurgical pathway. Unlike most other surgical specialties, it currently has its own independent training pathway which takes around eight years (ST1-8); before being able to sit for consultant exams with sufficient amounts of experience and practice behind them. Neurosurgery remains consistently amongst the most competitive medical specialties to obtain entry into.
Main divisions of neurosurgery.
General neurosurgery involves most neurosurgical conditions including neuro-trauma and other neuro-emergencies such as intracranial hemorrhage. Most level 1 hospitals have this kind of practice.
Specialized branches have developed to cater to special and difficult conditions. These specialized branches co-exist with general neurosurgery in more sophisticated hospitals. To practice these higher specialization within neurosurgery, additional higher fellowship training of 1–2 years is expected from the neurosurgeon.
Some of these divisions of neurosurgery are:
Neuropathology.
The pathology confronted by neurosurgeons could be either congenital, acquired, traumatic, due to infection, or neoplastic or degenerative conditions. Conditions like congenital hydrocephalus, pediatric tumors and myelomeningocele are encountered in children. Trauma with head or spine injury and bleeds due to arteriovenous malformation are encountered in young adults. Degenerative spine disease, aneurysm bleeds and Parkinson's disease are encountered in much older patients. The science of "neuropathology" is a well developed branch of pathology.
Neuroanesthesia.
Neuroanesthesia is a highly developed science that is linked to neurosurgery. This branch of medicine plays a very important part in day-to-day neurosurgery.
Neurosurgery methods.
For a satisfactory neurosurgery outcome a reasonable pre-operative diagnosis is essential. Neuroradiology plays a key role not only in diagnosis but also in the operative phase of neurosurgery.
Neuroradiology methods are used in modern neurosurgery diagnosis and treatment. They include computer assisted imaging computed tomography (CT), magnetic resonance imaging (MRI), positron emission tomography (PET), magnetoencephalography (MEG), and the stereotactic radiosurgery. Some neurosurgery procedures involve the use of intra-operative MRI and functional MRI.
In "conventional open surgery" the neurosurgeon opens the skull, uses a large opening to access the brain. Technique of using smaller openings and using microscopes and endoscopes were developed later. With this smaller openings and high clarity microscopic visualization of neural tissue excellent results can be obtained. But, the open methods are still used in trauma or emergency situations[10] "Principles of Neurosurgery-Rengachari, Ellenbogen, "[11]" Neurotrauma and Critical Care of the Brain-Jallo, Loftus
"Microsurgery" is utilized in many aspects of neurological surgery. Microvascular techniques are used in EC-IC by-pass surgery and in restoration carotid endarterectomy. The clipping of an aneurysm is performed under microscopic vision. Minimally invasive spine surgery utilizes microscopes or endoscopes. Procedures such as microdiscectomy, laminectomy, and artificial disc replacement rely on microsurgery.
Using "Stereotaxy" neurosurgeons can approach a minute target in the brain through a minimal opening. This is used in functional neurosurgery where electrodes are implanted or gene therapy is instituted with high level of accuracy as in the case of Parkinson's disease or Alzheimer's disease. Then in the combination method of open and stereotactic surgery intraventricular hemorrhages could be evacuated successfully.
Minimally invasive "endoscopic surgery" is utilized by neurosurgeons. Techniques such as endoscopic endonasal surgery is used in pituitary tumors, craniopharyngiomas, chordomas, and the repair of cerebrospinal fluid leaks. Ventricular endoscopy is used in the treatment of intraventricular bleeds, hydrocephalus, colloid cysts and neurocysticercosis. Endonasal endoscopy at times is carried out with neurosurgeons and ENT surgeons as a team.
Repair of craniofacial disorders and disturbance of cerebrospinal fluid circulation is done by neurosurgeons, and at times teaming up with maxillofacial and plastic surgeons. Cranioplasty for craniosynostosis is performed by pediatric neurosurgeons with or without plastic surgeons.
Neurosurgeons are involved in "Stereotactic Radiosurgery" along with Radiation Oncologists in tumor and AVM treatment[13]"Intracranial Stereotactic Radiosurgery-Lunsford, Sheehan", [14]"Spine Radiosurgery-Gerszten, Ryu". Radiosurgical methods such as Gamma knife, Cyberknife and Novalis Shaped Beam Surgery are used.
"Endovascular Neurosurgery" utilize endovascular image guided procedures for the treatment of aneurysms, AVMs, carotid stenosis, strokes, and spinal malformations, and vasospasms. Techniques such as angioplasty, stenting, clot retrieval, embolization, and diagnostic angiography are endovascular procedures.
A common procedure performed in neurosurgery is the placement of Ventriculo-Peritoneal Shunt (VP Shunt). In pediatric practice this is for congenital hydrocephalus. The commonest indication in adults is Normal Pressure Hydrocephalus (NPH).
"Neurosurgery of the spine" covers cervical, thoracic and lumbar spine. Some indications for spine surgery are spinal cord compression from trauma, arthritis or spondylosis. In cervical cord compression patients may have gait difficulty, balance issues, numbness and tingling in hands or feet. Spondylosis is spinal disc degeneration and arthritis that compresses the spinal canal resulting in bone spurring and disc herniation. Power drills and special instruments are used to correct any compression to the spinal canal. Disk herniations of spinal vertebral disks are removed by Kerrison pitiutary rongeurs. This is called a discectomy. Laminectomy is removing "Lamina" portion of the vertebra of the spine to make room for the compressed nerve tissue. Minimally invasive, radiology assisted spine surgery include vertebroplasty and kyphoplasty where some kinds of spinal fractures are managed[12] "Essentials of Spinal Cord Injury-Fehlings, Vaccaro, Boakye et al".
Pain surgery handled by the neurosurgeons include implantation of deep brain stimulators, spinal cord stimulators and pain pumps [9] "Functional Neurosurgery-Starr, Barbaro, Larson.
Surgery of the peripheral nervous system include carpal tunnel decompression and peripheral nerve transposition.
Conditions.
Other conditions treated by neurosurgeons include:

</doc>
<doc id="21849" url="http://en.wikipedia.org/wiki?curid=21849" title="Nintendo 64">
Nintendo 64

The Nintendo 64 (Japanese: ニンテンドー64, Hepburn: Nintendō Rokujūyon), stylized as NINTENDO64 and often referred to as N64, is Nintendo's third home video game console for the international market. Named for its 64-bit central processing unit, it was released in June 1996 in Japan, September 1996 in North America, March 1997 in Europe and Australia, September 1997 in France and December 1997 in Brazil. It is the industry's latest major home console to use the cartridge as its primary storage format, although current handheld systems (such as the PlayStation Vita and Nintendo 3DS) also use cartridges. While the N64 was succeeded by Nintendo's MiniDVD-based GameCube in November 2001, N64 consoles remained available until the system was retired in late 2003.
Code named Ultra 64, the console's design was mostly finalized by mid-1995, though Nintendo 64's launch was delayed until 1996. As part of the fifth generation of gaming, the N64 competed primarily with the PlayStation and the Sega Saturn. The Nintendo 64 was launched with three games: "Super Mario 64" and "Pilotwings 64", released worldwide; and "Saikyō Habu Shōgi", released only in Japan. The Nintendo 64's suggested retail price at launch was US$ and it was later marketed with the slogan "Get N, or get Out!". The console was ultimately released in a range of different colors and designs, and an assortment of limited-edition controllers were sold or used as contest prizes during the N64's lifespan. The N64 sold 32.93 million units worldwide, and in 2009, it was named the 9th greatest video game console by IGN. "Time Magazine" named it their 1996 Machine of the Year.
One of its technical drawbacks is a limited texture cache, which can hold textures of limited dimensions and reduced color depth, which must be stretched to cover larger in-game surfaces. Its vintage ROM cartridges are constrained by small capacity and high production expenses, compared to the compact disc format used by its chief competitors. Some third-party publishers that supported Nintendo's previous consoles reduced their output or stopped publishing for the console; the N64's most successful games came from first-party or second-party studios.
History.
Development.
<br>"At the heart of the [Project Reality] system will be a version of the MIPS(r) Multimedia Engine, a chip-set consisting of a 64-bit MIPS RISC microprocessor, a graphics co-processor chip and Application Specific Integrated Circuits (ASICs)." "The product, which will be developed specifically for Nintendo, will be unveiled in arcades in 1994, and will be available for home use by late 1995. The target U.S. price for the home system is below $250." "For the first time, leading-edge MIPS RISC microprocessor technology will be used in the video entertainment industry [and already] powers computers ranging from PCs to supercomputers."
—SGI press release, August 23, 1993
At the beginning of the 1990s, Nintendo led the video game industry with its Nintendo Entertainment System (NES). Although a follow-up console, the Super Nintendo Entertainment System (SNES), was successful, sales took a hit from the Japanese recession. Competition from long-time rival Sega, as well as relative newcomer Sony, emphasized Nintendo's need to develop a successor for the SNES, or risk losing market dominance to its rivals. Further complicating matters, Nintendo also faced a backlash from third-party developers unhappy with Nintendo's onerous licensing policies.
Silicon Graphics, Inc. (SGI), a long-time leader in graphics visualization and supercomputing, was interested in expanding its business by adapting its technology into the higher volume realm of consumer products, starting with the video game market. Based upon its MIPS R4000 family of supercomputing and workstation CPUs, SGI developed a CPU requiring a fraction of the resources: consuming only 0.5 watts of power instead of 1.5 to 2 watts, with an estimated target price of US$ instead of US$–200. The company created a design proposal for a video game system, seeking an already well established partner in that market. James H. Clark, founder of SGI, initially offered the proposal to Tom Kalinske, then CEO of Sega of America; the next candidate was Nintendo.
The historical details of these preliminary negotiations were controversial between the two competing suitors. Tom Kalinske said that he and Joe Miller of Sega of America were "quite impressed" with SGI's prototype, inviting their hardware team to travel from Japan to meet with SGI. The engineers from Sega of Japan claimed that their evaluation of the early prototype had uncovered several unresolved hardware issues and deficiencies. Those were subsequently resolved, but Sega had already decided against SGI's design. Nintendo resisted that summary conclusion, arguing that the reason for SGI's ultimate choice of partner is due to Nintendo having been a more appealing business partner than Sega. While Sega demanded exclusive rights to the chip, Nintendo was willing to license the technology on a non-exclusive basis. Michael Slater, publisher of "Microprocessor Report" said, "The mere fact of a business relationship there is significant because of Nintendo's phenomenal ability to drive volume. If it works at all, it could bring MIPS to levels of volume they never dreamed of."
James Clark met with Nintendo CEO Hiroshi Yamauchi in early 1993, thus initiating Project Reality. On August 23, 1993, the two companies announced a global joint partnership and licensing agreement surrounding Project Reality, projecting that the yet unnamed eventual product would be "developed specifically for Nintendo, will be unveiled in arcades in 1994, and will be available for home use by late 1995 ... below $250." This announcement coincided with Nintendo's August 1993 Shoshinkai trade show.
As with most of the computing industry, Nintendo had limited experience with 3D graphics, and worked with several outside companies to develop the technology. Some chip technology was provided by NEC, Toshiba, and Sharp. Silicon Graphics (SGI) and its subsidiary MIPS Technologies were responsible for the R4300i microprocessor and the 3D graphics hardware used in the N64. SGI had recently acquired MIPS Computer Systems, and the two worked together toward a low-cost realtime 3D graphics hardware system.
The initial Ultra 64 software development platform was developed by SGI in the form of their Onyx supercomputer featuring Project Reality's namesake RealityEngine2 graphics boards, with early Ultra 64 application and emulation APIs. Upon this early platform, Nintendo's select game developer partners could fully prototype their games according to SGI's estimated Ultra 64 performance target, prior to the finalization of the console hardware specifications. That software-based prototype platform was later supplanted by a workstation-hosted simulation board, representing the finalized console hardware. SGI's performance estimates based upon the supercomputing platform were ultimately reported to be fairly accurate to the consumer console product.
The console's design was revealed to the public for the first time in late Q2 1994. Pictures of the console showed the Nintendo Ultra 64 logo, a ROM cartridge, but no controller. This prototype console's form factor would be retained by the product eventually launched as Nintendo 64. The news that the console would be cartridge-based prompted analysis by the gaming media. Nintendo's vice president of marketing Peter Main stated that "The choice we made is not cartridge versus CD, it's silicon over optical. When it comes to speed, no other format approaches the silicon-based cartridge." The system was frequently marketed as the world's first 64-bit gaming system. Atari had claimed to have made the first 64-bit game console with their Atari Jaguar, but the Jaguar only uses a 64-bit architecture in conjunction with two 32-bit RISC processors and a 16/32-bit Motorola 68000.
 
Later in Q2 1994, Nintendo signed a licensing agreement with Midway's parent company which enabled Midway to develop and market arcade games using the Project Reality hardware and formed a joint venture company called Williams/Nintendo to market Nintendo-exclusive home conversions of these games. The result is two arcade games, "Killer Instinct" and "Cruis'n USA", which boasted their upcoming release on the arcade branch of the Ultra 64 platform. Compared to the console branch of Ultra 64, the arcade branch uses a different MIPS CPU, has no Reality Coprocessor, and uses a hard drive instead of a cartridge. "Killer Instinct" features pre-rendered character artwork, and CG movie backgrounds that are streamed off the hard drive and animated as the characters move horizontally.
The completed Nintendo 64 was fully unveiled in a playable form to the public on November 24, 1995, at the 7th Annual Shoshinkai Software Exhibition in Japan. Nintendo's next-generation console was introduced as the "Nintendo 64" (a name given by Shigesato Itoi, who had named the Game Boy), contrary to speculation that it would be called "Ultra 64". Photos of the event were disseminated on the web by "Game Zero" magazine two days later. Official coverage by Nintendo followed later via the "Nintendo Power" website and print magazine.
In the lead up to the console's release, Nintendo had adopted a new global branding strategy, assigning the console the same name for all markets: Nintendo 64. Previously the plan had been to release the console as the Ultra Famicom in Japan and as the Ultra 64 in other markets.
The console was originally slated for release by Christmas of 1995. In May 1995, Nintendo pushed back the release to April 1996. The prospect of a release the following year at a lower price than the competition lowered sales of competing Sega and Sony consoles during the important Christmas shopping season.:24
In its explanation of the delay, Nintendo claimed it needed more time for Nintendo 64 software to mature, and for third-party developers to produce games. Adrian Sfarti, a former engineer for SGI, attributed the delay to hardware problems; he claimed that the chips underperformed in testing and were being redesigned. In 1996, the Nintendo 64's software development kit was redesigned as the Partner-N64 system, by Kyoto Microcomputer, Co. Ltd. of Japan.
Release.
"Popular Electronics" called the launch a "much hyped, long-anticipated moment."
The console was first released in Japan on June 23, 1996. The North American version of the Nintendo 64 officially launched on September 29, 1996. It was launched with just two games in the United States, "Pilotwings 64" and "Super Mario 64". In 1994, prior to the launch, Nintendo of America chairman Howard Lincoln emphasized the quality of first-party games, saying "... we're convinced that a few great games at launch are more important than great games mixed in with a lot of dogs.":77 The PAL version of the console was released in Europe on March 1, 1997.
Originally intended to be US$, the console was ultimately priced at US$ to make it competitive with Sony and Sega offerings. Nintendo priced the console as an impulse purchase, a strategy from the toy industry. The price of the console in the United States was further reduced in August 1998.
Sales.
The Nintendo 64 was in heavy demand upon its release. David Cole, industry analyst, said "You have people fighting to get it from stores." "Time Magazine" called the purchasing interest "that rare and glorious middle-class Cabbage Patch-doll frenzy." The magazine said celebrities Matthew Perry, Steven Spielberg's office, and some Chicago Bulls players called Nintendo to ask for special treatment to get their hands on the console.
The console sold 350,000 of 500,000 available units during its first three days on sale. Longer term, the console sold 500,000 units in North America during its first four months. George Harrison, vice president of marketing at Nintendo, expected sales of 5 million consoles by Christmas 1997.
The N64 sold 3.6 million in its first full year in the United States.
As of December 31, 2009, the N64 had sold 5.54 million units in Japan, 20.63 million in the Americas, and 6.75 million in other regions, for a total of 32.93 million units. Benimaru Itō, a developer for "EarthBound 64" and friend of Shigeru Miyamoto, speculated in 1997 that the N64's lower popularity in Japan was due to the lack of role-playing video games.
Promotion.
To boost sales during the slow post-Christmas season, Nintendo and General Mills worked together on a promotional campaign that appeared in early 1999. A television advertising campaign cost $5 million. The advertisement by Saatchi and Saatchi, New York began on January 25 and encouraged children to buy Fruit by the Foot snacks for tips to help them with their Nintendo 64 games. Ninety different tips were available, with three variations of thirty tips each.
Nintendo advertised its Funtastic Series of peripherals with a $10 million print and television campaign from February 28 to April 30, 2000. Leo Burnett, Chicago, was in charge.
Reception.
The Nintendo 64 received generally positive reviews from critics. Reviewers generally praised the console's advanced 3D graphics and gameplay, while criticizing the lack of games.
In February 1996, "Next Generation" magazine called the Ultra 64 the "best kept secret in videogames" and the "world's most powerful game machine", and calling its November 24, 1995 unveiling at Shoshinkai "the most anticipated videogaming event of the 1990s, possibly of all time." Previewing the Nintendo 64 shortly prior to its launch, "Time Magazine" praised the realistic movement and gameplay provided by the combination of fast graphics processing, pressure-sensitive controller, and the "Super Mario 64" game. The review praised the "fastest, smoothest game action yet attainable via joystick at the service of equally virtuoso motion", where "[f]or once, the movement on the screen feels real".:61
At launch, the "Los Angeles Times" called the system "quite simply, the fastest, most graceful game machine on the market". Its form factor was described as small, light, and "built for heavy play by kids" unlike the "relatively fragile Sega Saturn". Showing concern for a major console product launch during a sharp, several-year long, decline in the game console market, the review said that the long-delayed Nintendo 64 was "worth the wait" in the company's pursuit of quality. Nintendo's "penchant for perfection" in game quality control was praised, though with concerns about having only two launch titles at retail and twelve expected by Christmas. Praising Nintendo's controversial choice of the cartridge medium with its "nonexistent" load times and "continuous, fast-paced action CD-ROMs simply cannot deliver", the review concluded that "the cartridge-based Nintendo 64 delivers blistering speed and tack-sharp graphics that are unheard of on personal computers and make competing 32-bit, disc-based consoles from Sega and Sony seem downright sluggish".
"Time Magazine" named it their 1996 Machine of the Year, saying the machine had "done to video-gaming what the 707 did to air travel." The magazine said the console achieved "the most realistic and compelling three-dimensional experience ever presented by a computer." "Time" credited the Nintendo 64 with revitalizing the video game market, "rescuing this industry from the dustbin of entertainment history." The magazine suggested that the Nintendo 64 would play a major role in introducing children to digital technology in the final years of the 20th century. The article concluded by saying the console had already provided "the first glimpse of a future where immensely powerful computing will be as common and easy to use as our televisions.":73
"Popular Electronics" complimented the system's hardware, calling its specifications "quite impressive." It found the controller "comfortable to hold, and the controls to be accurate and responsive."
Legacy.
The Nintendo 64 remains one of the most recognized video game systems in the world. On G4techTV's (now G4's) "Filter", the Nintendo 64 was voted up to No. 1 by registered users.
Games.
A total of 387 games were released for the console, though few were exclusively sold in Japan. For comparison, the rival PlayStation received around 1,100 games, while the earlier NES and SNES had 768 and 725 US games, respectively. However, the Nintendo 64 game library included a high number of critically acclaimed and widely sold games. "Super Mario 64" was the console's best selling game (selling over 11 million copies), receiving much praise from critics and helping to pioneer three-dimensional control schemes. "GoldenEye 007" was important in the evolution of the first-person shooter, and has been named one of the greatest in the genre. "" set the standard for future 3D action-adventure games and is considered by some to be the greatest game ever made.
Graphics.
The most graphically demanding N64 games that arrived on larger 32MB and 64MB cartridges are the most advanced and detailed of the 32-bit/64-bit generation. In order to maximize use of the Nintendo 64 hardware developers had to create their own alternate bespoke custom microcode. N64 Games running on custom microcode benefited from much higher polygon counts in tandem with more advanced lighting, animation, physics and AI routines than its 32-bit competition. Conker's Bad Fur Day is arguably the pinnacle of its generation combining multicolored real-time lighting that illuminates each area to real-time shadowing and detailed texturing replete with a full in game facial animation system. The Nintendo 64's graphics chip is capable of executing many more advanced and complex rendering techniques than its competitors. It was the first home console to feature trilinear filtering, which allowed textures to look very smooth. This contrasted with the Saturn and PlayStation, which used nearest-neighbor interpolation and produced more pixelated textures. Overall however the results of the Nintendo cartridge system were mixed and this was tied primarily to its storage medium. 
The smaller storage size of ROM cartridges limited the number of available textures. As a result, many games which utilized much smaller 8MB/12MB cartridges were forced to 'stretch' textures over larger surfaces. Compounded by a limit of 4,096-bytes allocated for texture storage, the end-result was often a distorted, out-of-proportion appearance. Many titles that featured larger 32MB and 64MB cartridges avoided this issue entirely, notable games include "Resident Evil 2", "Sin and Punishment: Successor of the Earth", and "Conker's Bad Fur Day" as they featured more ROM space, allowing for more detailed graphics by utilizing multiple, multilayered textures across all surfaces.
Game Paks.
Nintendo 64 games are ROM cartridge based. Cartridge size varies from 4 MB to 64 MB. ROM cartridges are expensive and time-consuming to manufacture. Many cartridges include the ability to save games internally.
Nintendo cited several advantages for making the N64 cartridge-based. Primarily cited was the ROM cartridges' very fast load times in comparison to disc-based games. While loading screens appear in many PlayStation games, they are rare on the N64. Although vulnerable to long-term environmental damage the cartridges are far more resistant to physical damage than compact discs.
The big strength was the N64 cartridge. We use the cartridge almost like normal RAM and are streaming all level data, textures, animations, music, sound and even program code while the game is running. With the final size of the levels and the amount of textures, the RAM of the N64 never would have been even remotely enough to fit any individual level. So the cartridge technology really saved the day.
Factor 5, "Bringing Indy to N64" at IGN
On the downside, cartridges took longer to manufacture than CDs, with each production run (from order to delivery) taking two weeks or more. This meant that publishers of N64 games had to attempt to predict demand for a game ahead of its release. They risked being left with a surplus of expensive cartridges for a failed game or a weeks-long shortage of product if they underestimated a game's popularity. The cost of producing an N64 cartridge was also far higher than for a CD. Publishers passed these expenses onto the consumer. N64 games cost an average of $10 more when compared to games produced for rival consoles.
As fifth generation games became more complex in content, sound and graphics, games began to exceed the limits of cartridge storage capacity. N64 cartridges had a maximum of 64 MB of data, whereas CDs held over 650 MB. Software ported from other platforms was often heavily compressed or redesigned with the storage limits of a cartridge in mind. Due to the cartridge's space limitations, full motion video was not usually feasible for use in cutscenes. When it was present, it was compressed to fit on the cartridge, extremely pixelated, and usually of very brief length.
The era's competing systems from Sony and Sega (the PlayStation and Saturn, respectively) used CD-ROM discs to store their games. As a result, game developers who had traditionally supported Nintendo game consoles were now developing games for the competition. Some third-party developers, such as Square and Enix, whose "Final Fantasy VII" and "Dragon Warrior VII" were initially pre-planned for the N64, switched to the PlayStation. Some who remained released fewer games to the Nintendo 64; Konami released fifty PlayStation games, but only thirteen for the N64. New Nintendo 64 game releases were infrequent while new games were coming out rapidly for the PlayStation.
Despite the difficulties with third parties, the N64 still managed to support popular games such as "GoldenEye 007", giving it a long shelf-life. Additionally, Nintendo's strong first-party franchises such as "Mario" had strong name brand appeal. Second-parties of Nintendo, such as Rare, helped.
Nintendo's controversial selection of the cartridge medium for the Nintendo 64 has been cited as a key factor in Nintendo losing its dominant position in the gaming market. Some of the cartridge's advantages are difficult for developers to manifest prominently, requiring innovative solutions which only came late in the console's life cycle.
Emulation.
Several Nintendo 64 games have been released for the Wii's and Wii U's Virtual Console service and are playable with either the Classic Controller, Nintendo GameCube controller, or Wii U GamePad. There are some differences between these versions and the original cartridge versions. For example, the games run in a higher resolution and at a more consistent framerate than their N64 counterparts. However, some features, such as Rumble Pak functionality, are not available in the Wii versions. Some features are also altered for the Virtual Console releases. For example, the VC version of "Pokémon Snap" allows players to send photos through the Wii's message service, while "Wave Race 64"'s in-game content was altered due to the expiration of the Kawasaki license. Several games from Rare have seen release on Microsoft's Xbox Live Arcade service, including "Banjo-Kazooie", "Banjo-Tooie" and "Perfect Dark", the reason being that Rareware was purchased by Microsoft in 2002. However one exception was Donkey Kong 64, which was released in April 2015 on the Wii U Virtual Console since Nintendo owns the rights to that game.
Prior to the Virtual Console's conception, unofficial emulation systems were developed in order to execute Nintendo 64 titles on multiple platforms, such as PCs, that would otherwise be impossible without the required N64 hardware. 
Technical specifications.
Hardware.
The Nintendo 64's central processing unit (CPU) is the NEC VR4300. This processor was the most powerful console CPU of its generation. "Popular Electronics" said it had power similar to the Pentium processors found in desktop computers. Except for its narrower 32-bit system bus, the VR4300 retained the computational abilities of the more powerful 64-bit MIPS R4300i, though software rarely took advantage of 64-bit data precision operations. N64 games generally used faster (and more compact) 32-bit data-operations, as these were sufficient to generate 3D-scene data for the console's RSP (Reality Signal Processor) unit. In addition, 32-bit code executed faster and required less storage space (which was at a premium on the N64's cartridges).
In terms of its random-access memory, or RAM, the Nintendo 64 was one of the first modern consoles to implement a unified memory subsystem, instead of having separate banks of memory for CPU, audio, and video, for example. The memory itself consists of 4 megabytes of RDRAM, made by Rambus. The RAM is expandable to 8 MB with the Expansion Pak. Rambus was quite new at the time and offered Nintendo a way to provide a large amount of bandwidth for a relatively low cost.
The system allows for video output in two formats: composite video and S-Video. The composite and S-Video cables are the same as those used with the earlier SNES and later GameCube systems.
The Nintendo 64 supports 16.8 million colors. The system can display resolutions from 320 × 240 up to 640 × 480 pixels. Most games that made use of the systems higher resolution 640x480 mode required use of the Expansion Pak RAM upgrade, there were a number however that didn't such as Acclaims NFL Quarterback Club series and EA Sports 2nd generation Madden, FIFA, Supercross and NHL games that arrived on the system. The majority of games used the system's low resolution 320 × 240 mode. A number of games also support a video display ratio of up to using either Anamorphic widescreen or Letterboxing.
Color variants.
The Nintendo 64 comes in several colors. The standard Nintendo 64 is dark gray, nearly black, and the controller is light gray (later releases in America included a bonus second controller in Atomic Purple). Various color variations and special editions were released.
The majority of Nintendo 64 game cartridges were gray in color, but some games were released on a colored cartridge. Fourteen games had black cartridges, while other colors (such as green, blue, red, yellow and gold) were each used for six or fewer games. Several games, such as "", were released both in standard gray and in colored, limited edition versions.
Accessories.
A number of accessories, from the Rumble Pak to the Transfer Pak, were available for the Nintendo 64.
The controller was shaped like an "M", employing a joystick in the center. "Popular Electronics" called its shape "evocative of some alien space ship." While noting that the three handles could be confusing, the magazine said "the separate grips allow different hand positions for various game types."
64DD.
Nintendo released a peripheral platform called 64DD, where "DD" stands for "Disk Drive." Connecting to the expansion slot at the bottom of the system, the 64DD turns the Nintendo 64 console into an Internet appliance and an expanded gaming platform. This large peripheral allows players to play Nintendo 64 disk-based games, capture images from an external video source, and connect to the now-defunct Japanese Randnet online service. Not long after its limited mail-order release, the add-on was discontinued. Only nine games were released, including the four "Mario Artist" games ("Paint Studio", "Talent Studio", "Communication Kit", and "Polygon Studio"). Many more were released in cartridge format or on other game consoles. The 64DD and the accompanying Randnet online service were released only in Japan.
To illustrate the fundamental significance of the 64DD to all game development at Nintendo, lead designer Shigesato Itoi said, "I came up with a lot of ideas because of the 64DD. All things start with the 64DD. There are so many ideas I wouldn’t have been allowed to come up with if we didn’t have the 64DD." Shigeru Miyamoto concluded, "Almost every new project for the N64 is based on the 64DD. ... we’ll make the game on a cartridge first, then add the technology we’ve cultivated to finish it up as a full-out 64DD game."
Programming characteristics.
The programming characteristics of the Nintendo 64 present unique challenges, with distinct potential advantages. "The Economist" described effective programming for the Nintendo 64 as being "horrendously complex." As with many other game consoles and other types of embedded systems, the Nintendo 64's architectural optimizations are uniquely acute, due to a combination of oversight on the part of the hardware designers, limitations on 3D technology of the time, and manufacturing capabilities.
As the Nintendo 64 reached the end of its lifecycle, hardware development chief Genyo Takeda repeatedly referred to the programming challenges using the word "hansei" (Japanese: 反省 "reflective regret"). Looking back, Takeda said "When we made Nintendo 64, we thought it was logical that if you want to make advanced games, it becomes technically more difficult. We were wrong. We now understand it's the cruising speed that matters, not the momentary flash of peak power."

</doc>
<doc id="21850" url="http://en.wikipedia.org/wiki?curid=21850" title="GNU nano">
GNU nano

nano is a text editor for Unix-like computing systems or operating environments using a command line interface. It emulates the Pico text editor, part of the Pine email client, and also provides additional functionality.
In contrast to Pico, nano is licensed under the GNU General Public License (GPL). Released as free software by Chris Allegretta in 1999, today nano is part of the GNU Project.
History.
nano was first created in 1999 with the name "TIP" ("This isn't Pico"), by Chris Allegretta. His motivation was to create a free software replacement for Pico, which was not distributed under a free software license. The name was changed to nano on January 10, 2000 to avoid a naming conflict with the existing Unix utility "tip". The name comes from the system of SI prefixes, in which nano is 1000 times larger than pico. In February 2001, nano became a part of the GNU Project.
nano implements some features that Pico lacks, including colored text, regular expression search and replace, smooth scrolling, multiple buffers, rebindable key support, and undoing and redoing of edit changes.
On August 11, 2003, Chris Allegretta officially handed the source code maintenance for nano to David Lawrence Ramsey. On December 20, 2007, Ramsey stepped down as nano's maintainer.
Control keys.
nano, like Pico, is keyboard-oriented, controlled with control keys. For example, Ctrl+O saves the current file; Ctrl+W goes to the search menu. Nano puts a two-line "shortcut bar" at the bottom of the screen, listing many of the commands available in the current context. For a complete list, Ctrl+G gets the help screen.
Unlike Pico, nano uses meta keys to toggle its behavior. For example, Meta+S toggles smooth scrolling mode on and off. Almost all features that can be selected from the command line can be dynamically toggled. On keyboards without the meta key it is often mapped to the escape key, Esc, such that in order to simulate, say, Meta+S one has to press the Esc key, then release it, and then press the S key.
Nano can also use pointer devices, such as a mouse, to activate functions that are on the shortcut bar, as well as position the cursor.

</doc>
<doc id="21851" url="http://en.wikipedia.org/wiki?curid=21851" title="Nieuwe Waterweg">
Nieuwe Waterweg

The Nieuwe Waterweg ("New Waterway") is a ship canal in the Netherlands from het Scheur (a branch of the Rhine-Meuse-Scheldt delta) west of the town of Maassluis to the North Sea at Hook of Holland: the Maasmond, where the Nieuwe Waterweg connects to the Maasgeul. It is the artificial mouth of the river Rhine.
The Nieuwe Waterweg, which opened in 1872 and has a length of approximately 20.5 km, was constructed to keep the city and port of Rotterdam accessible to seafaring vessels as the natural Meuse-Rhine branches silted up. The Waterway is a busy shipping route since it is the primary access to one of the busiest ports in the world, the Europoort of Rotterdam. At the entrance to the sea, a flood protection system called Maeslantkering has been installed (completed in 1997). There are no bridges or tunnels across the Nieuwe Waterweg.
History.
By the middle of the 19th century, Rotterdam was already one of the largest port cities in the world, mainly because of transshipment of goods from Germany to Great Britain. The increase in shipping traffic created a capacity problem: there were too many branches in the river delta, making the port difficult to reach.
In 1863, a law was passed that allowed for the provision of a new canal for large ocean-going ships from Rotterdam to the North Sea. Hydraulic engineer Pieter Caland was commissioned to design a canal cutting through the "Hook of Holland” and to extend the Mouth of Rhine to the sea. The designs for this were already done back in 1731 by Nicolaas Samuelsz Cruquius but the implementation could no longer be postponed to prevent the decline of the harbour of Rotterdam.
Construction began on October 31, 1863. The first phase consisted of the expropriation of farm lands from Rozenburg to Hoek van Holland.
During the second phase two dikes were built parallel to each other, which took 2 years. Caland proposed to extend the dikes 2 km into the sea to disrupt the coastal sea currents and decrease silt deposits in the shipping lane.
Upon the completion of the dikes, the third phase began by the digging of the actual waterway. This began on October 31, 1866, and was completed three years later. The large amounts of removed soil were in turn used to reinforce other dams and dikes.
The last phase consisted of the removal of the dam separating the new waterway from the sea and river. In 1872, the Nieuwe Waterweg was completed and Rotterdam was easily accessible.
Because of the currents and erosion, the shipping lane has been widened somewhat. Yet because of the draft of today's supertankers, it needs to be dredged constantly.
In 1997, the last part of the Delta Works, the Maeslantkering, was put in operation near the mouth of the Nieuwe Waterweg. This storm surge barrier protects Rotterdam against north westerly Beaufort Force 10 to 12 storms.
Current situation.
The Nieuwe Waterweg gives the Port of Rotterdam its deep-water access to the North Sea. From Hook of Holland it stretches for approximately 20.5 km where the waterway continues as the Nieuwe Maas. The very first Nieuwe Waterweg—a breach through the dunes at Hook of Holland—was only 4.3 km long, but in around 1877 the channel was made much larger and wider and the current Nieuwe Waterweg was created. Currently the width of the channel is between 480 and and it is dredged to a depth of 14.5 – below Amsterdam Ordnance Datum.
It is this channel, together with the dredged channels in the North Sea, Maasgeul and Eurogeul, that allows ships like the MS "Berge Stahl" and MV "Vale Rio de Janeiro" (both with a draught of 23 meters) to enter Europoort.
The Dutch government agency Rijkswaterstaat is responsible for maintaining the channel.
Maasmond.
The point where the Nieuwe Waterweg enters into the North Sea, between Hook of Holland on the north bank and the Maasvlakte to the south, is called the Maasmond. It is marked with two navigation light-towers called the Paddestoelen ("mushrooms"). The Nieuwe Waterweg connects, in the North Sea, to the Maasgeul. This dredged channel in the North Sea is being widened to 840 m to facilitate the largest container vessels for the new Maasvlakte 2 that will be opened in 2012.

</doc>
<doc id="21853" url="http://en.wikipedia.org/wiki?curid=21853" title="Neijia">
Neijia

Nèijiā () is a term in Chinese martial arts, grouping those styles that practice nèijìng (), usually translated as internal martial arts, occupied with spiritual, mental or qi-related aspects, as opposed to an "external" () approach focused on physiological aspects. The distinction dates to the 17th century, but its modern application is due to publications by Sun Lutang, dating to the period of 1915 to 1928. Nèijìng is developed by using "nèigōng" (內功), or "internal exercises," as opposed to "wàigōng" (外功), "external exercises."
Wǔdāngquán is a more specific grouping of internal martial arts named for their association with the Taoist monasteries of Wudangshan range, Hubei Province in Chinese popular legend. These styles were enumerated by Sun Lutang as Tàijíquán, Xíngyìquán and Bāguàzhǎng, but most also include Bājíquán and the legendary Wudang Sword.
Some other Chinese arts, not in the Wudangquan group, such as Qigong, Liuhebafa, Bak Mei Pai, Zi Ran Men (Nature Boxing), Bok Foo Pai and Yiquan are frequently classified (or classify themselves) as "internal".
History.
Qing China.
The term "nèijiā" and the distinction between internal and external martial arts first appears in Huang Zongxi's 1669 "Epitaph for Wang Zhengnan". Stanley Henning proposes that the "Epitaph"'s identification of the internal martial arts with the Taoism indigenous to China and of the external martial arts with the foreign Buddhism of Shaolin—and the Manchu Qing Dynasty to which Huang Zongxi was opposed—was an act of political defiance rather than one of technical classification.
In 1676 Huang Zongxi's son, Huang Baijia, who learned martial arts from Wang Zhengnan, compiled the earliest extant manual of internal martial arts, the "Nèijiā quánfǎ".
Republic of China.
Beginning in 1914, Sun Lutang together with Yang Shao-hou, Yang Chengfu and Wu Chien-ch'uan taught t'ai chi to the public at the Beijing Physical Education Research Institute. Sun taught there until 1928, a seminal period in the development of modern Yang, Wu and Sun-style t'ai chi ch'uan. Sun Lutang from 1915 also published martial arts texts.
In 1928, Kuomintang generals Li Jing Lin, Zhang Zi Jiang, and Fung Zu Ziang organized a national martial arts tournament in China; they did so to screen the best martial artists in order to begin building the Central Martial Arts Academy (Zhongyang Guoshuguan). The generals separated the participants of the tournament into Shaolin and Wudang. Wudang participants were recognized as having "internal" skills. These participants were generally practitioners of t'ai chi ch'uan, Xíngyìquán and Bāguàzhǎng. All other participants competed under the classification of Shaolin. One of the winners in the "internal" category was the Bāguàzhǎng master Fu Chen Sung.
Sun Lutang.
Sun Lutang identified the following as the criteria that distinguish an internal martial art:
Sun Lutang's eponymous style of t'ai chi ch'uan fuses principles from all three arts he named as neijia. Similarities applying classical principles between taiji, xingyi, and baquazhang include: Loosening (song) the soft tissue, opening shoulder and hip gates or gua, cultivating qi or intrinsic energy, issuing various jin or compounded energies. Taijiquan is characterized by an ever present peng jin or expanding energy. Xingyiquan is characterized by its solely forward moving pressing ji jin energy. Baguazhang is characterized by its “dragon body” circular movements. Some Chinese martial arts other than the ones Sun named also teach what are termed internal practices, despite being generally classified as external (e.g. Wing Chun that also is internal). Some non-Chinese martial arts also claim to be internal, for example Aikido and Kito Ryu. Many martial artists, especially outside of China, disregard the distinction entirely. Some neijia schools refer to their arts as "soft style" martial arts.
Training.
Internal styles focus on awareness of the spirit, mind, qi ("energy") and the use of relaxed ("sōng" 鬆) leverage rather than muscular tension. Pushing hands is a training method commonly used in neijia arts to develop sensitivity and softness.
Much time may nevertheless be spent on basic physical training, such as stance training ("zhan zhuang"), stretching and strengthening of muscles, as well as on empty hand and weapon forms which can be quite demanding.
Some forms in internal styles are performed slowly, although some include sudden outbursts of explosive movements (fa jin), such as those the Chen style of Taijiquan is famous for teaching earlier than some other styles (e.g. Yang and Wu). The reason for the generally slow pace is to improve coordination and balance by increasing the work load, and to require the student to pay minute attention to their whole body and its weight as they perform a technique. At an advanced level, and in actual fighting, internal styles are performed quickly, but the goal is to learn to involve the entire body in every motion, to stay relaxed, with deep, controlled breathing, and to coordinate the motions of the body and the breathing accurately according to the dictates of the forms while maintaining perfect balance.
Characteristics.
The reason for the label "internal," according to most schools, is that there is a focus on the internal aspects earlier in the training, once these internal relationships are apprehended (the theory goes) they are then applied to the external applications of the styles in question.
External styles (外家, pinyin: wàijiā; literally "external family") are characterized by fast and explosive movements and a focus on physical strength and agility. External styles include both the traditional styles focusing on application and fighting, as well as the modern styles adapted for competition and exercise. Examples of external styles are Shaolinquan, with its direct explosive attacks and many Wushu forms that have spectacular aerial techniques. External styles begin with a training focus on muscular power, speed and application, and generally integrate their qigong aspects in advanced training, after their desired "hard" physical level has been reached.
Some say that there is no differentiation between the so-called internal and external systems of the Chinese martial arts, while other well known teachers have expressed differing opinions. For example, the Taijiquan teacher Wu Jianquan:
Those who practice Shaolinquan leap about with strength and force; people not proficient at this kind of training soon lose their breath and are exhausted. Taijiquan is unlike this. Strive for quiescence of body, mind and intention.
Current practice.
Many internal schools teach forms that are practised for health benefits only. Thus, T'ai chi ch'uan in spite of its roots in martial arts has become similar in scope to Qigong, the purely meditative practice based on notions of circulation of qi. With purely a health emphasis, T'ai chi classes have become popular in hospitals, clinics, community and senior centers in the last twenty years or so, as baby boomers age and the art's reputation as a low stress training for seniors became better known.
Traditionalists feel that a school not teaching martial aspects somewhere in their syllabus cannot be said to be actually teaching the art itself, that they have accredited themselves prematurely. Traditional teachers also believe that understanding the core theoretical principles of neijia and the ability to apply them are a necessary gateway to health benefits.
Fiction.
Internal styles have been associated in legend and in much popular fiction with the Taoist monasteries of Wudangshan in central China.
Neijia are a common theme in Chinese Wuxia novels and films, and are usually represented as originating in Wudang or similar mythologies. Often, genuine internal practices are highly exaggerated to the point of making them seem miraculous, as in "Crouching Tiger Hidden Dragon" or "Tai Chi Master". Internal concepts have also been a source of comedy, such as in the films "Shaolin Soccer" and "Kung Fu Hustle".
In Naruto series, Neji Hyūga's name and techniques was based on Neijia.

</doc>
<doc id="21854" url="http://en.wikipedia.org/wiki?curid=21854" title="Navigation">
Navigation

Navigation is a field of study that focuses on the process of monitoring and controlling the movement of a craft or vehicle from one place to another. The field of navigation includes four general categories: land navigation, marine navigation, aeronautic navigation, and space navigation.
It is also the term of art used for the specialized knowledge used by navigators to perform navigation tasks. All navigational techniques involve locating the navigator's position compared to known locations or patterns.
Navigation, in a broader sense, can refer to any skill or study that involves the determination of position and direction. In this sense, navigation includes orienteering and pedestrian navigation. For information about different navigation strategies that people use, visit human navigation.
History.
In the European medieval period, navigation was considered part of the set of "seven mechanical arts", none of which were used for long voyages across open ocean. Polynesian navigation is probably the earliest form of open ocean navigation, though it was based on memory and observation rather than on scientific methods or instruments. Early Pacific Polynesians used the motion of stars, weather, the position of certain wildlife species, or the size of waves to find the path from one island to another.
Maritime navigation using scientific instruments such as the mariner's astrolabe first occurred in the Mediterranean during the Middle Ages. Although land astrolabes were invented in the Hellenistic period and existed in classical antiquity and the Islamic Golden Age, the oldest record of a sea astrolabe is that of Majorcan astronomer Ramon Llull dating from 1295. The perfecting of this navigation instrument is attributed to Portuguese navigators during early Portuguese discoveries in the Age of Discovery. The earliest known description of how to make and use a sea astrolabe comes from Spanish cosmographer Melvin Mel Pros Cespedes's "Arte de Navegar" ("The Art of Navigation") published in 1551, based on the principle of the archipendulum used in constructing the Egyptian pyramids.
Open-seas navigation using the astrolabe and the compass started during the Age of Discovery in the 15th century. The Portuguese began systematically exploring the Atlantic coast of Africa from 1418, under the sponsorship of Prince Henry. In 1488 Bartolomeu Dias reached the Indian Ocean by this route. In 1492 the Spanish monarchs funded Christopher Columbus's expedition to sail west to reach the Indies by crossing the Atlantic, which resulted in the Discovery of America. In 1498, a Portuguese expedition commanded by Vasco da Gama reached India by sailing around Africa, opening up direct trade with Asia. Soon, the Portuguese sailed further eastward, to the Spice Islands in 1512, landing in China one year later.
The first circumnavigation of the earth was completed in 1522 with the Magellan-Elcano expedition, a Spanish voyage of discovery led by Portuguese explorer Ferdinand Magellan and completed by Spanish navigator Juan Sebastián Elcano after the former's death in the Philippines in 1521. The fleet of seven ships sailed from Sanlúcar de Barrameda in Southern Spain in 1519, crossed the Atlantic Ocean and after several stopovers rounded the southern tip of South America. Some ships were lost, but the remaining fleet continued across the Pacific making a number of discoveries including Guam and the Philippines. By then, only two galleons were left from the original seven. The "Victoria" led by Elcano sailed across the Indian Ocean and north along the coast of Africa, to finally arrive in Spain in 1522, three years after its departure. The "Trinidad" sailed east from the Philippines, trying to find a maritime path back to the Americas, but was unsuccessful. The eastward route across the Pacific, also known as the "tornaviaje" (return trip) was only discovered forty years later, when Spanish cosmographer Andrés de Urdaneta sailed from the Philippines, north to parallel 39º, and hit the eastward Kuroshio Current which took its galleon across the Pacific. He arrived in Acapulco on October 8, 1565.
Etymology.
The term stems from 1530s, from Latin "navigationem" (nom. "navigatio"), from "navigatus", pp. of "navigare" "to sail, sail over, go by sea, steer a ship," from "navis" "ship" and the root of "agere" "to drive".
Basic concepts.
Latitude.
Roughly, the latitude of a place on Earth is its angular distance north or south of the equator. Latitude is usually expressed in degrees (marked with °) ranging from 0° at the Equator to 90° at the North and South poles. The latitude of the North Pole is 90° N, and the latitude of the South Pole is 90° S. Mariners calculated latitude in the Northern Hemisphere by sighting the North Star Polaris with a sextant and using sight reduction tables to correct for height of eye and atmospheric refraction. The height of Polaris in degrees above the horizon is the latitude of the observer, within a degree or so.
Longitude.
Similar to latitude, the longitude of a place on Earth is the angular distance east or west of the prime meridian or Greenwich meridian. Longitude is usually expressed in degrees (marked with °) ranging from 0° at the Greenwich meridian to 180° east and west. Sydney, for example, has a longitude of about 151° east. New York City has a longitude of 74° west. For most of history, mariners struggled to determine longitude. Longitude can be calculated if the precise time of a sighting is known. Lacking that, one can use a sextant to take a lunar distance (also called "the lunar observation", or "lunar" for short) that, with a nautical almanac, can be used to calculate the time at zero longitude (see Greenwich Mean Time). Reliable marine chronometers were unavailable until the late 18th century and not affordable until the 19th century. For about a hundred years, from about 1767 until about 1850, mariners lacking a chronometer used the method of lunar distances to determine Greenwich time to find their longitude. A mariner with a chronometer could check its reading using a lunar determination of Greenwich time.
Loxodrome.
In navigation, a rhumb line (or loxodrome) is a line crossing all meridians of longitude at the same angle, i.e. a path derived from a defined initial bearing. That is, upon taking an initial bearing, one proceeds along the same bearing, without changing the direction as measured relative to true or magnetic north.
Modern technique.
Most modern navigation relies primarily on positions determined electronically by receivers collecting information from satellites. Most other modern techniques rely on crossing lines of position or LOP. A line of position can refer to two different things: a line on a chart and a line between the observer and an object in real life. A bearing is a measure of the direction to an object. If the navigator measures the direction in real life, the angle can then be drawn on a nautical chart and the navigator will be on that line on the chart.
In addition to bearings, navigators also often measure distances to objects. On the chart, a distance produces a circle or arc of position. Circles, arcs, and hyperbolae of positions are often referred to as lines of position.
If the navigator draws two lines of position, and they intersect he must be at that position. A fix is the intersection of two or more LOPs.
If only one line of position is available, this may be evaluated against the Dead reckoning position to establish an estimated position.
Lines (or circles) of position can be derived from a variety of sources:
There are some methods seldom used today such as "dipping a light" to calculate the geographic range from observer to lighthouse
Methods of navigation have changed through history. Each new method has enhanced the mariner's ability to complete his voyage. One of the most important judgments the navigator must make is the best method to use. Some types of navigation are depicted in the table.
The practice of navigation usually involves a combination of these different methods.
Mental navigation checks.
By mental navigation checks, a pilot or a navigator estimates tracks, distances, and altitudes which then will help him or her avoid gross navigation errors.
Piloting.
Piloting (also called pilotage) involves navigating an aircraft by visual reference to landmarks, or a water vessel in restricted waters and fixing its position as precisely as possible at frequent intervals. More so than in other phases of navigation, proper preparation and attention to detail are important. Procedures vary from vessel to vessel, and between military, commercial, and private vessels.
A military navigation team will nearly always consist of several people. A military navigator might have bearing takers stationed at the gyro repeaters on the bridge wings for taking simultaneous bearings, while the civilian navigator must often take and plot them himself. While the military navigator will have a bearing book and someone to record entries for each fix, the civilian navigator will simply pilot the bearings on the chart as they are taken and not record them at all.
If the ship is equipped with an ECDIS, it is reasonable for the navigator to simply monitor the progress of the ship along the chosen track, visually ensuring that the ship is proceeding as desired, checking the compass, sounder and other indicators only occasionally. If a pilot is aboard, as is often the case in the most restricted of waters, his judgement can generally be relied upon, further easing the workload. But should the ECDIS fail, the navigator will have to rely on his skill in the manual and time-tested procedures.
Celestial navigation.
Celestial navigation systems are based on observation of the positions of the Sun, Moon, Planets and navigational stars. Such systems are in use as well for terrestrial navigating as for interstellar navigating. By knowing which point on the rotating earth a celestial object is above and measuring its height above the observer's horizon, the navigator can determine his distance from that subpoint. A nautical almanac and a marine chronometer are used to compute the subpoint on earth a celestial body is over, and a sextant is used to measure the body's angular height above the horizon. That height can then be used to compute distance from the subpoint to create a circular line of position. A navigator shoots a number of stars in succession to give a series of overlapping lines of position. Where they intersect is the celestial fix. The moon and sun may also be used. The sun can also be used by itself to shoot a succession of lines of position (best done around local noon) to determine a position.
Marine chronometer.
In order to accurately measure longitude, the precise time of a sextant sighting (down to the second, if possible) must be recorded. Each second of error is equivalent to 15 seconds of longitude error, which at the equator is a position error of .25 of a nautical mile, about the accuracy limit of manual celestial navigation.
The spring-driven marine chronometer is a precision timepiece used aboard ship to provide accurate time for celestial observations. A chronometer differs from a spring-driven watch principally in that it contains a variable lever device to maintain even pressure on the mainspring, and a special balance designed to compensate for temperature variations.
A spring-driven chronometer is set approximately to Greenwich mean time (GMT) and is not reset until the instrument is overhauled and cleaned, usually at three-year intervals. The difference between GMT and chronometer time is carefully determined and applied as a correction to all chronometer readings. Spring-driven chronometers must be wound at about the same time each day.
Quartz crystal marine chronometers have replaced spring-driven chronometers aboard many ships because of their greater accuracy. They are maintained on GMT directly from radio time signals. This eliminates chronometer error and watch error corrections. Should the second hand be in error by a readable amount, it can be reset electrically.
The basic element for time generation is a quartz crystal oscillator. The quartz crystal is temperature compensated and is hermetically sealed in an evacuated envelope. A calibrated adjustment capability is provided to adjust for the aging of the crystal.
The chronometer is designed to operate for a minimum of 1 year on a single set of batteries. Observations may be timed and ship's clocks set with a comparing watch, which is set to chronometer time and taken to the bridge wing for recording sight times. In practice, a wrist watch coordinated to the nearest second with the chronometer will be adequate.
A stop watch, either spring wound or digital, may also be used for celestial observations. In this case, the watch is started at a known GMT by chronometer, and the elapsed time of each sight added to this to obtain GMT of the sight.
All chronometers and watches should be checked regularly with a radio time signal. Times and frequencies of radio time signals are listed in publications such as Radio Navigational Aids.
The marine sextant.
The second critical component of celestial navigation is to measure the angle formed at the observer's eye between the celestial body and the sensible horizon. The sextant, an optical instrument, is used to perform this function. The sextant consists of two primary assemblies. The frame is a rigid triangular structure with a pivot at the top and a graduated segment of a circle, referred to as the "arc", at the bottom. The second component is the index arm, which is attached to the pivot at the top of the frame. At the bottom is an endless vernier which clamps into teeth on the bottom of the "arc". The optical system consists of two mirrors and, generally, a low power telescope. One mirror, referred to as the "index mirror" is fixed to the top of the index arm, over the pivot. As the index arm is moved, this mirror rotates, and the graduated scale on the arc indicates the measured angle ("altitude").
The second mirror, referred to as the "horizon glass", is fixed to the front of the frame. One half of the horizon glass is silvered and the other half is clear. Light from the celestial body strikes the index mirror and is reflected to the silvered portion of the horizon glass, then back to the observer's eye through the telescope. The observer manipulates the index arm so the reflected image of the body in the horizon glass is just resting on the visual horizon, seen through the clear side of the horizon glass.
Adjustment of the sextant consists of checking and aligning all the optical elements to eliminate "index correction". Index correction should be checked, using the horizon or more preferably a star, each time the sextant is used. The practice of taking celestial observations from the deck of a rolling ship, often through cloud cover and with a hazy horizon, is by far the most challenging part of celestial navigation.
Inertial navigation.
Inertial navigation system is a dead reckoning type of navigation system that computes its position based on motion sensors. Once the initial latitude and longitude is established, the system receives impulses from motion detectors that measure the acceleration along three or more axes enabling it to continually and accurately calculate the current latitude and longitude. Its advantages over other navigation systems are that, once the starting position is set, it does not require outside information, it is not affected by adverse weather conditions and it cannot be detected or jammed. Its disadvantage is that since the current position is calculated solely from previous positions, its errors are cumulative, increasing at a rate roughly proportional to the time since the initial position was input. Inertial navigation systems must therefore be frequently corrected with a location 'fix' from some other type of navigation system. The US Navy developed a Ships Inertial Navigation System (SINS) during the Polaris missile program to ensure a safe, reliable and accurate navigation system for its missile submarines. Inertial navigation systems were in wide use until satellite navigation systems (GPS) became available. Inertial Navigation Systems are still in common use on submarines, since GPS reception or other fix sources are not possible while submerged.
Electronic navigation.
Radio navigation.
A radio direction finder or RDF is a device for finding the direction to a radio source. Due to radio's ability to travel very long distances "over the horizon", it makes a particularly good navigation system for ships and aircraft that might be flying at a distance from land.
RDFs works by rotating a directional antenna and listening for the direction in which the signal from a known station comes through most strongly. This sort of system was widely used in the 1930s and 1940s. RDF antennas are easy to spot on German World War II aircraft, as loops under the rear section of the fuselage, whereas most US aircraft enclosed the antenna in a small teardrop-shaped fairing.
In navigational applications, RDF signals are provided in the form of "radio beacons", the radio version of a lighthouse. The signal is typically a simple AM broadcast of a morse code series of letters, which the RDF can tune in to see if the beacon is "on the air". Most modern detectors can also tune in any commercial radio stations, which is particularly useful due to their high power and location near major cities.
Decca, OMEGA, and LORAN-C are three similar hyperbolic navigation systems. Decca was a hyperbolic low frequency radio navigation system (also known as multilateration) that was first deployed during World War II when the Allied forces needed a system which could be used to achieve accurate landings. As was the case with Loran C, its primary use was for ship navigation in coastal waters. Fishing vessels were major post-war users, but it was also used on aircraft, including a very early (1949) application of moving-map displays. The system was deployed in the North Sea and was used by helicopters operating to oil platforms.
The OMEGA Navigation System was the first truly global radio navigation system for aircraft, operated by the United States in cooperation with six partner nations. OMEGA was developed by the United States Navy for military aviation users. It was approved for development in 1968 and promised a true worldwide oceanic coverage capability with only eight transmitters and the ability to achieve a four-mile (6 km) accuracy when fixing a position. Initially, the system was to be used for navigating nuclear bombers across the North Pole to Russia. Later, it was found useful for submarines. Due to the success of the Global Positioning System the use of Omega declined during the 1990s, to a point where the cost of operating Omega could no longer be justified. Omega was terminated on September 30, 1997 and all stations ceased operation.
LORAN is a terrestrial navigation system using low frequency radio transmitters that use the time interval between radio signals received from three or more stations to determine the position of a ship or aircraft. The current version of LORAN in common use is LORAN-C, which operates in the low frequency portion of the EM spectrum from 90 to 110 kHz. Many nations are users of the system, including the United States, Japan, and several European countries. Russia uses a nearly exact system in the same frequency range, called CHAYKA. LORAN use is in steep decline, with GPS being the primary replacement. However, there are attempts to enhance and re-popularize LORAN. LORAN signals are less susceptible to interference and can penetrate better into foliage and buildings than GPS signals.
Radar navigation.
When a vessel is within radar range of land or special radar aids to navigation, the navigator can take distances and angular bearings to charted objects and use these to establish arcs of position and lines of position on a chart. A fix consisting of only radar information is called a radar fix.
Types of radar fixes include "range and bearing to a single object," "two or more bearings," "tangent bearings," and "two or more ranges."
Parallel indexing is a technique defined by William Burger in the 1957 book "The Radar Observer's Handbook". This technique involves creating a line on the screen that is parallel to the ship's course, but offset to the left or right by some distance. This parallel line allows the navigator to maintain a given distance away from hazards.
Some techniques have been developed for special situations. One, known as the "contour method," involves marking a transparent plastic template on the radar screen and moving it to the chart to fix a position.
Another special technique, known as the Franklin Continuous Radar Plot Technique, involves drawing the path a radar object should follow on the radar display if the ship stays on its planned course. During the transit, the navigator can check that the ship is on track by checking that the pip lies on the drawn line.
Satellite navigation.
Global Navigation Satellite System or GNSS is the term for satellite navigation systems that provide positioning with global coverage. A GNSS allow small electronic receivers to determine their location (longitude, latitude, and altitude) to within a few metres using time signals transmitted along a line of sight by radio from satellites. Receivers on the ground with a fixed position can also be used to calculate the precise time as a reference for scientific experiments.
As of October 2011, only the United States NAVSTAR Global Positioning System (GPS) and the Russian GLONASS are fully globally operational GNSSs. The European Union's Galileo positioning system is a next generation GNSS in the initial deployment phase, scheduled to be operational by 2013. China has indicated it may expand its regional Beidou navigation system into a global system.
More than two dozen GPS satellites are in medium Earth orbit, transmitting signals allowing GPS receivers to determine the receiver's location, speed and direction.
Since the first experimental satellite was launched in 1978, GPS has become an indispensable aid to navigation around the world, and an important tool for map-making and land surveying. GPS also provides a precise time reference used in many applications including scientific study of earthquakes, and synchronization of telecommunications networks.
Developed by the United States Department of Defense, GPS is officially named NAVSTAR GPS (NAVigation Satellite Timing And Ranging Global Positioning System). The satellite constellation is managed by the United States Air Force 50th Space Wing. The cost of maintaining the system is approximately US$750 million per year, including the replacement of aging satellites, and research and development. Despite this fact, GPS is free for civilian use as a public good.
Navigation processes.
Day's work in navigation.
The Day's work in navigation is a minimal set of tasks consistent with prudent navigation. The definition will vary on military and civilian vessels, and from ship to ship, but takes a form resembling:
Passage planning.
Passage planning or voyage planning is a procedure to develop a complete description of vessel's voyage from start to finish. The plan includes leaving the dock and harbor area, the en route portion of a voyage, approaching the destination, and mooring. According to international law, a vessel's captain is legally responsible for passage planning, however on larger vessels, the task will be delegated to the ship's navigator.
Studies show that human error is a factor in 80 percent of navigational accidents and that in many cases the human making the error had access to information that could have prevented the accident. The practice of voyage planning has evolved from penciling lines on nautical charts to a process of risk management.
Passage planning consists of four stages: appraisal, planning, execution, and monitoring, which are specified in "International Maritime Organization Resolution A.893(21), Guidelines For Voyage Planning," and these guidelines are reflected in the local laws of IMO signatory countries (for example, Title 33 of the U.S. Code of Federal Regulations), and a number of professional books or publications. There are some fifty elements of a comprehensive passage plan depending on the size and type of vessel.
The appraisal stage deals with the collection of information relevant to the proposed voyage as well as ascertaining risks and assessing the key features of the voyage. In the next stage, the written plan is created. The third stage is the execution of the finalised voyage plan, taking into account any special circumstances which may arise such as changes in the weather, which may require the plan to be reviewed or altered. The final stage of passage planning consists of monitoring the vessel's progress in relation to the plan and responding to deviations and unforeseen circumstances.
Integrated bridge systems.
Electronic integrated bridge concepts are driving future navigation system planning. Integrated systems take inputs from various ship sensors, electronically display positioning information, and provide control signals required to maintain a vessel on a preset course. The navigator becomes a system manager, choosing system presets, interpreting system output, and monitoring vessel response.
References.
</dl>

</doc>
<doc id="21857" url="http://en.wikipedia.org/wiki?curid=21857" title="Non-fiction">
Non-fiction

Nonfiction or non-fiction is the classification for any informative work (often, a story) whose creator, in good faith, assumes responsibility for the truth or accuracy of the events, people, and/or information presented. A work whose creator dishonestly claims this same responsibility is a fraud; a story whose creator claims no such responsibility to the truth is classified as fiction. Nonfiction, which may be presented either objectively or subjectively, is traditionally one of the two main divisions of narratives (and, specifically, prose writing), the other traditional division being fiction, which contrasts with nonfiction by dealing in information, events, and characters expected to be partly or largely imaginary. 
Nonfiction's factual assertions and descriptions may or may not be accurate, and can give either a true or a false account of the subject in question; however, authors of such accounts genuinely believe or claim them to be truthful at the time of their composition or, at least, pose them to a convinced audience as historically or empirically factual. Reporting the beliefs of others in a nonfiction format is not necessarily an endorsement of the ultimate veracity of those beliefs, it is simply saying it is true that people believe them (for such topics as mythology). Nonfiction can also be written about fiction, typically known as literary criticism, giving information and analysis on these other works. Nonfiction need not necessarily be written text, since pictures and film can also purport to present a factual account of a subject.
Major types of nonfiction.
Common literary examples of nonfiction include expository, argumentative, functional, and opinion pieces; essays on art or literature; biographies; memoirs; journalism; and historical, scientific, technical, or economic writings (including electronic ones).
Journals, photographs, textbooks, travel books, blueprints, and diagrams are also often considered non-fictional. Including information that the author knows to be untrue within any of these works is usually regarded as dishonest. Other works can legitimately be either fiction or nonfiction, such as journals of self-expression, letters, magazine articles, and other expressions of imagination. Though they are mostly either one or the other, it is possible for there to be a blend of both. Some fiction may include nonfictional elements. Some nonfiction may include elements of unverified supposition, deduction, or imagination for the purpose of smoothing out a narrative, but the inclusion of open falsehoods would discredit it as a work of nonfiction. The publishing and bookselling business sometimes uses the phrase "literary nonfiction" to distinguish works with a more literary or intellectual bent, as opposed to the greater collection of nonfiction subjects.
Distinctions.
The numerous literary and creative devices used within fiction are generally thought inappropriate for use in nonfiction. They are still present particularly in older works but they are often muted so as not to overshadow the information within the work. Simplicity, clarity and directness are some of the most important considerations when producing nonfiction. Audience is important in any artistic or descriptive endeavor, but it is perhaps most important in nonfiction. In fiction, the writer believes that readers will make an effort to follow and interpret an indirectly or abstractly presented progression of theme, whereas the production of nonfiction has more to do with the direct provision of information. Understanding of the potential readers' use for the work and their existing knowledge of a subject are both fundamental for effective nonfiction. Despite the truth of nonfiction it is often necessary to persuade the reader to agree with the ideas and so a balanced, coherent and informed argument is vital. However, the boundaries between fiction and nonfiction are continually blurred and argued upon, especially in the field of biography; as Virginia Woolf said: "if we think of truth as something of granite-like solidity and of personality as something of rainbow-like intangibility and reflect that the aim of biography is to weld these two into one seamless whole, we shall admit that the problem is a stiff one and that we need not wonder if biographers, for the most part failed to solve it."
Semi-fiction is fiction implementing a great deal of nonfiction, e.g. a fictional description based on a true story.
History.
Cave paintings, from 32,000 years ago, are one of the oldest forms of human expression and could be either a record of what prehistoric man caught on hunting trips, i.e. nonfiction, or alternately a story expressing what they would like to catch on future occasions, i.e. fiction. If cave art is ambiguous on this matter then cuneiform inscriptions which hold the earliest writings seem to have been initially for nonfiction.
Much of the nonfiction produced throughout history is of a mundane and everyday variety, such as records and legal documents which were seen by only a few and are of little interest except to the historian. The nonfiction that transcends its original time tends to be viewed as either exceptionally well made or perfectly embodying the ideas, manners and attitudes of the time it was produced, even if it was not actually created as history.
At any one time in history there is the body of nonfiction work which represents the currently accepted truths of the period. Although these nonfiction works may be contradictory, they form a corpus that is regularly being altered with new facts and better explanations of ideas. A good example of this would be the nonfiction scientific books and papers which explain the science of the day, but are then superseded by better representations. Textbooks for explaining and teaching the current state of scientific and historical knowledge are regularly updated, and manuals for operating new technology are also produced.

</doc>
<doc id="21861" url="http://en.wikipedia.org/wiki?curid=21861" title="Cryptonomicon">
Cryptonomicon

Cryptonomicon is a 1999 novel by American author Neal Stephenson, set in two different time periods. One group of characters are World War II-era Allied codebreakers and tactical-deception operatives affiliated with the Government Code and Cypher School at Bletchley Park, and disillusioned Axis military and intelligence figures. The second narrative is set in the late 1990s, with characters that are (in part) descendants of those of the earlier time period, who employ cryptologic, telecom and computer technology to build an underground data haven in the fictional Sultanate of Kinakuta. Their goal is to facilitate anonymous Internet banking using electronic money and (later) digital gold currency, with a long-term objective to distribute Holocaust Education and Avoidance Pod (HEAP) media for instructing genocide-target populations on defensive warfare.
Genre and subject matter.
"Cryptonomicon" is closer to the genres of historical fiction and contemporary techno-thriller than to the science fiction of Stephenson's two previous novels, "Snow Crash" and "Diamond Age". It features fictionalized characterizations of such historical figures as Alan Turing, Albert Einstein, Douglas MacArthur, Winston Churchill, Isoroku Yamamoto, Karl Dönitz, Hermann Göring, and Ronald Reagan, as well as some highly technical and detailed descriptions of modern cryptography and information security, with discussions of prime numbers, modular arithmetic, and Van Eck phreaking.
Title.
According to Stephenson:
The title is a play on "Necronomicon", the title of a book mentioned in the stories of horror writer H. P. Lovecraft:
I wanted to give it a title a 17th-century book by a scholar would be likely to have. And that's how I came up with "Cryptonomicon". I've heard the word "Necronomicon" bounced around. I haven't actually read the Lovecraft books, but clearly it's formed by analogy to that.
The novel's Cryptonomicon, described as a "cryptographer's bible", is a fictional book summarizing America's knowledge of cryptography and cryptanalysis. Begun by John Wilkins (the Cryptonomicon is mentioned in "Quicksilver") and amended over time by William Friedman, Lawrence Waterhouse, and others, the Cryptonomicon is described by Katherine Hayles as "a kind of Kabala created by a Brotherhood of Code that stretches across centuries. To know its contents is to qualify as a Morlock among the Eloi, and the elite among the elite are those gifted enough actually to contribute to it."
Plot.
The action takes place in two periods — World War II and the late 1990s, during the Internet boom and Asian financial crisis.
In 1942, Lawrence Pritchard Waterhouse, a young United States Navy code breaker and mathematical genius, is assigned to the newly formed joint British and American Detachment 2702. This ultra-secret unit's role is to hide the fact that Allied intelligence has cracked the German Enigma code. The detachment stages events, often behind enemy lines, that provide alternative explanations for the Allied intelligence successes. United States Marine sergeant Bobby Shaftoe, a veteran of China and Guadalcanal, serves in unit 2702, carrying out Waterhouse's plans. At the same time, Japanese soldiers, including mining engineer Goto Dengo, an old friend of Shaftoe's, are assigned to build a mysterious bunker in the mountains in the Philippines as part of what turns out to be a literal suicide mission.
Circa 1997, Randy Waterhouse (Lawrence's grandson) joins his old role-playing game companion Avi Halaby in a new startup, providing Pinoy-grams (inexpensive, non-real-time video messages) to migrant Filipinos via new fiber-optic cables. The Epiphyte Corporation uses this income stream to fund the creation of a data haven in the nearby fictional Sultanate of Kinakuta. Vietnam veteran Doug Shaftoe and his daughter Amy do the undersea surveying for the cables and engineering work on the haven is overseen by Goto Furudenendu, heir-apparent to Goto Engineering. Complications arise as figures from the past reappear seeking gold or revenge.
Characters.
World War II storyline.
Historical figures.
Fictionalized versions of several historical figures appear in the World War II storyline:
1990s storyline.
The precise date of this storyline is not established, but the ages of characters, the technologies described, and certain date-specific references suggest that it is set in the late 1990s, at the time of the internet boom and the Asian financial crisis.
Technical content.
Portions of "Cryptonomicon" are notably complex and may be considered somewhat difficult by the non-technical reader. Several pages are spent explaining in detail some of the concepts behind cryptography and data storage security, including a description of Van Eck phreaking.
Stephenson also includes a precise description of (and even Perl script for) the Solitaire (or Pontifex) cipher, a cryptographic algorithm developed by Bruce Schneier for use with a deck of playing cards, as part of the plot. 
He also describes computers using a fictional operating system, Finux. The name is a thinly veiled reference to Linux, a kernel originally written by the Finnish native Linus Torvalds. Stephenson changed the name so as not to be creatively constrained by the technical details of Linux-based operating systems.
Allusions/references from other works.
An excerpt from "Cryptonomicon" was originally published in the short story collection "Disco 2000", edited by Sarah Champion and published in 1998.
Stephenson's subsequent work, "The Baroque Cycle", provides part of the backstory to the characters and events featured in "Cryptonomicon". An excerpt of "Quicksilver", Volume One of "The Baroque Cycle", is included in later prints of the Mass Market Paperback edition. 
"The Baroque Cycle", set in the late 17th and early 18th centuries, features ancestors of several characters in "Cryptonomicon", as well as events and items which affect the action of the later-set book. The subtext implies the existence of secret societies or conspiracies, and familial tendencies and groupings found within those darker worlds.
The short story "Jipi and the Paranoid Chip" appears to take place some time after the events of "Cryptonomicon". In the story, the construction of the Crypt has triggered economic growth in Manila and Kinakuta, in which Goto Engineering, and Homa/Homer Goto, a Goto family heir, are involved. The IDTRO ("Black Chamber") is also mentioned.
Peter Thiel states in his book "Zero to One" that "Cryptonomicon" was required reading during the early days of PayPal.
Literary significance and criticism.
According to critic Jay Clayton, the book is written for a technical or geek audience. Despite the technical detail, the book drew praise from both Stephenson's science fiction fan base and literary critics and buyers. In his book "Charles Dickens in Cyberspace: The Afterlife of the Nineteenth Century in Postmodern Culture" (2003), Jay Clayton calls Stephenson’s book the “ultimate geek novel” and draws attention to the “literary-scientific-engineering-military-industrial-intelligence alliance” that produced discoveries in two eras separated by fifty years, World War II and the Internet age. In July 2012, io9 included the book on its list of "10 Science Fiction Novels You Pretend to Have Read".

</doc>
<doc id="21862" url="http://en.wikipedia.org/wiki?curid=21862" title="In the Beginning... Was the Command Line">
In the Beginning... Was the Command Line

In the Beginning... Was the Command Line is an essay by Neal Stephenson which was originally published online in 1999 and later made available in book form (November 1999, ISBN 978-0380815937). The essay is a commentary on why the proprietary operating systems business is unlikely to remain profitable in the future because of competition from free software. It also analyzes the corporate/collective culture of the Microsoft, Apple, and free software communities.
Themes.
Stephenson explores the GUI as a metaphor in terms of the increasing interposition of abstractions between humans and the actual workings of devices (in a similar manner to "Zen and the Art of Motorcycle Maintenance") and explains the beauty hackers feel in good-quality tools. He does this with a car analogy. He compares four operating systems, Mac OS by Apple Computer to a luxury European car, Windows by Microsoft to a station wagon, Linux to a free tank, and BeOS to a batmobile. Stephenson argues that people continue to buy the station wagon despite free tanks being given away, because people do not want to learn how to operate a tank; they know that the station wagon dealership has a machine shop that they can take their car to when it breaks down. Because of this attitude, Stephenson argues that Microsoft is not really a monopoly, as evidenced by the free availability of other choice OSes, but rather has simply accrued enough mindshare among the people to have them coming back. He compares Microsoft to Disney, in that both are selling a vision to their customers, who in turn "want to believe" in that vision.
Stephenson relays his experience with the Debian bug tracking system (). He then contrasts it with Microsoft's approach. Debian developers responded from around the world within a day. He was completely frustrated with his initial attempt to achieve the same response from Microsoft, but he concedes that his subsequent experience was satisfactory. The difference he notes is that Debian developers are personally accessible and transparently own up to defects in their OS distribution, while Microsoft pretends errors don't exist.
Later developments.
The essay was written before the advent of Mac OS X. A recurring theme is the full power of the command line compared with easier to learn graphical user interfaces (GUIs) which are described as broken mixed metaphors for 'power users'. He then mentions GUIs which allow traditional terminal windows to be used. In a Slashdot interview in 2004, in response to the question:
... have you embraced the new UNIX based MacOS X as the OS you want to use when you "Just want to go to Disneyland"?
he replied:
I embraced OS X as soon as it was available and have never looked back. So a lot of "In the Beginning...was the Command Line" is now obsolete. I keep meaning to update it, but if I'm honest with myself, I have to say this is unlikely.
With Neal Stephenson's permission, Garrett Birkel responded to "In the Beginning...was the Command Line" in 2004, bringing it up to date and critically discussing Stephenson's argument. Birkel's response is interspersed throughout the original text, which remains untouched.

</doc>
<doc id="21863" url="http://en.wikipedia.org/wiki?curid=21863" title="Netscape Navigator">
Netscape Navigator

Netscape Navigator was a proprietary web browser. It was the flagship product of the Netscape Communications Corp and was the dominant web browser in terms of usage share in the 1990s, but by 2002 its usage had almost disappeared. This was primarily due to the increased usage of Microsoft's Internet Explorer web browser software, and partly because the Netscape Corporation (later purchased by AOL) did not sustain Netscape Navigator's technical innovation after the late 1990s.
The business demise of Netscape was a central premise of Microsoft's antitrust trial, wherein the Court ruled that Microsoft Corporation's bundling of Internet Explorer with the Windows operating system was a monopolistic and illegal business practice. The decision came too late for Netscape, however, as Internet Explorer had by then become the dominant web browser in Windows.
The Netscape Navigator web browser was succeeded by Netscape Communicator. Netscape Communicator's 4.x source code was the base for the Netscape-developed Mozilla Application Suite, which was later renamed SeaMonkey. Netscape's Mozilla Suite also served as the base for a browser-only spinoff called Mozilla Firefox and Netscape versions 6 through 9.
AOL stopped development of Netscape Navigator on 28 December 2007, but continued supporting the web browser with security updates until 1 March 2008. AOL allows downloading of archived versions of the Netscape Navigator web browser family. AOL maintains the Netscape website as an Internet portal.
History and development.
Origin.
Netscape Navigator was based on the Mosaic web browser, which was co-written by Marc Andreessen, a part-time employee of the National Center for Supercomputing Applications and a student at the University of Illinois. After Andreessen graduated in 1993, he moved to California and there met Jim Clark, the recently departed founder of Silicon Graphics. Clark believed that the Mosaic browser had great commercial possibilities and provided the seed money. Soon Mosaic Communications Corporation was in business in Mountain View, California, with Andreessen as a vice-president. Since the University of Illinois was unhappy with the company's use of the Mosaic name, the company changed its name to Netscape Communications (thought up by Product Manager Greg Sands) and named its flagship web browser Netscape Navigator.
Netscape announced in its first press release (13 October 1994) that it would make Navigator available without charge to all non-commercial users, and beta versions of version 1.0 and 1.1 were indeed freely downloadable in November 1994 and March 1995, with the full version 1.0 available in December 1994. Netscape's initial corporate policy regarding Navigator is interesting, as it claimed that it would make Navigator freely available for non-commercial use in accordance with the notion that Internet software should be distributed for free.
However, within 2 months of that press release, Netscape apparently reversed its policy on who could freely obtain and use version 1.0 by only mentioning that educational and non-profit institutions could use version 1.0 at no charge.
The reversal was complete with the availability of version 1.1 beta on 6 March 1995, in which a press release states that the final 1.1 release would be available at no cost only for academic and non-profit organizational use. Gone was the notion expressed in the first press release that Navigator would be freely available in the spirit of Internet software.
Some security experts and cryptographers found out that all released Netscape versions had major security problems with crashing the browser with long URLs and 40 bits encryption keys.
The first few releases of the product were made available in “commercial” and “evaluation” versions; for example, version “1.0” and version “1.0N”. The “N” evaluation versions were completely identical to the commercial versions; the letter was there to remind people to pay for the browser once they felt they had tried it long enough and were satisfied with it. This distinction was formally dropped within a year of the initial release, and the full version of the browser continued to be made available for free online, with boxed versions available on floppy disks (and later CDs) in stores along with a period of phone support. During this era, "Internet Starter Kit" books were popular, and usually included a floppy disk or CD containing internet software, and this was a popular means of obtaining Netscape's and other browsers. Email support was initially free, and remained so for a year or two until the volume of support requests grew too high.
During development, the Netscape browser was known by the code name "Mozilla", which became the name of a Godzilla-like cartoon dragon mascot used prominently on the company's web site. The Mozilla name was also used as the User-Agent in HTTP requests by the browser. Other web browsers claimed to be compatible with Netscape's extensions to HTML, and therefore used the same name in their User-Agent identifiers so that web servers would send them the same pages as were sent to Netscape browsers. Mozilla is now a generic name for matters related to the open source successor to Netscape Communicator.
The rise of Netscape.
When the consumer Internet revolution arrived in the mid-to-late 1990s, Netscape was well-positioned to take advantage of it. With a good mix of features and an attractive licensing scheme that allowed free use for non-commercial purposes, the Netscape browser soon became the de facto standard, particularly on the Windows platform. Internet service providers and computer magazine publishers helped make Navigator readily available.
An important innovation that Netscape introduced in 1994 was the on-the-fly display of web pages, where text and graphics appeared on the screen as the web page downloaded. Earlier web browsers would not display a page until all graphics on it had been loaded over the network connection; this often made a user stare at a blank page for as long as several minutes. With Netscape, people using dial-up connections could begin reading the text of a web page within seconds of entering a web address, even before the rest of the text and graphics had finished downloading. This made the web much more tolerable to the average user.
Through the late 1990s, Netscape made sure that Navigator remained the technical leader among web browsers. Important new features included cookies, frames, proxy auto-config, and JavaScript (in version 2.0). Although those and other innovations eventually became open standards of the W3C and ECMA and were emulated by other browsers, they were often viewed as controversial. Netscape, according to critics, was more interested in bending the web to its own de facto "standards" (bypassing standards committees and thus marginalizing the commercial competition) than it was in fixing bugs in its products. Consumer rights advocates were particularly critical of cookies and of commercial web sites using them to invade individual privacy.
In the marketplace, however, these concerns made little difference. Netscape Navigator remained the market leader with more than 50% usage share. The browser software was available for a wide range of operating systems, including Windows (3.1, 95, 98, NT), Macintosh, Linux, OS/2, and many versions of Unix including DEC, Sun Solaris, BSD/OS, IRIX, AIX, and HP-UX, and looked and worked nearly identically on every one of them. Netscape began to experiment with prototypes of a web-based system, known internally as “Constellation”, which would allow a user to access and edit his or her files anywhere across a network no matter what computer or operating system he or she happened to be using.
Industry observers confidently forecast the dawn of a new era of connected computing. The underlying operating system, it was believed, would become an unimportant consideration; future applications would run within a web browser. This was seen by Netscape as a clear opportunity to entrench Navigator at the heart of the next generation of computing, and thus gain the opportunity to expand into all manner of other software and service markets.
Decline.
With the success of Netscape showing the importance of the web (more people were using the Internet due in part to the ease of using Netscape), Internet browsing began to be seen as a potentially profitable market. Following Netscape's lead, Microsoft started a campaign to enter the web browser software market. Like Netscape before them, Microsoft licensed the Mosaic source code from Spyglass, Inc. (which in turn licensed code from University of Illinois). Using this basic code, Microsoft created Internet Explorer (IE).
The competition between Microsoft and Netscape dominated the Browser Wars. Internet Explorer, Version 1.0 (shipped in the Internet Jumpstart Kit in Microsoft Plus! For Windows 95) and IE, Version 2.0 (the first cross-platform version of the web browser, supporting both Windows and Mac OS) were thought by many to be inferior and primitive when compared to contemporary versions of Netscape Navigator. With the release of IE version 3.0 (1996) Microsoft was able to catch up with Netscape competitively, with IE Version 4.0 (1997) further improving in terms of market share. IE 5.0 (1999) improved stability and took significant market share from Netscape Navigator for the first time.
There were two versions of Netscape Navigator 3.0; the Standard Edition and the Gold Edition. The latter consisted of the Navigator browser with e-mail, news readers, and a WYSIWYG web page compositor; however, these extra functions enlarged and slowed the software, rendering it prone to crashing.
This Gold Edition was renamed Netscape Communicator starting with version 4.0; the name change diluted its name-recognition and confused users. Netscape CEO Jim Barksdale insisted on the name change because Communicator was a general-purpose "client" application, which contained the Navigator "browser".
The aging Netscape Communicator 4.x was slower than Internet Explorer 5.0. Typical web pages had become heavily illustrated, often JavaScript-intensive, and encoded with HTML features designed for specific purposes but now employed as global layout tools (HTML tables, the most obvious example of this, were especially difficult for Communicator to render). The Netscape browser, once a solid product, became crash-prone and buggy; for example, some versions re-downloaded an entire web page to re-render it when the browser window was re-sized (a nuisance to dial-up users), and the browser would usually crash when the page contained simple Cascading Style Sheets. Moreover, Netscape Communicator's browser interface design appeared dated in comparison to Internet Explorer and interface changes in Microsoft and Apple's operating systems.
At decade's end, Netscape's web browser had lost dominance over the Windows platform, and the August 1997 Microsoft financial agreement to invest one hundred and fifty million dollars in Apple required that Apple make Internet Explorer the default web browser in new Mac OS distributions. The latest IE Mac release at that time was Internet Explorer version 3.0 for Macintosh, but Internet Explorer 4 was released later that year.
Microsoft succeeded in having ISPs and PC vendors distribute Internet Explorer to their customers instead of Netscape Navigator, mostly due to Microsoft using its leverage from Windows OEM licenses, and partly aided by Microsoft's investment in making IE brandable, such that a customized version of IE could be offered. Also, web developers used proprietary, browser-specific extensions in web pages. Both Microsoft and Netscape did this, having added many proprietary HTML tags to their browsers, which forced users to choose between two competing and almost incompatible web browsers.
In March 1998, Netscape released most of the development code base for Netscape Communicator under an open source license. Only pre-alpha versions of Netscape 5 were released before the open source community decided to scrap the Netscape Navigator codebase entirely and build a new web browser around the Gecko layout engine which Netscape had been developing but which had not yet incorporated. The community-developed open source project was named "Mozilla", Netscape Navigator's original code name. America Online bought Netscape; Netscape programmers took a pre-beta-quality form of the Mozilla codebase, gave it a new GUI, and released it as Netscape 6. This did nothing to win back users, who continued to migrate to Internet Explorer. After the release of Netscape 7 and a long public beta test, Mozilla 1.0 was released on 5 June 2002. The same code-base, notably the Gecko layout engine, became the basis of independent applications, including Firefox and Thunderbird.
On 28 December 2007, the Netscape developers announced that AOL had canceled development of Netscape Navigator, leaving it unsupported as of 1 March 2008. Despite this, archived and unsupported versions of the browser remain available for download. Firefox would go on to win back market share from Internet Explorer in the next round of the browser wars.
Legacy.
Netscape's contributions to the web include JavaScript, which was submitted as a new standard to Ecma International. The resultant ECMAScript specification allowed JavaScript support by multiple web browsers and its use as a cross-browser scripting language, long after Netscape Navigator itself has dropped in popularity. Another example is the FRAME tag, that is widely supported today, and that has been incorporated into official web standards such as the "HTML 4.01 Frameset" specification.
In a 2007 "PC World" column, the original Netscape Navigator was considered the "best tech product of all time" due to its impact on the Internet.

</doc>
<doc id="21865" url="http://en.wikipedia.org/wiki?curid=21865" title="Neurotransmitter">
Neurotransmitter

Neurotransmitters are endogenous chemicals that transmit signals across a synapse from one neuron (nerve cell) to another "target" neuron. Neurotransmitters are released from synaptic vesicles in synapses into the synaptic cleft, where they are received by receptors on other synapses. Many neurotransmitters are synthesized from plentiful and simple precursors such as amino acids, which are readily available from the diet and only require a small number of biosynthetic steps to convert them. Neurotransmitters play a major role in shaping everyday life and functions. Their exact numbers are unknown but more than 100 chemical messengers have been identified.
Mechanism.
Neurotransmitters are stored in a synapse in synaptic vesicles, clustered beneath the membrane in the axon terminal located at the presynaptic side of the synapse. Neurotransmitters are released into and diffused across the synaptic cleft, where they bind to specific receptors in the membrane on the postsynaptic side of the synapse.
Most neurotransmitters are about the size of a single amino acid, however, some neurotransmitters may be the size of larger proteins or peptides. A released neurotransmitter is typically available in the synaptic cleft for a short time before it is metabolized by enzymes, pulled back into the presynaptic neuron through reuptake, or bound to a postsynaptic receptor. Nevertheless, short-term exposure of the receptor to a neurotransmitter is typically sufficient for causing a postsynaptic response by way of synaptic transmission.
In response to a threshold action potential or graded electrical potential, a neurotransmitter is released at the presynaptic terminal. Low level "baseline" release also occurs without electrical stimulation. The released neurotransmitter may then move across the synapse to be detected by and bind with receptors in the postsynaptic neuron. Binding of neurotransmitters may influence the postsynaptic neuron in either an inhibitory or excitatory way. This neuron may be connected to many more neurons, and if the total of excitatory influences are greater than those of inhibitory influences, the neuron will also "fire". Ultimately it will create a new action potential at its axon hillock to release neurotransmitters and pass on the information to yet another neighboring neuron.
Discovery.
Until the early 20th century, scientists assumed that the majority of synaptic communication in the brain was electrical. However, through the careful histological examinations by Ramón y Cajal (1852–1934), a 20 to 40 nm gap between neurons, known today as the synaptic cleft, was discovered. The presence of such a gap suggested communication via chemical messengers traversing the synaptic cleft, and in 1921 German pharmacologist Otto Loewi (1873–1961) confirmed that neurons can communicate by releasing chemicals. Through a series of experiments involving the vagus nerves of frogs, Loewi was able to manually slow the heart rate of frogs by controlling the amount of saline solution present around the vagus nerve. Upon completion of this experiment, Loewi asserted that sympathetic regulation of cardiac function can be mediated through changes in chemical concentrations. Furthermore, Otto Loewi is credited with discovering acetylcholine (ACh)—the first known neurotransmitter. Some neurons do, however, communicate via electrical synapses through the use of gap junctions, which allow specific ions to pass directly from one cell to another.
Identification.
There are four main criteria for identifying neurotransmitters:
However, given advances in pharmacology, genetics, and chemical neuroanatomy, the term "neurotransmitter" can be applied to chemicals that:
The anatomical localization of neurotransmitters is typically determined using immunocytochemical techniques, which identify either the location of either the transmitter substances themselves, or of the enzymes that are involved in their synthesis. Immunocytochemical techniques have also revealed that many transmitters, particularly the neuropeptides, are co-localized, that is, one neuron may release more than one transmitter from its synaptic terminal. Various techniques and experiments such as staining, stimulating, and collecting can be used to identify neurotransmitters throughout the central nervous system.
Types.
There are many different ways to classify neurotransmitters. Dividing them into amino acids, peptides, and monoamines is sufficient for some classification purposes.
Major neurotransmitters:
In addition, over 50 neuroactive peptides have been found, and new ones are discovered regularly. Many of these are "co-released" along with a small-molecule transmitter. Nevertheless, in some cases a peptide is the primary transmitter at a synapse. β-endorphin is a relatively well known example of a peptide neurotransmitter because it engages in highly specific interactions with opioid receptors in the central nervous system.
Single ions (such as synaptically released zinc) are also considered neurotransmitters by some, as well as some gaseous molecules such as nitric oxide (NO), carbon monoxide (CO), and hydrogen sulfide (H2S). The gases are produced in the neural cytoplasm and are immediately diffused through the cell membrane into the extracellular fluid and into nearby cells to stimulate production of second messengers. Soluble gas neurotransmitters are difficult to study, as they act rapidly and are immediately broken down, existing for only a few seconds.
The most prevalent transmitter is glutamate, which is excitatory at well over 90% of the synapses in the human brain. The next most prevalent is Gamma-Aminobutyric Acid, or GABA, which is inhibitory at more than 90% of the synapses that do not use glutamate. Although other transmitters are used in fewer synapses, they may be very important functionally: the great majority of psychoactive drugs exert their effects by altering the actions of some neurotransmitter systems, often acting through transmitters other than glutamate or GABA. Addictive drugs such as cocaine and amphetamines exert their effects primarily on the dopamine system. The addictive opiate drugs exert their effects primarily as functional analogs of opioid peptides, which, in turn, regulate dopamine levels.
Actions.
Neurons form elaborate networks through which nerve impulses—action potentials—travel. Each neuron has as many as 15,000 connections with neighboring neurons.
Neurons do not touch each other (except in the case of an electrical synapse through a gap junction); instead, neurons interact at contact points called synapses: a junction within two nerve cells, consisting of a miniature gap which impulses pass by a neurotransmitter. A neuron transports its information by way of a nerve impulse called an action potential. When an action potential arrives at the synapse's presynaptic terminal button, it may stimulate the release of neurotransmitters. These neurotransmitters are released into the synaptic cleft to bind onto the receptors of the postsynaptic membrane and influence another cell, either in an inhibitory or excitatory way. The next neuron may be connected to many more neurons, and if the total of excitatory influences is greater than that of inhibitory influences, it will also "fire". That is to say, it will create a new action potential at its axon hillock, releasing neurotransmitters and passing on the information to yet another neighboring neuron.
Excitatory and inhibitory.
A neurotransmitter can influence the function of a neuron through a remarkable number of mechanisms. In its direct actions in influencing a neuron’s electrical excitability, however, a neurotransmitter acts in only one of two ways: excitatory or inhibitory. A neurotransmitter influences trans-membrane ion flow either to increase (excitatory) or to decrease (inhibitory) the probability that the cell with which it comes in contact will produce an action potential. Thus, despite the wide variety of synapses, they all convey messages of only these two types, and they are labeled as such. Type I synapses are excitatory in their actions, whereas type II synapses are inhibitory. Each type has a different appearance and is located on different parts of the neurons under its influence. Each neuron receives thousands of excitatory and inhibitory signals every second.
Type I (excitatory) synapses are typically located on the shafts or the spines of dendrites, whereas type II (inhibitory) synapses are typically located on a cell body. In addition, Type I synapses have round synaptic vesicles, whereas the vesicles of type II synapses are flattened. The material on the presynaptic and post-synaptic membranes is denser in a Type I synapse than it is in a type II, and the type I synaptic cleft is wider. Finally, the active zone on a Type I synapse is larger than that on a Type II synapse.
The different locations of type I and type II synapses divide a neuron into two zones: an excitatory dendritic tree and an inhibitory cell body. From an inhibitory perspective, excitation comes in over the dendrites and spreads to the axon hillock to trigger an action potential. If the message is to be stopped, it is best stopped by applying inhibition on the cell body, close to the axon hillock where the action potential originates. Another way to conceptualize excitatory–inhibitory interaction is to picture excitation overcoming inhibition. If the cell body is normally in an inhibited state, the only way to generate an action potential at the axon hillock is to reduce the cell body’s inhibition. In this “open the gates” strategy, the excitatory message is like a racehorse ready to run down the track, but first the inhibitory starting gate must be removed.
Examples of important neurotransmitter actions.
As explained above, the only direct action of a neurotransmitter is to activate a receptor. Therefore, the effects of a neurotransmitter system depend on the connections of the neurons that use the transmitter, and the chemical properties of the receptors that the transmitter binds to.
Here are a few examples of important neurotransmitter actions:
Brain neurotransmitter systems.
Neurons expressing certain types of neurotransmitters sometimes form distinct systems, where activation of the system affects large volumes of the brain, called volume transmission. Major neurotransmitter systems include the noradrenaline (norepinephrine) system, the dopamine system, the serotonin system, and the cholinergic system, among others. It should be noted that trace amines, primarily via TAAR1 activation, have a very significant impact on neurotransmission in monoamine pathways (i.e., dopamine, histamine, norepinephrine, and serotonin pathways) throughout the brain. A brief comparison of these systems follows:
Drug effects.
Understanding the effects of drugs on neurotransmitters comprises a significant portion of research initiatives in the field of neuroscience. Most neuroscientists involved in this field of research believe that such efforts may further advance our understanding of the circuits responsible for various neurological diseases and disorders, as well as ways to effectively treat and someday possibly prevent or cure such illnesses.
Drugs can influence behavior by altering neurotransmitter activity. For instance, drugs can decrease the rate of synthesis of neurotransmitters by affecting the synthetic enzyme(s) for that neurotransmitter. When neurotransmitter syntheses are blocked, the amount of neurotransmitters available for release becomes substantially lower, resulting in a decrease in neurotransmitter activity. Some drugs block or stimulate the release of specific neurotransmitters. Alternatively, drugs can prevent neurotransmitter storage in synaptic vesicles by causing the synaptic vesicle membranes to leak. Drugs that prevent a neurotransmitter from binding to its receptor are called receptor antagonists. For example, drugs used to treat patients with schizophrenia such as haloperidol, chlorpromazine, and clozapine are antagonists at receptors in the brain for dopamine. Other drugs act by binding to a receptor and mimicking the normal neurotransmitter. Such drugs are called receptor agonists. An example of a receptor agonist is Valium, a benzodiazepine that mimics effects of the endogenous neurotransmitter gamma-aminobutyric acid (GABA) to decrease anxiety. Other drugs interfere with the deactivation of a neurotransmitter after it has been released, thereby prolonging the action of a neurotransmitter. This can be accomplished by blocking re-uptake or inhibiting degradative enzymes. Lastly, drugs can also prevent an action potential from occurring, blocking neuronal activity throughout the central and peripheral nervous system. Drugs such as tetrodotoxin that block neural activity are typically lethal.
Drugs targeting the neurotransmitter of major systems affect the whole system, which can explain the complexity of action of some drugs. Cocaine, for example, blocks the re-uptake of dopamine back into the presynaptic neuron, leaving the neurotransmitter molecules in the synaptic gap for an extended period of time. Since the dopamine remains in the synapse longer, the neurotransmitter continues to bind to the receptors on the postsynaptic neuron, eliciting a pleasurable emotional response. Physical addiction to cocaine may result from prolonged exposure to excess dopamine in the synapses, which leads to the downregulation of some post-synaptic receptors. After the effects of the drug wear off, an individual can become depressed due to decreased probability of the neurotransmitter binding to a receptor. Fluoxetine is a selective serotonin re-uptake inhibitor (SSRI), which blocks re-uptake of serotonin by the presynaptic cell which increases the amount of serotonin present at the synapse and furthermore allows it to remain there longer, providing potential for the effect of naturally released serotonin. AMPT prevents the conversion of tyrosine to L-DOPA, the precursor to dopamine; reserpine prevents dopamine storage within vesicles; and deprenyl inhibits monoamine oxidase (MAO)-B and thus increases dopamine levels.
Agonists.
An agonist is a chemical capable of binding to a receptor, such as a neurotransmitter receptor, and initiating the same reaction typically produced by the binding of the endogenous substance. An agonist of a neurotransmitter will thus initiate the same receptor response as the transmitter. This works when muscles are at relaxation.
There are two different types of Agonist: Direct-binding Agonist and Indirect-acting Agonist:
Drug agonists.
"An agonist is a drug or an endogenous substance that binds to a Receptor (it has affinity for the receptor binding site) and produces a biological response (it possesses intrinsic activity). The binding of a drug agonist to the receptor produces an effect that mimics the physiological response observed when an endogenous substance (e.g., hormone, Neurotransmitter) binds to the same receptor. In many cases, the biological response is directly related to the concentration of the agonist available to bind to the receptor. As more agonist is added, the number of receptors occupied increases, as does the magnitude of the response. The potency (strength) of the agonist for producing the physiological response (how much drug is needed to produce the effect) is related to the strength of binding (the affinity) for the receptor and to its intrinsic activity. Most drugs bind to more than one receptor; they have multiple receptor interactions."
Nicotine, found in tobacco, is an agonist for acetylcholine at nicotinic receptors. Opiate agonists include morphine, heroin, hydrocodone, oxycodone, codeine, and methadone. These drugs activate mu opioid receptors that typically respond to endogenous transmitters such as enkephalins. When these receptors are activated, individuals experience euphoria, pain relief, and drowsiness.
Antagonists.
An antagonist is a chemical that acts within the body to reduce the physiological activity of another chemical substance (as an opiate); especially one that opposes the action on the nervous system of a drug or a substance occurring naturally in the body by combining with and blocking its nervous receptor. This works when the muscles are in the phase of contraction.
There are two main types of Antagonist; Direct-acting Antagonist and Indirect-acting Antagonists:
Drug antagonists.
An antagonist drug is one that attaches (or binds) to a site called a receptor without activating that receptor to produce a biological response. It is therefore said to have no intrinsic activity. An antagonist may also be called a receptor "blocker" because they block the effect of an agonist at the site. The pharmacological effects of an antagonist therefore result in preventing the corresponding receptor site's agonists (e.g., drugs, hormones, neurotransmitters) from binding to and activating it. Antagonists may be "competitive" or "irreversible".
A competitive antagonist competes with an agonist for binding to the receptor. As the concentration of antagonist increases, the binding of the agonist is progressively inhibited, resulting in a decrease in the physiological response. High concentration of an antagonist can completely inhibit the response. This inhibition can be reversed, however, by an increase of the concentration of the agonist, since the agonist and antagonist compete for binding to the receptor. Competitive antagonists, therefore, can be characterized as shifting the dose-response relationship for the agonist to the right. In the presence of a competitive antagonist, it takes an increased concentration of the agonist to produce the same response observed in the absence of the antagonist.
An irreversible antagonist binds so strongly to the receptor as to render the receptor unavailable for binding to the agonist. Irreversible antagonists may even form covalent chemical bonds with the receptor. In either case, if the concentration of the irreversible antagonist is high enough, the number of unbound receptors remaining for agonist binding may be so low that even high concentrations of the agonist do not produce the maximum biological response.
Precursors.
Human biosynthesis pathway for trace amines and catecholamines
 
L-Phenylalanine
L-Tyrosine
L-Dopa
Epinephrine
Phenethylamine
"p"-Tyramine
Dopamine
Norepinephrine
"N"-Methylphenethylamine
"N"-Methyltyramine
"p"-Octopamine
Synephrine
3-Methoxytyramine
AADC
AADC
AADC
PNMT
PNMT
PNMT
PNMT
AAAH
AAAH
COMT
DBH
DBH
 In humans, catecholamines and phenethylaminergic trace amines are derived from the amino acid phenylalanine.
While intake of neurotransmitter precursors does increase neurotransmitter synthesis, evidence is mixed as to whether neurotransmitter release and postsynaptic receptor firing is increased. Even with increased neurotransmitter release, it is unclear whether this will result in a long-term increase in neurotransmitter signal strength, since the nervous system can adapt to changes such as increased neurotransmitter synthesis and may therefore maintain constant firing. Some neurotransmitters may have a role in depression and there is some evidence to suggest that intake of precursors of these neurotransmitters may be useful in the treatment of mild and moderate depression.
Catecholamine and trace amine precursors.
-DOPA, a precursor of dopamine that crosses the blood–brain barrier, is used in the treatment of Parkinson's disease. For depressed patients where low activity of the neurotransmitter norepinephrine is implicated, there is only little evidence for benefit of neurotransmitter precursor administration. L-phenylalanine and L-tyrosine are both precursors for dopamine, norepinephrine, and epinephrine. These conversions require vitamin B6, vitamin C, and S-adenosylmethionine. A few studies suggest potential antidepressant effects of L-phenylalanine and L-tyrosine, but there is much room for further research in this area.
Serotonin precursors.
Administration of L-tryptophan, a precursor for serotonin, is seen to double the production of serotonin in the brain. It is significantly more effective than a placebo in the treatment of mild and moderate depression. This conversion requires vitamin C. 5-hydroxytryptophan (5-HTP), also a precursor for serotonin, is more effective than a placebo.
Diseases and disorders.
Diseases and disorders may also affect specific neurotransmitter systems. For example, problems in producing dopamine can result in Parkinson's disease, a disorder that affects a person's ability to move as they want to, resulting in stiffness, tremors or shaking, and other symptoms. Some studies suggest that having too little dopamine or problems using dopamine in the thinking and feeling regions of the brain may play a role in disorders like schizophrenia or attention deficit hyperactivity disorder (ADHD). Moreover, research shows that people diagnosed with depression often have lower than normal levels of serotonin. The types of medications most commonly prescribed to treat depression act by blocking the recycling, or reuptake, of serotonin by the sending neuron. As a result, more serotonin stays in the synapse for the receiving neuron to bind onto, leading to more normal mood functioning. Furthermore, problems in making or using glutamate have been linked to many mental disorders, including autism, obsessive compulsive disorder (OCD), schizophrenia, and depression.
Elimination of neurotransmitters.
A neurotransmitter must be broken down once it reaches the post-synaptic cell to prevent further excitatory or inhibitory signal transduction. This allows new signals to be produced from the adjacent nerve cells. When the neurotransmitter has been secreted into the synaptic cleft, it binds to specific receptors on the postsynaptic cell, thereby generating a postsynaptic electrical signal. The transmitter must then be removed rapidly to enable the postsynaptic cell to engage in another cycle of neurotransmitter release, binding, and signal generation. Neurotransmitters are terminated in three different ways:
For example, choline is taken up and recycled by the pre-synaptic neuron to synthesize more ACh. Other neurotransmitters such as dopamine are able to diffuse away from their targeted synaptic junctions and are eliminated from the body via the kidneys, or destroyed in the liver. Each neurotransmitter has very specific degradation pathways at regulatory points, which may be targeted by the body's regulatory system or by recreational drugs.
Neurotransmitter imbalance.
Neurotransmitter imbalances have been connected to the cause of many diseases. These include Parkinson's, depression, insomnia, Attention Deficit Hyperactivity Disorder (ADHD), anxiety, memory loss, dramatic changes in weight and addictions. They all involve amino acids which form neurotransmitters. The acids are made up of protein and without a sufficient amount of this then cells are not structured properly; therefore not functioning properly. Chronic stress is the primary contributor to neurotransmitter imbalance. Physical and emotional stress from a job or a relationship causes neurons to use up large amounts of neurotransmitters in order to cope with the ongoing stress. Over time the stress wears out the nervous system and depletes neurotransmitter supply. Genetics play a part in correlating with neurotransmitter imbalance. Some people are already born with neurotransmitter deficiencies or excesses. Scientists are trying to supplement medication by changing the diets of some patients instead; adding amino acids into the body. Medications that directly react with serotonin and norepinephrine are prescribed to patients with diseases such as depression and anxiety disorders.

</doc>
<doc id="21868" url="http://en.wikipedia.org/wiki?curid=21868" title="Neutronium">
Neutronium

Neutronium (sometimes shortened to neutrium) is a proposed name for a substance composed purely of neutrons. The word was coined by scientist Andreas von Antropoff in 1926 (before the discovery of the neutron) for the conjectured "element of atomic number zero" that he placed at the head of the periodic table. However, the meaning of the term has changed over time, and from the last half of the 20th century onward it has been also used legitimately to refer to extremely dense substances resembling the neutron-degenerate matter theorized to exist in the cores of neutron stars; henceforth ""degenerate" neutronium" will refer to this. Science fiction and popular literature frequently use the term "neutronium" to refer to a highly dense phase of matter composed primarily of neutrons.
Neutronium and neutron stars.
Neutronium is used in popular literature to refer to the material present in the cores of neutron stars (stars which are too massive to be supported by electron degeneracy pressure and which collapse into a denser phase of matter). This term is very rarely used in scientific literature, for three reasons:
When neutron star core material is presumed to consist mostly of free neutrons, it is typically referred to as neutron-degenerate matter in scientific literature.
Neutronium and the periodic table.
The term "neutronium" was coined in 1926 by Andreas von Antropoff for a conjectured form of matter made up of neutrons with no protons or electrons, which he placed as the chemical element of atomic number zero at the head of his new version of the periodic table. It was subsequently placed in the middle of several spiral representations of the periodic system for classifying the chemical elements, such as those of Charles Janet (1928), E. I. Emerson (1944), John D. Clark (1950) and in Philip Stewart's Chemical Galaxy (2005).
Although the term is not used in the scientific literature either for a condensed form of matter, or as an element, there have been reports that, besides the free neutron, there may exist two bound forms of neutrons without protons. If neutronium were considered to be an element, then these neutron clusters could be considered to be the isotopes of that element. However, these reports have not been further substantiated.
Although not called "neutronium", the National Nuclear Data Center's "Nuclear Wallet Cards" lists as its first "isotope" an "element" with the symbol n and atomic number "Z" = 0 and mass number "A" = 1. This isotope is described as decaying to element H with a half life of .
Properties.
Due to beta (β−) decay of mononeutron and extreme instability of aforementioned heavier "isotopes", degenerate neutronium is not expected to be stable under ordinary pressures. Free neutrons decay with a half-life of 10 minutes, 11 seconds. A teaspoon of degenerate neutronium gas would have a mass of two billion tonnes, and if moved to standard temperature and pressure, would emit 57 billion joules of β− decay energy in the first half-life (average of 95 MW of power). This energy may be absorbed as the neutronium gas expands. Though, in the presence of atomic matter compressed to the state of electron degeneracy, the β− decay may be inhibited due to Pauli exclusion principle, thus making free neutrons stable. Also, elevated pressures should make neutrons degenerate themselves. Compared to ordinary elements, neutronium should be more compressible due to the absence of electrically charged protons and electrons. This makes neutronium more energetically favorable than (positive-"Z") atomic nuclei and leads to their conversion to (degenerate) neutronium through electron capture, a process which is believed to occur in stellar cores in the final seconds of the lifetime of massive stars, where it is facilitated by cooling via emission. As a result, degenerate neutronium can have a density of , roughly 13 magnitudes denser than the densest known ordinary substances. It was theorized that extreme pressures may deform the neutrons into a cubic symmetry, allowing tighter packing of neutrons, or cause a strange matter formation.
In fiction.
The term "neutronium" has been popular in science fiction since at least the middle of the 20th century. It typically refers to an extremely dense, incredibly strong form of matter. While presumably inspired by the concept of neutron-degenerate matter in the cores of neutron stars, the material used in fiction bears at most only a superficial resemblance, usually depicted as an extremely strong solid under Earth-like conditions, or possessing exotic properties such as the ability to manipulate time and space. In contrast, all proposed forms of neutron star core material are fluids and are extremely unstable at pressures lower than that found in stellar cores. According to one analysis, a neutron star with a mass below about 0.2 solar masses will explode.
Noteworthy appearances of neutronium in fiction include the following:

</doc>
<doc id="21869" url="http://en.wikipedia.org/wiki?curid=21869" title="Neutron star">
Neutron star

A neutron star is a type of stellar remnant that can result from the gravitational collapse of a massive star after a supernova. Neutron stars are the densest and smallest stars known to exist in the universe; with a radius of only about 12–13 km (7 mi), they can have a mass of about two times that of the Sun.
Neutron stars are composed almost entirely of neutrons, which are subatomic particles without net electrical charge and with slightly larger mass than protons. Neutron stars are very hot and are supported against further collapse by quantum degeneracy pressure due to the phenomenon described by the Pauli exclusion principle, which states that no two neutrons (or any other fermionic particles) can occupy the same place and quantum state simultaneously.
A neutron star has a mass of at least 1.1 and perhaps as many as 3 solar masses (M☉), though the highest observed mass is 2.01 M☉ Neutron stars typically have a surface temperature around ~. Neutron stars have overall densities of to ( to times the density of the Sun), which is comparable to the approximate density of an atomic nucleus of .
The neutron star's density varies from below in the crust – increasing with depth – to above or deeper inside (denser than an atomic nucleus). A normal-sized matchbox containing neutron star material would have a mass of approximately 5 billion tonnes or ~1 km3 of Earth rock.
In general, compact stars of less than 1.44 M☉ (the Chandrasekhar limit) are white dwarfs while compact stars weighing between that and 3 M☉ (the Tolman–Oppenheimer–Volkoff limit) should be neutron stars. The maximum observed mass of neutron stars is about 2 M☉. Compact stars with more than 10 M☉ will overcome the neutron degeneracy pressure and gravitational collapse will usually occur to produce a black hole. The smallest observed mass of a black hole is about 5 M☉. Between these, hypothetical intermediate-mass stars such as quark stars and electroweak stars have been proposed, but none have been shown to exist. The equations of state of matter at such high densities are not precisely known because of the theoretical and empirical difficulties.
Some neutron stars rotate very rapidly (up to 716 times a second, or approximately 43,000 revolutions per minute) and emit beams of electromagnetic radiation as pulsars. Indeed, the discovery of pulsars in 1967 first suggested that neutron stars exist.
Gamma-ray bursts may be produced from rapidly rotating, high-mass stars that collapse to form a neutron star, or from the merger of binary neutron stars. There are thought to be on the order of 108 neutron stars in the galaxy, but they can only be easily detected in certain instances, such as if they are a pulsar or part of a binary system. Non-rotating and non-accreting neutron stars are virtually undetectable; however, the Hubble Space Telescope has observed one thermally radiating neutron star, called RX J185635-3754.
Formation.
Any main sequence star with an initial mass of around 10 M☉ or above has the potential to become a neutron star. As the star evolves away from the main sequence, subsequent nuclear burning produces an iron-rich core. When all nuclear fuel in the core has been exhausted, the core must be supported by degeneracy pressure alone. Further deposits of material from shell burning cause the core to exceed the Chandrasekhar limit. Electron degeneracy pressure is overcome and the core collapses further, sending temperatures soaring to over . At these temperatures, photodisintegration (the breaking up of iron nuclei into alpha particles by high- energy gamma rays) occurs. As the temperature climbs even higher, electrons and protons combine to form neutrons, releasing a flood of neutrinos. When densities reach nuclear density of , neutron degeneracy pressure halts the contraction. The infalling outer atmosphere of the star is flung outwards, becoming a Type II or Type Ib supernova. The remnant left is a neutron star. If it has a mass greater than about 5 M☉, it collapses further to become a black hole. Other neutron stars are formed within close binaries.
As the core of a massive star is compressed during a Type II, Type Ib or Type Ic supernova, and collapses into a neutron star, it retains most of its angular momentum. Since it has only a tiny fraction of its parent's radius (and therefore its moment of inertia is sharply reduced), a neutron star is formed with very high rotation speed, and then gradually slows down. Neutron stars are known that have rotation periods from about 1.4 ms to 30 s. The neutron star's density also gives it very high surface gravity, with typical values ranging from 1012 to 1013 m/s2 (more than 1011 times of that of Earth). One measure of such immense gravity is the fact that neutron stars have an escape velocity ranging from 100,000 km/s to 150,000 km/s, that is, from a third to half the speed of light. Matter falling onto the surface of a neutron star would be accelerated to tremendous speed by the star's gravity. The force of impact would likely destroy the object's component atoms, rendering all its matter identical, in most respects, to the rest of the star.
Properties.
The gravitational field at the star's surface is about 2×1011 times stronger than on Earth. Such a strong gravitational field acts as a gravitational lens and bends the radiation emitted by the star such that parts of the normally invisible rear surface become visible.
If the radius of the neutron star is formula_1 or less, then the photons may be trapped in an orbit, thus making the whole surface of that neutron star visible, along with destabilizing orbits at that and less than that of the radius.
A fraction of the mass of a star that collapses to form a neutron star is released in the supernova explosion from which it forms (from the law of mass-energy equivalence, ). The energy comes from the gravitational binding energy of a neutron star.
Neutron star relativistic equations of state provided by Jim Lattimer include a graph of radius vs. mass for various models. The most likely radii for a given neutron star mass are bracketed by models AP4 (smallest radius) and MS2 (largest radius). BE is the ratio of gravitational binding energy mass equivalent to observed neutron star gravitational mass of "M" kilograms with radius "R" meters,
Given current values
and star masses "M" commonly reported as multiples of one solar mass,
then the relativistic fractional binding energy of a neutron star is
A 2 M☉ neutron star would not be more compact than 10,970 meters radius (AP4 model). Its mass fraction gravitational binding energy would then be 0.187, −18.7% (exothermic). This is not near 0.6/2 = 0.3, −30%.
A neutron star is so dense that one teaspoon (5 milliliters) of its material would have a mass over (that is 1100 tonnes per 1 nanolitre), about 900 times the mass of the Great Pyramid of Giza. Hence, the gravitational force of a typical neutron star is such that if an object were to fall from a height of one meter, it would only take one microsecond to hit the surface of the neutron star, and would do so at around 2000 kilometers per second, or 7.2 million kilometers per hour.
The temperature inside a newly formed neutron star is from around 1011 to 1012 kelvin. However, the huge number of neutrinos it emits carry away so much energy that the temperature falls within a few years to around 106 kelvin. Even at 1 million kelvin, most of the light generated by a neutron star is in X-rays.
The pressure increases from 3×1033 to 1.6×1035 Pa from the inner crust to the center.
The equation of state for a neutron star is still not known. It is assumed that it differs significantly from that of a white dwarf, whose EOS is that of a degenerate gas which can be described in close agreement with special relativity. However, with a neutron star the increased effects of general relativity can no longer be ignored. Several EOS have been proposed (FPS, UU, APR, L, SLy, and others) and current research is still attempting to constrain the theories to make predictions of neutron star matter. This means that the relation between density and mass is not fully known, and this causes uncertainties in radius estimates. For example, a 1.5 M☉ neutron star could have a radius of 10.7, 11.1, 12.1 or 15.1 kilometres (for EOS FPS, UU, APR or L respectively).
Structure.
Current understanding of the structure of neutron stars is defined by existing mathematical models, but it might be possible to infer through studies of neutron-star oscillations. Similar to asteroseismology for ordinary stars, the inner structure might be derived by analyzing observed frequency spectra of stellar oscillations.
On the basis of current models, the matter at the surface of a neutron star is composed of ordinary atomic nuclei crushed into a solid lattice with a sea of electrons flowing through the gaps between them. It is possible that the nuclei at the surface are iron, due to iron's high binding energy per nucleon. It is also possible that heavy element cores, such as iron, simply sink beneath the surface, leaving only light nuclei like helium and hydrogen cores. If the surface temperature exceeds 106 kelvin (as in the case of a young pulsar), the surface should be fluid instead of the solid phase observed in cooler neutron stars (temperature <106 kelvin).
The "atmosphere" of the star is hypothesized to be at most several micrometers thick, and its dynamic is fully controlled by the star's magnetic field. Below the atmosphere one encounters a solid "crust". This crust is extremely hard and very smooth (with maximum surface irregularities of ~5 mm), because of the extreme gravitational field. The expected hierarchy of phases of nuclear matter in the inner crust has been characterized as nuclear pasta.
Proceeding inward, one encounters nuclei with ever increasing numbers of neutrons; such nuclei would decay quickly on Earth, but are kept stable by tremendous pressures. As this process continues at increasing depths, neutron drip becomes overwhelming, and the concentration of free neutrons increases rapidly. In this region, there are nuclei, free electrons, and free neutrons. The nuclei become increasingly small (gravity and pressure overwhelming the strong force) until the core is reached, by definition the point where they disappear altogether.
The composition of the superdense matter in the core remains uncertain. One model describes the core as superfluid neutron-degenerate matter (mostly neutrons, with some protons and electrons). More exotic forms of matter are possible, including degenerate strange matter (containing strange quarks in addition to up and down quarks), matter containing high-energy pions and kaons in addition to neutrons, or ultra-dense quark-degenerate matter.
History of discoveries.
In 1934, Walter Baade and Fritz Zwicky proposed the existence of the neutron star, only a year after the discovery of the neutron by Sir James Chadwick. In seeking an explanation for the origin of a supernova, they tentatively proposed that in supernova explosions ordinary stars are turned into stars that consist of extremely closely packed neutrons that they called neutron stars. Baade and Zwicky correctly proposed at that time that the release of the gravitational binding energy of the neutron stars powers the supernova: "In the supernova process, mass in bulk is annihilated". Neutron stars were thought to be too faint to be detectable and little work was done on them until November 1967, when Franco Pacini (1939–2012) pointed out that if the neutron stars were spinning and had large magnetic fields, then electromagnetic waves would be emitted. Unbeknown to him, radio astronomer Antony Hewish and his research assistant Jocelyn Bell at Cambridge were shortly to detect radio pulses from stars that are now believed to be highly magnetized, rapidly spinning neutron stars, known as pulsars.
In 1965, Antony Hewish and Samuel Okoye discovered "an unusual source of high radio brightness temperature in the Crab Nebula". This source turned out to be the Crab Pulsar that resulted from the great supernova of 1054.
In 1967, Iosif Shklovsky examined the X-ray and optical observations of Scorpius X-1 and correctly concluded that the radiation comes from a neutron star at the stage of accretion.
In 1967, Jocelyn Bell and Antony Hewish discovered regular radio pulses from CP 1919. This pulsar was later interpreted as an isolated, rotating neutron star. The energy source of the pulsar is the rotational energy of the neutron star. The majority of known neutron stars (about 2000, as of 2010) have been discovered as pulsars, emitting regular radio pulses.
In 1971, Riccardo Giacconi, Herbert Gursky, Ed Kellogg, R. Levinson, E. Schreier, and H. Tananbaum discovered 4.8 second pulsations in an X-ray source in the constellation Centaurus, Cen X-3. They interpreted this as resulting from a rotating hot neutron star. The energy source is gravitational and results from a rain of gas falling onto the surface of the neutron star from a companion star or the interstellar medium.
In 1974, Antony Hewish was awarded the Nobel Prize in Physics "for his decisive role in the discovery of pulsars" without Jocelyn Bell who shared in the discovery.
In 1974, Joseph Taylor and Russell Hulse discovered the first binary pulsar, PSR B1913+16, which consists of two neutron stars (one seen as a pulsar) orbiting around their center of mass. Einstein's general theory of relativity predicts that massive objects in short binary orbits should emit gravitational waves, and thus that their orbit should decay with time. This was indeed observed, precisely as general relativity predicts, and in 1993, Taylor and Hulse were awarded the Nobel Prize in Physics for this discovery.
In 1982, Don Backer and colleagues discovered the first millisecond pulsar, PSR B1937+21. This objects spins 642 times per second, a value that placed fundamental constraints on the mass and radius of neutron stars. Many millisecond pulsars were later discovered, but PSR B1937+12 remained the fastest-spinning known pulsar for 24 years, until PSR J1748-2446ad was discovered.
In 2003, Marta Burgay and colleagues discovered the first double neutron star system where both components are detectable as pulsars, PSR J0737-3039. The discovery of this system allows a total of 5 different tests of general relativity, some of these with unprecedented precision.
In 2010, Paul Demorest and colleagues measured the mass of the millisecond pulsar PSR J1614–2230 to be 1.97±0.04 M☉, using Shapiro delay. This was substantially higher than any previously measured neutron star mass (1.67 M☉, see PSR J1903+0327), and places strong constraints on the interior composition of neutron stars.
In 2013, John Antoniadis and colleagues measured the mass of PSR J0348+0432 to be 2.01±0.04 M☉, using white dwarf spectroscopy. This confirmed the existence of such massive stars using a different method. Furthermore, this allowed, for the first time, a test of general relativity using such
a massive neutron star.
Rotation.
Neutron stars rotate extremely rapidly after their creation due to the conservation of angular momentum; like spinning ice skaters pulling in their arms, the slow rotation of the original star's core speeds up as it shrinks. A newborn neutron star can rotate several times a second; sometimes, the neutron star absorbs orbiting matter from a companion star, increasing the rotation to several hundred times per second, reshaping the neutron star into an oblate spheroid.
Over time, neutron stars slow down (spin down) because their rotating magnetic fields radiate energy; older neutron stars may take several seconds for each revolution.
The rate at which a neutron star slows its rotation is usually constant and very small: the observed rates of decline are between 10−10 and 10−21 seconds for each rotation. Therefore, for a typical slow down rate of 10−15 seconds per rotation, a neutron star now rotating in 1 second will rotate in 1.000003 seconds after a century, or 1.03 seconds after 1 million years.
Sometimes a neutron star will "spin up" or undergo a "glitch", a sudden small increase of its rotation speed. Glitches are thought to be the effect of a starquake — as the rotation of the star slows down, the shape becomes more spherical. Due to the stiffness of the "neutron" crust, this happens as discrete events when the crust ruptures, similar to tectonic earthquakes. After the starquake, the star will have a smaller equatorial radius, and since angular momentum is conserved, rotational speed increases. Recent work, however, suggests that a starquake would not release sufficient energy for a neutron star glitch; it has been suggested that glitches may instead be caused by transitions of vortices in the superfluid core of the star from one metastable energy state to a lower one.
Neutron stars have been observed to "pulse" radio and x-ray emissions believed to be caused by particle acceleration near the magnetic poles, which need not be aligned with the rotation axis of the star. Through mechanisms not yet entirely understood, these particles produce coherent beams of radio emission. External viewers see these beams as pulses of radiation whenever the magnetic pole sweeps past the line of sight. The pulses come at the same rate as the rotation of the neutron star, and thus, appear periodic. Neutron stars which emit such pulses are called pulsars.
The most rapidly rotating neutron star currently known, PSR J1748-2446ad, rotates at 716 rotations per second. A recent paper reported the detection of an X-ray burst oscillation (an indirect measure of spin) at 1122 Hz from the neutron star XTE J1739-285. However, at present, this signal has only been seen once, and should be regarded as tentative until confirmed in another burst from this star.
Population and distances.
At present, there are about 2000 known neutron stars in the Milky Way and the Magellanic Clouds, the majority of which have been detected as radio pulsars. Neutron stars are mostly concentrated along the disk of the Milky Way although the spread perpendicular to the disk is large because the supernova explosion process can impart high speeds (400 km/s) to the newly created neutron star.
Some of the closest neutron stars are RX J1856.5-3754 about 400 light years away and PSR J0108-1431 at about 424 light years. RX J1856.5-3754 is a member of a close group of neutron stars called The Magnificent Seven. Another nearby neutron star that was detected transiting the backdrop of the constellation Ursa Minor has been nicknamed Calvera by its Canadian and American discoverers, after the villain in the 1960 film "The Magnificent Seven". This rapidly moving object was discovered using the ROSAT/Bright Source Catalog.
Binary neutron stars.
About 5% of all known neutron stars are members of a binary system. The formation and evolution scenario of binary neutron stars is a rather exotic and complicated process. The companion stars may be either ordinary stars, white dwarfs or other neutron stars. According to modern theories of binary evolution it is expected that neutron stars also exist in binary systems with black hole companions. Such binaries are expected to be prime sources for emitting gravitational waves. Neutron stars in binary systems often emit X-rays which is caused by the heating of material (gas) accreted from the companion star. Material from the outer layers of a (bloated) companion star is sucked towards the neutron star as a result of its very strong gravitational field. As a result of this process binary neutron stars may also coalesce into black holes if the accretion of mass takes place under extreme conditions. It has been proposed that coalescence of binaries consisting of two neutron stars may be responsible for producing short gamma-ray bursts. Such events may also be responsible for creating all chemical elements beyond iron, as opposed to the supernova nucleosynthesis theory.
Giant nucleus.
A neutron star has some of the properties of an atomic nucleus, including density (within an order of magnitude) and being composed of nucleons. In popular scientific writing, neutron stars are therefore sometimes described as giant nuclei. However, in other respects, neutron stars and atomic nuclei are quite different. In particular, a nucleus is held together by the strong interaction, whereas a neutron star is held together by gravity, and thus the density and structure of neutron stars is more variable. It is generally more useful to consider such objects as stars.
References.
</dl>

</doc>
<doc id="21871" url="http://en.wikipedia.org/wiki?curid=21871" title="Nassau, Bahamas">
Nassau, Bahamas

 
Nassau is the capital, largest city, and commercial centre of the Commonwealth of the Bahamas. The city has a population of 248,948 (2010 census), 70 percent of the entire population of the Bahamas (353,658). Lynden Pindling International Airport, the major airport for the Bahamas, is located about 16 km west of Nassau city centre, and has daily flights to major cities in the United States, the Caribbean, Canada, and the United Kingdom. The city is located on the island of New Providence, which functions much like a business district. Nassau is the site of the House of Assembly and various judicial departments and was considered historically to be a stronghold of pirates. The city is ultimately named for the German town Nassau.
Nassau's modern growth began in the late eighteenth century, with the influx of thousands of American Loyalists and their slaves to the Bahamas following the American Revolutionary War. Many of them settled in Nassau (then and still the commerce capital of the Bahamas) and eventually came to outnumber the original inhabitants.
As the population of Nassau grew, so did its populated areas. Today the city dominates the entire island and its satellite, Paradise Island. However, until the post-Second World War era, the outer suburbs scarcely existed. Most of New Providence was uncultivated bush until Loyalists were resettled there following the American Revolutionary War; they established several plantations, such as Clifton and Tusculum. Slaves were imported as labour.
After the British abolished the international slave trade in 1807, they resettled thousands of Africans liberated from slave ships by the Royal Navy on New Providence (at Adelaide Village and Gambier Village), along with other islands such as Grand Bahama, Exuma, Abaco and Inagua. In addition, slaves freed from American ships, such as the Creole case in 1841, were allowed to settle here. The largest concentration of Africans historically lived in the "Over-the-Hill" suburbs of Grants Town and Bain Town to the south of the city of Nassau, while most of the inhabitants of European descent lived on the island's northern coastal ridges.
History.
Nassau was formerly known as Charles Town; it was burned to the ground by the Spanish in 1684. Rebuilt, it was renamed Nassau in 1695 under Governor Nicholas Trott in honour of the Dutch Stadtholder ("stadhouder" in Dutch) and later also King of England, Scotland and Ireland, William III from the Dutch House of Orange-Nassau. The name Nassau derives from the House of Nassau and ultimately from the town of Nassau, Rhineland-Palatinate in Germany. Due to a lack of effective Governors (after Trott), Nassau fell on hard times. In 1703 Spanish and French allied forces briefly occupied Nassau.
From 1703 to 1718 there was no governor in the colony and by 1713, the sparsely settled Bahamas had become a pirate haven. The Governor of Bermuda stated that there were over 1,000 pirates in Nassau and that they outnumbered the mere hundred inhabitants of the town. They proclaimed Nassau a pirate republic, establishing themselves as "governors." Examples of pirates that used Nassau as their base are Charles Vane, Thomas Barrow, Benjamin Hornigold, Calico Jack Rackham, Anne Bonny, Mary Read, and the infamous Edward Teach, known as "Blackbeard".
In 1718, the British sought to regain control of the islands and appointed Captain Woodes Rogers as Royal governor. He successfully clamped down on the pirates, reformed the civil administration, and restored commerce. Rogers cleaned up Nassau and rebuilt the fort, using his own wealth to try to overcome problems. In 1720 the Spanish made an unsuccessful attempt to capture Nassau.
During the wars in the Thirteen Colonies, Nassau experienced an economic boom. With funds from privateering, a new fort, street lights and over 2300 sumptuous houses were built and Nassau was extended. In addition to this, mosquito breeding swamps were filled.
In 1776 the Battle of Nassau resulted in a brief occupation by American Continental Marines during the American War of Independence, where the Marines staged their first amphibious raid on Fort Montague after attempting to sneak up on Fort Nassau. In 1778 after an overnight invasion, American raiders led by Captain Rathburn, left with ships, gunpowder and military stores after stopping in Nassau for only two days. In 1782 Spain captured Nassau for the last time when Don Juan de Cagigal, governor-general of Cuba, attacked New Providence with 5000 men. Andrew Deveaux, an American Loyalist who resettled on the island, set forth to recapture Nassau with 220 men and 150 muskets to face a force of 600 trained soldiers. Deveaux forced the Spanish to surrender on April 17, 1783, without a single shot fired.
Lord Dunmore governed the colony from 1787 to 1796. He oversaw the construction of Fort Charlotte and Fort Fincastle in Nassau.
During the American Civil War, Nassau served as a port for blockade runners making their way to and from ports along the southern Atlantic Coast for continued trade with the Confederacy.
In the 1920s and 1930s Nassau profited from Prohibition.
Geography.
Located on New Providence Island, Nassau has an attractive harbour, a colourful blend of old world and colonial architecture, and a busy port. The tropical climate and natural beauty of the Bahamas have made Nassau a popular tourist destination.
Nassau developed directly behind the port area. New Providence provides 200 km² of relatively flat and low-lying land intersected by low ridges (none of which restricted settlement). In the centre of the island there are several shallow lakes that are tidally connected.
The city's proximity to the United States (290 km east-southeast of Miami, Florida) has contributed to its popularity as a holiday resort, especially after the United States imposed a ban on travel to Cuba in 1963. The Atlantis resort on nearby Paradise Island accounts for more tourist arrivals to the city than any other hotel property. The mega-resort employs over 6,000 Bahamians, and is the largest employer outside government.
Climate.
Nassau features a tropical monsoon climate with relatively consistent temperatures throughout the course of the year. Summertime temperatures reach about 32 degrees Celsius (90 degrees Fahrenheit) and the winter months have daytime temperatures between 23 and, rarely falling below 15 °C.
Urban development.
During the 19th century, Nassau became urbanized, attracting rural residents. Growth since the 1950s has been outwards from the town. The 1788 heart of Nassau was just a few blocks of buildings between Government House and the harbour, but the town gradually expanded east to Malcolm's Park, south to Wulff Road, and west to Nassau Street. Grants Town and Bain Town south of the city became the main residential areas for blacks, and until about 30 years ago was the most populous part of the city.
Most whites built houses along the shore, east as far as Fort Montagu, west as far as Saunders Beach, and along the ridge edging the city. During the 20th century, the city spread east to Village Road and west to Fort Charlotte and Oakes Field. This semicircle of residential development was the main area of settlement until after the Second World War, and marks a distinct phase in the city's expansion, the outer boundary to this zone being the effective limit of the continuous built-up area. The wealthier residents continued to spread east (to East End Point) and West (to Lyford Cay).
In the last 40 years, residential development has been quite different. It has consisted mainly of planned middle-income sub-divisions. Since the 1960s, government has sponsored low-cost housing developments at Yellow Elder, Elizabeth Estates, and Pinewood Gardens, in the outer ring.
Downtown.
Downtown is the hub for all activities in Nassau. Thousands of people visit daily, to shop, dine, sightsee and to enjoy the tropical climate of the city. While the busiest part of Downtown is the Bay Street thoroughfare and the Woodes Rogers Walk, located across the street from the port and parallel to Bay, the area extends for several blocks in each direction. It starts at West Bay, around the Junkanoo Beach area. A few hotels and restaurants are located on West Bay.
The next landmark is the British Colonial Hotel, which marks the beginning of Bay Street proper. Pirates of Nassau Museum is just across from the British Colonial Hilton. The next few blocks of Bay Street are wall-to-wall boutiques, with a few restaurants and clubs interspersed throughout the retailers.
Famous historical landmarks are also in the vicinity, including Vendue House, Christ Church Cathedral, and the Nassau Public Library. Although the tourist part of Downtown peters out after about seven blocks, smaller, more local stores are found all the way down Bay Street. At this point, Bay Street becomes East Bay.
The new Straw Market is also a very busy place on a regular day. After the fire in 2001 it has been rebuilt to a new, more modern look. It consists of four sections that lead to Nassau Harbour in the back. Also in that area are many jewelry shops and bars. A next soon to be tourist hub is Pompey Square.
Cable Beach.
Cable Beach is recognised as the hotel district of Nassau. Five enormous hotels—two of which are all-inclusive—are located on this strip. The area is also known for its dining, the Crystal Palace Casino, and the golden sands of Cable Beach. Most of the area's restaurants are located either in the hotels or across the street. There is little to no nightlife. There is a bit of shopping, most of it located in the Wyndham. The commercial future of Cable Beach is being re-imagined with the development of Baha Mar, a resort and casino project that will bring more than 2,000 hotel rooms and the largest gaming and convention facility in the Caribbean to this section of New Providence Island in spring of 2015 (estimated opening date).
Demographics.
Nassau has a population of 126,500 females and 121,800 males and is home to 59,707 households with an average family size of 4.15 according to the 2000 census. Nassau's large population (at least in relation to the remainder of the Bahamas) is the result of waves of immigration from the Family Islands to the capital. Consequently this has led to the decline in the population of the lesser developed islands and the rapid growth of Nassau.
Transport.
Air.
Lynden Pindling International Airport (formerly Nassau International Airport) is located 16 km from Nassau.
New Providence Airport on Paradise Island was closed in 1999 with runway removed and integrated into the resort on the island.
Water.
Ferrys provide water travel around Nassau to the surrounding islands. Prince George Wharf is the main port in the city that serves cruise ships with ports of call in Nassau.
Roads.
Public jitney buses and taxis provide transport in and around Nassau. Rental cars are also available in the city and at the airport.
Major roads in Nassau include:
There are no controlled access highways in Nassau. Both Tonique Williams Darling Highway and Sir Milo Butler Highway are major roadways.
Vehicles in Nassau drive on the left side like in Britain, but many vehicles are imported from the United States with left hand steering wheel.
Culture.
Junkanoo.
The city's chief festival is Junkanoo, an energetic, colourful street parade of brightly costumed people dancing to the rhythmic accompaniment of cowbells, drums and whistles. The word 'Junkanoo' is named after the founder 'John Kanoo'. The celebration occurs on December 26 and January 1, beginning in the early hours of the morning (1:00 a.m.) and ending around 10 a.m.
In popular culture.
Nassau has featured as an important location in several movies, including the Beatles film "Help!" and the James Bond films "Thunderball", (1965) and "Never Say Never Again", (a remake of "Thunderball") (1983) and also for part of the action in "Casino Royale" (2006). In 1981, it was used as a location for the ocean scene (in the film portrayed as being in Greece) in "For Your Eyes Only."
Nassau is featured in the novel "Tobin in Paradise" by Stanley Morgan. The story is centred around the visit by the main character, Russ Tobin, to Nassau and Paradise Island, and the comedic events that ensue.
Several other late 20th and 21st century movies have been set here, including "After the Sunset", "Into the Blue" (2005), and "Flipper" (1996).
The capital hosted the games of the 2004 World's Strongest Man contest. Atlantis Paradise Island was the venue for the 2009 Miss Universe pageant.
Nassau is an unlockable level in the 2010 Gameloft racing game ".
In ", the character Elizabeth Swann says that Captain Jack Sparrow once "sacked Nassau Port without firing a shot".
The city is featured in the 2013 video game "" as a pirate haven, housing the main protagonists. Historical pirates are encountered there such as Benjamin Hornigold, Edward Teach/Blackbeard, Charles Vane, "Calico" Jack Rackham, Anne Bonney, and Mary Read.
It is the setting for much of the shoreside activity on the Starz pirate-themed television series "Black Sails".
Sister cities.
Nassau has six sister cities worldwide:

</doc>
<doc id="21873" url="http://en.wikipedia.org/wiki?curid=21873" title="Nastassja Kinski">
Nastassja Kinski

Nastassja Aglaia Kinski (born 24 January 1961) is a German actress and former model who has appeared in more than sixty films in Europe and the United States. She enjoyed her worldwide breakthrough with "Stay As You Are" (1978), then came to global prominence with her Golden Globe Award-winning performance as the title character in the Roman Polanski-directed film "Tess" (1979). Other notable films in which she acted include the erotic horror "Cat People" (1982), two Wim Wenders dramas "Paris, Texas" (1984) and "Faraway, So Close!" (1993), and "An American Rhapsody" (2001). She is the daughter of the actor Klaus Kinski.
Early life.
Born in Berlin as Nastassja Aglaia Nakszynski, Kinski is the daughter of the German actor Klaus Kinski and his wife, actress Ruth Brigitte Tocki. She is of part Polish descent. Kinski has two half-siblings; Pola and Nikolai Kinski. Her parents divorced in 1968. After the age of ten, Kinski rarely saw her father. Her mother struggled financially to support them. They eventually lived in a commune in Munich.
In a 1999 interview, Kinski denied that her father had sexually molested her as a child, but said he had abused her "in other ways." In 2013, when interviewed about the allegations of sexual abuse made by her half-sister Pola Kinski, she confirmed that he tried with her, but did not succeed. She said:
"He was no father. 99 percent of the time I was terrified of him. He was so unpredictable that the family lived in constant terror." When asked what she would say to him now, if she had the chance, she replied: "I would do anything to put him behind bars for life. I am glad he is no longer alive."
Career.
Kinski began working as a model as a teenager in Germany. Actress Lisa Kreuzer of the German New Wave helped get her the role of the dumb "Mignon" in Wim Wenders film "The Wrong Move". In 1976, while still a teenager, Kinski had her first two major roles: in Wolfgang Petersen's feature-film length episode "Reifezeugnis" of the German TV crime series "Tatort." Next she appeared in the British horror film "To the Devil a Daughter" (1976), produced by Hammer Film Productions. In regards to her early films, Kinski has stated that she felt exploited by the industry. In an interview with "W" magazine she said, "If I had had somebody to protect me or if I had felt more secure about myself, I would not have accepted certain things. Nudity things. And inside it was just tearing me apart."
In 1978, Kinski starred in the Italian romance "Stay As You Are" ("Cosi come sei") with Marcello Mastroianni, gaining her recognition in the United States after New Line Cinema released it there in December 1979. "Time" magazine wrote that she was "simply ravishing, genuinely sexy and high-spirited without being painfully aggressive about it." The film also received a major international release from Columbia Pictures.
Director Roman Polanski urged Kinski to study acting with Lee Strasberg in the United States and cast her as the female lead in his film, "Tess" (1979). The film was nominated for six awards, including Best Picture, at the 53rd Academy Awards and won three.
In 1981, Richard Avedon photographed Kinski with a Burmese python coiled around her nude body. The image was released as a poster and became a best-seller, further confirming her status as a sex symbol.
In 1982, she starred in Francis Ford Coppola's romantic musical "One from the Heart," her first film made in the United States. "Texas Monthly" described her as acting "as a Felliniesque circus performer to represent the twinkling evanescence of Eros." The film failed at the box office and was a major loss for Coppola's new Zoetrope Studios. That year, she was also in the erotic horror movie "Cat People". Dudley Moore's comedy "Unfaithfully Yours" and an adaptation of John Irving's "The Hotel New Hampshire" followed in 1984.
Kinski reteamed with Wenders for the 1984 film "Paris, Texas". One of her most acclaimed films to date, it won the top award at the Cannes Film Festival. Throughout the 1980s, Kinski split her time between Europe and the United States, making "Moon in the Gutter" (1983), "Harem" (1985) and "Torrents of Spring" (1989) in Europe, and "Exposed" (1983), "Maria's Lovers" (1984) and "Revolution" (1985) in the United States.
During the 1990s, Kinski appeared in a number of American films including the action movie "Terminal Velocity", opposite Charlie Sheen; the Mike Figgis 1997 adultery tale "One Night Stand"; "Your Friends & Neighbors" (1998); John Landis' "Susan's Plan" (1998); and "The Lost Son" (1999).
Her most recent films include David Lynch's "Inland Empire" (2006) and Rotimi Rainwater's "Sugar" (2013).
Personal life.
In 2001, Kinski revealed that she suffered from narcolepsy in an interview for the "The Daily Telegraph".
Relationships.
In 1976, when Kinski was 15, she reportedly began a romantic relationship with then 43-year-old director Roman Polanski. In a 1999 interview, she said, "There was categorically no affair... There was a flirtation. There could have been a seduction, but there was not. He had respect for me."
Marriage and children.
In the mid-1980s Kinski met the Egyptian filmmaker Ibrahim Moussa. They married on 10 September 1984. They have two children together; a son Aljosha (born 1984), and daughter Sonja Kinski (born 1986), who works as a model and actress. The marriage was dissolved in 1992.
From 1992 until 1995 Kinski lived with musician Quincy Jones, though she kept her own apartment on Hilgard Avenue, near UCLA, at the time. In 1993 they had a daughter, Kenya Julia Miambi Sarah Jones.

</doc>
<doc id="21875" url="http://en.wikipedia.org/wiki?curid=21875" title="Nuremberg trials">
Nuremberg trials

The Nuremberg trials were a series of military tribunals, held by the Allied forces after World War II, most notable for the prosecution of prominent members of the political, military, and economic leadership of Nazi Germany. The trials were held in the city of Nuremberg, Germany.
The first, and best known of these trials, described as "the greatest trial in history" by Norman Birkett, one of the British judges who presided over it, was the trial of the major war criminals before the International Military Tribunal (IMT). Held between 20 November 1945 and 1 October 1946, the Tribunal was given the task of trying 23 of the most important political and military leaders of the Third Reich, though one of the defendants, Martin Bormann, was tried "in absentia", while another, Robert Ley, committed suicide within a week of the trial's commencement. Not included were Adolf Hitler, Heinrich Himmler, and Joseph Goebbels, all of whom had committed suicide several months before the indictment was signed. The second set of trials of lesser war criminals was conducted under Control Council Law No. 10 at the U.S. Nuremberg Military Tribunals (NMT); among these included the Doctors' Trial and the Judges' Trial. This article primarily deals with the IMT; see Subsequent Nuremberg Trials for details on those trials.
Origin.
 There were, I suppose, three possible courses: to let the atrocities which had been committed go unpunished; to put the perpetrators to death or punish them by executive action; or to try them. Which was it to be? Was it possible to let such atrocities go unpunished? Could France, could Russia, could Holland, Belgium, Norway, Czechoslovakia, Poland or Yugoslavia be expected to consent to such a course? ... It will be remembered that after the first world war alleged criminals were handed over to be tried by Germany, and what a farce that was! The majority got off and such sentences as were inflicted were derisory and were soon remitted.
 —Geoffrey Lawrence<br>5 December 1946
A precedent for trying those accused of war crimes had been set at the end of World War I in the Leipzig War Crimes Trials held in May to July 1921 before the "Reichsgericht" (German Supreme Court) in Leipzig, although these had been on a very limited scale and largely regarded as ineffectual. At the beginning of 1940, the Polish government-in-exile asked the British and French governments to condemn the German invasion of their country. The British initially declined to do so; however, in April 1940, a joint British-French-Polish declaration was issued. Relatively bland because of Anglo-French reservations, it proclaimed the trio's "desire to make a formal and public protest to the conscience of the world against the action of the German government whom they must hold responsible for these crimes which cannot remain unpunished."
Three-and-a-half years later, the stated intention to punish the Germans was much more trenchant. On 1 November 1943, the Soviet Union, the United Kingdom and the United States published their "Declaration on German Atrocities in Occupied Europe", which gave a "full warning" that, when the Nazis were defeated, the Allies would "pursue them to the uttermost ends of the earth ... in order that justice may be done. ... The above declaration is without prejudice to the case of the major war criminals whose offences have no particular geographical location and who will be punished by a joint decision of the Government of the Allies." This Allied intention to dispense justice was reiterated at the Yalta Conference and at Berlin in 1945.
British War Cabinet documents, released on 2 January 2006, showed that as early as December 1944, the Cabinet had discussed their policy for the punishment of the leading Nazis if captured. British Prime Minister Winston Churchill had then advocated a policy of summary execution in some circumstances, with the use of an Act of Attainder to circumvent legal obstacles, being dissuaded from this only by talks with US and Soviet leaders later in the war.
In late 1943, during the Tripartite Dinner Meeting at the Tehran Conference, the Soviet leader, Joseph Stalin, proposed executing 50,000–100,000 German staff officers. US President Franklin D. Roosevelt joked that perhaps 49,000 would do. Churchill, believing them to be serious, denounced the idea of "the cold blooded execution of soldiers who fought for their country" and that he'd rather be "taken out in the courtyard and shot" himself than partake in any such action. However, he also stated that war criminals must pay for their crimes and that in accordance with the Moscow Document which he himself had written, they should be tried at the places where the crimes were committed. Churchill was vigorously opposed to executions "for political purposes." According to the minutes of a Roosevelt-Stalin meeting at Yalta, on 4 February 1945, at the Livadia Palace, President Roosevelt "said that he had been very much struck by the extent of German destruction in the Crimea and therefore he was more bloodthirsty in regard to the Germans than he had been a year ago, and he hoped that Marshal Stalin would again propose a toast to the execution of 50,000 officers of the German Army."
US Secretary of the Treasury Henry Morgenthau, Jr. suggested a plan for the total denazification of Germany; this was known as the Morgenthau Plan. The plan advocated the forced de-industrialisation of Germany and the summary execution of so-called "arch-criminals", i.e. the major war criminals. Roosevelt initially supported this plan, and managed to convince Churchill to support it in a less drastic form. Later, details were leaked to the public, generating widespread protest. Roosevelt, aware of strong public disapproval, abandoned the plan, but did not adopt an alternative position on the matter. The demise of the Morgenthau Plan created the need for an alternative method of dealing with the Nazi leadership. The plan for the "Trial of European War Criminals" was drafted by Secretary of War Henry L. Stimson and the War Department. Following Roosevelt's death in April 1945, the new president, Harry S. Truman, gave strong approval for a judicial process. After a series of negotiations between Britain, the US, Soviet Union and France, details of the trial were worked out. The trials were to commence on 20 November 1945, in the Bavarian city of Nuremberg.
Creation of the courts.
On 20 April 1942, representatives from the nine countries occupied by Germany met in London to draft the "Inter-Allied Resolution on German War Crimes". At the meetings in Tehran (1943), Yalta (1945) and Potsdam (1945), the three major wartime powers, the United Kingdom, United States, and the Soviet Union, agreed on the format of punishment for those responsible for war crimes during World War II. France was also awarded a place on the tribunal. The legal basis for the trial was established by the London Charter, which was agreed upon by the four so-called Great Powers on 8 August 1945, and which restricted the trial to "punishment of the major war criminals of the European Axis countries"
Some 200 German war crimes defendants were tried at Nuremberg, and 1,600 others were tried under the traditional channels of military justice. The legal basis for the jurisdiction of the court was that defined by the Instrument of Surrender of Germany. Political authority for Germany had been transferred to the Allied Control Council which, having sovereign power over Germany, could choose to punish violations of international law and the laws of war. Because the court was limited to violations of the laws of war, it did not have jurisdiction over crimes that took place before the outbreak of war on 1 September 1939.
Location.
Leipzig and Luxembourg were briefly considered as the location for the trial. The Soviet Union had wanted the trials to take place in Berlin, as the capital city of the 'fascist conspirators', but Nuremberg was chosen as the site for two reasons, with the first one having been the decisive factor:
As a compromise with the Soviets, it was agreed that while the location of the trial would be Nuremberg, Berlin would be the official home of the Tribunal authorities.<ref name="PRO-LCO-2/2980-1"></ref><ref name="PRO-LCO-2/2980-2"></ref> It was also agreed that France would become the permanent seat of the IMT and that the first trial (several were planned) would take place in Nuremberg.
Most of the accused had previously been detained at Camp Ashcan, a processing station and interrogation center in Luxembourg, and were moved to Nuremberg for the trial.
Participants.
Each of the four countries provided one judge and an alternate, as well as a prosecutor.
Chief prosecutors.
Assisting Jackson were the lawyers Telford Taylor, William S. Kaplan and Thomas J. Dodd, plus young US Army interpreter Richard Sonnenfeldt. Assisting Shawcross were Major Sir David Maxwell-Fyfe and Sir John Wheeler-Bennett. Mervyn Griffith-Jones, who was later to become famous as the chief prosecutor in the "Lady Chatterley's Lover" obscenity trial, was also on Shawcross's team. Shawcross also recruited a young barrister, Anthony Marreco, who was the son of a friend of his, to help the British team with the heavy workload.
Defense counsel.
The vast majority of the defense attorneys were German lawyers. These included Georg Fröschmann, Heinz Fritz (Hans Fritzsche), Otto Kranzbühler (Karl Dönitz), Otto Pannenbecker (Wilhelm Frick), Alfred Thoma (Alfred Rosenberg), Kurt Kauffmann (Ernst Kaltenbrunner), Hans Laternser (general staff and high command), Franz Exner (Alfred Jodl), Alfred Seidl (Hans Frank), Otto Stahmer (Hermann Göring), Walter Ballas (Gustav Krupp von Bohlen und Halbach), Hans Flächsner (Albert Speer), Günther von Rohrscheidt (Rudolf Heß), Egon Kubuschok (Franz von Papen), Robert Servatius (Fritz Sauckel), Fritz Sauter (Joachim von Ribbentrop), Walther Funk (Baldur von Schirach), Hanns Marx (Julius Streicher), Otto Nelte, and Herbert Kraus. The main counsels were supported by a total of 70 assistants, clerks and lawyers. The defense counsel witnesses included several men who took part in the war crimes during World War II, such as Rudolf Höss. The men testifying for the defense hoped to receive more lenient sentences. All of the men testifying on behalf of the defense were found guilty on several counts.
Trial.
The International Military Tribunal was opened on November 19, 1945, in the Palace of Justice in Nuremberg. The first session was presided over by the Soviet judge, Nikitchenko. The prosecution entered indictments against 24 major war criminals and seven organizations – the leadership of the Nazi party, the Reich Cabinet, the Schutzstaffel (SS), Sicherheitsdienst (SD), the Gestapo, the Sturmabteilung (SA) and the "General Staff and High Command", comprising several categories of senior military officers. These organizations were to be declared "criminal" if found guilty.
The indictments were for:
The 24 accused were, with respect to each charge, either indicted but not convicted (I), indicted and found guilty (G), or not charged (-), as listed below by defendant, charge, and eventual outcome:
Intelligence tests and psychiatric assessments.
The Rorschach test was administered to the defendants, along with the Thematic Apperception Test and a German adaptation of the Wechsler-Bellevue Intelligence Test. All were above average intelligence, several considerably.
Throughout the trials, specifically between January and July 1946, the defendants and a number of witnesses were interviewed by American psychiatrist Leon Goldensohn. His notes detailing the demeanor and comments of the defendants survive; they were edited into book form and published in 2004.
Overview of the trial.
The accusers were successful in unveiling the background of developments leading to the outbreak of World War II, which cost at least 40 million lives in Europe alone, as well as the extent of the atrocities committed in the name of the Hitler regime. Twelve of the accused were sentenced to death, seven received prison sentences (ranging from 10 years to life in prison), three were acquitted, and two were not charged.
Executions.
The death sentences were carried out 16 October 1946 by hanging using the standard drop method instead of long drop. The U.S. army denied claims that the drop length was too short which caused the condemned to die slowly from strangulation instead of quickly from a broken neck. But evidence remains that some of the condemned men died agonizingly slowly taking from between 14 minutes to choke to death to as long as struggling for 28 minutes. The executioner was John C. Woods. Woods had hanged 34 U.S. soldiers during the war, botching several of them. The executions took place in the gymnasium of the court building (demolished in 1983).
Although the rumor has long persisted that the bodies were taken to Dachau and burned there, they were actually incinerated in a crematorium in Munich, and the ashes scattered over the river Isar. The French judges suggested that the military condemned (Göring, Keitel and Jodl) be shot dead by a firing squad, as is standard for military courts-martial, but this was opposed by Biddle and the Soviet judges, who argued that the military officers had violated their military ethos and were not worthy of death by being shot, which was considered to be more dignified. The prisoners sentenced to incarceration were transferred to Spandau Prison in 1947.
Of the 12 defendants sentenced to death by hanging, two were not hanged: Martin Bormann was convicted in absentia (he had been, unknown to the Allies, killed while trying to escape from Berlin in May 1945), and Hermann Göring committed suicide the night before the execution. The remaining 10 defendants sentenced to death were hanged.
Nuremberg principles.
The definition of what constitutes a war crime is described by the Nuremberg principles, a set of guidelines document which was created as a result of the trial. The medical experiments conducted by German doctors and prosecuted in the so-called Doctors' Trial led to the creation of the Nuremberg Code to control future trials involving human subjects, a set of research ethics principles for human experimentation.
Of the indicted organizations the following were found not to be criminal:
Subsidiary and related trials.
The American authorities conducted subsequent Nuremberg Trials in their occupied zone.
Other trials conducted after the Nuremberg Trials include the following:
American role in the trial.
While Sir Geoffrey Lawrence of Britain was the judge chosen as president of the court, the most prominent of the judges at trial arguably was his American counterpart, Francis Biddle. Prior to the trial, Biddle had been Attorney General of the United States but had been asked to resign by Truman earlier in 1945.
Some accounts argue that Truman had appointed Biddle as the main American judge for the trial as an apology for asking for his resignation. Ironically, Biddle was known during his time as Attorney General for opposing the idea of prosecuting Nazi leaders for crimes committed before the beginning of the war, even sending out a memorandum on January 5, 1945 on the subject. The note also expressed Biddle's opinion that instead of proceeding with the original plan for prosecuting entire organizations, there should simply be more trials that would prosecute specific offenders.
Biddle soon changed his mind, as he approved a modified version of the plan on January 21, 1945, likely due to time constraints, since the trial would be one of the main issues discussed at Yalta. At trial, the Nuremberg tribunal ruled that any member of an organization convicted of war crimes, such as the SS or Gestapo, who had joined after 1939 would be considered a war criminal. Biddle managed to convince the other judges to make an exemption for any member who was drafted or had no knowledge of the crimes being committed by these organizations.
Justice Robert H. Jackson played an important role in not only the trial itself, but also in the creation of the International Military Tribunal, as he led the American delegation to London that, in the summer of 1945, argued in favour of prosecuting the Nazi leadership as a criminal conspiracy. According to Airey Neave, Jackson was also the one behind the prosecution's decision to include membership in any of the six criminal organizations in the indictments at the trial, though the IMT rejected this on the grounds that it was wholly without precedent in either international law or the domestic laws of any of the Allies. Jackson also attempted to have Alfried Krupp be tried in place of his father, Gustav, and even suggested that Alfried volunteer to be tried in his father's place. Both proposals were rejected by the IMT, particularly by Lawrence and Biddle, and some sources indicate that this resulted in Jackson being viewed unfavourably by the latter.
Thomas Dodd was a prosecutor for the United States. There was an immense amount of evidence backing the prosecutors' case, especially since meticulous records of the Nazis' actions had been kept. There were records taken in by the prosecutors that had signatures from specific Nazis signing for everything from stationery supplies to Zyklon B gas, which was used to kill the inmates of the deathcamps. Thomas Dodd showed a series of pictures to the courtroom after reading through the documents of crimes committed by the defendants. The showing consisted of pictures displaying the atrocities performed by the defendants. The pictures had been gathered when the inmates were liberated from the concentration camps.
Henry Gerecke, a Lutheran pastor, was sent to minister to the Nazi defendants.
Legacy.
The Tribunal is celebrated for establishing that "[c]rimes against international law are committed by men, not by abstract entities, and only by punishing individuals who commit such crimes can the provisions of international law be enforced." The creation of the IMT was followed by trials of lesser Nazi officials and the trials of Nazi doctors, who performed experiments on people in prison camps. It served as the model for the International Military Tribunal for the Far East which tried Japanese officials for crimes against peace and against humanity. It also served as the model for the Eichmann trial and for present-day courts at The Hague, for trying crimes committed during the Balkan wars of the early 1990s, and at Arusha, for trying the people responsible for the genocide in Rwanda.
The Nuremberg trials had a great influence on the development of international criminal law. The Conclusions of the Nuremberg trials served as models for:
The International Law Commission, acting on the request of the United Nations General Assembly, produced in 1950 the report "Principles of International Law Recognized in the Charter of the Nürnberg Tribunal and in the Judgement of the Tribunal" (Yearbook of the International Law Commission, 1950, vol. II). See Nuremberg Principles.
The influence of the tribunal can also be seen in the proposals for a permanent international criminal court, and the drafting of international criminal codes, later prepared by the International Law Commission.
From 2000 on during weekends, tourists can visit courtroom 600 where the trials were held and where a permanent exhibition has been dedicated to the trials.
Establishment of a permanent International Criminal Court.
The Nuremberg trials initiated a movement for the prompt establishment of a permanent international criminal court, eventually leading over fifty years later to the adoption of the Statute of the International Criminal Court. This movement was brought about because during the trials, there were conflicting court methods between the German court system and the U.S. court system. The crime of conspiracy was unheard of in the civil law systems of the Continent. Therefore, the German defense found it unfair to charge the defendants with conspiracy to commit crimes, while the judges from common-law countries were used to doing so.
"It [IMT] was the first successful international criminal court, and has since played a pivotal role in the development of international criminal law and international institutions” (Fichtelberg 5).
Criticism.
You'll see. A few years from now the lawyers of the world will condemn this trial. You can't have a trial without law.
 —Joachim von Ribbentrop<br>20 November 1945
Critics of the Nuremberg trials argued that the charges against the defendants were only defined as "crimes" after they were committed and that therefore the trial was invalid as a form of "victors' justice". The alleged double standards associated with putative victor's justice are also evident from the indictment of German defendants for conspiracy to commit aggression against Poland in 1939, while no one from the Soviet Union was charged for being part of the same conspiracy. As Biddiss observed, "the Nuremberg Trial continues to haunt us. ... It is a question also of the weaknesses and strengths of the proceedings themselves."
Quincy Wright, writing eighteen months after the conclusion of the IMT, explained the opposition to the Tribunal thus:
 The assumptions underlying the Charter of the United Nations, the Statute of the International Court of Justice, and the Charter of the Nuremberg Tribunal are far removed from the positivistic assumptions which greatly influenced the thought of international jurists in the nineteenth century. Consequently, the activities of those institutions have frequently been vigorously criticized by positivistic jurists ... [who] have asked: How can principles enunciated by the Nuremberg Tribunal, to take it as an example, be of legal value until most of the states have agreed to a tribunal with jurisdiction to enforce those principles? How could the Nuremberg Tribunal have obtained jurisdiction to find Germany guilty of aggression, when Germany had not consented to the Tribunal? How could the law, first explicitly accepted in the Nuremberg Charter of 1945, have bound the defendants in the trial when they committed the acts for which they were indicted years earlier?
Art.19 "The Tribunal shall not be bound by technical rules of evidence." 
Charter of the International Military Tribunal 
Art.21 "The Tribunal shall not require proof of facts of common knowledge but shall take judicial notice thereof." 
Charter of the International Military Tribunal 
Chief Justice of the United States Supreme Court Harlan Fiske Stone called the Nuremberg trials a fraud. "(Chief U.S. prosecutor) Jackson is away conducting his high-grade lynching party in Nuremberg," he wrote. "I don't mind what he does to the Nazis, but I hate to see the pretense that he is running a court and proceeding according to common law. This is a little too sanctimonious a fraud to meet my old-fashioned ideas."
Jackson, in a letter discussing the weaknesses of the trial, in October 1945 told U.S. President Harry S. Truman that the Allies themselves "have done or are doing some of the very things we are prosecuting the Germans for. The French are so violating the Geneva Convention in the treatment of prisoners of war that our command is taking back prisoners sent to them. We are prosecuting plunder and our Allies are practising it. We say aggressive war is a crime and one of our allies asserts sovereignty over the Baltic States based on no title except conquest."
Associate Supreme Court Justice William O. Douglas charged that the Allies were guilty of "substituting power for principle" at Nuremberg. "I thought at the time and still think that the Nuremberg trials were unprincipled," he wrote. "Law was created "ex post facto" to suit the passion and clamor of the time."
U.S. Deputy Chief Counsel Abraham Pomerantz resigned in protest at the low caliber of the judges assigned to try the industrial war criminals such as those at I.G. Farben.
Many Germans who agreed with the idea of punishment for war crimes, admitted trepidation concerning the trials. A contemporary German jurist said:
That the defendants at Nuremberg were held responsible, condemned and punished, will seem to most of us initially as a kind of historical justice. However, no one who takes the question of guilt seriously, above all no responsibly thoughtful jurist, will be content with this sensibility nor should they be allowed to be. Justice is not served when the guilty parties are punished in any old way, even if this seems appropriate with regard to their measure of guilt. Justice is only served when the guilty are punished in a way that carefully and conscientiously considers their criminal errors according to the provisions of valid law under the jurisdiction of a legally appointed judge.
The validity of the court has been questioned on a number of grounds:
In an editorial at the time "The Economist", a British weekly newspaper, criticised the hypocrisy of both Britain and France for supporting the expulsion of the Soviet Union from the League of Nations over its unprovoked attack against Finland in 1939 and for six years later cooperating with the USSR as a respected equal at Nuremberg. It also criticised the allies for their own double-standard at the Nuremberg Trials: "nor should the Western world console itself that the Russians alone stand condemned at the bar of the Allies' own justice. ... Among crimes against humanity stands the offence of the indiscriminate bombing of civilian populations. Can the Americans who dropped the atom bomb and the British who destroyed the cities of western Germany plead 'not guilty' on this count? Crimes against humanity also include the mass expulsion of populations. Can the Anglo-Saxon leaders who at Potsdam condoned the expulsion of millions of Germans from their homes hold themselves completely innocent? ... The nations sitting in judgement have so clearly proclaimed themselves exempt from the law which they have administered."
Legitimacy.
One criticism that was made of the IMT was that some treaties were not binding on the Axis powers because they were not signatories. This was addressed in the judgment relating to war crimes and crimes against humanity, which contains an expansion of customary law: "the Convention Hague 1907 expressly stated that it was an attempt 'to revise the general laws and customs of war,' which it thus recognised to be then existing, but by 1939 these rules laid down in the Convention were recognised by all civilised nations, and were regarded as being declaratory of the laws and customs of war which are referred to in Article 6 (b) of the [London] Charter."
Introduction of extempore simultaneous interpretation.
The Nuremberg Trials employed four official languages: English, German, French, and Russian. In order to address the complex linguistic issues that clouded over the proceedings, interpretation and translation departments had to be established. However, it was feared that consecutive interpretation would slow down the proceedings significantly. What is therefore unique in both the Nuremberg tribunals and history of the interpretation profession was the introduction of an entirely new technique, extempore simultaneous interpretation. This technique of interpretation requires the interpreter to listen to a speaker in a source (or passive) language and orally translate that speech into another language in real time, that is, simultaneously, through headsets and microphones. Interpreters were split into four sections, one for each official language, with three interpreters per section working from the other three languages into the fourth (their mother tongue). For instance, the English booth consisted of three interpreters, one working from German into English, one working from French, and one from Russian, etc. Defendants who did not speak any of the four official languages were provided with consecutive court interpreters. Some of the languages heard over the course of the proceedings included Yiddish, Hungarian, Czech, Ukrainian, and Polish.
The equipment used to establish this system was provided by IBM, and included an elaborate setup of cables which were hooked up to headsets and single earphones directly from the four interpreting booths (often referred to as "the aquarium"). Four channels existed for each working language, as well as a root channel for the proceedings without interpretation. Switching of channels was controlled by a setup at each table in which the listener merely had to turn a dial in order to switch between languages. People tripping over the floor-laid cables often led to the headsets getting disconnected, with several hours at a time sometimes being taken in order to repair the problem and continue on with the trials.
Interpreters were recruited and examined by the respective countries in which the official languages were spoken: US, UK, France, the Soviet Union, Germany, Switzerland, and Austria, as well as in special cases Belgium and the Netherlands. Many were former translators, army personnel, and linguists, some were experienced consecutive interpreters, others were ordinary individuals and even recent secondary school-graduates who led international lives in multilingual environments. It was, and still is believed, that the qualities that made the best interpreters were not just a perfect understanding of two or more languages, but more importantly a broad sense of culture, encyclopædic knowledge, inquisitiveness, as well as a naturally calm disposition.
With the simultaneous technique being extremely new, interpreters practically trained themselves, but many could not handle the pressure or the psychological strain. Many often had to be replaced, many returned to the translation department, and many left. Serious doubts were given as to whether interpretation provided a fair trial for the defendants, particularly because of fears of mistranslation and errors made on transcripts. The translation department had to also deal with the overwhelming problem of being understaffed and overburdened with an influx of documents that could not be kept up with. More often than not, interpreters were stuck in a session without having proper documents in front of them and were relied upon to do sight translation or double translation of texts, causing further problems and extensive criticism. Other problems that arose included complaints from lawyers and other legal professionals with regard to questioning and cross-examination. Legal professionals were most often appalled at the slower speed at which they had to conduct their task because of the extended time required for interpreters to do an interpretation properly. Also, a number of interpreters were noted for protesting the idea of using vulgar language reflected in the proceeds, especially if it referenced Jews or the conditions of the Nazi concentration camps. Bilingual/trilingual members who attended the trials picked up quickly on this aspect of character and were equally quick to file complaints.
Yet, despite the extensive trial and error, without the interpretation system the trials would not have been possible and in turn revolutionized the way multilingual issues were addressed in tribunals and conferences. A number of the interpreters following the trials were immediately recruited into the newly formed United Nations, while others returned to their ordinary lives, pursued other careers, or worked freelance. Outside the boundaries of the trials, many interpreters continued their positions on weekends interpreting for dinners, private meetings between judges, and excursions between delegates. Others worked as investigators or editors, or aided the translation department when they could, often using it as an opportunity to sharpen their skills and to correct poor interpretations on transcripts before they were available for public record.
For further reference, a book titled "The Origins of Simultaneous Interpretation: The Nuremberg Trial", written by interpreter Francesca Gaiba, was published by the University of Ottawa Press in 1998.
Today, all major international organizations, as well as any conference or government that uses more than one official language, uses extempore simultaneous interpretation. Notable bodies include the Parliament of Kosovo with three official languages, the Parliament of Canada with two official languages, the Parliament of South Africa with eleven official languages, the European Union with twenty-four official languages, and the United Nations with six official working languages.
References.
Citations.
Avalon Project.
These citations refer to documents at 
Bibliography.
</dl>

</doc>
<doc id="21876" url="http://en.wikipedia.org/wiki?curid=21876" title="Natasha Stott Despoja">
Natasha Stott Despoja

Natasha Jessica Stott Despoja AM (born 9 September 1969) is Australia's Ambassador for Women and Girls. A former politician and former leader of the Australian Democrats, she was a Democrats senator for South Australia from 1995 to 2008. Stott Despoja was appointed to the Senate at the age of 26, and until Sarah Hanson-Young was elected in 2007, was previously the youngest woman elected to the Parliament of Australia.
Early life.
Stott Despoja was born in Adelaide, the daughter of Shirley Stott Despoja, an Australian-born journalist with English heritage, and Mario Despoja, an immigrant from Croatia (then Yugoslavia). She was educated at Stradbroke Primary and Pembroke School and, later, the University of Adelaide where she graduated B.A.. She was active in student politics, becoming president of the Students' Association of the University of Adelaide (SAUA) and serving as state women's officer for the National Union of Students in South Australia. She then worked as a political advisor to Democrat senators John Coulter (SA) and Cheryl Kernot (Qld).
Personal life.
After her high-profile relationship with Hugh Riminton ended in 2001 Stott Despoja married former Liberal party advisor Ian Smith. Her husband is considered to be one of Australia's most influential political lobbyists, is the founder of consultancy Bespoke Approach and has been described by "The Power Index" as "an unabashed Tory".
Career.
On 29 November 1995, Stott Despoja was appointed to the casual vacancy created by the resignation of Coulter due to ill-health. She completed the remainder of Coulter's term and was re-elected at the 1996 election and 2001 election.
Stott Despoja was elected to the party's deputy leadership in 1997, under Meg Lees. At the time, she was party spokesperson for parliamentary portfolios including Science and Technology, Attorney General, Higher Education, IT, Employment and Youth Affairs.
During the passage of the Goods and Services Tax (GST) legislation in 1999, Stott Despoja, along with Andrew Bartlett, split from the party's other senators by opposing the package, which had been negotiated by Lees and prime minister John Howard. She said that she refused to break promises made by the party during the election. The party had gone to the election stating that they would work with whichever party formed government to improve their tax package. The Australian Democrats traditionally permitted parliamentary representatives to cast a conscience vote on any issue but, on this occasion, close numbers in the Senate placed greater pressure than usual on the dissenters.
In 1999, she was appointed a Global Leader for Tomorrow by the World Economic Forum (WEF).
Parliamentary leadership and deposition.
Stott Despoja was elected leader on 6 April 2001, replacing Meg Lees, who resigned from the party in July 2002. Further public criticism and disputes between Democrat senators resulted in Stott Despoja's resignation as leader on 21 August 2002, following presentation by four of her six colleagues (those who had earlier enabled the passage of the GST) with a ten-point 'reform' agenda proposed by John Cherry.After 16 months in the job, Senator Stott Despoja finally decided she couldn't heal the rifts which had divided her seven-member party room. Her colleagues were apparently stunned by the resignation, but shouldn't have been. Four of them had brought the crisis to a head, forcing Stott Despoja to accept a package of reforms she was utterly opposed to.
 She announced her resignation in a speech to the Senate, concluding with a "pledge to bring the party back home to the members again", and referring to her reluctance over colleagues' attitude towards her.
One colleague, Senator Murray, has said that he does not believe in ultimatums, yet one of his earliest communiques to the public and to me was to `shape up or ship out'. Some commentators have mistaken my relative public silence for weak leadership — my refusal to strike back aggressively, particularly in the public domain, as weakness. But I still believe that politics can be a civil discourse, and I choose not to inflame with returned invective.
She was replaced as leader by Bartlett following a membership ballot interval during which Brian Greig acted in the position.
In 2004, Stott Despoja took 11 weeks' leave from the Senate following the birth of her first child before returning to full duties as Democrat spokesperson on, inter alia, Higher Education, Status of Women, and Work and Family.
During her political career she also introduced 24 Private Member's Bills on issues including paid maternity leave, the Republic, genetic privacy, stem cells, captioning and same sex marriage. Stott Despoja regularly attends the Sydney Gay and Lesbian Mardi Gras.
Retirement from Parliament.
On 22 October 2006, after undergoing emergency surgery for an ectopic pregnancy, she announced that she would not be contesting the 2007 election to extend her term beyond 30 June 2008. She was the Australian Democrats' longest-serving senator. Her retirement coincided with the ending of her party's federal parliamentary representation; the Democrats' support had collapsed after 2002 and they won no seats at the 2004 and 2007 half-senate elections.
On 13 June 2011, Stott Despoja was named a Member of the Order of Australia for service to the Parliament of Australia, particularly as a Senator for South Australia, through leadership roles with the Australian Democrats, to education, and as a role model for women.
Later activities.
She is a regular commentator in "The Advertiser", a casual host on ABC 891 radio and is the Thursday night guest panellist on Channel 10's "The Project". She was previously a columnist for the Australian business news website "Business Spectator".
Stott Despoja is an Honorary Visiting Research Fellow at The University of Adelaide. Each year, she teaches winter school at The University of Adelaide with former Foreign Minister, Alexander Downer, 'The Practice of Politics'.
Currently Stott Despoja is a board member of non-profit organisations Burnet Institute (Australia's largest virology and communicable disease research institute), she is a deputy-chair at beyondblue (Australia's national depression initiative), the South Australian Museum and the Museum of Australian Democracy (MOAD). In June 2013, she retired from the Advertising Standards Board.
She is an Ambassador for Ovarian Cancer Australia (OCA), The Orangutan Project (TOP); secondbite; and the HIV/AIDS anti-stigma campaign, ENUF, (along with her husband Ian Smith). She is on the Advisory Panel of the Australian Privacy Foundation (APF).
In the past few years, Stott Despoja has also been an election observer for the US-based National Democratic Institute (NDI) in Nigeria (2011); has visited Burkina Faso for Oxfam (2012); and has been to Laos (2011) and Burma (2013) with The Burnet Institute.
In July 2013, Stott Despoja was named Chair of the Foundation to Prevent Violence against women and their children, a joint initiative of the Victorian and Commonwealth Governments which will be based in Melbourne. The foundation aims to educate the community by building partnerships with business, philanthropic organisations and government.
In December 2013, Australian Foreign Minister Julie Bishop announced the appointment of Stott Despoja as Australia's new ambassador for women and girls.
Stott Despoja was mentioned in June 2014 as a possible replacement for Kevin Scarce as the next Governor of South Australia, however Hieu Van Le was chosen.

</doc>
<doc id="21880" url="http://en.wikipedia.org/wiki?curid=21880" title="Nullum crimen, nulla poena sine praevia lege poenali">
Nullum crimen, nulla poena sine praevia lege poenali

Nullum crimen, nulla poena sine praevia lege poenali (Latin, "[There exists] no crime [and] no punishment without a pre-existing penal law [appertaining]") is a basic maxim in continental European legal thinking. It was written by Paul Johann Anselm Ritter von Feuerbach as part of the Bavarian Criminal Code in 1813.
The maxim itself is sometimes rendered:
or abbreviated to:
The maxim states that there can be no crime committed, and no punishment meted out, without a violation of penal law as it existed at the moment the alleged offence occurred. A consequence of this principle is that only those penalties that had already been established for the offence in the time when it was committed can be imposed. Thus, not only the existence of the crime depends on there being a previous legal provision declaring it to be a penal offense (nullum crimen sine praevia lege), but also, for a specific penalty to be imposed in a certain case, it is also necessary that the penal legislation in force at the time when the crime was committed ranked the penalty to be imposed as one of the possible sanctions to that crime (nulla poena sine praevia lege).
This basic legal principle has been incorporated into international criminal law. It thus prohibits the creation of any ex post facto law to the disadvantage of the defendant.
International criminal law.
Since the Nuremberg Trials, penal law is taken to include the prohibitions of international criminal law, in addition to those of domestic law. Thus prosecutions have been possible of such individuals as Nazi war criminals and officials of the German Democratic Republic responsible for the Berlin Wall, even though their deeds may have been allowed or even ordered by domestic law. Also, courts when dealing with such cases will tend to look to the letter of the law at the time, even in regimes where the law as it was written was generally disregarded in practice by its own authors.
However, some legal scholars criticize this, because generally, in the legal systems of Continental Europe where the maxim was first developed, "penal law" was taken to mean statutory penal law, so as to create a guarantee to the individual, considered as a fundamental right, that he would not be prosecuted for an action or omission that was not considered a crime according to the statutes passed by the legislators in force at the time of the action or omission, and that only those penalties that were in place when the infringement took place would be applied. Also, even if one considers that certain actions are prohibited under general principles of international law, critics point out that a prohibition in a general principle does not amount to the establishment of a crime, and that the rules of international law also do not stipulate specific penalties for the violations.
In an attempt to address those criticisms, the statute of the recently established International Criminal Court provides for a system in which crimes and penalties are expressly set out in written law, that shall only be applied to future cases.
This principle is enshrined in several national constitutions, and a number of international instruments. See e.g. European Convention on Human Rights, article 7(1); Rome Statute of the International Criminal Court, articles 22 and 23.
Common law.
In English criminal law there are offences of common law origin. For example, murder is still a common law offence and lacks a statutory definition. The Homicide Act 1957 did not include a statutory definition of murder (or any other homicidal offense). There was, consequently, the astonishing spectacle of the definition of murder, still a matter of common law, being the subject of no less than six appeals to the House of Lords within the next 40 years ("Director of Public Prosecutions v. Smith" [1961] A.C. 290; "Hyam v. Director of Public Prosecutions" [1975] A.C. 55; "Regina v. Cunningham" [1982] A.C. 566; "Regina v. Moloney" [1985] A.C. 905; "Regina v. Hancock" [1986] A.C. 455; "Regina v. Woollin" [1998] 4 A11 E.R. 103 (H.L.)).
References.
</dl>

</doc>
<doc id="21881" url="http://en.wikipedia.org/wiki?curid=21881" title="Nuremberg Code">
Nuremberg Code

The Nuremberg Code is a set of research ethics principles for human experimentation set as a result of the Subsequent Nuremberg Trials at the end of the Second World War.
Background.
On August 20, 1947, the judges delivered their verdict in the "Doctors' Trial" against Karl Brandt and 22 others. These trials focused on doctors involved in the human experiments in concentration camps. The suspects were involved in over 3,500,000 sterilizations of German citizens. 
The trials began on December 9, 1946 in Nuremberg, Germany and were led exclusively by the United States. Harry Truman approved these trials in January 1946.
Most of the suspects escaped punishment for their crimes. Several of the accused argued that their experiments differed little from pre-war ones and that there was no law that differentiated between legal and illegal experiments.
In May of the same year, Dr. Leo Alexander had submitted to the Counsel for War Crimes six points defining legitimate medical research. The trial verdict adopted these points and added an extra four. The ten points constituted the "Nuremberg Code". Although the legal force of the document was not established and it was not incorporated directly into either the American or German law, the Nuremberg Code and the related Declaration of Helsinki are the basis for the Code of Federal Regulations Title 45 Volume 46, which are the regulations issued by the United States Department of Health and Human Services governing federally funded human subjects research in the United States. In addition, the Nuremberg code has also been incorporated into the law of individual states such as California and other countries.
The Nuremberg code includes such principles as informed consent and absence of coercion; properly formulated scientific experimentation; and beneficence towards experiment participants.
The ten points of the Nuremberg Code.
The 10 points are, (all from United States National Institutes of Health).
Reprinted from "Trials of War Criminals before the Nuremberg Military Tribunals under Control Council Law No. 10, Vol. 2, pp. 181–182." Washington, D.C.: U.S. Government Printing Office, 1949. Note that complete electronic copies of the "Trials of War Criminals Before the Nuernberg [Nuremberg] Military Tribunals Under Control Council Law No. 10" are available online, as are most of the other proceedings from the Nuremberg Trials.
Further reading.
</dl>

</doc>
<doc id="21885" url="http://en.wikipedia.org/wiki?curid=21885" title="Nim">
Nim

 Nim is a mathematical game of strategy in which two players take turns removing objects from distinct heaps. On each turn, a player must remove at least one object, and may remove any number of objects provided they all come from the same heap.
Variants of Nim have been played since ancient times. The game is said to have originated in China—it closely resembles the Chinese game of "Tsyan-shizi", or "picking stones"—but the origin is uncertain; the earliest European references to Nim are from the beginning of the 16th century. Its current name was coined by Charles L. Bouton of Harvard University, who also developed the complete theory of the game in 1901, but the origins of the name were never fully explained. The name is probably derived from German "nimm" meaning "take [imperative]", or the obsolete English verb "nim" of the same meaning.
Nim can be played as a "misère" game, in which the player to take the last object loses. Nim can also be played as a "normal play" game, which means that the person who makes the last move (i.e., who takes the last object) wins. This is called normal play because most games follow this convention, even though Nim usually does not.
Normal play Nim (or more precisely the system of nimbers) is fundamental to the Sprague–Grundy theorem, which essentially says that in normal play every impartial game is equivalent to a Nim heap that yields the same outcome when played in parallel with other normal play impartial games (see disjunctive sum).
While all normal play impartial games can be assigned a nim value, that is not the case under the misère convention. Only tame games can be played using the same strategy as misère nim.
A version of Nim is played—and has symbolic importance—in the French New Wave film "Last Year at Marienbad" (1961).
At the 1940 New York World's Fair Westinghouse displayed a machine, the Nimatron, that played Nim. It was also one of the first ever electronic computerized games (1952). Herbert Koppel, Eugene Grant and Howard Bailer, engineers from the W.L. Maxon Corporation, developed a machine weighing 50 pounds which played Nim against a human opponent and regularly won. A NIM Playing Machine has been described made from TinkerToy 
Nim is a special case of a poset game where the poset consists of disjoint chains (the heaps).
Game play and illustration.
The normal game is between two players and played with three heaps of any number of objects. The two players alternate taking any number of objects from any single one of the heaps. The goal is to be the last to take an object. In misère play, the goal is instead to ensure that the opponent is forced to take the last remaining object.
The following example game is played between fictional players Bob and Alice who start with heaps of three, four and five objects.
 Sizes of heaps Moves
 A B C
 3 4 5 Bob takes 2 from A
 1 4 5 Alice takes 3 from C
 1 4 2 Bob takes 1 from B
 1 3 2 Alice takes 1 from B
 1 2 2 Bob takes entire A heap, leaving two 2s.
 0 2 2 Alice takes 1 from B
 0 1 2 Bob takes 1 from C leaving two 1s. ("In misère play he would take 2 from C leaving (0, 1, 0).")
 0 1 1 Alice takes 1 from B
 0 0 1 Bob takes entire C heap and wins.
Mathematical theory.
Nim has been mathematically solved for any number of initial heaps and objects, and there is an easily calculated way to determine which player will win and what winning moves are open to that player. In a game that starts with heaps of three, four, and five, the first player will win with optimal play, whether the misère or normal play convention is followed.
The key to the theory of the game is the binary digital sum of the heap sizes, that is, the sum (in binary) neglecting all carries from one digit to another. This operation is also known as "exclusive or" (xor) or "vector addition over GF(2)". Within combinatorial game theory it is usually called the nim-sum, as it will be called here. The nim-sum of "x" and "y" is written "x" ⊕ "y" to distinguish it from the ordinary sum, "x" + "y". An example of the calculation with heaps of size 3, 4, and 5 is as follows:
 Binary Decimal
 0112 310 Heap A
 1002 410 Heap B
 1012 510 Heap C
 0102 210 The nim-sum of heaps A, B, and C, 3 ⊕ 4 ⊕ 5 = 2
An equivalent procedure, which is often easier to perform mentally, is to express the heap sizes as sums of distinct powers of 2, cancel pairs of equal powers, and then add what's left:
 3 = 0 + 2 + 1 = 2 1 Heap A
 4 = 4 + 0 + 0 = 4 Heap B
 5 = 4 + 0 + 1 = 4 1 Heap C
 2 = 2 What's left after canceling 1s and 4s
In normal play, the winning strategy is to finish every move with a Nim-sum of 0. This is always possible if the Nim-sum is not zero before the move. If the Nim-sum is zero, then the next player will lose if the other player does not make a mistake. To find out which move to make, let X be the Nim-sum of all the heap sizes. Take the Nim-sum of each of the heap sizes with X, and find a heap whose size decreases. The winning strategy is to play in such a heap, reducing that heap to the Nim-sum of its original size with X. In the example above, taking the Nim-sum of the sizes is X = 3 ⊕ 4 ⊕ 5 = 2. The Nim-sums of the heap sizes A=3, B=4, and C=5 with X=2 are
The only heap that is reduced is heap A, so the winning move is to reduce the size of heap A to 1 (by removing two objects).
As a particular simple case, if there are only two heaps left, the strategy is to reduce the number of objects in the bigger heap to make the heaps equal. After that, no matter what move your opponent makes, you can make the same move on the other heap, guaranteeing that you take the last object.
When played as a misère game, Nim strategy is different only when the normal play move would leave no heap of size two or larger. In that case, the correct move is to leave an odd number of heaps of size one (in normal play, the correct move would be to leave an even number of such heaps).
In a misère game with heaps of sizes three, four and five, the strategy would be applied like this:
 A B C Nim-sum
 3 4 5 0102=210 I take 2 from A, leaving a sum of 000, so I will win.
 1 4 5 0002=010 You take 2 from C
 1 4 3 1102=610 I take 2 from B
 1 2 3 0002=010 You take 1 from C
 1 2 2 0012=110 I take 1 from A
 0 2 2 0002=010 You take 1 from C
 0 2 1 0112=310 The normal play strategy would be to take 1 from B, leaving an even number (2)
 heaps of size 1. For misère play, I take the entire B heap, to leave an odd
 number (1) of heaps of size 1.
 0 0 1 0012=110 You take 1 from C, and lose.
The previous strategy for a misère game can be easily implemented (for example in Python, below).
Proof of the winning formula.
The soundness of the optimal strategy described above was demonstrated by C. Bouton.
Theorem. In a normal Nim game, the player making the first move has a winning strategy if and only if the nim-sum of the sizes of the heaps is nonzero. Otherwise, the second player has a winning strategy.
"Proof:" Notice that the nim-sum (⊕) obeys the usual associative and commutative laws of addition (+) and also satisfies an additional property, "x" ⊕ "x" = 0 (technically speaking, that the nonnegative integers under ⊕ form an Abelian group of exponent 2).
Let "x"1, ..., "xn" be the sizes of the heaps before a move, and "y"1, ..., "yn" the corresponding sizes after a move. Let "s" = "x"1 ⊕ ... ⊕ "xn" and "t" = "y"1 ⊕ ... ⊕ "yn". If the move was in heap "k", we have "xi" = "yi" for all "i" ≠ "k", and "xk" > "yk". By the properties of ⊕ mentioned above, we have
 "t" = 0 ⊕ "t"
 = "s" ⊕ "s" ⊕ "t"
 = "s" ⊕ ("x"1 ⊕ ... ⊕ "xn") ⊕ ("y"1 ⊕ ... ⊕ "yn")
 = "s" ⊕ ("x"1 ⊕ "y"1) ⊕ ... ⊕ ("xn" ⊕ "yn")
 = "s" ⊕ 0 ⊕ ... ⊕ 0 ⊕ ("xk" ⊕ "yk") ⊕ 0 ⊕ ... ⊕ 0
 = "s" ⊕ "xk" ⊕ "yk"
 (*) "t" = "s" ⊕ "xk" ⊕ "yk".
The theorem follows by induction on the length of the game from these two lemmas.
Lemma 1. If "s" = 0, then "t" ≠ 0 no matter what move is made.
"Proof:" If there is no possible move, then the lemma is vacuously true (and the first player loses the normal play game by definition). Otherwise, any move in heap "k" will produce "t" = "xk" ⊕ "yk" from (*). This number is nonzero, since "xk" ≠ "yk".
Lemma 2. If "s" ≠ 0, it is possible to make a move so that "t" = 0.
"Proof:" Let "d" be the position of the leftmost (most significant) nonzero bit in the binary representation of "s", and choose "k" such that the "d"th bit of "xk" is also nonzero. (Such a "k" must exist, since otherwise the "d"th bit of "s" would be 0.)
Then letting "yk" = "s" ⊕ "xk", we claim that "yk" < "xk": all bits to the left of "d" are the same in "xk" and "yk", bit "d" decreases from 1 to 0 (decreasing the value by 2"d"), and any change in the remaining bits will amount to at most 2"d"−1. The first player can thus make a move by taking "xk" − "yk" objects from heap "k", then
 "t" = "s" ⊕ "xk" ⊕ "yk" (by (*))
 = "s" ⊕ "xk" ⊕ ("s" ⊕ "xk")
 = 0.
The modification for misère play is demonstrated by noting that the modification first arises in a position that has only one heap of size 2 or more. Notice that in such a position "s" ≠ 0, therefore this situation has to arise when it is the turn of the player following the winning strategy. The normal play strategy is for the player to reduce this to size 0 or 1, leaving an even number of heaps with size 1, and the misère strategy is to do the opposite. From that point on, all moves are forced.
Other variations of Nim.
Dividing natural number.
Give any natural number "n", the two people can divide "n" by a prime power ( ) which is a factor of "n", the person who gets 1 wins.
If formula_1, where formula_2 is the "k"-th prime, then it is a nim game with "k" groups of stones, and the "r"-th groups has formula_3 stones.
If the divisor changes to "can be a power of squarefree numbers" (sequence in OEIS), it is Wythoff's game.
The subtraction game "S"(1, 2, . . ., "k").
In another game which is commonly known as Nim (but is better called the subtraction game "S" (1,2...,"k")), an upper bound is imposed on the number of objects that can be removed in a turn. Instead of removing arbitrarily many objects, a player can only remove 1 or 2 or ... or "k" at a time. This game is commonly played in practice with only one heap (for instance with "k" = 3 in the game "Thai 21" on , where it appeared as an Immunity Challenge).
Bouton's analysis carries over easily to the general multiple-heap version of this game. The only difference is that as a first step, before computing the Nim-sums, we must reduce the sizes of the heaps modulo "k" + 1. If this makes all the heaps of size zero (in misère play), the winning move is to take "k" objects from one of the heaps. In particular, in ideal play from a single heap of "n" objects, the second player can win if and only if
This follows from calculating the nim-sequence of "S"(1,2...,"k"),
from which the strategy above follows by the Sprague–Grundy theorem.
The 21 game.
The game "21" is played as a misère game with any number of players who take turns saying a number. The first player says "1" and each player in turn increases the number by 1, 2, or 3, but may not exceed 21; the player forced to say "21" loses. This can be modeled as a subtraction game with a heap of 21–"n" objects. The winning strategy for the two-player version of this game is to always say a multiple of 4; it is then guaranteed that the other player will ultimately have to say 21 – so in the standard version where the first player opens with "1", they start with a losing move.
The 21 game can also be played with different numbers, like "Add at most 5; lose on 34".
A sample game of 21 in which the second player follows the winning strategy:
 Player Number
 1 1
 2 4
 1 5, 6 or 7
 2 8
 1 9, 10 or 11
 2 12
 1 13, 14 or 15
 2 16
 1 17, 18 or 19
 2 20
 1 21
The 100 game.
A similar version is the "100 game": two players start from 0 and alternatively add a number from 1 to 10 to the sum. The player who reaches 100 wins. The winning strategy is to reach a number in which the digits are subsequent (e.g. 01, 12, 23, 34...) and control the game by jumping through all the numbers of this sequence. Once reached 89, the opponent has lost (he can only tell numbers from 90 to 99, and the next answer can in any case be 100).
A multiple-heap rule.
In another variation of Nim, besides removing any number of objects from a single heap, one is permitted to remove the same number of objects from each heap.
Circular Nim.
Yet another variation of Nim is 'Circular Nim', where any number of objects are placed in a circle, and two players alternately remove one, two or three adjacent objects. For example, starting with a circle of ten objects,
three objects are taken in the first move
_ . . . . . . . _ _
then another three
_ . _ _ _ . . . _ _
then one
_ . _ _ _ . . _ _ _
but then three objects cannot be taken out in one move.
Grundy's game.
In Grundy's game, another variation of Nim, a number of objects are placed in an initial heap, and two players alternately divide a heap into two nonempty heaps of different sizes. Thus, six objects may be divided into piles of 5+1 or 4+2, but not 3+3. Grundy's game can be played as either misère or normal play.
Greedy Nim.
"Greedy Nim" is a variation where the players are restricted to choosing stones from only the largest pile. It is a finite impartial game. "Greedy Nim Misère" has the same rules as Greedy Nim, but here the last player able to make a move loses
Let the largest number of stones in a pile be "m", the second largest number of stones in a pile be "n". Let "p""m" be the number of piles having "m" stones, "p""n" be the number of piles having "n" stones. Then there is a theorem that game positions with "p""m" even are "P" positions. 
 This theorem can be shown by considering the positions where "p""m" is odd. If "p""m" is larger than 1, all stones may be removed from this pile to reduce "p""m" by 1 and the new "p""m" will be even. If "p""m" = 1 (i.e. the largest heap is unique), there are two cases:
Thus there exists a move to a state where "p""m" is even. Conversely, if "p""m" is even, if any move is possible ("p""m" ≠ 0) then it must take the game to a state where "p""m" is odd. The final position of the game is even ("p""m" = 0). Hence each position of the game with "p""m" even must be a "P" position.
Index-"k" Nim.
A generalization of multi-heap Nim was called "Nimformula_5" or "index-"k" Nim by E. H. Moore, who analyzed it in 1910. In index-"k" Nim, instead of removing objects from only one heap, players can remove objects from at least one but up to "k" different heaps. The number of elements that may be removed from each heap may be either arbitrary, or limited to at most "r" elements, like in the "subtraction game" above.
The winning strategy is as follows: Like in ordinary multi-heap Nim, one considers the binary representation of the heap sizes (or heap sizes modulo "r" + 1). In ordinary Nim one forms the XOR-sum (or sum modulo 2) of each binary digit, and the winning strategy is to make each XOR sum zero. In the generalization to index-"k" Nim, one forms the sum of each binary digit modulo "k" + 1.
Again the winning strategy is to move such that this sum is zero for every digit. Indeed, the value thus computed is zero for the final position, and given a configuration of heaps for which this value is zero, any change of at most "k" heaps will make the value non-zero. Conversely, given a configuration with non-zero value, one can always take from at most "k" heaps, carefully chosen, so that the value will become zero.
Building Nim.
Building Nim is a variant of Nim where the two players first construct the game of Nim. Given "n" stones and "s" empty piles, the players alternate turns placing exactly one stone into a pile of their choice. Once all the stones are placed, a game of Nim begins, starting with the next player that would move. This game is denoted "BN(n,s)".

</doc>
<doc id="21886" url="http://en.wikipedia.org/wiki?curid=21886" title="Ninon de l'Enclos">
Ninon de l'Enclos

Anne "Ninon" de l'Enclos also spelled Ninon de Lenclos and Ninon de Lanclos (10 November 1620 – 17 October 1705) was a French author, courtesan, freethinker, and patron of the arts.
Early life.
Born Anne de Lenclos in Paris, she was nicknamed "Ninon" by her father at an early age. In 1632 her father was exiled from France after a duel, and when her mother died ten years later the unmarried Ninon entered a convent, only to leave the next year.
For the remainder of her life, she was determined to remain unmarried and independent.
Life as a courtesan and author.
Returning to Paris, she became a popular figure in the salons, and her own drawing room became a centre for the discussion and consumption of the literary arts. In her early thirties she was responsible for encouraging the young Molière, and when she died she left money for the son of her accountant, a nine-year-old named François Marie Arouet, later to become known as Voltaire, so he could buy books.
It was during this period that her life as a courtesan began. Ninon took a succession of notable and wealthy lovers, including the king's cousin the Great Condé, Gaston de Coligny, and François, duc de La Rochefoucauld. These men did not support her, however; she prided herself on her independent income. "Ninon always had crowds of adorers but never more than one lover at a time, and when she tired of the present occupier, she said so frankly and took another. Yet such was the authority of this wanton, that no man dared fall out with his successful rival; he was only too happy to be allowed to visit as a familiar friend," Saint-Simon wrote. In 1652, Ninon took up with Louis de Mornay, the marquis de Villarceaux, by whom she had a son, also named Louis. She lived with the marquis until 1655, when she returned to Paris. When she would not return to him, the marquis fell into a fever; to console him, Ninon cut her hair and sent the shorn locks to him, starting a vogue for bobbed hair "à la Ninon". 
This life (not as acceptable in those days as it would become in later years) and her opinions on organized religion caused her some trouble, and she was imprisoned in the Madelonnettes Convent in 1656 at the behest of Anne of Austria, Queen of France and regent for her son Louis XIV. Not long after, however, she was visited by Christina, former queen of Sweden. Impressed, Christina wrote to Cardinal Mazarin on Ninon's behalf and arranged for her release.
In response, as an author she defended the possibility of living a good life in the absence of religion, notably in 1659's "La coquette vengée" ("The Flirt Avenged"). She was also noted for her wit; among her numerous sayings and quips are "Much more genius is needed to make love than to command armies" and "We should take care to lay in a stock of provisions, but not of pleasures: these should be gathered day by day." A picture of Ninon, under the name of Damo, was sketched in Mlle de Scudéry's "Clélie" (1654–1660).
Starting in the late 1660s she retired from her courtesan lifestyle and concentrated more on her literary friends – from 1667, she hosted her gatherings at "l'hôtel Sagonne", which was considered "the" location of the salon of Ninon de l'Enclos despite other locales in the past. During this time she was a friend of Jean Racine, the great French playwright. Later she would become a close friend with the devout Françoise d'Aubigné, better known as Madame de Maintenon, the lady-in-waiting who would later become the second wife of Louis XIV. Saint-Simon wrote that "The lady did not like her to be mentioned in her presence, but dared not disown her, and wrote cordial letters to her from time to time, to the day of her death". Ninon eventually died at the age of 84, as a very wealthy woman. To the end, she "was convinced that she had no soul, and never abandoned that conviction, not even in advanced old age, not even at the hour of her death." 
Influence.
Ninon de l'Enclos is a relatively obscure figure in the English-speaking world, but is much better known in France where her name is synonymous with wit and beauty. Saint-Simon noted "Ninon made friends among the great in every walk of life, had wit and intelligence enough to keep them, and, what is more, to keep them friendly with one another."
Dorothy Parker wrote the poem "Ninon De L'Enclos On Her Last Birthday" and also referenced Ninon in another of her poems, "Words Of Comfort To Be Scratched On A Mirror", writing, "Ninon was ever the chatter of France." 

</doc>
<doc id="21888" url="http://en.wikipedia.org/wiki?curid=21888" title="National Institute of Standards and Technology">
National Institute of Standards and Technology

The National Institute of Standards and Technology (NIST), known between 1901 and 1988 as the National Bureau of Standards (NBS), is a measurement standards laboratory, also known as a National Metrological Institute (NMI), which is a non-regulatory agency of the United States Department of Commerce. The institute's official mission is to:
Promote U.S. innovation and industrial competitiveness by advancing measurement science, standards, and technology in ways that enhance economic security and improve our quality of life.
NIST had an operating budget for fiscal year 2007 (October 1, 2006-September 30, 2007) of about $843.3 million. NIST's 2009 budget was $992 million, and it also received $610 million as part of the American Recovery and Reinvestment Act. NIST employs about 2,900 scientists, engineers, technicians, and support and administrative personnel. About 1,800 NIST associates (guest researchers and engineers from American companies and foreign countries) complement the staff. In addition, NIST partners with 1,400 manufacturing specialists and staff at nearly 350 affiliated centers around the country. NIST publishes the Handbook 44 that provides the "Specifications, tolerances, and other technical requirements for weighing and measuring devices".
History.
Initial mandate.
In 1821 John Quincy Adams stated, "Weights and measures may be ranked among the necessities of life to every individual of human society", but this had long been understood. The Articles of Confederation, ratified by the colonies in 1781, contained the clause, "The United States in Congress assembled shall also have the sole and exclusive right and power of regulating the alloy and value of coin struck by their own authority, or by that of the respective states—fixing the standards of weights and measures throughout the United States". Article 1, section 8, of the Constitution of the United States (1789), transferred this power to Congress; "The Congress shall have power...To coin money, regulate the value thereof, and of foreign coin, and fix the standard of weights and measures".
In January 1790 President George Washington, in his first annual message to Congress stated that, "Uniformity in the currency, weights, and measures of the United States is an object of great importance, and will, I am persuaded, be duly attended to", and ordered Secretary of State Thomas Jefferson to prepare a plan for Establishing Uniformity in the Coinage, Weights, and Measures of the United States, afterwards referred to as the Jefferson report. On October 25, 1791, Washington appealed a third time to Congress, "A uniformity of the weights and measures of the country is among the important objects submitted to you by the Constitution and if it can be derived from a standard at once invariable and universal, must be no less honorable to the public council than conducive to the public convenience", but it was not until 1838 that a uniform set of standards was worked out.
History.
From 1830 until 1901, the role of overseeing weights and measures was carried out by the Office of Standard Weights and Measures, which was part of the U.S. Treasury Department. In 1901, in response to a bill proposed by Congressman James H. Southard (R, Ohio), the National Bureau of Standards was founded with the mandate to provide standard weights and measures, and to serve as the national physical laboratory for the United States. (Southard had previously sponsored a bill for metric conversion of the United States.) President Theodore Roosevelt appointed Samuel W. Stratton as the first director. The budget for the first year of operation was $40,000. The Bureau took custody of the copies of the kilogram and meter bars that were the standards for U.S. measures, and set up a program to provide metrology services for United States scientific and commercial users. A laboratory site was constructed in Washington, D.C., and instruments were acquired from the national physical laboratories of Europe. In addition to weights and measures, the Bureau developed instruments for electrical units and for measurement of light. In 1905 a meeting was called that would be the first "National Conference on Weights and Measures".
Initially conceived as purely a metrology agency, the Bureau of Standards was directed by Herbert Hoover to set up divisions to develop commercial standards for materials and products.page 133 Some of these standards were for products intended for government use, but product standards also affected private-sector consumption. Quality standards were developed for products including some types of clothing, automobile brake systems and headlamps, antifreeze, and electrical safety. During World War I, the Bureau worked on multiple problems related to war production, even operating its own facility to produce optical glass when European supplies were cut off. Between the wars, Harry Diamond of the Bureau developed a blind approach radio aircraft landing system. During the Second World War, military research and development was carried out, including development of radio propagation forecast methods, the proximity fuze and the guided bomb.
In 1948, financed by the Air Force, the Bureau began design and construction of SEAC, the Standards Eastern Automatic Computer. The computer went into operation in May 1950 using a combination of vacuum tubes and solid-state diode logic. About the same time the Standards Western Automatic Computer, was built at the Los Angeles office of the NBS and used for research there. A mobile version, DYSEAC, was built for the Signal Corps in 1954.
The "National Bureau of Standards" became the National Institute of Standards and Technology in 1988.
Metric system.
The Congress of 1866 legalized the use of the metric system through the passage of U.S. code 1952 Ed., Title 15, Ch 6, sections 204 and 205. On May 20, 1875, 17 out of 20 countries signed a document known as the "Metric Convention" or the "Treaty of the Meter", which established the International Bureau of Weights and Measures under the control of an international committee elected by the General Conference on Weights and Measures.
Organization.
NIST is headquartered in Gaithersburg, Maryland, and operates a facility in Boulder, Colorado. NIST's activities are organized into laboratory programs and extramural programs. Effective October 1, 2010, NIST was realigned by reducing the number of NIST laboratory units from ten to six. NIST Laboratories include:
Extramural programs include:
 NIST's Boulder laboratories are best known for NIST‑F1, which houses an atomic clock. NIST‑F1 serves as the source of the nation's official time. From its measurement of the natural resonance frequency of cesium—which defines the second—NIST broadcasts time signals via longwave radio station WWVB near Fort Collins, Colorado, and shortwave radio stations WWV and WWVH, located near Fort Collins and Kekaha, Hawaii, respectively.
NIST also operates a neutron science user facility: the NIST Center for Neutron Research (NCNR). The NCNR provides scientists access to a variety of neutron scattering instruments, which they use in many research fields (materials science, fuel cells, biotechnology, etc.).
The SURF III Synchrotron Ultraviolet Radiation Facility is a source of synchrotron radiation, in continuous operation since 1961. SURF III now serves as the U.S. national standard for source-based radiometry throughout the generalized optical spectrum. All NASA-borne, extreme-ultraviolet observation instruments have been calibrated at SURF since the 1970s, and SURF is used for measurement and characterization of systems for extreme ultraviolet lithography.
The performs research in nanotechnology, both through internal research efforts and by running a user-accessible cleanroom nanomanufacturing facility. This "NanoFab" is equipped with tools for lithographic patterning and imaging (e.g., electron microscopes and atomic force microscopes).
Committees.
NIST has seven standing committees:
Projects.
Measurements and standards.
As part of its mission, NIST supplies industry, academia, government, and other users with over 1,300 (SRMs). These artifacts are certified as having specific characteristics or component content, used as calibration standards for measuring equipment and procedures, quality control benchmarks for industrial processes, and experimental control samples.
"Handbook 44".
NIST publishes the "Handbook 44" each year after the annual meeting of the National Conference on Weights and Measures (NCWM). Each edition is developed through cooperation of the Committee on Specifications and Tolerances of the NCWM and the Weights and Measures Division (WMD) of the NIST. The purpose of the book is a partial fulfillment of the statutory responsibility for "cooperation with the states in securing uniformity of weights and measures laws and methods of inspection".
NIST has been publishing various forms of what is now the "Handbook 44" since 1918 and began publication under the current name in 1949. The 2010 edition conforms to the concept of the primary use of the SI (metric) measurements recommended by the Omnibus Foreign Trade and Competitiveness Act of 1988.
Homeland security.
NIST is currently developing government-wide identification card standards for federal employees and contractors to prevent unauthorized persons from gaining access to government buildings and computer systems.
World Trade Center Collapse Investigation.
In 2002 the National Construction Safety Team Act mandated NIST to conduct an investigation into the collapse of the World Trade Center buildings 1 and 2 and the 47-story 7 World Trade Center. The "World Trade Center Collapse Investigation", directed by lead investigator Shyam Sunder, covered three aspects, including a technical building and fire safety investigation to study the factors contributing to the probable cause of the collapses of the WTC Towers (WTC 1 and 2) and WTC 7. NIST also established a research and development program to provide the technical basis for improved building and fire codes, standards, and practices, and a dissemination and technical assistance program to engage leaders of the construction and building community in implementing proposed changes to practices, standards, and codes. NIST also is providing practical guidance and tools to better prepare facility owners, contractors, architects, engineers, emergency responders, and regulatory authorities to respond to future disasters. The investigation portion of the response plan was completed with the release of the final report on 7 World Trade Center on November 20, 2008. The final report on the WTC Towers—including 30 recommendations for improving building and occupant safety—was released on October 26, 2005.
Election technology.
NIST works in conjunction with the Technical Guidelines Development Committee of the Election Assistance Commission to develop the Voluntary Voting System Guidelines for voting machines and other election technology.
People.
Four scientific researchers at NIST have been awarded Nobel Prizes for work in physics: William D. Phillips in 1997, Eric A. Cornell in 2001, John L. Hall in 2005 and David J. Wineland in 2012, which is the largest number for any U.S. government laboratory. All four were recognized for their work related to laser cooling of atoms, which is directly related to the development and advancement of the atomic clock. In 2011 Dan Shechtman was awarded the Nobel Prize in chemistry for his work on quasicrystals in the Metallurgy Division from 1982 to 1984. In addition, John Cahn was awarded the 2011 Kyoto Prize for Materials Science. Other notable people who have worked at NIST include:
Directors.
Since 1989, the director of NIST has been a Schedule-C Presidential appointee and is confirmed by the United States Senate, and since that year the average tenure of NIST directors has fallen from 11 years to 2 years in duration. Since the 2011 reorganization of NIST, the director also holds the title of Undersecretary of Commerce for Technology. Fourteen individuals have officially held the position (in addition to four "acting" directors who served on a temporary basis ). They are:
Controversy.
"The Guardian" and the "New York Times" reported that NIST allowed the National Security Agency (NSA) to insert a cryptographically secure pseudorandom number generator called Dual EC DRBG into NIST standard SP 800-90 that had a backdoor that the NSA can use to covertly decrypt material that was encrypted using this pseudorandom number generator. Both papers report that the NSA worked covertly to get its own version of SP 800-90 approved for worldwide use in 2006. The leaked document states that "eventually, NSA became the sole editor". The reports confirm suspicions and technical grounds publicly raised by cryptographers in 2007 that the EC-DRBG could contain an asymmetric backdoor (perhaps placed in the standard by NSA).
NIST responded to the allegations, stating that "NIST works to publish the strongest cryptographic standards possible" and that it uses "a transparent, public process to rigorously vet our recommended standards". The agency stated that "there has been some confusion about the standards development process and the role of different organizations in it...The National Security Agency (NSA) participates in the NIST cryptography process because of its recognized expertise. NIST is also required by statute to consult with the NSA." Recognizing the concerns expressed, the agency reopened the public comment period for the SP800-90 publications, promising that "if vulnerabilities are found in these or any other NIST standards, we will work with the cryptographic community to address them as quickly as possible”.

</doc>
<doc id="21891" url="http://en.wikipedia.org/wiki?curid=21891" title="NATO reporting name">
NATO reporting name

NATO reporting names are code names for military equipment of Russia, China, and, historically, the former Eastern Bloc (Soviet Union and other nations of the Warsaw Pact). They provide unambiguous and easily understood English language words in a uniform manner in place of the original designations — which may have been unknown to the West at the time or easily confused codes.
NATO maintains lists of these names. The assignment of the names for the Russian and Chinese aircraft was once managed by the five-nation Air Standardization Coordinating Committee (ASCC) (now called the Air and Space Interoperability Council, or ASIC, which includes representatives of Australia, Canada, New Zealand, the United Kingdom, and the United States). This is no longer the case.
U.S. variations.
The United States Department of Defense expands on the NATO reporting names in some cases. NATO refers to surface-to-air missile systems mounted on ships or submarines with the same names as the corresponding land-based systems, but the US DoD assigns a different series of numbers with a different suffix (i.e., SA-N- vs. SA-) for these systems. The names are kept the same as a convenience. Where there is no corresponding system, a new name is devised. Some US DoD nomenclature is included in the following pages and is noted as such.
Soviet nicknames.
The Soviet Union did not always assign official “popular names” to its aircraft, although unofficial nicknames were common as in any air force. Generally the Soviet pilots have not used the NATO names, preferring a different, Russian, nickname. An exception was that Soviet airmen appreciated the MiG-29's codename 'Fulcrum' as an indication of its pivotal role in Soviet air defence. Hundreds of names had to be chosen, so the names covered a wide variety of subjects and include some obscure words.
Nomenclature.
To reduce the risk of confusion, unusual or made-up names were allocated, the idea being that the names chosen would be unlikely to occur in normal conversation, and be easier to memorise. For fixed-wing aircraft, single-syllable words denoted piston-prop and turboprop, while multiple-syllable words denoted jets. Bombers had names starting with the letter "B" and names like "Badger" (2 syllables: jet), "Bear" (single syllable: propeller), and "Blackjack" were used. “Frogfoot,” the reporting name for the Sukhoi Su-25, references the aircraft’s close air support role. Transports had names starting with "C" (as in “cargo”), which resulted in names like "Condor" or "Candid".
A fictional NATO reporting name "Firefox" for a fictional "MiG-31" appears in the novel "Firefox" and subsequent movie. The real MiG-31 from 1979 was assigned the reporting name "Foxhound".
Lists of NATO reporting names.
Missiles.
The initial letter of the name indicated the use of that equipment.
Aircraft.
The first letter indicates the type of aircraft, like "B"ear for a bomber aircraft, or "F"ulcrum for a fighter aircraft.
For fixed-wing aircraft, one syllable names were used for propeller-powered craft (turboprops included), while two-syllable names indicated jet engines.

</doc>
<doc id="21892" url="http://en.wikipedia.org/wiki?curid=21892" title="List of NATO reporting names for surface-to-surface missiles">
List of NATO reporting names for surface-to-surface missiles

NATO reporting name for SS series surface-to-surface missiles, with Soviet designations:
U.S. DoD designations for SS-N series naval surface-to-surface missiles (fired from ships and submarines), with Soviet designations:
"See also": NATO reporting name

</doc>
<doc id="21893" url="http://en.wikipedia.org/wiki?curid=21893" title="List of NATO reporting names for air-to-air missiles">
List of NATO reporting names for air-to-air missiles

NATO reporting name for AA series air-to-air missiles, with Soviet designations:
"See also": NATO reporting name

</doc>
<doc id="21894" url="http://en.wikipedia.org/wiki?curid=21894" title="List of NATO reporting names for air-to-surface missiles">
List of NATO reporting names for air-to-surface missiles

NATO reporting name for AS series air-to-surface missiles, with Soviet designations:
Note: the Soviet / Russian designation is a Cyrillic letter "Х", which is translated as "Kh" or "H". Also, sometimes a combination ("complex") of a missile with its aircraft is marked with a letter "K" (for example, a missile Kh-22 with an aircraft is a "complex K-22"). The Cyrillic "X" (read "Kh") in the designation of Soviet ASMs is in fact a Latin "X" ("ecs") for Xperimental, as used by the design bureau. With passing time, however, this was ignored and used in Soviet/Russian as well as foreign literature as the Cyrillic Kh.
"See also": NATO reporting name

</doc>
<doc id="21895" url="http://en.wikipedia.org/wiki?curid=21895" title="List of NATO reporting names for anti-tank missiles">
List of NATO reporting names for anti-tank missiles

NATO reporting name for AT series anti-tank guided missiles, with Soviet designations:
"See also:" NATO reporting name, List of anti-tank guided missiles

</doc>
<doc id="21896" url="http://en.wikipedia.org/wiki?curid=21896" title="List of NATO reporting names for surface-to-air missiles">
List of NATO reporting names for surface-to-air missiles

NATO reporting name for SA series surface-to-air missiles, with Soviet designations:
U.S. DoD designations for SA-N series naval surface-to-air missiles, with Soviet designations. Note that these are not standard NATO names, NATO uses the regular SA series for naval SAMS also, however the US DoD refers to them by these names:
"See also": NATO reporting name

</doc>
<doc id="21897" url="http://en.wikipedia.org/wiki?curid=21897" title="List of NATO reporting names for bomber aircraft">
List of NATO reporting names for bomber aircraft

This is a list of NATO reporting name/ASCC names for bombers, with Soviet designations:

</doc>
<doc id="21898" url="http://en.wikipedia.org/wiki?curid=21898" title="List of NATO reporting names for fighter aircraft">
List of NATO reporting names for fighter aircraft

NATO reporting name/ASCC names for fighters, with Soviet, Russian and Chinese designations.

</doc>
<doc id="21899" url="http://en.wikipedia.org/wiki?curid=21899" title="List of NATO reporting names for helicopters">
List of NATO reporting names for helicopters

Helicopters, NATO/ASCC names:

</doc>
<doc id="21900" url="http://en.wikipedia.org/wiki?curid=21900" title="List of NATO reporting names for transport aircraft">
List of NATO reporting names for transport aircraft

NATO reporting name/ASCC names for transport aircraft and their Soviet, Russian and Chinese designations:
See also.
NATO reporting name

</doc>
<doc id="21901" url="http://en.wikipedia.org/wiki?curid=21901" title="List of NATO reporting names for miscellaneous aircraft">
List of NATO reporting names for miscellaneous aircraft

NATO reporting name/Air Standardization Coordinating Committee (ASCC) names for miscellaneous aircraft, with Soviet designations, sorted by reporting name:
NATO reporting name/ASCC names for miscellaneous aircraft, with Soviet designations, sorted by Soviet designation:

</doc>
<doc id="21904" url="http://en.wikipedia.org/wiki?curid=21904" title="List of NATO reporting names for submarines">
List of NATO reporting names for submarines

This is a list of NATO reporting names for submarines, with Russian and Soviet Navy designations. The names are often derived from the NATO phonetic alphabet.

</doc>
<doc id="21907" url="http://en.wikipedia.org/wiki?curid=21907" title="Seven Laws of Noah">
Seven Laws of Noah

The Seven Laws of Noah (Hebrew: שבע מצוות בני נח‎ "Sheva mitzvot B'nei Noach"), or the Noahide Laws, are a set of moral imperatives that, according to the Talmud, were given by God as a binding set of laws for the "children of Noah" – that is, all of humanity.
Accordingly, any non-Jew who adheres to these laws is regarded as a "righteous gentile", and is assured of a place in the world to come (Hebrew: עולם הבא‎ "Olam Haba"), the final reward of the righteous.
The seven Noahide laws as traditionally enumerated are:
According to the Talmud, the rabbis agree that the seven laws were given to the sons of Noah. However, they disagree on precisely which laws were given to Adam and Eve. Six of the seven laws are exegetically derived from passages in Genesis, with the seventh being the establishing of courts.
Sources.
Torah.
According to the Genesis flood narrative, a deluge covered the whole world, killing every surface-dwelling creature except Noah, his wife, his sons and their wives, and the animals taken aboard Noah's Ark. According to this, all modern humans are descendants of Noah, thus the name Noahide Laws in reference to laws that apply to all of humanity. After the flood, God sealed a covenant with Noah with the following admonitions ():
Book of Jubilees.
The Book of Jubilees, generally dated to the 2nd century BCE, may include an early reference to Noahide Law at verses 7:20–28:
And in the twenty-eighth jubilee Noah began to enjoin upon his sons' sons the ordinances and commandments, and all the judgments that he knew, and he exhorted his sons to observe righteousness, and to cover the shame of their flesh, and to bless their Creator, and honour father and mother, and love their neighbour, and guard their souls from fornication and uncleanness and all iniquity. For owing to these three things came the flood upon the earth ... For whoso sheddeth man's blood, and whoso eateth the blood of any flesh, shall all be destroyed from the earth.
Acts 15.
The Jewish Encyclopedia article on Saul of Tarsus states:
According to Acts, Paul began working along the traditional Jewish line of proselytizing in the various synagogues where the proselytes of the gate [e.g., ] and the Jews met; and only because he failed to win the Jews to his views, encountering strong opposition and persecution from them, did he turn to the Gentile world after he had agreed at a convention with the apostles at Jerusalem to admit the Gentiles into the Church only as proselytes of the gate, that is, after their acceptance of the Noachian laws ()".
The article "New Testament" states:
For great as was the success of Barnabas and Paul in the heathen world, the authorities in Jerusalem insisted upon circumcision as the condition of admission of members into the church, until, on the initiative of Peter, and of James, the head of the Jerusalem church, it was agreed that acceptance of the Noachian Laws — namely, regarding avoidance of idolatry, fornication, and the eating of flesh cut from a living animal — should be demanded of the heathen desirous of entering the Church.
The Apostolic Decree of the Council of Jerusalem resolved this early Christian dispute by commending that gentiles obey Noahide law () rather than to live under the same dictates as Torah-observant Jews and be circumcised (cf. , ).
Tosefta.
The earliest recorded of the seven laws can be found in the Tosefta here they are listed as follows.
Seven commandments were commanded of the sons of Noah:
Halakha and the Seven Laws.
Talmud.
According to the Talmud, the Noachide Laws apply to all humanity through humankind's descent from one paternal ancestor, the head of the only family to survive The Flood, who in Hebrew tradition is called Noah. In Judaism, בני נח "B'nei Noah" (Hebrew, "Descendants of Noah", "Children of Noah") refers to all of humankind. The Talmud also states: "Righteous people of all nations have a share in the world to come". Any non-Jew who lives according to these laws is regarded as one of "the righteous among the gentiles".
The rabbis agree that the seven laws were given to the sons of Noah. However, they disagree on precisely which laws were given to Adam and Eve. Six of the seven laws are exegetically derived from passages in Genesis. The Talmud adds extra laws beyond the seven listed in the Tosefta which are attributed to different rabbis, such as the grafting of trees and sorcery among others,:30–31 Ulla going so far as to make a list of 30 laws. The Talmud expands the scope of the seven laws to cover about 100 of the 613 mitzvoth.:18
Punishment.
In practice Jewish law makes it very difficult to apply the death penalty. No record exists of a gentile having been put to death for violating the seven laws. Some of the categories of capital punishment recorded in the Talmud are recorded as having never have been carried out. Nor ever to be carried out. It is thought that the rabbis including discussion of them in anticipation of the coming messianic age.
The Talmud lists the punishment for blaspheming the Ineffable Name of God as death. The sons of Noah are to be exclusively executed by decapitation, considered one of the lightest capital punishments. In Jewish law the only form of blasphemy which is punishable by death is blaspheming the Ineffable Name . Some Talmudic rabbis held that only those offences for which a Jew would be executed, are forbidden to gentiles. The Talmudic rabbis discuss which offences and sub-offences are capital offences and which are merely forbidden.
Maimonides states that anyone who does not accept the seven laws is to be executed. As God compelled the world to follow these laws. However, for the other probations such as the grafting of trees and bestiality he holds that the sons of Noah are not to be executed. Maimonides adds a universalism lacking from earlier Jewish sources.:18 The Talmud differs from Maimonides in that it handles the seven laws as enforceable by Jewish authorities on non-Jews living within a Jewish nation.:18 Nahmanides disagrees with Maimonides reasoning. He limits the obligation of enforcing the seven laws to non-Jewish authorities taking the matter out of Jewish hands. The Tosafot seems to agree with Nahmanides reasoning.:39 According to some opinions, punishment is the same whether the individual transgresses with knowledge of the law or is ignorant of the law.
Subdividing the Seven Laws.
Various rabbinic sources have different positions on the way the seven laws are to be subdivided in categories. Maimonides', in his Mishneh Torah, included the grafting of trees. Like the Talmud he interpreted the prohibition against homicide as including a prohibition against abortion. Rabbi David ben Solomon ibn Abi Zimra, a commentator on Maimonides, expressed surprise that he left out castration and sorcery which were also listed in the Talmud.
In Chullin 92a-b Ulla say that here are 30 laws which the sons of Noah took upon themselves. However he only lists three. Namely the three that the Gentiles follow, not to create a Ketubah between males, not to sell carrion in the market and to respect the Torah. The rest of the laws are not listed. Talmud commentator Rashi remarks on this that he does not know the other Commandments that are referred to. Though the authorities seem to take it for granted that Ulla's thirty commandments included the original seven, an additional thirty laws is also possible from the reading. Two different lists of the 30 laws exist. Both lists include an additional twenty-three mitzvot which are subdivisions or extensions of the seven laws. One from the 16th-century work "Asarah Maamarot" by Rabbi Menahem Azariah da Fano and a second from the 10th century Samuel ben Hofni which was recently published from his Judeo-Arabic writings after having been found in the Cairo Geniza. Rabbi Zvi Hirsch Chajes suggests Menahem Azariah of Fano enumerated commandments are not related to the first seven, nor based on Scripture, but instead were passed down by oral tradition.
The 10th-century Rabbi Saadia Gaon added tithes and levirate marriage. The 11th-century Rav Nissim Gaon included "listening to God's Voice", "knowing God" and "serving God" besides going on to say that all religious acts which can be understood through human reasoning are obligatory upon Jew and Gentile alike. The 14th-century Rabbi Nissim ben Reuben Gerondi added the commandment of charity.
Ger toshav (resident alien).
In earlier times, a Gentile living in the Land of Israel who accepted the Seven Laws in front of a rabbinical court was known as a "ger toshav" (literally stranger/resident). Jewish law recognizes a Biblical obligation to help a "ger toshav" in time of need (as opposed to the rabbinic obligation help all Gentiles who live among Jews.) The regulations regarding Jewish-Gentile relations are modified in the case of a "ger toshav". Jewish law only allows the official acceptance of a "ger toshav" as a resident in the Land of Israel during a time when the Year of Jubilee ("yovel") is in effect.
Contemporary status.
Historically, some rabbinic opinions consider non-Jews not only not obliged to adhere to all the remaining laws of the Torah, but actually forbidden to observe them.
Noachide law differs radically from Roman law for gentiles ("Jus Gentium"), if only because the latter was enforceable judicial policy. Rabbinic Judaism has never adjudicated any cases under Noachide law, Jewish scholars disagree about whether Noachide law is a functional part of Halakha ("Jewish law").
Some modern views hold that penalties are a detail of the Noahide Laws and that Noahides themselves must determine the details of their own laws for themselves. According to this school of thought – see N. Rakover, "Law and the Noahides" (1998); M. Dallen, "The Rainbow Covenant" (2003) – the Noahide Laws offer mankind a set of absolute values and a framework for righteousness and justice, while the detailed laws that are currently on the books of the world's states and nations are presumptively valid.
In recent years, the term "Noahide" has come to refer to non-Jews who strive to live in accord with the seven Noachide Laws; the terms "observant Noahide" or "Torah-centered Noahides" would be more precise but are infrequently used. Support for the use of Noahide in this sense can be found with the Ritva, who uses the term "Son of Noah" to refer to a Gentile who keeps the seven laws, but is not a Ger Toshav. The rainbow, referring to the Noachide or First Covenant (Genesis 9), is the symbol of many organized Noahide groups, following .
Maimonides.
The Jewish scholar Maimonides (12th century) held that Gentiles may have a part in the world to come just by observing Noahide law. He writes in his book of laws:"
Anyone who accepts upon himself and carefully observes the Seven Commandments is of the Righteous of the Nations of the World and has a portion in the World to Come. This is as long as he accepts and performs them because (he truly believes that) it was the Holy One, Blessed Be He, Who commanded them in the Torah, and that it was through Moses our Teacher we were informed that the Sons of Noah had already been commanded to observe them. But if he observes them because he convinced himself, then he is not considered a Resident Convert and is not of the Righteous of the Nations of the World, but merely one of their wise.
Some later editions of the Mishneh Torah differ by one letter and read "Nor one of their wise men." The later reading is narrower. Spinoza read Maimonides as using nor and accused him of being narrow and particularistic. Other philosophers such as Hermann Cohen and Moses Mendelssohn have used more inclusive interpretations of the passage by Maimonides.
In either reading, Maimonides appears to exclude philosophical Noahides from being Righteous Gentiles. Thus Maimonides wants to emphasis that a truly Righteous Gentile follows the seven laws because they are divinely revealed and thus are followed out of obedience to God.
Christianity and the Noahide Laws.
The Apostolic Decree recorded in Acts 15 is commonly seen as a parallel to Noahide Law; however, some modern scholars dispute the connection between Acts 15 and Noahide Law, the content of Noahide Law, the historical reliability of the Acts of the Apostles, and the nature of Biblical law in Christianity. The Apostolic Decree is still observed by Orthodox Christianity and includes some food restrictions.
The only Noahide law that is not part of the standard moral teaching of mainstream Christianity is the prohibition against eating the flesh of an animal while it is still alive. Many interpret Acts and the Pauline Epistles as making void the dietary laws found in the Torah and known by Noah ( and ). This claim is disputed by many Christians, including the Ethiopian Orthodox Tewahedo Church, the Seventh-day Adventist Church, the Church of God (Seventh Day).
The 18th-century rabbi Jacob Emden proposed that Jesus, and Paul after him, intended to convert the gentiles to the Noahide laws while allowing the Jews to follow the full Law of Moses.
Chabad movement.
Maimonides rules that Moses was commanded by God to compel the world to accept these seven commandments. For many centuries, however, the circumstances did not allow this to be done. But in 1983, rabbi Menachem M. Schneerson said it was time to revitalize this long-dormant aspect and role of the Jewish people. In 1987, President Ronald Reagan signed a proclamation speaking of "the historical tradition of ethical values and principles, which have been the bedrock of society from the dawn of civilization when they were known as the Seven Noahide Laws, transmitted through God to Moses on Mount Sinai," and in 1991, Congress did the same.
Sefer Sheva Mitzvot Hashem: A Shulchan Aruch for Gentiles.
Menachem Mendel Schneerson, rebbe of Chabad Lubavitch, started his Noahide Campaign in the 1980s. A codification of the exact obligations of the Gentiles in the spirit of the classical Shulchan Aruch was needed. In 2005 the scholar Rabbi Moshe Weiner of Jerusalem accepted to produce an in-depth codification of the Noahide precepts. The work is called Sefer Sheva Mitzvot HaShem, (The Book of Seven Divine Commandments) published 2008/2009. As it was approved by both of the then presiding Chief Rabbis of Israel, rabbi Shlomo Moshe Amar and rabbi Yonah Metzger, as well as other Hasidic and non-Hasidic halachic authorities, it can claim an authoritative character and is referred as a "Shulchan Aruch" for Gentiles at many places.
Public recognition.
United States Congress.
The Seven Laws of Noah were recognized by the United States Congress in the preamble to the 1991 bill that established Education Day in honor of the birthday of rabbi Menachem Mendel Schneerson, the leader of the Chabad movement:
Whereas Congress recognizes the historical tradition of ethical values and principles which are the basis of civilized society and upon which our great Nation was founded; Whereas these ethical values and principles have been the bedrock of society from the dawn of civilization, when they were known as the Seven Noahide Laws.
Israeli Druze.
In January 2004, Sheikh Mowafak Tarif, the spiritual leader of Israeli Druze, signed a declaration, which called on non-Jews living in Israel to observe the Noahide Laws. He was joined by the mayor of Shefa-'Amr.
Further reading.
The second edition now online at: http://www.scribd.com/my_document_collections/3551340

</doc>
<doc id="21911" url="http://en.wikipedia.org/wiki?curid=21911" title="Naturism">
Naturism

Naturism, or nudism, is a cultural and political movement practicing, advocating and defending social nudity, most but not all of which takes place on private property. The term may also refer to a lifestyle based on personal, family and/or social nudism.
Definition.
According to the XIV Congress of the International Naturist Federation (Agde, France, 1974), naturism is:
Several other terms ("social nudity", "public nudity", "skinny dipping", "sunning", and "clothes-free") have been proposed as alternative terms for naturism, but none has found the same widespread public acceptance as the older terms "naturism" and (in much of the United States) "nudism".
People interested in social nudity can attend clothes-free beaches and other types of ad-hoc nudist events. At these venues, participants generally need not belong to a naturist club.
Many contemporary naturists and naturist organisations feel that the practice of social nudity should be asexual. For various social, cultural, and historical reasons the lay public, the media, and many contemporary naturists and their organisations often oversimplify the relationship between naturism and sexuality. Current research has begun to explore this complex relationship.
The International Naturist Federation explains:
The usage and definition of these terms varies geographically and historically. Though in the United States, naturism and nudism have the same meaning, in Britain there is a clear distinction.
 Nudism is the "act of being naked", while naturism is a "lifestyle" which at various times embraced nature, environment, respect for others, self-respect, crafts, healthy eating, vegetarianism, teetotalism, non-smoking, yoga, physical exercise and pacifism as well as nudity.
In naturist parlance, "textile" or "textilist" is a non-naturist person, non-naturist behaviour or non-naturist facilities. e.g. "the textile beach starts at the flag", "they are a mixed couple – he is naturist, she is textile". "Textile" is the predominant term used in the UK ('textilist' is unknown in British naturist magazines including "H&E naturist"), although some naturists avoid it due to perceived negative or derogatory connotations. "Textilist" is said to be used interchangeably, but no dictionary definition to this effect exists, nor are there any equivalent examples of use in mainstream literature such as those for "textile". "Clothing optional" and "nude optional" (US specific) describe a policy or a venue that allows or encourages nudity but tolerates the wearing of clothes. The opposite is "clothing compulsory"; that is, prohibiting nudity. Adjectival phrases "clothes free" and "clothing free" prescribe where naturism is permitted in an otherwise textile environment, or define the preferred state of a naturist.
The social nudity movement includes a large range of variants including "naturism", "nudism", "Freikörperkultur (FKK)", the "free beach movement" as well as generalized "public lands/public nudity" advocacy. There is a large amount of shared history and common themes, issues and philosophy, but differences between these separate movements remain contentious.
Types of naturism.
Naturism is practised in many ways: Marc Alain Descamps, in his study written in French, classified the types as: individual nudism, nudism within family, nudism in the wild, social nudism. Additionally, militant nudism, including campaigning or extreme naturists, is sometimes considered a separate category.
Personal and family nudity.
Many people are often nude in the privacy of their home or garden, either alone or with members of the family. This may be occasional nudity or as a naturist lifestyle. There are differences of opinion as to whether, and if so to what extent, parents should appear naked in front of their children, and whether children should be nude within the home in the view of their family as well as visitors. This has attracted a great deal of academic study.
A United States study by Alfred Kinsey, (1948-1953) found that 75% of the participants stated that there was never nudity in the home when they were growing up, 5% of the participants said that there was "seldom" nudity in the home, 3% said "often", and 17% said that it was "usual". The study found that there was no significant difference between what was reported by men and by women with respect to frequency of nudity in the home.
Gordon and Schroeder in 1995 reported that parental nudity varies considerably from family to family. They say that "there is nothing inherently wrong with bathing with children or otherwise appearing naked in front of them", noting that doing so may provide an opportunity for parents to provide important information. They note that by ages 5 to 6 children begin to develop a sense of modesty, and recommend to parents who wish to be sensitive to their children's wishes that they limit such activities from that age onwards.
Barbara Bonner in 1999, cautions against nudity in the home if children exhibit sexual play of a type that is considered problematic.
In a 1995 review of the literature, Paul Okami concluded that there was no reliable evidence linking exposure to parental nudity to any negative effect. Three years later, his team finished an 18-year longitudinal study that showed that, if anything, such exposure was associated with slight beneficial effects, particularly for boys.
Social nudism.
The rhetoric of the nudism and anti-nudism movements emphasizes freedom from many of the normal constraints which regulate human interaction in nudist settings, although for different reasons. Using data from French and German beaches, this hypothesis was tested using five different indicators. Little significant variation between nudists and non-nudists within French and German settings is found in their patterns of interactional spacing, while more significant main effects for differences of cultures are found regardless of nudity status. As a subculture, nudists would appear to differ from nonnudists only in their propensity to like to sunbathe in the nude. Their nude status would appear to have none of the de-inhibiting effects often attributed to nudism. By contrast, clear cultural differences between German and French cultures are shown consistent with Hall's high-low context distinction and the Francoeurs' hot-cool sexuality continuum.
Naturist facilities.
At naturist organised events or venues clothing is usually optional, except by swimming pools or sunbathing lawns where complete nudity is expected, weather permitting. This rule is sometimes a source of controversy among some naturists. Staff at a naturist facility are usually required to be clothed due to health and safety regulations.
Facilities for naturists are classified in various ways. A landed or members' naturist club is one that owns its own facilities, while non-landed (or travel) clubs meet at various locations, such as private residences, swimming pools, hot springs, landed clubs and resorts, and rented facilities. Landed clubs can be run by members on democratic lines or by one or more owners who make the rules. In either case, they can determine membership criteria and the obligations of members. This usually involves sharing work necessary to maintain or develop the site.
Some clubs have stricter entrance requirements than some traditional 'country clubs', including the requirement to supply references, a sponsoring member, a trial membership, committee approval and/or, criminal background checks. UK clubs are now required to have child-protection policies in place, and designated child-protection officers. Many clubs promote frequent social activities.
The international naturist organizations were mainly composed of representatives of landed clubs. Nudist colony is no longer a favored term, but it is used by naturists as a term of derision for landed clubs that have rigid non-inclusive membership criteria, and in meta-data on naturist websites.
A holiday centre is a facility that specializes in providing apartments, chalets and camping pitches for visiting holidaymakers. The center is run commercially, and visitors are not members and have no say in the management. Most holiday centers expect visitors to hold an INF card, that is, be a member of their national organization, but some have relaxed this restriction, relying on the carrying of a trade card. Holiday centers can be quite small, just a couple of hectares or large occupying over 300 hectares. In a large holiday centre there will be swimming pools, sports pitches, an entertainment program, kids' clubs, restaurants and supermarkets. Some holiday centres allow regular visitors to purchase their own chalets, and generations of the same families will visit each year. Holiday centres are more tolerant of clothing than members-only clubs; total nudity is usually compulsory in the swimming pools and may be expected on the beaches, while on the football pitches, or in the restaurants in the evening, it is rare.
A naturist resort is, to a European, an essentially urban development where naturism is the norm. Cap d'Agde in France, naturist village Charco del Palo on Lanzarote, Canary Islands, Vera Playa in Spain and Vritomartis in Greece are examples. Some residents use these resorts as a year-round home.
In US usage, a naturist resort can mean a holiday centre.
Freikörperkultur (FKK) literally translated as 'free body culture' is the name for the general movement in Germany. The abbreviation is widely recognised all over Europe and often found on informal signs indicating the direction to a remote naturist beach.
Nude beaches.
Clothing is optional at nude beaches (or "free beaches"). A feature of bathing on a nude beach is the anonymity it offers, with membership of a club not being required, nor detailed application processes, nor pre-booking of visits.
In some European countries, such as Denmark, all beaches are clothing optional, while in others like Germany there are also naturist sunbathing areas in public parks, e.g., in Munich and Berlin. Beaches in some holiday destinations, such as Crete, are also clothing-optional, except some central urban beaches. There are two centrally located clothes-optional beaches in Barcelona.
Naturism and sports.
Naturism encourages a healthy life style, and many naturist clubs at times organize and encourage members to take part in local and international sport events and competitions. The German Association for Free Body Culture (DFK) promotes recreational sports and is a member of the German Olympic Sport Federation (DOSB).
Festival naturism.
From Woodstock to Edinburgh, and Nambassa in the southern hemisphere communal nudity is commonly recorded at music and counterculture festivals.
The series of 1970s Nambassa hippie festivals held in New Zealand is a further example of non sexualized naturism. Of the 75,000 patrons who attended the 1979 Nambassa 3 day counterculture Festival an estimated 35% of festival attendance spontaneously chose to remove their clothing, preferring complete or part nudity.
History.
Nudity in social contexts has been practised in various forms by many cultures at all time periods. In Western society nowadays, social nudity is most frequently encountered in the contexts of bathing, swimming and in saunas, whether in single-sex groups, within the family or with mixed-sex friends, but throughout history and in many tropical cultures till now, nudity is a norm at many sports events and competitions.
It is difficult to nominate exactly when naturism started as a movement. The word 'naturism' was used for the first time in 1778 by a French-speaking Belgian, Jean Baptiste Luc Planchon (1734–1781), and was advocated as a means of improving the 'l’hygiène de vie' (natural style of life) and health.
The earliest known naturist club in the "western" sense of the word was established in British India in 1891. The 'Fellowship of the Naked Trust' was founded by Charles Edward Gordon Crawford, a widower, who was a District and Sessions Judge for the Bombay Civil Service. The commune was based in Matheran and had just three members at the beginning; Crawford and two sons of an Anglican missionary, Andrew and Kellogg Calderwood.
The commune fell apart when Crawford was transferred to Ratnagiri; he died soon after in 1894.
In 1902, a series of philosophical papers was published in Germany by Dr. Heinrich Pudor, under the pseudonym Heinrich Scham, who coined the term "Nacktkultur". In 1906 he went on to write a three volume treatise with his new term as its title, which discussed the benefits of nudity in co-education and advocated participating in sports while being free of cumbersome clothing. Richard Ungewitter ("Nacktheit", 1906, "Nackt", 1908, etc.) proposed that combining physical fitness, sunlight, and fresh air bathing, and then adding the nudist philosophy, contributed to mental and psychological fitness, good health, and an improved moral-life view. Major promoters of these ideas included Adolf Koch and Hans Suren. Germany published the first journal of nudism between 1902 and 1932.
The wide publication of those papers and others, contributed to an explosive worldwide growth of nudism, in which nudists participated in various social, recreational, and physical fitness activities in the nude. The first organized club for nudists on a large scale, "Freilichtpark" (Free-Light Park), was opened near Hamburg in 1903 by Paul Zimmerman.
In 1919, German doctor Kurt Huldschinsky discovered that exposure to sunlight helped to cure rickets in many children, causing sunlight to be associated with improved health.
Naturism became a more widespread phenomenon in the 1920s, in Germany, the United Kingdom, France and other European countries and spread to the United States where it became established in the 1930s.
By 1951, the national federations united to form the International Naturist Federation or INF. Some naturists preferred not to join clubs, and after 1945, pressure was put to designate beaches for naturist use.
From the middle of the 20th century, with changing leisure patterns, commercial organisations began opening holiday resorts to attract naturists who expected the same – or better – standards of comfort and amenity offered to non-naturists. More recently, naturist holiday options have expanded to include cruises.
Philosophy.
Naturism had many different philosophical sources and means many things to different people. There is no one definition. In 1974, the INF defined naturism as:
At one end of the spectrum are the nudists who just enjoy a nude life style, and at the other are the naturists, who have deeply held beliefs and see communal nudity as just one of many important principles.
The naturist philosophy has several sources, many of which can be traced back to early 20th century health and fitness philosophies in Germany and England, although the concepts of returning to nature and creating equality have much deeper roots.
Naturist ideals.
Individuals have formed naturist groups for a variety of specific purposes. It is generally agreed by naturist organisations that eroticism and blatant sexuality have no place in naturism and are, in fact, antithetical to its ideals. Reasons that have at times been given:
Naturism and the romantics.
Walt Whitman American writer, A Sun-bathed Nakedness:
Never before did I get so close to Nature; never before did she come so close to me... Nature was naked, and I was also... Sweet, sane, still Nakedness in Nature! - ah if poor, sick, prurient humanity in cities might really know you once more! Is not nakedness indecent? No, not inherently. It is your thought, your sophistication, your fear, your respectability, that is indecent. There come moods when these clothes of ours are not only too irksome to wear, but are themselves indecent.
Henry David Thoreau, "In wildness is the preservation of the world.", Walking:
We cannot adequately appreciate this aspect of nature if we approach it with any taint of human pretense. It will elude us if we allow artifacts like clothing to intervene between ourselves and this Other. To apprehend it, we cannot be naked enough.
Naturism was part of a literary movement in the late 1800s (see the writings of André Gide) which also influenced the art movements of the time specifically Henri Matisse and other Fauve painters. This movement was based on the French concept of joie de vivre, the idea of revelling freely in physical sensations and direct experiences and a spontaneous approach to life.
Naturism for health.
Sunlight has been shown to be beneficial in some skin conditions and enables the body to make vitamin D, but with the increased awareness of skin cancer, wearing of sunscreen is now part of the culture.
Naturism in Europe.
France.
In 1903 la "Revue des deux mondes" published a report on German naturism and S. Gay created a naturist community at Bois-Fourgon. In 1907, supported by his superiors, Abbé Legrée encouraged the students at his catholic college to bathe nude on the rocky beaches near Marseille.
Marcel Kienné de Mongeot is credited with starting naturism in France in 1920. His family had suffered from tuberculosis, and he saw naturism as a cure and a continuation of the traditions of the ancient Greeks. In 1926, he started the magazine "Vivre intégralement" (later called "Vivre") and the first French naturist club, "Sparta Club" at Garambouville, near Evreux. The court action that he initiated, established that nudism was legal on private property that was fenced and screened.
Drs. André and Gaston Durville bought a 70 hectare site on the Île du Levant where they established the village of Héliopolis. The village was open to the public. In 1925 Dr François Fougerat de David de Lastours wrote a thesis on heliotherapy. and in that year opened the "Club gymnique de France". In 1936, the naturist movement was officially recognised.
Albert and Christine Lecocq were active members of many of these clubs, but after disagreements left and In 1944 Albert and Christine Lecocq founded the "Club du Soleil" with members in 84 cities. In 1948 they founded the , in 1949 they started the magazine, "Vie au Soleil" and in 1950 opened the CHM Montalivet, the world's first naturist holiday centre where the INF was formed.
The Quartier Naturiste at Agde offers a different form of social nudity. Euronat is the largest holiday centre (335ha) situated 10 km north of Montalivet. Naturism employs more than 3000 people, and is estimated to be worth 250 million Euro to the French economy. France is represented on the INF by the .
Germany.
German naturism was part of the Lebensreform movement and the Wandervogel youth movement of 1896, from Steglitz, Berlin which promoted ideas of fitness and vigour. At the same time doctors of the were using heliotherapy, treating diseases such as TB, rheumatism and scrofula with exposure to sunlight.
Nacktkultur, a term coined in 1903 by Heinrich Pudor, flourished. Nacktkultur connected nudity, vegetarianism and social reform. It was practised in a network of 200 members clubs. The movement gained prominence in the 1920s as offering a health giving life-style with Utopian ideals. Germany published the first naturist journal between 1902 and 1932.
It became politicised by radical socialists who believed it would lead to classlessness and a breaking down of society. It became associated with pacificism.
In 1926, Adolf Koch established a school of naturism in Berlin; encouraging a mixing of the sexes, open air exercises, and a programme of "sexual hygiene". In 1929, the Berlin school hosted the first International Congress on Nudity.
During the National Socialist "Gleichschaltung" era, all naturist clubs had to register with the "Reichsbund für Leibesübungen", which meant excluding Jews and Communists. Also, they had to keep all activities hidden in the countryside where there was little chance of being seen by others. The status as a West German "sports federation" member gave the clubs rights and privileges (e.g. tax exemptions) so the naturist clubs remained in the federation after the war had ended.
After the war, East Germans were free to practice naturism, chiefly at beaches rather than clubs (private organizations being regarded as potentially subversive). Naturism became a large element in DDR politics. The "Proletarische Freikörperkulturbewegung" subsection of the Workers Sports Organisation had 60,000 members.
Today, following reunification there are many clubs, parks and beaches open to naturists.
though nudity has become less common in the former eastern zone. Germans are typically the most commonly seen foreigners at nude beaches in France and around Europe.
Poland.
First reported naturist society was established in 1897 in Grudziądz. In pre-war and post-war Poland, naturism was practised in closed and secluded areas. Reported places for naturism were Zaleszczyki (in today's Ukraine) and Otwock. Under the communism regime, Poland's naturism became unofficial and was practiced mostly by the artistic boheme near Krynica Morska, Międzyzdroje and Dębki.
In the early 1980s naturism became popular mostly due to increased interest in media. As the pop song "Chałupy Welcome To" (about the naturist beach in Chałupy, featuring beach nudity in the clip) became the 1985 summer hit in Poland, the nude seaside locations like Chałupy or Rowy became known to an average Polish sunbather. Polish Naturist Society was formed and after the number of lawsuits, naturism became tolerated in selected "unofficial" beaches and distant spots.
In today's Poland naturism is practiced in number of the seaside and inland beaches. Most Polish beaches are actually clothes-optional rather than naturist. Among the most popular locations are Międzydroje-Lubiewo, Grzybowo, Rowy, Dębki, Gdańsk-Stogi and Piaski. The most popular inland locations include Warsaw (Wał Miedzeszyński), Kazimierz Dolny and Kryspinów near Kraków. In the winter season, naturism is practiced by organized groups in Warsaw and Tri-City. Public naturist events are held bi-monthly in Poznań-Koziegłowy and Łódź waterpark.
Portugal.
Naturism in Portugal had its first historical record around 1920, linked to the Portuguese Naturist Society, of which the anarcho-syndicalist José Peralta was a prominent member. Nudity was already being practiced on Costa da Caparica beaches. With the beginning of the New State authoritarian regime in the 1930s, the naturist movement was limited to vegetarian and alternative medicines, since nudity was banned and associated to the crime of "indecency". Only after the end of the New State regime in 1974 (April, 25th) the activities linked to the practice of nudity were resumed.
The "Federação Portuguesa de Naturismo" (Portuguese Naturist Federation) or FPN was founded on the March 1st, 1977, at a meeting in Lisbon.
At the present, there are seven official naturist beaches in Portugal. Besides these, there are several dozens of beaches were the practice of naturism is common. There are also several naturist campings and resorts.
Spain.
Public nudity on the beach is not illegal in Spain.
For nudity lovers, Spain offers various options for nude sunbathing. In addition to the long sandy beaches in the vicinity of large cities, topless sunbathing is possible on beaches in front of smaller villages. Hidden from view, nude sunbathing is always nice between the rocks of little coves besides the urbanisations.
United Kingdom.
In the United Kingdom, the first official nudist club was established in Wickford, Essex in 1924. According to Michael Farrar, writing for British Naturism the club adopted the name "Moonella Group" from the name of the owner of the ground, "Moonella", and called its site The Camp. Moonella, who was still living in 1965 but whose identity remains to be discovered, had inherited a house with land in 1923 and made it available to certain members of the New Gymnosophy Society. This society had been founded a few years before by H.C. Booth, M.H. Sorensen and Rex Wellbye under the name of the English Gymnosophical Society. It met for discussions at the Minerva Cafe at 144 High Holborn in London, the headquarters of the Women's Freedom League. Those who were permitted to join the Moonella Group were carefully selected, and the club was run by an "aristocracy" of the original members, all of whom had "club names" to preserve their anonymity. The club closed in 1926 because of building on adjacent land.
By 1943 there were a number of these so-called "sun clubs" and together they formed the British Sun Bathers Association or BSBA. In 1954 a group of clubs unhappy with the way the BSBA was being run split off to form the Federation of British Sun Clubs or FBSC. In 1961, the BSBA Annual Conference agreed that the term nudist was inappropriate and should be discarded in favour of naturist. The two organisations rivalled each other before eventually coming together again in 1964 as the Central Council for British Naturism or CCBN. This organisation structure has remained much the same but it is now called British Naturism which is often abbreviated to BN. BN is currently converting to a company limited by guarantee.
The first official nude beach was opened at Fairlight Glen in Covehurst Bay near Hastings in 1978 (not to be confused with Fairlight Cove, which is 2 km to the east) followed later by the beaches at Brighton and Fraisthorpe. Bridlington opened in April 1980.
Naturism in North America.
Canada.
In Canada, individuals around the country became interested in nudism, skinny-dipping, and physical culture in the early part of the 20th century. After 1940 they had their own Canadian magazine, "Sunbathing & Health", which occasionally carried local news. Canadians had scattered groups in several cities during the 1930s and 1940s, and some of these groups attracted enough interest to form clubs on private land. The most significant clubs were the Van Tan Club, formed in 1939, and continues today in North Vancouver, BC., and, in Ontario, the Sun Air Club.
Canadians who served in the military during the Second World War met like-minded souls from across the country, and often visited clubs while in Europe. They were a ready pool of recruits for post-war organizers. A few years later, the wave of post-war immigration brought many Europeans with their own extensive experience, and they not only swelled the ranks of membership, but often formed their own clubs, helping to expand nudism from coast to coast.
Most of those clubs united in the Canadian Sunbathing Association, which affiliated with the American Sunbathing Association in 1954. Several disagreements between eastern and western members of the CSA resulted in the breakup of CSA into the Western Canadian Sunbathing Association (WCSA) and the Eastern Canadian Sunbathing Association (ECSA) in 1960. The ECSA endured much in-fighting over the next decade and a half, leading to its official demise in 1978. The WCSA continues today as the American Association for Nude Recreation – Western Canadian Region (www.aanr-wc.com), a region of the American Association for Nude Recreation (AANR) which itself was formerly known as the ASA.
In 1977 the Fédération québécoise de naturisme (FQN) was founded in Quebec, by Michel Vaïs, who had experienced European naturism at Montalivet. In 1985 the Federation of Canadian Naturists (FCN) was formed with the support of the FQN. In 1988 the FQN and FCN formed the FQN-FCN Union as the official Canadian representative in the International Naturist Federation (INF).
United States.
In 1925, Katherine and Herman Shoshinki were familiar with nudism from Germany from 1918 to 1923. Kurt Barthel founded the American League for Physical Culture in 1929 and organized the first nudist event. In about 1930 they organized the American Gymnosophical Association. Barthel founded America's first official nudist camp, Sky Farm in New Jersey, in May, 1932. Around 1932, AGA established the Rock Lodge Club as a nudist facility in Stockholm, New Jersey and Ilsley Boone, a Dutch Reformed minister, formed the Christian naturism movement. Naturism began expanding nationwide. Nudism venues were teetotal until 1970, The American Association for Nude Recreation (AANR) is the national naturist organisation. Arnd Krüger compared nudists in Germany and the United States and came to the conclusion that in Germany the racial aspects ("Zuchtwahl") were important for the breakthrough (e.g. the Commanding General of the Army served as patron for nudists events), while in the U.S. nudism was far more commercial and had thus more difficulties.
In 2009, a campaign to promote Nudism in the United States occurred with an effort by AANR to record the largest simultaneous Skinny Dip at several U.S. Clubs and beaches, occurring on July 11 of that year.
There are two nudist or naturist magazines are published in the United States—NUDE & NATURAL, more commonly known as "N" magazine from The Naturist Society, and "Naturally" magazine from Internaturally.
The AANR withdrew from the INF in 2010, claiming it was too eurocentric.
Naturism in Asia.
Overall, public nudity in Asia is not tolerated although some traditional, cultural or religious nudity has survived the introduction of Western moral values against nudity, such as the Jain Digambara monks in India, hot springs in Taiwan and Japan and some traditional tribes in Papua. Nudism and naked recreation is slowly developing in some countries, mainly Indonesia (Bali) and Thailand. Nudists meet on the internet (e.g. Bareskinasia.com) and organize activities in remote or private locations. Several nudists also have their own blogs.
Indonesia.
In the seventies, nudity on Bali's remote and deserted beaches was common but with the massive growth of tourism, those beaches disappeared little by little and in 2002 nudity became illegal on the last beach in Seminyak that tolerated discreet nudity (Petitenget Beach). As a result, nudity started developing in private villas and resorts, first for gay men only (Laki Uma Villa) and in 2004 the first adult-only nudist resort for both genders "Bali au Naturel" opened its doors and expanded from 3 to 15 rooms, from one to three swimming pools.
Nepal.
Nudism is not exactly illegal in Nepal but is surely unacceptable to the society. People in Nepal do not practice nudism at all. Although there are no laws concerning it, people may be detained or arrested and fined for public nudity. Nudism is considered taboo in Nepal. Nevertheless, many Hindu (male) sages practice nudism and they are not bothered. Nudist sages can be seen in Pashupatinath.
Thailand.
Nudism was successfully introduced in Pattaya (Chan Resort and more recently La Sala Villa) and several other small nudist resorts were created all over Thailand. A gay hotel and sauna (Sansuk Hotel) located in Pattaya now also authorizes nudity in and around the swimming pool.
Issues in social nudity.
Naturism addresses, challenges and explores a myriad of sometimes taboo subjects: stereotypes and mores relating to the nude appearance of the human body, mixed sex nudity, personal space, human sexuality, gymnophobia, modesty, physical attractiveness, vanity, objectification, exploitation and consent. It can thus be controversial. Descamps assembled a list of criticisms of naturism: it is too cold; normal bodies look ugly—it is only for the physically beautiful; it is too embarrassing; it is against the laws of nature, against the law, or against religion; "nudism makes me think of sex"; it is for primitive people or animals.
Naturism can sometimes contain aspects of eroticism, although the debate about this is often simplified and seen negatively in the media and the public mind and by many modern naturists and naturist organisations. Historically the experience and discussion of erotic feelings during naturist activities such as dance and gymnastics played an important part in early Germanic naturism and formed part of its 'positive' connection with nature. However, it was when naturism arrived in the more sexually conservative cultures of the UK and the United States that the expression and discussion of eroticism within naturism became frowned upon.
Smith states the main reason younger people are not becoming naturists is the inability of modern naturism to engage with the issue of sexuality . While it is true that "naturism became popular in Germany...as a healthy outdoor lifestyle", this lifestyle also included a recognition that, socially, nudity could sometimes be erotic. It was only when naturism arrived in a more sexually conservative Britain that sexual feelings were censored out to make naturism culturally acceptable.
 This statement is in response to the quote "The world of naturism is in trouble. Membership is falling, and fewer young people than ever are getting involved. Has the great nude adventure run its course? "
Smith poses the following, in his self-published paper, "Naturism and Sexuality in the United Kingdom (A Pilot Study)"
Issues for the naturist community.
Any social group is said to go through four phases:
forming, storming, norming, performing, wrote Bruce Tuckman in 1965. In this context one can understand some of the current pressures on various aspects of naturism:
Naturist and nudist magazines.
Magazines published by, for or purportedly about naturists can be grouped:
Magazines in the second and, occasionally, third grouping feature naturist editorial and advertising, while some naturists argue over which magazines belonged in which of these categories – these views may change as publishers and editors change. Many clubs and groups have benefitted from magazines which, while not exclusively or even predominantly naturist in character, made naturist information available to many who would not otherwise have been aware of it. (These days, the information and advertising provided online, and the wide availability of free online porn, has meant the disappearance of old-style 'skin' magazines presenting significant glamour content masquerading as or alongside naturist content. Naturist magazines have to appeal strongly to naturists to succeed – they cannot sit on the fence between naturism and glamour.)
Some naturists still feel that the worthwhile editorial content in some magazines is not a fair balance for the disapproved-of photographic content.
Naturist and nudist photography, films and videos.
Some naturist clubs have been willing to allow filming by the media on their grounds, though content that proved not to be of genuine naturism can end up being parodied by the media as the norm.
Some commercial 'naturist' DVDs are dominated by imagery of naked children. Such material can be marketed in ways that appear to appeal directly to paedophile inclinations, and ownership of these DVDs (and their earlier video cassette incarnations) has resulted in successful British prosecutions for possession of indecent images of children. One case was appealed, unsuccessfully, to the European Court of Human Rights. The precedents set by the court cases mean that possession in Britain of any naturist image of a child is, potentially, grounds for prosecution.
Photo shoots, including major high-profile works by Spencer Tunick are done on public places including beaches.
References.
Websites.
</dl>
A bibliography of the economic impacts of naturism.
</dl>

</doc>
<doc id="21916" url="http://en.wikipedia.org/wiki?curid=21916" title="Nordea">
Nordea

Nordea Bank AB, commonly referred to as Nordea, is a Nordic-based financial services group operating in Northern Europe. The bank is the result of the successive mergers and acquisitions of the Finnish, Danish, Norwegian and Swedish banks of Merita Bank, Unibank, Kreditkassen (Christiania Bank) and Nordbanken that took place between 1997 and 2000. The Baltic countries and Poland are today also considered part of the home market. The largest share holder of Nordea is Sampo, a Finnish insurance company with around 20% of the shares. Nordea is listed on the Copenhagen Stock Exchange, Helsinki Stock Exchange and Stockholm Stock Exchange.
Nordea is headquartered from Stockholm and has more than 1,400 branches. The bank is present in 19 countries around the world, operating through full service branches, subsidiaries and representative offices.
The international corporate banking division has branches in Germany (Frankfurt), United Kingdom (London), Singapore, China (Shanghai) and in the United States (New York). Nordea International private banking has its headquarters in Luxembourg with branches in, Switzerland (Zurich) and Singapore. Nordea also has representative offices in Brazil (São Paulo) and China (Beijing). 
Nordea currently serves 11 million private and 700,000 active corporate customers. The group also operates an internet bank, which has more than 5.9 million online customers doing more than 260 million payments per year.
History.
Nordea is the result of the successive mergers and acquisitions of the Swedish, Finnish, Danish and Norwegian banks of Nordbanken, Merita Bank, Unibank and Kreditkassen (Christiania Bank) that took place between 1997 and 2000. The name Nordea comes from the Swedish bank Nordbanken, which was based on PK-banken (Post och Kreditbanken; owned by Swedish state) which in 1990 purchased the smaller private bank Nordbanken, and picked up that name. PK-banken was formed in 1974 at a merger between Postbanken (formed 1884) and Sveriges Kreditbank (formed 1923), both state owned. Merita Bank was a 1995 merger of the former main rivals in Finland, the originally Svecoman Union Bank of Finland ("Suomen Yhdyspankki") founded in 1842 and the Fennoman National Share Bank ("Kansallis-Osake-Pankki") founded in 1889.
The private Nordbanken was formed in 1986 at a merger between two smaller private local banks, Uplandsbanken and Sundsvallsbanken. In 1991 the Swedish banking crisis, resulting from deregulated markets and a housing price bubble, forced the government to nationalise Nordbanken for 64 billion kronor. Bad debts were transferred to the asset-management companies Securum and Retriva which sold off the assets.
Ownership.
Nordea is owned by:
Nordea Markets.
Nordea Markets is the international markets operation of Nordea. It handles a broad range of investment banking products and services including fixed income, currencies, commodities, equities, debt capital markets, and corporate finance. It also supplies advisory services and internationally acknowledged economic research and analysis.
There are approximately 2,200 employees including Financial Risk Control and Capital Markets Services. Its main operational centres are in Copenhagen (also the main trading floor), Helsinki, Oslo and Stockholm, and with regional offices also in Estonia, Latvia, Lithuania, Poland, Russia, Singapore and USA.
The organisation's stated aim is to provide rapid, easy access to market and trading facilities and a strong local presence to its customers in all its regions. It operates with a mission statement of "Making it possible" and a vision statement of "A great European, capital markets and investment banking organisation, acknowledged for its people, creating superior value for customers and shareholders".
Online theft.
In 2007 Nordea was the subject of an online phishing scam. The amount of money involved was "between seven and eight million SEK". The theft was perpetrated by targeting Nordea customers with phishing emails containing a trojan horse, that was especially made for this robbery. Apparently these emails were sent out over a period of 15 months. According to Nordea, at least 250 people had unwittingly installed the trojan. The thieves evaded detection by limiting their transfers to small sums. Nordea has refunded all the victims and has implemented a new security system, Chip Authentication Program
Awards.
Euromoney financial magazine named Nordea the "best provider of private banking services in the Nordic and Baltic region" each year from 2008 to 2014.

</doc>
<doc id="21918" url="http://en.wikipedia.org/wiki?curid=21918" title="Normal subgroup">
Normal subgroup

In abstract algebra, a normal subgroup is a subgroup which is invariant under conjugation by members of the group of which it is a part. In other words, a subgroup "H" of a group "G" is normal in "G" if and only if "gH" = "Hg" for all "g" in "G", i.e., the sets of left and right cosets coincide. Normal subgroups (and "only" normal subgroups) can be used to construct quotient groups from a given group.
Évariste Galois was the first to realize the importance of the existence of normal subgroups.
Definitions.
A subgroup "N" of a group "G" is called a normal subgroup if it is invariant under conjugation; that is, for each element "n" in "N" and each "g" in "G", the element "gng"−1 is still in "N". We write 
For any subgroup, the following conditions are equivalent to normality. Therefore any one of them may be taken as the definition:
The last condition accounts for some of the importance of normal subgroups; they are a way to internally classify all homomorphisms defined on a group. For example, a non-identity finite group is simple if and only if it is isomorphic to all of its non-identity homomorphic images, a finite group is perfect if and only if it has no normal subgroups of prime index, and a group is imperfect if and only if the derived subgroup is not supplemented by any proper normal subgroup.
Properties.
Lattice of normal subgroups.
The normal subgroups of a group "G" form a lattice under subset inclusion with least element {"e"} and greatest element "G". Given two normal subgroups "N" and "M" in "G", meet is defined as
and join is defined as 
The lattice is complete and modular.
Normal subgroups and homomorphisms.
If "N" is normal subgroup, we can define a multiplication on cosets by
This turns the set of cosets into a group called the quotient group "G/N". There is a natural homomorphism "f": "G" → "G/N" given by "f"("a") = "aN". The image "f"("N") consists only of the identity element of "G/N", the coset "eN" = "N".
In general, a group homomorphism "f": "G" → "H" sends subgroups of "G" to subgroups of "H". Also, the preimage of any subgroup of "H" is a subgroup of "G". We call the preimage of the trivial group {"e"} in "H" the kernel of the homomorphism and denote it by ker("f"). As it turns out, the kernel is always normal and the image "f"("G") of "G" is always isomorphic to "G"/ker("f") (the first isomorphism theorem). In fact, this correspondence is a bijection between the set of all quotient groups "G"/"N" of "G" and the set of all homomorphic images of "G" (up to isomorphism). It is also easy to see that the kernel of the quotient map, "f": "G" → "G/N", is "N" itself, so we have shown that the normal subgroups are precisely the kernels of homomorphisms with domain "G".

</doc>
<doc id="21919" url="http://en.wikipedia.org/wiki?curid=21919" title="Munkar and Nakir">
Munkar and Nakir

Munkar and Nakir (Arabic: منكر و نكير‎) (English translation: "The Denied and The Denier") in Islamic eschatology, are angels who test the faith of the dead in their graves.
Many Muslims believe that, after death, a person's soul passes through a stage called barzakh, where it exists in the grave (even if the person's body was destroyed, the soul will still rest in the earth near their place of death). The questioning will begin when the funeral is over and the last person of the funeral congregation has stepped 40 steps away from the grave. Nakir and Munkar prop the deceased soul upright in the grave and ask three questions: "Who is your Lord? Who is your Prophet? What is your religion?". A righteous believer will respond correctly, saying that their Lord is Allah, that Muhammad is their prophet and that their religion is Islam. If the deceased answers correctly, the time spent awaiting the resurrection is pleasant. Those who do not answer as described above are chastised until the day of judgment.
These angels are described as having solid black eyes, having a shoulder span measured in miles, and carrying hammers "so large, that if all of mankind tried at once to move them a single inch, they would fail". When they speak, tongues of fire come from their mouths. If one answers their questions incorrectly, one is beaten every day, other than Friday, until Allah gives permission for the beating to stop.
Muslims believe that a person will correctly answer the questions not by remembering the answers before death (compare with the Egyptian Book of the Dead) but by their iman and deeds such as salat and shahadah (the Islamic profession of faith).
Munkar is sometimes transliterated as Monkir.

</doc>
<doc id="21920" url="http://en.wikipedia.org/wiki?curid=21920" title="Napalm">
Napalm

Napalm is flammable liquid used in warfare. It is a mixture of a gelling agent and petroleum or a similar fuel. It was initially used as an incendiary device against buildings and later primarily as an anti-personnel weapon, as it sticks to skin and causes severe burns when on fire. Napalm was developed in 1942 in a secret laboratory at Harvard University by a team led by chemist Louis Fieser. Its first recorded use was in the European theatre of war during World War II. It was used extensively by the United States in incendiary attacks on Japanese cities in the Pacific War as well as during the Vietnam War.
"Napalm" is a combination of the names of two of the constituents of the thickening/gelling agent: co-precipitated aluminium salts of naphthenic and palmitic acids. "Napalm B" is the more modern version of napalm and, although distinctly different in its chemical composition, is often referred to simply as "napalm".
Forms.
Napalm was used in flamethrowers, bombs and tanks in World War II. It is believed to have been formulated to burn at a specific rate and to adhere to surfaces to increase its stopping power. During combustion, napalm rapidly deoxygenates the available air and generates large amounts of carbon monoxide and carbon dioxide.
Alternative compositions exist for different uses, e.g. triethylaluminium, a pyrophoric compound that aids ignition.
Development.
Use of fire in warfare has a long history. Greek fire, also described as "sticky fire" (πῦρ κολλητικόν, "pýr kolletikón"), is believed to have had a petroleum base. The development of napalm was precipitated by the use of jellied gasoline mixtures by the Allied forces during World War II. The supply of latex that had been used in these early forms of incendiary devices became scarce in the Pacific Theater of Operations, since natural rubber was almost impossible to obtain after the Japanese army captured the rubber plantations in Malaya, Indonesia, Vietnam, and Thailand.
This shortage of natural rubber prompted chemists at US companies such as Du Pont and Standard Oil, and researchers at Harvard University, to develop factory-made alternatives - artificial rubber for all uses, including vehicle tires, tank tracks, gaskets, hoses, medical supplies and rain clothing. A team of chemists led by Louis Fieser at Harvard University was the first to develop synthetic napalm, during 1942. "The production of napalm was first entrusted to Nuodex Products, and by the middle of April 1942 they had developed a brown, dry powder that was not sticky by itself, but when mixed with gasoline turned into an extremely sticky and flammable substance."" One of Fieser's colleagues suggested adding phosphorus to the mix which increased the "ability to penetrate deeply...into the musculature, where it would continue to burn day after day.""
On 4 July 1942, the first test occurred on the football field near the Harvard Business School. Tests under operational conditions were carried out at Jefferson Proving Ground on condemned farm buildings, and subsequently at Dugway Proving Ground on buildings designed and constructed to represent those to be found in German and Japanese towns. This new mixture of chemicals was widely used in the Second World War in incendiary bombs and in flamethrowers.
From 1965 to 1969, the Dow Chemical Company manufactured napalm B for the American armed forces. After news reports of napalm B's deadly and disfiguring effects were published, Dow Chemical experienced boycotts of its products, and its recruiters for new chemists, chemical engineers, etc., graduating from college were subject to campus boycotts. The management of the company decided that its "first obligation was the government." Meanwhile, napalm B became a symbol for the Vietnam War.
Military use.
Napalm was first employed in incendiary bombs and went on to be used as fuel for flamethrowers.
The first recorded strategic use of napalm incendiary bombs occurred in an attack by the US Army Air Force on Berlin on 6 March 1944, using American AN-M76 incendiary bombs with PT-1 (Pyrogel) filler. The first known tactical operation was by De Havilland D.H.98 Mosquito FB Mk.VIs of No. 140 Wing RAF, Second Tactical Air Force on 14 July 1944, which also employed the AN-M76 incendiary in a reprisal attack on the 17th SS Panzergrenadier Division „Götz von Berlichingen“ in Bonneuil-Matours. Soldiers of this Waffen SS unit had captured and then killed a British SAS prisoner-of-war, Lt. Tomos Stephens, taking part in Operation Bulbasket, and seven local Resistance fighters. Although it was not known at the time of the air strike, 31 other POWs from the same SAS unit, and an American airman who had joined up with the SAS unit, had also been executed.
Further use of napalm by American forces occurred in the Pacific Theater of Operations, where in 1944 and 1945, napalm was used as a tactical weapon against Japanese bunkers, pillboxes, tunnels, and other fortifications, especially on Saipan, Iwo Jima, the Philippines, and Okinawa, where deeply dug-in Japanese troops refused to surrender. Napalm bombs were dropped by aviators of the U.S. Navy, the United States Army Air Forces, and the U.S. Marine Corps in support of their ground troops.
Then, when the U.S. Army Air Forces on the Marianas Islands ran out of conventional thermite incendiary bombs for their B-29 Superfortresses to drop on Japanese cities, its top commanders, such as General Curtis LeMay, turned to napalm bombs to continue fire raids on the large Japanese cities.
In the European Theater of Operations napalm was used by American forces in the siege of La Rochelle in April 1945 against German soldiers (and inadvertently French civilians in Royan) - about two weeks before the end of the war.
Napalm B was also used during the Greek Civil War between the Greek Army and Communist rebels. During 1949, the last year of the war, the United States increased its military aid to the Greek Government by introducing a new weapon to finish off the war: napalm B. The first napalm attack in Greece took place on the mountain of Grammos, which was the stronghold of the Communist rebels.
Napalm B was also widely used by the United Nations military forces during the Korean War. These Allied ground forces in Korea were frequently outnumbered, and often greatly, by their Chinese and North Korean attackers, but the U.S. Air Force and the U.S. Navy naval aviators had control of the air over nearly all of the Korean Peninsula. Hence, close air support of the ground troops along the border between North Korea and South Korea was vital, and the American and other U.N. aviators turned to napalm B as an important weapon for defending against communist ground attacks. Napalm was used most notably during the defense of "Outpost Harry" in South Korea during the night of June 10–11, 1953.
Napalm B became an intrinsic element of U.S. military action during the Vietnam War as forces increasingly employed its widespread tactical as well as psychological effects. Reportedly about 388,000 tons of U.S. napalm bombs were dropped in the region between 1963 and 1973, compared to 32,357 tons used over three years in the Korean War, and 16,500 tons dropped on Japan in 1945.
The U.S. Air Force and U.S. Navy used napalm with great effect against all kinds of targets to include troops, tanks, buildings, jungles, and even railroad tunnels. The effect was not always purely physical as napalm had psychological effects on the enemy as well.
Other uses include: by France during the First Indochina War (1946–1954), the Algerian War (1954–1962), the Portuguese Colonial War (1961–1974), The Six-Day War by Israel (1967), in Nigeria (1969), India and Pakistan (1965 and 1971), Turkey during the Battle of Tylliria in Cyprus in 1964 and again during the invasion of Cyprus (1974), by Morocco during the Western Sahara War (1975–1991), Iran (1980–88), Egypt (1973), Iraq (1980–88, 1991), Angola (1993), Yugoslavia (1991-1996), and by Argentina (1982).
Effects on people.
""Napalm is the most terrible pain you can imagine," said Kim Phúc, a napalm bombing survivor known from a famous Vietnam War photograph. "Water boils at 100 degrees Celsius (212°F). Napalm generates temperatures of 800 to 1,200 degrees Celsius (1,500-2,200°F).""
When used as a part of an incendiary weapon, napalm can cause severe burns (ranging from superficial to subdermal), asphyxiation, unconsciousness, and death. In this implementation, napalm fires can create an atmosphere of greater than 20% carbon monoxide and firestorms with self-perpetuating winds of up to 70 mph. One of the main anti-personnel features of napalm is that it sticks to human skin, with no practical method for removal of the burning substance.
Napalm is effective against dug-in enemy personnel. The burning incendiary composition flows into foxholes, trenches and bunkers, and drainage and irrigation ditches and other improvised troop shelters. Even people in undamaged shelters can be killed by hyperthermia, radiant heat, dehydration, suffocation, smoke exposure, or carbon monoxide poisoning.
One firebomb released from a low-flying plane can damage an area of 2500 sqyd.
International law.
International law does not specifically prohibit the use of napalm or other incendiaries against military targets, but use against civilian populations was banned by the United Nations Convention on Certain Conventional Weapons (CCW) in 1980. Protocol III of the CCW restricts the use of all incendiary weapons, but a number of countries have not acceded to all of the protocols of the CCW. According to the Stockholm International Peace Research Institute (SIPRI), countries are considered a party to the convention, which entered into force as international law in December 1983, as long as they ratify at least two of the five protocols. The United States signed it approximately 25 years after the General Assembly adopted it, on January 21, 2009: President Barack Obama's first full day in office. Their ratification, however, is subject to a reservation that says it can disregard the treaty at its discretion if doing so would save civilian lives.

</doc>
<doc id="21921" url="http://en.wikipedia.org/wiki?curid=21921" title="Northern Crusades">
Northern Crusades

The Northern Crusades or Baltic Crusades were crusades undertaken by the Christian kings of Denmark, Poland and Sweden, the German Livonian and Teutonic military orders, and their allies against the pagan peoples of Northern Europe around the southern and eastern shores of the Baltic Sea. Swedish and German Catholic campaigns against Russian Eastern Orthodox Christians are also sometimes considered part of the Northern Crusades. Some of these wars were called crusades during the Middle Ages, but others, including most of the Swedish ones, were first dubbed crusades by 19th-century romantic nationalist historians. The east Baltic world was transformed by military conquest: first the Livs, Latgallians and Estonians, then the Semigallians, Curonians, Prussians and the Finns underwent defeat, baptism, military occupation and sometimes extermination by groups of Danes, Germans and Swedes.
Background.
The official starting point for the Northern Crusades was Pope Celestine III's call in 1193; but the Christian kingdoms of Scandinavia, Poland and the Holy Roman Empire had begun moving to subjugate their pagan neighbors even earlier. The non-Christian people who were objects of the campaigns at various dates included:
Armed conflict between the Baltic Finns, Balts and Slavs who dwelt by the Baltic shores and their Saxon and Danish neighbors to the north and south had been common for several centuries before the crusade. The previous battles had largely been caused by attempts to destroy castles and sea trade routes and gain economic advantage in the region, and the crusade basically continued this pattern of conflict, albeit now inspired and prescribed by the Pope and undertaken by Papal knights and armed monks.
Wendish Crusade.
The campaigns started with the 1147 Wendish Crusade against the Polabian Slavs (or "Wends") of what is now northern and eastern Germany. The crusade occurred parallel to the Second Crusade to the Holy Land, and continued irregularly until the 16th century.
Livonian Crusade.
By the 12th century, the peoples inhabiting the lands now known as Estonia, Latvia and Lithuania formed a pagan wedge between increasingly powerful rival Christian states – the Orthodox Church to their east and the Catholic Church to their west. The difference in creeds was one of the reasons they had not yet been effectively converted. During a period of more than 150 years leading up to the arrival of German crusaders in the region, Estonia was attacked thirteen times by Russian principalities, and by Denmark and Sweden as well. Estonians for their part made raids upon Denmark and Sweden. There were peaceful attempts by some Catholics to convert the Estonians, starting with missions dispatched by Adalbert, Archbishop of Bremen in 1045-1072. However, these peaceful efforts seem to have had only limited success.
Campaign against the Livonians (1198–1212).
Moving in the wake of German merchants who were now following the old trading routes of the Vikings, a monk named Meinhard landed at the mouth of the Daugava river in present-day Latvia in 1180 and was made bishop in 1186. Pope Celestine III proclaimed a crusade against the Baltic heathens in 1195, which was reiterated by Pope Innocent III and a crusading expedition led by Meinhard's successor, Bishop Berthold of Hanover, landed in Livonia (part of present-day Latvia, surrounding the Gulf of Riga) in 1198. Although the crusaders won their first battle, Bishop Berthold was mortally wounded and the crusaders were repulsed.
In 1199, Albert of Buxhoeveden was appointed by the Archbishop Hartwig II of Bremen to Christianise the Baltic countries. By the time Albert died 30 years later, the conquest and formal Christianisation of present-day Estonia and northern Latvia was complete. Albert began his task by touring the Empire, preaching a Crusade against the Baltic countries, and was assisted in this by a Papal Bull, which declared that fighting against the Baltic heathens was of the same rank as participating in a crusade to the Holy Land. Though he landed in the mouth of the Daugava in 1200 with only 23 ships and 500 soldiers, the bishop's efforts ensured that a constant flow of recruits followed. The first crusaders usually arrived to fight during the spring and returned to their homes in the autumn. To ensure a permanent military presence, the Livonian Brothers of the Sword were founded in 1202. The founding by Bishop Albert of the market at Riga in 1201 attracted citizens from the Empire and economic prosperity ensued. At Albert's request, Pope Innocent III dedicated the Baltic countries to the Virgin Mary to popularize recruitment to his army and the name "Mary's Land" has survived up to modern times.
In 1206, the crusaders subdued the Livonian stronghold in Turaida on the right bank of Gauja River, the ancient trading route to the Northwestern Rus. In order to gain control over the left bank of Gauja, the stone castle was built in Sigulda before 1210. By 1211, the Livonian province of Metsepole (now Limbaži district) and mixed Livonian-Latgallian inhabited county of Idumea (now Straupe) was converted to the Roman Catholic faith. The last battle against the Livonians was the siege of Satezele hillfort near to Sigulda in 1212. The Livonians, who had been paying tribute to the East Slavic Principality of Polotsk, had at first considered the Germans as useful allies. The first prominent Livonian to be christened was their leader Caupo of Turaida. As the German grip tightened, the Livonians rebelled against the crusaders and the christened chief, but were put down. Caupo of Turaida remained an ally of the crusaders until his death in the Battle of St. Matthew's Day in 1217.
The German crusaders enlisted newly baptised Livonian warriors to participate in their campaigns against Latgallians and Selonians (1208–1209), Estonians (1208–1227) and against Semigallians, Samogitians and Curonians (1219–1290).
Campaign against the Latgallians and Selonians (1208–1224).
After the subjugation of the Livonians the crusaders turned their attention to the Latgallian principalities to the east, along the Gauja and Daugava rivers. The military alliance in 1208 and later conversion from Greek Orthodoxy to Roman Catholicism of the Principality of Tālava was the only peaceful subjugation of the Baltic tribes during the Nordic crusades. The ruler of Tālava, Tālivaldis ("Talibaldus de Tolowa"), became the most loyal ally of German crusaders against the Estonians, and he died a Catholic martyr in 1215. The war against the Latgallian and Selonian countries along the Daugava waterway started in 1208 by occupation of the Orthodox Principality of Koknese and the Selonian hillfort of Sēlpils. The campaign continued in 1209 with an attack on the Orthodox Principality of Jersika (known as "Lettia"), accused by crusaders of being in alliance with Lithuanian pagans. After defeat the king of Jersika, Visvaldis, became the vassal of the Bishop of Livonia and received part of his country (Southern Latgale) as a fiefdom. The Selonian stronghold of Sēlpils was briefly the seat of a Selonian diocese (1218–1226), and then came under the rule of the Livonian Order. Only in 1224, with the division of Tālava and Adzele counties between the Bishop of Rīga and the Order of the Swordbearers, did Latgallian countries finally became the possession of German conquerors. The territory of the former Principality of Jersika was divided by the Bishop of Rīga and the Livonian Order in 1239.
Campaign against the Estonians (1208–1224).
By 1208, the Germans were strong enough to begin operations against the Estonians, who were at that time divided into eight major and several smaller counties led by elders with limited co-operation between them. In 1208-27, war parties of the different sides rampaged through the Livonian, Northern Latgallian, and Estonian counties, with Livonians and Latgallians normally as allies of the Crusaders, and the Principalities of Polotsk and Pskov appearing as allies of different sides at different times. Hill forts, which were the key centres of Estonian counties, were besieged and captured a number of times. A truce between the war-weary sides was established for three years (1213–1215) and proved generally more favourable to the Germans, who consolidated their political position, while the Estonians were unable to develop their system of loose alliances into a centralised state. The Livonian leader Kaupo was killed in battle near Viljandi (Fellin) on 21 September 1217, but the battle was a crushing defeat for the Estonians, whose leader Lembitu was also killed. Since 1211, his name had come to the attention of the German chroniclers as a notable Estonian elder, and he had become the central figure of the Estonian resistance.
The Christian kingdoms of Denmark and Sweden were also greedy for conquests on the Eastern shores of the Baltic. While the Swedes made only one failed foray into western Estonia in 1220, the Danish Fleet headed by King Valdemar II of Denmark had landed at the Estonian town of Lindanisse (present-day Tallinn) in 1219. After the Battle of Lyndanisse the Danes established a fortress, which was besieged by Estonians in 1220 and 1223, but held out. Eventually, the whole of northern Estonia came under Danish control.
Wars against Saaremaa (1206–61).
The last Estonian county to hold out against the invaders was the island county of Saaremaa, whose war fleets had raided Denmark and Sweden during the years of fighting against the German crusaders.
In 1206, a Danish army led by king Valdemar II and Andreas, the Bishop of Lund landed on Saaremaa and attempted to establish a stronghold without success. In 1216 the Livonian Brothers of the Sword and the bishop Theodorich joined forces and invaded Saaremaa over the frozen sea. In return the Oeselians raided the territories in Latvia that were under German rule the following spring. In 1220, the Swedish army led by king John I of Sweden and the bishop Karl of Linköping conquered Lihula in Rotalia in Western Estonia. Oeselians attacked the Swedish stronghold the same year, conquered it and killed the entire Swedish garrison including the Bishop of Linköping.
In 1222, the Danish king Valdemar II attempted the second conquest of Saaremaa, this time establishing a stone fortress housing a strong garrison. The Danish stronghold was besieged and surrendered within five days, the Danish garrison returned to Revel, leaving bishop Albert of Riga's brother Theodoric, and few others, behind as hostages for peace. The castle was razed to the ground by the Oeselians.
A 20,000 strong army under Papal legate William of Modena crossed the frozen sea while the Saaremaa fleet was icebound, in January 1227. After the surrender of two major Oeselian strongholds, Muhu and Valjala, the Oeselians formally accepted Christianity.
In 1236, after the defeat of the Livonian Brothers of the Sword in the Battle of Saule, military action on Saaremaa broke out again. In 1261, warfare continued as the Oeselians had once more renounced Christianity and killed all the Germans on the island. A peace treaty was signed after the united forces of the Livonian Order, the Bishopric of Ösel-Wiek, and Danish Estonia, including mainland Estonians and Latvians, defeated the Oeselians by conquering their stronghold at Kaarma. Soon thereafter, the Livonian Order established a stone fort at Pöide.
Wars against the Curonians and Semigallians (1201–90).
Although the Curonians had attacked Riga in 1201 and 1210, Albert of Buxhoeveden, considering Courland a tributary of Valdemar II of Denmark, had been reluctant to conduct a large scale campaign against them. After Albert's death in 1229, the crusaders secured the peaceful submission of Vanemane (a county with a mixed Livonian, Oselian, and Curonian population in the northeastern part of Courland) by treaty in 1230. In the same year the papal vice-legat Baldouin of Alnea annulled this agreement and concluded an agreement with the ruler of Bandava in the central Courland Lamekins ("Lammechinus rex"), delivering his kingdom into the hands of the papacy. Baldouin became the popes's delegate in Courland and bishop of Semigallia; however, the Germans complained about him to the Roman Curia, and in 1234 Pope Gregory IX removed Baldouin as his delegate.
After their decisive defeat in the Battle of Saule by the Samogitians and Semigallians, the remnants of the Swordbrothers were reorganized in 1237 as a subdivision of the Teutonic Order, and became known as the Livonian Order. In 1242, under the leadership of the master of the Livonian Order Andrew of Groningen, the crusaders began the military conquest of Courland. They defeated the Curonians as far south as Embūte, near the contemporary border with Lithuania, and founded their main fortress at Kuldīga. In 1245 Pope Innocent IV allotted two thirds of conquered Courland to the Livonian Order, and one third to the Bishopric of Courland.
At the Battle of Durbe in 1260 a force of Samogitians and Curonians overpowered the united forces of the Livonian and Teutonic Orders; over the following years, however, the Crusaders gradually subjugated the Curonians, and in 1267 concluded the peace treaty stipulating the obligations and the rights of their defeated rivals. The unconquered southern parts of their territories (Ceklis and Megava) were united under the rule of the Grand Duchy of Lithuania.
The conquest of Semigallian counties started in 1219 when crusaders from Rīga occupied Mežotne, the major port on the Lielupe waterway, and founded the Bishopric of Semigallia. After several unsuccessful campaigns against the pagan Semigallian duke Viestards and his Samogitian kinsfolk, the Roman Curia decided in 1251 to abolish the Bishopric of Semigallia, and divided its territories between the Bishopric of Rīga and the Order of Livonia. In 1265 a stone castle was built at Jelgava, on the Lielupe, and became the main military base for crusader attacks against the Semigallians. In 1271 the capital hillfort of Tērvete was conquered, but Semigallians under the Duke Nameisis rebelled in 1279, and the Lithuanians under Traidenis defeated Livonian Order forces in the Battle of Aizkraukle. Duke Nameisis' warriors unsuccessfully attacked Rīga in 1280, in response to which around 14,000 crusaders besieged Turaida castle in 1281. To conquer the remaining Semigallian hillforts the Order's master Villekin of Endorpe built a castle called "Heiligenberg" right next to the Tērvete castle in 1287. The same year the Semigallians made another attempt to conquer Rīga, but again failed to take it. On their return home Livonian knights attacked them, but were defeated at the Battle of Garoza, in which the Orders' master Villekin and at least 35 knights lost their lives. The new master of the Order Cuno of Haciginstein organised the last campaigns against the Semigallians in 1289 and 1290; the hillforts of Dobele, Rakte and Sidarbe were conquered and most of the Semigallian warriors joined the Samogitian and Lithuanian forces.
Prussia and Lithuania.
Campaigns of Konrad of Masovia.
Konrad I, the Polish Duke of Masovia, unsuccessfully attempted to conquer pagan Prussia in crusades in 1219 and 1222. Taking the advice of the first Bishop of Prussia, Christian of Oliva, Konrad founded the crusading Order of Dobrzyń (or "Dobrin") in 1220. However, this order was largely ineffective, and Konrad's campaigns against the Old Prussians were answered by incursions into the already captured territory of Culmerland (Chełmno Land). Subjected to constant Prussian counter-raids, Konrad wanted to stabilize the north of the Duchy of Masovia in this fight over border area of Chełmno Land. Masovia had only been conquered in the 10th century and native Prussians, Yotvingians, and Lithuanians were still living in the territory, where no settled borders existed. His military weakness led Konrad to invite the Teutonic Knights to Prussia.
Teutonic Order.
The Northern Crusades provided a rationale for the growth and expansion of the Teutonic Order of German crusading knights which had been founded in Palestine at the end of the 12th century. Due to Muslim successes in the Holy Land, the Order sought new missions in Europe. Duke Konrad I of Masovia in west-central Poland appealed to the Knights to defend his borders and subdue the pagan Baltic Prussians in 1226. After the subjugation of the Prussians, the Teutonic Knights fought against the Grand Duchy of Lithuania.
When the Livonian knights were crushed by Samogitians in the Battle of Saule in 1236, coinciding with a series of revolts in Estonia, the Livonian Order was inherited by the Teutonic Order, allowing the Teutonic Knights to exercise political control over large territories in the Baltic region. Mindaugas, the King of Lithuania, was baptised together with his wife after his coronation in 1253, hoping that this would help stop the Crusaders' attacks, which it did not. The Teutonic Knights failed to subdue pagan Lithuania, which officially converted to (Catholic) Christianity in 1386 on the marriage of Grand Duke Jogaila to the 11-year-old Queen Jadwiga of Poland. However, even after the country was officially converted, the crusades continued up until the Battle of Grunwald in 1410, when the Lithuanians and Poles, helped by the Tatars, Moldovans and the Czechs, defeated the Teutonic knights.
The Teutonic Order's attempts to conquer Orthodox Russia (particularly the Republics of Pskov and Novgorod), an enterprise endorsed by Pope Gregory IX, can also be considered as a part of the Northern Crusades. One of the major blows for the idea of the conquest of Russia was the Battle of the Ice in 1242. With or without the Pope's blessing, Sweden also undertook several crusades against Orthodox Novgorod.

</doc>
<doc id="21922" url="http://en.wikipedia.org/wiki?curid=21922" title="Neoteny">
Neoteny

Neoteny ( 
or ), also called juvenilization, is one of the two ways by which paedomorphism can arise. Paedomorphism or paedomorphosis is the retention by adults of traits previously seen only in the young, and is a subject studied in the field of developmental biology. Paedomorphism can also be the retention of larval traits which is commonly studied in salamanders. In neoteny, the physiological (or somatic) development of an organism (typically an animal) is slowed or delayed. In contrast, in progenesis, sexual development occurs faster. Both processes result in paedomorphism, a type of heterochrony. Ultimately this process results in the retention, in the adults of a species, of juvenile physical characteristics well into maturity and pedogenesis (paedogenesis), the reproduction in a neotenized state.
Neoteny is one of three dimensions of heterochrony, or the change in timing of developmental events: acceleration (faster) vs. neoteny (slower), hypermorphosis (further) vs. progenesis (not as far), and predisplacement (begins earlier) vs. postdisplacement (begins later).
The word "neoteny" is borrowed from the German "Neotenie", the latter constructed from the Greek νέος ("neos", "young") and τείνειν ("teínein", "to extend"). The adjective form of the word is either "neotenic" or "neotenous". For the opposite of "neotenic", different authorities use either "gerontomorphic" or "peramorphic".
In humans.
Neotenic traits in humans.
Various sources identify the following:
Human evolution.
Many prominent evolutionary theorists propose that neoteny has been a key feature in human evolution. Stephen Jay Gould believed that the "evolutionary story" of humans is one where we have been "retaining to adulthood the originally juvenile features of our ancestors". J. B. S. Haldane mirrors Gould's hypothesis by stating a "major evolutionary trend in human beings" is "greater prolongation of childhood and retardation of maturity." Delbert D. Thiessen said that "neoteny becomes more apparent as early primates evolved into later forms" and that primates have been "evolving toward flat face." However, in light of some groups using arguments based around neoteny to support racism, Gould also argued "that the whole enterprise of ranking groups by degree of neoteny is fundamentally unjustified" (Gould, 1996, pg. 150).
Doug Jones, a visiting scholar in anthropology at Cornell University, said that human evolution's trend toward neoteny may have been caused by sexual selection for neotenous facial traits in women by men with the resulting neoteny in male faces being a "by-product" of sexual selection for neotenous female faces. Jones said that this type of sexual selection "likely" had a major role in human evolution once a larger proportion of women lived past the age of menopause. This increasing proportion of women who were too old to reproduce resulted in a greater variance in fecundity in the population of women, and it resulted in a greater sexual selection for indicators of youthful fecundity in women by men.
Ashley Montagu said that the fetalized pithecanthropine represented by the juvenile Mojokerto skull and the fetalized australopithecine represented by the juvenile Australopithecus africanus skull would have had skulls with a closer resemblance to those of modern humans than to those of the adult forms of their own species. Montagu further listed the roundness of the skull, thinness of the skull bones, lack of brow ridges, lack of sagittal crests, form of the teeth, relative size of the brain and form of the brain as ways in which the juvenile skulls of these human ancestors resemble the skulls of adult modern humans. Montagu said that the retention of these juvenile characteristics of the skull into adulthood by australopithecine or pithecanthropine could have been a way that a modern type of human could have evolved earlier than what actually happened in human evolution.
Stanley Greenspan and Stuart G. Shanker proposed a theory in "The First Idea" of psychological development in which neoteny is seen as crucial for the "development of species-typical capacities" that depend upon a long period of attachment to caregivers for the opportunities to engage in and develop their capacity for emotional communication. Because of the importance of facial expression in the process of interactive signaling, neotenous features, such as hair loss, allow for more efficient and rapid communication of socially important messages that are based on facially expressive emotional signaling.
Other theorists have argued that neoteny has not been the main cause of human evolution, because humans only retain some juvenile traits, while relinquishing others. For example, the high leg-to-body ratio (long legs) of adult humans as opposed to human infants shows that there is not a holistic trend in humans towards neoteny when compared to the other great apes. Andrew Arthur Abbie agrees, citing the gerontomorphic fleshy human nose and long human legs as contradicting the neoteny hominid evolution hypothesis, although he does believe humans are generally neotenous. Brian K. Hall also cites the long legs of humans as a peramorphic trait, which is in sharp contrast to neoteny.
On the balance, an all or nothing approach could be regarded as pointless, with a combination of heterochronic processes being more likely and more reasonable (Vrba, 1996).
Growth pattern of children.
Desmond Collins who was an Extension Lecturer of Archaeology at London University said that the lengthened youth period of humans is part of neoteny.
Physical anthropologist Barry Bogin said that the pattern of children's growth may intentionally increase the duration of their cuteness. Bogin said that the human brain reaches adult size when the body is only 40 percent complete, when "dental maturation is only 58 percent complete" and when "reproductive maturation is only 10 percent complete". Bogin said that this allometry of human growth allows children to have a "superficially infantile" appearance (large skull, small face, small body and sexual underdevelopment) longer than in other "mammalian species". Bogin said that this cute appearance causes a "nurturing" and "care-giving" response in "older individuals".
Neotenous features elicit help.
The Multiple Fitness Model proposes that the qualities that make babies appear cute to adults additionally look "desirable" to adults when they see other adults. Neotenous features in adult females may help elicit more resource investment and nurturing from adult males. Likewise, neotenous features in adult males may similarly help elicit more resource investment and nurturing from adult females in addition to possibly making neotenous adult males appear less threatening and possibly making neotenous adult males more able to elicit resources from "other resource-rich people". Therefore, it could be adaptive for adult females to be attracted to adult males that have "some" neotenous traits.
Caroline F. Keating et al. tested the hypothesis that adult male and female faces with more neotenous features would elicit more help than adult male and female faces with less neotenous features. Keating et al. digitally modified photographs of faces of African-Americans and European Americans to make them appear more or less neotenous by either enlarging the size of their eyes and lips or decreasing the size of their eyes and lips. Keating et al. said that the more neotenous white male, white female and black female faces elicited more help from people in the United States and Kenya, but the difference in help from people in the United States and Kenya for more neotenous black male faces was not significantly different from less neotenous black male faces.
Brain.
Helmuth Nyborg said that a testable hypothesis can be made using the GTC-A/E model with regards to "neoteny". Nyborg said that the hypothesis is that "feminized", slower maturing, "neotenic" "androtypes" will differ from "masculinized", faster maturing "androtypes" by having bigger brains, more fragile skulls, bigger hips, narrower shoulders, less physical strength, live in cities (as opposed to living in the countryside) and by receiving higher performance scores on ability tests. Nyborg said that if the predictions made by this hypothesis are true, then the "material basis" of the differences would be "explained". Nyborg said that some ecological situations would favor the survival and reproduction of the "masculinized", faster maturing "androtypes" due to their "sheer brutal force" while other ecological situations would favor the survival and reproduction of the "feminized", slower maturing, "neotenic" "androtypes" due to their "subtle tactics".
Aldo Poiani who is an evolutionary ecologist at Monash University, Australia, said that he agrees that neoteny in humans may have become "accelerated" through "two-way sexual selection" whereby females have been choosing smart males as mates and males have been choosing smart females as mates.
Neoteny has been important to human evolution, because it has increased the maturation period and the size of the human brain. Two to three million years ago, there was an "incomplete segmental duplication of [the] ancestral SRGAP2" gene in the ancestors of humans. This new gene, SRGAC2, slowed spine maturation and allowed for more neuronal migration. As a result, the dendrite spines increased in number and length, and they became "more complex". This accounts for the greater synaptic densities in humans when compared to other primates and rodents.
Somel et al. said that 48% of the genes that affect the development of the prefrontal cortex change with age differently between humans and chimpanzees. Somel et al. said that there is a "significant excess of genes" related to the development of the prefrontal cortex that show "neotenic expression in humans" relative to chimpanzees and rhesus macaques. Somel et al. said that this difference was in accordance with the neoteny hypothesis of human evolution.
Humans have been evolving toward greater "psychological neoteny." Dr. Bruce Charlton, a Newcastle University psychology professor, said what looks like immaturity — or in his terms, the “retention of youthful attitudes and behaviors into later adulthood” — is actually a valuable developmental characteristic, which he calls psychological neoteny. Highly educated people and eminent scientists demonstrate more neotenous psychological traits. In fact, the ability of an adult human to learn is considered a neotenous trait. Physical neotenization in humans has, likewise, caused psychologically neotenous traits in humans: curiosity, playfulness, affection, sociality and an innate desire to cooperate.
Between sexes.
Ashley Montagu said that the following neotenous traits are in women when compared to men: more delicate skeleton, smoother ligament attachments, smaller mastoid processes, reduced brow ridges, more forward tilt of the head, narrower joints, less hairy, retention of fetal body hair, smaller body size, more backward tilt of pelvis, greater longevity, lower basal metabolism, faster heartbeat, greater extension of development periods, higher pitched voice and larger tear ducts.
Cro-Magnon humans (40,000 to 10,000 years ago) differed from co-existing Neanderthals in the following ways: "higher forehead, less prominent brow ridges, smaller teeth, less robust bodies, and reduced sexual dimorphism."
Attractive women's faces.
In a cross-cultural study, more neotenized female faces were the most attractive to men while less neotenized female faces were the least attractive to men, regardless of the females' actual age. Using a panel of Asian, Hispanic and White judges, Michael R. Cunningham found that the Asian, Hispanic and white female faces found most attractive were those that had "neonate large eyes, greater distance between eyes, and small noses" and his study led him to conclude that "large eyes" were the most "effective" of the "neonate cues". Cunningham also said that "shiny" hair may be indicative of "neonate vitality".
Cunningham said that there was a "difference" in the preferences of Asian and White judges. Cunningham said that Asian judges preferred women with "less mature faces" and smaller mouths than the White judges. Cunningham hypothesized that this difference in preference may stem from "ethnocentrism" since "Asian faces possess those qualities", so Cunningham re-analyzed the data with "11 Asian targets excluded" and he concluded that "ethnocentrism was not a primary determinant of Asian preferences." Using a panel of Blacks and Whites as judges, Cunningham said that more neotenous faces were perceived as having both higher "femininity" and "sociability".
In contrast, Cunningham said that faces that were "low in neoteny" were judged as "intimidating". Upon analyzing the results of his study Cunningham concluded that preference for "neonate features may display the least cross-cultural variability" in terms of "attractiveness ratings". In a study of Italian women who have won beauty competitions, the study said that the women had faces characterized by more "babyness" traits compared to the "normal" women used as a reference. In a study of sixty Caucasian female faces, the average facial composite of the fifteen faces considered most attractive differed from the facial composite of the whole by having a reduced lower facial region, a thinner jaw, and a higher forehead.
Doug Jones, a visiting scholar in anthropology at Cornell University, said that there is cross-cultural evidence for preference for facial neoteny in women, because of sexual selection for the appearance of youthful fecundity in women by men. Jones said that men are more concerned about women's sexual attractiveness than women are concerned about men's sexual attractiveness. Jones said that this greater concern over female attractiveness is unusual among animals, because it is usually the females that are more concerned with the male's sexual attractiveness in other species. Jones said that this anomalous case in humans is due to women living past their reproductive years and due to women having their reproductive capacity diminish with age, resulting in the adaption in men to be selective against physical traits of age that indicate lessening female fecundity. Jones said that the neoteny in women's faces may be a "by-product" of men's attraction to indicators of "youthful fecundity" in "adult females".
A similar study was conducted on the attractiveness of males with the subject of the skull and its application in human morphology Paul Wehr and team (2001) utilized psychology and evolutionary biology to understand selection on facial features. Averageness has been a result of stabilizing selection whereas facial paedomorphosis or juvenile traits are a result of directional selection (Wehr, 2001). It is necessary at this point to define several terms to put them into practical time and space, as they pertain to this argument. The idea of directional selection as defined by Bergstrom and Dugatkin (2012) is when a single phenotypic trait is driven by selection toward fixation in a population (Bergstrom and Dugatkin, p. 218). In contrast, stabilizing selection is defined as being a scenario wherein both alleles are driven toward fixation in a population (or polymorphic, both alleles reaching equilibrium at a fixation) (Bergstrom and Dugatkin, p. 221). To compare the effects of directional and stabilizing selection on facial paedomorphosis Wehr used graphic morphing to alter appearances to make faces appear more or less juvenile. The results concluded that the effect of averageness was preferred nearly twice over juvenile trait characteristics which indicates that stabilizing selection influences facial preference, and averageness was found more attractive than the retention of juvenile facial characteristics (Wehr, 2001). This follows the conclusions of the other study presented previously. It was perplexing to find that women tend to prefer the average facial features over the juvenile, because in animals the females tend to drive sexual selection by female choice and the Red Queen hypothesis. Some may hypothesize this is because in humans women tend to focus on social features including education, job status, family background, humor, and courtships. Experiments have found males tend to focus on the attractiveness of women, whereas women focus of overall quality and verbal interactions.
Between races and among primates.
Stephen Jay Gould objected to the ranking of races as more or less neotenous, but Gould argued that if one used the terms set forth by 1920s proponents of racial neoteny, "Asians" are "clearly" the most neotenized human race.
Ashley Montagu said that the "Mongoloid skull, whether Chinese or Japanese" is the most neotenized human skull. Montagu further said that the "European" skull was less neotenized than the Mongoloid, with the "Australian Aborigine" skull less neotenized than the European and the Neanderthal skull even less neotenized than the Australian Aborigine skull. Montagu said that humans have more neotenized skulls than "Australopithecus".
Delbert D. Thiessen said that "Homo sapiens" are more neotenized than "Homo erectus", "Homo erectus" was more neotenized than "Australopithecus", Great Apes are more neotenized than Old World monkeys and Old World monkeys are more neotenized than New World monkeys.
Nancy Lynn Barrickman said that Brian T. Shea concluded by multivariate analysis that Bonobos are more neotenized than the common chimpanzee, taking into account such features as the proportionately long torso length of the Bonobo. Ashley Montagu said that part of the differences seen in the morphology of "modernlike types of man" can be attributed to different rates of "neotenous mutations" in their early populations.
San people.
Ashley Montagu said that the San have the following neotenous traits relative to Caucasoids: large brain, light skin pigment, less hairy, round-headed, bulging forehead, small cranial sinuses, flat roof of the nose, small face, small mastoid processes, wide eye separation, median eye fold, short stature and horizontal penis.
M. R. Drennan of the Department of Anatomy, University of Cape Town, said that the Bushman's skull retains infantile morphological characteristics into adulthood that are only transiently present in the juvenile forms of other races. Drennan further said that the common description of an infant's skull from anatomy textbooks "epitomizes" the characteristics of the Bushman's skull.
Phillip V. Tobias of the Department of Anatomy, University of Witwatersrand, said that there are two phenotypical patterns in occipital curvature of "African crania": one for "Negroes" and one for Bushmen. Tobias said that the skulls of Bushmen retain strongly curved occiputs from youth into adulthood, but the curved occiputs of "Negro" skulls start to flatten when their first permanent teeth erupt. Tobias said that this flattening process in "Negroes" continues until their occiputs have flattened as adults. Tobias said that there are "infantile" features in the cranial morphology of Bushmen.
Marina L. Sardi of the anthropological division at the University of La Plata, Argentina, and Fernando V. Ramírez Rozzi said South African adults have neotenized relative facial heights and nose shapes in comparison to European adults, because "Europeans" develop relatively taller faces and relatively taller and narrower noses as they mature whereas "South Africans" do not undergo this ontogenic change as they mature. However, the relative length of both the tibia and the femur to the torso becomes greater in South Africans as they mature to a greater extent than in Europeans, so the relatively shorter legs of European adults are neotenous in comparison to the greater limb-to-torso ratio of South African adults.
Frederick S. Hulse said that either natural selection or genetic drift has caused "pedomorphic qualities" to develop in the Bushmen.
Europeans.
Frederick S. Hulse said that "...modern Europeans are, on average, distinctly less pedomorphic than are most non-Europeans...".
Aboriginal Australians.
Frederick S. Hulse said that aboriginal Australians have retained "similar" "skeletal characteristics" to those "which most men possessed in earlier times" (gerontomorphic characteristics) that are "contrary" to the "pedomorphic qualities" which the Bushmen have evolved.
Mongoloids.
Ashley Montagu said, "The Mongoloid skull has proceeded further than in any other people." "The Mongoloid skull, whether Chinese or Japanese, has been rather more neotenized than the Caucasoid or European." "The female skull, it will be noted, is more pedomorphic in all human populations than the male skull."
In Ashley Montagu's list of "[n]eotenous structural traits in which Mongoloids... differ from Caucasoids", Montagu lists "Larger brain, larger braincase, broader skull, broader face, flat roof of the nose, inner eye fold, more protuberant eyes, lack of brow ridges, greater delicacy of bones, shallow mandibular fossa, small mastoid processes, stocky build, persistence of thymus gland into adult life, persistence of juvenile form of zygomatic muscle, persistence of juvenile form of superior lip muscle, later eruption of full dentition (except second and third molars), less hairy, fewer sweat glands, fewer hairs per square centimeter [and] long torso".
Ashley Montagu said, "the skeleton of the classic Mongoloid type is very delicately made, even down to the character of the sutures of the skull which, like those of the infant skull, are relatively smooth and untortuous. In fact the Mongoloid presents so many physical traits which are associated with the late fetus or young infant that he has been called a fetalized, infantilized or pedomorphic type. Those who have carefully observed young babies may recall that the root of the nose is frequently flat or low as in Mongoloids, and that an internal epicanthic fold in such instances is usually present. The smaller number of individual head hairs and the marked hairlessness of the remainder of the body are infantile traits, as are likewise the small mastoid processes, the shallow fossa into which the jawbone fits (the mandibular fossa), the rather stocky build, the large brain-pan and brain, lack of brow ridges, and quite a number of other characters."
An interpretation of a claim by zoologist Clive Bromhall is that "Mongoloid races are explained in terms of being the most extreme pedomorphic humans."
Richard Grossinger said, "The intuition that advanced human development was pedomorphic rather than recapitulationary and accelerated was disturbing to many Eurocentric nineteenth century anthropologists." "If juvenilization was the characteristic for advanced status, then it was clear that the Mongoloid races were more deeply fetalized in most respects and thus capable of the greatest development."
Stephen Oppenheimer said, "An interesting hypothesis put forward by paleontologist Stephen Jay Gould many years ago was that the package of the Mongoloid anatomical changes could be explained by the phenomenon of neoteny, whereby an infantile or childlike body form is preserved in adult life. Neoteny in hominids is still one of the simplest explanations of how we developed a disproportionately large brain so rapidly over the past few million years. The relatively large brain and the forward rotation of the skull on the spinal column, and body hair loss, both characteristic of humans, are found in foetal chimps. Gould suggested a mild intensification of neoteny in Mongoloids, in whom it has been given the name pedomorphy. Such a mechanism is likely to involve only a few controller genes and could therefore happen over a relatively short evolutionary period. It would also explain how the counterintuitive retroussé [turned up at the end] nose and relative loss of facial hair got into the package." "[D]ecrease unnecessary muscle bulk, less tooth mass, thinner bones and smaller physical size; ...this follows the selective adaptive model of Mongoloid evolution."
Paul Storm of the Naturalis Biodiversity Center, Netherlands, said that in Australasia there are two types of cranial morphologies—the "Sunda" (Mongoloid) and "Sahul" (Australoid) types. Storm said that the "Sunda" (Mongoloid) type includes Chinese and Javanese people, and he said that the "Sahul" (Australoid) type includes Papuans and Australian aborigines. Storm said that the "Sunda" (Mongoloid) type has a flat face with high cheek bones, and Storm said that this "flat face" of the Chinese and Javanese is known as the "mongoloid face". Storm further said that the "Sunda" (Mongoloid) type has a more rounded skull, "feminine (juvenile) characters", a "retention of juvenile characters" and a limited outgrowth of superstructures such as the supraorbital region. Storm said that "Sunda" (Mongoloid) skulls resemble female skulls more than "Sahul" (Australoid) skulls resemble female skulls. Storm said that the skulls of "Asian" males ("Chinese and Javanese") have "more feminine characteristics", and he said that they have "many feminine characters in contrast with Australians".
Paul Storm said that Asia contained humans with "generalized" cranial morphology, but between 20,000 BP and 12,000 BP this generalized type disappeared as a new type emerged. This new type had a flatter face with more pronounced cheekbones, a more rounded head, reduced sexual dimorphism (male skulls started to resemble female skulls), a reduction of supestructures such as the supraorbital region and an increased "retention of juvenile characters". Storm said that this new type of skull that emerged is called the "Proto-Sunda" (Proto-Mongoloid) type, and it is distinguished from the "Sunda" (Mongoloid) type by being more "robust". Storm said that the "Mongoloid" or "Asian" type of skull developed relatively fast during a population bottleneck in Asia that happened during the Late Pleistocene or Early Holocene through a microevolutionary trend that involved a "continuation of neoteny and gracilisation trends". Due to different courses of evolution, Storm said that these two types of skulls, the "Sunda" (Mongoloid) type and the "Sahul" (Australoid) type, are now clearly recognizable at the present time.
Andrew Arthur Abbie who was an anatomist and anthropologist at the University of Adelaide talked about leg-to-torso length being related to neoteny. Abbie said that women normally have shorter legs than men, and he said that shorter legs are the normal condition in some ethnic groups such as Mongoloids. Abbie said that Mongoloids of whom he listed the people of "China, Japan and the Americas" have proportionately larger heads and shorter legs than Europeans, and he said that this is a case of "paedomorphism". Abbie said that aboriginal Australians and some African ethnic groups such as the "Negro", the "Hottentot" and the "Nubian" peoples have proportionately longer legs than Europeans, and he said that this is a case of "gerontomorphism". Abbie said that ethnic groups with proportionately shorter legs than Europeans are relatively "paedomorphic" in terms of leg-to-torso ratios when compared to Europeans, and he said that ethnic groups with proportionately longer legs than Europeans are relatively "gerontomorphic" in terms of leg-to-torso ratios when compared to Europeans.
William Ernest Castle said that the difference in limb proportions between the relatively short-limbed "Chiriguan" amerindian and the relatively long-limbed "Dinka negro" is the "same" as the difference in limb proportions between "boy and man". He said that there could be an ontogenic cause that produces "long-continued growth" in populations that characteristically have relatively longer limbs, and he said that the differences in height between the races could be due to "interruptions at different stages of the general growth process".
Leonard Halford Dudley Buxton who taught physical anthropology at Oxford University said that in the "Yellow man" the depression of the nose is below the nasion rather than at the place where the nasal bones meet the frontal bone like in the "European races". Buxton said that in the "Yellow man" the nasal bones form a wider angle rather than the narrower angle of the "European races". Buxton said that these features of the nose of the "Yellow man" make it "flatter" and "not unlike that found in European children". Buxton said that "Yellow men" have the "Mongolian fold", and Buxton said that this "fold occurs occasionally in European children, and sometimes even in adults". Buxton said that the presence of the "Mongolian fold" in "Yellow men" is possibly due to the shape of the nose of "Yellow men" that "in some cases resemble that of European children".
Zoologist L. Harrison Matthews and primatologist and anatomist William Charles Osman Hill said that Mongoloids have a "high a grade of paedomorphism".
Negroids.
Ashley Montagu said that Negroids have the following neotenous traits relative to Caucasoids: flattish nose, flat roof of the nose, small ears, narrower joints, frontal skull eminences, later closure of the premaxillary sutures, less hairy, longer eyelashes and cruciform pattern of the lower second and third molars.
Specific neotenies.
Populations with a history of dairy farming have evolved to be lactose tolerant in adulthood whereas other populations generally lose the ability to break down lactose as they grow into adults.
Down syndrome.
Down syndrome neotenizes the brain and body. Down syndrome is characterized by decelerated maturation (neoteny), incomplete morphogenesis (vestigia) and atavisms.
He notes both the physical neoteny of people with Down syndrome: "round in shape," "bowed legs which tend to be short," "slanty eyes," a "long tongue" and "short fingers," and their mental neoteny: "unsexual," "playful," "affectionate," "mischievous" and "imitative".
Neoteny in other species.
Neoteny has been observed in many other species. Neoteny in amphibians seems to be the most widely studied aside from humans; many examples of neoteny in amphibians stem from studies done mainly on salamanders. There is also a general prevalence of increased neoteny within domesticated animals like dogs. Neoteny has also been noted in species similar to humans, like chimpanzees. The neotenous traits in chimpanzees that resemble those within humans may give some insight into the evolutionary history of humans. What can be gathered from many studies on neoteny is that organisms with similar lineages tend to neotenize similar features, meaning they retain related features from the juvenile form into adulthood. Finally, there are two main reasons for the occurrence of neoteny: it can either be a result of the benefit of retaining juvenile characteristics due to an environment that favors those characteristics over the adult form, or the retention of juvenile characteristics leads to greater survival because those characteristics are less costly in terms of energy expenditure.
It is important to note the difference between partial and full neoteny when looking at other species in order to distinguish between juvenile traits that are only advantageous in the short term and traits that provide a benefit throughout the organism’s life; this might then provide some insight into the cause of neoteny in those species. Partial neoteny is the retention of the larval form beyond the usual age of maturation with the possibility of the development of sexual organs progenesis, but eventually the organism still matures into the adult form; this can be seen in "Lithobates clamitans". Full neoteny is seen in "Ambystoma tigrinum". This species is part of a larger group, perrenobranchiates, which remain in their larval form for the duration of their life. This means that they are capable of reproducing and they do not mature into adult forms. The species " Rana clamata" exhibits partial neoteny when it delays its maturation through the winter season because it is not advantageous for it to metamorphose into the adult form until there are more resources available since it can find those resources much more easily in the larval form. This would fall under both of the main causes of neoteny; the energy required to survive in the winter as a newly formed adult is too costly, so the organism exhibits neotenous characteristics until a time when it is capable of better survival as an adult. "Ambystoma tigrinum" retains its neotenous features for a similar reason, however the retention is permanent due to the lack of resources available throughout its lifetime. This is another example of an environmental cause of neoteny in that the species retains juvenile characteristics because the environment limits the ability of the organism to fully come into its adult form. A few species of birds show partial neoteny. A couple examples of such species are "Chiroxiphia linearis" and "Chiroxiphia caudata". The males of both species retain their juvenile plumage into adulthood, but they eventually lose it once they are fully mature. In certain species of birds the retention of juvenile plumage is often linked to the molting times within each species. In order to ensure there is no overlap between the molting and mating times, the birds may show partial neoteny in regards to their plumage so that the males do not attain their bright adult plumage before the females are prepared to mate. In this instance, neoteny is present because there is no need for the males to molt early and it would be a waste of energy for them to try to mate when the females are not yet prepared.
Neoteny is seen more in domesticated animals like dogs and mice. This is because there are more resources available, less competition for those resources, and with the lowered competition the animals expend less energy obtaining those resources. This allows them to mature and reproduce more quickly than their wild counterparts. The environment that domesticated animals are raised in determines whether or not neoteny is present in those animals. Evolutionary neoteny can arise in a species when those conditions occur, and a species becomes sexually mature ahead of its “normal development”. Another explanation for the neoteny in domesticated animals can be the selection for certain behavioral characteristics. Behavior is linked to genetics which therefore means that when a behavioral trait is selected for, a physical trait may also be selected for due to mechanisms like linkage disequilibrium. Often, juvenile behaviors are selected for in order to more easily domesticate a species; aggressiveness in certain species comes with adulthood when there is a need to compete for resources. If there is no need for competition, then there is no need for aggression. Selecting for juvenile behavioral characteristics can lead to neoteny in physical characteristics because, for example, with the reduced need for behaviors like aggression there is no need for developed traits that would help in that area. Traits that may become neotenized due to decreased aggression may be a shorter muzzle and smaller general size among the domesticated individuals. Some common neotenous physical traits in domesticated animals (mainly dogs, pigs, ferrets, cats, and even foxes) include: floppy ears, changes in reproductive cycle, curly tails, piebald coloration, fewer or shortened vertebra, large eyes, rounded forehead, large ears, and shortened muzzle.
Neoteny is commonly seen in flightless insects like the females in the order Strepsiptera. The flightless trait in insects has evolved many separate times; environments that may have contributed to the separate evolution of this trait are: high altitudes, isolation on islands, and insects that reside in colder climates. These environmental factors may be responsible for the flightless trait, because in these situations it would be disadvantageous to have a population that is more dispersed, so flightlessness would be favored due to the boundaries it poses to dispersal. Also, in cooler temperatures heat is lost more rapidly through wings, thus the circumstance favors flightlessness. Another couple of main points to note about insects are that the females in certain groups become sexually mature without metamorphosing into adulthood, and some insects which grow up in certain conditions do not ever develop wings. Flightlessness in some female insects has been linked to higher fecundity, this would increase the fitness of the individual because the female is producing more offspring and therefore passing on more of her genes. In those instances, neoteny occurs because it is more advantageous for the females to remain flightless in order to conserve energy which thereby increases their fecundity. Aphids are a great example of insects that may never develop wings due to their environmental setting. If resources are abundant there is no need to grow wings and disperse. When the nutrition of a host plant is abundant aphids may not grow wings and stay there for the duration of their life, however if the resources become diminished the offspring may develop wings in order to disperse to other host plants.
Two common environments that tend to favor neoteny are high-altitude and cool environments because neotenous individuals have a higher fitness than those that metamorphose into the adult form. This is because the energy required for metamorphosis is too costly for the individual’s fitness, also the conditions favor neoteny due to the ability of neotenous individuals to utilize the available resources more easily. This trend can be seen in the comparison of salamander species of lower and higher altitudes. The neotenous individuals have higher survivorship as well as higher fecundity than the salamanders that had gone to the adult form in the higher altitude and cooler environment. Insects in cooler environments tend to show neoteny in flight because wings have a high surface area and lose heat quickly, thus it is not advantageous for insects in that environment to metamorphose into adults.
Many species of salamander, and amphibians in general, are known to have neotenized characteristics because of the environment they live in. The axolotl is a species of salamander that retains its juvenile aquatic form throughout adulthood, which is an excellent example of full neoteny. Gills are a common juvenile characteristic in amphibians that are kept after maturation; an example of this would be a comparison of the tiger salamander and the rough-skinned newt, both of which retain gills into adulthood. These species are better able to survive when they retain certain juvenile features, like gills, that allow them access to both aquatic and land environments.
Pygmy chimpanzees (Bonobos) share many physical characteristics with humans. A prime example are their neotenous skulls. The shape of their skull does not change into adulthood; it only increases in size. This is due to sexual dimorphism and an evolutionary change in timing of development. Juveniles became sexually mature before their bodies had fully developed into adulthood, and due to some selective advantage the neotenic structure of the skull remained in later generations.
More examples of neoteny can be seen in these other species:
1. Species in which energy costs result in neoteny-
2. Species in which the environmental conditions cause neoteny-

</doc>
<doc id="21923" url="http://en.wikipedia.org/wiki?curid=21923" title="National Rail">
National Rail

In Great Britain, National Rail is the trading name licensed for use by the Association of Train Operating Companies (ATOC), an unincorporated association whose membership consists of the passenger train operating companies (TOCs) of Great Britain that run the passenger services previously provided by the British Railways Board, from 1965 using the brand name British Rail). National Rail generally does not include services that do not have a BR history; this distinction is important because National Rail services share a ticketing structure and inter-availability that do not necessarily extend to other services. The name and the accompanying double arrow symbol are the intellectual property of the Secretary of State for Transport.
The National Rail (NR) logo was introduced by ATOC in 1999, and was used on the Great Britain public timetable for the first time in the edition valid from 26 September in that year. Rules for its use are set out in the Corporate Identity Style Guidelines published by ATOC, available on its website. The NR title is sometimes described as a "brand" but according to ATOC manuals this is incorrect; this however is in conflict with the registration information for the name and logo as recorded by the UK Intellectual Property Office. The 2000 guidelines said: 'It has not been designed as a brand or identity, but to explain to rail travellers that there is a National Railway network and material carrying this descriptor covers all passenger Train Companies.' Consistent use of the NR logo on signs and maps, however, points travellers to railway stations. As it was used by British Rail, the single operator before franchising, its use also maintains continuity and public familiarity; and it avoids the need to replace signage.
National Rail and Network Rail.
"National" Rail should not be confused with "Network Rail". National Rail is a title used to promote passenger railway services, and providing some harmonisation for passengers (e.g. tickets to all London Terminals), while Network Rail is the organisation owning and managing most of the fixed assets (tracks, signals etc.) of the railway network.
The two networks are generally coincident where passenger services are run. Most major Network Rail lines carry freight traffic and some lines are freight only. There are some scheduled passenger services on their own privately managed, non-Network Rail lines, for example Heathrow Express which also partly runs on Network Rail and the London Underground also overlaps with Network Rail in places.
Train operating companies (TOCs).
About twenty privately owned train operating companies, each franchised for a defined term by government, operate passenger trains on the main rail network in Great Britain. ATOC is the trade association representing the TOCs and provides core services, including the provision of the National Rail Enquiries service. It also runs Rail Settlement Plan, which allocates ticket revenue to the various TOCs, and Rail Staff Travel, which manages travel facilities for railway staff. It does not compile the national timetable, which is the joint responsibility of the Office of Rail Regulation (allocation of paths) and Network Rail (timetable production and publication).
Design and marketing.
Since the privatisation of British Rail there is no longer a single approach to design on railways in Great Britain. The look and feel of signage, liveries and marketing material is largely the preserve of the individual TOCs.
However, National Rail continues to use BR's famous double-arrow symbol, designed by Gerald Burney of the Design Research Unit. It has been incorporated in the National Rail logotype and is displayed on tickets, the National Rail website and other publicity. The trademark rights to the double arrow symbol remain state-owned, being vested in the Secretary of State for Transport.
The double arrow was already prescribed for indicating a "railway station".
The lettering used in the National Rail logotype is a modified form of the typeface Sassoon Bold. Some train operating companies continue to use the former British Rail Rail Alphabet lettering to varying degrees in station signage, although its use is no longer universal; however it remains compulsory (under Railway Group Standards) for safety signage in trackside areas and is still common (although not universal) on rolling stock.
It is a common misconception that Rail Alphabet was also used for printed material, but with the exception of logos ("British Rail", etc.) this has never been the case. The British Rail typefaces of choice from 1965 were Helvetica and Univers, with others (particularly Frutiger) coming into use during the sectorisation period after 1983. TOCs may use what they like: examples include Futura (Stagecoach Group), Helvetica (FirstGroup and National Express), Frutiger (Arriva Trains Wales), Bliss (CrossCountry, an Arriva franchise but not branded as such), and a modified version of Precious by London Midland.
Although TOCs compete against each other for franchises, and for passengers on routes where more than one TOC operates, the strapline used with the National Rail logo is 'Britain's train companies working together'.
Other passenger rail operators in Great Britain.
Several conurbations have their own metro or tram systems, most of which are not part of National Rail. These include the London Underground, Docklands Light Railway, Blackpool Tramway, London Tramlink, Glasgow Subway, Tyne and Wear Metro, Manchester Metrolink, Sheffield Supertram, Midland Metro and Nottingham Express Transit. On the other hand, the largely self-contained Merseyrail system is part of the National Rail network, and urban rail networks around Birmingham, Cardiff, Glasgow and West Yorkshire consist entirely of National Rail services.
London Overground (LO) is a hybrid: its services are operated via a concession awarded by Transport for London, and are branded accordingly, but until 2010 all its routes used infrastructure owned by Network Rail. LO now also possesses some infrastructure in its own right, following the reopening of the former East London line of London Underground as the East London Railway of LO. Since all the previous LO routes were operated by National Rail franchise Silverlink until November 2007, they have continued to be shown in the National Rail timetable and are still considered to be a part of National Rail.
Heathrow Express and Eurostar are also not part of the National Rail network despite sharing of stations and routes (Heathrow Express and Heathrow Connect only). Northern Ireland Railways was never part of British Rail, which was always confined to Great Britain, and therefore is not part of the National Rail network.
There are many privately owned or heritage railways in Great Britain which are not part of the National Rail network and mostly operate for heritage or pleasure purposes rather than as public transport.
Ticketing.
National Rail services have a common ticketing structure inherited from British Rail. Through tickets are available between any pair of stations on the network, and can be bought from any station ticket office. Most tickets are inter-available between the services of all operators on routes appropriate to the journey being made. Operators on some routes offer operator-specific tickets that are cheaper than the inter-available ones.
Through tickets involving Heathrow Express and London Underground are also available. Oyster pay-as-you-go can be used on National Rail in Greater London from 2 January 2010.
Passengers without a valid ticket boarding a train at a station where ticket-buying facilities are available are required to pay the full Open Single or Return fare. On some services penalty fares apply - a ticketless passenger may be charged the greater of £20 or twice the full single fare to the next stop. Penalty Fares can be collected only by authorised Revenue Protection Inspectors, not by ordinary Guards.
National Rail distributes a number of technical manuals on which travel on the railways in Great Britain is based, such as the National Rail Conditions of Carriage, via their website.
Timetables and websites.
Pocket timetables for individual operators or routes are available free at staffed stations. A complete National Rail Timetable with up to 3,000 pages was also available for purchase, but the last hard copy edition was published in May 2007. Complete timetables are still available in printed form from TSO (The Stationery Office) and also an independent publisher.
A digital version of the full timetable is available as a pdf (portable document format) file without charge on the Network Rail website. The National Rail Enquiries website, run by ATOC, includes a real-time journey planner, fares and live departure information.

</doc>
<doc id="21926" url="http://en.wikipedia.org/wiki?curid=21926" title="Naked singularity">
Naked singularity

In general relativity, a naked singularity is a gravitational singularity without an event horizon. In a black hole, the singularity is completely enclosed by a boundary known as the event horizon, inside which the gravitational force of the singularity is strong enough so that light cannot escape. Hence, objects inside the event horizon—including the singularity itself—cannot be directly observed. A naked singularity, by contrast, is observable from the outside.
The theoretical existence of naked singularities is important because their existence would mean that it would be possible to observe the collapse of an object to "infinite density". It would also cause foundational problems for general relativity, because general relativity cannot make predictions about the future evolution of space-time near a singularity. In generic black holes, this is not a problem, as an outside viewer cannot observe the space-time within the event horizon.
Some research has suggested that if loop quantum gravity is correct, then naked singularities could exist in nature, implying that the cosmic censorship hypothesis does not hold. Numerical calculations and some other arguments have also hinted at this possibility.
To this date, no naked singularities (and no event horizons) have been observed.
Predicted formation.
From concepts drawn of rotating black holes, it is shown that a singularity, spinning rapidly, can become a ring-shaped object. This results in two event horizons, as well as an ergosphere, which draw closer together as the spin of the singularity increases. When the outer and inner event horizons merge, they shrink toward the rotating singularity and eventually expose it to the rest of the universe.
A singularity rotating fast enough might be created by the collapse of dust or by a supernova of a fast-spinning star. Studies of pulsars and some computer simulations (Choptuik, 1997) have been performed.
This is an example of a mathematical difficulty (divergence to infinity of the density) which reveals a more profound problem in our understanding of the relevant physics involved in the process. A workable theory of quantum gravity should be able to solve problems such as these.
Metrics.
Disappearing event horizons exist in the Kerr metric, which is a spinning black hole in a vacuum. Specifically, if the angular momentum is high enough the event horizons will disappear. Transforming the Kerr metric to Boyer–Lindquist coordinates, it can be shown that the formula_1 coordinate (which is not the radius) of the event horizon is
formula_2,
where formula_3, and formula_4. In this case, "event horizons disappear" means when the solutions are complex for formula_5, or formula_6.
Disappearing event horizons can also be seen with the Reissner–Nordström geometry of a charged black hole. In this metric it can be shown that the singularities occur at
formula_7,
where formula_3, and formula_9. Of the three possible cases for the relative values of formula_10 and formula_11, the case where formula_12 causes both formula_5 to be complex. This means the metric is regular for all positive values of formula_1, or in other words the singularity has no event horizon.
See Kerr–Newman metric for a spinning, charged ring singularity.
Effects.
A naked singularity could allow scientists to observe an infinitely dense material, which would under normal circumstances be impossible by the cosmic censorship hypothesis. Without an event horizon of any kind, some speculate that naked singularities could actually emit light.
Cosmic censorship hypothesis.
The cosmic censorship hypothesis says that a naked singularity cannot arise in our universe from realistic initial conditions.

</doc>
