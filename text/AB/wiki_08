<doc id="14378" url="http://en.wikipedia.org/wiki?curid=14378" title="History of Finland">
History of Finland

The land area that now makes up Finland was probably settled immediately after the last ice age, which ended c. 9000 BCE. Most of the region was a part of the Kingdom of Sweden from the 13th century to 1809, when the vast majority of the Finnish-speaking areas of Sweden were ceded to the Russian Empire (excluding the Finnish-speaking areas of the modern-day Northern Sweden), making this area the autonomous Grand Duchy of Finland. The Lutheran religion dominated. Finnish nationalism emerged, focused on Finnish cultural traditions, including music and—especially—the highly distinctive language and lyrics associated with it. The catastrophic Finnish famine of 1866–1868 was followed by eased economic regulations and extensive emigration.
In 1917, Finland declared independence. A civil war between the Finnish Red Guards and the White Guard ensued a few months later, with the "Whites" gaining the upper hand during the springtime of 1918. After the internal affairs stabilized, the still mainly agrarian economy grew relatively fast. Relations with the West, especially Sweden and Britain, were strong but tensions remained with the Soviet Union. During the Second World War, Finland fought twice against the Soviet Union and defended its independence, though in the 1947 peace settlement, it ended up ceding a large part of Karelia and some other areas to the Soviet Union. However, Finland remained an independent democracy in North Europe.
In the latter half of its independent history, Finland has maintained a mixed economy. Since its post-World War II economic boom in the 1970s, Finland's GDP per capita has been among the world's highest. The expanded welfare state of Finland from 1970 and 1990 increased the public sector employees and spending and the tax burden imposed on the citizens. In 1992, Finland simultaneously faced economic overheating and depressed Western, Russian, and local markets. Finland joined the European Union in 1995, and replaced the Finnish markka with the euro in 2002. According to a 2005 poll, most Finns at that point were reluctant to join NATO.
Prehistory.
Paleolithic.
If confirmed, the oldest archeological site in Finland would be the Wolf Cave in Kristinestad, in Ostrobothnia. Excavations are currently underway, and if the so far presented estimates hold true, the site would be the only pre-glacial (Neanderthal) site so far discovered in the Nordic Countries, and it is approximately 125,000 years old .
Mesolithic.
The last ice age in the area of the modern-day Finland ended c. 9000 BCE. Starting about that time, people migrated to the area of Finland from the Kunda and—possibly—Swiderian cultures, and they are believed to be ancestors of today's Finnish and Sami people in Finland.
The oldest confirmed evidence of the post-glacial human settlements in Finland are from the area of Ristola in Lahti and from Orimattila, from c. 8900 BCE. Finland has been continuously inhabited at least since the end of the last ice age, up to the present.
The earliest post-glacial inhabitants of the present-day area of Finland were probably mainly seasonal hunter-gatherers. Their artifacts discovered are known to represent the Suomusjärvi and the Kunda cultures. Among finds is the net of Antrea, the oldest fishing net known ever to have been excavated (calibrated carbon dating: c. 8300 BCE).
Neolithic.
By 5300 BCE pottery was present in Finland. The earliest samples belong to the Comb Ceramic Cultures, known for their distinctive decorating patterns. This marks the beginning of the neolithic period for Finland, although subsistence was still based on hunting and fishing. Extensive networks of exchange existed across Finland and Northeastern Europe during the 5th millennium BCE. For example, flint from Scandinavia and the Valdai Hills, amber from Scandinavia and the Baltic region and slate from Scandinavia and Lake Onega found their way into Finnish archeological sites, while asbestos and soap stone from e.g. the area of Saimaa spread outside of Finland. Rock paintings—apparently related to shamanistic and totemistic belief systems—have been found, especially in Eastern Finland, e.g. Astuvansalmi.
From 3200 BCE onwards, either immigrants or a strong cultural influence from south of the Gulf of Finland settled in Southwestern Finland. This culture was a part of the European Battle Axe cultures, which have often been associated with the movement of the Indo-European speakers. The Battle-Axe—or Cord Ceramic—culture seems to have practiced agriculture and animal husbandry outside of Finland, but the earliest confirmed traces of agriculture in Finland date later, approximately to the 2nd millennium BCE. Further inland, the societies retained their hunting-gathering lifestyles for the time being.
The Battle axe and the Comb Ceramic cultures merged, giving rise to the Kiukainen culture which existed between 2300 BCE and 1500 BCE, featuring fundamentally a comb ceramic tradition with cord ceramic characteristics.
Bronze Age.
The Bronze Age began some time after 1500 BCE. The coastal regions of Finland were a part of the Nordic Bronze Culture, whereas in the inland regions the influences came from the bronze-using cultures of Northern and Eastern Russia.
Iron Age.
The Iron Age in Finland is considered to last from c.500 BCE until c.1300 CE when known official and written records of Finland become more common due to the Swedish invasions as part of the Northern Crusades in the 13th century. As the Finnish Iron Age lasted almost two Millennia, it is further divided into six sub periods:
Very few written records of Finland or its people remain in any language of the era, but this is especially true of Finnic languages, which were only phonetically transliterated at the time. Primary written sources are thus mostly of foreign origin, most informative of which include Tacitus description of "Fenni" in his "Germania", the sagas written down by Snorri Sturluson as well as the 12th- and 13th-century ecclesiastical letters for Finns. Numerous other sources from the Roman period onwards contain brief mentions of ancient (and probably also mythological) Finnish kings and place names, nevertheless defining Finland as a kingdom and culture of its people.
Currently the oldest known Scandinavian documents mentioning a "land of the Finns" are two runestones: Söderby, Sweden, with the inscription "finlont" (U 582 †), Gotland with the inscription "finlandi" (G 319 M) dating from the 11th century. However, as the long continuum of the Finnish Iron Age into the historical Medieval period of Europe suggests, the primary source of information of the era in Finland is based on archaeological findings and modern appliances of natural scientific methods like those of DNA analysis or computer linguistics.
The production of the Ages name sake, the iron, was adopted from the neighboring cultures in the east, west and south about the same time as the first imported iron artifacts appear. This happened almost simultaneously in various parts of the country.
Pre-Roman period 500BCE - "0".
The Pre-Roman period of the Finnish Iron Age is scarcest in findings but the known ones suggest, that cultural connections to other Baltic cultures were already established. for which the findings of Pernaja and Savukoski provide solid argument. Many of the era's dwelling sites are the same as those of the Neolithic. Most of the iron of the era was typically produced on site.
Roman period "0" - 400CE.
The Roman period brought along an influx of imported iron (and other) artifacts like Roman wine glasses and dippers as well as various coins of the Empire. During this period the (proto) Finnish culture stabilized also on the coastal regions and larger graveyards become commonplace. The prosperity of the Finns rises to the level that the vast majority of gold treasures found within Finland date back to this period.
Migration period 400CE - 575CE.
The Migration period saw the expansion of land cultivation inland, especially in the Southern Bothnia and the growing influence of Germanic cultures both in the artifacts like swords and other weapons as well as in burial customs. However the primary source of iron as well as its forging was of domestic origin, probably from bog iron.
Merovingian period 575CE - 800CE.
The Merovingian period in Finland gave birth to distinctive fine crafts culture of its own, visible in the original decorations of domestically produced weapons and jewellery. Finest luxury weapons were, however imported from Western Europe. The very first Christian burials are found from the latter part of this era as well. The Leväluhta burial findings suggest that the average height of a man was 158 cm and that of a woman was 147 cm.
Viking Age 800CE - 1025CE.
Recent findings suggest, that the Finnish trade connections became more active already during the 8th century bringing an influx of silver onto Finnish markets. The opening of the Vikings eastern route to Constantinople via Finland's southern coast line archipelago brought Arabic and Byzantine artifacts into the excavation findings of the era.
The earliest findings of imported iron blades and local iron working appear in 500 BCE. From about 50 CE, there are indications of a more intense long-distance exchange of goods in coastal Finland. Inhabitants exchanged their products, presumably, mostly furs, for weapons and ornaments with the Balts and the Scandinavians as well as with the peoples along the traditional eastern trade routes. The existence of richly furnished burials, usually with weapons, suggests that there was a chiefly elite in southern and western parts of the country. Hillforts spread over most of southern Finland at the end of the Iron and early Medieval Age. There is no commonly accepted evidence of early state formations in Finland, and the presumedly Iron Age origins of urbanisation are contested.
Middle Ages.
Contact between Sweden and what is now Finland was considerable even during pre-Christian times—the Vikings were known to Finns both due to their participation in commerce and plundering. There is possible evidence of Viking settlement in the Finnish mainland. The Åland Islands probably had Swedish settlement during the Viking Period. However, some scholars claim that the archipelago was deserted during the 11th century.
According to the archaeological finds, Christianity gained a foothold in Finland during the 11th century. According to the very few written documents that have survived, the church in Finland was still in its early development in the 12th century. Later medieval legends describe Swedish attempts to conquer and Christianize Finland sometime in the mid-1150s. In the early 13th century, Bishop Thomas became the first bishop of Finland. There were several secular powers who aimed to bring the Finns under their rule. These were Sweden, Denmark, the Republic of Novgorod in Northwestern Russia and probably the German crusading orders as well. Finns had their own chiefs, but most probably no central authority. Russian chronicles indicate there were conflict between Novgorod and the Finnic tribes from the 11th or 12th century to the early 13th century.
The name "Finland" originally signified only the southwestern province that has been known as "Finland Proper" since the 18th century. Österland (lit. Eastern Land) was the original name for the Swedish realm's eastern part, but already in the 15th century Finland began to be used synonymously with Österland. The concept of a Finnish "country" in the modern sense developed only slowly during from the 15th to 18th centuries. 
It was the Swedish regent, Birger Jarl, who allegedly established Swedish rule in Finland through the Second Swedish Crusade, most often dated to 1249. It has been suggested that the "crusade" was aimed at Tavastians who had stopped being Christian and returned to their old ethnic faith. Novgorod gained control in Karelia, the region inhabited by speakers of Eastern Finnish dialects. Sweden however gained the control of Western Karelia with the Third Finnish Crusade in 1293. Western Karelians were from then on viewed as part of the western cultural sphere, while eastern Karelians turned culturally to Russia and Orthodoxy. While eastern Karelians remain linguistically and ethnically closely related to the Finns, they are considered a people of their own by most. Thus, the northern border between Catholic and Orthodox Christendom came to lie at the eastern border of what would become Finland with the Treaty of Nöteborg in 1323.
During the 13th century, Finland was integrated into medieval European civilization. The Dominican order arrived in Finland around 1249 and came to exercise huge influence there. In the early 14th century, the first documents of Finnish students at Sorbonne appear. In the south-western part of the country, an urban settlement evolved in Turku. Turku was one of the biggest towns in the Kingdom of Sweden, and its population included German merchants and craftsmen. Otherwise the degree of urbanization was very low in medieval Finland. Southern Finland and the long coastal zone of the Bothnian Gulf had a sparse farming settlement, organized as parishes and castellanies. In the other parts of the country a small population of Sami hunters, fishermen and small-scale farmers lived. These were exploited by the Finnish and Karelian tax collectors. During the 12th and 13th centuries, great numbers of Swedish settlers moved to the southern and north-western coasts of Finland, to the Åland Islands and to the archipelago between Turku and the Åland Islands: in these regions, the Swedish language is widely spoken even today. Swedish came to be the language of the high-status people in many other parts of Finland as well.
During the 13th century, the bishopric of Turku was established. The cathedral of Turku was the center of the cult of Saint Henry, and naturally the cultural center of the bishopric. The bishop had the ecclesiastical authority over much of today's Finland and was usually the most powerful man there. Bishops were often Finns, whereas the commanders in the castles were more often Scandinavian or German noblemen. In 1362, representatives from Finland were called to participate in the elections for king of Sweden. That year is often held to signify the incorporation of Finland into the kingdom of Sweden. As in the Scandinavian part of the kingdom, a gentry or (lower) nobility consisted of magnates and yeomen who could afford armament for a man and a horse. These were concentrated in the southern part of Finland.
The strong fortress of Viborg (Finnish: "Viipuri", Russian: "Vyborg") guarded the eastern border of Finland. Sweden and Novgorod signed the Treaty of Nöteborg ("Pähkinäsaari" in Finnish) in 1323, but that would not last long. For example, in 1348 the Swedish king Magnus Eriksson staged a failed crusade against the Orthodox "heretics", managing only to alienate his supporters and finally losing his crown. The bones of contention between Sweden and Novgorod were the northern coastline of the Bothnian Gulf and the wilderness regions of Savo in Eastern Finland. Novgorod considered these as hunting and fishing grounds of its Karelian subjects, protesting against the slow infiltration of Catholic settlers from the West. Occasional raids and clashes between Swedes and Novgorodians occurred during the late 14th and 15th centuries, but for most of the time an uneasy peace prevailed. There existed internal tensions as well. During the 1380s a civil war in the Scandinavian part of Sweden brought unrest to Finland, too. The victor of this struggle was Queen Margaret I of Denmark, who brought the three Scandinavian kingdoms of Sweden, Denmark and Norway under her rule (the "Kalmar Union") in 1389. The next 130 years or so were characterized by attempts of different Swedish factions to break out of the Union. Finland was sometimes involved in these struggles, but in general the 15th century seems to have been a relatively prosperous time, characterized by population growth and economic development. Towards the end of the 15th century, however, the situation on the eastern border was becoming more tense. The Principality of Moscow conquered Novgorod, preparing the way for a unified Russia, and soon tensions arose with Sweden. In 1495–1497, a war between Sweden and Russia was fought. The fortress-town of Viborg stood against a Russian siege: according to a contemporary legend, it was saved by a miracle.
16th century.
In 1521 the Kalmar Union collapsed and Gustav Vasa became the King of Sweden. During his rule, the Swedish church was reformed (1527). The state administration underwent extensive reforms and development too, giving it a much stronger grip on the life of local communities—and ability to collect higher taxes. Following the policies of the Reformation, in 1551 Mikael Agricola, bishop of Turku, published his translation of the New Testament into the Finnish language.
In 1550 Helsinki was founded by Gustav Vasa under the name of Helsingfors, but remained little more than a fishing village for more than two centuries.
King Gustav Vasa died in 1560 and his crown was passed to his three sons in separate turns. King Erik XIV started an era of expansion when the Swedish crown took the city of Tallinn in Estonia under its protection in 1561. The Livonian War was the beginning of a warlike era which lasted for 160 years. In the first phase, Sweden fought for the lordship of Estonia and Latvia against Denmark, Poland and Russia. The common people of Finland suffered because of drafts, high taxes, and abuse by military personnel. This resulted in the Cudgel War of 1596–1597, a desperate peasant rebellion, which was suppressed brutally and bloodily. A peace treaty (the Treaty of Teusina) with Russia in 1595 moved the border of Finland further to the east and north, very roughly where the modern border lies.
An important part of the 16th century history of Finland was growth of the area settled by the farming population. The crown encouraged farmers from the province of Savonia to settle the vast wilderness regions in Middle Finland. This was done, and the original Sami population often had to leave. Some of the wilderness settled was traditional hunting and fishing territory of Karelian hunters. During the 1580s, this resulted in a bloody guerrilla warfare between the Finnish settlers and Karelians in some regions, especially in Ostrobothnia.
17th century – the Swedish Empire.
In 1611–1632 Sweden was ruled by King Gustavus Adolphus, whose military reforms transformed the Swedish army from a peasant militia into an efficient fighting machine, possibly the best in Europe. The conquest of Livonia was now completed, and some territories were taken from internally divided Russia in the Treaty of Stolbova. In 1630, the Swedish (and Finnish) armies marched into Central Europe, as Sweden had decided to take part in the great struggle between Protestant and Catholic forces in Germany, known as the Thirty Years' War. The Finnish light cavalry was known as the Hakkapeliitat.
After the Peace of Westphalia in 1648, the Swedish Empire was one of the most powerful countries in Europe. During the war, several important reforms had been made in Finland:
However, the high taxation, continuing wars and the cold climate (the Little Ice Age) made the Imperial era of Sweden rather gloomy times for Finnish peasants. In 1655–1660, the Northern Wars were fought, taking Finnish soldiers to the battle-fields of Livonia, Poland and Denmark. In 1676, the political system of Sweden was transformed into an absolute monarchy.
In Middle and Eastern Finland, great amounts of tar were produced for export. European nations needed this material for the maintenance of their fleets. According to some theories, the spirit of early capitalism in the tar-producing province of Ostrobothnia may have been the reason for the witch-hunt wave that happened in this region during the late 17th century. The people were developing more expectations and plans for the future, and when these were not realized, they were quick to blame witches—according to a belief system the Lutheran church had imported from Germany.
The Empire had a colony in the New World in the modern-day Delaware-Pennsylvania area between 1638–1655. At least half of the immigrants were of Finnish origin.
The 17th century was an era of very strict Lutheran orthodoxy. In 1608, the law of Moses was declared the law of the land, in addition to secular legislation. Every subject of the realm was required to confess the Lutheran faith and church attendance was mandatory. Ecclesiastical penalties were widely used. The rigorous requirements of orthodoxy were revealed in the dismissal of the Bishop of Turku, Johan Terserus, who wrote a catechism which was decreed heretical in 1664 by the theologians of the Academy of Åbo. On the other hand, the Lutheran requirement of the individual study of Bible prompted the first attempts at wide-scale education. The church required from each person a degree of literacy sufficient to read the basic texts of the Lutheran faith. Although the requirements could be fulfilled by learning the texts by heart, also the skill of reading became known among the population.
In 1696–1699, a famine caused by climate decimated Finland. A combination of an early frost, the freezing temperatures preventing grain from reaching Finnish ports, and a lackluster response from the Swedish government saw about one-third of the population die. Soon afterwards, another war determining Finland's fate began (the Great Northern War of 1700–21).
18th century – the Age of Enlightenment.
Wars.
The Great Northern War (1700–1721) was devastating, as Sweden and Russia fought for control of the Baltic. Harsh conditions—worsening poverty and repeated crop failures—among peasants undermined support for the war, leading to Sweden's defeat. Finland was a battleground as both armies ravaged the countryside, leading to famine, epidemics, social disruption and the loss of nearly half the population. By 1721 only 250,000 remained. Landowners had to pay higher wages to keep their peasants. Russia was the winner, annexing the south-eastern part, including the town of Viborg, after the Treaty of Nystad. The border with Russia came to lie roughly where it returned to after World War II. Sweden's status as a European great power was forfeit, and Russia was now the leading power in the North. The absolute monarchy was ended in Sweden. During this Age of Liberty, the Parliament ruled the country, and the two parties of the Hats and Caps struggled for control leaving the lesser Court party, i.e. parliamentarians with close connections to the royal court, with little to no influence. The Caps wanted to have a peaceful relationship with Russia and were supported by many Finns, while other Finns longed for revenge and supported the Hats.
Finland by this time was depopulated, with a population in 1749 of 427,000. However with peace the population grew rapidly, and doubled before 1800. 90% of the population were typically classified as "peasants", most being free taxed yeomen. Society was divided into four Estates: peasants (free taxed yeomen), the clergy, nobility and burghers. A minority, mostly cottagers, were estateless, and had no political representation. Forty-five percent of the male population were enfranchised with full political representation in the legislature—although clerics, nobles and townsfolk had their own chambers in the parliament, boosting their political influence and excluding the peasantry on matters of foreign policy.
The mid-18th century was a relatively good time, partly because life was now more peaceful. However, during the Lesser Wrath (1741–1742), Finland was again occupied by the Russians after the government, during a period of Hat party dominance, had made a botched attempt to reconquer the lost provinces. Instead the result of the Treaty of Åbo was that the Russian border was moved further to the west. During this time, Russian propaganda hinted at the possibility of creating a separate Finnish kingdom.
Both the ascending Russian Empire and pre-revolutionary France aspired to have Sweden as a client state. Parliamentarians and others with influence were susceptible to taking bribes which they did their best to increase. The integrity and the credibility of the political system waned, and in 1771 the young and charismatic king Gustav III staged a coup d'état, abolished parliamentarism and reinstated royal power in Sweden—more or less with the support of the parliament. In 1788, he started a new war against Russia. Despite a couple of victorious battles, the war was fruitless, managing only to bring disturbance to the economic life of Finland. The popularity of King Gustav III waned considerably. During the war, a group of officers made the famous Anjala declaration demanding peace negotiations and calling of "Riksdag" (Parliament). An interesting sideline to this process was the conspiracy of some Finnish officers, who attempted to create an independent Finnish state with Russian support. After an initial shock, Gustav III crushed this opposition. In 1789, the new constitution of Sweden strengthened the royal power further, as well as improving the status of the peasantry. However, the continuing war had to be finished without conquests—and many Swedes now considered the king as a tyrant.
With the interruption of the war (1788–1790), the last decades of the 18th century had been an era of development in Finland. New things were changing even everyday life, such as starting of potato farming after the 1750s. New scientific and technical inventions were seen. The first hot air balloon in Finland (and in the whole Swedish kingdom) was made in Oulu (Uleåborg) in 1784, only a year after it was invented in France. Trade increased and the peasantry was growing more affluent and self-conscious. The Age of Enlightenment's climate of broadened debate in the society on issues of politics, religion and morals would in due time highlight the problem that the overwhelming majority of Finns spoke only Finnish, but the cascade of newspapers, belles-lettres and political leaflets was almost exclusively in Swedish—when not in French.
The two Russian occupations had been harsh and were not easily forgotten. These occupations were a seed of a feeling of separateness and otherness, that in a narrow circle of scholars and intellectuals at the university in Turku was forming a sense of a separate Finnish identity representing the eastern part of the realm. The shining influence of the Russian imperial capital Saint Petersburg was also much stronger in southern Finland than in other parts of Sweden, and contacts across the new border dispersed the worst fears for the fate of the educated and trading classes under a Russian régime. At the turn of the 19th century, the Swedish-speaking educated classes of officers, clerics and civil servants were mentally well prepared for a shift of allegiance to the strong Russian Empire.
King Gustav III was assassinated in 1792, and his son Gustav IV Adolf assumed the crown after a period of regency. The new king was not a particularly talented ruler; at least not talented enough to steer his kingdom through the dangerous era of the French Revolution and Napoleonic wars.
Meanwhile, the Finnish areas belonging to Russia after the peace treaties in 1721 and 1743 (not including Ingria), called "Old Finland" were initially governed with the old Swedish laws (a not uncommon practice in the expanding Russian Empire in the 18th century). However, gradually the rulers of Russia granted large estates of land to their non-Finnish favorites, ignoring the traditional landownership and peasant freedom laws of Old Finland. There were even cases where the noblemen punished peasants corporally, for example by flogging. The overall situation caused decline in the economy and morale in Old Finland, worsened since 1797 when the area was forced to send men to the Imperial Army. The construction of military installations in the area brought thousands of non-Finnish people to the region. In 1812, after the Russian conquest of Finland, "Old Finland" was rejoined to the rest of the country but the landownership question remained a serious problem until the 1870s.
Chronology of the Finno-Ugric, Finnic, Indo-European and Germanic languages in Finland.
The question of the time lines for the evolution and the spreading of the contemporary languages is controversial, and new theories challenging older postulations have been introduced continuously.
According to the recently most widespread presumption, Finno-Ugric (or Uralic) languages were first spoken in Finland and the adjacent areas during the (typical) Comb Ceramic period, around 4000 BCE at the latest. During the 2nd millennium BCE these evolved—possibly under an Indo-European (most likely Baltic) influence—into proto-Sami (inland) and proto(-Baltic)-Finnic (coast). However, this theory has been increasingly contested among comparative linguists. It has been suggested instead that the Finno-Ugric languages arrived in Finland later, perhaps only during the Iron Age. The Finnish language is thought to have started to differentiate during the Iron Age starting from the 1st centuries CE onwards.
Cultural influences from all points of the compass are visible in the Finnish archeological finds from the very first settlements onwards. E.g. archaeological finds from Finnish Lapland suggest the presence of the Komsa culture. The Sujala finds equal in age with the earliest Komsa-artefacts from Norway but may suggest also a connection to the Swiderian culture. South-Western Finland belonged to the Nordic Bronze Age, which may be associated with Indo-European languages and according to Finnish Germanist Jorma Koivulehto speakers of Proto-Germanic language in particular. Artefacts found in Kalanti and the province of Satakunta, for long monolingually Finnish, and their place-names have made several scholars argue for an existence of a proto-Germanic speaking population component a little later, during the Early and Middle Iron Age. Old Norse-speaking population settled parts of Finland's coastal areas in the 12th to 13th centuries. Swedish language differentiated from the eastern Norse dialects by the 13th century. During the subsequent Swedish reign over Finland particularly the coastal areas witnessed waves of settlement from Sweden.[Source?]
Peasants.
While the king of Sweden sent in his governor to rule Finland, in day to day reality the villagers ran their own affairs using traditional local assemblies (called the ting) which selected a local "lagman", or lawman, to enforce the norms. The Swedes used the parish system to collect taxes. The socken (local parish) was at once a community religious organization and a judicial district that administered the king's law. The ting participated in the taxation process; taxes were collected by the bailiff, a royal appointee.
In contrast to serfdom in Germany and Russia, the Finnish peasant was typically a freeholder who owned and controlled his small plot of land. There was no serfdom in which peasants were permanently attached to specific lands, and were ruled by the owners of that land. In Finland (and Sweden) the peasants formed one of the four estates and were represented in the parliament. Outside the political sphere, however, the peasants were considered at the bottom of the social order—just above vagabonds. The upper classes looked down on them as excessively prone to drunkenness and laziness, as clannish and untrustworthy, and especially as lacking honor and a sense of national spirit. This disdain dramatically changed in the 19th century when everyone idealised the peasant as the true carrier of Finnishness and the national ethos, as opposed to the Swedish-speaking elites.
The peasants were not passive; they were proud of their traditions and would band together and fight to uphold their traditional rights in the face of burdensome taxes from the king or new demands by the landowning nobility. The great "Club War" in the south in 1596–1597 attacked the nobles and their new system of state feudalism; this bloody revolt was similar to other contemporary peasant wars in Europe. In the north, there was less tension between nobles and peasants and more equality among peasants, due to the practice of subdividing farms among heirs, to non farm economic activities, and to the small numbers of nobility and gentry. Often the nobles and landowners were paternalistic and helpful. The Crown usually sided with the nobles, but after the "restitution" of the 1680s it ended the practice of the nobility extracting labor from the peasants and instead began a new tax system whereby royal bureaucrats collected taxes directly from the peasants, who disliked the efficient new system. After 1800 growing population pressure resulted in larger numbers of poor crofters and landless laborers and the impoverishment of small farmers.
Russian Grand Duchy.
During the Finnish War between Sweden and Russia, Finland was again conquered by the armies of Tsar Alexander I. The four Estates of occupied Finland were assembled at the Diet of Porvoo on March 29, 1809 to pledge allegiance to Alexander I of Russia. Following the Swedish defeat in the war and the signing of the Treaty of Fredrikshamn on September 17, 1809, Finland remained a Grand Duchy in the Russian Empire until the end of 1917, with the czar as Grand Duke. Russia assigned Karelia ("Old Finland") to the Grand Duchy in 1812. During the years of Russian rule the degree of autonomy varied. Periods of censorship and political prosecution occurred, particularly in the two last decades of Russian control, but the Finnish peasantry remained free (unlike the Russian serfs) as the old Swedish law remained effective (including the relevant parts from Gustav III's Constitution of 1772). The old four-chamber Diet was re-activated in the 1860s agreeing to supplementary new legislation concerning internal affairs.
Economy.
Before 1860 overseas merchant firms and the owners of landed estates had accumulated wealth that became available for industrial investments. After 1860 the government liberalized economic laws and began to build a suitable physical infrastructure of ports, railroads and telegraph lines. The domestic market was small but rapid growth took place after 1860 in export industries drawing on forest resources and mobile rural laborers. Industrialization began during the mid-19th century from forestry to industry, mining and machinery and laid the foundation of Finland's current day prosperity, even though agriculture employed a relatively large part of the population until the post–World War II era.
The beginnings of industrialism took place in Helsinki. Alfred Kihlman (1825–1904) began as a Lutheran priest and director of the elite Helsingfors boys' school, the Swedish Normal Lyceum. He became a financier and member of the diet. There was little precedent in Finland in the 1850s for raising venture capital. Kihlman was well connected and enlisted businessmen and capitalists to invest in new enterprises. In 1869, he organized a limited partnership that supported two years of developmental activities that led to the founding of the Nokia company in 1871.
After 1890 industrial productivity stagnated because entrepreneurs were unable to keep up with technological innovations made by competitors in Germany, Britain and the United States. However, Russification opened up a large Russian market especially for machinery.
Nationalism.
The Finnish national awakening in the mid-19th century was the result of members of the Swedish-speaking upper classes deliberately choosing to promote Finnish culture and language as a means of nation building, i.e. to establish a feeling of unity among all people in Finland including (and not of least importance) between the ruling elite and the ruled peasantry. The publication in 1835 of the Finnish national epic, the Kalevala, a collection of traditional myths and legends which is the folklore of the Karelian people (the Finnic Russian Orthodox people who inhabit the Lake Ladoga-region of eastern Finland and present-day NW Russia), stirred the nationalism that later led to Finland's independence from Russia.
Particularly following Finland's incorporation into the Swedish central administration during the 16th and 17th centuries, Swedish was spoken by about 15% of the population, especially the upper and middle classes. Swedish was the language of administration, public institutions, education and cultural life. Only the peasants spoke Finnish. The emergence of Finnish to predominance resulted from a 19th-century surge of Finnish nationalism, aided by Russian bureaucrats attempting to separate Finns from Sweden and to ensure the Finns' loyalty.
In 1863, the Finnish language gained an official position in administration. In 1892 Finnish finally became an equal official language and gained a status comparable to that of Swedish. Nevertheless, the Swedish language continued to be the language of culture, arts and business all the way to the 1920s.
Movements toward Finnish national pride, as well as liberalism in politics and economics involved ethnic and class dimensions. The nationalist movement against Russia began with the Fennoman movement led by Hegelian philosopher Johan Vilhelm Snellman in the 1830s. Snellman sought to apply philosophy to social action and moved the basis of Finnish nationalism to establishment of the language in the schools, while remaining loyal to the czar. Fennomania became the Finnish Party in the 1860s. 
Liberalism was the central issue of the 1860s to 1880s. The language issue overlapped both liberalism and nationalism, and showed some a class conflict as well, with the peasants pitted against the conservative Swedish-speaking landowners and nobles. As complications, the Finnish activists divided into "old" (no compromise on the language question and conservative nationalism) and "young" (liberation from Russia) Finns. The leading liberals were Swedish-speaking intellectuals who called for more democracy; they became the radical leaders after 1880. The liberals organized for social democracy, labor unions, farmer cooperatives, and women's rights.
Nationalism was contested by the pro-Russian element and by the internationalism of the labor movement. The result was a tendency to class conflict over nationalism, but the early 1900s the working classes split into the Valpas (class struggle emphasis) and Mäkelin (nationalist emphasis).
Religion.
The Finns were Lutherans but there were two strains that eventually merged to form the modern Finnish church. On the one hand was the high-church emphasis on ritual, with its roots in traditional peasant collective society. Paavo Ruotsalainen (1777–1852) on the other hand was a leader of the new pietism, with its subjectivity, revivalism, emphasis on personal morality, lay participation, and the social gospel. The pietism appealed to the emerging middle class. The Ecclesiastical Law of 1869 combined the two strains. Finland's political and Lutheran leaders considered both Russian Orthodoxy and Roman Catholicism to be threats to the emerging nation. Orthodoxy was rejected as a weapon of Russification, while anti-Catholicism was long-standing. Anti-Semitism was also a factor, so the Dissenter Law of 1889 upgraded the status only of the minor Protestant sects.
Music.
Before 1790 music was found in Lutheran churches and in folk traditions. In 1790 music lovers founded the Åbo Musical Society; it gave the first major stimulus to serious music by Finnish composers. In the 1880s, new institutions, especially the Helsinki Music Institute (since 1939 called the Sibelius Academy), the Institute of Music of Helsinki University and the Helsinki Philharmonic Orchestra, integrated Finland into the mainstream of European music. By far the most influential composer was Jean Sibelius (1865–1957); he composed most of his music before 1930. In April 1892 Sibelius presented his new symphony 'Kullervo' in Helsinki. It featured poetry from the "Kalevala," and was celebrated by critics as truly Finnish music.
Women.
Upper and upper middle class women took the lead in the deaconess movement in Finland. Coordinated by the Lutheran church, the women undertook local charitable social work to ameliorate harsh living conditions created by peasants adjusting to city life. They promoted nursing as a suitable profession for respectable women. Their efforts helped redefine the complex relationship between private charities and the traditional state and church responsibility for social welfare. Because they volunteered without pay and emphasized motherhood and nurturing as moral values for women, they contributed to the entrenchment of what in the 20th century became widespread gender roles.
Russification.
The policy of Russification of Finland (1899–1905 and 1908–1917, called "sortokaudet/sortovuodet" (times/years of oppression) in Finnish) was the policy of the Russian czars designed to limit the special status of the Grand Duchy of Finland and more fully integrate it politically, militarily, and culturally into the empire. Finns were strongly opposed and fought back by passive resistance and a strengthening of Finnish cultural identity. Key provisions were the "February Manifesto of 1899" which asserted the imperial government's right to rule Finland without the consent of local legislative bodies. Second, the "Language Manifesto of 1900" which made Russian the language of administration of Finland. Third, the conscription law of 1901 incorporated the Finnish army into the imperial army and sent conscripts away to Russian training camps.
Democratic change.
In 1906, as a result of the Russian Revolution of 1905 and the associated Finnish general strike of 1905, the old four-chamber Diet was replaced by a unicameral Parliament of Finland "(the "Eduskunta")." For the first time in Europe, universal suffrage (right to vote) and eligibility was implemented to include women: Finnish women were the first in Europe to gain full eligibility to vote; and have membership in an estate; land ownership or inherited titles were no longer required.
However, on the local level things were different, as in the municipal elections the number of votes was tied to amount of tax paid. Thus, rich people could cast a number of votes, while the poor perhaps none at all. The municipal voting system was changed to universal suffrage in 1917
when a left-wing majority was elected to Parliament.
Emigration trends.
Emigration was especially important 1890–1914, with many young men and some families headed to Finnish settlements in the United States, and also to Canada. They typically worked in lumbering and mining, and many were active in Marxist causes on the one hand, or the Finnish Evangelical Lutheran Church of America on the other. In the 21st century about 700,000 Americans and 110,000 Canadians claim Finnish ancestry.
By 2000 about 6% of the population spoke Swedish as their first language, or 300,000 people. However since the late 20th century there has been a steady migration of older, better educated Swedish speakers to Sweden.
Independence and Civil War.
In the aftermath of the February Revolution in Russia, Finland received a new Senate, a coalition-Cabinet with the same power structure as the Finnish Parliament. Based on the general election in 1916, the Social Democrats had a small majority, and the Social Democrat Oskari Tokoi became prime minister. The new Senate was willing to cooperate with the provisional government of Russia, but no agreement was reached. Finland considered the personal union with Russia to be over after the dethroning of the Tsar—although the Finns had "de facto" recognized the provisional government as the Tsar's successor by accepting its authority to appoint a new Governor General and Senate. They expected the Tsar's authority to be transferred to Finland's Parliament, which the provisional government of Russia refused, suggesting instead that the question should be settled by the Russian Constituent Assembly.
For the Finnish Social Democrats it seemed as though the bourgeoisie was an obstacle on Finland's road to independence as well as on the proletariat's road to power. The non-Socialists in Tokoi's Senate were, however, more confident. They and most of the non-Socialists in the Parliament, rejected the Social Democrats' proposal on parliamentarism (the so-called "Power Act") as being too far-reaching and provocative. The act restricted Russia's influence on domestic Finnish matters, but didn't touch the Russian government's power on matters of defence and foreign affairs. For the Russian Provisional government this was, however, far too radical. As the Parliament had exceeded its authority, it was dissolved.
The minority of the Parliament, and of the Senate, were content. New elections promised a chance to gain majority, which they were convinced would improve the chances to reach an understanding with Russia. The non-Socialists were also inclined to cooperate with the Russian Provisional government because they feared the Socialists' power would grow, resulting in radical reforms, such as equal suffrage in municipal elections, or a land reform. The majority had the completely opposite opinion. They didn't accept the Provisional government's right to dissolve the Parliament.
The Social Democrats held on to the Power Act and opposed the promulgation of the decree of dissolution of the Parliament, whereas the non-Socialists voted for promulgating it. The disagreement over the Power Act led to the Social Democrats leaving the Senate. When the Parliament met again after the summer recess in August 1917, only the groups supporting the Power Act were present. Russian troops took possession of the chamber, the Parliament was dissolved, and new elections were carried out. The result was a (small) non-Socialist majority and a purely non-Socialist Senate. The suppression of the Power Act, and the cooperation between Finnish non-Socialist forces and oppressive Russia provoked great bitterness among the Socialists, and had resulted in dozens of politically motivated attacks and murders.
Independence.
The October Revolution of 1917 turned Finnish politics upside down. Now, the new non-Socialist majority of the Parliament desired total independence, and the Socialists came gradually to view Soviet Russia as an example to follow. On November 15, 1917, the Bolsheviks declared a general right of self-determination, including the right of complete secession, "for the Peoples of Russia". On the same day the Finnish Parliament issued a declaration by which it temporarily took power in Finland.
Worried by the development in Russia, and Finland, the non-Socialist Senate proposed that Parliament declare Finland's independence, which was agreed on in the Parliament on December 6, 1917. On December 18 (December 31 N. S.) the Soviet government issued a Decree, recognizing Finland's independence, and on December 22 (January 4, 1918 N. S.) it was approved by the highest Soviet executive body—VTsIK. Germany and the Scandinavian countries followed without delay.
Civil War.
Finland after 1917 was bitterly divided along social lines. The Whites consisted of the Swedish-speaking middle and upper classes and the farmers and peasantry who dominated the northern two-thirds of the land. They had a conservative outlook and rejected socialism. The socialist-Communist Reds comprised the Finnish-speaking urban workers and the landless rural cottagers. They had a radical outlook and rejected capitalism.
From January to May 1918, Finland experienced the brief but bitter Finnish Civil War. On one side there were the "white" civil guards, who fought for the anti-Socialists. On the other side were the Red Guards, which consisted of workers and tenant farmers. The latter proclaimed a Finnish Socialist Workers' Republic. World War I was still underway and the defeat of the Red Guards was achieved with support from Imperial Germany, while Sweden remained neutral and Russia withdrew its forces. The Reds lost the war and the White peasantry rose to political leadership in the 1920s–1930s. About 37,000 men died, most of them in prisoner camps ravaged by influenza and other diseases.
Finland in the inter-war era.
After the civil war the parliament, controlled by the Whites, voted to establish a constitutional monarchy to be called the "Kingdom of Finland", with a German prince as king. However, Germany's defeat in November 1918 made the plan impossible and Finland instead became a republic, with Kaarlo Juho Ståhlberg elected as its first President in 1919. Despite the bitter civil war, and repeated threats from fascist movements, Finland became and remained a capitalist democracy under the rule of law. By contrast, nearby Estonia, in similar circumstances but without a civil war, started as a democracy and was turned into a dictatorship in 1934.
Agrarian reform.
Large scale agrarian reform in the 1920s involved breaking up the large estates controlled by the old nobility and selling the land to ambitious peasants. The farmers became strong supporters of the government.
Diplomacy.
The new republic faced a dispute over the Åland Islands, which were overwhelmingly Swedish-speaking and sought retrocession to Sweden. However, as Finland was not willing to cede the islands, they were offered an autonomous status. Nevertheless, the residents did not approve the offer, and the dispute over the islands was submitted to the League of Nations. The League decided that Finland should retain sovereignty over the Åland Islands, but they should be made an autonomous province. Thus Finland was under an obligation to ensure the residents of the Åland Islands a right to maintain the Swedish language, as well as their own culture and local traditions. At the same time, an international treaty was concluded on the neutral status of Åland, under which it was prohibited to place military headquarters or forces on the islands.
Prohibition.
Alcohol abuse had a long history, especially regarding binge drinking and public intoxication, which became a crime in 1733. In the 19th century the punishments became stiffer and stiffer, but the problem persisted. A strong abstinence movement emerged that cut consumption in half from the 1880s to the 1910s, and gave Finland the lowest drinking rate in Europe. Four attempts at instituting prohibition of alcohol during the Grand Duchy period were rejected by the czar; with the czar gone Finland enacted prohibition in 1919. Smuggling emerged and enforcement was slipshod. Criminal convictions for drunkenness went up by 500%, and violence and crime rates soared. Public opinion turned against the law, and a national plebiscite went 70% for repeal, so prohibition was ended in early 1932.
Politics.
Nationalist sentiment remaining from the Civil War developed into the proto-Fascist Lapua Movement in 1929. Initially the movement gained widespread support among anti-Communist Finns, but following a failed coup attempt in 1932 it was banned and its leaders imprisoned.
Relations with Soviet Union.
In the wake of the Civil War there were many incidents along the border between Finland and Soviet Russia, such as the Aunus expedition and the Pork mutiny. Relations with the Soviets were improved after the Treaty of Tartu in 1920, in which Finland gained Petsamo, but gave up its claims on East Karelia.
Tens of thousands of radical Finns—from Finland, the United States and Canada—took up Stalin's 1923 appeal to create a new Soviet society in the Karelian Autonomous Soviet Socialist Republic (KASSR), a part of Russia.
Most were executed in the purges of the 1930s.
The Soviet Union started to tighten its policy against Finland in the 1930s, limiting the navigation of Finnish merchant ships between Lake Ladoga and the Gulf of Finland and blocking it totally in 1937.
Finland in the Second World War.
During the Second World War, Finland fought two wars against the Soviet Union: the Winter War of 1939–1940, resulting in the loss of Finnish Karelia, and the Continuation War of 1941–1944 (with considerable support from Nazi Germany resulting in a swift invasion of neighboring areas of the Soviet Union), eventually leading to the loss of Finland's only ice-free winter harbour Petsamo. The Continuation War was, in accordance with the armistice conditions, immediately followed by the Lapland War of 1944–1945, when Finland fought the Germans to force them to withdraw from northern Finland back into Norway (then under German occupation). Finland was not occupied; its army of over 600,000 soldiers, saw only 3,500 prisoners-of-war. About 96,000 Finns lost their lives, or 2.5% of a population of 3.8 million; civilian casualties were under 2,500.
In August 1939 Nazi-Germany and the Soviet Union signed the Molotov-Ribbentrop Pact, where Finland and the Baltic states were given to the Soviet "sphere of influence". After the Invasion of Poland, the Soviet Union sent ultimatums to the Baltic countries, where it demanded military bases on their soil. The Baltic states accepted Soviet demands, and lost their independence in the summer of 1940. In October 1939, the Soviet Union sent the same kind of request to Finland, but the Finns refused to give any land areas or military bases for the usage of the Red Army. This caused the Soviet Union to start a military invasion against Finland on 30 November 1939. Soviet leaders predicted that Finland would be conquered in a couple of weeks. However, even though the Red Army had huge superiority in men, tanks, guns and airplanes, the Finns were able to defend their country about 3.5 months and still avoid invasion successfully. The Winter War ended on 13 March 1940 with the Moscow peace treaty. Finland lost the Karelian Isthmus to the Soviet Union after the war. The Winter War was a big loss of prestige for Soviet Union, and it was expelled from the League of Nations because of the illegal attack. Finland received lots of international goodwill and material help from many countries during the war.
After the Winter War the Finnish army was exhausted, and needed recovery and support as soon as possible. The British declined to help but in autumn 1940 Nazi Germany offered weapon deals to Finland, if the Finnish government would allow German troops to travel through Finland to occupied Norway. Finland accepted, weapon deals were made and military co-operation began in December 1940.
Finland's support from, and coordination with, Nazi Germany starting during the winter of 1940–41 and made other countries considerably less sympathetic to the Finnish cause; particularly since the Continuation War led to a Finnish invasion of the Soviet Union designed not only to recover lost territory, but additionally to answer the irredentist sentiment of a Greater Finland by incorporating East Karelia, whose inhabitants were culturally related to the Finnish people, although religiously Russian Orthodox. This invasion had caused Britain to declare war on Finland on 6 December 1941.
Finland managed to defend its democracy, contrary to most other countries within the Soviet sphere of influence, and suffered comparably limited losses in terms of civilian lives and property. It was, however, punished harsher than other German co-belligerents and allies, having to pay large reparations and resettle an eighth of its population after having lost an eighth of the territory including one of its industrial heartlands and the second-largest city of Viipuri. After the war, the Soviet government settled these gained territories with people from many different regions of the USSR, for instance from Ukraine.
The Finnish government did not participate in the systematic killing of Jews, although the country remained a "co-belligrent", a "de facto" ally of Germany until 1944. In total, eight German Jewish refugees were handed over to the German authorities. In the Tehran Conference of 1942, the leaders of the Allies agreed that Finland was fighting a separate war against the Soviet Union, and that in no way was it hostile to the Western allies. The Soviet Union was the only Allied country which Finland had conducted military operations against. Unlike any of the Axis nations, Finland was a parliamentary democracy throughout the 1939–1945 period. The commander of Finnish armed forces during the Winter War and the Continuation War, Carl Gustaf Emil Mannerheim, became the President of Finland after the war. Finland made a separate peace contract with the Soviet Union on 19 September 1944, and was the only bordering country of USSR in Europe that kept its independence after the war.
During and in between the wars, approximately 80,000 Finnish war-children were evacuated abroad: 5% went to Norway, 10% to Denmark, and the rest to Sweden. Most of the children were sent back by 1948, but 15–20% remained abroad.
The Moscow Armistice was signed between Finland on one side and the Soviet Union and Britain on the other side on September 19, 1944, ending the Continuation War. The armistice compelled Finland to drive German troops from its territory, leading to the Lapland War 1944–1945.
In 1947, Finland reluctantly declined Marshall aid in order to preserve good relations with the Soviets, ensuring Finnish autonomy. Nevertheless, the United States shipped secret development aid and financial aid to the non-communist SDP. Establishing trade with the Western powers, such as Britain, and the reparations to the Soviet Union caused Finland to transform itself from a primarily agrarian economy to an industrialised one. After the reparations had been paid off, Finland continued to trade with the Soviet Union in the framework of bilateral trade.
Finland's role in the Second World War was in many ways strange. Firstly the Soviet Union tried to invade Finland in 1939–1940. However, even with massive superiority in military strength, the Soviet Union was unable to conquer Finland. In late 1940, German-Finnish co-operation began; it took a form that was unique when compared to relations with the Axis. Finland signed the Anti-Comintern Pact, which made Finland an ally with Germany in the war against the Soviet Union. But, unlike all other Axis states, Finland never signed the Tripartite Pact and so Finland never was "de jure" an Axis nation.
Memory.
Although Finland lost two wars with the Soviets, the memory of the war was sharply inscribed in the national consciousness. Not just the fallen soldiers and the veterans, but many others are commemorated, including the orphans, evacuees from Karelia, the children who were evacuated to Sweden, women who worked at home or in factories, and the veterans of the women’s defence unit Lotta Svärd. It is celebrated as a victory for the national spirit by surviving against such long odds.
Postwar.
Neutrality in Cold War.
Finland retained a democratic constitution and free economy during the Cold War era. Treaties signed in 1947 and 1948 with the Soviet Union included obligations and restraints on Finland, as well as territorial concessions. Both treaties have been abrogated by Finland since the 1991 dissolution of the Soviet Union, while leaving the borders untouched. Even though being a neighbor to the Soviet Union sometimes resulted in overly cautious concern in foreign policy ("Finlandization"), Finland developed closer co-operation with the other Nordic countries and declared itself neutral in superpower politics.
In 1952, Finland and the countries of the Nordic Council entered into a passport union, allowing their citizens to cross borders without passports and soon also to apply for jobs and claim social security benefits in the other countries. Many from Finland used this opportunity to secure better paying jobs in Sweden in the 1950s and 1960s, dominating Sweden's first wave of post-war labour immigrants. Although Finnish wages and standard of living could not compete with wealthy Sweden until the 1970s, the Finnish economy rose remarkably from the ashes of World War II, resulting in the buildup of another Nordic-style welfare state.
Despite the passport union with Sweden, Norway, Denmark, and Iceland, Finland could not join the Nordic Council until 1955 because of Soviet fears that Finland might become too close to the West. At that time the Soviet Union saw the Nordic Council as part of NATO of which Denmark, Norway and Iceland were members.
That same year Finland joined the United Nations, though it had already been associated with a number of UN specialized organisations. The first Finnish ambassador to the UN was G.A. Gripenberg (1956–1959), followed by Ralph Enckell (1959–1965), Max Jakobson (1965–1972), Aarno Karhilo (1972–1977), Ilkka Pastinen (1977–1983), Keijo Korhonen (1983–1988), Klaus Törnudd (1988–1991), Wilhelm Breitenstein (1991–1998) and Marjatta Rasi (1998–2005). In 1972 Max Jakobson was a candidate for Secretary-General of the UN. In another remarkable event of 1955, the Soviet Union decided to return the Porkkala peninsula to Finland, which had been rented to the Soviet Union in 1948 for 50 years as a military base, a situation which somewhat endangered Finnish sovereignty and neutrality.
Finland became an associate member of the European Free Trade Association in 1961 and a full member in 1986. A trade agreement with the EEC was complemented by another with the Soviet Bloc. The first Conference for Security and Co-operation in Europe (CSCE), which lead to the creation of the OSCE, was held in Finland in 1972–1973. The CSCE was widely considered in Finland as a possible means of reducing tensions of the Cold War, and a personal triumph for President Urho Kekkonen.
Officially claiming to be neutral, Finland lay in the grey zone between the Western countries and the Soviet Union. The "YYA Treaty" (Finno-Soviet Pact of "Friendship, Cooperation, and Mutual Assistance") gave the Soviet Union some leverage in Finnish domestic politics. However, Finland maintained capitalism unlike most other countries bordering the Soviet Union. Property rights were strong. While nationalization committees were set up in France and UK, Finland avoided nationalizations. After failed experiments with protectionism in the 1950s, Finland eased restrictions and made a free trade agreement with the European Community in 1973, making its markets more competitive. Local education markets expanded and an increasing number of Finns also went abroad to study in the United States or Western Europe, bringing back advanced skills. There was a quite common, but pragmatic-minded, credit and investment cooperation by state and corporations, though it was considered with suspicion. Support for capitalism was widespread. Savings rate hovered among the world's highest, at around 8% until the 1980s. In the beginning of the 1970s, Finland's GDP per capita reached the level of Japan and the UK. Finland's economic development shared many aspects with export-led Asian countries.
Society and the welfare state.
Before 1940 Finland was a poor rural nation of urban and rural workers and independent farmers. There was a small middle class, employed chiefly as civil servants and in small local businesses. As late as 1950 half of the workers were in agriculture and only a third lived in urban towns. The new jobs in manufacturing, services and trade quickly attracted people to the towns and cities. The average number of births per woman declined from baby boom a peak of 3.5 in 1947 to 1.5 in 1973. When baby boomers entered the workforce, the economy did not generate jobs fast enough and hundreds of thousands emigrated to the more industrialized Sweden, migration peaking in 1969 and 1970 (today 4.7 percent of Swedes speak Finnish).
By the 1990s, farm laborers had nearly all moved on, leaving owners of small farms. By 2000 the social structure included a politically active working class, a primarily clerical middle class, and an upper bracket consisting of managers, entrepreneurs, and professionals. The social boundaries between these groups were not distinct. Causes of change included the growth of a mass culture, international standards, social mobility, and acceptance of democracy and equality as typified by the welfare state.
The generous system of welfare benefits emerged from a long process of debate, negotiations and maneuvers between efficiency-oriented modernizers on the one hand and Social Democrats and labor unions. A compulsory system provides old-age and disability insurance, financed mostly by taxes on employers. The national government provides unemployment insurance, maternity benefits, family allowances, and day-care centers. Health insurance covers most of the cost of outpatient care. The national health act of 1972 provided for the establishment of free health centers in every municipality. There were major cutbacks in the early 1990s, but they were distributed to minimize the harm to the vast majority of voters.
Economy.
The post-war period was a time of rapid economic growth and increasing social and political stability for Finland. The five decades after the Second World War saw Finland turn from a war-ravaged agrarian society into one of the most technologically advanced countries in the world, with a sophisticated market economy and high standard of living.
In 1991 Finland fell into a depression caused by a combination of economic overheating, fixed currency, depressed Western, Soviet, and local markets. Stock market and housing prices declined by 50%. The growth in the 1980s was based on debt and defaults started rolling in. GDP declined by 15% and unemployment increased from a virtual full employment to one fifth of the workforce. The crisis was amplified by trade unions' initial opposition to any reforms. Politicians struggled to cut spending and the public debt doubled to around 60% of GDP. Some 7–8% of GDP was needed to bail out failing banks and force banking sector consolidation. After devaluations the depression bottomed out in 1993.
Recent history.
The GDP growth rate has since been one of the highest of OECD countries and Finland has topped many indicators of national performance.
Until 1991, President Mauno Koivisto and two of the three major parties, Center Party and the Social Democrats opposed the idea of European Union membership and preferred entering into the European Economic Area treaty. However, after Sweden had submitted its membership application in 1991 and the Soviet Union was dissolved at the end of the year, Finland submitted its own application to the EU in March 1992. The accession process was marked by heavy public debate, where the differences of opinion did not follow party lines. Officially, all three major parties were supporting the Union membership, but members of all parties participated in the campaign against the membership. Before the parliamentary decision to join the EU, a consultative referendum was held on April 16, 1994 in which 56.9% of the votes were in favour of joining. The process of accession was completed on January 1, 1995, when Finland joined the European Union along with Austria and Sweden. Leading Finland into the EU is held as the main achievement of the Centrist-Conservative government of Esko Aho then in power.
In the economic policy, the EU membership brought with it many large changes. While politicians were previously involved in setting interest rates, the central bank was given an inflation-targeting mandate until Finland joined the eurozone. During Prime Minister Paavo Lipponen's two successive governments 1995–2003, several large state companies were privatized fully or partially. Matti Vanhanen's two cabinets followed suit until autumn 2008, when the state became a major shareholder in the Finnish telecom company Elisa with the intention to secure the Finnish ownership of a strategically important industry.
In addition to fast integration with the European Union, safety against Russian leverage has been increased by building fully NATO-compatible military. 1000 troops (a high per-capita amount) are simultaneously committed in NATO and UN operations. Finland has also opposed energy projects that increase dependency on Russian imports. At the same time, Finland remains one of the last non-NATO members in Europe and there seems to be not enough support for full membership unless Sweden joins first.
The population is aging with the birth rate at 10.42 births/1,000 population or fertility rate at 1.8. With median age at 41.6 years Finland is one of the countries with the highest average age of its citizens.

</doc>
<doc id="14379" url="http://en.wikipedia.org/wiki?curid=14379" title="Holy Spirit">
Holy Spirit

Holy Spirit, or Holy Ghost, is a term found in English translations of the Bible, but understood differently among the Abrahamic religions.
Judaism.
The Hebrew language phrase "ruach ha-kodesh" (Hebrew: רוח הקודש, "holy spirit" also transliterated "ruaḥ ha-qodesh") is a term used in the Hebrew Bible (Tanakh) and Jewish writings to refer to the spirit of YHWH (רוח יהוה). It literally means "the spirit of holiness" or "the spirit of the holy place". The Hebrew terms "ruaḥ qodshəka", "thy holy spirit" (רוּחַ קָדְשְׁךָ), and "ruaḥ qodshō", "his holy spirit" (רוּחַ קָדְשׁ֑וֹ) also occur (when a possessive suffix is added the definite article is dropped). The "Holy Spirit" in Judaism generally refers to the divine aspect of prophecy and wisdom. It also refers to the divine force, quality, and influence of the Most High God, over the universe or over his creatures, in given contexts.
According to Rabbi José Faur, probably the greatest Maimonidean scholar and rabbi in modernity, the whole notion of "Holy Spirit," "Holy Ghost," and so on, is another instance of Christian influence on Jewish thought and lack of regard for elemental Hebrew Grammar. This is a basic difference between "qodesh" and "qadosh". "Qadosh" is an adjective, 'holy'. "Qodesh" is a noun. It does "not" mean "holy" ("qadosh") but "Sanctuary". It refers to the spirit residing at the Sanctuary reaching the faithful "outside" the Sanctuary.
Christianity.
For the large majority of Christians, the Holy Spirit (or Holy Ghost, from Old English "gast", "spirit") is the third divine person of the Trinity: the "Triune God" manifested as Father, Son, and Holy Spirit; each person itself being God.
Islam.
The Holy Spirit (Arabic: الروح القدس "al-Ruh al-Quddus", "the-Spirit the-Holy") is mentioned a number of times in the Qur'an, where it acts as an agent of divine action or communication. The Muslim interpretation of the Holy Spirit is generally consistent with other interpretations based upon the Old and the New Testaments. On the basis of narrations in certain Hadith some Muslims identify it with the angel Gabriel (Arabic "Jibreel"). The Spirit (الروح "al-Ruh", without the adjective "holy" or "exalted") is described, among other things, as the creative spirit from God by which God enlivened Adam, and which inspired in various ways God's messengers, his prophets, and his angels, including Jesus and Abraham. The belief in a "Holy Trinity", according to the Qur'an, is forbidden and deemed to be blasphemy. The same prohibition applies to any idea of the duality of God (Allah). Though grammatical gender has no bearing on sexual identity in non-personal nouns, the term "Holy Spirit" translates in and is used in the masculine form throughout the Qur'an.
Bahá'í Faith.
The Bahá'í Faith has the concept of the "Most Great Spirit", seen as the bounty of God. It is usually used to describe the descent of the Spirit of God upon the messengers/prophets of God who include, among others, Jesus, Muhammad and Bahá'u'lláh.
In Bahá'í belief, the Holy Spirit is the conduit through which the wisdom of God becomes directly associated with his messenger, and it has been described variously in different religions such as the burning bush to Moses, the sacred fire to Zoroaster, the dove to Jesus, the angel Gabriel to Muhammad, and the Maid of Heaven to Bahá'u'lláh. The Bahá'í view rejects the idea that the Holy Spirit is a partner to God in the Godhead, but rather is the pure essence of God's attributes.

</doc>
<doc id="14380" url="http://en.wikipedia.org/wiki?curid=14380" title="Helium-3">
Helium-3

Helium-3 (He-3) is a light, non-radioactive isotope of helium with two protons and one neutron. It is rare on Earth, and it is sought for use in nuclear fusion and fourth generation nuclear weapons research. The abundance of helium-3 is thought to be greater on the Moon (embedded in the upper layer of regolith by the solar wind over billions of years), though still lower in quantity (28 ppm of lunar regolith is helium-4 and from one to 50 ppb is helium-3) than the solar system's gas giants (left over from the original solar nebula).
The helion, the nucleus of a helium-3 atom, consists of two protons but only one neutron, in contrast with two neutrons in common helium. Its hypothetical existence was first proposed in 1934 by the Australian nuclear physicist Mark Oliphant while he was working at the University of Cambridge Cavendish Laboratory. Oliphant had performed experiments in which fast deuterons collided with deuteron targets (incidentally, the first demonstration of nuclear fusion).
Helium-3 was hypothesized to be a radioactive isotope until helions were also found in samples of natural helium, which is mostly helium-4, taken both from the terrestrial atmosphere and from natural gas wells. This was done by Luis W. Alvarez and Robert Cornog in cyclotron experiments at the Lawrence Berkeley National Laboratory in California in 1939.
Although helium-3 was found to be about 10,000 times rarer than helium-4 in the helium from the gas wells, its significant presence in underground gas deposits implied that either it did not decay, or else it had a very long half-life – billions of years. Hydrogen-1 and helium-3 are the only stable nuclides that contain more protons than neutrons.
Helium-3 occurs as a primordial nuclide, escaping from the Earth's crust into the atmosphere and into outer space over millions of years. Helium-3 is also thought to be a natural nucleogenic and cosmogenic nuclide, one produced when lithium is bombarded by natural neutrons. Those are released by spontaneous fission and by nuclear reactions with cosmic rays. Some of the helium-3 found in the terrestrial atmosphere is also a relic of atmospheric and underwater nuclear weapons testing, conducted by the three big nuclear powers before 1963. Most of this comes from the decay of tritium (hydrogen-3), which decays into helium-3 with a half life of 12.3 years. Furthermore, some nuclear reactors (landbound or shipbound) periodically release some helium-3 and tritium into the atmosphere. The nuclear reactor disaster at Chernobyl released a huge amount of radioactive tritium into the atmosphere, and smaller problems cause smaller releases. Furthermore, significant amounts of tritium and helium-3 have been deliberately produced in national arsenal nuclear reactors by the irradiation of lithium-6. The tritium is used to "boost" nuclear weapons, and some of this inevitably escapes during its production, transportation, and storage. Hence, helium-3 enters the atmosphere both through its direct release and through the radioactive decay of tritium. The vast majority of these two gases have been produced and leaked by the former Soviet Union, Russia, the United Kingdom, and France.
Helium-3 is proposed as a second-generation fuel for nuclear fusion in hypothetical fusion power plants, but such plants are still very early in their development—especially since first generation reactors have not yet entered into service. Helium-3 can be used in instruments for the detection of free neutrons, such as neutrons leaking from nuclear reactors.
Physical properties.
Because of its lower atomic mass of 3.02 atomic mass units, helium-3 has some physical properties different from those of helium-4, with a mass of 4.00 atomic mass units. Because of the weak, induced dipole–dipole interaction between helium atoms, their macroscopic physical properties are mainly determined by their zero-point energy (ground-state kinetic energy). Also, the microscopic properties of helium-3 cause it to have a higher zero-point energy than helium-4. This implies that helium-3 can overcome dipole–dipole interactions with less thermal energy than helium-4 can.
The quantum mechanical effects on helium-3 and helium-4 are significantly different because with two protons, two neutrons, and two electrons, helium-4 has an overall spin of zero, making it a boson, but with one fewer neutron, helium-3 has an overall spin of one half, making it a fermion.
Helium-3 boils at 3.19 K compared with helium-4 at 4.23 K, and its critical point is also lower at 3.35 K, compared with helium-4 at 5.2 K. Helium-3 has less than one-half of the density when it is at its boiling point: 59 gram per liter compared to the 125 gram per liter of helium-4—at a pressure of one atmosphere. Its latent heat of vaporization is also considerably lower at 0.026 kilojoule per mole compared with the 0.0829 kilojoule per mole of helium-4.
Fusion reactions.
3He can be used in fusion reactions by either of the reactions 2D + 3He →   4He +  1p + 18.3 MeV, or 3He + 3He → 4He   + 2 1p+ 12.86 MeV
The conventional deuterium + tritium ("D-T") fusion process produces energetic neutrons which render reactor components radioactive with activation products. The appeal of helium-3 fusion stems from the aneutronic nature of its reaction products. Helium-3 itself is non-radioactive. The lone high-energy by-product, the proton, can be contained using electric and magnetic fields. The momentum energy of this proton (created in the fusion process) will interact with the containing electromagnetic field, resulting in direct net electricity generation.
Because of the higher Coulomb barrier, the temperatures required for 21H + 32He fusion are much higher than those of conventional D-T fusion. Moreover, since both reactants need to be mixed together to fuse, reactions between nuclei of the same reactant will occur, and the D-D reaction (21H + 21H) does produce a neutron. Reaction rates vary with temperature, but the D-3He reaction rate is never greater than 3.56 times the D-D reaction rate (see graph). Therefore fusion using D-3He fuel may produce a somewhat lower neutron flux than D-T fusion, but is by no means clean, negating some of its main attraction.
The second possibility, fusing 32He with itself (32He + 32He), requires even higher temperatures (since now both reactants have a +2 charge), and thus is even more difficult than the D-3He reaction. However, it does offer a possible reaction that produces no neutrons; the protons it produces possess charges and can be contained using electric and magnetic fields, which in turn results in direct electricity generation. 32He + 32He fusion has been demonstrated in the laboratory and is thus theoretically feasible and would have immense advantages, but commercial viability is many years in the future.
The amounts of helium-3 needed as a replacement for conventional fuels are substantial by comparison to amounts currently available. The total amount of energy produced in the 21H + 32He reaction is 18.4 MeV, which corresponds to some 493 megawatt-hours (4.93×108 W·h) per three grams (one mole) of ³He. If the total amount of energy could be converted to electrical power with 100% efficiency (a physical impossibility), it would correspond to about 30 minutes of output of a gigawatt electrical plant per mole of 3He. Thus, a year's production would require 52.5 kilograms of helium-3. The amount of fuel needed for large-scale applications can also be put in terms of total consumption: electricity consumption by 107 million U.S. households in 2001 totaled 1,140 billion kW·h (1.14×1015 W·h). Again assuming 100% conversion efficiency, 6.7 tonnes per year of helium-3 would be required for that segment of the energy demand of the United States, 15 to 20 tonnes per year given a more realistic end-to-end conversion efficiency.
Neutron detection.
Helium-3 is a most important isotope in instrumentation for neutron detection. It has a high absorption cross section for thermal neutron beams and is used as a converter gas in neutron detectors. The neutron is converted through the nuclear reaction
into charged particles tritium (T, 3H) and protium (p, 1H) which then are detected by creating a charge cloud in the stopping gas of a proportional counter or a Geiger-Müller tube.
Furthermore, the absorption process is strongly spin-dependent, which allows a spin-polarized helium-3 volume to transmit neutrons with one spin component while absorbing the other. This effect is employed in neutron polarization analysis, a technique which probes for magnetic properties of matter.
The United States Department of Homeland Security had hoped to deploy detectors to spot smuggled plutonium in shipping containers by their neutron emissions, but the worldwide shortage of helium-3 following the drawdown in nuclear weapons production since the Cold War has to some extent prevented this. As of 2012, DHS determined the commercial supply of boron-10 would support converting its neutron detection infrastructure to that technology.
Cryogenics.
A helium-3 refrigerator uses helium-3 to achieve temperatures of 0.2 to 0.3 kelvin. A dilution refrigerator uses a mixture of helium-3 and helium-4 to reach cryogenic temperatures as low as a few thousandths of a kelvin.
An important property of helium-3, which distinguishes it from the more common helium-4, is that its nucleus is a fermion since it contains an odd number of spin 1⁄2 particles. Helium-4 nuclei are bosons, containing an even number of spin 1⁄2 particles. This is a direct result of the addition rules for quantized angular momentum. At low temperatures (about 2.17 K), helium-4 undergoes a phase transition: A fraction of it enters a superfluid phase that can be roughly understood as a type of Bose–Einstein condensate. Such a mechanism is not available for helium-3 atoms, which are fermions. However, it was widely speculated that helium-3 could also become a superfluid at much lower temperatures, if the atoms formed into "pairs" analogous to Cooper pairs in the BCS theory of superconductivity. Each Cooper pair, having integer spin, can be thought of as a boson. During the 1970s, David Lee, Douglas Osheroff and Robert Coleman Richardson discovered two phase transitions along the melting curve, which were soon realized to be the two superfluid phases of helium-3. The transition to a superfluid occurs at 2.491 millikelvins (i.e., 0.002491 K) on the melting curve. They were awarded the 1996 Nobel Prize in Physics for their discovery. Tony Leggett won the 2003 Nobel Prize in Physics for his work on refining understanding of the superfluid phase of helium-3.
In zero magnetic field, there are two distinct superfluid phases of 3He, the A-phase and the B-phase. The B-phase is the low-temperature, low-pressure phase which has an isotropic energy gap. The A-phase is the higher temperature, higher pressure phase that is further stabilized by a magnetic field and has two point nodes in its gap. The presence of two phases is a clear indication that 3He is an unconventional superfluid (superconductor), since the presence of two phases requires an additional symmetry, other than gauge symmetry, to be broken. In fact, it is a "p"-wave superfluid, with spin one, S=1, and angular momentum one, L=1. The ground state corresponds to total angular momentum zero, J=S+L=0 (vector addition). Excited states are possible with non-zero total angular momentum, J>0, which are excited pair collective modes. Because of the extreme purity of superfluid 3He (since all materials except 4He have solidified and
sunk to the bottom of the liquid 3He and any 4He has phase separated entirely, this is the most pure condensed matter state), these collective modes have been studied with much greater precision than in any other unconventional pairing system.
Medical lung imaging.
Helium-3 nuclei have an intrinsic nuclear spin of 1⁄2, and a relatively high magnetogyric ratio. Helium-3 can be hyperpolarized using non-equilibrium means such as spin-exchange optical pumping. During this process, circularly polarized infrared laser light, tuned to the appropriate wavelength, is used to excite electrons in an alkali metal, such as caesium or rubidium inside a sealed glass vessel. The angular momentum is transferred from the alkali metal electrons to the noble gas nuclei through collisions. In essence, this process effectively aligns the nuclear spins with the magnetic field in order to enhance the NMR signal. The hyperpolarized gas may then be stored at pressures of 10 atm, for up to 100 hours. Following inhalation, gas mixtures containing the hyperpolarized helium-3 gas can be imaged with an MRI scanner to produce anatomical and functional images of lung ventilation. This technique is also able to produce images of the airway tree, locate unventilated defects, measure the alveolar oxygen partial pressure, and measure the ventilation/perfusion ratio. This technique may be critical for the diagnosis and treatment management of chronic respiratory diseases such as chronic obstructive pulmonary disease (COPD), emphysema, cystic fibrosis, and asthma.
Production.
Current US industrial consumption of helium-3 is approximately 60,000 liters (approximately 8 kg) per year; cost at auction has typically been approximately $100/liter although increasing demand has raised prices to as much as $2,000/liter in recent years. Helium-3 is naturally present in small quantities due to radioactive decay, but virtually all helium-3 used in industry is manufactured. Helium-3 is a product of tritium decay, and tritium can be produced through neutron bombardment of deuterium, lithium, boron, or nitrogen targets. Production of tritium in significant quantities requires the high neutron flux of a nuclear reactor; breeding tritium with lithium-6 consumes the neutron, while breeding with lithium-7 produces a low energy neutron as a replacement for the consumed fast neutron.
Current supplies of helium-3 come, in part, from the dismantling of nuclear weapons where it accumulates, however the need for warhead disassembly is diminishing. Consequently tritium itself is in short supply, and the US Department of Energy recently began producing it by the lithium irradiation method at the Tennessee Valley Authority's Watts Bar reactor. Substantial quantities of tritium could also be extracted from the heavy water moderator in CANDU nuclear reactors.
Production of helium-3 from tritium at a rate sufficient to meet world demand will require significant investment, as tritium must be produced at the same rate as helium-3, and approximately eighteen times as much tritium must be maintained in storage as the amount of helium-3 produced annually by decay (production rate "dN⁄dt" from number of moles or other unit mass of tritium "N", is "N γ" = "N" (ln 2)⁄t1/2 where the value of t1/2⁄(ln 2) is about 18 years; see radioactive decay). If commercial fusion reactors were to use helium-3 as a fuel, they would require tens of tonnes of helium-3 each year to produce a fraction of the world's power, requiring substantial expansion of facilities for tritium production and storage.
Abundance.
Solar nebula (primordial) abundance.
One early estimate of the primordial ratio of 3He to 4He in the solar nebula has been the measurement of their ratio in the atmosphere of Jupiter, measured by the mass spectrometer of the Galileo atmospheric entry probe. This ratio is about 1:10,000, or 100 parts of 3He per million parts of 4He. This is roughly the same ratio of the isotopes in lunar regolith, when it contains 28 ppm helium-4 and 2.8 ppb helium-3 (which is at the lower end of actual sample measurements, which vary from about 1.4 to 15 ppb). However, terrestrial ratios of the isotopes are lower by a factor of 100, mainly due to enrichment of helium-4 stocks in the mantle by billions of years of alpha decay from uranium and thorium.
Terrestrial abundance.
3He is a primordial substance in the Earth's mantle, considered to have become entrapped within the Earth during planetary formation. The ratio of 3He to 4He within the Earth's crust and mantle is less than that for assumptions of solar disk composition as obtained from meteorite and lunar samples, with terrestrial materials generally containing lower 3He/4He ratios due to ingrowth of 4He from radioactive decay.
In the space, 3He has a ratio of 300 atoms per million atoms of 4He (at. ppm), the original ratio of these primodal gases in mantle was around 200-300 ppm when Earth was formed. A lot of 4He was generated by alpha-particle decay of uranium and thorium, and now mantle has only around 7% primodal helium, lowering the total 3He/4He ratio to around 20 at ppm. Ratios of 3He/4He in excess of atmospheric are indicative of a contribution of 3He from the mantle. Crustal sources are dominated by the 4He which is produced by the decay of radioactive elements in the crust and mantle.
The ratio of helium-3 to helium-4 in natural Earth-bound sources varies greatly. Samples of the lithium ore spodumene from Edison Mine, South Dakota were found to contain 12 parts of helium-3 to a million parts of helium-4. Samples from other mines showed 2 parts per million.
Helium is also present as up to 7% of some natural gas sources, and large sources have over 0.5% (above 0.2% makes it viable to extract). Algeria's annual gas production is assumed to contain 100 million normal cubic metres and this would contain between 5 and 50 m3 of helium-3 (about 1 to 10 kilograms) using the normal abundance range of 0.5 to 5 ppm. Similarly the US 2002 stockpile of 1 billion normal m3 would have contained about 10 to 100 kilograms of helium-3.
3He is also present in the Earth's atmosphere. The natural abundance of 3He in naturally occurring helium gas is 1.38×10-6 (1.38 parts per million). The partial pressure of helium in the Earth's atmosphere is about 0.52 Pa, and thus helium accounts for 5.2 parts per million of the total pressure (101325 Pa) in the Earth's atmosphere, and 3He thus accounts for 7.2 parts per trillion of the atmosphere. Since the atmosphere of the Earth has a mass of about 5.14×1015 tonnes, the mass of 3He in the Earth's atmosphere is the product of these numbers, or about 37,000 tonnes of 3He.
3He is produced on Earth from three sources: lithium spallation, cosmic rays, and beta decay of tritium (3H). The contribution from cosmic rays is negligible within all except the oldest regolith materials, and lithium spallation reactions are a lesser contributor than the production of 4He by alpha particle emissions.
The total amount of helium-3 in the mantle may be in the range of 0.1–1 million tonnes. However, most of the mantle is not directly accessible. Some helium-3 leaks up through deep-sourced hotspot volcanoes such as those of the Hawaiian Islands, but only 300 grams per year is emitted to the atmosphere. Mid-ocean ridges emit another 3 kilogram per year. Around subduction zones, various sources produce helium-3 in natural gas deposits which possibly contain a thousand tonnes of helium-3 (although there may be 25 thousand tonnes if all ancient subduction zones have such deposits). Wittenberg estimated that United States crustal natural gas sources may have only half a tonne total. Wittenberg cited Anderson's estimate of another 1200 metric tonnes in interplanetary dust particles on the ocean floors. In the 1994 study, extracting helium-3 from these sources consumes more energy than fusion would release. Wittenberg also writes that extraction from US crustal natural gas, consumes ten times the energy available from fusion reactions.
Extraterrestrial abundance.
Materials on the Moon's surface contain helium-3 at concentrations on the order of between 1.4 and 15 ppb in sunlit areas, and may contain concentrations as much as 50 ppb in permanently shadowed regions. A number of people, starting with Gerald Kulcinski in 1986, have proposed to explore the moon, mine lunar regolith and use the helium-3 for fusion. Because of the low concentrations of helium-3, any mining equipment would need to process extremely large amounts of regolith (over 150 million tonnes of regolith to obtain one ton of helium 3), and some proposals have suggested that helium-3 extraction be piggybacked onto a larger mining and development operation.
The primary objective of Indian Space Research Organization's first lunar probe called Chandrayaan-I, launched on October 22, 2008, was reported in some sources to be mapping the Moon's surface for helium-3-containing minerals. However, this is debatable; no such objective is mentioned in the project's official list of goals, while at the same time, many of its scientific payloads have noted helium-3-related applications.
Cosmochemist and geochemist Ouyang Ziyuan from the Chinese Academy of Sciences who is now in charge of the Chinese Lunar Exploration Program has already stated on many occasions that one of the main goals of the program would be the mining of helium-3, from which operation "each year three space shuttle missions could bring enough fuel for all human beings across the world." To "bring enough fuel for all human beings across the world", more than one Space Shuttle load (and the processing of 4 million tonnes of regolith) per week, at least 52 per year, would be necessary.
In January 2006, the Russian space company RKK Energiya announced that it considers lunar helium-3 a potential economic resource to be mined by 2020, if funding can be found.
Mining gas giants for helium-3 has also been proposed. The British Interplanetary Society's hypothetical Project Daedalus interstellar probe design was fueled by helium-3 mines in the atmosphere of Jupiter, for example. Jupiter's high gravity makes this a less energetically favorable operation than extracting helium-3 from the other gas giants of the solar system, however.
Power generation.
A second-generation approach to controlled fusion power involves combining helium-3 (32He) and deuterium (21H). This reaction produces a helium-4 ion (42He) (like an alpha particle, but of different origin) and a high-energy proton (positively charged hydrogen ion) (11p). The most important potential advantage of this fusion reaction for power production as well as other applications lies in its compatibility with the use of electrostatic fields to control fuel ions and the fusion protons. Protons, as positively charged particles, can be converted directly into electricity, through use of solid-state conversion materials as well as other techniques. Potential conversion efficiencies of 70% may be possible, as there is no need to convert proton energy to heat in order to drive a turbine-powered electrical generator.
There have been many claims about the capabilities of helium-3 power plants. According to proponents, fusion power plants operating on deuterium and helium-3 would offer lower capital and operating costs than their competitors due to less technical complexity, higher conversion efficiency, smaller size, the absence of radioactive fuel, no air or water pollution, and only low-level radioactive waste disposal requirements. Recent estimates suggest that about $6 billion in investment capital will be required to develop and construct the first helium-3 fusion power plant. Financial breakeven at today's wholesale electricity prices (5 US cents per kilowatt-hour) would occur after five 1-gigawatt plants were on line, replacing old conventional plants or meeting new demand.
The reality is not so clear-cut. The most advanced fusion programs in the world are inertial confinement fusion (such as National Ignition Facility) and magnetic confinement fusion (such as ITER and other tokamaks). In the case of the former, there is no solid roadmap to power generation. In the case of the latter, commercial power generation is not expected until around 2050. In both cases, the type of fusion discussed is the simplest: D-T fusion. The reason for this is the very low Coulomb barrier for this reaction; for D+3He, the barrier is much higher, and it is even higher for 3He–3He. The immense cost of reactors like ITER and National Ignition Facility are largely due to their immense size, yet to scale up to higher plasma temperatures would require reactors far larger still. The 14.7 MeV proton and 3.6 MeV alpha particle from D–3He fusion, plus the higher conversion efficiency, means that more electricity is obtained per kilogram than with D-T fusion (17.6 MeV), but not that much more. As a further downside, the rates of reaction for helium-3 fusion reactions are not particularly high, requiring a reactor that is larger still or more reactors to produce the same amount of electricity.
To attempt to work around this problem of massively large power plants that may not even be economical with D-T fusion, let alone the far more challenging D–3He fusion, a number of other reactors have been proposed – the Fusor, Polywell, Focus fusion, and many more, though many of these concepts have fundamental problems with achieving a net energy gain, and generally attempt to achieve fusion in thermal disequilibrium, something that could potentially prove impossible, and consequently, these long-shot programs tend to have trouble garnering funding despite their low budgets. Unlike the "big", "hot" fusion systems, however, if such systems were to work, they could scale to the higher barrier "aneutronic" fuels, and therefore their proponents tend to promote p-B fusion, which requires no exotic fuels like helium-3.

</doc>
<doc id="14381" url="http://en.wikipedia.org/wiki?curid=14381" title="Hamiltonian (quantum mechanics)">
Hamiltonian (quantum mechanics)

In quantum mechanics, the Hamiltonian is the operator corresponding to the total energy of the system in most of the cases. It is usually denoted by "H", also "Ȟ" or "Ĥ". Its spectrum is the set of possible outcomes when one measures the total energy of a system. Because of its close relation to the time-evolution of a system, it is of fundamental importance in most formulations of quantum theory.
The Hamiltonian is named after Sir William Rowan Hamilton (1805 – 1865), an Irish physicist, astronomer, and mathematician, best known for his reformulation of Newtonian mechanics, now called Hamiltonian mechanics.
Introduction.
The Hamiltonian is the sum of the kinetic energies of all the particles, plus the potential energy of the particles associated with the system. For different situations or number of particles, the Hamiltonian is different since it includes the sum of kinetic energies of the particles, and the potential energy function corresponding to the situation.
The Schrödinger Hamiltonian.
One particle.
By analogy with classical mechanics, the Hamiltonian is commonly expressed as the sum of operators corresponding to the kinetic and potential energies of a system in the form
where
is the potential energy operator and 
is the kinetic energy operator in which "m" is the mass of the particle, the dot denotes the dot product of vectors, and 
is the momentum operator wherein ∇ is the del operator. The dot product of ∇ with itself is the Laplacian ∇2. In three dimensions using Cartesian coordinates the Laplace operator is
However, complications can arise in the many-body problem. Since the potential energy depends on the spatial arrangement of the particles, the kinetic energy will also depend on the spatial configuration to conserve energy. The motion due to any one particle will vary due to the motion of all the other particles in the system. For this reason cross terms for kinetic energy may appear in the Hamiltonian; a mix of the gradients for two particles:
where "M" denotes the mass of the collection of particles resulting in this extra kinetic energy. Terms of this form are known as "mass polarization terms", and appear in the Hamiltonian of many electron atoms (see below).
For "N" interacting particles, i.e. particles which interact mutually and constitute a many-body situation, the potential energy function "V" is "not" simply a sum of the separate potentials (and certainly not a product, as this is dimensionally incorrect). The potential energy function can only be written as above: a function of all the spatial positions of each particle.
For non-interacting particles, i.e. particles which do not interact mutually and move independently, the potential of the system is the sum of the separate potential energy for each particle, that is
The general form of the Hamiltonian in this case is:
where the sum is taken over all particles and their corresponding potentials; the result is that the Hamiltonian of the system is the sum of the separate Hamiltonians for each particle. This is an idealized situation - in practice the particles are usually always influenced by some potential, and there are many-body interactions. One illustrative example of a two-body interaction where this form would not apply is for electrostatic potentials due to charged particles, because they interact with each other by Coulomb interaction (electrostatic force), as shown below.
Schrödinger equation.
The Hamiltonian generates the time evolution of quantum states. If formula_9 is the state of the system at time "t", then
This equation is the Schrödinger equation. It takes the same form as the Hamilton–Jacobi equation, which is one of the reasons "H" is also called the Hamiltonian. Given the state at some initial time ("t" = 0), we can solve it to obtain the state at any subsequent time. In particular, if "H" is independent of time, then
The exponential operator on the right hand side of the Schrödinger equation is usually defined by the corresponding power series in "H". One might notice that taking polynomials or power series of unbounded operators that are not defined everywhere may not make mathematical sense. Rigorously, to take functions of unbounded operators, a functional calculus is required. In the case of the exponential function, the continuous, or just the holomorphic functional calculus suffices. We note again, however, that for common calculations the physicists' formulation is quite sufficient.
By the *-homomorphism property of the functional calculus, the operator
is a unitary operator. It is the "time evolution operator", or "propagator", of a closed quantum system. If the Hamiltonian is time-independent, {U(t)} form a one parameter unitary group (more than a semigroup); this gives rise to the physical principle of detailed balance.
Dirac formalism.
However, in the more general formalism of Dirac, the Hamiltonian is typically implemented as an operator on a Hilbert space in the following way:
The eigenkets (eigenvectors) of "H", denoted formula_13, provide an orthonormal basis for the Hilbert space. The spectrum of allowed energy levels of the system is given by the set of eigenvalues, denoted {"E"a}, solving the equation:
Since "H" is a Hermitian operator, the energy is always a real number.
From a mathematically rigorous point of view, care must be taken with the above assumptions. Operators on infinite-dimensional Hilbert spaces need not have eigenvalues (the set of eigenvalues does not necessarily coincide with the spectrum of an operator). However, all routine quantum mechanical calculations can be done using the physical formulation.
Expressions for the Hamiltonian.
Following are expressions for the Hamiltonian in a number of situations. Typical ways to classify the expressions are the number of particles, number of dimensions, and the nature of the potential energy function - importantly space and time dependence. Masses are denoted by "m", and charges by "q".
Free particle.
The particle is not bound by any potential energy, so the potential is zero and this Hamiltonian is the simplest. For one dimension:
and in three dimensions:
Constant-potential well.
For a particle in a region of constant potential "V" = "V"0 (no dependence on space or time), in one dimension, the Hamiltonian is:
in three dimensions
This applies to the elementary "particle in a box" problem, and step potentials.
Simple harmonic oscillator.
For a simple harmonic oscillator in one dimension, the potential varies with position (but not time), according to:
where the angular frequency, effective spring constant "k", and mass "m" of the oscillator satisfy:
so the Hamiltonian is:
For three dimensions, this becomes
where the three-dimensional position vector r using cartesian coordinates is ("x", "y", "z"), its magnitude is
Writing the Hamiltonian out in full shows it is simply the sum of the one-dimensional Hamiltonians in each direction:
Rigid rotor.
For a rigid rotor – i.e. system of particles which can rotate freely about any axes, not bound in any potential (such as free molecules with negligible vibrational degrees of freedom, say due to double or triple chemical bonds), Hamiltonian is:
where "Ixx", "Iyy", and "Izz" are the moment of inertia components (technically the diagonal elements of the moment of inertia tensor), and formula_26, formula_27 and formula_28 are the total angular momentum operators (components), about the "x", "y", and "z" axes respectively.
Electrostatic or coulomb potential.
The Coulomb potential energy for two point charges "q"1 and "q"2 (i.e. charged particles, since particles have no spatial extent), in three dimensions, is (in SI units - rather than Gaussian units which are frequently used in electromagnetism):
However, this is only the potential for one point charge due to another. If there are many charged particles, each charge has a potential energy due to every other point charge (except itself). For "N" charges, the potential energy of charge "qj" due to all other charges is (see also Electrostatic potential energy stored in a configuration of discrete point charges):
where "φ"(ri) is the electrostatic potential of charge "qj" at ri. The total potential of the system is then the sum over "j":
so the Hamiltonian is:
Electric dipole in an electric field.
For an electric dipole moment d constituting charges of magnitude "q", in a uniform, electrostatic field (time-independent) E, positioned in one place, the potential is:
the dipole moment itself is the operator
Since the particle is stationary, there is no translational kinetic energy of the dipole, so the Hamiltonian of the dipole is just the potential energy:
Magnetic dipole in a magnetic field.
For a magnetic dipole moment μ in a uniform, magnetostatic field (time-independent) B, positioned in one place, the potential is:
Since the particle is stationary, there is no translational kinetic energy of the dipole, so the Hamiltonian of the dipole is just the potential energy:
For a Spin-½ particle, the corresponding spin magnetic moment is:
where "gs" is the spin gyromagnetic ratio (a.k.a. "spin g-factor"), "e" is the electron charge, S is the spin operator vector, whose components are the Pauli matrices, hence
Charged particle in an electromagnetic field.
For a charged particle "q" in an electromagnetic field, described by the scalar potential "φ" and vector potential A, there are two parts to the Hamiltonian to substitute for. The momentum operator must be replaced by the kinetic momentum operator, which includes a contribution from the A field:
where formula_41 is the canonical momentum operator given as the usual momentum operator:
so the corresponding kinetic energy operator is:
and the potential energy, which is due to the "φ" field:
Casting all of these into the Hamiltonian gives:
Energy eigenket degeneracy, symmetry, and conservation laws.
In many systems, two or more energy eigenstates have the same energy. A simple example of this is a free particle, whose energy eigenstates have wavefunctions that are propagating plane waves. The energy of each of these plane waves is inversely proportional to the square of its wavelength. A wave propagating in the "x" direction is a different state from one propagating in the "y" direction, but if they have the same wavelength, then their energies will be the same. When this happens, the states are said to be "degenerate".
It turns out that degeneracy occurs whenever a nontrivial unitary operator "U" commutes with the Hamiltonian. To see this, suppose that formula_46 is an energy eigenket. Then formula_47 is an energy eigenket with the same eigenvalue, since
Since "U" is nontrivial, at least one pair of formula_46 and formula_47 must represent distinct states. Therefore, "H" has at least one pair of degenerate energy eigenkets. In the case of the free particle, the unitary operator which produces the symmetry is the rotation operator, which rotates the wavefunctions by some angle while otherwise preserving their shape.
The existence of a symmetry operator implies the existence of a conserved observable. Let "G" be the Hermitian generator of "U":
It is straightforward to show that if "U" commutes with "H", then so does "G":
Therefore,
In obtaining this result, we have used the Schrödinger equation, as well as its dual,
Thus, the expected value of the observable "G" is conserved for any state of the system. In the case of the free particle, the conserved quantity is the angular momentum.
Hamilton's equations.
Hamilton's equations in classical Hamiltonian mechanics have a direct analogy in quantum mechanics. Suppose we have a set of basis states formula_55, which need not necessarily be eigenstates of the energy. For simplicity, we assume that they are discrete, and that they are orthonormal, i.e.,
Note that these basis states are assumed to be independent of time. We will assume that the Hamiltonian is also independent of time.
The instantaneous state of the system at time "t", formula_57, can be expanded in terms of these basis states:
where
The coefficients "an(t)" are complex variables. We can treat them as coordinates which specify the state of the system, like the position and momentum coordinates which specify a classical system. Like classical coordinates, they are generally not constant in time, and their time dependence gives rise to the time dependence of the system as a whole.
The expectation value of the Hamiltonian of this state, which is also the mean energy, is
where the last step was obtained by expanding formula_57 in terms of the basis states.
Each of the "an(t)"'s actually corresponds to "two" independent degrees of freedom, since the variable has a real part and an imaginary part. We now perform the following trick: instead of using the real and imaginary parts as the independent variables, we use "an(t)" and its complex conjugate "an*(t)". With this choice of independent variables, we can calculate the partial derivative
By applying Schrödinger's equation and using the orthonormality of the basis states, this further reduces to
Similarly, one can show that
If we define "conjugate momentum" variables "πn" by
then the above equations become
which is precisely the form of Hamilton's equations, with the formula_67s as the generalized coordinates, the formula_68s as the conjugate momenta, and formula_69 taking the place of the classical Hamiltonian.

</doc>
<doc id="14382" url="http://en.wikipedia.org/wiki?curid=14382" title="Hi-hat">
Hi-hat

A hi-hat, also spelled hihat, is a type of cymbal and stand used as a typical part of a drum kit by percussionists in rhythm and blues, hip-hop, disco, jazz, metal, rock and roll, house, reggae and other forms of contemporary popular music. It is a standard part of the modern drum kit. The hi-hat consists of two cymbals that are mounted on a stand, one on top of the other, and a pedal which can be used to clash and hold the cymbals together. Open and closed hi-hat refer to notes struck while the two cymbals are apart or together (open or closed), while pedal hi-hat refers to parts or notes played solely with the pedal used to strike the two cymbals. Most cymbal patterns consist of both open and closed notes.
History.
Initial versions of the hi-hat were called clangers, which were small cymbals mounted onto a bass drum rim and struck with an arm on the bass drum pedal. Then came shoes, which were two hinged boards with cymbals on the ends that were clashed together. Next was the low-sock, low-boy or low-hat, similar to a modern hi-hat stand, only with cymbals close to the ground. Hi-hats that were raised and could be played by hand as well as foot may have been developed around 1926 by Barney Walberg of the drum accessory company Walberg and Auge.
Until the late 1960s, the standard hi-hats were 14 in, with 13 in available as a less-common alternative in professional cymbal ranges and smaller sizes down to 12 in restricted to children's kits. In the early 1970s, hard rock drummers (including Led Zeppelin's John Bonham) began to use 15-inch hi-hats, such as the Paiste Giant Beat. In the late 1980s, Zildjian released its revolutionary 12 inch Special Recording hats, which were small, heavy hi-hat cymbals intended for close miking either live or recording, and other manufacturers quickly followed suit, Sabian for example with their 10" mini hats. In the early to mid-1990s, Paiste offered 8 in mini hi-hats as part of its Visions series; these were among the world's smallest hi-hats. Starting in the 1980s, a number of manufacturers also experimented with rivets in the lower cymbal. But by the end of the 1990s, the standard size was again 14 inches, with 13 inches a less-common alternative, and smaller hats mainly used for special sounds. Rivets in hi-hats failed to catch on.
Modern hi-hat cymbals are much heavier than modern crash cymbals, reflecting the trend to lighter and thinner crash cymbals as well as to heavier hi-hats. The other change has been that a pair of hi-hat cymbals are no longer necessarily similar. More typically the bottom is now heavier than the top (but in some cases like the K Custom Zildjian Steve Gadd Session Hats the pattern is reversed for a cleaner chick and cleaner sticking), and may also be vented, this being one innovation to have caught on. Some examples are Sabian's Fusion Hats with holes in the bottom of the hi-hat, and the Sabian X-cellerator, Zildjian Master Sound and Zildjian Quick Beats, Paiste Sound Edge, and Meinl Soundwave. Some drummers even use completely mismatched hi-hats from different cymbal ranges (Zildjian's K/Z hats), of different manufacturers, and even of different sizes (similar to the K Custom Session Hats where the top hat is a sixteenth of an inch smaller than the bottom). Max Roach was particularly known for using a 15 inch top with a 14 inch bottom.
Other recent developments include the X-hat (fixed, closed, or half-open hi-hats) and cable-controlled or remote hi-hats. Sabian introduced the Triple Hi-Hat, designed by Peter Kuppers. In this variation of the hi-hat, the top cymbal moves down and the bottom cymbal moves up simultaneously while the middle cymbal remains stationary.
Drop-clutches are also used to lock and release hi-hats while both feet are in use playing double bass drums. The drop clutch was invented by ragtime drummer Graig Cortelyou . Drop clutches are commercially available from , , from Billdidit, and Tama.
Modern stands.
The traditional hi-hat stand has the pedal almost directly below the cymbals, which are supported by a hollow vertical tube. The top cymbal is mounted horizontal and bell up, while an adjustment screw allows the bottom cymbal to be either horizontal or slightly tilted.
A narrow metal shaft or rod runs through both cymbals and the tube and connects to the pedal. The top cymbal is connected to the rod with a clutch, and can be lowered by operating the pedal against a spring which holds it up in the "open" position, while the bottom cymbal remains stationary. The height of the top cymbal with the pedal released is adjustable by varying the position of the clutch on the centre shaft. When the hats are closed, the pressure holding them together can be varied by varying the foot pressure.
So, when the foot plate of the pedal is pressed, the top cymbal crashes onto the bottom cymbal (closed hi-hat). When released, the top cymbal returns to its original position above the bottom cymbal (open hi-hat). The spring tension controls the amount of pressure required to lower the top cymbal, and how fast it returns to its open position, and can also be varied.
Some stands allow the feet of the tripod to be adjusted to tilt the stand, or to allow the tripod to rotate on the stand to allow the feet to be positioned among other stands. Other stands omit the tripod and instead attach the stand to the side of the bass drum; This is particular suitable for very large bass drums or double bass drum configurations.
Clutch.
There are several patterns of clutch used to support the top cymbal, but the most common uses a knurled collar that is part threaded below the cymbal, and a pair of knurled rings above it. The collar is tightened against the end of the thread, while the rings are tightened against each other.
Drop clutch.
A drop clutch allows a pair of hats mounted on a conventional hi-hat stand to be closed without use of the pedal.
The drop clutch is provided with a lever that can be operated by hand or struck with a drumstick. This action releases the upper hi-hat cymbal, which falls onto the bottom cymbal and remains there, with gravity then holding the hats loosely closed, and allowing them to be played by the sticks in this position. Operation of the pedal re-engages the clutch and allows the player to resume normal playing.
Drop clutches were developed to allow players using double bass drum pedals to play closed hi-hats without needing to operate the hi-hat pedal, and this remains their primary application.
As it relies on gravity to close the cymbals, the drop clutch gives the player no control over the tension holding them together, and supplies only minimal tension. On the other hand, if the player manually lowers the top cymbal of a standard hi-hat stand before playing, this allows any desired tension to be set, and the pedal can still be used to increase the tension while playing, but not to open the hats or to reduce the tension. Some drummers prefer this technique and reject the drop clutch as too limiting to the sounds available.
A less common alternative is the locking hi-hat pedal, such as the Tama "Cobra Clutch". This and similar high-end locking pedals do allow for control over the tension. It is engaged by pressing a lock pedal separate from the main pedal.
Cable hats.
A cable hat or remote hat uses a cable to allow hi-hat cymbals to be positioned independently of the pedal. Operation is otherwise normal.
X-hats.
An X-hat is an adaptor to allow a pair of hi-hat cymbals to be mounted in a closed position on a cymbal stand. There is no pedal, the hats are simply kept closed at a constant tension, similarly to a cymbal stack.
The X-hat gives control over the tension holding the hats closed, and allows the player to apply similar tension and produce similar tone to pedal operation, but not to vary the tension while playing.
Playing.
When struck closed or played with the pedal, the hi-hat gives a short, crisp, muted percussive sound, sounding like and referred to as a "chick". Adjusting the gap between the cymbals can alter the sound of the open hi-hat from a shimmering, sustained tone to something similar to a ride cymbal. When struck with a drumstick, the cymbals make either a short, snappy sound or a longer sustaining sandy sound depending on the position of the pedal.
It can also be played just by lifting and lowering the foot to clash the cymbals together, a style commonly used to accent beats 2 and 4 in jazz music. In rock music, the hi-hats are commonly struck every beat or on beats 1 and 3, while the cymbals are held together. The drummer can control the sound by foot pressure. Less pressure allows the cymbals to rub together more freely, giving both greater sustain and greater volume for accent or crescendo. In shuffle time, a rhythm known as "cooking" is often employed. To produce this the cymbals are struck twice in rapid succession, being held closed on the first stroke and allowed to open just before the second, then allowed to ring before being closed with a chick to complete the pattern (the cymbals may or may not be struck on the chick).
A right-handed drummer will normally play the hi-hat pedal with his left foot, and may use one or both drumsticks. The traditional hi-hat rhythms of rock and jazz were produced by crossing the hands over, so the right stick would play the hi-hat while the left played the snare drum below it, but this is not universal. Some top modern drummers like Billy Cobham, Carter Beauford, Shawn Drover and Simon Phillips do not cross their hands over at all, playing the hi-hat mounted on the left with the left stick rather than the right. This is called open handed playing. Some drummers, such as Kenny Aronoff, and Jason Finn of The Presidents of the United States of America employ both open handed and cross-handed playing. Some trap sets may also include an extra hi-hat on the right for right-handed players, where it would be awkward to play crossed over. This is shown when drums or cymbals in the middle of the set are played with the hi-hat rhythm. The technique is common with metal genres, such as Lars Ulrich of Metallica and Mike Portnoy formerly of Dream Theater. In both rock and jazz, often the drummer will move the same stick pattern between the hi-hat cymbal and the ride cymbal, for example using the hi-hat in the verses and the ride in the chorus of a song, or using the ride to accompany a lead break or other instrumental solo.
Roger Taylor, drummer for the band Queen, plays with many unique hi-hat techniques, including involuntary opening of the hi-hat on every backbeat for a rhythm emphasis and leaving the hi-hat slightly open when hitting the snare. His trademark hi-hat beat is opening the hi-hat on first and third before hitting the snare.
Phil Rudd of AC/DC also uses distinct hi-hat techniques, which include very heavily accentuating the hi-hat hit on each beat and softer in between.
Charlie Watts of The Rolling Stones uses a technique in which he does not play the hi-hat in unison with the snare drum at all. If playing a standard 8th note pattern, he will play the hi-hat on 1 and 3 and not playing it on 2 and 4 where the snare drum is played.
In much hip-hop, the hi-hat is hit with drumsticks in a simple eighth-note pattern, although this playing is usually done by a drum machine or from an old recording from which the sound of a hi-hat is recorded and loaded into a sampler or similar recording-enabled equipment from which it is triggered. Pioneer Kurtis Mantronik was one of the first to program hi-hat patterns that employed thirty-second notes , although these can be played by a drummer using a technique similar to a drum roll.

</doc>
<doc id="14384" url="http://en.wikipedia.org/wiki?curid=14384" title="HAL 9000">
HAL 9000

HAL 9000 is a fictional character in Arthur C. Clarke's "Space Odyssey" series. The primary antagonist of ', HAL (Heuristically programmed AL"'gorithmic computer) is a sentient computer (or artificial intelligence) that controls the systems of the "Discovery One" spacecraft and interacts with the ship's astronaut crew. HAL's exterior physical form is not depicted, though it is visually represented as a red television camera eye located on equipment panels throughout the ship, and its interior in the scene where his advanced memory modules are disconnected. HAL 9000 is voiced by Douglas Rain in the two film adaptations of the "Space Odyssey" series. HAL speaks in a soft, calm voice and a conversational manner, in contrast to the crewmen, David Bowman and Frank Poole, who speak tersely and with little emotional inflection.
In the context of the series, HAL became operational on 12 January 1997 at the HAL Laboratories in Urbana, Illinois as production number 3; in the film "2001", the activation year was 1992 and 1991 in earlier screenplays. In addition to maintaining the "Discovery One" spacecraft systems during the interplanetary mission to Jupiter (or Saturn in the original novel, published shortly after the release of the film), HAL is capable of speech, speech recognition, facial recognition, natural language processing, lip reading, art appreciation, interpreting and reproducing emotional behaviours, automated reasoning, and playing chess.
Appearances.
"2001: A Space Odyssey".
HAL became operational in Urbana, Illinois, at the HAL Plant (the University of Illinois' Coordinated Science Laboratory, where the ILLIAC computers were built). The film says this occurred in 1992, while the book gives 1997 as HAL's birth year.<ref name=Urbana 1992/7></ref> 
In "", HAL is initially considered a dependable member of the crew, maintaining ship functions and engaging genially with its human crew-mates on an equal footing. As a recreational activity, Frank Poole plays against HAL in a game of chess. In the film the artificial intelligence is shown to triumph easily. 
However, as time progresses, HAL begins to malfunction in subtle ways and, as a result, the decision is made to shut down HAL in order to prevent more serious malfunctions. The sequence of events and manner in which HAL is shut down differs between the novel and film versions of the story. In the aforementioned game of chess HAL makes minor and undetected mistakes in his analysis, a possible foreshadowing to HAL's malfunctioning.
In the film, astronauts David Bowman and Frank Poole consider disconnecting HAL's cognitive circuits when he appears to be mistaken in reporting the presence of a fault in the spacecraft's communications antenna. They attempt to conceal what they are saying, but are unaware that HAL can read their lips. Faced with the prospect of disconnection, HAL decides to kill the astronauts in order to protect and continue its programmed directives, and to conceal its malfunction from Earth. HAL uses one of the Discovery's EVA pods to kill Poole while he is repairing the ship. When Bowman uses another pod to attempt to rescue Poole, HAL locks him out of the ship, then disconnects the life support systems of the other hibernating crew members. Dave circumvents HAL's control, entering the ship by manually opening an emergency airlock with his service pod's clamps, detaching the pod door via its explosive bolts. Bowman jumps across empty space, reenters Discovery, and quickly repressurizes the airlock.
The novel explains that HAL is unable to resolve a conflict between his general mission to relay information accurately, and orders specific to the mission requiring that he withhold from Bowman and Poole the true purpose of the mission. (This withholding is considered essential after the findings of a psychologic experiment, "Project Barsoom", where humans were made to believe that there had been alien contact. In every person tested, a deep-seated xenophobia was revealed, which was unknowingly replicated in HAL's constructed personality. Mission Control did not want the crew of "Discovery" to have their thinking compromised by the knowledge that alien contact was already real.) With the crew dead, HAL reasons, he would not need to lie to them. He fabricates the failure of the AE-35 antenna-steering unit so that their deaths would appear accidental.
In the novel, the orders to disconnect HAL come from Dave and Frank's superiors on Earth. After Frank is killed while attempting to repair the communications antenna—his oxygen hose gets disconnected and he is pushed away into deep space—Dave begins to revive his hibernating crewmates, but is foiled when HAL vents the ship's atmosphere into the vacuum of space, killing the awakening crew members and almost killing Dave. Dave is only narrowly saved when he finds his way to an emergency chamber which has its own oxygen supply and a spare space suit inside.
In both versions, Bowman then proceeds to shut down the machine. In the film, HAL's central core is depicted as a crawlspace full of brightly lit computer modules mounted in arrays from which they can be inserted or removed. Bowman shuts down HAL by removing modules from service one by one; as he does so, HAL's consciousness degrades. HAL regurgitates material that was programmed into him early in his memory, including announcing the date he became operational as 12 January 1992 (in the novel, it's 1997). When HAL's logic is completely gone, he begins singing the song "Daisy Bell" (in actuality, the first song sung by a computer). HAL's final act of any significance is to prematurely play a prerecorded message from Mission Control which reveals the true reasons for the mission to Jupiter.
"2010: Odyssey Two".
In the sequel "", HAL is restarted by his creator, Dr. Chandra, who arrives on the Soviet spaceship "Leonov".
Prior to leaving Earth, Dr. Chandra has also had a discussion with HAL's twin, the SAL 9000. Like HAL, SAL was created by Dr. Chandra. Whereas HAL was characterised as being "male", SAL is characterised as being "female" (voiced by Candice Bergen) and is represented by a blue camera eye instead of a red one.
Dr. Chandra discovers that HAL's crisis was caused by a programming contradiction: he was constructed for "the accurate processing of information without distortion or concealment", yet his orders, directly from Dr. Heywood Floyd at the National Council on Astronautics, required him to keep the discovery of the Monolith TMA-1 a secret for reasons of national security. This contradiction created a "Hofstadter-Moebius loop", reducing HAL to paranoia. Therefore, HAL made the decision to kill the crew, thereby allowing him to obey both his hardwired instructions to report data truthfully and in full, and his orders to keep the monolith a secret. In essence: if the crew were dead, he would no longer have to keep the information secret.
The alien intelligence initiates a terraforming scheme, placing the "Leonov", and everybody in it, in danger. Its human crew devises an escape plan, which unfortunately requires leaving the "Discovery" and HAL behind, to be destroyed. Dr. Chandra explains the danger, and HAL willingly sacrifices himself so that the astronauts may escape safely. In the moment of his destruction, the monolith-makers transform HAL into a non-corporeal being, so that David Bowman's avatar may have a companion.
The details in the book and the film are nominally the same, with a few exceptions. First, in contradiction to the book (and events described in both book and film versions of "2001: A Space Odyssey"), Heywood Floyd is absolved of responsibility for HAL's condition; it is asserted that the decision to program HAL with information concerning TMA-1 came directly from the White House. In the film, HAL functions normally after being reactivated, while in the book it is revealed that his mind was damaged during the shutdown, forcing him to begin communication through screen text. Also, in the film the "Leonov" crew lies to HAL about the dangers that he faced (suspecting that if he knew he would be destroyed he would not initiate the engine-burn necessary to get the "Leonov" back home), whereas in the novel he is told at the outset. However, in both cases the suspense comes from the question of what HAL will do when he knows that he may be destroyed by his actions.
The basic reboot sequence initiated by Dr. Chandra in the movie "2010" is voiced from 
HAL as, "HELLO_DOCTOR_NAME_CONTINUE_
YESTERDAY_TOMORROW" (which in the novel "2010" is a longer sequence).
Prior to "Leonov"‍ '​s return to Earth, Curnow tells Floyd that Dr. Chandra has begun designing HAL 10000.
In "" it is revealed that Chandra died on the journey back to Earth.
"2061: Odyssey Three" and "3001: The Final Odyssey".
In "", Heywood Floyd is surprised to encounter HAL, now stored alongside Dave Bowman in the Europa monolith.
' Frank Poole was introduced to the merged form of Dave Bowman and HAL, the two merging into one entity called "Halman" after Bowman rescued HAL from the dying "Discovery One" spaceship towards the end of '.
Concept and creation.
Clarke noted that the film "2001" was criticized for not having any characters, except for HAL and that a great deal of the establishing story on Earth was cut from the film (and even from Clarke's novel). Early drafts of Clarke's story called the computer Socrates (a preferred name to Autonomous Mobile Explorer–5), with another draft giving the computer a female personality called Athena. This name was later used in Clarke and Stephen Baxter's "A Time Odyssey" novel series.
The earliest draft depicted Socrates as a roughly humanoid robot, and is introduced as overseeing Project Morpheus, which studied prolonged hibernation in preparation for long term space flight. As a demonstration to "Senator" Floyd, Socrates' designer, Dr. Bruno Forster, asks Socrates to turn off the oxygen to hibernating subjects Kaminski and Whitehead, which Socrates refuses, citing Asimov's First Law of Robotics.
In a later version, Poole is killed outside the spacecraft, triggering the need for Bowman to revive Whitehead. The revival does not go according to plan, and after briefly awakening, Whitehead dies. Athena announces "All systems of Poole now No–Go. It will be necessary to replace him with a spare unit." After this, Bowman decides to go out in a pod and retrieve the antenna, which is moving away from the ship. Athena will not originally let him go, citing a "Directive 15", but eventually relents.
During rehearsals Kubrick asked Stefanie Powers to supply the voice of HAL 9000 while searching for a suitably androgynous voice so the actors had something to react to. On the set, British actor Nigel Davenport played HAL. When it came to dubbing HAL in post-production, Kubrick had originally cast Martin Balsam, but as he felt Balsam "just sounded a little bit too colloquially American", he was replaced with Douglas Rain, who "had the kind of bland mid-Atlantic accent we felt was right for the part." Rain was only handed HAL's lines instead of the full script, and recorded them across a day and a half.
HAL's point of view shots were created with a Cinerama 160-degree Fairchild-Curtis wide-angle lens. This lens is about 8 in in diameter, while HAL's prop eye lens is about 3 in in diameter. Stanley Kubrick chose to use the large Fairchild-Curtis lens to shoot the HAL 9000 POV shots because he needed a wide-angle fisheye lens that would fit onto his shooting camera, and this was the only lens at the time that would work. The HAL 9000 faceplate, without lens, was discovered in a junk shop in Paddington, London, in the early 1970s by Chris Randall. Research revealed that the original lens was a Nikon Nikkor 8mm F8. This was found along with the key to HAL's Brain Room. Both items were purchased for ten shillings (£0.50) The collection was sold at a Christies auction in 2010 for £17,500.
Origin of name.
Although it is often conjectured that the name HAL was based on a one-letter shift from the name IBM, this has been denied by both Clarke and "2001" director Stanley Kubrick. In "", Clarke speaks through the character of Dr. Chandra (he originally spoke through Dr. Floyd until Chandra was awakened), who characterized this idea as: "[u]tter nonsense! [...] I thought that by now every intelligent person knew that H-A-L is derived from "H"euristic "AL"gorithmic".
Clarke more directly addressed this issue in his book "The Lost Worlds of 2001":
As is clearly stated in the novel (Chapter 16), "HAL" stands for "H"euristically programmed "AL"gorithmic computer. However, about once a week some character spots the fact that HAL is one letter ahead of IBM, and promptly assumes that Stanley and I were taking a crack at the estimable institution ... As it happened, IBM had given us a good deal of help, so we were quite embarrassed by this, and would have changed the name had we spotted the coincidence.
Also, IBM is explicitly mentioned in the film "2001", as are many other real companies. IBM is given fictional credit as being the manufacturer of the Pan Am Clipper's computer, and the IBM logo can be seen in the center of the cockpit's instrument panel. In addition, the IBM logo is shown on the lower arm keypad on Poole's space suit in the scene where he space walks to replace the antenna unit, and may possibly be shown reflected on Bowman's face when he is inside the pod on his way to retrieve the body of Poole (there is speculation as to whether or not the reflection is that of the letters "IBM" or the letters "MGM", the film studio).
Influences.
The scene in which HAL's consciousness degrades was inspired by Clarke's memory of a speech synthesis demonstration by physicist John Larry Kelly, Jr., who used an IBM 704 computer to synthesize speech. Kelly's voice recorder synthesizer "vocoder" recreated the song "Daisy Bell", with musical accompaniment from Max Mathews.
HAL has inspired some designs of intelligent computers in some science fiction films, like "Mother" (MU-TH-R 182 model 2.1 terabyte AI Mainframe) in "Alien", VIKI in "I, Robot", and AUTO in "Wall-E".
HAL's capabilities, like all the technology in "2001", were based on the speculation of respected scientists. Marvin Minsky, director of the MIT Computer Science and Artificial Intelligence Laboratory (CSAIL) and one of the most influential researchers in the field, was an adviser on the film set. In the mid-1960s, many computer scientists in the field of artificial intelligence were optimistic that machines with HAL's capabilities would exist within a few decades. For example, AI pioneer Herbert A. Simon at Carnegie Mellon University, had predicted in 1965 that "machines will be capable, within twenty years, of doing any work a man can do", the overarching premise being that the issue was one of computational speed (which was predicted to increase) rather than principle.
Cultural impact.
HAL is listed as the 13th-greatest film villain in the AFI's 100 Years...100 Heroes & Villains.
Pierce, inspired in HAL 9000, is the main antagonist in one of the tales in The Simpsons "Treehouse of Horror XII". He resembles HAL in appearance but its voiced by Pierce Brosnan.
The physical form and behaviour of AUTO, the main computer of the Axiom in the film Wall-E, is a clear reference to HAL

</doc>
<doc id="14385" url="http://en.wikipedia.org/wiki?curid=14385" title="Hydrolysis">
Hydrolysis

Hydrolysis (; from " hydro-", meaning "water", and " lysis", meaning "separation") usually means the cleavage of chemical bonds by the addition of water. When a carbohydrate is broken into its component sugar molecules by hydrolysis (e.g. sucrose being broken down into glucose and fructose), this is termed saccharification. Generally, hydrolysis or saccharification is a step in the degradation of a substance.
Types.
Usually hydrolysis is a chemical process in which a molecule of water is added to a substance. Sometimes this addition causes both substance and water molecule to split into two parts. In such reactions, one fragment of the target molecule (or parent molecule) gains a hydrogen ion.
Salts.
A common kind of hydrolysis occurs when a salt of a weak acid or weak base (or both) is dissolved in water. Water spontaneously ionizes into hydroxide anions and hydronium cations. The salt also dissociates into its constituent anions and cations. For example, sodium acetate dissociates in water into sodium and acetate ions. Sodium ions react very little with the hydroxide ions whereas the acetate ions combine with hydronium ions to produce acetic acid. In this case the net result is a relative excess of hydroxide ions, yielding a basic solution.
Strong acids also undergo hydrolysis. For example, dissolving sulfuric acid (H2SO4) in water is accompanied by hydrolysis to give hydronium and bisulfate, the sulfuric acid's conjugate base. For a more technical discussion of what occurs during such a hydrolysis, see Brønsted–Lowry acid–base theory.
Esters and amides.
Acid–base-catalysed hydrolyses are very common; one example is the hydrolysis of amides or esters. Their hydrolysis occurs when the nucleophile (a nucleus-seeking agent, e.g., water or hydroxyl ion) attacks the carbon of the carbonyl group of the ester or amide. In an aqueous base, hydroxyl ions are better nucleophiles than polar molecules such as water. In acids, the carbonyl group becomes protonated, and this leads to a much easier nucleophilic attack. The products for both hydrolyses are compounds with carboxylic acid groups.
Perhaps the oldest commercially practiced example of ester hydrolysis is saponification (formation of soap). It is the hydrolysis of a triglyceride (fat) with an aqueous base such as sodium hydroxide (NaOH). During the process, glycerol is formed, and the fatty acids react with the base, converting them to salts. These salts are called soaps, commonly used in households.
In addition, in living systems, most biochemical reactions (including ATP hydrolysis) take place during the catalysis of enzymes. The catalytic action of enzymes allows the hydrolysis of proteins, fats, oils, and carbohydrates. As an example, one may consider proteases (enzymes that aid digestion by causing hydrolysis of peptide bonds in proteins). They catalyse the hydrolysis of interior peptide bonds in peptide chains, as opposed to exopeptidases (another class of enzymes, that catalyse the hydrolysis of terminal peptide bonds, liberating one free amino acid at a time).
However, proteases do not catalyse the hydrolysis of all kinds of proteins. Their action is stereo-selective: Only proteins with a certain tertiary structure are targeted as some kind of orienting force is needed to place the amide group in the proper position for catalysis. The necessary contacts between an enzyme and its substrates (proteins) are created because the enzyme folds in such a way as to form a crevice into which the substrate fits; the crevice also contains the catalytic groups. Therefore, proteins that do not fit into the crevice will not undergo hydrolysis. This specificity preserves the integrity of other proteins such as hormones, and therefore the biological system continues to function normally.
Upon hydrolysis, an amide converts into a carboxylic acid and an amine or ammonia. The carboxylic acid has a hydroxyl group derived from a water molecule and the amine (or ammonia) gains the hydrogen ion. The hydrolysis of peptides gives amino acids.
Many polyamide polymers such as nylon 6,6 hydrolyse in the presence of strong acids. The process leads to depolymerization. For this reason nylon products fail by fracturing when exposed to small amounts of acidic water. Polyesters are also susceptible to similar polymer degradation reactions. The problem is known as stress corrosion cracking.
ATP.
Hydrolysis is related to energy metabolism and storage. All living cells require a continual supply of energy for two main purposes: for the biosynthesis of micro and macromolecules, and for the active transport of ions and molecules across cell membranes. The energy derived from the oxidation of nutrients is not used directly but, by means of a complex and long sequence of reactions, it is channelled into a special energy-storage molecule, adenosine triphosphate (ATP). The ATP molecule contains pyrophosphate linkages (bonds formed when two phosphate units are combined together) that release energy when needed. ATP can undergo hydrolysis in two ways: the removal of terminal phosphate to form adenosine diphosphate (ADP) and inorganic phosphate, or the removal of a terminal diphosphate to yield adenosine monophosphate (AMP) and pyrophosphate. The latter usually undergoes further cleavage into its two constituent phosphates. This results in biosynthesis reactions, which usually occur in chains, that can be driven in the direction of synthesis when the phosphate bonds have undergone hydrolysis.
Polysaccharides.
Monosaccharides can be linked together by glycosidic bonds, which can be cleaved by hydrolysis. Two, three, several or many monosaccharides thus linked form disaccharides, trisaccharides, oligosaccharides or polysaccharides, respectively. Enzymes that hydrolyse glycosidic bonds are called "glycoside hydrolases" or "glycosidases".
The best-known disaccharide is sucrose (table sugar). Hydrolysis of sucrose yields glucose and fructose. Invertase is a sucrase used industrially for the hydrolysis of sucrose to so-called invert sugar. Lactase is essential for digestive hydrolysis of lactose in milk; many adult humans do not produce lactase and cannot digest the lactose in milk (not a disorder).
The hydrolysis of polysaccharides to soluble sugars is called "saccharification". Malt made from barley is used as a source of β-amylase to break down starch into the disaccharide maltose, which can be used by yeast to produce beer. Other amylase enzymes may convert starch to glucose or to oligosaccharides. Cellulose is first hydrolyzed to cellobiose by cellulase and then cellobiose is further hydrolyzed to glucose by beta-glucosidase. Animals such as cows (ruminants) are able to hydrolyze cellulose into cellobiose and then glucose because of symbiotic bacteria that produce cellulases.
Metal aqua ions.
Metal ions are Lewis acids, and in aqueous solution they form metal aqua ions of the general formula M(H2O)nm+.
The aqua ions undergo hydrolysis, to a greater or lesser extent. The first hydrolysis step is given generically as
Thus the aqua cations behave as acids in terms of Brønsted-Lowry acid-base theory. This effect is easily explained by considering the inductive effect of the positively charged metal ion, which weakens the O-H bond of an attached water molecule, making the liberation of a proton relatively easy.
The dissociation constant, pKa, for this reaction is more or less linearly related to the charge-to-size ratio of the metal ion. Ions with low charges, such as Na+ are very weak acids with almost imperceptible hydrolysis. Large divalent ions such as Ca2+, Zn2+, Sn2+ and Pb2+ have a pKa of 6 or more and would not normally be classed as acids, but small divalent ions such as Be2+ undergo extensive hydrolysis. Trivalent ions like Al3+ and Fe3+ are weak acids whose pKa is comparable to that of acetic acid. Solutions of salts such as BeCl2 or Al(NO3)3 in water are noticeably acidic; the hydrolysis can be suppressed by adding an acid such as nitric acid, making the solution more acidic.
Hydrolysis may proceed beyond the first step, often with the formation of polynuclear species via the process of olation. Some "exotic" species such as Sn3(OH)42+ are well characterized. Hydrolysis tends to proceed as pH rises leading, in many cases, to the precipitation of a hydroxide such as Al(OH)3 or AlO(OH). These substances, major constituents of bauxite, are known as laterites and are formed by leaching from rocks of most of the ions other than aluminium and iron and subsequent hydrolysis of the remaining aluminium and iron.

</doc>
<doc id="14386" url="http://en.wikipedia.org/wiki?curid=14386" title="Hydroxyl">
Hydroxyl

A hydroxyl is a chemical functional group containing an oxygen atom connected by a covalent bond to a hydrogen atom. It is sometimes called the alcohol functional group because when bonded to carbon in a molecule that otherwise contains only hydrogen and carbon the hydroxy group defines the molecule as an alcohol, resulting in a name ending in -ol. A hydroxy group bonded covalently to the carbon of a carbonyl group (C=O) produces a carboxyl group (C(O)OH) that is the defining group of a carboxylic acid. When the -OH group participates in an ionic bond, the [OH−] anion is called the "hydroxide" ion.
Hydroxy group.
According to IUPAC rules the term hydroxyl refers to the radical OH only while the functional group -OH is called hydroxy group.
The oxygen atom in the hydroxy group is much more electronegative than the hydrogen, so that the electrons are closer to the oxygen atom. Similar to water, compounds containing the hydroxy group are capable of forming hydrogen bonds. Primary alcohols are miscible with water. In complex compounds, the portion of the molecule containing the hydroxy group is hydrophilic.
The hydroxy group appears throughout organic chemical structure and biochemical structure. It appears covalently bonded to carbon in sugars. The hydroxy group appears on the second carbon atom of the hydroxy amino acids serine and threonine. It appears on the phenol side chain of tyrosine. The capacity of the hydroxy group to form hydrogen bonds imparts water solubility and internal structural stability to proteins that include these amino acids.
Hydroxy groups participate in the dehydration reactions that link simple biological molecules into long chains. The joining of a fatty acid to glycerol to form a triacylglycerol removes the -OH from the carboxy end of the fatty acid. The joining of two aldehyde sugars to form a disaccharide removes the -OH from the carboxy group at the aldehyde end of one sugar. The creation of a peptide bond to link two amino acids to make a protein removes the -OH from the carboxy group of one amino acid.
Hydroxyl radical.
Hydroxyl radicals are highly reactive and undergo chemical reactions that make them short-lived. When biological systems are exposed to hydroxyl radicals, they can cause damage to cells, including those in humans, where they react with DNA, lipids, and proteins.
Lunar and other extraterrestrial observations.
In 2009, India's Chandrayaan-1 satellite, NASA's Cassini spacecraft and the Deep Impact probe have each detected the presence of water by evidence of hydroxyl fragments on the Moon. As reported by Richard Kerr, "A spectrometer (the Moon Mineralogy Mapper, a.k.a. "M3"), detected an infrared absorption at a wavelength of 3.0 micrometers that only water or hydroxyl—a hydrogen and an oxygen bound together—could have created." NASA also reported in 2009 that the LCROSS probe revealed an ultraviolet emission spectrum consistent with hydroxyl presence. The Venus Express orbiter has been continuously sending back Venus science data since April 11, 2006. Results from "Venus Express" include the detection of hydroxyl in the atmosphere.

</doc>
<doc id="14387" url="http://en.wikipedia.org/wiki?curid=14387" title="Warm-blooded">
Warm-blooded

The term warm-blooded is a colloquial term to describe animal species that have a relatively high blood temperature when compared with ectothermic ones, and maintain thermal homeostasis primarily through internal metabolic processes. These are characteristics of mammals, birds and the Opah (only known warm-blooded fish). 
Both the terms "warm-blooded" and "cold-blooded" have fallen out of favour with scientists because of the vagueness of the terms and an increased understanding of the field. Body temperature types are not discrete categories. Each term may be replaced with one or more variants (see the next section for examples). Body temperature maintenance (thermoregulation) incorporates a wide range of different techniques that result in a body temperature continuum.
Characteristics of warm-bloodedness.
In general, warm-bloodedness refers to three separate aspects of thermoregulation.
Reasons for term falling into disuse.
A large proportion of the creatures traditionally called "warm-blooded", such as mammals and birds, fit all three of these categories (i.e., they are endothermic, homeothermic, "and" tachymetabolic). However, over the past 30 years, studies in the field of animal thermophysiology have revealed many species belonging to these two groups that do not fit all these criteria. For example, many bats and small birds are poikilothermic and bradymetabolic when they sleep for the night (or, in nocturnal species, for the day). For these creatures, the term heterothermy was coined.
Further studies on animals that were traditionally assumed to be cold-blooded have shown that most creatures incorporate different variations of the three terms defined above, along with their counterparts (ectothermy, poikilothermy, and bradymetabolism), thus creating a broad spectrum of body temperature types. Even some fish have warm-blooded characteristics. Swordfish and some sharks have circulatory mechanisms that keep their brains and eyes above ambient temperatures, and thus increase their ability to detect and react to prey. Tunas and some sharks have similar mechanisms in their muscles, improving their stamina when swimming at high speed.
Heat generation.
Body "heat" is generated by the metabolism. This refers to the chemical reactions cells use to break down glucose into water and carbon dioxide and, in so doing, generate ATP (adenosine triphosphate), a high-energy compound used to power other cellular processes. 
All organisms metabolize food and other inputs, but some make better use of the output than others. Like all energy conversions, metabolism is rather inefficient, and around 60% of the available energy is converted to heat rather than to ATP. In most organisms, this heat is simply lost to the environment. However, endothermic homeotherms (the animals generally characterized as "warm-blooded") both produce more heat and have better ways to retain and regulate it than other animals. They have a higher basal metabolic rate, and also a greater capacity to increase their metabolic rate when engaged in strenuous activity. They usually have well-developed insulation in order to retain body heat, fur in the case of mammals and feathers in birds. When this insulation is insufficient to maintain body temperature, they may resort to shivering — rapid muscle contractions that quickly use up ATP, thus stimulating cellular metabolism to replace it and consequently produce more heat. In general, in hot environments, they use evaporative cooling to shed excess heat, either by sweating (some mammals) or by panting (many mammals and all birds) — in general, mechanisms not present in poikilotherms.
Defence against fungi.
It has been hypothesized that mammals and birds evolved warm-bloodedness as a defence against fungal infections. Very few fungi can survive the body temperatures of warm-blooded animals. By comparison, insects, reptiles, and amphibians are plagued by fungal infections.

</doc>
<doc id="14388" url="http://en.wikipedia.org/wiki?curid=14388" title="Hephaestus">
Hephaestus

Hephaestus (, or ; eight spellings; Ancient Greek: Ἥφαιστος "Hēphaistos") is the Greek god of blacksmiths, craftsmen, artisans, sculptors, metals, metallurgy, fire and volcanoes. Hephaestus' Roman equivalent is Vulcan. In Greek mythology, Hephaestus was the son of Zeus and Hera, the king and queen of the gods.
As a smithing god, Hephaestus made all the weapons of the gods in Olympus. He served as the blacksmith of the gods, and was worshipped in the manufacturing and industrial centers of Greece, particularly Athens. The cult of Hephaestus was based in Lemnos. Hephaestus' symbols are a smith's hammer, anvil, and a pair of tongs.
Etymology.
Hephaestus is probably associated with the Linear B (Mycenean Greek) inscription 𐀀𐀞𐀂𐀴𐀍, "A-pa-i-ti-jo", found at Knossos; the inscription indirectly attests his worship at that time because it is believed that it reads the theophoric name "Haphaistios" or "Haphaistion". The name of the god in Greek ("Hēphaistos"), has a root which can be observed in names of places, of Pre-Greek origin, like Phaistos ("Pa-i-to" in Linear B).
Epithets.
Hephaestus is given many epithets. The meaning of each epithet is:
Mythology.
The craft of Hephaestus.
Hephaestus had his own palace on Olympus, containing his workshop with anvil and twenty bellows that worked at his bidding. Hephaestus crafted much of the magnificent equipment of the gods, and almost any finely-wrought metalwork imbued with powers that appears in Greek myth is said to have been forged by Hephaestus. He designed Hermes' winged helmet and sandals, the Aegis breastplate, Aphrodite's famed girdle, Agamemnon's staff of office, Achilles' armor, Heracles' bronze clappers, Helios' chariot, the shoulder of Pelops, and Eros' bow and arrows. In later accounts, Hephaestus worked with the help of the chthonic Cyclopes—among them his assistants in the forge, Brontes, Steropes and Pyracmon.
Hephaestus also built automatons of metal to work for him. This included tripods that walked to and from Mount Olympus. He gave to the blinded Orion his apprentice Cedalion as a guide. Prometheus stole the fire that he gave to man from Hephaestus's forge. Hephaestus also created the gift that the gods gave to man, the woman Pandora and her pithos. Being a skilled blacksmith, Hephaestus created all the thrones in the Palace of Olympus.
The Greek myths and the Homeric poems sanctified in stories that Hephaestus had a special power to produce motion. He made the golden and silver lions and dogs at the entrance of the palace of Alkinoos in such a way that they could bite the invaders. The Greeks maintained in their civilization an animistic idea that statues are in some sense alive. This kind of art and the animistic belief goes back to the Minoan period, when Daedalus, the builder of the labyrinth made images which moved of their own accord. A statue of the god was somehow the god himself, and the image on a man's tomb indicated somehow his presence.
Parentage.
Homer's "Odyssey" and "Iliad", as well as some Attic vase paintings, have Hephaestus being born of the union of Zeus and Hera. In another tradition, attested by Hesiod, Hera bore Hephaestus alone. In Hesiod's Zeus-centered cosmology, Hera gave birth to Hephaestus as revenge at Zeus for his asexual birthing of Athena. Several later texts follow Hesiod's account, including "Bibliotheke", Hyginus, and the preface to "Fabulae". However, in the account of Attic vase-painters, Hephaestus was present at the birth of Athena and wields the axe with which he split Zeus' head to free her. In the latter account, Hephaestus is there represented as older than Athena, so the mythology of Hephaestus is inconsistent in this respect.
Fall from Olympus.
In one branch of Greek mythology, Hera ejected Hephaestus from the heavens because he was "shrivelled of foot". He fell into the ocean and was raised by Thetis (mother of Achilles) and the Oceanid Eurynome.
In another account, Hephaestus, attempting to rescue his mother from Zeus' advances, was flung down from the heavens by Zeus. He fell for an entire day and landed on the island of Lemnos, where he was cared for and taught to be a master craftsman by the Sintians—an ancient tribe native to that island. (Hom. Il. i. 590, &c. Val. Flacc. ii. 8.5; Apollod. i. 3. § 5, who, however, confounds the two occasions on which Hephaestus was thrown from Olympus.) Later writers describe his lameness as the consequence of his second fall, while Homer makes him lame and weak from his birth.
Return to Olympus.
Hephaestus was the only Olympian to have returned to Olympus after being exiled.
In an archaic story, Hephaestus gained revenge against Hera for rejecting him by making her a magical golden throne, which, when she sat on it, did not allow her to stand up. The other gods begged Hephaestus to return to Olympus to let her go, but he refused, saying "I have no mother".
At last, Dionysus fetched him, intoxicated him with wine, and took the subdued smith back to Olympus on the back of a mule accompanied by revelers—a scene that sometimes appears on painted pottery of Attica and of Corinth. In the painted scenes, the padded dancers and phallic figures of the Dionysan throng leading the mule show that the procession was a part of the dithyrambic celebrations that were the forerunners of the satyr plays of fifth century Athens.
The theme of the "return of Hephaestus", popular among the Attic vase-painters whose wares were favored among the Etruscans, may have introduced this theme to Etruria. In the vase-painters' portrayal of the procession, Hephaestus was mounted on a mule or a horse, with Dionysus holding the bridle and carrying Hephaestus' tools (including a double-headed axe).
The traveller Pausanias reported seeing a painting in the temple of Dionysus in Athens, which had been built in the 5th century but may have been decorated at any time before the 2nd century CE. When Pausanias saw it, he said:
 There are paintings here – Dionysus bringing Hephaestus up to heaven. One of the Greek legends is that Hephaestus, when he was born, was thrown down by Hera. In revenge he sent as a gift a golden chair with invisible fetters. When Hera sat down she was held fast, and Hephaestus refused to listen to any other of the gods save Dionysus – in him he reposed the fullest trust – and after making him drunk Dionysus brought him to heaven.
 — Pausanias, 1.20.3
Consorts and children.
According to most versions, Hephaestus's consort is Aphrodite, who is unfaithful to Hephaestus with a number of gods and mortals, including Ares. However, in Homer's "Iliad", the consort of Hephaestus is a lesser Aphrodite, Charis "the grace" or Aglaia "the glorious"—the youngest of the Graces, as Hesiod calls her.
In Athens, there is a Temple of Hephaestus, the "Hephaesteum" (miscalled the "Theseum") near the agora. An Athenian founding myth tells that the city's patron goddess, Athena, refused a union with Hephaestus because of his unsightly appearance and crippled nature, and that when he became angry and forceful with her, she disappeared from the bed. His ejaculate fell on the earth, impregnating Gaia, who subsequently gave birth to Erichthonius of Athens. A surrogate mother later gave the child to Athena to foster, guarded by a serpent.
On the island of Lemnos, Hephaestus' consort was the sea nymph Cabeiro, by whom he was the father of two metalworking gods named the Cabeiri. In Sicily, his consort was the nymph Aetna, and his sons were two gods of Sicilian geysers called Palici. With Thalia, Hephaestus was sometimes considered the father of the Palici.
Hephaestus fathered several children with mortals and immortals alike. One of those children was the robber Periphetes.
This is the full list of his consorts and children according to the various accounts:
In addition, the Romans claim their equivalent god, Vulcan, to have produced the following children:
Hephaestus and Aphrodite.
Hephaestus, being the most unfaltering of the gods, was given Aphrodite’s hand in marriage by Zeus to prevent conflict over her between the other gods. The gods were fighting over her so much, they feared that they would lose their peace with one another and go to war on the other gods.
Hephaestus and Aphrodite had an arranged marriage, and Aphrodite, disliking the idea of being married to the unsightly Hephaestus, began an affair with Ares, the god of war. Eventually, Hephaestus discovered Aphrodite’s promiscuity through Helios, the all-seeing Sun, and planned a trap during one of their trysts. While Aphrodite and Ares lay together in bed, Hephaestus ensnared them in an unbreakable chain-link net so small as to be invisible and dragged them to Mount Olympus to shame them in front of the other gods for retribution.
However, the gods laughed at the sight of these naked lovers, and Poseidon persuaded Hephaestus to free them in return for a guarantee that Ares would pay the adulterer's fine. Hephaestus states in "The Odyssey" that he would return Aphrodite to her father and demand back his bride price.
The Thebans told that the union of Ares and Aphrodite produced Harmonia. However, of the union of Hephaestus with Aphrodite, there was no issue unless Virgil was serious when he said that Eros was their child. Later authors explain this statement by saying the love-god was sired by Ares but passed off to Hephaestus as his own son.
Hephaestus was somehow connected with the archaic, pre-Greek Phrygian and Thracian mystery cult of the Kabeiroi, who were also called the "Hephaistoi", "the Hephaestus-men", in Lemnos. One of the three Lemnian tribes also called themselves Hephaestion and claimed direct descent from the god.
Hephaestus and Athena.
Hephaestus is to the male gods as Athena is to the females, for he gives skill to mortal artists and was believed to have taught men the arts alongside Athena. He was nevertheless believed to be far inferior to the sublime character of Athena. At Athens they had temples and festivals in common. Both were believed to have great healing powers, and Lemnian earth (terra Lemnia) from the spot on which Hephaestus had fallen was believed to cure madness, the bites of snakes, and haemorrhage, and priests of Hephaestus knew how to cure wounds inflicted by snakes.
He was represented in the temple of Athena Chalcioecus (Athena of the Bronze House) at Sparta, in the act of delivering his mother; on the chest of Cypselus, giving Achilles's armour to Thetis; and at Athens there was the famous statue of Hephaestus by Alcamenes, in which his lameness was only subtly portrayed. The Greeks frequently placed small dwarf-like statues of Hephaestus near their hearths, and these figures are the oldest of all his representations. During the best period of Grecian art he was represented as a vigorous man with a beard, and is characterised by his hammer or some other crafting tool, his oval cap, and the chiton.
Volcano god.
Hephaestus was associated by Greek colonists in southern Italy with the volcano gods Adranus (of Mount Etna) and Vulcanus of the Lipari islands. The first-century sage Apollonius of Tyana is said to have observed, "there are many other mountains all over the earth that are on fire, and yet we should never be done with it if we assigned to them giants and gods like Hephaestus".
Other mythology.
In the Trojan war, Hephaestus sided with the Greeks, but was also worshipped by the Trojans and saved one of their men from being killed by Diomedes. (Il. v. 9, &c.) Hephaestus' favourite place in the mortal world was the island of Lemnos, where he liked to dwell among the Sintians (Od. viii. 283, &c., Il. i. 593; Ov Fast. viii. 82), but he also frequented other volcanic islands such as Lipara, Hiera, Imbros and Sicily, which were called his abodes or workshops. (Apollon. Rhod iii. 41; Callim. Hymn. in Dian. 47; Serv. ad Aen. viii. 416; Strab. p. 275; Plin. H. N. iii. 9; Val. Flacc. ii. 96.)
The epithets and surnames by which Hephaestus is known by the poets generally allude to his skill in the plastic arts or to his figure or lameness. The Greeks frequently placed small dwarf-like statues of Hephaestus near their hearths, and these figures are the oldest of all his representations. (Herod. iii. 37; Aristoph. Av. 436; Callim. Hymnn. in Dian. 60.)
Hephaestus was sometimes portrayed as a vigorous man with a beard, and was characterised by his hammer or some other crafting tool, his oval cap, and the chiton.
Symbolism.
Hephaestus is reported in mythological sources as "lame" (cholōs), and "halting" (ēpedanos).
He was depicted with crippled feet and as misshapen, either from birth or as a result of his fall from Olympus. In vase-paintings, Hephaestus is usually shown lame and bent over his anvil, hard at work on a metal creation, and sometimes with his feet back-to-front: "Hephaistos amphigyēeis". He walked with the aid of a stick. The Argonaut Palaimonius, "son of Hephaestus" (i.e. a bronze-smith) was also lame.
Other "sons of Hephaestus" were the Cabeiri on the island of Samothrace, who were identified with the crab ("karkinos") by the lexicographer Hesychius. The adjective "karkinopous" ("crab-footed") signified "lame", according to Detienne and Vernant. The Cabeiri were also lame.
In some myths, Hephaestus built himself a "wheeled chair" or chariot with which to move around, thus helping him overcome his lameness while demonstrating his skill to the other gods. In the "Iliad", it is said that Hephaestus built some bronze human machines in order to move around.
Hephaestus’s ugly appearance and lameness is taken by some to represent arsenicosis, an effect of low levels of arsenic exposure that would result in lameness and skin cancers. In place of less easily available tin, arsenic was added to copper in the Bronze Age to harden it; like the hatters, crazed by their exposure to mercury, who inspired Lewis Carroll's famous character of the Mad Hatter, most smiths of the Bronze Age would have suffered from chronic poisoning as a result of their livelihood. Consequently, the mythic image of the lame smith is widespread.
Comparative mythology.
Parallels in other mythological systems for Hephaestus's symbolism include:
Minor planet.
The minor planet 2212 Hephaistos discovered in 1978 by Soviet astronomer Lyudmila Chernykh was named in Hephaestus' honour.

</doc>
<doc id="14389" url="http://en.wikipedia.org/wiki?curid=14389" title="Herman Charles Bosman">
Herman Charles Bosman

Herman Charles Bosman (3 February 1905 – 14 October 1951) is widely regarded as South Africa's greatest short-story writer. He studied the works of Edgar Allan Poe and Mark Twain and developed a style emphasizing the use of satire. His English-language works utilize primarily Afrikaner characters and highlight the many contradictions in Afrikaner society during the first half of the twentieth century. The poet Roy Campbell called him "the only literary genius that South Africa has produced".
Early life.
Bosman was born at Kuils River, near Cape Town, to an Afrikaner family. He was raised with English as well as Afrikaans. While Bosman was still young, his family moved to Johannesburg where he went to school at Jeppe High School for Boys in Kensington. While there he contributed to the school magazine. When Bosman was sixteen, he started writing short stories for the national Sunday newspaper (the "Sunday Times"). He attended the Johannesburg College of Education (which in 2002 was incorporated into the University of the Witwatersrand) and submitted various pieces to student literary competitions.
Career and adult life.
After graduation, Bosman accepted a teaching position in the Groot Marico district in an Afrikaans-language school. The area and the people inspired him and provided the backdrop for his best-known short stories, the "Oom Schalk Lourens" series (featuring an older character named "Oom Schalk Lourens"), and the "Voorkamer" sketches.
Over the school holidays in 1926, Bosman visited his family in Johannesburg. During an argument, he shot and killed his stepbrother. Bosman was sentenced to death for the crime and was sent to Death row at the Pretoria Central Prison. But his sentence was later reduced to ten years with hard labour. In 1930 he was released on parole after serving half his sentence. His prison experiences formed the basis for his semi-autobiographical book, "Cold Stone Jug".
Bosman then started his own printing-press company and was part of a literary set in Johannesburg, associating with poets, journalists, and writers, including Aegidius Jean Blignaut. Needing a break, he then toured overseas for nine years, spending most of his time in London. The short stories that he wrote during this period formed the basis for another of his best-known books, "Mafeking Road".
At the start of the Second World War, he returned to South Africa and worked as a journalist. During this time he translated the Rubaiyat of Omar Khayyam into Afrikaans.
Bosman lamented the fact that Johannesburg neglected its heritage. In "The Standard Theatre" he complained that the city's residents:
"will pull down the Standard Theatre like they have pulled down all the old buildings, theatres, gin-palaces, dosshouses, temples, shops, arcades, cafes and joints that were intimately associated with the mining-camp days of Johannesburg. Because I know Johannesburg. And I am satisfied that there is no other city in the world that is so anxious to shake off the memories of its early origins."
Bosman's second wife was Ella Manson. The couple were renowned for their bohemian lifestyle and parties, which featured witty conversation and usually ended well after midnight.
From 1948 to his death in 1951 Bosman was employed as proof editor at The Sunday Express, but in addition he was contracted to write his weekly Voorkamer story for The Forum magazine.
His last wife was Helena Lake (née Stegmann). After a housewarming party in October 1951 Bosman experienced severe chest pains and was taken to Edenvale Hospital. On admission he was asked for his birthplace. He replied, "Born Kuilsrivier – Died Edenvale Hospital." He was discharged and collapsed at home a few hours later. Bosman died as he was being rushed to hospital. He is buried in Westpark Cemetery in Westdene under a triangular headstone that reads "Die Skrywer, The Writer, Herman Charles Bosman, b 3.2.1905, d 14.10.1951."
Legacy.
After his death, the rights to his works were auctioned. They were purchased by his last wife, Helena, and upon her death, the rights were passed to her son, who retains them. In 1960 however, Helena sold some of his documents and 123 of his water colours and pencil sketches to the Harry Ransom Center in Texas.
Only three of his books were published during his lifetime: "Mafeking Road" published by Dassie, and "Jacaranda in the Night" and "Cold Stone Jug" published by APB. "Mafeking Road" has never been out of print since its publication in 1947.
His biography was written several times by Valerie Rosenberg. Her first effort was called "Sunflower to the sun" ISBN 0-7981-1228-X (Human & Rousseau, 1976), followed by "Herman Charles Bosman, a Pictorial Biography" ISBN 0-628-02148-8 (Perskor, 1981), and most recently by "Herman Charles Bosman: Between the Lines" ISBN 1-77007-163-6 (Struik, 2005). The last of these contains much new research and deals in detail with aspects of Bosman's life and parentage that were previously considered taboo.
Because many of his stories were originally published in long-forgotten magazines and journals, there are a number of anthologies by different collators each containing a different selection. His original books have also been published many times by different publishers.
The Herman Charles Bosman Literary Society meets annually for readings, performances and discussions of his works.

</doc>
<doc id="14390" url="http://en.wikipedia.org/wiki?curid=14390" title="Hungarian">
Hungarian

Hungarian may refer to:

</doc>
<doc id="14392" url="http://en.wikipedia.org/wiki?curid=14392" title="Howitzer">
Howitzer

A howitzer is a type of artillery piece characterized by a relatively short barrel and the use of comparatively small propellant charges to propel projectiles at relatively high trajectories, with a steep angle of descent. 
In the taxonomies of artillery pieces used by European (and European-style) armies in the 17th, 18th, 19th, and 20th centuries, the howitzer stood between the "gun" (characterized by a longer barrel, larger propelling charges, smaller shells, higher velocities, and flatter trajectories) and the "mortar" (which was meant to fire at even higher angles of ascent and descent). Howitzers, like other artillery equipments, are usually organized in groups called batteries.
Etymology.
The English word "howitzer" comes from the Czech word "houfnice", from "houf", "crowd", and "houf" is in turn a borrowing from the Middle High German word "Hūfe" or "Houfe" (modern German "Haufen"), meaning "heap". "Haufen", sometimes in the compound "Gewalthaufen", also designated a pike square formation in German.
In the Hussite Wars of the 1420s and 1430s, the Czechs used short barreled "houfnice" cannons to fire at short distances into crowds of infantry, or into charging heavy cavalry, to make horses shy away. The word was rendered into German as "aufeniz" in the earliest attested use in a document dating from 1440; later German renderings include "haussnitz" and, eventually "haubitze", from which derive the Scandinavian "haubits", Bosnian, Croatian, Serbian "haubica", Finnish "haupitsi", Polish "haubica", Russian "gaubitsa", Italian "obice", Spanish "obús", Portuguese "obus", French "obusier" and the Dutch word "houwitser," which led to the English word "howitzer".
Since the First World War, the word "howitzer" has been increasingly used to describe artillery pieces that, strictly speaking, belong to the category of "gun-howitzers" - relatively long barrels and high muzzle velocities combined with multiple propelling charges and high maximum elevations. This is particularly true in the armed forces of the United States, where gun-howitzers have been officially described as "howitzers" for more than sixty years. Because of this practice, the word "howitzer" is used in some armies as a generic term for any kind of artillery piece that is designed to attack targets using indirect fire. Thus, artillery pieces that bear little resemblance to howitzers of earlier eras are now described as "howitzers", although the British call them "guns". Most other armies in the world reserve the word "howitzer" for guns with barrel lengths 15 to 25 times their caliber, longer-barreled guns being cannons.
The British had a further method of nomenclature. In the 18th century they adopted projectile weight for guns replacing the old naming system of culverin, saker, etc. that had developed in the late 15th century. Mortars had been categorized by calibre in inches in the 17th century and this was inherited by howitzers.
Current U.S. military doctrine defines howitzers as any cannon artillery capable of high-angle (45° to 90° elevation) and low angle (45° to 0° elevation) fire; guns are defined as being only capable of low-angle fire, and mortars only capable of high-angle fire.
History.
Early modern period.
The modern howitzers were invented in Sweden towards the end of the 17th century. These were characterized by a shorter trail than other field guns meaning less stability when firing, which reduced the amount of powder that could be used; armies using these had to rely on a greater elevation angle to achieve a given range, which gave a steeper angle of descent.
Originally intended for use in siege warfare, they were particularly useful for delivering cast-iron shells filled with gunpowder or incendiary materials into the interior of fortifications. In contrast to contemporary mortars, which were fired at a fixed angle and were entirely dependent upon adjustments to the size of propellant charges to vary range, howitzers could be fired at a wide variety of angles. Thus, while howitzer gunnery was more complicated than the technique of employing mortars, the howitzer was an inherently more flexible weapon that could fire its projectiles along a wide variety of trajectories.
In the middle of the 18th century a number of European armies began to introduce howitzers that were mobile enough to accompany armies in the field. Though usually fired at the relatively high angles of fire used by contemporary siege howitzers, these field howitzers were rarely defined by this capability. Rather, as the field guns of the day were usually restricted to inert projectiles (which relied entirely upon momentum for their destructive effects), the field howitzers of the 18th century were chiefly valued for their ability to fire explosive shells. Many, for the sake of simplicity and rapidity of fire, dispensed with adjustable propellant charges.
The Abus gun was an early form of howitzer in the Ottoman Empire. In 1758 the Russian Empire introduced a specific type of howitzer (or rather gun-howitzer), with a conical chamber, called a licorne, which remained in service for the next 100 years.
In the mid-19th century, some armies attempted to simplify their artillery parks by introducing smoothbore artillery pieces that were designed to fire both explosive projectiles and cannonballs, thereby replacing both field howitzers and field guns. The most famous of these "gun-howitzers" was the Napoleon 12-pounder, a weapon of French design that saw extensive service in the American Civil War. The longest-serving artillery piece of the 19th century was the mountain howitzer, which saw service from the War with Mexico to the Spanish–American War.
In 1859 the armies of Europe (including those that had recently adopted gun-howitzers) began to rearm field batteries with rifled field guns. These new field pieces used cylindrical projectiles that, while smaller in caliber than the spherical shells of smoothbore field howitzers, could carry a comparable charge of gunpowder. Moreover, their greater range let them create many of the same effects (such as firing over low walls) that previously required the sharply curved trajectories of smoothbore field howitzers. Because of this, military authorities saw no point in obtaining rifled field howitzers to replace their smoothbore counterparts but, instead, used rifled field guns to replace both guns and howitzers.
In siege warfare, the introduction of rifling had the opposite effect. In the 1860s, artillery officers discovered that rifled siege howitzers (substantially larger than field howitzers) were a more efficient means of destroying walls (particularly walls protected by certain kinds of intervening obstacles) than smoothbore siege guns or siege mortars. Thus, at the same time armies were taking howitzers of one sort out of their field batteries, they were introducing howitzers of another sort into their siege trains and fortresses. The lightest of these weapons (later known as "light siege howitzers") had calibers around 150 mm and fired shells that weighed between 40 and 50 kilograms. The heaviest (later called "medium siege howitzers") had calibers between 200 mm and 220 mm and fired shells that weighed about 100 kilograms (220 pounds).
In the Russo-Turkish War of 1877–1878 the inability of rifled field guns to inflict significant damage upon field fortifications led to a revival of interest in field howitzers. By the 1890s a number of European armies fielded either light (105 mm to 127 mm) or heavy (149 mm to 155 mm) field howitzers and a few, such as that of Germany, fielded both.
During the 1880s a third type of siege howitzer was added to inventories of a number of European armies. With calibers that ranged between 240 mm and 270 mm and shells that weighed more than 150 kilos, these soon came to be known as "heavy siege howitzers." A good example of a weapon of this class is provided by the 9.45-inch (240 mm) weapon that the British Army purchased from the Skoda works in 1899. Intended for use against the fortifications of Pretoria, which fell before the howitzer could be used, and subsequently deployed to China for use against the fortifications of Peking, which also fell without a siege, the 9.45 in howitzer was never fired in anger.
Twentieth century.
In the early 20th century the introduction of howitzers that were significantly larger than the heavy siege howitzers of the day made necessary the creation of a fourth category, that of "super-heavy siege howitzers". Weapons of this category include the famous Big Bertha of the German Army and the 15-inch (381 mm) howitzer of the Royal Marine Artillery. These large howitzers were transported mechanically rather than by teams of horses. They were transported as several loads and had to be assembled on their firing position.
These field howitzers introduced at the end of the 19th century could fire shells with high trajectories giving a steep angle of descent and, as a result, could strike targets that were protected by intervening obstacles. They could also fire shells that were about twice as large as shells fired by guns of the same size. Thus, while a 75 mm field gun that weighed one ton or so was limited to shells that weighed less than 8 kilograms, a 105 mm howitzer of the same weight could fire 15 kilogram shells. This is a matter of fundamental mechanics affecting the stability and hence the weight of the carriage. However, howitzers had a shorter maximum range than the equivalent gun.
As heavy field howitzers and light siege howitzers of the late 19th and early 20th centuries used ammunition of the same size and types, there was a marked tendency for the two types to merge. At first this was largely a matter of the same basic weapon being employed on two different mountings. Later, as on-carriage recoil-absorbing systems eliminated many of the advantages that siege platforms had enjoyed over field carriages, the same combination of barrel assembly, recoil mechanism and carriage was used in both roles.
By the early 20th century the differences between guns and howitzers were relative not absolute and generally recognized as follows:
The onset of trench warfare after the first few months of First World War greatly increased the demand for howitzers that gave a steep angle of descent, which were better suited than guns to the task of striking targets in a vertical plane (such as trenches), with large amounts of explosive and considerably less barrel wear. The German army was well equipped with howitzers, having far more at the beginning of the war than France.
Many howitzers introduced in the course of World War I had longer barrels than pre-war howitzers. The standard German light field howitzer at the start of the war (the 10.5 cm leichte Feldhaubitze 98/09) had a barrel that was 16 calibers long, but the light field howitzer adopted by the German Army in 1916 (105 mm leichte Feldhaubitze 16, see on the left) had a barrel that was 22 calibers long. At the same time, new models of field gun introduced during that conflict, such as the 77 mm field gun adopted by the German Army in 1916 (7,7 cm Feldkanone 16) were often provided with carriages that allowed firing at comparatively high angles, and adjustable propellant cartridges. In other words, there was a marked tendency for howitzers to become more "gun-like" while guns were taking on some of the attributes of howitzers.
In the years after World War I, the tendency of guns and howitzers to acquire each other's characteristics led to the renaissance of the concept of the gun-howitzer. This was a product of technical advances such as the French invention of autofrettage just before World War I, which led to stronger and lighter barrels, the use of cut-off gear to control recoil length depending on firing elevation angle, and the invention of muzzle brakes to reduce recoil forces. Like the gun-howitzers of the 19th century, those of the 20th century replaced both guns and howitzers.
Thus, the 25-pounder "gun-howitzer" of the British Army replaced both the 18-pounder field gun and the 4.5-inch howitzer. While this had the effect of simplifying such things as organization, training and the supply of ammunition, it created considerable confusion in the realm of nomenclature. In the US Army, however, the preferred term was "howitzer". Thus, as gun-howitzers replaced both guns and howitzers, words such as "obusier" (French) and "Haubitze" (German), which had originally been used to designate weapons with relatively short barrels, were applied to weapons with much longer barrels.
During World War II, the military doctrine of Soviet deep battle called for extensive use of heavy artillery to hold the formal line of front. Soviet doctrine was remarkably different from the German doctrine of Blitzkrieg, and called for a far more extensive use of artillery. As a result, howitzers saw most of the action on Eastern front, and most of the best howitzers of WWII period were Soviet-made, as other allies mostly relied on different types of assault for the battle. Most of the howitzers produced by the USSR at the time were not self-propelled, as the country did not have resources to spare for the construction of the engines for the self-propelled variants.
Notable example of Soviet howitzers include M-10, M-30 and D-1. As Soviet howitzers were deployed a lot more than comparable Allied or Axis guns, they often had worse paper characteristics that were deliberately sacrificed to improve operational performance and the usability of the artillery pieces by the deployed troops.
Since World War II most of the artillery pieces adopted by land armies for attacking targets on land have combined the traditional characteristics of guns and howitzers—high muzzle velocity, long barrels, long range, multiple charges and maximum elevation angles greater than 45 degrees. The term "gun-howitzer" is sometimes used for these (e.g., in Russia); many nations use "howitzer" while the UK (and most members of The Commonwealth of Nations) calls them "guns", see, for example Gun, 105mm, Field, L118.

</doc>
<doc id="14395" url="http://en.wikipedia.org/wiki?curid=14395" title="Hummer">
Hummer

Hummer was a brand of trucks and SUVs, first marketed in 1992 when AM General began selling a civilian version of the M998 Humvee. In 1998, General Motors (GM) purchased the brand name and marketed three vehicles: the original Hummer H1, based on the military Humvee, as well as the H2 and H3 models that were based on smaller, civilian-market GM platforms.
By 2008, Hummer's viability in the economic downturn was being questioned, and it was placed under review by GM management. Rather than being transferred to Motors Liquidation Company as part of the GM bankruptcy in 2009, the brand was retained by GM, in order to investigate its sale.
In 2009, a Chinese manufacturer, Sichuan Tengzhong Heavy Industrial Machinery Company, announced that it would acquire Hummer, pending government approvals, but later withdrew its bid. On February 24, 2010, Reuters reported that the Chinese ministry of commerce had prevented the deal, although a ministry spokesperson denied rejecting the application, which had been stalled for eight months. At the end of February, General Motors announced it would begin dismantling the Hummer brand.
Although the automaker announced two days later that it had been approached with new offers, by April 2010, any sale became unlikely, as inventory was depleted and Hummer dealerships began shutting down. After filling a rental-car fleet order, the last Hummer H3 rolled off the line at Shreveport on May 24, 2010.
History.
Origin.
The original Hummers were first designed by AM General Corporation, a wholly owned subsidiary of American Motors Corporation (AMC), and built in its Mishawaka, Indiana, assembly plant. In 1979, the United States Army was seeking contractors for a new "High Mobility Multi-Purpose Wheeled Vehicle" which could follow the tracks and ruts of full size army trucks (HMMWV). Among the four competitors for the contract, AM General designed an entirely new vehicle to meet the Army's requirements. In less than one year, it was the first to deliver a prototype vehicle. Initial production versions were delivered to the Army's proving grounds in April 1982.
After testing was completed AM General was awarded the contract to supply its HMMWV to the United States armed forces. The first models were built in a variety of military-based equipment and versions. The first contract was in 1983, worth US$1.2 billion to produce 55,000 "Humvees" by 1985. The first production vehicle was assembled by AM General on January 2, 1985. The contract was later increased for an additional 15,000 units.
AM General had planned to sell a civilian version of the Humvee as far back as the late-1980s. Having the same structure and most mechanical components, the civilian Hummers were finished in automotive gloss paint, adding passenger car enhancements such as air conditioning, sound insulation, upgraded upholstery, stereo systems, wood trim, and convenience packages. The civilian model began in part because of the persistence of Arnold Schwarzenegger, who saw an Army convoy while filming a movie.
In 1992, AM General began selling a civilian version of the M998 Humvee vehicle to the public under the brand name "Hummer".
GM purchase.
In December 1999, AM General sold the brand name to General Motors, but continued to manufacture the vehicles. GM was responsible for the marketing and distribution of all Hummers produced by AM General. Shortly thereafter, GM introduced two of its own design models, the H2 and H3, and renamed the original vehicle H1. AM General continued to build the H1 until it was discontinued in 2006, and was contracted by GM to produce the H2. The H3 was built in Shreveport, LA alongside the Chevrolet Colorado and GMC Canyon pickups, with which it shared the GMT-355 platform (modified and designated GMT-345). Hummer dealership buildings featured an over sized half Quonset Hut style roof, themed to the Hummer brand's military origins.
By 2006, the Hummer began to be exported and sold through importers and distributors in 33 countries. On October 10, 2006, GM began producing the Hummer H3 at its Port Elizabeth plant in South Africa for international markets. The Hummers built there at first were only left-hand drive, but right-hand drive versions were added and exported to Australia and other markets.
The H2 was also assembled in Kaliningrad, Russia, by Avtotor, starting in 2006 and ending in 2009. The plant produced a few hundred vehicles annually, and its output was limited to local consumption with five dealers in Russia.
On June 3, 2008, one day prior to GM's annual shareholder meeting, Rick Wagoner, GM's CEO at that time, said the brand was being reviewed, and had the possibility of either being sold, having the production line completely redesigned, or being discontinued. This was due to the decreasing demand for large SUVs as a result of higher oil prices. Almost immediately after the announcement, a pair of Indian automakers, including Mahindra & Mahindra, expressed interest in purchasing all or part of Hummer.
In April 2009, GM President Fritz Henderson stated several interested parties had approached GM regarding the Hummer business.
Failed sale.
On June 1, 2009, as a part of the General Motors bankruptcy announcement, the company revealed that the Hummer brand would be discontinued. However, the following day GM announced that instead it had reached a deal to sell the brand to an undisclosed buyer. After GM announced that same day that the sale was to an undisclosed Chinese company, CNN and the New York Times identified the buyer of the Hummer truck unit as China-based Sichuan Tengzhong Heavy Industrial Machinery Company Ltd. Later that day, Sichuan Tengzhong itself announced the deal on their own website.
On January 6, 2010, GM CEO Ed Whitacre said he hoped to close the deal with Tengzhong by the end of that month. On February 1, 2010, it was announced that Sichuan and General Motors had agreed to extend the deadline until the end of February as Sichuan tried to get approval by the Chinese government. It was also revealed that the price tag of the Hummer brand was $150 million.
Later, on February 24, 2010, GM announced the Tengzhong deal had collapsed and the Hummer brand would soon shut down. There were reports that Sichuan Tengzhong might pursue the purchase of the Hummer brand from GM by purchasing it privately through the company's new J&A Tengzhong Fund SPC, a private equity investment fund owned by an offshore entity that was recruiting private investors to buy into its acquisition plan. The financial markets posed problems for established borrowers and even more for Tengzhong, a little-known company from western China, at the same time as the potential value of the Hummer brand continued to decline given high fuel prices and weak consumer demand.
The company announced it was willing to consider offers for all or part of the assets. American company Raser Technologies along with several others expressed interest in buying the company. However, on April 7, 2010, this attempt failed as well, and General Motors officially said it was shutting down the Hummer SUV brand and offering rich rebates in a bid to move the remaining 2,200 vehicles.
Models.
Hummer H1.
The first vehicle in the Hummer range was the Hummer H1, based on the Humvee. Originally released in 1992, this vehicle was designed by American Motors' AM General subsidiary for the U.S. Military. Five years previously, AMC had been bought by Chrysler.
Hummer H2.
The Hummer H2 was the second vehicle in the Hummer range. There were two variations: The H2 SUV and H2 SUT.
Hummer H3.
The H3 and H3T truck were the smallest of the Hummer models and were based on the GMT355 platform shared with the Chevrolet Colorado and GMC Canyon compact pickup trucks.
Concept vehicles.
Hummer HX.
The Hummer HX was developed in 2008 as an open-air, two-door off-road concept car, smaller than other Hummer models.
Plug-in hybrid.
Raser Technologies (formerly of Utah) was to use technology similar to that in the Chevrolet Volt. The company unveiled the prototype to the 2009 Society of Automotive Engineers World Congress in Detroit. The E-REV (Extended-Range Electric Vehicle) powertrain technology, was claimed to power the vehicle for up to 40 mi on its battery, and then a small 4-cylinder internal combustion engine would start to generate more electricity.
Racing.
Team Hummer Racing was created in 1993. Led by off-road racer Rod Hall, Team Hummer competed in the stock classes of both BitD and SCORE, with specialized racing shock absorbers, tires, and other modifications, along with mandatory safety equipment. Team Hummer stock-class H3 driven by Hall finished first in class with the H3 in the 2005 Baja 1000. Team Hummer earned 11 production-class wins at the Baja 1000.
A highly modified, two-wheel drive Hummer was raced by Robby Gordon in the 2006 (did not finish), 2007 (8th place), 2009 (3rd place), 2010 (8th place), 2011 (did not finish), 2012 (disqualified), and 2013 (14th place) Dakar Rally.
Criticisms.
Criticism of Hummers mirrors the criticism of SUVs in general, but to a higher degree. Specific criticisms of Hummers include:
Licensing.
GM had been active in licensing the Hummer. Various companies had licensed the Hummer trademarks for use on colognes, flashlights, bicycles, shoes, coats, hats, laptops, toys, clothing, CD players, and other items. An electric quadricycle badged as a Hummer is currently[ [update]] produced in the UK.

</doc>
<doc id="14396" url="http://en.wikipedia.org/wiki?curid=14396" title="Humvee">
Humvee

The High Mobility Multipurpose Wheeled Vehicle (HMMWV), commonly known as the Humvee, is a four-wheel drive military automobile produced by AM General. It has largely supplanted the roles originally performed by the original jeep, and newer Military light utility vehicles such as the Vietnam-era M151 1/4 ton, the M561 "Gama Goat", their M718A1 and M792 ambulance versions, the CUCV, and other light trucks. Primarily used by the United States military, it is also used by numerous other countries and organizations and even in civilian adaptations. The Humvee's widespread use in the Persian Gulf War, where it negotiated the treacherous desert sand with ease, helped inspire the civilian Hummer automotive marque.
History.
Since the WWII era Bantam Reconnaissance Car, the United States Army had relied on jeeps to transport small groups of soldiers. The jeep was built around a requirement for a compact vehicle with a folding windshield that was actually shorter than the Volkswagen Beetle. It seated three with a 660 lb payload and weighed just over one ton. By the 1970s, the U.S. Army had tried larger militarized civilian trucks, but even these no longer satisfied newer requirements. In 1977, Lamborghini developed the Cheetah model in an attempt to meet the Army contract specifications.
In 1979, the U.S. Army drafted final specifications for a High Mobility Multipurpose Wheeled Vehicle, or HMMWV, which was to replace all the tactical vehicles in the 1/4 to 1 1/4-ton range, namely the M151 and M561 Gamma Goat, as one "jack-of-all-trades" light tactical vehicle to perform the role of several existing trucks. The specification called for excellent on and off-road performance, the ability to carry a large payload, and improved survivability against indirect fire. Compared to the jeep, it was larger and had a much wider track, with a 16 in ground clearance, double that of most sport-utility vehicles. The new truck was to climb a 60 percent incline and traverse a 40 percent slope. The air intake was to be mounted flush on top of the right fender (or to be raised on a stovepipe to roof level to ford 5 ft of water and electronics waterproofed to drive through 2.5 ft of water were specified. The radiator was to be mounted high, sloping over the engine on a forward-hinged hood.
Out of 61 companies that showed interest, only three submitted prototypes. In July 1979, AM General (a subsidiary of American Motors Corporation) began preliminary design work. Less than a year later, the first prototype was in testing; Chrysler Defense and Teledyne Continental also produced competing designs. In June 1981, the Army awarded AM General a contract for development of several more prototype vehicles to be delivered to the government for another series of tests. The original M998 A0 series had a curb weight of 5200 lb. with a payload of 2500 lbs, with a 6.2 L V-8 diesel engine and a three-speed automatic transmission.
The three companies were chosen to design and build eleven HMMWV prototypes, which covered over 600,000 miles in trials which included off-road courses in desert and arctic conditions. AM General was awarded an initial contract in 1983 for 2,334 vehicles, the first batch of a five-year contract that would see 55,000 vehicles delivered to the U.S. military, including 39,000 for the Army; 72,000 vehicles had been delivered to U.S. and foreign customers by the 1991 Gulf War, and 100,000 were delivered by the Humvee's 10th anniversary in 1995. Ft. Lewis, Washington and the 9th Infantry Division was the testing unit to employ HMMWV in the new concept of a motorized division. Yakima Training Center in Yakima, Washington was the main testing grounds for HMMWVs from 1985 through December 1991, when the motorized concept was abandoned and the division inactivated.
Usage in combat.
HMMWVs first saw combat in Operation Just Cause, the U.S. invasion of Panama in 1989.
The HMMWV was designed primarily for personnel and light cargo transport behind front lines, not as a front line fighting vehicle. Like the previous jeep, the basic HMMWV has no armor or protection against chemical, biological, radiological or nuclear threats. Nevertheless, losses were relatively low in conventional operations, such as the Gulf War. Vehicles and crews suffered considerable damage and losses during the Battle of Mogadishu due to the nature of the urban engagement; however, the chassis survivability allowed the majority of those crews to return to safety, though the HMMWV was never designed to offer protection against intense small arms fire, much less machine guns and rocket-propelled grenades. However, with the rise of asymmetric warfare and low intensity conflicts, the HMMWV was pressed into service in urban combat roles for which it was not originally intended.
After Somalia, the military recognized a need for a more protected HMMWV and AM General developed the M1114, an armored HMMWV to withstand small arms fire. The M1114 has been in limited production since 1996, seeing limited use in the Balkans before deployment to the Middle East. This design is superior to the M998 with a larger, more powerful turbocharged engine, air conditioning, and a strengthened suspension system. More importantly, it boasts a fully armored passenger area protected by hardened steel and bullet-resistant glass. With the increase in direct attacks and guerrilla warfare in Iraq, AM General diverted the majority of its manufacturing power to producing these vehicles.
Humvees were sent into Afghanistan following the 9/11 terrorist attacks, where they proved invaluable during initial operations. In the early years before IEDs became prevalent, the vehicle was liked by troops for its ability to access rough, mountainous terrain. Some soldiers would remove features from Humvees, including what little armor it had and sometimes even entire doors, to make them lighter and more maneuverable for off-road conditions and to increase visibility. With the onset of the Iraq War, Humvees proved very vulnerable to IEDs; in the first four months of 2006, 67 U.S. troops died in Humvees. To increase protection, the U.S. military hastily added-on armor kits to the vehicles. Although this somewhat improved survivability, bolting on armor made the Humvee an "ungainly beast," increasing weight and putting strain on the chassis, which lead to unreliability. Armored doors that weighed hundreds of pounds were difficult for troops to open and the newly armored turret made Humvees top heavy and increased the danger of rollovers. The U.S. Marine Corps decided to start replacing Humvees in combat with MRAPs in 2007, and the U.S. Army stated that the vehicle was "no longer feasible for combat" in 2012.
The HMMWV has become the vehicular backbone of U.S. forces around the world. Over 10,000 HMMWVs were employed by coalition forces during the Iraq War. The Humvee has been described as "the right capability for its era" to provide payload mobility in protected areas, but that conflicts exposing it to full-spectrum threat environments that it was never designed to operate or be survivable in led to adding protection at the cost of mobility and payload.
Modifications.
In December 2004, Secretary of Defense Donald Rumsfeld came under criticism from U.S. troops and their families for not providing better-equipped HMMWVs. Rumsfeld pointed out that, prior to the war, armor kits were produced only in small numbers per year. As the role of American forces in Iraq changed from fighting the Iraqi Army to suppressing the guerrilla insurgency, more armor kits were being manufactured, though perhaps not as fast as production facilities were capable of bringing them online. Even more advanced kits were also being developed. However, while these kits are much more effective against all types of attacks, they weigh between 1500 to and have some of the same drawbacks as the improvised armor. Unlike similar-size civilian cargo and tow trucks, which typically have dual rear wheels to reduce sway, the HMMWV has single rear wheels due to its independent rear suspension coupled with the body design.
Most up-armored HMMWVs hold up well against lateral attacks, when the blast is distributed in all different directions, but offers little protection from a mine blast below the truck, such as buried improvised explosive devices (IEDs) and land mines. Explosively formed penetrators (EFPs) can also defeat the armor kits, causing casualties.
The armor kits fielded include the Armor Survivability Kit (ASK), the FRAG 5, FRAG 6, as well as upgrade kits to the M1151. The ASK was the first fielded, in October 2003, adding about 1000 lb to the weight of the vehicle. Armor Holdings fielded an even lighter kit, adding only 750 lb to the vehicle's weight. The Marine Armor Kit (MAK), fielded in January 2005, offers more protection than the M1114, but also increases weight. The FRAG 5 offered even more protection but was still inadequate to stop EFP attacks. The FRAG 6 kit is designed to do just that, however its increased protection adds over 1,000 lb the vehicle over the FRAG 5 kit, and the width is increased by 2 ft. In addition, the doors may require a mechanical assist device to open and close.
Another drawback of the up-armored HMMWVs occurs during an accident or attack, when the heavily armored doors tend to jam shut, trapping the troops inside. As a result, HMMWVs were fitted with hooks on their doors, so that another vehicle can rip the door off, freeing the troops inside. In addition, Vehicle Emergency Escape (VEE) windows, developed by BAE Systems, were fielded for use on the M1114 uparmored HMMWV, with 1,000 kits ordered.
The soldier manning the exposed crew-served weapon on top of the vehicle is extremely vulnerable. In response, many HMMWVs have been fitted with basic gun shields or turrets, as was the case with M113 APCs after they were first deployed in Vietnam. The U.S. military is currently evaluating a new form of protection, developed by BAE Systems as well as systems designed by the Army, which are already in theater. The new gunner's seat is protected by 1.5 to high steel plates with bullet-proof glass windows. Additionally, some HMMWVs have been fitted with a remotely operated CROWS weapon station, which slaves the machine gun to controls in the back seat so it can be fired without exposing the crew. The Boomerang anti-sniper system was also fielded by some HMMWVs in Iraq to immediately give troops the location of insurgents firing on them.
Another weakness for the HMMWV has proven to be its size, which limited its deployment in Afghanistan because it is too wide for the smallest roads and too large for many forms of air transport compared to jeep or Land Rover-sized vehicles (which are nearly two feet narrower). This size also limits the ability for the vehicle to be manhandled out of situations.
Alternatives.
The Army purchased a purpose-built armored car, the M1117 Armored Security Vehicle, in limited numbers for use by the United States Army Military Police Corps. In 2007, the Marine Corps announced an intention to replace all HMMWVs in Iraq with MRAPs due to high loss rates, and issued contracts for the purchase of several thousand of these vehicles, which include the International MaxxPro, the BAE OMC RG-31, the BAE RG-33 and Caiman, and the Force Protection Cougar, which were deployed primarily for mine clearing duties. Heavier models of infantry mobility vehicles (IMV) can also be used for patrol vehicles. The MaxxPro Line has been shown to have the highest rate of vehicle rollover accidents to its very high center of gravity and immense weight. The massive weight of these vehicles combined with their high center of gravity also greatly reduces their utility in off-road situations versus the HMMWV, which was the primary cause for the push for the Oshkosh M-ATV to be developed quickly.
Future and replacement.
The Humvee replacement process, now being undertaken by the U.S. military, is focused on interim replacement with MRAPs and long-term replacement with the Joint Light Tactical Vehicle (JLTV). The HMMWV has evolved several times since its introduction, and is now used in tactical roles for which it was never originally intended. The military is pursuing several initiatives to replace it, both in the short and long terms. The short term replacement efforts utilize commercial off-the-shelf vehicles as part of the Mine Resistant Ambush Protected (MRAP) program. These vehicles are procured to replace Humvees in combat theaters. The long term replacement for the Humvee is the Joint Light Tactical Vehicle which is designed from the ground up. The Future Tactical Truck Systems (FTTS) program was initiated to make an analysis of potential requirements for a Humvee replacement. Various prototype vehicles such as the MillenWorks Light Utility Vehicle, and the ULTRA AP have been constructed as part of these efforts.
The U.S. Marine Corps issued a request for proposals (RFP) in 2013 for its Humvee sustainment modification initiative to upgrade 6,700 expanded capacity vehicles (ECVs). The Marines plan to field the Joint Light Tactical Vehicle, but do not have enough funding to completely replace all Humvees, so they decided to continue sustaining their fleet. Key areas of improvement include the suspension, engine, and transmission. Upgrades to the suspension would reduce the amount of force transferred to the chassis, lowering operation and maintenance costs. Additionally, upgrades to the engine and transmission would help to make the vehicles more fuel efficient, and enhancements to the cooling system will better prevent overheating. The Marine Corps is also looking at incorporating a central tire inflation system to allow for reduced tire pressures during off-road use to improve mobility and ride quality. They are also seeking to increase the underbody survivability. Testing of upgraded Humvees was to occur in 2014, with production and installation occurring from 2015 through 2018. Older A2 series Humvees make up half the current fleet, and 4,000 are to be disposed of through foreign military sales and transfers. By 2017, the Marines' light tactical vehicle fleet is to consist of 3,500 A2 series Humvees, 9,500 ECV Humvees, and 5,000 JLTVs, with 18,000 vehicles in total. Humvees in service with the Marine Corps will be upgraded through 2030. The Marines shelved the Humvee modernization effort in March 2015 due to budget cuts.
The U.S. Army and Marine Corps have vowed commitment to buying nearly 55,000 JLTVs even in the face of sequestration cuts. This level of support is given while major acquisition programs like the Ground Combat Vehicle were in danger of cuts (and eventually cancelled), which potentially meant the Army favored replacing Humvees more than the M2 Bradley. How many light vehicles that will need to be reduced are still being determined, but they are hoped to direct the effects to the existing Humvee fleet.
Several companies are offering modifications to maintain the remaining U.S. military Humvee fleets. Oshkosh Corporation is offering Humvee upgrades to the Marine Corps in addition to its JLTV offering, which are modular and scalable solutions providing varying levels of capabilities at a range of price points that can be provided individually or as complete solutions. Their approach is centered around the TAK-4 independent suspension system, which delivers greater off-road profile capability, improved ride quality, an increase in maximum speed, greater whole-vehicle durability, and restored payload capacity and ground clearance. They also can deliver a modern engine option that’s more powerful than the Humvee’s stock engine and provides increased fuel efficiency. In October 2014, Northrop Grumman unveiled a new chassis and power train for the Humvee that would combine the mobility and payload capabilities of original vehicle variants while maintaining the protection levels of up-armored versions. The new chassis increases fuel efficiency to 18 miles per gallon and allows the vehicle to accelerate to 66 mph in 22 seconds; the upgrade also includes a new dashboard, suspension, hydraulics, and central tire inflation systems. The company has installed the new chassis on four Humvees through a cooperative agreement with the Army, two of which have been delivered for trials. The cost to upgrade one Humvee with Northrop Grumman's features is $145,000. Textron has offered another Humvee upgrade option called the Survivable Combat Tactical Vehicle (SCTV) that not only restores mobility but improves survivability over armored Humvee levels. It was developed as a blast protected cab solution with a stronger frame and suspension with underbody armor and the ability to mount additional B-kit armor. It has a larger engine and transmission to power an increased gross vehicle weight of 18,500 lb, greater ground clearance, larger brakes, wheels, and tires, and additional headroom from an improved internal layout. The battery pack was moved, as was the fuel tank, which is also enlarged and better armored. It is available in four-door, two-door, ambulance, nine-seat troop carrier, and other variants. Although the SCTV costs more at $200,000 per vehicle, the company claims it can restore the Humvee for operational use, combining Humvee-level mobility and transportability with MRAP-level underbody protection, as a transitionary solution until the JLTV is introduced in significant numbers; both the Army and Marines have acquired about half a dozen vehicles each for testing.
One suggested future role for the Humvee is as an autonomous unmanned ground vehicle (UGV). If converted to a UGV, the vehicle could serve as a mobile scout vehicle with armor features removed to enhance mobility and terrain accessibility, since there would be no occupants needed to protect. Because there will still be tens of thousands of Humvees in the U.S. inventory after the JLTV enters service, it could be a low-cost way to build an unmanned combat vehicle fleet. Autonomy features would allow the Humvees to drive themselves and one soldier to control a "swarm" of several vehicles.
Design features.
The Humvee seats 4 with an available fully enclosed metal cabin with a vertical windshield. The body is constructed from lightweight and rust-resistant aluminum, instead of conventional steel. It has all-wheel drive with an independent suspension and helical gear-reduction hubs similar to portal axles which attach towards the top rather than center of each wheel to allow the drivetrain shafts to be raised for a full 16 in of ground clearance. The body is mounted on a narrow steel frame with boxed rails and five cross members for rigidity. The rails act as sliders to protect the drivetrain which is nestled between and above the rails. Raising the drivetrain into the cabin area and lowering the seats into the frame creates a massive chest-high transmission hump which separates passengers on each side and lowers the overall center of gravity compared to most trucks where the body and passengers are above the frame. The vehicle also has disc brakes on all 4 wheels, and 4-wheel double-wishbone suspension. The brake discs are not mounted at the wheels as on conventional automobiles, but are inboard, attached to the outside of each differential. The front and rear differentials are Torsen type, and the center differential is a regular, lockable type. Torque-biasing differentials allows forward movement as long as at least one wheel has traction. It runs on specialized 37 x 12.5 radial tires with low-profile runflat devices. Some HMMWVs are equipped with an optional central tire inflation system (CTIS), which enables pressure to be lowered for soft ground or raised for hard pavement. While it is optimized for off-road mobility, it can drive at highway speeds of 55 mph at maximum weight with a top speed of 70 mph.
HMMWVs are well suited for air mobile operations as they are transportable by C-130 or larger combat transports, droppable by parachute, and can be sling-loaded from helicopters, though there are smaller vehicles such as the Growler which were designed to fit into smaller craft such as the V-22. In combat conditions, the HMMWV can be delivered by the Low Altitude Parachute Extraction System which pulls the vehicle out of the open rear ramp just above the ground without the aircraft having to land.
There are at least 17 variants of the HMMWV in service with the U.S. military. HMMWVs serve as cargo/troop carriers, automatic weapons platforms, ambulances (four litter patients or eight ambulatory patients), M220 TOW missile carriers, M119 howitzer prime movers, M1097 Avenger Pedestal Mounted Stinger platforms, MRQ-12 direct air support vehicles, S250 shelter carriers, and other roles. The HMMWV is capable of 2.5 ft (76 cm) normally, or 5 ft (1.5 m) with the deep-water fording kits installed.
Optional equipment includes a winch (maximum load capacity 6000 lbs and supplemental armor. The M1025/M1026 and M1043/M1044 armament carriers provide mounting and firing capabilities for the M134 Minigun, the Mk 19 grenade launcher, the M2 heavy machine gun, the M240G/B machine gun and M249 LMG.
The M1114 "up-armored" HMMWV, introduced in 2004, also features a similar weapons mount. In addition, some M1114 and M1116 up-armored and M1117 Armored Security Vehicle models feature a Common Remotely Operated Weapon Station (CROWS), which allows the gunner to operate from inside the vehicle, and/or the Boomerang anti-sniper detection system. Recent improvements have also led to the development of the M1151 model, which is quickly rendering the previous models obsolete. By replacing the M1114, M1116, and earlier armored HMMWV types with a single model, the U.S. Army hopes to lower maintenance costs.
The latest iteration of the Humvee series can be seen in the M1151A1 and later up-armored A1-versions. It has a stronger suspension and larger 6.5 liter turbo-diesel engine to accommodate the weight of up to 680 kg of additional armor. The armor protection can be installed or taken off depending on the operating environment, so the vehicles can move more efficiently without armor when there is no threat of attack. There is some underbody armor that moderately protects against mines and roadside bombs. Other improvements include Vehicle Emergency Escape (VEE) windows that can be quickly removed so troops inside can escape in the event of a rollover, jammed door, or the vehicle catching fire, and a blast chimney that vents the force of a bomb blast upwards and away from the occupants. The M1151A1 has a crew of four, can carry 2,000 lb of payload, and can tow a 4,000 lb load. On roads, it has a top speed of 80 km/h and a range of 480 km.
Versions.
Expanded capacity.
The M1113 has been selected by the U.S. Army as its A2 chassis for HMMWV purchases. Currently, the ECV is used for special operations vehicles and communications shelter carriers.
During 1995, production of the M1114 based on the improved ECV chassis began. The M1114 meets Army requirements for a scout, military police, and explosive ordnance disposal vehicle with improved ballistic protection levels. The M1114 provides protection against 7.62 mm armor-piercing projectiles, 155 mm artillery air bursts and 12 lb anti-tank mine blasts. The U.S. Air Force has a number of these vehicles under the designation M1116, specifically designed to meet the requirements of the Air Force. The M1116 features an expanded cargo area, armored housing for the turret gunner, and increased interior heating and air conditioning system. The M1114 and M1116 receive armor at O'Gara-Hess & Eisenhardt Armoring Company of Fairfield, Ohio. The M1145 offers the protection of the M1114 and M1116 for Air Force Air Support Operations Squadrons (ASOS). Modifications include perimeter ballistic protection, overhead burst protection, IED protection, mine blast protection, and 'white glass' transparent armor. These extended capacity HMMWVs can drive over an 18 in vertical wall and carry a 6820 lb payload.
Operators.
Civilian sales.
In December 2014, the Department of Defense began auctioning off some 4,000 used Humvees to the public. While some have been transferred to domestic law enforcement agencies, this is the first time the military vehicles have been made available for civilian ownership. The idea is to sell them with starting bids at $10,000 each, for off-road use only, rather than simply scrapping them as a way to save money and repurpose them. M908, M908A1, M1038, and M1038A1 model Humvees are available, which are out of U.S. service and lack armor. AM General has been opposed to resale of military Humvees to the general public, primarily because surplus government vehicles would cut into sales related to the civilian Hummer model. The first sales from auction occurred on 17 December 2014 for 25 of the Humvees. Bids ranged from $21,500 for a 1989 M1038 to $41,000 for a 1994 AM General M998A1. The average bid was around $30,000 and the sale of the 25 vehicles netted $744,000 total. AM General works with American dealer company; Humvee Export LLC to distribute modified civilian Humvees called the Humvee C-Series across the globe.
Replicas.
Kits have been produced for the general market to turn a sedan into a Humvee lookalike. An alternative is to buy a preconstructed (or "turnkey") wombat. Various kits exist, but one of the most famous names is the Volkswagen Beetle-based "Wombat" (previously called a "HummBug", until the threat of a lawsuit from General Motors forced them to change both the name and the design of the grill to make it look less like the real thing ). It can be purchased/built for about US$18,000; this puts it considerably cheaper than the actual HMMWV ($56,000), or Hummer. In Australia, a Gold Coast-based company called Rhino Buggies produces replicas of the Hummer H1 based on the Nissan Patrol 4WD vehicle for around A$30,000.

</doc>
<doc id="14400" url="http://en.wikipedia.org/wiki?curid=14400" title="History of science">
History of science

The history of science is the study of the development of science and scientific knowledge, including both the natural sciences and social sciences. (The history of the arts and humanities is termed as the history of scholarship.) Science is a body of empirical, theoretical, and practical knowledge about the natural world, produced by scientists who emphasize the observation, explanation, and prediction of real world phenomena. Historiography of science, in contrast, often draws on the historical methods of both intellectual history and social history.
The English word "scientist" is relatively recent—first coined by William Whewell in the 19th century. Previously, people investigating nature called themselves natural philosophers. While empirical investigations of the natural world have been described since classical antiquity (for example, by Thales, Aristotle, and others), and scientific methods have been employed since the Middle Ages (for example, by Ibn al-Haytham, and Roger Bacon), the dawn of modern science is often traced back to the early modern period and in particular to the scientific revolution that took place in 16th- and 17th-century Europe. Scientific methods are considered to be so fundamental to modern science that some consider earlier inquiries into nature to be "pre-scientific". Traditionally, historians of science have defined science sufficiently broadly to include those inquiries.
From the 18th century through late 20th century, the history of science, especially of the physical and biological sciences, was often presented in a progressive narrative in which true theories replaced false beliefs. More recent historical interpretations, such as those of Thomas Kuhn, tend to portray the history of science in different terms, such as that of competing paradigms or conceptual systems in a wider matrix that includes intellectual, cultural, economic and political themes outside of science.
Early cultures.
In prehistoric times, advice and knowledge was passed from generation to generation in an oral tradition. For example, the domestication of maize for agriculture has been dated to about 9,000 years ago in southern Mexico, before the development of writing systems. Similarly, archaeological evidence indicates the development of astronomical knowledge in preliterate societies.
The development of writing enabled knowledge to be stored and communicated across generations with much greater fidelity. Combined with the development of agriculture, which allowed for a surplus of food, it became possible for early civilizations to develop, because more time could be devoted to tasks other than survival.
Many ancient civilizations collected astronomical information in a systematic manner through simple observation. Though they had no knowledge of the real physical structure of the planets and stars, many theoretical explanations were proposed. Basic facts about human physiology were known in some places, and alchemy was practiced in several civilizations. Considerable observation of macrobiotic flora and fauna was also performed.
Ancient Near East.
From their beginnings in Sumer (now Iraq) around 3500 BC, the Mesopotamian people began to attempt to record some observations of the world with numerical data. But their observations and measurements were seemingly taken for purposes other than for scientific laws. A concrete instance of Pythagoras' law was recorded, as early as the 18th century BC: the Mesopotamian cuneiform tablet Plimpton 322 records a number of Pythagorean triplets (3,4,5) (5,12,13). ..., dated 1900 BC, possibly millennia before Pythagoras, but an abstract formulation of the Pythagorean theorem was not.
In Babylonian astronomy, records of the motions of the stars, planets, and the moon are left on thousands of clay tablets created by scribes. Even today, astronomical periods identified by Mesopotamian scientists are still widely used in Western calendars such as the solar year and the lunar month. Using these data they developed arithmetical methods to compute the changing length of daylight in the course of the year and to predict the appearances and disappearances of the Moon and planets and eclipses of the Sun and Moon. Only a few astronomers' names are known, such as that of Kidinnu, a Chaldean astronomer and mathematician. Kiddinu's value for the solar year is in use for today's calendars. Babylonian astronomy was "the first and highly successful attempt at giving a refined mathematical description of astronomical phenomena." According to the historian A. Aaboe, "all subsequent varieties of scientific astronomy, in the Hellenistic world, in India, in Islam, and in the West—if not indeed all subsequent endeavour in the exact sciences—depend upon Babylonian astronomy in decisive and fundamental ways."
Ancient Egypt made significant advances in astronomy, mathematics and medicine. Their development of geometry was a necessary outgrowth of surveying to preserve the layout and ownership of farmland, which was flooded annually by the Nile river. The 3-4-5 right triangle and other rules of thumb were used to build rectilinear structures, and the post and lintel architecture of Egypt. Egypt was also a center of alchemy research for much of the Mediterranean.
The Edwin Smith papyrus is one of the first medical documents still extant, and perhaps the earliest document that attempts to describe and analyse the brain: it might be seen as the very beginnings of modern neuroscience. However, while Egyptian medicine had some effective practices, it was not without its ineffective and sometimes harmful practices. Medical historians believe that ancient Egyptian pharmacology, for example, was largely ineffective. Nevertheless, it applies the following components to the treatment of disease: examination, diagnosis, treatment, and prognosis, which display strong parallels to the basic empirical method of science and according to G. E. R. Lloyd played a significant role in the development of this methodology. The Ebers papyrus (c. 1550 BC) also contains evidence of traditional empiricism.
Greco-Roman world.
In Classical Antiquity, the inquiry into the workings of the universe took place both in investigations aimed at such practical goals as establishing a reliable calendar or determining how to cure a variety of illnesses and in those abstract investigations known as natural philosophy. The ancient people who are considered the first "scientists" may have thought of themselves as "natural philosophers", as practitioners of a skilled profession (for example, physicians), or as followers of a religious tradition (for example, temple healers).
The earliest Greek philosophers, known as the pre-Socratics, provided competing answers to the question found in the myths of their neighbors: "How did the ordered cosmos in which we live come to be?" The pre-Socratic philosopher Thales (640-546 BC), dubbed the "father of science", was the first to postulate non-supernatural explanations for natural phenomena, for example, that land floats on water and that earthquakes are caused by the agitation of the water upon which the land floats, rather than the god Poseidon. Thales' student Pythagoras of Samos founded the Pythagorean school, which investigated mathematics for its own sake, and was the first to postulate that the Earth is spherical in shape. Leucippus (5th century BC) introduced atomism, the theory that all matter is made of indivisible, imperishable units called atoms. This was greatly expanded by his pupil Democritus.
Subsequently, Plato and Aristotle produced the first systematic discussions of natural philosophy, which did much to shape later investigations of nature. Their development of deductive reasoning was of particular importance and usefulness to later scientific inquiry. Plato founded the Platonic Academy in 387 BC, whose motto was "Let none unversed in geometry enter here", and turned out many notable philosophers. Plato's student Aristotle introduced empiricism and the notion that universal truths can be arrived at via observation and induction, thereby laying the foundations of the scientific method. Aristotle also produced many biological writings that were empirical in nature, focusing on biological causation and the diversity of life. He made countless observations of nature, especially the habits and attributes of plants and animals in the world around him, classified more than 540 animal species, and dissected at least 50. Aristotle's writings profoundly influenced subsequent Islamic and European scholarship, though they were eventually superseded in the Scientific Revolution.
The important legacy of this period included substantial advances in factual knowledge, especially in anatomy, zoology, botany, mineralogy, geography, mathematics and astronomy; an awareness of the importance of certain scientific problems, especially those related to the problem of change and its causes; and a recognition of the methodological importance of applying mathematics to natural phenomena and of undertaking empirical research. In the Hellenistic age scholars frequently employed the principles developed in earlier Greek thought: the application of mathematics and deliberate empirical research, in their scientific investigations. Thus, clear unbroken lines of influence lead from ancient Greek and Hellenistic philosophers, to medieval Muslim philosophers and scientists, to the European Renaissance and Enlightenment, to the secular sciences of the modern day.
Neither reason nor inquiry began with the Ancient Greeks, but the Socratic method did, along with the idea of Forms, great advances in geometry, logic, and the natural sciences. According to Benjamin Farrington, former Professor of Classics at Swansea University:
and again:
The astronomer Aristarchus of Samos was the first known person to propose a heliocentric model of the solar system, while the geographer Eratosthenes accurately calculated the circumference of the Earth. Hipparchus (c. 190 – c. 120 BC) produced the first systematic star catalog. The level of achievement in Hellenistic astronomy and engineering is impressively shown by the Antikythera mechanism (150-100 BC), an analog computer for calculating the position of planets. Technological artifacts of similar complexity did not reappear until the 14th century, when mechanical astronomical clocks appeared in Europe.
In medicine, Hippocrates (c. 460 BC – c. 370 BC) and his followers were the first to describe many diseases and medical conditions and developed the Hippocratic Oath for physicians, still relevant and in use today. Herophilos (335–280 BC) was the first to base his conclusions on dissection of the human body and to describe the nervous system. Galen (129 – c. 200 AD) performed many audacious operations—including brain and eye surgeries— that were not tried again for almost two millennia.
In Hellenistic Egypt, the mathematician Euclid laid down the foundations of mathematical rigor and introduced the concepts of definition, axiom, theorem and proof still in use today in his "Elements", considered the most influential textbook ever written. Archimedes, considered one of the greatest mathematicians of all time, is credited with using the method of exhaustion to calculate the area under the arc of a parabola with the summation of an infinite series, and gave a remarkably accurate approximation of Pi. He is also known in physics for laying the foundations of hydrostatics, statics, and the explanation of the principle of the lever.
Theophrastus wrote some of the earliest descriptions of plants and animals, establishing the first taxonomy and looking at minerals in terms of their properties such as hardness. Pliny the Elder produced what is one of the largest encyclopedias of the natural world in 77 AD, and must be regarded as the rightful successor to Theophrastus. For example, he accurately describes the octahedral shape of the diamond, and proceeds to mention that diamond dust is used by engravers to cut and polish other gems owing to its great hardness. His recognition of the importance of crystal shape is a precursor to modern crystallography, while mention of numerous other minerals presages mineralogy. He also recognises that other minerals have characteristic crystal shapes, but in one example, confuses the crystal habit with the work of lapidaries. He was also the first to recognise that amber was a fossilized resin from pine trees because he had seen samples with trapped insects within them.
India.
Mathematics: The earliest traces of mathematical knowledge in the Indian subcontinent appear with the Indus Valley Civilization (c. 4th millennium BC ~ c. 3rd millennium BC). The people of this civilization made bricks whose dimensions were in the proportion 4:2:1, considered favorable for the stability of a brick structure. They also tried to standardize measurement of length to a high degree of accuracy. They designed a ruler—the "Mohenjo-daro ruler"—whose unit of length (approximately 1.32 inches or 3.4 centimetres) was divided into ten equal parts. Bricks manufactured in ancient Mohenjo-daro often had dimensions that were integral multiples of this unit of length.
Indian astronomer and mathematician Aryabhata (476-550), in his "Aryabhatiya" (499) introduced a number of trigonometric functions (including sine, versine, cosine and inverse sine), trigonometric tables, and techniques and algorithms of algebra. In 628 AD, Brahmagupta suggested that gravity was a force of attraction. He also lucidly explained the use of zero as both a placeholder and a decimal digit, along with the Hindu-Arabic numeral system now used universally throughout the world. Arabic translations of the two astronomers' texts were soon available in the Islamic world, introducing what would become Arabic numerals to the Islamic World by the 9th century. During the 14th–16th centuries, the Kerala school of astronomy and mathematics made significant advances in astronomy and especially mathematics, including fields such as trigonometry and analysis. In particular, Madhava of Sangamagrama is considered the "founder of mathematical analysis".
Astronomy: The first textual mention of astronomical concepts comes from the Vedas, religious literature of India. According to Sarma (2008): "One finds in the Rigveda intelligent speculations about the genesis of the universe from nonexistence, the configuration of the universe, the spherical self-supporting earth, and the year of 360 days divided into 12 equal parts of 30 days each with a periodical intercalary month.". The first 12 chapters of the "Siddhanta Shiromani", written by Bhāskara in the 12th century, cover topics such as: mean longitudes of the planets; true longitudes of the planets; the three problems of diurnal rotation; syzygies; lunar eclipses; solar eclipses; latitudes of the planets; risings and settings; the moon's crescent; conjunctions of the planets with each other; conjunctions of the planets with the fixed stars; and the patas of the sun and moon. The 13 chapters of the second part cover the nature of the sphere, as well as significant astronomical and trigonometric calculations based on it.
Nilakantha Somayaji's astronomical treatise the Tantrasangraha similar in nature to the Tychonic system proposed by Tycho Brahe had been the most accurate astronomical model until the time of Johannes Kepler in the 17th century.
Linguistics: Some of the earliest linguistic activities can be found in Iron Age India (1st millennium BC) with the analysis of Sanskrit for the purpose of the correct recitation and interpretation of Vedic texts. The most notable grammarian of Sanskrit was Pāṇini (c. 520–460 BC), whose grammar formulates close to 4,000 rules which together form a compact generative grammar of Sanskrit. Inherent in his analytic approach are the concepts of the phoneme, the morpheme and the root.
Medicine: Findings from Neolithic graveyards in what is now Pakistan show evidence of proto-dentistry among an early farming culture. Ayurveda is a system of traditional medicine that originated in ancient India before 2500 BC, and is now practiced as a form of alternative medicine in other parts of the world. Its most famous text is the Suśrutasamhitā of Suśruta, which is notable for describing procedures on various forms of surgery, including rhinoplasty, the repair of torn ear lobes, perineal lithotomy, cataract surgery, and several other excisions and other surgical procedures.
Metallurgy: The wootz, crucible and stainless steels were discovered in India, and were widely exported in Classic Mediterranean world. It was known from Pliny the Elder as "ferrum indicum". Indian Wootz steel was held in high regard in Roman Empire, was often considered to be the best. After in Middle Age it was imported in Syria to produce with special techniques the "Damascus steel" by the year 1000.
The Hindus excel in the manufacture of iron, and in the preparations of those ingredients along with which it is fused to obtain that kind of soft iron which is usually styled Indian steel (Hindiah). They also have workshops wherein are forged the most famous sabres in the world.
China.
Mathematics: From the earliest the Chinese used a positional decimal system on counting boards in order to calculate. To express 10, a single rod is placed in the second box from the right. The spoken language uses a similar system to English: e.g. four thousand two hundred seven. No symbol was used for zero. By the 1st century BC, negative numbers and decimal fractions were in use and "The Nine Chapters on the Mathematical Art" included methods for extracting higher order roots by Horner's method and solving linear equations and by Pythagoras' theorem. Cubic equations were solved in the Tang dynasty and solutions of equations of order higher than 3 appeared in print in 1245 AD by Ch'in Chiu-shao. Pascal's triangle for binomial coefficients was described around 1100 by Jia Xian.
Although the first attempts at an axiomatisation of geometry appear in the Mohist canon in 330 BC, Liu Hui developed algebraic methods in geometry in the 3rd century AD and also calculated pi to 5 significant figures. In 480, Zu Chongzhi improved this by discovering the ratio formula_1 which remained the most accurate value for 1200 years.
Astronomy: Astronomical observations from China constitute the longest continuous sequence from any civilisation and include records of sunspots (112 records from 364 BC), supernovas (1054), lunar and solar eclipses. By the 12th century, they could reasonably accurately make predictions of eclipses, but the knowledge of this was lost during the Ming dynasty, so that the Jesuit Matteo Ricci gained much favour in 1601 by his predictions.
By 635 Chinese astronomers had observed that the tails of comets always point away from the sun.
From antiquity, the Chinese used an equatorial system for describing the skies and a star map from 940 was drawn using a cylindrical (Mercator) projection. The use of an armillary sphere is recorded from the 4th century BC and a sphere permanently mounted in equatorial axis from 52 BC. In 125 AD Zhang Heng used water power to rotate the sphere in real time. This included rings for the meridian and ecliptic. By 1270 they had incorporated the principles of the Arab torquetum.
Seismology: To better prepare for calamities, Zhang Heng invented a seismometer in 132 CE which provided instant alert to authorities in the capital Luoyang that an earthquake had occurred in a location indicated by a specific cardinal or ordinal direction. Although no tremors could be felt in the capital when Zhang told the court that an earthquake had just occurred in the northwest, a message came soon afterwards that an earthquake had indeed struck 400 km (248 mi) to 500 km (310 mi) northwest of Luoyang (in what is now modern Gansu). Zhang called his device the 'instrument for measuring the seasonal winds and the movements of the Earth' (Houfeng didong yi 候风地动仪), so-named because he and others thought that earthquakes were most likely caused by the enormous compression of trapped air. See Zhang's seismometer for further details.
There are many notable contributors to the field of Chinese science throughout the ages. One of the best examples would be Shen Kuo (1031–1095), a polymath scientist and statesman who was the first to describe the magnetic-needle compass used for navigation, discovered the concept of true north, improved the design of the astronomical gnomon, armillary sphere, sight tube, and clepsydra, and described the use of drydocks to repair boats. After observing the natural process of the inundation of silt and the find of marine fossils in the Taihang Mountains (hundreds of miles from the Pacific Ocean), Shen Kuo devised a theory of land formation, or geomorphology. He also adopted a theory of gradual climate change in regions over time, after observing petrified bamboo found underground at Yan'an, Shaanxi province. If not for Shen Kuo's writing, the architectural works of Yu Hao would be little known, along with the inventor of movable type printing, Bi Sheng (990-1051). Shen's contemporary Su Song (1020–1101) was also a brilliant polymath, an astronomer who created a celestial atlas of star maps, wrote a pharmaceutical treatise with related subjects of botany, zoology, mineralogy, and metallurgy, and had erected a large astronomical clocktower in Kaifeng city in 1088. To operate the crowning armillary sphere, his clocktower featured an escapement mechanism and the world's oldest known use of an endless power-transmitting chain drive.
The Jesuit China missions of the 16th and 17th centuries "learned to appreciate the scientific achievements of this ancient culture and made them known in Europe. Through their correspondence European scientists first learned about the Chinese science and culture." Western academic thought on the history of Chinese technology and science was galvanized by the work of Joseph Needham and the Needham Research Institute. Among the technological accomplishments of China were, according to the British scholar Needham, early seismological detectors (Zhang Heng in the 2nd century), the water-powered celestial globe (Zhang Heng), matches, the independent invention of the decimal system, dry docks, sliding calipers, the double-action piston pump, cast iron, the blast furnace, the iron plough, the multi-tube seed drill, the wheelbarrow, the suspension bridge, the winnowing machine, the rotary fan, the parachute, natural gas as fuel, the raised-relief map, the propeller, the crossbow, and a solid fuel rocket, the multistage rocket, the horse collar, along with contributions in logic, astronomy, medicine, and other fields.
However, cultural factors prevented these Chinese achievements from developing into what we might call "modern science". According to Needham, it may have been the religious and philosophical framework of Chinese intellectuals which made them unable to accept the ideas of laws of nature:
It was not that there was no order in nature for the Chinese, but rather that it was not an order ordained by a rational personal being, and hence there was no conviction that rational personal beings would be able to spell out in their lesser earthly languages the divine code of laws which he had decreed aforetime. The Taoists, indeed, would have scorned such an idea as being too naïve for the subtlety and complexity of the universe as they intuited it.
Science in the Middle Ages.
With the division of the Roman Empire, the Western Roman Empire lost contact with much of its past. In the Middle East, Greek philosophy was able to find some support under the newly created Arab Empire. With the spread of Islam in the 7th and 8th centuries, a period of Muslim scholarship, known as the Islamic Golden Age, lasted until the 13th century. This scholarship was aided by several factors. The use of a single language, Arabic, allowed communication without need of a translator. Access to Greek texts from the Byzantine Empire, along with Indian sources of learning, provided Muslim scholars a knowledge base to build upon. 
While the Byzantine Empire still held learning centers such as Constantinople, Western Europe's knowledge was concentrated in monasteries until the development of medieval universities in the 12th and 13th centuries. The curriculum of monastic schools included the study of the few available ancient texts and of new works on practical subjects like medicine and timekeeping.
Islamic world.
Muslim scientists placed far greater emphasis on experiment than had the Greeks. This led to an early scientific method being developed in the Muslim world, where significant progress in methodology was made, beginning with the experiments of Ibn al-Haytham (Alhazen) on optics from c. 1000, in his "Book of Optics". The law of refraction of light
was known to the Persians. The most important development of the scientific method was the use of experiments to distinguish between competing scientific theories set within a generally empirical orientation, which began among Muslim scientists. Ibn al-Haytham is also regarded as the father of optics, especially for his empirical proof of the intromission theory of light. Some have also described Ibn al-Haytham as the "first scientist" for his development of the modern scientific method.
In mathematics, the Persian mathematician Muhammad ibn Musa al-Khwarizmi gave his name to the concept of the algorithm, while the term algebra is derived from "al-jabr", the beginning of the title of one of his publications. What is now known as Arabic numerals originally came from India, but Muslim mathematicians did make several refinements to the number system, such as the introduction of decimal point notation. Sabian mathematician Al-Battani (850-929) contributed to astronomy and mathematics, while Persian scholar Al-Razi contributed to chemistry and medicine.
In astronomy, Al-Battani improved the measurements of Hipparchus, preserved in the translation of Ptolemy's "Hè Megalè Syntaxis" ("The great treatise") translated as "Almagest". Al-Battani also improved the precision of the measurement of the precession of the Earth's axis. The corrections made to the geocentric model by al-Battani, Ibn al-Haytham, Averroes and the Maragha astronomers such as Nasir al-Din al-Tusi, Mo'ayyeduddin Urdi and Ibn al-Shatir are similar to Copernican heliocentric model. Heliocentric theories may have also been discussed by several other Muslim astronomers such as Ja'far ibn Muhammad Abu Ma'shar al-Balkhi, Abu-Rayhan Biruni, Abu Said al-Sijzi, Qutb al-Din al-Shirazi, and Najm al-Dīn al-Qazwīnī al-Kātibī.
Muslim chemists and alchemists played an important role in the foundation of modern chemistry. Scholars such as Will Durant and Fielding H. Garrison considered Muslim chemists to be the founders of chemistry. In particular, Jābir ibn Hayyān is "considered by many to be the father of chemistry". The works of Arabic scientists influenced Roger Bacon (who introduced the empirical method to Europe, strongly influenced by his reading of Persians writers), and later Isaac Newton.
Ibn Sina (Avicenna) is regarded as the most influential philosopher of Islam. He pioneered the science of experimental medicine and was the first physician to conduct clinical trials. His two most notable works in medicine are the "Kitāb al-shifāʾ" ("Book of Healing") and The Canon of Medicine, both of which were used as standard medicinal texts in both the Muslim world and in Europe well into the 17th century. Amongst his many contributions are the discovery of the contagious nature of infectious diseases, and the introduction of clinical pharmacology.
Some of the other famous scientists from the Islamic world include al-Farabi (polymath), Abu al-Qasim al-Zahrawi (pioneer of surgery), Abū Rayhān al-Bīrūnī (pioneer of Indology, geodesy and anthropology), Nasīr al-Dīn al-Tūsī (polymath), and Ibn Khaldun (forerunner of social sciences such as demography, cultural history, historiography, philosophy of history and sociology), among many others.
Islamic science began its decline in the 12th or 13th century, before the Renaissance in Europe, and due in part to the 11th–13th century Mongol conquests, during which libraries, observatories, hospitals and universities were destroyed. The end of the Islamic Golden Age is marked by the destruction of the intellectual center of Baghdad, the capital of the Abbasid caliphate in 1258.
Europe.
An intellectual revitalization of Europe started with the birth of medieval universities in the 12th century. The contact with the Islamic world in Spain and Sicily, and during the Reconquista and the Crusades, allowed Europeans access to scientific Greek and Arabic texts, including the works of Aristotle, Ptolemy, Jābir ibn Hayyān, al-Khwarizmi, Alhazen, Avicenna, and Averroes. European scholars had access to the translation programs of Raymond of Toledo, who sponsored the 12th century Toledo School of Translators from Arabic to Latin. Later translators like Michael Scotus would learn Arabic in order to study these texts directly. The European universities aided materially in the translation and propagation of these texts and started a new infrastructure which was needed for scientific communities. In fact, European university put many works about the natural world and the study of nature at the center of its curriculum, with the result that the "medieval university laid far greater emphasis on science than does its modern counterpart and descendent."
As well as this, Europeans began to venture further and further east (most notably, perhaps, Marco Polo) as a result of the Pax Mongolica. This led to the increased awareness of Indian and even Chinese culture and civilization within the European tradition. Technological advances were also made, such as the early flight of Eilmer of Malmesbury (who had studied Mathematics in 11th century England), and the metallurgical achievements of the Cistercian blast furnace at Laskill.
At the beginning of the 13th century, there were reasonably accurate Latin translations of the main works of almost all the intellectually crucial ancient authors, allowing a sound transfer of scientific ideas via both the universities and the monasteries. By then, the natural philosophy contained in these texts began to be extended by notable scholastics such as Robert Grosseteste, Roger Bacon, Albertus Magnus and Duns Scotus. Precursors of the modern scientific method, influenced by earlier contributions of the Islamic world, can be seen already in Grosseteste's emphasis on mathematics as a way to understand nature, and in the empirical approach admired by Bacon, particularly in his "Opus Majus". Pierre Duhem's provocative thesis of the Catholic Church's Condemnation of 1277 led to the study of medieval science as a serious discipline, "but no one in the field any longer endorses his view that modern science started in 1277". However, many scholars agree with Duhem's view that the Middle Ages were a period of important scientific developments.
The first half of the 14th century saw much important scientific work being done, largely within the framework of scholastic commentaries on Aristotle's scientific writings. William of Ockham introduced the principle of parsimony: natural philosophers should not postulate unnecessary entities, so that motion is not a distinct thing but is only the moving object and an intermediary "sensible species" is not needed to transmit an image of an object to the eye. Scholars such as Jean Buridan and Nicole Oresme started to reinterpret elements of Aristotle's mechanics. In particular, Buridan developed the theory that impetus was the cause of the motion of projectiles, which was a first step towards the modern concept of inertia. The Oxford Calculators began to mathematically analyze the kinematics of motion, making this analysis without considering the causes of motion.
In 1348, the Black Death and other disasters sealed a sudden end to the previous period of massive philosophic and scientific development. Yet, the rediscovery of ancient texts was improved after the Fall of Constantinople in 1453, when many Byzantine scholars had to seek refuge in the West. Meanwhile, the introduction of printing was to have great effect on European society. The facilitated dissemination of the printed word democratized learning and allowed a faster propagation of new ideas. New ideas also helped to influence the development of European science at this point: not least the introduction of Algebra. These developments paved the way for the Scientific Revolution, which may also be understood as a resumption of the process of scientific inquiry, halted at the start of the Black Death.
Impact of science in Europe.
The renewal of learning in Europe, that began with 12th century Scholasticism, came to an end about the time of the Black Death, and the initial period of the subsequent Italian Renaissance is sometimes seen as a lull in scientific activity. The Northern Renaissance, on the other hand, showed a decisive shift in focus from Aristoteleian natural philosophy to chemistry and the biological sciences (botany, anatomy, and medicine). Thus modern science in Europe was resumed in a period of great upheaval: the Protestant Reformation and Catholic Counter-Reformation; the discovery of the Americas by Christopher Columbus; the Fall of Constantinople; but also the re-discovery of Aristotle during the Scholastic period presaged large social and political changes. Thus, a suitable environment was created in which it became possible to question scientific doctrine, in much the same way that Martin Luther and John Calvin questioned religious doctrine. The works of Ptolemy (astronomy) and Galen (medicine) were found not always to match everyday observations. Work by Vesalius on human cadavers found problems with the Galenic view of anatomy.
The willingness to question previously held truths and search for new answers resulted in a period of major scientific advancements, now known as the Scientific Revolution. The Scientific Revolution is traditionally held by most historians to have begun in 1543, when the books "De humani corporis fabrica" ("On the Workings of the Human Body") by Andreas Vesalius, and also "De Revolutionibus", by the astronomer Nicolaus Copernicus, were first printed. The thesis of Copernicus' book was that the Earth moved around the Sun. The period culminated with the publication of the "Philosophiæ Naturalis Principia Mathematica" in 1687 by Isaac Newton, representative of the unprecedented growth of scientific publications throughout Europe.
Other significant scientific advances were made during this time by Galileo Galilei, Edmond Halley, Robert Hooke, Christiaan Huygens, Tycho Brahe, Johannes Kepler, Gottfried Leibniz, and Blaise Pascal. In philosophy, major contributions were made by Francis Bacon, Sir Thomas Browne, René Descartes, and Thomas Hobbes. The scientific method was also better developed as the modern way of thinking emphasized experimentation and reason over traditional considerations.
Age of Enlightenment.
The Age of Enlightenment was a European affair. The 17th century "Age of Reason" opened the avenues to the decisive steps towards modern science, which took place during the 18th century "Age of Enlightenment". Directly based on the works of Newton, Descartes, Pascal and Leibniz, the way was now clear to the development of modern mathematics, physics and technology
by the generation of Benjamin Franklin (1706–1790), Leonhard Euler (1707–1783), Mikhail Lomonosov (1711–1765) and Jean le Rond d'Alembert (1717–1783), epitomized in the appearance of Denis Diderot's "Encyclopédie" between 1751 and 1772. The impact of this process was not limited to science and technology, but affected philosophy (Immanuel Kant, David Hume), religion (the increasingly significant impact of science upon religion), and society and politics in general (Adam Smith, Voltaire), the French Revolution of 1789 setting a bloody cesura indicating the beginning of political modernity. The early modern period is seen as a flowering of the European Renaissance, in what is often known as the Scientific Revolution, viewed as a foundation of modern science.
Romanticism in science.
The Romantic Movement of the early 19th century reshaped science by opening up new pursuits unexpected in the classical approaches of the Enlightenment. Major breakthroughs came in biology, especially in Darwin's theory of evolution, as well as physics (electromagnetism), mathematics (non-Euclidean geometry, group theory) and chemistry (organic chemistry). The decline of Romanticism occurred because a new movement, Positivism, began to take hold of the ideals of the intellectuals after 1840 and lasted until about 1880.
Modern science.
The Scientific Revolution established science as a source for the growth of knowledge. During the 19th century, the practice of science became professionalized and institutionalized in ways that continued through the 20th century. As the role of scientific knowledge grew in society, it became incorporated with many aspects of the functioning of nation-states.
The history of science is marked by a chain of advances in technology and knowledge that have always complemented each other. Technological innovations bring about new discoveries and are bred by other discoveries, which inspire new possibilities and approaches to longstanding science issues.
Natural sciences.
Physics.
The Scientific Revolution is a convenient boundary between ancient thought and classical physics. Nicolaus Copernicus revived the heliocentric model of the solar system described by Aristarchus of Samos. This was followed by the first known model of planetary motion given by Kepler in the early 17th century, which proposed that the planets follow elliptical orbits, with the Sun at one focus of the ellipse. Galileo ("Father of Modern Physics") also made use of experiments to validate physical theories, a key element of the scientific method.
In 1687, Isaac Newton published the "Principia Mathematica", detailing two comprehensive and successful physical theories: Newton's laws of motion, which led to classical mechanics; and Newton's Law of Gravitation, which describes the fundamental force of gravity. The behavior of electricity and magnetism was studied by Faraday, Ohm, and others during the early 19th century. These studies led to the unification of the two phenomena into a single theory of electromagnetism, by James Clerk Maxwell (known as Maxwell's equations).
The beginning of the 20th century brought the start of a revolution in physics. The long-held theories of Newton were shown not to be correct in all circumstances. Beginning in 1900, Max Planck, Albert Einstein, Niels Bohr and others developed quantum theories to explain various anomalous experimental results, by introducing discrete energy levels. Not only did quantum mechanics show that the laws of motion did not hold on small scales, but even more disturbingly, the theory of general relativity, proposed by Einstein in 1915, showed that the fixed background of spacetime, on which both Newtonian mechanics and special relativity depended, could not exist. In 1925, Werner Heisenberg and Erwin Schrödinger formulated quantum mechanics, which explained the preceding quantum theories. The observation by Edwin Hubble in 1929 that the speed at which galaxies recede positively correlates with their distance, led to the understanding that the universe is expanding, and the formulation of the Big Bang theory by Georges Lemaître.
In 1938 Otto Hahn and Fritz Strassmann discovered nuclear fission with radiochemical methods, and 1939 Lise Meitner and Otto Robert Frisch wrote the first theoretical interpretation of the fission process, which was later improved by Niels Bohr and John A. Wheeler. Further developments took place during World War II, which led to the practical application of radar and the development and use of the atomic bomb. Though the process had begun with the invention of the cyclotron by Ernest O. Lawrence in the 1930s, physics in the postwar period entered into a phase of what historians have called "Big Science", requiring massive machines, budgets, and laboratories in order to test their theories and move into new frontiers. The primary patron of physics became state governments, who recognized that the support of "basic" research could often lead to technologies useful to both military and industrial applications. Currently, general relativity and quantum mechanics are inconsistent with each other, and efforts are underway to unify the two.
Chemistry.
Modern chemistry emerged from the sixteenth through the eighteenth centuries through the material practices and theories promoted by alchemy, medicine, manufacturing and mining. A decisive moment came when 'chymistry' was distinguished from alchemy by Robert Boyle in his work "The Sceptical Chymist", in 1661; although the alchemical tradition continued for some time after his work. Other important steps included the gravimetric experimental practices of medical chemists like William Cullen, Joseph Black, Torbern Bergman and Pierre Macquer and through the work of Antoine Lavoisier ("Father of Modern Chemistry") on oxygen and the law of conservation of mass, which refuted phlogiston theory. The theory that all matter is made of atoms, which are the smallest constituents of matter that cannot be broken down without losing the basic chemical and physical properties of that matter, was provided by John Dalton in 1803, although the question took a hundred years to settle as proven. Dalton also formulated the law of mass relationships. In 1869, Dmitri Mendeleev composed his periodic table of elements on the basis of Dalton's discoveries.
The synthesis of urea by Friedrich Wöhler opened a new research field, organic chemistry, and by the end of the 19th century, scientists were able to synthesize hundreds of organic compounds. The later part of the 19th century saw the exploitation of the Earth's petrochemicals, after the exhaustion of the oil supply from whaling. By the 20th century, systematic production of refined materials provided a ready supply of products which provided not only energy, but also synthetic materials for clothing, medicine, and everyday disposable resources. Application of the techniques of organic chemistry to living organisms resulted in physiological chemistry, the precursor to biochemistry. The 20th century also saw the integration of physics and chemistry, with chemical properties explained as the result of the electronic structure of the atom. Linus Pauling's book on "The Nature of the Chemical Bond" used the principles of quantum mechanics to deduce bond angles in ever-more complicated molecules. Pauling's work culminated in the physical modelling of DNA, "the secret of life" (in the words of Francis Crick, 1953). In the same year, the Miller–Urey experiment demonstrated in a simulation of primordial processes, that basic constituents of proteins, simple amino acids, could themselves be built up from simpler molecules.
Geology.
Geology existed as a cloud of isolated, disconnected ideas about rocks, minerals, and landforms long before it became a coherent science. Theophrastus' work on rocks, "Peri lithōn", remained authoritative for millennia: its interpretation of fossils was not overturned until after the Scientific Revolution. Chinese polymath Shen Kua (1031–1095) first formulated hypotheses for the process of land formation. Based on his observation of fossils in a geological stratum in a mountain hundreds of miles from the ocean, he deduced that the land was formed by erosion of the mountains and by deposition of silt.
Geology did not undergo systematic restructuring during the Scientific Revolution, but individual theorists made important contributions. Robert Hooke, for example, formulated a theory of earthquakes, and Nicholas Steno developed the theory of superposition and argued that fossils were the remains of once-living creatures. Beginning with Thomas Burnet's "Sacred Theory of the Earth" in 1681, natural philosophers began to explore the idea that the Earth had changed over time. Burnet and his contemporaries interpreted Earth's past in terms of events described in the Bible, but their work laid the intellectual foundations for secular interpretations of Earth history.
Modern geology, like modern chemistry, gradually evolved during the 18th and early 19th centuries. Benoît de Maillet and the Comte de Buffon saw the Earth as much older than the 6,000 years envisioned by biblical scholars. Jean-Étienne Guettard and Nicolas Desmarest hiked central France and recorded their observations on some of the first geological maps. Aided by chemical experimentation, naturalists such as Scotland's John Walker, Sweden's Torbern Bergman, and Germany's Abraham Werner created comprehensive classification systems for rocks and minerals—a collective achievement that transformed geology into a cutting edge field by the end of the eighteenth century. These early geologists also proposed a generalized interpretations of Earth history that led James Hutton, Georges Cuvier and Alexandre Brongniart, following in the steps of Steno, to argue that layers of rock could be dated by the fossils they contained: a principle first applied to the geology of the Paris Basin. The use of index fossils became a powerful tool for making geological maps, because it allowed geologists to correlate the rocks in one locality with those of similar age in other, distant localities. Over the first half of the 19th century, geologists such as Charles Lyell, Adam Sedgwick, and Roderick Murchison applied the new technique to rocks throughout Europe and eastern North America, setting the stage for more detailed, government-funded mapping projects in later decades.
Midway through the 19th century, the focus of geology shifted from description and classification to attempts to understand "how" the surface of the Earth had changed. The first comprehensive theories of mountain building were proposed during this period, as were the first modern theories of earthquakes and volcanoes. Louis Agassiz and others established the reality of continent-covering ice ages, and "fluvialists" like Andrew Crombie Ramsay argued that river valleys were formed, over millions of years by the rivers that flow through them. After the discovery of radioactivity, radiometric dating methods were developed, starting in the 20th century. Alfred Wegener's theory of "continental drift" was widely dismissed when he proposed it in the 1910s, but new data gathered in the 1950s and 1960s led to the theory of plate tectonics, which provided a plausible mechanism for it. Plate tectonics also provided a unified explanation for a wide range of seemingly unrelated geological phenomena. Since 1970 it has served as the unifying principle in geology.
Geologists' embrace of plate tectonics became part of a broadening of the field from a study of rocks into a study of the Earth as a planet. Other elements of this transformation include: geophysical studies of the interior of the Earth, the grouping of geology with meteorology and oceanography as one of the "earth sciences", and comparisons of Earth and the solar system's other rocky planets.
Astronomy.
Aristarchus of Samos published work on how to determine the sizes and distances of the Sun and the Moon, and Eratosthenes used this work to figure the size of the Earth. Hipparchus later discovered the precession of the Earth.
Advances in astronomy and in optical systems in the 19th century resulted in the first observation of an asteroid (1 Ceres) in 1801, and the discovery of Neptune in 1846.
George Gamow, Ralph Alpher, and Robert Herman had calculated that there should be evidence for a Big Bang in the background temperature of the universe. In 1964, Arno Penzias and Robert Wilson discovered a 3 Kelvin background hiss in their Bell Labs radiotelescope (the Holmdel Horn Antenna), which was evidence for this hypothesis, and formed the basis for a number of results that helped determine the age of the universe.
Supernova SN1987A was observed by astronomers on Earth both visually, and in a triumph for neutrino astronomy, by the solar neutrino detectors at Kamiokande. But the solar neutrino flux was a fraction of its theoretically expected value. This discrepancy forced a change in some values in the standard model for particle physics.
Biology, medicine and genetics.
In 1847, Hungarian physician Ignác Fülöp Semmelweis dramatically reduced the occurrency of puerperal fever by simply requiring physicians to wash their hands before attending to women in childbirth. This discovery predated the germ theory of disease. However, Semmelweis' findings were not appreciated by his contemporaries and came into use only with discoveries by British surgeon Joseph Lister, who in 1865 proved the principles of antisepsis. Lister's work was based on the important findings by French biologist Louis Pasteur. Pasteur was able to link microorganisms with disease, revolutionizing medicine. He also devised one of the most important methods in preventive medicine, when in 1880 he produced a vaccine against rabies. Pasteur invented the process of pasteurization, to help prevent the spread of disease through milk and other foods.
Perhaps the most prominent, controversial and far-reaching theory in all of science has been the theory of evolution by natural selection put forward by the British naturalist Charles Darwin in his book On the Origin of Species in 1859. Darwin proposed that the features of all living things, including humans, were shaped by natural processes over long periods of time. The theory of evolution in its current form affects almost all areas of biology. Implications of evolution on fields outside of pure science have led to both opposition and support from different parts of society, and profoundly influenced the popular understanding of "man's place in the universe". In the early 20th century, the study of heredity became a major investigation after the rediscovery in 1900 of the laws of inheritance developed by the Moravian monk Gregor Mendel in 1866. Mendel's laws provided the beginnings of the study of genetics, which became a major field of research for both scientific and industrial research. By 1953, James D. Watson, Francis Crick and Maurice Wilkins clarified the basic structure of DNA, the genetic material for expressing life in all its forms. In the late 20th century, the possibilities of genetic engineering became practical for the first time, and a massive international effort began in 1990 to map out an entire human genome (the Human Genome Project).
Ecology.
The discipline of ecology typically traces its origin to the synthesis of Darwinian evolution and Humboldtian biogeography, in the late 19th and early 20th centuries. Equally important in the rise of ecology, however, were microbiology and soil science—particularly the cycle of life concept, prominent in the work Louis Pasteur and Ferdinand Cohn. The word "ecology" was coined by Ernst Haeckel, whose particularly holistic view of nature in general (and Darwin's theory in particular) was important in the spread of ecological thinking. In the 1930s, Arthur Tansley and others began developing the field of ecosystem ecology, which combined experimental soil science with physiological concepts of energy and the techniques of field biology. The history of ecology in the 20th century is closely tied to that of environmentalism; the Gaia hypothesis, first formulated in the 1960s, and spreading in the 1970s, and more recently the scientific-religious movement of Deep Ecology have brought the two closer together.
Social sciences.
Successful use of the scientific method in the physical sciences led to the same methodology being adapted to better understand the many fields of human endeavor. From this effort the social sciences have been developed.
Political science.
Political science is a late arrival in terms of social sciences. However, the discipline has a clear set of antecedents such as moral philosophy, political philosophy, political economy, history, and other fields concerned with normative determinations of what ought to be and with deducing the characteristics and functions of the ideal form of government. The roots of politics are in prehistory. In each historic period and in almost every geographic area, we can find someone studying politics and increasing political understanding.
In Western culture, the study of politics is first found in Ancient Greece. The antecedents of European politics trace their roots back even earlier than Plato and Aristotle, particularly in the works of Homer, Hesiod, Thucydides, Xenophon, and Euripides. Later, Plato analyzed political systems, abstracted their analysis from more literary- and history- oriented studies and applied an approach we would understand as closer to philosophy. Similarly, Aristotle built upon Plato's analysis to include historical empirical evidence in his analysis.
An ancient Indian treatise on statecraft, economic policy and military strategy by Kautilya and Viṣhṇugupta, who are traditionally identified with Chāṇakya (c. 350–-283 BCE). In this treatise, the behaviors and relationships of the people, the King, the State, the Government Superintendents, Courtiers, Enemies, Invaders, and Corporations are analysed and documented. Roger Boesche describes the "Arthaśāstra" as "a book of political realism, a book analysing how the political world does work and not very often stating how it ought to work, a book that frequently discloses to a king what calculating and sometimes brutal measures he must carry out to preserve the state and the common good."
During the rule of Rome, famous historians such as Polybius, Livy and Plutarch documented the rise of the Roman Republic, and the organization and histories of other nations, while statesmen like Julius Caesar, Cicero and others provided us with examples of the politics of the republic and Rome's empire and wars. The study of politics during this age was oriented toward understanding history, understanding methods of governing, and describing the operation of governments.
With the fall of the Western Roman Empire, there arose a more diffuse arena for political studies. The rise of monotheism and, particularly for the Western tradition, Christianity, brought to light a new space for politics and political action. During the Middle Ages, the study of politics was widespread in the churches and courts. Works such as Augustine of Hippo's "The City of God" synthesized current philosophies and political traditions with those of Christianity, redefining the borders between what was religious and what was political. Most of the political questions surrounding the relationship between Church and State were clarified and contested in this period.
In the Middle East and later other Islamic areas, works such as the Rubaiyat of Omar Khayyam and Epic of Kings by Ferdowsi provided evidence of political analysis, while the Islamic Aristotelians such as Avicenna and later Maimonides and Averroes, continued Aristotle's tradition of analysis and empiricism, writing commentaries on Aristotle's works.
During the Italian Renaissance, Niccolò Machiavelli established the emphasis of modern political science on direct empirical observation of political institutions and actors. Later, the expansion of the scientific paradigm during the Enlightenment further pushed the study of politics beyond normative determinations. In particular, the study of statistics, to study the subjects of the state, has been applied to polling and voting.
In the 20th century, the study of ideology, behaviouralism and international relations led to a multitude of 'pol-sci' subdisciplines including rational choice theory, voting theory, game theory (also used in economics), psephology, political geography/geopolitics, political psychology/political sociology, political economy, policy analysis, public administration, comparative political analysis and peace studies/conflict analysis.
Linguistics.
Historical linguistics emerged as an independent field of study at the end of the 18th century. Sir William Jones proposed that Sanskrit, Persian, Greek, Latin, Gothic, and Celtic languages all shared a common base. After Jones, an effort to catalog all languages of the world was made throughout the 19th century and into the 20th century. Publication of Ferdinand de Saussure's "Cours de linguistique générale" created the development of descriptive linguistics. Descriptive linguistics, and the related structuralism movement caused linguistics to focus on how language changes over time, instead of just describing the differences between languages. Noam Chomsky further diversified linguistics with the development of generative linguistics in the 1950s. His effort is based upon a mathematical model of language that allows for the description and prediction of valid syntax. Additional specialties such as sociolinguistics, cognitive linguistics, and computational linguistics have emerged from collaboration between linguistics and other disciplines.
Economics.
The basis for classical economics forms Adam Smith's "An Inquiry into the Nature and Causes of the Wealth of Nations", published in 1776. Smith criticized mercantilism, advocating a system of free trade with division of labour. He postulated an "invisible hand" that regulated economic systems made up of actors guided only by self-interest. Karl Marx developed an alternative economic theory, called Marxian economics. Marxian economics is based on the labor theory of value and assumes the value of good to be based on the amount of labor required to produce it. Under this assumption, capitalism was based on employers not paying the full value of workers labor to create profit. The Austrian school responded to Marxian economics by viewing entrepreneurship as driving force of economic development. This replaced the labor theory of value by a system of supply and demand.
In the 1920s, John Maynard Keynes prompted a division between microeconomics and macroeconomics. Under Keynesian economics macroeconomic trends can overwhelm economic choices made by individuals. Governments should promote aggregate demand for goods as a means to encourage economic expansion. Following World War II, Milton Friedman created the concept of monetarism. Monetarism focuses on using the supply and demand of money as a method for controlling economic activity. In the 1970s, monetarism has adapted into supply-side economics which advocates reducing taxes as a means to increase the amount of money available for economic expansion.
Other modern schools of economic thought are New Classical economics and New Keynesian economics. New Classical economics was developed in the 1970s, emphasizing solid microeconomics as the basis for macroeconomic growth. New Keynesian economics was created partially in response to New Classical economics, and deals with how inefficiencies in the market create a need for control by a central bank or government.
The above "history of economics" reflects modern economic textbooks and this means that the last stage of a science is represented as the culmination of its history (Kuhn, 1962). The "invisible hand" mentioned in a lost page in the middle of a chapter in the middle of the to "Wealth of Nations", 1776, advances as Smith's central message. It is played down that this "invisible hand" acts only "frequently" and that it is "no part of his [the individual's] intentions" because competition leads to lower prices by imitating "his" invention. That this "invisible hand" prefers "the support of domestic to foreign industry" is cleansed—often without indication that part of the citation is truncated. The opening passage of the "Wealth" containing Smith's message is never mentioned as it cannot be integrated into modern theory: "Wealth" depends on the division of labour which changes with market volume and on the proportion of productive to Unproductive labor.
Psychology.
The end of the 19th century marks the start of psychology as a scientific enterprise. The year 1879 is commonly seen as the start of psychology as an independent field of study. In that year Wilhelm Wundt founded the first laboratory dedicated exclusively to psychological research (in Leipzig). Other important early contributors to the field include Hermann Ebbinghaus (a pioneer in memory studies), Ivan Pavlov (who discovered classical conditioning), William James, and Sigmund Freud. Freud's influence has been enormous, though more as cultural icon than a force in scientific psychology.
The 20th century saw a rejection of Freud's theories as being too unscientific, and a reaction against Edward Titchener's atomistic approach of the mind. This led to the formulation of behaviorism by John B. Watson, which was popularized by B.F. Skinner. Behaviorism proposed epistemologically limiting psychological study to overt behavior, since that could be reliably measured. Scientific knowledge of the "mind" was considered too metaphysical, hence impossible to achieve.
The final decades of the 20th century have seen the rise of a new interdisciplinary approach to studying human psychology, known collectively as cognitive science. Cognitive science again considers the mind as a subject for investigation, using the tools of psychology, linguistics, computer science, philosophy, and neurobiology. New methods of visualizing the activity of the brain, such as PET scans and CAT scans, began to exert their influence as well, leading some researchers to investigate the mind by investigating the brain, rather than cognition. These new forms of investigation assume that a wide understanding of the human mind is possible, and that such an understanding may be applied to other research domains, such as artificial intelligence.
Sociology.
Ibn Khaldun can be regarded as the earliest scientific systematic sociologist. The modern sociology, emerged in the early 19th century as the academic response to the modernization of the world. Among many early sociologists (e.g., Émile Durkheim), the aim of sociology was in structuralism, understanding the cohesion of social groups, and developing an "antidote" to social disintegration. Max Weber was concerned with the modernization of society through the concept of rationalization, which he believed would trap individuals in an "iron cage" of rational thought. Some sociologists, including Georg Simmel and W. E. B. Du Bois, utilized more microsociological, qualitative analyses. This microlevel approach played an important role in American sociology, with the theories of George Herbert Mead and his student Herbert Blumer resulting in the creation of the symbolic interactionism approach to sociology.
American sociology in the 1940s and 1950s was dominated largely by Talcott Parsons, who argued that aspects of society that promoted structural integration were therefore "functional". This structural functionalism approach was questioned in the 1960s, when sociologists came to see this approach as merely a justification for inequalities present in the status quo. In reaction, conflict theory was developed, which was based in part on the philosophies of Karl Marx. Conflict theorists saw society as an arena in which different groups compete for control over resources. Symbolic interactionism also came to be regarded as central to sociological thinking. Erving Goffman saw social interactions as a stage performance, with individuals preparing "backstage" and attempting to control their audience through impression management. While these theories are currently prominent in sociological thought, other approaches exist, including feminist theory, post-structuralism, rational choice theory, and postmodernism.
Anthropology.
Anthropology can best be understood as an outgrowth of the Age of Enlightenment. It was during this period that Europeans attempted systematically to study human behaviour. Traditions of jurisprudence, history, philology and sociology developed during this time and informed the development of the social sciences of which anthropology was a part.
At the same time, the romantic reaction to the Enlightenment produced thinkers such as Johann Gottfried Herder and later Wilhelm Dilthey whose work formed the basis for the culture concept which is central to the discipline. Traditionally, much of the history of the subject was based on colonial encounters between Western Europe and the rest of the world, and much of 18th- and 19th-century anthropology is now classed as forms of scientific racism.
During the late 19th-century, battles over the "study of man" took place between those of an "anthropological" persuasion (relying on anthropometrical techniques) and those of an "ethnological" persuasion (looking at cultures and traditions), and these distinctions became part of the later divide between physical anthropology and cultural anthropology, the latter ushered in by the students of Franz Boas.
In the mid-20th century, much of the methodologies of earlier anthropological and ethnographical study were reevaluated with an eye towards research ethics, while at the same time the scope of investigation has broadened far beyond the traditional study of "primitive cultures" (scientific practice itself is often an arena of anthropological study).
The emergence of paleoanthropology, a scientific discipline which draws on the methodologies of paleontology, physical anthropology and ethology, among other disciplines, and increasing in scope and momentum from the mid-20th century, continues to yield further insights into human origins, evolution, genetic and cultural heritage, and perspectives on the contemporary human predicament as well.
Emerging disciplines.
During the 20th century, a number of interdisciplinary scientific fields have emerged. These examples include:
Communication studies combines animal communication, information theory, marketing, public relations, telecommunications and other forms of communication.
Computer science, built upon a foundation of theoretical linguistics, discrete mathematics, and electrical engineering, studies the nature and limits of computation. Subfields include computability, computational complexity, database design, computer networking, artificial intelligence, and the design of computer hardware. One area in which advances in computing have contributed to more general scientific development is by facilitating large-scale archiving of scientific data. Contemporary computer science typically distinguishes
itself by emphasising mathematical 'theory' in contrast to the practical emphasis of software engineering.
Environmental science is an interdisciplinary field. It draws upon the disciplines of biology, chemistry, earth sciences, ecology, geography, mathematics, and physics.
Materials science has its roots in metallurgy, mineralogy, and crystallography. It combines chemistry, physics, and several engineering disciplines. The field studies metals, ceramics, glass, plastics, semiconductors, and composite materials.
Academic study.
As an academic field, history of science began with the publication of William Whewell's "History of the Inductive Sciences" (first published in 1837). A more formal study of the history of science as an independent discipline was launched by George Sarton's publications, "Introduction to the History of Science" (1927) and the "Isis" journal (founded in 1912). Sarton exemplified the early 20th-century view of the history of science as the history of great men and great ideas. He shared with many of his contemporaries a Whiggish belief in history as a record of the advances and delays in the march of progress. The history of science was not a recognized subfield of American history in this period, and most of the work was carried out by interested scientists and physicians rather than professional historians. With the work of I. Bernard Cohen at Harvard, the history of science became an established subdiscipline of history after 1945.
The history of mathematics, history of technology, and history of philosophy are distinct areas of research and are covered in other articles. Mathematics is closely related to but distinct from natural science (at least in the modern conception). Technology is likewise closely related to but clearly differs from the search for empirical truth.
History of science is an academic discipline, with an international community of specialists. Main professional organizations for this field include the History of Science Society, the British Society for the History of Science, and the European Society for the History of Science.
Theories and sociology of the history of science.
Much of the study of the history of science has been devoted to answering questions about what science "is", how it "functions", and whether it exhibits large-scale patterns and trends. The sociology of science in particular has focused on the ways in which scientists work, looking closely at the ways in which they "produce" and "construct" scientific knowledge. Since the 1960s, a common trend in science studies (the study of the sociology and history of science) has been to emphasize the "human component" of scientific knowledge, and to de-emphasize the view that scientific data are self-evident, value-free, and context-free. The field of Science and Technology Studies, an area that overlaps and often informs historical studies of science, focuses on the social context of science in both contemporary and historical periods.
Humboldtian science refers to the early 19th century approach of combining scientific field work with the age of Romanticism sensitivity, ethics and aestetic ideals. It helped to install natural history as a separate field, gave base for ecology and was based on the role model of scientist, naturalist and explorer Alexander von Humboldt. The later 19th century positivism asserted that all authentic knowledge allows verification and that all authentic knowledge assumes that the only valid knowledge is scientific.
A major subject of concern and controversy in the philosophy of science has been the nature of "theory change" in science. Karl Popper argued that scientific knowledge is progressive and cumulative; Thomas Kuhn, that scientific knowledge moves through "paradigm shifts" and is not necessarily progressive; and Paul Feyerabend, that scientific knowledge is not cumulative or progressive and that there can be no demarcation in terms of method between science and any other form of investigation.
The mid 20th century saw a series of studies relying to the role of science in a social context, starting from Thomas Kuhn's "The Structure of Scientific Revolutions" in 1962. It opened the study of science to new disciplines by suggesting that the evolution of science was in part sociologically determined and that positivism did not explain the actual interactions and strategies of the human participants in science. As Thomas Kuhn put it, the history of science may be seen in more nuanced terms, such as that of competing paradigms or conceptual systems in a wider matrix that includes intellectual, cultural, economic and political themes outside of science. "Partly by selection and partly by distortion, the scientists of earlier ages are implicitly presented as having worked upon the same set of fixed problems and in accordance with the same set of fixed canons that the most recent revolution in scientific theory and method made seem scientific."
Further studies, e.g. Jerome Ravetz 1971 "Scientific Knowledge and its Social Problems" referred to the role of the scientific community, as a social construct, in accepting or rejecting (objective) scientific knowledge. The Science wars of the 1990 were about the influence of especially French philosophers, which denied the objectivity of science in general or seemed to do so. They described as well differences between the idealized model of a pure science and the actual scientific practice; while scientism, a revival of the positivism approach, saw in precise measurement and rigorous calculation the basis for finally settling enduring metaphysical and moral controversies. However, more recently some of the leading critical theorists have recognized that their postmodern deconstructions have at times been counter-productive, and are providing intellectual ammunition for reactionary interests. Bruno Latour noted that "dangerous extremists are using the very same argument of social construction to destroy hard-won evidence that could save our lives. Was I wrong to participate in the invention of this field known as science studies? Is it enough to say that we did not really mean what we meant?"

</doc>
<doc id="14403" url="http://en.wikipedia.org/wiki?curid=14403" title="Hydrogen peroxide">
Hydrogen peroxide

Hydrogen peroxide is a chemical compound with the formula H2O2. In its pure form it is a colorless liquid, slightly more viscous than water; however, for safety reasons it is normally used as an aqueous solution. Hydrogen peroxide is the simplest peroxide (a compound with an oxygen-oxygen single bond) and finds use as a strong oxidizer, bleaching agent and disinfectant. Concentrated hydrogen peroxide, or 'high-test peroxide,' is a reactive oxygen species and has been used as a propellant in rocketry.
Hydrogen peroxide is often described as being “water but with one more oxygen atom” a description which can give the incorrect impression that there is a great deal of similarity between the two compounds. Pure hydrogen peroxide will explode if heated to boiling, will cause serious contact burns to the skin and can set materials alight on contact. For these reasons it is usually handled as a dilute solution (household grades are typically 3-6%). Its chemistry is dominated by the nature of its unstable peroxide bond.
Structure and properties.
Properties.
The boiling point of H2O2 has been extrapolated as being 150.2 °C, approximately 50 degrees higher than water; in practice hydrogen peroxide will undergo potentially explosive thermal decomposition if heated to this temperature. It may be safely distilled under reduced pressure.
In aqueous solutions.
In aqueous solutions hydrogen peroxide differs from the pure material due to the effects of hydrogen bonding between water and hydrogen peroxide molecules. Hydrogen peroxide and water form a eutectic mixture, exhibiting freezing-point depression; pure water has a melting point of 0 °C and pure hydrogen peroxide of −0.43 °C, but a 50% (by volume) solution of the two freezes at -51 °C. The boiling point of the same mixtures is also depressed in relation with the median of both boiling points (125.1 °C). It occurs at 114 °C. This boiling point is 14° greater than that of pure water and 36.2° less than that of pure hydrogen peroxide.
Structure.
Hydrogen peroxide (H2O2) is a nonplanar molecule with (twisted) C2 symmetry. Although the O−O bond is a single bond, the molecule has a relatively high barrier to rotation of 2460 cm−1 (29.45 kJ/mol); for comparison, the rotational barrier for ethane is 12.5 kJ/mol. The increased barrier is ascribed to repulsion between the lone pairs of the adjacent oxygen atoms and results in hydrogen peroxide displaying atropisomerism.
The molecular structures of gaseous and crystalline H2O2 are significantly different. This difference is attributed to the effects of hydrogen bonding, which is absent in the gaseous state. Crystals of H2O2 are tetragonal with the space group formula_1.
Comparison with analogues.
Hydrogen peroxide has several structural analogues with Hm-E-E-Hn bonding arrangements (Water also shown for comparison). It has the highest (theoretical) boiling point of this series (X = O, N, S). Its melting point is also fairly high, being comparable to that of hydrazine and water, with only hydroxylamine crystallising significantly more readily, indicative of particularly strong hydrogen bonding. Diphosphane and hydrogen disulfide exhibit only weak hydrogen bonding and have little chemical similarity to hydrogen peroxide. All of these analogues are thermodynamically unstable. Structurally, the analogues all adopt similar skewed structures, due to repulsion between adjacent lone pairs.
Discovery.
Hydrogen peroxide was first described in 1818 by Louis Jacques Thénard, who produced it by treating barium peroxide with nitric acid. An improved version of this process used hydrochloric acid, followed by addition of sulfuric acid to precipitate the barium sulfate byproduct. Thénard's process was used from the end of the 19th century until the middle of the 20th century.
Pure hydrogen peroxide was long believed to be unstable as early attempts to separate it from the water, which is present during synthesis, all failed. This instability was due to traces of impurities (transition metals salts) which catalyze the decomposition of the hydrogen peroxide. Pure hydrogen peroxide was first obtained in 1894 — almost 80 years after its discovery — by Richard Wolffenstein, who produced it via vacuum distillation.
Determination of the molecular structure of hydrogen peroxide proved to be very difficult. In 1892 the Italian physical chemist Giacomo Carrara (1864–1925) determined its molecular weight by freezing point depression, which confirmed that its molecular formula is H2O2. At least half a dozen hypothetical molecular structures seemed to be consistent with the available evidence. In 1934, the English mathematical physicist William Penney and the Scottish physicist Gordon Sutherland proposed a molecular structure for hydrogen peroxide which was very similar to the presently accepted one.
Manufacture.
Previously, hydrogen peroxide was prepared industrially by hydrolysis of the ammonium peroxydisulfate, which was itself obtained via the electrolysis of a solution of ammonium bisulfate (NH4HSO4) in sulfuric acid.
Today, hydrogen peroxide is manufactured almost exclusively by the anthraquinone process, which was formalized in 1936 and patented in 1939. It begins with the reduction of an anthraquinone (such as 2-ethylanthraquinone or the 2-amyl derivative) to the corresponding anthrahydroquinone, typically via hydrogenation on a palladium catalyst; the anthrahydroquinone then undergoes to autoxidation to regenerate the starting anthraquinone, with hydrogen peroxide being produced as a by-product. Most commercial processes achieve oxidation by bubbling compressed air through a solution of the derivatized anthracene, whereby the oxygen present in the air reacts with the labile hydrogen atoms (of the hydroxy group), giving hydrogen peroxide and regenerating the anthraquinone. Hydrogen peroxide is then extracted and the anthraquinone derivative is reduced back to the dihydroxy (anthracene) compound using hydrogen gas in the presence of a metal catalyst. The cycle then repeats itself.
The simplified overall equation for the process is deceptively simple:
The economics of the process depend heavily on effective recycling of the quinone (which is expensive) and extraction solvents, and of the hydrogenation catalyst.
A process to produce hydrogen peroxide directly from the elements has been of interest for many years. Direct synthesis is difficult to achieve as, in terms of thermodynamics, the reaction of hydrogen with oxygen favours production of water. Systems for direct synthesis have been developed, most of which are based around finely dispersed metal catalysts. None of these has yet reached a point where they can be used for industrial-scale synthesis.
Availability.
Hydrogen peroxide is most commonly available as a solution in water. For consumers, it is usually available from pharmacies at 3 and 6 wt% concentrations. The concentrations are sometimes described in terms of the volume of oxygen gas generated; one milliliter of a 20-volume solution generates twenty milliliters of oxygen gas when completely decomposed. For laboratory use, 30 wt% solutions are most common. Commercial grades from 70% to 98% are also available, but due to the potential of solutions of more than 68% hydrogen peroxide to be converted entirely to steam and oxygen (with the temperature of the steam increasing as the concentration increases above 68%) these grades are potentially far more hazardous, and require special care in dedicated storage areas. Buyers must typically allow inspection by commercial manufacturers.
In 1994, world production of H2O2 was around 1.9 million tonnes and grew to 2.2 million in 2006, most of which was at a concentration of 70% or less. In that year bulk 30% H2O2 sold for around US $0.54 per kg, equivalent to US $1.50 per kg (US $0.68 per lb) on a "100% basis".
Reactions.
Decomposition.
Hydrogen peroxide is thermodynamically unstable and decomposes to form water and oxygen with a Δ"H"o of −98.2 kJ·mol−1 and a ΔS of 70.5 J·mol−1·K−1.
The rate of decomposition increases with rising temperature, concentration and pH, with cool, dilute, acidic solutions showing the best stability. Decomposition is catalysed by various compounds, including most transition metals and their compounds (e.g. manganese dioxide, silver, and platinum). Certain metal ions, such as Fe2+ or Ti3+, can cause the decomposition to take a different path, with free radicals such as (HO·) and (HOO·) being formed.
Non-metallic catalysts include potassium iodide, which reacts particularly rapidly and forms the basis of the elephant toothpaste experiment. Hydrogen peroxide can also be decomposed biologically by enzyme catalase.
The decomposition of hydrogen peroxide liberates oxygen and heat; this can be dangerous as spilling high concentrations of hydrogen peroxide on a flammable substance can cause an immediate fire.
Redox reactions.
Hydrogen peroxide exhibits oxidizing and reducing properties, depending on pH.
In acidic solutions, H2O2 is one of the most powerful oxidizers known—stronger than chlorine, chlorine dioxide, and potassium permanganate. Also, through catalysis, H2O2 can be converted into hydroxyl radicals (•OH), which are highly reactive.
In acidic solutions Fe2+ is oxidized to Fe3+ (hydrogen peroxide acting as an oxidizing agent),
and sulfite (SO32−) is oxidized to sulfate (SO42−). However, potassium permanganate is reduced to Mn2+ by acidic H2O2. Under alkaline conditions, however, some of these reactions reverse; for example, Mn2+ is oxidized to Mn4+ (as MnO2).
In basic solution, hydrogen peroxide can reduce a variety of inorganic ions. When it acts as a reducing agent, oxygen gas is also produced. For example hydrogen peroxide will reduce sodium hypochlorite and potassium permanganate, which is a convenient method for preparing oxygen in the laboratory.
Organic reactions.
Hydrogen peroxide is frequently used as an oxidizing agent. Illustrative is oxidation of thioethers to sulfoxides.
Alkaline hydrogen peroxide is used for epoxidation of electron-deficient alkenes such as acrylic acid derivatives, and for the oxidation of alkylboranes to alcohols, the second step of hydroboration-oxidation. It is also the principal reagent in the Dakin oxidation process.
Precursor to other peroxide compounds.
Hydrogen peroxide is a weak acid, forming hydroperoxide or peroxide salts with many metals.
It also converts metal oxides into the corresponding peroxides. For example, upon treatment with hydrogen peroxide, chromic acid (CrO3) form an unstable blue peroxide CrO(O2)2.
This kind of reaction is used industrially to produce peroxoanions. For example, reaction with borax leads to sodium perborate, a bleach used in laundry detergents:
H2O2 converts carboxylic acids (RCO2H) into peroxy acids (RC(O)O2H), which are themselves used as oxidizing agents. Hydrogen peroxide reacts with acetone to form acetone peroxide, and it interacts with ozone to form hydrogen trioxide, also known as trioxidane. Reaction with urea produces the adduct hydrogen peroxide – urea, used for whitening teeth. An acid-base adduct with triphenylphosphine oxide is a useful "carrier" for H2O2 in some reactions.
Biological function.
Hydrogen peroxide is also one of the two chief chemicals in the defense system of the bombardier beetle, reacting with hydroquinone to discourage predators.
A study published in "Nature" found that hydrogen peroxide plays a role in the immune system. Scientists found that hydrogen peroxide presence inside cells increased after tissues are damaged in zebra fish, which is thought to act as a signal to white blood cells to converge on the site and initiate the healing process. When the genes required to produce hydrogen peroxide were disabled, white blood cells did not accumulate at the site of damage. The experiments were conducted on fish; however, because fish are genetically similar to humans, the same process is speculated to occur in humans. The study in "Nature" suggested asthma sufferers have higher levels of hydrogen peroxide in their lungs than healthy people, which could explain why asthma sufferers have inappropriate levels of white blood cells in their lungs.
Hydrogen peroxide has important roles as a signaling molecule in the regulation of a wide variety of biological processes. The compound is a major factor implicated in the free-radical theory of aging, based on how readily hydrogen peroxide can decompose into a hydroxyl radical and how superoxide radical byproducts of cellular metabolism can react with ambient water to form hydrogen peroxide. These hydroxyl radicals in turn readily react with and damage vital cellular components, especially those of the mitochondria. At least one study has also tried to link hydrogen peroxide production to cancer. These studies have frequently been quoted in fraudulent treatment claims.
The amount of hydrogen peroxide in biological systems can be assayed using a fluorimetric assay.
Applications.
Industrial.
About 60% of the world's production of hydrogen peroxide is used for pulp- and paper-bleaching.
The second major industrial application is the manufacture of sodium percarbonate and sodium perborate which are used as mild bleaches in laundry detergents.
It is used in the production of various organic peroxides with dibenzoyl peroxide being a high volume example. This is used in polymerisations, as a flour bleaching agent and as a treatment for acne. Peroxy acids, such as peracetic acid and meta-chloroperoxybenzoic acid are also typically produced using hydrogen peroxide.
Hydrogen peroxide is used in certain waste-water treatment processes to remove organic impurities. This is achieved by advanced oxidation processes, such as the Fenton reaction, which use it to generate highly reactive hydroxyl radicals (·OH). These are able to destroy organic contaminates which are ordinarily difficult to remove, such as aromatic or halogenated compounds. It can also oxidize sulphur based compounds present in the waste; which is beneficial as it generally reduces their odour.
Medical.
Disinfectant.
Hydrogen peroxide can be used for the sterilization of various surfaces, including surgical tools and may be deployed as a vapor (VHP) for room sterilization. H2O2 demonstrates broad-spectrum efficacy against viruses, bacteria, yeasts, and bacterial spores. In general, greater activity is seen against gram-positive than gram-negative bacteria; however, the presence of catalase or other peroxidases in these organisms can increase tolerance in the presence of lower concentrations. Higher concentrations of H2O2 (10 to 30%) and longer contact times are required for sporicidal activity.
Hydrogen peroxide is seen as an environmentally safe alternative to chlorine-based bleaches, as it degrades to form oxygen and water and it is generally recognized as safe as an antimicrobial agent by the U.S. Food and Drug Administration (FDA).
Historically hydrogen peroxide was used for disinfecting wounds, partly because of its low cost and prompt availability compared to other antiseptics. It is now thought to slow healing and lead to scarring because it destroys newly formed skin cells. Only a very low concentration of H2O2 can induce healing, and only if not repeatedly applied. Surgical use can lead to gas embolism formation. Despite this it is still used for wound treatment in many developing countries.
It is absorbed by skin upon contact and creates a local capillary embolism that appears as a temporary whitening of the skin.
Cosmetic applications.
Diluted H2O2 (between 1.9% and 12%) mixed with ammonium hydroxide is used to bleach human hair. The chemical's bleaching property lends its name to the phrase "peroxide blonde".
Hydrogen peroxide is also used for tooth whitening and can be mixed with baking soda and salt to make a home-made toothpaste.
Hydrogen peroxide may be used to treat acne, although benzoyl peroxide is a more common treatment.
Use in alternative medicine.
Practitioners of alternative medicine have advocated the use of hydrogen peroxide for the treatment of various conditions, including emphysema, influenza, AIDS and in particular cancer. The practise calls for the daily consumption of hydrogen peroxide, either orally or by injection and is, in general, based around two precepts. Firstly that hydrogen peroxide is naturally produced by the body to combat infection. Secondly, that human pathogens (including cancer: See Warburg hypothesis) are anaerobic and cannot survive in oxygen-rich environments. The ingestion or injection of hydrogen peroxide is therefore believed to kill disease by mimicking the immune response in addition to increasing levels of oxygen within the body. This makes it similar to other oxygen-based therapies, such as ozone therapy and hyperbaric oxygen therapy.
Both the effectiveness and safety of hydrogen peroxide therapy is disputed by mainstream scientists. Hydrogen peroxide is produced by the immune system but in a carefully controlled manner. Cells called by phagocytes engulf pathogens and then use hydrogen peroxide to destroy them. The peroxide is toxic to both the cell and the pathogen and so is kept within a special compartment, called a phagosome. Free hydrogen peroxide will damage any tissue it encounters via oxidative stress; a process which also has been proposed as a cause of cancer.
Claims that hydrogen peroxide therapy increase cellular levels of oxygen have not been supported. The quantities administered would be expected to provide very little additional oxygen compared to that available from normal respiration. It should also be noted that it is difficult to raise the level of oxygen around cancer cells within a tumour, as the blood supply tends to be poor, a situation known as tumour hypoxia.
Large oral doses of hydrogen peroxide at a 3% concentration may cause irritation and blistering to the mouth, throat, and abdomen as well as abdominal pain, vomiting, and diarrhea.
Intravenous injection of hydrogen peroxide has been linked to several deaths.
The American Cancer Society states that "there is no scientific evidence that hydrogen peroxide is a safe, effective or useful cancer treatment" The therapy is not approved by the U.S. FDA.
Propellant.
High concentration H2O2 is referred to as High Test Peroxide (HTP). It can be used either as a monopropellant (not mixed with fuel) or as the oxidizer component of a bipropellant rocket. Use as a monopropellant takes advantage of the decomposition of 70–98+% concentration hydrogen peroxide into steam and oxygen. The propellant is pumped into a reaction chamber where a catalyst, usually a silver or platinum screen, triggers decomposition, producing steam at over 600 °C (1,112 °F), which is expelled through a nozzle, generating thrust. H2O2 monopropellant produces a maximum specific impulse ("I"sp) of 161 s (1.6 kN·s/kg). Peroxide was the first major monopropellant adopted for use in rocket applications. Hydrazine eventually replaced hydrogen peroxide monopropellant thruster applications primarily because of a 25% increase in the vacuum specific impulse. Hydrazine (toxic) and hydrogen peroxide (non-toxic) are the only two monopropellants (other than cold gases) to have been widely adopted and utilized for propulsion and power applications. The Bell Rocket Belt, reaction control systems for X-1, X-15, Centaur, Mercury, Little Joe as well as the turbo-pump gas generators for X-1, X-15, Jupiter, Redstone and Viking used hydrogen peroxide as a monopropellant.
As a bipropellant H2O2 is decomposed to burn a fuel as an oxidizer. Specific impulses as high as 350 s (3.5 kN·s/kg) can be achieved, depending on the fuel. Peroxide used as an oxidizer gives a somewhat lower "I"sp than liquid oxygen, but is dense, storable, noncryogenic and can be more easily used to drive gas turbines to give high pressures using an efficient "closed cycle". It can also be used for regenerative cooling of rocket engines. Peroxide was used very successfully as an oxidizer in World War II German rocket motors (e.g. T-Stoff, containing oxyquinoline stabilizer, for the Me 163B), most often used with C-Stoff in a self-igniting hypergolic combination, and for the low-cost British Black Knight and Black Arrow launchers. 
In the 1940s and 1950s, the Walter turbine used hydrogen peroxide for use in submarines while submerged; it was found to be too noisy and require too much maintenance compared to diesel-electric power systems. Some torpedoes used hydrogen peroxide as oxidizer or propellant. Operator error in the use of hydrogen peroxide torpedoes were named as possible causes for the sinkings of HMS "Sidon" and the Russian submarine "Kursk". SAAB Underwater Systems is manufacturing the Torpedo 2000. This torpedo, used by the Swedish navy, is powered by a piston engine propelled by HTP as an oxidizer and kerosene as a fuel in a bipropellant system.
Explosives.
Hydrogen peroxide has been used for creating organic peroxide based explosives, such as acetone peroxide, for improvised explosive devices, including the 7 July 2005 London bombings. These explosives tend to degrade quickly and hence are not used as commercial or military explosives.
Other uses.
Hydrogen peroxide has various domestic uses, primarily as a cleaning and disinfecting agent.
Hydrogen peroxide reacts with esters, such as and phenyl oxalate ester (cyalume), to produce chemiluminescence; this application is most commonly encountered in the form of glow sticks.
Some horticulturalists and users of hydroponics advocate the use of weak hydrogen peroxide solution in watering solutions. Its spontaneous decomposition releases oxygen that enhances a plant's root development and helps to treat root rot (cellular root death due to lack of oxygen) and a variety of other pests.
Laboratory tests conducted by fish culturists in recent years have demonstrated that common household hydrogen peroxide can be used safely to provide oxygen for small fish. The hydrogen peroxide releases oxygen by decomposition when it is exposed to catalysts such as manganese dioxide.
Safety.
Regulations vary, but low concentrations, such as 6%, are widely available and legal to buy for medical use. Most over-the-counter peroxide solutions are not suitable for ingestion. Higher concentrations may be considered hazardous and are typically accompanied by a Material Safety Data Sheet (MSDS). In high concentrations, hydrogen peroxide is an aggressive oxidizer and will corrode many materials, including human skin. In the presence of a reducing agent, high concentrations of H2O2 will react violently.
High-concentration hydrogen peroxide streams, typically above 40%, should be considered hazardous due to concentrated hydrogen peroxide's meeting the definition of a DOT oxidizer according to U.S. regulations, if released into the environment. The EPA Reportable Quantity (RQ) for D001 hazardous wastes is 100 lb, or approximately 10 USgal, of concentrated hydrogen peroxide.
Hydrogen peroxide should be stored in a cool, dry, well-ventilated area and away from any flammable or combustible substances. It should be stored in a container composed of non-reactive materials such as stainless steel or glass (other materials including some plastics and aluminium alloys may also be suitable). Because it breaks down quickly when exposed to light, it should be stored in an opaque container, and pharmaceutical formulations typically come in brown bottles that filter out light.
Hydrogen peroxide, either in pure or diluted form, can pose several risks, the main one being that it forms explosive mixtures upon contact with organic compounds. Highly concentrated hydrogen peroxide itself is unstable, and can then cause a boiling liquid expanding vapor explosion (BLEVE) of the remaining liquid. Distillation of hydrogen peroxide at normal pressures is thus highly dangerous. It is also corrosive especially when concentrated but even domestic-strength solutions can cause irritation to the eyes, mucous membranes and skin. Swallowing hydrogen peroxide solutions is particularly dangerous, as decomposition in the stomach releases large quantities of gas (10 times the volume of a 3% solution) leading to internal bleeding. Inhaling over 10% can cause severe pulmonary irritation.
With a significant vapor pressure (1.2 kPa at 50 °C[CRC Handbook of Chemistry and Physics, 76th Ed, 1995–1996]), hydrogen peroxide vapor is potentially hazardous. According to U.S. NIOSH, the Immediately Dangerous to Life and Health (IDLH) limit is only 75 ppm. The U.S. Occupational Safety and Health Administration (OSHA) has established a permissible exposure limit of 1.0 ppm calculated as an eight-hour time weighted average (29 CFR 1910.1000, Table Z-1) and hydrogen peroxide has also been classified by the American Conference of Governmental Industrial Hygienists (ACGIH) as a "known animal carcinogen, with unknown relevance on humans." For workplaces where there is a risk of exposure to the hazardous concentrations of the vapors, continuous monitors for hydrogen peroxide should be used. Information on the hazards of hydrogen peroxide is available from OSHA and from the ATSDR.
References.
Notes
Bibliography
</dl>

</doc>
<doc id="14404" url="http://en.wikipedia.org/wiki?curid=14404" title="Hesychasm">
Hesychasm

Hesychasm (Greek: ἡσυχασμός, "hesychasmos", from ἡσυχία, "hesychia", "stillness, rest, quiet, silence") is a mystical tradition of prayer in the Eastern Orthodox Church and Eastern Catholic Churches of Byzantine Rite practised (Gk: ἡσυχάζω, "hesychazo": "to keep stillness") by the Hesychast (Gr. Ἡσυχαστής, "hesychastes").
Based on Christ's injunction in the Gospel of Matthew to "when thou prayest, enter into thy closet, and when thou hast shut thy door, pray", hesychasm in tradition has been the process of retiring inward by ceasing to register the senses, in order to achieve an experiential knowledge of God (see theoria).
Meanings of the term.
Kallistos Ware distinguishes five distinct meanings of the term "hesychasm":
History of the term.
The origin of the term "hesychasmos," and of the related terms "hesychastes", "hesychia" and "hesychazo," is not entirely certain. According to the entries in Lampe's "A Patristic Greek Lexicon", the basic terms "hesychia" and "hesychazo" appear as early as the 4th century in such fathers as St John Chrysostom and the Cappadocians. The terms also appear in the same period in Evagrius Pontikos (c. 345 – 399), who although he is writing in Egypt is out of the circle of the Cappadocians, and in the "Sayings of the Desert Fathers."
The term "Hesychast" is used sparingly in Christian ascetical writings emanating from Egypt from the 4th century on, although the writings of Evagrius and the "Sayings of the Desert Fathers" do attest to it. In Egypt, the terms more often used are "anchoretism" (Gr. ἀναχώρησις, "withdrawal, retreat"), and "anchorite" (Gr. ἀναχωρητής, "one who withdraws or retreats, i.e. a hermit").
The term "Hesychast" was used in the 6th century in Palestine in the "Lives" of Cyril of Scythopolis, many of which lives treat of Hesychasts who were contemporaries of Cyril. Here, it should be noted that several of the saints about whom Cyril was writing, especially Euthymios and Savas, were in fact from Cappadocia. The laws "(novellae)" of the Emperor Justinian I (r. 527–565) treat "Hesychast" and "anchorite" as synonyms, making them interchangeable terms.
The terms "hesychia" and "Hesychast" are used quite systematically in the "Ladder of Divine Ascent" of St John of Sinai (523–603) and in "Pros Theodoulon" by St Hesychios (c. 750?), who is ordinarily also considered to be of the School of Sinai. It is not known where either St John of Sinai or St Hesychios were born, nor where they received their monastic formation.
It appears that the particularity of the term "Hesychast" has to do with the integration of the continual repetition of the Jesus Prayer into the practices of mental ascesis that were already used by hermits in Egypt. "Hesychasm" itself is not recorded in Lampe's Lexicon, which indicates that it is a later usage, and the term "Jesus Prayer" is not found in any of the Fathers of the Church. Saint John Cassian (c. 360 – 435) presents as the formula used in Egypt for repetitive prayer, not the Jesus Prayer, but "O God, make speed to save me: O Lord, make haste to help me".
By the 14th century, however, on Mount Athos the terms "Hesychasm" and "Hesychast" refer to the practice and to the practitioner of a method of mental ascesis that involves the use of the Jesus Prayer assisted by certain psychophysical techniques. Most likely, the rise of the term "Hesychasm" reflects the coming to the fore of this practice as something concrete and specific that can be discussed.
Books used by the Hesychast include the "Philokalia", a collection of texts on prayer and solitary mental ascesis written from the 4th to the 15th centuries, which exists in a number of independent redactions; the "Ladder of Divine Ascent;" the collected works of St Symeon the New Theologian (949–1022); and the works of St Isaac the Syrian (7th century), as they were selected and translated into Greek at the Monastery of St Savas near Jerusalem about the 10th century.
Hesychastic practice.
Hesychasts are fully integrated into the liturgical and sacramental life of the Orthodox Church, including the daily cycle of liturgical prayer of the Divine Office and the Divine Liturgy. However, Hesychasts who are living as hermits might have a very rare attendance at the Divine Liturgy (see the life of Saint Seraphim of Sarov) and might not recite the Divine Office except by means of the Jesus Prayer (attested practice on Mt Athos). In general, the Hesychast restricts his external activities for the sake of his Hesychastic practice.
Hesychastic practice involves acquiring an inner focus and blocking of the physical senses. In this, hesychasm shows its roots in Evagrius Ponticus and even in the Greek tradition of asceticism going back to Plato. The Hesychast interprets Christ's injunction in the Gospel of Matthew to "go into your closet to pray" to mean that one should ignore the senses and withdraw inward. Saint John of Sinai writes: "Hesychasm is the enclosing of the bodiless primary Cognitive faculty of the soul (Orthodoxy teaches of two cognitive faculties, the nous and logos) in the bodily house of the body." "(Ladder," Step 27, 5, (Step 27, 6 in the Holy Transfiguration edition).)
In Step 27, 21 of the "Ladder" (Step 27, 22–3 of the Holy Transfiguration edition), St John of Sinai describes Hesychast practice as follows:
In this passage, St John of Sinai says that the primary task of the Hesychast is to engage in mental ascesis. This mental ascesis is the rejection of tempting thoughts (the "thieves") that come to the Hesychast as he watches in sober attention in his hermitage. Much of the literature of Hesychasm is occupied with the psychological analysis of such tempting thoughts (e.g. St Mark the Ascetic). This psychological analysis owes much to the ascetical works of Evagrius Pontikos, with its doctrine of the eight passions.
St. John Cassian is not represented in the "Philokalia" except by two brief extracts, but this is most likely due to his having written in Latin. His works "(Coenobitical Institutions" and the "Conferences)" represent a transmittal of Evagrius Pontikos' ascetical doctrines to the West. These works formed the basis of much of the spirituality of the Order of St Benedict and its offshoots. Hence, the tradition of St John Cassian in the West concerning the spiritual practice of the hermit can be considered to be a tradition parallel to that of Hesychasm in the Orthodox Church.
The highest goal of the Hesychast is the experiential knowledge of God. In the 14th century, the possibility of this experiential knowledge of God was challenged by a Calabrian monk, Barlaam, who although he was formally a member of the Orthodox Church had been trained in Western Scholastic theology. Barlaam asserted that our knowledge of God can only be propositional. The practice of the Hesychasts was defended by St. Gregory Palamas. (See below.)
In solitude and retirement, the Hesychast repeats the Jesus Prayer, "Lord Jesus Christ, son of God, have mercy on me, the sinner." The Hesychast prays the Jesus Prayer 'with the heart'—with meaning, with intent, 'for real' (see ontic). He never treats the Jesus Prayer as a string of syllables whose 'surface' or overt verbal meaning is secondary or unimportant. He considers bare repetition of the Jesus Prayer as a mere string of syllables, perhaps with a 'mystical' inner meaning beyond the overt verbal meaning, to be worthless or even dangerous. This emphasis on the actual, real invocation of Jesus Christ mirrors an Eastern understanding of mantra in that physical action/voice and meaning are utterly inseparable.
There is a very great emphasis on humility in the practice of the Jesus Prayer, great cautions being given in the texts about the disaster that will befall the would-be Hesychast if he proceeds in pride, arrogance or conceit. It is also assumed in the Hesychast texts that the Hesychast is a member of the Orthodox Church in good standing.
While he maintains his practice of the Jesus Prayer, which becomes automatic and continues twenty-four hours a day, seven days a week, the Hesychast cultivates watchful attention (Gr. "nepsis)." Sobriety contributes to this mental askesis described above that rejects tempting thoughts; it puts a great emphasis on focus and attention. The Hesychast is to pay extreme attention to the consciousness of his inner world and to the words of the Jesus Prayer, not letting his mind wander in any way at all.
The Hesychast is to attach Eros (Gr. "eros)", that is, "yearning", to his practice of sobriety so as to overcome the temptation to acedia (sloth). He is also to use an extremely directed and controlled anger against the tempting thoughts, although to obliterate them entirely he is to invoke Jesus Christ via the Jesus Prayer.
The Hesychast is to bring his mind (Gr. "nous)" into his heart so as to practise both the Jesus Prayer and sobriety with his mind in his heart. The descent of the mind into the heart is taken quite literally by the practitioners of Hesychasm and is not at all considered to be a metaphorical expression. Some of the psychophysical techniques described in the texts are to assist the descent of the mind into the heart at those times that only with difficulty it descends on its own.
The goal at this stage is a practice of the Jesus Prayer with the mind in the heart, which practice is free of images (see "Pros Theodoulon)." What this means is that by the exercise of sobriety (the mental ascesis against tempting thoughts), the Hesychast arrives at a continual practice of the Jesus Prayer with his mind in his heart and where his consciousness is no longer encumbered by the spontaneous inception of images: his mind has a certain stillness and emptiness that is punctuated only by the eternal repetition of the Jesus Prayer.
This stage is called the "guard of the mind." This is a very advanced stage of ascetical and spiritual practice, and attempting to accomplish this prematurely, especially with psychophysical techniques, can cause very serious spiritual and emotional harm to the would-be Hesychast. St Theophan the Recluse once remarked that bodily postures and breathing techniques were virtually forbidden in his youth, since, instead of gaining the Spirit of God, people succeeded only "in ruining their lungs."
The guard of the mind is the practical goal of the Hesychast. It is the condition in which he remains as a matter of course throughout his day, every day until he dies. It is from the guard of the mind that he is raised to contemplation by the Grace of God.
The Hesychast usually experiences the contemplation of God as light, the Uncreated Light of the theology of St Gregory Palamas. The Hesychast, when he has by the mercy of God been granted such an experience, does not remain in that experience for a very long time (there are exceptions—see for example the "Life" of St Savas the Fool for Christ (14th century), written by St Philotheos Kokkinos (14th century)), but he returns 'to earth' and continues to practise the guard of the mind.
The Uncreated Light that the Hesychast experiences is identified with the Holy Spirit. Experiences of the Uncreated Light are allied to the 'acquisition of the Holy Spirit'. Notable accounts of encounters with the Holy Spirit in this fashion are found in St Symeon the New Theologian's account of the illumination of 'George' (considered a pseudonym of St Symeon himself); in the 'conversation with Motovilov' in the "Life" of St Seraphim of Sarov (1759–1833); and, more recently, in the reminiscences of Elder Porphyrios ("Wounded by Love" pp. 27 – 31).
Orthodox Tradition warns against seeking ecstasy as an end in itself. Hesychasm is a traditional complex of ascetical practices embedded in the doctrine and practice of the Orthodox Church and intended to purify the member of the Orthodox Church and to make him ready for an encounter with God that comes to him when and if God wants, through God's Grace. The goal is to acquire, through purification and Grace, the Holy Spirit and salvation. Any ecstatic states or other unusual phenomena which may occur in the course of Hesychast practice are considered secondary and unimportant, even quite dangerous. Moreover, seeking after unusual 'spiritual' experiences can itself cause great harm, ruining the soul and the mind of the seeker. Such a seeking after 'spiritual' experiences can lead to "spiritual delusion" (Ru. "prelest," Gr. "plani)"—the antonym of sobriety—in which a person believes himself or herself to be a saint, has hallucinations in which he or she 'sees' angels, Christ, etc. This state of spiritual delusion is in a superficial, egotistical way pleasurable, but can lead to madness and suicide, and, according to the Hesychast fathers, makes salvation impossible.
Mount Athos is a centre of the practice of Hesychasm. St Paisius Velichkovsky and his disciples made the practice known in Russia and Romania, although Hesychasm was already previously known in Russia, as is attested by St Seraphim of Sarov's independent practice of it.
Hesychast controversy.
About the year 1337, hesychasm attracted the attention of a learned member of the Orthodox Church, Barlaam, a Calabrian monk who at that time held the office of abbot in the Monastery of St Saviour in Constantinople and who visited Mount Athos. Mount Athos was then at the height of its fame and influence, under the reign of Andronicus III Palaeologus and under the leadership of the "Protos" Symeon. On Mount Athos, Barlaam encountered Hesychasts and heard descriptions of their practices, also reading the writings of the teacher in Hesychasm of St Gregory Palamas, himself an Athonite monk. Trained in Western Scholastic theology, Barlaam was scandalized by hesychasm and began to combat it both orally and in his writings. As a private teacher of theology in the Western Scholastic mode, Barlaam propounded a more intellectual and propositional approach to the knowledge of God than the Hesychasts taught.
Barlaam took exception to the doctrine entertained by the Hesychasts as to the nature of the light, the experience of which was said to be the goal of Hesychast practice, regarding it as heretical and blasphemous. It was maintained by the Hesychasts to be of divine origin and to be identical to the light which had been manifested to Jesus' disciples on Mount Tabor at the Transfiguration. This Barlaam held to be polytheistic, inasmuch as it postulated two eternal substances, a visible and an invisible God.
On the Hesychast side, the controversy was taken up by St Gregory Palamas, afterwards Archbishop of Thessalonica, who was asked by his fellow monks on Mt Athos to defend hesychasm from the attacks of Barlaam. St Gregory himself was well-educated in Greek philosophy. St Gregory defended hesychasm in the 1340s at three different synods in Constantinople, and he also wrote a number of works in its defense.
In these works, St Gregory Palamas uses a distinction, already found in the 4th century in the works of the Cappadocian Fathers, between the energies or operations (Gr. "energeies)" of God and the essence of God. St Gregory taught that the energies or operations of God were uncreated. He taught that the essence of God can never be known by his creature even in the next life, but that his uncreated energies or operations can be known both in this life and in the next, and convey to the Hesychast in this life and to the righteous in the next life a true spiritual knowledge of God. In Palamite theology, it is the uncreated energies of God that illumine the Hesychast who has been vouchsafed an experience of the Uncreated Light.
In 1341, the dispute came before a synod held at Constantinople and presided over by the Emperor Andronicus III; the synod, taking into account the regard in which the writings of the pseudo-Dionysius were held, condemned Barlaam, who recanted and returned to Calabria, afterwards becoming bishop in the Roman Catholic Church.
One of Barlaam's friends, Gregory Akindynos, who originally was also a friend of St Gregory Palamas, took up the controversy, which also played a role in the civil war between the supporters of John Cantacuzenus and John V Palaeologus. Three other synods on the subject were held, at the second of which the followers of Barlaam gained a brief victory. But in 1351 at a synod under the presidency of the Emperor John VI Cantacuzenus, Hesychast doctrine was established as the doctrine of the Orthodox Church.
Roman Catholic views.
While Constantinople experienced a succession of councils alternately approving and condemning doctrine concerning hesychasm considered as identified with Palamism (the last of the five senses in which, according to Kallistos Ware, the term is used), the Western Church held no council in which to make a pronouncement on the issue, and the word "hesychasm" does not appear in the "Enchiridion Symbolorum et Definitionum" (Handbook of Creeds and Definitions), the collection of Roman Catholic teachings originally compiled by Heinrich Joseph Dominicus Denzinger.
The Roman Catholic Church has thus never expressed any condemnation of Palamism, and uses in its liturgy readings from the work of Nicholas Cabasilas, a supporter of Palamas in the controversy that took place in the East. Its Liturgy of the Hours includes extracts from Cabasilas's "Life in Christ" on Tuesday, Wednesday, and Thursday of the Fifth Week of Easter in Year II of the two-year cycle for the Office of Readings.
Western theologians have tended to reject hesychasm, in some instances equating it with quietism, perhaps because "quietism" is the literal translation of "hesychasm". However, according to Kallistos Ware, "To translate 'hesychasm' as 'quietism', while perhaps etymologically defensible, is historically and theologically misleading." Ware asserts that "the distinctive tenets of the 17th-century Western quietists is not characteristic of Greek hesychasm." Elsewhere too, Ware argues that it is important not to translate "hesychasm" as "quietism".
These theologians generally rejected the contention that, in the case of God, the distinction between essence and energies is real rather than, albeit with a foundation in reality, notional (in the mind). In their view, affirming an ontological essence-energies distinction in God contradicted the teaching of the First Council of Nicaea on divine unity. According to Adrian Fortescue, the Scholastic theory that God is pure actuality prevented Palamism from having much influence in the West, and it was from Western Scholasticism that hesychasm's philosophical opponents in the East borrowed their weapons.
In the "Catholic Encyclopedia" of 1909, Simon Vailhé accused Palamas's teachings that humans could achieve a corporal perception of the Divinity and his distinction between God's essence and his energies as "monstrous errors" and "perilous theological theories". He further characterized the Eastern canonization of Palamas's teachings as a "resurrection of polytheism". Fortescue, also writing in the "Catholic Encyclopedia", claimed that "the real distinction between God's essence and operation remains one more principle, though it is rarely insisted on now, in which the Orthodox differ from Catholics".
The later 20th century saw a remarkable change in the attitude of Roman Catholic theologians to Palamas, a "rehabilitation" of him that has led to increasing parts of the Western Church considering him a saint, even if uncanonized. John Meyendorff describes the 20th-century rehabilitation of Palamas in the Western Church as a "remarkable event in the history of scholarship." Andreas Andreopoulos cites the 1910 Catholic Encyclopedia article by Fortescue as an example of how Barlaam's distrustful and hostile attitude regarding hesychasm survived until recently in the West, adding that now "the Western world has started to rediscover what amounts to a lost tradition. Hesychasm, which was never anything close to a scholar's pursuit, is now studied by Western theologians who are astounded by the profound thought and spirituality of late Byzantium."
Some Western scholars maintain that there is no conflict between Palamas's teaching and Roman Catholic thought. Some Western theologians have incorporated the essence-energies distinction into their own thinking.
For example, G. Philips asserts that the essence-energies distinction as presented by Palamas is "a typical example of a perfectly admissible theological pluralism" that is compatible with the Roman Catholic magisterium.
Jeffrey D. Finch claims that "the future of East-West rapprochement appears to be overcoming the modern polemics of neo-scholasticism and neo-Palamism".
According to Kallistos Ware, some Western theologians, both Roman Catholic and Anglican, see the theology of Palamas as introducing an inadmissible division within God; however, others have incorporated his theology into their own thinking, maintaining, as Jeffrey D. Finch reports, that there is no conflict between his teaching and Roman Catholic thought.
Pope John Paul II repeatedly emphasized his respect for Eastern theology as an enrichment for the whole Church, declaring that, even after the painful division between the Christian East and the See of Rome, that theology has opened up profound thought-provoking perspectives of interest to the entire Church. He spoke in particular of the hesychast controversy. The term "hesychasm", he said, refers to a practice of prayer marked by deep tranquillity of the spirit intent on contemplating God unceasingly by invoking the name of Jesus. While from a Catholic viewpoint there have been tensions concerning some developments of the practice, the Pope said, there is no denying the goodness of the intention that inspired its defence, which was to stress that man is offered the concrete possibility of uniting himself in his inner heart with God in that profound union of grace known as "theosis", divinization.
Proposed Biblical and Jewish origins.
According to some of the adepts of the Jewish Merkabah mystical tradition, if one wished to "descend to the Merkabah" one had to adopt the prayer posture taken by the Prophet Elijah in I Kings 18:42, namely to pray with one's head between one's knees. This is the same prayer posture used by the Christian Hesychasts and is the reason that they were mocked by their opponents as "navel gazers" (omphalopsychites). This bodily position and the practice of rhythmically breathing while invoking a divine name seems to be common to both Jewish Merkabah mysticism and Christian Hesychasm. Thus the practice may have origins in the ascetical practices of the biblical prophets.
Alan Segal in his book "Paul the Convert" suggests that the Apostle Paul may have been an early adept of Merkabah mysticism in which case what was novel to Paul's experience of divine light on the road to Damascus was not the experience of divine light itself, but that the source of this divine light identified himself as the Jesus whose followers Paul was persecuting. Daniel Boyarin notes that Paul's own account of this experience would therefore be the earliest first person account of the mystical vision of a Merkabah adept.
In art.
The Jesus Prayer is referred to in J. D. Salinger's pair of stories "Franny and Zooey". It is also a central theme of the 2006 Russian film "Ostrov".

</doc>
<doc id="14405" url="http://en.wikipedia.org/wiki?curid=14405" title="Hemlock">
Hemlock

The word hemlock may refer to:

</doc>
<doc id="14406" url="http://en.wikipedia.org/wiki?curid=14406" title="Harmony Society">
Harmony Society

The Harmony Society was a Christian theosophy and pietist society founded in Iptingen, Germany, in 1785. Due to religious persecution by the Lutheran Church and the government in Württemberg, the group moved to the United States, where representatives initially purchased land in Butler County, Pennsylvania. On February 15, 1805, the group of approximately 400 followers formally organized the Harmony Society, placing all their goods in common.
Under its founder and spiritual leader, Johann Georg Rapp (1757–1847); Frederick (Reichert) Rapp (1775–1834), his adopted son who managed its business affairs; and their associates, the Society existed for one hundred years; roughly from 1805 until 1905. Members were known as Harmonists, Harmonites, or Rappites. The Society is best known for its worldly successes, most notably the establishment of three model communities, the first at Harmony, Pennsylvania; the second, also called Harmony, in the Indiana Territory, now New Harmony, Indiana; and the third and final town at Economy, now Ambridge, Pennsylvania.
Origins in Germany.
Johann Georg Rapp (November 1, 1757 – August 7, 1847), also known as George Rapp, was the founder of the religious sect called Harmonists, Harmonites, Rappites, or the Harmony Society. Born in Iptingen, Duchy of Württemberg, Germany, Rapp was a “bright but stubborn boy” who was also deeply religious. His "strong personality" and religious convictions began to concern local church authorities when he refused to attend church services or take communion. Rapp and his group of believers began meeting in Iptengen and eventually emigrated to the United States, where they established three communities: Harmony, Butler County, Pennsylvania; Harmony (later named New Harmony), Posey County, Indiana; and Economy, Beaver County, Pennsylvania.
Rapp became inspired by the philosophies of Jakob Böhme, Philipp Jakob Spener, Johann Heinrich Jung, and Emanuel Swedenborg, among others, and later wrote "Thoughts on the Destiny of Man", published in German in 1824 and in English a year later, in which he outlined his ideas and philosophy. Rapp lived out his remaining days in Economy, where he died on August 7, 1847, at the age of 89.
By the mid-1780s, Rapp had begun preaching to the Separatists, his followers in Iptengen, who met privately and refused to attend church services or take communion. As their numbers increased, Rapp’s group officially split with the Lutheran Church in 1785 and was banned from meeting. Despite warnings from local authorities, the group continued to meet privately and attract even more followers.
By 1798 Rapp and his group of followers had already begun to distance themselves from mainstream society and intended to establish a new religious congregation of fellow believers. In the Lomersheimer declaration, written in 1798, these religious Separatists presented their statement of faith, based on Christian principles, to the Wurttemberg legislature. Rapp's followers declared their desire to form a separate congregation who would meet in members’ homes, free from Lutheran Church doctrines. The group supported the belief that baptism was not necessary until children could decide for themselves whether they wanted to become a Christian. They also believed that confirmation for youth was not necessary and communion and confession would only be held a few times a year. Although the Separatists supported civil government, the group refused to make a physical oath in its support, "for according to the Gospel not oath is allowed him who gives evidence of a righteous life as an upright man." They also refused to serve in the military or attend Lutheran schools, choosing instead to teach their children at home. This declaration of faith, along with some later additions, guided the Harmony Society's religious beliefs even after they had emigrated from Germany to the United States.
In the 1790s, Rapp’s followers continued to increase, reaching as many as 10,000 to 12, 000 members. The increasing numbers, which included followers outside of Rapp’s village, continued to concern the government, who feared they might become rebellious and dangerous to the state. Although no severe actions were initially taken to repress the Separatists, the group began to consider emigration to France or the United States. In 1803, when the government began to persecute Rapp's followers, he decided to move the entire group to the United States. Rapp and a small group of men left Iptingen in 1803 and traveled to America to find a new home. On May 1, 1804, the first group of emigrants departed for the United States. The initial move scattered the followers and reduced Rapp's original group of 12,000 to just a few followers. Johan Frederich Reichert, who later agreed to become Rapp's adopted son and took the name of Frederick Reichert Rapp, reported in a letter dated February 25, 1804, that there were "at least 100 families or 500 persons actually ready to go" even if they had to sacrifice their property.
Settlements in the United States.
In 1804, while Rapp and his associates remained in the United States looking for a place to settle, his followers sailed to America aboard several vessels and made their way to western Pennsylvania, where they waited until land had been selected for their new settlement. Rapp was able to secure a large tract of land in Pennsylvania and started his first commune, known as Harmonie or Harmony, in Butler County, Pennsylvania, where the Society existed from 1804 to 1815. It soon grew to a population of about 800, and was highly profitable. Ten years later, the town was sold and the Harmonists moved westward to the Indiana Territory, where they established the town of Harmony, now called New Harmony, Indiana, and remained there from 1815 to 1825. The Indiana settlement was sold to Robert Owen and was renamed New Harmony. Ten years after the move to Indiana the commune moved again, this time returning to western Pennsylvania, and named their third and final town Economy ('Ökonomie' in German). The Harmonists lived in Economy until the Society was dissolved in 1905.
Articles of association.
On February 15, 1805, the settlers at Harmony, Pennsylvania, signed articles of association to formally establish the Harmony Society in the United States. In this document, Society members agreed to hold all property in a common fund, including working capital of $23,000 to purchase land, livestock, tools, and other goods needed to establish their town. The agreement gave the Society legal status in the United States and protected it from dissolution. Members contributed all of their possessions, pledged cooperation in promoting the interests of the group, and agreed to accept no pay for their services. In return, the members would receive care as long as they lived with the group. Under this agreement, if a member left the Society, their funds would be returned without interest or, if they had not contributed to the Society's treasury, they would receive a small monetary gift.
The Society was a religious congregation who submitted to submit to spiritual and material leadership under Rapp and his associates and worked together for the common good of all its members. Believing that the Second Coming of Christ would occur during their lifetimes, the Harmonists contented to live simply under a strict religious doctrine, gave up tobacco, and advocated celibacy.
First settlement: Harmony, Pennsylvania.
In December 1804 Rapp and a party of two others initially contracted to purchase 4,500 acre of land for $11,250 in Butler County, Pennsylvania, and later acquired additional land to increase their holdings to approximately 9,000 acre by time they advertised their property for sale in 1814. Here they built the town of Harmony, a small community that had, in 1805, nearly 50 log houses, a large barn, a gristmill, and more than 150 acres of cleared land to grow crops. Because the climate was not well suited for growing grapes and nearby property was not available to expand their landholdings, the Harmonists submitted a petition to the U.S. government for assistance in purchasing land elsewhere. In January 1806 Rapp traveled to Washington, D.C. to hear discussions in Congress regarding the Harmonists’ petition for a grant that would allow them to purchase approximately 30,000 acre acre of land in the Indiana Territory. While the Senate passed the petition on January 29, it was defeated in House of Representatives on February 18. The Harmonists had to find other financial means to support their plans for future expansion. By 1810 the town’s population reached approximately 700, with about 130 houses. The Society landholdings also increased to 7,000 acre. In the years that followed, the Society survived disagreements among its members, while shortages of cash and lack of credit threatened its finances. Still, the young community had a good reputation for its industry and agricultural production.
At Harmony, George Rapp, also known as Father Rapp, was recognized as the spiritual head of the Society, the one that they went to for discussions, confessions, and other matters. Rapp’s adopted son, Frederick, managed the Society’s business and commercial affairs.
Rapp let newcomers into the Society and, after a trial period, usually about a year, they were accepted as permanent members. While new members continued to arrive, including immigrants from Germany, others found the Harmonists' religious life too difficult and left the group. In addition, during a period of religious zeal in 1807 and 1808, most, but not all, of the Harmonists adopted the practice of celibacy and there were also few marriages among the members. Rapp's son, Johannes, was married in 1807; and it was the last marriage on record until 1817. Although Rapp did not entirely bar sex initially, it gradually became a custom and there were few births in later years.
In 1811 Harmony's population rose to around 800 persons involved in farming and various trades. Although profit was not a primary goal, their finances improved and the enterprise was profitable, but not sufficient to carry out their planned expansions. Within a few years of their arrival, the Harmonist community included an inn, a tannery, warehouses, a brewery, several mills, stables, and barns, a church/meetinghouse, a school, additional dwellings for members, a labyrinth, and workshops for different trades. In addition, more land was cleared for vineyards and crops. The Harmonists also produced yarn and cloth.
Several factors led to the Harmonists’ decision to leave Butler County. Because the area's climate was not suitable, they had difficulties growing grapes for wine. In addition, as westward migration brought new settlers to the county, making it less isolated, the Harmonists began having troubles with neighbors who were not part of the Society. By 1814 Butler County's growing population and rising land prices made it difficult for the Society to expand, causing the group's leaders to look for more land elsewhere. Once land had been located that offered a better climate and room to expand, the group began plans to move. In 1814 the Harmonites sold their first settlement to Abraham Ziegler, a Mennonite, for $100,000 and moved west to make a new life for themselves in the Indiana Territory.
Second settlement: Harmony, Indiana.
In 1814 the Harmony Society moved to the Indiana Territory, where it initially acquired approximately 3,500 acre of land along the Wabash River in Posey County and later acquired more. Over the next ten years the Society built a thriving new community they called Harmonie or Harmony on the Wabash in the Indiana wilderness. (The town's name was changed to New Harmony after the Harmonists left in 1824.) The Harmonists entered into agriculture and manufacture on a larger scale than they had done in Pennsylvania. When the Harmonists advertised their Indiana property for sale in 1824, they had acquired 20,000 acre of land, 2,000 acre of which was under cultivation.
During the summer and fall of 1814, many Harmonists fell sick from fever (malaria) and work on the new town nearly ceased. During this time the Society lost about 120 people and others fell ill until conditions were improved and the swamps around the area were drained. Despite these illnesses, construction of the new town continued. By 1819 the Harmonites had built 150 log homes, a church, a community storehouse, barns, stables, and a tavern, along with thriving shops and mills, and cleared land for farming. As the new settlement in Indiana grew, it also began to attract new arrivals, including emigrants from Germany, who expected the Harmonists to pay for their passage to America.
Visitors to the new town commented on its growing commercial and industrial work. In 1819 the town had a steam-operated wool carding and spinning factory, a brewery, distillery, vineyards, and a winery, but not all visitors were impressed with the growing communist town on the frontier. The Society also had visitors from another communal religious society, the Shakers. In 1816 meetings between the Shakers and Harmonists considered a possible union of the two societies, but religious differences between the two groups halted the union. Members of the groups remained, however, in contact over the years. George Rapp's daughter and others lived for a time at the Shaker settlement in West Union, Indiana, where the Shakers helped a number of Harmonites learn the English language.
The Harmonist community continued to thrive during the 1820s. The Society shipped its surplus agricultural produce and manufactured goods throughout the Ohio and Mississippi valleys or sold them through their stores at Harmony and Shawneetown and their agents in Pittsburgh, Saint Louis, Louisville, and elsewhere. Under Frederick Rapp's financial management the Society prospered, but he soon wished for a location better suited to manufacturing and commercial purposes. They had initially selected the land near the Wabash River for its isolation and opportunity for expansion, but the Harmonites were now a great distance from the eastern markets and trade in this location wasn't to their liking. They also had to deal with unfriendly neighbors. As abolitionists, the Harmonites faced disagreeable elements from slavery supporters in Kentucky, only 15 mi away, which caused them much annoyance. By 1824 the decision had been made to sell their property in Indiana and search for land to the east.
On January 3, 1825, the Harmonists and Robert Owen, a Welsh-born industrialist and social reformer, came to a final agreement for the sale of the Society's land and buildings in Indiana for $150,000. Owen named the town New Harmony, and by May, the last of the Harmony Society's remaining members returned to Pennsylvania.
Third settlement: Economy, Pennsylvania.
In 1824 Frederick Rapp initially purchased 1,000 acre along the Ohio River, 18 mi northwest of Pittsburgh, Pennsylvania, for $10,000, and later bought an additional 2,186 acre for $33,445, giving the Society more than 3,000 acre to develop into a new community. The Harmonites named their third and last town Economy, after the spiritual notion of the Divine Economy, “a city in which God would dwell among men” and where perfection would be attained.
At Economy the Harmonists intended to become more involved in manufacturing and their new town on the Ohio River provided better access to eastern markets and water access to the south and west than they had in Indiana. By 1826 the Harmonists had woolen and cotton mills in operation as well as a steam-operated grain mill. The Harmonist society also ran a wine press, a hotel, post office, saw mills, stores, and a variety of farms. Here, under the business acumen and efficient management of Frederick Rapp, they enjoyed such prosperity that by 1829 they dominated trade and the markets of Pittsburgh and down the Ohio River. The Harmonists' competitors accused them of creating a monopoly and called on state government to dissolve the group. Despite the attacks, the Harmonists developed Economy into a prosperous factory town, engaged in farming on a large scale, and maintained a brewery, distillery, and wine-making operation. They also pioneered the manufacturing of silk in the United States.
The community was not neglectful of matters pertaining to art and culture. Frederick Rapp purchased artifacts and installed a museum containing fine paintings and many curiosities and antiques, but it proved to be unprofitable and was sold at a loss. In addition, the Harmonists maintained a deer park, a floral park, and a maze, or labyrinth. The Harmonists were fond of music and many of the members were accomplished musicians. They sang, had a band/orchestra, composed songs, and gave much attention to its cultivation. By 1830 they had amassed a 360-volume library.
In 1832 the Society suffered a serious division. Of 750 members, 250 became alienated through the influence of Bernhard Müller (self-styled Count de Leon), who, with 40 followers (also at variance with the authorities in the old country), had come to Economy to affiliate with the Society. Rapp and Leon could not agree; a separation and apportionment of the property were therefore agreed upon. This secession of one-third of the Society, which consisted mostly of the flower of young manhood and young womanhood who did not want to maintain the custom of celibacy, broke Frederick's heart. He died within two years. It resulted in a considerable fracturing of the community. Nevertheless, the Society remained prosperous in business investments for many more years to come.
After Frederick Rapp's death in 1834, George Rapp appointed Romelius Baker and Jacob Henrici as trustees to manage the Society’s business affairs. After George Rapp's death in 1847, the Society reorganized. While a board of elders was elected for the enforcement of the Society's rules and regulations, business management passed to its trustees: Baker and Henrici, 1847–68; Henrici and Jonathan Lenz, 1869–90; Henrici and Wolfel, 1890; Henrici and John S. Duss, 1890–1892; Duss and Seiber, 1892–1893; Duss and Reithmuller, 1893–1897;Duss, 1897–1903; and finally to Suzanna (Susie) C. Duss in 1903. By 1905 membership had dwindled to just three members and the Society was dissolved.
The settlements at Economy remained economically successful until the late 19th century, producing many goods in their cotton and woolen factories, sawmill, tannery, and from their vineyards and distillery. They also produced high quality silk for garments. Rapp's granddaughter, Gertrude, began the silk production in Economy on a small scale from 1826 to 1828, and later expanded. This was planned in New Harmony, but fulfilled when they arrived at Economy. The Harmonists were industrious and utilized the latest technologies of the day in their factories. Because the group chose to adopt celibacy and their members grew older, more work gradually had to be hired out. As their membership declined, they stopped manufacturing operations, other than what they needed for themselves, and began to invest in other ventures such as the oil business, coal mining, timber, railroads, land development, and banking. The group invested in the construction of the Pittsburgh and Lake Erie Railroad, established the Economy Savings Institution and the Economy Brick Works, and operated the Economy Oil Company, as well as the Economy Planing Mill, Economy Lumber Company, and eventually donated some land in Beaver Falls for the construction of Geneva College. The Society exerted a major influence on the economic development of Western Pennsylvania.
Oil production in the mid-1860s brought the high-water mark of the Society's prosperity. By the close of Baker's administration in 1868, The Society's wealth was probably $2 million. By 1890, however, the Society was in debt and on the verge of bankruptcy with a depleted and aged membership. In addition, the Society faced litigation from previous members and would-be heirs. The Society's trustee, John S. Duss, settled the lawsuits, liquidated its business ventures, and paid the Society's indebtedness. The great strain which he had undergone at this time undermined his health and he resigned his trusteeship in 1903. With only a few members left, the remaining land and assets were sold under the leadership of Duss's wife, Susanna (Susie), and the Society was formally dissolved in 1905. At the time of the Society’s dissolution, its net worth was $1.2 million.
In 1916 the Commonwealth of Pennsylvania acquired 6 acre and 17 buildings of Economy, which became the Old Economy Village historic site. The American Bridge Company had already acquired other parts of the Society's land in 1902 to build the town of Ambridge.
Characteristics.
Religious views.
In 1791 George Rapp said, "I am a prophet, and I am called to be one" in front of the civil affairs official in Maulbronn, Germany, who promptly had him imprisoned for two days and threatened with exile if he did not cease preaching. To the great consternation of church and state authorities, this mere peasant from Iptingen had become the outspoken leader of several thousand Separatists in the southern German duchy of Württemberg. By 1802 the Separatists had grown in number to about 12,000 and the Württemberg government decided that they were a dangerous threat to social order. Rapp was summoned to Maulbronn for an interrogation, and the government confiscated Separatist books. When released in 1803, from a brief time in prison, Rapp told his followers to pool their assets and follow him on a journey for safety to the "land of Israel" in the United States, and soon over 800 people were living with him there.
The Harmonites were Christian pietist Separatists who split from the Lutheran Church in the late 18th century. Under the leadership of George Rapp, the group left Württemberg, Germany, and came to the United States in 1803. Due to the troubles they had in Europe, the group sought to establish a more perfect society in the American wilderness. They were nonviolent pacifists who refused to serve in the military and tried to live by George Rapp's philosophy and literal interpretations of the New Testament. They first settled and built the town of Harmony, Pennsylvania, in 1804, and established the Harmony Society in 1805 as a religious commune. In 1807, celibacy was advocated as the preferred custom of the community in an attempt to purify themselves for the coming Millennium. Rapp believed that the events and wars going on in the world at the time were a confirmation of his views regarding the imminent Second Coming of Christ, and he also viewed Napoleon as the Antichrist. In 1814, the Society sold their first town in Pennsylvania and moved to the Indiana Territory, where they built their second town. In 1824, they decided it was time to leave Indiana, sold their land and town in Indiana, and moved to their final settlement in Western Pennsylvania.
The Harmonites were Millennialists, in that they believed Jesus Christ was coming to earth in their lifetime to help usher in a thousand-year kingdom of peace on earth. This is perhaps why they believed that people should try to make themselves "pure" and "perfect", and share things with others while willingly living in communal "harmony" (Acts 4:32-35) and practicing celibacy. They believed that the old ways of life on earth were coming to an end, and that a new perfect kingdom on earth was about to be realized.
They also practiced forms of Esoteric Christianity, Mysticism (Christian mysticism), and Rapp often spoke of the virgin spirit or Goddess named Sophia in his writings. Rapp was very influenced by the writings of Jakob Böhme, Philipp Jakob Spener, and Emanuel Swedenborg, among others. Also, at Economy, there are glass bottles and literature that seem to indicate that the group was interested in (and practiced) alchemy. Other books found in the Harmony Society's library in Economy, include those by the following authors: Christoph Schütz, Gottfried Arnold, Justinus Kerner, Thomas Bromley, Jane Leade, Johann Scheible ("Sixth and Seventh Books of Moses"), Paracelsus, and Georg von Welling, among others.
The Harmonites tended to view unmarried celibate life as morally superior to marriage, based on Rapp's belief that God had originally created Adam as a dual being, having male and female sexual organs. According to this view, when the female portion of Adam separated to form Eve, disharmony followed, but one could attempt to regain harmony through celibacy.
George Rapp predicted that on September 15, 1829, the three and one half years of the Sun Woman would end and Christ would begin his reign on earth. Dissension grew when Rapp's predictions did not come to pass. In March 1832, one third of the group left the Society and some began following Bernhard Müller, who claimed to be the Lion of Judah. Nevertheless, most of the group stayed and Rapp continued to lead them until he died on August 7, 1847. His last words to his followers were, "If I did not so fully believe, that the Lord has designated me to place our society before His presence in the land of Canaan, I would consider this my last".
The Harmonites did not mark their graves with headstones or grave markers, because they thought it was unnecessary to do so; however, one exception is George Rapp's son Johannes' stone marker in Harmony, Pennsylvania, which was installed by non-Harmonites many years after the Harmonites left that town. Today, Harmonist graveyards are fenced in grassy areas with signs posted nearby explaining this practice.
Architecture.
The Harmony Society's architecture reflected their Swabian German traditions, as well as the styles that were being developed in America during the 19th century. In the early days of the Society, many of the homes were initially log cabins and later, Harmonist craftsmen built timber-frame homes. At Economy, their homes were mostly two-story brick houses "that showed the influence of their American neighbors." In general, Harmonist buildings, in addition to being sturdy and functional, were centrally heated, economical to maintain, and resistant to fire, weather, and termites.
Once established at Harmony, Pennsylvania, the Society planned to replace the log dwellings with brick structures, but the group moved to the Indiana Territory before the plan was completed. In Indiana, log homes were soon replaced with one- or two-story houses of timber frame or brick construction in addition to four large rooming houses (dormitories) for its growing membership. The new town also included shops, schools, mills, a granary, a hotel, library, distilleries, breweries, a brick kiln, pottery ovens, barn, stables, storehouses, and two churches, one of which was brick.
In 1822 William Herbert, a visitor to Harmony, Indiana, described the new brick church and the Harmonists' craftsmanship:
"These people exhibit considerable taste as well as boldness of design in some of their works. They are erecting a noble church, the roof of which is supported in
the interior by a great number of stately columns, which have been turned from
trees in their own forests. The kinds of wood made use of for this purpose are, I
am informed, black walnut, cherry and sassafras. Nothing I think can exceed the
grandeur of the joinery and the masonry and brickwork seem to be of the first
order. The form of this church is that of a cross, the limbs being short and equal;
and as the doors, which there are four, are placed at the end of the limbs, the
interior of the building as seen from the entrance, has a most ample and spacious effect... I could scarcely imagine myself to be in the woods of Indiana, on the borders of the Wabash, while pacing the long resounding aisles, and surveying the stately colonnades of this church."
Frame structures were built on piers to keep the air circulating across the area's damp soil, while brick structures had a root cellar with a drainage tunnel. Inside, Harmonists built fireplaces to the left or right of center to allow for a long center beam, adding strength to support the structure and its heavy, shingled roof. "Dutch biscuits" (wood laths wrapped in straw and mud) provided insulation and soundproofing between the ceiling and floors. The exterior was insulated with bricks between the exterior's unpainted weatherboards and the interior's lath and plaster walls. Structures had standard parts and pre-cut, pre-measured timbers, which were assembled on the ground, adjusted to fit on site, raised in place, and locked into place with pegs and mortise and tenon joints. Two-story floor plans for homes included a large living room, kitchen, and entrance hall, with stairs to the second floor and attic. In Indiana, Harmonists did their baking in communal ovens, so stoves could be substituted for fireplaces.
Living styles.
At Harmony, Pennsylvania, four to six members were assigned to a home, where they lived as families, although not all those living in the household were related. Even when the house contained those that were married, they would live together as brother and sister, since there was a suggestion and custom of practicing celibacy. In Indiana, Harmonists continued to live in homes, but they also built dormitories to house single men and women.
Society members woke between 5 a.m. and 6 a.m. They ate breakfast between 6 a.m. and 7 a.m., lunch at 9 a.m., dinner at noon, afternoon lunch at 3 p.m., and supper between 6 p.m. and 7 p.m. They did their chores and work during the day. At the end of the day, members met for meetings and had a curfew of 9 p.m. On Sundays, the members respected the "Holy day" and did no unnecessary work, but attended church services, singing groups, and other social activities.
Clothing.
Their style of dress reflected their Swabian German roots and traditions and was adapted to their life in America. Although the Harmonites typically wore plain clothing, made with their own materials by their own tailors, they would wear their fine garments on Sundays and on other special occasions. At Economy, on special occasions and Sundays, women wore silk dresses using fabric of their own manufacture. Clothing varied in color, but often carried the same design. On a typical day, women wore ankle-length dresses, while men wore pants with vests or coats and a hat.
Technology.
The Harmonites were a prosperous agricultural and industrial people. They had many machines that helped them be successful in their trades. They even had steam-powered engines that ran the machines at some of their factories in Economy. They kept their machines up to date, and had many factories and mills.
Work.
Each member of the Society had a job in a certain craft or trade. Most of the work done by men consisted of manual labor, while the women dealt more with textiles or agriculture.
As Economy became more technologically developed, Harmonites began to hire others from outside the Society, especially when their numbers decreased because of the custom of celibacy and as they eventually let fewer new members join. Although the Harmonites did seek work-oriented help from the outside, they were known as a community that supported themselves, kept their ways of living in their community, mainly exported goods, and tried to import as little as possible.
Rise and fall of Harmony Society.
George Rapp had an eloquent style, which matched his commanding presence, and he was the personality that led the group through all the different settlements. After Rapp's death in 1847, a number of members left the group because of disappointment and disillusionment over the fact that his prophecies regarding the return of Jesus Christ in his lifetime were not fulfilled. However, many stayed in the group, and the Harmony Society went on to become an even more profitable business community that had many worldly financial successes under the leadership of Romelius L. Baker and Jacob Henrici.
Over time the group became more protective of itself, did not allow many new members, moved further from its religious foundation to a more business-oriented and pragmatic approach, and the custom of celibacy eventually drained it of its membership. The land and financial assets of the Harmony Society were sold off by the few remaining members under the leadership of John Duss and his wife, Susanna, by the year 1906.
Today, many of the Society's remaining buildings are preserved; all three of their settlements in the United States have been declared National Historic Landmark Districts by the National Park Service.
Harmony lives on in name at Twin Oaks Community, a contemporary intentional community of 100 people in Virginia. Twin Oaks names all of its buildings after defunct communities, and "Harmony" is the name of one of the residences which also houses the community woodshop and main laundry area.

</doc>
<doc id="14408" url="http://en.wikipedia.org/wiki?curid=14408" title="Huneric">
Huneric

Huneric or Honeric (died December 23, 484) was King of the Vandals (477–484) and the oldest son of Genseric. He dropped the imperial politics of his father and concentrated mainly on internal affairs. He was married to Eudocia, daughter of western Roman Emperor Valentinian III (419–455) and Licinia Eudoxia. She left him, probably in 472. She had one son by him, Hilderic.
Huneric was the first Vandal king who used the title "King of the Vandals and Alans". Despite adopting this style, and that the Vandals maintained their sea-power and their hold on the islands of the western Mediterranean Sea, Huneric did not have the prestige that his father Genseric had enjoyed with other states.
His reign.
Although Huneric was a fervent adherent to Arianism, his reign opened with making a number of positive overtures towards the local Roman population. Following the visit of a diplomatic mission from the Eastern Roman Empire led by Alexander, Huneric restored properties seized by his father from the merchants of Carthage. He also lifted the policy of persecuting the local Catholics, allowing them to hold a synod wherein they elected a new Catholic bishop of Carthage, Eugenius, after a vacancy of 24 years. However, not long after the ordination of Eugenius Huneric reversed himself and began to once again persecute Catholics. Furthermore, he tried to make Catholic property fall to the state, but when this caused too much protest from the Eastern Roman Emperor, he chose to banish a number of Catholics to a faraway province instead. On February 1, 484 he organized a meeting of Catholic bishops with Arian bishops, but on February 24, 484 he forcibly removed the Catholic bishops from their offices and banished some to Corsica. A few were martyred, including the former proconsul Victorian along with Frumentius and other wealthy merchants, who were killed at Hadrumetum after refusing to become Arians. 
Additionally, Huneric murdered many members of the Hasdingi dynasty and also persecuted Manichaeans. He was succeeded by his nephew Gunthamund (reigned 484–496), and because of his cruelty was little mourned by either the Vandals or their subjects.
Towards the end of his reign, the Moors in the Aurès Mountains (in modern-day Algeria) successfully rebelled from Vandal rule. 

</doc>
<doc id="14409" url="http://en.wikipedia.org/wiki?curid=14409" title="Hasdingi">
Hasdingi

The Hasdingi were the southern tribes of the Vandals, an East Germanic tribe. They lived in areas of today's southern Poland, western Ukraine, Slovakia and Hungary. They were part of the migratory movements of the Vandals, into the Iberian peninsula and later on to North Africa.
The Hasdingi crossed the Rhine into Gaul in 406 AD, although their king Godigisel lost his life in battle against the Franks during the crossing. The Hasdingi settled as foederati in Gallaecia (today Galicia, Asturias and the north of Portugal) along with the Suebi.in 409 AD.
Gunderic, Godegisel's successor as king of the Hasdingi, lost his kingdom to king Hermeric of the Suebi after the Battle of the Nervasos Mountains against an allied force of Suebi and Romans in 419. He fled to Baetica with his army where he also became king of the Silingi Vandals and of the Alans. Gunderic was succeeded by his brother Genseric in 428 AD, who subsequently fled from Iberia to North Africa where he established a kingdom at Carthage.

</doc>
<doc id="14410" url="http://en.wikipedia.org/wiki?curid=14410" title="Hermes">
Hermes

Hermes (; Greek: Ἑρμῆς) is an Olympian god in Greek religion and mythology, son of Zeus and the Pleiad Maia. He is second youngest of the Olympian gods.
Hermes is a god of transitions and boundaries. He is quick and cunning, and moves freely between the worlds of the mortal and divine, as emissary and messenger of the gods, intercessor between mortals and the divine, and conductor of souls into the afterlife. He is protector and patron of travelers, herdsmen, thieves, orators and wit, literature and poets, athletics and sports, invention and trade. In some myths he is a trickster, and outwits other gods for his own satisfaction or the sake of humankind. His attributes and symbols include the herma, the rooster and the tortoise, purse or pouch, winged sandals, winged cap, and his main symbol is the herald's staff, the Greek "kerykeion" or Latin "caduceus" which consisted of two snakes wrapped around a winged staff.
In the Roman adaptation of the Greek pantheon (see "interpretatio romana"), Hermes is identified with the Roman god Mercury, who, though inherited from the Etruscans, developed many similar characteristics, such as being the patron of commerce.
Etymology.
The earliest form of the name "Hermes" is the Mycenaean Greek *hermāhās, written 𐀁𐀔𐁀 "e-ma-a2" ("e-ma-ha") in the Linear B syllabic script. Most scholars derive "Hermes" from Greek ἕρμα "herma", "prop, heap of stones, boundary marker", from which the word "hermai" ("boundary markers dedicated to Hermes as a god of travelers") also derives. The etymology of ἕρμα itself is unknown (probably not an Indo-European word). R. S. P. Beekes rejects the connection with "herma" and suggests a Pre-Greek origin.
The words Hermes and hermeneutics both have the same root, this being hermeneus.
I should imagine that the name Hermes has to do with speech, and signifies that he is the interpreter (ermeneus)—Socrates in Plato - "Cratylus"
Plato offers a Socratic folk-etymology for Hermes's name, deriving it from the divine messenger's reliance on "eirein" (the power of speech). Scholarly speculation that "Hermes" derives from a more primitive form meaning "one cairn" is disputed. In Greek a lucky find is a "hermaion".
It is also suggested that Hermes is cognate of the Vedic Sarama.
Mythology.
Early Greek sources.
Homer and Hesiod.
Homer and Hesiod portrayed Hermes as the author of skilled or deceptive acts, and also as a benefactor of mortals. In the "Iliad" he was called "the bringer of good luck," "guide and guardian" and "excellent in all the tricks." He was a divine ally of the Greeks against the Trojans. However, he did protect Priam when he went to the Greek camp to retrieve the body of his son Hector, and he accompanies them back to Troy.
He also rescued Ares from a brazen vessel where he had been imprisoned by Otus and Ephialtes. In the "Odyssey" he helped his great-grand son, the protagonist, Odysseus, informing him about the fate of his companions, who were turned into animals by the power of Circe, and instructed him to protect himself by chewing a magic herb; he also told Calypso Zeus' order for her to free the same hero from her island to continue his journey back home. When Odysseus killed the suitors of his wife, Hermes led their souls to Hades. In "The Works and Days", when Zeus ordered Hephaestus to create Pandora to disgrace humanity by punishing the act of Prometheus giving fire to man, every god gave her a gift, and Hermes's gift was lies and seductive words, and a dubious character. Then he was instructed to take her as wife to Epimetheus.
Aeschylus.
Aeschylus wrote in "The Eumenides" that Hermes helped Orestes kill Clytemnestra under a false identity and other stratagems, and also said that he was the god of searches, and those who seek things lost or stolen. In "Philoctetes", Sophocles invokes Hermes when Odysseus needs to convince Philoctetes to join the Trojan War on the side of the Greeks, and in Euripides' Rhesus Hermes helps Dolon spy on the Greek navy.
Aesop.
Aesop featured him in several of his fables, as ruler of the gate of prophetic dreams, as the god of athletes, of edible roots, and of hospitality. He also said that Hermes had assigned each person his share of intelligence.
The hymn to Hermes.
The hymn to Hermes invokes him as the one "of many shifts ("polytropos"), blandly cunning, a robber, a cattle driver, a bringer of dreams, a watcher by night, a thief at the gates, one who was soon to show forth wonderful deeds among the deathless gods." Hermes, as an inventor of fire, is a parallel of the Titan Prometheus. In addition to the lyre, Hermes was believed to have invented many types of racing and the sports of wrestling and boxing, and therefore was a patron of athletes.
In 1820 Shelley translated this hymn.
HG. Evelyn-White' (d.1924) translation,published 1914, is used on the Perseus Project.
Hellenistic Greek sources.
Several writers of the Hellenistic period expanded the list of Hermes's achievements. Callimachus said that Hermes disguised himself as a cyclops to scare the Oceanides and was disobedient to his mother. One of the Orphic Hymns Khthonios is dedicated to Hermes, indicating that he was also a god of the underworld. Aeschylus had called him by this epithet several times. Another is the Orphic Hymn to Hermes, where his association with the athletic games held in tone is mystic.
Phlegon of Tralles said he was invoked to ward off ghosts, and Pseudo-Apollodorus reported several events involving Hermes. He participated in the Gigantomachy in defense of Olympus; was given the task of bringing baby Dionysus to be cared for by Ino and Athamas and later by nymphs of Asia, followed Hera, Athena and Aphrodite in a beauty contest; favored the young Hercules by giving him a sword when he finished his education and lent his sandals to Perseus. The Thracian princes identified him with their god Zalmoxis, considering his ancestor.
Anyte of Tegea of the 3rd century BC, in translation by R Aldington, wrote:I Hermes stand here at the crossroads by the wind beaten orchard, near the hoary grey coast; and I keep a resting place for weary men. And the cool stainless spring gushes out.
called "Hermes of the Ways" after the patronage of travellers.
Epithets of Hermes.
Kriophoros.
In ancient Greek cult, kriophoros (Greek: κριοφόρος) or criophorus, the "ram-bearer," is a figure that commemorates the solemn sacrifice of a ram. It becomes an epithet of Hermes: Hermes Kriophoros
Argeiphontes.
Hermes's epithet Ἀργειφόντης "Argeiphontes" (Latin: "Argicida"), meaning "Argus-slayer", recalls his slaying of the hundred-eyed giant Argus Panoptes, who was watching over the heifer-nymph Io in the sanctuary of Queen Hera herself in Argos. Hermes placed a charm on Argus's eyes with the caduceus to cause the giant to sleep, after this he slew the giant. Argus' eyes were then put into the tail of the peacock, symbol of the goddess Hera.
Messenger and guide.
... Oh mighty messenger of the gods of the upper and lower worlds ... (Aeschylus).
 Explicitly, at least in sources of classical writings, of Euripides "Electra" and "Iphigenia in Aulis" and in Epictetus "Discourses". According to Blackwood's Edinburgh magazine (1849) the chief office of the God was as messenger.
The messenger divine and herald of the Gods, he wears the gifts from his father, the Petasus and Talaria ...
and also
the factor of travelling or motion with or without others with respect to the physical landscape, or the landscape of the soul
, is the core attribute of the god as messenger and guide
Dolios.
No cult to Hermes Dolios existed in Attica,of this Athens being the capital, and so this form of Hermes seems to have existed in speech only.
The god is ambiguous.
According to prominent folklorist Yeleazar Meletinsky, Hermes is a deified trickster. - god (or patron guidance) and master of thieves ("a plunderer, a cattle-raider, a night-watching" - in Homers' "Hymns")...
and deception (Euripides) and (possibly evil) tricks and trickeries, crafty (from "lit". god of craft), "the cheat", god of stealth because his stealthiness is always used to benevolent ends, Homer deemed the god: 
friendliest to man
and cunning, (see also, to act secretively as "kleptein", in reference - "EL Wheeler"), of treachery, "the schemer", wily, was worshipped at Pellene [Pausanias, vii. 27, 1]), and invoked through Odysseus.
(As the ways of gain are not always the ways of honesty and straightforwardness, Hermes obtains a bad character and an in-moral (amoral [ed.]) cult as Dolios)—
Hermes is "amoral" like a baby. although Zeus sent Hermes as a teacher to humanity to teach them knowledge of and value of justice and to improve inter-personal relationships ("bonding between mortals").
Considered to have a mastery of rhetorical persuasion and "special pleading", the god typically has nocturnal "". Hermes knows the boundaries and crosses the borders of them to confuse their definition.
The meaning of the word is part "to trick".
Thief.
In the Lang translation of Homer' Hymn to Hermes, the god after being born is described as a "robber" and "a captain of raiders", a "thief of the gates".
According to the late Jungian psychotherapist López-Pedraza, everything Hermes thieves, he later sacrifices to the gods.
patron of thieves.
Autolykus received his skills as the greatest of thieves due to sacrificing to Hermes as his patron.
Additional.
Other epithets included:
Worship and cult.
Prior to being known as Hermes, Frothingham thought the god to have existed as a snake-god. Angelo (1997) thinks Hermes to be based on the Thoth archetype. The absorbing ("combining") of the attributes of Hermes to Thoth developed after the time of Homer amongst Greek and Roman; Herodotus was the first to identify the Greek god with the Egyptian (Hermopolis), Plutarch and Diodorus also, although Plato thought the gods to be dis-similar (Friedlander 1992).
A cult was established in Greece in remote regions, likely making him a god of nature, farmers, and shepherds. It is also possible that since the beginning he has been a deity with shamanic attributes linked to divination, reconciliation, magic, sacrifices, and initiation and contact with other planes of existence, a role of mediator between the worlds of the visible and invisible.
During the 3rd century BC, a communication between Petosiris (a priest) to King Nechopso, probably written in Alexandria c. 150 BC, states Hermes is the teacher of all secret wisdoms available to knowing by the experience of religious ecstasy.
Due to his constant mobility, he was considered the god of commerce and social intercourse, the wealth brought in business, especially sudden or unexpected enrichment, travel, roads and crossroads, borders and boundary conditions or transient, the changes from the threshold, agreements and contracts, friendship, hospitality, sexual intercourse, games, data, the draw, good luck, the sacrifices and the sacrificial animals, flocks and shepherds and the fertility of land and cattle. In addition to serving as messenger to Zeus, Hermes carried the souls of the dead to Hades, and directed the dreams sent by Zeus to mortals.
Temples.
One of the oldest places of worship for Hermes was Mount Cyllene in Arcadia, where the myth says that he was born. Tradition says that his first temple was built by Lycaon. From there the cult would have been taken to Athens, and then radiate to the whole of Greece, according to Smith, and his temples and statues became extremely numerous. Lucian of Samosata said he saw the temples of Hermes everywhere.
In many places, temples were consecrated in conjunction with Aphrodite, as in Attica, Arcadia, Crete, Samos and in Magna Graecia. Several ex-votos found in his temples revealed his role as initiator of young adulthood, among them soldiers and hunters, since war and certain forms of hunting were seen as ceremonial initiatory ordeals. This function of Hermes explains why some images in temples and other vessels show him as a teenager.
As a patron of the gym and fighting, Hermes had statues in gyms and he was also worshiped in the sanctuary of the Twelve Gods in Olympia, where Greeks celebrated the Olympic Games. His statue was held there on an altar dedicated to him and Apollo together.
A temple within the Aventine was consecrated in 495 BC.
Symbols of Hermes were the palm tree, turtle, rooster, goat, the number four, several kinds of fish, incense. Sacrifices involved honey, cakes, pigs, goats, and lambs. In the sanctuary of Hermes Promakhos in Tanagra is a strawberry tree under which it was believed he had created, and in the hills Phene ran three sources that were sacred to him, because he believed that they had been bathed at birth.
Festival.
Hermes's feast was the special Hermaea was celebrated with sacrifices to the god and with athletics and gymnastics, possibly having been established in the 6th century BC, but no documentation on the festival before the 4th century BC survives. However, Plato said that Socrates attended a Hermaea. Of all the festivals involving Greek games, these were the most like initiations because participation in them was restricted to young boys and excluded adults.
Hermai/Herms.
In Ancient Greece, Hermes was a phallic god of boundaries. His name, in the form "herma," was applied to a wayside marker pile of stones; each traveller added a stone to the pile. In the 6th century BCE, Hipparchos, the son of Pisistratus, replaced the cairns that marked the midway point between each village "deme" at the central "agora" of Athens with a square or rectangular pillar of stone or bronze topped by a bust of Hermes with a beard. An erect phallus rose from the base. In the more primitive Mount Kyllini or Cyllenian herms, the standing stone or wooden pillar was simply a carved phallus. In Athens, herms were placed outside houses for good luck. "That a monument of this kind could be transformed into an Olympian god is astounding," Walter Burkert remarked.
In 415 BCE, when the Athenian fleet was about to set sail for Syracuse during the Peloponnesian War, all of the Athenian hermai were vandalized one night. The Athenians at the time believed it was the work of saboteurs, either from Syracuse or from the anti-war faction within Athens itself. Socrates' pupil Alcibiades was suspected of involvement, and Socrates indirectly paid for the impiety with his life.
Hermes's possible offspring.
Pan.
The satyr-like Greek god of nature, shepherds and flocks, Pan, could possibly be the son of Hermes through the nymph Dryope. In the Homeric Hymn to Pan, Pan's mother fled in fright from her newborn son's goat-like appearance.
Priapus.
Depending on the sources consulted, the god Priapus could be understood as a son of Hermes.
Autolycus.
Autolycus, the Prince of Thieves, was a son of Hermes and Chione (mortal) and grandfather of Odysseus.
Art and iconography.
The image of Hermes evolved and varied according to Greek art and culture. During Archaic Greece he was usually depicted as a mature man, bearded, dressed as a traveler, herald, or pastor. During Classical and Hellenistic Greece he is usually depicted young and nude, with athleticism, as befits the god of speech and of the gymnastics, or a robe, a formula is set predominantly through the centuries. When represented as Logios (speaker), his attitude is consistent with the attribute. Phidias left a statue of a famous Hermes Logios and Praxiteles another, also well known, showing him with the baby Dionysus in his arms. At all times, however, through the Hellenistic periods, Roman, and throughout Western history into the present day, several of his characteristic objects are present as identification, but not always all together.
Among these objects is a wide-brimmed hat, the Petasos, widely used by rural people of antiquity to protect themselves from the sun, and that in later times was adorned with a pair of small wings; sometimes the hat is not present, and may have been replaced with wings rising from the hair. Another object is the Porta: a stick, called a rhabdomyolysis (stick) or skeptron (scepter), which is referred to as a magic wand. Some early sources say that this was the bat he received from Apollo, but others question the merits of this claim. It seems that there may have been two canes, one of a shepherd's staff, as stated in the Homeric Hymn, and the other a magic wand, according to some authors. His bat also came to be called kerykeion, the caduceus, in later times. Early depictions of the staff show it as a baton stick topped by a golden way that resembled the number eight, though sometimes with its top truncated and open. Later the staff had two intertwined snakes and sometimes it was crowned with a pair of wings and a ball, but the old form remained in use even when Hermes was associated with Mercury by the Romans.
Hyginus explained the presence of snakes, saying that Hermes was traveling in Arcadia when he saw two snakes intertwined in battle. He put the caduceus between them and parted, and so said his staff would bring peace. The caduceus, historically, there appeared with Hermes, and is documented among the Babylonians from about 3500 BC. The two snakes coiled around a stick was a symbol of the god Ningishzida, which served as a mediator between humans and the mother goddess Ishtar or the supreme Ningirsu. In Greece itself the other gods have been depicted holding a caduceus, but it was mainly associated with Hermes. It was said to have the power to make people fall asleep or wake up, and also made peace between litigants, and is a visible sign of his authority, being used as a sceptre.
He was represented in doorways, possibly as an amulet of good fortune, or as a symbol of purification. The caduceus is not to be confused with the Rod of Asclepius, the patron of medicine and son of Apollo, which bears only one snake. The rod of Asclepius was adopted by most Western doctors as a badge of their profession, but in several medical organizations of the United States, the caduceus took its place since the 18th century, although this use is declining. After the Renaissance the caduceus also appeared in the heraldic crests of several, and currently is a symbol of commerce.
His sandals, called "pédila" by the Greeks and "talaria" by the Romans were made of palm and myrtle branches, but were described as beautiful, golden and immortal, made a sublime art, able to take the roads with the speed of wind. Originally they had no wings, but late in the artistic representations, they are depicted. In certain images, the wings spring directly from the ankles. He has also been depicted with a purse or a bag in his hands, and wearing a robe or cloak, which had the power to confer invisibility. His weapon was a sword of gold, which killed Argos; lent to Perseus to kill Medusa.
In other religions.
Christianity.
In Acts 14, Paul the Apostle visited Lystra and was mistaken for Hermes.
Modern interpretation.
Psychology.
For Carl Jung Hermes's role as messenger between realms and as guide to the underworld, made him the god of the unconscious, the mediator between the conscious and unconscious parts of the mind, and the guide for inner journeys.
Jung considered the gods Thoth and Hermes to be counterparts. In Jungian psychology especially, Hermes is seen as relevant to study of the phenomenon of synchronicity (together with Pan and Dionysus)
Hermes is ... the archetypal core of Jung's psyche, theories ...—DL Merritt
In the context of psycho-therapy Hermes is our inner friendliness bringing together the disparate and perhaps isolated core elements of our selves belonging to the realms of the other gods; ...He does not fight with the other gods... it is Hermes in us who befriends our psychological complexes centered by the other gods...—López-Pedraza
He is identified by some with the archetype of healer, as the ancient Greeks ascribed healing magic to him.
In the context of abnormal psychology Samuels (1986) states that Jung considers Hermes the archetype for narcissistic disorder; however, he lends the disorder a "positive" (beneficious) aspect, and represents both the good and bad of narcissism.
For López-Pedraza, Hermes is the protector of psychotherapy. For McNeely, Hermes is a god of the healing arts.
According to Christopher Booker, all the roles Hermes held in ancient Greek thought all considered reveals Hermes to be a guide or observer of transition.
For Jung, Hermes's role as trickster made him a guide through the psychotherapeutic process.
French thought.
Michel Serres wrote a set of essays called the "Hermes series".

</doc>
<doc id="14412" url="http://en.wikipedia.org/wiki?curid=14412" title="Hedge fund">
Hedge fund

A hedge fund is an investment vehicle and a business structure that pools capital from a number of investors and invests in securities and other instruments. It is administered by a professional management firm, and often structured as a limited partnership, limited liability company, or similar vehicle. Hedge funds are generally distinct from mutual funds as their use of leverage is not capped by regulators and from private equity funds as the majority of hedge funds invest in relatively liquid assets.
Hedge funds invest in a diverse range of markets and use a wide variety of investment styles and financial instruments. The name "hedge fund" originated from the hedging techniques traditionally used by hedge funds, but hedge funds today do not necessarily hedge.
Hedge funds are made available only to certain sophisticated or accredited investors and cannot be offered or sold to the general public. As such, they generally avoid direct regulatory oversight, bypass licensing requirements applicable to investment companies, and operate with greater flexibility than mutual funds and other investment funds. However, regulations passed in the United States and Europe after the financial crisis of 2007–08 were intended to increase government oversight of hedge funds and eliminate certain regulatory gaps.
While hedge funds have existed for many decades, they have become increasingly popular in recent years, growing to be one of the world's major investment vehicles and sources of capital.
Hedge funds are most often open-ended and allow additions or withdrawals by their investors (generally on a monthly or quarterly basis). A hedge fund's value is calculated as a share of the fund's net asset value, meaning that increases and decreases in the value of the fund's investment assets (and fund expenses) are directly reflected in the amount an investor can later withdraw.
Many hedge fund investment strategies aim to achieve a positive return on investment regardless of whether markets are rising or falling ("absolute return"). Hedge fund managers often invest money of their own in the fund they manage, which serves to align their own interests with those of the investors in the fund. A hedge fund typically pays its investment manager an annual management fee (for example 1% of the assets of the fund), and a performance fee (for example 20% of the increase in the fund's net asset value during the year). Some hedge funds have several billion dollars of assets under management (AUM). s of 2009[ [update]], hedge funds represented 1.1% of the total funds and assets held by financial institutions. As of June 2013, the estimated size of the global hedge fund industry was US$2.4 trillion.
Etymology.
The word "hedge", meaning a line of bushes around a field, has long been used as a metaphor for the placing of limits on risk. Early hedge funds sought to hedge specific investments against general market fluctuations by shorting the market, hence the name.:4 Nowadays, however, many different investment strategies are used, many of which do not "hedge risk".:16–34
History.
During the US bull market of the 1920s, there were numerous private investment vehicles available to wealthy investors. Of that period the best known today is the Graham-Newman Partnership, founded by Benjamin Graham and Jerry Newman, which was cited by Warren Buffett in a 2006 letter to the Museum of American Finance as an early hedge fund.
The sociologist Alfred W. Jones is credited with coining the phrase ""hedged" fund" and is credited with creating the first hedge fund structure in 1949, although this has been disputed. Jones referred to his fund as being "hedged", a term then commonly used on Wall Street to describe the management of investment risk due to changes in the financial markets.
In the 1970s, hedge funds specialized in a single strategy and most fund managers followed the long/short equity model. Many hedge funds closed during the recession of 1969–70 and the 1973–1974 stock market crash due to heavy losses. They received renewed attention in the late 1980s. During the 1990s, the number of hedge funds increased significantly, funded with wealth created during the 1990s stock market rise. The increased interest was due to the aligned-interest compensation structure (i.e. common financial interests) and the promise of above high returns. Over the next decade hedge fund strategies expanded to include: credit arbitrage, distressed debt, fixed income, quantitative, and multi-strategy. US institutional investors such as pension and endowment funds began allocating greater portions of their portfolios to hedge funds.
During the first decade of the 21st century hedge funds gained popularity worldwide, and by 2008 the worldwide hedge fund industry held US$1.93 trillion in assets under management (AUM). However, the 2008 financial crisis caused many hedge funds to restrict investor withdrawals and their popularity and AUM totals declined. AUM totals rebounded and in April 2011 were estimated at almost $2 trillion. s of 2011[ [update]], 61% of worldwide investment in hedge funds comes from institutional sources. In June 2011, the hedge funds with the greatest AUM was Bridgewater Associates (US$58.9 billion), Man Group (US$39.2 billion), Paulson & Co. (US$35.1 billion), Brevan Howard (US$31 billion), and Och-Ziff (US$29.4 billion). Bridgewater Associates, had $70 billion under management as of 1 2012[ [update]]. At the end of that year, the 241 largest hedge fund firms in the United States collectively held $1.335 trillion. In April 2012, the hedge fund industry reached a record high of US$2.13 trillion total assets under management.
Strategies.
Hedge fund strategies are generally classified among four major categories: global macro, directional, event-driven, and relative value (arbitrage). Strategies within these categories each entail characteristic risk and return profiles. A fund may employ a single strategy or multiple strategies for flexibility, for risk management, or for diversification. The hedge fund's prospectus, also known as an offering memorandum, offers potential investors information about key aspects of the fund, including the fund's investment strategy, investment type, and leverage limit.
The elements contributing to a hedge fund strategy include: the hedge fund's approach to the market; the particular instrument used; the market sector the fund specializes in (e.g. healthcare); the method used to select investments; and the amount of diversification within the fund. There are a variety of market approaches to different asset classes, including equity, fixed income, commodity, and currency. Instruments used include: equities, fixed income, futures, options and swaps. Strategies can be divided into those in which investments can be selected by managers, known as "discretionary/qualitative", or those in which investments are selected using a computerized system, known as "systematic/quantitative". The amount of diversification within the fund can vary; funds may be multi-strategy, multi-fund, multi-market, multi-manager or a combination.
Sometimes hedge fund strategies are described as absolute return and are classified as either market neutral or directional. Market neutral funds have less correlation to overall market performance by "neutralizing" the effect of market swings, whereas directional funds utilize trends and inconsistencies in the market and have greater exposure to the market's fluctuations.
Global macro.
Hedge funds utilizing a global macro investing strategy take sizable positions in share, bond or currency markets in anticipation of global macroeconomic events in order to generate a risk-adjusted return. Global macro fund managers use macroeconomic ("big picture") analysis based on global market events and trends to identify opportunities for investment that would profit from anticipated price movements. While global macro strategies have a large amount of flexibility due to their ability to use leverage to take large positions in diverse investments in multiple markets, the timing of the implementation of the strategies is important in order to generate attractive, risk-adjusted returns. Global macro is often categorized as a directional investment strategy.
Global macro strategies can be divided into discretionary and systematic approaches. Discretionary trading is carried out by investment managers who identify and select investments; systematic trading is based on mathematical models and executed by software with limited human involvement beyond the programming and updating of the software. These strategies can also be divided into trend or counter-trend approaches depending on whether the fund attempts to profit from following trends (long or short-term) or attempts to anticipate and profit from reversals in trends.
Within global macro strategies, there are further sub-strategies including "systematic diversified", in which the fund trades in diversified markets, or "systematic currency", in which the fund trades in currency markets. Other sub-strategies include those employed by commodity trading advisors (CTAs), where the fund trades in futures (or options) in commodity markets or in swaps. This is also known as a managed future fund. CTAs trade in commodities (such as gold) and financial instruments, including stock indices. In addition they take both long and short positions, allowing them to make profit in both market upswings and downswings.
Directional.
Directional investment strategies utilize market movements, trends, or inconsistencies when picking stocks across a variety of markets. Computer models can be used, or fund managers will identify and select investments. These types of strategies have a greater exposure to the fluctuations of the overall market than do market neutral strategies. Directional hedge fund strategies include US and international long/short equity hedge funds, where long equity positions are hedged with short sales of equities or equity index options.
Within directional strategies, there are a number of sub-strategies. "Emerging markets" funds focus on emerging markets such as China and India, whereas "sector funds" specialize in specific areas including technology, healthcare, biotechnology, pharmaceuticals, energy and basic materials. Funds using a "fundamental growth" strategy invest in companies with more earnings growth than the overall stock market or relevant sector, while funds using a "fundamental value" strategy invest in undervalued companies. Funds that use quantitative and Financial signal processing techniques for equity trading are described as using a "quantitative directional" strategy. Funds using a "short bias" strategy take advantage of declining equity prices using short positions.
Event-driven.
Event-driven strategies concern situations in which the underlying investment opportunity and risk are associated with an event. An event-driven investment strategy finds investment opportunities in corporate transactional events such as consolidations, acquisitions, recapitalizations, bankruptcies, and liquidations. Managers employing such a strategy capitalize on valuation inconsistencies in the market before or after such events, and take a position based on the predicted movement of the security or securities in question. Large institutional investors such as hedge funds are more likely to pursue event-driven investing strategies than traditional equity investors because they have the expertise and resources to analyze corporate transactional events for investment opportunities.
Corporate transactional events generally fit into three categories: distressed securities, risk arbitrage, and special situations. Distressed securities include such events as restructurings, recapitalizations, and bankruptcies. A distressed securities investment strategy involves investing in the bonds or loans of companies facing bankruptcy or severe financial distress, when these bonds or loans are being traded at a discount to their value. Hedge fund managers pursuing the distressed debt investment strategy aim to capitalize on depressed bond prices. Hedge funds purchasing distressed debt may prevent those companies from going bankrupt, as such an acquisition deters foreclosure by banks. While event-driven investing in general tends to thrive during a bull market, distressed investing works best during a bear market.
Risk arbitrage or merger arbitrage includes such events as mergers, acquisitions, liquidations, and hostile takeovers. Risk arbitrage typically involves buying and selling the stocks of two or more merging companies to take advantage of market discrepancies between acquisition price and stock price. The risk element arises from the possibility that the merger or acquisition will not go ahead as planned; hedge fund managers will use research and analysis to determine if the event will take place.
Special situations are events that impact the value of a company's stock, including the restructuring of a company or corporate transactions including spin-offs, share-buy-backs, security issuance/repurchase, asset sales, or other catalyst-oriented situations. To take advantage of special situations the hedge fund manager must identify an upcoming event that will increase or decrease the value of the company's equity and equity-related instruments.
Other event-driven strategies include: credit arbitrage strategies, which focus on corporate fixed income securities; an activist strategy, where the fund takes large positions in companies and uses the ownership to participate in the management; a strategy based on predicting the final approval of new pharmaceutical drugs; and legal catalyst strategy, which specializes in companies involved in major lawsuits.
Relative value.
Relative value arbitrage strategies take advantage of relative discrepancies in price between securities. The price discrepancy can occur due to mispricing of securities compared to related securities, the underlying security or the market overall. Hedge fund managers can use various types of analysis to identify price discrepancies in securities, including mathematical, technical or fundamental techniques. Relative value is often used as a synonym for market neutral, as strategies in this category typically have very little or no directional market exposure to the market as a whole. Other relative value sub-strategies include:
Miscellaneous.
In addition to those strategies within the four main categories, there are several strategies that do not fit into these categorizations or can apply across several of them.
Risk.
Investment in hedge funds may provide diversification which can reduce the overall risk of an investor's portfolio. Managers of hedge funds use particular trading strategies and instruments with the specific aim of reducing market risks to produce risk-adjusted returns, which are consistent with investors' desired level of risk. Hedge funds ideally produce returns relatively uncorrelated with market indices. While "hedging" can be a way of reducing the risk of an investment, hedge funds, like all other investment types, are not immune to risk. According to a report by the Hennessee Group, hedge funds were approximately one-third less volatile than the S&P 500 between 1993 and 2010.
Risk management.
Investors in hedge funds are, in most countries, required to be sophisticated qualified investors who are assumed to be aware of the investment risks, and accept these risks because of the potential returns relative to those risks. Fund managers may employ extensive risk management strategies in order to protect the fund and investors. According to the "Financial Times", "big hedge funds have some of the most sophisticated and exacting risk management practices anywhere in asset management." Hedge fund managers may hold a large number of investment positions for short durations and are likely to have a particularly comprehensive risk management system in place. Funds may have "risk officers" who assess and manage risks but are not otherwise involved in trading, and may employ strategies such as formal portfolio risk models. A variety of measuring techniques and models may be used to calculate the risk incurred by a hedge fund's activities; fund managers may use different models depending on their fund's structure and investment strategy. Some factors, such as normality of return, are not always accounted for by conventional risk measurement methodologies. Funds which use value at risk as a measurement of risk may compensate for this by employing additional models such as drawdown and "time under water" to ensure all risks are captured.
In addition to assessing the market-related risks that may arise from an investment, investors commonly employ operational due diligence to assess the risk that error or fraud at a hedge fund might result in loss to the investor. Considerations will include the organization and management of operations at the hedge fund manager, whether the investment strategy is likely to be sustainable, and the fund's ability to develop as a company.
Transparency and regulatory considerations.
Since hedge funds are private entities and have few public disclosure requirements, this is sometimes perceived as a lack of transparency. Another common perception of hedge funds is that their managers are not subject to as much regulatory oversight and/or registration requirements as other financial investment managers, and more prone to manager-specific idiosyncratic risks such as style drifts, faulty operations, or fraud. New regulations introduced in the US and the EU as of 2010 require hedge fund managers to report more information, leading to greater transparency. In addition, investors, particularly institutional investors, are encouraging further developments in hedge fund risk management, both through internal practices and external regulatory requirements. The increasing influence of institutional investors has led to greater transparency: hedge funds increasingly provide information to investors including valuation methodology, positions and leverage exposure.
Risks shared with other investment types.
Hedge funds share many of the same types of risk as other investment classes, including liquidity risk and manager risk. Liquidity refers to the degree to which an asset can be bought and sold or converted to cash; similar to private equity funds, hedge funds employ a lock-up period during which an investor cannot remove money. Manager risk refers to those risks which arise from the management of funds. As well as specific risks such as style drift, which refers to a fund manager "drifting" away from an area of specific expertise, manager risk factors include valuation risk, capacity risk, concentration risk and leverage risk. Valuation risk refers to the concern that the net asset value of investments may be inaccurate; capacity risk can arise from placing too much money into one particular strategy, which may lead to fund performance deterioration; and concentration risk may arise if a fund has too much exposure to a particular investment, sector, trading strategy, or group of correlated funds. These risks may be managed through defined controls over conflict of interest, restrictions on allocation of funds, and set exposure limits for strategies.
Many investment funds use leverage, the practice of borrowing money, trading on margin, or using derivatives to obtain market exposure in excess of that provided by investors' capital. Although leverage can increase potential returns, the opportunity for larger gains is weighed against the possibility of greater losses. Hedge funds employing leverage are likely to engage in extensive risk management practices. In comparison with investment banks, hedge fund leverage is relatively low; according to a National Bureau of Economic Research working paper, the average leverage for investment banks is 14.2, compared to between 1.5 and 2.5 for hedge funds.
Some types of funds, including hedge funds, are perceived as having a greater appetite for risk, with the intention of maximizing returns, subject to the risk tolerance of investors and the fund manager. Managers will have an additional incentive to increase risk oversight when their own capital is invested in the fund.
Fees and remuneration.
Fees paid to hedge funds.
Hedge fund management firms typically charge their funds both a management fee and a performance fee.
Management fees are calculated as a percentage of the fund's net asset value and typically range from 1% to 4% per annum, with 2% being standard. They are usually expressed as an annual percentage, but calculated and paid monthly or quarterly. Management fees for hedge funds are designed to cover the operating costs of the manager, whereas the performance fee provides the manager's profits. However, due to economies of scale the management fee from larger funds can generate a significant part of a manager's profits, and as a result some fees have been criticized by some public pension funds, such as CalPERS, for being too high.
The performance fee is typically 20% of the fund's profits during any year, though they range between 10% and 50%. Performance fees are intended to provide an incentive for a manager to generate profits. Performance fees have been criticized by Warren Buffett, who believes that because hedge funds share only the profits and not the losses, such fees create an incentive for high-risk investment management. Performance fee rates have fallen since the start of the credit crunch.
Almost all hedge fund performance fees include a "high water mark" (or "loss carryforward provision"), which means that the performance fee only applies to net profits ("i.e.," profits after losses in previous years have been recovered). This prevents managers from receiving fees for volatile performance, though a manager will sometimes close a fund that has suffered serious losses and start a new fund, rather than attempting to recover the losses over a number of years without performance fee.
Some performance fees include a "hurdle", so that a fee is only paid on the fund's performance in excess of a benchmark rate (e.g. LIBOR) or a fixed percentage. A "soft" hurdle means the performance fee is calculated on all the fund's returns if the hurdle rate is cleared. A "hard" hurdle is calculated only on returns above the hurdle rate. A hurdle is intended to ensure that a manager is only rewarded if the fund generates returns in excess of the returns that the investor would have received if they had invested their money elsewhere.
Some hedge funds charge a redemption fee (or withdrawal fee) for early withdrawals during a specified period of time (typically a year) or when withdrawals exceed a predetermined percentage of the original investment. The purpose of the fee is to discourage short-term investing, reduce turnover and deter withdrawals after periods of poor performance. Unlike management fees and performance fees, redemption fees are usually kept by the fund.
Remuneration of portfolio managers.
Hedge fund management firms are usually owned by their portfolio managers, who are therefore entitled to any profits that the business makes. As management fees are intended to cover the firm's operating costs, performance fees (and any excess management fees) are generally distributed to the firm's owners as profits. Many managers also have large stakes in their own funds.
Top hedge fund managers earn what has been termed "extraordinary" amounts of money, with the highest-grossing getting up to $4 billion per year. Earnings at the top are far higher than in any other sector of the financial industry. "They wouldn't even consider getting out of bed for the $13m (£8m) Goldman Sachs' boss Lloyd Blankfein was paid last year," writes Richard Anderson, a BBC Business reporter. Collectively, the top 25 hedge fund managers regularly earn more than all 500 of the chief executives in the S&P 500. Most hedge fund managers are remunerated much less, however, and the competitiveness of the industry, along with the structure of financial incentives, means that failure can lead to not getting paid. The BBC quotes an industry insider who says "a lot of managers are not making any money at all."
In 2011, the top manager earned $3,000m, the tenth earned $210m and the 30th earned $80m. In 2011, the average earnings for the 25 highest compensated hedge fund managers in the United States was $576 million. According to "Absolute Return + Alpha", in 2011 the mean total compensation for all hedge fund investment professionals was $690,786 and the median compensation was $312,329. The same figures for hedge fund CEOs were $1,037,151 and $600,000, and for chief investment officers were $1,039,974 and $300,000 respectively.
Of the 1,226 people on the "Forbes" World's Billionaires list for 2012, 36 of the financiers listed "derived significant chunks" of their wealth from hedge fund management. Among the richest 1,000 people in the United Kingdom, 54 were hedge fund managers, according to the "Sunday Times" Rich List for 2012. (Funds do not tend to report compensation. Published lists of the amounts earned by top managers use estimates based on factors such as the fees charged by their funds and the capital they are thought to have invested in them.)
Structure.
A hedge fund is an investment vehicle that is most often structured as an offshore corporation, limited partnership or limited liability company. The fund is managed by an investment manager in the form of an organization or company that is legally and financially distinct from the hedge fund and its portfolio of assets. Many investment managers utilize service providers for operational support. Service providers include prime brokers, banks, administrators, distributors and accounting firms.
Prime brokers clear trades, and provide leverage and short-term financing. They are usually divisions of large investment banks. The prime broker acts as a counterparty to derivative contracts, and lends securities for particular investment strategies, such as long/short equities and convertible bond arbitrage. It can provide custodial services for the fund's assets, and execution and clearing services for the hedge fund manager.
Hedge fund administrators are responsible for operations, accounting, and valuation services. This back office support allows fund managers to concentrate on trades. Administrators also process subscriptions and redemptions, and perform various shareholder services. Hedge funds in the United States are not required to appoint an administrator, and all of these functions can be performed by an investment manager. A number of conflict of interest situations may arise in this arrangement, particularly in the calculation of a fund's net asset value (NAV). Some US funds voluntarily employ external auditors, thereby offering a greater degree of transparency.
A distributor is an underwriter, broker, dealer, or other person who participates in the distribution of securities. The distributor is also responsible for marketing the fund to potential investors. Many hedge funds do not have distributors, and in such cases the investment manager will be responsible for distribution of securities and marketing, though many funds also use placement agents and broker-dealers for distribution.
Most funds use an independent accounting firm to audit the assets of the fund, provide tax services and perform a complete audit of the fund's financial statements. The year-end audit is often performed in accordance with either US generally accepted accounting principles (US GAAP) or international financial reporting standards (IFRS), depending on where the fund is established. The auditor may verify the fund's NAV and assets under management (AUM). Some auditors only provide "NAV lite" services, meaning that the valuation is based on prices received from the manager rather than independent assessment.
Domicile and taxation.
The legal structure of a specific hedge fund—in particular its domicile and the type of legal entity used—is usually determined by the tax expectations of the fund's investors. Regulatory considerations will also play a role. Many hedge funds are established in offshore financial centers to avoid adverse tax consequences for its foreign and tax exempt investors. Offshore funds that invest in the US typically pay withholding taxes on certain types of investment income but not US capital gains tax. However, the fund's investors are subject to tax in their own jurisdictions on any increase in the value of their investments. This tax treatment promotes cross-border investments by limiting the potential for multiple jurisdictions to layer taxes on investors.
US tax-exempt investors (such as pension plans and endowments) invest primarily in offshore hedge funds to preserve their tax exempt status and avoid unrelated business taxable income. The investment manager, usually based in a major financial center, pays tax on its management fees per the tax laws of the state and country where it is located. In 2011, half of the existing hedge funds were registered offshore and half onshore. The Cayman Islands was the leading location for offshore funds, accounting for 34% of the total number of global hedge funds. The US had 24%, Luxembourg 10%, Ireland 7%, the British Virgin Islands 6% and Bermuda had 3%.
Investment manager locations.
In contrast to the funds themselves, investment managers are primarily located onshore. The United States remains the largest center of investment, with US-based funds managing around 70% of global assets at the end of 2011. As of April 2012, there were approximately 3,990 investment advisers managing one or more private hedge funds registered with the Securities and Exchange Commission. New York City and the Gold Coast area of Connecticut are the leading locations for US hedge fund managers.
London is Europe's leading center for hedge fund managers. According to EuroHedge data, around 800 funds located in the UK managed some 85% of European-based hedge fund assets in 2011. Interest in hedge funds in Asia has increased significantly since 2003, especially in Japan, Hong Kong, and Singapore. However, the UK and the US remain the leading locations for management of Asian hedge fund assets.
From all 4124 investment managers that filed 13F form with the Security and Exchange Commission for the last quarter of 2014, 890 were based in New York, 463 in California, 267 in Massachusetts, 199 in Illinois, 190 in Texas – Dallas, 178 in Connecticut, 167 in Pennsylvania, 109 in New Jersey, 94 in Florida, 91 in Ohio, 76 in Virginia, 71 in Maryland.
The legal entity.
Hedge fund legal structures vary depending on location and the investor(s). US hedge funds aimed at US-based, taxable investors are generally structured as limited partnerships or limited liability companies. Limited partnerships and other flow-through taxation structures assure that investors in hedge funds are not subject to both entity-level and personal-level taxation. A hedge fund structured as a limited partnership must have a general partner. The general partner may be an individual or a corporation. The general partner serves as the manager of the limited partnership, and has unlimited liability. The limited partners serve as the fund's investors, and have no responsibility for management or investment decisions. Their liability is limited to the amount of money they invest for partnership interests. As an alternative to a limited partnership arrangement, U.S. domestic hedge funds may be structured as limited liability companies, with members acting as corporate shareholders and enjoying protection from individual liability.
By contrast, offshore corporate funds are usually used for non-US investors, and when they are domiciled in an applicable offshore tax haven, no entity-level tax is imposed. Many managers of offshore funds permit the participation of tax-exempt US investors, such as pensions funds, institutional endowments and charitable trusts. As an alternative legal structure, offshore funds may be formed as an open-ended unit trust using an unincorporated mutual fund structure. Japanese investors prefer to invest in unit trusts, such as those available in the Cayman Islands.
The investment manager who organizes the hedge fund may retain an interest in the fund, either as the general partner of a limited partnership or as the holder of "founder shares" in a corporate fund. For offshore funds structured as corporate entities, the fund may appoint a board of directors. The board's primary role is to provide a layer of oversight while representing the interests of the shareholders. However, in practice board members may lack sufficient expertise to be effective in performing those duties. The board may include both affiliated directors who are employees of the fund and independent directors whose relationship to the fund is limited.
Side pockets.
A side pocket is a mechanism whereby a fund compartmentalizes assets that are relatively illiquid or difficult to value reliably. When an investment is side-pocketed, its value is calculated separately from the value of the fund’s main portfolio. Because side pockets are used to hold illiquid investments, investors do not have the standard redemption rights with respect to the side pocket investment that they do with respect to the fund’s main portfolio. Profits or losses from the investment are allocated on a "pro rata" basis only to those who are investors at the time the investment is placed into the side pocket and are not shared with new investors. Funds typically carry side pocket assets "at cost" for purposes of calculating management fees and reporting net asset values. This allows fund managers to avoid attempting a valuation of the underlying investments, which may not always have a readily available market value.
Side pockets were widely used by hedge funds during the 2008 financial crisis amidst a flood of withdrawal requests. Side pockets allowed fund managers to lay away illiquid securities until market liquidity improved, a move that reduced losses. Despite these benefits, some investors complained that the practice was abused and not always transparent. The SEC also has expressed concern about aggressive use of side pockets and has sanctioned certain fund managers for inappropriate use of them.
Regulation.
Hedge funds must conform to the national, federal and state regulatory laws in their respective locations. The U.S. regulations and restrictions that apply to hedge funds differ from its mutual funds. Mutual funds, unlike hedge funds and other private funds, are subject to the Investment Company Act of 1940, which is a highly detailed and extensive regulatory regime. According to a report by the International Organization of Securities Commissions the most common form of regulation pertains to restrictions on financial advisers and hedge fund managers in an effort to minimize client fraud. On the other hand, U.S. hedge funds are exempt from many of the standard registration and reporting requirements because they only accept accredited investors. In 2010, regulations were enacted in the US and European Union, which introduced additional hedge fund reporting requirements. These included the U.S.'s Dodd-Frank Wall Street Reform Act and European Alternative Investment Fund Managers Directive.
United States.
Hedge funds within the US are subject to regulatory, reporting and record keeping requirements. Many hedge funds also fall under the jurisdiction of the Commodity Futures Trading Commission and are subject to rules and provisions of the 1922 Commodity Exchange Act which prohibits fraud and manipulation. The Securities Act of 1933 required companies to file a registration statement with the SEC to comply with its private placement rules before offering their securities to the public. The Securities Exchange Act of 1934 required a fund with more than 499 investors to register with the SEC. The Investment Advisers Act of 1940 contained anti-fraud provisions that regulated hedge fund managers and advisers, created limits for the number and types of investors, and prohibited public offerings. The Act also exempted hedge funds from mandatory registration with the U.S. Securities and Exchange Commission (SEC) when selling to accredited investors with a minimum of US$5 million in investment assets. Companies and institutional investors with at least US$25 million in investment assets also qualified.
In December 2004, the SEC began requiring hedge fund advisers, managing more than US$25 million and with more than 14 investors, to register with the SEC under the Investment Advisers Act. The SEC stated that it was adopting a "risk-based approach" to monitoring hedge funds as part of its evolving regulatory regimen for the burgeoning industry. The new rule was controversial, with two commissioners dissenting, and was later challenged in court by a hedge fund manager. In June 2006, the U.S. Court of Appeals for the District of Columbia overturned the rule and sent it back to the agency to be reviewed. In response to the court decision, in 2007 the SEC adopted Rule 206(4)-8, which unlike the earlier challenged rule, "does not impose additional filing, reporting or disclosure obligations" but does potentially increase "the risk of enforcement action" for negligent or fraudulent activity. Hedge fund managers with at least US$100 million in assets under management are required to file publicly quarterly reports disclosing ownership of registered equity securities and are subject to public disclosure if they own more than 5% of the class of any registered equity security. Registered advisers must report their business practices and disciplinary history to the SEC and to their investors. They are required to have written compliance policies, a chief compliance officer and their records and practices may be examined by the SEC.
The U.S.'s Dodd-Frank Wall Street Reform Act was passed in July 2010 and requires SEC registration of advisers who manage private funds with more than US$150 million in assets. Registered managers must file Form ADV with the SEC, as well as information regarding their assets under management and trading positions. Previously, advisers with fewer than 15 clients were exempt, although many hedge fund advisers voluntarily registered with the SEC to satisfy institutional investors. Under Dodd-Frank, investment advisers with less than US$100 million in assets under management became subject to state regulation. This increased the number of hedge funds under state supervision. Overseas advisers who managed more than US$25 million were also required to register with the SEC. The Act requires hedge funds to provide information about their trades and portfolios to regulators including the newly created Financial Stability Oversight Council. In this regard, most hedge funds and other private funds, including private equity funds, must file Form PF with the SEC, which is an extensive reporting form with substantial data on the funds' activities and positions. Under the "Volcker Rule," regulators are also required to implement regulations for banks, their affiliates, and holding companies to limit their relationships with hedge funds and to prohibit these organizations from proprietary trading, and to limit their investment in, and sponsorship of, hedge funds.
Europe.
Within the European Union (EU), hedge funds are primarily regulated through advisers managers. In the United Kingdom, where 80% of Europe's hedge funds are based, hedge fund managers are required to be authorised and regulated by the Financial Conduct Authority (FCA). Each country has their own specific restrictions on hedge fund activities, including controls on use of derivatives in Portugal, and limits on leverage in France.
In November 2010, the EU approved a law that will require all EU hedge fund managers to register with national regulatory authorities. The EU's Directive on Alternative Investment Fund Managers (AIFMD) was the first EU directive focused on hedge fund managers. According to the EU, the aim of the directive is to provide greater monitoring and control of alternative investment funds. The directive required managers to disclose more information, on a more frequent basis. It also directs hedge fund managers to hold larger amounts of capital. All hedge fund managers within the EU are subject to potential limitations on leveraged investments. The directive introduced a "passport" for hedge funds authorized in one EU country to operate throughout the EU. The scope of AIFMD is broad and encompasses managers located within the EU as well as non-EU managers that market their funds to European investors. An aspect of AIFMD which challenges established practices in the hedge funds sector is the potential restriction of remuneration through bonus deferrals and clawback provisions. Under the EU's 2010 Alternative Investment Fund Managers directive, offshore hedge funds using prime brokers as depositories are required to use EU-registered credit institutions before they can be sold in the EU. The AIFMD's regulatory requirements will essentially mandate equivalent regulations for non-EU investment funds, if they wish to operate in EU markets.
Other.
Some hedge funds are established in Offshore centers such as the Cayman Islands, Dublin, Luxembourg, the British Virgin Islands, and Bermuda which have different regulations concerning non-accredited investors, client confidentiality and fund manager independence.
In South Africa, investment fund managers must be approved by, and register with, the Financial Services Board (FSB).
Performance.
Measurement.
Performance statistics for individual hedge funds are difficult to obtain, as the funds have historically not been required to report their performance to a central repository and restrictions against public offerings and advertisement have led many managers to refuse to provide performance information publicly. However, summaries of individual hedge fund performance are occasionally available in industry journals and databases. and investment consultancy Hennessee Group.
One estimate is that the average hedge fund returned 11.4% per year, representing a 6.7% return above overall market performance before fees, based on performance data from 8,400 hedge funds. Another is that between January 2000 and December 2009 the hedge funds outperformed other investments were significantly less volatile, with stocks falling 2.62% per year over the decade and hedge funds rising 6.54%.
Hedge funds performance is measured by comparing their returns to an estimate of their risk. Common measures are the Sharpe ratio., Treynor measure and Jensen's alpha. These measures work best when returns follow normal distributions without autocorrelation, and these assumptions are often not met in practice.
New performance measures have been introduced that attempt to address some of theoretical concerns with traditional indicators, including: modified Sharpe ratios; the Omega ratio introduced by Keating and Shadwick in 2002; Alternative Investments Risk Adjusted Performance (AIRAP) published by Sharma in 2004; and Kappa developed by Kaplan and Knowles in 2004.
Sector-size effect.
There is a debate over whether alpha (the manager's skill element in performance) has been diluted by the expansion of the hedge fund industry. Two reasons are given. First, the increase in traded volume may have been reducing the market anomalies that are a source of hedge fund performance. Second, the remuneration model is attracting more managers, which may dilute the talent available in the industry.
Hedge fund indices.
Indices that track hedge fund returns are, in order of development, called Non-investable, Investable and Clone.
Indices play a central and unambiguous role in traditional asset markets, where they are widely accepted as representative of their underlying portfolios. Equity and debt index fund products provide investable access to most developed markets in these asset classes. Hedge funds, however, are actively managed, so that tracking is impossible. Non-investable hedge fund indices on the other hand may be more or less representative, but returns data on many of the reference group of funds is non-public. This may result in biased estimates of their returns. In an attempt to address this problem, clone indices have been created in an attempt to replicate the statistical properties of hedge funds without being directly based on their returns data. None of these approaches achieves the accuracy of indices in other asset classes for which there is more complete published data concerning the underlying returns.
Non-investable indices.
Non-investable indices are indicative in nature, and aim to represent the performance of some database of hedge funds using some measure such as mean, median or weighted mean from a hedge fund database. The databases have diverse selection criteria and methods of construction, and no single database captures all funds. This leads to significant differences in reported performance between different indices.
Although they aim to be representative, non-investable indices suffer from a lengthy and largely unavoidable list of biases.
Funds' participation in a database is voluntary, leading to self-selection bias because those funds that choose to report may not be typical of funds as a whole. For example, some do not report because of poor results or because they have already reached their target size and do not wish to raise further money..
The short lifetimes of many hedge funds means that there are many new entrants and many departures each year, which raises the problem of survivorship bias. If we examine only funds that have survived to the present, we will overestimate past returns because many of the worst-performing funds have not survived, and the observed association between fund youth and fund performance suggests that this bias may be substantial.
When a fund is added to a database for the first time, all or part of its historical data is recorded ex-post in the database. It is likely that funds only publish their results when they are favorable, so that the average performances displayed by the funds during their incubation period are inflated. This is known as "instant history bias" or "backfill bias".
Investable indices.
Investable indices are an attempt to reduce these problems by ensuring that the return of the index is available to shareholders. To create an investable index, the index provider selects funds and develops structured products or derivative instruments that deliver the performance of the index. When investors buy these products the index provider makes the investments in the underlying funds, making an investable index similar in some ways to a fund of hedge funds portfolio.
To make the index investable, hedge funds must agree to accept investments on the terms given by the constructor. To make the index liquid, these terms must include provisions for redemptions that some managers may consider too onerous to be acceptable. This means that investable indices do not represent the total universe of hedge funds. Most seriously, they under-represent more successful managers, who typically refuse to accept such investment protocols.
Hedge fund replication.
The most recent addition to the field approach the problem in a different manner. Instead of reflecting the performance of actual hedge funds they take a statistical approach to the analysis of historic hedge fund returns, and use this to construct a model of how hedge fund returns respond to the movements of various investable financial assets. This model is then used to construct an investable portfolio of those assets. This makes the index investable, and in principle they can be as representative as the hedge fund database from which they were constructed.
However, these clone indices rely on a statistical modelling process. Such indices have too short a history to state whether this approach will be considered successful.
Debates and controversies.
Systemic risk.
Systemic risk refers to the risk of instability across the entire financial system, as opposed to within a single company. Such risk may arise following a destabilizing event or events affecting a group of financial institutions linked through investment activity. Organizations such as the National Bureau of Economic Research and the European Central Bank have charged that hedge funds pose systemic risks to the financial sector, and following the failure of hedge fund Long-Term Capital Management (LTCM) in 1998 there was widespread concern about the potential for systemic risk if a hedge fund failure led to the failure of its counterparties. (As it happens, no financial assistance was provided to LTCM by the US Federal Reserve, so there was no direct cost to US taxpayers, but a large bailout had to be mounted by a number of financial institutions.)
However, these claims are widely disputed by the financial industry, who typically regard hedge funds as "small enough to fail", since most are relatively small in terms of the assets they manage and operate with low leverage, thereby limiting the potential harm to the economic system should one of them fail. Formal analysis of hedge fund leverage before and during the 2008 financial crisis suggests that hedge fund leverage is both fairly modest and counter-cyclical to the market leverage of investment banks and the larger financial sector. Hedge fund leverage decreased prior to the financial crisis, even while the leverage of other financial intermediaries continued to increase. Hedge funds fail regularly, and numerous hedge funds failed during the financial crisis. In testimony to the House Financial Services Committee in 2009, Ben Bernanke, the Federal Reserve Board Chairman said he "would not think that any hedge fund or private equity fund would become a systemically critical firm individually".
Nevertheless, although hedge funds go to great lengths to reduce the ratio of risk to reward, inevitably a number of risks remain. Systemic risk is increased in a crisis if there is "herd" behaviour, which causes a number of similar hedge funds to make losses in similar trades. In addition, while most hedge funds make only modest use of leverage, hedge funds differ from many other market participants, such as banks and mutual funds, in that there are no regulatory constraints on their use of leverage, and some hedge funds seek large amounts of leverage as part of their market strategy. The extensive use of leverage can lead to forced liquidations in a crisis, particularly for hedge funds that invest at least in part in illiquid investments. The close interconnectedness of the hedge funds with their prime brokers, typically investment banks, can lead to domino effects in a crisis, and indeed failing counterparty banks can freeze hedge funds. These systemic risk concerns are exacerbated by the prominent role of hedge funds in the financial markets. The global hedge fund industry has over $2 trillion in assets, and this does not take into account the full effect of leverage, which by definition is market exposure in excess of the amount invested.
An August 2012 survey by the Financial Services Authority concluded that risks were limited and had reduced as a result, "inter alia", of larger margins being required by counterparty banks, but might change rapidly according to market conditions. In stressed market conditions, investors might suddenly withdraw large sums, resulting in forced asset sales. This might cause liquidity and pricing problems if it occurred across a number of funds or in one large highly leveraged fund.
Transparency.
Hedge funds are structured to avoid most direct regulation (although their managers may be regulated) and are not required to publicly disclose their investment activities, except to the extent that investors generally are subject to disclosure requirements. This is in contrast to a regulated mutual fund or exchange-traded fund, which will typically have to meet regulatory requirements for disclosure. An investor in a hedge fund usually has direct access to the investment adviser of the fund, and may enjoy more personalized reporting than investors in retail investment funds. This may include detailed discussions of risks assumed and significant positions. However, this high level of disclosure is not available to non-investors, contributing to hedge funds' reputation for secrecy, while some hedge funds have very limited transparency even to investors.
Funds may choose to report some information in the interest of recruiting additional investors. Much of the data available in consolidated databases is self-reported and unverified. A study was done on two major databases containing hedge fund data. The study noted that 465 common funds had significant differences in reported information (e.g. returns, inception date, net assets value, incentive fee, management fee, investment styles, etc.) and that 5% of return numbers and 5% of NAV numbers were dramatically different. With these limitations, investors have to do their own research, which may cost on the scale of US$50,000 for a fund that is not well-established.
A lack of verification of financial documents by investors or by independent auditors has, in some cases, assisted in fraud. In the mid-2000s, Kirk Wright of International Management Associates was accused of mail fraud and other securities violations which allegedly defrauded clients of close to US$180 million. In December 2008, Bernard Madoff was arrested for running a US$50 billion Ponzi scheme which was incorrectly described as a hedge fund, and several feeder hedge funds, of which the largest was Fairfield Sentry, channeled money to it. Following the Madoff case, the SEC adopted reforms in December 2009 that required hedge funds managed by registered investment advisers to have their assets in the custody of a qualified custodian and subjected them to an audit requirement.
The process of matching hedge funds to investors has traditionally been fairly opaque, with investments often driven by personal connections or recommendations of portfolio managers. Many funds disclose their holdings, strategy, and historic performance relative to market indices, giving investors some idea of how their money is being allocated, although individual holdings are not always disclosed. Investors are often drawn to hedge funds by the possibility of realizing significant returns, or hedging against volatility in the market. The complexity and fees associated with hedge funds are causing some to exit the market – Calpers, the largest pension fund in the US, announced plans to completely divest from hedge funds in 2014. Some services are attempting to improve matching between hedge funds and investors: HedgeZ is designed to allow investors to easily search and sort through funds; iMatchative aims to match investors to funds through algorithms that factor in an investor's goals and behavioral profile, in hopes of helping funds and investors understand the how their perceptions and motivations drive investment decisions.
Links with analysts.
In June 2006, prompted by a letter from Gary J. Aguirre, the Senate Judiciary Committee began an investigation into the links between hedge funds and independent analysts. Aguirre was fired from his job with the SEC when, as lead investigator of insider trading allegations against Pequot Capital Management, he tried to interview John Mack, then being considered for chief executive officer at Morgan Stanley. The Judiciary Committee and the US Senate Finance Committee issued a scathing report in 2007, which found that Aguirre had been illegally fired in reprisal for his pursuit of Mack and in 2009, the SEC was forced to re-open its case against Pequot. Pequot settled with the SEC for US$28 million and Arthur J. Samberg, chief investment officer of Pequot, was barred from working as an investment advisor. Pequot closed its doors under the pressure of investigations.
The systemic practice of hedge funds submitting periodic electronic questionnaires to stock analysts as a part of market research was reported in by "The New York Times" in July 2012. According to the report, one motivation for the questionnaires was to obtain subjective information not available to the public and possible early notice of trading recommendations that could produce short term market movements.
Value in mean/variance efficient portfolios.
According to modern portfolio theory, rational investors will seek to hold portfolios that are mean/variance efficient (that is, portfolios offer the highest level of return per unit of risk, and the lowest level of risk per unit of return). One of the attractive features of hedge funds (in particular market neutral and similar funds) is that they sometimes have a modest correlation with traditional assets such as equities. This means that hedge funds have a potentially quite valuable role in investment portfolios as diversifiers, reducing overall portfolio risk.
However, there are three reasons why one might not wish to allocate a high proportion of assets into hedge funds. These reasons are:
Several studies have suggested that hedge funds are sufficiently diversifying to merit inclusion in investor portfolios, but this is disputed for example by Mark Kritzman who performed a mean-variance optimization calculation on an opportunity set that consisted of a stock index fund, a bond index fund, and ten hypothetical hedge funds. The optimizer found that a mean-variance efficient portfolio did not contain any allocation to hedge funds, largely because of the impact of performance fees. To demonstrate this, Kritzman repeated the optimization using an assumption that the hedge funds incurred no performance fees. The result from this second optimization was an allocation of 74% to hedge funds.
The other factor reducing the attractiveness of hedge funds in a diversified portfolio is that they tend to under-perform during equity bear markets, just when an investor needs part of their portfolio to add value. For example, in January–September 2008, the Credit Suisse/Tremont Hedge Fund Index was down 9.87%. According to the same index series, even "dedicated short bias" funds had a return of −6.08% during September 2008. In other words, even though low average correlations may appear to make hedge funds attractive this may not work in turbulent period, for example around the collapse of Lehman Brothers in September 2008.

</doc>
<doc id="14413" url="http://en.wikipedia.org/wiki?curid=14413" title="Hydrocodone">
Hydrocodone

Hydrocodone is a semi-synthetic opioid synthesized from codeine, one of the opioid alkaloids found in the opium poppy. It is a narcotic analgesic used orally as an antitussive/cough suppressant, but also commonly taken orally for relief of moderate to severe pain.
Hydrocodone is prescribed predominantly within the United States, with the International Narcotics Control Board reporting that 99% of the worldwide supply in 2007 was consumed in the United States. The Administrative Controlled Substances Code Number (ACSCN) for hydrocodone is 9193 and the aggregate production quota for 2014 is 99,625 kilograms in the U.S.
Medical uses.
Hydrocodone is used to treat moderate to severe pain and as an antitussive to treat cough. In one study comparing the potency of hydrocodone to that of oxycodone, it was found that it took 50% more hydrocodone to achieve the same degree of miosis (pupillary contraction). The investigators interpreted this to mean that oxycodone is about 50% more potent than hydrocodone. However, in a study of emergency room patients with fractures, it was found that an equal amount of either drug provided about the same degree of pain relief, indicating that there is little practical difference between them when used for that purpose. Some references state that the analgesic action of hydrocodone begins in 20–30 minutes and lasts about 4–8 hours. The manufacturer's information says onset of action is about 10–30 minutes and duration is about 4–6 hours. Recommended dosing interval is 4–6 hours.
Adverse effects.
Common side effects of hydrocodone are nausea, vomiting, constipation, drowsiness, dizziness, lightheadedness, fuzzy thinking, anxiety, abnormally happy or sad mood, dry throat, difficulty urinating, rash, itching, and narrowing of the pupils. Serious side effects include slowed or irregular breathing and chest tightness.
Several cases of progressive bilateral hearing loss unresponsive to steroid therapy have been described as an infrequent adverse reaction to hydrocodone/paracetamol misuse. This adverse effect has been considered by some to be due to the ototoxicity of hydrocodone. Other researchers have suggested that paracetamol is the primary agent responsible for the ototoxicity.
Hydrocodone is in U.S. Food and Drug Administration (FDA) pregnancy category C. No adequate and well-controlled studies in humans have been conducted. A newborn of a mother taking opioid medications regularly prior to the birth will be physically dependent. The baby may also exhibit respiratory depression if the opioid dose was high. An epidemiological study indicated that opioid treatment during early pregnancy results in increased risk of various birth defects.
Symptoms of hydrocodone overdose include narrowed or widened pupils; slow, shallow, or stopped breathing; slowed or stopped heartbeat; cold, clammy, or blue skin; excessive sleepiness; loss of consciousness; seizures; or death.
Hydrocodone can be habit-forming, causing physical and psychological dependence. Its abuse liability is similar to morphine and less than oxycodone.
Contraindications and interactions.
Patients consuming alcohol, other opioids, antihistamines, anti-psychotics, anti-anxiety agents, or other central nervous system (CNS) depressants together with hydrocodone may exhibit an additive CNS depression. Hydrocodone may interact with serotonergic medications.
Pharmacology.
As a narcotic, hydrocodone relieves pain by binding to opioid receptors in the CNS. It acts primarily on μ-opioid receptors, with about six times lesser affinity to δ-opioid receptors. In blood, 20–50% of hydrocodone is bound to protein.
Studies have shown hydrocodone is stronger than codeine but only one-tenth as potent as morphine at binding to receptors and reported to be only 59% as potent as morphine in analgesic properties. However, in tests conducted on rhesus monkeys, the analgesic potency of hydrocodone was actually higher than morphine. Per os hydrocodone has a mean equivalent daily dosage (MEDD) factor of 0.4, meaning that 1 mg of hydrocodone is equivalent to 0.4 mg of intravenous morphine. However, because of morphine's low oral bioavailability, there is a 1:1 correspondence between orally administered morphine and orally administered hydrocodone. The relative milligram strength of hydrocodone to codeine is given as 6 fold, that is 5 mg has the effect of 30 mg of codeine; by way of the Roman numeral VI this is said to have given rise to the trade name Vicodin.
Pharmacokinetics.
In the liver, hydrocodone is transformed into several metabolites. It has a serum half-life that averages 3.8 hours. The hepatic cytochrome P450 enzyme CYP2D6 converts it into hydromorphone, a more potent opioid. However, extensive and poor cytochrome 450 CYP2D6 metabolizers had similar physiological and subjective responses to hydrocodone, and CYP2D6 inhibitor quinidine did not change the responses of extensive metabolizers, suggesting that inhibition of CYP2D6 metabolism of hydrocodone has no practical importance. Ultra-rapid CYP2D6 metabolizers (1-2% of the population) may have an increased response to hydrocodone; however, hydrocodone metabolism in this population has not been studied.
A major metabolite, norhydrocodone, is predominantly formed by CYP3A4-catalyzed oxidation. Inhibition of CYP3A4 in a child who was, in addition, a poor CYP2D6 metabolizer, resulted in a fatal overdose of hydrocodone. Approximately 40% of hydrocodone metabolism is attributed to non-cytochrome-catalyzed reactions.
Formulations.
Hydrocodone/paracetamol.
Most hydrocodone is formulated in combination with a second analgesic, such as paracetamol (acetaminophen). Examples of hydrocodone-paracetamol combinations include Norco, Vicodin, and Lortab.
Zohydro ER.
In 2014, the FDA approved prescription-only marketing by Zogenix Pharmaceuticals of the first pure hydrocodone product in the U.S, known by the brand name Zohydro ER. The drug comes in extended-release capsules with hydrocodone powder inside, in doses of 10 mg, 15 mg, 20 mg, 30 mg, 40 mg and 50 mg. This is up to 5 times as much active opioid as the highest strength hydrocodone/APAP product (10 mg/325 mg), but it is important to note that the hydrocodone in Zohydro formulations is intended to be slowly released over 12 hours. Zohydro ER (hydrocodone bitartrate) is indicated for the management of pain severe enough to require daily, around-the-clock, long-term opioid treatment for which alternative treatment options are inadequate. Zohydro is a schedule II controlled substance under the CSA.
The approval of Zohydro ER was controversial, due to concerns over its potential for substance abuse. The FDA approved Zohydro ER over the objections of its own review panel, which voted 12 to 2 against approval. The panel stated that if approved, Zohydro ER would likely "be abused, possibly at a rate greater than that of currently available hydrocodone combination products". Thirty U.S. states asked the FDA not to approve Zohydro ER in capsule form due to its potency and the ease with which it could be abused, by being crushed and then snorted or injected. Zohydro ER was briefly prohibited in Massachusetts before a federal judge ruled that the state's ban was preempted by the earlier federal approval.
Recreational use.
Many users of hydrocodone report a sense of satisfaction (euphoria), especially at higher doses. A number of users also report a warm or pleasant numbing sensation throughout the body, one of the best-known effects of narcotics. A simultaneous warming of the stomach and rest of the body with the possible sensation of pleasant cooling in the lungs is sometimes also reported, as with opium and hydromorphone 
Withdrawal symptoms are similar to those of morphine and other opioids. More specifically, the symptoms may include severe pain, pins-and-needles sensations throughout the body, sweating, extreme anxiety and restlessness, sneezing, watery eyes, fever, depression, stomach cramps, diarrhea, and extreme drug cravings. Furthermore, unlike a light codeine or meptazinol dependence, hydrocodone withdrawal can be expected to reach the worst categories of symptoms, resembling that of morphine or hydromorphone. In a very small number of severe cases withdrawal can be lethal unless undertaken under medical supervision, particularly for users with cardiac or pulmonary disease or those unable to treat the dehydration and resultant acid-base and electrolyte problems. Unlike alcohol, benzodiazepine, barbiturate, and sedative-hypnotic dependence, the abstinence syndrome technically does not kill directly and is in fact self-limiting in many respects.
Taking hydrocodone with grapefruit juice is believed to enhance its narcotic effect. It is hypothesized that the CYP3A4 inhibitors in grapefruit juice may interfere with the metabolism of hydrocodone, although there has been no research into this issue. Additionally, many medications are either substrates (competing for metabolism and exhausting available enzymes) or direct inhibitors of CYP3A4. Inhibition of another enzyme, CYP2D6, would also increase the duration of hydrocodone's elevated concentration in the blood, leading to exaggerated effects. Complete inhibition of both enzymes would theoretically inhibit 60% of the factors involved in hydrocodone metabolism. Inducing CYP2D6 with, for example, glutethimide or promethazine, also increases the hydrocodone-hydromorphone conversion in the liver, and promethazine is an opioid potentiator used with everything from codeine to alphaprodine in clinical settings, which may increase effects but also muddy the picture vis à vis serum levels at any given time.
Detection in bodily fluids.
Hydrocodone concentrations are measured in blood, plasma, and urine to seek evidence of misuse, to confirm diagnoses of poisoning, and to assist in investigations into deaths. Many commercial opiate screening tests react indiscriminately with hydrocodone, other opiates, and their metabolites, but chromatographic techniques can easily distinguish hydrocodone uniquely. Blood and plasma hydrocodone concentrations typically fall in the 5–30 µg/L range among people taking the drug therapeutically, 100–200 µg/L among recreational users, and 100–1,600 µg/L in cases of acute, fatal overdosage.
Regulation.
Australia.
In Australia, hydrocodone is a Schedule 8 (S8) or Controlled Drug.
Austria.
Hydrocodone is regulated in Austria in the same fashion as in Germany (see below) under the Austrian Suchtmittelgesetz; since 2002, it has been available in the form of German products and those produced elsewhere in the European Union under Article 76 of the Schengen Treaty—prior to this, no Austrian companies produced hydrocodone products, with dihydrocodeine, nicomorphine, and nicocodeine being more commonly used for the same levels of pain and the former and last for coughing. The latter two were Austrian inventions of the first years of the 20th Century.
Nicocodeine, the nicotinoyl ester of codeine, is virtually identical in strength to hydrocodone. A third, nicodicodeine, the dihydrocodeine analogue of nicocodeine, and acetyldihydrocodeine and thebacon, acetyl esters of dihydrocodeine and hydrocodone respectively, were also used. Nicocodeine is known as Tusscodin, and abroad as Lyopect. Nicocodeine is a prodrug for nicomorphine in the same way hydrocodone is for hydromorphone; nicomorphine is a strong opioid of the 3,6 diester (heroin-nicomorphine-dibenzoylmorphine) type, which is also stronger than morphine, not quite the milligram strength of hydromorphone, but with a faster onset of action.
Belgium.
In Belgium, hydrocodone is no longer available for medical use.
Canada.
In Canada, hydrocodone is a Schedule I controlled substance and is available by prescription only. Hydrocodone is prescribed alone as well as in proprietary combinations, typically with an NSAID or paracetamol.
France.
In France, hydrocodone is no longer available for medical use. Hydrocodone is a prohibited narcotic.
Germany.
In Germany, hydrocodone is no longer available for medical use. Hydrocodone is listed under the Betäubungsmittelgesetz as a "Suchtgift" in the same category as morphine.
Luxembourg.
In Luxembourg, hydrocodone is available by prescription under the name Biocodone. Prescriptions are more commonly given for use as a cough suppressant (antitussive) rather than for pain relief (analgesic).
The Netherlands.
In the Netherlands, hydrocodone is not available for medical use and is classified as a List 1 drug under the Opium Law.
Sweden.
Hydrocodone is no longer available for medical use in Sweden. The last remaining formula was deregistered in 1967.
United Kingdom.
In the United Kingdom, hydrocodone is not available for medical use and is listed as a Class A drug under the Misuse of Drugs Act 1971. Various formulations of dihydrocodeine, a weaker opioid, are frequently used as an alternative for the aforementioned indications of hydrocodone use.
United States.
In the United States, hydrocodone is a Schedule II controlled substance, ACSCN 9193, subject to DEA aggregate annual manufacturing quotas. In 2013, this quota was 99,625 kg, unchanged from the prior year.
Hydrocodone was usually not commercially available in pure form in the United States due to a separate regulation, and was typically sold with an NSAID, paracetamol (acetaminophen), antihistamine, expectorant, antibiotic or homatropine. In solid pill form, Zohydro ER contains only hydrocodone as its active ingredient in an extended release format. As of October 6, 2014 all hydrocodone products are listed as Schedule II Controlled substance. They will no longer be a Schedule III narcotic. Prescriptions can no longer have refills and a handwritten paper script must be obtained for each fill. In some states a Schedule II substance can be electronically prescribed if the doctor has the proper technology and an electronic signature license.
Prior to October 6, 2014, hydrocodone was listed as both a Schedule II and Schedule III substance, depending on the amount of hydrocodone and type and amount of additional ingredient it was compounded with:
Prior to August 1990, formulations with at least three active ingredients which were less than one-ten thousandth hydrocodone base by weight were Schedule V, meaning a handful of hydrocodone syrups including a phenyltoloxamine-based, decongestant-containing version of Tussionex were available OTC (for those willing to sign a Narcotic Exempt Register) in about a dozen states.
As of 2006, hydrocodone was the active antitussive in more than 200 formulations of cough syrups and tablets sold in the United States. In late 2006, the U.S. Food and Drug Administration (FDA) began forcing the recall of many of these formulations due to reports of deaths in infants and children under the age of six. The legal status of drug formulations originally sold between 1938 and 1962—before FDA approval was required—was ambiguous. As a result of FDA enforcement action, by August 2010, 88% of the hydrocodone-containing medications had been removed from the market. As a result, doctors, pharmacists, and codeine-sensitive or allergic patients or sensitive to the amounts of histamine released by its metabolites had to choose among rapidly dwindling supplies of the Hycodan-Codiclear-Hydromet type syrups, Tussionex—an extended-release suspension similar to the European products Codipertussin (codeine hydrochloride), Paracodin suspension (dihydrocodeine hydroiodide), Tusscodin (nicocodeine hydrochloride) and others—and a handful of weak dihydrocodeine syrups. The low sales volume and Schedule II status of dilaudid cough syrup predictably leads to under-utilisation of the drug. There are several conflicting views concerning the US availability of cough preparations containing ethylmorphine (also called dionine or codethyline)—Feco Syrup and its equivalents were first marketed circa 1895 and still in common use in the 1940s and 1950s, and the main ingredient is treated like codeine under the Controlled Substances Act of 1970.
As of July 2010, the FDA was considering banning some hydrocodone and oxycodone fixed-combination proprietary prescription drugs—based on the paracetamol content and the widespread occurrence of liver damage. FDA action on this suggestion would ostensibly also affect codeine and dihydrocodeine products such as the Tylenol With Codeine and Panlor series of drugs. In 2010, it was the most prescribed drug in the USA, with 131.2 million prescriptions of hydrocodone (combined with acetaminophen) being written.
The rationale of combining hydrocodone with other pain-killers is that the combination may increase efficacy, and the adverse effects may be reduced as compared with an equally effective dose of a single agent. A combination of hydrocodone and ibuprofen was more effective than either of the drugs on their own in relieving postoperative pain. The overall effect of the combination could be presented as a sum of the effects of ibuprofen and hydrocodone, which is consistent with differing mechanisms of action of these drugs. Similar results were observed for hydrocodone-acetaminophen combination.
Four pharmaceutical companies (Purdue Pharma, Cephalon, Egalet and Zogenix) are developing extended-release formulations of hydrocodone by itself; the Zogenix product was approved by the US FDA on October 25, 2013 and was launched in the 1st Quarter of the Market in 2014. These formulations were designed to avoid the issue of hepatotoxicity precipitated by acetaminophen. These new extended-release preparations also offer lower abuse potential.
On 25 October 2013, with support from critics of hydrocodone use and the DEA, the U.S. Food & Drug Administration proposed tightening control of the drug by reclassifying the existing Schedule III formulations of hydrocodone as Schedule II. Critics of the change included pharmaceutical firms, medical professionals, and patients, particularly those undergoing pain management, who stressed that reclassification is unnecessary and would be counter-productive to effectively provide pain relief for those suffering. One issue regarding Class II drugs as compared to Class III drugs is that doctors cannot "call in" Class II medications to a pharmacy over the phone or fax: the prescription must be hand written and taken to the pharmacy by the patient. Another issue with Class II drugs is that the doctor can only prescribe a one month supply at a time, which means the prescription cannot have any refills. Those opposed to reclassification also maintain that the existing protocol for prescribing opioids and the existing inclusion of acetaminophen along with other NSAIDs are effective measures in deterring misuse.
Effective October 6, 2014, was amended (at 79 FR ) to remove ACSCNs 9805 and 9806 from Schedule III, the result being that all hydrocodone-containing preparations are now Schedule II, regardless of amount of hydrocodone or additional components.
History.
Hydrocodone was first synthesized in Germany in 1920 by Carl Mannich and Helene Löwenheim. It was approved by the Food and Drug Administration on 23 March 1943 for sale in the United States and approved by Health Canada for sale in Canada under the brand name Hycodan.
Hydrocodone was first marketed by Knoll as Dicodid, starting in February 1924 in Germany. This name is analogous to other products the company introduced or otherwise marketed: Dilaudid (hydromorphone, 1926), Dinarkon (oxycodone, 1917), Dihydrin (dihydrocodeine, 1911), and Dimorphan (dihydromorphine). Paramorfan is the trade name of dihydromorphine from another manufacturer, as is Paracodin, for dihydrocodeine.
The name Dicodid was registered in the United States and appears without a monograph as late as 1978 in the Physicians' Desk Reference; Dicodid may have been marketed to one extent or another in North America in the 1920s and early 1930s. The drug was pure hydrocodone in small 5 and 10 mg tablets, physically similar to the Dilaudid tablets. It is no longer manufactured by Knoll in Germany, nor is a generic available. Hydrocodone was never as common in Europe as it is in North America—dihydrocodeine is used for its spectrum of indications. Germany was the number two consumer of hydrocodone until the manufacture of the drug was discontinued there. Now, the world outside the United States accounts for less than 1% of annual consumption. It was listed as a "Suchtgift" under the German Betäubungsmittelgesetz and regulated like morphine. It became available in the Schengen Zone of the European Union as of 1 January 2002 under Title 76 of the Schengen Treaty.

</doc>
<doc id="14415" url="http://en.wikipedia.org/wiki?curid=14415" title="Hashish">
Hashish

Hashish, or hash, is a cannabis product composed of compressed or purified preparations of stalked resin glands, called trichomes. It contains the same active ingredients—such as tetrahydrocannabinol (THC) and other cannabinoids—but often in higher concentrations than unsifted buds or leaves.
Hashish may be solid or resinous depending on the preparation; pressed hashish is usually solid, whereas water-purified hashish—often called "bubble melt hash"—is often a paste-like substance with varying hardness and pliability, its color most commonly light to dark brown can vary to seethrough glass varying toward yellow/tan, black or red. This all depends on the process and amount of solvent left over.
History.
The name hashish comes from the Arabic word ( حشيش ) which means grass. It is believed that massive hashish production for international trade originated in Morocco during the 1960s, where the cannabis plant was widely available. Before the coming of the first hippies from the "Hippie Hashish Trail", only small pieces of Lebanese hashish were found in Morocco. However, hemp has been reported from a cultural setting on Taiwan as long ago as 10,000 BC., and "[t]he earliest human use of Cannabis appears to have occurred in the steppe regions of Central Asia or in China."
Northern India has a long social tradition in the production of hashish, known locally as "charas", which is believed to be the same plant resin as was burned in the ceremonial "booz rooz" of Ancient Persia. "Cannabis indica" grows wild almost everywhere on the Indian sub-continent, and special strains have been particularly cultivated for production of "ganja" and "hashish" particularly in West Bengal, Rajasthan and the Himalayas.
In 1596, Dutchman Jan Huyghen van Linschoten spent three pages on "Bangue" ("bhang") in his historic work documenting his journeys in the East. He particularly mentioned the Egyptian Hashish. He said, "Bangue is likewise much used in Turkie and Egypt, and is made in three sorts, having also three names. The first by the Egyptians is called Assis (Hashish (Arab.)), which is the poulder of Hemp, or of Hemp leaves, which is water made in paste or dough, they would eat five peeces, (each) as big as a Chestnut (or larger); This is used by the common people, because it is of a small price, and it is no wonder, that such vertue proceedeth from the Hempe, for that according to Galens opinion, Hempe excessively filleth the head."
Use.
It is consumed by being heated in a pipe, hookah, bong, bubbler, vaporizer, hot knife (placed between the tips of two heated knife blades), smoked in joints, mixed with cannabis buds or tobacco, smoked as bottle tokes ("brewing bots", "bucket bongs") or cooked in food, especially sweets.
Manufacturing processes.
Hashish is made from cannabinoid-rich glandular hairs known as trichomes, as well as varying amounts of cannabis flower and leaf fragments. The flowers of a mature female plant contain the most trichomes, though trichomes are also found on other parts of the plant. Certain strains of cannabis are cultivated specifically for their ability to produce large amounts of trichomes. The resin reservoirs of the trichomes, sometimes erroneously called pollen (vendors often use the euphemism "pollen catchers" to describe screened kief-grinders in order to skirt paraphernalia selling laws), are separated from the plant through various methods.
Mechanical separation methods use physical action to remove the trichomes from the plant, such as sieving through a screen by hand or in motorized tumblers. This technique is known as "drysifting". The resulting powder, referred to as "kief" or "drysift", is compressed with the aid of heat into blocks of hashish; if pure, the kief will become gooey and pliable. When a high level of pure THC is present, the end product will be almost transparent and will start to melt at the point of human contact. Ice-water separation is another mechanical method of isolating trichomes. The clarity of the final product determines quality of the final product. Nowadays, new techniques have been developed, such as heat and pressure separations, static-electricity sieving or acoustical dry sieving.
Chemical separation methods generally use a solvent such as ethanol, butane or hexane to dissolve the lipophilic desirable resin. Remaining plant materials are filtered out of the solution and sent to the compost. The solvent is then evaporated, or boiled off (purged) leaving behind the desirable resins, called honey oil, "hash oil", or just "oil". Honey oil still contains waxes and essential oils and can be further purified by vacuum distillation to yield "red oil". The product of chemical separations is more commonly referred to as "honey oil." This oil is not really hashish, as the latter name covers trichomes that are extracted by sieving. This leaves most of the glands intact.
Quality.
Tiny pieces of leaf matter may be accidentally or even purposefully added; adulterants introduced when the hash is being produced will reduce the purity of the material and often resulting in green finished product. The tetrahydrocannabinol (THC) content of hashish comes in wide ranges from almost none to 65% and that of hash oil from 30–90%.

</doc>
<doc id="14417" url="http://en.wikipedia.org/wiki?curid=14417" title="Hypnosis">
Hypnosis

Hypnosis is a state of human consciousness involving focused attention and reduced peripheral awareness characterized by an enhanced capacity for response to suggestion. Theories explaining what occurs during hypnosis fall into two groups. "Altered state" theories see hypnosis as an altered state of mind or trance, marked by a level of awareness different from the ordinary conscious state. In contrast, "Non-state" theories see hypnosis as a form of imaginative role-enactment.
During hypnosis, a person is said to have heightened focus and concentration. The person can concentrate intensely on a specific thought or memory, while blocking out sources of distraction. Hypnotised subjects are said to show an increased response to suggestions.
Hypnosis is usually induced by a procedure known as a hypnotic induction involving a series of preliminary instructions and suggestions. The use of hypnotism for therapeutic purposes is referred to as "hypnotherapy", while its use as a form of entertainment for an audience is known as "stage hypnosis".
Etymology.
The term "hypnosis" comes from the Ancient Greek word ὕπνος "hypnos", "sleep", and the suffix -ωσις -"osis", or from ὑπνόω "hypnoō", "put to sleep" (stem of aorist "hypnōs"-) and the suffix -"is". The words "hypnosis" and "hypnotism" both derive from the term "neuro-hypnotism" (nervous sleep), all of which were coined by the Scottish surgeon James Braid around 1841. Braid based his practice on that developed by Franz Mesmer and his followers (which was called "Mesmerism" or "animal magnetism"), but differed in his theory as to how the procedure worked.
Characteristics.
A person in a state of hypnosis is relaxed, has focused attention, and has increased suggestibility.
The hypnotized individual appears to heed only the communications of the hypnotist. He seems to respond in an uncritical, automatic fashion, ignoring all aspects of the environment other than those pointed out to him by the hypnotist. He sees, feels, smells, and otherwise perceives in accordance with the hypnotist's suggestions, even though these suggestions may be in apparent contradiction to the stimuli that impinge upon him. Even the subject's memory and awareness of self may be altered by suggestion, and the effects of the suggestions may be extended (posthypnotically) into the subject's subsequent waking activity.
It could be said that hypnotic suggestion is explicitly intended to make use of the placebo effect. For example, in 1994, Irving Kirsch distinguished hypnosis as a "nondeceptive placebo," "i.e.", a method that openly makes use of suggestion and employs methods to amplify its effects.
Definitions.
The earliest definition of hypnosis was given by Braid, who coined the term "hypnotism" as an abbreviation for "neuro-hypnotism", or nervous sleep, which he opposed to "normal" sleep, and defined as: "a peculiar condition of the nervous system, induced by a fixed and abstracted attention of the mental and visual eye, on one object, not of an exciting nature."
Braid elaborated upon this brief definition in a later work, "Hypnotic Therapeutics":
the real origin and essence of the hypnotic condition, is the induction of a habit of abstraction or mental concentration, in which, as in reverie or spontaneous abstraction, the powers of the mind are so much engrossed with a single idea or train of thought, as, for the nonce, to render the individual unconscious of, or indifferently conscious to, all other ideas, impressions, or trains of thought. The "hypnotic" sleep, therefore, is the very antithesis or opposite mental and physical condition to that which precedes and accompanies "common" sleep
Therefore, Braid defined hypnotism as a state of mental concentration that often leads to a form of progressive relaxation, termed "nervous sleep". Later, in his "The Physiology of Fascination" (1855), Braid conceded that his original terminology was misleading, and argued that the term "hypnotism" or "nervous sleep" should be reserved for the minority (10%) of subjects who exhibit amnesia, substituting the term "monoideism", meaning concentration upon a single idea, as a description for the more alert state experienced by the others.
A new definition of hypnosis, derived from academic psychology, was provided in 2005, when the Society for Psychological Hypnosis, Division 30 of the American Psychological Association (APA), published the following formal definition:
 New Definition: Hypnosis
The Division 30 Definition and Description of Hypnosis
Hypnosis typically involves an introduction to the procedure during which the subject is told that suggestions for imaginative experiences will be presented. The hypnotic induction is an extended initial suggestion for using one's imagination, and may contain further elaborations of the introduction. A hypnotic procedure is used to encourage and evaluate responses to suggestions. When using hypnosis, one person (the subject) is guided by another (the hypnotist) to respond to suggestions for changes in subjective experience, alterations in perception, sensation, emotion, thought or behavior. Persons can also learn self-hypnosis, which is the act of administering hypnotic procedures on one's own. If the subject responds to hypnotic suggestions, it is generally inferred that hypnosis has been induced. Many believe that hypnotic responses and experiences are characteristic of a hypnotic state. While some think that it is not necessary to use the word "hypnosis" as part of the hypnotic induction, others view it as essential.
Michael Nash provides a list of eight definitions of hypnosis by different authors, in addition to his own view that hypnosis is "a special case of psychological regression":
1. Janet, near the turn of the century, and more recently Ernest Hilgard ..., have defined hypnosis in terms of dissociation.
2. Social psychologists Sarbin and Coe ... have described hypnosis in terms of role theory. Hypnosis is a role that people play; they act "as if" they were hypnotized.
3. T. X. Barber ... defined hypnosis in terms of nonhypnotic behavioral parameters, such as task motivation and the act of labeling the situation as hypnosis.
4. In his early writings, Weitzenhoffer ... conceptualized hypnosis as a state of enhanced suggestibility. Most recently ... he has defined hypnotism as "a form of influence by one person exerted on another through the medium or agency of suggestion."
5. Psychoanalysts Gill and Brenman ... described hypnosis by using the psychoanalytic concept of "regression in the service of the ego."
6. Edmonston ... has assessed hypnosis as being merely a state of relaxation.
7. Spiegel and Spiegel ... have implied that hypnosis is a biological capacity.
8. Erickson ... is considered the leading exponent of the position that hypnosis is a special, inner-directed, altered state of functioning.
Joe Griffin and Ivan Tyrrell (the originators of the human givens approach) define hypnosis as "any artificial way of accessing the REM state, the same brain state in which dreaming occurs" and they suggest that this definition, when properly understood, resolves "many of the mysteries and controversies surrounding hypnosis". They see the REM state as being vitally important for life itself, for programming in our instinctive knowledge initially (after Dement and Jouvet) and then for adding to this throughout life. They explain this by pointing out that, in a sense, all learning is post-hypnotic, which explains why the number of ways people can be put into a hypnotic state are so varied: anything that focuses our attention, inward or outward, puts us into a trance.
Hypnotic induction.
Hypnosis is normally preceded by a "hypnotic induction" technique. Traditionally, this was interpreted as a method of putting the subject into a "hypnotic trance"; however, subsequent "nonstate" theorists have viewed it differently, seeing it as a means of heightening client expectation, defining their role, focusing attention, etc. There are several different induction techniques. One of the most influential methods was Braid's "eye-fixation" technique, also known as "Braidism". Many variations of the eye-fixation approach exist, including the induction used in the Stanford Hypnotic Susceptibility Scale (SHSS), the most widely used research tool in the field of hypnotism. Braid's original description of his induction is as follows: James Braid's Original Eye-Fixation Hypnotic Induction Method
Take any bright object (e.g. a lancet case) between the thumb and fore and middle fingers of the left hand; hold it from about eight to fifteen inches from the eyes, at such position above the forehead as may be necessary to produce the greatest possible strain upon the eyes and eyelids, and enable the patient to maintain a steady fixed stare at the object. The patient must be made to understand that he is to keep the eyes steadily fixed on the object, and the mind riveted on the idea of that one object. It will be observed, that owing to the consensual adjustment of the eyes, the pupils will be at first contracted: They will shortly begin to dilate, and, after they have done so to a considerable extent, and have assumed a wavy motion, if the fore and middle fingers of the right hand, extended and a little separated, are carried from the object toward the eyes, most probably the eyelids will close involuntarily, with a vibratory motion. If this is not the case, or the patient allows the eyeballs to move, desire him to begin anew, giving him to understand that he is to allow the eyelids to close when the fingers are again carried towards the eyes, but that the eyeballs must be kept fixed, in the same position, and the mind riveted to the one idea of the object held above the eyes. In general, it will be found, that the eyelids close with a vibratory motion, or become spasmodically closed.
Braid later acknowledged that the hypnotic induction technique was not necessary in every case and subsequent researchers have generally found that on average it contributes less than previously expected to the effect of hypnotic suggestions. Variations and alternatives to the original hypnotic induction techniques were subsequently developed. However, this method is still considered authoritative: "It can be safely stated that nine out of ten hypnotic techniques call for reclining posture, muscular relaxation, and optical fixation followed by eye closure."
Suggestion.
When James Braid first described hypnotism, he did not use the term "suggestion" but referred instead to the act of focusing the conscious mind of the subject upon a single dominant idea. Braid's main therapeutic strategy involved stimulating or reducing physiological functioning in different regions of the body. In his later works, however, Braid placed increasing emphasis upon the use of a variety of different verbal and non-verbal forms of suggestion, including the use of "waking suggestion" and self-hypnosis. Subsequently, Hippolyte Bernheim shifted the emphasis from the physical state of hypnosis on to the psychological process of verbal suggestion.
I define hypnotism as the induction of a peculiar psychical [i.e., mental] condition which increases the susceptibility to suggestion. Often, it is true, the [hypnotic] sleep that may be induced facilitates suggestion, but it is not the necessary preliminary. It is suggestion that rules hypnotism.
Bernheim's conception of the primacy of verbal suggestion in hypnotism dominated the subject throughout the twentieth century, leading some authorities to declare him the father of modern hypnotism.
Contemporary hypnotism uses a variety of suggestion forms including direct verbal suggestions, "indirect" verbal suggestions such as requests or insinuations, metaphors and other rhetorical figures of speech, and non-verbal suggestion in the form of mental imagery, voice tonality, and physical manipulation. A distinction is commonly made between suggestions delivered "permissively" and those delivered in a more "authoritarian" manner. Harvard hypnotherapist Deirdre Barrett writes that most modern research suggestions are designed to bring about immediate responses, whereas hypnotherapeutic suggestions are usually post-hypnotic ones that are intended to trigger responses affecting behavior for periods ranging from days to a lifetime in duration. The hypnotherapeutic ones are often repeated in multiple sessions before they achieve peak effectiveness.
The conscious and the unconscious mind.
Some hypnotists view suggestion as a form of communication that is directed primarily to the subject's conscious mind, whereas others view it as a means of communicating with the "unconscious" or "subconscious" mind. These concepts were introduced into hypnotism at the end of the 19th century by Sigmund Freud and Pierre Janet. Sigmund Freud's psychoanalytic theory describes conscious thoughts as being at the surface of the mind and unconscious processes as being deeper in the mind. Braid, Bernheim and other Victorian pioneers of hypnotism did not refer to the unconscious mind but saw hypnotic suggestions as being addressed to the subject's "conscious" mind. Indeed, Braid actually defines hypnotism as focused (conscious) attention upon a dominant idea (or suggestion). Different views regarding the nature of the mind have led to different conceptions of suggestion. Hypnotists who believe that responses are mediated primarily by an "unconscious mind", like Milton Erickson, make use of indirect suggestions such as metaphors or stories whose intended meaning may be concealed from the subject's conscious mind. The concept of subliminal suggestion depends upon this view of the mind. By contrast, hypnotists who believe that responses to suggestion are primarily mediated by the conscious mind, such as Theodore Barber and Nicholas Spanos, have tended to make more use of direct verbal suggestions and instructions.
Ideo-dynamic reflex.
The first neuropsychological theory of hypnotic suggestion was introduced early on by James Braid who adopted his friend and colleague William Carpenter's theory of the ideo-motor reflex response to account for the phenomenon of hypnotism. Carpenter had observed from close examination of everyday experience that under certain circumstances the mere idea of a muscular movement could be sufficient to produce a reflexive, or automatic, contraction or movement of the muscles involved, albeit in a very small degree. Braid extended Carpenter's theory to encompass the observation that a wide variety of bodily responses besides muscular movement can be thus affected, for example, the idea of sucking a lemon can automatically stimulate salivation, a secretory response. Braid, therefore, adopted the term "ideo-dynamic", meaning "by the power of an idea", to explain a broad range of "psycho-physiological" (mind-body) phenomena. Braid coined the term "mono-ideodynamic" to refer to the theory that hypnotism operates by concentrating attention on a single idea in order to amplify the ideo-dynamic reflex response. Variations of the basic ideo-motor, or ideo-dynamic, theory of suggestion have continued to exercise considerable influence over subsequent theories of hypnosis, including those of Clark L. Hull, Hans Eysenck, and Ernest Rossi. It should be noted that in Victorian psychology the word "idea" encompasses any mental representation, including mental imagery, memories, etc.
Susceptibility.
Braid made a rough distinction between different stages of hypnosis, which he termed the first and second conscious stage of hypnotism; he later replaced this with a distinction between "sub-hypnotic", "full hypnotic", and "hypnotic coma" stages. Jean-Martin Charcot made a similar distinction between stages which he named somnambulism, lethargy, and catalepsy. However, Ambroise-Auguste Liébeault and Hippolyte Bernheim introduced more complex hypnotic "depth" scales based on a combination of behavioural, physiological and subjective responses, some of which were due to direct suggestion and some of which were not. In the first few decades of the 20th century, these early clinical "depth" scales were superseded by more sophisticated "hypnotic susceptibility" scales based on experimental research. The most influential were the Davis-Husband and Friedlander-Sarbin scales developed in the 1930s. André Weitzenhoffer and Ernest R. Hilgard developed the Stanford Scale of Hypnotic Susceptibility in 1959, consisting of 12 suggestion test items following a standardised hypnotic eye-fixation induction script, and this has become one of the most widely referenced research tools in the field of hypnosis. Soon after, in 1962, Ronald Shor and Emily Carota Orne developed a similar group scale called the Harvard Group Scale of Hypnotic Susceptibility (HGSHS).
Whereas the older "depth scales" tried to infer the level of "hypnotic trance" from supposed observable signs such as spontaneous amnesia, most subsequent scales have measured the degree of observed or self-evaluated "responsiveness" to specific suggestion tests such as direct suggestions of arm rigidity (catalepsy). The Stanford, Harvard, HIP, and most other susceptibility scales convert numbers into an assessment of a person's susceptibility as 'high', 'medium', or 'low'. Approximately 80% of the population are medium, 10% are high and 10% are low. There is some controversy as to whether this is distributed on a “normal” bell-shaped curve or whether it is bi-modal with a small “blip” of people at the high end. Hypnotizability Scores are highly stable over a person’s lifetime. Research by Deirdre Barrett has found that there are two distinct types of highly susceptible subjects, which she terms fantasizers and dissociaters. Fantasizers score high on absorption scales, find it easy to block out real-world stimuli without hypnosis, spend much time daydreaming, report imaginary companions as a child and grew up with parents who encouraged imaginary play. Dissociaters often have a history of childhood abuse or other trauma, learned to escape into numbness, and to forget unpleasant events. Their association to “daydreaming” was often going blank rather than creating vividly recalled fantasies. Both score equally high on formal scales of hypnotic susceptibility.
Individuals with dissociative identity disorder have the highest hypnotizability of any clinical group, followed by those with posttraumatic stress disorder.
History.
Precursors.
According to his writings, Braid began to hear reports concerning various Oriental meditative practices soon after the release of his first publication on hypnotism, "Neurypnology" (1843). He first discussed some of these oriental practices in a series of articles entitled "Magic, Mesmerism, Hypnotism, etc., Historically & Physiologically Considered". He drew analogies between his own practice of hypnotism and various forms of Hindu yoga meditation and other ancient spiritual practices, especially those involving voluntary burial and apparent human hibernation. Braid’s interest in these practices stems from his studies of the "Dabistān-i Mazāhib", the “School of Religions”, an ancient Persian text describing a wide variety of Oriental religious rituals, beliefs, and practices.
Last May [1843], a gentleman residing in Edinburgh, personally unknown to me, who had long resided in India, favored me with a letter expressing his approbation of the views which I had published on the nature and causes of hypnotic and mesmeric phenomena. In corroboration of my views, he referred to what he had previously witnessed in oriental regions, and recommended me to look into the “Dabistan,” a book lately published, for additional proof to the same effect. On much recommendation I immediately sent for a copy of the “Dabistan”, in which I found many statements corroborative of the fact, that the eastern saints are all self-hypnotisers, adopting means essentially the same as those which I had recommended for similar purposes.
Although he rejected the transcendental/metaphysical interpretation given to these phenomena outright, Braid accepted that these accounts of Oriental practices supported his view that the effects of hypnotism could be produced in solitude, without the presence of any other person (as he had already proved to his own satisfaction with the experiments he had conducted in November 1841); and he saw correlations between many of the "metaphysical" Oriental practices and his own "rational" neuro-hypnotism, and totally rejected all of the fluid theories and magnetic practices of the mesmerists. As he later wrote:
In as much as patients can throw themselves into the nervous sleep, and manifest all the usual phenomena of Mesmerism, through their own unaided efforts, as I have so repeatedly proved by causing them to maintain a steady fixed gaze at any point, concentrating their whole mental energies on the idea of the object looked at; or that the same may arise by the patient looking at the point of his own finger, or as the Magi of Persia and Yogi of India have practised for the last 2,400 years, for religious purposes, throwing themselves into their ecstatic trances by each maintaining a steady fixed gaze at the tip of his own nose; it is obvious that there is no need for an exoteric influence to produce the phenomena of Mesmerism. […] The great object in all these processes is to induce a habit of abstraction or concentration of attention, in which the subject is entirely absorbed with one idea, or train of ideas, whilst he is unconscious of, or indifferently conscious to, every other object, purpose, or action.
Franz Mesmer.
Franz Mesmer (1734–1815) believed that there is a magnetic force or "fluid" within the universe that influences the health of the human body. He experimented with magnets to impact this field in order to produce healing. By around 1774, he had concluded that the same effect could be created by passing the hands in front of the subject's body, later referred to as making "Mesmeric passes." The word "mesmerize", formed from the last name of Franz Mesmer, was intentionally used to separate practitioners of mesmerism from the various "fluid" and "magnetic" theories included within the label "magnetism".
In 1784, at the request of King Louis XVI, a Board of Inquiry started to investigate whether Animal Magnetism existed. Among the board members were founding father of modern chemistry Antoine Lavoisier, Benjamin Franklin, and an expert in pain control, Joseph-Ignace Guillotin. They investigated the practices of a disaffected student of Mesmer, one Charles d'Eslon (1750–1786), and though they concluded that Mesmer's results were valid, their placebo-controlled experiments using d'Eslon's methods convinced them that mesmerism was most likely due to belief and imagination rather than to an invisible energy ("animal magnetism") transmitted from the body of the mesmerist.
In writing the majority opinion, Franklin said, "This fellow Mesmer is not flowing anything from his hands that I can see. Therefore, this mesmerism must be a fraud." Mesmer left Paris and went back to Vienna to practise mesmerism.
James Braid.
Following the French committee's findings, Dugald Stewart, an influential academic philosopher of the "Scottish School of Common Sense", encouraged physicians in his "Elements of the Philosophy of the Human Mind" (1818), to salvage elements of Mesmerism by replacing the supernatural theory of "animal magnetism" with a new interpretation based upon "common sense" laws of physiology and psychology. Braid quotes the following passage from Stewart:
It appears to me, that the general conclusions established by Mesmer’s practice, with respect to the physical effects of the principle of imagination (more particularly in cases where they co-operated together), are incomparably more curious than if he had actually demonstrated the existence of his boasted science [of "animal magnetism"]: nor can I see any good reason why a physician, who admits the efficacy of the moral [i.e., psychological] agents employed by Mesmer, should, in the exercise of his profession, scruple to copy whatever processes are necessary for subjecting them to his command, any more than that he should hesitate about employing a new physical agent, such as electricity or galvanism.
In Braid's day, the Scottish School of Common Sense provided the dominant theories of academic psychology and Braid refers to other philosophers within this tradition throughout his writings. Braid therefore revised the theory and practice of Mesmerism and developed his own method of hypnotism as a more rational and common sense alternative.
It may here be requisite for me to explain, that by the term Hypnotism, or Nervous Sleep, which frequently occurs in the following pages, I mean a peculiar condition of the nervous system, into which it may be thrown by artificial contrivance, and which differs, in several respects, from common sleep or the waking condition. I do not allege that this condition is induced through the transmission of a magnetic or occult influence from my body into that of my patients; nor do I profess, by my processes, to produce the higher [i.e., supernatural] phenomena of the Mesmerists. My pretensions are of a much more humble character, and are all consistent with generally admitted principles in physiological and psychological science. Hypnotism might therefore not inaptly be designated, Rational Mesmerism, in contra-distinction to the Transcendental Mesmerism of the Mesmerists.
Despite briefly toying with the name "rational Mesmerism", Braid ultimately chose to emphasise the unique aspects of his approach, carrying out informal experiments throughout his career in order to refute practices that invoked supernatural forces and demonstrating instead the role of ordinary physiological and psychological processes such as suggestion and focused attention in producing the observed effects.
Braid worked very closely with his friend and ally the eminent physiologist Professor William Benjamin Carpenter, an early neuro-psychologist who introduced the "ideo-motor reflex" theory of suggestion. Carpenter had observed instances of expectation and imagination apparently influencing involuntary muscle movement. A classic example of the ideo-motor principle in action is the so-called "Chevreul pendulum" (named after Michel Eugène Chevreul). Chevreul claimed that divinatory pendulae were made to swing by unconscious muscle movements brought about by focused concentration alone.
Braid soon assimilated Carpenter's observations into his own theory, realising that the effect of focusing attention was to enhance the ideo-motor reflex response. Braid extended Carpenter's theory to encompass the influence of the mind upon the body more generally, beyond the muscular system, and therefore referred to the "ideo-dynamic" response and coined the term "psycho-physiology" to refer to the study of general mind/body interaction.
In his later works Braid reserved the term "hypnotism" for cases in which subjects entered a state of amnesia resembling sleep. For other cases, he spoke of a "mono-ideodynamic" principle to emphasise that the eye-fixation induction technique worked by narrowing the subject's attention to a single idea or train of thought ("monoideism"), which amplified the effect of the consequent "dominant idea" upon the subject's body by means of the ideo-dynamic principle.
Hysteria vs. suggestion.
For several decades Braid's work became more influential abroad than in his own country, except for a handful of followers, most notably Dr. John Milne Bramwell. The eminent neurologist Dr. George Miller Beard took Braid's theories to America. Meanwhile, his works were translated into German by William Thierry Preyer, Professor of Physiology at Jena University. The psychiatrist Albert Moll subsequently continued German research, publishing "Hypnotism" in 1889. France became the focal point for the study of Braid's ideas after the eminent neurologist Dr. Étienne Eugène Azam translated Braid's last manuscript ("On Hypnotism", 1860) into French and presented Braid's research to the French Academy of Sciences. At the request of Azam, Paul Broca, and others, the French Academy of Science, which had investigated Mesmerism in 1784, examined Braid's writings shortly after his demise.
Azam's enthusiasm for hypnotism influenced Ambroise-Auguste Liébeault, a country doctor. Hippolyte Bernheim discovered Liébeault's enormously popular group hypnotherapy clinic and subsequently became an influential hypnotist. The study of hypnotism subsequently revolved around the fierce debate between Jean-Martin Charcot and Hippolyte Bernheim, the two most influential figures in late 19th-century hypnotism.
Charcot operated a clinic at the Pitié-Salpêtrière Hospital (thus, known as the "Paris School" or the "Salpêtrière School"), while Bernheim had a clinic in Nancy (known as the "Nancy School"). Charcot, who was influenced more by the Mesmerists, argued that hypnotism was an abnormal state of nervous functioning found only in certain hysterical women. He claimed that it manifested in a series of physical reactions that could be divided into distinct stages. Bernheim argued that anyone could be hypnotised, that it was an extension of normal psychological functioning, and that its effects were due to suggestion. After decades of debate, Bernheim's view dominated. Charcot's theory is now just a historical curiosity.
Pierre Janet.
Pierre Janet (1859–1947) reported studies on a hypnotic subject in 1882. Charcot subsequently appointed him director of the psychological laboratory at the Salpêtrière in 1889, after Janet had completed his PhD, which dealt with psychological automatism. In 1898 Janet was appointed psychology lecturer at the Sorbonne, and in 1902 he became chair of experimental and comparative psychology at the Collège de France. Janet reconciled elements of his views with those of Bernheim and his followers, developing his own sophisticated hypnotic psychotherapy based upon the concept of psychological dissociation, which, at the turn of the century, rivalled Freud's attempt to provide a more comprehensive theory of psychotherapy.
Sigmund Freud.
Sigmund Freud, the founder of psychoanalysis (1856 – 1939), studied hypnotism at the Paris School and briefly visited the Nancy School.
At first Sigmund Freud was an enthusiastic proponent of hypnotherapy. He "initially hypnotised patients and pressed on their foreheads to help them concentrate while attempting to recover (supposedly) repressed memories", and he soon began to emphasise hypnotic regression and ab reaction (catharsis) as therapeutic methods. He wrote a favorable encyclopedia article on hypnotism, translated one of Bernheim's works into German, and published an influential series of case studies with his colleague Joseph Breuer entitled "Studies on Hysteria" (1895). This became the founding text of the subsequent tradition known as "hypno-analysis" or "regression hypnotherapy."
However, Freud gradually abandoned hypnotism in favour of psychoanalysis, emphasizing free association and interpretation of the unconscious. Struggling with the great expense of time that psychoanalysis required, Freud later suggested that it might be combined with hypnotic suggestion to hasten the outcome of treatment,
It is very probable, too, that the application of our therapy to numbers will compel us to alloy the pure gold of analysis plentifully with the copper of direct [hypnotic] suggestion.
However, only a handful of Freud's followers were sufficiently qualified in hypnosis to attempt the synthesis. Their work had a limited influence on the hypno-therapeutic approaches now known variously as "hypnotic regression", "hypnotic progression", and "hypnoanalysis".
Émile Coué.
Émile Coué (1857–1926) assisted Ambroise-Auguste Liébeault for around two years at Nancy. After practising for several years as a hypnotherapist employing the methods of Liébeault and Bernheim's Nancy School, Coué developed a new orientation called "conscious autosuggestion." Several years after Liébeault's death in 1904, Coué founded what became known as the New Nancy School, a loose collaboration of practitioners who taught and promoted his views. Coué's method did not emphasise "sleep" or deep relaxation and instead focused upon autosuggestion involving a specific series of suggestion tests. Although Coué argued that he was no longer using hypnosis, followers such as Charles Baudouin viewed his approach as a form of light self-hypnosis. Coué's method became a renowned self-help and psychotherapy technique, which contrasted with psychoanalysis and prefigured self-hypnosis and cognitive therapy.
Clark L. Hull.
The next major development came from behavioral psychology in American university research. Clark L. Hull, an eminent American psychologist (1884 – 1952), published the first major compilation of laboratory studies on hypnosis, "Hypnosis & Suggestibility" (1933), in which he proved that hypnosis and sleep had nothing in common. Hull published many quantitative findings from hypnosis and suggestion experiments and encouraged research by mainstream psychologists. Hull's behavioural psychology interpretation of hypnosis, emphasising conditioned reflexes, rivalled the Freudian psycho-dynamic interpretation which emphasised unconscious transference.
Dave Elman.
Although Dave Elman (1900–1967) was a noted radio host, comedian and (song)writer, he also made a name as a hypnotist. He led many courses for physicians and wrote in 1964 the classic book: 'Findings in Hypnosis', later to be re-titled 'Hypnotherapy' (published by Westwood Publishing).
Perhaps the most well known aspect of Elman's legacy is his method of induction, which was originally fashioned for speed work and later adapted for the use of medical professionals; his students routinely obtained states of hypnosis adequate for medical and surgical procedures in under three minutes. His book and recordings provide much more than just his rapid induction techniques, however. The first heart operation using hypnosis rather than normal anesthesia (because of severe problems with the patient) was performed by his students with Dave Elman in the operating room as "coach".
Milton Erickson.
Milton H. Erickson, M.D. (1901 – 1980) was one of the most influential post-war hypnotherapists. He wrote several books and journal articles on the subject. During the 1960s, Erickson popularized a new branch of hypnotherapy, known as Ericksonian therapy, characterised primarily by indirect suggestion, "metaphor" (actually analogies), confusion techniques, and double binds in place of formal hypnotic inductions. However, the difference between Erickson's methods and traditional hypnotism led contemporaries such as André Weitzenhoffer to question whether he was practising "hypnosis" at all, and his approach remains in question.
Erickson had no hesitation in presenting any suggested effect as being "hypnosis", whether or not the subject was in a hypnotic state. In fact, he was not hesitant in passing off behaviour that was dubiously hypnotic as being hypnotic.
Cognitive-behavioural.
In the latter half of the twentieth century, two factors contributed to the development of the "cognitive-behavioural" approach to hypnosis:
Although cognitive-behavioural theories of hypnosis must be distinguished from cognitive-behavioural approaches to "hypnotherapy", they share similar concepts, terminology, and assumptions and have been integrated by influential researchers and clinicians such as Irving Kirsch, Steven Jay Lynn, and others.
At the outset of cognitive-behavioural therapy during the 1950s, hypnosis was used by early behaviour therapists such as Joseph Wolpe and also by early cognitive therapists such as Albert Ellis. Barber, Spanos and Chaves introduced the term "cognitive-behavioural" to describe their "nonstate" theory of hypnosis in "Hypnosis, imagination, and human potentialities". However, Clark L. Hull had introduced a behavioural psychology as far back as 1933, which in turn was preceded by Ivan Pavlov. Indeed, the earliest theories and practices of hypnotism, even those of Braid, resemble the cognitive-behavioural orientation in some respects.
Applications.
There are numerous applications for hypnosis across multiple fields of interest including medical/psychotherapeutic uses, military uses, self-improvement, and entertainment.
Hypnotism has also been used in forensics, sports, education, physical therapy and rehabilitation. Hypnotism has also been employed by artists for creative purposes, most notably the surrealist circle of André Breton who employed hypnosis, automatic writing and sketches for creative purposes. Hypnotic methods have been used to re-experience drug states and mystical experiences. Self-hypnosis is popularly used to quit smoking and reduce stress, while stage hypnosis can persuade people to perform unusual public feats.
Some people have drawn analogies between certain aspects of hypnotism and areas such as crowd psychology, religious hysteria, and ritual trances in preliterate tribal cultures.
Hypnotherapy.
Hypnotherapy is a use of hypnosis in psychotherapy. It is used by licensed physicians, psychologists, and others. Physicians and psychologists may use hypnosis to treat depression, anxiety, eating disorders, sleep disorders, compulsive gaming, and posttraumatic stress, while certified hypnotherapists who are not physicians or psychologists often treat smoking and weight management.
Hypnotherapy is a helpful adjunct having additive effects when treating psychological disorders, such as these, along with scientifically proven cognitive therapies. Hypnotherapy should not be used for repairing or refreshing memory, because hypnosis results in memory hardening which increases the confidence in false memories.
Modern hypnotherapy has been used in a variety of forms with varying success, such as:
In a January 2001 article in Psychology Today Harvard psychologist Deirdre Barrett wrote:
A hypnotic trance is not therapeutic in and of itself, but specific suggestions and images fed to clients in a trance can profoundly alter their behavior. As they rehearse the new ways they want to think and feel, they lay the groundwork for changes in their future actions... and she described specific ways this is operationalized for habit change and amelioration of phobias. In her 1998 book of hypnotherapy case studies, she reviews the clinical research on hypnosis with dissociative disorders, smoking cessation, and insomnia and describes successful treatments of these complaints.
In a July 2001 article for "Scientific American" titled "The Truth and the Hype of Hypnosis", Michael Nash wrote:
...using hypnosis, scientists have temporarily created hallucinations, compulsions, certain types of memory loss, false memories, and delusions in the laboratory so that these phenomena can be studied in a controlled environment.
Irritable bowel syndrome.
Hypnotherapy has been studied for the treatment of irritable bowel syndrome. Hypnosis for IBS has received moderate support in the National Institute for Health and Clinical Excellence guidance published for UK health services. It has been used as an aid or alternative to chemical anesthesia, and it has been studied as a way to soothe skin ailments.
Pain management.
A number of studies show that hypnosis can reduce the pain experienced during burn-wound debridement, bone marrow aspirations, and childbirth. The "International Journal of Clinical and Experimental Hypnosis" found that hypnosis relieved the pain of 75% of 933 subjects participating in 27 different experiments.
Hypnosis is effective in reducing pain from and coping with cancer and other chronic conditions. Nausea and other symptoms related to incurable diseases may also be managed with hypnosis. Some practitioners have claimed hypnosis might help boost the immune system of people with cancer. However, according to the American Cancer Society, "available scientific evidence does not support the idea that hypnosis can influence the development or progression of cancer."
Hypnosis has been used as a pain relieving technique during dental surgery and related pain management regimens as well. Researchers like Jerjes and his team have reported that hypnosis can help even those patients who have acute to severe orodental pain. What is more, Meyerson and Uziel have suggested that hypnotic methods have been found to be highly fruitful for alleviating anxiety in patients suffering from severe dental phobia.
The "American Psychological Association" published a study comparing the effects of hypnosis, ordinary suggestion and placebo in reducing pain. The study found that highly suggestible individuals experienced a greater reduction in pain from hypnosis compared with placebo, whereas less suggestible subjects experienced no pain reduction from hypnosis when compared with placebo. Ordinary non-hypnotic suggestion also caused reduction in pain compared to placebo, but was able to reduce pain in a wider range of subjects (both high and low suggestible) than hypnosis. The results showed that it is primarily the subject's responsiveness to suggestion, whether within the context of hypnosis or not, that is the main determinant of causing reduction in pain.
Other medical and psychotherapeutic uses.
Treating skin diseases with hypnosis (hypnodermatology) has performed well in treating warts, psoriasis, and atopic dermatitis.
The success rate for habit control is varied. A meta-study researching hypnosis as a quit-smoking tool found it had a 20 to 30 percent success rate, while a 2007 study of patients hospitalised for cardiac and pulmonary ailments found that smokers who used hypnosis to quit smoking doubled their chances of success.
Hypnosis may be useful as an adjunct therapy for weight loss. A 1996 meta-analysis studying hypnosis combined with cognitive-behavioural therapy found that people using both treatments lost more weight than people using CBT alone. The virtual gastric band procedure mixes hypnosis with hypnopedia. The hypnosis instructs the stomach it is smaller than it really is and hypnopedia reinforces alimentary habits.
Controversy surrounds the use of hypnotherapy to retrieve memories, especially those from early childhood or (supposed) past-lives. The American Medical Association and the American Psychological Association caution against recovered-memory therapy in cases of alleged childhood trauma, stating that "it is impossible, without corroborative evidence, to distinguish a true memory from a false one." Past life regression, meanwhile, is often viewed with skepticism.
Psychiatric nurses in most medical facilities are allowed to administer hypnosis to patients in order to relieve symptoms such as anxiety, arousal, negative behaviors, uncontrollable behavior, and improve self-esteem and confidence only when they have been completely trained about their clinical side effects and while under supervision when administering it.
Military.
A recently declassified document obtained by the US Freedom of Information Act archive shows that hypnosis was investigated for military applications. However, the overall conclusion of the study was that there was no evidence that hypnosis could be used for military applications, and no clear evidence whether 'hypnosis' is a definable phenomenon outside ordinary suggestion, motivation and subject expectancy. According to the document,
The use of hypnosis in intelligence would present certain technical problems not encountered in the clinic or laboratory. To obtain compliance from a resistant source, for example, it would be necessary to hypnotise the source under essentially hostile circumstances. There is no good evidence, clinical or experimental, that this can be done.
Furthermore, the document states that:
It would be difficult to find an area of scientific interest more beset by divided professional opinion and contradictory experimental evidence…No one can say whether hypnosis is a qualitatively unique state with some physiological and conditioned response components or only a form of suggestion induced by high motivation and a positive relationship between hypnotist and subject…T.X. Barber has produced “hypnotic deafness” and “hypnotic blindness,” analgesia and other responses seen in hypnosis—all without hypnotizing anyone…Orne has shown that unhypnotized persons can be motivated to equal and surpass the supposed superhuman physical feats seen in hypnosis.
The study concludes:
It is probably significant that in the long history of hypnosis, where the potential application to intelligence has always been known, there are no reliable accounts of its effective use by an intelligence service.
Research into hypnosis in military applications is further verified by the MKULTRA experiments, also conducted by the CIA. According to Congressional testimony, the CIA experimented with utilizing LSD and hypnosis for mind control. Many of these programs were done domestically and on participants who were not informed of the study's purposes or that they would be given drugs.
The full paper explores the potentials of operational uses.
Self-hypnosis.
Self-hypnosis happens when a person hypnotises oneself, commonly involving the use of autosuggestion. The technique is often used to increase motivation for a diet, quit smoking, or reduce stress. People who practice self-hypnosis sometimes require assistance; some people use devices known as mind machines to assist in the process, whereas others use hypnotic recordings.
Self-hypnosis is claimed to help with stage fright, relaxation, and physical well-being.
Stage hypnosis.
Stage hypnosis is a form of entertainment, traditionally employed in a club or theatre before an audience. Due to stage hypnotists' showmanship, many people believe that hypnosis is a form of mind control. Stage hypnotists typically attempt to hypnotise the entire audience and then select individuals who are "under" to come up on stage and perform embarrassing acts, while the audience watches. However, the effects of stage hypnosis are probably due to a combination of psychological factors, participant selection, suggestibility, physical manipulation, stagecraft, and trickery. The desire to be the centre of attention, having an excuse to violate their own fear suppressors and the pressure to please are thought to convince subjects to 'play along'. Books by stage hypnotists sometimes explicitly describe the use of deception in their acts, for example, Ormond McGill's "New Encyclopedia of Stage Hypnosis" describes an entire "fake hypnosis" act that depends upon the use of private whispers throughout.
The state versus non-state debate.
The central theoretical disagreement is known as the "state versus nonstate" debate. When Braid introduced the concept of hypnotism, he equivocated over the nature of the "state", sometimes describing it as a specific sleep-like neurological state comparable to animal hibernation or yogic meditation, while at other times he emphasised that hypnotism encompasses a number of different stages or states that are
an extension of ordinary psychological and physiological processes. Overall, Braid appears to have moved from a more "special state" understanding of hypnotism toward a more complex "nonstate" orientation.
State theorists interpret the effects of hypnotism as due primarily to a specific, abnormal, and uniform psychological or physiological state of some description, often referred to as "hypnotic trance" or an "altered state of consciousness." Nonstate theorists rejected the idea of hypnotic trance and interpret the effects of hypnotism as due to a combination of multiple task-specific factors derived from normal cognitive, behavioural, and social psychology, such as social role-perception and favorable motivation (Sarbin), active imagination and positive cognitive set (Barber), response expectancy (Kirsch), and the active use of task-specific subjective strategies (Spanos). The personality psychologist Robert White is often cited as providing one of the first nonstate definitions of hypnosis in a 1941 article:
Hypnotic behaviour is meaningful, goal-directed striving, its most general goal being to behave like a hypnotised person as this is continuously defined by the operator and understood by the client.
Put simply, it is often claimed that whereas the older "special state" interpretation emphasises the difference between hypnosis and ordinary psychological processes, the "nonstate" interpretation emphasises their similarity.
Comparisons between hypnotised and non-hypnotised subjects suggest that if a "hypnotic trance" does exist it only accounts for a small proportion of the effects attributed to hypnotic suggestion, most of which can be replicated without hypnotic induction.
Hyper-suggestibility.
Braid can be taken to imply, in later writings, that hypnosis is largely a state of heightened suggestibility induced by expectation and focused attention. In particular, Hippolyte Bernheim became known as the leading proponent of the "suggestion theory" of hypnosis, at one point going so far as to declare that there is no hypnotic state, only heightened suggestibility. There is a general consensus that heightened suggestibility is an essential characteristic of hypnosis.
 If a subject after submitting to the hypnotic procedure shows no genuine increase in susceptibility to any suggestions whatever, there seems no point in calling him hypnotised, regardless of how fully and readily he may respond to suggestions of lid-closure and other superficial sleeping behaviour.
Conditioned inhibition.
Ivan Pavlov stated that hypnotic suggestion provided the best example of a conditioned reflex response in human beings, i.e., that responses to suggestions were learned associations triggered by the words used. Pavlov himself wrote:
Speech, on account of the whole preceding life of the adult, is connected up with all the internal and external stimuli which can reach the cortex, signaling all of them and replacing all of them, and therefore it can call forth all those reactions of the organism which are normally determined by the actual stimuli themselves. We can, therefore, regard ‘suggestion’ as the most simple form of a typical reflex in man.
He also believed that hypnosis was a "partial sleep" meaning that a generalised inhibition of cortical functioning could be encouraged to spread throughout regions of the brain. He observed that the various degrees of hypnosis did not significantly differ physiologically from the waking state and hypnosis depended on insignificant changes of environmental stimuli. Pavlov also suggested that lower-brain-stem mechanisms were involved in hypnotic conditioning.
Pavlov's ideas combined with those of his rival Bekhterev and became the basis of hypnotic psychotherapy in the Soviet Union, as documented in the writings of his follower K.I. Platonov. Soviet theories of hypnotism subsequently influenced the writings of Western behaviourally-oriented hypnotherapists such as Andrew Salter.
Neuropsychology.
Changes in brain activity have been found in some studies of highly responsive hypnotic subjects. These changes vary depending upon the type of suggestions being given. The state of light to medium hypnosis, where the body undergoes physical and mental relaxation, is associated with a pattern mostly of alpha waves However, what these results indicate is unclear. They may indicate that suggestions genuinely produce changes in perception or experience that are not simply a result of imagination. However, in normal circumstances without hypnosis, the brain regions associated with motion detection are activated both when motion is seen and when motion is imagined, without any changes in the subjects' perception or experience. This may therefore indicate that highly suggestible hypnotic subjects are simply activating to a greater extent the areas of the brain used in imagination, without real perceptual changes. It is, however, premature to claim that hypnosis and meditation are mediated by similar brain systems and neural mechanisms.
Another study has demonstrated that a color hallucination suggestion given to subjects in hypnosis activated color-processing regions of the occipital cortex. A 2004 review of research examining the EEG laboratory work in this area concludes:
Hypnosis is not a unitary state and therefore should show different patterns of EEG activity depending upon the task being experienced. In our evaluation of the literature, enhanced theta is observed during hypnosis when there is task performance or concentrative hypnosis, but not when the highly hypnotizable individuals are passively relaxed, somewhat sleepy and/or more diffuse in their attention.
The induction phase of hypnosis may also affect the activity in brain regions that control intention and process conflict. Anna Gosline claims:
"Gruzelier and his colleagues studied brain activity using an fMRI while subjects completed a standard cognitive exercise, called the Stroop task. The team screened subjects before the study and chose 12 that were highly susceptible to hypnosis and 12 with low susceptibility. They all completed the task in the fMRI under normal conditions and then again under hypnosis. Throughout the study, both groups were consistent in their task results, achieving similar scores regardless of their mental state. During their first task session, before hypnosis, there were no significant differences in brain activity between the groups. But under hypnosis, Gruzelier found that the highly susceptible subjects showed significantly more brain activity in the anterior cingulate gyrus than the weakly susceptible subjects. This area of the brain has been shown to respond to errors and evaluate emotional outcomes. The highly susceptible group also showed much greater brain activity on the left side of the prefrontal cortex than the weakly susceptible group. This is an area involved with higher level cognitive processing and behaviour."
Dissociation.
Pierre Janet originally developed the idea of "dissociation of consciousness" from his work with hysterical patients. He believed that hypnosis was an example of dissociation, whereby areas of an individual's behavioural control separate from ordinary awareness. Hypnosis would remove some control from the conscious mind, and the individual would respond with autonomic, reflexive behaviour. Weitzenhoffer describes hypnosis via this theory as "dissociation of awareness from the majority of sensory and even strictly neural events taking place."
Neodissociation.
Ernest Hilgard, who developed the "neodissociation" theory of hypnotism, hypothesized that hypnosis causes the subjects to divide their consciousness voluntarily. One part responds to the hypnotist while the other retains awareness of reality. Hilgard made subjects take an ice water bath. They said nothing about the water being cold or feeling pain. Hilgard then asked the subjects to lift their index finger if they felt pain and 70% of the subjects lifted their index finger. This showed that even though the subjects were listening to the suggestive hypnotist they still sensed the water's temperature.
Mind-dissociation.
This theory was proposed by Y.D. Tsai in 1995 as part of his psychosomatic theory of dreams. Inside each brain, there is a program "I" (the conscious self), which is distributed over the conscious brain and coordinates mental functions (cortices), such as thinking, imagining, sensing, moving and reasoning. "I" also supervises memory storage. Many bizarre states of consciousness are actually the results of dissociation of certain mental functions from "I".
There are several possible types of dissociation that may occur:
A hypnotist's suggestion can also influence the subject long after the hypnosis session, as follows. In a normal state of mind, the subject will do or believe as his reason dictates. However, when hypnotized, reason is replaced by the hypnotist's suggestions to make up decisions or beliefs, and the subject will be very uneasy in later days if he/she does not do things as decided or his/her belief is contradicted. Hypnotherapy is also based on this principle.
Social role-taking theory.
The main theorist who pioneered the influential role-taking theory of hypnotism was Theodore Sarbin. Sarbin argued that hypnotic responses were motivated attempts to fulfill the socially constructed roles of hypnotic subjects. This has led to the misconception that hypnotic subjects are simply "faking". However, Sarbin emphasised the difference between faking, in which there is little subjective identification with the role in question, and role-taking, in which the subject not only acts externally in accord with the role but also subjectively identifies with it to some degree, acting, thinking, and feeling "as if" they are hypnotised. Sarbin drew analogies between role-taking in hypnosis and role-taking in other areas such as method acting, mental illness, and shamanic possession, etc. This interpretation of hypnosis is particularly relevant to understanding stage hypnosis in which there is clearly strong peer pressure to comply with a socially constructed role by performing accordingly on a theatrical stage.
Hence, the "social constructionism and role-taking theory" of hypnosis suggests that individuals are enacting (as opposed to merely "playing") a role and that really there is no such thing as a hypnotic trance. A socially constructed relationship is built depending on how much rapport has been established between the "hypnotist" and the subject (see Hawthorne effect, Pygmalion effect, and placebo effect).
Psychologists such as Robert Baker and Graham Wagstaff claim that what we call hypnosis is actually a form of learned social behaviour, a complex hybrid of social compliance, relaxation, and suggestibility that can account for many esoteric behavioural manifestations.
Cognitive-behavioural theory.
Barber, Spanos and Chaves (1974) proposed a nonstate "cognitive-behavioural" theory of hypnosis, similar in some respects to Sarbin's social role-taking theory and building upon the earlier research of Barber. On this model, hypnosis is explained as an extension of ordinary psychological processes like imagination, relaxation, expectation, social compliance, etc. In particular, Barber argued that responses to hypnotic suggestions were mediated by a "positive cognitive set" consisting of positive expectations, attitudes, and motivation. Daniel Araoz subsequently coined the acronym "TEAM" to symbolise the subject's orientation to hypnosis in terms of "trust", "expectation", "attitude", and "motivation".
Barber et al., noted that similar factors appeared to mediate the response both to hypnotism and to cognitive-behavioural therapy (CBT), in particular systematic desensitization. Hence, research and clinical practice inspired by their interpretation has led to growing interest in the relationship between hypnotherapy and CBT.:105
Information theory.
An approach loosely based on Information theory uses a brain-as-computer model. In adaptive systems, feedback increases the signal-to-noise ratio, which may converge towards a steady state. Increasing the signal-to-noise ratio enables messages to be more clearly received. The hypnotist's object is to use techniques to reduce interference and increase the receptability of specific messages (suggestions).
Systems theory.
Systems theory, in this context, may be regarded as an extension of Braid's original conceptualization of hypnosis as involving "the brain and nervous system generally".(p31) Systems theory considers the nervous system's organization into interacting subsystems. Hypnotic phenomena thus involve not only increased or decreased activity of particular subsystems, but also their interaction. A central phenomenon in this regard is that of feedback loops, which suggest a mechanism for creating hypnotic phenomena.

</doc>
<doc id="14421" url="http://en.wikipedia.org/wiki?curid=14421" title="Henry Chadwick (writer)">
Henry Chadwick (writer)

Henry Chadwick (October 5, 1824 – April 20, 1908) was an English-born American sportswriter, baseball statistician and historian, often called the "father of baseball" for his early reporting on and contributions to the development of the game. He edited the first baseball guide that was sold to the public. He is credited with creating box scores, as well as creating the abbreviation "K" that designates a strikeout. He is said to have created the statistics of batting average and earned run average (ERA). He was posthumously inducted into the National Baseball Hall of Fame.
Early life.
Chadwick was born in Exeter, England. His grandfather, Andrew Chadwick, had been a close friend of theologian John Wesley. His father, James Chadwick, was a supporter of the French Revolution who also tutored John Dalton in music and botany. James Chadwick had served as editor of a publication known as the "Western Times". Edwin Chadwick's mother had made James Chadwick a widower shortly after Edwin's birth. 
Chadwick was the younger half brother of Sir Edwin Chadwick, England's sanitary philosopher who developed environmental measures and laws designed to counteract the effects of the Industrial Revolution. Chadwick moved to Brooklyn with his family at the age of 12. Biographer Andrew Schiff writes that Henry Chadwick "was not brought up to value possessions or with an understanding of commerce and trade; rather he received an education that was drenched in moral philosophy and science." He began to write music and to teach piano and guitar.
In 1848, Chadwick married Jane Botts from Richmond, Virginia. Botts' father Alexander had been president of the Virginia State Council. She was also related to politician John Botts. Chadwick edited John Botts' work titled "The Great Rebellion". Chadwick and his wife had one child, Richard Westlake Chadwick, in 1851.
Chadwick became a frequent player of cricket and similar ball games such as rounders. He began covering cricket for numerous local newspapers such as the "Long Island Star". He first came across organized baseball in 1856 as a cricket reporter for "The New York Times"; he watched a match between New York's Eagles and Gothams. In 1857 he focused his attention as a journalist and writer on baseball after joining the "New York Clipper", and was also soon hired on to provide coverage for other New York papers including the "Sunday Mercury". 
Contributions to baseball.
Promotion of the game.
Chadwick was one of the prime movers in the rise of baseball to its unprecedented popularity at the turn of the 20th century. A keen amateur statistician and professional writer, he helped sculpt the public perception of the game, as well as providing the basis for the records of teams' and players' achievements in the form of baseball statistics. He also served on baseball rules committees and influenced the game itself. He is sometimes referred to as "the father of baseball" because he facilitated the popularity of the sport in its early days.
Early baseball had a provision known as the "bound rule", which held that a fielder could catch a batted ball on one bounce and that it would still be recorded as an out. Chadwick was an outspoken critic of the rule for many years, stating that fielders should have to catch a ball on the fly for it to count as an out. In 1864, the bound rule was eliminated for balls hit into fair territory. The bound rule for foul balls persisted into the 1880s.
Chadwick edited "The Beadle Dime Base-Ball Player", the first annual baseball guide on public sale, as well as the Spalding and Reach annual guides for a number of years and in this capacity promoted the game and influenced the infant discipline of sports journalism. In his 1861 "Beadle" guide, he listed totals of games played, outs, runs, home runs, and strikeouts for hitters on prominent clubs, the first database of its kind. His goal was to provide numerical evidence to prove which players helped a team to win.
In 1867 he accompanied the National Base Ball Club of Washington D.C. on their inaugural national tour, as their official scorer. The next year, Chadwick wrote the first hardcover baseball book, "The Game of Base Ball". In 1874 was instrumental in organizing a tour of England which included games of both baseball and cricket. In his role as journalist, he campaigned against the detrimental effects on the game of both alcohol and gambling.
Despite a friendship with Albert Spalding, Chadwick was scornful of the attempts to have Abner Doubleday declared the inventor of baseball. "He means well", said Chadwick, "but he don't know". Chadwick later willed his baseball library to Spalding. 
Author William Cook wrote that "Chadwick was at times a bit self-aggrandizing, but his heart was always deeply rooted in looking after the best interest of the game." An 1876 "Chicago Tribune" article attacked Chadwick's status as the father of baseball, saying in part that Chadwick "has had enough experience to have made himself a man of respect had heaven but given him a head... he proceeded to call himself the '"Father of the Game,' and to assume much on the strength of the title. But he found an unruly child, and one which disinherited him with rapidity and ease." Cook writes that Chadwick may have been a victim of "Western journalism", a sensationalized style of writing.
Box scores and statistics.
Chadwick is credited with devising the baseball box score (which he adapted from the cricket scorecard) for reporting game events. The first box score appeared in an 1859 issue of the "Clipper". It was a grid with nine rows for players and nine columns for innings. The original box scores also created the often puzzling abbreviation for strikeout as "K" – "K" being the last letter of "struck" in "struck out". Chadwick assigned numbers to each defensive position for scorekeeping purposes, a system that remains in modern baseball scorekeeping.
Newspapers had previously tallied runs scored, but Chadwick's 1859 box score looked similar in structure to modern ones. Baseball researcher Bill James credits Chadwick's creation of the box score with his interest in the game, but he criticized Chadwick's omission of the walk from calculation of a player's batting average: ""What they failed to understand is that actually the batter has as much or a little more to do with when the walk occurs as the pitcher does. They ignored that element of it and that did distort the game for a lot of people." The box score was popularized in 1925 when "Baseball Magazine" republished Chadwick's 1859 "Clipper" article.
Chadwick is credited with devising statistical measures such as batting average and earned run average (ERA). He felt that batting average was the best representation of a batter's offensive skills. He initially scored walks as errors charged to the pitcher. Walks did not exist in cricket and upon learning about them in baseball, he felt that they did not have anything to do with offensive skill. He later removed walks entirely from baseball statistics. ERA originated not in the goal of measuring a pitcher's worth but to differentiate between runs caused by batting skill (hits) and lack of fielding skill (errors). He is also noted as believing fielding range to be a superior skill to avoiding errors.
Journalistic style.
The following description of a game was written by Henry Chadwick and appeared in his "Base Ball Memoranda". It is typical of his style of sports journalism, and that of his time:
Later life.
Late in life, Chadwick continued editing the "Spalding Base Ball Guides" and producing a column for the "Brooklyn Daily Eagle". In late 1905, he wrote the editor of "The New York Times" to propose widening of the baseball bat to overcome the advantage that pitchers had established in the game. In his letter, Chadwick noted that some cricket experts had advocated for the narrowing of the cricket bat to bring balance to the advantage that belonged to the batter in that game. 
In the winter before the 1908 baseball season, Chadwick was struck by an automobile and was bedridden for several weeks. He recovered and attended an exhibition game at the Polo Grounds the week before the season began. He caught a cold while at the game, and the illness worsened when he attended an Opening Day game at Washington Park in Brooklyn. 
On April 19, Chadwick was moving furniture from the fourth floor of his apartment to the second floor when he fell unconscious. He was diagnosed with pneumonia and heart failure. He awakened briefly and asked about the game between Brooklyn and New York, but he died the next day. Henry Chadwick is interred at Green-Wood Cemetery in Brooklyn, New York.
Legacy.
For his contributions to the game of baseball, he was elected to the Baseball Hall of Fame by the Veterans Committee in 1938. He was inducted in the same ceremony as Cartwright.
In 2009, the Society for American Baseball Research (SABR) established the Henry Chadwick Award to honor the outstanding contributions of baseball researchers. Bill James and John Thorn are among the award's recipients. 
A collection of historical baseball items, which featured a letter written by Chadwick on the origins of baseball, sold at auction in 2004 for $310,500. 

</doc>
<doc id="14423" url="http://en.wikipedia.org/wiki?curid=14423" title="Higher education">
Higher education

Higher education, post-secondary education, tertiary education or third level education is an optional final stage of formal learning that occurs after secondary education. Often delivered at universities, academies, colleges, seminaries, and institutes of technology, higher education is also available through certain college-level institutions, including vocational schools, trade schools, and other career colleges that award academic degrees or professional certifications. Tertiary education at non-degree level is sometimes referred to as further education or continuing education as distinct from higher education.
The right of access to higher education is mentioned in a number of international human rights instruments. The UN International Covenant on Economic, Social and Cultural Rights of 1966 declares, in Article 13, that "higher education shall be made equally accessible to all, on the basis of capacity, by every appropriate means, and in particular by the progressive introduction of free education". In Europe, Article 2 of the First Protocol to the European Convention on Human Rights, adopted in 1950, obliges all signatory parties to guarantee the right to education.
In the days when few pupils progressed beyond primary education, the term "higher education" was often used to refer to secondary education, which can create some confusion.
Overview.
Higher education is an educational level that follows a completion of a school providing a secondary education, such as a high school, secondary school, or gymnasium. Tertiary education is normally taken to include undergraduate and postgraduate education, as well as vocational education and training. Colleges, universities, and institutes of technology are the main institutions that provide tertiary education (sometimes known collectively as tertiary institutions). Examples of institutions that provide post-secondary education are vocational schools, community colleges, independent colleges (e.g. institutes of technology), and universities in the United States, the institutes of technical and further education in Australia, pre-university colleges in Quebec, and the IEKs in Greece. They are sometimes known collectively as tertiary institutions. Completion of a tertiary education program of study generally results in the awarding of certificates, diplomas, or academic degrees.
Higher education includes teaching, research, exacting applied work (e.g. in medical schools and dental schools), and social services activities of universities. Within the realm of teaching, it includes both the "undergraduate" level, and beyond that, "graduate-level" (or "postgraduate" level). The latter level of education is often referred to as graduate school, especially in North America.
In many developed countries, a high proportion of the population (up to 50%), now enter higher education at some time in their lives. Higher education is therefore very important to national economies, both as a significant industry in its own right and as a source of trained and educated personnel for the rest of the economy. College educated workers command a significant wage premium and are much less likely to become unemployed than less educated workers.
Higher education in some countries, including the United States, Canada, the United Kingdom, and Ireland, specifically refers to post-secondary institutions that offer Associate's degrees, Bachelor's degrees, Master's degrees, Education Specialist (Ed.S.) degrees or Doctor of Philosophy (Ph.D.) degrees, or their equivalents, and also higher professional degrees in areas such as dentistry, law, medicine, optometry, pharmacology and veterinary medicine.
Such institutions may also offer non-degree certificates, which indicate completion of a set of courses comprising a body of knowledge on a particular topic, but the granting of such certificates is not the primary purpose of the institutions. Tertiary education is not a term used in reference to post-secondary institutions in the United States or Canada.
Entrance standards: Reading, mathematics, and writing.
Demonstrated ability in reading, mathematics, and writing, as typically measured in the United States by the SAT or similar tests such as the ACT, have often replaced colleges' individual entrance exams, and is often required for admission to higher education. There is some question as to whether advanced mathematical skills or talent are in fact necessary for fields such as history, English, philosophy, or art.
Types.
General.
The general higher education and training that takes place in a university, college, or Institute of Technology usually includes significant theoretical and abstract elements, as well as applied aspects (although limited offerings of internships or SURF programs attempt to provide practical applications). In contrast, the vocational higher education and training that takes place at vocational universities and schools usually concentrates on practical applications, with very little theory.
In addition, professional-level education is always included within Higher Education, and usually in graduate schools, since many postgraduate academic disciplines are both vocationally, professionally, and theoretically/research oriented, such as in the law, medicine, pharmacy, dentistry, and veterinary medicine. A basic requirement for entry into these graduate-level programs is almost always a bachelor's degree, although alternative means of obtaining entry into such programmes may be available at some universities. Requirements for admission to such high-level graduate programs is extremely competitive, and admitted students are expected to perform well.
In the United States, there are large differences in wages and employment associated with different degrees. Medical doctors and lawyers are generally the highest paid workers, and have among the lowest unemployment rates. Among undergraduate fields of study, science, technology, engineering, math, and business generally offer the highest wages and best chances of employment, while education, communication, and liberal arts degrees generally offer lower wages and a lower likelihood of employment.
Liberal arts.
Academic areas that are included within the Liberal arts include Environmental Science, Great Books, History, Languages including English, Linguistics, Literature, Mathematics, Music, Philosophy, Political Science, Psychology, Religious studies, Science, Sociology and Theater.
Engineering.
Teaching engineering is teaching the application of scientific, economic, social, and practical knowledge in order to design, build, maintain, and improve structures, machines, devices, systems, materials and processes. It may encompass using insights to conceive, model and scale an appropriate solution to a problem or objective. The discipline of engineering is extremely broad, and encompasses a range of more specialized fields of engineering, each with a more specific emphasis on particular areas of technology and types of application. Engineering disciplines include: aerospace, biological, civil, chemical, computer, electrical, industrial, and mechanical.
Performing arts.
The performing arts differ from the plastic arts or visual arts, insofar as the former uses the artist's own body, face and presence as a medium; the latter uses materials such as clay, metal or paint, which can be molded or transformed to create a work of art.
Performing arts institutions include , Dance schools, Drama schools and Music schools
Plastic or visual arts.
The plastic arts or visual arts are a class of art forms, that involve the use of materials, that can be moulded or modulated in some way, often in three dimensions. Examples are painting, sculpture, and drawing, etc.
Higher educational institutions in these arts include Film schools and Art schools.
Vocational.
Higher vocational education and training takes place at the non-university tertiary level. Such education combines teaching of both practical skills and theoretical expertise. Higher education differs from other forms of post-secondary education such as that offered by institutions of vocational education, which are more colloquially known as trade schools. Higher vocational education might be contrasted with education in a usually broader scientific field, which might concentrate on theory and abstract conceptual knowledge.
Professional higher education.
This describes a distinct form of Higher Education that offers a particularly intense integration with the world of work in all its aspects (including teaching, learning, research and governance) and at all levels of the overarching Qualifications Framework of the European Higher Education Area. Its function is to diversify learning opportunities, enhance employability, offer qualifications and stimulate innovation, for the benefit of learners and society.
The intensity of integration with the world of work (which includes enterprise, civil society and the public sector) is manifested by a strong focus on application of learning. This approach involves combining phases of work and study, a concern for employability, cooperation with employers, the use of practice-relevant knowledge and use-inspired research.
Examples of providers of Professional Higher Education may include, Graduate Colleges of Architecture, Business, Journalism, Law, Library Science, Optometry, Pharmacy, Public Policy, Human Medicine, Professional Engineering, Podiatric Medicine, Scientific Dentistry, K-12 Education, and Veterinary Medicine.
Statistics.
A report titled 'Education at a Glance 2014' published by the Organisation for Economic Co-operation and Development on 9 September 2014, revealed that by 2014, 84 percent of young people were completing upper secondary education over their lifetimes, in high-income countries. Tertiary-educated individuals were earning twice as much as median workers. In contrast to historical trends in education, young women were more likely to complete upper secondary education than young men. Additionally, access to education was expanding and growth in the number of people receiving university education was rising sharply. By 2014, close to 40 percent of people aged 25–34 (and around 25 percent of those aged 55–64), were being educated at university.
Recognition of studies.
The Lisbon Recognition Convention stipulates that degrees and periods of study must be recognised in all Signatory Parties of the Convention.
As employers.
Universities may employ a number of people. Depending on the funding, a university typically hires one teacher per 3–25 students. According to the ideal of research-university, the university teaching staff is actively involved in the research of the institution. In addition, the university usually also has dedicated research staff and a considerable support staff. Typically to work in higher education as a member of the academic faculty, a candidate must first obtain a doctorate in an academic field, although some lower teaching positions require only a master's degree.
Most of the administrative staff works in different administrative sections, such as Student Affairs. In addition, there may be central support units, such as a university library which have a dedicated staff.
The professional field involving the collection, analysis, and reporting of higher education data is called institutional research. Professionals in this field can be found at locations in addition to universities, e.g. state educational departments.
Post secondary institutions also employ graduate students in various assistantship roles. In the US, close to 50% of graduate students are employed as graduate assistants at some point. These apprenticeship-like positions provide opportunities for students to gain experience in, and exposure to, professional roles in exchange for funding of their academic programs.

</doc>
<doc id="14428" url="http://en.wikipedia.org/wiki?curid=14428" title="Heather Fargo">
Heather Fargo

Heather Fargo (born December 12, 1952, in Oakland, California) is a former Mayor and former City Council Member of Sacramento, California. She was sworn in as Mayor in November 2000, replacing Jimmie R. Yee, and served until December 2008, when she was replaced by Kevin Johnson.
Early life and education.
Heather Fargo grew up in Davis, Santa Maria, and Stockton, CA. She graduated from AA Stagg High School. She received a Bachelor of Science degree in Environmental Planning and Management from the University of California, Davis in 1975. In 1981, Fargo earned a Certificate of Completion from the Revenue Sources Management School in Boulder, Colorado. She also completed the State and Local Government Executive Program at the John F. Kennedy School of Government at Harvard University in 1991.
City Council Years.
Heather Fargo was first elected to the Sacramento City Council in 1989 to a five-year term as Sacramento was transitioning to even year city-wide elections. Fargo represented District One which includes Downtown and Natomas. In the September primary, she came in second place to businesswoman Kate Karpilow but beat future City Councilman Ray Tretheway who came in third place and incumbent David Shore who came in fourth place. However, Fargo came back to beat Karpilow in November.
Upon Grantland Johnson's resignation from the County Board of Supervisors in 1994, Fargo decided to run for the Board. In that election, she faced attorney and community activist Roger Dickinson. In a closely fought election, Dickinson narrowly beat Fargo. After that loss she was re-elected in 1994 and 1998. While serving on the city council, (prior to becoming Mayor full-time), she was employed as a manager of the California State Parks Volunteer Program.
2000 Mayoral Campaign.
Upon the sudden death in November 1999 of Mayor Joe Serna, Jr., Land Park city councilman Jimmie Yee became the acting mayor. Several candidates announced their intentions to run. Other than Fargo, three other councilmembers were also seeking the mayorship. North Sacramento city councilman Rob Kerth who represented an area immediately adjacent to Fargo's also decided to run. In addition, Steve Cohn, the city councilman for East Sacramento ran along with Robbie Waters who represents the Pocket and Greenhaven areas decided to run along with several lesser known candidates that included businessman and attorney Joe Genshlea and community activist Julie Padilla. Fargo, who won 22% of the vote in the primary and Kerth who won 20% of the vote made it into the November runoff, where Fargo was elected with just 53% of the vote. In winning, Fargo became the first Latina mayor of an American city.
2004 Mayoral Campaign.
Fargo did not face as stiff competition in her 2004 re-election. Her main opponent was Ross W. Relles, Jr., a businessman. Other candidates were Deputy Attorney General Mark Soble and Lorenzo Patino Law School President Leonard Padilla. Virtually unopposed against candidates far less funded, Fargo won solidly in the primary election, thus no runoff was necessary.
2008 Mayoral Campaign.
The primary election for Mayor took place on 3 June 2008. Fargo received 39% of the vote, while former NBA star and Sacramento native Kevin Johnson received 46% of the vote.
Since neither received a majority of the votes, a run off election was scheduled for November 2008, where she was defeated by a margin of 58% to 42%.
During the primary election campaign, Fargo initially claimed that she had the support of all the city councilmembers. Yet, Councilman Robbie Waters, Steve Cohn, and Sandra Sheedy all ended up endorsing Johnson during the primary. On September 4, 2008 only Councilman Kevin McCarty endorsed Heather Fargo.
Causes.
Environment.
Heather Fargo was a founding member and the first secretary of the Sacramento Tree Foundation, which is considered an important voice in Sacramento’s environmental community. 
Gun Control.
During her tenure Mayor Fargo became a member of the Mayors Against Illegal Guns Coalition, an organization formed in 2006 and co-chaired by New York City mayor Michael Bloomberg and Boston mayor Thomas Menino.
Mayoral tenure.
Mayor Fargo's tenure as mayor included disagreements with the Maloof family, owners of the NBA's Sacramento Kings, over the building of a new arena. 
In 2006, 2007, and 2008, Mayor Fargo was named "Best Local Elected Official" by the readers of "Sacramento Magazine" in their annual poll.
Electoral history.
2004 Primary Election for Mayor of Sacramento.
Because Fargo received a majority of the votes in the primary election, no general election was necessary.
2008 Primary Election for Mayor of Sacramento.
Johnson and Fargo proceeded to a runoff election on November 5.
2008 General Election for Mayor of Sacramento.
Precincts Reporting - 215 out of 391

</doc>
<doc id="14429" url="http://en.wikipedia.org/wiki?curid=14429" title="Henotheism">
Henotheism

Henotheism (Greek ἐνας θεός "henas theos" "one god") is the belief in and worship of a single God while accepting the existence or possible existence of other deities that may also be worshipped. The term was originally coined by Friedrich Wilhelm Joseph von Schelling (1775–1854) to depict early stages of monotheism. Max Müller (1823–1900), a German philologist and orientalist, brought the term into wider usage. Müller made the term central to his criticism of Western theological and religious exceptionalism (relative to Eastern religions), focusing on a cultural dogma which held "monotheism" to be both fundamentally well-defined and inherently superior to differing conceptions of God.
Definition and terminology.
Variations on the term have been "inclusive monotheism" and "monarchical polytheism", designed to describe differing forms of the idea. Related terms are monolatrism and kathenotheism, which are typically understood as subtypes of henotheism. The latter term is an extension of "henotheism", from καθ' ἕνα θεόν ("kath' hena theon") — "one god at a time". Henotheism is similar but less exclusive than monolatry because a monolator worships only one god (denying that other gods are worthy of worship), while the henotheist may worship any within the pantheon, depending on circumstances, although he or she will usually worship only one throughout their life (barring some sort of conversion). In some belief systems, the choice of the supreme deity within a henotheistic framework may be determined by cultural, geographical, historical or political reasons.
Hinduism.
Henotheism was coined to describe the theology of Rigvedic religion. The Rigveda was the basis for Max Müller's description of henotheism in the sense of a polytheistic tradition striving towards a formulation of The One ("ekam") Divinity aimed at by the worship of different cosmic principles. From this mix of monism, monotheism and naturalist polytheism Müller named the early Vedic religion henotheistic. A prime example of the monistic aspects of the late Rigveda is the Nasadiya Sukta, a hymn describing creation: "That One breathed by itself without breath, other than it there has been nothing." Hinduism later developed the concept of Brahman, which implies a transcendent and immanent reality. Different schools of thought interpret Brahman as either personal, impersonal or transpersonal. Ishwar Chandra Sharma describes it as "Absolute Reality, beyond all contradictions of existence and non-existence, light and darkness, and of time, space and cause."
Hellenistic religion.
While Greek and Roman religion began as polytheism, during the Classical period, under the influence of philosophy, differing conceptions emerged. Often Zeus (or Jupiter) was considered the supreme, all-powerful and all-knowing, king and father of the Olympian gods. According to Maijastina Kahlos "monotheism was pervasive in the educated circles in Late Antiquity" and "all divinities were interpreted as aspects, particles or epithets of one supreme God". Maximus Tyrius (2nd century A.D.) stated: "In such a mighty contest, sedition and discord, you will see one according law and assertion in all the earth, that there is one god, the king and father of all things, and many gods, sons of god, ruling together with him."
The Neoplatonic philosopher Plotinus taught that above the gods of traditional belief was "The One", and polytheist grammarian Maximus of Madauros even stated that only a madman would deny the existence of the supreme God.
Canaanite religion and early Judaism.
Rabbinical Judaism as it developed in Late Antiquity is emphatically monotheistic, but its predecessor, the various schools of Hellenistic Judaism and Second Temple Judaism, and especially the cult of Yahwe as it was practiced in ancient Israel and Judah during the 8th and 7th centuries BC, have been described as henotheistic.
For example, the Moabites worshipped the god Chemosh, the Edomites, Qaus, both of whom were part of the greater Canaanite pantheon, headed by the chief god, El. The Canaanite pantheon consisted of El and Asherah as the chief deities, with 70 sons who were said to rule over each of the nations of the earth. These sons were each worshiped within a specific region. Kurt Noll states that "the Bible preserves a tradition that Yahweh used to 'live' in the south, in the land of Edom" and that the original god of Israel was El Shaddai.
Several Biblical stories allude to the belief that the Canaanite gods all existed and possessed the most power in the lands that worshiped them or in their sacred objects; their power was real and could be invoked by the people who patronised them. There are numerous accounts of surrounding nations of Israel showing fear or reverence for the Israelite God despite their continued polytheistic practices. For instance, in 1 Samuel 4, the Philistines fret before the second battle of Aphek when they learn that the Israelites are bearing the Ark of the Covenant, and therefore Yahweh, into battle. In 2 Kings 5, the Aramean general Naaman insists on transporting Israelite soil back with him to Syria in the belief that only then will Yahweh have the power to heal him. The Israelites were forbidden to worship other deities, but according to some interpretations of the Bible, they were not fully monotheistic before the Babylonian captivity. Mark S. Smith refers to this stage as a form of monolatry. Smith argues that Yahweh underwent a process of merging with El and that acceptance of cults of Asherah was common in the period of the Judges. 2 Kings 3:27 has been interpreted as describing a human sacrifice in Moab that led the invading Israelite army to fear the power of Chemosh.

</doc>
<doc id="14431" url="http://en.wikipedia.org/wiki?curid=14431" title="Hedwig of Silesia">
Hedwig of Silesia

Saint Hedwig of Silesia (Polish: "Święta Jadwiga Śląska"), also Saint Hedwig of Andechs (German: "Heilige Hedwig von Andechs", Latin: "Hedvigis") (1174 – 15 October 1243), a member of the Bavarian comital House of Andechs, was Duchess of Silesia from 1201 and of Greater Poland from 1231 as well as High Duchess consort of Poland from 1232 until 1238. She was canonized by the Catholic Church in 1267.
Life.
The daughter of Count Berthold IV of Andechs and his second wife Agnes of Wettin, she was born at Andechs Castle in the Duchy of Bavaria. Her elder sister, Agnes married King Philip II of France (annulled in 1200) and her sister, Gertrude (killed in 1213) King Andrew II of Hungary, while the youngest Matilda, (Mechtild) became abbess at the Benedictine Abbey of Kitzingen in Franconia, where Hedwig also received her education. Through her sister Gertrude, she was the aunt of Saint Elizabeth of Hungary.
Duchess consort.
At the age of twelve, Hedwig married Henry I the Bearded, son and heir of the Piast duke Bolesław I the Tall of Silesia. As soon as Henry succeeded his father in 1201, he had to struggle with his Piast relatives, at first with his uncle Duke Mieszko IV Tanglefoot who immediately seized the Upper Silesian Duchy of Opole. In 1206 Henry and his cousin Duke Władysław III Spindleshanks of Greater Poland agreed to swap the Silesian Lubusz Land against the Kalisz region, which met with fierce protest by Władysław's III nephew Władysław Odonic. When Henry went to Gąsawa in 1227 to meet his Piast cousins, he narrowly saved his life, while High Duke Leszek I the White was killed by the men of the Pomerelian Duke Swietopelk II, instigated by Władysław Odonic.
The next year Henry's ally Władysław III Spindleshanks succeeded Leszek I as High Duke; however as he was still contested by his nephew in Greater Poland, he made Henry his governor at Kraków, whereby the Silesian duke once again became entangled into the dispute over the Seniorate Province. In 1229 he was captured and arrested at Płock Castle by rivaling Duke Konrad I of Masovia. Hedwig proceeded to Płock pleading for Henry and was able to have him released.
Her actions promoted the reign of her husband: Upon the death of the Polish High Duke Władysław III Spindleshanks in 1231, Henry also became Duke of Greater Poland and the next year prevailed as High Duke at Kraków. He thereby was the first of the Silesian Piast descendants of Władysław II the Exile to gain the rule over Silesia and the Seniorate Province according to the 1138 Testament of Bolesław III Krzywousty.
Widow.
In 1238, upon his death, Henry was buried at a Cistercian monastery of nuns, Trzebnica Abbey ("Kloster Trebnitz"), which he had established in 1202 at Hedwig's request. The widow moved into the monastery, which was led by her daughter Gertrude, assuming the religious habit of a lay sister, but she did not take vows. She invited numerous German religious people from the Holy Roman Empire into the Silesian lands, as well as German settlers who founded numerous cities, towns and villages in the course of the "Ostsiedlung", while cultivating barren parts of Silesia for agriculture.
Hedwig and Henry had several daughters, though only one surviving son, Henry II the Pious, who succeeded his father as Duke of Silesia and Polish High Duke. The widow however had to witness the killing of her son, vainly awaiting the support of Emperor Frederick II, during the Mongol invasion of Poland at the Battle of Legnica ("Wahlstatt") in 1241. The hopes for a re-united Poland were lost and even Silesia fragmented into numerous Piast duchies under Henry II's sons. Hedwig and her daughter-in-law, Henry II's widow Anna of Bohemia, established a Benedictine abbey at the site of the battle in Legnickie Pole, settled with monks coming from Opatovice in Bohemia.
Hedwig and Henry had lived very pious lives, and Hedwig had great zeal for religion. She had supported her husband in donating the Augustinian provostry at Nowogród Bobrzański ("Naumburg") and the commandery of the Knights Templar at Oleśnica Mała ("Klein Oels"). Hedwig always helped the poor and donated all her fortune to the Church. According to legend, she went barefoot even in winter, and when she was urged by the Bishop of Wrocław to wear shoes, she carried them in her hands. On 15 October 1243, Hedwig died and was buried in Trzebnica Abbey with her husband, while relics of her are preserved at Andechs Abbey and St. Hedwig's Cathedral in Berlin.
Veneration.
Hedwig was canonized in 1267 by Pope Clement IV, a supporter of the Cistercian order, at the suggestion of her grandson Prince-Archbishop Władysław of Salzburg. She is the patron saint of Silesia, of Andechs, and of the Roman Catholic Archdiocese of Wrocław and the Roman Catholic Diocese of Görlitz. Her feast day is celebrated on the General Roman Calendar on 16 October. A 17th-century legend has it that Hedwig, while on a pilgrimage to Rome, stopped at Bad Zell in Austria, where she had healing waters spring up at a source which today still bears her name.
In 1773 the Prussian king Frederick the Great, having conquered and annexed the bulk of Silesia in the First Silesian War, had St. Hedwig's Cathedral in Berlin built for the Catholic Upper Silesian immigrants, now the mother church of the Roman Catholic Archdiocese of Berlin.
Hedwig glasses are named after Hedwig of Andechs.
Other References.
Saint Hedwig's name inspired J.K. Rowling when writing the Harry Potter series, naming a character, Harry's owl, after the saint.
Children.
Hedwig and Henry I had seven children:

</doc>
<doc id="14436" url="http://en.wikipedia.org/wiki?curid=14436" title="Hasidic Judaism">
Hasidic Judaism

Hasidic Judaism (from the Hebrew: חסידות‎, Sephardic pronunciation: ]; Ashkenazic pronunciation: ]; Israeli pronunciation: ]), meaning "piety" (or "loving-kindness"), is a branch of Orthodox Judaism that promotes spirituality through the popularization and internalization of Jewish mysticism as the fundamental aspect of the faith. It was founded in 18th-century Eastern Europe by Rabbi Israel Baal Shem Tov as a reaction against overly legalistic Judaism. His example began the characteristic veneration of leadership in Hasidism as embodiments and intercessors of Divinity for the followers. Contrary to this, Hasidic teachings cherished the sincerity and concealed holiness of the unlettered common folk, and their equality with the scholarly elite. The emphasis on the Immanent Divine presence in everything gave new value to prayer and deeds of kindness, alongside rabbinical supremacy of study, and replaced historical mystical (kabbalistic) and ethical (musar) asceticism and admonishment with Simcha, encouragement, and daily fervor.
Hasidism comprises part of contemporary Haredi Judaism, alongside the previous Talmudic Lithuanian-Yeshiva approach and the Sephardi and Mizrahi traditions. Its charismatic mysticism has inspired non-Orthodox Neo-Hasidic thinkers and influenced wider modern Jewish denominations, while its scholarly thought has interested contemporary academic study. Each Hasidic dynasty follows its own principles; thus, Hasidic Judaism is not one movement but a collection of separate groups with some commonality. There are approximately 30 larger Hasidic groups, and several hundred smaller groups. Though there is no one version of Hasidism, individual Hasidic groups often share with each other underlying philosophy, worship practices, dress (borrowed from local cultures), and songs (borrowed from local cultures).
History.
Prelude.
Yisroel (Israel) ben Eliezer, most commonly known as Baal Shem Tov, founded Hasidic Judaism in the 18th century.
In Poland, where the bulk of Yiddish-speaking Jewry had established itself by the 18th century, three branches of Yiddishkeit (i.e. Jewishness) emerged: the first were those against the predominant study of Kabbalah (i.e. Jewish mysticism); the second were those supportive of the study of Kabbalah; and the third was the secular Yiddish theater culture originating in Lithuania but eventually spreading across the whole Yiddish speaking world. This schism became particularly acute after the Messianic movement of Sabbatai Zevi in the 17th century. Leanings to rigid mystical doctrines and sectarianism showed themselves prominently among the Jews of the south-eastern provinces of Poland, while in the Lithuanian and Estonian provinces, anti-kabbalistic (mysticism) orthodox leaders held sway. In part, this division in modes of thought reflected social differences between the northern (Estonian and Lithuanian) Jews and the southern Jews of Poland and the western Russian Empire. In Lithuania and Estonia, the Jewish masses lived mainly in densely populated towns where anti-kabbalistic (mysticism) rabbinical academic culture (in the yeshivot) flourished based on just the simple understanding getting deeper from there. In Poland itself, the Jews tended to live scattered in villages far removed from intellectual centers. In these villages, the influence of the kabbalists (mystics) prevailed; while other communities of Yiddish speakers were becoming completely secular and creating an identity in the Lithuanian, Belorussian, Ukrainian and Polish Yiddish theater separate from any serious mysticism, finding commonality with the Haskallah taking place within the Austro-Czech Yiddish speaking regions. This should be viewed in the context that there is really no form of original Judaica which does not believe in daily miracles and mysticism, a Jew's whole life technically speaking has always related to mysticism and the Ruach Hakodesh. One view of Judaism is that it is just an ethnicity, with cultural ritual and mystical spiritualism. The schism was between the various 'group thinks' within the kabbalistic mystical communities of the descendants of the French and German Jews called at some point Ashkenazi, but more accurately should be described as the diverse Yiddish speaking world.
Pessimism in the south was more intense after the Cossacks' Uprising (1648–1654) under Chmielnicki and the turbulent times in Poland (1648–1660), which violently ruined the Jewry of South East Poland, but did not much affect that of Lithuania and Estonia. The general population of Poland itself declined and economic chaos reigned, especially due to these events and the subsequent Turkish Invasion which left this region depopulated and barren. After the Polish magnates regained control of southern Rus in the last decade of the 17th century, an economic renaissance ensued. The magnates began a massive rebuilding and repopulation effort while being generally welcoming and benevolent towards the Jews. A type of frontier environment ensued where new people and new ideas were encouraged. The state of the Jews of what would later become southern Russia created a favorable field for mystical movements and religious sectarianism, which spread in the area from the middle of the 18th to the middle of the 19th century.
Besides these influences, deep-seated causes produced among many Jews a discontent and a gravitation toward mysticism. Rabbinism, which in Poland had become transformed into a system of religious formalism, no longer provided a satisfactory religious experience to many Jews. Although traditional Judaism had adopted some features of Kabbalah, it adapted them to fit its own system: it added to its own ritualism the asceticism of the "practical kabbalists" just across the eastern borders in the ancient Greek and Anatolian Jewish communities under the Ottoman Empire, who saw the essence of earthly existence only in fasting, in penance, and in spiritual sadness. Such a combination of religious practices, suitable for individuals and hermits, did not suit the bulk of the Jews. Many of these Jews would live in mountainous regions to get away from any non-Jewish influence.
Mystical individuals arose, outside the Rabbinic establishment, called Nistarim or Baal Shem ("Masters of the Name" of God, used for practical kabbalistic intervention and miracles), who sought to offer the downtrodden masses spiritual and physical encouragement, and practical healing. The image of these charismatic figures, often wandering among the people, became shaped by the Kabbalistic legend of the Lamed Vav Tzadikim (36 hidden righteous people who sustain the world). From these circles of spiritual inspiration, the early Hasidic movement arose, led by Israel ben Eliezer, the Baal Shem Tov, in 18th century Podolia (now Ukraine). He attracted to his cause the preceding followers of the ways of the Nistorim, who saw in his teachings a new direction in reviving and consoling the masses.
At the time in Jewish Eastern Europe were also public preachers ("Maggidim"), who would visit the shuls (synagogues) of the shtetls (towns and villages). During their Sabbath sermons, they would sometimes seek to encourage Jewish observance with ethical promises and warnings of Heaven and Hell. In their addresses, they also supported the communal Rabbi in helping to teach those who could not learn the spiritual and practical life of Jewish learning, and offered personal examples of Jewish conduct. The Baal Shem Tov opposed their use of ethical admonishments of punishment, which lacked love and inner spiritual values. Under the Hasidic movement, ideas of reward and punishment were avoided, and were replaced by the spiritual life of "dveikus" (cleaving) to God in all daily conduct. The Baal Shem Tov, and Hasidism, also opposed the earlier mystical and ethical ascetic paths of fasting and self-mortification, seeking to serve God by infusing physical activities with new spiritual inspiration.
Israel ben Eliezer.
The founder of Hasidism, Israel ben Eliezer (1698–1760), became known as the "Baal Shem Tov" (the "Master of the Good Name", abbreviated "Besht"). Following on from the earlier communal tradition of Baal Shem, his fame as a healer spread among not only the Jews, but also the non-Jewish peasants and the Polish nobles. The hagiography of oral stories about his life, that were posthumously compiled in writing by his disciples, describe his spiritual powers and knowledge, miracle working, and ability to predict the future. In turn, these notions were passed on to his saintly students and successors, and shaped the Hasidic doctrine of the Tzadik or Rebbe (righteous leader who channels Divine sustenance to his followers). The particular Hasidic emphasis and interpretation of this earlier Jewish and Kabbalistic concept, became one of the ideas that singled it out from non-Hasidic Judaism. The Hasidic concept of a Rebbe also combines their role as a teacher of Judaism and as a charismatic spiritual example. To their followers they teach Hasidic mysticism and interpretations of Biblical and Rabbinic Judaism.
The traditional accounts of his biography describe the beginnings of his life as a public teacher and leader of the Jewish people from his 36th birthday. His role and unique talent as a teacher and communicator of mystical revival began a new era in Jewish mysticism. To the common people, the Besht appeared wholly admirable. Characterized by an extraordinary sincerity and simplicity, he sought to meet the spiritual needs of the masses. He taught them that true Divine service consisted of not only religious scholarship, but also a sincere love of God combined with warm faith and belief in the efficacy of prayer; that the ordinary person filled with a sincere belief in God, and whose prayers come from the heart, is more acceptable to God than someone versed in and fully observant of Jewish law who lacks inspiration in his divine service. This democratization of Judaism attracted to the teachings of the Besht not only the common people, but also the scholars whom the rabbinical scholasticism and ascetic Kabbalah failed to satisfy.
About 1740, the Besht established himself in the Ukrainian town of Mezhebuzh. He gathered about him numerous disciples and followers whom he initiated into the secrets of his teachings not by systematic exposition, but by means of sayings and parables that contained both easily graspable insights, for the laymen, and profound Kabbalistic depth, for the great scholars. These sayings spread by oral transmission; later the founder's disciples set them in writing, developing the thoughts of their master into a system. The Besht himself wrote nothing.
The seminal teachings of the Baal Shem Tov captured new ideas and interpretations of Judaism, and were articulated and developed by his students and successors. These ideas offered the unlearned a folk spiritual revival, while also giving the scholarly elite a new depth and approach to mysticism. Hasidism gave a ready response to the burning desire of the common people, in the simple, stimulating, and comforting faith it awakened in them. The scholars attracted to Hasidism, also sought to learn selfless humility and simple sincerity from the common folk. In contrast to other sectarian teaching, early Hasidism aimed not at dogmatic or ritual reform, but at a deeper psychological one. It aimed to change not the belief, but the believer. By means of psychological suggestion, it created a new type of religious man, a type that placed emotion above reason and rites, and religious exaltation above knowledge. Traditional devotion to Jewish study and scholarship was not replaced, but was spiritualised as a means to cleave to God. The unlearned common folk were given spiritual enlivenment, as their sincerity also made them close to God.
Spread of Hasidism.
Israel ben Eliezer's disciples attracted many followers, who established numerous Hasidic courts across Europe. After the Besht's death, followers continued his cause, under the leadership of the Maggid, Rabbi Dov Ber of Mezeritch. From his court students went forth; they in turn attracted many Jews to Hasidism, and many of them came to study in Mezritch (Mezhirichi) with Dov Ber personally. By the 1830s the majority of Jews in Ukraine, Galicia, and central Poland were Hasidic, as were substantial minorities in Belarus, Hungary, and Romania. Hasidic Judaism began coming to Western Europe and then to the United States during the large waves of Jewish emigration in the 1880s.
After the passing of Rabbi Dov Ber, his inner circle of followers, known as the "Chevraya Kadisha," the Holy Fellowship, agreed to divide up the whole of Europe into different territories, and have each one charged with disseminating Hasidic teachings in his designated area.
Hasidism branched out into two main divisions: (1) in Ukraine and in Galicia (Central Europe) and (2) in Litta (Greater Lithuania from the time when it encompassed Belarus). Three disciples of Dov Ber of Mezritch (Elimelech of Lizhensk, Levi Yitzchok of Berditchev, and Menachem Nachum of Chernobyl), besides the grandson of the Besht, Boruch of Tulchin (later R' Boruch of Mezhbizh), directed the first of these divisions. Elimelech of Lizhensk fully developed the belief in Tzaddikism as a fundamental doctrine of Hasidism. In his book "No'am Elimelekh" he conveys the idea of the Tzadik ("righteous one") as the mediator between God and the common people, and suggests that through him God sends to the faithful earthly blessings in the three traditional categories: health and life, a livelihood, and children, on the condition, however, that the Hasidim support the Tzaddik by pecuniary contributions ("pidyonos"), in order to enable the holy man to become completely absorbed in the contemplation of God. Lithuanian Hasidim followed Rabbi Shneur Zalman of Liadi, who founded Habad Hasidism, and Rabbi Aharon of Karlin. The intellectual Habad method of Schneur Zalman, developed the mind, in contrast to general Hasidism, as the fundamental route to Hasidic spirituality. This articulation can therefore fully incorporate the other dimensions of Judaism, such as Jewish philosophy and Rabbinic Judaism. The Maggid directed Schneur Zalman to spread Hasidism in Belarus, as his intellectual articulation could appeal to the Rabbinic opposition in Vilna. Consequently, it posed more of a threat to the Mitnagdim, and Schneur Zalman was arrested and imprisoned in Saint Petersburg by the Tzarist government on false charges, instigated by some of the Jewish opposition. Habad tradition sees the reason for the imprisonment as a result of Heavenly opposition to his new, broader, intellectual dissemination of Hasidic thought, and his exoneration as vindication from Heaven to begin fully spreading the teachings of Hasidus.
Subsequent influential and famous Hasidic thinkers and leaders include Nachman of Breslov, in Ukraine, Menachem Mendel of Kotzk in Poland, and Israel Friedman of Ruzhyn in Russia. Nachman of Breslov is seen as the most imaginatively creative Hasidic thinker, while Menachem Mendel of Kotzk overturned the traditional view of the Tzadik, in pursuit of truthful introspection and integrity. The spiritual meaning of Tzadikic grandeur reached its fullest form in the regal majesty of the court of Yisroel Friedman. In the 19th-century flourishing of Hasidism, leadership succession usually became dynastic, rather than inherited by the greatest or most charismatic student. Each Hasidic court established itself in the scattered shtetls across Eastern Europe, and adopted their names, often in Yiddish form, for their approach to Hasidic thought and life. Where the Hasidic approach of a group was profound or influential, the spiritual vitality of their leadership remained charismatic or great, such as in the Polish dynasty of Ger (derived from Menachem Mendel of Kotzk), or the Belarusian dynasty of Lubavitch (the intellectual branch of Hasidism founded by Schneur Zalman of Liadi). In these examples, often their leaders combined Hasidic spirituality with traditional Rabbinic greatness of scholarship in Talmud. This synthesis helped dissolve much of the early opposition to Hasidism by the Rabbinic civilization of Lithuanian Jewish Orthodoxy.
Opposition.
Beginning at the founding of the Hasidic movement, a serious schism evolved between Hasidic and non-Hasidic Jews. Those European Jews who rejected the Hasidic movement were referred to as "misnagdim" (from the Hebrew נגד, literally, "against" or "opponents"). Critics of Hasidic Judaism:
Some other important differences between hasidim and "misnagdim" included:
On a more prosaic level, other "misnagdim" regarded hasidim as pursuing a less scholarly approach to Judaism, and opposed the movement for this reason. At one point, Hasidic Jews were put in "cherem" (a Jewish form of communal excommunication); after years of bitter acrimony, a rapprochement occurred between Hasidic Jews and their opponents within Orthodox Judaism. The reconciliation took place in response to the perceived even greater threat of the "Haskala", or Jewish Enlightenment. Despite this, the distinctions between the various sects of Hasidim and other Orthodox Jews remain, although now, there is almost no conflict between these two groups.
Vilna Gaon and Chabad Hasidism.
Dispute and resolution.
The most notable disputant of Hasidism was the Vilna Gaon. Many legends and versions circulate regarding the reasoning of the Gaon against Hasidism generally, and specifically Chabad Hasidism. In 1774 the Baal Hatanya, and Rabbi Menachem Mendel of Vitebsk traveled to Vilna in an attempt to create a dialogue with the Vilna Gaon who led the Misnagdim and had issued a ban against the Hasidim, but the Gaon refused to see them It should be noted that the Gaon wrote prolifically on mysticism as often as any Hassiadic leader, unlike others against the Hassidic dynasties. He too, had made himself a homeless wanderer for many years, similar to the Baal Shem Tov and far before them.
Scholars and historians note the philosophical idea of "tzimtzum" as the core of their argument. The Vilna Gaon rejected the Baal Hatanya's ideas as heresy. In 1797 (during the lifetime of the Vilna Gaon) the Baal Hatanya wrote a lengthy responsa explaining his view on this matter to his Chassidim in Vilna. Despite the dispute, he requested his Hasidim to respect the Gaon and not to engage in arguments with the misnagdim.
Much has been written on this fundamental debate. It has been addressed by the Vilna Gaon's disciple and successor Rabbi Chaim Volozhin, the Baal Haleshem, Rabbi Eliyahu Eliezer Dessler and others. The Lubavitcher Rebbe divides the debate to four schools of thought.
The Hasidim revered the Gaon during his lifetime and thereafter. They believe he acted out of good faith and was misled by the slander of the misnagdim. This could be seen in the wording of the ban he signed excommunicating the Hasidim.
An unfortunate chapter in history is the 1798 incarceration of the Baal Hatanya in St Petersburg Jail. The Misnagdim falsely accused the Hasidim of subversive activities – on charges of supporting the Ottoman Empire, since the Baal Hatanya advocated sending charity to support Jews living in the Ottoman territory of Palestine. He was arrested on suspicion of treason and brought to St. Petersburg where he was held in the Petropavlovski fortress for 53 days, at which time he was subjected to an examination by a secret commission. Ultimately he was released by order of Paul I of Russia. The Hebrew day of his acquittal and release, 19 Kislev, 5559 on the Hebrew calendar, is celebrated annually by Chabad Hasidim.
In 1800, The Baal Hatanya was again arrested and transported to St. Petersburg. He was released after several weeks but banned from leaving St. Petersburg. The elevation of Tsar Alexander I (Alexander I of Russia) a few weeks later led to his release; he was then "given full liberty to proclaim his religious teachings" by the Russian government.
These events occurred four years after the death of the Gaon.
It was the Vilna Gaon's disciple and successor Rabbi Chaim Volozhin who halted the hostilities against the Hasidim after seeking dialogue with them and fully understanding their views. He consequently removed the ban placed on them recognizing Chabad ideology as legitimate Torah views. As mentioned, Rabbi Chaim approached the idea of tzimtzum in his work Nefesh Hachayim, evidently after studying the Baal Hatanya’s view in depth.
This reconciliation continued between their descendants. Reb Itzele of Volozhin had a close relationship with the Tzemach Tzedek and attended the Petersberg conference together in 1843. The Tzemach Tzedek frequently visited Vilna where he was welcomed with great respect.
The Rashab and Reb Chaim Soloveitchik of Brisk had a close relationship, and was held in high respect by the Chafetz Chaim.
The Rayatz received Rabbinical Ordination (Smicha) from Rabbi Chaim Brisker.
Rabbi Yitzchok Zev Soloveitchik referred MK Menachem Porush to the Rayatz in order to influence the Israeli Government to grant Charedim autonomy on their education.
Reb Yosef Ber Soloveichik had a long-lasting relationship with the late Lubavitcher Rebbe.
19th century consolidation and changes in Jewish society.
The mid-19th century saw the founding burst of Hasidic leadership and innovative spirituality channeled into consolidated Hasidic dynastic courts. The original founding figures of Hasidism reinvigorated traditional Jewish society by charismatic example and teaching. Under the Maggid, leadership became organized into a structured movement. The subsequent leadership, now dispersed across Eastern Europe, became most often passed down through select family descent. Each court became known after the shtetl of origin, encapsulating the thought and style of Hasidism of each group. This focus could allow deeper development of each distinctive path in Hasidism, while alternatively diminishing the founding revolutionary impulse. In the organized Hasidic society, the Rebbe superseded the traditional legal authority and influence of the Beth din and Rav that had formerly led communal and personal welfare.
In the mid-19th-century the influence of modern changes in Jewish society arrived East from the Western European secularising "Haskalah" (Jewish Enlightenment) movement. While the unsuccessful 1812 French invasion of Russia by Napoleon had sought to bring Jewish emancipation from the non-Jewish political structures of Poland and Russia, Haskalah sought to reform and rationalize Jewish thought and life from within the Jewish community, to form an image of Jewish observance in the character of non-Jewish modernity. In this respect, it differed from the Deist philosophical impulse of the European Enlightenment. Haskalah focused special hostility to the mysticism of Hasidism, publishing critiques and satires of Hasidic fervour. The emergent early Reform movement in Judaism rejected traditional Halachic methodology of Talmudic thought, and dismissed Kabbalah. Later 20th century non-Orthodox Jewish denominations would rediscover value in traditional thought and observance, and a Neo-Hasidic adoption of Hasidic mysticism. When the attempts of the Maskilim in influencing Hasidic and Mitnagdic pious thought in Eastern Europe met with little success, they sought to enlist non-Jewish governmental decrees in their educational aims. To the intensely inward focused spiritualities of Judaism in Eastern Europe and its leadership, the campaigns of the Maskilim represented the antithesis of their fervour, thought and societies. In Germany, an Orthodox synthesis between the best of Western thought and committed Jewish learning was developed by Samson Raphael Hirsch. The Eastern Judaisms of Hasidic and Lithuanian leadership saw his proposition as possible only as a last resort in the already assimilating environment of Germany. The threat of Haskalah helped heal the division between Hasidism and Mitnagdim, as they saw a common goal in protecting sincere Jewish observance of the common folk, and the elite traditional thought and learning of the great Yeshiva academies and Hasidic courts.
In the late 19th and early 20th centuries, more radical secular ideologies reached traditional Jewish society in Eastern Europe. These Jewish political movements sought to replace adherence to Judaism with beliefs in Jewish socialism or nationalism. Here too synthesis could sometimes be made from radical aspects of Hasidic thought, or from the later development of Religious Zionism. However, mainstream Hasidic and Mitnagdic leadership was opposed to any replacement of Talmudic and Hasidic thought and fervour from its centrality in Eastern European Judaism. The development of Hasidic philosophy in its diverse expressions offered consolation to the unlearned, while satisfying the mystical thirst and theological depth of elite students. Its inner spiritual concepts underscored the Rabbinic rejection of secular ideologies. Orthodoxy responded with political organisation under the Agudah, while the ethical Mussar movement among non-Hasidic Lithuanian Jews offered spiritual psychological development as an alternative to outward political involvement, and allowed a bridge to the mysticism of Hasidic thought.
In the Soviet Union and the Holocaust.
The Bolshevik revolution and the rise of Communism in Russia saw the disintegration of the Hasidic centers such as Lubavitch, Breslov, Chernobyl and Ruzhin.
Many Hasidim, primarily those following the Chabad school, but also the Tshernobler Rebbe and the Ribnitzer Rebbe, remained in the Soviet Union (primarily in Russia), intent on preserving Judaism as a religion in the face of increasing Soviet opposition. With yeshivos and instruction in Hebrew outlawed, synagogues seized by the government and transformed into secular community centers, and Jewish circumcision forbidden to all members of the Communist Party, most Hasidim took part in the general Jewish religious underground movement. Many became so-called "wandering clerics", traveling from village to village and functioning as chazzanim, shochtim, mohels, and rabbis wherever such services were needed. These figures were often imprisoned and sometimes executed.
The Nazi invasion into the interior of European Soviet Union in 1941 destroyed the remaining Hasidic communities in the former Pale of Settlement under the first mass destruction of the Holocaust. The Hasidic communities were therefore disproportionately decimated. Subsequently, the Hasidim of Central Europe were transported to the Nazi camps in occupied Poland. Some Hasidic leaders, reluctant to leave their followers, found late exit to safety. Some survived in the camps, personifying spirituality against the adversity. The Jewish photographer Mendel Grossman came from a Hasidic family and captured some of the life and struggle within the Łódź Ghetto (renamed by the Nazis Litzmannstadt), and, together with the accounts of others in the ghettos and on the way to "sanctifying God" through their martyrdom, their stories form a new literature of Hasidic Holocaust tales. Hasidic mystical perspectives on Holocaust theology are less well known than more Westernised Jewish theologians.
Contemporary demographics.
Today there are over one million Hasidic Jews worldwide.
Extinction in Eastern Europe.
The Holocaust brought total destruction to the Hasidic centers of Eastern Europe. At least 500,000 Hasidim were killed and most survivors moved to Israel or to America soon after the war and established new centers modeled on their original communities.
Some of the larger and more well-known Hasidic sects that still exist include Belz, Bobov, Breslov, Ger, Lubavitch (Chabad), Munkacs, Puppa, Sanz (Klausenburg), Satmar, Skver, Spinka and Vizhnitz.
United States.
The two main Hasidic communities in the United States, where 180,000 Hasidic Jews live, are located in New York City and Rockland County, New York. In New York City, the neighborhoods include Borough Park, Williamsburg, and Crown Heights in the borough of Brooklyn. However, the most rapidly growing community of American Hasidic Jews is located in Rockland County and Orange County in the western Hudson Valley of New York State, including the communities of Monsey, Monroe, New Square, and Kiryas Joel. There is also a sizable and rapidly growing American Hasidic community in Lakewood, New Jersey, which was once a center of mainly Litvish and Yeshiva Orthodox Jews, as well as other areas of the U.S. state of New Jersey, including Teaneck, Englewood, Passaic, and Fair Lawn. Other American Hasidic communities also exist in Pikesville and Northwest Baltimore, Maryland; the Fairfax neighborhood of Los Angeles; the Sherman Park neighborhood of Milwaukee; and St. Louis Park, a Minneapolis suburb. The West Ridge community in Chicago has the largest Hasidic community in the Midwest. A Canadian Hasidic population can be found in the Outremont borough of Montreal.
According to "The New York Times", the high fertility rate of Orthodox Jews will eventually render them the dominant demographic force in New York Jewry. A 2009 article published by the University of Florida stated that the growth of Hasidic Judaism may cause Jewish politics in the US to shift towards the political right.
Chabad is a global Hasidic movement that is based in New York. According to The Orthodox Union, "The most visible expression of this flourishing is the steady growth in Chabad's outreach efforts. Currently, 4,000 shluchim, emissaries, are scattered across the globe".
Israel.
Outside of the United States, the largest Hasidic community is in Israel, located mainly in Jerusalem and its adjacent areas, such as Ramat Beit Shemesh and also the religious city of Bnei Brak. Smaller communities are scattered across Europe, most notably in and around Stamford Hill, north-east London.
The largest groups in Israel today are Ger, Chabad, Belz, Satmar, Breslov, Vizhnitz, Seret-Vizhnitz, Nadvorna, and Toldos Aharon. In the United States the largest are Satmar, Bobov, Ger, and Lubavitch all centered in Brooklyn, New York City, USA. Reb Aharon's Satmar camp is centered in Kiryas Joel, New York, while Reb Zalman is in Williamsburg, Brooklyn and Skver (New Square) in Rockland County, New York.
Hasidic thought.
Beginning in 12th and 13th century Provence and Spain, Kabbalah (the main Jewish mysticism) began to be taught to small circles of advanced students. This metaphysical theology and exegesis, offered an esoteric, imaginative, spiritual alternative to mainstream Rabbinic Judaism and Jewish philosophy. Its greatest expression was in the Scriptural commentary, the Zohar. Medieval Kabbalah taught new doctrines of the ten "sefirot" (emanations that reveal and mediate the unknowable Divine essence), the identification of the last sefirah with the earlier Rabbinic notion of the "shechina" (Divine presence) as a feminine aspect of God, and the harmonious "shefa" (substaining flow of Divine creation through the Heavenly realms until this world) that is dependent on each person's righteousness. In 16th century Safed, a special community of great Jewish thinkers developed, which brought new synthesis to Kabbalah. Above all, Isaac Luria taught new and radical doctrines of the primordial process of creation, which became accepted as the complete structure of traditional Jewish metaphysics. These ideas described an initial "tzimtzum" (constriction of the Divine Infinity that allowed creation to take place) and its cosmic purposes, a subsequent catastrophe called "Shevirat Hakelim" (the "Breaking of the Vessels") that resulted in the present unredeemed world, and the messianic process of Tikkun (metaphysical rectification) of this, that each individual helps complete in their spiritual life. While these notions were esoteric, they also deeply supported mainstream Rabbinic Judaism, as the "shefa" and the "tikkun" were automatically fulfilled by all Jews through normative Jewish observance, whether they were aware of their deeper significance or not. As a result, and especially in reaction to the sufferings and exiles of Jewish history, the Kabbalah became the mainstream traditional Jewish theology, and inspired a hold on wider Jewish cultural imagination. While its terminology entered the daily liturgy, its subtle and advanced concepts, that could be misunderstood by spiritual novices, kept its committed study to a scholarly elite. The mainstream acceptance of Kabbalah, can be seen by the mass following that the false messiah Shabbetai Zvi gained. His mystical heresy and apostasy, awakened a Rabbinic restriction on Jewish mystical activity for the wider population.
The Baal Shem Tov and his successors, inherited this Rabbinic suspicion of their teachings, as they sought to awaken a popular, mystical revival for the simple Jewish folk, as well as offering scholarly mysticism a new soulful direction. The new teachings of Hasidism left aside the abstract, subtle, advanced focus of Kabbalah on the Divine manifestations and Heavenly realms. Kabbalah describes the full, esoteric, complicated structures of the interaction of God and Creation. Among it traditional names is the "Chochma Nistorah" (hidden wisdom) of the Torah. Kabbalistic terminology is necessary to describe the traditional Jewish processes of metaphysics. It is used extensively in the more involved Hasidic writings, but the aim of this is different from in Kabbalah. The new teachings of Hasidism look to the simple, inner Divine soul, which it sees as permeating all and also transcending all. Hasidic thought bases itself upon earlier Kabbalistic theology, but relates its ideas to the psychology and experience of man, so that Jewish mysticism can awaken a personal experience and perception of the Divine. Gershom Scholem, who established the 20th century academic study of Jewish mysticism, describes Hasidism as the "internalization of Kabbalah". The Baal Shem Tov and his successors saw Divine immanence in all Creation, that gave a full expression to panentheistic traces in earlier Kabbalah (Panentheism teaches that "All is within God". This is different from Pantheism, which is heretical in Judaism, as it denies a personal God, and Divine transcendence outside Creation. Panentheism sees Creation as Divinity, but only the immanent revelation of a transcendent, infinite God). This encounter with God could be found by all Jews, as Hasidism elevated sincerity and soulful "devekus" (cleaving to God), as the most direct path to spirituality. Traditionally, Jewish study, especially of Talmud, gives the main route to Jewish spirituality. Hasidism did not seek to replace the essential endeavour of study, but rather to infuse and connect it with devekus. Common folk, to whom study may have been inaccessible, found spirituality and joy in Hasidic mysticism, while great scholars of Talmud and Kabbalah, were also attracted to its new depth and interpretation.
The Baal Shem Tov spread Hasidism by means of simple, soulful teachings, parables, and stories. These offered Jewish mysticism to the unlearned, while the close circle of saintly followers around him understood their deeper, profound significance. The Baal Shem Tov was a man of the people, while his successor Dov Ber of Mezeritch devoted himself to creating the third generation of great Hasidic leaders. As the theological and sociological architect of the Hasidic movement, Dov Ber elucidated the underlying profound meanings of Hasidic thought and its theological contributions to Judaism. He appointed his students in the "Hevra Kaddisha" (Holy Society) to become the future leaders of Hasidism in the different regions of Eastern Europe. Alternative interpretations of Hasidic thought arose, centered in schools of Hasidic dynasties. Hasidism stressed the new doctrine of the Rebbe or Tzaddik (saintly leader), through whom Divine influence is channeled. In some Hasidic paths the Tzaddik elevates his followers through charismatic conduct, while other groups emphasize his role primarily as teacher. Many creative thinkers of Hasidic mysticism established the variety of Hasidic approaches. Because the Tzaddik offers to his followers a microcosm of the Messianic redemption, mainstream Hasidism toned down the Messianic elements to Jewish mysticism, that had endangered Shabbetai Zvi. Nonetheless, infusing Hasidism from the time of the Baal Shem Tov onwards is a Messianic self-understanding that has come to the fore on some occasions, and in more ideological circles. These include Hasidic activity around the 1812 French invasion of Russia and responses of Menachem Mendel of Kotzk and Mordechai Yosef Leiner to Messianic speculation concerning 1840. Hasidic dynasties coexist in the principle that each Tzaddik's leadership does not overstep into another's court. In the early 19th century, Nachman of Breslav led his marginal circle in the most distinctive veneration in Hasidism, arousing hostility from other leaders. This Messianic drive was paralleled on a mass scale by Menachem Mendel Schneerson of Chabad in recent times. Through its emotional and intellectual aspects, Hasidism offered Jewish life a new spiritual revival. Within Jewish study, Hasidic philosophy gave earlier Jewish thought new interpretations, that can synthesize and spiritualize the other dimensions of Judaism. In its intellectual articulations, Hasidic philosophy can bridge Jewish mysticism with mainstream Jewish philosophy. It enabled the mystical dimensions of Judaism to be articulated in a form that was accessible for the first time to the whole Jewish community. Hasidic spirituality and thought has also had appeal and influence outside the Hasidic movement, and outside of Orthodox Judaism. In the 20th Century, the academic interest in Jewish mysticism, and Neo-Hasidism have offered spiritual contributions to many Jewish denominations. With the encounter of Judaism with Modernity, different philosophical and denominational views emerged on the meanings of Judaism and Jewish identity. It has been said that the three figures of the Baal Shem Tov (Hasidic spirituality), the Vilna Gaon (Lithuanian Jewish Orthodox scholarship), and Moses Mendelssohn (founding influence on the Haskalah movement), have together shaped the diverse Jewish articulations today.
The Hasidic Tales.
"The Hasidic Tales", as they are known en masse, are a collection of Hasidic stories and anecdotes collected from the late eighteenth century onward that deal with a variety of topics having to do with Hasid culture. Touching on issues such as proper worship of the Torah, the place of the Rebbes or Tzaddikimm in Hasid society, or the importance of certain virtues, The Hasid Tales have been studied as a supplement to conventional historical works. Some of the tales are short anecdotes uttered by one Rebbe to explain a point about a specific theological matter while others are conversation between either two Rebbes or a Rebbe and a loyal follower. Regardless of how they are formatted, the tales with the most longevity and influence all share a couple of traits in common besides an appreciation of spontaneous worship and joyous celebration. For one, they are terse and compact, never being terribly excessive in length. And secondly, they tend to carry a strong and obvious point, with little extra information.
A great portion of these tales have to do with the Zaddikim, or leaders of the Hasidism movement. As the Baal Shem were the heart of Hasidic Jewish communities and shtetls, the tales written about them were a reflection of the admiration and love that they were held in. Initially these tales, characterized by things like vivid metaphors, unbelievable occurrences, and fantastic holiness were about the Baal Shem Tov and his lessons but soon took on the characteristics of their time and place. Each set of Hasidic tales within a certain time period or about a certain Rebbe, is known to reflect what they focused on. Examples of dissenting opinions on issues may be in what is and is not acceptable to pray for, whether or not the common man can achieve complete oneness with God, or what it is to be wise. As the lineage of Baal Shem advanced through the late eighteenth and early nineteenth centuries from Baal Shem to disciple, so did the physical spread of Hassidism. And through this, legends and anecdotes about the Besht, along with common Hasidic sentiments, was able to spread from Poland to regions in like Ukraine and Lithuania.
This is believed to have been because the Rebbes, who would use such tales and stories to inspire the Hasadim, were trying to convince the “simple man” of these ideas. Some of the more influential Baal Shems embraced this form of simple teaching for multiple reasons. The Besht, for instance, praised teaching the simple man because his ability to have strong communion with God could, at times, be stronger than that of his disciples. The Maggid of Mezritch preached Tzimtum, or contraction, as a way to make stories simpler to follow and, if there was a blaring message at the end, easy to take to heart. Regardless of the reasoning supported by the Rabbis, a clear template is set throughout the majority of the most circulated Hasidic Tales. It is also believed that because many of these tales were not written down until several years after their inception that keeping them brief made them easier to remember, both for the deliverer and the receiver. These tales have developed such a strong presence in Hasid culture that they are still referenced today.
Characteristic ideas.
The teachings of Hasidism are founded on two theoretical conceptions: (1) religious Panentheism, or the omnipresence of God, and (2) the idea of Devekus, communion between God and man. The Besht (Baal Shem Tov) says: "Man must always bear in mind that God is omnipresent and is always with him; that God is the most subtle matter everywhere diffused... Let man realize that when he is looking at material things he is in reality gazing at the image of the Deity which is present in all things. With this in mind man will always serve God even in small matters."
Deveikus (communion) refers to the belief that an unbroken relationship takes place between the world of God and the world of humanity. According to it, not only does the Deity influence the acts of man, but also that man exerts an influence on the will of the Deity. Every act and word of man produces a corresponding effect in the upper spheres. From this conception is derived the chief practical principle of Hasidism, cleaving to God for the purpose of uniting with the source of life and of influencing it. This communion is achieved through the concentration of thoughts on God, and consulting Him in all the affairs of life.
The "tzadik" (righteous person) is in constant communion with God, even in their worldly affairs, since they also feel His presence in daily life. A special form of communion with God is prayer. In order to render this union complete the prayer must be full of fervor, ecstatic, and the soul of the person who prays must, during their devotions, detach itself from its material dwelling. For the attainment of ecstasy, recourse can be had to mechanical means, to enthusiastic bodily motions, to shouting and singing. According to the Besht, the path to God is in sincerity and fervour, rather than cold intellectual reasoning. Learning of Jewish texts and halakhic lore are important ways to approach God, but ultimately are useful as a means of producing an exalted religious elevation and communion. It is often more helpful to read books of moral and spiritual inspiration, than to engage in over-analytical approaches in study of the Talmud and Rabbinical literature. In the performance of rites the mood of the believer is of more importance than the externals, so therefore formalism and superfluous ceremonial details are an impediment. In later Hasidic articulations, a synthesis was made with the value of traditional, Lithuanian study and analysis. Many Hasidic Masters gained admiration from the non-Hasidic world, for being great scholars of Talmudic and Rabbinic works. The intellectual school of Chabad, founded by Schneur Zalman of Liadi, can be seen as a separate offshoot of general Hasidism. Mainstream Hasidism gives special emphasis to emotions, so that study of the "revealed" or "inner" dimensions of Judaism can inspire greater faith and emotional fervour, as well as knowledge of Rabbinic thought. In Chabad, Schneur Zalman emphasised the mind as the route to internalizing the emotions of the heart more fully. The systematic analysis of Hasidic philosophy in Chabad can integrate and synthesize "revealed" Jewish thought with the mystical. More recently, a neo-Hasidic movement has emerged in the United States, originating in the community of Woodmere, NY. Hasidic historian, Rabbi Meir Dershowitz, has labeled this watershed event a "tidal wave" of Hasidic re-emergence that is destined to reinvent the persona of the contemporary American Hasid. Dershowitz currently ministers to a small cabal of neo-Hasidim in Hillside, NJ.
Aims of Hasidic thought.
Hasidic philosophy teaches a method of contemplating on God, as well as the inner significance of the Mitzvot (commandments and rituals of Torah law). Hasidic philosophy has four main goals:
Hasidic practice and culture.
Liturgy and prayer.
Most hasidim pray according to one of the variations of the nusach known as "Nusach Sefard", a blend of Ashkenazi and Sephardi liturgies, based on the innovations of Rabbi Isaac Luria (also known as the "Arizal"). However, many Hasidic dynasties have their own specific adaptation of Nusach Sefard; some, such as the versions of the Belzer, Bobover and Dushinsky Hasidim, are closer to Nusach Ashkenaz, while others, such as the Munkacz version, are closer to Nusach Sefarad of the Arizal. Hasidic Nusach is a very complicated study. Many Hasidic groups believe that their siddur reflects the wording and mystical intentions of the Arizal. Chabad-Lubavitch has a distinctive variant known as Nusach Ari of the Baal HaTanya. Other Hasidic rabbis from many other Hasidic camps have compiled authoritative "Nusach Ari" siddurim. One should not confuse the contents of the Lubavitcher siddur with the historical study of the Arizal's actual nusach.
The Baal Shem introduced two innovations to the Friday services: the recitation of Psalm 107 before Mincha (the afternoon service), as a prelude to the Sabbath, one gives praise for the release of the soul from its weekday activities, and Psalm 23 just before the end of Maariv (evening service).
In regard to dialect, Hasidim pray in Ashkenazi Hebrew, a form of Hebrew with many distinct features; for instance, the vowel tsere is pronounced ] insead of ] like Sephardi Hebrew, and the vowel kamatz is pronounced ] or ] instead of ] like Sephardi Hebrew. This dialect has nothing to do with Hasidism in its origins, nor was it chosen deliberately; it just happens to be the dialect of the places from which most Hasidim originally came, such as Galicia and Ukraine. Thus, there are significant differences between the dialects used by Hasidim originating in different places, such as Poland, Belarus, Hungary, and Ukraine.
Hasidic prayer has a distinctive accompaniment of wordless melodies called "nigunim" that represent the overall mood of the prayer; in recent years this innovation has become increasingly popular in non-Hasidic communities as well. Hasidic prayer also has a reputation for taking a very long time (although some groups do pray quickly). Some hasidim will spend seven seconds of concentration on every single word of the prayer of "Amidah".
Hasidim have a reputation for having a lot of "kavana", mental concentration, during prayer. Overall, Hasidim regard prayer as one of the most paramount activities during the day. In fact, one of the most controversial innovations of Hasidic practice as practiced in several courts involves the near-abolition of the traditional specified times of day by which prayers must be conducted ("zemanim"), particularly "shacharis" (the morning prayer service); the preparations for prayer take precedence and may extend into the allotted time. The Kotsker Rebbe allegedly originated this practice, which is prevalent to this day in Chabad-Lubavitch. It is controversial in many other Hasidic courts, who place more emphasis on praying earlier and not eating before praying, according to the interpretation of Halacha (Jewish law) which is followed by the vast majority of other Hasidic and non-Hasidic Orthodox Jews.
Daily immersion.
Male Orthodox Jews customarily immerse in a "mikvah" (ritual pool of water) before major Jewish holidays (and particularly before Yom Kippur), in order to achieve spiritual cleanliness. Hasidim have extended this to a daily practice preceding . Although daily immersion in a "mikvah" is no longer mandated by halacha, Hasidism places great emphasis on this practice, because the Arizal taught that each time one immerses in a "mikvah" he adds holiness to his soul. It is also taught by the Baal Shem Tov, that all his wisdom was given to him by God in merit of his immersions in the mikvah, and that no male should go three days without going to the mikvah. The Talmud records an enactment by Ezra that after a seminal emission one must immerse in a "mikvah" before studying Torah or praying; although this enactment was later repealed, Hasidim and some other Jews still follow it, at least for prayer, though the Code of Jewish Law rules that it is not mandatory.
Dress.
Within the Hasidic world, it is possible to distinguish different Hasidic groups by subtle differences in dress. Some details of their dress are shared by non-Hasidic Haredim. Much of Hasidic dress was historically the clothing of all Eastern-European Jews. From at least the sixteenth century, styles of Jewish men’s dress in Eastern Europe were influenced by those of the "szlachta" (Polish nobles). While the "szlachta" abandoned certain types of clothing for newer fashions, Hasidim have preserved some of those older styles to the present day. Furthermore, Hasidim have attributed religious origins to specific Hasidic items of clothing.
The Tsarist edict of the mid-19th century banning Jewish clothing mentions the "Jewish kaftan" and the "Jewish hat" and, as a result of this edict, Hasidim modified their dress in the Russian Empire and generally hid their sidelocks. Modern Chabad Lubavitch wear the Prince Albert frock coat substitutes for the "bekishe" reflecting this change, while many Polish Hasidim do so by wearing a redesigned "shtreimel" sometimes known as a spodik.
Hasidic dress did change over the last hundred years, and became more European in response to the Emancipation Movement. Modern Hasidim tend to wear Hasidic dress as worn just prior to World War II. Numerous pictures of Hasidim in the mid-19th century show a far more Levantine outfit (i.e. a kaftan lacking lapels or buttons) that differs little from the classical oriental outfit consisting of the kaftan, white undershirt, sash, knee-breeches ("halbe-hoyzn"), white socks and slippers ("shtibblat"). This outfit allegedly had a Babylonian origin before its later adoption by Jews, Persians and lastly the Turks, who brought it to Europe. The Polish nobility adopted its 16th century outfit from the Turks, hence the similarity between the Hasidic outfit and Polish nobles' clothing. (Similarly, Hasidic dress has a vague connection with Shia Muslim clerical dress, the Shia clergy adopted this dress from the Persians.) One Hasidic belief (taught by the Klausenberger rebbe) holds that Jews originally invented this dress code and that the Babylonians adopted it from Jews during the Jewish exile in Babylon of the 6th century BCE. This belief is not widely held or even well known among Hasidim.
Hasidic men most commonly wear dark (black or navy) jackets and trousers and white shirts. They will usually also wear black shoes. On weekdays they wear a long, black, cloth jacket called a rekel and on Jewish Holy Days the bekishe "zaydene kapote" (Yiddish, lit. satin caftan), a similarly long, black jacket but of satin fabric traditionally silk. The preference for black comes from a decree made by community rabbis in the 18th century stipulating that black outer garments be worn on the Sabbath and Jewish Holy Days out of the home, as opposed to the shiny, colorful kaftans that were worn prior to that time. The rabbis feared that brightly colored clothes might arouse resentment among non-Jews thereby leading to violence. Indoors the colorful tish bekishe is still worn.
On the Sabbath the Hasidic Grand Rabbis ("rebbes") traditionally wore a white bekishe rather than a black one. This practice has fallen into disuse except for a minority of rebbes, such as Toldos Aharon and Lelov, and by Hungarian rebbes such as Tosh and Satmar. Many rebbes wear a black silk "bekishe" that is trimmed with velvet (known as "stro-kes" or "samet") and in those of Hungarian lineage a gold designed or other coloured, "tish bekishe" or "khalat" (especially during the "tish" or during the prayers that come right before or after the "tish").
Some Hasidim wear a satin overcoat, known among Hungarian and Galitsyaner Hasidim as a "rezhvolke", over the regular "bekishe". A rebbe's "rezhvolke" might be trimmed with velvet. Some rebbes wear a fur-lined "rezhvolke" known as a "tilep" (Yiddish: טולעפ fur coat).
Most Hasidim do not wear neckties (with the exception of some Russian Hasidim, such as those stemming from Ruzhin, Karlin, and Lubavitch).
These are some of the religious aspects claimed by Hasidim of their dress code. The connections are quite tenuous and the real reasons for the Hasidic dress code are historical and sociological and not theological.
Headwear.
Hasidim customarily wear black hats during the weekdays, as do nearly all Haredim today. A variety of hats are worn depending on the sect.
Hasidim wear a variety of fur headdresses on the Sabbath:
Other distinct clothing.
Gerrer Hasidim wear "hoyznzokn"—long black socks that the trousers are tucked into. Some Hasidim from Eastern Galicia wear black socks with their breeches on the Sabbath, as opposed to white ones, particularly Belzer Hasidim.
Many Hungarian Hasidic and non-Hasidic laymen wear a suit jacket that lies somewhere between a "rekel" and a regular three-quarter double breasted suit called a "drei-fertl" (Yiddish for "three-quarter"). It is distinct from a regular three-quarter suit inasmuch as the right side covers the left, like a "rekel".
Many Skverer hasidim wear knee-high leather boots ("shtifl") with their breeches on the Sabbath. This manner of concealing the stockings was introduced as a compromise prior to a family wedding when one side had the tradition of wearing white stockings and the other did not. The Skverer Rebbe and his family wear such boots every day, and so do some rabbinical families affiliated with other Hasidic groups.
Hair.
Following a Biblical commandment not to shave the sides of one's face, male members of most Hasidic groups wear long, uncut sidelocks called payot (Ashkenazi Hebrew "peyos", Yiddish "peyes"). Some Hasidic men shave off the rest of their hair. Not every Hasidic group requires long peyos, and not all Jewish men with peyos are Hasidic, but all Hasidic groups discourage the shaving of one's beard. Most Hasidic boys receive their first haircuts ceremonially at the age of three years (only the Skverrer Hasidim do this at their boys' second birthday). Until then, Hasidic boys have long hair. Some non-Hasidic Orthodox (and even a few non-Orthodox) Jews have adopted this custom.
Tzitzis.
The white threads dangling at the waists of Hasidim and other Orthodox Jewish males except for the strings that many leave hanging out; many Hasidim, as well as some other Haredim, wear the "tallis katan" over their shirt.
Women.
Hasidic women wear clothing adhering to the principles of modest dress in Jewish law. This includes long, conservative skirts and sleeves past the elbow as well as covered necklines. Also, the women wear stockings to cover their legs; in some Hasidic groups, such as Satmar or Toldot Aharon, the stockings must be opaque. In keeping with Jewish law, married women cover their hair, using either a "sheitel" (wig) or a "tichel" (headscarf) which is sometimes used to cover a "shpitzel". In some Hasidic groups, such as Satmar, women may wear two headcoverings – a wig and a scarf or a wig and a hat.
Families.
Hasidic men and women, as customary in Orthodox Judaism, usually meet through matchmakers in a process called a "shidduch", but marriages involve the mutual consent of the couple. Expectations exist that a bride and groom should be about the same age. Marriage age in Orthodox Judaism ranges from 18 to 25, with 18–21 range considered the norm among Hasidim. No custom encourages an older man marrying a young woman, but this is often considered the ideal nonetheless. Hasidic thought stresses the holiness of sex, and pious Jewish couples follow strict regulations in their sexual lives.
Hasidic Jews, like many other Orthodox Jews, typically produce large families; the average Hasidic family in the United States has 8 children. This is followed out of a desire to fulfill the Biblical mandate to "be fruitful and multiply".
Languages.
Most Hasidim speak the language of their countries of residence, but use Yiddish among themselves as a way of remaining distinct and preserving tradition. Thus children are still learning Yiddish today, and the language, despite predictions to the contrary, is not dead. Yiddish newspapers are still published, and Yiddish fiction is being written, primarily aimed at women. Films in Yiddish are being produced within the Hasidic community, and released immediately as DVDs (as opposed to the Yiddish movies of the past, which were produced by non-religious Jews). Some Hasidic groups, such as Satmar or Toldot Aharon, actively oppose the everyday use of Hebrew, which they consider a holy tongue. The use of Hebrew for anything other than prayer and study is, according to them, profane. Hence Yiddish is the vernacular and common tongue for many Hasidim around the world. The use of Yiddish is a major difference between Sephardi and Ashkenazi Haredim. Sephardi Haredim usually do not know Yiddish (unless they were educated in an Ashkenazi yeshiva).
Further reading.
</dl>

</doc>
<doc id="14439" url="http://en.wikipedia.org/wiki?curid=14439" title="Harmonic series (music)">
Harmonic series (music)

A harmonic series is the sequence of all multiples of a base frequency. 
Pitched musical instruments are often based on an approximate harmonic oscillator such as a string or a column of air, which oscillates at numerous frequencies simultaneously. At these resonant frequencies, waves travel in both directions along the string or air column, reinforcing and canceling each other to form standing waves. Interaction with the surrounding air causes audible sound waves, which travel away from the instrument. Because of the typical spacing of the resonances, these frequencies are mostly limited to integer multiples, or harmonics, of the lowest frequency, and such multiples form the harmonic series (see harmonic series (mathematics)).
The musical pitch of a note is usually perceived as the lowest partial present (the fundamental frequency), which may be the one created by vibration over the full length of the string or air column, or a higher harmonic chosen by the player. The musical timbre of a steady tone from such an instrument is determined by the relative strengths of each harmonic.
Terminology.
Partial, harmonic, fundamental, inharmonicity, and overtone.
Any complex tone "can be described as a combination of many simple periodic waves (i.e., sine waves) or "partials," each with its own frequency of vibration, amplitude, and phase." (Fourier analysis)
A partial is any of the sine waves by which a complex tone is described. 
A "harmonic" (or a "harmonic partial") is any of a set of partials that are whole number multiples of a common fundamental frequency. This set includes the "fundamental", which is a whole number multiple of itself (1 times itself). 
"Inharmonicity" is a measure of the deviation of a partial from the closest ideal harmonic, typically measured in cents for each partial.
Typical pitched instruments are designed to have partials that are close to being whole-number ratios, harmonics, with very low inharmonicity; therefore, in music theory, and in instrument tuning, it is convenient to speak of the partials in those instruments' sounds as harmonics, even if they have some inharmonicity. Other pitched instruments, especially certain percussion instruments, such as marimba, vibraphone, tubular bells, and timpani, contain mostly inharmonic partials, yet may give the ear a good sense of pitch. Unpitched, or indefinite-pitched instruments, such as cymbals, gongs, or tam-tams make sounds (produce spectra) rich in inharmonic partials. 
An "overtone" is any partial except the lowest. Overtone does not imply harmonicity or inharmonicity and has no other special meaning other than to exclude the fundamental. This can lead to numbering confusion when comparing overtones to partials; the first overtone is the second partial.
Some electronic instruments, such as theremins and synthesizers, can play a pure frequency with no overtones, although synthesizers can also combine frequencies into more complex tones, for example to simulate other instruments. Certain flutes and ocarinas are very nearly without overtones.
Frequencies, wavelengths, and musical intervals in example systems.
The simplest case to visualise is a vibrating string, as in the illustration; the string has fixed points at each end, and each harmonic mode divides it into 1, 2, 3, 4, etc., equal-sized sections resonating at increasingly higher frequencies. Similar arguments apply to vibrating air columns in wind instruments, although these are complicated by having the possibility of anti-nodes (that is, the air column is closed at one end and open at the other), conical as opposed to cylindrical bores, or end-openings that run the gamut from no flare (bell), cone flare (bell), or exponentially shaped flares (bells).
In most pitched musical instruments, the fundamental (first harmonic) is accompanied by other, higher-frequency harmonics. Thus shorter-wavelength, higher-frequency waves occur with varying prominence and give each instrument its characteristic tone quality. The fact that a string is fixed at each end means that the longest allowed wavelength on the string (giving the fundamental frequency) is twice the length of the string (one round trip, with a half cycle fitting between the nodes at the two ends). Other allowed wavelengths are 1/2, 1/3, 1/4, 1/5, 1/6, etc. times that of the fundamental.
Theoretically, these shorter wavelengths correspond to vibrations at frequencies that are 2, 3, 4, 5, 6, etc., times the fundamental frequency. Physical characteristics of the vibrating medium and/or the resonator it vibrates against often alter these frequencies. (See inharmonicity and stretched tuning for alterations specific to wire-stringed instruments and certain electric pianos.) However, those alterations are small, and except for precise, highly specialized tuning, it is reasonable to think of the frequencies of the harmonic series as integer multiples of the fundamental frequency.
The harmonic series is an arithmetic series (1×f, 2×f, 3×f, 4×f, 5×f, ...). In terms of frequency (measured in cycles per second, or hertz (Hz) where f is the fundamental frequency), the difference between consecutive harmonics is therefore constant and equal to the fundamental. But because human ears respond to sound nonlinearly, higher harmonics are perceived as "closer together" than lower ones. On the other hand, the octave series is a geometric progression (2×f, 4×f, 8×f, 16×f, ...), and people hear these distances as "the same" in the sense of musical interval. In terms of what one hears, each octave in the harmonic series is divided into increasingly "smaller" and more numerous intervals.
The second harmonic, whose frequency is twice of the fundamental, sounds an octave higher; the third harmonic, three times the frequency of the fundamental, sounds a perfect fifth above the second harmonic. The fourth harmonic vibrates at four times the frequency of the fundamental and sounds a perfect fourth above the third harmonic (two octaves above the fundamental). Double the harmonic number means double the frequency (which sounds an octave higher).
Harmonics and tuning.
If the harmonics are transposed into the span of one octave, they approximate some of the notes in what the West has adopted as the chromatic scale based on the fundamental tone. The Western chromatic scale has been modified into twelve equal semitones, which is slightly out of tune with many of the harmonics, especially the 7th, 11th, and 13th harmonics. In the late 1930s, composer Paul Hindemith ranked musical intervals according to their relative dissonance based on these and similar harmonic relationships.
Below is a comparison between the first 31 harmonics and the intervals of 12-tone equal temperament (12TET), transposed into the span of one octave. Tinted fields highlight differences greater than 5 cents (1/20th of a semitone), which is the human ear's "just noticeable difference" for notes played one after the other (smaller differences are noticeable with notes played simultaneously).
The frequencies of the harmonic series, being integer multiples of the fundamental frequency, are naturally related to each other by whole-numbered ratios and small whole-numbered ratios are likely the basis of the consonance of musical intervals (see just intonation). This objective structure is augmented by psychoacoustic phenomena. For example, a perfect fifth, say 200 and 300 Hz (cycles per second), causes a listener to perceive a combination tone of 100 Hz (the difference between 300 Hz and 200 Hz); that is, an octave below the lower (actual sounding) note. This 100 Hz first-order combination tone then interacts with both notes of the interval to produce second-order combination tones of 200 (300 – 100) and 100 (200 – 100) Hz and all further nth-order combination tones are all the same, being formed from various subtraction of 100, 200, and 300. When one contrasts this with a dissonant interval such as a tritone (not tempered) with a frequency ratio of 7:5 we get, for example, 700 – 500 = 200 (1st order combination tone) and 500 – 200 = 300 (2nd order). The rest of the combination tones are octaves of 100 Hz so the 7:5 interval actually contains 4 notes: 100 Hz (and its octaves), 300 Hz, 500 Hz and 700 Hz. Note that the lowest combination tone (100 Hz) is a 17th (2 octaves and a major third) below the lower (actual sounding) note of the tritone. All the intervals succumb to similar analysis as has been demonstrated by Paul Hindemith in his book "The Craft of Musical Composition", although he rejected the use of harmonics from the 7th and beyond.
Timbre of musical instruments.
The relative amplitudes (strengths) of the various harmonics primarily determine the timbre of different instruments and sounds, though onset transients, formants, noises, and inharmonicities also play a role. For example, the clarinet and saxophone have similar mouthpieces and reeds, and both produce sound through resonance of air inside a chamber whose mouthpiece end is considered closed. Because the clarinet's resonator is cylindrical, the even-numbered harmonics are less present. The saxophone's resonator is conical, which allows the even-numbered harmonics to sound more strongly and thus produces a more complex tone. The inharmonic ringing of the instrument's metal resonator is even more prominent in the sounds of brass instruments.
Human ears tend to group phase-coherent, harmonically-related frequency components into a single sensation. Rather than perceiving the individual partials–harmonic and inharmonic, of a musical tone, humans perceive them together as a tone color or timbre, and the overall pitch is heard as the fundamental of the harmonic series being experienced. If a sound is heard that is made up of even just a few simultaneous sine tones, and if the intervals among those tones form part of a harmonic series, the brain tends to group this input into a sensation of the pitch of the fundamental of that series, even if the fundamental is not present.
Variations in the frequency of harmonics can also affect the "perceived" fundamental pitch. These variations, most clearly documented in the piano and other stringed instruments but also apparent in brass instruments, are caused by a combination of metal stiffness and the interaction of the vibrating air or string with the resonating body of the instrument.
Interval strength.
David Cope (1997) suggests the concept of interval strength, in which an interval's strength, consonance, or stability (see consonance and dissonance) is determined by its approximation to a lower and stronger, or higher and weaker, position in the harmonic series. See also: Lipps–Meyer law.
Thus, an equal-tempered perfect fifth (  ) is stronger than an equal-tempered minor third (  ), since they approximate a just perfect fifth (  ) and just minor third (  ), respectively. The just minor third appears between harmonics 5 and 6 while the just fifth appears lower, between harmonics 2 and 3.

</doc>
<doc id="14441" url="http://en.wikipedia.org/wiki?curid=14441" title="Hasidim">
Hasidim

Hasidim/Chasidim (Hebrew: חסידים‎) is the plural of Hasid (חסיד), meaning "pious". The honorific "Hasid" was frequently used as a term of exceptional respect in the Talmudic and early medieval periods. In classic Rabbinic literature it differs from "Tzadik"-"righteous", by instead denoting one who goes beyond the legal requirements of ritual and ethical Jewish observance in daily life. The literal meaning of "Hasid" derives from Chesed-"kindness", the outward expression of love for God and other people. This spiritual devotion motivates pious conduct beyond everyday limits. The devotional nature of its description lent itself to a few Jewish movements in history being known as "Hasidim". Two of these derived from the Jewish mystical tradition, as it could tend towards piety over legalism.
As a personal honorific, both "Hasid" and "Tzadik" could be applied independently to a same individual with both different qualities. The 18th-century Vilna Gaon, for instance, while the head of Rabbinic opposition to the new Jewish mystical movement that itself became known as "Hasidism", was renowned for his righteous life. His scholarship became popularly honored with the formal title of "Genius", while amongst the Hasidic movement's leadership, despite his fierce opposition, he was respectfully referred to as "The Gaon, the Hasid from Vilna".
In the aggregate, it may refer to members of any of the following Jewish movements:

</doc>
<doc id="14443" url="http://en.wikipedia.org/wiki?curid=14443" title="Hoosier Hysteria">
Hoosier Hysteria

Hoosier Hysteria is the state of excitement surrounding basketball in Indiana, or more specifically the Indiana high school basketball tournament. In part, the excitement stemmed from the inclusion of all tournament entrants into the same tournament, where a small town's David might knock off a large city's Goliath. The most famous example occurred in 1954, when Milan (enrollment 161) defeated Muncie Central (enrollment over 1,600) to win the State title. The plot of the now famous movie, "Hoosiers", was based on the story of the 1954 Milan team and seems to typify the hysteria related to basketball in the state of Indiana. 
Indiana's passion for basketball was observed and written about by basketball's inventor, James Naismith. In 1925, Naismith visited an Indiana basketball state finals game along with 15,000 screaming fans and later wrote, that while it was invented in Massachusetts, "basketball really had its origin in Indiana, which remains the center of the sport." Hoosiers have a traditional love for basketball similar to that of Texans for football, Pennsylvanians for wrestling, and Minnesotans for ice hockey.
High school basketball.
Homegrown talent.
Indiana high schools boast a tradition of producing top caliber basketball players. Through the 2009-2010 NBA season, 152 hoosier athletes have played professional basketball in the world's top league. Considering the size of the state (population 6.4 million), this makes Indiana high schools by far the most successful at developing NBA players per capita. Today there are 22 hoosiers in the NBA - more than one for every 150,000 male residents. The state's unparalleled ability to produce NBA talent, both state-wide and specifically in smaller towns, is featured in this 
One-class tradition.
Historically, each of the several hundred small towns of Indiana had its own small school system. Before consolidation of many of these rural school districts in the last half of the twentieth century, Indiana high schools had fewer students than those of most other states; basketball was a natural game for these schools since it only required five starters and a few reserves. Even one or two great basketball players could make a high school team a powerhouse, and nearly every Indiana town dreamt of such glory.
The Franklin Wonder Five was the first team to win the state championship in three consecutive years, from 1920-1922. This accomplishment would not be matched for over six decades. The team was led by Fuzzy Vandivier.
After Milan's Miracle in the 1950s, no school with an enrollment of less than 500 won another boys' State title under the all-comers format. As school consolidation became more common and as more rural residents migrated to cities making large high schools grow even larger, smaller high schools had only a mismatch to look forward to come tournament time, as success concentrated in Indiana's large urban and suburban schools. Starting with the 1997-1998 season, Indiana established a controversial four-class system for its basketball championship, although many other sports remain single-class. The state's move to this new system has, to some extent, diminished the phenomenon and public opinion is widely split on the merits of "class basketball."
Aside from the "Milan Miracle," the story of Crispus Attucks High School ranks as one of the greatest in Indiana high school basketball tradition. In 1955, the year after Attucks had lost in the semistate final (state quarterfinals) to Milan's championship team, Attucks gained fame by winning the Indiana state championship, becoming the first all-black school in the nation to win a state title open to all schools regardless of race. Crispus Attucks repeated as champions in 1956, becoming the first Indiana high school team to complete a season undefeated. The Attucks teams of 1954 through 1956 were led by Oscar Robertson. Both stories, Milan and Crispus Attucks, are memorialized for their accomplishments and tradition at the Indiana State Museum as well as at the Indiana Basketball Hall of Fame in New Castle, Indiana.
A highlight of the single-class tournament was the 1990 State Championship game, in which the paid attendance was over 40,000 fans. This phenomenal turnout of fans who witnessed Damon Bailey's Bedford-North Lawrence Stars win the State Championship stands as the largest crowd ever to witness a high school basketball game.
After the 1997 season (when Bloomington North won the final single-class State Championship), the IHSAA controversially did away with the single-class system, ending the run of single-class champions in Indiana. There are many in Indiana who lament this loss, and who know that Hoosier Hysteria has been dramatically and significantly lessened thereby. Hoosier Hysteria has not completely diminished however. For example, in 2003, DeKalb High School (1200 students) nearly defeated Pike High School (3000) students). Also, the Indiana tournament is still the most attended in the nation, with final four games for the two larger divisions regularly selling out Bankers Life Fieldhouse (formerly Conseco Fieldhouse).
High school gymnasiums.
Perhaps one of the more telling signs of the passion and commitment to basketball at the high school level is the number and size of large basketball gymnasiums in the state. With considerable cost and effort, Indiana boasts nine of the ten largest high school gyms in the country, and a purported eighteen of the top twenty. Seventeen venues in Indiana today boast a capacity of over 6,000, the largest being the New Castle Fieldhouse, seating 9,325.
College basketball.
Hoosier Hysteria may have its roots firmly planted in the high school game, but the college tradition brings its own depth to Indiana's passion. In NCAA Division I basketball, Indiana's colleges and universities have a storied past. Big Ten rivals Purdue University and Indiana University are the most notable, with national and conference championships to boast. Smaller schools such as the University of Notre Dame, Indiana State University, Ball State University, Butler University, the University of Evansville, IUPUI, IPFW, and Valparaiso University add to the mix. Vincennes University boasts an outstanding national tradition in the junior college ranks. And in Division II St. Joseph's, University of Indianapolis and University of Southern Indiana have added their own successes to the legend of Indiana basketball. Wabash College won the Men's Division III NCAA Championship in 1982 and their 1905 24-0 team was considered World Champions; DePauw University and Manchester College were Div III National Finalists. It is safe to say that the terms "Final Four" and "March Madness" have grown out of the tradition of Hoosier Hysteria.
Ball State Cardinals.
The Ball State Cardinals have won several conference championships and earned a number of NCAA Tournament berths over the years, including:
Indiana Hoosiers.
Indiana's collegiate basketball squad, the Indiana Hoosiers men's basketball team has several championships to their credit:
The Hoosiers' five NCAA Championships are the third-most in history, tied with UNC trailing UCLA (11) and Kentucky (8). Their eight trips to the Final Four ranks seventh on the all-time list. The Hoosiers have made 32 appearances in the NCAA Men's Division I Basketball Tournament (fifth-most in NCAA history). In those 32 appearances, Indiana has posted 52 victories, the sixth-most in NCAA history.
Purdue Boilermakers.
With their only men's National Championship coming in the days before the NCAA Tournament, the Purdue Boilermakers have a basketball history:
The Boilermaker women have one National Championship (1999), one national runner-up finish (2001 to Notre Dame), seven Big Ten Championships, and have won six of the thirteen women's Big Ten Tournaments.
St. Joseph's Pumas.
They are members of the Great Lakes Valley Conference, the top Division II conference in the nation.
Vincennes Trailblazers.
The Vincennes University men's basketball program is the 4th winningest junior college program in the country, with 1,470 victories. The Trailblazers trail Southeastern Iowa Community College (1,519), Moberly, Mo., (1,505) and Hutchinson, Kan., with 1,490.
The Trailblazers' 3 National Titles place them 3rd in titles behind Moberly Area Community College and San Jacinto College - Central, which each have four titles.
The Vincennes program began in 1903, however, no teams were formed from 1910–1912 and 1931-1950.
Professional basketball.
Indiana Pacers.
The Indiana Pacers are a professional basketball team that plays in the National Basketball Association (NBA). The team is based in the state's capital and largest city, Indianapolis, located in the center of the state. The Indiana Fever of the WNBA, also owned by Melvin & Herb Simon, are the Pacers' sister team and also play in the Bankers Life Fieldhouse.
Indiana Fever.
The Indiana Fever is a professional women's basketball team that plays in the Women's National Basketball Association (WNBA). The Fever are based in Indiana's capital and largest city, Indianapolis. The Fever play at Bankers Life Fieldhouse, located in downtown Indianapolis. The team is the sister team of the NBA's Indiana Pacers.
National profile.
Big Ten Tournament.
At the conclusion of the regular Big Ten season, a tournament is held to determine the conference winner, who receives the conference's automatic bid to the NCAA tournament. Indianapolis has hosted all but one of the women's tournaments since its inception in 1995, and Bankers Life Fieldhouse has hosted every tournament since 2002, as well as the 2000 edition. The Big Ten Conference Men's Basketball Tournament began a five-year stint at Bankers Life Fieldhouse in 2008.
Final Four.
Indianapolis, headquarters of the National Collegiate Athletic Association and often referred to as the "Amateur Sports Capital of the World" has hosted a number of collegiate basketball events. Aside from the multitude of regional games held during the NCAA tournament, Indianapolis has hosted six men's NCAA Final Fours (1980, 1991, 1997, 2000, 2006, 2010) and two women's (2005, 2011). Indianapolis is scheduled to host the men's 2015 Final Four. Previous events were held in the Market Square Arena or the RCA Dome, but given the new stadium built for the Indianapolis Colts, Lucas Oil Stadium began hosting Final Four events in 2010. When the NCAA Headquarters relocated to Indianapolis, it was stated that Indianapolis would then host the men's Final Four once every five years. The leading factor in the NCAA's decision to move to Indianapolis was the overwhelming amount of local athletic infrastructure, all of it world-class.
World championships.
In 2002, Indianapolis hosted the FIBA World Championship (now known as the FIBA Basketball World Cup), an event that takes place on even years opposite the Olympic Games. Since inaugural event in 1950, Indianapolis is the only city in the United States to have hosted the event.
Local basketball stars.
Here follows a list of notable Indiana natives, as well as non-natives who were raised in the state, who have achieved success in basketball.
Non-natives (i.e., those who did not arrive in Indiana before college) who gained basketball fame in Indiana's tradition include:

</doc>
<doc id="14445" url="http://en.wikipedia.org/wiki?curid=14445" title="Hardcore">
Hardcore

Hardcore, hard core or hard-core may refer to:

</doc>
<doc id="14446" url="http://en.wikipedia.org/wiki?curid=14446" title="Harold Alexander, 1st Earl Alexander of Tunis">
Harold Alexander, 1st Earl Alexander of Tunis

Field Marshal Harold Rupert Leofric George Alexander, 1st Earl Alexander of Tunis KG GCB OM GCMG CSI DSO MC CD PC PC(Can) (10 December 1891 – 16 June 1969) was a British military commander and field marshal who served with distinction in both world wars and, afterwards, as Governor-General of Canada, the 17th since Canadian Confederation.
Alexander was born in London, England, to aristocratic parents and was educated at Harrow before moving on to the Royal Military College, Sandhurst, for training as an army officer. He rose to prominence through his service in the First World War, receiving numerous honours and decorations, and continued his military career through various British campaigns across Europe and Asia. In the Second World War, Alexander oversaw the final stages of the Allied evacuation from Dunkirk and subsequently held high-ranking field commands in Burma, North Africa, and Italy, including serving as Commander-in-Chief Middle East and commanding the 18th Army Group in Tunisia. He then commanded the 15th Army Group for the capture of Sicily and again in Italy before receiving his field marshal's baton and being made Supreme Allied Commander Mediterranean.
He was in 1946 appointed as governor general by King George VI, on the recommendation of Prime Minister of Canada William Lyon Mackenzie King, to replace the Earl of Athlone as viceroy, and he occupied the post until succeeded by Vincent Massey in 1952. Alexander proved to be enthusiastic about the Canadian wilderness and was a popular governor general with Canadians. He was the last non-Canadian-born governor general before the appointment of Adrienne Clarkson in 1999, as well as the last governor general to be a peer.
After the end of his viceregal tenure, Alexander was sworn into the Queen's Privy Council for Canada and thereafter, in order to serve as the British Minister of Defence in the Cabinet of Winston Churchill, into the Imperial Privy Council. Alexander retired in 1954 and died in 1969.
Early life.
Alexander was born in London, the third son of the Earl and Countess of Caledon, the latter being a daughter of the Earl of Norbury. Alexander was educated at Hawtreys and Harrow School, there participating as the 11th batsman in the sensational Fowler's Match against Eton College in 1910. Though Alexander toyed with the notion of becoming an artist, he went instead on to the Royal Military College, Sandhurst.
Military career.
In September 1911, Alexander was commissioned as a second lieutenant in the Irish Guards, British Army. He was promoted to lieutenant in December 1912.
First World War.
Alexander spent the war on the Western Front. As a 22-year-old platoon commander in the 1st Battalion Irish Guards, he served in the British Expeditionary Force (BEF) in 1914. He took part in the retreat from Mons and was wounded at First Ypres and invalided home. He was promoted temporary captain on 15 November 1914 and permanent captain in the newly raised 2nd Battalion on 7 February the following year.
Alexander returned to the Western Front in August 1915, fought at Loos and was, for ten days in October 1915, acting major and acting Commanding Officer of 1st Battalion Irish Guards as a "Battle Casualty Replacement". He then returned to 2nd Battalion as a company officer and, in January 1916, received the Military Cross for his bravery at Loos. For service on the Somme on 15 September 1916, he was in October appointed to the Distinguished Service Order, the citation for which read: "For conspicuous gallantry in action. He was the life and soul of the attack, and throughout the day led forward not only his own men but men of all regiments. He held the trenches gained in spite of heavy machine gun fire." In the same month, Alexander was further honoured with induction into the French Légion d'honneur.
On 10 December 1916, Alexander took second-in-command of 1st Battalion Irish Guards as acting major. By May, Alexander was briefly acting Commanding Officer of 1st Battalion, as an acting lieutenant-colonel, while still only a substantive captain. He became a permanent major on 1 August 1917 and was again promoted acting lieutenant-colonel, this time confirmed as Commanding Officer of 2nd Battalion Irish Guards, on 15 October. Alexander commanded his battalion at Third Ypres, where he was slightly wounded, then at Bourlon Wood (part of the battle of Cambrai), where his battalion suffered 320 casualties out of 400 men. Alexander, between 23 and 30 March 1918, had to assume command of the 4th Guards Brigade, during the British retreat. He once again commanded 2nd Battalion at Hazebrouck in April 1918, where it took such severe casualties that it saw no further action. Still an acting lieutenant-colonel, he then commanded a corps infantry school in October 1918.
Rudyard Kipling, who wrote a history of the Irish Guards, in which his own son fought and was killed, noted that, "it is undeniable that Colonel Alexander had the gift of handling the men on the lines to which they most readily responded... His subordinates loved him, even when he fell upon them blisteringly for their shortcomings; and his men were all his own."
Inter-war years.
Alexander in 1919 served with the Allied Control Commission in Poland. As a temporary lieutenant-colonel, he led the Baltic German Landeswehr in the Latvian War of Independence, commanding units loyal to Latvia in the successful drive to eject the Bolsheviks from Latgalia. During service there, he was accidentally wounded by one of his own sentries on 9 October 1919.
Alexander returned to Britain in May 1920 as a major, second in command of 1st Battalion Irish Guards; in May 1922, he was promoted substantive lieutenant-colonel and appointed commanding officer. He commanded the battalion at Constantinople (a sensitive posting in the runup to the Chanak Crisis), then Gibraltar from October 1922, then in London from April 1923 until January 1926, when he was released from that role to attend Staff College, Camberley. Alexander was then in February 1928 promoted to colonel (backdated to 14 May 1926) and was the next month appointed Officer Commanding the Irish Guards Regimental District and 140th (4th London) Infantry Brigade in the Territorial Army a post he held until January 1930, when he again returned to study, attending the Imperial Defence College for one year. There, two of Alexander's instructors—the future field marshals Alan Brooke and Bernard Montgomery—were unimpressed by him.
After the completion of his courses, Alexander, on 14 October 1931, married Lady Margaret Bingham, the daughter of the Earl of Lucan and with whom Alexander had two sons—Shane, born 1935, and Brian, born 1939—and a daughter, as well as adopting another daughter during his time as Canada's governor general. Alexander then held staff appointments as (from January 1931) GSO2 in the Directorate of Military Training at the War Office and (1932–34) GSO1 at HQ Northern Command in York, before being made in October 1934 a temporary brigadier and given command of the Nowshera Brigade, on the Northwest Frontier in India. For his service there, and in particular for his actions in the Loe-Agra operations against the Pathans in Malakand between February and April 1935, Alexander was that year made a Companion of the Order of the Star of India and was mentioned in despatches. He was mentioned once more for his service during the Second Mohmand Campaign in Northwest Frontier Province from August to October of the same year, serving under Brigadier Claude Auchinleck. Alexander had a reputation for leading from the front and for reaching mountain crests with or even ahead of his troops.
In March 1937, Alexander was appointed as one of the aides-de-camp to the recently acceded King George VI and in May returned to the United Kingdom to take part in this capacity in the state procession through London during the King's coronation. Alexander would have been seen in this event by two of his Canadian viceregal successors: Vincent Massey, who was then the Canadian high commissioner to the United Kingdom, and Massey's secretary, Georges Vanier, who watched the procession from the roof of Canada House on Trafalgar Square. Following the coronation celebration, Alexander returned to India, where he was made the honorary colonel of the 3rd Battalion 2nd Punjab Regiment, and then in October 1937 was promoted to the rank of major-general, making Alexander the youngest general in the British Army. He relinquished command of his brigade in January 1938, and in February returned to the United Kingdom to take command of the 1st Infantry Division. In June 1938 he was appointed a Companion of the Order of the Bath.
Second World War.
Following the outbreak of the Second World War in September 1939, Alexander brought the 1st Infantry Division to France, where, in late May 1940, he successfully led the division's withdrawal to Dunkirk. Shortly after Bernard Montgomery had been appointed to command II Corps, Alexander was, while still on the beachhead, placed in command of I Corps, and left the beach on the last destroyer on 3 June after ensuring that all British troops had been evacuated. In recognition of his services in the field from March to June 1940, Alexander was again mentioned in despatches.
After Dunkirk, Alexander returned to the UK and continued to command I Corps, now guarding the coasts of Yorkshire and Lincolnshire. He was promoted acting lieutenant-general in July 1940, and appointed the General Officer Commanding-in-Chief (GOC-in-C) of the Southern Command, which was responsible for the defence of south-west England. His rank of lieutenant-general was made permanent in December 1940.
On 1 January 1942 he was knighted and appointed a Knight Commander of the Order of the Bath, and in February, after the Japanese invasion of Burma, was sent to India to become GOC-in-C of British Forces in Burma as a full general. Alexander was unable to fulfil his orders to hold Rangoon, which was abandoned on 6–7 March. He took personal charge of some small local engagements, and was almost captured by the Japanese. Alexander increasingly left much of the tactical conduct of the campaign to his corps commander, Bill Slim, while he himself handled the more political aspects of relations with Joe Stillwell, the nominal commander of the Chinese forces. Alexander was promoted to Commander-in-Chief of Allied Land Forces in Burma, March 1942, and ordered Slim to abandon Mandalay and retreat to India.
By July 1942, the British and Indian forces in Burma had completed their fighting retreat back into India, and Alexander, having yet again been mentioned in dispatches for his Burma service, was recalled to the United Kingdom. He was at first selected to command the First Army, which was to take part in Operation Torch, the invasion of North Africa. However, following a visit in early August to Egypt by British prime minister Winston Churchill and the Chief of the Imperial General Staff, General Alan Brooke, Alexander flew to Cairo on 8 August to replace Claude Auchinleck as the Commander-in-Chief of Middle East Command, the post responsible for the overall conduct of the campaign in the desert of North Africa. At the same time, Lieutenant-General Bernard Montgomery replaced Auchinleck as the general officer commanding the Eighth Army. Alexander presided over Montgomery's victory at the Second Battle of El Alamein and the advance of the Eighth Army to Tripoli, for which Alexander was elevated to a Knight Grand Cross of the Order of the Bath, and, after the Anglo-American forces from Operation Torch and the Eighth Army converged in Tunisia in February 1943, they were brought under the unified command of a newly formed 18th Army Group headquarters, commanded by Alexander and reporting to Dwight D. Eisenhower, the Supreme Allied Commander in the Mediterranean at the Allied Forces Headquarters. Omar Bradley, an American general on the Tunisian Campaign, credited Alexander's patience and experience with helping an inexperienced United States "field command mature and eventually come of age." 
The Axis forces in Tunisia surrendered by May 1943, and Alexander's command became the 15th Army Group, which was, under Eisenhower, responsible for mounting in July the Allied invasion of Sicily, again seeing Alexander controlling two armies: Montgomery's Eighth Army and George S. Patton's Seventh United States Army. After Sicily, and in preparation for the allied invasion of Italy, the Seventh Army headquarters were replaced by those of the Fifth United States Army, led by Mark Clark.
When Eisenhower was appointed Supreme Allied Commander for the planned Normandy Landings he suggested that Alexander become ground forces commander, as he was popular with both British and US officers. Bradley, now the American commander of the 12th Army Group, remarked that he would have preferred to work with Alexander, rather than Montgomery, as he regarded the former as "a restrained, self-effacive, and punctilious soldier". Of the problems that subsequently surfaced with Montgomery's command of the British 21st Army Group, Bradley suspected they would not have occurred with Alexander in command. Brooke, however, applied pressure to keep Alexander in Italy, considering him unfit for the assignment in France. Thus, Alexander remained in command of the 15th Army Group, and, with the support of numerous allied commanders, controversially authorised the bombing of the historic abbey at Cassino, which resulted in little advance on the German Winter Line defences. It was not until the fourth attempt that the Winter Line was breached by the Allies, and Alexander's forces moved on to capture Rome in June 1944, thereby achieving one of the strategic goals of the Italian campaign. However, US Fifth Army forces at Anzio, under Clark's orders, failed to follow their original break-out plan that would have trapped the German forces escaping northwards in the aftermath of the Battle of Monte Cassino, instead favouring an early and highly publicised entry into Rome two days before the Allied landings in Normandy.
Alexander remained in command of 15th Army Group, as well as its successor, the Allied Armies in Italy, for most of the Italian Campaign, until December 1944, when he relinquished his command to Clark and took over as the Supreme Commander of the Allied Forces Headquarters, responsible for all military operations in the Mediterranean Theatre. Alexander was concurrently promoted to the rank of field marshal, though this was backdated to the fall of Rome on 4 June 1944, so that Alexander would once again be senior to Montgomery, who had himself been made a field marshal on 1 September 1944, after the end of the Battle of Normandy. Alexander then received the German surrender in Italy, on 29 April 1945. Further, as a reward for his leadership in North Africa and Italy, Alexander, along with a number of other prominent British Second World War military leaders, was elevated to the peerage on 1 March 1946 by King George VI; he was created Viscount Alexander of Tunis and Errigal in the County of Donegal.
Alan Brooke felt that Alexander needed an able chief of staff "to think for him", while Montgomery (Alexander's subordinate in Africa and Italy) claimed to think of Alexander as "incompetent" and success was attained in Tunisia only because Montgomery lent Brian Horrocks to organise the coup de grace. However, Harold Macmillan was impressed by Alexander's calm and style, conducting dinners in his mess like those at an Oxbridge high table, discussing architecture and the campaigns of Belisarius, rather than the current war. Macmillan thought Alexander's urbane manner and willingness to discuss and compromise were a sensible way to maintain inter-Allied cooperation, but Alexander's reserve was such that some thought him empty of strategic ideas and unable to make decisions. Graham and Bidwell wrote that Alexander's impenetrable reserve made it hard to judge whether or not he had any military ideas, but that he was "unable or unwilling" to assert his will over his army commanders, and that Mark Clark exploited this weakness.
Governor General of Canada.
With the cessation of hostilities, Alexander was under serious consideration for appointment to the post of Chief of the Imperial General Staff, the British army's most senior position beneath the sovereign, but he was invited by Canadian prime minister William Lyon Mackenzie King to be his recommendation to the King for the post of Governor General of Canada. Alexander thus chose to retire from the army and take up the new position, and, in anticipation of his viceregal posting, was on 26 January 1946 appointed Knight Grand Cross of the Order of Saint Michael and Saint George. It was then announced from the Office of the Prime Minister of Canada on 21 March 1946 that George VI had, by commission under the royal sign-manual and signet, approved the recommendation of his prime minister, Mackenzie King, to appoint Alexander as his representative. Alexander was subsequently sworn-in during a ceremony in the Senate chamber on 12 April that year.
Alexander took his duties as the viceroy quite seriously, feeling that, as governor general, he acted as a connection between Canadians and their king, and spent considerable time travelling Canada during his term; he eventually logged no less than 294,500 km (184,000 mi) during his five years as governor general. On these trips, he sought to engage with Canadians through various ceremonies and events; he was keenly interested in his role as Chief Scout of Canada, and, in preparation for his kicking of the opening ball in the 1946 Grey Cup final, practised frequently on the grounds of the royal and viceroyal residence, Rideau Hall. Also, in commemoration of Alexander being named the first non-aboriginal chief of the Kwakiutl tribe, he was given a totem pole on 13 July 1946; crafted by Mungo Martin, it remains on the grounds of Rideau Hall today. By the end of the year, Alexander was also distinguished with his induction as a Knight of the Order of the Garter.
In 1947, the King issued letters patent granting his Canadian governor general permission to exercise all those powers belonging to the monarch in respect of Canada and, at the Commonwealth Prime Ministers Conference of 1949, the decision was reached to use the term "member of the Commonwealth" instead of "Dominion" to refer to the non-British member states of the Commonwealth of Nations. That same year, Alexander oversaw the admission of the British crown colony of Newfoundland into Canadian Confederation and toured the new province that summer. Then, during a later visit to Alberta, the Governor General was admitted to the Blackfoot tribe as Chief Eagle Head. However, though the post-war period saw a boom in prosperity for Canada, the country was again at war by 1950, with Alexander, in his role as acting commander-in-chief, deploying to the Korean War soldiers, sailors, and airmen, whom he would visit prior to their departure for north-east Asia.
The Viscount travelled abroad on official trips—in 1947 visiting US president Harry S. Truman and in June 1948 Brazilian president Eurico Gaspar Dutra—as well as hosting a number of dignitaries. The visit of the Irish Taoiseach, John A. Costello, in 1948, caused Alexander some embarrassment when Costello chose the occasion to announce that Ireland was leaving the Commonwealth. Although the decision had been taken in principle some time before, the sudden announcement caused a diplomatic storm and Costello, to deflect criticism, claimed that he had been provoked into making the announcement by a series of diplomatic snubs by Alexander. In his memoirs Costello was to admit that Alexander's behaviour had in fact been perfectly civil and could have had no bearing on a decision which had already been made.
The Alexanders' relatively informal lifestyle at Rideau Hall was demonstrated when, during the Canadian tour of Princess Elizabeth and her husband, the Duke of Edinburgh, the Viscount and Viscountess hosted a square dance in the palace's ballroom. Alexander painted—creating a personal studio in the former dairy at Rideau Hall and mounting classes in art at the National Gallery of Canada—partook in a number of sports, including golf, ice hockey, and rugby, and enjoyed the outdoors—particularly during Ontario and Quebec's maple syrup harvest, himself overseeing the process on Rideau Hall's grounds. The Viscount was known to escape from official duties to partake in his most favourite pastime of fishing, once departing from the 1951 royal tour of Princess Elizabeth to take in a day's fishing at Griffin Island, in Georgian Bay, and granting a day off for students in the town of Drayton, Ontario, where his train briefly stopped.
Amongst Canadians, Alexander proved to be a popular viceroy, despite the calls for a Canadian-born governor general that had preceded his appointment. Not only did he have a much praised military reputation—he was considered to be the best military strategist since the Duke of Wellington—but he was also a charismatic figure with an easy ability to communicate with people. Others, however, did not fully approve of Alexander; editor Hugh Templin, from Fergus, Ontario, met with Alexander during Templin's time as a special correspondent with the Canadian Press during the Second World War, and he said of the encounter: "Lord Alexander impressed us considerably, if not too favourably. He was an aristocratic type, who didn't like newspaper men."
British Minister of Defence.
Alexander departed the office of Governor General of Canada in early 1952, after Churchill asked him to return to London to take the post of Minister of Defence in the British government. The ageing Churchill had found it increasingly difficult to cope with holding that portfolio concurrently with that of prime minister, although he still took many major decisions himself, leaving Alexander with little real power. Soon after, George VI died on the night of 5–6 February and Alexander, in respect of the King's mourning, departed quietly for the United Kingdom, leaving Chief Justice of Canada Thibaudeau Rinfret as administrator of the government in his place. After his return to the UK, Alexander was on 14 March 1952 elevated in the peerage by the new queen, becoming Earl Alexander of Tunis, Baron Rideau of Ottawa and Castle Derg. He was also appointed to the organising committee for the Queen's coronation and was charged with carrying the Sovereign's Orb in the state procession on that occasion in 1953.
Retirement.
The Earl served as the British defence minister until 1954, when he retired from politics and, in 1959, the Queen appointed Alexander to the Order of Merit. From 1960 to 1965, he served as Constable of the Tower of London.
Canada remained a favourite second home for the Alexanders and they returned frequently to visit family and friends until Alexander died on 16 June 1969 of a perforated aorta. His funeral was held on 24 June 1969, at St. George's Chapel, in Windsor Castle, and his remains are buried in the churchyard of Ridge, near Tyttenhanger, his family's Hertfordshire home.
Titles, styles, honours, and arms.
Titles.
 United Kingdom
 Canada
Unofficial.
 Alberta
Honours.
Ribbon bars of the Earl Alexander of Tunis
Appointments
Decorations
Medals
Awards
Foreign honours and decorations
Honorific eponyms.
Geographic locations
Schools

</doc>
<doc id="14454" url="http://en.wikipedia.org/wiki?curid=14454" title="Henry Moseley">
Henry Moseley

Henry Gwyn Jeffreys Moseley (23 November 1887 – 10 August 1915) was an English physicist. Moseley's outstanding contribution to the science of physics was the justification from physical laws of the previous empirical and chemical concept of the atomic number. This stemmed from his development of Moseley's law in X-ray spectra. Moseley's Law justified many concepts in chemistry by sorting the chemical elements of the periodic table of the elements in a logical order based on their physics.
Moseley's law advanced atomic physics by providing the first experimental evidence in favour of Niels Bohr's theory, aside from the hydrogen atom spectrum which the Bohr theory was designed to reproduce. That theory refined Ernest Rutherford's and Antonius van den Broek's model, which proposed that the atom contains in its nucleus a number of positive nuclear charges that is equal to its (atomic) number in the periodic table. This remains the accepted model today.
When World War I broke out in Western Europe, Moseley left his research work at the University of Oxford behind to volunteer for the Royal Engineers of the British Army. Moseley was assigned to the force of British Empire soldiers that invaded the region of Gallipoli, Turkey, in April 1915, as a telecommunications officer. Moseley was shot and killed during the Battle of Gallipoli on 10 August 1915, at the age of 27. Some prominent authors have speculated that Moseley could have been awarded the Nobel Prize in Physics in 1916, had he not died in the service of the British Army.
Biography.
Henry G. J. Moseley was born in Weymouth, Dorset, on the south coast of England in 1887. His father Henry Nottidge Moseley (1844–91), who died when Henry Moseley was quite young, was a biologist and also a professor of anatomy and physiology at the University of Oxford, who had been a member of the Challenger Expedition. Moseley's mother was Amabel Gwyn Jeffreys Moseley, who was the daughter of the Welsh biologist and conchologist John Gwyn Jeffreys.
Henry Moseley had been a very promising schoolboy at Summer Fields School (where one of the four 'leagues' is named after him), and he was awarded a King's scholarship to attend Eton College. In 1906 he won the chemistry and physics prizes at Eton. In 1906, Moseley entered Trinity College of the University of Oxford, where he earned his bachelor's degree. Immediately after graduation from Oxford in 1910, Moseley became a demonstrator in physics at the University of Manchester under the supervision of Sir Ernest Rutherford. During Moseley's first year at Manchester, he had a teaching load as a graduate teaching assistant, but following that first year, he was reassigned from his teaching duties to work as a graduate research assistant. He declined a fellowship offered by Rutherford, preferring to move back to Oxford, in November 1913, where he was given laboratory facilities but no support.
Contribution to physics and chemistry.
Experimenting with the energy of β-particles in 1912, Moseley showed that high potentials were attainable from a radioactive source of radium, thereby inventing the first atomic battery, though he was unable to produce the 1MeV necessary to stop the particles.
In 1913, Moseley observed and measured the X-ray spectra of various chemical elements (mostly metals) that were found by the method of diffraction through crystals. This was a pioneering use of the method of X-ray spectroscopy in physics, using Bragg's diffraction law to determine the X-ray wavelengths. Moseley discovered a systematic mathematical relationship between the wavelengths of the X-rays produced and the atomic numbers of the metals that were used as the targets in X-ray tubes. This has become known as Moseley's law.
Before Moseley's discovery, the atomic numbers (or elemental number) of an element had been thought of as a semi-arbitrary sequential number, based on the sequence of atomic masses, but modified somewhat where chemists found this to be desirable, such as by the great Russian chemist, Dmitri Ivanovich Mendeleev. In his invention of the Periodic Table of the Elements, Mendeleev had interchanged the orders of a few pairs of elements in order to put them in more appropriate places in this table of the elements. For example, the metals cobalt and nickel had been assigned the atomic numbers 27 and 28, respectively, based on their known chemical and physical properties, even though they have nearly the same atomic masses. In fact, the atomic mass of cobalt is slightly larger than that of nickel, which would have placed them in backwards order if they had been placed in the Periodic Table blindly according to atomic mass. Moseley's experiments in X-ray spectroscopy showed directly from their physics that cobalt and nickel have the different atomic numbers, 27 and 28, and that they are placed in the Periodic Table correctly by Moseley's objective measurements of their atomic numbers. Hence, Moseley's discovery demonstrated that the atomic numbers of elements are not just rather arbitrary numbers based on chemistry and the intuition of chemists, but rather, they have a firm experimental basis from the physics of their X-ray spectra.
In addition, Moseley showed that there were gaps in the atomic number sequence at numbers 43, 61, 72, and 75. These spaces are now known, respectively, to be the places of the radioactive synthetic elements technetium and promethium, and also the last two quite rare naturally-occurring stable elements hafnium (discovered 1923) and rhenium (discovered 1925). Nothing about these four elements was known of in Moseley's lifetime, not even their very existence. Based on the intuition of a very experienced chemist, Dmitri Mendeleev had predicted the existence of a missing element in the Periodic Table, which was later found to be filled by technetium, and Bohuslav Brauner had predicted the existence of another missing element in this Table, which was later found to be filled by promethium. Henry Moseley's experiments confirmed these predictions, by showing exactly what the missing atomic numbers were, 43 and 61. In addition, Moseley predicted the two more undiscovered elements, those with the atomic numbers 72 and 75, and gave very strong evidence that there were no other gaps in the Periodic Table between the elements aluminium (atomic number 13) and gold (atomic number 79).
This latter question about the possibility of more undiscovered ("missing") elements had been a standing problem among the chemists of the world, particularly given the existence of the large family of the lanthanide series of rare earth elements. Moseley was able to demonstrate that these lanthanide elements, i.e. lanthanum through lutetium, must have exactly 15 members – no more and no less. The number of elements in the lanthanides had been a question that was very far from being settled by the chemists of the early 20th Century. They could not yet produce pure samples of all the rare-earth elements, even in the form of their salts, and in some cases they were unable to distinguish between mixtures of two very similar (adjacent) rare-earth elements from the nearby pure metals in the Periodic Table. For example, there was a so-called "element" that was even given the chemical name of "didymium". "Didymium" was found some years later to be simply a mixture of two genuine rare-earth elements, and these were given the names neodymium and praseodymium, meaning "new twin" and "green twin". Also, the method of separating the rare-earth elements by the method of ion exchange had not been invented yet in Moseley's time.
Moseley's method in early X-ray spectroscopy was able to sort out the above chemical problems promptly, some of which had occupied chemists for a number of years. Moseley also predicted the existence of element 61, a lanthanide whose existence was previously unsuspected. Quite a few years later, this element 61 was created artificially in nuclear reactors and was named promethium.
Death and aftermath.
Sometime in the first half of 1914, Moseley resigned from his position at Manchester, with plans to return to Oxford and continue his physics research there. However, World War I broke out in August 1914, and Moseley turned down this job offer to instead enlist with the Royal Engineers of the British Army. Moseley served as a technical officer in communications during the Battle of Gallipoli, in Turkey, beginning in April 1915, where he was killed in action on 10 August 1915. Moseley was shot in the head by a Turkish sniper while in the act of telephoning a military order. Isaac Asimov once wrote, "In view of what he [Moseley] might still have accomplished … his death might well have been the most costly single death of the War to mankind generally." Because of Moseley's death in World War I, the British government instituted a policy of no longer allowing its prominent and promising scientists to enlist for combat duty in the armed forces of the Crown.
Isaac Asimov also speculated that, in the event that he had not been killed while in the service of the British Empire, Moseley might very well have been awarded the 1916 Nobel Prize in Physics, which, along with the prize for chemistry, was not awarded to anyone that year. Additional credence is given to this idea by noting the recipients of the Nobel Prize in Physics in the two preceding years, 1914 and 1915, and in the following year, 1917. In 1914, Max von Laue of Germany won the Nobel Prize in Physics for his discovery of the diffraction of X-rays by crystals, which was a crucial step towards the invention of X-ray spectroscopy. Then, in 1915, William Henry Bragg and William Lawrence Bragg, a British father-son pair, shared this Nobel Prize for their discoveries in the reverse problem — determining the structure of crystals using X-rays (Robert Charles Bragg, William Henry Bragg's other son, had also been killed at Gallipoli, on 2 September 1915). Next, Moseley used the diffraction of X-rays by known crystals in measuring the X-ray spectra of metals. This was the first use of X-ray spectroscopy and also one more step towards the creation of X-ray crystallography. In addition, Moseley's methods and analyses substantially supported the concept of atomic number, placing it on a firm, physics-based foundation. Moreover, Charles Barkla of Great Britain was awarded the Nobel Prize in 1917 for his experimental work in using X-ray spectroscopy in discovering the characteristic X-ray frequencies emitted by the various elements, especially the metals. Moseley's discoveries were thus of the same scope as those of his peers, and in addition, Moseley made the larger step of demonstrating the actual foundation of atomic numbers. Ernest Rutherford commented that Moseley's work, "Allowed him to complete during two years at the outset of his career a set of researches that would surely have brought him a Nobel prize".
Only twenty-seven years old at the time of his death, Moseley could, in the opinion of some scientists, have contributed much to the knowledge of atomic structure had he survived. As Niels Bohr said in 1962, "You see actually the Rutherford work [the nuclear atom] was not taken seriously. We cannot understand today, but it was not taken seriously at all. There was no mention of it any place. The great change came from Moseley."
Memorial plaques to Moseley were installed at Manchester and Eton, and a Royal Society scholarship, established by his will, had as its second recipient the physicist P. M. S. Blackett, who later became president of the Society.
Moseley's contribution to understanding of the atom.
Before Moseley and his law, atomic numbers had been thought of as a semi-arbitrary ordering number, vaguely increasing with atomic weight but not strictly defined by it. Moseley's discovery showed that atomic numbers were not arbitrarily assigned, but rather, they have a strong physical basis. Moseley redefined the idea of atomic numbers from its previous status as an "ad hoc" numerical tag to help sorting the elements, in particular in the Periodic Table, into a real and objective whole-number quantity that was experimentally measurable. Furthermore, as noted by Bohr, Moseley's law provided a reasonably complete experimental set of data that supported the (new from 1911) conception by Ernest Rutherford and Antonius van den Broek of the atom, with a positively-charged nucleus surrounded by negatively-charged electrons in which the atomic number is understood to be the exact physical number of positive charges (later discovered and called protons) in the central atomic nuclei of the elements. Moseley mentioned the two scientists above in his research paper, but he did not actually mention Bohr, who was rather new on the scene then. Simple modification of Rydberg's and Bohr's formulas were found to give theoretical justification for Moseley's empirically-derived law for determining atomic numbers.
The use of X-ray spectrometer.
X-ray spectrometers are the foundation-stones of X-ray crystallography. The X-ray spectrometers as Moseley knew them worked as follows. A glass-bulb electron tube was used, similar to that held by Moseley in the photo at the top of this article. Inside the evacuated tube, electrons were fired at a metallic substance (i.e. a sample of pure element in Moseley's work), causing the ionization of electrons from the inner electron shells of the element. The rebound of electrons into these holes in the inner shells next causes the emission of X-rays photons that were led out of the tube in a semi-beam, through an opening in the external X-ray shielding. These are next diffracted by a standardized salt crystal, with angular results read out as photographic lines by the exposure of an X-ray film fixed at the outside the vacuum tube at a known distance. Application of Bragg's law (after some initial guesswork of the mean distances between atoms in the metallic crystal, based on its density) next allowed the wavelength of the emitted -rays to be calculated.
Moseley participated in the design and development of early X-ray spectrometry equipment, learning some techniques from William Henry Bragg and William Lawrence Bragg at the University of Leeds, and developing others himself. Many of the techniques of X-ray spectroscopy were inspired by the methods that are used with visible light spectroscopes and spectrograms, by substituting crystals, ionization chambers, and photographic plates for their analogs in light spectroscopy. In some cases, Moseley found it necessary to modify his equipment to detect particularly soft [lower frequency] X-rays that could not penetrate either air or paper, by working with his instruments in a vacuum chamber.

</doc>
<doc id="14457" url="http://en.wikipedia.org/wiki?curid=14457" title="Prince Harry">
Prince Harry

Prince Henry of Wales (Henry Charles Albert David; born 15 September 1984), known as Prince Harry, is the younger son of Charles, Prince of Wales, and Diana, Princess of Wales. His paternal grandparents are Queen Elizabeth II and Prince Philip, Duke of Edinburgh. At the time of his birth, he was third in the line of succession to succeed his grandmother; he is currently fifth in line after the birth of his niece Princess Charlotte of Cambridge in 2015.
After an education at schools in the United Kingdom and spending parts of his gap year in Australia and Lesotho, Harry chose a military career, undergoing officer training at Royal Military Academy Sandhurst. He was commissioned as a second lieutenant into the Blues and Royals of the Household Cavalry Regiment, serving temporarily with his brother, and completed his training as a troop leader. In 2007–2008 he served for 77 days in Helmand, Afghanistan but he was pulled out following publication of his presence there by an Australian magazine. He returned to Afghanistan for a 20-week deployment in 2012–2013 with the Army Air Corps.
Early life.
Harry was born at St Mary's Hospital in Paddington, London, on 15 September 1984 at 4.20 pm. He weighed 6 lb. He was baptised on 21 December 1984 at St George's Chapel at Windsor Castle by the Archbishop of Canterbury, Robert Runcie. His godparents were the Duke of York (his paternal uncle), Lady Sarah Armstrong-Jones (his paternal cousin once removed), Lady Celia Vestey (née Knight), Carolyn Bartholomew (née Pride), Bryan Organ and Gerald Ward (former officer in the Household Cavalry).
Diana wanted Harry and his older brother William to have a broader range of experiences than previous royal children and took them to venues that ranged from Disney World and McDonald's to AIDS clinics and shelters for the homeless. Harry began to accompany his parents on official visits at an early age; his first overseas royal tour was with his parents to Italy in 1985.
Harry's parents divorced in 1996, and his mother died following a car accident in Paris the following year. Harry and William were staying with their father at Balmoral at the time, and the Prince of Wales told his sons about their mother's death. At his mother's funeral, Harry, then 12, accompanied his father, brother, paternal grandfather, and maternal uncle, Earl Spencer in walking behind the funeral cortège from Kensington Palace to Westminster Abbey.
Education.
Like his father and brother, Harry was educated at independent schools. He started at Jane Mynors' nursery school and the pre-preparatory Wetherby School, both in London. Following this, he attended Ludgrove School, and, after passing the entrance exams, was admitted to Eton College, where he studied geography, art history and art at A-Level. The decision to place Harry at Eton went against the Windsor family tradition of sending children to Gordonstoun (Harry's grandfather, father, two uncles, and two cousins all attended); it did make Harry follow in the Spencer family footsteps, as both Diana's father and brother had attended Eton.
In June 2003, Harry completed his education at Eton with two A-Levels (achieving a grade B in art and D in geography) having decided to drop history of art after AS level. He excelled in sports, particularly polo and rugby union. Passing two A-levels, Harry was eligible to apply for an officer commission in the British Army.
After school, Harry took a gap year, during which he spent time in Australia, working (as his father had done in his youth) on a cattle station and participating in the Young England vs Young Australia Polo Test Match. He also travelled to Lesotho, where he worked with orphaned children and produced the documentary film "The Forgotten Kingdom".
Military career.
Sandhurst, Blues and Royals, and First Tour of Duty to Afghanistan.
Harry entered the Royal Military Academy Sandhurst on 8 May 2005, where he was known as Officer Cadet Wales, and joined the Alamein Company. Within a year, in April 2006, Harry completed his officer training and was commissioned as a Cornet (second lieutenant) in the Blues and Royals, a regiment of the Household Cavalry in the British Army. He was given the service number 564673. On 13 April 2008, when he reached two years' seniority, Harry was promoted to lieutenant.
The British Ministry of Defence and Clarence House made a joint announcement on 22 February 2007 that Harry would be deployed with his regiment to Iraq, as part of the 1st Mechanised Brigade of the 3rd Mechanised Division – a move supported by Harry, who had stated that he would leave the army if he was told to remain in safety while his regiment went to war; he said: "There's no way I'm going to put myself through Sandhurst and then sit on my arse back home while my boys are out fighting for their country." The head of the British army at the time, General Sir Richard Dannatt, first said on 30 April 2007 that he had personally decided that Harry would serve with his unit in Iraq, and Harry was scheduled for deployment in May or June 2007, to patrol the Maysan Province. By 16 May, however, Dannatt announced that Prince Harry would not serve in Iraq; concerns included Harry being a high-value target (as several threats by various groups had already been made against him) and the dangers the soldiers around him would face should any attempt be made on Harry's life or capture. Clarence House made public Harry's disappointment with the decision, though he said he would abide by it.
It was reported in early June 2007 that Harry had arrived in Canada to train alongside soldiers of the Canadian Forces and British Army, at CFB Suffield, near Medicine Hat, Alberta. It was said that this was in preparation for a tour of duty in Afghanistan, where Canadian and British forces were participating in the NATO-led Afghan War; rumours that were confirmed in February the following year, when the British Ministry of Defence revealed that Harry had secretly been deployed as a Forward Air Controller to Helmand Province in Afghanistan. The revelation came after the media – notably, the German newspaper "Bild" and Australian magazine "New Idea" – breached the blackout placed over the information by the Canadian and British authorities. It was later reported that, while in Afghanistan, Harry had helped Gurkha troops repel an attack from Taliban insurgents, and performed patrol duty in hostile areas. His tour made Harry the first member of the Royal Family to serve in a war zone since his uncle, Prince Andrew, flew helicopters during the Falklands War. For his service, Harry was presented with an Operational Service Medal for Afghanistan by his aunt, Princess Anne, at the Combermere Barracks in May 2008.
Army Air Corps and Second Tour of Duty to Afghanistan.
In October 2008, it was announced that Harry was to follow his brother, father and uncle in learning to fly military helicopters. After passing the initial aptitude test, he was to undertake a month-long course; if he passed that, he would begin full flight training in early 2009. Harry had to pass his flying assessment at the Army Air Corps Base (AAC), Middle Wallop, the result of which determined if he would pass on to train as a pilot of the Apache, Lynx, or Gazelle helicopter. Having reached the requisite standard, Harry attended the Defence Helicopter Flying School at RAF Shawbury, where he joined brother William.
Harry was presented with his flying brevet (wings) by his father on 7 May 2010 at a ceremony at the Army Air Corps Base (AAC), Middle Wallop. Harry had let it be known that he intended to fly Apache attack helicopters if he was successful in passing the rigorous Apache training course, after which time it could be possible for him to see active military service once again on the frontline in Afghanistan. During the ceremony, he switched his Blues and Royals' Officer's cap for that of the Army Air Corps' sky blue beret with a Blues and Royals badge.
On 10 March 2011, it was revealed that Harry had passed his Apache flying test and he was awarded his Apache Flying Badge on 14 April 2011. There was speculation that he would return to Afghanistan before the withdrawal in 2015. On 16 April 2011, it was announced that Harry had been promoted to captain.
In June 2011, Clarence House announced that on completion of his training conversion course to use Apache helicopters in the war arena, Harry would be available for deployment, including in current operations in Afghanistan, as an Apache helicopter pilot. The final decision will ultimately rest with the Ministry of Defence's senior commanders, including principally the Chief of the Defence Staff in consultation with the wishes of Harry, the Prince of Wales and the Queen. In October, Harry was transferred to a US military base in California to complete his helicopter gunship training. This final phase will include live-fire training and "environmental and judgment training" at naval and air force facilities in California and Arizona. The majority of those completing the two-month Apache training are deployed to the front lines in Afghanistan. In the same month, it was reported that Harry was said to be a natural pilot who was top of his class in the extensive training he had undertaken at the Naval Air Facility, El Centro, California. On November 2011, Harry returned to England. He went to Wattisham Flying Station in Suffolk, in the east of England, to complete his training to fly Apache helicopters.
On 7 September 2012, he arrived at Camp Bastion in southern Afghanistan as part of the 100-strong 662 Squadron, 3 Regiment, Army Air Corps, to begin a four-month combat tour as a co-pilot and gunner for an Apache helicopter. This was considered a particular honour as most pilots are required to sit in the "back seat" before being promoted to gunner. On 10 September, within days of arriving in Afghanistan, it was reported that the Taliban threatened his life. Taliban spokesman Zabiullah Mujahid spoke to Reuters and was quoted as saying; "We are using all our strength to get rid of him, either by killing or kidnapping," and "We have informed our commanders in Helmand to do whatever they can to eliminate him."
It was announced on 21 January 2013 that Harry was returning from a 20-week deployment in Afghanistan, where he served as an Apache co-pilot/gunner.
On 8 July 2013, the Ministry of Defence announced that Harry had successfully qualified as an Apache aircraft commander.
HQ London District and Invictus Games.
On 17 January 2014, the Ministry of Defence announced that Harry had completed his attachment to 3 Regiment Army Air Corps and would take up a staff officer role at the position of SO3 (Defence Engagement) in HQ London District. His responsibilities would include helping to co-ordinate significant projects and commemorative events involving the Army in London. He will be based at Horse Guards in central London.
On 6 March 2014, Prince Harry launched Invictus Games, a Paralympic-style sporting event for injured servicemen and women, which is to be held on 10–14 September 2014. Prince Harry met British hopefuls for the Invictus Games at Tedworth House for the start of the selection process Invictus Games on 29 April 2014. On 15 May 2014, Harry attended a ticket sale launch for Invictus Games at BT Tower, where he made a public tweet on the Invictus Games official Twitter account as the President of Invictus Games. In order to promote the Games, Prince Harry was interviewed by BBC Radio 2's Chris Evans along with two Invictus Games hopefuls, where Prince Harry said: "This (Invictus Games) is basically my full-time job at the moment, making sure that we pull this off." The show aired on 31 July 2014. Harry later wrote an article in "The Sunday Times" about his experiences at Afghanistan, and how they had inspired him to help injured personnel, and how after the trip to the Warrior Games, he had vowed to create the Invictus Games. Harry and officials attended the British Armed Forces Team announcement for Invictus Games at Potters Field Park in August 2014, and as President of the Invictus Games, Harry attended all events related to the Games from 8 to 14 September 2014.
In January 2015 it was reported that Harry would take a new role in supporting wounded service personnel by working alongside members of the London District's Personal Recovery Unit for the MOD's Defence Recovery Capability scheme to ensure that wounded personnel have adequate recovery plans. The scheme established in partnership with Help for Heroes and the Royal British Legion, the palace confirmed weeks later.
In late January 2015, Prince Harry visited The Battle Back Centre, which is set up by the Royal British Legion, and Fisher House UK at the Queen Elizabeth Hospital Birmingham, which was created in the partnership between Help for Heroes, the Fisher House Foundation and the Queen Elizabeth Hospital Birmingham (QEHB) Charity. Fisher House Foundation is one of the Invictus Games' sponsors.
In Feb. and March 2015, Prince Harry visited Phoenix House in Catterick Garrison, North Yorkshire, a recovery centre run by Help for Heroes, and Merville Barracks in Colchester, where Chavasse VC House Personnel Recovery Centre is located, run by Help for Heroes in partnership with the Ministry of Defence and Royal British Legion.
On 17 March 2015, Kensington Palace announced that Prince Harry will be leaving the Armed Forces in June. Before then, Harry will spend four weeks throughout April and May at army barracks in Darwin, Perth and Sydney whilst seconded to the Australian Defence Force (ADF). After leaving the Army, while considering his future, he will return to work with the Ministry of Defence, supporting Case Officers in the Ministry of Defence's Recovery Capability Programme, working with both those who are administering and receiving physical and mental care within the London District area in a voluntary capacity.
On 6 April 2015, Prince Harry report to duty to Australia's Chief of the Defence Force, Air Chief Marshal Mark Binskin at the Royal Military College, Duntroon in Canberra, Australia. He flew to Darwin later that day, start his month long secondment to ADF's 1st Brigade. He will also include detachments to NORFORCE as well as to an aviation unit. 
Royal duties.
At the age of 21, Harry was appointed as a Counsellor of State and began his duties in that capacity when the Queen was attending the 2005 Commonwealth Heads of Government Meeting in Malta. The following year, Harry was in Lesotho to visit again Mants'ase Children's Home near Mohale's Hoek, which he first toured in 2004 and, along with Prince Seeiso of Lesotho, launched Sentebale: The Princes' Fund for Lesotho, a charity to aid children orphaned by HIV/AIDS. He has granted his patronage to organisations including WellChild, Dolen Cymru, and MapAction. To aid Sentebale, and the Diana, Princess of Wales Memorial Fund and Centrepoint, Harry and his brother organised the Concert for Diana at Wembley Stadium, on 1 July 2007.
Sport has been a way that Harry has helped charities and other organisations, such as training as a Rugby Development Officer for the Rugby Football Union in 2004 and coaching students in schools to encourage them to learn the sport. He has participated in polo matches, like his brother and father, to raise money for charitable causes.
On 6 January 2009, the Queen granted Harry and William their own royal household. It has three main staff members, supported by a "small" team. Sir David Manning, the former British ambassador to Washington, is a part-time adviser to the princes. Previously, William and Harry's affairs had been handled by the office of their father at Clarence House in central London. The new household released a statement, complete with their own cyphers at the top, announcing that they have established their own office at nearby St James's Palace to look after their public, military and charitable activities. Harry's cypher is similar to his brother's, but with an "H" in a shade of blue similar to that used by his mother. In September 2009, William and Harry set up The Foundation of Prince William and Prince Harry to enable the princes to take forward their charitable ambitions. The foundation is the culmination of the princes' charitable lives so far.
In March 2012, Harry led an official visit to Belize as part of the Queen's Diamond Jubilee celebrations. He continued to the Bahamas and Jamaica, where the Prime Minister, Portia Simpson-Miller, is considering severing ties between Jamaica and the constitutional monarchy. He next visited Brazil to attend the GREAT Campaign, as an ambassador of the 2012 Olympics to the 2016 Rio Olympics. On 12 August 2012, Harry represented the Queen at the Closing Ceremony of the London 2012 Olympic Games.
From 9 to 15 May 2013, Harry was on an official visit to the United States. The tour promoted the rehabilitation of injured American and UK troops, publicised his own charities and supported British interests. It included engagements in Washington DC, Denver, New York, New Jersey and Connecticut. He watched the opening ceremony of the Warrior Games, in Colorado Springs, where injured servicemen and women competed, and met survivors of Hurricane Sandy in New Jersey.
In August 2013, Prince Harry visited Angola to see Halo Turst's work there as Patron of the HALO Trust's 25th Anniversary Appeal.
In October 2013, Prince Harry visited Australia for his first official visit to the country. Prince Harry attended the International Fleet Review at Sydney Harbour. He also paid a visit to the Australian SAS HQ in Perth. On his way back to UK, he attended a charity event for Sentebale at Dubai.
In May 2014, Prince Harry visited Estonia and Italy. In Estonia he visited Freedom Square in the capital Tallinn to honour those who paid the ultimate sacrifice for their nation, and attended a reception at the Estonian Parliament, and attended Nato military exercise there. In Italy, Prince Harry attended commemorate the 70th anniversary of Monte Cassino battles for the Polish, Commonwealth and British troops. Prince Harry also revealed the British Pavilion at Expo Milano 2015 in Rome at the MAXXI Museum.
In June 2014, Prince Harry visited Brazil and Chile.
To mark the World War I centenary, on 4 August 2014, Prince Harry attended the unveiling of the Folkestone Memorial Arch in Kent. Subsequently he flew to Belgium, where he met families of WWI soldiers in a reception before reading a letter from a fallen soldier in a twilight service at St Symphorien Cemetery in Mons. Prince Harry and The Duke and Duchess of Cambridge planted poppies at an installation by artist Paul Cummins, titled "Blood Swept Lands and Seas of Red" at the Tower of London for commemorations of the war on 5 August.
On 6 November 2014, Prince Harry opened the Field of Remembrance at Westminster Abbey, the task usually held by The Duke of Edinburgh. On 7 November 2013 Prince Harry accompanied The Duke of Edinburgh to open the Field of Remembrance at Westminster Abbey as Harry's first visit to the event.
On 9 November 2014, Prince Harry attended Remembrance Sunday Service at Kandahar Air Base, Afghanistan, representing HM The Queen.
From 18 to 20 November 2014, Prince Harry made an official visit to Oman. His original plan was to attended the National Day Parade, but due to the illness of the Sultan, the parade is cancelled, hence the visited became semi-official. During there, Prince Harry visited the British Embassy, Nizwa Fort, Muttrah souk, and Sultan Qaboos Grand Mosque. On 20, November, Prince Harry played Sentebale Polo Cup in Abu Dhabi in aid for his charity Sentebale.
In December 2014, Prince Harry visited Lesotho with Prince Seeiso of Lesotho to see the work of their charity Sentebale.
On 13 March 2015, the British Royal Family attended the Afghanistan commemoration service at St Paul's Cathedral marked the end of the Afghanistan campaign.
Before report to duty to the Australian Defence Force (ADF), Prince Harry visited Australian War Memorial in Canberra on 6 April 2015.
Prince Harry is patron of the following organisations:
As part of the Walking With The Wounded – South Pole Allied Challenge 2013, Harry became the first member of the royal family to reach the South Pole.
Personal life.
Harry enjoys playing many sporting activities, playing competitive polo, skiing, and motocross. Prince Harry is a supporter of Arsenal Football Club. Harry is also a keen Rugby Union fan, and supported England's bid to host the 2015 Rugby World Cup.
Harry earned a reputation in his youth for being rebellious, leading the tabloid press to label him as a "wild child." He was found at age 17 smoking cannabis and partaking in under-age drinking with his friends, clashing physically with paparazzi outside nightclubs, and was photographed at Highgrove House at a "Colonial and Native" themed costume party wearing a Nazi German Afrika Korps uniform with a swastika armband. He later issued a public statement apologising for his behaviour.
In January 2009, the British tabloid "News of the World" revealed a video made by Harry three years earlier in which he referred to a Pakistani fellow officer cadet as "our little Paki friend" and later called a soldier wearing a cloth on his head a "raghead". These terms were described by David Cameron as "unacceptable", and by "The Daily Telegraph" as "racist", and a British Muslim youth organisation called Harry a "thug". Clarence House immediately issued an apology from Harry, who stated that no malice was intended in his remarks. A former British MP and Royal Marine, Rod Richards, said that such nicknames were common amongst military comrades, stating "in the Armed Forces people often used to call me Taffy. Others were called Yankie, Oz or Kiwi or whatever. I consider Paki as an abbreviation for Pakistani. I don't think on this occasion it was intended to be offensive."
While on holiday in Las Vegas in August 2012, Harry and an unknown young woman were photographed naked in a Wynn Las Vegas hotel room, reportedly during a game of strip billiards. The pictures were leaked by American celebrity website TMZ on 21 August, being reported worldwide by mainstream media on 22 August. The photographs were shown by the American media, but British media were reluctant to publish them – royal aides suggested that Clarence House may contact the Press Complaints Commission (PCC) if the pictures are used by British publications. St James's Palace confirmed that Harry was in the photographs, said that he was essentially a victim of sexting in a private moment, and contacted the Press Complaints Commission upon hearing that a number of British newspapers were considering publishing the photographs. On 24 August "The Sun" newspaper published photographs.
Polls conducted in the United Kingdom in November 2012 showed Harry to be the third most popular member of the Royal Family, after William and the Queen.
There are persistent rumours that Harry is the son of James Hewitt, with whom his mother had an affair. In response, Hewitt and Diana's police bodyguard have stated that Harry was born before the affair began.
Relationships.
Chelsy Davy, the daughter of a South African businessman Charles Davy, was referred to as Harry's girlfriend in an interview conducted for his 21st birthday, and Harry said he "would love to tell everyone how amazing she is but once I start talking about that, I have left myself open...There is truth and there is lies and unfortunately I cannot get the truth across." In early 2009, it was reported in the media that the pair had parted ways after knowing each other for five years. During the relationship, Davy was present as Harry received his Operational Service Medal for Afghanistan and also attended Prince Harry's graduation ceremony when he received his flying wings from his father.
Harry was introduced to Cressida Bonas, granddaughter of Edward Curzon, 6th Earl Howe, by his cousin Princess Eugenie in May 2012. On 30 April 2014 it was announced that the couple had parted amicably.
Titles, styles, honours and arms.
Titles and styles.
Harry's full style and title is "His Royal Highness Prince Henry Charles Albert David of Wales", but he is informally known as Prince Harry. He uses the name of the area over which his father holds title, i.e., "Wales", as a territorial suffix in lieu of surname. Past precedent is that such surnames are dropped from usage in adulthood, after which either title alone or Mountbatten-Windsor is used when necessary. Harry continues to use Wales as his surname for military purposes and is known as Captain Harry Wales in such contexts. Traditionally, sons of the reigning monarch and of the Prince of Wales receive a dukedom immediately prior to marriage, the most recent being Prince William, who received the dukedom of Cambridge.
Honours.
"See also List of honours of the British Royal Family by country"
Humanitarian awards.
Harry has twice had his charitable efforts recognised by the international community. In December 2010, the German charity "Ein Herz für Kinder" ("Heart for Children") awarded him the Golden Heart Award, in recognition of his "charitable and humanitarian efforts".
Ancestry.
Harry is a male line descendant of Elimar I, Count of Oldenburg and a member of the House of Oldenburg, one of Europe's oldest royal houses, and the cadet branch known as the House of Glücksburg, founded by his paternal ancestor Friedrich Wilhelm, Duke of Schleswig-Holstein-Sonderburg-Glücksburg. His paternal grandmother issued letters patent on 8 February 1960 declaring Harry's future father to be a member of the United Kingdom's reigning House of Windsor and a bearer of its name. Their male line House of Oldenburg ancestors include five Danish kings — Christian I, Frederick I, Christian III, Christian IX – King George I of Greece, 11 counts of Oldenburg, two dukes of Schleswig-Holstein-Sonderburg, five dukes of Schleswig-Holstein-Sonderburg-Beck and one duke of Schleswig-Holstein-Sonderburg-Glücksburg.
Among his other recent ancestors on his father's side are members of the House of Saxe-Coburg and Gotha, the House of Battenberg, the main line of the House of Hesse-Darmstadt, the House of Hesse-Kassel and the House of Hohenzollern. Among his distant ancestors are Henry IV and James II and VII. Through his father's royal family, Harry is of German, English and Scottish descent, and through his mother's family, the Earl Spencer and the Baron Fermoy families, of English descent and of remote German, Irish, Scottish and British-American descent.
External links.
Listen to this article ()
This audio file was created from a revision of the "Prince Harry" article dated 12 July 2014, and does not reflect subsequent edits to the article. ()
More spoken articles

</doc>
<doc id="14458" url="http://en.wikipedia.org/wiki?curid=14458" title="Hail">
Hail

Hail is a form of solid precipitation. It is distinct from sleet, though the two are often confused for one another. It consists of balls or irregular lumps of ice, each of which is called a hailstone. Sleet falls generally in cold weather while hail growth is greatly inhibited at cold temperatures. 
Unlike graupel, which is made of rime, and ice pellets, which are smaller and translucent, hailstones consist mostly of water ice and measure between 5 mm and 15 cm in diameter. The METAR reporting code for hail 5 mm or greater is GR, while smaller hailstones and graupel are coded GS. 
Hail is possible within most thunderstorms as it is produced by cumulonimbi, and within 2 nmi of the parent storm. Hail formation requires environments of strong, upward motion of air with the parent thunderstorm (similar to tornadoes) and lowered heights of the freezing level. In the mid-latitudes, hail forms near the interiors of continents, while in the tropics, it tends to be confined to high elevations.
There are methods available to detect hail-producing thunderstorms using weather satellites and weather radar imagery. Hailstones generally fall at higher speeds as they grow in size, though complicating factors such as melting, friction with air, wind, and interaction with rain and other hailstones can slow their descent through Earth's atmosphere. Severe weather warnings are issued for hail when the stones reach a damaging size, as it can cause serious damage to human-made structures and, most commonly, farmers' crops.
Definition.
Any thunderstorm which produces hail that reaches the ground is known as a hailstorm. Hail has a diameter of 5 mm or more. Hailstones can grow to 15 cm and weigh more than 0.5 kg.
Unlike ice pellets, hailstones are layered and can be irregular and clumped together. Hail is composed of transparent ice or alternating layers of transparent and translucent ice at least 1 mm thick, which are deposited upon the hailstone as it travels through the cloud, suspended aloft by air with strong upward motion until its weight overcomes the updraft and falls to the ground. Although the diameter of hail is varied, in the United States, the average observation of damaging hail is between 2.5 cm (1 in) and golf ball-sized (1.75 in).
Stones larger than 2 cm (0.80 in) are usually considered large enough to cause damage. The Meteorological Service of Canada will issue severe thunderstorm warnings when hail that size or above is expected. The US National Weather Service has a 2.5 cm (1 in) or greater in diameter threshold, effective January 2010, an increase over the previous threshold of ¾-inch hail. Other countries will have different thresholds according local sensitivity to hail; for instance grape growing areas could be adversely impacted by smaller hailstones. Hailstones can be very large or very small, depending on how strong the updraft is: weaker hailstorms produce smaller hailstones than stronger hailstorms (such as supercells).
Formation.
Hail forms in strong thunderstorm clouds, particularly those with intense updrafts, high liquid water content, great vertical extent, large water droplets, and where a good portion of the cloud layer is below freezing 0 C. These types of strong updrafts can also indicate the presence of a tornado. 
The growth rate is maximized where air is near a temperature of -13 C.
Layer nature of the hailstones.
Like other precipitation in cumulonimbus clouds hail begins as water droplets. As the droplets rise and the temperature goes below freezing, they become supercooled water and will freeze on contact with condensation nuclei. A cross-section through a large hailstone shows an onion-like structure. This means the hailstone is made of thick and translucent layers, alternating with layers that are thin, white and opaque. Former theory suggested that hailstones were subjected to multiple descents and ascents, falling into a zone of humidity and refreezing as they were uplifted. This up and down motion was thought to be responsible for the successive layers of the hailstone. New research, based on theory as well as field study, has shown this is not necessarily true.
The storm's updraft, with upwardly directed wind speeds as high as 110 mph, blows the forming hailstones up the cloud. As the hailstone ascends it passes into areas of the cloud where the concentration of humidity and supercooled water droplets varies. The hailstone’s growth rate changes depending on the variation in humidity and supercooled water droplets that it encounters. The accretion rate of these water droplets is another factor in the hailstone’s growth. When the hailstone moves into an area with a high concentration of water droplets, it captures the latter and acquires a translucent layer. Should the hailstone move into an area where mostly water vapour is available, it acquires a layer of opaque white ice.
Furthermore, the hailstone’s speed depends on its position in the cloud’s updraft and its mass. This determines the varying thicknesses of the layers of the hailstone. The accretion rate of supercooled water droplets onto the hailstone depends on the relative velocities between these water droplets and the hailstone itself. This means that generally the larger hailstones will form some distance from the stronger updraft where they can pass more time growing. As the hailstone grows it releases latent heat, which keeps its exterior in a liquid phase. Because it undergoes 'wet growth', the outer layer is "sticky", or more adhesive, so a single hailstone may grow by collision with other smaller hailstones, forming a larger entity with an irregular shape.
The hailstone will keep rising in the thunderstorm until its mass can no longer be supported by the updraft. This may take at least 30 minutes based on the force of the updrafts in the hail-producing thunderstorm, whose top is usually greater than 10 km high. It then falls toward the ground while continuing to grow, based on the same processes, until it leaves the cloud. It will later begin to melt as it passes into air above freezing temperature.
Thus, a unique trajectory in the thunderstorm is sufficient to explain the layer-like structure of the hailstone. The only case in which multiple trajectories can be discussed is in a multicellular thunderstorm, where the hailstone may be ejected from the top of the "mother" cell and captured in the updraft of a more intense "daughter" cell. This, however, is an exceptional case.
Factors favoring hail.
Hail is most common within continental interiors of the mid-latitudes, as hail formation is considerably more likely when the freezing level is below the altitude of 11000 ft. Movement of dry air into strong thunderstorms over continents can increase the frequency of hail by promoting evaporational cooling which lowers the freezing level of thunderstorm clouds giving hail a larger volume to grow in. Accordingly, hail is less common in the tropics despite a much higher frequency of thunderstorms than in the mid-latitudes because the atmosphere over the tropics tends to be warmer over a much greater altitude. Hail in the tropics occurs mainly at higher elevations.
Hail growth becomes vanishingly small when air temperatures fall below -30 C as supercooled water droplets become rare at these temperatures. Around thunderstorms, hail is most likely within the cloud at elevations above 20000 ft. Between 10000 ft and 20000 ft, 60 percent of hail is still within the thunderstorm, though 40 percent now lies within the clear air under the anvil. Below 10000 ft, hail is equally distributed in and around a thunderstorm to a distance of 2 nmi.
Climatology.
Hail occurs most frequently within continental interiors at mid-latitudes and is less common in the tropics, despite a much higher frequency of thunderstorms than in the mid-latitudes. Hail is also much more common along mountain ranges because mountains force horizontal winds upwards (known as orographic lifting), thereby intensifying the updrafts within thunderstorms and making hail more likely. The higher elevations also result in there being less time available for hail to melt before reaching the ground. One of the more common regions for large hail is across mountainous northern India, which reported one of the highest hail-related death tolls on record in 1888. China also experiences significant hailstorms. Central Europe and southern Australia also experience a lot of hailstorms. Popular regions for hailstorms are southern and western Germany, northern and eastern France and southern and eastern Benelux. In south-eastern Europe, Croatia and Serbia experience frequent occurrences of hail.
In North America, hail is most common in the area where Colorado, Nebraska, and Wyoming meet, known as "Hail Alley". Hail in this region occurs between the months of March and October during the afternoon and evening hours, with the bulk of the occurrences from May through September. Cheyenne, Wyoming is North America's most hail-prone city with an average of nine to ten hailstorms per season.
Short-term detection.
Weather radar is a very useful tool to detect the presence of hail-producing thunderstorms. However, radar data has to be complemented by a knowledge of current atmospheric conditions which can allow one to determine if the current atmosphere is conducive to hail development.
Modern radar scans many angles around the site. Reflectivity values at multiple angles above ground level in a storm are proportional to the precipitation rate at those levels. Summing reflectivities in the Vertically Integrated Liquid or VIL, gives the liquid water content in the cloud. Research shows that hail development in the upper levels of the storm is related to the evolution of VIL. VIL divided by the vertical extent of the storm, called VIL density, has a relationship with hail size, although this varies with atmospheric conditions and therefore is not highly accurate. Traditionally, hail size and probability can be estimated from radar data by computer using algorithms based on this research. Some algorithms include the height of the freezing level to estimate the melting of the hailstone and what would be left on the ground.
Certain patterns of reflectivity are important clues for the meteorologist as well. The three body scatter spike is an example. This is the result of energy from the radar hitting hail and being deflected to the ground, where they deflect back to the hail and then to the radar. The energy took more time to go from the hail to the ground and back, as opposed to the energy that went direct from the hail to the radar, and the echo is further away from the radar than the actual location of the hail on the same radial path, forming a cone of weaker reflectivities.
More recently, the polarization properties of weather radar returns have been analyzed to differentiate between hail and heavy rain. The use of differential reflectivity (formula_1), in combination with horizontal reflectivity (formula_2) has led to a variety of hail classification algorithms. Visible satellite imagery is beginning to be used to detect hail, but false alarm rates remain high using this method.
Size and terminal velocity.
The size of hailstones is best determined by measuring their diameter with a ruler. In the absence of a ruler, hailstone size is often visually estimated by comparing its size to that of known objects, such as coins. Using the objects such as hen's eggs, peas, and marbles for comparing hailstone sizes is often imprecise, due to their varied dimensions. The UK organisation, TORRO, also scales for both hailstones and hailstorms. When observed at an airport, METAR code is used within a surface weather observation which relates to the size of the hailstone. Within METAR code, GR is used to indicate larger hail, of a diameter of at least 0.25 in. GR is derived from the French word grêle. Smaller-sized hail, as well as snow pellets, use the coding of GS, which is short for the French word grésil.
Hail records.
Megacryometeors, large rocks of ice that are not associated with thunderstorms, are not officially recognized by the World Meteorological Organization as "hail," which are aggregations of ice associated with thunderstorms, and therefore records of extreme characteristics of megacryometeors are not given as hail records.
Terminal velocity of hail, or the speed at which hail is falling when it strikes the ground, varies. It is estimated that a hailstone of 1 cm in diameter falls at a rate of 9 m/s, while stones the size of 8 cm in diameter fall at a rate of 48 m/s. Hailstone velocity is dependent on the size of the stone, friction with air it is falling through, the motion of wind it is falling through, collisions with raindrops or other hailstones, and melting as the stones fall through a warmer atmosphere. As hail stones are not perfect spheres it is difficult to calculate their speed accurately.
Hazards.
Hail can cause serious damage, notably to automobiles, aircraft, skylights, glass-roofed structures, livestock, and most commonly, farmers' crops. Hail damage to roofs often goes unnoticed until further structural damage is seen, such as leaks or cracks. It is hardest to recognize hail damage on shingled roofs and flat roofs, but all roofs have their own hail damage detection problems. Metal roofs are fairly resistant to hail damage, but may accumulate cosmetic damage in the form of dents and damaged coatings.
Hail is one of the most significant thunderstorm hazards to aircraft. When hailstones exceed 0.5 in in diameter, planes can be seriously damaged within seconds. The hailstones accumulating on the ground can also be hazardous to landing aircraft. Hail is also a common nuisance to drivers of automobiles, severely denting the vehicle and cracking or even shattering windshields and windows. Wheat, corn, soybeans, and tobacco are the most sensitive crops to hail damage. Hail is one of Canada's most expensive hazards. Rarely, massive hailstones have been known to cause concussions or fatal head trauma. Hailstorms have been the cause of costly and deadly events throughout history. One of the earliest recorded incidents occurred around the 9th century in Roopkund, Uttarakhand, India. The largest hailstone in terms of diameter and weight ever recorded in the United States fell on July 23, 2010 in Vivian, South Dakota; it measured 8 in in diameter and 18.62 in in circumference, weighing in at 1.93 lbs. This broke the previous record for diameter set by a hailstone 7 inches diameter and 18.75 inches circumference (still the greatest "circumference" hailstone) which fell in Aurora, Nebraska in the United States on June 22, 2003, as well as the record for weight, set by a hailstone of 1.67 lbs that fell in Coffeyville, Kansas in 1970.
Accumulations.
Narrow zones where hail accumulates on the ground in association with thunderstorm activity are known as hail streaks or hail swaths, which can be detectable by satellite after the storms pass by. Hailstorms normally last from a few minutes up to 15 minutes in duration. Accumulating hail storms can blanket the ground with over 2 in of hail, cause thousands to lose power, and bring down many trees. Flash flooding and mudslides within areas of steep terrain can be a concern with accumulating hail.
On somewhat rare occasions, a thunderstorm can become stationary or nearly so while prolifically producing hail and significant depths of accumulation do occur; this tends to happen in mountainous areas, such as the July 29, 2010 case of a foot of hail accumulation in Boulder County, Colorado. Depths of up to a metre have been reported. A landscape covered in accumulated hail generally resembles one covered in accumulated snow and any significant accumulation of hail has the same restrictive effects as snow accumulation, albeit over a smaller area, on transport and infrastructure. Accumulated hail can also cause flooding by blocking drains, and hail can be carried in the floodwater, turning into a snow-like slush which is deposited at lower elevations.
Suppression and prevention.
During the Middle Ages, people in Europe used to ring church bells and fire cannons to try to prevent hail, and the subsequent damage to crops. Updated versions of this approach are available as modern hail cannons. Cloud seeding after World War II was done to eliminate the hail threat, particularly across the Soviet Union – where it was claimed a 70 to 98 percent reduction in crop damage from hail storms was achieved by deploying silver iodide in clouds using rockets and artillery shells. Hail suppression programs have been undertaken by 15 countries between 1965 and 2005.

</doc>
<doc id="14459" url="http://en.wikipedia.org/wiki?curid=14459" title="Hypnotherapy">
Hypnotherapy

Hypnotherapy is a form of psychotherapy used to create subconscious change in a patient in the form of new responses, thoughts, attitudes, behaviors or feelings. It is undertaken with a subject in hypnosis.
A person who is hypnotized displays certain unusual characteristics and propensities, compared with a non-hypnotized subject, most notably heightened suggestibility and responsiveness.
Definition of a hypnotherapist.
In 1973, Dr. John Kappas, Founder of the Hypnosis Motivation Institute, wrote and defined the profession of a hypnotherapist in the Federal Dictionary of Occupational Titles:
"Induces hypnotic state in client to increase motivation or alter behavior patterns: Consults with client to determine nature of problem. Prepares client to enter hypnotic state by explaining how hypnosis works and what client will experience. Tests subject to determine degree of physical and emotional suggestibility. Induces hypnotic state in client, using individualized methods and techniques of hypnosis based on interpretation of test results and analysis of client's problem. May train client in self-hypnosis conditioning."
Traditional hypnotherapy.
The form of hypnotherapy practiced by most Victorian hypnotists, including James Braid and Hippolyte Bernheim, mainly employed direct suggestion of symptom removal, with some use of therapeutic relaxation and occasionally aversion to alcohol, drugs, etc.
Ericksonian hypnotherapy.
In the 1950s, Milton H. Erickson developed a radically different approach to hypnotism, which has subsequently become known as "Ericksonian hypnotherapy" or "Neo-Ericksonian hypnotherapy." Erickson made use of an informal conversational approach with many clients and complex language patterns, and therapeutic strategies. This divergence from tradition led some of his colleagues, including Andre Weitzenhoffer, to dispute whether Erickson was right to label his approach "hypnosis" at all.
The founders of Neurolinguistic Programming (NLP), a methodology similar in some regards to hypnotism, claimed that they had modelled the work of Erickson extensively and assimilated it into their approach. Weitzenhoffer disputed whether NLP bears any genuine resemblance to Erickson's work.
Cognitive/behavioral hypnotherapy.
Cognitive behavioural hypnotherapy (CBH) is an integrated psychological therapy employing clinical hypnosis and cognitive behavioural therapy (CBT). The use of CBT in conjunction with hypnotherapy may result in greater treatment effectiveness. A meta-analysis of eight different researches revealed "a 70% greater improvement" for patients undergoing an integrated treatment to those using CBT only.
In 1974, Theodore Barber and his colleagues published an influential review of the research which argued, following the earlier social psychology of Theodore R. Sarbin, that hypnotism was better understood not as a "special state" but as the result of normal psychological variables, such as active imagination, expectation, appropriate attitudes, and motivation. Barber introduced the term "cognitive-behavioral" to describe the nonstate theory of hypnotism, and discussed its application to behavior therapy.
The growing application of cognitive and behavioral psychological theories and concepts to the explanation of hypnosis paved the way for a closer integration of hypnotherapy with various cognitive and behavioral therapies. However, many cognitive and behavioral therapies were themselves originally influenced by older hypnotherapy techniques, e.g., the systematic desensitisation of Joseph Wolpe, the cardinal technique of early behavior therapy, was originally called "hypnotic desensitisation" and derived from the "Medical Hypnosis" (1948) of Lewis Wolberg.
Uses.
Hypnosis in childbirth.
Hypnotherapy has long been used in relation to childbirth. It is sometimes used during pregnancy to prepare a mother for birth, and during childbirth to reduce anxiety, discomfort and pain.
Psychotherapy.
Hypnosis was originally used to treat the condition known in the Victorian era as hysteria. Modern hypnotherapy is widely accepted for the treatment of anxiety, subclinical depression, certain habit disorders, to control irrational fears, as well as in the treatment of conditions such as insomnia and addiction. Hypnosis has also been used to enhance recovery from non-psychological conditions such as after surgical procedures, in breast cancer care and even with gastro-intestinal problems, including IBS.
Cognitive hypnotherapy and bulimia.
Scientific literature suggests a wide variety of hypnotic interventions can be used to treat bulimia nervosa. Similar studies have shown that groups suffering from bulimia nervosa, undergoing hypnotherapy, were more exceptional to no treatment, placebos, or other alternative treatments.
Research.
Systematic reviews.
1890s.
In 1892, the British Medical Association (BMA) commissioned a team of doctors to undertake an evaluation of the nature and effects of hypnotherapy;
The Committee, having completed such investigation of hypnotism as time permitted, have to report that they have satisfied themselves of the genuineness of the hypnotic state.
The Committee are of opinion that as a therapeutic agent hypnotism is frequently effective in relieving pain, procuring sleep, and alleviating many functional ailments [i.e., psycho-somatic complaints and anxiety disorders].
1950s.
In 1955, the Psychological Medicine Group of the BMA commissioned a Subcommittee, led by Prof. T. Ferguson Rodger, to deliver a second, and more comprehensive, report on hypnosis. The Subcommittee consulted several experts on hypnosis from various fields, including the eminent neurologist Prof. W. Russell Brain, the 1st Baron Brain, and the psychoanalyst Wilfred Bion. After two years of study and research, its final report was published in the British Medical Journal (BMJ), under the title ‘Medical use of Hypnotism’. The terms of reference were:
To consider the uses of hypnotism, its relation to medical practice in the present day, the advisability of giving encouragement to research into its nature and application, and the lines upon which such research might be organized.
It concludes from a systematic review of available research that,
The Subcommittee is satisfied after consideration of the available evidence that hypnotism is of value and may be the treatment of choice in some cases of so-called psycho-somatic disorder and Psychoneurosis. It may also be of value for revealing unrecognized motives and conflicts in such conditions. As a treatment, in the opinion of the Subcommittee it has proved its ability to remove symptoms and to alter morbid habits of thought and behavior[...]
In addition to the treatment of psychiatric disabilities, there is a place for hypnotism in the production of anesthesia or analgesia for surgical and dental operations, and in suitable subjects it is an effective method of relieving pain in childbirth without altering the normal course of labor.
According to a statement of proceedings published elsewhere in the same edition of the BMJ, the report was officially ‘approved at last week’s Council meeting of the British Medical Association.’ In other words, it was approved as official BMA policy. This statement goes on to say that,
For the past hundred years there has been an abundance of evidence that psychological and physiological changes could be produced by hypnotism which were worth study on their own account, and also that such changes might be of great service in the treatment of patients.
In 1958, the American Medical Association (AMA) commissioned a similar (though more terse) report which endorses the 1955 BMA report and concludes,
That the use of hypnosis has a recognized place in the medical armamentarium and is a useful technique in the treatment of certain illnesses when employed by qualified medical and dental personnel.
Again, the AMA council approved this report rendering hypnotherapy an orthodox treatment,
The Reference Committee on Hygiene, Public Health, and Industrial Health approved the report and commended the Council on Mental Health for its work. The House of Delegates adopted the Reference Committee report [...]
1990s.
In 1995, the US National Institute for Health (NIH), established a Technology Assessment Conference that compiled an official statement entitled "Integration of Behavioral & Relaxation Approaches into the Treatment of Chronic Pain & Insomnia". This is an extensive report that includes a statement on the existing research in relation to hypnotherapy for chronic pain. It concludes that:
The evidence supporting the effectiveness of hypnosis in alleviating chronic pain associated with cancer seems strong. In addition, the panel was presented with other data suggesting the effectiveness of hypnosis in other chronic pain conditions, which include irritable bowel syndrome, oral mucositis (pain and swelling of the mucous membrane), temporomandibular disorders [jaw pain], and tension headaches. (NIH, 1995)
In 1999, the British Medical Journal (BMJ) published a Clinical Review of current medical research on hypnotherapy and relaxation therapies, it concludes,
Reports.
In 2001, the Professional Affairs Board of the British Psychological Society (BPS) commissioned a working party of expert psychologists to publish a report entitled "The Nature of Hypnosis". Its remit was 'to provide a considered statement about hypnosis and important issues concerning its application and practice in a range of contexts, notably for clinical purposes, forensic investigation, academic research, entertainment and training.' The report provides a concise (c. 20 pages) summary of the current scientific research on hypnosis. It opens with the following introductory remark:
"Hypnosis is a valid subject for scientific study and research and a proven therapeutic medium." 
With regard to the therapeutic uses of hypnosis, the report said:
"Enough studies have now accumulated to suggest that the inclusion of hypnotic procedures may be beneficial in the management and treatment of a wide range of conditions and problems encountered in the practice of medicine, psychiatry and psychotherapy." 
The working party then provided an overview of some of the most important contemporary research on the efficacy of clinical hypnotherapy, which is summarized as follows:
Meta-analysis.
In 2003, a meta-analysis of the efficacy of hypnotherapy was published by two researchers from the university of Konstanz in Germany, Flammer and Bongartz. The study examined data on the efficacy of hypnotherapy across the board, though studies included mainly related to psychosomatic illness, test anxiety, smoking cessation and pain control during orthodox medical treatment. Most of the better research studies used traditional-style hypnosis, only a minority (19%) employed Ericksonian hypnosis.
The authors considered a total of 444 studies on hypnotherapy published prior to 2002. By selecting the best quality and most suitable research designs for meta-analysis they narrowed their focus down to 57 controlled trials. These showed that on average hypnotherapy achieved at least 64% success compared to 37% improvement among untreated control groups. (Based on the figures produced by binomial effect size display or BESD.)
According to the authors this was an intentional underestimation. Their professed aim was to discover whether, even under the most skeptical weighing of the evidence, hypnotherapy was still proven effective. They showed conclusively that it was. In fact, their analysis of treatment designs concluded that expansion of the meta-analysis to include non-randomized trials for this data base would also produce reliable results. When all 133 studies deemed suitable in light of this consideration were re-analyzed, providing data for over 6,000 patients, the findings suggest an average improvement in 27% of untreated patients over the term of the studies compared with a 74% success rate among those receiving hypnotherapy. This is a high success rate given the fact that many of the studies measured included the treatment of addictions and medical conditions. The outcome rates for anxiety disorders alone, traditionally hypnotherapy's strongest application, were higher still (though a precise figure is not cited).
In 2005, a meta-analysis by the Cochrane Collaboration found no evidence that hypnotherapy was more successful than other treatments or no treatment in achieving cessation of smoking for at least six months. In 2007 a meta-analysis from the Cochrane Collaboration found that the therapeutic effect of hypnotherapy was "superior to that of a waiting list control or usual medical management, for abdominal pain and composite primary IBS symptoms, in the short term in patients who fail standard medical therapy", with no harmful side-effects. However the authors noted that the quality of data available was inadequate to draw any firm conclusions.
Occupational accreditation.
United States definition of hypnotherapist.
The U.S. (Department of Labor) "Directory of Occupational Titles" (D.O.T. 079.157.010) supplies the following definition:
The in the state of Washington regulates hypnotherapists.
United Kingdom.
UK National Occupational Standards.
In 2002, the Department for Education and Skills developed National Occupational Standards for hypnotherapy linked to National Vocational Qualification based on National Qualifications Framework under The Qualifications and Curriculum Authority. And thus hypnotherapy was approved as a stand-alone therapy in UK. , a national awarding body, issues level four national vocational qualification diploma in hypnotherapy.
UK Confederation of Hypnotherapy Organisations (UKCHO).
The regulation of the hypnotherapy profession in the UK is at present the main focus of , a non-profit umbrella body for hypnotherapy organisations. Founded in 1998 to provide a non-political arena to discuss and implement changes to the profession of hypnotherapy, UKCHO currently represents 9 of the UK's professional hypnotherapy organisations and has developed standards of training for hypnotherapists, along with codes of conduct and practice that all UKCHO registered hypnotherapists are governed by. As a step towards the regulation of the profession, UKCHO's website now includes a National Public Register of Hypnotherapists who have been registered by UKCHO's Member Organisations and are therefore subject to UKCHO's professional standards. Further steps to full regulation of the hypnotherapy profession will be taken in consultation with the Prince's Foundation for Integrated Health.
Australia.
Professional hypnotherapy and use of the occupational titles "hypnotherapist" or "clinical hypnotherapist" is not government-regulated in Australia.
In 1996, as a result of a three-year research project led by Lindsay B. Yeates, the Australian Hypnotherapists' Association (founded in 1949), the oldest hypnotism-oriented professional organization in Australia, instituted a peer-group accreditation system for full-time Australian professional hypnotherapists, the first of its kind in the world, which "accredit[ed] specific individuals on the basis of their actual demonstrated knowledge and clinical performance; instead of approving particular 'courses' or approving particular 'teaching institutions'" (Yeates, 1996, p.iv; 1999, p.xiv). The system was further revised in 1999.
Australian hypnotism/hypnotherapy organizations (including the Australian Hypnotherapists Association) are seeking government regulation similar to other mental health professions. However, the various tiers of Australian government have shown consistently over the last two decades that they are opposed to government legislation and in favour of self-regulation by industry groups.

</doc>
<doc id="14462" url="http://en.wikipedia.org/wiki?curid=14462" title="Hangman (game)">
Hangman (game)

Hangman is a paper and pencil guessing game for two or more players. One player thinks of a word, phrase or sentence and the other tries to guess it by suggesting letters or numbers.
Overview.
The word to guess is represented by a row of dashes, representing each letter of the word. Words you cannot use include proper nouns such as names, places, and brands. If the guessing player suggests a letter which occurs in the word, the other player writes it in all its correct positions. If the suggested letter or number does not occur in the word, the other player draws one element of a hanged man stick figure as a tally mark. The game is over when:
This diagram is, in fact, designed to look like a hanging man. Although debates have arisen about the questionable taste of this picture, it is still in use today. A common alternative for teachers is to draw an apple tree with ten apples, erasing or crossing out the apples as the guesses are used up.
The exact nature of the diagram differs; some players draw the gallows before play and draw parts of the man's body (traditionally the head, then the torso, then the arms and legs one by one). Some players begin with no diagram at all, and drawing the individual elements of the gallows as part of the game, effectively giving the guessing players more chances. The amount of detail on the man can also vary, affecting the number of chances. Some players include a face on the head, either all at once or one feature at a time.
Some modifications to game play to increase difficulty level are sometimes implemented, such as limiting guesses on high-frequency consonants and vowels. Another alternative is to give the definition of the word. This can be used to facilitate the learning of a foreign language.
History of the Hangman game.
"The origins of Hangman are obscure meaning not discovered, but it seems to have arisen in Victorian times," says Tony Augarde, author of "The Oxford Guide to Word Games". The game is mentioned in Alice Bertha Gomme's "Traditional Games" in 1894 under the name "Birds, Beasts and Fishes." The rules are simple; a player writes down the first and last letters of a word for an animal, and the other player guesses the letters in between. In other sources, the game is called "Gallows", "The Game of Hangin'", or "Hanger". Hangman has featured in the 1978 Speak & Spell video game system under the name "Mystery Word" and is sometimes played today on Internet forums.
Strategy for the game.
In the English language, the twelve most commonly occurring letters are, in descending order:
e-t-a-o-i-n-s-h-r-d-l-u. This and other letter-frequency lists are used by the guessing player to increase the odds when it is their turn to guess. On the other hand, the same lists can be used by the puzzle setter to stump their opponent by choosing a word which deliberately avoids common letters (e.g. "rhythm" or "zephyr") or one that contains rare letters (e.g. "jazz").
Another common strategy is to guess vowels first, as English only has six vowels (a, e, i, o, u and y), and almost every word has at least one.
According to a 2010 study conducted by Jon McLoone for Wolfram Research, the most difficult words to guess include "jazz", "buzz", "hajj", "faff", "fizz", "fuzz" and variations of these.
Derivations.
The game show "Wheel of Fortune" is based on Hangman, but with the addition of a roulette-styled wheel and cash is awarded for each letter.
Example game.
The following example game illustrates a player trying to guess the word "hangman" using a strategy based solely on letter frequency.

</doc>
<doc id="14463" url="http://en.wikipedia.org/wiki?curid=14463" title="Harmonic mean">
Harmonic mean

In mathematics, the harmonic mean (sometimes called the subcontrary mean) is one of several kinds of average, and in particular one of the Pythagorean means. Typically, it is appropriate for situations when the average of rates is desired.
The harmonic mean "H" of the positive real numbers 
formula_1 is defined to be
From the third formula in the above equation, it is more apparent that the harmonic mean is related to the arithmetic and geometric means.
Equivalently, the harmonic mean is the reciprocal of the arithmetic mean of the reciprocals. As a simple example, the harmonic mean of 1, 2, and 4 is formula_3
The Harmonic mean is a Schur-concave function, and dominated by the minimum of its arguments, in the sense that
for any positive set of arguments, 
formula_4
Thus, the harmonic mean can not be made arbitrarily large by adding more big values to the argument set. The harmonic mean
is the reciprical dual of the arithmetic mean for positive inputs:
Relationship with other means.
The harmonic mean is one of the three Pythagorean means. For all "positive" data sets "containing at least one pair of nonequal values", the harmonic mean is always the least of the three means, while the arithmetic mean is always the greatest of the three and the geometric mean is always in between. (If all values in a nonempty dataset are equal, the three means are always equal to one another; e.g. the harmonic, geometric, and arithmetic means of {2, 2, 2} are all 2.)
It is the special case "M"−1 of the power mean:
Since the harmonic mean of a list of numbers tends strongly toward the least elements of the list, it tends (compared to the arithmetic mean) to mitigate the impact of large outliers and aggravate the impact of small ones.
The arithmetic mean is often mistakenly used in places calling for the harmonic mean. In the speed example below for instance, the arithmetic mean of 50 is incorrect, and too big.
The harmonic mean is related to the other Pythagorean means, as seen in the third formula in the above equation. This is noticed if we interpret the denominator to be the arithmetic mean of the product of numbers "n" times but each time we omit the "j"th term. That is, for the first term, we multiply all "n" numbers except the first; for the second, we multiply all "n" numbers except the second; and so on. The numerator, excluding the "n", which goes with the arithmetic mean, is the geometric mean to the power "n". Thus the "n"th harmonic mean is related to the "n"th geometric and arithmetic means.
Three positive numbers "H", "G", and "A" are respectively the harmonic, geometric, and arithmetic means of three positive numbers if and only if:p.74,#1834
If a set of non-identical numbers is subjected to a mean-preserving spread — that is, two or more elements of the set are "spread apart" from each other while leaving the arithmetic mean unchanged — then the harmonic mean always decreases.
Weighted harmonic mean.
If a set of weights formula_8, ..., formula_9 is associated to the dataset formula_10, ..., formula_11, the weighted harmonic mean is defined by
The :formula_13 mean as defined is the special case where all of the weights are equal to 1, and is equivalent to any weighted harmonic mean where all weights are equal.
Examples.
In physics.
In certain situations, especially many situations involving rates and ratios, the harmonic mean provides the truest average. For instance, if a vehicle travels a certain distance at a speed "x" (e.g. 60 kilometres per hour) and then the same distance again at a speed "y" (e.g. 40 kilometres per hour), then its average speed is the harmonic mean of "x" and "y" (48 kilometres per hour), and its total travel time is the same as if it had traveled the whole distance at that average speed. However, if the vehicle travels for a certain amount of "time" at a speed "x" and then the same amount of time at a speed "y", then its average speed is the arithmetic mean of "x" and "y", which in the above example is 50 kilometres per hour. The same principle applies to more than two segments: given a series of sub-trips at different speeds, if each sub-trip covers the same "distance", then the average speed is the "harmonic" mean of all the sub-trip speeds; and if each sub-trip takes the same amount of "time", then the average speed is the "arithmetic" mean of all the sub-trip speeds. (If neither is the case, then a weighted harmonic mean or weighted arithmetic mean is needed.)
Similarly, if one connects two electrical resistors in parallel, one having resistance "x" (e.g. 60Ω) and one having resistance "y" (e.g. 40Ω), then the effect is the same as if one had used two resistors with the same resistance, both equal to the harmonic mean of "x" and "y" (48Ω): the equivalent resistance in either case is 24Ω (one-half of the harmonic mean). However, if one connects the resistors in series, then the average resistance is the arithmetic mean of "x" and "y" (with total resistance equal to the sum of x and y). And, as with previous example, the same principle applies when more than two resistors are connected, provided that all are in parallel or all are in series.
The same principle applies to capacitors in series.
The conductivity effective mass of a semiconductor is also defined as the harmonic mean of the effective masses along the three crystallographic directions
In other sciences.
In computer science, specifically information retrieval and machine learning, the harmonic mean of the precision (true positives per predicted positive) and the recall (true positives per real positive) is often used as an aggregated performance score for the evaluation of algorithms and systems: the F-score (or F-measure). This is used in information retrieval because only the positive class is of relevance and number of negatives is not in general known. It is thus a trade-off as to whether the correct positive predictions should be measured in relation to the number of predicted positives or the number of real positives, so it is measured versus a putative number of positives that is an arithmetic mean of the two possible denominators.
An interesting consequence arises from basic algebra in problems where people or systems work together. As an example, if a gas-powered pump can drain a pool in 4 hours and a battery-powered pump can drain the same pool in 6 hours, then it will take both pumps (6 · 4)/(6 + 4), which is equal to 2.4 hours, to drain the pool together. Interestingly, this is one-half of the harmonic mean of 6 and 4: (2*6*4)/(6+4) = 4.8. That is the appropriate average for the two types of pump is the harmonic mean, and with one pair of pumps (two pumps) it takes half this harmonic mean time, while with two pairs of pumps (four pumps) it would take a quarter of this harmonic mean time. 
In electronics the harmonic mean in the same way gives the average contribution per component for parallel resistance, parallel inductance, serial conductance and serial capacitance.
In hydrology, the harmonic mean is similarly used to average hydraulic conductivity values for flow that is perpendicular to layers (e.g. geologic or soil) - flow parallel to layers uses the arithmetic mean. This apparent difference in averaging is explained by the fact that hydrology uses conductivity, which is the inverse of resistivity.
In sabermetrics, the Power-speed number of a player is the harmonic mean of his home run and stolen base totals.
In population genetics, the harmonic mean is used when calculating the effects of fluctuations in generation size on the effective breeding population. This is to take into account the fact that a very small generation is effectively like a bottleneck and means that a very small number of individuals are contributing disproportionately to the gene pool, which can result in higher levels of inbreeding.
In transportation, to find the average speed of a trip over a route divided into constant speed segments (of distance) one must use the #weighted harmonic mean (weighted by the distance of each segment). For example, if one travels half-way to a destination at 20 mi/hr, and then goes 60 mi/hr for the second half of the distance, the average speed is only 30 mi/hr (harmonic mean) and not the 40 mi/hr (arithmetic mean). This is because it took 3 times as long (in time) to go the first half of the trip distance as it did to go the second half and true average speed is a simple Weighted arithmetic mean with the weights being time. Thus 20 mi/hr gets 3 times more weight than 60 mi/hr:( 3/4 x 20 ) + ( 1/4 x 60 ) = 30 mi/hr
When considering fuel economy in automobiles two measures are commonly used – miles per gallon (mpg), and litres per 100 km. As the dimensions of these quantities are the inverse of each other (one is distance per volume, the other volume per distance) when taking the mean value of the fuel-economy of a range of cars one measure will produce the harmonic mean of the other – i.e. converting the mean value of fuel economy expressed in litres per 100 km to miles per gallon will produce the harmonic mean of the fuel economy expressed in miles-per-gallon.
In finance.
The harmonic mean is the preferable method for averaging multiples, such as the price/earnings ratio, in which price is in the numerator. If these ratios are averaged using an arithmetic mean (a common error), high data points are given greater weights than low data points. The harmonic mean, on the other hand, gives equal weight to each data point.
In geometry.
In any triangle, the radius of the incircle is one-third of the harmonic mean of the altitudes.
For any point P on the minor arc BC of the circumcircle of an equilateral triangle ABC, with distances "q" and "t" from B and C respectively, and with the intersection of PA and BC being at a distance "y" from point P, we have that "y" is half the harmonic mean of "q" and "t".
In a right triangle with legs "a" and "b" and altitude "h" from the hypotenuse to the right angle, "h"2 is half the harmonic mean of "a"2 and "b"2.
Let "t" and "s" ("t" > "s") be the sides of the two inscribed squares in a right triangle with hypotenuse "c". Then "s"2 equals half the harmonic mean of "c"2 and "t"2.
Let a trapezoid have vertices A, B, C, and D in sequence and have parallel sides AB and CD. Let E be the intersection of the diagonals, and let F be on side DA and G be on side BC such that FEG is parallel to AB and CD. Then FG is the harmonic mean of AB and DC. (This is provable using similar triangles.)
In the crossed ladders problem, two ladders lie oppositely across an alley, each with feet at the base of one sidewall, with one leaning against a wall at height "A" and the other leaning against the opposite wall at height "B", as shown. The ladders cross at a height of "h" above the alley floor. Then "h" is half the harmonic mean of "A" and "B". This result still holds if the walls are slanted but still parallel and the "heights" "A", "B", and "h" are measured as distances from the floor along lines parallel to the walls.
In an ellipse, the semi-latus rectum (the distance from a focus to the ellipse along a line parallel to the minor axis) is the harmonic mean of the maximum and minimum distances of the ellipse from a focus.
In trigonometry.
In the case of the double-angle tangent identity, if the tangent of an angle "A" is given as "a"/"b", then the tangent of 2"A" is the product of (1) the harmonic mean of the numerator and denominator of tan "A" and (2) the reciprocal of (the denominator minus the numerator of tan "A").
In general, the double-angle formula can be written as
if formula_15 and formula_16 and formula_17 are real numbers.
For example, if
then the most familiar form of the double-angle formula is
but this can also be written as
Harmonic mean of two numbers.
For the special case of just two numbers, formula_10 and formula_22, the harmonic mean can be written
In this special case, the harmonic mean is related to the arithmetic mean formula_24
and the geometric mean formula_25 by
So formula_27, meaning the two numbers' geometric mean equals the geometric mean of their arithmetic and harmonic means.
As noted above, this relationship between the three Pythagorean means is not limited to "n" equals 1 or 2; there is a relationship for all "n". However, it should be noted that for "n" equals 1 all means are equal and for "n" equals 2 we have the above relationship between the means. For arbitrary "n" ≥ 2 we may generalize this formula, as noted above, by interpreting the third equation for the harmonic mean differently. The generalized relationship was already explained above. If one carefully observes the third equation, one will notice it also works for "n" = 1. That is, it predicts the equivalence between the harmonic and geometric means but it falls short by not predicting the equivalence between the harmonic and arithmetic means.
The general formula, which can be derived from the third formula for the harmonic mean by the reinterpretation as explained in relationship with other means, is
Notice that for formula_29 we have
where we used the fact that the arithmetic mean evaluates to the same number independent of the order of the terms. This equation can be reduced to the original equation if we reinterpret this result in terms of the operators themselves. If we do this, we get the symbolic equation
because each function was evaluated at

</doc>
<doc id="14465" url="http://en.wikipedia.org/wiki?curid=14465" title="Hellbender">
Hellbender

The hellbender ("Cryptobranchus alleganiensis"), also known as the hellbender salamander, is a species of giant salamander endemic to eastern North America. A member of the Cryptobranchidae family, hellbenders are the only members of the "Cryptobranchus" genus, and are joined only by one other genus of salamanders ("Andrias", which contains the Japanese and Chinese giant salamanders) at the family level. These salamanders are much larger than any others in their endemic range, they employ an unusual means of respiration (which involves cutaneous gas exchange through capillaries found in their dorsoventral skin folds), and they fill a particular niche—both as a predator and prey—in their ecosystems, which either they or their ancestors have occupied for around 65 million years.
Etymology.
The origin of the name "hellbender" is unclear. The Missouri Department of Conservation says:
The name 'hellbender' probably comes from the animal's odd look. Perhaps it was named by settlers who thought "it was a creature from hell where it's bent on returning." Another rendition says the undulating skin of a hellbender reminded observers of "horrible tortures of the infernal regions." In reality, it's a harmless aquatic salamander.
Vernacular names include "snot otter", "devil dog", "mud-devil", "grampus", "Allegheny alligator", "mud dog", "water dog", and "leverian water newt". The genus name is derived from the Ancient Greek "kryptos" (hidden) and "branchion" (gill).
Description.
"C. alleganiensis" has a flat body and head, with beady dorsal eyes and slimy skin. Like most salamanders, it has short legs with four toes on the front legs and five on its back limbs, and its tail is keeled for propulsion. The hellbender has working lungs, but gill slits are often retained, although only immature specimens have true gills; the hellbender absorbs oxygen from the water through capillaries of its side frills. It is blotchy brown or red-brown in color, with a paler underbelly.
Both males and females grow to an adult length of 24 to from snout to vent, with a total length of 30 to, making them the third-largest aquatic salamander species in the world (after the Chinese giant salamander and the Japanese giant salamander) and the largest in North America. An adult weighs 1.5 to. Hellbenders reach sexual maturity at about five years of age, and may live 30 years in captivity.
The hellbender has a few characteristics that make it distinguishable from other native salamanders, including a gigantic, dorsoventrally flattened body with thick folds travelling down the sides, a single open gill slit on each side, and hind feet with five toes each. Easily distinguished from most other endemic salamander species simply by their size, hellbenders average up to 60 cm or about 2 ft in length; the only species requiring further distinction (due to an overlap in distribution and size range) is the common mudpuppy ("Necturus maculosus"). This demarcation can be made by noting the presence of external gills in the mudpuppy, which are lacking in the hellbender, as well as the presence of four toes on each hind foot of the mudpuppy (in contrast with the hellbender's five). Furthermore, the average size of "C. a. alleganiensis" has been reported to be 45–60 cm (with some reported as reaching up to 74 cm or 30 in), while "N. m. maculosus" has a reported average size of 28–40 cm in length, which means that hellbender adults will still generally be notably larger than even the biggest mudpuppies.
Taxonomy.
The genus "Cryptobranchus" has historically only been considered to contain one species, "C. alleganiensis", with two subspecies, "C. a. alleganiensis" and "C. a. bishopi". A recent decline in population size of the Ozark subspecies "C. a. bishopi" has led to further research into populations of this subspecies, including genetic analysis to determine the best method for conservation.
Crowhurst et al., for instance, found that the "Ozark subspecies" denomination is insufficient for describing genetic (and therefore evolutionary) divergence within the "Cryptobranchus" genus in the Ozark region. They found three equally divergent genetic units within the genus: "C. a. alleganiensis", and two distinct eastern and western populations of "C. a. bishopi". These three groups were shown to be isolated, and are considered to most likely be "diverging on different evolutionary paths".
Distribution.
Hellbenders are present in a number of Eastern US states, from southern New York to northern Georgia, including parts of Ohio, Pennsylvania, Maryland, West Virginia, Virginia, Kentucky, Illinois, Indiana, Tennessee, North Carolina, South Carolina, Alabama, Mississippi, Arkansas, Missouri, and even a small bit of Oklahoma and Kansas. The subspecies (or species, depending on the source) "C. a. bishopi" is confined to the Ozarks of northern Arkansas and southern Missouri, while "C. a. alleganiensis" is found in the rest of these states.
Some hellbender populations—namely a few in Missouri, Pennsylvania, and Tennessee—have historically been noted to be quite abundant, but several man-made maladies have converged on the species such that it has seen a serious population decline throughout its range. Hellbender populations were listed in 1981 as already extinct or endangered in Illinois, Indiana, Iowa, and Maryland, decreasing in Arkansas and Kentucky, and generally threatened as a species throughout their range by various human activities and developments.
Ecology.
The hellbender salamander, considered a "habitat specialist", has adapted to fill a specific niche within a very specific environment, and is labeled as such "because its success is dependent on a constancy of dissolved oxygen, temperature and flow found in swift water areas", which in turn limits it to a narrow spectrum of stream/river choices. As a result of this specialization, hellbenders are generally found in areas with large, irregularly shaped, and intermittent rocks and swiftly moving water, while they tend to avoid wider, slow-moving waters with muddy banks and/or slab rock bottoms. This specialization likely contributed to the decline in their populations, as collectors could easily identify their specific habitats. One collector noted, at one time, "one could find a specimen under almost every suitable rock", but after years of collecting, the population had declined significantly. The same collector noted, he "never found two specimens under the same rock", corroborating the account given by other researchers that hellbenders are generally solitary; they are thought to gather only during the mating season.
Both subspecies, "C. a. alleganiensis" and "C. a. bishopi" undergo a metamorphosis after around a year and a half of life. At this point, when they are roughly 13.5 cm long, they lose the gills present during their larval stage, and develop toes from lobes on their front limbs and "paddle-shaped" hind limbs. Until then, they are easily confused with mudpuppies, and can be differentiated often only through toe number. After this metamorphosis, hellbenders must be able to absorb oxygen through the folds in their skin, which is largely behind the need for fast-moving, oxygenated water. If a hellbender ends up in an area of slow-moving water, not enough of it will pass over its skin in a given time, making it difficult to garner enough oxygen to support necessary respiratory functions. A below-favorable oxygen content can make life equally difficult.
Hellbenders are preyed upon by diverse predators, including various fish and reptiles (including both snakes and turtles). Cannibalism of eggs is also considered a common occurrence.
Life history and behavior.
Behavior.
Once a hellbender finds a favorable location, it generally does not stray too far from it—except occasionally for breeding and hunting—and will protect it from other hellbenders both in and out of the breeding season. While the range of two hellbenders may overlap, they are noted as rarely being present in the overlapping area when the other salamander is in the area. The species is at least somewhat nocturnal, with peak activity being reported by one source as occurring around "two hours after dark" and again at dawn (although the dawn peak was recorded in the lab and could be misleading as a result). Nocturnal activity has been found to be most prevalent in early summer, perhaps coinciding with highest water depths.
Diet.
"C. alleganiensis" feeds primarily on crayfish and small fish. One report, written by a commercial collector in the 1940s, noted a trend of more crayfish predation in the summer during times of higher prey activity, whereas fish made up a larger part of the winter diet, when crayfish are less active. There seems to be a specific temperature range in which hellbenders feed, as well: between 45 and 80°F. Cannibalism—mainly on eggs—has been known to occur within hellbender populations. One researcher claimed perhaps density is maintained, and density dependence in turn created, in part by intraspecific predation.
Reproduction.
The hellbenders' breeding season begins in late August or early- to mid-September and can continue as late as the end of November, depending on region. They exhibit no sexual dimorphism, except during the fall mating season, when males have a bulging ring around their cloacal glands. Unlike most salamanders, the hellbender performs external fertilization. Before mating, each male excavates a brood site, a saucer-shaped depression under a rock or log, with its entrance positioned out of the direct current, usually pointing downstream. The male remains in the brood site awaiting a female. When a female approaches, the male guides or drives her into his burrow and prevents her from leaving until she oviposits.
Female hellbenders lay 150–200 eggs over a two- to three-day period; the eggs are 18–20 mm in diameter, connected by five to 10 cords. As the female lays eggs, the male positions himself alongside or slightly above them, spraying the eggs with sperm while swaying his tail and moving his hind limbs, which disperses the sperm uniformly. The male often tempts other females to lay eggs in his nest, and as many as 1,946 eggs have been counted in a single nest. Cannibalism, however, leads to a much lower number of eggs in hellbender nests than would be predicted by egg counts.
After oviposition, the male drives the female away from the nest and guards the eggs. Incubating males rock back and forth and undulate their lateral skin folds, which circulates the water, increasing oxygen supply to both eggs and adult. Incubation lasts from 45 to 75 days, depending on region.
Hatchling hellbenders are 25–33 mm long, have a yolk sac as a source of energy for the first few months of life, and lack functional limbs.
Adaptations.
Hellbenders are superbly adapted to the shallow, fast-flowing, rocky streams in which they live. Their flattened shape offers little resistance to the flowing water, allowing them to work their way upstream and also to crawl into narrow spaces under rocks. Although their eyesight is relatively poor, they have light-sensitive cells all over their bodies. Those on their tails are especially finely tuned and may help them position safely under rocks without their tails poking out to give themselves away. They have a good sense of smell and move upstream in search of food such as dead fish, following the trail of scent molecules. Smell is possibly their most important sense when hunting. They also have a lateral line similar to those of fish, with which they can detect vibrations in the water.
Conservation status.
Research throughout the range of the hellbender has shown a dramatic decline in populations in the majority of locations. Many different anthropogenic sources have helped to create this decline, including the siltation and sedimentation, blocking of dispersal/migration routes, and destruction of riverine habitats created by dams and other development, as well as pollution, disease and overharvesting for commercial and scientific purposes. As many of these detrimental effects have irreversibly damaged hellbender populations, it is important to conserve the remaining populations through protecting habitats and—perhaps in places where the species was once endemic and has been extirpated—by augmenting numbers through reintroduction.
Due to sharp decreases seen in the Ozark subspecies, researchers have been trying to differentiate "C. a. alleganiensis" and "C. a. bishopi" into two management units. Indeed, researchers found significant genetic divergence between the two groups, as well as between them and another isolated population of "C. a. alleganiensis". This could be reason enough to ensure work is done on both subspecies, as preserving extant genetic diversity is of crucial ecological importance.
The Ozark hellbender has been listed as an endangered species under the Endangered Species Act by the US Fish and Wildlife Service since October 5, 2011. This hellbender subspecies inhabits the White River and Spring River systems in southern Missouri and northern Arkansas, and its population has declined an estimated 75% since the 1980s, with only about 590 individuals remaining in the wild. Degraded water quality, habitat loss resulting from impoundments, ore and gravel mining, sedimentation, and collection for the pet trade are thought to be the main factors resulting in the amphibian's decline. When chytridiomycosis killed 75% of the St. Louis Zoo's captive hellbender population between March 2006 and April 2007, tests began to be conducted on wild populations. The disease has been detected in all Missouri populations of the Ozark hellbender.
The Ozark hellbender was successfully bred in captivity for the first time at the St. Louis Zoo, in a joint project with the Missouri Department of Conservation, hatching on November 15, 2011.
Apart from the Ozark efforts, head-starting programs, in which eggs are collected from the wild and raised in captivity for re-release at a less vulnerable stage, have been initiated in New York and Ohio.
Fossil record.
Extant species in the Cryptobranchidae family are the modern-day members of a lineage that extends back millions of years; the earliest fossil records of a basal species date back to the Middle Jurassic and were found in volcanic deposits in northern China. These specimens are the earliest known relatives of modern salamanders, and together with the numerous other basal groups of salamanders found in the Asian fossil record, they form a firm base of evidence for the fact that "the early diversification of salamanders was well underway" in Asia during the Jurassic period. Little has changed in the morphology of the Cryptobranchidae since the time of these fossils, leaving researchers to note "extant cryptobranchid salamanders can be regarded as living fossils whose structures have remained little changed for over 160 million years."
As the fossil record for the Cryptobranchidae shows an Asian origin for the family, how these salamanders made it to the eastern US has been a point of scientific interest. Research has indicated a dispersal via land bridge, with waves of adaptive radiation seeming to have swept the Americas from north to south.

</doc>
<doc id="14466" url="http://en.wikipedia.org/wiki?curid=14466" title="Harold Eugene Edgerton">
Harold Eugene Edgerton

Harold Eugene "Doc" Edgerton (April 6, 1903 – January 4, 1990) was a professor of electrical engineering at the Massachusetts Institute of Technology. He is largely credited with transforming the stroboscope from an obscure laboratory instrument into a common device. He also was deeply involved with the development of sonar and deep-sea photography, and his equipment was used by Jacques Cousteau in searches for shipwrecks and even the Loch Ness monster.
Biography.
Early years.
Edgerton was born in Fremont, Nebraska, on April 6, 1903, the son of Mary Nettie Coe and Frank Eugene Edgerton, a descendant of Richard Edgerton, one of the founders of Norwich, Connecticut and a descendant of Governor William Bradford (1590–1657) of the Plymouth Colony and a passenger on the Mayflower. His father was a lawyer, journalist, author and orator and served as the assistant attorney general of Nebraska from 1911 to 1915. Harold grew up in Aurora, Nebraska. He also spent some of his childhood years in Washington, D.C., and Lincoln, Nebraska.
Education.
In 1925 Edgerton received a bachelor's degree in electrical engineering from the University of Nebraska at Lincoln where he became a member of Acacia Fraternity. He earned an S.M. in electrical engineering from MIT in 1927. Edgerton used stroboscopes to study synchronous motors for his Sc.D. thesis in electrical engineering at MIT, awarded in 1931. He credited Charles Stark Draper with inspiring him to photograph everyday objects using electronic flash; the first was a stream of water coming out of a faucet.
Career.
In 1937 Edgerton began a lifelong association with photographer Gjon Mili, who used stroboscopic equipment, in particular, multiple studio electronic flash units, to produce strikingly beautiful photographs, many of which appeared in Life Magazine. When taking multiflash photographs this strobe light equipment could flash up to 120 times a second. Edgerton was a pioneer in using short duration electronic flash in photographing fast events photography, subsequently using the technique to capture images of balloons at different stages of their bursting, a bullet during its impact with an apple, or using multiflash to track the motion of a devil stick, for example. He was awarded a bronze medal by the Royal Photographic Society in 1934, the Howard N. Potts Medal from the Franklin Institute in 1941, the David Richardson Medal by the Optical Society of America in 1968, the Albert A. Michelson Medal from the same Franklin Institute in 1969, and the National Medal of Science in 1973.
Edgerton teamed up with Kenneth J. Germeshausen to do consulting work with different industrial clients. Later Herbert Grier joined them. The company name "Edgerton, Germeshausen, and Grier" was changed to EG&G in 1947. EG&G became a prime contractor for the Atomic Energy Commission and had a major role in photographing and recording nuclear tests for the United States through the fifties and sixties. For this role Edgerton and Charles Wykoff and others at EG&G developed and manufactured the Rapatronic camera
His work was instrumental in the development of side-scan sonar technology, used to scan the sea floor for wrecks. Edgerton worked with the undersea explorer Jacques Cousteau, by first providing him with custom designed underwater photographic equipment featuring electronic flash, and then by developing sonar techniques used to discover the Britannic. Edgerton participated in the discovery of the American Civil War battleship USS Monitor. While working with Cousteau, he acquired the nickname he is still known by in photographic circles, "Papa Flash".
In addition to having the scientific and engineering acumen to perfect strobe lighting commercially, Edgerton is equally recognized for his visual aesthetic: many of the striking images he created in illuminating phenomena that occurred too fast for the naked eye adorn art museums worldwide. In 1940, his high speed stroboscopic short film "Quicker'n a Wink" won an Oscar.
Edgerton was appointed a professor of electrical engineering at the Massachusetts Institute of Technology (MIT) in 1934. In 1956, Edgerton was elected a Fellow of the American Academy of Arts and Sciences. He was especially loved by MIT students for his willingness to teach and his kindness: "The trick to education", he said, "is to teach people in such a way that they don't realize they're learning until it's too late". His last undergraduate class, taught during fall semester 1977, was a freshman seminar titled "Bird and Insect Photography". One of the graduate student dormitories at MIT carries his name.
In 1962, Dr. Edgerton appeared on "I've Got a Secret", where he demonstrated strobe flash photography by shooting a bullet into a playing card and photographing the result.
Edgerton's work was featured in an October 1987 "National Geographic Magazine" article entitled "Doc Edgerton: the man who made time stand still".
Family.
After graduating from the University of Nebraska at Lincoln, Edgerton married Esther May Garrett in 1928. She was born in Hamilton County, Nebraska on Sept. 8, 1903 and died on March 9, 2002 in Charlestown, South Carolina. She received a bachelor's degree in mathematics, music and education from the University of Nebraska - Lincoln. A skilled pianist and singer, she attended the New England Conservatory of Music and taught in public schools in Aurora, Nebraska and Boston. During their marriage they had three children: Mary Louise (4/21/1931), William Eugene (8/9/1933), Robert Frank (5/10/1935). His sister, Mary Ellen Edgerton, was the wife of L. Welch Pogue (1899–2003) a pioneering aviation attorney and Chairman of the old Civil Aeronautics Board. David Pogue, a technology writer, journalist and commentator, is his great nephew.
Death.
Edgerton remained active throughout his later years, and was seen on the MIT campus many times after his official retirement. He died suddenly on January 4, 1990 at the MIT Faculty Club at the age of 86, and is buried in Mount Auburn Cemetery, Cambridge, Massachusetts.
Legacy.
On July 3, 1990, in an effort to memorialize his accomplishments, several community members in Aurora, Nebraska decided to construct a "Hands-On" science center. It was designated as a "teaching museum," that would preserve Doc's work and artifacts, as well as feature the "Explorit Zone" where people of all ages could participate in hands-on exhibits and interact with live science demonstrations. After five years of private and community-wide fund-raising, as well as individual investments by Doc's surviving family members, the Edgerton Explorit Center was officially dedicated on September 9, 1995.
At MIT, the Edgerton Center, founded in 1992, is a hands-on laboratory resource for undergraduate and graduate students, and also conducts educational outreach programs for high school students and teachers.
Works.
Photographs.
Some of Edgerton's noted photographs are
External links.
PBS "Nova" series: "Edgerton and His Incredible Seeing Machines"
NOVA explores the fascinating world of Dr. Harold Edgerton, electronics wizard and inventor extraordinaire, whose invention of the electronic strobe, a "magic lamp," has enabled the human eye to see the unseen."
Original broadcast date: 01/15/85

</doc>
<doc id="14467" url="http://en.wikipedia.org/wiki?curid=14467" title="Harry Kroto">
Harry Kroto

Sir Harold (Harry) Walter Kroto, FRS (born Harold Walter Krotoschiner; 7 October 1939), is an English chemist. He shared the 1996 Nobel Prize in Chemistry with Robert Curl and Richard Smalley. Kroto is the Francis Eppes Professor of Chemistry at the Florida State University, which he joined in 2004. Prior to that, he spent a large part of his career at the University of Sussex, where he now holds an emeritus professorship.
Early years.
Kroto was born in Wisbech, Cambridgeshire, England, to Edith and Heinz Krotoschiner, with his name being of Silesian origin. His father's family came from Bojanowo, Poland, and his mother's from Berlin, Germany. Both his parents were born in Berlin and came to Great Britain in the 1930s as refugees from the Nazis because his father was Jewish. He was raised in Bolton, Lancashire, England, and attended Bolton School, where he was a contemporary of the highly acclaimed actor Ian McKellen. In 1955, the family name was shortened to Kroto.
As a child, he became fascinated by a Meccano set. Kroto credits Meccano — amongst other things — with developing skills useful in scientific research. He developed an interest in chemistry, physics, and mathematics in secondary school, and because his sixth form chemistry teacher (Harry Heaney – who subsequently became a University Professor) felt that the University of Sheffield had the best chemistry department in the United Kingdom, he went to Sheffield.
Although raised Jewish, Harry Kroto has stated that religion never made any sense to him. He is a humanist who claims to have three religions: Amnesty Internationalism, atheism, and humor. He is a distinguished supporter of the British Humanist Association. In 2003 he was one of 22 Nobel Laureates who signed the Humanist Manifesto.
Education and academic career.
Education.
Kroto was educated at Bolton School and went to Sheffield University in 1958. At Sheffield he obtained a first class honours BSc degree in Chemistry (1961) and a PhD in Molecular Spectroscopy (1964). At University he also became art editor of “Arrows” the University student magazine, played tennis for the University team (reaching the UAU finals twice) and was President of the Student Athletics Council (1963–64). After a 2-year postdoctoral position at the National Research Council in Ottawa from 1964-1966 carrying out further work in molecular spectroscopy, he spent a year at the Murray Hill Bell Laboratories in New Jersey (1966-1967) carrying out Raman studies of liquid phase interactions and worked on quantum chemistry. He started his academic career at the University of Sussex in Brighton.
Among other things such as making the first phosphaalkenes (compounds with carbon phosphorus double bonds), his doctoral studies included some unpublished research on carbon suboxide, O=C=C=C=O, and this led to a general interest in molecules containing chains of carbon atoms with numerous multiple bonds. He started his work with an interest in organic chemistry, but when he learned about spectroscopy it inclined him towards quantum chemistry; he later developed an interest in astrochemistry.
After postdoctoral research at the National Research Council in Canada and Bell Laboratories in the United States he began teaching and research at the University of Sussex in England in 1967. He became a full professor in 1975, and a Royal Society Research Professor from 1991 – 2007.
Early work at University of Sussex.
During 1967–1985 he carried out research mainly focused on the spectroscopic studies of new and novel unstable and semi-stable species. This work resulted in the birth of the various fields of new chemistry involving carbon multiply bonded to second and third row elements e.g. S, Se and P. A particularly important breakthrough (with Sussex colleague John Nixon) was the creation of several novel, new phosphorus species detected by microwave spectroscopy. This work resulted in the birth of the field(s) of phosphaalkene and phosphaalkyne chemistry. These species contain carbon double and triple bonded to phosphorus (C=P and C≡P).
Astronomy.
In 1975 Sussex laboratory microwave measurements (with Sussex colleague David Walton) on long linear carbon chain molecules led to radio astronomy observations (with Canadian astronomers) which revealed the surprising fact that these unusual carbonaceous species existed in relatively large abundances in interstellar space as well as the outer atmospheres of certain stars – the carbon-rich red giants.
Discovery of buckminsterfullerene.
In 1985, on the basis of the Sussex studies and the stellar discoveries, laboratory experiments (with co-workers Jim Heath Sean O’Brien, Yuan Liu, Robert Curl and Rick Smalley at Rice University) which simulated the chemical reactions in the atmospheres of the red giant stars uncovered the amazing fact that a stable C60 molecule could form spontaneously from a condensing carbon vapour. The C60 molecule is an elegant molecule with the same symmetry pattern as a football, with 12 pentagons and 20 hexagons. Kroto named the molecule buckminsterfullerene, after Buckminster Fuller who had conceived of the geodesic domes, as the dome concept had provided a clue to the likely structure of the new species. 
The discovery of C60 caused Kroto to postpone his dream of setting up an art and graphic design studio – he had been doing graphics semi-professionally for years. Indeed his first major award was for graphics – The Sunday Times Book Jacket Design Award (1964). In 1985 the C60 discovery appeared so exciting that he shifted his research from spectroscopy in order to probe the consequences of the C60 structural concept (and prove it correct) and to exploit the implications for chemistry and material science. His present research is in the areas of Nanoscience and Nanotechnology.
Research at Florida State University.
During the period 2004-5 he left the University of Sussex to take up a new position as Francis Eppes Professor of Chemistry at Florida State University. At FSU he is carrying out fundamental research on: Carbon vapour with Professor Alan Marshall; Open framework condensed phase systems with strategically important electrical and magnetic behaviour with Professors Naresh Dalal (FSU) and Tony Cheetham (Cambridge); and the mechanism of formation and properties of nano-structured systems. In 2007 he started a new Internet educational initiative. This Global Education Outreach in Science, Engineering and Technology – project known as GEOSET is streaming SET programmes of all kinds at www.geoset.info and www.geoset.fsu.edu. This project aims to help teachers improve the quality of science education in schools worldwide. From 2004 he has been on the Scripps Research Institute Board of Scientific Governors and was elected a Foreign Associate of the National Academy of Sciences in 2007.
Educational outreach and public service.
In 1995 he jointly set up the Vega Science Trust a UK educational charity to create high quality science films including lectures, interviews with Nobel Laureates, discussion programmes, careers and teaching resources for TV and Internet Broadcast. Vega has produced some 280 plus programmes of which 50 have been broadcast on BBC TV. All programmes stream for free from the Vega website which acts as a TV science channel. The website which is accessed by over 165 countries is designed by Harry Kroto and shows his other main interest – graphic design.
In 2009, Kroto spearheaded the development of a second science education initiative, GEOSET. Short for the Global Educational Outreach for Science, Engineering and Technology, GEOSET is an ever-growing online cache of recorded teaching modules that are freely downloadable to educators and the public. The program aims to increase knowledge of the sciences by creating a global repository of educational videos and presentations from leading universities and institutions.
In 2003, prior to the Blair/Bush invasion of Iraq on the pretext that Iraq
had Weapons of Mass Destruction, Harry Kroto initiated and organised the publication
of a letter to be signed by a dozen UK Nobel Laureates and published in the Times. It was
composed by his friend the Nobel Peace Prize Laureate the late Sir Joseph Rotblat
and published in The Times February 15 (2003).
He wrote a set of articles, mostly opinion pieces, from 2002-2003 for the Times Higher Education Supplement, a weekly UK publication.
From 2002–2004, Kroto served as President of the Royal Society of Chemistry. Since 2004, he has held the Francis Eppes Professorship in the chemistry department at Florida State University and presently carries out research in nanoscience and nanotechnology.
He spoke at Auburn University on 29 April 2010, and at the James A. Baker III Institute for Public Policy at Rice University with Robert Curl on 13 October 2010.
In October 2010 Kroto participated in the USA Science and Engineering Festival's Lunch with a Laureate program where middle and high school students had the opportunity to engage in an informal conversation with a Nobel Prize–winning scientist.
He spoke at Mahatma Gandhi University, at Kottayam, in Kerala, India in January 2011, where he was an 'Erudite' special invited lecturer of the Government of Kerala, from 5 to 11 January 2011.
Kroto spoke at CSIcon 2011. CSIcon is a convention "dedicated to scientific inquiry and critical thinking" organized by the Committee for Skeptical Inquiry in association with Skeptical Inquirer magazine and the Center for Inquiry.
He also delivered the IPhO 2012 lecture at the International Physics Olympiad held in Estonia.
In 2014, Kroto spoke at the Starmus Festival in the Canary Islands, delivering a lecture about his life in science, chemistry, design, and more.
Graphic design.
Kroto's graphic design work has resulted in numerous posters, letterheads, logos, book/journal covers, medal design, etc. He has produced numerous artwork after receiving graphic awards in the Sunday Times Book Jacket Design competition (1964) and the Moet Hennesy/Louis Vuitton Science pour l'Art Prize (1994). Other notable graphical works include the design of the Nobel UK Stamp for Chemistry (2001) and features at the Royal Academy (London) Summer Exhibition (2004).
Global Educational Outreach for Science Engineering and Technology.
The Global Educational Outreach for Science Engineering and Technology (Geoset) initiative uses new IT technology to provide imaginative teaching material in modules focused relatively tighly on specific topics. It is a highly flexible medium enabling a wide range of different educational approaches to be explored and it is particularly useful for STEM teachers who will find valuable downloadable teaching resource material created by innovative science and technology experts and educators. The materials has been created by faculty and students in universities as well as by high schools, thus guaranteeing a measure of reliability. A wonderful bonus of GEOSET recordings is that they provide revolutionary additions to the students' resumes, as they improve immeasurable succuess in gaining jobs, cholarships, award, and postdocs. The key aim of GEOSET is the creation of global network of participating sites catering to local and globed need for much improved STEM education. Participating institutions each set up its own streaming node and upload URLs with associated information to the searchable gateway www.geoset.info.
Personal life.
In 1963, he married Margaret Henrietta Hunter, also a student at the University. Harry and Margaret Kroto have two sons: Stephen and David. Throughout his entire life, Kroto has been a lover of film, theatre, art, and music and has published his own artwork. Kroto calls himself a devout atheist. On 15 September 2010, Kroto, along with 54 other public figures, signed an open letter published in "The Guardian", stating their opposition to Pope Benedict XVI's state visit to the UK.
Honours and awards.
Major Awards.
Kroto was made a Knight Bachelor in the 1996 New Year's Honours list.
The University of Sheffield North Campus contains two buildings named after Sir Harry Kroto, The Kroto Innovation Centre and the Kroto Research Institute.

</doc>
<doc id="14468" url="http://en.wikipedia.org/wiki?curid=14468" title="Heimskringla">
Heimskringla

Heimskringla is the best known of the Old Norse kings' sagas. It was written in Old Norse in Iceland by the poet and historian Snorri Sturluson (1178/79–1241) ca. 1230. The name "Heimskringla" was first used in the 17th century, derived from the first two words of one of the manuscripts ("kringla heimsins" - "the circle of the world").
"Heimskringla" is a collection of sagas about the Norwegian kings, beginning with the saga of the legendary Swedish dynasty of the Ynglings, followed by accounts of historical Norwegian rulers from Harald Fairhair of the 9th century up to the death of the pretender Eystein Meyla in 1177. The exact sources of his work are disputed, but included earlier kings' sagas, such as Morkinskinna, Fagrskinna and the twelfth century Norwegian synoptic histories and oral traditions, notably many skaldic poems. Snorri had himself visited Norway and Sweden. For events of the mid-12th century, Snorri explicitly names the now lost work "Hryggjarstykki" as his source. The composition of the sagas is Snorri's.
Manuscript history.
The earliest parchment copy of the work is referred to as "Kringla". It voyaged from Iceland to Bergen, Norway and was moved to Copenhagen, the University Library. At that time it had lost the first page, but the second (the current beginning of the Ynglinga Saga) starts "Kringla heimsins", "the Earth's circle" of the Laing translation.
In the 17th century copies were made by Icelanders Jon Eggertson and Asgeir Jonsson. Eggertson's copy went to the Royal Library at Stockholm. The Copenhagen manuscript was among the many valuables destroyed in the Copenhagen Fire of 1728. Only one leaf of the manuscript survived and it is now kept in the National and University Library of Iceland.
Translations.
By the mid-16th century, the Old Norse language was unintelligible to Norwegian, Swedish or Danish readers. At that time several translations of extracts were made in Norway into the Danish language, which was the literary language of Norway at the time. The first complete translation was made around 1600 by Peder Claussøn Friis, and printed in 1633. This was based on a manuscript known as "Jofraskinna".
Subsequently the Stockholm manuscript was translated into Swedish and Latin by Johan Peringskiöld (by order of Charles XI) and published in 1697 at Stockholm under the title "Heimskringla", which is the first known use of the name. This edition also included the first printing of the text in Old Norse. A new Danish translation with the text in Old Norse and a Latin translation came out in 1777-1783 (by order of Frederick VI as crown prince). An English translation by Samuel Laing was finally published in 1844, with a second edition in 1889. Other English translations followed.
In the 19th century, as Norway was achieving independence after centuries of union with Denmark and Sweden, the stories of the independent Norwegian medieval kingdom won great popularity in Norway. Heimskringla, although written by an Icelander, became an important national symbol for Norway during the period of romantic nationalism. In 1900, the Norwegian parliament, the Storting, subsidized the publication of new translations of Heimskringla into both Norwegian written forms, landsmål and riksmål, "in order that the work may achieve wide distribution at a low price".
Scope.
"Heimskringla" consists of several chapters, each one individually called a saga, which can be literally translated as 'tale'. The first of these tells the mythological prehistory of the Norwegian royal dynasty, tracing Odin, described here as a mortal man, and his followers from the East, from Asaland and Asgard, its chief city, to their settlement in Scandinavia (more precisely to east-central Sweden, according to Snorri). The subsequent sagas are (with few exceptions) devoted to individual rulers, starting with Halfdan the Black, and ending with Magnus Erlingsson. The saga narrates the contests of the kings, the establishment of the kingdom of Norway, Viking expeditions to various European countries, straying as far afield as Palestine in the saga of King Sigurd the Crusader. The stories are told with a life and freshness, giving a picture of human life in all its reality. The Saga of Olaf Haraldsson is the main part. His 15-year-long reign takes up about one third of the entire work.
The saga of Harold Hardrada narrates his expedition to the East, his brilliant exploits in Constantinople, Syria, and Sicily, his skaldic accomplishments, and his battles in England against Harold Godwinson, the son of Earl Godwin, where he fell at Stamford Bridge in 1066 only a few days before Harold himself fell at the battle of Hastings. This saga is a splendid epic in prose, and is also of particular relevance to the history of England. The first part of the Heimskringla is rooted in Norse mythology; as it advances, fable and fact all curiously intermingle, and it terminates in factual history.
The value of "Heimskringla" as a historical source has been estimated in different ways during recent times. The historians of mid-19th century put great trust in the factual truth of Snorri's narrative, as well as other old Norse sagas. In the early 20th century, this trust was largely abandoned with the advent of "saga criticism", pioneered by Curt and Lauritz Weibull. These historians pointed out that Snorri's work had been written several centuries after most of the events it describes. In Norway, the historian Edvard Bull famously proclaimed that "we have to give up all illusions that Snorri's mighty epic bears any deeper resemblance to what actually happened" in the time it describes. A school of historians has come to believe that the motives Snorri and the other saga writers give to their characters owe more to conditions in the 13th century than in earlier times. "Heimskringla" has, however, continued to be used as a historical source, though with more caution. It is not common to believe in the detailed accuracy of the historical narrative and historians tend to see little to no historical truth behind the first few sagas, however, they are still seen by many as a valuable source of knowledge about the society and politics of medieval Norway. The factual content of the work tends to be deemed more credible where it discusses more recent times, as the distance in time between the events described and the composition of the saga was shorter, allowing traditions to be retained in a largely accurate form, and because in the twelfth century the first contemporary written sources begin to emerge in Norway.
Contents.
"Heimskringla" contains the following sagas (see also List of Norwegian monarchs):

</doc>
<doc id="14470" url="http://en.wikipedia.org/wiki?curid=14470" title="Hamar">
Hamar

Hamar ] is a town and municipality in Hedmark county, Norway. It is part of the traditional region of Hedmarken. The administrative centre of the municipality is the town of Hamar. The municipality of Hamar was separated from Vang as a town and municipality of its own in 1849. Vang was merged back into Hamar on 1 January 1992.
The town is located on the shores of Mjøsa, Norway's largest lake, and is the principal city of Hedmark county. It is bordered to the northwest by the municipality of Ringsaker, to the north by Åmot, to the east by Løten, and to the south by Stange.
General information.
Name.
The municipality (originally the town) is named after the old "Hamar" farm (Old Norse: "Hamarr"), since the medieval town was built on its ground. The name is identical with the word "hamarr" which means "rocky hill".
Coat-of-arms.
The coat-of-arms shows a Black Grouse sitting in the top of a pine tree on a white background. It was first described in the anonymous Hamarkrøniken ("The Hamar Chronicle") written in 1553.
History.
Between 500 and 1000 AD, Aker farm was one of the most important power centres in Norway, located just a few kilometres away from today's Hamar. Three coins found in Ringerike in 1895 have been dated to the time of Harald Hardråde and are inscribed "Olafr a Hamri".
Middle Ages.
At some point, presumably after 1030 but clearly before 1152, the centre was moved from Aker to the peninsula near Rosenlundvika, what we today know as Domkirkeodden. There are some indications Harald Hardråde initiated this move because he had property at the new site.
Much of the information about medieval Hamar is derived from the Hamar Chronicles, dated to about 1550. The town is said to have reached its apex in the early 14th century, dominated by the Hamar cathedral, bishop's manor, and fortress, and surrounding urbanization. The town was known for its fragrant apple orchards, but there were also merchants, craftsmen, and fishermen in the town.
After the Christianization of Norway in 1030, Hamar began to gain influence as a centre for trade and religion, until the episcopal representative Nikolaus Breakspear in 1152 founded Hamar Kaupangen as one of five dioceses in medieval Norway. This diocese included Hedemarken and Christians Amt, being separated in 1152 from the former diocese of Oslo. The first bishop of Hamar was Arnold, Bishop of Gardar, Greenland (1124–1152). He began to build the now ruined cathedral of Christ Church, which was completed about the time of Bishop Paul (1232–1252). Bishop Thorfinn (1278–1282) was exiled and died at Ter Doest abbey in Flanders, and was later canonised. Bishop Jörund (1285–1286) was transferred to Trondheim. A provincial council was held in 1380. Hamar remained an important religious and political centre in Norway, organized around the cathedral and the bishop's manor until the Reformation in 1536, when it lost its status as a bishopric after the last Catholic bishop, Mogens Lauritssøn (1513–1537), was taken prisoner in his castle at Hamar by Truid Ulfstand, a Danish noble, and sent to Antvorskov in Denmark, where he was mildly treated until his death in 1542. There were at Hamar a cathedral chapter with ten canons, a school, a Dominican Priory of St. Olaf, and a monastery of the Canons Regular of St. Anthony of Vienne.
Hamar, like most of Norway, was severely diminished by the Black Plague in 1349, and by all accounts continued this decline until the Reformation, after which it disappeared.
The Reformation in Norway took less than 10 years to complete, from 1526 to 1536. The fortress was made into the residence of the sheriff and renamed Hamarhus fortress. The cathedral was still used but fell into disrepair culminating with the Swedish army's siege and attempted demolition in 1567, during the Northern Seven Years' War, when the manor was also devastated.
Reformation and decline.
By 1587, merchants in Oslo had succeeded in moving all of Hamar's market activities to Oslo. Though some regional and seasonal trade persisted into the 17th century, Hamar as a town ceased to exist by then. In its place, the area was used for agriculture under the farm of Storhamar, though the ruins of the cathedral, fortress, and lesser buildings became landmarks for centuries since then.
The King made Hamarhus a feudal seat until 1649, when Frederick III transferred the property known as Hammer to Hannibal Sehested, making it private property. In 1716, the estate was sold to Jens Grønbech (1666–1734). With this, a series of construction projects started, and the farm became known as Storhamar, passing through several owners until Norwegian nobility was abolished in 1831, when Erik Anker took over the farm.
The founding of modern Hamar.
As early as 1755, the Danish government in Copenhagen expressed an interest in establishing a trading center on Mjøsa. Elverum was considered a frontier town with frequent unrest, and there was even talk of encouraging the dissenting Hans Nielsen Hauge to settle in the area. Bishop Fredrik Julius Bech, one of the most prominent officials of his time, proposed establishing a town at or near Storhamar, at the foot of Furuberget.
In 1812, negotiations started in earnest, when the regional governor of Kristians Amt, proposed establishing a market on Mjøsa. A four-person commission was named on 26 July 1814, with the mandate of determining a suitable site for a new town along the shore. On 8 June 1815, the commission recommended establishing such a town at Lillehammer, then also a farm, part of Fåberg.
Acting on objections to this recommendation, the department of the interior asked two professors, Ludvig Stoud Platou and Gregers Fougner Lundh, to survey the area and develop an alternative recommendation. It appears that Lundh in particular put great effort into this assignment, and in 1824 he presented to the Storting a lengthy report, that included maps and plans for the new town.
Lundh's premise was that the national economic interest reigned supreme, so he based his recommendation on the proposed town's ability to quickly achieve self-sustaining growth. He proposed that the name of the new town be called "Carlshammer" and proposed it be built along the shore just north of Storhamar and eastward. His plans were detailed, calling for streets 20 meters broad, rectangular blocks with 12 buildings in each, 2 meters separating each of them. He also proposed tax relief for 20 years for the town's first residents, that the state relinquish property taxes in favor of the city, and that the city be given monopoly rights to certain trade. He even proposed that certain types of foreigners be allowed to settle in the town to promote trade, in particular, the Quakers.
His recommendation was accepted in principle by the government, but the parliamentary committee equivocated on the location. It left the determination of the actual site to the king so as to not slow down things further. Another commission was named in June 1825, consisting of Herman Wedel-Jarlsberg, professor Lundh, and other prominent Norwegians. After surveying the entire lake, it submitted another report that considered eleven different locations, including sites near today's Eidsvoll, Minnesund, Tangen in Stange, Aker, Storhamar, Brumunddal, Nes, Moelven, Lillehammer, Gjøvik, and Toten. Each was presented with pros and cons. The commission itself was split between Lillehammer and Storhamar. The parliament finally decided on Lillehammer, relegating Hamar once more, it seemed, to be a sleepy agricultural area.
As steamboats were introduced on the lake, the urban elite developed an interest in the medieval Hamar, and in 1841, editorials appeared advocating the reestablishment of a town at Storhamar. By then the limitations of Lillehammer's location had also become apparent, in particular those of its shallow harbor. After a few more years of discussions and negotiations both regionally and nationally, member of parliament Frederik Stang put on the table once more the possibility of a town in or near Storhamar. The governor at the time, Frederik Hartvig Johan Heidmann, presented a thorough deliberation of possible specific locations, and ended up proposing the current site, at Gammelhusbukten.
On 26 April 1848, the king signed into law the establishment of Hamar on the grounds of the farms of Storhamar and Holset, along the shores of Mjøsa. The law stated that the town will be founded on the date its borders are settled, which turned out to be 21 March 1849, known as the merchant town of Hamar, with a trading zone within five kilometers (5 km) of its borders.
Building a city.
The area of the new town covered 400 mål which is the equivalent to today's 40 ha (40 hectare). An army engineer, Røyem, drafted the initial plan. There would be three thoroughfares, at Strandgata, Torggata, and Grønnegate (the latter the name of a medieval road) and a grid system of streets between them. The orientation of the town was toward the shore. Røyem set aside space for three parks and a public square, and also room for a church just outside the town's borders.
There were critics of the plan, pointing out that the terrain was hilly and not suitable for the proposed rigid grid. Some adjustments were made, but the plan was largely accepted and is evident in today's Hamar. There were also lingering concerns about the town's vulnerability to flooding.
No sooner had the ink dried on the new law, and building started in the spring of 1849. The first buildings were much like sheds, but there was great enthusiasm, and by the end of 1849, ten buildings were insured in the new town. None of these are standing today; the last two were adjacent buildings on Skappelsgate. By 1850, there were 31 insured houses, and 1852, 42; and in 1853, 56. Building slowed down for a few years and then picked up again in 1858, and by the end of 1860 there were 100 insured houses in the town. The shore side properties were obliged to grow gardens, setting the stage for a leafy urban landscape.
Roads quickly became a challenge – in some places, it was necessary to ford creeks in the middle of town. The road inspector found himself under considerable stress, and it was not until 1869 street names were settled. Highways in and out of the city also caused considerable debate, especially when it came to financing their construction.
The first passenger terminal in Hamar was in fact a crag in the lake, from which travelers were rowed into the city. In 1850, another pier was built with a two-storey terminal building. All this was complicated by the significant seasonal variations in water levels. In 1857 a canal was built around a basin that would allow freight ships to access a large warehouse. Although the canal and basin still were not deep enough to accommodate passenger steamships, the area became one of the busiest areas in the town and the point around which the harbor was further developed.
The Diocese of Hamar was established in 1864, and the Hamar Cathedral was consecrated in 1866 and remains a central point in the city.
A promenade came into being from the harbor area, past the gardens on the shore, and north toward the site of the old town.
Establishment of government.
The first executive of Hamar was Johannes Bay, who arrived in October 1849 to facilitate an election of a board of supervisors and representatives. The town's Royal Charter called for the election of 3 supervisors and 9 representatives, and elections were announced in the paper and through town crier. Of the 10 eligible town citizens, three supervisors were elected, and the remaining six were elected by consent to be representatives, resulting in a shortfall of 3 on the board. The first mayor of Hamar was Christian Borchgrevink.
The first order of business was the allocation of liquor licenses and the upper limit of alcohol that could be sold within the town limits. The board quickly decided to award licenses to both applicants and set the upper limit to 12,000 "pots" of liquor, an amount that was for all intents and purposes limitless.
The electorate increased in 1849 to 26, including merchants and various craftsmen, and the empty representative posts were filled in November. In 1850, the board allowed for unlimited exercise of any craft for which no citizenship had been taken out, which led to much unregulated craftsmanship. Part-time policemen were hired, and the town started setting taxes and a budget by the end of 1849. In 1850, a new election was held for the town board.
The painter Jakobsen had early on offered his house for public meetings and assembly, and upon buying a set of solid locks, his basement also became the town prison. One merchant was designated as the town's firefighter and was given two buckets with equipment, and later a simple hose, but by 1852 a full-time fire chief was named. There was also some controversy around the watchman who loudly reported the time to all the town's inhabitants every half-hour, every night. Hamar also had a scrupulously enforced ordnance against smoking (pipe) without a lid in public or private.
In Hamar's early days, the entire population consisted of young entrepreneurs, and little was needed in the way of social services. After a few years, a small number of indigent people needed support, and a poorhouse was erected.
Fires, floods and other disasters.
In 1878, as the firefighting capabilities of the young town were upgraded, a fire broke out in a bakery that was put out without doing too much damage. In February 1879 at 2:00 in the morning another fire broke out after festivities, burning down an entire building that housed many historical items from town's history. This was followed by a series of fires that left entire blocks in ashes that seemed to come to an end in 1881, when a professional fire corps was hired.
In 1860, concerns about flooding were vindicated when a late and sudden spring caused the lake to flood, peaking on about 24 June, when the street-level floor of the front properties was completely inundated. This was the worst flood recorded since 1789. By 9 July, the floods had receded. But it was not to prove the end of the calamities. In August, massive rainfall led to flash flooding in the area, putting several streets under water. This was immediately followed by unseasonably cold weather, freezing the potato crops and inconveniencing Hamar's residents. And then, mild weather melted all the ice and accumulated snow, leading to another round of flooding. By the time a particularly cold and snow-filled winter set in, there was mostly relief about getting some stability.
In 1876, the town was scandalized by the apprehension of one Kristoffer Svartbækken, arrested for the cold-blooded murder of 19-year-old Even Nilsen Dæhlin. Svartbækken was convicted for the murder and executed the year after in the neighboring rural community of Løten in what must have been a spectacle with an audience of 3,000 locals, presumably most of Hamar's population at the time.
Then in 1889, there were riots in Hamar over the arrest of one of their own constables, one sergeant Huse, who had been insubordinate while on a military drill at the cavalry camp at Gardermoen. In an act of poor judgment, Huse's superior sent him to Hamar's prison in place of military stockades. Partly led and partly tolerated by other constables, the town's population engaged in demonstrations, marches, and other unlawful but non-violent acts that were effectively ended when a company of soldiers arrived from the camp at Terningmoen near Elverum.
Cityscape.
The Hedmark museum, located on Domkirkeodden, is an important historical landmark in Hamar, an outdoor museum with remains of the medieval church, in a protective glass housing, the episcopal fortress and a collection of old farm houses. The institution is a combined medieval, ethnological and archaeological museum, and has received architectural prizes for its approach to conservation and exhibition. It also houses a vast photographic archive for the Hedmark region.
Additionally, Hamar is known for its indoor long track speed skating and bandy arena, the "Olympia Hall", better known as Vikingskipet ("The Viking ship") for its shape. It was built to host the speed skating competitions of the 1994 Winter Olympics that were held in nearby Lillehammer. Already in 1993 it hosted the Bandy World Championships. The Vikingskipet Olympic Arena was later used in the winter of 2007 as the service park for Rally Norway, the second round of the 2007 World Rally Championship season. It has been the host for the worlds second largest computer party The Gathering starting on the Wednesday in Easter each year, for the last 13 years.
Also situated in Hamar is the Hamar Olympic Amphitheatre which hosted the figure skating and short track speed skating events of the 1994 Winter Olympics. The figure skating competition was highly anticipated. It featured Nancy Kerrigan and Tonya Harding, who drew most of the media attention, however the gold medal was won by Oksana Baiul of Ukraine.
The centre of Hamar is the pedestrian walkway in the middle of town, with the library, cinema and farmer's market on Stortorget (the big square) on the western side, and Østre Torg (the eastern square), which sits on top of an underground multi-story carpark, on the eastern side.
Transport.
Hamar is an important railway junction between two different lines to Trondheim. Rørosbanen, the old railway line, branches off from the mainline Dovrebanen. The Norwegian Railway Museum ("Norsk Jernbanemuseum") is also in Hamar.
Sports.
Team sports.
Hamar boasts several teams at the Norwegian top level in various sports:
Individual sports.
Hamar is known for its speed skating history, both for its skaters and the championships that have been hosted by the city, already in 1894 Hamar hosted its first European championship, and the first World Championship the year after. After the Vikingskipet was built, Hamar has hosted international championships on a regular basis.
The most notable skaters from Hamar are Dag Fornæss and Even Wetten, both former World champions, allround and 1000m respectively. Amund Sjøbrend, Ådne Sønderål and Eskil Ervik have all been members of the local club Hamar IL, although they were not born in Hamar.
In Hamar on 17 July 1993, Scottish cyclist Graeme Obree set a world record for the distance covered in an hour. His 51,596 metres broke the 51,151 set at altitude nine years earlier but lasted only six days before Chris Boardman broke it in Bordeaux.
Other notable athletes:
International relations.
Twin towns – Sister cities.
The following cities, both in Scandinavia and around the world, are twinned with Hamar:
In literature.
Part of the plot of "The Axe", the first volume of Sigrid Undset's "The Master of Hestviken", is set in the Medieval Hamar. The book's young lovers, denied the right to marry by malicious relatives, come to the town in order to try to get the help of the kindly and compassionate Bishop Thorfinn of Hamar.

</doc>
<doc id="14472" url="http://en.wikipedia.org/wiki?curid=14472" title="Book of Helaman">
Book of Helaman

The Book of Helaman is one of the books that make up the "Book of Mormon". The book continues the history of the Nephites and the Lamanites "according to the records of Helaman, who was the son of Helaman, and also according to the records of his sons, even down to the coming of Christ" ("The Book of Helaman", preface). According to footnotes, the book covers the time period between c. 52 BCE and 1 BCE.
Narrative.
In 52 BCE the Nephites had trouble over the succession to Pahoran as judge among his sons. He had many sons, but among these, Pahoran Jr., Paanchi and Pacumeni wanted the seat. They stirred up trouble among the people as they campaigned for the position. The people selected Pahoran by acclaim, and Pacumeni assented.
But Paanchi had the backing of the minority and he sought to instigate a rebellion. Before he could make much headway, he was arrested and tried, convicted of sedition, and sentenced to death. The minority sent a hitman named Kishkumen to kill Pahoran as he sat on the bench. The assassination was done in disguise so no one could accuse Kishkumen.
Men loyal to Pahoran gave chase, but Kiskkumen evaded them, and returned to the minority. They all swore to God never to utter a word that Kishkumen had murdered Pahoran. Still, some of the conspirators were found and sentenced to death. Pacumeni was elevated to Judge in place of Pahoran.
In 51 BCE the Lamanites came against the Nephites with a mighty host led by a large man named Coriantumr, descendant of Zarahemla. He was dispatched by Tubaloth, king of the Lamanites. The political turmoil surrounding the succession of Pahoran caused the city of Zarahemla to drop its guard somewhat. Coriantumr slew the guards at the gates, marched inside with his whole army, slew all who opposed them and took possession of the city. Pacumeni was personally slain by Coriantumr against the walls of Zarahemla.
Coriantumr, fresh from this victory, prepared a second phase of his campaign against the land of Zarahemla at large. His next goal was the city of Bountiful in the north of the land. The Nephites in the countryside were not able to assemble themselves into a large enough force to oppose the Lamanites, so they were picked off in detail.
But Moronihah had removed the bulk of the Nephite forces to the border regions, forming a hard crust while leaving the heart of the land largely undefended. Coriantumr was misled by the relative ease of his drive. After learning of the fall of Zarahemla, Moroniahah dispatched Lehi with an army to intercept the Lamanites before they came to Bountiful. In the great battle that followed, even Coriantumr was slain.
When the Lamanites found themselves surrounded on every side by Nephites, and their leader slain, they surrendered. Moronihah re-occupied Zarahemla, and allowed the captured Lamanite soldiers to depart the land in peace.

</doc>
<doc id="14526" url="http://en.wikipedia.org/wiki?curid=14526" title="Irina Krush">
Irina Krush

Irina Krush (Ukrainian: Ірина Круш, Russian: Ири́на Круш; born December 24, 1983) is an American chess International Grandmaster (GM) who has won the U.S. Women's Chess Championship in 1998, 2007, 2010, 2012, 2013, 2014, and 2015. On the March 2015 FIDE rating list for women, Krush has a FIDE rating of 2477, 27th best among active female players, and second among active American female players.
Krush was born in Odessa, USSR (now Ukraine). She learned to play chess at age five, emigrating with her parents to Brooklyn that same year (1989). Krush attended Edward R. Murrow High School in Brooklyn, whose chess team is considered by many to be one of the top high school teams in the U.S.
At age 14 Krush won the 1998 U.S. Women's Chess Championship to become the youngest U.S. Women's Champion ever. She has won the U.S. Championship on six other occasions, in 2007, 2010, 2012, 2013, 2014, and 2015.
Krush became widely known for her series of chess training videos, the "Krushing Attacks" series.
Krush gained an additional measure of fame both inside and outside chess circles during the well-publicized "Kasparov versus the World" chess competition in 1999. Garry Kasparov played the white pieces and the Internet public, via a Microsoft host website, voted on moves for the black pieces, guided by the recommendations of Krush and three of her contemporaries, Étienne Bacrot, Elisabeth Pähtz and Florin Felecan. On the tenth move, Krush suggested a novelty, for which the World Team voted. Kasparov said later that he lost control of the game at that point, and wasn't sure whether he was winning or losing. 
Krush currently plays for the New York Knights in the U.S. Chess League, and both she and her ex-husband Canadian Grandmaster Pascal Charbonneau have played in the United Kingdom league for Guildford-ADC. In 2006 they were students in Paris.
She played first board on the U.S. Women's team in the 38th Chess Olympiad, 2008, when the U.S. team scored a bronze medal.

</doc>
<doc id="14527" url="http://en.wikipedia.org/wiki?curid=14527" title="Institut des Hautes Études Scientifiques">
Institut des Hautes Études Scientifiques

The Institut des Hautes Études Scientifiques (IHÉS; in English: Institute of Advanced Scientific Studies) is a French institute supporting advanced research in mathematics and theoretical physics. It is located in Bures-sur-Yvette just south of Paris. It is now part of the confederal "University of Paris in Saclay" as an advanced studies institute..
History.
The IHÉS, was founded in 1958 by businessman and mathematical physicist Léon Motchane with the help of Robert Oppenheimer and Jean Dieudonné as a research centre in France, on model to the renowned Institute for Advanced Study in Princeton, United States.
The strong personality of Alexandre Grothendieck and the broad sweep of his revolutionizing theories were a dominating feature of the first ten years at the IHÉS. René Thom received an invitation from IHÉS in 1963 and after his appointment remained there until his retirement in 1988. Dennis Sullivan is remembered as one who had a special talent for encouraging fruitful exchanges among visitors and provoking a new and deeper insight into their ideas.
The IHÉS runs a highly regarded mathematical journal, "Publications Mathématiques de l'IHÉS".
IHÉS celebrated its 50th anniversary in 2008 and the 40th anniversary in 1998.
Mathematics faculty.
Some of the top mathematicians who were or are now permanent professors at the IHÉS include Jean Bourgain, Alain Connes, Pierre Deligne, Mikhail Gromov, Alexandre Grothendieck, Oscar Lanford III, Laurent Lafforgue, Maxim Kontsevich, Dennis Sullivan and René Thom. The long-term visitors are Ahmed Abbes, Ofer Gabber, and Christophe Soulé.
Theoretical Physics faculty.
The theoretical or mathematical physicists who were or are now permanent professors at the IHÉS are Louis Michel, Jürg Fröhlich, David Ruelle, Thibault Damour, Nikita Nekrasov, and Vasily Pestun.

</doc>
<doc id="14531" url="http://en.wikipedia.org/wiki?curid=14531" title="Iceland">
Iceland

Iceland (; Icelandic: "Ísland" ]) is a Nordic island country between the North Atlantic and the Arctic Ocean. It has a population of 329,100 and an area of 103000 km2, making it the most sparsely populated country in Europe. The capital and largest city is Reykjavík. Reykjavik and the surrounding areas in the southwest of the country are home to over two-thirds of the population. Iceland is volcanically and geologically active. The interior consists of a plateau characterised by sand and lava fields, mountains and glaciers, while many glacial rivers flow to the sea through the lowlands. Iceland is warmed by the Gulf Stream and has a temperate climate, despite a high latitude just outside the Arctic Circle.
According to "Landnámabók", the settlement of Iceland began in 874 CE when the Norwegian chieftain Ingólfr Arnarson became the first permanent settler on the island. In the following centuries, Scandinavians settled Iceland, bringing with them thralls of Gaelic origin. From 1262 to 1918, Iceland was ruled by Norway and later Denmark. The country became independent in 1918 and a republic in 1944.
Until the 20th century, Iceland relied largely on fishing and agriculture. Industrialisation of the fisheries and Marshall Plan aid following World War II brought prosperity and Iceland became one of the wealthiest and most developed nations in the world. In 1994, Iceland became party to the European Economic Area, which supported diversification into economic and financial services. 
Affected by the ongoing worldwide financial crisis, the nation's entire banking system systemically failed in October 2008, leading to a severe depression, substantial political unrest, the Icesave dispute, and the institution of capital controls. The economy has since made a significant recovery, in large part due to a surge in tourism.
Except for the capital controls, Iceland generally has a free-market economy with relatively low taxes compared to other OECD countries. It maintains a Nordic social welfare system that provides universal health care and tertiary education for its citizens. Iceland ranks highly in economic, political and social stability and equality. In 2013, it was ranked as the 13th most-developed country in the world by the United Nations' Human Development Index.
Icelandic culture is founded upon the nation's Scandinavian heritage. Most Icelanders are descendants of Germanic and Gaelic (Celtic) settlers. Icelandic, a North Germanic language, is descended from Old Norse and is closely related to Faroese and West Norwegian dialects. The country's cultural heritage includes traditional Icelandic cuisine, Icelandic literature and medieval sagas. Iceland has the smallest population of any NATO member and is the only one with no standing army, its lightly armed coast guard being in charge of defence.
History.
Settlement and Commonwealth 874–1262.
According to both Landnámabók and Íslendingabók, Celtic monks known as the Papar lived in Iceland before Scandinavian settlers arrived, possibly members of a Hiberno-Scottish mission. Recent archaeological excavations have revealed the ruins of a cabin in Hafnir on the Reykjanes peninsula. Carbon dating indicates that it was abandoned somewhere between 770 and 880.
Swedish Viking explorer Garðar Svavarsson was the first to circumnavigate Iceland in 870 and establish that it was an island. He stayed over winter and built a house in Húsavík. Garðar departed the following summer but one of his men, Náttfari, decided to stay behind with two slaves. Náttfari settled in what is now known as Náttfaravík and became the first permanent resident of Iceland.
The Norse chieftain Ingólfr Arnarson built his homestead in present-day Reykjavík in the year 874. Ingólfr was followed by many other emigrant settlers, largely Scandinavians and their thralls, many of whom were Irish or Scottish. By 930, most arable land on the island had been claimed; the Althing, a legislative and judicial assembly, was initiated to regulate the Icelandic Commonwealth. Lack of arable land also served impetus to the settlement of Greenland starting in 986. The period of these early settlements coincided with the Medieval Warm Period, when temperatures were similar to those of the early 20th century. At this time about 25% of Iceland was covered with forest compared to 1% in the present day. Christianity was adopted by consensus around 999–1000, although Norse paganism persisted among some segments of the population for some years afterwards.
The Middle Ages.
The Icelandic Commonwealth lasted until the 13th century, when the political system devised by the original settlers proved unable to cope with the increasing power of Icelandic chieftains. The internal struggles and civil strife of the Age of the Sturlungs led to the signing of the Old Covenant in 1262, which ended the Commonwealth and brought Iceland under the Norwegian crown. Possession of Iceland passed to the Kalmar Union in 1415, when the kingdoms of Norway, Denmark and Sweden were united. After the break-up of the union in 1523, it remained a Norwegian dependency, as a part of Denmark–Norway.
In the ensuing centuries, Iceland became one of the poorest countries in Europe. Infertile soil, volcanic eruptions, deforestation and an unforgiving climate made for harsh life in a society where subsistence depended almost entirely on agriculture. The Black Death swept Iceland twice, first in 1402–04 and again in 1494–95. The former outbreak killed 50% to 60% of the population, and the latter 30% to 50%.
Reformation and the Early Modern period.
Around the middle of the 16th century, as part of the Protestant Reformation, King Christian III of Denmark began to impose Lutheranism on all his subjects. Jón Arason, the last Catholic bishop of Hólar, was beheaded in 1550 along with two of his sons. The country subsequently became officially Lutheran and Lutheranism has since remained the dominant religion.
In the 17th and 18th centuries, Denmark imposed harsh trade restrictions on Iceland. Natural disasters, including volcanic eruption and disease, contributed to a decreasing population. Pirates from several countries, including the Barbary Coast, raided its coastal settlements and abducted people into slavery. A great smallpox epidemic in the 18th century killed around a third of the population. In 1783 the Laki volcano erupted, with devastating effects. In the years following the eruption, known as the Mist Hardships (Icelandic: "Móðuharðindin"), over half of all livestock died in the country. Around a quarter of the population died in the ensuing famine.
Independence movement 1814–1918.
In 1814, following the Napoleonic Wars, Denmark-Norway was broken up into two separate kingdoms via the Treaty of Kiel but Iceland remained a Danish dependency. Throughout the 19th century, the country's climate continued to grow colder, resulting in mass emigration to the New World, particularly to the region of Gimli, Manitoba in Canada, which was sometimes referred to as New Iceland. About 15,000 people emigrated, out of a total population of 70,000.
A national consciousness arose in the first half of the 19th century, inspired by romantic and nationalist ideas from mainland Europe. An Icelandic independence movement took shape in the 1850s under the leadership of Jón Sigurðsson, based on the burgeoning Icelandic nationalism inspired by the "Fjölnismenn" and other Danish-educated Icelandic intellectuals. In 1874, Denmark granted Iceland a constitution and limited home rule. This was expanded in 1904, and Hannes Hafstein served as the first Minister for Iceland in the Danish cabinet.
Kingdom of Iceland 1918–1944.
The Danish–Icelandic Act of Union, an agreement with Denmark signed on 1 December 1918 and valid for 25 years, recognised Iceland as a fully sovereign state in a personal union with Denmark. The Government of Iceland established an embassy in Copenhagen and requested that Denmark handle Icelandic foreign policy. Danish embassies around the world displayed two coats of arms and two flags: those of the Kingdom of Denmark and those of the Kingdom of Iceland.
During World War II, Iceland joined Denmark in asserting neutrality. After the German occupation of Denmark on 9 April 1940, the Althing replaced the King with a regent and declared that the Icelandic government should assume the control of foreign affairs and other matters previously handled by Denmark. A month later, British armed forces invaded and occupied the country, violating Icelandic neutrality. In 1941, the occupation was taken over by the United States so that Britain could use its troops elsewhere, an arrangement reluctantly agreed to by the Icelandic authorities.
Independent republic 1944–present.
On 31 December 1943, the Danish–Icelandic Act of Union expired after 25 years. Beginning on 20 May 1944, Icelanders voted in a four-day plebiscite on whether to terminate the personal union with Denmark, abolish the monarchy, and establish a republic. The vote was 97% to end the union, and 95% in favour of the new republican constitution. Iceland formally became a republic on 17 June 1944, with Sveinn Björnsson as its first president.
In 1946, the Allied occupation force left Iceland. The nation formally became a member of NATO on 30 March 1949, amid domestic controversy and riots. On 5 May 1951, a defence agreement was signed with the United States. American troops returned to Iceland as the Iceland Defence Force, and remained throughout the Cold War. The US withdrew the last of its forces on 30 September 2006.
Iceland had prospered during the war. The immediate post-war period was followed by substantial economic growth, driven by industrialisation of the fishing industry and the US Marshall Plan programme, through which Icelanders received the most aid per capita of any European country (at USD 209, with the war-ravaged Netherlands a distant second at USD 109).
The 1970s were marked by the Cod Wars — several disputes with the United Kingdom over Iceland's extension of its fishing limits to 200 miles offshore. Iceland hosted a summit in Reykjavík in 1986 between United States President Ronald Reagan and Soviet Premier Mikhail Gorbachev, during which they took significant steps toward nuclear disarmament. A few years later, Iceland became the first country to recognize the independence of Estonia, Latvia, and Lithuania as they broke away from the USSR. Throughout the 1990s, the country expanded its international role and developed a foreign policy oriented toward humanitarian and peacekeeping causes. To that end, Iceland provided aid and expertise to various NATO-led interventions in Bosnia, Kosovo, and Iraq.
Iceland joined the European Economic Area in 1994, after which the economy was greatly diversified and liberalised. International economic relations increased further after 2001, when Iceland's newly deregulated banks began to raise massive amounts of external debt, contributing to a 32% increase in Iceland's Gross national income between 2002 and 2007.
Economic boom and crisis.
In the years 2003–2007, following the privatization of the banking sector under the government of Davíð Oddsson, Iceland moved toward having an economy based on international investment banking and financial services. It was quickly becoming one of the most prosperous countries in the world but was hit hard by a major financial crisis. The crisis resulted in the greatest migration from Iceland since 1887, with a net emigration of 5,000 people in 2009. Iceland's economy stabilised under the government of Jóhanna Sigurðardóttir, and grew by 1.6% in 2012. Many Icelanders, however, have remained unhappy with the state of the economy and government austerity policies. The centre-right Independence Party was returned to power in coalition with the Progressive Party in the 2013 elections.
Geography.
Iceland is located at the juncture of the North Atlantic and Arctic oceans. The main island is entirely south of the Arctic Circle, which passes through the small Icelandic island of Grímsey off the main island's northern coast. The country lies between latitudes 63° and 67° N, and longitudes 25° and 13° W.
Iceland is closer to continental Europe than to mainland North America; thus, the island is generally included in Europe for historical, political, cultural, and practical reasons. Geologically the island includes parts of both continental plates. The closest body of land is Greenland (290 km). The closest bodies of land in Europe are the Faroe Islands (420 km); Jan Mayen Island (570 km); Shetland and the Outer Hebrides, both about 740 km; and the Scottish mainland and Orkney, both about 750 km. The mainland of Norway is about 970 km away.
Iceland is the world's 18th largest island, and Europe's second largest island after Great Britain. The main island is 101826 km², but the entire country is 103000 km2 in size, of which 62.7% is tundra. There are thirty minor islands in Iceland, including the lightly populated Grímsey and the Vestmannaeyjar archipelago. Lakes and glaciers cover 14.3% of its surface; only 23% is vegetated. The largest lakes are Þórisvatn (Reservoir): 83 – and Þingvallavatn: 82 km2; other important lakes include Lagarfljót and Mývatn. Jökulsárlón is the deepest lake, at 248 m.
Geologically, Iceland is part of the Mid-Atlantic Ridge, a ridge along which the oceanic crust spreads and forms new oceanic crust. This part of the mid-ocean ridge is located above a mantle plume, causing Iceland to be subaerial (above the surface of the sea). The ridge marks the boundary between the Eurasian and North American Plates, and Iceland was created by rifting and accretion through volcanism along the ridge.
Many fjords punctuate Iceland's 4,970-kilometre (3,088-mile) long coastline, which is also where most settlements are situated. The island's interior, the Highlands of Iceland, is a cold and uninhabitable combination of sand, mountains and lava fields. The major towns are the capital city of Reykjavík, along with its outlying towns of Kópavogur, Hafnarfjörður and Garðabær, nearby Reykjanesbær where the international airport is located, and the town of Akureyri in northern Iceland. The island of Grímsey on the Arctic Circle contains the northernmost habitation of Iceland. Iceland has three national parks: Vatnajökull National Park, Snæfellsjökull National Park, and Þingvellir National Park. The country is considered a "strong performer" in environmental protection, having been ranked 13th in Yale University's Environmental Performance Index of 2012.
Geology.
A geologically young land, Iceland is located on both the Iceland hotspot and the Mid-Atlantic Ridge, which runs right through it. This location means that the island is highly geologically active with many volcanoes, notably Hekla, Eldgjá, Herðubreið and Eldfell. The volcanic eruption of Laki in 1783–1784 caused a famine that killed nearly a quarter of the island's population. In addition, the eruption caused dust clouds and haze to appear over most of Europe and parts of Asia and Africa for several months afterward, and affected climates in other areas.
Iceland has many geysers, including Geysir, from which the English word is derived, and the famous Strokkur, which erupts every 5–10 minutes. After a phase of inactivity, Geysir started erupting again after a series of earthquakes in 2000. Geysir has since grown quieter and does not erupt often.
With the widespread availability of geothermal power, and the harnessing of many rivers and waterfalls for hydroelectricity, most residents have access to inexpensive hot water, heating and electricity. The island is composed primarily of basalt, a low-silica lava associated with effusive volcanism as has occurred also in Hawaii. Iceland, however, has a variety of volcanic types (composite and fissure), many producing more evolved lavas such as rhyolite and andesite. Iceland has hundreds of volcanoes with approx. 30 volcanic systems active.
Surtsey, one of the youngest islands in the world, is part of Iceland. Named after Surtr, it rose above the ocean in a series of volcanic eruptions between 8 November 1963 and 5 June 1968. Only scientists researching the growth of new life are allowed to visit the island.
On 21 March 2010, a volcano in Eyjafjallajökull in the south of Iceland erupted for the first time since 1821, forcing 600 people to flee their homes. Additional eruptions on 14 April forced hundreds of people to abandon their homes. The resultant cloud of volcanic ash brought major disruption to air travel across Europe.
Another large eruption occurred on 21 May 2011. This time it was the Grímsvötn volcano, located under the thick ice of Europe's largest glacier, Vatnajökull. Grímsvötn is one of Iceland's most active volcanoes, and this eruption was much more powerful than the 2010 Eyjafjallajökull activity, with ash and lava 20 km hurled into the atmosphere creating a large cloud.
Climate.
The climate of Iceland's coast is subpolar oceanic. The warm North Atlantic Current ensures generally higher annual temperatures than in most places of similar latitude in the world. Regions in the world with similar climates include the Aleutian Islands, the Alaska Peninsula, and Tierra del Fuego, although these regions are closer to the equator. Despite its proximity to the Arctic, the island's coasts remain ice-free through the winter. Ice incursions are rare, the last having occurred on the north coast in 1969.
The climate varies between different parts of the island. Generally speaking, the south coast is warmer, wetter and windier than the north. The Central Highlands are the coldest part of the country. Low-lying inland areas in the north are the most arid. Snowfall in winter is more common in the north than the south.
The highest air temperature recorded was 30.5 °C on 22 June 1939 at Teigarhorn on the southeastern coast. The lowest was −38 °C on 22 January 1918 at Grímsstaðir and Möðrudalur in the northeastern hinterland. The temperature records for Reykjavík are 26.2 °C on 30 July 2008, and −24.5 °C on 21 January 1918.
Biodiversity.
There are around 1,300 known species of insects in Iceland, which is low compared with other countries (over one million species have been described worldwide). The only native land mammal when humans arrived was the Arctic fox, which came to the island at the end of the ice age, walking over the frozen sea. On rare occasions, bats have been carried to the island with the winds, but they are not able to breed there. Polar bears occasionally come over from Greenland, but they are just visitors, and no Icelandic populations exist. There are no native or free-living reptiles or amphibians on the island.
Phytogeographically, Iceland belongs to the Arctic province of the Circumboreal Region within the Boreal Kingdom. Approximately three quarters of the island is barren of vegetation; plant life consists mainly of grassland, which is regularly grazed by livestock. The most common tree native to Iceland is the northern birch ("Betula pubescens"), which formerly formed forests over much of Iceland, along with aspens ("Populus tremula"), rowans ("Sorbus aucuparia"), common junipers ("Juniperus communis") and other smaller trees, mainly willows.
When the island was first settled, it was extensively forested. In the late 12th-century, Ari the Wise, described it in Íslendingabók as "forested from mountain to sea shore". Permanent human settlement greatly disturbed the isolated ecosystem of thin, volcanic soils and limited species diversity. The forests were heavily exploited over the centuries for firewood and timber. Deforestation, climatic deterioration during the Little Ice Age and overgrazing by sheep imported by settlers caused a loss of critical topsoil due to erosion. Today, many farms have been abandoned. Three-quarters of Iceland's hundred thousand square kilometres are affected by soil erosion, eighteen thousand square kilometres so seriously as to be useless. Only a few small birch stands now exist in isolated reserves. The planting of new forests has increased the number of trees, but does not compare to the original forests. Some of the planted forests include introduced species. The tallest tree in Iceland is a sitka spruce planted in 1949 in Kirkjubæjarklaustur; it was measured at 25.2 m in 2013.
The animals of Iceland include the Icelandic sheep, cattle, chickens, goats, the sturdy Icelandic horse, and the Icelandic Sheepdog, all descendants of animals imported by Europeans. Wild mammals include the Arctic fox, mink, mice, rats, rabbits and reindeer. Polar bears occasionally visit the island, travelling on icebergs from Greenland. In June 2008, two polar bears arrived in the same month. Marine mammals include the grey seal ("Halichoerus grypus") and harbor seal ("Phoca vitulina"). Many species of fish live in the ocean waters surrounding Iceland, and the fishing industry is a major part of Iceland's economy, accounting for approximately half of the country's total exports. Birds, especially seabirds, are an important part of Iceland's animal life. Puffins, skuas, and kittiwakes nest on its sea cliffs.
Commercial whaling is practised intermittently along with scientific whale hunts. Whale watching has become an important part of Iceland's economy since 1997.
Politics.
Iceland has a left–right multi-party system. Following the 2013 parliamentary election, the biggest parties are the centre-right Independence Party ("Sjálfstæðisflokkurinn") and the centrist Progressive Party ("Framsóknarflokkurinn"). Other political parties with seats in the Althing are the centre-left Social Democratic Alliance ("Samfylkingin"), Left-Green Movement ("Vinstrihreyfingin – grænt framboð"), Bright Future ("Björt framtíð"), and the Pirate Party of Iceland ("Píratar"). Many other parties exist on the municipal level, most of which run only locally in a single municipality.
Iceland was the first country in the world to have a political party formed and led entirely by women. Known as the Women's List or Women's Alliance ("Kvennalistinn"), it was founded in 1983 to advance the political, economic, and social needs of women. After participating in its first parliamentary elections, the Women's List helped increase the proportion of female parliamentarians by 15%. Although it disbanded in 1999, merging with the Social Democratic Alliance, it left a lasting influence on Iceland's politics: every major party has a 40% quota for women, and in 2009 nearly a third of members of parliament were female, compared to the global average of 16%.
In 2011 Iceland was ranked 2nd in the strength of its democratic institutions and 13th in government transparency. The country has a high level of civic participation, with 81.4% voter turnout during the most recent elections, compared to an OECD average of 72%. However, only 50% of Icelanders say they trust their political institutions, slightly less than the OECD average of 56% (and most probably a consequence of the political scandals in the wake of the Icelandic financial crisis).
Government.
Iceland is a representative democracy and a parliamentary republic. The modern parliament, "Alþingi" (English: Althing), was founded in 1845 as an advisory body to the Danish monarch. It was widely seen as a re-establishment of the assembly founded in 930 in the Commonwealth period and suspended in 1799. Consequently, "it is arguably the world's oldest parliamentary democracy." It currently has 63 members, elected for a maximum period of four years. The president is elected by popular vote for a term of four years, with no term limit. The elections for president, the Althing and local municipal councils are all held separately every four years.
The president of Iceland is a largely ceremonial head of state and serves as a diplomat, but can veto laws voted by the parliament and put them to a national referendum. The current president is Ólafur Ragnar Grímsson. The head of government is the prime minister (currently Sigmundur Davíð Gunnlaugsson) who, together with the cabinet, is responsible for executive government. The cabinet is appointed by the president after a general election to the Althing; however, the appointment is usually negotiated by the leaders of the political parties, who decide among themselves after discussions which parties can form the cabinet and how its seats are to be distributed, under the condition that it has a majority support in the Althing. Only when the party leaders are unable to reach a conclusion by themselves within a reasonable time span does the president exercise this power and appoint the cabinet personally. This has not happened since the republic was founded in 1944, but in 1942 regent Sveinn Björnsson, who had been installed in that position by the Althing in 1941, appointed a non-parliamentary government. The regent had, for all practical purposes, the position of a president, and Sveinn would later become the country's first president in 1944.
The governments of Iceland have always been coalition governments, with two or more parties involved, as no single political party has ever received a majority of seats in the Althing throughout the republican period. The extent of the political power possessed by the office of the president is disputed by legal scholars in Iceland; several provisions of the constitution appear to give the president some important powers, but other provisions and traditions suggest differently. In 1980, Icelanders elected Vigdís Finnbogadóttir as president, the world's first directly elected female head of state. She retired from office in 1996. In 2009, Iceland became the first country with an openly gay head of government when Jóhanna Sigurðardóttir became prime minister.
Administrative divisions.
Iceland is divided into regions, constituencies and municipalities. There are eight regions which are primarily used for statistical purposes; the district court jurisdictions also use an older version of this division. Until 2003, the constituencies for the parliamentary elections were the same as the regions, but by an amendment to the constitution, they were changed to the current six constituencies:
The redistricting change was made in order to balance the weight of different districts of the country, since previously a vote cast in the sparsely populated areas around the country would count much more than a vote cast in the Reykjavík city area. The imbalance between districts has been reduced by the new system, but still exists.
There are 74 municipalities in Iceland which govern local matters like schools, transport and zoning. These are the actual second-level subdivisions of Iceland, as the constituencies have no relevance except in elections and for statistical purposes. Reykjavík is by far the most populous municipality, about four times more populous than Kópavogur, the second one.
Foreign relations.
Iceland, which is a member of the UN, NATO, EFTA and OECD, maintains diplomatic and commercial relations with practically all nations, but its ties with the Nordic countries, Germany, the United States, Canada and the other NATO nations are particularly close. Historically, due to cultural, economic and linguistic similarities, Iceland is a Nordic country, and it participates in intergovernmental cooperation through the Nordic Council.
Iceland is a member of the European Economic Area (EEA), which allows the country access to the single market of the European Union (EU). It is not a member of the EU, but in July 2009 the Icelandic parliament, the Althing, voted in favour of application for EU membership and officially applied on 17 July 2009. However in 2013, opinion polls showed that many Icelanders were now against joining the EU; following recent elections the two parties that formed the island's new government – the centrist Progressive Party and the right-wing Independence Party – announced they would hold a referendum on EU membership.
Military.
Iceland has no standing army. The U.S. Air Force maintained four to six interceptor aircraft at the Keflavík base, until they were withdrawn on 30 September 2006. Since May 2008, NATO nations have periodically deployed fighters to patrol Icelandic airspace under the Icelandic Air Policing mission. Iceland supported the 2003 invasion of Iraq despite much domestic controversy, deploying a Coast Guard EOD team to Iraq which was replaced later by members of the Iceland Crisis Response Unit. Iceland has also participated in the ongoing conflict in Afghanistan and the 1999 NATO bombing of Yugoslavia. Despite the ongoing financial crisis the first new patrol ship in decades was launched on 29 April 2009.
Icelanders remain especially proud of their role in hosting the historic 1986 Reagan–Gorbachev summit in Reykjavík, which set the stage for the end of the Cold War. Iceland's principal historical international disputes involved disagreements over fishing rights. Conflict with the United Kingdom led to a series of so-called Cod Wars in 1952–1956 due to the extension of Iceland's fishing zone from 3 to, 1958–61 following a further extension to 12 nmi, 1972–73 with another extension to 50 nmi; and in 1975–76 another extension to 200 nmi.
According to the Global Peace Index, Iceland is the most peaceful country in the world, due to its lack of armed forces, low crime rate, and high level of socio-political stability.
Economy.
In 2007, Iceland was the seventh most productive country in the world per capita (US$54,858), and the fifth most productive by GDP at purchasing power parity ($40,112). About 85 percent of total primary energy supply in Iceland is derived from domestically produced renewable energy sources. Utilization of abundant hydroelectric and geothermal power has made Iceland the world's largest electricity producer per capita. As a result of its commitment to renewable energy, the 2014 Global Green Economy Index ranked Iceland among the top 10 greenest economies in the world.
Historically, Iceland's economy depended heavily on fishing, which still provides 40% of export earnings and employs 7% of the work force. The economy is vulnerable to declining fish stocks and drops in world prices for its main material exports: fish and fish products, aluminium, and ferrosilicon. Whaling in Iceland has been historically significant. Iceland still relies heavily on fishing, but its importance is diminishing from an export share of 90% in the 1960s to 40% in 2006.
Until the 20th century, Iceland was among the poorest countries in Western Europe. Currently, it remains one of the most developed countries in the world. Strong economic growth had led Iceland to be ranked first in the United Nations' Human Development Index report for 2007/2008, although as of 2011 its HDI rating had fallen to 14th place as a result of the economic crisis. Nevertheless, according to the Economist Intelligence Index of 2011, Iceland has the 2nd highest quality of life in the world. Based on the Gini coefficient, Iceland also has one of the lowest rates of income inequality in the world, and when adjusted for inequality, its HDI ranking climbs to 5th place. Iceland's unemployment rate has declined consistently since the crisis, with 4.8% of the labour force being unemployed as of June 2012, compared to 6% in 2011 and 8.1% in 2010.
Many political parties remain opposed to EU membership, primarily due to Icelanders' concern about losing control over their natural resources (particularly fisheries). The national currency of Iceland is the Icelandic króna (ISK).
A poll released on 5 March 2010 by Capacent Gallup showed that 31% of respondents were in favour of adopting the euro and 69% opposed.
Another Capacent Gallup poll conducted in February 2012 found that 67.4% of Icelanders would reject EU membership in a referendum.
Iceland's economy has been diversifying into manufacturing and service industries in the last decade, including software production, biotechnology, and finance; industry accounts for around a quarter of economic activity, while services comprise close to 70%. Despite the decision to resume commercial whale hunting in 2006, the tourism sector is expanding, especially in ecotourism and whale-watching. On average, Iceland receives around 1.1 million visitors annually, which is more than three times the native population. Iceland's agriculture industry, accounting for 5.4% of GDP, consists mainly of potatoes, green vegetables (in greenhouses), mutton and dairy products. The financial centre is Borgartún in Reykjavík, which hosts a large number of companies and three investment banks. Iceland's stock market, the Iceland Stock Exchange (ISE), was established in 1985.
Iceland is ranked 27th in the 2012 Index of Economic Freedom, lower than in prior years but still among the freest in the world. As of 2012, it ranks 30th in the World Economic Forum's Global Competitive Index, one place higher than in 2011. According to INSEAD's Global Innovation Index, Iceland is the 11th most innovative country in the world. Unlike most Western European countries, Iceland has a flat tax system: the main personal income tax rate is a flat 22.75%, and combined with municipal taxes, the total tax rate equals no more than 35.7%, not including the many deductions that are available. The corporate tax rate is a flat 18%, one of the lowest in the world. There is also a value added tax, whereas a net wealth tax was eliminated in 2006. Employment regulations are relatively flexible and the labour market is one of the freest in the world. Property rights are strong and Iceland is one of the few countries where they are applied to fishery management. Like other welfare states, taxpayers pay various subsidies to each other, but with spending being less than in most European countries.
Despite low tax rates, agricultural assistance is the highest among OECD countries and a potential impediment to structural change. Also, health care and education spending have relatively poor returns by OECD measures, though improvements have been made in both areas. The OECD "Economic Survey of Iceland 2008" had highlighted Iceland's challenges in currency and macroeconomic policy. There was a currency crisis that started in the spring of 2008, and on 6 October trading in Iceland's banks was suspended as the government battled to save the economy. The latest assessment by the OECD determined that Iceland has made progress in many areas, particularly in creating a sustainable fiscal policy and restoring the health of the financial sector; however, challenges remain in making the fishing industry more efficient and sustainable, as well as in improving monetary policy in order to address inflation. Iceland's public debt remains around 120% as of 2012, the 10th highest in the world by proportion of national GDP.
Economic contraction.
Iceland had been hit especially hard by the Great Recession that began in December 2007, because of the failure of its banking system and a subsequent economic crisis. Before the crash of the country's three largest banks, Glitnir, Landsbanki and Kaupthing, their combined debt exceeded approximately six times the nation's gross domestic product of €14 billion ($19 billion). In October 2008, the Icelandic parliament passed emergency legislation to minimise the impact of the Financial crisis. The Financial Supervisory Authority of Iceland used permission granted by the emergency legislation to take over the domestic operations of the three largest banks. Icelandic officials, including central bank governor Davíð Oddsson, stated that the state did not intend to take over any of the banks' foreign debts or assets. Instead, new banks were established around the domestic operations of the banks, and the old banks will be run into bankruptcy.
On 28 October 2008, the Icelandic government raised interest rates to 18% (as of August 2010, it was 7%), a move which was forced in part by the terms of acquiring a loan from International Monetary Fund (IMF). After the rate hike, trading on the Icelandic króna finally resumed on the open market, with valuation at around 250 ISK per Euro, less than one-third the value of the 1:70 exchange rate during most of 2008, and a significant drop from the 1:150 exchange ratio of the week before. On 20 November 2008, the Nordic countries agreed to lend Iceland $2.5 billion.
On 26 January 2009, the coalition government collapsed due to the public dissent over the handling of the financial crisis. A new left-wing government was formed a week later and immediately set about removing Central Bank governor Davíð Oddsson and his aides from the bank through changes in law. Davíð was removed on 26 February 2009 in the wake of protests outside the Central Bank.
Thousands of Icelanders have moved from the country after the collapse, and many of those moved to Norway. In 2005, 293 people moved from Iceland to Norway; in 2009, the figure was 1,625. In April 2010, the Icelandic Parliament‘s Special Investigation Commission published the findings of its investigation, revealing the extent of control fraud in this crisis. By June 2012, Landsbanki managed to repay about half of the Icesave debt.
According to Bloomberg, Iceland is on the trajectory of 2% unemployment as a result of crisis-management decisions made back in 2008, including allowing the banks to fail.
Transport.
Iceland has a high level of car ownership per capita; with a car for every 1.5 inhabitants; it is the main form of transport. Iceland has 13034 km of administered roads, of which 4617 km are paved and 8338 km are not. A great number of roads remain unpaved, mostly little-used rural roads. The road speed limits are 50 km/h in towns, 80 km/h on gravel country roads and 90 km/h on hard-surfaced roads. Iceland currently has no railways.
Route 1, or the Ring Road (Icelandic: "Þjóðvegur 1" or "Hringvegur"), was completed in 1974, and is a main road that runs around Iceland and connects all the inhabited parts of the island, with the interior of the island being uninhabited. This paved road is 1337 km long with one lane in each direction, except near larger towns and cities and in the Hvalfjörður Tunnel (also the site of a toll) where it has more lanes. Many bridges on it, especially in the north and east, are single lane and made of timber and/or steel.
The main hub for international transport is Keflavík International Airport, which serves Reykjavík and the country in general. It is 48 km to the west of Reykjavík. Domestic flights, flights to Greenland and the Faroe Islands, and business flights operate mostly out of Reykjavík Airport, which lies in the city centre. Most general aviation traffic is also in Reykjavík. There are 103 registered airports and airfields in Iceland; most of them are unpaved and located in rural areas. The biggest airport in Iceland is Keflavík International Airport and the biggest airfield is Geitamelur, a four-runway field around 100 km east of Reykjavík, dedicated exclusively to gliding. There are a number of international airlines that fly to and from Iceland regularly.
Energy.
Renewable sources—geothermal and hydropower—provide effectively all of Iceland's electricity and around 85% of the nation's total primary energy consumption, with most of the remainder consisting of imported oil products used in transportation and in the fishing fleet. Iceland expects to be energy-independent by 2050. Iceland's largest geothermal power plants are Hellisheiði and Nesjavellir, while Kárahnjúkar Hydropower Plant is the country's largest hydroelectric power station. When the Kárahnjúkavirkjun started operating, Iceland became the world's largest electricity producer per capita.
Icelanders emit 6.29 tonnes of CO2 in 2009 equivalent of greenhouse gases per capita. Iceland is one of the few countries that have filling stations dispensing hydrogen fuel for cars powered by fuel cells. It is also one of a few countries currently capable of producing hydrogen in adequate quantities at a reasonable cost, because of Iceland's plentiful renewable sources of energy.
On 22 January 2009, Iceland announced its first round of offshore licences for companies wanting to conduct hydrocarbon exploration and production in a region northeast of Iceland, known as the Dreki area. Two exploration licenses have been awarded.
As of 2012, the government of Iceland is in talks with the government of United Kingdom about the possibility of constructing a high-voltage direct-current connector for transmission of electricity between the two countries. Such a cable would give Iceland access to a market where electricity prices have generally been much higher than those in Iceland. Iceland has considerable renewable energy resources, especially geothermal energy and hydropower resources, and most of the potential has not been developed, partly because there is not enough demand for additional electricity generation capacity from the residents and industry of Iceland, but the United Kingdom is interested in importing inexpensive electricity from renewable sources of energy, and this could lead to further development of the energy resources.
Education and science.
The Ministry of Education, Science and Culture is responsible for the policies and methods that schools must use, and they issue the National Curriculum Guidelines. However, playschools, primary schools, and lower secondary schools are funded and administered by the municipalities. The government does allow citizens to Home educate their children, however under a very strict set of demands. Students must stick to the government mandated curriculum, and the parent teaching must acquire a government approved teaching certificate.
Nursery school, or "leikskóli", is non-compulsory education for children younger than six years, and is the first step in the education system. The current legislation concerning playschools was passed in 1994. They are also responsible for ensuring that the curriculum is suitable so as to make the transition into compulsory education as easy as possible.
Compulsory education, or "grunnskóli", comprises primary and lower secondary education, which often is conducted at the same institution. Education is mandatory by law for children aged from 6 to 16 years. The school year lasts nine months, beginning between 21 August and 1 September, ending between 31 May and 10 June. The minimum number of school days was once 170, but after a new teachers' wage contract, it increased to 180. Lessons take place five days a week. All public schools have mandatory education in Christianity, although an exemption may be considered by the Minister of Education.
Upper secondary education, or "framhaldsskóli", follows lower secondary education. These schools are also known as gymnasia in English. Though not compulsory, everyone who has had a compulsory education has the right to upper secondary education. This stage of education is governed by the Upper Secondary School Act of 1996. All schools in Iceland are mixed sex schools. The largest seat of higher education is the University of Iceland, which has its main campus in central Reykjavík. Other schools offering university-level instruction include Reykjavík University, University of Akureyri, Agricultural University of Iceland and Bifröst University.
An OECD assessment found 64% of Icelanders aged 25–64 have earned the equivalent of a high-school degree, which is lower than the OECD average of 73%. Among 25–34 year-olds, only 69% have earned the equivalent of a high-school degree, significantly lower than the OECD average of 80%. Nevertheless, Iceland's education system is considered to be of excellent quality: the Programme for International Student Assessment currently ranks it as the 16th best performing, above the OECD average. Students were particularly proficient in reading and math.
According to a 2013 Eurostat report by the European Commission, Iceland spends around 3.11% of its GDP on scientific research and development (R&D), over 1 percentage point higher than the EU average of 2.03%, and has set a target of 4% to be reached by 2020. A 2010 UNESCO report found that out of 72 countries that spend the most on R&D (100 million US dollars or more), Iceland ranked 9th by proportion of GDP, tied with Taiwan, Switzerland, and Germany and ahead of France, the UK, and Canada.
Demographics.
The original population of Iceland was of Nordic and Gaelic origin. This is evident from literary evidence dating from the settlement period as well as from later scientific studies such as blood type and genetic analyses. One such genetics study has indicated that the majority of the male settlers were of Nordic origin while the majority of the women were of Gaelic origin.
Iceland has extensive genealogical records dating back to the late 17th century and fragmentary records extending back to the Age of Settlement. The biopharmaceutical company deCODE genetics has funded the creation of a genealogy database which attempts to cover all of Iceland's known inhabitants. It views the database, called "Íslendingabók", as a valuable tool for conducting research on genetic diseases, given the relative isolation of Iceland's population.
The population of the island is believed to have varied from 40,000–60,000 in the period ranging from initial settlement until the mid-19th century. During that time, cold winters, ash fall from volcanic eruptions, and bubonic plagues adversely affected the population several times. There were 37 famine years in Iceland between 1500 and 1804. The first census was carried out in 1703 and revealed that the population was then 50,358. After the destructive volcanic eruptions of the Laki volcano during 1783–84, the population reached a low of about 40,000. Improving living conditions have triggered a rapid increase in population since the mid-19th century—from about 60,000 in 1850 to 320,000 in 2008. Iceland has a relatively young population for a developed country, with one out of five people being 14 years-old or younger. With a fertility rate of 2.1, Iceland is one of only a few European countries with a birth rate sufficient for long-term population growth (see table on the left).
In December 2007, 33,678 people (13.5% of the total population) living in Iceland had been born abroad, including children of Icelandic parents living abroad. Around 19,000 people (6% of the population) held foreign citizenship. Polish people make up the largest minority group by a considerable margin, and still form the bulk of the foreign workforce. About 8,000 Poles now live in Iceland, 1,500 of them in Reyðarfjörður where they make up 75% of the workforce who are constructing the Fjarðarál aluminium plant. The recent increase in immigration has been credited to a labour shortage due to the booming economy at the time, as well as to the lifting of restrictions on the movement of people from the countries that were a part of the 2004 enlargement of the European Union. Large-scale construction projects in the east of Iceland (see Kárahnjúkar Hydropower Plant) have also brought in many people whose stay is expected to be temporary. Many Polish immigrants were also considering leaving in 2008 as a result of the Icelandic financial crisis.
The southwest corner of Iceland is the most densely populated region. It is also the location of the capital Reykjavík, the northernmost national capital in the world. The largest towns outside the Greater Reykjavík area are Akureyri and Reykjanesbær, although the latter is relatively close to the capital.
Some 500 Icelanders under the leadership of Erik the Red colonised Greenland among the existing paleo-Eskimo inhabitants in the late 10th century. The total population reached a high point of perhaps 5,000 and developed independent institutions before disappearing by 1500. People from Greenland attempted to set up a colony at Vinland in North America, but it was abandoned in the face of hostility from the indigenous residents. Emigration to the United States and Canada began in the 1870s. s of 2006[ [update]], Canada had over 88,000 people of Icelandic descent, while there are more than 40,000 Americans of Icelandic descent, according to the 2000 US census.
Urbanisation.
Iceland's 10 most populous urban areas:
Language.
Iceland's official written and spoken language is Icelandic, a North Germanic language descended from Old Norse. In grammar and vocabulary, it has changed less from Old Norse than the other Nordic languages; Icelandic has preserved more verb and noun inflection, and has to a considerable extent developed new vocabulary based on native roots rather than borrowings from other languages. The puristic tendency in the development of Icelandic vocabulary is to a large degree a result of conscious language planning, in addition to centuries of isolation. Icelandic is the only living language to retain the use of the runic letter Þ in Latin script. The closest living relative of the Icelandic language is Faroese.
Icelandic Sign Language was officially recognised as a minority language in 2011. In education, its use for Iceland's deaf community is regulated by the "National Curriculum Guide".
English and Danish are compulsory subjects in the school curriculum. Both languages are widely understood and spoken. Other commonly spoken languages are Swedish, Norwegian, German and French. Danish is mostly spoken in a way largely comprehensible to Swedes and Norwegians—it is often referred to as "skandinavíska" (i. e. "Scandinavian") in Iceland.
Rather than using family names, as is the usual custom in most western nations, Icelanders carry patronymic/matronymic surnames, patronyms being far more commonly practiced. Patronymic last names are based on the first name of the father, while matronymic names are based on the first name of the mother. These follow the person's given name, e.g. "Elísabet Jónsdóttir" ("Elísabet, Jón's daughter" (Jón, being the father)) or "Ólafur Katrínarson" ("Ólafur, Katrín's son" (Katrín being the mother)). Consequently, Icelanders refer to one another by their given name, and the Icelandic telephone directory is listed alphabetically by first name rather than by surname.
Health.
Iceland has a universal health care system that is administered by its Ministry of Welfare (Icelandic: "Velferðarráðuneytið") and paid for mostly by taxes (85%) and to a lesser extent by service fees (15%). Unlike most developed nations, there are no private hospitals, and private insurance is practically nonexistent.
A considerable portion of the government budget is assigned to health care, and Iceland ranks 11th in health care expenditures as a percentage of GDP and 14th in spending per capita. Over all, the country’s health care system is one of the best performing in the world, ranked 15th by the World Health Organization. According to an OECD report, Iceland devotes far more resources to healthcare than most industrialised nations. As of 2009, Iceland had 3.7 doctors per 1,000 people (compared with an average of 3.1 in OECD countries) and 15.3 nurses per 1,000 people (compared with an OECD average of 8.4).
Icelanders are among the world’s healthiest people, with 81% reporting to be in good health, according to an OECD survey. Although it is a growing problem, obesity is not as prevalent as in other developed countries, infant mortality is one of the lowest in the world, and the proportion of the population that smokes is lower than the OECD average. The average life expectancy is 81.8 (compared to an OECD average of 79.5), the 4th highest in the world.
Additionally, Iceland has a very low level of pollution, thanks to an overwhelming reliance on cleaner geothermal energy, a low population density, and a high level of environmental consciousness among citizens. According to an OECD assessment, the amount of toxic material in the atmosphere is far lower than any other industrialised country measured.
Religion.
Icelanders have freedom of religion under the constitution of Iceland, though the Church of Iceland, a Lutheran body, is the state church. The Registers Iceland keeps account of the religious affiliation of every Icelandic citizen. In 2015, Icelanders were divided into religious groups as follows:
Iceland is a very secular country: as with other Nordic nations, religious attendance is relatively low. The above statistics represent administrative membership of religious organisations, which does not necessarily reflect the belief demographics of the population of Iceland. According to a study published in 2001, 23% of the inhabitants are either atheist or agnostic. A Gallup poll conducted in 2012 found that 57% of Icelanders considered themselves "a religious person", 31% consider themselves "a non religious person", while 10% define themselves as "a convinced atheist", placing Iceland among the top 10 atheist populations in the world.
Culture.
Icelandic culture has its roots in North Germanic traditions. Icelandic literature is popular, in particular the sagas and eddas that were written during the High and Late Middle Ages. Centuries of isolation have helped to insulate the country's Nordic culture from external influence; a prominent example is the preservation of the Icelandic language, which remains the closest to Old Norse of all modern Scandinavian languages.
In contrast to other Nordic countries, Icelanders place relatively great importance on independence and self-sufficiency; in a public opinion analysis conducted by the European Commission, over 85% of Icelanders found independence to be "very important," compared to 47% of Norwegians, 49% of Danes, and an average of 53% for the EU25. Icelanders also have a very strong work ethic, working some of the longest hours of any industrialised nation.
According to a poll conducted by the OECD, 66% of Icelanders were satisfied with their lives, while 70% believed that their lives will be satisfying in the future. Similarly, 83% of people in Iceland reported having more positive experiences in an average day than negative ones, compared to an OECD average of 72%, which makes Iceland one of the happiest countries in the OECD. A more recent 2012 survey found that around three quarters of respondents stated they were satisfied with their lives, compared to a global average of about 53%.
Iceland is liberal with regard to LGBT rights issues. In 1996, the Icelandic parliament passed legislation to create registered partnerships for same-sex couples, conferring nearly all the rights and benefits of marriage. In 2006, parliament voted unanimously to grant same-sex couples the same rights as heterosexual couples in adoption, parenting and assisted insemination treatment. On 11 June 2010, the Icelandic parliament amended the marriage law, making it gender neutral and defining marriage as between two individuals, making Iceland one of the first countries in the world to legalise same-sex marriage. The law took effect on 27 June 2010. The amendment to the law also means registered partnerships for same-sex couples are now no longer possible, and marriage is their only option—identical to the existing situation for opposite-sex couples.
Icelanders are known for their deep sense of community: an OECD survey found that 98% believe they know someone they could rely on in a time of need, higher than in any other industrialised country. Similarly, only 6% reported "rarely" or "never" socializing with others. This high level of social cohesion is attributed to the small size and homogeneity of the population, as well as to a long history of harsh survival in an isolated environment, which reinforced the importance of unity and cooperation.
Egalitarianism is highly valued among the people of Iceland, with income inequality being among the lowest in the world. The constitution explicitly prohibits the enactment of noble privileges, titles, and ranks. Everyone is addressed by their first name. As in other Nordic countries, equality between the sexes is very high; Iceland is consistently ranked among the top three countries in the world for women to live in.
Literature.
Iceland's best-known classical works of literature are the Icelanders' sagas, prose epics set in Iceland's age of settlement. The most famous of these include "Njáls saga", about an epic blood feud, and "Grænlendinga saga" and "Eiríks saga", describing the discovery and settlement of Greenland and Vinland (modern Newfoundland). "Egils saga", "Laxdæla saga", "Grettis saga", "Gísla saga" and "Gunnlaugs saga ormstungu" are also notable and popular Icelanders' sagas.
A translation of the Bible was published in the 16th century. Important compositions since the 15th to the 19th century include sacred verse, most famously the Passion Hymns of Hallgrímur Pétursson, and "rímur", rhyming epic poems. Originating in the 14th century, "rímur" were popular into the 19th century, when the development of new literary forms was provoked by the influential, National-Romantic writer Jónas Hallgrímsson. In recent times, Iceland has produced many great writers, the best-known of whom is arguably Halldór Laxness, who received the Nobel Prize in Literature in 1955 (the only Icelander to win a Nobel Prize thus far). Steinn Steinarr was an influential modernist poet during the early 20th century who remains popular.
Icelanders are avid consumers of literature, with the highest number of bookstores per capita in the world. For its size, Iceland imports and translates more international literature than any other nation. Iceland also has the highest per capita publication of books and magazines, and around 10% of the population will publish a book in their lifetimes.
Art.
The distinctive rendition of the Icelandic landscape by its painters can be linked to nationalism and the movement for home rule and independence, which was very active in the mid-19th century.
Contemporary Icelandic painting is typically traced to the work of Þórarinn Þorláksson, who, following formal training in art in the 1890s in Copenhagen, returned to Iceland to paint and exhibit works from 1900 to his death in 1924, almost exclusively portraying the Icelandic landscape. Several other Icelandic men and women artists studied at Royal Danish Academy of Fine Arts at that time, including Ásgrímur Jónsson, who together with Þórarinn created a distinctive portrayal of Iceland's landscape in a romantic naturalistic style. Other landscape artists quickly followed in the footsteps of Þórarinn and Ásgrímur. These included Jóhannes Kjarval and Júlíana Sveinsdóttir. Kjarval in particular is noted for the distinct techniques in the application of paint that he developed in a concerted effort to render the characteristic volcanic rock that dominates the Icelandic environment. Einar Hákonarson is an expressionistic and figurative painter who by some is considered to have brought the figure back into Icelandic painting. In the 1980s, many Icelandic artists worked with the subject of the new painting in their work.
In the recent years artistic practice has multiplied, and the Icelandic art scene has become a setting for many large scale projects and exhibitions. The artist run gallery space Kling og Bang, members of which later ran the studio complex and exhibition venue Klink og Bank, has been a significant part of the trend of self-organised spaces, exhibitions and projects. The Living Art Museum, Reykjavík Municipal Art Museum, Reykjavík Art Museum and the National Gallery of Iceland are the larger, more established institutions, curating shows and festivals.
Music.
Icelandic music is related to Nordic music, and includes vibrant folk and pop traditions, medieval music group Voces Thules, alternative and indie rock bands The Sugarcubes and Of Monsters and Men, jazz fusion band Mezzoforte, musicians Björk and Emilíana Torrini, and post-rock band Sigur Rós. The national anthem of Iceland is "Lofsöngur", written by Matthías Jochumsson, with music by Sveinbjörn Sveinbjörnsson.
Traditional Icelandic music is strongly religious. Hymns, both religious and secular, are a particularly well-developed form of music, due to the scarcity of musical instruments throughout much of Iceland's history. Hallgrímur Pétursson wrote many Protestant hymns in the 17th century. Icelandic music was modernised in the 19th century, when Magnús Stephensen brought pipe organs, which were followed by harmoniums. Other vital traditions of Icelandic music are epic alliterative and rhyming ballads called rímur. Rímur are epic tales, usually a cappella, which can be traced back to skaldic poetry, using complex metaphors and elaborate rhyme schemes. The best known rímur poet of the 19th century was Sigurður Breiðfjörð (1798–1846). A modern revitalisation of the tradition began in 1929 with the formation of Iðunn.
Icelandic contemporary music consists of a big group of bands, ranging from pop-rock groups such as Bang Gang, Quarashi and Amiina to solo ballad singers like Bubbi Morthens, Megas and Björgvin Halldórsson. Independent music is very strong in Iceland, with bands such as múm, The Sugarcubes, HAM, Of Monsters and Men, Sigur Rós, and Viking metal band Skálmöld, as well as solo artists Emilíana Torrini and Mugison.
Some Icelandic jazz musicians and jazz bands have earned a reputation outside Iceland. Perhaps best known is the jazz fusion band Mezzoforte and Los Angeles-based jazz vocalist Anna Mjöll. Many Icelandic artists and bands have enjoyed international success, most notably Björk and Sigur Rós but also Quarashi, Hera, Ampop, Mínus and múm. The main music festival is arguably Iceland Airwaves, an annual event on the Icelandic music scene, where Icelandic bands along with foreign ones play in the clubs of Reykjavík for a week. Electronic musicians include ones such as Thor and GusGus.
Media.
Iceland's largest television stations are the state-run Sjónvarpið and the privately owned Stöð 2 and SkjárEinn. Smaller stations exist, many of them local. Radio is broadcast throughout the country, including some parts of the interior. The main radio stations are Rás 1, Rás 2, X-ið 977, Bylgjan and FM957. The daily newspapers are Morgunblaðið and Fréttablaðið. The most popular websites are the news sites Vísir and Mbl.is.
Iceland is home to "LazyTown" (Icelandic: "Latibær"), a children's television programme created by Magnús Scheving. It has become a very popular programme for children and adults and is shown in over 100 countries, including the UK, the Americas and Sweden. The "LazyTown" studios are located in Garðabær.
In 1992 the Icelandic film industry achieved its greatest recognition hitherto, when Friðrik Þór Friðriksson was nominated for the Academy Award for Best Foreign Language Film for his film, "Children of Nature". Actress Guðrún S. Gísladóttir, who is Icelandic, played one of the major roles in Russian filmmaker Andrei Tarkovsky's 1986 film, "The Sacrifice". Anita Briem, known for her performance in Showtime's "The Tudors", is also Icelandic. Briem starred in the 2008 film "Journey to the Center of the Earth", which shot scenes in Iceland. The 2002 James Bond movie "Die Another Day" is set for a large-part in Iceland. Christopher Nolan's 2014 film, "Interstellar" was also filmed in Iceland for some of its scenes.
On 17 June 2010, the parliament passed the Icelandic Modern Media Initiative, a resolution proposing greater protection of free speech rights and the identity of journalists and whistle-blowers, the strongest journalist protection law in the world. According to a 2011 report by Freedom House, Iceland is one of the highest ranked countries in press freedom.
CCP Games, developers of the critically acclaimed EVE Online and Dust 514, is headquartered in Reykjavík. CCP Games hosts the third most populated MMO in the world, which also has the largest total game area for an online game.
Iceland has a highly developed internet culture, with around 95% of the population having internet access, the highest proportion in the world. Iceland ranked 12th in the World Economic Forum's 2009–2010 Network Readiness Index, which measures a country's ability to competitively exploit communications technology. The United Nations International Telecommunication Union ranks the country 3rd in its development of information and communications technology, having moved up four places between 2008 and 2010. In February 2013 the country (ministry of the interior) was researching possible methods to protect children in regards to Internet pornography, claiming that pornography online is a threat to children as it supports child slavery and abuse. Strong voices within the community expressed concerns with this, stating that it is impossible to block access to child pornography without compromising the freedom of speech.
Cuisine.
Much of Iceland's cuisine is based on fish, lamb, and dairy products, with little to no utilization of herbs or spices. Due to the island's climate, fruits and vegetables are not generally a component of traditional dishes, although the use of greenhouses has made them more common in contemporary food. Þorramatur is a selection of traditional cuisine consisting of many dishes, and is usually consumed around the month of Þorri, which begins on the first Friday after 19 January. Traditional dishes also include skyr, hákarl (cured shark), cured ram, singed sheep heads, and black pudding. Puffin is considered a local delicacy that is often prepared through broiling.
Breakfast usually consists of pancakes, cereal, fruit, and coffee, while lunch may take the form of a smörgåsbord. The main meal of the day for most Icelanders is dinner, which usually involves fish or lamb as the main course. Seafood is central to most Icelandic cooking, particularly cod and haddock but also salmon, herring, and halibut. It is often prepared in a wide variety of ways, either smoked, pickled, boiled, or dried. Lamb is by far the most common meat, and it tends to be either smoke-cured (known as "hangikjöt") or salt-preserved ("saltkjöt"). Many older dishes make use of every part of the sheep, such as "slátur", which consists of offal (internal organs and entrails) minced together with blood and served in sheep stomach. Additionally, boiled or mashed potatoes, pickled cabbage, green beans, and rye bread are prevalent side dishes.
Coffee is a popular beverage in Iceland, and is drunk at breakfast, after meals, and with a light snack in mid-afternoon. Coca-Cola is also widely consumed, to the extent that the country is said to have one of the highest per capita consumption rates in the world. Iceland's signature alcoholic beverage is "Brennivín" (literally "burnt (i.e. distilled) wine"), which is similar to Scandinavian akvavit. It is a type of vodka made from distilled potatoes and flavoured with either caraway seeds or angelica. Its potency has earned it the nickname "svarti dauði" ("Black Death").
Sports.
Sport is an important part of Icelandic culture, as the population is generally quite active. The main traditional sport in Iceland is "Glíma", a form of wrestling thought to have originated in medieval times.
Popular sports include association football, track and field, handball and basketball. Handball is often referred to as the national sport, and Iceland's men's national team is ranked among the top 12 in the world. Icelandic women excel at football relative to the size of the country, with the national team ranked 15th by FIFA. In 2014 Iceland men's national basketball team qualified into the EuroBasket 2015 for the first time in the country history.
Iceland has excellent conditions for skiing, fishing, snowboarding, ice climbing and rock climbing, although mountain climbing and hiking are preferred by the general public. Iceland is also a world-class destination for alpine ski touring and Telemark skiing, with the Troll Peninsula in Northern Iceland being the main centre of activity. Although the country's environment is generally ill-suited for golf, there are nevertheless lots of golf courses throughout the island, and Iceland holds the world record for most golf courses per capita with around 5000 individuals per golf course. Iceland regularly hosts an international tournament known as the Arctic Open. Iceland has also won the most competitions for World's Strongest Man, with eight titles shared evenly between Magnús Ver Magnússon and Jón Páll Sigmarsson.
Swimming is popular in Iceland. Geothermally heated outdoor pools are widespread, and swimming courses are a mandatory part of the national curriculum. Horseback riding, which was historically the most prevalent form of transportation on the island, remains a common pursuit for many Icelanders.
The oldest sport association in Iceland is the Reykjavík Shooting Association, founded in 1867. Rifle shooting became very popular in the 19th century with the encouragement of politicians and nationalists who were pushing for Icelandic independence. To this day, it remains a significant pastime.
Iceland has also produced many chess masters and hosted the historic World Chess Championship 1972 in Reykjavík during the height of the Cold War. As of 2008, there have been nine Icelandic chess grandmasters, a considerable number given the small size of the population. Bridge is also popular, with Iceland participating in a number of international tournaments. Iceland won the world bridge championship (the Bermuda Bowl) in Yokohama, Japan, in 1991 and took second place (with Sweden) in Hamilton, Bermuda, in 1950.

</doc>
<doc id="14532" url="http://en.wikipedia.org/wiki?curid=14532" title="Italy">
Italy

Italy (; Italian: "Italia" ]), officially the Italian Republic (Italian: "Repubblica italiana"), is a unitary parliamentary republic in Europe. Italy covers an area of 301338 km2 and has a largely mediterranean climate; due to its shape, it is often referred to in Italy as "lo Stivale" (the Boot). With 61 million inhabitants, it is the 4th most populous EU member state. Italy is a very highly developed country and has the third largest economy in the Eurozone and the eighth-largest in the world.
Since ancient times, Sherden, Etruscan, Magna Graecia and other cultures have flourished in the territory of present-day Italy, being eventually absorbed by Rome, that has for centuries remained the leading political and religious centre of Western civilisation, capital of the Roman Empire and Christianity. During the Dark Ages, the Italian Peninsula faced calamitous invasions by barbarian tribes, but beginning around the 11th century, numerous Italian city-states rose to great prosperity through shipping, commerce and banking (indeed, modern capitalism has its roots in Medieval Italy). Especially during The Renaissance, Italian culture thrived, producing scholars, artists, and polymaths such as Leonardo da Vinci, Galileo, Michelangelo and Machiavelli. Italian explorers such as Polo, Columbus, Vespucci, and Verrazzano discovered new routes to the Far East and the New World, helping to usher in the European Age of Discovery. Nevertheless, Italy would remain fragmented into many warring states for the rest of the Middle Ages, subsequently falling prey to larger European powers such as France, Spain, and later Austria. Italy would thus enter a long period of decline that lasted until the mid 19th century.
After various unsuccessful attempts, the second and the third wars for Italian independence resulted in the unification of most of present-day Italy between 1859–66. From the late 19th century to the early 20th century, the new Kingdom of Italy rapidly industrialised and acquired a colonial empire becoming a Great Power. However, Southern and rural Italy remained largely excluded from industrialisation, fuelling a large and influential diaspora. Despite victory in World War I, Italy entered a period of economic crisis and social turmoil, which favoured the establishment of a Fascist dictatorship in 1922. The subsequent participation in World War II at the side the Axis ended in military defeat, economic destruction and civil war. In the years that followed, Italy abolished the monarchy, reinstated democracy, and enjoyed a prolonged economic boom, thus becoming one of the most developed nations and the 5th largest economy in the world by 1990.
"Italy plays a prominent role in European and global military, cultural and diplomatic affairs". It is also considered to be a major regional power. Italy is one of the founding and leading member of the European Union. Italy is a member of numerous international institutions, including the UN, NATO, the OECD, the OSCE, the DAC, the WTO, the G6, G7, G8, G10, G20, the Union for the Mediterranean, the Latin Union, the Council of Europe, the Central European Initiative, the ASEM and the Uniting for Consensus.
Etymology.
The assumptions on the etymology of the name "Italia" are very numerous and the corpus of the solutions proposed by historians and linguists is very wide. According to one of the more common explanations, the term "Italia", from Latin: "Italia", was borrowed through Greek from the Oscan "Víteliú", meaning "land of young cattle" ("cf." Lat "vitulus" "calf", Umb "vitlo" "calf"). The bull was a symbol of the southern Italic tribes and was often depicted goring the Roman wolf as a defiant symbol of free Italy during the Social War. Greek historian Dionysius of Halicarnassus states this account together with the legend that Italy was named after Italus, mentioned also by Aristotle and Thucydides.
The name "Italia" originally applied only to a part of what is now Southern Italy – according to Antiochus of Syracuse, the southern portion of the Bruttium peninsula (modern Calabria: province of Reggio, and part of the provinces of Catanzaro and Vibo Valentia). But by his time Oenotria and Italy had become synonymous, and the name also applied to most of Lucania as well. The Greeks gradually came to apply the name "Italia" to a larger region, but it was during the reign of Emperor Augustus (end of the 1st century BC) that the term was expanded to cover the entire peninsula until the Alps.
History.
Prehistory and antiquity.
Excavations throughout Italy revealed a Neanderthal presence dating back to the Paleolithic period, some 200,000 years ago, modern Humans arrived about 40,000 years ago. The Ancient peoples of pre-Roman Italy – such as the Umbrians, the Latins (from which the Romans emerged), Volsci, Samnites, the Celts and the Ligures which inhabited northern Italy, and many others – were Indo-European peoples; the main historic peoples of non-Indo-European heritage include the Etruscans, the Elymians and Sicani in Sicily and the prehistoric Sardinians.
Between the 17th and the 11th centuries BC Mycenaean Greeks established contacts with Italy and in the 8th and 7th centuries BC Greek colonies were established all along the coast of Sicily and the southern part of the Italian Peninsula became known as Magna Graecia. Also the Phoenicians established colonies on the coasts of Sardinia and Sicily.
Rome, a settlement around a ford on the river Tiber conventionally founded in 753 BC, grew over the course of centuries into a massive empire, stretching from Britain to the borders of Persia, and engulfing the whole Mediterranean basin, in which Greek and Roman (and many other) cultures merged into a unique civilisation. The Roman legacy has deeply influenced the Western civilisation, shaping most of the modern world. In a slow decline since the third century AD, the Empire split in two in 395 AD. The Western Empire, under the pressure of the barbarian invasions, eventually dissolved in 476 AD, when its last Emperor was deposed by the Germanic chief Odoacer, while the Eastern half of the Empire survived for another thousand years.
Middle Ages.
After the fall of the Western Roman Empire, Italy was seized by the Ostrogoths, followed in the 6th century by a brief reconquest under Byzantine Emperor Justinian. The invasion of another Germanic tribe, the Lombards, late in the same century, reduced the Byzantine presence to a rump realm (the Exarchate of Ravenna) and started the end of political unity of the peninsula for the next 1,300 years. The Lombard kingdom was subsequently absorbed into the Frankish Empire by Charlemagne in the late 8th century. The Franks also helped the formation of the Papal States in central Italy. Until the 13th century, Italian politics was dominated by the relations between the Holy Roman Emperors and the Papacy, with most of the Italian city-states siding for the former (Ghibellines) or for the latter (Guelphs) from momentary convenience.
It was during this chaotic era that Italy saw the rise of a peculiar institution, the medieval commune. Given the power vacuum caused by extreme territorial fragmentation and the struggle between the Empire and the Holy See, local communities sought autonomous ways to restore law and order. In 1176 a league of city-states, the Lombard League, defeated the German emperor Frederick Barbarossa at the Battle of Legnano, thus ensuring effective independence for most of northern and central Italian cities. In coastal and southern areas, the maritime republics, the most notable being Venice, Genoa, Pisa and Amalfi, heavily involved in the Crusades, grew to eventually dominate the Mediterranean and monopolise trade routes to the Orient.
In the south, Sicily had become an Islamic emirate in the 9th century, thriving until the Italo-Normans conquered it in the late 11th century together with most of the Lombard and Byzantine principalities of southern Italy. Through a complex series of events, southern Italy developed as a unified kingdom, first under the House of Hohenstaufen, then under the Capetian House of Anjou and, from the 15th century, the House of Aragon. In Sardinia, the former Byzantine provinces became independent states known as Giudicati, although some parts of the island were under Genoese or Pisan control until the Aragonese conquered it in the 15th century. The Black Death pandemic of 1348 left its mark on Italy by killing perhaps one third of the population. However, the recovery from the plague led to a resurgence of cities, trade and economy which allowed the bloom of Humanism and Renaissance, that later spread in Europe.
Early Modern.
In the 14th and 15th centuries, northern-central Italy was divided into a number of warring city-states, the rest of the peninsula being occupied by the larger Papal States and the Kingdom of Sicily, referred to here as Naples. The strongest among these city-states gradually absorbed the surrounding territories giving birth to the Signorie, regional states often led by merchant families which founded local dynasties. War between the city-states was endemic, and primarily fought by armies of mercenaries known as "condottieri", bands of soldiers drawn from around Europe, especially Germany and Switzerland, led largely by Italian captains. Decades of fighting eventually saw Florence, Milan and Venice emerged as the dominant players that agreed to the Peace of Lodi in 1454, which saw relative calm brought to the region for the first time in centuries. This peace would hold for the next forty years.
The Renaissance, a period of vigorous revival of the arts and culture, originated in Italy thanks to a number of factors, as the great wealth accumulated by merchant cities, the patronage of its dominant families like the Medici of Florence, and the migration of Greek scholars and texts to Italy following the Conquest of Constantinople at the hands of the Ottoman Turks.
The Italian Renaissance peaked in the mid-16th century as foreign invasions plunged the region into the turmoil of the Italian Wars. The ideas and ideals of the Renaissance soon spread into Northern Europe, France, England and much of Europe. In the meantime, the discovery of the Americas, the new routes to Asia discovered by the Portuguese and the rise of the Ottoman Empire, all factors which eroded the traditional Italian dominance in trade with the East, caused a long economic decline in the peninsula.
Following the Italian Wars (1494 to 1559), ignited by the rivalry between France and Spain, the city-states gradually lost their independence and came under foreign domination, first under Spain (1559 to 1713) and then Austria (1713 to 1796). In 1629-1631, a new outburst of plague claimed about 14% of Italy’s population. In addition, as the Spanish Empire started to decline in the 17th century, so did its possessions in Naples, Sicily, Sardinia, and Milan. In particular, Southern Italy was impoverished and cut off from the mainstream of events in Europe. In the 18th century, as a result of the War of Spanish Succession, Austria replaced Spain as the dominant foreign power, while the House of Savoy emerged as a regional power expanding to Piedmont and Sardinia. In the same century, the two-century long decline was interrupted by the economic and state reforms pursued in several states by the ruling élites. During the Napoleonic Wars, northern-central Italy was invaded and reorganised as a new Kingdom of Italy, a client state of the French Empire, while the southern half of the peninsula was administered by Joachim Murat, Napoleon's brother-in-law, who was crowned as King of Naples. The 1814 Congress of Vienna restored the situation of the late 18th century, but the ideals of the French Revolution could not be eradicated, and soon re-surfaced during the political upheavals that characterised the first part of the 19th century.
Italian unification, Liberal Italy and the Great War.
The birth of the Kingdom of Italy was the result of efforts by Italian nationalists and monarchists loyal to the House of Savoy to establish a united kingdom encompassing the entire Italian Peninsula. In the context of the 1848 liberal revolutions that swept through Europe, an unsuccessful war was declared on Austria. The Kingdom of Sardinia again attacked the Austrian Empire in the Second Italian War of Independence of 1859, with the aid of France, resulting in liberating Lombardy.
In 1860–61, general Giuseppe Garibaldi led the drive for unification in Naples and Sicily, allowing the Sardinian government led by the Count of Cavour to declare a united Italian kingdom on 17 March 1861. In 1866, Victor Emmanuel II allied with Prussia during the Austro-Prussian War, waging the Third Italian War of Independence which allowed Italy to annexe Venetia. Finally, as France during the disastrous Franco-Prussian War of 1870 abandoned its garrisons in Rome, the Italians rushed to fill the power gap by taking over the Papal States.
The Piedmontese Albertine Statute of 1848, extended to the whole Kingdom of Italy in 1861, provided for basic freedoms, but electoral laws excluded the non-propertied and uneducated classes from voting. The government of the new kingdom took place in a framework of parliamentary constitutional monarchy dominated by liberal forces. In 1913, male universal suffrage was adopted. As Northern Italy quickly industrialised, the South and rural areas of North remained underdeveloped and overpopulated, forcing millions of people to migrate abroad, while the Italian Socialist Party constantly increased in strength, challenging the traditional liberal and conservative establishment. Starting from the last two decades of the 19th century, Italy developed into a colonial power by forcing Somalia, Eritrea and later Libya and the Dodecanese under its rule.
Italy, nominally allied with the German Empire and the Empire of Austria-Hungary in the Triple Alliance, in 1915 joined the Allies into the war with a promise of substantial territorial gains, that included western Inner Carniola, former Austrian Littoral, Dalmatia as well as parts of the Ottoman Empire. The war was initially inconclusive, as the Italian army get struck in a long attrition war on the Alps mountains, making little progress and suffering very heavy losses. Eventually, in October 1918, the Italians launched a massive offensive, culminating in the victory of Vittorio Veneto. The Italian victory marked the end of the war on the Italian Front, secured the dissolution of the Austro-Hungarian Empire and was chiefly instrumental in ending the First World War less than two weeks later.
During the war, more than 650,000 Italian soldiers and as many civilians died and the kingdom went on the brink of bankruptcy. Under the Peace Treaties of Saint-Germain, Rapallo and Rome, Italy obtained most of the promised territories, but not Dalmatia (except Zara), allowing nationalists to define the victory as "mutilated". Moreover, Italy annexed the Hungarian harbour of Fiume, that was not part of territories promised at London but had been occupied after the end of the war by Gabriele D'Annunzio.
Fascist Regime.
The socialist agitations that followed the devastation of the Great War, inspired by the Russian Revolution, led to turmoil and anarchy throughout Italy. The liberal establishment, fearing a Soviet-style revolution, started to endorse the small National Fascist Party, led by Benito Mussolini. In October 1922 the Blackshirts of the National Fascist Party attempted a coup (the "March on Rome"). The coup itself was a failure, but at the last minute king Victor Emmanuel III refused to proclaim the state of siege and appointed Mussolini prime minister. Over the next few years, Mussolini banned all political parties and curtailed personal liberties, thus forming a dictatorship. These actions attracted international attention and eventually inspired similar dictatorships such as Nazi Germany and Francoist Spain.
In 1935 Mussolini invaded Ethiopia, resulting in an international alienation and leading to Italy's withdrawal from the League of Nations. Consequently, Italy allied with Nazi Germany and the Empire of Japan and strongly supported Francisco Franco in the Spanish civil war. In 1939, Italy annexed Albania, a "de facto" protectorate for decades. Italy entered World War II on 10 June 1940. After initially advancing in British Somalialand and Egypt, the Italians suffered heavy defeats in Greece, Russia and North Africa.
Sicily was then invaded by the Allies in July 1943, leading to the collapse of the Fascist regime and the fall of Mussolini on 25 July. On 8 September 1943, Italy surrendered. The Germans shortly succeeded in taking control of northern and central Italy. The country remained a battlefield for the rest of the war, as the Allies were slowly moving up from the south.
In the north, the Germans set up the Italian Social Republic (RSI), a Nazi puppet state with Mussolini installed as leader. The post-armistice period saw the rise of a large anti-fascist resistance movement, the "Resistenza". Hostilities ended on 29 April 1945, when the German forces in Italy surrendered. Nearly half a million Italians (including civilians) died in the conflict, and the Italian economy had been all but destroyed; per capita income in 1944 was at its lowest point since the beginning of the 20th century.
Republican Italy.
Italy became a republic after a referendum held on 2 June 1946, a day celebrated since as Republic Day. This was also the first time that Italian women were entitled to vote. Victor Emmanuel III's son, Umberto II, was forced to abdicate and exiled. The Republican Constitution was approved on 1 January 1948. Under the Treaty of Peace with Italy of 1947, most of Julian March was lost to Yugoslavia and, later, the Free Territory of Trieste was divided between the two states. Italy also lost all its colonial possessions, formally ending the Italian Empire.
Fears in the Italian electorate of a possible Communist takeover proved crucial for the first universal suffrage electoral outcome on 18 April 1948, when the Christian Democrats, under the leadership of Alcide De Gasperi, obtained a landslide victory. Consequently, in 1949 Italy became a member of NATO. The Marshall Plan helped to revive the Italian economy which, until the late 1960s, enjoyed a period of sustained economic growth commonly called the "Economic Miracle". In 1957, Italy was a founding member of the European Economic Community (EEC), which became the European Union (EU) in 1993.
From the late 1960s until the early 1980s, the country experienced the Years of Lead, a period characterised by economic crisis (especially after the 1973 oil crisis), widespread social conflicts and terrorist massacres carried out by opposing extremist groups, with the alleged involvement of US and Soviet intelligence. The Years of Lead culminated in the assassination of the Christian Democrat leader Aldo Moro in 1978 and the Bologna railway station massacre in 1980, where 85 people died.
In the 1980s, for the first time since 1945, two governments were led by non-Christian-Democrat premiers: one liberal (Giovanni Spadolini) and one socialist (Bettino Craxi); the Christian Democrats remained, however, the main government party. During Craxi's government, the economy recovered and Italy became the world's fifth largest industrial nation, gaining entry into the G7 Group. However, as a result of his spending policies, the Italian national debt skyrocketed during the Craxi era, soon passing 100% of the GDP.
In the early 1990s, Italy faced significant challenges, as voters – disenchanted with political paralysis, massive public debt and the extensive corruption system (known as "Tangentopoli") uncovered by the 'Clean Hands' investigation – demanded radical reforms. The scandals involved all major parties, but especially those in the government coalition: the Christian Democrats, who ruled for almost 50 years, underwent a severe crisis and eventually disbanded, splitting up into several factions. The Communists reorganised as a social-democratic force. During the 1990s and the 2000s (decade), center-right (dominated by media magnate Silvio Berlusconi) and center-left coalitions (led by university professor Romano Prodi) alternatively governed the country, which entered a prolonged period of economic stagnation.
In 2008 Italy was hit by the Great Recession, being severely affected by hit. From 2008 to 2015, the country suffered 42 months of GDP recession. The economic crisis was one of the main problems that forced Berlusconi to resign in 2011. The government of the conservative Prime Minister was repleaced by the tecnochratic cabinet of Mario Monti.
In April 2013, after the general election, the Vice-Secretary of the Democratic Party Enrico Letta formed a new government at the head of a Grand coalition; but following tensions with the new Secretary of the PD Matteo Renzi, Letta resigned on 14 February 2014 and on 22 February Renzi sworn as new Prime Minister. Renzi started important constitutional reforms such as the abolition of the Senate and a new electoral law.
Geography.
Italy is located in Southern Europe, between latitudes 35° and 47° N, and longitudes 6° and 19° E. To the north, Italy borders France, Switzerland, Austria, and Slovenia, and is roughly delimited by the Alpine watershed, enclosing the Po Valley and the Venetian Plain. To the south, it consists of the entirety of the Italian Peninsula and the two Mediterranean islands of Sicily and Sardinia, in addition to many smaller islands. The sovereign states of San Marino and the Vatican City are enclaves within Italy, while Campione d'Italia is an Italian exclave in Switzerland.
The country's total area is 301230 km², of which 294020 km² is land and 7210 km² is water. Including the islands, Italy has a coastline and border of 7600 km on the Adriatic, Ionian, Tyrrhenian seas (740 km), and borders shared with France (488 km), Austria (430 km), Slovenia (232 km) and Switzerland (740 km). San Marino (39 km) and Vatican City (3.2 km), both enclaves, account for the remainder.
The Apennine Mountains form the peninsula's backbone and the Alps form most of its northern boundary, where Italy's highest point is located on Mont Blanc (4,810 m/15,782 ft). The Po, Italy's longest river (652 km/405 mi), flows from the Alps on the western border with France and crosses the Padan plain on its way to the Adriatic Sea.
The five largest lakes are, in order of diminishing size: Garda (367.94 km2), Maggiore (212.51 km2, shared with Switzerland), Como (145.9 km2), Trasimeno (124.29 km2) and Bolsena (113.55 km2).
The country is situated at the meeting point of the Eurasian Plate and the African Plate, leading to considerable seismic and volcanic activity. There are 14 volcanoes in Italy, four of which are active: Etna (the traditional site of Vulcan’s smithy), Stromboli, Vulcano and Vesuvius. Vesuvius is the only active volcano in mainland Europe and is most famous for the destruction of Pompeii and Herculanum. Several islands and hills have been created by volcanic activity, and there is still a large active caldera, the Campi Flegrei north-west of Naples.
Although the country comprises the Italian peninsula and most of the southern Alpine basin, some of Italy's territory extends beyond the Alpine basin and some islands are located outside the Eurasian continental shelf. These territories are the "comuni" of: Livigno, Sexten, Innichen, Toblach (in part), Chiusaforte, Tarvisio, Graun im Vinschgau (in part), which are all part of the Danube's drainage basin, while the Val di Lei constitutes part of the Rhine's basin and the islands of Lampedusa and Lampione are on the African continental shelf.
Environment.
After its quick industrial growth, Italy took a long time to confront its environmental problems. After several improvements, it now ranks 84th in the world for ecological sustainability. National parks cover about five percent of the country. In the last decade, Italy has become one of the world's leading producers of renewable energy, ranking as the world’s fourth largest holder of installed solar energy capacity and the sixth largest holder of wind power capacity in 2010. Renewable energies now make up about 12% of the total primary and final energy consumption in Italy, with a future target share set at 17% for the year 2020.
However, air pollution remains a severe problem, especially in the industrialised north, reaching the tenth highest level worldwide of industrial carbon dioxide emissions in the 1990s. Italy is the twelfth largest carbon dioxide producer.
Extensive traffic and congestion in the largest metropolitan areas continue to cause severe environmental and health issues, even if smog levels have decreased dramatically since the 1970s and 1980s, and the presence of smog is becoming an increasingly rarer phenomenon and levels of sulphur dioxide are decreasing.
Many watercourses and coastal stretches have also been contaminated by industrial and agricultural activity, while because of rising water levels, Venice has been regularly flooded throughout recent years. Waste from industrial activity is not always disposed of by legal means and has led to permanent health effects on inhabitants of affected areas, as in the case of the Seveso disaster. The country has also operated several nuclear reactors between 1963 and 1990 but, after the Chernobyl disaster and a referendum on the issue the nuclear program was terminated, a decision that was overturned by the government in 2008, planning to build up to four nuclear power plants with French technology. This was in turn struck down by a referendum following the Fukushima nuclear accident.
Deforestation, illegal building developments and poor land-management policies have led to significant erosion all over Italy's mountainous regions, leading to major ecological disasters like the 1963 Vajont Dam flood, the 1998 Sarno and 2009 Messina mudslides.
Climate.
Thanks to the great longitudinal extension of the peninsula and the mostly mountainous internal conformation, the climate of Italy is highly diverse. In most of the inland northern and central regions, the climate ranges from humid subtropical to humid continental and oceanic. In particular, the climate of the Po valley geographical region is mostly continental, with harsh winters and hot summers.
The coastal areas of Liguria, Tuscany and most of the South generally fit the Mediterranean climate stereotype (Köppen climate classification Csa). Conditions on peninsular coastal areas can be very different from the interior's higher ground and valleys, particularly during the winter months when the higher altitudes tend to be cold, wet, and often snowy. The coastal regions have mild winters and warm and generally dry summers, although lowland valleys can be quite hot in summer. Average winter temperatures vary from 0 C on the Alps to
12 C in Sicily, like so the average summer temperatures range from 20 C to over 30 C.
Politics.
Italy has been a unitary parliamentary republic since 2 June 1946, when the monarchy was abolished by a constitutional referendum. The President of Italy ("Presidente della Repubblica"), currently Sergio Mattarella since 2015, is Italy's head of state. The President is elected for a single seven years mandate by the Parliament of Italy in joint session. Italy has a written democratic constitution, resulting from the work of a Constituent Assembly formed by the representatives of all the anti-fascist forces that contributed to the defeat of Nazi and Fascist forces during the Civil War.
Government.
Italy has a parliamentary government based on a proportional voting system. The parliament is perfectly bicameral: the two houses, the Chamber of Deputies (that meets in Palazzo Montecitorio) and the Senate of the Republic (that meets in Palazzo Madama), have the same powers. The Prime Minister, officially President of the Council of Ministers ("Presidente del Consiglio dei Ministri"), is Italy's head of government. The Prime Minister and the cabinet are appointed by the President of the Republic, but must pass a vote of confidence in Parliament to become in office. The incumbent Italy's Prime Minister is Matteo Renzi of the Democratic Party.
While the office is similar to those in most other parliamentary systems, the Italian prime minister has less authority than some of his counterparts. The prime minister is not authorised to request the dissolution of Parliament or dismiss ministers (that are exclusive prerogatives of the President of the Republic) and must receive a vote of approval from the Council of Ministers—which holds effective executive power—to execute most political activities.
A peculiarity of the Italian Parliament is the representation given to Italian citizens permanently living abroad: 12 Deputies and 6 Senators elected in four distinct overseas constituencies. In addition, the Italian Senate is characterised also by a small number of senators for life, appointed by the President "for outstanding patriotic merits in the social, scientific, artistic or literary field". Former Presidents of the Republic are "ex officio" life senators.
Italy's three major political parties are the Democratic Party, Forza Italia and the Five Stars Movement. During the 2013 general election these three parties won 579 out of 630 seats available in the Chamber of Deputies and 294 out of 315 in the Senate. Most of the remaining seats were won by a short-lived electoral bloc formed to support the outgoing Prime Minister Mario Monti, the far left party Left, Ecology, Freedom or by parties that contest elections only in one part of Italy: the Northern League, the South Tyrolean People's Party, Vallée d'Aoste and Great South. On 15 November 2013, 58 splinter MPs from Forza Italia founded New Centre-Right.
Law and criminal justice.
The Italian judicial system is based on Roman law modified by the Napoleonic code and later statutes. The Supreme Court of Cassation is the highest court in Italy for both criminal and civil appeal cases. The Constitutional Court of Italy ("Corte Costituzionale") rules on the conformity of laws with the constitution and is a post–World War II innovation. Since their appearance in the middle of the 19th century, Italian organised crime and criminal organisations have infiltrated the social and economic life of many regions in Southern Italy, the most notorious of which being the Sicilian Mafia, which would later expand into some foreign countries including the United States. The Mafia receipts may reach 9% of Italy's GDP.
A 2009 report identified 610 comuni which have a strong Mafia presence, where 13 million Italians live and 14.6% of the Italian GDP is produced. The Calabrian 'Ndrangheta, nowadays probably the most powerful crime syndicate of Italy, accounts alone for 3% of the country's GDP. However, at 0.013 per 1,000 people, Italy has only the 47th highest murder rate (in a group of 62 countries) and the 43rd highest number of rapes per 1,000 people in the world (in a group of 65 countries), relatively low figures among developed countries.
Law enforcement.
Law enforcement in Italy is provided by multiple police forces, five of which are national, Italian agencies.
The Polizia di Stato (State Police) is the civil national police of Italy. Along with patrolling, investigative and law enforcement duties, it patrols the Autostrada (Italy's Express Highway network), and oversees the security of railways, bridges and waterways.
The Carabinieri is the common name for the Arma dei Carabinieri, a Gendarmerie-like military corps with police duties. They also serve as the military police for the Italian armed forces.
The Guardia di Finanza, (English: Financial Guard) is a corps under the authority of the Minister of Economy and Finance, with a role as police force. The Corps is in charge of financial, economic, judiciary and public safety.
The Corpo Forestale dello Stato (National Forestry Department) is responsible for law enforcement in Italian national parks and forests. Their duties include enforcing poaching laws, safeguarding protected animal species and preventing forest fires.
Foreign relations.
Italy is a founding member of the European Community, now the European Union (EU), and of the North Atlantic Treaty Organization (NATO). Italy was admitted to the United Nations in 1955, and it is a member and strong supporter of a wide number of international organisations, such as the Organisation for Economic Co-operation and Development (OECD), the General Agreement on Tariffs and Trade/World Trade Organization (GATT/WTO), the Organization for Security and Co-operation in Europe (OSCE), the Council of Europe, and the Central European Initiative. Its recent turns in the rotating presidency of international organisations include the Conference for Security and Co-operation in Europe (CSCE), the forerunner of the OSCE, in 1994; G8; and the EU in 2009 and from July to December 2003.
Italy strongly supports multilateral international politics, endorsing the United Nations and its international security activities. As of 2013, Italy was deploying 5,296 troops abroad, engaged in 33 UN and NATO missions in 25 countries of the world. Italy deployed troops in support of UN peacekeeping missions in Somalia, Mozambique, and East Timor and provides support for NATO and UN operations in Bosnia, Kosovo and Albania. Italy deployed over 2,000 troops in Afghanistan in support of Operation Enduring Freedom (OEF) from February 2003. Italy still supports international efforts to reconstruct and stabilise Iraq, but it had withdrawn its military contingent of some 3,200 troops by November 2006, maintaining only humanitarian operators and other civilian personnel.
In August 2006 Italy deployed about 2,450 troops in Lebanon for the United Nations' peacekeeping mission UNIFIL. Italy is one of the largest financiers of the Palestinian National Authority, contributing €60 million in 2013 alone.
Military.
The Italian Army, Navy, Air Force and Carabinieri collectively form the Italian armed forces, under the command of the Supreme Defence Council, presided over by the President of Italy. From 2005, military service is entirely voluntary. In 2010, the Italian military had 293,202 personnel on active duty, of which 114,778 are Carabinieri. Total Italian military spending in 2010 ranked tenth in the world, standing at $35.8 billion, equal to 1.7% of national GDP. As part of NATO's nuclear sharing strategy Italy also hosts 90 United States nuclear bombs, located in the Ghedi and Aviano air bases.
The Italian Army is the national ground defence force, numbering 109,703 in 2008. Its best-known combat vehicles are the Dardo infantry fighting vehicle, the Centauro tank destroyer and the Ariete tank, and among its aircraft the Mangusta attack helicopter, recently deployed in UN missions. It also has at its disposal a large number of Leopard 1 and M113 armoured vehicles.
The Italian Navy in 2008 had 35,200 active personnel with 85 commissioned ships and 123 aircraft. It is now equipping itself with a bigger aircraft carrier (the "Cavour"), new destroyers, submarines and multipurpose frigates. In modern times the Italian Navy, being a member of the NATO, has taken part in many coalition peacekeeping operations around the world.
The Italian Air Force in 2008 had a strength of 43,882 and operated 585 aircraft, including 219 combat jets and 114 helicopters. As a stopgap and as replacement for leased Tornado ADV interceptors, the AMI has leased 30 F-16A Block 15 ADF and four F-16B Block 10 Fighting Falcons, with an option for more. The coming years will also see the introduction of 121 EF2000 Eurofighter Typhoons, replacing the leased F-16 Fighting Falcons. Further updates are foreseen in the Tornado IDS/IDT and AMX fleets. A transport capability is guaranteed by a fleet of 22 C-130Js and Aeritalia G.222s of which 12 are being replaced with the newly developed G.222 variant called the C-27J Spartan.
An autonomous corps of the military, the Carabinieri are the gendarmerie and military police of Italy, policing the military and civilian population alongside Italy's other police forces. While the different branches of the Carabinieri report to separate ministries for each of their individual functions, the corps reports to the Ministry of Internal Affairs when maintaining public order and security.
Administrative divisions.
Italy is subdivided into 20 regions ("regioni", singular "regione"), five of these regions having a special autonomous status that enables them to enact legislation on some of their local matters. The country is further divided into 110 provinces ("province") and 8,100 municipalities ("comuni"). There are also 15 metropolitan cities ("città metropolitane"), established in 2009, but this administrative division is not yet operational.
Apulia 
Basilicata 
Calabria 
"Sicily" 
Molise 
Campania 
Abruzzo 
Lazio 
Umbria 
Marche 
Tuscany 
"Sardinia" 
Emilia-Romagna 
Liguria 
Piedmont 
"Friuli Venezia Giulia" 
"Aosta Valley" 
"South Tyrol" 
"Trentino" 
Veneto 
Lombardy 
Adriatic Sea 
Ionian Sea 
Mediterranean Sea 
Tyrrhenian Sea 
Ligurian Sea 
Economy.
Italy has a capitalist mixed economy, ranking as the third-largest in the Eurozone and the eighth-largest in the world. The country is a founding member of the G7, G8, the Eurozone and the OECD.
Italy is regarded as one of the world's most industrialised nations and a leading country in world trade and exports. It is a highly developed country, with the world's 8th highest quality of life and the 25th Human Development Index. In spite of the recent global economic crisis, Italian per capita GDP at purchasing power parity remains approximately equal to the EU 27 average, while the unemployment rate (12.6%) stands slightly above the Eurozone average. The country is well known for its creative and innovative business, a large and competitive agricultural sector (Italy is the world's largest wine producer), and for its influential and high-quality automobile, machinery, food, design and fashion industry.
Italy is the world's sixth largest manufacturing country, characterised by a smaller number of global multinational corporations than other economies of comparable size and a large number of dynamic small and medium-sized enterprises, notoriously clustered in several industrial districts, which are the backbone of the Italian industry. This has produced a manufacturing sector often focused on the export of niche market and luxury products, that if on one side is less capable to compete on the quantity, on the other side is more capable of facing the competition from China and other emerging Asian economies based on lower labour costs, with higher quality products.
The country was the world's 7th largest exporter in 2009. Italy's closest trade ties are with the other countries of the European Union, with whom it conducts about 59% of its total trade. Its largest EU trade partners, in order of market share, are Germany (12.9%), France (11.4%), and Spain (7.4%). Finally, tourism is one of the fastest growing and profitable sectors of the national economy: with 47.7 million international tourist arrivals and total receipts estimated at $43.9 billion in 2013, Italy was the fifth most visited country and the sixth highest tourism earner in the world.
Italy is part of the European single market which represents more than 500 million consumers. Several domestic commercial policies are determined by agreements among European Union (EU) members and by EU legislation. Italy introduced the common European currency, the Euro in 2002. It is a member of the Eurozone which represents around 330 million citizens. Its monetary policy is set by the European Central Bank.
However, Italy has been hit very hard by the late-2000s recession and the subsequent European sovereign-debt crisis, that exacerbated the country's structural problems. Effectively, after a strong GDP growth of 5–6% per year from the 1950s to the early 1970s, and a progressive slowdown in the 1980-90s, the country virtually stagnated in the 2000s. The political efforts to revive growth with massive government spending eventually produced a severe rise in public debt, that stood at over 135% of GDP in 2014, ranking second in the EU only after the Greek one (at 174%). For all that, the largest chunk of Italian public debt is owned by national subjects, a major difference between Italy and Greece, and the level of household debt is much lower than the OECD average.
A gaping North–South divide is a major factor of socio-economic weakness. It can be noted by the huge difference in statistical income between the northern and southern "comuni". The Index of Economic Freedom, the country ranks 86th in the world because of an inefficient state bureaucracy, low property rights protection and high levels of corruption, heavy taxation and public spending that accounts for about half of the national GDP. 
Infrastructure.
 In 2004 the transport sector in Italy generated a turnover of about 119.4 billion euros, employing 935,700 persons in 153,700 enterprises. Regarding the national road network, in 2002 there were 668721 km of serviceable roads in Italy, including 6487 km of motorways, state-owned but privately operated by Atlantia. In 2005, about 34,667,000 passenger cars (590 cars per 1,000 people) and 4,015,000 goods vehicles circulated on the national road network.
The national railway network, state-owned and operated by Ferrovie dello Stato, in 2008 totalled 16529 km of which 11 727 is electrified, and on which 4 802 locomotives and railcars circulated.
The national inland waterways network comprised 1477 km of navigable rivers and channels in 2002. In 2004 there were approximately 30 main airports (including the two hubs of Malpensa International in Milan and Leonardo da Vinci International in Rome) and 43 major seaports (including the seaport of Genoa, the country's largest and second largest in the Mediterranean Sea). In 2005 Italy maintained a civilian air fleet of about 389,000 units and a merchant fleet of 581 ships.
Italy needs to import about 80% of its energy requirements.
Demographics.
At the end of 2013, Italy had 60,782,668 inhabitants. The resulting population density, at 202/km² (520/sq. mile), is higher than that of most Western European countries. However, the distribution of the population is widely uneven. The most densely populated areas are the Po Valley (that accounts for almost a half of the national population) and the metropolitan areas of Rome and Naples, while vast regions such as the Alps and Apennines highlands, the plateaus of Basilicata and the island of Sardinia are very sparsely populated.
The population of Italy almost doubled during the 20th century, but the pattern of growth was extremely uneven because of large-scale internal migration from the rural South to the industrial cities of the North, a phenomenon which happened as a consequence of the Italian economic miracle of the 1950–1960s. High fertility and birth rates persisted until the 1970s, after which they start to dramatically decline, leading to rapid population ageing. At the end of the 2000s (decade), one in five Italians was over 65 years old. However, in recent years Italy experienced a significant growth in birth rates. The total fertility rate has also climbed from an all-time low of 1.18 children per woman in 1995 to 1.41 in 2008.
The TFR is expected to reach 1.6 - 1.8 in 2030.
From the late 19th century until the 1960s Italy was a country of mass emigration. Between 1898 and 1914, the peak years of Italian diaspora, approximately 750,000 Italians emigrated each year. The diaspora concerned more than 25 million Italians and it is considered the biggest mass migration of contemporary times. As a result, today more than 4.1 million Italian citizens are living abroad, while at least 60 million people of full or part Italian ancestry live outside of Italy, most notably in Argentina, Brazil, Uruguay, Venezuela, the United States, Canada, Australia, and France.
Ethnic groups.
Foreign population resident in Italy.
   European Union
 (29.2%)   Europe non-EU
 (24.2%)   North Africa
 (14.9%)   South Asia
 (8.8%)   East Asia
 (8.0%)   Latin America
 (7.7%)   Sub-Saharan Africa
 (6.7%)  Other (0.5%)
Starting from the early 1980s, until then a linguistically and culturally homogeneous society, Italy begun to attract substantial flows of foreign immigrants. The present-day figure of about 4.9 million foreign residents, making up some 8.1% of the total population, include more than half a million children born in Italy to foreign nationals—second generation immigrants, but exclude foreign nationals who have subsequently acquired Italian nationality; this applied to 53,696 people in 2008.
The official figures also exclude illegal immigrants, whose numbers are very difficult to determine; they were estimated in 2008 to number at least 670,000. Since the fall of the Berlin Wall and, more recently, the 2004 and 2007 enlargements of the European Union, the main waves of migration have originated from former socialist countries of Central and Eastern Europe (especially Romania, Albania, Ukraine and Poland). The second most important area of immigration to Italy has always been the neighbouring North Africa (in particular, Morocco, Egypt and Tunisia), with soaring arrivals as a consequence of the Arab Spring. Furthermore, in recent years, growing migration fluxes from the Far East (notably, China and the Philippines) and Latin America (mainly from South America) have been recorded.
Currently, about one million Romanian citizens (around one tenth of them being Roma) are officially registered as living in Italy, representing thus the most important individual country of origin, followed by Albanians and Moroccans with about 500,000 people each. The number of unregistered Romanians is difficult to estimate, but the Balkan Investigative Reporting Network suggested in 2007 that there might have been half a million or more.
Overall, at the end of the 2000s (decade) the foreign born population of Italy was from: Europe (54%), Africa (22%), Asia (16%), the Americas (8%) and Oceania (0.06%). The distribution of immigrants is largely uneven in Italy: 87% of immigrants live in the northern and central parts of the country (the most economically developed areas), while only 13% live in the southern half of the peninsula.
Languages.
Italy's official language is Italian. It is estimated that there are about 64 million native Italian speakers while the total number of Italian speakers, incluiding those who use it as a second language, is about 85 million. Italy has numerous regional dialects, however, the establishment of a national education system has led to decrease in variation in the languages spoken across the country during the 20th century. Standardisation was further expanded in the 1950s and 1960s thanks to economic growth and the rise of mass media and television (the state broadcaster RAI helped set a standard Italian).
Several minority languages are legally recognised: Albanian, Catalan, German, Greek, Slovene, Croatian, French, Franco-Provençal, Friulian, Ladin, Occitan and Sardinian (Law number 482 of 15 December 1999). French is co-official in the Valle d’Aosta—although in fact Franco-Provencal is more commonly spoken there. German has the same status in South Tyrol as, in some parts of that province and in parts of the neighbouring Trentino, does Ladin. Slovene is officially recognised in the provinces of Trieste, Gorizia and Udine.
Because of significant recent immigration, Italy has sizeable populations whose native language is not Italian. According to the Italian National Institute of Statistics, Romanian is the most common mother tongue among foreign residents in Italy: almost 800,000 people speak Romanian as their first language (21.9% of the foreign residents aged 6 and over). Other prevalent mother tongues are Arabic (spoken by over 475,000 people; 13.1% of foreign residents), Albanian (380,000 people) and Spanish (255,000 people). Other languages spoken in Italy are Ukrainian, Hindi, Polish, and Tamil amongst others.
Religion.
Roman Catholicism is, by far, the largest religion in the country, although Catholicism is no longer officially the state religion. In 2010, the proportion of Italians that identify themselves as Roman Catholic was 81.2%.
The Holy See, the episcopal jurisdiction of Rome, contains the central government of the entire Roman Catholic Church, including various agencies essential to administration. Diplomatically, it is recognised by other subjects of international law as a sovereign entity, headed by the Pope, who is also the Bishop of Rome, with which diplomatic relations can be maintained. Often incorrectly referred to as "the Vatican", the Holy See is not the same entity as the Vatican City State, which came into existence only in 1929; the Holy See dates back to early Christian times. Ambassadors are officially accredited not to the Vatican City State but to "the Holy See", and papal representatives to states and international organisations are recognised as representing the Holy See, not the Vatican City State.
Minority Christian faiths in Italy include Eastern Orthodox, Waldensians and Protestant communities. In 2011, there were an estimated 1.5 million Orthodox Christians in Italy, or 2.5% of the population; 0.5 million Pentecostals and Evangelicals (of whom 0.4 million are members of the Assemblies of God), 235,685 Jehovah's Witnesses, 30,000 Waldensians, 25,000 Seventh-day Adventists, 22,000 Latter-day Saints, 15,000 Baptists (plus some 5,000 Free Baptists), 7,000 Lutherans, 4,000 Methodists (affiliated with the Waldensian Church).
One of the longest-established minority religious faiths in Italy is Judaism, Jews having been present in Ancient Rome since before the birth of Christ. Italy has for centuries welcomed Jews expelled from other countries, notably Spain. However, as a result of the Holocaust, about 20% of Italian Jews lost their lives. This, together with the emigration that preceded and followed World War II, has left only a small community of around 28,400 Jews in Italy.
Soaring immigration in the last two decades has been accompanied by an increase in non-Christian faiths. In 2010, there were 1.6 million Muslims in Italy, forming 2.6 percent of population. In addition, there are more than 200,000 followers of faiths originating in the Indian subcontinent with some 70,000 Sikhs with 22 gurdwaras across the country, 70,000 Hindus, and 50,000 Buddhists. There were an estimated 4,900 Bahá'ís in Italy in 2005.
The Italian state, as a measure to protect religious freedom, devolves shares of income tax to recognised religious communities, under a regime known as Eight per thousand ("Otto per mille"). Donations are allowed to Christian, Jewish, Buddhist and Hindu communities; however, Islam remains excluded, since no Muslim communities have yet signed a concordat with the Italian state. Taxpayers who do not wish to fund a religion contribute their share to the state welfare system.
Education.
Education in Italy is free and mandatory from ages six to sixteen, and consists of five stages: kindergarten ("scuola dell'infanzia"), primary school ("scuola primaria"), lower secondary school ("scuola secondaria di primo grado"), upper secondary school ("scuola secondaria di secondo grado") and university ("università"). The Superior Graduate Schools are independent institutions similar to French Grandes écoles which offer advanced training and research through university-type courses or are dedicated to teaching at graduate or post-doctoral level.
Italy hosts a broad variety of universities, colleges and academies. Founded in 1088, the University of Bologna is likely the oldest in the world. In 2009, the University of Bologna is, according to The Times, the only Italian college in the top 200 World Universities. Milan's Bocconi University has been ranked among the top 20 best business schools in the world by The Wall Street Journal international rankings, especially thanks to its M.B.A. program, which in 2007 placed it no. 17 in the world in terms of graduate recruitment preference by major multinational companies. Bocconi was also ranked by Forbes as the best worldwide in the specific category Value for Money. In May 2008, Bocconi overtook several traditionally top global business schools in the Financial Times Executive education ranking, reaching no. 5 in Europe and no. 15 in the world.
Other top universities and polytechnics include the Polytechnic University of Turin, the Politecnico di Milano (which in 2011 was ranked as the 48th best technical university in the world by QS World University Rankings), the University of Rome La Sapienza (which in 2005 was Europe's 33rd best university, and ranks among Europe's 50 and the world's 150 best colleges and in 2013, the Center for World University Rankings ranked the Sapienza University of Rome 62nd in the world and the top in Italy in its "World University Rankings".) and the University of Milan (whose research and teaching activities have developed over the years and have received important international recognitions). The University is the only Italian member of the League of European Research Universities (LERU), a prestigious group of twenty research-intensive European Universities. It has also been awarded ranking positions such as 1st in Italy and 7th in Europe (The Leiden Ranking – Universiteit Leiden).
According to National Science Indicators (1981–2002), a database produced by Research Services Group containing listings of output and citation statistics for more than 90 countries, Italy has an above-average output of scientific papers (in terms of number of papers written with at least one author being from Italy) in space science (9.75% of papers in the world being from Italy), mathematics (5.51% of papers in the world), computer science, neurosciences, and physics; the lowest, but still slightly above world-average, output in terms of number of papers produced is recorded in the social sciences, psychology and psychiatry, and economics and business.
Healthcare.
The Italian state runs a universal public healthcare system since 1978. However, healthcare is provided to all citizens and residents by a mixed public-private system. The public part is the "Servizio Sanitario Nazionale", which is organised under the Ministry of Health and administered on a devolved regional basis. Healthcare spending in Italy accounted for more than 9.0% of the national GDP in 2008, slightly above the OECD countries' average of 8.9%.
Italy ranks as having the world's 2nd best healthcare system, and the world's 3rd best healthcare performance. Italy had the 8th highest worldwide life expectancy in 2013. As in many other western countries, Italy is seeing an increase in the proportion of overweight and obese people, with 34.2% of Italians self reporting as overweight and 9.8% self reporting as obese. The proportion of daily smokers was 22% in 2008. Smoking in public places including bars, restaurants, night clubs and offices has been restricted to specially ventilated rooms since 2005.
Culture.
For centuries divided by politics and geography until its eventual unification in 1861, Italy has developed a unique culture, shaped by a multitude of regional customs and local centres of power and patronage. During the Middle Ages and the Renaissance, a number of magnificent courts competed for attracting the best architects, artistis and scholars, thus producing an immense legacy of monuments, paintings, music and literature.
Italy has more UNESCO World Heritage Sites (50) than any other country in the world, and has rich collections of art, culture and literature from many different periods. The country has had a broad cultural influence worldwide, also because numerous Italians emigrated to other places during the Italian diaspora. Furthermore, the nation has, overall, an estimated 100,000 monuments of any sort (museums, palaces, buildings, statues, churches, art galleries, villas, fountains, historic houses and archaeological remains).
Architecture.
Italy has a very broad and diverse architectural style, which cannot be simply classified by period, but also by region, because of Italy's division into several regional states until 1861. This has created a highly diverse and eclectic range in architectural designs.
Italy is known for its considerable architectural achievements, such as the construction of arches, domes and similar structures during ancient Rome, the founding of the Renaissance architectural movement in the late-14th to 16th centuries, and being the homeland of Palladianism, a style of construction which inspired movements such as that of Neoclassical architecture, and influenced the designs which noblemen built their country houses all over the world, notably in the UK, Australia and the US during the late 17th to early 20th centuries. Several of the finest works in Western architecture, such as the Colosseum, the Milan Cathedral and Florence cathedral, the Leaning Tower of Pisa and the building designs of Venice are found in Italy.
Italian architecture has also widely influenced the architecture of the world. British architect Inigo Jones, inspired by the designs of Italian buildings and cities, brought back the ideas of Italian Renaissance architecture to 17th-century England, being inspired by Andrea Palladio. Additionally, Italianate architecture, popular abroad since the 19th century, was used to describe foreign architecture which was built in an Italian style, especially modelled on Renaissance architecture.
Visual art.
The history of Italian visual art is part of Western painting history. Roman art was influenced by Greece and can in part be taken as a descendant of ancient Greek painting. However, Roman painting does have important unique characteristics. The only surviving Roman paintings are wall paintings, many from villas in Campania, in Southern Italy. Such painting can be grouped into 4 main "styles" or periods and may contain the first examples of trompe-l'œil, pseudo-perspective, and pure landscape.
Panel painting becomes more common during the Romanesque period, under the heavy influence of Byzantine icons. Towards the middle of the 13th century, Medieval art and Gothic painting became more realistic, with the beginnings of interest in the depiction of volume and perspective in Italy with Cimabue and then his pupil Giotto. From Giotto on, the treatment of composition by the best painters also became much more free and innovative. They are considered to be the two great medieval masters of painting in western culture.
The Italian Renaissance is said by many to be the golden age of painting; roughly spanning the 14th through the mid-17th centuries with a significant influence also out of the borders of modern Italy. In Italy artists like Paolo Uccello, Fra Angelico, Masaccio, Piero della Francesca, Andrea Mantegna, Filippo Lippi, Giorgione, Tintoretto, Sandro Botticelli, Leonardo da Vinci, Michelangelo Buonarroti, Raphael, Giovanni Bellini, and Titian took painting to a higher level through the use of perspective, the study of human anatomy and proportion, and through their development of an unprecedented refinement in drawing and painting techniques. Michelangelo was an active sculptor from about 1500 to 1520, and his great masterpieces including his "David", "Pietà", "Moses". Other prominent Renaissance sculptors include Lorenzo Ghiberti, Luca Della Robbia, Donatello, Filippo Brunelleschi, Andrea del Verrocchio.
In the 15th and 16th centuries, the High Renaissance gave rise to a stylised art known as Mannerism. In place of the balanced compositions and rational approach to perspective that characterised art at the dawn of the 16th century, the Mannerists sought instability, artifice, and doubt. The unperturbed faces and gestures of Piero della Francesca and the calm Virgins of Raphael are replaced by the troubled expressions of Pontormo and the emotional intensity of El Greco. In the 17th century, among the greatest painters of Italian Baroque are Caravaggio, Annibale Carracci, Artemisia Gentileschi, Mattia Preti, Carlo Saraceni and Bartolomeo Manfredi. Subsequently, in the 18th century, Italian Rococo was mainly inspired by French Rococo, since France was the founding nation of that particular style, with artists such as Giovanni Battista Tiepolo and Canaletto. Italian Neoclassical sculpture focused, with Antonio Canova's nudes, on the idealist aspect of the movement.
In the 19th century, major Italian Romantic painters were Francesco Hayez, Giuseppe Bezzuoli and Francesco Podesti. Impressionism was brought from France to Italy by the "Macchiaioli", led by Giovanni Fattori, and Giovanni Boldini; Realism by Gioacchino Toma and Giuseppe Pellizza da Volpedo. In the 20th century, with Futurism, primarily through the works of Umberto Boccioni and Giacomo Balla, Italy rose again as a seminal country for artistic evolution in painting and sculpture. Futurism was succeeded by the metaphysical paintings of Giorgio de Chirico, who exerted a strong influence on the Surrealists and generations of artists to follow.
Literature and theatre.
The basis of the modern Italian language was established by the Florentine poet Dante Alighieri, whose greatest work, the Divine Comedy, is considered among the foremost literary statements produced in Europe during the Middle Ages. There is no shortage of celebrated literary figures in Italy: Giovanni Boccaccio, Giacomo Leopardi, Alessandro Manzoni, Torquato Tasso, Ludovico Ariosto, and Petrarch, whose best-known vehicle of expression, the sonnet, was created in Italy.
Prominent philosophers include Giordano Bruno, Marsilio Ficino, Niccolò Machiavelli, and Giambattista Vico. Modern literary figures and Nobel laureates are nationalist poet Giosuè Carducci in 1906, realist writer Grazia Deledda in 1926, modern theatre author Luigi Pirandello in 1936, poets Salvatore Quasimodo in 1959 and Eugenio Montale in 1975, satirist and theatre author Dario Fo in 1997.
Carlo Collodi's 1883 novel, "The Adventures of Pinocchio", is the most celebrated children's classic by an Italian author.
Italian theatre can be traced back to the Roman tradition which was heavily influenced by the Greek; as with many other literary genres, Roman dramatists tended to adapt and translate from the Greek. For example, Seneca's "Phaedra" was based on that of Euripides, and many of the comedies of Plautus were direct translations of works by Menander. During the 16th century and on into the 18th century, Commedia dell'arte was a form of improvisational theatre, and it is still performed today. Travelling troupes of players would set up an outdoor stage and provide amusement in the form of juggling, acrobatics, and, more typically, humorous plays based on a repertoire of established characters with a rough storyline, called "canovaccio".
Music.
From folk music to classical, music has always played an important role in Italian culture. Instruments associated with classical music, including the piano and violin, were invented in Italy, and many of the prevailing classical music forms, such as the symphony, concerto, and sonata, can trace their roots back to innovations of 16th- and 17th-century Italian music.
Italy's most famous composers include the Renaissance composers Palestrina and Monteverdi, the Baroque composers Scarlatti, Corelli and Vivaldi, the Classical composers Paganini and Rossini, and the Romantic composers Verdi and Puccini. Modern Italian composers such as Berio and Nono proved significant in the development of experimental and electronic music. While the classical music tradition still holds strong in Italy, as evidenced by the fame of its innumerable opera houses, such as La Scala of Milan and San Carlo of Naples, and performers such as the pianist Maurizio Pollini and the late tenor Luciano Pavarotti, Italians have been no less appreciative of their thriving contemporary music scene.
Italy is widely known for being the birthplace of opera. Italian opera was believed to have been founded in the early 17th century, in Italian cities such as Mantua and Venice. Later, works and pieces composed by native Italian composers of the 19th and early 20th centuries, such as Rossini, Bellini, Donizetti, Verdi and Puccini, are among the most famous operas ever written and today are performed in opera houses across the world. La Scala operahouse in Milan is also renowned as one of the best in the world. Famous Italian opera singers include Enrico Caruso and Alessandro Bonci.
Introduced in the early 1920s, jazz took a particularly strong foothold in Italy, and remained popular despite the xenophobic cultural policies of the Fascist regime. Today, the most notable centres of jazz music in Italy include Milan, Rome, and Sicily. Later, Italy was at the forefront of the progressive rock movement of the 1970s, with bands like PFM and Goblin. Italy was also an important country in the development of disco and electronic music, with Italo disco, known for its futuristic sound and prominent usage of synthesizers and drum machines, being one of the earliest electronic dance genres, as well as European forms of disco aside from Euro disco (which later went on to influence several genres such as Eurodance and Nu-disco).
Producers/songwriters such as Giorgio Moroder, who won three Academy Awards for his music, were highly influential in the development of EDM (electronic dance music). Today, Italian pop music is represented annually with the Sanremo Music Festival, which served as inspiration for the Eurovision song contest, and the Festival of Two Worlds in Spoleto. Singers such as pop diva Mina, classical crossover artist Andrea Bocelli, Grammy winner Laura Pausini, and European chart-topper Eros Ramazzotti have attained international acclaim.
Cinema.
The history of Italian cinema began a few months after the Lumière brothers began motion picture exhibitions. The first Italian film was a few seconds, showing Pope Leo XIII giving a blessing to the camera. The Italian film industry was born between 1903 and 1908 with three companies: the Società Italiana Cines, the Ambrosio Film and the Itala Film. Other companies soon followed in Milan and in Naples. In a short time these first companies reached a fair producing quality, and films were soon sold outside Italy. Cinema was later used by Benito Mussolini, who founded Rome's renowned Cinecittà studio for the production of Fascist propaganda until World War II.
After the war, Italian film was widely recognised and exported until an artistic decline around the 1980s. Notable Italian film directors from this period include Vittorio De Sica, Federico Fellini, Sergio Leone, Pier Paolo Pasolini, Luchino Visconti, Michelangelo Antonioni and Dario Argento. Movies include world cinema treasures such as "La dolce vita", "The Good, the Bad and the Ugly" and "Bicycle Thieves". The mid-1940s to the early 1950s was the heyday of neorealist films, reflecting the poor condition of post-war Italy.
As the country grew wealthier in the 1950s, a form of neorealism known as pink neorealism succeeded, and other film genres, such as sword-and-sandal followed as spaghetti westerns, were popular in the 1960s and 1970s. In recent years, the Italian scene has received only occasional international attention, with movies like "La vita è bella" directed by Roberto Benigni, "Il postino" with Massimo Troisi and "La grande bellezza" directed by Paolo Sorrentino
Science and Technology.
Through the centuries, Italy has given birth to some of the most notable scientific minds, particularly in modern and the contemporary era. Prominent Italian Polymaths such as Leonardo da Vinci, Michelangelo and Leon Battista Alberti made important contributions to a variety of fields, including biology, architecture, engineering. Galileo Galilei, a physicist, mathematician and astronomer, played a major role in the Scientific Revolution. His achievements include key improvements to the telescope and consequent astronomical observations, and ultimately the triumph of Copernicanism over the Ptolemaic model. Other astronomers suchs as Giovanni Domenico Cassini and Giovanni Schiaparelli made many important discoveries about the Solar System. In mathematics, Joseph Louis Lagrange (born Giuseppe Lodovico Lagrangia), Fibonacci, and Gerolamo Cardano made fundamental advances in the field. Physicist Enrico Fermi, a Nobel prize laureate, led the team that developed the first nuclear reactor and is also noted for his many other contributions to physics, including the co-development of the quantum theory. Other prominent physicist include: Amedeo Avogadro ( most noted for his contributions to molecular theory, in particular the Avogadro's law and the Avogadro constant), Evangelista Torricelli (inventor of barometer), Alessandro Volta (inventor of electric battery), Guglielmo Marconi (inventor of radio), Ettore Majorana (who discovered the Majorana fermions), Emilio G. Segrè (who discovered the elements technetium and astatine, and the antiproton), Carlo Rubbia (1984 Nobel Prize in Physics for work leading to the discovery of the W and Z particles at CERN). In biology, Marcello Malpighi founded microscopic anatomy, Lazzaro Spallanzani conducted important research in bodily functions, animal reproduction, and cellular theory, Camillo Golgi, whose many achievements include the discovery of the Golgi complex, paved the way to the acceptance of the Neuron doctrine, Rita Levi-Montalcini discovered the nerve growth factor (awarded 1986 Nobel Prize in Physiology or Medicine). In chemistry, Giulio Natta received the Nobel Prize in Chemistry in 1963 for his work on high polymers. Giuseppe Occhialini received the Wolf Prize in Physics for the discovery of the pion or pi-meson decay in 1947. Ennio de Giorgi, a Wolf Prize in Mathematics recipient in 1990, solved Bernstein's problem about minimal surfaces and the 19th Hilbert problem on the regularity of solutions of Elliptic partial differential equations.
Sport.
The most popular sport in Italy is, by far, football. Italy's Squadra Azzurra has won four FIFA World Cups (1934, 1938, 1982, and 2006), currently ranking as the world's third most successful national football team, preceded by Brazil and Germany. Italy's club sides have won 27 major European trophies, making them the most successful nation in European football, and Italy's top-flight club football league, Serie A, is ranked 4th best in Europe and is followed by fans around the world.
Other popular team sports in Italy include volleyball, basketball and rugby. The male and female national teams are often in top 4 ranking of teams in the world, regarded as the best volleyball league in the world. The Italian national basketball team's best results were gold at Eurobasket 1983 and EuroBasket 1999, as well as silver at the Olympics in 2004. The Italian League is widely considered one of the most competitive in Europe. Rugby union enjoys a good level of popularity, especially in the north of the country. Italy's national team competes in the Six Nations Championship, and is a regular at the Rugby World Cup. Italy ranks as a tier-one nation by the International Rugby Board.
Italy has a long and successful tradition in individual sports as well. Bicycle racing is a very familiar sport in the country. Italians have won the UCI World Championships more than any other country, except Belgium. The Giro d'Italia is a world famous long distance cycling race held every May, and constitutes one of the three Grand Tours, along with the Tour de France and the Vuelta a España, each of which last approximately three weeks. Alpine skiing is also a very widespread sport in Italy, and the country is a popular international skiing destination, known for its ski resorts. Italian skiers achieved good results in Winter Olympic Games, Alpine Ski World Cup, and World Championship. Tennis has a significant following in Italy, ranking as the fourth most practised sport in the country. The Rome Masters, founded in 1930, is one of the most prestigious tennis tournaments in the world. Italian professional tennis players won the Davis Cup in 1976 and the Fed Cup in 2006 and 2009. Motorsports are also extremely popular in Italy. Italy has won, by far, the most world Grand Prix motorcycle racing. Italian Scuderia Ferrari is the oldest surviving team in Grand Prix racing, having competed since 1948, and statistically the most successful Formula One team in history with a record of 15 drivers' championships and 16 constructors' championships.
Historically, Italy has been a very successful nation in the Olympic Games, taking part from the first Olympiad and in 47 Games out of 48. Italian sportsmen have won 522 medals at the Summer Olympic Games, and another 106 at the Winter Olympic Games, for a combined total of 628 medals with 235 golds, which makes them the fifth most successful nation in Olympic history and the sixth for total medals. The country hosted two Winter Olympics (in 1956 and 2006) and one Summer games (in 1960), and it's bidding for the 2024 Summer Olympics.
Fashion and design.
Italian fashion has a long tradition, and is regarded as one most important in the world. Milan, Florence and Rome are Italy's main fashion capitals. According to "Top Global Fashion Capital Rankings" 2013 by Global Language Monitor, Rome ranked sixth worldwide when Milan was twelfth. Major Italian fashion labels, such as Gucci, Armani, Prada, Versace, Valentino, Dolce & Gabbana, Missoni, Fendi, Moschino, Max Mara, Trussardi, and Ferragamo, to name a few, are regarded as among the finest fashion houses in the world. Also, the fashion magazine Vogue Italia, is considered the most important and prestigious fashion magazine in the world.
Italy is also prominent in the field of design, notably interior design, architectural design, industrial design and urban design. The country has produced some well-known furniture designers, such as Gio Ponti and Ettore Sottsass, and Italian phrases such as "Bel Disegno" and "Linea Italiana" have entered the vocabulary of furniture design. Examples of classic pieces of Italian white goods and pieces of furniture include Zanussi's washing machines and fridges, the "New Tone" sofas by Atrium, and the post-modern bookcase by Ettore Sottsass, inspired by Bob Dylan's song "Stuck Inside of Mobile with the Memphis Blues Again".
Today, Milan and Turin are the nation's leaders in architectural design and industrial design. The city of Milan hosts FieraMilano, Europe's largest design fair. Milan also hosts major design and architecture-related events and venues, such as the "Fuori Salone" and the Salone del Mobile, and has been home to the designers Bruno Munari, Lucio Fontana, Enrico Castellani and Piero Manzoni.
Cuisine.
Modern Italian cuisine has developed through centuries of social and political changes, with roots as far back as the 4th century BC. Italian cuisine in itself takes heavy influences, including Etruscan, ancient Greek, ancient Roman, Byzantine, and Jewish. Significant changes occurred with the discovery of the New World with the introduction of items such as potatoes, tomatoes, bell peppers and maize, now central to the cuisine but not introduced in quantity until the 18th century. Italian cuisine is noted for its regional diversity, abundance of difference in taste, and is known to be one of the most popular in the world, wielding strong influence abroad.
The Mediterranean diet forms the basis of Italian cuisine, rich in pasta, fish and vegetables and characterised by its extreme simplicity and variety, with many dishes having only four to eight ingredients. Italian cooks rely chiefly on the quality of the ingredients rather than on elaborate preparation. Dishes and recipes are often derivatives from local and familial tradition rather than created by chefs, so many recipes are ideally suited for home cooking, this being one of the main reasons behind the ever increasing worldwide popularity of Italian cuisine, from America to Asia. Ingredients and dishes vary widely by region.
A key factor in the success of Italian cuisine is its heavy reliance on traditional products; Italy has the most traditional specialities protected under EU law. Cheese, cold cuts and wine are a major part of Italian cuisine, with many regional declinations and Protected Designation of Origin or Protected Geographical Indication labels, and along with coffee (especially espresso) make up a very important part of the Italian gastronomic culture. Desserts have a long tradition of merging local flavours such as citrus fruits, pistachio and almonds with sweet cheeses like mascarpone and ricotta or exotic tastes as cocoa, vanilla and cinnamon. Gelato, tiramisù and cassata are among the most famous examples of Italian desserts, cakes and patisserie.

</doc>
