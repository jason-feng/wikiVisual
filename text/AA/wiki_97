<doc id="13276" url="http://en.wikipedia.org/wiki?curid=13276" title="Historiography">
Historiography

Historiography refers to both the study of the methodology of historians and the development of history as a discipline, and also to a body of historical work on a particular subject. The historiography of a specific topic covers how historians have studied that topic using particular sources, techniques, and theoretical approaches. Scholars discuss historiography topically – such as the "historiography of the British Empire," the "historiography of early Islam", or the "historiography of China" – as well as different approaches and genres, such as political history or social history. Beginning in the nineteenth century, with the ascent of academic history, a body of historiographic literature developed. The extent to which historians are influenced by their own groups and loyalties—such as to their nation state—is a much debated question.
The research interests of historians change over time, and in recent decades there has been a shift away from traditional diplomatic, economic and political history toward newer approaches, especially social and cultural studies. From 1975 to 1995, the proportion of professors of history in American universities identifying with social history rose from 31% to 41%, while the proportion of political historians fell from 40% to 30%. In the history departments of British universities in 2007, of the 5,723 faculty members, 1,644 (29%) identified themselves with social history while political history came next with 1,425 (25%).
Terminology.
In the early modern period, the term "historiography" tended to be used in a more basic sense, to mean simply "the writing of history". "Historiographer" therefore meant "historian", and it is in this sense that certain official historians were given the title "Historiographer Royal", in Sweden (from 1618), England (from 1660), and Scotland (from 1681). The Scottish post is still in existence.
Furay and Salevouris (1988) define historiography as "the study of the way history has been and is written – the history of historical writing... When you study 'historiography' you do not study the events of the past directly, but the changing interpretations of those events in the works of individual historians."
Premodern history.
Understanding the past appears to be a universal human need, and the telling of history has emerged independently in civilisations around the world. What constitutes history is a philosophical question (see philosophy of history). The earliest chronologies date back to Mesopotamia and ancient Egypt, though no historical writers in these early civilizations were known by name. For the purposes of this article, history is taken to mean written history recorded in a narrative format for the purpose of informing future generations about events. Some experts have advised against the tendency to extrapolate trends for historical patterns that do not align with expectations about the future.
East Asia.
Ancient China.
In China, the earliest history was recorded in oracle bone script which was deciphered and may date back to around late 2nd millennium BCE. The "Zuo Zhuan", attributed to Zuo Qiuming in the 5th century, is the earliest written of narrative history in the world and covers the period from 722 to 468. The "Classic of History" is one of the Five Classics of Chinese classic texts and one of the earliest narratives of China. The "Spring and Autumn Annals", the official chronicle of the State of Lu covering the period from 722 to 481, is among the earliest surviving historical texts to be arranged on annalistic principles in the world. It is traditionally attributed to Confucius(551–479 BCE). "Zhan Guo Ce" was a renowned ancient Chinese historical compilation of sporadic materials on the Warring States period compiled between the 3rd and 1st centuries.
Sima Qian (around 100) was the first in China to lay the groundwork for professional historical writing. His written work was the "Shiji" ("Records of the Grand Historian"), a monumental lifelong achievement in literature. Its scope extends as far back as the 16th century, and it includes many treatises on specific subjects and individual biographies of prominent people, and also explores the lives and deeds of commoners, both contemporary and those of previous eras. His work influenced every subsequent author of history in China, including the prestigious Ban family of the Eastern Han Dynasty era.
Traditional Chinese historiography describes history in terms of dynastic cycles. In this view, each new dynasty is founded by a morally righteous founder. Over time, the dynasty becomes morally corrupt and dissolute. Eventually, the dynasty becomes so weak as to allow its replacement by a new dynasty.
Korea.
The tradition of Korean historiography was established with the "Samguk Sagi", a history of Korea from its allegedly earliest times. It was compiled by Goryeo court historian Kim Busik after its commission by King Injong of Goryeo (r. 1122 - 1146). It was completed in 1145 and relied not only on earlier Chinese histories for source material, but also on the "Hwarang Segi" written by the Silla historian Kim Daemun in the 8th century. The latter work is now lost.
Japan.
The earliest works of history produced in Japan were the "Rikkokushi", a corpus of six national histories covering the history of Japan from its mythological beginnings until the 9th century. The first of these works were the "Nihon Shoki", compiled by Prince Toneri in 720.
Hellenic world.
The earliest known systematic historical thought emerged in ancient Greece, a development which would be an important influence on the writing of history elsewhere around the Mediterranean region. Greek historians greatly contributed to the development of historical methodology. The earliest known critical historical works were "The Histories", composed by Herodotus of Halicarnassus (484–425 BCE) who became known as the "father of history.". Herodotus attempted to distinguish between more and less reliable accounts, and personally conducted research by travelling extensively, giving written accounts of various Mediterranean cultures. Although Herodotus' overall emphasis lay on the actions and characters of men, he also attributed an important role to divinity in the determination of historical events.
The generation following Herodotus witnessed a spate of local histories of the individual city-states ("poleis"), written by the first of the local historians who employed the written archives of city and sanctuary. Dionysius of Halicarnassus characterized these historians as the forerunners of Thucydides, and these local histories continued to be written into Late Antiquity, as long as the city-states survived. Two early figures stand out: Hippias of Elis, who produced the lists of winners in the Olympic Games that provided the basic chronological framework as long as the pagan classical tradition lasted, and Hellanicus of Lesbos, who compiled more than two dozen histories from civic records, all of them now lost.
Thucydides largely eliminated divine causality in his account of the war between Athens and Sparta, establishing a rationalistic element which set a precedent for subsequent Western historical writings. He was also the first to distinguish between cause and immediate origins of an event, while his successor Xenophon (c. 431 – 355) introduced autobiographical elements and character studies in his Anabasis.
The proverbial Philippic attacks of the Athenian orator Demosthenes (384–322) on Philip II of Macedon marked the height of ancient political agitation. The now lost history of Alexander's campaigns by the diadoch Ptolemy I (367–283) may represent the first historical work composed by a ruler. Polybius (c. 203 – 120) wrote on the rise of Rome to world prominence, and attempted to harmonize the Greek and Roman points of view.
The Chaldean priest Berossus ( 3rd century) composed a Greek-language "History of Babylonia" for the Seleucid king Antiochus I, combining Hellenistic methods of historiography and Mesopotamian accounts to form a unique composite. Reports exist of other near-eastern histories, such as that of the Phoenician historian Sanchuniathon; but he is considered semi-legendary and writings attributed to him are fragmentary, known only through the later historians Philo of Byblos and Eusebius, who asserted that he wrote before even the Trojan war.
Roman world.
The Romans adopted the Greek tradition, writing at first in Greek, but eventually chronicling their history in a freshly non-Greek language. While early Roman works were still written in Greek, the "Origines", composed by the Roman statesman Cato the Elder (234–149), was written in Latin, in a conscious effort to counteract Greek cultural influence. It marked the beginning of Latin historical writings. Hailed for its lucid style, Julius Caesar's (100–44) "Bellum Gallicum" exemplifies autobiographical war coverage. The politician and orator Cicero (106–43) introduced rhetorical elements in his political writings.
Strabo (63 – c. 24) was an important exponent of the Greco-Roman tradition of combining geography with history, presenting a descriptive history of peoples and places known to his era. Livy (59 – 17) records the rise of Rome from city-state to empire. His speculation about what would have happened if Alexander the Great had marched against Rome represents the first known instance of alternate history.
Biography, although popular throughout antiquity, was introduced as a branch of history by the works of Plutarch (c. 46 – 127) and Suetonius (c. 69 – after 130) who described the deeds and characters of ancient personalities, stressing their human side. Tacitus (c. 56 – c. 117) denounces Roman immorality by praising German virtues, elaborating on the topos of the Noble savage.
Christendom.
Christian historiography began early, perhaps as early as Luke-Acts, which is the primary source for the Apostolic Age, though its historical reliability is disputed. In the first Christian centuries, the New Testament canon was developed. The growth of Christianity and its enhanced status in the Roman Empire after Constantine I (see State church of the Roman Empire) led to the development of a distinct Christian historiography, influenced by both Christian theology and the nature of the Christian Bible, encompassing new areas of study and views of history. The central role of the Bible in Christianity is reflected in the preference of Christian historians for written sources, compared to the classical historians' preference for oral sources and is also reflected in the inclusion of politically unimportant people. Christian historians also focused on development of religion and society. This can be seen in the extensive inclusion of written sources in the "Ecclesiastical History" written by Eusebius of Caesarea around 324 and in the subjects it covers. Christian theology considered time as linear, progressing according to divine plan. As God's plan encompassed everyone, Christian histories in this period had a universal approach. For example, Christian writers often included summaries of important historical events prior to the period covered by the work.
Writing history was popular among Christian monks and clergy in the Middle Ages. They wrote about the history of Jesus Christ, that of the Church and that of their patrons, the dynastic history of the local rulers. In the Early Middle Ages historical writing often took the form of annals or chronicles recording events year by year, but this style tended to hamper the analysis of events and causes. An example of this type of writing is the Anglo-Saxon Chronicles, which were the work of several different writers: it was started during the reign of Alfred the Great in the late 9th century, but one copy was still being updated in 1154. Some writers in the period did construct a more narrative form of history. These included Gregory of Tours, and more successfully Bede who wrote both secular and ecclesiastical history and is known for writing the "Ecclesiastical History of the English People".
During the Renaissance, history was written about states or nations. The study of history changed during the Enlightenment and Romanticism. Voltaire described the history of certain ages that he considered important, rather than describing events in chronological order. History became an independent discipline. It was not called "philosophia historiae" anymore, but merely history ("historia").
Islamic world.
Muslim historical writings first began to develop in the 7th century, with the reconstruction of the Prophet Muhammad's life in the centuries following his death. With numerous conflicting narratives regarding Muhammad and his companions from various sources, it was necessary to verify which sources were more reliable. In order to evaluate these sources, various methodologies were developed, such as the "science of biography", "science of hadith" and "Isnad" (chain of transmission). These methodologies were later applied to other historical figures in the Islamic civilization. Famous historians in this tradition include Urwah (d. 712), Wahb ibn Munabbih (d. 728), Ibn Ishaq (d. 761), al-Waqidi (745–822), Ibn Hisham (d. 834), Muhammad al-Bukhari (810–870) and Ibn Hajar (1372–1449). Historians of the medieval Islamic world also developed an interest in world history.
Islamic historical writing eventually culminated in the works of the Arab Muslim historian Ibn Khaldun (1332–1406), who published his historiographical studies in the "Muqaddimah" (translated as "Prolegomena") and "Kitab al-I'bar" ("Book of Advice"). His work was forgotten until it was rediscovered in the late 19th century.
Enlightenment.
During the Age of Enlightenment, the modern development of historiography through the application of scrupulous methods began.
Voltaire.
French "philosophe" Voltaire (1694–1778) had an enormous influence on the art of history writing. His best-known histories are "The Age of Louis XIV" (1751), and "Essay on the Customs and the Spirit of the Nations" (1756). "My chief object," he wrote in 1739, "is not political or military history, it is the history of the arts, of commerce, of civilization – in a word, – of the human mind." He broke from the tradition of narrating diplomatic and military events, and emphasized customs, social history and achievements in the arts and sciences. The "Essay on Customs" traced the progress of world civilization in a universal context, thereby rejecting both nationalism and the traditional Christian frame of reference. Influenced by Bossuet's "Discourse on the Universal History" (1682), he was the first scholar to make a serious attempt to write the history of the world, eliminating theological frameworks, and emphasizing economics, culture and political history. He treated Europe as a whole, rather than a collection of nations. He was the first to emphasize the debt of medieval culture to Arab civilization, but otherwise was weak on the Middle Ages. Although he repeatedly warned against political bias on the part of the historian, he lost few opportunities to expose what he saw as the intolerance and frauds of the church over the ages. Voltaire advised scholars that anything contradicting the normal course of nature was not to be believed. Although he found evil in the historical record, he fervently believed reason and educating the illiterate masses would lead to progress. Voltaire explains his view of historiography in his article on "History" in Diderot's "Encyclopédie":
Voltaire's histories used the values of the Enlightenment to evaluate the past. He helped free historiography from antiquarianism, Eurocentrism, religious intolerance and a concentration on great men, diplomacy, and warfare. Peter Gay says Voltaire wrote "very good history," citing his "scrupulous concern for truths," "careful sifting of evidence," "intelligent selection of what is important," "keen sense of drama," and "grasp of the fact that a whole civilization is a unit of study."
David Hume.
At the same time, philosopher David Hume was having a similar impact on history in Great Britain. In 1754 he published the "History of England", a 6-volume work which extended "From the Invasion of Julius Caesar to the Revolution in 1688". Hume adopted a similar scope to Voltaire in his history; as well as the history of Kings, Parliaments, and armies, he examined the history of culture, including literature and science, as well. His short biographies of leading scientists explored the process of scientific change and he developed new ways of seeing scientists in the context of their times by looking at how they interacted with society and each other – he paid special attention to Francis Bacon, Robert Boyle, Isaac Newton and William Harvey.
He also argued that the quest for liberty was the highest standard for judging the past, and concluded that after considerable fluctuation, England at the time of his writing had achieved "the most entire system of liberty, that was ever known amongst mankind."
William Robertson.
William Robertson, a Scottish historian, and the Historiographer Royal published the "History of Scotland 1542 - 1603", in 1759 and his most famous work, "The history of the reign of Charles V" in 1769. His scholarship was painstaking for the time and he was able to access a large number of documentary sources that had previously been unstudied. He was also one of the first historians who understood the importance of general and universally applicable ideas in the shaping of historical events.
Edward Gibbon.
The apex of Enlightenment history was reached with Edward Gibbon's monumental six-volume work, "The History of the Decline and Fall of the Roman Empire", published on 17 February 1776. Because of its relative objectivity and heavy use of primary sources, its methodology became a model for later historians. This has led to Gibbon being called the first "modern historian". The book sold impressively, earning its author a total of about £9000. Biographer Leslie Stephen wrote that thereafter, "His fame was as rapid as it has been lasting."
Gibbon's work has been praised for its style, its piquant epigrams and its effective irony. Winston Churchill memorably noted, "I set out upon...Gibbon's "Decline and Fall of the Roman Empire" [and] was immediately dominated both by the story and the style. ...I devoured Gibbon. I rode triumphantly through it from end to end and enjoyed it all." Gibbon was pivotal in the secularizing and 'desanctifying' of history, with his fiercely polemical attacks on Christianity. Unusually for an 18th-century historian, Gibbon was never content with secondhand accounts when the primary sources were accessible (though most of these were drawn from well-known printed editions). "I have always endeavoured," he says, "to draw from the fountain-head; that my curiosity, as well as a sense of duty, has always urged me to study the originals; and that, if they have sometimes eluded my search, I have carefully marked the secondary evidence, on whose faith a passage or a fact were reduced to depend." In this insistence upon the importance of primary sources, Gibbon is considered by many to have broken new ground in the methodical study of history:
In accuracy, thoroughness, lucidity, and comprehensive grasp of a vast subject, the 'History' is unsurpassable. It is the one English history which may be regarded as definitive. ...Whatever its shortcomings the book is artistically imposing as well as historically unimpeachable as a vast panorama of a great period.
19th century.
The tumultuous events surrounding the French Revolution inspired much of the historiography and analysis of the early 19th century. Interest in the 1688 Glorious Revolution was also rekindled by the Great Reform Act of 1832 in England.
Thomas Carlyle.
Thomas Carlyle published his three-volume "", in 1837. The first volume was accidentally burned by John Stuart Mill's maid. Carlyle rewrote it from scratch. Carlyle's style of historical writing stressed the immediacy of action, often using the present tense. He emphasised the role of forces of the spirit in history and thought that chaotic events demanded what he called 'heroes' to take control over the competing forces erupting within society. He considered the dynamic forces of history as being the hopes and aspirations of people that took the form of ideas, and were often ossified into ideologies. Carlyle's "The French Revolution" was written in a highly unorthodox style, far removed from the neutral and detached tone of the tradition of Gibbon. Carlyle presented the history as dramatic events unfolding in the present as though he and the reader were participants on the streets of Paris at the [famous events. Carlyle's invented style was epic poetry combined with philosophical treatise. It is rarely read or cited in the last century.
Thomas Macaulay.
Thomas Macaulay produced his most famous work of history, "The History of England from the Accession of James the Second", in 1848. His writings are famous for their ringing prose and for their confident, sometimes dogmatic, emphasis on a progressive model of British history, according to which the country threw off superstition, autocracy and confusion to create a balanced constitution and a forward-looking culture combined with freedom of belief and expression. This model of human progress has been called the Whig interpretation of history.
His legacy continues to be controversial; Gertrude Himmelfarb wrote that "most professional historians have long since given up reading Macaulay, as they have given up writing the kind of history he wrote and thinking about history as he did." However, J. R. Western wrote that: "Despite its age and blemishes, Macaulay's "History of England" has still to be superseded by a full-scale modern history of the period".
French historians: Michelet and Taine.
In his main work "Histoire de France", French historian Jules Michelet coined the term Renaissance (meaning "Rebirth" in French language), as a period in Europe's cultural history that represented a break from the Middle Ages, creating a modern understanding of humanity and its place in the world.
The nineteen volume work covered French history from Charlemagne to the outbreak of the Revolution.
Michelet was one of the first historians to shift the emphasis of history to the common people, rather than the leaders and institutions of the country. He devoted himself to writing a picturesque history of the Middle Ages, and his account is still one of the most vivid that exists. His inquiry into manuscript and printed authorities was most laborious, but his lively imagination, and his strong religious and political prejudices, made him regard all things from a singularly personal point of view.
Hippolyte Taine was the chief theoretical influence of French naturalism, a major proponent of sociological positivism and one of the first practitioners of historicist criticism. He was unable to secure an academic position. He pioneered The idea of "milieu" as an active historical force which amalgamated geographical, psychological and social factors. Historical writing for him was a search for general laws. His brilliant style kept his writing in circulation long after his theoretical approaches were passe.
Cultural and constitutional history.
One of the major progenitors of the history of culture and art, was the Swiss historian Jacob Burckhardt Siegfried Giedion described Burckhardt's achievement in the following terms: "The great discoverer of the age of the Renaissance, he first showed how a period should be treated in its entirety, with regard not only for its painting, sculpture and architecture, but for the social institutions of its daily life as well." Burckhardt's best known work is "The Civilization of the Renaissance in Italy" (1860).
His most famous work was "The Civilization of the Renaissance in Italy", published in 1860; it was the most influential interpretation of the Italian Renaissance in the nineteenth century and is still widely read. According to John Lukacs, he was the first master of cultural history, which seeks to describe the spirit and the forms of expression of a particular age, a particular people, or a particular place. His innovative approach to historical research stressed the importance of art and its inestimable value as a primary source for the study of history. He was one of the first historians to rise above the narrow nineteenth-century notion that "history is past politics and politics current history.
By the mid-19th century, scholars were beginning to analyse the history of institutional change, particularly the development of constitutional government. William Stubbs's "Constitutional History of England" (3 vols., 1874–78) was an important influence on this developing field. The work traced the development of the English constitution from the Teutonic invasions of Britain until 1485, and marked a distinct step in the advance of English historical learning. He argued that the theory of the unity and continuity of history should not remove distinctions between ancient and modern history. He believed that, though work on ancient history is a useful preparation for the study of modern history, either may advantageously be studied apart. He was a good palaeographer, and excelled in textual criticism, in examination of authorship, and other such matters, while his vast erudition and retentive memory made him second to none in interpretation and exposition.
Von Ranke and Professionalization in Germany.
The modern academic study of history and methods of historiography were pioneered in 19th-century German universities, especially the University of Göttingen. Leopold von Ranke was a pivotal influence in this regard, and is considered as the founder of modern source-based history. According to Caroline Hoefferle, “Ranke was probably the most important historian to shape historical profession as it emerged in Europe and the United States in the late 19th century.”
Specifically, he implemented the seminar teaching method in his classroom, and focused on archival research and analysis of historical documents. Beginning with his first book in 1824, the "History of the Latin and Teutonic Peoples from 1494 to 1514", Ranke used an unusually wide variety of sources for a historian of the age, including "memoirs, diaries, personal and formal missives, government documents, diplomatic dispatches and first-hand accounts of eye-witnesses". Over a career that spanned much of the century, Ranke set the standards for much of later historical writing, introducing such ideas as reliance on primary sources, an emphasis on narrative history and especially international politics ("aussenpolitik"). Sources had to be solid, not speculations and rationalizations. His credo was to write history the way it was. He insisted on primary sources with proven authenticity.
Ranke also rejected the 'teleological approach' to history, which traditionally viewed each period as inferior to the period which follows. In Ranke's view, the historian had to understand a period on its own terms, and seek to find only the general ideas which animated every period of history. In 1831 and at the behest of the Prussian government, Ranke founded and edited the first historical journal in the world, called "Historisch-Politische Zeitschrift".
Another important German thinker was Georg Wilhelm Friedrich Hegel, whose theory of historical progress ran counter to Ranke's approach. In Hegel's own words, his philosophical theory of "World history... represents the development of the spirit's consciousness of its own freedom and of the consequent realization of this freedom.". This realization is seen by studying the various cultures that have developed over the millennia, and trying to understand the way that freedom has worked itself out through them:
World history is the record of the spirit's efforts to attain knowledge of what it is in itself. The Orientals do not know that the spirit or man as such are free in themselves. And because they do not know that, they are not themselves free. They only know that One is free... The consciousness of freedom first awoke among the Greeks, and they were accordingly free; but, like the Romans, they only knew that Some, and not all men as such, are free... The Germanic nations, with the rise of Christianity, were the first to realize that All men are by nature free, and that freedom of spirit is his very essence.
Karl Marx introduced the concept of historical materialism into the study of world historical development. In his conception, the economic conditions and dominant modes of production determined the structure of society at that point. In his view five successive stages in the development of material conditions would occur in Western Europe. The first stage was primitive communism where property was shared and there was no concept of "leadership". This progressed to a slave society where the idea of class emerged and the State developed. Feudalism was characterized by an aristocracy working in partnership with a theocracy and the emergence of the Nation-state. Capitalism appeared after the bourgeois revolution when the capitalists (or their merchant predecessors) overthrew the feudal system and established a market economy, with
private property and Parliamentary democracy. Marx then predicted the eventual proletarian revolution that would result in the attainment of socialism, followed by Communism, where property would be communally owned.
Previous historians had focused on cyclical events of the rise and decline of rulers and nations. Process of nationalization of history, as part of national revivals in the 19th century, resulted with separation of "one's own" history from common universal history by such way of perceiving, understanding and treating the past that constructed history as history of a nation. A new discipline, sociology, emerged in the late 19th century and analyzed and compared these perspectives on a larger scale.
20th century.
Macaulay and Whig history.
The term Whig history, coined by Herbert Butterfield in his short book "The Whig Interpretation of History" in 1931, means the approach to historiography which presents the past as an inevitable progression towards ever greater liberty and enlightenment, culminating in modern forms of liberal democracy and constitutional monarchy. In general, Whig historians emphasized the rise of constitutional government, personal freedoms and scientific progress. The term has been also applied widely in historical disciplines outside of British history (the history of science, for example) to criticize any teleological (or goal-directed), hero-based, and transhistorical narrative.
Paul Rapin de Thoyras's history of England, published in 1723, became "the classic Whig history" for the first half of the 18th century. It was later supplanted by the immensely popular "The History of England" by David Hume. Whig historians emphasized the achievements of the Glorious Revolution of 1688. This included James Mackintosh's "History of the Revolution in England in 1688", William Blackstone's "Commentaries on the Laws of England" and Henry Hallam's "Constitutional History of England".
The most famous exponent of 'Whiggery' was Thomas Babington Macaulay, who published the first volumes of his "The History of England from the Accession of James II" in 1848. It proved an immediate success and replaced Hume's history to become the new orthodoxy. His 'Whiggish convictions' are spelled out in his first chapter:
This consensus was steadily undermined during the post-World War I re-evaluation of European history, and Butterfield's critique exemplified this trend. Intellectuals no longer believed the world was automatically getting better and better. Subsequent generations of academic historians have similarly rejected Whig history because of its presentist and teleological assumption that history is driving toward some sort of goal. Other criticized 'Whig' assumptions included viewing the British system as the apex of human political development, assuming that political figures in the past held current political beliefs (anachronism), considering British history as a march of progress with inevitable outcomes and presenting political figures of the past as heroes, who advanced the cause of this political progress, or villains, who sought to hinder its inevitable triumph. J. Hart says "a Whig interpretation requires human heroes and villains in the story."
France: Annales School.
The French Annales School radically changed the focus of historical research in France during the 20th century by stressing long-term social history, rather than political or diplomatic themes. The school emphasized the use of quantification and the paying of special attention to geography.
The "Annales d'histoire économique et sociale" journal was founded in 1929 in Strasbourg by Marc Bloch and Lucien Febvre. These authors, the former a medieval historian and the latter an early modernist, quickly became associated with the distinctive "Annales" approach, which combined geography, history, and the sociological approaches of the Année Sociologique (many members of which were their colleagues at Strasbourg) to produce an approach which rejected the predominant emphasis on politics, diplomacy and war of many 19th and early 20th-century historians as spearheaded by historians whom Febvre called Les Sorbonnistes. Instead, they pioneered an approach to a study of long-term historical structures ("la longue durée") over events and political transformations. Geography, material culture, and what later Annalistes called "mentalités," or the psychology of the epoch, are also characteristic areas of study. The goal of the Annales was to undo the work of the Sorbonnistes, to turn French historians away from the narrowly political and diplomatic toward the new vistas in social and economic history.
An eminent member of this school, Georges Duby, described his approach to history as one that relegated the sensational to the sidelines and was reluctant to give a simple accounting of events, but strived on the contrary to pose and solve problems and, neglecting surface disturbances, to observe the long and medium-term evolution of economy, society and civilisation. The Annalistes, especially Lucien Febvre, advocated a "histoire totale", or "histoire tout court", a complete study of a historic problem.
The second era of the school was led by Fernand Braudel and was very influential throughout the 1960s and 1970s, especially for his work on the Mediterranean region in the era of Philip II of Spain. Braudel developed the idea, often associated with Annalistes, of different modes of historical time: "l'histoire quasi immobile" (motionless history) of historical geography, the history of social, political and economic structures ("la longue durée"), and the history of men and events, in the context of their structures. His 'longue durée' approach stressed slow, and often imperceptible effects of space, climate and technology on the actions of human beings in the past. The "Annales" historians, after living through two world wars and incredible political upheavals in France, were deeply uncomfortable with the notion that multiple ruptures and discontinuities created history. They preferred to stress inertia and the longue durée. Special attention was paid to geography, climate, and demography as long-term factors. They believed the continuities of the deepest structures were central to history, beside which upheavals in institutions or the superstructure of social life were of little significance, for history lies beyond the reach of conscious actors, especially the will of revolutionaries.
Noting the political upheavals in Europe and especially in France in 1968, Eric Hobsbawm argued that "in France the virtual hegemony of Braudelian history and the "Annales" came to an end after 1968, and the international influence of the journal dropped steeply." Multiple responses were attempted by the school. Scholars moved in multiple directions, covering in disconnected fashion the social, economic, and cultural history of different eras and different parts of the globe. By the time of crisis the school was building a vast publishing and research network reaching across France, Europe, and the rest of the world. Influence indeed spread out from Paris, but few new ideas came in. Much emphasis was given to quantitative data, seen as the key to unlocking all of social history. However, the Annales ignored the developments in quantitative studies underway in the U.S. and Britain, which reshaped economic, political and demographic research.
Marxist historiography.
Marxist historiography developed as a school of historiography influenced by the chief tenets of Marxism, including the centrality of social class and economic constraints in determining historical outcomes. Friedrich Engels wrote "The Peasant War in Germany", which analysed social warfare in early Protestant Germany in terms of emerging capitalist classes. Although it lacked a rigorous engagement with archival sources, it indicated an early interest in history from below and class analysis, and it attempts a dialectical analysis. Another treatise of Engels, "The Condition of the Working Class in England in 1844", was salient in creating the socialist impetus in British politics from then on, e.g. the Fabian Society.
R. H. Tawney was an early historian working in this tradition. "The Agrarian Problem in the Sixteenth Century" (1912) and "Religion and the Rise of Capitalism" (1926), reflected his ethical concerns and preoccupations in economic history. He was profoundly interested in the issue of the enclosure of land in the English countryside in the sixteenth and seventeenth centuries and in Max Weber's thesis on the connection between the appearance of Protestantism and the rise of capitalism. His belief in the rise of the gentry in the century before the outbreak of the Civil War in England provoked the 'Storm over the Gentry' in which his methods were subjected to severe criticisms by Hugh Trevor-Roper and John Cooper.
A circle of historians inside the Communist Party of Great Britain (CPGB) formed in 1946 and became a highly influential cluster of British Marxist historians, who contributed to history from below and class structure in early capitalist society. While some members of the group (most notably Christopher Hill and E. P. Thompson) left the CPGB after the 1956 Hungarian Revolution, the common points of British Marxist historiography continued in their works. They placed a great emphasis on the subjective determination of history.
Christopher Hill's studies on 17th-century English history were widely acknowledged and recognised as representative of this school. His books include "Puritanism and Revolution" (1958), "Intellectual Origins of the English Revolution" (1965 and revised in 1996), "The Century of Revolution" (1961), "AntiChrist in 17th-century England" (1971), "The World Turned Upside Down" (1972) and many others.
E. P. Thompson pioneered the study of history from below in his work, "The Making of the English Working Class", published in 1963. It focused on the forgotten history of the first working-class political left in the world in the late-18th and early-19th centuries. In his preface to this book, Thompson set out his approach to writing history from below:
I am seeking to rescue the poor stockinger, the Luddite cropper, the "obsolete" hand-loom weaver, the "Utopian" artisan, and even the deluded follower of Joanna Southcott, from the enormous condescension of posterity. Their crafts and traditions may have been dying. Their hostility to the new industrialism may have been backward-looking. Their communitarian ideals may have been fantasies. Their insurrectionary conspiracies may have been foolhardy. But they lived through these times of acute social disturbance, and we did not. Their aspirations were valid in terms of their own experience; and, if they were casualties of history, they remain, condemned in their own lives, as casualties.
Thompson's work was also significant because of the way he defined "class." He argued that class was not a structure, but a relationship that changed over time. He opened the gates for a generation of labor historians, such as David Montgomery and Herbert Gutman, who made similar studies of the American working classes.
Other important Marxist historians included Eric Hobsbawm, C. L. R. James, Raphael Samuel, A. L. Morton and Brian Pearce.
Although Marxist historiography made important contributions to the history of the working class, oppressed nationalities, and the methodology of history from below, its chief problematic aspect was its argument on the nature of history as "determined" or "dialectical"; this can also be stated as the relative importance of subjective and objective factors in creating outcomes. It increasingly fell out of favour in the 1960s and '70s. Geoffrey Elton was important in undermining the case for a Marxist historiography, about which he argued was presenting seriously flawed interpretations of the past. In particular, Elton was opposed to the idea that the English Civil War was caused by socioeconomic changes in the 16th and 17th centuries, arguing instead that it was due largely to the incompetence of the Stuart kings.
In dealing with the era of the Second World War, Addison notes that in Britain by the 1990s, labour history was, "in sharp decline," because:
Biography.
Biography has been a major form of historiography since the days when Plutarch wrote the parallel lives of great Roman and Greek leaders. It is a field especially attractive to nonacademic historians, and often to the wives or children of famous men who have access to the trove of letters and documents. Academic historians tend to downplay biography because it pays too little attention to broad social, cultural, political and economic forces, and perhaps too much attention to popular psychology. The “Great Man” tradition in Britain originated in the multi-volume "Dictionary of National Biography" (which originated in 1882 and issued updates into the 1970s); it continues to this day in the new "Oxford Dictionary of National Biography." In the United States, the "Dictionary of American Biography" was planned in the late 1920s and appeared with numerous supplements into the 1980s. It has now been displaced by the "American National Biography" as well as numerous smaller historical encyclopedias that give thorough coverage to Great Persons. Bookstores do a thriving business in biographies, which sell far more copies than the esoteric monographs based on post-structuralism, cultural, racial or gender history. Michael Holroyd says the last forty years “may be seen as a golden age of biography” but nevertheless calls it the "shallow end of history." Nicolas Barker argues that “more and more biographies command an ever larger readership,” as he speculates that biography has come “to express the spirit of our age."
British debates.
Marxist historian E. H. Carr developed a controversial theory of history in his 1961 book "What Is History?", which proved to be one of the most influential books ever written on the subject. He presented a middle-of-the-road position between the empirical or (Rankean) view of history and R. G. Collingwood's idealism, and rejected the empirical view of the historian's work being an accretion of "facts" that he or she has at their disposal as nonsense. He maintained that there is such a vast quantity of information that the historian always chooses the "facts" he or she decides to make use of. In Carr's famous example, he claimed that millions had crossed the Rubicon, but only Julius Caesar's crossing in 49 BC is declared noteworthy by historians. For this reason, Carr argued that Leopold von Ranke's famous dictum "wie es eigentlich gewesen" (show what actually happened) was wrong because it presumed that the "facts" influenced what the historian wrote, rather than the historian choosing what "facts of the past" he or she intended to turn into "historical facts". At the same time, Carr argued that the study of the facts may lead the historian to change his or her views. In this way, Carr argued that history was "an unending dialogue between the past and present".
Carr is held by some critics to have had a deterministic outlook in history. Others have modified or rejected this use of the label 'determinist'. He took a hostile view of those historians who stress the workings of chance and contingency in the workings of history. In Carr's view, no individual is truly free of the social environment in which they live, but contended that within those limitations, there was room, albeit very narrow room for people to make decisions that have an impact on history. Carr emphatically contended that history was a social science, not an art, because historians like scientists seek generalizations that helped to broaden the understanding of one's subject.
One of Carr's most forthright critics was Hugh Trevor-Roper, who argued that Carr's dismissal of the "might-have-beens of history" reflected a fundamental lack of interest in examining historical causation. Trevor-Roper asserted that examining possible alternative outcomes of history was far from being a "parlour-game" was rather an essential part of the historians' work, as only by considering all possible outcomes of a given situation could a historian properly understand the period.
The controversy inspired Sir Geoffrey Elton to write his 1967 book "The Practice of History". Elton criticized Carr for his "whimsical" distinction between the "historical facts" and the "facts of the past", arguing that it reflected "...an extraordinarily arrogant attitude both to the past and to the place of the historian studying it". Elton, instead, strongly defended the traditional methods of history and was also appalled by the inroads made by postmodernism. Elton saw the duty of historians as empirically gathering evidence and objectively analyzing what the evidence has to say. As a traditionalist, he placed great emphasis on the role of individuals in history instead of abstract, impersonal forces. Elton saw political history as the highest kind of history. Elton had no use for those who seek history to make myths, to create laws to explain the past, or to produce theories such as Marxism.
American approaches.
In the historiography of the United States, there were a series of major approaches in the 20th century. In 2009-2012, there were an average of 16,000 new academic history books published in the U.S. every year.
Progressive historians.
From 1910 to the 1940s, "Progressive" historiography was dominant, especially in political studies. It stressed the central importance of class conflict in American history. Important leaders included Vernon L. Parrington, Carl L. Becker, Arthur M. Schlesinger, Sr., John Hicks, and C. Vann Woodward. The movement established a strong base at the History Department at the University of Wisconsin with Curtis Nettels, William Hesseltine, Merle Curti, Howard K. Beale, Merrill Jensen, Fred Harvey Harrington (who became the university president), William Appleman Williams, and a host of graduate students. Charles A. Beard was the most prominent representative with his "Beardian" approach that reached both scholars and the general public.
In covering the Civil War, Charles and Mary Beard did not find it useful to examine nationalism, unionism, states' rights, slavery, abolition or the motivations of soldiers in battle. Instead, they proclaimed it was a:
Arthur Schlesinger, Jr. wrote the "Age of Jackson" (1945), one of the last major books from this viewpoint. Schlesinger made Jackson a hero for his successful attacks on the Second Bank of the United States. His own views were clear enough: "Moved typically by personal and class, rarely by public, considerations, the business community has invariably brought national affairs to a state of crisis and exasperated the rest of society into dissatisfaction bordering on revolt."
Consensus history.
Consensus history emphasizes the basic unity of American values and downplays conflict as superficial. It was especially attractive in the 1950s and 1960s. Prominent leaders included Richard Hofstadter, Louis Hartz, Daniel Boorstin, Allan Nevins, Clinton Rossiter, Edmund Morgan, and David M. Potter. In 1948 Hofstadter made a compelling statement of the consensus model of the American political tradition:
New Left history.
Consensus history was rejected by New Left viewpoints that attracted a younger generation of radical historians in the 1960s. These viewpoints stress conflict and emphasize the central roles of class, race and gender. The history of dissent, and the experiences of racial minorities and disadvantaged classes was central to the narratives produced by New Left historians.
New social and political history.
Social history, often called the new social history, is a broad branch that studies the experiences of ordinary people in the past. In its "golden age" it was a major growth field in the 1960s and 1970s, and still is well represented in history departments. However after 1980 the "cultural turn" directed the next generation to new topics. In the two decades from 1975 to 1995, the proportion of professors of history in American universities identifying with social history rose from 31% to 41%, while the proportion of political historians fell from 40% to 30%. It growth was inspired by the social sciences, computers, statistics, new data sources such as individual census information, and summer training programs at the Newberry Library and the University of Michigan. The "New Political History" saw the application of social history methods to politics, as the focus shifted from politicians and legislation to voters and elections.
The Cultural turn.
The "cultural turn" of the 1980s and 1990s affected scholars in most areas of history. Inspired largely by anthropology, it turned away from leaders, ordinary people and famous events to look at the use of language and cultural symbols to represent the changing values of society.
The British historian Peter Burke finds that cultural studies has numerous spinoffs, or topical themes it has strongly influenced. The most important include gender studies and postcolonial studies, as well as memory studies, and film studies.
Diplomatic historian Melvyn P. Leffler finds that the problem with the "cultural turn" is that the culture concept is imprecise, and may produce excessively broad interpretations, because it:
Memory studies.
Memory studies is a new field, focused on how nations and groups (and historians) construct and select their memories of the past in order to celebrate (or denounce) key features, thus making a statement of their current values and beliefs. Historians have played a central role in shaping the memories of the past as their work is diffused through popular history books and school textbooks. French sociologist Maurice Halbwachs, opened the field with "La mémoire collective" (Paris: 1950).
Many historians examine the how the memory of the past has been constructed, memorialized or distorted. Historians examine how legends are invented. For example there are numerous studies of the memory of atrocities from World War II, notably the Holocaust in Europe and Japanese behavior in Asia. British historian Heather Jones argues that the historiography of the First World War in recent years has been reinvigorated by the cultural turn. Scholars have raised entirely new questions regarding military occupation, radicalization of politics, race, and the male body.
Representative of recent scholarship is a collection of studies on the "Dynamics of Memory and Identity in Contemporary Europe" SAGE has published the scholarly journal "Memory Studies" since 2008, and the book series ‘Memory Studies’ was launched by Palgrave Macmillan in 2010 with 5-10 titles a year.
World history.
World history, as a distinct field of historical study, emerged as an independent academic field in the 1980s. It focused on the examination of history from a global perspective and looked for common patterns that emerged across all cultures. The basic thematic approach of this field was to analyse two major focal points: integration - (how processes of world history have drawn people of the world together), and difference - (how patterns of world history reveal the diversity of the human experience).
Arnold J. Toynbee's ten-volume "A Study of History", written between 1933 and 1954, was an important influence on this developing field. He took a comparative topical approach to 26 independent civilizations and demonstrated that they displayed striking parallels in their origin, growth, and decay. He proposed a universal model to each of these civilizations, detailing the stages through which they all pass: genesis, growth, time of troubles, universal state, and disintegration. With his endless output of papers, articles, speeches and presentations, and numerous books translated into many languages, Toynbee was perhaps the world’s most read and discussed scholar in the 1940s and 1950s. Yet Toynbee's work lost favor among both the general public and scholars by the 1960s, due to the religious and spiritual outlook that permeates the largest part of his work. His work has seldom been read or cited in recent decades.
Chicago historian William H. McNeill wrote "The Rise of the West" (1965) to improve upon Toynbee by showing how the separate civilizations of Eurasia interacted from the very beginning of their history, borrowing critical skills from one another, and thus precipitating still further change as adjustment between traditional old and borrowed new knowledge and practice became necessary. He then discusses the dramatic effect of Western civilization on others in the past 500 years of history. McNeill took a broad approach organized around the interactions of peoples across the globe. Such interactions have become both more numerous and more continual and substantial in recent times. Before about 1500, the network of communication between cultures was that of Eurasia. The term for these areas of interaction differ from one world historian to another and include "world-system" and "ecumene." His emphasis on cultural fusions had a major impact on historical theory.
Scholarly journals.
The historical journal, a forum where academic historians could exchange ideas and publish newly discovered information, came into being in the 19th century. The early journals were similar to those for the physical sciences, and were seen as a means for history to become more professional. Journals also helped historians to establish various historiographical approaches, the most notable example of which was "Annales. Économies. Sociétés. Civilisations.", a publication of the Annales School in France. Journals now typically have one or more editors and associate editors, an editorial board, and a pool of scholars to whom articles that are submitted are sent for confidential evaluation. The editors will send out new books to recognized scholars for reviews that usually run 500 to 1000 words. The vetting and publication process often takes months or longer. Publication in a prestigious journal (which accept 10% or fewer of the articles submitted) is an asset in the academic hiring and promotion process. Publication demonstrates that the author is conversant with the scholarly field. Page charges and fees for publication are uncommon in history. Journals are subsidized by universities or historical societies, scholarly associations, and subscription fees from libraries and scholars. Increasingly they are available through library pools that allow many academic institutions to pool subscriptions to online versions. Most libraries have a system for obtaining specific articles through inter-library loan.
Narrative.
According to Lawrence Stone, narrative has traditionally been the main rhetorical device used by historians. In 1979, at a time when the new Social History was demanding a social-science model of analysis, Stone detected a move back toward the narrative. Stone defined narrative as follows: it is organized chronologically; it is focused on a single coherent story; it is descriptive rather than analytical; it is concerned with people not abstract circumstances; and it deals with the particular and specific rather than the collective and statistical. He reported that, "More and more of the 'new historians' are now trying to discover what was going on inside people's heads in the past, and what it was like to live in the past, questions which inevitably lead back to the use of narrative."
Historians committed to a social science approach, however, have criticized the narrowness of narrative and its preference for anecdote over analysis, and its use of clever examples rather than statistically verified empirical regularities.
Topics studied.
Some of the common topics in historiography are:
Approaches.
How a historian approaches historical events is one of the most important decisions within historiography. It is commonly recognised by historians that, in themselves, individual historical facts dealing with names, dates and places are not particularly meaningful. Such facts will only become useful when assembled with other historical evidence, and the process of assembling this evidence is understood as a particular historiographical approach.
The most influential historiographical approaches are:
Scholars typically specialize in a particular theme and region. see:
Related fields.
Important related fields include:

</doc>
<doc id="13277" url="http://en.wikipedia.org/wiki?curid=13277" title="Holy Roman Empire">
Holy Roman Empire

 |- class="mergedbottomrow"
 |- class="mergedbottomrow"
 |- class="mergedbottomrow"
 |- class="mergedbottomrow"
 |- class="mergedbottomrow"
 |style="padding-left:0;text-align:left;"| 1200 est.
 |- class="mergedrow"
 |style="padding-left:0;text-align:left;"| 1500 est.
 |- class="mergedrow"
 |style="padding-left:0;text-align:left;"| 1618 est.
 |- class="mergedrow"
 |style="padding-left:0;text-align:left;"| 1648 est.
 |- class="mergedrow"
 |style="padding-left:0;text-align:left;"| 1786 est.
 |- class="mergedbottomrow"
The Holy Roman Empire (Latin: "Sacrum Romanum Imperium", German: "Heiliges Römisches Reich") was a multi-ethnic complex of territories in central Europe that developed during the Early Middle Ages and continued until its dissolution in 1806. The largest territory of the empire after 962 was the Kingdom of Germany, though it included the Kingdom of Bohemia, the Kingdom of Burgundy, the Kingdom of Italy, and numerous other territories.
On 25 December 800, Pope Leo III crowned the Frankish king Charlemagne as Emperor, reviving the title in Western Europe after more than three centuries. The title continued in the Carolingian family until 888, after which it was contested by the rulers of Italy in a series of civil wars until the death of the last Italian claimant, Berengar, in 924. The title was revived in 962 when Otto I was crowned emperor, fashioning himself as the successor of Charlemagne and beginning a continuous existence of the empire for over eight centuries. Some historians refer to the coronation of Charlemagne as the origin of the empire, while others prefer the coronation of Otto I as its beginning. Scholars generally concur, however, in relating an evolution of the institutions and principles constituting the empire, describing a gradual assumption of the imperial title and role.
The precise term Holy Roman Empire was not used until the 13th century, but the concept of "translatio imperii" was fundamental to the prestige of the emperor, the notion that he held supreme power inherited from the emperors of Rome. The office of Holy Roman Emperor was traditionally elective, although frequently controlled by dynasties. The German prince-electors, the highest ranking noblemen of the empire, usually elected one of their peers as "King of the Romans", and he would later be crowned emperor by the Pope; the tradition of papal coronations was discontinued in the 16th century. The empire never achieved the extent of political unification formed in France, evolving instead into a decentralized, limited elective monarchy composed of hundreds of sub-units, principalities, duchies, counties, Free Imperial Cities, and other domains. The power of the emperor was limited, and while the various princes, lords, and kings of the empire were vassals and subjects who owed the emperor their allegiance, they also possessed an extent of privileges that gave them "de facto" sovereignty within their territories. Emperor Francis II dissolved the empire on 6 August 1806, after its defeat by Napoleon at the Battle of Austerlitz.
Name.
In various languages the Holy Roman Empire was known as: Latin: "Sacrum Imperium Romanum", German: "Heiliges Römisches Reich", Italian: "Sacro Romano Impero", Czech: "Svatá říše římská", Slovene: "Sveto rimsko cesarstvo", Dutch: "Heilige Roomse Rijk", French: "Saint-Empire romain germanique". Before 1157, the realm was merely referred to as the Roman Empire. The term "sacrum" ("holy," in the sense of "consecrated") in connection with the medieval Roman Empire was used beginning in 1157, under Frederick I Barbarossa ("Holy Empire") – the term was added to reflect Frederick's ambition to dominate Italy and the Papacy; the form "Holy Roman Empire" is attested from 1254 onward.
In a decree following the 1512 Diet of Cologne, the name was changed to Holy Roman Empire of the German Nation (German: "Heiliges Römisches Reich Deutscher Nation", Latin: "Imperium Romanum Sacrum Nationis Germanicæ"), a form first used in a document in 1474. The new title was adopted partly because the Empire had lost most of its Italian and Burgundian (Kingdom of Arles) territories by the late 15th century, but also to emphasize the new importance of the German Imperial Estates in ruling the Empire due to the Imperial Reform. However, by the end of the 18th century, the term 'Holy Roman Empire of the German Nation' had fallen out of official use. As Hermann Weisert points out, "Documents were thirty times as likely to omit this 'national' suffix as include it." 
In a famous assessment of the name, the French Enlightenment writer Voltaire remarked sardonically: "This agglomeration which was called and which still calls itself the Holy Roman Empire was neither holy, nor Roman, nor an empire."
History.
Carolingian forerunners.
The Western Roman Empire, which began its terminal collapse in 408, was notionally reborn nearly four centuries later through "translatio imperii", the transfer of rule, to Charlemagne, King of the Franks. Charlemagne was crowned Emperor on Christmas Day 800 by Pope Leo III. 
The Carolingian imperial crown was disputed among the Carolingian rulers of Western Francia and Eastern Francia, with first the western king (Charles the Bald) and then the eastern (Charles the Fat) attaining the prize. After the death of Charles the Fat in 888, however, the Carolingian Empire broke asunder, never to be restored. According to Regino of Prüm, each part of the realm elected a "kinglet" from its own "bowels." After the death of Charles the Fat, those crowned emperor by the pope controlled only territories in Italy. The last such emperor was Berengar I of Italy, who died in 924.
High Middle Ages.
Formation.
Around 900, autonomous stem duchies (Franconia, Bavaria, Swabia, Saxony and Lotharingia) reemerged in East Francia. After the Carolingian king Louis the Child died without issue in 911, East Francia did not turn to the Carolingian ruler of West Francia to take over the realm but instead elected one of the dukes, Conrad of Franconia, as "Rex Francorum Orientalium".:117 On his deathbed, Conrad yielded the crown to his main rival, Henry the Fowler of Saxony (r. 919–36), who was elected king at the Diet of Fritzlar in 919.:118 Henry reached a truce with the raiding Magyars, and in 933 he won a first victory against them in the Battle of Riade.:121
Henry died in 936, but his descendants, the Liudolfing (or Ottonian) dynasty, would continue to rule the Eastern kingdom for roughly a century. Upon Henry the Fowler's death, Otto, his son and designated successor, was elected King in Aachen in 936.:706 He overcame a series of revolts from an elder brother and from several dukes. After that, the king managed to control the appointment of dukes and often also employed bishops in administrative affairs.:212–13
The kingdom had no permanent capital city. Kings traveled between residences (called Kaiserpfalz) to discharge affairs. However, each king preferred certain places; in Otto's case, this was the city of Magdeburg. Kingship continued to be transferred by election, but Kings often had their sons elected during their lifetimes, enabling them to keep the crown for their families. This only changed after the end of the Salian dynasty in the 12th century.
In 955, Otto won a decisive victory over the Magyars in the Battle of Lechfeld.:707 In 951, Otto came to the aid of Adelaide, the widowed queen of Italy, defeating her enemies, marrying her, and taking control over Italy.:214–15 In 962, Otto was crowned Emperor by Pope John XII,:707 thus intertwining the affairs of the German kingdom with those of Italy and the Papacy. Otto's coronation as Emperor marked the German kings as successors to the Empire of Charlemagne, which through the concept of "translatio imperii", also made them consider themselves as successors to Ancient Rome. Additionally, in 963, Otto deposed the current pope John XII and chose Pope Leo VIII as the new pope (although John XII and Leo VIII both claimed the papacy until 964, when John XII died).
This also renewed the conflict with the Eastern Emperor in Constantinople, especially after Otto's son Otto II (r. 967–83) adopted the designation "imperator Romanorum". Still, Otto formed marital ties with the east when he married the Byzantine princess Theophanu.:708
Their son, Otto III, came to the throne only three years old, and was subjected to a power struggle and series of regencies until his age of majority in 994. Up to that time, he had remained in Germany, while a deposed Duke, Crescentius II, ruled over Rome and part of Italy, ostensibly in his stead.
In 996 Otto III appointed his cousin Gregory V, the first German Pope. A foreign pope and foreign papal officers were seen with suspicion by Roman nobles, who were led by Crescentius II to revolt. Otto III's former mentor Antipope John XVI briefly held Rome, until the Holy Roman Emperor seized the city.
Otto died young in 1002, and was succeeded by his cousin Henry II, who focused on Germany.:215–17
Henry II died in 1024, and Conrad II, first of the Salian Dynasty, was elected king only after some debate among dukes and nobles. This group eventually developed into the college of Electors.
Investiture controversy.
Kings often employed bishops in administrative affairs and often determined who would be appointed to ecclesiastical offices.:101–134 In the wake of the Cluniac Reforms, this involvement was increasingly seen as inappropriate by the Papacy. The reform-minded Pope Gregory VII was determined to oppose such practices, which led to the Investiture Controversy with King Henry IV (r. 1056–1106).:101–134 He repudiated the Pope's interference and persuaded his bishops to excommunicate the Pope, whom he famously addressed by his born name "Hildebrand", rather than his regnal name "Pope Gregory VII".:109 The Pope, in turn, excommunicated the king, declared him deposed, and dissolved the oaths of loyalty made to Henry.:109 The king found himself with almost no political support and was forced to make the famous Walk to Canossa in 1077,:122–24 by which he achieved a lifting of the excommunication at the price of humiliation. Meanwhile, the German princes had elected another king, Rudolf of Swabia.:123 Henry managed to defeat him but was subsequently confronted with more uprisings, renewed excommunication, and even the rebellion of his sons. His second son, Henry V, reached an agreement with the Pope and the bishops in the 1122 Concordat of Worms.:123–34 The political power of the Empire was maintained, but the conflict had demonstrated the limits of any ruler's power, especially in regard to the Church, and it robbed the king of the sacral status he had previously enjoyed. The Pope and the German princes had surfaced as major players in the political system of the empire.
Hohenstaufen dynasty.
When the Salian dynasty ended with Henry V's death in 1125, the princes chose not to elect the next of kin, but rather Lothair, the moderately powerful but already old Duke of Saxony. When he died in 1137, the princes again aimed to check royal power; accordingly they did not elect Lothair's favoured heir, his son-in-law Henry the Proud of the Welf family, but Conrad III of the Hohenstaufen family, the grandson of Emperor Henry IV and thus a nephew of Emperor Henry V. This led to over a century of strife between the two houses. Conrad ousted the Welfs from their possessions, but after his death in 1152, his nephew Frederick I "Barbarossa" succeeded him and made peace with the Welfs, restoring his cousin Henry the Lion to his — albeit diminished — possessions.
The Hohenstaufen rulers increasingly lent land to "ministerialia," formerly non-free service men, whom Frederick hoped would be more reliable than dukes. Initially used mainly for war services, this new class of people would form the basis for the later knights, another basis of imperial power. A further important constitutional move at Roncaglia was the establishment of a new peace mechanism for the entire empire, the Landfrieden. This was an attempt to abolish private feuds, between the many dukes and other people, and to tie the Emperor's subordinates to a legal system of jurisdiction and public prosecution of criminal acts — a predecessor of the modern concept of "rule of law". Another new concept of the time was the systematic foundation of new cities by the Emperor and by the local dukes. These were partly caused by the explosion in population, and they also concentrated economic power at strategic locations. Before this, cities had only existed in the form of old Roman foundations or older bishoprics. Cities that were founded in the 12th century include Freiburg, possibly the economic model for many later cities, and Munich.
Frederick I, also called Frederick Barbarossa, was crowned Emperor in 1155. He emphasized the "Romanness" of the empire, partly in an attempt to justify the power of the Emperor independent of the (now strengthened) Pope. An imperial assembly at the fields of Roncaglia in 1158 reclaimed imperial rights in reference to Justinian's Corpus Juris Civilis. Imperial rights had been referred to as "regalia" since the Investiture Controversy, but were enumerated for the first time at Roncaglia. This comprehensive list included public roads, tariffs, coining, collecting punitive fees, and the investiture, the seating and unseating of office holders. These rights were now explicitly rooted in Roman Law, a far-reaching constitutional act.
Frederick's policies were primarily directed at Italy, where he clashed with the increasingly wealthy and free-minded cities of the north, especially Milan. He also embroiled himself in another conflict with the Papacy by supporting a candidate elected by a minority against Pope Alexander III (1159–81). Frederick supported a succession of antipopes before finally making peace with Alexander in 1177. In Germany, the Emperor had repeatedly protected Henry the Lion against complaints by rival princes or cities (especially in the cases of Munich and Lübeck). Henry gave only lackluster support to Frederick's policies, and in a critical situation during the Italian wars, Henry refused the Emperor's plea for military support. After returning to Germany, an embittered Frederick opened proceedings against the Duke, resulting in a public ban and the confiscation of all his territories. In 1190, Frederick participated in the Third Crusade and died in Asia Minor.
During the Hohenstaufen period, German princes facilitated a successful, peaceful eastward settlement of lands that were uninhabited or inhabited sparsely by West Slavs. German speaking farmers, traders, and craftsmen from the western part of the Empire, both Christians and Jews, moved into these areas. The gradual Germanization of these lands was a complex phenomenon that should not be interpreted in the biased terms of 19th-century nationalism. The eastward settlement expanded the influence of the empire to include Pomerania and Silesia, as did the intermarriage of the local, still mostly Slavic, rulers with German spouses. The Teutonic Knights were invited to Prussia by Duke Konrad of Masovia to Christianize the Prussians in 1226. The monastic state of the Teutonic Order (German: "Deutschordensstaat") and its later German successor state of Prussia were, however, never part of the Holy Roman Empire.
Under the son and successor of Frederick Barbarossa, Henry VI, the Hohenstaufen dynasty reached its apex. Henry added the Norman kingdom of Sicily to his domains, held English king Richard the Lionheart captive, and aimed to establish a hereditary monarchy when he died in 1197. As his son, Frederick II, though already elected king, was still a small child and living in Sicily, German princes chose to elect an adult king, resulting in the dual election of Frederick Barbarossa's youngest son Philip of Swabia and Henry the Lion's son Otto of Brunswick, who competed for the crown. Otto prevailed for a while after Philip was murdered in a private squabble in 1208, until he began to also claim Sicily.
Pope Innocent III, who feared the threat posed by a union of the empire and Sicily, now supported Frederick II, who marched to Germany and defeated Otto. After his victory, Frederick did not act upon his promise to keep the two realms separate – though he had made his son Henry king of Sicily before marching on Germany, he still reserved real political power for himself. This continued after Frederick was crowned Emperor in 1220. Fearing Frederick's concentration of power, the Pope finally excommunicated the Emperor. Another point of contention was the crusade, which Frederick had promised but repeatedly postponed. Now, though excommunicated, Frederick led the Sixth Crusade in 1228, which ended in negotiations and a temporary restoration of the Kingdom of Jerusalem.
Despite his imperial claims, Frederick's rule was a major turning point towards the disintegration of central rule in the Empire. While concentrated on establishing a modern, centralized state in Sicily, he was mostly absent from Germany and issued far-reaching privileges to Germany's secular and ecclesiastical princes: In the 1220 "Confoederatio cum principibus ecclesiasticis," Frederick gave up a number of "regalia" in favour of the bishops, among them tariffs, coining, and fortification. The 1232 "Statutum in favorem principum" mostly extended these privileges to secular territories. Although many of these privileges had existed earlier, they were now granted globally, and once and for all, to allow the German princes to maintain order north of the Alps while Frederick concentrated on Italy. The 1232 document marked the first time that the German dukes were called "domini terræ," owners of their lands, a remarkable change in terminology as well.
Kingdom of Bohemia.
The Kingdom of Bohemia was a significant regional power during the Middle Ages. In 1212, King Přemysl Otakar I (bearing the title "king" since 1198) extracted a Golden Bull of Sicily (a formal edict) from the emperor Frederick II, confirming the royal title for Otakar and his descendants and the Duchy of Bohemia was raised to a kingdom. Czech kings should be exempt from all future obligations to the Holy Roman Empire except for participation in the imperial councils. Charles IV set Prague to be the seat of the Holy Roman Emperor and thus it also became the capital of the Holy Roman Empire.
Interregnum.
After the death of Frederick II in 1250, the German kingdom was divided between his son Conrad IV (died 1254) and the anti-king, William of Holland (died 1256). Conrad's death was followed by the Interregnum, during which no king could achieve universal recognition, allowing the princes to consolidate their holdings and become even more independent rulers. After 1257, the crown was contested between Richard of Cornwall, who was supported by the Guelph party, and Alfonso X of Castile, who was recognized by the Hohenstaufen party but never set foot on German soil. After Richard's death in 1273, the Interregnum ended with the unanimous election of Rudolf I of Germany, a minor pro-Staufen count.
Changes in political structure.
During the 13th century, a general structural change in how land was administered prepared the shift of political power towards the rising bourgeoisie at the expense of aristocratic feudalism that would characterize the Late Middle Ages. Instead of personal duties, money increasingly became the common means to represent economic value in agriculture. Peasants were increasingly required to pay tribute for their lands. The concept of "property" began to replace more ancient forms of jurisdiction, although they were still very much tied together. In the territories (not at the level of the Empire), power became increasingly bundled: Whoever owned the land had jurisdiction, from which other powers derived. It is important to note, however, that jurisdiction at this time did not include legislation, which virtually did not exist until well into the 15th century. Court practice heavily relied on traditional customs or rules described as customary.
During this time territories began to transform into the predecessors of modern states. The process varied greatly among the various lands and was most advanced in those territories that were most identical to the lands of the old Germanic tribes, "e.g." Bavaria. It was slower in those scattered territories that were founded through imperial privileges.
Late Middle Ages.
Rise of the territories after the Hohenstaufens.
The difficulties in electing the king eventually led to the emergence of a fixed college of prince-electors ("Kurfürsten"), whose composition and procedures were set forth in the Golden Bull of 1356, which was valid until 1806. This development probably best symbolizes the emerging duality between emperor and realm ("Kaiser und Reich"), which were no longer considered identical. The Golden Bull also set the election system of the Holy Roman Emperor. The emperor now had to be elected by a majority rather than by consent of all seven electors. For electors the title became hereditary, and they were given the right to mint coins and to exercise jurisdiction. Also their sons were to know the imperial languages – German, Italian, and Czech.
The shift in power away from the emperor is also revealed in the way the post-Hohenstaufen kings attempted to sustain their power. Earlier, the Empire's strength (and finances) greatly relied on the Empire's own lands, the so-called "Reichsgut", which always belonged to the king of the day and included many Imperial Cities. After the 13th century, the relevance of the "Reichsgut" faded, even though some parts of it did remain until the Empire's end in 1806. Instead, the "Reichsgut" was increasingly pawned to local dukes, sometimes to raise money for the Empire, but more frequently to reward faithful duty or as an attempt to establish control over the dukes. The direct governance of the "Reichsgut" no longer matched the needs of either the king or the dukes.
The kings beginning with Rudolf I of Germany increasingly relied on the lands of their respective dynasties to support their power. In contrast with the "Reichsgut", which was mostly scattered and difficult to administer, these territories were relatively compact and thus easier to control. In 1282, Rudolf I thus lent Austria and Styria to his own sons. In 1312, Henry VII of the House of Luxembourg was crowned as the first Holy Roman Emperor since Frederick II. After him all kings and emperors relied on the lands of their own family ("Hausmacht"): Louis IV of Wittelsbach (king 1314, emperor 1328–47) relied on his lands in Bavaria; Charles IV of Luxembourg, the grandson of Henry VII, drew strength from his own lands in Bohemia. Interestingly, it was thus increasingly in the king's own interest to strengthen the power of the territories, since the king profited from such a benefit in his own lands as well.
Imperial reform.
The "constitution" of the Empire was still largely unsettled at the beginning of the 15th century. Although some procedures and institutions had been fixed, for example by the Golden Bull of 1356, the rules of how the king, the electors, and the other dukes should cooperate in the Empire much depended on the personality of the respective king. It therefore proved somewhat damaging that Sigismund of Luxemburg (king 1410, emperor 1433–37) and Frederick III of Habsburg (king 1440, emperor 1452–93) neglected the old core lands of the empire and mostly resided in their own lands. Without the presence of the king, the old institution of the "Hoftag", the assembly of the realm's leading men, deteriorated. The "Imperial Diet" as a legislative organ of the Empire did not exist at that time. Even worse, dukes often went into feuds against each other that, more often than not, escalated into local wars.
Simultaneously, the Church was in a state of crisis too, with wide-reaching effects in the Empire. The conflict between several papal claimants (two anti-popes and the legitimate Pope) was only resolved at the Council of Constance (1414–18); after 1419, much energy was spent on fighting the Hussites. The medieval idea of unifying all Christendom into a single political entity, of which the Church and the Empire were the leading institutions, began to decline.
With these drastic changes, much discussion emerged in the 15th century about the Empire itself. Rules from the past no longer adequately described the structure of the time, and a reinforcement of earlier "Landfrieden" was urgently called for. During this time, the concept of "reform" emerged, in the original sense of the Latin verb "re-formare", to regain an earlier shape that had been lost.
When Frederick III needed the dukes to finance war against Hungary in 1486 and at the same time had his son, later Maximilian I elected king, he was presented with the dukes' united demand to participate in an Imperial Court. For the first time, the assembly of the electors and other dukes was now called the Imperial Diet (German "Reichstag") (to be joined by the Imperial Free Cities later). While Frederick refused, his more conciliatory son finally convened the Diet at Worms in 1495, after his father's death in 1493. Here, the king and the dukes agreed on four bills, commonly referred to as the "Reichsreform" (Imperial Reform): a set of legal acts to give the disintegrating Empire back some structure. Among others, this act produced the Imperial Circle Estates and the "Reichskammergericht" (Imperial Chamber Court); structures that would—to a degree—persist until the end of the Empire in 1806.
However, it took a few more decades until the new regulation was universally accepted and the new court actually began to function; only in 1512 would the Imperial Circles be finalized. The King also made sure that his own court, the "Reichshofrat", continued to function in parallel to the "Reichskammergericht". In this year, the Empire also received its new title, the "Heiliges Römisches Reich Deutscher Nation" ("Holy Roman Empire of the German Nation").
Reformation and Renaissance.
In 1516, Ferdinand II of Aragon, grandfather of the future Holy Roman Emperor Charles V, died. Due to a combination of (1) the traditions of dynastic succession in Aragon, which permitted maternal inheritance with no precedence for female rule; (2) the insanity of Charles's mother, Joanna of Castile; and (3) the insistence by his remaining grandfather, Maximilian I, that he take up his royal titles, Charles initiated his reign in Castile and Aragon, a union which evolved into Spain, in conjunction with his mother. This ensured for the first time that all the realms of what is now Spain would be united by one monarch under one nascent Spanish crown. The founding territories retained their separate governance codes and laws. In 1519, already reigning as "Carlos I" in Spain, Charles took up the imperial title as "Karl V". The balance (and imbalance) between these separate inheritances would be defining elements of his reign, and would ensure that personal union between the Spanish and German crowns would be short-lived. The latter would end up going to a more junior branch of the Habsburgs in the person of Charles's brother Ferdinand, while the senior branch continued rule in Spain and in the Burgundian inheritance in the person of Charles's son, Philip II of Spain.
In addition to conflicts between his Spanish and German inheritances, conflicts of religion would be another source of tension during the reign of Charles V. Before Charles's reign in the Holy Roman Empire began, in 1517, Martin Luther launched what would later be known as the Reformation. At this time, many local dukes saw it as a chance to oppose the hegemony of Emperor Charles V. The empire then became fatally divided along religious lines, with the north, the east, and many of the major cities—Strasbourg, Frankfurt and Nuremberg—becoming Protestant while the southern and western regions largely remained Catholic.
Baroque period.
Charles V continued to battle the French and the Protestant princes in Germany for much of his reign. After his son Philip married Queen Mary of England, it appeared that France would be completely surrounded by Habsburg domains, but this hope proved unfounded when the marriage produced no children. In 1555, Paul IV was elected pope and took the side of France, whereupon an exhausted Charles finally gave up his hopes of a world Christian empire. He abdicated and divided his territories between Philip and Ferdinand of Austria. The Peace of Augsburg ended the war in Germany and accepted the existence of the Protestant princes, although not Calvinism, Anabaptism, or Zwingliism.
Germany would enjoy relative peace for the next six decades. On the eastern front, the Turks continued to loom large as a threat, although war would mean further compromises with the Protestant princes, and so the Emperor sought to avoid it. In the west, the Rhineland increasingly fell under French influence. After the Dutch revolt against Spain erupted, the Empire remained neutral; de facto allowing the Netherlands to depart the empire in 1581, a succession acknowledged in 1648. A side effect was the Cologne War, which ravaged much of the upper Rhine.
After Ferdinand died in 1564, his son Maximilian II became Emperor, and like his father, accepted the existence of Protestantism and the need for occasional compromise with it. Maximilian was succeeded in 1576 by Rudolf II, a strange man who preferred classical Greek philosophy to Christianity and lived an isolated existence in Bohemia. He became afraid to act when the Catholic Church was forcibly reasserting control in Austria and Hungary and the Protestant princes became upset over this. Imperial power sharply deteriorated by the time of Rudolf's death in 1612. When Bohemians rebelled against the Emperor, the immediate result was the series of conflicts known as the Thirty Years' War (1618–48), which devastated the Empire. Foreign powers, including France and Sweden, intervened in the conflict and strengthened those fighting Imperial power, but also seized considerable territory for themselves. The long conflict so bled the Empire that it never recovered its strength.
At the Battle of Vienna (1683), the Army of the Holy Roman Empire, led by the Polish King John III Sobieski, decisively defeated a large Turkish army, ending the western colonial Ottoman advance and leading to the eventual dismemberment of the Ottoman Empire in Europe. The HRE army was half Polish/Lithuanian Commonwealth forces, mostly cavalry, and half Holy Roman Empire forces (German/Austrian), mostly infantry.
The actual end of the empire came in several steps. The Peace of Westphalia in 1648, which ended the Thirty Years' War, gave the territories almost complete sovereignty. The Swiss Confederation, which had already established quasi-independence in 1499, as well as the Northern Netherlands, left the Empire. The Habsburg Emperors focused on consolidating their own estates in Austria and elsewhere.
Modern period.
Prussia and Austria.
By the rise of Louis XIV, the Habsburgs were chiefly dependent on their hereditary lands to counter the rise of Prussia, some of whose territories lay inside the Empire. Throughout the 18th century, the Habsburgs were embroiled in various European conflicts, such as the War of the Spanish Succession, the War of the Polish Succession and the War of the Austrian Succession. The German dualism between Austria and Prussia dominated the empire's history after 1740.
French Revolutionary Wars and final dissolution.
From 1792 onwards, revolutionary France was at war with various parts of the Empire intermittently.
The German mediatization was the series of mediatizations and secularizations that occurred between 1795–1814, during the latter part of the era of the French Revolution and then the Napoleonic Era. "Mediatization" was the process of annexing the lands of one sovereign monarchy to another, often leaving the annexed some rights. "Secularization" was the redistribution to secular states of the secular lands held by an ecclesiastical ruler such as a bishop or an abbot.
The empire was dissolved on 6 August 1806, when the last Holy Roman Emperor Francis II (from 1804, Emperor Francis I of Austria) abdicated, following a military defeat by the French under Napoleon at Austerlitz (see Treaty of Pressburg). Napoleon reorganized much of the Empire into the Confederation of the Rhine, a French satellite. Francis' House of Habsburg-Lorraine survived the demise of the empire, continuing to reign as Emperors of Austria and Kings of Hungary until the Habsburg empire's final dissolution in 1918 in the aftermath of World War I.
The Napoleonic Confederation of the Rhine was replaced by a new union, the German Confederation, in 1815, following the end of the Napoleonic Wars. It lasted until 1866 when Prussia founded the North German Confederation, a forerunner of the German Empire which united the German-speaking territories outside of Austria and Switzerland under Prussian leadership in 1871. This served as the predecessor-state of modern Germany.
Institutions.
The Holy Roman Empire was not a highly centralized state like most countries today. Instead, it was divided into dozens—eventually hundreds—of individual entities governed by kings, dukes, counts, bishops, abbots and other rulers, collectively known as princes. There were also some areas ruled directly by the Emperor. At no time could the Emperor simply issue decrees and govern autonomously over the Empire. His power was severely restricted by the various local leaders.
From the High Middle Ages onwards, the Holy Roman Empire was marked by an uneasy coexistence of the princes of the local territories who were struggling to take power away from it. To a greater extent than in other medieval kingdoms such as France and England, the Emperors were unable to gain much control over the lands that they formally owned. Instead, to secure their own position from the threat of being deposed, Emperors were forced to grant more and more autonomy to local rulers, both nobles and bishops. This process began in the 11th century with the Investiture Controversy and was more or less concluded with the 1648 Peace of Westphalia. Several Emperors attempted to reverse this steady dissemination of their authority, but were thwarted both by the papacy and by the princes of the Empire.
Imperial estates.
The number of territories in the Empire was considerable, rising to approximately 300 at the time of the Peace of Westphalia. Many of these "Kleinstaaten" ("little states") covered no more than a few square miles, or included several non-contiguous pieces, so the Empire was often called a "Flickenteppich" ("patchwork carpet").
An entity was considered a "Reichsstand" (imperial estate) if, according to feudal law, it had no authority above it except the Holy Roman Emperor himself. The imperial estates comprised:
For a list of "Reichsstände" in 1792, see List of Imperial Diet participants (1792).
King of the Romans.
A prospective Emperor had first to be elected King of the Romans (Latin: "Rex romanorum"; German: "römischer König"). German kings had been elected since the 9th century; at that point they were chosen by the leaders of the five most important tribes (the Salian Franks of Lorraine, Ripuarian Franks of Franconia, Saxons, Bavarians and Swabians). In the Holy Roman Empire, the main dukes and bishops of the kingdom elected the King of the Romans. In 1356, Emperor Charles IV issued the Golden Bull, which limited the electors to seven: the King of Bohemia, the Count Palatine of the Rhine, the Duke of Saxony, the Margrave of Brandenburg and the archbishops of Cologne, Mainz, and Trier. During the Thirty Years' War, the Duke of Bavaria was given the right to vote as the eighth elector. A candidate for election would be expected to offer concessions of land or money to the electors in order to secure their vote.
After being elected, the King of the Romans could theoretically claim the title of "Emperor" only after being crowned by the Pope. In many cases, this took several years while the King was held up by other tasks: frequently he first had to resolve conflicts in rebellious northern Italy, or was in quarrel with the Pope himself. Later Emperors dispensed with the papal coronation altogether, being content with the styling "Emperor-Elect": the last Emperor to be crowned by the Pope was Charles V in 1530.
The Emperor had to be male and of noble blood. No law required him to be a Catholic, but as the majority of the Electors adhered to this faith, no Protestant was ever elected. Whether and to what degree he had to be German was disputed among the Electors, contemporary experts in constitutional law, and the public. During the Middle Ages, some Kings and Emperors were not of German origin, but since the Renaissance, German heritage was regarded as vital for a candidate in order to be eligible for imperial office.
Imperial Diet ("Reichstag").
The Imperial Diet ("Reichstag", or "Reichsversammlung") was the legislative body of the Holy Roman Empire and theoretically superior to the emperor himself. It was divided into three classes. The first class, the Council of Electors, consisted of the electors, or the princes who could vote for King of the Romans. The second class, the Council of Princes, consisted of the other princes. The Council of Princes was divided into two "benches," one for secular rulers and one for ecclesiastical ones. Higher-ranking princes had individual votes, while lower-ranking princes were grouped into "colleges" by geography. Each college had one vote.
The third class was the Council of Imperial Cities, which was divided into two colleges: Swabia and the Rhine. The Council of Imperial Cities was not fully happy with the others; it could not vote on several matters such as the admission of new territories. The representation of the Free Cities at the Diet had become common since the late Middle Ages. Nevertheless, their participation was formally acknowledged only as late as in 1648 with the Peace of Westphalia ending the Thirty Years' War.
Imperial courts.
The Empire also had two courts: the "Reichshofrat" (also known in English as the Aulic Council) at the court of the King/Emperor, and the "Reichskammergericht" (Imperial Chamber Court), established with the Imperial Reform of 1495.
Imperial circles.
As part of the Imperial Reform, six Imperial Circles were established in 1500; four more were established in 1512. These were regional groupings of most (though not all) of the various states of the Empire for the purposes of defence, imperial taxation, supervision of coining, peace-keeping functions and public security. Each circle had its own parliament, known as a "Kreistag" ("Circle Diet"), and one or more directors, who coordinated the affairs of the circle. Not all imperial territories were included within the imperial circles, even after 1512; the Lands of the Bohemian Crown were excluded, as were Switzerland, the imperial fiefs in northern Italy, the lands of the Imperial Knights, and certain other small territories like the Lordship of Jever.
Army.
The Army of the Holy Roman Empire (German "Reichsarmee", "Reichsheer" or "Reichsarmatur"; Latin "exercitus imperii") was created in 1422, and came to an end even before the Empire as the result of the Napoleonic Wars. It must not be confused with the Imperial Army ("Kaiserliche Armee") of the Emperor.
Despite appearances to the contrary, the Army of the Empire did not constitute a permanent standing army which was always at the ready to fight for the Empire. When there was danger, an Army of the Empire was mustered from among the elements constituting it, in order to conduct an imperial military campaign or "Reichsheerfahrt". In practice, the imperial troops often had stronger local allegiances than their loyalty to the Emperor.
Demographics.
Largest cities.
Largest cities or towns of the Empire by year:

</doc>
<doc id="13279" url="http://en.wikipedia.org/wiki?curid=13279" title="Holiday">
Holiday

A holiday is a day set aside by custom or by law on which normal activities, especially business or work, are suspended or reduced. Generally, holidays are intended to allow individuals to celebrate or commemorate an event or tradition of cultural or religious significance. Holidays may be designated by governments, religious institutions, or other groups or organizations. The degree to which normal activities are reduced by a holiday may depend on local laws, customs, the type of job being held or even personal choices.
The concept of holidays has most often originated in connection with religious observances. The intention of a holiday was typically to allow individuals to tend to religious duties associated with important dates on the calendar. In most modern societies, however, holidays serve as much of a recreational function as any other weekend days or activities.
In many societies there are important distinctions between holidays designated by governments and holidays designated by religious institutions. For example, in many predominantly Christian nations, government-designed holidays may center around Christian holidays, though non-Christians may instead observe religious holidays associated with their faith. In some cases, a holiday may only be nominally observed. For example, many Jews in the Americas and Europe treat the relatively minor Jewish holiday of Hanukkah as a "working holiday", changing very little of their daily routines for this day.
The word "holiday" has some variance in meaning across different locales. In North America the word refers to widely observed days of rest and recreation, whereas in the U.K. and many Commonwealth nations the word refers to any extended period of recreation. It is this first, more restricted sense of the word that concerns this article.
Etymology.
The word "holiday" comes from the Old English word "hāligdæg" ("hālig" "holy" + "dæg" "day"). The word originally referred only to special religious days. In modern use, it means any special day of rest or relaxation, as opposed to normal days away from work or school.
Types of holiday (observance).
Religious holidays.
See also: .
Many holidays are linked to faiths and religions (see etymology above). Christian holidays are defined as part of the liturgical year, the chief ones being Easter and Christmas. The Orthodox Christian and Western-Roman Catholic patronal feast day or "name day" are celebrated in each place's patron saint's day, according to the Calendar of saints. Jehovah's Witnesses annually commemorate "The Memorial of Jesus Christ's Death", but do not celebrate other holidays with any religious significance such as Easter, Christmas or New Year's. This holds especially true for those holidays that have combined and absorbed rituals, overtones or practices from non-Christian beliefs into the celebration, as well as those holidays that distract from or replace the worship of Jehovah. In Islam, the largest holidays are Eid ul-Fitr (immediately after Ramadan) and Eid al-Adha (at the end of the Hajj). Ahmadi Muslims additionally celebrate Promised Messiah Day, Promised Reformer Day, and Khilafat Day, but contrary to popular belief, neither are regarded as holidays. Hindus, Jains and Sikhs observe several holidays, one of the largest being Diwali (Festival of Light). Japanese holidays contain references to several different faiths and beliefs. Celtic, Norse, and Neopagan holidays follow the order of the Wheel of the Year. Some are closely linked to Swedish festivities. The Bahá'í Faith observes holidays as defined by the Bahá'í calendar. Jews have two holiday seasons: the Spring Feasts of Pesach (Passover) and Shavuot (Weeks, called Pentecost in Greek); and the Fall Feasts of Rosh Hashanah (Head of the Year), Yom Kippur (Day of Atonement), Sukkot (Tabernacles), and Shemini Atzeret (Eighth Day of Assembly).
Northern Hemisphere winter holidays.
Winter in the Northern Hemisphere features many holidays that involve festivals and feasts. The Christmas and holiday season surrounds the Christmas and other holidays, and is celebrated by many religions and cultures. Usually, this period begins near the start of November and ends with New Year's Day. "Holiday season" is, somewhat, a commercial term that applies, in the US, to the period that begins with Thanksgiving and ends with New Year's Eve. Some Christian countries consider the end of the festive season to be after the feast of Epiphany.
National holidays.
Sovereign nations and territories observe holidays based on events of significance to their history. For example, Americans celebrate Independence Day, celebrating the signing of the Declaration of Independence in 1776.
Other secular holidays.
See also: .
Other secular (non-religious) holidays are observed nationally, internationally (often in conjunction with organizations such as the United Nations), and across multi-country regions. An example of a major secular holiday is the Lunar New Year, which is celebrated across Asia. Many other days are marked to celebrate events or people, but are not strictly holidays as time off work is rarely given; examples include Arbor Day (originally US), Labor Day (celebrated sometimes under different names and on different days in different countries), and Earth Day (22 April).
Unofficial holidays.
See also: .
These are holidays that are not traditionally marked on calendars. These holidays are celebrated by various groups and individuals. Some promote a cause, others recognize historical events not officially recognized, and others are "funny" holidays celebrated with humorous intent. For example, Monkey Day is celebrated on December 14, International Talk Like a Pirate Day is observed on September 19, and Blasphemy Day is held on September 30.

</doc>
<doc id="13287" url="http://en.wikipedia.org/wiki?curid=13287" title="Hobby">
Hobby

A hobby is a regular activity that is done for enjoyment, typically during one's leisure time. Hobbies can include collecting themed items and objects, engaging in creative and artistic pursuits, playing sports, or pursuing other amusements. By continually participating in a particular hobby, one can acquire substantial skill and knowledge in that area.
Generally speaking, a person who engages in an activity solely for fun is called a 'hobbyist', whereas a 'professional' generally engages in an activity for reward and an 'amateur' (from French for "lover of") does so out of personal interest in an activity. While an amateur may be as skilled as a professional, a professional receives compensation while an amateur generally does not.
Etymology.
In the 13th century, the term "hobyn" had the meaning of "small horse or pony". The term "hobbyhorse" was documented in a 1557 payment confirmation for a "Hobbyhorse" from Reading, England. The item, originally called a "Tourney Horse", was made of a wooden or basketwork frame with an artificial tail and head. Designed to mimic a real horse, the hobbyhorse was used for religious activities and civic occasions. By 1816 the derivative, "hobby", was introduced into the vocabulary of an unknown number of English people. Over the course of subsequent centuries, the term came to mean "recreational" or "leisurely pursuit". A hobby is also called a pastime, derived from the use of hobbies to pass the time, though it may also refer to other activities (for example, baseball is often said to be America's favorite or national pastime).
Hobbies are practiced primarily for interest and enjoyment, rather than financial reward. In the 17th century, the term was used in a pejorative sense due to the childish origins of the term. Referring to the origin of the word, engaging in one's hobby equated to the horse outfit from the term's formulation and was considered a puerile overindulgence that would yield no benefit.
In the 21st century, personal fulfillment is the aim of hobbies in First World Western nations and they are widely considered to be helpful in such societies. Although, in the United Kingdom (UK), the pejorative noun "anorak", similar to the Japanese word "otaku", has the meaning of being a geek or enthusiast, and is often applied to people who obsessively pursue a particular hobby that others consider boring.
Development into other ventures.
There have been instances where hobbies have led to significant developments beyond the personal fulfillment for those involved. Amateur astronomers have made significant contributions to the profession, and hobbyists have made discoveries such as finding an unknown celestial body or celestial event. In the area of computer programming, the invention of the Linux kernel began as a student's hobby. A substantial amount of early scientific research came from the hobby activities of the wealthy, such as Antoine Lavoisier's contributions to the science of chemistry.
Hobbies have also risen to prominence after a period of relatively low interest. For example, a British conservationist was seen wearing field glasses at a London train station in the 1930s and was consequently asked if he was going to the horse races. Whilst the general public was not aware of nature observation which was formally conducted as field research, during the 1930s, practitioners of the hobby went on to become the pioneers of the conservation movement that flourished in the UK from 1965 onwards. Eventually, it became a global political movement within a generation's time span.
Types.
Collecting.
The hobby of collecting includes seeking, locating, acquiring, organizing, cataloging, displaying, storing, and maintaining whatever items are of interest to the individual collector. Some collectors are generalists, accumulating merchandise, or stamps from all countries of the world. Others focus on a subtopic within their area of interest, perhaps 19th century postage stamps, milk bottle labels from Sussex, or Mongolian harnesses and tack.
Many coin collections are also referred to as date sets, and may be stored in coin holders. The most popular of the coin holders for date sets are called coin albums.
Specialized commercial dealers that trade in the items being collected, as well as related accessories, may have started as collectors themselves, eventually turning their hobby into a profession.
One's finances may be a restriction on the more extravagant hobbies. For example, someone who has the financial means to collect stamps might not be able to collect sports-cars.
One alternative to collecting physical objects is collecting experiences of a particular kind. Examples include creating a list through observation or photography, train spotting, aircraft spotting, metrophiles, bus spotting, bird-watching, and systematically visiting continents and countries to collect stamps in their passports,or visiting various states, national parks, counties etc.
Outdoor recreation.
Outdoor pursuits are the group of activities which occur outdoors. These hobbies include gardening, hill walking, hiking, backpacking, cycling, canoeing, climbing, caving, fishing, wildlife viewing and engaging in watersports and snowsports.
Depending on an individual's desired level of adrenaline, outdoors experiences are considered one type of hobby. While many enjoy an adrenaline rush or just an escape from reality, outdoor recreational activities can also be an extremely effective medium in education and team building.
As interest increases, so has the desire for commercial outdoor pursuits. Outdoor recreational supply stores have opened in large numbers and are thriving, as have outdoor pursuit journalism and magazines, both on paper and the Internet.
The increased accessibility of outdoor pursuit resources has been the source of some negative publicity over the years, with complaints of the destruction of landscape. An example is the destruction of hillsides as footpaths are eroded due to an excessive number of visitors.
Performing arts.
Many hobbies involve performances by the hobbyist, such as singing, acting, juggling, magic, dancing, playing a musical instrument, martial arts and other performing arts.
Creative hobbies.
Some hobbies result in an end product. Examples of this would be woodworking, photography, moviemaking, jewelry making, software projects such as Photoshopping and home music or video production, making bracelets, artistic projects such as drawing, painting, writing, etc., The design, creation, and wearing a costume based on an already existing creative property - Cosplay, creating models out of card stock or paper - called papercraft. Hobbies also include higher-end projects like building or restoring a car, or building a computer from scratch.
For computer savvy do-it-yourself hobbyists, CNC (Computer Numerical Control) machining is also popular. A CNC machine can be assembled and programmed to make different parts from wood or metal.
Scale modeling/dioramas.
Making a replica of a real object in a smaller scale goes back to prehistoric times with small clay "dolls" and other children's toys having been found near known populated areas. The Greeks, Romans, and Persians took the form to a greater depth during their years of world domination, using scale replicas of enemy fortifications, coastal defense lines, and other geographic fixtures to plan battles.
At the turn of the Industrial Age and on through the 1920s, families could often afford things such as electric trains, wind-up toys (typically boats or cars) and the increasingly valuable tin toy soldiers.
Model engineering refers to building functioning machinery in metal, such as internal combustion motors and live steam models or locomotives. This is a demanding hobby, requiring a multitude of large and expensive tools, such as lathes and mills. This hobby originated in the United Kingdom in the late 19th century, later spreading and flourishing in the mid-20th century. Due to the expense and space required, it is becoming rare.
Scale modeling as we know it today became popular shortly after World War II. Before 1946, children as well as adults were content in carving and shaping wooden replicas from block wood kits, often depicting enemy aircraft to help with identification in case of an invasion.
With the advent of modern plastics, the amount of skill required to get the basic shape accurately shown for any given subject was lessened, making it easier for people of all ages to begin assembling replicas in varying scales. Superheroes, aeroplanes, boats, cars, tanks, artillery, and even figures of soldiers became quite popular subjects to build, paint and display. Although almost any subject can be found in almost any scale, there are common scales for such miniatures which remain constant today. The most popular scales for each subject are (in order of popularity):
Figures are probably the most variable of all subjects in terms of scale and are often referred to as their metric equivalent; for example, a 1:32 scale figure soldier is more commonly described as "54mm". Likewise other popular sizes are 90mm, 120mm and almost every increment in between. An example of a diorama hobby is Warhammer 40,000, from Games Workshop.
In addition to plastic kits, resin has become a popular material for "short run" productions. The level of detail is often quite exquisite, and while more expensive than the typical plastic soldier, is much easier to work with and modify, compared to White Metal or Pewter figures.
The advent of small and cheap computers, sensors (often derived from the smartphone industry), and radio equipment allowed hobbies such as Radio-controlled aircraft, cars, and toy robots to become more popular.
Scale modeling is no longer a high growth industry as it was during the 1960s and 1970s, but there are still thousands of retail shops selling kits, supplies, paints, and tools to support new and established hobbyists. There are more companies producing varieties of kits on subjects than ever before, and the levels of detail have become unbelievably accurate with the advent of modern drafting and molding equipment. Digitized CAD software have also contributed to this allowing accuracy of up to 1/1000 of an inch.
With more costly kits seeing an upward trend and youth entertainment moving more towards computers and in-home video gaming, the average age of the avid hobbyist is now older than ever before — with adults making up the vast majority of enthusiasts. At the same time, there are probably more people building from kits now than ever, and there is a large selection of supportive magazines such as "Fine Scale Modeler", "Military Miniatures in Review" (MMiR) and "Tamiya Magazine" from every era. There are several modeling clubs in most cities, with the largest being International Plastic Modellers' Society (IPMS). IPMS has support chapters and contests around the world.
Cooking.
Cooking requires applying heat to a food which usually, though not always, chemically transforms it, thus changing its flavor, texture, appearance, and nutritional properties. It encompasses a vast range of methods and tools, and may also be used to improve the digestibility of food. It may require the selection, measurement and combining of ingredients in an ordered procedure in an effort to achieve the desired result. Constraints on success include the ambient conditions, tools and the skill of the individual cook.
The diversity of cooking worldwide reveals the myriad of nutritional, aesthetic, agricultural, agronomic, economic, cultural and religious considerations that have an impact upon it.
Cooking properly, as opposed to roasting, requires the boiling of water or oil in a receptacle, and was practiced at least since the 10th millennium BC with the introduction of pottery. There is archaeological evidence of roasted foodstuffs, both animal and vegetable, in human ("Homo erectus") camp sites dating from the earliest known use of fire some 800,000 years ago.
Gardening.
Residential gardening most often takes place in or about ones own residence, in a space referred to as the garden. Although a garden typically is located on the land near a residence, it may also be located on a roof, in an atrium, on a balcony, in a windowbox, or on a patio or vivarium.
Gardening also takes place in non-residential green areas, such as parks, public or semi-public gardens (botanical gardens or zoological gardens), amusement and theme parks, along transportation corridors, and around tourist attractions and hotels. In these situations, a staff of gardeners or groundskeepers maintains the gardens.
Indoor gardening.
Indoor gardening is growing houseplants within a residence or building, in a conservatory, or in a greenhouse. Indoor gardens are sometimes incorporated into air conditioning or heating systems.
Water gardening.
Water gardening is growing plants that have adapted to pools and ponds. Bog gardens are also considered a type of water garden. These all require special conditions and considerations. A simple water garden may consist solely of a tub containing the water and plant(s).
Container gardening.
Container gardening is concerned with growing plants in containers that are placed above the ground.
Reading.
Reading, such as reading books, ebooks, magazines, comics, or newspapers, along with browsing the internet is a common hobby, and one that can trace its origins back hundreds of years. A love of literature, later in life, may be sparked by an interest in reading children's literature as a child.
Sports.
People who enjoy playing sports may be amateur athletes who play recreationally.

</doc>
<doc id="13288" url="http://en.wikipedia.org/wiki?curid=13288" title="Holland">
Holland

Holland is a region and former province on the western coast of the Netherlands. The name "Holland" is also frequently used to informally refer to the whole of the country of the Netherlands. This usage is commonly accepted in other countries, but in the Netherlands and particularly in other regions of the country it could be found undesirable or even insulting.
From the 10th to the 16th century, Holland proper was a unified political region within the Holy Roman Empire as a county ruled by the Counts of Holland. By the 17th century, Holland had risen to become a maritime and economic power, dominating the other provinces of the newly independent Dutch Republic.
Today, the former County of Holland roughly consists of the two Dutch provinces of North Holland and South Holland, which together include the Netherlands' three largest cities: the capital city of Amsterdam; Rotterdam, home of Europe's largest port; and the seat of government of The Hague.
Etymology and terminology.
The name "Holland" first appeared in sources in 866 for the region around Haarlem, and by 1064 was being used as the name of the entire county. By this time, the inhabitants of Holland were referring to themselves as "Hollanders". "Holland" is derived from the Middle Dutch term "holtland" ("wooded land"). This spelling variation remained in use until around the 14th century, at which time the name stabilised as "Holland" (alternative spellings at the time were "Hollant" and "Hollandt"). A popular folk etymology holds that "Holland" is derived from "hol land" ("hollow land") and was inspired by the low-lying geography of Holland.
The proper name of the area in both Dutch and English is "Holland". Holland is a part of the Netherlands. "Holland" is informally used in English and other languages, including sometimes the Dutch language itself, to mean the whole of the modern country of the Netherlands. This example of "pars pro toto" or synecdoche is similar to the tendency in the past to refer to the United Kingdom as "England".
The people of Holland are referred to as "Hollanders" in both Dutch and English. Today this refers specifically to people from the current provinces of North Holland and South Holland. Strictly speaking, the term "Hollanders" does not refer to people from the other provinces in the Netherlands, but colloquially "Hollanders" is sometimes used in this wider sense.
In Dutch, the Dutch word ""Hollands" is the adjectival form for "Holland". The Dutch word "Hollands" is also colloquially and occasionally used by some Dutch people in the sense of "Nederlands"" (Dutch), but then often with the intention of contrasting with other types of Dutch people or language, for example Limburgish, the Belgian form of the Dutch language ("Flemish"), or even any southern variety of Dutch within the Netherlands itself.
However, in English there is no commonly used adjective for "Holland". "Dutch" refers to the Netherlands as a whole, not just the region of Holland. "Hollands" is ordinarily expressed in English in two ways:
The following usages apply in certain limited situations but do not ordinarily serve as the English equivalent of the commonly used Dutch adjective "Hollands".
History.
Each of the provinces in the Netherlands has a history that deserves full attention on its own. However, to a certain extent at least, the history of Holland is the history of the Netherlands, and vice versa. See the article on "History of the Netherlands" for a more detailed history. The article here focuses on those points that are specific to Holland itself or that highlight the nature of the role played by Holland in the Netherlands as a whole.
County of Holland.
Until the 9th century, the inhabitants of the area that became Holland were Frisians. The area was part of Frisia. At the end of the 9th century, Holland became a separate county in the Holy Roman Empire. The first Count of Holland known about with certainty was Dirk I, who ruled from 896 to 931. He was succeeded by a long line of counts in the House of Holland (who were in fact known as counts of Frisia until 1101). When John I, count of Holland, died childless in 1299, the county was inherited by John II of Avesnes, count of Hainaut. By the time of William V (House of Wittelsbach; 1354–1388) the count of Holland was also the count of Hainaut and Zealand.
At the time a part of Frisia, West Friesland, was conquered (as a result, most provincial institutions, including the States of Holland and West Frisia, would for centuries refer to "Holland and West Frisia" as a unit). The Hook and Cod wars started around this time and ended when the countess of Holland, Jacoba or Jacqueline was forced to give up Holland to the Burgundian Philip III, known as Philip the Good, in 1432.
In 1432, Holland became part of the Burgundian Netherlands and since 1477 of the Habsburg Seventeen Provinces. In the 16th century the county became the most densely urbanised region in Europe, with the majority of the population living in cities. Within the Burgundian Netherlands, Holland was the dominant province in the north; the political influence of Holland largely determined the extent of Burgundian dominion in that area. The last count of Holland was Philip III, better known as Philip II king of Spain. He was deposed in 1581 by the Act of Abjuration, although the kings of Spain continued to carry the titular appellation of Count of Holland until the Peace of Münster signed in 1648.
Dutch Republic.
In the Dutch Rebellion against the Habsburgs during the Eighty Years' War, the naval forces of the rebels, the Watergeuzen, established their first permanent base in 1572 in the town of Brill. In this way, Holland, now a sovereign state in a larger Dutch confederation, became the centre of the rebellion. It became the cultural, political and economic centre of the United Provinces (Dutch: "Verenigde Provinciën"), in the 17th century, the Dutch Golden Age, the wealthiest nation in the world. After the King of Spain was deposed as the count of Holland, the executive and legislative power rested with the States of Holland, which was led by a political figure who held the office of Grand Pensionary.
The largest cities in the Dutch Republic were in the province of Holland, such as Amsterdam, Rotterdam, Leiden, Alkmaar, The Hague, Delft, Dordrecht and Haarlem. From the great ports of Holland, Hollandic merchants sailed to and from destinations all over Europe, and merchants from all over Europe gathered to trade in the warehouses of Amsterdam and other trading cities of Holland.
Many Europeans thought of the United Provinces first as "Holland" rather than as the "Republic of the Seven United Provinces of the Netherlands". A strong impression of "Holland" was planted in the minds of other Europeans, which then was projected back onto the Republic as a whole. Within the provinces themselves, a gradual slow process of cultural expansion took place, leading to a "Hollandification" of the other provinces and a more uniform culture for the whole of the Republic. The dialect of urban Holland became the standard language.
Under French rule.
The formation of the Batavian Republic, inspired by the French revolution, led to a more centralised government. Holland became a province of a unitary state. Its independence was further reduced by an administrative reform in 1798, in which its territory was divided into several departments called "Amstel", "Delf", "Texel", and part of "Schelde en Maas".
From 1806 to 1810 Napoleon styled his vassal state, governed by his brother Louis Napoleon and shortly by the son of Louis, Napoleon Louis Bonaparte, as the "Kingdom of Holland". This kingdom encompassed much of what would become the modern Netherlands. The name reflects how natural at the time it had become to equate Holland with the non-Belgian Netherlands as a whole.
During the period the Low Countries were annexed by the French Empire and actually incorporated into France (from 1810 to 1813), Holland was divided into départements Zuyderzée, and Bouches-de-la-Meuse. From 1811 to 1813 Charles-François Lebrun, duc de Plaisance served as governor-general. He was assisted by Antoine de Celles, Goswin de Stassart and François Jean-Baptiste d'Alphonse.
Kingdom of the Netherlands.
After 1813, Holland was restored as a province of the United Kingdom of the Netherlands. Holland was divided into the present provinces North Holland and South Holland in 1840, after the Belgian Revolution of 1830. This reflected a historical division of Holland along the IJ into a Southern Quarter ("Zuiderkwartier") and a Northern Quarter ("Noorderkwartier"), but the actual division is different from the old division. From 1850, a strong process of nation formation took place, the Netherlands being culturally unified and economically integrated by a modernisation process, with the cities of Holland as its centre.
Geography.
Holland is situated in the west of the Netherlands. A maritime region, Holland lies on the North Sea at the mouths of the Rhine and the Meuse (Maas). It has numerous rivers and lakes and an extensive inland canal and waterway system. To the south is Zealand. The region is bordered on the east by the IJsselmeer and four different provinces of the Netherlands.
Holland is protected from the sea by a long line of coastal dunes. Most of the land area behind the dunes consists of polder landscape lying well below sea level. At present the lowest point in Holland is a polder near Rotterdam, which is about seven meters below sea level. Continuous drainage is necessary to keep Holland from flooding. In earlier centuries windmills were used for this task. The landscape was (and in places still is) dotted with windmills, which have become a symbol of Holland.
Holland is 7,494 square kilometres (land and water included), making it roughly 13% of the area of the Netherlands. Looking at land alone, it is 5,488 square kilometres in size. The combined population is 6.1 million.
The main cities in Holland are Amsterdam, Rotterdam and The Hague. Amsterdam is formally the capital of the Netherlands and its largest city. The Port of Rotterdam is Europe's largest and most important harbour and port. The Hague is the seat of government of the Netherlands. These cities, combined with Utrecht and other smaller municipalities, effectively form a single metroplex—a conurbation called Randstad.
The Randstad area is one of the most densely populated regions of Europe, but still relatively free of urban sprawl. There are strict zoning laws. Population pressures are enormous, property values are high, and new housing is constantly under development on the edges of the built-up areas. Surprisingly, much of the province still has a rural character. The remaining agricultural land and natural areas are highly valued and protected. Most of the arable land is used for intensive agriculture, including horticulture and greenhouse agri-businesses.
Reclamation of the land.
The land that is now Holland had never been stable. Over the millennia the geography of the region had been dynamic. The western coastline shifted up to thirty kilometres to the east and storm surges regularly broke through the row of coastal dunes. The Frisian Isles, originally joined to the mainland, became detached islands in the north. The main rivers, the Rhine and the Meuse (Maas), flooded regularly and changed course repeatedly and dramatically.
The people of Holland found themselves living in an unstable, watery environment. Behind the dunes on the coast of the Netherlands a high peat plateau had grown, forming a natural protection against the sea. Much of the area was marsh and bog. By the tenth century the inhabitants set about cultivating this land by draining it. However, the drainage resulted in extreme soil shrinkage, lowering the surface of the land by up to fifteen metres.
To the south of Holland, in Zeeland, and to the north, in Frisia, this development led to catastrophic storm floods literally washing away entire regions, as the peat layer disintegrated or became detached and was carried away by the flood water. From the Frisian side the sea even flooded the area to the east, gradually hollowing Holland out from behind and forming the Zuiderzee (the present IJsselmeer). This inland sea threatened to link up with the "drowned lands" of Zealand in the south, reducing Holland to a series of narrow dune barrier islands in front of a lagoon. Only drastic administrative intervention saved the county from utter destruction. The counts and large monasteries took the lead in these efforts, building the first heavy emergency dikes to bolster critical points. Later special autonomous administrative bodies were formed, the "waterschappen" ("water control boards"), which had the legal power to enforce their regulations and decisions on water management. As the centuries went by, they eventually constructed an extensive dike system that covered the coastline and the polders, thus protecting the land from further incursions by the sea.
However, the Hollanders did not stop there. Starting around the 16th century, they took the offensive and began land reclamation projects, converting lakes, marshy areas and adjoining mudflats into polders. This continued right into the 20th century. As a result, historical maps of mediaeval and early modern Holland bear little resemblance to the maps of today.
This ongoing struggle to master the water played an important role in the development of Holland as a maritime and economic power and in the development of the character of the people of Holland.
Culture.
Holland tends to be associated with a particular image. The stereotypical image of Holland is an artificial amalgam of tulips, windmills, clogs, cheese and traditional dress ("klederdracht"). As is the case with many stereotypes, this is far from the truth and reality of life in Holland. This can at least in part be explained by the active exploitation of these stereotypes in promotions of Holland and the Netherlands. In fact only in a few of the more traditional villages, such as Volendam and locations in the Zaan area, are the different costumes with wooden shoes still worn by some inhabitants.
The predominance of Holland in the Netherlands has resulted in regionalism on the part of the other provinces. This is a reaction to the perceived threat that Holland poses to the identities and local cultures of the other provinces. The other provinces have a strong, and often negative, image of Holland and the Hollanders, to whom certain qualities are ascribed within a mental geography, a conceptual mapping of spaces and their inhabitants. On the other hand, some Hollanders take Holland's cultural dominance for granted and treat the concepts of "Holland" and the "Netherlands" as coincidental. Consequently, they see themselves not primarily as "Hollanders", but simply as "Dutch" ("Nederlanders"). This phenomenon has been called "hollandocentrism".
Language.
The predominant language spoken in Holland is Dutch. Hollanders sometimes refer to the Dutch language as "Hollands", instead of the standard term "Nederlands". Inhabitants of Belgium and other provinces of the Netherlands refer to "Hollands" to indicate someone speaking in a Hollandic dialect, or strong accent.
Standard Dutch was historically largely based on the dialect of the County of Holland, incorporating many traits derived from the dialects of the previously more powerful Duchy of Brabant and County of Flanders. Strong dialectal variation still exists throughout the Low Countries. Today, Holland-proper is the region where the original dialects are least spoken, in many areas having been completely replaced by standard Dutch, and the Randstad has the largest influence on the developments of the standard language—with the exception of the Dutch spoken in Belgium.
Despite this correspondence between standard Dutch and the Dutch spoken in the Randstad, there are local variations within Holland itself that differ from standard Dutch. The main cities each have their own modern urban dialect, that can be considered a sociolect. A small number of people, especially in the area north of Amsterdam, still speak the original dialect of the county, Hollandic. The Hollandic dialect is present in the north: Volendam and Marken and the area around there, West Friesland and the Zaanstreek; and in a south-eastern fringe bordering on the provinces of North Brabant and Utrecht. In the south on the island of Goeree-Overflakkee, Zealandic is spoken.
New Holland.
The province of Holland gave its name to a number of colonial settlements and discovered regions that were called "Nieuw Holland" or New Holland. The most extensive of these was the island continent presently known as Australia: New Holland was first applied to Australia in 1644 by the Dutch seafarer Abel Tasman as a Latin "Nova Hollandia", and remained in international use for 190 years. On the same voyage he named New Zealand after the Dutch province of Zeeland. In the Netherlands "Nieuw Holland" would remain the usual name of the continent until the end of the 19th century; it is now no longer in use there, the Dutch name today being "Australië".

</doc>
<doc id="13289" url="http://en.wikipedia.org/wiki?curid=13289" title="History of the Netherlands">
History of the Netherlands

The history of the Netherlands is the history of a seafaring people thriving on a lowland river delta on the North Sea in northwestern Europe. Records begin with the four centuries during which the region formed a militarized border zone of the Roman empire. This came under increasing pressure from Germanic peoples moving westwards. As Roman power collapsed and the Middle Ages began, three dominant Germanic peoples coalesced in the area, Frisians in the north, Low Saxons in the northeast, and the Franks.
During the Middle Ages, the descendants of the, the Carolingian dynasty, came to dominate the area and then extended their rule to a large part of Western Europe. The region of the Netherlands therefore became part of Lower Lotharingia within the Frankish Holy Roman Empire. For several centuries, lordships such as Brabant, Holland, Zeeland, Friesland, Guelders and others held a changing patchwork of territories. There was no unified equivalent of the modern Netherlands.
By 1433, the Duke of Burgundy had assumed control over most of the lowlands territories in Lower Lotharingia; he created the Burgundian Netherlands which included modern Belgium, Luxembourg, and a part of France. Under the heir Emperor Charles V this union was declared independent of Germany and France, and then became part of Charles' new Spanish empire.
The Catholic kings of Spain took strong measures against the new Protestantism and other dissent, which polarized those peoples of present-day Belgium and Holland. The subsequent Dutch revolt led to splitting the Burgundian Netherlands into a Catholic French and Dutch-speaking "Spanish Netherlands" (approximately modern) Belgium and Luxembourg, and a northern "United Provinces", which spoke Dutch and was predominantly Protestant, with a large Catholic minority. It became the modern Netherlands.
In the Dutch Golden Age, which had its zenith around 1667, there was a flowering of trade, industry, the arts and the sciences. A rich worldwide Dutch empire developed and the Dutch East India Company became one of the earliest and most important of national mercantile companies based on entrepreneurship and trade.
During the 18th century the power and wealth of the Netherlands declined. A series of wars with the more powerful British and French neighbors weakened it. Britain seized the North American colony of New Amsterdam, turning it into New York. There was growing unrest and conflict between the Orangists and the Patriots. The French Revolution spilled over after 1789, and a pro-French Batavian Republic was established in 1795–1806. Napoleon made it a satellite state, the Kingdom of Holland (1806–1810), and later simply a French imperial province.
After the collapse of Napoleon in 1813-15, an expanded "United Kingdom of the Netherlands" was created with the House of Orange as monarchs, also ruling Belgium and Luxembourg. The King imposed unpopular Protestant reforms on Belgian, which revolted in 1830 and became independent in 1839. After an initially conservative period, in the 1848 constitution the country became a parliamentary democracy with a constitutional monarch. Modern Luxembourg initially remained united with the Netherlands, but today is ruled by a separate branch of the Dutch royal family.
The Netherlands was neutral during the First World War, but during the Second World War, it was invaded and occupied by Nazi Germany. The Nazis, including many collaborators, rounded up and killed almost all the Jews (most famously Anne Frank). When the Dutch resistance increased, the Nazis cut off food supplies to much of the country, causing severe starvation in 1944-45. In 1942, the Dutch East Indies was conquered by Japan, but first the Dutch destroyed the oil wells that Japan needed so badly. Indonesia proclaimed its independence in 1947. Suriname gained independence in 1975. The postwar years saw rapid economic recovery (helped by the American Marshall Plan), followed by the introduction of a welfare state during an era of peace and prosperity. The Netherlands formed a new economic alliance with Belgium and Luxembourg, the Benelux, and all three became founding members of the European Union and NATO. In recent decades, the Dutch economy has been closely linked to that of Germany, and is highly prosperous. After World War II the pillarized system that had separated society into closed Catholic, Protestant and secular pillars became integrated; Catholic and Protestant religiosity declined sharply. However, the arrival of immigrant Muslims cause a new polarization in the 21st century.
Prehistory (before 800 BC).
Historical changes to the landscape.
The prehistory of the area that is now the Netherlands was largely shaped by its constantly shifting, low-lying geography.
Earliest groups of hunter-gatherers (before 5000 BC).
The area that is now the Netherlands was inhabited by early humans at least 37,000 years ago, as attested by flint tools discovered in Woerden in 2010. In 2009 a fragment of a 40,000-year-old Neanderthal skull was found in sand dredged from the North Sea floor off the coast of Zeeland.
During the last ice age, the Netherlands had a tundra climate with scarce vegetation and the inhabitants survived as hunter-gatherers. After the end of the ice age, various Paleolithic groups inhabited the area. It is known that around 8000 BC a Mesolithic tribe resided near Burgumer Mar (Friesland). Another group residing elsewhere is known to have made canoes. The oldest recovered canoe in the world is the Pesse canoe. According to C14 dating analysis it was constructed somewhere between 8200 BC and 7600 BC. This canoe is exhibited in the Drents Museum in Assen.
Autochthonous hunter-gatherers from the Swifterbant culture are attested from around 5600 BC onwards. They are strongly linked to rivers and open water and were related to the southern Scandinavian Ertebølle culture (5300 BC–4000 BC). To the west, the same tribes might have built hunting camps to hunt winter game, including seals.
The arrival of farming (around 5000 BC-4000 BC).
Agriculture arrived in the Netherlands somewhere around 5000 BC with the Linear Pottery culture, who were probably central European farmers. Agriculture was practised only on the loess plateau in the very south (southern Limburg), but even there it was not established permanently. Farms did not develop in the rest of the Netherlands.
There is also some evidence of small settlements in the rest of the country. These people made the switch to animal husbandry sometime between 4800 BC and 4500 BC. Dutch archaeologist Leendert Louwe Kooijmans wrote, "It is becoming increasingly clear that the agricultural transformation of prehistoric communities was a purely indigenous process that took place very gradually." This transformation took place as early as 4300 BC–4000 BC and featured the introduction of grains in small quantities into a traditional broad-spectrum economy.
Funnelbeaker and other cultures (around 4000 BC-3000 BC).
The Funnelbeaker culture was a farming culture extending from Denmark through northern Germany into the northern Netherlands. In this period of Dutch prehistory the first notable remains were erected: the dolmens, large stone grave monuments. They are found in Drenthe, and were probably built between 4100 BC and 3200 BC.
To the west, the Vlaardingen culture (around 2600 BC), an apparently more primitive culture of hunter-gatherers survived well into the Neolithic period.
Corded Ware and Bell Beaker cultures (around 3000 BC-2000 BC).
Around 2950 BC there was a transition from the Funnelbeaker farming culture to the Corded Ware pastoralist culture. The cause of this transition is a matter of debate, but it was a quick, smooth and internal change in culture and religion that occurred in just two generations, probably because of developments in eastern Germany and without immigration.
The Bell Beaker culture was also present in the Netherlands.
The Corded Ware and Bell Beaker cultures were not indigenous to the Netherlands but were pan-European in nature, extending across much of northern and central Europe.
The first evidence of the use of the wheel dates from this period, about 2400 BC. This culture also experimented with working with copper. Evidence of this, including stone anvils, copper knives and a copper spearhead, was found on the Veluwe. Copper finds show that there was trade with other areas in Europe, as natural copper is not found in Dutch soil.
Bronze Age (around 2000 BC-800 BC).
The Bronze age probably started somewhere around 2000 BC and lasted until around 800 BC. The earliest bronze tools have been found in the grave of a Bronze Age individual called "the smith of Wageningen". More Bronze Age objects from later periods have been found in Epe, Drouwen and elsewhere. Broken bronze objects found in Voorschoten were apparently destined for recycling. This indicates how valuable bronze was considered in the Bronze Age. Typical bronze objects from this period included knives, swords, axes, fibulae and bracelets.
 Most of the Bronze Age objects found in the Netherlands have been found in Drenthe. One item shows that trading networks during this period extended a far distance. Large bronze "situlae" (buckets) found in Drenthe were manufactured somewhere in eastern France or in Switzerland. They were used for mixing wine with water (a Roman/Greek custom). The many finds in Drenthe of rare and valuable objects, such as tin-bead necklaces, suggest that Drenthe was a trading centre in the Netherlands in the Bronze Age.
The Bell Beaker cultures (2700–2100) locally developed into the Bronze Age Barbed-Wire Beaker culture (2100–1800). In the second millennium BC, the region was the boundary between the Atlantic and Nordic horizons and was split into a northern and a southern region, roughly divided by the course of the Rhine.
In the north, the Elp culture (c. 1800 to 800 BC) was a Bronze Age archaeological culture having earthenware pottery of low quality known as ""Kümmerkeramik" (or "Grobkeramik"") as a marker. The initial phase was characterized by tumuli (1800–1200 BC) that were strongly tied to contemporary tumuli in northern Germany and Scandinavia, and were apparently related to the Tumulus culture (1600 BC – 1200 BC) in central Europe. This phase was followed by a subsequent change featuring Urnfield (cremation) burial customs (1200–800 BC). The southern region became dominated by the Hilversum culture (1800–800), which apparently inherited the cultural ties with Britain of the previous Barbed-Wire Beaker culture.
The pre-Roman period (800 BC – 58 BC).
Iron age.
The Iron Age brought a measure of prosperity to the people living in the area of the present-day Netherlands. Iron ore was available throughout the country, including bog iron extracted from the ore in peat bogs ("moeras ijzererts") in the north, the natural iron-bearing balls found in the Veluwe and the red iron ore near the rivers in Brabant. Smiths travelled from small settlement to settlement with bronze and iron, fabricating tools on demand, including axes, knives, pins, arrowheads and swords. Some evidence even suggests the making of Damascus steel swords using an advanced method of forging that combined the flexibility of iron with the strength of steel.
In Oss, a grave dating from around 500 BC was found in a burial mound 52 metres wide (and thus the largest of its kind in western Europe). Dubbed the "king's grave" ("Vorstengraf (Oss)"), it contained extraordinary objects, including an iron sword with an inlay of gold and coral.
In the centuries just before the arrival of the Romans, northern areas formerly occupied by the Elp culture emerged as the probably Germanic Harpstedt culture while the southern parts were influenced by the Hallstatt culture and assimilated into the Celtic La Tène culture. The contemporary southern and western migration of Germanic groups and the northern expansion of the Hallstatt culture drew these peoples into each other's sphere of influence. This is consistent with Caesar's account of the Rhine forming the boundary between Celtic and Germanic tribes.
Arrival of Germanic groups.
The Germanic tribes originally inhabited southern Scandinavia, Schleswig-Holstein and Hamburg, but subsequent Iron Age cultures of the same region, like Wessenstedt (800 BC–600 BC) and Jastorf, may also have belonged to this grouping.
The climate deteriorating in Scandinavia around 850 BC to 760 BC and later and faster around 650 BC might have triggered migrations. Archaeological evidence suggests around 750 BC a relatively uniform Germanic people from the Netherlands to the Vistula and southern Scandinavia. In the west, the newcomers settled the coastal floodplains for the first time, since in adjacent higher grounds the population had increased and the soil had become exhausted.
By the time this migration was complete, around 250 BC, a few general cultural and linguistic groupings had emerged.
One grouping - labelled the "North Sea Germanic" – inhabited the northern part of the Netherlands (north of the great rivers) and extending along the North Sea and into Jutland. This group is also sometimes referred to as the "Ingvaeones". Included in this group are the peoples who would later develop into, among others, the early Frisians and the early Saxons.
A second grouping, which scholars subsequently dubbed the "Weser-Rhine Germanic" (or "Rhine-Weser Germanic"), extended along the middle Rhine and Weser and inhabited the southern part of the Netherlands (south of the great rivers). This group, also sometimes referred to as the "Istvaeones", consisted of tribes that would eventually develop into the Salian Franks.
Celts in the south.
The Celtic culture had its origins in the central European Hallstatt culture (c. 800–450 BC), named for the rich grave finds in Hallstatt, Austria. By the later La Tène period (c. 450 BC up to the Roman conquest), this Celtic culture had, whether by diffusion or migration, expanded over a wide range, including into the southern area of the Netherlands. This would have been the northern reach of the Gauls.
In March 2005 17 Celtic coins were found in Echt (Limburg). The silver coins, mixed with copper and gold, date from around 50 BC to 20 AD. In October 2008 a horde of 39 gold coins and 70 silver Celtic coins was found in the Amby area of Maastricht. The gold coins were attributed to the Eburones people. Celtic objects have also been found in the area of Zutphen.
Although it is rare for hoards to be found, in past decades loose Celtic coins and other objects have been found throughout the central, eastern and southern part of the Netherlands. According to archaeologists these finds confirmed that at least the Maas river valley in the Netherlands was within the influence of the La Tène culture. Dutch archaeologists even speculate that Zutphen (which lies in the centre of the country) was a Celtic area before the Romans arrived, not a Germanic one at all.
Scholars debate the actual extent of the Celtic influence. The Celtic influence and contacts between Gaulish and early Germanic culture along the Rhine is assumed to be the source of a number of Celtic loanwords in Proto-Germanic. But according to Belgian linguist Luc van Durme, toponymic evidence of a former Celtic presence in the Low Countries is near to utterly absent. Although there were Celts in the Netherlands, Iron Age innovations did not involve substantial Celtic intrusions and featured a local development from Bronze Age culture.
The Nordwestblock theory.
Some scholars (De Laet, Gysseling, Hachmann, Kossack & Kuhn) have speculated that a separate ethnic identity, neither Germanic nor Celtic, survived in the Netherlands until the Roman period. They see the Netherlands as having been part of an Iron Age "Nordwestblock" stretching from the Somme to the Weser. Their view is that this culture, which had its own language, was being absorbed by the Celts to the south and the Germanic peoples from the east as late as the immediate pre-Roman perod.
Roman era (57 BC – 410 AD).
Native tribes.
During the Gallic Wars, the Belgic area south of the Oude Rijn and west of the Rhine was conquered by Roman forces under Julius Caesar in a series of campaigns from 57 BC to 53 BC. The tribes located in the area of the Netherlands at this time did not leave behind written records, so all the information known about them during this pre-Roman period is based on what the Romans and Greeks wrote about them. One of the most important is Caesar's own "Commentarii de Bello Gallico". Two main tribes he described as living in what is now the Netherlands were the Menapii, and the Eburones, both in the south, which is where Caesar was active. He established the principle that the Rhine defined a natural boundary between Gaul and Germania magna. But the Rhine was not a strong border, and he made it clear that there was a part of Belgic Gaul where many of the local tribes (including the Eburones) were "Germani cisrhenani", or in other cases, of mixed origin.
The Menapii stretched from the south of Zeeland, through North Brabant (and possibly South Holland), into the southeast of Gelderland. In later Roman times their territory seems to have been divided or reduced, so that it became mainly contained in what is now western Belgium.
The Eburones, the largest of the "Germani Cisrhenani" group, covered a large area including at least part of modern Dutch Limburg, stretching east to the Rhine in Germany, and also northwest to the delta, giving them a border with the Menapii. Their territory may have stretched into Gelderland.
In the delta itself, Caesar makes a passing comment about the "Insula Batavorum" ("Island of the Batavi") in the Rhine river, without discussing who lived there. Later, in imperial times, a tribe called the Batavi became very important in this region. Much later Tacitus wrote that they had originally been a tribe of the Chatti, a tribe in Germany never mentioned by Caesar. However, archaeologists find evidence of continuity, and suggest that the Chattic group may have been a small group, moving into a pre-existing (and possibly non-Germanic) people, who could even have been part of a known group such as the Eburones.
The approximately 450 years of Roman rule that followed would profoundly change the area that would become the Netherlands. Very often this involved large-scale conflict with the free Germanic tribes over the Rhine.
Other tribes who eventually inhabited the islands in the delta during Roman times are mentioned by Pliny the Elder are the Cananefates in South Holland; the Frisii, covering most of the modern Netherlands north of the Oude Rijn; the Frisiabones, who apparently stretched from the delta into the North of North Brabant; the Marsacii, who stretched from the Flemish coast, into the delta; and the Sturii.
Caesar reported that he eliminated the name of the Eburones but in their place the Texuandri inhabited most of North Brabant, and the modern province of Limburg, with the Maas running through it, appears to have been inhabited in imperial times by (from north to south) the Baetasii, the Catualini, the Sunuci and the Tungri. (Tacitus reported that the Tungri was a new name for the earlier "Germani cisrhenani".)
North of the Old Rhine, apart from the Frisii, Pliny reports some Chauci reached into the delta, and two other tribes known from the eastern Netherlands were the Tuihanti (or Tubantes) from Twenthe in Overijssel, and the Chamavi, from Hamaland in northern Gelderland, who became one of the first tribes to be named as Frankish (see below). The Salians, also Franks, probably originated in Salland in Overijssel, before they moved into the empire, forced by Saxons in the 4th century, first into Batavia, and then into Toxandria.
Roman settlements in the Netherlands.
Starting about 15 BC, the Rhine, in the Netherlands came to be defended by the Lower Limes Germanicus. After a series of military actions, the Rhine became fixed around 12 AD as Rome's northern frontier on the European mainland. A number of towns and developments would arise along this line. The area to the south would be integrated into the Roman Empire. At first part of Gallia Belgica, this area became part of the province of Germania Inferior. The tribes already within, or relocated to, this area became part of the Roman Empire. The area to the north of the Rhine, inhabited by the Frisii and the Chauci, remained outside Roman rule but not its presence and control.
Romans built military forts along the Limes Germanicus and a number of towns and smaller settlements in the Netherlands. The more notable Roman towns were at Nijmegen () and at Voorburg (Forum Hadriani).
Perhaps the most evocative Roman ruin is the mysterious Brittenburg, which emerged from the sand at the beach in Katwijk several centuries ago, only to be buried again. These ruins were part of .
Other Roman settlements, fortifications, temples and other structures have been found at Alphen aan de Rijn (); Bodegraven; Cuijk; Elst, Overbetuwe; Ermelo; Esch; Heerlen; Houten; Kessel, North Brabant; Oss, i.e. De Lithse Ham near Maren-Kessel; Kesteren in Neder-Betuwe; Leiden (); Maastricht; Meinerswijk (now part of Arnhem); Tiel; Utrecht (Traiectum); Valkenburg (South Holland) (); Vechten (Fectio) now part of Bunnik; Velsen; Vleuten; Wijk bij Duurstede (); Woerden ( or ); and Zwammerdam ().
Batavian revolt.
The Batavians, Cananefates, and the other border tribes were held in high regard as soldiers throughout the empire, and traditionally served in the Roman cavalry. The frontier culture was influenced by the Romans, Germanic people, and Gauls. In the first centuries after Rome's conquest of Gaul, trade flourished. And Roman, Gaulish and Germanic material culture are found combined in the region.
However, the Batavians rose against the Romans in the Batavian rebellion of 69 AD. The leader of this revolt was Batavian Gaius Julius Civilis. One of the causes of the rebellion was that the Romans had taken young Batavians as slaves. A number of Roman "castella" were attacked and burnt. Other Roman soldiers in Xanten and elsewhere and auxiliary troops of Batavians and Canninefatae in the legions of Vitellius) joined the revolt, thus splitting the northern part of the Roman army. In April 70 AD, a few legions sent by Vespasianus and commanded by Quintus Petillius Cerialis eventually defeated the Batavians and negotiated surrender with Gaius Julius Civilis somewhere between the Waal and the Maas near Noviomagus (Nijmegen), which was probably called "Batavodurum" by the Batavians. The Batavians later merged with other tribes and became part of the Salian Franks.
Dutch writers in the 17th and 18th centuries saw the rebellion of the independent and freedom-loving Batavians as mirroring the Dutch revolt against Spain and other forms of tyranny. According to this nationalist view, the Batavians were the "true" forefathers of the Dutch, which explains the recurring use of the name over the centuries. Jakarta was named "Batavia" by the Dutch in 1619. The Dutch republic created in 1795 on the basis of French revolutionary principles was called the Batavian Republic. Even today "Batavian" is a term sometimes used to describe the Dutch people. (This is similar to use of "Gallic" to describe the French and "Teutonic" to describe the Germans.)
Emergence of the Franks.
Modern scholars of the Migration Period are in agreement that the Frankish identity emerged at the first half of the 3rd century out of various earlier, smaller Germanic groups, including the Salii, Sicambri, Chamavi, Bructeri, Chatti, Chattuarii, Ampsivarii, Tencteri, Ubii, Batavi and the Tungri, who inhabited the lower and middle Rhine valley between the Zuyder Zee and the river Lahn and extended eastwards as far as the Weser, but were the most densely settled around the IJssel and between the Lippe and the Sieg. The Frankish confederation probably began to coalesce in the 210s.
The Franks eventually were divided into two groups: the Ripuarian Franks (Latin: Ripuari), who were the Franks that lived along the middle-Rhine River during the Roman Era, and the Salian Franks, who were the Franks that originated in the area of the Netherlands.
Franks appear in Roman texts as both allies and enemies ("laeti" and "dediticii"). By about 320, the Franks had the region of the Scheldt river (present day west Flanders and southwest Netherlands) under control, and were raiding the Channel, disrupting transportation to Britain. Roman forces pacified the region, but did not expel the Franks, who continued to be feared as pirates along the shores at least until the time of Julian the Apostate (358), when Salian Franks were allowed to settle as "foederati" in Toxandria, according to Ammianus Marcellinus.
Disappearance of the Frisii.
Three factors contributed to the disappearance of the Frisii from the northern Netherlands. First, according to the "Panegyrici Latini" (Manuscript VIII), the ancient Frisii were forced to resettle within Roman territory as "laeti" (i.e., Roman-era serfs) in c. 296. This is the last reference to the ancient Frisii in the historical record. What happened to them, however, is suggested in the archaeological record. The discovery of a type of earthenware unique to 4th-century Frisia, called "terp Tritzum", shows that an unknown number of them were resettled in Flanders and Kent, likely as "laeti" under Roman coercion.
Second, the environment in the low-lying coastal regions of northwestern Europe began to lower c. 250 and gradually receded over the next 200 years. Tectonic subsidence, a rising water table and storm surges combined to flood some areas with marine transgressions. This was accelerated by a shift to a cooler, wetter climate in the region. If there had been any Frisii left in Frisia, they would have drowned. 
Third, after the collapse of the Roman Empire, there was a decline in population as Roman activity stopped and Roman institutions withdrew. As a result of these three factors, the Frisii and Frisiaevones disappeared from the area. The coastal lands remained largely unpopulated for the next two centuries.
Early Middle Ages (411–1000).
Frisians.
As climatic conditions improved, there was another mass migration of Germanic peoples into the area from the east. This is known as the "Migration Period" ("Volksverhuizingen"). The northern Netherlands received an influx of new migrants and settlers, mostly Saxons, but also Angles and Jutes. Many of these migrants did not stay in the northern Netherlands but moved on to England and are known today as the Anglo-Saxons. The newcomers that stayed in the northern Netherlands would eventually be referred to as "Frisians", although they were not descended from the ancient Frisii. These new Frisians settled in the northern Netherlands and would become the ancestors of the modern Frisians. (Because the early Frisians and Anglo-Saxons were formed from largely identical tribal confederacies, their respective languages were very similar. Old Frisian is the most closely related language to Old English and the modern Frisian dialects are in turn the closest related languages to contemporary English.) By the end of the 6th century, the Frisian territory in the northern Netherlands had expanded west to the North Sea coast and, by the 7th century, south to Dorestad. During this period most of the northern Netherlands was known as Frisia. This extended Frisian territory is sometimes referred to as "Frisia Magna" (or Greater Frisia).
In the 7th and 8th centuries, the Frankish chronologies mention this area as the kingdom of the Frisians. This kingdom comprised the coastal provinces of the Netherlands and the German North Sea coast. During this time, the Frisian language was spoken along the entire southern North Sea coast. The 7th-century Frisian Kingdom (650–734) under King Aldegisel and King Redbad, had its centre of power in Utrecht.
Dorestad was the largest settlement (emporia) in northwestern Europe. It had grown around a former Roman fortress. It was a large, flourishing trading place, three kilometers long and situated where the rivers Rhine and Lek diverge southeast of Utrecht near the modern town of Wijk bij Duurstede. Although inland, it was a North Sea trading centre that primarily handled goods from the Middle Rhineland. Wine was among the major products traded at Dorestad, likely from vineyards south of Mainz. It was also widely known because of its mint. Between 600 and around 719 Dorestad was often fought over between the Frisians and the Franks.
Franks.
After Roman government in the area collapsed, the Franks expanded their territories until there were numerous small Frankish kingdoms, especially at Cologne, Tournai, Le Mans and Cambrai. The kings of Tournai eventually came to subdue the other Frankish kings. By the 490s, Clovis I had conquered and united all the Frankish territories to the west of the Meuse, including those in the southern Netherlands. He continued his conquests into Gaul.
After the death of Clovis I in 511, his four sons partitioned his kingdom amongst themselves, with Theuderic I receiving the lands that were to become Austrasia (including the southern Netherlands). A line of kings descended from Theuderic ruled Austrasia until 555, when it was united with the other Frankish kingdoms of Chlothar I, who inherited all the Frankish realms by 558. He redivided the Frankish territory amongst his four sons, but the four kingdoms coalesced into three on the death of Charibert I in 567. Austrasia (including the southern Netherlands) was given to Sigebert I. The southern Netherlands remained the northern part of Austrasia until the rise of the Carolingians.
The Franks who expanded south into Gaul settled there and eventually adopted the Vulgar Latin of the local population. However, a Germanic language was spoken as a second tongue by public officials in western Austrasia and Neustria as late as the 850s. It completely disappeared as a spoken language from these regions during the 10th century. During this expansion to the south, many Frankish people remained in the north (i.e. southern Netherlands, Flanders and a small part of northern France). A widening cultural divide grew between the Franks remaining in the north and the rulers far to the south in what is now France. Salian Franks continued to reside in their original homeland and the area directly to the south and to speak their original language, Old Frankish, which by the 9th century had evolved into Old Dutch. A Dutch-French language boundary came into existence (but this was originally south of where it is today). In the Maas and Rhine areas of the Netherlands, the Franks had political and trading centres, especially at Nijmegen and Maastricht. These Franks remained in contact with the Frisians to the north, especially in places like Dorestad and Utrecht.
Modern doubts about the traditional Frisian, Frank and Saxon distinction.
In the late 19th century, Dutch historians believed that the Franks, Frisians, and Saxons were the original ancestors of the Dutch people. Some went further by ascribing certain attributes, values and strengths to these various groups and proposing that they reflected 19th-century nationalist and religious views. In particular, it was believed that this theory explained why Belgium and the southern Netherlands (i.e. the Franks) had become Catholic and the northern Netherlands (Frisians and Saxons) had become Protestant. The success of this theory was partly due to anthropological theories based on a tribal paradigm. Being politically and geographically inclusive, and yet accounting for diversity, this theory was in accordance with the need for nation-building and integration during the 1890–1914 period. The theory was taught in Dutch schools.
However, the disadvantages of this historical interpretation became apparent. This tribal-based theory suggested that external borders were weak or non-existent and that there were clear-cut internal borders. This origins myth provided an historical premise, especially during the Second World War, for regional separatism and annexation to Germany. After 1945 the tribal paradigm lost its appeal for anthropological scholars and historians. When the accuracy of the three-tribe theme was fundamentally questioned, the theory fell out of favour.
Due to the scarcity of written sources, knowledge of this period depends to a large degree on the interpretation of archaeological data. The traditional view of a clear-cut division between Frisians in the north, Franks in the south and Saxons in the east has proven historically problematic. Archeological evidence suggests dramatically different models for different regions, with demographic continuity for some parts of the country and depopulation and possible replacement in other parts, notably the coastal areas of Frisia and Holland.
The emergence of the Dutch language.
The language from which Old Dutch (also sometimes called Old West Low Franconian, Old Low Franconian or Old Frankish) arose is not known with certainty, but it is thought to be the language spoken by the Salian Franks. Even though the Franks are traditionally categorized as Weser-Rhine Germanic, Dutch has a number of Ingvaeonic characteristics and is classified by modern linguists as an Ingvaeonic language. Dutch also has a number of Old Saxon characteristics. There was a close relationship between Old Dutch, Old Saxon, Old English and Old Frisian. Because texts written in the language spoken by the Franks are almost non-existent, and Old Dutch texts scarce and fragmentary, not much is known about the development of Old Dutch. Old Dutch made the transition to Middle Dutch around 1150.
Christianisation.
The Christianity that arrived in the Netherlands with the Romans appears not to have died out completely (in Maastricht, at least) after the withdrawal of the Romans in about 411.
The Franks became Christians after their king Clovis I converted to Catholicism, an event which is traditionally set in 496. Christianity was introduced in the north after the conquest of Friesland by the Franks. The Saxons in the east were converted before the conquest of Saxony, and became Frankish allies.
Hiberno-Scottish and Anglo-Saxon missionaries, particularly Willibrord, Wulfram and Boniface, played an important role in converting the Frankish and Frisian peoples to Christianity by the 8th century. Boniface was martyred by the Frisians in Dokkum (754).
Frankish dominance and incorporation into Holy Roman Empire.
In the early 8th century the Frisians came increasingly into conflict with the Franks to the south, resulting in a series of wars in which the Frankish Empire eventually subjugated Frisia. In 734, at the Battle of the Boarn, the Frisians in the Netherlands were defeated by the Franks, who thereby conquered the area west of the Lauwers. The Franks then conquered the area east of the Lauwers in 785 when Charlemagne defeated Widukind.
The linguistic descendants of the Franks, the modern Dutch-speakers of the Netherlands and Flanders, seem to have broken with the endonym "Frank" around the 9th century. By this time Frankish identity had changed from an ethnic identity to a national identity, becoming localized and confined to the modern "Franconia" and principally to the French province of "Île-de-France".
Although the people no longer referred to themselves as "Franks", the Netherlands was still part of the Frankish empire of Charlemagne. Indeed, because of the Austrasian origins of the Carolingians in the area between the Rhine and the Maas, the cities of Aachen, Maastricht, Liège and Nijmegen were at the heart of Carolingian culture. Charlemagne maintained his "palatium" in Nijmegen at least four times.
The Carolingian empire would eventually include France, Germany, northern Italy and much of Western Europe. In 843, the Frankish empire was divided into three parts, giving rise to West Francia in the west, East Francia in the east, and Middle Francia in the centre. Most of what is today the Netherlands became part of Middle Francia; Flanders became part of West Francia. This division was an important factor in the historical distinction between Flanders and the other Dutch-speaking areas.
Middle Francia (Latin: "Francia media") was an ephemeral Frankish kingdom that had no historical or ethnic identity to bind its varied peoples. It was created by the Treaty of Verdun in 843, which divided the Carolingian Empire among the sons of Louis the Pious. Situated between the realms of East and West Francia, Middle Francia comprised the Frankish territory between the rivers Rhine and Scheldt, the Frisian coast of the North Sea, the former Kingdom of Burgundy (except for a western portion, later known as "Bourgogne"), Provence and the Kingdom of Italy.
Middle Francia fell to Lothair I, the eldest son and successor of Louis the Pious, after an intermittent civil war with his younger brothers Louis the German and Charles the Bald. In acknowledgement of Lothair's Imperial title, Middle Francia contained the imperial cities of Aachen, the residence of Charlemagne, as well as Rome. In 855, on his deathbed at Prüm Abbey, Emperor Lothair I again partitioned his realm amongst his sons. Most of the lands north of the Alps, including the Netherlands, passed to Lothair II and consecutively were named Lotharingia. After Lothair II died in 869, Lotharingia was partitioned by his uncles Louis the German and Charles the Bald in the Treaty of Meerssen in 870. Although some of the Netherlands had come under Viking control, in 870 it technically became part of East Francia, which became the Holy Roman Empire in 962.
Viking raids.
In the 9th and 10th centuries, the Vikings raided the largely defenceless Frisian and Frankish towns lying on the coast and along the rivers of the Low Countries. Although Vikings never settled in large numbers in those areas, they did set up long-term bases and were even acknowledged as lords in a few cases. In Dutch and Frisian historical tradition, the trading centre of Dorestad declined after Viking raids from 834 to 863; however, since no convincing Viking archaeological evidence has been found at the site (as of 2007), doubts about this have grown in recent years.
One of the most important Viking families in the Low Countries was that of Rorik of Dorestad (based in Wieringen) and his brother the "younger Harald" (based in Walcheren), both thought to be nephews of Harald Klak. Around 850, Lothair I acknowledged Rorik as ruler of most of Friesland. And again in 870, Rorik was received by Charles the Bald in Nijmegen, to whom he became a vassal. Viking raids continued during that period. Harald’s son Rodulf and his men were killed by the people of Oostergo in 873. Rorik died sometime before 882.
Buried Viking treasures consisting mainly of silver have been found in the Low Countries. Two such treasures have been found in Wieringen. A large treasure found in Wieringen in 1996 dates from around 850 and is thought perhaps to have been connected to Rorik. The burial of such a valuable treasure is seen as an indication that there was a permanent settlement in Wieringen.
Around 879, Godfrid arrived in Frisian lands as the head of a large force that terrorised the Low Countries. Using Ghent as his base, they ravaged Ghent, Maastricht, Liège, Stavelot, Prüm, Cologne, and Koblenz. Controlling most of Frisia between 882 and his death in 885, Godfrid became known to history as Godfrid, Duke of Frisia. His lordship over Frisia was acknowledged by Charles the Fat, to whom he became a vassal. Godfried was assassinated in 885, after which Gerolf of Holland assumed lordship and Viking rule of Frisia came to an end.
Viking raids of the Low Countries continued for over a century. Remains of Viking attacks dating from 880 to 890 have been found in Zutphen and Deventer. In 920, King Henry of Germany liberated Utrecht. According to a number of chronicles, the last attacks took place in the first decade of the 11th century and were directed at Tiel and/or Utrecht.
These Viking raids occurred about the same time that French and German lords were fighting for supremacy over the middle empire that included the Netherlands, so their sway over this area was weak. Resistance to the Vikings, if any, came from local nobles, who gained in stature as a result.
High Middle Ages (1000–1432).
Part of the Holy Roman Empire.
The German kings and emperors ruled the Netherlands in the 10th and 11th century. Germany was called the Holy Roman Empire after the coronation of King Otto the Great as emperor. The Dutch city of Nijmegen used to be the spot of an important domain of the German emperors. Several German emperors were born and died there. (Byzantine empress Theophanu died in Nijmegen for instance.) Utrecht was also an important city and trading port at the time.
Political disunity.
The Holy Roman Empire was not able to maintain political unity. In addition to the growing independence of the towns, local rulers turned their counties and duchies into private kingdoms and felt little sense of obligation to the emperor who reigned over large parts of the nation in name only. Large parts of what now comprise the Netherlands were governed by the Count of Holland, the Duke of Gelre, the Duke of Brabant and the Bishop of Utrecht. Friesland and Groningen in the north maintained their independence and were governed by the lower nobility.
The various feudal states were in a state of almost continual war. Gelre and Holland fought for control of Utrecht. Utrecht, whose bishop had in 1000 ruled over half of what is today the Netherlands, was marginalised as it experienced continuing difficulty in electing new bishops. At the same time, the dynasties of neighbouring states were more stable. Groningen, Drenthe and most of Gelre, which used to be part of Utrecht, became independent. Brabant tried to conquer its neighbours, but was not successful. Holland also tried to assert itself in Zeeland and Friesland, but its attempts failed.
The Frisians.
The language and culture of most of the people who lived in the area that is now Holland were originally Frisian. The sparsely populated area was known as "West Friesland" ("Westfriesland"). As Frankish settlement progressed, the Frisians migrated away or were absorbed and the area quickly became Dutch. (The part of North Holland situated north of the 'IJ' is still colloquially known as West Friesland).
The rest of Friesland in the north continued to maintain its independence during this time. It had its own institutions (collectively called the "Frisian freedom") and resented the imposition of the feudal system and the patriciate found in other European towns. They regarded themselves as allies of Switzerland. The Frisian battle cry was "better dead than a slave". They later lost their independence when they were defeated in 1498 by the German Landsknecht mercenaries of Duke Albrecht of Saxony-Meissen.
The rise of Holland.
The center of power in these emerging independent territories was in the County of Holland. Originally granted as a fief to the Danish chieftain Rorik in return for loyalty to the emperor in 862, the region of Kennemara (the region around modern Haarlem) rapidly grew under Rorik's descendants in size and importance. By the early 11th century, Dirk III, Count of Holland was levying tolls on the Meuse estuary and was able to resist military intervention from his overlord, the Duke of Lower Lorraine.
In 1083, the name "Holland" first appears in a deed referring to a region corresponding more or less to the current province of South Holland and the southern half of what is now North Holland. Holland's influence continued to grow over the next two centuries. The counts of Holland conquered most of Zeeland but it was not until 1289 that Count Floris V was able to subjugate the Frisians in West Friesland (that is, the northern half of North Holland).
Expansion and growth.
Around 1000 AD there were several agricultural developments (described sometimes as an agricultural revolution) that resulted in an increase in production, especially food production. The economy started to develop at a fast pace, and the higher productivity allowed workers to farm more land or to become tradesmen.
Much of the western Netherlands was barely inhabited between the end of the Roman period until around 1100 AD, when farmers from Flanders and Utrecht began purchasing the swampy land, draining it and cultivating it. This process happened quickly and the uninhabited territory was settled in a few generations. They built independent farms that were not part of villages, something unique in Europe at the time.
Guilds were established and markets developed as production exceeded local needs. Also, the introduction of currency made trading a much easier affair than it had been before. Existing towns grew and new towns sprang into existence around monasteries and castles, and a mercantile middle class began to develop in these urban areas. Commerce and town development increased as the population grew.
The Crusades were popular in the Low Countries and drew many to fight in the Holy Land. At home, there was relative peace. Viking pillaging had stopped. Both the Crusades and the relative peace at home contributed to trade and the growth in commerce.
Cities arose and flourished, especially in Flanders and Brabant. As the cities grew in wealth and power, they started to buy certain privileges for themselves from the sovereign, including city rights, the right to self-government and the right to pass laws. In practice, this meant that the wealthiest cities became quasi-independent republics in their own right. Two of the most important cities were Brugge and Antwerp (in Flanders) which would later develop into some of the most important cities and ports in Europe.
Hook and Cod Wars.
The Hook and Cod Wars (Dutch: "Hoekse en Kabeljauwse twisten") were a series of wars and battles in the County of Holland between 1350 and 1490. Most of these wars were fought over the title of count of Holland, but some have argued that the underlying reason was because of the power struggle of the bourgeois in the cities against the ruling nobility.
The Cod faction generally consisted of the more progressive cities of Holland. The Hook faction consisted for a large part of the conservative noblemen. Some of the main figures in this multi-generational conflict were William IV, Margaret, William V, William VI, Count of Holland and Hainaut, John and Philip the Good, Duke of Burgundy. But perhaps the most well known is Jacqueline, Countess of Hainaut.
The conquest of the county of Holland by the Duke Philip the Good of Burgundy was an odd affair. Leading noblemen in Holland invited the duke to conquer Holland, even though he had no historical claim to it. Some historians say that the ruling class in Holland wanted Holland to integrate with the Flemish economic system and adopt Flemish legal institutions. Europe had been wracked by many civil wars in the 14th and 15th centuries, while Flanders had grown rich and enjoyed peace.
Burgundian and Habsburg period (1433–1567).
Burgundian period.
Most of what is now the Netherlands and Belgium was eventually united by the Duke of Burgundy in 1433. Before the Burgundian union, the Dutch identified themselves by the town they lived in, their local duchy or county or as subjects of the Holy Roman Empire. The Burgundian period is when the Dutch began the road to nationhood.
Holland's trade developed rapidly, especially in the areas of shipping and transport. The new rulers defended Dutch trading interests. The fleets of Holland defeated the fleets of the Hanseatic League several times. Amsterdam grew and in the 15th century became the primary trading port in Europe for grain from the Baltic region. Amsterdam distributed grain to the major cities of Belgium, Northern France and England. This trade was vital to the people of Holland, because Holland could no longer produce enough grain to feed itself. Land drainage had caused the peat of the former wetlands to reduce to a level that was too low for drainage to be maintained.
Habsburg rule from Spain.
Charles V (1500–58) was born and raised in the Flemish city of Ghent; he spoke French. Charles extended the Burgundian territory with the annexation of Tournai, Artois, Utrecht, Groningen and Guelders. The Seventeen Provinces had been unified by Charles's Burgundian ancestors, but nominally were fiefs of either France or the Holy Roman Empire. When he was a minor, his aunt Margaret acted as regent until 1515. France relinquished its ancient claim on Flanders in 1528.
From 1515 to 1523, Charles's government in the Netherlands had to contend with the rebellion of Frisian peasants (led by Pier Gerlofs Donia and Wijard Jelckama). Gelre attempted to build up its own state in northeast Netherlands and northwest Germany. Lacking funds in the 16th century, Gelre had its soldiers provide for themselves by pillaging enemy terrain. These soldiers were a great menace to the Burgundian Netherlands, as when they pillaged The Hague.
The dukes of Burgundy over the years through astute marriages, purchases and wars, had taken control of the Seventeen Provinces that made up the Low Countries. They are now the Netherlands in the north, the Southern Netherlands (now Belgium) in the south, and Luxemburg in the southeast. Known as the "Burgundian Circle," these lands came under the control of the Habsburg family. Charles (1500–58) became the owner in 1506, but in 1515 he left to become king of Spain and later became the Holy Roman Emperor. Charles turned over control to regents (his close relatives), and in practice rule was exercised by Spaniards he controlled. The provinces each had their own governments and courts, controlled by the local nobility, and their own traditions and rights ("liberties") dating back centuries. Likewise the numerous cities had their own legal rights and local governments, usually controlled by the merchants, On top of this the Spanish had imposed an overall government, the Estates General of the Netherlands, with its own officials and courts. The Spanish officials sent by Charles ignored traditions and the Dutch nobility as well as local officials, inciting an anti-Spanish sense of nationalism, and leading to the Dutch Revolt. With the emergence of the Protestant Reformation, Charles—now the Emperor—was determined to crush Protestantism and never compromise with it. Unrest began in the south, centered in the large rich metropolis of Antwerp. The Netherlands was an especially rich unit of the Spanish realm, especially after the Treaty of Cateau-Cambresis of 1559; it ended four decades of warfare between France and Spain and allowed Spain to reposition its army.
In 1548, Charles granted the Netherlands status as an entity separate from both the Holy Roman Empire and from France with the "Transaction of Augsburg." It was not full independence, but it allowed significant autonomy. In the Pragmatic Sanction of 1549 it was stated that the Seventeen Provinces could only be passed on to his heirs as a united entity.
The Reformation.
During the 16th century, the Protestant Reformation rapidly gained ground in northern Europe, especially in its Lutheran and Calvinist forms. Dutch Protestants, after initial repression, were tolerated by local authorities. By the 1560s, the Protestant community had become a significant influence in the Netherlands, although it clearly formed a minority then. In a society dependent on trade, freedom and tolerance were considered essential. Nevertheless, the Catholic rulers Charles V, and later Philip II, felt it was their duty to defeat Protestantism, which was considered a heresy by the Catholic Church and a threat to the stability of the whole hierarchical political system. On the other hand the intensely moralistic Dutch Protestants insisted their Biblical theology, sincere piety and humble lifestyle was morally superior to the luxurious habits and superficial religiosity of the ecclesiastical nobility. The rulers' harsh punitive measures led to increasing grievances in the Netherlands, where the local governments had embarked on a course of peaceful coexistence. In the second half of the century, the situation escalated. Philip sent troops to crush the rebellion and make the Netherlands once more a Catholic region.
In the first wave of the Reformation Lutheranism won over the elites in Antwerp and the South. The Spanish successfully suppressed it there, and Lutheranism only flourished in east Friesland.
The second wave of the Reformation, came in the form of Anabaptism, that was popular among ordinary farmers in Holland and Friesland. Anabaptists were socially very radical and equalitarian; they believed that the apocalypse was very near. They refused to live the old way, and began new communities, creating considerable chaos. A prominent Dutch anabaptist was Menno Simons, who initiated the Mennonite church. The movement was allowed in the north, but never grew to a large scale.
The third wave and most permanent wave of the Reformation, was Calvinism. It arrived in the Netherlands in the 1540s, converting many of the elite and the common population, especially in Flanders. The Catholic Spanish responded with harsh persecution and introduced the Inquisition of the Netherlands. Calvinists rebelled. First there was the iconoclasm in 1566, which was the systematic destruction of statues of saints and other Catholic devotional depictions in churches. In 1566 William the Silent, a Calvinist, started the Eighty Years' War to liberate all Dutch of whatever religion from Catholic Spain. Blum says, "His patience, tolerance, determination, concern for his people, and belief in government by consent held the Dutch together and kept alive their spirit of revolt." The provinces of Holland and Zeeland, being mainly Calvinist by 1572, submitted to the rule of William. The other states remained almost entirely Catholic.
Prelude to war.
The Netherlands was a valuable part of the Spanish Empire, especially after the Treaty of Cateau-Cambresis of 1559. This treaty ended a forty-year period of warfare between France and Spain conducted in Italy from 1521 to 1559. The Treaty of Cateau-Cambresis was somewhat of a watershed—not only for the battleground that Italy had been, but also for northern Europe. Spain had been keeping troops in the Netherlands to be ready to attack France from the north as well as from the south.
With the settlement of so many major issues between France and Spain by the Treaty of Cateau-Cambresis, there was no longer any reason to keep Spanish troops in the Netherlands. Thus, the people of the Netherlands could get on with their peacetime pursuits. As they did so they found that there was a great deal of demand for their products. Fishing had long been an important part of the economy of the Netherlands. However, now the fishing of herring alone came to occupy 2,000 boats operating out of Dutch ports. Spain, still the Dutch trader's best customer, was buying fifty large ships full of furniture and household utensils from Flanders merchants. Additionally, Dutch woolen goods were desired everywhere. The Netherlands bought and processed enough Spanish wool to sell four million florins of wool products through merchants in Bruges. So strong was the Dutch appetite for raw wool at this time that they bought nearly as much English wool as they did Spanish wool. Total commerce with England alone amounted to 24 million florins. Much of the export going to England resulted in pure profit to the Dutch because the exported items were of their own manufacture. The Netherlands was just starting to enter its "Golden Age." Brabant and Flanders were the richest and most flourishing parts of the Dutch Republic at the time. The Netherlands was one of the richest places in the world. The population reached 3 million in 1560, with 25 cities of 10,000 people or more, by far the largest urban presence in Europe; with the trading and financial center of Antwerp being especially important (population 100,000). Spain could not afford to lose this rich land, nor allow it to fall from Catholic control. Thus came 80 years of warfare.
A devout Catholic, Philip was appalled by the success of the Reformation in the Low Countries, which had led to an increasing number of Calvinists. His attempts to enforce religious persecution of the Protestants and his endeavours to centralise government, justice and taxes made him unpopular and led to a revolt. Fernando Alvarez de Toledo, Duke of Alba, was sent with a Spanish Army to punish the unruly Dutch in 1567.
The only opposition the Duke of Alba faced in his march across the Netherlands were the nobles, Lamoral, Count of Egmont; Philippe de Montmorency, Count of Horn and others. With the approach of Alba and the Spanish army, William the Silent of Orange fled to Germany with his three brothers and his whole family on 11 April 1567. The Duke of Alba sought to meet and negotiate with the nobles that now faced him with armies. However, when the nobles arrived in Brussels they were all arrested and Egmont and Horn were executed. Alba then revoked all the prior treaties that Margaret, the Duchess of Parma had signed with the Protestants of the Netherlands and instituted the Inquisition to enforce the decrees of the Council of Trent.
The Eighty Years' War (1568–1648).
The Dutch War for Independence from Spain is frequently called the Eighty Years' War (1568–1648). The first fifty years (1568 through 1618) were uniquely a war between Spain and the Netherlands. During the last thirty years (1618–1648) the conflict between Spain and the Netherlands was submerged in the general European War that became known as the Thirty Years War. The seven rebellious provinces of the Netherlands were eventually united by the Union of Utrecht in 1579 and formed the Republic of the Seven United Netherlands (also known as the "United Provinces"). The Act of Abjuration or "Plakkaat van Verlatinghe" was signed on 26 July 1581, and was the formal declaration of independence of the northern Low Countries from the Spanish king.
William of Orange (Slot Dillenburg, 24 April 1533 – Delft, 10 July 1584), the founder of the Dutch royal family, led the Dutch during the first part of the war, following the death of Egmont and Horn in 1568. The very first years were a success for the Spanish troops. However, the Dutch countered subsequent sieges in Holland. At several points the Spanish soldiers committed massacres known as Spanish Fury; the most famous 'Spanish Fury' was the sack of Antwerp in 1576, killing 10,000.
In a war composed mostly of sieges rather than battles, Governor-General Alexander Farnese proved his mettle. His strategy was to offer generous terms for the surrender of a city: there would be no more "Spanish furies" (massacres) or looting; historic urban privileges were retained; there was a full pardon and amnesty; return to the Catholic Church would be gradual. The conservative Catholics in the south and east supported the Spanish. Farnese recaptured Antwerp and nearly all of what became Belgium. Most of the Dutch-speaking territory in the Netherlands was taken from Spain, but not in Flanders, which to this day remains part of Belgium. Flanders was the most radical anti-Spanish territory. Many Flemish fled to Holland, among them half of the population of Antwerp, 3/4 of Bruges and Ghent and the entire population of Nieuwpoort, Dunkerque and countryside. His successful campaign gave the Catholics control of the lower half of the Low Countries, and was part of the Catholic Counter-Reformation.
The war dragged on for another half century, but the main fighting was over. The Peace of Westphalia, signed in 1648, confirmed the independence of the United Provinces from Spain. The Dutch people started to develop a national identity since the 15th century, but they officially remained a part of the Holy Roman Empire until 1648. National identity was mainly formed by the province people came from. Holland was the most important province by far. The republic of the Seven Provinces came to be known as Holland across Europe.
The Catholics in the Netherlands were an outlawed minority that had been suppressed by the Calvinists. After 1572, however, they made a striking comeback (also as part of the Catholic Counter-Reformation), setting up seminaries, reforming their Church, and sending missionaries into Protestant districts. Laity often took the lead; the Calvinist government often arrested or harassed priests who seemed too effective. Catholic numbers stabilized at about a third of the population in the Netherlands; they were strongest in the southeast.
Golden Age.
During the Eighty Years' War the Dutch provinces became the most important trading centre of Northern Europe, replacing Flanders in this respect. During the Golden Age, there was a great flowering of trade, industry, the arts and the sciences in the Netherlands. In the 17th and 18th centuries, the Dutch were arguably the most economically wealthy and scientifically advanced of all European nations. This new, officially Calvinist nation flourished culturally and economically, creating what historian Simon Schama has called an "embarrassment of riches". Speculation in the tulip trade led to a first stock market crash in 1637, but the economic crisis was soon overcome. Due to these developments the 17th century has been dubbed the Golden Age of the Netherlands.
The invention of the sawmill enabled the construction of a massive fleet of ships for worldwide trading and for defence of the republic's economic interests by military means. National industries such as shipyards and sugar refineries expanded as well.
The Dutch, traditionally able seafarers and keen mapmakers, obtained an increasingly dominant position in world trade, a position which before had been occupied by the Portuguese and Spaniards. In 1602 the Dutch East India Company (Dutch: "Verenigde Oostindische Compagnie" or "VOC") was founded. It was the first-ever multinational corporation, financed by shares that established the first modern stock exchange. It became the world's largest commercial enterprise of the 17th century. To finance the growing trade within the region, the Bank of Amsterdam was established in 1609, the precursor to, if not the first true central bank.
Dutch ships hunted whales off Svalbard, traded spices in India and Indonesia (via the Dutch East India Company) and founded colonies in New Amsterdam (now New York), South Africa and the West Indies. In addition some Portuguese colonies were conquered, namely in Northeastern Brazil, Angola, Indonesia and Ceylon. In 1640 by the Dutch East India Company began a trade monopoly with Japan through the trading post on Dejima.
The Dutch also dominated trade between European countries. The Low Countries were favorably positioned on a crossing of east-west and north-south trade routes and connected to a large German hinterland through the Rhine river. Dutch traders shipped wine from France and Portugal to the Baltic lands and returned with grain destined for countries around the Mediterranean Sea. By the 1680s, an average of nearly 1000 Dutch ships entered the Baltic Sea each year. The Dutch were able to gain control of much of the trade with the nascent English colonies in North America and following the end of war with Spain in 1648, Dutch trade with that country also flourished.
Renaissance Humanism, of which Desiderius Erasmus (c. 1466–1536) was an important advocate, had also gained a firm foothold and was partially responsible for a climate of tolerance. Overall, levels of tolerance were sufficiently high to attract religious refugees from other countries, notably Jewish merchants from Portugal who brought much wealth with them. The revocation of the Edict of Nantes in France in 1685 resulted in the immigration of many French Huguenots, many of whom were shopkeepers or scientists. Still tolerance had its limits, as philosopher Baruch de Spinoza (1632–1677) would find out. Due to its climate of intellectual tolerance the Dutch Republic attracted scientists and other thinkers from all over Europe. Especially the renowned University of Leiden (established in 1575 by the Dutch stadtholder, William of Oranje, as a token of gratitude for Leiden's fierce resistance against Spain during the Eighty Years War) became a gathering place for these people. For instance French philosopher René Descartes lived in Leiden from 1628 until 1649.
Dutch lawyers were famous for their knowledge of international law of the sea and commercial law. Hugo Grotius (1583–1645) played a leading part in the foundation of international law. Again due to the Dutch climate of tolerance, book publishers flourished. Many books about religion, philosophy and science that might have been deemed controversial abroad were printed in the Netherlands and secretly exported to other countries. Thus during the 17th century the Dutch Republic became more and more Europe's publishing house.
Christiaan Huygens (1629–1695) was a famous astronomer, physicist and mathematician. He invented the pendulum clock, which was a major step forward towards exact timekeeping. He contributed to the fields of optics. The most famous Dutch scientist in the area of optics is certainly Anton van Leeuwenhoek, who invented or greatly improved the microscope (opinions differ) and was the first to methodically study microscopic life, thus laying the foundations for the field of microbiology. Famous Dutch hydraulic engineer Jan Leeghwater (1575–1650) gained important victories in The Netherlands's eternal battle against the sea. Leeghwater added a considerable amount of land to the republic by converting several large lakes into polders, pumping all water out with windmills.
Painting was the dominant art form in 17th-century Holland. Dutch Golden Age painting followed many of the tendencies that dominated Baroque art in other parts of Europe, as with the Utrecht Caravaggisti, but was the leader in developing the subjects of still life, landscape, and genre painting. Portraiture were also popular, but history painting – traditionally the most-elevated genre struggled to find buyers. Church art was virtually non-existent, and little sculpture of any kind produced. While art collecting and painting for the open market was also common elsewhere, art historians point to the growing number of wealthy Dutch middle-class and successful mercantile patrons as driving forces in the popularity of certain pictorial subjects. Today, the best-known painters of the Dutch Golden Age are the period's most dominant figure Rembrandt, the Delft master of genre Johannes Vermeer, the innovative landscape painter Jacob van Ruisdael, and Frans Hals, who infused new life into portraiture. Some notable artistic styles and trends include Haarlem Mannerism, Utrecht Caravaggism, the School of Delft, the Leiden fijnschilders, and Dutch classicism.
Due to the thriving economy, cities expanded greatly. New town halls, weighhouses and storehouses were built. Merchants that had gained a fortune ordered a new house built along one of the many new canals that were dug out in and around many cities (for defence and transport purposes), a house with an ornamented façade that befitted their new status. In the countryside, many new castles and stately homes were built. Most of them have not survived. Starting at 1595 Reformed churches were commissioned, many of which are still landmarks today. The most famous Dutch architects of the 17th century were Jacob van Campen, Pieter Post, Pieter Vingbooms, Lieven de Key, Hendrick de Keyser. Overall, Dutch architecture, which generally combined traditional building styles with some foreign elements, did not develop to the level of painting.
The Golden Age was also an important time for developments in literature. Some of the major figures of this period were Gerbrand Adriaenszoon Bredero, Jacob Cats, Pieter Corneliszoon Hooft and Joost van den Vondel. Since Latin was the lingua franca of education, relatively few men could speak, write, and read Dutch all at the same time.
Music did not develop very much in the Netherlands since the Calvinists considered it an unnecessary extravagance, and organ music was forbidden in Reformed Church services, although it remained common at secular functions.
Dutch Empire.
The Dutch in the Americas.
The "Dutch West India Company" was a chartered company (known as the "GWC") of Dutch merchants. On 2 June 1621, it was granted a for a trade monopoly in the West Indies (meaning the Caribbean) by the Republic of the Seven United Netherlands and given jurisdiction over the African slave trade, Brazil, the Caribbean, and North America. Its area of operations stretched from West Africa to the Americas, and the Pacific islands. The company became instrumental in the Dutch colonization of the Americas. The first forts and settlements in Guyana and on the Amazon date from the 1590s. Actual colonization, with Dutch settling in the new lands, was not as common as with England and France. Many of the Dutch settlements were lost or abandoned by the end of that century, but the Netherlands managed to retain possession of Suriname and a number of Dutch Caribbean islands.
The colony was a private business venture to exploit the fur trade in beaver pelts. New Netherland was slowly settled during its first decades, partially as a result of policy mismanagement by the Dutch West India Company (WIC), and conflicts with Native Americans. During the 1650s, the colony experienced dramatic growth and became a major port for trade in the Atlantic World, tolerating a highly diverse ethnic mix. The surrender of Fort Amsterdam to the British control in 1664 was formalized in 1667, contributing to the Second Anglo–Dutch War. In 1673 the Dutch re-took the area, but later relinquished it under the 1674 Treaty of Westminster ending the Third Anglo-Dutch War.
Descendants of the original settlers played a prominent role in the History of the United States, as typified by the Roosevelt and Vanderbilt families. The Hudson Valley still boasts a Dutch heritage. The concepts of civil liberties and pluralism introduced in the province became mainstays of American political and social life.
Slave trade.
Although slavery was illegal inside the Netherlands it flourished in the Dutch Empire, and helped support the economy. In 1619 The Netherlands took the lead in building a large-scale slave trade between Africa and Virginia, by 1650 becoming the pre-eminent slave trading country in Europe. It was overtaken by Britain around 1700. Historians agree that in all the Dutch shipped about 550,000 African slaves across the Atlantic, about 75,000 of whom died on board before reaching their destinations. From 1596–1829, the Dutch traders sold 250,000 slaves in the Dutch Guianas, 142,000 in the Dutch Caribbean islands, and 28,000 in Dutch Brazil. In addition, tens of thousands of slaves, mostly from India and some from Africa, were carried to the Dutch East Indies and slaves from the East Indies to Africa and the West Indies.
The Dutch in Asia: The Dutch East India Company.
The Dutch East India Company, called the VOC began in 1602, when the government gave it a monopoly to trade with Asia. It had many world firsts—the first multinational corporation, the first company to issue stock, and was the first megacorporation, possessing quasi-governmental powers, including the ability to wage war, negotiate treaties, coin money, and establish colonial settlements.
England and France soon copied its model but could not match its record. Between 1602 and 1796 the VOC sent almost a million Europeans to work in the Asia trade on 4,785 ships. It returned over 2.5 million tons of Asian trade goods. The VOC enjoyed huge profits from its spice monopoly through most of the 17th century. The VOC was active chiefly in the Dutch East Indies, now Indonesia, where its base was Batavia (now Jakarta). Over the next two centuries the Company acquired additional ports as trading bases and safeguarded their interests by taking over surrounding territory. It remained an important trading concern and paid an 18% annual dividend for almost 200 years. Weighed down by corruption, the VOC went bankrupt in 1800. Its possessions were taken over by the government and turned into the Dutch East Indies.
The Dutch in Africa.
In 1647, a Dutch vessel was wrecked in the present-day Table Bay at Cape Town. The marooned crew, the first Europeans to attempt settlement in the area, built a fort and stayed for a year until they were rescued. Shortly thereafter, the Dutch East India Company (in the Dutch of the day: "Vereenigde Oostindische Compagnie", or VOC) decided to establish a permanent settlement. The VOC, one of the major European trading houses sailing the spice route to the East, had no intention of colonising the area, instead wanting only to establish a secure base camp where passing ships could shelter, and where hungry sailors could stock up on fresh supplies of meat, fruit, and vegetables. To this end, a small VOC expedition under the command of Jan van Riebeeck reached Table Bay on 6 April 1652.
To remedy a labour shortage, the VOC released a small number of VOC employees from their contracts and permitted them to establish farms with which they would supply the VOC settlement from their harvests. This arrangement proved highly successful, producing abundant supplies of fruit, vegetables, wheat, and wine; they also later raised livestock. The small initial group of "free burghers", as these farmers were known, steadily increased in number and began to expand their farms further north and east.
The majority of burghers had Dutch ancestry and belonged to the Calvinist Reformed Church of the Netherlands, but there were also numerous Germans as well as some Scandinavians. In 1688 the Dutch and the Germans were joined by French Huguenots, also Calvinists, who were fleeing religious persecution in France under King Louis XIV. The Huguenots in South Africa were absorbed into the Dutch population but they played a prominent role in South Africa's history.
From the beginning the VOC used the Cape as a place to supply ships travelling between the Netherlands and the Dutch East Indies. There was a close association between the Cape and these Dutch possessions in the far east. Van Riebeeck and the VOC began to import large numbers of slaves, primarily from Madagascar and Indonesia. These slaves often married Dutch settlers, and their descendants became known as the Cape Coloureds and the Cape Malays.
During the 18th century, the Dutch settlement in the area of the Cape grew and prospered. By the late 1700s the Cape Colony was one of the best developed European settlements outside Europe or the Americas. The two bases of the Cape Colony's economy for almost the entirety of its history were shipping and agriculture. Its strategic position meant that almost every ship sailing between Europe and Asia stopped off at the colony's capital Cape Town. The supplying of these ships with fresh provisions, fruit, and wine provided a very large market for the surplus produce of the colony.
Some free burghers continued to expand into the rugged hinterlands of the north and east, many began to take up a semi-nomadic pastoralist lifestyle, in some ways not far removed from that of the Khoikhoi they had displaced. In addition to its herds, a family might have a wagon, a tent, a Bible, and a few guns. As they became more settled, they would build a mud-walled cottage, frequently located, by choice, days of travel from the nearest European settlement. These were the first of the Trekboers (Wandering Farmers, later shortened to Boers), completely independent of official controls, extraordinarily self-sufficient, and isolated from the government and the main settlement in Cape Town.
Dutch was the official language, but a dialect had formed that was quite distinct from Dutch. The Afrikaans language originated mainly from 17th-century Dutch dialects.
This Dutch dialect, sometimes referred to as the "kitchen language" ("kombuistaal"), would eventually in the late 19th century be recognised as a distinct language called Afrikaans and replace Dutch as the official language of the Afrikaners.
As the 18th century drew to a close, Dutch mercantile power began to fade and the British moved in to fill the vacuum. They seized the Cape Colony in 1795 to prevent it from falling into French hands, then briefly relinquished it back to the Dutch (1803), before definitively conquering it in 1806. British sovereignty of the area was recognised at the Congress of Vienna in 1815. By the time the Dutch colony was seized by the British in 1806, it had grown into an established settlement with 25,000 slaves, 20,000 white colonists, 15,000 Khoisan, and 1,000 freed black slaves. Outside Cape Town and the immediate hinterland, isolated black and white pastoralists populated the country.
Dutch interest in South Africa was mainly as a strategically located VOC port. Yet in the 17th and 18th centuries the Dutch created the foundation of the modern state of South Africa. The Dutch legacy in South Africa is evident everywhere, but particularly in the Afrikaner people and the Afrikaans language.
Dutch Republic: Regents and Stadholders (1649–1784).
The Netherlands gained independence from Spain as a result of the Eighty Years War, during which the Dutch Republic was founded. As the Netherlands was a republic, it was largely governed by an aristocracy of city-merchants called the regents, rather than by a king. Every city and province had its own government and laws, and a large degree of autonomy. After attempts to find a competent sovereign proved unsuccessful, it was decided that sovereignty would be vested in the various provincial Estates, the governing bodies of the provinces. The Estates-General, with its representatives from all the provinces, would decide on matters important to the Republic as a whole. However, at the head of each province was the stadtholder of that province, a position held by a descendant of the House of Orange. Usually the stadtholdership of several provinces was held by a single man.
After having gained its independence in 1648, the Netherlands tried in various coalitions to help to contain France, which had replaced Spain as the strongest nation of Europe. The end of the War of the Spanish Succession (1713) marked the end of the Dutch Republic as a major player. In the 18th century, it just tried to maintain its independence and stuck to a policy of neutrality.
The economy, based on Amsterdam's role as the center of world trade, remained robust. In 1670 the Dutch merchant marine totalled 568,000 tons of shipping—about half the European total. The province of Holland was highly commercial and dominated the country. Its nobility was small and closed and had little influence, for it was numerically small, politically weak, and formed a strictly closed caste. Most land in the province of Holland was commercialized for cash crops and was owned by urban capitalists, not nobles; there were few links between Holland's nobility and the merchants. By 1650 the burgher families which had grown wealthy through commerce and become influential in government controlled the province of Holland, and to a large extent shaped national policies. The other six provinces were more rural and traditional in life style, had an active nobility, and played a small role in commerce and national politics. Instead they concentrated on their flood protections and land reclamation projects.
Refugees.
The Netherlands sheltered many notable refugees, including Protestants from Antwerp and Flanders, Portuguese and German Jews, French Protestants (Huguenots) (including Descartes) and English Dissenters (including the Pilgrim Fathers). Many immigrants came to the cities of Holland in the 17th and 18th century from the Protestant parts of Germany and elsewhere. The amount of first generation immigrants from outside the Netherlands in Amsterdam was nearly 50% in the 17th and 18th centuries. Indeed, Amsterdam's population consisted primarmily of immigrants, if one includes second and third generation immigrants and migrants from the Dutch countryside. People in most parts of Europe were poor and many were unemployed. But in Amsterdam there was always work. Tolerance was important, because a continuous influx of immigrants was necessary for the economy. Travellers visiting Amsterdam reported their surprise at the lack of control over the influx.
Economic growth.
The era of explosive economic growth is roughly coterminous with the period of social and cultural bloom that has been called the Dutch Golden Age, and that actually formed the material basis for that cultural era. Amsterdam became the hub of world trade, the center into which staples and luxuries flowed for sorting, processing, and distribution, and then reexported around Europe and the world.
During 1585 through 1622 there was the rapid accumulation of trade capital, often brought in by refugee merchantes from Antwerp and other ports. The money was typically invested in high-risk ventures like pioneering expeditions to the East Indies to engage in the spice trade. These ventures were soon consolidated in the Dutch East India Company (VOC). There were similar ventures in different fields however, like the trade on Russia and the Levant. The profits of these ventures were ploughed back in the financing of new trade, which led to its exponential growth.
Rapid industrialization led to the rapid growth of the nonagricultural labor force and the increase in real wages during the same time. In the half-century between 1570 and 1620 this labor supply increased 3 percent per annum, a truly phenomenal growth. Despite this, nominal wages were repeatedly increased, outstripping price increases. In consequence, real wages for unskilled laborers were 62 percent higher in 1615–1619 than in 1575–1579.
Amsterdam.
By the mid-1660s Amsterdam had reached the optimum population (about 200,000) for the level of trade, commerce and agriculture then available to support it. The city contributed the largest quota in taxes to the States of Holland which in turn contributed over half the quota to the States General. Amsterdam was also one of the most reliable in settling tax demands and therefore was able to use the threat to withhold such payments to good effect.
Amsterdam was governed by a body of regents, a large, but closed, oligarchy with control over all aspects of the city's life, and a dominant voice in the foreign affairs of Holland. Only men with sufficient wealth and a long enough residence within the city could join the ruling class. The first step for an ambitious and wealthy merchant family was to arrange a marriage with a long-established regent family. In the 1670s one such union, that of the Trip family (the Amsterdam branch of the Swedish arms makers) with the son of Burgomaster Valckenier, extended the influence and patronage available to the latter and strengthened his dominance of the council. The oligarchy in Amsterdam thus gained strength from its breadth and openness. In the smaller towns family interest could unite members on policy decisions but contraction through intermarriage could lead to the degeneration of the quality of the members. In Amsterdam the network was so large that members of the same family could be related to opposing factions and pursue widely separated interests. The young men who had risen to positions of authority in the 1670s and 1680s consolidated their hold on office well into the 1690s and even the new century.
Amsterdam's regents provided good services to residents. They spent heavily on the water-ways and other essential infrastructure, as well as municipal almshouses for the elderly, hospitals and churches.
Amsterdam's wealth was generated by its commerce, which was in turn sustained by the judicious encouragement of entrepreneurs whatever their origin. This open door policy has been interpreted as proof of a tolerant ruling class. But toleration was practiced for the convenience of the city. Therefore the wealthy Sephardic Jews from Portugal were welcomed and accorded all privileges except those of citizenship, but the poor Ashkenazi Jews from Eastern Europe were far more carefully vetted and those who became dependent on the city were encouraged to move on. Similarly, provision for the housing of Huguenot immigrants was made in 1681 when Louis XIV's religious policy was beginning to drive these Protestants out of France; no encouragement was given to the dispossessed Dutch from the countryside or other towns of Holland. The regents encouraged immigrants to build churches and provided sites or buildings for churches and temples for all except the most radical sects and the Catholics by the 1670s (although even the Catholics could practice quietly in a chapel within the Beguinhof).
First Stadtholderless Period and the Anglo-Dutch Wars (1650–1674).
During the wars a tension had arisen between the Orange-Nassau leaders and the patrician merchants. The former—the Orangists—were soldiers and centralizers who seldom spoke of compromise with the enemy and looked for military solutions. They included many rural gentry as well as ordinary folk attached to the banner of the House of Orange. The latter group were the Republicans, led by the Grand Pensionary (a sort of prime minister) and the regents stood for localism, municipal rights, commerce, and peace. In 1650, the stadtholder William II, Prince of Orange suddenly died; his son was a baby and the Orangists were leaderless. The regents seized the opportunity: there would be no new stadtholder in Holland for 22 years. Johan de Witt, a brilliant politician and diplomat, emerged as the dominant figure. Princes of Orange became the stadtholder and an almost hereditary ruler in 1672 and 1748. The Dutch Republic of the United Provinces was a true republic from 1650–1672 and 1702–1748. These periods are called the First Stadtholderless Period and Second Stadtholderless Period.
Anglo-Dutch wars.
The Republic and England were major rivals in world trade and naval power. Halfway through the 17th century the Republic's navy was the rival of Britain's Royal Navy as the most powerful navy in the world. The Republic fought a series of three naval wars against England in 1652-74.
In 1651, England imposed its first Navigation Act, which severely hurt Dutch trade interests. An incident at sea concerning the Act resulted in the First Anglo-Dutch War, which lasted from 1652 to 1654, ending in the Treaty of Westminster (1654), which left the Navigation Act in effect.
After the English Restoration in 1660, Charles II tried to serve his dynastic interests by attempting to make Prince William III of Orange, his nephew, stadtholder of the Republic, using some military pressure. King Charles thought a naval war would weaken the Dutch traders and strengthen the English economy and empire, so the Second Anglo-Dutch War was launched in 1665. At first many Dutch ships were captured and the English scored great victories. However, the Raid on the Medway, in June 1667, ended the war with a Dutch victory. The Dutch recovered their trade, while the English economy was seriously hurt and its treasury nearly bankrupt. The greatly expanded Dutch navy was for years after the world's strongest. The Dutch Republic was at the zenith of its power.
Franco-Dutch War and Third Anglo-Dutch War (1672–1702).
The year 1672 is known in the Netherlands as the "Disaster Year" ("Rampjaar"). England declared war on the Republic, (the Third Anglo-Dutch War), followed by France, Münster and Cologne, which had all signed alliances against the Republic. France, Cologne and Münster invaded the Republic. Johan de Witt and his brother Cornelis, who had accomplished a diplomatic balancing act for a long time, were now the obvious scapegoats. They were lynched, and a new stadtholder, William III, was appointed.
An Anglo-French attempt to land on the Dutch shore were barely repelled in three desperate naval battles under command of Admiral Michiel de Ruyter. The advance of French troops from the south was halted by a costly inundation of its own heartland, by breaching river dykes. With the aid of friendly German princes, the Dutch succeeded in fighting back Cologne and Münster, after which the peace was signed with both of them, although some territory in the east was lost for ever. Peace was signed with England as well, in 1674 (Second Treaty of Westminster). In 1678, peace was made with France at the Treaty of Nijmegen, although France's Spanish and German allies felt betrayed by this.
In 1688, the relations with England reached crisis level once again. Stadtholder William III decided he had to take a huge gamble when he was invited to invade England by Protestant British nobles feuding with William's father-in-law the Catholic James II of England. This led to the Glorious Revolution and cemented the principle of parliamentary rule and Protestant ascendency in England. James fled to France, and William ascended to the English throne as co-monarch with his wife Mary, James' eldest daughter. This manoeuvre secured England as a critical ally of the United Provinces in its ongoing wars with Louis XIV of France. William was the commander of the Dutch and English armies and fleets until his death in 1702. During William's reign as King of England his primary focus was leveraging British manpower and finances to aid the Dutch against the French. The combination continued after his death as the combined Dutch, British, and mercenary army conquered Flanders and Brabant, and invaded French territory before the alliance collapsed in 1713 due to British political infighting.
Second Stadtholderless Period (1702–1747).
The "Second Stadtholderless Period" (Dutch: "Tweede Stadhouderloze Tijdperk") is the designation in Dutch historiography of the period between the death of stadtholder William III on 19 March 1702 and the appointment of William IV, Prince of Orange as stadtholder and captain general in all provinces of the Dutch Republic on 2 May 1747. During this period the office of stadtholder was left vacant in the provinces of Holland, Zeeland, and Utrecht, though in other provinces that office was filled by members of the House of Nassau-Dietz (later called Orange-Nassau) during various periods.
During the period, the Republic lost its Great-Power status and its primacy in world trade, processes that went hand-in-hand, the latter causing the former. Though the economy declined considerably, causing deindustralization and deurbanization in the maritime provinces, a "rentier"-class kept accumulating a large capital fund that formed the basis for the leading position the Republic achieved in the international capital market. A military crisis at the end of the period caused the fall of the States-Party regime and the restoration of the Stadtholderate in all provinces. However, though the new stadtholder acquired near-dictatorial powers, this did not improve the situation.
Economic decline after 1730.
The slow economic decline after 1730 was relative: other countries grew faster, eroding the Dutch lead and surpassing it. Wilson identifies three causes. Holland lost its world dominance in trade as competitors emerged and copied its practices, built their own ships and ports, and traded on their own account directly without going through Dutch intermediaries. Second, there was no growth in manufacturing, due perhaps to a weaker sense of industrial entrepreneurship and to the high wage scale. Third the wealthy turned their investments to foreign loans. This helped jump-start other nations and provided the Dutch with a steady income from collecting interest, but leaving them with few domestic sectors with a potential for rapid growth.
After the Dutch fleet declined, merchant interests became dependent on the goodwill of Britain. The main focus of Dutch leaders was reducing the country's considerable budget deficits. Dutch trade and shipping remained at a fairly steady level through the 18th century, but no longer had a near monopoly and also could not match growing English and French competition. The Netherlands lost its position as the trading centre of Northern Europe to London.
Although the Netherlands remained wealthy, investors for the nation's money became more difficult to find. Some investment went into purchases of land for estates, but most went to foreign bonds and Amsterdam remained one of Europe's banking capitals.
Culture and society.
Dutch culture also declined both in the arts and sciences. Literature for example largely imitated English and French styles with little in the way of innovation or originality. The most influential intellectual was Pierre Bayle (1647-1706), a Protestant refugee from France who settled in Rotterdam where he wrote the massive Dictionnaire Historique et Critique ("Historical and Critical Dictionary", 1696). It had a major impact on the thinking of The Enlightenment across Europe, giving an arsenal of weapons to critics who wanted to attack religion. It was an encyclopaedia of ideas that argued that most "truths" were merely opinions, and that gullibility and stubbornness were prevalent.
Life for the average Dutchman became slower and more relaxed than in the 18th century. The upper and middle classes continued to enjoy prosperity and high living standards. The drive to succeed seemed less urgent. Unskilled laborers remained locked in poverty and hardship. The large underclass of unemployed beggars and riffraff required government and private charity to survive.
Religious life became more relaxed as well. Catholics grew from 18% to 23% of the population during the 18th century and enjoyed greater tolerance, even as they continued to be outside the political system. They became divided by the feud between moralistic Jansenists (who denied free will) and orthodox believers. One group of Jansenists formed a splinter sect, the Old Catholic Church in 1723. The upper classes willingly embraced the ideas of the Enlightenment, tempered by the tolerance that meant less hostility to organized religion compared to France.
The Orangist revolution (1747–1751).
During the term of Anthonie van der Heim as Grand Pensionary from 1737 to 1746, the Republic slowly drifted into the War of Austrian Succession. This started as a Prusso-Austrian conflict, but eventually all the neighbours of the Dutch Republic became involved. On one side were Prussia, France and their allies and on the other Austria, Britain (after 1744) and their allies. At first the Republic strove to remain neutral in this European conflict, but it maintained garrisons in a number of fortresses in the Austrian Netherlands. French grievances and threats spurred the Republic into bring its army up to European standards (84,000 men in 1743).
In 1744 and 1745 the French attacked Dutch fortresses at Menen and Tournai. This prompted the Dutch Republic in 1745 to join the Quadruple Alliance, but this alliance was severely defeated at the Battle of Fontenoy in May 1745. In 1746 the French occupied most of the large cities in the Austrian Netherlands. Then, in April 1747, apparently as an exercise in armed diplomacy, a relatively small French military force occupied Zeelandic Flanders, part of the Dutch Republic.
This relatively innocuous invasion fully exposed the rot underlying the Dutch defences. The consequences were spectacular. Still mindful of the French invasion in the "Disaster Year" of 1672, many fearful people clamored for the restoration of the stadtholderate. William IV, Prince of Orange, had been waiting impatiently in the wings since acquiring his princely title in 1732. Over the next year he and his supporters engaged in a number of political battles in various provinces and towns in the Netherlands to wrest control from the regents. The aim was for William IV to obtain a firm grip on government patronage and place loyal officials in all strategic government positions. Eventually he managed to achieve this aim in all provinces.
Willem Bentinck van Rhoon was a prominent Orangist. People like Bentinck hoped that gathering the reins of power in the hands of a single "eminent head" would soon help restore the state of the Dutch economy and finances. The regents they opposed included the Grand Pensionary Jacob Gilles and Adriaen van der Hoop. This popular revolt had religious, anti-Catholic and democratic overtones and sometimes involved mob violence. It eventually involved political agitation by Daniel Raap, Jean Rousset de Missy and the Doelisten, attacks on tax farmers (pachtersoproer), religious agitation for enforcement of the Sabbath laws and preference for followers of Gisbertus Voetius and various demands by the civil militia.
The war against the French was itself brought to a not-too-devastating end for the Dutch Republic with the Treaty of Aix-la-Chapelle (1748). The French retreated of their own accord from the Dutch frontier. William IV died unexpectedly, at the age of 40, on 22 October 1751.
Regency and indolent rule (1752–1779).
His son, William V, was 3 years old when his father died, and a long regency characterised by corruption and misrule began. His mother delegated most of the powers of the regency to Bentinck and her favorite, Duke Louis Ernest of Brunswick-Lüneburg. All power was concentrated in the hands of an unaccountable few, including the Frisian nobleman Douwe Sirtema van Grovestins. Still a teenager, William V assumed the position of stadtholder in 1766, the last to hold that office. In 1767, he married Princess Wilhelmina of Prussia, the daughter of Augustus William of Prussia, niece of Frederick the Great.
The position of the Dutch during the American War of Independence was one of neutrality. William V, leading the pro-British faction within the government, blocked attempts by pro-independence, and later pro-French, elements to drag the government to war. However, things came to a head with the Dutch attempt to join the Russian-led League of Armed Neutrality, leading to the outbreak of the disastrous Fourth Anglo-Dutch War in 1780. After the signing of the Treaty of Paris (1783), the impoverished nation grew restless under William's rule.
An English historian summed him up uncharitably as "a Prince of the profoundest lethargy and most abysmal stupidity." And yet he would guide his family through the difficult French-Batavian period and his son would be crowned king.
Fourth Anglo-Dutch War (1780–1784).
The Fourth Anglo–Dutch War (1780–1784) was a conflict between the Kingdom of Great Britain and the Dutch Republic. The war, tangentially related to the American Revolutionary War, broke out over British and Dutch disagreements on the legality and conduct of Dutch trade with Britain's enemies in that war.
Although the Dutch Republic did not enter into a formal alliance with the United States and their allies, U.S. ambassador (and future President) John Adams managed to establish diplomatic relations with the Dutch Republic, making it the second European country to diplomatically recognize the Continental Congress in April 1782. In October 1782, a treaty of amity and commerce was concluded as well.
Most of the war consisted of a series of largely successful British operations against Dutch colonial economic interests, although British and Dutch naval forces also met once off the Dutch coast. The war ended disastrously for the Dutch and exposed the weakness of the political and economic foundations of the country. The Treaty of Paris (1784), according to Fernand Braudel, "sounded the knell of Dutch greatness."
The French-Batavian period (1785–1815).
After the war with Great Britain ended disastrously in 1784, there was growing unrest and a rebellion by the anti-Orangist Patriots. The French Revolution resulted first in the establishment of a pro-French Batavian Republic (1795–1806), then the creation of the Kingdom of Holland, ruled by a member of the House of Bonaparte (1806–1810), and finally annexation by the French Empire (1810–1813).
Patriot rebellion and its suppression (1785–1795).
Influenced by the American Revolution, the Patriots sought a more democratic form of government. The opening shot of this revolution was the 1781 publication of a manifesto called "Aan het Volk van Nederland" ("To the People of the Netherlands") by Joan van der Capellen tot den Pol, the founder of the Patriots. The aim of the Patriots was to reduce corruption and the power held by the stadtholder, William V, Prince of Orange.
Support for the Patriots came mostly from the middle class. They formed a militia called the "Free Corps". In 1785 there was an open rebellion by the Patriots, which took the form of an armed insurrection by local militias in certain Dutch towns, "Vrijheid" being the rallying cry. Herman Willem Daendels attempted to organise an overthrow of various municipal governments (vroedschap). The goal was to oust government officials and force new elections. "Seen as a whole this revolution was a string of violent and confused events, accidents, speeches, rumours, bitter enmities and armed confrontations", wrote French historian Fernand Braudel, who saw it as a forerunner of the French Revolution.
In 1785 the stadholder left The Hague and moved his court to Guelders, a province remote from the heart of Dutch political life. In June 1787 his energetic wife Wilhelmina (the sister of Frederick William II of Prussia) tried to travel to The Hague. Outside Schoonhoven, she was stopped by militiamen and taken to a farm near Goejanverwellesluis. Within two days she was forced to return to Nijmegen, an insult not unnoticed in Prussia.
The House of Orange reacted with severity, relying on Prussian troops led by Charles William Ferdinand, Duke of Brunswick and a small contingent of British troops to suppress the rebellion. Dutch banks at this time still held much of the world's capital. Government-sponsored banks owned up to 40% of Great Britain's national debt and there were close connections to the House of Stuart. The stadholder had supported British policies after the American Revolution.
This severe military response overwhelmed the Patriots and put the stadholder firmly back in control. A small unpaid Prussian army was billeted in the Netherlands and supported themselves by looting and extortion. The Free Corps continued urging citizens to resist the government. They distributed pamphlets, formed "Patriot Clubs" and held public demonstrations. The government responded by pillaging those towns where opposition continued. Five leaders were sentenced to death (but fled first). Lynchings also occurred. For a while, no one dared appear in public without an orange cockade to show their support for Orangism. Many Patriots, perhaps around 40,000 in all, fled to Brabant, France (especially Dunkirk and St. Omer) and elsewhere. However, before long the French became involved in Dutch politics and the tide turned.
Batavian Republic (1795–1806).
The French Revolution was popular, and numerous underground clubs were promoting it when in January 1795 a French army invaded. The underground rose up, overthrew the municipal and provincial governments, and proclaimed the Batavian Republic (Dutch: "Bataafse Republiek"). The stadholder William V fled to England and the estates general dissolved itself. The new government was virtually a puppet of France. The Batavian Republic enjoyed widespread support and sent soldiers to fight in the French armies. Nevertheless Napoleon replaced it because the regime of Grand Pensionary Rutger Jan Schimmelpenninck (1805-6) was insufficiently docile.
The confederal structure of the old Dutch Republic was permanently replaced by a unitary state. The 1798 constitution had a genuinely democratic character, though a coup d'état of 1801 put an authoritarian regime in power. Ministerial government was introduced for the first time in Dutch history and many of the current government departments date their history back to this period. Meanwhile the exiled stadholder handed over the Dutch colonies in "safekeeping" to Great Britain and ordered the colonial governors to comply. This permanently ended the colonial empire in Guyana, Ceylon and the Cape Colony. The Dutch East Indies was returned to the Netherlands under the Anglo-Dutch Treaty of 1814.
Kingdom of Holland to William I (1806–1815).
In 1806 Napoleon restyled the Netherlands (along with a small part of what is now Germany) into the Kingdom of Holland, putting his brother Louis Bonaparte (1778–1846), on the throne. The new king was unpopular, but he was willing to cross his brother for the benefit of his new kingdom. Napoleon forced his abdication in 1810 and incorporated the Netherlands directly into the French empire, imposing economic controls and conscription of all young men as soldiers. When the French retreated from the northern provinces in 1813, a Triumvirate took over at the helm of a provisional government. Although most members of the provisional government had been among the men who had driven out William V 18 years earlier, the leaders of the provisional government knew that any new regime would have to be headed by his son, William Frederick. They also knew that it would be better in the long term if the Dutch people themselves installed the prince, rather than have him imposed on the country by the anti-French alliance. Accordingly, the Triumvirate called William Frederick back on November 30 and offered him the crown. He refused, but instead proclaimed himself "hereditary sovereign prince" on December 6.
The Great Powers had secretly agreed to merge the northern Netherlands with the more populated Austrian Netherlands and the smaller Prince-Bishopric of Liège into a single constitutional monarchy. Having a stronger country on France's northern border was considered (especially by Tsar Alexander) to be an important part of the strategy to keep France's power in check. In 1814, William Frederick gained sovereignty over the Austrian Netherlands and Liège as well. On March 15, 1815; with the encouragement of the powers gathered at the Congress of Vienna, William Frederick raised the Netherlands to the status of a kingdom and proclaimed himself King William I. This was made official later in 1815, when the Low Countries were formally recognized as the United Kingdom of the Netherlands, with the House of Orange-Nassau as hereditary rulers. William had thus fulfilled the nearly three-century quest of the House of Orange to unite the Low Countries under a single rule.
United Kingdom of the Netherlands (1815–1839).
William I was crowned king and also became the hereditary Grand Duke of Luxembourg. The newly created country had two capitals: Amsterdam and Brussels. The new nation had two equal parts. The north (the Netherlands proper) had 2 million people. They spoke chiefly Dutch but were divided religiously between a Protestant majority and a large Catholic minority. The south (which would be known as "Belgium" after 1830) had a population of 3.4 million people. Nearly all were Catholic, but it was divided between French-speaking Walloons and Dutch-speaking Flemings. The upper and middle classes in the south were mostly French-speaking. About 60,000 Belgians were eligible to vote, compared to about 80,000 Dutchmen. Officially Amsterdam was the capital, but in a compromise the government met alternately in Brussels and The Hague.
Adolphe Quetelet (1796-1874), the great Belgian statistician, calculated that the new nation was significantly better off than other states. Mortality was low, the food supply was good, education was good, public awareness was high and the charity rate was the highest in the world. The best years were in the mid-1820s.
The quality of schooling was dismal, however. According to Schama, about 1800 the local school teacher was the "humble auxiliary of the local priest. Despised by his co-villagers and forced to subsist on the gleanings of the peasants, he combined drumming the catechism into the heads of his unruly charges with the duties of winding the town clock, ringing the church bells or digging its graves. His principal use to the community was to keep its boys out of mischief when there was no labour for them in the fields, or setting the destitute orphans of the town to the 'useful arts' of picking tow or spinning crude flax. As one would expect, standards in such an occupation were dismal." But in 1806 the Dutch, led by Adriaan van den Ende, energetically set out to modernise education, focusing on a new system for advanced training of teachers with an elaborate system of inspectors, training courses, teacher examinations and teaching societies. By 1826, although much smaller than France, the Dutch national government was spending 12 times more than Paris on education.
Constitutional monarchy.
William I, who reigned from 1815–1840, had great constitutional power. An enlightened despot, he accepted the modernizing transformations of the previous 25 years, including equality of all before the law. However, he resurrected the estates as a political class and elevated a large number of people to the nobility. Voting rights were still limited, and only the nobility were eligible for seats in the upper house. The old provinces were reestablished in name only. The government was now fundamentally unitary, and all authority flowed from the center.
William I was a Calvinist and unsympathetic to the religious culture and practices of the Catholic majority. He promulgated the "Fundamental Law of Holland", with some modifications. This entirely overthrew the old order of things in the southern Netherlands: it abolished the privileges of the Catholic Church, and guaranteed equal protection to every religious creed and the enjoyment of the same civil and political rights to every subject of the king. It reflected the spirit of the French Revolution and in so doing did not please the Catholic bishops in the south, who had detested the Revolution.
William I actively promoted economic modernization. The first 15 years of the Kingdom showed progress and prosperity, as industrialization proceeded rapidly in the south, where the Industrial Revolution allowed entrepreneurs and labor to combine in a new textile industry, powered by local coal mines. There was little industry in the northern provinces, but most overseas colonies were restored, and highly profitable trade resumed after a 25-year hiatus. Economic liberalism combined with moderate monarchical authoritarianism to accelerate the adaptation of the Netherlands to the new conditions of the 19th century. The country prospered until a crisis arose in relations with the southern provinces.
Belgium breaks away.
William was determined to create a united people, even though the north and south had drifted far apart in the past three centuries. Protestants were the largest denomination in the North (population 2 million), but formed a quarter of the population in the overwhelmingly Catholic South (population 3.5 million). Nevertheless, Protestants dominated William's government and army. The Catholics did not consider themselves an integral part of the United Netherlands, preferring instead to identify with mediaeval Dutch culture. Other factors that contributed to this feeling were economic (the South was industrialising, the North had always been a merchants' nation) and linguistic (French was spoken in Wallonia and a large part of the bourgeoisie in Flemish cities).
After having been dominant for a long time, the French-speaking elite in the Southern Netherlands now felt like second-class citizens.
In the Catholic South, William's policies were unpopular. The French-speaking Walloons strenuously rejected his attempt to make Dutch the universal language of government, while the population of Flanders was divided. Flemings in the south spoke a Dutch dialect ("Flemish") and welcomed the encouragement of Dutch with a revival of literature and popular culture. Other Flemings, notably the educated bourgeoisie, preferred to speak French. Although Catholics possessed legal equality, they resented their subordination to a government that was fundamentally Protestant in spirit and membership after having been the state church for centuries in the south. Few Catholics held high office in state or army. Furthermore, political liberals in the south complained about the king's authoritarian methods. All southerners complained of underrepresentation in the national legislature. Although the south was industrializing and was more prosperous than the north the accumulated grievances allowed the multiple opposition forces to coalesce. The outbreak of revolution in France in 1830 was a signal for action, at first on behalf of autonomy for Belgium, as the southern provinces were now called, and later on behalf of total independence. William dithered and his half-hearted efforts to reconquer Belgium were thwarted both by the efforts of the Belgians themselves and by the diplomatic opposition of the great powers.
At the London Conference of 1830, the chief powers of Europe ordered (in November 1830) an armistice between the Dutch and the Belgians. The first draft for a treaty of separation of Belgium and the Netherlands was rejected by the Belgians. A second draft (June 1831) was rejected by William I, who resumed hostilities. Franco-British intervention forced William to withdraw Dutch forces from Belgium late in 1831, and in 1833 an armistice of indefinite duration was concluded. Belgium was effectively independent but William’s attempts to recover Luxembourg and Limburg led to renewed tension. The London Conference of 1838–39 prepared the final Dutch-Belgian separation treaty of 1839. It divided Luxembourg and Limburg between the Dutch and Belgian crowns. The Kingdom of the Netherlands thereafter was made up of the 11 northern provinces.
Democratic and Industrial Development (1840–1900).
The Netherlands did not industrialize as rapidly as Belgium after 1830, but it was prosperous enough. Griffiths argues that certain government policies facilitated the emergence of a national economy in the 19th century. They included the abolition of internal tariffs and guilds; the a unified coinage system, modern methods of tax collection; standardized weights and measures; and the building of many roads, canals, and railroads. However, compared to Belgium, which was leading in industrialization on the Continent, the Netherlands moved slowly. Possible explanations for this difference are the higher costs due to geography and high wages, and the emphasis of entrepreneurs on trade rather than industry. However, the provinces of North Brabant and Overijssel did industrialize, and they became the most economically advanced areas of the country.
As in the rest of Europe, the 19th century saw the gradual transformation of the Netherlands into a modern middle-class industrial society. The number of people employed in agriculture decreased, while the country made a strong effort to revive its stake in the highly competitive shipping and trade business. The Netherlands lagged behind Belgium until the late 19th century in industrialization, and caught up around 1920. Major industries included textiles and (later) the great Philips industrial conglomerate. Rotterdam became a major shipping and manufacturing center. Poverty slowly declined as begging largely disappeared along with steadily improving working conditions for the population.
1848 Constitutional reform and liberalism.
In 1840 William I abdicated in favor of his son, William II, who attempted to carry on the policies of his father in the face of a powerful liberal movement. In 1848 unrest broke out all over Europe. Although there were no major events in the Netherlands, these foreign developments persuaded King William II to agree to liberal and democratic reform. That same year Johan Rudolf Thorbecke, a prominent liberal, was asked by the king to draft a constitution that would turn the Netherlands into a constitutional monarchy. The new constitution was proclaimed on 3 November 1848. It severely limited the king's powers (making the government accountable only to an elected parliament), and it protected civil liberties. The new liberal constitution, which put the government under the control of the States General, was accepted by the legislature in 1848. The relationship between monarch, government and parliament has remained essentially unchanged ever since.
William II was succeeded by William III in 1849. The new king reluctantly chose Thorbecke to head the new government, which introduced several liberal measures, notably the extension of suffrage. However, Thorbecke's government soon fell, when Protestants rioted against the Vatican's reestablishment of the Catholic episcopate, in abeyance since the 16th century. A conservative government was formed, but it did not undo the liberal measures, and the Catholics were finally given equality after two centuries of subordination. Dutch political history from the middle of the 19th century until the First World War was fundamentally one of the extension of liberal reforms in government, the reorganization and modernization of the Dutch economy, and the rise of trade unionism and socialism as working-class movements independent of traditional liberalism. The growth in prosperity was enormous, as real per capita GNP soared from 106 guilders in 1804 to 403 in 1913.
Religion and pillarisation.
Religion was a contentious issue with repeated struggles over the relations of church and state in the field of education. In 1816, the government took full control of the Dutch Reformed Church ("Nederlands Hervormde Kerk"). In 1857, all religious instruction was ended in public schools, but the various churches set up their own schools, and even universities. Dissident members broke away from the Netherlands Reformed Church in the Secession of 1834. They were harassed by the government under an onerous Napoleonic law prohibiting gatherings of more than 20 members without a permit. After the harassment ended in the 1850s, a number of these dissidents eventually created the Christian Reformed Church in 1869; thousands migrated to Michigan, Illinois, and Iowa in the United States. By 1900 the dissidents represented about 10% of the population, as against 45% in the Netherlands Reformed Church, which continued to be the only church to receive state money.
At mid-century, most Dutch belonged either to the Dutch Reformed churches (around 55%) or the Roman Catholic church (35 to 40%), together with smaller Protestant and Jewish groups. A large and powerful sector of nominal Protestants were in fact secular liberals seeking to minimize religious influence. In reaction a novel alliance developed with Catholics and devout Calvinists joining against secular liberals. The Catholics, who had been loosely allied with the liberals in earlier decades, turned against them on the issue of state support, which the liberals insisted should be granted only to public schools, and joined with Protestant political parties in demanding equal state support to schools maintained by religious groups.
The Netherlands remained one of the most tolerant countries in Europe towards religious belief, although conservative Protestants objected to the liberalization of the Dutch Reformed Church during the 19th century and faced opposition from the government when they tried to establish separate communities (Catholics and other non-Protestants were left unmolested by Dutch authorities). Some moved to the United States as a consequence, but as the century drew to a close, religious persecution had totally ceased.
Dutch social and political life became divided by fairly clear-cut internal borders that were emerging as the society pillarized into three separate parts based on religion. The economy was not affected. One of the people most responsible for designing pillarization was Abraham Kuyper (1837-1920), a leading politician, Protestant theologian, and journalist. Kuyper established orthodox Calvinist organizations, and also provided a theoretical framework by developing such concepts as "sphere-sovereignty" that celebrated Dutch society as a society of organized minorities. "Verzuiling" ("pillarization" or "pluralism") after 1850 became the solution to the danger of internal conflict. Everyone was part of one (and only one) pillar ("zuil") based chiefly on religion (Protestant, Catholic, secular). The secular pillar eventually split into a socialist/working class pillar and a liberal (pro-business) secular pillar. Each pillar built a full set of its own social organizations, including churches (for the religious pillars), political parties, schools, universities, labor unions, sport clubs, boy scout unions and other youth clubs, and newspapers. The members of different "zuilen" lived in close proximity in cities and villages, spoke the same language, and did business with one another, but seldom interacted informally and rarely intermarried. In politics Kuyper formed the Anti-Revolutionary Party (ARP) in 1879, and headed it until 1905.
Pillarization was officially recognized in the Pacification of 1917, whereby socialists and liberals achieved their goal of universal male suffrage and the religious parties were guaranteed equal funding of all schools. In 1930 radio was organized so that each pillar had full control of its own network. When television began in the late 1940s the pillars divided up time equally on the one station. In politics and civic affairs leaders of the pillar organizations cooperated and the acknowledged the right of the other pillars, so public life generally ran smoothly.
Flourishing of art, culture and science.
The late 19th century saw a cultural revival. The Hague School brought a revival of realist painting, 1860-1890. The world famous Dutch painter was Vincent van Gogh, but he spent most of his career in France. Literature, music, architecture and science also flourished. A representative leader of science was Johannes Diderik van der Waals (1837-1923), a working class youth who taught himself physics, earned a PhD at the nation's leading school Leiden University, and in 1910 won the Nobel Prize for his discoveries in thermodynamics. Hendrik Lorentz (1853-1928) and his student Pieter Zeeman (1865-1943) shared the 1902 Nobel Prize in physics. Other notable scientists included biologist Hugo de Vries (1848-1935), who rediscovered Mendelian genetics.
1900 to 1940.
In 1890, William III died after a long reign and was succeeded by his young daughter, Queen Wilhelmina (1880-1962). She would rule the Netherlands for 58 years. On her accession to the throne, the personal union between the Netherlands and Luxembourg ended because Luxembourg law excluded women from rule. Her remote cousin Adolphe became the Grand Duke of Luxembourg.
This was a time of further growth and colonial development, but it was marked by the difficulties of the Great War (in which the Netherlands was neutral) 
and the Great Depression. The Dutch population grew rapidly in the 20th century, as death rates fell, more lands were opened up, and industrialisation created urban jobs. Between 1900 and 1950 the population doubled from 5.1 to 10 million people.
Colonial focus.
The Dutch empire comprised the Dutch East Indies (Indonesia), as well as Surinam in South America and some minor possessions. It was smaller in 1945 than in 1815 because the Netherlands was the only colonial power that did not expand into Africa or anywhere else. The empire was run from Batavia (in Java), where the governor and his technical experts had almost complete authority with little oversight from the Hague. Successive governors improved their bureaucratic and military controls, and allowed very little voice to the locals until the 1920s.
The colony brought economic opportunity to the mother country and there was little concern at the time about it. One exception came in 1860 when Eduard Dekker, under the pen name "Multatuli" wrote the novel "", one of the most notable books in the history of Dutch literature. He criticized the exploitation of the colony, and as well had harsh words about the indigenous princes who collaborated with the governor. The book helped inspire the Indonesian independence movement in the mid-20th century as well as the "Fair Trade" movement for coffee at the end of the century.
The military forces in the Dutch East Indies were controlled by the governor and were not part of the regular Dutch army. As the map shows, the Dutch slowly expanded their holdings from their base in Java to include all of modern Indonesia by 1920. Most islands were not a problem but there was a long, costly campaign against the Achin (Aceh) state in northern Sumatra.
The Netherlands had not fought a major military campaign since the 1760s, and the strength of its armed forces had gradually dwindled. The Dutch decided not to ally themselves with anyone, and kept out of all European wars especially the First World War that swirled about it.
Neutrality during the First World War.
The German war plan (the Schlieffen Plan) of 1905 was modified in 1908 to invade Belgium on the way to Paris but not the Netherlands. It supplied many essential raw materials to Germany such as rubber, tin, quinine, oil and food. The British used its blockade to limit supplies that the Dutch could pass on. There were other factors that made it expedient for both the Allies and the Central Powers for the Netherlands to remain neutral. The Netherlands controlled the mouths of the Scheldt, the Rhine and the Meuse Rivers. Germany had an interest in the Rhine since it ran through the industrial areas of the Ruhr and connected it with the Dutch port of Rotterdam. Britain had an interest in the Scheldt River and the Meuse flowed from France. All countries had an interest in keeping the others out of the Netherlands so that no one's interests could be taken away or be changed. If one country were to have invaded the Netherlands, another would certainly have counterattacked to defend their own interest in the rivers. It was too big a risk for any of the belligerent nations and none wanted to risk fighting on another front.
The Dutch were affected by the war, troops were mobilized and conscription was introduced in the face of harsh criticism from opposition parties. In 1918, mutinies broke out in the military. Food shortages were extensive, due to the control the belligerents exercised over the Dutch. Each wanted their share of Dutch produce. As a result, the price of potatoes rose sharply because Britain had demanded so much from the Dutch. Food riots even broke out in the country. A big problem was smuggling. When Germany had conquered Belgium, the Allies saw it as enemy territory and stopped exporting to Belgium. Food became scarce for the Belgian people, since the Germans seized all food. This gave the Dutch the opportunity to start to smuggle. This, however, caused great problems in the Netherlands, including inflation and further food shortages. The Allies demanded that the Dutch stop the smuggling, and the government took measures to remain neutral. The government placed many cities under 'state of siege'. On 8 January 1916, a 5 km zone was created by the government along the border. In that zone, goods could be moved on main roads with a permit. German authorities in Belgium had an electrified fence erected all along the Belgian–Dutch border that caused many refugees from Belgium to lose their lives. The fence was guarded by older German Landsturm soldiers.
Interwar period.
Although both houses of the Dutch parliament were elected by the people, only men with high incomes were eligible to vote until 1917, when pressure from socialist movements resulted in elections in which all men were allowed to vote. In 1919 women also obtained the right to vote.
The worldwide Great Depression of 1929 and the early 1930s had crippling effects on the Dutch economy, lasting longer than in most other European countries. The long duration of the Great Depression in the Netherlands is often explained by the very strict fiscal policy of the Dutch government at the time, and its decision to adhere to the Gold Standard for much longer than most of its trading partners. The depression led to high unemployment and widespread poverty, as well as increasing social unrest.
The rise of Nazism in Germany did not go unnoticed in the Netherlands, and there was growing concern at the possibility of armed conflict, but most Dutch citizens expected that Germany would again respect Dutch neutrality.
There were separate fascist and nazi movements in the 1930s. Dutch Fascists admired Mussolini's Italy and called for a traditional corporate ideology. The membership was small, elitist and ineffective. The pro-Nazi movement, however, won support from Berlin and attempted to build a mass base by 1935. It failed because most Dutch rejected its racial ideology and calls for violence.
The defense budget was not increased until Nazi Germany remilitarized the Rhineland in 1936. The budget was further increased in 1938 (after the annexation of Austria and occupation of the Czech Sudetenland). The colonial government also increased its military budget because of increasing tension with Japan. The Dutch did not mobilize their forces until shortly before France and Great Britain declared war in September, 1939. Neutrality was still the policy but the Dutch government tried to buy new arms for their badly equipped forces but a considerable share of ordered weapons never arrived.
The Second World War (1939–1945).
Nazi invasion and occupation.
At the outbreak of World War II in 1939, the Netherlands once again declared its neutrality. However, on 10 May 1940, Nazi Germany launched an attack on the Netherlands and Belgium and quickly overran most of the two countries. Fighting against the Dutch army proved more of a burden than foreseen; the northern attack was stopped dead, the one in the middle came to a grinding halt near the Grebbeberg and many airborne assault troops were killed and taken prisoner in the west of the country.
Only in the south, defenses broke but the one passage over the river Maas at Rotterdam was held by the Dutch. By 14 May, fighting in many locations had ceased and the German army could make little or no headway, So the Luftwaffe bombed Rotterdam, second largest city of the Netherlands, killing about 900 people, destroying the inner city and leaving 78,000 people homeless.
Following the bombing and German threats of the same treatment for Utrecht, the Netherlands capitulated on 15 May, except for the province of Zeeland where French and French Moroccan troops stood side by side with the Dutch forces. Still, the royal family and some armed forces fled to the United Kingdom. Some members of the royal family eventually moved to Ottawa, Canada until the Netherlands was liberated; Princess Margriet was born in Canadian exile.
Resentment of the Germans grew as the occupation became more harsh, prompting many Dutch in the latter years of the war to join the resistance. But collaboration was not uncommon either; many thousands of young Dutch males volunteered for combat service on the Russian Front with the Waffen-SS and many companies worked for the Germans.
Holocaust in the Netherlands.
About 140,000 Jews lived in the Netherlands at the beginning of the war. Persecution of Dutch Jews started shortly after the occupation. At the end of the war, 40,000 Jews were still alive. Of the 100,000 Jews who did not go in to hiding, about 1,000 survived the war.
One who perished was Anne Frank, who gained worldwide fame posthumously when her diary, written in the "achterhuis" ('backhouse') while hiding from the Nazis, was found and published by her father, Otto Frank, the only survivor of the family.
The war in the Dutch East Indies.
On 8 December 1941, the day after the attack on Pearl Harbor, the Netherlands declared war on Japan. The Dutch government in exile in London had for long been working with London and with Washington to cut off oil supplies to Japan. Japanese forces invaded the Dutch East Indies on 11 January 1942. The Dutch surrendered 8 March after Japanese troops landed on Java. Dutch citizens and everybody with Dutch ancestry, the so-called "Indo's" were captured and put to work in labour camps or interned. As in the homeland, many Dutch ships, planes and military personnel managed to reach safe territory, in this case Australia, from where they were able to fight again.
False hopes, the Hunger Winter and Liberation.
In Europe, after the Allies landed in Normandy in June 1944, progress was slow until the Battle of Normandy ended in August 1944. German resistance collapsed in western Europe and the allied armies advanced quickly towards the Dutch border. The First Canadian Army and the Second British Army conducted operations on Dutch soil from September onwards. On 17 September a daring operation, Operation Market Garden, was executed with the goal of capturing bridges across three major rivers in the southern Netherlands. Despite desperate fighting by American, British and Polish forces, the bridge at Arnhem, across the Neder Rijn, could not be captured.
Areas south of the Rhine river were liberated in the period September–December 1944, including the province of Zeeland, which was liberated in October and November in the Battle of the Scheldt. This opened Antwerp to allied shipping. The First Canadian Army held a static line along the river Meuse (Maas) from December 1944 through February 1945.
The rest of the country remained occupied until the spring of 1945. In the face of Dutch defiance the Nazis deliberately cut off food supplies resulting in near-starvation in the cities during the "Hongerwinter" (Hunger winter) of 1944–45. Soup kitchens were set up but many fragile people died. A few days before the Allied victory the Germans allowed emergency shipments of food.
The First Canadian Army launched Operation Veritable in early February, cracking the Siegfried Line and reaching the banks of the Rhine in early March. In the final weeks of the war in Europe, the First Canadian Army was charged with clearing the Netherlands of German forces.
The Liberation of Arnhem began on 12 April 1945 and proceeded to plan, as the three infantry brigades of the 49th Division leapfrogged each other through the city. Within four days Arnhem, now a ruined city, was totally under Allied control.
The Canadians then immediately advanced further into the country, encountering and defeating a German counterattack at Otterlo and Dutch SS resistance at Ede. On 27 April a temporary truce came into effect, allowing the distribution of food aid to the starving Dutch civilians in areas under German control (Operation Manna). On 5 May 1945, Generaloberst Blaskowitz agreed to the unconditional surrender of all German forces in the Netherlands, signing the surrender to Canadian general Charles Foulkes at Wageningen. (The fifth of May is now celebrated annually in the Netherlands as Liberation Day.) Three days later Germany unconditionally surrendered, bringing the war in Europe to a close.
After the euphoria and settling of scores had ended, the Dutch were a traumatized people with a ruined economy, a shattered infrastructure and several destroyed cities including Rotterdam, Nijmegen, Arnhem and part of The Hague.
Post-war events.
After the war, there were reprisals against those who had collaborated with the Nazis. Artur Seyss-Inquart, Nazi Commissioner of the Netherlands, was tried at Nüremberg.
In the early post-war years the Netherlands made continued attempts to expand its territory by annexing neighbouring German territory. The larger annexation plans were continuously rejected by the United States, but the London conference of 1949 permitted the Netherlands to perform a smaller scale annexation. Most of the annexed territory was returned to Germany on 1 August 1963.
Operation Black Tulip was a plan in 1945 by Dutch minister of Justice Kolfschoten to evict all Germans from the Netherlands. The operation lasted from 1946 to 1948 and in the end 3691 Germans (15% of Germans resident in the Netherlands) were deported. The operation started on 10 September 1946 in Amsterdam, where Germans and their families were taken from their homes in the middle of the night and given one hour to collect 50 kg of luggage. They were allowed to take 100 guilders. The rest of their possessions went to the state. They were taken to concentration camps near the German border, the biggest of which was Mariënbosch near Nijmegen.
Prosperity and European Unity (1945-present).
The post-war years were a time of hardship, shortages and natural disaster. This was followed by large-scale public works programmes, economic recovery, European integration and the gradual introduction of a welfare state.
Immediately after the war, there was rationing, including of cigarettes, textiles, washing powder and coffee. Even wooden shoes were rationed. There were severe housing shortages. In the 1950s, there was mass emigration, especially to Canada, Australia and New Zealand. Government-encouraged emigration efforts to reduce population density prompted some 500,000 Dutch people to leave the country after the war. The Netherlands failed to hold the Dutch East Indies, as Indonesia became independent and 300,000 Dutch inhabitants (and their Indonesian allies) left the islands.
Postwar politics saw shifting coalition governments. The 1946 Parliamentary elections saw the Catholic People's Party (KVP) come in first just ahead of the socialist Labour party (PvdA). Louis J. M. Beel formed a new coalition cabinet. The United States began Marshall Plan aid in 1948 that pumped cash into the economy, fostered modernization of business, and encouraged economic cooperation. The 1948 elections led to a new coalition led by Labor's Willem Drees. He led four successive cabinets Drees I, Drees II, Drees III and Drees IV until late 1958. His terms saw four major political developments: the traumas of decolonization, economic reconstruction, the establishment of the Dutch welfare state, and international integration and co-operation, including the formation of Benelux, the OEEC, NATO, the ECSC, and the EEC.
Baby boom and economic reconstruction.
Despite the problems, this was a time of optimism for many. A baby boom followed the war, as young Dutch couples started planning their families. They had lived through the hardships of depression and the hell of war. They wanted to start fresh and live better lives without the poverty, starvation, terror, and extreme frugality they knew so well. They had little taste for a strictly imposed rule-oriented traditional system with its rigid hierarchies, sharp pillarized boundaries and strictly orthodox religious doctrines. They made a best seller out of the translation of "The Common Sense Book of Baby and Child Care" (1946), by American pediatrician Benjamin Spock. His vision of family life as companionate, permissive, enjoyable and even fun took hold, and seemed the best way to achieve family happiness in a dawning age of freedom and prosperity.
Wages were kept low and the recovery of consumption to prewar levels was delayed to permit rapid rebuilding of the infrastructure. In the years after the war, unemployment fell and the economy grew at an astonishing pace, despite the high birth rate. The shattered infrastructure and destroyed cities were rebuilt. A key contribution to the recovery in the postwar Netherlands came from the Marshall Plan, which provided the country with funds, goods, raw materials and produce.
The Dutch became internationally active again. Dutch corporations, particularly Royal Dutch Shell and Philips, became internationally prominent. Business people, scientists, engineers and artists from the Netherlands made important international contributions. For example, Dutch economists, especially Jan Tinbergen (1903–1994), Tjalling Koopmans (1910–1985) and Henri Theil (1924-2000), made major contributions to the mathematical and statistical methodology known as econometrics.
Across Western Europe, the period from 1973 to 1981 marked the end of the booming economy of the 1960s. The Netherlands also experienced years of negative growth after that. Unemployment increased steadily, causing rapid growth in social-security expenditures. Inflation reached double digits; government surpluses disappeared. On the positive side, rich natural gas resources were developed, providing a current account trade surplus during most of the period. Public deficits were high. According to the long-term economic analysis of Horlings and Smits, the major gains in the Dutch economy were concentrated between 1870 and 1930 and between 1950 and 1970. Rates were much lower in 1930-45 and after 1987.
Flood control.
The last major flood in the Netherlands took place in early February 1953, when a huge storm caused the collapse of several dikes in the southwest of the Netherlands. More than 1,800 people drowned in the ensuing inundation.
The Dutch government subsequently decided on a large-scale programme of public works (the "Delta Works") to protect the country against future flooding. The project took more than thirty years to complete. The Oosterscheldedam, an advanced sea storm barrier, became operational in 1986. According to Dutch government engineers, the odds of a major inundation anywhere in the Netherlands are now one in 10,000 years.
Europeanisation, Americanisation and internationalisation.
The European Coal and Steel Community (ECSC), was founded in 1951 by the six founding members: Belgium, the Netherlands and Luxembourg (the Benelux countries) and West Germany, France and Italy. Its purpose was to pool the steel and coal resources of the member states, and to support the economies of the participating countries. As a side effect, the ECSC helped defuse tensions between countries which had recently been enemies in the war. In time, this economic merger grew, adding members and broadening in scope, to become the European Economic Community, and later the European Union.
The United States started to have more influence. After the war higher education changed from a German model to more of an American model. American influences had been small in the interwar era, and during the war the Nazis had emphasised the dangers of a "degraded" American culture as represented by jazz. However, the Dutch became more attracted to the United States during the postwar era, perhaps partly because of antipathy towards the Nazis but certainly because of American movies and consumer goods. The Marshall Plan also introduced the Dutch to American management practices. NATO brought in American military doctrine and technology. Intellectuals, artists and the political left, however, remained more reserved about the Americans. According to Rob Kroes, the anti-Americanism in the Netherlands was ambiguous: American culture was both accepted and criticised at the same time.
The Netherlands is a founding member of the EU, NATO, OECD and WTO. Together with Belgium and Luxembourg it forms the Benelux economic union. The country is host to the Organization for the Prohibition of Chemical Weapons and five international courts: the Permanent Court of Arbitration, the International Court of Justice, the International Criminal Tribunal for the Former Yugoslavia, the International Criminal Court and the Special Tribunal for Lebanon. The first four are situated in The Hague, as is the EU's criminal intelligence agency Europol and judicial co-operation agency Eurojust. This has led to the city being dubbed "the world's legal capital".
Decolonisation and multiculturalism.
By the first half of the 20th century, new organisations and leadership had developed in the Dutch East Indies. Under its Ethical Policy, the government had helped create an educated Indonesian elite. These profound changes constituted the "Indonesian National Revival". Increased political activism and Japanese occupation undermining Dutch rule culminated in nationalists proclaiming independence on 17 August 1945, two days after the surrender of Japan.
The Dutch East Indies had long been a valuable resource to the Netherlands, so the Dutch feared its independence. The Indonesian National Revolution followed as Indonesia attempted to secure its independence in the face of Dutch diplomatic and military opposition (sometimes brutal in nature). Increasing international pressure eventually led the Netherlands to withdraw and it formally recognised Indonesian independence on 27 December 1949. The western part of New Guinea, remained under Dutch control as Netherlands New Guinea until 1961, when the Netherlands transferred sovereignty of this area to Indonesia.
During and after the Indonesian National Revolution, around 300,000 people, pre-dominantly "Indos" (Dutch-Indonesian Eurasians), left Indonesia for the Netherlands. This difficult, complex and messy mass migration was called repatriation, but the majority of this group had never set foot in the Netherlands before. This migration occurred in five distinct waves over a period of 20 years. It included Indos (many of whom spent the war years in Japanese concentration camps), former South Moluccan soldiers and their families, "New-Guinea Issue" Dutch citizens, Dutch citizens from Netherlands New Guinea (including Papuan civil servants and their families), and other Indos who had remained behind but later regretted their decision to take out Indonesian citizenship (called "spijtoptanten" in Dutch and "warga negara" in Indonesian).
The Indo community (now numbering around 680,000) is the largest minority group in the Netherlands. They are integrated into Dutch society, but they have also retained many aspects of their culture and have added a distinct Indonesian flavour to the Netherlands.
Although it was originally expected that the loss of the Dutch East Indies would contribute to an economic decline, the Dutch economy experienced exceptional growth (partly because a disproportionate amount of Marshall Aid was received) in the 1950s and 1960s. In fact, the demand for labour was so strong that immigration was actively encouraged, first from Italy and Spain then later on, in larger numbers, from Turkey and Morocco.
Suriname became independent on 25 November 1975. The Dutch government supported independence because it wanted to stem the flow of immigrants from Suriname and also to end its colonial status. However, about one third of the entire population of Suriname, fearing political unrest and economic decline, relocated to the Netherlands, creating a Surinamese community in the Netherlands that is now roughly as large as the population of Suriname itself.
Liberalisation.
When the postwar baby-boom children grew up, they led the revolt in the 1960s against all rigidities in Dutch life. The 1960s and 1970s were a time of great social and cultural change, such as rapid "ontzuiling" (literally: depillarisation), a term that describes the decay of the old divisions along class and religious lines. A youth culture emerged all across Western Europe and the U.S., characterised by student rebellion, informality, sexual freedom, informal clothes, new hair styles, protest music, drugs and idealism. Young people, and students in particular, rejected traditional mores, and pushed for change in matters like women's rights, sexuality, disarmament and environmental issues.
Secularization, or the decline in religiosity, first became noticeable after 1960 in the Protestant rural areas of Friesland and Groningen. Then, it spread to Amsterdam, Rotterdam and the other large cities in the west. Finally the Catholic southern areas showed religious declines. As the social distance between the Calvinists and Catholics narrowed (and they began to intermarry), it became possible to merge their parties. The Anti Revolutionary Party (ARP) in 1977 merged with the Catholic People's Party (KVP) and the Protestant Christian Historical Union (CHU) to form the Christian Democratic Appeal (CDA). However, a countervailing trend later appeared as the result of a religious revival in the Protestant Bible Belt, and the growth of the Muslim and Hindu communities as a result of immigration and high fertility levels.
After 1982, there was a retrenchtment of the welfare system, especially regarding old-age pensions, unemployment benefits, and disability pensions/early retirement benefits.
Following the election of 1994, in which the Christian democratic CDA lost a considerable portion of its representatives, the social-liberal Democrats 66 (D66) doubled in size and formed a coalition with the labour party (Netherlands) (PvdA), and the People's Party for Freedom and Democracy (VVD). This purple (government) coalition marked the first absence of the CDA in government in decades. During the Purple Coalition years, a period lasting until the rise of the populist politician Pim Fortuyn, the government addressed issues previously viewed as taboo under the Christian-influenced cabinet. At this time, the Dutch government introduced unprecedented legislation based on a policy of official tolerance ("gedoogbeleid"). Abortion and euthanasia were decriminalized, but stricter guidelines were set for their implementation. Drug policy, especially with regard to the regulation of cannabis, was reformed. Prostitution was legalised, but confined to brothels where the health and safety of those involved could be properly monitored. With the 2001 Same-Sex Marriage Act, the Netherlands became the first country to legalise same-sex marriage. In addition to social reforms, the Purple Coalition also presided over a period of remarkable economic prosperity.
Recent politics.
In the 1998 election the Purple Coalition consisting of Social Democrats, Democrats and Liberals increased its majority. Both the social-democratic PvdA and the conservative liberal VVD grew at the cost of their junior partner in cabinet, the progressive liberal D66. The voters rewarded the Purple Coaliation for its economic performance, which had included reduction of unemployment and the budget deficit, steady growth and job creation combined with wage freezes and trimming of the welfare state, together with a policy of fiscal restraint. The result was the second Kok cabinet.
The power of the coalition waned with the introduction of List Pim Fortuyn in the Dutch general election of 2002, a populist party, which ran a distinctly anti-immigration and anti-purple campaign, citing "Purple Chaos" ("Puinhopen van Paars") as the source of the countries economic and social woes. In the first political assassination in three centuries, Fortuyn was murdered with little over a week left before the election. In the wake of its leader's death, LPF swept the elections, entering parliament with one sixth of the seats, while the PvdA (Labour) lost half of its seats. The ensuing cabinet was formed by CDA, VVD and LPF, led by Prime Minister Jan Peter Balkenende. Though the party succeeded in displacing the rival Purple Coalition, without the charismatic figure of Pim Fortuyn at its helm, it proved to be short-lived lasting 87 days in power.
Two events changed the political landscape:
The Netherlands today.
By 2000 the population had increased to 15.9 million people, making the Netherlands one of the most densely populated countries in the world. Urban development has led to the development of a conurbation called the "Randstad" (Dutch: "Randstad"), which includes the four largest cities (Amsterdam, Rotterdam, The Hague and Utrecht), and the surrounding areas. With a population of 7,100,000 it is one of the largest conurbations in Europe.
This small nation has successfully developed into one of the most open, dynamic and prosperous countries in the world. It had the tenth-highest per capita income in the world in 2011. It has an open, market-based mixed economy, ranking 13th of 157 countries according to the Index of Economic Freedom. In May 2011, the OECD ranked the Netherlands as the "happiest" country in the world.
Historians and Historiography.
Historiography.
The American John Lothrop Motley was the first foreign historian to write a major history of the Dutch Republic. In 3500 pages he crafted a literary masterpiece that was translated into numerous languages; his dramatic story reached a wide audience in the 19th century. Motley relied heavily on Dutch scholarship and immersed himself in the sources. His style no longer attracts readers, and scholars have moved away from his simplistic dichotomies of good versus evil, Dutch versus Spanish, Catholic versus Protestant, freedom versus authoritarianism. His theory of causation over-emphasized ethnicity as an unchanging characteristic, exaggerated the importance of William of Orange, and gave undue importance to the issue religious tolerance.
The pioneering Dutch cultural historian Johan Huizinga (1872-1945), author of "The Autumn of the Middle Ages" (1919) (the English translation was called "The Waning of the Middle Ages") and "Homo Ludens: A Study of the Play Element in Culture" (1935), which expanded the field of cultural history and influenced the historical anthropology of younger historians of the French Annales School. He was influenced by art history and advised historians to trace "patterns of culture" by studying "themes, figures, motifs, symbols, styles and sentiments."
The "polder model" continues to strongly influence historians as well as Dutch political discussion. The polder model stresses the need for finding consensus; it discourages furious debate and angry dissent in both academia and politics - in contrast to the highly developed, intense debates in Germany.
The H-Net list H-Low-Countries is published free by email and is edited by scholars. Its occasional messages serve an international community with diverse methodological approaches, archival experiences, teaching styles, and intellectual traditions, promotes discussion relevant to the region and to the different national histories in particular, with an emphasis on the Netherlands. H-Low-Countries publishes conference announcements, questions and discussions; reviews of books, journals, and articles; and tables of contents of journals on the history of the Low Countries (in both Dutch and English). After World War II both research-oriented and teaching-oriented historians have been rethinking their interpretive approaches to Dutch history, balancing traditional memories and modern scholarship. In terms of popular history, there has been an effort to ensure greater historical accuracy in museums and historic tourist sites.
Once heralded as the leading event of modern Dutch history, the Dutch Revolt lasted from 1568 to 1648, and historians have worked to interpret it for even longer. Cruz (2007) explains the major debates among scholars regarding the Dutch bid for independence from Spanish rule. While agreeing that the intellectual milieus of late 19th and 20th centuries affected historians' interpretations, Cruz argues that writings about the revolt trace changing perceptions of the role played by small countries in the history of Europe. In recent decades grand theory has fallen out of favor among most scholars, who emphasize the particular over the general. Dutch and Belgian historiography since 1945 no longer says the revolt was the culmination of an inevitable process leading to independence and freedom. Instead scholars have put the political and economic details of the towns and provinces under the microscope, while agreeing on the weaknesses of attempts at centralization by the Habsburg rulers. The most influential new studies have been rooted in demographic and economic history, though scholars continue to debate the relationship between economics and politics. The religious dimension has been viewed in terms of mentalities, exposing the minority position of Calvinism, while the international aspects have been studied more seriously by foreign historians than by the Dutch themselves.
Pieter Geyl was the leading historian of the Dutch Revolt, and a highly influential professor at the University of London (1919-1935) and at the State University of Utrecht (1936–58). He wrote a six-volume history of the Dutch-speaking peoples. The Nazis imprisoned him in World War II. In his political views, Geyl adopted the views of the 17th-century Dutch Louvestein faction, led by Johan van Oldenbarneveldt (1547-1619) and Johan de Witt (1625–72). It stood for liberty, toleration, and national interests in contrast to the Orange stadholders who sought to promote their own self-interest. According to Geyl, the Dutch Republic reached the peak of its powers during the 17th century. He was also a staunch nationalist and suggested that Flanders could split off from Belgium and join the Netherlands. Later he decried what he called radical nationalism and stressed more the vitality of Western Civilization. Geyl was highly critical of the world history approach of Arnold J. Toynbee.
Jan Romein (1893-1962) created a "theoretical history" in an attempt to reestablish the relevance of history to public life in the 1930s at a time of immense political uncertainty and cultural crisis, when, in Romein's view, history had become too inward-looking and isolated from other disciplines. Romein, a Marxist, felt that history must contribute to social improvement. At the same time, influenced by the successes of theoretical physics and his study of Oswald Spengler, Arnold J. Toynbee, Frederick John Teggart, and others, he spurred on the development of theoretical history in the Netherlands, to the point where it became a subject in its own right at the university level after the war. Romein used the term integral history as a substitute for cultural history and focused his attention on the period around the turn of the century. He concluded that a serious crisis occurred in European civilization in 1900 because of the rise of anti-Semitism, extreme nationalism, discontent with the parliamentary system, depersonalization of the state, and the rejection of positivism. European civilization waned as the result of this crisis which was accompanied by the rise of the United States, the Americanization of the world, and the emergence of Asia. His interpretation is reminiscent of that of his mentor Johan Huizinga and was criticized by his colleague Pieter Geyl.
Further reading.
</dl>
Geography and environment.
</dl>

</doc>
<doc id="13290" url="http://en.wikipedia.org/wiki?curid=13290" title="Harold and Maude">
Harold and Maude

 
Harold and Maude is a 1971 American romantic dark comedy directed by Hal Ashby and released by Paramount Pictures. It incorporates elements of dark humor and existentialist drama, with a plot that revolves around the exploits of a young man named Harold (played by Bud Cort) intrigued with death. Harold drifts away from the life that his detached mother (Vivian Pickles) prescribes for him, and slowly develops quite a strong and close friendship and eventually a romantic relationship with a 79-year-old woman named Maude (Ruth Gordon) who teaches Harold about living life to its fullest and that life is the most precious gift of all.
The film was based on a screenplay written by Colin Higgins and published as a novel in 1971. Filming locations in the San Francisco Bay Area included both Holy Cross Cemetery and Golden Gate National Cemetery, and the ruins of the Sutro Baths.
Critically and commercially unsuccessful when originally released, the film developed a cult following and in 1983 began making a profit. The film is ranked number 45 on the American Film Institute's list of 100 Funniest Movies of all Time and was selected for preservation in the National Film Registry of the Library of Congress in 1997, for being "culturally, historically or aesthetically significant". The Criterion Collection special edition Blu-ray and DVD were released June 12, 2012.
Plot.
Harold Chasen (Bud Cort) is a young man obsessed with death. He stages elaborate fake suicides, attends funerals and drives a hearse, all to the chagrin of his socialite mother (Vivian Pickles).
At another stranger's funeral service, Harold meets Maude (Ruth Gordon), a 79-year-old woman who shares Harold's hobby of attending funerals. He is entranced by her quirky outlook on life, which is bright and excessively carefree in contrast with his morbidity. The pair form a bond and Maude slowly shows Harold the pleasures of art and music (including how to play banjo), and teaches him how to "[make] the most of his time on earth". Meanwhile, Harold's mother is determined, against Harold's wishes, to find him a wife. One by one, Harold frightens and horrifies each of his appointed dates, by appearing to commit gruesome acts such as self-immolation, self-mutilation and seppuku.
As they become closer, their friendship soon blossoms into a romance and Harold announces that he will marry Maude, resulting in disgusted outbursts from his family, psychiatrist and priest. Maude's 80th birthday arrives and Harold throws a surprise party for her. As the couple dance, Maude tells Harold that she "couldn't imagine a lovelier farewell". Confused, he questions Maude as to her meaning and she reveals that she has taken an overdose of sleeping pills and will be dead by midnight. She restates her firm belief that eighty is the proper age to die.
Harold rushes Maude to the hospital, where she is treated unsuccessfully and dies. In the final sequence, Harold's car is seen going off a seaside cliff but after the crash, the final shot reveals Harold standing calmly atop the cliff, holding his banjo. After gazing down at the wreckage, he dances away, picking out on his banjo Cat Stevens' "If You Want to Sing Out, Sing Out".
Production.
UCLA student Colin Higgins wrote "Harold and Maude" as his master’s thesis. While working as producer Edward Lewis' pool boy, Higgins showed the script to Lewis's wife, Mildred. Mildred was so impressed that she got Edward to give it to Stanley Jaffe at Paramount. Higgins sold the script with the understanding that he would direct the film but he was told he wasn't ready, after tests he shot proved unsatisfactory to the studio heads. Ashby would only commit to directing the film after getting Higgins' blessing and then, so Higgins could watch and learn from him on the set, Ashby made Higgins a co-producer. Higgins says he originally thought of the story as a play. It then became a 20 minute thesis while at film school. After the film came out, the script was turned into a novel then a play, which ran for several years in Paris.
Ashby felt that Maude should ideally be European and his list of possible actresses included dames Peggy Ashcroft, Edith Evans, Gladys Cooper and Celia Johnson as well as Lotte Lenya, Luise Rainer, Pola Negri, Minta Durfee and Agatha Christie. Ruth Gordon indicated that in addition she heard that Edwige Feuillere, Elisabeth Bergner, Mildred Natwick, Mildred Dunnock and Dorothy Stickney had been considered.
For Harold, in addition to Bud Cort, Ashby considered all promising unknowns, Richard Dreyfuss, Bob Balaban and John Savage. Also on his list were John Rubinstein, for whom Higgins had written the part and then up-and-coming British pop star Elton John, whom Ashby had seen live and hoped would also do the music.
Anne Brebner, the casting director, was almost cast as Harold's mother, when Vivian Pickles was briefly unable to do the role.
Themes.
Hal Ashby, the director, shared certain ideals with the era’s youth culture and in this film he contrasts the doomed outlook of the alienated youth with the hard-won optimism of those who endured the horrors of the early 20th century, nihilism with purpose. Harold is the present, Maude's past is revealed in a glimpse of the Auschwitz ID number tattooed on her arm, as well as her talk with Harold about using an umbrella to defend herself from thugs at political meetings before moving to America. Part of what has made the film a classic is that Ashby understands and is sympathetic of both the doomed and optimistic outlooks rather than portraying the world as Us vs. Them. This is a love story of two people, Harold and Maude.
Meaning threads through the film as does choice mostly seen through the changes in Harold. He is part of a society in which he is of no importance; existentially, he is without meaning. Maude lives a life of deliberate choice and rich with meaning. It is in this crisis, shown against the backdrop of the Vietnam War, that we see the differences between experiencing a meaningless war and experiencing and living beyond a war of great meaning. He is part of a generation and she an individual. He no longer believes in anything while she lives the ideals of the era's youth culture. He plays with death, she accepts death as a fact of life and decides her own time to die. 
Because he is forced to accept that deliberate choice Harold gains the strength to make his own. He won't react to a society that sees him only as a position he fills or the background of a meaningless world. He, too will be an individual, he will live a life with meaning. 
Harold's "deaths".
When Harold and Maude are talking candidly at her home he tells her that he has "died a few times". He describes how, when he was at boarding school, he set his chemistry lab on fire and escaped through a hole in the floor, going home believing his school career was at an end and he was free. When the police came to his house, Harold watched as they told his mother that he had died in the fire and saw her collapse into the policemen's arms. As he reaches this part of the story, Harold bursts into tears and declares, "I decided then I enjoyed being dead".
Throughout the movie, Harold "dies" seven to eight times. He tells his psychologist at one early juncture that he has made similar attempts in all fifteen times now, which he calls a rough estimate.
Reception.
Awards.
"Harold and Maude" is #45 on the American Film Institute’s list of 100 Years... 100 Laughs, the list of the top 100 films in American comedy. The list was released in 2000. Two years later, AFI released the list AFI's 100 Years... 100 Passions honoring the most romantic films for the past 100 years, "Harold and Maude" ranked #69. In September 2008, "Empire" listed "Harold and Maude" as #65 in "Empire"'s 500 Greatest Movies of All Time. "Entertainment Weekly" ranked the film #4 on their list of “The Top 50 Cult Films.”
In June 2008, AFI revealed its "Ten Top Ten"—the best ten films in ten "classic" American film genres—after polling over 1,500 people from the creative community. "Harold and Maude" was acknowledged as the ninth best film in the romantic comedy genre.
At the 29th Golden Globe Awards, Bud Cort and Ruth Gordon received a nomination for Best Actor and Best Actress in a Musical or Comedy film, respectively.
Critical response.
"Harold and Maude" received mixed reviews, with several critics being offended by the film's dark humor. Roger Ebert, in a review dated January 1, 1972, did not care for the film. He wrote, "And so what we get, finally, is a movie of attitudes. Harold is death, Maude life, and they manage to make the two seem so similar that life's hardly worth the extra bother. The visual style makes everyone look fresh from the Wax Museum, and all the movie lacks is a lot of day-old gardenias and lilies and roses in the lobby, filling the place with a cloying sweet smell. Nothing more to report today. Harold doesn't even make pallbearer." Vincent Canby also panned the film, stating that the actors "are so aggressive, so creepy and off-putting, that Harold and Maude are obviously made for each other, a point the movie itself refuses to recognize with a twist ending that betrays, I think, its life-affirming pretensions."
The reputation of the film has increased; Rotten Tomatoes, which labeled the film as "Certified Fresh", gave it a score of 86% based on 42 reviews, with an average score of 7.6/10. A consensus on the site read, "Hal Ashby's comedy is too dark and twisted for some, and occasionally oversteps its bounds, but there's no denying the film's warm humor and big heart." In 2005, the Writers Guild of America ranked the screenplay #86 on its list of 101 Greatest Screenplays ever written. Sight & Sound magazine conducts a poll every ten years of the world's finest film directors, to find out the Ten Greatest Films of All Time. This poll has been going since 1992 and has become the most recognised poll of its kind in the world. In 2012, Niki Caro, Wanuri Kahiu and Cyrus Frisch voted for "Harold and Maude". Frisch commented: "An encouragement to think beyond the obvious!"
Music.
The music in "Harold and Maude" was composed and performed by Cat Stevens. He had been suggested by Elton John to do the music after John had dropped out of the project. Stevens composed two original songs for the film, "Don't Be Shy" and "If You Want to Sing Out, Sing Out" and performed instrumental and alternate versions of the songs "On the Road to Find Out", "I Wish, I Wish", "Miles from Nowhere", "Tea for the Tillerman", "I Think I See the Light", "Where Do the Children Play?" and "Trouble" which were either on the album "Mona Bone Jakon" or "Tea for the Tillerman". Those albums had been released before the film. "Don't Be Shy" and "If You Want to Sing Out, Sing Out" were not released on an album, until his 1984 compilation "".
There is some additional non-Cat Stevens music in the film. "Greensleeves" is played on the harp during dinner. During the scene where Harold is floating face-down in the swimming pool, the opening bars of Tchaikovsky's Piano Concerto No. 1 are heard. A marching band is also heard playing a John Philip Sousa march outside the church following a funeral.
1972 soundtrack.
The first soundtrack was released in Japan in 1972 on vinyl and cassette, (A&M Records GP-216). It omitted the two original songs and all instrumental and alternate versions of songs and was generally composed of re-released material that was in the film, along with five songs that are not in the film.
2007 soundtrack.
The second soundtrack was released in December 2007, by Vinyl Films Records, as a vinyl-only limited edition release of 2,500 copies. It contained a 30-page oral history of the making of the film, the most extensive series of interviews yet conducted on "Harold and Maude".
Adaptations.
Colin Higgins later adapted the story into a stage play. The original Broadway production, starring Janet Gaynor as Maude and Keith McDermott as Harold, closed after four performances in February 1980.
A French adaptation for television, translated and written by Jean-Claude Carrière, appeared in 1978. It was also adapted for the stage and performed in Québec, starring Roy Dupuis.
Unproduced sequel and prequel.
Higgins expressed interest in 1978 about both a sequel and prequel to "Harold and Maude". The sequel, "Harold's Story", would have Cort portray Harold's life after Maude. Higgins also imagined a prequel showing Maude's life before Harold, "Grover and Maude" had Maude learning how to steal cars from Grover Muldoon, the character portrayed by Richard Pryor in Higgins' 1976 film "Silver Streak". Higgins wanted Gordon and Pryor to reprise their roles.

</doc>
<doc id="13291" url="http://en.wikipedia.org/wiki?curid=13291" title="Habitus (sociology)">
Habitus (sociology)

Habitus can be defined as individual's personality structure. It refers to the lifestyle, values, dispositions and expectations of particular social groups that are acquired through the activities and experiences of everyday life. In other words, the habitus could be understood as a structure of the mind characterized by a set of acquired schemata, sensibilities, dispositions and taste. The particular contents of the habitus are a complex result of embodying social structures—such as the gender, race, and class discrimination embedded in welfare reforms—that are then reproduced through tastes, preferences, and actions for future embodiment. The habitus can be seen as counterpoint to the notions of rationality that are prevalent within other disciplines of social science research, as it relativizes the notion of an actor's 'best interest' through attention to the cultural definition of 'best'. It is perhaps best understood in relation to the notion 'field', which describes the dialectical relationship between individual agents (habitus) and the contextual environment (field).
Habitus is one’s physical and psychological demeanor as a result of habits developed over a period of time. It develops a person’s attitudes towards society and influences the way that an individual reacts to the world around them. Habitus is a structuring feature of life and is determined by a series of influences on the individual, such as one’s socio-economic status, family, religion, education and ethnicity. That is, the attitudes, mannerisms, ideologies, actions and habits that a person has been subjected to in their life manifests to create the person that they are today. Therefore, an individual is a result of the internalised influences throughout their life.
Habitus is produced by an individual’s position in the social structure. As a result of understanding their place in the social structure, an individual is able to determine what is achievable or possible in their life. The consequences of the development of habitus are large: Bourdieu argued that the reproduction of the social structure results from the habitus of individuals (Bourdieu, 1987).
Origins.
The concept of habitus has been used as early as Aristotle but in contemporary usage was introduced by Marcel Mauss and later re-elaborated by Maurice Merleau-Ponty and Pierre Bourdieu. Bourdieu elaborates on the notion of Habitus by explaining its dependency on history and human memory. For instance, a certain behaviour or belief becomes part of a society's structure when the original purpose of that behaviour or belief can no longer be recalled and becomes socialized into individuals of that culture.
Loïc Wacquant wrote that habitus is an old philosophical notion, originating in the thought of Aristotle, whose notion of "hexis" ("state") was translated into "habitus" by the Medieval Scholastics. Bourdieu first adapted the term in his 1967 postface to Erwin Panofsky's "Gothic Architecture and Scholasticism". The term was earlier used in sociology by Norbert Elias in "The Civilizing Process" (1939) and in Marcel Mauss's account of "body techniques" (techniques du corps). The concept is also present in the work of Max Weber, Gilles Deleuze, and Edmund Husserl.
Mauss defined habitus as those aspects of culture that are anchored in the body or daily practices of individuals, groups, societies, and nations. It includes the totality of learned habits, bodily skills, styles, tastes, and other non-discursive knowledges that might be said to "go without saying" for a specific group (Bourdieu 1990:66-67) — in that way it can be said to operate beneath the level of rational ideology.
According to Bourdieu, habitus is composed of:
[s]ystems of durable, transposable dispositions, structured structures predisposed to function as structuring structures, that is, as principles which generate and organize practices and representations that can be objectively adapted to their outcomes without presupposing a conscious aiming at ends or an express mastery of the operations necessary in order to attain them.
Literary criticism.
The term has also been adopted in literary criticism, adapting from Bourdieu's usage of the term. For example, Joe Moran's examination of authorial identities in "Star Authors: Literary Celebrity in America" uses the term in discussion of how authors develop a habitus formed around their own celebrity and status as authors, which manifests in their writing.
The Use of Habitus in Literary Theory.
Bourdieu’s principle of habitus is interwoven with the concept of structuralism in literary theory. Peter Barry explains, “in the structuralist approach to literature there is a constant movement away from interpretation of the individual literary work and a parallel drive towards understanding the larger structures which contain them” (2009, p. 39). There is therefore a strong desire to understand the larger influencing factors which makes an individual literary work. As Bourdieu explains, habitus “are structured structures, generative principles of distinct and distinctive practices – what the worker eats, and especially the way he eats it, the sport he practices and the way he practices it, his political opinions and the way he expresses them are systematically different from the industrial proprietor’s corresponding activities / habitus are also structuring structures, different classifying schemes classification principles, different principles of vision and division, different tastes. Habitus make different differences; they implement distinctions between what is good and what is bad, what is right and what is wrong, between what is distinguished and what is vulgar, and so on, but they are not the same. Thus, for instance, the same behaviour or even the same good can appear distinguished to one person, pretentious to someone else, and cheap or showy to yet another” (Bourdieu, 1996). As a result, habitus may be employed in literary theory in order to understand those larger, external structures which influence individual theories and works of literature.
Non-sociological uses.
Body habitus.
Body habitus (or "bodily habitus") is the medical term for physique, and is defined as either endomorphic (overweight), ectomorphic (underweight) or mesomorphic (normal weight). In this sense, habitus can be understood as the physical and constitutional characteristics of an individual, especially as related to the tendency to develop a certain disease. For example, "Marfanoid bodily habitus".

</doc>
<doc id="13292" url="http://en.wikipedia.org/wiki?curid=13292" title="Hypoxia (medical)">
Hypoxia (medical)

Hypoxia (also known as hypoxiation or anoxemia) is a condition in which the body or a region of the body is deprived of adequate oxygen supply. Hypoxia may be classified as either "generalized", affecting the whole body, or "local", affecting a region of the body. Although hypoxia is often a pathological condition, variations in arterial oxygen concentrations can be part of the normal physiology, for example, during hypoventilation training or strenuous physical exercise.
Hypoxia differs from hypoxemia in that hypoxia refers to a state in which oxygen supply is insufficient, whereas hypoxemia refers specifically to states that have low arterial oxygen supply. Hypoxia in which there is complete deprivation of oxygen supply is referred to as "anoxia".
Generalized hypoxia occurs in healthy people when they ascend to high altitude, where it causes altitude sickness leading to potentially fatal complications: high altitude pulmonary edema (HAPE) and high altitude cerebral edema (HACE). Hypoxia also occurs in healthy individuals when breathing mixtures of gasses with a low oxygen content, e.g. while diving underwater especially when using closed-circuit rebreather systems that control the amount of oxygen in the supplied air. A mild and non-damaging intermittent hypoxia is used intentionally during altitude trainings to develop an athletic performance adaptation at both the systemic and cellular level.
Hypoxia is also a serious consequence of preterm birth in the neonate. The main cause for this is that the lungs of the human fetus are among the last organs to develop during pregnancy. To assist the lungs to distribute oxygenated blood throughout the body, infants at risk of hypoxia are often placed inside an incubator capable of providing continuous positive airway pressure (also known as a humidicrib). 
Signs and symptoms.
Generalised hypoxia.
The symptoms of generalized hypoxia depend on its severity and acceleration of onset.
In the case of altitude sickness, where hypoxia develops gradually, the symptoms include light-headedness / fatigue, numbness / tingling of extremities, nausea and anoxia. In severe hypoxia, or hypoxia of very rapid onset, ataxia, confusion / disorientation / hallucinations / behavioral change, severe headaches / reduced level of consciousness, papilloedema, breathlessness, pallor, tachycardia and pulmonary hypertension eventually leading to the late signs cyanosis, slow heart rate / cor pulmonale and low blood pressure followed by death.
Because hemoglobin is a darker red when it is not bound to oxygen (deoxyhemoglobin), as opposed to the rich red color that it has when bound to oxygen (oxyhemoglobin), when seen through the skin it has an increased tendency to reflect blue light back to the eye. In cases where the oxygen is displaced by another molecule, such as carbon monoxide, the skin may appear 'cherry red' instead of cyanotic.
Local hypoxia.
If a tissue is not being perfused properly, it may feel cold and appear pale; if severe, hypoxia can result in cyanosis, a blue discoloration of the skin. If hypoxia is very severe, a tissue may eventually become gangrenous
Extreme pain may also be felt at or around the site.
Cause.
Oxygen passively diffuses in the lung alveoli according to a pressure gradient. Oxygen diffuses from the breathed air, mixed with water vapour, to arterial blood, where its partial pressure is around 100 mmHg (13.3 kPa). In the blood, oxygen is bound to hemoglobin, a protein in red blood cells. The binding capacity of hemoglobin is influenced by the partial pressure of oxygen in the environment, as described in the oxygen–hemoglobin dissociation curve. A smaller amount of oxygen is transported in solution in the blood. 
In peripheral tissues, oxygen again diffuses down a pressure gradient into cells and their mitochondria, where it is used to produce energy in conjunction with the breakdown of glucose, fats and some amino acids. 
Hypoxia can result from a failure at any stage in the delivery of oxygen to cells. This can include decreased partial pressures of oxygen, problems with diffusion of oxygen in the lungs, insufficient available hemoglobin, problems with blood flow to the end tissue, and problems with breathing rhythm.
Experimentally, oxygen diffusion becomes rate limiting (and lethal) when arterial oxygen partial pressure falls to 60 mmHg (5.3 kPa) or below. 
Ischemia.
Ischemia, meaning insufficient blood flow to a tissue, can also result in hypoxia. This is called 'ischemic hypoxia'. This can include an embolic event, a heart attack that decreases overall blood flow, or trauma to a tissue that results in damage. An example of insufficient blood flow causing local hypoxia is gangrene that occurs in diabetes. 
Diseases such as peripheral vascular disease can also result in local hypoxia. For this reason, symptoms are worse when a limb is used. Pain may also be felt as a result of increased hydrogen ions leading to a decrease in blood pH (acidity) created as a result of anaerobic metabolism.
Hypoxemic hypoxia.
This refers specifically to hypoxic states where the arterial content of oxygen is insufficient. This can be caused by alterations in respiratory drive, such as in respiratory alkalosis, physiological or pathological shunting of blood, diseases interfering in lung function resulting in a ventilation-perfusion mismatch, such as a pulmonary embolus, or alterations in the partial pressure of oxygen in the environment or lung alveoli, such as may occur at altitude or when diving.
Problems with hemoglobin.
Almost all the oxygen in the blood is bound to hemoglobin, so interfering with this carrier molecule limits oxygen delivery to the periphery. Hemoglobin increases the oxygen-carrying capacity of blood by about 40-fold, with the ability of hemoglobin to carry oxygen influenced by the partial pressure of oxygen in the environment, a relationship described in the oxygen–hemoglobin dissociation curve. When the ability of hemoglobin to carry oxygen is interfered with, a hypoxic state can result.:997–999
Anemia.
Hemoglobin plays a substantial role in carrying oxygen throughout the body, and when it is deficient, anemia can result, causing 'anaemic hypoxia' if tissue perfusion is decreased. Iron deficiency is the most common cause of anemia. As iron is used in the synthesis of hemoglobin, less hemoglobin will be synthesised when there is less iron, due to insufficient intake, or poor absorption.:997–999
Anemia is typically a chronic process that is compensated over time by increased levels of red blood cells via upregulated erythropoetin. A chronic hypoxic state can result from a poorly compensated anaemia.:997–999
Carbon monoxide poisoning.
Carbon monoxide competes with oxygen for binding sites on hemoglobin molecules. As carbon monoxide binds with hemoglobin hundreds of times tighter than oxygen, it can prevent the carriage of oxygen. 
Carbon monoxide poisoning can occur acutely, as with smoke intoxication, or over a period of time, as with cigarette smoking. Due to physiological processes, carbon monoxide is maintained at a resting level of 4-6 ppm. This is increased in urban areas (7 - 13 ppm) and in smokers (20 - 40 ppm). A carbon monoxide level of 40 ppm is equivalent to a reduction in hemoglobin levels of 10 g/L.
CO has a second toxic effect, namely removing the allosteric shift of the oxygen dissociation curve and shifting the foot of the curve to the left. In so doing, the hemoglobin is less likely to release its oxygens at the peripheral tissues. Certain abnormal hemoglobin variants also have higher than normal affinity for oxygen, and so are also poor at delivering oxygen to the periphery.
Asphyxiant gases and hypoxic breathing gases.
The breathing gas in scuba diving may contain an insufficient partial pressure of oxygen, particularly in malfunction of rebreathers. Such situations may lead to unconsciousness without symptoms since carbon dioxide levels are normal and the human body senses pure hypoxia poorly.
A similar problem exists when inhaling certain odorless asphyxiant gases. These produce a hypoxic breathing gas which can produce unconsciousness and death without symptoms. This may cause inert gas asphyxiation. Such asphyxia may be deliberate with use of a suicide bag. Accidental death has occurred in cases where concentrations of nitrogen in controlled atmospheres, or methane in mines, has not been detected or appreciated.
Cyanide poisoning.
Histotoxic hypoxia results when the quantity of oxygen reaching the cells is normal, but the cells are unable to use the oxygen effectively, due to disabled oxidative phosphorylation enzymes. This may occur in Cyanide poisoning. 
Other.
Hemoglobin's function can also be lost by chemically oxidizing its iron atom to its ferric form. This form of inactive hemoglobin is called methemoglobin and can be made by ingesting sodium nitrite as well as certain drugs and other chemicals.
Physiological compensation.
Acute.
If oxygen delivery to cells is insufficient for the demand (hypoxia), hydrogen will be shifted to pyruvic acid converting it to lactic acid. This temporary measure (anaerobic metabolism) allows small amounts of energy to be released. Lactic acid build up (in tissues and blood) is a sign of inadequate mitochondrial oxygenation, which may be due to hypoxemia, poor blood flow (e.g., shock) or a combination of both. If severe or prolonged it could lead to cell death. 
In humans, hypoxia is detected by chemoreceptors in the carotid body. This response does not control ventilation rate at normal pO2, but below normal the activity of neurons innervating these receptors increases dramatically, so much so to override the signals from central chemoreceptors in the hypothalamus, increasing pO2 despite a falling pCO2
In most tissues of the body, the response to hypoxia is vasodilation. By widening the blood vessels, the tissue allows greater perfusion.
By contrast, in the lungs, the response to hypoxia is vasoconstriction. This is known as "Hypoxic pulmonary vasoconstriction", or "HPV". 
Chronic.
When the pulmonary
capillary pressure remains elevated chronically
(for at least 2 weeks), the lungs become even more
resistant to pulmonary edema because the lymph
vessels expand greatly, increasing their capability of carrying
fluid away from the interstitial spaces perhaps as
much as 10-fold. Therefore, in patients with chronic
mitral stenosis, pulmonary capillary pressures of 40 to
45 mm Hg have been measured without the development
of lethal pulmonary edema.[Guytun and Hall physiology]
Hypoxia exists when there is a reduced amount of oxygen in the tissues of the body. Hypoxemia refers to a reduction in PO2 below the normal range, regardless of whether gas exchange is impaired in the lung, CaO2 is adequate, or tissue hypoxia exists. There are several potential physiologic mechanisms for hypoxemia, but in patients with COPD the predominant one is V/Q mismatching, with or without alveolar hypoventilation, as indicated by PaCO2. Hypoxemia caused by V/Q mismatching as seen in COPD is relatively easy to correct, so that only comparatively small amounts of supplemental oxygen (less than 3 L/min for the majority of patients) are required for LTOT. Although hypoxemia normally stimulates ventilation and produces dyspnea, these phenomena and the other symptoms and signs of hypoxia are sufficiently variable in patients with COPD as to be of limited value in patient assessment. Chronic alveolar hypoxia is the main factor leading to development of cor pulmonale--right ventricular hypertrophy with or without overt right ventricular failure--in patients with COPD. Pulmonary hypertension adversely affects survival in COPD, to an extent that parallels the degree to which resting mean pulmonary artery pressure is elevated. Although the severity of airflow obstruction as measured by FEV1 is the best correlate with overall prognosis in patients with COPD, chronic hypoxemia increases mortality and morbidity for any severity of disease. Large-scale studies of LTOT in patients with COPD have demonstrated a dose-response relationship between daily hours of oxygen use and survival. There is reason to believe that continuous, 24-hours-per-day oxygen use in appropriately selected patients would produce a survival benefit even greater than that shown in the NOTT and MRC studies.
Treatment.
To counter the effects of high-altitude diseases, the body must return arterial pO2 toward normal. Acclimatization, the means by which the body adapts to higher altitudes, only partially restores pO2 to standard levels. Hyperventilation, the body’s most common response to high-altitude conditions, increases alveolar pO2 by raising the depth and rate of breathing. However, while pO2 does improve with hyperventilation, it does not return to normal. Studies of miners and astronomers working at 3000 meters and above show improved alveolar pO2 with full acclimatization, yet the pO2 level remains equal to or even below the threshold for continuous oxygen therapy for patients with chronic obstructive pulmonary disease (COPD). In addition, there are complications involved with acclimatization. Polycythemia, in which the body increases the number of red blood cells in circulation, thickens the blood, raising the danger that the heart can’t pump it.
In high-altitude conditions, only oxygen enrichment can counteract the effects of hypoxia. By increasing the concentration of oxygen in the air, the effects of lower barometric pressure are countered and the level of arterial pO2 is restored toward normal capacity. A small amount of supplemental oxygen reduces the equivalent altitude in climate-controlled rooms. At 4000 m, raising the oxygen concentration level by 5 percent via an oxygen concentrator and an existing ventilation system provides an altitude equivalent of 3000 m, which is much more tolerable for the increasing number of low-landers who work in high altitude. In a study of astronomers working in Chile at 5050 m, oxygen concentrators increased the level of oxygen concentration by almost 30 percent (that is, from 21 percent to 27 percent). This resulted in increased worker productivity, less fatigue, and improved sleep.
Oxygen concentrators are uniquely suited for this purpose. They require little maintenance and electricity, provide a constant source of oxygen, and eliminate the expensive, and often dangerous, task of transporting oxygen cylinders to remote areas. Offices and housing already have climate-controlled rooms, in which temperature and humidity are kept at a constant level. Oxygen can be added to this system easily and relatively cheaply. 
A prescription renewal for home oxygen following hospitalization requires an assessment of the patient for ongoing hypoxemia.
See also.
For aircraft decompression incidents at altitude see:

</doc>
<doc id="13293" url="http://en.wikipedia.org/wiki?curid=13293" title="Historical revisionism">
Historical revisionism

In historiography, historical revisionism is the reinterpretation of orthodox views on evidence, motivations, and decision-making processes surrounding a historical event. Though the word "revisionism" is sometimes used in a negative way, constant revision of history is part of the normal scholarly process of writing history.
Scholarly process.
Pulitzer Prize winning historian James McPherson, writing for the American Historical Association, described the importance of revisionism:
The 14,000 members of this Association, however, know that revision is the lifeblood of historical scholarship. History is a continuing dialogue between the present and the past. Interpretations of the past are subject to change in response to new evidence, new questions asked of the evidence, new perspectives gained by the passage of time. There is no single, eternal, and immutable "truth" about past events and their meaning. The unending quest of historians for understanding the past—that is, "revisionism"—is what makes history vital and meaningful. Without revisionism, we might be stuck with the images of Reconstruction after the American Civil War that were conveyed by D. W. Griffith's "The Birth of a Nation" and Claude Bowers's "The Tragic Era". Were the Gilded Age entrepreneurs "Captains of Industry" or "Robber Barons"? Without revisionist historians who have done research in new sources and asked new and nuanced questions, we would remain mired in one or another of these stereotypes. Supreme Court decisions often reflect a "revisionist" interpretation of history as well as of the Constitution.
Those historians who work within the existing establishment and who have a body of existing work from which they claim authority, often have the most to gain by maintaining the "status quo". This can be called an accepted paradigm, which in some circles or societies takes the form of a denunciative stance towards revisionism of any kind. However, the historian and philosopher of science, Thomas Kuhn, pointed out that in contrast to the sciences, in which there tends to be (except in times of paradigm shift) a single reigning paradigm, the social sciences are characterized by a "tradition of claims, counterclaims, and debates over fundamentals". Historian David Williams describes the resistance to the advocates of a more inclusive United States history that would include the roles of women, African Americans, and the labor movement:
These and other scholarly voices called for a more comprehensive treatment of American history, stressing that the mass of Americans, not simply the power elites, made history. Yet it was mainly white males of the power elite who had the means to attend college, become professional historians, and shape a view of history that served their own class, race, and gender interests at the expense of those not so fortunate — and quite literally to paper over aspects of history they found uncomfortable. "One is astonished in the study of history", wrote Du Bois in 1935, "at the recurrence of the idea that evil must be forgotten, distorted, skimmed over... The difficulty, of course, with this philosophy is that history loses its value as an incentive and an example; it paints perfect men and noble nations, but it does not tell the truth."
After World War II "a new and more broadly based generation of scholars", as the result of the G.I. Bill, the nationwide expansion of state universities and community colleges, and the feminist movement, civil rights movement, and American Indian Movement, expanded the scope of American history.
If there were a universally accepted view of history that never changed, there would be no need to research it further. Many historians who write revisionist exposés are motivated by a genuine desire to educate and to correct history. Many great discoveries have come as a result of the research of men and women who have been curious enough to revisit certain historical events and explore them again in depth from a new perspective. Historian Arthur M. Schlesinger Jr., in contrasting the United States with the Soviet Union during the Cold War, wrote:
But others, especially in the United States ... represent what American historians call "revisionism" — that is a readiness to challenge official explanations. No one should be surprised by this phenomenon. Every war in American history has been followed in due course by skeptical reassessments of supposedly sacred assumptions ... for revisionism is an essential part of the process by which history, through the posing of new problems and the investigation of new possibilities, enlarges its perspectives and enriches its insights.
Revisionist historians contest the mainstream or traditional view of historical events, they raise views at odds with traditionalists, which must be freshly judged. Revisionist history is often practiced by those who are in the minority, such as feminist historians, ethnic minority historians, those working outside of mainstream academia in smaller and less known universities, or the youngest scholars, essentially historians who have the most to gain and the least to lose in challenging the status quo. In the friction between the mainstream of accepted beliefs and the new perspectives of historical revisionism, received historical ideas are either changed, solidified, or clarified. If over a period of time the revisionist ideas become the new establishment "status quo" a paradigm shift is said to have occurred. Historian Forrest McDonald is often critical of the turn that revisionism has taken but he nevertheless admits that the turmoil of the 1960s in the United States changed the way history was written. He wrote:
The result, as far as the study of history was concerned, was an awakened interest in subjects that historians had previously slighted. Indian history, black history, women’s history, family history, and a host of specializations arose. These expanded horizons enriched our understanding of the American past, but they also resulted in works of special pleading, trivialization, and downright falsification.
Historians, like all people, are inexorably influenced by the "zeitgeist" (the spirit of the times). Historian C. Vann Woodward sees this as a positive influence. Speaking of the changes that occurred after the end of World War II, he wrote:
These events have come with a concentration and violence for which the term "revolution" is usually reserved. It is a revolution, or perhaps a set of revolutions for which we have not yet found a name. My thesis is that these developments will and should raise new questions about the past and affect our reading of large areas of history, and my belief is that future revisions may be extensive enough to justify calling the coming age of historiography an age of reinterpretation. The first illustration [the absence from United States’ history of external threats due to its geographic isolation] happens to come mainly from American history, but this should not obscure the broader scope of the revolution, which has no national limitations.
Developments in other academic areas, and cultural and political fashions, all help to shape the currently accepted model and outlines of history (the accepted historiographical paradigm). For example, philosopher Karl Popper echoed Woodward’s sentiments regarding revisionism when he noted that "each generation has its own troubles and problems, and therefore its own interests and its own point of view" and:
It follows that each generation has a right to look upon and re-interpret history in its own way... After all, we study history because we are interested in it, and perhaps because we wish to learn something about our problems. But history can serve neither of these two purpose if, under the influence of an inapplicable idea of objectivity, we hesitate to present historical problems from our point of view. And we should not think that our point of view, if consciously and critically applied to the problem, will be inferior to that of a writer who naively believes ... that he has reached a level of objectivity permitting him to present "the events of the past as they actually did happen".
As time passes and these influences change so do most historians views on the explanation of historical events. The old consensus may no longer be considered by most historians to explain how and why certain events in the past occurred, and so the accepted model is revised to fit in with the current agreed-upon version of events. For example, historian John Hope Franklin in 1986 described four specific stages in the historiography of African American that were based on different consensus models.
Revisionism vs. denial.
Deborah Lipstadt (1993), Michael Shermer, and Alex Grobman (2000), authors of critical studies of Holocaust denial, make a distinction between revisionism and denial. Lipstadt notes that Holocaust deniers such as Harry Elmer Barnes often refer to themselves as revisionists so as to obscure their denialism under a guise of academic revision. In the view of Lipstadt, Shermer, and Grobman, legitimate revisionism entails a refinement of existing knowledge about a historical event, not a denial of the event itself, a refinement that comes through the examination of new empirical evidence or a reexamination or reinterpretation of existing evidence. Legitimate historical revisionism acknowledges a 'certain body of irrefutable evidence' or a 'convergence of evidence' that suggest that an event — like the black plague, American slavery, or the Holocaust — did occur. Denial, on the other hand, rejects the entire foundation of historical evidence..."
Influences.
Some of the influences on historians, which may change over time are:
Examples.
These are examples of historical revisionist ideas.
The "Dark Ages".
As non-Latin texts such as Welsh, Gaelic and the Norse sagas have been analysed and added to the canon of knowledge about the period and a lot more archaeological evidence has come to light, the period traditionally known as the Dark Ages has narrowed to the point where many historians no longer believe that such a term is useful. Moreover, the term "dark" implies less of a void of culture and law, but more a lack of many source texts in mainland Europe. Many modern scholars who study the era tend to avoid the term altogether for its negative connotations, finding it misleading and inaccurate for any part of the Middle Ages.
"Feudalism".
The concept of feudalism has been questioned. Revisionist scholars led by historian Elizabeth A. R. Brown have rejected the term.
Agincourt.
For centuries, historians thought the Battle of Agincourt was an engagement in which the English army, though overwhelmingly outnumbered four to one by the French army, pulled off a stunning victory—a version especially popularised by Shakespeare's play Henry V. However, recent research by Professor Anne Curry using the original enrollment records, has brought into question this interpretation. Though her research is not finished, she has published her initial findings, that the French only outnumbered the English and Welsh 12,000 to 8,000. If true, the numbers may have been exaggerated for patriotic reasons by the English.
New World discovery.
In recounting the European colonization of the Americas, some history books of the past paid little attention to the indigenous peoples of the Americas, usually mentioning them only in passing and making no attempt to understand the events from their point of view. This was reflected in the description of Christopher Columbus having discovered America. The portrayal of these events has since been revised, and much present scholarship examines the impact of European exploration and colonization on indigenous peoples ("see" Postcolonialism). Historians like Kirkpatrick Sale and James Loewen exemplify Columbian revisionism.
French attack formations in the Napoleonic wars.
The military historian James R. Arnold argues that:
The writings of Sir Charles Oman and Sir John Fortescue dominated subsequent English-language Napoleonic history. Their views [that the French infantry used heavy columns to attack lines of infantry] became very much the received wisdom... By 1998 a new paradigm seemed to have set in with the publication of two books devoted to Napoleonic battle tactics. Both claimed that the French fought in line at Maida and both fully explored French tactical variety. The 2002 publication of "The Battle of Maida 1806: Fifteen Minutes of Glory", appeared to have brought the issue of column versus line to a satisfactory conclusion: "The contemporary sources are ... the best evidence and their conclusion is clear: General Compère's brigade formed into line to attack Kempt's Light Battalion." The decisive action at Maida took place in less than fifteen minutes. It had taken 72 years to rectify a great historian's error about what transpired during those minutes.
Military leadership during World War I.
The military leadership of the British Army during the World War I was frequently condemned as poor by historians and politicians for decades after the war ended. Common charges were that the generals commanding the army were blind to the realities of trench warfare, ignorant of the conditions of their men and were unable to learn from their mistakes, thus causing enormous numbers of casualties ('lions led by donkeys'). However, during the 1960s historians such as John Terraine began to challenge this interpretation. In recent years as new documents have come forth and the passage of time has allowed for more objective analysis, historians such as Gary D. Sheffield and Richard Holmes observe that the military leadership of the British Army on the Western Front had to cope with many problems that they could not control such as a lack of adequate military communications, which was not known before. Furthermore, military leadership improved throughout the war culminating in the Hundred Days Offensive advance to victory in 1918. Some historians, even revisionists, still criticise the British High Command severely, but they are less inclined to portray the war in a simplistic manner with brave troops being led by foolish officers.
There has been a similar movement regarding the French Army during the war with contributions by historians such as Anthony Clayton. Revisionists are far more likely to view commanders such as French General Ferdinand Foch, British General Douglas Haig and other figures, such as American General Pershing, in a sympathetic light.
Reconstruction in U.S..
Revisionist historians of Reconstruction after the U.S. Civil War rejected the dominant Dunning School that stated the blacks were used by Carpetbaggers, and instead has stressed economic greed on the part of northern businessmen. Indeed, in recent years a "neoabolitionist" revisionism has become standard, that uses the moral standards of racial equality of the 19th century abolitionists to criticize racial policies. "Foner's book represents the mature and settled Revisionist perspective," historian Michael Perman has concluded regarding Eric Foner's "Reconstruction: America's Unfinished Revolution, 1863–1877" (1988)
German guilt in causing World War I.
In reaction to the orthodox interpretation enshrined in the Versailles Treaty (which declared that Germany was guilty of starting World War I), the self-described "revisionist" historians of the 1920s rejected the orthodox view and presented a complex causation in which several other countries were equally guilty. Intense debate continues among scholars (see Causes of World War I).
Guilt for causing World War II.
The orthodox interpretation blamed Hitler and Nazi Germany, and Imperial Japan, for causing the war (see Causes of World War II). Revisionist historians of World War II, notably Charles A. Beard, said the U.S. was partly to blame because it pressed the Japanese too hard in 1940–41 and rejected compromises. British historian A. J. P. Taylor ignited a firestorm when he argued that Hitler was a rather ordinary diplomat and did not deliberately set out to cause a war.
The American conservative, Patrick Buchanan, argued that the British-French guarantee to Poland in 1939 encouraged Poland not to seek a compromise over Danzig, though Britain and France were in no position to come to Poland's aid, and Hitler was offering the Poles an alliance in return. He argues that they thereby turned a minor border dispute into a catastrophic world conflict, and handed East Europe, including Poland, to Stalin.
American Business and the "Robber Barons".
The role of American business and the alleged "robber barons" began to be revised in the 1930s. Termed "business revisionism" by Gabriel Kolko, historians such as Allan Nevins, and, later, Alfred D. Chandler emphasized the positive contributions of individuals who were previously pictured as villains. Peter Novick writes, "The argument that whatever the moral delinquencies of the robber barons, these were far outweighed by their decisive contributions to American military [and industrial] prowess, was frequently invoked by Allan Nevins."
Cold War.
In the Historiography of the Cold War a debate exists between historians advocating an "orthodox" and "revisionist" interpretation of Soviet history and other aspects of the cold war such as the Vietnam War.
Vietnam War.
"America in Vietnam" by Guenter Lewy is an example of historical revisionism that substantially differs from the popular view of America's role in the Vietnam War. Lewy's work was the first of a body of work by other historians that form the revisionist school with respect to the behavior and role of the United States in the Vietnam War. Other reinterpretations that attempt to offer alternative explanations for American behavior include those by Norman Podhoretz, Mark Moyar, and Michael Lind. "America in Vietnam" attracted both criticism and support of Lewy for belonging to the "revisionist" school on Vietnam. According to Lewy:It is the reasoned conclusion of this study... that the sense of guilt created by the Vietnam war in the minds of many Americans is not warranted and that the charges of "officially, condoned" illegal and grossly immoral conduct are without substance. Indeed, detailed examination of battlefield practices reveals that the loss of civilian life in Vietnam was less great than in World War II and Korea and that concern with minimizing the ravages of the war was strong. To measure and compare the devastation and loss of human life caused by different war will be objectionable to those who repudiate all resort to military force as an instrument of foreign policy and may be construed as callousness. Yet as long as wars do take place at all it remains a moral duty to seek to reduce the agony caused by war, and the fulfillment of this obligation should not be disdained.

</doc>
<doc id="13294" url="http://en.wikipedia.org/wiki?curid=13294" title="History of the petroleum industry in the United States">
History of the petroleum industry in the United States

The history of the petroleum industry in the United States goes back to the early 19th century, although the indigenous peoples, like many ancient societies, have used petroleum seeps since prehistoric times; where found, these seeps signaled the growth of the industry from the earliest discoveries to the more recent. Petroleum became a major industry following the oil discovery at Oil Creek Pennsylvania in 1859. For much of the 19th and 20th centuries, the US was the largest oil producing country in the world; it is now the 3rd largest.
Before the Drake well.
Indians had known of the oil in western Pennsylvania, and had made some use of it for many years before the mid-19th century. Early European explorers noted seeps of oil and natural gas in western Pennsylvania and New York. Interest grew substantially in the mid-1850s as scientists reported on the potential to manufacture kerosene from crude oil, if a sufficiently large oil supply could be found.
The Jesuit Relations of 1657 states:
As one approaches nearer to the country of the Cats, one finds heavy and thick water, which ignites like brandy, and boils up in bubbles of flame when fire is applied to it. It is, moreover, so oily, that all our Savages use it to anoint and grease their heads and their bodies.
Salt was a valuable commodity, and an industry developed near salt springs in the Ohio River Valley, producing salt by evaporating brine from the springs. Salt wells were sunk at the salt springs to increase the supply of brine for evaporation. Some of the wells were hand-dug, but salt producers also learned to drill wells by percussion (cable tool) methods. In a number of locations in western Virginia, Ohio, and Kentucky, oil and natural gas came up the wells along with the brine. The oil was mostly a nuisance, but some salt producers saved it and sold it as illuminating oil or medicine. In some locations, enough natural gas was produced to be used as fuel for the salt evaporating pans. Early salt brine wells that produced byproduct oil included the Thorla-McKee Well of Ohio in 1814, a well near Burkesville, Kentucky, in 1828, and wells at Burning Springs, West Virginia, by 1836.
The US natural gas industry started in 1821 at Fredonia, Chautauqua County, New York, when William Hart dug a well to a depth of 27 ft into gas-bearing shale, then drilled a borehole 43 ft further, and piped the natural gas to a nearby inn where it was burned for illumination. Soon many gas wells were drilled in the area, and the gas-lit streets of Fredonia became a tourist attraction.
Drake well, Titusville, Pennsylvania.
On August 28, 1859, George Bissell and Edwin L. Drake made the first successful use of a drilling rig on a well drilled especially to produce oil, at a site on Oil Creek near Titusville, Pennsylvania. 
The Drake well is often referred to as the "first" commercial oil well, although that title is also claimed for wells in Azerbaijan, Ontario, West Virginia, and Poland, among others. However, before the Drake well, oil-producing wells in the United States were wells that were drilled for salt brine, and produced oil and gas only as accidental byproducts. An intended drinking water well at Oil Springs, Ontario found oil in 1858, a year before the Drake well, but it had not been drilled for oil. Historians have noted that the importance of the Drake well was not in being the first well to produce oil, but in attracting the first great wave of investment in oil drilling, refining, and marketing: 
Appalachian Basin.
The success of the Drake well quickly led to oil drilling in other locations in the western Appalachian mountains, where oil was seeping to the surface, or where salt drillers had previously found oil fouling their salt wells. During the American Civil War, the oil-producing region spread over much of western Pennsylvania, up into western New York state, and down the Ohio River valley into the states of Ohio, Kentucky, and the western part of Virginia (now West Virginia). The Appalachian Basin continued to be the leading oil-producing region in the United States through 1904.
The first commercial oil well in New York was drilled in 1865. New York's (and Northwestern Pennsylvania) crude oil is very high in paraffin.
The principal product of the oil in the 19th century was kerosene, which quickly replaced whale oil for illuminating purposes in the United States. Originally dealing in whale oil which was widely used for illumination, Charles Pratt (1830–1891) of Massachusetts was an early pioneer of the natural oil industry in the United States. He was founder of Astral Oil Works in the Greenpoint section of Brooklyn, New York. Pratt's product later gave rise to the slogan, ""The holy lamps of Tibet are primed with Astral Oil"." He joined with his protégé Henry H. Rogers to form Charles Pratt and Company in 1867. Both companies became part of John D. Rockefeller's Standard Oil in 1874.
Mid-Continent.
The Mid-continent area is an area generally including Kansas, Oklahoma, Arkansas, North Louisiana and the part of Texas away from the Gulf Coast. The first commercially successful oil well drilled in Kansas was the Norman No. 1 near Neodesha, Kansas, on November 28, 1892. 
Oklahoma.
Oil was discovered at Bartlesville and Burbank in 1897. But the initial discoveries created no great excitement until the discovery gusher of the Glenn Pool in 1905. The Glenn discovery came when Gulf Coast production was declining rapidly, and the operators were eager for new areas to drill. The increased drilling resulted in major discoveries at Cushing in 1912 and Healdton in 1913.
East Texas.
The largest oil field in the lower 48 states, the East Texas oil field, was not discovered until 1930, when wildcatter Columbus Marion Joiner (more commonly known as "Dad" Joiner) drilled the Daisy Bradford No. 3 well, in Rusk County, Texas.
North Louisiana.
In 1906, the Caddo-Pine Island Field in northern Caddo Parish, Louisiana was discovered, and a rush of leasing and drilling activity ensued. In 1908, the first natural gas pipeline was constructed to transport gas from Caddo-Pine Island to Shreveport, Louisiana. This was one of the earliest commercial uses of natural gas, which was commonly viewed as an undesirable by-product of oil production and often "flared" or burnt off at the well site.
Other innovations in the Caddo-Pine Island Field included the first over-water oil platform, which was constructed in the field on Caddo Lake in 1910. In that same year, a major oil pipeline was constructed from Caddo-Pine Island Field to a refinery built and operated by Standard Oil Company of Louisiana in Baton Rouge, Louisiana. The refinery continues to operate today.
Other early petroleum discoveries in North Louisiana included the Bull Bayou Field, Red River Parish, Louisiana (1913), Monroe Gas Field, Ouachita Parish, Louisiana (1916), Homer Field, Claiborne Parish, Louisiana (1919) and Haynesville Field, Claiborne Parish, Louisiana (1921).
Gulf Coast.
Capt. Anthony Francis Lucas, an experienced mining engineer and salt driller, drilled a well to find oil at Spindletop Hill. On the morning of January 10, 1901, the little hill south of Beaumont, Texas began to tremble and mud bubbled up over the rotary table. A low rumbling sound came from underground, and then, with a force that shot 6 tons of 4-inch (100 mm) diameter pipe out over the top of the derrick, knocking off the crown block, the Lucas Gusher roared in and the Spindletop oil field was born. Spindletop became the focus of frenzied drilling; oil production from the field peaked in 1902 at 17400000 oilbbl, but by 1905 production had declined 90% from the peak. 
Spindletop Hill turned out to be the surface expression of an underground salt dome, around which the oil accumulated. The Spindletop gusher started serious oil exploration of the Gulf Coast in Texas and Louisiana, an area that had previously been dismissed by oil men. Other salt dome mounds were quickly drilled, resulting in discoveries at Sour Lake (1902), Batson (1904) and Humble (1905).
The Standard Oil Company was slow to appreciate the economic potential of the Spindletop oil field, and the Gulf Coast generally, which gave greater opportunity to others; Spindletop became the birthplace of oil giants Texaco and Gulf Oil. Although in 1899 Standard Oil controlled more than 85% of the oil production in the older oil regions in the Appalachian Basin and the Lima-Indiana trend, it never controlled more than 10% of the oil production in the new Gulf Coast province.
California.
Native Americans had known of the tar seeps in southern California for thousands of years, and used the tar to waterproof their canoes. Spanish settlers also knew of the seeps, such as at Rancho La Brea (Spanish for "Tar Ranch") in present-day Los Angeles, from which the priests obtained tar to waterproof the roofs of the Los Angeles and San Gabriel missions.
Despite the abundance of well-known seeps in southern California, the first commercial oil well in California was drilled in Humboldt County, northern California in 1865.
Some attempts were made in the 1860s to exploit oil deposits under tar seeps in the Ventura Basin of Ventura County and northeastern Los Angeles county. The early efforts failed because of complex geology, and, more importantly, because the refining techniques then available could not manufacture high-quality kerosene from California crude oil, which differed chemically from Pennsylvania crude oil. Most California crude oil in the early years was turned into the less lucrative products of fuel oil and asphalt. 
Oil production in the Los Angeles Basin started with the discovery of the Brea-Olinda Oil Field in 1880, and continued with the development of the Los Angeles City Oil Field in 1893, the Beverly Hills Oil Field in 1900, the Salt Lake Oil Field in 1902, and many others. The discovery of the Long Beach Oil Field in 1921, which proved to be the world's richest in production per-acre of the time, increased the importance of the Los Angeles Basin as a worldwide oil producer. This increased again with the discovery of the Wilmington Oil Field in 1932, and the development of the Port of Los Angeles as a means of shipping crude oil overseas.
Production in Santa Barbara County began in the 1890s with the development of the Summerland Oil Field, which included the world's first offshore oil wells. With the discovery of the Orcutt and Lompoc fields, northern Santa Barbara County became a regional center of production; towns such as Orcutt owe their existence to the quickly growing industry.
Oil in the San Joaquin Basin was first discovered at the Coalinga field in 1890. By 1901, the San Joaquin Basin was the main oil-producing region of California, and it remains so in the 21st century, with huge oil fields including the Midway-Sunset, Kern River, and Belridge fields producing much of California's onshore oil.
Rocky Mountains.
The first commercial oil well in the Rocky Mountains was drilled near Canon City, Colorado in 1862. The wells in the Canyon City-Florence field, drilled near surface oil seeps, produced from fractures in the Pierre Shale. 
Alaska.
A Russian sea captain noted oil seeps along the shore of the Cook Inlet as early as 1853, and oil drilling began in 1898 in a number of locations along the southern coast of Alaska. Production was relatively small, however, until huge discoveries were made on Alaska's remote North Slope.
Petroleum seeps on the North Slope have been known for many years, and in 1923, the federal government created US Naval Petroleum Reserve No. 4 to cover the presumed oil fields beneath the seeps. Some exploration drilling was done in the reserve during World War II and the 1950s, but the remote location deterred intensive exploration until the 1960s. The Prudhoe Bay Oil Field, the largest oil field in the United States in terms of total oil produced, was discovered in 1968. Production began in 1977, following completion of the Trans-Alaska Pipeline. Through 2005, the field has produced 13 Goilbbl of oil (an average of 1.5 million barrels/day), and is estimated to contain another 2 Goilbbl of economically recoverable oil.
North Dakota.
As of December, 2012, North Dakota was producing oil at the rate of 750,000 barrels/day.
Federal price regulation.
By the Natural Gas Act of 1938, the federal government imposed price controls on natural gas in interstate commerce. The Federal Power Commission was mandated to set interstate gas prices at "just and reasonable" rates. The FPC at first only regulated the price at which pipelines sold gas to utilities and industry, but later put limits on the wellhead price of gas sold to an interstate pipeline. Gas producers challenged the controls, but lost in the Supreme Court in Phillips Petroleum Co. v. Wisconsin (1954). 
The federal government had controlled the price of natural gas that crossed state lines, but not of gas produced and sold within a state. In the 1970s, the low interstate price set by the federal government caused supply shortages of gas in consuming states, because gas producers sold as much as they could of their product for higher prices in the local markets within gas-producing states. In the Natural Gas Policy Act of 1978, the federal government extended price controls to all natural gas in the country. At the same time, the government created a complex price system in which the price paid to the producer depended on the date the well was drilled, the depth of the well, the geological formation, the distance to other gas wells, and several other factors. The price system was an attempt to keep the average price low while encouraging new production.
The last federal price controls on natural gas were removed by the Natural Gas Decontrol Act of 1989, which phased out the last remaining price control as of 1 January 1993.

</doc>
<doc id="13297" url="http://en.wikipedia.org/wiki?curid=13297" title="Hudson's Bay Company">
Hudson's Bay Company

The Hudson's Bay Company (HBC; French: "Compagnie de la Baie d'Hudson"), commonly referred to as "The Bay" ("La Baie" in French), is a Canadian retail business group. A fur trading business for much of its existence, today Hudson's Bay Company owns and operates retail stores throughout Canada and the United States, including Hudson's Bay, Home Outfitters, Lord & Taylor, Saks Fifth Avenue and Saks Fifth Avenue OFF 5TH. HBC's head office is in the Simpson Tower in Toronto, Ontario. The company is owned by the New York-based firm NRDC Equity Partners.
The company was incorporated by English royal charter in 1670 as The Governor and Company of Adventurers of England trading into Hudson's Bay and functioned as the "de facto" government in parts of North America before European states and later the United States laid claim to some of those territories. It was at one time the largest landowner in the world, with the area of the Hudson Bay watershed, known as Rupert's Land, having 15% of North American acreage. From its long-time headquarters at York Factory on Hudson Bay, the company controlled the fur trade throughout much of the English and later British controlled North America for several centuries. Undertaking early exploration, its traders and trappers forged early relationships with many groups of aboriginal peoples. Its network of trading posts formed the nucleus for later official authority in many areas of Western Canada and the United States. In the late 19th century, with the signing of the Deed of Surrender, its vast territory became the largest component in the newly formed Dominion of Canada, in which the company was the largest private landowner.
With the decline of the fur trade, the company evolved into a mercantile business selling vital goods to settlers and prospectors in the Canadian West who "quickly introduced a new type of client to the HBC – one that shopped with cash and not with skins"; the retail era had begun as the HBC began establishing retail stores across cities in the prairies. With the sale of its Northern Stores and Fur Sales Departments in 1987, the HBC completely removed itself from the fur trade.
The Hudson's Bay Company Archives (HBCA), a collection of the company's many records and maps, are located in Winnipeg, Manitoba. Along with company records, the HBCA also manages collections of private records which includes the records of "related and/or subsidiary companies and individuals." The HBCA is a division of the Archives of Manitoba.
In July 2008, the company, after a series of change of ownership, was eventually acquired by the American private equity firm, NRDC Equity Partners, which also owned department store chain Lord & Taylor. From 2008 to 2012, the HBC was run through a holding company of NRDC, Hudson's Bay Trading Company, which was dissolved on 23 January 2012. Since 2012, The HBC directly oversees the operations of Lord & Taylor in the United States in addition to its Canadian subsidiaries Hudson's Bay (formerly The Bay) and Home Outfitters. On 29 July 2013, the HBC announced a friendly takeover of Saks, Inc., operator of the Saks Fifth Avenue department store chain, which was completed on 3 November 2013.
History.
17th century.
In the 17th century the French had a "de facto" monopoly on the Canadian fur trade. However, two French traders, Pierre-Esprit Radisson and Médard des Groseilliers (Médard de Chouart, Sieur des Groseilliers), Radisson's brother-in-law, learned from the Cree that the best fur country lay north and west of Lake Superior and that there was a "frozen sea" still further north. Assuming that this was Hudson Bay, they sought French backing for a plan to set up a trading post on the Bay, thus reducing the cost of moving furs overland. According to Peter C. Newman, "concerned that exploration of the Hudson Bay route might shift the focus of the fur trade away from the St. Lawrence River, the French governor", Marquis d'Argenson (in office 1658-1661), "refused to grant the coureurs de bois permission to scout the distant territory". Despite this refusal, in 1659 Radisson and Groseilliers set out for the upper Great Lakes basin. A year later they returned from their expedition with premium furs, evidence of the potential of the Hudson Bay region. Subsequently they were arrested for trading without a licence and fined, and their furs were confiscated.
Determined to establish trade in the Hudson Bay, Radisson and Groseilliers approached a group of business men in Boston, Massachusetts to help finance their explorations. The Bostonians agreed on the plan's merits but their speculative voyage in 1663 failed when their ship ran into pack ice in Hudson Strait. This came to the attention of Boston-based English commissioner Colonel George Cartwright, who brought the two to England to elicit financing. Radisson and Groseilliers arrived in London in 1665 at the height of the Great Plague. Eventually, the two met and received the sponsorship of Prince Rupert. Prince Rupert also introduced the two to his cousin, King Charles II. In 1668 the English acquired two ships, the "Nonsuch" and the "Eaglet", to explore possible trade into Hudson Bay. Groseilliers sailed on the "Nonsuch", commanded by Captain Zachariah Gillam, while the "Eaglet" was commanded by Captain William Stannard and accompanied by Radisson. On 5 June 1668, both ships left port at Deptford, England, but the "Eaglet" was forced to turn back off the coast of Ireland.
The "Nonsuch" continued to James Bay, the southern portion of Hudson Bay, where its explorers founded the first fort on Hudson Bay, Charles Fort (later Rupert House, now Waskaganish, Quebec), at the mouth of the Rupert River. Both the fort and the river were named after the sponsor of the expedition, Prince Rupert of the Rhine, one of the major investors and soon to be the new company's first governor. After a successful trading expedition over the winter of 1668–1669, the "Nonsuch" returned to England on 9 October 1669 with the first cargo of fur resulting from trade in Hudson Bay. The bulk of the fur - worth £1,233 - was sold to Thomas Glover, one of London's most prominent furriers. This and subsequent purchases by Glover made it clear that the fur trade in Hudson Bay was indeed viable.
The Governor and Company of Adventurers of England Trading into Hudson's Bay was incorporated on 2 May 1670, with a royal charter from King Charles II. The charter granted the company a monopoly over the region drained by all rivers and streams flowing into Hudson Bay in northern Canada. The area gained the name "Rupert's Land" after Prince Rupert, the first governor of the company appointed by the King. This drainage basin of Hudson Bay constitutes 1.5 e6sqmi, comprising over one-third of the area of modern-day Canada and stretches into the present-day north-central United States. The specific boundaries were unknown at the time. Rupert's Land would eventually become Canada's largest land "purchase" in the 19th century.
The HBC established six posts between 1668 and 1717. Rupert House (1668, southeast), Moose Factory (1673, south) and Fort Albany, Ontario (1679, west) were erected on James Bay; three other posts were established on the western shore of Hudson Bay proper: Fort Severn (1689), York Factory (1684) and Fort Churchill (1717). Inland posts were not built until 1774. After 1774, York Factory became the main post because of its convenient access to the vast interior waterway systems of the Saskatchewan and Red rivers. Called "factories" (because the "factor," i.e., a person acting as a mercantile agent did business from there), these posts operated in the manner of the Dutch fur trading operations in New Netherlands.
During the fall and winter, First Nations and trappers did the vast majority of the animal trapping and pelt preparation. They travelled by canoe and on foot to the forts to sell their pelts. In exchange they typically received popular trade goods such as knives, kettles, beads, needles, and the Hudson's Bay point blanket. The arrival of the First Nations trappers was one of the high points of the year, met with pomp and circumstance. The highlight was very formal, an almost ritualized "Trading Ceremony" between the Chief Trader and the Captain of the aboriginal contingent who traded on their behalf. During the initial years of the fur trade, prices for items varied from post to post. With the adoption of Standard of Trade in the 18th century, the HBC ensured consistent pricing throughout Rupert's Land. A means of exchange arose based on the Made Beaver (MB); a prime pelt, worn for a year and ready for processing: "the prices of all trade goods were set in values of Made Beaver (MB) with other animal pelts, such as squirrel, otter and moose quoted in their MB (made beaver) equivalents. For example, two otter pelts might equal 1 MB".
The early coastal factory model contrasted with the system of the French, who established an extensive system of inland posts and sent traders to live among the tribes of the region. In March 1686, the French sent a raiding party under the Chevalier des Troyes over 1,300 km to capture the HBC posts along James Bay. The French appointed Pierre Le Moyne d'Iberville, who had shown great heroism during the raids, as commander of the company's captured posts. In 1687 an English attempt to resettle Fort Albany failed due to ruses and deceptions by d'Iberville. After 1688 England and France were officially at war. D'Iberville raided Fort Severn in 1690 but did not attempt to raid the well-defended local headquarters at York Factory. In 1693 the company recovered Fort Albany; d'Iberville captured York Factory in 1694, but the company recovered it the next year. In 1697, d'Iberville again commanded a French naval raid on York Factory. On the way to the fort, he defeated three ships of the Royal Navy in the Battle of Hudson's Bay (5 September 1697), the largest naval battle in the history of the North American Arctic. D'Iberville's depleted French force captured York Factory by a ruse; they laid siege to the fort while pretending to be a much larger army, the French held all of the outposts except Fort Albany until 1713. (Fort Albany was again unsuccessfully attacked in 1709 by a small French and Indian force.) The economic consequences of the French possession to the company were significant; it did not pay any dividends for more than 20 years. See Anglo-French conflicts on Hudson Bay.
18th century.
The war ended in 1713 with the signing of the Treaty of Utrecht. Among its many provisions, the Treaty required France to relinquish all claims to Hudson Bay, which again became a British possession. The Kingdom of Great Britain had been established (following the union of Scotland and England in 1707). After the treaty, the company built Prince of Wales Fort, a stone star fort at the mouth of the nearby Churchill River. In 1782, during the American Revolutionary War, a French squadron under Jean-François de Galaup, comte de Lapérouse captured and demolished York Factory and Prince of Wales Fort.
In its trade with native peoples, Hudson's Bay Company exchanged wool blankets, called Hudson's Bay point blankets, for the beaver pelts trapped by aboriginal hunters. By 1700, point blankets accounted for over 60% of the trade. The number of indigo stripes (a.k.a. points) woven into the blankets identified its finished size. A long-held misconception is that the number of stripes is related to its value in beaver pelts.
A parallel may be drawn between the HBC's control over Rupert's Land with the trade monopoly and government functions enjoyed by the Honourable East India Company over India during roughly the same period. Viewed as a major competitor, the HBC invested £10,000 in the East India Company in 1732.
Hudson's Bay Company's first inland trading post was established by Samuel Hearne in 1774 in Cumberland House, Saskatchewan.
In 1779, the North West Company (NWC) was founded in Montreal as a seasonal partnership to provide more capital and to continue competing with the HBC. It became operative for the outfit of 1780 and was the first joint stock company in Canada and possibly North America. The agreement lasted one year. A second agreement established in 1780 had a three-year term. The company became a permanent entity in 1783. By 1784, the NWC had begun to have a serious impact on the HBC's profits.
19th century.
In 1821, the North West Company of Montreal and Hudson's Bay Company were forcibly merged by intervention of the British government to put an end to often-violent competition. A total of 175 posts, 68 of them the HBC's, were reduced to 52 for efficiency and because many were redundant as a result of the rivalry and were inherently unprofitable. Their combined territory was extended by a licence to the North-Western Territory, which reached to the Arctic Ocean in the north and, with the creation of the Columbia Department in the Pacific Northwest, to the Pacific Ocean in the west. The NWC's regional headquarters at Fort George (Fort Astoria) was relocated to Fort Vancouver, which became the HBC base of operations on the Pacific Slope.
Before the merger, the employees of the HBC, unlike the North West Company, did not participate in its profits. After the merger, with all operations under the management of Sir George Simpson (1826–1860), the company had a corps of commissioned officers, 25 chief factors and 28 chief traders, who shared in the profits of the company during the monopoly years. Its trade covered 7,770,000 km2, and it had 1,500 contract employees.:8–23
The progression for officers, together referred to as the Commissioned Gentlemen, was to enter the company as a fur trader. Typically, they were men who had the capital to invest in starting up their trading. They sought to be promoted to the rank of Chief Trader. A Chief Trader would be in charge of an individual post and was entitled to one share of the profits of the company. Chief Factors sat in council with the Governors and were the heads of districts. They were entitled to two shares of the profits or the losses of the company. The average income of a Chief Trader was £360 and that of a Chief Factor was £720.:690
Although the HBC maintained a monopoly on the fur trade during the early to mid-19th century there was competition from James Sinclair and Andrew McDermot (Dermott), independent traders in the Red River Colony. They shipped furs by the Red River Trails to Norman Kittson:60–72 a buyer in the United States. In addition, Americans controlled the Maritime fur trade on the Northwest Coast until the 1830s.
Throughout the 1820s and 1830s, the HBC controlled nearly all trading operations in the Pacific Northwest, based at the company headquarters at Fort Vancouver on the Columbia River. Although claims to the region were by agreement in abeyance, commercial operating rights were nominally shared by the United States and Britain through the Anglo-American Convention of 1818, company policy, enforced via Chief Factor John McLoughlin of the company's Columbia District, was to discourage U.S. settlement of the territory. The company's effective monopoly on trade virtually forbade any settlement in the region. It established Fort Boise in 1834 (in present-day southwestern Idaho) to compete with the American Fort Hall, 483 km to the east. In 1837, it purchased Fort Hall, also along the route of the Oregon Trail, where the outpost director displayed the abandoned wagons of discouraged settlers to those seeking to move west along the trail.
The company's stranglehold on the region was broken by the first successful large wagon train to reach Oregon in 1843, led by Marcus Whitman. In the years that followed, thousands of emigrants poured into the Willamette Valley. In 1846, the United States acquired full authority south of the 49th parallel; the most settled areas of the Oregon Country were south of the Columbia River in what is now Oregon. McLoughlin, who had once turned away would be settlers as company director, then welcomed them from his general store at Oregon City and was later proclaimed the "Father of Oregon". The company retains no presence today in what is now the United States portion of the Pacific Northwest.
During the 1820s and 1830s, HBC trappers were deeply involved in the early exploration and development of Northern California. Company trapping brigades were sent south from Fort Vancouver, along what became known as the Siskiyou Trail, into Northern California as far south as the San Francisco Bay Area where the company operated a trading post at Yerba Buena (San Francisco). These trapping brigades in Northern California faced serious risks, and were often the first to explore relatively uncharted territory.
Between 1820 and 1870, the HBC issued its own paper money. The notes, denominated in pounds sterling, were printed in London and issued at the York Factory, Fort Garry and the Red River Colony.
The Guillaume Sayer Trial in 1849 contributed to the end of the HBC monopoly. Sayer, a Métis trapper and trader, was accused of the illegal trading of furs. The Court of Assiniboia brought Sayer to trial, before a jury of HBC officials and supporters. During the trial, a crowd of armed Métis men led by Louis Riel, Sr. gathered outside the courtroom. Although Sayer was found guilty of illegal trade, having evaded the HBC monopoly, Judge Adam Thom did not levy a fine or punishment. Some accounts attributed that to the intimidating armed crowd gathered outside the courthouse. With the cry, "Le commerce est libre! Le commerce est libre!" ("Trade is free! Trade is free!"), the Métis loosened the HBC's previous control of the courts, which had enforced their monopoly on the settlers of Red River.
Another factor was the findings of the Palliser Expedition of 1857 to 1860, led by Captain John Palliser. Although he recommended against settlement of the region the report sparked a debate. That ended the myth publicized by Hudson's Bay Company that the Canadian West was unfit for agricultural settlement. In 1863, the International Financial Society became the majority shareholders of the HBC.
In 1869, after rejecting the American government offer of CA$, the company approved the return of Rupert’s Land to Britain which in turn gave it to Canada and loaned the new country the £300,000 required to compensate HBC for its losses. The deal, known as The Deed of Surrender, came into force the following year. The resulting territory, now known as the Northwest Territories, was brought under Canadian jurisdiction under the terms of the Rupert's Land Act 1868, enacted by the Parliament of the United Kingdom. The Deed enabled the admission of the fifth province, Manitoba, to the Confederation on 15 July 1870, the very same day that the deed itself came into force.
During the 19th century the Hudson Bay's Company was going through a lot of change such as growth and settlement, ongoing pressure from Britain, and the future of the West seemed unlikely to remain in the hands of the company.
Rent obligation under charter.
Under the charter establishing Hudson's Bay Company, the company was required to give two elk skins and two black beaver pelts to the English king, then Charles II, or his heirs, whenever the monarch visited Rupert's Land. The exact text from the 1670 Charter reads:
"...Yielding and paying yearly to us and our heirs and successors for the same two Elks and two Black beavers whensoever and as often as We, our heirs and successors shall happen to enter into the said Countries, Territories and Regions hereby granted."
The ceremony was first conducted with the Prince of Wales (the future Edward VIII) in 1927, then with King George VI in 1939, and last with his daughter, Queen Elizabeth II in 1959 and 1970. On the last such visit, the pelts were given in the form of two live beavers, which the Queen donated to the Winnipeg Zoo in Assiniboine Park.[10] However, when the company permanently moved its headquarters to Canada, the Charter was amended to remove the rent obligation.[11] Each of the four "rent ceremonies" took place in or around Winnipeg.
Rivals.
The HBC is the only European trading company to have survived and outlived all its rivals.
Store operations.
Department stores and diversification.
By the late 18th century, the HBC expanded into the interior and set-up posts along the river settlements that later developed into the modern cities of Winnipeg, Calgary and Edmonton. In 1857, the first sales shop was established in Fort Langley. This was followed by other sales shops in Victoria, Winnipeg, Calgary, Vancouver, Vernon, Edmonton, Yorkton, and Nelson. The first of the grand "original six" department stores was built in Calgary in 1913. The other department stores that followed were in Edmonton, Vancouver, Victoria, Saskatoon, and Winnipeg.
The First World War interrupted a major remodelling and restoration of retail trade shops planned in 1912. Following the war, the company revitalized its fur-trade and real-estate activities, and diversified its operations by venturing into the oil business.
During the early years of the 20th century, demand for general merchandise increased, and stores were first operated from the trading posts that were established across northern Canada. Many HBC stores were the only stores in remote Canadian towns. Today, the department store business is the only remaining part of the company's operations, in the form of department stores under the Hudson's Bay brand. The company exited the fur trade and retail in northern and remote communities in 1987.
Oil and gas operations.
The company co-founded Hudson's Bay Oil and Gas Company (HBOG) in 1926 with Marland Oil Company (which merged with Conoco in 1929). HBOG expanded during the 1940s and 1950s, and in 1960 began shipping Canadian crude through a new link to the Glacier pipeline and on to the refinery in Billings, Montana. The company became the sixth-largest Canadian oil producer in 1967. In 1973, HBOG acquired a 35% stake in Siebens Oil and Gas, and, in 1979, it divested that interest. In 1980, it bought a controlling interest in Roxy Petroleum. In the 1980s, sales and oil prices slipped, while debt from acquisitions piled up which led to Hudson's Bay Company selling its 52.9% stake in HBOG to Dome Petroleum in 1981.
Retail expansion.
In 1960, the company acquired Morgan's allowing it to expand into Montreal, Toronto, Hamilton, and Ottawa. In 1965, HBC rebranded all its department stores as The Bay. The Morgan's logo was changed to match the new visual identity. But by 1972 the last of the former Morgan’s stores had been rebranded to Bay stores.
In 1970, on the 300th anniversary of the company, as a result of punishing new British tax laws, the company relocated to Canada, and was rechartered as a Canadian business corporation under Canadian law, Head Office functions were transferred from London to Winnipeg. By 1974, as the company expanded into eastern Canada, head office functions were moved to Toronto.
In 1972, the company acquired the four-store Shop-Rite chain of catalogue stores. The chain was quickly expanded to 65 stores in Ontario, but closed in 1982 due to declining sales. In these stores, little merchandise was displayed; customers made their selections from catalogues, and staff would retrieve the merchandise from storerooms. The HBC also acquired Freimans department stores in Ottawa and converted them to the Bay.
In 1978, the Zellers discount store chain made a bid to acquire the HBC, but the HBC turned the tables and acquired Zellers instead. Also in 1978, Simpson's department stores were acquired by Hudson's Bay Company, and were converted to Bay stores in 1991. (The related chain Simpsons-Sears was not acquired by the Bay, but became Sears Canada in 1978.) By 1991, Simpsons, originally operated as a stand-alone premium retail banned, had disappeared, having been folded into the Bay.
In 1979, Canadian billionaire Kenneth Thomson won control of the company in a battle with George Weston Limited, and acquired a 75% stake for $400 million. Thomson sold the company's oil and gas business, financial services, distillery, and other interests for approximately $550 million, transforming the company into a leaner, more focused operation. In 1997, the Thomson family sold the last of its remaining shares.
Hudson's Bay Company reversed a formidable debt problem in 1987, by shedding non-strategic assets such as its wholesale division and getting completely out of the oil and gas business. HBC also sold its Canadian fur-auction business to Hudson's Bay Fur Sales Canada. (This company is now known as North American Fur Auctions.) The Northern Stores Division was sold that same year to a group of investors and employees, which adopted The North West Company name three years later.
The HBC acquired Towers Department Stores in 1990, combining them with the Zellers chain, and Woodward's stores in 1993, converting them into Bay or Zellers stores. Kmart Canada was acquired in 1998 and merged with Zellers.
In 1991, the Bay agreed to stop retailing fur in response to complaints from people opposed to killing animals for this purpose. In 1997, the Bay reopened its fur salons to meet the demand of consumers. Animal rights groups, such as People for the Ethical Treatment of Animals (PETA) and Freedom for Animals, continue to try and induce retailers like HBC to stop selling furs, with varying success.
From 2004 to 2008, the HBC owned and operated a small chain of off-price stores called Designer Depot. Similar to the Winners and HomeSense retail format, Designer Depot did not meet sales expectations, and its nine stores were sold. Another HBC chain, Fields, was sold to a private firm in 2012. Established in 1950, Fields was acquired by Zellers in 1976. When Zellers was acquired by HBC in 1978, Fields became part of the HBC portfolio. Zellers is still owned by HBC but as been reduced to a chain of two liquidation stores following the successful sale of its lease portfolio to Target in 2011.
On 29 July 2013, Hudson's Bay Company announced that it would buy Saks Incorporated for USD 2.9 billion.
Purchase by American interests, 2003.
In December 2003, Maple Leaf Heritage Investments, a Nova Scotia-based company created to acquire shares of Hudson's Bay Company, announced that it was considering making an offer to acquire all or some of the common shares of Hudson's Bay Company. Maple Leaf Heritage Investments is a subsidiary of B-Bay Inc. Its CEO and chairman is American businesswoman, Anita Zucker, widow of Jerry Zucker. Zucker had previously been the head of the Polymer Group, which acquired another Canadian institution, the Dominion Textile Company.
On 26 January 2006, the HBC's board unanimously agreed to a bid of $15.25 CAD/share from Jerry Zucker whose original bid was $14.75 CAD/share, ending a prolonged fight between the HBC and Zucker. The South Carolina billionaire financier was a longtime HBC minority shareholder. In a 9 March 2006 press release, the HBC announced that Zucker would replace Yves Fortier as Governor and George Heller as CEO, becoming the first US citizen to lead the company. After Jerry Zucker's death the board named his widow, Anita Zucker, as HBC Governor and HBC Deputy-Governor Rob Johnston as CEO.
On 16 July 2008, the company was sold to NRDC Equity Partners, a private equity firm based in Purchase, New York which already owned Lord & Taylor, the oldest department store chain in the United States. The Canadian and U.S. holdings were transferred to NRDC Equity Partners' holding company, Hudson's Bay Trading Company, as of the fall of 2008.
In September 2011, the HBC began downsizing the Zellers chain with the announcement that it would sell the majority of the leases for its locations to the U.S.-based retailer Target Corporation and close all of their remaining locations by early 2013. Target used the acquisition of this real estate as a means to enable its entry in the Canadian market. HBC used the proceeds to allow it to pay down debt and to invest in growing its Hudson's Bay and Lord & Taylor banners. In January 2013, it was confirmed that only three of the remaining Zellers locations would remain open.
On 24 January 2012, the "Financial Post" reported that Richard Baker (owner of NDRC and governor of Hudson's Bay Company) had dissolved Hudson's Bay Trading Company and that the HBC would now also operate the Lord & Taylor chain. This new structure would be run by the then Bay CEO Bonnie Brooks. Baker remained governor and CEO of the business and Donald Watros stayed on as chief operating officer.
Public offering, 2012 to present.
In October 2012, the HBC announced a $1.6 billion initial public offering (IPO); Baker planned to use the IPO to allow Canadian ownership to return to the company, and to help pay off debts with other partners. Additionally, the company also announced that it would re-brand The Bay department store chain as 'Hudson's Bay'.
The new Hudson's Bay brand was launched in March 2013; incorporating a new logo with an updated rendition of the classic Hudson's Bay Company coat of arms, designed to be modern and better reflect the company's heritage. Following the IPO, HBC had also introduced a new corporate logo of its own (reviving a wordmark from the original HBC flag), but the new logo was not intended to be a consumer-facing brand.
In July 2013, the HBC announced its intent to purchase New York's Saks, Inc. for $2.9 billion (USD), or $16 per share. The company also stated that as a result of the purchase, Canadian consumers would see Saks stores arriving in their country soon. After the purchase was finalized, HBC had a net loss of $124.2 million in the 2013 3Q due to the cost of the purchase and promotions.
Current operations.
The HBC is diversified into joint ventures and other types of business products. The HBC has credit card, mortgage, and personal insurance branches. These other products and services are joint partnerships with other corporations. The HBC also has other HBC Rewards corporate partners such as: Imperial Oil/Esso, M&M Meat Shops, Chapters/Indigo Books, Kelsey's/Montana's Restaurants, Thrifty Car Rental, Cineplex Entertainment Theatres, etc. HBC Rewards points can be redeemed in house or into corporate partners' gift cards and certificates. Points can also be converted to Air Miles.
The HBC is involved in community and charity activities. The HBC Rewards Community Program raises funds for community causes. The HBC Foundation is a charity agency involved in social issues and service. The HBC used to sponsor the annual HBC Run for Canada, a series of public-participation runs and walks held across the country on Canada Day to raise funds for Canadian athletes. The company discontinued this event in 2009.
Olympic outfitter.
The HBC was the official outfitter of clothing for members of the Canadian Olympic team in 1936, 1960, 1964, 1968, 2006, 2008, 2010, 2012, and 2014. The sponsorship has been renewed through 2020. Since the late 2000s, HBC has used its status as the official Canadian Olympics team outfitter to gain global exposure, as part of a turnaround plan that included shedding underperforming brands and luring new high-end brands.
On 2 March 2005, the company was announced as the new clothing outfitter for the Canadian Olympic team, in a $100 million deal, providing apparel for the 2006, 2008, 2010, and 2012 Games, having outbid the existing Canadian Olympic wear-supplier, Roots Canada, which had supplied Canada's Olympic teams from 1998 to 2004. The Canadian Olympic collection is sold through HBC's store chains, The Bay and Zellers (until 2013 when the Zellers leases were sold to Target Canada).
HBC's 2006 Winter Olympics and 2008 Summer Olympics uniforms and toques received a mixed reception for their multicolored stripes (green, red, yellow, blue) which seemed to be not-so-subtle advertising for HBC rather than representing the Canadian Olympic team's traditional colours of red and white (with black as a secondary), in contrast to well-received Root's 1998 collection with its trendy red letter jackets and iconic Poor Boy caps. HBC produced 80% to 90% of their Olympic clothes in China which drew criticism, as Roots ensured that the Olympic clothes were made in Canada using Canadian material.
HBC's apparel for the 2010 Winter Olympics held in Vancouver proved to be extremely successful, in part because Canada was the host country and their athletes had a record medal haul. The "Red Mittens" (red-and-white mittens featuring a large maple leaf) that were sold for $10 CAD, with one-third of the proceeds going to the Canadian Olympic Committee, proved very popular, as were the "Canada" hoodies. Lord Sebastian Coe, chairman of the 2012 London Olympic Games Organizing Committee, who attended the Vancouver Olympics, noted that the Canadians were passionate in embracing the Games with 'their "Canada" hoodies and their red mittens – the must-have item of 2010 (2.6 million pairs sold to date!)'. HBC has continued to produce these red mittens for subsequent Olympic Games.
Archives.
The legacy of the HBC has been maintained in part by the detailed record-keeping and archiving of material by the company. Before 1974, the records of the HBC were kept in the London office headquarters. The HBC opened an Archives department to researchers in 1931. In 1974, Hudson's Bay Company Archives (HBCA) were transferred from London and placed on deposit with the Manitoba archives in Winnipeg. The company granted public access to the collection the following year.
On 27 January 1994, the company’s archives were formally donated to the Archives of Manitoba.
At the time of the donation, the appraised value of the records was nearly $60 million. A foundation, Hudson's Bay Company History Foundation, funded through the tax savings resulting from the donation, was established to support the operations of the HBC Archive as a division of the Archives of Manitoba, along with other activities and programs. More than two kilometers of filed documents and hundreds of microfilm reels are now stored in a special climate-controlled vault in the Manitoba Archives Building.
In 2007, Hudson's Bay Company Archives became part of the United Nations "Memory of the World Programme" project, under UNESCO. The records covered the HBC history from the founding of the company in 1670. The records contained business transactions, medical records, personal journals of officials, inventories, company reports, etc.
Corporate governance.
Current members of the board of directors of Hudson's Bay Company are:
Corporate hierarchy.
Hudson's Bay Company operated with a very rigid hierarchy when it came to its employees. This hierarchy essentially broke down into two levels; the officers and the servants. Comprising the officers were the factors, masters and chief traders, clerks and surgeons. The servants were the tradesmen, boatmen, and laborers. The officers essentially ran the fur trading posts. They had many duties which included supervising the workers in their trade posts, valuing the furs, and keeping trade and post records. In 1821, when Hudson's Bay Company and the North West Company merged, the hierarchy became even stricter and the lines between officers and servants became virtually impossible to cross. Officers in charge of individual trading posts had much responsibility because they were directly in charge of enforcing the policies made by the governor and committee (the board) of the company. One of these policies was the price of particular furs and trade goods. These prices were called the Official and Comparative Standards. Made-Beaver, the quality measurement of the pelt, was the means of exchange used by Hudson's Bay Company to define the Official and Comparative Standards. Because the governor was stationed in London, England, they needed to have reliable officers managing the trade posts halfway around the world. Because the fur trade was a very dynamic market, HBC needed to have some form of flexibility when dealing with prices and traders. Price fluctuation was deferred to the officers in charge of the trade posts, and the head office recorded any difference between the company's standard and that set by the individual officers. Overplus, or any excess revenue gained by officers was strictly documented to insure that it wasn't being pocketed and taken from the company. This strict yet flexible hierarchy exemplifies how Hudson's Bay Company was able to be so successful while still having its central management and trade posts located so far apart.
Further reading.
</dl>

</doc>
<doc id="13298" url="http://en.wikipedia.org/wiki?curid=13298" title="Hoplite">
Hoplite

Hoplites were citizen-soldiers of Ancient Greek city-states who were primarily armed with spears and shields. Their main tactic was the phalanx formation. The hoplites were primarily free citizens—propertied farmers and artisans—who were able to afford the bronze armor suit and weapons (estimated at a third to a half of its able-bodied adult male population). Hoplites generally received basic military training.
In the 8th or 7th century BC Greek armies adopted a military innovation known as the phalanx formation. This tactic proved successful in defeating the Persians when employed by the Athenians at the Battle of Marathon in 490 BC during the First Greco-Persian War. The Persian archers and light troops who fought in the Battle of Marathon failed, in part, because their bows were too weak for their arrows to penetrate the Greek shields and armor, and their own armor and shields could not stand up to the longer spears and swords of the Greeks. The phalanx was also successfully employed by the Greeks at the Battle of Thermopylae in 480 BC and at the Battle of Plataea in 479 BC during the Second Greco-Persian War.
The word "hoplite" (Greek: ὁπλίτης "hoplitēs"; pl. ὁπλῖται "hoplitai") derives from "hoplon" (ὅπλον, plural "hopla" ὅπλα), the type of shield used by the soldiers. There is however considerable debate about this as the shield was more commonly known as an aspis.
Although, as a word, "hopla" could also denote the soldiers' weapons or even their full armament. In the modern Hellenic Army, the word "hoplite" (Greek: oπλίτης) is used to refer to an infantryman.
History.
Ancient Greece.
The exact time when hoplitic warfare was developed is uncertain, the prevalent theory being that it was established sometime during the 8th or 7th century BC, when the "heroic age was abandoned and a far more disciplined system introduced" and the Argive shield became popular. Peter Krentz argues that "the ideology of hoplitic warfare as a ritualized contest developed not in the 7th century [BC], but only after 480, when non-hoplite arms began to be excluded from the phalanx". Anagnostis Agelarakis, based on recent archaeo-anthropological discoveries of the earliest monumental polyandrion (communal burial of male warriors) at Paros Island in Greece, unveils a last quarter of the 8th century BC date for a hoplitic phalangeal military organization.
The rise and fall of hoplite warfare was tied to the rise and fall of the city-state. As discussed above, hoplites were a solution to the armed clashes between independent city-states. As Greek civilization found itself confronted by the world at large, particularly the Persians, the emphasis in warfare shifted. Confronted by huge numbers of enemy troops, individual city-states could not realistically fight alone. During the Greco-Persian Wars (499–448 BC), alliances between groups of cities (whose composition varied over time) fought against the Persians. This drastically altered the scale of warfare and the numbers of troops involved. The hoplite phalanx proved itself far superior to the Persian infantry at such conflicts as the Battle of Marathon, Thermopylae, and the Battle of Plataea.
During this period, Athens and Sparta rose to a position of political eminence in Greece, and their rivalry in the aftermath of the Persian wars brought Greece into renewed internal conflict. However, the Peloponnesian War was on a scale unlike conflicts before. Fought between leagues of cities, dominated by Athens and Sparta respectively, the pooled manpower and financial resources allowed a diversification of warfare. Hoplite warfare was in decline; there were three major battles in the Peloponnesian War, and none proved decisive. Instead there was increased reliance on navies, skirmishers, mercenaries, city walls, siege engines, and non-set piece tactics. These reforms made wars of attrition possible and greatly increased the number of casualties. In the Persian war, hoplites faced large numbers of skirmishers and missile-armed troops, and such troops (e.g., peltasts) became much more commonly used by the Greeks during the Peloponnesian War. As a result, hoplites began wearing less armour, carrying shorter swords, and in general adapting for greater mobility; this led to the development of the ekdromoi light hoplite.
Many famous personalities, philosophers, artists, and poets fought as hoplites.
Sparta.
Sparta is one of the most famous city-states, next to Athens, which had a unique position in ancient Greece. Contrary to other city states, the free citizens of Sparta served as hoplites their entire life, training and exercising also in peacetime, which gave Sparta a professional standing army. Although small, numbering no more than 1,500 to 2,000 men, divided into six mora or battalions, the Spartan army was feared for its discipline and ferocity. Military service was the primary duty of Spartan men, and Spartan society was organized around its army.
Young boys were sent to military school at the age of 7 until the age of 21 when they became full soldiers and moved into their own barracks. These boys who made it endured physical, mental, and spiritual training throughout their education. It is said they were often instructed by their teachers to fight one another. Since the Spartan diet was meagre and not very tasty, stealing food was a necessity, and when caught, the boy would be punished for being captured rather than for stealing. Their graduation included having to live in the wild for a week and killing a slave.
Military service for hoplites lasted until the age of 40, and sometimes even until 60 years of age, depending on a man's physical ability to perform on the battlefield.
Macedonia.
Later on in the hoplite era, more sophisticated tactics were developed, in particular by the Theban general Epaminondas. These tactics inspired the future king Philip II of Macedon, who was at the time a hostage in Thebes, and also inspired the development of new kind of infantry, the Macedonian phalanx. After the Macedonian conquests of the 4th century BC, the hoplite was slowly abandoned in favour of the phalangite, armed in the Macedonian fashion, in the armies of the southern Greek states. Although clearly a development of the hoplite, the Macedonian phalanx was tactically more versatile, especially used in the combined arms tactics favoured by the Macedonians. These forces defeated the last major hoplite army, at the Battle of Chaeronea (338 BC), after which Athens and its allies joined the Macedonian empire.
Warfare.
The fragmentary nature of Ancient Greece, with many competing city-states, increased the frequency of conflict, but conversely limited the scale of warfare. Limited manpower did not allow most Greek city-states to form large armies which could operate for long periods, especially in the case of light troops like the psiloi, who were recruited from the lower citizen classes, and as such, they were mainly farmers, workers, even slaves. They were expected to take part in any military campaign when they would be called for duty. The Lacedaemonian citizens of Sparta were renowned for their lifelong combat training and almost mythical military prowess, while their greatest adversaries, the Athenians, were exempted from service only after the 60th year of their lives. This inevitably reduced the potential duration of campaigns, as a large portion of any Greek army would need to return to their own professions as farmers and artisans. Campaigns would therefore often be restricted to summer. Armies marched directly to their target, the battlefield having possibly already been agreed on by the contestants.
If battle was refused by the defender, they would generally retreat to their city, in which case the attackers generally had to content themselves with ravaging the surrounding countryside, since siegecraft was not efficient, at least until the 5th century BC. When battles occurred, they were usually set piece and intended to be decisive. The battlefield would be flat and open to facilitate phalanx warfare. These battles were usually short and required a high degree of discipline. At least in the early classical period, cavalry was usually used to protect the flanks, when present at all, and cover a possible retreat. Light infantry and missile troops took part in the battle, but their role was of a lower importance.
The military structure created by the Spartans was a rectangular phalanx formation. The formation was organized from eight to ten rows deep, stretching down for about a quarter of a mile or more with well heavily armed fighters fighting in a unit. The phalanxes would approach each other in a steady, slow march to keep cohesion or rarely at a run, if the enemy was prone to panic, or if they fought against enemies equipped with bows, as was the case with the Persians at the Battle of Marathon. The two lines would remain at a small distance to be able to effectively use their spears, while the psiloi threw stones and javelins from behind their lines. If the "doratismos" (spear combat) was not decisive, then the lines would close and swords would be drawn. The shields would clash and the first lines (protostates) would stab at their opponents, at the same time trying to keep in position. The ranks behind them would support them with their own spears and the mass of their shields gently pushing them, not to force them into the enemy formation but to keep them steady and in place. At certain points, a command would be given to the phalanx or a part thereof to collectively take a certain number of steps forward (ranging from half to multiple steps). This was the famed "othismos".
At this point, the phalanx would put its collective weight to push back the enemy line and thus create fear and panic among its ranks. There could be multiple such instances of attempts to push, but it seems from the accounts of the ancients that these were perfectly orchestrated and attempted organized "en masse". Battles rarely lasted more than an hour. Once one of the lines broke, the troops would generally flee from the field, sometimes chased by psiloi, peltasts, or light cavalry.
If a hoplite escaped, he would sometimes be forced to drop his cumbersome aspis, thereby disgracing himself to his friends and family (becoming a "ripsaspis", one who threw his shield). To lessen the amount of casualties inflicted by the enemy during battles, soldiers were positioned to stand shoulder to shoulder with their hoplon. Casualties were slight compared to later battles, rarely amounting to more than 5% of the losing side, but the slain often included the most prominent citizens and generals who led from the front. Thus, the whole war could be decided by a single field battle; victory was enforced by ransoming the fallen back to the defeated, called the "Custom of the Greeks".
Individual hoplites carried their shields on their left arm, protecting not only themselves but also the soldier to the left. This meant that the men at the extreme right of the phalanx were only half-protected. In battle, opposing phalanxes would exploit this weakness by attempting to overlap the enemy's right flank. It also meant that, in battle, a phalanx would tend to drift to the right (as hoplites sought to remain behind the shield of their neighbour). The most experienced hoplites were often placed on the right side of the phalanx, to counteract these problems. According to Plutarch's "Sayings of Spartans", "a man carried a shield for the sake of the whole line".
The phalanx is an example of a military formation in which single combat and other individualistic forms of battle were suppressed for the good of the whole. In earlier Homeric combat, the words and deeds of supremely powerful heroes turned the tide of battle. With his friends jostling and pushing on both sides and behind, and his enemies forming a solid wall in front of him, the hoplite had little opportunity for feats of technique and weapon skill, but great need for commitment and mental toughness. By forming a human wall to provide a powerful defensive armour, the Hoplites became invincible in the battlefield. The Hoplites were elite soldiers with much discipline and taught to be loyal and trustworthy. They had to trust their neighbours for mutual protection, so a phalanx was only as strong as its weakest elements. Its effectiveness depended on how well the hoplites could maintain this formation while in combat, and how well they could stand their ground, especially when engaged against another phalanx. The more disciplined and courageous the army, the more likely it was to win—often engagements between the various city-states of Greece would be resolved by one side fleeing before the battle. 
Equipment.
Each hoplite provided his own equipment. Thus, only those who could afford such weaponry fought as hoplites; as with the Roman Republican army it was the middle classes who formed the bulk of the infantry. Equipment was not standardised, although there were doubtless trends in general designs over time, and between city-states. Hoplites had customized armour, the shield was decorated with family or clan emblems, although in later years these were replaced by symbols or monograms of the city states. The equipment might well be passed down in families, since it would have been expensive to manufacture.
The Hoplite army consisted of heavily armored infantrymen. Their armour, also called panoply, was made of full bronze, weighing nearly 32 kg. The average farmer-peasant hoplite typically wore no armour, carrying only a shield, a spear, and perhaps a helmet plus a secondary weapon. Some hoplite spears were 2.7 m long. The linothorax was the most popular type armour worn by the hoplites, since it was cost-effective and provided decent protection. The richer upper-class hoplites typically had a bronze cuirass of either the bell or muscled variety, a bronze helmet with cheekplates, as well as greaves and other armour. The design of the helmets used varied through time. The Corinthian helmet was at first standardised and was a very successful design. Later variants included the Chalcidian helmet, a lightened version of the Corinthian helmet, and the very simple Pilos helmet worn by the later hoplites. Often the helmet was decorated with one, sometimes more horsehair crests, and/or bronze animal horns and ears. Helmets were often painted as well. The Thracian helmet had a large visor to further increase protection. In later periods, linen breastplates called "linothorax" were used, as they were tougher and cheaper to make. The linen was 0.5 cm thick. Hoplites carried a large concave shield called an "aspis" (often referred to as a "hoplon") made from wood and covered in bronze, measuring roughly 1 metre in diameter and weighing about 16 pounds. This large shield was made possible partly by its shape, which allowed it to be supported on the shoulder. The revolutionary part of the shield was, in fact, the grip. Known as an Argive grip, it placed the handle at the edge of the shield, and was supported by a leather fastening (for the forearm) at the centre. This allowed the hoplite soldier more mobility with the shield, as well as the ability to capitalize on its offensive capabilities and better support the Phalanx. It rested on a man's shoulders, stretching down the knees. These large shields, designed for pushing ahead, were the most essential equipment for the Hoplites.
The main offensive weapon used was a 2.4 - long and 2.5 cm in diameter spear called a "doru", or "dory". It was held with the right hand, the other hand holding the hoplite's shield. Soldiers usually held their spears in an underhand position when approaching but once they came into close contact with their opponents, they were held in an overhand position ready to strike. The spearhead was usually a curved leaf shape, while the rear of the spear had a spike called a "sauroter" ("lizard-killer") which was used to stand the spear in the ground (hence the name). It was also used as a secondary weapon if the main shaft snapped, or for the rear ranks to finish off fallen opponents as the phalanx advanced over them. In addition to being used as a secondary weapon, the sauroter also doubled to balance the spear, but not for throwing purposes. It is a matter of contention, among historians, whether the hoplite used the spear overarm or underarm. Held underarm, the thrusts would have been less powerful but under more control, and vice versa. It seems likely that both motions were used, depending on the situation. If attack was called for, an overarm motion was more likely to break through an opponent's defence. The upward thrust is more easily deflected by armour due to its lesser leverage. However, when defending, an underarm carry absorbed more shock and could be 'couched' under the shoulder for maximum stability. It should also be said that an overarm motion would allow more effective combination of the "aspis" and "doru" if the shield wall had broken down, while the underarm motion would be more effective when the shield had to be interlocked with those of one's neighbours in the battle-line. Hoplites in the rows behind the lead would almost certainly have made overarm thrusts. The rear ranks held their spears underarm, and raised their shields upwards at increasing angles. This was an effective defence against missiles, deflecting their force.
Hoplites also carried a sword, mostly a short sword called a "xiphos", but later also longer and heavier types. The short sword was a secondary weapon, used if or when their spears were broken or lost, or if the phalanx broke rank. The xiphos usually had a blade around 60 cm long, however those used by the Spartans were often only 30–45 centimetres long. This very short xiphos would be very advantageous in the press that occurred when two lines of hoplites met, capable of being thrust through gaps in the shieldwall into an enemy's unprotected groin or throat, while there was no room to swing a longer sword. Such a small weapon would be particularly useful after many hoplites had started to abandon body armour during the Peloponnesian War. Hoplites could also alternatively carry the "kopis", a heavy knife with a forward-curving blade.
By contrast with hoplites, other contemporary infantry (e.g., Persian) tended to wear relatively light armour, use wicker shields, and were armed with shorter spears, javelins, and bows. The most famous are the Peltasts, light-armed troops who wore no armour and were armed with a light shield, javelins and a short sword. The Athenian general Iphicrates developed a new type of armour and arms for his mercenary army, which included light linen armour, smaller shields and longer spears, whilst arming his peltasts with larger shields, helmets and a longer spear, thus enabling them to defend themselves easier against enemy hoplites. With this new type of army he defeated a Spartan army in 392 BC. Nevertheless, most hoplites stuck to the traditional arms and armour.

</doc>
<doc id="13299" url="http://en.wikipedia.org/wiki?curid=13299" title="History of Spain">
History of Spain

The history of Spain dates back to the Early Middle Ages. In 1516, Habsburg Spain unified a number of disparate predecessor kingdoms; its modern form of a constitutional monarchy was introduced in 1813, and the current democratic constitution dates to 1978.
After the completion of the Reconquista, the kingdoms of Spain were united under Habsburg rule in 1516. At the same time, the Spanish Empire began to expand to the New World across the ocean, marking the beginning of the Spanish Golden Age of Spain, during which, from the early 1500s to the 1650s, Habsburg Spain was among the most powerful states in Europe.
In this time, Spain was involved in all major European wars, including the Italian Wars, the Eighty Years' War, the Thirty Years' War, and the Franco-Spanish War. In the later 17th century, however, Spanish power began to decline, and after the death of the last Habsburg ruler, the War of the Spanish Succession ended with the relegation of Spain, now under Bourbon rule, to the status of a second-rate power with a reduced influence in European affairs. The so-called Bourbon Reforms attempted the renewal of state institutions, with some success, but as the century ended, instability set in with the French Revolution and the Peninsular War, so that Spain never regained its former strength.
Fragmented by the war, Spain at the beginning of the 19th century was destabilised as different political parties representing "liberal", "reactionary", and "moderate" groups throughout the remainder of the century fought for and won short-lived control without any being sufficiently strong to bring about lasting stability. The former Spanish Empire overseas quickly disintegrated with the Latin American wars of independence and eventually the loss of what old colonies remained in the Spanish–American War of 1898.
A tenuous balance between liberal and conservative forces was struck in the establishment of constitutional monarchy during 1874–1931 but brought no lasting solution, and Spain descended into Civil War between the Republican and the Nationalist factions.
The war ended in a nationalist dictatorship, led by Francisco Franco, which controlled the Spanish government until 1975. The post-war decades were relatively stable (with the notable exception of an armed independence movement in the Basque Country), and the country experienced rapid economic growth in the 1960s and early 1970s.
Only with the death of Franco in 1975 did Spain return to Bourbon constitutional monarchy headed by Prince Juan Carlos and to democracy. Spain entered the European Economic Community in 1986 (transformed into the European Union with the Maastricht Treaty of 1992), and the Eurozone in 1999. The financial crisis of 2007–08 ended a decade of economic boom and Spain entered a recession and debt crisis and remains plagued by very high unemployment and a weak economy.
Spain is ranked as a middle power able to exert regional influence but unlike other powers with similar status (such as Germany, Italy and Japan) it is not part of the G8 and participates in the G20 only as a guest. Spain is part of the G6.
Prehistory.
The Iberian Peninsula was first inhabited by anatomically modern humans about 32,000 years BP.
The earliest record of hominids living in Western Europe has been found in the Spanish cave of Atapuerca; a flint tool found there dates from 1.4 million years ago, and early human fossils date to roughly 1.2 million years ago. Modern humans in the form of Cro-Magnons began arriving in the Iberian Peninsula from north of the Pyrenees some 35,000 years ago. The most conspicuous sign of prehistoric human settlements are the famous paintings in the northern Spanish cave of Altamira, which were done c. 15,000 BC and are regarded as paramount instances of cave art.
Furthermore, archeological evidence in places like Los Millares and El Argar, both in the province of Almería, and La Almoloya near Murcia suggests developed cultures existed in the eastern part of the Iberian Peninsula during the late Neolithic and the Bronze Age.
Spanish prehistory extends to the pre-Roman Iron Age cultures that controlled most of Iberia: those of the Iberians, Celtiberians, Tartessians, Lusitanians, and Vascones and trading settlements of Phoenicians, Carthaginians, and Greeks on the Mediterranean coast.
Early history of the Iberian Peninsula.
In the time before the Roman conquest the major cultures were the Iberians along the Mediterranean coast, the Celts in the interior and north-west, the Lusitanians in the west, and the Tartessians in the southwest. The seafaring Phoenicians, Carthaginians, and Greeks successively established trading settlements along the eastern and southern coast. The first Greek colonies, such as Emporion (modern Empúries), were founded along the northeast coast in the 9th century BC, leaving the south coast to the Phoenicians.
The Greeks are responsible for the name "Iberia", apparently after the river Iber (Ebro). In the 6th century BC, the Carthaginians arrived in Iberia, struggling first with the Greeks, and shortly after, with the newly arriving Romans for control of the Western Mediterranean. Their most important colony was Carthago Nova (Latin name of modern day Cartagena).
The peoples whom the Romans met at the time of their invasion in what is now known as Spain were the Iberians, inhabiting an area stretching from the northeast part of the Iberian Peninsula through the southeast. The Celts mostly inhabited the inner and north-west part of the peninsula. In the inner part of the peninsula, where both groups were in contact, a mixed culture arose, the Celtiberians. The Celtiberian Wars were fought between the advancing legions of the Roman Republic and the Celtiberian tribes of Hispania Citerior from 181 to 133 BC. The Roman conquest of the peninsula was completed in 19 BC.
Roman Hispania.
"Hispania" was the name used for the Iberian Peninsula under Roman rule from the 2nd century BC. The populations of the peninsula were gradually culturally Romanized, and local leaders were admitted into the Roman aristocratic class.
The Romans improved existing cities, such as Tarragona ("Tarraco"), and established others like Zaragoza ("Caesaraugusta"), Mérida ("Augusta Emerita"), Valencia ("Valentia"), León ("Legio Septima"), Badajoz ("Pax Augusta"), and Palencia. The peninsula's economy expanded under Roman tutelage. Hispania supplied Rome with food, olive oil, wine and metal. The emperors Trajan, Hadrian, and Theodosius I, the philosopher Seneca, and the poets Martial, Quintilian, and Lucan were born in Hispania. Hispanic bishops held the Council of Elvira around 306.
After the fall of the Western Roman Empire in the 5th century, parts of Hispania came under the control of the Germanic tribes of Vandals, Suebi, and Visigoths.
The collapse of the Western Roman Empire did not lead to the same wholesale destruction of Western classical society as happened in areas like Roman Britain, Gaul and Germania Inferior during the Early Middle Ages, although the institutions and infrastructure did decline. Spain's present languages, its religion, and the basis of its laws originate from this period. The centuries of uninterrupted Roman rule and settlement left a deep and enduring imprint upon the culture of Spain.
Gothic Hispania (5th–8th centuries).
The first Germanic tribes to invade Hispania arrived in the 5th century, as the Roman Empire decayed. The Visigoths, Suebi, Vandals and Alans arrived in Spain by crossing the Pyrenees mountain range, leading to the establishment of the Suebi Kingdom in Gallaecia, in the northwest, the Vandal Kingdom of Vandalusia (Andalusia), and the Visigothic Kingdom in Toledo. The Romanized Visigoths entered Hispania in 415. After the conversion of their monarchy to Roman Catholicism and after conquering the disordered Suebic territories in the northwest and Byzantine territories in the southeast, the Visigothic Kingdom eventually encompassed a great part of the Iberian Peninsula.
As the Roman Empire declined, Germanic tribes invaded the former empire. Some were "foederati", tribes enlisted to serve in Roman armies, and given land within the empire as payment, while others, such as the Vandals, took advantage of the empire's weakening defenses to seek plunder within its borders. Those tribes that survived took over existing Roman institutions, and created successor-kingdoms to the Romans in various parts of Europe. Iberia was taken over by the Visigoths after 410.
At the same time, there was a process of "Romanization" of the Germanic and Hunnic tribes settled on both sides of the "limes" (the fortified frontier of the Empire along the Rhine and Danube rivers). The Visigoths, for example, were converted to Arian Christianity around 360, even before they were pushed into imperial territory by the expansion of the Huns.
In the winter of 406, taking advantage of the frozen Rhine, refugees from (Germanic) Vandals and Sueves, and the (Sarmatian) Alans, fleeing the advancing Huns, invaded the empire in force. Three years later they crossed the Pyrenees into Iberia and divided the Western parts, roughly corresponding to modern Portugal and western Spain as far as Madrid, between them.
The Visigoths, having sacked Rome two years earlier, arrived in the region in 412, founding the Visigothic kingdom of Toulouse (in the south of modern France) and gradually expanded their influence into the Iberian peninsula at the expense of the Vandals and Alans, who moved on into North Africa without leaving much permanent mark on Hispanic culture. The Visigothic Kingdom shifted its capital to Toledo and reached a high point during the reign of Leovigild.
Visigothic rule.
The Visigothic Kingdom conquered all of Hispania and ruled it until the early 8th century, when the peninsula fell to the Muslim conquests. The Muslim state in Iberia came to be known as Al-Andalus. After a period of Muslim dominance, the medieval history of Spain is dominated by the long Christian "Reconquista" or "reconquest" of the Iberian Peninsula from Muslim rule. The Reconquista gathered momentum during the 12th century, leading to the establishment of the Christian kingdoms of Portugal, Aragon, Castile and Navarre and by 1250, had reduced Muslim control to the Emirate of Granada in the south-east of the peninsula. Muslim rule in Granada survived until 1492, when it fell to the Catholic Monarchs.
Importantly, Spain never saw a decline in interest in classical culture to the degree observable in Britain, Gaul, Lombardy and Germany. The Visigoths, having assimilated Roman culture during their tenure as "foederati", tended to maintain more of the old Roman institutions, and they had a unique respect for legal codes that resulted in continuous frameworks and historical records for most of the period between 415, when Visigothic rule in Spain began, and 711, when it is traditionally said to end. However, during the Visigothic dominion the cultural efforts made by the Franks and other Germanic tribes was not felt in the peninsula, and were not achieved in the lesser kingdoms that emerged after the Muslim conquest.
The proximity of the Visigothic kingdoms to the Mediterranean and the continuity of western Mediterranean trade, though in reduced quantity, supported Visigothic culture. Arian Visigothic nobility kept apart from the local Catholic population. The Visigothic ruling class looked to Constantinople for style and technology while the rivals of Visigothic power and culture were the Catholic bishops – and a brief incursion of Byzantine power in Córdoba.
Spanish Catholic religion also coalesced during this time. The period of rule by the Visigothic Kingdom saw the spread of Arianism briefly in Spain. The Councils of Toledo debated creed and liturgy in orthodox Catholicism, and the Council of Lerida in 546 constrained the clergy and extended the power of law over them under the blessings of Rome. In 587, the Visigothic king at Toledo, Reccared, converted to Catholicism and launched a movement in Spain to unify the various religious doctrines that existed in the land. This put an end to dissension on the question of Arianism. (For additional information about this period, see the History of Roman Catholicism in Spain.)
The Visigoths inherited from Late Antiquity a sort of feudal system in Spain, based in the south on the Roman villa system and in the north drawing on their vassals to supply troops in exchange for protection. The bulk of the Visigothic army was composed of slaves, raised from the countryside. The loose council of nobles that advised Spain's Visigothic kings and legitimized their rule was responsible for raising the army, and only upon its consent was the king able to summon soldiers.
The impact of Visigothic rule was not widely felt on society at large, and certainly not compared to the vast bureaucracy of the Roman Empire; they tended to rule as barbarians of a mild sort, uninterested in the events of the nation and economy, working for personal benefit, and little literature remains to us from the period. They did not, until the period of Muslim rule, merge with the Spanish population, preferring to remain separate, and indeed the Visigothic language left only the faintest mark on the modern languages of Iberia.
The most visible effect was the depopulation of the cities as they moved to the countryside. Even while the country enjoyed a degree of prosperity when compared to the famines of France and Germany in this period, the Visigoths felt little reason to contribute to the welfare, permanency, and infrastructure of their people and state. This contributed to their downfall, as they could not count on the loyalty of their subjects when the Moors arrived in the 8th century.
Islamic "al-Andalus" and the Christian "Reconquista" (8th–15th centuries).
The Arab Islamic conquest dominated most of North Africa by 640 AD. In 711 an Islamic Berber and Arab raiding party, led by Tariq ibn Ziyad, was sent to Iberia to intervene in a civil war in the Visigothic Kingdom. Crossing the Strait of Gibraltar, they won a decisive victory in the summer of 711 when the Visigothic King Roderic was defeated and killed on July 19 at the Battle of Guadalete.
Tariq's commander, Musa bin Nusayr, quickly crossed with reinforcements, and by 718 the Muslims were in control of nearly the whole Iberian Peninsula. The advance into Western Europe was only stopped in what is now north-central France by the West Germanic Franks under Charles Martel at the Battle of Tours in 732.
A decisive victory for the Christians took place at Covadonga, in the north of the Iberian Peninsula, in the summer of 722. In a minor battle known as the Battle of Covadonga, a Muslim force sent to put down the Christian rebels in the northern mountains was defeated by Pelagius of Asturias, who established the monarchy of the Christian Kingdom of Asturias. In 739, a rebellion in Galicia, assisted by the Asturians, drove out Muslim forces and it joined the Asturian kingdom. The Kingdom of Asturias became the main base for Christian resistance to Islamic rule in the Iberian Peninsula for several centuries.
Caliph Al-Walid I had paid great attention to the expansion of an organized military, building the strongest navy in the Umayyad Caliphate era (the second major Arab dynasty after Mohammad and the first Arab dynasty of Al-Andalus). It was this tactic that supported the ultimate expansion to Spain. Caliph Al-Walid I's reign is considered as the apex of Islamic power, though Islamic power in Spain specifically climaxed in the 10th century under Abd-ar-Rahman III.
Abbasids overthrow the Umayyad Caliphate.
The rulers of Al-Andalus were granted the rank of Emir by the Umayyad Caliph Al-Walid I in Damascus. Emir Abd al-Rahman I challenged the Abbasids. The Umayyad Caliphate, with origin in Hejaz, Arabian peninsula "or Emirate" was overthrown by the Abbasid Caliphate "or Emirate" (second Arab dynasty), some of the remaining Umayyad leaders escaped to Castile and declared Córdoba an independent emirate. Al-Andalus was rife with internal conflict between the Islamic Umayyad rulers and people and the Christian Visigoth-Roman leaders and people.
In the 10th century Abd-ar-Rahman III declared the Caliphate of Córdoba, effectively breaking all ties with the Egyptian and Syrian caliphs. The Caliphate was mostly concerned with maintaining its power base in North Africa, but these possessions eventually dwindled to the Ceuta province. The first navy of the Caliph of Córdoba "or Emir" was built after the humiliating Viking ascent of the Guadalquivir in 844 when they sacked Seville.
In 942, pagan Magyars (present day Hungary) raided across Europe as far west as Al-Andalus. Meanwhile, a slow but steady migration of Christian subjects to the northern kingdoms in Christian Hispania was slowly increasing the latter's power. Even so, Al-Andalus remained vastly superior to all the northern kingdoms combined in population, economy and military might; and internal conflict between the Christian kingdoms contributed to keep them relatively harmless.
Al-Andalus coincided with "La Convivencia", an era of relative religious tolerance, and with the Golden age of Jewish culture in the Iberian Peninsula. (See: Emir Abd-ar-Rahman III 912; the Granada massacre 1066).
Warfare between Muslims and Christians.
Muslim interest in the peninsula returned in force around the year 1000 when Al-Mansur (also known as "Almanzor") sacked Barcelona in 985. Under his son, other Christian cities were subjected to numerous raids. After his son's death, the caliphate plunged into a civil war and splintered into the so-called "Taifa Kingdoms". The Taifa kings competed against each other not only in war but also in the protection of the arts, and culture enjoyed a brief upswing.
Medieval Spain was the scene of almost constant warfare between Muslims and Christians. The Almohads, who had taken control of the Almoravids' Maghribi and al-Andalus territories by 1147, surpassed the Almoravides in fundamentalist Islamic outlook, and they treated the non-believer "dhimmis" harshly. Faced with the choice of death, conversion, or emigration, many Jews and Christians left.
By the mid-13th century Emirate of Granada was the only independent Muslim realm in Spain, which would last until 1492. Despite the decline in Muslim-controlled kingdoms, it is important to note the lasting effects exerted on the peninsula by Muslims in technology, culture, and society.
The Taifa kingdoms lost ground to the Christian realms in the north. After the loss of Toledo in 1085, the Muslim rulers reluctantly invited the Almoravides, who invaded Al-Andalus from North Africa and established an empire. In the 12th century the Almoravid empire broke up again, only to be taken over by the Almohad invasion, who were defeated by an alliance of the Christian kingdoms in the decisive battle of Las Navas de Tolosa in 1212. By 1250, nearly all of Iberia was back under Christian rule with the exception of the small Muslim kingdom of Granada.
The Kings of Aragón ruled territories that consisted of not only the present administrative region of Aragon but also Catalonia, and later the Balearic Islands, Valencia, Sicily, Naples and Sardinia (see Crown of Aragon). Considered by most to have been the first mercenary company in Western Europe, the Catalan Company proceeded to occupy the Duchy of Athens, which they placed under the protection of a prince of the House of Aragon and ruled until 1379.
The Spanish language and universities.
In the 13th century, many languages were spoken in the Christian kingdoms of Iberia. These were the Latin-based Romance languages of Castilian, Aragonese, Catalan, Galician, Aranese, Asturian and Leonese, and the ancient language isolate of Basque. Throughout the century, Castilian (what is also known today as Spanish) gained a growing prominence in the Kingdom of Castile as the language of culture and communication, at the expense of Leonese and of other close dialects.
One example of this is the epic song ('cantar') written after the military leader "El Cid". In the last years of the reign of Ferdinand III of Castile, Castilian began to be used for certain types of documents, and it was during the reign of Alfonso X that it became the official language. Henceforth all public documents were written in Castilian; likewise all translations were made into Castilian instead of Latin.
At the same time, Catalan and Galician became the standard languages in their respective territories, developing important literary traditions and being the normal languages in which public and private documents were issued: Galician from the 13th to the 16th century in Galicia and nearby regions of Asturias and Leon, and Catalan from the 12th to the 18th century in Catalonia, the Balearic Islands and Valencia, where it was known as Valencian. Both languages were later substituted in its official status by Castillian Spanish, till the 20th century.
In the 13th century many universities were founded in León and in Castile. Some, such as the Leonese Salamanca and the Castilian Palencia, were among the earliest universities in Europe.
In 1492, under the Catholic Monarchs, the first edition of the "Grammar of the Castilian Language" by Antonio de Nebrija was published.
Early Modern Spain.
Dynastic union.
In the 15th century, the most important among all of the separate Christian kingdoms that made up the old Hispania were the Kingdom of Castile (occupying northern and central portions of the Iberian Peninsula) the Crown of Aragon (occupying northeastern portions of the peninsula) and the kingdom of Portugal occupying the far western Iberian Peninsula. The rulers of the kingdoms of Castille and Aragon were allied with dynastic families in Portugal, France, and other neighboring kingdoms.
The death of King Henry IV of Castile in 1474 set off a struggle for power called the War of the Castilian Succession (1475-1479). Contenders for the throne of Castile were Henry's one-time heir Joanna la Beltraneja, supported by Portugal and France, and Henry's half-sister Queen Isabella I of Castile, supported by the Kingdom of Aragon and by the Castilian nobility.
Isabella retained the throne and ruled jointly with her husband, King Ferdinand II. Isabella and Ferdinand had married in 1469 in Valladolid. Their marriage united both crowns and set the stage for the creation of the Kingdom of Spain, at the dawn of the modern era. That union, however, was a union in title only, as each region retained its own political and judicial structure. Pursuant to an agreement signed by Isabella and Ferdinand on January 15, 1474, Isabella held more authority over the newly unified Spain than her husband, although their rule was shared. Together, Isabella of Castile and Ferdinand of Aragon were known as the "Catholic Monarchs" (Spanish: "los Reyes Católicos"), a title bestowed on them by Pope Alexander VI.
Conclusion of the Reconquista and start of the Spanish Inquisition.
The monarchs oversaw the final stages of the Reconquista of Iberian territory from the Moors with the conquest of Granada, conquered the Canary Islands, and expelled the Jews and Muslims from Spain under the Alhambra decree. Although until the 13th century religious minorities (Jews and Muslims) had enjoyed considerable tolerance in Castilla and Aragon – the only Christian kingdoms where Jews were not restricted from any professional occupation – the situation of the Jews collapsed over the 14th century, reaching a climax in 1391 with large scale massacres in every major city except Ávila.
Over the next century, half of the estimated 80,000 Spanish Jews converted to Christianity (becoming "conversos"). The final step was taken by the Catholic Monarchs, who, in 1492, ordered the remaining Jews to convert or face expulsion from Spain. Depending on different sources, the number of Jews actually expelled, traditionally estimated at 120,000 people, now believed to have numbered about 40,000.
Over the following decades, Muslims faced the same fate and about 60 years after the Jews, they were also compelled to convert ("moriscos") or be expelled. However, sufficient numbers of moriscos stayed that Muslim culture remained influential in Spain. Jews and Muslims were not the only people to be persecuted during this time period. All Roma (Gypsy) males between the ages of 18 and 26 were forced to serve in galleys – which was equivalent to a death sentence – but the majority managed to hide and avoid arrest.
Isabella and Ferdinand authorized the 1492 expedition of Christopher Columbus, who became the first known European to reach the New World since Leif Ericson. This and subsequent expeditions led to an influx of wealth into Spain, supplementing income from within Castile for the state that would prove to be a dominant power of Europe for the next two centuries.
Isabella ensured long-term political stability in Spain by arranging strategic marriages for each of her five children. Her firstborn, a daughter named Isabella, married Afonso of Portugal, forging important ties between these two neighboring countries and hopefully ensuring future alliance, but Isabella soon died before giving birth to an heir. Juana, Isabella's second daughter, married into the Habsburg dynasty when she wed Philip the Handsome, the son of Maximilian I, King of Bohemia (Austria) and entitled to the crown of the Holy Roman Emperor.
This ensured an alliance with the Habsburgs and the Holy Roman Empire, a powerful, far-reaching territory that assured Spain's future political security. Isabella's only son, Juan, married Margaret of Austria, further maintaining ties with the Habsburg dynasty. Isabella's fourth child, Maria, married Manuel I of Portugal, strengthening the link forged by her older sister's marriage. Her fifth child, Catherine, married King Henry VIII of England and was mother to Queen Mary I of England.
Imperial Spain.
The Spanish Empire was one of the first modern global empires. It was also one of the largest empires in world history. In the 16th century, Spain and Portugal were in the vanguard of European global exploration and colonial expansion. The two kingdoms on the conquest and Iberian Peninsula competed with each other in opening of trade routes across the oceans. Spanish imperial conquest and colonization began with two Castilian expeditions. The first was an expedition of a Castilian fleet led by a Genoese, Lanzarotto Malocello. The second was another expedition in 1502 led by French adventurers, Jean de Bethancourt, Lord of Grainville in Normandy and Gadifer de la Salle of Poitou.
In the 15th and 16th centuries, trade flourished across the Atlantic between Spain and the Americas and across the Pacific between East Asia and Mexico via the Philippines. Conquistadors deposed the Aztec, Inca and Maya governments with extensive help from local factions and laid claim to vast stretches of land in North and South America.
This New World empire was at first a disappointment, as the natives had little to trade, though settlement did encourage trade. Diseases such as smallpox and measles that arrived with the colonizers devastated the native populations, especially in the densely populated regions of the Aztec, Maya and Inca civilizations, and this reduced the economic potential of conquered areas.
In the 1520s, large-scale extraction of silver from the rich deposits of Mexico's Guanajuato began to be greatly augmented by the silver mines in Mexico's Zacatecas and Bolivia's Potosí from 1546. These silver shipments re-oriented the Spanish economy, leading to the importation of luxuries and grain. They also became indispensable in financing the military capability of Habsburg Spain in its long series of European and North African wars, though, with the exception of a few years in the 17th century, Spain itself (Castile in particular) was by far the most important source of revenue.
Spain enjoyed a cultural golden age in the 16th and 17th centuries. For a time, the Spanish Empire dominated the oceans with its experienced navy and ruled the European battlefield with its fearsome and well trained infantry, the famous "tercios", in the words of the prominent French historian Pierre Vilar, "enacting the most extraordinary epic in human history".
The financial burden within the peninsula was on the backs of the peasant class while the nobility enjoyed an increasingly lavish lifestyle. From the time beginning with the incorporation of the Portuguese Empire in 1580 (lost in 1640) until the loss of its North and South American colonies in the 19th century, Spain maintained the largest empire in the world even though it suffered fluctuating military and economic fortunes from the 1640s.
Confronted by the new experiences, difficulties and suffering created by empire-building, Spanish thinkers formulated some of the first modern thoughts on natural law, sovereignty, international law, war, and economics; there were even questions about the legitimacy of imperialism – in related schools of thought referred to collectively as the School of Salamanca. Despite these innovations, many motives for the empire were rooted in the Middle Ages. Religion played a very strong role in the spread of the Spanish empire. The thought that Spain could bring Christianity to the New World certainly played a strong role in the expansion of Spain's empire.
Spanish Kingdoms under the Habsburgs (16th–17th centuries).
Spain's world empire reached its greatest territorial extent in the late 18th century but it was under the Habsburg dynasty in the 16th and 17th centuries it reached the peak of its power and declined. When Spain's first Habsburg ruler Charles I became king of Spain in 1516, Spain became central to the dynastic struggles of Europe. After he became king of Spain, Charles also became Charles V, Holy Roman Emperor and because of his widely scattered domains was not often in Spain. As he approached the end of his life he made provision for the division of the Habsburg inheritance into two parts. On the one hand was Spain, its possessions in Europe, North Africa, the Americas and the Netherlands; on the other hand was the Holy Roman Empire. This was to create enormous difficulties for his son Philip II of Spain.
Philip II became king on Charles I's abdication in 1556. Spain largely escaped the religious conflicts that were raging throughout the rest of Europe and remained firmly Roman Catholic. Philip saw himself as a champion of Catholicism, both against the Muslim Ottoman Empire and the Protestant heretics.
In the 1560s, plans to consolidate control of the Netherlands led to unrest, which gradually led to the Calvinist leadership of the revolt and the Eighty Years' War. This conflict consumed much Spanish expenditure during the later 16th century. Conflicts included an attempt to conquer England – a cautious supporter of the Dutch – in the unsuccessful Spanish Armada, an early battle in the Anglo-Spanish War (1585–1604), and war with France (1590–1598).
Despite these problems, the growing inflow of New World silver from mid-16th century, the justified military reputation of the Spanish infantry and even the navy quickly recovering from its Armada disaster, made Spain the leading European power, a novel situation of which its citizens were only just becoming aware. The Iberian Union with Portugal in 1580 not only unified the peninsula, but added that country's worldwide resources to the Spanish crown.
However, economic and administrative problems multiplied in Castile, and the weakness of the native economy became evident in the following century. Rising inflation, financially draining wars in Europe, the ongoing aftermath of the expulsion of the Jews and Moors from Spain, and Spain's growing dependency on the gold and silver imports, combined to cause several bankruptcies that caused economic crisis in the country, especially in heavily burdened Castile.
Barbary pirates from North Africa became an increasing problem. The coastal villages of Spain and of the Balearic Islands were frequently attacked. Formentera was even temporarily abandoned by its population. This occurred also along long stretches of the Spanish and Italian coasts, a relatively short distance across a calm sea from the pirates in their North African lairs. The most famous corsair was the Turkish Barbarossa ("Redbeard"). According to Robert Davis between 1 million and 1.25 million Europeans were captured by North African pirates and sold as slaves in North Africa and Ottoman Empire between the 16th and 19th centuries. This was gradually alleviated as Spain and other Christian powers began to check Muslim naval dominance in the Mediterranean after the 1571 victory at Lepanto, but it would be a scourge that continued to afflict the country even in the next century.
The great plague of 1596–1602 killed 600,000 to 700,000 people, or about 10% of the population. Altogether more than 1,250,000 deaths resulted from the extreme incidence of plague in 17th-century Spain. Economically, the plague destroyed the labor force as well as creating a psychological blow to an already problematic Spain.
Philip II died in 1598, and was succeeded by his son Philip III. In his reign (1598–1621) a ten-year truce with the Dutch was overshadowed in 1618 by Spain's involvement in the European-wide Thirty Years' War. Government policy was dominated by favorites, but it was also the period in which the geniuses of Cervantes and El Greco flourished.
Philip III was succeeded in 1621 by his son Philip IV of Spain (reigned 1621–1665). Much of the policy was conducted by the minister Gaspar de Guzmán, Count-Duke of Olivares. In 1640, with the war in central Europe having no clear winner except the French, both Portugal and Catalonia rebelled. Portugal was lost to the crown for good; in Italy and most of Catalonia, French forces were expelled and Catalonia's independence was suppressed
In the reign of Philip's developmentally disabled son and successor Charles II (1665–1700), Spain was essentially left leaderless and was gradually being reduced to a second-rank power.
The Habsburg dynasty became extinct in Spain with Charles II's death in 1700, and the War of the Spanish Succession ensued in which the other European powers tried to assume control of the Spanish monarchy. King Louis XIV of France eventually lost the War of the Spanish Succession, but because the victor's (Great Britain, Holland and Austria) candidate for the Spanish throne (Archduke Charles of Austria) became Holy Roman Emperor, control of Spain was allowed to pass to the Bourbon dynasty. However, the peace deals that followed included relinquishing the right to unite the French and Spanish thrones and the partitioning of Spain's European empire.
The Golden Age ("Siglo de Oro").
The Spanish Golden Age (in Spanish, "Siglo de Oro") was a period of flourishing arts and letters in the Spanish Empire (now Spain and the Spanish-speaking countries of Latin America), coinciding with the political decline and fall of the Habsburgs (Philip III, Philip IV and Charles II). It is interesting to note how arts during the Golden Age flourished despite the decline of the empire in the 17th century. The last great writer of the age, Sor Juana Inés de la Cruz, died in New Spain in 1695.
The Habsburgs, both in Spain and Austria, were great patrons of art in their countries. "El Escorial", the great royal monastery built by King Philip II, invited the attention of some of Europe's greatest architects and painters. Diego Velázquez, regarded as one of the most influential painters of European history and a greatly respected artist in his own time, cultivated a relationship with King Philip IV and his chief minister, the Count-Duke of Olivares, leaving us several portraits that demonstrate his style and skill. El Greco, a respected Greek artist from the period, settled in Spain, and infused Spanish art with the styles of the Italian renaissance and helped create a uniquely Spanish style of painting.
Some of Spain's greatest music is regarded as having been written in the period. Such composers as Tomás Luis de Victoria, Luis de Milán and Alonso Lobo helped to shape Renaissance music and the styles of counterpoint and polychoral music, and their influence lasted far into the Baroque period.
Spanish literature blossomed as well, most famously demonstrated in the work of Miguel de Cervantes, the author of "Don Quixote de la Mancha". Spain's most prolific playwright, Lope de Vega, wrote possibly as many as one thousand plays over his lifetime, over four hundred of which survive to the present day.
Decline in the 17th century.
The Spanish "Golden Age" politically ends no later than 1659, with the Treaty of the Pyrenees, ratified between France and Habsburg Spain. 
Spain had experienced severe difficulties in the later 16th century, including military defeats in Europe like the Spanish Armada and a series of financial crises that had caused the Spanish Crown to declare bankruptcy four times in the late 1500s (1557, 1560, 1576, 1596). Many different factors, including the decentralized political nature of Spain, inefficient taxation, a succession of weak kings, power struggles in the Spanish court and a tendency to focus on the American colonies instead of Spain's domestic economy, all contributed to the decline of the Habsburg rule of Spain.
During the long regency for Charles II, the last of the Spanish Habsburgs, favouritism milked Spain's treasury, and Spain's government operated principally as a dispenser of patronage. Plague, famine, floods, drought, and renewed war with France wasted the country. The Peace of the Pyrenees (1659) had ended fifty years of warfare with France, whose king, Louis XIV, found the temptation to exploit weakened Spain too great. Louis instigated the War of Devolution (1667–68) to acquire the Spanish Netherlands.
By the 17th century, the Catholic Church and the Spain had showcased a close bond to one another, attesting to the fact that Spain was virtually free of Protestantism during the 16th century. In 1620, there were 100,000 Spaniards in the clergy, by 1660 there were about 200,000 Spaniards in the clergy and the Church owned 20% of all the land in Spain. The Spanish bureaucracy in this period was highly centralized, and totally reliant on the king for its efficient functioning. Under Charles II, the councils became the sinecures of wealthy aristocrats despite various attempt at reform. Political commentators in Spain, known as arbitristas, proposed a number of measures to reverse the decline of the Spanish economy, with limited success. In rural areas of Spain, heavy taxation of peasants reduced agricultural output as peasants in the countryside migrated to the cities. Many believed that the influx of gold and silver from the Americas was the cause of inflation, when only one fifth of the precious metals actually went into Spain. A more prominent internal factor was the Spanish economy's dependence on luxurious Merino wool, which faced competition from cheaper textiles from England and the Netherlands.
Spain under the Bourbons (18th century).
Charles II, having no direct heir, was succeeded by his great-nephew Philippe d'Anjou, a French prince, in 1700. Concern among other European powers that Spain and France united under a single Bourbon monarch would upset the balance of power led to the War of the Spanish Succession between 1701 and 1714. It pitted powerful France and fairly strong Spain against the Grand Alliance of England, Portugal, Savoy, the Netherlands and Austria.
After many battles, especially in Spain, the treaty of Utrecht recognised Philip, Duke of Anjou, Louis XIV's grandson, as King of Spain (as Philip V), thus confirming the succession stipulated in the will of the Charles II of Spain. However, Philip was compelled to renounce for himself and his descendants any right to the French throne, despite some doubts as to the lawfulness of such an act. Spain's Italian territories were apportioned.
Philip V signed the "Decreto de Nueva Planta" in 1715. This new law revoked most of the historical rights and privileges of the different kingdoms that formed the Spanish Crown, especially the Crown of Aragon, unifying them under the laws of Castile, where the Castillian Cortes Generales had been more receptive to the royal wish. Spain became culturally and politically a follower of absolutist France. Lynch says Philip V advanced the government only marginally over that of his predecessors and was more of a liability than the incapacitated Charles II; when a conflict came up between the interests of Spain and France, he usually favored France.
Philip made reforms in government, and strengthened the central authorities relative to the provinces. Merit became more important, although most senior positions still went to the landed aristocracy. Below the elite level, inefficiency and corruption was as widespread as ever.
The reforms started by Philip V culminated in much more important reforms of Charles III. However Israel argues that King Charles III cared little for the Enlightenment and his ministers paid little attention to the Enlightenment ideas influential elsewhere on the Continent. Israel says, "Only a few ministers and officials were seriously committed to enlightened aims. Most were first and foremost absolutists and their objective was always to reinforce monarchy, empire, aristocracy...and ecclesiastical control and authority over education."
The economy, on the whole, improved over the depressed 1650–1700 era, with greater productivity and fewer famines and epidemics.
The rule of the Spanish Bourbons continued under Ferdinand VI (1746–1759) and Charles III (1759–1788). Elisabeth of Parma, Philip V's widow, exerted great influence on Spain's foreign policy. Her principal aim was to have Spain's lost territories in Italy restored. She eventually received Franco-British support for this after the Congress of Soissons (1728–1729).
Under the rule of Charles III and his ministers – Leopoldo de Gregorio, Marquis of Esquilache and José Moñino, Count of Floridablanca – the economy improved. Fearing that Britain's victory over France in the Seven Years' War (1756–63) threatened the European balance of power, Spain allied itself to France but suffered a series of military defeats and ended up having to cede Florida to the British at the Treaty of Paris (1763) while gaining Louisiana from France. Spain regained Florida with the Treaty of Paris (1783), which ended the American Revolutionary War (1775–83), and gained an improved international standing.
However, there were no reforming impulses in the reign of Charles IV (1788 to abdication in 1808), seen by some as mentally handicapped. Dominated by his wife's lover, Manuel de Godoy, Charles IV embarked on policies that overturned much of Charles III's reforms. After briefly opposing Revolutionary France early in the French Revolutionary Wars, Spain was cajoled into an uneasy alliance with its northern neighbor, only to be blockaded by the British. Charles IV's vacillation, culminating in his failure to honour the alliance by neglecting to enforce the Continental System led to Napoleon I, Emperor of the French, invading Spain in 1808, thereby triggering the Peninsular War, with enormous human and property losses, and loss of control over most of the overseas empire.
During most of the 18th century Spain had arrested its relative decline of the latter part of the 17th century. But despite the progress, it continued to lag in the political and mercantile developments then transforming other parts of Europe, most notably in Great Britain, the Low Countries, and France. The chaos unleashed by the Peninsular War caused this gap to widen greatly and Spain would not have an Industrial Revolution.
The Age of Enlightenment reached Spain in attenuated form about 1750. Attention focused on medicine and physics, with some philosophy. French and Italian visitors were influential but there was little challenge to Catholicism or the Church such as characterized the French philosophes. The leading Spanish figure was Benito Feijóo (1676–1764), a Benedictine monk and professor. He was a successful popularizer noted for encouraging scientific and empirical thought in an effort to debunk myths and superstitions. By the 1770s the conservatives had launched a counterattack and used censorship and the Inquisition to suppress Enlightenment ideas.
At the top of the social structure of Spain in the 1780s stood the nobility and the church. A few hundred families dominated the aristocracy, with another 500,000 holding noble status. There were 200,000 church men and women, half of them in heavily endowed monasteries that controlled much of the land not owned by the nobles. Most people were on farms, either as landless peons or as holders of small properties. The small urban middle class was growing, but was distrusted by the landowners and peasants alike.
The 19th century.
War of Spanish Independence (1808–14).
In the late 18th century, Bourbon-ruled Spain had an alliance with Bourbon-ruled France, and therefore did not have to fear a land war. Its only serious enemy was Britain, which had a powerful Royal Navy; Spain therefore concentrated its resources on its navy. When the French Revolution overthrew the Bourbons, a land war with France became a threat which the king tried to avoid. The Spanish army was ill-prepared. The officer corps was selected primarily on the basis of royal patronage, rather than merit. About a third of the junior officers have been promoted from the ranks, and they did have talent, but they had few opportunities for promotion or leadership. The rank-and-file were poorly trained peasants. Elite units included foreign regiments of Irishmen, Italians, Swiss, and Walloons, in addition to elite artillery and engineering units. Equipment was old-fashioned and in disrepair. The army lacked its own horses, oxen and mules for transportation, so these auxiliaries were operated by civilians, who might run away if conditions looked bad. In combat, small units fought well, but their old-fashioned tactics were hardly of use against the Napoleonic forces, despite repeated desperate efforts at last-minute reform. When war broke out with France in 1808, the army was deeply unpopular. Leading generals were assassinated, and the army proved incompetent to handle command-and-control. Junior officers from peasant families deserted and went over to the insurgents; many units disintegrated. Spain was unable to mobilize its artillery or cavalry. In the war, there was one victory at the Battle of Bailén, and many humiliating defeats. Conditions steadily worsened, as the insurgents increasingly took control of Spain's battle against Napoleon. Napoleon ridiculed the army as "the worst in Europe"; the British who had to work with it agreed. It was not the Army that defeated Napoleon, but the insurgent peasants Whom Napoleon ridiculed as packs of "bandits led by monks" (they in turn believed Napoleon was the devil0. By 1812, the army controlled only scattered enclaves, and could only harass the French with occasional raids. The morale of the army had reached a nadir, and reformers stripped the aristocratic officers of most of their legal privileges. 
Spain initially sided against France in the Napoleonic Wars, but the defeat of her army early in the war led to Charles IV's pragmatic decision to align with the revolutionary French. Spain was put under a British blockade, and her colonies began to trade independently with Britain but it was the defeat of the British invasions of the Río de la Plata in South America (1806 and 1807) that emboldened independence and revolutionary hopes in Spain's North and South American colonies. A major Franco-Spanish fleet was lost at the Battle of Trafalgar in 1805, prompting the vacillating king of Spain to reconsider his difficult alliance with Napoleon. Spain temporarily broke off from the Continental System, and Napoleon – aggravated with the Bourbon kings of Spain – invaded Spain in 1808 and deposed Ferdinand VII, who had been on the throne only forty-eight days after his father's abdication in March 1808. On July 20, 1808, Joseph Bonaparte, eldest brother of Napoleon Bonaparte, entered Madrid and established a government by which he became King of Spain, serving as a surrogate for Napoleon.
The former Spanish king was dethroned by Napoleon, who put his own brother on the throne. Spaniards revolted. Thompson says the Spanish revolt was, "a reaction against new institutions and ideas, a movement for loyalty to the old order: to the hereditary crown of the Most Catholic kings, which Napoleon, an excommunicated enemy of the Pope, had put on the head of a Frenchman; to the Catholic Church persecuted by republicans who had desecrated churches, murdered priests, and enforced a "loi des cultes"; and to local and provincial rights and privileges threatened by an efficiently centralized government. "Juntas" were formed all across Spain that pronounced themselves in favor of Ferdinand VII. On September 26, 1808, a Central Junta was formed in the town of Aranjuez to coordinate the nationwide struggle against the French. Initially, the Central Junta declared support for Ferdinand VII, and convened a "General and Extraordinary Cortes" for all the kingdoms of the Spanish Monarchy. On February 22 and 23, 1809, a popular insurrection against the French occupation broke out all over Spain. 
The peninsular campaign was a disaster for France. Napoleon did well when he was in direct command, but that followed severe losses, and when he left in 1809 conditions grew worse for France. Vicious reprisals, famously portrayed by Goya in "The Disasters of War", only made the Spanish guerrillas angrier and more active; the war in Spain proved to be a major, long-term drain on French money, manpower and prestige.
In March 1812, the Cádiz Cortes created the first modern Spanish constitution, the Constitution of 1812 (informally named "La Pepa"). This constitution provided for a separation of the powers of the executive and the legislative branches of government. The Cortes was to be elected by universal suffrage, albeit by an indirect method. Each member of the Cortes was to represent 70,000 people. Members of the Cortes were to meet in annual sessions. The King was prevented from either convening or proroguing the Cortes. Members of the Cortes were to serve single two-year terms. They could not serve consecutive terms; a member could serve a second term only by allowing someone else to serve a single intervening term in office. This attempt at the development of a modern constitutional government lasted from 1808 until 1814. Leaders of the liberals or reformist forces during this revolution were José Moñino, Count of Floridablanca, Gaspar Melchor de Jovellanos and Pedro Rodríguez, Conde de Campomanes. Born in 1728, Floridablanca was eighty years of age at the time of the revolutionary outbreak in 1808. He had served as Prime Minister under King Charles III of Spain from 1777 until 1792; However, he tended to be suspicious of the popular spontaneity and resisted a revolution. Born in 1744, Jovellanos was somewhat younger than Floridablanco. A writer and follower of the philosophers of the Enlightenment tradition of the previous century, Jovellanos had served as Minister of Justice from 1797 to 1798 and now commanded a substantial and influential group within the Central Junta. However, Jovellanos had been imprisoned by Manuel de Godoy, Duke of Alcudia, who had served as the prime minister, virtually running the country as a dictator from 1792 until 1798 and from 1801 until 1808. Accordingly, even Jovellanos tended to be somewhat overly cautious in his approach to the revolutionary upsurge that was sweeping Spain in 1808.
The Spanish army was stretched as it fought Napoleon's forces because of a lack of supplies and too many untrained recruits, but at Bailén in June 1808, the Spanish army inflicted the first major defeat suffered by a Napoleonic army; this resulted in the collapse of French power in Spain. Napoleon took personal charge and with fresh forces reconquered Spain in a matter of months, defeating the Spanish and British armies in a brilliant campaign of encirclement. After this the Spanish armies lost every battle they fought against the French imperial forces but were never annihilated; after battles they would retreat into the mountains to regroup and launch new attacks and raids. Guerrilla forces sprang up all over the country and with the army, tied down huge numbers of Napoleon's troops, making it difficult to sustain concentrated attacks on enemy forces. The attacks and raids of the Spanish army and guerrillas became a massive drain on Napoleon's military and economic resources. In this war, Spain was aided by the British and Portuguese, led by the Duke of Wellington. The Duke of Wellington fought Napoleon's forces in the Peninsular War, with Joseph Bonaparte playing a minor role as king at Madrid. The brutal war was one of the first guerrilla wars in modern Western history. French supply lines stretching across Spain were mauled repeatedly by the Spanish armies and guerrilla forces; thereafter, Napoleon's armies were never able to control much of the country. The war fluctuated, with Wellington spending several years behind his fortresses in Portugal while launching occasional campaigns into Spain.
After Napoleon's disastrous 1812 campaign in Russia, Napoleon began to recall his forces for the defence of France against the advancing Russian and other coalition forces, leaving his forces in Spain increasingly undermanned and on the defensive against the advancing Spanish, British and Portuguese armies. At the Battle of Vitoria in 1813, an allied army under the Duke of Wellington decisively defeated the French and in 1814 Ferdinand VII was restored as King of Spain.
Loss of North and South American colonies.
Spain lost all of its North and South American colonies, except Cuba and Puerto Rico, in a complex series of revolts 1808-1826. Spain was at war with Britain 1798-1808, and the British Navy cut off its ties to its colonies. Trade was handled by American and Dutch traders. The colonies thus had achieved economic independence from Spain, and set up temporary governments or juntas which were generally out of touch with the mother country. After 1814, as Napoleon was defeated and Ferdinand VII was back on the throne, the king sent armies to regain control and reimpose autocratic rule. In the next phase 1809–16, Spain defeated all the uprising. A second round 1816–25 was successful and drove the Spanish out of all of its mainland holdings. Spain had no help from European powers. Indeed Britain (and the United States) worked against it. When they were cut off from Spain, the colonies saw a struggle for power between Spaniards who were born in Spain (called "peninsulares") and those of Spanish descent born in New Spain (called "creoles"). The creoles were the activists for independence. Multiple revolutions enabled the colonies to break free of the mother country. In 1824 the armies of generals José de San Martín of Argentina and Simón Bolívar of Venezuela defeated the last Spanish forces; the final defeat came at the Battle of Ayacucho in southern Peru. After that Spain played a minor role in international affairs. Business and trade in the ex-colonies were under British control. Spain kept only Cuba and Puerto Rico in the New World.
Reaction and change (1814–1873).
Although the "juntas", that had forced the French to leave Spain, had sworn by the liberal Constitution of 1812, Ferdinand VII had the support of conservatives and he rejected it. He ruled in the authoritarian fashion of his forebears.
The government, nearly bankrupt, was unable to pay her soldiers. There were few settlers or soldiers in Florida, so it was sold to the United States for 5 million dollars. In 1820, an expedition intended for the colonies revolted in Cadiz. When armies throughout Spain pronounced themselves in sympathy with the revolters, led by Rafael del Riego, Ferdinand relented and was forced to accept the liberal Constitution of 1812. This was the start of the second bourgeois revolution in Spain, which would last from 1820 to 1823. Ferdinand himself was placed under effective house arrest for the duration of the liberal experiment.
The tumultuous three years of liberal rule that followed (1820–1823) were marked by various absolutist conspiracies. The liberal government, which reminded European statesmen entirely too much of the governments of the French Revolution, was viewed with hostility by the Congress of Verona in 1822, and France was authorized to intervene. France crushed the liberal government with massive force in the so-called "Hundred Thousand Sons of Saint Louis" expedition, and Ferdinand was restored as absolute monarch in 1823. In Spain proper, this marked the end of the second Spanish bourgeois revolution.
In Spain, the failure of the second bourgeois revolution was followed by a period of uneasy peace for the next decade. Having borne only a female heir presumptive, it appeared that Ferdinand would be succeeded by his brother, Infante Carlos of Spain. While Ferdinand aligned with the conservatives, fearing another national insurrection, he did not view the Carlos's reactionary policies as a viable option. Ferdinand – resisting the wishes of his brother – decreed the Pragmatic Sanction of 1830, enabling his daughter Isabella to become Queen. Carlos, who made known his intent to resist the sanction, fled to Portugal.
Ferdinand's death in 1833 and the accession of Isabella II as Queen of Spain sparked the First Carlist War (1833–1839). Isabella was only three years old at the time so her mother, Maria Cristina of Bourbon-Two Sicilies, was named regent until her daughter came of age. Carlos invaded the Basque country in the north of Spain and attracted support from absolutist reactionaries and conservatives; these forces were known as the "Carlist" forces. The supporters of reform and of limitations on the absolutist rule of the Spanish throne rallied behind Isabella and the regent, Maria Christina; these reformists were called "Cristinos." Though Cristino resistance to the insurrection seemed to have been overcome by the end of 1833, Maria Cristina's forces suddenly drove the Carlist armies from most of the Basque country. Carlos then appointed the Basque general Tomás de Zumalacárregui as his commander-in-chief. Zumalacárregui resuscitated the Carlist cause, and by 1835 had driven the Cristino armies to the Ebro River and transformed the Carlist army from a demoralized band into a professional army of 30,000 of superior quality to the government forces. Zumalacárregui's death in 1835 changed the Carlists' fortunes. The Cristinos found a capable general in Baldomero Espartero. His victory at the Battle of Luchana (1836) turned the tide of the war, and in 1839, the Convention of Vergara put an end to the first Carlist insurrection.
The progressive General Espartero, exploiting his popularity as a war hero and his sobriquet "Pacifier of Spain", demanded liberal reforms from Maria Cristina. The Queen Regent, who resisted any such idea, preferred to resign and let Espartero become regent instead in 1840. Espartero's liberal reforms were then opposed by moderates, and the former general's heavy-handedness caused a series of sporadic uprisings throughout the country from various quarters, all of which were bloodily suppressed. He was overthrown as regent in 1843 by Ramón María Narváez, a moderate, who was in turn perceived as too reactionary. Another Carlist uprising, the Matiners' War, was launched in 1846 in Catalonia, but it was poorly organized and suppressed by 1849.
Isabella II of Spain took a more active role in government after coming of age, but she was immensely unpopular throughout her reign (1833–1868). She was viewed as beholden to whoever was closest to her at court, and the people of Spain believed that she cared little for them. As a result, there was another insurrection in 1854 led by General Domingo Dulce y Garay and General Leopoldo O'Donnell y Jarris. Their coup overthrew the dictatorship of Luis Jose Sartorius, 1st Count of San Luis. As the result of the popular insurrection, the "Partido Progresista" (Progressive Party) obtained widespread support in Spain and came to power in the government in 1854. In 1856, Isabella attempted to form the Liberal Union, a pan-national coalition under the leadership of Leopoldo O'Donnell, who had already marched on Madrid that year and deposed another Espartero ministry. Isabella's plan failed and cost Isabella more prestige and favor with the people. In 1860, Isabella launched a successful war against Morocco, waged by generals O'Donnell and Juan Prim that stabilized her popularity in Spain. However, a campaign to reconquer Peru and Chile during the Chincha Islands War (1864–1866) proved disastrous and Spain suffered defeat before the determined South American powers.
In 1866, a revolt led by Juan Prim was suppressed, but in 1868 there was a further revolt, known as the Glorious Revolution. The "progresista" generals Francisco Serrano and Juan Prim revolted against Isabella and defeated her "moderado" generals at the Battle of Alcolea (1868). Isabella was driven into exile in Paris.
Two years of revolution and anarchy followed, until in 1870 the Cortes declared that Spain would again have a king. Amadeus of Savoy, the second son of King Victor Emmanuel II of Italy, was selected and duly crowned King of Spain early the following year. Amadeus – a liberal who swore by the liberal constitution the Cortes promulgated – was faced immediately with the incredible task of bringing the disparate political ideologies of Spain to one table. The country was plagued by internecine strife, not merely between Spaniards but within Spanish parties.
First Spanish Republic (1873–1874).
Following the Hidalgo affair and an army rebellion, Amadeus famously declared the people of Spain to be ungovernable, abdicated the throne, and left the country (11 February 1873).
In his absence, a government of radicals and Republicans was formed that declared Spain a republic. The First Spanish Republic (1873–1874) was immediately under siege from all quarters. The Carlists were the most immediate threat, launching a violent insurrection after their poor showing in the 1872 elections. There were calls for socialist revolution from the International Workingmen's Association, revolts and unrest in the autonomous regions of Navarre and Catalonia, and pressure from the Catholic Church against the fledgling republic.
The Restoration (1874–1931).
Although the former queen, Isabella II was still alive, she recognized that she was too divisive as a leader, and abdicated in 1870 in favor of her son, Alfonso.
Alfonso XII of Spain was duly crowned on 28 December 1874 after returning from exile. After the tumult of the First Spanish Republic, Spaniards were willing to accept a return to stability under Bourbon rule. The Republican armies in Spain — which were resisting a Carlist insurrection — pronounced their allegiance to Alfonso in the winter of 1874–1875, led by Brigadier General Martínez-Campos. The Republic was dissolved and Antonio Cánovas del Castillo, a trusted advisor to the king, was named Prime Minister on New Year's Eve, 1874. The Carlist insurrection was put down vigorously by the new king, who took an active role in the war and rapidly gained the support of most of his countrymen. A system of "turnos" was established in Spain in which the liberals, led by Práxedes Mateo Sagasta and the conservatives, led by Antonio Cánovas del Castillo, alternated in control of the government. A modicum of stability and economic progress was restored to Spain during Alfonso XII's rule (1874–1885), although progress was cut short by his sudden death at age 28.
Constitutional monarchy continued under King Alfonso XIII. Alfonso XIII was born after his father's death and was proclaimed king upon his birth. However, the government had become destabilized by Alfonso XII's unexpected death in 1885, followed by the assassination of prime minister Antonio Cánovas del Castillo in 1897. The reign of Alfonso XIII (1886–1931) saw the Spanish–American War of 1898, culminating in the loss of the Philippines plus Spain's last colonies in the Americas, Cuba and Puerto Rico; the "Great War" in Europe (now known as World War I, 1914–1918), although Spain maintained neutrality throughout the conflict; the influenza pandemic nicknamed the Spanish Flu (1918–1919); and the Rif War in Morocco (1920–1926). His reign also saw the rise to dictatorship of General Miguel Primo de Rivera, who seized control of the government by military coup in 1923 and ruled as a dictator – with the monarch's support – for seven years (1923–1930). The world-wide recession, marked first by the Wall Street Crash of 1929, caused deepening economic hardships in Spain and the resignation of Primo de Rivera's government in 1930. General elections were held in 1931 to replace the government, with Republican and anticlerical candidates winning the majority of votes. Alfonso XIII left the country in response to the proclamation of the Second Spanish Republic, although he never abdicated.
Disaster of 1898.
Cuba rebelled against Spain in the Ten Years' War beginning in 1868, resulting in the abolition of slavery in Spain's colonies in the New World. American business interests in the island, coupled with concerns for the people of Cuba, aggravated relations between the two countries. The explosion of the USS "Maine" launched the Spanish–American War in 1898, in which Spain fared disastrously. Cuba gained its independence and Spain lost its remaining New World colony, Puerto Rico, which together with Guam and the Philippines were ceded to the United States for 20 million dollars. In 1899, Spain sold its remaining Pacific islands—the Northern Mariana Islands, Caroline Islands and Palau—to Germany and Spanish colonial possessions were reduced to Spanish Morocco, Spanish Sahara and Spanish Guinea, all in Africa.
The "disaster" of 1898 created the Generation of '98, a group of statesmen and intellectuals who demanded liberal change from the new government. However both Anarchism on the left and fascism on the right grew rapidly in Spain in the early 20th century. A revolt in 1909 in Catalonia was bloodily suppressed. Jensen (1999) argues that the defeat of 1898 led many military officers to abandon the liberalism that had been strong in the officer corps and turn to the right. They interpreted the American victory in 1898 as well as the Japanese victory against Russia in 1905 as proof of the superior value of willpower and moral values over technology. Over the next three decades, Jensen argues, these values shaped the outlook of Francisco Franco and other Falangists.
The 20th century.
1914–31.
Spain's neutrality in World War I allowed it to become a supplier of material for both sides to its great advantage, prompting an economic boom in Spain. The outbreak of Spanish influenza in Spain and elsewhere, along with a major economic slowdown in the postwar period, hit Spain particularly hard, and the country went into debt. A major worker's strike was suppressed in 1919.
Spanish colonial policies in Spanish Morocco led to an uprising known as the Rif War; rebels took control of most of the area except for the enclaves of Ceuta and Melilla in 1921. King Alfonso XIII decided to support the dictatorship of General Miguel Primo de Rivera in 1923. As Prime Minister Primo de Rivera promised to reform the country quickly and restore elections soon. He deeply believed that it was the politicians who had ruined Spain and that governing without them he could regenerate the nation. His slogan was "Country, Religion, Monarchy."
 Spain (in joint action with France) won a decisive military victory in Morocco, (1925–1926). The war had dragged on since 1917 and cost Spain $800 million.
The late 1920s were prosperous until the worldwide Great Depression hit in 1929. In early 1930 bankruptcy and massive unpopularity forced the king to remove Primo de Rivera. Historians depict an idealistic but inept dictator who did not understand government, lacked clear ideas and showed very little political acumen. He consulted no one, had a weak staff, and made frequent strange pronouncements. He started with very broad support but lost every element until only the army was left. His projects ran large deficits which he kept hidden. His multiple repeated mistakes discredited the king and ruined the monarchy, while heightening social tensions that led in 1936 to a full-scale Spanish Civil War. Urban voters had lost faith in the king, and voted for republican parties in the municipal elections of April 1931. The king fled the country without abdicating and a republic was established.
Second Spanish Republic (1931–39).
Political ideologies were intensely polarized, as both right and left saw vast evil conspiracies on the other side that had to be stopped. The central issue was the role of the Catholic Church, which the left saw as the major enemy of modernity and the Spanish people, and the right saw as the invaluable protector of Spanish values.
Power seesawed back and forth, 1931-36 as the monarchy was overthrown, and complex coalitions formed and fell apart. The end came in a devastating civil war, 1936–39, which was won by the conservative, pro-church, Army-backed “Nationalist” forces supported by Nazi Germany and Italy. The Nationalists, led by General Francisco Franco, defeated the Republican coalition of liberals, socialists, anarchists, and communists, which was backed by the Soviet Union.
Under the Second Spanish Republic, women were allowed to vote in general elections for the first time. The Republic devolved substantial autonomy to the Basque Country and to Catalonia.
The first governments of the Republic were center-left, headed by Niceto Alcalá-Zamora and Manuel Azaña. Economic turmoil, substantial debt, and fractious, rapidly changing governing coalitions led to escalating political violence and attempted coups by right and left.
In 1933, the right-wing Spanish Confederation of the Autonomous Right (CEDA), based on the Catholic vote, won power. An armed rising of workers in October 1934, which reached its greatest intensity in Asturias and Catalonia, was forcefully put down by the CEDA government. This in turn energized political movements across the spectrum in Spain, including a revived anarchist movement and new reactionary and fascist groups, including the Falange and a revived Carlist movement.
Spanish Civil War (1936–39).
The Spanish Civil War was marked by numerous small battles and sieges, and many atrocities, until the rebels (the "Nationalists"), led by Francisco Franco, won in 1939. There was military intervention as Italy sent land forces, and Germany sent smaller elite air force and armored units to the rebel side (the Nationalists). The Soviet Union sold armaments to the "Loyalists" ("Republicans"), while the Communist parties in numerous countries sent soldiers to the "International Brigades." The civil war did not escalate into a larger conflict, but did become a worldwide ideological battleground that pitted the left and many liberals against Catholics and conservatives. Britain, France and the United States remained neutral and refused to sell military supplies. Worldwide there was a decline in pacifism and a growing sense that another world war was imminent, and that it would be worth fighting for.
Political and military balance.
In the 1930s, Spanish politics were polarized at the left and right extremes of the political spectrum. The left-wing favored class struggle, land reform to overthrow the land owners, autonomy to the regions, and the destruction of the Catholic Church. The right-wing groups, the largest of which was CEDA, a Catholic coalition, believed in tradition, stability and hierarchy. Religion was the main dividing line between right and left, but there were regional variations. The Basques were devoutly Catholic but they put a high priority on regional autonomy. The Left offered a better deal so in 1936-37 they fought for the Republicans. In 1937 they pulled out of the war.
The Spanish Republican government moved to Valencia, to escape Madrid, which was under siege by the Nationalists. It had some military strength in the Air Force and Navy, but it had lost nearly all of the regular Army. After opening the arsenals to give rifles, machine guns and artillery to local militias, it had little control over the Loyalist ground forces. Republican diplomacy proved ineffective, with only useful two allies, the Soviet Union and Mexico. Britain, France and 27 other countries had agreed on an arms embargo to Spain, and the United States went along. Nazi Germany and Fascist Italy both signed that agreement, but ignored it and sent supplies and vital help, including a powerful air force under German command, the Condor Legion. Tens of thousands of Italian arrived under Italian command. Portugal supported the Nationalists, and allowed the trans-shipment of supplies to Franco's forces. The Soviets sold tanks and other armaments for Spanish gold, and sent well-trained officers and political commissars. It organized the mobilization of tens of thousands of mostly communist volunteers from around the world, who formed the International Brigades .
In 1936, the Left united in the Popular Front and were elected to power. However, this coalition, dominated by the centre-left, was undermined both by the revolutionary groups such as the anarchist Confederación Nacional del Trabajo (CNT) and Federación Anarquista Ibérica (FAI) and by anti-democratic far-right groups such as the Falange and the Carlists. The political violence of previous years began to start again. There were gunfights over strikes; landless labourers began to seize land, church officials were killed and churches burnt. On the other side, right wing militias (such as the Falange) and gunmen hired by employers assassinated left wing activists. The Republican democracy never generated the consensus or mutual trust between the various political groups that it needed to function peacefully. As a result, the country slid into civil war. The right wing of the country and high ranking figures in the army began to plan a coup, and when Falangist politician José Calvo-Sotelo was shot by Republican police, they used it as a signal to act whilst the Republican leadership was confused and inert.
Military operations.
The Nationalists under Franco won the war, and historians continue to debate the reasons. The Nationalists were much better unified and led than the Republicans, who squabbled and fought amongst themselves endlessly and had no clear military strategy. The Army went over to the Nationalists, but it was very poorly equipped—there were no tanks or modern airplanes. The small navy supported the Republicans, but their armies were made up of raw recruits and they lacked both equipment and skilled officers and sergeants. Nationalist senior officers were much better trained and more familiar with modern tactics than the Republicans.
On 17 July 1936, General Francisco Franco brought the colonial army stationed in Morocco to the mainland, while another force from the north under General Mola moved south from Navarre. Another conspirator, General Sanjurjo, who was in exile in Portugal, was killed in a plane crash while being brought to join the other military leaders. Military units were also mobilised elsewhere to take over government institutions. Franco intended to seize power immediately, but successful resistance by Republicans in key the centers of Madrid, Barcelona, Valencia, the Basque country (and other points) meant that Spain faced a prolonged civil war. By 1937 much of the south and west was under the control of the Nationalists, whose Army of Africa was the most professional force available to either side. Both sides received foreign military aid: the Nationalists from Nazi Germany and Italy, while the Republicans were supported by organised far-left volunteers from the Soviet Union.
The Siege of the Alcázar at Toledo early in the war was a turning point, with the Nationalists winning after a long siege. The Republicans managed to hold out in Madrid, despite a Nationalist assault in November 1936, and frustrated subsequent offensives against the capital at Jarama and Guadalajara in 1937. Soon, though, the Nationalists began to erode their territory, starving Madrid and making inroads into the east. The North, including the Basque country fell in late 1937 and the Aragon front collapsed shortly afterwards. The bombing of Guernica on the afternoon of 26 April 1937 – a mission used as a testing ground for the German Luftwaffe's Condor Legion – was probably the most infamous event of the war and inspired Picasso's painting. The Battle of the Ebro in July–November 1938 was the final desperate attempt by the Republicans to turn the tide. When this failed and Barcelona fell to the Nationalists in early 1939, it was clear the war was over. The remaining Republican fronts collapsed, as civil war broke out inside the Left, as the Republicans suppressed the Communists. Madrid fell in March 1939.
The war, cost between 300,000 to 1,000,000 lives. It ended with the total collapse of the Republic and the accession of Francisco Franco as dictator of Spain. Franco amalgamated all the right wing parties into a reconstituted fascist party Falange and banned the left-wing and Republican parties and trade unions. The Church was more powerful than it had been in centuries,
The conduct of the war was brutal on both sides, with widespread massacres of civilians and prisoners. After the war, many thousands of Republicans were imprisoned and up to 150,000 were executed between 1939 and 1943. Some 500,000 refugees escaped to France; they remained in exile for the years or decades.
The dictatorship of Francisco Franco (1936–75).
During Franco's rule, Spain was officially neutral in World War II and remained largely economically and culturally isolated from the outside world. Under a military dictatorship, Spain saw its political parties banned, except for the official party (Falange). Labor unions were banned and all political activity using violence or intimidation to achieve its goals was forbidden.
Under Franco, Spain actively sought the return of Gibraltar by the United Kingdom, and gained some support for its cause at the United Nations. During the 1960s, Spain began imposing restrictions on Gibraltar, culminating in the closure of the border in 1969. It was not fully reopened until 1985.
Spanish rule in Morocco ended in 1967. Though militarily victorious in the 1957–1958 Moroccan invasion of Spanish West Africa, Spain gradually relinquished its remaining African colonies. Spanish Guinea was granted independence as Equatorial Guinea in 1968, while the Moroccan enclave of Ifni had been ceded to Morocco in 1969. Two cities in Africa, Ceuta and Melilla remain under Spanish rule and sovereignty.
The latter years of Franco's rule saw some economic and political liberalization, the Spanish miracle, including the birth of a tourism industry. Spain began to catch up economically with its European neighbors.
Franco ruled until his death on 20 November 1975, when control was given to King Juan Carlos. In the last few months before Franco's death, the Spanish state went into a paralysis. This was capitalized upon by King Hassan II of Morocco, who ordered the 'Green March' into Western Sahara, Spain's last colonial possession.
Spain since 1975.
Transition to democracy.
The Spanish transition to democracy or new Bourbon restoration was the era when Spain moved from the dictatorship of Francisco Franco to a liberal democratic state. The transition is usually said to have begun with Franco's death on 20 November 1975, while its completion is marked by the electoral victory of the socialist PSOE on 28 October 1982.
Under its current (1978) constitution, Spain is a constitutional monarchy. It comprises 17 autonomous communities (Andalusia, Aragon, Asturias, Balearic Islands, Canary Islands, Cantabria, Castile and León, Castile–La Mancha, Catalonia, Extremadura, Galicia, La Rioja, Community of Madrid, Region of Murcia, Basque Country, Valencian Community, Navarre) and 2 autonomous cities (Ceuta and Melilla).
Between 1978 and 1982, Spain was led by the "Unión del Centro Democrático" governments.
In 1981 the 23-F coup d'état attempt took place. On 23 February Antonio Tejero, with members of the Guardia Civil entered the Congress of Deputies, and stopped the session, where Leopoldo Calvo Sotelo was about to be named prime minister of the government. Officially, the coup d'état failed thanks to the intervention of King Juan Carlos. Spain joined NATO before Calvo-Sotelo left office.
Along with political change came radical change in Spanish society. Spanish society had been extremely conservative under Franco, but the transition to democracy also began a liberalization of values and societal mores.
From 1982 until 1996, the social democratic PSOE governed the country, with Felipe González as prime minister. In 1986, Spain joined the European Economic Community (EEC, now European Union), and the country hosted the 1992 Barcelona Olympics and Seville Expo '92.
Spain within the European Union (1993 to present).
In 1996, the centre-right "Partido Popular" government came to power, led by José María Aznar. On 1 January 1999, Spain exchanged the "peseta" for the new Euro currency. The peseta continued to be used for cash transactions until January 1, 2002. On 11 March 2004 a number of terrorist bombs exploded on busy commuter trains in Madrid by Islamic extremists linked to Al-Qaeda, killing 191 persons and injuring thousands.
The election, held three days after the attacks, was won by the PSOE, and José Luis Rodríguez Zapatero replaced Aznar as prime minister. As José María Aznar and his ministers at first accused ETA of the atrocity, it has been argued that the outcome of the election has been influenced by this event.
In the wake of its joining the EEC, Spain experienced an economic boom during two decades, cut painfully short by the financial crisis of 2008.
During the boom years, Spain attracted a large number of immigrants, especially from the United Kingdom, but also including unknown but substantial illegal immigration, mostly from Latin America, eastern Europe and north Africa.
Spain had the fourth largest economy in the Eurozone, but after 2008 the global economic recession hit Spain hard, with the burst of the housing bubble, unemployment reaching over 25%, and sharp budget cutbacks needed to stay in the Euro zone. The GDP shrank 1.2% in 2012. Losses were especially high in real estate, banking, and construction. Economists concluded in early 2013 that, "Where once Spain's problems were acute, now they are chronic: entrenched unemployment, a large mass of small and medium-sized enterprises with low productivity, and, above all, a constriction in credit.."
With the financial crisis and high unemployment, Spain is now suffering from a combination of continued illegal immigration paired with a massive emigration of workers, forced to seek employment elsewhere under the EU's "Freedom of Movement", with an estimated 700,000, or 1.5% of total population, leaving the country between 2008 and 2013.
Spanish statehood and secessionism.
Although it had been used in treaties as far back as the seventeenth century, it was not until the constitution of 1812 that the name "Españas" became the official name for the Spanish kingdom and "King of the Spains" became the official title of the head of state. It was not until the constitution of 1876 that the singular form of the name, "España" (Spain), became the official name of the Spanish state.
Although colloquially and literally the expression "King of Spain" or "King of the Spains" was already widespread, and although the two crowns, Aragonese and Castilian, were held by the same monarch, and although the different kings had the long-term shared intention of uniting the peninsula under a single kingdom to restore the Visigoth unity, they were never proclaimed officially as a single kingdom until the enactment of the Spanish Constitution of 1812. Portugal was also ruled by the House of Habsburg with Castile and Aragon but this came to an end with a revolt after sixty years.
The statehood of Spain is generally accepted by the population of Spain as the Spanish Constitution of 1978 was massively approved by universal referendum. The vigor of the constitutional regime and tacit support by the Spanish population has been repeatedly confirmed ever since through periodical national elections to configure the Spanish Parliament. Said constitutional bicameral organ represents all the Spanish territories and people, where the national sovereignty is vested.
Still, there are some nationalist movements and political parties of regional scope (i.e. in Aragon, the Canaries, Catalonia, Euskadi, Galicia), mostly with seminal ideologies born in the late 19th century, some enjoying relatively important yet wavering support from local population. Traditional nationalist parties' claims range from increasing transfer of competencies and new financing and tax regime arrangements with the Central Government to sovereign rights and secessionism from Spain.
Spain is ranked among the best democracies in the world by reputed, independent analysts. As the Spanish Constitution legal framework guarantees civil rights, including the freedom of speech, a part of said nationalist regional parties have openly promoted and pursued the secession from Spain, by arguing most notably language, cultural and historic reasons and in some cases, also justified by alleged race issues.
Economic reasons are also a separatists' recurrent argument. The ongoing Catalan campaign for independence includes the motto "Spain is robbing us" ("España nos roba"), an argument refuted by many and claimed to be as simply propaganda for the nationalists and secessionists interests. Secessionists claim that an independent Catalan State, released from its financial contribution to the rest of Spain, would grow prosper and solve the difficulties currently faced by the autonomous region, an already self-governed economy, in particular local unemployment and Catalan public debt issues.
In parallel to the democratic arena and political activism, some terrorists groups (i.e. TERRA LLIURE (Catalan for "Free Land"), ETA (Basque acronym for "Basque Homeland and Freedom")) engaged in criminal activities (assassinations -indiscriminate bomb attacks to civilians incl.- extorsions or kidnappings) in an attempt to reach their secessionist goals. It has been recently noticed an increasing extremism in Catalonia in form of attacks, boycotts and even death menaces to those not supporting secessionist movement and events like the so-called consultation on independence organized by the Catalan government and some civil organisations held in November 2014 despite the manifest illegality of the process as it was previously deemed by the Spanish Constitutional Court. Some analysts believe said extremism could lead some current secessionist groups and individuals to undertake terrorist activities.
The Spanish Constitution configures and enables a modern democratic system with its own procedures to create, modify and derogate any law, including the Constitution itself, or even the adoption of a completely new one as may be decided by the people of Spain. Any such legitimate initiative must comply with the corresponding legal procedures as stated in the Constitution. Integrity and unity of the Spanish territory are therefore not irremovable principles, and secessionism would then be possible but subject to the law and to the sovereignty of the whole Spanish population, as it is proclaimed by the constitutionalists.
The Spanish Constitution of 1978, in its second article, recognizes "nationalities"(a carefully chosen word in order to avoid the more politically charged "nations") and "regions", within the context of "the Spanish nation". Account taken of this rich variety of cultures, Spain has enabled one of the most decentralized systems in Europe and worldwide in terms of decision-making power, its Autonomous Regions enjoying the highest rates of both political and fiscal competencies from an international comparative law viewpoint.
 Distinct traditional regional identities within Spain include the Basques, Catalans, Galicians, Cantabrians and Castilians, among others.

</doc>
<doc id="13305" url="http://en.wikipedia.org/wiki?curid=13305" title="History of the Republic of Turkey">
History of the Republic of Turkey

The Republic of Turkey was created after the overthrow of Sultan Mehmet VI Vahdettin by the new Republican Parliament in 1922. This new regime delivered the "coup de grâce" to the Ottoman state which had been practically wiped away from the world stage following the First World War.
Single-party period, 1923–1946.
The history of modern Turkey begins with the foundation of the republic on October 29, 1923, with Mustafa Kemal (Atatürk) as its first president. The government was formed from the Ankara-based revolutionary group, led by Mustafa Kemal Atatürk and his colleagues. The second constitution was ratified by the Grand National Assembly on April 20, 1924.
For about the next 10 years, the country saw a steady process of secular Westernization through Atatürk's Reforms, which included the unification of education; the discontinuation of religious and other titles; the closure of Islamic courts and the replacement of Islamic canon law with a secular civil code modeled after Switzerland's and a penal code modeled after the Italian Penal Code; recognition of the equality between the sexes and the granting of full political rights to women on 5 December 1934; the language reform initiated by the newly founded Turkish Language Association; replacement of the Ottoman Turkish alphabet with the new Turkish alphabet derived from the Latin alphabet; the dress law (the wearing of a fez, is outlawed); the law on family names; and many others.
Chronology of Major Kemalist Reforms: 
The first party to be established in the newly formed republic was the Women's Party (Kadınlar Halk Fırkası). It was founded by Nezihe Muhiddin and several other women but was stopped from its activities, since during the time women were not yet legally allowed to engage in politics. The actual passage to multi-party period was first attempted with the Liberal Republican Party by Ali Fethi Okyar. The Liberal Republican Party was dissolved on 17 November 1930 and no further attempt for a multi-party democracy was made until 1945. Turkey was admitted to the League of Nations in July 1932.
Atatürk's successor after his death on November 10, 1938 was İsmet İnönü. He started his term in the office as a respected figure of the Independence War but because of internal fights between power groups and external events like the World War which caused a lack of goods in the country, he lost some of his popularity and support.
World War II.
After failing in 1939 to get a defensive alliance against Germany with Britain, Turkey maintained neutrality during the war (1939–45). Ambassadors from the Axis powers and Allies intermingled in Ankara. İnönü signed a non-aggression treaty with Nazi Germany on June 18, 1941, 4 days before the Axis powers invaded the Soviet Union.
Nationalist magazines Bozrukat and Chinar Altu called for the declaration of war against the Soviet Union. In July 1942, Bozrukat published a map of Greater Turkey, which included Soviet controlled Caucasus and central Asian republics.
In August 1942, during talks with the German ambassador, Turkish prime minister Şükrü Saracoğlu stated: "The Russian problem can only be solved in case half the Russian population is exterminated."
In the summer of 1942, Turkish high command considered war with the Soviet Union almost unavoidable. An operation was planned, with Baku being the initial target.
Turkey traded with both sides and purchased arms from both sides. The Allies tried to stop German purchases of chrome (used in making better steel). Inflation was high as prices doubled.
By August 1944, the Axis was clearly losing the war and Turkey broke off relations. Only in February 1945, Turkey declared war on Germany and Japan, a symbolic move that allowed Turkey to join the future United Nations.
On October 24, 1945 Turkey signed the United Nations Charter as one of the fifty-one original members.
In 1946, İnönü's government organized multi-party elections, which were won by his party. He remained as the president of the country until 1950. He is still remembered as one of the key figures of Turkey.
Multi-party period, 1946–present.
The real multi-party period begins with the election of the Democratic Party government in 1950.
The government of Adnan Menderes (1950-1960) proved very popular at first, relaxing the restrictions on Islam and presiding over a booming economy. In the latter half of the 1950s, however, the economy began to fail and the government introduced censorship laws limiting dissent. The government became plagued by high inflation and a massive debt.
On May 27, 1960, General Cemal Gürsel led a military coup d'état, removing President Celal Bayar and Prime Minister Menderes, the second of whom was executed. The system returned to civilian control in October 1961. A fractured political system emerged in the wake of the 1960 coup, producing a series of unstable government coalitions in parliament alternating between the Justice Party of Süleyman Demirel on the right and the Republican People's Party of İsmet İnönü and Bülent Ecevit on the left.
The army issued a memorandum warning the civilian government in 1971, leading to another coup which resulted in the fall of the Demirel government and the establishment of interim governments.
In 1974, under Prime Minister Ecevit in coalition with the religious National Salvation Party, Turkey carried out an invasion of Cyprus.
The governments of the National Front, a series of coalitions between rightist parties, followed as Ecevit was not able to remain in office despite ranking first in the elections. The fractured political scene and poor economy led to mounting violence between ultranationalists and communists in the streets of Turkey's cities, resulting in some 5,000 deaths during the late 1970s.
A military coup d'état, headed by General Kenan Evren, took place in 1980. Martial law was extended from 20 to all then existing 67 provinces of Turkey. Within two years, the military returned the government to civilian hands, although retaining close control of the political scene. The political system came under one-party governance under the Motherland Party (ANAP) of Turgut Özal (Prime Minister from 1983 to 1989). The Motherland Party combined a globally oriented economic program with the promotion of conservative social values. Under Özal, the economy boomed, converting towns like Gaziantep from small provincial capitals into mid-sized economic boomtowns. Military rule began to be phased out at the end of 1983. In particular in provinces in the south-east of Turkey it was replaced by a state of emergency. In 1985 the government established village guards (local paramilitary militias) to oppose separatist Kurdish groups.
Starting in July 1987, the South-East was submitted to state of emergency legislation, a measure which lasted until November 2002. With the turn of the 1990s, political instability returned. The 1995 elections brought a short-lived coalition between Mesut Yılmaz's ANAP and the True Path Party, now with Tansu Çiller at the helm.
In 1997, the military, citing his government's support for religious policies deemed dangerous to Turkey's secular nature, sent a memorandum to Prime Minister Necmettin Erbakan requesting that he resign, which he did. This was named a postmodern coup. Shortly thereafter, the Welfare Party (RP) was banned and reborn as the Virtue Party (FP). A new government was formed by ANAP and Ecevit's Democratic Left Party (DSP) supported from the outside by the center-left Republican People's Party (CHP), led by Deniz Baykal. The DSP became the largest parliamentary party in the 1999 elections. Second place went to the far-right Nationalist Movement Party (MHP). These two parties, alongside Yılmaz's ANAP formed a government. The government was somewhat effective, if not harmonious, bringing about much-needed economic reform, instituting human rights legislation, and bringing Turkey ever closer to the European Union.
AK Party government, 2002–present.
A series of economic shocks led to new elections in 2002, bringing into power the conservative Justice and Development Party (AK Party) of the former mayor of Istanbul, Recep Tayyip Erdoğan. The political reforms of the AK Party has ensured the beginning of the negotiations with the European Union. The AK Party again won the 2007 elections, which followed the controversial August 2007 presidential election, during which AK Party member Abdullah Gül was elected President at the third round. Recent developments in Iraq (explained under positions on terrorism and security), secular and religious concerns, the intervention of the military in political issues, relations with the EU, the United States, and the Muslim world were the main issues. The outcome of this election, which brought the Turkish and Kurdish ethnic/nationalist parties (MHP and DTP) into the parliament, will affect Turkey's bid for the European Union membership, as Turkish perceptions of the current process (or lack thereof) affected the results and will continue to affect policy making in coming years.
AKP is the only government in Turkish political history that has managed to win three general elections in a row with an increasing amount of votes received in each one. The AKP has positioned itself in the midpoint of the Turkish political scene, much thanks to the stability brought by steady economic growth since they came to power in 2002. A large part of the population have welcomed the end of the political and economic instability of the 1990s, often associated with coalition governments - see Economic history of Turkey. 2011 figures showed a 9% GDP growth for Turkey.
Alleged members of a clandestine group called Ergenekon were detained in 2008 as part of a long and complex trial. Members are accused of terrorism and of plotting to overthrow the civilian government.
On 22 February 2010 more than 40 officers were arrested and formally charged with attempting to overthrow the government with respect to so-called "Sledgehammer" plot. The accused included four admirals, a general and two colonels, some of them retired, including former commanders of the Turkish navy and air force (three days later, the former commanders of the navy and air force were released).
Although the 2013 protests in Turkey started as a response against the removal of Taksim Gezi Park in Istanbul, they have sparked riots across the country in cities such as Izmir and Ankara as well.

</doc>
<doc id="13306" url="http://en.wikipedia.org/wiki?curid=13306" title="History of Islam">
History of Islam

The history of Islam concerns the religion of Islam and its adherents, Muslims. "Muslim" is an Arabic word meaning "one who submits to God". Muslims and their religion have greatly impacted the political, economic, and military history of the Old World, especially the Middle East, where its roots lie. Though it is believed by non-Muslims to have originated in Mecca and Medina, Muslims believe that the religion of Islam has been present since the time of the prophet Adam. Muslims believe that prophets Noah, Abraham, Moses, Jesus, among others, were all Islamic prophets, and they have equal veneration in the Qur'an. The Islamic world expanded to include people of the Islamic civilization, inclusive of non-Muslims living in that civilization.
A century after the death of last Islamic prophet Muhammad, the Islamic empire extended from Al-Andalus (Spain) in the west to Indus in the east. The subsequent empires such as those of the Abbasids, Fatimids, Almoravids, Seljukids, Ajuuraan, Adal and Warsangali in Somalia, Mughals in India and Safavids in Persia and Ottomans were among the influential and distinguished powers in the world. The Islamic civilization gave rise to many centers of culture and science and produced notable scientists, astronomers, mathematicians, doctors, nurses and philosophers during the Golden Age of Islam. Technology flourished; there was investment in economic infrastructure, such as irrigation systems and canals; and the importance of reading the Qur'an produced a comparatively high level of literacy in the general populace.
In the later Middle Ages, destructive Mongol invasions from the East, and the loss of population in the Black Death, greatly weakened the traditional centre of the Islamic world, stretching from Persia to Egypt, and the Ottoman Empire was able to conquer most Arabic-speaking areas, creating an Islamic world power again, although one that was unable to master the challenges of the Early Modern period.
Later, in modern history (18th and 19th centuries), many Islamic regions fell under the influence of European Great Powers. After the First World War, Ottoman territories (a Central Powers member) were partitioned into several nations under the terms of the Treaty of Sèvres. 
Islam itself is more a politic ideology than a religion. Although affected by ideologies such as socialism and secularism during much of the 20th century, the Islamic identity and the imposition of Islam on political issues intensified during the early 21st century. Muslim extremism and Islamic regional and international conflicts greatly effected the attitude toward Islam in the contemporary world. Also, in the contemporary period, a set of ideologies holding interpretations of Islamic texts that advocate the unification of religion and state - theocracy - has spread, and as a result, the ideology has been criticized.
Major periods.
The Islamic state and Muslims' system of government evolved through various stages. The precise dates of various periods in history are more or less arbitrary. The "City-state period" lasted from 620s to 630s. The "Imperial period" lasted from 630s to 750s. The "Universal period" lasted from 750s to around 900s. These correspond to the early period of post-classical history. The ""Decentralization" period" lasted from around 900s to the early 1500s. This correspond to the high period and late period of post-classical history. The ""Fragmentation" period" lasted from around 1500s to the late 1910s. The contemporary period, referred to as the "National period", lasted from 1910s into the twenty-first century.
Early sources.
The study of the earliest periods in Islamic history is made difficult by a lack of sources. For example, the most important historiographical source for the origins of Islam is the work of al-Tabari. While al-Tabari was an excellent historian by the standards of his time and place, use of his work as a source is problematic for two reasons. For one, his style of historical writing nonetheless permitted liberal use of mythical, legendary, stereotyped, distorted, and polemical presentations of its subject matter. Second, al-Tabari's descriptions of the beginning of Islam post-date the events by a large amount of time, al-Tabari having died in 923 CE.
Differing views about how to deal with the available sources has led to the development of four different approaches to the history of early Islam. All four methods have some level of support today. The "descriptive" method uses the outlines of Islamic traditions, while being adjusted for the stories of miracles and faith-centred claims within those sources. Edward Gibbon and Gustav Weil represent some of the first historians following the descriptive method. On the "source critical" method, a comparison of all the sources is sought in order to identify which informants to the sources are weak and thereby distinguish spurious material. The work of William Montgomery Watt and that of Wilferd Madelung are two source critical examples. On the "tradition critical" method, the sources are believed to be based on oral traditions with unclear origins and transmission history, and so are treated very cautiously. Ignaz Goldziher was the pioneer of the tradition critical method, and Uri Rubin gives a contemporary example. The "skeptical" method doubts nearly all of the material in the traditional sources, regarding any possible historical core as too difficult to decipher from distorted and fabricated material. An early example of the skeptical method was the work of John Wansbrough.
Nowadays, the popularity of the different methods employed varies on the scope of the works under consideration. For overview treatments of the history of early Islam, the descriptive approach is more popular. For scholars who look at the beginnings of Islam in depth, the source critical and tradition critical methods are more often followed.
After the 8th century CE, the quality of sources improves. Those sources which treated earlier times with a large temporal and cultural gap now begin to give accounts which are more contemporaneous, the quality of genre of available historical accounts improves, and new documentary sources—such as official documents, correspondence and poetry—appear. For the time prior to the beginning of Islam—in the 6th century CE—sources are superior as well, if still of mixed quality. In particular, the sources covering the Sasanian realm of influence in the 6th century CE are poor, while the sources for Byzantine areas at the time are of a respectable quality, and complemented by Syriac Christian sources for Syria and Iraq.
Islamic origins.
Islam began within the context of Late Antiquity. In pre-Islamic Arabia, Arab people lived on the Arabian Plate. In the south of Hedjaz (principal religious and commercial center of post-classical Arabia), the Arabic tribe of Quraysh (Adnani Arabs), to which Muhammad belonged, had been in existence. Near Mecca, the tribe was increasing in power. The Quraysh were the guardians of the Kaaba within the town of Mecca and was the dominant tribe of Mecca upon the appearance of Islam. The Kaaba, at the time, was used as an important pagan shrine. It brought revenues to Mecca because of the multitude of pilgrims that it attracted. Muhammad was born into the Banu Hashim tribe of the Quraysh clan, a branch of the Banu Kinanah tribe, descended from Khuzaimah and derived its inheritance from the Khuza'imah (House of Khuza'a).
According to the traditional Islamic view, the Qur'an (Koran) began with revelations to Muhammad by the angel Gabriel in 610. The history of the Qur'an began when its verses were revealed to the Muhammad. The rise of Islam began around the time Muslims took flight in the Hijra, moving to Medina.
In 628, the Makkah tribe of Quraish and the Muslim community in Medina signed a truce called the Treaty of Hudaybiyya beginning a ten-year period of peace. War returned when the Quraish and their allies, the tribe of 'Bakr', attacked the tribe of 'Khuza'ah', who were Muslim allies. In 630, Muslims conquered Mecca. Muhammad died in June 632. The Battle of Yamama was fought in December of the same year, between the forces of the first caliph Abu Bakr and Musailima.
City-states and Imperial period.
After prophet Muhammad died, a series of Caliphs governed the Islamic state: Abu Bakr (632-634), Umar ibn al-Khattab (Umar І, 634-644), Uthman ibn Affan, (644-656), and Ali ibn Abi Talib (656-661). These leaders are known as the "Rashidun" or "rightly guided" Caliphs in Sunni Islam. They oversaw the initial phase of the Muslim conquests, advancing through Persia, Egypt, the Middle East and North Africa.
Umar improved the administration and built cities like Basra and canal and irrigation networks. To be close to the poor, Umar lived in a simple mud hut without doors and walked the streets every evening. After consulting with the poor, Umar established the first welfare state Bayt al-mal. The Bayt al-mal or the welfare state was for the Muslim and non-Muslim poor, needy, elderly, orphans, widows, and the disabled. The Bayt al-mal ran for hundreds of years under the Rashidun Caliphate in the 7th century and continued through the Umayyad period and well into the Abbasid era. Umar also introduced child benefit for the children and pensions for the elderly. The expansion of the state, was partially terminated between 638–639 during the years of great famine and plague in Arabia and Levant respectively. During Umars reign, within 10 years Levant, Egypt, Cyrenaica, Tripolitania, Fezzan, Eastern Anatolia, almost the whole of Sassanid Persian Empire including Bactria, Persia, Azerbaijan, Armenia, Caucasus and Makran were incorporated into Islamic State. When Umar was assassinated in 644, the election of Uthman as successor was met with increasing opposition. The Qur'an was standardized during this time.
Local populations of Jews and indigenous Christians, persecuted as religious minorities and taxed heavily to finance the Byzantine–Sassanid Wars, often aided Muslims to take over their lands from the Byzantines and Persians, resulting in exceptionally speedy conquests. As new areas joining the Islamic state, they also benefited from free trade, while trading with other areas in the Islamic state, so as to encourage commerce, in Islam trade is not taxed, wealth is taxed. The Muslims paid Zakat on their wealth to the poor. Since the Constitution of Medina, was drafted by the Islamic prophet Muhammad the Jews and the Christians continued to use their own laws in the Islamic State and had their own judges. Therefore they only paid for policing for the protection of their property. To assist in the quick expansion of the state, the Byzantine and the Persian tax collection systems were maintained and the people paid a poll tax lower than the one imposed under the Byzantines and the Persians.
In 639, Muawiyah I was appointed as the governor of Syria after the previous governor Abu Ubaidah ibn al-Jarrah died in a plague along with 25,000 other people. To stop the Byzantine harassment from the sea during the Arab–Byzantine wars, in 649 Muawiyah I set up a navy; manned by Monophysitise Christians, Copts and Jacobite Syrian Christians sailors and Muslim troops. This resulted in the defeat of the Byzantine navy at the Battle of the Masts in 655, opening up the Mediterranean.
When Umar was assassinated in 644, Uthman ibn Affan became the next caliph. As it is well known that Arabic language is written without vowels, and when Qur'an reached the non-Arabic speakers, people began having different dielects and phonics which was changing the exact meaning of verses in the Qur'an. This was brought to the notice of Uthman ibn Affan. Begun in the time of Uthman ibn Affan, the compilation of the Qur'an was finished sometime between 650 and 656, Uthman sent copies to the different centers of the expanding Islamic empire. From then on, thousands of Muslim scribes began copying the Qur'an.
The Qur'an and Muhammad talked about racial equality and justice as in the Farewell Sermon. Tribal and nationalistic differences were discouraged. But after Muhammad's passing the old tribal differences between the Arabs started to resurface. Following the Roman–Persian Wars and the Byzantine–Sassanid Wars deep rooted differences between Iraq, formally under the Persian Sassanid Empire and Syria formally under the Byzantine Empire also existed. Each wanted the capital of the newly established Islamic State to be in their area. Previously, the second caliph, Umar, was very firm on the governors and his spies kept an eye on the governors. If he felt that a governor or a commander was becoming attracted to wealth or did not meet the required administrative standards, he had him removed from his position.
Early Muslim armies stayed in encampments away from cities because Umar feared that they may get attracted to wealth and luxury. In the process, they may get away from the worship of God and become attracted to wealth and start accumulating wealth and establishing dynasties. "Wealth and children are [but] adornment of the worldly life. But the enduring good deeds are better to your Lord for reward and better for [one's] hope." Qur'an 18:46 "O you who have believed, let not your wealth and your children divert you from remembrance of Allah . And whoever does that - then those are the losers." Qur'an 63:9 Staying in these encampments away from the cities also ensured that there was no stress on the population and also that the populations remained autonomous and kept their own judges and representatives. Some of these encampments later grew into cities themselves, like Basra and Kufa in Iraq and Fustat in Egypt. Some cities also had agreements with the Muslims, such as during the Siege of Jerusalem in 637 CE.
As Uthman ibn Affan became very old, Marwan I a relative of Muawiyah I slipped into the vacuum and became his secretary and slowly assumed more control and relaxed some of these restrictions. Marwan I had previously been excluded from positions of responsibility. In 656, Muhammad ibn Abi Bakr the son of Abu Bakr and the adopted son of Ali ibn Abi Talib and the great grandfather of Ja'far al-Sadiq showed some Egyptians, the house of Uthman ibn Affan. Later the Egyptians ended up killing Uthman ibn al-Affan. Ali then assumed the position of caliph and moved the capital to Kufa in Iraq. Muawiyah I the governor of Syria, a relative of Uthman ibn al-Affan and Marwan I wanted the culprits arrested. Marwan I manipulated every one and created conflict. This later resulted in the first civil war (the "First Fitna"), Ali was assassinated by Kharijites in 661. Six months later in 661, in the interest of peace, Hasan ibn Ali, highly regarded for his wisdom and as a peacemaker, the Second Imam for the Shias and the grandson of Muhammad, made a peace treaty with Muawiyah I. In the Hasan–Muawiya treaty, Hasan ibn Ali handed over power to Muawiya on the condition that he be just to the people and keep them safe and secure and after his death he does not establish a dynasty. This brought to an end the era of the Rightly Guided Caliphs for the Sunnis and Hasan ibn Ali was also the last Imam for the Shias to be a Caliph. Following this, Muawiyah broke the conditions of the agreement and began the Umayyad dynasty, with its capital in Damascus. After Mu'awiyah's death in 680, conflict over succession broke out again in a civil war known as the "Second Fitna". After making every one else fight, the Umayyad dynasty later fell into the hands of Marwan I who was also an Umayyad. The Umayyads conquered the Maghrib, the Iberian Peninsula, Narbonnese Gaul and Sindh.
After the peace treaty with Ali's son, Hasan ibn Ali, and the suppression of the revolt of the Kharijites, Muawiyah I proclaimed himself Caliph in 661 and began consolidating power. In 663, a new Kharijite revolt resulted in the death of their chief. In 664, Muawiyah and Ziyad ibn Abi Sufyan reached an agreement: the Caliph recognised Ziyad as a brother and appointed him governor at Basra. Ziyad took the name ibn Abi Sufyan. Muawiyah arranged for his son Yazid I to be appointed caliph on his death, which came in 680. Husayn ibn Ali, by then Muhammad's only living grandson, refused to swear allegiance to Yazid. He was killed in the Battle of Karbala the same year, an event still mourned by Shia on the Day of Ashura. Unrest continued in the Second Fitna, but Muslim rule was extended under Muawiyah to Rhodes, Crete, Kabul, Bukhara, and Samarkand, and expanded in North Africa. In 664, Arab armies conquered Kabul, and in 665 pushed into the Maghreb.
The Umayyad dynasty (or "Ommiads"), whose name derives from Umayya ibn Abd Shams, the great-grandfather of the first Umayyad caliph, ruled from 661 to 750. Although the Umayyad family came from the city of Mecca, Damascus was the capital. After the death of Abdu'l-Rahman ibn Abu Bakr in 666, Muawiyah I consolidated his power. Muawiyah I moved his capital to Damascus from Medina, which led to profound changes in the empire. In the same way, at a later date, the transfer of the Caliphate from Damascus to Baghdad marked the accession of a new family to power.
As the state grew, the state expenses increased. Additionally the Bayt al-mal and the Welfare State expenses to assist the Muslim and the non-Muslim poor, needy, elderly, orphans, widows, and the disabled, increased, the Umayyads asked the new converts (mawali) to continue paying the poll tax. The Umayyad rule, with its wealth and luxury also seemed at odds with the Islamic message preached by Muhammad. All this increased discontent. The descendants of Muhammad's uncle Abbas ibn Abd al-Muttalib rallied discontented "mawali", poor Arabs, and some Shi'a against the Umayyads and overthrew them with the help of the general Abu Muslim, inaugurating the Abbasid dynasty in 750, which moved the capital to Baghdad. A branch of the Ummayad family fled across North Africa to Al-Andalus, where they established the Caliphate of Córdoba, which lasted until 1031 before falling due to the Fitna of al-Andalus. The Bayt al-mal, the Welfare State then continued under the Abbasids.
At its largest extent, the Umayyad dynasty covered more than 5000000 sqmi making it one of the largest empires the world had yet seen, and the fifth largest contiguous empire ever. After the Umayyads were overthrown by the Abbasid Caliphate, they fled across North Africa to Al-Andalus, where they established the Caliphate of Córdoba, which lasted until 1031 with the Fitna of al-Andalus.
Muawiyah beautified Damascus, and developed a court to rival that of Constantinople. He expanded the frontiers of the empire, reaching the edge of Constantinople at one point, though the Byzantines drove him back and he was unable to hold any territory in Anatolia. Sunni Muslims credit him with saving the fledgling Muslim nation from post-civil war anarchy. However, Shia Muslims accuse him of instigating the war, weakening the Muslim nation by dividing the Ummah, fabricating self-aggrandizing heresies slandering the Prophet's family and even selling his Muslim critics into slavery in the Byzantine empire. One of Muawiyah's most controversial and enduring legacies was his decision to designate his son Yazid as his successor. According to Shi'a doctrine, this was a clear violation of the treaty he made with Hasan ibn Ali.
In 682 AD Yazid restored Uqba ibn Nafi as the governor of North Africa. Uqba won battles against the Berbers and Byzantines. From there Uqba marched thousands of miles westward towards Tangier, where he reached the Atlantic coast, and then marched eastwards through the Atlas Mountains. With about 300 cavalrymen, he proceeded towards Biskra where he was ambushed by a Berber force under Kaisala. Uqba and all his men died fighting. The Berbers attacked and drove Muslims from north Africa for a period. Weakened by the civil wars the Umayyad lost supremacy at sea, and had to abandon the islands of Rhodes and Crete. Under the rule of Yazid I, some Muslims in Kufa began to think that if Husayn ibn Ali the descendent of Muhammad was their ruler, he would have been more just. He was invited to Kufa but was later betrayed and killed. Later this concept was taken one step further and they started thinking, what if history took a different course and Ali was the first caliph and these ideas were later adopted by some Shia and institutionalised by the Safavids.
The period under Muawiya II was marked by civil wars (Second Fitna). This would ease in the reign of Abd al-Malik ibn Marwan, a well-educated and capable ruler. Despite the many political problems that impeded his rule, all important records were translated into Arabic. In his reign, a currency for the Muslim world was minted. This led to war with the Byzantine Empire under Justinian II (Battle of Sebastopolis) in 692 in Asia Minor. The Byzantines were decisively defeated by the Caliph after the defection of a large contingent of Slavs. The Islamic currency was then made the exclusive currency in the Muslim world. He reformed agriculture and commerce. Abd al-Malik consolidated Muslim rule and extended it, made Arabic the state language, and organized a regular postal service.
Al-Walid I began the next stage of Islamic conquests. Under him the early Islamic empire reached its farthest extent. He reconquered parts of Egypt from the Byzantine Empire and moved on into Carthage and across to the west of North Africa. Muslim armies under Tariq ibn Ziyad crossed the Strait of Gibraltar and began to conquer Spain using North African Berber armies. The Visigoths of Spain were defeated when the Umayyad conquered Lisbon. Spain was the farthest extent of Islamic control of Europe (they were stopped at the Battle of Tours). In the east, Islamic armies under Muhammad bin Qasim made it as far as the Indus Valley. Under Al-Walid, the caliphate empire stretched from Spain to India. Al-Hajjaj ibn Yusuf played a crucial role in the organization and selection of military commanders. Al-Walid paid great attention to the expansion of an organized military, building the strongest navy in the Umayyad era., This tactic was crucial for the expansion to Spain. His reign is considered to be the apex of Islamic power.
Sulayman ibn Abd al-Malik was hailed as caliph the day al-Walid died. He appointed Yazid ibn al-Muhallab governor of Mesopotamia. Sulayman ordered the arrest and execution of the family of al-Hajjaj, one of two prominent leaders (the other was Qutayba ibn Muslim) who had supported the succession of al-Walid's son Yazid, rather than Sulayman. Al-Hajjaj had predeceased al-Walid, so he posed no threat. Qutaibah renounced allegiance to Sulayman, though his troops rejected his appeal to revolt. They killed him and sent his head to Sulayman. Sulayman did not move to Damascus on becoming Caliph, remaining in Ramla. Sulayman sent Maslama ibn Abd al-Malik to attack the Byzantine capital (siege of Constantinople). The intervention of Bulgaria on the Byzantine side proved decisive. The Muslims sustained heavy losses. Sulayman died suddenly in 717.
Yazid II came to power on the death of Umar II. Yazid fought the Kharijites, with whom Umar had been negotiating, and killed the Kharijite leader Shawdhab. In Yazid's reign, civil wars began in different parts of the empire. Yazid expanded the Caliphate's territory into the Caucasus, before dying in 724. Inheriting the caliphate from his brother, Hisham ibn Abd al-Malik ruled an empire with many problems. He was effective in addressing these problems, and in allowing the Umayyad empire to continue as an entity. His long rule was an effective one, and renewed reforms introduced by Umar II. Under Hisham's rule, regular raids against the Byzantines continued. In North Africa, Kharijite teachings combined with local restlessness to produce the Berber Revolt. He was also faced with a revolt by Zayd ibn Ali. Hisham suppressed both revolts. The Abbasids continued to gain power in Khurasan and Iraq. However, they were not strong enough to make a move yet. Some were caught and punished or executed by eastern governors. The Battle of Akroinon, a decisive Byzantine victory, was during the final campaign of the Umayyad dynasty. Hisham died in 743.
Al-Walid II saw political intrigue during his reign. Yazid III spoke out against his cousin Walid's "immorality" which included discrimination on behalf of the Banu Qays Arabs against Yemenis and non-Arab Muslims, and Yazid received further support from the Qadariya and Murji'iya (believers in human free will). Walid was shortly thereafter deposed in a coup. Yazid disbursed funds from the treasury and acceded to the Caliph. He explained that he had rebelled on behalf of the Book of Allah and the Sunna. Yazid reigned for only six months, while various groups refused allegiance and dissident movements arose, after which he died. Ibrahim ibn al-Walid, named heir apparent by his brother Yazid III, ruled for a short time in 744, before he abdicated. Marwan II ruled from 744 until he was killed in 750. He was the last Umayyad ruler to rule from Damascus. Marwan named his two sons Ubaydallah and Abdallah heirs. He appointed governors and asserted his authority by force. Anti-Umayyad feeling was very prevalent, especially in Iran and Iraq. The Abbasids had gained much support. Marwan's reign as caliph was almost entirely devoted to trying to keep the Umayyad empire together. His death signalled the end of Umayyad rule in the East, and was followed by the massacre of Umayyads by the Abbasids. Almost the entire Umayyad dynasty was killed, except for the talented prince Abd al-Rahman who escaped to Spain and founded a dynasty there.
Universal period and decentralization.
Islamic Golden Age.
The Abbasid dynasty rose to power in 750, consolidating the gains of the earlier Caliphates. Initially, they conquered Mediterranean islands including the Balearics and, after, in 827 the Sicily. The ruling party had come to power on the wave of dissatisfaction with the Umayyads, cultivated by the Abbasid revolutionary Abu Muslim. Under the Abbasids Islamic civilization flourished. Most notable was the development of Arabic prose and poetry, termed by "The Cambridge History of Islam" as its "golden age". Commerce and industry (considered a Muslim Agricultural Revolution) and the arts and sciences (considered a Muslim Scientific Revolution) also prospered under Abbasid caliphs al-Mansur (ruled 754 — 775), Harun al-Rashid (ruled 786 — 809), al-Ma'mun (ruled 809 — 813) and their immediate successors.
The capital was moved from Damascus to Baghdad, due to the importance placed by the Abbasids upon eastern affairs in Persia and Transoxania. At this time the caliphate showed signs of fracture amid the rise of regional dynasties. Although the Umayyad family had been killed by the revolting Abbasids, one family member, Abd ar-Rahman I, escaped to Spain and established an independent caliphate there in 756. In the Maghreb, Harun al-Rashid appointed the Arab Aghlabids as virtually autonomous rulers, although they continued to recognise central authority. Aghlabid rule was short-lived, and they were deposed by the Shiite Fatimid dynasty in 909. By around 960, the Fatimids had conquered Abbasid Egypt, building a capital there in 973 called "al-Qahirah" (meaning "the planet of victory", known today as Cairo). In Persia the Turkic Ghaznavids snatched power from the Abbasids. Abbasid influence had been consumed by the Great Seljuq Empire (a Muslim Turkish clan which had migrated into mainland Persia) by 1055.
Expansion continued, sometimes by force, sometimes by peaceful proselytising. The first stage in the conquest of India began just before the year 1000. By some 200 (from 1193 — 1209) years later, the area up to the Ganges river had fallen. In sub-Saharan West Africa, Islam was established just after the year 1000. Muslim rulers were in Kanem starting from sometime between 1081 to 1097, with reports of a Muslim prince at the head of Gao as early as 1009. The Islamic kingdoms associated with Mali reached prominence in the 13th century.
The Abbasids developed initiatives aimed at greater Islamic unity. Different sects of the Islamic faith and mosques, separated by doctrine, history, and practice, were pushed to cooperate. The Abbasids also distinguished themselves from the Umayyads by attacking the Umayyads' moral character and administration. According to Ira Lapidus, "The Abbasid revolt was supported largely by Arabs, mainly the aggrieved settlers of Marw with the addition of the Yemeni faction and their Mawali". The Abbasids also appealed to non-Arab Muslims, known as "mawali", who remained outside the kinship-based society of the Arabs and were perceived as a lower class within the Umayyad empire. Islamic ecumenism, promoted by the Abbasids, refers to the idea of unity of the "Ummah" in the literal meaning: that there was a single faith. Islamic philosophy developed as the Shariah was codified, and the four Madhabs were established. This era also saw the rise of classical Sufism. Religious achievements included completion of the canonical collections of Hadith of Sahih Bukhari and others. Islam recognized to a certain extent the validity of the Abrahamic religions, the Qur'an identifying Jews, Christians, Zoroastrians, and "Sabi'un" or "baptists" (usually taken as a reference to the Mandeans and related Mesopotamian groups) as "people of the book". Toward the beginning of the high Middle Ages, the doctrines of the Sunni and Shia, two major denominations of Islam, solidified and the divisions of the world theologically would form. These trends would continue into the Fatimid and Ayyubid periods.
Politically, the Abbasid Caliphate evolved into an Islamic monarchy (unitary system of government.) The regional Sultanate and Emirate governors' existence, validity, or legality were acknowledged for unity of the state. In the early Islamic philosophy of the Iberian Umayyads, Averroes presented an argument in "The Decisive Treatise", providing a justification for the emancipation of science and philosophy from official Ash'ari theology; thus, Averroism has been considered a precursor to modern secularism.
Golden Baghdad Abbasids.
"Early Middle Ages"
According to Arab sources in the year 750, Al-Saffah, the founder of the Abbasid Caliphate, launched a massive rebellion against the Umayyad Caliphate from the province of Khurasan near Talas. After eliminating the entire Umayyad family and achieving victory at the Battle of the Zab, Al-Saffah and his forces marched into Damascus and founded a new dynasty. His forces confronted many regional powers and consolidated the realm of the Abbasid Caliphate.
In Al-Mansur's time, Persian scholarship emerged. Many non-Arabs converted to Islam. The Umayyads actively discouraged conversion in order to continue the collection of the jizya, or the tax on non-Muslims. Islam nearly doubled within its territory from 8% of residents in 750 to 15% by the end of Al-Mansur's reign. Al-Mahdi, whose name means "Rightly-guided" or "Redeemer", was proclaimed caliph when his father was on his deathbed. Baghdad blossomed during Al-Mahdi's reign, becoming the world's largest city. It attracted immigrants from Arabia, Iraq, Syria, Persia and as far away as India and Spain. Baghdad was home to Christians, Jews, Hindus, and Zoroastrians, in addition to the growing Muslim population. Like his father, Al-Hadi was open to his people and allowed citizens to address him in the palace at Baghdad. He was considered an "enlightened ruler", and continued the policies of his Abbasid predecessors. His short rule was plagued by military conflicts and internal intrigue.
The military conflicts subsided as Harun al-Rashid ruled. His reign was marked by scientific, cultural and religious prosperity. He established the library Bayt al-Hikma ("House of Wisdom"), and the arts and music flourished during his reign. The Barmakid family played a decisive advisorial role in establishing the Caliphate, but declined during Rashid's rule.
According to signed pledges during a pilgrimage to Mecca, Al-Amin received the Caliphate from his father Harun Al-Rashid. Al-Amin faced internal rebellions. General Tahir ibn Husayn rebelled and besieged Baghdad. Tahir led reinforcements to regain positions lost by another officer. When Tahir pushed into the city, Al-Amin sought to negotiate safe passage. Tahir agreed on the condition Al-Amin turn over his sceptre, seal and other signs that he was caliph. Al-Amin tried to leave on a boat and rejected warnings that he wait. Tahir's forces attacked the boat and Al-Amin was thrown into the water. He swam to shore where he was captured and executed. His head was placed on the Al Anbar Gate.
Regional powers.
The Abbasids soon became caught in a three-way rivalry among Coptic Arabs, Indo-Persians, and immigrant Turks. In addition, the cost of running a large empire became too great. The Turks, Egyptians, and Arabs adhered to the Sunnite sect; the Persians, a great portion of the Turkic groups, and several of the princes in India were Shia. The political unity of Islam began to disintegrate. Under the influence of the Abbasid caliphs, independent dynasties appeared in the Muslim world and the caliphs recognized such dynasties as legitimately Muslim. The first was the Tahirid dynasty in Khorasan, which was founded during the caliph Al-Ma'mun's reign. Similar dynasties included the Saffarids, Samanids, Ghaznavids and Seljuqs. During this time, advancements were made in the areas of astronomy, poetry, philosophy, science, and mathematics.
High Baghdad Abbasids.
"Early Middle Ages"
Upon Al-Amin's death, Al-Ma'mun became Caliph. Al-Ma'mun extended the Abbasid empire's territory during his reign and dealt with rebellions. Al-Ma'mun had been named governor of Khurasan by Harun, and after his ascension to power, the caliph named Tahir as governor of his military services in order to assure his loyalty. Tahir and his family became entrenched in Iranian politics and became powerful, frustrating Al-Ma'mun's desire to centralize and strengthen Caliphal power. The rising power of the Tahirid dynasty became a threat as Al-Ma'mun's own policies alienated them and other opponents.
Al-Ma'mun worked to centralize power and ensure a smooth succession. Al-Mahdi proclaimed that the caliph was the protector of Islam against heresy, and also claimed the ability to declare orthodoxy. Religious scholars averred that Al-Ma'mun was overstepping his bounds in the "Mihna", the Abbasid inquisition which he introduced in 833 four months before he died. The "Ulama" emerged as a force in Islamic politics during Al-Ma'mun's reign for opposing the inquisitions. The "Ulema" and the major Islamic law schools took shape in the period of Al-Ma'mun. In parallel, Sunnism became defined as a religion of laws. Doctrinal differences between Sunni and Shi'a Islam became more pronounced.
During the Al-Ma'mun regime, border wars increased. Al-Ma'mun made preparations for a major campaign, but died while leading an expedition in Sardis. Al-Ma'mun gathered scholars of many religions at Baghdad, whom he treated well and with tolerance. He sent an emissary to the Byzantine Empire to collect the most famous manuscripts there, and had them translated into Arabic. His scientists originated alchemy. Shortly before his death, during a visit to Egypt in 832, the caliph ordered the breaching of the Great Pyramid of Giza to search for knowledge and treasure. Workers tunneled in near where tradition located the original entrance. Al-Ma'mun later died near Tarsus under questionable circumstances and was succeeded by his half-brother, Al-Mu'tasim, rather than his son, Al-Abbas ibn Al-Ma'mun.
As Caliph, Al-Mu'tasim promptly ordered the dismantling of al-Ma'mun's military base at Tyana. He faced Khurramite revolts. One of the most difficult problems facing this Caliph was the ongoing uprising of Babak Khorramdin. Al-Mu'tasim overcame the rebels and secured a significant victory. Byzantine emperor Theophilus launched an attack against Abbasid fortresses. Al-Mu'tasim sent Al-Afshin, who met and defeated Theophilus' forces at the Battle of Anzen. On his return he became aware of a serious military conspiracy which forced him and his successors to rely upon Turkish commanders and ghilman slave-soldiers (foreshadowing the Mamluk system). The Khurramiyyah were never fully suppressed, although they slowly declined during the reigns of succeeding Caliphs. Near the end of al-Mu'tasim's life there was an uprising in Palestine, but he defeated the rebels.
During Al-Mu'tasim's reign, the Tahirid dynasty continued to grow in power. The Tahirids were exempted from many tribute and oversight functions. Their independence contributed to Abbasid decline in the east. Ideologically, al-Mu'tasim followed his half-brother al-Ma'mun. He continued his predecessor's support for the Islamic Mu'tazila sect, applying brutal torture against the opposition. Arab mathematician Al-Kindi was employed by Al-Mu'tasim and tutored the Caliph's son. Al-Kindi had served at the House of Wisdom and continued his studies in Greek geometry and algebra under the caliph's patronage.
Al-Wathiq succeeded his father. Al-Wathiq dealt with opposition in Arabia, Syria, Palestine and in Baghdad. Using a famous sword he personally joined the execution of the Baghdad rebels. The revolts were the result of an increasingly large gap between Arab populations and the Turkish armies. The revolts were put down, but antagonism between the two groups grew, as Turkish forces gained power. He also secured a captive exchange with the Byzantines. Al-Wathiq was a patron of scholars, as well as artists. He personally had musical talent and is reputed to have composed over one hundred songs.
When Al-Wathiq died of high fever, Al-Mutawakkil succeeded him. Al-Mutawakkil's reign is remembered for many reforms and is viewed as a golden age. He was the last great Abbasid caliph; after his death the dynasty fell into decline. Al-Mutawakkil ended the Mihna. Al-Mutawakkil built the Great Mosque of Samarra as part of an extension of Samarra eastwards. During his reign, Al-Mutawakkil met famous Byzantine theologian Constantine the Philosopher, who was sent to strengthen diplomatic relations between the Empire and the Caliphate by Emperor Michael III. Al-Mutawakkil involved himself in religious debates, as reflected in his actions against minorities. The Shīʻi faced repression embodied in the destruction of the shrine of Hussayn ibn ʻAlī, an action that was ostensibly carried out to stop pilgrimages. Al-Mutawakkil continued to rely on Turkish statesmen and slave soldiers to put down rebellions and lead battles against foreign empires, notably capturing Sicily from the Byzantines. Al-Mutawakkil was assassinated by a Turkish soldier.
Al-Muntasir succeeded to the Caliphate on the same day with the support of the Turkish faction, though he was implicated in the murder. The Turkish party had al-Muntasir remove his brothers from the line of succession, fearing revenge for the murder of their father. Both brothers wrote statements of abdication. During his reign, Al-Muntasir removed the ban on pilgrimage to the tombs of Hassan and Hussayn and sent Wasif to raid the Byzantines. Al-Muntasir died of unknown causes. The Turkish chiefs held a council to select his successor, electing Al-Musta'in. The Arabs and western troops from Baghdad were displeased at the choice and attacked. However, the Caliphate no longer depended on Arabian choice, but depended on Turkish support. After the failed Muslim campaign against the Christians, people blamed the Turks for bringing disaster on the faith and murdering their Caliphs. After the Turks besieged Baghdad, Al-Musta'in planned to abdicate to Al-Mu'tazz but was put to death by his order. Al-Mu'tazz was enthroned by the Turks, becoming the youngest Abbasaid Caliph to assume power.
Al-Mu'tazz proved too apt a pupil of his Turkish masters, but was surrounded by parties jealous of each other. At Samarra, the Turks were having problems with the "Westerns" (Berbers and Moors), while the Arabs and Persians at Baghdad, who had supported al-Musta'in, regarded both with equal hatred. Al-Mu'tazz put his brothers Al-Mu'eiyyad and Abu Ahmed to death. The ruler spent recklessly, causing a revolt of Turks, Africans, and Persians for their pay. Al-Mu'tazz was brutally deposed shortly thereafter. Al-Muhtadi became the next Caliph. He was firm and virtuous compared to the earlier Caliphs, though the Turks held the power. The Turks killed him soon after his ascension. Al-Mu'tamid followed, holding on for 23 years, though he was largely a ruler in name only. After the Zanj Rebellion, Al-Mu'tamid summoned al-Muwaffak to help him. Thereafter, Al-Muwaffaq ruled in all but name. The Hamdanid dynasty was founded by Hamdan ibn Hamdun when he was appointed governor of Mardin in Anatolia by the Caliphs in 890. Al-Mu'tamid later transferred authority to his son, al-Mu'tadid, and never regained power. The Tulunids became the first independent state in Islamic Egypt, when they broke away during this time.
Al-Mu'tadid ably administered the Caliphate. Egypt returned to allegiance and Mesopotamia was restored to order. He was tolerant towards Shi'i, but toward the Umayyad community he was not so just. Al-Mu'tadid was cruel in his punishments, some of which are not surpassed by those of his predecessors. For example, the Kharijite leader at Mosul was paraded about Baghdad clothed in a robe of silk, of which Kharijites denounced as sinful, and then crucified. Upon Al-Mu'tadid's death, his son by a Turkish slave-girl, Al-Muktafi, succeeded to the throne.
Al-Muktafi became a favorite of the people for his generosity, and for abolishing his father's secret prisons, the terror of Baghdad. During his reign, the Caliphate overcame threats such as the Carmathians. Upon Al-Muktafi's death, the vazir next chose Al-Muqtadir. Al-Muqtadir's reign was a constant succession of thirteen Vazirs, one rising on the fall or assassination of another. His long reign brought the Empire to its lowest ebb. Africa was lost, and Egypt nearly. Mosul threw off its dependence, and the Greeks raided across the undefended border. The East continued to formally recognise the Caliphate, including those who virtually claimed independence.
At the end of the Early Baghdad Abbasids period, Empress Zoe Karbonopsina pressed for an armistice with Al-Muqtadir and arranged for the ransom of the Muslim prisoner while the Byzantine frontier was threatened by Bulgarians. This only added to Baghdad's disorder. Though despised by the people, Al-Muqtadir was again placed in power after upheavals. Al-Muqtadir was eventually slain outside the city gates, whereupon courtiers chose his brother al-Qahir. He was even worse. Refusing to abdicate, he was blinded and cast into prison.
His son Ar-Radi took over only to experience a cascade of misfortune. Praised for his piety, he became the tool of the de facto ruling Minister, Ibn Raik ("amir al-umara"; 'Amir of the Amirs'). Ibn Raik held the reins of government and his name was joined with the Caliph's in public prayers. Around this period, the Hanbalis, supported by popular sentiment, set up in fact a kind of 'Sunni inquisition'. Ar-Radi is commonly regarded as the last of the real Caliphs: the last to deliver orations at the Friday service, to hold assemblies, to commune with philosophers, to discuss the questions of the day, to take counsel on the affairs of State; to distribute alms, or to temper the severity of cruel officers. Thus ended the Early Baghdad Abbasids.
In the late mid-930s, the Ikhshidids of Egypt carried the Arabic title "Wali" reflecting their position as governors on behalf of the Abbasids, The first governor (Muhammad bin Tughj Al-Ikhshid) was installed by the Abbasid Caliph. They gave him and his descendants the Wilayah for 30 years. The last name Ikhshid is Soghdian for "prince".
Also in the 930s, ‘Alī ibn Būyah and his two younger brothers, al-Hassan and Aḥmad founded the Būyid confederation. Originally a soldier in the service of the Ziyārīds of Ṭabaristān, ‘Alī was able to recruit an army to defeat a Turkish general from Baghdad named Yāqūt in 934. Over the next nine years the three brothers gained control of the remainder of the caliphate, while accepting the titular authority of the caliph in Baghdad. The Būyids made large territorial gains. Fars and Jibal were conquered. Central Iraq submitted in 945, before the Būyids took Kermān (967), Oman (967), the Jazīra (979), Ṭabaristān (980), and Gorgan (981). After this the Būyids went into slow decline, with pieces of the confederation gradually breaking off and local dynasties under their rule becoming "de facto" independent.
Middle Baghdad Abbasids.
"Early High Middle Ages"
At the beginning of the Middle Baghdad Abbasids, the Caliphate had become of little importance. The "amir al-umara" Bajkam contented himself with dispatching his secretary to Baghdad to assemble local dignitaries to elect a successor. The choice fell on Al-Muttaqi. Bajkam was killed on a hunting party by marauding Kurds. In the ensuing anarchy in Baghdad, Ibn Raik persuaded the Caliph to flee to Mosul where he was welcomed by the Hamdanids. They assassinated Ibn Raik. Hamdanid Nasir al-Dawla advanced on Baghdad, where mercenaries and well-organised Turks repelled them. Turkish general Tuzun became "amir al-umara". The Turks were staunch Sunnis. A fresh conspiracy placed the Caliph in danger. Hamdanid troops helped ad-Daula escape to Mosul and then to Nasibin. Tuzun and the Hamdanid were stalemated. Al-Muttaqi was at Ar Raqqah, moving to Tuzun where he was deposed. Tuzun installed the blinded Caliph's cousin as successor, with the title of Al-Mustakfi. With the new Caliph, Tuzun attacked the Buwayhid dynasty and the Hamdanids. Soon after, Tuzun died, and was succeeded by one of his generals, Abu Ja'far. The Buwayhids then attacked Baghdad, and Abu Ja'far fled into hiding with the Caliph. Buwayhid Sultan Muiz ud-Daula assumed command forcing the Caliph into abject submission to the Amir. Eventually, Al-Mustakfi was blinded and deposed. The city fell into chaos, and the Caliph's palace was looted.
Once the Buwayhids controlled Baghdad, Al-Muti became caliph. The office was shorn of real power and Shi'a observances were established. The Buwayhids held on Baghdad for over a century. Throughout the Buwayhid reign the Caliphate was at its lowest ebb, but was recognized religiously, except in Iberia. Buwayhid Sultan Mu'izz al-Dawla was prevented from raising a Shi'a Caliph to the throne by fear for his own safety, and fear of rebellion, in the capital and beyond.
The next Caliph, Al-Ta'i, reigned over factional strife in Syria among the Fatimids, Turks, and Carmathians. The Hideaway dynasyty also fractured. The Abbasid borders were the defended only by small border states. Baha' al-Dawla, the Buyid amir of Iraq, deposed al-Ta'i in 991 and proclaimed al-Qadir the new caliph.
During al-Qadir's Caliphate, Mahmud of Ghazni looked after the empire. The great Mahmud of Ghazni, of Eastern fame, was friendly towards the Caliphs, and his victories in the Indian Empire were accordingly announced from the pulpits of Baghdad in grateful and glowing terms. Al-Qadir fostered the Sunni struggle against Shiʿism and outlawed heresies such as the Baghdad Manifesto and the doctrine that the Qu'ran was created. He outlawed the Muʿtazila, bringing an end to the development of rationalist Muslim philosophy. During this and the next period, Islamic literature, especially Persian literature, flourished under the patronage of the Buwayhids. By 1000 the global Muslim population had climbed to about 4 per cent of the world total compared to the Christian population of 10 per cent.
During Al-Qa'im's reign, the Buwayhid ruler often fled the capital and the Seljuq dynasty gained power. Toghrül overran Syria and Armenia. He then made his way into the Capital, where he was well-received both by chiefs and people. In Bahrain, the Qarmatian state collapsed in Al-Hasa. Arabia recovered from the Fatimids and again acknowledged the spiritual jurisdiction of the Abbasids. Al-Muqtadi was honored by the Seljuq Sultan Malik-Shah I, during whose reign the Caliphate was recognized throughout the extending range of Seljuq conquest. The Sultan was critical of the Caliph's interference in affairs of state, but died before deposing the last of the Middle Baghdad Abbasids.
Late Baghdad Abbasids.
"Late High Middle Ages"
The Late Baghdad Abbasids reigned from the beginning of the Crusades to the Seventh Crusade. The first Caliph was Al-Mustazhir. He was politically irrelevant, despite civil strife at home and the First Crusade in Syria. Raymond IV of Toulouse attempted to attack Baghdad, losing at the Battle of Manzikert. The global Muslim population climbed to about 5 per cent as against the Christian population of 11 per cent by 1100. Jerusalem was captured by crusaders who massacred its inhabitants. Preachers travelled throughout the caliphate proclaiming the tragedy and rousing men to recover the Al-Aqsa Mosque from the "Franks" (European Crusaders). Crowds of exiles rallied for war against the infidel. Neither the Sultan nor the Caliph sent an army west.
Al-Mustarshid achieved more independence while the sultan Mahmud II of Great Seljuq was engaged in war in the East. The Banu Mazyad (Mazyadid State) general, Dubays ibn Sadaqa (emir of Al-Hilla), plundered Bosra and attacked Baghdad together with a young brother of the sultan, Ghiyath ad-Din Mas'ud. Dubays was crushed by a Seljuq army under Zengi, founder of the Zengid dynasty. Mahmud's death was followed by a civil war between his son Dawud, his nephew Mas'ud and the atabeg Toghrul II. Zengi was recalled to the East, stimulated by the Caliph and Dubays, where he was beaten. The Caliph then laid siege to Mosul for three months without success, resisted by Mas'ud and Zengi. It was nonetheless a milestone in the caliphate's military revival.
After the siege of Damascus (1134), Zengi undertook operations in Syria. Al-Mustarshid attacked sultan Mas'ud of western Seljuq and was taken prisoner. He was later found murdered. His son, Al-Rashid failed to gain independence from Seljuq Turks. Zengi, because of the murder of Dubays, set up a rival Sultanate. Mas'ud attacked; the Caliph and Zengi, hopeless of success, escaped to Mosul. The Sultan regained power, a council was held, the Caliph was deposed, and his uncle, son of Al-Muqtafi, appointed as the new Caliph. Ar-Rashid fled to Isfahan and was killed by Hashshashins.
Continued disunion and contests between Seljuq Turks allowed al-Muqtafi to maintain control in Baghdad and to extend it throughout Iraq. In 1139, al-Muqtafi granted protection to the Nestorian patriarch Abdisho III. While the Crusade raged, the Caliph successfully defended Baghdad against Muhammad II of Seljuq in the Siege of Baghdad (1157). The Sultan and the Caliph dispatched men in response to Zengi's appeal, but neither the Seljuqs, nor the Caliph, nor their Amirs, dared resist the Crusaders.
The next caliph, Al-Mustanjid, saw Saladin extinguish the Fatimid dynasty after 260 years, and thus the Abbasids again prevailed. Al-Mustadi reigned when Saladin become the sultan of Egypt and declared allegiance to the Abbasids.
An-Nasir, "The Victor for the Religion of God", attempted to restore the Caliphate to its ancient dominant role. He consistently held Iraq from Tikrit to the Gulf without interruption. His forty-seven year reign was chiefly marked by ambitious and corrupt dealings with the Tartar chiefs, and by his hazardous invocation of the Mongols, which ended his dynasty. His son, Az-Zahir, was Caliph for a short period before his death and An-Nasir's grandson, Al-Mustansir, was made caliph.
Al-Mustansir founded the Mustansiriya Madrasah. In 1236 Ögedei Khan commanded to raise up Khorassan and populated Herat. The Mongol military governors mostly made their camp in Mughan plain, Azerbaijan. The rulers of Mosul and Cilician Armenia surrendered. Chormaqan divided the Transcaucasia region into three districts based on military hierarchy. In Georgia, the population were temporarily divided into eight tumens. By 1237 the Mongol Empire had subjugated most of Persia, excluding Abbasid Iraq and Ismaili strongholds, and all of Afghanistan and Kashmir.
Al-Musta'sim was the last Abbasid Caliph in Baghdad and is noted for his opposition to the rise of Shajar al-Durr to the Egyptian throne during the Seventh Crusade. To the east, Mongol forces under Hulagu Khan swept through the Transoxiana and Khorasan. Baghdad was sacked and the caliph deposed soon afterwards. The Mamluk sultans and Syria later appointed a powerless Abbasid Caliph in Cairo.
Cairo Abbasid Caliphs.
"Abbasid "shadow" caliph of Cairo"
"Late Middle Ages"
The Abbasid "shadow" caliph of Cairo reigned under the tutelage of the Mamluk sultans and nominal rulers used to legitimize the actual rule of the Mamluk sultans. All the Cairene Abbasid caliphs who preceded or succeeded Al-Musta'in were spiritual heads lacking any temporal power. Al-Musta'in was the only Cairo-based Abbasid caliph to even briefly hold political power. Al-Mutawakkil III was the last "shadow" caliph. In 1517, Ottoman sultan Selim I defeated the Mamluk Sultanate, and made Egypt part of the Ottoman Empire.
Fatimid Empire.
The Fatimids originated in Ifriqiya (modern-day Tunisia and eastern Algeria). The dynasty was founded in 909 by ʻAbdullāh al-Mahdī Billah, who legitimised his claim through descent from Muhammad by way of his daughter Fātima as-Zahra and her husband ʻAlī ibn-Abī-Tālib, the first Shīʻa Imām, hence the name "al-Fātimiyyūn" "Fatimid". The Fatamids and the Zaydis at the time, used the Hanafi jurisprudence, as did most Sunnis.
Abdullāh al-Mahdi's control soon extended over all of central Maghreb, an area consisting of the modern countries of Morocco, Algeria, Tunisia and Libya, which he ruled from Mahdia, his capital in Tunisia.
The Fatimids entered Egypt in the late 10th century, conquering the Ikhshidid dynasty and founding a capital at "al-Qāhira"(Cairo) in 969. The name was a reference to the planet Mars, "The Subduer", which was prominent in the sky at the moment that city construction started. Cairo was intended as a royal enclosure for the Fatimid caliph and his army, though the actual administrative and economic capital of Egypt was in cities such as Fustat until 1169. After Egypt, the Fatimids continued to conquer surrounding areas until they ruled from Tunisia to Syria and even crossed the Mediterranean into Sicily and southern Italy.
Under the Fatimids, Egypt became the center of an empire that included at its peak North Africa, Sicily, Palestine, Lebanon, Syria, the Red Sea coast of Africa, Yemen and the Hejaz. Egypt flourished, and the Fatimids developed an extensive trade network in both the Mediterranean and the Indian Ocean. Their trade and diplomatic ties extended all the way to China and its Song Dynasty, which determined the economic course of Egypt during the High Middle Ages.
Unlike other governments in the area, Fatimid advancement in state offices was based more on merit than heredity. Members of other branches of Islam, including Sunnis, were just as likely to be appointed to government posts as Shiites. Tolerance covered non-Muslims such as Christians and Jews; they took high levels in government based on ability. There were, however, exceptions to this general attitude of tolerance, notably Al-Hakim bi-Amr Allah.
The Fatimid palace was in two parts. It was in the Khan el-Khalili area at Bin El-Quasryn street.
Fatimid caliphs.
"Early and High Middle Ages"
During the beginning of the Middle Baghdad Abbasids, the Fatimid Caliphs claimed spiritual supremacy not only in Egypt, but also contested the religious leadership of Syria. At the beginning of the Abbasid realm in Baghdad, the Alids faced severe persecution by the ruling party as they were a direct threat to the Caliphate. Owing to the Abbasid inquisitions, the forefathers opted for concealment of the Dawa's existence. Subsequently, they traveled towards the Iranian Plateau and distanced themselves from the epicenter of the political world. Al Mahdi's father, Al Husain al Mastoor returned to control the Dawa's affairs. He sent two Dai's to Yemen and Western Africa. Al Husain died soon after the birth of his son, Al Mahdi. A system of government helped update Al Mahdi on the development which took place in North Africa.
Al Mahdi established the first Imam of the Fatimid dynasty. He claimed genealogic origins dating as far back as Fatimah through Husayn and Ismail. Al Mahdi established his headquarters at Salamiyah and moved towards north-western Africa, under Aghlabid rule. His success of laying claim to being the precursor to the Mahdi was instrumental among the Berber tribes of North Africa, specifically the Kutamah tribe. Al Mahdi established himself at the former Aghlabid residence at Raqqadah, a suburb of Al-Qayrawan in Tunisia. At the time of his death he had extended his reign to Morocco of the Idrisids, as well as Egypt itself. In 920, Al Mahdi took up residence at the newly established capital of the empire, Al-Mahdiyyah. After his death, Al Mahdi was succeeded by his son, Abu Al-Qasim Muhammad Al-Qaim, who continued his expansionist policy.
Berbers and Iberian Umayyads.
The Arabs, under the command of the Berber General Tarik ibn Ziyad, first began their conquest of southern Spain or al-Andalus in 711. A raiding party led by Tarik was sent to intervene in a civil war in the Visigothic kingdom in Hispania. Crossing the Strait of Gibraltar (named after the General), it won a decisive victory in the summer of 711 when the Visigothic king Roderic was defeated and killed on July 19 at the Battle of Guadalete. Tariq's commander, Musa bin Nusair crossed with substantial reinforcements, and by 718 the Muslims dominated most of the peninsula. Some later Arabic and Christian sources present an earlier raid by a certain Ṭārif in 710 and also, the Ad Sebastianum recension of the "Chronicle of Alfonso III", refers to an Arab attack incited by Erwig during the reign of Wamba (672–80). The two large armies may have been in the south for a year before the decisive battle was fought.
The rulers of Al-Andalus were granted the rank of Emir by the Umayyad Caliph Al-Walid I in Damascus. After the Abbasids came to power, some Umayyads fled to Muslim Spain to establish themselves there. By the end of the 10th century, the ruler Abd al-Rahman III took over the title of "Emir of Córdoba"(912-961). Soon after, the Umayyads went on developing a strengthened state with its capital as Córdoba. Al-Hakam II succeeded to the Caliphate after the death of his father Abd ar-Rahman III in 961. He secured peace with the Christian kingdoms of northern Iberia, and made use of the stability to develop agriculture through the construction of irrigation works. Economic development was also encouraged through the widening of streets and the building of markets. The rule of the Caliphate is known as the heyday of Muslim presence in the peninsula.
The Umayyad Caliphate collapsed in 1031 due to political divisions and civil unrest during the rule of Hicham II who was ousted because of his indolence. Al-Andalus then broke up into a number of states called "taifa kingdoms" (Arabic, "Muluk al-ṭawā'if"; English, Petty kingdoms). The decomposition of the Caliphate into those petty kingdoms weakened the Muslims in the Iberian Peninsula "vis-à-vis" the Christian kingdoms of the north. Some of the "taifas", such as that of Seville, were forced to enter into alliances with Christian princes and pay tributes in money to Castille.
Emirs of Córdoba.
Abd al-Rahman I and Bedr (a former Greek slave) escaped with their lives after the popular revolt known as the Abbasid Revolution. Rahman I continued south through Palestine, the Sinai, and then into Egypt. Rahman I was one of several surviving Umayyad family members to make a perilous trek to Ifriqiya at this time. Rahman I and Bedr reached modern day Morocco near Ceuta. Next step would be to cross to sea to al-Andalus, where Rahman I could not have been sure whether he would be welcome. Following the Berber Revolt (740s), the province was in a state of confusion, with the Ummah torn by tribal dissensions among the Arabs and racial tensions between the Arabs and Berbers. Bedr lined up three Syrian commanders – Obeid Allah ibn Uthman and Abd Allah ibn Khalid, both originally of Damascus, and Yusuf ibn Bukht of Qinnasrin and contacted al-Sumayl (then in Zaragoza) to get his consent, but al-Sumayl refused, fearing Rahman I would try to make himself emir. After discussion with Yemenite commanders, Rahman I was told to go to al-Andalus. Shortly thereafter, he set off with Bedr and a small group of followers for Europe. Abd al-Rahman landed at Almuñécar in al-Andalus, to the east of Málaga.
During his brief time in Málaga, he quickly amassed local support. News of the prince's arrival spread throughout the peninsula. In order to help speed his ascension to power, he took advantage of the feuds and dissensions. However, before anything could be done, trouble broke out in northern al-Andalus. Abd al-Rahman and his followers were able to control Zaragoza. Rahman I fought to rule al-Andalus in a battle at the Guadalquivir river, just outside of Córdoba on the plains of Musarah (Battle of Musarah). Rahman I was victorious, chasing his enemies from the field with parts of their army. Rahman I marched into the capital, Córdoba, fighting off a counterattack, but negotiations ended the confrontation. After Rahman I consolidated power, he proclaimed himself the al-Andalus emir. Rahman I did not claim the Muslim caliph, though. The last step was to have al-Fihri's general, al-Sumayl, garroted in Córdoba's jail. Al-Andalus was a safe haven for the house of Umayya that managed to evade the Abbasids.
In Baghdad, the Abbasid caliph al-Mansur had planned to depose the emir. Rahman I and his army confronted the Abbasids, killing most of the Abbasid army. The main Abbasid leaders were decapitated, their heads preserved in salt, with identifying tags pinned to their ears. The heads were bundled in a gruesome package and sent to the Abbasid caliph who was on pilgrimage at Mecca. Rahman I quelled repeated rebellions in al-Andalus. He began the building of the great mosque [cordova], and formed ship-yards along the coast; he is moreover said to have been the first to transplant the palm and the pomegranate into the congenial climate of Spain: and he encouraged science and literature in his states. This good king died on the 29th of September, 788, after a reign of thirty-four years and one month.
Rahman I's successor was his son Hisham I. Born in Córdoba, he built many mosques and completed the Mezquita. He called for a jihad that resulted in a campaign against the Kingdom of Asturias and the County of Toulouse; in this second campaign he was defeated at Orange by William of Gellone, first cousin to Charlemagne. His successor Al-Hakam I came to power and was challenged by his uncles, other sons of Rahman I. One, Abdallah, went to the court of Charlemagne in Aix-la-Chapelle to negotiate for aid. In the mean time Córdoba was attacked, but was defended. Hakam I spent much of his reign suppressing rebellions in Toledo, Saragossa and Mérida.
Abd ar-Rahman II succeeded his father and engaged in nearly continuous warfare against Alfonso II of Asturias, whose southward advance he halted. Rahman II repulsed an assault by Vikings who had disembarked in Cadiz, conquered Seville (with the exception of its citadel) and attacked Córdoba. Thereafter he constructed a fleet and naval arsenal at Seville to repel future raids. He responded to William of Septimania's requests of assistance in his struggle against Charles the Bald's nominations.
Muhammad I's reign was marked by the movements of the Muladi (ethnic Iberian Muslims) and Mozarabs (Muslim-Iberia Christians). Muhammad I was succeeded by his son Mundhir I. During the reign of his father, Mundhir I commanded military operations against the neighbouring Christian kingdoms and the Muladi rebellions. At his father's death, he inherited the throne. During his two-year reign, Mundhir I fought against Umar ibn Hafsun. He died in 888 at Bobastro, succeeded by his brother Abdullah ibn Muhammad al-Umawi.
Umawi showed no reluctance to dispose of those he viewed as a threat. His government was marked by continuous wars between Arabs, Berbers and Muladi. His power as emir was confined to the area of Córdoba, while the rest had been seized by rebel families. The son he had designated as successor was killed by one of Umawi's brothers. The latter was in turn executed by Umawi's father, who named as successor Abd ar-Rahman III, son of the killed son of Umawi.
Caliphs at Córdoba.
Rahman III to help in his fight against the invasion by the Fatimids claimed the Caliphate in opposition to the generally recognized Abbasid Caliph of Baghdad.
The Crusades.
Beginning in the 8th century, the Iberian Christian kingdoms had begun the Reconquista aimed at retaking Al-Andalus from the Moors. In 1095, Pope Urban II, inspired by the conquests in Spain by Christian forces and implored by the eastern Roman emperor to help defend Christianity in the East, called for the First Crusade from Western Europe which captured Odessa, Antioch, County of Tripoli and Jerusalem.
In the early period of the Crusades, the Christian Kingdom of Jerusalem emerged and for a time controlled Jerusalem. The Kingdom of Jerusalem and other smaller Crusader kingdoms over the next 90 years formed part of the complicated politics of the Levant, but did not threaten the Islamic Caliphate nor other powers in the region. After Shirkuh ended Fatimid rule in 1169, uniting it with Syria, the Crusader kingdoms were faced with a threat, and his nephew Saladin reconquered most of the area in 1187, leaving the Crusaders holding a few ports.
In the Third Crusade armies from Europe failed to recapture Jerusalem, though Crusader states lingered for several decades, and other crusades followed. The Christian Reconquista continued in Al-Andalus, and was eventually completed with the fall of Granada in 1492. During the low period of the Crusades, the Fourth Crusade was diverted from the Levant and instead took Constantinople, leaving the Eastern Roman Empire (now the Byzantine Empire) further weakened in their long struggle against the Turkish peoples to the east. However, the crusaders did manage to damage Islamic caliphates; according to William of Malmesbury, preventing them from further expansion into Christendom and being targets of the Mamluks and the Mongols.
Ayyubid dynasty.
The Ayyubid dynasty was founded by Saladin and centered in Egypt. In 1174, Saladin proclaimed himself Sultan and conquered the Near East region. The Ayyubids ruled much of the Middle East during the 12th and 13th centuries, controlling Egypt, Syria, northern Mesopotamia, Hejaz, Yemen, and the North African coast up to the borders of modern-day Tunisia. After Saladin, his sons contested control over the sultanate, but Saladin's brother al-Adil eventually established himself in 1200. In the 1230s, Syria's Ayyubid rulers attempted to win independence from Egypt and remained divided until Egyptian Sultan as-Salih Ayyub restored Ayyubid unity by taking over most of Syria, excluding Aleppo, by 1247. In 1250, the dynasty in the Egyptian region was overthrown by slave regiments. A number of attempts to recover it failed, led by an-Nasir Yusuf of Aleppo. In 1260, the Mongols sacked Aleppo and wrested control of what remained of the Ayyubid territories soon after.
Mongol invasions.
After the Crusades the Mongols invaded in the 13th century, marking the end of the Islamic Golden Age. Some historians assert that the eastern Islamic world never fully recovered. Under the leadership of Genghis Khan, The Mongols put an end to the Abbasid era. The Mongol invasion of Central Asia began in 1219 at a huge cost in civilian life and economic devastation. The Mongols spread throughout Central Asia and Persia: the Persian city of Isfahan had fallen to them by 1237.
With the election of Khan Mongke in 1251, Mongol targeted the Abbasid capital, Baghdad. Mongke's brother, Hulegu, was made leader of the Mongol Army assigned to the task of subduing Baghdad. The fall of Bagdhad in 1258 destroyed what had been the largest city in Islam. The last Abbasid caliph, al-Musta'sim, was captured and killed; and Baghdad was ransacked and destroyed. The cities of Damascus and Aleppo fell in 1260. Plans for the conquest of Egypt were delayed due to the death of Mongke at around the same time. The Abbasid army lost to the superior Mongol army, but the invaders were finally stopped by Egyptian Mamluks north of Jerusalem in 1260 at the pivotal Battle of Ain Jalut.
Ultimately, the Ilkhanate, Golden Horde, and the Chagatai Khanate - three of the four principal Mongol khanates - embraced Islam. In power in Syria, Mesopotamia, Persia and further east, over the rest of the 13th century gradually all converted to Islam. Most Ilkhanid rulers were replaced by the new Mongol power founded by Timur (himself a Muslim), who conquered Persia in the 1360s, and moved against the Delhi Sultanate in India and the Ottoman Turks in Anatolia. His invasions were equally destructive, sacking Bagdhad, Damascus, Delhi and many other cities, with enormous loss of life. Timur had attacked areas still recovering from the Black Death, which may have killed one third of the population of the Middle East. The plague began in China, and reached Alexandria in Egypt in 1347, spreading over the following years to most Islamic areas. The combination of the plague and the wars left the Middle Eastern Islamic world in a seriously weakened position. The Timurid dynasty would found many branches of Islam, including the Mughals of India.
The Mamluks.
In 1250, the Ayyubid Egyptian dynasty was overthrown by slave regiments, and the Mamluk Sultanate was born. In the 1260s, the Mongols sacked and controlled the Islamic Near East territories. The Mamluks, who were Turkic, forced out the Mongols (see Battle of Ain Jalut) after the final destruction of the Ayyubid dynasty. Thus they united Syria and Egypt for the longest interval between the Abbasid and Ottoman empires (1250–1517). The Mamluks experienced a continual state of political conflict, military tension, proxy wars, and economic competition between the "Muslim territory" (Dar al-Islam) and "non-Muslim territory" (Dar al-Harb).
As part of their chosen role as defenders of Islamic orthodoxy, the Mamluks sponsored many religious buildings, including mosques, madrasas and khanqahs. Though some construction took place in the provinces, the vast bulk of these projects expanded the capital. Many Mamluk buildings in Cairo have survived to this day, particularly in Old Cairo.
Bahri Sultans.
A former Mamluk slave who was born a prince, Aybak (known as "Lion of Ain Jaloot") replaced the Mamluks in 1250. Aybak, by then a general, married Shajar al-Durr, the widow of Ayyubid caliph al-Salih Ayyub. Military prestige was at the center of Mamluk society, and it played a key role in the confrontations with the Mongol forces. After Aybak's assassination and the accession of Qutuz in 1259, the Mamluks challenged and routed the Mongols at the Battle of Ain Jalut in late 1260. The Mongols were again defeated by the Mamluks at the Battle of Hims a few months later, and then driven out of Syria altogether. With this, the Mamluks were able to concentrate their forces and to conquer the last of the crusader territories in the Levant.
Burji Sultans.
The global Muslim population had reached about 8 per cent of the world total as against the Christian population of 14 per cent by 1400.
Africa.
The Umayyad conquest of North Africa continued the century of rapid Muslim military expansion following the death of Muhammad in 632. By 640 the Arabs controlled Mesopotamia, had invaded Armenia, and were concluding their conquest of Byzantine Syria. Damascus was the seat of the Umayyad caliphate. By the end of 641 all of Egypt was in Arab hands.
Horn of Africa.
The history of Islam in the Horn of Africa is almost as old as the faith itself. Through extensive trade and social interactions with their converted Muslim trading partners on the other side of the Red Sea, in the Arabian peninsula, merchants and sailors in the Horn region gradually came under the influence of the new religion.
Early Islamic disciples fled to the port city of Zeila in modern-day northern Somalia to seek protection from the Quraysh at the court of the Aksumite Emperor in present-day Somalia. Some of the Muslims that were granted protection are said to have then settled in several parts of the Horn region to promote the religion. The victory of the Muslims over the Quraysh in the 7th century had a significant impact on local merchants and sailors, as their trading partners in Arabia had by then all adopted Islam, and the major trading routes in the Mediterranean and the Red Sea came under the sway of the Muslim Caliphs. Instability in the Arabian peninsula saw further migrations of early Muslim families to the Somali seaboard. These clans came to serve as catalysts, forwarding the faith to large parts of the Horn region.
Maghreb.
Kairouan in Tunisia was the first city founded by Muslims in the Maghreb. Arab general Uqba ibn Nafi erected the city (in 670) and, in the same time, the Great Mosque of Kairouan considered as the oldest and most prestigious sanctuary in the western Islamic world.
This part of Islamic territory has had independent governments during most of Islamic history. The Idrisid were the first Arab rulers in the western Maghreb (Morocco), ruling from 788 to 985. The dynasty is named after its first sultan Idris I.
The Almoravid dynasty was a Berber dynasty from the Sahara flourished over a wide area of North-Western Africa and the Iberian Peninsula during the 11th century. Under this dynasty the Moorish empire was extended over present-day Morocco, Western Sahara, Mauritania, Gibraltar, Tlemcen (in Algeria) and a part of what is now Senegal and Mali in the south, and Spain and Portugal in the north.
The Almohad Dynasty or "the Unitarians", were a Berber Muslim religious power which founded the fifth Moorish dynasty in the 12th century, and conquered all Northern Africa as far as Egypt, together with Al-Andalus.
Great Lakes.
Islam came to the Great Lakes region of South Eastern Africa along existing trade routes. They learned from them the manners of the Muslims and this led to their conversion by the Muslim Arabs.
Local Islamic governments centered in Tanzania (then Zanzibar). The people of "Zayd" were Muslims that immigrated to the Great Lakes region. In the pre-colonial period, the structure of Islamic authority here was held up through the "Ulema" ("wanawyuonis", in Swahili language). These leaders had some degree of authority over most of the Muslims in South East Africa before territorial boundaries were established. The chief Qadi there was recognized for having the final religious authority.
West Africa.
Much later, Usman dan Fodio after the Fulani War, found himself in command of the largest state in Africa, the Fulani Empire. Dan Fodio worked to establish an efficient government grounded in Islamic laws. Already aged at the beginning of the war, he retired in 1815 passing the title of Sultan of Sokoto to his son Muhammed Bello.
Asia and the Far East.
South Asia.
On the Indian subcontinent, Islam first appeared in the southwestern tip of the peninsula, in today's Kerala state. Arabs traded with Malabar even before the birth of Muhammad. Native legends say that a group of Sahaba, under Malik Ibn Deenar, arrived on the Malabar Coast and preached Islam. According to that legend, the first mosque of India was built by Second Chera King Cheraman Perumal, who accepted Islam and received the name "Tajudheen". He traveled to Arabia to meet Muhammad and died on the trip back, somewhere in today's Oman. Historical records suggest that the Cheraman Perumal Mosque was built in around 629.
Islamic rule came to India in the 8th century, when Muhammad bin Qasim conquered Sindh. Muslim conquests expanded under Mahmud and the Ghaznavids until the late 12th century, when the Ghurids overran the Ghaznavids and extended the conquests in Northern India. Qutb-ud-din Aybak conquered Delhi in 1206 and began the reign of the Delhi Sultanates.
In the 14th century, Alauddin Khilji extended Muslim rule south to Gujarat, Rajasthan and Deccan. Various other Muslim dynasties also formed and ruled across India from the 13th to the 18th century such as the Qutb Shahi and the Bahmani, but none rivalled the power and extensive reach of the Mughal Empire at its peak.
China.
In China, four Sahabas (Sa'ad ibn abi Waqqas, Wahb Abu Kabcha, Jafar ibn Abu Talib and Jahsh) preached in 616/17 and onwards after following the Chittagong–Kamrup–Manipur route after sailing from Abyssinia in 615/16. After conquering Persia in 636, Sa'ad ibn abi Waqqas went with Sa'id ibn Zaid, Qais ibn Sa'd and Hassan ibn Thabit to China in 637 taking the complete Quran. Sa'ad ibn abi Waqqas headed for China for the third time in 650-51 after Caliph Uthman asked him to lead an embassy to China, which the Chinese emperor received.
Southeast Asia.
Islam first reached Maritime Southeast Asia through traders from Mecca in the 7th century CE, particularly via the western part of what is now Indonesia. Arab traders from Yeman already had a presence in Asia through trading and sea travelling by sea, serving as intermediary traders to and from Europe and Africa. They traded not only Arabian goods but also from Africa, India, and so on including ivory, fragrances, spices, and gold.
According to T.W. Arnold in "The Preaching of Islam", by the 2nd century of the Islamic Calendar, Arab traders had been trading with the inhabitants of Ceylon. The same argument has been told by Dr. B.H. Burger and Dr. Mr. Prajudi in "Sedjarah Ekonomis Sosiologis Indonesia" (History of Socio Economic of Indonesia) According to the atlas by geographer Al Biruni (973 - 1048), the Indian or Indonesia Ocean used to be called the Persian Ocean. After the Western Imperialist ruled, it is replaced Persian Ocean to be Indian Ocean.
Soon, many Sufi missionaries translated classical Sufi literature from Arabic and Persian into Malay; a tangible product of this is the Jawi script. Coupled with the composing of original Islamic literature in Malay, this led the way to the transformation of Malay into an Islamic language. By 1292, when Marco Polo visited Sumatra, most of the inhabitants had converted to Islam. The Sultanate of Malacca was founded on the Malay Peninsula by Parameswara, a Srivijayan Prince.
Through trade and commerce, Islam then spread to Borneo and Java. By the late 15th century, Islam had been introduced to the Philippines via the southern island of Mindanao. The foremost socio-cultural Muslim entities that resulted form this are the present-day Sultanate of Sulu and Sultanate of Maguindanao; Islamised kingdoms in the northern Luzon island, such as the Kingdom of Maynila and the Kingdom of Tondo, were later conquered and Christianised with the majority of the archipelago by Spanish colonisers beginning in the 16th century.
As Islam spread, societal changes developed from the individual conversions, and five centuries later it emerged as a dominant cultural and political power in the region. Three main Muslim political powers emerged. The Aceh Sultanate was the most important, controlling much of the area between Southeast Asia and India from its centre in northern Sumatra. The Sultanate also attracted Sufi poets. The second Muslim power was the Sultanate of Malacca on the Malay Peninsula. The Sultanate of Demak on Java was the third power, where the emerging Muslim forces defeated the local Majapahit kingdom in the early 16th century. Although the sultanate managed to expand its territory somewhat, its rule remained brief.
Portuguese forces captured Malacca in 1511 under naval general Afonso de Albuquerque. With Malacca subdued, the Aceh Sultanate and Bruneian Empire established themselves as centres of Islam in Southeast Asia. The Sultanate's territory, although vastly diminished, remains intact to this day as the modern state of Brunei Darussalam.
Fragmentation period.
Three Early Modern empires.
In the 15th and 16th centuries three major Muslim empires formed: the Ottoman Empire in the Middle East, the Balkans and Northern Africa; the Safavid Empire in Greater Iran; and the Mughal Empire in South Asia. These imperial powers were made possible by the discovery and exploitation of gunpowder and more efficient administration. By the end of the 19th century, all three had declined, and by the early 20th century, with the Ottomans' defeat in World War I, the last Muslim empire collapsed.
Dar al-'Ahd (House of truce) began to develop in the Ottoman Empire's relationship with its tributary states. In the contemporary "National period", the term referred to non-Muslim governments that had armistice or peace agreements with Muslim governments. Today, the actual status of the non-Muslim country in question may vary from acknowledged equality to tributary states.
Mughal Empire.
The Mughal Empire was a product of various Central Asian invasions into the Indian subcontinent. It was founded by the Timurid prince Babur in 1526 with the destruction of the Delhi sultanate, placing its capital in Agra. Babur's death some years later and the indecisive rule of his son, Humayun, brought instability to Mughal rule. The resistance of the Afghani Sher Shah, who administered a string of defeats to Humayun, weakened the empire. A year before his death, however, Humayun managed to recover much of the lost territories, leaving a substantial legacy for his son, the 13 year old Akbar (later known as "Akbar the Great"), in 1556. Under Akbar, consolidation of the Mughal Empire occurred through both expansion and administrative reforms. After Akbar, Jahangir and Shah Jahan came to power. Subsequently, Aurangazeb ruled vast areas including Afghanisthan, Pakistan, India and Bangladesh.
The empire ruled most of present-day India, Pakistan, Bangladesh and Afghanistan for several centuries. Its decline in the early 18th century allowed India to be divided into smaller kingdoms and states. The Mughal dynasty was dissolved by the British Empire after the Indian rebellion of 1857. It left a lasting legacy on Indian culture and architecture. Famous buildings built by the Mughals, include: the Taj Mahal, the Red Fort, the Badshahi Mosque, the Lahore Fort, the Shalimar Gardens and the Agra Fort. During the empire's reign, Muslim communities flourished all over India, in Gujarat, Bengal and Hyderabad. Various Sufi orders from Afghanistan and Persia were active throughout the region. More than a quarter of the population converted to Islam.
Safavid Empire.
The Safavid dynasty rose to power in Tabriz in 1501 and later conquered the rest of Iran. The Safavids were originally Sufi and Iran was Sunni. After their defeat at the hands of the Sunni Ottomans at the Battle of Chaldiran, to unite the Persians behind him Ismail I made conversion mandatory for the largely Sunni population to Twelver Shia so that he could get them to fight the Sunni Ottomans.
This resulted in the Safavid conversion of Iran to Shia Islam. Zaydis, the largest group amongst the Shia before the Safavid Dynasty were also forced to convert to the Twelver Shia. The Zaydis at that time used the Hanafi Fiqh, as did most Sunnis and there were good relations between them. Abu Hanifah and Zayd ibn Ali were also very good friends.
The Safavids dynasty from Azarbaijan ruled from 1501 to 1736, and which established Twelver Shi'a Islam as the region's official religion and united its provinces under a single sovereignty, thereby reigniting the Persian identity.
Although claiming to be the descendants of Ali ibn Abu Talib, the Safavids were Sunni (the name "Safavid" comes from a Sufi order called "Safavi"). Their origins go back to Firuz Shah Zarrinkolah, a local dignitary from the north. During their rule, the Safavids recognized Twelver Shi'a Islam as the State religion, thus giving the region a separate identity from its Sunni neighbours.
In 1524, Tahmasp I acceded to the throne, initiating a revival of the arts. Carpetmaking became a major industry. The tradition of Persian miniature painting in manuscripts reached its peak, until Tahmasp turned to strict religious observance in middle age, prohibiting the consumption of alcohol and hashish and removing casinos, taverns and brothels. Tahmasp's nephew Ibrahim Mirza continued to patronize a last flowering of the arts until he was murdered, after which many artists were recruited by the Mughal dynasty.
Tahmasp's grandson, Shah Abbas I, restored the shrine of the eighth Twelver Shi'a Imam, Ali al-Ridha at Mashhad, and restored the dynastic shrine at Ardabil. Both shrines received jewelry, fine manuscripts and Chinese porcelains. Abbas moved the capital to Isfahan, revived old ports, and established thriving trade with Europeans. Amongst Abbas's most visible cultural achievements was the construction of "Naqsh-e Jahan Square" ("Design of the World"). The plaza, located near a Friday mosque, covered 20 acre.
The Safavid Dynasty was toppled in 1722 by the Hotaki dynasty, which ended their forceful conversion of Sunni areas to Shiaism.
Salafi.
In the 18th century a reform and revival movement was initiated led by Ibn Abd al-Wahhab in today's Saudi Arabia. Referred to as Wahhabi, their self designation is Muwahiddun (unitarians). Building upon earlier efforts such as those by the logician Ibn Taymiyyah and Ibn al-Qayyim, the movement seeks to uphold monotheism and purify Islam of later innovations. Their zeal against idolatrous shrines led to the destruction of sacred tombs in Mecca and Medina, including those of Muhammad's Companions.
Ottoman Empire.
The Seljuq Turks declined in the second half of the 13th century, after the Mongol invasion. This resulted in the establishment of multiple Turkish principalities, known as beyliks. Osman I, the founder of the Ottoman dynasty, assumed leadership of one of these principalities (Söğüt) in 1281, succeeding his father Ertuğrul. Declaring an independent Ottoman emirate in 1299, Osman I afterwards led it in a series of battles with the Byzantine Empire. By 1331, the Ottomans had captured Nicaea, the former Byzantine capital, under the leadership of Osman's son and successor, Orhan I. Victory at the Battle of Kosovo against the Serbs in 1389 then facilitated their expansion into Europe. The Ottomans were established in the Balkans and Anatolia by the time Bayezid I ascended to power in the same year, now at the helm of a growing empire.
Growth halted when Mongol warlord Timur (also known as "Tamerlane") captured Bayezid I in the Battle of Ankara in 1402, beginning the Ottoman Interregnum. This episode was characterized by the division of the Ottoman territory amongst Bayezid I's sons, who submitted to Timurid authority. When a number of Ottoman territories regained independent status, ruin for the Empire loomed. However, the empire recovered, as the youngest son of Bayezid I, Mehmed I, waged offensive campaigns against his ruling brothers, thereby reuniting Asia Minor and declaring himself sultan in 1413.
Around this time the Ottoman naval fleet developed, such that they were able to challenge Venice, a naval power. They also attempted to reconquer the Balkans. By the time of Mehmed I's grandson, Mehmed II (ruled 1444 — 1446; 1451 — 1481), the Ottomans could lay siege to Constantinople, the capital of Byzantium. A factor in this siege was the use of muskets and large cannons introduced by the Ottomans. The Byzantine fortress succumbed in 1453, after 54 days of siege. Without its capital the Byzantine Empire disintegrated. The future successes of the Ottomans and later empires would depend upon the exploitation of gunpowder.
In the early 16th century, the Shi'ite Safavid dynasty assumed control in Persia under the leadership of Shah Ismail I, defeating the ruling Turcoman federation Aq Qoyunlu (also called the "White Sheep Turkomans") in 1501. The Ottoman sultan Selim I sought to repel Safavid expansion, challenging and defeating them at the Battle of Chaldiran in 1514. Selim I also deposed the ruling Mamluks in Egypt, absorbing their territories in 1517. Suleiman I (also known as "Suleiman the Magnificent"), Selim I's successor, took advantage of the diversion of Safavid focus to the Uzbeks on the eastern frontier and recaptured Baghdad, which had fallen under Safavid control. Despite this, Safavid power remained substantial, rivalling the Ottomans. Suleiman I advanced deep into Hungary following the Battle of Mohács in 1526 — reaching as far as the gates of Vienna thereafter, and signed a Franco-Ottoman alliance with Francis I of France against Charles V of the Holy Roman Empire 10 years later. Suleiman I's rule (1520 — 1566) was the apex of the Ottoman Empire. The rapid European industrialization thereafter sent it into a relative decline. It was recognized as a superpower, even at the time of its decline and eventual demise after World War I.
Modern history.
The modern age brought technological and organizational changes to Europe while the Islamic region continued the patterns of earlier centuries. The Great Powers globalized economically and colonized much of the region.
Ottoman Empire partition.
By the end of the 19th century, the Ottoman empire had declined. The decision to back Germany in World War I meant they shared the Central Powers' defeat in that war. The defeat led to the overthrow of the Ottomans by Turkish nationalists led by the victorious general of the Battle of Gallipoli: Mustafa Kemal, who became known to his people as Atatürk, "Father of the Turks." Atatürk was credited with renegotiating the treaty of Sèvres (1920) which ended Turkey's involvement in the war and establishing the modern Republic of Turkey, which was recognized by the Allies in the Treaty of Lausanne (1923). Atatürk went on to implement an ambitious program of modernization that emphasized economic development and secularization. He transformed Turkish culture to reflect European laws, adopted Hindu-Arabic numerals, the Latin script, separated the religious establishment from the state, and emancipated woman—even giving them the right to vote in parallel with women's suffrage in the west.
Following World War I, the vast majority of former Ottoman territory outside of Asia Minor was handed over to the victorious European powers as protectorates. During the war the Allies had promised the subject peoples independence in exchange for their assistance fighting the Turkish powers. To their dismay, they found that this system of "protectorates" was a smoke-screen for their continued subjugation by the British and the French. The struggles for independence from their Turkish overlords and the cooperation of partisan forces with the British were romanticized in the stories of British secret intelligence agent T. E. Lawrence—later known as "Lawrence of Arabia." Ottoman successor states include today's Albania, Bosnia and Herzegovina, Bulgaria, Egypt, Greece, Iraq, Lebanon, Romania, Saudi Arabia, Serbia, Syria, Jordan, Turkey, Balkan states, North Africa and the north shore of the Black Sea.
Many Muslim countries sought to adopt European political organization and nationalism began to emerge in the Muslim world. Countries like Egypt, Syria and Turkey organized their governments sought to develop national pride amongst their citizens. Other places, like Iraq, were not as successful due to a lack of unity and an inability to resolve age-old prejudices between Muslim sects and against non-Muslims.
Some Muslim countries, such as Turkey and Egypt, sought to separate Islam from the secular government. In other cases, such as Saudi Arabia, the government brought out religious expression in the re-emergence of the puritanical form of Sunni Islam known to its detractors as Wahabism, which found its way into the Saudi royal family.
Independence of South Asia.
The independence of South Asia refers to the creation in August 1947 of the now sovereign states of India and Pakistan. The two nations were formed out of the former British Raj, including treaty states, when Britain granted independence to the area (see Undivided India). In particular, the term refers to the partition of Bengal and Punjab, the two main provinces of what would be Pakistan.
In 1947, after the independence of India, Pakistan became the largest Islamic country in the world (by population) and the tenth largest post-World War II state in the modern world. In 1971, after a bloody war of independence, the Bengal part of Pakistan became an independent state called Bangladesh. Pakistan in the contemporary era is the second largest Islamic country in the world, following Indonesia. Pakistan is a declared nuclear power, being the only Muslim nation to have that status.
Post-1945 era.
Between 1953 and 1964, King Saud reorganized the government of the monarchy his father, Ibn Saud, had created. Saudi Arabia's ministries included Communication (1953), Agriculture and Water (1953), Petroleum (1960), Pilgrimage and Islamic Endowments (1960), Labour and Social Affairs (1962) and Information (1963). He also put Talal, one of his many younger brothers (29 years his junior) in charge of the Ministry of Transport.
In 1958-59, Talal proposed the formation of a National Council. As he proposed it, it would have been a consultative body, not a legislature. Still, he thought of it as a first step toward broader popular participation in the government. Talal presented this proposal to the king when the Crown Prince was out of the country. Saud forwarded the proposal to the ulama asking them whether a National Council was a legitimate institution in Islam. The idea then disappeared until it was revived more than three decades later. A Consultative Council came into existence in 1992.
The Organization of Petroleum Exporting Countries came into existence in 1960. For the first decade or more of its existence, it was unable to increase revenue for the member nations. Tension between Faisal and Saud continued to mount until a showdown in 1964. Saud threatened to mobilize the Royal Guard against Faisal and Faisal threatened to mobilize the National Guard against Saud. Saud then abdicated and left for Cairo, then Greece, where he would die in 1969. Faisal then became King.
The Six-Day War of June 5–10, 1967, was fought between Israel and the neighbouring states of Egypt, Jordan, and Syria. It closed the Suez canal, and may have contributed to the revolution in Libya that put Muammar Gaddafi in power. It led in May 1970 to the closure of the "tapline" from Saudi Arabia through Syria to Lebanon. These developments had the effect of increasing the importance of petroleum in Libya, which is a short (and canal-free) shipping distance from Europe. In 1970, Occidental Petroleum broke with other oil companies and accepted Qaddafi's demands for price increases.
In October 1973, another war between Israel and its Muslim neighbors, known as the Yom Kippur War, broke out just as oil company began meeting with OPEC leaders. OPEC had been emboldened by the success of Libya's demands and the war strengthened their unity. The Arab defeats in 1967 and 1973 triggered the 1973 oil crisis. In response to the emergency resupply effort by the West that enabled Israel to defeat Egyptian and Syrian forces, the Arab world imposed the 1973 oil embargo against the United States and Western Europe. Faisal agreed that Saudi Arabia would use some of its oil wealth to finance the "front-line states", those that bordered Israel, in their struggle. The centrality of petroleum, the Arab-Israeli Conflict and political and economic instability and uncertainty remain constant features of the politics of the region.
Persian revolutions.
The Iranian Constitutional Revolution took place between 1905 and 1911. The revolution marked the beginning of the end of Iran's feudalistic society and led to the establishment of a parliament in Persia and the restriction of the power of the Shah (king). Iran approved its first constitution at this time. The modernist and conservative blocks then began to fight with each other. World War I intervened and all of the combatants invaded Iran. This weakened the government and threatened the country's independence. The constitutional monarchy created by the decree of Mozzafar al-Din Shah that was established in Persia as a result of the Revolution, was damaged in 1925 with the dissolution of the Qajar dynasty and the ascension of Reza Shah Pahlavi to the throne.
In 1979 the Iranian Revolution transformed Iran from a constitutional monarchy to a populist theocratic Islamic republic under the rule of Ayatollah Ruhollah Khomeini, a Shi`i Muslim cleric and "marja". Following the Revolution, and a new constitution was approved and a referendum established the government, electing Ruhollah Khomeini as Supreme Leader. During the following two years, liberals, leftists, and Islamic groups fought each other, and the Islamics captured power. Gulf states such as Saudi Arabia and Kuwait (despite being hostile to Iraq) encouraged Saddam Hussein to invade Iran, which resulted in the Iran-Iraq war, as they feared that an Islamic revolution would take place within their own borders. Certain Iranian exiles also helped convince Saddam that if he invaded, the fledgling Islamic republic would quickly collapse.
National period.
Arab–Israeli conflict.
The Arab–Israeli conflict spans about a century of political tensions and open hostilities. It involves the establishment of the modern State of Israel as a Jewish nation state, the consequent displacement of the Palestinian people and Jewish exodus from Arab and Muslim countries, as well as the adverse relationship between the Arab states and the State of Israel (see related Israeli–Palestinian conflict). Despite at first involving only the Arab states bordering Israel, animosity has also developed between Israel and other predominantly Muslim states. Many countries, individuals and non-governmental organizations elsewhere in the world feel involved in this conflict for reasons such as cultural and religious ties with Islam, Arab culture, Christianity, Judaism, Jewish culture, or for ideological, human rights, or strategic reasons. Although some consider the Arab–Israeli conflict a part of (or a precursor to) a wider clash of civilizations between the Western World and the Muslim world, others oppose this view. Animosity emanating from this conflict has caused numerous attacks on supporters (or perceived supporters) of each side by supporters of the other side in many countries around the world.
Salafi and the Safavid.
Some have argued that the development of the two opposite fringes, the Safavid conversion of Iran to Shia Islam the Twelver Shia version and its reinforcement by the Iranian Revolution and the Salafi in Saudi Arabia, coupled with the Iran–Saudi Arabia relations resulted in these governments using sectarian conflict to enhance their political interests. Many have argued that these governments, them selves do not conforms to Islamic economic jurisprudence, and continue to deal in usury and in Government bonds. While their rulers like Akbar Hashemi Rafsanjani and some ayatollah's in Iran on the List of Iranian people by net worth and the House of Saud, accumulated huge personal wealth that some have argued is at odds with the Islamic message preached by Muhammad and the Quran. Wealth that some think should belong in Bayt al-mal or the welfare state. The Bayt al-mal or the welfare state was for the Muslim and Non-Muslim poor, needy, elderly, orphans, widows, and the disabled. The Bayt al-mal ran for hundreds of years under the Rashidun Caliphate in the 7th century and continued through the Umayyad period and well into the Abbasid era.
Anatolian region.
Since the establishment of the Republic of Turkey in 1923, there has been a strong tradition of secularism in Turkey established and institutionalized by Atatürk's Reforms. Although the First Grand National Assembly of Turkey had rallied support from the population for the Independence War against the occupying forces on behalf of Islamic principles, Islam was omitted from the public sphere after the Independence War. The principle of secularism was thus inserted in the Turkish Constitution as late as 1937. This legal action was assisted by stringent state policies against domestic Islamist groups and establishments to neutralize the strong appeal of Islam in Turkish society. Even though an overwhelming majority of the population, at least nominally, adheres to Islam in Turkey, the state, which was established with the Kemalist ideology has no official religion nor promotes any and it monitors the area between the religions using the Presidency of Religious Affairs. The Republic Protests were a series of mass rallies by Turkish secular citizens that took place in Turkey in 2007. The target of the first protest was the possible presidential candidacy of the Prime Minister Recep Tayyip Erdoğan, afraid that if elected President of Turkey Erdoğan would alter the Turkish secularist state.
Further reading.
Books, articles, and journals
Encyclopedias

</doc>
<doc id="13308" url="http://en.wikipedia.org/wiki?curid=13308" title="Hittites">
Hittites

The Hittites () were an Ancient Anatolian people who established an empire centred on Hattusa in north-central Anatolia around 1600 BC. This empire reached its height during the mid-14th century BC under Suppiluliuma I, when it encompassed an area that included most of Asia Minor as well as parts of the northern Levant and Upper Mesopotamia. After c. 1180 BC, the empire came to an end during the Bronze Age collapse, splintering into several independent "Neo-Hittite" city-states, some of which survived until the 8th century BC.
The Hittite language was a distinct member of the Anatolian branch of the Indo-European language family. They referred to their native land as "Hatti". The conventional name "Hittites" is due to their initial identification with the Biblical Hittites in 19th century archaeology.
Despite the use of "Hatti" for their core territory, the Hittites should be distinguished from the Hattians, an earlier people who inhabited the same region (until the beginning of the 2nd millennium BC) and spoke a language possibly in the Northwest Caucasian languages group known as Hattic.
The Hittite military made successful use of chariots. Although belonging to the Bronze Age, they were the forerunners of the Iron Age, developing the manufacture of iron artifacts from as early as the 18th century BC, when the "man of Burushanda"'s gift of an iron throne and iron sceptre to the Kaneshite king Anitta was recorded in the "Anitta text" inscription.
After 1180 BC, amid general turmoil in the Levant conjectured to have been associated with the sudden arrival of the Sea Peoples, the kingdom disintegrated into several independent "Neo-Hittite" city-states, some of which survived until as late as the 8th century BC. The history of the Hittite civilization is known mostly from cuneiform texts found in the area of their kingdom, and from diplomatic and commercial correspondence found in various archives in Egypt and the Middle East.
Archaeological discovery.
The Hittites used Mesopotamian cuneiform letters. Archaeological expeditions to Hattusa have discovered entire sets of royal archives in cuneiform tablets, written either in the Semitic Mesopotamian Akkadian language of Assyria and Babylonia, the diplomatic language of the time, or in the various dialects of the Hittite confederation.
Before the discoveries, the only source of information about Hittites had been the Old Testament (see Biblical Hittites). Francis William Newman expressed the critical view, common in the early 19th Century, that, if the Hittites existed at all, "no Hittite king could have compared in power to the King of Judah...". As archaeological discoveries revealed the scale of the Hittite kingdom in the second half of the 19th Century, Archibald Henry Sayce postulated, rather than to be compared to Judah, the Anatolian civilization "[was] worthy of comparison to the divided Kingdom of Egypt", and was "infinitely more powerful than that of Judah". Sayce and other scholars also mention that Judah and the Hittites were never enemies in the Hebrew texts; in the Book of Kings, they supplied the Israelites with cedar, chariots, and horses, as well as being a friend and allied to Abraham in the Book of Genesis.
The first archaeological evidence for the Hittites appeared in tablets found at the Assyrian colony of Kültepe (ancient Karum Kanesh), containing records of trade between Assyrian merchants and a certain "land of "Hatti"". Some names in the tablets were neither Hattic nor Assyrian, but clearly Indo-European.
The script on a monument at Boğazköy by a "People of Hattusas" discovered by William Wright in 1884 was found to match peculiar hieroglyphic scripts from Aleppo and Hamath in Northern Syria. In 1887, excavations at Tell El-Amarna in Egypt uncovered the diplomatic correspondence of Pharaoh Amenhotep III and his son Akhenaton. Two of the letters from a "kingdom of "Kheta""—apparently located in the same general region as the Mesopotamian references to "land of "Hatti""—were written in standard Akkadian cuneiform script, but in an unknown language; although scholars could read it, no one could understand it. Shortly after this, Archibald Sayce proposed that "Hatti" or "Khatti" in Anatolia was identical with the "kingdom of "Kheta"" mentioned in these Egyptian texts, as well as with the biblical Hittites. Others, such as Max Müller, agreed that "Khatti" was probably "Kheta", but proposed connecting it with Biblical Kittim, rather than with the "Children of Heth". Sayce's identification came to be widely accepted over the course of the early 20th century; and the name "Hittite" has become attached to the civilization uncovered at Boğazköy.
During sporadic excavations at Boğazköy (Hattusa) that began in 1906, the archaeologist Hugo Winckler found a royal archive with 10,000 tablets, inscribed in cuneiform Akkadian and the same unknown language as the Egyptian letters from "Kheta"—thus confirming the identity of the two names. He also proved that the ruins at Boğazköy were the remains of the capital of an empire that, at one point, controlled northern Syria.
Under the direction of the German Archaeological Institute, excavations at Hattusa have been underway since 1907, with interruptions during both wars. Kültepe was successfully excavated by Professor Tahsin Özgüç from 1948 until his death in 2005. Smaller scale excavations have also been carried out in the immediate surroundings of Hattusa, including the rock sanctuary of Yazılıkaya, which contains numerous rock-cut reliefs portraying the Hittite rulers and the gods of the Hittite pantheon.
Museums.
The Museum of Anatolian Civilizations in Ankara, Turkey houses the richest collection of Hittite and Anatolian artifacts.
Geography.
The Hittite kingdom was centred on the lands surrounding Hattusa and Neša, known as "the land Hatti" (URU"Ha-at-ti"). After Hattusa was made capital, the area encompassed by the bend of the Halys River (Hittite "Marassantiya", Turkish: "Kızılırmak") was considered the core of the Empire, and some Hittite laws make a distinction between "this side of the river" and "that side of the river". For example, the reward for the capture of an eloped slave after he managed to flee beyond the Halys is higher than that for a slave caught before he could reach the river.
To the west and south of the core territory lay the region known as "Luwiya" in the earliest Hittite texts. This terminology was replaced by the names Arzawa and Kizzuwatna with the rise of those kingdoms. Nevertheless, the Hittites continued to refer to the language that originated in these areas as Luwian. Prior to the rise of Kizzuwatna, the heart of that territory in Cilicia was first referred to by the Hittites as Adaniya. Upon its revolt from the Hittites during the reign of Ammuna, it assumed the name of Kizzuwatna and successfully expanded northward to encompass the lower Anti-Taurus mountains as well. To the north, lived the mountainous people called the Kaskians. To the southeast of the Hittites lay the Hurrian empire of Mitanni. At its peak, during the reign of Mursili II, the Hittite empire stretched from Arzawa in the west to Mitanni in the east, many of the Kaskian territories to the north including Hayasa-Azzi in the far north-east, and on south into Canaan approximately as far as the southern border of Lebanon, incorporating all of these territories within its domain.
History.
Background.
Around 5000 BC, the region centered in Hattusa, that would later become the core of the Hittite kingdom, was inhabited by people with a distinct culture who spoke a non-Indo-European language. The name "Hattic" is used by Anatolianists to distinguish this language from the Indo-European Hittite language that appeared on the scene at the beginning of the 2nd millennium BC and became the administrative language of the Hittite kingdom over the next six or seven centuries.
The early Hittites, whose prior whereabouts are unknown, borrowed heavily from the pre-existing Hattian and Hurrian cultures, and also from that of the Assyrian colonisers—in particular, the cuneiform writing and the use of cylindrical seals.
Since Hattic continued to be used in the Hittite kingdom for religious purposes, and there is substantial continuity between the two cultures, it is not known whether the Hattic speakers—the Hattians—were displaced by the speakers of Hittite, were absorbed by them, or just adopted their language.
Origins.
It is generally assumed that the Hittites came into Anatolia some time before 2000 BC. While their earlier location is disputed, there has been strong evidence for more than a century that the home of the Indo-Europeans in the fourth and third millennia was in the Pontic Steppe, present day Ukraine around the Sea of Azov.
The arrival of the Hittites in Anatolia in prehistoric times was one of a superstrate imposing itself on a native culture, either by means of conquest or by gradual assimilation. In archaeological terms, relationships of the Hittites to the Ezero culture of the Balkans and Maikop culture of the Caucasus have been considered within the migration framework. The Indo-European element at least establishes Hittite culture as intrusive to Anatolia in scholarly mainstream (excepting the opinions of Colin Renfrew), whose Anatolian hypothesis assumes that Indo-European is indigenous to Anatolia, and (more recently) Quentin Atkinson.
The Hittites and other members of the Anatolian family then came from the north, possibly along the Caspian Sea. Their movement into the region may have set off a Near East mass migration sometime around 1900 BC. The dominant inhabitants in central Anatolia at the time were Hurrians and Hattians who spoke non-Indo-European languages (some have argued that Hattic was a Northwest Caucasian language, but its affiliation remains uncertain). There were also Assyrian colonies in the country; it was from the Assyrians that the Hittites adopted the cuneiform script. It took some time before the Hittites established themselves, as is clear from some of the texts included here. For several centuries there were separate Hittite groups, usually centered on various cities. But then strong rulers with their center in Boğazköy succeeded in bringing these together and conquering large parts of central Anatolia to establish the Hittite kingdom.
Early period.
The early history of the Hittite kingdom is known through tablets that may first have been written in the 17th century BC, possibly in Hittite; but survived only as Akkadian copies made in the 14th and 13th centuries BC. These reveal a rivalry within two branches of the royal family up to the Middle Kingdom; a northern branch first based in Zalpa and secondarily Hattusa, and a southern branch based in Kussara (still not found) and Kanesh. These are distinguishable by their names; the northerners retained Hattian names, and the southerners adopted Hittite and Luwiyan names.
Zalpa first attacked Kanesh under Uhna in 1833 BC.
One set of tablets, known collectively as the Anitta text, begin by telling how Pithana the king of Kussara conquered neighbouring Neša (Kanesh). However, the real subject of these tablets is Pithana's son Anitta (r. 1745–20), who continued where his father left off and conquered several northern cities: including Hattusa, which he cursed, and also Zalpuwa (Zalpa). This was likely propaganda for the southern branch of the royal family, against the northern branch who had fixed on Hattusa as capital. Another set, the Tale of Zalpa, supports Zalpa and exonerates the later Hattusili I from the charge of sacking Kanesh.
Anitta was succeeded by Zuzzu (r. 1720–10); but sometime in 1710–05, Kanesh was destroyed taking the long-established Assyrian merchant trading system with it. A Kussaran noble family survived to contest the Zalpuwan / Hattusan family, though whether these were of the direct line of Anitta is uncertain.
Meanwhile, the lords of Zalpa lived on. Huzziya I, descendent of a Huzziya of Zalpa, took over Hatti. His son-in-law Labarna I, a southerner (of Hurma) usurped the throne but made sure to adopt Huzziya's grandson Hattusili as his own son and heir.
Old Kingdom.
The founding of the Hittite Kingdom is attributed to either Labarna I or Hattusili I (the latter might also have had Labarna as a personal name), who conquered the area south and north of Hattusa. Hattusili I campaigned as far as the Amorite kingdom of Yamkhad in Syria, where he attacked, but did not capture, its capital of Aleppo. His heir, Mursili I, conquered that city in a campaign conducted in 1595 BC. Also in 1595 BC, Mursili I (or Murshilish I) conducted a great raid down the Euphrates River and captured Mari and Babylon, ejecting the Amorite founders of the Babylonian state in the process. However, the Hittite campaigns caused internal dissension which forced a withdrawal of troops to the Hittite homelands. Throughout the remainder of the sixteenth century BC, the Hittite kings were held to their homelands by dynastic quarrels and warfare with the Hurrians—their neighbours to the east. Also the campaigns into Syria and Mesopotamia may be responsible for the reintroduction of cuneiform writing into Anatolia, since the Hittite script is quite different from the script of the preceding Assyrian Colony period.
Mursili continued the conquests of Hattusili I. Mursili's conquests reached southern Mesopotamia and even ransacked Babylon itself in 1531 BC. Rather than incorporate Babylonia into Hittite domains, Mursili seems to have instead turned control of Babylonia over to his Kassite allies, who were to rule it for the next four centuries. This lengthy campaign, however, strained the resources of Hatti, and left the capital in a state of near-anarchy. Mursili was assassinated shortly after his return home, and the Hittite Kingdom was plunged into chaos. The Hurrians (under the control of an Indo-European Mitanni ruling class), a people living in the mountainous region along the upper Tigris and Euphrates rivers took advantage of the situation to seize Aleppo and the surrounding areas for themselves, as well as the coastal region of Adaniya, renaming it Kizzuwatna (later Cilicia).
Following this, the Hittites entered a weak phase of obscure records, insignificant rulers, and reduced area of control. This pattern of expansion under strong kings followed by contraction under weaker ones, was to be repeated over and over again throughout the Hittite Kingdom's 500-year history, making events during the waning periods difficult to reconstruct with much precision. The political instability of these years of the Old Hittite Kingdom, can be explained in part by the nature of the Hittite kingship at that time. During the Old Hittite Kingdom period prior to 1400 BC, the king of the Hittites was not viewed by the Hittite citizenry as a "living god", like the Pharaohs of Egypt, but rather as a first among equals. Only in the later period of the Hittite Empire, from 1400 BC until 1200 BC, did the kingship of the Hittites become more centralized and powerful. Also in earlier years the succession was not legally fixed, enabling the "war of the Roses" rivalries between northern and southern branches.
The next monarch of any note following Mursili I was Telepinu (ca. 1500 BC), who won a few victories to the southwest, apparently by allying himself with one Hurrian state (Kizzuwatna) against another (Mitanni). Telepinu also attempted to secure the lines of succession.
Middle Kingdom.
The last monarch of the Old kingdom, Telepinu, reigned until about 1500 BC. Telepinu's reign marked the end of the "Old Kingdom" and the beginning of the lengthy weak phase known as the "Middle Kingdom". The period of the 15th century BC is largely unknown with very sparse surviving records. Part of the reason for both the weakness and the obscurity is that the Hittites were under constant attack, mainly from the Kaska, a non Indo-European people settled along the shores of the Black Sea. The capital once again went on the move, first to Sapinuwa and then to Samuha. There is an archive in Sapinuwa but it has not been adequately translated to date.
It segues into the "Hittite Empire period" proper, which dates from the reign of Tudhaliya I from ca. 1430 BC.
One innovation that can be credited to these early Hittite rulers is the practice of conducting treaties and alliances with neighboring states; the Hittites were thus among the earliest known pioneers in the art of international politics and diplomacy. This is also when the Hittite religion adopted several gods and rituals from the Hurrians.
New Kingdom.
With the reign of Tudhaliya I (who may actually not have been the first of that name; see also Tudhaliya), the Hittite Kingdom re-emerges from the fog of obscurity. Hittite civilization entered the period of time called the "Hittite Empire period". Many changes were afoot during this time, not the least of which was a strengthening of the kingship. Settlement of the Hittites progressed in the Empire period. However, the Hittite people tended to settle in the older lands of south Anatolia rather than the lands of the Aegean. As this settlement progressed, treaties were signed with neighboring peoples. During the Hittite Empire period the kingship became hereditary and the king took on a "superhuman aura" and began to be referred to by the Hittite citizens as "My Sun". The kings of the Empire period began acting as a high priest for the whole kingdom—making an annual tour of the Hittite holy cities, conducting festivals and supervising the upkeep of the sanctuaries.
During his reign (c. 1400 BC), King Tudhaliya I, again allied with Kizzuwatna, then vanquished the Hurrian states of Aleppo and Mitanni, and expanded to the west at the expense of Arzawa (a Luwian state).
Another weak phase followed Tudhaliya I, and the Hittites' enemies from all directions were able to advance even to Hattusa and raze it. However, the Kingdom recovered its former glory under Suppiluliuma I (c. 1350 BC), who again conquered Aleppo, reduced Mitanni to tribute under his son-in-law, and defeated Carchemish, another Syrian city-state. With his own sons placed over all of these new conquests, Babylonia still in the hands of the Kassites, this left Suppiluliuma the supreme power broker in the known world, alongside Assyria and Egypt, and it was not long before Egypt was seeking an alliance by marriage of another of his sons with the widow of Tutankhamen. Unfortunately, that son was evidently murdered before reaching his destination, and this alliance was never consummated. However, Assyria began to grow in power also, with the ascension of Ashur-uballit I in 1365 BC. Ashur-uballit I attacked and defeated Mattiwaza the Mitanni king despite attempts by the Hittite king Suppiluliumas I, now fearful of growing Assyrian power, attempting to preserve his throne with military support. The lands of the Mitanni and Hurrians were duly appropriated by Assyria, enabling it to encroach on Hittite territory in Asia Minor, and Adad-nirari I annexed Carchemish from the control of the Hittites.
After Suppiluliumas I, and a very brief reign by his eldest son, another son, Mursili II became king (c. 1330). Having inherited a position of strength in the east, Mursili was able to turn his attention to the west, where he attacked Arzawa and a city known as Millawanda in the coastal land of Ahhiyawa. Many recent scholars have surmised that Millawanda in Ahhiyawa is likely a reference to Miletus and Achaea known to Greek history, though there is a small number who has disputed this connection.
Battle of Kadesh.
Hittite prosperity was mostly dependent on control of the trade routes and metal sources. Because of the importance of Northern Syria to the vital routes linking the Cilician gates with Mesopotamia, defense of this area was crucial, and was soon put to the test by Egyptian expansion under Pharaoh Ramesses II. The outcome of the battle is uncertain, though it seems that the timely arrival of Egyptian reinforcements prevented total Hittite victory. The Egyptians forced the Hittites to take refuge in the fortress of Kadesh, but their own losses prevented them from sustaining a siege. This battle took place in the 5th year of Ramesses (c.1274 BC by the most commonly used chronology).
Downfall and demise of the Kingdom.
After this date, the power of both the Hittites and Egyptians began to decline yet again because of the rising power of the Assyrians. The Assyrian king Shalmaneser I had seized the opportunity to vanquish Hurria and Mitanni, occupy their lands, and expand up to the head of the Euphrates in Anatolia and into Babylonia, Iran, Aram (Syria), while Muwatalli was preoccupied with the Egyptians. The Hittites had vainly tried to preserve the Mitanni kingdom with military support. Assyria now posed just as great a threat to Hittite trade routes as Egypt ever had. Muwatalli's son, Urhi-Teshub, took the throne and ruled as king for 7 years as Mursili III before being ousted by his uncle, Hattusili III after a brief civil war. In response to increasing Assyrian encroachments into Hittite territory, he concluded a peace and alliance with Rameses II, presenting his daughter's hand in marriage to the Pharaoh. The "Treaty of Kadesh", one of the oldest completely surviving treaties in history, fixed their mutual boundaries in Canaan, and was signed in the 21st year of Rameses (c. 1258 BC). Terms of this treaty included the marriage of one of the Hittite princesses to the Pharaoh Rameses.
Hattusili's son, Tudhaliya IV, was the last strong Hittite king able to keep the Assyrians out of the Hittite heartland to some degree, though he lost territory to them, and was heavily defeated by Tukulti-Ninurta I of Assyria in the Battle of Nihiriya. He even temporarily annexed the island of Cyprus, before that too fell to Assyria. The very last king, Suppiluliuma II also managed to win some victories, including a naval battle against Alashiya off the coast of Cyprus. But the Assyrians, under Ashur-resh-ishi I had by this time annexed much Hittite territory in Asia Minor and Syria, driving out the Babylonian king Nebuchadnezzar I in the process, who also had eyes on Hittite lands. The Sea Peoples had already begun their push down the Mediterranean coastline, starting from the Aegean, and continuing all the way to Philistia—taking Cilicia and Cyprus away from the Hittites en route and cutting off their coveted trade routes. This left the Hittite homelands vulnerable to attack from all directions, and Hattusa was burnt to the ground sometime around 1180 BC following a combined onslaught from new waves of invaders, the Kaskas, Phrygians and Bryges. The Hittite Kingdom thus vanished from historical records. The end of the kingdom was part of the larger Bronze Age Collapse.
Syro-Hittite kingdoms.
By 1160 BC, the political situation in Asia Minor looked vastly different from that of only 25 years earlier. In that year, the Assyrian king Tiglath-Pileser I was defeating the "Mushku" (Phrygians) who had been attempting to press into Assyrian colonies in southern Anatolia from the Anatolian highlands, and the Gasga people, the Hittites' old enemies from the northern hill-country between Hatti and the Black Sea, seem to have joined them soon after. The Phrygians had apparently overrun Cappadocia from the West, with recently discovered epigraphic evidence confirming their origins as the Balkan "Bryges" tribe, forced out by the Macedonians.
Although the Hittite kingdom disappeared from Anatolia at this point, there emerged a number of so-called Neo-Hittite kingdoms in Anatolia and northern Syria. They were the successors of the Hittite Kingdom. The most notable Syrian Neo-Hittite kingdoms were those at Carchemish and Milid (near the later Melitene). These Neo-Hittite Kingdoms gradually fell under the control of the Neo Assyrian Empire (911–608 BC). Carchemish and Milid were made vassals of Assyria under Shalmaneser III (858–823 BC), and fully incorporated into Assyria during the reign of Sargon II (722–705 BC).
A large and powerful state known as Tabal occupied much of southern Anatolia. Known as Gk. Τιβαρηνοί Tibarenoi, Lat. Tibareni, Thobeles in Josephus, their language may have been Luwian, testified to by monuments written using Luwian hieroglyphics. This state too was conquered and incorporated into the vast Assyrian Empire.
Ultimately, both Luwian hieroglyphs and cuneiform were rendered obsolete by an innovation, the alphabet, which seems to have entered Anatolia simultaneously from the Aegean (with the Bryges, who changed their name to Phrygians), and from the Phoenicians and neighboring peoples in Syria.
Government.
The head of the Hittite state was the king, followed by the heir-apparent. However, some officials exercised independent authority over various branches of the government. One of the most important of these posts in the Hittite society was that of the Gal Mesedi (Chief of the Royal Bodyguards). It was superseded by the rank of the Gal Gestin (Chief of the Wine Stewards), who, like the "Gal Mesedi", was generally a member of the royal family. The kingdom's bureaucracy was headed by the Gal Dubsar (Chief of the Scribes), whose authority didn't extend over the "Lugal Dubsar", the king's personal scribe.
Language.
The Hittite language is recorded fragmentarily from about the 19th century BC (in the Kültepe texts, see "Ishara"). It remained in use until about 1100 BC. Hittite is the best attested member of the Anatolian branch of the Indo-European language family.
The language of the Hattusa tablets was eventually deciphered by a Czech linguist, Bedřich Hrozný (1879–1952), who, on 24 November 1915, announced his results in a lecture at the Near Eastern Society of Berlin. His book about the discovery was printed in Leipzig in 1917, under the title "The Language of the Hittites; Its Structure and Its Membership in the Indo-European Linguistic Family". The preface of the book begins with:
Due to its marked differences in its structure and phonology, some early philologists, most notably Warren Cowgill had even argued that it should be classified as a sister language to Indo-European languages (Indo-Hittite), rather than a daughter language. By the end of the Hittite Empire, the Hittite language had become a written language of administration and diplomatic correspondence. The population of most of the Hittite Empire by this time spoke Luwian dialects, another Indo-European language of the Anatolian family that had originated to the west of the Hittite region.
Religion and mythology.
Hittite religion and mythology were heavily influenced by their Hattic, Mesopotamian, and Hurrian counterparts. In earlier times, Indo-European elements may still be clearly discerned.
"Storm gods" were prominent in the Hittite pantheon. Tarhunt (Hurrian's Teshub) was referred to as 'The Conqueror', 'The king of Kummiya', 'King of Heaven', 'Lord of the land of Hatti'. He was chief among the gods and his symbol is the bull. As Teshub he was depicted as a bearded man astride two mountains and bearing a club. He was the god of battle and victory, especially when the conflict involved a foreign power. Teshub was also known for his conflict with the serpent Illuyanka.
Biblical Hittites.
The Hebrew Bible refers to "Hittites" in several passages, ranging from Genesis to the post-Exilic Ezra-Nehemiah. Genesis 10 (the Table of Nations) links them to an eponymous ancestor Heth, a descendant of Ham through his son Canaan. The Hittites are thereby counted among the Canaanites. The Hittites are usually depicted as a people living among the Israelites—Abraham purchases the Patriarchal burial-plot of Machpelah from "Ephron HaChiti", Ephron the Hittite; and Hittites serve as high military officers in David's army. In 2 Kings 7:6, however, they are a people with their own kingdoms (the passage refers to "kings" in the plural), apparently located outside geographic Canaan, and sufficiently powerful to put a Syrian army to flight.
It is a matter of considerable scholarly debate whether the biblical "Hittites" signified any or all of: 1) the original Hattians; 2) their Indo-European conquerors, who retained the name "Hatti" for Central Anatolia, and are today referred to as the "Hittites" (the subject of this article); or 3) a Canaanite group who may or may not have been related to either or both of the Anatolian groups, and who also may or may not be identical with the later Neo-Hittite (Luwian) polities.
Other biblical scholars (following Max Müller) have argued that, rather than being connected with Heth, son of Canaan, the Anatolian land of "Hatti" was instead mentioned in Old Testament literature and apocrypha as "Kittim" (Chittim), a people said to be named for a son of Javan.
Literature.
</dl>

</doc>
<doc id="13311" url="http://en.wikipedia.org/wiki?curid=13311" title="Hormone">
Hormone

A hormone (from Greek ὁρμή, "impetus") is any member of a class of signaling molecules produced by glands in multicellular organisms that are transported by the circulatory system to target distant organs to regulate physiology and behaviour. Hormones have diverse chemical structures that include eicosanoids, steroids, amino acid derivatives, peptides, and proteins. The glands that secrete hormones comprise the endocrine signaling system. The term hormone is sometimes extended to include chemicals produced by cells that affect the same cell (autocrine or intracrine signalling) or nearby cells (paracrine signalling).
Hormones are used to communicate between organs and tissues to regulate physiological and behavioral activities, such as digestion, metabolism, respiration, tissue function, sensory perception, sleep, excretion, lactation, stress, growth and development, movement, reproduction, and mood. Hormones affect distant cells by binding to specific receptor proteins in the target cell resulting in a change in cell function. When a hormone binds to the receptor, it results in the activation of a signal transduction pathway. This may lead to cell type-specific responses that include rapid non-genomic effects or slower genomic responses where the hormones acting through their receptors activate gene transcription resulting in increased expression of target proteins.
Hormone synthesis may occur in specific tissues of endocrine glands or in other specialized cells. Hormone synthesis occurs in response to specific biochemical signals induced by a wide range of regulatory systems. For instance, ionized calcium concentration affects PTH synthesis, whereas glucose concentration affects insulin synthesis. Regulation of hormone synthesis of gonadal, adrenal, and thyroid hormones is often dependent on complex sets of direct influence and feedback interactions involving the hypothalamic-pituitary-adrenal (HPA), -gonadal (HPG), and -thyroid (HPT) axes.
Upon secretion, certain hormones, including protein hormones and catecholamines, are water soluble and are thus readily transported through the circulatory system. Other hormones, including steroid and thyroid hormones, are lipid soluble; to allow for their widespread distribution, these hormones must bond to carrier plasma glycoproteins (e.g., thyroxine-binding globulin (TBG)) to form ligand-protein complexes. Some hormones are completely active when released into the bloodstream (as is the case for insulin and growth hormones), while others must be activated in specific cells through a series of activation steps that are commonly highly regulated. The endocrine system secretes hormones directly into the bloodstream typically into fenestrated capillaries, whereas the exocrine system secretes its hormones indirectly using ducts. Hormones with paracrine function diffuse through the interstitial spaces to nearby target tissue.
Overview.
Hormonal signaling involves the following steps:
Hormone cells are typically of a specialized cell type, residing within a particular endocrine gland, such as the thyroid gland, ovaries, and testes. Hormones exit their cell of origin via exocytosis or another means of membrane transport. The hierarchical model is an oversimplification of the hormonal signaling process. Cellular recipients of a particular hormonal signal may be one of several cell types that reside within a number of different tissues, as is the case for insulin, which triggers a diverse range of systemic physiological effects. Different tissue types may also respond differently to the same hormonal signal.
Regulation.
The rate of hormone biosynthesis and secretion is often regulated by a homeostatic negative feedback control mechanism. Such a mechanism depends on factors that influence the metabolism and excretion of hormones. Thus, higher hormone concentration alone cannot trigger the negative feedback mechanism. Negative feedback must be triggered by overproduction of an "effect" of the hormone.
Hormone secretion can be stimulated and inhibited by:
One special group of hormones is the tropic hormones that stimulate the hormone production of other endocrine glands. For example, thyroid-stimulating hormone (TSH) causes growth and increased activity of another endocrine gland, the thyroid, which increases output of thyroid hormones.
To release active hormones quickly into the circulation, hormone biosynthetic cells may produce and store biologically inactive hormones in the form of pre- or prohormones. These can then be quickly converted into their active hormone form in response to a particular stimulus.
Eicosanoids are considered to act as local hormones.
Receptors.
 Most hormones initiate a cellular response by initially binding to either cell membrane associated or intracellular receptors. A cell may have several different receptor types that recognize the same hormone but activate different signal transduction pathways, or a cell may have several different receptors that recognize different hormones and activate the same biochemical pathway.
Receptors for most peptide as well as many eicosanoid hormones are embedded in the plasma membrane at the surface of the cell and the majority of these receptors belong to the G protein-coupled receptor (GPCR) class of seven alpha helix transmembrane proteins. The interaction of hormone and receptor typically triggers a cascade of secondary effects within the cytoplasm of the cell, often involving phosphorylation or dephosphorylation of various other cytoplasmic proteins, changes in ion channel permeability, or increased concentrations of intracellular molecules that may act as secondary messengers (e.g., cyclic AMP). Some protein hormones also interact with intracellular receptors located in the cytoplasm or nucleus by an intracrine mechanism.
For steroid or thyroid hormones, their receptors are located inside the cell within the cytoplasm of the target cell. These receptors belong to the nuclear receptor family of ligand-activated transcription factors. To bind their receptors, these hormones must first cross the cell membrane. They can do so because they are lipid-soluble. The combined hormone-receptor complex then moves across the nuclear membrane into the nucleus of the cell, where it binds to specific DNA sequences, regulating the expression of certain genes, and thereby increasing the levels of the proteins encoded by these genes. However, it has been shown that not all steroid receptors are located inside the cell. Some are associated with the plasma membrane.
Effects.
A variety of exogenous chemical compounds, both natural and synthetic, have hormone-like effects on both humans and wildlife. Their interference with the synthesis, secretion, transport, binding, action, or elimination of natural hormones in the body can change the homeostasis, reproduction, development, and/or behavior, similar to endogenously produced hormones.
Hormones have the following effects on the body:
A hormone may also regulate the production and release of other hormones. Hormone signals control the internal environment of the body through homeostasis.
Chemical classes.
As hormones are defined functionally, not structurally, they may have diverse chemical structures. Hormones occur in multicellular organisms (plants, animals, fungi, brown algae and red algae). These compounds occur also in unicellular organisms, and may act as signaling molecules, but there is no consensus if, in this case, they can be called hormones.
Animal.
Vertebrate hormones fall into three main chemical classes:
Compared with vertebrate, insects and crustaceans possess a number of structurally unusual hormones such as the juvenile hormone, a sesquiterpenoid.
Plant.
Plant hormones include abscisic acid, auxin, cytokinin, ethylene, and gibberellin.
Therapeutic use.
Many hormones and their analogues are used as medication. The most commonly prescribed hormones are estrogens and progestogens (as methods of hormonal contraception and as HRT), thyroxine (as levothyroxine, for hypothyroidism) and steroids (for autoimmune diseases and several respiratory disorders). Insulin is used by many diabetics. Local preparations for use in otolaryngology often contain pharmacologic equivalents of adrenaline, while steroid and vitamin D creams are used extensively in dermatological practice.
A "pharmacologic dose" or "supraphysiological dose" of a hormone is a medical usage referring to an amount of a hormone far greater than naturally occurs in a healthy body. The effects of pharmacologic doses of hormones may be different from responses to naturally occurring amounts and may be therapeutically useful, though not without potentially adverse side effects. An example is the ability of pharmacologic doses of glucocorticoids to suppress inflammation.
Hormone-behavior interactions.
At the neurological level, behavior can be inferred based on: hormone concentrations; hormone-release patterns; the numbers and locations of hormone receptors; and the efficiency of hormone receptors for those involved in gene transcription. Not only do hormones influence behavior, but also behavior and the environment influence hormones. Thus, a feedback loop is formed. For example, behavior can affect hormones, which in turn can affect behavior, which in turn can affect hormones, and so on.
Three broad stages of reasoning may be used when determining hormone-behavior interactions:
Comparison with neurotransmitters.
There are various clear distinctions between hormones and neurotransmitters:

</doc>
<doc id="13312" url="http://en.wikipedia.org/wiki?curid=13312" title="Hammond organ">
Hammond organ

The Hammond organ is an electric organ, invented by Laurens Hammond and John M. Hanert and first manufactured in 1935. Various models have been produced, most of which use sliding drawbars to create a variety of sounds. Until 1975, Hammond organs generated sound by creating an electric current from rotating a metal tonewheel near an electromagnetic pickup. Around two million Hammond organs have been manufactured, and it has been described as one of the most successful organs. The organ is commonly used with, and associated with, the Leslie speaker.
The organ was originally marketed and sold by the Hammond Organ Company to churches as a lower-cost alternative to the wind-driven pipe organ, or instead of a piano. It quickly became popular with professional jazz musicians, who found it a cheaper alternative to the big band. Jimmy Smith's use of the Hammond B-3, with its additional harmonic percussion feature, inspired a generation of organ players, and its use became more widespread in the 1960s and 1970s in rhythm and blues, rock and reggae, as well as being an important instrument in progressive rock.
The Hammond Organ Company struggled financially during the 1970s as they abandoned tonewheel organs and switched to manufacturing instruments using integrated circuits. These instruments were not as popular with musicians as the tonewheels had been, and the company went out of business in 1985. The Hammond name was purchased by the Suzuki Musical Instrument Corporation, which proceeded to manufacture digital simulations of the most popular tonewheel organs. This culminated in the production of the "New B-3" in 2002, which provided an accurate recreation of the original B-3 organ using modern digital technology.
Hammond-Suzuki continues to manufacture a variety of organs for both the professional player and the church. Other companies, such as Korg, Roland and Clavia, have also achieved success in providing emulations of the original tonewheel organs. The sound of a tonewheel Hammond can also be emulated using modern software such as Native Instruments B4.
Features.
A number of distinctive Hammond organ features are not usually found on other keyboards like the piano or synthesizer. Some are similar to a pipe organ, but others are unique to the instrument.
Keyboards and pedalboard.
Most Hammond organs have two 61-note (5-octave) manuals. Each manual is laid out in a similar manner to a piano keyboard, except pressing a key results in the sound continuously playing until it is released. There is no difference in volume regardless of how heavily the key is pressed, so overall volume is controlled by a pedal (also known as a "swell" or "expression" pedal). The keys on each manual have a lightweight action, which allows players to perform rapid passages more easily than on a piano. In contrast to piano and pipe organ keys, Hammond keys have a flat-front profile, commonly referred to as "waterfall" style. Early Hammond console models had sharp edges, but starting with the B-2 these were rounded, as they were cheaper to manufacture. The M series of spinets also had waterfall keys (which has subsequently made them ideal for spares on B-3s and C-3s), but later models had "diving board" style keys which resembled those found on a church organ. Modern Hammond-Suzuki models use waterfall keys.
Hammond console organs come with a wooden pedalboard played with the feet, for bass notes. Most Hammond pedalboards have 25 notes, with the top note a middle C, because Hammond found that on traditional 32-note pedalboards used in churches, the top seven notes were seldom used. The Hammond Concert models E, RT, RT-2, RT-3 and D-100 had 32-note American Guild of Organists (AGO) pedalboards going up to the G above middle C as the top note. The RT-2, RT-3 and D-100 also contained a separate solo pedal system that had its own volume control and various other features. Spinet models had 12- or 13-note miniature pedalboards with stamped steel pedals.
Drawbars.
The sound on a tonewheel Hammond organ is varied through the manipulation of drawbars. A drawbar is a metal slider that controls the volume of a particular sound component, in a similar way to a fader on an audio mixing board. As a drawbar is incrementally pulled out, it increases the volume of its sound. When pushed all the way in, the volume is decreased to zero.
The labeling of the drawbar derives from the stop system in pipe organs, in which the physical length of the pipe corresponds to the pitch produced. Most Hammonds contain nine drawbars per manual. The drawbar marked "8'" generates the fundamental of the note being played, the drawbar marked "16'" is an octave below, and the drawbars marked "4'", "2'" and "1'" are one, two and three octaves above respectively. The other drawbars generate various subharmonics of the note. While each individual drawbar generates a relatively pure sound similar to a flute or electronic oscillator, more complex sounds can be created by mixing the drawbars in varying amounts. Some spinet models do not include the two subharmonic drawbars on the lower manual.
Some drawbar settings have become well known and associated with certain musicians. A very popular setting is 888000000 (i.e., with the drawbars labelled "16'", "51/3'" and "8'" fully pulled out), and has been identified as the "classic" Jimmy Smith sound.
Presets.
In addition to drawbars, many Hammond tonewheel organ models also include presets, which make predefined drawbar combinations available at the press of a button. Console organs have one octave of reverse colored keys (naturals are black, sharps and flats are white) to the left of each manual, with each key activating a preset; the far left key (C), also known as the cancel key, de-activates all presets, and results in no sound coming from that manual. The two right-most preset keys (B and B♭) activate the corresponding set of drawbars for that manual, while the other preset keys produce preselected drawbar settings that are internally wired into the preset panel. Presets can be changed by rerouting the associated color-coded wires on the rear of the organ. Some spinet models have flip tabs for presets situated above the manuals.
Vibrato and chorus.
Hammond organs have a built-in vibrato effect that provides a small variation in pitch while a note is being played, and a chorus effect where a note's sound is combined with another sound at a slightly different and varying pitch. The best known vibrato and chorus system consists of six settings, V1, V2, V3, C1, C2 and C3 (i.e., 3 vibrato and 3 chorus), which can be selected via a rotary switch. Vibrato / chorus can be selected for each manual independently.
Harmonic Percussion.
The B-3 and C-3 models introduced the concept of "Harmonic Percussion", which was designed to emulate the percussive sounds of the harp, xylophone and marimba. When selected, this feature plays a decaying second- or third-harmonic overtone when a key is pressed. The selected percussion harmonic fades out, leaving the sustained tones the player selected with the drawbars. The volume of this percussive effect is selectable as either Normal or Soft. Harmonic Percussion retriggers only after all notes have been released, so legato passages sound the effect only on the very first note or chord, making Harmonic Percussion uniquely a "single-trigger, polyphonic" effect
Start and Run switches.
Before a Hammond organ can produce sound, the motor that drives the tonewheels must come up to speed. On most models, starting a Hammond organ involves two switches. The "Start" switch turns a dedicated starter motor, which must run for about 12 seconds. Then, the "Run" switch is turned on for about four seconds. The "Start" switch is then released, whereupon the organ is ready to generate sound. The H-100 and E-series consoles and L-100 and T-100 spinet organs, however, had a self-starting motor that required only a single "On" switch.
It is possible to create a pitch bend on the Hammond organ by turning the "Run" switch off and on again. This briefly cuts power to the generators, causing them to run at a slower pace and generate a lower pitch for a short time. Hammond's New B3 contains similar switches to emulate this effect, though it is a digital instrument.
History.
Background.
The Hammond organ's technology derives from the Telharmonium, an instrument created in 1897 by Thaddeus Cahill. The telharmonium used revolving electric alternators which generated tones that could be transmitted over wires. The instrument was bulky, because the alternators had to be large enough to generate high voltage for a loud enough signal. The Hammond organ solved this problem by using an amplifier.
Laurens Hammond graduated from Cornell University with a mechanical engineering degree in 1916. By the start of the 1920s he had designed a spring-driven clock, which provided enough sales for him to start his own business, the Hammond Clock Company, in 1928. As well as clocks, his early inventions included 3D glasses and an automatic bridge table shuffler. However, as the Great Depression continued into the 1930s, sales of the bridge table declined and he decided to look elsewhere for a commercially successful product. Hammond got the idea for the tonewheel or "phonic wheel" by listening to the moving gears of his electric clocks and the tones produced by them. He gathered pieces from a second-hand piano he had purchased for $15 and combined it with a tonewheel generator in a similar form to the telharmonium, albeit much shorter and more compact. Since Hammond was not a musician, he asked the company's assistant treasurer, W. L. Lahey, to help him achieve the desired organ sound. To cut costs, Hammond made a pedalboard with only 25 notes, instead of the standard 32 on church organs, and it quickly became a "de facto" standard.
On April 24, 1934, Hammond filed U.S. Patent for an "electrical musical instrument", which was personally delivered to the patent office by Hanert, explaining that they could start production immediately and it would be good for local employment in Chicago. The invention was unveiled to the public in April 1935 and the first model, the Model A, was made available in June of that year. Over 1,750 churches purchased a Hammond organ in the first three years of manufacturing, and by the end of the 1930s over 200 instruments were being made each month. For all its subsequent success with professional musicians, the original company did not target its products at that market, principally because Hammond did not think there was enough money in it. It has been estimated that the Hammond Organ Company produced about two million instruments in its lifetime; these have been described as "probably the most successful electronic organs ever made". In 1966, it was estimated that about 50,000 churches had installed a Hammond.
In 1936, the Federal Trade Commission (FTC) filed a complaint claiming that the Hammond Company made "false and misleading" claims in advertisements for its organ, including that the Hammond could produce "the entire range of tone coloring of a pipe organ". The complaint resulted in lengthy hearing proceedings, which featured a series of auditory tests that pitted a Hammond costing about $2600 against a $75,000 Skinner pipe organ in the University of Chicago Rockefeller Chapel. During the auditory tests, sustained tones and excerpts from musical works were played on the electric and pipe organs while a group of musicians and laymen attempted to distinguish between the instruments. While attorneys for Hammond argued that the test listeners were wrong or guessed nearly half the time, witnesses for the FTC claimed that Hammond employees had unfairly manipulated the Skinner organ to sound more like the Hammond. In 1938, the FTC ordered Hammond to "cease and desist" a number of advertising claims, including that its instrument was equivalent to a $10,000 pipe organ. After the FTC's decision, Hammond claimed that the hearings had vindicated his company's assertions that the organ produced "real", "fine", and "beautiful" music, phrases which were each cited in the FTC's original complaint but not included in the "cease and desist" order. Hammond also claimed that although the hearing was expensive for his company, the proceedings generated so much publicity that "as a result we sold enough extra organs to cover the expense."
A key ingredient to the Hammond organ's success was the use of dealerships and a sense of community. Several dedicated organ dealers set up business in the United States and there was a bi-monthly newsletter, "The Hammond Times", mailed out to subscribers. Advertisements tended to show families centered around the instrument, often with a child playing it, as an attempt to show the organ as a center-point of home life and to encourage children to learn music.
Tonewheel organs.
Hammond organs, as manufactured by the original company, can be divided into two main groups:
Console organs.
The first model in production, in June 1935, was the Model A. It contained most of the features that came to be standard on all console Hammonds, including two 61-key manuals, a 25-key pedalboard, an expression pedal, 12 reverse-color preset keys, two sets of drawbars for each manual, and one for the pedals.
To address concerns that the sound of the Hammond was not rich enough to accurately mimic a pipe organ, the model BC was introduced in December 1936. It included a chorus generator, in which a second tonewheel system added slightly sharp or flat tones to the overall sound of each note. The cabinet was made deeper to accommodate this. Production of the old Model A cases stopped, but the older model continued to be available as the AB until October 1938.
Criticism that the Hammond organ was more aesthetically suitable to the home instead of the church led to the introduction of the model C in September 1939. It contained the same internals as the AB or BC, but covered on the front and sides by "modesty panels" to allow for modesty while playing in a skirt, often a consideration when a church organ was placed in front of the congregation. The model C did not contain the chorus generator, but had space in the cabinet for it to be fitted. The concurrent model D was a model C with a pre-fitted chorus. Development of the vibrato system took place during the early 1940s, and was put into production shortly after the end of World War II. The various models available were the BV and CV (vibrato only) and BCV and DV (vibrato and chorus).
The B-2 and C-2, introduced in 1949, allowed vibrato to be enabled or disabled on each manual separately. In 1954, the B-3 and C-3 models were introduced with the additional harmonic percussion feature. Despite several attempts by Hammond to replace them, these two models remained popular and stayed in continuous production through early 1975.
To cater more specifically to the church market, Hammond introduced the Concert Model E in July 1937, which included a full 32-note pedalboard and four electric switches known as toe pistons, allowing various sounds to be selected by the feet. The model E was replaced by the model RT in 1949, which retained the full size pedalboard, but otherwise was internally identical to the B and C models. RT-2 and RT-3 models subsequently appeared in line with the B-2/C-2 and B-3/C-3 respectively.
In 1959, Hammond introduced the A-100 series. It was effectively a self-contained version of the B-3/C-3, with an internal power amplifier and speakers. The organ was manufactured in a variety of different chassis, with the last two digits of the specific model number determining the style and finish of the instrument. For example, A-105 was "Tudor styling in light oak or walnut," while the A-143 was "warm cherry finish, Early American styling". This model numbering scheme was used for several other series of console and spinet organs that subsequently appeared. The D-100 series, which provided a self-contained version of the RT-3, followed in 1963.
The E-100 series was a cost-reduced version of the A-100 introduced in 1965, with only one set of drawbars per manual, a reduced number of presets, and a slightly different tone generator. This was followed by the H-100 series, with a redesigned tonewheel generator and various other additional features. Unfortunately, the organ was not particularly well made, and suffered a reputation for being unreliable. Hammond service engineer Harvey Olsen said "When they [H-100s] work, they sound pretty decent. But die-hard enthusiasts won't touch it."
Spinet organs.
Though the instrument had been originally designed for use in a church, Hammond realized that the amateur home market was a far more lucrative business, and started manufacturing spinet organs in the late 1940s. Outside of the United States, they were manufactured in greater numbers than the consoles, and hence were more widely used. Several different types of M series instruments were produced between 1948 and 1964; they contained two 44-note manuals with one set of drawbars each, and a 12-note pedalboard. The M model was produced from 1948 to 1951, the M-2 from 1951 to 1955, and the M-3 from 1955 to 1964. The M series was replaced by the M-100 series in 1961, which used a numbering system to identify the body style and finish as used on earlier console series. It included the same manuals as the M, but increased the pedalboard size to 13 notes, stretching a full octave, and included a number of presets.
The L-100 series entered production at the same time as the M-100. It was an economy version, with various cost cutting changes so the organ could retail for under $1000. The vibrato was a simpler circuit than on other consoles and spinets. Two variations of the vibrato were provided, plus a chorus that mixed various vibrato signals together. The expression pedal, based on a cheaper design, was not as sophisticated as on the other organs. The L-100 was particularly popular in the UK and sold well, with several notable British musicians using it instead of a B-3 or C-3.
The T series, produced from 1968 to 1975, was the last of the tonewheel spinet organs. Unlike all the earlier Hammond organs, which used vacuum tubes for pre-amplification, amplification, Percussion and Chorus-Vibrato control, the T series used all-solid-state, transistor circuitry, though, unlike the L-100, it did include the scanner-vibrato as seen on the B-3. Other than the T-100 series models, all other T-Series models included a built-in rotating Leslie speaker and some included an analog drum machine, while the T-500 also included a built-in cassette recorder. It was one of the last tonewheel Hammonds produced.
Transistor organs.
In the 1960s, Hammond started making transistor organs. The first organ that bridged the gap between tonewheel and transistor was the X-66, introduced in May 1967. The X-66 contained just 12 tonewheels, and used electronics for frequency division. It contained separate "vibrato bass" and "vibrato treble" in an attempt to simulate a Leslie speaker. Hammond designed it as the company's flagship product, in response to market competition and to replace the B-3. However, it was considered expensive at $9,795 and it sold poorly. It did not sound like a B-3.
Hammond introduced their first integrated circuit (IC) model, the Concorde, in 1971. The company had stopped manufacturing tonewheel organs entirely by 1975, due to increased financial inefficiency, and switched to making IC models full-time. Console models included the 8000 Aurora (1976) and 8000M Aurora (1977), which contained drawbars and a built-in rotating speaker. Spinet organs included the Romance series, manufactured between 1977 and 1983. In 1979, a Japanese offshoot, Nihon Hammond, introduced the X-5, a portable solid-state clone of the B-3.
Hammond-Suzuki.
Laurens Hammond died in 1973, and the company struggled to survive, proposing an acquiring of Roland in 1972, which was turned down. Roland's Ikutaro Kakehashi did not believe it was practical at that point to move the entire manufacturing operation from Chicago to Japan, and also viewed Hammond's declining sales figures as a problem. Hammond went out of business in 1985, though servicing and spares continued to be available after this under the name of The Organ Service Company. In early 1986, the Hammond brand and rights were acquired by Hammond Organ Australia, run by Noel Crabbe.
The name was purchased by the Suzuki Musical Instrument Corporation in 1989, who rebranded the company as Hammond-Suzuki. Although nominally a Japanese company, founder Manji Suzuki was a fan of the instrument and retained several former Hammond Organ Company staff for research and development, and ensured that production would partially remain in the United States. The new company produced their own brand of portable organs, including the XB-2, XB-3 and XB-5. "Sound on Sound"‍‍ '​‍s Rod Spark, a longtime Hammond enthusiast, said these models were "a matter of taste, of course, but I don't think they're a patch on the old ones".
In 2002, Hammond-Suzuki relaunched the B-3 as the 'New B-3', a re-creation of the original electromechanical instrument using contemporary electronics and a digital tonewheel simulator. The New B-3 is constructed to appear like the original B-3, and the designers attempted to retain the subtle nuances of the familiar B-3 sound. Hammond-Suzuki promotional material states that it would be difficult for even an experienced B-3 player to distinguish between the old and new B-3 organs. A review of the New B-3 by Hugh Robjohns called it "a true replica of an original B-3 ... in terms of the look and layout, and the actual sound." The instrument project nearly stalled after a breakdown in negotiations between Japanese and United States staff, the latter of whom insisted on manufacturing the case in the United States and designing the organ to identical specifications to the original.
The company has since released the XK-3, a single-manual organ using the same digital tonewheel technology as the New B-3. The XK-3 is part of a modular system that allows an integrated lower manual and pedals to be added. In response to some clones including a variety of vintage keyboards in a single package, Hammond released the SK series of organs, which include grand piano, Rhodes piano, Wurlitzer electronic piano, Hohner Clavinet and samples of wind and brass instruments alongside the standard drawbar and tonewheel emulation. "Keyboard Magazine"‍‍ '​‍s Stephen Fortner praised the single manual SK1, indicated that it gave an accurate sound throughout the range of drawbar settings, and said the organ sound was "fat, warm, utterly authentic". The XK-1c model was introduced in early 2014, which is simply an organ-only version of the SK1.
In the US, Hammond manufactures a number of dedicated console organs, including the B-3mk2 and the C-3mk2, and the A-405, a Chapel Console Organ. The company has a dedicated Church Advisory Team that provides a consultancy so that churches can choose the most appropriate instrument.
Speakers.
Tone cabinet.
The authorized loudspeaker enclosure to use with a console organ was the Hammond Tone Cabinet, which housed an external amplifier and speaker in a box. The cabinet carried a balanced mono signal along with the necessary mains power directly from the organ, using a six-pin cable. Spinet organs contained a built-in power amplifier and loudspeakers, and so did not require a tone cabinet.
The tone cabinet was originally the only method of adding reverb to a Hammond organ; reverb was not fitted to older organs. The most commercially successful tone cabinets were probably the PR series, particularly the 40-watt PR40.
Leslie speaker.
Many players prefer to play the Hammond through a rotating speaker cabinet known, after several name changes, as a Leslie speaker, after its inventor Donald J. Leslie. The Leslie system is an integrated speaker/amplifier combination in which sound is emitted by a rotating horn over a stationary treble compression driver, and a rotating baffle beneath a stationary bass woofer. This creates a characteristic sound because of the constantly changing pitch shifts that result from the Doppler effect created by the moving sound sources.
The Leslie was originally designed to mimic the complex tones and constantly shifting sources of sound emanating from a large group of ranks in a pipe organ. The effect varies depending on the speed of the rotors, which can be toggled between fast (tremolo) and slow (chorale) using a console or pedal switch, with the most distinctive effect occurring as the speaker rotation speed changes. The most popular Leslies were the 122, which accepted a balanced signal suitable for console organs, and the 147, which accepted an unbalanced signal and could be used for spinet organs with a suitable adapter. The Pro-Line series of Leslies which were made to be portable for gigging bands using solid-state amps were popular during the 1970s.
Leslie initially tried to sell his invention to Hammond, but Laurens Hammond was unimpressed and declined to purchase it. Hammond modified their interface connectors to be "Leslie-proof", but Leslie quickly engineered a workaround. The Leslie company was sold to CBS in 1965 and was finally bought by Hammond in 1980. Hammond-Suzuki acquired the rights to Leslie in 1992; the company currently markets a variety of speakers under this name. As well as faithful reissues of the original 122 speaker, the company announced in 2013 that they would start manufacturing a standalone Leslie simulator in a stomp box.
Tone generation.
Although they are sometimes included in the category of electronic organs, the majority of Hammond organs are, strictly speaking, "electric" or "electromechanical" rather than "electronic" organs because the sound is produced by moving parts rather than electronic oscillators.
The basic component sound of a Hammond organ comes from a tonewheel. Each one rotates in front of an electromagnetic pickup. The variation in the magnetic field induces a small alternating current (AC) at a particular frequency, which represents a signal similar to a sine wave. When a key is pressed on the organ, it completes a circuit of nine electrical switches, which are linked to the drawbars. The position of the drawbars, combined with the switches selected by the key pressed, determines which tonewheels are allowed to sound. Every tonewheel is connected to a synchronous motor via a system of gears, which ensures that each note remains at a constant relative pitch to every other. The combined signal from all depressed keys and pedals is fed through to the vibrato system, which is driven by a metal scanner. As the scanner rotates around a set of pickups, it changes the pitch of the overall sound slightly. From here, the sound is sent to the main amplifier, and on to the audio speakers.
The Hammond organ makes technical compromises in the notes it generates. Rather than produce harmonics that are exact multiples of the fundamental as in equal temperament, it uses the nearest-available frequencies generated by the tonewheels. The only guaranteed frequency for a Hammond's tuning is concert A at 440 Hz.
Crosstalk or "leakage" occurs when the instrument's magnetic pickups receive the signal from rotating metal tonewheels other than those selected by the organist. Hammond considered crosstalk a defect that required correcting, and in 1963 introduced a new level of resistor–capacitor (R/C) filtering to greatly reduce this crosstalk, along with 50–60 Hz mains hum. However, the sound of tonewheel crosstalk is now considered part of the signature of the Hammond organ, to the extent that modern digital clones explicitly emulate it.
Some Hammond organs have an audible pop or click when a key is pressed. Originally, key click was considered a design defect and Hammond worked to eliminate or at least reduce it with equalization filters. However, many performers liked the percussive effect, and it has been accepted as part of the classic sound. Hammond research and development engineer Alan Young said "the professionals who were playing popular music [liked] that the attack was so prominent. And they objected when it was eliminated."
Clones and emulation devices.
The original Hammond organ was never designed to be transported on a regular basis. A Hammond B-3 organ, bench, and pedalboard weighs 425 lb. This weight, combined with that of a Leslie speaker, makes the instrument cumbersome and difficult to move between venues. Consequently, there has been a demand for a more portable, reliable way of generating the same sound. Electronic and digital keyboards that imitate the sound of the Hammond are often referred to as "clonewheel organs".
The first attempts to electronically copy a Hammond appeared in the 1970s, including the Roland VK-1 and VK-9, the Yamaha YP45D and the Crumar Organiser. The Korg CX-3 (single manual) and BX-3 (dual manual) were the first lightweight organs to produce a comparable sound to the original. "Sound on Sound"‍‍ '​‍s Gordon Reid said that the CX-3 "came close to emulating the true depth and passion of a vintage Hammond," particularly when played through a Leslie speaker.
The Roland VK-7, introduced in 1997, attempted to emulate the sound of a Hammond using digital signal processing technology. An updated version, the VK-8, which appeared in 2002, also provided emulations of other vintage keyboards and provided a connector for a Leslie. Clavia introduced the Nord Electro in 2001; this used buttons to emulate the physical action of pulling or pushing a drawbar, with an LED graph indicating its current state. Clavia has released several updated versions of the Electro since then, and introduced the Nord Stage with the same technology. The Nord C2D was Clavia's first organ with real drawbars. Diversi, founded by former Hammond-Suzuki sales rep Tom Tuson in 2003, has specialised in Hammond clones, and featured a notable endorsement from Joey DeFrancesco.
The Hammond organ has also been emulated in software. The most prominent emulator in this field has been the Native Instruments B4 series, which has been praised for its attention to detail and choice of features. Emagic (now part of Apple) has also produced a software emulation, the EVB3.
Notable users.
Early customers of the Hammond included Dr. Albert Schweitzer, Henry Ford, Eleanor Roosevelt and George Gershwin.
The instrument was not initially favored by classical organ purists, because the tones of two notes an octave apart were in exact synchronization, as opposed to the slight variation present on a pipe organ. However, the instrument did gradually become popular with jazz players. One of the first notable performers to use the Hammond organ was Ethel Smith, who was known as the "first lady of the Hammond Organ". Fats Waller and Count Basie also started using the Hammond. Organist John Medeski thinks the Hammond became "the poor man's big band", but because of that, it became more economical to book organ trios.
Jimmy Smith became a notable user of the Hammond in the 1950s, particularly in his sessions for the Blue Note label between 1956 and 1963. He eschewed a bass player, and played all the bass parts himself using the pedals, generally using a walking bassline on the pedals in combination with percussive left hand chords. His trio format, composed of organ, guitar and drums, became internationally famous following an appearance at the Newport Jazz Festival in 1957. Medeski says musicians "were inspired when they heard Jimmy Smith's records." "Brother" Jack McDuff switched from piano to Hammond in 1959, and toured regularly throughout the 1960s and 70s. Keith Emerson was inspired to take up the Hammond by hearing McDuff's arrangement of "Rock Candy".
Booker T Jones is cited as being the bridge from rhythm and blues to rock. British organist James Taylor said the Hammond "became popular [in the UK] when people such as Booker T & The MGs and artists on the Stax Records label came over to London and played gigs." Matthew Fisher first encountered the Hammond in 1966 having heard the Small Faces' Ian McLagan playing one. When Fisher asked if he could play it, McLagan told him "They're yelling out for Hammond players; why don't you go out and buy one for yourself?" Fisher went on to play the organ lines on Procol Harum's A Whiter Shade Of Pale, which topped the UK charts in the summer of 1967. Steve Winwood started his musical career with the Spencer Davis Group playing guitar and piano, but he switched to Hammond when he hired one to record "Gimme Some Lovin'".
Gregg Allman became interested in the Hammond after Mike Finnigan had introduced him to Jimmy Smith's music, and started to write material with it. His brother Duane specifically requested he play the instrument when forming the Allman Brothers Band, and he was presented with a brand new B-3 and Leslie 122RV upon joining. Allman recalls the instrument was cumbersome to transport, particularly on flights of stairs, which often required the whole band's assistance. Author Frank Moriarty considers Allman's Hammond playing a vital ingredient of the band's sound.
Deep Purple's Jon Lord became inspired to play the Hammond after hearing Jimmy Smith's "Walk on the Wild Side". He modified his Hammond so it could be played through a Marshall stack to get a growling, overdriven sound, which became known as his trademark and he is strongly identified with it. This organ was later acquired by Joey DeFrancesco. Van der Graaf Generator's Hugh Banton modified his Hammond E-100 extensively with customised electronics, including the ability to put effects such as distortion on one manual but not the other, and rewiring the motor. The modifications created, in Banton's own words, "unimaginable sonic chaos."
The Hammond was a key instrument in progressive rock music. Author Edward Macan thinks this is because of its versatility, allowing both chords and lead lines to be played, and a choice between quiet and clean, and what Emerson described as a "tacky, aggressive, almost distorted, angry sound." Emerson first found commercial success with the Nice, with whom he used and abused an L-100, putting knives in the instrument, setting fire to it, playing it upside down, or riding it across stage in the manner of a horse. He continued to play the instrument in this manner alongside other keyboards in Emerson, Lake and Palmer. Other prominent Hammond organists in progressive rock include the Zombies' and Argent's Rod Argent, Yes's Tony Kaye and Rick Wakeman, Focus's Thijs van Leer, Uriah Heep's Ken Hensley, Pink Floyd's Rick Wright, Kansas's Steve Walsh, and Genesis's Tony Banks. Banks later claimed he only used the Hammond because a piano was impractical to transport to gigs.
Ska and reggae music made frequent use of the Hammond throughout the 1960s and '70s. Junior Marvin started to play the instrument after hearing Booker T & The MGs' "Green Onions", although he complained about its weight. Winston Wright was regarded in the music scene of Jamaica as one of the best organ players, and used the Hammond when performing live with Toots and the Maytals, as well as playing it on sessions with Lee "Scratch" Perry, Jimmy Cliff and Gregory Isaacs. Tyrone Downie, best known as Bob Marley & The Wailers' keyboard player, made prominent use of the Hammond on "No Woman, No Cry", as recorded at the Lyceum Theatre, London, for the album "Live!"
The Hammond organ was perceived as outdated by the late 1970s, particularly in the UK, where it was often used to perform pop songs in social clubs. Punk and New Wave bands tended to prefer second-hand combo organs from the 1960s, or use no keyboards at all. Other groups started taking advantage of cheaper and more portable synthesizers that were starting to come onto the market. The Stranglers' Dave Greenfield was a notable exception to this, and used a Hammond onstage during the band's early career. Andy Thompson, better known for being an aficionado of the Mellotron, stated that "the Hammond never really went away. There are a lot of studios that have had a B-3 or C-3 sitting away in there since the 70s." The instrument underwent a brief renaissance in the 1980s with the mod revival movement. Taylor played the Hammond through the 1980s, first with the Prisoners and later with the James Taylor Quartet. The sound of the Hammond made an appearance in hip-hop music, albeit mostly via samples. A notable exception was the Beastie Boys' "So What'cha Want", where it was mixed into the foreground.
Jazz musicians continued to use Hammond organs into the 21st century. Barbara Dennerlein has received critical acclaim for her performances on the Hammond, particularly her use of the bass pedals, and has modified the instrument to include samplers triggered by the pedals. Joey DeFrancesco embraced the instrument during the 1990s, and later collaborated with Jimmy Smith. He is positive about the future of the Hammond organ, saying "Everybody loves it. It makes you feel good ... I think it's bigger now than ever."
References.
</dl>

</doc>
<doc id="13315" url="http://en.wikipedia.org/wiki?curid=13315" title="Hypoglycemia">
Hypoglycemia

Hypoglycemia (also spelled hypoglycaemia or hypoglycæmia, not to be confused with hyperglycemia) is a medical emergency that involves an abnormally diminished content of glucose in the blood. The term literally means low blood sugar (Gr. "ὑπογλυκαιμία", from "hypo-", "glykys", "haima"). Such blood sugar levels can produce a variety of symptoms and effects, but the principal problems arise from an inadequate supply of glucose to the brain, resulting in impairment of function (neuroglycopenia). Effects can range from mild dysphoria to more serious issues such as seizures, unconsciousness, and (rarely) permanent brain damage or death.
The most common forms of hypoglycemia occur as a complication of treatment of diabetes mellitus with insulin or oral medications. Hypoglycemia is less common in non-diabetic persons, but can occur at any age. Among the causes are excessive insulin produced in the body (hyperinsulinemia), inborn error of metabolism, medications and poisons, alcohol, hormone deficiencies, prolonged starvation, alterations of metabolism associated with infection, and organ failure.
Hypoglycemia is treated by restoring the blood glucose level to normal by the ingestion or administration of dextrose or carbohydrate foods. It is often self-diagnosed and self-medicated orally by the ingestion of balanced meals. In more severe circumstances, it is treated by injection or infusion of glucagon. Recurrent hypoglycemia may be prevented by reversing or removing the underlying cause, by increasing the frequency of meals, with medications like diazoxide, octreotide, or glucocorticoids, or by surgical removal of much of the pancreas.
The level of blood glucose low enough to define hypoglycemia may be different for different people, in different circumstances, and for different purposes, and occasionally has been a matter of controversy. Most healthy adults maintain fasting glucose levels above 4.0 mmol/L (72 mg/dl), and develop symptoms of hypoglycemia when the glucose falls below 4 mmol/L. It can sometimes be difficult to determine whether a person's symptoms are due to hypoglycemia. Criteria referred to as Whipple's triad are used to determine a diagnosis of hypoglycemia:
Hypoglycemia (common usage) is also a term in popular culture and alternative medicine for a common condition characterized by shakiness and altered mood and thinking, but without measured low glucose or risk of severe harm. It is treated by changing eating patterns, i.e. eating regular balanced meals with reasonable portions and avoiding excessive sugar.
Definition.
In those treated for diabetes a diagnosis of hypoglycemia can be made based on the presence of a low blood sugar alone. Otherwise Whipple's triad is required which include symptoms consistent with hypoglycemia, a low blood sugar, and resolution of these symptoms once the blood sugar improves.
Throughout a 24‑hour period blood plasma glucose levels are generally maintained between 4-8 mmol/L (72 and 144 mg/dL).:11 Although 3.3 or 3.9 mmol/L (60 or 70 mg/dL) is commonly cited as the lower limit of normal glucose, symptoms of hypoglycemia usually do not occur until 2.8 to 3.0 mmol/L (50 to 54 mg/dL).
The precise level of glucose considered low enough to define hypoglycemia is dependent on (1) the measurement method, (2) the age of the person, (3) presence or absence of effects, and (4) the purpose of the definition. While there is no disagreement as to the normal range of blood sugar, debate continues as to what degree of hypoglycemia warrants medical evaluation or treatment, or can cause harm.
Glucose concentrations are expressed as milligrams per deciliter (mg/dL or mg/100 mL) in Lebanon, the United States, Japan, Portugal, Spain, France, Belgium, Egypt, Saudi Arabia, Colombia, India and Israel, while millimoles per liter (mmol/L or mM) are the units used in most of the rest of the world. Glucose concentrations expressed as mg/dL can be converted to mmol/L by dividing by 18.0 g/dmol (the molar mass of glucose). For example, a glucose concentration of 90 mg/dL is 5.0 mmol/L or 5.0 mM.
Method of measurement.
Blood glucose levels discussed in this article are venous plasma or serum levels measured by standard, automated glucose oxidase methods used in medical laboratories. For clinical purposes, plasma and serum levels are similar enough to be interchangeable. Arterial plasma or serum levels are slightly higher than venous levels, and capillary levels are typically in between. This difference between arterial and venous levels is small in the fasting state but is amplified and can be greater than 10% in the postprandial state. On the other hand, whole blood glucose levels (e.g., by fingerprick meters) are about 10%-15% lower than venous plasma levels. Furthermore, available fingerstick glucose meters are only warranted to be accurate to within 15% of a simultaneous laboratory value under optimal conditions, and home use in the investigation of hypoglycemia is fraught with misleading low numbers. In other words, a meter glucose reading of 39 mg/dL could be properly obtained from a person whose laboratory serum glucose was 53 mg/dL; even wider variations can occur with "real world" home use.
Two other factors significantly affect glucose measurement: hematocrit and delay after blood drawing. The disparity between venous and whole blood concentrations is greater when the hematocrit is high, as in newborn infants, or adults with polycythemia. High neonatal hematocrits are particularly likely to confound glucose measurement by meter. Second, unless the specimen is drawn into a fluoride tube or processed immediately to separate the serum or plasma from the cells, the measurable glucose will be gradually lowered by "in vitro" metabolism of the glucose at a rate of approximately 7 mg/dL/h, or even more in the presence of leukocytosis. The delay that occurs when blood is drawn at a satellite site and transported to a central laboratory hours later for routine processing is a common cause of mildly low glucose levels in general chemistry panels.
Age differences.
Children's blood sugar levels are often slightly lower than adults'. Overnight fasting glucose levels are below 70 mg/dL (3.9 mM) in 5% of healthy adults, but up to 5% of children can be below 60 mg/dL (3.3 mM) in the morning fasting state. As the duration of fasting is extended, a higher percentage of infants and children will have mildly low plasma glucose levels, usually without symptoms. The normal range of newborn blood sugars continues to be debated. It has been proposed that newborn brains are able to use alternate fuels when glucose levels are low more readily than adults. Experts continue to debate the significance and risk of such levels, though the trend has been to recommend maintenance of glucose levels above 60–70 mg/dL the first day after birth.
Presence or absence of effects.
Research in healthy adults shows that mental efficiency declines slightly but measurably as blood glucose falls below 65 mg/dL (3.6 mM) in many people. Hormonal defense mechanisms (adrenaline and glucagon) are normally activated as it drops below a threshold level (about 55 mg/dL (3.0 mM) for most people), producing the typical hypoglycemic symptoms of shakiness and dysphoria.:1589 Obvious impairment may not occur until the glucose falls below 40 mg/dL (2.2 mM), and many healthy people may occasionally have glucose levels below 65 in the morning without apparent effects. Since the brain effects of hypoglycemia, termed neuroglycopenia, determine whether a given low glucose is a "problem" for that person, most doctors use the term "hypoglycemia" only when a moderately low glucose level is accompanied by symptoms or brain effects.
Determining the presence of both parts of this definition is not always straightforward, as hypoglycemic symptoms and effects are vague and can be produced by other conditions; people with recurrently low glucose levels can lose their threshold symptoms so that severe neuroglycopenic impairment can occur without much warning, and many measurement methods (especially glucose meters) are imprecise at low levels.
Diabetic hypoglycemia represents a special case with respect to the relationship of measured glucose and hypoglycemic symptoms for several reasons. First, although home glucose meter readings are often misleading, the probability that a low reading, whether accompanied by symptoms or not, represents real hypoglycemia is much higher in a person who takes insulin than in someone who does not. Second, because injected insulin cannot be "turned off," diabetic hypoglycemia has a greater chance of progressing to serious impairment if not treated, compared to most other forms of hypoglycemia. Third, because glucose levels are often above normal for long periods of time (hours, days, or months) in persons with diabetes, hypoglycemic symptoms may sometimes occur at higher thresholds than in people whose blood sugar is usually normal. For all of these reasons, higher meter glucose thresholds are often considered "hypoglycemic" in people with diabetes.
Purpose of definition.
For all of the reasons explained in the above paragraphs, deciding whether a blood glucose in the borderline range of 45–75 mg/dL (2.5-4.2 mM) represents clinically problematic hypoglycemia is not always simple. This leads people to use different "cutoff levels" of glucose in different contexts and for different purposes. Because of all of the statistical and measurement variations listed above, the Endocrine Society recommends that a diagnosis of hypoglycemia as problem for an individual person be based on the combination of a low glucose level and evidence of adverse effects.
Signs and symptoms.
Hypoglycemic symptoms and manifestations can be divided into those produced by the counterregulatory hormones (epinephrine/adrenaline and glucagon) triggered by the falling glucose, and the neuroglycopenic effects produced by the reduced brain sugar.
Neuroglycopenic manifestations.
Not all of the above manifestations occur in every case of hypoglycemia. There is no consistent order to the appearance of the symptoms, if symptoms even occur. Specific manifestations may also vary by age, by severity of the hypoglycemia and the speed of the decline. In young children, vomiting can sometimes accompany morning hypoglycemia with ketosis. In older children and adults, moderately severe hypoglycemia can resemble mania, mental illness, drug intoxication, or drunkenness. In the elderly, hypoglycemia can produce focal stroke-like effects or a hard-to-define malaise. The symptoms of a single person may be similar from episode to episode, but are not necessarily so and may be influenced by the speed at which glucose levels are dropping, as well as previous incidents.
In newborns, hypoglycemia can produce irritability, jitters, myoclonic jerks, cyanosis, respiratory distress, apneic episodes, sweating, hypothermia, somnolence, hypotonia, refusal to feed, and seizures or "spells." Hypoglycemia can resemble asphyxia, hypocalcemia, sepsis, or heart failure.
In both young and old patients, the brain may habituate to low glucose levels, with a reduction of noticeable symptoms despite neuroglycopenic impairment. In insulin-dependent diabetic patients this phenomenon is termed "hypoglycemia unawareness" and is a significant clinical problem when improved glycemic control is attempted. Another aspect of this phenomenon occurs in type I glycogenosis, when chronic hypoglycemia before diagnosis may be better tolerated than acute hypoglycemia after treatment is underway.
Hypoglycemic symptoms can also occur when one is sleeping. Examples of symptoms during sleep can include damp bed sheets or clothes from perspiration. Having nightmares or the act of crying out can be a sign of hypoglycemia. Once the individual is awake they may feel tired, irritable, or confused and these may be signs of hypoglycemia as well.
In nearly all cases, hypoglycemia that is severe enough to cause seizures or unconsciousness can be reversed without obvious harm to the brain. Cases of death or permanent neurological damage occurring with a single episode have usually involved prolonged, untreated unconsciousness, interference with breathing, severe concurrent disease, or some other type of vulnerability. Nevertheless, brain damage or death has occasionally resulted from severe hypoglycemia.
Long-term effects.
Significant hypoglycemia appears to increase the risk of cardiovascular disease.
Causes.
The circumstances of hypoglycemia provide most of the clues to diagnosis. Circumstances include the age of the patient, time of day, time since last meal, previous episodes, nutritional status, physical and mental development, drugs or toxins (especially insulin or other diabetes drugs), diseases of other organ systems, family history, and response to treatment. When hypoglycemia occurs repeatedly, a record or "diary" of the spells over several months, noting the circumstances of each spell (time of day, relation to last meal, nature of last meal, response to carbohydrate, and so forth) may be useful in recognizing the nature and cause of the hypoglycemia.
An especially important aspect is whether the patient is seriously ill with another problem. Severe disease of nearly all major organ systems can cause hypoglycemia as a secondary problem. Hospitalized patients, especially in intensive care units or those prevented from eating, can suffer hypoglycemia from a variety of circumstances related to the care of their primary disease. Hypoglycemia in these circumstances is often multifactorial or even iatrogenic. Once identified, these types of hypoglycemia are readily reversed and prevented, and the underlying disease becomes the primary problem.
It may take longer to recover from severe hypoglycemia with unconsciousness or seizure even after restoration of normal blood glucose. When a person has not been unconscious, failure of carbohydrate to reverse the symptoms in 10–15 minutes increases the likelihood that hypoglycemia was not the cause of the symptoms. When severe hypoglycemia has persisted in a hospitalized patient, the amount of glucose required to maintain satisfactory blood glucose levels becomes an important clue to the underlying etiology. Glucose requirements above 10 mg/kg/minute in infants, or 6 mg/kg/minute in children and adults are strong evidence for hyperinsulinism. In this context this is referred to as the "glucose infusion rate" (GIR). Finally, the blood glucose response to glucagon given when the glucose is low can also help distinguish among various types of hypoglycemia. A rise of blood glucose by more than 30 mg/dl (1.70 mmol/l) suggests insulin excess as the probable cause of the hypoglycemia.
Part of the value of the critical sample may simply be the proof that the symptoms are indeed due to hypoglycemia. More often, measurement of certain hormones and metabolites at the time of hypoglycemia indicates which organs and body systems are responding appropriately and which are functioning abnormally. For example, when the blood glucose is low, hormones which raise the glucose should be rising and insulin secretion should be completely suppressed.
The following is a brief list of hormones and metabolites which may be measured in a critical sample. Not all tests are checked on every patient. A "basic version" would include insulin, cortisol, and electrolytes, with C-peptide and drug screen for adults and growth hormone in children. The value of additional specific tests depends on the most likely diagnoses for an individual patient, based on the circumstances described above. Many of these levels change within minutes, especially if glucose is given, and there is no value in measuring them after the hypoglycemia is reversed. Others, especially those lower in the list, remain abnormal even after hypoglycemia is reversed, and can be usefully measured even if a critical specimen is missed.
Pathophysiology.
Like most animal tissues, brain metabolism depends primarily on glucose for fuel in most circumstances. A limited amount of glucose can be derived from glycogen stored in astrocytes, but it is consumed within minutes. For most practical purposes, the brain is dependent on a continual supply of glucose diffusing from the blood into the interstitial tissue within the central nervous system and into the neurons themselves.
Therefore, if the amount of glucose supplied by the blood falls, the brain is one of the first organs affected. In most people, subtle reduction of mental efficiency can be observed when the glucose falls below 65 mg/dl (3.6 mM). Impairment of action and judgment usually becomes obvious below 40 mg/dl (2.2 mM). Seizures may occur as the glucose falls further. As blood glucose levels fall below 10 mg/dl (0.55 mM), most neurons become electrically silent and nonfunctional, resulting in coma. These brain effects are collectively referred to as neuroglycopenia.
The importance of an adequate supply of glucose to the brain is apparent from the number of nervous, hormonal and metabolic responses to a falling glucose level. Most of these are defensive or adaptive, tending to raise the blood sugar via glycogenolysis and gluconeogenesis or provide alternative fuels. If the blood sugar level falls too low the liver converts a storage of glycogen into glucose and releases it into the bloodstream, to prevent the person going into a diabetic coma, for a short period of time.
Brief or mild hypoglycemia produces no lasting effects on the brain, though it can temporarily alter brain responses to additional hypoglycemia. Prolonged, severe hypoglycemia can produce lasting damage of a wide range. This can include impairment of cognitive function, motor control, or even consciousness. The likelihood of permanent brain damage from any given instance of severe hypoglycemia is difficult to estimate, and depends on a multitude of factors such as age, recent blood and brain glucose experience, concurrent problems such as hypoxia, and availability of alternative fuels. It has been frequently found that those Type 1 diabetics found "dead in bed" in the morning after suspected severe hypoglycemia had some underlying coronary pathology that led to an induced fatal heart attack. Recently, several of these individuals found "dead in bed" were wearing Continuous Glucose Monitors, which provided a history of glucose levels prior to the fatal event. It has been found in several cases, that the fatal event was preceded by at least two hours of blood glucose levels under 40 mg/dl, possibly lower as the continuous glucose monitors are not accurate at levels below 40 mg/dl. The individuals failed to respond to the audible alarms produced by the continuous glucose monitor which may have been "alarming" for many hours prior to the fatal event. The vast majority of symptomatic hypoglycemic episodes result in no detectable permanent harm.
Diagnosis.
When suspected hypoglycemia recurs and a critical specimen has not been obtained, the diagnostic evaluation may take several paths. However good nutrition and prompt intake is essential.
When general health is good, the symptoms are not severe, and the person can fast normally through the night, experimentation with diet (extra snacks with fat or protein, reduced sugar) may be enough to solve the problem. If it is uncertain whether "spells" are indeed due to hypoglycemia, some physicians will recommend use of a home glucose meter to test at the time of the spells to confirm that glucoses are low. This approach may be most useful when spells are fairly frequent or the patient is confident that he or she can provoke a spell. The principal drawback of this approach is the high rate of false positive or equivocal levels due to the imprecision of the currently available meters: both physician and patient need an accurate understanding of what a meter can and cannot do to avoid frustrating and inconclusive results.
In cases of recurrent hypoglycemia with severe symptoms, the best method of excluding dangerous conditions is often a "diagnostic fast". This is usually conducted in the hospital, and the duration depends on the age of the patient and response to the fast. A healthy adult can usually maintain a glucose level above 50 mg/dl (2.8 mM) for 72 hours, a child for 36 hours, and an infant for 24 hours. The purpose of the fast is to determine whether the person can maintain his or her blood glucose as long as normal, and can respond to fasting with the appropriate metabolic changes. At the end of the fast the insulin should be nearly undetectable and ketosis should be fully established. The patient's blood glucose levels are monitored and a critical specimen is obtained if the glucose falls. Despite its unpleasantness and expense, a diagnostic fast may be the only effective way to confirm or refute a number of serious forms of hypoglycemia, especially those involving excessive insulin.
A traditional method for investigating suspected hypoglycemia is the oral glucose tolerance test, especially when prolonged to 3, 4, or 5 hours. Although quite popular in the United States in the 1960s, repeated research studies have demonstrated that many healthy people will have glucose levels below 70 or 60 during a prolonged test, and that many types of significant hypoglycemia may go undetected with it. This combination of poor sensitivity and specificity has resulted in its abandonment for this purpose by physicians experienced in disorders of glucose metabolism.
Prescription misfill can also be a cause of severe unexplained hypoglycemia; for example, sulfonylureas accidentally given to non-diabetics can dangerously lower blood sugar. Symptoms will coincide with a recent prescription refill. A 1 mg estrogen tablet closely resembles the 4 mg glimeperide pill, making the two easy to confuse for the pharmacist and the patient.
It can also be mistaken for alcohol intoxication.
Prevention.
The most effective means of preventing further episodes of hypoglycemia depends on the cause.
The risk of further episodes of diabetic hypoglycemia can often (but not always) be reduced by lowering the dose of insulin or other medications, or by more meticulous attention to blood sugar balance during unusual hours, higher levels of exercise, or decreasing alcohol intake.
Many of the inborn errors of metabolism require avoidance or shortening of fasting intervals, or extra carbohydrates. For the more severe disorders, such as type 1 glycogen storage disease, this may be supplied in the form of cornstarch every few hours or by continuous gastric infusion.
Several treatments are used for hyperinsulinemic hypoglycemia, depending on the exact form and severity. Some forms of congenital hyperinsulinism respond to diazoxide or octreotide. Surgical removal of the overactive part of the pancreas is curative with minimal risk when hyperinsulinism is focal or due to a benign insulin-producing tumor of the pancreas. When congenital hyperinsulinism is diffuse and refractory to medications, near-total pancreatectomy may be the treatment of last resort, but in this condition is less consistently effective and fraught with more complications.
Hypoglycemia due to hormone deficiencies such as hypopituitarism or adrenal insufficiency usually ceases when the appropriate hormone is replaced.
Hypoglycemia due to dumping syndrome and other post-surgical conditions is best dealt with by altering diet. Including fat and protein with carbohydrates may slow digestion and reduce early insulin secretion. Some forms of this respond to treatment with a glucosidase inhibitor, which slows starch digestion.
Reactive hypoglycemia with demonstrably low blood glucose levels is most often a predictable nuisance which can be avoided by consuming fat and protein with carbohydrates, by adding morning or afternoon snacks, and reducing alcohol intake.
Idiopathic postprandial syndrome without demonstrably low glucose levels at the time of symptoms can be more of a management challenge. Many people find improvement by changing eating patterns (smaller meals, avoiding excessive sugar, mixed meals rather than carbohydrates by themselves), reducing intake of stimulants such as caffeine, or by making lifestyle changes to reduce stress. See the following section of this article.
Treatment.
Treatment of some forms of hypoglycemia, such as in diabetes, involves immediately raising the blood sugar to normal through the ingestion of carbohydrates, determining the cause, and taking measures to hopefully prevent future episodes. However, this treatment is not optimal in other forms such as reactive hypoglycemia, where rapid carbohydrate ingestion may lead to a further hypoglycemic episode.
Blood glucose can be raised to normal within minutes by taking (or receiving) 10-20 grams of carbohydrate. It can be taken as food or drink if the person is conscious and able to swallow. This amount of carbohydrate is contained in about 3–4 ounces (100–120 ml) of orange, apple, or grape juice although fruit juices contain a higher proportion of fructose which is more slowly metabolized than pure dextrose, alternatively, about 4–5 ounces (120-150 ml) of regular (non-diet) soda may also work, as will about one slice of bread, about 4 crackers, or about 1 serving of most starchy foods. Starch is quickly digested to glucose (unless the person is taking acarbose), but adding fat or protein retards digestion. Symptoms should begin to improve within 5 minutes, though full recovery may take 10–20 minutes. Overfeeding does not speed recovery and if the person has diabetes will simply produce hyperglycemia afterwards. A mnemonic used by the American Diabetes Association and others is the "rule of 15" – consuming 15 grams of carbohydrate followed by a 15-minute wait, repeated if glucose remains low (variable by individual, sometimes 70 mg/dl).
If a person is suffering such severe effects of hypoglycemia that they cannot (due to combativeness) or should not (due to seizures or unconsciousness) be given anything by mouth, medical personnel such as paramedics, or in-hospital personnel can establish IV access and give intravenous dextrose, concentrations varying depending on age (infants are given 2 ml/kg dextrose 10%, children are given dextrose 25%, and adults are given dextrose 50%). Care must be taken in giving these solutions because they can cause skin necrosis if the IV is infiltrated, sclerosis of veins, and many other fluid and electrolyte disturbances if administered incorrectly. If IV access cannot be established, the patient can be given 1 to 2 milligrams of glucagon in an intramuscular injection. More treatment information can be found in the article diabetic hypoglycemia. If a person is suffering less severe effects, and is conscious with the ability to swallow, medical personal such as EMT-B's may administer gelatinous oral glucose.
One situation where starch may be less effective than glucose or sucrose is when a person is taking acarbose. Since acarbose and other alpha-glucosidase inhibitors prevents starch and other sugars from being broken down into monosaccharides that can be absorbed by the body, patients taking these medications should consume monosaccharide-containing foods such as glucose tablets, honey, or juice to reverse hypoglycemia.

</doc>
<doc id="13316" url="http://en.wikipedia.org/wiki?curid=13316" title="List of historical anniversaries">
List of historical anniversaries

Condensed list of historical anniversaries.
External links and resources.
Types
Topics
Places, people and times
Indices

</doc>
<doc id="13370" url="http://en.wikipedia.org/wiki?curid=13370" title="Helsingborg Municipality">
Helsingborg Municipality

Helsingborg Municipality ("Helsingborgs kommun") is a municipality in Skåne County in Sweden. Its seat is located in the city of Helsingborg, which is Sweden's eighth largest city. The municipality had a population of 132,011 on January 1, 2013, and the population is increasing with roughly 1500 people annually.
Between 1912 and 1971 the name of the town was officially spelled Hälsingborg (rather like the region of Hälsingland but unlike neighbouring Danish Helsingør and the Finnish capital Helsingfors (Helsinki)). The spelling was changed back to the older version when the present municipality was created in 1971 through the amalgamation of the "Town of Hälsingborg" with four surrounding rural municipalities. Since the 1990s the municipality again styles itself "Helsingborgs stad" ("Town of Helsingborg"). This usage is only nominal and has no effect on the status of the municipality.
Localities.
There are 15 urban areas (also called a Tätort or locality) in Helsingborg Municipality. In the table they are listed according to the size of the population as of December 31, 2010. The municipal seat is in bold characters.
1) Rydebäck is bimunicipal locality as a minor part of it (with about 40 inhabitants) is located in Landskrona Municipality.
2) Population for Helsingborg tätort-locality 2009
International relations.
Twin towns — Sister cities.
Helsingborg is twinned with:

</doc>
<doc id="13371" url="http://en.wikipedia.org/wiki?curid=13371" title="Henry Ford">
Henry Ford

Henry Ford (July 30, 1863 – April 7, 1947) was an American industrialist, the founder of the Ford Motor Company, and sponsor of the development of the assembly line technique of mass production.
Although Ford did not invent the automobile or the assembly line, he developed and manufactured the first automobile that many middle class Americans could afford. In doing so, Ford converted the automobile from an expensive curiosity into a practical conveyance that would profoundly impact the landscape of the twentieth century. His introduction of the Model T automobile revolutionized transportation and American industry. As owner of the Ford Motor Company, he became one of the richest and best-known people in the world. He is credited with "Fordism": mass production of inexpensive goods coupled with high wages for workers. Ford had a global vision, with consumerism as the key to peace. His intense commitment to systematically lowering costs resulted in many technical and business innovations, including a franchise system that put dealerships throughout most of North America and in major cities on six continents. Ford left most of his vast wealth to the Ford Foundation and arranged for his family to control the company permanently.
Ford was also widely known for his pacifism during the first years of World War I, and also for being the publisher of antisemitic texts such as the book "The International Jew".
Early life.
Henry Ford was born July 30, 1863, on a farm in Greenfield Township, Michigan. His father, William Ford (1826–1905), was born in County Cork, Ireland, to a family that was originally from Somerset, England, His mother, Mary Ford (née Litogot) (1839–1876), was born in Michigan as the youngest child of Belgian immigrants; her parents died when she was a child and she was adopted by neighbors, the O'Herns. Henry Ford's siblings were Margaret Ford (1867–1938); Jane Ford (c. 1868–1945); William Ford (1871–1917) and Robert Ford (1873–1934).
His father gave him a pocket watch in his early teens. At 15, Ford dismantled and reassembled the timepieces of friends and neighbors dozens of times, gaining the reputation of a watch repairman. At twenty, Ford walked four miles to their Episcopal church every Sunday.
Ford was devastated when his mother died in 1876. His father expected him to eventually take over the family farm, but he despised farm work. He later wrote, "I never had any particular love for the farm—it was the mother on the farm I loved."
In 1879, Ford left home to work as an apprentice machinist in Detroit, first with James F. Flower & Bros., and later with the Detroit Dry Dock Co. In 1882, he returned to Dearborn to work on the family farm, where he became adept at operating the Westinghouse portable steam engine. He was later hired by Westinghouse to service their steam engines. During this period Ford also studied bookkeeping at Goldsmith, Bryant & Stratton Business College in Detroit.
Marriage and family.
Ford married Clara Ala Bryant (1866–1950) in 1888 and supported himself by farming and running a sawmill. They had one child: Edsel Ford (1893–1943).
Career.
In 1891, Ford became an engineer with the Edison Illuminating Company. After his promotion to Chief Engineer in 1893, he had enough time and money to devote attention to his personal experiments on gasoline engines. These experiments culminated in 1896 with the completion of a self-propelled vehicle which he named the Ford Quadricycle. He test-drove it on June 4. After various test drives, Ford brainstormed ways to improve the Quadricycle.
Also in 1896, Ford attended a meeting of Edison executives, where he was introduced to Thomas Edison. Edison approved of Ford's automobile experimentation. Encouraged by Edison, Ford designed and built a second vehicle, completing it in 1898. Backed by the capital of Detroit lumber baron William H. Murphy, Ford resigned from the Edison Company and founded the Detroit Automobile Company on August 5, 1899. However, the automobiles produced were of a lower quality and higher price than Ford wanted. Ultimately, the company was not successful and was dissolved in January 1901.
With the help of C. Harold Wills, Ford designed, built, and successfully raced a 26-horsepower automobile in October 1901. With this success, Murphy and other stockholders in the Detroit Automobile Company formed the Henry Ford Company on November 30, 1901, with Ford as chief engineer. In 1902, Murphy brought in Henry M. Leland as a consultant; Ford, in response, left the company bearing his name. With Ford gone, Murphy renamed the company the Cadillac Automobile Company.
Teaming up with former racing cyclist Tom Cooper, Ford also produced the 80+ horsepower racer "999" which Barney Oldfield was to drive to victory in a race in October 1902. Ford received the backing of an old acquaintance, Alexander Y. Malcomson, a Detroit-area coal dealer. They formed a partnership, "Ford & Malcomson, Ltd." to manufacture automobiles. Ford went to work designing an inexpensive automobile, and the duo leased a factory and contracted with a machine shop owned by John and Horace E. Dodge to supply over $160,000 in parts. Sales were slow, and a crisis arose when the Dodge brothers demanded payment for their first shipment.
Ford Motor Company.
In response, Malcomson brought in another group of investors and convinced the Dodge Brothers to accept a portion of the new company. Ford & Malcomson was reincorporated as the Ford Motor Company on June 16, 1903, with $28,000 capital. The original investors included Ford and Malcomson, the Dodge brothers, Malcomson's uncle John S. Gray, Malcolmson's secretary James Couzens, and two of Malcomson's lawyers, John W. Anderson and Horace Rackham. Ford then demonstrated a newly designed car on the ice of Lake St. Clair, driving 1 mi in 39.4 seconds and setting a new land speed record at 91.3 mph. Convinced by this success, the race driver Barney Oldfield, who named this new Ford model "999" in honor of the fastest locomotive of the day, took the car around the country, making the Ford brand known throughout the United States. Ford also was one of the early backers of the Indianapolis 500.
Model T.
The Model T was introduced on October 1, 1908. It had the steering wheel on the left, which every other company soon copied. The entire engine and transmission were enclosed; the four cylinders were cast in a solid block; the suspension used two semi-elliptic springs. The car was very simple to drive, and easy and cheap to repair. It was so cheap at $825 in 1908 ($ today) (the price fell every year) that by the 1920s, a majority of American drivers had learned to drive on the Model T.
Ford created a huge publicity machine in Detroit to ensure every newspaper carried stories and ads about the new product. Ford's network of local dealers made the car ubiquitous in almost every city in North America. As independent dealers, the franchises grew rich and publicized not just the Ford but the concept of automobiling; local motor clubs sprang up to help new drivers and to encourage exploring the countryside. Ford was always eager to sell to farmers, who looked on the vehicle as a commercial device to help their business. Sales skyrocketed—several years posted 100% gains on the previous year. Always on the hunt for more efficiency and lower costs, in 1913 Ford introduced the moving assembly belts into his plants, which enabled an enormous increase in production. Although Ford is often credited with the idea, contemporary sources indicate that the concept and its development came from employees Clarence Avery, Peter E. Martin, Charles E. Sorensen, and C. Harold Wills. (See Piquette Plant)
Sales passed 250,000 in 1914. By 1916, as the price dropped to $360 for the basic touring car, sales reached 472,000. (Using the consumer price index, this price was equivalent to $7,020 in 2008 dollars.)
By 1918, half of all cars in America were Model T's. All new cars were black; as Ford wrote in his autobiography, "Any customer can have a car painted any color that he wants so long as it is black". Until the development of the assembly line, which mandated black because of its quicker drying time, Model Ts were available in other colors, including red. The design was fervently promoted and defended by Ford, and production continued as late as 1927; the final total production was 15,007,034. This record stood for the next 45 years. This record was achieved in 19 years from the introduction of the first Model T (1908).
President Woodrow Wilson asked Ford to run as a Democrat for the United States Senate from Michigan in 1918. Although the nation was at war, Ford ran as a peace candidate and a strong supporter of the proposed League of Nations. Ford was defeated in a close election by the Republican candidate, Truman Newberry, a former United States Secretary of the Navy.
Henry Ford turned the presidency of Ford Motor Company over to his son Edsel Ford in December 1918. Henry retained final decision authority and sometimes reversed his son. Henry started another company, Henry Ford and Son, and made a show of taking himself and his best employees to the new company; the goal was to scare the remaining holdout stockholders of the Ford Motor Company to sell their stakes to him before they lost most of their value. (He was determined to have full control over strategic decisions.) The ruse worked, and Henry and Edsel purchased all remaining stock from the other investors, thus giving the family sole ownership of the company.
By the mid-1920s, sales of the Model T began to decline due to rising competition. Other auto makers offered payment plans through which consumers could buy their cars, which usually included more modern mechanical features and styling not available with the Model T. Despite urgings from Edsel, Henry refused to incorporate new features into the Model T or to form a customer credit plan.
Model A and Ford's later career.
By 1926, flagging sales of the Model T finally convinced Henry to make a new model. He pursued the project with a great deal of technical expertise in design of the engine, chassis, and other mechanical necessities, while leaving the body design to his son. Edsel also managed to prevail over his father's initial objections in the inclusion of a sliding-shift transmission.
The result was the successful Ford Model A, introduced in December 1927 and produced through 1931, with a total output of more than 4 million. Subsequently, the Ford company adopted an annual model change system similar to that recently pioneered by its competitor General Motors (and still in use by automakers today). Not until the 1930s did Ford overcome his objection to finance companies, and the Ford-owned Universal Credit Corporation became a major car-financing operation.
Ford did not believe in accountants; he amassed one of the world's largest fortunes without ever having his company audited under his administration.
Labor philosophy.
The five-dollar workday.
Ford was a pioneer of "welfare capitalism", designed to improve the lot of his workers and especially to reduce the heavy turnover that had many departments hiring 300 men per year to fill 100 slots. Efficiency meant hiring and keeping the best workers.
Ford astonished the world in 1914 by offering a $5 per day wage ($ today), which more than doubled the rate of most of his workers. A Cleveland, Ohio newspaper editorialized that the announcement "shot like a blinding rocket through the dark clouds of the present industrial depression." The move proved extremely profitable; instead of constant turnover of employees, the best mechanics in Detroit flocked to Ford, bringing their human capital and expertise, raising productivity, and lowering training costs. Ford announced his $5-per-day program on January 5, 1914, raising the minimum daily pay from $2.34 to $5 for qualifying workers. It also set a new, reduced workweek, although the details vary in different accounts. Ford and Crowther in 1922 described it as six 8-hour days, giving a 48-hour week, while in 1926 they described it as five 8-hour days, giving a 40-hour week. (Apparently the program started with Saturday being a workday and sometime later it was changed to a day off.)
Detroit was already a high-wage city, but competitors were forced to raise wages or lose their best workers. Ford's policy proved, however, that paying people more would enable Ford workers to afford the cars they were producing and be good for the local economy. He viewed the increased wages as profit-sharing linked with rewarding those who were most productive and of good character. It may have been Couzens who convinced Ford to adopt the $5-day.
The profit-sharing was offered to employees who had worked at the company for six months or more, and, importantly, conducted their lives in a manner of which Ford's "Social Department" approved. They frowned on heavy drinking, gambling, and (what today are called) deadbeat dads. The Social Department used 50 investigators, plus support staff, to maintain employee standards; a large percentage of workers were able to qualify for this "profit-sharing."
Ford's incursion into his employees' private lives was highly controversial, and he soon backed off from the most intrusive aspects. By the time he wrote his 1922 memoir, he spoke of the Social Department and of the private conditions for profit-sharing in the past tense, and admitted that "paternalism has no place in industry. Welfare work that consists in prying into employees' private concerns is out of date. Men need counsel and men need help, often special help; and all this ought to be rendered for decency's sake. But the broad workable plan of investment and participation will do more to solidify industry and strengthen organization than will any social work on the outside. Without changing the principle we have changed the method of payment."
Labor unions.
Ford was adamantly against labor unions. He explained his views on unions in Chapter 18 of "My Life and Work". He thought they were too heavily influenced by some leaders who, despite their ostensible good motives, would end up doing more harm than good for workers. Most wanted to restrict productivity as a means to foster employment, but Ford saw this as self-defeating because, in his view, productivity was necessary for any economic prosperity to exist.
He believed that productivity gains that obviated certain jobs would nevertheless stimulate the larger economy and thus grow new jobs elsewhere, whether within the same corporation or in others. Ford also believed that union leaders had a perverse incentive to foment perpetual socio-economic crisis as a way to maintain their own power. Meanwhile, he believed that smart managers had an incentive to do right by their workers, because doing so would maximize their own profits. Ford did acknowledge, however, that many managers were basically too bad at managing to understand this fact. But Ford believed that eventually, if good managers such as he could fend off the attacks of misguided people from both left and right (i.e., both socialists and bad-manager reactionaries), the good managers would create a socio-economic system wherein neither bad management nor bad unions could find enough support to continue existing.
To forestall union activity, Ford promoted Harry Bennett, a former Navy boxer, to head the Service Department. Bennett employed various intimidation tactics to squash union organizing. The most famous incident, on May 26, 1937, involved Bennett's security men beating with clubs UAW representatives, including Walter Reuther. While Bennett's men were beating the UAW representatives, the supervising police chief on the scene was Carl Brooks, an alumnus of Bennett’s Service Department, and [Brooks] "did not give orders to intervene." The incident became known as The Battle of the Overpass.
In the late 1930s and early 1940s, Edsel—who was president of the company—thought Ford had to come to some sort of collective bargaining agreement with the unions because the violence, work disruptions, and bitter stalemates could not go on forever. But Henry, who still had the final veto in the company on a "de facto" basis even if not an official one, refused to cooperate. For several years, he kept Bennett in charge of talking to the unions that were trying to organize the Ford Motor Company. Sorensen's memoir makes clear that Henry's purpose in putting Bennett in charge was to make sure no agreements were ever reached.
The Ford Motor Company was the last Detroit automaker to recognize the United Auto Workers union (UAW). A sit-down strike by the UAW union in April 1941 closed the River Rouge Plant. Sorensen recounted that a distraught Henry Ford was very close to following through with a threat to break up the company rather than cooperate, but his wife Clara told him she would leave him if he destroyed the family business. In her view, it would not be worth the chaos it would create. Henry complied with his wife's ultimatum, and even agreed with her in retrospect. Overnight, the Ford Motor Company went from the most stubborn holdout among automakers to the one with the most favorable UAW contract terms. The contract was signed in June 1941.
Ford Airplane Company.
Ford, like other automobile companies, entered the aviation business during World War I, building Liberty engines. After the war, it returned to auto manufacturing until 1925, when Ford acquired the Stout Metal Airplane Company.
Ford's most successful aircraft was the Ford 4AT Trimotor, often called the "Tin Goose" because of its corrugated metal construction. It used a new alloy called Alclad that combined the corrosion resistance of aluminum with the strength of duralumin. The plane was similar to Fokker's V.VII-3m, and some say that Ford's engineers surreptitiously measured the Fokker plane and then copied it. The Trimotor first flew on June 11, 1926, and was the first successful U.S. passenger airliner, accommodating about 12 passengers in a rather uncomfortable fashion. Several variants were also used by the U.S. Army. Ford has been honored by the Smithsonian Institution for changing the aviation industry. 199 Trimotors were built before it was discontinued in 1933, when the Ford Airplane Division shut down because of poor sales during the Great Depression.
Peace and war.
World War I era.
Ford opposed war, which he viewed as a terrible waste. Ford became highly critical of those who he felt financed war, and he tried to stop them. In 1915, the pacifist Rosika Schwimmer gained favor with Ford, who agreed to fund a Peace Ship to Europe, where World War I was raging. He and about 170 other prominent peace leaders traveled there. Ford's Episcopalian pastor, Reverend Samuel S. Marquis, accompanied him on the mission. Marquis headed Ford's Sociology Department from 1913 to 1921. Ford talked to President Wilson about the mission but had no government support. His group went to neutral Sweden and the Netherlands to meet with peace activists. A target of much ridicule, Ford left the ship as soon as it reached Sweden.
Ford plants in the United Kingdom produced tractors to increase the British food supply, as well as trucks and aircraft engines. When the U.S. entered the war in 1917 the company became a major supplier of weapons, especially the Liberty engine for airplanes, and anti-submarine boats.
In 1918, with the war on and the League of Nations a growing issue in global politics, President Woodrow Wilson, a Democrat, encouraged Ford to run for a Michigan seat in the U.S. Senate. Wilson believed that Ford could tip the scales in Congress in favor of Wilson's proposed League. "You are the only man in Michigan who can be elected and help bring about the peace you so desire," the president wrote Ford. Ford wrote back: "If they want to elect me let them do so, but I won't make a penny's investment." Ford did run, however, and came within 4,500 votes of winning, out of more than 400,000 cast statewide. Ford remained a staunch Wilsonian and supporter of the League. When Wilson made a major speaking tour in the summer of 1919 to promote the League, Ford helped fund the attendant publicity.
The coming of World War II and Ford's mental collapse.
Ford had opposed America's entry into World War II and continued to believe that international business could generate the prosperity that would head off wars. Ford "insisted that war was the product of greedy financiers who sought profit in human destruction"; in 1939 he went so far as to claim that the torpedoing of U.S. merchant ships by German submarines was the result of conspiratorial activities undertaken by financier war-makers. The financiers to whom he was referring was Ford's code for Jews; he had also accused Jews of fomenting the First World War (see the section on his anti-Semitism below). In the run-up to World War II and when the war erupted in 1939, he reported that he did not want to trade with belligerents. Like many other businessmen of the Great Depression era, he never liked or entirely trusted the Franklin Roosevelt Administration, and thought Roosevelt was inching the U.S. closer to war. However, Ford continued to do business with Nazi Germany, including the manufacture of war materiel. Beginning in 1940, with the requisitioning of between 100 and 200 French POWs to work as slave laborers, "Ford-Werke" contravened Article 31 of the 1929 Geneva Convention. At that time, which was before the U.S. entered the war and still had full diplomatic relations with Nazi Germany, "Ford-Werke" was under the control of the Ford Motor Company. The number of slave laborers grew as the war expanded although Wallace made it clear that companies in Germany were not required by the Nazi authorities to use slave laborers.
When Rolls-Royce sought a U.S. manufacturer as an alternative source for the Merlin engine (as fitted to Spitfire and Hurricane fighters), Ford first agreed to do so and then reneged. He "lined up behind the war effort" when the U.S. entered in late 1941. His support of the American war effort, however, was problematic.
Once the U.S. entered the war, Ford directed the Ford Motor Company to construct a vast new purpose-built factory at Willow Run near Detroit, Michigan. Ford broke ground on Willow Run in the spring of 1941, and the first B-24 came off the line in October 1942. At 3,500,000 ft2, it was the largest assembly line in the world at the time. At its peak in 1944, the Willow Run plant produced 650 B-24s per month, and by 1945 Ford was completing each B-24 in eighteen hours, with one rolling off the assembly line every 58 minutes. Ford produced 9,000 B-24s at Willow Run, half of the 18,000 total B-24s produced during the war.
When Edsel Ford died prematurely in 1943, Henry Ford nominally resumed control of the company, but a series of strokes in the late 1930s had left him increasingly debilitated, and his mental ability was fading. Ford was increasingly sidelined, and others made decisions in his name. The company was in fact controlled by a handful of senior executives led by Charles Sorensen, an important engineer and production executive at Ford; and Harry Bennett, the chief of Ford's Service Unit, Ford's paramilitary force that spied on, and enforced discipline upon, Ford employees. Ford grew jealous of the publicity Sorensen received and forced Sorensen out in 1944. Ford's incompetence led to discussions in Washington about how to restore the company, whether by wartime government fiat, or by instigating some sort of coup among executives and directors. Nothing happened until 1945 when, with bankruptcy a serious risk, Edsel's widow led an ouster and installed her son, Henry Ford II, as president. The young man took full control, and forced out Harry Bennett in a purge of the old guard in 1947.
"The Dearborn Independent" and anti-Semitism.
In the early 1920s, Ford sponsored a weekly newspaper that published strongly anti-Semitic views. At the same time, Ford had a reputation as one of the few major corporations actively hiring black workers, and was not accused of discrimination against Jewish workers or suppliers. He also hired women and handicapped men at a time when doing so was uncommon.
In 1918, Ford's closest aide and private secretary, Ernest G. Liebold, purchased an obscure weekly newspaper for Ford, "The Dearborn Independent". The "Independent" ran for eight years, from 1920 until 1927, with Liebold as editor. Every Ford franchise nation-wide had to carry the paper and distribute it to its customers.
The newspaper published "The Protocols of the Elders of Zion", which was discredited by "The Times" of London as a forgery during the "Independents publishing run. The American Jewish Historical Society described the ideas presented in the magazine as "anti-immigrant, anti-labor, anti-liquor, and anti-Semitic." In February 1921, the "New York World" published an interview with Ford, in which he said: "The only statement I care to make about the Protocols is that they fit in with what is going on." During this period, Ford emerged as "a respected spokesman for right-wing extremism and religious prejudice," reaching around 700,000 readers through his newspaper. The 2010 documentary film ' (written by Pulitzer Prize winner Ira Berkow) states that Ford wrote on May 22, 1920: "If fans wish to know the trouble with American baseball they have it in three words—too much Jew."
In Germany, Ford's anti-Semitic articles from "The Dearborn Independent" were issued in four volumes, cumulatively titled "The International Jew, the World's Foremost Problem" published by Theodor Fritsch, founder of several anti-Semitic parties and a member of the Reichstag. In a letter written in 1924, Heinrich Himmler described Ford as "one of our most valuable, important, and witty fighters." Ford is the only American mentioned in "Mein Kampf". Adolf Hitler wrote, "only a single great man, Ford, [who], to [the Jews'] fury, still maintains full independence...[from] the controlling masters of the producers in a nation of one hundred and twenty millions." Speaking in 1931 to a "Detroit News" reporter, Hitler said he regarded Ford as his "inspiration," explaining his reason for keeping Ford's life-size portrait next to his desk. Steven Watts wrote that Hitler "revered" Ford, proclaiming that "I shall do my best to put his theories into practice in Germany," and modeling the Volkswagen, the people's car, on the Model T.
On February 1, 1924, Ford received Kurt Ludecke, a representative of Hitler, at home. Ludecke was introduced to Ford by Siegfried Wagner (son of the composer Richard Wagner) and his wife Winifred, both Nazi sympathizers and anti-Semites. Ludecke asked Ford for a contribution to the Nazi cause, but was apparently refused.
While Ford's articles were denounced by the Anti-Defamation League (ADL), the articles explicitly condemned pogroms and violence against Jews (Volume 4, Chapter 80), but blamed the Jews for provoking incidents of mass violence. None of this work was written by Ford, but he allowed his name to be used as author. According to trial testimony, he wrote almost nothing. Friends and business associates have said they warned Ford about the contents of the "Independent" and that he probably never read the articles. (He claimed he only read the headlines.) However, court testimony in a libel suit, brought by one of the targets of the newspaper, alleged that Ford did know about the contents of the "Independent" in advance of publication.
A libel lawsuit was brought by San Francisco lawyer and Jewish farm cooperative organizer Aaron Sapiro in response to the anti-Semitic remarks, and led Ford to close the "Independent" in December 1927. News reports at the time quoted him as saying he was shocked by the content and unaware of its nature. During the trial, the editor of Ford's "Own Page," William Cameron, testified that Ford had nothing to do with the editorials even though they were under his byline. Cameron testified at the libel trial that he never discussed the content of the pages or sent them to Ford for his approval. Investigative journalist Max Wallace noted that "whatever credibility this absurd claim may have had was soon undermined when James M. Miller, a former "Dearborn Independent" employee, swore under oath that Ford had told him he intended to expose Sapiro."
Michael Barkun observed, That Cameron would have continued to publish such anti-Semitic material without Ford's explicit instructions seemed unthinkable to those who knew both men. Mrs. Stanley Ruddiman, a Ford family intimate, remarked that 'I don't think Mr. Cameron ever wrote anything for publication without Mr. Ford's approval.'
According to Spencer Blakeslee,
The ADL mobilized prominent Jews and non-Jews to publicly oppose Ford's message. They formed a coalition of Jewish groups for the same purpose and raised constant objections in the Detroit press. Before leaving his presidency early in 1921, Woodrow Wilson joined other leading Americans in a statement that rebuked Ford and others for their anti-Semitic campaign. A boycott against Ford products by Jews and liberal Christians also had an impact, and Ford shut down the paper in 1927, recanting his views in a public letter to Sigmund Livingston, ADL.
Wallace also found that Ford's apology was likely, at least partly, motivated by a business that was slumping as result of his anti-Semitism repelling potential buyers of Ford cars. Up until the apology, a considerable number of dealers, who had been required to make sure that buyers of Ford cars received the "Independent", bought up and destroyed copies of the newspaper rather than alienate customers.
Ford's 1927 apology was well received. "Four-Fifths of the hundreds of letters addressed to Ford in July 1927 were from Jews, and almost without exception they praised the Industrialist." In January 1937, a Ford statement to the "Detroit Jewish Chronicle" disavowed "any connection whatsoever with the publication in Germany of a book known as the "International Jew"."
According to Pool and Pool (1978), Ford's retraction and apology (which were written by others) were not even truly signed by him (rather, his signature was forged by Harry Bennett), and Ford never privately recanted his anti-Semitic views, stating in 1940, "I hope to republish "The International Jew" again some time."
In July 1938, before the outbreak of war, the German consul at Cleveland gave Ford, on his 75th birthday, the award of the Grand Cross of the German Eagle, the highest medal Nazi Germany could bestow on a foreigner. James D. Mooney, vice-president of overseas operations for General Motors, received a similar medal, the Merit Cross of the German Eagle, First Class.
On January 7, 1942, Ford wrote a letter to Sigmund Livingston as the Founder and National Chairman of the Anti-Defamation League. The purpose of the letter was to clarify some general misconceptions that he subscribed or supported directly or indirectly, “any agitation which would promote antagonism toward my Jewish fellow citizens.” He concluded the letter with “My sincere hope that now in this country and throughout the world when the war is finished, hatred of the Jews and hatred against any other racial or religious groups shall cease for all time.” 
Distribution of "International Jew" was halted in 1942 through legal action by Ford, despite complications from a lack of copyright. It is still banned in Germany. Extremist groups often recycle the material; it still appears on antisemitic and neo-Nazi websites.
Testifying at Nuremberg, convicted Hitler Youth leader Baldur von Schirach who, in his role as military governor of Vienna deported 65,000 Jews to camps in Poland, stated,
The decisive anti-Semitic book I was reading and the book that influenced my comrades was ... that book by Henry Ford, "The International Jew." I read it and became anti-Semitic. The book made a great influence on myself and my friends because we saw in Henry Ford the representative of success and also the representative of a progressive social policy. 
Robert Lacey wrote in "Ford: The Men and the Machines" that a close Willow Run associate of Ford reported that when he was shown newsreel footage of the Nazi concentration camps, he "was confronted with the atrocities which finally and unanswerable laid bare the bestiality of the prejudice to which he contributed, he collapsed with a stroke – his last and most serious." Ford had suffered previous strokes and his final cerebral hemorrhage occurred in 1947 at age 83.
International business.
Ford's philosophy was one of economic independence for the United States. His River Rouge Plant became the world's largest industrial complex, pursuing vertical integration to such an extent that it could produce its own steel. Ford's goal was to produce a vehicle from scratch without reliance on foreign trade. He believed in the global expansion of his company. He believed that international trade and cooperation led to international peace, and he used the assembly line process and production of the Model T to demonstrate it.
He opened Ford assembly plants in Britain and Canada in 1911, and soon became the biggest automotive producer in those countries. In 1912, Ford cooperated with Giovanni Agnelli of Fiat to launch the first Italian automotive assembly plants. The first plants in Germany were built in the 1920s with the encouragement of Herbert Hoover and the Commerce Department, which agreed with Ford's theory that international trade was essential to world peace. In the 1920s, Ford also opened plants in Australia, India, and France, and by 1929, he had successful dealerships on six continents. Ford experimented with a commercial rubber plantation in the Amazon jungle called Fordlândia; it was one of his few failures.
In 1929, in the absence of diplomatic relations between the United States and the Soviet Union, Ford accepted an offer by the Soviet Government to provide technical aid in building the first Soviet automobile plant (GAZ) near Nizhnii Novgorod (Gorky). The technical assistance agreement between the Ford Motor Company, VSNKh, and Amtorg (as purchasing agent) was concluded for nine years and was signed in Dearborn on May 31, 1929, by Henry Ford, vice-president of the Ford Motor Company, Peter E. Martin, vice-chairman of VSNKh, Valery I. Mezhlauk, and the president of Amtorg, Saul G. Bron. (An additional contract for actual construction of the plant was signed with on August 23, 1929.) The contract involved the purchase of $30,000,000 worth of knocked-down Ford cars and trucks for assembly during the first four years of the plant’s operation, after which the plant would gradually switch to Soviet-made components. Ford sent his engineers and technicians to the Soviet Union to help install the equipment and train the working force, while over a hundred Soviet engineers and technicians were stationed at Ford’s plants in Detroit and Dearborn “for the purpose of learning the methods and practice of manufacture and assembly in the Company's plants.” Said Ford: “No matter where industry prospers, whether in India or China, or Russia, the more profit there will be for everyone, including us. All the world is bound to catch some good from it.”
By 1932, Ford was manufacturing one third of all the world's automobiles. It set up numerous subsidiaries that sold or assembled the Ford cars and trucks:
Ford's image transfixed Europeans, especially the Germans, arousing the "fear of some, the infatuation of others, and the fascination among all". Germans who discussed "Fordism" often believed that it represented something quintessentially American. They saw the size, tempo, standardization, and philosophy of production demonstrated at the Ford Works as a national service—an "American thing" that represented the culture of United States. Both supporters and critics insisted that Fordism epitomized American capitalist development, and that the auto industry was the key to understanding economic and social relations in the United States. As one German explained, "Automobiles have so completely changed the American's mode of life that today one can hardly imagine being without a car. It is difficult to remember what life was like before Mr. Ford began preaching his doctrine of salvation". For many Germans, Ford embodied the essence of successful Americanism.
In "My Life and Work", Ford predicted that if greed, racism, and short-sightedness could be overcome, then economic and technological development throughout the world would progress to the point that international trade would no longer be based on (what today would be called) colonial or neocolonial models and would truly benefit all peoples. His ideas in this passage were vague, but they were idealistic.
Racing.
Ford maintained an interest in auto racing from 1901 to 1913 and began his involvement in the sport as both a builder and a driver, later turning the wheel over to hired drivers. He entered stripped-down Model Ts in races, finishing first (although later disqualified) in an "ocean-to-ocean" (across the United States) race in 1909, and setting a one-mile (1.6 km) oval speed record at Detroit Fairgrounds in 1911 with driver Frank Kulick. In 1913, Ford attempted to enter a reworked Model T in the Indianapolis 500 but was told rules required the addition of another 1,000 lb to the car before it could qualify. Ford dropped out of the race and soon thereafter dropped out of racing permanently, citing dissatisfaction with the sport's rules, demands on his time by the booming production of the Model Ts, and his low opinion of racing as a worthwhile activity.
In "My Life and Work" Ford speaks (briefly) of racing in a rather dismissive tone, as something that is not at all a good measure of automobiles in general. He describes himself as someone who raced only because in the 1890s through 1910s, one had to race because prevailing ignorance held that racing was the way to prove the worth of an automobile. Ford did not agree. But he was determined that as long as this was the definition of success (flawed though the definition was), then his cars would be the best that there were at racing. Throughout the book, he continually returns to ideals such as transportation, production efficiency, affordability, reliability, fuel efficiency, economic prosperity, and the automation of drudgery in farming and industry, but rarely mentions, and rather belittles, the idea of merely going fast from point A to point B.
Nevertheless, Ford did make quite an impact on auto racing during his racing years, and he was inducted into the Motorsports Hall of Fame of America in 1996.
Later career and death.
When Edsel, president of Ford Motor Company, died of cancer in May 1943, the elderly and ailing Henry Ford decided to assume the presidency. By this point in his life, he had had several cardiovascular events (variously cited as heart attack or stroke) and was mentally inconsistent, suspicious, and generally no longer fit for such immense responsibilities.
Most of the directors did not want to see him as president. But for the previous 20 years, though he had long been without any official executive title, he had always had "de facto" control over the company; the board and the management had never seriously defied him, and this moment was not different. The directors elected him, and he served until the end of the war. During this period the company began to decline, losing more than $10 million a month ($ a month today). The administration of President Franklin Roosevelt had been considering a government takeover of the company in order to ensure continued war production, but the idea never progressed.
In ill health, Ford ceded the presidency to his grandson Henry Ford II in September 1945 and went into retirement. He died in 1947 of a cerebral hemorrhage at age 83 in Fair Lane, his Dearborn estate. A public viewing was held at Greenfield Village where up to 5,000 people per hour filed past the casket. Funeral services were held in Detroit's Cathedral Church of St. Paul and he was buried in the Ford Cemetery in Detroit.
Personal interests.
A compendium of short biographies of famous Freemasons, published by a Freemason lodge, lists Ford as a member. The Grand Lodge of New York confirms that Ford was a Freemason, and was raised in Palestine Lodge No. 357, Detroit, in 1894. When he received his 33rd in 1940, he said, "Masonry is the best balance wheel the United States has."
In 1923, Ford's pastor, and head of his sociology department, Episcopal minister Samuel S. Marquis, claimed that Ford believed, or "once believed," in reincarnation.
Ford published an anti-smoking book, circulated to youth in 1914, called "The Case Against the Little White Slaver", which documented many dangers of cigarette smoking attested to by many researchers and luminaries. At the time smoking was ubiquitous and was not yet widely associated with health detriment, so Ford's opposition to cigarettes was unusual.
Interest in materials science and engineering.
Henry Ford long had an interest in materials science and engineering. He enthusiastically described his company's adoption of vanadium steel alloys and subsequent metallurgic R&D work.
Ford long had an interest in plastics developed from agricultural products, especially soybeans. He cultivated a relationship with George Washington Carver for this purpose. Soybean-based plastics were used in Ford automobiles throughout the 1930s in plastic parts such as car horns, in paint, etc. This project culminated in 1942, when Ford patented an automobile made almost entirely of plastic, attached to a tubular welded frame. It weighed 30% less than a steel car and was said to be able to withstand blows ten times greater than could steel. Furthermore, it ran on grain alcohol (ethanol) instead of gasoline. The design never caught on.
Ford was interested in engineered woods ("Better wood can be made than is grown") (at this time plywood and particle board were little more than experimental ideas); corn as a fuel source, via both corn oil and ethanol; and the potential uses of cotton. Ford was instrumental in developing charcoal briquets, under the brand name "Kingsford". His brother in law, E.G. Kingsford, used wood scraps from the Ford factory to make the briquets.
Ford was a prolific inventor and was awarded 161 U.S. patents.
Florida and Georgia residences and community.
Ford had a vacation residence in Fort Myers, Florida next to Thomas Edison that he bought in 1915 and used until approximately 1930. It is still in existence today and is .
He also had a vacation home (known today as the "Ford Plantation") in Richmond Hill, Georgia which is still in existence today as a private community. Henry started buying land in this area and eventually owned 70,000 acres (110 square miles) there. In 1936, Ford broke ground for a beautiful Greek revival style mansion on the banks of the Ogeechee River on the site of a 1730s plantation. The grand house, made of Savannah-gray brick, had marble steps, air conditioning, and an elevator. It sat on 55 acres of manicured lawns and flowering gardens. The house became the center of social gatherings with visitations by the Vanderbilts, Rockefellers, and the DuPonts. It remains the centerpiece of today. Mr. Ford converted the 1870s–era rice mill into his personal research laboratory and powerhouse and constructed an underground tunnel from there to the new home, providing it with steam. He contributed substantially to the community, building a chapel and schoolhouse and employing numerous local residents.
Preserving Americana.
Ford had an interest in "Americana". In the 1920s, Ford began work to turn Sudbury, Massachusetts, into a themed historical village. He moved the schoolhouse supposedly referred to in the nursery rhyme, "Mary Had a Little Lamb", from Sterling, Massachusetts, and purchased the historic Wayside Inn. This plan never saw fruition. Ford repeated the concept of collecting historic structures with the creation of Greenfield Village in Dearborn, Michigan. It may have inspired the creation of Old Sturbridge Village as well. About the same time, he began collecting materials for his museum, which had a theme of practical technology. It was opened in 1929 as the Edison Institute. Although greatly modernized, the museum continues today.
References.
Memoirs by Ford Motor Company principals.
</dl>
Biographies.
</dl>
Specialized studies.
</dl>
Further reading.
</dl>

</doc>
<doc id="13372" url="http://en.wikipedia.org/wiki?curid=13372" title="Human geography">
Human geography

Human geography is the branch of the social sciences that deals with the world, its peoples, and their communities and cultures, by emphasising their relations of and across space and place. As an intellectual discipline, geography is divided into the sub-fields of physical geography and of human geography, which concentrates upon the study of human activities, by the application of qualitative research methods. As an academic discipline, human geography features various philosophical and theoretic methods for the study of the cultures and communities of the peoples of the world.
History.
Geographical knowledge, both physical and social, has a long history. In the history of geography, geographers have often recorded and described features of the Earth that might now be considered the remit of human, rather than physical, geographers. For example Hecataeus of Miletus, a geographer and historian in ancient Greece, described inhabitants of the ancient world as well as physical features.
It was not until the 18th and 19th centuries, however, that geography was recognised as a formal academic discipline. 
The Royal Geographical Society was founded in England in 1830, although the United Kingdom did not get its first full Chair of geography until 1917. The first real geographical intellect to emerge in United Kingdom geography was Halford John Mackinder, appointed reader at Oxford University in 1887.
The National Geographic Society was founded in the USA in 1888 and began publication of the "National Geographic" magazine which became and continues to be a great populariser of geographic information. The society has long supported geographic research and education.
One of the first examples of geographic methods being used for purposes other than to describe and theorise the physical properties of the earth is John Snow's map of the 1854 Broad Street cholera outbreak. Though a physician and a pioneer of epidemiology, the map is probably one of the earliest examples of health geography.
The now fairly distinct differences between the subfields of physical and human geography developed at a later date. This connection between both physical and human properties of geography is most apparent in the theory of environmental determinism, made popular in the 19th century by Carl Ritter and others, and with close links to evolutionary biology of the time. Environmental determinism is the theory that a people's physical, mental and moral habits are directly due to the influence of their natural environment. However, by the mid-19th century, environmental determinism was under attack for lacking methodological rigour associated with modern science, and later as serving to justify racism and imperialism.
A similar concern with both human and physical aspects is apparent in the later regional geography, during the later 19th and first half of the 20th centuries. The goal of regional geography, through regionalization, was to delineate space into regions and then understand and describe the unique characteristics of each region, in both human and physical aspects. With links to possibilism and cultural ecology, some of the same notions of causal effect of the environment on society and culture, as with environmental determinism remained.
By the 1960s, however, the quantitative revolution led to strong criticism of regional geography. Due to a perceived lack of scientific rigour in and overly descriptive nature of the discipline, and a continued separation of geography from geology and the two subfields of physical and human geography, geographers in the mid-20th century began to apply statistical and mathematical model methods to solving spatial problems. Much of the development during the quantitative revolution is now apparent in the use of geographic information systems; the use of statistics, spatial modelling and positivist approaches is still important to many branches of human geography. Well-known geographers from this period are Fred K. Schaefer, Waldo Tobler, William Garrison, Peter Haggett, Richard J. Chorley, William Bunge, and Torsten Hägerstrand.
From the 1970s a number of critiques of the positivism now associated with geography emerged. Known under the term 'critical geography' this signalled another turning point in the discipline. Behavioural geography emerged for some time as a means to understand how people made perceived spaces and places, and made locational decisions. More influentially, 'radical geography' emerged in the 1970s and 1980s, drawing heavily on Marxist theory and techniques, and is associated with geographers such as David Harvey and Richard Peet. Seeking to say something 'meaningful' about the problems recognised through quantitative methods, to provide explanations rather than descriptions, to put forward alternatives and solutions and to be politically engaged, rather than the detachment associated with positivist methods. (The detachment and objectivity of the quantitative revolution was itself critiqued by radical geographers as being a tool of capital). Radical geography and the links to Marxism and related theories remain an important part of contemporary human geography (See: Antipode (Journal)) Critical geography also saw the introduction of 'humanistic geography', associated with the work of Yi-Fu Tuan, which, though similar to behavioural geography, pushed for a much more qualitative approach in methodology.
The changes under critical geography have led to contemporary approaches in the discipline such as feminist geography, new cultural geography, and the engagement with postmodern and post-structural theories and philosophies.
Fields.
The main fields of study in human geography focus around the core fields of:
Animals.
Animal geography is the examinations of the lifeworlds of animals themselves The field has emerged through geographers' concerns with the nonhuman and material world, sometimes dubbed as 'hybrid' or 'more-than-human' geography. Animal geographies are beginning to extend the domain and boundaries of 'human' geography.
Culture.
Cultural geography is the study of cultural products and norms - their variation across spaces and places, as well as their relations. It focuses on describing and analysing the ways language, religion, economy, government, and other cultural phenomena vary or remain constant from one place to another and on explaining how humans function spatially.
Development.
Development Geography is the study of the Earth's geography with reference to the Standard of living and the Quality of life of its human inhabitants, study of the location, distribution and spatial organization of economic activities, across the Earth. The subject matter investigated is strongly influenced by the researcher's methodological approach.
Economic.
Economic geography examines relationships between human economic systems, states, and other factors, and the biophysical environment.
Health.
Health geography is the application of geographical information, perspectives, and methods to the study of health, disease, and health care.
Historical.
Historical geography is the study of the human, physical, fictional, theoretical, and "real" geographies of the past. Historical geography studies a wide variety of issues and topics. A common theme is the study of the geographies of the past and how a place or region changes through time. Many historical geographers study geographical patterns through time, including how people have interacted with their environment, and created the cultural landscape.
Political.
Political geography is concerned with the study of both the spatially uneven outcomes of political processes and the ways in which political processes are themselves affected by spatial structures.
Population.
Population geography is the study of the ways in which spatial variations in the distribution, composition, migration, and growth of populations are related to the nature of places.
Settlement.
Settlement geography, including urban geography, is the study of urban and rural areas with specific regards to spatial, relational and theoretical aspects of settlement. That is the study of areas which have a concentration of buildings and infrastructure. These are areas where the majority of economic activities are in the secondary sector and tertiary sectors. In case of urban settlement, they probably have a high population density.
Philosophical and theoretical approaches.
Within each of the subfields, various philosophical approaches can be used in research; therefore, an urban geographer could be a Feminist or Marxist geographer, etc.
Such approaches are:
Human geography journals.
As with all social sciences, human geographers publish research and other written work in a variety of academic journals. Whilst human geography is interdisciplinary, there are a number of journals with a human geography focus.
These include:

</doc>
<doc id="13373" url="http://en.wikipedia.org/wiki?curid=13373" title="Haiti">
Haiti

Haiti (; French: "Haïti" ]; Haitian Creole: "Ayiti" ]), officially the Republic of Haïti ("République d'Haïti"; "Repiblik Ayiti"), is a Caribbean country. It occupies the western, smaller portion of the island of Hispaniola, in the Greater Antillean archipelago, which it shares with the Dominican Republic. In addition, Haiti also occupies small satellite islands known for tourists, including; Île-à-Vache ("Cow Island"), which includes Port Morgan and Abaka Bay resorts. In French, the country's nickname is "La Perle des Antilles" (The Pearl of the Antilles), because of its natural beauty. It is the most mountainous nation in the Caribbean and the country's highest point is Pic la Selle, at 2680 m. By area and population, Haiti is the third largest Caribbean nation (after Cuba and the Dominican Republic), with 27750 km2, and an estimated 9.9 million people; about a million of whom live in the capital city of Port-au-Prince.
Haiti's regional, historical, and ethno-linguistic position is unique for several reasons. Originally inhabited by the indigenous Taíno people, the island was first discovered by Christopher Columbus during his first voyage across the Atlantic in 1492. When Columbus first landed in Haiti (western Hispaniola), he had thought he had found India or Asia. His flagship, the "Santa Maria", sank after running aground on 25 December in the north coast of present-day Haiti. Deciding to establish a settlement in the area, a contingent of men were left at an outpost christened La Navidad, because the wreck occurred on Christmas, north of what is now Limonade.
Gaining its independence in 1804, Haiti was the first independent nation of Latin America and the Caribbean, the second republic successful in a war of independence against a European colonial power in the Americas, the only nation in the western hemisphere to have defeated three European superpowers (Britain, France, and Spain), and the only nation in the world established as a result of a successful slave revolt. The rebellion, begun in 1791, was led by a former slave and the first black general of the French Army, Toussaint Louverture, whose military genius and political acumen transformed an entire society of slaves into the independent country. Upon his death in a prison in France, he was succeeded by his lieutenant, Jean-Jacques Dessalines, who declared Haiti's sovereignty and later became the first emperor of Haiti, "Jacques I". Its successful revolution by slaves and free people of color lasted nearly a decade; and apart from Alexandre Pétion, the first President of the Republic, all the first leaders of government were former slaves.
The Citadelle Laferrière is the largest fortress in the Americas. Henri Christophe—former slave and first king of Haiti, "Henri I"—built it to withstand a possible foreign attack.
At 9.9 million people, Haiti is the most populous full member-state of the Caribbean Community (CARICOM). The country is also a member of the Latin Union. In 2012, Haiti announced its intention to seek associate membership status in the African Union. It has the lowest Human Development Index in the Americas. Political violence has occurred regularly throughout its history, leading to government instability. Most recently, in February 2004, a "coup d'état" originating in the north of the country forced the resignation and exile of President Jean-Bertrand Aristide. A provisional government took control with security provided by the United Nations Stabilization Mission in Haiti (MINUSTAH). Michel Martelly, the current president, was elected in the 2011 general election.
Etymology.
The name "Haïti" comes from the indigenous Taíno language. It is the French spelling for the original word "Ayiti", which was the native name given to the entire island of Hispaniola to mean, "land of high mountains". The original spelling is kept in Haitian Creole, but since the "h" is silent in French, the pronunciation remains the same. The "ï" in "Haïti", is a diacritical mark used to show that the second vowel is pronounced separately, as in the word "naïve". In English, the rules for the pronunciation are disregarded; thus the spelling "Haiti" is used, pronounced as ""Hay"-ti".
History.
Pre-European history.
At the time of European encounter, the island of Hispaniola, of which Haiti occupies the western three-eighths, was one of many Caribbean islands inhabited by the Taíno Indians, speakers of an Arawakan language called Taino, which has been preserved in the Haitian Creole language. The Taíno name for the entire island was either "Ayiti" or "Kiskeya" "(Quisqueya)". The people had migrated over centuries into the Caribbean islands from South America. Genetic studies show they were related to the Yanomami of the Amazon Basin. They also originated in Central and South America. After migrating to Caribbean islands, in the 15th century, the Taíno were pushed into the northeast Caribbean islands by the Caribs.
In the Taíno societies of the Caribbean Islands, the largest unit of political organization was led by a "cacique," or chief, as the Europeans understood them. The island of Ayiti was divided among five Caciquats: the Magua in the north east, the Marien in the north west, the Xaragua in the south west, the Maguana in the center region of Cibao and the Higuey in the south east or six long-established caciquedoms The caciquedoms were tributary kingdoms, with payment consisting of harvests.
Taíno cultural artifacts include cave paintings in several locations in the country. These have become national symbols of Haiti and tourist attractions. Modern-day Léogane, started as a French colonial town in the southwest, is located at the site of the former capital of the caciquedom of "Xaragua."
Spanish rule (1492–1625).
Navigator Christopher Columbus landed at Môle Saint-Nicolas on 5 December 1492, and claimed the island for the Crown of Castile. Nineteen days later, his ship the "Santa María" ran aground near the present site of Cap-Haïtien. Columbus left 39 men on the island, who founded the settlement of La Navidad.
The sailors carried endemic Eurasian infectious diseases. The natives lacked immunity to these new diseases and died in great numbers in epidemics. The first recorded smallpox epidemic in the Americas erupted on Hispaniola in 1507. The "encomienda" system forced natives to work in gold mines and plantations.
The Spanish passed the Laws of Burgos, 1512–1513, which forbade the maltreatment of natives, endorsed their conversion to Catholicism, and gave legal framework to "encomiendas." The natives were brought to these sites to work in specific plantations or industries.
As a gateway to the Caribbean, Hispaniola became a haven for pirates during the early colonial period. The western part of the island was settled by French buccaneers. Among them was Bertrand d'Ogeron, who succeeded in growing tobacco. He recruited many French colonial families from Martinique and Guadeloupe. European nations were competing for control in the New World, in the Caribbean as well as in North America. France and Spain settled their hostilities on the island, by way of the Treaty of Ryswick of 1697, and divided Hispaniola between them.
French rule (1625–1804).
France received the western third and subsequently named it Saint-Domingue, the French equivalent of "Santo Domingo", the Spanish colony of Hispaniola and the name of its patron saint, Saint Dominic. To develop it into sugar cane plantations, they imported thousands of slaves from Africa. Sugar was a lucrative commodity crop throughout the 18th century. By 1789, approximately 40,000 French colonists lived in Saint-Domingue. In contrast, by 1763 the French population of Canada, a vast territory, had numbered 65,000. The (white) French were vastly outnumbered by the tens of thousands of (Black African) slaves they had imported to work on their plantations, which were primarily devoted to the production of sugar cane. In the north of the island, slaves were able to retain many ties to African cultures, religion, and language; these ties were continually being renewed by newly imported Africans. Blacks outnumbered whites by about ten-to-one.
The French-enacted "Code Noir" ("Black Code"), prepared by Jean-Baptiste Colbert and ratified by Louis XIV, had established rules on slave treatment and permissible freedoms. Saint-Domingue has been described as one of the most brutally efficient slave colonies; one-third of newly imported Africans died within a few years. Many slaves died from diseases such as smallpox and typhoid fever. They had low birth rates, and there is evidence that some women aborted fetuses rather than give birth to children within the bonds of slavery.
As in its Louisiana colony, the French colonial government allowed some rights to free people of color: the mixed-race descendants of white male colonists and black female slaves (and later, mixed-race women). Over time, many were released from slavery. They established a separate social class. White French Creole fathers frequently sent their mixed-race sons to France for their education. Some men of color were admitted into the military. More of the free people of color lived in the south of the island, near Port-au-Prince, and many intermarried within their community. They frequently worked as artisans and tradesmen, and began to own some property. Some became slave holders. The free people of color petitioned the colonial government to expand their rights.
Haitian Revolution (1804).
Inspired by the French Revolution of 1789 and principles of the rights of man, free people of color and slaves in Saint-Domingue and the French West Indies pressed for freedom and more civil rights. Most important was the revolution of the slaves in Saint-Domingue, starting in the northern plains in 1791, where Africans greatly outnumbered the whites.
In 1792, the French government sent three commissioners with troops to re-establish control. To build an alliance with the "gens de couleur" and slaves, the French commissioners Sonthonax and Polverel abolished slavery in the colony. Six months later, the National Convention, led by Robespierre and the Jacobins, endorsed abolition and extended it to all the French colonies.
Political leaders in the United States, which was a new republic itself, reacted with ambivalence, at times providing aid to enable planters to put down the revolt. Later in the revolution, the US provided support to black Haitian military forces, with the goal of reducing French influence in North America and the Caribbean.
Toussaint Louverture, a former slave and leader in the slave revolt, drove out the Spanish (from Santo Domingo) and the British invaders who threatened the colony. In the uncertain years of revolution, the United States played both sides off against each other, with its traders supplying both the French and the rebels. The struggle within Haiti between the free people of color led by André Rigaud and the black Haitians led by Louverture devolved into the War of the Knives in 1799 and 1800. Many surviving free people of color left the island as refugees.
After Louverture created a separatist constitution, Napoléon Bonaparte in 1802 sent an expedition of more than 20,000 men under the command of his brother-in-law, General Charles Leclerc, to retake the island. The French achieved some victories, but within a few months, most of the French troops had died from yellow fever. More than 50,000 French troops died in an attempt to retake the colony, including 18 generals. The French captured Louverture, transporting him to France for trial. He was imprisoned at Fort de Joux, where he died in 1803 of exposure and possibly tuberculosis.
The slaves, along with free "gens de couleur" and allies, continued their fight for independence. Jean-Jacques Dessalines defeated French troops at the Battle of Vertières on 18 November 1803, leading the first ever successful slave army revolution. In late 1803, France withdrew its remaining 7,000 troops from the island and Napoleon gave up his idea of re-establishing a North American empire. With the war going badly, he sold Louisiana (New France) to the United States, in the Louisiana Purchase.
Early post-independence.
The independence of Saint-Domingue was proclaimed by Dessalines on 1 January 1804. The exact number of deaths due to the Haitian revolution is unknown. Slaves that made it to Haiti from the trans-Atlantic journey and slaves born in Haiti were first documented in Haiti's archives and transferred to France's Ministry of Defense and the Ministry of Foreign Affairs. As of 2015, these records are in The National Archives of France. According to the 1788 Census, Haiti's population consisted of nearly 28,000 whites, 22,000 free coloreds, and 500,000 slaves. After the revolution, census was taken in every city. From an etic or outsider or the oppressor point-of-view, it is alleged that Dessalines massacred nearly all of the whites, including their mulatto children. However, copy of the 1804 census of the city of Gros Morne retrieved from John Carter Brown Library suggests an emic or insider or the victim point-of-view.
Dessalines was proclaimed "Emperor for Life" by his troops. Dessalines at first offered protection to the white planters and others; but once in power, he ordered the massacre of most whites, without regard to age or gender. In the continuing competition for power, he was assassinated by rivals on 17 October 1806.
Fearful of the influence of the slaves' revolution, US President Thomas Jefferson refused to recognize the new republic, as did most European nations. The US did not officially recognize Haiti for decades, until after the American Civil War. Haiti's new government was not supported by other republics.
The revolution led to a wave of emigration. In 1809, nearly 10,000 refugees from Saint-Domingue settled "en masse" in New Orleans. They doubled the city's population. In addition, the newly arrived slaves added to the city's African population.
Saint-Domingue was divided between the Kingdom of Haiti in the north, directed by Henri I, and a republic in the south, directed by Alexandre Pétion, an "homme de couleur". Henri Christophe established a semi-feudal corvée system, with a rigid education and economic code.
President Pétion gave military and financial assistance to the revolutionary leader Simón Bolívar, which were critical in enabling him to liberate the Viceroyalty of New Granada. He was instrumental in aiding countries in South America achieve independence from Spain.
Beginning in 1821, President Jean-Pierre Boyer, also an "homme de couleur" and successor to Pétion, reunified the two parts of Haiti and extended control over the entire western portion of the island. In addition, after Santo Domingo declared its independence from Spain, Boyer sent forces in to take control. Boyer ruled the entire island, ending slavery in Santo Domingo. After Santo Domingo achieved independence from Haiti, it established a separate national identity.
Struggling to revive the agricultural economy to produce commodity crops, Boyer passed the Code Rural, which denied peasant laborers the right to leave the land, enter the towns, or start farms or shops of their own. Following the Revolution, many peasants wanted to have their own farms rather than work on plantations.
The American Colonization Society (ACS) encouraged free blacks in the United States to emigrate to Haiti. Starting in September 1824, more than 6,000 African Americans migrated to Haiti, with transportation paid by the ACS. Many found the conditions too harsh and returned to the United States.
In July 1825, King Charles X of France, during a period of "restoration" for the monarchy, sent a fleet to reconquer the island. Under pressure, President Boyer agreed to a treaty by which France formally recognized the independence of the nation in exchange for a payment of 150 million francs (reduced to 90 million in 1838). After losing the support of Haiti's elite, Boyer was ousted in 1843. A long succession of coups followed his departure to exile.
The enforced payment to France reduced Haiti's economy for years. Western nations did not give Haiti formal diplomatic recognition. Both of these problems kept the Haitian economy and society isolated. Expatriates bankrolled and armed opposing groups. In 1892, the German government supported suppression of the reform movement of Anténor Firmin.
20th century.
In January 1914, British, German and U.S. military forces entered Haiti, ostensibly to protect their citizens from civil unrest at the time. In an expression of the Theodore Roosevelt Corollary to the Monroe Doctrine, the United States occupied the island in 1915. U.S. Marines were stationed in the country until 1934, a period of nineteen years.
Sisal was introduced to Haiti, and sugar and cotton became significant exports. Haitian traditionalists, based in rural areas, were highly resistant to American-backed changes, while the urban elites wanted more control. Together they helped secure an end to the occupation in 1934. The debts were still outstanding and the American financial advisor-general receiver handled the budget until 1941.
Recognition of the distinctive traditionalism of the Haitian people had an influence on United States writers, including Eugene O'Neill, James Weldon Johnson, Langston Hughes, Zora Neale Hurston and Orson Welles.
After US forces left in 1934, Dominican dictator Rafael Trujillo used anti-Haitian sentiment as a nationalist tool. In an event that became known as the Parsley Massacre, he ordered his Army to kill Haitians living on the Dominican side of the border. Between 10,000 and 20,000 Haitians were killed. One-quarter Haitian, Trujillo continued policies against the neighboring population for some time.
United States and European tourists started to visit Haiti in the 1950s.
The waterfront area of Port-au-Prince was redeveloped to allow cruise ship passengers to walk from the docks to cultural attractions.
Among these attractions were the Moorish-styled "Iron Market", where fine Haitian art and mahogany were sold. In the evenings entrepreneurs provided dancing, casino gambling, and Voodoo shows. Truman Capote and Noël Coward visited the Hotel Oloffson, a 19th-century Gothic gingerbread mansion set in a tropical garden, which was even portrayed in the Graham Greene novel, "The Comedians".
After a period of disorder, in September 1957 Dr. François Duvalier was elected President of Haiti. Known as "Papa Doc" and initially popular, Duvalier was President until his death in 1971. He advanced black interests in the public sector, where over time people of color had predominated as the educated urban elite. He stayed in power by enlisting an organization known as "Tontons Macoutes" ("Bogeymen"), which maintained order by terrorizing the populace and political opponents.
Haiti's brief tourism boom was wiped out by the rule of Francois "Papa Doc" Duvalier and his unstable government. When his son Jean-Claude "Baby Doc" Duvalier succeeded him as "President for Life", tourism returned in the 1970s. Tourists included Bill and Hillary Clinton, who honeymooned there in 1975. "Vive la différence" has long been Haiti's national tourism slogan and its proximity to the United States, made Haiti a hot attraction until the Duvalier regime was ousted in 1986.
Papa Doc's son Jean-Claude Duvalier – also known as "Baby Doc" – led the country from 1971 until his ouster in 1986, when protests led him to seek exile in France. Army leader General Henri Namphy headed a new National Governing Council. General elections in November were aborted after dozens of inhabitants were shot in the capital by soldiers and Tontons Macoutes. Fraudulent elections followed. The elected President, Leslie Manigat, was overthrown some months later in the June 1988 Haitian coup d'état. The September 1988 Haitian coup d'état, which followed the St Jean Bosco massacre, revealed the increasing prominence of former Tontons Macoutes. General Prosper Avril led a military regime until March 1990.
In December 1990, a former Catholic priest, Jean-Bertrand Aristide was elected President in the Haitian general election. In September of the following year, Aristide was overthrown by the military in the 1991 Haitian coup d'état. In 1994, an American team negotiated the departure of Haiti's military leaders and the peaceful entry of US forces under Operation Uphold Democracy. This enabled the restoration of the democratically elected Jean-Bertrand Aristide as president. In October 1994, Aristide returned to Haiti to complete his term in office. Aristide vacated the presidency in February 1996. In the 1995 election, René Préval was elected as president for a five-year term, winning 88% of the popular vote.
21st century.
The November 2000 election 
returned Aristide to the presidency with 92% of the vote. The election had been boycotted by the opposition, then organized into the Convergence Démocratique, over a dispute in the May legislative elections. In subsequent years, there was increasing violence and human rights abuses. Aristide supporters attacked the opposition. Aristide spent years negotiating with the Convergence Démocratique on new elections, but the Convergence's inability to develop a sufficient electoral base made elections unattractive.
In 2004, a revolt began in northern Haiti. The rebellion eventually reached the capital; and Aristide was forced into exile, whereupon the United Nations stationed peacekeepers in Haiti. Some including Aristide and his bodyguard, Franz Gabriel, stated that he was the victim of a "new coup d'état or modern kidnapping" by U.S. forces. Mrs. Aristide stated that the kidnappers wore US Special Forces uniforms, but changed into civilian clothes upon boarding the aircraft that was used to remove Aristide from Haiti. 
Boniface Alexandre assumed interim authority. René Préval was elected President in February 2006, following elections marked by uncertainties and popular demonstrations. The United Nations Stabilization Mission in Haiti (also known as MINUSTAH) remains in the country, having been there since the 2004 coup d'état. The United States led a vast international campaign to prevent Aristide from returning to his country while he was exiled in South Africa. Released Wikileaks cables show that high-level U.S. and U.N. officials coordinated activity against Aristide to prevent him from "gaining more traction with the Haitian population and returning to Haiti." The United States and its allies allegedly poured tens of millions of dollars into unsuccessful efforts to slander Aristide as a drug trafficker, human rights violator, and heretical practitioner of vodou.
In 2004, Tropical Storm Jeanne skimmed the north coast of Haiti, leaving 3,006 people dead in flooding and mudslides, mostly in the city of Gonaïves. In 2008 Haiti was again struck by tropical storms; Tropical Storm Fay, Hurricane Gustav, Hurricane Hanna and Hurricane Ike all produced heavy winds and rain. There were 331 dead and about 800,000 in need of humanitarian aid. The state of affairs produced by these storms was intensified by already high food and fuel prices that had caused a food crisis and political unrest in April 2008.
On 12 January 2010, at 4:53pm local time, Haiti was struck by a magnitude-7.0 earthquake. This was the country's most severe earthquake in over 200 years. The 2010 Haiti earthquake was reported to have left up to 316,000 people dead and 1.6 million homeless, though later reports found these numbers to have been grossly inflated, and put the death toll between 46,000 and 85,000. The country has yet to recover from the 2010 earthquake and subsequent Haiti cholera outbreak due to both the severity of the damage Haiti endured in 2010, as well as a government that was ineffective well before the earthquake.
General elections had been planned for January 2010, but were postponed due to the earthquake. The elections were held on 28 November 2010 for the senate, the parliament and the first round of the presidential elections. The run-off between Michel Martelly and Mirlande Manigat took place on 20 March 2011, and preliminary results, released on 4 April, named Michel Martelly the winner.
In 2013, Haiti called for European nations to pay reparations for slavery and established an official reparations commission.
Geography.
Haiti is on the western part of Hispaniola, the second largest island in the Greater Antilles. Haiti is the third largest country in the Caribbean behind Cuba and the Dominican Republic (the latter shares a 360 km border with Haiti). Haiti at its closest point is about 45 nmi away from Cuba and comprises the "horseshoe"-shape peninsula and because of this, it has a disproportionately long coastline and is "second" in length (1771 km) in the Greater Antilles. Cuba has the longest. 
Haiti lies mostly between latitudes 18° and 20°N (Tortuga island lies just north of 20°), and longitudes 71° and 75°W. Haiti's terrain consists mainly of rugged mountains interspersed with small coastal plains and river valleys. The climate is tropical, with some variation depending on altitude.
The northern region consists of the "Massif du Nord" (Northern Massif) and the "Plaine du Nord" (Northern Plain). The "Massif du Nord" is an extension of the "Cordillera Central" in the Dominican Republic. It begins at Haiti's eastern border, north of the Guayamouc River, and extends to the northwest through the northern peninsula. The lowlands of the "Plaine du Nord" lie along the northern border with the Dominican Republic, between the "Massif du Nord" and the North Atlantic Ocean. The central region consists of two plains and two sets of mountain ranges. The "Plateau Central" (Central Plateau) extends along both sides of the Guayamouc River, south of the "Massif du Nord". It runs from the southeast to the northwest. To the southwest of the "Plateau Central" are the "Montagnes Noires", whose most northwestern part merges with the "Massif du Nord". Its westernmost point is known as Cap Carcasse.
The southern region consists of the Plaine du Cul-de-Sac (the southeast) and the mountainous southern peninsula (also known as the Tiburon Peninsula). The Plaine du Cul-de-Sac is a natural depression that harbors the country's saline lakes, such as Trou Caïman and Haiti's largest lake, Étang Saumatre. The Chaîne de la Selle mountain range – an extension of the southern mountain chain of the Dominican Republic (the Sierra de Baoruco) – extends from the Massif de la Selle in the east to the Massif de la Hotte in the west. This mountain range harbors Pic la Selle, the highest point in Haiti at 2680 m.
The country's most important valley in terms of crops is the Plaine de l'Artibonite, which is oriented south of the Montagnes Noires. This region supports the country's (also Hispaniola's) longest river, the Riviere l'Artibonite, which begins in the western region of the Dominican Republic and continues most of its length through central Haiti and onward where it empties into the Golfe de la Gonâve. The eastern and central region of the island is a large elevated plateau. Haiti also includes various offshore islands. The island of Tortuga (Île de la Tortue) is located off the coast of northern Haiti. The arrondissement of La Gonâve is located on the island of the same name, in the Golfe de la Gonâve. Gonâve Island is moderately populated by rural villagers. Île à Vache (Cow Island), a lush island with many beautiful sights, is located off the tip of southwestern Haiti. Also part of Haiti are the Cayemites and Île d' Anacaona. La Navasse located 40 nmi west of Jérémie on the south west peninsula of Haiti, is subject to an ongoing territorial dispute with the United States.
Geology.
There are blind thrust faults associated with the Enriquillo-Plantain Garden fault system over which Haiti lies. After the Earthquake of 2010, there was no evidence of surface rupture and based on seismological, geological and ground deformation data.
The northern boundary of the fault is where the Caribbean tectonic plate shifts eastwards by about 20 mm per year in relation to the North American plate. The strike-slip fault system in the region has two branches in Haiti, the Septentrional-Oriente fault in the north and the Enriquillo-Plantain Garden fault in the south.
A 2007 earthquake hazard study by C. DeMets and M. Wiggins-Grandison noted that the Enriquillo-Plantain Garden fault zone could be at the end of its seismic cycle and concluded that a worst-case forecast would involve a 7.2 Mw earthquake, similar in size to the 1692 Jamaica earthquake. Paul Mann and a group including the 2006 study team presented a hazard assessment of the Enriquillo-Plantain Garden fault system to the 18th Caribbean Geologic Conference in March 2008, noting the large strain; the team recommended "high priority" historical geologic rupture studies, as the fault was fully locked and had recorded few earthquakes in the preceding 40 years. An article published in Haiti's "Le Matin" newspaper in September 2008 cited comments by geologist Patrick Charles to the effect that there was a high risk of major seismic activity in Port-au-Prince.
Haiti also has rare elements such as Gold, which can be found at The Mont Organisé gold mine.
Environment.
The soil erosion and deforestation have caused periodic and severe flooding in Haiti, as experienced, for example, on 17 September 2004. Earlier in May that year, floods had killed over 3,000 people on Haiti's southern border with the Dominican Republic.
There has been little marine, coastal, and river basin management. Forest cover in the steep hills surrounds Haiti's river basin retains soil, which in turn retains water from rainfall, reducing river flood peaks and conserving flows in the dry season. Haiti's forests covered 60 percent of the country as recently as fifty years ago, but today less than one percent of Haiti remains forested. 
Deforestation has resulted in much of the soil being released from the upper catchments. Many of Haiti's rivers are now highly unstable, changing rapidly from destructive flooding to inadequate flows. Scientists at the Columbia University's Center for International Earth Science Information Network (CIESIN) and the United Nations Environment Programme are working on the Haiti Regenerative Initiative an initiative aiming to reduce poverty and natural disaster vulnerability in Haiti through ecosystem restoration and sustainable resource management.
Flora.
In 1925, Haiti was lush, with 60% of its original forest covering the lands and mountainous regions. Since then, Haiti's residents have cut down an estimated 98% of its original forest cover for use as fuel for cookstoves, destroying fertile farmland soils and contributing to desertification.
Demographics.
Although Haiti averages approximately 350 people per square kilometer (~900 per sq mi.), its population is concentrated most heavily in urban areas, coastal plains, and valleys. Haiti's population was about 10.1 million according to UN 2011 estimates, with half of the population younger than age 20. In 1950 the first formal census gave a total population of 3.1 million.
Most modern Haitians are descendants of former black African slaves, including Mulattoes who are of multiracial admixture. The remainder are of European and Levantine/Semitic stock, the descendants of settlers (colonial remnants and contemporary immigration during WWI and WWII). Haitians of East Asian descent or East Indian origin number approximately 400+.
Millions of Haitians live abroad in the United States, Dominican Republic, Cuba, Canada (primarily Montreal), Bahamas, France, French Antilles, the Turks and Caicos, Jamaica, Puerto Rico, Venezuela, Brazil and French Guiana. There are an estimated 881,500 in the United States, 800,000 in the Dominican Republic, 300,000 in Cuba, 100,000 in Canada, 80,000 in France, and up to 80,000 in the Bahamas. But there are also smaller Haitian communities in many other countries, including Chile, Switzerland, Japan and Australia.
Casta discrimination.
Due to the racial caste system instituted in colonial Haiti, Haitian mulattoes became the nation's social elite and racially privileged. Numerous leaders throughout Haiti's history have been mulattoes. Comprising 5% of the nation's population, mulattoes have retained their preeminence, evident in the political, economic, social and cultural hierarchy in Haiti. Alexandre Pétion, born to a Haitian mother and a wealthy French father, was the first President of the Republic of Haiti.
Religion.
Religion in Haiti 
   Catholicism
 (80%)   Protestantism
 (16%)  other religion (3%)  no religion (1%)
The 2015 CIA Factbook reported that around 80% of Haitians profess to be Catholics while Protestants made up about 16% of the population (Baptist 10%, Pentecostal 4%, Adventist 1%, other 1%). Other sources put the Protestant population higher than this, suggesting that it might have formed one-third of the population in 2001.
Haitian Cardinal Chibly Langlois is president of the National Bishops Conference of the Catholic Church. Some Haitians combine their Catholicism with elements of vodou.
Minority religions in Haiti include Islam, Bahá'í Faith, Judaism, and Buddhism.
Languages.
The two official languages of Haiti are French and Haitian Creole. French is the principal written and administratively authorized language (as well as the main language of the press) and is spoken by 40% of Haitians. It is spoken by all educated Haitians, is the medium of instruction in most schools, and is used in the business sector. It is also used in ceremonial events such as weddings, graduations and church masses. Haiti is one of two independent nations in the Americas (along with Canada) to designate French as an official language; the other French-speaking areas are all overseas "départements", or "collectivités," of France. Haitian Creole, which has recently undergone a standardization, is spoken by virtually the entire population of Haiti. Haitian Creole is one of the French-based creole languages. Its vocabulary is 90% derived from French, but its grammar and influences are from some West African, Taino, Spanish, and Portuguese languages. Haitian Creole is related to the other French creoles, but most closely to Antillean Creole and Louisiana Creole.
Emigration.
Emigrants from Haiti have constituted a segment of American and Canadian society, before the independence of Haiti from France in 1804.
Haiti's proximity to the United States, and its status as a free black republic in the years before the American Civil War, have contributed to this relationship. Many influential early American settlers and black freemen, including Jean Baptiste Point du Sable and W. E. B. Du Bois, were of Haitian origin.
Jean Baptiste Point du Sable, an immigrant from Saint-Domingue (now the Republic of Haiti), founded the first nonindigenous settlement in what is now Chicago, Illinois, the third largest city in the United States. The state of Illinois and city of Chicago declared du Sable the founder of Chicago on 26 October 1968.
Government and politics.
The government of Haiti is a semi-presidential republic, a multiparty system wherein the President of Haiti is head of state elected directly by popular elections. The Prime Minister acts as head of government and is appointed by the President, chosen from the majority party in the National Assembly. Executive power is exercised by the President and Prime Minister who together constitute the government. In 2013, the annual budget was US$1 billion.
Legislative power is vested in both the government and the two chambers of the National Assembly of Haiti. The government is organized unitarily, thus the central government "delegates" powers to the departments without a constitutional need for consent. The current structure of Haiti's political system was set forth in the Constitution of Haiti on 29 March 1987. The current president is Michel Martelly.
Haitian politics have been contentious: since independence, Haiti has suffered 32 coups. Haiti is the only country in the Western Hemisphere to undergo a successful slave revolution, but a long history of oppression by dictators – including François Duvalier and his son Jean-Claude Duvalier – has markedly affected the nation. France, the United States and other Western countries have repeatedly intervened in Haitian politics since the country's founding, sometimes at the request of one party or another. Along with international financial institutions, they have imposed large quantities of debt – so much that foreign debt payments have rivaled the available government budget for social sector spending. They also enforced trade policies that have broken down the Haitian government's ability to protect the local economy, forcing greater dependence on imports and eroding economic self-sufficiency.
According to a Corruption Perceptions Index report in 2006, there is a strong correlation between corruption and poverty and Haiti ranked first of all countries surveyed for of levels of perceived domestic corruption. The International Red Cross reports that seven out of ten Haitians live on less than US$2 a day, however, stated below "such statitical estimations should be looked upon very skeptically because of the fact that the average Haitian and Haitian family has to and does spend a lot more than that daily. The disconnect likely lies in the fact that these are estimates based on surveys conducted by asking individuals what their incomes are; in the Haitian culture it is very unlikely that one will receive a truthful and accurate answer to such a personal question. For various reasons individuals will not tell the truth on such a private matter. For some it is because "it's none of your business," for others, they will simply exaggerate their poor situation in hopes that some type of financial aide will be gained or rendered to them".
Cité Soleil in Port-au-Prince, one of the biggest slums in the Northern Hemisphere, has been called "the most dangerous place on Earth" by the United Nations. Many residents are supporters of former Haitian President Jean-Bertrand Aristide, who, according to the BBC, "accused the US of forcing him out – an accusation the US rejected as 'absurd'".
Jean-Bertrand Aristide was initially denied access to Haiti by Haitian immigration authorities, despite issuing appeals for entrance to his supporters and international observers. The world's most prominent governments did not overtly oppose such appeals, nor did they support them; an unnamed analyst "close to the Haitian government" quoted in several media sources – including "The New York Times" – is reported to have said: "Aristide could have 15 passports and he's still not going to come back to Haiti ... France and the United States are standing in the way." However, Aristide finally returned to Haiti on 18 March 2011, days before the 2011 presidential election.
The first round of the 2010 general election was held in December. Mirlande Manigat and Jude Celestin qualified for the second round of the presidential election, but its results were contested. Some people said that the first round was a fraud and that Michel Martelly should replace Jude Celestin, René Préval's chosen successor. There was some violence between the contending parties. On 4 April 2011, the Provisional Electoral Council announced preliminary results indicating that Martelly had won the presidential election.
In February 2012, Haiti signaled it would seek to upgrade its observer status to full associate member status of the African Union (AU). At its next summit in June 2013, the AU plans to upgrade Haiti's status from observer to associate.
In 2010, the Haitian National Police force numbered 7,000. The legal system for torts is based on a version of the Napoleonic Code.
The Institute for the Protection of National Heritage has preserved 33 historical monuments and the historic center of Cap-Haïtien.
Cabinet.
The executive function is divided into ministries, each led by a Minister appointed by the Prime Minister and confirmed by Parliament:
Military.
Haiti's Ministry of Defense is the main body of their armed forces. The former Haitian Armed Forces were demobilized in 1995. The current defense force for Haiti is the Haitian National Police, which has a highly trained SWAT team, and works alongside the Haitian Coast Guard.
Law enforcement and crime.
Haiti has consistently ranked among the most corrupt countries in the world on the Corruption Perceptions Index. It is estimated that President "Baby Doc" Duvalier, his wife Michelle, and their agents stole US$504 million from the country's treasury between 1971 and 1986.
Similarly, some media outlets alleged that millions were stolen by former president Jean-Bertrand Aristide. In March 2004, at the time of Aristide's being kidnapped, a BBC article wrote that the Bush administration State Department stated that Aristide had been involved in drug trafficking. The BBC also described pyramid schemes, in which Haitians lost hundreds of millions in 2002, as the "only real economic initiative" of the Aristide years.
Conversely, according to the 2013 United Nations Office on Drugs and Crime (UNODC) report, murder rates in Haiti (10.2 per 100,000) are far "below" the regional average (26 per 100,000); less than 1/4 that of Jamaica (39.3 per 100,000) and nearly 1/2 that of the Dominican Republic (22.1 per 100,000), making it among the safer countries in the region. In large part, this is due to the country's ability to fulfill a pledge by increasing its national police yearly by 50%, a four-year initiative that was started in 2012. In addition to the yearly recruits, the Haitian National Police (HNP) has been using innovative technologies to crackdown on crime. A notable bust in recent years, led to the dismantlement of the largest kidnapping ring in the country with the use of an advanced software program developed by a Westpoint-trained Haitian official that proved to be so effective that it has led to its foreign advisers to make inquiries.
In 2010, the New York City Police Department (NYPD) has sent a team of veteran officers to Haiti to assist in the rebuilding of its police force with special training in investigative techniques, strategies to improve the anti-kidnapping personnel and community outreach to build stronger relationships with the public especially among the youth. It has also helped the HNP set up a police unit in the center of Delmas, a neighborhood of Port-au-Prince. 
In 2012 and 2013, 150 HNP officers received specialized training funded by the U.S. government, which also contributed to the infrastructure and communications support by upgrading radio capacity and constructing new police stations from the most violent-prone neighborhoods of Cité Soleil and Grande Ravine in Port-au-Prince to the new northern industrial park at Caracol.
Departments, arrondissements and communes.
Administratively, Haiti is divided into ten departments. The departments are listed below, with the departmental capital cities in parentheses.
The departments are further divided into 41 arrondissements and 133 communes. These serve as, respectively, second- and third-level administrative divisions.
Economy.
Haiti's purchasing power parity GDP fell 8% in 2010 (from US$12.15 billion to US$11.18 billion) and the GDP per capita remained unchanged at PPP US$1,200. Despite having a viable tourist industry, Haiti is one of the world's poorest countries and the poorest in the Americas region, with poverty, corruption, poor infrastructure, lack of health care and lack of education cited as the main sources. The economy receded due to the 2010 earthquake and subsequent outbreak of Cholera. The country ranked 145 of 182 countries in the 2010 United Nations Human Development Index, with 57.3% of the population being deprived in at least three of the HDI's poverty measures.
Following the disputed 2000 election and accusations about President Aristide's rule, US aid to the Haitian government was cut off between 2001 and 2004. After Aristide's departure in 2004, aid was restored and the Brazilian army led a United Nations Stabilization Mission in Haiti peacekeeping operation. After almost four years of recession, the economy grew by 1.5% in 2005. In September 2009, Haiti met the conditions set out by the IMF and World Bank's Heavily Indebted Poor Countries program to qualify for cancellation of its external debt.
More than 90 percent of the government’s budget comes from an agreement with Petrocaribe, a Venezuela-led oil alliance.
Foreign aid.
Foreign aid is indispensable to Haiti. Haiti received more than US$4 billion in aid from 1990 to 2003, including US$1.5 billion from the United States.
The largest donor is the US, followed by Canada and the European Union. In January 2010, following the earthquake, US President Barack Obama promised US$1.15 billion in assistance. European Union nations pledged more than €400 million (US$616 million).
According to the UN Office of the Special Envoy for Haiti, as of March 2012, of Humanitarian funding committed or disbursed by bilateral and multilateral donors in 2010 and 2011, only 1% has been pledged to the Haitian Government
According to the 2013 CIA World Factbook, the 2010 Haiti Earthquake inflicted an estimated US$7.8 billion in damage and caused the country's GDP to contract.
The United Nations states that in total US$13.34 billion has been earmarked for the crisis through 2020, though two years after the 2010 quake, less than half of that amount had actually been released, according to U.N. documents. As of 2015, the U.S. government has allocated US$4 billion; US$3 billion has already been spent, and the rest is dedicated to longer-term projects.
Former US President Bill Clinton's foundation contributed US$250k to a recycling initiative for a sister-program of "Ranmase Lajan" or "Picking Up Money" by use of reverse vending machines.
Trade.
Haiti had a large trade deficit of US$3 billion in 2011, or 41% of GDP. As of September 2014, Haiti recorded a trade deficit of US$226.27 million, or 2.5% of GDP.
Energy.
Haiti relies heavily on an oil alliance with Petrocaribe for much of its energy requirements. In recent years, Hydroelectric, Solar and wind energy have been explored as possible sustainable energy sources.
Personal income.
"The World Factbook" reports a shortage of skilled labor, widespread unemployment and underemployment, saying "more than two-thirds of the labor force do not have formal jobs." It is also often stated that three-quarters of the population lives on US$2 or less per day. Such statistical estimations should be viewed with skepticism because the average Haitian and Haitian family spends more than that daily. The former are estimates based on surveys conducted by asking individuals what their incomes are. In the Haitian culture it is very unlikely that one will receive a truthful and accurate answer to such a personal question. For some it is because "it's none of your business," for others, they will simply exaggerate their poor situation in hopes that some type of financial aid will be gained or rendered to them. Statistical sampling, foreign to Haiti, have been used irrespective of its appropriateness for the culture and situation at hand.
With respect to the business environment reforms have had little effect because of widespread corruption and the inefficient judicial framework.
Haiti continues to exhibit the greatest income inequality in the continent, and is one of the most unequal countries in the world. The richest 20% of households earn 64% of the country’s total income, while the poorest 20% makes do with just 1%.
Between 2000 and 2012, the percentage of people living in extreme poverty —with one dollar or less a day— dropped from 31% to 24% at the national level, and from 20% to 5% in Port-au-Prince. More than 200,000 people have climbed out of poverty. There is a growing gap between Port-au-Prince and the rest of the country. More than 80% of those living in extreme poverty do so in rural areas. Families in the north and southwest of the country work hard to grow food, but they fail to earn enough. Extreme climatic events, lack of fertilizers, pesticides and seeds, and limited market access are just some of the impediments they face.
The World Bank estimates that over 80% of college graduates from Haiti were living abroad in 2004, with their remittances home representing 52.7% of Haiti's GDP.
Remittances are the primary source of foreign exchange, equaling nearly 20% of GDP in 2012. Haiti's economy was severely impacted by the 2010 Haiti earthquake which occurred on 12 January 2010.
Agriculture.
Haiti is the world's leading producer of vetiver, a root plant used to make luxury perfumes, essential oils and fragrances, providing for half the world's supply. Half of all Haitians work in the agricultural sector. Haiti relies upon imports for half its food needs and 80% of its rice. Haiti exports crops such as mangoes, cacao, coffee, papayas, mahogany nuts, spinach, and watercress. Agricultural products comprise 6% of all exports. In addition, local agricultural products include corn, beans, cassava, sweet potato, peanuts, pistachios, bananas, millet, pigeon peas, sugar cane, rice, sorghum, and wood.
Currency.
The Haitian gourde (HTG) is the national currency. The "Haitian dollar" equates to 5 gourdes ("goud"), which is a fixed exchange rate that exists in concept "only," but are commonly used as informal prices.
The vast majority of the business sector and individuals in Haiti will also accept U.S. dollars, though at the outdoor markets gourdes may be preferred. Locals may refer to the USD as "dollar américain" ("dola ameriken") or "dollar US" (pronounced "oos").
Tourism.
In 2012, the country received 950,000 tourists (mostly from cruise ships), and the industry generated US$200 million in 2012. In December 2012, the US State Department issued a travel warning about the country, noting that while thousands of American citizens safely visit Haiti each year, few foreign tourists had been victims of burglary, predominantly in the Port-au-Prince area. 
Several hotels were opened in 2012, including a Best Western Premier, a five-star Royal Oasis hotel by Occidental Hotel and Resorts in Pétionville, a four-star Marriott hotel in the Turgeau area of Port-au-Prince and other new hotel developments in Port-au-Prince, Les Cayes, Cap-Haïtien and Jacmel. Other tourist destinations include Île-à-Vache, Camp-Perrin, Pic Macaya.
The Haitian Carnival has been one of the most popular carnivals in the Caribbean. In 2010, the government decided to stage the event in a different city outside of Port-au-Prince every year in an attempt to decentralize the country. The National Carnival—usually held in one of the country's largest cities (i.e., Port-au-Prince, Cap-Haïtien or Les Cayes)—follows the also very popular Jacmel Carnival, which takes place a week earlier in February or March.
Caracol Industrial Park.
In 21 October 2012, Haitian President Michel Martelly, US Secretary of State Hillary Rodham Clinton, Bill Clinton, Richard Branson, Ben Stiller and Sean Penn inaugurated the 600 acre Caracol industrial park, the largest in the Caribbean. Costing US$300 million, the project, which includes a 10-megawatt power plant, a water-treatment plant and worker housing, is intended to transform the northern part of the country by creating 65,000 jobs.
The park is part of a "master plan" for Haiti's North and North-East departments, including the expansion of the Cap-Haitien International Airport to accommodate large international flights, the construction of an international Seaport in Fort-Liberté and the opening of the $50 million Roi Henri Christophe Campus of a new university in Limonade (near Cap-Haitien) on 12 January 2012.
South Korean clothing manufacturer Sae-A Trading Co. Ltd, one of the park's main tenants, has created 5,000 permanent jobs out of the 20,000 projected and has built 8,600 houses in the surrounding area for its workers. The industrial park ultimately has the potential to create as many as 65,000 jobs once fully developed.
Infrastructure.
Transportation.
Haiti has two main highways that run from one end of the country to the other. The northern highway, Route Nationale No. 1 (National Highway One), originates in Port-au-Prince, winding through the coastal towns of Montrouis and Gonaïves, before reaching its terminus at the northern port Cap-Haïtien. The southern highway, Route Nationale No. 2, links Port-au-Prince with Les Cayes via Léogâne and Petit-Goâve.
According to the Washington Post, "Officials from the U.S. Army Corps of Engineers said Saturday [23 January 2010] that they assessed the damage from the 12 Jan. quake in Port-au-Prince, Haiti, and found that many of the roads aren't any worse than they were before because they've always been in poor condition."
The port at Port-au-Prince, Port international de Port-au-Prince, has more registered shipping than any of the other dozen ports in the country. The port's facilities include cranes, large berths, and warehouses, but these facilities are not in good condition. The port is underused, possibly due to the substantially high port fees. The port of Saint-Marc is currently the preferred port of entry for consumer goods coming into Haiti. Reasons for this may include its location away from volatile and congested Port-au-Prince, as well as its central location relative to numerous Haitian cities.
During the 2010 earthquake, the Port-au-Prince port suffered widespread damage, impeding aid to the victims. The main pier caved in and fell into the water. One of the main cranes also collapsed in the water. Port access roads were severely damaged as well.
In the past, Haiti used rail transport, but, today, railroads are no longer in use, due to their replacement by other forms of transportation.
Airports.
Toussaint Louverture International Airport is located 10 km North/North East of Port-au-Prince. It has Haiti's main jetway, and along with Hugo Chavez International Airport located near Cap-Haïtien, handles the vast majority of the country's international flights. To travel on from the international airport at Port-au-Prince to other Haitian cities requires boarding a smaller plane. Cities such as Jacmel, Jérémie, Les Cayes, and Port-de-Paix have airports that are accessible by smaller aircraft. Companies that fly to these airports include: Caribintair, Sunrise Airways and Tortug' Air.
In 2013, plans for the development of an international airport on Île-à-Vache were introduced by the Prime Minister.
Bus service.
Tap tap buses are colorfully painted buses or pick-up trucks that serve as share taxis. The "tap tap" name comes from the sound of passengers tapping on the metal bus body to indicate they want off. These vehicles for hire are often privately owned and extensively decorated. They follow fixed routes, do not leave until filled with passengers, and riders can usually disembark at any point. It is a typically Haitian form of art.
In August 2013, the first coach bus prototype was made in Haiti.
Electricity.
In Haiti, 12.5% of the population have access to electricity officially, although the Ministry of Public Works estimated that the coverage could be around 25% when irregular connections are considered. In the capital, Port-au-Prince, the access rate is about 45%.
Some towns in Haiti, such as the capital of the Nord-Est Department Fort-Liberté, have an electricity distribution network, but have been effectively abandoned by the Haiti Electric Company (EdH) national utility for about a decade. Users thus have to rely entirely on small, privately owned generators to meet their electricity demand.
Communications.
In Haiti, communications include the radio, television, fixed and mobile telephones, and the Internet. Haiti ranked last among North American countries in the World Economic Forum's Network Readiness Index (NRI) – an indicator for determining the development level of a country's information and communication technologies. Haiti ranked number 143 out of 148 overall in the 2014 NRI ranking, down from 141 in 2013.
Culture.
Haitian culture is largely a mixture of French, Spanish, and African influences, with sizeable contributions from the indigenous Taíno culture. The country's customs essentially are a blend of cultural beliefs that derived from the various ethnic groups that inhabited the island of Hispaniola. Haiti's culture is greatly reflected in its paintings, music, and literature. Galleries and museums in the United States and France have exhibited the works of the better-known artists to have come out of Haiti.
Art.
Haitian art is distinctive, particularly painting and sculpture. Brilliant colors and sly humor characterize Haitian art. Frequent subjects in Haitian art include big, delectable foods, lush landscapes, market activities, jungle animals, rituals, dances, and gods. Artists frequently paint in fables. People are disguised as animals and animals are transformed into people. As a result of a deep history and strong African ties, symbols take on great meaning within Haitian society. For example, a rooster often represents Aristide and the red and blue colors of the Haitian flag often represent his Lavalas party. Many artists cluster in 'schools' of painting, such as the Cap-Haïtien school, which features depictions of daily life in the city, the Jacmel School, which reflects the steep mountains and bays of that coastal town, or the Saint-Soleil School, which is characterized by abstracted human forms and is heavily influenced by vodou symbolism.
Music and dance.
Haitian music combines a wide range of influences drawn from the many people who have settled on this Caribbean island. It reflects French, African rhythms, Spanish elements and others who have inhabited the island of Hispaniola and minor native Taino influences. Styles of music unique to the nation of Haiti include music derived from Vodou ceremonial traditions, Rara parading music, Twoubadou "ballads", Mini-jazz rock bands, Rasin movement, Hip hop Kreyòl, Méringue, and Compas. Youth attend parties at nightclubs called "discos", (pronounced "deece-ko"), and attend "Bal". This term is the French word for ball, as in a formal dance.
"Compas (konpa)" (also known as "compas direct" in French, or "konpa dirèk" in creole) is a complex, ever-changing music that arose from African rhythms and European ballroom dancing, mixed with Haiti's bourgeois culture. It is a refined music, with méringue as its basic rhythm. Haiti had no recorded music until 1937 when Jazz Guignard was recorded non-commercially.
Literature.
Dating back to the days of its independence, Haiti has always been a literary nation, that has produced a number of poetry and plays of international reputation. Despite attempts to write in Haitian Creole dating back to the eighteenth century due to its unofficial status, French has always been the exclusive literary language of Haiti. With the recognition of Creole as an official language, more and more novels, poems, and plays are being written in Creole. In 1975, the first novel written entirely in Haitian Creole was published entitled "Dezafi" written by Franketienne describing a poetic picture of Haitian life.
Cuisine.
Haitian cuisine originates from several culinary styles from the various historical ethnic groups that populated the western portion of the island of Hispaniola. Haitian cuisine is similar to the rest of the Latin-Caribbean (the French and the Spanish-speaking countries of the Antilles), however it differs in several ways from its regional counterparts. While the cuisine is unpretentious and simple, the flavors are bold and spicy that demonstrate a primary influence of African culinary aesthetic, paired with a very French sophistication with notable derivatives coming from native Taíno and Spanish techniques. Though similar to other cooking styles in the region, it carries a uniqueness native to the country and an appeal to many visitors to the island. Haitians often use peppers and other strong flavorings.
Dishes tend to be seasoned liberally. Consequently Haitian cuisine is often moderately spicy. In the country, however, several foreign cuisines have been introduced. These include Levantine from Arab migration to Haiti. Rice and beans in several differing ways are eaten throughout the country regardless of location, becoming a sort of national dish. They form the staple diet, which consists of a lot of starch and is high in carbohydrates. Rural areas, with better access to agricultural products, have a larger variety of choices.
One such dish is mais moulu ("mayi moulen"), which is comparable to cornmeal that can be eaten with sauce pois ("sòs pwa"), a bean sauce made from one of many types of beans such as kidney, pinto, chickpeas, or pigeon peas (known in some countries as gandules). Mais moulin can be eaten with fish (often red snapper), or alone depending on personal preference. Some of the many plants used in Haitian dishes include tomato, oregano, cabbage, avocado, bell peppers. A popular food is banane pesée ("ban-nan'n peze"), flattened plantain slices fried in cooking oil (known as tostones in the Spanish speaking Latin American countries). It is eaten both as a snack and as part of a meal is, often eaten with tassot or griot, which are deep-fried goat and pork respectively.
Traditionally, the food that Haitians eat on the independence day (1 January) is Soup Joumou.
Haiti is also known internationally for its rum. Rhum Barbancourt is one of the nation's exports and is regarded highly by international standards.
Architecture.
Monuments include the Sans-Souci Palace and the Citadelle Laferrière, inscribed as a World Heritage site in 1982. Situated in the Northern Massif du Nord, in one of Haiti's National Parks, the structures date from the early 19th century. The buildings were among the first built after Haiti's independence from France.
The Citadelle Laferrière, the largest fortress in the Americas, is located in northern Haiti. It was built between 1805 and 1820 and is today referred to by some Haitians as the eighth wonder of the world.
Jacmel, a colonial city that was tentatively accepted as a World Heritage site, was extensively damaged by the 2010 Haiti earthquake.
Museums.
The anchor of Christopher Columbus' largest ship, the "Santa María" now rests in the Musée du Panthéon National Haïtien (MUPANAH), in Port-au-Prince, Haiti.
Folklore and mythology.
Haiti is known for its folklore traditions. The country has tales that are part of the Haitian Vodou tradition.
National holidays and festivals.
The most festive time of the year in Haiti is during Carnival (referred to as "Kanaval" in Haitian Creole or Mardi Gras) in February. There is music, parade floats, and dancing and singing in the streets. Carnival week is traditionally a time of all-night parties.
Rara is a festival celebrated before Easter. The festival has generated a style of Carnival music.
Sports.
Association Football is the most popular sport in Haiti with hundreds of small football clubs competing at the local level. Basketball is growing in popularity. Hundreds of small football clubs compete at the local level. Stade Sylvio Cator is the multi-purpose stadium in Port-au-Prince, where it is currently used mostly for association football matches that fits a capacity of 30,000 people. In 1974, the Haiti national football team were only the second Caribbean team to make the World Cup (after Cuba's entry in 1938). They lost in the opening qualifying stages against three of the pre-tournament favorites; Italy, Poland, and Argentina. The national team won the 2007 Caribbean Nations Cup.
Haiti has participated in the Olympic Games since the year 1900 and won a number of medals. Haitian soccer player Joe Gaetjens played for the United States national team in the 1950 FIFA World Cup, scoring the winning goal in the 1–0 upset of England.
Education.
The educational system of Haiti is based on the French system. Higher education, under the responsibility of the Ministry of Education, is provided by universities and other public and private institutions. Haiti counts 15,200 primary schools, of which 90% are non-public and managed by communities, religious organizations or NGOs. The enrollment rate for primary school is 67%, and fewer than 30% reach 6th grade. Secondary schools enroll 20% of eligible-age children. Charity organizations, including Food for the Poor and Haitian Health Foundation, are building schools for children and providing necessary school supplies. Haiti's literacy rate is 52.9%.
The January 2010 earthquake was a major setback for education reform in Haiti as it diverted limited resources to survival. Literacy levels remain near 50%. Haiti is one of the lowest-ranked countries in the world, 177th out of 186, for national spending on education.
Many reformers have advocated the creation of a free, public and universal education system for all primary school-age students in Haiti. The Inter-American Development Bank estimates that the government will need at least US$3 billion to create an adequately funded system.
Higher education.
Upon successful graduation of secondary school, students may continue into higher education. The higher education schools in Haiti include the University of Haiti. There are also medical schools and law schools offered at both the University of Haiti and abroad. Presently, Brown University is cooperating with L'Hôpital Saint-Damien in Haiti to coordinate a pediatric health care curriculum.
Health.
In the past, children's vaccination rates have been low—as of 2012, 60% of the children in Haiti under the age of 10 were vaccinated, compared to rates of childhood vaccination in other countries in the 93-95% range. Recently there have been mass vaccination campaigns claiming to vaccinate as many as 91% of a target population against specific diseases (measles and rubella in this case). Most people have no transportation or access to Haitian hospitals. 
The World Health Organization cites diarrheal diseases, HIV/AIDS, meningitis, and respiratory infections as common causes of death in Haiti. Ninety percent of Haiti's children suffer from waterborne diseases and intestinal parasites. HIV infection is found in 1.8% of Haiti's population. The incidence of tuberculosis (TB) in Haiti is more than ten times as high as in the rest of Latin America. Approximately 30,000 Haitians fall ill with malaria each year.
Most people living in Haiti are at high risk for major infectious diseases. Food or water-borne diseases include bacterial and protozoal diarrhea, typhoid fever and hepatitis A and E; common vector-borne diseases are dengue fever and malaria; water-contact diseases include leptospirosis. Roughly 75% of Haitian households lack running water. Unsafe water, along with inadequate housing and unsanitary living conditions, contributes to the high incidence of infectious diseases. There is a chronic shortage of health care personnel and hospitals lack resources, a situation that became readily apparent after the January 2010 earthquake. The infant mortality rate in Haiti in 2013 was 55 deaths per 1,000 live births, compared to a rate of 6 per 1,000 in other countries.

</doc>
<doc id="13374" url="http://en.wikipedia.org/wiki?curid=13374" title="History of Haiti">
History of Haiti

The recorded history of Haiti began on 5 December 1492 when the European navigator Christopher Columbus happened upon a large island in the region of the western Atlantic Ocean that later came to be known as the Caribbean. It was inhabited by the Taíno, an Arawakan people, who variously called their island "Ayiti", "Bohio", or "Kiskeya" "(Quisqueya)". Columbus promptly claimed the island for the Spanish Crown, naming it "La Isla Española" ("the Spanish Island"), later Latinized to "Hispaniola".
Pre-Spanish history.
Successive waves of Arawak migrants, moving northward from the Orinoco delta in South America, settled the islands of the Caribbean. Around AD 600, the Taíno Indians, an Arawak culture, arrived on the island, displacing the previous inhabitants. They were organized into "cacicazgos" (chiefdoms), each led by a "cacique" (chief).
The Taíno people called the island "Quisqueya" (mother of all lands) and "Ayiti" (land of high mountains). At the time of Columbus's arrival in 1492, the island's territory consisted of five chiefdoms: Marién, Maguá, Maguana, Jaragua, and Higüey. Two of these chiefdoms, Marien and Jaragua, were on the territory of present-day Haiti. Guacanagarix, who ruled Marien from his capital El Guarico near present-day Cap-Haïtien, met Columbus and gave him permission to construct La Navidad. Jaragua was the largest caique on the island and ruled by Bohechío and his sister Anacaona, who ruled from its capital Yaguana near present-day Léogâne, and later came into conflict with the Spanish.
Spanish Hispaniola - (1492–1625).
Christopher Columbus established the settlement, La Navidad, near the modern town of Cap-Haïtien. It was built from the timbers of his wrecked ship Santa María, during his first voyage in December 1492. When he returned in 1493 on his second voyage he found the settlement had been destroyed and all 39 settlers killed. Colombus continued east and founded a new settlement at La Isabela on the territory of the present-day Dominican Republic in 1493. The capital of the colony was moved to Santo Domingo in 1496, on the south west coast of the island also in the territory of the present-day Dominican Republic. The Spanish returned to western Hispaniola in 1502, establishing a settlement at Yaguana, near modern-day Léogâne. A second settlement was established on the north coast in 1504 called Puerto Real near modern Fort-Liberté – which in 1578 was relocated to a nearby site and renamed Bayaha.
Following the arrival of Europeans, La Hispaniola's indigenous population suffered near extinction, in possibly the worst case of depopulation in the Americas. A commonly accepted hypothesis attributes the high mortality of this colony in part to Old World diseases to which the natives had no immunity. A small number of Taínos were able to survive and set up villages elsewhere. Spanish interest in Hispaniola began to wane in the 1520s, as more lucrative gold and silver deposits were found in Mexico and South America. Thereafter, the population of Spanish Hispaniola grew at a slow pace.
The settlement of Yacanagua was burnt to the ground three times in its just over a century long existence as a Spanish settlement, first by French pirates in 1543, again on 27 May 1592 by a 110 strong landing party from a 4 ship English naval squadron led by Christopher Newport in his flagship Golden Dragon, who destroyed all 150 houses in the settlement, and finally by the Spanish themselves in 1605, for reasons set out below.
In 1595, the Spanish, frustrated by the twenty-year rebellion of their Dutch subjects, closed their home ports to rebel shipping from the Netherlands, cutting them off from the critical salt supplies necessary for their herring industry. The Dutch responded by sourcing new salt supplies from Spanish America where colonists were more than happy to trade. So large numbers of Dutch traders/pirates joined their English and French brethren trading on the remote coasts of Hispaniola. In 1605, Spain was infuriated that Spanish settlements on the northern and western coasts of the island persisted in carrying out large scale and illegal trade with the Dutch, who were at that time fighting a war of independence against Spain in Europe and the English, a very recent enemy state, and so decided to forcibly resettle their inhabitants closer to the city of Santo Domingo. This action, known as the "Devastaciones de Osorio", proved disastrous; more than half of the resettled colonists died of starvation or disease, over 100,000 cattle were abandoned, and many slaves escaped. Five of the existing thirteen settlements on the island were brutally razed by Spanish troops including the two settlements on the territory of present day Haiti, La Yaguana, and Bayaja. Many of the inhabitants fought, escaped to the jungle, or fled to the safety of passing Dutch ships This Spanish action was counterproductive as English, Dutch, and French pirates were now free to establish bases on the island's abandoned northern and western coasts, where wild cattle were now plentiful and free.
French Saint-Domingue (1625–1789).
The Foundation of a Colony (1625–1711).
French buccaneers established a settlement on the island of Tortuga in 1625, and were soon joined by like-minded English and Dutch privateers and pirates, who formed a lawless international community that survived by preying on Spanish ships and hunting wild cattle. Although the Spanish destroyed the buccaneers' settlements in 1629, 1635, 1638 and 1654, on each occasion they returned. In 1655, the newly established English administration on Jamaica sponsored the re-occupation of Tortuga under Elias Watts as Governor. In 1660, the English made the mistake of replacing Watts as Governor by a Frenchman Jeremie Deschamps, on condition he defended English interests. Deschamps on taking control of the island proclaimed for the King of France, set up French colours, and defeated several English attempts to reclaim the island. It is from this point in 1660 that unbroken French rule in Haiti begins.
In 1663, Deschamps founded a French settlement Léogâne on the western coast of the island on the abandoned site of the former Spanish town of Yaguana.
In 1664, the newly established French West India Company took control of the new colony, and France formally claimed control of the western portion of the island of Hispaniola. In 1665, they established a French settlement on the mainland of Hispaniola opposite Tortuga at Port-de-Paix. In 1670, the headland of Cap Français (now Cap-Haïtien), was settled further to the east along the northern coast. In 1676, the colonial capital was moved from Tortuga to Port-de-Paix. In 1684, the French and Spanish signed the Treaty of Ratisbon that included provisions to suppress the actions of the Caribbean privateers, which effectively ended the era of the buccaneers on Tortuga, many being employed by the French Crown to hunt down any of their former comrades who preferred to turn outright pirate. Under the 1697 Treaty of Ryswick, Spain officially ceded the western three-eighths of Hispaniola to France which renamed the colony Saint-Domingue. By that time, planters outnumbered buccaneers and, with the encouragement of Louis XIV, they had begun to grow tobacco, indigo, cotton, and cacao on the fertile northern plain, thus prompting the importation of [African slaves],the ancestors of today's Haitians. Slave insurrections were frequent and some slaves escaped to the mountains where they were met by what would be one of the last generations of Taíno natives. After the last Taíno (Arawak) died, the full-blooded Arawak population on the island was "falsely said to be extinct." Today, many people are in search of their Taíno Arawak roots, some as a spiritual movement, some as a political movement, some as a cultural movement, though none are so far acknowledged as autochthones by the political governments on either side of Hispaniola and the split between the two sides of the island has so far continued.
The Pearl of the Antilles (1711–89).
In 1711, the city of Cap-Français was formally established by Louis XIV and took over as capital of the colony from Port-de-Paix. In 1726, the city of Les Cayes was founded on the Southern coast which became the biggest settlement in the south. In 1749, the city of Port-au-Prince was established on the West coast, which in 1770 took over as the capital of the colony from Cap-Français, however that same year the 1770 Port-au-Prince earthquake and tsunami destroyed the city killing 200 people immediately, and 30,000 later from famine and disease brought on by the natural disaster. This was the second major earthquake to hit Saint-Domingue as it followed the 1751 Port-au-Prince earthquake which had left only a single stone built building standing in the town.
Prior to the Seven Years' War (1756–63), the economy of Saint-Domingue gradually expanded, with sugar and, later, coffee becoming important export crops. After the war, which disrupted maritime commerce, the colony underwent rapid expansion. In 1767, it exported 72 million pounds of raw sugar and 51 million pounds of refined sugar, one million pounds of indigo, and two million pounds of cotton. Saint-Domingue became known as the "Pearl of the Antilles" – one of the richest colonies in the 18th century French empire. By the 1780s, Saint-Domingue produced about 40 percent of all the sugar and 60 percent of all the coffee consumed in Europe. This single colony, roughly the size of Maryland or Belgium, produced more sugar and coffee than all of Britain's West Indian colonies combined.
The labor for these plantations was provided by an estimated 790,000 African slaves (accounting in 1783–91 for a third of the entire Atlantic slave trade). Between 1764 and 1771, the average importation of slaves varied between 10 000–15 000, by 1786 about 28 000, and, from 1787 onward, the colony received more than 40 000 slaves a year. However, the inability to maintain slave numbers without constant resupply from Africa meant the slave population, by 1789, totaled 500 000, ruled over by a white population that, by 1789, numbered only 32 000. At all times, a majority of slaves in the colony were African-born, as the brutal conditions of slavery prevented the population from experiencing growth through natural increase . African culture thus remained strong among slaves to the end of French rule, in particular the folk-religion of Vodou, which commingled Catholic liturgy and ritual with the beliefs and practices of Guinea, Congo, and Dahomey. Slave traders scoured the Atlantic coast of Africa, and the slaves who arrived came from hundreds of different tribes, their languages often mutually incomprehensible.
To regularize slavery, in 1685 Louis XIV enacted the "Code Noir", which accorded certain human rights to slaves and responsibilities to the master, who was obliged to feed, clothe, and provide for the general well-being of their slaves. The "code noir" also sanctioned corporal punishment, allowing masters to employ brutal methods to instill in their slaves the necessary docility, while ignoring provisions intended to regulate the administration of punishments. A passage from Henri Christophe's personal secretary, who lived more than half his life as a slave, describes the crimes perpetrated against the slaves of Saint-Domingue by their French masters:
Have they not hung up men with heads downward, drowned them in sacks, crucified them on planks, buried them alive, crushed them in mortars? Have they not forced them to eat excretement? And, having flayed them with the lash, have they not cast them alive to be devoured by worms, or onto anthills, or lashed them to stakes in the swamp to be devoured by mosquitoes? Have they not thrown them into boiling cauldrons of cane syrup? Have they not put men and women inside barrels studded with spikes and rolled them down mountainsides into the abyss? Have they not consigned these miserable blacks to man-eating dogs until the latter, sated by human flesh, left the mangled victims to be finished off with bayonet and poniard?"
Thousands of slaves found freedom by fleeing from their masters, forming communities of maroons and raiding isolated plantations. The most famous was Mackandal, a one-armed slave, originally from Guinea, who escaped in 1751. A Vodou Houngan (priest), he united many of the different maroon bands. He spent the next six years staging successful raids and evading capture by the French, reputedly killing over 6,000 people, while preaching a fanatic vision of the destruction of white civilization in St. Domingue. In 1758, after a failed plot to poison the drinking water of the plantation owners, he was captured and burned alive at the public square in Cap-Français.
Saint-Domingue also had the largest and wealthiest free population of color in the Caribbean, the "gens de couleur" (French, "people of color"). The mixed-race community in Saint-Domingue numbered 25,000 in 1789. First-generation gens de couleur were typically the offspring of a male, French slaveowner and an African slave chosen as a concubine. In the French colonies, the semi-official institution of "plaçage" defined this practice. By this system, the children were free people and could inherit property, thus originating a class of "mulattos" with property and some with wealthy fathers. This class occupied a middle status between African slaves and French colonists. Africans who attained freedom also enjoyed status as gens de couleur.
As numbers of "gens de couleur" grew, the French rulers enacted discriminatory laws. Statutes forbade "gens de couleur" from taking up certain professions, marrying whites, wearing European clothing, carrying swords or firearms in public, or attending social functions where whites were present. However, these regulations did not restrict their purchase of land, and many accumulated substantial holdings and became slave-owners. By 1789, they owned one-third of the plantation property and one-quarter of the slaves of Saint-Domingue. Central to the rise of the "gens de couleur" planter class was the growing importance of coffee, which thrived on the marginal hillside plots to which they were often relegated. The largest concentration of "gens de couleur" was in the southern peninsula, the last region of the colony to be settled, owing to its distance from Atlantic shipping lanes and its formidable terrain, with the highest mountain range in the Caribbean.
Revolutionary period (1789–1804).
Ogé's revolt (1789–91).
The outbreak of revolution in France in the summer of 1789 had a powerful effect on the colony. While the French settlers debated how new revolutionary laws would apply to Saint-Domingue, outright civil war broke out in 1790 when the free men of color claimed they too were French citizens under the terms of the Declaration of the Rights of Man and of the Citizen. Ten days before the fall of the Bastille, in July 1789, the French National Assembly had voted to seat six delegates from Saint-Domingue. In Paris, a group of wealthy mulattoes, led by Julien Raimond and Vincent Ogé, unsuccessfully petitioned the white planter delegates to support mulatto claims for full civil and political rights. Through the efforts of a group called "Société d'Amis des Noirs", of which Raimond and Ogé were prominent leaders, in March 1790 the National Assembly granted full civic rights to the "gens de couleur.'
Vincent Ogé traveled to St. Domingue to secure the promulgation and implementation of this decree, landing near Cap-Français (now Cap-Haïtien) in October 1790 and petitioning the royal governor, the Comte de Peynier. After his demands were refused, he attempted to incite the "gens de couleur" to revolt. Ogé and Jean-Baptiste Chavennes, a veteran of the Siege of Savannah during the American Revolution, attempted to attack Cap-Français. However, the mulatto rebels refused to arm or free their slaves, or to challenge the status of slavery, and their attack was defeated by a force of white militia and black volunteers (including Henri Christophe). Afterwards, they fled across the frontier to Hinche, at the time in the Spanish part of the island. However, they were captured, returned to the French authorities, and both Ogé and Chavennes were executed in February 1791.
The rising of the slaves (1791–93).
On 22 August 1791, slaves in the northern region of the colony staged a revolt that began the Haitian Revolution. Tradition marks the beginning of the revolution at a vodou ceremony at Bois Caïman (Alligator Woods) near Cap-Français. The call to arms was issued by a Houngan (Vodou priest) named Dutty Boukman. Within hours, the northern plantations were in flames. The rebellion spread through the entire colony. Boukman was captured and executed, but the rebellion continued to spread rapidly.
In 1792, Léger-Félicité Sonthonax was sent to the colony by the French Legislative Assembly as part of the Revolutionary Commission. His main goal was to maintain French control of Saint-Domingue, stabilize the colony, and enforce the social equality recently granted to free people of color by the National Convention of France.
Toussaint Louverture ascendant (1793–1802).
On 29 August 1793, Sonthonax took the radical step of proclaiming the freedom of the slaves in the north province (with severe limits on their freedom). In September and October, emancipation was extended throughout the colony. The French National Convention, the first elected Assembly of the First Republic (1792–1804), on 4 February 1794, under the leadership of Maximilien de Robespierre, abolished slavery by law in France and all its colonies. The constitution of 1793, which was never applied, and the constitution of 1795, which was put into effect, did both contain an explicit ban on slavery.
The slaves did not immediately flock to Sonthonax's banner, however. White colonists continued to fight Sonthonax, with assistance from the British. They were joined by many of the free men of color who opposed the abolition of slavery. It was not until word of France's ratification of emancipation arrived back in the colony that Toussaint Louverture and his corps of well disciplined, battle-hardened former slaves came over to the French Republican side in early May 1794. A change in the political winds in France caused Sonthonax to be recalled in 1796, but not before taking the step of arming the former slaves.
With the colony facing a full-scale invasion by Britain, the emancipated slave rebels emerged as a powerful military force, under the leadership of Toussaint Louverture, Jean-Jacques Dessalines, and Henri Christophe. Louverture successfully drove back the British and by 1798 was the de facto ruler of the colony. In 1799, he defeated the mulatto General André Rigaud, who controlled most of the south and west and refused to acknowledge Toussaint's authority. By 1801, he was in control of all of Hispaniola, after conquering Spanish Santo Domingo and proclaiming the abolition of slavery there. He did not, however, proclaim full independence for the country, nor did he seek reprisals against the country's former white slaveholders, convinced that the French would not restore slavery and "that a population of slaves recently landed from Africa could not attain to civilization by 'going it alone.'"
Napoleon defeated (1802–04).
Toussaint, however, asserted enough independence that in 1802, Napoleon Bonaparte sent a massive invasion force, under his brother-in-law Charles Leclerc, to increase French control. For a time, Leclerc met with some success; he also brought the eastern part of the island of Hispaniola under the direct control of France in accordance with the terms of the 1795 Treaties of Bâle with Spain. With a large expedition that eventually included 40 000 European troops, and receiving help from white colonists and mulatto forces commanded by Alexandre Pétion, a former lieutenant of Rigaud, the French won several victories after severe fighting. Two of Toussaint's chief lieutenants, Dessalines and Christophe, recognizing their untenable situation, held separate parleys with the invaders, and agreed to transfer their allegiance. At this point, Leclerc invited Toussaint to negotiate a settlement. It was a deception; Toussaint was seized and deported to France, where he died of pneumonia while imprisoned at Fort de Joux in the Jura Mountains in April 1803.
On 20 May 1802, Napoleon signed a law to maintain slavery where it had not yet disappeared, namely Martinique, Tobago, and Saint Lucia. A confidential copy of this decree was sent to Leclerc, who was authorized to restore slavery in Saint-Domingue when the time was opportune. At the same time, further edicts stripped the "gens de couleur" of their newly won civil rights. None of these decrees were published or executed in St. Domingue, but, by midsummer, word began to reach the colony of the French intention to restore slavery. The betrayal of Toussaint and news of French actions in Martinique undermined the collaboration of leaders such as Dessalines, Christophe, and Pétion. Convinced that the same fate lay in store for Saint-Domingue, these commanders and others once again battled Leclerc. With the French intent on reconquest and re-enslavement of the colony's black population, the war became a bloody struggle of atrocity and attrition. The rainy season brought yellow fever and malaria, which took a heavy toll on the invaders. By November, when Leclerc died of yellow fever, 24 000 French soldiers were dead and 8,000 were hospitalized, the majority from disease.
Afterwards, Leclerc was replaced by Donatien-Marie-Joseph de Vimeur, vicomte de Rochambeau. Rochambeau wrote to Napoleon that, to reclaim Saint-Domingue, France must 'declare the negroes slaves, and destroy at least 30,000 negroes and negresses.' In his desperation, he turned to increasingly wanton acts of brutality; the French burned alive, hanged, drowned, and tortured black prisoners, reviving such practices as burying blacks in piles of insects and boiling them in cauldrons of molasses. One night, at Port-Républican, he held a ball to which he invited the most prominent mulatto ladies and, at midnight, announced the death of their husbands. However, each act of brutality was repaid by the Haitian rebels. After one battle, Rochambeau buried 500 prisoners alive; Dessalines responded by hanging 500 French prisoners. Rochambeau's brutal tactics helped unite black, mulatto, and mestizo soldiers against the French.
As the tide of the war turned toward the former slaves, Napoleon abandoned his dreams of restoring France's New World empire. In 1803, war resumed between France and Britain, and with the Royal Navy firmly in control of the seas, reinforcements and supplies for Rochambeau never arrived in sufficient numbers. To concentrate on the war in Europe, Napoleon signed the Louisiana Purchase in April, selling France's North American possessions to the United States. The Haitian army, now led by Dessalines, devastated Rochembeau and the French army at the Battle of Vertières on 18 November 1803.
On 1 January 1804 Dessalines then declared independence, reclaiming the indigenous Taíno name of Haiti ("Land of Mountains") for the new nation. Most of the remaining French colonists fled ahead of the defeated French army, many migrating to Louisiana or Cuba. Unlike Toussaint, Dessalines showed little equanimity with regard to the whites. In a final act of retribution, the remaining French were slaughtered by Haitian military forces. Some 2 000 Frenchmen were massacred at Cap-Français, 900 in Port-au-Prince, and 400 at Jérémie. He issued a proclamation declaring, "we have repaid these cannibals, war for war, crime for crime, outrage for outrage."
One exception was a military force of Poles from the Polish Legions that had fought in Napoleon's army. A majority of them refused to fight against the Black inhabitants, by supporting the principles of liberty for all the people; also, many Poles actually joined the Haitan rebels (Władysław Franciszek Jabłonowski who was half-Black was one of the Polish generals). Polish soldiers had a remarkable input in helping the Haitans in the retaliation fights against the French oppressor. Therefore, Poles were allowed to stay and were spared the fate of other Europeans. About 500 of the 5280 Poles chose this option. Of the remainder, 700 returned to France and many were – after capitulation – forced to serve in British units. 160 Poles were later given permission to leave Haiti and were sent to France at Haitian expense. Today, descendants of those Poles who stayed are living in Cazale and Fond-des-Blancs.
Despite the Haitian victory, France refused to recognize the newly independent country's sovereignty until 1825, in exchange for 150 million gold francs. This fee, demanded as retribution for the "lost property,"—slaves, land, equipment etc.—of the former colonialists, was later reduced to 90 million. Haiti agreed to pay the price to lift a crippling embargo imposed by France, Britain, and the United States— but to do so, the Haitian government had to take out high interest loans. The debt was not repaid in full until 1947.
Independence: The early years (1804–43).
Black Republic (1804).
Haiti is the world's oldest black republic and one of the oldest republics in the Western Hemisphere. Although Haiti actively assisted the independence movements of many Latin American countries – and secured a promise from the great liberator, Simón Bolívar, that he would free their slaves after winning independence from Spain – the nation of former slaves was excluded from the hemisphere's first regional meeting of independent nations, held in Panama in 1826. Furthermore, owing to entrenched opposition from Southern slave states, Haiti did not receive U.S. diplomatic recognition until 1862 (after those states had seceded from the Union) – largely through the efforts of anti-slavery senator Charles Sumner of Massachusetts.
Upon assuming power, General Dessalines authorized the Constitution of 1804. This constitution, in terms of social freedoms, called for:
First Haitian Empire (1804–06).
On 22 September 1804, Dessalines, preferring Napoleon's style rather than the more liberal yet vulnerable type of political government of the French Republican Radicals (see liberalism and radicalism in France), proclaimed himself Emperor Jacques I. Yet two of his own advisers, Henri Christophe and Alexandre Pétion, helped provoke his assassination in 1806. The conspirators ambushed him north of Port-au-Prince at Pont Larnage (now known as Pont-Rouge) on 17 October 1806 en route to battle rebels to his regime.
The struggle for unity (1806–20).
After the Dessalines coup d'état, the two main conspirators divided the country in two rival regimes. Christophe created the authoritarian State of Haiti in the north, and the Gens de couleur Pétion helped establish the Republic of Haiti in the south. Christophe attempted to maintain a strict system of labor and agricultural production akin to the former plantations. Although, strictly speaking, he did not establish slavery, he imposed a semi-feudal system, fumage, in which every able man was required to work in plantations (similar to Latifundios) to produce goods for the fledging country. His method, though undoubtedly oppressive, produced the most revenues of the two governments.
By contrast, Pétion broke up the former colonial estates and parceled out the land into small holdings. In Pétion's south, the gens de couleur minority led the government and feared losing popular support, and thus, sought to assuage class tensions with land redistribution. Because of the weak international position and its labor policies (most peasants lived through a subsistence economy), Pétion's government was perpetually on the brink of bankruptcy. Yet, for most of its time, it produced one of the most liberal and tolerant Haitian governments ever. In 1815, at a key period of Bolívar's fight for Venezuelan independence, he gave the Venezuelan leader asylum and provided him soldiers and substantial material support. It also had the least of internal military skirmishes, despite its continuous conflicts with Christophe's northern kingdom. In 1816, however, after finding the burden of the Senate intolerable, he suspended the legislature and turned his post into President for Life. Not long after, he died of yellow fever, and his assistant Jean-Pierre Boyer replaced him.
In this period, the eastern part of the island rose against the new powers following general Juan Sánchez Ramírez's claims of independence from France, which broke the Treaties of Bâle attacking Spain and prohibited commerce with Haiti. In the Palo Hincado battle (7 November 1808), all the remaining French forces were defeated by Spanish-creole insurrectionists. On 9 July 1809, Santo Domingo was born. The government put itself under the control of Spain, earning it the nickname of "España Boba" (meaning "The Idiot Spain").
In 1811, Christophe proclaimed himself King Henri I in the North and commissioned several extraordinary buildings. He even created a nobility class in the fashion of European monarchies. Yet in 1820, weakened by illness and with a decreasing support for his authoritarian regime, he killed himself with a silver bullet rather than face a coup d'état. Immediately after, Pétion's successor, Boyer, reunited Haiti through diplomatic tactics, and ruled as president until his overthrow in 1843.
Boyer's domination of Hispaniola (1820–43).
Almost two years after Boyer had consolidated power in the west, in 1821, Santo Domingo declared independence from Spain and requested from Simón Bolívar inclusion in the Gran Colombia. Boyer, however, responding to a party on the east that preferred Haiti over Colombia, occupied the ex-Spanish colony in January 1822, encountering no military resistance. In this way he accomplished the unity of the island, which was only carried out for a short period of time by Toussaint Louverture in 1801. Boyer's occupation of the Spanish side also responded to internal struggles among Christophe's generals, to which Boyer gave extensive powers and lands in the east. This occupation, however, pitted the Spanish white elite against the iron fisted Haitian administration, and stimulated the emigration of many white wealthy families. Even today, the various memories and interpretations of this occupation still fuel animosities between Haiti and the Dominican Republic. The entire island remained under Haitian rule until 1844, when in the east a nationalist group called La Trinitaria led a revolt that partitioned the island into Haiti on the west and Dominican Republic on the east, based on what would appear to be a riverine territorial 'divide' from the pre-contact period.
From 1824 to 1826, while the island was under one government, Boyer promoted the largest single free-Black immigration from the United States in which more than 6000 immigrants settled in different parts of the island. Today remnants of these immigrants live throughout the island, but the larger number reside in Samaná, a peninsula on the Dominican side of the island. From the government's perspective, the intention of the immigration was to help establish commercial and diplomatic relationships with the US, and to increase the number of skilled and agricultural workers in Haiti.
In exchange for diplomatic recognition from France, Boyer was forced to pay a huge indemnity for the loss of French property during the revolution. To pay for this, he had to float loans in France, putting Haiti into a state of debt. Boyer attempted to enforce production through the "Code Rural", enacted in 1826, but peasant freeholders, mostly former revolutionary soldiers, had no intention of returning to the forced labor they fought to escape. By 1840, Haiti had ceased to export sugar entirely, although large amounts continued to be grown for local consumption as "taffia"-a raw rum. However, Haiti continued to export coffee, which required little cultivation and grew semi-wild.
The 1842 Cap-Haitien earthquake destroyed the city, and the Sans-Souci Palace, killing 10,000 people. This was the third major earthquake to hit Western Hispaniola following the 1751 and 1770 Port-au-Prince earthquakes, and the last until the devastating earthquake of 2010.
Political struggles (1843–1911).
Instability and chaos (1843–49).
In 1843, a revolt, led by Charles Rivière-Hérard, overthrew Boyer and established a brief parliamentary rule under the Constitution of 1843. Revolts soon broke out and the country descended into near chaos, with a series of transient presidents until March 1847, when General Faustin Soulouque, a former slave who had fought in the rebellion of 1791, became President.
Second Haitian Empire (1849–59).
In 1849, taking advantage of his popularity, President Faustin Soulouque proclaimed himself Emperor Faustin I. His iron rule succeeded in uniting Haiti for a time, but it came to an abrupt end in 1859 when he was deposed by General Fabre Geffrard, styled the Duke of Tabara.
Building a new republic (1859–1911).
Geffrard's military government held office until 1867, and he encouraged a successful policy of national reconciliation. In 1860, he reached an agreement with the Vatican, reintroducing official Roman Catholic institutions, including schools, to the nation. In 1867 an attempt was made to establish a constitutional government, but successive presidents Sylvain Salnave and Nissage Saget were overthrown in 1869 and 1874 respectively. A more workable constitution was introduced under Michel Domingue in 1874, leading to a long period of democratic peace and development for Haiti. The debt to France was finally repaid in 1879, and Michel Domingue's government peacefully transferred power to Lysius Salomon, one of Haiti's abler leaders. Monetary reform and a cultural renaissance ensued with a flowering of Haitian art.
The last two decades of the 19th century were also marked by the development of a Haitian intellectual culture. Major works of history were published in 1847 and 1865. Haitian intellectuals, led by Louis-Joseph Janvier and Anténor Firmin, engaged in a war of letters against a tide of racism and Social Darwinism that emerged during this period.
The Constitution of 1867 saw peaceful and progressive transitions in government that did much to improve the economy and stability of the Haitian nation and the condition of its people. Constitutional government restored the faith of the Haitian people in legal institutions. The development of industrial sugar and rum industries near Port-au-Prince made Haiti, for a while, a model for economic growth in Latin American countries.
This period of relative stability and prosperity ended in 1911, when revolution broke out and the country slid once again into disorder and debt.
Failing state (1911–15).
From 1911 to 1915, there were six different Presidents, each of whom was killed or forced into exile. The revolutionary armies were formed by "cacos", peasant brigands from the mountains of the north, along the porous Dominican border, who were enlisted by rival political factions with promises of money to be paid after a successful revolution and an opportunity to plunder.
The United States was particularly apprehensive about the role of the German community in Haiti (approximately 200 in 1910), who wielded a disproportionate amount of economic power. Germans controlled about 80% of the country's international commerce; they also owned and operated utilities in Cap Haïtien and Port-au-Prince, the main wharf and a tramway in the capital, and a railroad serving the Plaine de Cul-du-Sac.
The German community proved more willing to integrate into Haitian society than any other group of white foreigners, including the French. A number married into the nation's most prominent mulatto families, bypassing the constitutional prohibition against foreign land-ownership. They also served as the principal financiers of the nation's innumerable revolutions, floating innumerable loans-at high interest rates-to competing political factions.
In an effort to limit German influence, in 1910–11, the US State Department backed a consortium of American investors, assembled by the National City Bank of New York, in acquiring control of the "Banque Nationale d'Haïti", the nation's only commercial bank and the government treasury.
In February 1915, Vilbrun Guillaume Sam established a dictatorship, but in July, facing a new revolt, he massacred 167 political prisoners, all of whom were from elite families, and was lynched by a mob in Port-au-Prince.
United States occupation (1915–34).
In 1915 the United States, responding to complaints to President Woodrow Wilson from American banks to which Haiti was deeply in debt, occupied the country. The occupation of Haiti lasted until 1934. The US occupation was resented by Haitians as a loss of sovereignty and there were revolt against US forces. Reforms were however carried out.
Under the supervision of the United States Marines, the Haitian National Assembly elected Philippe Sudré Dartiguenave President. He signed a treaty that made Haiti a "de jure" US protectorate, with American officials assuming control over the Financial Adviser, Customs Receivership, the Constabulary, the Public Works Service, and the Public Health Service for a period of ten years. The principal instrument of American authority was the newly created "Gendarmerie d'Haïti", commanded by American officers. In 1917, at the demand of US officials, the National Assembly was dissolved, and officials were designated to write a new constitution, which was largely dictated by officials in the US State Department and US Navy Department. Franklin D. Roosevelt, Under-Secretary for the Navy in the Wilson administration, claimed to have personally written the new constitution. This document abolished the prohibition on foreign ownership of land – the most essential component of Haitian law. When the newly elected National Assembly refused to pass this document and drafted one of its own preserving this prohibition, it was forcibly dissolved by "Gendarmerie" commandant Smedley Butler. This constitution was approved by a plebiscite in 1919, in which less than 5% of the population voted. The US State Department authorized this plebiscite presuming that "the people casting ballots would be 97% illiterate, ignorant in most cases of what they were voting for."
The Marines and "Gendarmerie" initiated an extensive road-building program to enhance their military effectiveness and open the country to US investment. Lacking any source of adequate funds, they revived an 1864 Haitian law, discovered by Butler, requiring peasants to perform labor on local roads in lieu of paying a road tax. This system, known as the corvée, originated in the unpaid labor that French peasants provided to their feudal lords. In 1915, Haiti had 3 mi of road usable by automobile outside the towns. By 1918, more than 470 mi of road had been built or repaired through the corvée system, including a road linking Port-au-Prince to Cap-Haïtien. However, Haitians forced to work in the corvée labor-gangs, frequently dragged from their homes and harassed by armed guards, received few immediate benefits and saw this system of forced labor as a return to slavery at the hands of white men.
In 1919, a new "caco" uprising began, led by Charlemagne Péralte, vowing to 'drive the invaders into the sea and free Haiti.' The Cacos attacked Port-au-Prince in October but were driven back with heavy casualties. Afterwards, a Creole-speaking American "Gendarmerie" officer and two US marines infiltrated Péralte's camp, killing him and photographing his corpse in an attempt to demoralize the rebels. Leadership of the rebellion passed to Benoît Batraville, a Caco chieftain from Artibonite. His death in 1920 marked the end of hostilities. During Senate hearings in 1921, the commandant of the Marine Corps reported that, in the twenty months of active resistance, 2 250 Haitians had been killed. However, in a report to the Secretary of the Navy he reported the death toll as being 3 250. Haitian historians have estimated the true number was much higher; one suggested, "the total number of battle victims and casualties of repression and consequences of the war might have reached, by the end of the pacification period, four or five times that – somewhere in the neighborhood of 15,000 persons."
In 1922, Dartiguenave was replaced by Louis Borno, who ruled without a legislature until 1930. That same year, General John H. Russell, Jr., was appointed High Commissioner. The Borno-Russel dictatorship oversaw the expansion of the economy, building over 1000 mi of road, establishing an automatic telephone exchange, modernizing the nation's port facilities, and establishing a public health service. Sisal was introduced to Haiti, and sugar and cotton became significant exports. However, efforts to develop commercial agriculture had limited success, in part because much of Haiti's labor force was employed at seasonal work in the more established sugar industries of Cuba and the Dominican Republic. An estimated 30,000–40,000 Haitian laborers, known as "braceros", went annually to the Oriente Province of Cuba between 1913 and 1931. Most Haitians continued to resent the loss of sovereignty. At the forefront of opposition among the educated elite was "L'Union Patriotique," which established ties with opponents of the occupation in the US itself, in particular the National Association for the Advancement of Colored People (NAACP).
The Great Depression decimated the prices of Haiti's exports and destroyed the tenuous gains of the previous decade. In December 1929, Marines in Les Cayes killed ten Haitians during a march to protest local economic conditions. This led Herbert Hoover to appoint two commissions, including one headed by a former US governor of the Philippines William Cameron Forbes, which criticized the exclusion of Haitians from positions of authority in the government and constabulary, now known as the "Garde d'Haïti". In 1930, Sténio Vincent, a long-time critic of the occupation, was elected President, and the US began to withdraw its forces. The withdrawal was completed under US President Franklin D. Roosevelt (FDR), in 1934, under his "Good Neighbor policy". The US retained control of Haiti's external finances until 1947. All three rulers during the occupation came from the country's small mulatto minority. At the same time, many in the growing black professional classes departed from the traditional veneration of Haiti's French cultural heritage and emphasized the nation's African roots, most notably ethnologist Jean Price-Mars and the journal "Les Griots", edited by Dr. François Duvalier.
The transition government left a better infrastructure, public health, education, and agricultural development as well as a democratic system. The country had fully democratic elections in 1930, won by Sténio Vincent. The Garde was a new kind of military institution in Haiti. It was a force manned overwhelmingly by blacks, with a United States-trained black commander, Colonel Démosthènes Pétrus Calixte. Most of the Garde's officers, however, were mulattoes. The Garde was a national organization; it departed from the regionalism that had characterized most of Haiti's previous armies. In theory, its charge was apolitical—to maintain internal order, while supporting a popularly elected government. The Garde initially adhered to this role.
Elections and coups (1934–57).
Vincent's presidency (1934–41).
President Vincent took advantage of the comparative national stability, which was being maintained by a professionalized military, to gain absolute power. A plebiscite permitted the transfer of all authority in economic matters from the legislature to the executive, but Vincent was not content with this expansion of his power. In 1935 he forced through the legislature a new constitution, which was also approved by plebiscite. The constitution praised Vincent, and it granted the executive sweeping powers to dissolve the legislature at will, to reorganize the judiciary, to appoint ten of twenty-one senators (and to recommend the remaining eleven to the lower house), and to rule by decree when the legislature was not in session. Although Vincent implemented some improvements in infrastructure and services, he brutally repressed his opposition, censored the press, and governed largely to benefit himself and a clique of merchants and corrupt military officers.
Under Calixte the majority of Garde personnel had adhered to the doctrine of political nonintervention that their Marine Corps trainers had stressed. Over time, however, Vincent and Dominican dictator Rafael Leónidas Trujillo Molina sought to buy adherents among the ranks. Trujillo, determined to expand his influence over all of Hispaniola, in October 1937 ordered the indiscriminate butchery by the Dominican army of an estimated 15,000 to 20,000 Haitians on the Dominican side of the Massacre River. Some observers claim that Trujillo supported an abortive coup attempt by young Garde officers in December 1937. Vincent dismissed Calixte as commander and sent him abroad, where he eventually accepted a commission in the Dominican military as a reward for his efforts while on Trujillo's payroll. The attempted coup led Vincent to purge the officer corps of all members suspected of disloyalty, marking the end of the apolitical military.
Lescot's presidency (1941–46).
In 1941 Vincent showed every intention of standing for a third term as president, but after almost a decade of disengagement, the United States made it known that it would oppose such an extension. Vincent accommodated the Roosevelt administration and handed power over to Elie Lescot.
Lescot was a mulatto who had served in numerous government posts. He was competent and forceful, and many considered him a sterling candidate for the presidency, despite his elitist background. Like the majority of previous Haitian presidents, however, he failed to live up to his potential. His tenure paralleled that of Vincent in many ways. Lescot declared himself commander in chief of the military, and power resided in a clique that ruled with the tacit support of the Garde. He repressed his opponents, censored the press, and compelled the legislature to grant him extensive powers. He handled all budget matters without legislative sanction and filled legislative vacancies without calling elections. Lescot commonly said that Haiti's declared state-of-war against the Axis powers during World War II justified his repressive actions. Haiti, however, played no role in the war except for supplying the United States with raw materials and serving as a base for a United States Coast Guard detachment.
Aside from his authoritarian tendencies, Lescot had another flaw: his relationship with Trujillo. While serving as Haitian ambassador to the Dominican Republic, Lescot fell under the sway of Trujillo's influence and wealth. In fact, it was Trujillo's money that reportedly bought most of the legislative votes that brought Lescot to power. Their clandestine association persisted until 1943, when the two leaders parted ways for unknown reasons. Trujillo later made public all his correspondence with the Haitian leader. The move undermined Lescot's already dubious popular support.
In January 1946, events came to a head when Lescot jailed the Marxist editors of a journal called La Ruche (The Beehive). This action precipitated student strikes and protests by government workers, teachers, and shopkeepers in the capital and provincial cities. In addition, Lescot's mulatto-dominated rule had alienated the predominantly black Garde. His position became untenable, and he resigned on 11 January. Radio announcements declared that the Garde had assumed power, which it would administer through a three-member junta.
Revolution of 1946.
The Revolution of 1946 was a novel development in Haiti's history, as the Garde assumed power as an institution, not as the instrument of a particular commander. The members of the junta, known as the Military Executive Committee (Comité Exécutif Militaire), were Garde commander Colonel Franck Lavaud, Major Antoine Levelt, and Major Paul E. Magloire, commander of the Presidential Guard. All three understood Haiti's traditional way of exercising power, but they lacked a thorough understanding of what would be required to make the transition to an elected civilian government. Upon taking power, the junta pledged to hold free elections. The junta also explored other options, but public clamor, which included public demonstrations in support of potential candidates, eventually forced the officers to make good on their promise.
Haiti elected its National Assembly in May 1946. The Assembly set 16 August 1946, as the date on which it would select a president. The leading candidates for the office—all of whom were black—were Dumarsais Estimé, a former school teacher, assembly member, and cabinet minister under Vincent; Félix d'Orléans Juste Constant, leader of the Haitian Communist Party (Parti Communiste d'Haïti—PCH); and former Garde commander Démosthènes Pétrus Calixte, who stood as the candidate of a progressive coalition that included the Worker Peasant Movement (Mouvement Ouvrier Paysan—MOP). MOP chose to endorse Calixte, instead of a candidate from its own ranks, because the party's leader, Daniel Fignolé, was only twenty-six years old—too young to stand for the nation's highest office. Estimé, politically the most moderate of the three, drew support from the black population in the north, as well as from the emerging black middle class. The leaders of the military, who would not countenance the election of Juste Constant and who reacted warily to the populist Fignolé, also considered Estimé the safest candidate. After two rounds of polling, legislators gave Estimé the presidency.
Estimé's presidency (1946–50).
Estimé's election represented a break with Haiti's political tradition. Although he was reputed to have received support from commanders of the Garde, Estimé was a civilian. Of humble origins, he was passionately anti-elitist and therefore generally antimulatto. He demonstrated, at least initially, a genuine concern for the welfare of the people. Operating under a new constitution that went into effect in November 1946, Estimé proposed, but never secured passage of, Haiti's first social- security legislation. He did, however, expand the school system, encourage the establishment of rural cooperatives, raise the salaries of civil servants, and increase the representation of middle-class and lower-class blacks in the public sector. He also attempted to gain the favor of the Garde—renamed the Haitian Army (Armée d'Haïti) in March 1947—by promoting Lavaud to brigadier general and by seeking United States military assistance.
Estimé eventually fell victim to two of the time-honored pitfalls of Haitian rule: elite intrigue and personal ambition. The elite had a number of grievances against Estimé. Not only had he largely excluded them from the often lucrative levers of government, but he also enacted the country's first income tax, fostered the growth of labor unions, and suggested that vodou be considered as a religion equivalent to Roman Catholicism—a notion that the Europeanized elite abhorred. Lacking direct influence in Haitian affairs, the elite resorted to clandestine lobbying among the officer corps. Their efforts, in combination with deteriorating domestic conditions, led to a coup in May 1950.
To be sure, Estimé had hastened his own demise in several ways. His nationalization of the Standard Fruit banana concession sharply reduced the firm's revenues. He alienated workers by requiring them to invest between 10 percent and 15 percent of their salaries in national-defense bonds. The president sealed his fate by attempting to manipulate the constitution in order to extend his term in office. Seizing on this action and the popular unrest it engendered, the army forced the president to resign on 10 May 1950. The same junta that had assumed power after the fall of Lescot reinstalled itself. An army escort conducted Estimé from the National Palace and into exile in Jamaica. The events of May 1946 made an impression upon the deposed minister of labor, François Duvalier. The lesson that Duvalier drew from Estimé's ouster was that the military could not be trusted. It was a lesson that he would act upon when he gained power.
Magloire's presidency (1950–56).
The power balance within the junta shifted between 1946 and 1950. Lavaud was the preeminent member at the time of the first coup, but Magloire, now a colonel, dominated after Estimé's overthrow. When Haiti announced that its first direct elections (all men twenty-one or over were allowed to vote) would be held on 8 October 1950, Magloire resigned from the junta and declared himself a candidate for president. In contrast to the chaotic political climate of 1946, the campaign of 1950 proceeded under the implicit understanding that only a strong candidate backed by both the army and the elite would be able to take power. Facing only token opposition, Magloire won the election and assumed office on 6 December.
Magloire restored the elite to prominence. The business community and the government benefited from favorable economic conditions until Hurricane Hazel hit the island in 1954. Haiti made some improvements on its infrastructure, but most of these were financed largely by foreign loans. By Haitian standards, Magloire's rule was firm, but not harsh: he jailed political opponents, including Fignolé, and shut down their presses when their protests grew too strident, but he allowed labor unions to function, although they were not permitted to strike. It was in the arena of corruption, however, that Magloire overstepped traditional bounds. The president controlled the sisal, cement, and soap monopolies. He and other officials built imposing mansions. The injection of international hurricane relief funds into an already corrupt system boosted graft to levels that disillusioned all Haitians. To make matters worse, Magloire followed in the footsteps of many previous presidents by disputing the termination date of his stay in office. Politicians, labor leaders, and their followers flocked to the streets in May 1956 to protest Magloire's failure to step down. Although Magloire declared martial law, a general strike essentially shut down Port-au-Prince. Again like many before him, Magloire fled to Jamaica, leaving the army with the task of restoring order.
The rise of Duvalier (1956–57).
The period between the fall of Magloire and the election of Duvalier in September 1957 was a chaotic one, even by Haitian standards. Three provisional presidents held office during this interval; one resigned and the army deposed the other two, Franck Sylvain and Fignolé. Duvalier is said to have engaged actively in the behind-the-scenes intrigue that helped him to emerge as the presidential candidate that the military favored. The military went on to guide the campaign and the elections in a way that gave Duvalier every possible advantage. Most political actors perceived Duvalier—a medical doctor who had served as a rural administrator of a United States-funded anti-yaws campaign before entering the cabinet under Estimé—as an honest and fairly unassuming leader without a strong ideological motivation or program. When elections were finally organized, this time under terms of universal suffrage (both men and women now had the vote), Duvalier, a black, painted himself as the legitimate heir to Estimé. This approach was enhanced by the fact that Duvalier's only viable opponent, Louis Déjoie, was a mulatto and the scion of a prominent family. Duvalier scored a decisive victory at the polls. His followers took two-thirds of the legislature's lower house and all of the seats in the Senate.
The Duvalier era (1957–86).
'Papa Doc' (1957–71).
A former Minister of Health who had earned a reputation as a humanitarian while serving as an administrator in a U.S.-funded anti-yaws campaign, Duvalier (known as "Papa Doc") soon established another dictatorship. His regime is regarded as one of the most repressive and corrupt of modern times, combining violence against political opponents with exploitation of Vodou to instill fear in the majority of the population. Duvalier's paramilitary police, officially the Volunteers for National Security (Volontaires de la Sécurité Nationale – VSN) but more commonly known as the Tonton Macoutes, named for a Vodou monster, carried out political murders, beatings, and intimidation. An estimated 30,000 Haitians were killed by his government. Duvalier employed rape as a political tool to silence political opposition. Incorporating many "houngans" into the ranks of the Macoutes, his public recognition of Vodou and its practitioners and his private adherence to Vodou ritual, combined with his reputed private knowledge of magic and sorcery, enhanced his popular persona among the common people and served as a peculiar form of legitimization.
Duvalier's policies, designed to end the dominance of the mulatto elite over the nation's economic and political life, led to massive emigration of educated people, deepening Haiti's economic and social problems. However, Duvalier appealed to the black middle class of which he was a member by introducing public works into middle-class neighborhoods that previously had been unable to have paved roads, running water, or modern sewage systems. In 1964, Duvalier proclaimed himself "President for Life".
The Kennedy administration suspended aid in 1961, after allegations that Duvalier had pocketed aid money and intended to use a Marine Corps mission to strengthen the Macoutes. Duvalier also clashed with Dominican President Juan Bosch in 1963, after Bosch provided aid and asylum to Haitian exiles working to overthrow his regime. He ordered the Presidential Guard to occupy the Dominican chancery in Pétionville to apprehend an officer involved in a plot to kidnap his children, leading Bosch to publicly threaten to invade Haiti. However, the Dominican army, which distrusted Bosch's leftist leanings, expressed little support for an invasion, and the dispute was settled by OAS emissaries.
In 1971, Papa Doc entered into 99-year contract with Don Pierson representing Dupont Caribbean Inc. of Texas for a free port project on the old buccaneer stronghold of Tortuga island located some 10 mi off the north coast of the main Haitian island of Hispaniola.
'Baby Doc' (1971–86).
On Duvalier's death in April 1971, power passed to his 19-year-old son Jean-Claude Duvalier (known as "Baby Doc"). Under Jean-Claude Duvalier, Haiti's economic and political condition continued to decline, although some of the more fearsome elements of his father's regime were abolished. Foreign officials and observers also seemed more tolerant toward Baby Doc, in areas such as human-rights monitoring, and foreign countries were more generous to him with economic assistance. The United States restored its aid program in 1971. In 1974, Baby Doc expropriated the Freeport Tortuga project and this caused the venture to collapse. Content to leave administrative matters in the hands of his mother, Simone Ovid Duvalier, while living as a playboy, Jean-Claude enriched himself through a series of fraudulent schemes. Much of the Duvaliers' wealth, amounting to hundreds of millions of dollars over the years, came from the Régie du Tabac (Tobacco Administration), a tobacco monopoly established by Estimé, which expanded to include the proceeds from all government enterprises and served as a slush fund for which no balance sheets were ever kept. His marriage, in 1980, to a beautiful mulatto divorcée, Michèle Bennett, in a $3 million ceremony, provoked widespread opposition, as it was seen as a betrayal of his father's antipathy towards the mulatto elite. At the request of Michèle, Papa Doc's widow Simone was expelled from Haiti. Baby Doc's kleptocracy left the regime vulnerable to unanticipated crises, exacerbated by endemic poverty, most notably the epidemic of African swine fever virus—which, at the insistence of USAID officials, led to the slaughter of the creole pigs, the principal source of income for most Haitians; and the widely publicized outbreak of AIDS in the early 1980s. Widespread discontent in Haiti began in 1983, when Pope John Paul II condemned the regime during a visit, finally provoking a rebellion, and in February 1986, after months of disorder, the army forced Duvalier to resign and go into exile.
The struggle for democracy (1986–present day).
Transitional government (1986–90).
From 1986 to early 1988 Haiti was ruled by a provisional military government under General Namphy. In 1987, a new constitution was ratified, providing for an elected bicameral parliament, an elected president, and a prime minister, cabinet, ministers, and supreme court appointed by the president with parliament's consent. The Constitution also provided for political decentralization through the election of mayors and administrative bodies responsible for local government. The November 1987 elections was cancelled after troops massacred 30–300 voters on election day. Jimmy Carter later wrote that "Citizens who lined up to vote were mowed down by fusillades of terrorists’ bullets. Military leaders, who had either orchestrated or condoned the murders, moved in to cancel the election and retain control of the Government." The election was followed several months later by the Haitian presidential election, 1988, which was boycotted by almost all the previous candidates, and saw turnout of just 4%.
The 1988 elections led to Professor Leslie Manigat becoming President, but three months later he too was ousted by the military. Further instability ensued, with several massacres, including the St Jean Bosco massacre in which the church of Jean-Bertrand Aristide was attacked and burned down. During this period, the Haitian National Intelligence Service (SIN), which had been set up and financed in the 80s by the Central Intelligence Agency as part of the war on drugs, participated in drug trafficking and political violence.
The rise of Aristide (1990–91).
In December 1990, Jean-Bertrand Aristide, a liberation theology Roman Catholic (Salesian) priest, won 67% of the vote in elections that international observers deemed largely free and fair.
Aristide's radical populist policies and the violence of his bands of supporters alarmed many of the country's elite, and, in September 1991, he was overthrown in the 1991 Haitian coup d'état, which brought General Raoul Cédras to power. The coup saw hundreds killed, and Aristide was forced into exile, his life saved by international diplomatic intervention.
Military rule (1991–94).
An estimated 3 000–5 000 Haitians were killed during the period of military rule. The coup created a large-scale exodus of refugees to the United States. The United States Coast Guard interdicted (in many cases, rescued) a total of 41 342 Haitians during 1991 and 1992. Most were denied entry to the United States and repatriated back to Haiti. According to Mark Weisbrot, Aristide has accused the United States of backing the 1991 coup. In response to the coup, the United Nations Security Council passed Resolution 841 imposing international sanctions and an arms embargo on Haiti.
On 16 February 1993, the ferry "Neptune" sank, drowning an estimated 700 passengers. This was the worst ferry disaster in Haitian history.
The military regime governed Haiti until 1994, and according to some sources included drug trafficking led by Chief of National Police Michel François. Various initiatives to end the political crisis through the peaceful restoration of the constitutionally elected government failed. In July 1994, as repression mounted in Haiti and a civilian human rights monitoring mission was expelled from the country, the United Nations Security Council adopted United Nations Security Council Resolution 940, which authorized member states to use all necessary means to facilitate the departure of Haiti's military leadership and to restore Haiti's constitutionally elected government to power.
The return of Aristide (1994–96).
In mid-September 1994, with U.S. troops prepared to enter Haiti by force for Operation Uphold Democracy, President Bill Clinton dispatched a negotiating team led by former President Jimmy Carter to persuade the authorities to step aside and allow for the return of constitutional rule. With intervening troops already airborne, Cédras and other top leaders agreed to step down. In October, Aristide was able to return. The Haitian general election, 1995 in June 1995 saw Aristide's coalition, the Lavalas (Waterfall) Political Organization, gain a sweeping victory, and René Préval, a prominent Aristide political ally, elected President with 88% of the vote. When Aristide's term ended in February 1996, this was Haiti's first ever transition between two democratically elected presidents.
Preval's first Presidency (1996–2001).
In late 1996, Aristide broke with Préval and formed a new political party, the Lavalas Family (Fanmi Lavalas, FL), which won elections in April 1997 for one-third of the Senate and local assemblies, but these results were not accepted by the government. The split between Aristide and Préval produced a dangerous political deadlock, and the government was unable to organize the local and parliamentary elections due in late 1998. In January 1999, Préval dismissed legislators whose terms had expired – the entire Chamber of Deputies and all but nine members of the Senate, and Préval then ruled by decree.
Aristide's second presidency (2001–04).
In May 2000 the Haitian legislative election, 2000 for the Chamber of Deputies and two-thirds of the Senate took place. The election drew a voter turnout of more than 60%, and the FL won a virtual sweep. However, the elections were marred by controversy in the Senate race over the calculation of whether Senate candidates had achieved the majority required to avoid a run-off election (in Haiti, seats where no candidate wins an absolute majority of votes cast has to enter a second-round run-off election). The validity of the Electoral Council's post-ballot calculations of whether a majority had been attained was disputed. The Organization of American States complained about the calculation and declined to observe the July run-off elections. The opposition parties, regrouped in the Democratic Convergence (Convergence Démocratique, CD), demanded that the elections be annulled, and that Préval stand down and be replaced by a provisional government. In the meantime, the opposition announced it would boycott the November presidential and senatorial elections. Haiti's main aid donors threatened to cut off aid. At the November 2000 elections, boycotted by the opposition, Aristide was again elected president, with more than 90% of the vote, on a turnout of around 50% according to international observers. The opposition refused to accept the result or to recognize Aristide as president.
Allegations emerged of drug trafficking reaching into the upper echelons of government, as it had done under the military regimes of the 1980s and early 1990s (illegal drug trade in Haiti). Canadian police arrested Oriel Jean, Aristide's security chief and one of his most trusted friends, for money laundering. Beaudoin Ketant, a notorious international drug trafficker, Aristide's close partner, and his daughter's godfather, claimed that Aristide "turned the country into a narco-country; it's a one-man show; you either pay (Aristide) or you die".
Aristide spent years negotiating with the Convergence Démocratique on new elections, but the Convergence's inability to develop a sufficient electoral base made elections unattractive, and it rejected every deal offered, preferring to call for a US invasion to topple Aristide.
The 2004 coup d'état.
Anti-Aristide protests in January 2004 led to violent clashes in Port-au-Prince, causing several deaths. In February, a revolt broke out in the city of Gonaïves, which was soon under rebel control. The rebellion then began to spread, and Cap-Haïtien, Haiti's second-largest city, was captured. A mediation team of diplomats presented a plan to reduce Aristide's power while allowing him to remain in office until the end of his constitutional term. Although Aristide accepted the plan, it was rejected by the opposition, which mostly consisted of Haitian businessmen and former members of the army (who sought to reinstate the military following Aristide's disbandment of it).
On 29 February 2004, with rebel contingents marching towards Port-au-Prince, Aristide departed from Haiti. Aristide insists that he was essentially kidnapped by the U.S., while the U.S. State Department maintains that he resigned from office. Aristide and his wife left Haiti on an American airplane, escorted by American diplomats and military personnel, and were flown directly to Bangui, capital of the Central African Republic, where he stayed for the following two weeks, before seeking asylum in a less remote location. This event was later characterized by Aristide as a kidnapping. Though this has never been proven, many observers in the press and academia believe that the US has not provided convincing answers to several of the more suspicious details surrounding the coup, such as the circumstances under which the US obtained Aristide's purported letter of "resignation" (as presented by the US) which, translated from Kreyol, does not actually read as a resignation.
Aristide has accused the U.S. of deposing him in concert with the Haitian opposition. In a 2006 interview, he said the U.S. went back on their word regarding compromises he made with them over privatization of enterprises to ensure that part of the profits would go to the Haitian people and then "relied on a disinformation campaign" to discredit him.
Political organizations and writers, as well as Aristide himself, have suggested that the rebellion was in fact a foreign controlled coup d'état. Caricom, which had been backing the peace deal, accused the United States, France, and the International community of failing in Haiti because they allegedly allowed a controversially elected leader to be violently forced out of office. The international community stated that the crisis was of Aristide's making and that he was not acting in the best interests of his country. They have argued that his removal was necessary for future stability in the island nation.
Some investigators claimed to have discovered extensive embezzlement, corruption, and money laundering by Aristide. It was claimed Aristide had stolen tens of millions of dollars from the country, though specific bank account documents proving this have yet to be presented. None of the allegations about Aristide's involvement in embezzlement, corruption, or money laundering schemes could be proven. The criminal court case brought against Aristide was quietly shelved, though various members of his Lavalas party languished for years in prison without charge or trial due to similar accusations
 The Haitian government suspended the suit against Aristide on 30 Jun 2006 to prevent it from being thrown out for want of prosecution.
The government was taken over by Supreme Court Chief Justice Boniface Alexandre. Alexandre petitioned the United Nations Security Council for the intervention of an international peacekeeping force. The Security Council passed a resolution the same day "[t]aking note of the resignation of Jean-Bertrand Aristide as President of Haiti and the swearing-in of President Boniface Alexandre as the acting President of Haiti
in accordance with the Constitution of Haiti" and authorized such a mission. As a vanguard of the official U.N. force, a force of about 1,000 U.S. Marines arrived in Haiti within the day, and Canadian and French troops arrived the next morning; the United Nations indicated it would send a team to assess the situation within days. These international troops have been criticized for cooperating with rebel forces, refusing to disarm them, and integrating former military and death-squad (FRAPH) members into the re-militarized Haitian National Police force following the coup.
On 1 June 2004, the peacekeeping mission was passed to MINUSTAH and comprised a 7,000 strength force led by Brazil and backed by Argentina, Chile, Jordan, Morocco, Nepal, Peru, Philippines, Spain, Sri Lanka, and Uruguay.
Brazilian forces led the United Nations peacekeeping troops in Haiti composed of United States, France, Canada, and Chile deployments. These peacekeeping troops were a part of the ongoing MINUSTAH operation.
In November 2004, the University of Miami School of Law carried out a Human Rights Investigation in Haiti and documented serious human rights abuses. It stated that "summary executions are a police tactic." It also suggested a "disturbing pattern."
On 15 October 2005, Brazil called for more troops to be sent due to the worsening situation in the country.
After Aristide's overthrow, the violence in Haiti continued, despite the presence of peacekeepers. Clashes between police and Fanmi Lavalas supporters were common, and peacekeeping forces were accused of conducting a massacre against the residents of Cité Soleil in July 2005. Several of the protests resulted in violence and deaths.
The second Préval presidency (2006–2011).
In the midst of the ongoing controversy and violence, however, the interim government planned legislative and executive elections. After being postponed several times, these were held in February 2006. The elections were won by René Préval, who had a strong following among the poor, with 51% of the votes. Préval took office in May 2006.
In the spring of 2008, Haitians demonstrated against rising food prices. In some instances, the few main roads on the island were blocked with burning tires and the airport at Port-au-Prince was closed. Protests and demonstrations by Fanmi Lavalas continued in 2009.
Earthquake 2010.
On 12 January 2010, Haiti suffered a devastating earthquake, magnitude 7.0 with a death toll estimated by the Haitian government at over 300,000, and by non-Haitian sources from 50,000 to 220,000. Aftershocks followed, including one of magnitude 5.9. The capital city, Port-au-Prince, was effectively leveled. A million Haitians were left homeless, and hundreds of thousands starved. The earthquake caused massive devastation, with most buildings crumbled, including Haiti's presidential palace. The enormous death toll made it necessary to bury the dead in mass graves. Most bodies were unidentified and few pictures were taken, making it impossible for families to identify their loved ones. The spread of disease was a major secondary disaster. Many survivors were treated for injuries in emergency makeshift hospitals, but many more died of gangrene, malnutrition, and infectious diseases.
The Martelly presidency (2011–present day).
On 4 April 2011, a senior Haitian official announced that Michel Martelly had won the second round of the election against candidate Mirlande Manigat. Michel Martelly also known by his stage name "Sweet Micky" is a former musician and businessman.

</doc>
<doc id="13375" url="http://en.wikipedia.org/wiki?curid=13375" title="Geography of Haiti">
Geography of Haiti

The Republic of Haiti comprises the western three-eighths of the island of Hispaniola, west of the Dominican Republic. It is positioned between the Caribbean Sea and the North Atlantic Ocean. Haiti's geographic coordinates are at a longitude of 72° 25′ west and a latitude of 19° 00′ north. The total area is 27750 km2, of which 27560 km2 is land and 190 km2 is water. Haiti is slightly smaller than the U.S. state of Maryland. Haiti has 1771 km of coastline and a 360 km-border with the Dominican Republic.
Physical geography.
Haiti is a very mountainous country with more than 3/4ths of the territory above 700 ft. Its climate is tropical and semiarid. Fertile valleys are interspersed between the mountain ranges forming vast areas of contrast between elevations in many areas throughout the territory. The country (and Hispaniola) is separated from Cuba by way of the Windward Passage, a 45 nmi wide strait that passes between the two countries. Haiti's lowest elevation is reported by one source to be sea level (the Caribbean Sea), by another source to be below sea level (Gheskio clinic, Port-au-Prince or in Gonaïves, <-1m), while its highest point is Pic la Selle at 2680 m.
Islands.
Numerous smaller islands make up a part of Haiti's total territory. The most notable islands are:
Haiti also harbors several lakes. The largest lake of Haiti, and the second largest lake of Ile d'Haiti and the West Indies, is "Lake Azuei". It is located in the "Cul-de-Sac Depression" with an area of 170 km². It is a saline lake with a higher concentration of salt than the sea water and harbors numerous fauna such as American Crocodiles and American Flamingos.
Lake Peligre is an artificial lake created by the construction of the Peligre Hydroelectric Dam.
"Trou Caïman" is a saltwater lake with a total area of 16.2 km². "Lake Miragoâne" is one of the largest natural freshwater lakes in the Caribbean, with an area of 25 km².
Climate.
The climate is tropical, with some variation depending on altitude. Port-au-Prince ranges in January from an average minimum of 23 °C to an average maximum of 31 °C; in July, from 25 –. The rainfall pattern is varied, with rain heavier in some of the lowlands and on the northern and eastern slopes of the mountains. Port-au-Prince receives an average annual rainfall of 1370 mm. There are two rainy seasons, April–June and October–November. Haiti is subject to periodic droughts and floods, made more severe by deforestation. Hurricanes are also a menace.

</doc>
<doc id="13376" url="http://en.wikipedia.org/wiki?curid=13376" title="Demographics of Haiti">
Demographics of Haiti

Although Haiti averages approximately 255 people per square kilometer (650 per sq. mi.), its population is concentrated most heavily in urban areas, coastal plains, and valleys. The nation is multi-ethnic, home to peoples of different races and ethnic groups. 95% of Haitians are of predominantly African descent. The remainder 5% of the population is primarily mulattoes, Europeans, Asians and Arabs. Hispanic residents in Haiti are mostly Cuban and Dominican. About two thirds of the Haitian population live in rural areas.
Although there was a national census taken in Haiti in 2003, much of that data has not been released to the public. Several demographic studies, including those by social work researcher Athena Kolbe, have shed light on the current status of urban residents. In 2006, households averaged 4.5 members. The median age was 25 years with a mean average age of 27 years. People aged 15 and younger counted for roughly a third of the population. Overall, 52.7 percent of the population was female.
Population.
According to the 2012 revison of the World Population Prospects the total population was 9,896,000 in 2010, compared to 3,221,000 in 1950. The proportion of children below the age of 15 in 2010 was 36.2%, 59.7% was between 15 and 65 years of age, while 4.5% was 65 years or older
Vital statistics.
Registration of vital eventes is in Haiti not complete. The Population Department of the United Nations prepared the following estimates.
Disasters often cause human populations to increase long term, rather than decrease, by way of increased fertility exceeding the deaths caused by the initial disaster, as shell-shocked mothers replace every lost child with more than needed. In Haiti's case, the fertility rate nearly tripled after the quake, and is likely to remain elevated (above pre-quake levels) for long after.
Fertility and Births.
Total Fertility Rate (TFR) and Crude Birth Rate (CBR):
Languages.
Taíno was the major pre-Columbian language in the region now known as Haiti. One of the country's official languages is Haitian Creole, a French-based creole with African influences, as well as minor Spanish and Taíno influences. French is the other official language. Spanish, though not official, is spoken by a growing amount of the population, and is spoken more frequently near the border with the Dominican Republic. English is increasingly spoken among the young and in the business sector.
Religion.
The state religion is Roman Catholicism which 80-85% of the population professes. 15-20% of Haitians practice Protestantism. Roughly half of the population practice Vodou, mostly along with another religion.
Education.
Although public education at the primary level is now free, private and parochial schools provide around 75% of educational programs offered.
In recent years, several annual literacy campaigns launched in by the Martelly administration has increased overall literacy among adults in Haiti. UNESCO projects an overall literacy rate of 61.1% in Haiti by 2015.
As of December 2014, World bank has reported that school enrollment has increased from 78% to 90% in Haiti, very close to the goal of universal child enrollment.
Labor.
In 2004, 300,000 children were restavecs, which are somewhat like indentured service for minors. This was done by their parents in order that the children would be fed.
Emigration.
Large-scale emigration, principally to the United States, and Canada (predominantly to Quebec, with other areas of the country) - but also to Cuba, other areas of Europe and the Americas (like Argentina) such as France (with French Guiana), Spain, Belgium, the United Kingdom and Ireland; and Venezuela, Brazil, the Dominican Republic, the Bahamas and other Caribbean neighbors - has created what Haitians refer to as the Eleventh Department or the Diaspora. About one of every six Haitians live abroad.
CIA World Factbook demographic statistics.
The following demographic statistics are from the CIA World Factbook (as of June 22, 2014[ [update]]).
Population: 9,996,731 (2014 est.)†
Nationality:
Religions: Roman Catholic 80%, Protestant 16% (Baptist 10%, Pentecostal 4%, Adventist 1%, other 1%), none 1%, other 3% (Islam, Bahá'í Faith, Judaism, Buddhism, Hinduism).
Languages: French (official), Haitian Creole (official), Spanish (non-official)
Literacy: (2008 est. by IHSI)

</doc>
<doc id="13377" url="http://en.wikipedia.org/wiki?curid=13377" title="Politics of Haiti">
Politics of Haiti

The Politics of Haiti have often been defined with conflict when strongmen have taken over the government. Only within the later part of the twentieth century, has normal political activity established.
History.
On February 29, 2004, a coup d'état ousted the popularly elected president, Jean-Bertrand Aristide, allegedly with the assistance of the French and United States governments; U.S. and French soldiers were on the ground in Haiti at the time, recently arrived (See controversy). The first elections since the overthrow were held on February 8, 2006 to elect a new President. René Préval was declared to have won with over 50 percent of the vote.
Runoff elections for legislative seats were held on April 21.
In 2008, Parliament voted to dismiss President Preval's Prime Minister following severe rioting over food prices. His selected replacement for the post was rejected by Parliament, throwing the country into a prolonged period without a government.
Yvon Neptune was appointed Prime Minister on March 4, 2002, but following the overthrow of the government in February 2004, he was replaced by an interim Prime Minister, Gérard Latortue. The constitutional Prime Minister, Yvon Neptune languished in jail for 
over a year, accused of complicity in an alleged massacre in Saint-Marc. United Nations officials, expressing scepticism towards the evidence, called for either due process or his release. Having entered custody in June 2004, Neptune was formally charged on September 20, 2005, but was never sent to trial. He was finally released on 28 July 2006. The last Prime Minister, Jacques-Édouard Alexis, entered office in 2006 and was removed in April 2008. Michèle Pierre-Louis received approval to become the next Prime Minister from both houses in July.
Corruption.
Political corruption is a common problem in Haiti. The country has consistently ranked as one of the most corrupt nations according to the Corruption Perceptions Index, a measure of perceived political corruption. In 2006, Haiti was ranked as the most corrupt nation out of the 163 that were surveyed for the Index. In 2012, Haiti was #165 out of #176. The International Red Cross reported that Haiti was 155th out of 159 countries in a similar survey of corrupt countries.
In 2013, Haiti ranked #8 in the Fragile States Index
Creole in Politics and Corruption.
French has been the major language in Haitian politics since the colonial era. Scholars have since referred to Creole, the other language of Haiti as linguistically inferior. Creole grammar is said to be simplified and lacking sophistication compared to its European ancestors. This original demotion of the language created a subordinate sociopolitical, economic, and biological status for the country's majority that had been relocated by slavery. 
Today, Creole is spoken by 90-95% of the country. The remaining are bilingual and speak both French and Creole. Per the 1987 Constitution, both Creole and French are official languages of Haiti. However, French is still the main language taught in schools and used in politics. With only 2-5% speaking the language of the politics, Creole speakers are politically disenfranchised. Haitian Creole and French are mutually unintelligible, so the vast majority of citizens cannot communicate with leaders in the language of their choice. 
This disenfranchisement is furthered by the lack of a systematic educational system. Literacy programs failed in the 1980s, and French is still the language being used to instruct students. Haitian linguist, Yves Dejean, recalls warnings posted in the principal's office forbidding the use of Creole. In the 1970s, only one percent of the children who entered kindergarten stayed on track to obtain state certificate at the end of the sixth grade.
Even after the literacy programs of the 1980s, 90% of the teachers ten years after the decree were still not able to encompass the Creole language into the education system. The language handicap makes education and furthermore, political enfranchisement almost impossible.

</doc>
<doc id="13378" url="http://en.wikipedia.org/wiki?curid=13378" title="Economy of Haiti">
Economy of Haiti

Haiti has a market economy. Labor costs are lower than average for North America. Its major trading partner is the United States. Haiti has preferential trade access to the US market through the Haiti Hemispheric Opportunity though Partnership HOPE and Haiti Economic Lift Program Encouragement Acts {HELP} legislation, which allows duty-free access, for a variety of textiles, to the US market. 
Haiti has an agricultural economy. Over half of the world's vetiver oil (an essential oil used in high-end perfumes) comes from Haiti, and bananas, cocoa, and mangoes are important export crops. Haiti has also moved to expand to higher-end manufacturing, producing Android-based tablets and current sensors and transformers. While Haiti's national languages are French and Creole, English is the most commonly used language in business, with Spanish widely adopted in certain sectors.
Vulnerability to natural disasters, as well as poverty and limited access to education are among Haiti's most serious disadvantages. Two-fifths of all Haitians depend on the agriculture sector, mainly small-scale subsistence farming, and remain vulnerable to damage from frequent natural disasters, exacerbated by the country's widespread deforestation. Haiti suffers from a severe trade deficit, which it is working to address by moving into higher-end manufacturing and more value-added products in the agriculture sector. Remittances are the primary source of foreign exchange, equaling nearly 20% of GDP. Haiti's economy was severely impacted by the 2010 Haiti earthquake which occurred on 12 January 2010.
Economic history.
Before Haiti established its independence from French administration in 1804, Haiti ranked as the world's richest and most productive colony. In the formative years of independence, Haiti suffered from isolation on the international stage, as evidenced by the early lack of diplomatic recognition accorded to it by Europe and the United States; this had a negative impact on willingness of foreigners to invest in Haiti. One very significant economic obstacle in Haiti's early independence was its necessary payment of 150 million francs to France beginning in 1825; this did much to drain the country of its capital stock. In 1838, France agreed to reduce the debt to 60 million francs to be paid over a period of 30 years. In 1883, Haiti made the final payment to France. Since then, and even in recent years, public spokesmen in Haiti as well as international academics and statesmen have denounced this event as the payment of an illegitimate debt, in several cases calling on the French government to repay it (the French government has never been willing to repay it, though there was a hoax following the 2010 Haiti Earthquake involving a fake website purporting to offer reparation payment on behalf of the French Government).
Since the demise of the Duvalier dictatorship in 1986, international economists have urged Haiti to reform and modernize its economy. Under President René Préval (President from 1996 to 2001 and from 2006 until 14 May 2011), the country's economic agenda included trade and tariff liberalization, measures to control government expenditure and increase tax revenues, civil-service downsizing, financial-sector reform, and the modernization of state-owned enterprises through their sale to private investors, the provision of private sector management contracts, or joint public-private investment. Structural adjustment agreements with the International Monetary Fund, World Bank, Inter-American Development Bank, and other international financial institutions aiming at creating necessary conditions for private sector growth, have proved only partly successful.
In the aftermath of the 1994 restoration of constitutional governance, Haitian officials have indicated their commitment to economic reform through the implementation of sound fiscal and monetary policies and the enactment of legislation mandating the modernization of state-owned enterprises. A council to guide the modernization program (CMEP) was established and a timetable was drawn up to modernize nine key parastatals. Although the state-owned flour-mill and cement plants have been transferred to private owners, progress on the other seven parastatals has stalled. The modernization of Haiti's state-enterprises remains a controversial political issue in Haiti.
External aid is essential to the future economic development of Haiti, the least-developed country in the Americas. Comparative social and economic indicators show Haiti falling behind other low-income developing countries (particularly in the Western hemisphere) since the 1980s. Haiti's economic stagnation results from earlier inappropriate economic policies, political instability, a shortage of good arable land, environmental deterioration, continued use of traditional technologies, under-capitalization and lack of public investment in human resources, migration of large portions of the skilled population, and a weak national savings rate.
Haiti continues to suffer the consequences of the 1991 coup. The irresponsible economic and financial policies of "de facto" authorities greatly accelerated Haiti's economic decline. Following the coup, the United States adopted mandatory sanctions, and the OAS instituted voluntary sanctions aimed at restoring constitutional government. International sanctions culminated in the May 1994 United Nations embargo of all goods entering Haiti except humanitarian supplies, such as food and medicine. The assembly sector, heavily dependent on U.S. markets for its products, employed nearly 80,000 workers in the mid-1980s. During the embargo, employment fell from 33,000 workers in 1991 to 400 in October 1994. Private, domestic and foreign investment has been slow to return to Haiti. Since the return of constitutional rule, assembly sector employment has gradually recovered with over 20,000 now employed, but further growth has been stalled by investor concerns over safety and supply reliability.
If the political situation stabilizes, high crime levels wane, and new investment increases, tourism could take its place next to export-oriented manufacturing (the assembly sector) as a potential source of foreign exchange. Remittances from abroad have consistently constituted a significant source of financial support for many Haitian households.
The Haitian Ministry of Economy and Finance designed the Haiti economic reforms of 1996 to rebuild the economy of Haiti after significant downturns suffered in the previous years. The primary reforms centered around the Emergency Economic Recovery Plan (EERP) and were followed by budget reforms.
Haiti's real GDP growth turned negative in FY 2001 after six years of growth. Real GDP fell by 1.1% in FY 2001 and 0.9% in FY 2002. Macroeconomic stability was adversely affected by political uncertainty, the collapse of informal banking cooperatives, high budget deficits, low investment, and reduced international capital flows, including suspension of IFI lending as Haiti fell into arrears with the Inter-American Development Bank (IDB) and World Bank.
Haiti's economy stabilized in 2003. Although FY 2003 began with the rapid decline of the gourde due to rumors that U.S. dollar deposit accounts would be nationalized and due to the withdrawal of fuel subsidies, the government successfully stabilized the gourde as it took the politically difficult decisions to float fuel prices freely according to world market prices and to raise interest rates. Government agreement with the International Monetary Fund (IMF) on a staff monitored program (SMP), followed by its payment of its $32 million arrears to the IDB in July, paved the way for renewed IDB lending. The IDB disbursed $35 million of a $50 million policy-based loan in July and began disbursing four previously approved project loans totaling $146 million. The IDB, IMF, and World Bank also discussed new lending with the government. Much of this would be contingent on government adherence to fiscal and monetary targets and policy reforms, such as those begun under the SMP, and Haiti's payment of its World Bank arrears ($30 million at 9/30/03).
The IMF estimated that real GDP was flat in FY 2003 and projected 1% real GDP growth for FY 2004. However, GDP per capita— amounting to $425 in FY 2002 — will continue to decline as population growth is estimated at 1.3% p.a. While implementation of governance reforms and peaceful resolution of the political stalemate are key to long-term growth, external support remains critical in avoiding economic collapse. The major element is foreign remittances, reported as $931 million in 2002, primarily from the U.S. Foreign assistance, meanwhile, was $130 million in FY 2002. Overall foreign assistance levels have declined since FY 1995, the year elected government was restored to power under a United Nations mandate, when the international community provided over $600 million in aid.
A legal minimum wage of 36 gourdes a day (about U.S. $1.80) was set in 1995, and applies to most workers in the formal sector. It was later raised to 70 gourdes per day. Actually this minimum is 200 gourdes a day(about U.S. $4.80). 39.175 gourds= a U.S dollar.
Haiti's economy suffered a severe setback in January 2010 when a 7.0 magnitude earthquake destroyed much of its capital city, Port-au-Prince, and neighboring areas. Already the poorest country in the Western Hemisphere with 80% of the population living under the poverty line and 54% in abject poverty, the earthquake inflicted $7.8 billion in damage and caused the country's GDP to contract 5.4% in 2010. Following the earthquake, Haiti received $4.59 billion in international pledges for reconstruction, which has proceeded slowly.
US economic engagement under the Haitian Hemispheric Opportunity through Partnership Encouragement (HOPE) Act, passed in December 2006, has boosted apparel exports and investment by providing duty-free access to the US. Congress voted in 2010 to extend the legislation until 2020 under the HELP Act; the apparel sector accounts for about 90% of Haitian exports and nearly one-tenth of GDP. Remittances are the primary source of foreign exchange, equaling nearly 20% of GDP and more than twice the earnings from exports. Haiti suffers from a lack of investment, partly because of limited infrastructure and a lack of security. In 2005, Haiti paid its arrears to the World Bank, paving the way for reengagement with the Bank. Haiti received debt forgiveness for over $1 billion through the Highly-Indebted Poor Country initiative in mid-2009. The remainder of its outstanding external debt was cancelled by donor countries following the 2010 earthquake but has since risen to over $600 million. The government relies on formal international economic assistance for fiscal sustainability, with over half of its annual budget coming from outside sources. The Michel Martelly administration in 2011 launched a campaign aimed at drawing foreign investment into Haiti as a means for sustainable development.
Corruption in Haiti.
According to a World Bank report in 2015, in Haiti, the process of business regulations is complex and customs procedures are lengthy. On average, opening a business took 97 days. For comparison, the average was 30.1 days in Latin America and 9.2 days in OECD countries. It took 30 days to register a property.
Haiti ranked 31st out of 32 in 'Ease of doing business in Latin America & Caribbean' economies. Haiti Also ranked 180th out of 189 countries worldwide in 'Ease of doing business". Due to bribery and red-tape, expedient service may require establishing a rapport with officials.
Haiti's location in the central Caribbean makes it an ideal transshipment point for drugs being smuggled from Colombia to the U.S. Political turmoil and lack of transparency has enticed many local officials in the past to collaborate with drug smugglers from neighboring countries. Although it should be noted that steps have been taken by the international community in conjunction with the Haitian government to secure the Haitian borders.
Debt cancellation.
In 2005 Haiti's total external debt reached an estimated US$1.3 billion, which corresponds to debt per capita of US$169, in contrast to the debt per capita of the United States which is US$40,000. Following the democratic election of Aristide in December 1990, many international creditors responded by cancelling significant amounts of Haiti's debt, bringing the total down to US$777 million in 1991. However, new borrowing during the 1990s swelled the debt to more than US$1 billion.
At peak, Haiti's total external debt was estimated at 1.8 billion dollars, including half a billion dollars to the Inter-American Development Bank, Haiti's largest creditor. In September 2009, Haiti met the conditions set out by the IMF and World Bank's Heavily Indebted Poor Countries program, qualifying it for cancellation of some of its external debt. This amounted to a cancellation of $1.2 billion. Despite this as of 2010 calls for cancellation of its remaining $1 billion debts came strongly from civil society groups such as the Jubilee Debt Campaign in reaction to the effects of the earthquake that hit the country.
Industries.
Agriculture, forestry, and fishing.
Although many Haitians make their living through subsistence farming, Haiti also has an agricultural export sector. Agriculture, together with forestry and fishing, accounts for about one-quarter (28% in 2004) of Haiti's annual gross domestic product and employs about two-thirds (66% in 2004) of the labor force. However, expansion has been difficult because mountains cover much of the countryside and limit the land available for cultivation. Of the total arable land of 550,000 hectares, 125,000 hectares are suited for irrigation, and of those only 75,000 hectares actually have been improved with irrigation. Haiti's dominant cash crops include coffee, mangoes, and cocoa. Haiti has decreased its production of sugarcane, traditionally an important cash crop, because of declining prices and fierce international competition. Because Haiti's forests have thinned dramatically, timber exports have declined. Roundwood removals annually total about 1,000 kilograms. Haiti also has a small fishing industry. Annual catches in recent years have totaled about 5,000 tons
Mining and minerals.
Haiti has a mining industry which extracted minerals worth approximately US$13 million in 2013. Bauxite, copper, calcium carbonate, gold, and marble were the most extensively extracted minerals in Haiti. Lime and aggregates and to a lesser extent marble are extracted. Gold was mined by the Spanish in early colonial times. Bauxite was mined for a number of years in recent times at a site near Miragoâne on the Southern peninsula. Operating from 1960 to 1972 International Halliwell Mines, Ltd. ("Halliwell"), a Canadian corporation, through its wholly owned Haitian subsidiary, La Societe d'Exploitation et de Developpement Economique et Natural d'Haiti ("Sedren") mined copper near Gonaïves. 1.5 million tons of ore were exported. The copper ore was valued at about $83.5 million. The government of Haiti received about $3 million. As of 2012 there was promise of gold and copper mining in northern Haiti
Gold.
In 2012, it was reported that confidential agreements and negotiations had been entered into by the Haitian government granting licenses for exploration or mining of gold and associated metals such as copper for over 1000 mi2 in the mineralized zone stretching from east to west across northern Haiti. Estimates for the value of the gold which might be extracted through open-pit mining are as high as US$20 billion. Eurasian Minerals and Newmont Mining Corporation are two of the firms involved. According to Alex Dupuy, Chair of African American Studies and John E. Andrus Professor of Sociology at Wesleyan University the ability of Haiti to adequately manage the mining operations or to obtain and use funds obtained from the operations for the benefit of its people is untested and seriously questioned. Lakwèv, where earth dug from hand-made tunnels is washed for specks of free gold by local residents, is one of the locations. In the same mineralized zone in the Dominican Republic Barrick Gold and Goldcorp are planning on reopening the Pueblo Viejo mine.
Industry and manufacturing.
The leading industries in Haiti produce beverages, butter, cement, detergent, edible oils, flour, refined sugar, soap, and textiles. Growth in both manufacturing and industry as a whole has been slowed by a lack of capital investment. Grants from the United States and other countries have targeted this problem, but without much success. Private home building and construction appear to be one subsector with positive prospects for growth.
In 2004 industry accounted for about 20 percent of the gross domestic product (GDP), and less than 10 percent of the labor force worked in industrial production. As a portion of the GDP, the manufacturing sector has contracted since the 1980s. The United Nations embargo of 1994 put out of work most of the 80,000 workers in the assembly sector. Additionally, the years of military rule following the presidential coup in 1991 resulted in the closure of most of Haiti's offshore assembly plants in the free zones surrounding Port-au-Prince. When President Aristide returned to Haiti, some improvements did occur in the manufacturing sector.
Haiti's cheaper labor brought some textile and garment assembly work back to the island in the late 1990s. Although these gains were undercut by international competition, the apparel sector in 2008 made up two-thirds of Haiti's annual 490 million US dollars exports. USA economic engagement under the HOPE Act, from December 2006, increased apparel exports and investment by providing tariff-free access to the USA. HOPE II, in October 2008, further improved the situation by extending preferences to 2018.
Energy.
Haiti uses very little energy, the equivalent of approximately 250 kilograms of oil per head per year. In 2003, Haiti produced 546 million kilowatt-hours of electricity while consuming 508 million kilowatt-hours. In 2013, it stood 135th out of 135 countries in net total consumption of electricity.
Most of the country's energy comes from the burning of wood. Haiti imports oil, consuming about 11800 oilbbl/d, as of 2003. The Péligre Dam, the country's largest, provides the capital city of Port-au-Prince with energy. Thermal plants provide electricity to the rest of the country. Even with the country's low level of demand for energy, the supply of electricity traditionally has been sporadic and prone to shortages. Mismanagement by the state has offset more than US$100 million in foreign investment targeted at improving Haiti's energy infrastructure. Businesses have resorted to securing back-up power sources to deal with the regular outages. The potential for greater hydropower exists, should Haiti have the desire and means to develop it. The government controls oil and gas prices, to an extent insulating Haitians from international price fluctuations.
Services.
Haiti's services sector made up 52 percent of the country's gross domestic product in 2004 and employed 25 percent of the labor force. According to World Bank statistics, the services sector is one of the few sectors of Haiti's economy that sustained steady, if modest, growth throughout the 1990s.
Banking and finance.
Lack of a stable and trustworthy banking system has impeded Haiti's economic development. Banks in Haiti have collapsed on a regular basis. Most Haitians do not have access to loans of any sort. When reelected in 2000, President Aristide promised to remedy this situation but instead introduced a non-sustainable plan of "cooperatives" that guaranteed investors a 10 percent rate of return. By 2000, the cooperatives had crumbled and Haitians had collectively lost more than US$200 million in savings.
Haiti's central bank, the Banque de la République d'Haïti, oversees 10 commercial banks and two foreign banks operating in the country. Most banking takes place in the capital city of Port-au-Prince. The United Nations and the International Monetary Fund have led efforts to diversify and expand the finance sector, making credit more available to rural populations. In 2002, the Canadian International Development Agency led a training program for Haitian Credit Unions. Haiti has no stock exchange.
Tourism.
Tourism in Haiti has suffered from the country's political upheaval. Inadequate infrastructure also has limited visitors to the island. In the 1970s and 1980s, however, tourism was an important industry, drawing an average of 150,000 visitors annually. Since the 1991 coup, tourism has recovered slowly. The Caribbean Tourism Organization (CTO) has joined the Haitian government in an effort to restore the island's image as a tourist destination. In 2001, 141,000 foreigners visited Haiti. Most came from the United States. To make tourism a major industry for Haiti, further improvements in hotels, restaurants and other infrastructure still are needed.
Labor force.
As of 1995, the labor force was estimated at 3.6 million, but with a shortage of skilled labor.
Finding unemployment statistics from Haiti is very difficult because of the lack of publication of such data from the Haitian agencies in charge of collecting it. Most sources that we do have available come from United States agencies such as the Agency for International Development (USAID).
These numbers are highly speculative; many sources give vague ideas of the unemployment rating being (for example, in 2003) around 50%, giving the impression that the actual rate could be several percentage points higher or lower. Still, given that the sources of this data has remained the same for the past 15 years, we can at least see a trend of unemployment staying high throughout this period, but rising sharply in the mid to late 90s peaking at 70% in 1999 (2000 CIA World Factbook is the source for that number), and then decreasing to the usual rates of around 50% in recent years.
References.
Much of this article is based on public domain material from the U.S. government. See:
http://www.state.gov/r/pa/ei/bgn/1982.htm

</doc>
<doc id="13379" url="http://en.wikipedia.org/wiki?curid=13379" title="Telecommunications in Haiti">
Telecommunications in Haiti

Telecommunications in Haiti include radio, television, fixed and mobile telephones, and the Internet.
Telephones.
In 2012, there were 50,000 main lines in use ranking Haiti 163rd in the world.
Natcom, the result of the privatization of Télécommunications d'Haiti S.A.M. (Teleco) in 2010, has a monopoly on the provision of landline services throughout the country. The Vietnamese company Viettel bought a 60% share, with the Haitian government keeping the remaining 40% of the company.
Teleco was constantly hobbled by political interference which affected its performance. A net generator of revenues for the government in the 1970s and early 1980s, Teleco's fortunes then began to decline.
Despite wide-ranging poverty, Haiti increased its mobile phone coverage rate from 6% to 30% in one year (May 2006 to May 2007). Haiti is now the driving force in mobile phone growth in the Caribbean, while radio remains the primary information medium for most Haitians.
In May 2006, Comcel and Haitel had a total of about 500,000 subscribers - a cell phone coverage rate of 6% for a population of 8.2 million. Digicel entered the market in May 2006. After one year of operations, May 2006-May 2007, Digicel went from zero to 1.4 millions subscribers. The other two cell phone providers, Comcel and Haitel, responded by cutting their prices and offering new services such as Voilà, a GSM service by Comcel, and CDMA 2000 by Haitel. As a result, Comcel and Haitel increased their subscribers from 500,000 to 1 million. As of April 2012, Digicel has about 3.5 millions cell phone subscribers in Haiti. In May 2007, Digicel started offering two BlackBerry services with Internet, one for enterprises and one for individuals. On March 30, 2012, Digicel completed the acquisition of Comcel / Voila, its main competitor in the Haitian market.
Internet.
There are 5 Internet service providers serving the country. Among them are Multilink, H@inet and Access Haiti. In June 2010, Viettel (Natcom) announced that it would provide high speed Internet throughout the country by laying 3100 km of optical fiber.
The Haitian telecommunications authority, CONATEL, decided in October 2010 to allow the introduction of 3G services by the mobile telephone service providers. This will enable them to deploy faster mobile internet access speeds throughout their networks than what is currently available with GPRS/EDGE.
Internet censorship and surveillance.
There are no government restrictions on access to the Internet or credible reports that the government monitors e-mail or Internet chat rooms without judicial oversight.
The law provides for freedom of speech and press, and the government and elected officials generally respect these rights in practice. The independent media are active and express a wide variety of views without restriction. However, there have been incidents of local officials harassing or threatening journalists and others who criticized the government. Journalists complain about defamation lawsuits that the government threatens or files against the press for statements made about public officials or private figures in the public arena.
Defamation carries both criminal and civil penalties. Some journalists practice self-censorship on stories related to drug trafficking or allegations of business and political corruption, likely due to past patterns of retribution against activists and journalists engaged in investigative reporting. The law prohibits arbitrary interference with privacy, family, home, or correspondence, but the government does not always respect these prohibitions in practice.

</doc>
<doc id="13380" url="http://en.wikipedia.org/wiki?curid=13380" title="Transport in Haiti">
Transport in Haiti

All of the major transportation systems in Haiti are located near or run through the capital, Port-au-Prince.
Roads.
Haiti’s network of roads consists of National Roads, Department Roads, and county roads. The hub of the road network is located at the old airport (at the intersection of Boulevard Jean-Jacques Dessalines and Autoroute de Delmas). From this intersection, Route Nationale #1 and Route Nationale #2 commence.
Maintenance for RN1 and RN2 lapsed after the 1991 coup, prompting the World Bank to loan US$50 million designated for road repairs. The project was canceled in January 1999. The World Bank, who view the cancellation of those projects will ruin Haiti road Infrastructure Concise into creating, FER (Fond d’Etretient Routiers) in 2003, this was a way to cut down corruption, get local company involved, and not stopping those works because of political Contestation. President Rene Preval on his campaign for his second terms vow on his Maillages Routiers to rebuild the majority of those roads that was disintegrate rapidly and build new one that will enable the country to move forward; when he could not get fund from the world Bank went Literally and beg Foreign donor for assistant which was heavily criticize by many politicians in the media, but was greatly embrace by a population desperate to see road pave come in to their town. Therefore EU had pledge to help Build RN6 than RN3. In the mean time the World Bank loan Haiti US$200 Million to rebuild RN2, From River Froide which was where the starting point of RN2 all the way to Aquin and Repair on RN1 from Titanyen to Cap-Haitian. The hurricane of 2008 was a major setback since many bridges in multiple areas was either Collapse or suffers extensive damage; was in immediate need of repair. Most of those works on RN1 and RN2 who were already stopped suffer a Major setback during the earthquake of January 12, 2010. For the Construction of RN7 Canada Pledge US$75 and IDB US$31 Million for the construction of the road which started in 2009; it did suffer major setback because of the earthquake also.
Public transportation.
The public transportation is mostly privately owned in Haiti, previously it was an individual business, with the new generation of entrepreneurs, it is mainly association. The most common form of public transportation in Haiti is the use of brightly painted pickup trucks as taxis called "tap-taps". They are named this because when a passenger needs to be let off they use their coin money to tap the side of the vehicle and the driver usually stops. Most tap-taps are fairly priced at around 10-15 gourdes per ride within a city. The catch to the price is that the driver will often fill a truck to maximum capacity, which is nearly 20-30 people. The Government in an effort to structure the public transportation has attempted several time to bring BUS, in around 1979, It was the BUS called CONATRA a contract between the government and association of driver which quickly failed because of sabotage from different factor and poor maintenance. In 1998 another attempt was made with the Service Plus and Dignite for student and teacher. Sabotage, poor maintenance and the overthrow of Aristide in 2004 had severely undermined the effort, in 2006 at the return of Preval in power another effort was made to recover the majority of the bus left, and a Gift of 300 new bus from Taiwan an effort to bring back Service Plus in association of the drivers. Mini-vans are frequently used to cover towns close to Port-au-Prince, such as Pétionville, Jacmel, Leogane and others. Today throughout the island, motorcycles are widely used as a form of taxi.
Water transport.
The port at Port-au-Prince, Port international de Port-au-Prince, has more registered shipping than any of the over dozen ports in the country. The port's facilities include cranes, large berths, and warehouses, but these facilities are in universally poor shape. The port is underused, possibly due to the substantially high port fees compared to ports in the Dominican Republic.
The port of Saint-Marc is currently the preferred port of entry for consumer goods coming into Haiti. Reasons for this may include its location away from volatile and congested Port-au-Prince, as well as its central location relative to a large group of Haitian cities including Cap-Haïtien, Carrefour, Delmas, Desarmes, Fond-Parisien, Fort-Liberté, Gonaïves, Hinche, l'Artibonite, Limbe, Pétionville, Port-de-Paix, and Verrettes. These cities, together with their surrounding areas, contain about six million of Haiti's eight million people.
The Island of Ile-a-vache, La Tortue, Petit and Grand Caillimite, gros-caille and la Gonave are reachable only by ferry or small sailing boat, except for La Gonave, which has an air strip that is rarely used. The majority of towns near the coast of Haiti are also accessible by the small sailing boat, which is preferable and cheaper to many passengers. In some area sailing boats are more available for the commute than public transportation, which usually is on the back of a Truck load with merchandise and passengers that rarely come to those areas except when it’s the Public market day.
Statistics.
 150 km navigable
none (1999 est.)
Ports and harbors.
Cap-Haïtien, Gonaïves, Jacmel, Jérémie, Les Cayes, Miragoâne, Port-au-Prince, Port-de-Paix, Saint-Marc, Fort-Liberté
History.
Haiti has one of the oldest maritime histories in the Americas.
The Panama Canal Railway Company ran a shipping line with three ocean liners that traveled between New York City (USA) - Port-au-Prince (Haiti) - Cristobal (Panama). The company had facilities in Port-au-Prince and their ocean liners stopped there. It has not had any known railroad operations in Haiti.
The three ocean liners were:
Aviation.
" International flights: " Toussaint Louverture International Airport (formerly known as Port-au-Prince International Airport), which opened in 1965 (as François Duvalier International Airport), is located 10 km North/North East of Port-au-Prince. It is Haiti's only jetway, and as such, handles the vast majority of the country's international flights. Air Haïti, Tropical Airways and a handful of major airlines from Europe, the Caribbean, and the Americas serve the airport. 
" Domestic flights: " are available through Sunrise Airways which is Haiti's largest airline for the general public offering scheduled, as well as, charter flights. Another domestic company is, Mission Aviation Fellowship catering to non-Catholic registered Christians.
Statistics.
14 (2007 est.)
Railroads.
Railroads ran in Haiti Between 1876 to 1991. Haiti was the first country in the Caribbean with a railway system, in the urban area of Port-au-Prince and later a project that was supposed to run by The company McDonald from Port-au-Prince to Cap-Haitian, and From Port-au-Prince to Les Cayes, it was not completed. Most of the disoperation of the railroad in Haiti is due to bankruptcy, and closure of the company who supported the construction of the railroad.

</doc>
<doc id="13381" url="http://en.wikipedia.org/wiki?curid=13381" title="Military of Haiti">
Military of Haiti

The country of Haiti currently has no regular military. The former Haitian Armed Forces were demobilized in 1995.
Haiti's current forces consist of the Haitian National Police, which has several paramilitary units, a highly trained and equipped SWAT team, and the Haitian Coast Guard. The regular Haitian Army, Navy, and Air Force still exist on paper and have not been constitutionally abolished.
Haitian National Police.
The Haitian National Police is tasked with providing law enforcement and security for Haiti. The force currently numbers more than 8,500 police officers, and is expected to reach 14,000. The force consists of the General and Administrative Services, the Administrative Police, the Judicial Police, the SWAT team, and the Presidential Protection Unit. The Police also has several paramilitary units for defense.
The Haitian police uses the following weapons:
Haitian Coast Guard.
The Haitian Coast Guard is charged with law enforcement, security, and search and rescue operations. It maintains bases in Port-au-Prince, Cap-Haïtien, and Jacmel. It is led by the Commandant of the Coast Guard, an Assistant Commandant, an Operations Manager, and a Head of Administration. The force currently has 19 vessels. Officially, it is a part of the Haitian National police.

</doc>
<doc id="13383" url="http://en.wikipedia.org/wiki?curid=13383" title="Heard Island and McDonald Islands">
Heard Island and McDonald Islands

The Territory of Heard Island and McDonald Islands (abbreviated as HIMI) are an Australian external territory and volcanic group of barren Antarctic islands, about two-thirds of the way from Madagascar to Antarctica. The group's overall size is 372 km2 in area and it has 101.9 km of coastline. Discovered in the mid-19th century, they have been territories of Australia since 1947 and contain the only two active volcanoes in Australian territory. The summit of one, Mawson Peak, is higher than any mountain on the Australian mainland. They lie on the Kerguelen Plateau in the Indian Ocean.
The islands are among the most remote places on Earth: They are located approximately 4099 km southwest of Perth, 3845 km southwest of Cape Leeuwin, Australia, 4200 km southeast of South Africa, 3830 km southeast of Madagascar, 1630 km north of Antarctica, and 450 km southeast of the Kerguelen Islands. The islands are currently uninhabited.
Geography.
Heard Island, by far the largest of the group, is a 368 km2 bleak and mountainous island located at . Its mountains are covered by 41 glaciers (the island is 80% covered with ice) and dominated by Mawson Peak, a 2745 m high complex volcano which forms part of the Big Ben massif. A July 2000 satellite image from the University of Hawaii's Institute of Geophysics and Planetology (HIGP) Thermal Alert Team, University of Hawai'i showed an active 2 km long (and 50 - wide) lava flow trending south-west from the summit of Big Ben.
The McDonald Islands are located 44 km to the west of Heard Island at . The islands are small and rocky. In 1980 they consisted of McDonald Island (186 m high), Flat Island (55 m high) and Meyer Rock (170 m high). They totalled approximately 2.5 km2 in area, where McDonald Island was 1.13 km2 large. 
Mawson Peak is one of only 2 active volcanoes in Australian territory, the other being McDonald Island. It is also one of the highest Australian mountains (higher than Mount Kosciuszko); surpassed only by peaks in the Antarctic territory. There is a small group of islets and rocks about 10 km north of Heard Island, consisting of Shag Islet, Sail Rock, Morgan Island and Black Rock. They total about 1.1 km2 in area. The volcano on McDonald Island, after being dormant for 75,000 years, became active in 1992 and has erupted several times since. The most recent eruption is thought to have been on 10 August 2005.
Heard Island and the McDonald Islands have no ports or harbours; ships must anchor offshore. The coastline is 101.9 km, and a 12 nmi territorial sea and 200 nmi exclusive fishing zone are claimed.
Climate.
The islands have an Antarctic climate, tempered by their maritime setting. The weather is marked by low seasonal and daily temperature ranges, persistent and generally low cloud cover, frequent precipitation and strong winds. Snowfall occurs throughout the year. Monthly average temperatures at Atlas Cove (at the northwestern end of Heard Island) range from 0.0 to, with an average daily range of 3.7 to in summer and -0.8 to in winter. The winds are predominantly westerly and persistently strong. At Atlas Cove, monthly average wind speeds range between around 26 to. Gusts in excess of 180 km/h have been recorded. Annual precipitation at sea level on Heard Island is in the order of 1300 to; rain or snow falls on about 3 out of 4 days.
Meteorological records at Heard Island are incomplete, but there is evidence that the local climate is changing. Observations at Atlas Cove indicate an increase in average annual air temperature of almost 1 °C between the periods 1948-1954 and 1997-2001.
Flora.
Constraints.
The islands are part of the Southern Indian Ocean Islands tundra ecoregion that includes several subantarctic islands. In this cold climate plant life is mainly limited to grasses and mosses. Low plant diversity reflects the islands’ isolation, small size, severe climate, the short, cool growing season and, for Heard Island, substantial permanent ice cover. The main environmental determinants of vegetation on subantarctic islands are wind exposure, water availability, parent soil composition, salt spray exposure, nutrient availability, disturbance by trampling (from seabirds and seals) and, possibly, altitude. At Heard Island, exposure to salt spray and the presence of breeding and moulting seabirds and seals are particularly strong influences on vegetation composition and structure in coastal areas
History.
Evidence from microfossil records indicates that ferns and woody plants were present on Heard Island during the Tertiary (a period with a cool and moist climate.) Neither group of plants is present today, although potential Tertiary survivors include the vascular plant "Pringlea antiscorbutica" and six moss species. Volcanic activity has altered the distribution and abundance of the vegetation. The vascular flora covers a range of environments and, although only six species are currently widespread, glacial retreat and the consequent connection of previously separate ice-free areas is providing opportunities for further distribution of vegetation into adjacent areas.
Flowering plants and ferns.
Low-growing herbaceous flowering plants and bryophytes are the major vegetation components. The vascular flora comprises the smallest number of species of any major subantarctic island group, reflecting its isolation, small ice-free area and severe climate. Twelve vascular species are known from Heard Island, of which five have also been recorded on McDonald Island. None of the vascular species is endemic, although "Pringlea antiscorbutica", "Colobanthus kerguelensis", and "Poa kerguelensis" occur only on subantarctic islands in the southern Indian Ocean.
The plants are typically subantarctic, but with a higher abundance of the cushion-forming "Azorella selago" than other subantarctic islands. Heard Island is the largest subantarctic island with no confirmed human-introduced plants. Areas available for plant colonisation on Heard Island are generally the result of retreating glaciers or new ice-free land created by lava flows. Today, substantial vegetation covers over 20 km2 of Heard Island, and is best developed on coastal areas at elevations below 250 m.
Mosses and liverworts.
Bryophytes (mosses and liverworts) contribute substantially to the overall biodiversity of Heard Island, with 43 mosses and 19 liverworts being recorded, often occupying habitats unsuitable for vascular plants, such as cliff faces. Bryophytes are present in most of the major vegetation communities including several soil and moss-inhabiting species. A 1980 survey of McDonald Island found lower diversity than that on Heard Island; four mosses and a number of algal species are recorded from there.
Algae.
At least 100 species of terrestrial algae are known from Heard Island, commonly in permanently moist and ephemeral habitats. Forests of the giant Antarctic kelp "Durvillaea antarctica" occur at a number of sites around Heard Island and at least 17 other species of seaweed are known, with more to be added following the identification of recent collections. Low seaweed diversity is due to the island's isolation from other land masses, unsuitable beach habitat, constant abrasion by waves, tides and small stones, and the extension of glaciers into the sea in many areas.
Vegetation communities.
Heard Island has a range of terrestrial environments in which vegetation occurs. Seven general vegetation communities are currently recognised, although vegetation composition is considered more of a continuum than discrete units:
Outlook.
One of the most rapidly changing physical settings in the subantarctic has been produced on Heard Island by a combination of rapid glacial recession and climate warming. The consequent increase in habitat available for plant colonisation, plus the coalescing of previously discrete ice-free areas, has led to marked changes in the vegetation of Heard Island in the last 20 years or so. Other species and vegetation communities found on subantarctic islands north of the Antarctic Convergence now absent from the Heard Island flora may colonise the island if climate change produces more favourable conditions.
Some plant species are spreading and modifying the structure and composition of communities, some of which are also increasing in distribution. It is likely that further changes will occur, and possibly at an accelerated rate. Changes in population numbers of seal and seabird species are also expected to affect the vegetation by changing nutrient availability and disturbance through trampling.
One plant species on Heard Island, "Poa annua", a cosmopolitan grass native to Europe, was possibly introduced by humans, though is more likely to have arrived naturally, probably by skuas from the Kerguelen Islands where it is widespread. It was initially recorded in 1987 in two recently deglaciated areas of Heard Island not previously exposed to human visitation, while being absent from known sites of past human habitation. Since 1987 "Poa annua" populations have increased in density and abundance within the original areas and have expanded beyond them. Expeditioner boot traffic during the Australian Antarctic program expedition in 1987 may be at least partly responsible for the spread, but it is probably mainly due to dispersal by wind and the movement of seabirds and seals around the island.
The potential for introducing additional plant species (including invasive species not previously found on subantarctic islands) by both natural and human-induced means is high. This is due to the combination of low species diversity and climatic amelioration. During the 2003/04 summer a new plant species, "Cotula plumosa", was recorded. Only one small specimen was found growing on a coastal river terrace that had experienced substantial development and expansion of vegetation over the past decade. The species has a circumantarctic distribution and occurs on many subantarctic islands.
Fungi.
71 species of lichens have been recorded from Heard Island and they are common on exposed rock, dominating the vegetation in some areas. As with plants, a 1980 survey of McDonald Island found lower diversity there, with just eight lichen species and a number of non-lichenized fungi recorded.
Fauna.
The main indigenous animals are insects along with large populations of ocean-going seabirds, seals and penguins.
Mammals.
Sealing at Heard Island came to an end in the late 19th century, after the seal populations there had either become locally extinct or reduced to levels too low to exploit economically. Since then the populations have generally increased and are protected. Seals breeding on Heard include the southern elephant seal, the Antarctic fur seal and the subantarctic fur seal. Leopard seals visit regularly in winter to haul-out though they do not breed on the islands. Crabeater, Ross and Weddell seals are occasional visitors.
Birds.
Heard Island and the McDonald Islands are free from introduced predators and provide crucial breeding habitat in the middle of the vast Southern Ocean for a range of birds. The surrounding waters are important feeding areas for birds and some scavenging species also derive sustenance from their co-habitants on the islands. The islands have been identified by BirdLife International as an Important Bird Area because they support very large numbers of nesting seabirds.
Nineteen species of birds have been recorded as breeding on Heard Island and the McDonald Islands, although recent volcanic activity at the McDonald Islands in the last decade is likely to have reduced vegetated and un-vegetated nesting areas.
Penguins are by far the most abundant birds on the islands, with four breeding species present, comprising king, gentoo, macaroni and eastern rockhopper penguins. The penguins mostly colonise the coastal tussock and grasslands of Heard Island, and have previously been recorded as occupying the flats and gullies on McDonald Island.
Other seabirds recorded as breeding at Heard Island include three species of albatross (wandering, black-browed and light-mantled albatrosses, southern giant petrels, Cape petrels, four species of burrowing petrels Antarctic and Fulmar prions, common and South Georgian diving-petrels), Wilson's storm-petrels, kelp gulls, subantarctic skuas, Antarctic terns and the Heard shag. Although not a true seabird, the Heard Island subspecies of the black-faced sheathbill also breeds on the island. Both the shag and the sheathbill are endemic to Heard Island.
A further 28 seabird species are recorded as either non-breeding visitors or have been noted during 'at-sea surveys' of the islands. All recorded breeding species, other than the Heard Island sheathbill, are listed marine species under the Australian Environmental Protection and Biodiversity Act (1999, four are listed as threatened species and five are listed migratory species. Under the EPBC Act a recovery plan has been made for albatrosses and giant petrels, which calls for ongoing population monitoring of the species found at HIMI, and at the time of preparing this plan a draft recovery plan has also been made for the Heard Island cormorant (or shag) and Antarctic tern.
The recorded populations of some seabird species found in the Reserve have shown marked change. The king penguin population is the best studied seabird species on Heard Island and has shown a dramatic increase since first recorded in 1947/48, with the population doubling every five years or so for more than 50 years.
A paper reviewing population data for the black-browed albatross between 1947 and 2000/01 suggested that the breeding population had increased to approximately three times that present in the late 1940s, although a Convention for the Conservation of Antarctic Marine Living Resources CCAMLR) Working Group was cautious about the interpretation of the increasing trend given the disparate nature of the data, as discussed in the paper. The discovery of a large, previously unknown, colony of Heard shags in 2000/01 at Cape Pillar raised the known breeding population from 200 pairs to over 1000 pairs. On the other hand, the breeding population of southern giant petrels decreased by more than 50% between the early 1950s and the late 1980s.
Terrestrial, freshwater and coastal invertebrates.
Heard Island supports a relatively low number of terrestrial invertebrate species compared to other Southern Ocean islands, in parallel with the low species richness in the flora–that is, the island's isolation and limited ice-free area. Endemism is also generally low and the invertebrate fauna is exceptionally pristine with few, if any, (successful) human-induced introductions of alien species.
Two species, including the thrip "Apterothrips apteris" and the mite "Tyrophagus putrescentiae" are thought to be recent, possibly natural, introductions. An exotic species of earthworm "Dendrodrilus rubidus" was also collected in 1929 from a dump near Atlas Cove, and has recently been collected from a variety of habitats including wallows, streams and lakes on Heard Island.
The arthropods of Heard Island are comparatively well known with 54 species of mite and tick, one spider and eight springtails recorded. A study over summer at Atlas Cove in 1987/88 showed overall densities of up to 60 000 individual springtails per square metre in soil under stands of "Pringlea antiscorbutica". Despite a few recent surveys, the non-arthropod invertebrate fauna of Heard Island remain poorly known.
Beetles and flies dominate Heard Island's known insect fauna, which comprises up to 21 species of ectoparasite (associated with birds and seals) and up to 13 free-living species. Approximately half of the free-living insects are habitat-specific, while the remainder are generalists found in a variety of habitats, being associated with either supralittoral or intertidal zones, "Poa cookii" and "Pringlea antiscorbutica" stands, bryophytes, lichen-covered rocks, exposed rock faces or the underside of rocks. There is a pronounced seasonality to the insect fauna, with densities in winter months dropping to a small percentage (between 0.75%) of the summer maximum. Distinct differences in relative abundances of species between habitats has also been shown, including a negative relationship between altitude and body size for Heard Island weevils.
The fauna of the freshwater pools, lakes, streams and mires found in the coastal areas of Heard Island are broadly similar to those on other subantarctic islands of the southern Indian Ocean. Many species reported from Heard Island are found elsewhere. Some sampling of freshwater fauna has been undertaken during recent expeditions and records to date indicate that the freshwater fauna includes a species of Protista, a gastrotrich, two species of tardigrade, at least four species of nematode, 26 species of rotifer, six species of annelid and 14 species of arthropod.
As with the other shore biota, the marine macro-invertebrate fauna of Heard Island is similar in composition and local distribution to other subantarctic islands, although relatively little is known about the Heard Island communities compared with the well-studied fauna of some other islands in the subantarctic region, such as Macquarie and Kerguelen.
Despite Heard Island's isolation, species richness is considered to be moderate, rather than depauperate, although the number of endemic species reported is low. The large macro-alga "Durvillaea antarctica" supports a diverse array of invertebrate taxa and may play an important role in transporting some of this fauna to Heard Island.
The rocky shores of Heard Island exhibit a clear demarcation between fauna of the lower kelp holdfast zone and the upper shore zone community, probably due to effects of desiccation, predation and freezing in the higher areas. The limpet "Nacella kerguelensis" is abundant in the lower part of the shore, being found on rock surfaces and on kelp holdfasts. Other common but less abundant species in this habitat include the chiton "Hemiarthrum setulosum" and the starfish "Anasterias mawsoni". The amphipod "Hyale" sp. and the isopod "Cassidinopsis" sp. are closely associated with the kelp. Above the kelp holdfast zone, the littornid "Laevilitorina (Corneolitorina) heardensis" and the bivalve mollusc "Kidderia bicolor" are found in well-sheltered situations, and another bivalve "Gaimardia trapesina trapesina" has been recorded from immediately above the holdfast zone. Oligochaetes are also abundant in areas supporting porous and spongy layers of algal mat.
Wetlands.
Heard Island has a number of small wetland sites scattered around its coastal perimeter, including areas of wetland vegetation, lagoons or lagoon complexes, rocky shores and sandy shores, including the Elephant Spit. Many of these wetland areas are separated by active glaciers. There are also several short glacier-fed streams and glacial pools. Some wetland areas have been recorded on McDonald Island but, due to substantial volcanic activity since the last landing was made in 1980, their present extent is unknown.
The HIMI wetland is listed on the Directory of Important Wetlands in Australia and, in a recent analysis of Commonwealth-managed wetlands, was ranked highest for nomination under the Convention on Wetlands of International Importance Especially as Waterfowl Habitat (Ramsar Convention) as an internationally important wetland.
Six wetland types have been identified from HIMI covering approximately 1860 ha: coastal ‘pool complex’ (237 ha); inland ‘pool complex’ (105 ha); vegetated seeps mostly on recent glaciated areas (18 ha); glacial lagoons (1103 ha); non-glacial lagoons (97ha); Elephant Spit (300 ha) plus some coastal areas. On Heard Island, the majority of these types suites are found below 150m asl. The wetland vegetation occurs in the ‘wet mixed herbfield’ and ‘coastal biotic vegetation’ communities described above.
The wetlands provide important breeding and feeding habitat for a number of Antarctic and subantarctic wetland animals. These include the southern elephant seal and macaroni, gentoo, king and southern rockhopper penguins, considered to be wetland species under the Ramsar Convention. Non-wetland vegetated parts of the islands also support penguin and other seabird colonies.
History.
Neither island-cluster had recorded visitors until the mid-1850s. Peter Kemp, a British sailor, may have become the first person to have seen the island. On 27 November 1833, he spotted it from the brig "Magnet" during a voyage from the Kerguelen Islands to the Antarctic and was believed to have entered the island on his 1833 chart.
An American sailor, Captain John Heard, on the ship "Oriental", sighted Heard Island on 25 November 1853, en route from Boston to Melbourne. He reported the discovery one month later and had the island named after him. Captain William McDonald aboard the "Samarang" discovered the nearby McDonald Islands six weeks later, on 4 January 1854.
No landing took place on the islands until March 1855, when sealers from the "Corinthian", led by Captain Erasmus Darwin Rogers, went ashore at a place called Oil Barrel Point. In the sailing period from 1855 to 1880 a number of American sealers spent a year or more on the island, living in appalling conditions in dark smelly huts, also at Oil Barrel Point. At its peak the community consisted of 200 people. By 1880 sealers had wiped out most of the seal population and then left the island. In all the islands furnished more than 100,000 barrels of elephant-seal oil during this period.
A number of wrecks have occurred in the vicinity of the islands. There is also a discarded building left from John Heard's sealing station which is situated near Atlas Cove.
The first recorded landing on McDonald Island was made by Australian scientists Grahame Budd and Hugh Thelander on 12 February 1971, using a helicopter.
The islands have been a territory of Australia since 1947, when they were transferred from the U.K. The archipelago became a World Heritage Site in 1997.
Several amateur radio operators have visited Heard, often associated with scientific expeditions. The first activity there was in 1947 by Alan Campbell-Drury. Amateur radio DXpeditions to the island took place in January 1997 and two in 1983. An operation is planned for early 2016 organized by Cordell Expeditions.
Administration and economy.
The United Kingdom formally established its claim to Heard Island in 1910, marked by the raising of the Union Flag and the erection of a beacon by Captain Evensen, master of the "Mangoro". Effective government, administration and control of Heard
Island and the McDonald Islands was transferred to the Australian government on 26 December 1947 at the commencement of the first Australian National Antarctic Research Expedition (ANARE) to Heard Island, with a formal declaration that took
place at Atlas Cove. The transfer was confirmed by an exchange of letters between the two governments on 19 December 1950.
The islands are a territory (Territory of Heard Island and McDonald Islands) of Australia administered from Hobart by the Australian Antarctic Division of the Australian Department of the Environment and Water Resources. They are populated by large numbers of seal and bird species. The islands are contained within a 65000 km2 marine reserve and are primarily visited for research. There is no permanent human habitation.
From 1947 until 1955 there were camps of visiting scientists on Heard Island (at Atlas Cove in the northwest, which was in 1969 again occupied by American scientists and expanded in 1971 by French scientists) and in 1971 on McDonald Island (at Williams Bay). Later expeditions used a temporary base at Spit Bay in the east, such as in 1988, 1992–93 and 2004–05.
With no population, there is no indigenous economic activity. The islands' only natural resource is fish; the Australian government allows limited fishing in the surrounding waters. Despite the lack of population, the islands have been assigned the country code HM in ISO 3166-1 () and therefore the Internet top-level domain .hm. The timezone of the islands is UTC+5.

</doc>
<doc id="13393" url="http://en.wikipedia.org/wiki?curid=13393" title="Holy See">
Holy See

The Holy See (Latin: "Sancta Sedes"; ]) is the ecclesiastical jurisdiction of the Catholic Church in Rome, the episcopal see of the Bishop of Rome—the Pope. It is the central point of reference for the church everywhere and the focal point of communion due to its prominence. It traces its origin to the apostolic era, when Saint Peter arrived in Rome to evangelize, thus forming a community of believers there which maintained a significant Christian presence. Today, it is responsible for the governance of the faithful, organized in their local Christian communities.
The Holy See is viewed as analogous to a sovereign state, having a centralized government called the Roman Curia with the Secretary of State as its chief administrator and various departments essential to administration comparable to ministries and executive departments. It enters diplomatic relations with states, and has Vatican City as its sovereign territory.
Diplomatically, the Holy See acts and speaks for the whole church. It is also recognized by other subjects of international law as a sovereign entity, headed by the Pope, with which diplomatic relations can be maintained.
Often incorrectly referred to as "the Vatican", the "Holy See" is not the same entity as the "Vatican City State", which came into existence only in 1929 because of the Lateran Treaty; the Holy See, the episcopal see of Rome, dates back to antiquity. Ambassadors are officially accredited not to the Vatican City State but to "the Holy See", and Papal representatives to states and international organizations are recognized as representing the Holy See, not the Vatican City State.
Though all episcopal sees may be considered holy, the expression "the Holy See" (without further specification) is normally used in international relations (and in the canon law of the Catholic Church) to refer to the See of Rome viewed as the central government of the Catholic Church.
Terminology.
Every see is considered holy. In Greek, the adjective "holy" or "sacred" (ἱερά transliterated as "hiera") is constantly applied to all such sees as a matter of course. In the West, the adjective is not commonly added, but it does form part of an official title of two sees: as well as Rome, the Bishopric of Mainz (the former Archbishopric of Mainz), which was also of electoral and primatial rank, bears the title of "the Holy See of Mainz" (Latin: "Sancta Sedes Moguntina").
The term "see" comes from the Latin word "sedes", meaning "seat", which refers to the Episcopal throne (cathedra). The term "Apostolic See" can refer to any see founded by one of the Apostles, but, when used with the definite article, it is used in the Catholic Church to refer specifically to the see of the Bishop of Rome, whom that Church sees as successor of Saint Peter, the Prince of the Apostles.
Organization.
The Pope governs the Catholic Church through the Roman Curia. The Roman Curia consists of a complex of offices that administer church affairs at the highest level, including the Secretariat of State, nine Congregations, three Tribunals, eleven Pontifical Councils, and seven Pontifical Commissions. The Secretariat of State, under the Cardinal Secretary of State, directs and coordinates the Curia. The incumbent, Archbishop Pietro Parolin, is the See's equivalent of a prime minister. Archbishop Dominique Mamberti, Secretary of the Section for Relations with States of the Secretariat of State, acts as the Holy See's minister of foreign affairs. Parolin was named in his role by Pope Francis On 31 August 2013. Mamberti was named in his role by Pope Benedict XVI in September 2006.
The Secretariat of State is the only body of the Curia that is situated within Vatican City. The others are in buildings in different parts of Rome that have extraterritorial rights similar to those of embassies.
Among the most active of the major Curial institutions are the Congregation for the Doctrine of the Faith, which oversees the Catholic Church's doctrine; the Congregation for Bishops, which coordinates the appointment of bishops worldwide; the Congregation for the Evangelization of Peoples, which oversees all missionary activities; and the Pontifical Council for Justice and Peace, which deals with international peace and social issues.
Three tribunals exercise judicial power. The Roman Rota handles normal judicial appeals, the most numerous being those that concern alleged nullity of marriage. The Apostolic Signatura is the supreme appellate and administrative court concerning decisions even of the Roman Rota and administrative decisions of ecclesiastical superiors (bishops and superiors of religious institutes), such as closing a parish or removing someone from office. It also oversees the work of other ecclesiastical tribunals at all levels. The Apostolic Penitentiary deals not with external judgments or decrees, but with matters of conscience, granting absolutions from censures, dispensations, commutations, validations, condonations, and other favors; it also grants indulgences.
The Prefecture for the Economic Affairs of the Holy See coordinates the finances of the Holy See departments and supervises the administration of all offices, whatever be their degree of autonomy, that manage these finances. The most important of these is the Administration of the Patrimony of the Apostolic See.
The Prefecture of the Papal Household is responsible for the organization of the papal household, audiences, and ceremonies (apart from the strictly liturgical part).
The Holy See does not dissolve upon a Pope's death or resignation. It instead operates under a different set of laws "sede vacante". During this interregnum, the heads of the dicasteries of the Roman Curia (such as the prefects of congregations) cease immediately to hold office, the only exceptions being the Major Penitentiary, who continues his important role regarding absolutions and dispensations, and the Camerlengo of the Holy Roman Church, who administers the temporalities ("i.e.", properties and finances) of the See of St. Peter during this period. The government of the See, and therefore of the Catholic Church, then falls to the College of Cardinals. Canon law prohibits the College and the Camerlengo from introducing any innovations or novelties in the government of the Church during this period.
In 2001, the Holy See had a revenue of 422.098 billion Italian lire (about 202 million USD at the time), and a net income of 17.720 billion Italian lire (about 8 million USD). According to an article by David Leigh in the "Guardian" newspaper, a 2012 report from the Council of Europe identified the value of a section of the Vatican's property assets as an amount in excess of €680m (£570m); as of January 2013, Paolo Mennini, a papal official in Rome, manages this portion of the Holy See's assets—consisting of British investments, other European holdings and a currency trading arm. The "Guardian" newspaper described Mennini and his role in the following manner: "... Paolo Mennini, who is in effect the pope's merchant banker. Mennini heads a special unit inside the Vatican called the extraordinary division of APSA – "Amministrazione del Patrimonio della Sede Apostolica" – which handles the "patrimony of the Holy See"."
Status in international law.
The Holy See has been recognized, both in state practice and in the writing of modern legal scholars, as a subject of public international law, with rights and duties analogous to those of States. Although the Holy See, as distinct from the Vatican City State, does not fulfill the long-established criteria in international law of statehood—having a permanent population, a defined territory, a stable government and the capacity to enter into relations with other states—its possession of full legal personality in international law is shown by the fact that it maintains diplomatic relations with 180 states, that it is a "member-state" in various intergovernmental international organizations, and that it is: "respected by the international community of sovereign States and treated as a subject of international law having the capacity to engage in diplomatic relations and to enter into binding agreements with one, several, or many states under international law that are largely geared to establish and preserving peace in the world."
Diplomacy.
Since medieval times the episcopal see of Rome has been recognized as a sovereign entity. The Holy See (not the State of Vatican City) maintains formal diplomatic relations with and for the most recent establishment of diplomatic relations with 180 sovereign states, and also with the European Union, and the Sovereign Military Order of Malta, as well as having relations of a special character with the Palestine Liberation Organization; 69 of the diplomatic missions accredited to the Holy See are situated in Rome. The Holy See maintains 180 permanent diplomatic missions abroad, of which 74 are non-residential, so that many of its 106 concrete missions are accredited to two or more countries or international organizations. The diplomatic activities of the Holy See are directed by the Secretariat of State (headed by the Cardinal Secretary of State), through the Section for Relations with States. There are 15 internationally recognized states with which the Holy See does not have relations. The Holy See is the only European subject of international law that has diplomatic relations with the government of the Republic of China as representing China, rather than the government of the People's Republic of China (see Holy See–Taiwan relations).
The British Foreign and Commonwealth Office speaks of Vatican City as the "capital" of the Holy See, although it compares the legal personality of the Holy See to that of the Crown in Christian monarchies and declares that the Holy See and the state of Vatican City are two international identities. It also distinguishes between the employees of the Holy See (2,750 working in the Roman Curia with another 333 working in the Holy See's diplomatic missions abroad) and the 1,909 employees of the state. The British Ambassador to the Holy See uses more precise language, saying that the Holy See "is not the same as the Vatican City State. … (It) is the universal government of the Catholic Church and "operates from" the Vatican City State." This agrees exactly with the expression used by the website of the United States Department of State, in giving information on both the Holy See and the Vatican City State: it too says that the Holy See "operates from the Vatican City State".
The Holy See is a member of various International organizations and groups including the International Atomic Energy Agency (IAEA), International Telecommunication Union, the Organization for Security and Co-operation in Europe (OSCE), the Organization for the Prohibition of Chemical Weapons (OPCW) and the United Nations High Commissioner for Refugees (UNHCR). The Holy See is also a permanent observer in various international organizations, including the United Nations General Assembly, the Council of Europe, UNESCO (United Nations Educational, Scientific and Cultural Organization), the World Trade Organization (WTO), and the Food and Agriculture Organization (FAO).
Relationship with the Vatican City and other territories.
The Holy See participates as an observer in AU, Arab League, Council of Europe, OAS, IOM, and in the United Nations and its agencies FAO, ILO, UNCTAD, UNEP, UNESCO, UN-HABITAT, UNHCR, UNIDO, UNWTO, WFP, WHO, WIPO. It participates as a guest in NAM, and as a full member in IAEA, OPCW, OSCE.
Although the Holy See is closely associated with the Vatican City, the independent territory over which the Holy See is sovereign, the two entities are separate and distinct. After the Italian takeover of the Papal States in 1870, the Holy See had no territorial sovereignty. In spite of some uncertainty among jurists as to whether it could continue to act as an independent personality in international matters, the Holy See continued in fact to exercise the right to send and receive diplomatic representatives, maintaining relations with states that included the major powers of Russia, Prussia and Austria-Hungary. Where, in accordance with the decision of the 1815 Congress of Vienna, the Nuncio was not only a member of the Diplomatic Corps but its Dean, this arrangement continued to be accepted by the other ambassadors. In the course of the 59 years during which the Holy See held no territorial sovereignty, the number of states that had diplomatic relations with it, which had been reduced to 16, actually increased to 29.
The State of the Vatican City was created by the Lateran Treaty in 1929 to "ensure the absolute and visible independence of the Holy See" and "to guarantee to it an indisputable sovereignty in international affairs." Archbishop Jean-Louis Tauran, the Holy See's former Secretary for Relations with States, said that the Vatican City is a "minuscule support-state that guarantees the spiritual freedom of the Pope with the minimum territory".
The Holy See, not the Vatican City, maintains diplomatic relations with states. Foreign embassies are accredited to the Holy See, not to the Vatican City, and it is the Holy See that establishes treaties and concordats with other sovereign entities. When necessary, the Holy See will enter a treaty on behalf of the Vatican City.
Under the terms of the Lateran Treaty, the Holy See has extraterritorial authority over various sites in Rome and two Italian sites outside of Rome, including the Pontifical Palace at Castel Gandolfo. The same authority is extended under international law over the Apostolic Nunciature of the Holy See in a foreign country.
Military.
Though, like various European powers, earlier Popes recruited Swiss mercenaries as part of an army, the Pontifical Swiss Guard was founded by Pope Julius II on 22 January 1506 as the personal bodyguard of the Pope and continues to fulfil that function. It is listed in the "Annuario Pontificio" under "Holy See", not under "State of Vatican City". At the end of 2005, the Guard had 134 members. Recruitment is arranged by a special agreement between the Holy See and Switzerland. All recruits must be Catholic, unmarried males with Swiss citizenship who have completed their basic training with the Swiss Army with certificates of good conduct, be between the ages of 19 and 30, and be at least 175 cm (5 ft 9 in) in height. Members are armed with small arms and the traditional halberd (also called the Swiss voulge), and trained in bodyguarding tactics.
The police force within Vatican City, known as the Corps of Gendarmerie of Vatican City, belongs to the city state, not to the Holy See.
Coat of arms.
The difference between both coats of arms is that the arms of the Holy See have the gold key in bend and the silver key in bend sinister (as also in the sede vacante coat of arms and in the external ornaments of the papal coats of arms of individual popes), while the reversed arrangement of the keys was chosen for the arms of the newly founded Vatican City State in 1929.

</doc>
