<doc id="10067" url="http://en.wikipedia.org/wiki?curid=10067" title="Episcopal polity">
Episcopal polity

An episcopal polity is a hierarchical form of church governance ("ecclesiastical polity") in which the chief local authorities are called bishops. (The word "bishop" derives, via the British Latin and Vulgar Latin term "*ebiscopus"/"*biscopus", from the Ancient Greek επίσκοπος "epískopos" meaning "overseer".) It is the structure used by many of the major Christian Churches and denominations, such as Catholic, Eastern, Eastern Orthodox, Anglican and Lutheran churches or denominations, as well as other churches founded independently from these lineages.
Churches with an episcopal polity are governed by bishops with authority over the judicatory (dioceses and conferences or synods). Their presidency is both sacramentoal and political; as well as performing ordinations, confirmations, and consecrations, the bishop supervises the clergy within the judicatory and is the representative to both secular structures and in the hierarchy of the church. It is usually considered that bishops derive their authority from an unbroken, personal apostolic succession from the Twelve Apostles of Jesus. Bishops with such authority are known as the historical episcopate. Churches with this type of government usually believe that the Church requires episcopal government as described in the New Testament. In some systems, bishops may be subject to higher-ranking bishops (variously called archbishops, metropolitans, and/or patriarchs, depending upon the tradition). They also meet in councils or synods. These gatherings, subject to presidency by higher ranking bishops, may govern the judicatory which are represented in the council, though the synod or council may also be purely advisory.
For much of the written history of Christianity, episcopal government was the only known form of church organization. This changed at the Reformation. Many Protestant churches are now organized by either congregational or presbyterian church polities, both descended from the writings of John Calvin, a Protestant reformer working and writing independently following the break with the Roman Catholic Church precipitated by The Ninety-Five Theses of Martin Luther.
Overview of episcopal churches.
The definition of the word "episcopal" has variation among Christian traditions. There are subtle differences in governmental principles among episcopal churches at the present time. To some extent the separation of episcopal churches can be traced to these differences in ecclesiology, that is, their theological understanding of church and church governance. For some, "episcopal churches" are churches that use a hierarchy of bishops that regard themselves as being in an unbroken, personal apostolic succession.
Episcopal is also commonly used to distinguish between the various organizational structures of denominations. For instance, the word "presbyterian" (Greek: 'πρεσβύτης, presbítes) is used to describe a church governed by a hierarchy of assemblies of elected elders, referred to as Presbyterian. Similarly, "episcopal" is used to describe a church governed by bishops. Self-governed local congregations, governed neither by elders nor bishops, are usually referred to as "Congregational".
More specifically, the title "Episcopal" (capitalized in this instance) is applied to several churches historically based within Anglicanism ("Episcopalianism") including those still in communion with the Church of England.
Using these definitions, examples of specific episcopal churches include:
Some Lutheran churches practice congregational polity or a form of presbyterian polity. Others, including the Church of Sweden, practice episcopal polity; the Church of Sweden also counts its bishops among the historic episcopate as do some American Lutheran churches like the Anglo-Lutheran Catholic Church, Lutheran Orthodox Church, Lutheran Church-International, and the Lutheran Episcopal Communion.
Many Methodist churches (see The United Methodist Church, among others) retain the form and function of episcopal polity, although in a modified form, called connexionalism. Since all trace their ordinations to an Anglican priest, John Wesley, it is generally considered that their bishops do not share in apostolic succession, though United Methodists still affirm that their bishops share in the historic episcopate.
Before the Great Schism.
All orthodox Christians were in churches with an episcopal government, that is, one Church under local bishops and regional Patriarchs. Writing between ca. 85 and 110, St. Ignatius of Antioch, Patriarch of Antioch, was the earliest of the Church fathers to define the importance of episcopal government. Assuming Ignatius' view was the Apostolic teaching and practice, the line of succession was unbroken and passed through the four ancient Patriarchal sees (those local churches known to be founded by apostles), Rome, Jerusalem, Antioch and Alexandria. Rome was the leading Patriarchate of the ancient four by virtue of its founding by Saints Peter and Paul and their martyrdom there, not to mention being the political center of the Roman empire at the time. Some organizations (e.g. the Assyrian Church of the East), though aloof from the political wranglings of imperial Christianity, nevertheless also practiced episcopal polity.
Shortly after the Roman Emperor Constantine I legalized Christianity in 321, he also constructed an elaborate second capital of the Roman Empire located at Byzantium and renamed it Constantinople, in 324. The single Roman Empire was divided between these two autonomous administrative centers, Roman and Constantinopolitan, West and East, Latin speaking and Greek speaking. This remained the status quo through the fourth century.
In the fifth century, Pope Dioscorus, the Patriarch of Alexandria, rejected certain Christological dogmas promulgated by the Council of Chalcedon, and as a result, the Oriental Orthodox churches split from the rest; however they continued the episcopal tradition, and today in fact there is dialog between the various orthodox churches over whether the schism was due to real differences or simply translation failures.
Also during the fifth century, the Western Roman Empire declined and was overrun by German and Frankish peoples. Although the city of Rome was in ruins, distant from the seat of secular power, and constantly harassed by invaders, the Roman Patriarchate remained the center of the Western or Latin Church. Claiming the ancient primacy of Peter and the title of "Apostolic See", it remained the last court of episcopal appeal in serious matters for the whole Church, East and West.
However, the center of the civilized Roman world had shifted definitively to Constantinople, or New Rome, the capital of the Greek speaking Empire. Along with this shift, the effective administration of the Church in the Eastern Roman Empire also shifted. This practical eminence of Constantinople in the East is evident, first at the First Council of Constantinople 381, and then ecumenically at the Council of Chalcedon in 451.
Beginning with John the Faster, the Bishop of Constantinople (John IV, 582-595) adopted as a formal title for himself the by-then-customary honorific, Ecumenical Patriarch ("pre-eminent father for the civilized world") over the strong objections of Rome: a title based on the political prestige of Constantinople and its economic and cultural centrality in the Empire. In the following years, Rome's appeals to the East were based on the unique authority of the Apostolic See and the primacy of Peter, over against the powers of councils as defended by the East (councils, for example, had endorsed that lofty title which Rome contested).
The sometimes subtle differences between Eastern and Western conceptions of authority and its exercise produced a gradually widening rift between the Churches which continued with some occasional relief throughout the following centuries until the final rupture of the Great Schism (marked by two dates: 16 July 1054, and the Council of Florence in 1439).
Roman Catholic Church.
The Catholic Church has an episcopate, with the Pope, who is the Bishop of Rome, at the top. The Catholic Church teaches that juridical oversight over the Church is not a power that derives from human ambition, but strictly from the authority of Christ which was given to his twelve apostles. The See of Rome, as the sole unbroken line of apostolic authority, descending from St. Peter (the "prince and head of the apostles"), is a visible sign and instrument of communion among the college of bishops and therefore also of the local churches around the world. In communion with the worldwide college of bishops the Pope has all legitimate juridical and teaching authority over the whole Church. This authority given by Christ to Peter and the apostles is transmitted from one generation to the next by the power of the Holy Spirit, through the laying on of hands, from the Apostles to the bishops, and from bishops to priests and deacons, in unbroken succession.
Eastern Orthodox Church.
The conciliar idea of episcopal government continues in the Orthodox Church. In Eastern Orthodoxy, the sixteen or so autocephalous primates are seen as collectively gathering around Christ, with other archbishops and bishops gathering around them, and so forth, in a model called "conciliar hierarchy". This is based in part on the vision in the book of Revelation of the 24 elders gathered around the throne of Christ, who are believed to represent the 12 patriarchs of Israel and the 12 apostles of Jesus Christ. There is no single Patriarch with exclusive authority comparable to the Pope in Rome.
Oriental Orthodox churches.
The Oriental Orthodox Churches affirm the ideas of apostolic succession and episcopal government. Within each national Church, the bishops form a holy synod to which even the Patriarch is subject. The Syriac Orthodox Church traces its apostolic succession to St. Peter and recognises Antioch as the original See of St. Peter. The Armenian Apostolic Church traces its lineage to the Apostle Bartholomew. The Indian Orthodox Church traces its lineage to the Apostle Thomas. The Ethiopian Orthodox Church received its lines of succession through the Coptic Orthodox Church in the fifth century.
Both the Greek and Coptic Orthodox Churches each recognise their own Pope of Alexandria, both of whom trace their apostolic succession back to the Mark the Evangelist. There are official ongoing efforts in recent times to heal this ancient breach. Already, the two recognize each other's baptisms, chrismations, and marriages, making intermarriage much easier.
Church of the East.
Historically, the Church of the East has traced its episcopal succession to St. Thomas the Apostle. The bishops of the Assyrian Church of the East continue to maintain the doctrine of apostolic succession.
Anglican Communion.
Anglicanism is the most prominent of the Reformation traditions to lay claim to the historic episcopate through apostolic succession in terms comparable to the various Catholic and Orthodox Communions. Anglicans assert unbroken episcopal succession in and through the Church of England back to St. Augustine of Canterbury and to the first century Roman province of Britannia. While some Celtic Christian practices were changed at the Synod of Whitby, the church in the British Isles was under papal authority from earliest times.
The legislation of Henry VIII effectively establishing the independence from Rome of the Church of England, did not alter its constitutional or pastoral structures. Royal supremacy was exercised through the extant legal structures of the church, whose leaders were bishops. Episcopacy was thus seen as a given of the Reformed "Ecclesia Anglicana", and a foundation in the institution's appeal to ancient and apostolic legitimacy. What did change was that bishops were now seen to be ministers of the Crown for the spiritual government of its subjects. The influence of Richard Hooker was crucial to an evolution in this understanding in which bishops came to be seen in their more traditional role as ones who delegate to the presbyterate inherited powers, act as pastors to presbyters, and holding a particular teaching office with respect to the wider church.
Anglican opinion has differed as to the way in which episcopal government is "de jure divino". On the one hand, the seventeenth century divine, John Cosin, held that episcopal authority is "jure divino", but that it stemmed from "apostolic practice and the customs of the Church...[not] absolute precept that either Christ or His Apostles gave about it" (a view maintained also by Hooker). In contrast, Lancelot Andrewes and others held that episcopal government is derived from Christ via the apostles. Regardless, both parties viewed the episcopacy as bearing the apostolic function of oversight, which both includes, and derives from the power of ordination, and is normative for the governance of the church. The practice of apostolic succession both ensures the legitimacy of the church's mission and establishes the unity, communion, and continuity of the local church with the universal church. This formulation, in turn, laid the groundwork for an independent view of the church as a "sacred society" distinct from civil society, which was so crucial for the development of local churches as non-established entities outside England, and gave direct rise to the Catholic Revival and disestablishmentarianism within England.
Functionally, Anglican episcopal authority is expressed synodically, although individual provinces may accord their primate with more or less authority to act independently. Called variously "synods," "councils," or "conventions," they meet under episcopal chairmanship. In many jurisdictions, conciliar resolutions that have been passed require episcopal assent and/or consent to take force. Seen in this way, Anglicans often speak of "the bishop-in-synod" as the force and authority of episcopal governance. Such conciliar authority extends to the standard areas of doctrine, discipline, and worship, but in these regards is limited by Anglicanism's tradition of the limits of authority. Those limits are expressed in Article XXI of the Thirty-Nine Articles of Religion, ratified in 1571 (significantly, just as the Council of Trent was drawing to a close), which held that "General Councils...may err, and sometimes have erred...wherefore things ordained by them as necessary to salvation have neither strength nor authority, unless it may be declared that they be taken out of holy Scripture." Hence, Anglican jurisdictions have traditionally been conservative in their approach to either innovative doctrinal development or in encompassing actions of the church as doctrinal (see lex orandi, lex credendi).
Anglican synodical government, though varied in expression, is characteristically representative. Provinces of the Anglican Communion, their ecclesiastical provinces and dioceses are governed by councils consisting not only of bishops, but also representatives of the presbyterate and laity. The spread of increasingly democratic forms of representative governance has its origin in the formation of the first General Conventions of the American Episcopal Church in the 1780s, which established a "House of Bishops" and a "House of Deputies." In many jurisdictions, there is also a third, clerical House. Resolutions may be voted on jointly or by each House, in the latter case requiring passage in all Houses to be adopted by the particular council.
There is no international juridical authority in Anglicanism, although the tradition's common experience of episcopacy, symbolised by the historical link with the See of Canterbury, along with a common and complex liturgical tradition, has provided a measure of unity. This has been reinforced by the Lambeth Conferences of Anglican Communion bishops, which first met in 1867. These conferences, though they propose and pass resolutions, are strictly consultative, and the intent of the resolutions are to provide guideposts for Anglican jurisdictions - not direction. The Conferences also express the function of the episcopate to demonstrate the ecumenical and Catholic nature of the church.
The Scottish Episcopal Church traces its history back to the origins of Christianity in Scotland, and during the 16th century Scottish Reformation became a distinct church from the presbyterian Church of Scotland which rejected episcopal government. The Scottish Episcopal Church was formally incorporated in 1712, and it more recently became part of the Anglican Communion.
Churches that are members of the Anglican Communion are episcopal churches in polity, and some are named "Episcopal." However, some churches that self-identify as Anglican do not belong to the Anglican Communion, and not all episcopally-governed churches are Anglican. The Roman Catholic Church, the Old Catholic Churches (in full communion with, but not members of, the Anglican Communion), and the Eastern Orthodox churches are recognized, and also their bishops, by Anglicans.
American Methodist churches.
As an offshoot of Anglicanism, Methodist churches often use episcopal polity for historical as well as practical reasons, albeit to limited use. Methodists often use the term "connexionalism" or "connexional polity" in addition to "episcopal". Nevertheless, the powers of the Methodist episcopacy can be relatively strong and wide-reaching compared to traditional conceptions of episcopal polity. For example, in the United Methodist Church, bishops are elected for life, can serve up to two terms in a specific conference (three if special permission is given), are responsible for ordaining and appointing clergy to pastor churches, perform many administrative duties, preside at the annual sessions of the regional Conferences and at the quadrennial meeting of the worldwide General Conference, have authority for teaching and leading the church on matters of social and doctrinal import, and serve to represent the denomination in ecumenical gatherings. United Methodist bishops in the United States serve in their appointed conferences, being moved to a new "Episcopal Area" after 8 (or 12) years, until their mandated retirement at the end of the quadrenium following their sixty-sixth birthday.
British Methodism holds that all ordained minsters are equal in terms of spirituality. However, for practical management lines are drawn into President of Conference, Chair of District, Superintendent Minister, Minister. However, all are ministers.
Episcopal government in other denominations.
The Reformed Church of Hungary, and the Lutheran churches in mainland Europe may sometimes be called "episcopal". In these latter cases, the form of government is not radically different from the presbyterian form, except that their councils of bishops have hierarchical jurisdiction over the local ruling bodies to a greater extent than in most Presbyterian and other Reformed churches. As mentioned, the Lutheran Church in Sweden and Finland are exceptions, claiming apostolic succession in a pattern somewhat like the Anglican churches. Otherwise, forms of polity are not mandated in the Lutheran churches, as it is not regarded as having doctrinal significance. Old World Lutheranism, for historical reasons, has tended to adopt Erastian theories of episcopal authority (by which church authority is to a limited extent sanctioned by secular government). In the United States, the Lutheran churches tend to adopt a form of government more comparable to congregationalism. A small minority of Episcopal Baptists exists.
Although it never uses the term, The Church of Jesus Christ of Latter-day Saints (LDS Church) is episcopal, rather than presbyterian or congregational, in the sense that it has a strict hierarchy of leadership from the local bishop/branch president up to a single prophet/president, believed to be personally authorized and guided by Jesus Christ. Local congregations (branches, wards, and stakes) have "de jure" boundaries by which members are allocated, and membership records are centralized. This system developed gradually from a more presbyterian polity (Joseph Smith's original title in 1830 was "First Elder") for pragmatic and doctrinal reasons, reaching a full episcopacy during the Nauvoo period (1839–1846).

</doc>
<doc id="10068" url="http://en.wikipedia.org/wiki?curid=10068" title="Episcopal">
Episcopal

Episcopal and episcopalian may refer to:

</doc>
<doc id="10070" url="http://en.wikipedia.org/wiki?curid=10070" title="East Slavic languages">
East Slavic languages

The East Slavic languages constitute one of three regional subgroups of Slavic languages, currently spoken in Eastern Europe. It is the group with the largest numbers of speakers, far out-numbering the Western and Southern Slavic groups. The existing East Slavic languages are Belarusian, Russian and Ukrainian; Rusyn is considered to be either a separate language or a dialect of Ukrainian.
The East Slavic languages descend from a common predecessor, the language of the medieval Kievan Rus' (9th to 13th centuries).
All these languages use the Cyrillic script, but with particular modifications.
Differentiation.
The East Slavic territory shows a definite linguistic continuum with many transitional dialects. Between Belarusian and Ukrainian there is the Polesian dialect, which shares features from the both languages. East Polesian is a transitional variety between Belarusian and Ukrainian on the one hand, and between South Russian and Ukrainian on the other hand. While Belarusian and Southern Russian form a continuous area, making it virtually impossible to draw a line between two languages. Central or Middle Russian (with its Moscow sub-dialect), the transitional step between the North and the South, became a base for the Russian literary standard. Northern Russian with its predecessor, the Old Novgorod dialect, has many original and archaic features. As well, existing several centuries within Polish-Lithuanian Commonwealth, Belarusian and Ukrainian share many common elements, lexical and grammatical above all. Ruthenian, the mixed Belarusian-Ukrainian literary language with Church Slavonic substratum and Polish adstratum, was together with Middle Polish an official language in Belarus and Ukraine until the end of the 18th century.
History.
When the common Old East Slavic language became separated from the ancient Slavic tongue common to all Slavs is difficult to ascertain, though in the 12th century the common language of Rus' is still referred to in contemporary as Slavic.
Therefore, a crucial differentiation has to be made between the history of the East Slavic "dialects" and that of the "literary languages" employed by the Eastern Slavs. Although most ancient texts betray the dialect their author(s) and/or scribe(s) spoke, it is also clearly visible that they tried to write in a language different from their dialects and to avoid those mistakes that enable us nowadays to locate them.
In both cases one has to keep in mind that the history of the East Slavic languages is of course a history of written texts. We do not know how the writers of the preserved texts would have spoken in every-day life.
Influence of Church Slavonic.
After the conversion of the East Slavic region to Christianity the people used service books borrowed from Bulgaria, which were written in Old Church Slavonic. The Church Slavonic language was strictly used only in text, while the colloquial language of the Bulgarians was communicated in its spoken form.
Throughout the Middle Ages (and in some way up to the present day) there existed a duality between the Church Slavonic language used as some kind of 'higher' register (not only) in religious texts and the popular tongue used as a 'lower' register for secular texts. It has been suggested to describe this situation as diglossia, although there do exist mixed texts where it is sometimes very hard to determine why a given author used a popular or a Church Slavonic form in a given context. Church Slavonic was a major factor in the evolution of modern Russian, where there still exists a "high stratum" of words that were imported from this language.
Current status.
All of these languages are today separate in their own right. In the Russian Empire the official view was that the Belarusian ("White Russian"), Ukrainian ("Little Russian"), and Russian ("Great Russian") languages were dialects of one common "Russian" language (the common languages of Eastern Slavic countries). In the course of the 20th century, "Great Russian" came to be known as Russian proper, "Little Russian" as Ukrainian and "White Russian" as Belarusian.

</doc>
<doc id="10071" url="http://en.wikipedia.org/wiki?curid=10071" title="Elizabeth Gracen">
Elizabeth Gracen

Elizabeth Ward Gracen (born Elizabeth Grace Ward) is an American actress who won the title of Miss America in 1982.
Early life, beauty and acting careers.
She was born on April 3, 1961, in Ozark, Arkansas, and raised in Booneville, Arkansas, the daughter of Jimmy Young Ward and Patricia "Pat" (Murphy) Ward. She later moved to Russellville, Arkansas with her family, where she graduated from Russellville High School in 1979. She won the titles of Miss Arkansas in 1981 and Miss America in 1982. She used her Miss America scholarship money to study acting at HB Studios in New York City before moving to Hollywood to pursue a film and television career. During this time, Gracen says she had a one-night stand with future President Bill Clinton. She posed nude for "Playboy" magazine's May 1992 issue.
She built an acting career, and in 1989, while filming "", she met actor Brendan Hughes and they married soon after. The couple divorced in 1994. Before that she was married to Jon Birmingham. She has since remarried and has a daughter.
She made her professional feature film debut in "Three For The Road" with Charlie Sheen. Her film credits also include a featured role in "Marked For Death" opposite Steven Seagal, "Pass The Ammo" with Tim Curry, and the CBS feature "83 Hours Till Dawn" with Peter Strauss and Robert Urich. Gracen starred in "Lower Level" and "Discretion Assured" with Michael York.
On television, Gracen has appeared in Shelley Duvall's "Strange Case of Dr. Jekyll and Mr. Hyde", Sidney Sheldon's "The Sands of Time" and "Death of the Incredible Hulk". She also appeared with a starring role in the series "Extreme" for NBC and the syndicated series "Renegade" and "Queen of Swords".
Elizabeth Gracen's best-known acting role has been as the character of the Immortal Amanda in the series ', and its spin-off series, '. She is focused currently on writing and directing. Gracen made her directorial debut with a documentary short feature called "The Damn Deal". The film is an intimate portrait of three young drag queens from her home state who compete in female impersonator beauty pageants.
Claimed affair with Bill Clinton.
In 1992, rumors swirled that Gracen had had an affair with Arkansas Governor Bill Clinton. At first, Gracen dismissed this claim. In Spring 1998 Gracen recanted her six-year-old denial and stated she had a one-night stand with Clinton in 1982.
After claiming this, Independent Counsel Kenneth Starr, who was investigating Clinton in the Paula Jones lawsuit, issued a subpoena to have her testify her claim in court.
Gracen, however, eluded the subpoena and was at one point able to avoid it because "" was being filmed out of the country. Paula Jones' legal team was also unable to track down Gracen because she had made unscheduled trips to Las Vegas and the Caribbean.
Voiceover work.
After "Highlander: the Raven" was cancelled after the first season, Gracen was unable to find more work in acting and was soon in deep financial trouble. In December 1999, Gracen filed for bankruptcy protection. Afterward, Gracen was given a few television guest roles, and a supporting role in the made-for-television movie "Interceptor Force 2", before taking a long leave of absence from her acting career in 2002. Gracen recently began doing voiceover work for Blue Hours Productions, which has revived the classic radio anthology "Suspense", which airs on Sirius XM. In 2012, Gracen did a character voice-over in the Malaysian animated science fiction film "".

</doc>
<doc id="10073" url="http://en.wikipedia.org/wiki?curid=10073" title="Epicurus">
Epicurus

Epicurus ( or ; Greek: Ἐπίκουρος, "Epíkouros", "ally, comrade"; 341–270 BC) was an ancient Greek philosopher as well as the founder of the school of philosophy called Epicureanism. Only a few fragments and letters of Epicurus's 300 written works remain. Much of what is known about Epicurean philosophy derives from later followers and commentators.
For Epicurus, the purpose of philosophy was to attain the happy, tranquil life, characterized by "ataraxia"—peace and freedom from fear—and "aponia"—the absence of pain—and by living a self-sufficient life surrounded by friends. He taught that pleasure and pain are the measures of what is good and evil; death is the end of both body and soul and should therefore not be feared; the gods neither reward nor punish humans; the universe is infinite and eternal; and events in the world are ultimately based on the motions and interactions of atoms moving in empty space.
Biography.
His parents, Neocles and Chaerestrate, both Athenian-born, and his father a citizen, had emigrated to the Athenian settlement on the Aegean island of Samos about ten years before Epicurus's birth in February 341 BC. As a boy, he studied philosophy for four years under the Platonist teacher Pamphilus. At the age of eighteen, he went to Athens for his two-year term of military service. The playwright Menander served in the same age-class of the ephebes as Epicurus.
After the death of Alexander the Great, Perdiccas expelled the Athenian settlers on Samos to Colophon, on the coast of what is now Turkey. After the completion of his military service, Epicurus joined his family there. He studied under Nausiphanes, who followed the teachings of Democritus. In 311/310 BC Epicurus taught in Mytilene but caused strife and was forced to leave. He then founded a school in Lampsacus before returning to Athens in 306 BC where he remained until his death. There he founded The Garden (κῆπος), a school named for the garden he owned that served as the school's meeting place, about halfway between the locations of two other schools of philosophy, the Stoa and the Academy.
Even though many of his teachings were heavily influenced by earlier thinkers, especially by Democritus, he differed in a significant way with Democritus on determinism. Epicurus would often deny this influence, denounce other philosophers as confused, and claim to be "self-taught".
Epicurus never married and had no known children. He was mostly likely a vegetarian. He suffered from kidney stones, to which he finally succumbed in 270 BC at the age of seventy-two, and despite the prolonged pain involved, he wrote to Idomeneus:
I have written this letter to you on a happy day to me, which is also the last day of my life. For I have been attacked by a painful inability to urinate, and also dysentery, so violent that nothing can be added to the violence of my sufferings. But the cheerfulness of my mind, which comes from the recollection of all my philosophical contemplation, counterbalances all these afflictions. And I beg you to take care of the children of Metrodorus, in a manner worthy of the devotion shown by the young man to me, and to philosophy.
The school.
Epicurus' school, which was based in the garden of his house and thus called "The Garden", had a small but devoted following in his lifetime. The primary members were Hermarchus, the financier Idomeneus, Leonteus and his wife Themista, the satirist Colotes, the mathematician Polyaenus of Lampsacus, Leontion, and Metrodorus of Lampsacus, the most famous popularizer of Epicureanism. His school was the first of the ancient Greek philosophical schools to admit women as a rule rather than an exception. An inscription on the gate to The Garden is recorded by Seneca in epistle XXI of Epistulae morales ad Lucilium:
Stranger, here you will do well to tarry; here our highest good is pleasure.
Epicurus emphasized friendship as an important ingredient of happiness, and the school resembled in many ways a community of friends living together. However, he also instituted a hierarchical system of levels among his followers, and had them swear an oath on his core tenets.
Teachings.
Prefiguring science and ethics.
Epicurus is a key figure in the development of science and scientific methodology because of his insistence that nothing should be believed, except that which was tested through direct observation and logical deduction. He was a key figure in the Axial Age, the period from 800 BC to 200 BC, during which, according to Karl Jaspers, similar thinking appeared in China, India, Iran, the Near East, and Ancient Greece. His statement of the Ethic of Reciprocity as the foundation of ethics is the earliest in Ancient Greece, and he differs from the formulation of utilitarianism by Jeremy Bentham and John Stuart Mill by emphasizing the minimization of harm to oneself and others as the way to maximize happiness.
Epicurus's teachings represented a departure from the other major Greek thinkers of his period, and before, but was nevertheless founded on many of the same principles as Democritus. Like Democritus, he was an atomist, believing that the fundamental constituents of the world were indivisible little bits of matter (atoms; Greek: ἄτομος "atomos", "indivisible") flying through empty space (Greek: κενόν "kenon"). Everything that occurs is the result of the atoms colliding, rebounding, and becoming entangled with one another, with no purpose or plan behind their motions. (Compare this with the modern study of particle physics.) His theory differs from the earlier atomism of Democritus because he admits that atoms do not always follow straight lines but their direction of motion may occasionally exhibit a "swerve" (Greek: παρέγκλισις "parenklisis"; Latin: "clinamen"). This allowed him to avoid the determinism implicit in the earlier atomism and to affirm free will.
He regularly admitted women and slaves into his school and was one of the first Greeks to break from the god-fearing and god-worshiping tradition common at the time, even while affirming that religious activities are useful as a way to contemplate the gods and to use them as an example of the pleasant life. Epicurus participated in the activities of traditional Greek religion, but taught that one should avoid holding false opinions about the gods. The gods are immortal and blessed and men who ascribe any additional qualities that are alien to immortality and blessedness are, according to Epicurus, impious. The gods do not punish the bad and reward the good as the common man believes. The opinion of the crowd is, Epicurus claims, that the gods "send great evils to the wicked and great blessings to the righteous who model themselves after the gods," whereas Epicurus believes the gods, in reality, do not concern themselves at all with human beings.
It is not the man who denies the gods worshipped by the multitude, who is impious, but he who affirms of the gods what the multitude believes about them.
Pleasure as absence of suffering.
Epicurus' philosophy is based on the theory that all good and bad derive from the sensations of what he defined as pleasure and pain: What is good is what is pleasurable, and what is bad is what is painful. His ideas of pleasure and pain were ultimately, for Epicurus, the basis for the moral distinction between good and evil. If pain is chosen over pleasure in some cases it is only because it leads to a greater pleasure. Although Epicurus has been commonly misunderstood to advocate the rampant pursuit of pleasure, his teachings were more about striving for an absence of pain and suffering, both physical and mental, and a state of satiation and tranquility that was free of the fear of death and the retribution of the gods. Epicurus argued that when we do not suffer pain, we are no longer in need of pleasure, and we enter a state of "ataraxia", "tranquility of soul" or "imperturbability".
Epicurus' teachings were introduced into medical philosophy and practice by the Epicurean doctor Asclepiades of Bithynia, who was the first physician who introduced Greek medicine in Rome. Asclepiades introduced the friendly, sympathetic, pleasing and painless treatment of patients. He advocated humane treatment of mental disorders, had insane persons freed from confinement and treated them with natural therapy, such as diet and massages. His teachings are surprisingly modern, therefore Asclepiades is considered to be a pioneer physician in psychotherapy, physical therapy and molecular medicine.
Epicurus explicitly warned against overindulgence because it often leads to pain. For instance, Epicurus warned against pursuing love too ardently. He defended friendships as ramparts for pleasure and denied them any inherent worth. He also believed, contrary to Aristotle, that death was not to be feared. When a man dies, he does not feel the pain of death because he no longer is and therefore feels nothing. Therefore, as Epicurus famously said, "death is nothing to us." When we exist, death is not; and when death exists, we are not. All sensation and consciousness ends with death and therefore in death there is neither pleasure nor pain. The fear of death arises from the belief that in death, there is awareness.
From this doctrine arose the Epicurean epitaph: "Non fui, fui, non sum, non curo" ("I was not; I was; I am not; I do not care"), which is inscribed on the gravestones of his followers and seen on many ancient gravestones of the Roman Empire. This quotation is often used today at humanist funerals.
As an ethical guideline, Epicurus emphasized minimizing harm and maximizing happiness of oneself and others:
It is impossible to live a pleasant life without living wisely and well and justly, and it is impossible to live wisely and well and justly without living pleasantly.
Epicurean paradox.
The "Epicurean paradox" is a version of the problem of evil. It is a "trilemma" argument (God is omnipotent, God is good, but Evil exists); or more commonly seen as this quote:
 Is God willing to prevent evil, but not able?<br>
Then he is not omnipotent.<br>
Is he able, but not willing?<br>
Then he is malevolent.<br>
Is he both able and willing?<br>
Then whence cometh evil?<br>
Is he neither able nor willing?<br>
Then why call him God?
This argument was a type favoured by the ancient Greek skeptics, and may have been wrongly attributed to Epicurus by Lactantius, who, from his Christian perspective, regarded Epicurus as an atheist. It has been suggested that it may actually be the work of an early skeptic writer, possibly Carneades. According to Reinhold F. Glei, it is certain that the argument of theodicy is from an academic source which is not only not Epicurean, but even anti-Epicurean. The earliest extant version of this "trilemma" appears in the writings of the skeptic Sextus Empiricus (160–210 AD).
Epicurus did not deny the existence of gods. He instead stated that what gods there may be, do not concern themselves with us, and thus, that they would not seek to punish us either in this or any other life.
Epistemology.
Epicurus emphasized the senses in his epistemology, and his Principle of Multiple Explanations ("if several theories are consistent with the observed data, retain them all") is an early contribution to the philosophy of science.
There are also some things for which it is not enough to state a single cause, but several, of which one, however, is the case. Just as if you were to see the lifeless corpse of a man lying far away, it would be fitting to list all the causes of death in order to make sure that the single cause of this death may be stated. For you would not be able to establish conclusively that he died by the sword or of cold or of illness or perhaps by poison, but we know that there is something of this kind that happened to him.
Politics.
In contrast to the Stoics, Epicureans showed little interest in participating in the politics of the day, since doing so leads to trouble. He instead advocated seclusion. This principle is epitomized by the phrase "lathe biōsas" (λάθε βιώσας), meaning "live in obscurity", "get through life without drawing attention to yourself", i.e., live without pursuing glory or wealth or power, but anonymously, enjoying little things like food, the company of friends, etc. Plutarch elaborated on this theme in his essay "Is the Saying "Live in Obscurity" Right?" (Εἰ καλῶς εἴρηται τὸ λάθε βιώσας, "An recte dictum sit latenter esse vivendum") 1128c; cf. Flavius Philostratus, "Vita Apollonii" .
Legacy.
Elements of Epicurean philosophy have resonated and resurfaced in various diverse thinkers and movements throughout Western intellectual history.
The atomic poems (such as 'All Things are Governed by Atoms') and natural philosophy of Margaret Cavendish were influenced by Epicurus.
His emphasis on minimizing harm and maximizing happiness in his formulation of the Ethic of Reciprocity was later picked up by the democratic thinkers of the French Revolution, and others, like John Locke, who wrote that people had a right to "life, liberty, and property." To Locke, one's own body was part of their property, and thus one's right to property would theoretically guarantee safety for their persons, as well as their possessions.
This triad, as well as the egalitarianism of Epicurus, was carried forward into the American freedom movement and Declaration of Independence, by the American founding father, Thomas Jefferson, as "all men are created equal" and endowed with certain "unalienable rights," such as "life, liberty, and the pursuit of happiness." Jefferson considered himself an Epicurean. 
In "An Enquiry Concerning Human Understanding", David Hume uses Epicurus as a character for explaining the impossibility of our knowing God to be any greater or better than his creation proves him to be.
Karl Marx's doctoral thesis was on "The Difference Between the Democritean and Epicurean Philosophy of Nature." 
Epicurus was first to assert human freedom as coming from a fundamental indeterminism in the motion of atoms. This has led some philosophers to think that for Epicurus free will was "caused directly by chance". In his "On the Nature of Things" ("De rerum natura"), Lucretius appears to suggest this in the best-known passage on Epicurus' position. But in his Letter to Menoeceus, Epicurus follows Aristotle and clearly identifies "three" possible causes - "some things happen of necessity, others by chance, others through our own agency." Aristotle said some things "depend on us" ("eph hemin"). Epicurus agreed, and said it is to these last things that praise and blame naturally attach. For Epicurus, the random "swerve" (or "clinamen") of the atoms simply defeated determinism to leave room for autonomous agency.
Epicurus was also a significant source of inspiration and interest for both Arthur Schopenhauer, having particular influence on the famous pessimist's views on suffering and death, as well as one of Schopenhauer's successors: Friedrich Nietzsche. Nietzsche cites his affinities to Epicurus in a number of his works, including "The Gay Science", "Beyond Good and Evil", and his private letters to Peter Gast. Nietzsche was attracted to, among other things, Epicurus' ability to maintain a cheerful philosophical outlook in the face of painful physical ailments. Nietzsche also suffered from a number of sicknesses during his lifetime. However, he thought that Epicurus' conception of happiness as freedom from anxiety was too passive and negative.
Works.
The only surviving complete works by Epicurus are three letters, which are to be found in book X of Diogenes Laërtius' "Lives of Eminent Philosophers", and two groups of quotes: the "Principal Doctrines" (Κύριαι Δόξαι), reported as well in Diogenes' book X, and the "Vatican Sayings", preserved in a manuscript from the Vatican Library.
Numerous fragments of his thirty-seven volume treatise "On Nature" have been found among the charred papyrus fragments at the Villa of the Papyri at Herculaneum. In addition, other Epicurean writings found at Herculaneum contain important quotations from his other works. Moreover, numerous fragments and testimonies are found throughout ancient Greek and Roman literature, a collection of which can be found in Usener's "Epicurea".
According to Diogenes Laertius, the major works of Epicurus include:
Hero cult.
According to Diskin Clay, Epicurus himself established a custom of celebrating his birthday annually with common meals, befitting his stature as hero ctistes (or founding hero) of the Garden. He ordained in his will annual memorial feasts for himself on the same date (10th of Gamelion month). Epicurean communities continued this tradition, referring to Epicurus as their "savior" (soter) and celebrating him as hero. Lucretius apotheosized Epicurus as the main character of his epic poem De rerum natura. The hero cult of Epicurus may have operated as a Garden variety civic religion. However, clear evidence of an Epicurean hero cult, as well as the cult itself, seems buried by the weight of posthumous philosophical interpretation. Epicurus' cheerful demeanor, as he continued to work despite dying from a painful stone blockage of his urinary tract lasting a fortnight, according to his successor Hermarchus and reported by his biographer Diogenes Laërtius, further enhanced his status among his followers.
In literature and popular media.
Paul the Apostle encountered Epicurean and Stoic philosophers as he was ministering in Athens.
Horace describes himself as "Epicuri de grege porcum" "a swine from Epicure's herd" in his "Epistles".
In Canto X Circle 6 ("Where the heretics lie") of Dante's Inferno, Epicurus and his followers are criticized for supporting a materialistic ideal when they are mentioned to have been condemned to the Circle of Heresy.
"Epicurus the Sage" is a two-part comic book by William Messner-Loebs and Sam Kieth portraying Epicurus as "the only sane philosopher" by anachronistically bringing him together with many other well-known Greek philosophers. It was republished as graphic novel by the Wildstorm branch of DC Comics.
Epicurus and the "Epicurism".
In Judaism, Epicurians are ones which do not have a share in Olam Haba—the afterlife and the world to come.
In Rabbinic literature the term "Epikoros" is used, without a specific reference to the Greek philosopher Epicurus, yet it seems apparent that the term was derived from his name.
Epicurus's apparent hedonistic views (Hedonism being a sub-set of Epicureanism) and philosophical teachings, though opposed to the Hedonists of his time, countered Jewish scripture, the strictly monotheistic conception of God in Judaism and the Jewish belief in the afterlife and the world to come.
The Talmudic interpretation is that the Aramaic word is derived from the root-word פק"ר (PKR; lit. "licentious"), hence disrespect.
The Christian censorship of the Jewish Talmud in the aftermath of the Disputation of Barcelona and during the Spanish Inquisition and Roman Inquisition, let the term spread within the Jewish classical texts, since Roman Catholic Church censors replaced terms like "Minim" ("sectarians", coined on the Christians) with the term "Epikorsim" or "Epicursim", meaning heretics.

</doc>
<doc id="10074" url="http://en.wikipedia.org/wiki?curid=10074" title="Epitaph">
Epitaph

An epitaph (from Greek ἐπιτάφιος "epitaphios" "a funeral oration" from ἐπί "epi" "at, over" and τάφος "taphos" "tomb") is a short text honoring a deceased person. Strictly speaking, it refers to text that is inscribed on a tombstone or plaque, but it may also be used in a figurative sense. Some epitaphs are specified by the person themselves before their death, while others are chosen by those responsible for the burial. An epitaph may be in poem verse; poets have been known to compose their own epitaphs prior to their death, as William Shakespeare did.
Most epitaphs are brief records of the family, and perhaps the career, of the deceased, often with an expression of love or respect - "beloved father of ..." - but others are more ambitious. From the Renaissance to the 19th century in Western culture, epitaphs for notable people became increasingly lengthy and pompous descriptions of their family origins, career, virtues and immediate family, often in Latin. However, the Laudatio Turiae, the longest known Ancient Roman epitaph, exceeds almost all of these at 180 lines; it celebrates the virtues of a wife, probably of a consul.
Some are quotes from holy texts, or aphorisms. One approach of many epitaphs is to 'speak' to the reader and warn them about their own mortality. A wry trick of others is to request the reader to get off their resting place, inasmuch as the reader would have to be standing on the ground above the coffin to read the inscription. Some record achievements (e.g., past politicians note the years of their terms of office). Nearly all (excepting those where this is impossible by definition, such as the Tomb of the Unknown Soldier) note name, year or date of birth, and date of death. Many list family members and the relationship of the deceased to them (for example, "Father / Mother / Son / Daughter of").
Notable epitaphs.
"Heroes and Kings your distance keep;<br>
"In peace let one poor poet sleep,<br>
"Who never flattered folks like you;<br>
"Let Horace blush and Virgil too."
"Wir müssen wissen. Wir werden wissen." <br>
In English: 
"We must know. We will know."
"Here lies One whose Name was writ in Water<br>
"Sleep after toyle, port after stormie seas",<br>"Ease after warre, death after life, does greatly please."
"That's all folks."
"I've finally stopped getting dumber."
"Consider, friend, as you pass by: As you are now, so once was I. As I am now, you too shall be. Prepare, therefore, to follow me."
"Go tell the Spartans, stranger passing by"
"that here, obedient to their law, we lie."
"I told you I was ill."
"If anyone at my funeral has a long face, I'll never speak to him again."
"Here sleeps at peace a Hampshire Grenadier<br>
"Who caught his early death by drinking cold small beer.<br>
"Soldiers, be wise at his untimely fall,<br>
"And when you're hot, drink strong or none at all."
"To save your world you asked this man to die:"
"Would this man, could he see you now, ask why?"
"There is borne an empty hearse"
"covered over for such as appear not." 
"Heroes have the whole earth for their tomb."
"Against you I will fling myself, unvanquished and unyielding, O Death!"
"Good frend for Jesus sake forebeare,"<br>
"To digg þe dust encloased heare."<br> 
"Blese be þe man þat spares þes stones,"<br>
"And curst be he þat moves my bones."
In modern spelling:<br>
Good friend for Jesus sake forbear,<br>
To dig the dust enclosed here.<br> 
Blessed be the man that spares these stones,<br>
And cursed be he that moves my bones.
"I am ready to meet my Maker. "
"Whether my Maker is prepared for the great ordeal"
"of meeting me is another matter."
Epitaphs in music.
In a more figurative sense, the term may be used for music composed in memory of the deceased. Igor Stravinsky composed in 1958 "Epitaphium" for flute, clarinet and harp. In 1967 Krzysztof Meyer called his Symphony No. 2 for choir and orchestra "Epitaphium Stanisław Wiechowicz in memoriam". Jeffrey Lewis composed "Epitaphium — Children of the Sun" for narrator, chamber choir, piano, flute, clarinet and percussion. Bronius Kutavičius composed in 1998 "Epitaphium temporum pereunti". Valentin Silvestrov composed in 1999 "Epitaph L.B." (Епітафія Л.Б.) for viola (or cello) and piano. In 2007 Graham Waterhouse composed "Epitaphium" for string trio as a tribute to the memory of his father William Waterhouse. The South African poet Gert Vlok Nel wrote an (originally) untitled song, which appeared on his first music album 'Beaufort-Wes se Beautiful Woorde' as 'Epitaph', because his producer Eckard Potgieter told him that the song sounded like an epitaph.
Epitaph in space.
In the late 1990s, a unique epitaph was flown to the moon along with the cremains of geologist/planetary scientist Eugene Shoemaker. At the suggestion of colleague Carolyn Porco, Shoemaker's ashes were launched aboard the Lunar Prospector spacecraft on January 6, 1998. The ashes were accompanied by a laser-engraved epitaph on a small piece of foil. The spacecraft, along with the ashes and epitaph, crashed on command into the south polar region of the moon on July 31, 1999.

</doc>
<doc id="10075" url="http://en.wikipedia.org/wiki?curid=10075" title="Epigram">
Epigram

An epigram is a brief, interesting, memorable, and sometimes surprising or satirical statement. Derived from the Greek: ἐπίγραμμα "epigramma" "inscription" from ἐπιγράφειν "epigraphein" "to write on, to inscribe", this literary device has been employed for over two millennia.
Ancient Greek.
The Greek tradition of epigrams began as poems inscribed on votive offerings at sanctuaries – including statues of athletes – and on funerary monuments, for example "Go tell it to the Spartans, passersby...". These original epigrams did the same job as a short prose text might have done, but in verse. Epigram became a literary genre in the Hellenistic period, probably developing out of scholarly collections of inscriptional epigrams.
Though modern epigrams are usually thought of as very short, Greek literary epigram was not always as short as later examples, and the divide between "epigram" and "elegy" is sometimes indistinct (they share a characteristic metre, elegiac couplets); all the same, the origin of the genre in inscription exerted a residual pressure to keep things concise. Many of the characteristic types of literary epigram look back to inscriptional contexts, particularly funerary epigram, which in the Hellenistic era becomes a literary exercise. Other types look instead to the new performative context which epigram acquired at this time, even as it made the move from stone to papyrus: the Greek symposium. Many "sympotic" epigrams combine sympotic and funerary elements – they tell their readers (or listeners) to drink and live for today because life is short.
Epigrams are also thought of as having a "point" – that is, the poem ends in a punchline or satirical twist. By no means do all Greek epigrams behave this way; many are simply descriptive. Epigram is associated with 'point' because the European epigram tradition takes the Latin poet Martial as its principal model; he copied and adapted Greek models (particularly the contemporary poets Lucillius and Nicarchus) selectively and in the process redefined the genre, aligning it with the indigenous Roman tradition of 'satura', hexameter satire, as practised by (among others) his contemporary Juvenal. Greek epigram was actually much more diverse, as the Milan Papyrus now indicates.
A major source for Greek literary epigram is the "Greek Anthology", a compilation from the 10th century AD based on older collections. It contains epigrams ranging from the Hellenistic period through the Imperial period and Late Antiquity into the compiler's own Byzantine era – a thousand years of short elegiac texts on every topic under the sun. The "Anthology" includes one book of Christian epigrams as well as one book of erotic and amorous epigrams called the Μουσα Παιδικη (Mousa Paidike, "The Boyish Muse").
Ancient Roman.
Roman epigrams owe much to their Greek predecessors and contemporaries. Roman epigrams, however, were often more satirical than Greek ones, and at times used obscene language for effect. Latin epigrams could be composed as inscriptions or graffiti, such as this one from Pompeii, which exists in several versions and seems from its inexact meter to have been composed by a less educated person. Its content, of course, makes it clear how popular such poems were:
However, in the literary world, epigrams were most often gifts to patrons or entertaining verse to be published, not inscriptions. Many Roman writers seem to have composed epigrams, including Domitius Marsus, whose collection "Cicuta" (now lost) was named after the poisonous plant "Cicuta" for its biting wit, and Lucan, more famous for his epic "Pharsalia". Authors whose epigrams survive include Catullus, who wrote both invectives and love epigrams – his poem 85 is one of the latter.
The master of the Latin epigram, however, is Martial. His technique relies heavily on the satirical poem with a joke in the last line, thus drawing him closer to the modern idea of epigram as a genre. Here he defines his genre against a (probably fictional) critic (in the latter half of 2.77):
Poets known for their epigrams whose work has been lost include Cornificia.
English.
In early English literature the short couplet poem was dominated by the poetic epigram and proverb, especially in the translations of the Bible and the Greek and Roman poets.
Since 1600, two successive lines of verse that rhyme with each other, known as a couplet featured as a part of the longer sonnet form, most notably in William Shakespeare's sonnets. Sonnet 76 is an excellent example. The two line poetic form as a closed couplet was also used by William Blake in his poem Auguries of Innocence and also by Byron (Don Juan (Byron) XIII); John Gay (Fables); Alexander Pope (An Essay on Man).
In Victorian times the epigram couplet was often used by the prolific American poet Emily Dickinson. Her poem No. 1534 is a typical example of her eleven poetic epigrams. The novelist George Eliot also included couplets throughout her writings. Her best example is in her sequenced sonnet poem entitled , in which each of the eleven sequenced sonnet ends with a couplet. In her sonnets, the preceding lead-in-line, to the couplet ending of each, could be thought of as a title for the couplet, as is shown in Sonnet VIII of the sequence.
During the early 20th century, the rhymed epigram couplet form developed into a fixed verse image form, with an integral title as the third line. Adelaide Crapsey codified the couplet form into a two line rhymed verse of ten syllables per line with her image couplet poem , first published in 1915.
By the 1930s, the five-line cinquain verse form became widely known in the poetry of the Scottish poet William Soutar. These were originally labelled epigrams but later identified as image cinquains in the style of Adelaide Crapsey.
J. V. Cunningham was also a noted writer of epigrams,(a medium suited to a 'short-breathed' person).
Non-poetic epigrams.
Occasionally, simple and witty statements, though not poetic per se, may also be considered epigrams. Oscar Wilde's witticisms such as "I can resist everything except temptation" are considered epigrams. Wilde's statement, "the only thing worse than being talked about is not being talked about" is another example. This shows the epigram's tendency towards paradox. Dorothy Parker's one-liners can be considered epigrams, as can Macdonald Carey's statement, "like sands through the hourglass, so are the days of our lives". Friedrich Nietzsche considered that, "a witticism is an epigram on the death of a feeling," in Human, All Too Human.
The term is sometimes used for particularly pointed or much-quoted quotations taken from longer works.

</doc>
<doc id="10076" url="http://en.wikipedia.org/wiki?curid=10076" title="El Cid">
El Cid

Rodrigo Díaz de Vivar (c. 1043 – 1099) was a Castilian nobleman and military leader in medieval Hispanic kingdoms. He was called El Cid ("the Lord") by the Moors and El Campeador ("the Champion") by Christians. He is the otherwise real but made legendary national hero of Castile. He was born in Vivar del Cid, a town near the city of Burgos.
Born a member of the minor nobility, El Cid was brought up at the court of King Ferdinand the Great and served in the household of Ferdinand's son Sancho. He rose to become commander and the royal standard-bearer ("armiger regis") of Castile upon Sancho's ascension in 1065. He went on to lead the Castilian military campaigns against Sancho's brothers, the rulers of the kingdoms of Leon and Galicia as well as against the Muslim kingdoms in Al-Andalus. He became famous for his military prowess in these campaigns, and helped enlarge Castilian territory at the expense of the Muslims while driving Sancho's brothers from their thrones. This, however, ended up putting him in a difficult position when suddenly, in 1072, Sancho was murdered and with no legitimate heir, leaving his recently ousted brother, Alfonso, as his only heir and ruler of the reunified empire. Although El Cid continued to serve the crown in the person of Alfonso, who was now Emperor of Spain, he lost his status in court and was held in suspicion. Finally, in 1081, he was ordered into exile.
Rodrigo Díaz found work fighting for the Muslim rulers of Zaragoza, whom he protected from the domination of Aragon and Barcelona, further bolstering his military record and reputation as a leader. He was also victorious in battles against the Muslim rulers of Lérida and their Christian allies, as well as against a large Christian army under King Sancho Ramírez of Aragon. In 1086, Alfonso was defeated by Almoravids from North Africa, and he overcame his antagonism to talk El Cid into fighting for him again. Over the next several years El Cid set his sights on the kingdom-city of Valencia, operating more or less independently of Alfonso while politically supporting the Banu Hud and other Muslim dynasties opposed to the Almoravids. He gradually increased his control over Valencia; the Islamic ruler, al-Qadir, became his tributary in 1092. However, the Almoravids instigated an uprising that resulted in the death of al-Qadir – he responded by laying siege to the city. Valencia finally fell in 1094 and El Cid established an independent principality in the eastern Mediterranean coast of Spain. He ruled over a pluralistic state with the popular support of both Christians and Muslims.
The final years of El Cid were spent in fighting the Almoravid Berbers. He inflicted the first major defeat on them in 1094 in the plains of Caurte outside Valencia and continued resisting them until his death. Although El Cid himself remained undefeated in Valencia, he suffered a tragedy when his only son and heir, Diego Rodríguez, died fighting against the Almoravids in the service of Alfonso in 1097. After El Cid's death in 1099, his wife, Jimena Díaz, succeeded him as ruler of Valencia, but she had to surrender the principality to the Almoravids in 1102.
Long after his death, El Cid remains an idolised figure in Spain. The character and his name have been immortalized in plays, film, folk tales, songs, and videogames.
Title.
The name "El Cid" (]) is a modern Spanish denomination composed by the article "el" meaning "the" and "Cid" which comes from the Old Castilian loan word "Çid" from the dialectal Arabic word سيد "sîdi" or sayyid, which means "Lord" or "Master". He could be so addressed by the Mozarabs or by the Arabs serving in his own ranks, and then its transliteration was adopted by the Christians, but no contemporary record referring to Rodrigo as "Cid" has been found. Arab sources use instead "Rudriq", "Ludriq al-Kanbiyatur" or "al-Qanbiyatur" ("Rodrigo el Campeador"). The cognomen "Campeador" given by his Christian countrymen derives from Latin "campi doctor" that means "battlefield master". He probably gained it during the campaigns of King Sancho II of Castile against his brothers King Alfonso VI of León and King García II of Galicia. While there are no contemporary documents proving that he was addressed as "Cid", there are many Christian and Arab records addressing him as "Campeador", even autographs which prove that he used the cognomen himself. The whole combination "Cid Campeador" is first documented ca. 1195 in the Navarro-Aragonese "Linage de Rodric Díaz" included in the "Liber Regum" under the formula "mio Cid el Campeador".
Life and career.
Origins.
El Cid was born circa 1043 AD in Vivar, also known as Castillona de Bivar, a small town about six miles north of Burgos, the capital of Castile. His father, Diego Laínez, was a courtier, bureaucrat, and cavalryman who had fought in several battles. Despite the fact that El Cid's mother's family was aristocratic, in later years the peasants would consider him one of their own. However, his relatives were not major court officials; documents show that El Cid's paternal grandfather, Lain, confirmed only five documents of Ferdinand I's, his maternal grandfather, Rodrigo Alvarez, certified only two of Sancho II's, and El Cid's own father confirmed only one.
Service under Sancho II.
As a young man in 1057, Rodrigo fought against the Moorish stronghold of Zaragoza, making its emir al-Muqtadir a vassal of Sancho. In the spring of 1063, Rodrigo fought in the Battle of Graus, where Ferdinand's half-brother, Ramiro I of Aragon, was laying siege to the Moorish town of Cinca which was in Zaragozan lands. Al-Muqtadir, accompanied by Castilian troops including El Cid, fought against the Aragonese. The party would emerge victorious; Ramiro I was killed and the Aragonese fled the field. One legend has said that during the conflict, El Cid killed an Aragonese knight in single combat, thereby receiving the honorific title Campeador.
When Ferdinand died, Sancho continued to enlarge his territory, conquering both Christian and the Moorish cities of Zamora and Badajoz. When Sancho learned that Alfonso was planning on overthrowing him in order to gain his territory, Sancho sent Cid to bring Alfonso back so that Sancho could speak to him.
Service under Alfonso VI.
Sancho was assassinated in 1072, as the result of a pact between his brother Alfonso and his sister Urraca. Since Sancho died unmarried and childless, all of his power passed to his brother Alfonso.
Almost immediately, Alfonso returned from exile in Toledo and took his seat as king of Castile and León. He was deeply suspected in Castile, probably correctly, of having been involved in Sancho's murder. According to the epic of El Cid, the Castilian nobility led by El Cid and a dozen "oath-helpers" forced Alfonso to swear publicly in front of Santa Gadea (Saint Agatha) Church in Burgos on holy relics multiple times that he did not participate in the plot to kill his brother. This is widely reported as truth, but contemporary documents on the lives of both Rodrigo Diaz and Alfonso VI of Castile and León do not mention any such event. Rodrigo's position as "armiger regis" was taken away and given to Rodrigo's enemy, Count García Ordóñez.
In 1079 Rodrigo was sent by Alfonso VI to Seville to the court of al-Mutamid to collect the "parias" owed by that "taifa" to León–Castile. While he was there Granada, assisted by other Castilean knights, attacked Seville, and Rodrigo and his forces repulsed the Christian and Grenadine attackers at the Battle of Cabra, in the (probably mistaken) belief that he was defending the king's tributary. The Count García Ordóñez and the other Castilian leaders were taken captive and held for three days before being released.
Exile.
In the Battle of Cabra (1079), El Cid rallied his troops and turned the battle into a rout of Emir Abdullah of Granada and his ally García Ordóñez. However, El Cid's unauthorized expedition into Granada greatly angered Alfonso, and May 8, 1080, was the last time El Cid confirmed a document in King Alfonso's court. This is the generally given reason for El Cid's exile, although several others are plausible and may have been contributing factors: jealous nobles turning Alfonso against El Cid, Alfonso's own animosity towards El Cid and an accusation of pocketing some of the tribute from Seville.
At first he went to Barcelona, where Ramón Berenguer II (1076–1082) and Berenguer Ramón II (1076–1097) refused his offer of service.
Moorish service.
After being rejected by Ramón Berenguer II, El Cid journeyed to the Taifa of Zaragoza where he received a warmer welcome.
According to Moorish accounts:
Andalusian Knights found El Cid their foe ill, thirsty and exiled from the court of Alfonso, he was presented before the elderly Yusuf al-Mu'taman ibn Hud and accepted command of the forces of the Taifa of Zaragoza as their Master.
However, the exile was not the end of El Cid, either physically or as an important figure. In 1081, El Cid, went on to offer his services to the Moorish king of the northeast Al-Andalus city of Zaragoza, Yusuf al-Mu'taman ibn Hud, and served both him and his successor, Al-Mustain II. He was given the title "El Cid" ("The Master") and served as a leading figure in a diverse Moorish force consisting of Muladis, Berbers, Arabs and Malians.
In his "History of Medieval Spain" (Cornell University Press, 1975), Joseph F. O'Callaghan writes:
That kingdom was divided between al-Mutamin (1081–1085) who ruled Zaragoza proper, and his brother al-Mundhir, who ruled Lérida and Tortosa. El Cid entered al-Mutamin's service and successfully defended Zaragoza against the assaults of al-Mundhir, Sancho I of Aragón, and Ramón Berenguer II, whom he held captive briefly in 1082. In 1084, El Cid and the Moorish armies defeated Sancho of Aragon at the Battle of Morella near Tortosa. He was then troubled by the fierce conflicts between the Muladis of Badajoz and the Arabs of Seville.
In 1086, the Almoravid invasion of the Iberian Peninsula through and around Gibraltar began. The Almoravids, Berber residents of present-day North Africa, led by Yusuf ibn Tashfin, were asked to help defend the divided Moors from Alfonso. El Cid had probably commanded a large Moorish force during the Battle of Sagrajas, which took place in 1086, near the Taifa of Badajoz. The Almoravid and Andalusian Taifas, including the armies of Badajoz, Málaga, Granada, Tortosa and Seville, defeated a combined army of León, Aragón and Castile.
Recall from exile.
Terrified after his crushing defeat, Alfonso recalled El Cid. It has been shown that El Cid was at court on July 1087; however, what happened after that is unclear. 
El Cid returned to Alfonso, but now he had his own plans. He only stayed a short while and then returned to Zaragoza. El Cid was content to let the Almoravid armies and the armies of Alfonso fight without his help, even when there was a chance that the armies of Almoravid might defeat Alfonso and take over all of Alfonso's lands. The reason El Cid did not want to fight was because he was hoping that both armies would become weak. That would make it easier for him to carry out his own plan which was to become ruler of the Kingdom of Valencia.
Conquest of Valencia.
Around this time, El Cid, with a combined Christian and Moorish army, began maneuvering in order to create his own fiefdom in the Moorish Mediterranean coastal city of Valencia. Several obstacles lay in his way. First was Berenguer Ramón II, who ruled nearby Barcelona. In May 1090, El Cid defeated and captured Berenguer in the Battle of Tébar (nowadays Pinar de Tévar, near Monroyo, Teruel). Berenguer was later released and his nephew Ramón Berenguer III married El Cid's youngest daughter Maria to ward against future conflicts.
Along the way to Valencia, El Cid also conquered other towns, many of which were near Valencia, such as El Puig and Quart de Poblet.
El Cid gradually came to have more influence on Valencia, then ruled by al-Qadir. In October 1092 an uprising occurred in Valencia inspired by the city's chief judge Ibn Jahhaf and the Almoravids. El Cid began a siege of Valencia. A December 1093 attempt to break the siege failed. By the time the siege ended in May 1094, El Cid had carved out his own principality on the coast of the Mediterranean. Officially El Cid ruled in the name of Alfonso; in reality, El Cid was fully independent. The city was both Christian and Muslim, and both Moors and Christians served in the army and as administrators.
Death.
El Cid and his wife Jimena Díaz lived peacefully in Valencia for five years until the Almoravids besieged the city. El Cid died on June 10, 1099. His death was likely a result of the famine and deprivations caused by the siege. Valencia was captured by Masdali on May 5, 1102 and it did not become a Christian city again for over 125 years. Jimena fled to Burgos, Castile, in 1101. She rode into the town with her retinue and the body of El Cid. Originally buried in Castile in the monastery of San Pedro de Cardeña, his body now lies at the center of Burgos Cathedral.
After his demise, but still during the siege of Valencia, legend holds that Jimena ordered that the corpse of El Cid be fitted with his armor and set atop his horse Babieca, to bolster the morale of his troops. In several variations of the story, the dead Rodrigo and his knights win a thundering charge against Valencia's besiegers, resulting in a war-is-lost-but-battle-is-won catharsis for generations of Christian Spaniards to follow. It is believed that the legend originated shortly after Jimena entered Burgos, and that it is derived from the manner in which Jimena's procession rode into Burgos, i.e. alongside her deceased husband.
Warrior and general.
Battle tactics.
During his campaigns, El Cid often ordered that books by classic Roman and Greek authors on military themes be read aloud to him and his troops, for both entertainment and inspiration before battle. El Cid's army had a novel approach to planning strategy as well, holding what might be called brainstorming sessions before each battle to discuss tactics. They frequently used unexpected strategies, engaging in what modern generals would call psychological warfare — waiting for the enemy to be paralyzed with terror and then attacking them suddenly; distracting the enemy with a small group of soldiers, etc. (El Cid used this distraction in capturing the town of Castejón as depicted in "Cantar de Mio Cid" ("The Song of my Cid"). El Cid accepted or included suggestions from his troops. In "The Song" the man who served him as his closest adviser was his vassal and kinsman Álvar Fáñez "Minaya" (meaning "My brother", a compound word of Spanish possessive "Mi" (My) and "Anaia", the basque word for "brother"), although the historical Álvar Fáñez remained in Castile with Alfonso VI.
Taken together, these practices imply an educated and intelligent commander who was able to attract and inspire good subordinates, and who would have attracted considerable loyalty from his followers, including those who were not Christian. It is these qualities, coupled with El Cid's legendary martial abilities, which have fueled his reputation as an outstanding battlefield commander.
Babieca.
Babieca or Bavieca was El Cid's warhorse. Several stories exist about El Cid and Babieca. One well-known legend about El Cid describes how he acquired the stallion. According to this story, Rodrigo's godfather, Pedro El Grande, was a monk at a Carthusian monastery. Pedro's coming-of-age gift to El Cid was his pick of a horse from an Andalusian herd. El Cid picked a horse that his godfather thought was a weak, poor choice, causing the monk to exclaim ""Babieca"!" (stupid!) Hence, it became the name of El Cid's horse. Another legend states that in a competition of battle to become King Sancho's "Campeador", or champion, a knight on horseback wished to challenge El Cid. The King wished a fair fight and gave El Cid his finest horse, Babieca, or Bavieca. This version says Babieca was raised in the royal stables of Seville and was a highly trained and loyal war horse, not a foolish stallion. The name in this instance could suggest that the horse came from the Babia region in León, Spain. In the poem Carmen Campidoctoris, Babieca appears as a gift from "a barbarian" to El Cid, so its name could also be derived from "Barbieca", or "horse of the barbarian".
Regardless, Babieca became a great warhorse, famous to the Christians, feared by El Cid's enemies, and loved by El Cid, who allegedly requested that Babieca be buried with him in the monastery of San Pedro de Cardeña. His name is mentioned in several tales and historical documents about El Cid, including "The Lay of El Cid".
Swords.
A weapon traditionally identified as El Cid's sword, Tizona, used to be displayed in the Army Museum (Museo del Ejército) in Toledo. In 1999, a small sample of the blade underwent metallurgical analysis which confirmed that the blade was made in Moorish Córdoba in the eleventh century and contained amounts of Damascus steel. El Cid also had a sword called Colada.
In 2007 the Autonomous Community of Castile and León bought the sword for 1.6 million Euros, and it is currently on display at the Museum of Burgos.
Marriage and family.
El Cid was married in July 1075 to Alfonso's kinswoman Jimena Díaz. The "Historia Roderici" calls her a daughter of a Count Diego of Oviedo, a person unknown to contemporary records, while later poetic sources name her father as an otherwise unknown Count Gomez de Gormaz.
Tradition states that when El Cid first laid eyes on her, he was enamored by her great beauty. Together El Cid and Jimena had two daughters and a son. Their daughters Cristina and María both married into royal families; Cristina to Ramiro, Lord of Monzón, grandson of García Sánchez III of Navarre via an illegitimate son; María, first (it is said) to a prince of Aragon (presumably the son of Peter I) and second to Ramón Berenguer III, count of Barcelona. El Cid's son Diego Rodríguez was killed while fighting against the invading Muslim Almoravids from North Africa at the Battle of Consuegra (1097).
El Cid's own marriage and those of his daughters raised his status by connecting him to the peninsular royalty; even today, most European monarchs (including the current King of Spain) and many commoners of European ancestry descend from El Cid, through Cristina's son, King García Ramírez of Navarre and to a lesser extent via Maria's daughter, Jimena of Barcelona, who married Roger III, Count of Foix.

</doc>
<doc id="10078" url="http://en.wikipedia.org/wiki?curid=10078" title="Enjambment">
Enjambment

In poetry, enjambment or enjambement (; from the French "enjambement" ]) is incomplete syntax at the end of a line; the meaning runs-over from one poetic line to the next, without terminal punctuation. Lines without enjambment are end-stopped.
In reading, the delay of meaning creates a tension that is released when the word or phrase that completes the syntax is encountered (called the rejet); the tension arises from the "mixed message" produced both by the pause of the line-end, and the suggestion to continue provided by the incomplete meaning. In spite of the apparent contradiction between rhyme, which heightens closure, and enjambment, which delays it, the technique is compatible with rhymed verse. Even in couplets, the closed or heroic couplet was a late development; older is the open couplet, where rhyme and enjambed lines co-exist.
Enjambment has a long history in poetry. Homer used the technique, and it is the norm for alliterative verse where rhyme is unknown. In the 32nd Psalm of the Hebrew Bible enjambment is unusually conspicuous. It was used extensively in England by Elizabethan poets for dramatic and narrative verse, before giving way to closed couplets. The example of John Milton in "Paradise Lost" laid the foundation for its subsequent use by the English Romantic poets; in its preface he identified it as one of the chief features of his verse: "sense variously drawn out from one verse into another".
Examples.
Meaning flows as the lines progress, and the reader's eye is forced to go on to the next sentence. It can also make the reader feel uncomfortable or the poem feel like "flow-of-thought" with a sensation of urgency or disorder. In contrast, the following lines from "Romeo and Juliet" ("c." 1595) are completely end-stopped:
Each line is formally correspondent with a unit of thought—in this case, a clause of a sentence. End-stopping is more frequent in early Shakespeare: as his style developed, the proportion of enjambment in his plays increased. Scholars such as Goswin König and A. C. Bradley have estimated approximate dates of undated works of Shakespeare by studying the frequency of enjambment.

</doc>
<doc id="10080" url="http://en.wikipedia.org/wiki?curid=10080" title="European Convention on Nationality">
European Convention on Nationality

The European Convention on Nationality (E.T.S. No. 166) was signed in Strasbourg on 6 November 1997. It is a comprehensive convention of the Council of Europe dealing with the law of nationality. The Convention is open for signature by the member States of the Council of Europe and the non-member States which have participated in its elaboration and for accession by other non-member States. The Convention came into force on 1 March 2000 after ratification by 3 countries. As at 6 March 2014, the Convention has been signed by 29 countries, but has been ratified by only 20 of those countries.
Provisions.
Article 4d provides that neither marriage nor dissolution of marriage shall automatically affect the nationality of either spouse, nor shall a change of nationality by one spouse during marriage automatically affect the nationality of their spouse. Common practice among states at the beginning of the 20th century was that a woman was to have the nationality of her husband; i.e., upon marrying a foreigner the wife would automatically acquire the nationality of her husband, and lose her previous nationality. Even after the nationality of a married woman was no longer dependent on the nationality of her husband, legal provisions were still retained which automatically naturalising married women, and sometimes married men as well. This led to a number of problems, such as loss of the spouses' original nationality, the spouse losing the right to consular assistance (since consular assistance cannot be provided to nationals under the jurisdiction of a foreign state of which they are also nationals), and becoming subject to military service obligations. Article 4d addresses this situation.
Article 5 provides that no discrimination shall exist in a state's internal nationality law on the grounds of "sex, religion, race, colour or national or ethnic origin". It also provides that a state shall not discriminate amongst its nationals on the basis of whether they hold their nationality by birth or acquired it subsequently.
Article 6 relates to the acquisition of nationality. It provides for nationality to be acquired at birth by descent from either parent to those born within the territory of the state. (States may exclude partially or fully children born abroad). It also provides for nationality by virtue of birth in the territory of state; however, states may limit this to only children who would be otherwise stateless. It requires the possibility of naturalisation, and provides that the period of residence required for eligibility cannot be more than ten years lawful and habitual residence. It also requires to "facilitate" the acquisition of nationality by certain persons, including spouses of nationals, children of its nationals born abroad, children one of whose parents has acquired the nationality, children adopted by a national, persons lawfully and habitually resident for a period before the age of eighteen, and stateless persons and refugees lawfully and habitually resident on its territory.
Article 7 regulates the involuntary loss of nationality. It provides that states may deprive their nationals of their nationality in only the cases of voluntary acquisition of another nationality, fraud or failure to provide relevant information when acquiring nationality, voluntary military service in a foreign military force, or adoption as a child by foreign nationals. It also provides for the possibility of loss of nationality for nationals habitually residing abroad. Finally it provides loss of nationality for "conduct seriously prejudicial to the vital interests of the State Party".
Article 8 provides nationals with the right to renounce their nationality, providing they do not thereby become stateless. States may however restrict this right with respect to nationals residing abroad.
Status.
As at 6 March 2014, the following countries have signed or ratified the Convention:

</doc>
<doc id="10081" url="http://en.wikipedia.org/wiki?curid=10081" title="English orthography">
English orthography

English orthography is the orthography used in writing the English language, including English spelling, hyphenation, capitalization, word breaks, emphasis, and punctuation. Like the orthographic systems of most world languages, it has a broad degree of standardization, but unlike most languages, English provides more than one way to spell nearly every phoneme, and most letters and letter-combinations can stand for different pronunciations depending on context and meaning. This is largely due to the complex history of the English language together with the absence of systematic spelling reforms. In general, modern English spelling, much of which was devised originally for the phonetic spelling of Middle English, does not reflect the sound changes that have occurred since the late fifteenth century (such as the Great Vowel Shift). There are some variations in English orthography by global regions, some of which resulted from spelling reform efforts that succeeded only partially and only in certain regions.
Function of the letters.
"Note: In the following discussion, only one or two common pronunciations of American and British English varieties are used in this article for each word cited. Other regional pronunciations may be possible for some words, but indicating all possible regional variants in the article is impractical. "
Phonemic representation.
As in most alphabetic languages, letters in English orthography may represent a particular sound. For example, the word "cat" consists of three letters ⟨c⟩, ⟨a⟩, and ⟨t⟩, in which ⟨c⟩ represents the sound /k/, ⟨a⟩ the sound /æ/, and ⟨t⟩ the sound /t/.
Multiple sequences of letters may perform this role as well as single letters. Thus, in the word "ship" (pronounced /ˈʃɪp/), the digraph ⟨sh⟩ (two letters) represents the sound /ʃ/. In the word "ditch", the three letters ⟨tch⟩ represent the sound /tʃ/.
Less commonly, a single letter can represent multiple successive sounds. The most common example is the letter ⟨x⟩ which normally represents the consonant cluster /ks/ (for example, in the word "six", pronounced /sɪks/).
The same letter (or sequence of letters) may be pronounced in different ways when it occurs in different positions within a word. For instance, the digraph ⟨gh⟩ represents the sound /f/ at the end of some words, such as "rough" /ˈrʌf/. At the beginning of syllables (i.e. the syllable onset), the digraph ⟨gh⟩ is pronounced /ɡ/, as in the word "ghost" (pronounced /ˈɡoʊst/). Conversely, the digraph ⟨gh⟩ is never pronounced /f/ in syllable onsets and is almost never pronounced /ɡ/ in syllable codas (the proper name "Pittsburgh" is an exception).
Word origin.
Another type of spelling characteristic is related to word origin. For example, when representing a vowel, the letter ⟨y⟩ represents the sound /ɪ/ in some words borrowed from Greek (reflecting an original upsilon), whereas the letter usually representing this sound in non-Greek words is the letter ⟨i⟩. Thus, the word "myth" is of Greek origin, while "pith" is a Germanic word. Other examples include ⟨ph⟩ pronounced /f/ (which is usually spelt ⟨f⟩), and ⟨ch⟩ pronounced /k/ (which is usually spelt ⟨c⟩ or ⟨k⟩) – the use of these spellings for these sounds often mark words that have been borrowed from Greek.
Some researchers, such as Brengelman (1970), have suggested that, in addition to this marking of word origin, these spellings indicate a more formal level of style or register in a given text, although Rollings (2004) finds this point to be exaggerated as there would be many exceptions where a word with one of these spellings, such as ⟨ph⟩ for /f/ (like "telephone"), could occur in an informal text.
Homophone differentiation.
Spelling may also be useful to distinguish between homophones (words with the same pronunciation but different meanings), although in most cases the reason for the difference is historical and was not introduced for the purpose of making a distinction. For example, the words "heir" and "air" are pronounced identically in most dialects (as ). However, they are distinguished from each other orthographically by the addition of the letter ⟨h⟩. Another example is the pair of homophones "plain" and "plane", where both are pronounced but have two different spellings of the vowel /eɪ/.
In written language, this may help to resolve potential ambiguities that would arise otherwise (cf. "He's breaking the car" vs. "He's braking the car"). Nevertheless, many homophones that are unresolved by spelling still exist (for example, the word "bay" has at least five fundamentally different meanings).
Marking sound changes in other letters.
Another function of some letters in English is to provide information about the pronunciation of "other" letters in the word. Rollings (2004) uses the term "markers" for letters with this function. Letters may mark different types of information. For instance the letter ⟨e⟩ in the word "cottage" indicates that the preceding ⟨g⟩ is pronounced /dʒ/, rather than the more common value of ⟨g⟩ in word-final position as the sound /ɡ/, such as in "tag" . The letter ⟨e⟩ also often marks an altered pronunciation of a preceding vowel. In the pair "ban" and "bane", the ⟨a⟩ of "ban" has the value /æ/, whereas the ⟨a⟩ of "bane" is marked by the ⟨e⟩ as having the value /eɪ/. In this context, the ⟨e⟩ is not pronounced, and is referred to as "silent e".
A single letter may even fill multiple pronunciation-marking roles simultaneously. For example, in the word "wage" the ⟨e⟩ marks not only the change of the ⟨a⟩ from /æ/ to /eɪ/, but also of the ⟨g⟩ from /ɡ/ to /dʒ/.
Multiple functionality.
A given letter or (letters) may have dual functions. For example, the letter ⟨i⟩ in the word "cinema" has a sound-representing function (representing the sound /ɪ/) and a pronunciation-marking function (marking the ⟨c⟩ as having the value /s/ opposed to the value /k/).
Underlying representation.
Like many other alphabetic orthographies, English spelling does not represent non-contrastive phonetic sounds (that is, minor differences in pronunciation which are not used to distinguish between different words). Although the letter ⟨t⟩ is pronounced by some speakers with aspiration [tʰ] at the beginning of words, this is never indicated in the spelling, and, indeed, this phonetic detail is probably not noticeable to the average native speaker not trained in phonetics. However, unlike some orthographies, English orthography often represents a very abstract underlying representation (or morphophonemic form) of English words.
 [T]he postulated underlying forms are systematically related to the conventional orthography ... and are, as is well known, related to the underlying forms of a much earlier historical stage of the language. There has, in other words, been little change in lexical representation since Middle English, and, consequently, we would expect ... that lexical representation would differ very little from dialect to dialect in Modern English ... [and] that conventional orthography is probably fairly close to optimal for all modern English dialects, as well as for the attested dialects of the past several hundred years.
In these cases, a given morpheme (i.e. a component of a word) has a fixed spelling even though it is pronounced differently in different words. An example is the past tense suffix -⟨ed⟩, which may be pronounced variously as /t/, /d/, or - in some accents - /ɨd/ (for example, "dip" /ˈdɪp/, "dipped" /ˈdɪpt/, "boom" /ˈbuːm/, "boomed" /ˈbuːmd/, "loot" /ˈluːt/, "looted" /ˈluːtɨd/). As it happens, these different pronunciations of -⟨ed⟩ can be predicted by a few phonological rules, but that is not the reason why its spelling is fixed.
Another example involves the vowel differences (with accompanying stress pattern changes) in several related words. For instance, the word "photographer" is derived from the word "photograph" by adding the derivational suffix -⟨er⟩. When this suffix is added, the vowel pronunciations change largely owing to the moveable stress:
Other examples of this type are the -⟨ity⟩ suffix (as in "agile" vs "agility", "acid" vs "acidity", "divine" vs "divinity", "sane" vs "sanity"). See also: Trisyllabic laxing.
Another such class of words includes "sign" and "bomb" with "silent" letters ⟨g⟩ and ⟨b⟩, respectively. However, in the related words "signature" and "bombard" these letters are pronounced and , respectively. Here it could be argued that the underlying representation of "sign" and "bomb" is |saɪɡn| and |bɒmb|, in which the underlying |ɡ| and |b| are only pronounced in the surface forms when followed by certain suffixes (-⟨ature⟩, -⟨ard⟩). Otherwise, the |ɡ| and |b| are not realized in the surface pronunciation (e.g. when standing alone, or when followed by suffixes like -⟨ing⟩ or -⟨er⟩). In these cases, the orthography indicates the underlying consonants that are present in certain words but are absent in other related words. Other examples include the ⟨t⟩ in "fast" and "fasten" , and the ⟨h⟩ in "heir" and "inherit" .
Another example includes words like "mean" and "meant" . Here the vowel spelling ⟨ea⟩ is pronounced differently in the two related words. Thus, again the orthography uses only a single spelling that corresponds to the single morphemic form rather than to the surface phonological form.
English orthography does not always provide an underlying representation; sometimes it provides an intermediate representation between the underlying form and the surface pronunciation. This is the case with the spelling of the regular plural morpheme, which is written as either -⟨s⟩ (as in "tick, ticks" and "mite, mites") or -⟨es⟩ (as in "box, boxes"). Here the spelling -⟨s⟩ is pronounced either /s/ or /z/ (depending on the environment, e.g. "ticks" and "pigs" ) while -⟨es⟩ is usually pronounced (e.g. "boxes" ). Thus, there are two different spellings that correspond to the single underlying representation |z| of the plural suffix and the three surface forms. The spelling indicates the insertion of /ɨ/ before the /z/ in the spelling -⟨es⟩, but does not indicate the devoiced /s/ distinctly from the unaffected /z/ in the spelling -⟨s⟩.
The abstract representation of words as indicated by the orthography can be considered advantageous since it makes etymological relationships more apparent to English readers. This makes writing English more complex, but arguably makes reading English more efficient. However, very abstract underlying representations, such as that of Chomsky & Halle (1968) or of underspecification theories, are sometimes considered too abstract to accurately reflect the communicative competence of native speakers. Followers of these arguments believe the less abstract surface forms are more "psychologically real" and thus more useful in terms of pedagogy.
Diacritics.
English has some words that can be written with accent marks. These words have mostly been imported from other languages, usually French. As imported words become increasingly naturalised, there is an increasing tendency to omit the accent marks, even in formal writing. For example, words such as "rôle" and "hôtel" were first seen with accents when they were borrowed into English, but now the accent is almost never used. The words were originally considered foreign – and some people considered that English alternatives were preferable – but today their foreign origin is largely forgotten. Words most likely to retain the accent are those atypical of English morphology and therefore still perceived as slightly foreign. For example, "café" and "pâté" both have a pronounced final "e", which would otherwise be silent under the normal English pronunciation rules. However "café" is now sometimes facetiously pronounced "caff", while in "pâté", the acute accent is helpful to distinguish it from "pate".
Further examples of words sometimes retaining diacritics when used in English are: Ångström (partly because the scientific symbol for this unit of measurement is "Å"), "appliqué", "attaché", "blasé", "bric-à-brac", "Brötchen", "cliché", "crème", "crêpe", "façade", "fiancé(e)", "flambé", "naïve", "naïveté", "né(e)", "papier-mâché", "passé", "piñata", "protégé", "résumé", "risqué", "über-", "voilà". Italics, with appropriate accents, are generally applied to foreign terms that are uncommonly used in or have not been assimilated into English: for example, "adiós, crème brûlée, pièce de résistance, raison d'être, über (Übermensch), vis-à-vis. "
It was formerly common in American English to use a diaeresis mark to indicate a hiatus: for example, "coöperate", "daïs", "reëlect". "The New Yorker" and "Technology Review" magazines still use it for this purpose, even though it is increasingly rare in modern English. Nowadays the diaeresis is normally left out ("cooperate"), or a hyphen is used ("co-operate"). It is, however, still common in loanwords such as "naïve" and "Noël".
Written accents are also used occasionally in poetry and scripts for dramatic performances to indicate that a certain normally unstressed syllable in a word should be stressed for dramatic effect, or to keep with the metre of the poetry. This use is frequently seen in archaic and pseudoarchaic writings with the "-ed" suffix, to indicate that the "e" should be fully pronounced, as with "cursèd".
Ligatures.
In certain older texts (typically British), the use of the ligatures æ and œ is common in words such as "archæology", "diarrhœa", and "encyclopædia". Such words have Latin or Greek origin. Nowadays, the ligatures have been generally replaced in British English by the separated digraph "ae" and "oe" ("encyclopaedia", "diarrhoea"); but usually "economy", "ecology, " and in American English by "e" ("encyclopedia", "diarrhea"; but usually "paean", "amoeba", "oedipal", "Caesar"). In some cases, usage may vary; for instance, both "encyclopedia" and "encyclopaedia" are current in the UK.
Phonic irregularities.
Partly because English has never had any formal regulating authority for spelling, such as the Spanish "Real Academia Española" or the French "Académie française", English spelling, compared to many other languages, is quite irregular and complex. Although French, among other languages, presents a similar degree of difficulty when "encoding" (writing), English is more difficult when "decoding" (reading), as there are clearly many more possible pronunciations of a group of letters. For example, in French the [u] sound (as in "food"), can be spelled "ou", "ous", "out", or "oux" ("ou", n"ous", t"out", ch"oux"), but the pronunciation of each of those sequences is always the same. In English, the /uː/ sound can be spelled in up to 18 different ways (see the Sound to spelling correspondences section below), including oo, u, ui, ue, o, oe, ou, ough, and ew (food, truth, fruit, blues, to, shoe, group, through, grew), but all of these have other pronunciations as well (e.g. as in flood, trust, build, bluest, go, hoe, grout, rough, sew). The Spelling-to-sound correspondences section below presents a summary of pronunciation variations. Thus, in unfamiliar words and proper nouns the pronunciation of some sequences, "ough" being the prime example, is unpredictable to even educated native English speakers.
Spelling irregularities.
Attempts to regularize or reform the spelling of English have usually met with failure. However, Noah Webster popularized more phonetic spellings in the United States; such as "flavor" for British "flavour", "fiber" for "fibre", "defense" for "defence", "analyze" for "analyse", "catalog" for "catalogue" and so forth. These spellings already existed as alternatives, but Webster’s dictionaries helped make them standard in the US. See American and British English spelling differences for details.
Besides the quirks the English spelling system has inherited from its past, there are other idiosyncrasies in spelling that make it tricky to learn. English contains, depending on dialect, 24–27 separate consonant phonemes and 14–20 vowels. However, there are only 26 letters in the modern English alphabet, so there cannot be a one-to-one correspondence between letters and sounds. Many sounds are spelled using different letters or multiple letters, and for those words whose pronunciation is predictable from the spelling, the sounds denoted by the letters depend on the surrounding letters. For example, the digraph "th" represents two different sounds (the voiced interdental fricative and the voiceless interdental fricative) (see Pronunciation of English "th"), and the voiceless alveolar sibilant can be represented by the letters "s" and "c".
It is, however, not the shortage of letters which makes English spelling irregular. Its irregularities are caused mainly by the use of many different spellings for some of its sounds, such as the sounds /uː/, /iː/ and /oʊ/ (too, true, shoe, flew, through; sleeve, leave, even, seize, siege; stole, coal, bowl, roll, old, mould), and the use of identical sequences for spelling different sounds (over, oven, move).
Furthermore, English no longer makes any attempt to anglicise the spellings of loanwords, but preserves the foreign spellings, even when they employ exotic conventions like the Polish "cz" in "Czech" (rather than "*Check") or the Norwegian "fj" in "fjord" (although "fiord" was formerly the most common spelling). In early Middle English, until roughly 1400, most imports from French were respelt according to English rules (e.g. "bataille" - "battle", "bouton" - "button", but not "double", "trouble"). Instead of loans being respelled to conform to English spelling standards, sometimes the pronunciation changes as a result of pressure from the spelling. One example of this is the word "ski", which was adopted from Norwegian in the mid-18th century, although it did not become common until 1900. It used to be pronounced /ʃiː/, which is similar to the Norwegian pronunciation, but the increasing popularity of the sport after the middle of the 20th century helped the /skiː/ pronunciation replace it. 
There was also a period when the spelling of a small number of words was altered in what is now regarded as a misguided attempt to make them conform to what were perceived to be the etymological origins of the words. For example, the letter "b" was added to "debt" (originally "dette") in an attempt to link it to the Latin "debitum", and the letter "s" in "island" is a misplaced attempt to link it to Latin "insula" instead of the Old English word "īġland", which is the true origin of the English word. The letter "p" in "ptarmigan" has no etymological justification whatsoever, only seeking to invoke Greek despite being a Gaelic word.
The spelling of English continues to evolve. Many loanwords come from languages where the pronunciation of vowels corresponds to the way they were pronounced in Old English, which is similar to the Italian or Spanish pronunciation of the vowels, and is the value the vowel symbols [a], [e], [i], [o], and [u] have in the International Phonetic Alphabet. As a result, there is a somewhat regular system of pronouncing "foreign" words in English, and some borrowed words have had their spelling changed to conform to this system. For example, "Hindu" used to be spelled "Hindoo", and the name "Maria" used to be pronounced like the name "Mariah", but was changed to conform to this system.
Commercial advertisers have also had an effect on English spelling. They introduced new or simplified spellings like "lite" instead of "light", "thru" instead of "through", "smokey" instead of "smoky" (for "smokey bacon" flavour crisps), and "rucsac" instead of "rucksack". The spellings of personal names have also been a source of spelling innovations: diminutive versions of women's names that sound the same as men's names have been spelled differently: "Nikki" and "Nicky", "Toni" and "Tony", "Jo" and "Joe".
As examples of the idiosyncratic nature of English spelling, the combination "ou" can be pronounced in at least four different ways: /ə/ in "famous", /aʊ/ in "loud", /ʊ/ in "should", /uː/ in "you"; and the vowel sound /iː/ in "me" can be spelt in at least nine different ways: "paediatric", "me", "seat", "seem", "ceiling", "people", "machine", "siege", "phoenix". (These examples assume a more-or-less standard non-regional British English accent. Other accents will vary.)
Sometimes everyday speakers of English change a counterintuitive pronunciation simply because it is counterintuitive. Changes like this are not usually seen as "standard", but can become standard if used enough. An example is the word "miniscule", which still competes with its original spelling of "minuscule", though this might also be because of analogy with the word "mini". A further example is the modern pronunciation of "tissue". 
History.
Inconsistencies and irregularities in English pronunciation and spelling have gradually increased in number throughout the history of the English language. There are a number of contributing factors. First, gradual changes in pronunciation, such as the Great Vowel Shift, account for a tremendous number of irregularities. Second, relatively recent loan words from other languages generally carry their original spellings, which are often not phonetic in English. The Romanization of languages (e.g., Chinese) using alphabets derived from the Latin alphabet has further complicated this problem, for example when pronouncing Chinese proper names (of people or places).
The regular spelling system of Old English was swept away by the Norman Conquest, and English itself was supplanted in some spheres by Norman French for three centuries, eventually emerging with its spelling much influenced by French. English had also borrowed large numbers of words from French, which naturally kept their French spellings as there was no reason or mechanism to change them. The spelling of Middle English, such as in the writings of Geoffrey Chaucer, is very irregular and inconsistent, with the same word being spelled in different ways, sometimes even in the same sentence. However, these were generally much better guides to the then pronunciation than modern English spelling is.
For example, the sound /ʌ/, normally written "u", is spelled with an "o" in "son", "love", "come", etc., due to Norman spelling conventions which prohibited writing "u" before "v", "m", "n" due to the graphical confusion that would result. ("v", "u", "n" were identically written with two minims in Norman handwriting; "w" was written as two "u" letters; "m" was written with three minims, hence "mm" looked like "vun", "nvu", "uvu", etc.) Similarly, spelling conventions also prohibited final "v". Hence the identical spellings of the three different vowel sounds in "love", "grove" and "prove" are due to ambiguity in the Middle English spelling system, not sound change.
There was also a series of linguistic sound changes towards the end of this period, including the Great Vowel Shift, which resulted in the "i" in "mine", for example, changing from a pure vowel to a diphthong. These changes for the most part did not detract from the rule-governed nature of the spelling system; but in some cases they introduced confusing inconsistencies, like the well-known example of the many pronunciations of "ough" ("rough", "through", "though", "trough", "plough", etc.). Most of these changes happened before the arrival of printing in England. However, the arrival of the printing press froze the current system, rather than providing the impetus for a realignment of spelling with pronunciation. Furthermore, it introduced further inconsistencies, partly because of the use of typesetters trained abroad, particularly in the Low Countries. For example, the "h" in "ghost" was influenced by Dutch. The addition and deletion of a silent "e" at the ends of words was also sometimes used to make the right-hand margin line up more neatly.
By the time dictionaries were introduced in the mid 17th century, the spelling system of English had started to stabilise. By the 19th century, most words had set spellings, though it took some time before they diffused throughout the English-speaking world. In The Mill on the Floss (1860), English novelist George Eliot satirized the attitude of the English rural gentry of the 1820s towards orthography:
The modern English spelling system, with its national variants, spread together with the expansion of public education later in the 19th century.
"Ough" words.
The most notorious group of letters in the English language, "ough", is commonly pronounced in at least ten different ways, six of which are illustrated in the construct, "Though the tough cough and hiccough plough him through", which is quoted by Robert A. Heinlein in "The Door into Summer" to illustrate the difficulties facing automated speech transcription and reading. "Ough"[] is in fact a word in its own right; it is an exclamation of disgust similar to "ugh".
The place name Loughborough uses two different pronunciations of "ough": the first "ough" has the sound as in "cuff" and the second rhymes with "thorough".
Spelling patterns.
Spelling-to-sound correspondences.
Vowels.
In a generative approach to English spelling, Rollings (2004) identifies twenty main orthographic vowels of stressed syllables that are grouped into four main categories: "Lax", "Tense", "Heavy", "Tense-R". (As this classification is based on orthography, not all orthographic "lax" vowels are necessarily phonologically lax.)
For instance, the letter "a" can represent the lax vowel /æ/, tense /eɪ/, heavy /ɑː/, or (often allophonically) [ɛə] before |r|. Heavy and tense-r vowels are the respective lax and tense counterparts followed by the letter "r".
Tense vowels are distinguished from lax vowels with a "silent" "e" letter that is added at the end of words. Thus, the letter "a" in "hat" is lax /æ/, but when the letter "e" is added in the word "hate" the letter "a" is tense /eɪ/. Similarly, heavy and tense-r vowels pattern together: the letters "ar" in "car" are heavy /ɑr/, the letters "ar" followed by silent "e" in the word "care" are /ɛər/. The letter "u" represents two different vowel patterns, one being /ʌ/, /juː/, /ə/, /jʊ/, the other /ʊ/, /uː/, /ʊ/. There is no distinction between heavy and tense-r vowels with the letter "o", and the letter "u" in the /ʊ-uː-ʊ/ pattern does not have a heavy vowel member.
Besides silent "e", another strategy for indicating tense and tense-r vowels, is the addition of another orthographic vowel forming a digraph. In this case, the first vowel is usually the main vowel while the second vowel is the "marking" vowel. For example, the word "man" has a lax "a" pronounced /æ/, but with the addition of "i" (as the digraph "ai") in the word "main" the "a" is marked as tense and pronounced /eɪ/. These two strategies produce words that are spelled differently but pronounced identically, as in "mane" (silent "e" strategy), "main" (digraph strategy) and "Maine" (both strategies). The use of two different strategies relates to the function of distinguishing between words that would otherwise be homonyms.
Besides the 20 basic vowel spellings, Rollings (2004) has a reduced vowel category (representing the sounds /ə, ɪ/) and a miscellaneous category (representing the sounds /ɔɪ, aʊ, aɪ, aʊ/ and /j/+V, /w/+V, V+V).
Combinations of vowel letters.
To reduce dialectal difficulties, the sound values given here correspond to the conventions at . This table includes H, W and Y when they represent vowel sounds. If no information is given, it is assumed that the vowel is in a stressed syllable.
Deriving the pronunciation of an English word from its spelling requires not only a careful knowledge of the rules given below (many of which are not explicitly known even by native speakers: speakers merely learn the spelling of a word along with its pronunciation) and their many exceptions, but also:
† In many if not most North American accents /ær/ and /ɛr/ are merged into the latter pronunciation.<br>
Consonants.
Notes:
† Nearly 80% of Americans pronounce "luxurious" with /gʒ/, while two thirds of Brits use /kʒ/. Half the American speakers pronounce "luxury" as /ˈlʌg ʒəri/, the rest says /ˈlʌk ʃəri/<br>
†† About half of both British and American speakers say /ˈɛksɪt/, the other half says /ˈɛgzɪt/.
Combinations of other consonant and vowel letters.
† Where GA distinguishes between /ɑː/ and /ɔː/ in the letter combination ong, RP only has the vowel /ɒ/
Sound-to-spelling correspondences.
The following table shows for each sound the various spelling patterns used to denote it, starting with the prototypical pattern(s) followed by others in alphabetical order. Some of these patterns are very rare or unique (such as "gh" for /p/, "ph" for /v/, "i" for /ɑː/). The symbol "…" stands for an intervening consonant.
Consonants.
In order of the IPA consonant tables
Vowels.
Sorted more or less from close to open sounds in the vowel diagram.
† Identical to previous vowel in non-rhotic dialects like RP.

</doc>
<doc id="10083" url="http://en.wikipedia.org/wiki?curid=10083" title="Æthelred the Unready">
Æthelred the Unready

Æthelred the Unready, or Æthelred II ( 968 – 23 April 1016), was King of the English (978–1013 and 1014–1016). He was the son of King Edgar and Queen Ælfthryth and was only about ten years old (no more than thirteen) when his half-brother Edward was murdered. Although Æthelred was not personally suspected of participation, the murder was committed at Corfe Castle by his attendants, making it more difficult for the new king to rally the nation against the military raids by Danes, especially as the legend of St Edward the Martyr grew.
From 991 onwards, Æthelred paid tribute, or Danegeld, to the Danish king. In 1002, Æthelred ordered a massacre of Danish settlers. In 1003, King Sweyn invaded England, and in 1013, Æthelred fled to Normandy and was replaced by Sweyn, who was also King of Denmark. Æthelred returned as king, however, after Sweyn died in 1014.
"Unready" is a mistranslation of Old English "unræd" (meaning bad-counsel)—a twist on his name "Æthelred", meaning noble-counsel. A better translation would be "ill-advised".
Name.
The story of Æthelred's notorious nickname, from Old English "Æþelræd Unræd", goes a long way toward explaining how his reputation has declined through history. His first name, composed of the elements "æðele", meaning "noble", and "ræd", meaning "counsel" or "advice", is typical of the compound names of those who belonged to the royal House of Wessex, and it characteristically alliterates with the names of his ancestors, like Æthelwulf ("noble-wolf"), Ælfred ("elf-counsel"), Edward ("rich-protection"), and Edgar ("rich-spear"). His nickname "Unræd" is usually translated into present-day English as "The Unready" (less often, though less confusingly, as "The Redeless"), though, because the present-day meaning of "unready" no longer resembles its ancient counterpart, this translation disguises the meaning of the Old English term. Bosworth-Toller's "Anglo-Saxon Dictionary" defines the noun "unræd" in various ways, though it seems always to have been used pejoratively. Generally, it means "evil counsel", "bad plan", "folly". Bosworth-Toller do not record it as describing a person directly; it most often describes decisions and deeds, and once refers to the nature of Satan's deceit (see Fall of Man). The element "ræd" in "unræd" is the element in Æthelred's name which means "counsel". Thus "Æþelræd Unræd" is a pun meaning "Noble counsel, No counsel". The nickname has alternatively been taken adjectivally as "ill-advised", "ill-prepared", "indecisive", thus "Æthelred the ill-advised".
The epithet would seem to describe the poor quality of advice which Æthelred received throughout his reign, presumably from those around him, specifically from the royal council, known as the Witan. Though the nickname does not suggest anything particularly respectable about the king himself, its invective is not actually focused on the king but on those around him, who were expected to provide the young king with "god ræd" (i.e., good counsel). Unfortunately, historians, both mediaeval and modern, have taken less of an interest in what this epithet suggests about the king's advisers, and have instead focused on the image it creates of a blundering, misfit king. Because the nickname was first recorded in the 1180s, more than 150 years after Æthelred's death, it is doubtful that it carries any implications for how the king was seen by his contemporaries or near contemporaries.
In the view of Oxford professor Chris Wickham, Æthelred was one of the most forceful kings of the tenth century, who ended the control of every one of the major magnate families over their ealdormanries in the two decades after 985, and although this was ultimately to prove to his disadvantage, it is significant that he maintained the strength to push all of them into private life in spite of the military crisis of the period.
Early life.
Sir Frank Stenton remarked that "much that has brought condemnation of historians on King Æthelred may well be due in the last resort to the circumstances under which he became king." Æthelred's father, King Edgar, had died suddenly in July 975, leaving two young sons behind. The elder, Edward (later Edward the Martyr), was probably illegitimate, and was "still a youth on the verge of manhood" in 975. The younger son was Æthelred, whose mother, Ælfthryth, Edgar had married in 964. Ælfthryth was the daughter of Ordgar, ealdorman of Devon, and widow of Æthelwold, Ealdorman of East Anglia. At the time of his father's death, Æthelred could have been no more than 10 years old. As the elder of Edgar's sons, Edward – reportedly a young man given to frequent violent outbursts – probably would have naturally succeeded to the throne of England despite his young age, had not he "offended many important persons by his intolerable violence of speech and behaviour." In any case, a number of English nobles took to opposing Edward's succession and to defending Æthelred's claim to the throne; Æthelred was, after all, the son of Edgar's last, living wife, and no rumour of illegitimacy is known to have plagued Æthelred's birth, as it might have his elder brother's. Both boys, Æthelred certainly, were too young to have played any significant part in the political manoeuvring which followed Edgar's death. It was the brothers' supporters, and not the brothers themselves, who were responsible for the turmoil which accompanied the choice of a successor to the throne. Æthelred's cause was led by his mother and included Ælfhere, Ealdorman of Mercia and Bishop Æthelwold of Winchester, while Edward's claim was supported by Dunstan, the Archbishop of Canterbury and Saint Oswald of Worcester, the Archbishop of York among other noblemen, notably Æthelwine, Ealdorman of East Anglia, and Byrhtnoth, ealdorman of Essex. In the end, Edward's supporters proved the more powerful and persuasive, and he was crowned king at Kingston upon Thames before the year was out.
Edward reigned for only three years before he was murdered by members of his brother's household. Though we know little about Edward's short reign, we do know that it was marked by political turmoil. Edgar had made extensive grants of land to monasteries which pursued the new monastic ideals of ecclesiastical reform, but these disrupted aristocratic families' traditional patronage. The end of his firm rule saw a reversal of this policy, with aristocrats recovering their lost properties or seizing new ones. This was opposed by Dunstan, but according to Cyril Hart, "The presence of supporters of church reform on both sides indicates that the conflict between them depended as much on issues of land ownership and local power as on ecclesiastical legitimacy. Adherents of both Edward and Æthelred can be seen appropriating, or recovering, monastic lands." Nevertheless, favour for Edward must have been strong among the monastic communities. When Edward was killed at Æthelred's estate at Corfe Castle in Dorset in March 978, the job of recording the event, as well as reactions to it, fell to monastic writers. Stenton offers a summary of the earliest account of Edward's murder, which comes from a work praising the life of Saint Oswald of Worcester: "On the surface his [Edward's] relations with Æthelred his half-brother and Ælfthryth his stepmother were friendly, and he was visiting them informally when he was killed. [Æthelred's] retainers came out to meet him with ostentatious signs of respect, and then, before he had dismounted, surrounded him, seized his hands, and stabbed him. ... So far as can be seen the murder was planned and carried out by Æthelred's household men in order that their young master might become king. There is nothing to support the allegation, which first appears in writing more than a century later, that Queen Ælfthryth had plotted her stepson's death. No one was punished for a part in the crime, and Æthelred, who was crowned a month after the murder, began to reign in an atmosphere of suspicion which destroyed the prestige of the crown. It was never fully restored in his lifetime." Nevertheless, at first, the outlook of the new king's officers and counsellors seems in no way to have been bleak. According to one chronicler, the coronation of Æthelred took place with much rejoicing by the councillors of the English people. Simon Keynes notes that "Byrhtferth of Ramsey states similarly that when Æthelred was consecrated king, by Archbishop Dunstan and Archbishop Oswald, 'there was great joy at his consecration’, and describes the king in this connection as 'a young man in respect of years, elegant in his manners, with an attractive face and handsome appearance'." Æthelred could not have been older than 13 years of age in this year.
During these early years, Æthelred was developing a close relationship to Æthelwold, bishop of Winchester, one who had supported his unsuccessful claim to the throne. When Æthelwold died, on 1 August 984, Æthelred deeply lamented the loss, and he wrote later in a charter from 993 that the event had deprived the country of one "whose industry and pastoral care administered not only to my interest but also to that of all inhabitants of the country."
Conflict with the Danes.
England had experienced a period of peace after the reconquest of the Danelaw in the mid-10th century by King Edgar, Æthelred's father. However, beginning in 980, when Æthelred could not have been more than 14 years old, small companies of Danish adventurers carried out a series of coast-line raids against England. Hampshire, Thanet, and Cheshire were attacked in 980, Devon and Cornwall in 981, and Dorset in 982. A period of six years then passed before, in 988, another coastal attack is recorded as having taken place to the south-west, though here a famous battle was fought between the invaders and the thegns of Devon. Stenton notes that, though this series of isolated raids had no lasting effect on England itself, "their chief historical importance is that they brought England for the first time into diplomatic contact with Normandy." During this period, the Normans, who remembered their origins as a Scandinavian people, were well-disposed to their Danish cousins who, occasionally returning from a raid on England, sought port in Normandy. This led to grave tension between the English and Norman courts, and word of their enmity eventually reached Pope John XV. The pope was disposed to dissolve their hostility towards each other, and took steps to engineer a peace between England and Normandy, which was ratified in Rouen in 991.
Battle of Maldon.
However, in August of that same year, a sizeable Danish fleet began a sustained campaign in the south-east of England. It arrived off Folkestone, in Kent, and made its way around the south-east coast and up the river Blackwater, coming eventually to its estuary and occupying Northey Island. About 2 km west of Northey lies the coastal town of Maldon, where Byrhtnoth, ealdorman of Essex, was stationed with a company of thegns. The battle that followed between English and Danes is immortalised by the Old English poem "The Battle of Maldon", which describes the doomed but heroic attempt of Byrhtnoth to defend the coast of Essex against overwhelming odds. Stenton summarises the events of the poem: "For access to the mainland they [the Danes] depended on a causeway, flooded at high tide, which led from Northey to the flats along the southern margin of the estuary. Before they [the Danes] had left their camp on the island[,] Byrhtnoth, with his retainers and a force of local militia, had taken possession of the landward end of the causeway. Refusing a demand for tribute, shouted across the water while the tide was high, Byrhtnoth drew up his men along the bank, and waited for the ebb. As the water fell the raiders began to stream out along the causeway. But three of Byrthnoth's retainers held it against them, and at last they asked to be allowed to cross unhindered and fight on equal terms on the mainland. With what even those who admired him most called 'over-courage', Byrhtnoth agreed to this; the pirates rushed through the falling tide, and battle was joined. Its issue was decided by Byrhtnoth's fall. Many even of his own men immediately took to flight and the English ranks were broken. What gives enduring interest to the battle is the superb courage with which a group of Byrhtnoth's thegns, knowing that the fight was lost, deliberately gave themselves to death in order that they might avenge their lord." This was the first of a series of crushing defeats felt by the English: beaten first by Danish raiders, and later by organised Danish armies.
England begins tributes.
In 991, Æthelred was around 24 years old. In the aftermath of Maldon, it was decided that the English should grant the tribute to the Danes that they desired, and so a "gafol" of 10,000 pounds was paid them for their peace. Yet it was presumably the Danish fleet that had beaten Byrhtnoth at Maldon that continued to ravage the English coast from 991 to 993. In 994, the Danish fleet, which had swollen in ranks since 991, turned up the Thames estuary and headed toward London. The battle fought there was inconclusive. It was about this time that Æthelred met with the leaders of the fleet, foremost among them Olaf Tryggvason, and arranged an uneasy accord. A treaty was signed between Æthelred and Olaf that provided for seemingly civilised arrangements between the then-settled Danish companies and the English government, such as regulation settlement disputes and trade. But the treaty also stipulated that the ravaging and slaughter of the previous year would be forgotten, and ended abruptly by stating that 22,000 pounds of gold and silver had been paid to the raiders as the price of peace. In 994, Olaf Tryggvason, already a baptised Christian, was confirmed as Christian in a ceremony at Andover; King Æthelred stood as his sponsor. After receiving gifts, Olaf promised "that he would never come back to England in hostility." Olaf then left England for Norway and never returned, though "other component parts of the Viking force appear to have decided to stay in England, for it is apparent from the treaty that some had chosen to enter into King Æthelred's service as mercenaries, based presumably on the Isle of Wight."
Renewed Danish raids.
In 997, Danish raids began again. According to Keynes, "there is no suggestion that this was a new fleet or army, and presumably the mercenary force created in 994 from the residue of the raiding army of 991 had turned on those whom it had been hired to protect." It harried Cornwall, Devon, western Somerset, and south Wales in 997, Dorset, Hampshire, and Sussex in 998. In 999, it raided Kent, and, in 1000, it left England for Normandy, perhaps because the English had refused in this latest wave of attacks to acquiesce to the Danish demands for "gafol" or tribute, which would come to be known as Danegeld, 'Dane-payment'. This sudden relief from attack Æthelred used to gather his thoughts, resources, and armies: the fleet's departure in 1000 "allowed Æthelred to carry out a devastation of Strathclyde, the motive for which is part of the lost history of the north."
In 1001, a Danish fleet – perhaps the same fleet from 1000 – returned and ravaged west Sussex. During its movements, the fleet regularly returned to its base in the Isle of Wight. There was later an attempted attack in the south of Devon, though the English mounted a successful defence at Exeter. Nevertheless, Æthelred must have felt at a loss, and, in the Spring of 1002, the English bought a truce for 24,000 pounds. Æthelred's frequent payments of immense Danegelds are often held up as exemplary of the incompetency of his government and his own short-sightedness. However, Keynes points out that such payments had been practice for at least a century, and had been adopted by Alfred the Great, Charles the Bald, and many others. Indeed, in some cases it "may have seemed the best available way of protecting the people against loss of life, shelter, livestock, and crops. Though undeniably burdensome, it constituted a measure for which the king could rely on widespread support."
St. Brice's Day massacre of 1002.
On 13 November 1002, Æthelred ordered the massacre of all Danish men in England on St Brice's Day. No order of this kind could be carried out in more than a third of England, where the Danes were too strong, but Gunhilde, sister of Sweyn Forkbeard, King of Denmark, was said to have been among the victims. It is likely that a wish to avenge her was a principal motive for Sweyn's invasion of western England the following year. By 1004 Sweyn was in East Anglia, where he sacked Norwich. In this year, a nobleman of East Anglia, Ulfcytel Snillingr met Sweyn in force, and made an impression on the until-then rampant Danish expedition. Though Ulfcytel was eventually defeated, outside of Thetford, he caused the Danes heavy losses and was nearly able to destroy their ships. The Danish army left England for Denmark in 1005, perhaps because of their injuries sustained in East Anglia, perhaps from the very severe famine which afflicted the continent and the British Isles in that year.
An expedition the following year was bought off in early 1007 by tribute money of 36,000 pounds, and for the next two years England was free from attack. In 1008, the government created a new fleet of warships, organised on a national scale, but this was weakened when one of its commanders took to piracy, and the king and his council decided not to risk it in a general action. In Stenton's view: "The history of England in the next generation was really determined between 1009 and 1012...the ignominious collapse of the English defence caused a loss of morale which was irreparable." The Danish army of 1009, led by Thorkell the Tall and his brother Hemming, was the most formidable force to invade England since Æthelred became king. It harried England until it was bought off by 48,000 pounds in April 1012.
Invasion of 1013.
Sweyn then launched an invasion in 1013 intending to crown himself king of England, during which he proved himself to be a general greater than any other Viking leader of his generation. By the end of 1013 English resistance had collapsed and Sweyn had conquered the country, forcing Æthelred into exile in Normandy. But the situation changed suddenly when Sweyn died on 3 February 1014. The crews of the Danish ships in the Trent that had supported Sweyn immediately swore their allegiance to Sweyn's son Cnut the Great, but leading English noblemen sent a deputation to Æthelred to negotiate his restoration to the throne. He was required to declare his loyalty to them, to bring in reforms regarding everything that they disliked and to forgive all that had been said and done against him in his previous reign. The terms of this agreement are of great constitutional interest in early English History as they are the first recorded pact between a King and his subjects and are also widely regarded as showing that many English noblemen had submitted to Sweyn simply because of their distrust of Æthelred.
Æthelred then launched an expedition against Cnut and his allies, the men of the Kingdom of Lindsey. Cnut's army had not completed its preparations and, in April 1014, he decided to withdraw from England without a fight leaving his Lindsey allies to suffer Æthelred's revenge. In August 1015, he returned to find a complex and volatile situation unfolding in England. Æthelred's son, Edmund Ironside, had revolted against his father and established himself in the Danelaw, which was angry at Cnut and Æthelred for the ravaging of Lindsey and was prepared to support Edmund in any uprising against both of them.
Death and burial.
Over the next months, Cnut conquered most of England, and Edmund had rejoined Æthelred to defend London when Æthelred died on 23 April 1016. The subsequent war between Edmund and Cnut ended in a decisive victory for Cnut at the Battle of Ashingdon on 18 October 1016. Edmund's reputation as a warrior was such that Cnut nevertheless agreed to divide England, Edmund taking Wessex and Cnut the whole of the country beyond the Thames. However, Edmund died on 30 November and Cnut became king of the whole country.
Æthelred was buried in old St Paul's Cathedral, London. The tomb and his monument were destroyed along with the cathedral in the Great Fire of London in 1666. A modern monument in the crypt lists him among the important graves lost.
Appearance and character.
"[A] youth of graceful manners, handsome countenance, and fine person..." as well as "[A] tall, handsome man, elegant in manners, beautiful in countenance, and interesting in his deportment."
Marriages and issue.
Æthelred married first Ælfgifu, daughter of Thored, earl of Northumbria, in about 985. Their known children are:
In 1002 Æthelred married Emma of Normandy, sister of Richard II, Duke of Normandy. Their children were:
All of Æthelred's sons were named after predecessors of Æthelred on the throne.
Legislation.
Æthelred's government produced extensive legislation, which he "ruthlessly enforced." Records of at least six legal codes survive from his reign, covering a range of topics. Notably, one of the members of his council (known as the "Witan") was Wulfstan II, Archbishop of York, a well-known homilist. The three latest codes from Æthelred's reign seemed to have been drafted by Wulfstan. These codes are extensively concerned with ecclesiastical affairs. They also exhibit the characteristics of Wulfstan's highly rhetorical style. Wulfstan went on to draft codes for King Cnut, and recycled there many of the laws which were used in Æthelred's codes.
Despite the failure of his government in the face of the Danish threat, Æthelred's reign was not without some important institutional achievements. The quality of the coinage, a good indicator of the prevailing economic conditions, significantly improved during his reign due to his numerous coinage reform laws.
Legacy.
Later perspectives of Æthelred have been less than flattering. Numerous legends and anecdotes have sprung up to explain his shortcomings, often elaborating abusively on his character and failures. One such anecdote is given by William of Malmesbury (lived  1080– 1143), who reports that Æthelred had defecated in the baptismal font as a child, which led St. Dunstan to prophesy that the English monarchy would be overthrown during his reign. This story is, however, a fabrication, and a similar story is told of the Byzantine Emperor Constantine Copronymus, another mediaeval monarch who was unpopular among certain of his subjects.
Efforts to rehabilitate Æthelred's reputation have gained momentum since about 1980. Chief among the rehabilitators has been Simon Keynes, who has often argued that our poor impression of Æthelred is almost entirely based upon after-the-fact accounts of, and later accretions to, the narrative of events during Æthelred's long and complex reign. Chief among the culprits is in fact one of the most important sources for the history of the period, the "Anglo-Saxon Chronicle", which, as it reports events with a retrospect of 15 years, cannot help but interpret events with the eventual English defeat a foregone conclusion. Yet, as virtually no strictly contemporary narrative account of the events of Æthelred's reign exists, historians are forced to rely on what evidence there is. Keynes and others thus draw attention to some of the inevitable snares of investigating the history of a man whom later popular opinion has utterly damned. Recent cautious assessments of Æthelred's reign have more often uncovered reasons to doubt, rather than uphold, Æthelred's later infamy. Though the failures of his government will always put Æthelred's reign in the shadow of the reigns of kings Edgar, Aethelstan, and Alfred, historians' current impression of Æthelred's personal character is certainly not as unflattering as it once was: "Æthelred's misfortune as a ruler was owed not so much to any supposed defects of his imagined character, as to a combination of circumstances which anyone would have found difficult to control."
Did Æthelred invent the jury?
Æthelred has been credited with the formation of a local investigative body made up of twelve thegns who were charged with publishing the names of any notorious or wicked men in their respective districts. Because the members of these bodies were under solemn oath to act in accordance with the law and their own good consciences, they have been seen by some legal historians as the prototype for the English "Grand Jury". Æthelred makes provision for such a body in a law code he enacted at Wantage in 997, which states:
"þæt man habbe gemot on ælcum wæpentace; & gan ut þa yldestan XII þegnas & se gerefa mid, & swerian on þam haligdome, þe heom man on hand sylle, þæt hig nellan nænne sacleasan man forsecgean ne nænne sacne forhelan. & niman þonne þa tihtbysian men, þe mid þam gerefan habbað, & heora ælc sylle VI healfmarc wedd, healf landrican & healf wæpentake."
that there shall be an assembly in every wapentake, and in that assembly shall go forth the twelve eldest thegns and the reeve along with them, and let them swear on holy relics, which shall be placed in their hands, that they will never knowingly accuse an innocent man nor conceal a guilty man. And thereafter let them seize those notorious [lit. "charge-laden"] men, who have business with the reeve, and let each of them give a security of 6 half-marks, half of which shall go to the lord of that district, and half to the wapentake.
But the wording here suggests that Æthelred was perhaps revamping or re-confirming a custom which had already existed. He may actually have been expanding an established English custom for use among the Danish citizens in the North (the Danelaw). Previously, King Edgar had legislated along similar lines in his Whitbordesstan code:
"ic wille, þæt ælc mon sy under borge ge binnan burgum ge buton burgum. & gewitnes sy geset to ælcere byrig & to ælcum hundrode. To ælcere byrig XXXVI syn gecorone to gewitnesse; to smalum burgum & to ælcum hundrode XII, buton ge ma willan. & ælc mon mid heora gewitnysse bigcge & sylle ælc þara ceapa, þe he bigcge oððe sylle aþer oððe burge oððe on wæpengetace. & heora ælc, þonne hine man ærest to gewitnysse gecysð, sylle þæne að, þæt he næfre, ne for feo ne for lufe ne for ege, ne ætsace nanes þara þinga, þe he to gewitnysse wæs, & nan oðer þingc on gewitnysse ne cyðe buton þæt an, þæt he geseah oððe gehyrde. & swa geæþdera manna syn on ælcum ceape twegen oððe þry to gewitnysse."
It is my wish that each person be in surety, both within settled areas and without. And 'witnessing' shall be established in each city and each hundred. To each city let there be 36 chosen for witnessing; to small towns and to each hundred let there be 12, unless they desire more. And everybody shall purchase and sell their goods in the presence a witness, whether he is buying or selling something, whether in a city or a wapentake. And each of them, when they first choose to become a witness, shall give an oath that he will never, neither for wealth nor love nor fear, deny any of those things which he will be a witness to, and will not, in his capacity as a witness, make known any thing except that which he saw and heard. And let there be either two or three of these sworn witnesses at every sale of goods.
The 'legend' of an Anglo-Saxon origin to the jury was first challenged seriously by Heinrich Brunner in 1872, who claimed that evidence of the jury was only seen for the first time during the reign of Henry II, some 200 years after the end of the Anglo-Saxon period, and that the practice had originated with the Franks, who in turn had influenced the Normans, who thence introduced it to England. Since Brunner's thesis, the origin of the English jury has been much disputed. Throughout the twentieth century, legal historians disagreed about whether the practice was English in origin, or was introduced, directly or indirectly, from either Scandinavia or Francia. Recently, the legal historians Patrick Wormald and Michael Macnair have reasserted arguments in favour of finding in practices current during the Anglo-Saxon period traces of the Angevin practice of conducting inquests using bodies of sworn, private witnesses. Wormald has gone as far as to present evidence suggesting that the English practice outlined in Æthelred's Wantage code is at least as old as, if not older than, 975, and ultimately traces it back to a Carolingian model (something Brinner had done). However, no scholarly consensus has yet been reached.
References.
</dl>

</doc>
<doc id="10085" url="http://en.wikipedia.org/wiki?curid=10085" title="Edward Elgar">
Edward Elgar

Sir Edward William Elgar, 1st Baronet, (2 June 1857 – 23 February 1934) was an English composer, many of whose works have entered the British and international classical concert repertoire. Among his best-known compositions are orchestral works including the "Enigma Variations", the "Pomp and Circumstance Marches", concertos for violin and cello, and two symphonies. He also composed choral works, including "The Dream of Gerontius", chamber music and songs. He was appointed Master of the King's Musick in 1924.
Although Elgar is often regarded as a typically English composer, most of his musical influences were not from England but from continental Europe. He felt himself to be an outsider, not only musically, but socially. In musical circles dominated by academics, he was a self-taught composer; in Protestant Britain, his Roman Catholicism was regarded with suspicion in some quarters; and in the class-conscious society of Victorian and Edwardian Britain, he was acutely sensitive about his humble origins even after he achieved recognition. He nevertheless married the daughter of a senior British army officer. She inspired him both musically and socially, but he struggled to achieve success until his forties, when after a series of moderately successful works his "Enigma Variations" (1899) became immediately popular in Britain and overseas. He followed the Variations with a choral work, "The Dream of Gerontius" (1900), based on a Roman Catholic text that caused some disquiet in the Anglican establishment in Britain, but it became, and has remained, a core repertory work in Britain and elsewhere. His later full-length religious choral works were well received but have not entered the regular repertory.
In his fifties, Elgar composed a symphony and a violin concerto that were immensely successful. His second symphony and his cello concerto did not gain immediate public popularity and took many years to achieve a regular place in the concert repertory of British orchestras. Elgar's music came, in his later years, to be seen as appealing chiefly to British audiences. His stock remained low for a generation after his death. It began to revive significantly in the 1960s, helped by new recordings of his works. Some of his works have, in recent years, been taken up again internationally, but the music remains more played in Britain than elsewhere.
Elgar has been described as the first composer to take the gramophone seriously. Between 1914 and 1925, he conducted a series of acoustic recordings of his works. The introduction of the microphone in 1925 made far more accurate sound reproduction possible, and Elgar made new recordings of most of his major orchestral works and excerpts from "The Dream of Gerontius".
Biography.
Early years.
Edward Elgar was born in the small village of Lower Broadheath, outside Worcester, England. His father, William Henry Elgar (1821–1906), was raised in Dover and had been apprenticed to a London music publisher. In 1841 William moved to Worcester, where he worked as a piano tuner and set up a shop selling sheet music and musical instruments. In 1848 he married Ann Greening (1822–1902), daughter of a farm worker. Edward was the fourth of their seven children. Ann Elgar had converted to Roman Catholicism shortly before Edward's birth, and he was baptised and brought up as a Roman Catholic, to the disapproval of his father. William Elgar was a violinist of professional standard and held the post of organist of St. George's Roman Catholic Church, Worcester, from 1846 to 1885. At his instigation, masses by Cherubini and Hummel were first heard at the Three Choirs Festival by the orchestra in which he played the violin. All the Elgar children received a musical upbringing. By the age of eight, Elgar was taking piano and violin lessons, and his father, who tuned the pianos at many grand houses in Worcestershire, would sometimes take him along, giving him the chance to display his skill to important local figures.
Elgar's mother was interested in the arts and encouraged his musical development. He inherited from her a discerning taste for literature and a passionate love of the countryside. His friend and biographer W. H. "Billy" Reed wrote that Elgar's early surroundings had an influence that "permeated all his work and gave to his whole life that subtle but none the less true and sturdy English quality." He began composing at an early age; for a play written and acted by the Elgar children when he was about ten, he wrote music that forty years later he rearranged with only minor changes and orchestrated as the suites titled "The Wand of Youth".
Until he was fifteen, Elgar received a general education at Littleton (now Lyttleton) House school, near Worcester. However, his only formal musical training beyond piano and violin lessons from local teachers was more advanced violin studies with Adolf Pollitzer, during brief visits to London in 1877–78. Elgar said "my first music was learnt in the Cathedral ... from books borrowed from the music library, when I was eight, nine or ten." He worked through manuals of instruction on organ playing and read every book he could find on the theory of music. He later said that he had been most helped by Hubert Parry's articles in the "Grove Dictionary of Music and Musicians". Elgar began to learn German, in the hope of going to the Leipzig Conservatory for further musical studies, but his father could not afford to send him. Years later a profile in "The Musical Times" considered that his failure to get to Leipzig was fortunate for Elgar's musical development: "Thus the budding composer escaped the dogmatism of the schools." However, it was a disappointment to Elgar that on leaving school in 1872 he went not to Leipzig but to the office of a local solicitor as a clerk. He did not find an office career congenial, and for fulfilment he turned not only to music but to literature, becoming a voracious reader. Around this time, he made his first public appearances as a violinist and organist.
After a few months, Elgar left the solicitor to embark on a musical career, giving piano and violin lessons and working occasionally in his father's shop. He was an active member of the Worcester Glee Club, along with his father, and he accompanied singers, played the violin, composed and arranged works, and conducted for the first time. Pollitzer believed that, as a violinist, Elgar had the potential to be one of the leading soloists in the country, but Elgar himself, having heard leading virtuosi at London concerts, felt his own violin playing lacked a full enough tone, and he abandoned his ambitions to be a soloist. At twenty-two he took up the post of conductor of the attendants' band at the Worcester and County Lunatic Asylum in Powick, three miles (5 km) from Worcester. The band consisted of: piccolo, flute, clarinet, two cornets, euphonium, three or four first and a similar number of second violins, occasional viola, cello, double bass and piano. Elgar coached the players and wrote and arranged their music, including quadrilles and polkas, for the unusual combination of instruments. "The Musical Times" wrote, "This practical experience proved to be of the greatest value to the young musician. ... He acquired a practical knowledge of the capabilities of these different instruments. ... He thereby got to know intimately the tone colour, the ins and outs of these and many other instruments." He held the post for five years, from 1879, travelling to Powick once a week. Another post he held in his early days was professor of the violin at the Worcester College for the Blind Sons of Gentlemen.
Although rather solitary and introspective by nature, Elgar thrived in Worcester's musical circles. He played in the violins at the Worcester and Birmingham Festivals, and one great experience was to play Dvořák's Symphony No. 6 and "Stabat Mater" under the composer's baton. Elgar regularly played the bassoon in a wind quintet, alongside his brother Frank, an oboist (and conductor who ran his own wind band). Elgar arranged numerous pieces by Mozart, Beethoven, Haydn, and others for the quintet, honing his arranging and compositional skills.
In his first trips abroad, Elgar visited Paris in 1880 and Leipzig in 1882. He heard Saint-Saëns play the organ at the Madeleine and attended concerts by first-rate orchestras. In 1882 he wrote, "I got pretty well dosed with Schumann (my ideal!), Brahms, Rubinstein & Wagner, so had no cause to complain." In Leipzig he visited a friend, Helen Weaver, who was a student at the Conservatoire. They became engaged in the summer of 1883, but for unknown reasons the engagement was broken off the next year. Elgar was greatly distressed, and some of his later cryptic dedications of romantic music may have alluded to Helen and his feelings for her. Throughout his life, Elgar was often inspired by close women friends; Helen Weaver was succeeded by Mary Lygon, Dora Penny, Julia Worthington, Alice Stuart Wortley and finally Vera Hockman, who enlivened his old age.
In 1883, while a regular member of the orchestra for W. C. Stockley's winter concert seasons in Birmingham, Elgar took part in a performance of one of his first works for full orchestra, the "Sérénade mauresque". Stockley had invited him to conduct the piece, but, as Stockley later recalled, "he declined, and, further, insisted upon playing in his place in the orchestra. The consequence was that he had to appear, fiddle in hand, to acknowledge the genuine and hearty applause of the audience." He often went to London in an attempt to get his works published, but this period in his life found him frequently despondent and low on money. He wrote to a friend in April 1884, "My prospects are about as hopeless as ever ... I am not wanting in energy I think, so sometimes I conclude that 'tis want of ability. ... I have no money – not a cent." For a number of years he was assistant to his father, William Elgar, as organist of St George's, Worcester, and succeeded him for four years from 1885. During this period he wrote his first liturgical works in the Roman Catholic tradition, beginning with his three motets Op. 2 (1887) for four-part choir ("Ave Verum Corpus", "Ave Maria" and "Ave Maris Stella"), and followed by a setting of "Ecce sacerdos magnus" for the entry of the Bishop on an official visit to St. George's in 1888, all four of which remain in the repertoire of church choirs.
Marriage.
When Elgar was twenty-nine, he took on a new pupil, Caroline Alice Roberts, daughter of the late Major-General Sir Henry Roberts, and a published author of verse and prose fiction. Eight years older than Elgar, Alice became his wife three years later. Elgar's biographer Michael Kennedy writes, "Alice's family was horrified by her intention to marry an unknown musician who worked in a shop and was a Roman Catholic. She was disinherited." They were married on 8 May 1889, at Brompton Oratory. From then until her death she acted as his business manager and social secretary, dealt with his mood swings and was a perceptive musical critic. She did her best to gain him the attention of influential society, though with limited success. In time he would learn to accept the honours given him, realising that they mattered more to her and her social class and recognising what she had given up to further his career. In her diary she wrote, "The care of a genius is enough of a life work for any woman." As an engagement present, Elgar dedicated his short violin and piano piece "Salut d'Amour" to her. With Alice's encouragement, the Elgars moved to London to be closer to the centre of British musical life, and Elgar started devoting his time to composition. Their only child, Carice Irene, was born at their home in West Kensington on 14 August 1890. Her name, revealed in Elgar's dedication of "Salut d'Amour", was a contraction of her mother's names Caroline and Alice.
Elgar took full advantage of the opportunity to hear unfamiliar music. In the days before miniature scores and recordings were available, it was not easy for young composers to get to know new music. Elgar took every chance to do so at the Crystal Palace concerts. He and Alice attended day after day, hearing music by a wide range of composers. Among these were masters of orchestration from whom he learned much, such as Berlioz and Richard Wagner. His own compositions, however, made little impact on London's musical scene. August Manns conducted Elgar's orchestral version of "Salut d'amour" and the Suite in D at the Crystal Palace, and two publishers accepted some of Elgar's violin pieces, organ voluntaries, and partsongs. Some tantalising opportunities seemed to be within reach but vanished unexpectedly. For example, an offer from the Royal Opera House, Covent Garden, to run through some of his works was withdrawn at the last second when Sir Arthur Sullivan arrived unannounced to rehearse some of his own music. Sullivan was horrified when Elgar later told him what had happened. Elgar's only important commission while in London came from his home city: the Worcester Festival Committee invited him to compose a short orchestral work for the 1890 Three Choirs Festival. The result is described by Diana McVeagh in the "Grove Dictionary of Music and Musicians", as "his first major work, the assured and uninhibited "Froissart"." Elgar conducted the first performance in Worcester in September 1890. For lack of other work, he was obliged to leave London in 1891 and return with his wife and child to Worcestershire, where he could earn a living conducting local musical ensembles and teaching. They settled in Alice's former home town, Great Malvern.
Growing reputation.
During the 1890s, Elgar gradually built up a reputation as a composer, chiefly of works for the great choral festivals of the English Midlands. "The Black Knight" (1892) and "King Olaf" (1896), both inspired by Longfellow, "The Light of Life" (1896) and "Caractacus" (1898) were all modestly successful, and he obtained a long-standing publisher in Novello and Co. Other works of this decade included the "Serenade for Strings" (1892) and "Three Bavarian Dances" (1897). Elgar was of enough consequence locally to recommend the young composer Samuel Coleridge-Taylor to the Three Choirs Festival for a concert piece, which helped establish the younger man's career. Elgar was catching the attention of prominent critics, but their reviews were polite rather than enthusiastic. Although he was in demand as a festival composer, he was only just getting by financially and felt unappreciated. In 1898, he said he was "very sick at heart over music" and hoped to find a way to succeed with a larger work. His friend August Jaeger tried to lift his spirits: "A day's attack of the blues ... will not drive away your desire, your necessity, which is to exercise those creative faculties which a kind providence has given you. Your time of universal recognition will come."
In 1899, that prediction suddenly came true. At the age of forty-two, Elgar produced the "Enigma Variations", which were premiered in London under the baton of the eminent German conductor Hans Richter. In Elgar's own words, "I have sketched a set of Variations on an original theme. The Variations have amused me because I've labelled them with the nicknames of my particular friends ... that is to say I've written the variations each one to represent the mood of the 'party' (the person) ... and have written what I think they would have written – if they were asses enough to compose". He dedicated the work "To my friends pictured within". Probably the best known variation is "Nimrod", depicting Jaeger. Purely musical considerations led Elgar to omit variations depicting Arthur Sullivan and Hubert Parry, whose styles he tried but failed to incorporate in the variations. The large-scale work was received with general acclaim for its originality, charm and craftsmanship, and it established Elgar as the pre-eminent British composer of his generation.
The work is formally titled "Variations on an Original Theme"; the word "Enigma" appears over the first six bars of music, which led to the familiar version of the title. The enigma is that, although there are fourteen variations on the "original theme", there is another overarching theme, never identified by Elgar, which he said "runs through and over the whole set" but is never heard. Later commentators have observed that although Elgar is today regarded as a characteristically English composer, his orchestral music and this work in particular share much with the Central European tradition typified at the time by the work of Richard Strauss. The "Enigma Variations" were well received in Germany and Italy, and remain to the present day a worldwide concert staple.
National and international fame.
Elgar's biographer Basil Maine commented, "When Sir Arthur Sullivan died in 1900 it became apparent to many that Elgar, although a composer of another build, was his true successor as first musician of the land." Elgar's next major work was eagerly awaited. For the Birmingham Triennial Music Festival of 1900, he set Cardinal John Henry Newman's poem "The Dream of Gerontius" for soloists, chorus and orchestra. Richter conducted the premiere, which was marred by a poorly prepared chorus, which sang badly. Elgar was deeply depressed, but the critics recognised the mastery of the piece despite the defects in performance. It was performed in Düsseldorf, Germany, in 1901 and again in 1902, conducted by Julius Buths, who also conducted the European premiere of the "Enigma Variations" in 1901. The German press was enthusiastic. "The Cologne Gazette" said, "In both parts we meet with beauties of imperishable value. ... Elgar stands on the shoulders of Berlioz, Wagner, and Liszt, from whose influences he has freed himself until he has become an important individuality. He is one of the leaders of musical art of modern times." "The Düsseldorfer Volksblatt" wrote, "A memorable and epoch-making first performance! Since the days of Liszt nothing has been produced in the way of oratorio ... which reaches the greatness and importance of this sacred cantata." Richard Strauss, then widely viewed as the leading composer of his day, was so impressed that in Elgar's presence he proposed a toast to the success of "the first English progressive musician, Meister Elgar." Performances in Vienna, Paris and New York followed, and "The Dream of Gerontius" soon became equally admired in Britain. According to Kennedy, "It is unquestionably the greatest British work in the oratorio form ... [it] opened a new chapter in the English choral tradition and liberated it from its Handelian preoccupation." Elgar, as a Roman Catholic, was much moved by Newman's poem about the death and redemption of a sinner, but some influential members of the Anglican establishment disagreed. His colleague, Charles Villiers Stanford complained that the work "stinks of incense". The Dean of Gloucester banned "Gerontius" from his cathedral in 1901, and at Worcester the following year, the Dean insisted on expurgations before allowing a performance.
Elgar is probably best known for the first of the five "Pomp and Circumstance Marches", which were composed between 1901 and 1930. It is familiar to millions of television viewers all over the world every year who watch the Last Night of the Proms, where it is traditionally performed. When the theme of the slower middle section (technically called the "trio") of the first march came into his head, he told his friend Dora Penny, "I've got a tune that will knock 'em – will knock 'em flat". When the first march was played in 1901 at a London Promenade Concert, it was conducted by Henry J. Wood, who later wrote that the audience "rose and yelled ... the one and only time in the history of the Promenade concerts that an orchestral item was accorded a double encore." To mark the coronation of Edward VII, Elgar was commissioned to set A. C. Benson's "Coronation Ode" for a gala concert at the Royal Opera House in June 1901. The approval of the king was confirmed, and Elgar began work. The contralto Clara Butt had persuaded him that the trio of the first "Pomp and Circumstance" march could have words fitted to it, and Elgar invited Benson to do so. Elgar incorporated the new vocal version into the Ode. The publishers of the score recognised the potential of the vocal piece, "Land of Hope and Glory", and asked Benson and Elgar to make a further revision for publication as a separate song. It was immensely popular and is now considered an unofficial British national anthem. In the United States, the trio, known simply as "Pomp and Circumstance" or "The Graduation March", has been adopted since 1905 for virtually all high school and university graduations.
In March 1904 a three-day festival of Elgar's works was presented at Covent Garden, an honour never before given to any English composer. "The Times" commented, "Four or five years ago if any one had predicted that the Opera-house would be full from floor to ceiling for the performance of an oratorio by an English composer he would probably have been supposed to be out of his mind." The king and queen attended the first concert, at which Richter conducted "The Dream of Gerontius", and returned the next evening for the second, the London premiere of "The Apostles" (first heard the previous year at the Birmingham Festival). The final concert of the festival, conducted by Elgar, was primarily orchestral, apart for an excerpt from "Caractacus" and the complete "Sea Pictures" (sung by Clara Butt). The orchestral items were "Froissart", the "Enigma Variations", "Cockaigne", the first two (at that time the only two) "Pomp and Circumstance" marches, and the premiere of a new orchestral work, "In the South (Alassio)", inspired by a holiday in Italy.
Elgar was knighted at Buckingham Palace on 5 July 1904. The following month, he and his family moved to Plâs Gwyn, a large house on the outskirts of Hereford, overlooking the River Wye, where they lived until 1911. Between 1902 and 1914, Elgar was, in Kennedy's words, at the zenith of popularity. He made four visits to the U.S., including one conducting tour, and earned considerable fees from the performance of his music. Between 1905 and 1908, he held the post of Peyton Professor of Music at the University of Birmingham. He had accepted the post reluctantly, feeling that a composer should not head a school of music. He was not at ease in the role, and his lectures caused controversy, with his attacks on the critics and on English music in general: "Vulgarity in the course of time may be refined. Vulgarity often goes with inventiveness ... but the commonplace mind can never be anything but commonplace. An Englishman will take you into a large room, beautifully proportioned, and will point out to you that it is white – all over white – and somebody will say, 'What exquisite taste'. You know in your own mind, in your own soul, that it is not taste at all, that it is the want of taste, that is mere evasion. English music is white, and evades everything." He regretted the controversy and was glad to hand on the post to his friend Granville Bantock in 1908. His new life as a celebrity was a mixed blessing to the highly strung Elgar, as it interrupted his privacy, and he often was in ill-health. He complained to Jaeger in 1903, "My life is one continual giving up of little things which I love." Both W. S. Gilbert and Thomas Hardy sought to collaborate with Elgar in this decade. Elgar refused, but would have collaborated with George Bernard Shaw had Shaw been willing.
Elgar's principal composition in 1905 was the "Introduction and Allegro for Strings", dedicated to Samuel Sanford, professor at Yale University. Elgar visited America in that year to conduct his music and to accept a doctorate from Yale. His next large-scale work was the sequel to "The Apostles" – the oratorio "The Kingdom" (1906). It was well received but did not catch the public imagination as "The Dream of Gerontius" had done and continued to do. Among keen Elgarians, however, "The Kingdom" was sometimes preferred to the earlier work: Elgar's friend Frank Schuster told the young Adrian Boult: "compared with "The Kingdom", "Gerontius" is the work of a raw amateur." As Elgar approached his fiftieth birthday, he began work on his first symphony, a project that had been in his mind in various forms for nearly ten years. His First Symphony (1908) was a national and international triumph. Within weeks of the premiere it was performed in New York under Walter Damrosch, Vienna under Ferdinand Löwe, St. Petersburg under Alexander Siloti, and Leipzig under Arthur Nikisch. There were performances in Rome, Chicago, Boston, Toronto and fifteen British towns and cities. In just over a year, it received a hundred performances in Britain, America and continental Europe.
The Violin Concerto (1910) was commissioned by Fritz Kreisler, one of the leading international violinists of the time. Elgar wrote it during the summer of 1910, with occasional help from W. H. Reed, the leader of the London Symphony Orchestra, who helped the composer with advice on technical points. Elgar and Reed formed a firm friendship, which lasted for the rest of Elgar's life. Reed's biography, "Elgar As I Knew Him" (1936), records many details of Elgar's methods of composition. The work was presented by the Royal Philharmonic Society, with Kreisler and the London Symphony Orchestra, conducted by the composer. Reed recalled, "the Concerto proved to be a complete triumph, the concert a brilliant and unforgettable occasion." So great was the impact of the concerto that Kreisler's rival Eugène Ysaÿe spent much time with Elgar going through the work. There was great disappointment when contractual difficulties prevented Ysaÿe from playing it in London.
The Violin Concerto was Elgar's last popular triumph. The following year he presented his Second Symphony in London, but was disappointed at its reception. Unlike the First Symphony, it ends not in a blaze of orchestral splendour but quietly and contemplatively. Reed, who played at the premiere, later wrote that Elgar was recalled to the platform several times to acknowledge the applause, "but missed that unmistakable note perceived when an audience, even an English audience, is thoroughly roused or worked up, as it was after the Violin Concerto or the First Symphony." Elgar asked Reed, "What is the matter with them, Billy? They sit there like a lot of stuffed pigs." The work was, by normal standards, a success, with twenty-seven performances within three years of its premiere, but it did not achieve the international "furore" of the First Symphony.
Last major works.
In June 1911, as part of the celebrations surrounding the coronation of King George V, Elgar was appointed to the Order of Merit, an exclusive honour limited to twenty-four holders at any time. The following year, the Elgars moved back to London, to a large house in Netherhall Gardens, Hampstead, designed by Norman Shaw. There Elgar composed his last two large-scale works of the pre-war era, the choral ode, "The Music Makers" (for the Birmingham Festival, 1912) and the symphonic study "Falstaff" (for the Leeds Festival, 1913). Both were received politely but without enthusiasm. Even the dedicatee of "Falstaff", the conductor Landon Ronald, confessed privately that he could not "make head or tail of the piece," while the musical scholar Percy Scholes wrote of "Falstaff" that it was a "great work" but, "so far as public appreciation goes, a comparative failure."
When World War I broke out, Elgar was horrified at the prospect of the carnage, but his patriotic feelings were nonetheless aroused. He composed "A Song for Soldiers", which he later withdrew. He signed up as a special constable in the local police and later joined the Hampstead Volunteer Reserve of the army. He composed patriotic works, "Carillon", a recitation for speaker and orchestra in honour of Belgium, and "Polonia", an orchestral piece in honour of Poland. "Land of Hope and Glory", already popular, became still more so, and Elgar wished in vain to have new, less nationalistic, words sung to the tune.
Elgar's other compositions during the war included incidental music for a children's play, "The Starlight Express" (1915); a ballet, "The Sanguine Fan" (1917); and "The Spirit of England" (1915–17, to poems by Laurence Binyon), three choral settings very different in character from the romantic patriotism of his earlier years. His last large-scale composition of the war years was "The Fringes of the Fleet", settings of verses by Rudyard Kipling, performed with great popular success around the country, until Kipling for unexplained reasons objected to their performance in theatres. Elgar conducted a recording of the work for the Gramophone Company.
Towards the end of the war, Elgar was in poor health. His wife thought it best for him to move to the countryside, and she rented 'Brinkwells', a house near Fittleworth in Sussex, from the painter Rex Vicat Cole. There Elgar recovered his strength and, in 1918 and 1919, he produced four large-scale works. The first three of these were chamber pieces: the Violin Sonata in E minor, the Piano Quintet in A minor, and the String Quartet in E minor. On hearing the work in progress, Alice Elgar wrote in her diary, "E. writing wonderful new music". All three works were well received. "The Times" wrote, "Elgar's sonata contains much that we have heard before in other forms, but as we do not at all want him to change and be somebody else, that is as it should be." The quartet and quintet were premiered at the Wigmore Hall on 21 May 1919. "The Manchester Guardian" wrote, "This quartet, with its tremendous climaxes, curious refinements of dance-rhythms, and its perfect symmetry, and the quintet, more lyrical and passionate, are as perfect examples of chamber music as the great oratorios were of their type."
By contrast, the remaining work, the Cello Concerto in E minor, had a disastrous premiere, at the opening concert of the London Symphony Orchestra's 1919–20 season in October 1919. Apart from the Elgar work, which the composer conducted, the rest of the programme was conducted by Albert Coates, who overran his rehearsal time at the expense of Elgar's. Lady Elgar wrote, "that brutal selfish ill-mannered bounder ... that brute Coates went on rehearsing." The critic of "The Observer", Ernest Newman, wrote, "There have been rumours about during the week of inadequate rehearsal. Whatever the explanation, the sad fact remains that never, in all probability, has so great an orchestra made so lamentable an exhibition of itself. ... The work itself is lovely stuff, very simple – that pregnant simplicity that has come upon Elgar's music in the last couple of years – but with a profound wisdom and beauty underlying its simplicity." Elgar attached no blame to his soloist, Felix Salmond, who played for him again later. In contrast with the First Symphony and its hundred performances in just over a year, the Cello Concerto did not have a second performance in London for more than a year.
Last years.
Although in the 1920s Elgar's music was no longer in fashion, his admirers continued to present his works when possible. Reed singles out a performance of the Second Symphony in March 1920 conducted by "a young man almost unknown to the public", Adrian Boult, for bringing "the grandeur and nobility of the work" to a wider public. Also in 1920, Landon Ronald presented an all-Elgar concert at the Queen's Hall. Alice Elgar wrote with enthusiasm about the reception of the symphony, but this was one of the last times she heard Elgar's music played in public. After a short illness, she died of lung cancer on 7 April 1920, at the age of seventy-two.
Elgar was devastated by the loss of his wife. With no public demand for new works, and deprived of Alice's constant support and inspiration, he allowed himself to be deflected from composition. His daughter later wrote that Elgar inherited from his father a reluctance to "settle down to work on hand but could cheerfully spend hours over some perfectly unnecessary and entirely unremunerative undertaking", a trait that became stronger after Alice's death. For much of the rest of his life, Elgar indulged himself in his several hobbies. Throughout his life he was a keen amateur chemist, sometimes using a laboratory in his back garden. He even patented the "Elgar Sulphuretted Hydrogen Apparatus" in 1908. He enjoyed football, supporting Wolverhampton Wanderers F.C., for whom he composed an anthem, "He Banged the Leather for Goal", and in his later years he frequently attended horseraces. His protégés, the conductor Malcolm Sargent and violinist Yehudi Menuhin, both recalled rehearsals with Elgar at which he swiftly satisfied himself that all was well and then went off to the races. In his younger days, Elgar had been an enthusiastic cyclist, buying Royal Sunbeam bicycles for himself and his wife in 1903 (he named his "Mr. Phoebus"). As an elderly widower, he enjoyed being driven about the countryside by his chauffeur. In November and December 1923, he took a voyage to Brazil, journeying up the Amazon to Manaus, where he was impressed by its opera house, the Teatro Amazonas. Almost nothing is recorded about Elgar's activities or the events that he encountered during the trip, which gave the novelist James Hamilton-Paterson considerable latitude when writing "Gerontius", a fictional account of the journey.
After Alice's death, Elgar sold the Hampstead house, and after living for a short time in a flat in St James's in the heart of London, he moved back to Worcestershire, to the village of Kempsey, where he lived from 1923 to 1927. He did not wholly abandon composition in these years. He made large-scale symphonic arrangements of works by Bach and Handel and wrote his "Empire March" and eight songs "Pageant of Empire" for the 1924 British Empire Exhibition. Shortly after these were published, he was appointed Master of the King's Musick on 13 May 1924, following the death of Sir Walter Parratt.
From 1926 onwards, Elgar made a series of recordings of his own works. Described by the music writer Robert Philip as "the first composer to take the gramophone seriously", he had already recorded much of his music by the early acoustic-recording process for His Master's Voice (HMV) from 1914 onwards, but the introduction of electrical microphones in 1925 transformed the gramophone from a novelty into a realistic medium for reproducing orchestral and choral music. Elgar was the first composer to take full advantage of this technological advance. Fred Gaisberg of HMV, who produced Elgar's recordings, set up a series of sessions to capture on disc the composer's interpretations of his major orchestral works, including the "Enigma Variations", "Falstaff", the first and second symphonies, and the cello and violin concertos. For most of these, the orchestra was the LSO, but the "Variations" were played by the Royal Albert Hall Orchestra. Later in the series of recordings, Elgar also conducted two newly founded orchestras, Boult's BBC Symphony Orchestra and Sir Thomas Beecham's London Philharmonic Orchestra.
Elgar's recordings were released on 78-rpm discs by both HMV and RCA Victor. After World War II, the 1932 recording of the Violin Concerto with the teenage Menuhin as soloist remained available on 78 and later on LP, but the other recordings were out of the catalogues for some years. When they were reissued by EMI on LP in the 1970s, they caused surprise to many by their fast tempi, in contrast to the slower speeds adopted by many conductors in the years since Elgar's death. The recordings were reissued on CD in the 1990s.
In November 1931, Elgar was filmed by Pathé for a newsreel depicting a recording session of "Pomp and Circumstance March No. 1" at the opening of EMI's Abbey Road Studios in London. It is believed to be the only surviving sound film of Elgar, who makes a brief remark before conducting the London Symphony Orchestra, asking the musicians to "play this tune as though you've never heard it before." A memorial plaque to Elgar at Abbey Road was unveiled on 24 June 1993.
A late piece of Elgar's, the "Nursery Suite", was an early example of a studio premiere: its first performance was in the Abbey Road studios. For this work, dedicated to the wife and daughters of the Duke of York, Elgar once again drew on his youthful sketch-books.
In his final years, Elgar experienced a musical revival. The BBC organised a festival of his works to celebrate his seventy-fifth birthday, in 1932. He flew to Paris in 1933 to conduct the Violin Concerto for Menuhin. While in France, he visited his fellow composer Frederick Delius at his house at Grez-sur-Loing. He was sought out by younger musicians such as Adrian Boult, Malcolm Sargent and John Barbirolli, who championed his music when it was out of fashion. He began work on an opera, "The Spanish Lady", and accepted a commission from the BBC to compose a Third Symphony. His final illness, however, prevented their completion. He fretted about the unfinished works. He asked Reed to ensure that nobody would "tinker" with the sketches and attempt a completion of the symphony, but at other times he said, "If I can't complete the Third Symphony, somebody will complete it – or write a better one." After Elgar's death, Percy M. Young, in cooperation with the BBC and Elgar's daughter Carice, produced a version of "The Spanish Lady", which was issued on CD. The Third Symphony sketches were elaborated by the composer Anthony Payne into a complete score in 1998.
Inoperable colorectal cancer was discovered during an operation on 8 October 1933. Elgar died on 23 February 1934 at the age of seventy-six and was buried next to his wife at St. Wulstan's Church in Little Malvern.
Music.
Influences, antecedents and early works.
Elgar was contemptuous of folk music and had little interest in or respect for the early English composers, calling William Byrd and his contemporaries "museum pieces". Of later English composers, he regarded Purcell as the greatest, and he said that he had learned much of his own technique from studying Hubert Parry's writings. The continental composers who most influenced Elgar were Handel, Dvořák and, to some degree, Brahms. In Elgar's chromaticism, the influence of Wagner is apparent, but Elgar's individual style of orchestration owes much to the clarity of nineteenth-century French composers, Berlioz, Massenet, Saint-Saëns and, particularly, Delibes, whose music Elgar played and conducted at Worcester and greatly admired.
Elgar began composing when still a child, and all his life he drew on his early sketchbooks for themes and inspiration. The habit of assembling his compositions, even large-scale ones, from scraps of themes jotted down randomly remained throughout his life. His early adult works included violin and piano pieces, music for the wind quintet in which he and his brother played between 1878–81, and music of many types for the Powick Asylum band. Diana McVeagh in "Grove's Dictionary" finds many embryonic Elgarian touches in these pieces, but few of them are regularly played, except "Salut d'Amour" and (as arranged decades later into "The Wand of Youth" Suites) some of the childhood sketches. Elgar's sole work of note during his first spell in London in 1889–91, the overture "Froissart", was a romantic-bravura piece, influenced by Mendelssohn and Wagner, but also showing further Elgarian characteristics. Orchestral works composed during the subsequent years in Worcestershire include the "Serenade for Strings" and "Three Bavarian Dances". In this period and later, Elgar wrote songs and partsongs. W. H. Reed expressed reservations about these pieces, but praised the partsong "The Snow", for female voices, and "Sea Pictures", a cycle of five songs for contralto and orchestra which remains in the repertory.
Elgar's principal large-scale early works were for chorus and orchestra for the Three Choirs and other festivals. These were "The Black Knight", "King Olaf", "The Light of Life", "The Banner of St George" and "Caractacus". He also wrote a "Te Deum" and "Benedictus" for the Hereford Festival. Of these, McVeagh comments favourably on his lavish orchestration and innovative use of leitmotifs, but less favourably on the qualities of his chosen texts and the patchiness of his inspiration. McVeagh makes the point that, because these works of the 1890s were for many years little known (and performances remain rare), the mastery of his first great success, the "Enigma Variations", appeared to be a sudden transformation from mediocrity to genius, but in fact his orchestral skills had been building up throughout the decade.
Peak creative years.
Elgar's best-known works were composed within the twenty-one years between 1899 and 1920. Most of them are orchestral. Reed wrote, "Elgar's genius rose to its greatest height in his orchestral works" and quoted the composer as saying that, even in his oratorios, the orchestral part is the most important. The "Enigma Variations" made Elgar's name nationally. The variation form was ideal for him at this stage of his career, when his comprehensive mastery of orchestration was still in contrast to his tendency to write his melodies in short, sometimes rigid, phrases. His next orchestral works, "Cockaigne (In London Town)", a concert-overture (1900–1901), the first two "Pomp and Circumstance" marches (1901), and the gentle "Dream Children" (1902), are all short: the longest of them, "Cockaigne", lasting less than fifteen minutes. "In the South (Alassio)" (1903–1904), although designated by Elgar as a concert-overture, is, according to Kennedy, really a tone poem and the longest continuous piece of purely orchestral writing Elgar had essayed. He wrote it after setting aside an early attempt to compose a symphony. The work reveals his continuing progress in writing sustained themes and orchestral lines, although some critics, including Kennedy, find that in the middle part "Elgar's inspiration burns at less than its brightest." In 1905 Elgar completed the "Introduction and Allegro for Strings". This work is based, unlike much of Elgar's earlier writing, not on a profusion of themes but on only three. Kennedy called it a "masterly composition, equalled among English works for strings only by Vaughan Williams's "Tallis Fantasia"." Nevertheless, at less than a quarter of an hour, it was not by contemporary standards a lengthy composition. Gustav Mahler's Seventh Symphony, composed at the same time, runs for well over an hour.
During the next four years, however, Elgar composed three major concert pieces, which, though shorter than comparable works by some of his European contemporaries, are among the most substantial such works by an English composer. These were his First Symphony, Violin Concerto, and Second Symphony, which all play for between forty-five minutes and an hour. McVeagh says of the symphonies that they "rank high not only in Elgar's output but in English musical history. Both are long and powerful, without published programmes, only hints and quotations to indicate some inward drama from which they derive their vitality and eloquence. Both are based on classical form but differ from it to the extent that ... they were considered prolix and slackly constructed by some critics. Certainly the invention in them is copious; each symphony would need several dozen music examples to chart its progress."
Elgar's Violin Concerto and Cello Concerto, in the view of Kennedy, "rank not only among his finest works, but among the greatest of their kind". They are, however, very different from each other. The Violin Concerto, composed in 1909 as Elgar reached the height of his popularity, and written for the instrument dearest to his heart, is lyrical throughout and rhapsodical and brilliant by turns. The Cello Concerto, composed a decade later, immediately after World War I, seems, in Kennedy's words, "to belong to another age, another world ... the simplest of all Elgar's major works ... also the least grandiloquent." Between the two concertos came Elgar's symphonic study "Falstaff", which has divided opinion even among Elgar's strongest admirers. Donald Tovey viewed it as "one of the immeasurably great things in music", with power "identical with Shakespeare's", while Kennedy criticises the work for "too frequent reliance on sequences" and an over-idealised depiction of the female characters. Reed thought that the principal themes show less distinction than some of Elgar's earlier works. Elgar himself thought "Falstaff" the highest point of his purely orchestral work.
The major works for voices and orchestra of the twenty-one years of Elgar's middle period are three large-scale works for soloists, chorus and orchestra: "The Dream of Gerontius" (1900), and the oratorios "The Apostles" (1903) and "The Kingdom" (1906); and two shorter odes, the "Coronation Ode" (1902) and "The Music Makers" (1912). The first of the odes, as a "pièce d'occasion", has rarely been revived after its initial success, with the culminating "Land of Hope and Glory". The second is, for Elgar, unusual in that it contains several quotations from his earlier works, as Richard Strauss quoted himself in "Ein Heldenleben". The choral works were all successful, although the first, "Gerontius", was and remains the best-loved and most performed. On the manuscript Elgar wrote, quoting John Ruskin, "This is the best of me; for the rest, I ate, and drank, and slept, loved and hated, like another. My life was as the vapour, and is not; but this I saw, and knew; this, if anything of mine, is worth your memory." All three of the large-scale works follow the traditional model with sections for soloists, chorus and both together. Elgar's distinctive orchestration, as well as his melodic inspiration, lifts them to a higher level than most of their British predecessors.
Elgar's other works of his middle period include incidental music for "Grania and Diarmid", a play by George Moore and W. B. Yeats (1901), and for "The Starlight Express", a play based on a story by Algernon Blackwood (1916). Of the former, Yeats called Elgar's music "wonderful in its heroic melancholy". Elgar also wrote a number of songs during his peak period, of which Reed observes, "it cannot be said that he enriched the vocal repertory to the same extent as he did that of the orchestra."
Final years and posthumous completions.
After the Cello Concerto, Elgar completed no more large-scale works. He made arrangements of works by Bach, Handel and Chopin, in distinctively Elgarian orchestration, and once again turned his youthful notebooks to use for the "Nursery Suite" (1931). His other compositions of this period have not held a place in the regular repertory. For most of the rest of the twentieth century, it was generally agreed that Elgar's creative impulse ceased after his wife's death. Anthony Payne's elaboration of the sketches for Elgar's Third Symphony led to a reconsideration of this supposition. Elgar left the opening of the symphony complete in full score, and those pages, along with others, show Elgar's orchestration changed markedly from the richness of his pre-war work. "The Gramophone" described the opening of the new work as something "thrilling ... unforgettably gaunt". Payne also subsequently produced a performing version of the sketches for a sixth "Pomp and Circumstance March", premiered at the Proms in August 2006. Elgar's sketches for a piano concerto dating from 1913 were elaborated by the composer Robert Walker and first performed in August 1997 by the pianist David Owen Norris. The realisation has since been extensively revised.
Reputation.
Views of Elgar's stature have varied in the decades since his music came to prominence at the beginning of the twentieth century. Richard Strauss, as noted, hailed Elgar as a progressive composer; even the hostile reviewer in "The Observer", unimpressed by the thematic material of the First Symphony in 1908, called the orchestration "magnificently modern". Hans Richter rated Elgar as "the greatest modern composer" in any country, and Richter's colleague Arthur Nikisch considered the First Symphony "a masterpiece of the first order" to be "justly ranked with the great symphonic models – Beethoven and Brahms." By contrast, the critic W. J. Turner, in the mid-twentieth century, wrote of Elgar's "Salvation Army symphonies," and Herbert von Karajan called the "Enigma Variations" "second-hand Brahms". Elgar's immense popularity was not long-lived. After the success of his First Symphony and Violin Concerto, his Second Symphony and Cello Concerto were politely received but without the earlier wild enthusiasm. His music was identified in the public mind with the Edwardian era, and after the First World War he no longer seemed a progressive or modern composer. In the early 1920s, even the First Symphony had only one London performance in more than three years. Henry Wood and younger conductors such as Boult, Sargent and Barbirolli championed Elgar's music, but in the recording catalogues and the concert programmes of the middle of the century his works were not well represented.
In 1924, the music scholar Edward J. Dent wrote an article for a German music journal in which he identified four features of Elgar's style that gave offence to a section of English opinion (namely, Dent indicated, the academic and snobbish section): "too emotional", "not quite free from vulgarity", "pompous", and "too deliberately noble in expression". This article was reprinted in 1930 and caused controversy. In the later years of the century there was, in Britain at least, a revival of interest in Elgar's music. The features that had offended austere taste in the inter-war years were seen from a different perspective. In 1955, the reference book "The Record Guide" wrote of the Edwardian background during the height of Elgar's career:
Boastful self-confidence, emotional vulgarity, material extravagance, a ruthless philistinism expressed in tasteless architecture and every kind of expensive yet hideous accessory: such features of a late phase of Imperial England are faithfully reflected in Elgar's larger works and are apt to prove indigestible today. But if it is difficult to overlook the bombastic, the sentimental, and the trivial elements in his music, the effort to do so should nevertheless be made, for the sake of the many inspired pages, the power and eloquence and lofty pathos, of Elgar's best work. ... Anyone who doubts the fact of Elgar's genius should take the first opportunity of hearing "The Dream of Gerontius", which remains his masterpiece, as it is his largest and perhaps most deeply felt work; the symphonic study, "Falstaff"; the Introduction and Allegro for Strings; the "Enigma Variations"; and the Violoncello Concerto.
By the 1960s, a less severe view was being taken of the Edwardian era. In 1966 the critic Frank Howes wrote that Elgar reflected the last blaze of opulence, expansiveness and full-blooded life, before World War I swept so much away. In Howes's view, there was a touch of vulgarity in both the era and Elgar's music, but "a composer is entitled to be judged by posterity for his best work. ... Elgar is historically important for giving to English music a sense of the orchestra, for expressing what it felt like to be alive in the Edwardian age, for conferring on the world at least four unqualified masterpieces, and for thereby restoring England to the comity of musical nations."
In 1967 the critic and analyst David Cox considered the question of the supposed Englishness of Elgar's music. Cox noted that Elgar disliked folk-songs and never used them in his works, opting for an idiom that was essentially German, leavened by a lightness derived from French composers including Berlioz and Gounod. How then, asked Cox, could Elgar be "the most English of composers"? Cox found the answer in Elgar's own personality, which "could use the alien idioms in such a way as to make of them a vital form of expression that was his and his alone. And the personality that comes through in the music is English." This point about Elgar's transmuting his influences had been touched on before. In 1930 "The Times" wrote, "When Elgar's first symphony came out, someone attempted to prove that its main tune on which all depends was like the Grail theme in Parsifal. ... but the attempt fell flat because everyone else, including those who disliked the tune, had instantly recognized it as typically 'Elgarian', while the Grail theme is as typically Wagnerian." As for Elgar's "Englishness", his fellow-composers recognised it: Richard Strauss and Stravinsky made particular reference to it, and Sibelius called him, "the personification of the true English character in music ... a noble personality and a born aristocrat".
Among Elgar's admirers there is disagreement about which of his works are to be regarded as masterpieces. The "Enigma Variations" are generally counted among them. "The Dream of Gerontius" has also been given high praise by Elgarians, and the Cello Concerto is similarly rated. Many rate the Violin Concerto equally highly, but some do not. Sackville-West omitted it from the list of Elgar masterpieces in "The Record Guide", and in a long analytical article in "The Musical Quarterly", Daniel Gregory Mason criticised the first movement of the concerto for a "kind of sing-songiness ... as fatal to noble rhythm in music as it is in poetry." "Falstaff" also divides opinion. It has never been a great popular favourite, and Kennedy and Reed identify shortcomings in it. In a "Musical Times" 1957 centenary symposium on Elgar led by Vaughan Williams, by contrast, several contributors share Eric Blom's view that "Falstaff" is the greatest of all Elgar's works.
The two symphonies divide opinion even more sharply. Mason rates the Second poorly for its "over-obvious rhythmic scheme", but calls the First "Elgar's masterpiece. ... It is hard to see how any candid student can deny the greatness of this symphony." However, in the 1957 centenary symposium, several leading admirers of Elgar express reservations about one or both symphonies. In the same year, Roger Fiske wrote in "The Gramophone", "For some reason few people seem to like the two Elgar symphonies equally; each has its champions and often they are more than a little bored by the rival work." The critic John Warrack wrote, "There are no sadder pages in symphonic literature than the close of the First Symphony's Adagio, as horn and trombones twice softly intone a phrase of utter grief", whereas to Michael Kennedy, the movement is notable for its lack of anguished yearning and "angst" and is marked instead by a "benevolent tranquillity."
Despite the fluctuating critical assessment of the various works over the years, Elgar's major works taken as a whole have in the twenty-first century recovered strongly from their neglect in the 1950s. "The Record Guide" in 1955 could list only one currently available recording of the First Symphony, none of the Second, one of the Violin Concerto, two of the Cello Concerto, two of the "Enigma Variations", one of "Falstaff", and none of "The Dream of Gerontius". Since then there have been multiple recordings of all the major works. More than thirty recordings have been made of the First Symphony since 1955, for example, and more than a dozen of "The Dream of Gerontius". Similarly, in the concert hall, Elgar's works, after a period of neglect, are once again frequently programmed. The Elgar Society's website, in its diary of forthcoming performances, lists performances of Elgar's works by orchestras, soloists and conductors across Europe, North America and Australia.
Honours, awards and commemorations.
Elgar was knighted in 1904, and in 1911 he was appointed a member of the Order of Merit. In 1920 he received the Cross of Commander of the Belgian Order of the Crown; in 1924 he was made Master of the King's Musick; the following year he received the Gold Medal of the Royal Philharmonic Society; and in 1928 he was appointed a Knight Commander of the Royal Victorian Order (KCVO). Between 1900 and 1931, Elgar received honorary degrees from the Universities of Cambridge, Durham, Leeds, Oxford, Yale (USA), Aberdeen, Western Pennsylvania (USA), Birmingham and London. Foreign academies of which he was made a member were Regia Accademia di Santa Cecilia, Rome; Accademia del Reale Istituto Musicale, Florence; Académie des Beaux Arts, Paris; Institut de France; and the American Academy. In 1931 he was created a Baronet, of Broadheath in the County of Worcester. In 1933 he was promoted within the Royal Victorian Order to Knight Grand Cross (GCVO). In Kennedy's words, he "shamelessly touted" for a peerage, but in vain. In "Who's Who", post World War I, he claimed to have been awarded "several Imperial Russian and German decorations (lapsed)".
The house in Lower Broadheath where Elgar was born is now the Elgar Birthplace Museum, devoted to his life and work. Elgar's daughter, Carice, helped to found the museum in 1936 and bequeathed to it much of her collection of Elgar's letters and documents on her death in 1970. Carice left Elgar manuscripts to musical colleges: "The Black Knight" to Trinity College of Music; "King Olaf" to the Royal Academy of Music; "The Music Makers" to Birmingham University; the Cello Concerto to the Royal College of Music; "The Kingdom" to the Bodleian Library; and other manuscripts to the British Museum. The Elgar Society dedicated to the composer and his works was formed in 1951. The University of Birmingham's Special Collections contain an archive of letters written by Elgar.
Elgar's statue at the end of Worcester High Street stands facing the cathedral, only yards from where his father's shop once stood. Another statue of the composer by Rose Garrard is at the top of Church Street in Malvern, overlooking the town and giving visitors an opportunity to stand next to the composer in the shadow of the Hills that he so often regarded. In September 2005, a third statue sculpted by Jemma Pearson was unveiled near Hereford Cathedral in honour of his many musical and other associations with the city. It depicts Elgar with his bicycle. From 1999 until early 2007, new Bank of England twenty pound notes featured a portrait of Elgar. The change to remove his image generated controversy, particularly because 2007 was the 150th anniversary of Elgar's birth. From 2007 the Elgar notes were phased out, ceasing to be legal tender on 30 June 2010.
There are around 65 roads in the UK named after Elgar, including six in the counties of Herefordshire and Worcestershire. Among these are eleven Elgar Avenues, including one in Malvern, and another close to the house where Elgar lived, Plâs Gwyn in Hereford. A street in North Springfield, Virginia and a major road in Box Hill, Melbourne, are also named after him. Elgar had three locomotives named in his honour (all of them renamings). The first was a "Bulldog" class locomotive of the Great Western Railway (GWR): it was built in May 1906 as no. 3704, renumbered 3414 in December 1912, named "A. H. Mills" in July 1914, renamed "Sir Edward Elgar" in August 1932, and withdrawn from service in October 1938. The second was a "Castle" class locomotive, also of the GWR: it was built in June 1946 as no. 7005 "Lamphey Castle", renamed "Sir Edward Elgar" in August 1957 and withdrawn from service in September 1964. The third was a British Rail diesel locomotive: it was built in March 1968 as no. D407, renumbered 50 007 in the mid-1970s, named "Hercules" in April 1978, and renamed "Sir Edward Elgar" in February 1984. The new nameplates were specially cast in the former GWR style. On 25 February 1984, this locomotive was officially named "Sir Edward Elgar" at Paddington station in London by Simon Rattle, then conductor of the City of Birmingham Symphony Orchestra.
Elgar's life and music have inspired works of literature including the novel "Gerontius" and several plays. "Elgar's Rondo", a 1993 stage play by David Pownall depicts the dead Jaeger offering ghostly advice on Elgar's musical development. Pownall also wrote a radio play, "Elgar's Third" (1994); another Elgar-themed radio play is Alick Rowe's "The Dorabella Variation" (2003). David Rudkin's BBC television "Play for Today" "Penda's Fen" (1974) deals with themes including sex and adolescence, spying, and snobbery, with Elgar's music, chiefly "The Dream of Gerontius", as its background. In one scene, a ghostly Elgar whispers the secret of the "Enigma" tune to the youthful central character, with an injunction not to reveal it. "Elgar on the Journey to Hanley", a novel by Keith Alldritt (1979), tells of the composer's attachment to Dora Penny, later Mrs Powell, (depicted as "Dorabella" in the "Enigma Variations"), and covers the fifteen years from their first meeting in the mid-1890s to the genesis of the Violin Concerto when, in the novel, Dora has been supplanted in Elgar's affections by Alice Stuart-Wortley.
Perhaps the best-known work depicting Elgar is Ken Russell's 1962 BBC television film "Elgar", made when the composer was still largely out of fashion. This hour-long film contradicted the view of Elgar as a jingoistic and bombastic composer, and evoked the more pastoral and melancholy side of his character and music.
Selected works.
The following have been selected as representative of Elgar's works, based on quality, significance and popularity.
Sources.
</dl>
Further reading.
</dl>

</doc>
<doc id="10086" url="http://en.wikipedia.org/wiki?curid=10086" title="European Investment Fund">
European Investment Fund

The European Investment Fund (EIF), established in 1994, is a European Union agency for the provision of finance to SMEs (small and medium-sized enterprises), headquartered in Luxembourg.
It does not lend money to SMEs directly; rather it provides finance through private banks and funds. Its main operations are in the areas of venture capital and guaranteeing loans. Its shareholders are: the European Investment Bank (62%); the European Union, represented by the European Commission (29%); and 30 privately owned EU financial institutions (9%).

</doc>
<doc id="10087" url="http://en.wikipedia.org/wiki?curid=10087" title="European Currency Unit">
European Currency Unit

The European Currency Unit (₠ or ECU, ]) was a basket of the currencies of the European Community member states, used as the unit of account of the European Community before being replaced by the euro on 1 January 1999, at parity. The ECU itself replaced the European Unit of Account, also at parity, on 13 March 1979. The European Exchange Rate Mechanism attempted to minimize fluctuations between member state currencies and the ECU. The ECU was also used in some international financial transactions, where its advantage was that securities denominated in ECUs provided investors with the opportunity for foreign diversification without reliance on the currency of a single country.
The ECU was conceived on 13 March 1979 as an internal accounting unit. It had the ISO 4217 currency code XEU.
Euro replaces ECU.
On 1 January 1999, the euro (with the code EUR and symbol €) replaced the ECU, at the value €1 = 1 ECU. Unlike the ECU, the euro is a real currency, although not all member states participate (for details on euro membership see Eurozone). Two of the countries in the ECU basket of currencies, UK and Denmark, did not join the eurozone, and a third, Greece, joined late. On the other hand, Finland and Austria joined the Eurozone from the beginning although their currencies were not part of the ECU basket (since they had joined the EU in 1995, two years after the ECU composition was "frozen")
Legal implications.
Due to the ECU being used in some international financial transactions, there was a concern that foreign courts might not recognize the euro as the legal successor to the ECU. This was unlikely to be a problem, since it is a generally accepted principle of private international law that states determine their currencies, and that therefore states would accept the European Union legislation to that effect. However, for abundant caution, several foreign jurisdictions adopted legislation to ensure a smooth transition. Of particular importance, the US states of Illinois and New York adopted legislation to ensure a large proportion of international financial contracts recognized the euro as the successor of the ECU.
Etymology.
Although the acronym ECU is formed from English words, "écu" is also the name of an ancient French coin. That was one (perhaps the main) reason that a new name was devised for its successor currency, "euro", which was felt not to favour any single language..
Symbol.
The currency's symbol, ₠ (U+20A0), comprises an interlaced C and E, which are the initial letters of the phrase 'European Community' in many European languages. However, this symbol was not widely used: few systems at the time could render it and in any case banks preferred (as with all currencies) to use the ISO code XEU.
Coins and notes.
As the ECU was only an electronic unit of account and not a full currency, it did not have any official coins or notes that could be used for everyday transactions. However, various European countries and organisations like the European Parliament made commemorative and mock-up coins and notes. A common theme on the coins was usually celebrating European unity, such as celebrating membership of the European Union.

</doc>
<doc id="10088" url="http://en.wikipedia.org/wiki?curid=10088" title="East Caribbean dollar">
East Caribbean dollar

The East Caribbean dollar (symbol: $; code: XCD) is the currency of eight of the nine members of the Organisation of Eastern Caribbean States (the one exception being the British Virgin Islands, which uses the United States dollar). It has existed since 1965, being the successor to the British West Indies dollar, and it is normally abbreviated with the dollar sign "$" or, alternatively, "EC$" to distinguish it from other dollar-denominated currencies. The EC$ is subdivided into 100 cents. It has been pegged to the United States dollar since July 7, 1976 and the exchange rate is US$1 = EC$2.70.
Circulation.
Six of the states using the EC$ are independent states: Antigua and Barbuda, Dominica, Grenada, Saint Kitts and Nevis, Saint Lucia, and Saint Vincent and the Grenadines. The other two are British overseas territories: Anguilla and Montserrat. These states are all members of the Eastern Caribbean Currency Union. The only OECS associate member not using the East Caribbean dollar as their official currency is the British Virgin Islands. The British Virgin Islands were always problematic for currency purposes due to their proximity to the Danish West Indies which became the US Virgin Islands in 1917. Officially, the British Virgin Islands used to use sterling, but in practice the situation was a lot more complicated and involved the circulation of Francs and US dollars. In 1951, the British Virgin Islands adopted the British West Indies dollar which at that time operated in conjunction with the sterling coinage, and in 1961 they changed over officially to the US dollar, no doubt due to the close proximity of the US Virgin Islands. British Guiana and Barbados had previously been members of this currency union but withdrew in 1966 and 1972 respectively. Trinidad and Tobago had been a member of the earlier British West Indies currency union, but withdrew in 1964.
The combined population of the EC$ area is about 613,000 (2014 census and estimates), which is comparable to Montenegro or the American capital city of Washington, D.C.. The combined GDP is 5.46 billion US dollars, which is comparable to Bermuda.
Queen Elizabeth II appears on the banknotes and also on the obverse of the coins. She is the head of state of all the states and territories using the EC$, except for Dominica. Dominica is nevertheless a member of the Commonwealth of Nations which recognises Queen Elizabeth II as Head of the Commonwealth.
History.
Queen Anne's proclamation of 1704 introduced the gold standard to the British West Indies, putting the West Indies about two hundred years ahead of the East Indies in this respect. Nevertheless, silver pieces of eight continued to form an important portion of the circulating coinage right up until the late 1870s. In 1822, the British government coined 1/4, 1/8, and 1/16 fractional 'Anchor dollars' for use in Mauritius and the British West Indies (but not Jamaica). A few years later copper fractional dollars were coined for Mauritius, Sierra Leone, and the British West Indies.
The first move to introduce British sterling silver coinage to the colonies came with an imperial order-in-council dated 1825. This move was inspired by a number of factors. The United Kingdom was now operating a very successful gold standard in relation to the gold sovereign that was introduced in 1816, and there was a desire to extend this system to the colonies. In addition to this, there was the fact that the supply of Spanish dollars (pieces of eight) had been cut off as a result of the revolutions in Latin America where most of the Spanish dollars were minted. The last Spanish Dollar was in fact minted at Potosi in 1825. There was now a growing desire to have a stable and steady supply of British shillings everywhere the British drum was beating. The 1825 order-in-council was largely a failure because it made sterling silver coinage legal tender at the unrealistic rating in relation to the Spanish dollar of $1 = 4 shillings and 4 pence. Interestingly it did succeed in Jamaica, Bermuda, and British Honduras because the authorities in those territories set aside the official ratings and used the more realistic rating of $1 = 4 shillings. The reality of the rating between the dollar and the pound was based on the silver content of the Spanish pieces of eight as compared to the gold content of the British gold sovereign.
A second imperial order-in-council was passed in 1838 with the correct rating of $1 = 4 shillings 2 pence. In the years following the 1838 order-in-council, the British West Indies territories began to enact local legislation for the purposes of assimilating their monies of account with the British pound sterling. Gold discoveries in Australia in 1851 drove the silver dollar out of the West Indies, but it returned again with the great depreciation in the value of silver that followed with Germany's transition to the gold standard between 1871 and 1873. In the years immediately following 1873, there was a fear that the British West Indies might return to a silver standard. As such, legislation was passed in the individual territories to demonetize the silver dollars. Even though the British coinage was also silver, it represented fractions of the gold sovereign and so its value was based on a gold standard.
During this period, and into the nineteenth century, accounts could be kept in either dollars or sterling. Jamaica, Bermuda, and the Bahamas preferred to use sterling accounts whereas British Guiana used dollar accounts. British Guiana used dollar accounts for the purpose of assisting in the transition from the Dutch guilder system of currency to the British pound sterling system. In the Eastern Caribbean territories the private sector preferred to use dollar accounts whereas the government preferred to use sterling accounts. In some of the Eastern Caribbean territories, notes were issued by various private banks, denominated in dollars equivalent to 4 shillings 2 pence. See Antigua dollar, Barbadian dollar, Dominican dollar, Grenadan dollar, Guyanese dollar, Saint Kitts dollar, Saint Lucia dollar, Saint Vincent dollar and Trinidad and Tobago dollar.
In 1946, a West Indian Currency Conference saw Barbados, British Guiana, the Leeward Islands, Trinidad and Tobago and the Windward Islands agree to establish a unified decimal currency system based on a West Indian dollar to replace the current arrangement of having three different Boards of Commissioners of Currency (for Barbados (which also served the Leeward and Windward Islands), British Guiana and Trinidad & Tobago).
In 1949, the British government formalized the dollar system of accounts in British Guiana and the Eastern Caribbean territories by introducing the British West Indies dollar (BWI$) at the already existing conversion rate of $4.80 per pound sterling (or $1 = 4 shillings 2 pence). It was one of the many experimental political and economic ventures tested by the British government to form a uniform system within their British West Indies territories. The ISO 4217 code of the currency was "XBWD". The symbol "BWI$" for frequently used and the currency was known verbally as the "Beewee" (slang for British West Indies) dollar. Shortly thereafter in the 1950, the British Caribbean Currency Board (BCCB) was set up in Trinidad with the sole right to issue notes and coins of the new unified currency and given the mandate of keeping full foreign exchange cover to ensure convertibility at $4.80 per pound sterling. In 1951, the British Virgin Islands joined the arrangement, but this led to discontent because that territory was more naturally drawn to the currency of the neighbouring US Virgin Islands. In 1961, the British Virgin Islands withdrew from the arrangement and adopted the US dollar.
Until 1955, the BWI$ existed only as banknotes in conjunction with sterling fractional coinage. Decimal coins replaced the sterling coins in 1955. These decimal coins were denominated in cents, with each cent being worth one halfpenny in sterling.
In 1958, the West Indies Federation was established and the BWI$ was its currency. However, although Jamaica (including the Cayman Islands and the Turks and Caicos Islands) was part of the West Indies Federation, it retained the Jamaican pound, despite adopting the BWI$ as legal tender from 1954. Jamaica, the Cayman Islands, and the Turks and Caicos Islands were already long established users of the sterling accounts system of pounds, shillings, and pence.
In 1964 Jamaica ended the legal tender status of the BWI$ and Trinidad and Tobago withdrew from the currency union (adopting the Trinidad and Tobago dollar) forcing the movement of the headquarters of the BCCB to Barbados and soon the "BWI$" dollar lost its regional support.
In 1965, the British West Indies dollar of the now defunct West Indies Federation was replaced at par by the East Caribbean dollar and the BCCB was replaced by the Eastern Caribbean Currency Authority or ECCA (established by the Eastern Caribbean Currency Agreement 1965). British Guiana withdrew from the currency union the following year. Grenada rejoined the common currency arrangement in 1968 having utilized the Trinidad and Tobago dollar from 1964. Barbados withdrew from the currency union in 1972, following which the ECCA headquarters were moved to St. Kitts.
Between 1965 and 1983, the Eastern Caribbean Currency Authority issued the EC$, with banknotes from 1965 and coins from 1981. The EC$ is now issued by the Eastern Caribbean Central Bank, based in the city of Basseterre, in Saint Kitts and Nevis. The bank was established by an agreement (the Eastern Caribbean Central Bank Agreement) signed at Port of Spain on July 5, 1983.
The exchange rate of $4.80 = £1 sterling (equivalent to the old $1 = 4s 2d) continued right into up until 1976 for the new Eastern Caribbean dollar.
For a wider outline of the history of currency in the region see Currencies of the British West Indies.
Coins.
Until 1981, the coins of the BWI$ circulated. In 1981, a new series of coins was introduced in denominations of 1, 2, 5, 10 and 25 cents and 1 dollar. The round, aluminium bronze dollar coin was replaced in 1989 with a decagonal, cupro-nickel type. Higher denominations exist, but these were issued only as medal-coins.
Banknotes.
In 1965, the Eastern Caribbean Currency Authority issued banknotes in denominations of 1, 5, 20 and 100 dollars, all featuring Pietro Annigoni’s 1956 portrait of Queen Elizabeth II in regalia of Order of the Garter. The first issues in the name of the Eastern Caribbean Central Bank in 1985 were of the same denominations, with the addition of 10 dollar notes. The last 1 dollar notes were issued in 1989 and 50 dollar notes were introduced in 1993. On April 1, 2008, the East Caribbean Central Bank issued a new series of banknotes like the preceding issues, but omit both the bar code and the country code letterings which form part of the serial number on current notes. In 2012, the East Caribbean Central Bank issued a series of banknotes with Braille features in an effort to provide notes which are easier for blind and visually impaired persons to use. The raised Braille characters on the upgraded notes feature a Cricket theme in the form of balls and stumps. These characters have been added to the 10-, 20-, 50-, and 100 dollar notes.

</doc>
<doc id="10090" url="http://en.wikipedia.org/wiki?curid=10090" title="Erythromycin">
Erythromycin

Erythromycin is an antibiotic useful for the treatment of a number of bacterial infections. It is in the macrolide class and has an antimicrobial spectrum similar to or slightly wider than that of penicillin, and is often prescribed for people who have an allergy to penicillins. For respiratory tract infections, it has better coverage of atypical organisms, including "Mycoplasma" and "Legionella". It was first marketed by Eli Lilly and Company, and it is today commonly known as erythromycin ethylsuccinate (EES), a commonly administered ester prodrug. It is commonly applied after delivery to the eyes of newborns to prevent neonatal conjunctivitis. It is used as an alternative treatment to treat sexually transmitted diseases.
Erythromycin improves gastric emptying and symptoms from delayed gastric emptying, yet it is used in an off-label basis. Intravenous (IV) erythromycin Is sometimes administered when IV prokinetic therapy is needed in hospitalized patients. Oral treatment with erythromycin improves gastric emptying, but has limited long-term efficacy.
In structure, this macrocyclic compound contains a 14-membered lactone ring with 10 asymmetric centers and two sugars (-cladinose and -desosamine), making it a compound very difficult to produce by synthetic methods. Erythromycin is produced from a strain of the actinomycete "Saccharopolyspora erythraea".
It is on the World Health Organization's List of Essential Medicines, a list of the most important medications needed in a basic health system.
History.
Dr. Abelardo B. Aguilar, a Filipino scientist, sent some soil samples to his employer Eli Lilly in 1949. Eli Lilly’s research team, led by J. M. McGuire, managed to isolate erythromycin from the metabolic products of a strain of "Streptomyces erythreus" (designation changed to "Saccharopolyspora erythraea") found in the samples.
Lilly filed for patent protection of the compound and U.S. patent 2,653,899 was granted in 1953. The product was launched commercially in 1952 under the brand name Ilosone (after the Philippine region of Iloilo where it was originally collected). Erythromycin was formerly also called Ilotycin.
In 1981, Nobel laureate (1965 in chemistry) and professor of chemistry at Harvard University (Cambridge, MA) Robert B. Woodward (posthumously), along with a large number of members from his research group, reported the first stereocontrolled asymmetric chemical synthesis of erythromycin A.
The antibiotic clarithromycin was invented by scientists at the Japanese drug company Taisho Pharmaceutical in the 1970s as a result of their efforts to overcome the acid instability of erythromycin.
Scientists at Chugai Pharmaceuticals discovered an erythromycin-derived motilin agonist called mitemcinal that is believed to have strong prokinetic properties (similar to erythromycin) but lacking antibiotic properties. Erythromycin is commonly used off-label for gastric motility indications such as gastroparesis. If mitemcinal can be shown to be an effective a prokinetic agent, it would represent a significant advance in the gastrointestinal field, as treatment with this drug would not carry the risk of unintentional selection for antibiotic-resistant bacteria.
Adverse effects.
Gastrointestinal disturbances, such as diarrhea, nausea, abdominal pain, and vomiting, are very common because erythromycin is a motilin agonist. Because of this, erythromycin tends not to be prescribed as a first-line drug. However, it may be useful in treating gastroparesis due to this promotility effect. Intravenous erythromycin may also be used in endoscopy as an adjunct to clear gastric contents.
More serious side effects include arrhythmia with prolonged QT intervals including "torsades de pointes", and reversible deafness. Allergic reactions range from urticaria to anaphylaxis. Cholestasis, Stevens–Johnson syndrome, and toxic epidermal necrolysis are some other rare side effects that may occur.
Studies have shown evidence both for and against the association of pyloric stenosis and exposure to erythromycin prenatally and postnatally. Exposure to erythromycin (especially long courses at antimicrobial doses, and also through breastfeeding) has been linked to an increased probability of pyloric stenosis in young infants. Erythromycin used for feeding intolerance in young infants has not been associated with hypertrophic pyloric stenosis.
Erythromycin estolate has been associated with reversible hepatotoxicity in pregnant women in the form of elevated serum glutamic-oxaloacetic transaminase and is not recommended during pregnancy. Some evidence suggests similar hepatotoxicity in other populations.
It can also affect the central nervous system, causing psychotic reactions, nightmares and night sweats.
It may also alter the effectiveness of combined oral contraceptive pills because of its effect on the gut flora. Erythromycin is an inhibitor of the cytochrome P450 system, which means it can have a rapid effect on levels of other drugs metabolised by this system, e.g., warfarin.
Synthesis.
Over the three decades after the discovery of erythromycin A and its activity as an antimicrobial, many attempts were made to synthesize it in the laboratory. However, the presence of 10 stereospecific carbons and several points of distinct substitution has made the total synthesis of erythromycin A a formidable task. Complete syntheses of erythromycins’ related structures and precursors such as 6-deoxyerythronolide B have been accomplished, giving way to possible syntheses of different erythromycins and other macrolide antimicrobials. However, Woodward did successfully complete the synthesis of erythromycin A. This total synthesis begins with (7) and (8). After being coupled, the resulting structure is subjected to a series of reactions, including hydrolysis and stereospecific aldolization. The resulting pure enone is then converted to the desired (9) through a series of reduction and oxidation reactions. The dithiadecalin product (9) is then converted to both a ketone (10) and an aldehyde (11).
Available forms.
Erythromycin is available in enteric-coated tablets, slow-release capsules, oral suspensions, ophthalmic solutions, ointments, gels, Enteric-coated Capsules Non Enteric-coated tablets Non Enteric-coated capsules and injections.
The following erythromycin combinations are available for oral dosage:
For injection the available combinations are:
Brand names include Robimycin, E-Mycin, E.E.S. Granules, E.E.S.-200, E.E.S.-400, E.E.S.-400 Filmtab, Erymax, Ery-Tab, Eryc, Ranbaxy, Erypar, EryPed, Eryped 200, Eryped 400, Erythrocin Stearate Filmtab, Erythrocot, E-Base, Erythroped, Ilosone, MY-E, Pediamycin, Zineryt, Abboticin, Abboticin-ES, Erycin, PCE Dispertab, Stiemycine, Acnasol, and Tiloryth.
Composition.
Standard-grade erythromycin is primarily composed of four related compounds known as erythromycins A, B, C, and D. Each of these compounds can be present in varying amounts and can differ by lot. Erythromycin A has been found to have the most antibacterial activity, followed by erythromycin B. Erythromycins C and D are about half as active as erythromycin A. Some of these related compounds have been purified and can be studied and researched individually.
Spectrum of susceptibility.
Erythromycin can be used to treat bacteria responsible for causing infections of the skin and upper respiratory tract, including "Streptococcus", "Staphylococcus", and "Haemophilus" genera. The following represents MIC susceptibility data for a few medically significant bacteria:
Mechanism of action.
Erythromycin displays bacteriostatic activity or inhibits growth of bacteria, especially at higher concentrations, but the mechanism is not fully understood. By binding to the 50s subunit of the bacterial 70s rRNA complex, protein synthesis and subsequent structure and function processes critical for life or replication are inhibited. Erythromycin interferes with aminoacyl translocation, preventing the transfer of the tRNA bound at the A site of the rRNA complex to the P site of the rRNA complex. Without this translocation, the A site remains occupied, thus the addition of an incoming tRNA and its attached amino acid to the nascent polypeptide chain is inhibited. This interferes with the production of functionally useful proteins, which is the basis of this antimicrobial action.
Pharmacokinetics.
Erythromycin is easily inactivated by gastric acid; therefore, all orally administered formulations are given as either enteric-coated or more-stable salts or esters, such as erythromycin ethylsuccinate. Erythromycin is very rapidly absorbed, and diffuses into most tissues and phagocytes. Due to the high concentration in phagocytes, erythromycin is actively transported to the site of infection, where, during active phagocytosis, large concentrations of erythromycin are released.
Metabolism.
Most of erythromycin is metabolised by demethylation in the liver by the hepatic enzyme CYP3A4. Its main elimination route is in the bile with little renal excretion, 2%-15% unchanged drug. Erythromycin's elimination half-life ranges between 1.5 and 2.0 hours and is between 5 and 6 hours in patients with end-stage renal disease. Erythromycin levels peak in the serum 4 hours after dosing; ethylsuccinate peaks 0.5-2.5 hours after dosing, but can be delayed if digested with food.
Erythromycin crosses the placenta and enters breast milk. The American Association of Pediatrics determined erythromycin is safe to take while breastfeeding. Absorption in pregnant patients has been shown to be variable, frequently resulting in levels lower than in nonpregnant patients.
Interactions.
Erythromycin is metabolized by enzymes of the cytochrome P450 system, in particular, by isozymes of the CYP3A superfamily, CYP3A. The activity of the CYP3A enzymes can be induced or inhibited by certain drugs (e.g. dexamethasone) which can cause it to affect the metabolism of many different drugs, e.g. erythromycin. If other CYP3A substrates — drugs that are broken down by CYP3A — such as simvastatin (Zocor), lovastatin (Mevacor), or atorvastatin (Lipitor)—are taken concomitantly with erythromycin, levels of the substrates increase, often causing adverse effects. A noted drug interaction involves erythromycin and simvastatin, resulting in increased simvastatin levels and the potential for rhabdomyolysis. Another group of CYP3A4 substrates are drugs used for migraine such as ergotamine and dihydroergotamine; their adverse effects may be more pronounced if erythromycin is associated.
Earlier case reports on sudden death prompted a study on a large cohort that confirmed a link between erythromycin, ventricular tachycardia, and sudden cardiac death in patients also taking drugs that prolong the metabolism of erythromycin (like verapamil or diltiazem) by interfering with CYP3A4. Hence, erythromycin should not be administered to people using these drugs, or drugs that also prolong the QT interval. Other examples include terfenadine (Seldane, Seldane-D), astemizole (Hismanal), cisapride (Propulsid, withdrawn in many countries for prolonging the QT time) and pimozide (Orap). Theophylline, which is used mostly in asthma, is also contraindicated.
Erythromycin may affect neuromuscular transmission by acting presynaptically, so may produce or worsen symptoms of myasthenia gravis in patients with pre-existing postsynaptic defects. Exacerbations of myasthenia gravis have also been reported with the use of telithromycin and azithromycin.
Erythromycin is not recommended when using clindamycin-containing products, even topical products such as Duac or BenzaClin. In general, the simultaneous use of two different erythromycin derivatives (such as clindamycin and Mitemcinal) should be avoided as drugs in this macrolide family possess a common mechanism of action.
Erythromycin and Doxycycline can have a synergistic effect when combined and kill bacteria ("E. coli)" with a higher potency than the sum of the two drugs together. However, this synergistic relationship is only temporary. After approximately 72 hours, the relationship shifts to become antagonistic, whereby a 50/50 combination of the two drugs kills less bacteria than if the two drugs were administered separately. 

</doc>
<doc id="10091" url="http://en.wikipedia.org/wiki?curid=10091" title="Environmental law">
Environmental law

Environmental law - or "environmental and natural resources law" - is a collective term describing the network of treaties, statutes, regulations, and common and customary laws addressing the effects of human activity on the natural environment.
Regulatory subjects.
The broad category of "environmental law" may be broken down into a number of more specific regulatory subjects. While there is no single agreed-upon taxonomy, the core environmental law regimes address environmental pollution. A related but distinct set of regulatory regimes, now strongly influenced by environmental legal principles, focus on the management of specific natural resources, such as forests, minerals, or fisheries. Other areas, such as environmental impact assessment, may not fit neatly into either category, but are nonetheless important components of environmental law.
Impact assessment.
Environmental impact assessment 
Air quality.
Air quality laws 
AirLex is a website that provides a worldwide database of air quality policies and legislation. The air quality standards for each country are displayed by pollutant through a world map representation. The AirLex also provides the tools to establish comparisons between the legislation of different countries. This tool aims to provide updated information regarding worldwide air quality regulations. 
Water quality.
Water quality laws 
Waste management.
Waste management laws 
Contaminant cleanup.
Environmental cleanup laws 
Chemical safety.
Chemical safety laws govern the use of chemicals in human activities, particularly man-made chemicals in modern industrial applications. As contrasted with media-oriented environmental laws (e.g., air or water quality laws), chemical control laws seek to manage the (potential) pollutants themselves. Regulatory efforts include banning specific chemical constituents in consumer products (e.g., Bisphenol A in plastic bottles), and regulating pesticides.
Water resources.
Water resources laws govern the ownership and use of water resources, including surface water and ground water. Regulatory areas may include water conservation, use restrictions, and ownership regimes.
Mineral resources.
Mineral resource laws cover 
Wildlife and plants.
Wildlife laws govern the potential impact of human activity on wild animals, whether directly on individuals or populations, or indirectly via habitat degradation. Similar laws may operate to protect plant species. Such laws may be enacted entirely to protect biodiversity, or as a means for protecting species deemed important for other reasons. Regulatory efforts may including the creation of special conservation statuses, prohibitions on killing, harming, or disturbing protected species, efforts to induce and support species recovery, establishment of wildlife refuges to support conservation, and prohibitions on trafficking in species or animal parts to combat poaching.
Fish and game.
Fish and game laws regulate the right to pursue and take or kill certain kinds of fish and wild animal (game). Such laws may restrict the days to harvest fish or game, the number of animals caught per person, the species harvested, or the weapons or fishing gear used. Such laws may seek to balance dueling needs for preservation and harvest and to manage both environment and populations of fish and game. Game laws can provide a legal structure to collect license fees and other money which is used to fund conservation efforts as well as to obtain harvest information used in wildlife management practice.
Important principles.
Environmental law has developed in response to emerging awareness of and concern over issues impacting the entire world. While laws have developed piecemeal and for a variety of reasons, some effort has gone into identifying key concepts and guiding principles common to environmental law as a whole. The principles discussed below are not an exhaustive list and are not universally recognized or accepted. Nonetheless, they represent important principles for the understanding of environmental law around the world.
Sustainable Development.
Defined by the United Nations Environment Programme as "development that meets the needs of the present without compromising the ability of future generations to meet their own needs," sustainable development may be considered together with the concepts of "integration" (development cannot be considered in isolation from sustainability) and "interdependence" (social and economic development, and environmental protection, are interdependent). Laws mandating environmental impact assessment and requiring or encouraging development to minimize environmental impacts may be assessed against this principle.
The modern concept of sustainable development was a topic of discussion at the 1972 United Nations Conference on the Human Environment (Stockholm Conference), and the driving force behind the 1983 World Commission on Environment and Development (WCED, or Bruntland Commission). In 1992, the first UN Earth Summit resulted in the Rio Declaration, Principle 3 of which reads: "The right to development must be fulfilled so as to equitably meet developmental and environmental needs of present and future generations." Sustainable development has been a core concept of international environmental discussion ever since, including at the World Summit on Sustainable Development (Earth Summit 2002), and the United Nations Conference on Sustainable Development (Earth Summit 2012, or Rio+20).
Equity.
Defined by UNEP to include intergenerational equity - "the right of future generations to enjoy a fair level of the common patrimony" - and intragenerational equity - "the right of all people within the current generation to fair access to the current generation's entitlement to the Earth's natural resources" - environmental equity considers the present generation under an obligation to account for long-term impacts of activities, and to act to sustain the global environment and resource base for future generations. Pollution control and resource management laws may be assessed against this principle.
Transboundary responsibility.
Defined in the international law context as an obligation to protect one's own environment, and to prevent damage to neighboring environments, UNEP considers transboundary responsibility at the international level as a potential limitation on the rights of the sovereign state. Laws that act to limit externalities imposed upon human health and the environment may be assessed against this principle.
Public participation and transparency.
Identified as essential conditions for "accountable governments . . ., industrial concerns," and organizations generally, public participation and transparency are presented by UNEP as requiring "effective protection of the human right to hold and express opinions and to seek, receive and impart ideas," "a right of access to appropriate, comprehensible and timely information held by governments and industrial concerns on economic and social policies regarding the sustainable use of natural resources and the protection of the environment, without imposing undue financial burdens upon the applicants and with adequate protection of privacy and business confidentiality," and "effective judicial and administrative proceedings." These principles are present in environmental impact assessment, laws requiring publication and access to relevant environmental data, and administrative procedure.
Precautionary principle.
One of the most commonly encountered and controversial principles of environmental law, the Rio Declaration formulated the precautionary principle as follows:
The principle may play a role in any debate over the need for environmental regulation.
Polluter pays principle.
The polluter pays principle stands for the idea that "the environmental costs of economic activities, including the cost of preventing potential harm, should be internalized rather than imposed upon society at large." All issues related to responsibility for cost for environmental remediation and compliance with pollution control regulations involve this principle.
History.
Early examples of legal enactments designed to consciously preserve the environment, for its own sake or human enjoyment, are found throughout history. In the common law, the primary protection was found in the law of nuisance, but this only allowed for private actions for damages or injunctions if there was harm to land. Thus smells emanating from pig stys, strict liability against dumping rubbish, or damage from exploding dams. Private enforcement, however, was limited and found to be woefully inadequate to deal with major environmental threats, particularly threats to common resources. During the "Great Stink" of 1858, the dumping of sewerage into the River Thames began to smell so ghastly in the summer heat that Parliament had to be evacuated. Ironically, the Metropolitan Commission of Sewers Act 1848 had allowed the Metropolitan Commission for Sewers to close cesspits around the city in an attempt to "clean up" but this simply led people to pollute the river. In 19 days, Parliament passed a further Act to build the London sewerage system. London also suffered from terrible air pollution, and this culminated in the "Great Smog" of 1952, which in turn triggered its on legislative response: the Clean Air Act 1956. The basic regulatory structure was to set limits on emissions for households and business (particularly burning coal) while an inspectorate would enforce compliance. 
Notwithstanding early analogues, the concept of "environmental law" as a separate and distinct body of law is a twentieth-century development. The recognition that the natural environment was fragile and in need of special legal protections, the translation of that recognition into legal structures, the development of those structures into a larger body of "environmental law," and the strong influence of environmental law on natural resource laws, did not occur until about the 1960s. At that time, numerous influences - including a growing awareness of the unity and fragility of the biosphere; increased public concern over the impact of industrial activity on natural resources and human health; the increasing strength of the regulatory state; and more broadly the advent and success of environmentalism as a political movement - coalesced to produce a huge new body of law in a relatively short period of time. While the modern history of environmental law is one of continuing controversy, by the end of the twentieth century environmental law had been established as a component of the legal landscape in all developed nations of the world, many developing ones, and the larger project of international law.
Controversy.
Environmental law is a continuing source of controversy. Debates over the necessity, fairness, and cost of environmental regulation are ongoing. Allegations of scientific uncertainty fuel the ongoing debate over greenhouse gas regulation and are a major factor in the debate over whether to ban pesticides. It is very common for regulated industry to argue against environmental regulation on the basis of cost. Difficulties arise, however, in performing cost-benefit analysis of environmental issues. It is difficult to quantify the value of an environmental value such as a healthy ecosystem, clean air, or species diversity. Furthermore environmental issues may gain an ethical or moral dimension that would discount financial cost. Controversy is not limited to those who oppose environmental regulation: many groups take the position that current regulations are inadequately protective, and advocate for strengthening regulations.
Around the world.
International law.
Global and regional environmental issues are increasingly the subject of international law. Debates over environmental concerns implicate core principles of international law and have been the subject of numerous international agreements and declarations.
Customary international law is an important source of international environmental law. These are the norms and rules that countries follow as a matter of custom and they are so prevalent that they bind all states in the world. When a principle becomes customary law is not clear cut and many arguments are put forward by states not wishing to be bound. Examples of customary international law relevant to the environment include the duty to warn other states promptly about icons of an environmental nature and environmental damages to which another state or states may be exposed, and Principle 21 of the Stockholm Declaration ('good neighbourliness' or sic utere).
Numerous legally binding international agreements encompass a wide variety of issue-areas, from terrestrial, marine and atmospheric pollution through to wildlife and biodiversity protection. International environmental agreements are generally multilateral (or sometimes bilateral) treaties (a.k.a. convention, agreement, protocol, etc.). Protocols are subsidiary agreements built from a primary treaty. They exist in many areas of international law but are especially useful in the environmental field, where they may be used to regularly incorporate recent scientific knowledge. They also permit countries to reach agreement on a framework that would be contentious if every detail were to be agreed upon in advance. The most widely known protocol in international environmental law is the Kyoto Protocol, which followed from the United Nations Framework Convention on Climate Change.
While the bodies that proposed, argued, agreed upon and ultimately adopted existing international agreements vary according to each agreement, certain conferences, including 1972's United Nations Conference on the Human Environment, 1983's World Commission on Environment and Development, 1992's United Nations Conference on Environment and Development and 2002's World Summit on Sustainable Development have been particularly important. Multilateral environmental agreements sometimes create an International Organization, Institution or Body responsible for implementing the agreement. Major examples are the Convention on International Trade in Endangered Species of Wild Fauna and Flora (CITES) and the International Union for Conservation of Nature (IUCN).
International environmental law also includes the opinions of international courts and tribunals. While there are few and they have limited authority, the decisions carry much weight with legal commentators and are quite influential on the development of international environmental law. One of the biggest challenges in international decisions is to determine an adequate compensation for environmental damages. The courts include the International Court of Justice (ICJ); the international Tribunal for the Law of the Sea (ITLOS); the European Court of Justice; European Court of Human Rights and other regional treaty tribunals.
Africa.
According to the International Network for Environmental Compliance and Enforcement (INECE), the major environmental issues in Africa are “drought and flooding, air pollution, deforestation, loss of biodiversity, freshwater availability, degradation of soil and vegetation, and widespread poverty.” The U.S. Environmental Protection Agency (EPA) is focused on the “growing urban and industrial pollution, water quality, electronic waste and indoor air from cookstoves.” They hope to provide enough aid on concerns regarding pollution before their impacts contaminate the African environment as well as the global environment. By doing so, they intend to “protect human health, particularly vulnerable populations such as children and the poor.” In order to accomplish these goals in Africa, EPA programs are focused on strengthening the ability to enforce environmental laws as well as public compliance to them. Other programs work on developing stronger environmental laws, regulations, and standards.
Asia.
The Asian Environmental Compliance and Enforcement Network (AECEN) is an agreement between 16 Asian countries dedicated to improving cooperation with environmental laws in Asia. These countries include Cambodia, China, Indonesia, India, Maldives, Japan, Korea, Malaysia, Nepal, Philippines, Pakistan, Singapore, Sri Lanka, Thailand, Vietnam, and Lao PDR.
European Union.
The European Union issues secondary legislation on environmental issues that are valid throughout the EU (so called regulations) and many directives that must be implemented into national legislation from the 28 member states (national states). Examples are the Regulation (EC) No. 338/97 on the implementation of CITES; or the Natura 2000 network the centerpiece for nature & biodiversity policy, encompassing the bird Directive (79/409/EEC/ changed to 2009/147/EC)and the habitats directive (92/43/EEC). Which are made up of multiple SACs (Special Areas of Conservation, linked to the habitats directive) & SPAs (Special Protected Areas, linked to the bird directive), throughout Europe.
EU legislation is ruled in Article 249 Treaty for the Functioning of the European Union (TFEU). Topics for common EU legislation are:
Middle East.
The U.S. Environmental Protection Agency is working with countries in the Middle East to improve “environmental governance, water pollution and water security, clean fuels and vehicles, public participation, and pollution prevention.”
Oceania.
The main concerns on environmental issues in the Oceanic Region are “illegal releases of air and water pollutants, illegal logging/timber trade, illegal shipment of hazardous wastes, including e-waste and ships slated for destruction, and insufficient institutional structure/lack of enforcement capacity”. The Secretariat of the Pacific Regional Environmental Programme (SPREP) is an international organization between Australia, the Cook Islands, FMS, Fiji, France, Kiribati, Marshall Islands, Nauru, New Zealand, Niue, Palau, PNG, Samoa, Solomon Island, Tonga, Tuvalu, USA, and Vanuatu. The SPREP was established in order to provide assistance in improving and protecting the environment as well as assure sustainable development for future generations.
Australia.
The Environment Protection and Biodiversity Conservation Act 1999 is the center piece of environmental legislation in the Australian Government. It sets up the “legal framework to protect and manage nationally and internationally important flora, fauna, ecological communities and heritage places”. It also focuses on protecting world heritage properties, national heritage properties, wetlands of international importance, nationally threatened species and ecological communities, migratory species, Commonwealth marine areas, Great Barrier Reef Marine Park, and the environment surrounding nuclear activities.
Brazil.
The Brazilian government created the Ministry of Environment in 1992 in order to develop better strategies of protecting the environment, use natural resources sustainably, and enforce public environmental policies. The Ministry of Environment has authority over policies involving environment, water resources, preservation, and environmental programs involving the Amazon.
Canada.
The Department of the Environment Act establishes the Department of the Environment in the Canadian government as well as the position Minister of the Environment. Their duties include “the preservation and enhancement of the quality of the natural environment, including water, air and soil quality; renewable resources, including migratory birds and other non-domestic flora and fauna; water; meteorology;" The Environmental Protection Act is the main piece of Canadian environmental legislation that was put into place March 31, 2000. The Act focuses on “respecting pollution prevention and the protection of the environment and human health in order to contribute to sustainable development." Other principle federal statutes include the Canadian Environmental Assessment Act, and the Species at Risk Act. When provincial and federal legislation are in conflict federal legislation takes precedence, that being said individual provinces can have their own legislation such as Ontario's Environmental Bill of Rights, and Clean Water Act.
China.
According to the U.S. Environmental Protection Agency, "China has been working with great determination in recent years to develop, implement, and enforce a solid environmental law framework. Chinese officials face critical challenges in effectively implementing the laws, clarifying the roles of their national and provincial governments, and strengthening the operation of their legal system." Explosive economic and industrial growth in China has led to significant environmental degradation, and China is currently in the process of developing more stringent legal controls. The harmonization of Chinese society and the natural environment is billed as a rising policy priority.
Ecuador.
With the enactment of the 2008 Constitution, Ecuador became the first country in the world to codify the Rights of Nature. The Constitution, specifically Articles 10 and 71-74, recognizes the inalienable rights of ecosystems to exist and flourish, gives people the authority to petition on the behalf of ecosystems, and requires the government to remedy violations of these rights. The rights approach is a break away from traditional environmental regulatory systems, which regard nature as property and legalize and manage degradation of the environment rather than prevent it. 
The Rights of Nature articles in Ecuador's constitution are part of a reaction to a combination of political, economic, and social phenomena. Ecuador's abusive past with the oil industry, most famously the class-action litigation against Chevron, and the failure of an extraction-based economy and neoliberal reforms to bring economic prosperity to the region has resulted in the election of a New Leftist regime, led by President Rafael Correa, and sparked a demand for new approaches to development. In conjunction with this need, the principle of "Buen Vivir," or good living—focused on social, environmental and spiritual wealth versus material wealth—gained popularity among citizens and was incorporated into the new constitution.
The influence of indigenous groups, from whom the concept of "Buen Vivir" originates, in the forming of the constitutional ideals also facilitated the incorporation of the Rights of Nature as a basic tenet of their culture and conceptualization of "Buen Vivir." 
Egypt.
The Environmental Protection Law outlines the responsibilities of the Egyptian government to “preparation of draft legislation and decrees pertinent to environmental management, collection of data both nationally and internationally on the state of the environment, preparation of periodical reports and studies on the state of the environment, formulation of the national plan and its projects, preparation of environmental profiles for new and urban areas, and setting of standards to be used in planning for their development, and preparation of an annual report on the state of the environment to be prepared to the President."
India.
In India, Environmental law is governed by the . This act is enforced by the Central Pollution Control Board and the numerous State Pollution Control Boards. Apart from this, there are also individual legislations specifically enacted for the protection of Water, Air, Wildlife, etc. Such legislations include the Water (Prevention and Control of Pollution) Act, 1974; the Water (Prevention and Control of Pollution) Cess Act, 1977; the Forest (Conservation) Act, 1980; the Air (Prevention and Control of Pollution) Act, 1981; The Biological Diversity Act, 2002 and the Wild Life Protection Act, 1972. The National Green Tribunal established under the has jurisdiction over all environmental cases dealing with a substantial environmental question and acts covered under the Water (Prevention and Control of Pollution) Act, 1974; the Water (Prevention and Control of Pollution) Cess Act, 1977; the Forest (Conservation) Act, 1980; the Air (Prevention and Control of Pollution) Act, 1981; the Public Liability Insurance Act, 1991 and the Biological Diversity Act, 2002. The acts covered under do not fall within the jurisdiction of the National Green Tribunal. Appeals can be filed in the Hon'ble Supreme Court of India.
Japan.
The Basic Environmental Law is the basic structure of Japan’s environmental policies replacing the Basic Law for Environmental Pollution Control and the Nature Conservation Law. The updated law aims to address “global environmental problems, urban pollution by everyday life, loss of accessible natural environment in urban areas and degrading environmental protection capacity in forests and farmlands.”
The three basic environmental principles that the Basic Environmental Law follows are “the blessings of the environment should be enjoyed by the present generation and succeeded to the future generations, a sustainable society should be created where environmental loads by human activities are minimized, and Japan should contribute actively to global environmental conservation through international cooperation.”
From these principles, the Japanese government have established policies such as “environmental consideration in policy formulation, establishment of the Basic Environment Plan which describes the directions of long-term environmental policy, environmental impact assessment for development projects, economic measures to encourage activities for reducing environmental load, improvement of social infrastructure such as sewerage system, transport facilities etc., promotion of environmental activities by corporations, citizens and NGOs, environmental education, and provision of information, promotion of science and technology."
New Zealand.
The Ministry for the Environment and Office of the Parliamentary Commissioner for the Environment were established by the Environment Act 1986. These positions are responsible for advising the Minister on all areas of environmental legislation. A common theme of New Zealand’s environmental legislation is sustainably managing natural and physical resources, fisheries, and forests. The Resource Management Act 1991 is the main piece of environmental legislation that outlines the government’s strategy to managing the “environment, including air, water soil, biodiversity, the coastal environment, noise, subdivision, and land use planning in general.”
Russia.
The Ministry of Natural Resources and Environment of the Russian Federation makes regulation regarding “conservation of natural resources, including the subsoil, water bodies, forests located in designated conservation areas, fauna and their habitat, in the field of hunting, hydrometeorology and related areas, environmental monitoring and pollution control, including radiation monitoring and control, and functions of public environmental policy making and implementation and statutory regulation."
Vietnam.
Vietnam is currently working with the U.S. Environmental Protection Agency on dioxin remediation and technical assistance in order to lower methane emissions. On March 2002, the U.S and Vietnam signed the U.S.-Vietnam Memorandum of Understanding on Research on Human Health and the Environmental Effects of Agent Orange/Dioxin.

</doc>
<doc id="10093" url="http://en.wikipedia.org/wiki?curid=10093" title="Eurostar">
Eurostar

Eurostar is a high-speed railway service connecting London with Paris and Brussels. All its trains traverse the Channel Tunnel between the United Kingdom and France, owned and operated separately by Eurotunnel.
The London terminus is St Pancras International, with the other British calling points being Ebbsfleet International and Ashford International in Kent. Calling points in France are Calais-Fréthun and Lille-Europe, with trains to Paris terminating at Gare du Nord. Trains to Belgium terminate at Midi/Zuid station in Brussels. In addition, there are limited services from London to Disneyland Paris at Marne-la-Vallée – Chessy, services to southern France as of 1 May 2015 and seasonal services to the Alps in winter.
The service is operated by eighteen-coach Class 373/1 trains which run at up to 300 km/h on a network of high-speed lines. The LGV Nord line in France opened before Eurostar services began in 1994, and newer lines enabling faster journeys were added later—HSL 1 in Belgium and High Speed 1 in southern England. The French and Belgian parts of the network are shared with Paris–Brussels Thalys services and also with TGV trains. In the United Kingdom the two-stage Channel Tunnel Rail Link project was completed on 14 November 2007 and renamed High Speed 1, when the London terminus of Eurostar transferred from Waterloo International to St Pancras International.
Eurostar was until 2010 operated jointly by the national railway companies of France and Belgium, SNCF and SNCB/NMBS, and Eurostar (UK) Ltd (EUKL), a subsidiary of London and Continental Railways (LCR), which also owned the high-speed infrastructure and stations on the British side. Eurostar has become the dominant operator on the routes that it operates, carrying more passengers than all airlines combined. Other operators have expressed an interest in starting competing services following deregulation in 2010. On 1 September 2010, Eurostar was incorporated as a single corporate entity called Eurostar International Limited (EIL), replacing the joint operation between EUKL, SNCF and SNCB/NMBS. EIL is owned by SNCF (55%), LCR (40%) and SNCB/NMBS (5%).
In June 2014, the UK shareholding in Eurostar International Limited was transferred from London and Continental Railways / Department for Transport to HM Treasury. In October 2014, it was announced that the UK government planned to raise £300 million by selling that stake. In March 2015, the UK government announced that it will be selling its 40% share to an Anglo-Canadian consortium. If the sale goes ahead, the ownership of Eurostar International wil be SNCF (55%), Caisse de dépôt et placement du Québec (30%), Hermes Infrastructure (10%) and SNCB (5%).
History.
Conception and planning.
The history of Eurostar can be traced to the 1986 choice of a rail tunnel to provide a cross-channel link between Britain and France.
A previous attempt at constructing a tunnel between the two nations had begun in 1974, but was quickly aborted. In 1988 construction began on a new basis. Eurotunnel was created to manage and own the tunnel, which was finished in 1993, the official opening taking place in May 1994.
In addition to the tunnel's shuttle trains carrying cars and lorries between Folkestone and Calais, the decision to build a railway tunnel opened up the possibility of through passenger and freight train services between places further afield. British Rail and SNCF contracted with Eurotunnel to use half the tunnel's capacity for this purpose. In 1987 Britain, France and Belgium set up an International Project Group to specify a train to provide an international high-speed passenger service through the tunnel. France had been operating high-speed TGV services since 1981, and had begun construction of a new high-speed line between Paris and the Channel Tunnel, LGV Nord; French TGV technology was chosen as the basis for the new trains. An order for 30 trainsets, to be manufactured in France but with some British and Belgian components, was placed in December 1989. On 20 June 1993, the first Eurostar test train travelled through the tunnel to the UK. Various technical difficulties in running the new trains on British tracks were quickly overcome.
Launch of service.
On 14 November 1994 Eurostar services began between Waterloo International station in London, Gare du Nord in Paris and Brussels-South railway station in Brussels.
In 1995 Eurostar was achieving an average end-to-end speed of 171.5 km/h between London and Paris.
On 8 January 1996 Eurostar launched services from a second railway station in the UK when Ashford International was opened. Journey times between London and Brussels were reduced by the opening of HSL 1 on 14 December 1997.
On 23 September 2003 passenger services began running on the first completed section of High Speed 1. Following a high-profile glamorous opening ceremony
and a large advertising campaign, on 14 November 2007 Eurostar services in London transferred from Waterloo to the extended and extensively refurbished St Pancras International.
Records achieved.
The Channel Tunnel used by Eurostar services holds the record for having the longest undersea section anywhere in the world, and it is the second longest rail tunnel in the world.
A Eurostar train set a new British speed record of 334.7 km/h on the first section of High Speed 1 on 30 July 2003, two months before services began running upon the first section of High Speed 1.
On 16 May 2006 Eurostar set a new record for the longest non-stop high-speed journey, a distance of 1421 km from London to Cannes taking 7 hours 25 minutes.
On 4 September 2007 a record-breaking train left Paris Gare du Nord at 10:44 (09:44 BST) and reached London St Pancras in 2 hours 3 minutes 39 seconds; carrying journalists and railway workers. The train was the first passenger-carrying arrival at St Pancras International station.
On 20 September 2007, Eurostar broke another record when it completed the journey from Brussels to London in 1 hour, 43 minutes.
Regional Eurostar and Nightstar.
The original proposals for Eurostar included direct services to Paris and Brussels from cities north of London (NoL): Manchester via Birmingham on the West Coast Main Line and Glasgow via Edinburgh, Newcastle and York on the East Coast Main Line.
Seven shorter NoL Eurostar trains for these Regional Eurostar services were built, but these services never ran. Predicted journey times of almost nine hours for Glasgow to Paris at the time of growth of low-cost air travel during the 1990s made the plans commercially unviable against the cheaper and quicker airlines. Other reasons that have been suggested for these services having never been run were both government policies and the disruptive privatisation of British Rail.
Three of the Regional Eurostar units were leased by Great North Eastern Railway (GNER) to increase domestic services from London King's Cross to York and later Leeds. The leases ended in December 2005, and most of the NoL sets have since been transferred to SNCF for TGV services in northern France.
An international Nightstar sleeper train was also planned; this would have travelled the same routes as Regional Eurostar, plus the Great Western Main Line to Cardiff.
These were also deemed commercially unviable, and the scheme was abandoned with no services ever operated. In 2000 the coaches were sold to Via Rail in Canada.
Ashford International station.
Ashford International station was the original station for Eurostar services in Kent.
Once Ebbsfleet International railway station, also designed to serve the Kent region, had opened, only three trains a day to Paris and one to Disneyland Paris called at Ashford for a considerable amount of time. There were fears that services at Ashford International might be further reduced or withdrawn altogether as Eurostar planned to make Ebbsfleet the new regional hub instead.
However, after a period during which no Brussels trains served the station, to the dissatisfaction of the local communities, on 23 February 2009 Eurostar re-introduced a single daily Ashford-Brussels service.
Mainline routes.
LGV Nord.
LGV Nord is a French 333 km-long high-speed rail line that connects Paris to the Belgian border and the Channel Tunnel via Lille. It opened in 1993.
Its extensions to Belgium and towards Paris, as well as connecting to the Channel Tunnel, have made LGV Nord a part of every Eurostar journey undertaken. A Belgian high-speed line, HSL 1, was added to the end of LGV Nord, at the Belgian border, in 1997. Of all French high-speed lines, LGV Nord sees the widest variety of high-speed rolling stock and is quite busy; a proposed cut-off bypassing Lille, which would reduce Eurostar journey times to Paris, is called LGV Picardie.
Channel Tunnel.
The Channel Tunnel is a crucial part of the route as it is the only rail connection between Great Britain and the European mainland. It joins LGV Nord in France with High Speed One in Britain. Tunnelling began in 1988, and the 50.5 km tunnel was officially opened by the British sovereign Queen Elizabeth II and the French President François Mitterrand at a ceremony in Calais on 6 May 1994.
It is owned by Eurotunnel, which charges a significant toll to Eurostar for its use.
In 1996 the American Society of Civil Engineers identified the tunnel as one of the Seven Wonders of the Modern World.
Along the current route of the Eurostar service, line speeds are 300 km/h except within the Channel Tunnel, where a reduced speed of 160 km/h applies for safety reasons.
Since the launch of Eurostar services, severe disruptions and cancellations have been caused by fires breaking out within the Channel Tunnel, such as in 1996, 2006 (minor), 2008 and 2015.
HSL 1.
Journey times between London and Brussels were improved when an 88 km Belgian high-speed line, HSL 1, opened on 14 December 1997.
It links with LGV Nord on the border with France, allowing Eurostar trains heading to Brussels to make the transition between the two without having to reduce speed. A further four-minute improvement for London–Brussels trains was achieved in December 2006 with the opening of the 435 m Brussels South Viaduct.
Linking the international platforms of Brussels-South railway station with the high-speed line, the viaduct separates Eurostar (and Thalys) from local services.
High Speed 1.
High Speed 1 (HS1), formerly known as the Channel Tunnel Rail Link (CTRL), is a 108 km high-speed railway line running from London through Kent to the British end of the Channel Tunnel.
It was built in two stages. The first section between the tunnel and Fawkham Junction in north Kent opened in September 2003, cutting London–Paris journey times by 21 minutes to 2 hours 35 minutes, and London–Brussels to 2 hours 20 minutes. On 14 November 2007, commercial services began over the whole of the new HS1 line. The redeveloped St Pancras International station became the new London terminus for all Eurostar services.
The completion of High Speed 1 has brought the British part of Eurostar's route up to the same standards as the French and Belgian high-speed lines. Non-stop journey times were reduced by a further 20 minutes to 2 hours 15 minutes for London–Paris and 1 hour 51 minutes for London–Brussels.
Services.
Frequency.
Eurostar offers up to sixteen weekday London – Paris services (eighteen on Fridays) including ten non-stop (twelve on Fridays). There used to be ten London–Lille and Brussels services, including five running non-stop as far as Lille, but this has now been reduced to seven each way.
In addition, there is a return trip from London to Marne-la-Vallée - Chessy for Disneyland Paris which runs at least 4 times a week with increased frequency during school holidays and an up to 5 times a week service to Marseille via Lyon and Avignon. There are also seasonal services in the winter. "Snow trains", aimed at skiers, to Bourg-Saint-Maurice, Aime-la-Plagne and Moûtiers in the Alps; these run twice-weekly, one overnight and one during the daytime.
Intermediate stations are Ebbsfleet International in northwest Kent, Ashford International in southeast Kent, and Calais-Fréthun and Lille-Europe in Nord-Pas-de-Calais.
Since 14 November 2007, all Eurostar trains have been routed via High Speed 1 to or from the redeveloped London terminus at St Pancras International, which at a cost of £800 million was extensively rebuilt and extended to cope with 394 m long Eurostar trains.
It had originally been intended to retain some Eurostar services at Waterloo International terminal, but this was ruled out on cost grounds.
Completion of High Speed 1 has increased the potential number of trains serving London. Separation of Eurostar from British domestic services through Kent meant that timetabling was no longer affected by peak-hour restrictions.
Fares.
Eurostar's fares were significantly higher in its early years; the cheapest fare in 1994 was £99 return.
In 2002, Eurostar was planning cheaper fares, an example of which was an offer of £50 day returns from London to Paris or Brussels.
By March 2003, the cheapest fare from the UK was £59 return, available all year around. In June 2009 it was announced that one-way single fares would be available at £31 at the cheapest. Competition between Eurostar and airline services was a large factor in ticket prices being reduced from the initial levels.
Business Premier fares also slightly undercut air fares on similar routes, targeted at regular business travellers.
In 2009, Eurostar greatly increased its budget ticket availability to help maintain and grow its dominant market share.
The Eurostar ticketing system is very complex, being distributed through no fewer than 48 individual sales systems.
Eurostar is a member of the Amadeus CRS distribution system, making its tickets available alongside those of airlines worldwide.
First class on Eurostar is called Business Premier; benefits include guaranteed faster checking-in and meals served at-seat, as well as the improved furnishings and interior of Business Premier carriages.
The rebranding is part of Eurostar's marketing drive to attract more business professionals. Increasingly, business people in a group have been chartering private carriages as opposed to individual seats on the train.
Service connections.
Without the operation of Regional Eurostar services using the North of London trainsets across the rest of Britain, Eurostar has developed its connections with other transport services instead, such as integrating effectively with traditional UK rail operators' schedules and routes, making it possible for passengers to use Eurostar as a quick connection to further destinations on the continent.
All three main terminals used by the Eurostar service – St Pancras International, Paris Gare du Nord, and Brussels Midi/Zuid – are served by domestic trains and by local urban transport networks such as the London Underground and the Paris Metro. Standard Eurostar tickets no longer include free onward connections to or from any other station in Belgium: this is now available for a flat-rate supplement, currently £5.50.
Eurostar has announced several partnerships with other rail services,
most notably Thalys connections at Lille and Brussels for passengers to go beyond current Eurostar routes towards the Netherlands and Germany.
In 2002, Eurostar initiated the Eurostar-Plus program, offering connecting tickets for onward journeys from Lille and Paris to dozens of destinations in France.
Through fares are also available from 68 British towns and cities to destinations in France and Belgium.
In May 2009 Eurostar announced that a formal connection to Switzerland had been established in a partnership between Eurostar and Lyria, which will operate TGV services from Lille to the Swiss Alps for Eurostar connection.
Controls and security.
Because the UK is not part of the Schengen Area, and because Belgium and France are not part of the Common Travel Area, all Eurostar passengers must go through border controls. Both the British Government and the Schengen governments concerned (Belgium and France) have legal obligations to check the travel documents of those entering their respective countries (as well as those leaving, in the case of Belgium and France).
To allow passengers to walk off the train on arrival in most cases, passport controls ordinarily take place at the embarkation station.
In order to comply with special UK legislation, there are full security checks similar to those at airports, scanning both bags and people's pockets. Security checks at Eurostar are comparable to those at a small airport and generally much quicker than at London Heathrow. The recommended check-in time is 30 minutes except for business class where it is 10 minutes.
Eurostar passengers travelling inside the Schengen Area (mainly from Brussels to Lille, but also from Brussels to Calais) are also checked by the UK Border Force within Belgian territory, since there is no way of separating them out from Brussels–London passengers. When the tripartite agreements were signed, the Belgian Government said that it had serious questions about the compatibility of this agreement with the Schengen Convention and the principle of free movement of people enshrined in various European Treaties.
On 30 June 2009 Eurostar raised concerns at the UK House of Commons Home Affairs Select Committee that it was illegal under French law for the collection of information desired by the UK government under the e-Borders scheme, and they would be unable to cooperate.
Where there is no facility for security checks, for example on the northbound Provence service, passengers must leave the train at Lille and undergo security and passport checks there before reboarding the train.
On several occasions, people have illegally tried to stow away on board the train, sometimes in large groups, trying to enter the UK; border monitoring and security is therefore extremely tight.
Eurostar claims to have good and well-funded security measures.
Operational performance.
Eurostar's punctuality has fluctuated from year to year, but usually remains over 90%; in the first quarter of 1999, 89% of services operated were on time, and in the second quarter it reached 92%. Eurostar's best punctuality record was 97.35%, between 16 and 22 August 2004. In 2006, it was 92.7%, and in 2007, 91.5% were on time. In the first quarter of 2009, 96% of Eurostar services were punctual compared with rival air routes' 76%.
An advantage held by Eurostar is the convenience and speed of the service: with shorter check-in times than at most airports and hence quicker boarding and less queueing and high punctuality, it takes less time to travel between central London and central Paris by high-speed rail than it does by air. Eurostar now has a dominant share of the combined rail–air market on its routes to Paris and Brussels. In 2004, it had a 66% share of the London–Paris market, and a 59% share of the London–Brussels market. In 2007, it achieved record market shares of 71% for London–Paris and 65% for London–Brussels routes.
Eurostar's passenger numbers initially failed to meet predictions. In 1996, London and Continental Railways forecast that passenger numbers would reach 21.4 million annually by 2004, but only 7.3 million was achieved. 82 million passengers used Waterloo International Station from its opening in 1994 to its closure in 2007. 2008 was a record year for Eurostar, with a 10.3% rise in passenger use, which was attributed to the use of High Speed 1 and the move to St Pancras. The following year, Eurostar saw an 11.5% fall in passenger numbers during the first three months of 2009, attributed to the 2008 Channel Tunnel fire and the 2009 recession.
As a result of the poor economic conditions, Eurostar received state aid in May 2009 to cancel out some of the accumulated debt from the High Speed 1 construction programme. Later that year, during snowy conditions in the run-up to Christmas, thousands of passengers were left stranded as several trains broke down and many more were cancelled. In an independent review commissioned by Eurostar, the company came in for serious criticism about its handling of the incident and lack of plans for such a scenario.
In 2006, the Department for Transport predicted that, by 2037, annual cross-channel passenger numbers would probably reach 16 million, considerably less optimistic than London and Continental Railways's original 1996 forecast. In 2007 Eurostar set a target of carrying 10 million passengers by 2010.
The company cited several factors to support this objective, such as improved journey times, punctuality and station facilities. Passengers in general, it stated, are becoming increasingly aware of the environmental effects of air travel, and Eurostar services emit much less carbon dioxide. and that its remaining carbon emissions are now offset, making its services carbon neutral. Further expansion of the high-speed rail network in Europe, such as the HSL-Zuid line between Belgium and the Netherlands, continues to bring more destinations within rail-competitive range, giving Eurostar the possibility of opening up new services in future.
The following chart presents the estimated number of passengers annually transported by the Eurostar service since 1995, in millions:
Awards and accolades.
Eurostar has been hailed as having set new standards in international rail travel and has won praise several times over, recognising its high standards. Eurostar won the Train Operator of the Year award in the HSBC Rail Awards for 2005. It was declared the Best Train Company in the joint Guardian/Observer Travel Awards 2008. Eurostar had previously struggled with its reputation and brand image. One commentator had defined the situation at the time as:
In June 2003, Eurostar was battling to recover from the worst period in its 10-year history. Negative media coverage combined with poor sales and the general public's low opinion of the British rail industry, created a major challenge... Eurostar was finding it difficult to pick itself up from one of the worst periods in its decade-long history. The period post 9/11 had sent the business into a downturn. Passenger numbers were drying up due to worries over international travel. Several management changes had led to a pause in strategy. Punctuality had suffered badly because of wider problems with the UK's rail infrastructure.
By 2008, Eurostar's environmental credentials had become highly developed and promoted. In 2006 Eurostar's Environment Group was set up, with the aim of making changes in the Eurostar services' daily running to decrease the environmental impact, the organisation setting itself a target of reducing carbon emissions per passenger journey by 25% by 2012. Drivers are trained in techniques to achieve maximum energy efficiency, and lighting has been minimised; the provider of the bulk of the energy for the Channel Tunnel has been switched to nuclear power stations in France.
Eurostar's current target is to reduce emissions by 35 percent per passenger journey by 2012, putting itself beyond the efforts of other railway companies in this field and thereby winning the 2007 Network Rail Efficiency Award.
In the grand opening ceremony of St Pancras International, one of the Eurostar trains was given the name 'Tread Lightly', said to symbolise their smaller impact on the environment compared to planes.
Organisation.
Since 2010, Eurostar is owned by Eurostar International Limited, a company jointly owned by London & Continental Railways, SNCF and SNCB/NMBS.
Railteam.
Eurostar is a member of Railteam, a marketing alliance formed in July 2007 of seven European high-speed rail operators, including Thalys.
The alliance plans to allow tickets to be booked from one end of Europe to the other on a single website. In June 2009 London and Continental Railways, and the Eurostar UK operations they held ownership of, became fully nationalised by the UK government.
Fleet.
Fleet details.
Each train has a unique four-digit number starting with "3" (3xxx). This designates the train as a Mark 3 TGV (Mark 1 being SNCF TGV Sud-Est; Mark 2 being SNCF TGV Atlantique). The second digit denotes the country of ownership:
Current fleet.
Built between 1992 and 1996, Eurostar's fleet consists of 38 EMU trains, designated Class 373 in the United Kingdom and TGV TMST in France. The units have also been branded as the Eurostar e300 by Eurostar since 2015. There are two variants:
The trains are essentially modified TGV sets, and can operate at up to 300 km/h on high-speed lines, and 160 km/h in the Channel Tunnel. It is possible to exceed the 300-kilometre-per-hour speed limit, but only with special permission from the safety authorities in the respective country.
Speed limits in the Channel Tunnel are dictated by air-resistance, energy (heat) dissipation and the need to fit in with other, slower trains. The trains were designed with Channel Tunnel safety in mind, and consist of two independent "half-sets" each with its own power car. In the event of a serious fire on board while travelling through the tunnel, passengers would be transferred into the undamaged half of the train, which would then be detached and driven out of the tunnel to safety.
If the undamaged part were the rear half of the train, this would be driven by the Chef du Train, who is a fully authorised driver and occupies the rear driving cab while the train travels through the tunnel for this purpose.
As 27 of the 31 Inter-Capital sets are sufficient to operate the service, four are currently used by SNCF for domestic TGV services; one of these regularly operates a Paris–Lille shuttle. The Eurostar logos have been removed from these sets, but the base colours of white, black, and yellow remain. SNCF's lease of the sets is scheduled to last until 2011, with an option for a further two years.
In addition to its Class 373 units, Eurostar operates a single Class 08 diesel shunter as the pilot at Temple Mills depot.
Fleet updates.
In 2004–2005 the "Inter-Capital" sets still in daily use for international services were refurbished with a new interior designed by Philippe Starck.
The original grey-yellow scheme in Standard class and grey-red of First/Premium First were replaced with a grey-brown look in Standard and grey-burnt-orange in First class. Power points were added to seats in First class and coaches 5 and 14 in Standard class. Premium First class was renamed BusinessPremier.
In 2008, Eurostar announced that it would be carrying out a mid-life refurbishment of its Class 373 trains to allow the fleet to remain in service beyond 2020.
This will include the 28 units making up the Eurostar fleet, but not the three Class 373/1 units used by SNCF or the seven Class 373/2 "North of London" sets.
As part of the refurbishment, the Italian company Pininfarina was contracted to redesign the interiors, and The Yard Creative was selected to design the new buffet cars.
On 11 May 2009 Eurostar revealed the new look for its first-class compartments.
The first refurbished train was due in service in 2012, and Eurostar plans to have completed the entire process by 2014.
On 13 November 2014 Eurostar announced the first refurbished trains would not re-enter the fleet until the 3rd or 4th quarter of 2015 due to delays at the completion centre.
Future fleet.
In addition to the announced mid-life update of the existing Class 373 fleet, Eurostar in 2009 reportedly entered prequalification bids for eight new trainsets to be purchased. Any new trains would need to meet the same safety rules governing passage through the Channel Tunnel as the existing Class 373 fleet. Any replacement to the Class 373 trains would be decided joinly between the French Transport Ministry and the UK Department for Transport. Current expectations place 2025 as the earliest forecast date for the existing fleet replacement; it is highly likely that the new trains would be equipped to use the new ERTMS in-cab signalling system, due to be fitted to High Speed 1 around 2040.
Velaro e320.
On 7 October 2010, it was reported that Eurostar had selected Siemens as preferred bidder to supply 10 Siemens Velaro e320 trainsets at a cost of €600 million (and a total investment of more than £700 million with the refurbishment of the existing fleet included) to operate an expanded route network, including services from London to Cologne and Amsterdam. These would be sixteen-car, 400 m long trainsets built to meet current Channel Tunnel regulations. The top speed will be 320 km/h and they will have 894–950 seats, unlike the current fleet by the French Alstom, which has a top speed of 300 km/h and a seating capacity of 750. Total traction power will be rated at 16 MW.
The nomination of Siemens would see it break into the French high-speed market for the first time, as all French and French subsidiary high-speed operators use TGV derivatives produced by Alstom. Alstom attempted legal action to prevent Eurostar from acquiring German-built trains, claiming that the Siemens sets ordered would breach Channel Tunnel safety rules, but this was thrown out of court. Alstom said, after its High Court defeat, that it would "pursue alternative legal options to uphold its position". On 4 November 2010, the company lodged a complaint with the European Commission over the tendering process, which then asked the British government for "clarification". Alstom then announced it had started legal action against Eurostar, again in the High Court in London.
In July 2011, the High Court rejected Alstom's claim that the tender process was "ineffective", and in April 2012 Alstom said it would call off pending court actions against Siemens. This effectively freed the way for Siemens to build the new Eurostar trains, the first of which is expected to enter service in late 2014. Eurostar has commissioned London-based composer Jason Edge to write a set of sounds (alarm tones and public address system (PA) chimes) for inclusion in the new fleet.
On 13 November 2014 Eurostar announced the purchase of an additional seven e320s for delivery in the second half of 2016. At the same time, Eurostar announced the first five e320s from the original order of ten would be available by December 2015, with the remaining five entering service by May 2016. Of the five sets ready by December 2015, three of them were planned to be used on London-Paris and London-Brussels routes.
Accidents, incidents and events.
A number of technical incidents have affected Eurostar services over the years, but up to the present[ [update]] there has only been one major accident involving a service operated by Eurostar, a derailment in June 2000. Other incidents in the Channel Tunnel — such as the 1996 and 2008 Channel Tunnel fires — have affected Eurostar services but were not directly related to Eurostar's operations. However, the breakdowns in the tunnel, which resulted in cessation of service and inconvenience to thousands of passengers, in the run-up to Christmas 2009, proved a public-relations disaster.
Minor incidents.
There have been several minor incidents with a few Eurostar services. In October 1994 there were teething problems relating to the start of operations. The first preview train, carrying 400 members of the press and media, was delayed for two hours by technical problems.
On 29 May 2002 a Eurostar train was initially sent down a wrong line — towards London Victoria railway station instead of London Waterloo — causing the service to arrive 25 minutes late. A signalling error that led to the incorrect routeing was stated to have caused "no risk" as a result.
On 11 April 2006, a house collapsed next to a railway line near London which caused Eurostar services to have to terminate and start from Ashford International instead of London Waterloo. Passengers waiting at Waterloo International were initially directed on to local trains towards Ashford leaving from the adjacent London Waterloo East railway station, until overcrowding occurred at Ashford.
1996.
Approximately 1000 passengers were trapped in darkness for several hours inside two Eurostar trains on the night of 19/20 February 1996. The trains stopped inside the tunnels due to electronic failures caused by snow and ice. Questions were raised at the time about the ability of the train and tunnel electronics to withstand the mix of snow, salt and ice which collect in the tunnels during periods of extreme cold.
2000.
On 5 June 2000 a Eurostar train travelling from Paris to London derailed on the LGV Nord high-speed line while traveling at 290 km/h. Fourteen people were treated for light injuries or shock, with no fatalities or major injuries. The articulated nature of the trainset was credited with maintaining stability during the incident and all of the train stayed upright. The incident was caused by a traction link on the second bogie of the front power car coming loose, leading to components of the transmission system on that bogie impacting the track.
2007.
The first departures from St Pancras on 14 November 2007 coincided with an open-ended strike by French rail unions as part of general strike actions over proposed public-sector pension reforms. The trains were operated by uninvolved British employees and service was not interrupted.
2009.
On 23 September 2009 an overhead power line dropped on to a Class 373 train arriving at St Pancras station, activating a circuit breaker and delaying eleven other trains. Two days later, on 25 September 2009, electrical power via the overhead lines was lost on a section of high-speed line outside Lille, delaying passengers on two evening Eurostar-operated services.
During the December 2009 European snowfall, four Eurostar trains broke down inside the Channel Tunnel, after leaving France, and one in Kent on 18 December. Although the trains had been winterised, the systems had not coped with the conditions. Over 2,000 passengers were stuck inside failed trains inside the tunnel, and over 75,000 had their services disrupted. All Eurostar services were cancelled from Saturday 19 December to Monday 21 December 2009. An independent review, published on 12 February 2010, was critical of the contingency plans in place for assisting passengers stranded by the delays, calling them "insufficient".
2010.
On 7 January 2010 a Brussels-London train broke down in the Channel Tunnel, resulting in three other trains failing to complete their journeys. The cause of the failure was the onboard signalling system. Due to the severe weather, a limited service was operated in the next few days.
On 15 February 2010, services between Brussels and London were interrupted following the Halle train collision, this time after the dedicated HSL 1 lines in the suburbs of the Belgian capital were blocked by debris from a serious train crash on the suburban commuter lines alongside. No efforts were made to reroute trains around the blockage; Eurostar instead terminated services to Brussels at Lille, directing passengers to continue their journey on local trains. Brussels services resumed on a limited scale on 22 February.
On 21 February 2010 the 21:43 service from Paris to London broke down just outside Ashford International, stranding 740 passengers for several hours while a rescue train was called in.
On 15 April 2010 air traffic in Western Europe closed because of the eruption of the Eyjafjallajökull volcano. Many travellers between the UK and the European mainland instead took the Eurostar train, all tickets between Brussels and London on 15 and 16 April being sold out within 3½ hours after the closure of British airspace.
 Between 15 and 20 April, Eurostar put on 33 additional trains and carried 165,000 passengers – 50,000 more than had been scheduled to travel during this period.
2011.
On 17 October 2011 a man fell at approximately 17:40 or 17:50 from the 17:04 service from London to Brussels as it passed through Westenhanger and Cheriton in Folkestone, near the entry to the Channel Tunnel. The individual was an Albanian who had been refused entry to the United Kingdom and was voluntarily returning to Brussels. The line was handed back at 22:09 after being closed for several hours following the incident. The train itself returned north to Ashford International, where passengers were transferred to a Eurostar service operating from Marne-la-Vallée to London, where passengers arrived again at approximately 22:30.
Possible developments.
Stratford International station.
Eurostar trains do not currently call at Stratford International, originally intended to be the London stop for the regional Eurostars. This was to be reviewed following the 2012 Olympics. However, in 2013, Eurostar claimed that its 'business would be hit' by stopping trains there.
Regional Eurostar.
Although the original plan for Regional Eurostar services to destinations north of London was abandoned, the significantly improved journey times available since the opening of High Speed 1 — which is physically connected to both the East Coast Main Line and the North London Line (for the West Coast Main Line) at St Pancras — and the recently increased maximum speeds on the West Coast Main Line may make potential Regional Eurostar services more commercially viable. This would be even more likely if proposals are adopted for a new high-speed line from London to the north of Britain.
Simon Montague, Eurostar's Director of Communications, commented that: "...International services to the regions are only likely once High Speed 2 is built."
Key pieces of infrastructure still belong to LCR via its subsidiary London & Continental Stations and Property, such as the Manchester International Depot, and Eurostar (UK) still owns several track access rights and the rights to paths on both the East Coast and West Coast Main Lines.
While no announcement has been made of plans to start Regional Eurostar services, it remains a possibility for the future. In the meantime, the closest equivalent to Regional Eurostar services are same-station connections with East Midlands Trains and Thameslink, changing at St Pancras. The recent construction of a new concourse at adjacent King's Cross Station has improved interchange with St Pancras and provided East Coast, Great Northern, First Hull Trains and Grand Central services with easier connections to Eurostar.
High Speed 2.
Eurostar has already been involved in reviewing and publishing reports into High Speed 2 for the British Government and looks favourably upon such an undertaking. The operation of Regional Eurostar services will not be considered until such time as High Speed 2 has been completed. Alternatively, future loans of the North of London sets to other operators would enable the trains to operate at their full speed, unlike GNER's previous loan between 2000 and 2005, where the trains were limited to 175 km/h on regular track. A separate company called High Speed Two (HS2) Ltd has been set up to investigate the feasibility and viability of a new line likely serving a similar route to the West Coast Main Line.
LGV Picardie.
LGV Picardie is a proposed high-speed line between Paris and Calais via Amiens. By cutting off the corner of the LGV Nord at Lille, it would enable Eurostar trains to save 20 minutes on the journey between Paris and Calais, bringing the London–Paris journey time under 2 hours. In 2008 the French Government announced its future investment plans for new LGVs to be built up to 2020; LGV Picardie was not included but was listed as planned in the longer term. It has later been confirmed that LGV Picardie is intended to be built between 2020 and 2030.
New destinations.
"We know we can go to most places in France physically, because our trains are compatible with French infrastructure, but then you've got to look at impact on fleet utilisation, you've got to have a station that's got the spare capacity to have a train stood for a number of hours, for all the security, screening, passport control passes. So it's not possible to go just anywhere. And you've got to be able to get the control authorities to agree that there's a big enough market for it to be worthwhile for them to set up there."
The reduced journey times offered by the opening of High Speed 1 and the opening of the LGV Est and HSL-Zuid bring more continental destinations
within a range from London where rail is competitive with air travel. By Eurostar's estimates a train would then take 3 hours 30 minutes from London to Amsterdam.
At present Eurostar is concentrating on developing its connections with other services, but direct services to other destinations would be possible. However, the routes that any potential services are likely to take would include infrastructure that Eurostar's rolling stock has not been built to use — German railways mostly have 15 kV AC electrification, while the Netherlands uses 1.5 kV DC (except on HSL Zuid and the Betuweroute).
To operate on these lines would require new or heavily modified rolling stock designed to operate at these different voltages, in addition to those already in use. Signalling systems also differ. In addition to the infrastructure difficulties, any potential Eurostar services beyond Paris and Brussels would also require the installation of stringent security measures, due to the UK's not having signed up to the Schengen Agreement, which allows unrestricted movement across borders of member countries.
The difficulties that Eurostar faces in expanding its services would also be faced by any potential competitors to Eurostar. As the UK is outside the Schengen Agreement, London-bound trains must use platforms that are physically isolated, a constraint which other international operators such as Thalys do not face. In addition, the British authorities are required to make passenger security and passport checks before they board the train,
which might deter domestic passengers. Compounding the difficulties in providing a similar service are the Channel Tunnel safety rules, the major ones being the "half-train rule" and the "length rule". The "half-train rule" stipulated that passenger trains had to be able to split in the case of emergency. Class 373 trains were designed as two half-sets, which when coupled form a complete train, enabling them to be split easily in the event of an emergency while in the tunnel, with the unaffected set able to be driven out. The half-train rule was finally abolished in May 2010. However, the "length rule", which states that passenger trains must be at least 375 metres long with a through corridor (to match the distance between the safety doors in the tunnel), was retained, preventing any potential operators from applying to run services with existing fleets (the majority of both TGV and ICE trains are only 200m long).
On 13 October 2009 the President of SNCF, Guillaume Pepy, outlined plans to expand TGV services around Paris as well as for fleet renewal. A plan to connect LGV Nord, the line used by Eurostar into Paris, with La Défense, a large commercial and business centre in the west of Paris, was described as the "top priority". Pepy estimated that the connection (which would also allow interchange to the proposed Paris – Rouen – Le Havre LGV line) would allow a journey time from central London to La Défense of 2hrs 15mins. Guillaume Pepy defined SNCF's priorities for the future as:
Our dream is to have 12 TGV stations for the 12 million inhabitants of Île de France. Grand Paris would be linked with the European high speed network, to challenge London or Frankfurt.
At the same time as Pepy's announcement, Richard Brown announced that Eurostar's plans for expanding its network potentially included Amsterdam and Rotterdam as destinations, using the HSL Zuid line. This would require either equipment upgrades of the existing fleet, or a new fleet equipped for both ERTMS and the domestic signalling systems used by Nederlandse Spoorwegen. Following the December 2009 opening of HSL Zuid, a London–Amsterdam journey is estimated to take 4hrs 16mins.
In an interview with Eurostar's Chief Executive Nicolas Petrovic in the "Financial Times" in May 2012, an intention for Eurostar to serve ten new destinations was expressed, including Amsterdam, Frankfurt, Cologne, Lyon, Marseille and Geneva, along with a likely second hub to be created in Brussels.
In September 2013, Eurostar announced an agreement with the Government of Netherlands and NS, the Dutch railway company to start twice daily services between London and Amsterdam Centraal starting in December 2016. The service will use the newly bought Siemens Velaro trainsets and will also call at Brussels, Antwerp, and Rotterdam. The journey time will be around four hours. On the 13th of November, 2014, Eurostar announced the service to Amsterdam would start in "2016-2017", and would include a stop at Amsterdam Schipol Airport in addition to the previously announced destinations. The company also said they would announced border control procedures for the service in January 2015, specifically whether it would be necessary for passenger to alight at Lille to pass through border control. Eurostar also announced a new service from London to Lyon and Marseille to start in May 2015.
In December 2012 Eurostar announced that on Saturdays during May 2013–June 2013 a new seasonal service would be introduced to Aix-en-Provence, also serving Lyon Part-Dieu and Avignon TGV on the way (the latter being 6 km from central Avignon). This is in addition to the long-standing seasonal summer service on Saturdays during July and August and the first week of September travelling to Avignon Centre. The Aix-en-Provence services did not run in 2014 but will be replaced along with the seasonal Avignon Centre services with the new year round service to Marseille as of 1 May 2015
Competition.
In 2010, international rail travel was liberalised by new European Union directives, designed to break up monopolies in order to encourage competition for services between countries. This sparked interest among other companies in providing services in competition to Eurostar and new services to destinations beyond Paris and Brussels. The only rail carrier to formally propose and secure permission for such a service up to now is Deutsche Bahn, which intends to run services between London and Germany and the Netherlands. The sale of High Speed One by the British Government having effectively nationalised LCR in June 2009 is also likely to stimulate competition on the line.
On 22 March 2010, it was announced that Eurotunnel was in discussions with the Intergovernment Commission, which oversees the tunnel, with the aim of amending elements of the safety code governing the tunnel's usage. Most saliently, the requirement that trains be able to split within the tunnel and each part of the train be driven out to opposite ends has been removed. However, the proposal to allow shorter trains was not passed. Eurotunnel Chairman & Chief Executive Jacques Gounon said that he hoped the liberalisation of rules would allow entry into the market of competitors such as Deutsche Bahn. Sources at Eurotunnel suggested that Deutsche Bahn could have entered the market at the timetable change in December 2012. This, however, did not happen.
On 28 July 2010 Deutsche Bahn (DB) announced that it intended to make a test run with a high-speed ICE-3MF train through the Channel Tunnel in October 2010 in preparation for possible future operations. The trial ran on 19 October 2010 with a Class 406 ICE train specially liveried with a British "Union flag" decal. The train was then put on display for the press at St Pancras International. However, this is not the class of train that would be used for the proposed service. At the St Pancras ceremony, DB revealed that it planned to operate from London to Frankfurt and Amsterdam (two of the biggest air travel markets in Europe), with trains 'splitting & joining' in Brussels. It hoped to begin these services in 2013 using Class 407 ICE units, with three trains per day each way—morning, midday and afternoon. Initially the only calling points would be Rotterdam on the way to Amsterdam, and Cologne on the way to Frankfurt. Amsterdam and Cologne would be under four hours from London, Frankfurt around five hours. DB decided to put this on hold mainly due to advance passport check requirements. DB had hoped that immigration checks could be done on board, but British authorities required immigration and security checks to be done at Lille Europe station, taking at least 30 minutes.
On 6 August 2010, Trenitalia announced its desire to eventually run high-speed trains from Italy to the United Kingdom, using its newly ordered high-speed trains. The trains will be delivered from 2013.
Bibliography.
</dl>

</doc>
<doc id="10100" url="http://en.wikipedia.org/wiki?curid=10100" title="Equinox">
Equinox

An equinox occurs twice a year, around 20 March and 22 September. The word itself has several related definitions. The oldest meaning is the day when daytime and night are of approximately equal duration. The word "equinox" comes from this definition, derived from the Latin "aequus" (equal) and "nox" (night). The equinox is not exactly the same as the day when period of daytime and night are of equal length for two reasons. Firstly, sunrise, which begins daytime, occurs when the top of the Sun's disk rises above the eastern horizon. At that instant, the disk's center is still below the horizon. Secondly, Earth's atmosphere refracts sunlight. As a result, an observer sees daylight before the first glimpse of the Sun's disk above the horizon. To avoid this ambiguity, the word "equilux" is sometimes used to mean a day on which the periods of daylight and night are equal. Times of sunset and sunrise vary with an observer's location (longitude and latitude), so the dates when day and night are closest together in length depend on location.
The other definitions are based on several related simultaneous astronomical events, and refer either to the events themselves or to the days on which they occur. These events are the reason that the period of daytime and night are approximately equal on the day of an equinox.
An equinox occurs when the plane of Earth's Equator passes the center of the Sun. At that instant, the tilt of Earth's axis neither inclines away from nor towards the Sun. The two annual equinoxes are the only times when the subsolar point—the place on Earth's surface where the center of the Sun is exactly overhead—is on the Equator, and, consequently, the Sun is at zenith over the Equator. The subsolar point crosses the equator, moving northward at the March equinox and southward at the September equinox.
At an equinox, the Sun is at one of the two opposite points on the celestial sphere where the celestial equator (i.e. declination 0) and ecliptic intersect. These points of intersection are called equinoctial points: classically, the vernal point (RA = 00h 00m 00s and longitude = 0°) and the autumnal point (RA = 12h 00m 00s and longitude = 180°).
The equinoxes are the only times when the solar terminator is perpendicular to the Equator. As a result, the northern and southern Hemispheres are illuminated equally.
Equinoxes on the Earth.
Date.
When Julius Caesar established his calendar in 45 BC he set 25 March as the spring equinox. Because a Julian year (365.25 days) is slightly longer than the tropical year the calendar drifted with respect to the equinox, such that the equinox was occurring on about 21 March in AD 300 and by AD 1500 it had reached 11 March.
This drift induced Pope Gregory XIII to create a modern Gregorian calendar. The Pope wanted to continue to conform with the edicts concerning the date of Easter of the Council of Nicaea of AD 325, which means he wanted to move the vernal equinox to 21 March, which is the day allocated to it in the Easter table of the Julian calendar. However, the leap year intervals in his calendar were not smooth (400 is not an exact multiple of 97). This causes the equinox to oscillate by about 53 hours around its mean position. This in turn raised the possibility that it could fall on 22 March, and thus Easter Day might theoretically commence before the equinox. The astronomers chose the appropriate number of days to omit so that the equinox would swing from 19 to 21 March but never fall on the 22nd (although it can in a handful of years fall early in the morning of that day in the Far East)
The "mean position" is not the "mean vernal equinox" (defined as the moment when the Right Ascension of the Mean Sun (R.A.M.S.) is 0 hours). It changes constantly since the Gregorian calendar does not accurately track the tropical year. In 1903 the astronomical equinox fell at 7.15 PM on 21 March and in 2096 it will fall at 2.02 PM on 19 March, the median time being 26 1/2 hours from these extremes (all times GMT). In 1983 the mean equinox fell at 1.48 AM GMT on 23 March.
Length of equinoctial day and night.
On the day of the equinox, the center of the Sun spends a roughly equal amount of time above and below the horizon at every location on the Earth, so night and day are about the same length. The word "equinox" derives from the Latin words "aequus" (equal) and "nox" (night). In reality, the day is longer than the night at an equinox. Day is usually defined as the period when sunlight reaches the ground in the absence of local obstacles. From the Earth, the Sun appears as a disc rather than a point of light, so when the center of the Sun is below the horizon, its upper edge is visible. Furthermore, the atmosphere refracts light, so even when the upper limb of the Sun is 0.4 degrees below the horizon, its rays curve over the horizon to the ground. In sunrise/sunset tables, the assumed semidiameter (apparent radius) of the Sun is 16 minutes of arc and the atmospheric refraction is assumed to be 34 minutes of arc. Their combination means that when the upper limb of Sun is on the visible horizon, its center is 50 minutes of arc below the geometric horizon, which is the intersection with the celestial sphere of a horizontal plane through the eye of the observer. These effects make the day about 14 minutes longer than the night at the Equator and longer still towards the poles. The real equality of day and night only happens in places far enough from the Equator to have a seasonal difference in day length of at least 7 minutes, actually occurring a few days towards the winter side of each equinox.
Because the Sun is a spherical (rather than a single-point) source of light, the actual crossing of the Sun over the Equator takes approximately 33 hours.
At the equinoxes, the rate of change for the length of daylight and night-time is the greatest. At the poles, the equinox marks the start of the transition from 24 hours of nighttime to 24 hours of daylight (or vice versa). Far north of the Arctic Circle, at Longyearbyen, Svalbard, Norway, there is an additional 15 minutes more daylight every day about the time of the Spring equinox, whereas in Singapore (which is just one degree of latitude north of the Equator), the amount of daylight in each daytime varies by just a few seconds.
Geocentric view of the astronomical seasons.
In the half-year centered on the June solstice, the Sun rises north of east and sets north of west, which means longer days with shorter nights for the northern hemisphere and shorter days with longer nights for the southern hemisphere. In the half-year centered on the December solstice, the Sun rises south of east and sets south of west and the durations of day and night are reversed.
Also on the day of an equinox, the Sun rises everywhere on Earth (except at the poles) at about 06:00 and sets at about 18:00 (local time). These times are not exact for several reasons:
Day arcs of the Sun.
Some of the statements above can be made clearer by picturing the day arc (i.e., the path the Sun tracks along the celestial dome in its diurnal movement). The pictures show this for every hour on equinox day. In addition, some 'ghost' suns are also indicated below the horizon, up to 18° below it; the Sun in such areas still causes twilight. The depictions presented below can be used for both the northern hemisphere and the southern hemisphere. The observer is understood to be sitting near the tree on the island depicted in the middle of the ocean; the green arrows give cardinal directions.
The following special cases are depicted:
Celestial coordinate systems.
The vernal equinox occurs in March, about when the Sun crosses the celestial equator south to north. The term "vernal point" is used for the time of this occurrence and for the direction in space where the Sun is seen at that time, which is the origin of some celestial coordinate systems:
Strictly speaking, at the equinox the Sun's ecliptic longitude is zero. Its latitude will not be exactly zero since the Earth is not exactly in the plane of the ecliptic. (The ecliptic is defined by the center of mass of the Earth and Moon combined.) The modern definition of equinox is the instants when the Sun's apparent longitude is 0° (northward equinox) or 180° (southward equinox). This definition is used when astronomical almanacs are computed.
Because of the precession of the Earth's axis, the position of the vernal point on the celestial sphere changes over time, and the equatorial and the ecliptic coordinate systems change accordingly. Thus when specifying celestial coordinates for an object, one has to specify at what time the vernal point and the celestial equator are taken. That reference time is called the equinox of date.
The autumnal equinox is at ecliptic longitude 180° and at right ascension 12h.
The upper culmination of the vernal point is considered the start of the sidereal day for the observer. The hour angle of the vernal point is, by definition, the observer's sidereal time.
The same is true in western tropical astrology: the vernal equinox is the first point (i.e. the start) of the sign of Aries. In this system, it is of no significance that the equinoxes shift over time with respect to the fixed stars.
Using the current official IAU constellation boundaries – and taking into account the variable precession speed and the rotation of the ecliptic – the equinoxes shift through the constellations as follows (expressed in astronomical year numbering in which the year 0 = 1 BC, −1 = 2 BC, etc.):
Cultural aspects.
A number of traditional spring and autumn (harvest) festivals are celebrated on the date of the equinoxes.
Equinoxes of other planets.
Equinox is a phenomenon that can occur on any planet with a significant tilt to its rotational axis. Most dramatic of these is Saturn, where the equinox places its normally majestic ring system edge-on facing the Sun. As a result, they are visible only as a thin line when seen from Earth. When seen from above – a view seen by humans during an equinox for the first time from the "Cassini" space probe in 2009 – they receive very little sunshine, indeed more planetshine than light from the Sun.
This lack of sunshine occurs once every 14.7 years. It can last a few weeks before and after the exact equinox. The most recent exact equinox for Saturn was on 11 August 2009. Its next equinox will take place on 30 April 2024.
One effect of equinoctial periods is the temporary disruption of communications satellites. For all geostationary satellites, there are a few days around the equinox when the sun goes directly behind the satellite relative to Earth (i.e. within the beam-width of the ground-station antenna) for a short period each day. The Sun's immense power and broad radiation spectrum overload the Earth station's reception circuits with noise and, depending on antenna size and other factors, temporarily disrupt or degrade the circuit. The duration of those effects varies but can range from a few minutes to an hour. (For a given frequency band, a larger antenna has a narrower beam-width and hence experiences shorter duration "Sun outage" windows.)

</doc>
<doc id="10101" url="http://en.wikipedia.org/wiki?curid=10101" title="Eugene Wigner">
Eugene Wigner

Eugene Paul "E. P." Wigner (Hungarian: "Wigner Jenő Pál"; November 17, 1902 – January 1, 1995), was a Hungarian American theoretical physicist and mathematician. He received a share of the Nobel Prize in Physics in 1963 "for his contributions to the theory of the atomic nucleus and the elementary particles, particularly through the discovery and application of fundamental symmetry principles"; the other half of the award was shared between Maria Goeppert-Mayer and J. Hans D. Jensen. Wigner is notable for having laid the foundation for the theory of symmetries in quantum mechanics as well as for his research into the structure of the atomic nucleus. It was Eugene Wigner who first identified Xe-135 "poisoning" in nuclear reactors, and for this reason it is sometimes referred to as "Wigner poisoning". Wigner is also important for his work in pure mathematics, having authored a number of theorems. In particular, Wigner's theorem is a cornerstone in the mathematical formulation of quantum mechanics.
Early life.
Wigner Jenő Pál was born in Budapest, Austria-Hungary on November 17, 1902, to middle class Jewish parents, Elisabeth (Einhorn) and Anthony Wigner, a leather tanner. He had an older sister, Bertha, known as Biri, and a younger sister Margit, known as Manci, who later married British theoretical physicist Paul Dirac. He was home schooled by a professional teacher until the age of 9, when he started school at the third grade. During this period, Wigner developed an interest in mathematical problems. At the age of 11, Wigner contracted what his doctors believed to be tuberculosis. His parents sent him to live for six weeks in a sanatorium in the Austrian mountains, before the doctors concluded that the diagnosis was mistaken.
Wigner's family was Jewish, but not religiously observant, and his Bar Mitzvah was a secular one. From 1915 through 1919, he studied at the secondary grammar school called Fasori Evangélikus Gimnázium, the school his father had attended. Religious education was compulsory, and he attended classes in Judaism taught by a rabbi. A fellow student was János von Neumann, who was a year behind Wigner. They both benefited from the instruction of the noted mathematics teacher László Rátz. In 1919, to escape the Béla Kun communist regime, the Wigner family briefly fled to Austria, returning to Hungary after Kun's downfall. Partly as a reaction to the prominence of Jews in the Kun regime, the family converted to Lutheranism. Wigner explained later in his life that his family decision to convert to Lutheranism "was not at heart a religious decision but an anti-communist one". On religious views, Wigner was an atheist.
After graduating from the secondary school in 1920, Wigner enrolled at the Budapest University of Technical Sciences, known as the "Műegyetem". He was not happy with the courses on offer, and in 1921 enrolled at the Technische Hochschule in Berlin (today the Technische Universität Berlin), where he studied chemical engineering. He also attended the Wednesday afternoon colloquia of the German Physical Society. These colloquia featured such luminaries as Max Planck, Max von Laue, Rudolf Ladenburg, Werner Heisenberg, Walther Nernst, Wolfgang Pauli, and Albert Einstein. Wigner also met the physicist Leó Szilárd, who at once became Wigner's closest friend. A third experience in Berlin was formative. Wigner worked at the Kaiser Wilhelm Institute for Physical Chemistry and Electrochemistry (now the Fritz Haber Institute), and there he met Michael Polanyi, who became, after László Rátz, Wigner's greatest teacher. Polanyi supervised Wigner's DSc thesis, "Bildung und Zerfall von Molekülen" ("Formation and Decay of Molecules").
Middle years.
Wigner returned to Budapest, where he went to work at his father's tannery, but in 1926, he accepted an offer from Karl Weissenberg at the Kaiser Wilhelm Institute in Berlin. Weissenberg wanted someone to assist him with his work on x-ray crystallography, and Polanyi had recommended Wigner. After six months as Weissenberg's assistant, Wigner went to work for Richard Becker for two semesters. Wigner explored quantum mechanics, studying the work of Erwin Schrödinger. He also delved into the group theory of Ferdinand Frobenius and Eduard Ritter von Weber.
Wigner received a request from Arnold Sommerfeld to work in Göttingen as an assistant to the great mathematician David Hilbert. This proved a disappointment, as Hilbert's interests had shifted to logic. Wigner nonetheless studied independently. He laid the foundation for the theory of symmetries in quantum mechanics and in 1927 introduced what is now known as the Wigner D-matrix. Wigner and Hermann Weyl were responsible for introducing group theory into quantum mechanics. The latter had written a standard text, "Group Theory and Quantum Mechanics" (1928), but it was not easy to understand, especially for younger physicists. Wigner's "Group Theory and Its Application to the Quantum Mechanics of Atomic Spectra" (1931) made group theory accessible to a wider audience.
In the late 1930s, Wigner extended his research into atomic nuclei. He developed an important general theory of nuclear reactions, the Wigner–Eisenbud R-matrix theory, published in 1947. By 1929, his papers were drawing notice in the world of physics. In 1930, Princeton University recruited Wigner for a one-year lectureship, at 7 times the salary that he had been drawing in Europe. Princeton recruited von Neumann at the same time. Wigner and von Neumann had collaborated on three papers together in 1928 and two in 1929. They anglicized their first names to "Eugene" and "John", respectively. When their year was up, Princeton offered a five-year contract as visiting professors for half the year. The Technische Hochschule responded with a teaching assignment for the other half of the year. This was very timely, since the Nazis soon rose to power in Germany. At Princeton in 1934, Wigner introduced his sister Manci to the physicist Paul Dirac, whom she married.
Princeton did not rehire Wigner when his contract ran out in 1936. Through Gregory Breit, Wigner found new employment at the University of Wisconsin. There he met his first wife, Amelia Frank, who was a physics student there. However she died unexpectedly in 1937, leaving Wigner distraught. He therefore accepted a 1938 offer from Princeton to return there. Wigner became a naturalized citizen of the United States on January 8, 1937, and he brought his parents to the United States.
Manhattan Project.
Although he was a professed political amateur, on August 2, 1939, he introduced Leó Szilárd to Albert Einstein for a meeting that resulted in the Einstein-Szilárd letter which urged President Franklin D. Roosevelt to initiate the Manhattan Project to develop atomic bombs. Wigner remained fearful of the Germans acquiring an atomic bomb after the war began, and even refused to have his fingerprints taken because he feared they would be used to track him down if Germany won. "Thoughts of being murdered," he later recalled, "focus your mind wonderfully."
On June 4, 1941, Wigner married his second wife, Mary Annette Wheeler, a professor of physics at Vassar College, who had completed her Ph.D. at Yale University in 1932. They remained married until her death in 1977. They had two children, David Wigner and Martha Wigner Upton (1944-2011).
During the Manhattan Project, Wigner led a team that included Alvin Weinberg, Katherine Way, Gale Young and Edward Creutz. The group's task was to design the production nuclear reactors that would convert uranium into weapons grade plutonium. At the time, reactors existed only on paper, and no reactor had yet gone critical. In July 1942, Wigner chose a conservative 100 MW design, with a graphite neutron moderator and water cooling. Wigner was present at a converted rackets court under the stands at the University of Chicago's abandoned Stagg Field on December 2, 1942, when the world's first atomic reactor, Chicago Pile One (CP-1) achieved a nuclear chain reaction (a critical reaction).
Wigner was disappointed that DuPont was given responsibility for the detailed design of the reactors, not just their construction. He threatened to resign in February 1943, but was talked out of it by the head of the Metallurgical Laboratory, Arthur Compton, who sent him on vacation instead. As it turned out, a design decision by DuPont to give the reactor additional load tubes for more uranium saved the project when neutron poisoning became a problem. During the 1950s, he would even work for DuPont on the Savannah River Site. Wigner did not regret working on the Manhattan Project, and sometimes wished the atomic bomb had been ready a year earlier.
Later years.
In 1945, Wigner accepted a position as the Director of Research at the Clinton Laboratory (now the Oak Ridge National Laboratory) in Oak Ridge, Tennessee. When the newly created Atomic Energy Commission took charge of the laboratory's operations at the start of 1947, Wigner feared that many of the technical decisions would be made in Washington. He also saw the Army's continuation of wartime security policies at the laboratory as a "meddlesome oversight", interfering with research. Feeling unsuited to a managerial role in such an environment, he left Oak Ridge at the end of summer in 1947 and returned to Princeton University. He maintained a consulting role with the facility for many years. In the postwar period he served on a number of government bodies, including the National Bureau of Standards from 1947 to 1951, the mathematics panel of the National Research Council from 1951 to 1954, the physics panel of the National Science Foundation, and the influential General Advisory Committee of the Atomic Energy Commission from 1952 to 1957 and again from 1959 to 1964. He also contributed to civil defense.
In 1960, Wigner published a now classic article on the philosophy of mathematics and of physics, which has become his best-known work outside of technical mathematics and physics, "The Unreasonable Effectiveness of Mathematics in the Natural Sciences". He argued that biology and cognition could be the origin of physical concepts, as we humans perceive them, and that the happy coincidence that mathematics and physics were so well matched, seemed to be "unreasonable" and hard to explain. His reasoning was resisted by the Harvard mathematician Andrew M. Gleason.
In 1963, Wigner was awarded the Nobel Prize in Physics. He professed to never have considered the possibility that this might occur, and he added: "I never expected to get my name in the newspapers without doing something wicked." Wigner also won the Enrico Fermi award in 1958, and the National Medal of Science in 1969. In 1968 he gave the Josiah Willard Gibbs lecture. In 1992, at the age of 90, Wigner published a memoir, "The Recollections of Eugene P. Wigner" with Andrew Szanton. Wigner died three years later in Princeton, New Jersey. One of his significant students was Abner Shimony. Wigner's third wife was Eileen Clare-Patton Hamilton Wigner ("Pat") (1915–2010), the widow of another physicist, Donald Ross Hamilton, the Dean of the Graduate School at Princeton University who had died in 1972.
Near the end of his life, Wigner's thoughts turned more philosophical. In his memoirs, Wigner said: "The full meaning of life, the collective meaning of all human desires, is fundamentally a mystery beyond our grasp. As a young man, I chafed at this state of affairs. But by now I have made peace with it. I even feel a certain honor to be associated with such a mystery." He became interested in the Vedanta philosophy of Hinduism, particularly its ideas of the universe as an all pervading consciousness. In his collection of essays "Symmetries and Reflections – Scientific Essays", he commented "It was not possible to formulate the laws (of quantum theory) in a fully consistent way without reference to consciousness."
Wigner also conceived the "Wigner's friend" thought experiment in physics, which is an extension of the "Schrödinger's cat" thought experiment. The "Wigner's friend" experiment asks the question: "At what stage does a 'measurement' take place?" Wigner designed the experiment to highlight how he believed that consciousness is necessary to the quantum-mechanical measurement processes.

</doc>
<doc id="10103" url="http://en.wikipedia.org/wiki?curid=10103" title="Electroweak interaction">
Electroweak interaction

In particle physics, the electroweak interaction is the unified description of two of the four known fundamental interactions of nature: electromagnetism and the weak interaction. Although these two forces appear very different at everyday low energies, the theory models them as two different aspects of the same force. Above the unification energy, on the order of 100 GeV, they would merge into a single electroweak force. Thus, if the universe is hot enough (approximately 1015 K, a temperature exceeded until shortly after the Big Bang), then the electromagnetic force and weak force merge into a combined electroweak force. During the electroweak epoch, the electroweak force separated from the strong force. During the quark epoch, the electroweak force split into the electromagnetic and weak force.
For contributions to the unification of the weak and electromagnetic interaction between elementary particles, Sheldon Glashow, Abdus Salam, and Steven Weinberg were awarded the Nobel Prize in Physics in 1979. The existence of the electroweak interactions was experimentally established in two stages, the first being the discovery of neutral currents in neutrino scattering by the Gargamelle collaboration in 1973, and the second in 1983 by the UA1 and the UA2 collaborations that involved the discovery of the W and Z gauge bosons in proton–antiproton collisions at the converted Super Proton Synchrotron. In 1999, Gerardus 't Hooft and Martinus Veltman were awarded the Nobel prize for showing that the electroweak theory is renormalizable.
Formulation.
Mathematically, the unification is accomplished under an "SU"(2) × "U"(1) gauge group. The corresponding gauge bosons are the three W bosons of weak isospin from SU(2) (#redirect , #redirect , and #redirect ), and the #redirect boson of weak hypercharge from U(1), respectively, all of which are massless.
In the Standard Model, the #redirect [[Template:Subatomic particle]] and #redirect [[Template:Subatomic particle]] bosons, and the photon, are produced by the spontaneous symmetry breaking of the electroweak symmetry from "SU"(2) × "U"(1)"Y" to "U"(1)em, caused by the Higgs mechanism (see also Higgs boson). "U"(1)"Y" and "U"(1)em are different copies of "U"(1); the generator of "U"(1)em is given by "Q" = "Y"/2 + "I"3, where "Y" is the generator of "U"(1)"Y" (called the weak hypercharge), and "I"3 is one of the "SU"(2) generators (a component of weak isospin).
The spontaneous symmetry breaking causes the #redirect and #redirect bosons to coalesce together into two different bosons – the #redirect boson, and the photon (γ) as follows:
Where θW is the "weak mixing angle". The axes representing the particles have essentially just been rotated, in the (#redirect , #redirect ) plane, by the angle θW. This also introduces a discrepancy between the mass of the #redirect and the mass of the #redirect particles (denoted as MZ and MW, respectively);
The distinction between electromagnetism and the weak force arises because there is a (nontrivial) linear combination of "Y" and "I"3 that vanishes for the Higgs boson (it is an eigenstate of both "Y" and "I"3, so the coefficients may be taken as −"I"3 and "Y"): "U"(1)em is defined to be the group generated by this linear combination, and is unbroken because it does not interact with the Higgs.
Lagrangian.
Before electroweak symmetry breaking.
The Lagrangian for the electroweak interactions is divided into four parts before electroweak symmetry breaking
The formula_4 term describes the interaction between the three W particles and the B particle.
where formula_6 (formula_7) and formula_8 are the field strength tensors for the weak isospin and weak hypercharge fields.
formula_9 is the kinetic term for the Standard Model fermions. The interaction of the gauge bosons and the fermions are through the gauge covariant derivative.
where the subscript formula_11 runs over the three generations of fermions, formula_12, formula_13, and formula_14 are the left-handed doublet, right-handed singlet up, and right handed singlet down quark fields, and formula_15 and formula_16 are the left-handed doublet and right-handed singlet electron fields.
The "h" term describes the Higgs field F.
The "y" term gives the Yukawa interaction that generates the fermion masses after the Higgs acquires a vacuum expectation value.
After electroweak symmetry breaking.
The Lagrangian reorganizes itself after the Higgs boson acquires a vacuum expectation value. Due to its complexity, this Lagrangian is best described by breaking it up into several parts as follows.
The kinetic term formula_20 contains all the quadratic terms of the Lagrangian, which include the dynamic terms (the partial derivatives) and the mass terms (conspicuously absent from the Lagrangian before symmetry breaking)
where the sum runs over all the fermions of the theory (quarks and leptons), and the fields formula_22, formula_23, formula_24, and formula_25 are given as
The neutral current formula_27 and charged current formula_28 components of the Lagrangian contain the interactions between the fermions and gauge bosons.
where the electromagnetic current formula_30 and the neutral weak current formula_31 are
and
formula_34 and formula_35 are the fermions' electric charges and weak isospin.
The charged current part of the Lagrangian is given by
formula_37 contains the Higgs three-point and four-point self interaction terms.
formula_39 contains the Higgs interactions with gauge vector bosons.
formula_41 contains the gauge three-point self interactions.
formula_43 contains the gauge four-point self interactions
and formula_45 contains the Yukawa interactions between the fermions and the Higgs field.
Note the formula_47 factors in the weak couplings: these factors project out the left handed components of the spinor fields. This is why electroweak theory (after symmetry breaking) is commonly said to be a chiral theory.

</doc>
<doc id="10104" url="http://en.wikipedia.org/wiki?curid=10104" title="Elara">
Elara

Elara may refer to one of the following:

</doc>
<doc id="10105" url="http://en.wikipedia.org/wiki?curid=10105" title="Erasmus Reinhold">
Erasmus Reinhold

Erasmus Reinhold (October 22, 1511 – February 19, 1553) was a German astronomer and mathematician, considered to be the most influential astronomical pedagogue of his generation. He was born and died in Saalfeld, Saxony.
He was educated, under Jacob Milich, at the University of Wittenberg, where he was first elected dean and later became rector. In 1536 he was appointed professor of higher mathematics by Philipp Melanchthon. In contrast to the limited modern definition, "mathematics" at the time also included applied mathematics, especially astronomy. His colleague, Georg Joachim Rheticus, also studied at Wittenberg and was appointed professor of lower mathematics in 1536.
Reinhold catalogued a large number of stars. His publications on astronomy include a commentary (1542, 1553) on Georg Purbach's "Theoricae novae planetarum". Reinhold knew about Copernicus and his heliocentric ideas prior to the publication of "De revolutionibis" and made a favourable reference to him in his commentary on Purbach. However, Reinhold (like other astronomers before Kepler and Galileo) translated Copernicus' mathematical methods back into a geocentric system, rejecting heliocentric cosmology on physical and theological grounds. 
Duke Albert of Brandenburg Prussia supported Reinhold and financed the printing of Reinhold's "Prutenicae Tabulae" or "Prussian Tables". These astronomical tables helped to disseminate calculation methods of Copernicus throughout the Empire, however, Gingerich notes that they showed a "notable lack of commitment" to heliocentricity and were "carefully framed" to be independent of the movement of the Earth. Both Reinholds's "Prutenic Tables" and Copernicus' studies were the foundation for the Calendar Reform by Pope Gregory XIII in 1582. 
It was Reinhold's heavily annotated copy of "De revolutionibus" in the Royal Observatory, Edinburgh, that started Owen Gingerich on his search for copies of the first and second editions which he describes in "The Book Nobody Read". In Reinhold's unpublished commentary on "De revolutionibus", he calculated the distance from the Earth to the sun. He "massaged" his calculation method in order to arrive at an answer close to that of Ptolemy. 
His name has been given to a prominent lunar impact crater that lies to the south-southwest of the crater Copernicus, on the Mare Insularum.

</doc>
<doc id="10106" url="http://en.wikipedia.org/wiki?curid=10106" title="Earthquake">
Earthquake

An earthquake (also known as a quake, tremor or temblor) is the perceptible shaking of the surface of the Earth, which can be violent enough to destroy major buildings and kill thousands of people. The severity of the shaking can range from barely felt to violent enough to toss people around. Earthquakes have destroyed whole cities. They result from the sudden release of energy in the Earth's crust that creates seismic waves. The seismicity, seismism or seismic activity of an area refers to the frequency, type and size of earthquakes experienced over a period of time.
Earthquakes are measured using observations from seismometers. The moment magnitude is the most common scale on which earthquakes larger than approximately 5 are reported for the entire globe. The more numerous earthquakes smaller than magnitude 5 reported by national seismological observatories are measured mostly on the local magnitude scale, also referred to as the Richter magnitude scale. These two scales are numerically similar over their range of validity. Magnitude 3 or lower earthquakes are mostly almost imperceptible or weak and magnitude 7 and over potentially cause serious damage over larger areas, depending on their depth. The largest earthquakes in historic times have been of magnitude slightly over 9, although there is no limit to the possible magnitude. The most recent large earthquake of magnitude 9.0 or larger was a 9.0 magnitude earthquake in Japan in 2011 (as of March 2014[ [update]]), and it was the largest Japanese earthquake since records began. Intensity of shaking is measured on the modified Mercalli scale. The shallower an earthquake, the more damage to structures it causes, all else being equal.
At the Earth's surface, earthquakes manifest themselves by shaking and sometimes displacement of the ground. When the epicenter of a large earthquake is located offshore, the seabed may be displaced sufficiently to cause a tsunami. Earthquakes can also trigger landslides, and occasionally volcanic activity.
In its most general sense, the word "earthquake" is used to describe any seismic event — whether natural or caused by humans — that generates seismic waves. Earthquakes are caused mostly by rupture of geological faults, but also by other events such as volcanic activity, landslides, mine blasts, and nuclear tests. An earthquake's point of initial rupture is called its focus or hypocenter. The epicenter is the point at ground level directly above the hypocenter.
Naturally occurring earthquakes.
Tectonic earthquakes occur anywhere in the earth where there is sufficient stored elastic strain energy to drive fracture propagation along a fault plane. The sides of a fault move past each other smoothly and aseismically only if there are no irregularities or asperities along the fault surface that increase the frictional resistance. Most fault surfaces do have such asperities and this leads to a form of stick-slip behaviour. Once the fault has locked, continued relative motion between the plates leads to increasing stress and therefore, stored strain energy in the volume around the fault surface. This continues until the stress has risen sufficiently to break through the asperity, suddenly allowing sliding over the locked portion of the fault, releasing the stored energy. This energy is released as a combination of radiated elastic strain seismic waves, frictional heating of the fault surface, and cracking of the rock, thus causing an earthquake. This process of gradual build-up of strain and stress punctuated by occasional sudden earthquake failure is referred to as the elastic-rebound theory. It is estimated that only 10 percent or less of an earthquake's total energy is radiated as seismic energy. Most of the earthquake's energy is used to power the earthquake fracture growth or is converted into heat generated by friction. Therefore, earthquakes lower the Earth's available elastic potential energy and raise its temperature, though these changes are negligible compared to the conductive and convective flow of heat out from the Earth's deep interior.
Earthquake fault types.
There are three main types of fault, all of which may cause an interplate earthquake: normal, reverse (thrust) and strike-slip. Normal and reverse faulting are examples of dip-slip, where the displacement along the fault is in the direction of dip and movement on them involves a vertical component. Normal faults occur mainly in areas where the crust is being extended such as a divergent boundary. Reverse faults occur in areas where the crust is being shortened such as at a convergent boundary. Strike-slip faults are steep structures where the two sides of the fault slip horizontally past each other; transform boundaries are a particular type of strike-slip fault. Many earthquakes are caused by movement on faults that have components of both dip-slip and strike-slip; this is known as oblique slip.
Reverse faults, particularly those along convergent plate boundaries are associated with the most powerful earthquakes, megathrust earthquakes, including almost all of those of magnitude 8 or more. Strike-slip faults, particularly continental transforms, can produce major earthquakes up to about magnitude 8. Earthquakes associated with normal faults are generally less than magnitude 7. For every unit increase in magnitude, there is a roughly thirtyfold increase in the energy released. For instance, an earthquake of magnitude 6.0 releases approximately 30 times more energy than a 5.0 magnitude earthquake and a 7.0 magnitude earthquake releases 900 times (30 × 30) more energy than a 5.0 magnitude of earthquake. An 8.6 magnitude earthquake releases the same amount of energy as 10,000 atomic bombs that were used in World War II.
This is so because the energy released in an earthquake, and thus its magnitude, is proportional to the area of the fault that ruptures and the stress drop. Therefore, the longer the length and the wider the width of the faulted area, the larger the resulting magnitude. The topmost, brittle part of the Earth's crust, and the cool slabs of the tectonic plates that are descending down into the hot mantle, are the only parts of our planet which can store elastic energy and release it in fault ruptures. Rocks hotter than about 300 degrees Celsius flow in response to stress; they do not rupture in earthquakes. The maximum observed lengths of ruptures and mapped faults (which may break in a single rupture) are approximately 1000 km. Examples are the earthquakes in Chile, 1960; Alaska, 1957; Sumatra, 2004, all in subduction zones. The longest earthquake ruptures on strike-slip faults, like the San Andreas Fault (1857, 1906), the North Anatolian Fault in Turkey (1939) and the Denali Fault in Alaska (2002), are about half to one third as long as the lengths along subducting plate margins, and those along normal faults are even shorter.
The most important parameter controlling the maximum earthquake magnitude on a fault is however not the maximum available length, but the available width because the latter varies by a factor of 20. Along converging plate margins, the dip angle of the rupture plane is very shallow, typically about 10 degrees. Thus the width of the plane within the top brittle crust of the Earth can become 50 to 100 km (Japan, 2011; Alaska, 1964), making the most powerful earthquakes possible.
Strike-slip faults tend to be oriented near vertically, resulting in an approximate width of 10 km within the brittle crust, thus earthquakes with magnitudes much larger than 8 are not possible. Maximum magnitudes along many normal faults are even more limited because many of them are located along spreading centers, as in Iceland, where the thickness of the brittle layer is only about 6 km.
In addition, there exists a hierarchy of stress level in the three fault types. Thrust faults are generated by the highest, strike slip by intermediate, and normal faults by the lowest stress levels. This can easily be understood by considering the direction of the greatest principal stress, the direction of the force that 'pushes' the rock mass during the faulting. In the case of normal faults, the rock mass is pushed down in a vertical direction, thus the pushing force (greatest principal stress) equals the weight of the rock mass itself. In the case of thrusting, the rock mass 'escapes' in the direction of the least principal stress, namely upward, lifting the rock mass up, thus the overburden equals the least principal stress. Strike-slip faulting is intermediate between the other two types described above. This difference in stress regime in the three faulting environments can contribute to differences in stress drop during faulting, which contributes to differences in the radiated energy, regardless of fault dimensions.
Earthquakes away from plate boundaries.
Where plate boundaries occur within the continental lithosphere, deformation is spread out over a much larger area than the plate boundary itself. In the case of the San Andreas fault continental transform, many earthquakes occur away from the plate boundary and are related to strains developed within the broader zone of deformation caused by major irregularities in the fault trace (e.g., the "Big bend" region). The Northridge earthquake was associated with movement on a blind thrust within such a zone. Another example is the strongly oblique convergent plate boundary between the Arabian and Eurasian plates where it runs through the northwestern part of the Zagros mountains. The deformation associated with this plate boundary is partitioned into nearly pure thrust sense movements perpendicular to the boundary over a wide zone to the southwest and nearly pure strike-slip motion along the Main Recent Fault close to the actual plate boundary itself. This is demonstrated by earthquake focal mechanisms.
All tectonic plates have internal stress fields caused by their interactions with neighbouring plates and sedimentary loading or unloading (e.g. deglaciation). These stresses may be sufficient to cause failure along existing fault planes, giving rise to intraplate earthquakes.
Shallow-focus and deep-focus earthquakes.
The majority of tectonic earthquakes originate at the ring of fire in depths not exceeding tens of kilometers. Earthquakes occurring at a depth of less than 70 km are classified as 'shallow-focus' earthquakes, while those with a focal-depth between 70 and 300 km are commonly termed 'mid-focus' or 'intermediate-depth' earthquakes. In subduction zones, where older and colder oceanic crust descends beneath another tectonic plate, deep-focus earthquakes may occur at much greater depths (ranging from 300 up to 700 kilometers). These seismically active areas of subduction are known as Wadati-Benioff zones. Deep-focus earthquakes occur at a depth where the subducted lithosphere should no longer be brittle, due to the high temperature and pressure. A possible mechanism for the generation of deep-focus earthquakes is faulting caused by olivine undergoing a phase transition into a spinel structure.
Earthquakes and volcanic activity.
Earthquakes often occur in volcanic regions and are caused there, both by tectonic faults and the movement of magma in volcanoes. Such earthquakes can serve as an early warning of volcanic eruptions, as during the Mount St. Helens eruption of 1980. Earthquake swarms can serve as markers for the location of the flowing magma throughout the volcanoes. These swarms can be recorded by seismometers and tiltmeters (a device that measures ground slope) and used as sensors to predict imminent or upcoming eruptions.
Rupture dynamics.
A tectonic earthquake begins by an initial rupture at a point on the fault surface, a process known as nucleation. The scale of the nucleation zone is uncertain, with some evidence, such as the rupture dimensions of the smallest earthquakes, suggesting that it is smaller than 100 m while other evidence, such as a slow component revealed by low-frequency spectra of some earthquakes, suggest that it is larger. The possibility that the nucleation involves some sort of preparation process is supported by the observation that about 40% of earthquakes are preceded by foreshocks. Once the rupture has initiated, it begins to propagate along the fault surface. The mechanics of this process are poorly understood, partly because it is difficult to recreate the high sliding velocities in a laboratory. Also the effects of strong ground motion make it very difficult to record information close to a nucleation zone.
Rupture propagation is generally modeled using a fracture mechanics approach, likening the rupture to a propagating mixed mode shear crack. The rupture velocity is a function of the fracture energy in the volume around the crack tip, increasing with decreasing fracture energy. The velocity of rupture propagation is orders of magnitude faster than the displacement velocity across the fault. Earthquake ruptures typically propagate at velocities that are in the range 70–90% of the S-wave velocity, and this is independent of earthquake size. A small subset of earthquake ruptures appear to have propagated at speeds greater than the S-wave velocity. These supershear earthquakes have all been observed during large strike-slip events. The unusually wide zone of coseismic damage caused by the 2001 Kunlun earthquake has been attributed to the effects of the sonic boom developed in such earthquakes. Some earthquake ruptures travel at unusually low velocities and are referred to as slow earthquakes. A particularly dangerous form of slow earthquake is the tsunami earthquake, observed where the relatively low felt intensities, caused by the slow propagation speed of some great earthquakes, fail to alert the population of the neighbouring coast, as in the 1896 Meiji-Sanriku earthquake.
Tidal forces.
Research work has shown a robust correlation between small tidally induced forces and non-volcanic tremor activity.
Earthquake clusters.
Most earthquakes form part of a sequence, related to each other in terms of location and time. Most earthquake clusters consist of small tremors that cause little to no damage, but there is a theory that earthquakes can recur in a regular pattern.
Aftershocks.
An aftershock is an earthquake that occurs after a previous earthquake, the mainshock. An aftershock is in the same region of the main shock but always of a smaller magnitude. If an aftershock is larger than the main shock, the aftershock is redesignated as the main shock and the original main shock is redesignated as a foreshock. Aftershocks are formed as the crust around the displaced fault plane adjusts to the effects of the main shock.
Earthquake swarms.
Earthquake swarms are sequences of earthquakes striking in a specific area within a short period of time. They are different from earthquakes followed by a series of aftershocks by the fact that no single earthquake in the sequence is obviously the main shock, therefore none have notable higher magnitudes than the other. An example of an earthquake swarm is the 2004 activity at Yellowstone National Park. In August 2012, a swarm of earthquakes shook Southern California's Imperial Valley, showing the most recorded activity in the area since the 1970s.
Earthquake storms.
Sometimes a series of earthquakes occur in a sort of earthquake storm, where the earthquakes strike a fault in clusters, each triggered by the shaking or stress redistribution of the previous earthquakes. Similar to aftershocks but on adjacent segments of fault, these storms occur over the course of years, and with some of the later earthquakes as damaging as the early ones. Such a pattern was observed in the sequence of about a dozen earthquakes that struck the North Anatolian Fault in Turkey in the 20th century and has been inferred for older anomalous clusters of large earthquakes in the Middle East.
Size and frequency of occurrence.
It is estimated that around 500,000 earthquakes occur each year, detectable with current instrumentation. About 100,000 of these can be felt. Minor earthquakes occur nearly constantly around the world in places like California and Alaska in the U.S., as well as in El Salvador, Mexico, Guatemala, Chile, Peru, Indonesia, Iran, Pakistan, the Azores in Portugal, Turkey, New Zealand, Greece, Italy, India, Nepal and Japan, but earthquakes can occur almost anywhere, including Downstate New York, England, and Australia. Larger earthquakes occur less frequently, the relationship being exponential; for example, roughly ten times as many earthquakes larger than magnitude 4 occur in a particular time period than earthquakes larger than magnitude 5. In the (low seismicity) United Kingdom, for example, it has been calculated that the average recurrences are:
an earthquake of 3.7–4.6 every year, an earthquake of 4.7–5.5 every 10 years, and an earthquake of 5.6 or larger every 100 years. This is an example of the Gutenberg–Richter law.
The number of seismic stations has increased from about 350 in 1931 to many thousands today. As a result, many more earthquakes are reported than in the past, but this is because of the vast improvement in instrumentation, rather than an increase in the number of earthquakes. The United States Geological Survey estimates that, since 1900, there have been an average of 18 major earthquakes (magnitude 7.0–7.9) and one great earthquake (magnitude 8.0 or greater) per year, and that this average has been relatively stable. In recent years, the number of major earthquakes per year has decreased, though this is probably a statistical fluctuation rather than a systematic trend. More detailed statistics on the size and frequency of earthquakes is available from the United States Geological Survey (USGS).
A recent increase in the number of major earthquakes has been noted, which could be explained by a cyclical pattern of periods of intense tectonic activity, interspersed with longer periods of low-intensity. However, accurate recordings of earthquakes only began in the early 1900s, so it is too early to categorically state that this is the case.
Most of the world's earthquakes (90%, and 81% of the largest) take place in the 40,000 km long, horseshoe-shaped zone called the circum-Pacific seismic belt, known as the Pacific Ring of Fire, which for the most part bounds the Pacific Plate. Massive earthquakes tend to occur along other plate boundaries, too, such as along the Himalayan Mountains.
With the rapid growth of mega-cities such as Mexico City, Tokyo and Tehran, in areas of high seismic risk, some seismologists are warning that a single quake may claim the lives of up to 3 million people.
Induced seismicity.
While most earthquakes are caused by movement of the Earth's tectonic plates, human activity can also produce earthquakes. Four main activities contribute to this phenomenon: storing large amounts of water behind a dam (and possibly building an extremely heavy building), drilling and injecting liquid into wells, and by coal mining and oil drilling. Perhaps the best known example is the 2008 Sichuan earthquake in China's Sichuan Province in May; this tremor resulted in 69,227 fatalities and is the 19th deadliest earthquake of all time. The Zipingpu Dam is believed to have fluctuated the pressure of the fault 1650 ft away; this pressure probably increased the power of the earthquake and accelerated the rate of movement for the fault. The greatest earthquake in Australia's history is also claimed to be induced by humanity, through coal mining. The city of Newcastle was built over a large sector of coal mining areas. The earthquake has been reported to be spawned from a fault that reactivated due to the millions of tonnes of rock removed in the mining process.
Measuring and locating earthquakes.
Earthquakes can be recorded by seismometers up to great distances, because seismic waves travel through the whole Earth's interior. The absolute magnitude of a quake is conventionally reported by numbers on the moment magnitude scale (formerly Richter scale, magnitude 7 causing serious damage over large areas), whereas the felt magnitude is reported using the modified Mercalli intensity scale (intensity II–XII).
Every tremor produces different types of seismic waves, which travel through rock with different velocities:
Propagation velocity of the seismic waves ranges from approx. 3 km/s up to 13 km/s, depending on the density and elasticity of the medium. In the Earth's interior the shock- or P waves travel much faster than the S waves (approx. relation 1.7 : 1). The differences in travel time from the epicentre to the observatory are a measure of the distance and can be used to image both sources of quakes and structures within the Earth. Also the depth of the hypocenter can be computed roughly.
In solid rock P-waves travel at about 6 to 7 km per second; the velocity increases within the deep mantle to ~13 km/s. The velocity of S-waves ranges from 2–3 km/s in light sediments and 4–5 km/s in the Earth's crust up to 7 km/s in the deep mantle. As a consequence, the first waves of a distant earthquake arrive at an observatory via the Earth's mantle.
On average, the kilometer distance to the earthquake is the number of seconds between the P and S wave times 8. Slight deviations are caused by inhomogeneities of subsurface structure. By such analyses of seismograms the Earth's core was located in 1913 by Beno Gutenberg.
Earthquakes are not only categorized by their magnitude but also by the place where they occur. The world is divided into 754 Flinn–Engdahl regions (F-E regions), which are based on political and geographical boundaries as well as seismic activity. More active zones are divided into smaller F-E regions whereas less active zones belong to larger F-E regions.
Standard reporting of earthquakes includes its magnitude, date and time of occurrence, geographic coordinates of its epicenter, depth of the epicenter, geographical region, distances to population centers, location uncertainty, a number of parameters that are included in USGS earthquake reports (number of stations reporting, number of observations, etc.), and a unique event ID.
Effects of earthquakes.
The effects of earthquakes include, but are not limited to, the following:
Shaking and ground rupture.
Shaking and ground rupture are the main effects created by earthquakes, principally resulting in more or less severe damage to buildings and other rigid structures. The severity of the local effects depends on the complex combination of the earthquake magnitude, the distance from the epicenter, and the local geological and geomorphological conditions, which may amplify or reduce wave propagation. The ground-shaking is measured by ground acceleration.
Specific local geological, geomorphological, and geostructural features can induce high levels of shaking on the ground surface even from low-intensity earthquakes. This effect is called site or local amplification. It is principally due to the transfer of the seismic motion from hard deep soils to soft superficial soils and to effects of seismic energy focalization owing to typical geometrical setting of the deposits.
Ground rupture is a visible breaking and displacement of the Earth's surface along the trace of the fault, which may be of the order of several metres in the case of major earthquakes. Ground rupture is a major risk for large engineering structures such as dams, bridges and nuclear power stations and requires careful mapping of existing faults to identify any which are likely to break the ground surface within the life of the structure.
Landslides and avalanches.
Earthquakes, along with severe storms, volcanic activity, coastal wave attack, and wildfires, can produce slope instability leading to landslides, a major geological hazard. Landslide danger may persist while emergency personnel are attempting rescue.
Fires.
Earthquakes can cause fires by damaging electrical power or gas lines. In the event of water mains rupturing and a loss of pressure, it may also become difficult to stop the spread of a fire once it has started. For example, more deaths in the 1906 San Francisco earthquake were caused by fire than by the earthquake itself.
Soil liquefaction.
Soil liquefaction occurs when, because of the shaking, water-saturated granular material (such as sand) temporarily loses its strength and transforms from a solid to a liquid. Soil liquefaction may cause rigid structures, like buildings and bridges, to tilt or sink into the liquefied deposits. For example, in the 1964 Alaska earthquake, soil liquefaction caused many buildings to sink into the ground, eventually collapsing upon themselves.
Tsunami.
Tsunamis are long-wavelength, long-period sea waves produced by the sudden or abrupt movement of large volumes of water. In the open ocean the distance between wave crests can surpass 100 km, and the wave periods can vary from five minutes to one hour. Such tsunamis travel 600-800 kilometers per hour (373–497 miles per hour), depending on water depth. Large waves produced by an earthquake or a submarine landslide can overrun nearby coastal areas in a matter of minutes. Tsunamis can also travel thousands of kilometers across open ocean and wreak destruction on far shores hours after the earthquake that generated them.
Ordinarily, subduction earthquakes under magnitude 7.5 on the Richter scale do not cause tsunamis, although some instances of this have been recorded. Most destructive tsunamis are caused by earthquakes of magnitude 7.5 or more.
Floods.
A flood is an overflow of any amount of water that reaches land. Floods occur usually when the volume of water within a body of water, such as a river or lake, exceeds the total capacity of the formation, and as a result some of the water flows or sits outside of the normal perimeter of the body. However, floods may be secondary effects of earthquakes, if dams are damaged. Earthquakes may cause landslips to dam rivers, which collapse and cause floods.
The terrain below the Sarez Lake in Tajikistan is in danger of catastrophic flood if the landslide dam formed by the earthquake, known as the Usoi Dam, were to fail during a future earthquake. Impact projections suggest the flood could affect roughly 5 million people.
Human impacts.
An earthquake may cause injury and loss of life, road and bridge damage, general property damage, and collapse or destabilization (potentially leading to future collapse) of buildings. The aftermath may bring disease, lack of basic necessities, and higher insurance premiums.
Major earthquakes.
One of the most devastating earthquakes in recorded history was the 1556 Shaanxi earthquake, which occurred on 23 January 1556 in Shaanxi province, China. More than 830,000 people died. Most houses in the area were yaodongs—dwellings carved out of loess hillsides—and many victims were killed when these structures collapsed. The 1976 Tangshan earthquake, which killed between 240,000 to 655,000 people, was the deadliest of the 20th century.
The 1960 Chilean Earthquake is the largest earthquake that has been measured on a seismograph, reaching 9.5 magnitude on 22 May 1960. Its epicenter was near Cañete, Chile. The energy released was approximately twice that of the next most powerful earthquake, the Good Friday Earthquake (March 27, 1964) which was centered in Prince William Sound, Alaska. The ten largest recorded earthquakes have all been megathrust earthquakes; however, of these ten, only the 2004 Indian Ocean earthquake is simultaneously one of the deadliest earthquakes in history.
Earthquakes that caused the greatest loss of life, while powerful, were deadly because of their proximity to either heavily populated areas or the ocean, where earthquakes often create tsunamis that can devastate communities thousands of kilometers away. Regions most at risk for great loss of life include those where earthquakes are relatively rare but powerful, and poor regions with lax, unenforced, or nonexistent seismic building codes.
Prediction.
Many methods have been developed for predicting the time and place in which earthquakes will occur. Despite considerable research efforts by seismologists, scientifically reproducible predictions cannot yet be made to a specific day or month. However, for well-understood faults the probability that a segment may rupture during the next few decades can be estimated.
Earthquake warning systems have been developed that can provide regional notification of an earthquake in progress, but before the ground surface has begun to move, potentially allowing people within the system's range to seek shelter before the earthquake's impact is felt.
Preparedness.
The objective of earthquake engineering is to foresee the impact of earthquakes on buildings and other structures and to design such structures to minimize the risk of damage. Existing structures can be modified by seismic retrofitting to improve their resistance to earthquakes. Earthquake insurance can provide building owners with financial protection against losses resulting from earthquakes.
Emergency management strategies can be employed by a government or organization to mitigate risks and prepare for consequences.
Historical views.
From the lifetime of the Greek philosopher Anaxagoras in the 5th century BCE to the 14th century CE, earthquakes were usually attributed to "air (vapors) in the cavities of the Earth." Thales of Miletus, who lived from 625–547 (BCE) was the only documented person who believed that earthquakes were caused by tension between the earth and water. Other theories existed, including the Greek philosopher Anaxamines' (585–526 BCE) beliefs that short incline episodes of dryness and wetness caused seismic activity. The Greek philosopher Democritus (460–371 BCE) blamed water in general for earthquakes. Pliny the Elder called earthquakes "underground thunderstorms."
Earthquakes in culture.
Mythology and religion.
In Norse mythology, earthquakes were explained as the violent struggling of the god Loki. When Loki, god of mischief and strife, murdered Baldr, god of beauty and light, he was punished by being bound in a cave with a poisonous serpent placed above his head dripping venom. Loki's wife Sigyn stood by him with a bowl to catch the poison, but whenever she had to empty the bowl the poison dripped on Loki's face, forcing him to jerk his head away and thrash against his bonds, which caused the earth to tremble.
In Greek mythology, Poseidon was the cause and god of earthquakes. When he was in a bad mood, he struck the ground with a trident, causing earthquakes and other calamities. He also used earthquakes to punish and inflict fear upon people as revenge.
In Japanese mythology, Namazu (鯰) is a giant catfish who causes earthquakes. Namazu lives in the mud beneath the earth, and is guarded by the god Kashima who restrains the fish with a stone. When Kashima lets his guard fall, Namazu thrashes about, causing violent earthquakes.
In popular culture.
In modern popular culture, the portrayal of earthquakes is shaped by the memory of great cities laid waste, such as Kobe in 1995 or San Francisco in 1906. Fictional earthquakes tend to strike suddenly and without warning. For this reason, stories about earthquakes generally begin with the disaster and focus on its immediate aftermath, as in "Short Walk to Daylight" (1972), "The Ragged Edge" (1968) or "" (1998). A notable example is Heinrich von Kleist's classic novella, "The Earthquake in Chile", which describes the destruction of Santiago in 1647. Haruki Murakami's short fiction collection After the Quake depicts the consequences of the Kobe earthquake of 1995.
The most popular single earthquake in fiction is the hypothetical "Big One" expected of California's San Andreas Fault someday, as depicted in the novels "Richter 10" (1996) and "Goodbye California" (1977) among other works. Jacob M. Appel's widely anthologized short story, "A Comparative Seismology", features a con artist who convinces an elderly woman that an apocalyptic earthquake is imminent.
Contemporary depictions of earthquakes in film are variable in the manner in which they reflect human psychological reactions to the actual trauma that can be caused to directly afflicted families and their loved ones. Disaster mental health response research emphasizes the need to be aware of the different roles of loss of family and key community members, loss of home and familiar surroundings, loss of essential supplies and services to maintain survival. Particularly for children, the clear availability of caregiving adults who are able to protect, nourish, and clothe them in the aftermath of the earthquake, and to help them make sense of what has befallen them has been shown even more important to their emotional and physical health than the simple giving of provisions. As was observed after other disasters involving destruction and loss of life and their media depictions, such as those of the 2001 World Trade Center Attacks or Hurricane Katrina—and has been recently observed in the 2010 Haiti earthquake, it is also important not to pathologize the reactions to loss and displacement or disruption of governmental administration and services, but rather to validate these reactions, to support constructive problem-solving and reflection as to how one might improve the conditions of those affected.

</doc>
<doc id="10109" url="http://en.wikipedia.org/wiki?curid=10109" title="Esotericism">
Esotericism

Esotericism (or esoterism) signifies the holding of esoteric opinions or beliefs, that is, ideas preserved or understood by a small group of those specially initiated, or of rare or unusual interest. The term derives from the Greek, either from the comparative ἐσώτερος ("esôteros"), "inner", or from its derived adjective ἐσωτερικός "(esôterikos)", "pertaining to the innermost".
The term can also refer to the academic study of esoteric religious movements and philosophies, or to the study of those religious movements and philosophies whose proponents distinguish their beliefs, practices, and experiences from mainstream exoteric and more dogmatic institutionalized traditions.
Examples of esoteric religious movements and philosophies include Alchemy, Anthroposophy, Astrology, early Christian mysticism, The Fourth Way, Tantra, Freemasonry, Gnosticism, Hermetism, Mahavidya, Vamachara, Kabbalah, Magic, Mesmerism, Neoplatonism, Numerology, Perennialism, Rosicrucianism, Scientology, Druze, Sufism, Swedenborgianism, Spiritualism, Taoism, the Alawites, the Theosophy of Jacob Böhme and his followers, the Theosophist movement associated with Helena Blavatsky.
Although esotericism refers to an exploration of the hidden meanings and symbolism in various philosophical, historical, and religious texts, the texts themselves are often central to mainstream religions. For example, the Bible and the Torah are considered esoteric material.
Etymology.
The term derives from the Greek, either from the comparative ἐσώτερος ("esôteros"), "inner", or from its derived adjective ἐσωτερικός ("esôterikos"), "pertaining to the innermost," both compounds of ἔσω ("esô"), "within", thus pertaining to interiority, the initiatic or mysticism, all these terms relating to what lies within a sacred enclosure. Its antonym is "exoteric" or "profane".
Plato, in his dialogue "Alcibíades" (circa 390 BC), uses the expression "ta esô" meaning "the inner things", and in his dialogue "Theaetetus" (circa 360 BC) he uses "ta exô" meaning "the outside things". Aristotle applied this distinction to his own writings. The probable first appearance of the Greek adjective "esôterikos" is in Lucian of Samosata's "The Auction of Lives", § 26, written around AD 166.
The term "esoteric" first appeared in English in the 1660 "History of Philosophy" by Thomas Stanley, in his description of the mystery-school of Pythagoras; the Pythagoreans were divided into "exoteric" (under training), and "esoteric" (admitted into the "inner" circle). A corresponding Gallicism, "ésotérisme", was coined in French by Jacques Matter in 1828, it is first recorded by the OED in 1835, and it was popularized by Eliphas Levi in the 1850s. . It was notably given currency in the English language in the 1880s via the works of theosophist Alfred Sinnett.
Definition.
Among the competing understandings of what unites the various currents designated by "Esotericism" in the scholarly sense, perhaps the most influential has been proposed by Antoine Faivre. His definition is based on the presence in the esoteric currents of four essential characteristics: a theory of correspondences between all parts of the invisible and the visible cosmos, the conviction that nature is a living entity owing to a divine presence or life-force, the need for mediating elements (such as symbols, rituals, angels, visions) in order to access spiritual knowledge, and, fourthly, an experience of personal and spiritual transmutation when arriving at this knowledge. To this are added two non-intrinsic characteristics. Esotericists frequently suggest that there is a concordance between different religious traditions: best example is the belief in "prisca theologia" (ancient theology) or in "philosophia perennis" (perennial philosophy). Finally, esotericism sometimes suggests the idea of a secret transmission of spiritual teachings, through initiation from master to disciple. It should, however, be emphasized that Faivre's definition is one of several divergent understandings of the most appropriate use of the term.
The “perennialist” or “traditionalist” school is represented by authors like the French René Guénon (1886–1951), the Indian Ananda Coomaraswamy (1877–1947), the Swiss Frithjof Schuon (1907–1998), the Italian Julius Evola (1898–1974), the Iranian Seyyed Hossein Nasr (born in 1933), both scholars and esotericists. They postulate that there exists a Primordial Tradition of non-human origin.
In perennialist usage, esotericism is a metaphysical concept referring to a supposed “transcendent unity” of all great religious traditions. Esotericism is the metaphysical point of unity where exoteric religions are believed to converge. 
After all, the esoteric tradition may be recovered if the seeker undergoes initiation.
History.
Since the field of esotericism is not a single tradition but a vast array of often unrelated figures and movements, there is no single historical thread underlying them all.
The developments that one might wish to emphasize in drawing up a history of esotericism furthermore depends on whether esotericism in the dictionary (non-scholarly) or the scholarly sense is intended.
Several historically attested religions emphasize secret or hidden knowledge, and are thus esoteric in the dictionary sense, without necessarily being esoteric movements in the scholarly sense of the word. Thus, the Roman Empire had several mystery religions which emphasized initiation. Some saw Christianity, with its ritual of baptism, as a mystery religion. None of these are "esoteric" in the scholarly sense. The terms "Gnosticism" and "Gnosis" refer to a family of religious movements which claimed to possess secret knowledge (gnosis). Another important movement from the ancient world was Hermeticism or "Hermetism". Both of these are often seen as precursors to esoteric movements in the scholarly sense of the word.
Non-Western traditions can also display the characteristics of esoteric movements. The Ismaili Muslims also stress a distinction between the inner and the outer. It is believed that spiritual salvation is attained by receiving the "Nur" (light) through the "esoteric", that is, spiritual search for enlightenment. Ismaili Islam also has some of the characteristics associated with esotericism as defined by Faivre, e.g. the belief in an intermediate spiritual sphere mediating between humans and the divine. Esoteric movements in Buddhism, which fall under the general category of Vajrayana Buddhism, employ esoteric training into Buddha's teachings, through use of symbols, mantra and hand-gestures, or mudra. Initiation rituals are typically given to students as they progress along these paths, and care is taken not to discuss specific rituals to those lacking the right empowerment.
In order to distinguish esoteric currents based primarily on sources from late Antiquity and the European Middle Ages, from e.g. Islamic or Jewish currents with similar features, the more precise term "Western esotericism" is often employed.
Western esoteric movements in the scholarly sense thus have roots in Antiquity and the Middle Ages. A major phase in the development of Western esotericism begins in the Renaissance, partly as the result of various attempts to revive such earlier movements. During the Italian Renaissance, for example, translators such as Ficino and Pico della Mirandola turned their attention to the classical literature of Neoplatonism, and what was thought to be the pre-Mosaic tradition of Hermeticism. Other pursuits of Antiquity that entered into the mix of esoteric speculation were astrology and alchemy. Beside such revived currents from late Antiquity, a second major source of esoteric speculation is the Kabbalah, which was lifted out of its Jewish context and adapted to a Christian framework by people such as Johannes Reuchlin. Outside the Italian Renaissance, yet another major current of esotericism was initiated by Paracelsus, who combined alchemical and astrological themes (among others) into a complex body of doctrines.
In the early 17th century, esotericism is represented by currents such as Christian theosophy and Rosicrucianism. A century later, esoteric ideas entered various strands of Freemasonry. Later in the 18th century, as well as in the early 19th century, the diffuse movement known as Mesmerism became a major expression of esotericism. In the 19th century, esotericism is also represented by certain aspects of the philosophy, literature and science associated with Romanticism, by spiritualism, and by a notable French wave of occultism.
The major exponent of esotericism in the latter part of the 19th century is the Theosophy of H. P. Blavatsky, not to be confused with the Christian Theosophy mentioned above. In the 20th century, Theosophy was further developed by Annie Besant and Charles Webster Leadbeater, while people like Alice Bailey, Rudolf Steiner and many others, became the source for a whole range of post-theosophical movements such as The Summit Lighthouse. The post-theosophical Anthroposophical movement is a synthesis of occultist, Christian and Neoplatonic ideas with Western esoteric concepts as formulated in the wake of Theosophy. Anthroposophy, which was founded by Rudolf Steiner in the early part of the 20th century, includes esoteric versions of education, agriculture, and medicine.
Yet another notable esoteric strain stems from the teachings of G. I. Gurdjieff and P. D. Ouspensky.
Theosophy is also considered a major influence on the many less institutionally organized varieties of esotericism in metaphysical milieus, "Ascended Master Activities", and within the New Age.
Finally, it can be noted that Carl Gustav Jung can be seen as an exponent of esotericism: his writings concern esoteric subject matter such as alchemy, and rephrased the concept of correspondences in a modern, psychologizing terminology in his theory of synchronicity.
Methodology.
Wouter J. Hanegraaff is Professor of “History of Hermetic Philosophy and Related Currents” at the University of Amsterdam (1999). The Universiteit van Amsterdam (UvA) is the world's first academic institution to have created a complete program for research and teaching in the field of Western Esotericism. He is also president of the European Society for the Study of Western Esotericism. Essential to Hanegraaff’s methodology is what he calls an “empirical” approach, with an informed, open, and, so much as possible, neutral mind. He makes a sharp division between a “religionist” perspective and an “empiricist” one.
Secondly, Hanegraaff follows a distinction between an “emic” and an “etic” approach to religious studies. The emic approach is that of the alchemist or theosopher as an alchemist or theosopher. The etic approach is that of the scholar as an historian, a researcher, with a critical look. An empirical study of esotericism needs “emic material and etic interpretation”.
Pierre A. Riffard (Ph.D., University of the French West Indies) studies the method used by esotericists themselves (alchemists, magicians, Rosicrucians, Anthroposophists...). He examines some of their procedures. 1) Mythological origins. The esotericists trace the origins of their doctrine or practice to an extremely distant past. They situate the life of Hermes in times immemorial. 2) Cosmic cycles. For Gaston Georgel, “history is governed by cycles of 540, 1080 and 2160 years”. 3) The chains of initiation. Some Rosicrucians include Francis Bacon among their masters and trace their origins back to the time of Thutmosis III. 4) The secret books. Esotericists prefer to base their beliefs on secret writings, unknown to the majority of people and inaccessible to the uninitiated: for instance, among the Theosophists, "The Book of Dzyan". 5) Spiritual interpretations. The esotericists are able to endow the most profane texts with an occult meaning. The alchemists discover within the Greek and Roman myths the Great Work of alchemy. 6) Magical uses. A book can be used as a talisman, a divinatory machine... The "Sortes Sanctorum" (Lots of the saints) were, in early Christianity, a divination which consists in taking passages of the Bible at chance, and drawing conclusions from them concerning future. 
Arthur Versluis (Professor, Ph.D., Michigan State University) proposes the term “sympathetic empiricism” as the approach that he finds most amenable in the study of Western Esotericism. 
Esotericism in philosophy.
Leo Strauss.
In the late 1930s, Leo Strauss called for a reconsideration of the "distinction between exoteric (or public) and esoteric (or secret) teaching". In 1952 he published "Persecution and the Art of Writing", arguing that serious writers write Esotericism|esoterically, that is, with multiple or layered meanings, often disguised within irony or paradox, obscure references, even deliberate self-contradiction. Esoteric writing serves several purposes: protecting the philosopher from the retribution of the regime, and protecting the regime from the corrosion of philosophy; it attracts the right kind of reader and repels the wrong kind; and ferreting out the interior message is in itself an exercise of philosophic reasoning. Taking his bearings from his study of Maimonides and Al Farabi, and pointing further back to Plato's discussion of writing as contained in the "Phaedrus", Strauss proposed that the classical and medieval art of "esoteric" writing is the proper medium for philosophic learning: rather than displaying philosophers' thoughts superficially, classical and medieval philosophical texts guide their readers in thinking and learning independently of imparted knowledge. Thus, Strauss agrees with the Socrates of the "Phaedrus", where the Greek indicates that, insofar as writing does not respond when questioned, good writing provokes questions in the reader—questions that orient the reader towards an understanding of problems the author thought about with utmost seriousness.
Strauss's general "hermeneutical" argument—rearticulated throughout his subsequent writings (most notably in "The City and Man" [1978])—is that, prior to the 19th century, Western scholars commonly understood that philosophical writing is not at home in any polity, no matter how liberal. Insofar as it questions conventional wisdom at its roots, philosophy must guard itself especially against those readers who believe themselves authoritative, wise, and liberal defenders of the status quo. In questioning established opinions, or in investigating the principles of morality, philosophers of old found it necessary to convey their messages in an oblique manner. Their "art of writing" was the art of esoteric communication. This was especially apparent in medieval times, when heterodox political thinkers wrote under the threat of the Inquisition or comparably obtuse tribunals.
Strauss's argument is not that the medieval writers he studies reserved one exoteric meaning for the many (hoi polloi) and an esoteric, hidden one for the few (hoi aristoi), but that, through rhetorical stratagems including self-contradiction and hyperboles, these writers succeeded in conveying their proper meaning at the tacit heart of their writings—a heart or message irreducible to "the letter" or historical dimension of texts.
Explicitly following G. E. Lessing's lead, Strauss indicates that medieval political philosophers, no less than their ancient counterparts, carefully adapted their wording to the dominant moral views of their time, lest their writings be condemned as heretical or unjust, not by "the many" (who did not read), but by those "few" whom the many regarded as the most righteous guardians of morality. It was precisely these righteous personalities who would be most inclined to persecute/ostracize anyone who was in the business of exposing the noble or great lie upon which the authority of the few over the many stands or falls.
Further reading.
</dl>

</doc>
<doc id="10110" url="http://en.wikipedia.org/wiki?curid=10110" title="Emperor of Japan">
Emperor of Japan

The Emperor of Japan is the head of the Imperial Family and is the ceremonial head of state of Japan's system of constitutional monarchy. According to the 1947 constitution, he is "the symbol of the State and of the unity of the people." Historically, he is also the highest authority of the Shinto religion as he and his family are said to be the direct descendants of the sun-goddess Amaterasu, and his importance also lies in dealing with heavenly affairs, including Shinto ritual and rites throughout the nation.
In Japanese, the Emperor is called Tennō (天皇), which means "heavenly sovereign". In English, the use of the term Mikado (帝) for the Emperor was once common, but is now considered obsolete.
Currently, the Emperor of Japan is the only remaining monarch in the world reigning under the title of "Emperor". The Imperial House of Japan is the oldest continuing hereditary monarchy in the world. In Kojiki or Nihon Shoki, a book of Japanese history finished in the eighth century, it is said that Japan was founded in 660 BC by Emperor Jimmu. The current Emperor is Akihito, who has been on the Chrysanthemum Throne since he was enthroned after his father, the Emperor Shōwa (Hirohito), died in 1989.
The role of the Emperor of Japan has historically alternated between a largely ceremonial symbolic role and that of an actual imperial ruler. Since the establishment of the first shogunate in 1192, the Emperors of Japan have rarely taken on a role as supreme battlefield commander, unlike many Western monarchs. Japanese Emperors have nearly always been controlled by external political forces, to varying degrees. In fact, from 1192 to 1867, the shoguns, or their "shikken" regents in Kamakura (1203–1333), were the "de facto" rulers of Japan, although they were nominally appointed by the Emperor. After the Meiji restoration in 1867, the Emperor was the embodiment of all sovereign power in the realm, as enshrined in the Meiji Constitution of 1889. His current status as a figurehead dates from the 1947 Constitution.
Since the mid-nineteenth century, the Imperial Palace has been called "Kyūjō" (宮城), then "Kōkyo" (皇居), and is located on the former site of Edo Castle in the heart of Tokyo. Earlier, Emperors resided in Kyoto for nearly eleven centuries.
The Emperor's Birthday (currently celebrated on December 23) is a national holiday.
Modern role.
The Emperor is not even the "nominal" Chief Executive unlike most other constitutional monarchies and he possesses only certain important ceremonial powers. The Constitution states that the Emperor "shall perform only such acts in matters of state as are provided for in the Constitution and he shall not have powers related to government" (). It also stipulates that "the advice and approval of the Cabinet shall be required for all acts of the Emperor in matters of state" (article 3). Article 4 also states that these duties can be delegated by the Emperor as provided for by law. explicitly vests executive power in the Cabinet, of which the Prime Minister is the leader. The Emperor is also not the (ceremonial) commander-in-chief of the Japan Self-Defense Forces. The Japan Self-Defense Forces Act of 1954 also explicitly vests this role with the Prime Minister.
While the Emperor formally appoints the Prime Minister to office, article 6 of the constitution requires him to appoint the candidate "as designated by the Diet", without any right to decline appointment.
Article 6 of the Constitution delegates the Emperor the following ceremonial roles:
The Emperor's other duties is laid down in article 7 of the Constitution, where it is stated that the "Emperor with the advice and approval of the Cabinet, shall perform the following acts in matters of state on behalf of the people":
Regular ceremonies of the Emperor with a constitutional basis are the Imperial Investitures in the Imperial palace and the Speech from the Throne ceremony in the House of Councillors in the National Diet Building. The latter ceremony opens ordinary and extra sessions of the Diet. Ordinary sessions are opened this way each January and also after new elections to the House of Representatives. Extra sessions usually convene in the autumn and are opened then.
History.
Although the emperor has been a symbol of continuity with the past, the degree of power exercised by the Emperor of Japan has varied considerably throughout Japanese history. In the early 7th century, the Emperor began to be called "Son of Heaven" (天子, tenshi　or, 天子様 tenshi-sama).
Origin.
The earliest Emperor recorded in Kojiki and Nihon Shoki is Emperor Jimmu, who is said to be a descendant of Amaterasu's grandson Ninigi who descended from Heaven (Tenson kōrin). According to Nihon Shoki, the Emperors have an unbroken male lineage that goes back more than 2,600 years. The key to knowing the origin of the Japanese imperial line may lie within the ancient imperial tombs known as kofun. However, since the Meiji period, the Imperial Household Agency has refused to open the kofun to the public or to archaeologists, citing their desire not to disturb the spirits of the past Emperors. In December 2006, the Imperial Household Agency reversed its position and decided to allow researchers to enter some of the kofun with no restrictions.
Factional control.
There have been six non-imperial families who have controlled Japanese emperors: the Soga (530s–645), the Fujiwara (850s–1070), the Taira (1159-1180s), the Minamoto (and Kamakura bakufu) (1192–1333), the Ashikaga (1336–1565), and the Tokugawa (1603–1867). However, every shogun from the Minamoto, Ashikaga, and Tokugawa families had to be officially recognized by the emperors, who were still the source of sovereignty, although they could not exercise their powers independently from the Shogunate.
Disputes.
The growth of the samurai class from the 10th century gradually weakened the power of the imperial family over the realm, leading to a time of instability. Emperors have been known to come into conflict with the reigning shogun from time to time. Some instances, such as Emperor Go-Toba's 1221 rebellion against the Kamakura shogunate and the 1336 Kemmu Restoration under Emperor Go-Daigo, show the power struggle between the Imperial House and the military governments of Japan.
Territorial matters.
Until recent centuries, Japan's territory did not include several remote regions of its modern-day territory. The name Nippon came into use only many centuries after the start of the current imperial line. Centralized government only began to appear shortly before and during the time of Prince Shōtoku (572-622). The emperor was more like a revered embodiment of divine harmony than the head of an actual governing administration. In Japan, it has always been easy for ambitious lords to hold actual power, as such positions have not been inherently contradictory to the Emperor's position. Parliamentary government today continues a similar coexistence with the Emperor as have various shoguns, regents, warlords, guardians, etc.
Historically the titles of "Tennō" in Japanese have never included territorial designations as is the case with many European monarchs. The position of emperor is a territory-independent phenomenon—the emperor is the emperor, even if he has followers only in one province (as was the case sometimes with the southern and northern courts).
Shoguns.
From 1192 to 1867, sovereignty of the state was exercised by the shoguns, or their "shikken" regents (1203–1333), whose authority was conferred by Imperial warrant. When Portuguese explorers first came into contact with the Japanese (see "Nanban period"), they described Japanese conditions in analogy, likening the Emperor, with great symbolic authority but little political power, to the Pope, and the Shogun to secular European rulers (e.g., the Holy Roman Emperor). In keeping with the analogy, they even used the term "Emperor" in reference to the shogun/regent, e.g. in the case of Toyotomi Hideyoshi, whom missionaries called "Emperor Taicosama" (from Taiko and the honorific "sama").
Meiji restoration.
After the United States Navy Commodore Matthew C. Perry's Black Ships forcibly opened Japan to foreign trade and the shogunate proved incapable of hindering the "barbarian" interlopers, the Emperor Kōmei began to assert himself politically. By the early 1860s, the relationship between the imperial court and the Shogunate was changing radically. Disaffected domains and ronin began to rally to the call of "sonnō jōi" ("revere the emperor, expel the barbarians"). The domains of Satsuma and Chōshū, historic enemies of the Tokugawa, used this turmoil to unite their forces and won an important military victory outside of Kyoto against Tokugawa forces.
In 1868, imperial "restoration" was declared, and the Shogunate was dissolved. A new constitution described the Emperor as "the head of the Empire, combining in Himself the rights of sovereignty", whose rights included to sanction and promulgate laws, to execute them and to exercise "supreme command of the Army and the Navy". The liaison conference created in 1893 also made the Emperor the leader of the Imperial General Headquarters.
World War II.
The role of the emperor as head of the State Shinto religion was exploited during the war, creating an Imperial cult that led to kamikaze bombers and other fanaticism. This in turn led to the requirement in the Potsdam Declaration for the elimination "for all time [of] the authority and influence of those who have deceived and misled the people of Japan into embarking on world conquest". Following Japan's surrender, the Allies issued the Shinto Directive separating church and state within Japan, leading to the Humanity Declaration of the incumbent Emperor. Subsequently, a new constitution was drafted to define the role of the emperor and the government.
Current constitution.
The constitution provides for a parliamentary system of government and guarantees certain fundamental rights. Under its terms, the Emperor of Japan is "the symbol of the State and of the unity of the people" and exercises a purely ceremonial role without the possession of sovereignty.
The constitution, also known as the "Constitution of the State of Japan" (日本國憲法, Nihonkoku-Kenpō), "Postwar Constitution" (戦後憲法, Sengo-Kenpō) or the "Peace Constitution" (平和憲法, Heiwa-Kenpō), was drawn up under the Allied occupation that followed World War II and was intended to replace Japan's previous militaristic and absolute monarchy system with a form of liberal democracy. Currently, it is a rigid document and no subsequent amendment has been made to it since its adoption.
Education.
The Emperors traditionally had an education officer. In recent times, Emperor Taishō had Count Nogi Maresuke, Emperor Shōwa Marshal-Admiral Marquis Tōgō Heihachirō, and the Reigning Emperor (Akihito) had Elizabeth Gray Vining as well as as their tutors.
Addressing and naming.
There are two Japanese words equivalent to the English word "emperor": "tennō" (天皇, lit. "heavenly sovereign"), which is used exclusively to refer to an emperor of Japan, and "kōtei" (皇帝, the title used for Chinese emperors), which is used primarily to describe non-Japanese emperors. Sumeramikoto (lit. "the Imperial person") was also used in Old Japanese. The term "tennō" was used by the emperors up until the Middle Ages; then, following a period of disuse, it was used again from the 19th century. In English, the term mikado (御門 or 帝 or みかど), literally meaning "the honorable gate" (i.e. the gate of the imperial palace, which indicates the person who lives in and possesses the palace), was once used (as in "The Mikado", a 19th-century operetta), but this term is now obsolete. (Compare Sublime Porte, an old term for the Ottoman government.)
Traditionally, the Japanese considered it disrespectful to call any person by his given name, and more so for a person of noble rank. This convention is more relaxed in modern age and now it is acceptable among friends to use the given name, but use of the family name is still common. In the case of the imperial family, it is still considered inappropriate to use the given name. Since Emperor Meiji, it has been customary to have one era per emperor and to rename each emperor after his death using the name of the era over which he presided, plus the word "Tennō". Prior to Emperor Meiji, the names of the eras were changed more frequently, and the posthumous names of the emperors were chosen in a different manner.
Outside of Japan, beginning with Emperor Shōwa, the emperors are often referred to by their given names, both whilst alive and posthumously. For example, the previous emperor is usually called Hirohito in English, although he was never referred to as Hirohito in Japan, and was renamed "Shōwa Tennō" after his death, which is the only name that Japanese speakers currently use when referring to him.
The current emperor on the throne is typically referred to by the title "Tennō Heika" (天皇陛下, literally "His Majesty the heavenly sovereign") or "Kinjō Heika" (今上陛下, literally "his current majesty") or simply "Tennō" when speaking Japanese. The current Emperor will be renamed "Heisei Tennō" (平成天皇) after his death and will then be referred to exclusively by that name in Japanese. Non-Japanese speakers typically refer to him now as Akihito, or "Emperor Akihito", and will almost certainly continue to do so after his death. It is considered a major faux pas to refer to a living emperor by his posthumous name, though.
Origin of the title.
Originally, the ruler of Japan was known as either 大和大王/大君 (Yamato-ōkimi, Grand King of Yamato), 倭王/倭国王 ("Wa-ō"/"Wakoku-ō", King of Wa, used externally), or 治天下大王 ("ame-no-shita shiroshimesu ōkimi" or "sumera no mikoto", Grand King who rules all under heaven, used internally) in Japanese and Chinese sources prior to the 7th century. The oldest documented use of the word "tennō" is on a wooden slat, or "mokkan", that was unearthed in Asuka-mura, Nara Prefecture in 1998 and dated back to the reign of Emperor Temmu and Empress Jitō.
Marriage traditions.
Throughout history, Japanese emperors and noblemen appointed the position of chief wife, rather than just keeping a harem or an assortment of female attendants.
The Japanese imperial dynasty consistently practiced official polygamy, a practice that only ended in the Taishō period (1912–1926). Besides the empress, the emperor could take, and nearly always took, several secondary consorts ("concubines") of various hierarchical degrees. Concubines were allowed also to other dynasts (Shinnōke, Ōke). After a decree by Emperor Ichijō, some emperors even had two empresses simultaneously ("kōgō" and "chūgū" are the two separate titles for that situation). With the help of all this polygamy, the imperial clan thus was capable of producing more offspring. (Sons by secondary consorts were usually recognized as imperial princes, too, and could be recognized as heir to the throne if the empress did not give birth to an heir.)
Of the eight female tennō (reigning empress) of Japan, none married or gave birth after ascending the throne. Some of them, being widows, had produced children prior to their reigns.
In the succession, children of the empress were preferred over sons of secondary consorts. Thus it was significant which quarters had preferential opportunities in providing chief wives to imperial princes, i.e. supplying future empresses.
Apparently, the oldest tradition of official marriages within the imperial dynasty were marriages between dynasty members, even half-siblings or uncle and niece. Such marriages were deemed to preserve better the imperial blood or were aimed at producing children symbolic of a reconciliation between two branches of the imperial dynasty. Daughters of others than imperials remained concubines, until Emperor Shōmu (701-706) — in what was specifically reported as the first elevation of its kind — elevated his Fujiwara consort Empress Kōmyō to chief wife.
Japanese monarchs have been, as much as others elsewhere, dependent on making alliances with powerful chiefs and other monarchs. Many such alliances were sealed by marriages. The specific feature in Japan has been the fact that these marriages have been soon incorporated as elements of tradition which controlled the marriages of later generations, though the original practical alliance had lost its real meaning. A repeated pattern has been an imperial son-in-law under the influence of his powerful non-imperial father-in-law.
Beginning from the 7th and 8th centuries, emperors primarily took women of the Fujiwara clan as their highest wives—the most probable mothers of future monarchs. This was cloaked as a tradition of marriage between heirs of two "kami" (Shinto deities): descendants of Amaterasu with descendants of the family "kami" of the Fujiwara. (Originally, the Fujiwara were descended from relatively minor nobility, thus their "kami" is an unremarkable one in the Japanese myth world.) To produce imperial children, heirs of the nation, with two-side descent from the two kamis, was regarded as desirable—or at least it suited powerful Fujiwara lords, who thus received preference in the imperial marriage market. The reality behind such marriages was an alliance between an imperial prince and a Fujiwara lord, his father-in-law or grandfather, the latter with his resources supporting the prince to the throne and most often controlling the government. These arrangements created the tradition of regents (Sesshō and Kampaku), with these positions held only by a Fujiwara sekke lord.
Earlier, the emperors had married women from families of the government-holding Soga lords, and women of the imperial clan itself, i.e. various-degree cousins and often even their own sisters (half-sisters). Several imperials of the 5th and 6th centuries such as Prince Shōtoku were children of half-sibling couples. These marriages often were alliance or succession devices: the Soga lord ensured his domination of a prince who would be put on the throne as a puppet; or a prince ensured the combination of two imperial descents, to strengthen his own and his children's claim to the throne. Marriages were also a means to seal a reconciliation between two imperial branches.
After a couple of centuries, emperors could no longer take anyone from outside such families as primary wife, no matter what the expediency of such a marriage and power or wealth brought by such might have been. Only very rarely did a prince ascend the throne whose mother was not descended from the approved families. The earlier necessity and expediency had mutated into a strict tradition that did not allow for current expediency or necessity, but only dictated that daughters of a restricted circle of families were eligible brides, because they had produced eligible brides for centuries. Tradition had become more forceful than law.
Fujiwara women were often Empresses, and concubines came from less exalted noble families. In the last thousand years, sons of an imperial male and a Fujiwara woman have been preferred in the succession.
The five Fujiwara families, Ichijō, Kujō, Nijō, Konoe, and Takatsukasa, were the primary source of imperial brides from the 8th century to the 19th century, even more often than daughters of the imperial clan itself. Fujiwara daughters were thus the usual empresses and mothers of emperors.
This restriction on brides for the emperor and crown prince was made explicit in the Meiji-era imperial house laws of 1889. A clause stipulated that daughters of Sekke (the five main branches of the higher Fujiwara) and daughters of the imperial clan itself were primarily acceptable brides.
That law was repealed in the aftermath of World War II. The present emperor, Akihito, became the first crown prince for over a thousand years to marry a consort from outside the previously eligible circle.
Burial traditions.
During the Kofun Period, so-called "archaic funerals" were held for the dead emperors, but only the funerary rites from the end of the period, which the chronicles describe in more detail, are known. They were centered around the rite of the "mogari", a provisional depository between death and permanent burial.
Empress Jitō was the first Japanese imperial personage to be cremated (in 703). After that, with a few exceptions, all emperors were cremated up to the Edo Period. It has been decided that Emperor Akihito and Empress Michiko will be cremated after they die.
Succession.
The Japanese imperial dynasty bases its position in the expression that it has "reigned since time immemorial" (万世一系 "bansei ikkei"). It is true that its origins are buried in the mists of time: there are no records of any emperor who was not said to have been a descendant of other, yet earlier emperors. There is suspicion that Emperor Keitai (c. 500 AD) may have been an unrelated outsider, though the sources state that he was a male-line descendant of Emperor Ōjin. However, his descendants, including his successors, were according to records descended from at least one and probably several imperial princesses of the older lineage. The tradition built by those legends has chosen to recognize just the putative male ancestry as valid for legitimizing his succession, not giving any weight to ties through the said princesses.
Millennia ago, the Japanese imperial family developed its own peculiar system of hereditary succession. It has been non-primogenitural, more or less agnatic, based mostly on rotation. Today, Japan uses strict agnatic primogeniture, which was adopted from Prussia, by which Japan was greatly influenced in the 1870s.
The controlling principles and their interaction were apparently very complex and sophisticated, leading to even idiosyncratic outcomes. Some chief principles apparent in the succession have been:
Historically, the succession to Japan's Chrysanthemum Throne has always passed to descendants in male line from the imperial lineage. Generally, they have been males, though of the over one hundred monarchs there have been nine women (one pre-historical and eight historical) as Emperor on eleven occasions. See of the Yamato dynasty.
Over a thousand years ago, a tradition started that an emperor should ascend relatively young. A dynast who had passed his toddler years was regarded suitable and old enough. Reaching the age of legal majority was not a requirement. Thus, a multitude of Japanese emperors have ascended as children, as young as 6 or 8 years old. The high-priestly duties were deemed possible for a walking child. A reign of around ten years was regarded a sufficient service. Being a child was apparently a fine property, to better endure tedious duties and to tolerate subjugation to political power-brokers, as well as sometimes to cloak the truly powerful members of the imperial dynasty. Almost all Japanese empresses and dozens of emperors abdicated, and lived the rest of their lives in pampered retirement, wielding influence behind the scenes. Several emperors abdicated to their entitled retirement while still in their teens. These traditions show in Japanese folklore, theater, literature, and other forms of culture, where the emperor is usually described or depicted as an adolescent.
Before the Meiji Restoration, Japan had eleven reigns of reigning empresses, all of them daughters of the male line of the Imperial House. None ascended purely as a wife or as a widow of an emperor. Imperial daughters and granddaughters, however, usually ascended the throne as a sort of a "stop gap" measure—if a suitable male was not available or some imperial branches were in rivalry so that a compromise was needed. Over half of Japanese empresses and many emperors abdicated once a suitable male descendant was considered to be old enough to rule (just past toddlerhood, in some cases). Four empresses, Empress Suiko, Empress Kōgyoku (also Empress Saimei), and Empress Jitō, as well as the mythical Empress Jingū, were widows of deceased emperors and princesses of the blood imperial in their own right. One, Empress Gemmei, was the widow of a crown prince and a princess of the blood imperial. The other four, Empress Genshō, Empress Kōken (also Empress Shōtoku), Empress Meishō, and Empress Go-Sakuramachi, were unwed daughters of previous emperors. None of these empresses married or gave birth after ascending the throne.
Article 2 of the 1889 Meiji Constitution (the Constitution of the Empire of Japan) stated, "The Imperial Throne shall be succeeded to by imperial male descendants, according to the provisions of the Imperial House Law." The 1889 Imperial Household Law fixed the succession on male descendants of the imperial line, and specifically excluded female descendants from the succession. In the event of a complete failure of the main line, the throne would pass to the nearest collateral branch, again in the male line. If the empress did not give birth to an heir, the emperor could take a concubine, and the son he had by that concubine would be recognized as heir to the throne. This law, which was promulgated on the same day as the Meiji Constitution, enjoyed co-equal status with that constitution.
Article 2 of the Constitution of Japan, promulgated in 1947 by influence of the U.S. occupation administration and still in force, provides that "The Imperial Throne shall be dynastic and succeeded to in accordance with the Imperial Household Law passed by the Diet." The Imperial Household Law of January 16, 1947, enacted by the ninety-second and last session of the Imperial Diet, retained the exclusion on female dynasts found in the 1889 law. The government of Prime Minister Yoshida Shigeru hastily cobbled together the legislation to bring the Imperial Household in compliance with the American-written Constitution of Japan that went into effect in May 1947. In an effort to control the size of the imperial family, the law stipulates that only legitimate male descendants in the male line can be dynasts; that imperial princesses lose their status as Imperial Family members if they marry outside the Imperial Family; and that the Emperor and other members of the Imperial Family may not adopt children. It also prevented branches, other than the branch descending from Taishō, from being imperial princes any longer.
Current status.
Succession is now regulated by laws passed by the Japanese Diet. The current law excludes women from the succession. A change to this law had been considered until Princess Kiko gave birth to a son.
Until the birth of Prince Hisahito, son of Prince Akishino, on September 6, 2006, there was a potential succession problem, since Prince Akishino was the only male child to be born into the imperial family since 1965. Following the birth of Princess Aiko, there was public debate about amending the current Imperial Household Law to allow women to succeed to the throne. In January 2005, Prime Minister Junichiro Koizumi appointed a special panel composed of judges, university professors, and civil servants to study changes to the Imperial Household Law and to make recommendations to the government.
The panel dealing with the succession issue recommended on October 25, 2005 amending the law to allow females of the male line of imperial descent to ascend the Japanese throne. On January 20, 2006, Prime Minister Junichiro Koizumi devoted part of his annual keynote speech to the controversy, pledging to submit a bill allowing women to ascend the throne to ensure that the succession continues in the future in a stable manner. Shortly after the announcement that Princess Kiko was pregnant with her third child, Koizumi suspended such plans. Her son, Prince Hisahito, is the third in line to the throne under the current law of succession. On January 3, 2007, Prime Minister Shinzō Abe announced that he would drop the proposal to alter the Imperial Household Law.

</doc>
<doc id="10111" url="http://en.wikipedia.org/wiki?curid=10111" title="Emperor">
Emperor

An emperor (through Old French "empereor" from Latin "imperator") is a (male) monarch, usually the sovereign ruler of an empire or another type of imperial realm. Empress, the female equivalent, may indicate an emperor's wife ("empress consort"), mother ("empress dowager"), or a woman who rules in her own right ("empress regnant"). Emperors are generally recognized to be of a higher honour and rank than kings.
The Emperor of Japan is the only currently reigning monarch whose title is translated into English as "Emperor".
Distinction from other monarchs.
Both kings and emperors are monarchs. Within the European context, "emperor" and "empress" are considered the higher monarchical titles. However monarchs heading empires have not always used the title—the British sovereign did not assume the title until the incorporation of India into the British Empire, and even then used it only in a limited context. For purposes of protocol, emperors were once given precedence over kings in international diplomatic relations; currently, however, precedence amongst heads of state - whether they be Kings, Queens, Emperors, or Presidents - is determined by the duration of time that each one has been continuously in office.
Outside the European context, "emperor" was the translation given to holders of titles who were accorded the same precedence as European emperors in diplomatic terms. In reciprocity, these rulers might accredit equal titles in their native languages to their European peers. Through centuries of international convention, this has become the dominant rule to identifying an emperor in the modern era.
Some empires, such as the Holy Roman Empire and the Russian Empire, derived their office from the authority of the Roman Emperors ("translatio imperii"). The title was a conscious attempt by monarchs to link themselves to the institutions and traditions of the Romans as part of state ideology.
Historians have liberally used "emperor" and, especially so, "empire" anachronistically and out of its Roman and European context to describe any large state and its ruler in the past and present; sometimes even to refer to non-monarchically ruled states and their spheres of influence: such examples include the "Athenian Empire" of the late 5th century BC, the "Angevin Empire" of the Plantagenets, or the Soviet and American "empires" of the Cold War era. "Empire" became identified with vast territorial holdings rather than the title of its ruler by the mid-18th century.
Roman tradition.
The title was first used as an honorific for a military leader in ancient Rome, meaning commander or general.
In the Roman tradition a large variety in the meaning and importance of the imperial form of monarchy developed: in "intention" it was always the highest office, but it could as well fall down to a redundant title for nobility that had never been near to the "Empire" they were supposed to be reigning. Also the "name" of the position split in several branches of Western tradition, see below.
The importance and meaning of coronation ceremonies and regalia also varied within the tradition: for instance Holy Roman Emperors could only be crowned emperor by the pope, which meant the coronation ceremony usually took place in Rome, often several years after these emperors had ascended to the throne (as "king") in their home country. The first Latin Emperors of Constantinople on the other hand had to be present in the newly conquered capital of their empire, because that was the only place where they could be granted to become emperor.
Early Roman Emperors avoided any type of ceremony or regalia different from what was already usual for republican offices in the Roman Republic: the most intrusive change had been changing the color of their robe to purple. Later new symbols of worldly and/or spiritual power, like the orb, became an essential part of the imperial accessories.
Rules for indicating successors also varied: there was a tendency towards "male" "inheritance" of the supreme office, but as well election by noblemen, as ruling empresses (for empires not too strictly under salic law) are known. Ruling monarchs could additionally steer the succession by adoption, as often occurred in the two first centuries of Imperial Rome. Of course, intrigue, murder and military force could also mingle in for appointing successors; the Roman imperial tradition made no exception to other monarchical traditions in this respect. Probably the epoch best known for this part of the imperial tradition is Rome's third century rule.
Ancient Roman empire and Byzantine emperors.
Classical Antiquity.
When Republican Rome turned into a "de facto" monarchy in the second half of the 1st century BC, at first there was no name for the title of the new type of monarch. Ancient Romans abhorred the name Rex ("king"), and it was critical to the political order to maintain the forms and pretenses of republican rule. Julius Caesar had been Dictator, an acknowledged and traditional office in Republican Rome. Caesar was not the first to hold it, but following his assassination the term was abhorred in Rome.
Augustus, considered the first Roman Emperor, established his by collecting on himself offices, titles, and honours of Republican Rome that had traditionally been distributed to different people, concentrating what had been distributed power in one man. One of these offices was "princeps senatus", ("first man of the Senate") and became shortened into Augustus' chief honorific, "Princeps" (usually translated as "first citizen") from which the modern English word and title prince is descended. The first period of the Roman Empire, from 27 BC – 284 AD, is called the "principate" for this reason. However, it was the informal descriptive of "Imperator" ("commander") that became the title increasingly favored by his successors. Previously bestowed on high officials and military commanders who had "imperium", Augustus reserved it exclusively to himself as the ultimate holder of all "imperium". ("Imperium" is Latin for the authority to command, one of a various types of authority delineated in Roman political thought.)
Beginning with Augustus, "Imperator" appeared in the title of all Roman monarchs through the extinction of the Empire in 1453. After the reign of Augustus' immediate successor Tiberius, being proclaimed "imperator" was transformed into the act of accession to the head of state. Other honorifics used by the Roman Emperors have also come to be synonyms for Emperor:
After the turbulent Year of the four emperors in 69, the Flavian Dynasty reigned for three decades. The succeeding Nervan-Antonian Dynasty, ruling for most of the 2nd century, stabilised the Empire. This epoch became known as the era of the "Five Good Emperors", and was followed by the short-lived Severan Dynasty.
During the Crisis of the 3rd century, Barracks Emperors succeeded one another at short intervals. Three short lived secessionist attempts had their own emperors: the Gallic Empire, the Britannic Empire, and the Palmyrene Empire though the latter used "rex" more regularly.
The Principate (27 BC – 284 AD) period was succeeded by what is known as the Dominate (284 AD – 527 AD), during which Emperor Diocletian tried to put the Empire on a more formal footing. Diocletion sought to address the challenges of the Empire's now vast geography and the instability caused by the informality of succession by the creation of co-emperors and junior emperors. At one point, there were as many as five sharers of the "imperium" (see: Tetrarchy). In 325 AD Constantine I abolished the system and restored single emperor rule, but following the death of Theodosius in 395 AD, the empire returned to the system of co-emperors, each with primary authority for half the empire. The areas administered from Rome are referred to by historians the Western Roman Empire and those under the immediate authority of Constantinople called the Eastern Roman Empire or (after the Battle of Yarmouk in 636 AD) the Later Roman or Byzantine Empire. The subdivisions and co-emperor system were formally abolished by Emperor Zeno in 480 AD following the death of Julius Nepos last Western Emperor and the ascension of Odoacer as the "de facto" King of Italy in 476 AD.
Byzantine period.
Before the 4th Crusade.
Historians generally refer to the continuing Roman Empire in the east as the Byzantine Empire after Byzantium, the original name of the town that Constantine I would elevate to the Imperial capital as New Rome in AD 330. (The city is more commonly called Constantinople and is today named Istanbul). Although the empire was again subdivided and a co-emperor sent to Italy at the end of the fourth century, the office became unitary again only 95 years later at the request of the Roman Senate and following the death of Julius Nepos, last Western Emperor. This change was a recognition of the reality that little remained of Imperial authority in the areas that had been the Western Empire, with even Rome and Italy itself now ruled by the essentially autonomous Odoacer.
These Later Roman "Byzantine" Emperors completed the transition from the idea of the Emperor as a semi-republican official to the Emperor as an absolute monarch. Of particular note was the translation of the Latin "Imperator" into the Greek "Basileus", after Emperor Heraclius changed the official language of the empire from Latin to Greek in AD 620. Basileus, a title which had long been used for Alexander the Great was already in common usage as the Greek word for the Roman emperor, but its definition and sense was "King" in Greek, essentially equivalent with the Latin "Rex". Byzantine period emperors also used the Greek word "autokrator", meaning "one who rules himself", or "monarch", which was traditionally used by Greek writers to translate the Latin "dictator". Essentially, the Greek language did not incorporate the nuances of the Ancient Roman concepts that distinguished "imperium" from other forms of political power.
In general usage, the Byzantine imperial title evolved from simply "emperor" ("basileus"), to "emperor of the Romans" ("basileus tōn Rōmaiōn") in the 9th century, to "emperor and autocrat of the Romans" ("basileus kai autokratōr tōn Rōmaiōn") in the 10th. In fact, none of these (and other) additional epithets and titles had ever been completely discarded.
One important distinction between the post Constantine I (reigned AD 306–337) emperors and their pagan predecessors was cesaropapism, the assertion that the Emperor (or other head of state) is also the head of the Church. Although this principle was held by all emperors after Constantine, it met with increasing resistance and ultimately rejection by bishops in the west after the effective end of Imperial power in there. This concept became a key element of the meaning of "emperor" in the Byzantine and Orthodox east, but went out of favor with in the west with the rise of Roman Catholicism.
The Byzantine empire also produced three women who effectively governed the state: the Empress Irene and the Empresses Zoe and Theodora.
Latin emperors.
In 1204 Constantinople fell to the Venetians and the Franks in the Fourth Crusade. Following the tragedy of the horrific sacking of the city, the conquerors declared a new "Empire of Romania", known to historians as the Latin Empire of Constantinople, installing Baldwin IX, Count of Flanders, as Emperor. However, Byzantine resistance to the new empire meant that it was in constant struggle to establish itself. Byzantine Emperor Michael VII Palaiologos succeeded in recapturing Constantinople in 1261. The Principality of Achaea, a vassal state the empire had created in Morea (Greece) intermittently continued to recognize the authority of the crusader emperors for another half century. Pretenders to the title continued among the European nobility until circa 1383.
After the 4th Crusade.
With Constantinople occupied, claimants to the imperial succession styled themselves as emperor in the chief centers of resistance: The Laskarid dynasty in the Empire of Nicaea, the Komnenid dynasty in the Empire of Trebizond and the Doukid dynasty in the Despotate of Epirus. In 1248, the Epirus recognized the Nicaean Emperors, who then recaptured Constantinople in 1261. The Trebizond emperor formally submitted in Constantinople in 1281, but frequently flouted convention by styling themselves emperor back in Trebizond thereafter.
Ottoman Empire.
Ottoman rulers held several titles denoting their Imperial status. These included: Sultan, Khan, Sovereign of the Imperial House of Osman, Sultan of Sultans, Khan of Khans, Commander of the Faithful and Successor of the Prophet of the Lord of the Universe, Protector of the Holy Cities of Mecca, Medina and Jerusalem, Emperor of The Three Cities of Constantinople, Adrianopole and Bursa as well as many other cities and countries.
After the Ottoman capture of Constantinople in 1453, the Ottoman sultans began to style themselves Kaysar-i Rum (Emperor of the Romans) as they asserted themselves to be the heirs to the Roman empire by right of conquest. The title was of such importance to them that it led them to eliminate the various Byzantine successor states — and therefore rival claimants — over the next eight years.
Holy Roman Empire.
The "Roman" of the Emperor's title was a reflection of the "translatio imperii" ("transfer of rule") principle that regarded the Holy Roman Emperors as the inheritors of the title of Emperor of the Western Roman Empire, despite the continued existence of the Roman Empire in the east.
From the time of Otto the Great onward, much of the former Carolingian kingdom of Eastern Francia became the Holy Roman Empire. The prince-electors elected one of their peers as Roman King and King of Italy before being crowned by the Pope. The Emperor could also pursue the election of his heir (usually a son) as King, who would then succeed him after his death. This junior King then bore the title King of the Romans. Although technically already ruling, after the election he would be crowned as emperor by the Pope. The last emperor to be crowned by the pope was Charles V; all emperors after him were technically "emperors-elect", but were universally referred to as "Emperor".
Austrian Empire.
The first Austrian Emperor was the last Holy Roman Emperor Francis II. In the face of aggressions by Napoleon, Francis feared for the future of the Holy Roman Empire. He wished to maintain his and his family's Imperial status in the event that the Holy Roman Empire should be dissolved, as it indeed was in 1806 when an Austrian-led army suffered a humiliating defeat at the Battle of Austerlitz. After which, the victorious Napoleon proceeded to dismantle the old "Reich" by severing a good portion from the empire and turning it into a separate Confederation of the Rhine. With the size of his imperial realm significantly reduced, Francis II, "Holy Roman Emperor" became Francis I, "Emperor of Austria". The new imperial title may have sounded less prestigious than the old one, but Francis' dynasty continued to rule from Austria and a Habsburg monarch was still an emperor ("Kaiser"), and not just merely a king ("König"), in name.
The title lasted just a little over one century until 1918, but it was never clear what territory constituted the "Empire of Austria". When Francis took the title in 1804, the Habsburg lands as a whole were dubbed the "Kaisertum Österreich". "Kaisertum" might literally be translated as "emperordom" (on analogy with "kingdom") or "emperor-ship"; the term denotes specifically "the territory ruled by an emperor", and is thus somewhat more general than Reich, which in 1804 carried connotations of universal rule. Austria proper (as opposed to the complex of Habsburg lands as a whole) had been an Archduchy since the 15th century, and most of the other territories of the Empire had their own institutions and territorial history, although there were some attempts at centralization, especially during the reign of Marie Therese and her son Joseph II and then finalized in the early 19th century. When Hungary was given self-government in 1867, the non-Hungarian portions were called the Empire of Austria and were officially known as the "Kingdoms and Lands Represented in the Imperial Council ("Reichsrat")". The title of Emperor of Austria and the associated Empire were both abolished at the end of the First World War in 1918, when German Austria became a republic and the other kingdoms and lands represented in the Imperial Council established their independence or adhesion to other states.
Emperors of Eastern Europe.
Byzantium's close cultural and political interaction with its Balkan neighbors Bulgaria and Serbia, and with Russia (Kievan Rus', then Muscovy) led to the adoption of Byzantine imperial traditions in all of these countries.
Bulgaria.
In 913, Simeon I of Bulgaria was crowned Emperor (Tsar) by the Patriarch of Constantinople and imperial regent Nicholas Mystikos outside of the Byzantine capital. In its final simplified form, the title read "Emperor and Autocrat of all Bulgarians and Romans" ("Tsar i samodarzhets na vsichki balgari i gartsi" in the modern vernacular). The Roman component in the Bulgarian imperial title indicated both rulership over Greek speakers and the derivation of the imperial tradition from the Romans.
Byzantine recognition of Simeon's imperial title was revoked by the succeeding Byzantine government. The decade 914–924 was spent in destructive warfare between Byzantium and Bulgaria over this and other matters of conflict. The Bulgarian monarch, who had further irritated his Byzantine counterpart by claiming the title "Emperor of the Romans" ("basileus tōn Rōmaiōn"), was eventually recognized, as "Emperor of the Bulgarians" ("basileus tōn Boulgarōn") by the Byzantine Emperor Romanos I Lakapenos in 924. Byzantine recognition of the imperial dignity of the Bulgarian monarch and the patriarchal dignity of the Bulgarian patriarch was again confirmed at the conclusion of permanent peace and a Bulgarian-Byzantine dynastic marriage in 927. In the meantime, the Bulgarian imperial title may have been also confirmed by the pope. The Bulgarian imperial title "tsar" was adopted by all Bulgarian monarchs up to the fall of Bulgaria under Ottoman rule. 14th-century Bulgarian literary compositions clearly denote the Bulgarian capital (Tarnovo) as a successor of Rome and Constantinople, in effect, the "Third Rome".
It should be noted that after Bulgaria obtained full independence from the Ottoman Empire in 1908, its monarch, who was previously styled "Knyaz", i.e., Prince, took the traditional title of "Tsar" which in Bulgarian means King and was recognized internationally as such.
Serbia.
In 1345, the Serbian King Stefan Uroš IV Dušan proclaimed himself Emperor (Tsar) and was crowned as such at Skopje on Easter 1346 by the newly created Patriarch of Serbia, and by the Patriarch of Bulgaria and the autocephalous Archbishop of Ohrid. His imperial title was recognized by Bulgaria and various other neighbors and trading partners but not by the Byzantine Empire. In its final simplified form, the Serbian imperial title read "Emperor of Serbs and Greeks" ("цар Срба и Грка" in modern Serbian). It was only employed by Stefan Uroš IV Dušan and his son Stefan Uroš V in Serbia (until his death in 1371), after which it became extinct. A half-brother of Dušan, Simeon Uroš, and then his son Jovan Uroš, claimed the same title, until the latter's abdication in 1373, while ruling as dynasts in Thessaly. The "Greek" component in the Serbian imperial title indicates both rulership over Greeks and the derivation of the imperial tradition from the Romans.
Russia.
In 1472, the niece of the last Byzantine emperor, Sophia Palaiologina, married Ivan III, grand prince of Moscow, who began championing the idea of Russia being the successor to the Byzantine Empire. This idea was represented more emphatically in the composition the monk Filofej addressed to their son Vasili III. After ending Muscovy's dependence on its Mongol overlords in 1480, Ivan III began the usage of the titles Tsar and Autocrat ("samoderzhets "). His insistence on recognition as such by the emperor of the Holy Roman Empire since 1489 resulted in the granting of this recognition in 1514 by Emperor Maximilian I to Vasili III. His son Ivan IV emphatically crowned himself Tsar of Russia on 16 January 1547. The word "Tsar" derives from Latin Caesar, but this title was used in Russia as equivalent to "King"; the error occurred when medieval Russian clerics referred to the biblical Jewish kings with the same title that was used to designate Roman and Byzantine rulers — "Caesar".
On 31 October 1721, Peter I was proclaimed Emperor by the Senate. The title used was Latin ""Imperator", which is a westernizing form equivalent to the traditional Slavic title "Tsar"". He based his claim partially upon a letter discovered in 1717 written in 1514 from Maximilian I to Vasili III, in which the Holy Roman Emperor used the term in referring to Vasili.
A formal address to the ruling Russian monarch adopted thereafter was 'Your Imperial Majesty'. The crown prince was addressed as 'Your Imperial Highness'.
The title has not been used in Russia since the abdication of Emperor Nicholas II on 15 March 1917.
Imperial Russia produced four reigning Empresses, all in the eighteenth century.
Emperors in Western Europe.
France.
The kings of the "Ancien Régime" and the July Monarchy used the title "Empereur de France" in diplomatic correspondence and treaties with the Ottoman emperor from at least 1673 onwards. The Ottomans insisted on this elevated style while refusing to recognize the Holy Roman Emperors or the Russian tsars because of their rival claims of the Roman crown. In short, it was an indirect insult by the Ottomans to the HRE and the Russians. The French kings also used it for Morocco (1682) and Persia (1715).
First French Empire.
Napoleon Bonaparte, who was already First Consul of the French Republic ("Premier Consul de la République française") for life, declared himself Emperor of the French ("Empereur des Français") on 18 May 1804, thus creating the French Empire ("Empire Français").
Napoleon relinquished the title of Emperor of the French on 6 April and again on 11 April 1814.
Napoleon's infant son, Napoleon II, was recognized by the Council of Peers, as Emperor from the moment of his father's abdication, and therefore reigned (as opposed to ruled) as Emperor for fifteen days, 22 June to 7 July 1815.
Elba.
Since 3 May 1814, the Sovereign Principality of Elba was created a miniature non-hereditary Monarchy under the exiled French Emperor Napoleon I. Napoleon I was allowed, by the treaty of Fontainebleau with (27 April), to enjoy, for life, the imperial title. The islands were "not" restyled an empire.
On 26 February 1815, Napoleon abandoned Elba for France, reviving the French Empire for a Hundred Days; the Allies declared an end to Napoleon's sovereignty over Elba on 25 March 1815, and on 31 March 1815 Elba was ceded to the restored Grand Duchy of Tuscany by the Congress of Vienna. After his final defeat, Napoleon was treated as a general by the British authorities during his second exile to Atlantic Isle of St. Helena. His title was a matter of dispute with the governor of St Helena, who insisted on addressing him as "General Bonaparte", despite the "historical reality that he had been an emperor" and therefore retained the title.
Second French Empire.
Napoleon I's nephew, Napoleon III, resurrected the title of emperor on 2 December 1852, after establishing the Second French Empire in a presidential coup, subsequently approved by a plebiscite. His reign was marked by large scale public works, the development of social policy, and the extension of France's influence throughout the world. During his reign, he also set about creating the Second Mexican Empire (headed by his choice of Maximilian I of Mexico, a member of the House of Habsburg), to regain France's hold in the Americas and to achieve greatness for the 'Latin' race. Napoleon III was deposed on 4 September 1870, after France's defeat in the Franco-Prussian War. The Third Republic followed and after the death of his son Napoleon (IV), in 1879 during the Zulu War, the Bonapartist movement split, and the Third Republic was to last until 1940.
Iberian Peninsula.
The origin of the title "Imperator totius Hispaniae" (Latin for "Emperor of All Spain") is murky. It was associated with the Leonese monarchy perhaps as far back as Alfonso the Great ("r." 866–910). The last two kings of its Pérez Dynasty were called emperors in a contemporary source.
King Sancho III of Navarre conquered Leon in 1034 and began using it. His son, Ferdinand I of Castile also took the title in 1039. Ferdinand's son, Alfonso VI of León and Castile took the title in 1077. It then passed to his son-in-law, Alfonso I of Aragon in 1109. His stepson and Alfonso VI's grandson, Alfonso VII was the only one who actually had an imperial coronation in 1135.
The title was not exactly hereditary but self-proclaimed by those who had, wholly or partially, united the Christian northern part of the Iberian Peninsula, often at the expense of killing rival siblings. The popes and Holy Roman emperors protested at the usage of the imperial title as a usurpation of leadership in western Christendom. After Alfonso VII's death in 1157, the title was abandoned, and the kings who used it are not commonly mentioned as having been "emperors", in Spanish or other historiography.
After the fall of the Byzantine Empire, the legitimate heir to the throne, Andreas Palaiologos, willed away his claim to Ferdinand and Isabella in 1503. This claim seems to have been forgotten or abandoned quietly for the last 300 years.
Britain.
In the late 3rd century, by the end of the epoch of the "barracks emperors" in Rome, there were two Britannic Emperors, reigning for about a decade. After the end of Roman rule in Britain, the Imperator Cunedda forged the Kingdom of Gwynedd in northern Wales, but all his successors were titled kings and princes.
England.
There was no set title for the king of England before 1066 and monarchs chose to style themselves as they pleased. Imperial titles were used inconsistently beginning with Athelstan in 930 and ended with the Norman conquest of England. Empress Matilda (1102–1167) is the only British monarch commonly referred to as "emperor" or "empress", but acquired her title through her marriage to Henry V, Holy Roman Emperor, and had little legitimacy as Queen of England.
During the rule of Henry VIII an Act of Parliament declared that 'this realm of England is an Empire...governed by one Supreme Head and King having the dignity and royal estate of the imperial Crown of the same'. Hence England and, by extension its modern successor state, the United Kingdom of Great Britain and Northern Ireland, is in fact an Empire ruled by a King endowed with the imperial dignity. However, this has not led to the creation of the "title" of Emperor in England or in the United Kingdom itself.
United Kingdom.
In 1801, George III rejected the title of Emperor when offered. The only period when British monarchs held the title of "Emperor" in a dynastic succession started when the title Empress of India was created for Queen Victoria. The government led by Prime Minister Benjamin Disraeli, conferred the additional title upon her by an Act of Parliament, reputedly to assuage the monarch's irritation at being, as a mere Queen, notionally inferior to her own daughter (Princess Victoria, who was the wife of the reigning German Emperor); the Indian Imperial designation was also formally justified as the expression of Britain succeeding the former Mughal Emperor as suzerain over hundreds of princely states. The title was relinquished by George VI when India became independent on 15 August 1947.
The last Empress of India was George VI's wife, Queen Elizabeth The Queen Mother.
German Empire.
Under the guise of idealism giving way to realism, German nationalism rapidly shifted from its liberal and democratic character in 1848 to Prussian prime minister Otto von Bismarck's authoritarian "Realpolitik". Bismarck wanted to unify the rival German states to achieve his aim of a conservative, Prussian-dominated Germany. Three wars led to military successes and helped to convince German people to do this: the Second war of Schleswig against Denmark in 1864, the Austro-Prussian War against Austria in 1866, and the Franco-Prussian War against the Second French Empire in 1870–71. During the Siege of Paris in 1871, the North German Confederation, supported by its allies from southern Germany, formed the German Empire with the proclamation of the Prussian king Wilhelm I as German Emperor in the Hall of Mirrors at the Palace of Versailles, to the humiliation of the French, who ceased to resist only days later.
After his death he was succeeded by his son Frederick III who was only emperor for 99 days. In the same year his son Wilhelm II became the third emperor within a year. He was the last German emperor. After the empire's defeat in World War I the empire ceased to exist.
Emperors in the Americas.
Pre-Columbian traditions.
The Aztec and Inca traditions are unrelated to one another. Both were conquered under the reign of King Charles I of Spain who was simultaneously emperor-elect of the Holy Roman Empire during the fall of the Aztecs and fully emperor during the fall of the Incas. Incidentally by being king of Spain, he was also Roman (Byzantine) emperor in pretence through Andreas Palaiologos. The translations of their titles were provided by the Spanish.
Aztec Empire.
The only pre-Columbian North American rulers to be commonly called emperors were the "Hueyi Tlatoani" of the Aztec Empire (1375–1521). It was an elected monarchy chosen by the elite. Spanish conquistador Hernán Cortés slew Emperor Cuauhtémoc and installed puppet rulers who became vassals for Spain. Mexican Emperor Maximilian built his palace, Chapultepec Castle, over the ruins of an Aztec one.
Inca Empire.
The only pre-Columbian South American rulers to be commonly called emperors were the "Sapa Inca" of the Inca Empire (1438–1533). Spanish conquistador Francisco Pizarro, conquered the Inca for Spain, killed Emperor Atahualpa, and installed puppets as well. Atahualpa may actually be considered a usurper as he had achieved power by killing his half-brother and he did not perform the required coronation with the imperial crown "mascaipacha" by the "Huillaq Uma" (high priest).
Post-Columbian Americas.
Brazil.
When Napoleon I ordered the invasion of Portugal in 1807 because it refused to join the Continental System, the Portuguese Braganzas moved their capital to Rio de Janeiro to avoid the fate of the Spanish Bourbons (Napoleon I arrested them and made his brother Joseph king). When the French general Junot arrived in Lisbon, the Portuguese fleet had already left with all the local elite.
In 1808, under a British naval escort, the fleet arrived in Brazil. Later, in 1815, the Portuguese Prince Regent (since 1816 King Dom João VI) proclaimed the "United Kingdom of Portugal, Brazil and the Algarves", as a union of three kingdoms, lifting Brazil from its colonial status.
After the fall of Napoleon I and the Liberal revolution in Portugal, the Portuguese Royals returned to Europe (1820). Prince Pedro of Braganza (King D. João's older son) stayed in South America acting as regent of the local kingdom, but, two years later in 1822, he proclaimed himself D. Pedro I, first Emperor of Brazil. He did, however, recognize his father, D. João VI, as "Titular Emperor of Brazil" —a purely honorific title—until D. João VI's death in 1826.
The empire came to an end in 1889, with the overthrow of Emperor D. Pedro II (D. Pedro I's son and successor), when the Brazilian republic was proclaimed.
Haiti.
Haiti was declared an empire by its ruler, Jean-Jacques Dessalines, who made himself Jacques I, in 20 May 1805. He was assassinated the next year. Haiti again became an empire from 1849 to 1859 under Faustin Soulouque.
Mexico.
In Mexico, the First Mexican Empire was the first of two empires created. After the declaration of independence on September 15, 1821, it was the intention of the Mexican parliament to establish a commonwealth whereby the King of Spain, Ferdinand VII, would also be Emperor of Mexico, but in which both countries were to be governed by separate laws and with their own legislative offices. Should the king refuse the position, the law provided for a member of the House of Bourbon to accede to the Mexican throne.
Ferdinand VII, however, did not recognize the independence and said that Spain would not allow any other European prince to take the throne of Mexico. By request of Parliament, the president of the regency Agustín de Iturbide was proclaimed emperor of Mexico in 12 July 1822 as Agustín I. Agustín de Iturbide was the general who helped secure Mexican independence from Spanish rule, but was overthrown by the Plan of Casa Mata.
In 1863, the invading French, under Napoleon III (see above), in alliance with Mexican conservatives and nobility, helped create the Second Mexican Empire, and invited Archduke Maximilian, of the House of Habsburg-Lorraine, younger brother of the Austrian Emperor Franz Josef I, to become emperor Maximilian I of Mexico. The childless Maximilian and his consort Empress Carlota of Mexico, daughter of Leopold I of Belgium, adopted Agustín's grandsons Agustin and Salvador as his heirs to bolster his claim to the throne of Mexico. Maximilian and Carlota made Chapultepec Castle their home, which has been the only palace in North America to house sovereigns. After the withdrawal of French protection in 1867, Maximilian was captured and executed by the liberal forces of Benito Juárez.
This empire led to French influence in the Mexican culture and also immigration from France, Belgium, and Switzerland to Mexico.
Persia (Iran).
In Persia, from the time of Darius the Great, Persian rulers used the title "King of Kings" ("Shahanshah" in Persian) since they had dominion over peoples from India to Greece and Egypt. Alexander probably crowned himself "shahanshah" after conquering Persia, bringing the phrase "basileus toon basileoon" to Greek. It is also known that Tigranes the Great, king of Armenia, was named as the king of kings when he made his empire after defeating the Parthians. Georgian title "mephet'mephe" has the same meaning.
The last "shahanshah" (Mohammad Reza Pahlavi) was ousted in 1979 following the Iranian Revolution. "Shahanshah" is usually translated as "king of kings" or simply "king" for ancient rulers of the Achaemenid, Arsacid, and Sassanid dynasties, and often shortened to "shah" for rulers since the Safavid dynasty in the 16th century.
Indian subcontinent.
The Sanskrit word for emperor is "Samrāṭ" or "Chakravarti" (word stem: "samrāj"). This word has been used as an epithet of various Vedic deities, like Varuna, and has been attested in the Holy Rig Veda, possibly the oldest compiled book among the Indo-Europeans. "Chakravarti" refers to the king of kings. A "Chakravarti" is not only a sovereign ruler but also has feudatories.
Typically, in the later Vedic age, a Hindu high king ("Maharajah") was only called "Samrāṭ" after performing the Vedic "Rajasuya" sacrifice, enabling him by religious tradition to claim superiority over the other kings and princes. Another word for emperor is "sārvabhaumā". The title of "Samrāṭ" has been used by many rulers of the Indian subcontinent as claimed by the Hindu mythologies. In proper history, most historians call Chandragupta Maurya the first "samrāṭ" (emperor) of the Indian subcontinent, because of the huge empire he ruled. The most famous Buddhist emperor was his grandson Ashoka the Great. Other dynasties that are considered imperial by historians are the Kushanas, Guptas, Vijayanagara, Kakatiya, Hoysala and the Cholas.
Rudhramadevi (1259–1289) was one of the most prominent rulers of the Kakatiya dynasty on the Deccan Plateau, being one of the few ruling queens (empress) in Indian history.
After India was invaded by the Mongol Khans and Turkic Muslims, the rulers of their major states on the subcontinent were titled "Sultān", In this manner, the only empress-regnant ever to have actually sat on the throne of Delhi was Razia Sultan. For the period from 1877 to 1947 when British Emperors ruled colonial India as the pearl in the crown of the British Empire, see above.
Africa.
Ethiopia.
In Ethiopia, the Solomonic dynasty used, beginning in 1270, the title of "nəgusä nägäst" which is literally "King of Kings". The use of the "king of kings" style began a millennium earlier in this region, however, with the title being used by the Kings of Aksum, beginning with Sembrouthes in the 3rd century. Another title used by this dynasty was "Itegue Zetopia".
"Itegue" translates as Empress, and was also used by the only female reigning Empress, Zauditu, along with the official title "Negiste Negest" (Queen of Kings).
In 1936, the Italian king Victor Emmanuel III claimed the title of Emperor of Ethiopia after Ethiopia was occupied by Italy during the Second Italo-Abyssinian War. After the defeat of the Italians by the Ethiopians who were assisted by soldiers from Britain in 1941, Haile Selassie was restored to the throne but Victor Emmanuel did not relinquish his claim to the title until 1943.
Central African Empire.
In 1976, President Jean-Bédel Bokassa of the Central African Republic, proclaimed the country to be an autocratic Central African Empire, and made himself Emperor as Bokassa I. The expenses of his coronation ceremony actually bankrupted the country. He was overthrown three years later and the republic was restored.
East Asian tradition.
China.
The East Asian tradition is different from the Roman tradition, having arisen separately. What links them together is the use of the Chinese logographs 皇 ("huáng") and 帝 ("dì") which together or individually are imperial. Because of the cultural influence of China, China's neighbors adopted these titles or had their native titles conform in "hanzi". Anyone who spoke to the emperor was to address him as bìxià (陛下, lit. the "Bottom of the Steps"), corresponding to "Imperial Majesty"; shèngshàng (聖上, lit. Holy Highness); or wànsuì (萬歲, lit. "You, of Ten Thousand Years").
In 221 BC, Ying Zheng, who was king of Qin at the time, proclaimed himself "Shi Huangdi" (始皇帝), which translates as "first emperor". "Huangdi" is composed of "huang" ("august one", 皇) and "di" ("sage-king", 帝), and referred to legendary/mythological sage-emperors living several millennia earlier, of which three were "huang" and five were "di". Thus Zheng became Qin Shi Huang, abolishing the system where the "huang"/"di" titles were reserved to dead and/or mythological rulers. Since then, the title "king" became a lower ranked title, and later divided into two grades. Although not as popular, the title 王 "wang" (king or prince) was still used by many monarchs and dynasties in China up to the Taipings in the 19th century. 王 is pronounced "vương" in Vietnamese, "ō" in Japanese, and "wang" in Korean.
The imperial title continued in China until the Qing Dynasty was overthrown in 1912. The title was briefly revived from 12 December 1915 to 22 March 1916 by President Yuan Shikai and again in early July 1917 when General Zhang Xun attempted to restore last Qing emperor Puyi to the throne. Puyi retained the title and attributes of a foreign emperor, as a personal status, until 1924. After the Japanese occupied Manchuria in 1931, they proclaimed it to be the Empire of Manchukuo, and Puyi became emperor of Manchukuo. This empire ceased to exist when it was occupied by the Soviet Red Army in 1945. 
In general, an emperor would have one empress ("Huanghou", 皇后) at one time, although posthumous entitlement to empress for a concubine was not uncommon. The earliest known usage of "huanghou" was in the Han Dynasty. The emperor would generally select the empress from his concubines. In subsequent dynasties, when the distinction between wife and concubine became more accentuated, the crown prince would have chosen an empress-designate before his reign. Imperial China produced only one reigning empress, Wu Zetian, and she used the same Chinese title as an emperor ("Huangdi", 皇帝). Wu Zetian then reigned for about 15 years (690–705 AD).
Japan.
The earliest Emperor recorded in Kojiki and Nihon Shoki is Emperor Jimmu, who is said to be a descendant of Amaterasu's grandson Ninigi who descended from Heaven (Tenson kōrin). If one believes what is written in Nihon Shoki, the Emperors have an unbroken direct male lineage that goes back more than 2,600 years.
In ancient Japan, the earliest titles for the sovereign were either ヤマト大王/大君 ("yamato ōkimi", Grand King of Yamato), 倭王/倭国王 ("waō"/"wakokuō", King of Wa, used externally), or 治天下大王 ("amenoshita shiroshimesu ōkimi", Grand King who rules all under heaven, used internally). As early as the 7th century the word 天皇 (which can be read either as "sumera no mikoto", divine order, or as "tennō", Heavenly Emperor, the latter being derived from a Tang Chinese term referring to the Pole star around which all other stars revolve) began to be used. The earliest use of this term is found on a wooden slat, or "mokkan", unearthed in Asuka-mura, Nara Prefecture in 1998. The slat dated back to the reign of Emperor Temmu and Empress Jitō. The reading 'Tennō' has become the standard title for the Japanese sovereign up to the present age. The term 帝 ("mikado", Emperor) is also found in literary sources.
Japanese monarchs were given the official title by Chinese emperor. The new Japanese monarch after coming into power would send a representative to China and receive the anointment. They would receive their official title on several golden plates of several meters tall. Since the Japanese monarchs changed their title to 天皇 (Heavenly Emperor) in 607, the Chinese emperor refused to anoint the Japanese king, thus, ending relations with Japan for the next few hundred years. With Chinese emperors in titulary terms, but rarely was the Chinese-style "Son of Heaven" term used. In the Japanese language, the word "tennō" is restricted to Japan's own monarch; "kōtei" (皇帝) is used for foreign emperors. Historically, retired emperors often kept power over a child-emperor as de facto Regent. For a fairly long time, a shōgun (formally the imperial generalissimo, but made hereditary) or regent wielded actual political power. In fact, through much of Japanese history, the emperor has been little more than a figurehead.
After World War II, all claims of divinity were dropped (see Ningen-sengen). The Diet acquired all prerogative powers of the Crown, reverting the latter to a ceremonial role. By the end of the 20th century, Japan was the only country with an emperor on the throne.
As of the early 21st century, Japan's succession law prohibits a female from ascending the throne. With the birth of a daughter as the first child of the current Crown Prince, Naruhito, Japan considered abandoning that rule. However, shortly after the announcement that Princess Kiko was pregnant with her third child, the proposal to alter the Imperial Household Law was suspended by Prime Minister Junichiro Koizumi. On 3 January 2007, after the birth of her son, Prince Hisahito, Prime Minister Shinzo Abe announced that he would drop the proposal.
Currently, many believe the new prince of Japan will ascend the throne, as the law defines. Historically, Japan has had eight reigning empresses who used the genderless title "Tennō", rather than the female consort title "kōgō" (皇后) or "chūgū" (中宮). There is ongoing discussion of the Japanese Imperial succession controversy.
Although current Japanese law prohibits female succession, all Japanese emperors claim to trace their lineage to "Amaterasu", the Sun Goddess of the Shintō religion. Thus, the Emperor is thought to be the highest authority of the Shinto religion, and one of his duties is to perform Shinto rituals for the people of Japan.
Korea.
The rulers of Goguryeo (37 BC-668 AD) used the title of "Taewang" (Hangul: 태왕, Hanja:太王), literally translated as the "Greatest of the Kings". Also some Silla (57 BC-935 AD) rulers including Beopheung and Jinheung used this title for their declaration of independence from the influence of Goguryeo. However, it does not signify "emperor" itself.
The rulers of Balhae (698–926) internally called themselves "Seongwang" (Hangul: 성왕, Hanja: 聖王). In the 10th century, Gwangjong of Goryeo took the title of emperor himself as a means of enhancing the prestige of the monarchy, and it was first used in Korea. Many Goryeo sovereign alternately used both supreme king and emperor. After the Mongolian invasions (1231–1258), however, Korea relinquished the imperial title.
The rulers of the Joseon Dynasty (1392–1897) still used the term "King of the Joseon" (Hangul: 조선국왕, Hanja: 朝鮮國王). In the First Sino-Japanese War of 1894–'95, Japan defeated the Qing Dynasty China, and the Treaty of Shimonoseki was concluded in which Japan had China recognize the independence and autonomy of Korea. However, King Gojong used term of "His Majesty the Great Monarch" (Hangul: 대군주폐하, Hanja: 大君主陛下) not officlal imperial title.
In 1897, King Gojong proclaimed the founding of the Korean Empire (1897–1910), and became emperor of Korea. Emperor Gojong declared the new era name "Gwangmu" (Hangul: 광무, Hanja: 光武, Warrior of light). Korean Empire maintained their state until 1910 — though it was an Empire by name, in fact in the process of being absorbed by Japan.
Mongolia.
Pre-Mongol Kingdoms such as the Xiongnu used the title "Chanu" meaning "Ruler of all" in old Mongolian. However it was not until the Chanu name was dropped and instead replaced by "Khan" that the rulers of Mongolia claimed the divine right as the ruler of all under the blue sky, this rule was closely tied with the ancient religious beliefs of the people of Mongolia (Tengrism). The title Khagan (khan of khans or grand khan) was held by Genghis Khan, founder of the Mongol Empire in 1206. After 1271, the emperors of the Yuan Dynasty also took the Chinese title "huangdi", or Chinese emperor. Only the Khagans from Genghis Khan to the fall of the Yuan Dynasty in 1368 are normally referred to as Emperors in English.
Vietnam.
Ngô Quyền, the first ruler of Đại Việt as an independent state, used the title "Vương" (王, "King"). However, after the death of Ngô Quyền, the country immersed in a civil war known as Chaos of the 12 Lords that lasted for over 20 years. In the end, Đinh Bộ Lĩnh unified the country after defeating all the warlords and became the first ruler of Đại Việt to use the title "Hoàng Đế" (皇帝, "Emperor") in 968. Succeeding rulers in Vietnam then continued to use this Emperor title until 1806 when this title was stopped being used for a century.
Đinh Bộ Lĩnh wasn't the first to claim the title of "Đế" (帝, "Emperor"). Before him, Lý Bí and Mai Thúc Loan also claimed this title. However, their rules were very short lived.
The Vietnamese emperors also gave this title to their ancestors who were lords or influence figures in the previous dynasty like the Chinese emperors. This practice is one of many indications of the idea "Vietnam's equality with China" which is remained intact up to twentieth century.
In 1802 the newly established Nguyễn dynasty requested canonization from Chinese Jiaqing Emperor and got the title "Quốc Vương" (國王, "King of a State)" and the name of the country as "An Nam" (安南) instead "Đại Việt" (大越). To avoid unnecessary armed conflicts, the Vietnamese rulers accepted this in diplomatic relation and use the title Emperor only domestically. However, Vietnamese rulers never accepted the vassalage relationship with China and always refused to come to Chinese courts to pay homage to Chinese rulers (a sign of vassalage acceptance). China waged a number of wars against Vietnam throughout history, and after each failure, settled for the tributary relationship. The Yuan dynasty under Kublai Khan waged three wars against Vietnam to force it into a vassalage relationship but after successive failures, Kublai Khan's successor, Temür Khan, finally settled for a tributary relationship with Vietnam. Vietnam sent tributary missions to China once in three years (with some periods of disruptions) until the 19th century, Sino-French War France replaced China in control of northern Vietnam.
The emperors of the last dynasty of Vietnam continued to hold this title until the French conquered Vietnam. The emperor, however, was then a puppet figure only and could easily be disposed of by the French for more pro-France figure. Japan took Vietnam from France and the Axis-occupied Vietnam was declared an empire by the Japanese in March 1945. The line of emperors came to an end with Bảo Đại, who was deposed after the war, although he later served as head of state of South Vietnam from 1949 to 1955.
Oceania.
The lone holders of the imperial title in Oceania were the heads of the semi-mythical Tuʻi Tonga Empire.
Fictional uses.
There have been many fictional emperors in movies and books. To see a list of these emperors, see .

</doc>
<doc id="10113" url="http://en.wikipedia.org/wiki?curid=10113" title="Egalitarianism">
Egalitarianism

Egalitarianism (from " égal", meaning "equal")—or, rarely, equalitarianism or equalism—is a trend of thought that favors equality for all people. Egalitarian doctrines maintain that all humans are equal in fundamental worth or social status, according to the "Stanford Encyclopedia of Philosophy". According to the Merriam-Webster Dictionary, the term has two distinct definitions in modern English. It is defined either as a political doctrine that all people should be treated as equals and have the same political, economic, social, and civil rights or as a social philosophy advocating the removal of economic inequalities among people, economic egalitarianism, or the decentralization of power. Some sources define egalitarianism as the point of view that equality reflects the natural state of humanity.
Forms.
Some specifically focused egalitarian concerns include economic egalitarianism, legal egalitarianism, luck egalitarianism, political egalitarianism, gender egalitarianism, racial equality, asset-based egalitarianism, and Christian egalitarianism. Common forms of egalitarianism include political and philosophical.
Economic.
Egalitarianism in economics is a controversial phrase with conflicting potential meanings. It may refer either to equality of opportunity, the view that the government ought not to discriminate against citizens or hinder opportunities for them to prosper, or the quite different notion of equality of outcome, a state of economic affairs in which the government promotes equal prosperity for all citizens.
The free-market economist Milton Friedman supported equality-of-opportunity economic egalitarianism. Economist John Maynard Keynes supported more equal outcomes.
An early example of equality-of-outcome economic egalitarianism is Xu Xing, a scholar of the Chinese philosophy of Agriculturalism, who supported the fixing of prices, in which all similar goods and services, regardless of differences in quality and demand, are set at exactly the same, unchanging price.
Social ownership of means of production is sometimes considered to be a form of "economic egalitarianism" because in an economy characterized by social ownership, the surplus product generated by industry would accrue to the population as a whole as opposed to private owners, thereby granting each individual increased autonomy and greater equality in their relationships with one another (see: Social dividend and Social ownership). Although the economist Karl Marx is sometimes mistaken to be an egalitarian, Marx eschewed normative theorizing on moral principles. Marx did, however, have a theory of the evolution of moral principles in relation to specific economic systems.
Karl Marx and Friedrich Engels rejected egalitarianism in the sense of greater equality between classes, clearly distinguishing it from the socialist notion of the abolition of classes based on the division between owners and workers (which is on their relation to productive property). Marx's view of classlessness was not the subordination of society to a universal interest (such as a universal notion of "equality"), but rather, was about the creation of the conditions that would enable individuals to pursue their true interests and desires. Thus, Marx's notion of communist society is radically individualistic.
The American economist John Roemer has put forth a new perspective of equality and its relationship to socialism. Roemer attempts to reformulate Marxist analysis to accommodate normative principles of distributive justice, shifting the argument for socialism away from purely technical and materialist reasons to one of distributive justice. Roemer argues that, according to the principle of distributive justice, the traditional definition of socialism based on the principle that individual compensation be proportional to the value of the labour one expands in production is inadequate. Roemer concludes that egalitarians must reject socialism as it is classically defined.
Political.
Egalitarianism in politics can be of at least two forms. One form is "equality of persons in right", sometimes referred to as natural rights; John Locke is sometimes considered the founder of this form. The slogan "Liberté, égalité, fraternité" was used during the French Revolution and is still used as an official slogan of the French government.
Karl Marx was a proponent of two principles, the first applied to socialism and the second to an advanced communist society: "To each according to his contribution" and "from each according to their ability; to each according to their need". Marx's position is often confused or conflated with "distributive egalitarianism", in which only the goods and services resulting from production are distributed according to a notional equality; but in reality Marx eschewed the entire concept of equality as abstract and bourgeois in nature, focusing instead on more concrete principles such as opposition to exploitation on materialist and economic logic.
Philosophical.
At a cultural level, egalitarian theories have developed in sophistication and acceptance during the past two hundred years. Among the notable broadly egalitarian philosophies are libertarianism, classical liberalism, liberalism, socialism, communism, social anarchism, libertarian socialism, left-libertarianism, social liberalism, one-nation conservatism and progressivism, all of which propound economic, political, and legal egalitarianism. Several egalitarian ideas enjoy wide support among intellectuals and in the general populations of many countries. Whether any of these ideas have been significantly implemented in practice, however, remains a controversial question.
One argument is that liberalism provides democracy with the experience of civic reformism. Without it, democracy loses any tie—argumentative or practical─to a coherent design of public policy endeavoring to provide the resources for the realization of democratic citizenship. For instance, some argue that modern representative democracy is a realization of political egalitarianism, while in reality, most political power still resides in the hands of a ruling class, rather than in the hands of the people.
The cultural theory of risk holds egalitarianism as defined by (1) a negative attitude towards rules and principles, and (2) a positive attitude towards group decision-making, with fatalism termed as its opposite.
Religious and spiritual.
Sikhism
The Sikh faith was founded upon egalitarian principles, going beyond most faiths to provide equality not only based upon race but also gave equality to man and woman. This equality led to denunciation of saathi - the practice of widows sacrificing themselves on the funeral pires of deceased husbands - and provided women in the Sikh faith equal rights to practice their faith and be regarded as created equal in the eyes of God.
In Christianity.
The Christian egalitarian view holds that the Bible teaches the fundamental equality of women and men of all racial and ethnic mixes, all economic classes, and all age groups, based on the teachings and example of Jesus Christ and the overarching principles of scripture. However, within the wide range of Christianity, there are dissenting views from opposing groups, some of which are Complementarians and Patriarchalists. There are also those who may say that, whilst the Bible encourages equality, it also encourages law and order and social structure (for example, parents having authority over their children, and the view that wife should submit to her husband). These ideas are considered by some to be contrary to the ideals of egalitarianism. At its foundational level, holds that "There is neither Jew nor Greek, there is neither bond nor free, there is neither male nor female, for you are all one in Christ Jesus"—defining all as equal in the sight of God. Similarly, says, "Here there is no Gentile or Jew, circumcised or uncircumcised, barbarian, Scythian, slave or free, but Christ is all, and is in all", defining all as equal in the sight of God in relationship to faith in Jesus Christ. Various Christian groups have attempted to hold to this view and develop Christian oriented communities. In Acts, chapter 4, members of the early Christian community sell their possessions, give the proceeds to a common fund overseen by the disciples, then take 'according to their need'. One of the most notable of present-day communities are the Hutterite groups of Europe and North America, living in agricultural and collective communities.
Judaism.
Judaism is not a universalist religion and teaches that Jews (defined as the biological descendants of Jacob "Israel", the son of Abraham) have a specific covenant with God, as a chosen people (Deutoronomy 7:6 "chosen as God's treasured people"), to serve as an example of God's light to the goyim. Rabbinic literature such as the Babylonian Talmud makes key distinctions in religious and legal contexts between Jews and the gentiles (literally, "the nations"). However, (Genesis 1:27) clearly states that humans are created in the image of God, and from this is argued that all humans are created equal. Regardless of gender, ethnicity and race all humans contain the Divine Spark within them and as a result must be treated with human respect and dignity. In modern Judaism, particularly Conservative Judaism, egalitarian refers to religious observance omitting separations and prohibitions based on gender. Synagogues that identify as egalitarian generally allow mixed seating (i.e., no mechitza) and allow women to lead services with men in attendance, as well as read publicly from the Torah.
Islam.
The Islamic stance on equality is to some extent similar to that of Christianity (another universalist religion), and stresses that all humans are equal in the eyes of God, regardless of gender, class and race. The Quran states, "O mankind, indeed We have created you from male and female and made you peoples and tribes that you may know one another. Indeed, the most noble of you in the sight of Allah is the most righteous of you. Indeed, Allah is Knowing and Acquainted.". Louise Marlow's "Hierarchy and Egalitarianism in Islamic Thought" compares the egalitarianism of early Islam to current practice.
Military.
Military egalitarianism has been noted since ancient times, such as with Shakespeare's St. Crispin's Day Speech. This occurs in spite of the distinctions military forces attempt to make between officers and enlisted men. For example former Major General Charles J. Dunlap, Jr. said that United States Air Force culture included an egalitarianism bred from officers as warriors who work with small groups of enlisted airmen either as the service crew or onboard crew of their aircraft.
Reception.
Alexander Berkman suggests:
...equality does not mean an equal amount but equal opportunity... Do not make the mistake of identifying equality in liberty with the forced equality of the convict camp. True anarchist equality implies freedom, not quantity. It does not mean that every one must eat, drink, or wear the same things, do the same work, or live in the same manner. Far from it: the very reverse in fact... Individual needs and tastes differ, as appetites differ. It is equal opportunity to satisfy them that constitutes true equality... Far from levelling, such equality opens the door for the greatest possible variety of activity and development. For human character is diverse.
The Cultural Theory of Risk distinguishes between hierarchists, who are positive towards both rules and groups, and egalitarianists, who are positive towards groups but negative towards rules. This is by definition a form of "anarchist equality" as referred to by Berkman. The fabric of an "egalitarianist society" is thus held together by cooperation and implicit peer pressure rather than by explicit rules and punishment. However, Thompson et al. theorise that any society consisting of only one perspective, be it egalitarianist, hierarchist, individualist, fatalist or autonomist, will be inherently unstable: the claim is that an interplay between all these perspectives are required if each perspective is to be fulfilling. For instance, although an individualist according to Cultural Theory is aversive towards both principles and groups, individualism is not fulfilling if individual brilliance cannot be recognised by groups, or if individual brilliance cannot be made permanent in the form of principles. Accordingly, egalitarianists have no power except through their presence, unless they (by definition, reluctantly) embrace principles which enable them to cooperate with fatalists and hierarchists. They will also have no individual sense of direction in the absence of a group. This could be mitigated by following individuals outside their group: autonomists or individualists.

</doc>
<doc id="10115" url="http://en.wikipedia.org/wiki?curid=10115" title="Expert witness">
Expert witness

 <ns>10</ns>
 <id>2198199</id>
 <revision>
 <id>646505875</id>
 <parentid>645922985</parentid>
 <timestamp>2015-02-10T15:06:52Z</timestamp>
 <contributor>
 <username>Edokter</username>
 <id>1624037</id>
 </contributor>
 <minor />
 <comment>Reverted edits by () to last version by 24.131.80.54</comment>
 <model>wikitext</model>
 <format>text/x-wiki</format>
An expert witness, professional witness or judicial expert is a witness, who by virtue of education, training, skill, or experience, is believed to have expertise and specialised knowledge in a particular subject beyond that of the average person, sufficient that others may officially and legally rely upon the witness's specialized (scientific, technical or other) opinion about an evidence or fact issue within the scope of his expertise, referred to as the expert opinion, as an assistance to the fact-finder. Expert witnesses may also deliver expert evidence about facts from the domain of their expertise. At times, their testimony may be rebutted with a learned treatise, sometimes to the detriment of their reputations.
In Scots Law, "Davie v Magistrates of Edinburgh" (1953) provides authority that where a witness has particular knowledge or skills in an area being examined by the court, and has been called to court in order to elaborate on that area for the benefit of the court, that witness may give evidence of his opinion on that area.
Role of expert witnesses.
Typically, experts are relied on for opinions on severity of injury, degree of sanity, cause of failure in a machine or other device, loss of earnings, care costs, and the like. In an intellectual property case, an expert may be shown two music scores, book texts, or circuit boards and asked to ascertain their degree of similarity. In the majority of cases the expert's personal relation to the defendant is considered irrelevant.
The tribunal itself, or the judge, can in some systems call upon experts to technically evaluate a certain fact or action, in order to provide the court with a complete knowledge on the fact/action it is judging. The expertise has the legal value of an acquisition of data. The results of these experts are then compared to those by the experts of the parties.
The expert has a heavy responsibility, especially in penal trials, and perjury by an expert is a severely punished crime in most countries. The use of expert witnesses is sometimes criticized in the United States because in civil trials, they are often used by both sides to advocate differing positions, and it is left up to a jury to decide which expert witness to believe. Although experts are legally prohibited from expressing their opinion of submitted evidence until after they are hired, sometimes a party can surmise beforehand, because of reputation or prior cases, that the testimony will be favorable regardless of any basis in the submitted data; such experts are commonly disparaged as "hired guns."
Duties of experts.
In England and Wales, under the Civil Procedure Rules 1998 (CPR), an expert witness is required to be independent and address his or her expert report to the court. A witness may be jointly instructed by both sides if the parties agree to this, especially in cases where the liability is relatively small.
Under the CPR, expert witnesses may be instructed to produce a joint statement detailing points of agreement and disagreement to assist the court or tribunal. The meeting is held quite independently of instructing lawyers, and often assists in resolution of a case, especially if the experts review and modify their opinions. When this happens, substantial trial costs can be saved when the parties to a dispute agree to a settlement. In most systems, the trial (or the procedure) can be suspended in order to allow the experts to study the case and produce their results. More frequently, meetings of experts occur before trial. Experts charge a professional fee which is paid by the party commissioning the report (both parties for joint instructions) although the report is addressed to the court. The fee must not be contingent on the outcome of the case. Expert witnesses may be subpoenaed (issued with a witness summons), although this is normally a formality to avoid court date clashes.
In the United States, under the Federal Rule of Evidence 702 (FRE), an expert witness must be qualified on the topic of testimony. In determining the qualifications of the expert, the FRE requires the expert have specialized education, training, or practical experience in the subject matter relating to the case. The expert's testimony must be based on facts in evidence, and should offer opinion about the causation or correlation to the evidence in drawing a conclusion. 
Experts in the U.S. typically are paid on an hourly basis for their services in investigating the facts, preparing a report, and if necessary, testifying during pre-trial discovery, or at trial. Hourly fees range from approximately $200 to $750 or more per hour, varying primarily by the expert's field of expertise, and the individual expert's qualifications and reputation. In several fields, such as handwriting analysis, where the expert compares signatures to determine the likelihood of a forgery, and medical case reviews by a physician or nurse, in which the expert goes over hospital and medical records to assess the possibility of malpractice, experts often initially charge a flat fixed fee for their initial report. As with the hourly fees discussed previously, the amount of that flat fee varies considerably based on the reviewing expert's field, experience and reputation. 
The expert's professional fee, plus his or her related expenses, is generally paid by the party retaining the expert. In some circumstance the party who prevails in the litigation may be entitled to recover the amounts paid its expert from the losing party.
In high stakes cases multiple experts, in multiple topics, are often retained by each party. Although it is still relatively rare, the court itself may also retain its own independent expert. In all cases, fees paid to an expert may not be contingent on the outcome of the case.
History.
The earliest known use of an expert witness in English law came in 1782, when a court that was hearing litigation relating to the silting-up of Wells harbour in Norfolk accepted evidence from a leading civil engineer, John Smeaton. This decision by the court to accept Smeaton's evidence is widely cited as the root of modern rules on expert evidence. However, it was still such an unusual feature in court that in 1957 in the Old Bailey, Lord Justice Patrick Devlin could describe the case of suspected serial killer Dr John Bodkin Adams thus: "It is a most curious situation, perhaps unique in these courts, that the act of murder has to be proved by expert evidence."
On the other hand, expert evidence is often the most important component of many civil and criminal cases today. Fingerprint examination, blood analysis and DNA fingerprinting are common kinds of expert evidence heard in serious criminal cases. In civil cases, the work of accident analysis, forensic engineers, and forensic accountants is usually important, the latter to assess damages and costs in long and complex cases. Intellectual property and medical negligence cases are typical examples.
Electronic evidence has also entered the courtroom as critical forensic evidence. Audio and video evidence must be authenticated by both parties in any litigation by a forensic expert who is also an expert witness who assists the court in understanding details about that electronic evidence.
Voice-mail recordings and closed-circuit television systems produce electronic evidence often used in litigation, more so today than in the past. Video recordings of bank robberies and audio recordings of life threats are presented in court rooms by electronic expert witnesses.
Non-testifying experts.
In the U.S., a party may hire experts to help them evaluate a given case. For example, a car maker may hire an experienced mechanic to decide if its cars were built to specification. This kind of expert opinion will be protected from discovery by the opposing party. In other words, if the expert finds evidence against their client, the opposite party will not automatically gain access to it. This privilege is similar to the work-product doctrine (not to be confused with attorney–client privilege). 
The non-testifying expert can be present at the trial or hearing to aid the attorney in asking questions of other expert witnesses. Unlike a testifying expert, a non-testifying expert can be easily withdrawn from a case. It is also possible to change a non-testifying expert to a testifying expert before the expert disclosure date. 
Testifying experts.
If the witness needs to testify in court, the privilege is no longer protected. The expert witness's identity and nearly all documents used to prepare the testimony will become discoverable. Usually an experienced lawyer will advise the expert not to take notes on documents because all of the notes will be available to the other party.
An expert testifying in a United States federal court must satisfy the requirements of Fed. R. Evid. 702. Generally, under Rule 702, an expert is a person with "scientific, technical, or other specialized knowledge" who can "assist the trier of fact," which is typically a jury. A witness who is being offered as an expert must first establish his or her competency in the relevant field through an examination of his or her credentials. The opposing attorney is permitted to conduct a voir dire of the witness in order to challenge that witness’ qualifications. If qualified by the court, then the expert may testify "in the form of an opinion or otherwise" so long as: "(1) the testimony is based upon sufficient facts or data, (2) the testimony is the product of reliable principles and methods, and (3) the witness has applied the principles and methods reliably to the facts of the case."
Although experts can testify in any case in which their expertise is relevant, criminal cases are more likely to use forensic scientists or forensic psychologists, whereas civil cases, such as personal injury, may use forensic engineers, forensic accountants, employment consultants or care experts. Senior physicians – UK, Ireland, and Commonwealth consultants, U.S. attending physicians – are frequently used in both the civil and criminal courts.
The Federal Court of Australia has issued guidelines for experts appearing in Australian courts. This covers the format of the expert's written testimony as well as their behaviour in court. Similar procedures apply in non-court forums, such as the Australian Human Rights and Equal Opportunity Commission.
Types of expert witness.
Educating witness.
The educating witness teaches the fact-finder (jury or, in a bench trial, judge) about the underlying scientific theory and instrument implementing theory. This witness is an expert witness, called to elicit opinions that a theory is valid and the instruments involved are reliable. The witness must be accredited as an expert witness, which may require academic qualifications or specific training.
Reporting witness.
Called after teaching witness leaves stand. Usually the laboratory technician who personally conducted the test. Witness will describe both the test and the results. When describing test, will venture opinions that proper test procedures were used and that equipment was in good working order.
Scientific evidence.
In law, scientific evidence is evidence derived from scientific knowledge or techniques. Most forensic evidence, including genetic evidence, is scientific evidence.
"Frye" test.
The "Frye" test, coming from the case "Frye v. United States" (1923), said that admissible scientific evidence must be a result of a theory that had "general acceptance" in scientific community. This test results in uniform decisions regarding admissibility. In particular, the judges in "Frye" ruled that:
This test has been criticized as misunderstanding the scientific process and being based on the assumption that a jury is unable to evaluate scientific testimony. The goals of the test were to avoid evidence from overly questionable or controversial scientific theories to be used; it was used to exclude lie-detector results employed by the defense in the original case.
"Daubert" test.
The "Daubert" test arose out of the United States Supreme Court case "Daubert v. Merrell Dow Pharmaceuticals", 509 U.S. 579 (1993). It requires four things to be shown:
The Federal Rules of Evidence use the Daubert Test. See FRE 702.

</doc>
<doc id="10116" url="http://en.wikipedia.org/wiki?curid=10116" title="Endocytosis">
Endocytosis

 
Endocytosis is an energy-using process by which cells absorb molecules (such as proteins) by engulfing them. It is used by all cells of the body because most substances important to them are large polar molecules that cannot pass through the hydrophobic plasma or cell membrane. The opposite process is exocytosis. 
Endocytosis pathways.
Endocytosis pathways can be subdivided into four categories: namely, clathrin-mediated endocytosis, caveolae, macropinocytosis, and phagocytosis.
More recent experiments have suggested that these morphological descriptions of endocytic events may be inadequate, and a more appropriate method of classification may be based upon the clathrin-dependence of particular pathways, with multiple subtypes of clathrin-dependent and clathrin-independent endocytosis. Mechanistic insight into non-phagocytic, clathrin-independent endocytosis has been lacking, but a recent study has shown how Graf1 regulates a highly prevalent clathrin-independent endocytic pathway known as the CLIC/GEEC pathway.
Principal components of endocytic pathway.
The endocytic pathway of mammalian cells consists of distinct membrane compartments, which internalize molecules from the plasma membrane and recycle them back to the surface (as in early endosomes and recycling endosomes), or sort them to degradation (as in late endosomes and lysosomes). The principal components of the endocytic pathway are:
It was recently found that an eisosome serves as a portal of endocytosis in yeast.
Clathrin-mediated endocytosis.
The major route for endocytosis in most cells, and the best-understood, is that mediated by the molecule clathrin. This large protein assists in the formation of a coated pit on the inner surface of the plasma membrane of the cell. This pit then buds into the cell to form a coated vesicle in the cytoplasm of the cell. In so doing, it brings into the cell not only a small area of the surface of the cell but also a small volume of fluid from outside the cell.
Coats function to deform the donor membrane to produce a vesicle, and they also function in the selection of the vesicle cargo. Coat complexes that have been well characterized so far include coat protein-I (COP-I), COP-II, and clathrin. Clathrin coats are involved in two crucial transport steps: (i) receptor-mediated and fluid-phase endocytosis from the plasma membrane to early endosome and (ii) transport from the TGN to endosomes. In endocytosis, the clathrin coat is assembled on the cytoplasmic face of the plasma membrane, forming pits that invaginate to pinch off (scission) and become free CCVs. In cultured cells, the assembly of a CCV takes ~ 1min, and several hundred to a thousand or more can form every minute. The main scaffold component of clathrin coat is the 190-kD protein called clathrin heavy chain (CHC), which is associated with a 25- kD protein called clathrin light chain (CLC), forming three-legged trimers called triskelions.
Vesicles selectively concentrate and exclude certain proteins during formation and are not representative of the membrane as a whole. AP2 adaptors are multisubunit complexes that perform this function at the plasma membrane. The best-understood receptors that are found concentrated in coated vesicles of mammalian cells are the LDL receptor (which removes LDL from circulating blood), the transferrin receptor (which brings ferric ions bound by transferrin into the cell) and certain hormone receptors (such as that for EGF).
At any one moment, about 25% of the plasma membrane of a fibroblast is made up of coated pits. As a coated pit has a life of about a minute before it buds into the cell, a fibroblast takes up its surface by this route about once every 16 minutes. Coated vesicles formed from the plasma membrane have a diameter of about 36 nm and a lifetime measured in a few seconds. Once the coat has been shed, the remaining vesicle fuses with endosomes and proceeds down the endocytic pathway. The actual budding-in process, whereby a pit is converted to a vesicle, is carried out by clathrin assisted by a set of cytoplasmic proteins, which includes dynamin and adaptors such as adaptin.
Coated pits and vesicles were first seen in thin sections of tissue in the electron microscope by Matt Lions and Parker George. The importance of them for the clearance of LDL from blood was discovered by R. G Anderson, Michael S. Brown and Joseph L. Goldstein in 1977. Coated vesicles were first purified by Barbara Pearse, who discovered the clathrin coat molecule in 1976.

</doc>
<doc id="10118" url="http://en.wikipedia.org/wiki?curid=10118" title="Ezra Abbot">
Ezra Abbot

Ezra Abbot (April 28, 1819, Jackson, Maine – March 21, 1884, Cambridge, Massachusetts) was an American biblical scholar.
Life and writings.
He graduated from Bowdoin College in 1840. In 1847, at the request of Prof. Andrews Norton, he went to Cambridge, where he was principal of a public school until 1856. He was assistant librarian of Harvard University from 1856 to 1872, and planned and perfected an alphabetical card catalog, combining many of the advantages of the ordinary dictionary catalogs with the grouping of the minor topics under more general heads, which is characteristic of a systematic catalogue. From 1872 until his death he was Bussey Professor of New Testament Criticism and Interpretation in the Harvard Divinity School. 
Abbot's studies were chiefly in Oriental languages and textual criticism of the New Testament, though his work as a bibliographer showed such results as the exhaustive list of writings (5300 in all) on the doctrine of the future life, appended to W. R. Alger's "History of the Doctrine of a Future Life, as it has prevailed in all Nations and Ages" (1862), and published separately in 1864.
Abbot's publications, though always of the most thorough and scholarly character, were to a large extent dispersed in the pages of reviews, dictionaries, concordances, texts edited by others, Unitarian controversial treatises, etc. However, he took a more conspicuous and personal part in the preparation (with Baptist scholar Horatio B. Hackett) of the enlarged American edition of Dr. (afterwards Sir) William Smith's "Dictionary of the Bible" (1867-1870), to which he contributed more than 400 articles, as well as greatly improving the bibliographical completeness of the work. He was an efficient member of the American revision committee for the Revised Version (1881-1885) of the King James Bible, and helped prepare Caspar René Gregory's Prolegomena to the revised Greek New Testament of Constantin von Tischendorf.
He was one of the 32 founding members of the Society of Biblical Literature in 1880.
His principal single work, representing his scholarly method and conservative conclusions, was "The Authorship of the Fourth Gospel: External Evidences" (1880; 2nd ed. by J. H. Thayer, with other essays, 1889), originally a lecture. In spite of the compression due to its form, this work was up to that time probably the ablest defense, based on external evidence, of the Johannine authorship, and certainly the most complete treatment of the relation of Justin Martyr to this gospel.
Honors.
Abbot was elected a Fellow of the American Academy of Arts and Sciences in 1861. Though a layman, he received the degree of S.T.D. from Harvard in 1872, and that of D.D. from Edinburgh in 1884.

</doc>
<doc id="10119" url="http://en.wikipedia.org/wiki?curid=10119" title="Edwin Abbott Abbott">
Edwin Abbott Abbott

Edwin Abbott Abbott (20 December 1838 – 12 October 1926) was an English schoolmaster and theologian, best known as the author of the novella "Flatland" (1884).
Biography.
Edwin Abbott Abbott was the eldest son of Edwin Abbott (1808–1882), headmaster of the Philological School, Marylebone, and his wife, Jane Abbott (1806–1882). His parents were first cousins.
He was educated at the City of London School and at St John's College, Cambridge, where he took the highest honours in classics, mathematics and theology, and became a fellow of his college. In particular, he was 1st Smith's prizeman in 1861. [This seems to be an error by Venn:
Colby's preface to Abbott's "Flatland" states that Abbott was 7th "Senior Optime", "Senior Classic"
and 1st Chancellor's Medallist in 1861; William Steadman Aldis was 1st Smith's Prizeman in 1861.]
In 1862 he took orders. After holding masterships at King Edward's School, Birmingham, he succeeded G. F. Mortimer as headmaster of the City of London School in 1865 at the early age of twenty-six. Here he oversaw the education of future Prime Minister H. H. Asquith. He was Hulsean lecturer in 1876.
He retired in 1889, and devoted himself to literary and theological pursuits. Dr. Abbott's liberal inclinations in theology were prominent both in his educational views and in his books. His "Shakespearian Grammar" (1870) is a permanent contribution to English philology. In 1885 he published a life of Francis Bacon. His theological writings include three anonymously published religious romances - "Philochristus" (1878), where he tried to raise interest in Gospels reading, "Onesimus" (1882), and "Silanus the Christian" (1908).
More weighty contributions are the anonymous theological discussion "" (1886), "Philomythus" (1891), his book "The Anglican Career of Cardinal Newman" (1892), and his article "The Gospels" in the ninth edition of the "Encyclopædia Britannica", embodying a critical view which caused considerable stir in the English theological world. He also wrote "St Thomas of Canterbury, his Death and Miracles" (1898), "Johannine Vocabulary" (1905), "Johannine Grammar" (1906).
Abbott also wrote educational text books, one being "Via Latina: First Latin Book" which was published in 1898 and distributed around the world within the education system.
"Flatland".
Abbott's best-known work is his 1884 novella "Flatland: A Romance of Many Dimensions" which describes a two-dimensional world and explores the nature of dimensions. It has often been categorized as science fiction although it could more precisely be called "mathematical fiction".
With the advent of modern science fiction from the 1950s to the present day, "Flatland" has seen a revival in popularity, especially among science fiction and cyberpunk fans. Many works have been inspired by the novella, including novel sequels and short films.
Further reading.
</dl>

</doc>
<doc id="10120" url="http://en.wikipedia.org/wiki?curid=10120" title="Emma Abbott">
Emma Abbott

Emma Abbott (December 9, 1850 – January 5, 1891) was an American operatic soprano and impresario known for her pure, clear voice of great flexibility and volume.
Biography.
Early life.
Emma Abbott was born in 1850 in Chicago, Illinois, the daughter of the struggling Chicago musician Seth Abbott and his wife Almira Palmer. As a child she and her brother George studied singing, piano, guitar and violin with their father. The family moved to Peoria, Illinois in 1854 but Professor Abbott was unable to find a sufficient number of music students to make ends meet and the family suffered from financial problems. To help out, she and George began performing professionally when Emma was nine years old. She made her debut as a guitar player and singer in Peoria, Illinois in 1859, with George on the violin, and was teaching guitar by age thirteen.
Early career.
In 1866 she joined an itinerant concert troup and toured the country. While performing on the road she met and was befriended by Clara Louise Kellogg. Upon hearing Abbott in a concert in Toledo, Kellogg made it a point to meet her and encourage her to pursue an opera career and gave her a letter of introduction. Consequently, Abbott studied in New York City under Achille Errani, and made her concert début there in December 1871.
In 1872 Abbott went abroad to study with Antonio Sangiovanni in Milan. This was followed by further studies with Mathilde Marchesi, Pierre François Wartel and Enrico Delle Sedie in Paris. She appeared in several productions in Paris, earning rave reviews for her fine soprano voice. She was awarded a contract with the Royal Opera in London and made her début at Covent Garden as Marie in "La Fille du régiment" in 1876. However, her contract was cancelled shortly thereafter when she refused to sing Violetta from Verdi's "La Traviata" on moral grounds. That same year she secretly married Eugene Wetherell (d. 1889) and they returned to the United States, where she remained for the rest of her life.
Abbott English Opera Company.
On February 23, 1877, Abbott made her American operatic début in New York, once again portraying Marie. In 1878 she and her husband Eugene Wetherell, organized an opera company known by her name (the Abbott English Opera Company), which toured extensively throughout the United States. It was the first opera company formed by a woman in the United States. Her husband ran the business end of the company and she managed the artistic side, often starring in the productions.
The company garnered a reputation among the public for quality productions and was quite successful. Among the notable roles that Abbott sang with the company are Juliette in Gounod's "Roméo et Juliette", Virginia in "Paul et Virginie", Josephine in "H. M. S. Pinafore", the title role in Flotow's "Martha", Amina in Bellini's "La Sonnambula", and Violetta in "La Traviata", a role which she apparently no longer objected to, however, instead of singing "Addio del passato", she made Violetta expire with "Nearer, my God, to Thee".
Throughout her career, she retained artistic control over her troupe, which sometimes numbered 60. Although the company's repertoire included works from the French, Italian and English operatic literatures, they always performed in English. Many of the works were abridged and interpolated songs were commonplace. For this reason the company and Abbott were not popular with many music critics who were unhappy with the changes to the standard repertoire. However, the company was incredibly popular with the public and was consistently financially successful. Abbott herself became known among Americans as 'the people's prima donna'.
Death.
Abbott continued performing up until her sudden and unexpected death of pneumonia in Salt Lake City in 1891.

</doc>
<doc id="10121" url="http://en.wikipedia.org/wiki?curid=10121" title="Epimetheus">
Epimetheus

Epimetheus may mean one of several things:

</doc>
<doc id="10125" url="http://en.wikipedia.org/wiki?curid=10125" title="Emperor Shōmu">
Emperor Shōmu

Emperor Shōmu (聖武天皇, Shōmu-tennō, 701 – June 4, 756) was the 45th emperor of Japan, according to the traditional order of succession.
Shōmu's reign spanned the years 724 through 749.
Traditional narrative.
Before his ascension to the Chrysanthemum Throne, his personal name ("imina") is not clearly known, but he was known as Oshi-hiraki Toyosakura-hiko-no-mikoto.
Shōmu was the son of Emperor Mommu and Fujiwara no Miyako, a daughter of Fujiwara no Fuhito.
Shōmu had four Empresses and six Imperial sons and daughters.
Events of Shōmu's reign.
Shōmu was still a child at the time of his father's death; thus, Empresses Gemmei and Gensho occupied the throne before he acceded.
Shōmu continued to reside in the Hezei Palace.
Shōmu is known as the first emperor whose consort was not born into the imperial household. His consort Kōmyō was a non-royal Fujiwara commoner. A ritsuryo office was created for the queen-consort, the "Kogogushiki"; and this bureaucratic innovation continued into the Heian period.
Emperor Shōmu's tour to the eastern provinces.
While battle maneuvers of the Fujiwara no Hirotsugu Rebellion were still underway, in Tenpyō 12 10th month (November, 740) Emperor Shōmu left the capital at Heijō-kyō (Nara) and traveled eastward via Horikoshi (堀越頓宮; today Tsuge; 10th month, 29th day: November 22), Nabari (10th month, 30th day: November 23), Ao (安保頓宮; today Aoyama ; 11th month 1st day: November 24) to Kawaguchi in Ichishi District, Ise Province (today part of Tsu, formerly part of Hakusan) where he retreated together with his court to a temporary palace. One of his generals was left in command of the capital. Presumably Shōmu feared Fujiwara supporters in Nara and was hoping to quell potential uprisings in other parts of the country with his presence. After four days travelling through heavy rain and thick mud, the party reached Kawaguchi on Tenpyō 12 11th month, 2nd day (25 November, 740) A couple of days later, they learn of Hirotsugu's execution and that the rebellion had been quelled.
Despite the good news, Shōmu did not return to Heijō-kyō immediately, but stayed in Kawaguchi until Tenpyō 12 11th month, 11th day (4 December, 740). He continued his journey east, then north via Mino Province and back west along the shores of Lake Biwa to Kuni in Yamashiro Province (today in Kizugawa) which he reached on Tenpyō 12 12th month, 15th day (6 January, 741). Places passed along the way included Akasaka (赤坂頓宮; today Suzuka; 11th m. 14th d.: Dec 7）, Asake district (朝明郡; today Yokkaichi; 11th m. 20th d.: Dec 13）, Ishiura (石占頓宮; today Tado; 11th m. 25th d.: Dec 18）, Tagi district (当伎郡; today Yōrō; 11th m. 26th d.: Dec 19）, Fuwa (不破頓宮; today Tarui; 12th m. 1st d.: Dec 23）, Yokokawa (横川頓宮; today Santō or Maihara; 12th m. 6th d.: Dec 28), Inukami (犬上頓宮; today Hikone; 12th m. 7th d.: Dec 29）, Gamō district (蒲生郡; today near Yōkaichi; 12th m. 9th d.: Dec 31）, Yasu (野洲頓宮; today Yasu or Moriyama; 12th m. 10th d.: Jan 1）, Awazu (禾津頓宮; today Ōtsu; 12th m. 11th d.： Jan 2）, Tamanoi (玉井頓宮; today Yamashina-ku, Kyoto; 12th m. 14th d.）. Situated among the hills and near a river north of Nara, Kuni was easily defensible. In addition, the area was linked with the Minister of the Right, Tachibana no Moroe, while Nara was a center of the Fujiwara clan. On Tenpyō 12 12th month, 15 day (6 January, 741) Shōmu proclaimed a new capital at Kuni-kyō.
Legacy.
Shōmu, a devout Buddhist, is best remembered for commissioning, in 743, the sixteen-meter high statue of the Vairocana Buddha (the "Daibutsu") in Tōdai-ji of Nara. At the time, this was such a massive undertaking that later chroniclers accuse him of having completely exhausted the country's reserves of bronze and precious metals. In 752, the Shōmu held the Eye-opening Ceremony of the Great Buddha.
Earlier in 741, he established the system of provincial temples, making this the closest anyone ever came to declaring Japan a Buddhist nation. In addition he commissioned the observance of the ohigan holiday for both spring and autumnal equinox.
Emperor Shōmu died at age 56.
The actual site of Shōmu's grave is known. This emperor is traditionally venerated at a memorial Shinto shrine ("misasagi") at Nara.
The Imperial Household Agency designates this location as Shōmu's mausoleum. It is formally named "Sahoyama no minami no misasagi". The tomb site can be visited today in Horenji-cho, Tenri City near Nara City. The Imperial tomb of Shōmu's consort, Empress Kōmyō, is located nearby.
Kugyō.
"Kugyō" (公卿) is a collective term for the very few most powerful men attached to the court of the Emperor of Japan in pre-Meiji eras.
In general, this elite group included only three to four men at a time. These were hereditary courtiers whose experience and background would have brought them to the pinnacle of a life's career. During Shōmu's reign, this apex of the "Daijō-kan" included:
Eras of Shōmu's life.
The years of Shōmu's reign are more specifically identified by more than one era name or "nengō".

</doc>
<doc id="10126" url="http://en.wikipedia.org/wiki?curid=10126" title="Emperor Kanmu">
Emperor Kanmu

Emperor Kanmu (桓武天皇, Kanmu-tennō, 737–806) was the 50th emperor of Japan, according to the traditional order of succession. Kanmu reigned from 781 to 806.
Traditional narrative.
Kanmu's personal name ("imina") was Yamabe (山部). He was the eldest son of Prince Shirakabe (later known as Emperor Kōnin), and was born prior to Shirakabe's ascension to the throne. According to the "Shoku Nihongi" (続日本紀), Yamabe's mother, Yamato no Niigasa (later called Takano no Niigasa), was a 10th generation descendant of Muryeong of Baekje.
After his father became emperor, Kanmu's half-brother, Prince Osabe was appointed to the rank of crown prince. His mother was Princess Inoe, a daughter of Emperor Shōmu; but instead of Osabe, it was Kanmu who was later named to succeed their father. After Inoe and Prince Osabe were confined and then died in 775, Osabe's sister – Kanmu's half-sister Princess Sakahito – became Kanmu's wife. Later, when he ascended to the throne in 781, Kanmu appointed his young brother, Prince Sawara, whose mother was Takano no Niigasa, as crown prince. Hikami no Kawatsugu, a son of Emperor Temmu's grandson Prince Shioyaki and Shōmu's daughter Fuwa, attempted to carry out a coup d'état in 782, but it failed and Kawatsugu and his mother were sent into exile. In 785 Sawara was expelled and died in exile.
Kanmu had 16 empresses and consorts, and 32 imperial sons and daughters. Among them, three sons would eventually ascend to the imperial throne: Emperor Heizei, Emperor Saga and Emperor Junna. Some of his descendants (known as the "Kanmu Taira" or "Kanmu Heishi") took the Taira hereditary clan title, and in later generations became prominent warriors. Examples include Taira no Masakado, Taira no Kiyomori, and (with a further surname expansion) the Hōjō clan. The "waka" poet Ariwara no Narihira was one of his grandsons.
Kanmu is traditionally venerated at his tomb; the Imperial Household Agency designates Kashiwabara no Misasagi (柏原陵, Kashiwabara Imperial Mausoleum)
, in Fushimi-ku, Kyoto, as the location of Kanmu's mausoleum.
Events of Kanmu's life.
Kanmu was an active emperor who attempted to consolidate government hierarchies and functions. Kanmu appointed Sakanoue no Tamuramaro (758–811) to lead a military expedition against the Emishi.
Eras of Kanmu's reign.
The years of Kanmu's reign are more specifically identified by more than one era name ("nengō").
Politics.
Earlier Imperial sponsorship of Buddhism, beginning with Prince Shōtoku (574–622), had led to a general politicization of the clergy, along with an increase in intrigue and corruption. In 784 Kanmu shifted his capital from Nara to Nagaoka-kyō in a move that was said to be designed to edge the powerful Nara Buddhist establishments out of state politics—while the capital moved, the major Buddhist temples, and their officials, stayed put. Indeed there was a steady stream of edicts issued from 771 right through the period of Kūkai's studies which, for instance, sought to limit the number of Buddhist priests, and the building of temples. However the move was to prove disastrous and was followed by a series of natural disasters including the flooding of half the city. In 785 the principal architect of the new capital, and royal favourite, Fujiwara no Tanetsugu, was assassinated.
Meanwhile, Kanmu's armies were pushing back the boundaries of his empire. This led to an uprising, and in 789 a substantial defeat for Kanmu's troops. Also in 789 there was a severe drought and famine—the streets of the capital were clogged with the sick, and people avoiding being drafted into the military, or into forced labour. Many disguised themselves as Buddhist priests for the same reason. Then in 794 Kanmu suddenly shifted the capital again, this time to Heian-kyō, which is modern day Kyoto. The new capital was started early the previous year, but the change was abrupt and led to even more confusion amongst the populace.
Politically Kanmu shored up his rule by changing the syllabus of the university. Confucian ideology still provided the "raison d'être" for the Imperial government. In 784 Kanmu authorised the teaching of a new course based on the "Spring and Autumn Annals" based on two newly imported commentaries: "Kung-yang" and "Ku-liang". These commentaries used political rhetoric to promote a state in which the Emperor, as "Son of Heaven," should extend his sphere of influence to barbarous lands, thereby gladdening the people. In 798 the two commentaries became required reading at the government university.
Kanmu also sponsored the travels of the monks Saichō and Kūkai to China, from where they returned to found the Japanese branches of, respectively, Tendai and Shingon Buddhism.
Kugyō.
"Kugyō" (公卿) is a collective term for the very few most powerful men attached to the court of the Emperor of Japan in pre-Meiji eras.
In general, this elite group included only three to four men at a time. These were hereditary courtiers whose experience and background would have brought them to the pinnacle of a life's career. During Kanmu's reign, this apex of the "Daijō-kan included:
When the daughter of a "chūnagon" became the favored consort of the Crown Prince Ate (later known as Heizei"-tennō"), her father's power and position in court was affected. Kanmu disapproved of Fujiwara no Kusuko (藤原薬子, ?-810), daughter of Fujiwara no Tadanushi; and Kanmu had her removed from his son's household.
Consorts and children.
Emperor Kanmu's Imperial family included 36 children.
His Empress was Fujiwara no Otomuro (藤原乙牟漏) (760–790), daughter of Fujiwara no Yoshitsugu (藤原良継)
"Hi": Princess Sakahito (酒人内親王) (754–829), daughter of Emperor Kōnin
"Bunin": Fujiwara no Tabiko (藤原旅子) (759–788), daughter of Fujiwara no Momokawa 
"Bunin": Fujiwara no Yoshiko (藤原吉子) (?–807), daughter of Fujiwara no Korekimi 
"Bunin": Tajihi no Mamune (多治比真宗) (769–823), daughter of Tajihi no Nagano (多治比長野)
"Bunin": Fujiwara no Oguso (藤原小屎), daughter of Fujiwara no Washitori 
"Nyōgo": Tachibana no Miiko (橘御井子), daughter of Tachibana no Irii (橘入居)
"Nyōgo": Fujiwara no Nakako (藤原仲子), daughter of Fujiwara no Ieyori (藤原家依)
"Nyōgo": Fujiwara no "Shōshi" (藤原正子), daughter of Fujiwara no Kiyonari (藤原清成)
"Nyōgo": Ki no Otoio (紀乙魚) (?–840)
"Nyōgo": Kudara no Kyōhō (百済教法) (?–840), daughter of Kudara no Shuntetsu (百済俊哲)
Court lady: Fujiwara no Kamiko (藤原上子), daughter of Fujiwara no Oguromaro (藤原小黒麻呂)
Court lady: Tachibana no Tsuneko (橘常子) (788–817), daughter of Tachibana no Shimadamaro (橘島田麻呂)
Court lady: Sakanoue no Matako (坂上全子) (?–790), daughter of Sakanoue no Karitamaro (坂上刈田麻呂)
Court lady: Ki no Wakako (紀若子), daughter of Ki no Funamori (紀船守)
Court lady: Fujiwara no Kawako (藤原河子) (?–838), daughter of Fujiwara no Ōtsugu (藤原大継)
Court lady: Kudara no Kyōnin (百済教仁), daughter of Kudara no Bukyō (百済武鏡)
Court lady: Fujiwara no Azumako (藤原東子) (?–816), daughter of Fujiwara no Tanetsugu (藤原種継)
Court lady: Sakanoue no Haruko (坂上春子) (?–834), daughter of Sakanoue no Tamuramaro (坂上田村麻呂)
Court lady: Fujiwara no "Heishi/Nanshi" (藤原平子/南子) (?–833), daughter of Fujiwara no Takatoshi (藤原乙叡)
Court lady: Tachubana no Tamurako (橘田村子), daughter of Tachibana no Irii (橘入居)
Court lady: Kudara no Jōkyō (百済貞香), daughter of Kudara no Kyōtoku (百済教徳)
Court lady: Nakatomi no Toyoko (中臣豊子), daughter of Nakatomi no Ōio (中臣大魚)
Court lady: Kawakami no Manu (河上真奴), daughter of Nishikibe no Haruhito (錦部春人)
Court lady ("Nyoju"): Tajihi no Toyotsugu (多治比豊継), daughter of Tajihi no Hironari (多治比広成)
Court lady: Kudara no Yōkei (百済永継), daughter of Asukabe no Natomaro (飛鳥部奈止麻呂)
Legacy.
In 2001, Japan's emperor Akihito told reporters "I, on my part, feel a certain kinship with Korea, given the fact that it is recorded in the "Chronicles of Japan" that the mother of Emperor Kanmu was of the line of King Muryong of Baekje." It was the first time that a Japanese emperor publicly acknowledged Korean blood in the imperial line. According to the Shoku Nihongi, Emperor Kammu's mother, Takano no Niigasa is a descendant of Prince Junda, son of Muryeong, who died in Japan in 513 (Nihon Shoki Chapter 17).

</doc>
<doc id="10128" url="http://en.wikipedia.org/wiki?curid=10128" title="Elizabeth I of England">
Elizabeth I of England

Elizabeth I (7 September 1533 – 24 March 1603) was Queen of England and Ireland from 17 November 1558 until her death. Sometimes called The Virgin Queen, Gloriana or Good Queen Bess, the childless Elizabeth was the fifth and last monarch of the Tudor dynasty.
Elizabeth was the daughter of Henry VIII by second wife, Anne Boleyn, who was executed two and a half years after Elizabeth's birth. Anne's marriage to Henry VIII was annulled, and Elizabeth was declared illegitimate. Her half-brother, Edward VI, ruled until his death in 1553, bequeathing the crown to Lady Jane Grey and ignoring the claims of his two half-sisters, Elizabeth and the Roman Catholic Mary, in spite of statute law to the contrary. Edward's will was set aside and Mary became queen, deposing Lady Jane Grey. During Mary's reign, Elizabeth was imprisoned for nearly a year on suspicion of supporting Protestant rebels.
In 1558, Elizabeth succeeded her half-sister to the throne and set out to rule by good counsel. She depended heavily on a group of trusted advisers, led by William Cecil, Baron Burghley. One of her first actions as queen was the establishment of an English Protestant church, of which she became the Supreme Governor. This Elizabethan Religious Settlement was to evolve into the Church of England. It was expected that Elizabeth would marry and produce an heir to continue the Tudor line. She never did, despite numerous courtships. As she grew older, Elizabeth became famous for her virginity. A cult grew around her which was celebrated in the portraits, pageants, and literature of the day.
In government, Elizabeth was more moderate than her father and half-siblings had been. One of her mottoes was "video et taceo" ("I see, and say nothing"). In religion she was relatively tolerant and avoided systematic persecution. After 1570, when the pope declared her illegitimate and released her subjects from obedience to her, several conspiracies threatened her life, all of which were defeated with the help of her ministers' secret service. Elizabeth was cautious in foreign affairs, manoeuvring between the major powers of France and Spain. She only half-heartedly supported a number of ineffective, poorly resourced military campaigns in the Netherlands, France, and Ireland. By the mid-1580s, England could no longer avoid war with Spain. England's defeat of the Spanish Armada in 1588 associated Elizabeth with one of the greatest military victories in English history.
Elizabeth's reign is known as the Elizabethan era. The period is famous for the flourishing of English drama, led by playwrights such as William Shakespeare and Christopher Marlowe, and for the seafaring prowess of English adventurers such as Francis Drake. Some historians depict Elizabeth as a short-tempered, sometimes indecisive ruler, who enjoyed more than her share of luck. Towards the end of her reign, a series of economic and military problems weakened her popularity. Elizabeth is acknowledged as a charismatic performer and a dogged survivor in an era when government was ramshackle and limited, and when monarchs in neighbouring countries faced internal problems that jeopardised their thrones. Such was the case with Elizabeth's rival, Mary, Queen of Scots, whom she imprisoned in 1568 and had executed in 1587. After the short reigns of Elizabeth's half-siblings, her 44 years on the throne provided welcome stability for the kingdom and helped forge a sense of national identity.
Early life.
Elizabeth was born at Greenwich Palace and was named after both her grandmothers, Elizabeth of York and Elizabeth Howard. She was the second child of Henry VIII of England born in wedlock to survive infancy. Her mother was Henry's second wife, Anne Boleyn. At birth, Elizabeth was the heiress presumptive to the throne of England. Her older half-sister, Mary, had lost her position as a legitimate heir when Henry annulled his marriage to Mary's mother, Catherine of Aragon, to marry Anne and sire a male heir to ensure the Tudor succession. Elizabeth was baptised on 10 September; Archbishop Thomas Cranmer, the Marquess of Exeter, the Duchess of Norfolk and the Dowager Marchioness of Dorset stood as her godparents.
When Elizabeth was two years and eight months old, her mother was executed on 19 May 1536. Elizabeth was declared illegitimate and deprived of her place in the royal succession. Eleven days after Anne Boleyn's death, Henry married Jane Seymour, but she died shortly after the birth of their son, Prince Edward, in 1537. From his birth, Edward was undisputed heir apparent to the throne. Elizabeth was placed in his household and carried the chrisom, or baptismal cloth, at his christening.
Elizabeth's first governess or Lady Mistress, Margaret Bryan, wrote that she was "as toward a child and as gentle of conditions as ever I knew any in my life". By the autumn of 1537, Elizabeth was in the care of Blanche Herbert, Lady Troy, who remained her Lady Mistress until her retirement in late 1545 or early 1546. Catherine Champernowne, better known by her later, married name of Catherine "Kat" Ashley, was appointed as Elizabeth's governess in 1537, and she remained Elizabeth's friend until her death in 1565, when Blanche Parry succeeded her as Chief Gentlewoman of the Privy Chamber. Champernowne taught Elizabeth four languages: French, Flemish, Italian and Spanish. By the time William Grindal became her tutor in 1544, Elizabeth could write English, Latin, and Italian. Under Grindal, a talented and skilful tutor, she also progressed in French and Greek. After Grindal died in 1548, Elizabeth received her education under Roger Ascham, a sympathetic teacher who believed that learning should be engaging. By the time her formal education ended in 1550, she was one of the best educated women of her generation. By the end of her life, Elizabeth was also believed to speak Welsh, Cornish, Scottish and Irish in addition to English. The Venetian ambassador stated in 1603 that she "possessed [these] languages so thoroughly that each appeared to be her native tongue". Historian Mark Stoyle suggests that she was probably taught Cornish by William Killigrew, Groom of the Privy Chamber and later Chamberlain of the Exchequer.
Thomas Seymour.
Henry VIII died in 1547; Elizabeth's half-brother, Edward VI, became king at age nine. Catherine Parr, Henry's widow, soon married Thomas Seymour of Sudeley, Edward VI's uncle and the brother of the Lord Protector, Edward Seymour, Duke of Somerset. The couple took Elizabeth into their household at Chelsea. There Elizabeth experienced an emotional crisis that some historians believe affected her for the rest of her life. Seymour, approaching age 40 but having charm and "a powerful sex appeal", engaged in romps and horseplay with the 14-year-old Elizabeth. These included entering her bedroom in his nightgown, tickling her and slapping her on the buttocks. Parr, rather than confront her husband over his inappropriate activities, joined in. Twice she accompanied him in tickling Elizabeth, and once held her while he cut her black gown "into a thousand pieces." However, after Parr discovered the pair in an embrace, she ended this state of affairs. In May 1548, Elizabeth was sent away.
However, Thomas Seymour continued scheming to control the royal family and tried to have himself appointed the governor of the King's person. When Parr died after childbirth on 5 September 1548, he renewed his attentions towards Elizabeth, intent on marrying her. The details of his former behaviour towards Elizabeth emerged, and for his brother and the council, this was the last straw. In January 1549, Seymour was arrested on suspicion of plotting to marry Elizabeth and overthrow his brother. Elizabeth, living at Hatfield House, would admit nothing. Her stubbornness exasperated her interrogator, Sir Robert Tyrwhitt, who reported, "I do see it in her face that she is guilty". Seymour was beheaded on 20 March 1549.
Mary I's reign.
Edward VI died on 6 July 1553, aged 15. His will swept aside the Succession to the Crown Act 1543, excluded both Mary and Elizabeth from the succession, and instead declared as his heir Lady Jane Grey, granddaughter of Henry VIII's sister Mary, Duchess of Suffolk. Lady Jane was proclaimed queen by the Privy Council, but her support quickly crumbled, and she was deposed after nine days. On 3 August 1553, Mary rode triumphantly into London, with Elizabeth at her side.
The show of solidarity between the sisters did not last long. Mary, a devout Catholic, was determined to crush the Protestant faith in which Elizabeth had been educated, and she ordered that everyone attend Catholic Mass; Elizabeth had to outwardly conform. Mary's initial popularity ebbed away in 1554 when she announced plans to marry Prince Philip of Spain, the son of Emperor Charles V and an active Catholic. Discontent spread rapidly through the country, and many looked to Elizabeth as a focus for their opposition to Mary's religious policies.
In January and February 1554, Wyatt's rebellion broke out; it was soon suppressed. Elizabeth was brought to court, and interrogated regarding her role, and on 18 March, she was imprisoned in the Tower of London. Elizabeth fervently protested her innocence. Though it is unlikely that she had plotted with the rebels, some of them were known to have approached her. Mary's closest confidant, Charles V's ambassador Simon Renard, argued that her throne would never be safe while Elizabeth lived; and the Chancellor, Stephen Gardiner, worked to have Elizabeth put on trial. Elizabeth's supporters in the government, including Lord Paget, convinced Mary to spare her sister in the absence of hard evidence against her. Instead, on 22 May, Elizabeth was moved from the Tower to Woodstock, where she was to spend almost a year under house arrest in the charge of Sir Henry Bedingfield. Crowds cheered her all along the way.
On 17 April 1555, Elizabeth was recalled to court to attend the final stages of Mary's apparent pregnancy. If Mary and her child died, Elizabeth would become queen. If, on the other hand, Mary gave birth to a healthy child, Elizabeth's chances of becoming queen would recede sharply. When it became clear that Mary was not pregnant, no one believed any longer that she could have a child. Elizabeth's succession seemed assured.
King Philip, who ascended the Spanish throne in 1556, acknowledged the new political reality and cultivated his sister-in-law. She was a better ally than the chief alternative, Mary, Queen of Scots, who had grown up in France and was betrothed to the Dauphin of France. When his wife fell ill in 1558, King Philip sent the Count of Feria to consult with Elizabeth. This interview was conducted at Hatfield House, where she had returned to live in October 1555. By October 1558, Elizabeth was already making plans for her government. On 6 November, Mary recognised Elizabeth as her heir. On 17 November 1558, Mary died and Elizabeth succeeded to the throne.
Accession.
Elizabeth became queen at the age of 25, and declared her intentions to her Council and other peers who had come to Hatfield to swear allegiance. The speech contains the first record of her adoption of the mediaeval political theology of the sovereign's "two bodies": the body natural and the body politic:
My lords, the law of nature moves me to sorrow for my sister; the burden that is fallen upon me makes me amazed, and yet, considering I am God's creature, ordained to obey His appointment, I will thereto yield, desiring from the bottom of my heart that I may have assistance of His grace to be the minister of His heavenly will in this office now committed to me. And as I am but one body naturally considered, though by His permission a body politic to govern, so shall I desire you all ... to be assistant to me, that I with my ruling and you with your service may make a good account to Almighty God and leave some comfort to our posterity on earth. I mean to direct all my actions by good advice and counsel.
As her triumphal progress wound through the city on the eve of the coronation ceremony, she was welcomed wholeheartedly by the citizens and greeted by orations and pageants, most with a strong Protestant flavour. Elizabeth's open and gracious responses endeared her to the spectators, who were "wonderfully ravished". The following day, 15 January 1559, Elizabeth was crowned and anointed by Owen Oglethorpe, the Catholic bishop of Carlisle, in Westminster Abbey. She was then presented for the people's acceptance, amidst a deafening noise of organs, fifes, trumpets, drums, and bells.
Church settlement.
Elizabeth's personal religious convictions have been much debated by scholars. She was a Protestant, but kept Catholic symbols (such as the crucifix), and downplayed the role of sermons in defiance of a key Protestant belief.
In terms of public policy she favoured pragmatism in dealing with religious matters. The question of her legitimacy was a key concern: although she was technically illegitimate under both Protestant and Catholic law, her retroactively declared illegitimacy under the English church was not a serious bar compared to having never been legitimate as the Catholics claimed she was. For this reason alone, it was never in serious doubt that Elizabeth would embrace Protestantism.
Elizabeth and her advisers perceived the threat of a Catholic crusade against heretical England. Elizabeth therefore sought a Protestant solution that would not offend Catholics too greatly while addressing the desires of English Protestants; she would not tolerate the more radical Puritans though, who were pushing for far-reaching reforms. As a result, the parliament of 1559 started to legislate for a church based on the Protestant settlement of Edward VI, with the monarch as its head, but with many Catholic elements, such as priestly vestments.
The House of Commons backed the proposals strongly, but the bill of supremacy met opposition in the House of Lords, particularly from the bishops. Elizabeth was fortunate that many bishoprics were vacant at the time, including the Archbishopric of Canterbury. This enabled supporters amongst peers to outvote the bishops and conservative peers. Nevertheless, Elizabeth was forced to accept the title of Supreme Governor of the Church of England rather than the more contentious title of Supreme Head, which many thought unacceptable for a woman to bear. The new Act of Supremacy became law on 8 May 1559. All public officials were to swear an oath of loyalty to the monarch as the supreme governor or risk disqualification from office; the heresy laws were repealed, to avoid a repeat of the persecution of dissenters practised by Mary. At the same time, a new Act of Uniformity was passed, which made attendance at church and the use of an adapted version of the 1552 Book of Common Prayer compulsory, though the penalties for recusancy, or failure to attend and conform, were not extreme.
Marriage question.
From the start of Elizabeth's reign, it was expected that she would marry and the question arose to whom. She never did, although she received many offers for her hand; the reasons for this are not clear. Historians have speculated that Thomas Seymour had put her off sexual relationships, or that she knew herself to be infertile. She considered several suitors until she was about fifty. Her last courtship was with Francis, Duke of Anjou, 22 years her junior. While risking possible loss of power like her sister, who played into the hands of King Philip II of Spain, marriage offered the chance of an heir. However, the choice of a husband might also provoke political instability or even insurrection.
Robert Dudley.
In the spring of 1559, it became evident that Elizabeth was in love with her childhood friend Robert Dudley. It was said that Amy Robsart, his wife, was suffering from a "malady in one of her breasts", and that the Queen would like to marry Dudley if his wife should die. By the autumn of 1559 several foreign suitors were vying for Elizabeth's hand; their impatient envoys engaged in ever more scandalous talk and reported that a marriage with her favourite was not welcome in England: "There is not a man who does not cry out on him and her with indignation ... she will marry none but the favoured Robert". Amy Dudley died in September 1560 from a fall from a flight of stairs and, despite the coroner's inquest finding of accident, many people suspected Dudley to have arranged her death so that he could marry the queen. Elizabeth seriously considered marrying Dudley for some time. However, William Cecil, Nicholas Throckmorton, and some conservative peers made their disapproval unmistakably clear. There were even rumours that the nobility would rise if the marriage took place.
Among other marriages being considered for the queen, Robert Dudley was regarded as a possible candidate for nearly another decade. Elizabeth was extremely jealous of his affections, even when she no longer meant to marry him herself. In 1564 Elizabeth raised Dudley to the peerage as Earl of Leicester. He finally remarried in 1578, to which the queen reacted with repeated scenes of displeasure and lifelong hatred towards his wife, Lettice Knollys. Still, Dudley always "remained at the centre of [Elizabeth's] emotional life", as historian Susan Doran has described the situation. He died shortly after the defeat of the Armada. After Elizabeth's own death, a note from him was found among her most personal belongings, marked "his last letter" in her handwriting.
Foreign candidates.
Marriage negotiations constituted a key element in Elizabeth's foreign policy. She turned down Philip II's own hand early in 1559 but for several years entertained the proposal of King Eric XIV of Sweden. For several years she also seriously negotiated to marry Philip II's cousin Archduke Charles of Austria. By 1569, relations with the Habsburgs had deteriorated, and Elizabeth considered marriage to two French Valois princes in turn, first Henry, Duke of Anjou, and later, from 1572 to 1581, his brother Francis, Duke of Anjou, formerly Duke of Alençon. This last proposal was tied to a planned alliance against Spanish control of the Southern Netherlands. Elizabeth seems to have taken the courtship seriously for a time, and wore a frog-shaped earring that Anjou had sent her.
In 1563, Elizabeth told an imperial envoy: "If I follow the inclination of my nature, it is this: beggar-woman and single, far rather than queen and married". Later in the year, following Elizabeth's illness with smallpox, the succession question became a heated issue in Parliament. They urged the queen to marry or nominate an heir, to prevent a civil war upon her death. She refused to do either. In April she prorogued the Parliament, which did not reconvene until she needed its support to raise taxes in 1566. Having promised to marry previously, she told an unruly House:
I will never break the word of a prince spoken in public place, for my honour's sake. And therefore I say again, I will marry as soon as I can conveniently, if God take not him away with whom I mind to marry, or myself, or else some other great let happen.
By 1570, senior figures in the government privately accepted that Elizabeth would never marry or name a successor. William Cecil was already seeking solutions to the succession problem. For her failure to marry, Elizabeth was often accused of irresponsibility. Her silence, however, strengthened her own political security: she knew that if she named an heir, her throne would be vulnerable to a coup; she remembered that the way "a second person, as I have been" had been used as the focus of plots against her predecessor.
Elizabeth's unmarried status inspired a cult of virginity. In poetry and portraiture, she was depicted as a virgin or a goddess or both, not as a normal woman. At first, only Elizabeth made a virtue of her virginity: in 1559, she told the Commons, "And, in the end, this shall be for me sufficient, that a marble stone shall declare that a queen, having reigned such a time, lived and died a virgin". Later on, poets and writers took up the theme and turned it into an iconography that exalted Elizabeth. Public tributes to the Virgin by 1578 acted as a coded assertion of opposition to the queen's marriage negotiations with the Duke of Alençon.
Ultimately, Elizabeth would insist she was married to her kingdom and subjects, under divine protection. In 1599, she spoke of "all my husbands, my good people".
Mary, Queen of Scots.
Elizabeth's first policy toward Scotland was to oppose the French presence there. She feared that the French planned to invade England and put Mary, Queen of Scots, who was considered by many to be the heir to the English crown, on the throne. Elizabeth was persuaded to send a force into Scotland to aid the Protestant rebels, and though the campaign was inept, the resulting Treaty of Edinburgh of July 1560 removed the French threat in the north. When Mary returned to Scotland in 1561 to take up the reins of power, the country had an established Protestant church and was run by a council of Protestant nobles supported by Elizabeth. Mary refused to ratify the treaty.
In 1563 Elizabeth proposed her own suitor, Robert Dudley, as a husband for Mary, without asking either of the two people concerned. Both proved unenthusiastic, and in 1565 Mary married Henry Stuart, Lord Darnley, who carried his own claim to the English throne. The marriage was the first of a series of errors of judgement by Mary that handed the victory to the Scottish Protestants and to Elizabeth. Darnley quickly became unpopular in Scotland and then infamous for presiding over the murder of Mary's Italian secretary David Rizzio. In February 1567, Darnley was murdered by conspirators almost certainly led by James Hepburn, Earl of Bothwell. Shortly afterwards, on 15 May 1567, Mary married Bothwell, arousing suspicions that she had been party to the murder of her husband. Elizabeth wrote to her:
How could a worse choice be made for your honour than in such haste to marry such a subject, who besides other and notorious lacks, public fame has charged with the murder of your late husband, besides the touching of yourself also in some part, though we trust in that behalf falsely.
These events led rapidly to Mary's defeat and imprisonment in Loch Leven Castle. The Scottish lords forced her to abdicate in favour of her son James, who had been born in June 1566. James was taken to Stirling Castle to be raised as a Protestant. Mary escaped from Loch Leven in 1568 but after another defeat fled across the border into England, where she had once been assured of support from Elizabeth. Elizabeth's first instinct was to restore her fellow monarch; but she and her council instead chose to play safe. Rather than risk returning Mary to Scotland with an English army or sending her to France and the Catholic enemies of England, they detained her in England, where she was imprisoned for the next nineteen years.
Mary and the Catholic cause.
Mary was soon the focus for rebellion. In 1569 there was a major Catholic rising in the North; the goal was to free Mary, marry her to Thomas Howard, 4th Duke of Norfolk, and put her on the English throne. After the rebels' defeat, over 750 of them were executed on Elizabeth's orders. In the belief that the revolt had been successful, Pope Pius V issued a bull in 1570, titled "Regnans in Excelsis", which declared "Elizabeth, the pretended Queen of England and the servant of crime" to be excommunicate and a heretic, releasing all her subjects from any allegiance to her. Catholics who obeyed her orders were threatened with excommunication. The papal bull provoked legislative initiatives against Catholics by Parliament, which were however mitigated by Elizabeth's intervention. In 1581, to convert English subjects to Catholicism with "the intent" to withdraw them from their allegiance to Elizabeth was made a treasonable offence, carrying the death penalty. From the 1570s missionary priests from continental seminaries came to England secretly in the cause of the "reconversion of England". Many suffered execution, engendering a cult of martyrdom.
"Regnans in Excelsis" gave English Catholics a strong incentive to look to Mary Stuart as the true sovereign of England. Mary may not have been told of every Catholic plot to put her on the English throne, but from the Ridolfi Plot of 1571 (which caused Mary's suitor, the Duke of Norfolk, to lose his head) to the Babington Plot of 1586, Elizabeth's spymaster Sir Francis Walsingham and the royal council keenly assembled a case against her. At first, Elizabeth resisted calls for Mary's death. By late 1586 she had been persuaded to sanction her trial and execution on the evidence of letters written during the Babington Plot. Elizabeth's proclamation of the sentence announced that "the said Mary, pretending title to the same Crown, had compassed and imagined within the same realm divers things tending to the hurt, death and destruction of our royal person." On 8 February 1587, Mary was beheaded at Fotheringhay Castle, Northamptonshire. After Mary's execution, Elizabeth claimed not to have ordered it and indeed most accounts have her telling Secretary Davidson, who brought her the warrant to sign, not to dispatch the warrant even though she had signed it. The sincerity of Elizabeth's remorse and her motives for telling Davidson not to execute the warrant have been called into question both by her contemporaries and later historians.
Wars and overseas trade.
Elizabeth's foreign policy was largely defensive. The exception was the English occupation of Le Havre from October 1562 to June 1563, which ended in failure when Elizabeth's Huguenot allies joined with the Catholics to retake the port. Elizabeth's intention had been to exchange Le Havre for Calais, lost to France in January 1558. Only through the activities of her fleets did Elizabeth pursue an aggressive policy. This paid off in the war against Spain, 80% of which was fought at sea. She knighted Francis Drake after his circumnavigation of the globe from 1577 to 1580, and he won fame for his raids on Spanish ports and fleets. An element of piracy and self-enrichment drove Elizabethan seafarers, over which the queen had little control.
Netherlands expedition.
After the occupation and loss of Le Havre in 1562–1563, Elizabeth avoided military expeditions on the continent until 1585, when she sent an English army to aid the Protestant Dutch rebels against Philip II. This followed the deaths in 1584 of the allies William the Silent, Prince of Orange, and Francis, Duke of Anjou, and the surrender of a series of Dutch towns to Alexander Farnese, Duke of Parma, Philip's governor of the Spanish Netherlands. In December 1584, an alliance between Philip II and the French Catholic League at Joinville undermined the ability of Anjou's brother, Henry III of France, to counter Spanish domination of the Netherlands. It also extended Spanish influence along the channel coast of France, where the Catholic League was strong, and exposed England to invasion. The siege of Antwerp in the summer of 1585 by the Duke of Parma necessitated some reaction on the part of the English and the Dutch. The outcome was the Treaty of Nonsuch of August 1585, in which Elizabeth promised military support to the Dutch. The treaty marked the beginning of the Anglo-Spanish War, which lasted until the Treaty of London in 1604.
The expedition was led by her former suitor, Robert Dudley, Earl of Leicester. Elizabeth from the start did not really back this course of action. Her strategy, to support the Dutch on the surface with an English army, while beginning secret peace talks with Spain within days of Leicester's arrival in Holland, had necessarily to be at odds with Leicester's, who wanted and was expected by the Dutch to fight an active campaign. Elizabeth on the other hand, wanted him "to avoid at all costs any decisive action with the enemy". He enraged Elizabeth by accepting the post of Governor-General from the Dutch States General. Elizabeth saw this as a Dutch ploy to force her to accept sovereignty over the Netherlands, which so far she had always declined. She wrote to Leicester:
We could never have imagined (had we not seen it fall out in experience) that a man raised up by ourself and extraordinarily favoured by us, above any other subject of this land, would have in so contemptible a sort broken our commandment in a cause that so greatly touches us in honour ... And therefore our express pleasure and commandment is that, all delays and excuses laid apart, you do presently upon the duty of your allegiance obey and fulfill whatsoever the bearer hereof shall direct you to do in our name. Whereof fail you not, as you will answer the contrary at your utmost peril.
Elizabeth's "commandment" was that her emissary read out her letters of disapproval publicly before the Dutch Council of State, Leicester having to stand nearby. This public humiliation of her "Lieutenant-General" combined with her continued talks for a separate peace with Spain, irreversibly undermined his standing among the Dutch. The military campaign was severely hampered by Elizabeth's repeated refusals to send promised funds for her starving soldiers. Her unwillingness to commit herself to the cause, Leicester's own shortcomings as a political and military leader and the faction-ridden and chaotic situation of Dutch politics were reasons for the campaign's failure. Leicester finally resigned his command in December 1587.
Spanish Armada.
Meanwhile, Sir Francis Drake had undertaken a major voyage against Spanish ports and ships to the Caribbean in 1585 and 1586, and in 1587 had made a successful raid on Cadiz, destroying the Spanish fleet of war ships intended for the "Enterprise of England": Philip II had decided to take the war to England.
On 12 July 1588, the Spanish Armada, a great fleet of ships, set sail for the channel, planning to ferry a Spanish invasion force under the Duke of Parma to the coast of southeast England from the Netherlands. A combination of miscalculation, misfortune, and an attack of English fire ships on 29 July off Gravelines which dispersed the Spanish ships to the northeast defeated the Armada. The Armada straggled home to Spain in shattered remnants, after disastrous losses on the coast of Ireland (after some ships had tried to struggle back to Spain via the North Sea, and then back south past the west coast of Ireland). Unaware of the Armada's fate, English militias mustered to defend the country under the Earl of Leicester's command. He invited Elizabeth to inspect her troops at Tilbury in Essex on 8 August. Wearing a silver breastplate over a white velvet dress, she addressed them in one of her most famous speeches:
My loving people, we have been persuaded by some that are careful of our safety, to take heed how we commit ourself to armed multitudes for fear of treachery; but I assure you, I do not desire to live to distrust my faithful and loving people ... I know I have the body but of a weak and feeble woman, but I have the heart and stomach of a king, and of a King of England too, and think foul scorn that Parma or Spain, or any Prince of Europe should dare to invade the borders of my realm.
When no invasion came, the nation rejoiced. Elizabeth's procession to a thanksgiving service at St Paul's Cathedral rivalled that of her coronation as a spectacle. The defeat of the armada was a potent propaganda victory, both for Elizabeth and for Protestant England. The English took their delivery as a symbol of God's favour and of the nation's inviolability under a virgin queen. However, the victory was not a turning point in the war, which continued and often favoured Spain. The Spanish still controlled the southern provinces of the Netherlands, and the threat of invasion remained. Sir Walter Raleigh claimed after her death that Elizabeth's caution had impeded the war against Spain:
If the late queen would have believed her men of war as she did her scribes, we had in her time beaten that great empire in pieces and made their kings of figs and oranges as in old times. But her Majesty did all by halves, and by petty invasions taught the Spaniard how to defend himself, and to see his own weakness.
Though some historians have criticised Elizabeth on similar grounds, Raleigh's verdict has more often been judged unfair. Elizabeth had good reason not to place too much trust in her commanders, who once in action tended, as she put it herself, "to be transported with an haviour of vainglory".
Supporting Henry IV of France.
When the Protestant Henry IV inherited the French throne in 1589, Elizabeth sent him military support. It was her first venture into France since the retreat from Le Havre in 1563. Henry's succession was strongly contested by the Catholic League and by Philip II, and Elizabeth feared a Spanish takeover of the channel ports. The subsequent English campaigns in France, however, were disorganised and ineffective. Lord Willoughby, largely ignoring Elizabeth's orders, roamed northern France to little effect, with an army of 4,000 men. He withdrew in disarray in December 1589, having lost half his troops. In 1591, the campaign of John Norreys, who led 3,000 men to Brittany, was even more of a disaster. As for all such expeditions, Elizabeth was unwilling to invest in the supplies and reinforcements requested by the commanders. Norreys left for London to plead in person for more support. In his absence, a Catholic League army almost destroyed the remains of his army at Craon, north-west France, in May 1591. In July, Elizabeth sent out another force under Robert Devereux, Earl of Essex, to help Henry IV in besieging Rouen. The result was just as dismal. Essex accomplished nothing and returned home in January 1592. Henry abandoned the siege in April. As usual, Elizabeth lacked control over her commanders once they were abroad. "Where he is, or what he doth, or what he is to do," she wrote of Essex, "we are ignorant".
Ireland.
Although Ireland was one of her two kingdoms, Elizabeth faced a hostile, and in places virtually autonomous, Irish population that adhered to Catholicism and was willing to defy her authority and plot with her enemies. Her policy there was to grant land to her courtiers and prevent the rebels from giving Spain a base from which to attack England. In the course of a series of uprisings, Crown forces pursued scorched-earth tactics, burning the land and slaughtering man, woman and child. During a revolt in Munster led by Gerald FitzGerald, Earl of Desmond, in 1582, an estimated 30,000 Irish people starved to death. The poet and colonist Edmund Spenser wrote that the victims "were brought to such wretchedness as that any stony heart would have rued the same". Elizabeth advised her commanders that the Irish, "that rude and barbarous nation", be well treated; but she showed no remorse when force and bloodshed were deemed necessary.
Between 1594 and 1603, Elizabeth faced her most severe test in Ireland during the Nine Years' War, a revolt that took place at the height of hostilities with Spain, who backed the rebel leader, Hugh O'Neill, Earl of Tyrone. In spring 1599, Elizabeth sent Robert Devereux, 2nd Earl of Essex, to put the revolt down. To her frustration, he made little progress and returned to England in defiance of her orders. He was replaced by Charles Blount, Lord Mountjoy, who took three years to defeat the rebels. O'Neill finally surrendered in 1603, a few days after Elizabeth's death. Soon afterwards, a peace treaty was signed between England and Spain.
Russia.
Elizabeth continued to maintain the diplomatic relations with the Tsardom of Russia originally established by her deceased brother. She often wrote to Ivan IV ("Ivan the Terrible"), on amicable terms, though the Tsar was often annoyed by her focus on commerce rather than on the possibility of a military alliance. The Tsar even proposed to her once, and during his later reign, asked for a guarantee to be granted asylum in England should his rule be jeopardised.
Upon Ivan's death, he was succeeded by his simple-minded son Feodor. Unlike his father, Feodor had no enthusiasm in maintaining exclusive trading rights with England. Feodor declared his kingdom open to all foreigners, and dismissed the English ambassador Sir Jerome Bowes, whose pomposity had been tolerated by the new Tsar's late father. Elizabeth sent a new ambassador, Dr. Giles Fletcher, to demand from the regent Boris Godunov that he convince the Tsar to reconsider. The negotiations failed, due to Fletcher addressing Feodor with two of his titles omitted. Elizabeth continued to appeal to Feodor in half appealing, half reproachful letters. She proposed an alliance, something which she had refused to do when offered one by Feodor's father, but was turned down.
Barbary states, Ottoman Empire.
Trade and diplomatic relations developed between England and the Barbary states during the rule of Elizabeth. England established a trading relationship with Morocco in opposition to Spain, selling armour, ammunition, timber, and metal in exchange for Moroccan sugar, in spite of a Papal ban. In 1600, Abd el-Ouahed ben Messaoud, the principal secretary to the Moroccan ruler Mulai Ahmad al-Mansur, visited England as an ambassador to the court of Queen Elizabeth I, to negotiate an Anglo-Moroccan alliance against Spain. Elizabeth "agreed to sell munitions supplies to Morocco, and she and Mulai Ahmad al-Mansur talked on and off about mounting a joint operation against the Spanish". Discussions however remained inconclusive, and both rulers died within two years of the embassy.
Diplomatic relations were also established with the Ottoman Empire with the chartering of the Levant Company and the dispatch of the first English ambassador to the Porte, William Harborne, in 1578. For the first time, a Treaty of Commerce was signed in 1580. Numerous envoys were dispatched in both directions and epistolar exchanges occurred between Elizabeth and Sultan Murad III. In one correspondence, Murad entertained the notion that Islam and Protestantism had "much more in common than either did with Roman Catholicism, as both rejected the worship of idols", and argued for an alliance between England and the Ottoman Empire. To the dismay of Catholic Europe, England exported tin and lead (for cannon-casting) and ammunitions to the Ottoman Empire, and Elizabeth seriously discussed joint military operations with Murad III during the outbreak of war with Spain in 1585, as Francis Walsingham was lobbying for a direct Ottoman military involvement against the common Spanish enemy.
Later years.
The period after the defeat of the Spanish Armada in 1588 brought new difficulties for Elizabeth that lasted the fifteen years until the end of her reign. The conflicts with Spain and in Ireland dragged on, the tax burden grew heavier, and the economy was hit by poor harvests and the cost of war. Prices rose and the standard of living fell. During this time, repression of Catholics intensified, and Elizabeth authorised commissions in 1591 to interrogate and monitor Catholic householders. To maintain the illusion of peace and prosperity, she increasingly relied on internal spies and propaganda. In her last years, mounting criticism reflected a decline in the public's affection for her.
One of the causes for this "second reign" of Elizabeth, as it is sometimes called, was the changed character of Elizabeth's governing body, the privy council in the 1590s. A new generation was in power. With the exception of Lord Burghley, the most important politicians had died around 1590: the Earl of Leicester in 1588; Sir Francis Walsingham in 1590; and Sir Christopher Hatton in 1591. Factional strife in the government, which had not existed in a noteworthy form before the 1590s, now became its hallmark. A bitter rivalry arose between the Earl of Essex and Robert Cecil, son of Lord Burghley and their respective adherents, and the struggle for the most powerful positions in the state marred politics. The queen's personal authority was lessening, as is shown in the 1594 affair of Dr. Lopez, her trusted physician. When he was wrongly accused by the Earl of Essex of treason out of personal pique, she could not prevent his execution, although she had been angry about his arrest and seems not to have believed in his guilt.
During the last years of her reign, Elizabeth came to rely on the granting of monopolies as a cost-free system of patronage, rather than asking Parliament for more subsidies in a time of war. The practice soon led to price-fixing, the enrichment of courtiers at the public's expense, and widespread resentment. This culminated in agitation in the House of Commons during the parliament of 1601. In her famous "Golden Speech" of 30 November 1601 at Whitehall Palace to a deputation of 140 members, Elizabeth professed ignorance of the abuses, and won the members over with promises and her usual appeal to the emotions:
Who keeps their sovereign from the lapse of error, in which, by ignorance and not by intent they might have fallen, what thank they deserve, we know, though you may guess. And as nothing is more dear to us than the loving conservation of our subjects' hearts, what an undeserved doubt might we have incurred if the abusers of our liberality, the thrallers of our people, the wringers of the poor, had not been told us!
This same period of economic and political uncertainty, however, produced an unsurpassed literary flowering in England. The first signs of a new literary movement had appeared at the end of the second decade of Elizabeth's reign, with John Lyly's "Euphues" and Edmund Spenser's "The Shepheardes Calender" in 1578. During the 1590s, some of the great names of English literature entered their maturity, including William Shakespeare and Christopher Marlowe. During this period and into the Jacobean era that followed, the English theatre reached its highest peaks. The notion of a great Elizabethan age depends largely on the builders, dramatists, poets, and musicians who were active during Elizabeth's reign. They owed little directly to the queen, who was never a major patron of the arts.
As Elizabeth aged her image gradually changed. She was portrayed as Belphoebe or Astraea, and after the Armada, as Gloriana, the eternally youthful Faerie Queene of Edmund Spenser's poem. Her painted portraits became less realistic and more a set of enigmatic icons that made her look much younger than she was. In fact, her skin had been scarred by smallpox in 1562, leaving her half bald and dependent on wigs and cosmetics. Sir Walter Raleigh called her "a lady whom time had surprised". However, the more Elizabeth's beauty faded, the more her courtiers praised it.
Elizabeth was happy to play the part, but it is possible that in the last decade of her life she began to believe her own performance. She became fond and indulgent of the charming but petulant young Robert Devereux, Earl of Essex, who was Leicester's stepson and took liberties with her for which she forgave him. She repeatedly appointed him to military posts despite his growing record of irresponsibility. After Essex's desertion of his command in Ireland in 1599, Elizabeth had him placed under house arrest and the following year deprived him of his monopolies. In February 1601, the earl tried to raise a rebellion in London. He intended to seize the queen but few rallied to his support, and he was beheaded on 25 February. Elizabeth knew that her own misjudgements were partly to blame for this turn of events. An observer reported in 1602 that "Her delight is to sit in the dark, and sometimes with shedding tears to bewail Essex".
Death.
Elizabeth's senior adviser, Burghley, died on 4 August 1598. His political mantle passed to his son, Robert Cecil, who soon became the leader of the government. One task he addressed was to prepare the way for a smooth succession. Since Elizabeth would never name her successor, Cecil was obliged to proceed in secret. He therefore entered into a coded negotiation with James VI of Scotland, who had a strong but unrecognised claim. Cecil coached the impatient James to humour Elizabeth and "secure the heart of the highest, to whose sex and quality nothing is so improper as either needless expostulations or over much curiosity in her own actions". The advice worked. James's tone delighted Elizabeth, who responded: "So trust I that you will not doubt but that your last letters are so acceptably taken as my thanks cannot be lacking for the same, but yield them to you in grateful sort". In historian J. E. Neale's view, Elizabeth may not have declared her wishes openly to James, but she made them known with "unmistakable if veiled phrases".
The Queen's health remained fair until the autumn of 1602, when a series of deaths among her friends plunged her into a severe depression. In February 1603, the death of Catherine Howard, Countess of Nottingham, the niece of her cousin and close friend Catherine, Lady Knollys, came as a particular blow. In March, Elizabeth fell sick and remained in a "settled and unremovable melancholy". She died on 24 March 1603 at Richmond Palace, between two and three in the morning. A few hours later, Cecil and the council set their plans in motion and proclaimed James VI of Scotland as James I of England.
Elizabeth's coffin was carried downriver at night to Whitehall, on a barge lit with torches. At her funeral on 28 April, the coffin was taken to Westminster Abbey on a hearse drawn by four horses hung with black velvet. In the words of the chronicler John Stow:
Westminster was surcharged with multitudes of all sorts of people in their streets, houses, windows, leads and gutters, that came out to see the obsequy, and when they beheld her statue lying upon the coffin, there was such a general sighing, groaning and weeping as the like hath not been seen or known in the memory of man.
Elizabeth was interred in Westminster Abbey in a tomb she shares with her half-sister, Mary. The Latin inscription on their tomb, "Regno consortes & urna, hic obdormimus Elizabetha et Maria sorores, in spe resurrectionis", translates to "Consorts in realm and tomb, here we sleep, Elizabeth and Mary, sisters, in hope of resurrection".
Legacy and memory.
Elizabeth was lamented by many of her subjects, but others were relieved at her death. Expectations of King James started high but then declined, so by the 1620s there was a nostalgic revival of the cult of Elizabeth. Elizabeth was praised as a heroine of the Protestant cause and the ruler of a golden age. James was depicted as a Catholic sympathiser, presiding over a corrupt court. The triumphalist image that Elizabeth had cultivated towards the end of her reign, against a background of factionalism and military and economic difficulties, was taken at face value and her reputation inflated. Godfrey Goodman, Bishop of Gloucester, recalled: "When we had experience of a Scottish government, the Queen did seem to revive. Then was her memory much magnified." Elizabeth's reign became idealised as a time when crown, church and parliament had worked in constitutional balance.
The picture of Elizabeth painted by her Protestant admirers of the early 17th century has proved lasting and influential. Her memory was also revived during the Napoleonic Wars, when the nation again found itself on the brink of invasion. In the Victorian era, the Elizabethan legend was adapted to the imperial ideology of the day, and in the mid-20th century, Elizabeth was a romantic symbol of the national resistance to foreign threat. Historians of that period, such as J. E. Neale (1934) and A. L. Rowse (1950), interpreted Elizabeth's reign as a golden age of progress. Neale and Rowse also idealised the Queen personally: she always did everything right; her more unpleasant traits were ignored or explained as signs of stress.
Recent historians, however, have taken a more complicated view of Elizabeth. Her reign is famous for the defeat of the Armada, and for successful raids against the Spanish, such as those on Cádiz in 1587 and 1596, but some historians point to military failures on land and at sea. In Ireland, Elizabeth's forces ultimately prevailed, but their tactics stain her record. Rather than as a brave defender of the Protestant nations against Spain and the Habsburgs, she is more often regarded as cautious in her foreign policies. She offered very limited aid to foreign Protestants and failed to provide her commanders with the funds to make a difference abroad.
Elizabeth established an English church that helped shape a national identity and remains in place today. Those who praised her later as a Protestant heroine overlooked her refusal to drop all practices of Catholic origin from the Church of England. Historians note that in her day, strict Protestants regarded the Acts of Settlement and Uniformity of 1559 as a compromise. In fact, Elizabeth believed that faith was personal and did not wish, as Francis Bacon put it, to "make windows into men's hearts and secret thoughts".
Though Elizabeth followed a largely defensive foreign policy, her reign raised England's status abroad. "She is only a woman, only mistress of half an island," marvelled Pope Sixtus V, "and yet she makes herself feared by Spain, by France, by the Empire, by all". Under Elizabeth, the nation gained a new self-confidence and sense of sovereignty, as Christendom fragmented. Elizabeth was the first Tudor to recognise that a monarch ruled by popular consent. She therefore always worked with parliament and advisers she could trust to tell her the truth—a style of government that her Stuart successors failed to follow. Some historians have called her lucky; she believed that God was protecting her. Priding herself on being "mere English", Elizabeth trusted in God, honest advice, and the love of her subjects for the success of her rule. In a prayer, she offered thanks to God that:
[At a time] when wars and seditions with grievous persecutions have vexed almost all kings and countries round about me, my reign hath been peacable, and my realm a receptacle to thy afflicted Church. The love of my people hath appeared firm, and the devices of my enemies frustrate.
References.
</dl>
Further reading.
Historiography and memory.
</dl>

</doc>
<doc id="10130" url="http://en.wikipedia.org/wiki?curid=10130" title="Emperor Jimmu">
Emperor Jimmu

Emperor Jimmu (神武天皇, Jinmu-tennō) was the first emperor of Japan, according to legend. His accession is traditionally dated as 660 BCE. He was seen as a descendant of the sun goddess Amaterasu through her grandson Ninigi, as well as a descendant of the storm god Susanoo. He launched a military expedition from Hyuga near the Inland Sea, captured Yamato, and established this as his center of power.
Name and title.
The conventional names and dates of the early emperors were accepted in the reign of Emperor Kanmu (737–806), when Ōmi no Mifune conferred on all putative 'emperors' before Ōjin, known until then as "sumera no mikoto/ōkimi", the title of "tennō" ("Heavenly Ruler"), a Japanese pendant to the Chinese imperial title "Tiān-dì" (天帝). This practice had begun under Empress Suiko, and took root after the Taika Reforms with the ascendancy of the Nakatomi clan. Jimmu's name, like those of several other legendary emperors, was already attested among the ruler names of the Korean kingdom of Silla.
According to the legendary account in the Kojiki, Emperor Jimmu was born on February 13, 711 BCE (the first day of the first month of the Chinese calendar), and died, again according to legend, on March 11, 585 BCE (both dates according to the lunisolar ).
Both the Kojiki and the Nihon Shoki give Jimmu's name as Kan'yamato Iware-biko (神倭伊波礼) "Iware" indicates a toponym whose precise purport is unclear.
The Imperial house of Japan traditionally based its claim to the throne on its putative descent from the sun-goddess Amaterasu via Jimmu's great grandfather Ninigi.
Legendary narrative.
In Japanese mythology, the Age of the Gods is the period before Jimmu's accession.
The story of Jimmu seems to rework legends associated with the Ōtomo clan, and its function was to establish that clan's links to the ruling family, just as those of Suijin arguably reflect Mononobe tales and the legends in Ōjin's chronicles seem to derive from Soga clan traditions. Jimmu figures as a direct descendant of the sun goddess, Amaterasu via the side of his father, Ugayafukiaezu. Amaterasu had a son called Ame no Oshihomimi no Mikoto and through him a grandson named Ninigi-no-Mikoto. She sent her grandson to the Japanese islands where he eventually married Konohana-Sakuya-hime. Among their three sons was Hikohohodemi no Mikoto, also called Yamasachi-hiko, who married Toyotama-hime. She was the daughter of Ryūjin, the Japanese sea god. They had a single son called Hikonagisa Takeugaya Fukiaezu no Mikoto. The boy was abandoned by his parents at birth and consequently raised by Tamayori-hime, his mother's younger sister. They eventually married and had four sons. The last of these, Kan'yamato Iwarebiko, became Emperor Jimmu.
Jimmu's migration.
Mythic records in the "Kojiki" and "Nihon Shoki" describe, with distinct versions that often disagree on details, how Jimmu's brothers were born in Takachiho, the southern part of Kyūshū (in modern day Miyazaki prefecture), and decided to move eastward, as they found the location inappropriate for reigning over the entire country. Jimmu's older brother, Itsuse no Mikoto, originally led the migration, and led the clan eastward through the Seto Inland Sea with the assistance of local chieftain "Sao Netsuhiko". As they reached Naniwa (modern day Ōsaka), they encountered another local chieftain, "Nagasunehiko" (lit. "the long-legged man"), and Itsuse was killed in the ensuing battle. Jimmu realized that they had been defeated because they battled eastward against the sun, so he decided to land on the east side of Kii Peninsula and to battle westward. They reached Kumano, and, with the guidance of a three-legged crow, "Yatagarasu" (lit. "eight-span crow"), they moved to Yamato. There, they once again battled Nagasunehiko and were victorious.
In Yamato, "Nigihayahi no Mikoto", who also claim descent from the Takamagahara gods, was protected by Nagasunehiko. However, when Nigihayahi met Jimmu, he accepted Jimmu's legitimacy. At this point, Jimmu is said to have ascended to the throne of Japan.
According to the "Kojiki", Jimmu died when he was 126 years old. This emperor's posthumous name literally means "divine might" or "god-warrior". It is undisputed that this identification is Chinese in form and Buddhist in implication, which suggests that the name must have been regularized centuries after the lifetime ascribed to Jimmu. It is generally thought that Jimmu's name and character evolved into their present shape just before the time in which legends about the origins of the Yamato dynasty were chronicled in the "Kojiki".
The fluidity of Jimmu before the compilation of the "Kojiki" and of the "Nihon Shoki" is demonstrated by somewhat earlier texts that place three dynasties as successors to the mythological Yamato state. According to these texts, Jimmu's dynasty was supplanted by that of Emperor Ōjin, whose dynasty was supplanted by that of Emperor Keitai. The "Kojiki" and the "Nihon Shoki" then combined these three mythical dynasties into one long and continuous genealogy.
The traditional site of Jimmu's grave is near Unebiyama in Kashihara.
Modern veneration of Emperor Jimmu.
Veneration of Emperor Jimmu was a central component of the imperial cult that formed following the Meiji restoration. 1872-73 saw the establishment of a new holiday called "Kigensetsu" ("Era Day") commemorating the anniversary of Jimmu's ascension to the throne 2,532 years earlier. Between 1873 and 1945 an imperial envoy sent offerings every year to Mount Unebi, the supposed site of Jimmu's tomb.
In 1890 Kashihara Shrine was established nearby, on the spot where Jimmu was said to have ascended to the throne.
Before and during World War II, expansionist propaganda made frequent use of the phrase "hakkō ichiu", a neologism coined by Tanaka Chigaku based on a passage in the "Nihon Shoki" discussing Emperor Jimmu. Some media incorrectly attributed the exact phrase to Emperor Jimmu. For the 1940 "Kigensetsu" celebration, marking the supposed 2,600th anniversary of Jimmu's enthronement, the Peace Tower (平和の塔, Heiwa no Tō, originally called the "Hakkō Ichiu Tower" 八紘一宇の塔 "Hakkō Ichiu no Tō" or the "Pillar of Heaven and Earth" 八紘之基柱 "Ametsuchi no Motohashira") was constructed in Miyazaki.
The same year numerous stone monuments relating to key events in Jimmu's life were erected around Japan. The sites at which these monuments were erected are known as "Emperor Jimmu Sacred Historical Sites". "Kigensetsu" was suspended in 1948 during the occupation of Japan, but was reinstated in 1966 as "Kenkoku Kinen no hi", which continues to be celebrated as a national holiday.
References.
</dl>

</doc>
<doc id="10133" url="http://en.wikipedia.org/wiki?curid=10133" title="Elias Boudinot">
Elias Boudinot

Elias Boudinot ( ; May 2, 1740 – October 24, 1821) was a lawyer and statesman from Elizabeth, New Jersey who was a delegate to the Continental Congress (more accurately referred to as the Congress of the Confederation) and served as President of Congress from 1782 to 1783. He was elected as a U.S. Congressman for New Jersey following the American Revolutionary War. He was appointed by President George Washington as Director of the United States Mint, serving from 1795 until 1805.
Early life and education.
Elias Boudinot was born in Philadelphia on May 2, 1740. His father, Elias Boudinot III, was a merchant and silversmith; he was a neighbor and friend of Benjamin Franklin. His mother, Mary Catherine Williams, was born in the British West Indies; her father was from Wales. Elias' paternal grandfather, Elie (sometimes called Elias) Boudinot, was the son of Jean Boudinot and Marie Suire of Marans, Aunis, France. They were a Huguenot (French Protestant) family who fled to New York about 1687 to avoid the religious persecutions of King Louis XIV. 
Mary Catherine Williams and Elias Boudinot, Sr. were married on August 8, 1729. Over the next twenty years, they had nine children. The first, John, was born in the British West Indies-Antigua. Of the others, only the younger Elias and his siblings Annis, Mary, and Elisha reached adulthood. Annis became one of the first published women poets in the Thirteen Colonies, and her work appeared in leading newspapers and magazines. Elisha Boudinot became Chief Justice of the Supreme Court of New Jersey.
After studying and being tutored at home, Elias Boudinot went to Princeton, New Jersey to read the law as a legal apprentice to Richard Stockton. An attorney, he had married Elias' older sister Annis Boudinot. Richard Stockton was later a signatory of the Declaration of Independence.
Career.
In 1760, Boudinot was admitted to the bar, and began his practice in Elizabeth, New Jersey. He owned land adjacent to the road from Elizabethtown to Woodbridge Township, New Jersey.
Marriage and family.
After getting established, on April 21, 1762, Boudinot married Hannah Stockton (1736–1808), Richard's younger sister. They had two children, Maria Boudinot, who died at age two, and Susan Vergereau Boudinot. 
Susan married William Bradford, who became Chief Justice of Pennsylvania and Attorney General under George Washington. After her husband's death in 1795, Susan Boudinot Bradford returned to her parents' home to live. The young widow edited her father's papers. Now held by Princeton University, these provide significant insight into the events of the Revolutionary era. 
In 1805, Elias, Hannah and Susan moved to a new home in Burlington, New Jersey. Hannah died a few years after their move, and Elias lived there for the remainder of his years.
Later career.
In his later years, Boudinot invested and speculated in land. He owned large tracts in Ohio including most of Green Township in what is now the western suburbs of Cincinnati, where there is a street bearing his surname. At his death, he willed 13,000 acre to the city of Philadelphia for parks and city needs.
Political career.
Boudinot became a prominent lawyer and his practice prospered. As the revolution drew near, he aligned with the Whigs, and was elected to the New Jersey provincial assembly in 1775. In the early stages of the Revolutionary War, he was active in promoting enlistment; several times he loaned money to field commanders to purchase supplies. Boudinot helped support the activities of rebel spies. After the British occupation of New York City, spies were sent to Staten Island and Long Island, New York to observe and report on movements of specific British garrisons and regiments. 
On May 5, 1777, General George Washington asked Boudinot to be appointed as commissary general for prisoners. Congress through the board of war concurred. Boudinot was commissioned as a colonel in the Continental Army for this work. He served until July 1778, when competing responsibilities forced him to resign. The commissary managed enemy prisoners, and also was responsible for supplying American prisoners who were held by the British.
In November 1777, the New Jersey legislature named Boudinot as one of their delegates to the Second Continental Congress. His duties as Commissary prevented his attendance, so in May 1778 he resigned. By early July he had been replaced and attended his first meeting of the Congress on July 7, 1778. As a delegate, he still continued his concerns for the welfare of prisoners of war. His first term ended that year.
In 1781, Boudinot returned to the Congress, for a term lasting through 1783. In November 1782, he was elected as President of the Continental Congress for a one-year term. The President of Congress was a mostly ceremonial position with no real authority, but the office did require him to handle a good deal of correspondence and sign official documents. On April 15, 1783 he signed the Preliminary Articles of Peace.
When the United States (US) government was formed in 1789, Boudinot was elected from New Jersey to the US House of Representatives. He was elected to the second and third congresses as well, where he generally supported the administration. He refused to join the expansion of affiliated groups that formed formal political parties. 
In 1794, he declined to serve another term, and left Congress in early 1795. In October 1795, President George Washington appointed him as Director of the United States Mint, a position he held through succeeding administrations until he retired in 1805.
Later public service.
In addition to serving in political office, Elias supported many civic, religious, and educational causes during his life. Boudinot served as one of the trustees of the College of New Jersey (later Princeton University) for nearly half a century, from 1772 until 1821. When the Continental Congress was forced to leave Philadelphia in 1783 while he was president, he moved the meetings to Princeton, where they met in the College's Nassau Hall.
On September 24, 1789, the House of Representatives voted to recommend the First Amendment of the newly drafted Constitution to the states for ratification. The next day, Congressman Boudinot proposed that the House and Senate jointly request of President Washington to proclaim a day of thanksgiving for “the many signal favors of Almighty God.” Boudinot said that he
“could not think of letting the session pass over without offering an opportunity to all the citizens of the United States of joining, with one voice, in returning to Almighty God their sincere thanks for the many blessings he had poured down upon them.”
Boudinot was elected a member of the American Antiquarian Society in 1814.
A devout Presbyterian, Boudinot supported missions and missionary work. He wrote "The Age of Revelation" in response to Thomas Paine's "The Age of Reason." He was one of the founders of the American Bible Society, and after 1816 served as its President. 
He argued for the rights of black and American Indian citizens, and sponsored students to the Board School for Indians in Connecticut. One of these, a young Cherokee named "Gallegina Uwatie", also known as "Buck Watie", stayed with him in Burlington on his way to the school. The two so impressed each other that "Gallegina" asked for and was given permission to adopt the statesman's name. Later known as Elias Boudinot, he was an editor of the "Cherokee Phoenix", the nation's first newspaper, which was published in Cherokee and English.
Archival Collections.
The Presbyterian Historical Society in Philadelphia has a related to Boudinot from 1777-1821 in its holdings. The correspondence dating from 1777-1778 almost exclusively deals with the trading and releasing of prisoners.

</doc>
<doc id="10134" url="http://en.wikipedia.org/wiki?curid=10134" title="Electromagnetic spectrum">
Electromagnetic spectrum

<br>
The electromagnetic spectrum is the range of all possible frequencies of electromagnetic radiation. The "electromagnetic spectrum" "of an object" has a different meaning, and is instead the characteristic distribution of electromagnetic radiation emitted or absorbed by that particular object.
The electromagnetic spectrum extends from below the low frequencies used for modern radio communication to gamma radiation at the short-wavelength (high-frequency) end, thereby covering wavelengths from thousands of kilometers down to a fraction of the size of an atom. The limit for long wavelengths is the size of the universe itself, while it is thought that the short wavelength limit is in the vicinity of the Planck length. Until the middle of last century it was believed by most physicists that this spectrum was infinite and continuous.
Most parts of the electromagnetic spectrum are used in science for spectroscopic and other probing interactions, as ways to study and characterize matter. In addition, radiation from various parts of the spectrum has found many other uses for communications and manufacturing (see electromagnetic radiation for more applications).
History of electromagnetic spectrum discovery.
For most of history, visible light was the only known part of the electromagnetic spectrum. The ancient Greeks recognized that light traveled in straight lines and studied some of its properties, including reflection and refraction. Over the years the study of light continued and during the 16th and 17th centuries there were conflicting theories which regarded light as either a wave or a particle.
The first discovery of electromagnetic radiation other than visible light came in 1800, when William Herschel discovered infrared radiation. He was studying the temperature of different colors by moving a thermometer through light split by a prism. He noticed that the highest temperature was beyond red. He theorized that this temperature change was due to "calorific rays" which would be in fact a type of light ray that could not be seen. The next year, Johann Ritter worked at the other end of the spectrum and noticed what he called "chemical rays" (invisible light rays that induced certain chemical reactions) that behaved similar to visible violet light rays, but were beyond them in the spectrum. They were later renamed ultraviolet radiation.
Electromagnetic radiation had been first linked to electromagnetism in 1845, when Michael Faraday noticed that the polarization of light traveling through a transparent material responded to a magnetic field (see Faraday effect). During the 1860s James Maxwell developed four partial differential equations for the electromagnetic field. Two of these equations predicted the possibility of, and behavior of, waves in the field. Analyzing the speed of these theoretical waves, Maxwell realized that they must travel at a speed that was about the known speed of light. This startling coincidence in value led Maxwell to make the inference that light itself is a type of electromagnetic wave.
Maxwell's equations predicted an infinite number of frequencies of electromagnetic waves, all traveling at the speed of light. This was the first indication of the existence of the entire electromagnetic spectrum.
Maxwell's predicted waves included waves at very low frequencies compared to infrared, which in theory might be created by oscillating charges in an ordinary electrical circuit of a certain type. Attempting to prove Maxwell's equations and detect such low frequency electromagnetic radiation, in 1886 the physicist Heinrich Hertz built an apparatus to generate and detect what is now called radio waves. Hertz found the waves and was able to infer (by measuring their wavelength and multiplying it by their frequency) that they traveled at the speed of light. Hertz also demonstrated that the new radiation could be both reflected and refracted by various dielectric media, in the same manner as light. For example, Hertz was able to focus the waves using a lens made of tree resin. In a later experiment, Hertz similarly produced and measured the properties of microwaves. These new types of waves paved the way for inventions such as the wireless telegraph and the radio.
In 1895 Wilhelm Röntgen noticed a new type of radiation emitted during an experiment with an evacuated tube subjected to a high voltage. He called these radiations x-rays and found that they were able to travel through parts of the human body but were reflected or stopped by denser matter such as bones. Before long, many uses were found for them in the field of medicine.
The last portion of the electromagnetic spectrum was filled in with the discovery of gamma rays. In 1900 Paul Villard was studying the radioactive emissions of radium when he identified a new type of radiation that he first thought consisted of particles similar to known alpha and beta particles, but with the power of being far more penetrating than either. However, in 1910, British physicist William Henry Bragg demonstrated that gamma rays are electromagnetic radiation, not particles, and in 1914, Ernest Rutherford (who had named them gamma rays in 1903 when he realized that they were fundamentally different from charged alpha and beta rays) and Edward Andrade measured their wavelengths, and found that gamma rays were similar to X-rays, but with shorter wavelengths and higher frequencies.
Range of the spectrum.
Electromagnetic waves are typically described by any of the following three physical properties: the frequency "f", wavelength λ, or photon energy "E". Frequencies observed in astronomy range from (1 GeV gamma rays) down to the local plasma frequency of the ionized interstellar medium (~1 kHz). Wavelength is inversely proportional to the wave frequency, so gamma rays have very short wavelengths that are fractions of the size of atoms, whereas wavelengths on the opposite end of the spectrum can be as long as the universe. Photon energy is directly proportional to the wave frequency, so gamma ray photons have the highest energy (around a billion electron volts), while radio wave photons have very low energy (around a femtoelectronvolt). These relations are illustrated by the following equations:
where:
Whenever electromagnetic waves exist in a medium with matter, their wavelength is decreased. Wavelengths of electromagnetic radiation, no matter what medium they are traveling through, are usually quoted in terms of the "vacuum wavelength", although this is not always explicitly stated.
Generally, electromagnetic radiation is classified by wavelength into radio wave, microwave, terahertz (or sub-millimeter) radiation, infrared, the visible region is perceived as light, ultraviolet, X-rays and gamma rays. The behavior of EM radiation depends on its wavelength. When EM radiation interacts with single atoms and molecules, its behavior also depends on the amount of energy per quantum (photon) it carries.
Spectroscopy can detect a much wider region of the EM spectrum than the visible range of 400 nm to 700 nm. A common laboratory spectroscope can detect wavelengths from 2 nm to 2500 nm. Detailed information about the physical properties of objects, gases, or even stars can be obtained from this type of device. Spectroscopes are widely used in astrophysics. For example, many hydrogen atoms emit a radio wave photon that has a wavelength of 21.12 cm. Also, frequencies of 30 Hz and below can be produced by and are important in the study of certain stellar nebulae and frequencies as high as have been detected from astrophysical sources.
Rationale for spectrum regional names.
Electromagnetic radiation interacts with matter in different ways across the spectrum. These types of interaction are so different that historically different names have been applied to different parts of the spectrum, as though these were different types of radiation. Thus, although these "different kinds" of electromagnetic radiation form a quantitatively continuous spectrum of frequencies and wavelengths, the spectrum remains divided for practical reasons related to these qualitative interaction differences.
Types of radiation.
Boundaries.
A discussion of the regions (or bands or types) of the electromagnetic spectrum is given below. Note that there are no precisely defined boundaries between the bands of the electromagnetic spectrum; rather they fade into each other like the bands in a rainbow (which is the sub-spectrum of visible light). Radiation of each frequency and wavelength (or in each band) will have a mixture of properties of two regions of the spectrum that bound it. For example, red light resembles infrared radiation in that it can excite and add energy to some chemical bonds and indeed must do so to power the chemical mechanisms responsible for photosynthesis and the working of the visual system.
Regions of the spectrum.
The types of electromagnetic radiation are broadly classified into the following classes:
This classification goes in the increasing order of wavelength, which is characteristic of the type of radiation.
While, in general, the classification scheme is accurate, in reality there is often some overlap between neighboring types of electromagnetic energy. For example, SLF radio waves at 60 Hz may be received and studied by astronomers, or may be ducted along wires as electric power, although the latter is, in the strict sense, not electromagnetic radiation at all (see near and far field).
The distinction between X-rays and gamma rays is partly based on sources: the photons generated from nuclear decay or other nuclear and subnuclear/particle process, are always termed gamma rays, whereas X-rays are generated by electronic transitions involving highly energetic inner atomic electrons. In general, nuclear transitions are much more energetic than electronic transitions, so gamma-rays are more energetic than X-rays, but exceptions exist. By analogy to electronic transitions, muonic atom transitions are also said to produce X-rays, even though their energy may exceed 6 MeV, whereas there are many (77 known to be less than 10 keV) low-energy nuclear transitions (e.g., the 7.6 eV nuclear transition of thorium-229), and, despite being one million-fold less energetic than some muonic X-rays, the emitted photons are still called gamma rays due to their nuclear origin.
The convention that EM radiation that is known to come from the nucleus, is always called "gamma ray" radiation is the only convention that is universally respected, however. Many astronomical gamma ray sources (such as gamma ray bursts) are known to be too energetic (in both intensity and wavelength) to be of nuclear origin. Quite often, in high energy physics and in medical radiotherapy, very high energy EMR (in the >10 MeV region) which is of higher energy than any nuclear gamma ray, is not referred to as either X-ray or gamma-ray, but instead by the generic term of "high energy photons."
The region of the spectrum in which a particular observed electromagnetic radiation falls, is reference frame-dependent (due to the Doppler shift for light), so EM radiation that one observer would say is in one region of the spectrum could appear to an observer moving at a substantial fraction of the speed of light with respect to the first to be in another part of the spectrum. For example, consider the cosmic microwave background. It was produced, when matter and radiation decoupled, by the de-excitation of hydrogen atoms to the ground state. These photons were from Lyman series transitions, putting them in the ultraviolet (UV) part of the electromagnetic spectrum. Now this radiation has undergone enough cosmological red shift to put it into the microwave region of the spectrum for observers moving slowly (compared to the speed of light) with respect to the cosmos.
Radio frequency.
Radio waves generally are utilized by antennas of appropriate size (according to the principle of resonance), with wavelengths ranging from hundreds of meters to about one millimeter. They are used for transmission of data, via modulation. Television, mobile phones, wireless networking, and amateur radio all use radio waves. The use of the radio spectrum is regulated by many governments through frequency allocation.
Radio waves can be made to carry information by varying a combination of the amplitude, frequency, and phase of the wave within a frequency band. When EM radiation impinges upon a conductor, it couples to the conductor, travels along it, and induces an electric current on the surface of that conductor by exciting the electrons of the conducting material. This effect (the skin effect) is used in antennas.
Microwaves.
The super-high frequency (SHF) and extremely high frequency (EHF) of microwaves are on the short side of radio waves. Microwaves are waves that are typically short enough (measured in millimeters) to employ tubular metal waveguides of reasonable diameter. Microwave energy is produced with klystron and magnetron tubes, and with solid state diodes such as Gunn and IMPATT devices. Microwaves are absorbed by molecules that have a dipole moment in liquids. In a microwave oven, this effect is used to heat food. Low-intensity microwave radiation is used in Wi-Fi, although this is at intensity levels unable to cause thermal heating.
Volumetric heating, as used by microwave ovens, transfers energy through the material electromagnetically, not as a thermal heat flux. The benefit of this is a more uniform heating and reduced heating time; microwaves can heat material in less than 1% of the time of conventional heating methods.
When active, the average microwave oven is powerful enough to cause interference at close range with poorly shielded electromagnetic fields such as those found in mobile medical devices and poorly made consumer electronics.
Terahertz radiation.
Terahertz radiation is a region of the spectrum between far infrared and microwaves. Until recently, the range was rarely studied and few sources existed for microwave energy at the high end of the band (sub-millimeter waves or so-called terahertz waves), but applications such as imaging and communications are now appearing. Scientists are also looking to apply terahertz technology in the armed forces, where high-frequency waves might be directed at enemy troops to incapacitate their electronic equipment.
Infrared radiation.
The infrared part of the electromagnetic spectrum covers the range from roughly 300 GHz to 400 THz (1 mm - 750 nm). It can be divided into three parts:
Visible radiation (light).
Above infrared in frequency comes visible light. The Sun emits its peak power in the visible region, although integrating the entire emission power spectrum through all wavelengths shows that the Sun emits slightly more infrared than visible light. By definition, visible light is the part of the EM spectrum to which the human eye is the most sensitive. Visible light (and near-infrared light) is typically absorbed and emitted by electrons in molecules and atoms that move from one energy level to another. This action allows the chemical mechanisms that underlie human vision and plant photosynthesis. The light which excites the human visual system is a very small portion of the electromagnetic spectrum. A rainbow shows the optical (visible) part of the electromagnetic spectrum; infrared (if it could be seen) would be located just beyond the red side of the rainbow with ultraviolet appearing just beyond the violet end.
Electromagnetic radiation with a wavelength between 380 nm and 760 nm (400–790 terahertz) is detected by the human eye and perceived as visible light. Other wavelengths, especially near infrared (longer than 760 nm) and ultraviolet (shorter than 380 nm) are also sometimes referred to as light, especially when the visibility to humans is not relevant. White light is a combination of lights of different wavelengths in the visible spectrum. Passing white light through a prism splits it up into the several colors of light observed in the visible spectrum between 400 nm and 780 nm.
If radiation having a frequency in the visible region of the EM spectrum reflects off an object, say, a bowl of fruit, and then strikes the eyes, this results in visual perception of the scene. The brain's visual system processes the multitude of reflected frequencies into different shades and hues, and through this insufficiently-understood psychophysical phenomenon, most people perceive a bowl of fruit.
At most wavelengths, however, the information carried by electromagnetic radiation is not directly detected by human senses. Natural sources produce EM radiation across the spectrum, and technology can also manipulate a broad range of wavelengths. Optical fiber transmits light that, although not necessarily in the visible part of the spectrum (it is usually infrared), can carry information. The modulation is similar to that used with radio waves.
Ultraviolet radiation.
Next in frequency comes ultraviolet (UV). The wavelength of UV rays is shorter than the violet end of the visible spectrum but longer than the X-ray.
UV in the very shortest range (next to X-rays) is capable even of ionizing atoms (see photoelectric effect), greatly changing their physical behavior.
At the middle range of UV, UV rays cannot ionize but can break chemical bonds, making molecules to be unusually reactive. Sunburn, for example, is caused by the disruptive effects of middle range UV radiation on skin cells, which is the main cause of skin cancer. UV rays in the middle range can irreparably damage the complex DNA molecules in the cells producing thymine dimers making it a very potent mutagen.
The Sun emits significant UV radiation (about 10% of its total power), including extremely short wavelength UV that could potentially destroy most life on land (ocean water would provide some protection for life there). However, most of the Sun's most-damaging UV wavelengths are absorbed by the atmosphere and ozone layer before they reach the surface. The higher energy (shortest wavelength) ranges of UV (called "vacuum UV") are absorbed by nitrogen and, at longer wavelengths, by simple diatomic oxygen in the air. Most of the UV in the mid-range of energy is blocked by the ozone layer, which absorbs strongly in the important 200–315 nm range, the lower part of which is too long to be absorbed by ordinary dioxygen in air. The very lowest energy range of UV between 315 nm and visible light (called UV-A) is not blocked well by the atmosphere, but does not cause sunburn and does less biological damage. However, it is not harmless and does cause oxygen radicals, mutation and skin damage. See ultraviolet for more information.
X-rays.
After UV come X-rays, which, like the upper ranges of UV are also ionizing. However, due to their higher energies, X-rays can also interact with matter by means of the Compton effect. Hard X-rays have shorter wavelengths than soft X-rays. As they can pass through most substances with some absorption, X-rays can be used to 'see through' objects with thicknesses less than equivalent to a few meters of water. One notable use in this category is diagnostic X-ray images in medicine (a process known as radiography). X-rays are useful as probes in high-energy physics. In astronomy, the accretion disks around neutron stars and black holes emit X-rays, which enable them to be studied. X-rays are also emitted by the coronas of stars and are strongly emitted by some types of nebulae. However, X-ray telescopes must be placed outside the Earth's atmosphere to see astronomical X-rays, since the atmosphere of Earth is a radiation shield with areal density of 1000 grams per cm2, which is the same areal density as 1000 centimeters or 10 meters thickness of water. This is an amount sufficient to block almost all astronomical X-rays (and also astronomical gamma rays—see below).
Gamma rays.
After hard X-rays come gamma rays, which were discovered by Paul Villard in 1900. These are the most energetic photons, having no defined lower limit to their wavelength. In astronomy they are valuable for studying high-energy objects or regions, however like with X-rays this can only be done with telescopes outside the Earth's atmosphere. Gamma rays are useful to physicists thanks to their penetrative ability and their production from a number of radioisotopes. Gamma rays are also used for the irradiation of food and seed for sterilization, and in medicine they are occasionally used in radiation cancer therapy. More commonly, gamma rays are used for diagnostic imaging in nuclear medicine, with an example being PET scans. The wavelength of gamma rays can be measured with high accuracy by means of Compton scattering. Gamma rays are first and mostly blocked by Earth's magnetosphere then by the atmosphere.

</doc>
<doc id="10136" url="http://en.wikipedia.org/wiki?curid=10136" title="Expert system">
Expert system

In artificial intelligence, an expert system is a computer system that emulates the decision-making ability of a human expert.
Expert systems are designed to solve complex problems by reasoning about knowledge, represented primarily as if–then rules rather than through conventional procedural code. The first expert systems were created in the 1970s and then proliferated in the 1980s. Expert systems were among the first truly successful forms of AI software.
An expert system is divided into two sub-systems: the inference engine and the knowledge base. The knowledge base represents facts and rules. The inference engine applies the rules to the known facts to deduce new facts. Inference engines can also include explanation and debugging capabilities.
History.
Edward Feigenbaum in a 1977 paper said that the key insight of early expert systems was that "intelligent systems derive their power from the knowledge they possess rather than from the specific formalisms and inference schemes they use" (as paraphrased by Hayes-Roth, et al.) Although, in retrospect, this seems a rather straightforward insight, it was a significant step forward at the time. Until then, research had been focused on attempts to develop very general-purpose problem solvers such as those described by Newell and Simon.
Expert systems were introduced by the Stanford Heuristic Programming Project led by Feigenbaum, who is sometimes referred to as the "father of expert systems". The Stanford researchers tried to identify domains where expertise was highly valued and complex, such as diagnosing infectious diseases (Mycin) and identifying unknown organic molecules (Dendral).
In addition to Feigenbaum key early contributors were Edward Shortliffe, Bruce Buchanan, and Randall Davis. Expert systems were among the first truly successful forms of AI software.
Research on expert systems was also active in France. In the US the focus tended to be on rule-based systems, first on systems hard coded on top of LISP programming environments and then on expert system shells developed by vendors such as Intellicorp. In France research focused more on systems developed in Prolog. The advantage of expert system shells was that they were somewhat easier for non-programmers to use. The advantage of Prolog environments was that they weren't focused only on IF-THEN rules. Prolog environments provided a much fuller realization of a complete First Order Logic environment.
In the 1980s, expert systems proliferated. Universities offered expert system courses and two thirds of the Fortune 1000 companies applied the technology in daily business activities. Interest was international with the Fifth Generation Computer Systems project in Japan and increased research funding in Europe.
In 1981 the first IBM PC was introduced, with the MS-DOS operating system. The imbalance between the relatively powerful chips in the highly affordable PC compared to the much more expensive price of processing power in the Mainframes that dominated the corporate IT world at the time created a whole new type of architecture for corporate computing known as the Client-server model. Calculations and reasoning could be performed at a fraction of the price of a mainframe using a PC. This model also enabled business units to bypass corporate IT departments and directly build their own applications. As a result client server had a tremendous impact on the expert systems market. Expert systems were already outliers in much of the business world, requiring new skills that many IT departments did not have and were not eager to develop. They were a natural fit for new PC-based shells that promised to put application development into the hands of end users and experts. Up until that point the primary development environment for expert systems had been high end Lisp machines from Xerox, Symbolics and Texas Instruments. With the rise of the PC and client server computing vendors such as Intellicorp and Inference Corporation shifted their priorities to developing PC based tools. In addition new vendors often financed by Venture Capital started appearing regularly. These new vendors included Aion Corporation, Neuron Data, Exsys, and many others.
In the 1990s and beyond the term "expert system" and the idea of a standalone AI system mostly dropped from the IT lexicon. There are two interpretations of this. One is that "expert systems failed": the IT world moved on because expert systems didn't deliver on their over hyped promise. The other is the mirror opposite, that expert systems were simply victims of their success. As IT professionals grasped concepts such as rule engines such tools migrated from standalone tools for the development of special purpose "expert" systems to one more tool that an IT professional has at their disposal. Many of the leading major business application suite vendors such as SAP, Siebel, and Oracle integrated expert system capabilities into their suite of products as a way of specifying business logic. Rule engines are no longer simply for defining the rules an expert would use but for any type of complex, volatile, and critical business logic. They often go hand in hand with business process automation and integration environments.
Software architecture.
An expert system is an example of a knowledge-based system. Expert systems were the first commercial systems to use a knowledge-based architecture. A knowledge-based system is essentially composed of two sub-systems: the knowledge base and the inference engine.
The knowledge base represents facts about the world. In early expert systems such as Mycin and Dendral these facts were represented primarily as flat assertions about variables. In later expert systems developed with commercial shells the knowledge base took on more structure and utilized concepts from object-oriented programming. The world was represented as classes, subclasses, and instances and assertions were replaced by values of object instances. The rules worked by querying and asserting values of the objects.
The inference engine is an automated reasoning system that evaluates the current state of the knowledge-base, applies relevant rules, and then asserts new knowledge into the knowledge base. The inference engine may also include capabilities for explanation, so that it can explain to a user the chain of reasoning used to arrive at a particular conclusion by tracing back over the firing of rules that resulted in the assertion.
There are primarily two modes for an inference engine: forward chaining and backward chaining. The different approaches are dictated by whether the inference engine is being driven by the antecedent (left hand side) or the consequent (right hand side) of the rule. In forward chaining an antecedent fires and asserts the consequent. For example, consider the following rule:
formula_1
A simple example of forward chaining would be to assert Man(Socrates) to the system and then trigger the inference engine. It would match R1 and assert Mortal(Socrates) into the knowledge base.
Backward chaining is a bit less straight forward. In backward chaining the system looks at possible conclusions and works backward to see if they might be true. So if the system was trying to determine if Mortal(Socrates) is true it would find R1 and query the knowledge base to see if Man(Socrates) is true. One of the early innovations of expert systems shells was to integrate inference engines with a user interface. This could be especially powerful with backward chaining. If the system needs to know a particular fact but doesn't it can simply generate an input screen and ask the user if the information is known. So in this example, it could use R1 to ask the user if Socrates was a Man and then use that new information accordingly.
The use of rules to explicitly represent knowledge also enabled explanation capabilities. In the simple example above if the system had used R1 to assert that Socrates was Mortal and a user wished to understand why Socrates was mortal they could query the system and the system would look back at the rules which fired to cause the assertion and present those rules to the user as an explanation. In English if the user asked "Why is Socrates Mortal?" the system would reply "Because all men are mortal and Socrates is a man". A significant area for research was the generation of explanations from the knowledge base in natural English rather than simply by showing the more formal but less intuitive rules.
As Expert Systems evolved many new techniques were incorporated into various types of inference engines. Some of the most important of these were:
Advantages.
The goal of knowledge-based systems is to make the critical information required for the system to work explicit rather than implicit. In a traditional computer program the logic is embedded in code that can typically only be reviewed by an IT specialist. With an expert system the goal was to specify the rules in a format that was intuitive and easily understood, reviewed, and even edited by domain experts rather than IT experts. The benefits of this explicit knowledge representation were rapid development and ease of maintenance.
Ease of maintenance is the most obvious benefit. This was achieved in two ways. First, by removing the need to write conventional code many of the normal problems that can be caused by even small changes to a system could be avoided with expert systems. Essentially, the logical flow of the program (at least at the highest level) was simply a given for the system, simply invoke the inference engine. This also was a reason for the second benefit: rapid prototyping. With an expert system shell it was possible to enter a few rules and have a prototype developed in days rather than the months or year typically associated with complex IT projects.
A claim for expert system shells that was often made was that they removed the need for trained programmers and that experts could develop systems themselves. In reality this was seldom if ever true. While the rules for an expert system were more comprehensible than typical computer code they still had a formal syntax where a misplaced comma or other character could cause havoc as with any other computer language. In addition, as expert systems moved from prototypes in the lab to deployment in the business world, issues of integration and maintenance became far more critical. Inevitably demands to integrate with and take advantage of large legacy databases and systems arose. To accomplish this integration required the same skills as any other type of system.
Disadvantages.
The most common disadvantage cited for expert systems in the academic literature is the knowledge acquisition problem. Obtaining the time of domain experts for any software application is always difficult but for expert systems it was especially difficult because the experts were by definition highly valued and in constant demand by the organization. As a result of this problem a great deal of research in the later years of expert systems was focused on tools for knowledge acquisition, to help automate the process of designing, debugging, and maintaining rules defined by experts. However, when looking at the life-cycle of expert systems in actual use other problems seem at least as critical as knowledge acquisition. These problems were essentially the same as those of any other large system: integration, access to large databases, and performance.
Performance was especially problematic because early expert systems were built using tools such as Lisp, which executed interpreted rather than compiled code. Interpreting provided an extremely powerful development environment but with the drawback that it was virtually impossible to match the efficiency of the fastest compiled languages of the time, such as C. System and database integration were difficult for early expert systems because the tools were mostly in languages and platforms that were neither familiar to nor welcomed in most corporate IT environments – programming languages such as Lisp and Prolog and hardware platforms such as Lisp Machines and personal computers. As a result a great deal of effort in the later stages of expert system tool development was focused on integration with legacy environments such as COBOL, integration with large database systems, and porting to more standard platforms. These issues were resolved primarily by the client-server paradigm shift as PCs were gradually accepted in the IT world as a legitimate platform for serious business system development and as affordable minicomputer servers provided the processing power needed for AI applications.
Applications.
Hayes-Roth divides expert systems applications into 10 categories illustrated in the following table. Note that the example applications were not in the original Hayes-Roth table and some of the example applications came along quite a bit later. Any application that is not foot noted is described in the Hayes-Roth book. Also, while these categories provide an intuitive framework for describing the space of expert systems applications, they are not rigid categories and in some cases an application may show characteristics of more than one category.
Hearsay was an early attempt at solving voice recognition through an expert systems approach. For the most part this category or expert systems was not all that successful. Hearsay and all interpretation systems are essentially pattern recognition systems—looking for patterns in noisy data. In the case of Hearsay recognizing phonemes in an audio stream. Other early examples were analyzing sonar data to detect Russian submarines. These kinds of systems proved much more amenable to a neural network AI solution than a rule-based approach.
CADUCEUS and MYCIN were medical diagnosis systems. The user describes their symptoms to the computer as they would to a doctor and the computer returns a medical diagnosis.
Dendral was a tool to study hypothesis formation in the identification of organic molecules. The general problem it solved—designing a solution given a set of constraints—was one of the most successful areas for early expert systems applied to business domains such as sales people configuring Dec Vax computers and mortgage loan application development.
SMH.PAL is an expert system for the assessment of students with multiple disabilities.
Mistral is an expert system for the monitoring of dam safety developed in the 90's by Ismes (Italy). It gets data from an automatic monitoring system and performs a diagnosis of the state of the dam. Its first copy, installed in 1992 on the Ridracoli Dam (Italy), is still operational 24/7/365. It has been installed on several dams in Italy and abroad (e.g. Itaipu Dam in Brazil), as well as on landslides under the name of Eydenet, and on monuments under the name of Kaleidos. Mistral is a registered trade mark of CESI.

</doc>
<doc id="10139" url="http://en.wikipedia.org/wiki?curid=10139" title="Edward de Vere, 17th Earl of Oxford">
Edward de Vere, 17th Earl of Oxford

Edward de Vere, 17th Earl of Oxford (12 April 1550 – 24 June 1604), was an English peer and courtier of the Elizabethan era. Oxford was heir to the second oldest earldom in the kingdom, a court favourite for a time, a sought-after patron of the arts, and noted by his contemporaries as a lyric poet and court playwright, but his reckless and volatile temperament precluded him from attaining any courtly or governmental responsibility and contributed to the dissipation of his estate. Since the 1920s he has been the most popular alternative candidate proposed for the authorship of Shakespeare's works.
Oxford was the only son of John de Vere, 16th Earl of Oxford, and Margery Golding. After the death of his father in 1562, he became a ward of Queen Elizabeth and was sent to live in the household of her principal advisor, Sir William Cecil. He married Cecil's daughter, Anne, with whom he had five children. Oxford was estranged from her for five years after he refused to acknowledge her first child as his.
Oxford was a champion jouster and travelled widely throughout Italy and France. He was among the first to compose love poetry at the Elizabethan court, and he was praised as a playwright, although none of his plays survive. A stream of dedications praised Oxford for his generous patronage of literary, religious, musical, and medical works, and he patronised both adult and boy acting companies, as well as musicians, tumblers, acrobats and performing animals.
He fell out of favour with the Queen in the early 1580s and was exiled from court after impregnating one of her maids of honour, Anne Vavasour, which instigated violent street brawls between Oxford's retainers and her uncle's. Oxford was reconciled to the Queen in 1583, but all opportunities for advancement had been lost. In 1586 the Queen granted Oxford a £1,000 annuity to relieve his financial distress caused by his extravagance and selling off his income-producing lands for ready money. After his wife's death he married Elizabeth Trentham, one of the Queen's maids of honour, with whom he got an heir, Henry de Vere. He died in 1604, having lost the entirety of his inherited estates.
Family and childhood.
Edward de Vere was born heir to the second oldest earldom in England at the de Vere ancestral home, Hedingham Castle, in Essex, north-east of London. He was the only son of John de Vere, 16th Earl of Oxford, and his second wife, Margery Golding. He was probably named to honour Edward VI, from whom he received a gilded christening cup. He had an older half-sister, Katherine, the child of his father's first marriage to Dorothy Neville, and a younger sister, Mary de Vere. Both his parents had established court connections: the 16th Earl accompanying Princess Elizabeth from house arrest at Hatfield to the throne, and the countess being appointed a maid of honour in 1559.
De Vere was styled Viscount Bulbeck and raised in the Protestant reformed faith. Like many children of the nobility, he was raised by surrogate parents, in his case in the household of Sir Thomas Smith. At eight he entered Queens' College, Cambridge, as an "impubes", or immature fellow-commoner, later transferring to St John's. Thomas Fowle, a former fellow of St John's College, Cambridge, was paid £10 annually as Oxford's tutor.
His father died on 3 August 1562, shortly after making his will. Because he held lands from the Crown by knight service, his son became a royal ward of the Queen and was placed in the household of Sir William Cecil, her secretary of state and chief advisor. At 12, de Vere had become the 17th Earl of Oxford, Lord Great Chamberlain of England, and heir to an estate whose annual income, though assessed at approximately £2,500, may have run as high as £3,500.
Wardship.
While living at the Cecil House, Edward's daily studies consisted of dancing instruction, French, Latin, cosmography, writing exercises, drawing, and common prayers. During his first year at Cecil House, Oxford was briefly tutored by Laurence Nowell, the antiquarian and Anglo-Saxon scholar. Nowell's letter to Cecil stating: "I clearly see that my work for the Earl of Oxford cannot be much longer required" and his departure after eight months has been interpreted as either a sign of the thirteen-year-old Oxford's intractability as a pupil, or an indication that his precocity surpassed Nowell's ability to instruct him. In May 1564 Arthur Golding, in his dedication to his "Th' Abridgement of the Histories of Trogus Pompeius", attributed to his young nephew an interest in ancient history and contemporary events.
In 1563 Oxford's older half-sister, Katherine, then Baroness Windsor, challenged the legitimacy of the marriage of Oxford's parents in the Ecclesiastical court. His uncle Golding argued that the Archbishop of Canterbury should halt the proceedings since a proceeding against a ward of the Queen could not be brought without prior licence from the Court of Wards and Liveries.
Some time before October 1563 Edward's mother married Charles Tyrrell, a Gentleman Pensioner. In May 1565 she wrote to Cecil, urging that the money from family properties set aside for Oxford's use during his minority by his father's will should be entrusted to herself and other family friends to protect it and ensure that he would be able to meet the expenses of furnishing his household and suing his livery when he reached his majority; this last would end his wardship though cancelling his debt with that Court, and convey the powers attached to his title. There is no evidence that Cecil ever replied to her request. She died three years later, and was buried beside her first husband at Earls Colne. Oxford's stepfather, Charles Tyrrell, died in March 1570.
In August 1564 Oxford was among 17 nobles, knights and esquires in the Queen's entourage who were awarded the honorary degree of Master of Arts by the University of Cambridge, and was awarded another by Oxford University on a Royal progress in 1566. His future father-in-law, William Cecil, also received honorary degrees of Master of Arts on the same progresses. There is no evidence Oxford ever received a Bachelor of Arts degree. In February 1567 he was admitted to Gray's Inn to study law.
On 23 July 1567, while practising fencing in the backyard of Cecil House in the Strand, the seventeen-year-old Oxford killed Thomas Brincknell, an under-cook in the Cecil household. At the coroner's inquest the next day, the jury, which included Oxford's servant and Cecil's protégé, the future historian Raphael Holinshed, found that Brincknell was drunk when he ran onto Oxford's blade. Cecil later wrote that he attempted to have the jury find for Oxford's acting in self-defence.
Records of books purchased for Oxford in 1569 attest to his continued interest in history, as well as literature and philosophy. Among them were editions of a Geneva Bible gilt, Chaucer, Plutarch, two books in Italian, and folio editions of Cicero and Plato. In the same year Thomas Underdowne dedicated his translation of the "Æthiopian History" of Heliodorus to Oxford, praising his 'haughty courage', 'great skill' and 'sufficiency of learning'. Oxford made the acquaintance of the mathematician and astrologer John Dee in the winter of 1570 and became interested in occultism, studying magic and conjuring.
In November of 1569, Oxford petitioned Cecil for a foreign military posting. Although the Catholic Revolt of the Northern Earls had broken out that year, Elizabeth refused to grant the request. Cecil eventually obtained a position for him under the Earl of Sussex in a Scottish campaign the following spring. Oxford and Sussex became staunch mutual supporters at court. Oxford received his first vote for membership in the Order of the Garter in 1569, but never attained the honour in spite of his high rank and office.
Coming of age.
On 12 April 1571, Oxford attained his majority and took his seat in the House of Lords. Great expectations attended his coming of age; Sir George Buc recalled predictions that 'he was much more like ... to acquire a new erldome then to wast & lose an old erldom', a prophecy that was never fulfilled.
Although formal certification of his freedom from Burghley's control was deferred until May 1572, Oxford was finally granted the income of £666 which his father had intended him to have earlier, but properties set aside to pay his father's debts would not come his way for another decade. During his minority as the Queen's ward, one third of his estate had already reverted to the Crown, much of which Elizabeth had long since settled on Robert Dudley. Elizabeth demanded a further payment of £3,000 for overseeing the wardship and a further £4,000 for suing his livery. Oxford pledged double the amount if he failed to pay when it fell due, effectively risking a total obligation of £21,000.
By 1571, Oxford was a court favourite of Elizabeth's. In May, he participated in the three-day tilt, tourney and barrier, where although he did not win he was given chief honours in celebration of the attainment of his majority, his prowess winning admiring comments from spectators. In August, Oxford attended Paul de Foix, who had come to England to negotiate a marriage between Elizabeth and the Duke of Anjou, the future King Henry III of France. His published poetry dates from this period and, along with Edward Dyer he was one of the first courtiers to introduce vernacular verse to the court.
Marriage.
In 1562, the 16th Earl of Oxford had contracted with Henry Hastings, 3rd Earl of Huntingdon, for his son Edward to marry one of Huntingdon's sisters; when he reached the age of eighteen, he was to choose either Elizabeth or Mary Hastings. However, after the death of the 16th Earl, the indenture was allowed to lapse. Elizabeth Hastings later married Edward Somerset, while Mary Hastings died unmarried.
In the summer of 1571, Oxford declared an interest in Cecil's fourteen-year-old daughter, Anne, and received the queen's consent to the marriage. Anne had been pledged to Philip Sidney two years earlier, but after a year of negotiations Sidney's father, Sir Henry, was declining in the Queen's favour and Cecil suspected financial difficulties. In addition, Cecil had been elevated to the peerage as Lord Burghley in February 1571, thus elevating his daughter's rank, so the negotiations were cancelled. Cecil was displeased with the arrangement, given his daughter's age compared to Oxford's, and had entertained the idea of marrying her to the Earl of Rutland instead. The wedding was deferred until Anne was fifteen and finally took place at the Palace of Whitehall on 16 December 1571, together with that of Lady Elizabeth Hastings and Lord Herbert, with the Queen in attendance. The tying of two young English noblemen of great fortune into Protestant families was not lost on Elizabeth's Catholic enemies. Burghley gave Oxford a marriage settlement of land worth £800, and a cash settlement of £3,000. This amount was equal to Oxford's livery fees and was probably intended to be used as such, but the money vanished without a trace.
Oxford assigned Anne a jointure of some £669, but even though he was of age and a married man, he was still not in possession of his inheritance. After finally paying the Crown the £4,000 it demanded for his livery, he was finally licensed to enter on his lands in May. He was entitled to yearly revenues from his estates and the office of Lord Great Chamberlain of approximately £2,250, but he was not entitled to the income from his mother's jointure until after her death, nor to the income from certain estates set aside to pay his father's debts until 1583. In addition, the fines assessed against Oxford in the Court of Wards for his wardship, marriage and livery already totalled some £3,306. To guarantee payment, Oxford entered into bonds to the Court totalling £11,000, and two further private bonds for £6,000 apiece.
In 1572, de Vere's first cousin and closest relative, the Duke of Norfolk, was found guilty of a Catholic conspiracy against Elizabeth and was executed for treason. Oxford had earlier petitioned both the Queen and Burghley on the condemned Norfolk's behalf, to no avail, and it was claimed in a "murky petition from an unidentified woman" that he had plotted to provide a ship to assist his cousin's escape attempt to Spain.
The following summer Oxford planned to travel to Ireland; at this point, his debts were estimated at a minimum of £6,000.
In the summer of 1574, Elizabeth admonished Oxford "for his unthriftyness", and on 1 July Oxford bolted to the continent without permission, travelling to Calais with Lord Edward Seymour, and then to Flanders, "carrying a great sum of money with him". Coming as it did during a time of expected hostilities with Spain, Mary, Queen of Scots, interpreted his flight as an indication of his Catholic sympathies, as did the Catholic rebels then living on the continent. Burghley, however, assured the queen that Oxford was loyal, and she sent two Gentlemen Pensioners to summon him back under threat of heavy penalties. Oxford returned to England by the end of the month and was in London on the 28th. His request for a place on the Privy Council was rejected, but the queen's anger was abated and she promised him a licence to travel to Paris, Germany, and Italy on his pledge of good behaviour.
Foreign travel.
Elizabeth issued Oxford a licence to travel in January 1575, and provided him with letters of introduction to foreign monarchs. Prior to his departure, Oxford entered into two indentures. In first contract he sold his manors in Cornwall, Staffordshire and Wiltshire to three trustees for £6,000. In the second, since he had no heirs and if he should die abroad the estates would pass to his sister, Mary, he entailed the lands of the earldom on his first cousin, Hugh Vere. The indenture also provided for payment of debts amounting to £9,096, £3,457 of which was still owed to the Queen as expenses for his wardship.
Oxford left England in the first week of February, and a month later was presented to the King and Queen of France. News that Anne was pregnant had reached him in Paris, and he sent her many extravagant presents in the coming months. But somewhere along the way his mind was poisoned against Anne and the Cecils, and he became convinced that the expected child was not his. The elder Cecils loudly voiced their outrage at the rumours, which probably worsened the situation. In mid-March he travelled to Strasbourg, and then made his way to Venice, via Milan. Although his daughter, Elizabeth, was born at the beginning of July, for unexplained reasons Oxford did not learn of her birth until late September.
He was so taken with Italian culture and language during his travels that after his return he became known as the "Italian Earl" at court. He is recorded by Stow as having introduced various Renaissance fashions to court which immediately became fashionable, such as embroidered or trimmed scented gloves. Elizabeth had a pair of decorated gloves scented with perfume that for many years was known as the "Earl of Oxford's perfume".
In January 1576 Oxford wrote to Lord Burghley from Siena about complaints that had reached him about his creditors' demands, which included the Queen and his sister, and directing that more of his land be sold to pay them. Oxford left Venice in March, intending to return home by way of Lyons and Paris; although one later report has him as far south as Palermo in Sicily. At this point the Italian financier Benedict Spinola had lent Oxford over £4,000 for his 15-month-long continental tour, while in England over 100 tradesmen were seeking settlement of debts totalling thousands of pounds.
On Oxford's return across the Channel in April, his ship was hijacked by pirates from Flushing who took his possessions, stripped him to his shirt, and might have murdered him had not one of them recognized him.
On his return he refused to live with his wife and took rooms at Charing Cross. Aside from the unspoken suspicion that Elizabeth was not his child, Burghley's papers reveal a flood of bitter complaints by Oxford against the Cecil family. Upon the Queen's request, Oxford allowed his wife to attend the Queen at court, but only when Oxford was not present and that she not attempt to speak to him. He also stipulated that Burghley must make no further appeals to him on Anne's behalf. He was estranged from Anne for five years.
In February 1577 it was rumoured that Oxford's sister Mary would marry Lord Gerald Fitzgerald (1559–1580), but by 2 July she was linked with Peregrine Bertie, later Lord Willoughby d'Eresby. His mother, the Duchess of Suffolk, wrote to Lord Burghley that "my wise son has gone very far with my Lady Mary Vere, I fear too far to turn". Both the Duchess and her husband Richard Bertie first opposed the marriage, and the Queen initially withheld her consent. Oxford's own opposition to the match was so vehement that for some time Mary's prospective husband feared for his life. On 15 December the Duchess of Suffolk wrote to Burghley describing a plan she and Mary had devised to arrange a meeting between Oxford and his daughter. Whether the scheme came to fruition is unknown. Mary and Bertie were married sometime before March of the following year.
Quarrels, plots and scandals.
Oxford had sold his inherited lands in Cornwall, Staffordshire and Wiltshire prior to his continental tour. On his return to England in 1576 he sold his manors in Devonshire; by the end of 1578 he had sold at least seven more.
In 1577 Oxford invested £25 in the second of Martin Frobisher's expeditions in search of the Northwest Passage. In July 1577 he asked the Crown for the grant of Castle Rising, which had been forfeited to the Crown due to his cousin Norfolk's attainder in 1572. As soon as it was granted to him, he sold it, along with two other manors, and sank some £3,000 into Frobisher's third expedition. The 'gold' ore brought back turned out to be worthless, and Oxford lost the entire investment.
In the summer of 1578 Oxford attended the Queen's progress through East Anglia. The royal party stayed at Lord Henry Howard's residence at Audley End. A contretemps occurred during the progress in mid-August when the Queen twice requested Oxford to dance before the French ambassadors, who were in England to negotiate a marriage between the 46-year-old Elizabeth and the younger brother of Henri III of France, the 24-year-old Duke of Anjou. Oxford refused on the grounds that he "would not give pleasure to Frenchmen".
In April the Spanish ambassador, Bernardino de Mendoza, wrote to King Philip II of Spain that it had been proposed that if Anjou were to travel to England to negotiate his marriage to the Queen, Oxford, Surrey and Windsor should be hostages for his safe return. Anjou himself did not arrive in England until the end of August, but his ambassadors were already in England. Oxford was sympathetic to the proposed marriage, Leicester and his nephew Philip Sidney were adamantly opposed to it. This antagonism may have triggered the famous quarrel between Oxford and Sidney on the tennis court at Whitehall. It is not entirely clear who was playing on the court when the fight erupted; what is undisputed is that Oxford called Sidney a 'puppy', while Sidney responded that "all the world knows puppies are gotten by dogs, and children by men". The French ambassadors, whose private galleries overlooked the tennis court, were witness to the display. Whether it was Sidney who next challenged Oxford to a duel or the other way around, Oxford did not take it further, and the Queen personally took Sidney to task for not recognizing the difference between his status and Oxford's. Christopher Hatton and Sidney's friend Hubert Languet also tried to dissuade Sidney from pursuing the matter, and it was eventually dropped. The specific cause is not known, but in January 1580 Oxford wrote and challenged Sidney; by the end of the month Oxford was confined to his chambers, and was not released until early February.
Oxford openly quarrelled with the Earl of Leicester about this time; he was confined to his chamber at Greenwich for some time 'about the libelling between him and my Lord of Leicester'. In the summer of 1580, Gabriel Harvey, apparently motivated by a desire to ingratiate himself with Leicester, satirized Oxford's love for things Italian in verses entitled "Speculum Tuscanismi" in "Three Proper and Witty Familiar Letters".
Although details are unclear, there is evidence that in 1577 Oxford attempted to leave England to see service in the French Wars of Religion on the side of King Henry III. Like many members of older established aristocratic families in England, Oxford inclined to Catholicism; after his return from Italy he was reported to have embraced the religion, perhaps after being introduced to a seminary priest, Richard Stephens, by a distant kinsman, Charles Arundell. But just as quickly, late in 1580 he denounced a group of Catholics, among them Arundell, Francis Southwell and Henry Howard, for treasonous activities and asking the Queen's mercy for his own, now repudiated, Catholicism. Elizabeth characteristically delayed in acting on the matter and he was detained under house arrest for a short time.
Leicester is credited for having "dislodged Oxford from the pro-French group", i.e., the group at court which favoured Elizabeth's marriage to the Duke of Anjou. The Spanish ambassador, Mendoza, was also of the view that Leicester was behind Oxford's informing on his fellow Catholics in an attempt to prevent the French marriage. Peck concurs, stating that Leicester was "intent upon rendering Sussex's allies politically useless".
The Privy Council ordered the arrest of both Howard and Arundell; Oxford immediately met secretly with Arundell to convince him to support his allegations against Howard and Southwell, offering him money and a pardon from the Queen. Arundell refused Oxford's offer, and he and Howard initially sought asylum with Mendoza. Only after being assured they would be placed under house arrest in the home of a Privy Council member did the pair gave themselves up. During the first weeks after their arrest they pursued a threefold strategy: they would admit to minor crimes, prove Oxford a liar by his offers of money to testify to his accusations, and demonstrate that their accuser posed the real danger to the Crown. The extensive list to discredit Oxford included atheism, lying, heresy, disobedience to the crown, treason, murder for hire, sexual perversion and pederasty with his English and Italian servants ("buggering a boy that is his cook and many other boys"), habitual drunkenness, vowing to murder various courtiers and declaring that Elizabeth had a bad singing voice.
Arundell and Howard cleared themselves of Oxford's accusations, although Howard remained under house arrest into August, while Arundell was not freed until October or November. None of the three was ever indicted or tried. In the meantime Oxford was at liberty, and won a tournament at Westminster on 22 January. His page's speech at the tournament, describing Oxford's appearance as the Knight of the Tree of the Sun, was published in 1592 in a pamphlet entitled "Plato, Axiochus".
On 14 April 1589 Oxford was among the peers who found Philip Howard, Earl of Arundel, the eldest son and heir of Oxford's cousin, Thomas, Duke of Norfolk, guilty of treason. Arundel later died in prison. Oxford later insisted that "the Howards were the most treacherous race under heaven" and that "my Lord Howard [was] the worst villain that lived in this earth."
During the early 1580s it is likely that the Earl lived mainly at one of his Essex country houses, Wivenhoe, which was sold in 1584. In June 1580 he purchased a tenement and seven acres of land near Aldgate in London from the Italian merchant Benedict Spinola for £2,500. The property, located in the parish of St Botolphs, was known as the Great Garden of Christchurch and had formerly belonged to Magdalene College, Cambridge. He also purchased a London residence, a mansion in Bishopsgate known as Fisher's Folly. According to Henry Howard, Oxford paid a large sum for the property and renovations to it.
Oxford's triumph was short-lived. On 23 March 1581 Sir Francis Walsingham advised the Earl of Huntingdon that two days earlier Anne Vavasour, one of the Queen's maids of honour, had given birth to a son, and that "the Earl of Oxford is avowed to be the father, who hath withdrawn himself with intent, as it is thought, to pass the seas". Oxford was captured and imprisoned in the Tower, as was Anne and her infant, who would later be known as Sir Edward Vere. Burghley interceded for him, and he was released from the Tower on 8 June, but he remained under house arrest until sometime in July.
While Oxford was under house arrest in May, Thomas Stocker dedicated to him his "Divers Sermons of Master John Calvin", stating in the dedication that he had been "brought up in your Lordship's father's house". Oxford was still under house arrest in mid-July, but took part in an Accession Day tournament at Whitehall on 17 November 1581.
Oxford was banished from court until June 1583. He appealed to Burghley to intervene with the Queen on his behalf, but his father-in-law repeatedly put the matter in the hands of Sir Christopher Hatton.
At Christmas 1581 Oxford reconciled with his wife, Anne, but his affair with Anne Vavasour continued to have repercussions. In March 1582 there was a skirmish in the streets of London between Oxford and Anne's uncle, Sir Thomas Knyvet. Oxford was wounded and his servant killed; reports conflict as to whether Kynvet was also injured. There was another fray between Knyvet's and Oxford's retinues on 18 June, and a third six days later, where it was reported that Knyvet had "slain a man of the Earl of Oxford's in fight". In a letter to Burghley three years later Oxford offered to attend his father-in-law at his house "as well as a lame man might"; it is possible his lameness was a result of injuries from that encounter. On 19 January 1585 Anne Vavasour's brother Thomas sent Oxford a written challenge; it appears to have been ignored.
Meanwhile, the street-brawling between factions continued. Another of Oxford's men was slain that month, and in March Burghley wrote to Sir Christopher Hatton about the death of one of Knyvet's men, thanking Hatton for his efforts "to bring some good end to these troublesome matters betwixt my Lord and Oxford and Mr Thomas Knyvet".
On 6 May 1583, eighteen months after their reconciliation, Edward and Anne's only son was born, and died the same day. The infant was buried at Castle Hedingham three days later.
After intervention by Burghley and Sir Walter Raleigh, Oxford was reconciled to the Queen and his two-year exile from court ended at the end of May on condition of his guarantee of good behaviour. However, he never regained his position as a courtier of the first magnitude.
Theatrical enterprises.
Oxford's father maintained a company of players known as Oxford's Men, which was discontinued by the 17th Earl two years after his father's death. Beginning in 1580, Oxford patronised both adult and boy companies, a company of musicians, and sponsored performances by tumblers, acrobats and performing animals. Oxford's Men toured the provinces during 1580-87. Sometime after November 1583, Oxford bought a sublease of the premises used by the boy companies in the Blackfriars, and then gave it to his secretary, the writer John Lyly. Lyly installed Henry Evans, a Welsh scrivener and theatrical affectionado, as the manager of the new company of Oxford's Boys, composed of the Children of the Chapel and the Children of Paul's, and turned his talents to play writing until the end of June, 1584, when the original playhouse lease was voided by its owner. In 1584–85, "the Earl of Oxford's musicians" received payments for performances in the cities of Oxford and Barnstaple. Oxford's Men (also known as Oxford's Players) stayed active until 1602.
Royal annuity.
On 6 April 1584, Oxford's daughter, Bridget, was born, and two works were dedicated to him, Robert Greene's "Gwydonius; The Card of Fancy", and John Southern's "Pandora". Verses in the latter work mention Oxford's knowledge of astronomy, history, languages and music.
Oxford's financial situation was steadily deteriorating. At this point he had sold almost all his inherited lands, which cut him off from his principal source of income. Moreover, because the properties were security for his unpaid debt to the Queen in the Court of Wards, he had had to enter into a bond with the purchaser, guaranteeing that he would indemnify them if the Queen were to make a claim against the lands to collect on the debt. To avoid this eventuality, the purchasers of his estates agreed to repay Oxford's debt to the Court of Wards in instalments.
In 1585 negotiations were underway for King James to come to England to discuss the release of his mother, Mary, Queen of Scots, and in March Oxford was to be sent to Scotland as one of the hostages for James's safety.
In 1586, Oxford petitioned the queen for an annuity to relieve his distressed financial situation. His father-in-law made him several large loans, and Elizabeth granted Oxford a £1,000 annuity, to be continued at her pleasure or until he could be provided for otherwise. This annuity was continued by James I. De Vere's widow, Elizabeth, petitioned James I for an annuity of £250 on behalf of her 11-year-old son, Henry, to continue the £1,000 annuity granted to de Vere. Henry ultimately was awarded a £200 annuity for life. James would continue the grant after her death.
Another daughter, Susan, was born on 26 May 1587. On 12 September, another daughter, Frances, is recorded to be buried at Edmonton. Her birthdate is unknown; presumably she was between one and three years of age.
In July Elizabeth granted the Earl property which been seized from Edward Jones, who had been executed for his role in the Babington Plot. In order to protect the land from his creditors, the grant was made in the name of two trustees. At the end of November it was agreed that the purchasers of Oxford's lands would pay his entire debt of some £3,306 due to Court of Wards over a five-year period, finishing in 1592.
In July and August 1588 England was threatened by the Spanish Armada. On 28 July Leicester, who was in overall command of the English land troops, asked for instructions regarding Oxford, stating that "he seems most willing to hazard his life in this quarrel". The Earl was offered government of the port of Harwich, but he thought it was unworthy and declined the post; Leicester was glad to be rid of him.
In December 1588 Oxford had secretly sold his London mansion of Fisher's Folly to Sir William Cornwallis; by January 1591 the author Thomas Churchyard was dealing with rent owing for rooms he had taken in a house on behalf of his patron. Widowed, weary of the unsettled life of a courtier, and anxious to provide for his children and himself, Oxford wrote to Burghley outlining a plan to purchase the manoral lands of Denbigh, in Wales, if the Queen would consent, offering to pay for them by commuting his £1,000 annuity and agreeing to abandon his suit to regain the Forest of Essex.
In the spring of 1591 the plan for the purchasers of his land to discharge his debt to the Court of Wards was disrupted by the Queen's taking extents, or writs allowing a creditor to temporarily seize a debtor's property. Oxford complained that his servant Thomas Hampton had taken advantage of these writs by taking money from the tenants to his own use, and had also conspired with another of Oxford's servants to pass a fraudulent document under the Great Seal of England. The Lord Mayor, Thomas Skinner, was also involved. In June Oxford wrote to Burghley reminding him that he made an agreement with Elizabeth to relinquish his claim to the Forest of Essex for three reasons, one of which was the Queen's reluctance to punish Skinner's felony, which had caused Oxford to forfeit £20,000 in bonds and statutes.
In 1586 Angel Day dedicated "The English Secretary", the first epistolary manual for writing model letters in English, to Oxford, and William Webbe praised him as "most excellent among the rest" of our poets in his "Discourse of English Poetry". In 1588 Anthony Munday dedicated to Oxford the two parts of his "Palmerin d'Oliva". The following year "The Arte of English Poesie", attributed to George Puttenham, placed Oxford among a "crew" of courtier poets; he also considered Oxford among the best comic playwrights of the day. In 1590 Edmund Spenser addressed to Oxford the third of seventeen dedicatory sonnets which preface "The Faerie Queene", celebrating his patronage of poets. The composer John Farmer, who was in Oxford's service at the time, dedicated "The First Set of Divers & Sundry Ways of Two Parts in One" to him in 1591, noting in the dedication his patron's love of music.
Remarriage and later life.
On 5 June 1588 Anne Cecil died at court of a fever; she was 31.
On 4 July 1591 Oxford sold the Great Garden property at Aldgate to John Wolley and Francis Trentham. The arrangement was stated to be for the benefit of Francis' sister, Elizabeth Trentham, one of the Queen's Maids of Honour, whom Oxford married later that year. On 24 February 1593 she gave birth to Oxford's only surviving son and heir, Henry de Vere, at Stoke Newington.
Between 1591 and 1592 Oxford disposed of the last of his large estates; Castle Hedingham, the seat of his earldom, went to Lord Burghley, it was held in trust for Oxford's three daughters by his first marriage. he commissioned his servant, Roger Harlakenden, to sell Colne Priory. Harlekenden contrived to undervalue the land, then purchase it (as well as other parcels that were not meant to be sold) under his son's name; the suits Oxford brought against Harlakenden for fraud dragged out for decades and were never settled in his lifetime.
Protracted negotiations to arrange a match between his daughter Elizabeth and Henry Wriothesley, 3rd Earl of Southampton, did not result in marriage; in 19 November 1594, six weeks after Southampton turned 21, 'the young Earl of Southampton, refusing the Lady Vere, payeth £5000 of present money'. In January Elizabeth married William Stanley, 6th Earl of Derby. Derby had promised Oxford his new bride would have £1,000 a year, but the financial provision for her was slow in materializing.
His father-in-law, Lord Burghley, died on 4 August 1598 at the age of 78, leaving substantial bequests to Oxford's two unmarried daughters, Bridget and Susan. The bequests were structured in such a way to prevent Oxford from gaining control of his daughters' inheritance by assuming custody of them.
Earlier negotiations for a marriage to William Herbert having fallen through, in May or June 1599 Oxford's 15-year-old daughter Bridget married Francis Norris. Susan married Philip Herbert, 4th Earl of Pembroke and Montgomery.
From March to August 1595 Oxford actively importuned the Queen, in competition with Lord Buckhurst, to farm the tin mines in Cornwall. He wrote to Burghley, enumerating years of fruitless attempts to amend his financial situation and complained: 'This last year past I have been a suitor to her Majesty that I might farm her tins, giving £3000 a year more than she had made.' Oxford's letters and memoranda indicate that he pursued his suit into 1596, and renewed it again three years later, but was ultimately unsuccessful in obtaining the tin monopoly.
In October 1595 Oxford wrote to his brother in law, Sir Robert Cecil, of friction between himself and the ill-fated Earl of Essex, partly over his claim to the property, terming him 'the only person that I dare rely upon in the court'. Cecil seems to have done little to further Oxford's interests in the suit.
In March he was unable to go to court due to illness, in August he wrote to Burghley from Byfleet, where he gone for his health: 'I find comfort in this air, but no fortune in the court.' In September Oxford again wrote of ill health, regretting he had not been able to pay attendance to the Queen. Two months later Rowland Whyte wrote to Sir Robert Sidney that 'Some say my Lord of Oxford is dead'. Whether the rumour of Oxford's death was related to the illness mentioned in his letters earlier in the year is unknown. Oxford attended his last Parliament in December, perhaps another indication of failing health.
On 28 April 1599 Oxford was sued by the widow of his tailor for a debt of £500 for services rendered some two decades earlier. Oxford claimed that not only had he paid the debt, but that the tailor had absconded with 'cloth of gold and silver and other stuff' belonging to him, worth £800. The outcome of the suit is unknown.
In July 1600 Oxford wrote requesting Sir Robert Cecil's help in securing an appointment as Governor of the Isle of Jersey, once again citing the Queen's unfulfilled promises to him. In February he again wrote for his support, this time for the office of President of Wales. As with his former suits, Oxford was again unsuccessful; during this time he was listed on the Pipe Rolls as owing £20 for the subsidy.
After the abortive Essex rebellion in February 1601, Oxford was 'the senior of the twenty-five noblemen' who rendered verdicts at the trials of Essex and Southampton for treason. After Essex's co-conspirator Sir Charles Danvers was executed on in March, Oxford became involved in a complicated suit regarding lands which had reverted to the Crown by escheat at Danvers' attainder, a suit opposed by Danvers' kinsmen. Oxford continued to suffer from ill health, which kept him from court. On 4 December he was shocked that Cecil, who had encouraged him to undertake the Danvers suit on the Crown's behalf, had now withdrawn his support for it. As with all his other suits aimed at improving his financial situation, this last of Oxford's suits to the Queen ended in disappointment.
Last years.
In the early morning of 24 March 1603 Queen Elizabeth died without naming a successor. A few days beforehand Oxford at his house at Hackney had entertained the Earl of Lincoln, a nobleman known for erratic and violent behaviour similar to his host's. Lincoln reported that after dinner Oxford spoke of the Queen's impending death, claiming that the peers of England should decide the succession, and suggested that since Lincoln had 'a nephew of the blood royal...Lord Hastings', he should be sent to France to find allies to support this claim. Lincoln relayed this conversation to Sir John Peyton, Lieutenant of the Tower, who, knowing how physically and financially infirm Oxford was, refused to take Lincoln's report as a serious threat to King James' accession.
Oxford expressed his grief at the late Queen's death, and his apprehension for the future. These fears were unfounded; in letters to Cecil in May and June 1603 he again pressed his decades-long claim to have Waltham Forest and the house and park of Havering restored to him, and on 18 July the new King granted his suit. On 25 July Oxford was among those who officiated at the King's coronation, a month later James confirmed Oxford's annuity of £1,000.
On 18 June 1604 Oxford granted the custody of the Forest of Essex to his son-in-law, Lord Norris, and his cousin, Sir Francis Vere. He died six days later, of unknown causes, at King's Place, Hackney, and was buried on 6 July in the parish church of St. Augustine. In spite of his bouts of ill health, he left no will. Elizabeth's will requested that she be buried with her husband at Hackney. Although this document and the parish registers confirm Oxford's burial there, his cousin Percival Golding later claimed that his body was interred at Westminster.
Literary reputation.
Oxford's manuscript verses circulated widely in courtly circles. Three of his poems, , , and , are among the texts that repeatedly appear in the surviving 16th-century manuscript miscellanies and poetical anthologies. His earliest published poem was in Thomas Bedingfield's translation of Cardano's "Comforte" (1573). Bedingfield's dedication to Oxford is dated 1 January 1572. In addition to his poem, Oxford also contributed a commendatory letter setting forth the reasons why Bedingfield should publish. In 1576 eight of his poems were published in the poetry miscellany "The Paradise of Dainty Devises". According to the introduction, all the poems in the collection were meant to be sung, but Oxford's were almost the only genuine love songs in the collection. Oxford's was published in "The Phoenix Nest" (1593) and republished in "England's Helicon" (1600). appeared in "The Teares of Fancie" (1593). "Brittons Bowre of Delight" (1597) published under Oxford's name, but the attribution today is not considered certain.
Contemporary critics praised Oxford as a poet and a playwright. William Webbe names Oxford as "the most excellent" of Elizabeth's courtier poets. Puttenham's "The Arte of English Poesie" (1589), places Oxford first on a list of courtier poets and included an excerpt of "When wert thou born desire" as an example of "his excellance and wit". Puttenham also says that "highest praise" should be given to Oxford and Richard Edwardes for "Comedy and Enterlude". Francis Meres' "Palladis Tamia" (1598) names Oxford first of 17 playwrights listed by rank who are "the best for comedy amongst us", and Oxford appears first on a list of seven Elizabethan courtly poets "who honoured Poesie with their pens and practice" in Henry Peacham's 1622 "The Compleat Gentleman".
Steven W. May writes that Oxford was Elizabeth's "first truly prestigious courtier poet ... [whose] precedent did at least confer genuine respectability upon the later efforts of such poets as Sidney, Greville and Raleigh." He describes Oxford as a "competent, fairly experimental poet working in the established modes of mid-century lyric verse" and his poetry as "examples of the standard varieties of mid-Elizabethan amorous lyric". May says that Oxford’s youthful love lyrics, which have been described as experimental and innovative, "create a dramatic break with everything known to have been written at the Elizabethan court up to that time" by virtue of being lighter in tone and metre and more imaginative and free from the moralizing tone of the courtier poetry of the "drab" age, which tended to be occasional and instructive. and describes one poem, in which the author cries out against "this loss of my good name", as a "defiant lyric without precedent in English Renaissance verse".
 May says that Oxford's poetry was "one man's contribution to the rhetorical mainstream of an evolving Elizabethan poetic" indistinguishable from "the output of his mediocre mid-century contemporaries". C. S. Lewis said that de Vere's poetry shows "a faint talent", but is "for the most part undistinguished and verbose." Nelson says that "contemporary observers such as Harvey, Webbe, Puttenham, and Meres clearly exaggerated Oxford's talent in deference to his rank. By any measure, his poems pale in comparison with those of Sidney, Lyly, Spenser, Shakespeare, Donne, and Jonson." He says that his known poems are "astonishingly uneven" in quality, ranging from the "fine" to the "execrable".
Oxford was sought for his literary and theatrical patronage, and between 1564 and 1599 28 works were dedicated to him by such authors as Arthur Golding, John Lyly, Robert Greene and Anthony Munday. Of his 33 dedications, thirteen appeared in original or translated works of literature, a higher percentage of literary works than other patrons of similar means. His lifelong patronage of writers, musicians and actors prompted May to term Oxford "a nobleman with extraordinary intellectual interests and commitments", whose biography exhibits a "lifelong devotion to learning". He goes on to say that "Oxford's genuine commitment to learning throughout his career lends a necessary qualification to Stone's conclusion that De Vere simply squandered the more than 70,000 pounds he derived from selling off his patrimony...for which some part of this amount Oxford acquired a splendid reputation for nurture of the arts and sciences".
Oxfordian theory of Shakespeare authorship.
The Oxfordian theory of Shakespeare authorship proposes that de Vere wrote the plays and poems traditionally attributed to William Shakespeare of Stratford-upon-Avon. Though the attribution has been rejected by nearly all academic Shakespeareans, popular interest in the Oxfordian theory persists, and his candidacy was featured in the 2011 Hollywood film "Anonymous" (directed by Roland Emmerich), in which he was played by Rhys Ifans.

</doc>
<doc id="10141" url="http://en.wikipedia.org/wiki?curid=10141" title="Erinyes">
Erinyes

In, Greek mythology the Erinyes (; sing. Erinys ; Greek: Ἐρῑνύες [ῠ], pl. of Ἐρῑνύς [ῡ], "Erinys"), also known as Furies, were female chthonic deities of vengeance; they were sometimes referred to as "infernal goddesses" (χθόνιαι θεαί). A formulaic oath in the "Iliad" invokes them as "those who beneath the earth punish whosoever has sworn a false oath". Burkert suggests they are "an embodiment of the act of self-cursing contained in the oath". They correspond to the Dirae in Roman mythology, and some suppose that they are called Furies in hell, Harpies on earth, and Dirae in heaven.
According to Hesiod's Theogony, when the Titan Cronus castrated his father Uranus and threw his genitalia into the sea, the Erinyes as well as the Meliae emerged from the drops of blood when it fell on the earth (Gaia), while Aphrodite was born from the crests of sea foam. According to variant accounts, they emerged from an even more primordial level—from Nyx, "Night", or from a union between air and mother earth. Their number is usually left indeterminate. Virgil, probably working from an Alexandrian source, recognized three: Alecto "or Alekto" ("unceasing"), Megaera ("grudging"), and Tisiphone "or Tilphousia" ("vengeful destruction"), all of whom appear in the "Aeneid". Dante followed Virgil in depicting the same three-character triptych of Erinyes; in Canto IX of the "Inferno" they confront the poets at the gates of the city of Dis. Whilst the Erinyes were usually described as three maiden goddesses, the Erinys Telphousia was usually a by-name for the wrathful goddess Demeter, who was worshipped under the title of Erinys in the Arkadian town of Thelpousa.
Description.
The Erinyes live in Erebus and are more ancient deities than any of the Olympians. Their task is to hear complaints brought by mortals against the insolence of the young to the aged, of children to parents, of hosts to guests, and of householders or city councils to suppliants - and to punish such crimes by hounding culprits relentlessly. The Erinyes are crones and, depending upon authors, described as having snakes for hair, dog's heads, coal black bodies, bat's wings, and blood-shot eyes. In their hands they carry brass-studded scourges, and their victims die in torment. 
Erinyes in ancient Greek literature.
Tantalizing myth fragments deal with the Erinyes that date to the earliest records we have of ancient Greek culture. One of the most frequently repeated examples of ancient Greek literature featuring the Erinyes is found in examples that focus upon the Orestes myth. 
Aeschylus.
Featured in ancient Greek literature, from poems to plays, the Erinyes form the Chorus and play a major role in the conclusion of Aeschylus's dramatic trilogy the "Oresteia". In the first play, Agamemnon, King Agamemnon returns home from the Trojan War, where he is slain by his wife, Clytemnestra, who wants vengeance for her daughter Iphigenia, who was sacrificed by Agamemnon in order to obtain favorable winds to sail to Troy. In the second play, The Libation Bearers, their son Orestes has reached manhood and has been commanded by Apollo’s oracle to avenge his father‘s murder at his mother’s hand. Returning home and revealing himself to his sister Electra, Orestes pretends to be a messenger bringing the news of his own death to Clytemnestra. He then slays his mother and her lover Aegisthus.
Although Orestes’ actions were what Apollo had commanded him to do, Orestes has still committed matricide, a grave sacrilege. Because of this, he is pursued and tormented by the terrible Erinyes, who demand yet further blood vengeance. At Delphi, Orestes has been told by Apollo that he should go to Athens to seek the aid of the goddess Athena. In Athens, Athena arranges for Orestes to be tried by a jury of Athenian citizens, with her presiding. The Erinyes appear as Orestes’ accusers, while Apollo speaks in his defense. The trial becomes a debate about the necessity of blood vengeance, the honor that is due to a mother compared to that due to a father, and the respect that must be paid to ancient deities such as the Erinyes compared to the newer generation of Apollo and Athena. The jury vote is evenly split. Athena participates in the vote and chooses for acquittal. Athena declares Orestes acquitted because of the rules she established for the trial. Despite the verdict, the Erinyes threaten to torment all inhabitants of Athens and to poison the surrounding countryside. Athena, however, offers the ancient goddesses a new role, as protectors of justice, rather than vengeance, and of the city. She persuades them to break the cycle of blood for blood (except in the case of war, which is fought for glory, not vengeance). While promising that the goddesses will receive due honor from the Athenians and Athena, she also reminds them that she possesses the key to the storehouse where Zeus keeps the thunderbolts that defeated the other older deities. This mixture of bribes and veiled threats satisfies the Erinyes, who are then led by Athena in a procession to their new abode. In the play, the "Furies" are thereafter addressed as "Semnai" (Venerable Ones), as they will now be honored by the citizens of Athens and ensure the city's prosperity.
Euripides.
In Euripides' "Orestes" the Erinyes are for the first time "equated" with the Eumenides (Εὐμενίδες, pl. of Εὐμενίς; literally "the gracious ones", but also translated as "Kindly Ones"). This is because it was considered unwise to mention them by name (for fear of attracting their attention), the ironic name is similar to how Hades, god of the dead is styled Pluton, or Pluto, "the Rich One'. Using euphemisms for the names of deities serves many purposes throughout ancient religions.
Sophocles.
In Sophocles's play, "Oedipus at Colonus", it is significant that he comes to his final resting place in the grove dedicated to the Erinyes. It shows that he has paid his penance for his blood crime, as well as come to integrate the balancing powers to his early over-reliance upon Apollo, the god of the individual, the sun, and reason. He is asked to make an offering to the Erinyes and complies, having made his peace.
Modern references and literature.
The Erinyes persist as a theme that appears in modern literature as well as the subject of scholarly pursuits of mythology and ancient Greek culture. The Orestes theme becomes an important subject to scholars such as James Frazer and Robert Graves. In "The Greek Myths" Graves translates and interprets the legends and myth fragments about Clytemnestra, Agamemnon, and Orestes, as suggesting a ritual killing of a "king" (Agamemnon) in very early religious ceremonies that were suppressed when patriarchy replaced the matriarchies of very ancient Greece. Graves asserts that the sacrilege for which the Erinyes pursued Orestes was the killing of his mother, who represented matriarchy. He explains that worship of Athena was retained as a cult because it was too strong to be suppressed, but she was "recast" as a child of Zeus in new myths, even given the previously incomprehensible role of justifying what would have been a horrific crime against the old religious customs. Graves, and many other mythographers, were influenced by "The Golden Bough" of James Frazer, and since it was published many myths have been reinterpreted to reveal clues to ancient religious practices that were kept as secret rituals. They are mentioned in the poem To Brooklyn Bridge by Hart Crane. The Eumenides are also featured in T. S. Eliot's play, "The Family Reunion".

</doc>
<doc id="10142" url="http://en.wikipedia.org/wiki?curid=10142" title="Marquess of Aberdeen and Temair">
Marquess of Aberdeen and Temair

Marquess of Aberdeen and Temair, in the County of Aberdeen, in the County of Meath and in the County of Argyll, is a title in the Peerage of the United Kingdom. It was created on 4 January 1916 for John Hamilton-Gordon, 7th Earl of Aberdeen.
Family history.
Baronetcy of Haddo.
The Gordon family descends from John Gordon, who fought as a Royalist against the Covenanters in the Civil War. In 1642 he was created a baronet, of Haddo in the County of Aberdeen, in the Baronetage of Nova Scotia. In 1644 he was found guilty of treason and beheaded, with the baronetcy forfeited. The title was restored after the Restoration for his son John, the second Baronet.
Earldom of Aberdeen.
The second Baronet died without male issue and was succeeded by his younger brother, the third Baronet. He was a noted advocate and served as Lord President of the Court of Session and as Lord Chancellor of Scotland. On 30 November 1682 he was raised to the Peerage of Scotland as Lord Haddo, Methlick, Tarves and Kellie, Viscount of Formartine and Earl of Aberdeen. He was succeeded by his only surviving son, the second Earl. He sat in the House of Lords as a Scottish Representative Peer from 1721 to 1727. On his death the titles passed to his eldest son from his second marriage, the third Earl. He was a Scottish Representative Peer from 1747 to 1761 and from 1774 to 1790.
Lord Aberdeen, Prime Minister.
The third earl was succeeded by his grandson, the fourth Earl, who was the eldest son of George Gordon, Lord Haddo. Lord Aberdeen was a distinguished diplomat and statesman and served as Foreign Secretary from 1828 to 1830 and from 1841 to 1846 and as Prime Minister of the United Kingdom from 1852 to 1855. In 1815 he was created Viscount Gordon, of Aberdeen in the County of Aberdeen, in the Peerage of the United Kingdom, which entitled him to an automatic seat in the House of Lords. Aberdeen married firstly Lady Catherine Elizabeth (1784–1812), daughter of John Hamilton, 1st Marquess of Abercorn, and assumed by Royal license the additional surname of Hamilton in 1818. When he died the titles passed to his eldest son from his second marriage to Harriet Douglas, the fifth Earl. He sat as Liberal Member of Parliament for Aberdeenshire. His eldest son, the sixth Earl, was a sailor and adventurer. He was accidentally drowned off the coast of America in 1870, and had not married or had children.
Marquess of Aberdeen and Temair.
The sixth earl of Aberdeen was succeeded by his younger brother, the seventh Earl. John Hamilton-Gordon, was a Liberal politician and served as Lord-Lieutenant of Ireland in 1886 and from 1905 to 1915 and as Governor General of Canada from 1893 to 1898. In 1916 he was created Earl of Haddo, in the County of Aberdeen, and Marquess of Aberdeen and Temair, in the County of Aberdeen, in the County of Meath and in the County of Argyll. Both titles are in the Peerage of the United Kingdom.
He was succeeded by his eldest son, the second Marquess, who was a member of the London County Council and served as Lord-Lieutenant of Aberdeenshire. He was childless and was succeeded by his younger brother, the third Marquess. He was notably President of the Federation of British Industries. When he died the titles passed to his eldest son, the fourth Marquess. He was a member of the Aberdeenshire County Council and Lord-Lieutenant of Aberdeenshire. He had four adopted children but no biological issue and was succeeded by his younger brother, the fifth Marquess. He was a broadcaster working for the BBC. He never married and on his death in 1984 the titles passed to his fourth and youngest brother, the sixth Marquess. He was Chairman of The Arts Club. s of 2013[ [update]] the titles are held by his only son, the seventh Marquess, who succeeded in 2002.
Other family members.
Numerous other members of the Gordon family have also gained distinction. The Hon. William Gordon (d. 1816), eldest son from the third marriage of the second Earl, was a General in the Army. The Hon. Cosmo Gordon, second son from the third marriage of the second Earl, was a Colonel in the Army. The Hon. Alexander Gordon (1739–1792), third son from the third marriage of the second Earl, was a Lord of Session from 1788 to 1792 under the judicial title of Lord Rockville. His son William Duff-Gordon was Member of Parliament for Worcester. In 1815 he succeeded his uncle as second Baron of Halkin according to a special remainder and assumed the additional surname of Duff (see Duff-Gordon baronets for further history of this branch of the family). The Hon. William Gordon, younger brother of the fourth Earl, was a Vice-Admiral in the Royal Navy and sat as Member of Parliament for Aberdeenshire. The Hon. Alexander Gordon (1786–1815), younger brother of the fourth Earl, was a soldier and was killed at the Battle of Waterloo.
The Hon. Sir Robert Gordon, younger brother of the fourth Earl, was a diplomat and served as British Ambassador to Austria. The Hon. John Gordon (1792–1869), younger brother of the fourth Earl, was an Admiral in the Royal Navy. The Hon. Sir Alexander Hamilton-Gordon (1817–1890), eldest son of the second marriage of the fourth Earl, was a General in the Army and sat as Member of Parliament for Aberdeenshire East. His eldest son, Sir Alexander Hamilton-Gordon was also a General in the Army. Reverend the Hon. Douglas Hamilton-Gordon (1824–1901), third son of the second marriage of the fourth Earl, was Chaplain-in-Ordinary to Queen Victoria and Canon of Salisbury. The Hon. Arthur Hamilton-Gordon, fourth son of the second marriage of the fourth Earl, was a Liberal politician and was created Baron Stanmore in 1893 (see this title for more information on him and this branch of the family). Ishbel Hamilton-Gordon, Marchioness of Aberdeen and Temair, daughter of Dudley Marjoribanks, 1st Baron Tweedmouth, and wife of the first Marquess of Aberdeen and Temair, was an author, philanthropist and an advocate of woman's interests.
The family seat is Haddo House, Aberdeenshire. The title Earl of Haddo is the courtesy title for the Marquess's eldest son and heir, the eldest son of whom uses the courtesy title Viscount of Formartine. The Marquesses of Aberdeen and Temair are related to the Marquesses of Huntly. Sir John Gordon (d. c. 1395) of Strathbogie, ancestor of Sir John Gordon, 1st Baronet, was the brother of Elizabeth Gordon. She married Sir Alexander Seton (d. 1438) and was the mother of Alexander Gordon, 1st Earl of Huntly (ancestor of the Marquesses of Huntly).
Marquesses of Aberdeen and Temair (1916).
The heir apparent is the present holder's son George Ian Alastair Gordon, Earl of Haddo (b. 1983).<br> 
The heir apparent's heir apparent is his son Ivo Alexander Ninian Gordon, Viscount Formartine (b. 18 July 2012).

</doc>
<doc id="10147" url="http://en.wikipedia.org/wiki?curid=10147" title="East Coast Swing">
East Coast Swing

East Coast Swing (ECS) is a form of social partner dance. It belongs to the group of swing dances. It is danced under fast swing music, including rock and roll and boogie-woogie.
Yerrington and Outland equated East Coast Swing to the New Yorker in 1961. Originally known as "Eastern Swing" by Arthur Murray Studios, the name East Coast Swing became more common between 1975 and 1980.
History.
The dance was created by dance studios including the Arthur Murray dance studios in the 1940s, based on the Lindy Hop. Lindy Hop was felt by dance studios to be both too difficult and too unstructured to teach to beginning dancers, but there was market demand for training in Swing Dance. The dance studios had initially dismissed Lindy Hop in particular as a fad. East Coast Swing can be referred to by many different names in different regions of the United States and the World. It has alternatively been called Eastern Swing, Jitterbug, American Swing, East Coast Lindy, Lindy (not to be confused with Lindy Hop), and Triple Swing. Other variants of East Coast Swing that use altered footwork forms are known as Single Swing or "Single-step Swing" (where the triple step is replaced by a single step forming a slow, slow, quick, quick rhythm common to Foxtrot), and Double Swing (using a tap-step footwork pattern).
East Coast Swing is a Rhythm Dance that has both 6 and 8 beat patterns.
The name "East Coast Swing" was coined initially to distinguish the dance from the street form and the new variant used in the competitive ballroom arena (as well as separating the dance from West Coast Swing, which was developed in California). While based on Lindy Hop, it does have clear distinctions. East Coast Swing is a standardized form of dance developed first for instructional purposes in the Arthur Murray studios, and then later codified to allow for a medium of comparison for competitive ballroom dancers. It can be said that there is no right or wrong way to dance it; however, certain styles of the dance are considered correct "form" within the technical elements documented and governed by the National Dance Council of America. The N.D.C.A. oversees all the standards of American Style Ballroom and Latin dances. Lindy Hop was never standardized and later became the inspiration for several other dance forms such as: (European) Boogie Woogie, Jive, East Coast Swing, West Coast Swing and Rock and Roll.
In practice on the social dance floor, the six count steps of the East Coast Swing are often mixed with the eight count steps of Lindy Hop, Charleston, and less frequently, Balboa.
Basic technique.
Single-step Swing
East Coast Swing has a 6 count basic step. This is in contrast to the meter of most swing music, which has a 4 count basic rhythm. In practice, however, the 6-count moves of the east coast swing are often combined with 8-count moves from the Lindy hop, Charleston, and Balboa.
Depending on the region and instructor, the basic step of single-step East Coast Swing is either "rock step, step, step" or "step, step, rock step". In both cases, the rock step always starts on the downbeat.
For "rock step, step, step" the beats, or counts, are the following:
Steps for the "lead" (traditionally, the man's part)
Steps for the "follow" (traditionally, the woman's part which mirrors the lead's part)
For "step, step, rock step," the rock step occurs on beats 5 and 6, but the overall progression remains the same.
The normal steps can be substituted with a triple step or double step "step-tap" or "kick-step" instead of a single step. This is commonly used during songs when a slower tempo makes the single step difficult (an example progression would be "rock step, triple step, triple step").
Timing.
Because East Coast uses a six step pattern with music employing 4 beats per measure, three measures of music are required to complete two sets of steps, as shown in the following table.
The rock step starts on 1, 2 the first triple step starts 3a4 and the second on 5a6.
In single time style (used with faster music) the triple steps are replaced by single steps, so two beats of music are used for each single step while each step in the rock (R) step (S) is still completed in one beat, finishing the cycle in six musical beats. Some instructors will teach vocalizing the single time style as" "Quick. Quick. Slow. Slow. " or "Back Step. Slow. Slow."
There is the choice to start with triples or with a rock step, however if you check the above chart where a triple step starts on a 1, 2 you can see that the pattern progresses and wraps back around. The choice of starting with a triple or a rock step does have musical consequences as music has phrasing with hits that often happen on 12, or 24 or 36... This means that dancers who choose to start with a rock step you will probably find themselves on a rock step on every new phrase. Those who start with a triple will start with a triple on each new phrase. An advantage of starting with the triple step is that dancers can more easily change their foot work right at the start of the musical phrase.

</doc>
<doc id="10148" url="http://en.wikipedia.org/wiki?curid=10148" title="Ernst Kaltenbrunner">
Ernst Kaltenbrunner

Ernst Kaltenbrunner (4 October 1903 – 16 October 1946) was an Austrian-born senior official of Nazi Germany during World War II. An "Obergruppenführer" (general) in the "Schutzstaffel" (SS), between January 1943 and May 1945 he held the offices of Chief of the "Reichssicherheitshauptamt" (RSHA, Reich Main Security Office) and President of the ICPC, later to become Interpol. He was the highest-ranking member of the SS to face trial at the first Nuremberg Trials. He was found guilty of war crimes and crimes against humanity and executed.
Early life.
Born in Ried im Innkreis, Austria, Kaltenbrunner was the son of a lawyer, and was educated at the State Realgymnasium in Linz and at Graz University. He'd had deep scars on his face from dueling in his student days, although some sources attribute them to an automobile accident.
SS career.
Kaltenbrunner joined the Nazi Party and his NSDAP number was 300,179. In 1932, he joined the SS in Austria. His SS number was 13,039. He was the "Gauredner" (district speaker) and "Rechtsberater" (legal consultant) of the SS Abschnitt VIII. In January 1934, Kaltenbrunner was briefly jailed by the Engelbert Dollfuss government with other National Socialists at the Kaisersteinbruch concentration camp. In 1934, he was jailed again on suspicion of high treason in the assassination of Dollfuss. This accusation was dropped, but he was sentenced to six months for conspiracy. In 1934, Kaltenbrunner married Elisabeth Eder (b. 1908) and they had three children. In addition to the children from his marriage, Kaltenbrunner had twins, Ursula and Wolfgang, (b. 1945) with his long-time mistress Gisela Gräfin von Westarp (née Wolf). All of his children survived the war.
From mid-1935 Kaltenbrunner was the leader of the Austrian SS. He assisted in the "Anschluss" and Hitler promoted him to SS-"Brigadeführer" on the day the "Anschluss" was completed. On 11 September 1938 he was promoted to the rank of SS-"Gruppenführer", equivalent to a lieutenant general in the army (see ). He was also a member of the "Reichstag" from 1938.
World War II.
In July 1940, he was commissioned as a SS-"Untersturmführer" in the Waffen-SS Reserve. Later in April 1941, he was promoted to major general ("Generalleutnant") of the Police. On 30 January 1943 Kaltenbrunner was appointed Chief of the RSHA, composed of the SiPo ("Sicherheitspolizei": the combined forces of the Gestapo and Kripo) along with the SD ("Sicherheitsdienst": Security Service). He replaced Reinhard Heydrich, who was assassinated in June 1942. Kaltenbrunner held this position until the end of the war. He was promoted to SS-"Obergruppenführer und General der Polizei" on 21 June 1943. He also replaced Heydrich as President of the International Criminal Police Commission (ICPC), the organization today known as Interpol.
Toward the end of the war, Kaltenbrunner's power increased greatly, especially after the attack on Hitler of 20 July 1944, upon which he gained direct access to the Führer. He was also responsible for conducting "kangaroo trials" and calling for the execution of all the people who were accused of plotting against Hitler. It was often said that even Heinrich Himmler feared him and he managed to be an intimidating figure with his 1.94 m height, facial scars and volatile temper. It was rumored that he was responsible for Adolf Eichmann's failure to attain the rank of SS-Standartenführer (Colonel). Kaltenbrunner was also long-time friends with Otto Skorzeny and recommended him for many secret missions, allowing Skorzeny to become one of Hitler's valued agents. Kaltenbrunner was also responsible for heading Operation Long Jump, the attempt to assassinate Stalin, Churchill, and Roosevelt. This mission was later thwarted by Soviet intelligence agent Gevork Vartanian.
Following Himmler's appointment as Minister of the Interior in August 1943, Kaltenbrunner sent him a letter wherein he argued that Himmler's new powers must be used to reverse the party cadre organisation's annexation.
In December 1944, Kaltenbrunner was granted the rank of General of the Waffen-SS. Other SS General Officers were granted equivalent Waffen-SS ranks in 1944 as well, so that in the event that they were captured by the Allies, they would have status as military officers instead of police officials. For those who had held police rank prior to 1944, the SS General's title could become rather lengthy. Kaltenbrunner was listed on the SS rolls in 1945 as SS-"Obergruppenführer und General der Polizei und Waffen-SS". On 9 December 1944 he was awarded the Knights Cross of the War Merit Cross with Swords. In addition he was awarded the NSDAP Golden Party Badge and the "Blutorden".
On 12 March 1945 a meeting took place in the Vorarlberg between Kaltenbrunner and Carl Jacob Burckhardt, President of the International Committee of the Red Cross (1945–48). By this stage the Nazis were willing to make some concessions to the wishes of the Red Cross.
On 18 April 1945, Himmler named Kaltenbrunner Commander-in-Chief of those remaining German forces in Southern Europe. Kaltenbrunner reorganized his intelligence agencies as a stay-behind underground net. He divided the subcommands between Otto Skorzeny, head of the sabotage units, and Wilhelm Waneck, who kept in contact not only with Kaltenbrunner and other centers in Germany, but also with stay-behind agents in the southern European capitals.
Nuremberg trials.
At the Nuremberg Trials, Kaltenbrunner was charged with conspiracy to commit crimes against peace, war-crimes and crimes against humanity. The most notable witness in this trial was Rudolf Höss, the camp commander of the Auschwitz concentration camp.
Due to his tight control over the RSHA, Kaltenbrunner was held directly responsible for the following crimes:
During the initial stages of the Nuremberg trials, Kaltenbrunner was absent because of two episodes of subarachnoid hemorrhage. His lawyer Kurt Kaufmann requested that Kaltenbrunner be acquitted on grounds of health complications as he was medically unfit for the trial. Kaltenbrunner's state of health improved and the tribunal denied his request for pardon. When Kaltenbrunner was released from a military hospital he pleaded not guilty to the charges of the indictment served on his person. Kaltenbrunner stressed during cross-examination that all decrees and legal documents which bore his signature were "rubber-stamped" and filed by his adjutant(s).
During the trial, Kaltenbrunner argued in his defense that his position as RSHA chief existed only in title and was only committed to matters of espionage and intelligence. He maintained that Himmler, as his superior, was the person actually culpable for the atrocities committed during his tenure as chief of the RSHA. The International Military Tribunal noted that Kaltenbrunner was a keen functionary in matters involving the sphere of the RSHA's intelligence network, but the evidence also showed that Kaltenbrunner was an active authority and participant in many instances of war crimes and crimes against humanity. On September 30, 1946 the IMT found Kaltenbrunner not guilty of crimes against peace. However, Kaltenbrunner was found guilty of war crimes and crimes against humanity. On October 1, 1946 the IMT sentenced him to death by hanging.
Execution.
Kaltenbrunner was executed by hanging at around 1:40 a.m. on 16 October 1946. Kaltenbrunner's last words were:
I have loved my German people and my fatherland with a warm heart. I have done my duty by the laws of my people and I am sorry this time my people were led by men who were not soldiers and that crimes were committed of which I had no knowledge. Germany, good luck.
Recovered evidence.
In 2001, Ernst Kaltenbrunner's personal Nazi security seal was found in an Alpine lake in Styria, Austria, 56 years after he threw it away in an effort to hide his identity. The seal was recovered by a Dutch citizen on vacation. The seal has the words "Chef der Sicherheitspolizei und des SD" (Chief of the Security Police and SD) engraved on it. Experts have examined the seal and believe it was discarded in the final days of the war in May 1945. It was one of Kaltenbrunner's last acts as a free man. Kaltenbrunner gave himself up claiming to be a doctor and offering a false name. However, his mistress spotted him, and by chance occurrence, she called out his name and rushed to hug him. On 12 May 1945, this action tipped off the Allied troops, resulting in his capture, trial, and execution.
The Altaussee Treasures.
In late April 1945, Kaltenbrunner fled his headquarters from Berlin to Altaussee, where he had often vacationed and had strong ties. While there, he opposed and thwarted the efforts of local governor August Eigruber to destroy the huge and irreplaceable collection of art stolen by the Nazis from museums and private collections across occupied Europe (more than 6,500 paintings plus statuary) which had been intended for Hitler's planned Führermuseum in Linz.
Ernst Kaltenbrunner's nephew, Michl Kaltenbrunner, revealed that a hoard of Nazi treasure was buried in Lake Toplitz, confirming suspicions held by investigators for decades. It was also the first time any related family member of Ernst Kaltenbrunner gave any information in regards to their relative and the dumping of Nazi property. Ernst Kaltenbrunner's role was also discussed of his acting in defiance of Hitler's orders and the helping to save artworks from the Altaussee salt mines near Lake Toplitz from being destroyed. Kaltenbrunner's nephew substantiated claims made by Austrian journalist Konrad Kramar in his book "Mission Michelangelo" that Ernst Kaltenbrunner allowed Austrian miners in charge of the area to remove the paintings as well as remove bombs that were planted to blow them up.
These were stored in a nearby extensive complex of salt mines. Eigruber was determined to carry out what he had determined was Hitler's true desire – to prevent the collection from falling into the hands of "Bolsheviks and Jews" by destroying it with explosives set off in the mine. Working with Dr. Emmerin Pöchmüller, the mine overseer, Kaltenbrunner countermanded the order and had the explosives removed. Thus, such world treasures as Michelangelo's "Madonna of Bruges" stolen from the Church of Our Lady in Bruges, and Jan van Eyck's "Ghent Altarpiece" stolen from Saint Bavo Cathedral in Ghent; Vermeer's "The Astronomer" and "The Art of Painting" were not destroyed.
The same story, told from an American point of view, became the subject of George Clooney's "The Monuments Men" film.
Popular culture representations.
Dramas.
Kaltenbrunner has been portrayed by the following actors in film, television and theater productions.

</doc>
<doc id="10150" url="http://en.wikipedia.org/wiki?curid=10150" title="Engelbert Dollfuss">
Engelbert Dollfuss

Engelbert Dollfuss (German: "Engelbert Dollfuß"; October 4, 1892 – July 25, 1934) was an Austrian Christian Social and Patriotic Front statesman. Having served as Minister for Forests and Agriculture, he ascended to Federal Chancellor in 1932 in the midst of a crisis for the conservative government. In early 1933, he shut down parliament, banned the Austrian Nazi party and assumed dictatorial powers. Suppressing the Socialist movement in February 1934, he cemented the rule of “austrofascism” through the authoritarian "First of May Constitution". Dollfuss was assassinated as part of a failed coup attempt by Nazi agents in 1934. His successor Kurt Schuschnigg maintained his regime until Adolf Hitler's annexing of Austria in 1938.
Early life.
He was born in Texing in Lower Austria to unmarried mother Josepha Dollfuss and her lover Joseph Weninger. The couple, of peasant origin, was unable to get married due to financial problems. Josepha married landowner Leopold Schmutz a few months after her son's birth, who did not, however, adopt Engelbert as his own child. Dollfuss, who was raised as a devout Roman Catholic, was shortly in seminary before deciding to study law at the University of Vienna and then economics at the University of Berlin. There he met Alwine Glienke, a German woman from a Protestant family, whom he married in 1921. The couple had a son and two daughters, one of whom died in early childhood.
Dollfuss had difficulty gaining admission into the Austro-Hungarian army in World War I because he was only 153 cm (slightly over five feet) tall. He was eventually accepted and sent to the Alpine Front. He was a highly decorated soldier and was briefly taken by the Italians as a prisoner of war in 1918. After the war he worked for the agriculture ministry as secretary of the Farmers' Association and became director of the Lower Austrian Chamber of Agriculture in 1927. In 1930, as a member of the conservative Christian Social Party (CS), he was appointed president of the Federal Railway System. (One of the founders of the CS was a hero of Dollfuss', Karl Freiherr von Vogelsang.) The following year, he was named Minister of Agriculture and Forests.
Chancellor of Austria.
In late May 1932, with the resignation of Karl Buresch's Christian-Social government, Dollfuss, age 39 and with only one year's experience in the Federal government, was offered the office of Chancellor by President Wilhelm Miklas, also a member of the Christian-Social Party. Accordingly, Dollfuss refused to reply, instead spending the night in his favorite church praying, returning in the morning for a bath and a spartan meal before replying to the President he would accept the offer. Dollfuss was sworn in on May 20, 1932, as head of a coalition government between the Christian-Social Party, the Landbund—a right-wing agrarian party—and Heimatblock, the parliamentary wing of the "Heimwehr", a paramilitary ultra-nationalist group. The coalition assumed the pressing task of tackling the problems of the Great Depression. Much of the Austro-Hungarian Empire's industry had been situated in the areas that became part of Czechoslovakia and Yugoslavia after World War I as a result of the Treaty of Saint-Germain. Postwar Austria was therefore economically disadvantaged.
Dollfuss' majority in Parliament was marginal; his government had only a one-vote majority.
Dollfuss as dictator of Austria.
In March 1933, an argument arose over irregularities in the voting procedure. The Social Democratic president of the National Council (the lower house of parliament) Karl Renner resigned to be able to cast a vote as a parliament member. As a consequence, the two vice presidents, belonging to other parties, resigned as well to be able to vote. Without a president, the parliament could not conclude the session. Dollfuss took the three resignations as a pretext to declare that the National Council had become unworkable, and advised President Wilhelm Miklas to issue a decree adjourning it indefinitely. When the National Council wanted to reconvene days after the resignation of the three presidents, Dollfuss had police bar entrance to parliament, effectively eliminating democracy in Austria. From that point onwards, he governed as dictator by emergency decree with absolute power.
Dollfuss was concerned that with German National Socialist leader Adolf Hitler becoming Chancellor of Germany in 1933, the Austrian National Socialists (DNSAP) could gain a significant minority in future elections (according to fascism scholar Stanley G. Payne, should elections have been held in 1933, the DNSAP could have mustered about 25% of the votes - contemporary "Time" magazine analysts suggest a higher support of 50%, with a 75% approval rate in the Tyrol region bordering Nazi Germany). As well, the Soviet Union's influence in Europe had increased throughout the 1920s and early 1930s. Dollfuss banned the communists on May 26, 1933 and the DNSAP on June 19, 1933. Under the banner of Christian Social Party, he later established a one-party dictatorship rule largely modeled after fascism in Italy, banning all other Austrian parties including the Social Democratic Labour Party (SDAPÖ). Social Democrats however continued to exist as an independent organization, nevertheless, without its paramilitary "Republikanischer Schutzbund", which until March 31, 1939 could have mustered tens of thousands against Dollfuss' government.
Austrofascism.
Dollfuss modeled austrofascism after Italian fascism juxtaposed to Catholic corporatism and anti-secularism, dropping Austrian pretences of reunification with Germany as long as the Nazi Party remained in power. In August 1933, Benito Mussolini's regime issued a guarantee of Austrian independence. Dollfuss also exchanged 'Secret Letters' with Mussolini about ways to guarantee Austrian independence. Mussolini was interested in Austria forming a buffer zone against Nazi Germany. Dollfuss always stressed the similarity of the regimes of Hitler in Germany and Joseph Stalin in the Soviet Union, and was convinced that Austrofascism and Italian fascism could counter totalitarian national socialism and communism in Europe.
In September 1933 Dollfuss merged his Christian Social Party with elements of other nationalist and conservative groups, including the Heimwehr, which encompassed many workers who were unhappy with the radical leadership of the socialist party, to form the "Vaterländische Front", though the Heimwehr continued to exist as an independent organization until 1936, when Dollfuss' successor Kurt von Schuschnigg forcibly merged it into the Front, instead creating the unabidingly loyal "Frontmiliz" as paramilitary task force. Dollfuss escaped an assassination attempt in October 1933 by Rudolf Dertill, a 22-year old who had been ejected from the military for his national socialist views.
Austrian civil war and new constitution.
In February 1934, Nazi agents in the security forces provoked arrests of Social Democrats and unjustified searches for weapons of the Social Democrats' already outlawed Republikanischer Schutzbund. After the Dollfuss dictatorship took steps against known Social Democrats, the Social Democrats called for nationwide resistance against the government. A civil war began, which lasted from February 12 until February 27. Fierce fighting took place primarily in the East of Austria, especially in the streets of some outer Vienna districts, where large fortress-like municipal workers' buildings were situated, and in the northern, industrial areas of the province of Styria, where Nazi agents had great interest in a bloodbath between security forces and workers' militias. The resistance was suppressed by police and military power. The Social Democrats were outlawed, and their leaders were imprisoned or fled abroad.
New constitution.
Dollfuss staged a parliamentary session with just his party members present in April 1934 to have his new constitution approved, effectively the second constitution in the world espousing corporatist ideas (after that of the Portuguese "Estado Novo"). The session retrospectively made all the decrees already passed since March 1933 legal. The new constitution became effective on May 1, 1934, and swept away the last remnants of democracy and the system of the first Austrian Republic.
Assassination.
Dollfuss was assassinated on July 25, 1934, by ten Austrian Nazis (Paul Hudl, Franz Holzweber, Otto Planetta and others) of Regiment 89 who entered the Chancellery building and shot him in an attempted coup d'état, the July Putsch. Mussolini had no hesitation in attributing the attack to the German dictator: the news reached him at Cesena, where he was examining the plans for a psychiatric hospital. The Duce personally gave the announcement to the widow, who was a guest at his villa in Riccione with children. He also put at the disposal of Ernst Rüdiger Starhemberg, who spent a holiday in Venice, a plane that allowed the prince to rush back to Vienna and to face the assailants with his militia, with the permission of President Wilhelm Miklas.
Mussolini also mobilized a part of the Italian army on the Austrian border and threatened Hitler with war in the event of a German invasion of Austria to thwart the putsch. Then he announced to the world: "The independence of Austria, for which he has fallen, is a principle that has been defended and will be defended by Italy even more strenuously", and then replaced in the main square of Bolzano the statue of Walther von der Vogelweide, a Germanic troubadour, with that of Drusus, a Roman general who conquered part of Germany. This was the greatest moment of friction between Fascism and National Socialism and Mussolini himself came down several times to reaffirm the differences in the field. The assassination of Dollfuss was accompanied by uprisings in many regions in Austria, resulting in further deaths. In Carinthia, a large contingent of northern German Nazis tried to seize power but were subdued by the Italian units nearby. At first Hitler was jubilant, but the Italian reaction surprised him. Hitler became convinced that he could not face a conflict with the Western European powers, and he officially denied liability, stating his regret for the murder of the Austrian Prime Minister. He replaced the ambassador to Vienna with Franz von Papen and prevented the conspirators entering Germany, also expelling them from the Austrian Nazi Party. The Nazi assassins in Vienna, after declaring the formation of a new government under Austrian Nazi Anton Rintelen, previously exiled by Dollfuss as Austrian Ambassador to Rome, surrendered after threats from Austrian military of blowing up the Chancellery using dynamite, and were subsequently tried and executed by hanging. Kurt Schuschnigg, previously Minister of Education was appointed new chancellor of Austria after a few days, assuming the office from Dollfuss' deputy Starhemberg.
Out of a population of 6.5 million, approximately 500,000 Austrians were present at Dollfuss' burial in Vienna. He is interred in the Hietzing cemetery in Vienna beside his wife Alwine Dollfuss (d. 1973) and two of his children, Hannerl and Eva, all of whom were in Italy as guests of Rachele Mussolini at the time of his death, an event which saw Mussolini himself shed some tears over his slain ally.
Stature.
Dollfuss was a very short man and his diminutive stature (155 cm = 5'2" or 150 cm = 4'11" according to the "New York Times") was the object of satire; among his nicknames were 'Millimetternich' (making a portmanteau out of millimeter and Metternich), and the "Jockey". The "New York Times" also reported a series of jokes, including how in the coffee houses of Vienna, one could order a "Dollfuss" cup of coffee instead of a "Short Black" cup of coffee (black being the color of the Christian Democratic political faction).
In contrast to his own diminutive stature, his personal assistant and secretary Eduard Hedvicek, who later played a significant role in the unsuccessful attempt to save his life, was a very large and tall man (2 m).
In literature.
In Bertolt Brecht's "Lehrstück" "The Resistible Rise of Arturo Ui", Dollfuss is represented by the character "Dullfeet".<ref name="The New York Times - 9 May 1991- Review/Theater; Brecht's Cauliflower King In Another Resistible Rise"></ref>

</doc>
<doc id="10151" url="http://en.wikipedia.org/wiki?curid=10151" title="E. T. A. Hoffmann">
E. T. A. Hoffmann

Ernst Theodor Amadeus Hoffmann (24 January 1776 – 25 June 1822) (E. T. A. Hoffmann), who was born Ernst Theodor Wilhelm Hoffmann, was a German Romantic author of fantasy and horror, a jurist, composer, music critic, draftsman and caricaturist. His stories form the basis of Jacques Offenbach's famous opera "The Tales of Hoffmann", in which Hoffmann appears (heavily fictionalized) as the hero. He is also the author of the novella "The Nutcracker and the Mouse King", on which the famous ballet "The Nutcracker" is based. The ballet "Coppélia" is based on two other stories that Hoffmann wrote, while Schumann's "Kreisleriana" is based on Hoffmann's character Johannes Kreisler.
Hoffmann's stories were very influential during the 19th century, and he is one of the major authors of the Romantic movement.
Life.
Youth.
Hoffmann's ancestors, both maternal and paternal, were jurists. His father, Christoph Ludwig Hoffmann (1736–97), was a barrister in Königsberg, Prussia (now Kaliningrad, Russia), as well as a poet and amateur musician who played the viola da gamba. In 1767 he married his cousin, Lovisa Albertina Doerffer (1748–96). Ernst Theodor Wilhelm, born on 24 January 1776, was the youngest of three children, of whom the second died in infancy.
When his parents separated in 1778, the father went to Insterburg (now Chernyakhovsk) with his elder son, Johann Ludwig Hoffmann (1768–after 1822), while Ernst's mother stayed in Königsberg with her relatives: two aunts, Johanna Sophie Doerffer (1745–1803) and Charlotte Wilhelmine Doerffer (c. 1754–79) and their brother, Otto Wilhelm Doerffer (1741–1811), who were all unmarried. This trio raised the youngster.
The household, dominated by the uncle (whom Ernst nicknamed "O Weh"—"Oh dear!"—in a play on his initials), was pietistic and uncongenial. Hoffmann was to regret his estrangement from his father. Nevertheless he remembered his aunts with great affection, especially the younger, Charlotte, whom he nicknamed "Tante Füßchen" ("Aunt Littlefeet"). Although she died when he was only three years old, he treasured her memory (e.g. see "Kater Murr") and embroidered stories about her to such an extent that later biographers sometimes assumed her to be imaginary, until proof of her existence was found after World War II.
Between 1781 and 1792 he attended the Lutheran school or "Burgschule", where he made good progress in classics. He was taught drawing by one Saemann, and counterpoint by a Polish organist named Podbileski, who was to be the prototype of Abraham Liscot in "Kater Murr". Ernst showed great talent for piano-playing, and busied himself with writing and drawing. The provincial setting was not, however, conducive to technical progress, and despite his many-sided talents he remained rather ignorant of both classical forms and of the new artistic ideas that were developing in Germany. He had however read Schiller, Goethe, Swift, Sterne, Rousseau and Jean Paul, and wrote part of a novel titled "Der Geheimnisvolle".
Around 1787 he became friends with Theodor Gottlieb von Hippel the Younger (1775–1843), the son of a pastor, and nephew of Theodor Gottlieb von Hippel the Elder, the well-known writer friend of Immanuel Kant. During 1792, both attended some of Kant's lectures at the University of Königsberg. Their friendship, although often tested by an increasing social difference, was to be lifelong.
In 1794, Hoffmann became enamored of Cora Hatt, a married woman to whom he had given music lessons. She was ten years older, and in 1795 gave birth to her sixth child. In February 1796, her family protested against his attentions and, with his hesitant consent, asked another of his uncles to arrange employment for him in Glogau (Głogów), Prussian Silesia.
The provinces.
From 1796 Hoffmann obtained employment as a clerk for his uncle, Johann Ludwig Doerffer, who lived in Glogau with his daughter Minna. After passing further examinations he visited Dresden, where he was amazed by the paintings in the gallery, particularly those of Correggio and Raphael. During the summer of 1798 his uncle was promoted to a court in Berlin, and the three of them moved there in August—Hoffmann's first residence in a large city. It was there that Hoffmann first attempted to promote himself as a composer, writing an operetta called "Die Maske" and sending a copy to Queen Luise of Prussia. The official reply advised to him to write to the director of the Royal Theatre, a man named Iffland. By the time the latter responded, Hoffmann had passed his third round of examinations and had already left for Posen (Poznań) in South Prussia in the company of his old friend Hippel, with a brief stop in Dresden to show him the gallery.
From June 1800 to 1803 he worked in Prussian provinces in the area of Greater Poland and Masovia. This was the first time he had lived without supervision by members of his family, and he started to become "what school principals, parsons, uncles, and aunts call dissolute."
His first job, at Posen, was endangered after Carnival on Shrove Tuesday 1802, when caricatures of military officers were distributed at a ball. It was immediately deduced who had drawn them, and complaints were made to authorities in Berlin, who were reluctant to punish the promising young official. The problem was solved by "promoting" Hoffmann to Płock in New East Prussia, the former capital of Poland (1079–1138) where administrative offices were relocated from Thorn (Toruń). He visited the place to arrange lodging, before returning to Posen where he married "Mischa" (Maria, or Marianna Tekla Michalina Rorer, whose Polish surname was Trzcińska). They moved to Płock in August 1802.
Hoffmann despaired because of his exile, and drew caricatures of himself drowning in mud alongside ragged villagers. He did make use, however, of his isolation, by writing and composing. He started a diary on 1 October 1803. An essay on the theatre was published in Kotzebue's periodical, "Die Freimüthige", and he entered a competition in the same magazine to write a play. Hoffmann's was called "Der Preis" ("The Prize"), and was itself about a competition to write a play. There were fourteen entries, but none was judged worthy of the award: 100 Friedrichs d'or. Nevertheless, his entry was singled out for praise. This was one of the few good times of a sad period of his life, which saw the deaths of his uncle J. L. Hoffmann in Berlin, his Aunt Sophie, and Cora Hatt in Königsberg.
At the beginning of 1804 he obtained a post at Warsaw. On his way there, he passed through his hometown and met one of Cora Hatt's daughters. He was never to return to Königsberg.
Warsaw.
Hoffmann assimilated well with Polish society; the years spent in Prussian Poland he recognized as the happiest of his life. In Warsaw he found the same atmosphere he had enjoyed in Berlin, renewing his friendship with Zacharias Werner, and meeting his future biographer, a neighbour and fellow jurist called Julius Eduard Itzig (who changed his name to Hitzig after his baptism). Itzig had been a member of the Berlin literary group called the "Nordstern", and he gave Hoffmann the works of Novalis, Ludwig Tieck, Achim von Arnim, Clemens Brentano, Gotthilf Heinrich von Schubert, Carlo Gozzi, and Calderon. These relatively late introductions marked his work profoundly.
He moved in the circles of August Wilhelm Schlegel, Adelbert von Chamisso, Friedrich de la Motte Fouqué, Rahel Levin, and David Ferdinand Koreff.
His fortunate position was not to last: on 28 November 1806 during the War of the Fourth Coalition, Napoleon Bonaparte's troops captured Warsaw, and the Prussian bureaucrats lost their jobs. They divided the contents of the treasury between them and fled. In January 1807 his wife and two-year-old daughter Cäcilia returned to Posen, while he pondered whether to move to Vienna or go back to Berlin. A delay of six months was caused by severe illness. Eventually the French authorities demanded that all former officials swear allegiance or leave the country. As they refused to grant him a passport to Vienna, he was forced to return to Berlin.
He visited his family in Posen before arriving in Berlin on 18 June 1807, hoping to further his career there as an artist and writer.
Berlin and Bamberg.
The next fifteen months were some of the worst in Hoffmann's life.
The city of Berlin was also occupied by Napoleon's troops. Obtaining only meagre allowances, he had frequent recourse to his friends, constantly borrowing money and still going hungry for days at a time; he learned that his daughter had died. Nevertheless, he managed to compose his Six Canticles for "a cappella" choir: one of his best compositions, which he would later attribute to Kreisler in "Lebensansichten des Katers Murr".
On 1 September 1808 he arrived with his wife in Bamberg, where he began a job as theatre manager. The director, Count Soden, left almost immediately for Würzburg, leaving a man named Heinrich Cuno in charge. Hoffmann was unable to improve standards of performance, and his efforts caused intrigues against him which resulted in him losing his job to Cuno. He began work as music critic for the "Allgemeine musikalische Zeitung", a newspaper in Leipzig, and his articles on Beethoven were especially well received, and highly regarded by the composer himself. It was in its pages that the "Kapellmeister Johannes Kreisler" character made his first appearance.
Hoffmann's breakthrough came in 1809, with the publication of "Ritter Gluck", a story about a man who meets, or believes he has met, the composer Christoph Willibald Gluck (1714–87) more than twenty years after the latter's death. The theme alludes to the work of Jean Paul, who invented the term Doppelgänger the previous decade, and continued to exact a powerful influence over Hoffmann, becoming one of his earliest admirers. With this publication, Hoffmann began to use the pseudonym E. T. A. Hoffmann, telling people that the "A" stood for "Amadeus", in homage to the composer Wolfgang Amadeus Mozart (1756–91). However, he continued to use Wilhelm in official documents throughout his life, and the initials E. T. W. also appear on his gravestone.
The next year, he was employed at the Bamberg Theatre as stagehand, decorator, and playwright, while also giving private music lessons.
He became so enamored of a young singing student, Julia Marc, that his feelings were obvious whenever they were together, and Julia's mother quickly found her a more suitable match. When Joseph Seconda offered Hoffmann a position as musical director for his opera company (then performing in Dresden), he accepted, leaving on 21 April 1813.
Dresden and Leipzig.
Prussia had declared war against France on 16 March during the War of the Sixth Coalition, and their journey was fraught with difficulties. They arrived on the 25th, only to find that Seconda was in Leipzig; on the 26th, they sent a letter pleading for temporary funds. That same day Hoffmann was surprised to meet Hippel, whom he had not seen for nine years.
The situation deteriorated, and in early May Hoffmann tried in vain to find transport to Leipzig. On 8 May, the bridges were destroyed, and his family were marooned in the city. During the day, Hoffmann would roam, watching the fighting with curiosity. Finally, on 20 May, they left for Leipzig, only to be involved in an accident which killed one of the passengers in their coach and injured his wife.
They arrived on 23 May, and Hoffmann started work with Seconda's orchestra, which he found to be of the best quality. On 4 June an armistice began, which allowed the company to return to Dresden. But on 22 August, after the end of the armistice, the family was forced to relocate from their pleasant house in the suburbs into the town, and during the next few days the Battle of Dresden raged. The city was bombarded; many people were killed by bombs directly in front of him. After the main battle was over, he visited the gory battlefield. His account can be found in "Vision auf dem Schlachtfeld bei Dresden". After a long period of continued disturbance the town surrendered on 11 November, and on 9 December the company travelled to Leipzig.
On 25 February Hoffmann quarrelled with Seconda, and the next day he was given notice of twelve weeks. When asked to accompany them on their journey to Dresden in April, he refused, and they left without him. But during July his friend Hippel visited, and soon he found himself being guided back into his old career as a jurist.
Berlin.
At the end of September 1814, in the wake of Napoleon's defeat, Hoffmann returned to Berlin and succeeded in regaining a job at the "Kammergericht", the chamber court. His opera "Undine" was performed by the Berlin Theatre. Its successful run came to an end only after a fire on the night of the 25th performance. Magazines clamoured for his contributions, and after a while his standards started to decline. Nevertheless, many masterpieces date from this time.
During the period from 1819 Hoffmann involved with legal disputes, while fighting ill health. Alcohol abuse and syphilis eventually caused weakening of his limbs during 1821, and paralysis from the beginning of 1822. His last works were dictated to his wife or to a secretary.
Prince Metternich's anti-liberal crusades began to put Hoffmann in situations that tested his conscience. Thousands of people were accused of treason for having certain political opinions,
and university professors were monitored during their lectures.
King Frederick William III of Prussia appointed an Immediate Commission for the investigation of political dissidence; when he found its observance of the rule of law too frustrating, he established a Ministerial Commission to interfere with its processes. The latter was greatly influenced by Commissioner Kamptz. During the trial of "Turnvater" Jahn, the founder of the gymnastics association movement, Hoffmann found himself annoying Kamptz, and became a political target. When Hoffmann caricatured Kamptz in a story ("Meister Floh"), Kamptz began legal proceedings. These ended when Hoffmann's illness was found to be life-threatening. The King asked for a reprimand only, but no action was ever taken. Eventually "Meister Floh" was published with the offending passages removed.
Hoffmann died in Berlin on 25 June 1822 at the age of 46. His grave is preserved in the Protestant "Friedhof III der Jerusalems- und Neuen Kirchengemeinde" (Cemetery No. III of the congregations of Jerusalem Church and New Church) in Berlin-Kreuzberg, south of Hallesches Tor.
Assessment.
Hoffmann is one of the best-known representatives of German Romanticism, and a pioneer of the fantasy genre, with a taste for the macabre combined with realism that influenced such authors as Edgar Allan Poe (1809–1849), Nikolai Gogol (1809–1852), Charles Dickens (1812–1870), Charles Baudelaire (1821–1867), George MacDonald (1824–1905), Fyodor Dostoevsky (1821–1881), Vernon Lee (1856-1935), Franz Kafka (1883–1924) and Alfred Hitchcock (1899–1980). Hoffmann's story "Das Fräulein von Scuderi" is sometimes cited as the first detective story and a direct influence on Poe's "The Murders in the Rue Morgue".
The twentieth-century Russian literary theorist Mikhail Bakhtin characterised Hoffmann's works as Menippea, essentially satirical and self-parodying in form, thus including him in a tradition that includes Cervantes, Diderot and Voltaire.
Robert Schumann's piano suite Kreisleriana (1838) has its title from one of Hoffmann's books (and according to Charles Rosen's "The Romantic Generation", is possibly also inspired by "The Life and Opinions of Tomcat Murr", in which Kreisler appears). Jacques Offenbach's masterwork, the opera "Les contes d'Hoffmann" ("The Tales of Hoffmann", 1881), is based on the stories "Der Sandmann" ("The Sandman", 1816), "Rat Krespel" ("Councillor Krespel", 1818), and "Das verlorene Spiegelbild" ("The Lost Reflection") from "Die Abenteuer der Silvester-Nacht" ("The Adventures of New Year's Eve", 1814). Pyotr Ilyich Tchaikovsky's ballet "The Nutcracker" (1892) is based on "Nutcracker and Mouse King".
Hoffmann also influenced 19th century musical opinion directly through his music criticism. His reviews of Beethoven's Symphony No. 5 in C minor, Op. 67 (1808) and other important works set new literary standards for writing about music, and encouraged later writers to consider music as "the most Romantic of all the arts." Hoffmann's reviews were first collected for modern readers by Friedrich Schnapp, ed., in "E.T.A. Hoffmann: Schriften zur Musik; Nachlese" (1963) and have been made available in an English translation in "E.T.A. Hoffmann's Writings on Music, Collected in a Single Volume" (2004).
Hoffmann strove for artistic polymathy. He created far more in his works than mere political commentary achieved through satire. His masterpiece novel "Lebensansichten des Katers Murr" ("The Life and Opinions of Tomcat Murr", 1819–1821) deals with such issues as the aesthetic status of true artistry and the modes of self-transcendence that accompany any genuine endeavour to create. Hoffmann's portrayal of the character Kreisler (a genius musician) is wittily counterpointed with the character of the tomcat Murr – a virtuoso illustration of artistic pretentiousness that many of Hoffmann's contemporaries found offensive and subversive of Romantic ideals.
Hoffmann's literature indicates the failings of many so-called artists to differentiate between the superficial and the authentic aspects of such Romantic ideals. The "self-conscious" effort to impress must, according to Hoffmann, be divorced from the "self-aware" effort to create. This essential duality in "Kater Murr" is conveyed structurally through a discursive 'splicing together' of two biographical narratives.

</doc>
<doc id="10152" url="http://en.wikipedia.org/wiki?curid=10152" title="Desiderius Erasmus">
Desiderius Erasmus

Desiderius Erasmus Roterodamus (; 27 October 1466 – 12 July 1536), known as Erasmus of Rotterdam, or simply Erasmus, was a Dutch Renaissance humanist, Catholic priest, social critic, teacher, and theologian.
Erasmus was a classical scholar who wrote in a pure Latin style. Amongst humanists, he enjoyed the sobriquet "Prince of the Humanists"; he has been called "the crowning glory of the Christian humanists". Using humanist techniques for working on texts, he prepared important new Latin and Greek editions of the New Testament. These raised questions that would be influential in the Protestant Reformation and Catholic Counter-Reformation. He also wrote "On Free Will," "The Praise of Folly", "Handbook of a Christian Knight", "On Civility in Children", "", "Julius Exclusus", and many other works.
Erasmus lived against the backdrop of the growing European religious Reformation; but while he was critical of the abuses within the Church and called for reform, he kept his distance from Luther and Melanchthon and continued to recognise the authority of the pope. Erasmus emphasized a middle way, with a deep respect for traditional faith, piety and grace, and rejected Luther's emphasis on faith alone. Erasmus therefore remained a member of the Catholic Church all his life.
Erasmus remained committed to reforming the Church and its clerics' abuses from within. He also held to Catholic doctrines such as that of free will, which some Reformers rejected in favour of the doctrine of predestination. His middle road approach disappointed and even angered scholars in both camps.
Erasmus died suddenly in Basel in 1536 while preparing to return to Brabant, and was buried in the Basel Minster, the former cathedral of the city. A bronze statue of him was erected in his city of birth in 1622, replacing an earlier work in stone. Erasmus was his baptismal name, given after St. Erasmus of Formiae. Desiderius was a self-adopted additional name, which he used from 1496. The "Roterodamus" in his scholarly name is the Latinized adjectival form for the city of Rotterdam.
Early life.
Desiderius Erasmus was born in Holland on 27 October in the late 1460s.
Some people maintain that he was called Geert Geerts (also Gerhard Gerhards or Gerrit Gerritsz), but of this there is no proof. He was born in Rotterdam, although there are insufficient records to confirm this. On a well-known wooden picture is indicated: "Goudæ conceptus, Roterodami natus" (Latin: conceived in Gouda; born in Rotterdam). According to an article by historian Renier Snooy (1478-1537), Erasmus was born in Gouda.
The exact year of his birth is debated, with most biographers citing the year as 1466. Some evidence confirming 1466 can be found in Erasmus's own words: of twenty-three statements Erasmus made about his age, all but one of the first fifteen indicate 1466. He was christened "Erasmus" after the saint of that name. Although associated closely with Rotterdam, he lived there for only four years, never to return. Information on his family and early life comes mainly from vague references in his writings. His parents were not legally married. His father, Gerard, was a Catholic priest and curate in Gouda. Little is known of his mother other than that her name was Margaretha Rogerius (Latinized form of Dutch surname 'Rutgers') and she was the daughter of a physician from Zevenbergen; she may have been Gerard's housekeeper. Although he was born out of wedlock, Erasmus was cared for by his parents until their early deaths from the plague in 1483; but he felt his origin to be a stain, and threw a smoke-screen around his youth.
Erasmus was given the highest education available to a young man of his day, in a series of monastic or semi-monastic schools. At the age of nine, he and his older brother Peter were sent to one of the best Latin schools in the Netherlands, located at Deventer and owned by the chapter clergy of the Lebuïnuskerk (St. Lebuin's Church), though some earlier biographies assert it was a school run by the Brethren of the Common Life. During his stay there the curriculum was renewed by the principal of the school, Alexander Hegius. For the first time ever Greek was taught at a lower level than a university in Europe, and this is where he began learning it. He also gleaned there the importance of a personal relationship with God but eschewed the harsh rules and strict methods of the religious brothers and educators. His education there ended when plague struck the city about 1483, and his mother, who had moved there to provide a home for her sons, died of the infection.
Ordination and monastic experience.
In 1492, poverty forced Erasmus into the consecrated life. He took vows as a canon regular at the canonry of Stein, in South Holland, and was ordained to the Catholic priesthood at about the age of 25, but he never seemed to have actively worked as a priest for a longer time, and certain tenets of life in Religious Orders were among the chief objects of his attack in his lifelong assault upon Church excesses.
While at Stein, Erasmus fell in love with a fellow canon, Servatius Rogerus, and wrote a series of passionate letters in which he called Rogerus "half my soul". He wrote, "I have wooed you both unhappily and relentlessly". This correspondence contrasts sharply with the generally detached and much more restrained attitude he showed in his later life. Later, while tutoring in Paris, he was suddenly dismissed by the guardian of Thomas Grey. Some have taken this as evidence of an illicit affair. No personal denunciation was made of Erasmus during his lifetime, however, and he took pains in later life to distance these earlier episodes by condemning sodomy in his works, and praising sexual desire in marriage between men and women.
Soon after his priestly ordination, he got his chance to leave the canonry when offered the post of secretary to the Bishop of Cambrai, Henry of Bergen, on account of his great skill in Latin and his reputation as a man of letters. To allow him to accept that post, he was given a temporary dispensation from his religious vows on the grounds of poor health and love of Humanistic studies, though he remained a priest. Pope Leo X later made the dispensation permanent, a considerable privilege at the time.
Education and scholarship.
In 1495, with Bishop Henry's consent and a stipend, he went on to study at the University of Paris, in the Collège de Montaigu, a centre of reforming zeal, under the direction of the ascetic Jan Standonck, of whose rigors Erasmus complained. The University was then the chief seat of Scholastic learning, but already coming under the influence of Renaissance humanism. For instance, Erasmus became an intimate friend of an Italian Humanist Publio Fausto Andrelini, poet and "professor of humanity" in Paris.
The chief centres of Erasmus's activity were Paris, Leuven (in the Duchy of Brabant), England, and Basel; yet he never belonged firmly in any one of these places. In 1499 he was invited by William Blount, 4th Baron Mountjoy to accompany him on his return to England. Erasmus "ever susceptible to the charms of attractive, well-connected, and rich young men" agreed. His time in England was fruitful in the making of lifelong friendships with the leaders of English thought in the days of King Henry VIII: John Colet, Thomas More, John Fisher, Thomas Linacre and William Grocyn. At the University of Cambridge, he was the Lady Margaret's Professor of Divinity and had the option of spending the rest of his life as an English professor. He stayed at Queens' College, Cambridge from 1510 to 1515. His rooms were in the "I" staircase of Old Court, and he famously hated English ale and English weather. He suffered from poor health and complained that Queens' could not supply him with enough decent wine (wine was the Renaissance medicine for gallstones, from which Erasmus suffered). Until the 19th century, Queens' College used to have a corkscrew that was purported to be "Erasmus' corkscrew" which was a third of a metre long, though today the college still has what it calls "Erasmus' chair". Today Queens' College has an Erasmus Building and an Erasmus Room. His legacy is marked for someone who complained bitterly about the lack of comforts and luxuries to which he was accustomed. As Queens' was an unusually humanist-leaning institution in the 16th century, Queens' College Old Library still houses many first editions of Erasmus' publications, many of which were acquired during that period by bequest or purchase, including Erasmus' New Testament translation which is signed by friend and Polish religious reformer John Lasky. Erasmus' friend, Chancellor John Fisher, was president of Queens' College from 1505 to 1508. His friendship with Fisher is the reason he chose to stay at Queens' while lecturing in Greek at the University.
In 1499, while in England, Erasmus was particularly impressed by the Bible teaching of John Colet who pursued a style more akin to the church fathers than the Scholastics. This prompted him, upon his return from England, to master the Greek language, which would enable him to study theology on a more profound level and to prepare a new edition of Jerome's Bible translation. On one occasion he wrote Colet: 
"I cannot tell you, dear Colet, how I hurry on, with all sails set, to holy literature. How I dislike everything that keeps me back, or retards me".
Despite a chronic shortage of money, he succeeded in learning Greek by an intensive, day-and-night study of three years, continuously begging his friends to send him books and money for teachers in his letters. Discovery in 1506 of Lorenzo Valla's "New Testament Notes" encouraged Erasmus to continue the study of the New Testament.
Erasmus preferred to live the life of an independent scholar and made a conscious effort to avoid any actions or formal ties that might inhibit his freedom of intellect and literary expression. Throughout his life, he was offered many positions of honor and profit throughout the academic world but declined them all, preferring the uncertain but sufficient rewards of independent literary activity. From 1506 to 1509, he was in Italy: in 1506 he graduated as Doctor of Divinity at the Turin University, and he spent part of the time as a proofreader at the publishing house of Aldus Manutius in Venice. According to his letters, he was associated with the Venetian natural philosopher, Giulio Camillo, but, apart from this, he had a less active association with Italian scholars than might have been expected.
His residence at Leuven, where he lectured at the Catholic University, exposed Erasmus to much criticism from those ascetics, academics and clerics hostile to the principles of literary and religious reform and the loose norms of the Renaissance adherents to which he was devoting his life. In 1517, he supported the foundation at the University, by his friend Hieronymus van Busleyden, of the Collegium Trilingue for the study of Hebrew, Latin, and Greek—after the model of the College of the Three Languages at the University of Alcalá. However, feeling that the lack of sympathy which prevailed at Leuven at that time was actually a form of mental persecution, he sought refuge in Basel, where under the shelter of Swiss hospitality he could express himself freely. Admirers from all quarters of Europe visited him there and he was surrounded by devoted friends, notably developing a lasting association with the great publisher Johann Froben.
Only when he had mastered Latin did he begin to express himself on major contemporary themes in literature and religion. He felt called upon to use his learning in a purification of the doctrine by returning to the historic documents and original languages of sacred Scripture. He tried to free the methods of scholarship from the rigidity and formalism of medieval traditions, but he was not satisfied with this. His revolt against certain forms of Christian monasticism and scholasticism was not based on doubts about the truth of doctrine, nor from hostility to the organization of the Church itself, nor from rejection of celibacy or monastical lifestyles. He saw himself as a preacher of righteousness by an appeal to reason, applied frankly and without fear of the magisterium. He always intended to remain faithful to Catholic doctrine, and therefore was convinced he could criticize frankly virtually everyone and everything. Aloof from entangling obligations, Erasmus was the centre of the literary movement of his time, corresponding with more than five hundred men in the worlds of politics and of thought.
Publication of the Greek New Testament.
The first New Testament printed in Greek was part of the Complutensian Polyglot. This portion was printed in 1514, but publication was delayed until 1522 by waiting for the Old Testament portion, and the sanction of Pope Leo X. Erasmus had been working for years on two projects: a collation of Greek texts and a fresh Latin New Testament. In 1512, he began his work on this Latin New Testament. He collected all the Vulgate manuscripts he could find to create a critical edition. Then he polished the Latin. He declared, "It is only fair that Paul should address the Romans in somewhat better Latin." In the earlier phases of the project, he never mentioned a Greek text:
While his intentions for publishing a fresh Latin translation are clear, it is less clear why he included the Greek text. Though some speculate that he intended to produce a critical Greek text or that he wanted to beat the Complutensian Polyglot into print, there is no evidence to support this. He wrote, "There remains the New Testament translated by me, with the Greek facing, and notes on it by me."
He further demonstrated the reason for the inclusion of the Greek text when defending his work:
So he included the Greek text to permit qualified readers to verify the quality of his Latin version. But by first calling the final product "Novum Instrumentum omne" ("All of the New Teaching") and later "Novum Testamentum omne" ("All of the New Testament") he also indicated clearly that he considered a text in which the Greek and the Latin versions were consistently comparable to be the essential core of the church's New Testament tradition.
In a way it is legitimate to say that Erasmus "synchronized" or "unified" the Greek and the Latin traditions of the New Testament by producing an updated version of either simultaneously. Both being part of canonical tradition, he clearly found it necessary to ensure that both were actually presenting the same content. In modern terminology, he made the two traditions "compatible". This is clearly evidenced by the fact that his Greek text is not just the basis for his Latin translation, but also the other way round: there are numerous instances where he edits the Greek text to reflect his Latin version. For instance, since the last six verses of "Revelation" were missing from his Greek manuscript, Erasmus translated the Vulgate's text back into Greek. Erasmus also translated the Latin text into Greek wherever he found that the Greek text and the accompanying commentaries were mixed up, or where he simply preferred the Vulgate’s reading to the Greek text.
Erasmus said it was "rushed into print rather than edited", resulting in a number of transcription errors. After comparing what writings he could find, Erasmus wrote corrections between the lines of the manuscripts he was using (among which was Minuscule 2) and sent them as proofs to Froben. His hurried effort was published by his friend Johann Froben of Basel in 1516 and thence became the first "published" Greek New Testament, the "Novum Instrumentum omne, diligenter ab Erasmo Rot. Recognitum et Emendatum". Erasmus used several Greek manuscript sources because he did not have access to a single complete manuscript. Most of the manuscripts were, however, late Greek manuscripts of the Byzantine textual family and Erasmus used the oldest manuscript the least because "he was afraid of its supposedly erratic text." He also ignored much older and better manuscripts that were at his disposal.
In the second (1519) edition, the more familiar term "Testamentum" was used instead of "Instrumentum". This edition was used by Martin Luther in his German translation of the Bible, written for people who could not understand Latin. Together, the first and second editions sold 3,300 copies. By comparison, only 600 copies of the Complutensian Polyglot were ever printed. The first and second edition texts did not include the passage (1 John 5:7–8) that has become known as the Comma Johanneum. Erasmus had been unable to find those verses in any Greek manuscript, but one was supplied to him during production of the third edition. That manuscript is now thought to be a 1520 creation from the Latin Vulgate, which likely got the verses from a fifth-century marginal gloss in a Latin copy of I John. The Roman Catholic Church decreed that the "Comma Johanneum" was open to dispute (2 June 1927), and it is rarely included in modern scholarly translations.
The third edition of 1522 was probably used by Tyndale for the first English New Testament (Worms, 1526) and was the basis for the 1550 Robert Stephanus edition used by the translators of the Geneva Bible and King James Version of the English Bible. Erasmus published a fourth edition in 1527 containing parallel columns of Greek, Latin Vulgate and Erasmus's Latin texts. In this edition Erasmus also supplied the Greek text of the last six verses of Revelation (which he had translated from Latin back into Greek in his first edition) from Cardinal Ximenez's "Biblia Complutensis". In 1535 Erasmus published the fifth (and final) edition which dropped the Latin Vulgate column but was otherwise similar to the fourth edition. Later versions of the Greek New Testament by others, but based on Erasmus's Greek New Testament, became known as the "Textus Receptus".
Erasmus dedicated his work to Pope Leo X as a patron of learning and regarded this work as his chief service to the cause of Christianity. Immediately afterward, he began the publication of his "Paraphrases of the New Testament", a popular presentation of the contents of the several books. These, like all of his writings, were published in Latin but were quickly translated into other languages, with his encouragement.
Beginnings of Protestantism.
Attempts at impartiality in dispute.
Martin Luther's movement began in the year following the publication of the New Testament and tested Erasmus' character. The issues between growing religious movements, which would later become known as Protestantism, and the Catholic Church had become so clear that few could escape the summons to join the debate. Erasmus, at the height of his literary fame, was inevitably called upon to take sides, but partisanship was foreign to his nature and his habits. In all his criticism of clerical follies and abuses, he had always protested that he was not attacking the Church itself or its doctrines, and had no enmity toward churchmen. The world had laughed at his satire, but few had interfered with his activities. He believed that his work so far had commended itself to the best minds and also to the dominant powers in the religious world.
Erasmus did not build a large body of supporters with his letters. He chose to write in Greek and Latin, the languages of scholars. His critiques reached an elite, but small audience.
Disagreement with Luther.
"Free will does not exist", according to Luther in his letter De Servo Arbitrio to Erasmus translated into German by Justus Jonas (1526) in that sin makes human beings completely incapable of bringing themselves to God. Noting Luther's criticism of the Catholic Church, Erasmus described him as "a mighty trumpet of gospel truth" while agreeing, "It is clear that many of the reforms for which Luther calls are urgently needed.” He had great respect for Luther, and Luther spoke with admiration of Erasmus's superior learning. Luther hoped for his cooperation in a work which seemed only the natural outcome of his own. In their early correspondence, Luther expressed boundless admiration for all Erasmus had done in the cause of a sound and reasonable Christianity and urged him to join the Lutheran party. Erasmus declined to commit himself, arguing that to do so would endanger his position as a leader in the movement for pure scholarship which he regarded as his purpose in life. Only as an independent scholar could he hope to influence the reform of religion. When Erasmus hesitated to support him, the straightforward Luther became angered that Erasmus was avoiding the responsibility due either to cowardice or a lack of purpose. However, any hesitancy on the part of Erasmus stemmed, not from lack of courage or conviction, but rather from a concern over the mounting disorder and violence of the reform movement. To Philip Melanchthon in 1524 he wrote:
I know nothing of your church; at the very least it contains people who will, I fear, overturn the whole system and drive the princes into using force to restrain good men and bad alike. The gospel, the word of God, faith, Christ, and Holy Spirit – these words are always on their lips; look at their lives and they speak quite another language.
Again, in 1529, he writes “An epistle against those who falsely boast they are Evangelicals” to Vulturius Neocomus (Gerardus Geldenhouwer). Here Erasmus complains of the doctrines and morals of the Reformers:
You declaim bitterly against the luxury of priests, the ambition of bishops, the tyranny of the Roman Pontiff, and the babbling of the sophists; against our prayers, fasts, and Masses; and you are not content to retrench the abuses that may be in these things, but must needs abolish them entirely...<br>Look around on this ‘Evangelical’ generation, and observe whether amongst them less indulgence is given to luxury, lust, or avarice, than amongst those whom you so detest. Show me any one person who by that Gospel has been reclaimed from drunkenness to sobriety, from fury and passion to meekness, from avarice to liberality, from reviling to well-speaking, from wantonness to modesty. I will show you a great many who have become worse through following it...The solemn prayers of the Church are abolished, but now there are very many who never pray at all...<br>I have never entered their conventicles, but I have sometimes seen them returning from their sermons, the countenances of all of them displaying rage, and wonderful ferocity, as though they were animated by the evil spirit...<br>Who ever beheld in their meetings any one of them shedding tears, smiting his breast, or grieving for his sins ?... Confession to the priest is abolished, but very few now confess to God... They have fled from Judaism that they may become Epicureans.
Apart from these perceived moral failings of the Reformers, Erasmus also dreaded any change in doctrine, citing the long history of the Church as a bulwark against innovation. In book I of his "Hyperaspistes" he puts the matter bluntly to Luther:
We are dealing with this: Would a stable mind depart from the opinion handed down by so many men famous for holiness and miracles, depart from the decisions of the Church, and commit our souls to the faith of someone like you who has sprung up just now with a few followers, although the leading men of your flock do not agree either with you or among themselves – indeed though you do not even agree with yourself, since in this same "Assertion" you say one thing in the beginning and something else later on, recanting what you said before.
Continuing his chastisement of Luther—and undoubtedly put off by the notion of there being "no pure interpretation of Scripture anywhere but in Wittenberg" – Erasmus touches upon another important point of the controversy:
You stipulate that we should not ask for or accept anything but Holy Scripture, but you do it in such a way as to require that we permit you to be its sole interpreter, renouncing all others. Thus the victory will be yours if we allow you to be not the steward but the lord of Holy Scripture.
Though he remained firmly neutral, each side accused him of siding with the other, perhaps because of his neutrality. It was not for lack of fidelity with either side but a desire for fidelity with them both:
"I detest dissension because it goes both against the teachings of Christ and against a secret inclination of nature. I doubt that either side in the dispute can be suppressed without grave loss."
In his catechism (entitled "Explanation of the Apostles' Creed") (1533), Erasmus took a stand against Luther's teaching by asserting the unwritten Sacred Tradition as just as valid a source of revelation as the Bible, by enumerating the Deuterocanonical books in the canon of the Bible and by acknowledging seven sacraments. He called "blasphemers" anyone who questioned the perpetual virginity of Mary. However, he supported lay access to the Bible.
In a letter to Nikolaus von Amsdorf, Luther objected to Erasmus’ Catechism and called Erasmus a "viper," "liar,"
and "the very mouth and organ of Satan."
Erasmus was accused by the monks against the Reformation, that he had: "prepared the way and was responsible for Martin Luther. Erasmus, they said, had laid the egg, and Luther had hatched it. Erasmus wittily dismissed the charge, claiming that Luther had hatched a different bird entirely.".
Free will.
Twice in the course of the great discussion, he allowed himself to enter the field of doctrinal controversy, a field foreign to both his nature and his previous practice. One of the topics he dealt with was free will, a crucial question. In his "De libero arbitrio diatribe sive collatio" (1524), he lampoons the Lutheran view on free will. He lays down both sides of the argument impartially. The "Diatribe" did not encourage any definite action; this was its merit to the Erasmians and its fault in the eyes of the Lutherans. In response, Luther wrote his "De servo arbitrio" (On the Bondage of the Will) (1525), which attacks the "Diatribe" and Erasmus himself, going so far as to claim that Erasmus was not a Christian. Erasmus responded with a lengthy, two-part "Hyperaspistes" (1526–27). In this controversy Erasmus lets it be seen that he would like to claim more for free will than St. Paul and St. Augustine seem to allow according to Luther's interpretation. For Erasmus the essential point is that humans have the freedom of choice. The conclusions Erasmus reached drew upon a large array of notable authorities, including, from the Patristic period, Origen, John Chrysostom, Ambrose, Jerome, and Augustine, in addition to many leading Scholastic authors, such as Thomas Aquinas and Duns Scotus. The content of Erasmus' works also engaged with later thought on the state of the question, including the perspectives of the "via moderna" school and of Lorenzo Valla, whose ideas he rejected.
As the popular response to Luther gathered momentum, the social disorders, which Erasmus dreaded and Luther disassociated himself from, began to appear, including the German Peasants' War, the Anabaptist disturbances in Germany and in the Low Countries, iconoclasm and the radicalization of peasants across Europe. If these were the outcomes of reform, he was thankful that he had kept out of it. Yet he was ever more bitterly accused of having started the whole "tragedy" (as the Catholics dubbed Protestantism).
When the city of Basel was definitely and officially "reformed" in 1529, Erasmus gave up his residence there and settled in the imperial town of Freiburg im Breisgau.
Religious toleration.
Certain works of Erasmus laid a foundation for religious toleration. For example, in "De libero arbitrio", opposing certain views of Martin Luther, Erasmus noted that religious disputants should be temperate in their language, "because in this way the truth, which is often lost amidst too much wrangling may be more surely perceived." Gary Remer writes, "Like Cicero, Erasmus concludes that truth is furthered by a more harmonious relationship between interlocutors." Although Erasmus did not oppose the punishment of heretics, in individual cases he generally argued for moderation and against the death penalty. He wrote, "It is better to cure a sick man than to kill him."
Sacraments.
A test of the Reformation was the doctrine of the sacraments, and the crux of this question was the observance of the Eucharist. In 1530, Erasmus published a new edition of the orthodox treatise of Algerus against the heretic Berengar of Tours in the eleventh century. He added a dedication, affirming his belief in the reality of the Body of Christ after consecration in the Eucharist, commonly referred to as transubstantiation. The sacramentarians, headed by Œcolampadius of Basel, were, as Erasmus says, quoting him as holding views similar to their own in order to try to claim him for their schismatic and "erroneous" movement.
Death.
When his strength began to fail, he decided to accept an invitation by Queen Mary of Hungary, Regent of the Netherlands, to move from Freiburg to Brabant. However, during preparations for the move in 1536, he suddenly died from an attack of dysentery during a visit to Basel. He had remained loyal to the papal authorities in Rome, but he did not receive the last rites of the Catholic Church; and whether he asked for a priest or not is nowhere mentioned in the reports of his death. This is consistent with his view that outward signs were not important; what mattered was the believer's direct relationship with God, which he noted "as the [Catholic] church believes". He was buried with great ceremony in the Basel Minster (the former cathedral) there.
His last words, as recorded by his friend Beatus Rhenanus, were apparently "lieve God" (Dutch: "Dear God"). A bronze statue of him was erected in the city of his birth in 1622, replacing an earlier work in stone.
Writings.
Erasmus wrote both on ecclesiastic subjects and those of general human interest. He seems to have regarded the latter as trifling, a leisure activity. By the 1530s, the writings of Erasmus accounted for 10 to 20 percent of all book sales in Europe. He is credited with coining the adage, "In the land of the blind, the one-eyed man is king." With the collaboration of Publio Fausto Andrelini, he formed a Paremiography (collection) of Latin proverbs and adages, commonly titled "Adagia". Erasmus is also generally credited with originating the phrase "Pandora's box", arising through an error in his translation of Hesiod's "Pandora" in which he confused "pithos" (storage jar) with "pyxis" (box).
His more serious writings begin early with the "Enchiridion militis Christiani," the "Handbook of the Christian Soldier" (1503) (translated into English a few years later by the young William Tyndale). (A more literal translation of "enchiridion" - 'dagger' - has been likened to "the spiritual equivalent of the modern Swiss Army knife.") In this short work, Erasmus outlines the views of the normal Christian life, which he was to spend the rest of his days elaborating. The chief evil of the day, he says, is formalism - going through the motions of tradition without understanding their basis in the teachings of Christ. Forms can teach the soul how to worship God, or they may hide or quench the spirit. In his examination of the dangers of formalism, Erasmus discusses monasticism, saint worship, war, the spirit of class and the foibles of "society."
The "Enchiridion" is more like a sermon than a satire. With it Erasmus challenged common assumptions, painting the clergy as educators who should share the treasury of their knowledge with the laity. He emphasized personal spiritual disciplines, and called for a reformation which he characterized as a collective return to the Fathers and Scripture. Most importantly, he extolled the reading of scripture as vital because of its power to transform and motivate toward love. Much like the Brethren of the Common Life, he wrote that the New Testament is the law of Christ people are called to obey and that Christ is the example they are called to imitate.
According to Ernest Barker, "Besides his work on the New Testament, Erasmus laboured also, and even more arduously, on the early Fathers...Among the Latin Fathers he edited the works of St Jerome, St Hilary, and St Augustine; among the Greeks he worked on Irenaeus, Origen and Chrysostom."
Erasmus also wrote of the legendary Frisian freedom fighter and rebel Pier Gerlofs Donia (Greate Pier), though more often in criticism than in praise of his exploits. Erasmus saw him as a dim, brutal man who preferred physical strength to wisdom.
One of Erasmus's best-known works, inspired by "De triumpho stultitiae" (written by Italian humanist Faustino Perisauli), is "The Praise of Folly", published under the double title "Moriae encomium" (Greek, Latinised) and "Laus stultitiae" (Latin). A satirical attack on superstitions and other traditions of European society in general and the western Church in particular, it was written in 1509, published in 1511, and dedicated to Sir Thomas More.
The "Institutio principis Christiani" ("Education of a Christian Prince") (Basel, 1516) was written as advice to the young king Charles of Spain (later Charles V, Holy Roman Emperor). Erasmus applies the general principles of honor and sincerity to the special functions of the Prince, whom he represents throughout as the servant of the people. "Education" was published in 1516, three years after Niccolò Machiavelli’s "The Prince"; a comparison between the two is worth noting. Machiavelli stated that, to maintain control by political force, it is safer for a prince to be feared than loved. Erasmus preferred for the prince to be loved, and strongly suggested a well-rounded education in order to govern justly and benevolently and avoid becoming a source of oppression.
As a result of his reformatory activities, Erasmus found himself at odds with both the great parties. His last years were embittered by controversies with men toward whom he was sympathetic. Notable among these was Ulrich von Hutten, a brilliant but erratic genius, who had thrown himself into the Lutheran cause and declared that Erasmus, if he had a spark of honesty, would do the same. In his reply in 1523, "Spongia adversus aspergines Hutteni", Erasmus displays his skill in semantics. He accuses Hutten of having misinterpreted his utterances about reform and reiterates his determination never to break with the Church.
The "Ciceronianus" came out in 1528, attacking the style of Latin that was based exclusively and fanatically on Cicero's writings. Etienne Dolet wrote a riposte titled "Erasmianus" in 1535.
Erasmus's last major work, published the year of his death, is the "Ecclesiastes" or "Gospel Preacher" (Basel, 1536), in which he comments on the function of preaching.
"Sileni Alcibiadis" (1515).
Erasmus’s "Sileni Alcibiadis" is one of his most direct assessments of the need for Church reform. Johann Froben published it first within a revised edition of the "Adagia" in 1515, then as a stand-alone work in 1517. This essay has been likened to John Colet’s "Convocation Sermon", though the styles differ.
"Sileni" is the plural (Latin) form of "Silenus", a creature often related to the Roman wine god Bacchus and represented in pictorial art as inebriated, merry revellers, variously mounted on donkeys, singing, dancing, playing flutes etc. Alcibiades was a Greek politician in the 5th century BCE and a general in the Peloponnesian War; he figures here more as a character written into some of Plato's dialogues—a young, debauched playboy whom Socrates tries to convince to seek truth instead of pleasure, wisdom instead of pomp and splendor.
The term "Sileni"—especially when juxtaposed with the character of Alcibiades—can therefore be understood as an evocation of the notion that something on the inside is more expressive of a person's character than what one sees on the outside. For instance, something or someone ugly on the outside can be beautiful on the inside, which is one of the main points of Plato's dialogues featuring "Alcibiades" and the "Symposion", in which Alcibiades also appears.
In support of this, Erasmus states, "Anyone who looks closely at the inward nature and essence will find that nobody is further from true wisdom than those people with their grand titles, learned bonnets, splendid sashes and bejeweled rings, who profess to be wisdom’s peak". Erasmus lists several Sileni and then questions whether Christ is the most noticeable Silenus of them all. The Apostles were Sileni since they were ridiculed by others. He believes that the things which are the least ostentatious can be the most significant, and that the Church constitutes all Christian people—that despite contemporary references to clergy as the whole of the Church, they are merely its servants. He criticizes those that spend the Church’s riches at the people’s expense. The true point of the Church is to help people lead Christian lives. Priests are supposed to be pure, yet when they stray away, no one condemns them. He criticizes the riches of the popes, believing that it would be better for the Gospel to be most important.
Legacy.
The popularity of his books is reflected in the number of editions and translations that have appeared since the sixteenth century. Ten columns of the catalogue of the British Library are taken up with the enumeration of the works and their subsequent reprints. The greatest names of the classical and patristic world are among those translated, edited or annotated by Erasmus, including Saint Ambrose, Aristotle, Saint Augustine, Saint Basil, Saint John Chrysostom, Cicero and Saint Jerome.
In his native Rotterdam, the University and Gymnasium Erasmianum have been named in his honor. In 2003, a poll showing that most Rotterdammers believed Erasmus to be the designer of the local "Erasmus Bridge" instigated the founding of the Erasmus House, dedicated to celebrating Erasmus's legacy. Three moments in Erasmus's life are celebrated annually. On 1 April, the city celebrates the publication of his best-known book "The Praise of Folly". On 11 July, the "Night of Erasmus" celebrates the lasting influence of his work. His birthday is celebrated on 28 October.
Erasmus's reputation and the interpretations of his work have varied over time. Following his death, there was a long period of time when his countrymen mourned his death. Moderate Catholics felt that he had been a leading figure in attempts to reform the Church, while Protestants recognized his initial support for Luther's ideas and the groundwork he laid for the future Reformation. By the 1560s, however, there was a marked change in reception.
The Catholic Counter-Reformation movement often condemned Erasmus as having "laid the egg that hatched the Reformation." Their critique of him was based principally on his not being strong enough in his criticism of Luther, not seeing the dangers (from their perspective) of a vernacular Bible and dabbling in dangerous scriptural criticism that weakened the Church's arguments against Arianism and other doctrines. All of his works were placed on the Index of Prohibited Books by Pope Paul IV, and some of his works continued to be banned or viewed with caution in the later Index of Pope Pius IV.
According to Franz Anton Knittel, Erasmus in his "Novum Instrumentum omne" did not incorporate the "Comma" from the "Codex Montfortianus", because of grammar differences, but used "Complutensian Polyglotta". According to him the "Comma" was known to Tertullian.
Protestant views of Erasmus fluctuated depending on region and period, with continual support in his native Netherlands and in cities of the Upper Rhine area. However, following his death and in the late sixteenth century, Reformation supporters saw Erasmus's critiques of Luther and lifelong support for the universal Catholic Church as damning. His reception was particularly cold by the Reformed Protestant groups.
By the coming of the Age of Enlightenment, however, Erasmus increasingly again became a more widely respected cultural symbol and was hailed as an important figure by increasingly broad groups. In a letter to a friend, Erasmus once had written: "That you are patriotic will be praised by many and easily forgiven by everyone; but in my opinion it is wiser to treat men and things as though we held this world the common fatherland of all."
Several schools, faculties and universities in the Netherlands and Belgium are named after him, as is Erasmus Hall in Brooklyn, New York, USA. The European Union's Erasmus Programme scholarships enable students to spend up to a year of their university courses in a university in another European country.

</doc>
<doc id="10153" url="http://en.wikipedia.org/wiki?curid=10153" title="Encyclopedia Brown">
Encyclopedia Brown

 
Encyclopedia Brown is a series of books featuring the adventures of boy detective Leroy Brown, nicknamed "Encyclopedia" for his intelligence and range of knowledge. The series of 29 children's novels was written (one co-written) by Donald J. Sobol, with the first book published in 1963 and the most recent new novel published in 2012—shortly after Sobol's death. The Encyclopedia Brown series has spawned a comic strip, a TV series, compilation books of puzzles and games, and a feature film is in development (2013).
Style.
Each book in the "Encyclopedia Brown" mystery series is self-contained in that the reader is not required to have read earlier books in order to understand the stories. The major characters, settings, etc. are usually introduced (or reintroduced) in each book.
Books featuring Brown are subdivided into a number—usually ten or more—of (possibly interlinked) short stories, each of which presents a mystery. The mysteries are intended to be solved by the reader, thanks to the placement of a logical or factual inconsistency somewhere within the text. This is very similar to the layout of Donald Sobol's other book series, "Two-Minute Mysteries". Brown invariably solves the case by exposing this inconsistency, in the "Answers" section in the back of the book.
Formula.
Often, these books follow a formula wherein the first chapter involves Brown solving a case at the dinner table for his father, the local police chief in the fictional town of Idaville, Maine. When Chief Brown barely tastes his meal, that is a cue he was handed a difficult case. He pulls out his casebook and goes over it with the family. Encyclopedia solves these cases by briefly closing his eyes while he thinks deeply, then asking a single question which directly leads to him finding the solution.
The second mystery often begins in the Brown garage on Rover Avenue, where Encyclopedia has set up his own detective agency to help neighborhood children solve cases for "25 cents per day, plus expenses - No case too small." This second case usually involves the town bully and mischief maker Bugs Meany, leader of a gang who call themselves the Tigers, who, after being foiled, will attempt revenge in the third mystery.
In the third mystery, the plot involves Encyclopedia's partner, close friend, and bodyguard, Sally Kimball, the one person under 12 years of age to physically stand up to Bugs. She is the only reason neither Bugs nor any of his Tigers ever try to physically attack Encyclopedia. Encyclopedia tends to dislike anyone whom Sally has a crush on, possibly indicating that he has a crush on her. Also intelligent, Sally once attempted—in the first book of the series—to prove herself smarter than Encyclopedia by stumping him with a mystery of her own creation. Ironically the contest was held at the Tigers' clubhouse, with Bugs and the others cheering him on. However, she was beaten in the contest (although Encyclopedia admitted that she almost tricked him), after which she became his friend. In subsequent storylines Bugs or his gang usually set up some sort of trap to get Encyclopedia or Sally in trouble. However, as in the previous story, they make a key mistake that Encyclopedia exposes.
Later cases may find Encyclopedia assisting his father at a crime scene (rarely more serious than larceny, and Encyclopedia is always discreet when helping his father) or interacting with people around town, often exposing scams. One such example is a high school dropout and would-be con artist named Wilford Wiggins who spends time trying to dream up schemes to fleece kids out of their money. Like Bugs, his schemes have an inconsistency which Encyclopedia exposes.
In some cases it is Sally and not Encyclopedia who figures it out, because as she tells Encyclopedia: "You are a boy". In other words, she notices things that only a female would find inconsistent. Sally further displays her intelligence in the various mysteries in that she often can deduce who committed the crime, or whether a certain person is lying, but she simply cannot always prove it.
Comic strip.
From December 3, 1978, to September 20, 1980, Encyclopedia Brown was a daily and Sunday comic strip syndicated by Universal Press Syndicate. The artwork was done by Frank Bolle, and Donald J. Sobol was credited as the writer.
Legacy.
The "Encyclopedia Brown" books experienced some enduring popularity.
In 1976, the Mystery Writers of America honored Sobol and his Encyclopedia Brown series with a special Edgar Award.
The books were originally published by Thomas Nelson Inc. and later, by Lodestar Books. They were also published by Scholastic Inc. and Bantam Books through arrangement with those publishers. The current publishing rights are held by Penguin Books. Current editions of the books feature new illustrations in place of the originals by Leonard Shortall, updated to contemporary cultural styles.
Encyclopedia Brown inspired many other crack-the-mystery-yourself mystery stories for younger readers, such as "Einstein" Anderson, and Hawkeye Collins & Amy Adams.
Educators have used Encyclopedia Brown in classrooms to instruct students in skills such as writing reports. In 1986, the Society for Visual Education, Inc. published a filmstrip series, produced and written by Lynne V. Gibbs, with accompanying audio cassette tapes and workbooks for elementary and middle schools' use. The following four Encyclopedia Brown stories were utilized: "The Case of the Missing Statue, The Case of the Happy Nephew, The Case of the Kidnapped Pigs", and "The Case of the Marble Shooter". According to WorldCat's library catalog listing, "As super-sleuth Encyclopedia Brown solves four mysteries, he shows students how he fills out his reports, including selecting a topic, gathering information, taking notes, making an outline, and revising and editing." The "School Library Journal" reviewed this item in its April 1987 issue.
Adaptations.
TV series on HBO.
The "Encyclopedia Brown" television series premiered on HBO in 1989, with 30-minute episodes. Scott Bremner played the title role, with Laura Bridge playing Sally. The live action series ran a little over 10 episodes. It was produced by Howard David Deutsch and directed by Savage Steve Holland. It also included a 60-minute episode ("The Case of the Missing Time Capsule").
Exact episode run information is difficult to track down, but here is at least a partial list of episodes (not necessarily in airdate order), most all of which have been officially released to VHS.
Film.
In June 2013, Warner Bros. adapted the "Encyclopedia Brown" books into a feature film, which is currently in development.
Matthew Johnson, director of "The Dirties" (2013), is currently in talks to write the movie. Roy Lee and Howard David Deutsch (producer of the 1989 "Encyclopedia Brown" TV series) and Jonathan Zakin will be producing.
Books.
The Encyclopedia Brown books, in order of publication (parentheses indicate numbers on original release cover art):
Solve-It-Yourself Mystery Sweepstakes.
From January 15 to June 30, 1989, a special Solve-It-Yourself Mystery Sweepstakes was held in conjunction with the Encyclopedia Brown books and Bantam Books. In the back of specially-marked copies of "Encyclopedia Brown and the Case of the Treasure Hunt", Sobol presented an unsolved mystery for the contestant to solve for himself and submit an answer for a chance to win a prize. The mystery for the contest was called "The Case of the Missing Birthday Gift", wherein Encyclopedia had to solve the case of a stolen bicycle that was given as a birthday gift to Willie Grant on his tenth birthday. The Tigers make an appearance as the suspects in the case; Bugs Meany, Jack Beck, and Rocky Graham all show up at the Tigers' clubhouse.
Contestants were allowed to enter as many times as they wished, provided they used a separate envelope for each entry. The sweepstakes was only available to USA and Canada residents. No purchase was necessary, as one could either use the official form in the back of specially-marked copies of "Encyclopedia Brown and the Case of the Treasure Hunt" or send in a 3" by 5" index card with the solution and the contestant's contact information.
The winners were chosen in a random drawing from all the correct entries submitted. The Grand Prize winner received a BMX bicycle and an autographed copy of "Encyclopedia Brown and the Case of the Treasure Hunt". Second Prize winners (up to 10) received Encyclopedia Brown five-volume boxed sets and an autographed copy of "Encyclopedia Brown and the Case of the Treasure Hunt." Third Prize winners (up to 25) received an autographed copy of "Encyclopedia Brown and the Case of the Treasure Hunt". Additionally, all winners received a certificate of Superb Detective Skills signed by Sobol.

</doc>
<doc id="10158" url="http://en.wikipedia.org/wiki?curid=10158" title="Empire">
Empire

An empire is a geographically extensive group of diverse states and peoples (ethnic groups) united and ruled by a central authority, either by a monarch (emperor, empress) or an oligarchy. The term "empire" is derived from the Latin term "imperium" (a rule, a command; authority, control, power; supreme power, sole dominion; military authority; a dominion, realm), the 'ruling’ of territories that are far beyond the homeland.
Aside from the more formal usage, the term "empire" can also be used to describe a large-scale business enterprise (e.g., a transnational corporation), a political organisation controlled by a single individual (a political boss) or a group (political bosses). The term empire is associated with other words such as imperialism, colonialism, and globalization. Empire is often used to describe a displeasure to overpowering situations. The effects of imperialism exist throughout the world today.
An imperial political structure can be established and maintained in two ways: (i) as a territorial empire of direct conquest and control with force or (ii) as a coercive, hegemonic empire of indirect conquest and control with power. The former method provides greater tribute and direct political control, yet limits further expansion because it absorbs military forces to fixed garrisons. The latter method provides less tribute and indirect control, but avails military forces for further expansion. Territorial empires (e.g., the Mongol Empire and Median Empire) tend to be contiguous areas. The term, on occasion, has been applied to maritime empires or thalassocracies, (e.g., the Athenian and British empires) with looser structures and more scattered territories. Empires are usually larger than kingdoms.
This aspiration to universality resulted in conquest by converting ‘outsiders’ or ‘inferiors’ into the colonialized religion. This association of nationality and race became complex and has had a more intense drive for expansion.
Definition.
An empire is a multi-ethnic or multinational state with political and/or military dominion of populations who are culturally and ethnically distinct from the imperial (ruling) ethnic group and its culture. This is in contrast to a federation, which is an extensive state voluntarily composed of autonomous states and peoples. An empire is a large political party who rules over territories outside of its original borders.
Definitions of what physically and politically constitute an empire vary. It might be a state affecting imperial policies or a particular political structure. Empires are typically formed from diverse ethnic, national, cultural, and religious components. Empire and colonialism are used to refer to relationships between powerful state or society versus a less powerful one.
Tom Nairn and Paul James define empires as polities that: 
extend relations of power across territorial spaces over which they have no prior or given legal sovereignty, and where, in one or more of the domains of economics, politics, and culture, they gain some measure of extensive hegemony over those spaces for the purpose of extracting or accruing value.
Sometimes, an empire is a semantic construction, such as when a ruler assumes the title of "emperor". That ruler's nation logically becomes an "empire", despite having no additional territory or hegemony. Examples of this form of empire are the Central African Empire, or the Korean Empire proclaimed in 1897 when Korea, far from gaining new territory, was on the verge of being annexed by the Empire of Japan, the last to use the name officially. Among the last of the empires in the 20th century were the Central African Empire, Ethiopia, Vietnam, Manchukuo, the German Empire, and Korea.
The terrestrial empire's maritime analogue is the thalassocracy, an empire composed of islands and coasts which are accessible to its terrestrial homeland, such as the Athenian-dominated Delian League.
Furthermore, empires can expand by both land and sea. Stephen Howe notes that empires by land can be characterized by expansion over terrain, “extending directly outwards from the original frontier” while an empire by sea can be characterized by colonial expansion and empire building “by an increasingly powerful navy”.
Characteristics.
Empires originated as different types of states, although they commonly began as powerful monarchies. Ideas about empires changed throughout century varying from approval from the public to becoming universally distasteful. Empires are built out of separate units with some kind of diversity – ethnic, national, cultural, religious – and imply at least some inequality between the rulers and the ruled. Without this inequality, the system would be seen as commonwealth.
Many empires were the result of military conquest, incorporating the vanquished states into a political union, but imperial hegemony can be established in other ways. The Athenian Empire, the Roman Empire, and the British Empire developed at least in part under elective auspices. The Empire of Brazil declared itself an empire after separating from the Portuguese Empire in 1822. France has twice transitioned from being called the French Republic to being called the French Empire, while France remained an overseas empire.
Weaker states may seek annexation into the empire. An example is the bequest of Pergamon to the Roman Empire by Attalus III. The Unification of Germany as the empire accreted to the Prussian metropole was less a military conquest of the German states than their political divorce from the Austrian Empire. Having convinced the other states of its military prowess, and having excluded the Austrians, Prussia dictated the terms of imperial membership.
Politically, it was typical for either a monarchy or an oligarchy, rooted in the original core territory of the empire, to continue to dominate. If governmental authority was maintained by controlling water supplies, vital to colonial subjects, such régimes were called hydraulic empires.
Europeans began applying the designation of "empire" to non-European monarchies, such as the Qing dynasty and the Mughal Empire, as well as the Maratha Empire, eventually leading to the looser denotations applicable to any political structure meeting the criteria of "imperium".
Some empires styled themselves as having greater size, scope, and power than the territorial, politico-military, and economic facts support. As a consequence, some monarchs assumed the title of "emperor" (or its corresponding translation, "tsar", "empereur", "kaiser", etc.) and renamed their states as "The Empire of ..."
Empires were seen as an expanding power, administration, ideas and beliefs followed by cultural habits from place to place. Empires tend to impose their culture on the subject states to strengthen the imperial structure. This can have notable effects that outlast the empire itself, both positive and negative.
History of imperialism.
Early empires.
The Akkadian Empire, established by Sargon the Great (24th century BC), was an early large empire. In the 15th century BC, the New Kingdom of Ancient Egypt, ruled by Thutmose III, was ancient Africa's major force upon incorporating Nubia and the ancient city-states of the Levant. The first empire comparable to Rome in organization was the Neo-Assyrian Empire (916–612 BC). The Median Empire was the first empire within the territory of Persia. By the 6th century BC, after having allied with the Babylonians to defeat the Neo-Assyrian Empire, the Medes were able to establish their own empire, which was the largest of its day and lasted for about sixty years. The successful, extensive, and multi-cultural Achaemenid Empire (550–330 BC), also known as the first Persian Empire, absorbed Mesopotamia, Egypt, parts of Greece, Thrace, the Middle East, much of Central Asia, and Pakistan, until it was overthrown and replaced by the short-lived empire of Alexander the Great.
The Maurya Empire was a geographically extensive and powerful empire in ancient India, ruled by the Mauryan dynasty from 321-185 BC. The empire was founded in 322 BC by Chandragupta Maurya, who rapidly expanded his power westward across central and western India, taking advantage of the disruptions of local powers following the withdrawal by Alexander the Great. By 320 BC, the Maurya Empire had fully occupied northwestern India as well as defeating and conquering the satraps left by Alexander. It has been estimated that the Maurya dynasty controlled an unprecedented one-third of the world's entire economy, was home to one-third of the world's population at the time (an estimated 50 million out of 150 million humans), contained the world's largest city of the time (Pataliputra, estimated to be larger than Rome under Emperor Trajan) and according to Megasthenes, the empire wielded a military of 600,000 infantry, 30,000 cavalry, and 9,000 war elephants.
Classical period.
In western Asia, the term "Persian Empire" denotes the Iranian imperial states established at different historical periods of pre–Islamic and post–Islamic Persia. In East Asia, various Celestial empires arose periodically between periods of war, civil war, and foreign conquests. In India, Chandragupta expanded the Mauryan Empire to Northwest India (modern day Pakistan and Afghanistan). This also included the era of the spread of Buddhism under Ashoka the Great. In China, the Han Empire, one of East Asia's most long-lived dynasties, was preceded by the short-lived Qin Empire. The Kingdom of Macedonia, under Alexander the Great, became an empire that spanned from Greece to Northwestern India. After Alexander's death, his empire separated into four discrete kingdoms ruled by the Diadochi, which, despite being independent, are called the "Hellenistic Empire" by virtue of their similarities in culture and administration. These successor empires were ultimately absorbed into the Roman Empire.
The Romans were the first nation to invent and embody the concept of empire in their two mandates: to wage war and to make and execute laws. They were the most extensive Western empire until the early modern period, and left a lasting impact on Western Europe. Many languages, cultural values, religious institutions, political divisions, urban centers, and legal systems can trace their origins to the Roman Empire. The Roman Empire governed and rested on exploitative actions. They took slaves and money from the peripheries to support the imperial center. However, the absolute reliance on conquered peoples to carry out the empire's fortune, sustain wealth, and fight wars would ultimately lead to the collapse of the Roman Empire. The Romans were strong believers in what they called their "civilizing mission". This term was legitimized and justified by writers like Cicero who wrote that only under Roman rule could the world flourish and prosper. This ideology, that was envisioned to bring a new world order, was eventually spread across the Mediterranean world and beyond. People started to build houses like Romans, eat the same food, wear the same clothes and engage in the same cruel games. Even rights of citizenship and authority to rule were granted to people not of Roman or Italian birth. This authority given to people outside of Roman culture is an example of how its empire collapsed, with a strong dependence on "foreign" rulers.
The Latin word "imperium", referring to a magistrate's power to command, gradually assumed the meaning "The territory in which a magistrate can effectively enforce his commands", while the term "imperator" was originally an honorific meaning "commander". The title was given to generals who were victorious in battle. Thus, an "empire" may include regions that are not legally within the territory of a state, but are under either direct or indirect control of that state, such as a colony, client state, or protectorate. Although historians use the terms "Republican Period" and "Imperial Period" to identify the periods of Roman history before and after absolute power was assumed by Augustus, the Romans themselves continued to refer to their government as a republic, and during the Republican Period, the territories controlled by the republic were referred to as "Imperium Romanum". The emperor's actual legal power derived from holding the office of "consul", but he was traditionally honored with the titles of "imperator" (commander) and "princeps" (first man or, chief). Later, these terms came to have legal significance in their own right; an army calling their general "imperator" was a direct challenge to the authority of the current emperor.
The legal systems of France and its former colonies are strongly influenced by Roman law. Similarly, the United States was founded on a model inspired by the Roman Republic, with upper and lower legislative assemblies, and executive power vested in a single individual, the president. The president, as "commander-in-chief" of the armed forces, reflects the ancient Roman titles "imperator princeps". The Roman Catholic Church, founded in the early Imperial Period, spread across Europe, first by the activities of Christian evangelists, and later by official imperial promulgation.
Post-classical period.
The 7th century saw the emergence of the Islamic Empire, also referred to as the Arab Empire. The Rashidun Caliphate expanded from the Arabian Peninsula and swiftly conquered the Persian Empire and much of the Byzantine Roman Empire. Its successor state, the Umayyad Caliphate, expanded across North Africa and into the Iberian Peninsula. By the beginning of the 8th century, the Umayyad Caliphate had become the largest empire in history, it would not be surpassed in size until the establishment of the Mongol Empire in the 13th century. In the 7th century, Maritime Southeast Asia witnessed the rise of a Buddhist thallasocracy, the Srivijaya Empire, which thrived for 600 years and was succeeded by the Hindu-Buddhist Majapahit Empire that ruled from the 13th to 15th centuries. In the Southeast Asian mainland, the Hindu-Buddhist Khmer Empire was centered in the city of Angkor and flourished from the 9th to 13th centuries. Following the demise of the Khmer Empire, the Siamese Empire flourished alongside the Burmese and Lan Chang Empires from the 13th through the 18th centuries. In Eastern Europe, during the year of 917, the Byzantine Empire was forced to recognize the Imperial title of Bulgarian rulers (who were called Tsars). The Bulgarian Empire remained a major power in the Balkans until its fall in the late 14th century.
At the time, in the Medieval West, the title "empire" had a specific technical meaning that was exclusively applied to states that considered themselves the heirs and successors of the Roman Empire. Among these were the Byzantine Empire, which was the actual continuation of the Eastern Roman Empire, the Carolingian Empire, the largely Germanic Holy Roman Empire, and the Russian Empire. Yet, these states did not always fit the geographic, political, or military profiles of empires in the modern sense of the word. To legitimise their "imperium", these states directly claimed the title of "Empire" from Rome. The "sacrum Romanum imperium" (Holy Roman Empire), which lasted from 800 to 1806, claimed to have exclusively comprehended Christian principalities, and was only nominally a discrete imperial state. The Holy Roman Empire was not always centrally-governed, as it had neither core nor peripheral territories, and was not governed by a central, politico-military elite. Hence, Voltaire's remark that the Holy Roman Empire "was neither holy, nor Roman, nor an empire" is accurate to the degree that it ignores German rule over Italian, French, Provençal, Polish, Flemish, Dutch, and Bohemian populations, and the efforts of the ninth-century Holy Roman Emperors (i.e., the Ottonians) to establish central control. Voltaire's "... nor an empire" observation applies to its late period.
In 1204, after the Fourth Crusade conquered Constantinople, the crusaders established a Latin Empire (1204–1261) in that city, while the defeated Byzantine Empire's descendants established two smaller, short-lived empires in Asia Minor: the Empire of Nicaea (1204–1261) and the Empire of Trebizond (1204–1461). Constantinople was retaken in 1261 by the Byzantine successor state centered in Nicaea, re-establishing the Byzantine Empire until 1453, by which time the Turkish-Muslim Ottoman Empire (ca. 1300–1918), had conquered most of the region. The Ottoman Empire was a successor of the Abbasid Empire and it was the most powerful empire to succeed the Abbasi empires at the time, as well as one of the most powerful empires in the world. The Ottoman Empire centered on modern day Turkey, dominated the eastern Mediterranean, overthrew the Byzantine Empire to claim Constantinople and it would start battering at Austria and Malta, which were countries that were key to central and to south-west Europe respectivelymainly for their geographical location. The reason these occurrences of batterings were so important was because the Ottomans were Muslim and the rest of Europe was Christian so there was a sense of religious fighting going on. This was not just a rivalry of East and West but a rivalry between Christians and Muslims. Both the Christians and Muslims had alliances with other countries and they had problems in them as well. The flows of trade and of cultural influences across the supposed great divide never ceased so the countries never stopped bartering with each other. These epochal clashes between civilizations profoundly shaped many people's thinking back then and continues to do so in the present day. Modern hatred against Muslim communities in South-Eastern Europe, mainly in Bosnia and Kosovo, has often been articulated in terms of seeing them as unwelcome residues of this imperialism: in short, as Turks. Moreover, Eastern Orthodox imperialism was not re-established until the coronation of Peter the Great as Emperor of Russia in 1721. Likewise, with the collapse of the Holy Roman Empire in 1806 during the Napoleonic Wars (1803–1815), the Austrian Empire (1804–1867) emerged reconstituted as the Empire of Austria–Hungary (1867–1918), having "inherited" the imperium of Central and Western Europe from the losers of said wars.
In the thirteenth century, Genghis Khan expanded the Mongol Empire to be the largest contiguous empire in the world. Genghis Khan's grandson, Kublai Khan, was proclaimed emperor, and established his imperial capital at Beijing. However, during his reign, the empire separated into four discrete khanates. Nevertheless, the emergence of the Pax Mongolica had significantly eased trade and commerce across Asia.
In Oceania, the Tonga Empire was a lonely empire that existed from the Medieval to the Modern period.
Colonial empires.
In the 15th century, European landings in the so-called "New World" (first, the Americas, and later Australia), along with Portuguese travels around the Cape of Good Hope and along the coast of Africa bordering the southeast Indian Ocean, proved ripe opportunities for the continent's Renaissance-era monarchies to establish colonial empires like those of the ancient Romans and Greeks. In the Old World, colonial imperialism was attempted and established on the Canary Islands and Ireland. These conquered lands and people became "de jure" subordinates of the empire, rather than "de facto" imperial territories and subjects. Such subjugation often elicited "client-state" resentment that the empire unwisely ignored, leading to the collapse of the European colonial imperial system in the late 19th century and the early and mid-20th century. Spanish discovery of the New World gave way to many expeditions led by England, Portugal, France, the Dutch Republic, and Spain. In the 18th century, the Spanish Empire was at its height because of the great mass of goods taken from conquered territory in the Americas (Mexico, parts of the United States, the Caribbean, most of Central America, and South America) and the Philippines.
Modern period.
The French emperors Napoleon I and Napoleon III (See: Premier Empire, Second French Empire, and French colonial empire) each attempted establishing a western imperial hegemony centered in France. The German Empire (1871–1918), another "heir to the Holy Roman Empire", arose in 1871.
The Ashanti Empire (or Confederacy), also Asanteman (1701–1896), was a West African state of the Ashanti, the Akan people of the Ashanti Region, Akanland in modern day Ghana. The Ashanti (or Asante) were a powerful, militaristic and highly disciplined people in West Africa. Their military power, which came from effective strategy and an early adoption of European firearms, created an empire that stretched from central Akanland (in modern-day Ghana) to present day Benin and Côte d'Ivoire, bordered by the Dagomba kingdom to the north and Dahomey to the east. Due to the empire's military prowess, sophisticated hierarchy, social stratification and culture, the Ashanti empire had one of the largest historiographies of any indigenous Sub-Saharan African political entity.
The Sikh Empire (1799–1846) was established in the Punjab region of India. The empire collapsed when its founder, Ranjit Singh, died and its army fell to the British. During the same period, the Maratha Empire (also known as the Maratha Confederacy) was a Hindu state located in present-day India. It existed from 1674 to 1818, and at its peak, the empire's territories covered much of Southern Asia. The empire was founded and consolidated by Shivaji. After the death of Mughal Emperor Aurangzeb, it expanded greatly under the rule of the Peshwas. In 1761, the Maratha army lost the Third Battle of Panipat, which halted the expansion of the empire. Later, the empire was divided into a confederacy of states which, in 1818, were lost to the British during the Anglo-Maratha wars.
The British established their first empire (1583–1783) in North America by colonising lands that made up British America, including parts of Canada and the Thirteen Colonies. In 1776, the Continental Congress of the Thirteen Colonies declared itself independent from the British Empire, thus beginning the American Revolution. Britain turned towards Asia, the Pacific, and later Africa, with subsequent exploration leading to the rise of the Second British Empire (1783–1815), which was followed by the Industrial Revolution and Britain's Imperial Century (1815–1914).
Transition from empire.
In time, an empire may change from one political entity to another. To wit, the Holy Roman Empire, a German re-constitution of the Roman Empire, metamorphosed into various political structures (i.e., federalism), and eventually, under Habsburg rule, re-constituted itself as the Austrian Empire, an empire of much different politics and vaster extension.
An autocratic empire can become a republic (e.g., the Central African Empire in 1979), or it can become a republic with its imperial dominions reduced to a core territory (e.g., Weimar Germany (1918–1919) and the Ottoman Empire (1918–1923)). The dissolution of the Austro–Hungarian Empire after 1918 is an example of a multi-ethnic superstate broken into its constituent states: the republics, kingdoms, and provinces of Austria, Hungary, Transylvania, Croatia, Slovenia, Bosnia and Herzegovina, Czechoslovakia, Ruthenia, Galicia, "et al".
After the Second World War (1939–1945), the process became commonly known as decolonisation. The British Empire evolved into a loose, multinational Commonwealth of Nations, while the French colonial empire metamorphosed to a Francophone commonwealth. The French territory of Kwang-Chou-Wan was given back to China in 1946. The British gave Hong Kong back to China in 1997 after 150 years of rule. The Portuguese territory of Macau was given back to China in 1999. Macau and Hong Kong were not incorporated into the provincial structure of China; they have an autonomous system of government as Special Administrative Regions of the People's Republic of China.
France still governs colonies (French Guyana, Martinique, Réunion, French Polynesia, New Caledonia, St Martin, Saint-Pierre-et-Miquelon, Guadeloupe, TAAF, Wallis and Futuna, Saint Barthélemy, and Mayotte) and exerts hegemony in Francophone Africa (29 francophone countries such as Chad, Rwanda, "et cetera"). Fourteen British Overseas Territories remain under British sovereignty. Sixteen countries of the Commonwealth of Nations share their head of state, Queen Elizabeth II, as Commonwealth realms.
While the notion of "formal empire" may have ended, it is important to note that many of these former colonial populations still continue to face the historical legacy of colonialism. While traditional sovereignty has been granted to these political units, one must not forget the economic, political and cultural entanglements that continue to affect these subject populations. Therefore, discursive practices of Empire are still present in countries today.
Contemporary usage.
Contemporaneously, the concept of "empire" is politically valid, yet is not always used in the traditional sense. For example, Japan is considered the world's sole remaining empire because of the continued presence of the Japanese Emperor in national politics. Despite the semantic reference to imperial power, Japan is a de jure constitutional monarchy, with a homogeneous population of 127 million people that is 98.5 percent ethnic Japanese, making it one of the largest nation-states.
Characterizing some aspects of American foreign policy and international behavior as "American Empire" is controversial but not uncommon. Stuart Creighton Miller posits that the public's sense of innocence about Realpolitik (cf. American Exceptionalism) impairs popular recognition of US imperial conduct since it governed other countries via surrogates. These surrogates were domestically-weak, right-wing governments that would collapse without US support. Former President G.W. Bush's Secretary of Defense, Donald Rumsfeld, said: "We don't seek empires. We're not imperialistic; we never have been." This statement directly contradicts Thomas Jefferson who, in the 1780s while awaiting the fall of the Spanish empire, said: "...till our population can be sufficiently advanced to gain it from them piece by piece". In turn, historian Sidney Lens argues that from its inception, the US has used every means available to dominate other nations.
Since the European Union began in 1993 as a west European trade bloc, it has established its own currency, the Euro (1999), established discrete military forces, and exercised its limited hegemony in parts of eastern Europe and Asia. The political scientist suggests that this behaviour is imperial because it coerces its neighbouring countries into adopting its "European" economic, legal, and political structures.
In his book review of "Empire" (2000) by Michael Hardt and Antonio Negri, Mehmet Akif Okur posits that since the 11 September 2001 terrorist attacks in the US, the international relations determining the world's balance of power (political, economic, military) have been altered. These alterations include the intellectual (political science) trends that perceive the contemporary world's order via the re-territorrialisation of "political space", the re-emergence of "classical imperialist practices" (the "inside" vs. "outside" duality, cf. the Other), the deliberate weakening of international organisations, the restructured international economy, economic nationalism, the expanded arming of most countries, the proliferation of nuclear weapon capabilities and the politics of identity emphasizing a state's "subjective" perception of its place in the world, as a nation and as a civilisation. These changes constitute the "Age of Nation Empires"; as imperial usage, "nation-empire" denotes the return of geopolitical power from "global" power blocs to "regional" power blocs (i.e., centred upon a "regional power" state [China, Russia, U.S., "et al".]) and regional multi-state power alliances (i.e., Europe, Latin America, South East Asia). Nation-empire regionalism claims sovereignty over their respective (regional) political (social, economic, ideologic), cultural, and military spheres.
Timeline of empires.
The chart below shows a timeline of polities that have been called empires. Dynastic changes are marked with a white line.

</doc>
<doc id="10160" url="http://en.wikipedia.org/wiki?curid=10160" title="Final Solution">
Final Solution

The Final Solution (German: "(die) Endlösung", ]) or Final Solution to the Jewish Question (German: "die Endlösung der Judenfrage", ]) was Nazi Germany's plan during World War II to systematically exterminate the Jewish population in Nazi-occupied Europe through genocide. This policy was formulated in procedural terms at the Wannsee Conference in January 1942, and culminated in the Shoah or Holocaust which saw the killing of two thirds of the Jewish population of Europe.
In his account, "The Origins of the Final Solution: The Evolution of Nazi Jewish Policy: September 1939 – March 1942", Christopher Browning describes the Final Solution as "a program aimed at murdering every last Jew in the German grasp". Declaring that no area of Holocaust studies has been studied and debated as intensively as the nature and timing of the decisions that led to the Final Solution, Browning writes: "Most historians agree there is no 'big bang' theory for the origins of the Final Solution, predicated on a single decision made at a single moment in time. It is generally accepted the decision-making process was prolonged and incremental." Raul Hilberg has stated that in the first phase of the Final Solution, in the occupied USSR, the killers moved to the victims; in the second phase, across Europe, the victims were brought to the killers.
Background.
The "Final Solution" was the Nazis' euphemistic term for their plan to annihilate the Jewish people. Historians, including Mark Roseman, have shown that the usual tendency of the Nazi leadership when discussing the Final Solution was to be extremely guarded. Euphemisms were "their normal mode of communicating about murder".
From gaining power in January 1933 until the outbreak of war in September 1939, the chief focus of the Nazi persecution of the Jews was on intimidation, expropriating their money and property, and encouraging them to emigrate. After the Anschluss with Austria in 1938, special facilities were established in Vienna and Berlin to "facilitate" Jewish emigration. The aim was not to hold Jews in readiness for later annihilation.
The outbreak of war and the invasion of Poland brought a population of three million Polish Jews under the control of the Nazi security forces, and marked the start of a far more savage persecution, including mass killings. Jews were forced into ghettos pending other solutions. After the invasion of the Soviet Union, in June 1941 the Nazi government began to conceive of a plan to exterminate the Jews of Europe. Reichsführer-SS Heinrich Himmler was the chief architect of the plan, which came to be called the Final Solution to the Jewish Question. On July 31, 1941, Reichsmarschall Hermann Göring wrote to Reinhard Heydrich, who was Himmler's deputy and the chief of the RHSA, instructing Heydrich to submit plans "for the implementation of the projected final solution of the Jewish question (Endlösung der Judenfrage)".
Raul Hilberg writes that, broadly speaking, the annihilation phase was accomplished in two major operations. With the invasion of the USSR in June 1941, mobile killing units of the SS and the police were dispatched to Soviet territory where they were to kill all Jewish inhabitants. In the second operation, the Jewish population of central, western, south-eastern Europe were transported to camps with gassing facilities. Hilberg writes, "In essence, the killers of the occupied USSR moved to the victims, whereas outside this arena, the victims were brought to the killers." Massacres of about one million Jews occurred before plans for the Final Solution were fully implemented in 1942, but it was only with the decision to annihilate the entire Jewish population that extermination camps such as Auschwitz and Treblinka were constructed with gas chambers to kill large numbers of Jews in a relatively short period of time.
The decision to systematically kill the Jews of Europe "irrespective of geographic borders", including Jews in Vichy France and French North Africa, had been made by the time of the Wannsee Conference, which took place at the Wannsee Villa in Berlin, on January 20, 1942. The conference was chaired by Heydrich, and attended by 15 senior officials of the Nazi Party and the German government. Most of those attending were senior representatives of ministries with responsibilities for the "Jewish question"—the Interior Ministry, the Foreign Ministry, the Justice Ministry, and Ministers for the Eastern Territories. The purpose of the conference was to discuss and co-ordinate plans outlined by Heydrich as how best to implement the "Final Solution of the Jewish Question". A surviving copy of the minutes of this meeting was found by the Allies in March 1947; it was too late to serve as evidence during the first Nuremberg Trial but was used by prosecutor Brigadier General Telford Taylor in the subsequent Nuremberg Trials.
From July 1942, Operation Reinhard, the mass murder of Polish Jews, initiated the systematic extermination of the Jews. Heinrich Himmler's speeches at the Posen Conference on October 6, 1943, in which he discussed why the Nazi leadership found it necessary to kill Jewish women and children as well as men, clearly explained to the assembled leaders of the Third Reich that the Nazi state policy was "the extermination of the Jewish people".
At the end of the war, captured German documents provided a clear record of the Final Solution policies and actions of Nazi Germany. The Wannsee Conference Protocol, which documented the co-operation of various German state agencies in the SS-led Holocaust, and the Einsatzgruppen Reports, which documented the progress of the mobile killing units assigned, among other tasks, to kill Jewish civilians during the invasion of the Soviet Union in 1941, were central to the evidence which documented the mechanism of the Holocaust, and were submitted at Nuremberg.
Hitler exterminated the Jews of Europe. But he did not do so alone. The task was so enormous, complex, time-consuming, and mentally and economically demanding that it took the best efforts of millions of Germans... All spheres of life in Germany actively participated: Businessmen, policemen, bankers, doctors, lawyers, soldiers, railroad and factory workers, chemists, pharmacists, foremen, production managers, economists, manufacturers, jewelers, diplomats, civil servants, propagandists, film makers and film stars, professors, teachers, politicians, mayors, party members, construction experts, art dealers, architects, landlords, janitors, truck drivers, clerks, industrialists, scientists, generals, and even shopkeepers—all were essential cogs in the machinery that accomplished the final solution.
”
—Konnilyn G. Feig
Historiographic debate about the decision.
Historians disagree as to precisely when Hitler personally (1) decided that the European Jews should be killed and (2) gave orders to that effect. The issue is commonly described as functionalism versus intentionalism: was the Holocaust gradually improvised, or was it the execution of a plan laid in advance?
Prior to the beginning of World War II, during a speech given on January 30, 1939 (the sixth anniversary of his accession to power), Hitler foretold the coming Holocaust of the Jews of Europe when he said:
Today I will once more be a prophet: If the international Jewish financiers in and outside Europe should succeed in plunging the nations once more into a world war, then the result will not be the Bolshevization of the earth, and thus the victory of Jewry, but the annihilation of the Jewish race in Europe!
Raul Hilberg, in his book "The Destruction of the European Jews", was the first historian to systematically document and analyse the Nazi project to kill every Jew in Europe. The book was initially published in 1961, and issued in an enlarged version in 1985.
Hilberg's analysis of the steps that led to the destruction of European Jews states that it was "an administrative process carried out by bureaucrats in a network of offices spanning a continent". Hilberg divides this bureaucracy into four components or hierarchies: the Nazi Party, the civil service, industry, and the Wehrmacht or armed forces—but their cooperation is viewed as "so complete that we may truly speak of their fusion into a machinery of destruction". For Hilberg, the key stages in the destruction process were: definition and registration of the Jews; expropriation of property; concentration into ghettoes and camps; and, finally, annihilation. Hilberg gives an estimate of 5.1 million as the total number of Jews killed. He breaks this figure down into three categories: Ghettoization and general privation: over 800,000; open-air shootings: over 1,300,000; extermination camps: up to 3,000,000.
With respect to the "functionalism versus intentionalism" debate, Hilberg posits what has been described as "a kind of structural determinism". Hilberg argues "a destruction process has an inherent pattern" and the "sequence of steps in a destruction process is thus determined". If a bureaucracy is motivated "to inflict maximum damage upon a group of people", it is "inevitable that a bureaucracy—no matter how decentralized its apparatus or how unplanned its activities—should push its victims through these stages", culminating in their annihilation.
In his detailed account, "The Origins Of The Final Solution: The Evolution of Nazi Jewish Policy, September 1939 – March 1942", published in 2004, Christopher Browning argues that Nazi policy towards the Jews was radicalized twice: in September 1939, when the invasion of Poland implied policies of mass expulsion and massive loss of Jewish life; and in spring 1941, when preparation for Operation Barbarossa involved the planning of mass execution, mass expulsion and starvation—to dwarf what had happened in Jewish Poland.
Browning believes that the "Final Solution as it is now understood—the systematic attempt to murder every last Jew within the German grasp" took shape during a five week period, 18 September to 25 October 1941. During this time: the sites of the first extermination camps were selected, different methods of killing were tested, Jewish emigration from the Third Reich was forbidden, and 11 transports departed for Łódź as a temporary holding station. During this period, Browning writes, "The vision of the Final Solution had crystallised in the minds of the Nazi leadership and was being turned into reality." This period was the peak of Nazi victories against the Soviet Army on the Eastern Front, and, according to Browning, the stunning series of German victories led to both an expectation that the war would soon be won, and the planning of the final destruction of the Jewish-Bolshevik enemy.
Browning describes the creation of the extermination camps, which were responsible for the largest number of deaths in the Final Solution, as bringing together three separate developments within the Third Reich: the concentration camps which had been established in Germany since 1933; an expansion of the gassing technology of the Nazi euthanasia programme to provide killing mechanism of greater efficiency and psychological detachment; and the creation of "factories of death" to be fed endless streams of victims by mass uprooting and deportation that utilized the experience and personnel from earlier population resettlement programmes—especially the HSSPF and Adolf Eichmann’s RSHA for "Jewish affairs and evacuations".
Peter Longerich argues that the search for a finite date on which the Nazis embarked upon the extermination of the Jews is futile, in his book "Holocaust: The Nazi Persecution and Murder of the Jews" (2011). Longerich writes: “We should abandon the notion that it is historically meaningful to try to filter the wealth of available historical material and pick out a single decision” that led to the Holocaust.
Timothy Snyder writes that Longerich "grants the significance of Greiser’s murder of Jews by gas at Chełmno in December 1941", but also detects a significant moment of escalation in spring 1942, which includes "the construction of the large death factory at Treblinka for the destruction of the Warsaw Jews, and the addition of a gas chamber to the concentration camp at Auschwitz for the murder of the Jews of Silesia". Longerich suggests that it "was only in the summer of 1942, that mass killing was finally understood as the realization of the Final Solution, rather than as an extensively violent preliminary to some later program of slave labor and deportation to the lands of a conquered USSR". For Longerich, to see mass killing as the Final Solution was an acknowledgement by the Nazi leadership that there would not be a German military victory over the USSR in the near future.
A different time frame had been proposed by Christian Gerlach, who argued in 1997 that the Final Solution decision was made by Hitler on December 12, 1941, when he addressed a meeting of the Nazi Party (the "Reichsleiter") and of regional party leaders (the "Gauleiter"). In his diary entry of December 13, 1941, the day after Hitler’s private speech, Joseph Goebbels wrote:
Regarding the Jewish Question, the "Führer" is determined to clear the table. He warned the Jews that if they were to cause another world war, it would lead to their own destruction. Those were not empty words. Now the world war has come. The destruction of the Jews must be its necessary consequence. We cannot be sentimental about it. It is not for us to feel sympathy for the Jews. We should have sympathy rather with our own German people. If the German people have to sacrifice 160,000 victims in yet another campaign in the east, then those responsible for this bloody conflict will have to pay for it with their lives.
Goebbels echoed his above statements, and combined them with the January 30, 1939 speech by Hitler, in an article which Goebbels wrote in 1943, entitled "The War and the Jews":
None of the "Führer"'s prophetic words has come so inevitably true as his prediction that if Jewry succeeded in provoking a second world war, the result would be not the destruction of the Aryan race, but rather the wiping out of the Jewish race. This process is of vast importance, and will have unforeseeable consequences that will require time. But it can no longer be halted. It must only be guided in the right direction.
After this decision, plans were made to put the Final Solution into effect. For example, on December 16, 1941, at a meeting of the officials of the General Government, Hans Frank referred to Hitler's speech as he described the coming annihilation of the Jews:
As for the Jews, well, I can tell you quite frankly that one way or another we have to put an end to them. The "Führer" once put it this way: if the combined forces of Judaism should again succeed in unleashing a world war, that would mean the end of the Jews in Europe... At present I am involved in discussions aimed at having them moved away to the east. In January there is going to be an important meeting in Berlin to discuss this question... It is scheduled to take place in the offices of the RSHA in the presence of "Obergruppenführer" Heydrich. Whatever its outcome, a great Jewish emigration will commence. But what is going to happen to these Jews? Do you imagine there will be settlement villages for them in the Ostland? In Berlin we were told: Why are you making all this trouble for us? There is nothing we can do with them here in the Ostland or in the Reich Commissariat. Liquidate them yourselves!
Journalist Ron Rosenbaum, in his book "Explaining Hitler: The Search for the Origins of His Evil", found that the phrase "final solution" had been used much earlier. An investigative report by the "Münchener Post", a socialist newspaper that was an early opponent of Hitler, found as early as 1931 Nazi Party and SA documents using the phrase as part of a description of plans for what became the Nuremberg Laws and a suggestion that "for the final solution of the Jewish question it is proposed to use the Jews in Germany for slave labor or for cultivation of the German swamps administered by a special SS division".
By 1943 the extermination of European Jewry was taking place. The necessity of murdering women and children was explicitly addressed by Heinrich Himmler in two speeches made to the Nazi Party leadership at Posen on October 4, 1943:
In front of you here, I want to refer explicitly to a very serious matter...I mean here...the annihilation of the Jewish people... Most of you will know what it means when 100 corpses lie side by side, or 500 or 1,000... This page of glory in our history has never been written and will never be written... We had the moral right, we were obligated to our people to kill this people which wanted to kill us.
And on October 6, 1943:
I ask of you that that which I say to you in this circle be really only heard and not ever discussed. We were faced with the question: what about the women and children? – I decided to find a clear solution to this problem too. I did not consider myself justified to exterminate the men – in other words, to kill them or have them killed and allow the avengers of our sons and grandsons in the form of their children to grow up. The difficult decision had to be made to have this people disappear from the earth. For the organisation which had to execute this task, it was the most difficult which we had ever had. [...] I felt obliged to you, as the most superior dignitary, as the most superior dignitary of the party, this political order, this political instrument of the Führer, to also speak about this question quite openly and to say how it has been. The Jewish question in the countries that we occupy will be solved by the end of this year. Only remainders of odd Jews that managed to find hiding places will be left over.
Prelude to the Final Solution: Operation Barbarossa.
Preparations for Operation Barbarossa, the Nazi invasion of the Soviet Union which commenced on June 22, 1941, set in motion a murderous "war of destruction" which quickly opened the door to the mass murder of first Soviet and then European Jews. For Hitler, Bolshevism was merely "the most recent and most nefarious manifestation of the eternal Jewish threat". On March 3, 1941, Wehrmacht Joint Operations Staff Chief Alfred Jodl quoted Hitler's comment that the forthcoming war would be a confrontation between two world views, and Hitler's declaration that the "Jewish-Bolshevik intelligentsia would have to be eliminated". In May 1941, Gestapo leader Heinrich Müller wrote, "The troops will encounter an especially dangerous element from the civilian population, the carriers of the Jewish-Bolshevik worldview."
Himmler assembled a force of about 3000 men as "special commandos of the security forces", known as Einsatzgruppen, to "exterminate" the intelligentsia of Stalin's state. These forces were supported by 21 battalions of Order Police under Kurt Daluege, adding up to 11,000 men.
The explicit orders given to the Order Police varied, but in Police Battalion 309, Major Weiss explained to his officers that this would be a war against Jews and Bolshevism, and that his battalions would proceed ruthlessly against the Jews.
In the first five weeks of Operation Barbarossa, argues Browning, what had been regarded as morally questionable became a normal way of operating in "the east". The crucial taboo against the killing of women and children was breached in Gargždai and Bialystok in late June 1941. By July, significant numbers of women and children were being killed by Germans, Ukrainians and Lithuanians. The largest single massacre of Jewish women and children before the end of September 1941 took place in the ravine of Babi Yar near Kiev when more than 33,000 Jews were killed. By mid-October 1941, HSSPF South under the command of Friedrich Jeckeln had reported the killing of more than 100,000 people, including women and children.
By the end of 1941, before the Wannsee Conference, between 600,000 and 800,000 Jewish people had been murdered and entire regions were reported "free of Jews". By this time, awareness of the Final Solution policy in the east was spreading. Addressing his district governors in the General Government on December 16,1941, Governor-General Hans Frank said, "But what will happen to the Jews? Do you believe they will be lodged in settlements in Ostland? In Berlin, we were told: why all this trouble; we cannot use them in the Ostland or the Reichskommissariat either; liquidate them yourselves!"
Holocaust in Lithuania.
Several scholars have noted that the Final Solution and the Holocaust in Lithuania began after the German invasion. Dina Porat wrote: "The Final Solution – the systematic overall physical extermination of Jewish communities one after the other – began in Lithuania." Konrad Kweit wrote: "Lithuanian Jews were among the first victims of the Holocaust [...] The Germans carried out the mass executions [...] signaling the beginning of the "Final Solution"."
Holocaust in General Government (GG) Galicia.
Dr. Samuel Drix ("Witness to Annihilation"), Jochaim Schoenfeld ("Holocaust Memoirs"), and several survivors of the Janowska Camp, who were interviewed in the film, "Janovska: The Janovska Camp at Lvov", among other witnesses, have argued equally as convincingly that the Final Solution began in Lwów (Lemberg) during that same week. Statements and memoirs of these survivors emphasize that, when Ukrainian civilians and "ad hoc" or auxiliary militias began to murder women and children rather than only male Jews, the "Final Solution" was begun. Witnesses have said that such murders happened both prior to and during the pogroms associated with the "Prison Massacre". The question of whether there was some coordination between the Lithuanian and Ukrainian militias remains (i.e. collaborating for a joint assault in Kovno, Wilno, and Lwów). Historians still find it difficult to determine precisely when the first concerted effort at annihilation of all Jews began in the last weeks of June 1941 during Operation "Barbarossa", despite the assertion of Dina Porat that the Lithuanian Jews, rather than the Galician Jews, had the dubious distinction of being the first victims of the Final Solution. "See generally" Jakob Weiss, "The Lemberg Mosaic", (New York: Alderbrook Press, 2011)

</doc>
<doc id="10163" url="http://en.wikipedia.org/wiki?curid=10163" title="Eusebius (disambiguation)">
Eusebius (disambiguation)

Eusebius (AD 263 – 339; also called Eusebius of Caesarea and Eusebius Pamphili) was a Roman historian, exegete and Christian polemicist. 
Eusebius (; Greek Εὐσέβιος "pious" from "eu" (εὖ) "well" and "sebein" (σέβειν) "to respect") may also refer to:
Eusebius is also the name of:

</doc>
<doc id="10164" url="http://en.wikipedia.org/wiki?curid=10164" title="Eurystheus">
Eurystheus

In Greek mythology, Eurystheus (; Greek: Εὐρυσθεύς meaning "broad strength" in folk etymology and pronounced ]) was king of Tiryns, one of three Mycenaean strongholds in the Argolid, although other authors including Homer and Euripides cast him as ruler of Argos: Sthenelus was his father and the "victorious horsewoman" Nicippe his mother, and he was a grandson of the hero Perseus, as was his opponent Heracles. He was married to Antimache, daughter of Amphidamas.
Labors of Heracles.
In the contest of wills between Hera and Zeus over whose candidate would be hero, fated to defeat the remaining creatures representing an old order and bring about the reign of the Twelve Olympians, Eurystheus was Hera's candidate and Heracles – though his name implies that at one archaic stage of myth-making he had carried "Hera's fame" – was the candidate of Zeus. The arena for the actions that would bring about this deep change are the Twelve Labors imposed on Heracles by Eurystheus. The immediate necessity for the Labours of Heracles is as penance for Heracles' murder of his own family, in a fit of madness, which had been sent by Hera; however, further human rather than mythic motivation is supplied by mythographers who note that their respective families had been rivals for the throne of Mycenae. Details of the individual episodes may be found in the article on the Labours of Heracles, but Hera was connected with all of the opponents Heracles had to overcome.
Heracles' human stepfather Amphitryon was also a grandson of Perseus, and since Amphitryon's father (Alcaeus) was older than Eurystheus' father (Sthenelus), he might have received the kingdom, but Sthenelus had banished Amphitryon for accidentally killing (a familiar mytheme) the eldest son in the family (Electryon). When, shortly before his son Heracles was born, Zeus proclaimed the next-born descendant of Perseus should get the kingdom, Hera thwarted his ambitions by delaying Alcmene's labour and having her candidate Eurystheus born prematurely.
Heracles' first task was to slay the Nemean Lion and bring back its skin, which Heracles decided to wear. Eurystheus was so scared by Heracles' fearsome guise that he hid in a subterranean bronze winejar, and from that moment forth all labors were communicated to Heracles through a herald, Copreus.
For his second labour, to slay the Lernaean Hydra, Heracles took with him his nephew, Iolaus, as a charioteer. When Eurystheus found out that Heracles' nephew had helped him he declared that the labour had not been completed alone and as a result did not count towards the ten labours set for him.
Eurystheus' third task did not involve killing a beast, but capturing one alive - the Cerynian Hind, a golden-horned stag sacred to Artemis. Heracles knew that he had to return the hind, as he had promised, to Artemis, so he agreed to hand it over on the condition that Eurystheus himself come out and take it from him. Eurystheus did come out, but the moment Heracles let the hind go, she sprinted back to her mistress, and Heracles departed, saying that Eurystheus had not been quick enough.
When Heracles returned with the Erymanthian Boar, Eurystheus was again frightened and hid in his jar, begging Heracles to get rid of the beast; Heracles obliged.
The fifth labour proposed by Eurystheus was to clear out the numerous stables of Augeias. Striking a deal with Augeias, Heracles proposed a payment of a tenth of Augeias' cattle if the labour was completed successfully. Not believing the task feasible, Augeias agreed, asking his son Phyleus to witness.
Heracles rerouted two nearby rivers (Alpheis and Peneios) through the stable, clearing out the dung rapidly. When Augeias learned of Heracles' bargain for the task, he refused payment. Heracles brought the case to court, and Phyleus testified against his father. Enraged, Augeias banished both Phyleus and Heracles from the land before the court had cast their vote. However, Eurystheus refused to credit the labour to Heracles, as he had performed it for payment. So Heracles went and drove Augeias out of the kingdom and installed Phyleus as king. Heracles then took his tenth of the cattle and left them to graze in a field by his home.
For his sixth labour, Heracles had to drive the Stymphalian Birds off the marshes they plagued. He did so, shooting down several birds with his Hydra-poisoned arrows and bringing them back to Eurystheus as proof.
For his seventh labour, Heracles captured the Cretan Bull. He used a lasso and rode it back to his cousin. Eurystheus offered to sacrifice the bull to Hera his patron, who hated Heracles. She refused the sacrifice because it reflected glory on Heracles. The bull was released and wandered to Marathon, becoming known as the Marathonian Bull.
When Heracles brought back the man-eating Mares of Diomedes successfully, Eurystheus dedicated the horses to Hera and allowed them to roam freely in the Argolid. Bucephalus, Alexander the Great's horse, was said to be descended from these mares.
To acquire the belt of Hippolyte, queen of the Amazons was Heracles ninth task. This task was at the request of Eurystheus' daughter, Admete. For the tenth labour, he stole the cattle of the giant Geryon, which Eurystheus then had sacrificed to Hera.
To extend what may have once been ten Labours to the canonical dozen, it was said that Eurystheus didn't count the Hydra, as he was assisted, nor the Augean stables, as Heracles received payment for his work. For the eleventh labour Heracles had to obtain the Apples of the Hesperides; he convinced their father, the Titan Atlas, to help him, but did his share of work by temporarily holding up the sky in the Titan's stead. For his final labour, he was to capture Cerberus, the three-headed hound that guarded the entrance to Hades. When he managed to bring the struggling animal back, the terrified Eurystheus hid in his jar one more time, begging Heracles to leave for good and take the dog with him.
Death.
After Heracles died, Eurystheus remained bitter over the indignity the hero had caused him. He attempted to destroy Heracles' many children (the Heracleidae, led by Hyllus), who fled to Athens. He attacked the city but was soundly defeated, and Eurystheus and his sons were killed. The stories about the killer of Eurystheus and the fate of his corpse vary, but the Athenians believed the burial site of Eurystheus remained on their soil and served to protect the country against the descendants of Heracles, who traditionally included the Spartans and Argives.
After Eurystheus' death, the brothers Atreus and Thyestes, whom he had left in charge during his absence, took over the city, the former exiling the latter and assuming the kingship, while Tiryns returned to the overlordship of Argos. It is also widely believed that after his death, Eurystheus's head shrivelled to resemble that of a duckling.
Eurystheus in Euripides.
Eurystheus was a character in "Heracleidae", a play by Euripides. Macaria, one of the daughters of Heracles, and her brothers and sisters hid from Eurystheus in Athens, ruled by King Demophon. As Eurystheus prepared to attack, an oracle told Demophon that he would win if and only if a noble woman was sacrificed to Persephone. Macaria volunteered for the sacrifice and a spring was named the Macarian spring in her honor. Eurystheus speaks prophetically of his burial within Attica, claiming that he will be an anti-hero of sorts, though one who will eventually protect the Athenians.

</doc>
<doc id="10165" url="http://en.wikipedia.org/wiki?curid=10165" title="Effects unit">
Effects unit

Effects units are electronic devices that alter how a musical instrument or other audio source sounds. Some effects subtly "color" a sound, while others transform it dramatically. Effects are used during live performances or in the studio, typically with electric guitar, keyboard and bass. While most frequently used with electric or electronic instruments, effects can also be used with acoustic instruments, drums and vocals. Examples of common effects units include wah-wah pedals, fuzzboxes and reverb units.
Effects are housed in amplifiers, table top units, "stompboxes" and "rackmounts", or they are built into the instruments themselves. A stompbox (or "pedal") is a small metal or plastic box placed on the floor in front of the musician and connected to his or her instrument. The box is typically controlled by one or more foot-pedal on-off switches and contains only one or two effects. A rackmount is mounted on a standard 19-inch equipment rack and usually contains several different types of effects.
While there is currently no firm consensus on how to categorize effects, the following are seven common classifications: distortion, dynamics, filter, modulation, pitch/frequency, time-based and feedback/sustain. Guitarists derive their signature sound or "tone" from their choice of instrument, pickups, effects units, and guitar amp.
Formats (form factor).
Effects units are available in a variety of formats or "form factors". Stompbox pedals are usually the smallest, least expensive and most rugged format. Rackmount devices are generally more expensive and offer a wider range of functions. An effects unit can consist of analog or digital circuitry or a combination of the two. During a live performance, the effect is plugged into the electrical "signal" path of the instrument. In the studio, the instrument or other sound-source's auxiliary output is patched into the effect. Form factors are part of a studio or musician's outboard gear.
Stompboxes.
Stompboxes, or effects pedals, are designed to be positioned on the floor or within a pedalboard and operated with the user's feet. The simplest stompbox pedals have a single footswitch; one to three potentiometers for controlling the effect, gain or tone; and a single LED to indicate if the effect is on. Complex stompbox pedals may have multiple footswitches, large numbers of knobs, additional switches, and an alphanumeric display screen that indicates the status of the effect with short acronyms (e.g. DIST for "distortion").
An "effects chain" or "signal chain" may be formed by connecting two or more stompboxes. Effect chains are typically created between the guitar and the amp or between the preamplifier ("preamp") and the power amp. When a pedal is off or inactive, the electric audio signal coming into the pedal is diverted onto a "bypass", resulting in a "dry" signal which continues on to other effects down the chain. In this way, the effects within a chain can be combined in a variety of ways without having to reconnect boxes during a performance. A "controller" or "effects management system" allows for multiple effect chains to be created, so that one or several chains can be engaged or disengaged by tapping a single switch. The switches are usually organized in a row or a simple grid.
To preserve the clarity of the tone, it is most common to put compression, wah and overdrive pedals at the start of the chain; modulation (chorus, flanger, phase shifter) in the middle; and time-based units (delay/echo, reverb) at the end. When using many effects, unwanted noise and hum can be introduced into the sound. Some performers use a noise gate pedal at the end of a chain to reduce unwanted noise and hum introduced by overdrive units or vintage gear.
Rackmounts.
Rackmounted effects are built into a case designed to integrate into a 19-inch rack standard to the telecommunication and computing industries. A rackmount unit may contain electronic circuitry identical to a stompbox's, although its circuits are typically more complex. Unlike stompboxes, rackmounts usually have several different types of effects.
Rackmounts are most commonly used in recording studios and "front of house" live sound mixing situations, though many musicians use them in place of stompboxes. Rackmounts are controlled by knobs or switches on their front panel, and often by a MIDI digital control interface. During live performances, a musician can operate rackmounted effects using a "foot controller".
"Shock mount" racks are designed for musicians who are shipping gear on major tours. Devices that are less than 19 inches wide may use special "ear" adapters that allow them to be mounted on a rack.
Built-in units.
Effects are often incorporated into amplifiers and even some types of instruments. Electric guitar amplifiers typically have built-in reverb and distortion, while acoustic guitar and keyboard amplifiers tend to only have built-in reverb. The Fender Bandmaster Reverb, for example, had built-in reverb and vibrato.
Since the 2000s, guitar amplifiers began having built-in multi-effects units or digital modeling effects. Bass amplifiers are less likely to have built-in effects, although some may have a compressor/limiter or distortion. Instruments with built-in effects include Hammond organs, electronic organs, electronic pianos and digital synthesizers. Occasionally, acoustic-electric and electric guitars will have built-in effects, such as a preamp or equalizer.
Multi-effects and tabletop units.
A multi-effects device (also called a "multi-FX" device) is a single electronics effects pedal or rackmount device that contains many different electronic effects. Multi-FX devices allow users to "preset" combinations of different effects, allowing musicians quick on-stage access to different effects combinations.
A tabletop unit is a type of multi-effects device that sits on a desk and is controlled manually. One such example is the Pod guitar amplifier modeler. Digital effects designed for DJs are often sold in tabletop models, so that the units can be placed alongside a mixer, turntables and CD scratching gear.
History.
Studio effects and early stand alone units.
The earliest sound effects were strictly studio productions. In the mid to late 1940s, recording engineers and experimental musicians such as Les Paul began manipulating reel-to-reel recording tape to create echo effects and unusual, futuristic sounds. Microphone placement ("miking") techniques were used in spaces with specially designed acoustic properties to simulate echo chambers.<br>
<br>In 1948 DeArmond released the Trem-Trol, the first commercially available stand-alone effects unit. This device produced a tremolo by passing an instrument's electrical signal through a water-based electrolytic fluid. Most stand-alone effects of the 1950s and early 60s such as the Gibson GA-VI vibrato unit and the Fender reverb box, were expensive and impractical, requiring bulky transformers and high voltages. The original stand-alone units were not especially in-demand as many effects came built into amplifiers. The first popular stand-alone was the 1958 Watkins Copicat, a relatively portable tape echo effect made famous by the British band, The Shadows.
Amplifiers.
Amplifier built-ins were the first effects to be used regularly outside the studio by guitar players. From the late 1940s onward, the Gibson Guitar Corp. began including vibrato circuits in combo amplifiers. The 1950 Ray Butts EchoSonic amp was the first to feature the "slapback" echo sound, which quickly became popular with guitarists such as Chet Atkins, Carl Perkins, Scotty Moore, Luther Perkins, and Roy Orbison. By the 1950s, tremolo, vibrato and reverb were available as built-in effects on many guitar amplifiers. Both Premier and Gibson built tube-powered amps with spring reverb. Fender began manufacturing the tremolo amps Tremolux in 1955 and Vibrolux in 1956.
Distortion was not an effect originally intended by amplifier manufacturers, but could often easily be achieved by "overdriving" the power supply in early tube amplifiers. In the 1950s, guitarists began deliberately increasing gain beyond its intended levels to achieve "warm" distorted sounds. Among the first musicians to experiment with distortion were Willie Johnson of Howlin' Wolf, Goree Carter, Joe Hill Louis, Ike Turner, Guitar Slim, and Chuck Berry.
In 1954 Pat Hare produced heavily distorted power chords for several recordings (including James Cotton's "), creating "a grittier, nastier, more ferocious electric guitar sound," accomplished by turning the volume knob on his amplifier "all the way to the right until the speaker was screaming." Link Wray's 1958 recording "Rumble" inspired young musicians such as Pete Townshend of The Who, Jimmy Page of Led Zeppelin, Jeff Beck, Dave Davies of The Kinks, and Neil Young to explore distortion. Davies would famously doctor the speakers of his amp by slitting them with a razor blade to achieve a grittier guitar sound on the 1964 song "You Really Got Me". In 1966, the British company Marshall Amplification began producing the Marshall 1963, a guitar amplifier capable of producing the distorted "crunch" that rock musicians were starting to seek.
Stompboxes.
The electronic transistor finally made it possible to cram the aural creativity of the recording studio into small, highly portable stompbox units. Transistors replaced vacuum tubes, allowing for much more compact formats and greater stability. The first transistorized guitar effect was the 1962 Maestro Fuzz Tone pedal, which became a sensation after its use in the 1965 Rolling Stones hit "(I Can't Get No) Satisfaction".
Warwick Electronics manufactured the first wah-wah pedal, The Clyde McCoy, in 1967 and that same year Jim Morris of Kelsey-Morris Sound developed the first octave effect, which Jimi Hendrix named "Octavio." In 1968, Univox began marketing its Uni-Vibe pedal, an effect designed by noted audio engineer Fumio Mieda that mimicked the odd phase shift and chorus effects of the Leslie rotating speakers used in Hammond organs. The pedals soon became favorite effects of guitarists Jimi Hendrix and Robin Trower. Upon first hearing the Octavia, Hendrix allegedly rushed back to the studio and immediately used it to record the guitar solos on "Purple Haze" and "Fire" By the mid-1970s a variety of solid-state effects pedals including flangers, chorus pedals, ring modulators and phase shifters were available.
In the 1980s, digitized rackmount units began replacing stompboxes as the effects format of choice. Often musicians would record "dry", unaltered tracks in the studio and effects would be added in post-production. The success of Nirvana's 1991 album "Nevermind" helped to re-ignite interest in stompboxes. Throughout the 1990s, musicians committed to a "lo-fi" aesthic such as J Mascis of Dinosaur Jr., Stephen Malkmus of Pavement and Robert Pollard of Guided by Voices continued to use analog effects pedals.
Effects and effects units—stompboxes in particular—have been celebrated by pop and rock musicians in album titles, songs and band names. The Big Muff, a classic fuzzbox manufactured by Electro-Harmonix, is commemorated by the Depeche Mode song "Big Muff" and the Mudhoney EP "Superfuzz Bigmuff". Nine Inch Nails, Pink Floyd, George Harrison, They Might Be Giants and Joy Division are among the many musicians who have referenced effects units in their music.
Types.
Temporal vs Dynamic Effects.
Audio effects can generally separated into two categories, dynamic effects that affect the volume of a sound signal, such as distortion, compression and equalization, and temporal effects which affect the time, phase and frequency of the signal, such as reverb, delay, phazer, and pitch shifting/auto-harmony. It is normal (but not required) for dynamic effects to be used as an *Insert* on a channel or group, and temporal effects to be used on an *aux send*.
Distortion.
Distortion effects create "warm", "gritty" and "fuzzy" sounds by "clipping" an instrument's audio signal, which distorts the shape of its wave form and adds overtones. Distortion effects are sometimes called "gain" effects, as distorted guitar sounds were first achieved by increasing the electric power supply, e.g. gain, to tube amplifiers.
Distortion and overdrive: Distortion and overdrive units re-shape or "clip" an audio signal's wave form so that it has flattened peaks, creating "warm" sounds by adding harmonics or "gritty" sounds by adding inharmonic overtones. In tube amplifiers, distortion is created by compressing the instrument's out-going electrical signal in vacuum tubes or "valves". Distortion pedals produce perfectly flattened peaks or “hard” clipping. Overdrive pedals produce "soft” tube-like distortion by compressing the sine wave without completely flattening it. Much like tube amps, overdrive units produce "clean" sounds at quieter volumes and distorted "warm" sounds at louder volumes. Distortion and overdrive pedals may either be transistor-based or digital.<br>
Distortion and overdrive effects: Boss DS-1 Distortion, Ibanez Tube Screamer, Marshall ShredMaster, MXR Distortion +, Pro Co RAT.
Fuzz: A fuzz pedal or "fuzzbox" is a type of overdrive pedal that clips a sound-wave until it is nearly a squarewave, resulting in a heavily distorted or "fuzzy" sound. Fuzzboxes may contain frequency multiplier circuitry to achieve a harsh timbre by adding complex harmonics. The Rolling Stones' "(I Can't Get No) Satisfaction" greatly popularized the use of fuzz effects. Fuzz bass (also called "bass overdrive") is a style of playing the electric bass that produces a buzzy, overdriven sound via a tube or transistor amp or by using a fuzz or overdrive pedal.
<br>
Fuzz effects: Arbiter Fuzz Face, Electro-Harmonix Big Muff, Shin-ei Companion FY-2, Univox Super-Fuzz, Vox Tone Bender, Z.Vex Fuzz Factory.
Dynamics.
Also called volume and amplitude effects, dynamics effects modify the volume of an instrument. Dynamics effects were the first effects to be introduced to guitarists.
Boost/volume pedal: A boost or "clean boost" amplifies the volume of an instrument by increasing the amplitude of its audio signal. These units are generally used for "boosting" volume during solos and preventing signal loss in long "effects chains". A guitarist switching from rhythm guitar to lead guitar may use a boost to increase the volume of his or her solo.<br> Treadle based volume pedals are often also used to create swelling effects by removing the attack of a note or chord, as popularised by pedal steel guitar players. 
Volume effects: Electro-Harmonix LPB-1, Fender Volume Pedal, MXR Micro Amp.
Compressor: Compressors make loud sounds quieter and quiet sounds louder by decreasing or "compressing" the dynamic range of an audio signal. A compressor is often used to stabilize volume and smooth a note's "attack" by dampening its onset and amplifying its sustain. A compressor can also function as a limiter with extreme settings of its controls.<br>
Compressor effects: Keeley Compressor, MXR Dyna Comp.
Noise gate: Noise gates eliminate "hum", "hiss" and "static" by greatly diminishing the volume of sounds that fall below a set threshold. Noise gates are expanders, meaning unlike compressors they increase the dynamic range of an audio signal in order to make quiet sounds even quieter. If used with extreme settings along with reverb, they can create unusual sounds, such as the gated drum effect used in 1980s pop songs, a style popularized by the Phil Collins song "In the Air Tonight".<br>
Noise gate effects: Boss NS-2 Noise Suppressor.
Filter.
Filter effects alter the frequency content of an audio signal that passes through them by either boosting or weakening specific frequencies or frequency regions.
Equalizer: An equalizer is a set of linear filters that strengthen ("boost") or weaken ("cut") specific frequency regions. While home stereos often have equalizers for two bands, to adjust bass and treble, professional graphic equalizers offer much more targeted control over the audio frequency spectrum. Audio engineers use highly sophisticated equalizers to eliminate unwanted sounds, make an instrument or voice more prominent, and enhance particular aspects of an instrument's tone.<br>
Equalizer effects: Boss GE-7 Equalizer, MXR 10-band EQ Pedal.
Talk box: A talk box directs the sound from a guitar or synthesizer into the mouth of a performer, allowing him or her to shape the sound into vowels and consonants. The modified sound is then picked up by a microphone. In this way the guitar is able to "talk". Some famous uses of the talkbox include Bon Jovi's "Livin' on a Prayer", Stevie Wonder's "Black Man", Mötley Crüe's "Kickstart My Heart", Joe Walsh's "Rocky Mountain Way", Alice in Chains's "Man in the box" and Peter Frampton's "Show Me the Way".<br>
Talk boxes: Dunlop HT1 Heil Talk Box, Rocktron Banshee.
Wah-wah: A wah-wah pedal creates vowel-like sounds by altering the frequency spectrum produced by an instrument—i.e., how loud it is at each separate frequency—in what is known as a spectral glide or "sweep".
The device is operated by a foot treadle that opens and closes a potentiometer. Wah-wah pedals are often used by funk and rock guitarists.<br>
Wah effects: Dunlop Cry Baby, Morley Power Wah, Musitronics Mu-Tron III.
Modulation.
Modulation is a control feature rather than a specific architecture wherein one(or more) processing parameters effecting an audio signal is varied over time in order to create sounds with unusual tonal properties. Some modulation effects mix ("modulate") an instrument's audio signal with a signal generated by the effect called a carrier wave. Other modulation effects split an instrument's audio signal in two, altering one portion of the signal and mixing it with the unaltered portion.
Chorus: Chorus pedals mimic the effect choirs and string orchestras produce naturally, by having slight variations in timbre and pitch, by mixing sounds with slight differences in timbre and pitch. A chorus effect splits the instrument-to-amplifier audio signal, and adds a slight delay and frequency variations or "vibrato" to part of the signal while leaving the rest unaltered. A well-known usage of chorus is the lead guitar in "Come As You Are" by Nirvana.<br>
Chorus effects: Boss CE-1 Chorus Ensemble, Electro-Harmonix Small Clone, TC Electronic Stereo Chorus.
Flanger: A flanger creates a "jet plane" or "spaceship" sound, simulating a studio effect produced by recording a track on two synchronized tapes and periodically slowing one tape by pressing the edge of its reel (the "flange"). When the two tapes' audio signals are later mixed, a comb filter effect can be heard. Flanger units add a variably delayed version of the audio signal to the original or signal, creating a comb filter or Doppler effect. Some famous uses of flanger effects include "Walking on the Moon" by The Police, the intro to "Ain't Talkin' 'Bout Love" by Van Halen, and "Barracuda" by Heart.<br>
Flanger effects: Electro-Harmonix Electric Mistress, MXR Flanger.
Phaser: A phaser or "phase shifter" creates a slight rippling effect—amplifying some aspects of the tone while diminishing others—by splitting an audio signal in two and altering the phase of one portion. Three well-known examples of phaser are the two handed tapping part on the Van Halen instrumental Eruption and the keyboard parts on Billy Joel's "Just the Way You Are" and Paul Simon's "Slip Slidin' Away".<br>
Phase shift effects: Electro-Harmonix Small Stone, MXR Phase 90, Univox Uni-Vibe.
Ring modulator: A ring modulator produces a resonant, metallic sound by mixing an instrument's audio signal with a carrier wave generated by the device's internal oscillator. The original sound wave is suppressed and replaced by a "ring" of inharmonic higher and lower pitches or "sidebands". A notable use of ring modulation is the guitar in the Black Sabbath song "Paranoid".<br>
Ring modulator effects: moogerfooger MF-102 Ring Modulator.
Tremolo: A tremolo effect produces a slight, rapid variation in the volume of a note or chord. The "tremolo effect" should not be confused with the misleadingly-named "tremolo bar", a device on a guitar bridge that creates a vibrato or "pitch-bending" effect. In transistorized effects, a tremolo is produced by mixing an instrument's audio signal with a sub-audible carrier wave in such a way that generates amplitude variations in the sound wave.
The guitar intro in the Rolling Stones' "Gimme Shelter" features a tremolo effect.<br>
Tremolo effects: Demeter TRM-1 Tremulator, Fender Tremolux.
Vibrato: Vibrato effects produce slight, rapid variations in pitch, mimicking the fractional semitone variations produced naturally by opera singers and violinists when prolonging a single note. Vibrato effects often allow the performer to control the rate of the variation as well as the difference in pitch (e.g. "depth"). A vibrato with an extreme "depth" setting (e.g., half a semitone or more) will produce a dramatic, ululating sound. In transistorized effects, vibrato is produced by mixing an instrument's audio signal with a carrier wave in such a way that generates frequency variations in the sound wave. Guitarists often use the terms "vibrato" and "tremolo" misleadingly. A so-called "vibrato unit" in a guitar amplifier actually produces tremolo, while a "tremolo arm" or "whammy bar" on a guitar produces vibrato.
Vibrato effects: Boss VB-2 Vibrato.
Pitch/frequency.
Pitch/frequency effects modify pitch by altering the frequency of a sound wave or adding new harmonies.
Pitch shifter and harmonizer: A pitch shifter raises or lowers (e.g. "transposes") each note a performer plays by a pre-set interval. For example, a pitch shifter set to increase the pitch by a fourth will raise each note four diatonic intervals above the notes actually played. Simple pitch shifters raise or lower the pitch by one or two octaves, while more sophisticated devices offer a range of interval alterations.
A harmonizer is a type of pitch shifter that combines the altered pitch with the original pitch to create a two or more note harmony. Some hamonizers are able to create chorus-like effects by adding very tiny shifts in pitch.<br>
Pitch shift effects: DigiTech Whammy, Electro-Harmonix POG.
Time-based.
Time-based effects delay the sound signal or adds echos.
Delay/echo: Delay/echo units produce an echo effect by adding a duplicate instrument-to-amplifier electrical signal to the original signal at a slight time-delay. The effect can either be a single echo called a "slap" or "slapback," or multiple echos. A well-known use of delay is the lead guitar in the U2 song "Where the Streets Have No Name".<br>
Delay effects: Boss DD-3 Digital Delay, Electro-Harmonix Deluxe Memory Man, Line 6 DL4, Roland RE-201.
Looper pedal: A looper pedal or "phrase looper" allows a performer to record and later replay a phrase or passage from a song. Loops can be created on the spot during a performance (live looping) or they can be pre-recorded. Some units allow a performer to layer multiple loops. The first loop effects were created with reel-to-reel tape using a tape loop. High-end boutique tape loop effects are still used by some studios who want a vintage sound. Digital loop effects recreate this effect using an electronic memory.<br>
Looper effects: Boss RC-30 Loop Station.
Reverb: Reverb units simulate sounds produced in a finite acoustic space by creating a large number of echoes that gradually fade or "decay". One early technique for creating a reverb effect was to send an amplified signal of the music to room with reflective surfaces, such as a tile bathroom, and then record the natural reverberations. A plate reverb system uses an electromechanical transducer to create vibrations in a plate of metal. Spring reverb systems, which are often used in guitar amplifiers, use a transducer to create vibrations in a spring. Digital reverb effects use various signal processing algorithms to create the reverb effect, often by using multiple feedback delay circuits. Rockabilly and surf guitar are two genres that make heavy use of reverb.<br>
Reverb effects: Electro-Harmonix Holy Grail, Fender Reverb Unit.
Feedback/sustain.
Audio feedback: Audio feedback is an effect produced when amplified sound is picked up by a microphone and played back through an amplifier, initiating a "feedback loop". Feedback as pioneered by guitarists such as Jimi Hendrix is generated by playing an instrument directly in front of an amplifier set to a high volume. This relatively primitive technique tends to create high-pitched overtones and can be difficult to sustain. It can also be hard to determine the sound volume and guitar position relative to a loudspeaker necessary for achieving feedback conditions.
EBow is a brand name of Heet Sound Products, of Los Angeles, California, for the original type of small handheld resonator, invented by Greg Heet. The resonator uses a pickup - inductive string driver - feedback circuit, including a sensor coil, driver coil, and amplifier, to induce forced string resonance. The Ebow brand resonator is monophonic, and drives only one string at a time; Other handheld guitar and bass resonators on the market, manufactured under the tradename SRG, produced by Aescher Europa, in Germany, are available in both monophonic and polyphonic models, which include multiple onboard trigger switch effects, such as HPF (high pass filter) for enhancing harmonics and producing feedback effects, and LPF (low pass filter), producing a bass boost with a cello sound on heavy gauge strings. Later EBow models, such as the plus Ebow, contain a mode slide switch on the back, which allows the player to either produce just sustain or overtone feedback in addition to sustain.
Many compressor pedals are often also marketed as "sustainer pedals". As a note is sustained, it loses energy and volume due to diminishing vibration in the string. The compressor pedal boosts its electrical signal to the specified dynamic range, slightly prolonging the duration of the note. This, combined with heavy distortion and the close proximity of the guitar and the speaker cabinet, can lead to infinite sustain at higher volumes.
Other effects.
Envelope follower: An envelope follower activates an effect once a designated volume is reached. One effect that uses an envelope follower is the "auto-wah", which produces a "wah" effect depending on how loud or soft the notes are being played.
Guitar amplifier modeling: Amplifier modeling is a digital effect that replicates the sound of various amplifiers, most often analog "tube" amps. Sophisticated modeling effects can simulate speaker cabinets and miking techniques. A rotary speaker simulator mimics the doppler sound of a vintage Leslie speaker system by replicating its volume and pitch modulations, overdrive capacity and phase shifts.
Pitch correction/vocal effects: Pitch correction effects use signal-processing algorithms to re-tune faulty intonation in a vocalist's performance or create unusual vocoder-type vocal effects.
Simulators: Simulators enable electric guitars to mimic the sound of other instruments such as acoustic guitar, electric bass and sitar. Pick up simulators used on guitars with single-coil pick ups replicate the sound of guitars with humbucker pick ups, or vice versa. A de-fretter is a bass guitar effect that simulates the sound of a fretless bass. The effect uses an envelope-controlled filter and voltage-controlled amplifier to "soften" a note's attack both in volume and timbre.
Rotating speakers are specially constructed amplifier/loudspeakers used to create special audio effects using the Doppler effect by rotating the speakers or a sound-directing duct. The rotating speaker creates a chorus-type effect. Named after its inventor, Donald Leslie, it is particularly associated with the Hammond organ but is used with a variety of instruments as well as vocals. The Hammond/Leslie combination has become an element in many genres of music. The Leslie Speaker and the Hammond Organ brands are currently owned by Suzuki Musical Instrument Corporation. The Stompbox version of this effect is the Uni-Vibe pedal.
Bass effects.
Some electronic effects are designed specifically for the electric bass, including fuzz bass, an overdrive or distortion pedal designed for bass, and bass chorus, a chorus effect designed for the electric bass. In both cases, the effects are optimized to work with the low pitch range of the bass.
Boutique pedals.
Boutique pedals are designed by smaller, independent companies and are typically produced in limited quantities. Some may even be hand-made, with hand-soldered connections. These pedals are mainly distributed online or through mail-order, or sold in a few music stores. They are often more expensive than mass-produced pedals and offer non-standard features such as true-bypass switching, higher-quality components, innovative designs, in-house-made knobs and hand-painted artwork or etching. Some boutique companies focus on re-creating classic or vintage effects.<br>Some boutique pedal manufacturers include: Analog Man, BJFE, Pete Cornish, Emlyn Crowther, Death By Audio, Devi Ever, Robert Keeley, Roger Linn, Roger Mayer, Strymon, T-Rex Engineering, ToadWorks and Z.Vex Effects.
Effects unit modification.
There is also a niche market for modifying or "modding" effects. Typically, vendors provide either custom modification services or sell new effects pedals which have been modified. The Ibanez Tube Screamer, Boss DS-1, Pro Co RAT and DigiTech Whammy are some of the most often-modified effects. Common modifications include value changes in capacitors or resistors, adding true-bypass so that the effect's circuitry is no longer in the signal path, substituting higher-quality components, replacing the unit's original operational amplifiers (op-amps), or adding functions to the device, such as allowing additional control of some factor or adding another output jack.
Other pedals and rackmount units.
Not all stompboxes and rackmounted electronic devices designed for musicians are effects. Strobe tuner and regular electronic tuner pedals indicate whether a guitar string is too sharp or flat. A footswitch pedal such as the "A/B" pedal routes a guitar signal to an amplifier or enables a performer to switch between two guitars, or between two amplifiers.
Guitar amplifiers and electronic keyboards may have switch pedals for turning built-in reverb and distortion effects on and off; the pedals contain only a switch, with the circuitry for the effect being housed in the amplifier chassis. Some musicians who use rackmounted effects or laptops employ a MIDI controller pedalboard or armband remote controls to trigger sound samples, switch between different effects or control effect settings.
 A pedal keyboard is a foot-operated keyboard typically used to play bass lines.
See also.
<br>
Technologies

</doc>
<doc id="10166" url="http://en.wikipedia.org/wiki?curid=10166" title="Enron">
Enron

Enron Corporation (former New York Stock Exchange ticker symbol ENE) was an American energy, commodities, and services company based in Houston, Texas. Before its bankruptcy on December 2, 2001, Enron employed approximately 20,000 staff and was one of the world's major electricity, natural gas, communications, and pulp and paper companies, with claimed revenues of nearly $111 billion during 2000. "Fortune" named Enron "America's Most Innovative Company" for six consecutive years.
At the end of 2001, it was revealed that its reported financial condition was sustained substantially by an institutionalized, systematic, and creatively planned accounting fraud, known since as the Enron scandal. Enron has since become a well-known example of willful corporate fraud and corruption. The scandal also brought into question the accounting practices and activities of many corporations in the United States and was a factor in the creation of the Sarbanes–Oxley Act of 2002. The scandal also affected the greater business world by causing the dissolution of the Arthur Andersen accounting firm.
Enron filed for bankruptcy in the Southern District of New York during late 2001 and selected Weil, Gotshal & Manges as its bankruptcy counsel. It ended its bankruptcy during November 2004, pursuant to a court-approved plan of reorganization, after one of the most complex bankruptcy cases in U.S. history. A new board of directors changed the name of Enron to Enron Creditors Recovery Corp., and emphasized reorganizing and liquidating certain operations and assets of the pre-bankruptcy Enron. On September 7, 2006, Enron sold Prisma Energy International Inc., its last remaining business, to Ashmore Energy International Ltd. (now AEI).
Early history.
Enron's predecessor was the Northern Natural Gas Company, which was formed in 1932, in Omaha, Nebraska. It was reorganized in 1979 as the main subsidiary of a holding company, InterNorth which was a diversified energy and energy related products company. InterNorth was a major business for natural gas production, transmission and marketing as well as for natural gas liquids and was an innovator in the plastics industry.
The company initially named itself "HNG/InterNorth Inc.", even though InterNorth was the nominal parent. It built a large and lavish headquarters complex with pink marble in Omaha (dubbed locally as the "Pink Palace"), that was later sold to Physicians Mutual corporation. However, the departure of ex-InterNorth and first CEO of Enron Corp Samuel Segnar six months after the merger allowed former HNG CEO Kenneth Lay to become the next CEO of the newly merged company. Lay soon relocated the company's headquarters to Houston (after promising to keep it in Omaha) and began to change the business. Lay and his secretary, Nancy McNeil, originally selected the name "Enteron" (possibly spelled in "upper camelcase" as "EnterOn"), but, when informed that the term approximated a Greek word referring to the intestines, the name was quickly abbreviated to Enron. The final name was decided upon only after business cards, stationery, and other items had been printed reading "Enteron". Enron's "crooked E" logo was designed during the mid-1990s by the American graphic designer Paul Rand. Rand's original design included one of the elements of the E in yellow which disappeared when copied or faxed. This was quickly replaced by a green element. Almost immediately after the relocation to Houston, Enron began selling major assets such as its chemicals division Northern PetroChemicals, accepted silent partners in Enron CoGeneration, Northern Border Pipeline and Transwestern Pipeline, and became a less diversified company. Early financial analysts said Enron was accumulating great debt and the sale of major operations would not solve the problem.
Misleading financial accounts.
In 1990, Enron's Chief Operating Officer Jeffrey Skilling hired Andrew Fastow, who was well acquainted with the burgeoning deregulated energy market that Skilling wanted to exploit. In 1993, Fastow began establishing numerous limited liability special purpose entities (a common business practice in the energy sector); however, it also allowed Enron to transfer liability so that it would not appear in its accounts, allowing it to maintain a robust and generally increasing stock price and thus keeping its critical investment grade credit ratings.
Enron was originally involved in transmitting and distributing electricity and natural gas throughout the United States. The company developed, built, and operated power plants and pipelines while dealing with rules of law and other infrastructures worldwide. Enron owned a large network of natural gas pipelines, which stretched ocean to ocean and border to border including Northern Natural Gas, Florida Gas Transmission, Transwestern Pipeline company and a partnership in Northern Border Pipeline from Canada. The states of California, New Hampshire and Rhode Island had already passed power deregulation laws by July 1996, the time of Enron's proposal to acquire Portland General Electric corporation. During 1998, Enron began operations in the water sector, creating the Azurix Corporation, which it part-floated on the New York Stock Exchange during June 1999. Azurix failed to become successful in the water utility market, and one of its major concessions, in Buenos Aires, was a large-scale money-loser. After the relocation to Houston, many analysts criticized the Enron management as being greatly in debt. The Enron management pursued aggressive retribution against its critics, setting the pattern for dealing with accountants, lawyers, and the financial media.
Enron grew wealthy due largely to marketing, promoting power, and its high stock price. Enron was named "America's Most Innovative Company" by the magazine "Fortune" for six consecutive years, from 1996 to 2001. It was on the "Fortune"‍ '​s "100 Best Companies to Work for in America" list during 2000, and had offices that were stunning in their opulence. Enron was hailed by many, including labor and the workforce, as an overall great company, praised for its large long-term pensions, benefits for its workers and extremely effective management until the exposure of its corporate fraud. The first analyst to question the company's success story was Daniel Scotto, an energy market expert at BNP Paribas, who issued a note in August 2001 entitled "Enron: All stressed up and no place to go", which encouraged investors to sell Enron stocks, although he only changed his recommendation on the stock from "buy" to "neutral".
As was later discovered, many of Enron's recorded assets and profits were inflated or even wholly fraudulent and nonexistent. One example of fraudulent records was during 1999 when Enron promised to repay Merrill Lynch & Co.'s investment with interest in order to show profit on its books. Debts and losses were put into entities formed "offshore" that were not included in the company's financial statements, and other sophisticated and arcane financial transactions between Enron and related companies were used to eliminate unprofitable entities from the company's books.
Its most valuable asset and the largest source of honest income, the 1930s-era Northern Natural Gas company, was eventually purchased by a group of Omaha investors, who relocated its headquarters back to Omaha; it is now a unit of Warren Buffett's Berkshire Hathaway Energy. NNG was established as collateral for a $2.5 billion capital infusion by Dynegy Corporation when Dynegy was planning to buy Enron. When Dynegy examined Enron's financial records carefully, they repudiated the deal and dismissed their CEO, Chuck Watson. The new chairman and CEO, the late Daniel Dienstbier, had been president of NNG and an Enron executive at one time and was forced out of Enron by Ken Lay. Dienstbier was an acquaintance of Warren Buffett. NNG continues to be profitable now.
Products.
Enron traded in more than 30 different products, including the following:
It was also an extensive futures trader, including sugar, coffee, grains, hogs, and other meat futures. At the time of its bankruptcy filing during December 2001, Enron was structured into seven distinct business units.
Capital and risk management services.
Project development and management services.
Enron manufactured gas valves, circuit breakers, thermostats, and electrical equipment in Venezuela by means of INSELA SA, a 50–50 joint venture with General Electric. Enron owned three paper and pulp products companies: Garden State Paper, a newsprint mill; as well as Papiers Stadacona and St. Aurelie Timberlands. Enron had a controlling stake in the Louisiana-based petroleum exploration and production company Mariner Energy.
Enron International.
Enron International (EI) was Enron's wholesale asset development and asset management business. Its primary emphasis was developing and building natural gas power plants outside North America. Enron Engineering and Construction Company (EECC) was a wholly owned subsidiary of Enron International, and built almost all of Enron International's power plants. Unlike other business units of Enron, Enron International had a strong cash flow on bankruptcy filing. Enron International consisted of all of Enron's foreign power projects, including ones in Europe.
The company's Teesside plant was one of the largest gas-fired power stations in the world, built and operated by Enron from 1989, and produced 3 percent of the United Kingdom's energy needs. Enron owned half of the plant's equity, with the remaining 50 per cent split between four regional electricity companies.
Management.
Rebecca Mark was the CEO of Enron International until she resigned to manage Enron's newly acquired water business, Azurix, during 1997. Mark had a major role in the development of the Dabhol project in India, Enron's largest international endeavor.
Projects.
Enron International constructed power plants and pipelines across the globe. Some are presently still operating, including the massive Teesside plant in England. Others, like a barge-mounted plant off Puerto Plata in the Dominican Republic, cost Enron money by lawsuits and investment losses. Puerto Plata was a barge-mounted power plant next to the hotel "Hotelero del Atlantico". When the plant was activated, winds blew soot from the plant onto the hotel guests' meals, blackening their food. The winds also blew garbage from nearby slums into the plant's water-intake system. For some time the only solution was to hire men who would row out and push the garbage away with their paddles. Through mid-2000 the company collected a paltry $3.5 million from a $95 million investment. Enron also had other investment projects in Europe, South America, Argentina, Brazil, Bolivia, Colombia, Mexico, Jamaica, Venezuela, and across the Caribbean.
India.
Around 1992 Indian experts came to the United States to find energy investors to help with India's energy shortage problems. During December 1993, Enron finalized a 20-year power-purchase contract with the Maharashtra State Electricity Board. The contract allowed Enron to construct a massive 2,015 megawatt power plant on a remote volcanic bluff 100 miles south of Bombay. Construction would be completed in two phases, and Enron would form the Dabhol Power Company to help manage the plant. The power project was the first step in a $20 billion scheme to help rebuild and stabilize India's power grid. Enron, GE (which was selling turbines to the project), and Bechtel (which was actually constructing the plant), each contributed 10% equity.
During 1996, when India's Congress Party was no longer in power, the Indian government assessed the project as being excessively expensive and refused to pay for the plant and stopped construction. The Maharashtra State Electricity Board (MSEB), the local state-owned utility, was required by contract to continue to pay Enron plant maintenance charges, even if no power was purchased from the plant. The MSEB determined that it could not afford to purchase the power (at Rs. 8 per unit kWh) charged by Enron. The plant operator was unable to find alternate customers for Dabhol power due to the absence of a free market in the regulated structure of utilities in India. From 1996 until Enron's bankruptcy during 2001 the company tried to revive the project and revive interest in India's need for the power plant without success.
Project Summer.
During the summer of 2001, Enron made an attempt to sell a number of Enron International's assets, many of which were not sold. The public and media believed it was unknown why Enron wanted to sell these assets, suspecting it was because Enron was in need of cash.
Employees who worked with company assets were told in 2000 that Jeff Skilling believed that business assets were an outdated means of company worth, and instead he wanted to build a company based on "intellectual assets".
Enron Global Exploration & Production, Inc..
Enron Global Exploration & Production Inc. (EGEP) was an Enron subsidiary that was born from the split of domestic assets via EOG Resources (formerly Enron Oil and Gas EOG) and international assets via EGEP (formerly Enron Oil and Gas Int'l, Ltd EOGIL). 
Among the EGEP assets were the Panna-Mukta and the South Tapti fields, discovered by the Indian state-owned Oil and Natural Gas Corporation (ONGC), which operated the fields initially.
December 1994, a joint venture began between ONGC (40%), Enron (30%) and Reliance (30%).
Mid year of 2002, British Gas (BG) completed the acquisition of EGEP's 30% share of the Panna-Mukta and Tapti fields for $350 million, a few months before Enron filed bankruptcy.
EnronOnline.
Enron opened EnronOnline, an electronic trading platform for energy commodities, on November 29, 1999. Conceptualized by the company's European Gas Trading team, it was the first web-based transaction system that allowed buyers and sellers to buy, sell, and trade commodity products globally. It allowed users to do business only with Enron. The site allowed Enron to transact with participants in the global energy markets. The main commodities offered on EnronOnline were natural gas and electricity, although there were 500 other products including credit derivatives, bankruptcy swaps, pulp, gas, plastics, paper, steel, metals, freight, and TV commercial time. At its maximum, more than $6 billion worth of commodities were transacted by means of EnronOnline every day.
After Enron's bankruptcy in late 2001, EnronOnline was sold to the Swiss financial giant UBS. Within a year, UBS abandoned its efforts to relaunch the division, and closed it in November 2002.
Principal assets.
At the time of bankruptcy, Enron owned interests in the following major assets:
Power plants.
Enron owned or operated 38 electric power plants worldwide:
Development.
Enron also developed the Gaza Power Plant which became active during 2002.
Enron Prize for Distinguished Public Service.
During the mid-1990s, Enron established an endowment for the Enron Prize for Distinguished Public Service, awarded by Rice University's Baker Institute to "recognize outstanding individuals for their contributions to public service". Recipients were:
Greenspan, because of his position as the Fed chairman, was not at liberty to accept the $10,000 honorarium, the $15,000 sculpture, nor the crystal trophy, but only accepted the "honor" of being named an Enron Prize recipient. The situation was further complicated because a few days earlier, Enron had filed paperwork admitting it had falsified financial statements for five years. Greenspan did not mention Enron a single time during his speech. At the ceremony, Ken Lay stated, "I'm looking forward to our first woman recipient." The next morning, it was reported in The Houston Chronicle that no decision had been made on whether the name of the prize would be changed. 19 days after the prize was awarded to Greenspan, Enron declared bankruptcy.
During early 2002, Enron was awarded Harvard's (in)famous Ig Nobel Prize for 'Most Creative Use of Imaginary Numbers.' The various former members of Enron management all refused to accept the award in person, although no reason was given at the time.
2001 Accounting scandals.
During 2001, after a series of revelations involving irregular accounting procedures bordering on fraud perpetrated throughout the 1990s involving Enron and its accounting company Arthur Andersen, Enron suffered the largest Chapter 11 bankruptcy in history (since surpassed by those of Worldcom during 2002 and Lehman Brothers during 2008).
As the scandal progressed, Enron share prices decreased from US $90.56 during the summer of 2000, to just pennies. Enron had been considered a blue chip stock investment, so this was an unprecedented event in the financial world. Enron's demise occurred after the revelation that much of its profits and revenue were the result of deals with special purpose entities (limited partnerships which it controlled). This meant that many of Enron's debts and the losses that it suffered were not reported in its financial statements.
A rescue attempt by a similar, smaller energy company, Dynegy, failed during late November due to concerns about an unexpected restatement of earnings. Enron filed for bankruptcy on December 2, 2001. In addition, the scandal caused the dissolution of Arthur Andersen, which at the time was one of the world's main accounting companies. The company was found guilty of obstruction of justice during 2002 for destroying documents related to the Enron audit. Since the SEC is not allowed to accept audits from convicted felons, Andersen was forced to stop auditing public companies. Although the conviction was dismissed during 2005 by the Supreme Court, the damage to the Andersen name has prevented it from reviving as a viable business even on a limited scale.
Enron also withdrew a naming-rights deal with the Houston Astros Major League Baseball club to have its name associated with their new stadium, which was known formerly as Enron Field (now Minute Maid Park).
Accounting practices.
Enron used a variety of deceptive, bewildering, and fraudulent accounting practices and tactics to cover their fraud in reporting Enron's financial information. These entities made Enron seem more profitable than it actually was, and created a dangerous spiral in which, each quarter, corporate officers would have to perform more and more financial deception to create the illusion of billions of dollars in profit while the company was actually losing money. This practice increased their stock price to new levels, at which point the executives began to work on insider information and trade millions of dollars' worth of Enron stock. The executives and insiders at Enron knew about the offshore accounts that were hiding losses for the company; however, the investors knew nothing of this. Chief Financial Officer Andrew Fastow directed the team which created the off-books companies, and manipulated the deals to provide himself, his family, and his friends with hundreds of millions of dollars in guaranteed revenue, at the expense of the corporation for which he worked and its stockholders.
During 1999, Enron initiated EnronOnline, an Internet-based trading operation, which was used by virtually every energy company in the United States. Enron president and chief operating officer Jeffrey Skilling began advocating a novel idea: the company didn't really need any "assets". By promoting the company's aggressive investment strategy, he helped make Enron the biggest wholesaler of gas and electricity, trading over $27 billion per quarter. The corporation's financial claims, however, had to be accepted at face value. Under Skilling, Enron adopted mark to market accounting, in which anticipated future profits from any deal were tabulated as if currently real. Thus, Enron could record gains from what over time might turn out to be losses, as the company's fiscal health became secondary to manipulating its stock price on Wall Street during the so-called "Tech boom". But when a company's success is measured by undocumented financial statements, actual balance sheets are inconvenient. Indeed, Enron's unscrupulous actions were often gambles to keep the deception going and so increase the stock price. An advancing price meant a continued infusion of investor capital on which debt-ridden Enron in large part subsisted (much like a financial "pyramid" or "Ponzi scheme"). Attempting to maintain the illusion, Skilling verbally attacked Wall Street Analyst Richard Grubman, who questioned Enron's unusual accounting practice during a recorded conference telephone call. When Grubman complained that Enron was the only company that could not release a balance sheet along with its earnings statements, Skilling replied "Well, thank you very much, we appreciate that . . . asshole." Though the comment was met with dismay and astonishment by press and public, it became an inside joke among many Enron employees, mocking Grubman for his perceived meddling rather than Skilling's offensiveness. When asked during his trial, Skilling declared that industrial dominance and abuse was a global problem: "Oh yes, yes sure, it is."
Peak and decline of stock price.
During August 2000, Enron's stock price attained its greatest value of $90.56 At this time Enron executives, who possessed inside information on the hidden losses, began to sell their stock. At the same time, the general public and Enron's investors were told to buy the stock. Executives told the investors that the stock would continue to increase until it attained possibly the $130 to $140 range, while secretly unloading their shares.
As executives sold their shares, the price began to decrease. Investors were told to continue buying stock or hold steady if they already owned Enron because the stock price would rebound during the near future. Kenneth Lay's strategy for responding to Enron's continuing problems was his demeanor. As he did many times, Lay would issue a statement or make an appearance to calm investors and assure them that Enron was doing well. In February 2001 an article by Bethany McLean appeared in "Fortune" magazine questioning whether Enron stock was overvalued.
By August 15, 2001, Enron's stock price had decreased to $42. Many of the investors still trusted Lay and believed that Enron would rule the market. They continued to buy or retain their stock as the equity value decreased. As October ended, the stock had decreased to $15. Many considered this a great opportunity to buy Enron stock because of what Lay had been telling them in the media.
Lay was accused of selling more than $70 million worth of stock at this time, which he used to repay cash advances on lines of credit. He sold another $20 million worth of stock in the open market. Also, Lay's wife, Linda, was accused of selling 500,000 shares of Enron stock totaling $1.2 million on November 28, 2001. The money earned from this sale did not go to the family but rather to charitable organizations, which had already received pledges of contributions from the foundation. Records show that Mrs. Lay made the sale order sometime between 10:00 and 10:20 am. News of Enron's problems, including the millions of dollars in losses they hid, became public about 10:30 that morning, and the stock price soon decreased to less than one dollar.
Former Enron executive Paula Rieker was charged with criminal insider trading. Rieker obtained 18,380 Enron shares for $15.51 a share. She sold that stock for $49.77 a share during July 2001, a week before the public was told what she already knew about the $102 million loss.
Post-bankruptcy.
Enron initially planned to retain its three domestic pipeline companies as well as most of its overseas assets. However, before emerging from bankruptcy, Enron sold its domestic pipeline companies as CrossCountry Energy for $2.45 billion and later sold other assets to Vulcan Capital Management.
Enron sold its last business, Prisma Energy, during 2006, leaving Enron asset-less. During early 2007, its name was changed to Enron Creditors Recovery Corporation. Its goal is to repay the old Enron's remaining creditors and end Enron's affairs.
Azurix, the former water utility part of the company, remains under Enron ownership, although it is currently asset-less. It is involved in several litigations against the government of Argentina claiming compensation relating to the negligence and corruption of the local governance during its management of the Buenos Aires water concession during 1999, which resulted in substantial amounts of debt (approx. $620 million) and the eventual collapse of the branch.
Soon after emerging from bankruptcy during November 2004, Enron's new board of directors sued 11 financial institutions for helping Lay, Fastow, Skilling and others hide Enron's true financial condition. The proceedings were dubbed the "megaclaims litigation". Among the defendants were Royal Bank of Scotland, Deutsche Bank and Citigroup. s of 2008[ [update]], Enron has settled with all of the institutions, ending with Citigroup. Enron was able to obtain nearly $20 billion to distribute to its creditors as a result of the megaclaims litigation. As of December 2009, some claim and process payments were still being distributed.
California's deregulation and subsequent energy crisis.
During October 2000, Daniel Scotto, the most renowned utility analyst on Wall Street, suspended his ratings on all energy companies conducting business in California because of the possibility that the companies would not receive full and adequate compensation for the deferred energy accounts used as the basis for the California Deregulation Plan enacted during the late 1990s. Five months later, Pacific Gas & Electric (PG&E) was forced into bankruptcy. Senator Phil Gramm, the second largest recipient of campaign contributions from Enron, succeeded in legislating California's energy commodity trading deregulation. Despite warnings from prominent consumer groups which stated that this law would give energy traders too much influence over energy commodity prices, the legislation was passed during December 2000.
As the periodical Public Citizen reported, "Because of Enron's new, unregulated power auction, the company's 'Wholesale Services' revenues quadrupled—- from $12 billion in the first quarter of 2000 to $48.4 billion in the first quarter of 2001."
Before passage of the deregulation law, there had been only one Stage 3 rolling blackout declared. After passage, California had a total of 38 blackouts defined as Stage 3 rolling blackouts, until federal regulators intervened during June 2001. These blackouts occurred mainly as a result of a poorly designed market system that was manipulated by traders and marketers. Enron traders were revealed as intentionally encouraging the removal of power from the market during California's energy crisis by encouraging suppliers to shut down plants to perform unnecessary maintenance, as documented in recordings made at the time. These acts contributed to the need for rolling blackouts, which adversely affected many businesses dependent upon a reliable supply of electricity, and inconvenienced a large number of retail consumers. This scattered supply increased the price exponentially, and Enron traders were thus able to sell power at premium prices, sometimes up to a factor of 20x its normal peak value.

</doc>
<doc id="10168" url="http://en.wikipedia.org/wiki?curid=10168" title="Eusebius of Alexandria">
Eusebius of Alexandria

Eusebius of Alexandria is an author to whom certain extant homilies are attributed.
Biography.
Nothing is known of the author. In all events, he was not a patriarch of Alexandria, as is affirmed in an early biography, written by one Johannes, a notary, and stating that Eusebius was called by Cyril to be his successor in the episcopate.
There has been much dispute regarding the details of his life and the age in which he lived. Galland (Vet. Patr. Biblioth., VIII, 23) says: "de Eusebio qui vulgo dicitur episcopus Alexandræ incerta omnia" (Concerning Eusebius, commonly called bishop of Alexandria there is nothing sure). His writings have been attributed to Eusebius of Emesa, Eusebius of Cæsarea, and others. According to an old biography said to have been written by his notary, the monk John, and discovered by Cardinal Mai, he lived in the fifth century and led a monastic life near Alexandria. The fame of his virtues attracted the attention of Cyril, Bishop of Alexandria, who visited him with his clergy, and in 444, when dying, had him elected his successor, and consecrated him bishop, though much against his will. Eusebius displayed great zeal in the exercise of his office and did much good by his preaching. Among those he converted was a certain Alexander, a man of senatorial rank. After having ruled his see for seven or, according to another account, for twenty years, he made Alexander his successor and retired to the desert, whence Cyril had summoned him and there died in the odor of sanctity.
While Mai seems to have established the existence of a Eusebius of Alexandria who lived in the fifth century, it had been objected than neither the name of Eusebius or his successor Alexander, appears in the list of the occupants of that ancient see. Dioscurus is mentioned as the immediate successor of Cyril. Nor does the style of the homilies seem on the whole in keeping with the age of Cyril. It may be noted, however, that the biographer of Eusebius expressly states that the Cyril in question is the great opponent of Nestorius. Various solution of the difficulty have been proposed. Thilo thinks that the authorship of the homilies is to be assigned either to a certain monk – one of four brothers 3 of the fifth century, or to a presbyter and court chaplain of Justinian I, who took an active part in the theological strifes of the sixth century. Mai suggests that after the death of Cyril, there were two bishops at Alexandria, Dioscurus, the Monophysite leader, and Eusebius, the head of the Catholic party. The homilies cover a variety of subjects, and the author is one of the earliest patristic witnesses to the doctrine regarding the descent of Christ into Hell. A list of homilies with the complete text is given by Mai. They may also be found in Migne, which was published with an introduction by Rand in "Modern Philology", II, 261.
Works.
These homilies enjoyed some renown in the Eastern Church in the sixth and seventh centuries.
The discourses belong probably to the fifth or sixth century, and possibly originated in Alexandria. They deal with the life of Jesus of Nazareth and with questions of ecclesiastical life and practise, which they resolve in a monastic-ascetic way. Their literary character is not quite clear; while most of them are adapted for public delivery, not a few bear the character of ecclesiastical pronouncements. They are now in print except four included among John Chrysostom's works. The fragments preserved in the so-called "Sacra parallela" are to be found in Karl Holl's "Fragmente vornicänischer Kirchenväter." A homily concerning the observance of Sunday is attributed by Zahn to Eusebius of Emesa.

</doc>
<doc id="10169" url="http://en.wikipedia.org/wiki?curid=10169" title="Eusebius of Angers">
Eusebius of Angers

Eusebius (Bruno) of Angers (died September 1, 1081) was bishop of Angers, France.
He first appears in the historical record as bishop of Angers at the synod of Rheims in 1049, and for a long time had been an adherent of Berengar's doctrine of the Lord's Supper. As such he was regarded by Berengar himself and by his opponents Dietwin of Liege (Theodwin), Durand of Troarne, and Humbert of Mourmoutiers. But when he recognized the strength of the opposition, he favored a compromise; at any rate he advised Berengar is 1054 to swear to the formula presented to him.
Nevertheless Berengar considered him his friend many years later and requested him to silence a certain Galfrid Martini or to arrange a disputation. In his reply Eusebius not only regretted the whole controversy, but also stated that he would abide by the words of the Bible, according to which the bread and wine after the consecration become the body and blood of the Lord (see transubstantiation); if one asks how this can take place, the answer must be that it is not according to the order of nature but in accordance with the divine omnipotence; at any rate one must be careful not to give offense to the plain Christian. The epistle is a downright renunciation of Berengar in case he should still maintain his view.
In favor of the supposition that Eusebius changed his opinion from deference to the Count of Anjou, the decided opponent of Berengar and his doctrine, it can be adduced that he did not defend Berengar against the hostilities of the court, and that for a long time he sided with this violent prince. It is also possible that the fact impressed itself upon Eusebius that the religious consciousness of the time more and more opposed Berengar. Our knowledge, however, is too fragmentary to pass a very accurate sentence.

</doc>
<doc id="10172" url="http://en.wikipedia.org/wiki?curid=10172" title="Eusebius">
Eusebius

Eusebius of Caesarea (; Greek: Εὐσέβιος, "Eusébios"; AD 260/265 – 339/340), also known as Eusebius Pamphili, was a Roman historian, exegete, and Christian polemicist of Greek descent. He became the bishop of Caesarea about 314. Together with Pamphilus, he was a scholar of the Biblical canon and is regarded as an extremely well learned Christian of his time. He wrote "Demonstrations of the Gospel", "Preparations for the Gospel", and "On Discrepancies between the Gospels", studies of the Biblical text. As "Father of Church History" he produced the "Ecclesiastical History", "On the Life of Pamphilus", the "Chronicle" and "On the Martyrs".
Sources.
Little is known about the life of Eusebius. His successor at the see of Caesarea, Acacius, wrote a "Life of Eusebius", a work that has since been lost. Eusebius' own surviving works probably only represent a small portion of his total output. Beyond notices in his extant writings, the major sources are the 5th-century ecclesiastical historians Socrates, Sozomen, and Theodoret, and the 4th-century Christian author Jerome. There are assorted notices of his activities in the writings of his contemporaries Athanasius, Arius, Eusebius of Nicomedia, and Alexander of Alexandria. Eusebius' pupil, Eusebius of Emesa, provides some incidental information.
Early life.
In his "Ecclesiastical History", Eusebius writes of Dionysius of Alexandria as his contemporary. If this is true, Eusebius' birth must have been before Dionysius' death in autumn 264; most modern scholars date the birth to some point in the five years between 260 and 265. He was presumably born in the town in which he lived for most of his adult life, Caesarea Maritima. He was baptized and instructed in the city, and lived in Palestine in 296, when Diocletian's army passed through the region (in the "Life of Constantine", Eusebius recalls seeing Constantine traveling with the army). Eusebius was made presbyter by Agapius of Caesarea. Some, like theologian and ecclesiastical historian John Henry Newman, understand Eusebius' statement that he had heard Dorotheus of Tyre "expound the Scriptures wisely in the Church" to indicate that Eusebius was Dorotheus' pupil while the priest was resident in Antioch; others, like the scholar D. S. Wallace-Hadrill, deem the phrase too ambiguous to support the contention.
By the 3rd century, Caesarea had a population of about 100,000. It had been a pagan city since Pompey had given control of the city to the gentiles during his command of the eastern provinces in the 60s BC. The gentiles retained control of the city in the three centuries since that date, despite Jewish petitions for joint governorship. Gentile government was strengthened by the city's refoundation under Herod the Great (r. 37–4 BC), when it had taken on the name of Augustus Caesar. In addition to the gentile settlers, Caesarea had large Jewish and Samaritan minorities. Eusebius was probably born into the Christian contingent of the city. Caesarea's Christian community presumably had a history reaching back to apostolic times, but it is a common claim that no bishops are attested for the town before about 190, even though the Apostolic Constitutions 7.46 states that Zacchaeus was the first bishop.
Through the activities of the theologian Origen (185/6–254) and the school of his follower Pamphilus (later 3rd century – 309), Caesarea became a center of Christian learning. Origen was largely responsible for the collection of usage information regarding the texts which became the New Testament. The information used to create the late-fourth-century Easter Letter, which declared accepted Christian writings, was probably based on the Ecclesiastical History [HE] of Eusebius of Caesarea, wherein he uses the information passed on to him by Origen to create both his list at HE 3:25 and Origen's list at HE 6:25. Eusebius got his information about what texts were accepted by the third-century churches throughout the known world, a great deal of which Origen knew of firsthand from his extensive travels, from the library and writings of Origen. On his deathbed, Origen had made a bequest of his private library to the Christian community in the city. Together with the books of his patron Ambrosius, Origen's library (including the original manuscripts of his works) formed the core of the collection that Pamphilus established. Pamphilus also managed a school that was similar to (or perhaps a re-establishment of) that of Origen. Pamphilus was compared to Demetrius of Phalerum and Pisistratus, for he had gathered Bibles "from all parts of the world". Like his model Origen, Pamphilus maintained close contact with his students. Eusebius, in his history of the persecutions, alludes to the fact that many of the Caesarean martyrs lived together, presumably under Pamphilus.
Soon after Pamphilus settled in Caesarea ("ca". 280s), he began teaching Eusebius, who was then somewhere between twenty and twenty-five. Because of his close relationship with his schoolmaster, Eusebius was sometimes called "Eusebius Pamphili": "Eusebius, son of Pamphilus". The name may also indicate that Eusebius was made Pamphilus' heir. Pamphilus gave Eusebius a strong admiration for the thought of Origen. Neither Pamphilus nor Eusebius knew Origen personally; Pamphilus probably picked up Origenist ideas during his studies under Pierius (nicknamed "Origen Junior") in Alexandria. In Caesarea, Origenist thought was continued in the generation after his death by Theotecnus, bishop of the city for much of the late 3rd century and an alumnus of Origen's school.
Eusebius' "Preparation for the Gospel" bears witness to the literary tastes of Origen: Eusebius quotes no comedy, tragedy, or lyric poetry, but makes reference to all the works of Plato and to an extensive range of later philosophic works, largely from Middle Platonists from Philo to the late 2nd century. Whatever its secular contents, the primary aim of Origen and Pamphilus' school was to promote sacred learning. The library's biblical and theological contents were more impressive: Origen's Hexapla and Tetrapla, a copy of the original Hebrew Version of the Gospel of Matthew, and many of Origen's own writings. Marginal comments in extant manuscripts note that Pamphilus and his friends and pupils, including Eusebius, corrected and revised much of the biblical text in their library. Their efforts made the hexaplaric Septuagint text increasingly popular in Syria and Palestine. Soon after joining Pamphilus' school, Eusebius started helping his master expand the library's collections and broaden access to its resources. At about this time Eusebius compiled a "Collection of Ancient Martyrdoms", presumably for use as a general reference tool.
In the 290s, Eusebius began work on his "magnum opus", the "Ecclesiastical History", a narrative history of the Church and Christian community from the Apostolic Age to Eusebius' own time. At about the same time, Eusebius worked on his "Chronicle", a universal calendar of events from Creation to Eusebius' own time. Eusebius completed the first editions of the "Ecclesiastical History" and "Chronicle" before 300.
Bishop of Caesarea.
Eusebius succeeded Agapius as Bishop of Caesarea soon after 313 and played a prominent role at the Council of Nicaea in 325. Eusebius, a learned man and famous author, enjoyed the favour of the Emperor Constantine. Because of this he was called upon to present the creed of his own church to the 318 attendees." However, the anti-Arian creed from Palestine prevailed becoming the basis for the Nicene Creed.
The theological views of Arius, that taught the subordination of the Son to the Father, continued to be a problem. Eustathius of Antioch strongly opposed the growing influence of Origen's theology as the root of Arianism. Eusebius, an admirer of Origen, was reproached by Eustathius for deviating from the Nicene faith. Eusebius prevailed and Eustathius was deposed at a synod in Antioch.
However, Athanasius of Alexandria became a more powerful opponent and in 334, he was summoned before a synod in Caesarea (which he refused to attend). In the following year, he was again summoned before a synod in Tyre at which Eusebius of Caesarea presided. Athanasius, foreseeing the result, went to Constantinople to bring his cause before the Emperor. Constantine called the bishops to his court, among them Eusebius. Athanasius was condemned and exiled at the end of 335. Eusebius remained in the Emperor's favour throughout this time and more than once was exonerated with the explicit approval of the Emperor Constantine. After the Emperor's death (c.337), Eusebius wrote the , an important historical work because of eye witness accounts and the use of primary sources. Eusebius died c.339.
Death.
Much like his birth, the exact date of Eusebius’ death is unknown. However, there is primary text evidence from a council held in Antioch that by the year 341, his successor Acacius had already filled the seat as Bishop. Socrates and Sozomen write about Eusebius’ death, and place it just before Constantine’s son (Constantine II or Constantine the Younger) died, which was in early 340. They also say that it was after the second banishment of Athanasius, which began in mid 339. This means that his death occurred some time between the second half of 339 and early 340.
Works.
Of the extensive literary activity of Eusebius, a relatively large portion has been preserved. Although posterity suspected him of Arianism, Eusebius had made himself indispensable by his method of authorship; his comprehensive and careful excerpts from original sources saved his successors the painstaking labor of original research. Hence, much has been preserved, quoted by Eusebius, which otherwise would have been destroyed.
The literary productions of Eusebius reflect on the whole the course of his life. At first, he occupied himself with works on Biblical criticism under the influence of Pamphilus and probably of Dorotheus of Tyre of the School of Antioch. Afterward, the persecutions under Diocletian and Galerius directed his attention to the martyrs of his own time and the past, and this led him to the history of the whole Church and finally to the history of the world, which, to him, was only a preparation for ecclesiastical history.
Then followed the time of the Arian controversies, and dogmatic questions came into the foreground. Christianity at last found recognition by the State; and this brought new problems—apologies of a different sort had to be prepared. Lastly, Eusebius wrote eulogies in praise of Constantine. To all this activity must be added numerous writings of a miscellaneous nature, addresses, letters, and the like, and exegetical works that extended over the whole of his life and that include both commentaries and treatises on Biblical archaeology.
"Onomasticon".
Eusebius' "Onomasticon" (more properly "On the Place-Names in the Holy Scripture", the name Eusebius gives to it) is a work that moderns would recognize as a gazetteer, a directory of place names, but which ancients had no category for. It sits uneasily between the ancient genres of geography and lexicography, taking elements from both but a member of neither. Eusebius' description of his own method—"I shall collect the entries from the whole of the divinely inspired Scriptures, and I shall set them out grouped by their initial letters so that one may easily perceive what lies scattered throughout the text"—implies that he had no similar type of book to work from; his work was entirely original, based only on the text of the Bible. As he describes, Eusebius organizes his entries into separate categories according to their first letters. Under each letter, the entries are organized first by the book they are found in, and then by their place in that book. The entries for Joshua under Tau, for example, read as follows:
Tina (15:22): of the tribe of Judah.<br>
Telem (15:24): of the tribe of Judah.<br>
Tessam (15:29): of the tribe of Judah.<br>
Tyre (19:35): of the tribe of Naphthali.
Where there is a contemporary town at the site or nearby, Eusebius notes it in the corresponding entry. "Terebinth", for example, describes Shechem as "near Neapolis", modern Nablus, and "Tophet" is located "in the suburbs of Jerusalem". The "Onomasticon" has traditionally been dated before 324, on the basis of its sparse references to Christianity, and complete absence of remarks on Constantine's buildings in the Holy Land. The work also describes traditional religious practices at the oak of Mamre as though they were still happening, while they are known to have been suppressed soon after 325, when a church was built on the site. Eusebius references to the encampment of the Legio X Fretensis at Aila (in southern Israel, near modern Aqaba and Eilat); the X Fretensis was probably transferred from Jerusalem to Aila under Diocletian.
Biblical text criticism.
Pamphilus and Eusebius occupied themselves with the textual criticism of the Septuagint text of the Old Testament and especially of the New Testament. An edition of the Septuagint seems to have been already prepared by Origen, which, according to Jerome, was revised and circulated by Eusebius and Pamphilus. For an easier survey of the material of the four Evangelists, Eusebius divided his edition of the New Testament into paragraphs and provided it with a synoptical table so that it might be easier to find the pericopes that belong together. These canon tables or "Eusebian canons" remained in use throughout the Middle Ages, and illuminated manuscript versions are important for the study of early medieval art, as they are the most elaborately decorated pages of many Gospel books. Eusebius detailed in "Epistula ad Carpianum" how to use his canons.
"Chronicle".
The "Chronicle" (Παντοδαπὴ Ἱστορία ("Pantodape historia")) is divided into two parts. The first part, the "Chronography" (Χρονογραφία ("Chronographia")), gives an epitome of universal history from the sources, arranged according to nations. The second part, the "Canons" (Χρονικοὶ Κανόνες ("Chronikoi kanones")), furnishes a synchronism of the historical material in parallel columns, the equivalent of a parallel timeline.
The work as a whole has been lost in the original Greek, but it may be reconstructed from later chronographists of the Byzantine school who made excerpts from the work, especially George Syncellus. The tables of the second part have been completely preserved in a Latin translation by Jerome, and both parts are still extant in an Armenian translation. The loss of the Greek originals has given an Armenian translation a special importance; thus, the first part of Eusebius' "Chronicle", of which only a few fragments exist in the Greek, has been preserved entirely in Armenian, though with lacunae. The "Chronicle" as preserved extends to the year 325.
"Church History".
In his "Church History" or "Ecclesiastical History", Eusebius wrote the first surviving history of the Christian Church as a chronologically-ordered account, based on earlier sources, complete from the period of the Apostles to his own epoch. The time scheme correlated the history with the reigns of the Roman Emperors, and the scope was broad. Included were the bishops and other teachers of the Church, Christian relations with the Jews and those deemed heretical, and the Christian martyrs through 324 C.E. Although its accuracy and biases have been questioned, it remains an important source on the early church due to Eusebius's access to materials now lost.
"Life of Constantine".
Eusebius' "Life of Constantine" ("Vita Constantini") is a eulogy or panegyric, and therefore its style and selection of facts are affected by its purpose, rendering it inadequate as a continuation of the "Church History." As the historian Socrates Scholasticus said, at the opening of his history which was designed as a continuation of Eusebius, "Also in writing the life of Constantine, this same author has but slightly treated of matters regarding Arius, being more intent on the rhetorical finish of his composition and the praises of the emperor, than on an accurate statement of facts." The work was unfinished at Eusebius' death. Some scholars have questioned the Eusebian authorship of this work.
Minor historical works.
Before he compiled his church history, Eusebius edited a collection of martyrdoms of the earlier period and a biography of Pamphilus. The martyrology has not survived as a whole, but it has been preserved almost completely in parts. It contained:
Of the life of Pamphilus, only a fragment survives. A work on the martyrs of Palestine in the time of Diocletian was composed after 311; numerous fragments are scattered in legendaries which have yet to be collected. The life of Constantine was compiled after the death of the emperor and the election of his sons as Augusti (337). It is more a rhetorical eulogy on the emperor than a history but is of great value on account of numerous documents incorporated in it.
Apologetic and dogmatic works.
To the class of apologetic and dogmatic works belong:
A number of writings, belonging in this category, have been entirely lost.
Exegetical and miscellaneous works.
All of the exegetical works of Eusebius have suffered damage in transmission. The majority of them are known to us only from long portions quoted in Byzantine catena-commentaries. However these portions are very extensive. Extant are:
Eusebius also wrote a work "Quaestiones ad Stephanum et Marinum", "On the Differences of the Gospels" (including solutions). This was written for the purpose of harmonizing the contradictions in the reports of the different Evangelists. This work was recently (2011) translated into the English language by David J. Miller and Adam C McCollum (edited by Roger Pearse) and was published under the name "Eusebius of Caesarea: Gospel Problems and Solutions." The original work was also translated into Syriac, and lengthy quotations exist in a "catena" in that language, and also in Coptic and Arabic catenas.
Eusebius also wrote treatises on Biblical archaeology:
These three treatises have been lost.
The addresses and sermons of Eusebius are mostly lost, but some have been preserved, e.g., a sermon on the consecration of the church in Tyre and an address on the thirtieth anniversary of the reign of Constantine (336).
Most of Eusebius' letters are lost. His letters to Carpianus and Flacillus exist complete. Fragments of a letter to the empress Constantia also exists.
Doctrine.
From a dogmatic point of view, Eusebius stands entirely upon the shoulders of Origen. Like Origen, he started from the fundamental thought of the absolute sovereignty ("monarchia") of God. God is the cause of all beings. But he is not merely a cause; in him everything good is included, from him all life originates, and he is the source of all virtue. God sent Christ into the world that it may partake of the blessings included in the essence of God. Christ is God and is a ray of the eternal light; but the figure of the ray is so limited by Eusebius that he expressly distinguishes the Son as distinct from Father as a ray is also distinct from its source the sun.
Eusebius was intent upon emphasizing the difference of the persons of the Trinity and maintaining the subordination of the Son (Logos, or Word) to God. The Logos, the Son (Jesus) is an hypostasis of God the Father whose generation, for Eusebius, took place before time. The Logos acts as the organ or instrument of God, the creator of life, the principle of every revelation of God, who in his absoluteness and transcendence is enthroned above and isolated from all the world. Eusebius, with most of the Christian tradition, assumed God was immutable. Therefore, to Eusebius's mind, the Logos must possess divinity by participation (and not originally like the Father), so that he can change, unlike God the Father. Thus he assumed a human body without altering the immutable divine Father. (Eusebius never calls Jesus "o theós", but "theós") because in all contrary attempts he suspected either polytheism (three distinct gods) or Sabellianism (three modes of one divine person).
Likewise, Eusebius described the relation of the Holy Spirit within the Trinity to that of the Son to the Father. No point of this doctrine is original with Eusebius, all is traceable to his teacher Origen. The lack of originality in his thinking shows itself in the fact that he never presented his thoughts in a system. After nearly being excommunicated due to charges of heresy by Alexander of Alexandria, Eusebius submitted and agreed to the Nicene Creed at the First Council of Nicea in 325.
Eusebius held that men were sinners by their own free choice and not by the necessity of their natures. Eusebius said, "The Creator of all things has impressed a natural law upon the soul of every man, as an assistant and ally in his conduct, pointing out to him the right way by this law; but, by the free liberty with which he is endowed, making the choice of what is best worthy of praise and acceptance, because he has acted rightly, not by force, but from his own free-will, when he had it in his power to act otherwise, As, again, making him who chooses what is worst, deserving of blame and punishment, as having by his own motion neglected the natural law, and becoming the origin and fountain of wickedness, and misusing himself, not from any extraneous necessity, but from free will and judgment. The fault is in him who chooses, not in God. For God has not made nature or the substance of the soul bad; for he who is good can make nothing but what is good. Everything is good which is according to nature. Every rational soul has naturally a good free-will, formed for the choice of what is good. But when a man acts wrongly, nature is not to be blamed; for what is wrong, takes place not according to nature, but contrary to nature, it being the work of choice, and not of nature".
By the time of the Byzantine Iconoclasm several centuries later, Eusebius had unfairly gained the reputation of having been an Arian, and was roundly condemned as such by Patriarch Nikephoros I of Constantinople. A letter Eusebius is supposed to have written to Constantine's daughter Constanza, refusing to fulfill her request for images of Christ, was quoted in the decrees (now lost) of the Iconoclast Council of Hieria in 754, and later quoted in part in the rebuttal of the Hieria decrees in the Second Council of Nicaea of 787, now the only source from which some of the text is known. The authenticity, or authorship of the letter remain uncertain.
Assessment.
Alternate views have suggested that Gibbon's dismissal of Eusebius is inappropriate:
While many have shared Burckhardt's assessment, particularly with reference to the "Life of Constantine", others, while not pretending to extol his merits, have acknowledged the irreplaceable value of his works which may principally reside in the copious quotations that they contain from other sources, often lost.
References.
</dl>
</dl>

</doc>
<doc id="10174" url="http://en.wikipedia.org/wiki?curid=10174" title="Empiricism">
Empiricism

Empiricism is a theory which states that knowledge comes only or primarily from sensory experience. One of several views of epistemology, the study of human knowledge, along with rationalism and skepticism, empiricism emphasizes the role of experience and evidence, especially sensory experience, in the formation of ideas, over the notion of innate ideas or traditions; empiricists may argue however that traditions (or customs) arise due to relations of previous sense experiences.
Empiricism in the philosophy of science emphasizes evidence, especially as discovered in experiments. It is a fundamental part of the scientific method that all hypotheses and theories must be tested against observations of the natural world rather than resting solely on "a priori" reasoning, intuition, or revelation.
Empiricism, often used by natural scientists, says that "knowledge is based on experience" and that "knowledge is tentative and probabilistic, subject to continued revision and falsification." One of the epistemological tenets is that sensory experience creates knowledge. The scientific method, including experiments and validated measurement tools, guides empirical research.
Etymology.
The English term "empirical" derives from the Greek word ἐμπειρία, which is cognate with and translates to the Latin "experientia", from which we derive the word "experience" and the related "experiment". The term was used by the Empiric school of ancient Greek medical practitioners, who rejected the three doctrines of the Dogmatic school, preferring to rely on the observation of "phenomena".
History.
Background.
A central concept in science and the scientific method is that it must be "empirically" based on the evidence of the senses. Both natural and social sciences use working hypotheses that are testable by observation and experiment. The term "semi-empirical" is sometimes used to describe theoretical methods that make use of basic axioms, established scientific laws, and previous experimental results in order to engage in reasoned model building and theoretical inquiry.
Philosophical empiricists hold no knowledge to be properly inferred or deduced unless it is derived from one's sense-based experience. This view is commonly contrasted with rationalism, which states that knowledge may be derived from reason independently of the senses. For example John Locke held that some knowledge (e.g. knowledge of God's existence) could be arrived at through intuition and reasoning alone. Similarly Robert Boyle, a prominent advocate of the experimental method, held that we have innate ideas. The main continental rationalists (Descartes, Spinoza, and Leibniz) were also advocates of the empirical "scientific method".
Early empiricism.
 The notion of "tabula rasa" ("clean slate" or "blank tablet") connotes a view of mind as an originally blank or empty recorder (Locke used the words "white paper") on which experience leaves marks. This denies that humans have innate ideas. The image dates back to Aristotle:
What the mind ("nous") thinks must be in it in the same sense as letters are on a tablet ("grammateion") which bears no actual writing ("grammenon"); this is just what happens in the case of the mind. (Aristotle, "On the Soul", 3.4.430a1).
Aristotle's explanation of how this was possible was not strictly empiricist in a modern sense, but rather based on his theory of potentiality and actuality, and experience of sense perceptions still requires the help of the active "nous". These notions contrasted with Platonic notions of the human mind as an entity that pre-existed somewhere in the heavens, before being sent down to join a body on Earth (see Plato's "Phaedo" and "Apology", as well as others). Aristotle was considered to give a more important position to sense perception than Plato, and commentators in the middle ages summarized one of his positions as "nihil in intellectu nisi prius fuerit in sensu" (Latin for "nothing in the intellect without first being in the senses").
This idea was later developed in Ancient Philosophy by the Stoic school. Stoic epistemology generally emphasized that the mind starts blank, but acquires knowledge as the outside world is impressed upon it. The doxographer Aetius summarizes this view as "When a man is born, the Stoics say, he has the commanding part of his soul like a sheet of paper ready for writing upon." Later stoics, such as Sextus of Chaeronea, would continue this idea of empiricism in later Stoic writings as well. As Sextus contends "For every thought comes from sense-perception or not without sense-perception and either from direct experience or not without direct experience" ("Against the Professors", 8.56-8).
During the middle ages Aristotle's theory of "tabula rasa" was developed by Islamic philosophers starting with Al Farabi, developing into an elaborate theory by Avicenna and demonstrated as a thought experiment by Ibn Tufail. For Avicenna (Ibn Sina), for example, the "tabula rasa" is a pure potentiality that is actualized through education, and knowledge is attained through "empirical familiarity with objects in this world from which one abstracts universal concepts" developed through a "syllogistic method of reasoning in which observations lead to propositional statements which when compounded lead to further abstract concepts." The intellect itself develops from a material intellect ("al-'aql al-hayulani"), which is a potentiality "that can acquire knowledge to the active intellect ("al-'aql al-fa'il"), the state of the human intellect in conjunction with the perfect source of knowledge". So the immaterial "active intellect", separate from any individual person, is still essential for understanding to occur.
In the 12th century CE the Andalusian Muslim philosopher and novelist Abu Bakr Ibn Tufail (known as "Abubacer" or "Ebn Tophail" in the West) included the theory of "tabula rasa" as a thought experiment in his Arabic philosophical novel, "Hayy ibn Yaqdhan" in which he depicted the development of the mind of a feral child "from a "tabula rasa" to that of an adult, in complete isolation from society" on a desert island, through experience alone. The Latin translation of his philosophical novel, entitled "Philosophus Autodidactus", published by Edward Pococke the Younger in 1671, had an influence on John Locke's formulation of "tabula rasa" in "An Essay Concerning Human Understanding".
A similar Islamic theological novel, "Theologus Autodidactus", was written by the Arab theologian and physician Ibn al-Nafis in the 13th century. It also dealt with the theme of empiricism through the story of a feral child on a desert island, but departed from its predecessor by depicting the development of the protagonist's mind through contact with society rather than in isolation from society.
During the 13th century Thomas Aquinas adopted the Aristotelian position that the senses are essential to mind into scholasticism. Bonaventure (1221–1274), one of Aquinas' strongest intellectual opponents, offered some of the strongest arguments in favour of the Platonic idea of the mind.
Renaissance Italy.
In the late renaissance various writers began to question the medieval and classical understanding of knowledge acquisition in a more fundamental way. In political and historical writing Niccolò Machiavelli and his friend Francesco Guicciardini initiated a new realistic style of writing. Machiavelli in particular was scornful of writers on politics who judged everything in comparison to mental ideals and demanded that people should study the "effectual truth" instead.
Their contemporary, Leonardo da Vinci (1452–1519) said,
If you find from your own experience that something is a fact and it contradicts what some authority has written down, then you must abandon the authority and base your reasoning on your own findings.
The decidedly anti-Aristotelian and anti-clerical music theorist Vincenzo Galilei (ca. 1520–1591), father of Galileo and the inventor of monody, made use of the method in successfully solving musical problems, firstly, of tuning such as the relationship of pitch to string tension and mass in stringed instruments, and to volume of air in wind instruments; and secondly to composition, by his various suggestions to composers in his "Dialogo della musica antica e moderna" (Florence, 1581). The Italian word he used for "experiment" was "esperienza". It is known that he was the essential pedagogical influence upon the young Galileo, his eldest son (cf. Coelho, ed. "Music and Science in the Age of Galileo Galilei"), arguably one of the most influential empiricists in history. Vincenzo, through his tuning research, found the underlying truth at the heart of the misunderstood myth of 'Pythagoras' hammers' (the square of the numbers concerned yielded those musical intervals, not the actual numbers, as believed), and through this and other discoveries that demonstrated the fallibility of traditional authorities, a radically empirical attitude developed, passed on to Galileo, which regarded "experience and demonstration" as the "sine qua non" of valid rational enquiry.
British empiricism.
British empiricism, though it was not a term used at the time, derives from the 17th century period of early modern philosophy and modern science. The term became useful in order to describe differences perceived between two of its founders Francis Bacon, described as empiricist, and René Descartes, who is described as a rationalist. Thomas Hobbes and Baruch Spinoza, in the next generation, are often also described as an empiricist and a rationalist respectively. John Locke, George Berkeley, and David Hume were the primary exponents of empiricism in the 18th century Enlightenment, with Locke being the person who is normally known as the founder of empiricism as such.
In response to the early-to-mid-17th century "continental rationalism" John Locke (1632–1704) proposed in "An Essay Concerning Human Understanding" (1689) a very influential view wherein the "only" knowledge humans can have is "a posteriori", i.e., based upon experience. Locke is famously attributed with holding the proposition that the human mind is a "tabula rasa", a "blank tablet," in Locke's words "white paper," on which the experiences derived from sense impressions as a person's life proceeds are written. There are two sources of our ideas: sensation and reflection. In both cases, a distinction is made between simple and complex ideas. The former are unanalysable, and are broken down into primary and secondary qualities. Primary qualities are essential for the object in question to be what it is. Without specific primary qualities, an object would not be what it is. For example, an apple is an apple because of the arrangement of its atomic structure. If an apple was structured differently, it would cease to be an apple. Secondary qualities are the sensory information we can perceive from its primary qualities. For example, an apple can be perceived in various colours, sizes, and textures but it is still identified as an apple. Therefore its primary qualities dictate what the object essentially is, while its secondary qualities define its attributes. Complex ideas combine simple ones, and divide into substances, modes, and relations. According to Locke, our knowledge of things is a perception of ideas that are in accordance or discordance with each other, which is very different from the quest for certainty of Descartes.
A generation later, the Irish Anglican bishop, George Berkeley (1685–1753), determined that Locke's view immediately opened a door that would lead to eventual atheism. In response to Locke, he put forth in his "Treatise Concerning the Principles of Human Knowledge" (1710) an important challenge to empiricism in which things "only" exist either as a "result" of their being perceived, or by virtue of the fact that they are an entity doing the perceiving. (For Berkeley, God fills in for humans by doing the perceiving whenever humans are not around to do it). In his text "Alciphron", Berkeley maintained that any order humans may see in nature is the language or handwriting of God. Berkeley's approach to empiricism would later come to be called subjective idealism.
The Scottish philosopher David Hume (1711–1776) responded to Berkeley's criticisms of Locke, as well as other differences between early modern philosophers, and moved empiricism to a new level of skepticism. Hume argued in keeping with the empiricist view that all knowledge derives from sense experience, but he accepted that this has implications not normally acceptable to philosophers. He wrote for example, "Mr. Locke divides all arguments into demonstrative and probable. In this view, we must say, that it is only probable all men must die, or that the sun will rise to-morrow." And, "Mr. Locke, in his chapter of power, says that, finding from experience, that there are several new productions in nature, and concluding that there must somewhere be a power capable of producing them, we arrive at last by this reasoning at the idea of power. But no reasoning can ever give us a new, original, simple idea; as this philosopher himself confesses. This, therefore, can never be the origin of that idea."
Hume divided all of human knowledge into two categories: "relations of ideas" and "matters of fact" (see also Kant's analytic-synthetic distinction). Mathematical and logical propositions (e.g. "that the square of the hypotenuse is equal to the sum of the squares of the two sides") are examples of the first, while propositions involving some contingent observation of the world (e.g. "the sun rises in the East") are examples of the second. All of people's "ideas", in turn, are derived from their "impressions". For Hume, an "impression" corresponds roughly with what we call a sensation. To remember or to imagine such impressions is to have an "idea". Ideas are therefore the faint copies of sensations.
Hume maintained that all knowledge, even the most basic beliefs about the natural world, cannot be conclusively established by reason. Rather, he maintained, our beliefs are more a result of accumulated "habits", developed in response to accumulated sense experiences. Among his many arguments Hume also added another important slant to the debate about scientific method — that of the problem of induction. Hume argued that it requires inductive reasoning to arrive at the premises for the principle of inductive reasoning, and therefore the justification for inductive reasoning is a circular argument. Among Hume's conclusions regarding the problem of induction is that there is no certainty that the future will resemble the past. Thus, as a simple instance posed by Hume, we cannot know with certainty by inductive reasoning that the sun will continue to rise in the East, but instead come to expect it to do so because it has repeatedly done so in the past.
Hume concluded that such things as belief in an external world and belief in the existence of the self were not rationally justifiable. According to Hume these beliefs were to be accepted nonetheless because of their profound basis in instinct and custom. Hume's lasting legacy, however, was the doubt that his skeptical arguments cast on the legitimacy of inductive reasoning, allowing many skeptics who followed to cast similar doubt.
Phenomenalism.
Most of Hume's followers have disagreed with his conclusion that belief in an external world is "rationally" unjustifiable, contending that Hume's own principles implicitly contained the rational justification for such a belief, that is, beyond being content to let the issue rest on human instinct, custom and habit. According to an extreme empiricist theory known as phenomenalism, anticipated by the arguments of both Hume and George Berkeley, a physical object is a kind of construction out of our experiences. Phenomenalism is the view that physical objects, properties, events (whatever is physical) are reducible to mental objects, properties, events. Ultimately, only mental objects, properties, events, exist — hence the closely related term subjective idealism. By the phenomenalistic line of thinking, to have a visual experience of a real physical thing is to have an experience of a certain kind of group of experiences. This type of set of experiences possesses a constancy and coherence that is lacking in the set of experiences of which hallucinations, for example, are a part. As John Stuart Mill put it in the mid-19th century, matter is the "permanent possibility of sensation".
Mill's empiricism went a significant step beyond Hume in still another respect: in maintaining that induction is necessary for "all" meaningful knowledge including mathematics. As summarized by D.W. Hamlin:
[Mill] claimed that mathematical truths were merely very highly confirmed generalizations from experience; mathematical inference, generally conceived as deductive [and "a priori"] in nature, Mill set down as founded on induction. Thus, in Mill's philosophy there was no real place for knowledge based on relations of ideas. In his view logical and mathematical necessity is psychological; we are merely unable to conceive any other possibilities than those that logical and mathematical propositions assert. This is perhaps the most extreme version of empiricism known, but it has not found many defenders.
Mill's empiricism thus held that knowledge of any kind is not from direct experience but an inductive inference from direct experience. The problems other philosophers have had with Mill's position center around the following issues: Firstly, Mill's formulation encounters difficulty when it describes what direct experience is by differentiating only between actual and possible sensations. This misses some key discussion concerning conditions under which such "groups of permanent possibilities of sensation" might exist in the first place. Berkeley put God in that gap; the phenomenalists, including Mill, essentially left the question unanswered. In the end, lacking an acknowledgement of an aspect of "reality" that goes beyond mere "possibilities of sensation", such a position leads to a version of subjective idealism. Questions of how floor beams continue to support a floor while unobserved, how trees continue to grow while unobserved and untouched by human hands, etc., remain unanswered, and perhaps unanswerable in these terms. Secondly, Mill's formulation leaves open the unsettling possibility that the "gap-filling entities are purely possibilities and not actualities at all". Thirdly, Mill's position, by calling mathematics merely another species of inductive inference, misapprehends mathematics. It fails to fully consider the structure and method of mathematical science, the products of which are arrived at through an internally consistent deductive set of procedures which do not, either today or at the time Mill wrote, fall under the agreed meaning of induction.
The phenomenalist phase of post-Humean empiricism ended by the 1940s, for by that time it had become obvious that statements about physical things could not be translated into statements about actual and possible sense data. If a physical object statement is to be translatable into a sense-data statement, the former must be at least deducible from the latter. But it came to be realized that there is no finite set of statements about actual and possible sense-data from which we can deduce even a single physical-object statement. Remember that the translating or paraphrasing statement must be couched in terms of normal observers in normal conditions of observation. There is, however, no "finite" set of statements that are couched in purely sensory terms and can express the satisfaction of the condition of the presence of a normal observer. According to phenomenalism, to say that a normal observer is present is to make the hypothetical statement that were a doctor to inspect the observer, the observer would appear to the doctor to be normal. But, of course, the doctor himself must be a normal observer. If we are to specify this doctor's normality in sensory terms, we must make reference to a second doctor who, when inspecting the sense organs of the first doctor, would himself have to have the sense data a normal observer has when inspecting the sense organs of a subject who is a normal observer. And if we are to specify in sensory terms that the second doctor is a normal observer, we must refer to a third doctor, and so on (also see the third man).
Logical empiricism.
Logical empiricism (also "logical positivism" or "neopositivism") was an early 20th-century attempt to synthesize the essential ideas of British empiricism (e.g. a strong emphasis on sensory experience as the basis for knowledge) with certain insights from mathematical logic that had been developed by Gottlob Frege and Ludwig Wittgenstein. Some of the key figures in this movement were Otto Neurath, Moritz Schlick and the rest of the Vienna Circle, along with A.J. Ayer, Rudolf Carnap and Hans Reichenbach.
The neopositivists subscribed to a notion of philosophy as the conceptual clarification of the methods, insights and discoveries of the sciences. They saw in the logical symbolism elaborated by Frege (1848–1925) and Bertrand Russell (1872–1970) a powerful instrument that could rationally reconstruct all scientific discourse into an ideal, logically perfect, language that would be free of the ambiguities and deformations of natural language. This gave rise to what they saw as metaphysical pseudoproblems and other conceptual confusions. By combining Frege's thesis that all mathematical truths are logical with the early Wittgenstein's idea that all logical truths are mere linguistic tautologies, they arrived at a twofold classification of all propositions: the "analytic" (a priori) and the "synthetic" (a posteriori). On this basis, they formulated a strong principle of demarcation between sentences that have sense and those that do not: the so-called verification principle. Any sentence that is not purely logical, or is unverifiable is devoid of meaning. As a result, most metaphysical, ethical, aesthetic and other traditional philosophical problems came to be considered pseudoproblems.
In the extreme empiricism of the neopositivists—at least before the 1930s—any genuinely synthetic assertion must be reducible to an ultimate assertion (or set of ultimate assertions) that expresses direct observations or perceptions. In later years, Carnap and Neurath abandoned this sort of "phenomenalism" in favor of a rational reconstruction of knowledge into the language of an objective spatio-temporal physics. That is, instead of translating sentences about physical objects into sense-data, such sentences were to be translated into so-called "protocol sentences", for example, ""X" at location "Y" and at time "T" observes such and such." The central theses of logical positivism (verificationism, the analytic-synthetic distinction, reductionism, etc.) came under sharp attack after World War II by thinkers such as Nelson Goodman, W.V. Quine, Hilary Putnam, Karl Popper, and Richard Rorty. By the late 1960s, it had become evident to most philosophers that the movement had pretty much run its course, though its influence is still significant among contemporary analytic philosophers such as Michael Dummett and other anti-realists.
Pragmatism.
In the late 19th and early 20th century several forms of pragmatic philosophy arose. The ideas of pragmatism, in its various forms, developed mainly from discussions that took place while Charles Sanders Peirce and William James were both at Harvard in the 1870s. James popularized the term "pragmatism", giving Peirce full credit for its patrimony, but Peirce later demurred from the tangents that the movement was taking, and redubbed what he regarded as the original idea with the name of "pragmaticism". Along with its "pragmatic theory of truth", this perspective integrates the basic insights of empirical (experience-based) and rational (concept-based) thinking.
Charles Peirce (1839–1914) was highly influential in laying the groundwork for today's empirical scientific method. Although Peirce severely criticized many elements of Descartes' peculiar brand of rationalism, he did not reject rationalism outright. Indeed, he concurred with the main ideas of rationalism, most importantly the idea that rational concepts can be meaningful and the idea that rational concepts necessarily go beyond the data given by empirical observation. In later years he even emphasized the concept-driven side of the then ongoing debate between strict empiricism and strict rationalism, in part to counterbalance the excesses to which some of his cohorts had taken pragmatism under the "data-driven" strict-empiricist view.
Among Peirce's major contributions was to place inductive reasoning and deductive reasoning in a complementary rather than competitive mode, the latter of which had been the primary trend among the educated since David Hume wrote a century before. To this, Peirce added the concept of abductive reasoning. The combined three forms of reasoning serve as a primary conceptual foundation for the empirically based scientific method today. Peirce's approach "presupposes that (1) the objects of knowledge are real things, (2) the characters (properties) of real things do not depend on our perceptions of them, and (3) everyone who has sufficient experience of real things will agree on the truth about them. According to Peirce's doctrine of fallibilism, the conclusions of science are always tentative. The rationality of the scientific method does not depend on the certainty of its conclusions, but on its self-corrective character: by continued application of the method science can detect and correct its own mistakes, and thus eventually lead to the discovery of truth".
In his Harvard "Lectures on Pragmatism" (1903), Peirce enumerated what he called the "three cotary propositions of pragmatism" (L: "cos, cotis" whetstone), saying that they "put the edge on the maxim of pragmatism". First among these he listed the peripatetic-thomist observation mentioned above, but he further observed that this link between sensory perception and intellectual conception is a two-way street. That is, it can be taken to say that whatever we find in the intellect is also incipiently in the senses. Hence, if theories are theory-laden then so are the senses, and perception itself can be seen as a species of abductive inference, its difference being that it is beyond control and hence beyond critique – in a word, incorrigible. This in no way conflicts with the fallibility and revisability of scientific concepts, since it is only the immediate percept in its unique individuality or "thisness" – what the Scholastics called its "haecceity" – that stands beyond control and correction. Scientific concepts, on the other hand, are general in nature, and transient sensations do in another sense find correction within them. This notion of perception as abduction has received periodic revivals in artificial intelligence and cognitive science research, most recently for instance with the work of Irvin Rock on "indirect perception".
Around the beginning of the 20th century, William James (1842–1910) coined the term "radical empiricism" to describe an offshoot of his form of pragmatism, which he argued could be dealt with separately from his pragmatism – though in fact the two concepts are intertwined in James's published lectures. James maintained that the empirically observed "directly apprehended universe needs ... no extraneous trans-empirical connective support", by which he meant to rule out the perception that there can be any value added by seeking supernatural explanations for natural phenomena. James's "radical empiricism" is thus "not" radical in the context of the term "empiricism", but is instead fairly consistent with the modern use of the term "empirical". (His method of argument in arriving at this view, however, still readily encounters debate within philosophy even today.)
John Dewey (1859–1952) modified James' pragmatism to form a theory known as instrumentalism. The role of sense experience in Dewey's theory is crucial, in that he saw experience as unified totality of things through which everything else is interrelated. Dewey's basic thought, in accordance with empiricism was that reality is determined by past experience. Therefore, humans adapt their past experiences of things to perform experiments upon and test the pragmatic values of such experience. The value of such experience is measured experientially and scientifically, and the results of such tests generate ideas that serve as instruments for future experimentation, in physical sciences as in ethics. Thus, ideas in Dewey's system retain their empiricist flavour in that they are only known "a posteriori".
References.
</dl>

</doc>
<doc id="10175" url="http://en.wikipedia.org/wiki?curid=10175" title="Estampie">
Estampie

The estampie (French: "estampie", Occitan and Catalan: "estampida", Italian: "istampitte") is a medieval dance and musical form, it was a popular instrumental and vocal form in the 13th and 14th centuries. The name was also applied to poetry . 
Musical form.
The estampie is similar in form to the lai, consisting of a succession of repeated sections . According to Johannes de Grocheio, there were both vocal and instrumental estampies (for which he used the Latin calque "stantipes"), which differed somewhat in form, in that the vocal estampie begins with a refrain, which is repeated at the end of each verse . Also according to Grocheio, the repeating sections in both the vocal and instrumental estampie were called "puncta" (singular "punctus") , in the form: 
The two statements of each punctus differ only in their endings, described as "apertum" ("open") and "clausum" ("closed") by Grocheio, who believed that six "puncta" were standard for the stantipes (his term for the estampie), though he was aware of stantipes with seven "puncta" . The structure can therefore be diagrammed as: 
Sometimes the same two endings are used for all the "puncta", producing the structure 
A similar structure was shared with the saltarello, another medieval dance.
The earliest reported example of this musical form is the song "Kalenda maya", written by the troubadour Raimbaut de Vaqueiras (1180–1207) to the melody of an estampida played by French jongleurs.
All other known examples are purely instrumental pieces.
Fourteenth-century examples include estampies with subtitles such as "Lamento di Tristano", "La Manfredina", Salterello, "Isabella", "Tre fontane". 
Though the estampie is generally monophonic, there are also two-voice compositions in the form of an estampie, such as the three for keyboard in the Robertsbridge Fragment.
According to Grocheio, the fiddle was the supreme instrument of the period, and the stantipes, together with the cantus coronatus and ductia, were the principal forms played on fiddles before the wealthy in their celebration .
Dance.
The idealized dance character of all these pieces suggests that the "estampie" may have been a true dance but there are no surviving dance manuals describing the "estampie" as a dance. Illuminations and paintings from the period seem to indicate that the "estampie" involves fairly vigorous hopping. Some "estampies", such as the famous "Tre fontane" ("Three Fountains") "estampie", contain florid and virtuosic instrumental writing, signifying that they may have been intended as abstract performance music rather than actual dance music.
Etymology.
The etymology of the name is disputed; an alternative name of the dance is "stantipes", which suggests that one foot was stationary during the dance; but the more widely accepted etymology relates it to "estamper", to stamp the feet.
According to the "OED", however, the name comes from the Provençal "estampida", feminine of "estampit", the past participle of "estampir" "to resound" .

</doc>
<doc id="10176" url="http://en.wikipedia.org/wiki?curid=10176" title="Experimental cancer treatment">
Experimental cancer treatment

Experimental cancer treatments are medical therapies intended or claimed to treat cancer (see also "tumor") by improving on, supplementing or replacing conventional methods (surgery, chemotherapy, radiation, and immunotherapy).
The entries listed below vary between theoretical therapies to unproven controversial therapies. Many of these treatments are alleged to help against only specific forms of cancer. It is not a list of treatments widely available at hospitals.
Studying treatments for cancer.
The twin goals of research are to determine whether the treatment actually works (called efficacy) and whether it is sufficiently safe. Regulatory processes attempt to balance the potential benefits with the potential harms, so that people given the treatment are more likely to benefit from it than to be harmed by it.
Medical research for cancer begins much like research for any disease. In organized studies of new treatments for cancer, the pre-clinical development of drugs, devices, and techniques begins in laboratories, either with isolated cells or in small animals, most commonly rats or mice. In other cases, the proposed treatment for cancer is already in use for some other medical condition, in which case more is known about its safety and potential efficacy.
Clinical trials are the study of treatments in humans. The first-in-human tests of a potential treatment are called Phase I studies. Early clinical trials typically enroll a very small number of patients, and the purpose is to identify major safety issues and the "maximum tolerated dose", which is the highest dose that does not produce serious or fatal adverse effects. The dose given in these trials may be far too small to produce any useful effect. In most research, these early trials may involve healthy people, but cancer studies normally enroll only people with relatively severe forms of the disease in this stage of testing. On average, 95% of the participants in these early trials receive no benefit, but all are exposed to the risk of adverse effects. Most participants show signs of optimism bias (the irrational belief that they will beat the odds).
Later studies, called Phase II and Phase III studies, enroll more people, and the goal is to determine whether the treatment actually works. Phase III studies are frequently randomized controlled trials, with the experimental treatment being compared to the current best available treatment rather than to a placebo. In some cases, the Phase III trial provides the best available treatment to all participants, in addition to some of the patients receiving the experimental treatment.
Bacterial treatments.
Chemotherapeutic drugs have a hard time penetrating tumors to kill them at their core because these cells may lack a good blood supply. Researchers have been using anaerobic bacteria, such as "Clostridium novyi", to consume the interior of oxygen-poor tumours. These should then die when they come in contact with the tumour's oxygenated sides, meaning they would be harmless to the rest of the body. A major problem has been that bacteria do not consume all parts of the malignant tissue. However, combining the therapy with chemotheraputic treatments can help to solve this problem.
Another strategy is to use anaerobic bacteria that have been transformed with an enzyme that can convert a non-toxic prodrug into a toxic drug. With the proliferation of the bacteria in the necrotic and hypoxic areas of the tumour, the enzyme is expressed solely in the tumour. Thus, a systemically applied prodrug is metabolised to the toxic drug only in the tumour. This has been demonstrated to be effective with the nonpathogenic anaerobe "Clostridium sporogenes".
Drug therapies.
HAMLET (human alpha-lactalbumin made lethal to tumor cells).
HAMLET (human alpha-lactalbumin made lethal to tumor cells) is a molecular complex derived from human breast milk that kills tumor cells by a process resembling programmed cell death (apoptosis). It has been tested in humans with skin papillomas and bladder cancer.
Dichloroacetate.
Dichloroacetate (DCA) has been found to shrink tumors "in vivo" in rats, and has a plausible scientific mechanism: DCA appears to reactivate suppressed mitochondria in some types of oxygen-starved tumor cells, and thus promotes apoptosis. Because it was tested for other conditions, DCA is known to be relatively safe, available, and inexpensive, and it can be taken by mouth as a pill, which is convenient. Five patients with brain cancer have been treated with DCA in a clinical trial, and the authors say that the lives of four were 'probably' extended. However, without a large controlled trial it is impossible to say whether the drug is truly effective against cancer.
Quercetin.
Quercetin is a principal flavonoid compound and an excellent free-radical-scavenging antioxidant that promotes apoptosis. In vitro it shows some antitumor activity in oral cancer and leukemia. Cultured skin and prostate cancer cells showed significant mortality (compared to nonmalignant cells) when treated with a combination of quercetin and ultrasound Note that ultrasound also promotes topical absorption by up to 1,000 times, making the use of topical quercetin and ultrasound wands an interesting proposition.
High dietary intake of fruits and vegetables is associated with reduction in cancer, and some scientists, such as Gian Luigi Russo at the Institute of Food Sciences in Italy, suspect quercetin may be partly responsible. Research shows that quercetin influences cellular mechanisms in vitro and in animal studies. According to the American Cancer society, "there is no reliable clinical evidence that quercetin can prevent or treat cancer in humans".
Insulin potentiation therapy.
Insulin potentiation therapy is practice of injecting insulin, usually alongside conventional cancer drugs, in the belief that this improves the overall effect of the treatment. Quackwatch state: "Insulin Potentiation Therapy (IPT) is one of several unproven, dangerous treatments that is promoted by a small group of practitioners without trustworthy evidence that it works." 
Drugs that restore p53 activity.
Several drug therapies are being developed based on p53, the tumour suppressor gene that protects the cell in response to damage and stress. It is analogous to deciding what to do with a damaged car: p53 brings everything to a halt, and then decides whether to fix the cell or, if the cell is beyond repair, to destroy the cell. This protective function of p53 is disabled in most cancer cells, allowing them to multiply without check. Restoration of p53 activity in tumours (where possible) has been shown to inhibit tumour growth and can even shrink the tumour.
As p53 protein levels are usually kept low, one could block its degradation and allow large amounts of p53 to accumulate, thus stimulating p53 activity and its antitumour effects. Drugs that utilize this mechanism include nutlin and MI-219, which are both in phase I clinical trials. There are also other drugs that are still in the preclinical stage of testing, such as RITA and MITA.
BI811283.
BI811283 is a small molecule inhibitor of the Aurora B kinase protein being developed by Boehringer Ingelheim for use as an anti-cancer agent. BI 811283 is currently in the early stages of clinical development and is undergoing first-in-human trials in patients with solid tumors and Acute Myeloid Leukaemia.
Gene therapy.
Introduction of tumor suppressor genes into rapidly dividing cells has been thought to slow down or arrest tumor growth. Adenoviruses are a commonly utilized vector for this purpose. Much research has focused on the use of adenoviruses that cannot reproduce, or reproduce only to a limited extent, within the patient to ensure safety via the avoidance of cytolytic destruction of noncancerous cells infected with the vector. However, new studies focus on adenoviruses that can be permitted to reproduce, and destroy cancerous cells in the process, since the adenoviruses' ability to infect normal cells is substantially impaired, potentially resulting in a far more effective treatment.
Another use of gene therapy is the introduction of enzymes into these cells that make them susceptible to particular chemotherapy agents; studies with introducing thymidine kinase in gliomas, making them susceptible to aciclovir, are in their experimental stage.
Epigenetic Options.
Epigenetics is the study of heritable changes in gene activity that are not caused by changes in the DNA sequence, often a result of environmental or dietary damage to the histone receptors within the cell. Current research has shown that epigenetic pharmaceuticals could be a putative replacement or adjuvant therapy for currently accepted treatment methods such as radiation and chemotherapy, or could enhance the effects of these current treatments. It has been shown that the epigenetic control of the proto-onco regions and the tumor suppressor sequences by conformational changes in histones directly affects the formation and progression of cancer. Epigenetics also has the factor of reversibility, a characteristic that other cancer treatments do not offer.
Some investigators, like Randy Jirtle, PhD, of Duke University Medical Center, think epigenetics may ultimately turn out to have a greater role in disease than genetics.
Telomerase therapy.
Because most malignant cells rely on the activity of the protein telomerase for their immortality, it has been proposed that a drug that inactivates telomerase might be effective against a broad spectrum of malignancies. At the same time, most healthy tissues in the body express little if any telomerase, and would function normally in its absence. Currently, Inositol hexaphosphate, which is available over-the-counter, is undergoing testing in cancer research due to its telomerase-inhibiting abilities.
A number of research groups have experimented with the use of telomerase inhibitors in animal models, and as of 2005 and 2006 phase I and II human clinical trials are underway. Geron Corporation is currently conducting two clinical trials involving telomerase inhibitors. One uses a vaccine (GRNVAC1) and the other uses a lipidated oligonucleotide(GRN163L).
Radiation therapies.
Photodynamic therapy.
Photodynamic therapy (PDT) is generally a non-invasive treatment using a combination of light and a photosensitive drug, such as 5-ALA, Foscan, Metvix, Tookad, WST09, WST11, Photofrin, or Visudyne. The drug is triggered by light of a specific wavelength.
Hyperthermia therapy.
Localized and whole-body application of heat has been proposed as a technique for the treatment of malignant tumours. Intense heating will cause denaturation and coagulation of cellular proteins, rapidly killing cells within a tumour.
More prolonged moderate heating to temperatures just a few degrees above normal (39,5°C) can cause more subtle changes. A mild heat treatment combined with other stresses can cause cell death by apoptosis. There are many biochemical consequences to the heat shock response within the cell, including slowed cell division and increased sensitivity to ionizing radiation therapy. The purpose of overheating the tumor cells is to create a lack of oxygen so that the heated cells become overacidified, which leads to a lack of nutrients in the tumor. This in turn disrupts the metabolism of the cells so that cell death (apoptosis) can set in. In certain cases chemotherapy or radiation that has previously not had any effect can be made effective. Hyperthermia alters the cell walls by means of so-called heat shock proteins. The cancer cells then react very much more effectively to the cytostatics and radiation. If hyperthermia is used conscientiously it has no serious side effects.
There are many techniques by which heat may be delivered. Some of the most common involve the use of focused ultrasound (FUS or HIFU), microwave heating, induction heating, magnetic hyperthermia, and direct application of heat through the use of heated saline pumped through catheters. Experiments with carbon nanotubes that selectively bind to cancer cells have been performed. Lasers are then used that pass harmlessly through the body, but heat the nanotubes, causing the death of the cancer cells. Similar results have also been achieved with other types of nanoparticles, including gold-coated nanoshells and nanorods that exhibit certain degrees of 'tunability' of the absorption properties of the nanoparticles to the wavelength of light for irradiation. The success of this approach to cancer treatment rests on the existence of an 'optical window' in which biological tissue (i.e., healthy cells) are completely transparent at the wavelength of the laser light, while nanoparticles are highly absorbing at the same wavelength. Such a 'window' exists in the so-called near-infrared region of the electromagnetic spectrum. In this way, the laser light can pass through the system without harming healthy tissue, and only diseased cells, where the nanoparticles reside, get hot and are killed.
Magnetic hyperthermia makes use of magnetic nanoparticles, which can be injected into tumours and then generate heat when subjected to an alternating magnetic field.
One of the challenges in thermal therapy is delivering the appropriate amount of heat to the correct part of the patient's body. A great deal of current research focuses on precisely positioning heat delivery devices (catheters, microwave, and ultrasound applicators, etc.) using ultrasound or magnetic resonance imaging, as well as of developing new types of nanoparticles that make them particularly efficient absorbers while offering little or no concerns about toxicity to the circulation system. Clinicians also hope to use advanced imaging techniques to monitor heat treatments in real time—heat-induced changes in tissue are sometimes perceptible using these imaging instruments.
Non-invasive cancer treatment.
This preclinical treatment involves using radio waves to heat up tiny metals that are implanted in cancerous tissue. Gold nanoparticles or carbon nanotubes are the most likely candidate. Promising preclinical trials have been conducted, although clinical trials may not be held for another few years.
Another method that is entirely non-invasive referred to as Tumor Treating Fields has already reached clinical trial stage in many countries. The concept applies an electric field through a tumour region using electrodes external to the body. Successful trials have shown the process effectiveness to be greater than chemotherapy and there are no side-effects and only negligible time spent away from normal daily activities. This treatment is still in very early development stages for many types of cancer.
High-intensity focused ultrasound (HIFU) is still in investigatory phases in many places around the world. In China it has CFDA approval and over 180 treatment centres have been established in China, Hong Kong, and Korea. HIFU has been successfully used to treat cancer to destroy tumours of the bone, brain, breast, liver, pancreas, rectum, kidney, testes, and prostate. Several thousand patients have been treated with various types of tumours. HIFU has CE approval for palliative care for bone metastasis. Experimentally, palliative care has been provided for cases of advanced pancreatic cancer.
Electromagnetic treatments.
Tumor Treating Fields is a novel FDA-approved cancer treatment therapy that uses alternating electric field to disturb the rapid cell division exhibited by cancer cells.
Complementary and alternative treatments.
Complementary and alternative medicine (CAM) treatments are the diverse group of medical and healthcare systems, practices, and products that are not part of conventional medicine and have not been proven to be effective. "Complementary medicine" usually refers to methods and substances used along with conventional medicine, while "alternative medicine" refers to compounds used instead of conventional medicine. CAM use is common among people with cancer.
Most complementary and alternative medicines for cancer have not been rigorously studied or tested. Some alternative treatments that have been proven ineffective continue to be marketed and promoted.

</doc>
<doc id="10181" url="http://en.wikipedia.org/wiki?curid=10181" title="Emission">
Emission

Emission may refer to:
Emission of chemical products:
Emission of electromagnetic radiation:
Other uses:

</doc>
<doc id="10183" url="http://en.wikipedia.org/wiki?curid=10183" title="Environmental movement in the United States">
Environmental movement in the United States

In the United States today, the organized environmental movement is represented by a wide range of organizations sometimes called non-governmental organizations or NGOs. These organizations exist on local, national, and international scales. Environmental NGOs vary widely in political views and in the amount they seek to influence the environmental policy of the United States and other governments. The environmental movement today consists of both large national groups and also many smaller local groups with local concerns. Some resemble the old U.S. conservation movement - whose modern expression is The Nature Conservancy, Audubon Society and National Geographic Society - American organizations with a worldwide influence.
Scope of the movement.
As public awareness and the environmental sciences have improved in recent years, environmental issues have broadened to include key concepts such as "sustainability" and also new emerging concerns such as ozone depletion, global warming, acid rain, land use and biogenetic pollution.
Environmental movements often interact or are linked with other social movements, e.g. for peace, human rights, and animal rights; and against nuclear weapons and/or nuclear power, endemic diseases, poverty, hunger, etc.
Some US colleges are now going green by signing the "President's Climate Commitment," a document that a college President can sign to enable said colleges to practice environmentalism by switching to solar power, etc.
History.
Early European settlers to the United States brought from Europe the concept of the commons. In the colonial era, access to natural resources was allocated by individual towns, and disputes over fisheries or land use were resolved at the local level. Changing technologies, however, strained traditional ways of resolving disputes of resource use, and local governments had limited control over powerful special interests. For example, the damming of rivers for mills cut off upriver towns from fisheries; logging and clearing of forest in watersheds harmed local fisheries downstream. In New England, many farmers became uneasy as they noticed clearing of forest changed stream flows and a decrease in bird population which helped control insects and other pests. These concerns become widely known with the publication of Man and Nature (1864) by George Perkins Marsh. The environmental impact method of analysis is generally the main mode for determining what issues the environmental movement is involved in. This model is used to determine how to proceed in situations that are detrimental to the environment by choosing the way that is least damaging and has the fewest lasting implications.
Conservation movement.
Conservation first became a national issue during the progressive era's conservation movement (1890s - 1920s). The early national conservation movement shifted emphasis to scientific management which favored larger enterprises and control began to shift from local governments to the states and the federal government.(Judd) Some writers credit sportsmen, hunters and fishermen with the increasing influence of the conservation movement. In the 1870s sportsman magazines such as American Sportsmen, Forest and Stream, and Field and Stream are seen as leading to the growth of the conservation movement.(Reiger) This conservation movement also urged the establishment of state and national parks and forests, wildlife refuges, and national monuments intended to preserve noteworthy natural features.
Conservation groups focus primarily on an issue that's origins are routed in general expansion. As Industrialization became more prominent as well as the increasing trend towards Urbanization the conservative environmental movement began. Contrary to popular belief conservation groups are not against expansion in general, instead they are concerned with efficiency with resources and land development.
Progressive era.
Theodore Roosevelt and his close ally George Bird Grinnell, were motivated by the wanton waste that was taking place at the hand of market hunting. This practice resulted in placing a large number of North American game species on the edge of extinction. Roosevelt recognized that the laissez-faire approach of the U.S. Government was too wasteful and inefficient. In any case, they noted, most of the natural resources in the western states were already owned by the federal government. The best course of action, they argued, was a long-term plan devised by national experts to maximize the long-term economic benefits of natural resources. To accomplish the mission, Roosevelt and Grinnell formed the Boone and Crockett Club in 1887. The Club was made up of the best minds and influential men of the day. The Boone and Crockett Club's contingency of conservationists, scientists, politicians, and intellectuals became Roosevelt's closest advisers during his march to preserve wildlife and habitat across North America. As president, Theodore Roosevelt became a prominent conservationist, putting the issue high on the national agenda. He worked with all the major figures of the movement, especially his chief advisor on the matter, Gifford Pinchot. Roosevelt was deeply committed to conserving natural resources, and is considered to be the nation's first conservation President. He encouraged the Newlands Reclamation Act of 1902 to promote federal construction of dams to irrigate small farms and placed 230 million acres (360,000 mi² or 930,000 km²) under federal protection. Roosevelt set aside more Federal land for national parks and nature preserves than all of his predecessors combined.
Roosevelt established the United States Forest Service, signed into law the creation of five National Parks, and signed the 1906 Antiquities Act, under which he proclaimed 18 new U.S. National Monuments. He also established the first 51 Bird Reserves, four Game Preserves, and 150 National Forests, including Shoshone National Forest, the nation's first. The area of the United States that he placed under public protection totals approximately 230000000 acre.
Gifford Pinchot had been appointed by McKinley as chief of Division of Forestry in the Department of Agriculture. In 1905, his department gained control of the national forest reserves. Pinchot promoted private use (for a fee) under federal supervision. In 1907, Roosevelt designated 16 million acres (65,000 km²) of new national forests just minutes before a deadline.
In May 1908, Roosevelt sponsored the Conference of Governors held in the White House, with a focus on natural resources and their most efficient use. Roosevelt delivered the opening address: "Conservation as a National Duty."
In 1903 Roosevelt toured the Yosemite Valley with John Muir, who had a very different view of conservation, and tried to minimize commercial use of water resources and forests. Working through the Sierra Club he founded, Muir succeeded in 1905 in having Congress transfer the Mariposa Grove and Yosemite Valley to the National Park Service. While Muir wanted nature preserved for the sake of pure beauty, Roosevelt subscribed to Pinchot's formulation, "to make the forest produce the largest amount of whatever crop or service will be most useful, and keep on producing it for generation after generation of men and trees." Muir and the Sierra Club vehemently opposed the damming of the Hetch Hetchy Valley in Yosemite in order to provide water to the city of San Francisco. Roosevelt and Pinchot supported the dam, as did President Woodrow Wilson. The Hetch Hetchy dam was finished in 1923 and is still in operation, but the Sierra Club still wants to tear it down.
Other influential conservationists of the Progressive Era included George Bird Grinnell (a prominent sportsmen who founded the Boone and Crockett Club), the Izaak Walton League and John Muir, the founder of the Sierra Club in 1892. Conservationists organized the National Parks Conservation Association, the Audubon Society, and other groups that still remain active.
New Deal.
Franklin Delano Roosevelt (1933–45), like his cousin Theodore Roosevelt, was an ardent conservationist. He used numerous programs of the departments of Agriculture and Interior to end wasteful land-use, mitigate the effects of the Dust Bowl, and efficiently develop natural resources in the West. One of the most popular of all New Deal programs was the Civilian Conservation Corps (1933–1943), which sent two million poor young men to work in rural and wilderness areas, primarily on conservation projects.
Post 1945.
After World War II increasing encroachment on wilderness land evoked the continued resistance of conservationists, who succeeded in blocking a number of projects in the 1950s and 1960s, including the proposed Bridge Canyon Dam that would have backed up the waters of the Colorado River into the Grand Canyon National Park.
The Inter-American Conference on the Conservation of Renewable Natural Resources met in 1948 as a collection of nearly 200 scientists from all over the Americans forming the trusteeship principle that:
"No generation can exclusively own the renewable resources by which it lives. We hold the commonwealth in trust for prosperity, and to lessen or destroy it is to commit treason against the future"
Beginning of the modern movement.
During the 1950s, 1960s and 1970s, several events occurred which raised the public awareness of harm to the environment caused by man. In 1954, the 23 man crew of the Japanese fishing vessel Lucky Dragon was exposed to radioactive fallout from a hydrogen bomb test at Bikini Atoll, in 1969, an ecologically catastrophic oil spill from an offshore well in California's Santa Barbara Channel, Barry Commoner's protest against nuclear testing, Rachel Carson's book Silent Spring, Paul R. Ehrlich's The Population Bomb all added anxiety about the environment. Pictures of Earth from space emphasized that the earth was small and fragile.
As the public became more aware of environmental issues, concern about air pollution, water pollution, solid waste disposal, dwindling energy resources, radiation, pesticide poisoning (particularly as described in Rachel Carson's influential Silent Spring, 1962), noise pollution, and other environmental problems engaged a broadening number of sympathizers. That public support for environmental concerns was widespread became clear in the Earth Day demonstrations of 1970.
Unlike the Progressive Era's conservation movement (1890s - 1920s), which was largely elitist consisting of largely of wealthy, politically powerful men, the modern environmental movement was a social movement with more popular support. The environmental movement borrowed tactics from both the successful civil rights movement and the protests against the Vietnam war.
Wilderness preservation.
In the modern wilderness preservation movement, important philosophical roles are played by the writings of John Muir who had been activist in the late 19th and early 20th century. Along with Muir perhaps most influential in the modern movement is Henry David Thoreau who published Walden in 1854. Also important was forester and ecologist Aldo Leopold, one of the founders of the Wilderness Society in 1935, who wrote a classic of nature observation and ethical philosophy, "A Sand County Almanac", published in 1949. Other philosophical foundations were established by Ralph Waldo Emerson and Thomas Jefferson.
Anti-nuclear movement.
The anti-nuclear movement in the United States consists of more than 80 anti-nuclear groups which have acted to oppose nuclear power or nuclear weapons, or both, in the United States. These groups include the Abalone Alliance, Clamshell Alliance, Institute for Energy and Environmental Research, Nuclear Information and Resource Service, and Physicians for Social Responsibility. The anti-nuclear movement has delayed construction or halted commitments to build some new nuclear plants, and has pressured the Nuclear Regulatory Commission to enforce and strengthen the safety regulations for nuclear power plants.
Anti-nuclear protests reached a peak in the 1970s and 1980s and grew out of the environmental movement. Campaigns which captured national public attention involved the Calvert Cliffs Nuclear Power Plant, Seabrook Station Nuclear Power Plant, Diablo Canyon Power Plant, Shoreham Nuclear Power Plant, and Three Mile Island. On June 12, 1982, one million people demonstrated in New York City's Central Park against nuclear weapons and for an end to the cold war arms race. It was the largest anti-nuclear protest and the largest political demonstration in American history. International Day of Nuclear Disarmament protests were held on June 20, 1983 at 50 sites across the United States.
There were many Nevada Desert Experience protests and peace camps at the Nevada Test Site during the 1980s and 1990s.
More recent campaigning by anti-nuclear groups has related to several nuclear power plants including the Enrico Fermi Nuclear Power Plant, Indian Point Energy Center, Oyster Creek Nuclear Generating Station, Pilgrim Nuclear Generating Station, Salem Nuclear Power Plant, and Vermont Yankee Nuclear Power Plant. There have also been campaigns relating to the Y-12 Nuclear Weapons Plant, the Idaho National Laboratory, proposed Yucca Mountain nuclear waste repository, the Hanford Site, the Nevada Test Site, Lawrence Livermore National Laboratory, and transportation of nuclear waste from the Los Alamos National Laboratory.
Some scientists and engineers have expressed reservations about nuclear power, including: Barry Commoner, S. David Freeman, John Gofman, Arnold Gundersen, Mark Z. Jacobson, Amory Lovins, Arjun Makhijani, Gregory Minor, Joseph Romm and Benjamin K. Sovacool. Scientists who have opposed nuclear weapons include Linus Pauling and Eugene Rabinowitch.
Antitoxics groups.
Antitoxics groups are a subgroup that is affiliated with the Environmental Movement in the United States, that is primarily concerned with the effects that cities and their by products have on humans. This aspect of the movement is a self-proclaimed "movement of housewives". Concern around the issues of ground water contamination and air pollution rose in the early 1980s and individuals involved in antitoxics groups claim that they are concerned for the health of their families.
A prominent case can be seen in the Love Canal Homeowner's association (LCHA); in this case a housing development was built on a site that had been used for toxic dumping by the Hooker Chemical Company. As a result of this dumping the residents had symptoms of skin irritation, Lois Gibbs, a resident of the development, started a grass routes campaign for reparations. Eventual success led to the government having to purchase homes that were sold in the development.
Federal legislation in the 1970s.
Prior to the 1970s the protection of basic air and water supplies was a matter mainly left to each state. During the 1970s, primary responsibility for clean air and water shifted to the federal government. Growing concerns, both environmental and economic, from cites and towns as well as sportsman and other local groups, and senators such as Maine's Edmund S. Muskie, led to passage of extensive legislation, notably the Clean Air Act of 1970 and the Water Pollution Control Act Amendments of 1972. Other legislation included National Environmental Policy Act (NEPA), signed into law in 1970, which established a United States Environmental Protection Agency and a Council on Environmental Quality; the Marine Protection, Research, and Sanctuaries Act of 1972; the Endangered Species Act of 1973, the Safe Drinking Water Act (1974), the Resource Conservation and Recovery Act (1976), the Water Pollution Control Act Amendments of 1977, which became known as the Clean Water Act, and the Comprehensive Environmental Response, Compensation, and Liability Act, commonly known as the Superfund Act (1980). These laws regulated public drinking water systems, toxic substances, pesticides, and ocean dumping; and protected wildlife, wilderness, and wild and scenic rivers. Moreover, the new laws provide for pollution research, standard setting, contaminated site cleanup, monitoring, and enforcement.
The creation of these laws led to a major shift in the environmental movement. Groups such as the Sierra Club shifted focus from local issues to becoming a lobby in Washington and new groups, for example, the Natural Resources Defense Council and Environmental Defense, arose to influence politics as well. (Larson)
Renewed focus on local action.
In the 1980s President Ronald Reagan sought to curtail scope of environmental protection taking steps such as appointing James G. Watt who was called one of the most "blatantly anti-environmental political appointees". The major environmental groups responded with mass mailings which led to increased membership and donations. The large environmental organization increasingly relied on ties within Washington DC to advance their environmental agenda. At the same time membership in environmental groups became more suburban and urban. Groups such as animal rights, and the gun control lobby became linked with environmentalism while sportsmen, farmers and ranchers were no longer influential in the movement.
When industry groups lobbied to weaken regulation and a backlash against environmental regulations, the so-called wise use movement gained importance and influence. The wise use movement and anti-environmental groups were able to portray environmentalist as out of touch with main-stream values. (Larson)
"Post-environmentalism".
In 2004, with the environmental movement seemingly stalled, some environmentalists started questioning whether "environmentalism" was even a useful political framework. According to a controversial essay titled "" (Michael Shellenberger and Ted Nordhaus, 2004) American environmentalism has been remarkably successful in protecting the air, water, and large stretches of wilderness in North America and Europe, but these environmentalists have stagnated as a vital force for cultural and political change.
Shellenberger and Nordhaus wrote, "Today environmentalism is just another special interest. Evidence for this can be found in its concepts, its proposals, and its reasoning. What stands out is how arbitrary environmental leaders are about what gets counted and what doesn't as 'environmental.' Most of the movement's leading thinkers, funders, and advocates do not question their most basic assumptions about who we are, what we stand for, and what it is that we should be doing." Their essay was followed by a speech in San Francisco called "Is Environmentalism Dead?" by former Sierra Club President, Adam Werbach, who argued for the evolution of environmentalism into a more expansive, relevant and powerful progressive politics. Werbach endorsed building an environmental movement that is more relevant to average Americans, and controversially chose to lead Wal-Mart's effort to take sustainability mainstream.
These "post-environmental movement" thinkers argue that the ecological crises the human species faces in the 21st century are qualitatively different from the problems the environmental movement was created to address in the 1960s and 1970s. They argue that climate change and habitat destruction are global and more complex, therefore demanding far deeper transformations of the economy, the culture and political life. The consequence of environmentalism's outdated and arbitrary definition, they argue, is political irrelevancy.
These "politically neutral" groups tend to avoid global conflicts and view the settlement of inter-human conflict as separate from regard for nature - in direct contradiction to the ecology movement and peace movement which have increasingly close links: while Green Parties, Greenpeace, and groups like the ACTivist Magazine regard ecology, biodiversity, and an end to non-human extinction as an absolute basis for peace, the local groups may not, and see a high degree of global competition and conflict as justifiable if it lets them preserve their own local uniqueness. However, such groups tend not to "burn out" and to sustain for long periods, even generations, protecting the same local treasures.
Local groups increasingly find that they benefit from collaboration, e.g. on consensus decision making methods, or making simultaneous policy, or relying on common legal resources, or even sometimes a common glossary. However, the differences between the various groups that make up the modern environmental movement tend to outweigh such similarities, and they rarely co-operate directly except on a few major global questions. In a notable exception, over 1,000 local groups from around the country united for a single day of action as part of the Step It Up 2007 campaign for real solutions to global warming.
Groups such as The Bioregional Revolution are calling on the need to bridge these differences, as the converging problems of the 21st century they claim compel us to unite and to take decisive action. They promote bioregionalism, permaculture, and local economies as solutions to these problems, overpopulation, global warming, global epidemics, and water scarcity, but most notably to "peak oil"—the prediction that we are likely to reach a maximum in global oil production which could spell drastic changes in many aspects of our everyday lives.
Environmental rights.
Many environmental lawsuits turn on the question of who has standing; are the legal issues limited to property owners, or does the general public have a right to intervene? Christopher D. Stone's 1972 essay, "Should trees have standing?" seriously addressed the question of whether natural objects themselves should have legal rights, including the right to participate in lawsuits. Stone suggested that there was nothing absurd in this view, and noted that many entities now regarded as having legal rights were, in the past, regarded as "things" that were regarded as legally rightless; for example, aliens, children and women. His essay is sometimes regarded as an example of the fallacy of hypostatization.
One of the earliest lawsuits to establish that citizens may sue for environmental and aesthetic harms was Scenic Hudson Preservation Conference v. Federal Power Commission, decided in 1965 by the Second Circuit Court of Appeals. The case helped halt the construction of a power plant on Storm King Mountain in New York State. See also United States environmental law and David Sive, an attorney who was involved in the case.
Role of science.
Conservation biology is an important and rapidly developing field.
One way to avoid the stigma of an "ism" was to evolve early anti-nuclear groups into the more scientific Green Parties, sprout new NGOs such as Greenpeace and Earth Action, and devoted groups to protecting global biodiversity and preventing global warming and climate change. But in the process, much of the emotional appeal, and many of the original aesthetic goals were lost. Nonetheless, these groups have well-defined ethical and political views, backed by science.
Criticisms of the environmental movement.
Some people are skeptical of the environmental movement and feel that it is more deeply rooted in politics than science. Although there have been serious debates about climate change and effects of some pesticides and herbicides that mimic animal sex steroids, science has shown that some of the claims of environmentalists have credence.
Claims made by environmentalists may be perceived as veiled attacks on industry and globalization rather than legitimate environmental concerns. Detractors note that a significant number of environmental theories and predictions have been inaccurate and suggest that the regulations recommended by environmentalists will more likely harm society rather than help nature.
DDT.
Specific examples include when Rachel Carson, in her book "Silent Spring", suggested that the pesticide DDT caused cancer and drastically harmed ecosystems. DDT is highly toxic to aquatic life, including crawfish, daphnids, sea shrimp and many species of fish. However, DDT is also used to control malaria.
Prominent novelist and Harvard Medical School graduate Michael Crichton appeared before the U.S. Senate Committee on Environment and Public Works to address such concerns and recommended the employment of double-blind experimentation in environmental research. Crichton suggested that because environmental issues are so political in nature, policy makers need neutral, conclusive data to base their decisions on, rather than conjecture and rhetoric, and double-blind experiments are the most efficient way to achieve that aim.
A consistent theme acknowledged by both supporters and critics (though more commonly vocalized by critics) of the environmental movement is that we know very little about the Earth we live in. Most fields of environmental studies are relatively new, and therefore what research we have is limited and does not date far enough back for us to completely understand long-term environmental trends. This has led a number of environmentalists to support the use of the precautionary principle in policy making, which ultimately asserts that we don't know how certain actions may affect the environment, and because there is reason to believe they may cause more harm than good we should refrain from such actions.
Elitist.
In the December 1994 "Wild Forest Review," Alexander Cockburn and Jeffrey St. Clair wrote "The mainstream environmental movement was elitist, highly paid, detached from the people, indifferent to the working class, and a firm ally of big government.…The environmental movement is now accurately perceived as just another well-financed and cynical special interest group, its rancid infrastructure supported by Democratic Party operatives and millions in grants from corporate foundations."
Wilderness myth.
Historian and President of the American Historical Association William Cronon has criticized the modern environmental movement for having a romantic idealizations of wilderness. Cronon writes "wilderness serves as the unexamined foundation on which so many of the quasi-religious values of modern environmentalism rest." Cronon claims that "to the extent that we live in an urban-industrial civilization but at the same time pretend to ourselves that our real home is in the wilderness, to just that extent we give ourselves permission to evade responsibility for the lives we actually lead."
Similarly Michael Pollan has argued that the wilderness ethic leads people to dismiss areas whose wildness is less than absolute. In his book Second Nature, Pollan writes that "once a landscape is no longer 'virgin' it is typically written off as fallen, lost to nature, irredeemable."
Debates within the movement.
Within the environmental movement an ideological debate has taken place between those with an ecocentric view point and an anthropocentric view point. The anthropocentric view has been seen as the conservationist approach to the environment with nature viewed, at least in part, as resource to be used by man. In contrast to the conservationist approach the ecocentric view, associated with John Muir, Henry David Thoreau and William Wordsworth referred to as the preservationist movement. This approach sees nature in a more spiritual way. Many environmental historians consider the split between John Muir and Gifford Pinchot. During the preservation / conservation debate the term preservationist become to be seen as a pejorative term.
While the ecocentric view focused on biodiversity and wilderness protection the anthropocentric view focus on urban pollution and social justice. Some environmental writers, for example William Cronon have criticized the ecocentric view as have a dualist view as man being separate from nature. Critics of the anthropocentric view point contend that the environmental movement has been taken over by so-called leftist with an agenda beyond environmental protection.
Several books after the middle of the 20th century contributed to the rise of American environmentalism (as distinct from the longer-established conservation movement), especially among college and university students and the more literate public. One was the publication of the first textbook on ecology, "Fundamentals of Ecology," by Eugene Odum and Howard Odum, in 1953. Another was the appearance of the best-seller "Silent Spring" by Rachel Carson, in 1962. Her book brought about a whole new interpretation on pesticides by exposing their harmful effects in nature. From this book many began referring to Carson as the "mother of the environmental movement". Another influential development was a 1965 lawsuit, Scenic Hudson Preservation Conference v. Federal Power Commission, opposing the construction of a power plant on Storm King Mountain, which is said to have given birth to modern United States environmental law. The wide popularity of "The Whole Earth Catalogs", starting in 1968, was quite influential among the younger, hands-on, activist generation of the 1960s and 1970s. Recently, in addition to opposing environmental degradation and protecting wilderness, an increased focus on coexisting with natural biodiversity has appeared, a strain that is apparent in the movement for sustainable agriculture and in the concept of Reconciliation Ecology.
Environmentalism and politics.
Environmentalists became much more influential in American politics after the creation or strengthening of numerous U.S. environmental laws, including the Clean Air Act and Clean Water Act and the formation of the US Environmental Protection Agency, or EPA in 1970. These successes were followed by the enactment of a whole series of laws regulating waste (Resource Conservation and Recovery Act), toxic substances (Toxic Substances Control Act), pesticides (FIFRA: Federal Insecticide, Fungicide, and Rodenticide Act), clean-up of polluted sites (Superfund), protection of endangered species (Endangered Species Act), and more.
Fewer environmental laws have been passed in the last decade as corporations and other conservative interests have increased their influence over American politics. Corporate cooperation against environmental lobbyists has been organized by the Wise Use group. At the same time, many environmentalists have been turning toward other means of persuasion, such as working with business, community, and other partners to promote sustainable development.
Much environmental activism is directed towards conservation, as well as the prevention or elimination of pollution. However, conservation movements, ecology movements, peace movements, green parties, green- and eco-anarchists often subscribe to very different ideologies, while supporting the same goals as those who call themselves "environmentalists". To outsiders, these groups or factions can appear to be indistinguishable.
As human population and industrial activity continue to increase, environmentalists often find themselves in serious conflict with those who believe that human and industrial activities should not be overly regulated or restricted, such as some libertarians.
Environmentalists often clash with others, particularly "corporate interests," over issues of the management of natural resources, like in the case of the atmosphere as a "carbon dump", the focus of climate change, and global warming controversy. They usually seek to protect commonly owned or unowned resources for future generations.
Those who take issue with new untested technologies are more precisely known, especially in Europe, as political ecologists. They usually seek, in contrast, to preserve the integrity of existing ecologies and ecoregions, and in general are more pessimistic about human "management".
Radical environmentalism.
While most environmentalists are mainstream and peaceful, a small minority are more radical in their approach. Adherents of radical environmentalism and ecological anarchism are involved in direct action campaigns to protect the environment. Some campaigns have employed controversial tactics including sabotage, blockades, and arson, while most use peaceful protests such as marches, tree-sitting, and the like. There is substantial debate within the environmental movement as to the acceptability of these tactics, but almost all environmentalists condemn violent actions that can harm humans.

</doc>
<doc id="10184" url="http://en.wikipedia.org/wiki?curid=10184" title="Environmentalist">
Environmentalist

An environmentalist broadly supports the goals of the environmental movement, "a political and ethical movement that seeks to improve and protect the quality of the natural environment through changes to environmentally harmful human activities". An environmentalist is engaged in or believes in the philosophy of environmentalism.
Environmentalists are sometimes referred to using informal or derogatory terms such as "greenie" and "tree-hugger".
Notable environmentalists.
Some of the notable environmentalists who have been active in lobbying for environmental protection and conservation include:

</doc>
