<doc id="11445" url="http://en.wikipedia.org/wiki?curid=11445" title="Fatherland">
Fatherland

Fatherland is the nation of one's "fathers", "forefathers" or "patriarchs". It can be viewed as a nationalist concept, insofar as it is evocative of emotions related to family ties and links them to national identity and patriotism. It can be compared to motherland and homeland, and some countries will use more than one of these terms. The term was used throughout Germanic language countries ("e.g." in Hermann Broch's novel "The Sleepwalkers"), or often to refer to their homelands much as the word "motherland" does. For example, "Wien Neêrlands Bloed", national anthem of the Netherlands between 1815 and 1932, makes extensive and conspicuous use of the parallel Dutch word.
The Ancient Greek "patris", fatherland, led to "patrios", "of our fathers" and thence to the Latin "patriota" and Old French "patriote", meaning compatriot; from these the English world patriotism is derived. The related Ancient Roman word "Patria" led to similar forms in modern Romance languages.
"Fatherland" was first encountered by the vast majority of citizens in countries that did not themselves use it during World War II, when it was featured in news reports associated with Nazi Germany. German government propaganda used its appeal to nationalism when making references to Germany and the state. It was used in Mein Kampf., and on a sign in a German concentration camp, also signed, Adolf Hitler. As such, the word "Vaterland" and the near English translation "fatherland" are often connotated with National Socialism outside Germany; in Germany, this is not the case.
Groups that refer to their native country as a "fatherland".
Groups that refer to their native country as a "fatherland" include:

</doc>
<doc id="11447" url="http://en.wikipedia.org/wiki?curid=11447" title="Flag of the United States">
Flag of the United States

The national flag of the United States of America, often referred to as the American flag, consists of thirteen equal horizontal stripes of red (top and bottom) alternating with white, with a blue rectangle in the canton (referred to specifically as the "union") bearing fifty small, white, five-pointed stars arranged in nine offset horizontal rows of six stars (top and bottom) alternating with rows of five stars. The 50 stars on the flag represent the 50 states of the United States of America, and the 13 stripes represent the thirteen British colonies that declared independence from the Kingdom of Great Britain, and became the first states in the Union. Nicknames for the flag include the "Stars and Stripes", "Old Glory", and "The Star-Spangled Banner".
History.
The design of the flag has been modified 26 times officially since 1777. The 48-star flag was in effect for 47 years until the 49-star version became official on July 4, 1959. The 50-star flag was ordered by President Eisenhower on August 21, 1959 and was adopted in July 1960. It is the longest-used version of the U.S. flag and has been in use for over 54 years.
First flag.
At the time of the Declaration of Independence in July 1776, the Continental Congress would not legally adopt flags with "stars, white in a blue field" for another year. The flag contemporaneously known as "the Continental Colors" has historically been referred to as the first national flag.
The Continental Navy raised the Colors as the ensign of the fledgling nation in the American War for Independence—likely with the expedient of transforming their previous British red ensigns by adding white stripes—and would use this flag until 1777, when it would form the basis for the subsequent "de jure" designs.
The name "Grand Union" was first applied to the Continental Colors by George Preble in his 1872 history of the American flag.
The flag closely resembles the British East India Company flag of the era, and Sir Charles Fawcett argued in 1937 that the Company flag inspired the design. Both flags could have been easily constructed by adding white stripes to a British Red Ensign, one of the three maritime flags used throughout the British Empire at the time. However, an East India Company flag could have from nine to 13 stripes, and was not allowed to be flown outside the Indian Ocean.
In any case, both the stripes (barry) and the stars (mullets) have precedents in classical heraldry. Mullets were comparatively rare in early modern heraldry, but an example of mullets representing territorial divisions predating the U.S. flag are those in the coat of arms of Valais of 1618, where seven mullets stood for seven districts.
The first American flags were made out of hemp.
The Flag Resolution of 1777.
On June 14, 1777, the Second Continental Congress passed the Flag Resolution which stated: ""Resolved," That the flag of the thirteen United States be thirteen stripes, alternate red and white; that the union be thirteen stars, white in a blue field, representing a new constellation." Flag Day is now observed on June 14 of each year. While scholars still argue about this, tradition holds that the new flag was first hoisted in June 1777 by the Continental Army at the Middlebrook encampment.
The first official U.S. flag flown during battle was on August 3, 1777 at Fort Schuyler (Fort Stanwix) during the Siege of Fort Stanwix. Massachusetts reinforcements brought news of the adoption by Congress of the official flag to Fort Schuyler. Soldiers cut up their shirts to make the white stripes; scarlet material to form the red was secured from red flannel petticoats of officers' wives, while material for the blue union was secured from Capt. Abraham Swartwout's blue cloth coat. A voucher is extant that Capt. Swartwout of Dutchess County was paid by Congress for his coat for the flag.
The 1777 resolution was most probably meant to define a naval ensign. In the late 18th century, the notion of a national flag did not yet exist, or was only nascent. The flag resolution appears between other resolutions from the Marine Committee. On May 10, 1779, Secretary of the Board of War Richard Peters expressed concern "it is not yet settled what is the Standard of the United States." However, the term, "Standard," referred to a national standard for the Army of the United States. Each regiment was to carry the national standard in addition to its regimental standard. The national standard was not a reference to the national or naval flag.
The Flag Resolution did not specify any particular arrangement, number of points, nor orientation for the stars and the arrangement or whether the flag had to have seven red stripes and six white ones or vice versa. The appearance was up to the maker of the flag. Some flag makers arranged the stars into one big star, in a circle or in rows and some replaced a state's star with its initial. One arrangement features 13 five-pointed stars arranged in a circle, with the stars arranged pointing outwards from the circle (as opposed to up), the so-called Betsy Ross flag. This flag, however, is more likely a flag used for celebrations of anniversaries of the nation's birthday. Experts have dated the earliest known example of this flag to be 1792 in a painting by John Trumbull.
Despite the 1777 resolution, the early years of American independence featured many different flags. Most were individually crafted rather than mass-produced. While there are many examples of 13-star arrangements, some of those flags included blue stripes as well as red and white. Benjamin Franklin and John Adams, in a letter dated October 3, 1778, to the King of the Two Sicilies, described the American flag as consisting of "13 stripes, alternately red, white, and blue, a small square in the upper angle, next the flag staff, is a blue field, with 13 white stars, denoting a new Constellation." John Paul Jones used a variety of 13-star flags on his U.S. Navy ships including the well-documented 1779 flags of the Serapis and the Alliance. The Serapis flag had three rows of eight-pointed stars with stripes that were red, white, and blue. The flag for the "Alliance", however, had five rows of eight-pointed stars with 13 red and white stripes, and the white stripes were on the outer edges. Both flags were documented by the Dutch government in October 1779, making them two of the earliest known flags of 13 stars.
Designer of the first stars and stripes.
Francis Hopkinson of New Jersey a naval flag designer, and a signer of the Declaration of Independence, designed the 1777 flag while he was the Chairman of the Continental Navy Board's Middle Department, sometime between his appointment to that position in November 1776 and the time that the flag resolution was adopted in June 1777. The Navy Board was under the Continental Marine Committee. Not only did Hopkinson claim that he designed the U.S. flag, but he also claimed that he designed a flag for the U.S. Navy. Hopkinson was the only person to have made such a claim during his own lifetime, when he sent a letter and several bills to Congress for his work. These claims are documented in the Journals of the Continental Congress and George Hasting's biography of Hopkinson. Hopkinson initially wrote a letter to Congress, via the Continental Board of Admiralty. In this letter, he asked for a "Quarter Cask of the Public Wine" as payment for designing the U.S. Flag, the seal for the Admiralty Board, the seal for the Treasury Board, Continental currency, the Great Seal of the United States, and other devices. However, in three subsequent bills to Congress, Hopkinson asked to be paid in cash, but he did not list his U.S. Flag design. Instead, he asked to be paid for designing the “great Naval Flag of the United States” in the first bill; the “Naval Flag of the United States” in the second bill; and “the Naval Flag of the States” in the third, along with the other items. The flag references were generic terms for the naval ensign that Hopkinson had designed, that is, a flag of seven red stripes and six white ones. The predominance of red stripes made the naval flag more visible against the sky on a ship at sea. By contrast, Hopkinson’s flag for the United States had seven white stripes, and six red ones – in reality, six red stripes laid on a white background. Hopkinson’s sketches have not been found, but we can make these conclusions because Hopkinson incorporated different stripe arrangements in the Admiralty (naval) Seal that he designed in the Spring of 1780 and the Great Seal of the United States that he proposed at the same time. His Admiralty Seal had seven red stripes; whereas, his second U.S. Seal proposal had seven white ones. Hopkinson’s flag for the Navy is the one that the Nation preferred as the national flag. Remnants of Hopkinson’s U.S. Flag of seven white stripes can be found in the Great Seal of the United States and the President’s seal. When Hopkinson was chairman of the Navy Board, his position was like that of today’s Secretary of the Navy. The payment was not made, however, because it was determined he had already received a salary as a member of Congress. This definitively contradicts the legend of the Betsy Ross flag, which suggests that she sewed the first Stars and Stripes flag by request of the government in the Spring of 1776. Furthermore, a letter from the War Board to George Washington on May 10, 1779, documents that there was still no design established for a national flag for the Army's use in battle.
The origin of the stars and stripes design has been muddled by a story disseminated by the descendants of Betsy Ross. The apocryphal story credits Betsy Ross for sewing the first flag from a pencil sketch handed to her by George Washington. No evidence for this exists either in the diaries of George Washington nor in the records of the Continental Congress. Indeed, nearly a century passed before Ross' grandson, William Canby, first publicly suggested the story in 1870. By her family's own admission, Ross ran an upholstery business, and she had never made a flag as of the supposed visit in June 1776. Furthermore, her grandson admitted that his own search through the Journals of Congress and other official records failed to find corroboration of his grandmother's story.
The family of Rebecca Young claimed that she sewed the first flag. Young's daughter was Mary Pickersgill, who made the Star Spangled Banner Flag. According to rumor, the Washington family coat of arms, shown in a 15th-century window of Selby Abbey, was the origin of the stars and stripes.
Later flag acts.
In 1795, the number of stars and stripes was increased from 13 to 15 (to reflect the entry of Vermont and Kentucky as states of the Union). For a time the flag was not changed when subsequent states were admitted, probably because it was thought that this would cause too much clutter. It was the 15-star, 15-stripe flag that inspired Francis Scott Key to write "Defence of Fort M'Henry", later known as "The Star Spangled Banner", which is now the American national anthem. The flag is currently on display in the exhibition, "The Star-Spangled Banner: The Flag That Inspired the National Anthem" at the Smithsonian Institution National Museum of American History in a two-story display chamber that protects the flag while it is on view.
On April 4, 1818, a plan was passed by Congress at the suggestion of U.S. Naval Captain Samuel C. Reid in which the flag was changed to have 20 stars, with a new star to be added when each new state was admitted, but the number of stripes would be reduced to 13 so as to honor the original colonies. The act specified that new flag designs should become official on the first July 4 (Independence Day) following admission of one or more new states. The most recent change, from 49 stars to 50, occurred in 1960 when the present design was chosen, after Hawaii gained statehood in August 1959. Before that, the admission of Alaska in January 1959 prompted the debut of a short-lived 49-star flag.
Prior to the adoption of the 48-star flag in 1912, there was no official arrangement of the stars in the canton, although the U.S. Army and U.S. Navy used standardized designs. Throughout the 19th century there was an abundance of different star patterns, rectangular and circular.
On July 4, 2007, the 50-star flag became the version of the flag in longest use, surpassing the 48-star flag that was used from 1912 to 1959.
The "Flower Flag" arrives in Asia.
The U.S. flag was brought to the city of Canton (Guǎngzhōu) in China in 1785 by the merchant ship "Empress of China", which carried a cargo of ginseng. There it gained the designation "Flower Flag" (). According to a pseudonymous account first published in the "Boston Courier" and later retold by author and U.S. naval officer George H. Preble:
When the thirteen stripes and stars first appeared at Canton, much curiosity was excited among the people. News was circulated that a strange ship had arrived from the further end of the world, bearing a flag "as beautiful as a flower." Every body went to see the "kwa kee chuen" [], or "flower flagship." This name at once established itself in the language, and America is now called the "kwa kee kwoh" [], the "flower flag country"—and an American, "kwa kee kwoh yin" []—"flower flag countryman"—a more complimentary designation than that of "red headed barbarian"—the name first bestowed upon the Dutch.
In the above quote, the Chinese words are written phonetically based on spoken Cantonese. The names given were common usage in the nineteenth and early twentieth centuries. Other Asian nations have equivalent terms for America, for example Vietnamese: "Hoa Kỳ" ("Flower Flag"). Chinese now refer to the United States as . "Měi" is short for "Měilìjiān" (a Chinese pronunciation of "America") and "guó" means "country", so this name is unrelated to the flag. However, the "flower flag" terminology persists in some places today; for example, American Ginseng is called in Chinese.
The U.S. flag took its first trip around the world in 1787–90 on board the "Columbia". William Driver, who coined the phrase "Old Glory", took the U.S. flag around the world in 1831–32. The flag attracted the notice of Japanese when an oversized version was carried to Yokohama by the steamer "Great Republic" as part of a round-the-world journey in 1871.
Historical progression of designs.
In the following table depicting the 28 various designs of the United States flag, the star patterns for the flags are merely the "usual" patterns, often associated with the United States Navy. Canton designs, prior to the proclamation of the 48-star flag, had no official arrangement of the stars. Furthermore, the exact "colors" of the flag were not standardized until 1934.
Symbolism.
The modern meaning of the flag was forged in December 1860, when Major Robert Anderson moved the U.S. garrison from Fort Moultrie to Fort Sumter in Charleston Harbor. Adam Goodheart argues this was the opening move of the American Civil War, and the flag was used throughout northern states to symbolize American nationalism and rejection of secessionism.
Before that day, the flag had served mostly as a military ensign or a convenient marking of American territory, flown from forts, embassies, and ships, and displayed on special occasions like American Independence day. But in the weeks after Major Anderson's surprising stand, it became something different. Suddenly the Stars and Stripes flew—as it does today, and especially as it did after the September 11 attacks in 2001—from houses, from storefronts, from churches; above the village greens and college quads. For the first time American flags were mass-produced rather than individually stitched and even so, manufacturers could not keep up with demand. As the long winter of 1861 turned into spring, that old flag meant something new. The abstraction of the Union cause was transfigured into a physical thing: strips of cloth that millions of people would fight for, and many thousands die for.—Adam Goodheart, Prologue of "" (2011).
The flag of the United States is one of the nation's most widely recognized symbols. Within the United States, flags are frequently displayed not only on public buildings but on private residences. The flag is a common motif on decals for car windows, and clothing ornaments such as badges and lapel pins. Throughout the world the flag has been used in public discourse to refer to the United States.
The flag has become a powerful symbol of Americanism, and is proudly flown on many occasions, with giant outdoor flags used by retail outlets to draw customers. Desecration of the flag is considered a public outrage, but remains protected as freedom of speech. In worldwide comparison, Testi noted in 2010 that the United States was not unique in adoring its banner, for the flags of Scandinavian countries are also "beloved, domesticated, commercialized and sacralized objects".
Design.
Creation.
The man credited with designing the current 50 star American flag was Robert G. Heft. He was 17 years old at the time and created the flag design in 1958 as a high school class project while living with his grandparents in Ohio. He received a B− on the project.
Specifications.
The basic design of the current flag is specified by #redirect ; #redirect outlines the addition of new stars to represent new states. The gives the following values:
These specifications are contained in an executive order which, strictly speaking, governs only flags made for or by the U.S. federal government. In practice, most U.S. national flags available for sale to the public have a different width-to-height ratio; common sizes are 2 × 3 ft. or 4 × 6 ft. (flag ratio 1.5), 2.5 × 4 ft. or 5 × 8 ft. (1.6), or 3 × 5 ft. or 6 × 10 ft. (1.667). Even flags flown over the U.S. Capitol for sale to the public through Representatives or Senators are provided in these sizes. Flags that are made to the prescribed 1.9 ratio are often referred to as "G-spec" (for "government specification") flags.
Colors.
The exact red, white, and blue colors to be used in the flag are specified with reference to the CAUS Standard Color Reference of America, 10th edition. Specifically, the colors are "White", "Old Glory Red", and "Old Glory Blue". The CIE coordinates for the colors of the 9th edition of the Standard Color Card were formally specified in "JOSA" in 1946. These colors form the standard for cloth, and there is no perfect way to convert them to RGB for display on screen or CMYK for printing. The "relative" coordinates in the following table were found by scaling the luminous reflectance relative to the flag's "white".
As with the design, the official colors are only officially required for flags produced for the U.S. federal government, and other colors are often used for mass-market flags, printed reproductions, and other products intended to evoke flag colors. The practice of using more saturated colors than the official cloth is not new. As Taylor, Knoche, and Granville wrote in 1950: "The color of the official wool bunting [of the blue field] is a very dark blue, but printed reproductions of the flag, as well as merchandise supposed to match the flag, present the color as a deep blue much brighter than the official wool."
Sometimes, Pantone Matching System (PMS) approximations to the flag colors are used. One set was given on the website of the U.S. embassy in London as early as 1998; the website of the U.S. embassy in Stockholm claimed in 2001 that those had been suggested by Pantone, and that the U.S. Government Printing Office preferred a different set. A third red was suggested by a California Military Department document in 2002. In 2001, the Texas legislature specified that the colors of the Texas flag should be "(1) the same colors used in the United States flag; and (2) defined as numbers 193 (red) and 281 (dark blue) of the Pantone Matching System."
The 49- and 50-star unions.
When Alaska and Hawaii were being considered for statehood in the 1950s, more than 1,500 designs were submitted to President Dwight D. Eisenhower. Although some of them were 49-star versions, the vast majority were 50-star proposals. At least three of these designs were identical to the present design of the 50-star flag. At the time, credit was given by the executive department to the United States Army Institute of Heraldry for the design.
Of these proposals, one created by 17-year-old Robert G. Heft in 1958 as a school project received the most publicity. His mother was a seamstress, but refused to do any of the work for him. He originally received a B– for the project. After discussing the grade with his teacher, it was agreed (somewhat jokingly) that if the flag was accepted by Congress, the grade would be reconsidered. Heft's flag design was chosen and adopted by presidential proclamation after Alaska and before Hawaii was admitted into the Union in 1959. According to Heft, his teacher did keep to their agreement and changed his grade to an A for the project. Both the 49- and 50-star flags were each flown for the first time ever at Fort McHenry on Independence Day one year apart, 1959 and 1960 respectively.
Decoration.
Traditionally, the flag may be decorated with golden fringe surrounding the perimeter of the flag as long as it does not deface the flag proper. Ceremonial displays of the flag, such as those in parades or on indoor posts, often use fringe to enhance the beauty of the flag.
The first recorded use of fringe on a flag dates from 1835, and the Army used it officially in 1895. No specific law governs the legality of fringe, but a 1925 opinion of the attorney general addresses the use of fringe (and the number of stars) "... is at the discretion of the Commander in Chief of the Army and Navy ..." as quoted from footnote in previous volumes of Title 4 of the United States Code law books and is a source for claims that such a flag is a military ensign not civilian. However, according to the Army Institute of Heraldry, which has official custody of the flag designs and makes any change ordered, there are no implications of symbolism in the use of fringe. Several federal courts have upheld this conclusion, most recently and forcefully in "Colorado v. Drew", a Colorado Court of Appeals judgment that was released in May 2010. Traditionally, the Army and Air Force use a fringed National Color for parade, color guard and indoor display, while the Sea Services (Navy, Marine Corps and Coast Guard) use a fringeless National Color for all uses.
Display and use.
The flag is customarily flown year-round at most public buildings, and it is not unusual to find private houses flying full-size (3 by) flags. Some private use is year-round, but becomes widespread on civic holidays like Memorial Day, Veterans Day, Presidents' Day, Flag Day, and on Independence Day. On Memorial Day it is common to place small flags by war memorials and next to the graves of U.S. war veterans. Also on Memorial Day it is common to fly the flag at half staff, until noon, in remembrance of those who lost their lives fighting in U.S. wars.
Flag etiquette.
The United States Flag Code outlines certain guidelines for the use, display, and disposal of the flag. For example, the flag should never be dipped to any person or thing, unless it is the ensign responding to a salute from a ship of a foreign nation. This tradition may come from the 1908 Summer Olympics in London, where countries were asked to dip their flag to King Edward VII: the American flag bearer did not. Team captain Martin Sheridan is famously quoted as saying "this flag dips to no earthly king", though the true provenance of this quotation is unclear.
The flag should never be allowed to touch the ground and, if flown at night, must be illuminated. If the edges become tattered through wear, the flag should be repaired or replaced. When a flag is so tattered that it can no longer serve as a symbol of the United States, it should be destroyed in a dignified manner, preferably by burning. The American Legion and other organizations regularly conduct flag retirement ceremonies, often on Flag Day, June 14. (The Boy Scouts of America recommends that modern nylon or polyester flags be recycled instead of burned, due to hazardous gases being produced when such materials are burned.)
The Flag Code prohibits using the flag "for any advertising purpose" and also states that the flag "should not be embroidered, printed, or otherwise impressed on such articles as cushions, handkerchiefs, napkins, boxes, or anything intended to be discarded after temporary use". Both of these codes are generally ignored, almost always without comment.
Section 8, entitled Respect For Flag states in part: "The flag should never be used as wearing apparel, bedding, or drapery", and "No part of the flag should ever be used as a costume or athletic uniform". Section 3 of the Flag Code defines "the flag" as anything "by which the average person seeing the same without deliberation may believe the same to represent the flag of the United States of America".
An additional part of Section 8 Respect For Flag, that is frequently violated at sporting events is part (c) "The flag should never be carried flat or horizontally, but always aloft and free."
Although the Flag Code is U.S. federal law, there is no penalty for a private citizen or group failing to comply with the Flag Code and it is not widely enforced—indeed, punitive enforcement would conflict with the First Amendment right to freedom of speech. Passage of the proposed Flag Desecration Amendment would overrule legal precedent that has been established.
Display on vehicles.
When the flag is affixed to the right side of a vehicle of any kind (e.g.: cars, boats, planes, any physical object that moves), it should be oriented so that the canton is towards the front of the vehicle, as if the flag were streaming backwards from its hoist as the vehicle moves forward. Therefore, U.S. flag decals on the right sides of vehicles may appear to be reversed, with the union to the observer's right instead of left as more commonly seen.
The flag has been displayed on every U.S. spacecraft designed for manned flight, including Mercury, Gemini, Apollo Command/Service Module, Apollo Lunar Module, and the Space Shuttle. The flag also appeared on the S-IC first stage of the Saturn V launch vehicle used for Apollo. But since Mercury, Gemini, and Apollo were launched and landed vertically and were not capable of horizontal atmospheric flight like an airplane, the "streaming" convention was not followed and these flags were oriented with the stripes running horizontally, perpendicular to the direction of flight.
Display on uniforms.
On some U.S. military uniforms, flag patches are worn on the right shoulder, following the vehicle convention with the union toward the front. This rule dates back to the Army's early history, when both mounted cavalry and infantry units would designate a standard bearer, who carried the Colors into battle. As he charged, his forward motion caused the flag to stream back. Since the Stars and Stripes are mounted with the canton closest to the pole, that section stayed to the right, while the stripes flew to the left. Several US military uniforms, such as flight suits worn by members of the United States Navy, have the flag patch on the left shoulder.
Other organizations that wear flag patches on their uniforms can have the flag facing in either direction. The congressional charter of the Boy Scouts of America stipulates that the uniforms should not imitate U.S. military uniforms; consequently, the flags are displayed on the right shoulder with the stripes facing front, the reverse of the military style. Law enforcement officers often wear a small flag patch, either on a shoulder, or above a shirt pocket.
Every U.S. astronaut since the crew of Gemini 4 has worn the flag on the left shoulder of his or her space suit, with the exception of the crew of Apollo 1, whose flags were worn on the right shoulder. In this case, the canton was on the left.
Postage stamps.
The flag did not appear on U.S. postal stamp issues until the Battle of White Plains Issue was released in 1926, depicting the flag with a circle of 13 stars. The 48-star flag first appeared on the General Casimir Pulaski issue of 1931, though in a . The first U.S. postage stamp to feature the flag as the sole subject was issued July 4, 1957, Scott catalog number 1094. Since that time the flag has frequently appeared on U.S. stamps.
Display in museums.
In 1907 Eben Appleton, New York stockbroker and grandson of Lieutenant Colonel George Armistead
(the commander of Fort McHenry during the 1814 bombardment) lent the Star Spangled Banner Flag to the Smithsonian Institution, and in 1912 he converted the loan to a gift. Appleton donated the flag with the wish that it would always be on view to the public. In 1994, the National Museum of American History determined that the Star Spangled Banner Flag required further conservation treatment to remain on public display. In 1998 teams of museum conservators, curators, and other specialists helped move the flag from its home in the Museum's Flag Hall into a new conservation laboratory. Following the reopening of the National Museum of American History on November 21, 2008, the flag is now on display in a special exhibition, "The Star-Spangled Banner: The Flag That Inspired the National Anthem," where it rests at a 10 degree angle in dim light for conservation purposes.
Places of continuous display.
By presidential proclamation, acts of Congress, and custom, U.S. flags are displayed continuously at certain locations.
Particular days for display.
The flag should especially be displayed at full staff on the following days:
Display at half-staff.
The flag is displayed at half-staff (half-mast in naval usage) as a sign of respect or mourning. Nationwide, this action is proclaimed by the president; statewide or territory-wide, the proclamation is made by the governor. In addition, there is no prohibition against municipal governments, private businesses or citizens flying the flag at half-staff as a local sign of respect and mourning. However, many flag enthusiasts feel this type of practice has somewhat diminished the meaning of the original intent of lowering the flag to honor those who held high positions in federal or state offices. President Dwight D. Eisenhower issued the first proclamation on March 1, 1954, standardizing the dates and time periods for flying the flag at half-staff from all federal buildings, grounds, and naval vessels; other congressional resolutions and presidential proclamations ensued. However, they are only guidelines to all other entities: typically followed at state and local government facilities, and encouraged of private businesses and citizens.
To properly fly the flag at half-staff, one should first briefly hoist it top of the staff, then lower it to the half-staff position, halfway between the top and bottom of the staff. Similarly, when the flag is to be lowered from half-staff, it should be first briefly hoisted to the top of the staff.
Federal statutes provide that the flag should be flown at half-staff on the following dates:
National Korean War Veterans Armistice Day, on July 27, was formerly a day of half-staff observance until the law expired in 2003. Upon its re-enactment in 2009, it became a day of full-staff observance.
Folding for storage.
Though not part of the official Flag Code, according to military custom, flags should be folded into a triangular shape when not in use. To properly fold the flag:
There is also no specific meaning for each fold of the flag. However, there are scripts read by non-government organizations and also by the Air Force that are used during the flag folding ceremony. These scripts range from historical timelines of the flag to religious themes.
Use in funerals.
Traditionally, the flag of the United States plays a role in military funerals, and occasionally in funerals of other civil servants (such as law enforcement officers, fire fighters, and U.S. presidents). A burial flag is draped over the deceased's casket as a pall during services. Just prior to the casket being lowered into the ground, the flag is ceremonially folded and presented to the deceased's next of kin as a token of respect.

</doc>
<doc id="11448" url="http://en.wikipedia.org/wiki?curid=11448" title="Federated States of Micronesia">
Federated States of Micronesia

The Federated States of Micronesia (; abbreviated FSM) is an independent sovereign island nation and a United States associated state consisting of four states – from west to east, Yap, Chuuk, Pohnpei and Kosrae – that are spread across the Western Pacific Ocean. Together, the states comprise around 607 islands (a combined land area of approximately 702 km2) that cover a longitudinal distance of almost 2700 km just north of the equator. They lie northeast of New Guinea, south of Guam and the Marianas, west of Nauru and the Marshall Islands, east of Palau and the Philippines, about 2900 km north of eastern Australia and some 4000 km southwest of the main islands of Hawaii.
While the FSM's total land area is quite small, it occupies more than 2600000 km2 of the Pacific Ocean. The capital is Palikir, located on Pohnpei Island, while the largest city is Weno, located in the Chuuk Atoll.
Each of its four states is centered on one or more main high islands, and all but Kosrae include numerous outlying atolls. The Federated States of Micronesia is spread across part of the Caroline Islands in the wider region of Micronesia, which consists of thousands of small islands divided among several countries. The term "Micronesia" may refer to the Federated States or to the region as a whole.
The FSM was formerly a part of the Trust Territory of the Pacific Islands (TTPI), a United Nations Trust Territory under U.S. administration, but it formed its own constitutional government on May 10, 1979, becoming a sovereign state after independence was attained on November 3, 1986 under a Compact of Free Association with the United States. Other neighboring island entities, and also former members of the TTPI, formulated their own constitutional governments and became the Republic of the Marshall Islands (RMI) and the Republic of Palau (ROP). The FSM has a seat in the United Nations.
History.
The ancestors of the Micronesians settled over four thousand years ago. A decentralized chieftain-based system eventually evolved into a more centralized economic and religious empire centered on Yap.
Nan Madol, consisting of a series of small artificial islands linked by a network of canals, is often called the Venice of the Pacific. It is located on the eastern periphery of the island of Pohnpei and used to be the ceremonial and political seat of the Saudeleur dynasty that united Pohnpei's estimated 25,000 people from about AD 500 until 1500, when the centralized system collapsed.
European explorers—first the Portuguese in search of the Spice Islands (Indonesia) and then the Spanish—reached the Carolines in the sixteenth century. The Spanish incorporated the archipelago to the Spanish East Indies and in the 19th century established a number of outposts and missions. In 1887 they founded the town of "Santiago de la Ascension" in what today is Kolonia on the island of Pohnpei. Following the Spanish–American War the Spanish sold the archipelago to Germany in 1899. It was awarded to the Empire of Japan following World War I as a League of Nations mandate.
During World War II, a significant portion of the Japanese fleet was based in Truk Lagoon. In February 1944, Operation Hailstone, one of the most important naval battles of the war, took place at Truk, in which many Japanese support vessels and aircraft were destroyed.
Following World War II, it was administered by the United States under United Nations auspices in 1947 as part of the Trust Territory of the Pacific Islands.
On May 10, 1979, four of the Trust Territory districts ratified a new constitution to become the Federated States of Micronesia. Palau, the Marshall Islands, and the Northern Mariana Islands chose not to participate. The FSM signed a Compact of Free Association with the United States, which entered into force on November 3, 1986, marking Micronesia's emergence from trusteeship to independence. The Compact was renewed in 2004.
Politics.
The Federated States of Micronesia is governed by the 1979 constitution, which guarantees fundamental human rights and establishes a separation of governmental powers. The unicameral Congress has fourteen members elected by popular vote. Four senators—one from each state—serve four-year terms; the remaining ten senators represent single-member districts based on population, and serve two-year terms. The President and Vice President are elected by Congress from among the four state-based senators to serve four-year terms in the executive branch. Their congressional seats are then filled by special elections.
The president and vice president are supported by an appointed cabinet. There are no formal political parties.
In international politics, the Federated States of Micronesia has often voted with the United States with respect to United Nations General Assembly resolutions.
Administrative divisions.
The four states in the federation are:
These states are further divided into municipalities.
Geography.
The Federated States of Micronesia consists of 607 islands extending 2900 km across the archipelago of the Caroline Islands east of the Philippines. The islands have a combined area of 702 km2.
The islands are grouped into four states, which are Yap, Chuuk (called Truk until January 1990), Pohnpei (known as "Ponape" until November 1984), and Kosrae (formerly Kusaie). These four states are each represented by a white star on the national flag. The capital is Palikir, on Pohnpei.
Economy.
Economic activity in the Federated States of Micronesia consists primarily of subsistence farming and fishing. The islands have few mineral deposits worth exploiting, except for high-grade phosphate. Long line fishing of tuna is also viable with foreign vessels from China operated in the 1990s. The potential for a tourist industry exists, but the remoteness of the location and a lack of adequate facilities hinder development. Financial assistance from the U.S. is the primary source of revenue, with the U.S. pledged to spend $1.3 billion in the islands in 1986–2001; the CIA World Factbook lists high dependence on U.S. aid as one of the main concerns of the FSM. Geographical isolation and a poorly developed infrastructure are major impediments to long-term growth.
Transportation.
The Federated States of Micronesia is served by four international airports.
Demographics.
The indigenous population of the nation, which is predominantly Micronesian, consists of various ethnolinguistic groups. It has a nearly 100% Pacific Islander and Asian population. Chuukese 48.8%, Pohnpeian 24.2%, Kosraean 6.2%, Yapese 5.2%, Yap outer islands 4.5%, Asian 1.8%, Polynesian 1.5%, other 6.4%, unknown 1.4%. A sizeable minority also have some Japanese ancestry, which is a result of intermarriages between Japanese settlers and Micronesians during the Japanese colonial period.
There is also growing expatriate population of Americans, Australians, Europeans, and residents from China and the Philippines since the 1990s. English has become the common language of the government, and for secondary and tertiary education. Outside of the main capital towns of the four FSM states, the local languages are primarily spoken. Population growth remains high at more than 3% annually, offset somewhat by net emigration. Pohnpei is notable for the prevalence of the extreme form of color blindness known as maskun.
Culture.
Each of the four States has its own culture and traditions, but there are also common cultural and economic bonds that are centuries old. For example, cultural similarities like the importance of the traditional extended family and clan systems can be found on all the islands.
The island of Yap is notable for its "stone money" (Rai stones), large disks usually of calcite, up to 4 m (about 13 ft) in diameter, with a hole in the middle. The islanders, aware of the owner of a piece, do not necessarily move them when ownership changes. There are five major types: "Mmbul", "Gaw", "Ray", "Yar", and "Reng", the last being only 30 cm in diameter. Their value is based on both size and history, many of them having been brought from other islands, as far as New Guinea, but most coming in ancient times from Palau. Approximately 6,500 of them are scattered around the island.
Languages.
English is the official and common language. Also spoken are Chuukese (Trukese), Kosraean, Pohnpeian, Yapese, and Woleaian.
Other languages spoken in the country include Pingelapese, Ngatikese, Satawalese, Puluwatese, Mortlockese, and Mokilese. There are also about 3,000 speakers of Kapingamarangi and Ulithian, and under 1,000 speakers of Nukuoro.
Literature.
There have been few published literary writers from the Federated States of Micronesia. In 2008, Emelihter Kihleng became the first ever Micronesian to publish a collection of poetry in the English language.
Religion.
Several Protestant denominations, as well as the Roman Catholic Church, are present in every Micronesian state. Most Protestant groups trace their roots to American Congregationalist missionaries. On the island of Kosrae, the population is approximately 7,800; 95 percent are Protestants. On Pohnpei, the population of 35,000 is evenly divided between Protestants and Catholics. On Chuuk and Yap, an estimated 60 percent are Catholic and 40 percent are Protestant. Religious groups with small followings include Baptists, Assemblies of God, Salvation Army, Seventh-day Adventists, Jehovah's Witnesses, The Church of Jesus Christ of Latter-day Saints (Mormons), and the Baha'i Faith. There is a small group of Buddhists on Pohnpei. Attendance at religious services is generally high; churches are well supported by their congregations and play a significant role in civil society.
Most immigrants are Filipino Catholics who have joined local Catholic churches. The Filipino Iglesia ni Cristo also has a church in Pohnpei. In the 1890s, on the island of Pohnpei, intermissionary conflicts and the conversion of clan leaders resulted in religious divisions along clan lines which persist today. More Protestants live on the western side of the island, while more Catholics live on the eastern side. Missionaries of many religious traditions are present and operate freely. The Constitution provides for freedom of religion, and the Government generally respected this right in practice. The US government received no reports of societal abuses or discrimination based on religious belief or practice in 2007.
Defense and foreign affairs.
The FSM is a sovereign, self-governing state in free association with the United States, which is wholly responsible for its defense. The Division of Maritime Surveillance operates a paramilitary Maritime Wing and a small Maritime Police Unit. The Compact of Free Association allows FSM citizens to join the U.S. military without having to obtain U.S. permanent residency or citizenship, allows for immigration and employment for Micronesians in the U.S., and establishes economic and technical aid programs.
FSM has foreign relations with 56 countries, including the Holy See. The FSM is an active member of the Pacific Islands Forum.

</doc>
<doc id="11449" url="http://en.wikipedia.org/wiki?curid=11449" title="Frederick William, Elector of Brandenburg">
Frederick William, Elector of Brandenburg

Frederick William (German: "Friedrich Wilhelm") (16 February 1620 – 29 April 1688) was Elector of Brandenburg and Duke of Prussia – and thus ruler of Brandenburg-Prussia – from 1640 until his death. A member of the House of Hohenzollern, he is popularly known as "the Great Elector" ("der Große Kurfürst") because of his military and political prowess. Frederick William was a staunch pillar of the Calvinist faith, associated with the rising commercial class. He saw the importance of trade and promoted it vigorously. His shrewd domestic reforms gave Prussia a strong position in the post-Westphalian political order of north-central Europe, setting Prussia up for elevation from duchy to kingdom, achieved under his son and successor.
Biography.
Elector Frederick William was born in Berlin to George William, Elector of Brandenburg, and Elisabeth Charlotte of the Palatinate. His inheritance consisted of the Margraviate of Brandenburg, the Duchy of Cleves, the County of Mark, and the Duchy of Prussia.
Foreign diplomacy.
During the Thirty Years' War, George William strove to maintain, with a minimal army, a delicate balance between the Protestant and Catholic forces fighting throughout the Holy Roman Empire. Out of these unpromising beginnings Frederick William managed to rebuild his war-ravaged territories. In contrast to the religious disputes that disrupted the internal affairs of other European states, Brandenburg-Prussia benefited from the policy of religious tolerance adopted by Frederick William. With the help of French subsidies, he built up an army to defend the country. In the Second Northern War, he was forced to accept Swedish vassalage for the Duchy of Prussia according to the terms of the Treaty of Königsberg (1656), but as the war progressed he succeeded in gaining full sovereignty for the Prussian duchy in the treaties of Labiau, Wehlau, Bromberg and Oliva, leaving the Holy Roman Emperor as his only liege for his imperial holdings.
In the conflict for Pomerania inheritance, Frederick William had to accept two setbacks, one in the Northern War and one in the Scanian War. Though militarily successful in Swedish Pomerania, he had to bow to France's demands and return his gains to Sweden in the Treaty of Saint-Germain-en-Laye (1679).
Military career.
Frederick William was a military commander of wide renown, and his standing army would later become the model for the Prussian Army. He is notable for his joint victory with Swedish forces at the Battle of Warsaw (1656), which, according to Hajo Holborn, marked "the beginning of Prussian military history", but the Swedes turned on him at the behest of King Louis XIV of France and invaded Brandenburg. After marching 250 kilometres in 15 days back to Brandenburg, he caught the Swedes by surprise and managed to defeat them on the field at the Battle of Fehrbellin, destroying the myth of Swedish military invincibility. He later destroyed another Swedish army that invaded the Duchy of Prussia during the Great Sleigh Drive in 1678. He is noted for his use of broad directives and delegation of decision-making to his commanders, which would later become the basis for the German doctrine of Auftragstaktik, and he is noted for using rapid mobility to defeat his foes.
Domestic policies.
Frederick William is notable for raising an army of 40,000 soldiers by 1678, through the General War Commissariat presided over by Joachim Friedrich von Blumenthal. He was an advocate of mercantilism, monopolies, subsidies, tariffs, and internal improvements. Following Louis XIV's revocation of the Edict of Nantes, Frederick William encouraged skilled French and Walloon Huguenots to emigrate to Brandenburg-Prussia with the Edict of Potsdam, bolstering the country's technical and industrial base. On Blumenthal's advice he agreed to exempt the nobility from taxes and in return they agreed to dissolve the Estates-General. He also simplified travel in Brandenburg and the Duchy of Prussia by connecting riverways with canals, a system that was expanded by later Prussian architects, such as Georg Steenke; the system is still in use today.
Marriages.
On 7 December 1646 in The Hague, Frederick William entered into a marriage, proposed by Blumenthal as a partial solution to the Jülich-Berg question, with Luise Henriette of Nassau (1627–1667), daughter of Frederick Henry of Orange-Nassau and Amalia of Solms-Braunfels and his 1st cousin once removed through William the Silent. Their children were as follows:
On 13 June 1668 in Gröningen, Frederick William married Sophie Dorothea of Holstein-Sonderburg-Glücksburg, daughter of Philip, Duke of Schleswig-Holstein-Sonderburg-Glücksburg and Sophie Hedwig of Saxe-Lauenburg.
Their children were the following:
External links.
 

</doc>
<doc id="11454" url="http://en.wikipedia.org/wiki?curid=11454" title="Frederick V">
Frederick V

Frederick V or Friedrich V may refer to: 

</doc>
<doc id="11456" url="http://en.wikipedia.org/wiki?curid=11456" title="French horn">
French horn

The French horn (commonly known simply as the horn) is a brass instrument made of tubing wrapped into a coil with a flared bell. The double horn in F/B♭ is the version most used by professional bands and orchestras. The main tubing on an F Horn is about 12 - long and that associated with the valves adds additional length to achieve up to about 17 ft of tubing overall. A musician who plays the French horn is called a horn player (or less frequently, a hornist).
Pitch is controlled through the adjustment of lip tension in the mouthpiece and the operation of valves by the left hand, which route the air into extra tubing. Most horns have lever-operated rotary valves, but some, especially older horns, use piston valves (similar to a trumpet's) and the Vienna horn uses double-piston valves, or pumpenvalves. The backward facing orientation of the bell relates to the perceived desirability to create a subdued sound, in concert situations, in contrast to the more-piercing quality of the trumpet. A horn without valves is known as a natural horn, changing pitch along the natural harmonics of the instrument (similar to a bugle). Pitch may also be controlled by the position of the hand in the bell, in effect reducing the bell's diameter. The pitch of any note can easily be raised or lowered by adjusting the hand position in the bell.
Three valves control the flow of air in the "single horn", which is tuned to F or less commonly B♭. The more common "double horn" has a fourth valve, usually operated by the thumb, which routes the air to one set of tubing tuned to F or another tuned to B♭. Triple horns with five valves are also made, tuned in F, B♭, and a descant E♭ or F. Also common are "descant" doubles, which typically provide B♭ and Alto F branches. This configuration provides a high-range horn while avoiding the additional complexity and weight of a triple.
A crucial element in playing the horn deals with the mouthpiece. Most of the time, the mouthpiece is placed in the exact center of the lips, but, because of differences in the formation of the lips and teeth of different players, some tend to play with the mouthpiece slightly off center. Although the exact side-to-side placement of the mouthpiece varies for most horn players, the up-and-down placement of the mouthpiece is generally two-thirds on the upper lip and one-third on the lower lip. Usually, in order to play higher octave notes, the pressure exerted on the lips from the mouthpiece is increased. But, although some pressure is needed, excessive pressure is not desirable. Playing with excessive pressure makes the playing of the horn sound forced and harsh as well as decreases endurance of the player by about half.
Name.
The name "French horn" is often used because the word "horn" by itself, even in the context of musical instruments, may refer to nearly any wind instrument with a flared exit for the sound. Nevertheless, the adjective is normally omitted when referring to the European orchestral horn, and the International Horn Society has recommended since 1971 that the instrument be simply called the "horn", despite the ambiguity of the term.
General characteristics.
The horn is the third highest sounding instrument group in the brass family, below the cornet and the trumpet. Horns are mostly tuned in B♭ or F, or a combination of both. In some traditions, novice players use a single horn in F, while others prefer the B♭ horn. The F horn is used more commonly than the B♭ horn, especially in school bands. Compared to the other brass instruments in orchestras and concert bands, it has a very different mouthpiece, but has the widest usable range – approximately four octaves, depending on the ability of the player. To produce different notes on the horn, one must do many things – the seven most important are pressing the valves, holding the appropriate amount of lip tension, raising the soft palate, positioning the tongue, lowering the larynx, blowing air into the instrument, and placing the hand in the bell. More lip tension and faster air produces higher notes. Less lip tension and slower air produces lower notes. The right hand, usually cupped at a "three o-clock" position in the bell, can lower the pitch, depending on how far into the bell the player puts it, by as much as a semitone in the instrument's midrange. The horn plays in a higher portion of its overtone series compared to most brass instruments. Its conical bore (as opposed to the cylindrical bore of the trumpet or trombone) is largely responsible for its characteristic tone, often described as "mellow".
Today, music for the horn is typically written in F and sounds a perfect fifth lower than written. The limitations on the range of the instrument are primarily governed by the available valve combinations for the first four octaves of the overtone series and after that by the ability of the player to control the pitch through their air supply and embouchure. The typical written ranges for the horn start at either the F♯ immediately below the bass clef or the C an octave below middle A.
The standard range starting from a low F♯ is based on the characteristics of the single horn in F. But there is a great deal of music written beyond this range, on the assumption that players are using a double horn in F/B♭. This is the standard orchestral and concert band instrument and its valve combinations allow for the production of every chromatic tone from two octaves on either side of the horn's written middle C (sounding F immediately below the bass clef to F at the top of the treble clef). Although the upper range of the horn repertoire rarely exceeds high C (two octaves above the horn's middle C, sounding F at the top of the treble clef), skilled players can achieve yet higher pitches.
Also important to note is that many pieces from the Baroque to Romantic periods are written in keys other than F. This practice began in the early days of the horn before valves, when the composer would indicate the key the horn should be in (horn in D, horn in C, etc.) and the part would be notated as if it were in C. For a player with a valveless (i.e. natural) horn that is a help, showing where in the harmonic series a particular note is. A player with a modern instrument must provide the final transposition to the correct pitch. For example, a written C for horn in D must be transposed down a minor third and played as an A on an F horn.
History.
As the name indicates, humans originally used to blow on the actual horns of animals before starting to emulate them in metal. This original usage survives in the shofar, a ram's horn, which plays an important role in Jewish religious rituals.
Early metal horns were less complex than modern horns, consisting of brass tubes with a slightly flared opening (the bell) wound around a few times. These early "hunting" horns were originally played on a hunt, often while mounted, and the sound they produced was called a recheat. Change of pitch was effected entirely by the lips (the horn not being equipped with valves until the 19th century). Without valves, only the notes within the harmonic series are available. The horn was used, among other reasons, to call hounds on a hunt and created a sound most like a human voice, but carried much farther.
In orchestral settings, the horn (or, more often, pairs of horns) often invoked the idea of the hunt, or, beginning in the later baroque, determined the character of the key being played or represented nobility, royalty, or divinity.
Early horns were commonly pitched in B♭ alto, A, A♭, G, F, E, E♭, D, C, and B♭ basso. Since the only notes available were those on the harmonic series of one of those pitches, they had no ability to play in different keys. The remedy for this limitation was the use of crooks, i.e., sections of tubing of differing length that, when inserted, altered the length of the instrument, and thus its pitch.
Orchestral horns are traditionally grouped into "high" horn and "low" horn pairs. Players specialize to negotiate the unusually wide range required of the instrument. Formerly, in certain situations, composers called for two pairs of horns in two different keys. For example, a composer might call for two horns in C and two in E♭ for a piece in c minor, in order to gain harmonics of the relative major unavailable on the C horns. Eventually, two pairs of horns became the standard, and from this tradition of two independent pairs, each with its own "high" and "low" horn, came the modern convention of writing the 1st and 3rd parts above 2nd and 4th.
In the mid-18th century, horn players began to insert the right hand into the bell to change the length of the instrument, adjusting the tuning up to the distance between two adjacent harmonics depending on how much of the opening was covered. This technique, known as hand-stopping, is generally credited to Anton Joseph Hampel around 1750, and was refined and carried to much of Europe by the influential Giovanni Punto. This offered more possibilities for playing notes not on the harmonic series. By the early classical period, the horn had become an instrument capable of much melodic playing. A notable example of this are the four Mozart Horn Concerti and Concert Rondo (K. 412, 417, 477, 495, 371), wherein melodic chromatic tones are used, owing to the growing prevalence of hand-stopping and other newly emerging techniques.
Around 1815 the use of pistons (later rotary valves) was introduced, initially to overcome problems associated with changing crooks during a performance. Valves' unreliability, musical taste, and players' distrust, among other reasons, slowed their adoption into mainstream. Many traditional conservatories and players refused to use them at first, claiming that the valveless horn, or "natural horn," was a better instrument. Some musicians, specializing in period instruments, still use a natural horn when playing in original performance styles, seeking to recapture the sound and tenor in which an older piece was written.
The use of valves, however, opened up a great deal more flexibility in playing in different keys; in effect, the horn became an entirely different instrument, fully chromatic for the first time. Valves were originally used primarily as a means to play in different keys without crooks, not for harmonic playing. That is reflected in compositions for horns, which only began to include chromatic passages in the late 19th century. When valves were invented, generally, the French made smaller horns with piston valves and the Germans made larger horns with rotary valves.
In English, the term "French horn" is often used because the word "horn" by itself, even in the context of musical instruments, may refer to nearly any wind instrument with a flared exit for the sound. Nevertheless, the International Horn Society has recommended since 1971 that the instrument be simply called the "horn", despite the ambiguity of the term.
Types of horns.
Horns may be classified in single horn, double horn, compensating double horn, and triple horn as well as the versatility of detachable bells.
Single horn.
Single horns use a single set of tubes connected to the valves. This allows for simplicity of use and a much lighter weight. They are usually in the keys of F or B♭, although many F horns have longer slides to tune them to E♭, and almost all B♭ horns have a valve to put them in the key of A. The problem with single horns is the inevitable choice between accuracy or tone – while the F horn has the "typical" horn sound, above third-space C accuracy is concern for the majority of players because, by its nature, one plays high in the horn's harmonic series where the overtones are closer together. This led to the development of the B♭ horn, which, although easier to play accurately, has a less desirable sound in the mid and especially the low register where it is not able to play all of the notes. The solution has been the development of the double horn, which combines the two into one horn with a single lead pipe and bell. Both main types of single horns are still used today as student models because they are cheaper and lighter than double horns. In addition, the single B♭ horns are sometimes used in solo and chamber performances and the single F survives orchestrally as the Vienna horn. Additionally, single F alto and B♭ alto descants are used in the performance of some baroque horn concertos and F, B♭ and F alto singles are occasionally used by jazz performers.
Dennis Brain's benchmark recordings of the Mozart Horn Concerti were made on a single B♭ instrument by Gebr. Alexander, now on display at the Royal Academy of Music in London.
Double horn.
Despite the introduction of valves, the single F horn proved difficult for use in the highest range, where the partials grew closer and closer, making accuracy a great challenge. An early solution was simply to use a horn of higher pitch—usually B♭. The use of the F versus the B♭ horn was a hotbed of debate between horn players of the late 19th century, until the German horn maker Ed. Kruspe (namesake of his family's brass instrument firm) produced a prototype of the "double horn" in 1897.
The double horn also combines two instruments into a single frame: the original horn in F, and a second, higher horn keyed in B♭. By using a fourth valve (usually operated by the thumb), the horn player can quickly switch from the deep, warm tones of the F horn to the higher, brighter tones of the B♭ horn. The two sets of tones are commonly called "sides" of the horn. Using the fourth valve not only changes the basic length (and thus the harmonic series and pitch) of the instrument, it also causes the three main valves to use proportionate slide lengths.
In the USA, the two most common styles ("wraps") of double horns are named Kruspe and Geyer/Knopf, after the first instrument makers who developed and standardized them. The Kruspe wrap locates the B♭ change valve above the first valve, near the thumb. The Geyer wrap has the change valve behind the third valve, near the little finger (although the valve's trigger is still played with the thumb). In effect, the air flows in a completely different direction on the other model. Kruspe wrap horns tend to be larger in the bell throat than the Geyer wrap horns. Typically, Kruspe models are constructed from nickel silver or German Silver, while Geyer horns tend to be of yellow brass. Both models have their own strengths and weaknesses, and while the choice of instrument is very personal, an orchestral horn section is usually found to have either one or the other, owing to the differences in tone color, response, and projection of the two different styles.
In Europe the most popular horns are arguably those made by Gebr. Alexander, of Mainz (particularly the Alexander 103), and those made by Paxman in London. In Germany and the Benelux countries, the Alex. 103 is extremely popular. These horns do not fit strictly into the Kruspe or Knopf camps, but have features of both. Alexander prefers the traditional medium bell size, which they have produced for many years, whereas Paxman do offer their models in a range of bell throat sizes. In the United States, the Conn 8D, a mass-produced instrument based on the Kruspe design, has been extremely popular in many areas (New York, Los Angeles, Cleveland, Philadelphia). Since roughly the early 1990s, however, for reasons ranging from changing tastes to a general dislike of Conn's newer 8Ds, orchestras have been moving away from the popular Conn 8D. Geyer model horns (by Carl Geyer, Karl Hill, Keith Berg, Steve Lewis, Jerry Lechniuk, Dan Rauch, and Ricco-Kuhn) are used in other areas (San Francisco, Chicago, Pittsburgh, Boston, Houston). The CF Schmidt double, with its unique piston change valve, is occasionally found in sections playing Geyer/Knopf model equipment.
Compensating double horn.
The first design of the double horn did not have a separate set of slides pitched in F. Rather, the main key of the horn was B♭ (the preference of German horn players) and it could be played in F by directing air through the B♭ slides, an F extension, and another set of smaller slides. This "compensated" for the longer length of the F slides, producing a horn now called the "compensating double." It was, and still is, widely used by European horn players because of its light weight and ease of playing, especially in the high register.
Triple horn.
This relatively new design was created to afford the player even more security in the high register. It employs not only the F and B♭ horns, but also a third, descant horn. This descant horn is usually pitched an octave above the F horn, though it can be alternatively pitched in E♭. It is activated through the use of a second thumb valve. The triple horn was met with considerable resistance when it first appeared. Horn players were reluctant to spend far more money for a triple horn than they would for a double horn, and a feeling that using a triple horn to help with the high register was "cheating" was rampant among prominent horn players. Also, the horns were much heavier than the average double horn. Players noted that their arms became fatigued much faster. Moreover, the combination of three different horns creates issues with sonority, because the piping shared among all three sides (that is, the lead pipe and bell) are mathematically disproportional to two or all three horn lengths. Horn makers have had to make concessions to "even out" the sound between all three, often to the loss of sound quality of each side or entire ranges of the instrument. Advances in horn production are gradually eliminating these drawbacks, and the triple horn is gaining popularity. They are rarely available in anything lower than professional quality. Like double horns, triple horns can come in both full and compensating wraps. Today they are found being played in many professional orchestras, although the substantial cost difference between double and triple horns limits their usage elsewhere.
Detachable bell.
The horn, although not large, is awkward in its shape and does not lend itself well to transport, especially on commercial airlines. To compensate, horn makers can make the bell detachable; this allows for smaller and more manageable horn cases. A detachable bell also allows the use of different bells on the same horn, somewhat alleviating the need for multiple horns for different styles.
Sotone.
The Sotone is a model of horn made by the British firm Boosey and Hawkes during the late 19th and early 20th century. It is based on the natural horn, and plays a good deal closer to the way a natural horn does than a conventional French horn.
Related horns.
The variety in horn history necessitates consideration of the natural horn, vienna horn, mellophone, marching horn, and Wagner tuba.
Natural horn.
The natural horn is the ancestor of the modern horn. It is essentially descended from hunting horns, with its pitch controlled by air speed, aperture (opening of the lips through which air passes) and the use of the right hand moving in and out of the bell. Today it is played as a period instrument. The natural horn can only play from a single harmonic series at a time because there is only one length of tubing available to the horn player. A proficient player can indeed alter the pitch by partially muting the bell with the right hand, thus enabling the player to reach some notes that are not part of the instrument's natural harmonic series – of course this technique also affects the quality of the tone. The player has a choice of key by using crooks to change the length of tubing.
Vienna horn.
The Vienna horn is a special horn used primarily in Vienna, Austria. Instead of using rotary valves or piston valves, it uses the Pumpenvalve (or Vienna Valve), which is a double-piston operating inside the valve slides, and usually situated on the opposite side of the corpus from the player's left hand, and operated by a long pushrod. Unlike the modern horn, which has grown considerably larger internally (for a bigger, broader, and louder tone), and considerably heavier (with the addition of valves and tubing in the case of the double horn) the Vienna horn very closely mimics the size and weight of the natural horn, (although the valves do add some weight, they are lighter than rotary valves) even using crooks in the front of the horn, between the mouthpiece and the instrument. Although instead of the full range of keys, Vienna horn players usually use an F crook and it is looked down upon to use others, though switching to an A or B♭ crook for higher pitched music does happen on occasion. Vienna horns are often used with funnel shaped mouthpieces similar to those used on the natural horn, with very little (if any) backbore and a very thin rim. The Viennese horn requires very specialized technique and can be quite challenging to play, even for accomplished players of modern horns. The Vienna horn has a warmer, softer sound than the modern horn. Its pumpen-valves facilitate a continuous transition between notes (glissando); conversely, a more precise operating of the valves is required to avoid notes that sound out of tune.
Mellophone.
Two instruments are called a "mellophone." The first is an instrument shaped somewhat like a horn, in that it is formed in a circle. It has piston valves and is played with the right hand on the valves. Manufacturing of this instrument sharply decreased in the middle of the twentieth century, and this mellophone (or mellophonium) rarely appears today. Amati still makes circular mellophoniums.
The second instrument is used in modern brass bands and marching bands, and is more accurately called a "marching mellophone" or mellophone. A derivative of the F alto horn, it is keyed in F. It is shaped like a flugelhorn, with piston valves played with the right hand and a forward-pointing bell. These horns are generally considered better marching instruments than regular horns because their position is more stable on the mouth, they project better, and they weigh less. It is primarily used as the middle voice of drum and bugle corps. Though they are usually played with a V-cup cornet-like mouthpiece, their range overlaps the common playing range of the horn. This mouthpiece switch makes the mellophone louder, less mellow, and more brassy and brilliant, making it more appropriate for marching bands. Often now with the use of converters, traditional conical horn mouthpieces are used to achieve the more mellow sound of a horn to make the marching band sound more like a concert band.
As they are pitched in F or G and their range overlaps that of the horn, mellophones can be used in place of the horn in brass and marching band settings. Mellophones are, however, sometimes unpopular with horn players because the mouthpiece change can be difficult and requires a different embouchure. Mouthpiece adapters are available so that a horn mouthpiece can fit into the mellophone lead pipe, but this does not compensate for the many differences that a horn player must adapt to. The bore is generally cylindrical as opposed to the more conical horn; thus, the "feel" of the mellophone can be foreign to a horn player. Another unfamiliar aspect of the mellophone is that it is designed to be played with the right hand instead of the left (although it can be played with the left). Intonation can also be an issue when playing the mellophone.
In orchestral or concert band settings, regular concert horns are normally preferred to mellophones because of their tone, which blends better with woodwinds and strings, and their greater intonational subtlety—since the player can adjust the tuning by hand. For these reasons, mellophones are played more usually in marching bands and brass band ensembles, occasionally in jazz bands, and almost never in orchestral or concert band settings.
While horn players may be asked to play the mellophone, it is unlikely that the instrument was ever intended as a substitute for the horn, mainly because of the fundamental differences described. As an instrument it compromises between the ability to sound like a horn, while being used like a trumpet or flugelhorn, a tradeoff that sacrifices acoustic properties for ergonomics.
Marching horn.
The marching horn is quite similar to the mellophone in shape and appearance, but is pitched in the key of B♭ (the same as the B♭ side of a regular double horn). It is also available in F alto (one octave above the F side of a regular double horn). The marching horn is also normally played with a horn mouthpiece (unlike the mellophone, which needs an adapter to fit the horn mouthpiece). These instruments are primarily used in marching bands so that the sound comes from a forward-facing bell, as dissipation of the sound from the backward-facing bell becomes a concern in open-air environments. Many college marching bands and drum corps, however, use mellophones instead, which, with many marching bands, better balance the tone of the other brass instruments; additionally, mellophones require less special training of trumpet players, who considerably outnumber horn players.
Wagner tuba.
The Wagner tuba is a rare brass instrument that is essentially a horn modified to have a larger bell throat and a vertical bell. Despite its name, it is generally not considered part of the tuba family. Invented for Richard Wagner specifically for his work Der Ring des Nibelungen, it has since been written for by various other composers, including Bruckner, Stravinsky and Richard Strauss. It uses a horn mouthpiece and is available as a single tuba in B♭ or F, or, more recently, as a double tuba similar to the double horn. Its common range is similar to that of the euphonium, but its possible range is the same as that of the horn, extending from low F♯, below the bass clef staff to high C above the treble staff when read in F. These low pedals are substantially easier to play on the Wagner tuba than on the horn. Wagner viewed the regular horn as a woodwind rather than a brass instrument, evidenced by his placing of the horn parts in his orchestral scores in the woodwind group and not in their usual place above the trumpets in the brass section.
Repertoire.
Discussion of the repertoire of horns must recognize the different needs of orchestras and concert bands in contrast to marching bands, as above, but also the use of horns in a wide variety of music, including chamber music and jazz.
Orchestra and concert band.
The horn is most often used as an orchestral and concert band instrument, with its singular tone being employed by composers to achieve specific effects. Leopold Mozart, for example, used horns to signify the hunt, as in his "Jagdsinfonie" (hunting symphony). Once the technique of hand-stopping had been developed, allowing fully chromatic playing, composers began to write seriously for the horn. Telemann wrote much for the horn, and it features prominently in the work of Handel and in Bach's "Brandenburg Concerto no. 1". Gustav Mahler made great use of the horn's uniquely haunting and distant sound in his symphonies, notably the famous "Nachtmusik" (serenade) section of his Symphony No. 7.
Many composers have written works that have become favorites in the horn repertoire. These includes Poulenc ("Elegie") and Saint-Saëns ("Morceau de Concert for horn and orchestra", op. 94 and "Romance", op. 36). Others, particularly Wolfgang Amadeus Mozart, whose friend Joseph Leutgeb was a noted horn player, wrote extensively for the instrument, including concerti and other solo works. Mozart's "A Musical Joke" satirizes the limitations of contemporary horn playing, including the risk of selecting the wrong crook by mistake. By the end of the 18th Century the horn was sufficiently established as a solo instrument that the horn player Giovanni Punto became an international celebrity, touring Europe and inspiring works by composers as significant as Beethoven.
The development of the valve horn was exploited by romantic composers such as Bruckner, Mahler, and Richard Strauss, whose father was a well-known professional horn player. Strauss's "Till Eulenspiegel's Merry Pranks" contains one of the best known horn solos from this period, relying on the chromatic facility of the valved horn. Schumann's "Konzertstuck for Four Horns and Orchestra" is a notable three-movement work. Brahms had a lifelong love-affair with the instrument, with many prominently featured parts throughout his four symphonies. Unlike most of his contemporaries Brahms composed for the older natural (valveless) horn, feeling it to be superior in tone to the valved instrument. However players today typically play Brahms on modern valved instruments.
Horn music in Britain had a renaissance in the mid-20th century when Dennis Brain inspired works such as Britten's "Serenade for Tenor, Horn and Strings" and other works from contemporary composers such as Michael Tippett, who stretches horn ensemble playing to its technical limits in his "Sonata for Four Horns". Peter Maxwell Davies was commissioned by 50 amateur and professional UK horn players to write a horn piece to commemorate the 50th anniversary of Brain's death.
Much of the horn repertoire is scored as featured parts for the orchestral players, especially the principal horn. It is common for leading horn players to move from principal positions in the great orchestras to distinguished solo careers, a path followed by Brain and many since.
Because of the heroic quality of the horn's sound, it is often used in film music. Bernard Herrmann's
score for "On Dangerous Ground", however, uses four horns (and anvils) during a chase sequence to suggest a wild state of mind.
Chamber music.
There is an abundance of chamber music repertoire for horn. It is a standard member of the wind quintet and brass quintet, and often appears in other configurations, such as Brahms' "Horn Trio" for violin, horn and piano. Also, the horn can be used by itself in a horn ensemble or "horn choir". The horn choir is especially practical because the extended range of the horn provides the composer or arranger with more possibilities, registerally, sonically, and contrapuntally.
Orchestral and concert band horns.
A classical orchestra usually contained two horns. Typically, the 1st horn played a high part and the 2nd horn played a low part. Composers from Beethoven onwards commonly used four horns. Here, the 1st and 2nd horns played as a pair (1st horn being high, 2nd horn being low), and the 3rd and 4th horns played as another pair (3rd horn being high, 4th horn being low). Music written for the modern horn follows a similar pattern with 1st and 3rd horns being high and 2nd and 4th horns being low.
This configuration serves multiple purposes. It is easier to play high when the adjacent player is playing low and vice versa. Pairing makes it easier to write for horns, as the 3rd and 4th horns can take over from the 1st and 2nd horns, or play contrasting material. Horn music was first written for the natural horn, which could only easily play certain notes. This required that the 1st and 2nd horns be in a different key from the 3rd and 4th horns, so that more notes could be played. For example, if the piece is in C minor, the 1st and 2nd horns might be in C, the tonic major key, which could get most of the notes, and the 3rd and 4th horns might be in E♭, the relative major key, to fill in the gaps.
Many orchestral horn sections today also have an assistant who doubles the 1st horn part for selected passages, joining in loud parts, playing instead of the principal if there is a 1st horn solo approaching, or alternating with the principal if the part is tiring to play. Often the assistant is asked to play a passage after resting a long time. Also, he or she may be asked to enter in the middle of a passage, exactly matching the sound, articulation, and overall interpretation of the principal. The assistant is occasionally referred to as a "bumper."
Some pieces (like Rachmaninov's "Isle of the Dead", Britten's "Sinfonia da Requiem", Holst's "The Planets" and Richard Strauss' "Don Quixote") have called for 6 horns, or as many as 20 horns, as found in Strauss' Alpine Symphony. Here the pairing remains the same, with the odd horns being high parts and the even horns being low parts. Stravinsky's Rite of Spring calls for 8 horns.
A modern concert band horn section generally has between four and six horns.
In jazz.
The horn has rarely been used in jazz music. Notable exponents, however, include composer/arranger Gil Evans who included the horn as an ensemble instrument from the 1940s, first in Claude Thornhill's groups, and later with the pioneering cool jazz nonet led by trumpeter Miles Davis, and in many other projects that sometimes also featured Davis, as well as Don Ellis, a trumpet player from Stan Kenton's jazz band. Notable works of Ellis' jazz horn include "Strawberry Soup" and other songs on the album Tears of Joy. Notable improvising horn players in jazz include Julius Watkins, Willie Ruff, John Graas, David Amram, John Clark, Vincent Chancey, , Giovanni Hoffer, Arkady Shilkloper, Adam Unsworth, and Tom Varner.
Notable horn players.
People who are more notable for their other achievements, but also play the horn, include actors Ewan McGregor and David Ogden Stiers, comedian and television host Jon Stewart, journalist Chuck Todd, The Who bassist and singer John Entwistle, and rapper and record producer B.o.B.

</doc>
<doc id="11457" url="http://en.wikipedia.org/wiki?curid=11457" title="Fra Angelico">
Fra Angelico

Fra Angelico (born Guido di Pietro; c. 1395 – February 18, 1455) was an Early Italian Renaissance painter described by Vasari in his "Lives of the Most Excellent Painters, Sculptors, and Architects" as having "a rare and perfect talent".
He was known to contemporaries as Fra Giovanni da Fiesole (Brother John of Fiesole) and Fra Giovanni Angelico (Angelic Brother John). In modern Italian he is called il Beato Angelico (Blessed Angelic One); the common English name Fra Angelico means the "Angelic friar".
In 1982 Pope John Paul II proclaimed his beatification, in recognition of the holiness of his life, thereby making the title of "Blessed" official. Fiesole is sometimes misinterpreted as being part of his formal name, but it was merely the name of the town where he took his vows as a Dominican friar, and was used by contemporaries to separate him from other Fra Giovannis. He is listed in the Roman Martyrology as "Beatus Ioannes Faesulanus, cognomento Angelicus"—"Blessed Giovanni of Fiesole, known as 'the Angelic' ".
Vasari wrote of Fra Angelico:But it is impossible to bestow too much praise on this holy father, who was so humble and modest in all that he did and said and whose pictures were painted with such facility and piety.
Biography.
Early life, 1395–1436.
Fra Angelico was born Guido di Pietro at Rupecanina in the Tuscan area of Mugello near Fiesole towards the end of the 14th century. Nothing is known of his parents. He was baptized Guido or Guidolino. The earliest recorded document concerning Fra Angelico dates from October 17, 1417 when he joined a religious confraternity at the Carmine Church, still under the name of Guido di Pietro. This record also reveals that he was already a painter, a fact that is subsequently confirmed by two records of payment to Guido di Pietro in January and February 1418 for work done in the church of Santo Stefano del Ponte. The first record of Angelico as a friar dates from 1423, when he is first referred to as Fra Giovanni, following the custom of those entering a religious order of taking a new name. He was a member of the Dominican community at Fiesole. Fra, a contraction of "frater" (from the Latin), is a conventional title for a friar.
According to Vasari, Fra Angelico initially received training as an illuminator, possibly working with his older brother Benedetto who was also a Dominican and an illuminator. San Marco in Florence holds several manuscripts that are thought to be entirely or partly by his hand. The painter Lorenzo Monaco may have contributed to his art training, and the influence of the Sienese school is discernible in his work. He had several important charges in the convents he lived in, but this did not limit his art, which very soon became famous. According to Vasari, the first paintings of this artist were an altarpiece and a painted screen for the Carthusian Monastery of Florence; none such exist there now.
From 1408 to 1418 Fra Angelico was at the Dominican friary of Cortona where he painted frescoes, now destroyed, in the Dominican Church and may have been assistant to or follower of Gherardo Starnina. Between 1418 and 1436 he was at the convent of Fiesole where he also executed a number of frescoes for the church, and the Altarpiece, deteriorated but restored. A predella of the Altarpiece remains intact in the National Gallery, London which is a superb example of Fra Angelico's ability. It shows Christ in Glory, surrounded by more than 250 figures, including beatified Dominicans.
San Marco, Florence, 1436–1445.
In 1436 Fra Angelico was one of a number of the friars from Fiesole who moved to the newly built Friary of San Marco in Florence. This was an important move which put him in the centre of artistic activity of the region and brought about the patronage of one of the wealthiest and most powerful members of the city's governing authority, or "Signoria" (namely Cosimo de' Medici), who had a large cell (later occupied by Savonarola) reserved for himself at the friary in order that he might retreat from the world. 
It was, according to Vasari, at Cosimo's urging that Fra Angelico set about the task of decorating the monastery, including the magnificent Chapter House fresco, the often-reproduced Annunciation at the top of the stairs to the cells, the Maesta with Saints and the many smaller devotional frescoes depicting aspects of the Life of Christ that adorn the walls of each cell. 
In 1439 he completed one of his most famous works, the Altarpiece for St. Marco's, Florence. The result was unusual for its times. Images of the enthroned Madonna and Child surrounded by saints were common, but they usually depicted a setting that was clearly heavenlike, in which saints and angels hovered about as divine presences rather than people. But in this instance, the saints stand squarely within the space, grouped in a natural way as if they were able to converse about the shared experience of witnessing the Virgin in glory. Paintings such as this, known as Sacred Conversations, were to become the major commissions of Giovanni Bellini, Perugino and Raphael.
The Vatican, 1445–1455.
In 1445 Pope Eugenius IV summoned him to Rome to paint the frescoes of the Chapel of the Holy Sacrament at St Peter's, later demolished by Pope Paul III. Vasari claims that at this time Fra Angelico was offered by Pope Nicholas V the Archbishopric of Florence, and that he refused it, recommending another friar for the position. While the story seems possible and even likely, if Vasari's date is correct, then the pope must have been Eugenius and not Nicholas. In 1447 Fra Angelico was in Orvieto with his pupil, Benozzo Gozzoli, executing works for the Cathedral. Among his other pupils were Zanobi Strozzi.
From 1447 to 1449 he was back at the Vatican, designing the frescoes for the Niccoline Chapel for Nicholas V. The scenes from the lives of the two martyred deacons of the Early Christian Church, St. Stephen and St. Lawrence may have been executed wholly or in part by assistants. The small chapel, with its brightly frescoed walls and gold leaf decorations gives the impression of a jewel box. From 1449 until 1452, Fra Angelico was back at his old convent of Fiesole, where he was the Prior.
Death and beatification.
In 1455 Fra Angelico died while staying at a Dominican convent in Rome, perhaps in order to work on Pope Nicholas' chapel. He was buried in the church of Santa Maria sopra Minerva. 
When singing my praise, don't liken my talents to those of Apelles. Say, rather, that, in the name of Christ, I gave all I had to the poor.
The deeds that count on Earth are not the ones that count in Heaven.
I, Giovanni, am the flower of Tuscany.—Translation of epitaph
For the 1911 edition of the Encyclopædia Britannica, the English writer and critic William Michael Rossetti wrote of the friar:
From various accounts of Fra Angelico's life, it is possible to gain some sense of why he was deserving of canonization. He led the devout and ascetic life of a Dominican friar, and never rose above that rank; he followed the dictates of the order in caring for the poor; he was always good-humored. All of his many paintings were of divine subjects, and it seems that he never altered or retouched them, perhaps from a religious conviction that, because his paintings were divinely inspired, they should retain their original form. He was wont to say that he who illustrates the acts of Christ should be with Christ. It is averred that he never handled a brush without fervent prayer and he wept when he painted a Crucifixion. The Last Judgment and the Annunciation were two of the subjects he most frequently treated.
Pope John Paul II beatified Fra Angelico on October 3, 1982, and in 1984 declared him patron of Catholic artists.Angelico was reported to say "He who does Christ's work must stay with Christ always". This motto earned him the epithet "Blessed Angelico", because of the perfect integrity of his life and the almost divine beauty of the images he painted, to a superlative extent those of the Blessed Virgin Mary.—Pope John Paul II
Evaluation.
Background.
Fra Angelico was working at a time when the style of painting was in a state of change. This process of change had begun a hundred years previous with the works of Giotto and several of his contemporaries, notably Giusto de' Menabuoi, both of whom had created their major works in Padua, although Giotto was trained in Florence by the great Gothic artist, Cimabue, and painted a fresco cycle of St Francis in the Bardi Chapel in the Basilica di Santa Croce. Giotto had many enthusiastic followers, who imitated his style in fresco, some of them, notably the Lorenzetti, achieving great success.
Patronage.
The patrons of these artists were most often monastic establishments or wealthy families endowing a church. Because the paintings often had devotional purpose, the clients tended to be conservative. Frequently, it would seem, the wealthier the client, the more conservative the painting. There was a very good reason for this. The paintings that were commissioned made a statement about the patron. Thus the more gold leaf it displayed, the more it spoke to the patron's glory. The other valuable commodities in the paint-box were lapis lazuli and vermilion. Paint made from these colours did not lend itself to a tonal treatment. The azure blue made of powdered lapis lazuli went on flat, the depth and brilliance of colour being, like the gold leaf, a sign of the patron's ability to provide well. For these reasons, altarpieces are often much more conservatively painted than frescoes, which were often of almost life-sized figures and relied upon a stage-set quality rather than lavish display in order to achieve effect.
Contemporaries.
Fra Angelico was the contemporary of Gentile da Fabriano. Gentile's altarpiece of the Adoration of the Magi, 1423, in the Uffizi is regarded as one of the greatest works of the style known as International Gothic. At the time it was painted, another young artist, known as Masaccio, was working on the frescoes for the Brancacci Chapel at the church of the Carmine. Masaccio had fully grasped the implications of the art of Giotto. Few painters in Florence saw his sturdy, lifelike and emotional figures and were not affected by them. His work partner was an older painter, Masolino, of the same generation as Fra Angelico. Masaccio died at 27, leaving the work unfinished.
Altarpieces.
The works of Fra Angelico reveal elements that are both conservatively Gothic and progressively Renaissance. In the altarpiece of the Coronation of the Virgin, painted for the Florentine church of Santa Maria Novella, are all the elements that a very expensive altarpiece of the 14th century was expected to provide- a precisely tooled gold background, lots of azure, lots of vermilion and an obvious display of arsenic green. The workmanship of the gilded haloes and gold-edged robes is exquisite and all very Gothic. What make this a Renaissance painting, as against Gentile da Fabriano's masterpiece, is the solidity, the three-dimensionality and naturalism of the figures and the realistic way in which their garments hang or drape around them. Even though it is clouds these figures stand upon, and not the earth, they do so with weight.
Frescoes.
The series of frescoes that Fra Angelico painted for the Dominican friars at San’ Marcos realise the advancements made by Masaccio and carry them further. Away from the constraints of wealthy clients and the limitations of panel painting, Fra Angelico was able to express his deep reverence for his God and his knowledge and love of humanity. The meditational frescoes in the cells of the convent have a quieting quality about them. They are humble works in simple colours. There is more mauvish-pink than there is red while the brilliant and expensive blue is almost totally lacking. In its place is dull green and the black and white of Dominican robes. There is nothing lavish, nothing to distract from the spiritual experiences of the humble people who are depicted within the frescoes. Each one has the effect of bringing an incident of the life of Christ into the presence of the viewer. They are like windows into a parallel world. These frescoes remain a powerful witness to the piety of the man who created them.
Vasari relates that Cosimo de' Medici seeing these works, inspired Fra Angelico to create a large Crucifixion scene with many saints for the Chapter House. As with the other frescoes, the wealthy patronage did not influence the Friar's artistic expression with displays of wealth.
Masaccio ventured into perspective with his creation of a realistically painted niche at Santa Maria Novella. Subsequently, Fra Angelico demonstrated an understanding of linear perspective particularly in his Annunciation paintings set inside the sort of arcades that Michelozzo and Brunelleschi created at San’ Marco's and the square in front of it.
Lives of the Saints.
When Fra Angelico and his assistants went to the Vatican to decorate the chapel of Pope Nicholas, then the artist was again confronted with the need to please the very wealthiest of clients. In consequence, walking into the small chapel is like stepping into a jewel box. The walls are decked with the brilliance of colour and gold that one sees in the most lavish creations of the Gothic painter Simone Martini at the Lower Church of St Francis of Assisi, a hundred years earlier. Yet Fra Angelico has succeeded in creating designs which continue to reveal his own preoccupation with humanity, with humility and with piety. The figures, in their lavish gilded robes, have the sweetness and gentleness for which his works are famous. According to Vasari:
In their bearing and expression, the saints painted by Fra Angelico come nearer to the truth than the figures done by any other artist.
It is probable that much of the actual painting was done by his assistants to his design. Both Benozzo Gozzoli and Gentile da Fabriano were highly accomplished painters. Benozzo took his art further towards the fully developed Renaissance style with his expressive and lifelike portraits in his masterpiece of the Journey of the Magi, painted in the Medici's private chapel at their palazzo.
Artistic legacy.
Through Fra Angelico's pupil Benozzo Gozzoli's careful portraiture and technical expertise in the art of fresco we see a link to Domenico Ghirlandaio, who in turn painted extensive schemes for the wealthy patrons of Florence, and through Ghirlandaio to his pupil Michelangelo and the High Renaissance.
Apart from the lineal connection, superficially there may seem little to link the humble priest with his sweetly pretty Madonnas and timeless Crucifixions to the dynamic expressions of Michelangelo's larger-than-life creations. But both these artists received their most important commissions from the wealthiest and most powerful of all patrons, the Vatican.
When Michelangelo took up the Sistine Chapel commission, he was working within a space that had already been extensively decorated by other artists. Around the walls the "Life of Christ" and "Life of Moses" were depicted by a range of artists including his teacher Ghirlandaio, Raphael's teacher Perugino and Botticelli. They were works of large scale and exactly the sort of lavish treatment to be expected in a Vatican commission, vying with each other in complexity of design, number of figures, elaboration of detail and skilful use of gold leaf. Above these works stood a row of painted Popes in brilliant brocades and gold tiaras. None of these splendours have any place in the work which Michelangelo created. Michelangelo, when asked by Pope Julius II to ornament the robes of the Apostles in the usual way, responded that they were very poor men.
Within the cells of San’Marco, Fra Angelico had demonstrated that painterly skill and the artist's personal interpretation were sufficient to create memorable works of art, without the expensive trappings of blue and gold. In the use of the unadorned fresco technique, the clear bright pastel colours, the careful arrangement of a few significant figures and the skilful use of expression, motion and gesture, Michelangelo showed himself to be the artistic descendant of Fra Angelico. Frederick Hartt describes Fra Angelico as "prophetic of the mysticism" of painters such as Rembrandt, El Greco and Zurbarán.
Works.
Early works, 1408–1436.
Cortona
Fiesole
Florence, Santa Trinita 
Florence, Santa Maria degli Angeli 
Florence, Santa Maria Novella 
San Marco, Florence, 1436–1445.
Each cell is decorated with a fresco which matches in size and shape the single round-headed window beside it. The frescoes are apparently for contemplative purpose. They are have a pale, serene, unearthly beauty. Many of Fra Angelico's finest and most reproduced works are among them. There are, particularly in the inner row of cells, some of less inspiring quality and of more repetitive subject, perhaps completed by assistants. Many pictures include Dominican saints as witnesses, allowing the friar using the cell to place himself in the scene.
Late works, 1445–1455.
Orvieto Cathedral
Three segments of the ceiling in the Cappella Nuova, with the assistance of Benozzo Gozzoli.
Niccoline Chapel
The Chapel of Pope Nicholas V, at the Vatican, was probably painted with much assistance from Benozzo Gozzoli and Gentile da Fabriano. The entire surface of wall and ceiling is sumptuously painted. There is much gold leaf for borders and decoration, and a great use of brilliant blue made from lapis lazuli.
Discovery of lost works.
Worldwide press coverage reported in November 2006 that two missing masterpieces by Fra Angelico had turned up, having hung in the spare room of the late Jean Preston, in her "modest terrace house" in Oxford, England. Her father had bought them for £100 each in 1965 then bequeathed them to her when he died in 1974. Preston had been consulted by their then owner in her capacity as an expert medievalist. She recognised them as being high quality Florentine renaissance, but it never occurred to anyone, even all the dealers she approached on behalf of the owner, that they could possibly be by Fra Angelico. They were finally identified in 2005 by Michael Liversidge of Bristol University. There was almost no demand at all for medieval art during the 1960s and no dealers showed any interest, so Preston's father bought them almost as an afterthought along with some manuscripts. Coincidentally the manuscripts turned out to be high quality Victorian forgeries by The Spanish Forger. The paintings are two of eight side panels of a large altarpiece painted in 1439 for Fra Angelico's monastery at San Marco, but split up by Napoleon's army 200 years ago. While the centre section is still at the monastery, the other six small panels are in German and US museums. These two panels were presumed lost forever. The Italian Government had hoped to purchase them but they were outbid at auction on 20 April 2007 by a private collector for £1.7M. Both panels are now restored and exhibited in the San Marco Museum in Florence.
References.
</dl>

</doc>
<doc id="11458" url="http://en.wikipedia.org/wiki?curid=11458" title="Fra Bartolomeo">
Fra Bartolomeo

Fra Bartolomeo or Fra Bartolommeo (di Pagholo) OP (March 28, 1472 – October 6, 1517), also known as "Baccio della Porta", was an Italian Renaissance painter of religious subjects.
Biography.
He was born in Savignano di Prato, Tuscany. He received the nickname of Baccio della Porta for his house was near the Porta ("Gate") San Pier Gattolini.
Starting from 1483 or 1484, by recommendation of Benedetto da Maiano, he apprenticed in the workshop of Cosimo Rosselli. He was one of the greatest painters of his time. In 1490 or 1491 he began a collaboration with Mariotto Albertinelli. In the late 1490s Baccio was drawn to the teachings of Fra Girolamo Savonarola, who denounced what he viewed as vain and corrupt contemporary art. Savonarola argued for art serving as a direct visual illustration of the Bible to educate those unable to read the book. From 1498 is his famous portrait of Savonarola, now in the Museo Nazionale di San Marco in Florence. The following year he was commissioned a fresco of the "Universal Judgement" for the Ospedale di Santa Maria Nuova, completed by Albertinelli and Giuliano Bugiardini when Baccio became a Dominican friar on July 26, 1500. The following year he entered the convent of San Marco.
He renounced painting for several years, not resuming until 1504 when he became the head of the monastery workshop in obedience to his superior. In that year he began a "Vision of St. Bernard" for Bernardo Bianco's family chapel in the Badia Fiorentina, finished in 1507.
Soon thereafter, Raphael visited Florence and befriended the friar. Bartolomeo learned perspective from the younger artist, while Raphael added skills in coloring and handling of drapery, which was noticeable in the works he produced after their meeting. With Raphael, he remained on the friendliest terms, and when he departed from Rome, left in his hands two unfinished pictures which Raphael completed.
At the beginning of 1508 Bartolomeo moved to Venice to paint a "Holy Father, St. Mary Magdalene and St. Catherine of Siena" for the Dominicans of San Pietro Martire in Murano, influenced somewhat by Venetian colorism. As the Dominicans did not pay the work, he took it back to Lucca, where it can be seen now. Also in Lucca, in the October 1509, he painted by Albertinelli an altarpiece with "Madonna and Child with Saints" for the local cathedral. On November 26, 1510 Pier Soderini commissioned him an altarpiece for the Sala del Consiglio of Florence, now in the Museum of San Marco. Two years later he finished another altarpiece for the cathedral of Besançon.
In 1513 he went to Rome, where he painted a "Peter and Paul", now in the Pinacoteca Vaticana, while from the following years are the "St. Mark Evangelist" of Palazzo Pitti in Florence and the frescoes in the Dominican convent of Pian di Mugnone. After a promised "Feast of Venus" for Duke Alfonso I d'Este of Ferrara, of which only drawings remain, his last work is fresco of "Noli me tangere" also in Pian di Mugnone.
He died in Florence in 1517.
Evaluation.
Initially, his works showed the influence of Rosselli's assistant, Piero di Cosimo, and those of Domenico Ghirlandaio and Filippino Lippi. After his hiatus from 1500 to 1503, he seemed to change vision, taking from Raphael the representation of light and its effects over moving shapes.
Fra Bartolomeo's figures are generally small and draped. These qualities were alleged against him as defects, and to prove that his style was not the result of want of power, he painted the magnificent figure of the "St. Mark Evangelist" (ranked as his masterpiece), and the undraped figure of Saint Sebastian. It is alleged that the latter was felt to be so strongly expressive of suffering and agony, that it was found necessary to remove it from the place where it had been exhibited in the chapel of a convent.
Fra Bartolomeo's compositions are remarkable for skill in the massing of light and shade, richness and delicacy of colouring, and for the admirable drapery of the figures, Bartolomeo having been the first to introduce and use the lay-figure with joints.
Among his pupils were Cecchino del Frate, Benedetto Ciamfanini, Gabriel Rustici, Ridolfo Ghirlandaio (the son of Domenico Ghirlandaio), and Fra Paolo Pistolese.

</doc>
<doc id="11459" url="http://en.wikipedia.org/wiki?curid=11459" title="Frédéric Bazille">
Frédéric Bazille

Jean Frédéric Bazille (December 6, 1841 – November 28, 1870) was a French Impressionist painter. Many of Bazille's major works are examples of figure painting in which Bazille placed the subject figure within a landscape painted "en plein air".
Life and work.
Frédéric Bazille was born in Montpellier, Hérault, Languedoc-Roussillon, France, into a wealthy Protestant family. He became interested in painting after seeing some works of Eugène Delacroix. His family agreed to let him study painting, but only if he also studied medicine.
Bazille began studying medicine in 1859, and moved to Paris in 1862 to continue his studies. There he met Pierre-Auguste Renoir and Alfred Sisley, was drawn to Impressionist painting, and began taking classes in Charles Gleyre's studio. After failing his medical exam in 1864, he began painting full-time. His close friends included Claude Monet, Alfred Sisley, and Édouard Manet. Bazille was generous with his wealth, and helped support his less fortunate associates by giving them space in his studio and materials to use.
Bazille was just twenty-three years old when he painted several of his best-known works, including "The Pink Dress" (ca. 1864, Musée d'Orsay, Paris). This painting combines a portrait-like depiction of Bazille's cousin, Thérèse des Hours, who is seen from behind—and the sunlit landscape at which she gazes. His best-known painting is "Family Reunion" of 1867–1868 (Musée d'Orsay, Paris).
Frédéric Bazille joined a Zouave regiment in August 1870, a month after the outbreak of the
Franco-Prussian War. On November 28 of that year he was with his unit at the Battle of Beaune-la-Rolande when, his officer having been injured, he took command and led an assault on the German position. He was hit twice in the failed attack and died on the battlefield at the age of twenty eight. His father travelled to the battlefield a few days later to take his body back for burial at Montpellier over a week later.

</doc>
<doc id="11460" url="http://en.wikipedia.org/wiki?curid=11460" title="Ford Madox Brown">
Ford Madox Brown

Ford Madox Brown (16 April 1821 – 6 October 1893) was an English painter of moral and historical subjects, notable for his distinctively graphic and often Hogarthian version of the Pre-Raphaelite style. Arguably, his most notable painting was "Work" (1852–1865). Brown spent the latter years of his life painting the Manchester Murals, depicting Mancunian history, for Manchester Town Hall.
Early life.
Brown was the grandson of the medical theorist John Brown, founder of the Brunonian system of medicine. His great grandfather was a Scottish labourer. His father Ford Brown served as a purser in the Royal Navy, including a period serving under Sir Isaac Coffin and a period on HMS "Arethusa". He left the Navy after the end of the Napoleonic Wars.
In 1818, Ford Brown married Caroline Madox, of an old Kentish family, from which his middle name was taken. Brown's parents had limited financial resources, and they moved to Calais to seek cheaper lodgings, where their daughter Elizabeth Coffin was born in 1819 and their son Ford Madox Brown in 1821.
Brown's education was limited, as the family frequently moved between lodgings in the Pas de Calais and relatives in Kent, but he showed artistic talent in copying of old master prints. His father initially sought a naval career for his son, writing to his former captain Sir Isaac Coffin. The family moved to Bruges in 1835 so Brown could study at the academy under Albert Gregorius. Brown moved to Ghent in 1836 to continue his studies under Pierre Van Hanselaer. He moved to Antwerp in 1837 to study under Egide Charles Gustave Wappers. He continued to study in Antwerp after his mother's death in 1839. His sister died in 1840, and then his father in 1842.
Works.
The Tate Gallery holds an early example of Brown's work, a portrait of his father. He first exhibited at the Royal Academy in 1840, a work inspired by Lord Byron's poem "The Giaour" (now lost) and then completed a version of "The Execution of Mary, Queen of Scots", with his cousin and future wife Elisabeth Bromley as one of his models. He lived in Montmartre with his new wife and aging father in 1841. He painted "Manfred on the Jungfrau", inspired by Lord Byron's poem "Manfred" while he was in Paris.
In 1843 he submitted work to the Westminster Cartoon Competition, for compositions to decorate the new Palace of Westminster. His entry, "The Body of Harold Brought before William", was not successful. His early works were, however, greatly admired by the young Dante Gabriel Rossetti, who asked him to become his tutor. Through Rossetti, Brown came into contact with the artists who went on to form the Pre-Raphaelite Brotherhood. Though closely linked to them, he was never actually a member of the brotherhood itself, but adopted the bright colours and realistic style of William Holman Hunt and John Everett Millais. He was also influenced by the works of Holbein that he saw in Basel in 1845, and by Friedrich Overbeck and Peter Cornelius, whom he met in Rome in 1845-46.
Brown struggled to make his mark in the 1850s, with his paintings failing to find buyers, and he considered emigrating to India. In 1852 he started work on two of his most significant works.
One of his most famous images is "The Last of England", painted from 1852 to 1855, which was sold in March 1859 for 325 Guineas ("2010: £"). It depicts a pair of stricken emigrants as they sail away on the ship that will take them from England forever. It was inspired by the departure of the Pre-Raphaelite sculptor Thomas Woolner, who had left for Australia. In an unusual tondo format, the painting is structured with Brown's characteristic linear energy, and emphasis on apparently grotesque and banal details, such as the cabbages hanging from the ship's side. The husband and wife are portraits of Brown and his second wife Emma.
Brown's most important painting was "Work" (1852–1865), begun in Hampstead in 1852 and which he showed at his retrospective exhibition in 1865. Thomas Plint advanced funds to enable Brown to complete the work, in anticipation of obtaining the finished painting, but died in 1861 before the painting had been completed. In this painting, Brown attempted to depict the totality of the mid-Victorian social experience in a single image, depicting 'navvies' digging up a road (Heath Street in Hampstead, London) and disrupting the old social hierarchies as they did so. The image erupts into proliferating details from the dynamic centre of the action, as the workers tear a hole in the road – and, symbolically, in the social fabric. Each character represents a particular social class and role in the modern urban environment. Brown wrote a catalogue to accompany the special exhibition of "Work." This publication included an extensive explanation of "Work" that nevertheless leaves many questions unanswered. Brown's concern with the social issues addressed in "Work" prompted him to open a soup kitchen for Manchester's hungry, and to attempt to aid the city's unemployed to find work by founding a labour exchange.
Brown found patrons in the north of England, including Plint, George Rae from Birkenhead, John Miller from Liverpool, and James Leathart from Newcastle. By the late 1850s he had lost patience with the poor reception he received at the Royal Academy and ceased to show his works there, rejecting an offer from Millais to support his becoming an associate member. He founded the Hogarth Club in 1858, with William Morris, Edward Burne-Jones, and his former pupil Rossetti. After a successful period of a few years, the club reached over 80 members, including several prominent members of the Royal Academy, but Brown resigned in 1860, and the club collapsed in 1861.
From the 1860s, Brown also designed furniture and stained glass. He was a founder partner of William Morris's design company, Morris, Marshall, Faulkner & Co., in 1861, which dissolved in 1874 with Morris continuing on his own. He was a close friend of the landscape artist Henry Mark Anthony. 
Brown's major achievement after "Work" was "The Manchester Murals", a cycle of twelve paintings in the Great Hall of Manchester Town Hall depicting the history of the city. Brown would be 72 by the time he finished the murals. In total, he took six years perfecting the murals, which were his last major work.
Family.
Ford Madox Brown was married twice. His first wife Elizabeth Bromley was his first cousin, the daughter of his mother's sister Mary. They were married in Meopham in Kent in April 1841, shortly before his 20th birthday and less than a year after the sudden death of his sister Elizabeth. The lived in Montmartre in 1841 with Brown's invalid father who died the following summer.
Their first child died young as an infant in November 1842. Their daughter Emma Lucy was born in 1843 and the family moved back to England in 1844. They travelled to Rome in 1845 to alleviate the illness of his wife, who was suffering from consumption (pulmonary tuberculosis). She died in Paris in June 1846, aged 27, on the journey back to England from Rome.
Emma Hill became a frequent model for Brown from 1848; for example, she is the wife in "The Last of England". She became his mistress, and they shared a house in London, but social convention made him unable to marry an illiterate daughter of a bricklayer. Their daughter Catherine Emily was born in 1850, and eventually they were married at St Dunstan-in-the-West in April 1853. Their son, Oliver Madox Brown (1855–1874) (known as Nolly) showed promise both as an artist and poet, but died of blood poisoning before his maturity. The death of Nolly was a crushing blow for Brown, and he kept a room for his son's belongings as a shrine. Another son Arthur was born in September 1856. Brown used Arthur as the model for the baby held by a ragged girl in the foreground of "Work", but he died aged only ten months old in July 1857.
His daughters Lucy and Catherine were also competent artists. Lucy married William Michael Rossetti in 1874. Catherine, married Francis Hueffer; through Catherine, Brown was the grandfather of novelist Ford Madox Ford and great-grandfather of Labour Home Secretary Frank Soskice. 
Brown's second wife died in October 1890, and he died in Primrose Hill in 1893. He is buried in the St Pancras and Islington Cemetery in East Finchley, close to Muswell Hill. He was given a secular funeral, and the funeral oration was delivered by the American Moncure D. Conway, the secularist after whom Conway Hall was later named.
Heritage.
The J D Wetherspoon pub in Oxford Road, Manchester is named after Ford Madox Brown. It states on the Wetherspoon's website that "This J D Wetherspoon pub is named after the much-travelled artist Ford Madox Brown, a one-time resident of Victoria Park, a suburb south of the pub." The pub opened in 2007.

</doc>
<doc id="11461" url="http://en.wikipedia.org/wiki?curid=11461" title="Francis Crick">
Francis Crick

Francis Harry Compton Crick, OM, FRS (8 June 1916 – 28 July 2004) was a British molecular biologist, biophysicist, and neuroscientist, most noted for being a co-discoverer of the structure of the DNA molecule in 1953 with James Watson. Together with Watson and Maurice Wilkins, he was jointly awarded the 1962 Nobel Prize for Physiology or Medicine "for their discoveries concerning the molecular structure of nucleic acids and its significance for information transfer in living material".
Crick was an important theoretical molecular biologist and played a crucial role in research related to revealing the genetic code. He is widely known for use of the term "central dogma" to summarize the idea that genetic information flow in cells is essentially one-way, from DNA to RNA to protein.
During the remainder of his career, he held the post of J.W. Kieckhefer Distinguished Research Professor at the Salk Institute for Biological Studies in La Jolla, California. His later research centered on theoretical neurobiology and attempts to advance the scientific study of human consciousness. He remained in this post until his death; "he was editing a manuscript on his death bed, a scientist until the bitter end" according to Christof Koch.
Early life and education.
Crick was the first son of Harry Crick (1887–1948) and Annie Elizabeth Crick (née Wilkins; 1879–1955). He was born and raised in Weston Favell, then a small village near the English town of Northampton, in which Crick’s father and uncle ran the family’s boot and shoe factory. His grandfather, Walter Drawbridge Crick (1857–1903), an amateur naturalist, wrote a survey of local foraminifera (single-celled protists with shells), corresponded with Charles Darwin, and had two gastropods (snails or slugs) named after him.
At an early age, Francis was attracted to science and what he could learn about it from books. As a child, he was taken to church by his parents. But by about age 12, he said he did not want to go anymore, as he preferred a scientific search for answers over religious belief.
Walter Crick, his uncle, lived in a small house on the south side of Abington Avenue; he had a shed at the bottom of his little garden where he taught Crick to blow glass, do chemical experiments and to make photographic prints. When he was eight or nine he transferred to the most junior form of the Northampton Grammar School, on the Billing Road. This was about 1 1/4 miles from his home so he could walk there and back, by Park Avenue South and Abington Park Crescent, but he more often went by bus or, later, by bicycle. The teacher – a Miss Holding – was an inspired teacher and made everything interesting. The teaching in the higher forms was satisfactory, but not as stimulating. After the age of 14, he was educated at Mill Hill School in London (on scholarship), where he studied mathematics, physics, and chemistry with his best friend John Shilston. He shared the Walter Knox Prize for Chemistry on Mill Hill School's Foundation Day, Friday, 7 July 1933. He declared that his success was inspired by the quality of teaching he received whilst a pupil at Mill Hill.
At the age of 21, Crick earned a Bachelor of Science degree in physics from University College London. Crick had failed to gain a place at a Cambridge college, probably through failing their requirement for Latin. Crick later became a PhD student and Honorary Fellow of Gonville and Caius College, Cambridge and mainly worked at the Cavendish Laboratory and the Medical Research Council (MRC) Laboratory of Molecular Biology in Cambridge. He was also an Honorary Fellow of Churchill College, Cambridge and of University College, London.
Crick began a Ph.D. research project on measuring viscosity of water at high temperatures (which he later described as "the dullest problem imaginable") in the laboratory of physicist Edward Neville da Costa Andrade at University College, London, but with the outbreak of World War II (in particular, an incident during the Battle of Britain when a bomb fell through the roof of the laboratory and destroyed his experimental apparatus), Crick was deflected from a possible career in physics. During his second year as a PhD student, however, he was awarded the Carey Foster Research Prize, a great honour.
During World War II, he worked for the Admiralty Research Laboratory, from which emerged a group of many notable scientists, including David Bates, Robert Boyd, George Deacon, John Gunn, Harrie Massey, and Nevill Mott; he worked on the design of magnetic and acoustic mines, and was instrumental in designing a new mine that was effective against German minesweepers.
Post-World War II.
In 1947, aged 31, Crick began studying biology and became part of an important migration of physical scientists into biology research. This migration was made possible by the newly won influence of physicists such as Sir John Randall, who had helped win the war with inventions such as radar. Crick had to adjust from the "elegance and deep simplicity" of physics to the "elaborate chemical mechanisms that natural selection had evolved over billions of years." He described this transition as, "almost as if one had to be born again." According to Crick, the experience of learning physics had taught him something important—hubris—and the conviction that since physics was already a success, great advances should also be possible in other sciences such as biology. Crick felt that this attitude encouraged him to be more daring than typical biologists who tended to concern themselves with the daunting problems of biology and not the past successes of physics.
For the better part of two years, Crick worked on the physical properties of cytoplasm at Cambridge's Strangeways Laboratory, headed by Honor Bridget Fell, with a Medical Research Council studentship, until he joined Max Perutz and John Kendrew at the Cavendish Laboratory. The Cavendish Laboratory at Cambridge was under the general direction of Sir Lawrence Bragg, who had won the Nobel Prize in 1915 at the age of 25. Bragg was influential in the effort to beat a leading American chemist, Linus Pauling, to the discovery of DNA's structure (after having been 'pipped-at-the-post' by Pauling's success in determining the alpha helix structure of proteins). At the same time Bragg's Cavendish Laboratory was also effectively competing with King's College London, whose Biophysics department was under the direction of Sir John Randall. (Randall had turned down Francis Crick from working at King's College.) Francis Crick and Maurice Wilkins of King's College were personal friends, which influenced subsequent scientific events as much as the close friendship between Crick and James Watson. Crick and Wilkins first met at King's College and not, as erroneously recorded by two authors, at the Admiralty during World War II.
He married twice, fathered three children and was the grandfather of six grandchildren; his brother Anthony (born in 1918) predeceased him in 1966.
Spouses:
Children:
Grandchildren
Death.
Crick died of colon cancer on the morning of 28 July 2004 at the University of California, San Diego (UCSD) Thornton Hospital in La Jolla; he was cremated and his ashes were scattered into the Pacific Ocean. A public memorial was held on 27 September 2004 at the Salk Institute, La Jolla, near San Diego, California; guest speakers included James Watson, Sydney Brenner, Alex Rich, Seymour Benzer, Aaron Klug, Christof Koch, Pat Churchland, Vilayanur Ramachandran, Tomaso Poggio, Leslie Orgel, Terry Sejnowski, his son Michael Crick, and his youngest daughter Jacqueline Nichols. A private memorial for family and colleagues was held on 3 August 2004.
Research.
Crick was interested in two fundamental unsolved problems of biology: how molecules make the transition from the non-living to the living, and how the brain makes a conscious mind. He realized that his background made him more qualified for research on the first topic and the field of biophysics. It was at this time of Crick’s transition from physics to biology that he was influenced by both Linus Pauling and Erwin Schrödinger. It was clear in theory that covalent bonds in biological molecules could provide the structural stability needed to hold genetic information in cells. It only remained as an exercise of experimental biology to discover exactly which molecule was the genetic molecule. In Crick’s view, Charles Darwin’s theory of evolution by natural selection, Gregor Mendel’s genetics and knowledge of the molecular basis of genetics, when combined, revealed the secret of life. Crick had the very optimistic view that life would very soon be created in a test tube. However, some people (such as fellow researcher and colleague Esther Lederberg) thought that Crick's views were overly optimistic 
It was clear that some macromolecule such as a protein was likely to be the genetic molecule. However, it was well known that proteins are structural and functional macromolecules, some of which carry out enzymatic reactions of cells. In the 1940s, some evidence had been found pointing to another macromolecule, DNA, the other major component of chromosomes, as a candidate genetic molecule. In the 1944 Avery-MacLeod-McCarty experiment, Oswald Avery and his collaborators showed that a heritable phenotypic difference could be caused in bacteria by providing them with a particular DNA molecule.
However, other evidence was interpreted as suggesting that DNA was structurally uninteresting and possibly just a molecular scaffold for the apparently more interesting protein molecules. Crick was in the right place, in the right frame of mind, at the right time (1949), to join Max Perutz’s project at the University of Cambridge, and he began to work on the X-ray crystallography of proteins. X-ray crystallography theoretically offered the opportunity to reveal the molecular structure of large molecules like proteins and DNA, but there were serious technical problems then preventing X-ray crystallography from being applicable to such large molecules.
1949–1950.
Crick taught himself the mathematical theory of X-ray crystallography. During the period of Crick's study of X-ray diffraction, researchers in the Cambridge lab were attempting to determine the most stable helical conformation of amino acid chains in proteins (the Alpha helix). Linus Pauling was the first to identify the 3.6 amino acids per helix turn ratio of the Alpha helix. Crick was witness to the kinds of errors that his co-workers made in their failed attempts to make a correct molecular model of the α helix; these turned out to be important lessons that could be applied, in the future, to the helical structure of DNA. For example, he learned the importance of the structural rigidity that double bonds confer on molecular structures which is relevant both to peptide bonds in proteins and the structure of nucleotides in DNA.
1951–1953: DNA structure.
In 1951, together with William Cochran and Vladimir Vand, Crick assisted in the development of a mathematical theory of X-ray diffraction by a helical molecule. This theoretical result matched well with X-ray data for proteins that contain sequences of amino acids in the Alpha helix conformation. Helical diffraction theory turned out to also be useful for understanding the structure of DNA.
Late in 1951, Crick started working with James Watson at Cavendish Laboratory at the University of Cambridge, England. Using "Photo 51" (the X-ray diffraction results of Rosalind Franklin and her graduate student Raymond Gosling of King's College London, given to them by Gosling and Franklin's colleague Maurice Wilkins), Watson and Crick together developed a model for a helical structure of DNA, which they published in 1953. For this and subsequent work they were jointly awarded the Nobel Prize in Physiology or Medicine in 1962 with Maurice Wilkins.
When James Watson came to Cambridge, Crick was a 35-year-old graduate student (due to his work during WWII) and Watson was only 23, but he already had a Ph.D. They shared an interest in the fundamental problem of learning how genetic information might be stored in molecular form. Watson and Crick talked endlessly about DNA and the idea that it might be possible to guess a good molecular model of its structure. A key piece of experimentally-derived information came from X-ray diffraction images that had been obtained by Maurice Wilkins, Rosalind Franklin, and their research student, Raymond Gosling. In November 1951, Wilkins came to Cambridge and shared his data with Watson and Crick. Alexander Stokes (another expert in helical diffraction theory) and Wilkins (both at King's College) had reached the conclusion that X-ray diffraction data for DNA indicated that the molecule had a helical structure—but Franklin vehemently disputed this conclusion. Stimulated by their discussions with Wilkins and what Watson learned by attending a talk given by Franklin about her work on DNA, Crick and Watson produced and showed off an erroneous first model of DNA. Their hurry to produce a model of DNA structure was driven in part by the knowledge that they were competing against Linus Pauling. Given Pauling's recent success in discovering the Alpha helix, they feared that Pauling might also be the first to determine the structure of DNA.
Many have speculated about what might have happened had Pauling been able to travel to Britain as planned in May 1952. As it was, his political activities caused his travel to be restricted by the U. S. government and he did not visit the UK until later, at which point he met none of the DNA researchers in England. At any rate he was preoccupied with proteins at the time, not DNA. Watson and Crick were not officially working on DNA. Crick was writing his Ph.D. thesis; Watson also had other work such as trying to obtain crystals of myoglobin for X-ray diffraction experiments. In 1952, Watson performed X-ray diffraction on tobacco mosaic virus and found results indicating that it had helical structure. Having failed once, Watson and Crick were now somewhat reluctant to try again and for a while they were forbidden to make further efforts to find a molecular model of DNA.
Of great importance to the model building effort of Watson and Crick was Rosalind Franklin's understanding of basic chemistry, which indicated that the hydrophilic phosphate-containing backbones of the nucleotide chains of DNA should be positioned so as to interact with water molecules on the outside of the molecule while the hydrophobic bases should be packed into the core. Franklin shared this chemical knowledge with Watson and Crick when she pointed out to them that their first model (from 1951, with the phosphates inside) was obviously wrong.
Crick described what he saw as the failure of Maurice Wilkins and Rosalind Franklin to cooperate and work towards finding a molecular model of DNA as a major reason why he and Watson eventually made a second attempt to do so. They asked for, and received, permission to do so from both William Lawrence Bragg and Wilkins. In order to construct their model of DNA, Watson and Crick made use of information from unpublished X-ray diffraction images of Franklin's (shown at meetings and freely shared by Wilkins), including preliminary accounts of Franklin's results/photographs of the X-ray images that were included in a written progress report for the King's College laboratory of Sir John Randall from late 1952.
It is a matter of debate whether Watson and Crick should have had access to Franklin's results without her knowledge or permission, and before she had a chance to formally publish the results of her detailed analysis of her X-ray diffraction data which were included in the progress report. However, Watson and Crick found fault in her steadfast assertion that, according to her data, a helical structure was not the only possible shape for DNA—so they had a dilemma. In an effort to clarify this issue, Max Ferdinand Perutz later published what had been in the progress report, and suggested that nothing was in the report that Franklin herself had not said in her talk (attended by Watson) in late 1951. Further, Perutz explained that the report was to a Medical Research Council (MRC) committee that had been created in order to "establish contact between the different groups of people working for the Council". Randall's and Perutz's laboratories were both funded by the MRC.
It is also not clear how important Franklin's unpublished results from the progress report actually were for the model-building done by Watson and Crick. After the first crude X-ray diffraction images of DNA were collected in the 1930s, William Astbury had talked about stacks of nucleotides spaced at 3.4 angström (0.34 nanometre) intervals in DNA. A citation to Astbury's earlier X-ray diffraction work was one of only eight references in Franklin's first paper on DNA. Analysis of Astbury's published DNA results and the better X-ray diffraction images collected by Wilkins and Franklin revealed the helical nature of DNA. It was possible to predict the number of bases stacked within a single turn of the DNA helix (10 per turn; a full turn of the helix is 27 angströms [2.7 nm] in the compact A form, 34 angströms [3.4 nm] in the wetter B form). Wilkins shared this information about the B form of DNA with Crick and Watson. Crick did not see Franklin's B form X-ray images (Photo 51) until after the DNA double helix model was published.
One of the few references cited by Watson and Crick when they published their model of DNA was to a published article that included Sven Furberg's DNA model that had the bases on the inside. Thus, the Watson and Crick model was not the first "bases in" model to be proposed. Furberg's results had also provided the correct orientation of the DNA sugars with respect to the bases. During their model building, Crick and Watson learned that an antiparallel orientation of the two nucleotide chain backbones worked best to orient the base pairs in the centre of a double helix. Crick's access to Franklin's progress report of late 1952 is what made Crick confident that DNA was a double helix with antiparallel chains, but there were other chains of reasoning and sources of information that also led to these conclusions.
As a result of leaving King's College for Birkbeck College, Franklin was asked by John Randall to give up her work on DNA. When it became clear to Wilkins and the supervisors of Watson and Crick that Franklin was going to the new job, and that Linus Pauling was working on the structure of DNA, they were willing to share Franklin's data with Watson and Crick, in the hope that they could find a good model of DNA before Pauling was able. Franklin's X-ray diffraction data for DNA and her systematic analysis of DNA's structural features was useful to Watson and Crick in guiding them towards a correct molecular model. The key problem for Watson and Crick, which could not be resolved by the data from King's College, was to guess how the nucleotide bases pack into the core of the DNA double helix.
Another key to finding the correct structure of DNA was the so-called Chargaff ratios, experimentally determined ratios of the nucleotide subunits of DNA: the amount of guanine is equal to cytosine and the amount of adenine is equal to thymine. A visit by Erwin Chargaff to England in 1952 reinforced the salience of this important fact for Watson and Crick. The significance of these ratios for the structure of DNA were not recognized until Watson, persisting in building structural models, realized that A:T and C:G pairs are structurally similar. In particular, the length of each base pair is the same. Chargaff had also pointed out to Watson that, in the aqueous, saline environment of the cell, the predominant tautomers of the pyrimidine (C and T) bases would be the amine and keto configurations of cytosine and thymine, rather than the imino and enol forms that Crick and Watson had assumed. They consulted Jerry Donohue who confirmed the most likely structures of the nucleotide bases. The base pairs are held together by hydrogen bonds, the same non-covalent interaction that stabilize the protein α-helix. The correct structures were essential for the positioning of the hydrogen bonds. These insights led Watson to deduce the true biological relationships of the A:T and C:G pairs. After the discovery of the hydrogen bonded A:T and C:G pairs, Watson and Crick soon had their anti-parallel, double helical model of DNA, with the hydrogen bonds at the core of the helix providing a way to "unzip" the two complementary strands for easy replication: the last key requirement for a likely model of the genetic molecule. As important as Crick's contributions to the discovery of the double helical DNA model were, he stated that without the chance to collaborate with Watson, he would not have found the structure by himself.
Crick did tentatively attempt to perform some experiments on nucleotide base pairing, but he was more of a theoretical biologist than an experimental biologist. There was another near-discovery of the base pairing rules in early 1952. Crick had started to think about interactions between the bases. He asked John Griffith to try to calculate attractive interactions between the DNA bases from chemical principles and quantum mechanics. Griffith's best guess was that A:T and G:C were attractive pairs. At that time, Crick was not aware of Chargaff's rules and he made little of Griffith's calculations, although it did start him thinking about complementary replication. Identification of the correct base-pairing rules (A-T, G-C) was achieved by Watson "playing" with cardboard cut-out models of the nucleotide bases, much in the manner that Linus Pauling had discovered the protein alpha helix a few years earlier. The Watson and Crick discovery of the DNA double helix structure was made possible by their willingness to combine theory, modeling and experimental results (albeit mostly done by others) to achieve their goal.
The DNA double helix structure proposed by Watson and Crick was based upon "Watson-Crick" bonds between the four bases most frequently found in DNA (A, C, T, G) and RNA (A, C, U, G). However, later research showed that triple-stranded, quadruple-stranded and other more complex DNA molecular structures required Hoogsteen base pairing. In addition, the entire field of synthetic biology began with researchers such as Erik T. Kool, where bases other than A, C, T and G are used in a synthetic DNA. In addition to synthetic DNA there are also attempts to construct synthetic codons, synthetic endonucleases, synthetic proteins and synthetic zinc fingers. Using synthetic DNA, instead of there being 43 codons, if there are n new bases there could be as many as n3 codons. Research is currently being done to see if codons can be expanded to more than 3 bases. These new codons can code for new amino acids. These synthetic molecules can be used not only in medicine, but in creation of new materials.
The discovery was made on 28 February 1953; the first Watson/Crick paper appeared in "Nature" on 25 April 1953. Sir Lawrence Bragg, the director of the Cavendish Laboratory, where Watson and Crick worked, gave a talk at Guy's Hospital Medical School in London on Thursday 14 May 1953 which resulted in an article by Ritchie Calder in The News Chronicle of London, on Friday 15 May 1953, entitled "Why You Are You. Nearer Secret of Life." The news reached readers of The New York Times the next day; Victor K. McElheny, in researching his biography, "Watson and DNA: Making a Scientific Revolution", found a clipping of a six-paragraph New York Times article written from London and dated 16 May 1953 with the headline "Form of 'Life Unit' in Cell Is Scanned." The article ran in an early edition and was then pulled to make space for news deemed more important. (The New York Times subsequently ran a longer article on 12 June 1953). The Universities undergraduate newspaper "Varsity" also ran its own short article on the discovery on Saturday 30 May 1953. Bragg's original announcement of the discovery at a Solvay conference on proteins in Belgium on 8 April 1953 went unreported by the British press.
In a seven-page, handwritten letter to his son at a British boarding school on 19 March 1953 Crick explained his discovery, beginning the letter "My Dear Michael, Jim Watson and I have probably made a most important discovery...". The letter was put up for auction at Christie's New York on 10 April 2013 with an estimate of $1 to $2 million, eventually selling for $6,059,750, the largest amount ever paid for a letter at auction.
Sydney Brenner, Jack Dunitz, Dorothy Hodgkin, Leslie Orgel, and Beryl M. Oughton, were some of the first people in April 1953 to see the model of the structure of DNA, constructed by Crick and Watson; at the time they were working at Oxford University's Chemistry Department. All were impressed by the new DNA model, especially Brenner who subsequently worked with Crick at Cambridge in the Cavendish Laboratory and the new Laboratory of Molecular Biology. According to the late Dr. Beryl Oughton, later Rimmer, they all travelled together in two cars once Dorothy Hodgkin announced to them that they were off to Cambridge to see the model of the structure of DNA. Orgel also later worked with Crick at the Salk Institute for Biological Studies.
Molecular biology.
In 1954, at the age of 37, Crick completed his Ph.D. thesis: "X-Ray Diffraction: Polypeptides and Proteins" and received his degree. Crick then worked in the laboratory of David Harker at Brooklyn Polytechnic Institute, where he continued to develop his skills in the analysis of X-ray diffraction data for proteins, working primarily on ribonuclease and the mechanisms of protein synthesis. David Harker, the American X-ray crystallographer, was described as "the John Wayne of crystallography" by Vittorio Luzzati, a crystallographer at the Centre for Molecular Genetics in Gif-sur-Yvette near Paris, who had worked with Rosalind Franklin.
After the discovery of the double helix model of DNA, Crick's interests quickly turned to the biological implications of the structure. In 1953, Watson and Crick published another article in "Nature" which stated: "it therefore seems likely that the precise sequence of the bases is the code that carries the genetical information".
In 1956, Crick and Watson speculated on the structure of small viruses. They suggested that spherical viruses such as Tomato bushy stunt virus had icosahedral symmetry and were made from 60 identical subunits.
After his short time in New York, Crick returned to Cambridge where he worked until 1976, at which time he moved to California. Crick engaged in several X-ray diffraction collaborations such as one with Alexander Rich on the structure of collagen. However, Crick was quickly drifting away from continued work related to his expertise in the interpretation of X-ray diffraction patterns of proteins.
George Gamow established a group of scientists interested in the role of RNA as an intermediary between DNA as the genetic storage molecule in the nucleus of cells and the synthesis of proteins in the cytoplasm (the RNA Tie Club). It was clear to Crick that there had to be a code by which a short sequence of nucleotides would specify a particular amino acid in a newly synthesized protein. In 1956, Crick wrote an informal paper about the genetic coding problem for the small group of scientists in Gamow's RNA group. In this article, Crick reviewed the evidence supporting the idea that there was a common set of about 20 amino acids used to synthesize proteins. Crick proposed that there was a corresponding set of small "adaptor molecules" that would hydrogen bond to short sequences of a nucleic acid, and also link to one of the amino acids. He also explored the many theoretical possibilities by which short nucleic acid sequences might code for the 20 amino acids.
During the mid-to-late 1950s Crick was very much intellectually engaged in sorting out the mystery of how proteins are synthesized. By 1958, Crick's thinking had matured and he could list in an orderly way all of the key features of the protein synthesis process:
The adaptor molecules were eventually shown to be tRNAs and the catalytic "ribonucleic-protein complexes" became known as ribosomes. An important step was later realization (in 1960) that the messenger RNA was not the same as the ribosomal RNA. None of this, however, answered the fundamental theoretical question of the exact nature of the genetic code. In his 1958 article, Crick speculated, as had others, that a triplet of nucleotides could code for an amino acid. Such a code might be "degenerate", with 4×4×4=64 possible triplets of the four nucleotide subunits while there were only 20 amino acids. Some amino acids might have multiple triplet codes. Crick also explored other codes in which, for various reasons, only some of the triplets were used, "magically" producing just the 20 needed combinations. Experimental results were needed; theory alone could not decide the nature of the code. Crick also used the term "central dogma" to summarize an idea that implies that genetic information flow between macromolecules would be essentially one-way:
Some critics thought that by using the word "dogma", Crick was implying that this was a rule that could not be questioned, but all he really meant was that it was a compelling idea without much solid evidence to support it. In his thinking about the biological processes linking DNA genes to proteins, Crick made explicit the distinction between the materials involved, the energy required, and the information flow. Crick was focused on this third component (information) and it became the organizing principle of what became known as molecular biology. Crick had by this time become a highly influential theoretical molecular biologist.
Proof that the genetic code is a degenerate triplet code finally came from genetics experiments, some of which were performed by Crick. The details of the code came mostly from work by Marshall Nirenberg and others who synthesized synthetic RNA molecules and used them as templates for "in vitro" protein synthesis.
Controversy.
An enduring controversy has been generated by Watson and Crick's use of DNA X-ray diffraction data collected by Rosalind Franklin and her student Raymond Gosling. The controversy arose from the fact that some of Franklin's unpublished data were used without her knowledge or consent by Watson and Crick in their construction of the double helix model of DNA. Of the four DNA researchers, only Rosalind Franklin had a degree in chemistry: Wilkins and Crick had backgrounds in physics, Watson in molecular biology.
Prior to publication of the double helix structure, Watson and Crick had little direct interaction with Franklin herself. They were, however, aware of her work, more aware than she herself realized. Watson was present at a lecture, given in November 1951, where Franklin presented the two forms of the molecule, type A and type B, and discussed the position of the phosphate units on the external part of the molecule. She also specified the amount of water to be found in the molecule in accordance with other parts of it, data that have considerable importance in terms of the stability of the molecule. Franklin was the first to discover and formulate these facts, which in fact constituted the basis for all later attempts to build a model of the molecule. Before this both Linus Pauling and Watson and Crick had generated erroneous models with the chains inside and the bases pointing outwards. Her identification of the space group for DNA crystals revealed to Crick that the two DNA strands were antiparallel.
In January 1953, James Watson was shown an X-ray photograph of B-DNA (called photograph 51), by Maurice Wilkins. Maurice Wilkins had been given photograph 51 by Rosalind Franklin's Ph.D. student Raymond Gosling. Wilkins and Gosling had worked together in the Medical Research Council's (MRC) Biophysics Unit before director John Randall appointed Franklin to take over both DNA diffraction work and guidance of Gosling's thesis. It appears that Randall did not communicate effectively with them about Franklin's appointment, contributing to confusion and friction between Wilkins and Franklin.
In the middle of February 1953, Crick's thesis advisor, Max Perutz, gave Crick a copy of a report written for a Medical Research Council biophysics committee visit to King's in December 1952, containing data from the King's group, including some of Rosalind Franklin's crystallographic calculations.
Franklin was unaware that photograph 51 and other information had been shared with Crick and Watson. She wrote a series of three draft manuscripts, two of which included a double helical DNA backbone. Her two A form manuscripts reached Acta Crystallographica in Copenhagen on 6 March 1953, one day before Crick and Watson had completed their model.
The X-ray diffraction images collected by Gosling and Franklin provided the best evidence for the helical nature of DNA. Franklin's experimental work thus proved crucial in Watson and Crick's discovery. Her experimental results provided estimates of the water content of DNA crystals, and these results were most consistent with the three sugar-phosphate backbones being on the outside of the molecule. Franklin's X-Ray photograph showed that the backbones had to be on the outside. Although she at first insisted vehemently that her data did not force one to conclude that DNA has a helical structure, in the drafts she submitted in 1953 she argues for a double helical DNA backbone. Her identification of the space group for DNA crystals revealed to Crick that the DNA strands were antiparallel, which helped Watson and Crick decide to look for DNA models with two antiparallel polynucleotide strands.
In summary, Watson and Crick had three sources for Franklin's unpublished data: 1) her 1951 seminar, attended by Watson, 2) discussions with Wilkins, who worked in the same laboratory with Franklin, 3) a research progress report that was intended to promote coordination of Medical Research Council-supported laboratories. Watson, Crick, Wilkins and Franklin all worked in MRC laboratories.
Crick and Watson felt that they had benefited from collaborating with Wilkins. They offered him a co-authorship on the article that first described the double helix structure of DNA. Wilkins turned down the offer, a fact that may have led to the terse character of the acknowledgment of experimental work done at King's College in the eventual published paper. Rather than make any of the DNA researchers at King's College co-authors on the Watson and Crick double helix article, the solution that was arrived at was to publish two additional papers from King's College along with the helix paper. Brenda Maddox suggests that because of the importance of her experimental results in Watson and Crick's model building and theoretical analysis, Franklin should have had her name on the original Watson and Crick paper in "Nature". Franklin and Gosling submitted their own joint 'second' paper to "Nature" at the same time as Wilkins, Stokes, and Wilson submitted theirs (i.e. the 'third' paper on DNA).
Watson's portrayal of Franklin in "The Double Helix" (written after Franklin's death when libel laws did not apply anymore) was negative and gave the appearance that she was Wilkins' assistant and was unable to interpret her own DNA data.
The X-ray diffraction images collected by Franklin provided the best evidence for the helical nature of DNA. While Franklin's experimental work proved important to Crick and Watson's development of a correct model, she herself could not realize it at the time. When she left King's College, Director Sir John Randall insisted that all DNA work belonged exclusively to King's and ordered Franklin to not even think about it. Franklin subsequently did superb work in J. D. Bernal's Lab at Birkbeck College with the tobacco mosaic virus extending ideas on helical construction.
Views on religion.
Crick referred to himself as a humanist, which he defined as the belief "that human problems can and must be faced in terms of human moral and intellectual resources without invoking supernatural authority." He publicly called for humanism to replace religion as a guiding force for humanity, writing:
Crick was especially critical of Christianity:
Crick once joked, "Christianity may be OK between consenting adults in private but should not be taught to young children."
In his book "Of Molecules and Men", Crick expressed his views on the relationship between science and religion. After suggesting that it would become possible for a computer to be programmed so as to have a soul, he wondered: at what point during biological evolution did the first organism have a soul? At what moment does a baby get a soul? Crick stated his view that the idea of a non-material soul that could enter a body and then persist after death is just that, an imagined idea. For Crick, the mind is a product of physical brain activity and the brain had evolved by natural means over millions of years. He felt that it was important that evolution by natural selection be taught in schools and that it was regrettable that English schools had compulsory religious instruction. He also considered that a new scientific world view was rapidly being established, and predicted that once the detailed workings of the brain were eventually revealed, erroneous Christian concepts about the nature of humans and the world would no longer be tenable; traditional conceptions of the "soul" would be replaced by a new understanding of the physical basis of mind. He was sceptical of organized religion, referring to himself as a skeptic and an agnostic with "a strong inclination towards atheism".
In 1960, Crick accepted an honorary fellowship at Churchill College, Cambridge, one factor being that the new college did not have a chapel. Some time later a large donation was made to establish a chapel and the College Council decided to accept it. Crick resigned his fellowship in protest.
In October 1969 Crick participated in a celebration of the 100th year of the journal "Nature" in which he attempted to make some predictions about what the next 30 years would hold for molecular biology. His speculations were later published in "Nature". Near the end of the article, Crick briefly mentioned the search for life on other planets, but he held little hope that extraterrestrial life would be found by the year 2000. He also discussed what he described as a possible new direction for research, what he called "biochemical theology". Crick wrote "so many people pray that one finds it hard to believe that they do not get some satisfaction from it".
Crick suggested that it might be possible to find chemical changes in the brain that were molecular correlates of the act of prayer. He speculated that there might be a detectable change in the level of some neurotransmitter or neurohormone when people pray. He might have been imagining substances such as dopamine that are released by the brain under certain conditions and produce rewarding sensations. Crick's suggestion that there might someday be a new science of "biochemical theology" seems to have been realized under an alternative name: there is now the new field of neurotheology. Crick's view of the relationship between science and religion continued to play a role in his work as he made the transition from molecular biology research into theoretical neuroscience.
Crick asked in 1998 "and if some of the Bible is manifestly wrong, why should any of the rest of it be accepted automatically? ... And what would be more important than to find our true place in the universe by removing one by one these unfortunate vestiges of earlier beliefs?"
In 2003 he was one of 22 Nobel laureates who signed the Humanist Manifesto.
Directed panspermia.
During the 1960s, Crick became concerned with the origins of the genetic code. In 1966, Crick took the place of Leslie Orgel at a meeting where Orgel was to talk about the origin of life. Crick speculated about possible stages by which an initially simple code with a few amino acid types might have evolved into the more complex code used by existing organisms. At that time, everyone thought of proteins as the only kind of enzymes and ribozymes had not yet been found. Many molecular biologists were puzzled by the problem of the origin of a protein replicating system that is as complex as that which exists in organisms currently inhabiting Earth. In the early 1970s, Crick and Orgel further speculated about the possibility that the production of living systems from molecules may have been a very rare event in the universe, but once it had developed it could be spread by intelligent life forms using space travel technology, a process they called "directed panspermia". In a retrospective article, Crick and Orgel noted that they had been overly pessimistic about the chances of abiogenesis on Earth when they had assumed that some kind of self-replicating protein system was the molecular origin of life.
In 1976 Crick addressed the origin of protein synthesis in a paper with Sydney Brenner, Aaron Klug, and George Pieczenik. In this paper, based on Pieczenik's work, they speculate that code constraints on nucleotide sequences allow protein synthesis without the need for a ribosome. It, however, requires a five base binding between the mRNA and tRNA with a flip of the anti-codon creating a triplet coding, even though it is a five-base physical interaction. Thomas H. Jukes pointed out that the code constraints on the mRNA sequence required for this translation mechanism is still preserved.
Neuroscience and other interests.
Crick's period at Cambridge was the pinnacle of his long scientific career, but he left Cambridge in 1977 after 30 years, having been offered (and having refused) the Mastership of Gonville & Caius. James Watson claimed at a Cambridge conference marking the 50th anniversary of the discovery of the structure of DNA in 2003: "Now perhaps it's a pretty well kept secret that one of the most uninspiring acts of the University of Cambridge over this past century was to turn down Francis Crick when he applied to be the Professor of Genetics, in 1958. Now there may have been a series of arguments, which led them to reject Francis. It was really saying, don't push us to the frontier." The apparently "pretty well kept secret" had already been recorded in Soraya De Chadarevian's "Designs For Life: Molecular Biology After World War II", published by CUP in 2002. His major contribution to molecular biology in Cambridge is well documented in The History of the University of Cambridge: Volume 4 (1870 to 1990), which was published by Cambridge University Press in 1992.
According to the University of Cambridge's genetics department official website, the electors of the professorship could not reach consensus, prompting the intervention of then University Vice-Chancellor Lord Adrian. Lord Adrian first offered the professorship to a compromise candidate, Guido Pontecorvo, who refused, and is said to have offered it then to Crick, who also refused.
In 1976, Crick took a sabbatical year at the Salk Institute for Biological Studies in La Jolla, California. Crick had been a nonresident fellow of the Institute since 1960. Crick wrote, "I felt at home in Southern California." After the sabbatical, Crick left Cambridge in order to continue working at the Salk Institute. He was also a professor at the University of California, San Diego. He taught himself neuroanatomy and studied many other areas of neuroscience research. It took him several years to disengage from molecular biology because exciting discoveries continued to be made, including the discovery of alternative splicing and the discovery of restriction enzymes, which helped make possible genetic engineering. Eventually, in the 1980s, Crick was able to devote his full attention to his other interest, consciousness. His autobiographical book, ", includes a description of why he left molecular biology and switched to neuroscience.
Upon taking up work in theoretical neuroscience, Crick was struck by several things:
Crick hoped he might aid progress in neuroscience by promoting constructive interactions between specialists from the many different subdisciplines concerned with consciousness. He even collaborated with neurophilosophers such as Patricia Churchland. In 1983, as a result of their studies of computer models of neural networks, Crick and Mitchison proposed that the function of REM sleep is to remove certain modes of interactions in networks of cells in the mammalian cerebral cortex; they called this hypothetical process 'reverse learning' or 'unlearning'. In the final phase of his career, Crick established a collaboration with Christof Koch that lead to publication of a series of articles on consciousness during the period spanning from 1990 to 2005. Crick made the strategic decision to focus his theoretical investigation of consciousness on how the brain generates visual awareness within a few hundred milliseconds of viewing a scene. Crick and Koch proposed that consciousness seems so mysterious because it involves very short-term memory processes that are as yet poorly understood. Crick also published a book describing how neurobiology had reached a mature enough stage so that consciousness could be the subject of a unified effort to study it at the molecular, cellular and behavioural levels. Crick's book "The Astonishing Hypothesis" made the argument that neuroscience now had the tools required to begin a scientific study of how brains produce conscious experiences. Crick was skeptical about the value of computational models of mental function that are not based on details about brain structure and function.
Reactions.
Crick was often described as very talkative, with Watson – in "The Double Helix" – implying lack of modesty. His personality combined with his scientific accomplishments produced many opportunities for Crick to stimulate reactions from others, both inside and outside the scientific world, which was the centre of his intellectual and professional life. Crick spoke rapidly, and rather loudly, and had an infectious and reverberating laugh, and a lively sense of humour. One colleague from the Salk Institute described him as "a brainstorming intellectual powerhouse with a mischievous smile... Francis was never mean-spirited, just incisive. He detected microscopic flaws in logic. In a room full of smart scientists, Francis continually reearned his position as the heavyweight champ."
Eugenics.
Crick occasionally expressed his views on eugenics, usually in private letters. For example, Crick advocated a form of positive eugenics in which wealthy parents would be encouraged to have more children. He once remarked, "In the long run, it is unavoidable that society will begin to worry about the character of the next generation... It is not a subject at the moment which we can tackle easily because people have so many religious beliefs and until we have a more uniform view of ourselves I think it would be risky to try and do anything in the way of eugenics... I would be astonished if, in the next 100 or 200 years, society did not come round to the view that they would have to try to improve the next generation in some extent or one way or another."
Creationism.
Crick was a firm critic of Young Earth creationism. In the 1987 United States Supreme Court case "Edwards v. Aguillard", Crick joined a group of other Nobel laureates who advised, "'Creation-science' simply has no place in the public-school science classroom." Crick was also an advocate for the establishment of Darwin Day as a British national holiday.
Recognition.
In addition to his third share of the 1962 Nobel prize for Physiology or Medicine, he received many awards and honours, including the Royal and Copley medals of the Royal Society (1972 and 1975), and also the Order of Merit (on 27 November 1991); he refused an offer of a CBE in 1963 and later refused an offer of a knighthood, but was often referred to in error as 'Sir Francis Crick' and even on occasions as 'Lord Crick.'
The award of Nobel prizes to John Kendrew and Max Perutz, and to Crick, Watson, and Wilkins was satirised in a short sketch in the BBC TV programme That Was The Week That Was with the Nobel Prizes being referred to as 'The Alfred Nobel Peace Pools.'
Francis Crick Medal and Lecture.
The Francis Crick Medal and Lecture was established in 2003 following an endowment by his former colleague, Sydney Brenner, joint winner of the 2002 Nobel Prize in Physiology and Medicine. The lecture is delivered annually in any field of biological sciences, with preference given to the areas in which Francis Crick himself worked. Importantly, the lectureship is aimed at younger scientists, ideally under 40, or whose career progression corresponds to this age. s of 2015[ [update]], Crick lecture have been delivered by Julie Ahringer, Dario Alessi, Ewan Birney, Simon Boulton, Jason Chin, Simon Fisher, Matthew Hurles, Gilean McVean, Duncan Odom, Geraint Rees, Sarah Teichmann and Daniel Wolpert.
Francis Crick Institute.
The Francis Crick Institute is a £660,000,000 biomedical research centre currently under construction, located in London, United Kingdom. The Francis Crick Institute is a partnership between Cancer Research UK, Imperial College London, King's College London, the Medical Research Council, University College London (UCL) and the Wellcome Trust. Once completed in 2015, it will be the largest centre for biomedical research and innovation in Europe.
Francis Crick Graduate Lectures.
The University of Cambridge Graduate School of Biological, Medical and Veterinary Sciences hosts The Francis Crick Graduate Lectures. The first two lectures were by John Gurdon and Tim Hunt.

</doc>
<doc id="11463" url="http://en.wikipedia.org/wiki?curid=11463" title="Francis van Aarssens">
Francis van Aarssens

Baron Francis van Aarssens or Baron François van Aerssen (27 September 1572 - 27 December 1641), from 1611 on lord of Sommelsdijk, was a diplomat and statesman of the United Provinces.
Biography.
He was born in Brussels, the son of Cornelis van Aarsens, also a statesman. His talents commended him to the notice of Advocate Johan van Oldenbarnevelt, who sent him, at the age of 26 years, as a diplomatic agent of the states-general to the court of France. He took a considerable part in the negotiations of the Twelve Years' Truce in 1609.
His conduct of affairs having displeased the French king, he was recalled from his post by Oldenbarneveldt in 1616. Such was the hatred he henceforth conceived against his former benefactor, that he did his very utmost to effect Oldebarneveldt's ruin. He was one of the packed court of judges who in 1619 condemned the aged statesman to death. For his share in this judicial murder a deep stain rests on the memory of Aarssens.
He afterwards became the confidential counsellor of Maurice, Prince of Orange, and afterwards of Frederick Henry, Prince of Orange, in their conduct of the foreign affairs of the republic. He was sent on special embassies to Venice, Germany and England, and displayed so much diplomatic skill and finesse that Cardinal Richelieu ranked him among the three greatest politicians of his time. He died, aged 69, in The Hague.

</doc>
<doc id="11464" url="http://en.wikipedia.org/wiki?curid=11464" title="Frigate">
Frigate

A frigate is any of several types of warship, the term having been used for ships of various sizes and roles over the last few centuries.
In the 17th century, the term was used for any warship built for speed and maneuverability, the description often used being "frigate-built". These could be warships carrying their principal batteries of carriage-mounted guns on a single deck or on two decks (with further smaller carriage-mounted guns usually carried on the forecastle and quarterdeck of the vessel). The term was generally used for ships too small to stand in the line of battle, although early line-of-battle ships were frequently referred to as frigates when they were built for speed.
In the 18th century, the term referred to ships that were usually as long as a ship of the line and were square-rigged on all three masts (full rigged), but were faster and with lighter armament, used for patrolling and escort. In the definition adopted by the British Admiralty, they were rated ships of at least 28 guns, carrying their principal armaments upon a single continuous deck — the upper deck — while ships of the line possessed two or more continuous decks bearing batteries of guns.
In the late 19th century (beginning about 1858 with the construction of prototypes by the British and French navies), the armoured frigate was a type of ironclad warship that for a time was the most powerful type of vessel afloat. The term "frigate" was used because such ships still mounted their principal armaments on a single continuous upper deck. The later 19th century battleship thus developed from the frigate rather than from the ship of the line.
In modern navies, frigates are used to protect other warships and merchant-marine ships, especially as anti-submarine warfare (ASW) combatants for amphibious expeditionary forces, underway replenishment groups, and merchant convoys. Ship classes dubbed "frigates" have also more closely resembled corvettes, destroyers, cruisers, and even battleships. The rank "frigate captain" derives from the name of this type of ship.
Age of sail.
Origins.
The term "frigate" (Italian: "fregata"; Spanish/Catalan/Portuguese/Sicilian: "fragata"; Dutch: "fregat"; French: "fregate") originated in the Mediterranean in the late 15th century, referring to a lighter galleass type ship with oars, sails and a light armament, built for speed and maneuverability. The etymology of the word is unknown, although it may have originated as a corruption of "", a Latin word for an open vessel with no lower deck. "Aphractus" was, in turn, derived from the Ancient Greek phrase ἄφρακτος ναῦς ("aphraktos naus"), or "undefended ship".
In 1583, during the Eighty Years' War, Habsburg Spain recovered the Southern Netherlands from the rebellious Dutch. This soon led to the occupied ports being used as bases for privateers, the Dunkirkers, to attack the shipping of the Dutch and their allies. To achieve this they developed small, maneuverable, sail-only vessels that came to be referred to as frigates. The success of these Dunkirker vessels influenced the ship design of the Dutch and other navies contending with them but because most regular navies required ships of greater endurance than the Dunkirker frigates could provide, the term was soon applied less exclusively to any relatively fast and elegant sail-only war ship. In French, the term "frigate" became a verb, meaning 'to build long and low', and an adjective, adding further confusion. Even the huge English "Sovereign of the Seas" could be described as "a delicate frigate" by a contemporary after her upper decks were reduced in 1651.
The navy of the Dutch Republic was the first navy to build the larger ocean-going frigates. The Dutch navy had three principal tasks in the struggle against Spain: to protect Dutch merchant ships at sea, to blockade the ports of Spanish-held Flanders to damage trade and halt enemy privateering, and to fight the Spanish fleet and prevent troop landings. The first two tasks required speed, shallowness of draft for the shallow waters around the Netherlands, and the ability to carry sufficient supplies to maintain a blockade. The third task required heavy armament, sufficient to fight against the Spanish fleet. The first of these larger battle-capable frigates were built around 1600 at Hoorn in Holland. By the later stages of the Eighty Years War the Dutch had switched entirely from the heavier ships still used by the English and Spanish to the lighter frigates, carrying around 40 guns and weighing around 300 tons.
The effectiveness of the Dutch frigates became most visible in the Battle of the Downs in 1639, encouraging most other navies, especially the English, to adopt similar designs.
The fleets built by the Commonwealth of England in the 1650s generally consisted of ships described as "frigates", the largest of which were two-decker 'great frigates' of the third rate. Carrying 60 guns, these vessels were as big and capable as 'great ships' of the time; however, most other frigates at the time were used as 'cruisers': independent fast ships. The term "frigate" implied a long hull design, which relates directly to speed (see hull speed) and also, in turn, helped the development of the broadside tactic in naval warfare.
At this time, a further design evolved, reintroducing oars to create the galley frigate such as HMS "Charles Galley" of 1676 which was rated as a 32-gun fifth rate but also had a bank of 40 oars set below the upper deck which could be used to propel the ship in the absence of a favourable wind.
In Danish, the word "fregat" is often applied to warships carrying as few as 16 guns, such as HMS "Falcon" which the British classified as a sloop.
Under the rating system of the Royal Navy, by the middle of the 18th century, the term "frigate" was technically restricted to single-decked ships of the fifth rate, though small 28-gun frigates were classed as sixth rate.
Classic design.
The classic sailing frigate, well-known today for its role in the Napoleonic wars, can be traced back to French developments in the second quarter of the 18th century. The French-built "Médée" of 1740 is often regarded as the first example of this type. These ships were square-rigged and carried all their main guns on a single continuous upper deck. The lower deck, known as the "gun deck", now carried no armament, and functioned as a "berth deck" where the crew lived, and was in fact placed below the waterline of the new frigates.
A total of fifty-nine French sailing frigates were built between 1777 and 1790, with a standard design averaging a hull length of 135 ft and an average draught of 13 ft. The new frigates recorded sailing speeds of up to 14 kn, significantly faster than their predecessor vessels. They were able to fight with all their guns when the seas were so rough that comparable two-deckers had to close the gun-ports on their lower decks (see the Action of 13 January 1797, for an example when this was decisive). Like the larger 74 which was developed at the same time, the new frigates sailed well and were good fighting vessels due to a combination of long hulls and low upperworks compared to vessels of comparable size and firepower.
The Royal Navy captured a handful of the new French frigates during the War of the Austrian Succession (1740–1748) and were impressed by them, particularly for their inshore handling capabilities. They soon built copies and started to adapt the type to their own needs, setting the standard for other frigates as the leading naval power. The first British frigates carried 28 guns including an upper deck battery of twenty-four 9-pounder guns (the remaining four smaller guns were carried on the quarter deck) but soon developed into fifth-rate ships of 32 or 36 guns including an upper deck battery of twenty-six 12-pounder guns, with the remaining six or ten smaller guns carried on the quarter deck and forecastle. From around 1778, a larger "heavy" frigate was developed with a main battery of twenty-six or twenty-eight 18-pounder guns (again with the remaining ten smaller guns carried on the quarter deck and forecastle).
Both British and American frigates could (and usually did) additionally carry smaller carriage-mounted guns on their quarter decks and forecastles (the superstructures above the upper deck). Technically, rated ships with fewer than 28 guns could not be classed as frigates but as "post ships"; however, in common parlance most post ships were often described as "frigates", the same casual misuse of the term being extended to smaller two-decked ships that were too small to stand in the line of battle.
Royal Navy frigates of the late 18th century included the 1780-vintage "Perseverance" class, which measured around 900 tons burthen and carried 36 guns; this successful class was followed by numerous other classes that measured over 1,000 tons burthen and carried 38 guns.
In 1797, three of the United States Navy's first six major ships were rated as 44-gun frigates (or "super-frigates"), which operationally carried fifty-six to sixty 24-pounder long guns and 32-pounder or 42-pounder carronades on two decks; by all regards they were exceptionally powerful and tough. These ships were so well-armed that they were often regarded as equal to ships of the line, and after a series of losses at the outbreak of the War of 1812, Royal Navy fighting instructions ordered British frigates (usually of 38 guns or less) to never engage American frigates at any less than a 2:1 advantage. , preserved as a museum ship by the US Navy, is the oldest commissioned warship afloat, and is a surviving example of a frigate from the Age of Sail. "Constitution" and her sister ships "President" and "United States" were created in a response to deal with the Barbary Coast pirates and in conjunction with the Naval Act of 1794. The three big frigates, when built, had a distinctive building pattern which minimised "hogging" (in which the centre of the keel rises while both ends drop) and improves hydrodynamic efficiency.
The hull was designed so that all the weight from the guns was upon the keel itself. Joshua Humphreys proposed that only live oak, a tree that grew only in America, should be used to build these ships. The method was to use diagonal riders, eight on each side that sat a 45 degree angle. These beams of live oak were about two feet wide and around a foot thick and helped to maintain the shape of the hull, serving also to reduce flexibility and to minimize impacts. These ideas were considered revolutionary in the late 18th and early 19th century. A three-layer method was used in which the planks along the sides of the hull were laid horizontally across the ribs, making a crossing or checker board pattern. The sides of the ship could be as thick as 25 inches, and were able to absorb substantial damage. The strength of this braced construction earned USS "Constitution" the nickname "Old Ironsides".
Role.
Frigates were perhaps the hardest-worked of warship types during the Age of Sail. While smaller than a ship-of-the-line, they were formidable opponents for the large numbers of sloops and gunboats, not to mention privateers or merchantmen. Able to carry six months' stores, they had very long range; and vessels larger than frigates were considered too valuable to operate independently.
Frigates scouted for the fleet, went on commerce-raiding missions and patrols, and conveyed messages and dignitaries. Usually, frigates would fight in small numbers or singly against other frigates. They would avoid contact with ships-of-the-line; even in the midst of a fleet engagement it was bad etiquette for a ship of the line to fire on an enemy frigate which had not fired first. Frigates were involved in fleet battles, often as "repeating frigates". In the smoke and confusion of battle, signals made by the fleet commander, whose flagship might be in the thick of the fighting, might be missed by the other ships of the fleet. Frigates were therefore stationed to windward or leeward of the main line of battle, and had to maintain a clear line of sight to the commander's flagship. Signals from the flagship were then repeated by the frigates, which themselves standing out of the line and clear from the smoke and disorder of battle, could be more easily seen by the other ships of the fleet. If damage or loss of masts prevented the flagship from making clear conventional signals, the repeating frigates could interpret them and hoist their own in the correct manner, passing on the commander's instructions clearly.
For officers in the Royal Navy, a frigate was a desirable posting. Frigates often saw action, which meant a greater chance of glory, promotion, and prize money.
Unlike larger ships that were placed in ordinary, frigates were kept in service in peacetime as a cost-saving measure and to provide experience to frigate captains and officers which would be useful in wartime. Frigates could also carry marines for boarding enemy ships or for operations on shore; in 1832, the frigate USS "Potomac" landed a party of 282 sailors and Marines ashore in the US Navy's first Sumatran expedition.
Common armament was one gundeck with 24-30 long guns, from 8- to 24-pounders (3.6 to 11 kg), with up to a dozen light guns or carronades carronades on the quarterdeck and forecastle above.
Frigates remained a crucial element of navies until the mid-19th century. The first ironclads were classified as "frigates" because of the number of guns they carried. However, terminology changed as iron and steam became the norm, and the role of the frigate was assumed first by the protected cruiser and then by the light cruiser.
Frigates are often the vessel of choice in historical naval novels due to their relative freedom compared to ships of the line (kept for fleet actions) and smaller vessels (generally assigned to a home port and less widely ranging). For example the Patrick O'Brian Aubrey–Maturin series, C. S. Forester's Horatio Hornblower series and Alexander Kent's Richard Bolitho series. The motion picture "" features a reconstructed historic frigate, HMS "Rose", to depict Aubrey's frigate HMS "Surprise".
Age of steam.
Vessels classed as frigates continued to play a great role in navies with the adoption of steam power in the 19th century. In the 1830s, navies experimented with large paddle steamers equipped with large guns mounted on one deck, which were termed "paddle frigates".
From the mid-1840s on, frigates which more closely resembled the traditional sailing frigate were built with steam engines and screw propellers. These "screw frigates", built first of wood and later of iron, continued to perform the traditional role of the frigate until late in the 19th century.
Armoured frigate.
From 1859, armour was added to ships based on existing frigate and ship of the line designs. The additional weight of the armour on these first ironclad warships meant that they could have only one gun deck, and they were technically frigates, even though they were more powerful than existing ships-of-the-line and occupied the same strategic role. The phrase "armoured frigate" remained in use for some time to denote a sail-equipped, broadside-firing type of ironclad.
After 1875, the term "frigate" fell out of use. Vessels with armoured sides were designated as "battleships" or "armoured cruisers", while "protected cruisers" only possessed an armoured deck, and unarmoured vessels, including frigates and sloops, were classified as "unprotected cruisers".
Second World War.
Modern frigates are related to earlier frigates only by name. The term "frigate" was readopted during the Second World War by the Royal Navy to describe an anti-submarine escort vessel that was larger than a corvette, smaller than a destroyer, and about equal in size and capability to the American destroyer escort. Anti-submarine escorts had previously been classified as sloops by the Royal Navy, and the "Black Swan"-class sloops of 1939–1945 were as large as the new types of frigate, and more heavily armed. Twenty-two of these were reclassified as Frigates after the war, as were the remaining 24 smaller Castle class corvettes.
The frigate was introduced to remedy some of the shortcomings inherent in the corvette design: limited armament, a hull form not suited to open-ocean work, a single shaft which limited speed and maneuverability, and a lack of range. The frigate was designed and built to the same mercantile construction standards (scantlings) as the corvette, allowing manufacture by yards unused to warship construction. The first frigates of the River class (1941) were essentially two sets of corvette machinery in one larger hull, armed with the latest Hedgehog anti-submarine weapon.
The frigate possessed less offensive firepower and speed than a destroyer, but such qualities were not required for anti-submarine warfare. Submarines were slow while submerged, and ASDIC sets did not operate effectively at speeds of over 20 kn. Rather, the frigate was an austere and weatherly vessel suitable for mass-construction and fitted with the latest innovations in anti-submarine warfare. As the frigate was intended purely for convoy duties, and not to deploy with the fleet, it had limited range and speed.
The contemporary German "Flottenbegleiter" ("fleet escorts"), also known as "F-Boats", were essentially frigates. They were based on a pre-war "Oberkommando der Marine" concept of vessels which could fill roles such as fast minesweeper, minelayer, merchant escort and anti-submarine vessel. Because of the Treaty of Versailles their displacement was officially limited to 600 tons, although in reality they exceeded this by about 100 tons. F-boats had two stacks and two 105 mm gun turrets. The design was flawed because of its narrow beam, sharp bow and unreliable high pressure steam turbines. F-boats were succeeded in operational duties by Type 35 and Elbing class torpedo boats. "Flottenbegleiter" remained in service as advanced training vessels.
It was not until the Royal Navy's Bay class of 1944 that a British design classified as a "frigate" was produced for fleet use, although it still suffered from limited speed. These anti-aircraft frigates, built on incomplete Loch-class frigate hulls, were similar to the United States Navy's destroyer escorts (DE), although the latter had greater speed and offensive armament to better suit them to fleet deployments. The destroyer escort concept came from design studies by the General Board of the United States Navy in 1940, as modified by requirements established by a British commission in 1941 prior to the American entry into the war, for deep-water escorts. The American-built destroyer escorts serving in the British Royal Navy were rated as Captain-class frigates. The U.S. Navy's two Canadian-built "Asheville"-class and 96 British-influenced, American-built "Tacoma"-class frigates that followed originally were classified as "patrol gunboats" (PG) in the U.S. Navy but on 15 April 1943 were all reclassified as patrol frigates (PF).
In preservation and in fiction.
Moored on the Thames Embankment in London are two surviving Royal Navy anti-submarine sloops, which are the predecessors of the WW2 frigates:
Contemporary.
Guided-missile role.
The introduction of the surface-to-air missile after the Second World War made relatively small ships effective for anti-aircraft warfare: the "guided missile frigate." In the USN, these vessels were called "ocean escorts" and designated "DE" or "DEG" until 1975 – a holdover from the Second World War destroyer escort or "DE". The Royal Canadian Navy and British Royal Navy maintained the use of the term "frigate"; likewise, the French Navy refers to missile-equipped ship, up to cruiser-sized ships, by the name of "frégate", while smaller units are named "aviso". Soviet Navy used the term "guard-ship" ("сторожевой корабль").
From the 1950s to the 1970s, the United States Navy commissioned ships classed as guided missile frigates which were actually anti-aircraft warfare cruisers built on destroyer-style hulls. Some of these ships—the "Bainbridge", "Truxtun", "California" and "Virginia" classes—were nuclear-powered. These "frigates" were roughly mid-way in size between cruisers and destroyers. This was similar to the use of the term "frigate" during the age of sail during which it referred to a medium-sized warship, but it was inconsistent with conventions used by other contemporary navies which regarded frigates as being smaller than destroyers. During the 1975 ship reclassification, the large American frigates were redesignated as cruisers or destroyers, while ocean escorts (the American classification for ships smaller than destroyers) were renamed as frigates.
One of the most successful post-1945 designs was the British "Leander"-class frigate, which was used by several navies. Laid down in 1959, the "Leanders" were based on the previous Type 12 anti-submarine frigate but equipped for anti-aircraft use as well. They were used by the UK into the 1990s, at which point some were sold onto other navies. The "Leander" design, or improved versions of it, were licence-built for other navies.
Nearly all modern frigates are equipped with some form of offensive or defensive missiles, and as such are rated as guided-missile frigates (FFG). Improvements in surface-to-air missiles (e.g., the Eurosam Aster 15) allow modern guided-missile frigates to form the core of many modern navies and to be used as a fleet defence platform, without the need for specialised anti-air warfare frigates.
Other uses.
The Royal Navy Type 61 "Salisbury" class were "air direction" frigates equipped to track aircraft. To this end they had reduced armament compared to the Type 41 "Leopard"-class air-defence frigates built on the same hull.
Multi-role frigates like MEKO 200, "Anzac" class frigate and "Halifax" class frigate are designed for navies needing warships deployed in a variety of situations that a general frigate class would not be able to fulfill and not requiring the need for deploying destroyers.
Anti-submarine role.
At the opposite end of the spectrum, some frigates are specialised for anti-submarine warfare. Increasing submarine speeds towards the end of the Second World War (see German Type XXI submarine) greatly reduced the margin of speed superiority of frigate over submarine. The frigate could no longer be slow and powered by mercantile machinery and consequently postwar frigates, such as the "Whitby" class, were faster.
Such ships carry improved sonar equipment, such as the variable depth sonar or towed array, and specialised weapons such as torpedoes, forward-throwing weapons such as Limbo and missile-carried anti-submarine torpedoes such as ASROC or Ikara. Surface-to-air missiles such as Sea Sparrow and surface-to-surface missiles such as Exocet give them defensive and offensive capabilities. The Royal Navy's original Type 22 frigate is an example of a specialised anti-submarine warfare frigate.
Especially for anti-submarine warfare, most modern frigates have a landing deck and hangar aft to operate helicopters, eliminating the need for the frigate to close with unknown sub-surface threats, and using fast helicopters to attack nuclear submarines which may be faster than surface warships. For this task the helicopter is equipped with sensors such as sonobuoys, wire-mounted dipping sonar and magnetic anomaly detectors to identify possible threats, and torpedoes or depth-charges to attack them.
With their onboard radar helicopters can also be used to reconnoitre over-the-horizon targets and, if equipped with anti-ship missiles such as Penguin or Sea Skua, to attack them. The helicopter is also invaluable for search and rescue operation and has largely replaced the use of small boats or the jackstay rig for such duties as transferring personnel, mail and cargo between ships or to shore. With helicopters these tasks can be accomplished faster and less dangerously, and without the need for the frigate to slow down or change course.
Further developments.
Stealth technology has been introduced in modern frigate design. Frigate shapes are designed to offer a minimal radar cross section, which also lends them good air penetration; the maneuverability of these frigates has been compared to that of sailing ships. Examples are the French "La Fayette" class with the Aster 15 missile for anti-missile capabilities, the German F125 class and "Sachsen"-class frigates, the Turkish TF-2000 type frigates with the MK-41 VLS, and the Indian "Shivalik" class frigate and "Talwar" class frigate with the Brahmos missile system.
The modern French Navy applies the term first-class frigate and second-class frigate to both destroyers and frigates in service. Pennant numbers remain divided between F-series numbers for those ships internationally recognised as frigates and D-series pennant numbers for those more traditionally recognised as destroyers. This can result in some confusion as certain classes are referred to as frigates in French service while similar ships in other navies are referred to as destroyers. This also results in some recent classes of French ships being among the largest in the world to carry the rating of frigate.
In the German Navy, frigates were used to replace aging destroyers; however in size and role the new German frigates exceed the former class of destroyers. The future German F125 class frigate will be the largest class of frigates worldwide with a displacement of more than 7,200 tons. The same was done in the Spanish Navy, which went ahead with the deployment of the first Aegis frigates, the "Álvaro de Bazán"-class frigates.
Littoral Combat Ship (LCS).
Some new classes of ships similar to corvettes are optimized for high-speed deployment and combat with small craft rather than combat between equal opponents; an example is the U.S. Littoral Combat Ship (LCS). By 2019, all Oliver Hazard Perry-class frigates in the United States Navy were to be replaced by the LCS. While the LCS class ships are smaller than the frigate class they will replace, they offer a similar degree of weaponry while requiring less than half the crew complement and offering a top speed of over 40 knots. A major advantage for the LCS ships is that they are designed around specific mission modules allowing them to fulfill a variety of roles. The modular system also allows for most upgrades to be performed ashore and installed later into the ship, keeping the ships available for deployment for the maximum time.
The latest U.S. deactivation plans will retire all "Oliver Hazard Perry"-class frigates by October 2015, which will be the first time that the U.S. Navy has been without a frigate class of ships since 1943 (technically the is rated as a frigate and is still in commission, but does not count towards Navy force levels). 
The remaining 20 LCSs to be acquired from 2019 and onwards that will be enhanced will be designated as frigates, and existing ships given modifications may also have their classification changed to "FF" as well.
See also.
Lists.
Note that Algerian, Tripolitan and Tunisian sail frigates are listed under Turkey. All Italian city-state frigates are listed under Italy.

</doc>
<doc id="11466" url="http://en.wikipedia.org/wiki?curid=11466" title="Francisco Franco">
Francisco Franco

Francisco Franco Bahamonde (]; 4 December 1892 – 20 November 1975) was a Spanish general and the dictator of Spain from 1939 until his death in 1975. Coming from a military background, he became the youngest general in Europe in the 1920s.
A strong conservative, he was shocked when the monarchy was removed and replaced with a republic in 1931. With the 1936 elections, the conservatives lost by a narrow margin and the leftist Popular Front came to power. Looking to overthrow the republic, Franco and other generals staged a partially successful coup, which started the Spanish Civil War. With the death of the other generals, Franco quickly became his faction's only leader.
Franco's ultranationalist faction received military support from several fascist groups, most notably from Nazi Germany and the Kingdom of Italy, while the Republican side was supported by Spanish communists, anarchists, and several Basques, Catalans, and Galicians. It also received help from the Soviet Union and the International Brigades. Leaving half a million dead, the war was eventually won by Franco in 1939. He established an autocratic dictatorship, which he defined as a totalitarian state. Franco proclaimed himself as both head of state and government under the title Caudillo, a term similar to duce (Italian) and Führer (German). During the Francoist regime, only one political party was legal: a merger of the monarchist party and the fascist party that helped him during the war, FET y de las JONS.
Franco led a series of politically-motivated violent acts, including but not limited to concentration camps, forced labor and executions, mostly against political and ideological enemies, causing an estimated 200,000 to 400,000 deaths, depending on how death in the more than 190 concentration camps is considered. Franco's Spain maintained an official policy of neutrality during World War II, with the exception of the Blue Division. By the 1950s, the nature of his regime changed from an extreme form of dictatorship to a semi-pluralist authoritarian system. During the Cold War, Franco appeared as one of the World’s foremost anticommunist figures and his regime was assisted by the United States and was asked to join the United Nations and came under NATO's protection. By the 1960s, Spain saw progressive economical development and timid democratic improvements.
After a 36-year rule, Franco died in 1975. He restored the monarchy before his death, which made King Juan Carlos I his successor, who led the Spanish transition to democracy. After a referendum, a new constitution was adopted, which effectively created a democratic regime in Spain.
Early life.
Francisco Franco was born at 12:30 p.m. on 4 December 1892 at number 108 Calle Frutos Saavedra in Ferrol, Spain. He was baptised on 17 December at the military church of San Francisco with the baptismal names Francisco Paulino Hermenegildo Teódulo Franco Bahamonde: Francisco for his paternal grandfather, Paulino for his godfather, Hermenegildo for his maternal grandmother and godmother and Teódulo for the saint day of his birth.
His father's ancestry was from Andalusia. Since relocating to Galicia, his father's family was strongly involved in the Spanish Navy and over the span of two centuries produced naval officers for six uninterrupted generations, right down to Franco's father Nicolás Franco y Salgado-A (22 November 1855 – 22 February 1942).
His mother was María del Pilar Bahamonde y Pardo de Andrade (1865 – 28 February 1934)and she was an upper middle-class Roman Catholic. His parents married in 1890. The young Franco spent much of his childhood with his two brothers, Nicolás (Ferrol, 1891–1977), later a naval officer and diplomat who in time was married to María Isabel Pascual del Pobil y Ravello, and Ramón, and his two sisters, María del Pilar (Ferrol, 1894 – Madrid, 1989), later wife of Alonso Jaráiz y Jeréz, and María de la Paz (Ferrol, 1899 – Ferrol, 1903).
Military career.
Rif War and advancement through the ranks.
Francisco was to follow his father into the Navy, but as a result of the Spanish–American War the country lost much of its navy as well as most of its colonies. Not needing any more officers, the Naval Academy admitted no new entrants from 1906 to 1913. To his father's chagrin, Francisco decided to try the Spanish Army. In 1907, he entered the Infantry Academy in Toledo, graduating in 1910 as a lieutenant. Two years later, he obtained a commission to Morocco. Spanish efforts to occupy their new African protectorate provoked the protracted Rif War (from 1909 to 1927) with native Moroccans. Their tactics resulted in heavy losses among Spanish military officers, but they also provided an opportunity to earn promotion through merit. It was said that officers would receive either "la caja o la faja" (a coffin or a general's sash). Franco quickly gained a reputation as a good officer. In 1913, Franco transferred into the newly formed regulares: Moroccan colonial troops with Spanish officers, who acted as shock troops. This transfer may have been decided because Franco failed to win the hand of his first love, Sofía Subirán.
In 1916, age 23 and already a captain, he was shot by enemy machine gun fire. He was badly wounded in the abdomen, specifically the liver, in a skirmish at "El Biutz" and possibly lost a testicle. The physicians of the battle later concluded that his intestines were spared because he inhaled when he was shot. His survival marked him permanently in the eyes of the native troops as a man of "baraka" (good luck). He was recommended for Spain's highest honor for gallantry, the coveted "Cruz Laureada de San Fernando", but was instead received the "Cross of Maria Cristina, First Class". With that he was promoted to Major in the end of February 1917. This made him the youngest major in the Spanish army. From 1917 to 1920, he served in Spain. In 1920, Lieutenant Colonel José Millán Astray, a histrionic but charismatic officer, founded the Spanish Foreign Legion, on similar lines to the French Foreign Legion. Franco became the Legion's second-in-command and returned to Africa. On 24 July 1921, the poorly commanded and overextended Spanish Army suffered a crushing defeat at Annual from Rif tribesmen led by the Abd el-Krim brothers. The Legion and supporting units relieved the Spanish enclave of Melilla after a three-day forced march led by Franco. In 1923, by now a lieutenant colonel, he was made commander of the Legion.
That year, he married María del Carmen Polo y Martínez-Valdès. Three years later the couple had a daughter, María del Carmen. Following his honeymoon Franco was summoned to Madrid to be presented to King Alfonso XIII. This and other occasions of royal attention would mark him during the Republic as a monarchical officer. Promoted to colonel, Franco led the first wave of troops ashore at Al Hoceima in 1925. This landing in the heartland of Abd el-Krim's tribe, combined with the French invasion from the south, spelled the beginning of the end for the short-lived Republic of the Rif. Franco's recognition eventually caught up to him and was promoted to Brigadier General on February 3, 1926. This made him the youngest General in Spain, and perhaps the youngest General of Europe. Nonetheless, in 1928 Franco was appointed director of the newly created General Military Academy of Zaragoza, a new college for all Army cadets, replacing the former separate institutions for young men seeking to become officers in infantry, cavalry, artillery, and other branches of the army. When Franco was removed as Director of the Zaragoza Military Academy in 1931, about 95% of Franco's former Zaragoza cadets would come to side with him in the Civil War.
During the Second Spanish Republic.
With the fall of the monarchy in 1931, Franco did not take any notable stand. But the closing of the Academy in June by War Minister Manuel Azaña provoked his first clash with the Spanish Republic. Azaña found Franco's farewell speech to the cadets insulting. In Franco's speech though, he did stress the Republic's need for discipline and respect. For six months, Franco was without a post and under surveillance.
Franco was a subscriber to "Acción Española", an ultra-right wing monarchist theoretical journal, and a firm believer in the Jewish-Masonic-Bolshevik conspiracy or "contubernio" (filthy cohabitation)—'one of Franco's favourite words'; a conspiracy in which Jews, Freemasons and leftists allegedly sought the destruction of Christian Europe, with Spain the principal target.
On February 5, 1932, he was given a command in A Coruña. Franco avoided involvement in José Sanjurjo's attempted "coup" that year, and even wrote a hostile letter to Sanjurjo expressing his anger over the attempt. As a side result of Azaña's military reform, in January 1933, Franco was relegated from the first to the 24th in the list of Brigadiers; conversely, the same year (17 February), he was given the military command of the Balearic Islands: a post above his rank.
New elections held in October 1933 resulted in a center-right majority. In opposition to this government, a revolutionary communist movement broke out October 5, 1934. This uprising was rapidly quelled in most of the country, but gained a stronghold in Asturias, with the support of the miners' unions. Franco, already General of Division and aide to the war minister, Diego Hidalgo, was put in command of the operations directed to suppress the insurgency. Troops of the Spanish Army of Africa carried this out, with General Eduardo López Ochoa as commander in the field. After two weeks of heavy fighting (and a death toll estimated between 1,200 and 2,000), the rebellion was suppressed.
The insurgency in Asturias (see Asturian miners' strike of 1934) sharpened the antagonism between Left and Right. Franco and López Ochoa (who, prior to the campaign in Asturias, had been seen as a left-leaning officer) emerged as officers prepared to use 'troops against Spanish civilians as if they were a foreign enemy'. Franco described the rebellion to a journalist in Oviedo as, 'a frontier war and its fronts are socialism, communism and whatever attacks civilization in order to replace it with barbarism.' Though the colonial units sent to the north by the government at Franco's recommendation consisted of the Spanish Foreign Legion and the Moroccan Regulares Indigenas, the right wing press portrayed the Asturian rebels in xenophobic terms as lackeys of a foreign Jewish-Bolshevik conspiracy. At the start of the Civil War, López Ochoa was assassinated. Some time after these events, Franco was briefly commander-in-chief of the Army of Africa (from 15 February onwards), and from 19 May 1935 on, Chief of the General Staff.
General election of 1936.
After the ruling centre-right coalition collapsed amid the Straperlo corruption scandal, new elections were scheduled. Two wide coalitions formed: the Popular Front on the left, ranging from Republican Union Party to Communists, and the Frente Nacional on the right, ranging from the center radicals to the conservative Carlists. On 16 February 1936, the left won by a narrow margin. Growing political bitterness surfaced again. The government and its supporters, the Popular Front, had launched a campaign against the Opposition whom they accused of plotting against the Republic. According to the right wing opposition, the real enemies of the Republic were not on the Right but on the Left; Spain was in imminent danger of falling under a "Communist dictatorship", and therefore by fighting the democratically elected Popular Front they, the opposition, were merely doing their duty in defence of law and order and of the freedom and the fundamental rights of the Spanish people.
The days after the election were marked by near-chaotic circumstances.
On February 23, Franco was sent to the distant Canary Islands to serve as the islands' military commander, an appointment perceived by him as a "destierro" (banishment). Meanwhile, a conspiracy led by Emilio Mola was taking shape. In June, Franco was contacted and a secret meeting was held within the forest of La Esperanza on Tenerife to discuss starting a military coup. (An obelisk commemorating this historic meeting was erected at the site in a clearing at Las Raíces.)
Outwardly, Franco maintained an ambiguous attitude almost up until July. On 23 June 1936, he wrote to the head of the government, Casares Quiroga, offering to quell the discontent in the Spanish Republican Army, but was not answered. The other rebels were determined to go ahead "con Paquito o sin Paquito" (with "Paquito" or without "Paquito"; "Paquito" being a diminutive of "Paco", which in turn is short for "Francisco"), as it was put by José Sanjurjo, the honorary leader of the military uprising. After various postponements, 18 July was fixed as the date of the uprising. The situation reached a point of no return and, as presented to Franco by Mola, the coup was unavoidable and he had to choose a side. He decided to join the rebels and was given the task of commanding the Army of Africa. A privately owned DH 89 De Havilland Dragon Rapide, flown by two British MI6 agents, Cecil Bebb and Hugh Pollard, was chartered in England 11 July to take Franco to Africa.
The assassination of the right-wing opposition leader José Calvo Sotelo by government police troops, possibly acting on their own in retaliation for the murder of José Castillo, precipitated the uprising. On 17 July one day earlier than planned, the African Army rebelled, detaining their commanders. On 18 July, Franco published a manifesto and left for Africa, where he arrived the next day to take command.
A week later, the rebels, who soon called themselves the "Nationalists", controlled a third of Spain, but most navy units remained under control of the Republican loyalist forces, which left Franco isolated. The coup had failed in the attempt to bring a swift victory, but the Spanish Civil War had begun.
From the Spanish Civil War to World War II.
The Spanish Civil War began in July 1936 and officially ended with Franco's victory in April 1939, leaving 190,000 to 500,000 dead. Despite the Non-Intervention Agreement of August 1936, the war was marked by foreign intervention on behalf of both sides, leading to international repercussions. The nationalist side was supported by Fascist Italy, which sent the "Corpo Truppe Volontarie", and later by Nazi Germany, which assisted with the Condor Legion. They were opposed by the Soviet Union and communist, socialists and anarchists within Spain. The United Kingdom and France strictly adhered to the arms embargo, provoking dissensions within the French Popular Front coalition led by Léon Blum, but the Republican side was nonetheless supported by the Soviet Union and volunteers fighting in the International Brigades (see for example Ken Loach's "Land and Freedom").
Because Adolf Hitler and Joseph Stalin used the war as a testing ground for modern warfare, some historians, such as Ernst Nolte, have considered the Spanish Civil War, along with World War II, part of a "European Civil War" lasting from 1936 to 1945 and characterized mainly as a left/right ideological conflict. However, this interpretation has not found acceptance among most historians, who consider the Spanish Civil War and Second World War to be two distinct conflicts. Among other things, they point to the political heterogeneity on both sides ("See Spanish Civil War: other factions") and criticize a monolithic interpretation which overlooks the local nuances of Spanish history.
The first months.
Following 18 July 1936 "pronunciamiento", Franco assumed the leadership of the 30,000 soldiers of the Spanish Army of Africa. The first days of the insurgency were marked with a serious need to secure control over the Spanish Moroccan Protectorate. On one side, Franco managed to win the support of the natives and their (nominal) authorities, and, on the other, to ensure his control over the army. This led to the summary execution of some 200 senior officers loyal to the Republic (one of them his own cousin). His loyal bodyguard was shot by Manuel Blanco. Franco's first problem was how to move his troops to the Iberian Peninsula, since most units of the Navy had remained in control of the Republic and were blocking the Strait of Gibraltar. He requested help from Benito Mussolini, who responded with an unconditional offer of arms and planes; in Germany, Wilhelm Canaris, the head of the "Abwehr" military intelligence, persuaded Hitler to also support the Nationalists. From 20 July onward, Franco was able, with a small group of 22 mainly German Junkers Ju 52 airplanes, to initiate an air bridge to Seville, where his troops helped to ensure the rebel control of the city. Through representatives, he started to negotiate with the United Kingdom, Germany, and Italy for more military support, and above all for more airplanes. Negotiations were successful with the last two on 25 July and airplanes began to arrive in Tetouan on 2 August. On 5 August Franco was able to break the blockade with the newly arrived air support, successfully deploying a ship convoy with some 2,000 soldiers.
In early August, the situation in western Andalusia was stable enough to allow him to organize a column (some 15,000 men at its height), under the command of then Lieutenant-Colonel Juan Yagüe, which would march through Extremadura towards Madrid. On 11 August Mérida was taken, and on 15 August Badajoz, thus joining both nationalist-controlled areas. Additionally, Mussolini ordered a voluntary army, the "Corpo Truppe Volontarie" (CTV) of some 12,000 Italians of fully motorized units to Seville and Hitler added to them a professional squadron from the Luftwaffe (2JG/88) with about 24 planes. All these planes had the Nationalist Spanish insignia painted on them, but were flown by Italian and German nationals. The backbone of Franco's aviation in those days were the Italian SM.79 and SM.81 bombers, the biplane Fiat CR.32 fighter and the German Junkers Ju 52 cargo-bomber and the Heinkel He 51 biplane fighter.
On 21 September, with the head of the column at the town of Maqueda (some 80 km away from Madrid), Franco ordered a detour to free the besieged garrison at the Alcázar of Toledo, which was achieved 27 September. This controversial decision gave the Popular Front time to strengthen its defences in Madrid and hold the city that year, but the holding of Alcázar was an important morale and propaganda success for the Nationalists.
Rise to power.
The designated leader of the uprising, Gen. José Sanjurjo, died on 20 July 1936 in an airplane crash. Therefore, in the nationalist zone, "Political life ceased." Initially, only military command mattered; this was divided into regional commands (Emilio Mola in the North, Gonzalo Queipo de Llano in Seville commanding Andalusia, Franco with an independent command and Miguel Cabanellas in Zaragoza commanding Aragon). The Spanish Army of Morocco itself was split into two columns, one commanded by General Juan Yagüe and the other commanded by Colonel José Varela.
From 24 July, a coordinating "junta" was established, based at Burgos. Nominally led by Cabanellas, as the most senior general, it initially included Mola, three other generals, and two colonels; Franco was later added in early August. On 21 September it was decided that Franco was to be commander-in-chief (this unified command was opposed only by Cabanellas), and, after some discussion, with no more than a lukewarm agreement from Queipo de Llano and from Mola, also head of government. He was, doubtlessly, helped to this primacy by the fact that, in late July, Hitler had decided that all of Germany's aid to the nationalists would go to Franco.
Mola had been somewhat discredited as the main planner of the attempted coup that had now degenerated into a civil war, and was strongly identified with the Carlist monarchists and not at all with the Falange, a party with Fascist leanings and connections ("phalanx", a far-right Spanish political party founded by José Antonio Primo de Rivera), nor did he have good relations with Germany; Queipo de Llano and Cabanellas had both previously rebelled against the dictatorship of Miguel Primo de Rivera and were therefore discredited in some nationalist circles; and Falangist leader José Antonio Primo de Rivera was in prison in Alicante (he would be executed a few months later) and the desire to keep a place open for him prevented any other Falangist leader from emerging as a possible head of state. Franco's previous aloofness from politics meant that he had few active enemies in any of the factions that needed to be placated, and had cooperated in recent months with both Germany and Italy.
On 1 October 1936, in Burgos, Franco was publicly proclaimed as "Generalísimo" of the National army and "Jefe del Estado" (Head of State). When Mola was killed in another air accident a year later (which some believe was an assassination) (2 June 1937), no military leader was left from those who organized the conspiracy against the Republic between 1933 and 1935.
Military command.
From that time until the end of the war, Franco personally guided military operations. After the failed assault on Madrid in November 1936, Franco settled on a piecemeal approach to winning the war, rather than bold maneuvering. As with his decision to relieve the garrison at Toledo, this approach has been subject of some debate; some of his decisions, such as in June 1938, when he preferred to head for Valencia instead of Catalonia, remain particularly controversial from a military viewpoint. It was however, in Valencia, Castellon and Alicante where the last troops were defeated by Franco.
Although both Germany and Italy provided military support to Franco, the degree of influence of both powers on his direction of the war seems to have been very limited. Nevertheless, the Italian troops, despite not being always effective, were present in most of the large operations in large numbers, while the German airplanes helped the Nationalist air force dominate the skies for most of the war. António de Oliveira Salazar's Portugal also openly assisted the Nationalists from the start, contributing some 20,000 troops.
It is said that Franco's direction of the German and Italian forces was limited, particularly in the direction of the Condor Legion, however, he was officially, by default, their supreme commander and they rarely made decisions on their own. For reasons of prestige, it was decided to continue assisting Franco until the end of the war, and Italian and German troops paraded on the day of the final victory in Madrid.
Political command.
From 1937 to 1948 the Franco regime was doctrinally at least a semi-fascist state, the categorical fascism of the FET (Falange Española Tradicionalista) as state party being mitigated above all by the confessional nature of the regime—creating the strange hybrid known to some as clerical fascism and to Amando de Miguel as "fascismo frailuno" (friar fascism). 
On 19 April 1937, Franco managed to fuse the ideologically incompatible national-syndicalist Falange ("phalanx", a fascist Spanish political party founded by José Antonio Primo de Rivera) and the Carlist monarchist parties under a single-party under his rule, dubbed "Falange Española Tradicionalista y de las Juntas de Ofensiva Nacional-Sindicalista" (FET y de las JONS), which became the only legal party in 1939. Unlike some other fascist movements, the Falangists did develop an official program, the Twenty Seven Points. These exhibited all the main points of fascistic doctrine. Franco made himself "jefe nacional" of the new FET (Falange Española Tradicionalista), with a secretary, Junta Political and National Council to be named subsequently by himself. Five days later (24 April) the raised-arm Fascist salute of the Falange was made the official salute of the Nationalist regime. In 1939 the fascist style heavily predominated, with ritualistic invocations of "Franco, Franco, Franco." The Falangists' hymn, "Cara al Sol", became the semi-national anthem of Franco's not yet established regime.
This new political formation appeased the pro-Nazi Falangists while tempering them with the anti-German Carlists. Franco's brother-in-law Ramón Serrano Súñer, who was his main political advisor, was able to turn the various parties under Franco against each other to absorb a series of political confrontations against Franco himself. Franco expelled the original leading members of both the Carlists (Manuel Fal Condé) and the Falangists (Manuel Hedilla) to secure his political future. Franco also appeased the Carlists by exploiting the Republicans' anti-clericalism in his propaganda, in particular concerning the "Martyrs of the war". While the loyalist forces presented the war as a struggle to defend the Republic against Fascism, Franco depicted himself as the defender of "Catholic Spain" against "atheist Communism."
The end of the Civil War.
Before the fall of Catalonia in February 1939, the Prime Minister of Spain Juan Negrín unsuccessfully proposed, in the meeting of the Cortes in Figueres, capitulation with the sole condition of respecting the lives of the vanquished. Negrín was ultimately deposed by Colonel Segismundo Casado, later joined by José Miaja.
Thereafter, only Madrid (see History of Madrid) and a few other areas remained under control of the government forces. On 27 February Chamberlain and Daladier's governments recognized the Franco regime, before the official end of the war. The PCE (the Spanish Communist Party) attempted a mutiny in Madrid with the aim of re-establishing Negrín's leadership, but José Miaja retained control. Finally, on 28 March 1939, with the help of pro-Franco forces inside the city (the "fifth column" General Mola had mentioned in propaganda broadcasts in 1936), Madrid fell to the Nationalists. The next day, Valencia, which had held out under the guns of the Nationalists for close to two years, also surrendered. Victory was proclaimed on 1 April 1939, when the last of the Republican forces surrendered. On the same day, Franco placed his sword upon the altar of a church and in a vow, promised that he would never again take up his sword unless Spain itself was threatened with invasion.
At least 70,000 people were executed during the civil war. Franco's victory was followed by thousands of summary executions (from 15,000 to 25,000 people) and imprisonments, while many were put to forced labour, building railways, drying out swamps, digging canals ("La Corchuela", the Canal of the Bajo Guadalquivir), construction of the Valle de los Caídos monument, etc. The 1940 shooting of the president of the Catalan government, Lluís Companys, was one of the most notable cases of this early suppression of opponents and dissenters. According to Gabriel Jackson, the number of victims of the "White Terror" (executions and hunger or illness in prisons) only between 1939 and 1943 was 200,000.
Although leftists suffered a high death-toll, the Spanish intelligentsia and atheists, as well as military and government figures who had remained loyal to the Madrid government during the civil war, were also targeted for oppression.
In his recent, updated history of the Spanish Civil War, Antony Beevor "reckons Franco's ensuing 'white terror' claimed 200,000 lives. The 'red terror' had already killed 38,000." Julius Ruiz concludes that "although the figures remain disputed, a minimum of 37,843 executions were carried out in the Republican zone with a maximum of 150,000 executions (including 50,000 after the war) in Nationalist Spain."
Despite the official end of the war, guerrilla resistance to Franco (known as "the "maquis"") was widespread in many mountainous regions, and continued well into the 1950s. In 1944, a group of republican veterans, which also fought in the French resistance against the Nazis, invaded the Val d'Aran in northwest Catalonia, but they were quickly defeated.
The end of the war led to hundreds of thousands of exiles, mostly to France (but also Mexico, Chile, Cuba, the USA and so on.). On the other side of the Pyrenees, refugees were confined in internment camps of the French Third Republic, such as Camp Gurs or Camp Vernet, where 12,000 Republicans were housed in squalid conditions (mostly soldiers from the Durruti Division). The 17,000 refugees housed in Gurs were divided into four categories (Brigadists, pilots, "Gudaris" and ordinary 'Spaniards'). The "Gudaris" (Basques) and the pilots easily found local backers and jobs, and were allowed to quit the camp, but the farmers and ordinary people, who could not find relations in France, were encouraged by the Third Republic, in agreement with the Francoist government, to return to Spain. The great majority did so and were turned over to the Francoist authorities in Irún. From there they were transferred to the Miranda de Ebro camp for "purification" according to the Law of Political Responsibilities.
After the proclamation by Marshal Philippe Pétain of the Vichy France regime, the refugees became political prisoners, and the French police attempted to round-up those who had been liberated from the camp. Along with other "undesirables", they were sent to the Drancy internment camp before being deported to Nazi Germany. 5,000 Spaniards thus died in Mauthausen concentration camp. The Chilean poet Pablo Neruda, who had been named by the Chilean President Pedro Aguirre Cerda special consul for immigration in Paris, was given responsibility for what he called "the noblest mission I have ever undertaken": shipping more than 2,000 Spanish refugees, who had been housed by the French in squalid camps, to Chile on an old cargo ship, the "Winnipeg".
World War II.
In September 1939, World War II broke out in Europe, and on 23 October 1940 Hitler and Franco met in Hendaye, France, to discuss the possibility of Spain's entry on the side of the Axis. However, Franco's demands, which included food, military equipment, and Spanish control of Gibraltar and French North Africa proved too much for Hitler, and no agreement was reached. (An oft-cited remark attributed to Hitler is that the German leader would rather have some teeth extracted than to have to deal further with Franco.) Although Franco's tactics had received important support from Adolf Hitler and Benito Mussolini during the Spanish civil war, Franco remained emphatically neutral in the Second World War, but nonetheless offered various kinds of support to Italy and Germany. He allowed Spanish soldiers to volunteer to fight in the German Army against the USSR (the Blue Division), but forbade Spaniards to fight in the West against the democracies. Franco's common ground with Hitler was particularly weakened by Hitler's propagation of Nazi mysticism and his attempts to manipulate Christianity, which went against Franco's fervent commitment to defending Christianity and Catholicism. Contributing to the disagreement was an ongoing dispute over German mining rights in Spain. Some historians argue that Franco made demands he knew Hitler would not accede to in order to stay out of the war. (German resistance leader Wilhelm Canaris had secretly briefed him on which demands would be found excessive.) Other historians argue that Franco, as the leader of a destroyed country in chaos following a brutal three-year civil war, simply had nothing to offer the Germans and their military.
Yet, after the Fall of France in June 1940, Spain did adopt a pro-Axis non-belligerency stance (for example, he offered Spanish naval facilities to German ships and U-boats) until returning to complete neutrality in 1943 when the tide of the war had turned decisively against Germany and its allies. In 1940, Franco also considered blocking allied access to the Mediterranean Sea by invading the British-controlled Gibraltar, but he abandoned the idea after learning that the plan would have likely failed and it would have given the British the grounds to declare war on Spain and thus give Great Britain and its allies an excellent opportunity to take both the Canary Islands and Spanish Morocco, as well as possibly invade mainland Spain itself. Some volunteer Spanish troops (the "División Azul", or "Blue Division")—not given official state sanction by Franco—went to fight on the Eastern Front under German command from 1941 to 1943. Some historians have argued that not all of the Blue Division were true volunteers and that Franco expended relatively small but significant resources to aid the Axis powers' battle against the Soviet Union.
Franco was initially disliked by Cuban President Fulgencio Batista, who, during World War II, had suggested a joint U.S.-Latin American assault on Spain in order to overthrow Franco's regime.
According to the recent discovery of a World War II document, Franco ordered his provincial governors to compile a list of Jews while he negotiated an alliance with the Axis powers. Franco supplied Reichsführer-SS Heinrich Himmler with a list of 6,000 Jews in Spain, for the Nazis' "Final Solution". Despite the creation of the list, there is not even evidence of any Jew seeking refuge from Germany being sent back to Germany. The list of Spanish Jews, may have not reflected Franco's personal beliefs of Jews. Although Franco made occasional negative references to Jews, Franco had Jewish friends in Morocco and even publicly stopped an outbreak of discriminations against Jews in Morocco. When Franco became dictator, no Jewish concentration camps were built on Spanish territory, nor did he voluntarily hand Jews over to Germany. Spanish Jews in the army served Franco with the same conditions as anyone else. With that, the government never placed any regulation that restricted or discriminated Jews. Spain ended up helping more Jews than any other neutral nation during WW2. Furthermore, Spanish diplomats extended their diplomatic protection over Jews in Hungary, Czechoslovakia and the Balkans.
On 14 June 1940, Spanish forces in Morocco occupied Tangier (a city under the rule of the League of Nations) and did not leave it until the war's end in 1945.
Spain under Franco.
Franco was recognized as the Spanish head of state by Britain and France in February 1939. Already proclaimed "Generalísimo" of the Nationalists and "Jefe del Estado" (Head of State) in October 1936, he thereafter assumed the official title of "Su Excelencia el Jefe de Estado" ("His Excellency the Head of State"). However, he was also referred to in state and official documents as "Caudillo de España" ("the Leader of Spain"), and sometimes called "el Caudillo de la Última Cruzada y de la Hispanidad" ("the Leader of the Last Crusade and of the Hispanic heritage") and "el Caudillo de la Guerra de Liberación contra el Comunismo y sus Cómplices" ("the Leader of the War of Liberation Against Communism and Its Accomplices").
In 1947, Franco proclaimed Spain a monarchy, but did not designate a monarch. This gesture was largely done to appease the monarchists in the "Movimiento Nacional" (Carlists and Alfonsists). Although a self-proclaimed monarchist himself, Franco did not feel it was time to have a king to rule the country yet, let alone proclaim himself king. As such, he left the throne vacant, with himself as a "de facto" regent for life. At the same time, he appropriated many of the privileges of a king. He wore the uniform of a Captain General (a rank traditionally reserved for the King) and resided in the El Pardo Palace. In addition, he began walking under a canopy, and his portrait appeared on most Spanish coins and postage stamps. He also added "by the grace of God", a phrase usually part of the styles of monarchs, to his style.
Franco initially sought support from various groups. Franco's administration marginalized fascist ideologues in favor of technocrats, many of whom were linked with Opus Dei, who promoted the economic modernization under Franco.
Although Franco and Spain under his rule adopted some trappings of fascism, he, and Spain under his rule, are generally not considered to be fascist; among the distinctions, fascism entails a revolutionary aim to transform society, where Franco and Franco's Spain did not seek to do so, and, to the contrary, although authoritarian, were conservative and traditional. Stanley Payne notes: "scarcely any of the serious historians and analysts of Franco consider the generalissimo to be a core fascist". The few consistent points in Franco's long rule were above all authoritarianism, nationalism, Catholicism, anti-Freemasonry, and anti-Communism.
The aftermath of the Civil War was socially bleak: many of those who had supported the Republic fled into exile. Spain lost thousands of doctors, nurses, teachers, lawyers, judges, professors, businessmen, artists, etc. Many of those who had to stay lost their jobs or lost their rank. Sometimes those jobs were given to unskilled and even untrained personnel. This deprived the country of many of its brightest minds, and also of a very capable workforce. However, this was done to keep Spain's citizens consistent with the ideals sought by the Nationalists and Franco.
With the end of World War II, Spain suffered from the economic consequences of its isolation from the international community. This situation ended in part when, due to Spain's strategic location in light of Cold War tensions, the United States entered into a trade and military alliance with Spain. This historic alliance commenced with United States President Eisenhower's visit in 1953 which resulted in the Pact of Madrid. Spain was then admitted to the UN in 1955.
In 1952, a syndicate from Dallas, Texas, including Jack Crichton, Everette Lee DeGolyer, and Clint Murchison sought drilling rights to petroleum in Spain. The operation was handled by Delta Drilling Company.
Political oppression.
The first decade of Franco's rule in the 1940s following the end of the Civil War in 1939 saw continued oppression and the killing of an undetermined number of political opponents. Estimation is difficult and controversial, but the number of people killed probably lies somewhere between 15,000 and 50,000.
Subsequently, Franco's state became less violent, but during his rule non-government trade unions and all political opponents across the political spectrum, from communist and anarchist organizations to liberal democrats and Catalan or Basque separatists, were either suppressed or tightly controlled by all means, up to and including violent police repression. The "Confederación Nacional del Trabajo" (CNT) and the "Unión General de Trabajadores" (UGT) trade-unions were outlawed, and replaced in 1940 by the corporatist "Sindicato Vertical". The Spanish Socialist Workers' Party and the "Esquerra Republicana de Catalunya" (ERC) were banned in 1939, while the Communist Party of Spain (PCE) went underground. The Basque Nationalist Party (PNV) went into exile, and in 1959, the ETA armed group was created to wage a low-intensity war against Franco.
Franco's Spanish nationalism promoted a unitary national identity by repressing Spain's cultural diversity. Bullfighting and flamenco were promoted as national traditions while those traditions not considered "Spanish" were suppressed. Franco's view of Spanish tradition was somewhat artificial and arbitrary: while some regional traditions were suppressed, Flamenco, an Andalusian tradition, was considered part of a larger, national identity. All cultural activities were subject to censorship, and many, such as the Sardana, the national dance of Catalunya, were plainly forbidden (often in an erratic manner). This cultural policy relaxed with time, most notably in the late 1960s and early 1970s.
Franco also used language politics in an attempt to establish national homogeneity. He promoted the use of Castilian Spanish and suppressed other languages such as Catalan, Galician, and Basque. The legal usage of languages other than Castilian was forbidden. All government, notarial, legal and commercial documents were to be drawn up exclusively in Castilian and any written in other languages were deemed null and void. The usage of any other language was forbidden in schools, in advertising, and on road and shop signs. For unofficial use, citizens continued to speak these languages. This was the situation throughout the 1940s and, to a lesser extent, during the 1950s, but after 1960 the non-Castilian Spanish languages were freely spoken and written and reached bookshops and stages, although they never received official status.
On the other hand, the Catholic Church was upheld as the established church of the Spanish State, and regained many of the traditional privileges it had lost under the Republic. Civil servants had to be Catholic, and some official jobs even required a "good behavior" statement by a priest. Civil marriages which had taken place under Republican Spain were declared null and void unless confirmed by the Catholic Church. Divorce was forbidden, and also contraceptives and abortion.
Most country towns, and rural areas, were patrolled by pairs of "Guardia Civil", a military police for civilians, which functioned as his chief means of social control. Larger cities, and capitals, were mostly under the Policia Armada, or "grises" ("greys", due to the color of its uniform) as they were called.
Student revolts, at universities in the late 1960s and early 1970s, were violently repressed by the heavily armed "Policía Armada" (Armed Police). Plainclothes secret police worked inside Spanish universities. In May 1972, an American student was arrested by university secret police in Barcelona and charged and imprisoned under martial law for the crime of wearing an old Spanish Army jacket.
The enforcement by public authorities of traditional Catholic values was a stated intent of the regime, mainly by using a law (the "Ley de Vagos y Maleantes", Vagrancy Act) enacted by Azaña. The remaining nomads of Spain (Gitanos and Mercheros like El Lute) were especially affected. In 1954, homosexuality, pedophilia, and prostitution were, through this law, made criminal offenses, although its application was seldom consistent.
Women in Francoist Spain.
Francoism professed a devotion to the traditional role of women in society, that is: loving child to her parents and brothers, faithful to her husband, residing with her family. Official propaganda confined the role of women to family care and motherhood. Immediately after the war, most progressive laws passed by the Republic aimed at equality between the sexes were made void. Women could not become judges, or testify in trial. They could not become university professors. Their affairs and economy had to be managed by fathers and husbands. Even in the 1970s a woman fleeing from an abusive husband could be arrested and imprisoned for "abandoning the home" ("abandono del hogar"). Until the 1970s a woman could not have a bank account without a co-sign by her father or husband. In the 1960s and 1970s the situation was somewhat relieved, but it was not until after Franco's death that a more egalitarian view of the sexes was adopted.
Spanish colonial empire and decolonisation.
Spain attempted to retain control of its colonial empire throughout Franco's rule. During the Algerian War (1954–62), Madrid became the base of the "Organisation de l'armée secrète" (OAS) right-wing French Army group which sought to preserve French Algeria. Despite this, Franco was forced to make some concessions. When French Morocco became independent in 1956, he surrendered Spanish Morocco to Mohammed V, retaining only a few enclaves (the "Plazas de soberanía"). The year after, Mohammed V invaded Spanish Sahara during the Ifni War (known as the "Forgotten War" in Spain). Only in 1975, with the Green March, did Morocco take control of all of the former Spanish territories in the Sahara.
In 1968, under United Nations pressure, Franco granted Spain's colony of Equatorial Guinea its independence, and the next year, ceded the exclave of Ifni to Morocco. Under Franco, Spain also pursued a campaign to force a negotiation on the British overseas territory of Gibraltar, and closed its border with that territory in 1969. The border would not be fully reopened until 1985.
Economic policy.
The Civil War had ravaged the Spanish economy. Infrastructure had been damaged, workers killed, and daily business severely hampered. For more than a decade after Franco's victory, the devastated economy recovered very slowly. Franco initially pursued a policy of autarky, cutting off almost all international trade. The policy had devastating effects, and the economy stagnated. Only black marketeers could enjoy an evident affluence.
On the brink of bankruptcy, a combination of pressure from the United States, the IMF and, most importantly, the technocrats from Opus Dei, managed to convince the regime to adopt a freer market economy. Many of the old guard in charge of the economy were replaced by "technocrata", despite some initial opposition from Franco. From the mid-1950s there was a modest pick up in economic activity after some minor reforms and a freeing up of controls. But the growth proved too much for the economy, with shortages and inflation breaking out towards the end of the 1950s.
When Franco replaced his ideological ministers with the apolitical technocrats, the regime implemented several development policies that included deep economic reforms. After a recession, growth took off from 1959, creating an economic boom that lasted until 1974, and became known as the "Spanish Miracle".
Concurrent with the absence of social reforms, and the economic power shift, a tide of mass emigration commenced to other European countries, and to a lesser extent, to South America. Emigration helped the regime in two ways. The country got rid of populations it would not have been able to keep in employment, and the emigrants supplied the country with much needed monetary remittances.
During the 1960s, the wealthy classes of Francoist Spain experienced further increases in wealth, particularly those who remained politically faithful, while a burgeoning middle class became visible as the "economic miracle" progressed. International firms established factories in Spain where salaries were low, company taxes very low, strikes forbidden and workers' health or state protections almost unheard of. State-owned firms like the car manufacturer SEAT, truck builder Pegaso and oil refiner INH, massively expanded production. Furthermore, Spain was virtually a new mass market. Spain became the second-fastest growing economy in the world during the 1959–1973 period, just behind Japan. By the time of Franco's death in 1975, Spain still lagged behind most of Western Europe, but the gap between its per capita GDP and that of the leading Western European countries had narrowed greatly and the country had developed a large industrialized economy.
Regions.
Franco was reluctant to enact any form of administrative and legislative decentralisation and kept a fully centralized government with a similar administrative structure to that established by the House of Bourbon and General Miguel Primo de Rivera y Orbaneja. Such structures were both based on the model of the French centralised State. The main drawback of this kind of management is that government attention and initiatives were irregular, and often depended more on the goodwill of regional Government representatives than on regional needs. Thus, inequalities in schooling, health care or transport facilities among regions were patent: classically affluent regions like Madrid, Catalonia, or the Basque Country fared much better than Extremadura, Galicia or Andalusia. Some regions, like Extremadura or La Mancha did not have a university.
The Basque Country and Catalonia were among the regions that offered the strongest resistance to Franco in the Civil War. Franco dissolved the autonomy granted by the Second Spanish Republic to these two regions and to Galicia. Franco abolished the centuries-old fiscal privileges and autonomy (the "fueros") in two of the three Basque provinces: Guipuzcoa and Biscay, but kept them for Álava which had sided with the nationalists in the civil war.
Among Franco's greatest area of support during the civil war was Navarre, also a Basque speaking region in its north half. Navarre remained a separate region from the Basque Country and Franco decided to preserve its also centuries-old fiscal privileges and autonomy, the so-called Fueros of Navarre. The regional privileges for Álava and Navarre were kept because Álava and Navarre had participated in the initial coup d'état against the Republican government on 18 July 1936.
Franco abolished the official statute and recognition of the Basque, Galician, and Catalan languages that the Second Spanish Republic had granted for the first time in the history of Spain. He returned to Castilian as the only official language of the State and education. The Franco era corresponded with the popularisation of the compulsory national educational system and the development of modern mass media, both controlled by the State and in the Castilian language, and heavily reduced the number of speakers of Basque, Catalan and Galician, as happened during the second half of the 20th century with other European minority languages which were not officially protected, such as Scottish Gaelic or French Breton. By the 1970s the majority of the population in urban areas could not speak the minority language or, as in some Catalan towns, their social use had been abandoned, leaving them limited to family use. Because of the already fragile situation of the Basque language before the Civil War, it became the most endangered language in Spain. By the 1970s Basque lacked a sufficient number of new speakers to assure its future, getting closer to extinction. It is now recognised that the Basque language would have disappeared in a few more decades if the same linguistic policies had been preserved. This was the main reason that drove the Francoist provincial government of Álava to create a network of Basque medium schools (Ikastola) in 1973 which were State-financed.
Franco and the United States.
At the end of World War II, Spain's fascist dealings made it an international pariah and kept the country out of the United Nations, the Marshall Plan and NATO; in the 1950s, however, Spain's strategic location and hostility towards the Soviet Union led the U.S. to reconsider its position towards Spain and entered into a trade and military alliance as part of its policy of containment.
This historic alliance began with the signing of the Pact of Madrid in 1953, which guaranteed American support for Franco's regime. Spain was admitted to the United Nations in 1955 and Eisenhower visited Spain.
President Richard Nixon toasted Franco, and, after Franco's death, stated: "General Franco was a loyal friend and ally of the United States." American military facilities in Spain built during this era included Naval Station Rota, Morón Air Base, and Torrejón Air Base.
Death and funeral.
In 1969, Franco designated Prince Juan Carlos de Borbón, who had been educated by him in Spain, with the new title of Prince of Spain, as his heir-apparent. This designation came as a surprise for the Carlist pretender to the throne, as well as for Juan Carlos' father, Don Juan, the Count of Barcelona, who had a superior claim to the throne, but was feared by Franco to be too liberal. By 1973, Franco had surrendered the function of prime minister ("Presidente del Gobierno"), remaining only as head of state and commander in chief of the military.
As his final years progressed, tension within the various factions of the "Movimiento" would consume Spanish political life, as varying groups jockeyed for position to control the country's future. The death on 20 December 1973 of prime minister Luis Carrero Blanco in a spectacular bombing by ETA eventually gave an edge to the liberalizing faction. On 19 July 1974, the aged Franco fell ill from various health problems, and Juan Carlos took over as Acting Head of State. Franco soon recovered, and on 2 September he resumed his duties as Head of State. One year later he fell ill once again from more health problems including a long battle with Parkinson's disease. On 30 October 1975, he fell into a coma and was put on life support. Francisco Franco's family agreed to disconnect life supporting machines and Francisco Franco died just after midnight on 20 November 1975, at the age of 82—just two weeks before his 83rd birthday—the same date as the death of José Antonio Primo de Rivera, founder of the Falange. However, the historian Ricardo de la Cierva claims that on 19 November around 6 pm, he was told that Franco had already died. After Franco's death, and according to his own wishes, he was buried at Valle de los Caídos, a colossal memorial built by the forced labour of political prisoners to honour the Francoist casualties of the Spanish Civil War. Franco's funeral was attended by Prince Rainier III of Monaco, the Chilean dictator General Augusto Pinochet, who revered Franco and modelled his leadership style in Chile in the way Franco led Spain, Bolivia's dictator General Hugo Banzer, Jordan's King Hussein and US Vice President Nelson Rockefeller.
Legacy.
In Spain and abroad, the legacy of Franco remains controversial. The length of his rule, the suppression of opposition, and the effective propaganda sustained through the years have made a detached evaluation almost impossible. Franco had won the hearts of many and was then able to win the Civil war; even Churchill himself said that if he was a Spaniard living in Spain he would have supported Franco. For 40 years, Spaniards, and particularly children at school were told that Divine Providence had sent him to save Spain from chaos and poverty, which Franco did do. With Western influence and their pressure, the fascist regime slowly turned into a country that more than guaranteed human rights.
In 2006, the BBC reported that Maciej Giertych, an MEP of the clerical-nationalist League of Polish Families, had expressed admiration for Franco, stating that he "guaranteed the maintenance of traditional values in Europe".
Many Spaniards, particularly those who suffered under Franco's rule, have sought to remove official recognition of his regime. Most government buildings and streets that were named after him during his long rule, reverted to their original names. Owing to Franco's human rights record, in 2007, the Spanish government banned all official public references to the Franco regime and removed any statues, street names and memorials associated with the regime, with reportedly the last statue in Santander having been removed in 2008. Churches which retain plaques commemorating Franco and the victims of his Republican opponents may lose state aid. Since 1978, the national anthem of Spain, the "Marcha Real", has not been accompanied by the lyrics introduced by Franco. Recent attempts to give the national anthem new lyrics have failed due to lack of consensus.
In March 2006, the Permanent Commission of the Parliamentary Assembly of the Council of Europe unanimously adopted a resolution "firmly" condemning the "multiple and serious violations" of human rights committed in Spain under the Francoist regime from 1939 to 1975. The resolution was at the initiative of Leo Brincat and of the historian Luis María de Puig, and is the first international official condemnation of the repression enacted by Franco's regime. The resolution also urged to provide public access to historians (professional and amateurs) to the various archives of the Francoist regime, including those of the private "Fundación Francisco Franco" which, as well as other Francoist archives, remain as of 2006 inaccessible to the public. The "Fundación Francisco Franco" received various archives from the El Pardo Palace, and is alleged to have sold some of them to private individuals. Furthermore, it urged the Spanish authorities to set up an underground exhibition in the Valle de los Caidos monument, in order to explain the "terrible" conditions in which it was built. Finally, it proposes the construction of monuments to commemorate Franco's victims in Madrid and other important cities.
In Spain, a commission to repair the dignity and restore the memory of the victims of Francoism ("Comisión para reparar la dignidad y restituir la memoria de las víctimas del franquismo") was approved in the summer of 2004, and is directed by the socialist vice-president María Teresa Fernández de la Vega.
Recently the Association for the Recovery of Historical Memory (ARHM) initiated a systematic search for mass graves of people executed during Franco's regime, which has been supported since the Spanish Socialist Workers' Party`s (PSOE) victory during the 2004 elections by José Luis Rodríguez Zapatero's government. A "Ley de la memoria histórica de España" (Law on the Historical Memory of Spain) was approved on 28 July 2006 by the Council of Ministers, but it took until 31 October 2007 for the Congress of Deputies to approve an amended version as "The Bill to recognise and extend rights and to establish measures in favour of those who suffered persecution or violence during the Civil War and the Dictatorship" (in common parlance still known as Law of Historical Memory). The Senate approved the bill on 10 December 2007. Among other things, the law is supposed to enforce an official recognition of the crimes committed against civilians during the Francoist rule and organize under state supervision the search for mass graves.
Official endeavors to preserve the historical memory of the Franco regime include exhibitions like the one the Museu d'Història de Catalunya (Catalonian Museum of History) organized around the prison experience.
The accumulated wealth of Franco's family (including much real estate inherited from Franco, such as the "Pazo de Meirás", the "Canto del Pico" in Torrelodones or the Cornide Palace in A Coruña) has also been discussed. Estimates of the family's wealth have ranged from 350 million to 600 million euros, well above what could be accumulated from his official income. When Franco was sick, the Cortes voted a pension for his wife, Carmen Polo. At the time of her death in 1988, Carmen Polo was receiving more than 12.5 million pesetas (four million more than Felipe González, then head of the government).
Further reading.
</dl>

</doc>
<doc id="11467" url="http://en.wikipedia.org/wiki?curid=11467" title="Flash Crowd">
Flash Crowd

"Flash Crowd" is a 1973 English language novella by science fiction author Larry Niven, one of a series about the social consequence of inventing an instant, practically free transfer booth that could take one anywhere on Earth in milliseconds.
One consequence not foreseen by the builders of the system was that with the almost immediate reporting of newsworthy events, tens of thousands of people worldwide — along with criminals — would teleport to the scene of anything interesting, thus creating disorder and confusion. The plot centers around a television journalist who, after being fired for his inadvertent role in inciting a post-robbery riot in Los Angeles, seeks to independently investigate the teleportation system for the flaws in its design allowing for such spontaneous riots to occur. His investigation takes him to destinations and people around the world within the matter of less than 12 hours before he gets his chance to plead his case on television, and he encounters the wide-ranging effects of displacements upon aspects of human behavior such as settlement, crime, natural resources, agriculture, waste management and tourism.
Use in other works.
In various other books, for example "Ringworld", Niven suggests that easy transportation might be disruptive to traditional behavior and open the way for new forms of parties, spontaneous congregations, or shopping trips around the world. The central character in "Ringworld", celebrating his birthday, teleports across time-zones to "lengthen" his birthday multiple times (particularly notable since the first edition had the error of the character heading the wrong direction, increasing that edition's value).
Niven's essay "Exercise in Speculation: The Theory and Practice of Teleportation" was published in the collection "All the Myriad Ways" In it he discusses the ideas that underlie his teleportation stories.
Similar references.
On the World Wide Web, a similar phenomenon can occur, when a web site catches the attention of a large number of people, and gets an unexpected and overloading surge of traffic. This usage was first coined by John Pettitt of Beyond.com in 1996. Multiple other terms for the phenomenon exist, often coming from the name of a particular prominent, high-traffic site whose normal base of viewers can constitute a flash crowd when directed to a less famous website. Notorious examples include the "Slashdot effect", the "Instalanche" (when a smaller site gets links by the popular blog Instapundit), or a website being "Farked" or Drudged (where the target site is crashed due to the large number of hits in a short time).

</doc>
<doc id="11469" url="http://en.wikipedia.org/wiki?curid=11469" title="August Kekulé">
August Kekulé

Friedrich August Kekulé, later Friedrich August Kekule von Stradonitz (]) (7 September 1829 – 13 July 1896) was a German organic chemist. From the 1850s until his death, Kekulé was one of the most prominent chemists in Europe, especially in theoretical chemistry. He was the principal founder of the theory of chemical structure.
Name.
Kekulé never used his first given name; he was known throughout his life as August Kekulé. After he was ennobled by the Kaiser in 1895, he adopted the name August Kekule von Stradonitz, without the French acute accent over the second "e". The French accent had apparently been added to the name by Kekulé's father during the Napoleonic occupation of Hesse by France, in order to ensure that French speakers pronounced the third syllable.
Early years.
The son of a civil servant, Kekulé was born in Darmstadt, the capital of the Grand Duchy of Hesse. After graduating from secondary school (the Grand Ducal Gymnasium in Darmstadt), in the fall of 1847 he entered the University of Giessen, with the intention of studying architecture. After hearing the lectures of Justus von Liebig in his first semester, he decided to study chemistry. Following four years of study in Giessen and a brief compulsory military service, he took temporary assistantships in Paris (1851–52), in Chur, Switzerland (1852–53), and in London (1853–55), where he was decisively influenced by Alexander Williamson. His Giessen doctoral degree was awarded in the summer of 1852.
Theory of chemical structure.
In 1856 Kekulé became Privatdozent at the University of Heidelberg. In 1858 he was hired as full professor at the University of Ghent, then in 1867 he was called to Bonn, where he remained for the rest of his career. Basing his ideas on those of predecessors such as Williamson, Edward Frankland, William Odling, Auguste Laurent, Charles Adolphe Wurtz and others, Kekulé was the principal formulator of the theory of chemical structure (1857–58). This theory proceeds from the idea of atomic valence, especially the tetravalence of carbon (which Kekulé announced late in 1857) and the ability of carbon atoms to link to each other (announced in a paper published in May 1858), to the determination of the bonding order of all of the atoms in a molecule. Archibald Scott Couper independently arrived at the idea of self-linking of carbon atoms (his paper appeared in June 1858), and provided the first molecular formulas where lines symbolize bonds connecting the atoms.
For organic chemists, the theory of structure provided dramatic new clarity of understanding, and a reliable guide to both analytic and especially synthetic work. As a consequence, the field of organic chemistry developed explosively from this point. Among those who were most active in pursuing early structural investigations were, in addition to Kekulé and Couper, Frankland, Wurtz, Alexander Crum Brown, Emil Erlenmeyer, and Aleksandr Mikhailovich Butlerov.
Kekulé's idea of assigning certain atoms to certain positions within the molecule, and schematically connecting them using what he called their "Verwandtschaftseinheiten" ("affinity units", now called "valences" or "bonds"), was based largely on evidence from chemical reactions, rather than on instrumental methods that could peer directly into the molecule, such as X-ray crystallography. Such physical methods of structural determination had not yet been developed, so chemists of Kekulé's day had to rely almost entirely on so-called "wet" chemistry. Some chemists, notably Adolph Wilhelm Hermann Kolbe, heavily criticized the use of structural formulas that were offered, as he thought, without proof. However, most chemists followed Kekulé's lead in pursuing and developing what some have called "classical" structure theory, which was modified after the discovery of electrons (1897) and the development of quantum mechanics (in the 1920s).
The idea that the number of valences of a given element was invariant was a key component of Kekulé's version of structural chemistry. This generalization suffered from many exceptions, and was subsequently replaced by the suggestion that valences were fixed at certain oxidation states. For example, periodic acid according to Kekuléan structure theory could be represented by the chain structure I-O-O-O-O-H. By contrast, the modern structure of (meta) periodic acid has all four oxygen atoms surrounding the iodine in a tetrahedral geometry.
Benzene.
Kekulé's most famous work was on the structure of benzene. In 1865 Kekulé published a paper in French (for he was then still in Francophone Belgium) suggesting that the structure contained a six-membered ring of carbon atoms with alternating single and double bonds. The next year he published a much longer paper in German on the same subject. The empirical formula for benzene had been long known, but its highly unsaturated structure was a challenge to determine. Archibald Scott Couper in 1858 and Joseph Loschmidt in 1861 suggested possible structures that contained multiple double bonds or multiple rings, but the study of aromatic compounds was in its earliest years, and too little evidence was then available to help chemists decide on any particular structure.
More evidence was available by 1865, especially regarding the relationships of aromatic isomers. Kekulé argued for his proposed structure by considering the number of isomers observed for derivatives of benzene. For every monoderivative of benzene (C6H5X, where X = Cl, OH, CH3, NH2, etc.) only one isomer was ever found, implying that all six carbons are equivalent, so that substitution on any carbon gives only a single possible product. For diderivatives such as the toluidines, C6H4(NH2)(CH3), three isomers were observed, for which Kekulé proposed structures with the two substituted carbon atoms separated by one, two and three carbon-carbon bonds, later named ortho, meta, and para isomers respectively.
The counting of possible isomers for diderivatives was however criticized by Albert Ladenburg, a former student of Kekulé, who argued that Kekulé's 1865 structure implied two distinct "ortho" structures, depending on whether the substituted carbons are separated by a single or a double bond. Since ortho derivatives of benzene were never actually found in more than one isomeric form, Kekulé modified his proposal in 1872 and suggested that the benzene molecule oscillates between two equivalent structures, in such a way that the single and double bonds continually interchange positions. This implies that all six carbon-carbon bonds are equivalent, as each is single half the time and double half the time. A firmer theoretical basis for a similar idea was later proposed in 1928 by Linus Pauling, who replaced Kekulé's oscillation by the concept of resonance between quantum-mechanical structures.
The ouroboros dream.
The new understanding of benzene, and hence of all aromatic compounds, proved to be so important for both pure and applied chemistry after 1865 that in 1890 the German Chemical Society organized an elaborate appreciation in Kekulé's honor, celebrating the twenty-fifth anniversary of his first benzene paper. Here Kekulé spoke of the creation of the theory. He said that he had discovered the ring shape of the benzene molecule after having a reverie or day-dream of a snake seizing its own tail (this is an ancient symbol known as the ouroboros). This vision, he said, came to him after years of studying the nature of carbon-carbon bonds.
A similar humorous depiction of benzene had appeared in 1886 in the "Berichte der Durstigen Chemischen Gesellschaft" (Journal of the Thirsty Chemical Society), a parody of the "Berichte der Deutschen Chemischen Gesellschaft", only the parody had monkeys seizing each other in a circle, rather than snakes as in Kekulé's anecdote. Some historians have suggested that the parody was a lampoon of the snake anecdote, possibly already well-known through oral transmission even if it had not yet appeared in print. Others have speculated that Kekulé's story in 1890 was a re-parody of the monkey spoof, and was a mere invention rather than a recollection of an event in his life. 
Kekulé's 1890 speech, in which these anecdotes appeared, has been translated into English. If one takes the anecdote as the memory of a real event, circumstances mentioned in the story suggest that it must have happened early in 1862.
He told yet another anecdote in 1890, of a vision of dancing atoms and molecules that led to his theory of structure. This happened, he claimed, while he was riding on the upper deck of a horse-drawn omnibus in London. This probably occurred in the late summer of 1855.
Honors.
In 1895 Kekulé was ennobled by Kaiser Wilhelm II of Germany, giving him the right to add "von Stradonitz" to his name, referring to a possession of his patrilineal ancestors in Stradonice, Bohemia. This title was also used by his son, the genealogist Stephan Kekulé von Stradonitz.
Of the first five Nobel Prizes in Chemistry, Kekulé's students won three: van 't Hoff in 1901, Fischer in 1902 and Baeyer in 1905.
A larger-than-life size monument of Kekulé is situated in front of the former Chemical Institute at the University of Bonn. His monument is often decorated by students, e.g. for Valentine's Day.

</doc>
<doc id="11472" url="http://en.wikipedia.org/wiki?curid=11472" title="Frederick III, Holy Roman Emperor">
Frederick III, Holy Roman Emperor

Frederick III (21 September 1415 – 19 August 1493), called the Peaceful, was the Holy Roman Emperor from 1452 until his death. Prior to his imperial coronation, he was hereditary Duke of Austria (as Frederick V) from 1424 and elected King of Germany (as Frederick IV) from 1440. He was the first emperor of the House of Habsburg. In 1493, he was succeeded by his son Maximilian I after ten years of joint rule.
Life.
Born in Innsbruck, he was the son of Duke Ernest the Iron of the Leopoldian line of the Habsburg family, the ruler of Inner Austria, i.e. the duchies of Styria, Carinthia and Carniola, and of Ernest's wife Cymburgis of Masovia. He became duke of Inner Austria as Frederick V upon his father's death in 1424.
In 1440 he was elected German king as Frederick IV and in 1452 crowned Holy Roman Emperor as Frederick III by Pope Nicholas V. In 1452, at the age of 37, he married the 18-year-old Infanta Eleanor, daughter of King Edward of Portugal, whose dowry helped him to alleviate his debts and cement his power.
In 1442, Frederick allied himself with Rudolf Stüssi, burgomaster of Zurich, against the Old Swiss Confederacy in the Old Zurich War (Alter Zürichkrieg).
In 1448, he entered into the Concordat of Vienna with the Holy See, which remained in force until 1806 and regulated the relationship between the Habsburgs and the Holy See.
Frederick was the last Emperor to be crowned in Rome (his great-grandson Charles V was the last emperor to be crowned, but in Bologna). He opposed the reform of the Holy Roman Empire at that time and was barely able to prevent the electors from holding another election.
Personality.
Frederick's style of rulership was marked by hesitation and a sluggish pace of decision making. The Italian humanist Enea Silvio Piccolomini, later Pope Pius II, who at one time worked at Frederick's court, described the Emperor as a person who wanted to conquer the world while remaining seated. Although this was regarded as a character flaw in older academic research, his delaying tactics are now viewed as a means of coping with political challenges in far-flung territorial possessions. Frederick is credited with having the ability to sit out difficult political situations patiently.
According to contemporary accounts, Frederick had difficulties developing emotional closeness to other persons, including his children and wife Eleanor. In general, Frederick kept himself away from women, the reasons for which are not known. As Frederick was rather distant to his family, Eleanor had a great influence on the raising and education of Frederick's children, and she therefore played an important role in the House of Habsburg's rise to prominence.
Politics.
Frederick's political initiatives were hardly bold, but they were still successful. His first major opponent was his brother Albert VI, who challenged his rule. He did not manage to win a single conflict on the battlefield against him, and thus resorted to more subtle means. He held his second cousin once removed Ladislaus the Posthumous, the ruler of the Archduchy of Austria, Hungary and Bohemia, (born in 1440) as a prisoner and attempted to extend his guardianship over him in perpetuity to maintain his control over Lower Austria. Ladislaus was freed in 1452 by the Lower Austrian estates. He acted similarly towards his first cousin Sigismund of the Tyrolian line of the Habsburg family. Despite those efforts, he failed to gain control over Hungary and Bohemia in the Bohemian War (1468–1478) and was even defeated in the Austrian-Hungarian War (1477–1488) by the Hungarian King Matthias Corvinus in 1485, who managed to maintain residence in Vienna until his death five years later (see Siege of Vienna (1485)).
Ultimately, Frederick prevailed in all those conflicts by outliving his opponents and sometimes inheriting their lands, as was the case with Ladislaus, from whom he gained Lower Austria in 1457, and with his brother Albert VI, whom he succeeded in Upper Austria. These conflicts forced him into an anachronistic itinerant existence, as he had to move his court between various places through the years, residing in Graz, Linz and Wiener Neustadt. Wiener Neustadt owes him its castle and the "New Monastery".
Still, in some ways his policies were astonishingly successful. In the Siege of Neuss (1474–75), he forced Charles the Bold of Burgundy to give up his daughter Mary of Burgundy as wife to Frederick's son Maximilian. With the inheritance of Burgundy, the House of Habsburg began to rise to predominance in Europe. This gave rise to the saying "Let others wage wars, but you, happy Austria, shall marry", which became a motto of the dynasty.
The marriage of his daughter Kunigunde of Austria to Albert IV, Duke of Bavaria, was another result of intrigues and deception, but must be counted as a defeat for Frederick. Albert illegally took control of some imperial fiefs and then asked to marry Kunigunde (who lived in Innsbruck, far from her father), offering to give her the fiefs as a dowry. Frederick agreed at first, but after Albert took over yet another fief, Regensburg, Frederick withdrew his consent. On January 2, 1487, however, before Frederick's change of heart could be communicated to his daughter, Kunigunde married Albert. A war was prevented only through the mediation of the Emperor's son, Maximilian.
In some smaller matters, Frederick was quite successful: in 1469 he managed to establish bishoprics in Vienna and Wiener Neustadt, a step that no previous Duke of Austria had been able to achieve.
Frederick's personal motto was the mysterious string A.E.I.O.U., which he imprinted on all his belongings. He never explained its meaning, leading to many different interpretations being presented, although it has been claimed that shortly before his death he said it stands for "Alles Erdreich ist Österreich untertan" (English: "All the world is subject to Austria.") It may well symbolise his own understanding of the historical importance and meaning of his rule and of the early gaining of the Imperial title.
Marriage and children.
Frederick had five children from his marriage with Eleanor of Portugal: 
For the last 10 years of Frederick's life, he and Maximilian ruled jointly.
Death.
Frederick III died in 1493, aged 77, at Linz. His left foot had become gangrenous, and was amputated. He survived this procedure, but continued infection prompted amputation of his left leg, after which he was said to have bled to death.
His grave, built by Nikolaus Gerhaert von Leyden, in St. Stephen's Cathedral, Vienna, is one of the most important works of sculptural art of the late Middle Ages. (His amputated leg was buried with him.) The heavily adorned tomb was not completed until 1513, two decades after Frederick's death, and has survived in its original condition.

</doc>
<doc id="11475" url="http://en.wikipedia.org/wiki?curid=11475" title="Fuerteventura">
Fuerteventura

Fuerteventura (]; loosely translated as "Strong Winds" or a corruption of the French term for "Great Adventure") is one of the Canary Islands, in the Atlantic Ocean off the coast of Africa, politically part of Spain. At 1660 km², it is the second largest of the Canary Islands, after Tenerife. It was declared a biosphere reserve by UNESCO in May 2009.
History.
Precolonial history.
The first settlers are believed to have arrived here from North Africa - the word "Mahorero" ("Majorero") or "Maho" is still used today to describe the people of Fuerteventura and comes from the ancient word 'mahos' meaning a type of goatskin shoe worn by the original inhabitants. They lived in caves and semi-subterranean dwellings, a few of which have been discovered and excavated revealing relics of early tools and pottery. In antiquity, the island was known as "Planaria", among other names, in reference to the flatness of most of its landscape.
In the 11th century BC, the Phoenician settlers arrived in Fuerteventura and Lanzarote. Several Spanish and Portuguese expeditions occurred in about 1340 around the island and the island were inhabited by Maurs and were afflicted with European slave holders. By the time of the conquest, the island was divided into two Guanches kingdoms, one following the king Guize and the other Ayoze. The territories of these tribes were called Maxorata (in the north) and Jandía (in the south). The kingdoms were separated by a wall whose remains are still preserved today. The wall crossed the La Pared isthmus. The ancient name for the island, Erbania, refers to that wall.
The conquest.
The conquest began in 1402, commanded by Jean de Béthencourt and Gadifer de la Salle. They arrived with only 63 sailors out of the original 283 as so many had deserted. After arriving and settling in Lanzarote, the invaders made their first excursions to the neighbouring islands. In 1404, Bethencourt and Gadifer founded Betancuria, the first settlement on the island. After numerous difficulties, Gadifer took charge of the invasion, while Bethencourt went to the Spanish peninsula to seek the recognition and support of the Castilian king.
In 1405, the French conqueror Jean de Béthencourt completed his conquest of the island and gave his name to the former capital, Betancuria, on the west coast (Puerto Rosario took over the mantle as island capital in 1835). The name of the island itself comes from fuerte (strong) and ventura (wind) as mentioned by mallorcan navigator Angelino Dulcert in 1339.
The first census showed a population of 1,200 inhabitants. Following that, the population increased gradually. In 1476 the territory became the "Señorío Territorial de Fuerteventura", a subject of the Catholic Monarchs. Over the years, the island has been invaded by the Spanish, French and the English.
Colonial Fuerteventura.
The island suffered from various pirate incursions. A Berber expedition invaded in 1593, sweeping as far as the capital. Various castles were built to protect against this type of attack. The castles were built all along the coast. The population all moved inland as a second protective measure. Because of the invasions, the first Captain General was sent to Fuerteventura, charged with defending the island in the name of the crown. With him came a number of Sergeant Majors. Betancuria became the religious capital of the island
The military regiment was created in 1708. Its colonel assumed the title of Governor at Arms, a hereditary lifetime appointment which stayed in the hands of the Sánchez-Dumpiérrez family. Over time they acquired more power in the other islands through the family of Arias de Saavedra, the Lady of Fuerteventura. The same year, the religious leader created the Assistant Parish of La Oliva and Pájara, to launch in 1711. On 17 December 1790 he created the Assistant Parish of Tuineje, which became a new parish division on 23 June 1792 under the bishop Tavira with lands including part of the Jandía peninsular with a population of 1,670 inhabitants. In 1780 the barrilla growing economy began.
In 1852, the free trade zone was extended by Isabella II to the Canary Islands. The military rule over the island which began from 1708 dissolved in 1859 and Puerto de Cabras (now Puerto del Rosario) became entirely the new capital.
The Canary Islands obtained the right to self-govern in 1912.
In 1927, Fuerteventura and Lanzarote became part of the province of Gran Canaria.
By the 1940s the island had an airport (just west of Puerto del Rosario on the road to Tindaya, still visible today).
Tourism arrived in the mid-1960s with the building of the present airport at El Mattoral and the first tourist hotels.
The seat of the island government ("cabildo insular") is in Puerto del Rosario. A total of 74,983 people (2003) live on the island.
Since the island is close to Africa, many illegal immigrants try to enter the European Union through it, by a dangerous boat trip from Morocco.
Environment.
Geography.
The elongated island has an area of 1660 km². The island is 100 km long and 31 km wide. It is part of the province of Las Palmas. It is divided into six municipalities:
100 individual settlements are distributed through these municipalities. A nearby islet, Islote de Lobos, is part of the municipality of La Oliva.
Located just 100 km off the coast of north Africa, it is the second biggest of the islands, after Tenerife, and has the longest beaches in the archipelago. The island is a destination for sun, beach and watersports enthusiasts. It lies on the same latitude as Florida and Mexico and temperatures here rarely fall below 18 °C or rise above 32 °C. There are no fewer than 152 beaches along its coastline — 50 km of fine, white sand and 25 km of black volcanic shingle.
Geology.
Fuerteventura is the oldest island in the Canary Islands dating back 20 million years to a volcanic eruption from the Canary hotspot. The majority of the island was created about 5 million years ago and since then has been eroded by wind and other weather. On the seabed off the west coast of the island rests a block of rock 22 km long and 11 km wide, which appears to have slid off the island largely intact at some point in prehistory, similar to the predicted future collapse of Cumbre Vieja, a geological fault on the neighboring island, La Palma. The last volcanic activity in Fuerteventura was between 4,000 and 5,000 years ago.
The highest point in Fuerteventura is Mount Jandía (807 m) in the southwestern part of the island. Geographical features include Istmo de la Pared which is 5 km wide and is the narrowest part of Fuerteventura. The island is divided into two parts, the northern portion which is Maxorata and the southwestern part called the Jandía peninsula. 
Beaches.
Fuerteventura was chosen among 500 European destinations by the Quality Coast International Certification Program of the European Coastal and Marine Union as one of the most attractive tourist destinations for visitors interested in cultural heritage, environment and sustainability.
Climate.
The climate on Fuerteventura is pleasant throughout the year. The island is also often referred to as "the island of eternal spring". The sea adjusts the temperature making the hot Sahara winds blow away from the island. The island's name in English translates as "strong fortune" or "strong wind", the Spanish word for wind being "viento". During the winter months, temperatures average a high of 22 °C and a low of around 15 °C, whereas during the summer a mean high of 28 °C and a low of 20 °C can be expected. Precipitation is about 147 mm per year, most of which falls in autumn and winter. October is the month with highest rainfall.
A sandstorm known as the Calima (similar to the Sirocco wind that blows North from the Sahara into Europe) blows southwestward from the Sahara Desert and can cause high temperatures, low visibility and drying air. Temperatures during this phenomenon rise temporarily by approximately 10 degrees Celsius. The wind brings in fine white sand, visibility can drop to between 100 to or even lower and can even bring African locusts to the island.
Wildlife.
The island is home to one of the two surviving populations of the threatened Canarian Egyptian vulture. It is also inhabited by many wild dogs and cats. On the barren, rocky land there are Barbary ground squirrels and geckos. Fuerteventura also hosts several migratory and nesting birds. The island has significant populations of the collared dove, common swifts and several finch species especially in the vicinity of holiday developments.
Despite its arid climate, the island is also home to a surprisingly large insect fauna. Butterflies which commonly occur on the island include the clouded yellow (Colias hyale) and the bath white ("Pontia daplidice") which feeds on xerophytic cruciferae. The island is also home the monarch butterfly ("Danaus plexippus") and its close African relative "Danaus chrysippus". Around holiday developments such as Caleta de Fuste, water is relatively abundant, and dragonfly species including the blue emperor, "Anax imperator" and the scarlet darter, "Crocothemis erythraea" can be found. The islands sand dunes and shoreline are home to a number of bee and wasp species including the large Eumenid caterpillar hunting wasp, "Delta dimiatipenne" and the striking blue banded bee, ("Amegilla canifrons").
Hawkmoths also occur on the island. One of the more notable species is "Hyles tithymali" which feeds on endemic spurges such as "Euphorbia regis-jubae". "Acherontia atropos", the deaths-head hawkmoth also occurs on the island presumably feeding on members of the Solanaceae, for example, "Datura innoxia" and "Nicotiana glauca" which are common weeds in the vicinity of human habitation.
Demographics.
Population.
The island has a population of 74,983. Throughout its long history, Fuerteventura has suffered from a population decline due to the economic situation and the climate, which have made it into a desert island. However, the development of tourism during the 1980s has caused the population to grow year on year since then, doubling it in a little less than a decade.
In 2005, with 86,642 registered inhabitants, the Fuerteventura population was formed by the following:
Comparing this data with the 2001 census shows that the number of permanent residents born on the island has increased by just 3,000. The number who have moved in from abroad has increased by 22,910, making this the biggest contributor to population growth in recent years.
Education.
The island has 116 schools, with a total of 14,337 pupils. Of these, 45 are primary schools, ten are secondary schools, six are for Baccalaureate students and four are vocational colleges.
Fuerteventura also has a centre linked with the National University of Distance Education, offering courses in many subjects including economics, business studies, law, history and tourism.
State administration.
Fuerteventura is governed by the Island Department of the Government of Spain, which holds the rank of a Government Subdepartment. The government building is located in the centre of the capital city, in front of the parish church of the Virgin of Rosario, the patron saint of Puerto del Rosario municipality.
This institution is charged with representing the Government of Spain on the island, and managing all the functions that are not under control of the Canarian Government. This includes the following public services:
Since 30 June 2007, the island's governor has been Eustaquio Juan Santana Gil. 4
Island Council of Fuerteventura.
The councils, formed as part of the Councils Act of 1912, administer the Canary Islands and have two principal functions. On one hand, they perform services for the Autonomous Community, and on the other, they are the local government centre for the island. In the 2003 elections, Mario Cabrera González was elected as president representing the Canarian Coalition, with 31.02% of the votes, followed by the Spanish Socialist Workers' Party with 27.53%, represented by the Vice President Domingo Fuentes Curbelo.
Municipalities.
The island is divided into six municipalities with their respective city councils which form part of the FECAM (Federation of Canarian Municipalities). They are governed by the basic legislation of the local regime and their respective organic rules. The populations of the municipalities are as follows:
In turn, these municipalities are organised into two associations: the "Mancomunidad de Municipios del Centro-Norte de Fuerteventura" formed from La Oliva and Puerto del Rosario, and the remaining municipalities make up the "Mancomunidad de Municipios del Centro-Sur de Fuerteventura".
Economy.
The economy of Fuerteventura is mainly based on tourism. Primary tourist areas are located around the existing towns of Corralejo in the north and Morro Jable in Jandia, plus the purely tourist development of Caleta de Fuste, south of Puerto del Rosario. Other main industries are fishing and agriculture (cereals and vegetables). The famous Majorero cheese is locally made from the milk of the indigenous majorera goat.
In 2009, Fuerteventura recorded the highest EU regional unemployment rate at a NUTS3 level, at 29.2 percent.
Tourism.
The first tourist hotel was built in 1965 followed by the construction of Fuerteventura Airport at El Matorral, heralding the dawn of a new era for the island. Fuerteventura, with its 3,000 sunshine hours a year, was placed firmly on the world stage as a major European holiday destination.
While having fully developed tourist facilities, the island has not experienced the overdevelopment found on some other islands and consequently caters for visitors attracted by its rugged natural beauty.
The summer Trade Winds and winter swells of the Atlantic make this a year-round surfers' paradise, with more exposed areas on the north and west shores such as Corralejo and El Cotillo proving most popular. Wind surfing takes places at locations around the island. Sailors, scuba divers and big-game fishermen are all drawn to these clear blue Atlantic waters where whales, dolphins, marlin and turtles are all common sights. With many hills present throughout the Island, hikers are also attracted to this Island.
Excellent sandy beaches are found in many locations. Western beaches, such as those around El Cotillo, can experience strong surf. The beaches adjoining the extensive sand dunes east of Corralejo are popular, as are the more protected extensive sandy shores of the Playa de Sotavento de Jandia on the southeastern coast between Costa Calma and the Morro Jable. Naked sun bathing and swimming are the norm on beaches away from inhabited areas.
Much of the interior, with its large plains, lavascapes and volcanic mountains, consists of protected areas, although there are organised tours and vehicular access across them.
Art and culture.
Traditional holidays.
Like the rest of the Canaries, Carnival is traditionally one of the biggest festivals celebrated on the island. It is celebrated in different ways in all the towns during February and March. These festivities have a different theme each year. They include activities such as parades and galas to choose the Carnival King.
Concerts and festivals.
There are many concerts and festivals held in the auditoriums, such as the Festival of Canarian Music. They are also held in smaller venues across the island, featuring bands such as Estopa, Van Gogh's Ear, and King Afrhica.
Festival Internacional de Cometas/International Kite Festival is held on the second week of November each year centering on the Corralejo Beaches. It attracts kitefliers and kite surfers from all over Europe. It is popular because the winds are warm and constant and the beaches become filled with hundreds of colourful kites of all shapes and sizes.
Auditoriums.
Fuerteventura has three auditoriums. These are used for all types of performing art. They are also used for non-artistic purposes, such as conferences, charity galas and political meetings.
Central library.
The Central Library of the Island is located in Antigua's city centre, in the public university. In addition to providing the traditional library services, it has an 180-seat multipurpose room, air conditioning, a wifi zone, and a multimedia room used for seminars, presentations, film festivals etc.
Museums and exhibition spaces.
The island has several museums with different themes and plenty of exhibition spaces, both public and private. These include:
Sculpture park.
In addition to the museums, the capital Puerto del Rosario has an open-air sculpture park consisting of around 100 sculptures by different artists scattered across the city. Most of them were created for the International Symposium of Sculpture celebrated annually since 2001. During the festival, artists come from all over the world to erect their sculptures in the open air, in full view of passers by.
Main sights.
Sites of interest include Corralejo and El Jable to the north which are made up of fine sand dunes whilst the south is filled with long beaches and remote bays. The constant winds blowing onto the beaches provide a paradise for windsurfing. Surfing is common on the west and north coasts where there are large waves. Windsurfing is common around Corralejo and Playas de Sotavento and wave sailing (windsurfing on the waves) on the coast along the northern half of the island. El Cotillo is a small fishing village in the north-west of the Island famous for a very long beach to the south of the village and few very calm beaches to the north. The northern beaches frequented by snorkeling enthusiasts and sun worshipers alike are referred to as lakes by the locals. 
At Cofete on the western side of Jandía a remote and imposing house - Villa Winter - looks out to sea across wide and generally empty beaches. It was reputedly built by a Mr Winter on land given by Generalisimo Franco. Despite being one of the most beautiful part of Fuerteventura Cofete has very little touristic facilities.
For a time, the beaches were home to a popular accidental attraction. On 18 January 1994 the once-beautiful and proud United States Lines ocean liner SS "American Star" (former "America", USS "West Point", "Australis") was beached in Playa de Garcey during a severe storm. Within a year, it broke in two and later lost its back half. By 2007 the rest of the severely deteriorated ship had collapsed onto its port side, gradually keeling over further and almost completely submerged. By 2008-2012, most of the remains finally slipped below the surface.
Food.
The cuisine is fairly basic due to the customs and climate conditions. They share this simplicity with the other Canary islands, and similarly to them, they use a large quantity of fish. They also use whatever they can grow in the near-barren land. This includes papas arrugadas, a dish of wrinkled potatoes usually served with mojo, which is a hot pepper sauce or with puchero canario, a meat stew.
Seafood is prepared in many ways traditionally, such as pejines (salted fish), jareas, or sancocho (a type of stew) made from fish, generally the grouper, corvina or sama, boiled after salting, and served with mojo, potatoes, or gofio (a type of grain). People are also very keen on the mussels and limpets collected on the island's coasts.
They also use meat such as beef and pork to make different dishes or simply to for braising, but their main meat is goat, both from the kids and from the older animals. They eat the goat roasted or stewed. Goats are not only useful for their meat - the Fuerteventurans also use the milk to make the cheese majorero, which has won many prizes. The majorero is mostly made of goats milk, and occasionally it is up to 15% ewes milk. It is cured in pimento oil or gofio meal. Majorero and palmero cheese are the only two Canarian cheeses with protected denomination of origin.
Sport.
Many sports are commonly played in Fuerteventura, both in the open air and in sports centres across the island.
Native sports.
These are the Canarian sports found on the island:
Canarian wrestling.
The wrestling takes place in a ring of sand called the "terrero". Inside it, the two contestants try to knock each other over. Fuerteventura has 14 terreros distributed through all the towns except Betancuria.
The island also has a school wrestling league organized by the council and a programme to promote this sport in clubs. Twelve wrestling schools participate in this, based in Antigua, Costa Calma, El Matorral, La Lajita, Lajares, Las Playitas, Morro Jable, Puerto del Rosario, Tefía, Tetir, Unión Sur and Villaverde.
Juego del Palo.
Juego del Palo is a Canarian martial art which literally translates as "game of the stick". It is played by two players both armed with sticks. They aim to defeat each other without making contact with their opponent's body. The origin of this game is unclear. All we know is that it is based on a method of combat used by the precolonial Canarian people.
Fuerteventura has the following Palo clubs:
Canarian boules.
This is a similar game to the French Pétanque which is actually played very little on the island, although there are a few teams and courts. Basically the game consists of scoring points by rolling a ball to get it as near as possible to an object called a "mingue" or "boliche". It is played on a rectangular sand or earth pitch which is 18–25 metres long and 3.5–6 metres wide.
Watersports.
The sea and climate conditions make the island the perfect place for a huge variety of watersports.
Surfing, windsurfing and kitesurfing.
Many types of surfing are popular on the island, including traditional surfing, windsurfing (where the board is propelled by a sail) and most recently kitesurfing. The island has many schools and courses dedicated to teaching these sports.
The sports where Fuerteventura has the most impact internationally are windsurfing and kitesurfing, mainly due to the International Windsurfing and Kiteboarding Championship. This has run since 1985 and is held at Playas de Sotavento in Pájara municipality. Many important wind and kitesurfing figures compete in this championship, such as the several-times world windsurfing champion Björn Dunkerbeck and Gisela Pulido, the very young kiteboarding champion from Tarifa.
Many Canarian windsurfers are on the Canarian Waveriders circuit, which has been based in Corralejo since 2005.
Diving.
Diving schools are just as frequent as surfing ones, all around the coast of Fuerteventura. Unlike the other islands of the archipelago, Fuerteventura has a shelf which at some points goes up to 30 km, making it an ideal place to practice this sport.
Two of the most useful points for diving are the coast off Playa del Matorral in the South, and the zone between Lobos Island and Corralejo in the north. It is here in Corralejo that the International Sea and Submarine Photography Festival takes places, known as Fimarsub Corralejo - Lobos. During the festival there are beginners' lessons, professional dives, lessons in underwater photography, screenings and other events related to the sport.
Swimming.
There are lots of swimming pools on the island but the most obvious place to swim is in the open sea. There is an annual swim from Lobos Island to Fuerteventura, held every year since 1999. The event attracts amateur swimmers from all over the Canaries and Spain, and also swimming professionals such as David Meca and Maarten Van der Weijden, the paralympist Jesús Collado Alarcón who won gold medals for 100m backstroke and butterfly in Athens 2004, and Xavi Torres Ramis, the paralympic champion in Barcelona '92, Sydney and Atlanta.
Sailing.
The island holds competitions involving different types of boat, such as the lateen and the Optimist. An interesting event is the Tour of Fuerteventura by Kayak, which is organised as a series of stages rather than a competition, and is an easy way to explore the island.
Fishing.
The most notable competition here is the Gran Tarajal Fishing Open.
Other sports.
Since 2004 the Marcha Ciclotourista has been held in La Oliva and the Criterium Ciclista has been held in Corralejo (also part of the La Oliva municipality) since 2005. Participants include Euskaltel-Euskadi, T-Mobile and a team from Orbea. These competitions have contributed to local interest in the sport and the first professional local team, the Fuerteventura-Canarias, was formed, initially run by Óscar Guerrero, director of Kaiku, although they have not competed for the past few seasons.
There are various motocross circuits on the island, including "Los Alares" in Antigua and "Isla de Fuerteventura" in Puerto del Rosario municipality. They hold regular trials, some of which form part of the Canarian Regional Motocross Championship. Throughout the year there are gravel rally races. Two are part of the Canarian Dirt Rally Championship. These are the Antiguan Rally and the La Oliva Rally.
The island's main football clubs are UD Pájara Playas de Jandía and CD Corralejo, who play in Group XII of the Spanish Tercera División.
The resort Playitas on the south coast is since around 2008 equipped with a 50 m swimming pool and has become a destination for triathlon training camps for Europeans. An annual race called Challenge Fuerteventura is held there on the half ironman distance.

</doc>
<doc id="11476" url="http://en.wikipedia.org/wiki?curid=11476" title="Fairmount, Indiana">
Fairmount, Indiana

Fairmount is a town in Fairmount Township, Grant County in the east central part of the U.S. state of Indiana. The population was 2,954 at the 2010 census. It is ninety kilometers (fifty-five miles) northeast of Indianapolis. Largely a bedroom community to its three thousand citizens, Fairmount is best known as the boyhood home of actor James Dean, who is buried there.
Geography.
Fairmount is located at (40.417702, −85.648942).
According to the 2010 census, the town has a total area of 1.58 sqmi, all land.
Demographics.
2010 census.
As of the census of 2010, there were 2,954 people, 1,241 households, and 837 families residing in the town. The population density was 1869.6 PD/sqmi. There were 1,350 housing units at an average density of 854.4 /sqmi. The racial makeup of the town was 98.6% White, 0.1% African American, 0.2% Native American, 0.2% Asian, 0.2% from other races, and 0.7% from two or more races. Hispanic or Latino of any race were 0.9% of the population.
There were 1,241 households of which 31.2% had children under the age of 18 living with them, 48.6% were married couples living together, 14.1% had a female householder with no husband present, 4.8% had a male householder with no wife present, and 32.6% were non-families. 28.0% of all households were made up of individuals and 12% had someone living alone who was 65 years of age or older. The average household size was 2.38 and the average family size was 2.85.
The median age in the town was 40.3 years. 23.9% of residents were under the age of 18; 8.4% were between the ages of 18 and 24; 23.2% were from 25 to 44; 28% were from 45 to 64; and 16.5% were 65 years of age or older. The gender makeup of the town was 48.5% male and 51.5% female.
2000 census.
As of the census of 2000, there were 2,992 people, 1,226 households, and 859 families residing in the town. The population density was 2,033.0 people per square mile (785.9/km²). There were 1,325 housing units at an average density of 900.3 per square mile (348.0/km²). The racial makeup of the town was 98.30% White, 0.17% Black or African American, 0.70% Native American, 0.20% Asian, 0.07% from other races, and 0.57% from two or more races. Hispanic or Latino of any race were 0.43% of the population.
There were 1,226 households out of which 31.2% had children under the age of 18 living with them, 55.5% were married couples living together, 11.0% had a female householder with no husband present, and 29.9% were non-families. 26.5% of all households were made up of individuals and 12.5% had someone living alone who was 65 years of age or older. The average household size was 2.44 and the average family size was 2.91.
In the town the population was spread out with 25.2% under the age of 18, 8.2% from 18 to 24, 28.2% from 25 to 44, 24.3% from 45 to 64, and 14.1% who were 65 years of age or older. The median age was 38 years. For every 100 females there were 90.5 males. For every 100 females age 18 and over, there were 90.0 males.
The median income for a household in the town was $33,843, and the median income for a family was $44,033. Males had a median income of $31,136 versus $23,041 for females. The per capita income for the town was $18,029. About 7.4% of families and 9.1% of the population were below the poverty line, including 11.8% of those under age 18 and 7.8% of those age 65 or over.
History.
The Fairmount area was settled in the 1830s mostly by Quakers from North Carolina. The town was laid out in 1850 and named for Fairmount Park in Philadelphia; it was formally incorporated in 1870.
After a large deposit of natural gas was found in 1887, Fairmount became part of the Indiana Gas Boom and a center of the glass industry for the rest of the 19th century. Shortly after the depletion of the gas in 1900 the automobile industry set up factories in the nearby large cities, and Fairmount became a bedroom community, restoring some of its lost prosperity.
In the 1940s, James Dean lived with an aunt and uncle, Ortense and Marcus Winslow on a farm north of Fairmount. He attended Fairmount High School, graduating in 1949. After his death in 1955, Dean was buried in Park Cemetery. In 1996, a small Memorial Park north of the town's business district was dedicated in his memory with a bronze bust by Hollywood artist Kenneth Kendall.
During the prosperity of the 1960s, Fairmount enjoyed a time of building with a new town hall, water works, post office and elementary school. At the end of the decade the local school district merged with a neighboring one, forming the Madison-Grant united school district. A new high school was built for this district, and Fairmount High School became a middle school. When a new junior high school was opened in 1986, the Fairmount High School building was permanently closed.
Fairmount was hit hard by the recession of 1980–1982, which brought the permanent loss of factory jobs and the failure of many farms, but rebounded later in the decade. Fairmount is still relatively prosperous despite the ill fortunes of nearby industrial cities and a steady loss of population.
In September 1988, The James Dean Gallery opened in a restored Victorian House on North Main Street. Over the years the Museum Exhibit has been toured by nearly 200,000 visitors who come from around the world to visit the hometown of James Dean. Also in 1988, English musician Morrissey filmed the music video for his single Suedehead; a song inspired by his lifelong admiration of Dean, in the town.
The annual James Dean Festival takes place during the last full weekend in September and includes a Custom & Hot Rod Car Show, The Grand Parade, Street Fair, Carnival Rides, Live Entertainment, a 1950's Dance Contest and the James Dean lookalike Contest.
On September 30 of each year there is a Memorial Service for James Dean at The Back Creek Friends Church, south of The Winslow Farm.

</doc>
<doc id="11477" url="http://en.wikipedia.org/wiki?curid=11477" title="Epistles to the Thessalonians">
Epistles to the Thessalonians

There are two Epistles to the Thessalonians in the Bible:

</doc>
<doc id="11478" url="http://en.wikipedia.org/wiki?curid=11478" title="Free verse">
Free verse

Free verse is an open form of poetry. It does not use consistent meter patterns, rhyme, or any other musical pattern. It thus tends to follow the rhythm of natural speech.
Prefatory.
Poets have explained that free verse is, despite its freedom, not entirely free. Free verse displays some elements of form. Most free verse, for example, self-evidently continues to observe a convention of the poetic line in some sense, at least in written representations, though retaining a potential degree of linkage. Donald Hall goes as far as to say that "the "form" of free verse is as binding and as liberating as the "form" of a rondeau", and T. S. Eliot wrote, "No verse is free for the man who wants to do a good job". Kenneth Allott the poet/critic said the adoption by some poets of vers libre arose from 'mere desire for novelty, the imitation of Whitman, the study of Jacobean dramatic blank verse, and the awareness of what French poets had already done to the Alexandrine in France'. The American critic John Livingston Lowes in 1916 observed 'Free verse may be written as very beautiful prose; prose may be written as very beautiful free verse. Which is which ?' 
Some poets have considered free verse restrictive in its own way. In 1922 Robert Bridges voiced his reservations in the essay 'Humdrum and Harum-Scarum.' Robert Frost later remarked that writing free verse was like "playing tennis without a net." William Carlos Williams said "being an art form, verse cannot be free in the sense of having no limitations or guiding principles". Yvor Winters, the poet/critic said "the free verse that is really verse, the best that is, of W.C. Williams, H. D., Marianne Moore, Wallace Stevens, and Ezra Pound is the antithesis of free"
Antecedents.
As the name vers libre suggests, this technique of using more irregular cadences is often said to be derived from the practices of 19th-century French poets such as Gustave Kahn and Jules Laforgue in his "Derniers vers" of 1890.Taupin, the USA based French poet/critic concluded that free verse and vers libre are not synonymous, since 'The French language tends to give equal weight to each spoken syllable, whereas English syllables vary in quantity according to whether stressed or unstressed'. The sort of cadencing that we now recognize as a variety of free verse can be traced back at least as far as the King James Bible. By referring to it is possible to argue that free verse in English first appeared in the 1380s in the John Wycliffe translation of the Psalms and was repeated in different form in most biblical translations ever since. Walt Whitman, who based his long lines in "Leaves of Grass" on the phrasing of the King James Bible, influenced later American free verse practitioners, notably Allen Ginsberg. One form of free verse was employed by Christopher Smart in a long poem called Jubilate Agno, written sometime between 1759 and 1763 but not published until 1939.
Many poets of the Victorian era experimented with free verse. Christina Rossetti, Coventry Patmore, and T. E. Brown all wrote examples of rhymed but unmetered verse. Poems such as W. E. Henley's 'Discharged' (from his "In Hospital" sequence). Free verse in English was persuasively advocated by critic T. E. Hulme in his "A Lecture on Modern Poetry" (1908). Later in the preface to "Some Imagist Poets" 1916, he comments, 'Only the name is new, you will find something much like vers libre in Dryden's "Threnodia Augustalis"; a great deal of Milton's "Samson Agonistes"..and the oldest in Chaucer's "House of Fame".' 
In France, a few pieces in Arthur Rimbaud's prose poem collection Illuminations were arranged in manuscript in lines, rather than prose and in the Netherlands, tachtiger (i.e. member of 1880s generation of innovative poets) Frederik van Eeden employed the form at least once (in his poem "Waterlelie" ["water lily"]).
Goethe (particularly in some early poems, such as "Prometheus") and Hölderlin used free verse occasionally, due in part to a misinterpretation of the meter used in Pindar's poetry; in Hölderlin's case, he also continued to write unmetered poems after discovering this error. The German poet Heinrich Heine made an important contribution to the development of free verse with 22 poems, written in two-poem cycles called 'Die Nordsee' (The North Sea) (written 1825-1826). These were first published in "Buch der Lieder" (Book of Songs) in 1827.
Form and structure.
Although free verse requires no meter, rhyme, or other traditional poetic techniques, a poet can still use them to create some sense of structure. A clear example of this can be found in Walt Whitman's poems, where he repeats certain phrases and uses commas to create both a rhythm and structure. Much pattern and discipline is to be found in free verse: the internal pattern of sounds, the choice of exact words, and the effect of associations give free verse its beauty. With the Imagists free verse became a discipline and acquired status as a legitimate poetic form. Herbert Read however, noting that 'the Imagist Ezra Pound gave free verse its musical structure to an extent that parodoxically it was no longer free'.
Because of a lack of predetermined form, free verse poems have the potential to take truly unique shapes. Unrestrained by traditional boundaries, Yvor Winters described this as 'attempts to widen experience by establishing 'abnormal' conventions', the poet possesses more license to express, and has more control over the development of the poem. This could allow for a more spontaneous and individualized product.

</doc>
<doc id="11479" url="http://en.wikipedia.org/wiki?curid=11479" title="F. W. de Klerk">
F. W. de Klerk

Frederik Willem de Klerk (]; born 18 March 1936) is a South African politician who served as the country's State President from September 1989 to May 1994. He was the seventh and last head of state of South Africa under the apartheid era. De Klerk was also leader of the National Party (which later became the New National Party) from February 1989 to September 1997.
De Klerk brokered the end of apartheid, South Africa's racial segregation policy, and supported the transformation of South Africa into a multi-racial democracy by entering into the negotiations that resulted in all citizens, including the country's black majority, having equal voting and other rights. He won the Félix Houphouët-Boigny Peace Prize in 1991, the Prince of Asturias Award in 1992 and the Nobel Peace Prize in 1993 along with Nelson Mandela for his role in the ending of apartheid.
He was one of the deputy presidents of South Africa during the presidency of Nelson Mandela until 1996, and is the last white person to hold the position. In 1997 he retired from active politics. He continues to remain active as a lecturer internationally. After the deaths of P.W. Botha in 2006 and Marais Viljoen in 2007, de Klerk is the last surviving State President of South Africa. Until the ascension of Guy Scott as acting President of Zambia in October 2014, he was the last White African to be president of a continental African country.
Background and early career.
The name "de Klerk" is derived from Le Clerc, Le Clercq, and de Clercq and is of French Huguenot origin (literally it means "the clerk" in both French and Dutch). De Klerk noted that he is also of Dutch descent, with an Indian ancestor from the late 1600s or early 1700s. He is also said to be descended from the Khoi interpreter known as Krotoa or Eva.
De Klerk was born in Johannesburg, in the then Transvaal Province of the Union of South Africa, to Johannes "Jan" de Klerk and Hendrina Cornelia Coetzer – "her forefather was a Kutzer who stems from Austria". He came from a family environment in which the conservatism of traditional white South African politics was deeply ingrained. His paternal great-grandfather was Senator Johannes Cornelis "Jan" van Rooy. His aunt was married to NP Prime Minister J. G. Strijdom. In 1948, the year when the NP swept to power in whites-only elections on an apartheid platform, F. W. de Klerk's father, Johannes "Jan" de Klerk, became secretary of the NP in the Transvaal province and later rose to the positions of cabinet minister and President of the Senate, becoming interim State President in 1975. His brother Willem is a liberal newspaperman and one of the founders of the Democratic Party. De Klerk graduated from Monument High School in Krugersdorp. De Klerk graduated in 1958 from the Potchefstroom University with BA and LL.B degrees (the latter "cum laude"). Following graduation, de Klerk practised law in Vereeniging in the Transvaal. In 1959 he married Marike Willemse, with whom he had two sons and a daughter.
"F.W.", pronounced "eff-veer", as he became popularly known, was first elected to the House of Assembly in 1969 as the member for Vereeniging, and entered the cabinet in 1978. De Klerk had been offered a professorship of administrative law at Potchefstroom in 1972 but he declined the post because he was serving in Parliament. In 1978, he was appointed Minister of Posts and Telecommunications and Social Welfare and Pensions by Prime Minister Vorster. Under Prime Minister and later State President P. W. Botha, he held a succession of ministerial posts, including Posts and Telecommunications and Sports and Recreation (1978–1979), Mines, Energy and Environmental Planning (1979–1980), Mineral and Energy Affairs (1980–1982), Internal Affairs (1982–1985), and National Education and Planning (1984–1989). He became Transvaal provincial National Party leader in 1982. In 1985, he became chairman of the Minister's Council in the House of Assembly.
Ending apartheid.
For most of his career, de Klerk had a very conservative reputation. The NP's Transvaal branch was historically the most staunchly conservative wing of the party, and he supported continued segregation of universities while Minister of National Education. It thus came as a surprise when in 1989 he placed himself at the head of "verligte" ("enlightened") forces within the governing party who had come to believe that apartheid could not be maintained forever. This wing favoured beginning negotiations while there was still time to get reasonable terms.
P. W. Botha resigned as leader of the National Party after an apparent stroke, and de Klerk defeated Botha's preferred successor, finance minister Barend du Plessis, in the race to succeed him. A month later, the NP caucus nominated de Klerk as state president. Botha initially refused to resign, saying that he intended to serve out his full five-year term, which expired in 1990. He even hinted that he might run for re-election. However, after protracted negotiations, Botha agreed to resign after the September 1989 parliamentary elections and hand power to de Klerk. However, Botha abruptly resigned on 14 August, and de Klerk was named acting state president until 20 September, when he was elected to a full five-year term as state president.
In some of his first speeches after assuming the party leadership, he called for a non-racist South Africa and for negotiations about the country's future. A couple of months later, in February 1990, he suddenly lifted the bans on the African National Congress (ANC) and the Communist Party of South Africa, released Nelson Mandela and also many others who had been imprisoned solely on the grounds of their membership in the ANC or CPSA. In legislative terms, he enabled the gradual end of apartheid. De Klerk also opened the way for the negotiations of the government with the anti-apartheid-opposition about a new constitution for the country. Nevertheless, he was accused by Anthony Sampson of complicity in the violence between the ANC, the Inkatha Freedom Party and elements of the security forces. In "", Sampson accuses de Klerk of permitting his ministers to build their own criminal empires.
His presidency was dominated by the negotiation process, mainly between his NP government and Mandela's ANC, which led to the democratisation of South Africa. In 1992, de Klerk held a whites-only referendum on ending apartheid, with the result being an overwhelming "yes" vote to continue negotiations to end apartheid.
In 1990, de Klerk gave orders to end South Africa's nuclear weapons programme; the process of nuclear disarmament was essentially completed in 1991. The existence of the programme was not officially acknowledged before 1993.
In 1993, de Klerk and Mandela were jointly awarded the Nobel Peace Prize for their work ending apartheid.
After the first universal elections in 1994, de Klerk became deputy president in the government of national unity under Nelson Mandela, a post he kept until 1996. In 1997 he resigned the leadership of the National Party and retired from politics.
Later life.
In 1996, de Klerk was offered the Harper Fellowship at Yale Law School. He later declined, citing protests at the university. De Klerk did, however, speak at Central Connecticut State University the day before his fellowship would have begun.
In 1998, de Klerk and his wife of 38 years, Marike de Klerk, were divorced following the discovery of his affair with Elita Georgiades, then the wife of Tony Georgiades, a Greek shipping tycoon who had allegedly given de Klerk and the NP financial support. Soon after his divorce, de Klerk and Georgiades were married. His divorce and remarriage scandalised conservative South African opinion, especially among the Calvinist Afrikaners. In 1999, his autobiography, "The Last Trek – A New Beginning", was published. De Klerk successfully had a chapter from Marike's biography, "A Place Where the Sun Shines Again", dealing with his infidelity, censored.
In 1999, de Klerk established the pro-peace FW de Klerk Foundation of which he is the chairman. De Klerk is also chairman of the Global Leadership Foundation which he set up in 2004, an organisation which works to support democratic leadership, prevent and resolve conflict through mediation and promote good governance in the form of democratic institutions, open markets, human rights and the rule of law. It does so by making available, discreetly and in confidence, the experience of former leaders to today's national leaders. It is a not-for-profit organisation composed of former heads of government and senior governmental and international organisation officials who work closely with heads of government on governance-related issues of concern to them.
On 4 December 2001, Marike de Klerk was found stabbed and violently strangled to death in her Cape Town flat. De Klerk, who was on a brief visit to Stockholm, Sweden, to celebrate the 100-year anniversary of the Nobel Prize foundation, announced he would immediately return to mourn his dead ex-wife. The atrocity was reportedly condemned strongly by South African president Thabo Mbeki and Winnie Mandela, among others, who openly spoke in favour of Marike de Klerk. On 6 December 21-year-old security guard Luyanda Mboniswa was arrested for the murder. On 15 May 2003, he received two life sentences for murder, as well as three years for breaking into Marike de Klerk's apartment.
In 2004, de Klerk announced that he was quitting the New National Party and seeking a new political home after it was announced that the NNP would merge with the ruling ANC. That same year, while giving an interview to US journalist Richard Stengel, de Klerk was asked whether South Africa had turned out the way he envisioned it back in 1990. His response was: "There are a number of imperfections in the new South Africa where I would have hoped that things would be better, but on balance I think we have basically achieved what we set out to achieve. And if I were to draw balance sheets on where South Africa stands now, I would say that the positive outweighs the negative by far. There is a tendency by commentators across the world to focus on the few negatives which are quite negative, like how are we handling AIDS, like our role vis-à-vis Zimbabwe. But the positives – the stability in South Africa, the adherence to well-balanced economic policies, fighting inflation, doing all the right things in order to lay the basis and the foundation for sustained economic growth – are in place." In 2008, he repeated in a speech that "despite all the negatives facing South Africa, he is very positive about the country".
In 2006, he underwent surgery for a malignant tumour in his colon, discovered after an examination on 3 June. His condition deteriorated sharply, and he underwent a second operation after developing respiratory problems. On 13 June, it was announced that he was to undergo a tracheotomy. He recovered and on 11 September 2006 gave a speech at Kent State University Stark Campus.
In January 2007, de Klerk was a speaker promoting peace and democracy in the world at the "Towards a Global Forum on New Democracies" event in Taipei, Taiwan, along with other dignitaries including Poland's Lech Wałęsa and Taiwan's then president Chen Shui-Bian.
De Klerk is an Honorary Patron of the University Philosophical Society and Honorary Chairman of the Prague Society for International Cooperation. He has also received the Gold Medal for Outstanding Contribution to Public Discourse from the College Historical Society for his contribution to ending apartheid.
De Klerk is also a Member of the Advisory Board of the Global Panel Foundation based in Berlin, Copenhagen, New York, Prague, Sydney and Toronto – founded by the Dutch entrepreneur Bas Spuybroek in 1988, with the support of Dutch billionaire Frans Lurvink and former Dutch Foreign Minister Hans van den Broek. The Global Panel Foundation is known for its behind-the-scenes work in public policy and the annual presentation of the Hanno R. Ellenbogen Citizenship Award with the Prague Society for International Cooperation.
After the inauguration of Jacob Zuma as South Africa's president in May 2009, de Klerk said he is optimistic that Zuma and his government can "confound the prophets of doom".
In a BBC interview broadcast in April 2012, he said he lived in an all-white neighbourhood. He had five servants, three coloured and two black: "We are one great big family together; we have the best of relationships." About Nelson Mandela, he said, "When Mandela goes it will be a moment when all South Africans put away their political differences, will take hands, and will together honour maybe the biggest known South African that has ever lived."
Upon hearing of the death of Mandela, de Klerk said: "He was a great unifier and a very, very special man in this regard beyond everything else he did. This emphasis on reconciliation was his biggest legacy."

</doc>
<doc id="11488" url="http://en.wikipedia.org/wiki?curid=11488" title="Furlong">
Furlong

A furlong is a measure of distance in imperial units and U.S. customary units equal to one-eighth of a mile, equivalent to 660 feet, 220 yards, 40 rods, or 10 chains. Using the internationally accepted conversion ratio that one inch equals exactly 25.4 millimetres, one furlong is 201.168 metres. However, the United States does not uniformly use this conversion ratio. Older ratios are in use for surveying purposes in some states, leading to variations in the length of the furlong of about two parts per million, or 0.4 millimetres (1⁄64 inch). This variation is too small to have many practical consequences. Five furlongs are about 1.0 kilometre (1.00584 km is the exact value, according to the international conversion).
History.
The name "furlong" derives from the Old English words "furh" (furrow) and "lang" (long). Dating back at least to early Anglo-Saxon times, it originally referred to the length of the furrow in one acre of a ploughed open field (a medieval communal field which was divided into strips). The system of long furrows arose because turning a team of oxen pulling a heavy plough was difficult. This offset the drainage advantages of short furrows and meant furrows were made as long as possible. An acre is an area that is one furlong long and one chain (66 feet or 22 yards) wide. For this reason, the furlong was once also called an acre's length, though in modern usage an area of one acre can be of any shape. The term furlong, or shot, was also used to describe a grouping of adjacent strips within an open field.
Among the early Anglo-Saxons, the rod was the fundamental unit of land measurement. A furlong was forty rods, an acre four by 40 rods, or four rods by one furlong. and thus 160 square rods. At the time, the Saxons used the North German foot, which was 10 percent longer than the foot of today. When England changed to the shorter foot in the late 13th century, rods and furlongs remained unchanged, since property boundaries were already defined in rods and furlongs. The only thing that changed was the number of feet and yards in a rod or a furlong, and the number of square feet and square yards in an acre. The definition of the rod went from 15 old feet to 16 1/2 new feet, or from five old yards to 5 1/2 new yards. The furlong went from 600 old feet to 660 new feet, or from 200 old yards to 220 new yards. The acre went from 36,000 old square feet to 43,560 new square feet, or from 4,000 old square yards to 4,840 new square yards.
The furlong was historically viewed as being equivalent to the Roman stade ("stadium"), which in turn derived from the Greek system. For example, the King James Bible uses the term "furlong" in place of the Greek "stadion", although more recent translations often use miles or kilometres in the main text and give the original numbers in footnotes.
In the Roman system, there were 625 feet to the "stadium", eight "stadia" to the mile, and three miles to the league. A league was considered to be the distance a man could walk in one hour, and the mile (from "mille", meaning 1000) consisted of 1,000 "passus" (paces, five feet, or double-step).
After the fall of the Roman Empire, medieval Europe continued with the Roman system, which the people proceeded to diversify, leading to serious complications in trade, taxation, etc. Around the year 1300, by royal decree England standardized a long list of measures. Among the important units of distance and length at the time were the foot, yard, rod(or pole), furlong, and the mile. The rod was defined as 5 1/2 yards or 16 1/2 feet, and the mile was eight furlongs, so the definition of the furlong became 40 rods and that of the mile became 5,280 feet (eight furlongs/mile times 40 rods/furlong times 16 1/2 feet/rod).
A description from 1675 states, "Dimensurator or Measuring Instrument whereof the mosts usual has been the Chain, and the common length for English Measures four Poles, as answering indifferently to the Englishs Mile and Acre, 10 such Chains in length making a Furlong, and 10 single square Chains an Acre, so that a square Mile contains 640 square Acres." —John Ogilby, Britannia, 1675
The official use of the furlong was abolished in the United Kingdom under the Weights and Measures Act 1985, an act that also abolished the official use of many other traditional units of measurement.
Use.
In Myanmar, furlongs are currently used in conjunction with miles to indicate distances on highway signs. Mileposts on the Yangon-Mandalay Expressway use miles and furlongs.
In the rest of the world, the furlong has very limited use, with the notable exception of horse racing in most English-speaking countries, including Canada and the United States. The distances for horse-racing in Australia were metricized in 1972; but, in the United Kingdom, Ireland, Canada, and the United States, races are still given in miles and furlongs. 
The city of Chicago's street numbering system allots a measure of 800 address units to each mile, in keeping with the city's system of eight blocks per mile. This means that every block in a typical Chicago neighborhood (in either North/South or East/West direction but rarely both) is approximately one furlong in length. Salt Lake City's blocks are also each a square furlong in the downtown area. The blocks become less regular in shape further from the center, but the numbering system (800 units to each mile) remains the same everywhere in Salt Lake County. Bus stops in Ann Arbor, Michigan, are about a furlong apart. Blocks in central Logan, Utah, and in large sections of Phoenix, Arizona, are similarly a square furlong in extent (eight to a mile, which explains the series of freeway exits: 19th Ave, 27th, 35th, 43rd, 51st, 59th ...). City blocks in the Hoddle Grid of Melbourne are also one furlong in length.
Much of Ontario, Canada, was originally surveyed on a ten-furlong grid, with major roads being laid out along the grid lines. Now that distances are shown on road signs in kilometres, it is obvious that these major roads are almost exactly two kilometres apart. The exits on highways running through Toronto, for example, are generally at intervals of two kilometres.
The furlong is also a base unit of the humorous FFF system of units.
Conversion to SI units.
The exact conversion of the furlong to SI units varies slightly among English-speaking countries. In Canada and the United Kingdom,
which define the furlong in terms of the international yard of exactly 0.9144 metre, a furlong is 201.168 m.
Australia does not formally define the furlong, but it does define the chain and link in terms of the international yard.
In the United States, which defines the furlong, chain, rod, and link in terms of the U.S. survey foot of exactly 1200⁄3937 metre, a furlong is approximately 201.1684 m long. The United States does not formally define a "survey yard". The difference of approximately two parts per million between the U.S. value and the "international" value is insignificant for most practical measurements.

</doc>
<doc id="11489" url="http://en.wikipedia.org/wiki?curid=11489" title="File">
File

File or filing may refer to:

</doc>
<doc id="11490" url="http://en.wikipedia.org/wiki?curid=11490" title="Fundamental frequency">
Fundamental frequency

The fundamental frequency, often referred to simply as the fundamental, is defined as the lowest frequency of a periodic waveform. In terms of a superposition of sinusoids (e.g. Fourier series), the fundamental frequency is the lowest frequency sinusoidal in the sum. In some contexts, the fundamental is usually abbreviated as f"0 (or FF), indicating the lowest frequency counting from zero. In other contexts, it is more common to abbreviate it as f"1, the first harmonic. (The second harmonic is then f2 = 2⋅f1, etc. In this context, the zeroth harmonic would be 0 Hz.)
Explanation.
All sinusoidal and many non-sinusoidal waveforms are periodic, which is to say they repeat exactly over time. A single period is thus the smallest repeating unit of a signal, and one period describes the signal completely. We can show a waveform is periodic by finding some period "T" for which the following equation is true:
Where "x"("t") is the function of the waveform.
This means that for multiples of some period T the value of the signal is always the same. The least possible value of T for which this is true is called the fundamental period and the fundamental frequency ("f"0) is:
Where "f"0 is the fundamental frequency and "T" is the fundamental period.
For a tube of length "L" with one end closed and the other end open the wavelength of the fundamental harmonic is 4"L", as indicated by the top two animations on the right. Hence,
Therefore, using the relation
where "v" is the speed of the wave, we can find the fundamental frequency in terms of the speed of the wave and the length of the tube:
If the ends of the same tube are now both closed or both opened as in the bottom two animations on the right, the wavelength of the fundamental harmonic becomes 2"L". By the same method as above, the fundamental frequency is found to be
At 20 °C (68 °F) the speed of sound in air is 343 m/s (1129 ft/s). This speed is temperature dependent and does increase at a rate of 0.6 m/s for each degree Celsius increase in temperature (1.1 ft/s for every increase of 1 °F).
The velocity of a sound wave at different temperatures:-
Mechanical systems.
Consider a spring, fixed at one end and having a mass attached to the other; this would be a single degree of freedom (SDoF) oscillator. Once set into motion it will oscillate at its natural frequency. For a single degree of freedom oscillator, a system in which the motion can be described by a single coordinate, the natural frequency depends on two system properties: mass and stiffness; (providing the system is undamped). The radian frequency, "ω"n, can be found using the following equation:
Where:
"k" = stiffness of the spring
"m" = mass 
"ω"n = radian frequency (radians per second)
From the radian frequency, the natural frequency, "f"n, can be found by simply dividing "ω"n by 2"π". Without first finding the radian frequency, the natural frequency can be found directly using:
Where:
"f"n = natural frequency in hertz (cycles/second)
"k" = stiffness of the spring (Newtons/meter or N/m)
"m" = mass(kg) 
while doing the modal analysis of structures and mechanical equipment, the frequency of 1st mode is called fundamental frequency.

</doc>
<doc id="11491" url="http://en.wikipedia.org/wiki?curid=11491" title="Fable">
Fable

Fable is a literary genre: a succinct fictional story, in prose or verse, that features animals, mythical creatures, plants, inanimate objects, or forces of nature that are anthropomorphized (given human qualities, such as verbal communication) and that illustrates or leads to an interpretation of a moral lesson (a "moral"), which may at the end be added explicitly as a pithy maxim.
A fable differs from a parable in that the latter "excludes" animals, plants, inanimate objects, and forces of nature as actors that assume speech or other powers of humankind.
Usage has not always been so clearly distinguished. In the King James Version of the New Testament, "μῦθος" ("mythos") was rendered by the translators as "fable" in the First Epistle to Timothy, the Second Epistle to Timothy, the Epistle to Titus and the First Epistle of Peter.
A person who writes fables is a fabulist.
History.
The fable is one of the most enduring forms of folk literature, spread abroad, modern researchers agree, less by literary anthologies than by oral transmission. Fables can be found in the literature of almost every country.
Aesopic or Aesop's fable.
The varying corpus denoted "Aesopica" or "Aesop's Fables" includes most of the best-known western fables, which are attributed to the legendary Aesop, supposed to have been a slave in ancient Greece around 550 BC. When Babrius set down fables from the "Aesopica" in verse for a Hellenistic Prince "Alexander," he expressly stated at the head of Book II that this type of "myth" that Aesop had introduced to the "sons of the Hellenes" had been an invention of "Syrians" from the time of "Ninos" (personifying Nineveh to Greeks) and Belos ("ruler"). Epicharmus of Kos and Phormis are reported as having been among the first to invent comic fables. Many familiar fables of Aesop include "The Crow and the Pitcher", "The Tortoise and the Hare" and "The Lion and the Mouse". In ancient Greek and Roman education, the fable was the first of the "progymnasmata"—training exercises in prose composition and public speaking—wherein students would be asked to learn fables, expand upon them, invent their own, and finally use them as persuasive examples in longer forensic or deliberative speeches. The need of instructors to teach, and students to learn, a wide range of fables as material for their declamations resulted in their being gathered together in collections, like those of Aesop.
Africa.
African oral culture has a rich story-telling tradition. As they have for thousands of years, people of all ages in Africa continue to interact with nature, including plants, animals and earthly structures such as rivers, plains and mountains. Grandparents enjoy enormous respect in African societies and fill the new role of story-telling during retirement years. Children and, to some extent, adults are mesmerized by good story-tellers when they become animated in their quest to tell a good fable.
India.
India has a rich tradition of fabulous novels, mostly explainable by the fact that the culture derives traditions and learns qualities from natural elements. Most of the gods are some form of animals with ideal qualities. Also hundreds of fables were composed in ancient India during the first millennium BC, often as stories within frame stories. Indian fables have a mixed cast of humans and animals. The dialogues are often longer than in fables of Aesop and often witty as the animals try to outwit one another by trickery and deceit. In Indian fables, man is not superior to the animals. The tales are often comical. The Indian fable adhered to the universally known traditions of the fable.
The best examples of the fable in India are the Panchatantra and the Jataka Tales. These included Vishnu Sarma's "Panchatantra", the "Hitopadesha", "Vikram and The Vampire", and Syntipas' "Seven Wise Masters", which were collections of fables that were later influential throughout the Old World. Ben E. Perry (compiler of the "Perry Index" of Aesop's fables)has argued controversially that some of the Buddhist "Jataka tales" and some of the fables in the "Panchatantra" may have been influenced by similar Greek and Near Eastern ones. Earlier Indian epics such as Vyasa's "Mahabharata" and Valmiki's "Ramayana" also contained fables within the main story, often as side stories or back-story. The most famous fables from the Middle East were the "One Thousand and One Nights", also known as the "Arabian Nights".
Europe.
Fables had a further long tradition through the Middle Ages, and became part of European high literature. During the 17th century, the French fabulist Jean de La Fontaine (1621–1695) saw the soul of the fable in the moral — a rule of behavior. Starting with the Aesopian pattern, La Fontaine set out to satirize the court, the church, the rising bourgeoisie, indeed the entire human scene of his time. La Fontaine's model was subsequently emulated by England's John Gay (1685–1732); Poland's Ignacy Krasicki (1735–1801); Italy's (1739–1812) and (1754–1827); Serbia's Dositej Obradović (1742–1811); Spain's Félix María de Samaniego (1745–1801) and Tomás de Iriarte y Oropesa (1750–1791); France's Jean-Pierre Claris de Florian (1755–94); and Russia's Ivan Krylov (1769–1844).
Modern era.
In modern times, while the fable has been trivialized in children's books, it has also been fully adapted to modern adult literature. Felix Salten's "Bambi" (1923) is a "Bildungsroman" — a story of a protagonist's coming-of-age — cast in the form of a fable. James Thurber used the ancient fable style in his books "Fables for Our Time" (1940) and "Further Fables for Our Time" (1956), and in his stories "The Princess and the Tin Box" in "The Beast in Me and Other Animals" (1948) and "The Last Clock: A Fable for the Time, Such As It Is, of Man" in "Lanterns and Lances" (1961). Władysław Reymont's "The Revolt" (1922), a metaphor for the Bolshevik Revolution of 1917, described a revolt by animals that take over their farm in order to introduce "equality." George Orwell's "Animal Farm" (1945) similarly satirized Stalinist Communism in particular, and totalitarianism in general, in the guise of animal fable.
In the 21st century the Neapolitan writer Sabatino Scia is the author of more than two hundred fables, that he describes as “western protest fables”. The characters are not only animals, but also Things, Beings and Elements from nature. Scia’s aim is the same as in the traditional fable, playing the role of revealer of human society.
In Latin America, the brothers Juan and Victor Ataucuri Garcia have contributed to the resurgence of the fable. But they do so with a novel idea: use the fable as a means of dissemination of traditional literature of that place. In the book "Peruvian Fables" published in 2003, they have collected myths, legends, beliefs Andean and Amazonian Peru, to write as fables. The result has been an extraordinary work rich in regional nuances. Here we discover the relationship between man and his origin, with nature, with its history, its customs and beliefs then become norms and values.
See also.
See also: .

</doc>
<doc id="11492" url="http://en.wikipedia.org/wiki?curid=11492" title="Foot">
Foot

The foot (plural feet) is an anatomical structure found in many vertebrates. It is the terminal portion of a limb which bears weight and allows locomotion. In many animals with feet, the foot is a separate organ at the terminal part of the leg made up of one or more segments or bones, generally including claws or nails.
Structure.
The human foot and ankle is a strong and complex mechanical structure containing 26 bones, 33 joints (20 of which are actively articulated), and more than a hundred muscles, tendons, and ligaments.
An anthropometric study of 1197 North American adult Caucasian males (mean age 35.5 years) found that a man's foot length was 26.3 cm with a standard deviation of 1.2 cm.
The foot can be subdivided into the hindfoot, the midfoot, and the forefoot:
The "hindfoot" is composed of the talus (or ankle bone) and the calcaneus (or heel bone). The two long bones of the lower leg, the tibia and fibula, are connected to the top of the talus to form the ankle. Connected to the talus at the subtalar joint, the calcaneus, the largest bone of the foot, is cushioned inferiorly by a layer of fat.
The five irregular bones of the "midfoot", the cuboid, navicular, and three cuneiform bones, form the arches of the foot which serves as a shock absorber. The midfoot is connected to the hind- and fore-foot by muscles and the plantar fascia.
The "forefoot" is composed of five toes and the corresponding five proximal long bones forming the metatarsus. Similar to the fingers of the hand, the bones of the toes are called phalanges and the big toe has two phalanges while the other four toes have three phalanges. The joints between the phalanges are called interphalangeal and those between the metatarsus and phalanges are called metatarsophalangeal (MTP).
Both the midfoot and forefoot constitute the "dorsum" (the area facing upwards while standing) and the "planum" (the area facing downwards while standing).
The "instep" is the arched part of the top of the foot between the toes and the ankle.
Bones.
There can be many sesamoid bones near the metatarsophalangeal joints, although they are only regularly present in the distal portion of the first metatarsal bone.
Arches.
The human foot has two longitudinal arches and a transverse arch maintained by the interlocking shapes of the foot bones, strong ligaments, and pulling muscles during activity. The slight mobility of these arches when weight is applied to and removed from the foot makes walking and running more economical in terms of energy. As can be examined in a footprint, the medial longitudinal arch curves above the ground. This arch stretches from the heel bone over the "keystone" ankle bone to the three medial metatarsals. In contrast, the lateral longitudinal arch is very low. With the cuboid serving as its keystone, it redistributes part of the weight to the calcaneus and the distal end of the fifth metatarsal. The two longitudinal arches serve as pillars for the transverse arch which run obliquely across the tarsometatarsal joints. Excessive strain on the tendons and ligaments of the feet can result in fallen arches or flat feet.
Muscles.
The muscles acting on the foot can be classified into extrinsic muscles, those originating on the anterior or posterior aspect of the lower leg, and intrinsic muscles, originating on the dorsal (top) or plantar (base) aspects of the foot.
Extrinsic.
All muscles originating on the lower leg except the popliteus muscle are attached to the bones of the foot. The tibia and fibula and the interosseous membrane separate these muscles into anterior and posterior groups, in their turn subdivided into subgroups and layers.
"Anterior group"
"Extensor group": tibialis anterior originates on the proximal half of the tibia and the interosseous membrane and is inserted near the tarsometatarsal joint of the first digit. In the non-weight-bearing leg tibialis anterior flexes the foot dorsally and lift its medial edge (supination). In the weight-bearing leg it brings the leg towards the back of the foot, like in rapid walking. Extensor digitorum longus arises on the lateral tibial condyle and along the fibula to be inserted on the second to fifth digits and proximally on the fifth metatarsal. The extensor digitorum longus acts similar to the tibialis anterior except that it also dorsiflexes the digits. Extensor hallucis longus originates medially on the fibula and is inserted on the first digit. As the name implies it dorsiflexes the big toe and also acts on the ankle in the unstressed leg. In the weight-bearing leg it acts similar to the tibialis anterior.
"Peroneal group": peroneus longus arises on the proximal aspect of the fibula and peroneus brevis below it on the same bone. Together, their tendons pass behind the lateral malleolus. Distally, peroneus longus crosses the plantar side of the foot to reach its insertion on the first tarsometatarsal joint, while peroneus brevis reaches the proximal part of the fifth metatarsal. These two muscles are the strongest pronators and aid in plantar flexion. Longus also acts like a bowstring that braces the transverse arch of the foot.
"Posterior group"
The "superficial layer" of posterior leg muscles is formed by the triceps surae and the plantaris. The triceps surae consists of the soleus and the two heads of the gastrocnemius. The heads of gastrocnemius arise on the femur, proximal to the condyles, and soleus arises on the proximal dorsal parts of the tibia and fibula. The tendons of these muscles merge to be inserted onto the calcaneus as the Achilles tendon. Plantaris originates on the femur proximal to the lateral head of the gastrocnemius and its long tendon is embedded medially into the Achilles tendon. The triceps surae is the primary plantar flexor and its strength becomes most obvious during ballet dancing. It is fully activated only with the knee extended because the gastrocnemius is shortened during knee flexion. During walking it not only lifts the heel, but also flexes the knee, assisted by the plantaris.
In the "deep layer" of posterior muscles tibialis posterior arises proximally on the back of the interosseous membrane and adjoining bones and divides into two parts in the sole of the foot to attach to the tarsus. In the non-weight-bearing leg, it produces plantar flexion and supination, and, in the weight-bearing leg, it proximates the heel to the calf. flexor hallucis longus arises on the back of the fibula (i.e. on the lateral side), and its relatively thick muscle belly extends distally down to the flexor retinaculum where it passes over to the medial side to stretch across the sole to the distal phalanx of the first digit. The popliteus is also part of this group, but, with its oblique course across the back of the knee, does not act on the foot.
Intrinsic.
On the "back" (top) "of the foot", the tendons of extensor digitorum brevis and extensor hallucis brevis lie deep to the system of long extrinsic extensor tendons. They both arise on the calcaneus and extend into the dorsal aponeurosis of digits one to four, just beyond the penultimate joints. They act to dorsiflex the digits.
Similar to the intrinsic muscles of the hand, there are three groups of muscles in the "sole of foot", those of the first and last digits, and a central group:
"Muscles of the big toe": abductor hallucis stretches medially along the border of the sole, from the calcaneus to the first digit. Below its tendon, the tendons of the long flexors pass through the tarsal canal. It is an abductor and a weak flexor, and also helps maintain the arch of the foot. flexor hallucis brevis arises on the medial cuneiform bone and related ligaments and tendons. An important plantar flexor, it is crucial for ballet dancing. Both these muscles are inserted with two heads proximally and distally to the first metatarsophalangeal joint. Adductor hallucis is part of this group, though it originally formed a separate system (see contrahens.) It has two heads, the oblique head originating obliquely across the central part of the midfoot, and the transverse head originating near the metatarsophalangeal joints of digits five to three. Both heads are inserted into the lateral sesamoid bone of the first digit. Adductor hallucis acts as a tensor of the plantar arches and also adducts the big toe and then might plantar flex the proximal phalanx.
"Muscles of the little toe": Stretching laterally from the calcaneus to the proximal phalanx of the fifth digit, abductor digiti minimi form the lateral margin of the foot and is the largest of the muscles of the fifth digit. Arising from the base of the fifth metatarsal, flexor digiti minimi is inserted together with abductor on the first phalanx. Often absent, opponens digiti minimi originates near the cuboid bone and is inserted on the fifth metatarsal bone. These three muscles act to support the arch of the foot and to plantar flex the fifth digit.
"Central muscle group": The four lumbricals arise on the medial side of the tendons of flexor digitorum longus and are inserted on the medial margins of the proximal phalanges. Quadratus plantae originates with two slips from the lateral and medial margins of the calcaneus and inserts into the lateral margin of the flexor digitorum tendon. It is also known as flexor accessorius. Flexor digitorum brevis arise inferiorly on the calcaneus and its three tendons are inserted into the middle phalanges of digits two to four (sometimes also the fifth digit). These tendons divide before their insertions and the tendons of flexor digitorum longus pass through these divisions. Flexor digitorum brevis flexes the middle phalanges. It is occasionally absent. Between the toes, the dorsal and plantar interossei stretch from the metatarsals to the proximal phalanges of digits two to five. The plantar interossei adducts and the dorsal interossei abducts these digits and are also plantar flexors at the metatarsophalangeal joints.
Clinical relevance.
Due to their position and function, feet are exposed to a variety of potential infections and injuries, including athlete's foot, bunions, ingrown toenails, Morton's neuroma, plantar fasciitis, plantar warts and stress fractures. In addition, there are several genetic disorders that can affect the shape and function of the feet, including a club foot or flat feet.
This leaves humans more vulnerable to medical problems that are caused by poor leg and foot alignments. Also, the wearing of shoes, sneakers and boots can impede proper alignment and movement within the ankle and foot. For example, High-heeled footwear are known to throw off the natural weight balance (this can also affect the lower back). For the sake of posture, flat soles with no heels are advised.
A doctor who specializes in the treatment of the feet practices podiatry and is called a podiatrist. A pedorthist specializes in the use and modification of footwear to treat problems related to the lower limbs.
Fractures of the foot include:
Foot sweat is the major cause of foot odor. Sweat itself is odorless, but it creates a beneficial environment for certain bacteria to grow and produce bad-smelling substances.
Pronation.
In anatomy, pronation is a rotational movement of the forearm (at the radioulnar joint) or foot (at the subtalar and talocalcaneonavicular joints). Pronation of the foot refers to how the body distributes weight as it cycles through the gait. During the gait cycle the foot can pronate in many different ways based on rearfoot and forefoot function. Types of pronation include neutral pronation, underpronation (supination), and overpronation.
An individual who neutrally pronates initially strikes the ground on the lateral side of the heel. As the individual transfers weight from the heel to the metatarsus, the foot will roll in a medial direction, such that the weight is distributed evenly across the metatarsus. In this stage of the gait, the knee will generally, but not always, track directly over the hallux.
This rolling inwards motion as the foot progresses from heel to toe is the way that the body naturally absorbs shock. Neutral pronation is the most ideal, efficient type of gait when using a heel strike gait; in a forefoot strike, the body absorbs shock instead via flexation of the foot.
As with a neutral pronator, an individual who overpronates initially strikes the ground on the lateral side of the heel. As the individual transfers weight from the heel to the metatarsus, however, the foot will roll too far in a medial direction, such that the weight is distributed unevenly across the metatarsus, with excessive weight borne on the hallux. In this stage of the gait, the knee will generally, but not always, track inwards.
An overpronator does not absorb shock efficiently. Imagine someone jumping onto a diving board, but the board is so flimsy that when it is struck, it bends and allows the person to plunge straight down into the water instead of back into the air. Similarly, an overpronator's arches will collapse, or the ankles will roll inwards (or a combination of the two) as they cycle through the gait. An individual whose bone structure involves external rotation at the hip, knee, or ankle will be more likely to overpronate than one whose bone structure has internal rotation or central alignment. An individual who overpronates tends to wear down their running shoes on the medial (inside) side of the shoe towards the toe area.
When choosing a running or walking shoe, a person with overpronation can choose shoes that have good inside support—usually by strong material at the inside sole and arch of the shoe. It is usually visible. The inside support area is marked by strong greyish material to support the weight when a person lands on the outside foot and then roll onto the inside foot.
An individual who underpronates also initially strikes the ground on the lateral side of the heel. As the individual transfers weight from the heel to the metatarsus, the foot will not roll far enough in a medial direction. The weight is distributed unevenly across the metatarsus, with excessive weight borne on the fifth metatarsal, towards the lateral side of the foot. In this stage of the gait, the knee will generally, but not always, track laterally of the hallux.
Like an overpronator, an underpronator does not absorb shock efficiently – but for the opposite reason. The underpronated foot is like a diving board that, instead of failing to spring someone in the air because it is too flimsy, it fails to do so because it is too rigid. There is virtually no give. An underpronator's arches or ankles don't experience much motion as they cycle through the gait. An individual whose bone structure involves internal rotation at the hip, knee, or ankle will be more likely to underpronate than one whose bone structure has external rotation or central alignment. Usually – but not always – those who are bow-legged tend to underpronate. An individual who underpronates tends to wear down their running shoes on the lateral (outside) side of the shoe towards the rear of the shoe in the heel area.
Society and culture.
Humans usually wear shoes or similar footwear for protection from hazards when walking outside. There are a number of contexts where it is considered inappropriate to wear shoes. Some people consider it rude to wear shoes into a house and a Māori Marae should only be entered with bare feet.
Foot fetishism is the most common form of sexual fetish.
Other animals.
A paw is the soft foot of a mammal, generally a quadruped, that has claws or nails. A hard foot is called a hoof.
Depending on style of locomotion, animals can be classified as plantigrade (sole walking), digitigrade (toe walking), or unguligrade (nail walking).
The metatarsals are the bones that make up the main part of the foot in humans, and part of the leg in large animals or paw in smaller animals. The number of metatarsals are directly related to the mode of locomotion with many larger animals having their digits reduced to two (elk, cow, sheep) or one (horse). The metatarsal bones of feet and paws are tightly grouped compared to, most notably, the human hand where the thumb metacarpal diverges from the rest of the metacarpus.

</doc>
<doc id="11493" url="http://en.wikipedia.org/wiki?curid=11493" title="Fallout shelter">
Fallout shelter

A fallout shelter is an enclosed space specially designed to protect occupants from radioactive debris or fallout resulting from a nuclear explosion. Many such shelters were constructed as civil defense measures during the Cold War.
During a nuclear explosion, matter vaporized in the resulting fireball is exposed to neutrons from the explosion, absorbs them, and becomes radioactive. When this material condenses in the rain, it forms dust and light sandy materials that resembles ground pumice. The fallout emits alpha and beta particles, as well as gamma rays.
Much of this highly radioactive material falls to earth, subjecting anything within the line of sight to radiation, becoming a significant hazard. A fallout shelter is designed to allow its occupants to minimize exposure to harmful fallout until radioactivity has decayed to a safer level.
History.
During the Cold War, many countries built fallout shelters for high-ranking government officials and crucial military facilities, such as Project Greek Island and Cheyenne Mountain nuclear bunker in the United States and Canada's Emergency Government Headquarters. Plans were made, however, to use existing buildings with sturdy below-ground-level basements as makeshift fallout shelters. These buildings were usually placarded with the yellow and black trefoil sign.
The National Emergency Alarm Repeater (N.E.A.R.) program was developed in the United States 1956 during the Cold War to supplement the existing siren warning systems and radio broadcasts in the event of a nuclear attack. The N.E.A.R. civilian alarm device was engineered and tested but the program was not viable and was terminated in 1967. In the U.S. in September 1961, under the direction of Steuart L. Pittman, the federal government started the Community Fallout Shelter Program. A letter from President Kennedy advising the use of fallout shelters appeared in the September 1961 issue of "Life" magazine.
In November 1961 in "Fortune" magazine, an article by Gilbert Burck appeared that outlined the plans of Nelson Rockefeller, Edward Teller, Herman Kahn, and Chet Holifield for an enormous network of concrete lined underground fallout shelters throughout the United States sufficient to shelter millions of people to serve as a refuge in case of nuclear war.
Switzerland built an extensive network of fallout shelters, not only through extra hardening of government buildings such as schools, but also through a building regulation that ensured that all residential building built after 1978 contained a nuclear shelter able to withstand a blast from a 12 megaton explosion at a distance of 700 metres. In addition, the Swiss government maintains large communal shelters (including the Sonnenberg Tunnel) stocked with over four months of food and fuel. The reference "Nuclear War Survival Skills" declared that, as of 1986, "Switzerland has the best civil defense system, one that already includes blast shelters for over 85 percent of all its citizens."
Similar projects have been undertaken in Finland, which requires all buildings with area over 600 m² to have an NBC shelter, and Norway, which requires all buildings with an area over 1000 m² to have a shelter.
The former Soviet Union and other Eastern Bloc countries often designed their underground mass-transit and subway tunnels to serve as bomb and fallout shelters in the event of an attack.
In Switzerland, most residential shelters are no longer stocked with the food and water required for prolonged habitation and a large number have been converted by the owners to other uses (e.g., wine cellars, ski rooms, gyms).
Details of shelter construction.
Shielding.
A basic fallout shelter consists of shields that reduce gamma ray exposure by a factor of 1000. The required shielding can be accomplished with 10 times the thickness of any quantity of material capable of cutting gamma ray exposure in half. Shields that reduce gamma ray intensity by 50% (1/2) include 1 cm (0.4 inch) of lead, 6 cm (2.4 inches) of concrete, 9 cm (3.6 inches) of packed earth or 150 m (500 ft) of air. When multiple thicknesses are built, the shielding multiplies. Thus, a practical fallout shield is ten halving-thicknesses of packed earth, reducing gamma rays by approximately 1024 times (210).
Usually, an expedient purpose-built fallout shelter is a trench; with a strong roof buried by c. 1 m (3 ft) of earth. The two ends of the trench have ramps or entrances at right angles to the trench, so that gamma rays cannot enter (they can travel only in straight lines). To make the overburden waterproof (in case of rain), a plastic sheet may be buried a few inches below the surface and held down with rocks or bricks.
Blast doors are designed to absorb the shock wave of a nuclear blast, bending and then returning to their original shape.
Climate control.
Dry earth is a reasonably good thermal insulator, and over several weeks of habitation, a shelter will become dangerously hot. The simplest form of effective fan to cool a shelter is a wide, heavy frame with flaps that swing in the shelter's doorway and can be swung from hinges on the ceiling. The flaps open in one direction and close in the other, pumping air. (This is a Kearny Air Pump, or KAP, named after the inventor, Cresson Kearny)
Unfiltered air is safe, since the most dangerous fallout has the consistency of sand or finely ground pumice. Such large particles are not easily ingested into the soft tissues of the body, so extensive filters are not required. Any exposure to fine dust is far less hazardous than exposure to the fallout outside the shelter. Dust fine enough to pass the entrance will probably pass through the shelter. Some shelters, however, incorporate NBC-filters for additional protection.
Locations.
Effective public shelters can be the middle floors of some tall buildings or parking structures, or below ground level in most buildings with more than 10 floors. The thickness of the upper floors must form an effective shield, and the windows of the sheltered area must not view fallout-covered ground that is closer than 1.5 km (1 mi). One of Switzerland's solutions is to utilise road tunnels passing through the mountains, with some of these shelters being able to protect tens of thousands.
Fallout shelters are not always underground. Above ground buildings with walls and roofs dense enough to afford a meaningful protection factor can be used as a fallout shelter.
Contents.
A battery-powered radio may be helpful to get reports of fallout patterns and clearance. However, radio and other electronic equipment may be disabled by electromagnetic pulse. For example, even at the height of the cold war, EMP protection had been completed for only 125 of the approximately 2,771 radio stations in the United States Emergency Broadcast System. Also, only 110 of 3,000 existing Emergency Operating Centers had been protected against EMP effects. The Emergency Broadcast System has since been supplanted in the United States by the Emergency Alert System.
The reference "Nuclear War Survival Skills" includes the following supplies in a list of "Minimum Pre-Crisis Preparations": one or more shovels, a pick, a bow-saw with an extra blade, a hammer, and 4-mil polyethylene film (also any necessary nails, wire, etc.); a homemade shelter-ventilating pump (a KAP); large containers for water; a plastic bottle of sodium hypochlorite bleach; one or two KFMs and the knowledge to operate them; at least a 2-week supply of compact, nonperishable food; an efficient portable stove; wooden matches in a waterproof container; essential containers and utensils for storing, transporting, and cooking food; a hose-vented 5-gallon can, with heavy plastic bags for liners, for use as a toilet; tampons; insect screen and fly bait; any special medications needed by family members; pure potassium iodide, a 2-oz bottle, and a medicine dropper; a first-aid kit and a tube of antibiotic ointment; long-burning candles (with small wicks) sufficient for at least 14 nights; an oil lamp; a flashlight and extra batteries; and a transistor radio with extra batteries and a metal box to protect it from electromagnetic pulse.
Inhabitants should have water on hand, 1-2 gallons per person per day. Water stored in bulk containers requires less space than water stored in smaller bottles.
Kearny Fallout Meter.
Commercially made Geiger counters are expensive and require frequent calibration. It is possible to construct an electrometer-type radiation meter called the Kearny Fallout Meter, which does not require batteries or professional calibration, from properly-scaled plans with just a coffee can or pail, gypsum board, monofilament fishing line, and aluminum foil. Plans are freely available in the public domain in the reference "Nuclear War Survival Skills" by Cresson Kearny.
Use.
Inhabitants should plan to remain sheltered for at least two weeks (with an hour out at the end of the first week – see Swiss Civil Defense guidelines (which was once part of Swiss Zivilschutz)), then work outside for gradually increasing amounts of time, to four hours a day at three weeks. The normal work is to sweep or wash fallout into shallow trenches to decontaminate the area. They should sleep in a shelter for several months. Evacuation at three weeks is recommended by official authorities.
If available, inhabitants may take potassium iodide at the rate of 130 mg/day per adult (65 mg/day per child) as an additional measure to protect the thyroid gland from the uptake of dangerous radioactive iodine, a component of most fallout and reactor waste.
Different types of radiation emitted by fallout.
Alpha (α).
In the vast majority of accidents, and in all atomic bomb blasts, the threat due to beta and gamma emitters is greater than that posed by the alpha emitters in the fallout. Alpha particles are identical to a helium-4 nucleus (two protons and two neutrons), and travel at speeds in excess of 5% of the speed of light. Alpha particles have little penetrating power; most cannot penetrate through human skin. Avoiding direct exposure with fallout particles will prevent injury from alpha radiation.
Beta (β).
Beta radiation consists of particles (high-speed electrons) given off by some fallout. Most beta particles cannot penetrate more than about 10 feet (3 m) of air or about 1⁄8 inch (3 mm) of water, wood, or human body tissue; or a sheet of aluminum foil. Avoiding direct exposure with fallout particles will prevent most injuries from beta radiation.
The primary dangers associated with beta radiation are internal exposure from ingested fallout particles and beta burns from fallout particles no more than a few days old. Beta burns can result from contact with highly radioactive particles on bare skin; ordinary clothing separating fresh fallout particles from the skin can provide significant shielding.
Gamma (γ).
Gamma radiation penetrates further through matter than alpha or beta radiation. Most of the design of a typical fallout shelter is intended to protect against gamma rays. Gamma rays are better absorbed by materials with high atomic numbers and high density, although neither effect is important compared to the total mass per area in the path of the gamma ray. Thus, lead is only modestly better as a gamma shield than an equal mass of another shielding material such as aluminum, concrete, water or soil.
Some gamma radiation from fallout will penetrate into even the best shelters. However, the radiation dose received while inside a shelter can be significantly reduced with proper shielding. Ten halving thicknesses of a given material can reduce gamma exposure to less than 1⁄1000 of unshielded exposure.
Weapons versus nuclear accident fallout.
The bulk of the radioactivity in nuclear accident fallout is more long-lived than that in weapons fallout. A good table of the nuclides, such as that provided by the Korean Atomic Energy Research Institute, includes the fission yields of the different nuclides. From this data it is possible to calculate the isotopic mixture in the fallout (due to fission products in bomb fallout).
Other matters and simple improvements.
While a person's home may not be a purpose-made shelter, it could be thought of as one if measures are taken to improve the degree of fallout protection.
Measures to lower the beta dose.
The main threat of beta radiation exposure comes from "hot particles" in contact with or close to the skin of a person. Also, swallowed or inhaled hot particles could cause beta burns. As it is important to avoid bringing hot particles into the shelter, one option is to remove one's outer clothing, or follow other decontamination procedures, on entry. Fallout particles will cease to be radioactive enough to cause beta burns within a few days following a nuclear explosion. The danger of gamma radiation will persist for far longer than the threat of beta burns in areas with heavy fallout exposure.
Measures to lower the gamma dose rate.
The gamma dose rate due to the contamination brought into the shelter on the clothing of a person is likely to be small (by wartime standards) compared to gamma radiation that penetrates through the walls of the shelter. The following measures can be taken to reduce the amount of gamma radiation entering the shelter:
Fallout shelters in popular culture.
Fallout shelters feature prominently in the Robert A. Heinlein novel "Farnham's Freehold" (Heinlein built a fairly extensive shelter near his home in Colorado Springs in 1963), "Pulling Through" by Dean Ing, "A Canticle for Leibowitz" by Walter M. Miller and "Earth" by David Brin.
The "Twilight Zone" episode "The Shelter", from a Rod Serling script, deals with the consequences of actually using a shelter.
In the "Only Fools and Horses" episode "The Russians are Coming", Derek Trotter buys a lead fallout shelter, then decides to construct it in fear of an impending nuclear war caused by the Soviet Union (who were still active during the episode's creation).
"Happy Days" dealt with the topic in a humorous but straightforward way, as Howard Cunningham staked out part of his backyard for a family shelter in "Be the First on Your Block". Visiting friends objected to being included out from a shelter drill, leading the Cunninghams to rethink the whole idea.
The 1982 album "The Nightfly" by Donald Fagen features a song, 'New Frontier', about an early-1960s teenager enticing his girlfriend into spending a romantic weekend with him in his family's backyard fallout shelter.
Fallout shelter signs can be seen in the background in several scenes of "AfterMASH".
In 1999 the film "Blast from the Past" was released. It is a romantic comedy film about a nuclear physicist, his wife, and son that enter a well-equipped, spacious fallout shelter during the 1962 Cuban Missile Crisis. They do not emerge until 35 years later, in 1997. The film shows their reaction to contemporary society.
"Daria" included a fallout shelter story, in the episode "Legends of the Mall": Lawndale's infamous House of Bad Grades earned its name during the Cold War era, when a college coed hopeful became trapped in the forgotten shelter behind her family's house, and thus could never leave town. Her vengeful spirit kept future occupants of the house stuck in Lawndale, even after they moved.
In book 11 of the "Cirque du Freak" book series, Darren and Harkat must go into an alternate world. They then find a fallout shelter with post cards on the refrigerator from the late 1940s and realized that they had gone forward in time.
The "Fallout" series of computer games depicts the remains of human civilization after an immensely destructive nuclear war; the United States of America had built underground vaults that were advertised to protect the general population against a nuclear attack, but were, in fact, grand social experiments that did little to protect their inhabitants.
"Paranoia", a role-playing game, takes place in a form of fallout shelter, which has become ruled by an insane computer.
The "Metro 2033" book series by Russian author Dmitry Glukhovsky depicts survivors' life in the subway systems below Moscow and Saint-Petersburg after a nuclear exchange between the Russian Federation and the United States of America.
Cormac McCarthy's book "The Road" and the accompanying movie has its main characters finding a shelter (bomb or fallout) with uneaten rations.
Fallout shelters are often featured on the reality television show "Doomsday Preppers".

</doc>
<doc id="11494" url="http://en.wikipedia.org/wiki?curid=11494" title="History of the Federated States of Micronesia">
History of the Federated States of Micronesia

The Federated States of Micronesia are located on the Caroline Islands in the western Pacific Ocean. The history of the modern Federated States of Micronesia is one of settlement by Micronesians; colonization by Spain, Germany, and Japan; United Nations trusteeship under United States-administered Trust Territory of the Pacific Islands; and gradual independence beginning with the ratification of a sovereign constitution in 1979.
Pre-colonial history.
The ancestors of the Micronesians settled there over 4,000 years ago. A decentralized chieftain-based system eventually evolved into a more centralized economic and religious Micronesian Empire centered on Yap and Pohnpei.
Pohnpei.
On Pohnpei, pre-colonial history is divided into three eras: "Mwehin Kawa" or "Mwehin Aramas" (Period of Building, or Period of Peopling, before ca. 1100); "Mwehin Sau Deleur" (Period of the Lord of Deleur, ca. 1100 to ca. 1628); and "Mwehin Nahnmwarki" (Period of the Nahnmwarki, ca. 1628 to ca. 1885). Pohnpeian legend recounts that the Saudeleur rulers, the first to bring government to Pohnpei, were of foreign origin. The Saudeleur centralized form of absolute rule is characterized in Pohnpeian legend as becoming increasingly oppressive over several generations. Arbitrary and onerous demands, as well as a reputation for offending Pohnpeian deities, sowed resentment among Pohnpeians. The Saudeleur Dynasty ended with the invasion of Isokelekel, another semi-mythical foreigner, who replaced the Saudeleur rule with the more decentralized "nahnmwarki" system in existence today. Isokelekel is regarded as the creator of the modern Pohnpeian "nahnmwarki" social system and the father of the Pompeian people.
Nan Madol.
Nan Madol offshore of Temwen Island near Pohnpei, consists of a series of small artificial islands linked by a network of canals, and is often called the "Venice of the Pacific". It is located near the island of Pohnpei and was the ceremonial and political seat of the Saudeleur Dynasty that united Pohnpei's estimated 25,000 people until its centralized system collapsed amid the invasion of Isokelekel. Isokelekel and his descendants initially occupied the stone city, but later abandoned it.
European colonization.
European explorers - first the Portuguese in search of the Spice Islands (Indonesia) and then the Spanish - reached the Carolines in the 16th century, with the Spanish establishing sovereignty.
Spain sold the islands to Germany in 1899 under the terms of the German–Spanish Treaty of that year.
Yap was a major German naval communications center before the First World War and an important international hub for cable telegraphy. It was occupied by Japanese troops in September, 1914, and passed to the Japanese Empire under the Versailles Treaty in 1919 as a mandated territory under League of Nations supervision. US commercial rights on the island were secured by a special US-Japanese treaty to that effect, concluded on February 11, 1922.
Empire of Japan.
During World War I, many of the Germany possessions in the Pacific were conquered by Japan, who fought on the side of the Allies of World War I and was active in the Asian and Pacific theatre of World War I.
The Empire of Japan administrated the islands from 1920 under the South Pacific Mandate granted by the League of Nations. During this period, the Japanese population grew to over 100,000 throughout Micronesia, while the indigenous population was about 40,000. Sugar cane, mining, fishing and tropical agriculture became the major industries.
In World War II, Japanese-held Yap was one of the islands bypassed in the U.S. "island-hopping" strategy, although it was regularly bombed by U.S. ships and aircraft, and Yap-based Japanese bombers did some damage in return. The Japanese garrison comprised 4,423 Imperial Japanese Army men under the command of Colonel Daihachi Itoh and 1,494 Imperial Japanese Navy men. A significant portion of the Japanese fleet was based in Truk Lagoon. In February 1944, Operation Hailstone, one of the most important naval battles of the war, took place at Truk, in which many Japanese support vessels and aircraft were destroyed.
World War II brought an abrupt end to the relative prosperity experienced during Japanese civil administration. By the War's conclusion most infrastructure had been laid waste by bombing, and the islands and people had been exploited by the Japanese military to the point of impoverishment.
Trusteeship.
The United Nations created the Trust Territory of the Pacific Islands (TTPI) in 1947. Pohnpei (then including Kusaie), Truk, Yap, Palau, the Marshall Islands and the Northern Mariana Islands, together constituted the TTPI. The United States accepted the role of Trustee of this, the only United Nations Trusteeship to be designated as a "Security Trusteeship", whose ultimate disposition was to be determined by the UN Security Council. As Trustee the US was to "promote the economic advancement and self-sufficiency of the inhabitants."
Independence.
On May 10, 1979, four of the Trust Territory districts ratified the Constitution of the Federated States of Micronesia. The neighboring trust districts of Palau, the Marshall Islands, and the Northern Mariana Islands chose not to participate. The Honorable Tosiwo Nakayama, the former President of the Congress of Micronesia, became the first President of the FSM and formed his Cabinet. The FSM signed a Compact of Free Association with the U.S., which entered into force on November 3, 1986, marking Micronesia's emergence from trusteeship to independence. Under the Compact, the U.S. has full authority and responsibility for the defense of the FSM. This security relationship can be changed or terminated by mutual agreement. The Compact provides U.S. grant funds and federal program assistance to the FSM. Amended financial assistance provisions came on-line in FY 2004. The basic relationship of free association continues indefinitely.
Trusteeship of the islands ended under United Nations Security Council Resolution 683, passed on December 22, 1990. The Compact was renewed in 2004.

</doc>
<doc id="11495" url="http://en.wikipedia.org/wiki?curid=11495" title="Politics of the Federated States of Micronesia">
Politics of the Federated States of Micronesia

The politics of the Federated States of Micronesia (FSM) takes place in a framework of a federal representative democratic republic. The President of the Federated States of Micronesia is both head of state and head of government. Executive power is exercised by the president and his cabinet, while legislative power is vested in both the president and the Congress. The judiciary is independent of the executive and the legislature.
The internal workings of the Micronesia are governed by the 1979 constitution, which guarantees fundamental human rights and establishes a separation of governmental powers. The Federation is in free association with the United States; the Compact of Free Association entered into force 3 November 1986.
Executive branch.
The president and the vice president are elected by Congress from among the four senators-at-large for four-year terms. The president is both the chief of state and head of government. Their congressional seats are then filled by special elections. The president and vice president are supported by an appointed cabinet.
Legislative branch.
The Congress has fourteen non-partisan members, ten members elected for a two-year term in single-seat constituencies and four members elected for a four-year term, one from every state 'at large'.
Political parties and elections.
A head of state (the President) and a legislature are elected on a national level. As far as available, at the last elections, 8 March 2005, only non-partisans have been elected. The president is elected for a four-year term by Congress. There are no political parties in Micronesia, though they are not banned. Political allegiances depend mainly on family and island-related factors.
Judicial branch.
The judiciary is headed by the Supreme Court, which is divided into trial and appellate divisions. The president appoints judges with the advice and consent of the Congress. Andon Amaraich was Chief Justice of the Supreme Court until his death in January 2010. He was succeeded by Martin G. Yinug.
Administrative divisions.
The FSM is divided in four states: Chuuk (Truk), Kosrae, Pohnpei, and Yap. Each has its own constitution, elected legislature, and governor. The state governments maintain considerable power, particularly regarding the implementation of budgetary policies.
International organization participation.
AsDB, ESCAP, G-77, IBRD, ICAO, IDA, IFC, IMF, Intelsat, IOC, ITU, OPCW, PIF, Sparteca, SPC, UN, UNCTAD, WHO, WMO
External links.
Government

</doc>
<doc id="11496" url="http://en.wikipedia.org/wiki?curid=11496" title="Geography of the Federated States of Micronesia">
Geography of the Federated States of Micronesia

Geography of the Federated States of Micronesia (FSM), a country located in the western Pacific Ocean, and in the Micronesia cultural and ecological sub-region of Oceania.
Geography.
The country consists of 607 islands extending 1800 mi across the Caroline Islands Archipelago. They are east of the Philippine Islands, and north of the island of New Guinea. The federal capital is Palikir, on Pohnpei island.
The 607 islands are grouped into four states, and east to west are: 
Separated from the main islands in southern Pohnpei State are the two islands of Nukuoro and Kapingamarangi. They are geographically part of the Micronesia region, but are linguistically and culturally part of the Polynesia region. The indigenous languages spoken on these two islands are in the Samoic family of Polynesian languages.
Location.
The Federated States of Micronesia are an island group in the Caroline Islands Archipelago of the western Pacific Ocean, in the Micronesia sub-region of Oceania.
Located about three-quarters of the way from Hawaii to Indonesia at Geographic coordinates: 
Map references are Oceania and Micronesia.
Dimensions.
Area:
The country's total area is four times the size of Washington, D.C. in the U.S.
Coastline:
The combined coastlines of the country's 607 islands equal 6112 km.
Maritime claims:
Terrain.
The country's 607 islands vary from high mountainous ones to low coral atolls. Geologically, there are volcanic rock outcroppings on the islands of Pohnpei, Kosrae, and Truk.
Extreme points.
The extreme points of the Federated States of Micronesia, the landforms that are farther north, south, east or west — than any other location in the country.
Environment.
Environment—current issues:
Overfishing, climate change, land and water pollution.
Environment—international agreements:
Land use.
Products:
Tropical woods and lumber, marine products, deep-seabed minerals, surface mined phosphate.
Climate.
Tropical; heavy year-round rainfall, especially in the eastern islands; l
The Federated States of Micronesia enjoys a tropical climate, with quite even, warm temperatures throughout the year.
Precipitation is generally plentiful, with heavy year-round rainfall. Pohnpei reputedly is one of the wettest places on earth, with up to 330 inches (8.4 m) of rain per year. Nevertheless, drought conditions do occur periodically throughout FSM, especially when the El Niño condition moves into the Western Pacific, when groundwater supplies can dwindle to emergency proportions.
Natural hazards.
Tropical typhoons are an annual threat, from June to December. The country is located on southern edge of the typhoon belt, with occasionally severe damage, particularly to the low-lying atolls.
Tsunamis and rising sea levels are other natural threats.

</doc>
<doc id="11497" url="http://en.wikipedia.org/wiki?curid=11497" title="Demographics of the Federated States of Micronesia">
Demographics of the Federated States of Micronesia

This article is about the demographic features of the population of the Federated States of Micronesia, including population density, ethnicity, education level, health of the populous, economic status, religious affiliations and other aspects of the population.
The Demographics of the Federated States of Micronesia refers to the population characteristics of people who inhabit the Federated States of Micronesia. The indigenous population of the Federated States of Micronesia, which is predominantly Micronesian, consists of various ethnolinguistic groups. English has become the common language. Population growth remains high at more than 3%, but is ameliorated somewhat by net emigration. 
The island of Pohnpei is genetically notable for the prevalence of the extreme form of color blindness known as maskun.
CIA World Factbook demographic statistics.
The following demographic statistics are from the CIA World Factbook, unless otherwise indicated.
Population:
133,144 (July 2000 est.)
Age structure:
<br>"0-14 years:"
NA
<br>"15-64 years:"
NA
<br>"65 years and over:"
NA
Population growth rate:
-0.11% (2006 est.)
Birth rate:
27.09 births/1,000 population (2000 est.)
Death rate:
5.95 deaths/1,000 population (2000 est.)
Net migration rate:
11.65 migrant(s)/1,000 population (2000 est.)
Infant mortality rate:
33.48 deaths/1,000 live births (2000 est.)
Life expectancy at birth:
<br>"total population:"
68.63 years
<br>"male:"
66.67 years
<br>"female:"
70.62 years (2000 est.)
Total fertility rate:
3.83 children born/woman (2000 est.)
Nationality:
<br>"noun:"
Micronesian(s)
<br>"adjective:"
Micronesian; Kosrae(s), Pohnpeian(s), Trukese, Yapese
Ethnic groups:
Chuukese 48.8%, Pohnpeian 24.2%, Yapese 9.7%, Kosraean 6.2%, other 11.1%
Religions:
Roman Catholic 50%, Protestant 47%, other and none 3% (see Religion in the Federated States of Micronesia)
Languages:
English (official and common language), Trukese, Pohnpeian, Yapese, Kosraean
Literacy:
<br>"definition:"
age 15 and over can read and write
<br>"total population:"
89%
<br>"male:"
91%
<br>"female:"
88% (1980 est.)

</doc>
<doc id="11498" url="http://en.wikipedia.org/wiki?curid=11498" title="Economy of the Federated States of Micronesia">
Economy of the Federated States of Micronesia

The economic activity of the Federated States of Micronesia consists primarily of subsistence agriculture and fishing. The islands have few mineral deposits worth exploiting, except for high-grade phosphate. The potential for a tourist industry exists, but the remoteness of the location and a lack of adequate facilities hinder development. Financial assistance from the US is the primary source of revenue, with the US pledged to spend $1.3 billion in the islands in 1986-2001. Geographical isolation and a poorly developed infrastructure are major impediments to long-term growth.
Under the terms of the Compact of Free Association, the United States provided FSM with around $2 billion in grants and services from 1986 to 2001. The Compact's financial terms are being renegotiated for an extension period. In 2001 the U.S. provided more than $84 million in Compact grants—an amount equivalent to over one-third of FSM's GDP—plus more than $20 million through other federal programs. Total official development assistance from all sources was more than $100 million in 2001, with nearly 90% of that total coming from the U.S.
The FSM public sector plays a central role in the economy as the administrator of the Compact money. The national and state-level governments employ over one-half of the country's workers and provide services accounting for more than 40%of GDP. Faced with the potential decrease or cessation of some of the assistance programs upon the Compact's financial provisions' expiry in 2001, the Government of the FSM in 1996 began to implement a program of economic reforms designed to reduce the role of the public sector in the economy. In addition, the advent of music startups using .fm domain names has provided a new stream of revenue to the government.
Industries.
The fishing industry is highly important. Foreign commercial fishing fleets pay over $20 million annually for the right to operate in FSM territorial waters. These licensing fees account for nearly 30% of domestic budgetary revenue. Additionally, exports of marine products, mainly reexports of fish to Japan, account for nearly 85% of export revenue.
The tourist industry is present but has been hampered by a lack of infrastructure. Visitor attractions include scuba diving in each state, World War II battle sites, and the ancient ruined city of Nan Madol on Pohnpei. Some 15,000 tourists visit the islands each year. The Asian Development Bank has identified tourism as one of FSM's highest potential growth industries.
Farming is mainly subsistence, and its importance is declining. The principal crops are coconuts, bananas, betel nuts, cassava, and sweet potatoes. Less than 10% of the formal labor force and less than 7% of export revenue come from the agriculture sector. Manufacturing activity is modest, consisting mainly of a garment factory in Yap and production of buttons from trochus shells.
Taxation and trade.
The large inflow of official assistance to FSM allows it to run a substantial trade deficit and to have a much lighter tax burden than other states in the region (11% of GDP in FSM compared to 18%-25% elsewhere). The government also borrowed against future Compact disbursements in the early 1990s, yielding an external debt of $111 million in 1997 (over 50% of GDP).
There are no patent laws in Micronesia.
Statistics.
GDP:
purchasing power parity - $277 million (2002 est.)
<br>"note:"
GDP is supplemented by grant aid, averaging perhaps $100 million annually
GDP - real growth rate:
1% (2002 est.)
GDP - per capita:
purchasing power parity - $3 900 (2002 est.)
GDP - composition by sector:
<br>"agriculture:"
47%
<br>"industry:"
10%
<br>"services:"
43% (2010 est.)
Population below poverty line:
22.3%
Household income or consumption by percentage share:
<br>"lowest 10%:"
NA%
<br>"highest 10%:"
NA%
Inflation rate (consumer prices):
2% (2012 est.)
Labor force:
37,410 (2000)
Labor force - by occupation:
two-thirds are government employees
Unemployment rate:
15% (2010 estimate)
Budget:
<br>"revenues:"
$157.5 million ($74 million less grants
<br>"expenditures:"
$134 million; including capital expenditures of $17.9 million (FY05 est.)
Industries:
tourism, construction, fish processing, craft items from shell, wood, and pearls
Industrial production growth rate:
NA%
Electricity - production:
261 million kWh (2010)
Electricity - consumption:
222 million kWh (2010)
Electricity - exports:
0 kWh (2010)
Electricity - imports:
0 kWh (2010)
Agriculture - products:
black pepper, tropical fruits and vegetables, coconuts, cassava (tapioca), sweet potatoes; pigs, chickens
Exports:
$123 million (f.o.b., 2000 est.)
Exports - commodities:
fish, garments, bananas, black pepper
Exports - partners:
Japan, United States, Guam, China (2010)
Imports:
$82.5 million f.o.b. (2010 est.)
Imports - commodities:
food, manufactured goods, machinery and equipment, beverages
Imports - partners:
US, Australia, Japan (2010)
Debt - external:
$44 million (2010 est.)
Economic aid - recipient:
$64 million (2010); note - under terms of the Compact of Free Association, the US will provide $1.3 billion in grant aid during the period 1986-2001
Currency:
1 United States dollar (US$) = 100 cents
Exchange rates:
US currency is used
Fiscal year:
1 October - 30 September
References.
 This article incorporates public domain material from websites or documents of the .

</doc>
<doc id="11499" url="http://en.wikipedia.org/wiki?curid=11499" title="Telecommunications in the Federated States of Micronesia">
Telecommunications in the Federated States of Micronesia

This article is about communications systems in the Federated States of Micronesia. 
In 2010, Pohnpei State was connected to the Internet using the HANTRU-1 undersea cable to provide high-speed bandwidth. Kosrae State, Chuuk State, and Yap State, were planned to be connected in a second phase.
Telephone.
Main lines in use:
8,000 (1995)
Mobile cellular:
NA
Telephone system:
<br>"domestic:"
islands interconnected by shortwave radiotelephone (used mostly for government purposes)
<br>"international:"
satellite earth stations - 4 Intelsat (Pacific Ocean)
Radio.
Broadcast stations:
AM 5, FM 1, shortwave 1 (2011)
Stations below are included in the total:
AM Radio stations:
FM Radio stations:
There is also a shortwave relay of 88.5 FM, V6MP.
Radios:
NA
Television.
Broadcast stations:
Several are available on cable (converted from ATSC to DVB-T): KHON-TV (Fox), KITV-TV (ABC), KHNL-TV (NBC) and KGMB-TV (CBS).
Televisions:
NA
Internet.
Internet Service Providers (ISPs):
1
Country code: FM

</doc>
<doc id="11501" url="http://en.wikipedia.org/wiki?curid=11501" title="Transport in the Federated States of Micronesia">
Transport in the Federated States of Micronesia

Railways:
0 km
Highways:
<br>"total:"
240 km
<br>"paved:"
42 km
<br>"unpaved:"
198 km (1996 est.)
Ports and harbours:
Colonia (Yap), Kolonia (Pohnpei), Lele, Moen
Merchant marine:
total: three ships (1000 GRT or over) 3,560 GRT/ tonnes deadweight (DWT) 
by type: cargo one, passenger/cargo two (2007) 
Airports:
Six (2007)
Airports - with paved runways:
<br>"total:"
Six
<br>"1,524 to 2,437 m:"
Four (Chuuk International Airport, Kosrae International Airport, Pohnpei International Airport and Yap International Airport)
<br>"914 to 1,523 m:"
Two (2007)

</doc>
<doc id="11503" url="http://en.wikipedia.org/wiki?curid=11503" title="Foreign relations of the Federated States of Micronesia">
Foreign relations of the Federated States of Micronesia

The government of the Federated States of Micronesia (FSM) conducts its own foreign relations.
Since independence in 1986, the FSM has established diplomatic relations with a number of nations, including most of its Pacific neighbors.
Regional relations.
Regional cooperation through various multilateral organizations is a key element in FSM's foreign policy. FSM is a full member of the Pacific Islands Forum, the South Pacific Applied Geoscience Commission, the Pacific Regional Environment Programme and the Secretariat of the Pacific Community. The country also is one of the eight signatories of the Nauru Agreement Concerning Cooperation In The Management Of Fisheries Of Common Interest which collectively controls 25-30% of the world's tuna supply and approximately 60% of the western and central Pacific tuna supply .
Bilateral relations.
FSM has established diplomatic relations with 65 states, the Holy See, the Sovereign Military Order of Malta and the European Union.
The FSM maintains permanent embassies in four nations: China, Fiji, Japan and the United States. The FSM also maintains a resident consulate in Hawaii and Guam. The FSM maintains non-resident embassies for four nations: Indonesia, Malaysia and Singapore (all in Japan) and Israel in Fiji. Four nations maintain permanent embassies in the FSM: Australia, China, Japan and the United States Additionally, 15 nations maintain non-resident embassies with the FSM. France and the United Kingdom have non-resident embassies for the FSM in Fiji. Canada, Italy and South Africa have non-resident embassies for the FSM in Australia. Indonesia has a non-resident embassy for the FSM in Japan. Chile has its non-resident embassies for the FSM in the United States. Croatia has its non-resident embassy for the FSM in Indonesia. Czech Republic, Finland, the Netherlands, Portugal, Spain, and Switzerland have non-resident embassies in the Philippines. New Zealand has its non-resident embassy for the FSM in Kiribati.
China.
The People's Republic of China has close relations with the FSM both in terms of trade and foreign aid. Chinese aid projects have included among others the Giant Clam Farm Project in Kosrae, the Pilot Farm Project in Madolenihmw, the construction of a gymnasium on Pohnpei (officially named the FSM-China Friendship Sports Center), donation of police vehicles for the Yap state police, a facility to house the FSM's Tuna Commission, an expansion of the Chuuk State Airport Terminal, a biogas project on Chuuk, the construction of the Pohnpei Administration Building, and the construction of Kosrae High School Project. 
China is the FSM's third largest trade partner (after the United States and Japan), a fact marked by the rapid increase in trade between the two nations. As the Chinese Ambassador to the FSM Zhang Weidong observed on the 20th anniversary of relations between the two countries, trade between China and the FSM had gone from "almost zero to $9.5 million in 2007."
Cuba.
Micronesia was one of ten Pacific countries to send a government member to the first Cuba-Pacific Islands ministerial meeting, held in Havana in September 2008. The aim of the meeting was to "strengthen cooperation" between Micronesia and Cuba, notably on addressing the impact of climate change.
India.
India and Micronesia have maintained diplomatic relations with each other since 1996. India has made 'Development assistance' to the country of about US $ 73,145 in 2009 for the purchase of machinery for the coconut industry. India has also made a grant of 3 ITEC scholarships in 2010-11. As per the Ministry of External Affairs of the Government of India, "Micronesia has been supportive of issues of importance to India, particularly Indian candidatures to international organizations and supported India’s candidature for the UNSC non-permanent seat in 2011-12. As per information available, there is one 
Indian family in Micronesia."
Israel.
The FSM is one of the most consistent supporters of Israel (along with the United States) in international affairs. Throughout the history of the United Nations General Assembly, it is claimed by some there has always been an "automatic majority" against Israel.
The United States has consistently opposed what it perceives as "unbalanced" "anti-Israel" resolutions and, in recent years, one other nation has joined Israel's defense — Micronesia. 
The foreign policy goals of the Federated States of Micronesia (FSM) are primarily linked to achieving economic development and protecting their vast marine environment. Israel was one of the first to welcome the FSM into the family of nations, even before the FSM became a member of the U.N. According to the FSM U.N. deputy ambassador, Micronesia has since sought close bilateral relations with Israel in areas such as agriculture, technical training and health care training.
Israel has assisted the FSM in its early development. As one Micronesian diplomat said, "We need Israeli expertise, so I don't see a change in our policy anytime soon."
Kosovo.
The Federated States of Micronesia officially recognised the independence of the Republic of Kosovo on 5 December 2008. Kosovo and Micronesia established diplomatic relations on 19 September 2013.
United States.
The Governments of the FSM and the U.S. signed the final version of the Compact of Free Association on October 1, 1982.
The Compact went into effect on November 3, 1986, and the FSM became a sovereign nation in free association with the United States.
Under the Compact, the U.S. has full authority and responsibility for the defense of the FSM.
This security relationship can be changed or terminated by mutual agreement.
The Compact provides U.S. grant funds and federal program assistance to the FSM.
The basic relationship of free association continues indefinitely, but certain economic and defense provisions of the Compact expire in 2001, subject to renegotiation.
Negotiations on extending the Compact began in November 1999.
The United States is the FSM's largest trading partner. The relationship is heavily imbalanced. Of the FSM-US total balance of trade in goods in 2010 of US $38.3, the FSM imported $42.5 million in goods from the United States while exporting only US $4.2 million to the United States. (see Economy of the Federated States of Micronesia).
Membership in international organizations.
The Federated States of Micronesia was admitted to the United Nations on 17 September 1991. Additionally outside the region, FSM is a member or participant of the ACP (Lomé Convention), the Alliance of Small Island States, the Asian Development Bank, the Economic and Social Commission for Asia and the Pacific (ESCAP), the Food and Agriculture Organization (FAO), the G-77, the International Bank for Reconstruction and Development, the International Civil Aviation Organization, the International Red Cross and Red Crescent Movement, the International Development Association, the International Finance Corporation, the IMF, the International Olympic Committee, the ITU, the NAM and the World Meteorological Organization.
The FSM is notably one of four UN-recognized nations with a sea border that is not a member of the International Maritime Organization (the others are Naura, Niue and Palau). Similarly, the FSM is one of only six UN members that is not a member of the Universal Postal Union.
Finally, as with many other nations in Oceania, the FSM is not a member of Interpol or of the International Hydrographic Organization.

</doc>
<doc id="11504" url="http://en.wikipedia.org/wiki?curid=11504" title="Fandom">
Fandom

Fandom (a portmanteau consisting of "fan" [fanatic] plus the suffix "-dom", as in kingdom) is a term used to refer to a subculture composed of fans characterized by a feeling of empathy and camaraderie with others who share a common interest. Fans typically are interested in even minor details of the object(s) of their fandom and spend a significant portion of their time and energy involved with their interest, often as a part of a social network with particular practices (a fandom); this is what differentiates "fannish" (fandom-affiliated) fans from those with only a casual interest.
A fandom can grow up centered on any area of human interest or activity. The subject of fan interest can be narrowly defined, focused on something like an individual celebrity, or more widely defined, encompassing entire hobbies, genres or fashions. While it is now used to apply to groups of people fascinated with any subject, the term has its roots in those with an enthusiastic appreciation for sports. Merriam-Webster's dictionary traces the usage of the term back as far as 1903.
Fandom as a term can also be used in a broad sense to refer to the interconnected social networks of individual fandoms, many of which overlap.
Organized subculture.
Fans of the literary detective Sherlock Holmes are widely considered to have comprised the first modern fandom, holding public demonstrations of mourning after Holmes was "killed off" in 1893, and creating some of the first fan fiction as early as about 1897 to 1902. Outside the scope of media, railway enthusiasts are another early fandom with its roots in the late 19th century that began to gain in popularity and increasingly organize in the first decades of the early 20th century.
A wide variety of Western modern organized fannish subcultures originated with science fiction fandom, the community of fans of the science fiction and fantasy genres. Science fiction fandom dates back to the 1930s and maintains organized clubs and associations in many cities around the world. Fans have held the annual World Science Fiction Convention since 1939, along with many other events each year, and has created its own jargon, sometimes called "fanspeak". In addition, the Society for Creative Anachronism, a medievalist re-creation group, has its roots in science fiction fandom. It was founded by members thereof; and many science fiction/fantasy author/fans such as Marion Zimmer Bradley, Poul Anderson, Randall Garrett, David D. Friedman and Robert Asprin, and other members of SF fandom, are or were members of the organization.
Media fandom split from science fiction fandom in the early 1970s with a focus on relationships between characters within TV and movie media franchises, such as "Star Trek" and "The Man from U.N.C.L.E.". Fans of these franchises generated creative products like fan art and fan fiction at a time when typical science fiction fandom was focused on critical discussions. The MediaWest convention provided a video room and was instrumental in the emergence of fan vids, or analytic music videos based on a source, in the late 1970s. By the mid-1970s, it was possible to meet fans at science fiction conventions who did not read science fiction, but only viewed it on film or TV.
Anime and manga fandom began in the 1970s in Japan. In America, the fandom also began as an offshoot of science fiction fandom, with fans bringing imported copies of Japanese manga to conventions. Before anime began to be licensed in the U.S., fans who wanted to get a hold of anime would leak copies of anime movies and subtitle them to exchange with friends in the community, thus marking the start of fansubs.
Furry fandom refers to the fandom for fictional anthropomorphic animal characters with human personalities and characteristics. The concept of "furry" originated at a science fiction convention in 1980, when a drawing of a character from Steve Gallacci's "Albedo Anthropomorphics" initiated a discussion of anthropomorphic characters in science fiction novels, which in turn initiated a discussion group that met at science fiction and comics conventions.
The literature fandom, which is a fandom of people who are passionate about books. Novels, poetry, etc. The literature fandom is one of the oldest fandoms as books have existed for hundreds of years, and have carried fans with them.Because of the number of published authors out there, there is a large number of sub fandoms found within the bigger and more general literary fandom. Significant fandoms of the 21st century include: The Harry Potter series,The Twilight Saga, The Hunger Games Trilogy, The Divergent series, The Maze Runner series, novels by the american writer John Green, which include Paper Towns, Looking For Alaska, An Abundance of Katherines, The extremely popular The Fault In Our stars, and two co-written novels with authors: David Levithan, Maureen Johnson and Lauren Myracle, among many other books. This fandom creates a majority of it's fanbase on social media such as Instagram and Twitter, where owners of the accounts post pictures, photo edits, tweets, news, etc., related to the specific literary fandom.There are many conventions and activities relates to literature that fans can attend such as: Geekycon, BookCon, Yall fest, and many others as well as author signings, concerts for bands who sing songs relates to literature, and meet-ups with other fans. This fandom can sometimes be expanded into the movie fandom, when books are adapted into a film.
In addition, a new YouTube category called BookTube was created when fans started uploading videos talking about their favorite books, doing reviews, books hauls, etc. Some booktube channels like polandbananasBOOKS, katytastic, and abookutopia have reached more than 100,000 subscribers.
Additional significant types of fandoms include comics fandom, sports fandom, music fandom, pulp magazine fandom, soap opera fandom, celebrity fandom, and video game fandom.
Fan activities.
Members of a fandom associate with one another, often attending fan conventions and publishing and exchanging fanzines and newsletters. Amateur press associations are another form of fan publication and networking. Originally using print-based media, these sub-cultures have migrated much of their communications and interaction onto the Internet, which they also use for the purpose of archiving detailed information pertinent to their given fanbase. Often, fans congregate on forums and discussion boards to share their love for and criticism of a specific work. This congregation can lead to a high level of organization and community within the fandom, as well as infighting. Although there is some level of hierarchy among most of the discussion boards in which certain contributors are valued more highly than others, newcomers are most often welcomed into the fold. Most importantly, these sorts of discussion boards can have an effect on the media itself as was the case in the television show "Glee". Trends on the discussion boards have been known to influence the writers and producers of the show. The media fandom for the TV series "Firefly" was able to generate enough corporate interest to create a movie after the series was canceled.
Some fans write fan fiction ("fanfic"), stories based on the universe and characters of their chosen fandom. This fiction can take the form of video-making as well as writing. Fan fiction may or may not tie in with the story's canon; sometimes the fans use the story's characters in different situations that do not relate to the plot line at all.
Especially at events, fans may also partake in "cosplay" (a portmanteau between "cos"tume and "play") – the creation and wearing of costumes designed in the likeness of characters from a source work – which can also be combined with role-playing, reenacting scenes or inventing likely behavior inspired by their chosen sources. A headcanon is another kind of fan fiction, but is much shorter in length.
Others create fan vids, or analytical music videos focusing on the source fandom, and yet others create fan art. Such activities are sometimes known as "fan labor" or "fanac", an abbreviated form of the phrase "fan activity". The advent of the Internet has significantly facilitated fan association and activities. Activities that have been aided by the Internet includes the creation of fan "shrines" dedicated to favorite characters, computer screen wallpapers, avatars. Furthermore, the advent of the Internet has resulted in the creation of online fan networks who help facilitate the exchange of fanworks.
Some fans create pictures known as "edits", which consist of pictures or photos with their chosen fandom characters in different scenarios. These edits are often shared on social media networks such as Instagram, Tumblr, or Pinterest. In some edits, one may see content relating to several different fandoms.
Fandom is sometimes caricatured as religious faith, as the interest of fans sometimes grows to dominate their lifestyle, and fans are often very obstinate in professing (and refusing to change) their beliefs about their fandom. However, society at large does not treat fandom with the same weight as organized religion.
There are also active fan organizations that participate in philanthropy and create a positive social impact. For example, the Harry Potter Alliance is a civic organization with a strong online component which runs campaigns around human rights issues, often in partnership with other advocacy and nonprofit groups; its membership skews college age and above. Nerdfighters, another fandom formed around a YouTube vlog channel, are mainly high school students united by a common goal of "decreasing world suck".
In film.
Feature-length documentaries about fandom (some more respectful of the subjects than others) include "Trekkies", "", , and "Done the Impossible". "Fandom" is also the name of a documentary / mockumentary about a fan obsessed with Natalie Portman.
In books.
"Fangirl" is a novel written by Rainbow Rowell about a college student who is a fan of a book series called Simon Snow, which is written by a fictional author named Gemma T. Leslie.
Relationship with the industry.
The film and television entertainment industry refers to the totality of fans devoted to a particular area of interest, whether organized or not, as the "fanbase".
Media fans, have, on occasion, organized on behalf of canceled television series, with notable success in cases such as ' in 1968, "Cagney & Lacey" in 1983, ', in 1995, "Roswell" in 2000 and 2001 (it was canceled with finality at the end of the 2002 season), "Farscape" in 2002, "Firefly" in 2002, and "Jericho" in 2007. (In the case of "Firefly" the result was the movie "Serenity", not another season.) It was likewise the fans who facilitated the push to create a "Veronica Mars" film through a Kickstarter campaign.
Such outcries, even when unsuccessful, suggests a growing self-consciousness on the part of entertainment consumers, who appear increasingly likely to attempt to assert their power as a bloc. Fan activism in support of the 2007 Writers Guild of America strike through Fans4Writers appears to be an extension of this trend.
Gaming fans have also recently made a big impact on content developers. In March 2012, when the most recent installment of Bioware's "Mass Effect" series was released, the fandom was so displeased with the game's available endings that they demanded there be some kind of change. Buckling under the pressure of this heated demand, BioWare released a DLC (downloadable content) packet on June 26, 2012 in hopes of reconciling the game's endings and soothing the fandom's aggression. This simple change to the game's ending was a huge step for fandoms because the entertainment industry has never before taken such large steps to comply with a fanbase's desires.
In science fiction, a large number of the practitioners and other professionals in the field, not only writers but editors and publishers, traditionally have themselves come from and participate in science fiction fandom, from Ray Bradbury and Harlan Ellison to Patrick Nielsen Hayden and Toni Weisskopf; the "fan" "vs." "pro" dualism does not exist in SF the way it does in the media entertainment industry.

</doc>
<doc id="11507" url="http://en.wikipedia.org/wiki?curid=11507" title="Fort Collins, Colorado">
Fort Collins, Colorado

The City of Fort Collins is the Home Rule Municipality that is the county seat and the most populous municipality of Larimer County, Colorado, United States. Situated on the Cache La Poudre River along the Colorado Front Range, Fort Collins is located 65 mi north of the Colorado State Capitol in Denver. With a 2012 estimated population of 148,612, it is the fourth most populous city in Colorado after Denver, Colorado Springs, and Aurora. Fort Collins is a midsize college city, home to Colorado State University. It was named "Money" magazine's Best Place to Live in the U.S. in 2006, No. 2 in 2008, and No. 6 in 2010.
It is also known as one of the towns that inspired the design of Main Street, U.S.A. inside the main entrance of the many 'Disneyland'-style parks run by The Walt Disney Company around the world.
History.
Fort Collins was founded as a military outpost of the United States Army in 1864. It succeeded a previous encampment, known as Camp Collins, on the Cache La Poudre River, near what is known today as Laporte. Camp Collins was erected during the Indian wars of the mid-1860s to protect the Overland mail route that had been recently relocated through the region. Travelers crossing the county on the Overland Trail would camp there, but a flood destroyed the camp in June 1864. Afterward, the commander of the fort wrote to the commandant of Fort Laramie in southeast Wyoming, Colonel William O. Collins, suggesting that a site several miles farther down the river would make a good location for the fort. The post was manned originally by two companies of the 11th Ohio Volunteer Cavalry and never had walls.
Settlers began arriving in the vicinity of the fort nearly immediately. The fort was decommissioned in 1867. The original fort site is now adjacent to the present historic "Old Town" portion of the city. The first school and church opened in 1866, and the town was platted in 1867. The civilian population of Fort Collins, led by local businessman Joseph Mason, led an effort to relocate the county seat to Fort Collins from LaPorte, and they were successful in 1868.
The city's first population boom came in 1872, with the establishment of an agricultural colony. Hundreds of settlers arrived, developing lots just south of the original Old Town. Tension between new settlers and earlier inhabitants led to political divisions in the new town, which was incorporated in 1873. Although the Colorado Agricultural College was founded in 1870, the first classes were held in 1879.
The 1880s saw the construction of a number of elegant homes and commercial buildings and the growth of a distinctive identity for Fort Collins. Stone quarrying, sugar-beet farming, and the slaughter of sheep were among the area's earliest industries. Beet tops, an industry supported by the College and its associated agricultural experiment station, proved to be an excellent and abundant food for local sheep, and by the early 1900s the area was being referred to as the "Lamb feeding capital of the world." In 1901 the Great Western sugar processing plant was built in the neighboring city of Loveland.
Although the city was affected by the Great Depression and simultaneous drought, it nevertheless experienced slow and steady growth throughout the early part of the twentieth century. During the decade following World War II, the population doubled and an era of economic prosperity occurred. Old buildings were razed to make way for new, modern structures. Along with revitalization came many changes, including the closing of the Great Western sugar factory in 1955, and a new city charter, adopting a council-manager form of government in 1954. Similarly, Colorado State University's enrollment doubled during the 1960s, making it the city's primary economic force by the end of the century.
Fort Collins gained a reputation as a very conservative city in the twentieth century, with a prohibition of alcoholic beverages, a contentious political issue in the town's early decades, being retained from the late 1890s until student activism helped bring it to an end in 1969. During that same period, civil rights activism and anti-war disturbances heightened tensions in the city, including the burning of several buildings on the CSU campus.
During the late 20th century, Fort Collins expanded rapidly to the south, adding new development, including several regional malls. Management of city growth patterns became a political priority during the 1980s, as well as the revitalization of Fort Collins' Old Town with the creation of a Downtown Development Authority. In late July 1997, the city experienced after and during a 31-hour period when 10 - of rain fell. The rainfall was the heaviest on record for an urban area of Colorado. Five people were killed and $5 million in damages were dealt to the city. The waters flooded Colorado State University's library and brought about $140 million in damages to the institution.
In 2006, "Money" ranked Fort Collins as the best place to live in America, proclaiming that "great schools, low crime, good jobs in a high-tech economy and a fantastic outdoor life make Fort Collins No. 1." Fort Collins continues to grow in population at a measured pace, with competition from other development in northern Colorado, debate over future growth patterns and town and gown relations emerging as dominant local issues in the early 21st century. In 2012, the city was listed among the 10 best places to retire in the U.S. by CBS Money Watch.
In 2011, Allstate Insurance listed Fort Collins as "America's Safest Driving City" in their annual "Best Drivers Report". Drivers in Fort Collins average 14 years between collisions and are 26.8% less likely to be in a collision compared to the national average.
Fort Collins is also known along with Marceline, Missouri as one of the towns that inspired the design of Main Street, U.S.A. inside the main entrance of the many 'Disneyland'-style parks run by The Walt Disney Company around the world. Harper Goff, who worked on Main Street, U.S.A. with Walt, showed Walt some photos of his childhood home of Fort Collins, Colorado. Walt liked the look, and so many of the features of the town were incorporated into Main Street, U.S.A.
For more information on local history see the Fort Collins Museum and Discovery Science Center's local historical archives.
Geography and climate.
Fort Collins is located at (40.559238, −105.078302). The city is situated at the base of the Rocky Mountain foothills of the northern Front Range approximately 60 mi north of Denver, Colorado and 45 mi south of Cheyenne, Wyoming. Elevation is 4982 ft above sea level. Geographic landmarks include Horsetooth Reservoir and Horsetooth Mountain—so named because of a tooth-shaped granite rock that dominates the city's western skyline. Longs Peak can also clearly be seen on a clear day to the southwest of the city.
According to the United States Census Bureau, the city has a total area of 47.1 sqmi, of which 46.5 sqmi is land and 0.6 sqmi, or 1.27%, is water. The Cache La Poudre River and Spring Creek run through Fort Collins.
Located along the Front Range of the Rocky Mountains, Fort Collins experiences a semi-arid climate (Köppen "BSk"), with four distinct seasons and low annual precipitation. Summers range from mild to hot, with low humidity and occasional afternoon thunderstorms. Winters range from mild to moderately cold. The city experiences lots of sunshine, with 300 days of sunshine per year and 19 days with 90° + weather. The average temperature in July, the warmest month, is 71 °F. The average temperature in January, the coldest month, is 29 °F. Annual snowfall averages 59 in, and can occur from early September through the end of May. Average precipitation overall is 15.9 in.
Demographics.
Fort Collins is the fourth most populous city in Colorado and the 163rd most populous city in the United States. The Census Bureau estimates that the city's population was 151,330 in 2013, the population of the Fort Collins-Loveland Metropolitan Statistical Area was 310,487 (151st most populous MSA), and the population of the Front Range Urban Corridor was 4,495,181.
As of the census of 2000, there were 118,652 people, 45,882 households, and 25,785 families residing in the city. The population density was 2,549.3 people per square mile (984.4/km²). There were 47,755 housing units at an average density of 1,026.0 per square mile (396.2/km²). The racial makeup of the city was 82.4% White, 3.01% Black or African American, 0.60% Native American, 2.48% Asian, 0.12% Pacific Islander, 3.61% from other races, and 2.53% from two or more races. Hispanic or Latino of any race were 10.79% of the population.
There were 45,882 households out of which 29.0% had children under the age of 18 living with them, 44.9% were married couples living together, 7.9% had a female householder with no husband present, and 43.8% were non-families. 26.0% of all households were made up of individuals and 5.9% had someone living alone who was 65 years of age or older. The average household size was 2.45 and the average family size was 3.01.
In the city the population was spread out with 21.5% under the age of 18, 22.1% from 18 to 24, 31.5% from 25 to 44, 17.0% from 45 to 64, and 7.9% who were 65 years of age or older. The median age was 28 years. For every 100 females there were 100.9 males. For every 100 females age 18 and over, there were 99.7 males.
The median income for a household in the city was $64,459, and the median income for a family was $89,332. Males had a median income of $60,856 versus $48,385 for females. The per capita income for the city was $32,133. About 5.5% of families and 14.0% of the population were below the poverty line, including 8.3% of those under age 18 and 5.8% of those age 65 or over.
Law and government.
Fort Collins has a council-manager form of government. The mayor, who serves a two-year term and stands for election in municipal elections held in April of odd-numbered years, presides over a seven-member City Council. The current mayor of Fort Collins is Wade Troxell, elected in April 2015. The six remaining council members are elected from districts for staggered four-year terms; odd-numbered districts are up for election in April 2017 and even-numbered districts in April 2019.
Fort Collins is the largest city in Colorado's 2nd Congressional district, and is represented in Congress by Representative Jared Polis (Democrat). On the state level, the city lies in the 14th district of the Colorado Senate, represented by John Kefalas and is split between the 52nd and 53rd districts of the Colorado House of Representatives, represented by Joann Ginal and Jennifer Arndt, respectively. All three of Fort Collins' state legislators are Democrats. Fort Collins is additionally the county seat of Larimer County, and houses county offices and courts.
The city maintains a police department.
Culture.
Much of Fort Collins's culture is centered on the students of Colorado State University. The city provides school year residences for its large college-age population; there is a local music circuit which is influenced by its college town atmosphere and is home to a number of well known microbreweries. The hosts a number of small and large festivals each year in the historic Downtown district, including Bohemian Nights at NewWestFest in late summer, which features local cuisine, music, and businesses. The Fort Collins Lincoln Center is home to the Fort Collins Symphony Orchestra and regularly attracts national touring companies of Broadway plays.
The city's thriving beer culture supports many microbreweries: the New Belgium Brewing Company, the Odell Brewing Company, the Fort Collins Brewery, Equinox Brewing, Funkwerks, Horse & Dragon Brewery, Pateros Creek Brewing Company, Zwei Brüder Brewing, and 1933 Brewing. New Belgium is the largest of the local craft-breweries, with national distribution from California to states east of the Mississippi. The largest brewer in the world, Anheuser-Busch, also has a brewery northeast of the city near I-25. There are several brewpubs, including the original C.B. & Potts Restaurant and its Big Horn Brewery, CooperSmith's Pub & Brewing, a local mainstay since 1989, Pitchers Brewery, and Black Bottle Brewery.
The Colorado Brewer's Festival is held in late June annually in Fort Collins. The festival features beers from as many as 45 brewers from the state of Colorado and averages around 30,000 attendees. New Belgium Brewery also hosts the Tour de Fat which draws over 20,000 people riding bikes and dressing in costume. As well as a series of Bike in movies starting late September.
The Colorado Marathon is a yearly event running down the Poudre Valley and finishing in Downtown Fort Collins.
The principal venue for the performing arts in Fort Collins is the Lincoln Center, 417 W. Magnolia St., at Meldrum Street. Built in 1978, the center includes the 1,180-seat Performance Hall and the 220-seat Magnolia Theatre, as well as four exhibit galleries and an outdoor sculpture and performance garden. It is home to many local arts groups, including the Fort Collins Symphony, Opera Fort Collins, Canyon Concert Ballet, Larimer Chorale, Youth Orchestra of the Rockies, OpenStage Theatre and Company, Foothills Pops Band and the Fort Collins Children's Theatre. Concert, dance, children's, and travel film series are presented annually. The center is wheelchair-accessible and has an infrared sound system for the hearing-impaired. Ticket prices vary considerably, but children's programs are often free or less than $10, and big name acts and Broadway shows are $18 to $36. The center hosts nearly 1,750 events each year.
The Fort Collins Museum, established in 1941, is a regional center focusing on the culture and history of Fort Collins and the surrounding area. The Fort Collins Museum houses over 30,000 artifacts and features temporary and permanent exhibits, on-going educational programs and events, and is home to four historic structures located in the outdoor Heritage Courtyard.
The arts are represented by The Center for Fine Art Photography, University Center for the Arts, Fort Collins Museum of Art (FCMOA), the Arts Incubator of the Rockies (AIR), and the Bas Bleu Theatre Company.
Communications.
One daily newspaper, the "Fort Collins Coloradoan", is published in the city. Several niche publications, including the "Fort Collins Courier" and "Fossil Creek Current", are distributed for free at local businesses and by mail. The "Rocky Mountain Collegian" is Colorado State University's student newspaper, and is published each weekday during the fall and spring semesters. The "Collegian" is the only daily student-run newspaper in the state, and includes a weekly entertainment tabloid called "The Weekender".
The "Scene Magazine" is a longtime entertainment and lifestyle monthly magazine, serving Ft. Collins and the northern front range. The "Rocky Mountain Parent Magazine "and "Parent Pages" are niche publications serving northern Colorado families.
The city of Fort Collins publishes the "Recreator," a popular seasonal guide to recreational activities and facilities in Fort Collins. The "Recreator" has continually been published for over 30 years. It is distributed via direct mail, online and locally at libraries, recreation centers and businesses.
The "Northern Colorado Business Report" is also housed in Fort Collins, and is the largest business-to-business newspaper in Northern Colorado. It covers Larimer and Weld counties.
Colorado State University funds a student-run radio station that focuses on underground and local music, KCSU-FM; and KRFC is the local Front Range Public Radio, a volunteer radio station.
One local television station provided coverage of Fort Collins and the surrounding area, NoCo Channel 5, a CBS affiliate, until the a new station owner decided to shutter operations. Fort Collins has Public, educational, and government access (PEG) cable TV channels. City Cable 14 is the local Government-access television (GATV) cable channel, and broadcasts city and county meetings, as well as studio-produced local programming. Poudre School District and Colorado State University each have public access stations as well. There is also a Fort Collins Public Access Network (PAN) station, channel 97 on Comcast, which broadcasts 24 hours a day.
Education.
K-12 public education is provided through Poudre School District (PSD), the second-largest employer in Fort Collins after Colorado State University. Fort Collins is home to four major high schools and several charter schools with middle school and high school grades. They include Fort Collins High School, Rocky Mountain High School, Poudre High School, Fossil Ridge High School, Centennial High School, Polaris School for Expeditionary Learning Outward Bound, Ridgeview Classical Schools, and Liberty Common High School. Liberty Common High School and Liberty Common School are the same, with LCHS housing grades 7–12 and LCS housing K-6.
The Poudre School District is also home to ten middle schools, including , Boltz Middle School, Cache La Poudre Middle School, Kinard Core Knowledge Middle School, Lincoln IB World Middle School, Polaris Expeditionary Learning School, Preston Middle School, Webber Middle School, and Wellington Middle School. Liberty Common School and Ridgeview Classical Schools are K–12 schools and therefore also have middle school students.
PSD is home to 32 elementary schools. The elementary schools range from neighborhood schools to specialized schools, core knowledge programs and the IB program. Among the schools housing the core knowledge program are Moore Core Knowledge, O'Dea Core Knowledge, Traut Core Knowledge, Zach Core Knowledge and Ridgeview Classical Schools. Bennett IB World School, Dunn IB World School and McGraw IB World School house the IB program. In addition, PSD is home to a bilingual educational experience at Harris Bilingual. Other schools with an entrance selection include the Lab School and Traut Core Knowledge. The newest elementary school is Bethke, a Core Knowledge school in Timnath, that started in the fall of 2008.
The city has a number of private and charter schools. Ridgeview Classical Schools was rated by "U.S. News & World Report" (December 2008) among the top ten charter high schools in the nation. T.R. Paul Academy of Arts and Knowledge is a charter school formerly known as Northern Colorado Academy of Arts and Knowledge. Heritage Christian Academy (formerly known as Heritage Christian School) is a private, pre-K–12 school.
Higher education.
Colorado State University heads up the choices in higher education. Front Range Community College also maintains a campus in the city, and grants associate's degrees in arts, science, general studies, and applied science. The college offers 17 high school vocational programs and more than 90 continuing education classes. Additionally, the University of Phoenix and Regis University maintain satellite campuses there.
The Institute of Business & Medical Careers provides professional training in the business and medical professions. The institute's first campus was established in the city in 1987.
The Fort Collins Public Library was established in 1900, the sixth public library in the state. The library formed a regional library district through a ballot measure in 2006. It has been renamed Poudre River Public Library District. The district operates three branches: the Old Town Library is located in downtown Fort Collins; the Harmony library is hosted at Front Range Community College; and the Council Tree Library, which opened in 2009, is at the Front Range Village Shopping Center. The library participates in cooperative projects with the local school district and Colorado State University.
Fort Collins has a range of research institutes. Facilities are maintained by the Centers for Disease Control and Prevention's Division of Vector-Borne Diseases, the Center for Advanced Technology and the Colorado Water Resource Research Institute. Other facilities include the Cooperative Institute for Research in the Atmosphere, the Institute for Scientific Computing, the U.S. Forest Service Experimental Station, the National Center for Genetic Resources Preservation (NCGRP), and the U.S.D.A. Crops Research Laboratory.
Economy.
Major industries and commercial activity.
Fort Collins' economy has a mix of manufacturing and service-related businesses. Fort Collins manufacturing includes Woodward Governor, Anheuser-Busch, and Otterbox. Many high-tech companies have relocated to Fort Collins because of the resources of Colorado State University and its research facilities. Hewlett Packard, Intel, AMD, Avago, Beckman Coulter, National Semiconductor, LSI, Rubicon Water and Pelco all have offices in Fort Collins. Other industries include clean energy, bioscience, and agri-tech businesses.
The largest employers of Fort Collins residents at the turn of the century were the following:
Regional economic development partners include the City of Fort Collins Economic Health Office, Northern Colorado Economic Development Corporation, Small Business Development Center, and Rocky Mountain Innovation Initiative (RMI2).
In 2013, Fort Collins ranked No. 7 on "Forbes"' list of the Best Places for Business and Careers, just below Denver (ranked No. 6).
Sustainability programs.
FortZED is growing to be the world's largest zero energy district. The FortZED area encompasses the Downtown area of Fort Collins and the main campus of Colorado State University.
FortZED is a set of active projects and initiatives, created by public-private partnerships, which utilize smart grid and renewable energy technologies to achieve local power generation and energy demand management. Federal, state, and local funding are making the project a reality. The U.S. Department of Energy has contributed $6.3 million, the Colorado Department of Local Affairs has contributed $778,000 while locally, private companies and foundations have contributed nearly $8 million.
Transportation.
Allegiant Air did offer regular passenger airplane service into the nearby Fort Collins / Loveland Airport, but as of October 2012 has ended commercial flights to this airport. Denver International Airport, which is 70 mi to the south, is served by nearly twenty airlines. Fort Collins can be approached from Denver by car via Interstate 25 or by way of the RTD bus system and the FLEX regional bus line.
The city's former general aviation airport, known as Fort Collins Downtown Airport (3V5), opened in 1966 and closed in 2006.
Fort Collins's downtown streets form a grid with Interstate 25 running north and south on the east side of the city. Many of the streets are named after the town's founders. U.S. Highway 287 becomes College Avenue inside the city and is the busiest street; It runs north and south, effectively bisecting the city, and serving as the east–west meridian, while Mountain Avenue is the north-south. SH 14 runs concurrent with US 287 at the northern city limit to Jefferson Street, running southeast along Jefferson (later turning into Riverside Avenue), then turning east onto Mulberry Street where it goes east out of the city after an interchange with Interstate 25.
The city bus system, known as Transfort, operates more than a dozen routes throughout Fort Collins Monday through Saturday, except major holidays.
The Mason Corridor (MAX) is a bus rapid transit that provides service parallel to College Avenue from Downtown Fort Collins to a transit center just south of Harmony Road. The trip takes approximately 15 minutes from end to end with various stops between. The service began in May 2014. The Mason Corridor and the Mason Express are intended to be the center of future transit-oriented development.
Fort Collins is connected to Loveland, Berthoud, and Longmont via the FLEX regional bus route.
Taxi service is provided 24 hours a day, 365 days per year by Northern Colorado Yellow Cab. Pedicabs are also available from HopON LLC and Dream team Pedicabs. Northern Colorado Yellow Cab operates the largest fleet of wheelchair accessible vehicles in Northern Colorado, and also provides courier and paratransit services.
Bicycling is a popular and viable means of transportation in Fort Collins. There are more than 280 mi of designated bikeways in Fort Collins, including on street designated bike lanes, and the Spring Creek and Poudre River Trails, both paved. There is also a dirt trail, the 5.8 mi Foothills Trail, parallel to Horsetooth Reservoir from Dixon Reservoir north to Campeau Open Space and Michaud Lane.
The Fort Collins Bicycle Library lends bicycles to visitors, students, and residents looking to explore the city of Fort Collins. There are self-guided tours from the "Bike the Sites" collection, including a Brewery Tour, Environmental Learning Tour, and the Historic Tour. The Bike Library is centrally located in the heart of downtown Fort Collins in Old Town Square.
In 2013 the League of American Bicyclists designated Fort Collins as a Platinum-level Bicycle Friendly Community – one of four in the United States.
Fort Collins also once had a municipally owned trolley service with three branches from the intersection of Mountain and College avenues. It was closed in 1951 after ceasing to be profitable. In 1983–84, a portion of the Mountain Avenue line and one of the original trolley cars, Car 21, were restored as a heritage trolley service, under the same name used by the original system, the Fort Collins Municipal Railway. This has been in operation since the end of 1984 on weekends and holidays in the spring and summer, as a tourist- and cultural/educational attraction small fee applies to ride.
Commercial shipping.
Parcel service for Fort Collins is provided by FedEx, Airport Express, DHL, Burlington Air Express, UPS, and Purolator. Fort Collins has two-day rail freight access to the West Coast or the East Coast and has eight motor freight carriers. Many local industrial sites have rail freight spur service. The city is served by Union Pacific and Burlington Northern Santa Fe railroads.

</doc>
<doc id="11508" url="http://en.wikipedia.org/wiki?curid=11508" title="Francis Drake">
Francis Drake

Sir Francis Drake, vice admiral ( 1540 – 27 January 1596) was an English sea captain, privateer, navigator, slaver, and politician of the Elizabethan era. Drake carried out the second circumnavigation of the world in a single expedition, from 1577 to 1580.
Elizabeth I of England awarded Drake a knighthood in 1581. He was second-in-command of the English fleet against the Spanish Armada in 1588. He died of dysentery in January 1596 after unsuccessfully attacking San Juan, Puerto Rico.
His exploits were legendary, making him a hero to the English but a pirate to the Spaniards to whom he was known as "El Draque". King Philip II was said to have offered a reward of 20,000 ducats, about £4 million (US$6.5M) by modern standards, for his life.
Birth and early years.
Francis Drake was born in Tavistock, Devon, England. Although his birth is not formally recorded, it is known that he was born while the Six Articles were in force. "Drake was two and twenty when he obtained the command of the "Judith"" (1566). This would date his birth to 1544. A date of c.1540 is suggested from two portraits: one a miniature painted by Nicholas Hilliard in 1581 when he was allegedly 42, the other painted in 1594 when he was said to be 53.
He was the eldest of the twelve sons of Edmund Drake (1518–1585), a Protestant farmer, and his wife Mary Mylwaye. The first son was reportedly named after his godfather Francis Russell, 2nd Earl of Bedford.
Because of religious persecution during the Prayer Book Rebellion in 1549, the Drake family fled from Devonshire into Kent. There the father obtained an appointment to minister to men in the King's Navy. He was ordained deacon and made vicar of Upnor Church on the Medway. Drake's father apprenticed Francis to his neighbour, the master of a barque used for coastal trade transporting merchandise to France. The ship master was so satisfied with the young Drake's conduct that, being unmarried and childless at his death, he bequeathed the barque to Drake.
Marriage and family.
Francis Drake married Mary Newman in 1569. She died 12 years later, in 1581. In 1585, Drake married Elizabeth Sydenham—born circa 1562, the only child of Sir George Sydenham, of Combe Sydenham, who was the High Sheriff of Somerset. After Drake's death, the widow Elizabeth eventually married Sir William Courtenay of Powderham. As Sir Francis Drake had no children, his estate and titles passed on to his nephew (also named Francis).
Sailing career.
At age 23, Drake made his first voyage to the Americas, sailing with his second cousin, Sir John Hawkins, on one of a fleet of ships owned by his relatives, the Hawkins family of Plymouth. In 1568 Drake was again with the Hawkins fleet when it was trapped by the Spaniards in the Mexican port of San Juan de Ulúa. He escaped along with Hawkins.
Following the defeat at San Juan de Ulúa, Drake vowed revenge. He made two voyages to the West Indies, in 1570 and 1571, of which little is known.
In 1572, he embarked on his first major independent enterprise. He planned an attack on the Isthmus of Panama, known to the Spanish as Tierra Firme and the English as the Spanish Main. This was the point at which the silver and gold treasure of Peru had to be landed and sent overland to the Caribbean Sea, where galleons from Spain would pick it up at the town of Nombre de Dios. Drake left Plymouth on 24 May 1572, with a crew of 73 men in two small vessels, the "Pascha" (70 tons) and the "Swan" (25 tons), to capture Nombre de Dios.
His first raid was late in July 1572. Drake and his men captured the town and its treasure. When his men noticed that Drake was bleeding profusely from a wound, they insisted on withdrawing to save his life and left the treasure. Drake stayed in the area for almost a year, raiding Spanish shipping and attempting to capture a treasure shipment.
In 1573, he joined Guillaume Le Testu, a French buccaneer, in an attack on a richly laden mule train. Drake and his party found that they had captured around 20 tons of silver and gold. They buried much of the treasure, as it was too much for their party to carry. (An account of this may have given rise to subsequent stories of pirates and buried treasure.) Wounded, Le Testu was captured and later beheaded. The small band of adventurers dragged as much gold and silver as they could carry back across some 18 miles of jungle-covered mountains to where they had left the raiding boats. When they got to the coast, the boats were gone. Drake and his men, downhearted, exhausted and hungry, had nowhere to go and the Spanish were not far behind.
At this point Drake rallied his men, buried the treasure on the beach, and built a raft to sail with two volunteers ten miles along the surf-lashed coast to where they had left the flagship. When Drake finally reached its deck, his men were alarmed at his bedraggled appearance. Fearing the worst, they asked him how the raid had gone. Drake could not resist a joke and teased them by looking downhearted. Then he laughed, pulled a necklace of Spanish gold from around his neck and said "Our voyage is made, lads!" By 9 August 1573, he had returned to Plymouth.
Circumnavigation of the earth (1577–1580).
With the success of the Panama isthmus raid, in 1577 Elizabeth I of England sent Drake to start an expedition against the Spanish along the Pacific coast of the Americas. Drake used the Plans that Sir Richard Greynvile had received the Patent for in 1574 from Elizabeth, which was rescinded a year later after protests from Philip of Spain. He set out from Plymouth on 15 November 1577, but bad weather threatened him and his fleet. They were forced to take refuge in Falmouth, Cornwall, from where they returned to Plymouth for repair.
After this major setback, he set sail again on 13 December, aboard "Pelican", with four other ships and 164 men. He soon added a sixth ship, "Mary" (formerly "Santa Maria"), a Portuguese merchant ship that had been captured off the coast of Africa near the Cape Verde Islands. He also added its captain, Nuno da Silva, a man with considerable experience navigating in South American waters.
Drake's fleet suffered great attrition; he scuttled both "Christopher" and the flyboat "Swan" due to loss of men on the Atlantic crossing. He made landfall at the gloomy bay of San Julian, in what is now Argentina. Ferdinand Magellan had called here half a century earlier, where he put to death some mutineers.
Drake's men saw weathered and bleached skeletons on the grim Spanish gibbets. They discovered that "Mary" had rotting timbers, so they burned the ship. Following Magellan's example, Drake tried and executed his own 'mutineer' Thomas Doughty. Drake decided to remain the winter in San Julian before attempting the Strait of Magellan.
Entering the Pacific (1578).
The three remaining ships of his convoy departed for the Magellan Strait at the southern tip of South America. A few weeks later (September 1578) Drake made it to the Pacific, but violent storms destroyed one of the three ships, the "Marigold" (captained by John Thomas) in the strait and caused another, the "Elizabeth" captained by John Wynter, to return to England, leaving only the "Pelican". After this passage, the "Pelican" was pushed south and discovered an island which Drake called Elizabeth Island. Drake, like navigators before him, probably reached a latitude of 55°S (according to astronomical data quoted in Hakluyt's "The Principall Navigations, Voiages and Discoveries of the English Nation" of 1589) along the Chilean coast.
Despite popular lore, it seems unlikely that he reached Cape Horn or the eponymous Drake Passage, because his descriptions do not fit the first and his shipmates denied having seen an open sea. The first report of his discovery of an open channel south of Tierra del Fuego was written after the 1618 publication of the voyage of Willem Schouten and Jacob le Maire around Cape Horn in 1616.
He pushed onwards in his lone flagship, now renamed the "Golden Hind" in honour of Sir Christopher Hatton (after his coat of arms). The "Golden Hind" sailed north along the Pacific coast of South America, attacking Spanish ports and pillaging towns. Some Spanish ships were captured, and Drake used their more accurate charts. Before reaching the coast of Peru, Drake visited Mocha Island, where he was seriously injured by hostile Mapuche. Later he sacked the port of Valparaíso further north in Chile where he also captured a ship full of Chilean wine.
Capture of Spanish treasure ships.
Near Lima, Drake captured a Spanish ship laden with 25,000 pesos of Peruvian gold, amounting in value to 37,000 ducats of Spanish money (about £7m by modern standards). Drake also discovered news of another ship, "Nuestra Señora de la Concepción", which was sailing west towards Manila. It would come to be called the "Cacafuego". Drake gave chase and eventually captured the treasure ship, which proved his most profitable capture.
Aboard "Nuestra Señora de la Concepción", Drake found 80 lb of gold, a golden crucifix, jewels, 13 chests full of royals of plate and 26 tons of silver. Drake was naturally pleased at his good luck in capturing the galleon and he showed it by dining with the captured ship's officers and gentleman passengers. He offloaded his captives a short time later, and gave each one gifts appropriate to their rank, as well as a letter of safe conduct.
Coast of California: Nova Albion (1579).
After looting the Cacafuego, Drake turned north, hoping to meet another Spanish treasure ship coming south on its return from Manila to Acapulco. Although he failed to find a treasure ship, Drake reputedly sailed as far north as the 38th parallel, landing on the coast of California on 17 June 1579. He found a good port, landed, repaired and restocked his vessels, then stayed for a time, keeping friendly relations with the Coast Miwok natives. He claimed the land in the name of the Holy Trinity for the English Crown, called "Nova Albion"—Latin for "New Britain". Assertions that he left some of his men behind as an embryo "colony" are founded on the reduced number who were with him in the Moluccas.
The precise location of the port was carefully guarded to keep it secret from the Spaniards, and several of Drake's maps may have been altered to this end. All first-hand records from the voyage, including logs, paintings and charts, were lost when Whitehall Palace burned in 1698. A bronze plaque inscribed with Drake's claim to the new lands – Drake's Plate of Brass – fitting the description in his account, was discovered in Marin County, California but was later declared a hoax. Now a National Historic Landmark, the officially recognised location of Drake's New Albion is Drakes Bay, California.
Across the Pacific and around Africa.
Drake left the Pacific coast, heading southwest to catch the winds that would carry his ship across the Pacific, and a few months later reached the Moluccas, a group of islands in the south west Pacific, in eastern modern-day Indonesia. While there, "Golden Hind" became caught on a reef and was almost lost. After the sailors waited three days for expedient tides and dumped cargo, they freed the barque. Befriending a sultan king of the Moluccas, Drake and his men became involved in some intrigues with the Portuguese there. He made multiple stops on his way toward the tip of Africa, eventually rounded the Cape of Good Hope, and reached Sierra Leone by 22 July 1580.
Return to Plymouth (1580).
On 26 September, "Golden Hind" sailed into Plymouth with Drake and 59 remaining crew aboard, along with a rich cargo of spices and captured Spanish treasures. The Queen's half-share of the cargo surpassed the rest of the crown's income for that entire year. Drake was hailed as the first Englishman to circumnavigate the Earth (and the second such voyage arriving with at least one ship intact, after Elcano's in 1520).
The Queen declared that all written accounts of Drake's voyages were to become the Queen's secrets of the Realm, and Drake and the other participants of his voyages on the pain of death sworn to their secrecy; she intended to keep Drake's activities away from the eyes of rival Spain. Drake presented the Queen with a jewel token commemorating the circumnavigation. Taken as a prize off the Pacific coast of Mexico, it was made of enamelled gold and bore an African diamond and a ship with an ebony hull.
For her part, the Queen gave Drake a jewel with her portrait, an unusual gift to bestow upon a commoner, and one that Drake sported proudly in his 1591 portrait by Marcus Gheeraerts now at the National Maritime Museum, Greenwich. On one side is a state portrait of Elizabeth by the miniaturist Nicholas Hilliard, on the other a sardonyx cameo of double portrait busts, a regal woman and an African male. The "Drake Jewel", as it is known today, is a rare documented survivor among sixteenth-century jewels; it is conserved at the Victoria and Albert Museum, London.
Award of knighthood.
Queen Elizabeth awarded Drake a knighthood aboard "Golden Hind" in Deptford on 4 April 1581; the dubbing being performed by a French diplomat, Monsieur de Marchaumont, who was negotiating for Elizabeth to marry the King of France's brother, Francis, Duke of Anjou. By getting the French diplomat involved in the knighting, Elizabeth was gaining the implicit political support of the French for Drake's actions. During the Victorian era, in a spirit of nationalism, the story was promoted that Elizabeth I had done the knighting.
Award of arms.
After receiving his knighthood Drake unilaterally adopted the armorials of the ancient Devon family of Drake of Ash, near Musbury, to whom he claimed a distant but unspecified kinship. These arms were: "Argent, a wyvern wings displayed and tail nowed gules", and the crest, "a dexter arm Proper grasping a battle axe Sable, headed Argent". The head of that family, also a distinguished sailor, Sir Bernard Drake (d.1586), angrily refuted Sir Francis's claimed kinship and his right to bear his family's arms. That dispute led to "a box in the ear" being given to Sir Francis by Sir Bernard at court, as recorded by John Prince in his "Worthies of Devon" (1697). Queen Elizabeth, to assuage matters, awarded Sir Francis his own coat of arms, blazoned as follows: 
"Sable a fess wavy between two pole-stars [Arctic and Antarctic] argent;" and for his crest, "a ship on a globe under ruff, held by a cable with a hand out of the clouds;" over it this motto, "Auxilio Divino;" underneath, "Sic Parvis Magna;" in the rigging whereof is hung up by the heels "a wivern, gules," which was the arms of Sir Bernard Drake.
The above is considered by students of heraldry to be an early example of "debased arms" due to their over-complexity, particularly as regards the crest. The motto, "Sic Parvis Magna", translated literally, is: "Thus great things from small things (come)". The hand out of the clouds, labelled "Auxilio Divino", means "With Divine Help". The full achievement is depicted in the form of a large coloured plaster overmantel in the Lifetimes Gallery at Buckland Abbey
Nevertheless, Drake continued to quarter his new arms with the wyvern gules. The arms adopted by his nephew Sir Francis Drake, 1st Baronet (1588–1637) of Buckland were the arms of Drake of Ash, but the wyvern without a "nowed" (knotted) tail.
Political career.
In September 1581, Drake became the Mayor of Plymouth, and was a member of parliament in 1581, for an unknown constituency (possibly Camelford), and again in 1584 for Bossiney and Plymouth in 1593.
Purchase of Buckland Abbey.
In 1580 Drake purchased Buckland Abbey via intermediaries from Sir Richard Greynvile, hiding who was actually purchasing the Abbey, a large manor house near Yelverton in Devon, from Sir Richard. He lived there for fifteen years, until his final voyage, and it remained in his family for several generations. Buckland Abbey is now in the care of the National Trust and a number of mementos of his life are displayed there.
Great Expedition.
War had already been declared by Phillip II after the Treaty of Nonsuch, so the Queen through Francis Walsingham ordered Sir Francis Drake to lead an expedition to attack the Spanish colonies in a kind of preemptive strike. An expedition left Plymouth in September 1585 with Drake in command of twenty one ships with 1,800 soldiers under Christopher Carleill. He first attacked Vigo in Spain and held the place for two weeks ransoming supplies. He then plundered Santiago in the Cape Verde islands after which the fleet then sailed across the Atlantic, sacked the port of Santo Domingo and captured the city of Cartagena de Indias in present-day Colombia. On 6 June 1586, during the return leg of the voyage, he raided the Spanish fort of San Augustín in Spanish Florida.
After the raids he then went on to find Sir Walter Raleigh's settlement much further North at Roanoke which he replenished and also took back with him all of the original colonists before Sir Richard Greynvile arrived with supplies and more colonists. He finally reached England on 22 July, when he sailed into Portsmouth, England to a hero's welcome.
Spanish Armada.
Encouraged by these acts Philip II ordered a planned invasion of England.
Cadiz raid.
In another pre-emptive strike, Drake "singed the beard of the King of Spain" in 1587 by sailing a fleet into Cadiz and also Corunna, two of Spain's main ports, and occupied the harbours. He destroyed 37 naval and merchant ships. The attack delayed the Spanish invasion by a year. Over the next month, Drake patrolled the Iberian coasts between Lisbon and Cape St. Vincent, intercepting and destroying ships on the Spanish supply lines. Drake estimated that he captured around 1600–1700 tons of barrel staves, enough to make 25,000 to 30000 oilbbl for containing provisions.
Defeat of the Spanish Armada.
Drake was vice admiral in command of the English fleet (under Lord Howard of Effingham) when it overcame the Spanish Armada that was attempting to invade England in 1588. As the English fleet pursued the Armada up the English Channel in closing darkness, Drake broke off and captured the Spanish galleon "Rosario", along with Admiral Pedro de Valdés and all his crew. The Spanish ship was known to be carrying substantial funds to pay the Spanish Army in the Low Countries. Drake's ship had been leading the English pursuit of the Armada by means of a lantern. By extinguishing this for the capture, Drake put the fleet into disarray overnight.
On the night of 29 July, along with Howard, Drake organised fire-ships, causing the majority of the Spanish captains to break formation and sail out of Calais into the open sea. The next day, Drake was present at the Battle of Gravelines. He wrote as follows to Admiral Henry Seymour after coming upon part of the Spanish Armada, whilst aboard "Revenge" on 31 July 1588 (21 July 1588 O.S.):Coming up to them, there has passed some common shot between some of our fleet and some of them; and as far as we perceive, they are determined to sell their lives with blows.
The most famous (but probably apocryphal) anecdote about Drake relates that, prior to the battle, he was playing a game of bowls on Plymouth Hoe. On being warned of the approach of the Spanish fleet, Drake is said to have remarked that there was plenty of time to finish the game and still beat the Spaniards. There is no known eyewitness account of this incident and the earliest retelling of it was printed 37 years later. Adverse winds and currents caused some delay in the launching of the English fleet as the Spanish drew nearer, perhaps prompting a popular myth of Drake's cavalier attitude to the Spanish threat.
Drake-Norris Expedition.
In 1589, the year after defeating the Armada, Drake and Sir John Norreys were given three tasks. They were ordered to first seek out and destroy the remaining ships, second they were to support the rebels in Lisbon, Portugal against King Philip II (then king of Spain and Portugal), and third they were to take the Azores if possible. Drake and Norreys destroyed a few ships in the harbour of A Coruña in Spain but lost more than 12,000 lives and 20 ships. This delayed Drake, and he was forced to forgo hunting the rest of the surviving ships and head on to Lisbon.
Final years.
"The people of quality dislike him for having risen so high from such a lowely family; the rest say he is the main cause of wars."
Drake's seafaring career continued into his mid-fifties. In 1595, he failed to conquer the port of Las Palmas, and following a disastrous campaign against Spanish America, where he suffered a number of defeats, he unsuccessfully attacked San Juan de Puerto Rico, eventually losing the Battle of San Juan.
The Spanish gunners from El Morro Castle shot a cannonball through the cabin of Drake's flagship, and he survived; but a few weeks later, in January 1596, he died of dysentery when he was about 55, while anchored off the coast of Portobelo, Panama, where some Spanish treasure ships had sought shelter. Following his death, the English fleet withdrew.
Before dying, he asked to be dressed in his full armour. He was buried at sea in a lead coffin, near Portobelo. Divers continue to search for the coffin.
Cultural impact.
In the UK there are various places named after him, especially in Plymouth, Devon, where various places carry his name, including the naval base (HMS Drake), Drake's Island and a roundabout named Drake Circus, along with a shopping mall named after the roundabout. Plymouth Hoe is also home to a statue of Drake.
In the United States Drakes Bay and Sir Francis Drake Boulevard of Marin County, California are both named after him, as well as the high school in San Anselmo, California. The boulevard runs between Drakes Bay at Point Reyes to Point San Quentin on San Francisco Bay. A large hotel in Union Square, San Francisco also bears his name. Additionally, the Sir Francis Drake Channel in the British Virgin Islands bears his name.
In British Columbia, Canada, where some theorize he may also have landed to the north of the usual site considered to be Nova Albion, various mountains were named in the 1930s for him, or in connection with Elizabeth I or other figures of that era, including Mount Sir Francis Drake, Mount Queen Bess, and the Golden Hinde, the highest mountain on Vancouver Island.
Drake's will was the focus of a vast confidence scheme which Oscar Hartzell perpetrated in the 1920s and 1930s. He convinced thousands of people, mostly in the American Midwest, that Drake's fortune was being held by the British government, and had compounded to a huge amount. If their last name was Drake they might be eligible for a share if they paid Hartzell to be their agent. The swindle continued until a copy of Drake's will was brought to Hartzell's mail fraud trial and he was convicted and imprisoned.
Drake was portrayed by the Canadian actor Matheson Lang in the 1935 film "Drake of England". Modern workings of stories involving Drake include the 1961 British television series "Sir Francis Drake", and the 2009 US television movie "The Immortal Voyage of Captain Drake".
In 2003, he was the namesake of the Drake Tribe in "".
Drake's execution of Thomas Doughty is the subject of Robert E. Howard's Solomon Kane poem, "."
Nathan Drake, a fictional descendant of Sir Francis Drake, searches for lost treasure supposedly found by Sir Francis during his circumnavigation in the video game ', and again in '.
Controversies.
Slave trading.
Drake accompanied his second cousin Sir John Hawkins in making the third English slave-trading expeditions, making fortunes through the abduction and transportation of West African people, and then exchanging them for high-value goods. The first Englishman recorded to have taken slaves from Africa was John Lok, a London trader who, in 1555, brought to England five slaves from Guinea.
A second London trader taking slaves at that time was William Towerson whose fleet sailed into Plymouth following his 1556 voyage to Africa and from Plymouth on his 1557 voyage. Despite the exploits of Lok and Towerson, John Hawkins of Plymouth is widely acknowledged to be an early pioneer of the English slave trade. While Hawkins made only three such trips, ultimately the English were to dominate the trade.
Around 1563 Drake first sailed west to the Spanish Main, on a ship owned and commanded by John Hawkins, with a cargo of people forcibly removed from the coast of West Africa. The Englishmen sold their African captives into slavery in Spanish plantations. In general, the kidnapping and forced transportation of people was considered to be a criminal offence under English law at the time, although legal protection did not extend to slaves, non-Protestants or criminals. Hawkins' own account of his actions (in which Drake took part) cites two sources for their victims. One was military attacks on African towns and villages (with the assistance of rival African warlords), the other was attacking Portuguese slave ships.
Conflict in the Caribbean.
During his early days as a slave-trader, Drake took an immediate dislike to the Spanish, at least in part due to their Catholicism and inherent distrust of non-Spanish. His hostility is said to have increased over an incident at San Juan de Ulúa in 1568, when Drake was sailing with the fleet of his second cousin John Hawkins. Whilst negotiating to resupply and repair at the Spanish port, the fleet were attacked by Spanish warships, with all but two of the English ships lost. Drake survived the attack by swimming.
The most celebrated of Drake's adventures along the Spanish Main was his capture of the Spanish Silver Train at Nombre de Dios in March 1573. With a crew including many French privateers and Maroons—African slaves who had escaped the Spanish—Drake raided the waters around Darien (in modern Panama) and tracked the Silver Train to the nearby port of Nombre de Dios. He made off with a fortune in gold, but had to leave behind another fortune in silver, because it was too heavy to carry back to England.
It was during this expedition that he climbed a high tree in the central mountains of the Isthmus of Panama and thus became the first Englishman to see the Pacific Ocean. He remarked as he saw it that he hoped one day an Englishman would be able to sail it—which he would do years later as part of his circumnavigation of the world.
When Drake returned to Plymouth after the raids, the government signed a temporary truce with King Philip II of Spain and so was unable to acknowledge Drake's accomplishment officially. Drake was considered a hero in England and a pirate in Spain for his raids.
Ireland.
In 1575, Drake was present at the Rathlin Island Massacre, which was a part of the English plantation effort in Ulster, where 600 men, women, and children were massacred after surrendering.
Francis Drake was in charge of the ships which transported John Norreys' troops to Rathlin Island, commanding a small frigate called "Falcon", with a total complement of 25. At the time of the massacre, he was charged with the task of keeping Scottish vessels from bringing reinforcements to Rathlin Island. The people who were massacred were, in fact, the families of Sorley Boy MacDonnell's followers.
Execution of Thomas Doughty.
On his voyage to interfere with Spanish treasure fleets, Drake had several quarrels with his co-commander Thomas Doughty and on 3 June 1578, accused him of witchcraft and charged him with mutiny and treason in a shipboard trial. Drake claimed to have a (never presented) commission from the Queen to carry out such acts and denied Doughty a trial in England. The main pieces of evidence against Doughty were the testimony of the ship's carpenter, Edward Bright, who after the trial was promoted to master of the ship "Marigold", and Doughty's admission of telling Lord Burghley, a vocal opponent of agitating the Spanish, of the intent of the voyage. Drake consented to his request of Communion and dined with him, of which Francis Fletcher had this strange account:
And after this holy repast, they dined also at the same table together, as cheerfully, in sobriety, as ever in their lives they had done aforetime, each cheering up the other, and taking their leave, by drinking each to other, as if some journey only had been in hand.
Drake had Thomas Doughty beheaded on 2 July 1578. When the ship's chaplain Francis Fletcher in a sermon suggested that the woes of the voyage in January 1580 were connected to the unjust demise of Doughty, Drake chained the clergyman to a hatch cover and pronounced him excommunicated.

</doc>
<doc id="11512" url="http://en.wikipedia.org/wiki?curid=11512" title="Fast Fourier transform">
Fast Fourier transform

A fast Fourier transform (FFT) is an algorithm to compute the discrete Fourier transform (DFT) and its inverse. Fourier analysis converts time (or space) to frequency (or wavenumber) and vice versa; an FFT rapidly computes such transformations by factorizing the DFT matrix into a product of sparse (mostly zero) factors. As a result, fast Fourier transforms are widely used for many applications in engineering, science, and mathematics. The basic ideas were popularized in 1965, but some algorithms had been derived as early as 1805. In 1994 Gilbert Strang described the fast Fourier transform as "the most important numerical algorithm of our lifetime".
Overview.
There are many different FFT algorithms involving a wide range of mathematics, from simple complex-number arithmetic to group theory and number theory; this article gives an overview of the available techniques and some of their general properties, while the specific algorithms are described in subsidiary articles linked below.
The DFT is obtained by decomposing a sequence of values into components of different frequencies. This operation is useful in many fields (see discrete Fourier transform for properties and applications of the transform) but computing it directly from the definition is often too slow to be practical. An FFT is a way to compute the same result more quickly: computing the DFT of "N" points in the naive way, using the definition, takes O("N"2) arithmetical operations, while an FFT can compute the same DFT in only O("N" log2 "N") operations. The difference in speed can be enormous, especially for long data sets where "N" may be in the thousands or millions. In practice, the computation time can be reduced by several orders of magnitude in such cases, and the improvement is roughly proportional to "N" / log("N"). This huge improvement made the calculation of the DFT practical; FFTs are of great importance to a wide variety of applications, from digital signal processing and solving partial differential equations to algorithms for quick multiplication of large integers.
The best-known FFT algorithms depend upon the factorization of "N", but there are FFTs with O("N" log "N") complexity for all "N", even for prime "N". Many FFT algorithms only depend on the fact that formula_1 is an "N"-th primitive root of unity, and thus can be applied to analogous transforms over any finite field, such as number-theoretic transforms. Since the inverse DFT is the same as the DFT, but with the opposite sign in the exponent and a 1/"N" factor, any FFT algorithm can easily be adapted for it.
Definition and speed.
An FFT computes the DFT and produces exactly the same result as evaluating the DFT definition directly; the most important difference is that an FFT is much faster. (In the presence of round-off error, many FFT algorithms are also much more accurate than evaluating the DFT definition directly, as discussed below.)
Let "x"0, ..., "x""N"-1 be complex numbers. The DFT is defined by the formula
Evaluating this definition directly requires O("N"2) operations: there are "N" outputs "X""k", and each output requires a sum of "N" terms. An FFT is any method to compute the same results in O("N" log "N") operations. More precisely, all known FFT algorithms require Θ("N" log "N") operations (technically, O only denotes an upper bound), although there is no known proof that a lower complexity score is impossible.(Johnson and Frigo, 2007)
To illustrate the savings of an FFT, consider the count of complex multiplications and additions. Evaluating the DFT's sums directly involves "N"2 complex multiplications and "N"("N"−1) complex additions [of which O("N") operations can be saved by eliminating trivial operations such as multiplications by 1]. The well-known radix-2 Cooley–Tukey algorithm, for "N" a power of 2, can compute the same result with only ("N"/2)log2("N") complex multiplications (again, ignoring simplifications of multiplications by 1 and similar) and "N"log2("N") complex additions. In practice, actual performance on modern computers is usually dominated by factors other than the speed of arithmetic operations and the analysis is a complicated subject (see, e.g., Frigo & Johnson, 2005), but the overall improvement from O("N"2) to O("N" log "N") remains.
Algorithms.
Cooley–Tukey algorithm.
By far the most commonly used FFT is the Cooley–Tukey algorithm. This is a divide and conquer algorithm that recursively breaks down a DFT of any composite size "N" = "N"1"N"2 into many smaller DFTs of sizes "N"1 and "N"2, along with O("N") multiplications by complex roots of unity traditionally called twiddle factors (after Gentleman and Sande, 1966).
This method (and the general idea of an FFT) was popularized by a publication of J. W. Cooley and J. W. Tukey in 1965, but it was later discovered that those two authors had independently re-invented an algorithm known to Carl Friedrich Gauss around 1805 (and subsequently rediscovered several times in limited forms).
The best known use of the Cooley–Tukey algorithm is to divide the transform into two pieces of size "N"/2 at each step, and is therefore limited to power-of-two sizes, but any factorization can be used in general (as was known to both Gauss and Cooley/Tukey). These are called the radix-2 and mixed-radix cases, respectively (and other variants such as the split-radix FFT have their own names as well). Although the basic idea is recursive, most traditional implementations rearrange the algorithm to avoid explicit recursion. Also, because the Cooley–Tukey algorithm breaks the DFT into smaller DFTs, it can be combined arbitrarily with any other algorithm for the DFT, such as those described below.
Other FFT algorithms.
There are other FFT algorithms distinct from Cooley–Tukey.
Cornelius Lanczos did pioneering work on the FFS and FFT with G.C. Danielson (1940).
For "N" = "N"1"N"2 with coprime "N"1 and "N"2, one can use the Prime-Factor (Good-Thomas) algorithm (PFA), based on the Chinese Remainder Theorem, to factorize the DFT similarly to Cooley–Tukey but without the twiddle factors. The Rader-Brenner algorithm (1976) is a Cooley–Tukey-like factorization but with purely imaginary twiddle factors, reducing multiplications at the cost of increased additions and reduced numerical stability; it was later superseded by the split-radix variant of Cooley–Tukey (which achieves the same multiplication count but with fewer additions and without sacrificing accuracy). Algorithms that recursively factorize the DFT into smaller operations other than DFTs include the Bruun and QFT algorithms. (The Rader-Brenner and QFT algorithms were proposed for power-of-two sizes, but it is possible that they could be adapted to general composite "n". Bruun's algorithm applies to arbitrary even composite sizes.) Bruun's algorithm, in particular, is based on interpreting the FFT as a recursive factorization of the polynomial "zN"−1, here into real-coefficient polynomials of the form "zM"−1 and "z2M" + "azM" + 1.
Another polynomial viewpoint is exploited by the Winograd algorithm, which factorizes "zN"−1 into cyclotomic polynomials—these often have coefficients of 1, 0, or −1, and therefore require few (if any) multiplications, so Winograd can be used to obtain minimal-multiplication FFTs and is often used to find efficient algorithms for small factors. Indeed, Winograd showed that the DFT can be computed with only O("N") irrational multiplications, leading to a proven achievable lower bound on the number of multiplications for power-of-two sizes; unfortunately, this comes at the cost of many more additions, a tradeoff no longer favorable on modern processors with hardware multipliers. In particular, Winograd also makes use of the PFA as well as an algorithm by Rader for FFTs of "prime" sizes.
Rader's algorithm, exploiting the existence of a generator for the multiplicative group modulo prime "N", expresses a DFT of prime size "n" as a cyclic convolution of (composite) size "N"−1, which can then be computed by a pair of ordinary FFTs via the convolution theorem (although Winograd uses other convolution methods). Another prime-size FFT is due to L. I. Bluestein, and is sometimes called the chirp-z algorithm; it also re-expresses a DFT as a convolution, but this time of the "same" size (which can be zero-padded to a power of two and evaluated by radix-2 Cooley–Tukey FFTs, for example), via the identity formula_3.
FFT algorithms specialized for real and/or symmetric data.
In many applications, the input data for the DFT are purely real, in which case the outputs satisfy the symmetry
and efficient FFT algorithms have been designed for this situation (see e.g. Sorensen, 1987). One approach consists of taking an ordinary algorithm (e.g. Cooley–Tukey) and removing the redundant parts of the computation, saving roughly a factor of two in time and memory. Alternatively, it is possible to express an "even"-length real-input DFT as a complex DFT of half the length (whose real and imaginary parts are the even/odd elements of the original real data), followed by O("N") post-processing operations.
It was once believed that real-input DFTs could be more efficiently computed by means of the discrete Hartley transform (DHT), but it was subsequently argued that a specialized real-input DFT algorithm (FFT) can typically be found that requires fewer operations than the corresponding DHT algorithm (FHT) for the same number of inputs. Bruun's algorithm (above) is another method that was initially proposed to take advantage of real inputs, but it has not proved popular.
There are further FFT specializations for the cases of real data that have even/odd symmetry, in which case one can gain another factor of (roughly) two in time and memory and the DFT becomes the discrete cosine/sine transform(s) (DCT/DST). Instead of directly modifying an FFT algorithm for these cases, DCTs/DSTs can also be computed via FFTs of real data combined with O("N") pre/post processing.
Computational issues.
Bounds on complexity and operation counts.
A fundamental question of longstanding theoretical interest is to prove lower bounds on the complexity and exact operation counts of fast Fourier transforms, and many open problems remain. It is not even rigorously proved whether DFTs truly require Ω("N" log("N")) (i.e., order "N" log("N") or greater) operations, even for the simple case of power of two sizes, although no algorithms with lower complexity are known. In particular, the count of arithmetic operations is usually the focus of such questions, although actual performance on modern-day computers is determined by many other factors such as cache or CPU pipeline optimization.
Following pioneering work by Winograd (1978), a tight Θ("N") lower bound "is" known for the number of real multiplications required by an FFT. It can be shown that only formula_5 irrational real multiplications are required to compute a DFT of power-of-two length formula_6. Moreover, explicit algorithms that achieve this count are known (Heideman & Burrus, 1986; Duhamel, 1990). Unfortunately, these algorithms require too many additions to be practical, at least on modern computers with hardware multipliers (Duhamel, 1990; Frigo & Johnson, 2005).
A tight lower bound is "not" known on the number of required additions, although lower bounds have been proved under some restrictive assumptions on the algorithms. In 1973, Morgenstern proved an Ω("N" log("N")) lower bound on the addition count for algorithms where the multiplicative constants have bounded magnitudes (which is true for most but not all FFT algorithms). Pan (1986) proved an Ω("N" log("N")) lower bound assuming a bound on a measure of the FFT algorithm's "asynchronicity", but the generality of this assumption is unclear. For the case of power-of-two "N", Papadimitriou (1979) argued that the number formula_7 of complex-number additions achieved by Cooley–Tukey algorithms is "optimal" under certain assumptions on the graph of the algorithm (his assumptions imply, among other things, that no additive identities in the roots of unity are exploited). (This argument would imply that at least formula_8 real additions are required, although this is not a tight bound because extra additions are required as part of complex-number multiplications.) Thus far, no published FFT algorithm has achieved fewer than formula_7 complex-number additions (or their equivalent) for power-of-two "N".
A third problem is to minimize the "total" number of real multiplications and additions, sometimes called the "arithmetic complexity" (although in this context it is the exact count and not the asymptotic complexity that is being considered). Again, no tight lower bound has been proven. Since 1968, however, the lowest published count for power-of-two "N" was long achieved by the split-radix FFT algorithm, which requires formula_10 real multiplications and additions for "N" > 1. This was recently reduced to formula_11 (Johnson and Frigo, 2007; Lundy and Van Buskirk, 2007). A slightly larger count (but still better than split radix for "N"≥256) was shown to be provably optimal for "N"≤512 under additional restrictions on the possible algorithms (split-radix-like flowgraphs with unit-modulus multiplicative factors), by reduction to a Satisfiability Modulo Theories problem solvable by brute force (Haynal & Haynal, 2011).
Most of the attempts to lower or prove the complexity of FFT algorithms have focused on the ordinary complex-data case, because it is the simplest. However, complex-data FFTs are so closely related to algorithms for related problems such as real-data FFTs, discrete cosine transforms, discrete Hartley transforms, and so on, that any improvement in one of these would immediately lead to improvements in the others (Duhamel & Vetterli, 1990).
Accuracy and approximations.
All of the FFT algorithms discussed above compute the DFT exactly (in exact arithmetic, i.e. neglecting floating-point errors). A few "FFT" algorithms have been proposed, however, that compute the DFT "approximately", with an error that can be made arbitrarily small at the expense of increased computations. Such algorithms trade the approximation error for increased speed or other properties. For example, an approximate FFT algorithm by Edelman et al. (1999) achieves lower communication requirements for parallel computing with the help of a fast multipole method. A wavelet-based approximate FFT by Guo and Burrus (1996) takes sparse inputs/outputs (time/frequency localization) into account more efficiently than is possible with an exact FFT. Another algorithm for approximate computation of a subset of the DFT outputs is due to Shentov et al. (1995). The Edelman algorithm works equally well for sparse and non-sparse data, since it is based on the compressibility (rank deficiency) of the Fourier matrix itself rather than the compressibility (sparsity) of the data. Conversely, if the data are sparse—that is, if only "K" out of "N" Fourier coefficients are nonzero—then the complexity can be reduced to O("K"log("N")log("N"/"K")), and this has been demonstrated to lead to practical speedups compared to an ordinary FFT for N/K>32 in a large-N example (N=222) using a probabilistic approximate algorithm (which estimates the largest "K" coefficients to several decimal places).
Even the "exact" FFT algorithms have errors when finite-precision floating-point arithmetic is used, but these errors are typically quite small; most FFT algorithms, e.g. Cooley–Tukey, have excellent numerical properties as a consequence of the pairwise summation structure of the algorithms. The upper bound on the relative error for the Cooley–Tukey algorithm is O(ε log "N"), compared to O(ε"N"3/2) for the naïve DFT formula, where ε is the machine floating-point relative precision. In fact, the root mean square (rms) errors are much better than these upper bounds, being only O(ε √log "N") for Cooley–Tukey and O(ε √"N") for the naïve DFT (Schatzman, 1996). These results, however, are very sensitive to the accuracy of the twiddle factors used in the FFT (i.e. the trigonometric function values), and it is not unusual for incautious FFT implementations to have much worse accuracy, e.g. if they use inaccurate trigonometric recurrence formulas. Some FFTs other than Cooley–Tukey, such as the Rader-Brenner algorithm, are intrinsically less stable.
In fixed-point arithmetic, the finite-precision errors accumulated by FFT algorithms are worse, with rms errors growing as O(√"N") for the Cooley–Tukey algorithm (Welch, 1969). Moreover, even achieving this accuracy requires careful attention to scaling in order to minimize the loss of precision, and fixed-point FFT algorithms involve rescaling at each intermediate stage of decompositions like Cooley–Tukey.
To verify the correctness of an FFT implementation, rigorous guarantees can be obtained in O("N"log("N")) time by a simple procedure checking the linearity, impulse-response, and time-shift properties of the transform on random inputs (Ergün, 1995).
Multidimensional FFTs.
As defined in the multidimensional DFT article, the multidimensional DFT
transforms an array "x"n with a "d"-dimensional vector of indices formula_13 by a set of "d" nested summations (over formula_14 for each "j"), where the division n/N, defined as formula_15, is performed element-wise. Equivalently, it is the composition of a sequence of "d" sets of one-dimensional DFTs, performed along one dimension at a time (in any order).
This compositional viewpoint immediately provides the simplest and most common multidimensional DFT algorithm, known as the row-column algorithm (after the two-dimensional case, below). That is, one simply performs a sequence of "d" one-dimensional FFTs (by any of the above algorithms): first you transform along the "n"1 dimension, then along the "n"2 dimension, and so on (or actually, any ordering will work). This method is easily shown to have the usual O("N"log("N")) complexity, where formula_16 is the total number of data points transformed. In particular, there are "N"/"N"1 transforms of size "N"1, etcetera, so the complexity of the sequence of FFTs is:
In two dimensions, the "x"k can be viewed as an formula_18 matrix, and this algorithm corresponds to first performing the FFT of all the rows (resp. columns), grouping the resulting transformed rows (resp. columns) together as another formula_18 matrix, and then performing the FFT on each of the columns (resp. rows) of this second matrix, and similarly grouping the results into the final result matrix.
In more than two dimensions, it is often advantageous for cache locality to group the dimensions recursively. For example, a three-dimensional FFT might first perform two-dimensional FFTs of each planar "slice" for each fixed "n"1, and then perform the one-dimensional FFTs along the "n"1 direction. More generally, an asymptotically optimal cache-oblivious algorithm consists of recursively dividing the dimensions into two groups formula_20 and formula_21 that are transformed recursively (rounding if "d" is not even) (see Frigo and Johnson, 2005). Still, this remains a straightforward variation of the row-column algorithm that ultimately requires only a one-dimensional FFT algorithm as the base case, and still has O("N"log("N")) complexity. Yet another variation is to perform matrix transpositions in between transforming subsequent dimensions, so that the transforms operate on contiguous data; this is especially important for out-of-core and distributed memory situations where accessing non-contiguous data is extremely time-consuming.
There are other multidimensional FFT algorithms that are distinct from the row-column algorithm, although all of them have O("N"log("N")) complexity. Perhaps the simplest non-row-column FFT is the vector-radix FFT algorithm, which is a generalization of the ordinary Cooley–Tukey algorithm where one divides the transform dimensions by a vector formula_22 of radices at each step. (This may also have cache benefits.) The simplest case of vector-radix is where all of the radices are equal (e.g. vector-radix-2 divides "all" of the dimensions by two), but this is not necessary. Vector radix with only a single non-unit radix at a time, i.e. formula_23, is essentially a row-column algorithm. Other, more complicated, methods include polynomial transform algorithms due to Nussbaumer (1977), which view the transform in terms of convolutions and polynomial products. See Duhamel and Vetterli (1990) for more information and references.
Other generalizations.
An O("N"5/2log("N")) generalization to spherical harmonics on the sphere "S"2 with "N"2 nodes was described by Mohlenkamp, along with an algorithm conjectured (but not proven) to have O("N"2 log2("N")) complexity; Mohlenkamp also provides an implementation in the . A spherical-harmonic algorithm with O("N"2log("N")) complexity is described by Rokhlin and Tygert.
The Fast Folding Algorithm is analogous to the FFT, except that it operates on a series of binned waveforms rather than a series of real or complex scalar values. Rotation (which in the FFT is multiplication by a complex phasor) is a circular shift of the component waveform.
Various groups have also published "FFT" algorithms for non-equispaced data, as reviewed in Potts "et al." (2001). Such algorithms do not strictly compute the DFT (which is only defined for equispaced data), but rather some approximation thereof (a non-uniform discrete Fourier transform, or NDFT, which itself is often computed only approximately). More generally there are various other methods of spectral estimation.

</doc>
<doc id="11513" url="http://en.wikipedia.org/wiki?curid=11513" title="Fort William, Scotland">
Fort William, Scotland

Fort William (Scottish Gaelic: "An Gearasdan" ] "The Garrison") is the second largest settlement in the Highlands of Scotland with around 10,000 inhabitants — and the largest town: only the city of Inverness is larger.
Fort William is a major tourist centre, with Glen Coe just to the south, Aonach Mòr to the north and Glenfinnan to the west, on the Road to the Isles. It is a centre for hillwalking and climbing due to its proximity to Ben Nevis and many other Munro mountains. It is also known for its nearby downhill mountain bike track. It is the start/end of both the West Highland Way (Milngavie-Fort William) and the Great Glen Way (a walk/cycle way Fort William-Inverness).
Around 726 people (7.33% of the population) can speak Gaelic.
Etymology.
Questions over the town's English name are various. The post-Reformation fort was named "Fort William" after William of Orange, and the settlement that grew around it was called "Maryburgh", after his wife. This settlement was later renamed "Gordonsburgh", and then "Duncansburgh" before being renamed "Fort William", this time after Prince William, Duke of Cumberland; known to some Scots as "Butcher Cumberland". Given these origins, there have been various suggestions over the years to rename the town (for example, to "Invernevis"). These proposals have led to nothing yet.
Questions over the town's Gaelic name are equally interesting. The Gaelic name for the town is "An Gearasdan", and this is the result of a transliteration from the French term Garrison. French loan-words in the Gaelic language are very rare, and can only correspond with specific times in Scottish history: during David I's politically pacifying introduction of a Norman aristocracy in Scotland after the Norman conquest of England, and the period covering the Auld Alliance.
The most likely derivation for the town's Franco-Gaelic name is from the Scoto-Norman Clan Comyn, who built Inverlochy Castle in the Norman style that is familiar throughout Scotland during this period. French loan-words that take root during the Auld Alliance are far more common in the Scots language than in Gaelic.
History.
Historically, this area of Lochaber was strongly Clan Cameron country, and there were a number of mainly Cameron settlements in the area (such as Blarmacfoldach). The nearby settlement of Inverlochy was the main settlement in the area before the building of the fort, and was also site of the Battle of Inverlochy.
The town grew in size as a settlement when the fort was constructed to control the population after Oliver Cromwell's invasion during the English Civil War, and then to suppress the Jacobite uprisings of the 18th century.
In the Jacobite rising known as the Forty-Five, Fort William was besieged for two weeks by the Jacobites, from 20 March to 3 April 1746. However, although the Jacobites had captured both of the other forts in the chain of three Great Glen fortifications (Fort Augustus and the original Fort George) they failed to take Fort William.
During the Second World War, Fort William was the home of HMS "St Christopher" which was a training base for Royal Navy Coastal Forces.
More on the history of the town and the region can be found in the West Highland Museum on the High Street.
Fort William is the northern end of the West Highland Way, a long distance route which runs 95 mi through the Scottish Highlands to Milngavie, on the outskirts of Glasgow, and the start/end point of the Great Glen Way, which runs between Fort William and Inverness.
On 2 June 2006, a fire destroyed McTavish's Restaurant in Fort William High Street along with the two shops which were part of the building. The restaurant had been open since the 1970s and prior to that the building had been Fraser's Cafe since the 1920s. Development work began in 2012 on new hotel accommodation and street-level shops and these opened in 2014.
Future development.
A "Waterfront" development has been proposed by the Council though there is not overwhelming support for this in the town. The development will include a hotel, some shops and some housing but it was discovered early in 2008 that it is unlikely to be completed before 2020. It was announced in April 2010 that the project has been abandoned.
Geography.
Fort William lies near the head of Loch Linnhe, one of Scotland's longest sea lochs, beside the mouth of the rivers Nevis and Lochy. They join in the intertidal zone to briefly become one river before discharging to the sea. The town and its suburbs are surrounded by picturesque mountains.
The town is centred on the High Street, which was pedestrianised in the 1990s. Off this there are several squares. Monzie Square (named after the Cameron Campbells of Monzie, Perthshire, former landowners in the town), Station Square, where the long-since demolished railway station used to be, Gordon Square (named for the Gordons, who owned land where the town now stands in the late 18th century, during which time the town was named Gordonsburgh), and Cameron Square — formerly known as Town Hall Square. There is also Fraser Square which is not so square-like since it now opens out into Middle Street but it still houses the Imperial Hotel.
The main residential areas of the town are unseen from the high street or the A82 main road. Upper Achintore and the Plantation spread steeply uphill from above the high street.
Inverlochy, Claggan, An-Aird, Lochyside, Caol, Banavie and Corpach outwith the town are the other main residential areas. These areas are built on much flatter land than the town.
Glenfinnan, 17 mi away, is home of the Glenfinnan Monument (Jacobite era) and the famous Glenfinnan Viaduct (as seen on a Bank Of Scotland £10 note). The viaduct has become known to millions in recent years as the "Harry Potter Bridge" after it featured in the films of the books by J.K. Rowling, specifically "Harry Potter and the Chamber of Secrets". Glenfinnan has also been used in "Charlotte Gray" and "Highlander".
Just outside the town is a large aluminium plant operated by Alcan and powered by the Lochaber hydroelectric scheme, in its day the biggest tunnelling project in the world. This was formerly served by the Lochaber Narrow Gauge Railway better known locally as the Puggy Line.
Location.
Originally based on the still-existent village of Inverlochy, the town lies at the southern end of the Great Glen, on the shores of Loch Linnhe and Loch Eil. It is close to Ben Nevis, the highest mountain in the British Isles, and Glen Nevis. When the railway opened to Fort William on 7 August 1894, the station was given prime position at the south end of the town. The consequence was that the town was separated from the lochside by railway tracks until the 1970s when the present by-pass was built, and the station was re-located to the north end.
Climate.
Fort William has an oceanic climate ("Cfb") with moderate, but generally cool, temperatures and abundant precipitation.
Transport.
The West Highland Line passes through Fort William. Owing to the difficult terrain in the area, the line from Glasgow, to the south, enters from the northeast. Trains from Glasgow to Mallaig, the terminus of the line, have to reverse at Fort William railway station.
An overnight train, the Caledonian sleeper, has its terminus at Fort William. This service is known colloquially as 'The Deerstalker'.
A bus station outside the railway station is served by local buses and express coaches.
The Caledonian Canal connects the Scottish east coast at Inverness with the west coast at Corpach near Fort William.
Sports.
Mountain biking.
Just outside the town, parallel to the Nevis Range Gondola, there is a large downhill mountain bike track which attracts thousands of visitors every year, including international competitors and fans.
Each year since 2001, Fort William has hosted a round of UCI Mountain Bike World Cup, and in 2007 it hosted the UCI Mountain Bike & Trials World Championships ('The Worlds'). Also a trials competition is held, at the various courses at the bottom.
Winners of key men's downhill events at Fort William are:
Winners of key women's downhill events at Fort William are:
Winners of key women's 4-cross events at Fort William are:
Motorcycle trials.
Fort William is the home of the Scottish Six Day Motorcycle Trial (SSDT), held annually in the first full week of May. It attracts many competitors from all across the globe and in 2011 the event celebrated its centenary year.
Shinty.
Fort William has two major shinty teams, Fort William Shinty Club and Kilmallie Shinty Club.
Football.
The town also has a football team, Fort William F.C., competing in the Scottish Highland Football League. They play their home games at Claggan Park.
Rugby.
Fort William is the home of Lochaber Rugby Club.
Sailing.
The Lochaber Yacht Club on Achintore Road, Fort William is a Community Amateur Sports Club and was founded in 1954.
As a film location.
Movies filmed in or near Fort William include "Being Human", "Braveheart", "Highlander", "Restless Natives", "the Harry Potter series" and "Rob Roy". The TV series "Rockface" was filmed mainly around Fort William and some scenes of "Monarch of the Glen" were filmed around Lochaber although mostly near Newtonmore. "Local Hero" shot the internal Houston scenes in Fort William.
Festival.
In a celebration of mountains and the culture that surrounds them, and in recognition of the importance of climbing and walking tourism to the town, the Fort William Mountain Festival is held there each year. For a number of years, this volunteer-led festival has concentrated mostly around film but, starting in the Year of Highland Culture - Highland 2007, its scope was widened, and it dropped the word 'film' from its title.
Education.
Lochaber High School is the local high school and serves a large catchment area which includes the surrounding villages. The town itself is served by three primary schools, one of which is a Catholic school.

</doc>
<doc id="11515" url="http://en.wikipedia.org/wiki?curid=11515" title="List of French expressions in English">
List of French expressions in English

English contains many words of French origin, such as "art", "competition", "force", "machine", "money", "police", "publicity", "role", "routine", "table", and many other anglicized French words. These are pronounced according to English rules of phonology, rather than French. Around 45% of English vocabulary is of French origin, most coming from the Anglo-Norman spoken by the upper classes in England for several hundred years after the Norman Conquest, before the language settled into what became Modern English.
This article, however, covers words and phrases that generally entered the lexicon later, as through literature, the arts, diplomacy, and other cultural exchanges not involving conquests. As such, they have not lost their character as Gallicisms, or words that seem unmistakably foreign and "French" to an English speaker.
The phrases are given as used in English, and may seem correct modern French to English speakers, but may not be recognized as such by French speakers as many of them are now defunct or have drifted in meaning. A general rule is that, if the word or phrase retains French diacritics or is usually printed in italics, it has retained its French identity.
Few of these phrases are common knowledge to all English speakers, and for some English speakers most are rarely if ever used in daily conversation, but for other English speakers many of them are a routine part of both their conversational and their written vocabulary.
Used in English and French.
A.
The letter "y" is the place, as in "il y a" ("there is").
B.
 
C.
- A person who excels in cooking. 
- An award given to such a person.
- An international group of hospitality management and cooking schools teaching French cuisine, founded in France.
- An escalope of veal, chicken or pork stuffed with ham and cheese, then breaded and fried.
Example : "Besoin d'un coup de main ?" means "Need help ?"
F.
lit. "accomplished fact"; something that has already happened and is thus unlikely to be reversed, a done deal. In French used only in the expression "placer/mettre quelqu'un devant le fait accompli" meaning to present somebody with a fait accompli. Also see point of no return.
Not used as such in French.
Through the evolution of the language, many words and phrases are no longer used in modern French. Also there are expressions that, even though grammatically correct, do not have the same meaning in French as the English words derived from them. Some older word usages still appear in Quebec French.
French phrases in international air-sea rescue.
International authorities have adopted a number of words and phrases from French for use by speakers of all languages in voice communications during air-sea rescues. Note that the "phonetic" versions of spelling are presented as shown and not the .
It is a serious breach in most countries, and in international zones, to use any of these phrases without justification.
"See Mayday (distress signal) for a more detailed explanation."
See also.
See also: .

</doc>
<doc id="11516" url="http://en.wikipedia.org/wiki?curid=11516" title="Financial rand">
Financial rand

The South African financial rand was the most visible part of a system of capital controls. Although the financial rand was abolished in March 1995, the capital controls remain in place. These capital controls are locally referred to as "exchange controls". 
Capital controls have been in place in South Africa in various guises on an uninterrupted basis since the outbreak of World War II, when Great Britain and its dominions implemented the Sterling area. 
Following the 1960 Sharpeville massacre, South Africa experienced significant outflows of foreign exchange on the capital account of the balance of payments and instituted an additional level of capital controls, known as the Blocked Rand system. This had the principal effect of blocking outflows of capital to the other countries in the Sterling Area, notably Britain.
To some extent the Blocked Rand system mirrored Germany's Reichsbank system introduced under Hjalmar Schacht in 1937, called "aski" accounts—short for "Auslaender Sonderkonten fuer Inlandszahlungen" ("foreigners' special accounts for inland payments"). In other words creating a closed loop system that did not create a claim on the foreign exchange reserves of the Third Reich, or in this case South Africa.
The report of the De Kock Commission on Exchange Controls tabled in November 1978, proposed a gradual easing of exchange controls. This saw the replacement of the Blocked Rand by the Financial Rand in early 1979. In line with this policy, the Financial Rand itself was abolished in 1983 and non-residents could repatriate the majority of their South African investments via the Commercial Rand.
This easing was, however, short-lived and the Financial Rand system was re-introduced on 1 September 1985. The outflows during 1984–1985 were largely the result of economic sanctions in response to apartheid. At the same time, the government enacted the exchange controls. Investments in South African by foreigners could only be sold for financial rand.
The financial rand system provided for two exchange rates for the rand, one for current account transactions, and one for capital account transactions for non-residents. Investments made in South Africa by non-residents could only be sold for financial rand, and limitations were placed on the convertibility of financial rand into foreign currencies. Financial rand had the ISO 4217 currency code ZAL. The financial had a previous life, from January 1979 to February 1983. The 1985 crisis coincided with a default (then called a "standstill") on foreign debt by the apartheid government.

</doc>
<doc id="11517" url="http://en.wikipedia.org/wiki?curid=11517" title="List of FIPS country codes">
List of FIPS country codes

This is a list of FIPS 10-4 country codes for "Countries, Dependencies, Areas of Special Sovereignty, and Their Principal Administrative Divisions".
The two-letter country codes were used by the US government for geographical data processing in many publications, such as the CIA World Factbook. The standard is also known as DAFIF 0413 ed 7 Amdt. No. 3 (Nov 2003) and as DIA 65-18 (Defense Intelligence Agency, 1994, "Geopolitical Data Elements and Related Features").
The FIPS standard includes both the codes for independent countries (similar but sometimes incompatible with the ISO 3166-1 alpha-2 standard) and the codes for top-level subdivision of the countries (similar to but usually incompatible with the ISO 3166-2 standard). The ISO 3166 codes are used by the United Nations and for Internet top-level country code domains.
Non-sovereign entities are in italics.
On September 2, 2008, FIPS 10-4 was one of ten standards withdrawn by NIST as a Federal Information Processing Standard. It was replaced in the U.S. Government by the Geopolitical Entities, Names, and Codes (GENC), which is based on ISO 3166.
 
 * A
Resources.
The complete standard can be found at:
Updates to previous version of the standard (before FIPS-10 was withdrawn in September 2008) are at:
Updates to the standard since September 2008 are at:
External links.
Related websites

</doc>
<doc id="11519" url="http://en.wikipedia.org/wiki?curid=11519" title="Fair Isle">
Fair Isle

Fair Isle ("from Old Norse Friðarey; Scottish Gaelic Fara") is an island in northern Scotland, lying around halfway between mainland Shetland and the Orkney islands. It is famous for its bird observatory and a traditional style of knitting.
Geography.
Fair Isle is the most remote inhabited island in the United Kingdom. It is administratively part of Shetland and is roughly equidistant from Sumburgh Head some 38 km to the northeast on the Mainland of Shetland and North Ronaldsay, Orkney, some 43 km to the southwest. Fair Isle is 4.8 km in length and 2.4 km wide. It has an area of 768 hectares (3 square miles), making it the tenth largest of the Shetland Islands. It gives its name to one of the British Sea Areas.
The majority of the seventy islanders live in the crofts on the southern half of the island, with the northern half consisting of rocky moorland. The western coast consists of cliffs of up to 200 metres (660 feet) in height.
History.
Fair Isle has been occupied since the Bronze Age which is remarkable because of the lack of raw materials on the island, although it is surrounded by rich fishing waters. There are two known Iron Age sites - a promontory fort at Landberg and the foundations of a house underlying an early Christian settlement at Kirkigeo.
Most of the place-names date from after the ninth-century Norse settlement of the Northern Isles. By that time the croft lands had clearly been in use for many centuries.
On 20 August 1588 the flagship of the Spanish Armada, "El Gran Grifón", was shipwrecked in the cove of Stroms Heelor, forcing its 300 sailors to spend six weeks living with the islanders. The wreck was discovered in 1970. The large Canadian sailing ship "Black Watch" was wrecked on Fair Isle in 1877.
Fair Isle was bought by the National Trust for Scotland in 1954 from George Waterston, the founder of the bird observatory.
The population has been decreasing steadily from about 400 in 1900. There are currently around 70 permanent residents on the island, including the majority crofters who work the land. It has 14 scheduled monuments, ranging from the earliest signs of human activity to the remains of a Second World War radar station. The two automated lighthouses are protected as listed buildings.
The island houses a series of high-technology relay stations carrying vital TV, radio, telephone and military communication links between Shetland, Orkney and the Scottish mainland. In this respect it continues its historic role as a signal-station, linking the mainland and the more remote island systems. In 1976, when television relay equipment was updated to permit colour broadcasts to Shetland, the new equipment was housed in former World War Two radar station buildings on Fair Isle. Many television signals are relayed from Orkney to Shetland (rather than from the Scottish mainland) via Orkney's Keelylang Hill transmitter station.
Economy.
Over the centuries the island changed hands many times. Trading links with Northern Europe are reflected in Fair Isle Haa, a traditional Hanseatic trading booth located not far from the South Harbour, traditionally used by residents of the southern part of the island. Rent was usually paid to absentee landlords (who rarely visited) in butter, cloth and fish oil.
Fishing has always been an important industry for the island. In 1702, the Dutch, who were interested in Shetland's herring fisheries, fought a naval battle against the French warships just off the island.
Fair Isle is also famous for its woollen jumpers, with knitting forming an important source of income for the women of the islands. The principal activity for the male islanders is crofting.
In January 2004, Fair Isle was granted Fairtrade Island status.
Bird observatory.
Fair Isle has a permanent bird observatory, founded by George Waterston in 1948. Because of its importance as a bird migration watchpoint, it provides most of the accommodation on the island. The first director of the observatory was Kenneth Williamson. It is unusual amongst bird observatories in providing catered, rather than hostel-style, accommodation.
Many rare species of bird have been found on the island, and it is probably the best place in western Europe to see skulking Siberian passerines such as Pechora pipit, lanceolated warbler and Pallas's grasshopper warbler. In spring 2008 a calandra lark was identified in April, and in May a Caspian plover was observed, only the fourth such record for the UK. On 6 June a citril finch was found and identified by Islander Tommy Hyndman, a first record for Britain. September was highlighted by brown flycatcher, red-flanked bluetail and Siberian thrush.
Fair Isle can claim to be the best place to find rare birds in Britain with at least 27 first records. Spring 2009 started well with notable birds including white-tailed eagle, green-winged teal, red-rumped swallow and a brown-headed cowbird (second for Britain). The island is home to an endemic subspecies of Eurasian wren, the Fair Isle wren "Troglodytes troglodytes fridariensis".
Infrastructure.
There are no pubs or restaurants on the island, though meals are available for the public at the restaurant of the Bird Observatory, and its little bar is also open in the evening. There is one shop, and one school (see below). There is a community hall available for meetings and social events.
Electricity supply.
Since 1982, two thirds of the community's power has been supplied by wind turbines, and a third by diesel generators. 
The island has two electrical networks. Standard electricity service is provided on one network, and electric heating is delivered by a second set of cables. The electrical heating is mostly provided by excess electricity from the two wind turbines. Remote frequency-sensitive programmable relays control water heaters and storage heaters in the buildings of the community.
As Fair Isle is not connected to the national grid, electricity is provided by the Fair Isle Electricity Company. Power is generated by two diesel generators and two wind turbines. Diesel generators are automatically switched off if wind turbines provide sufficient power. Excess capacity is distributed through a separate network for home heating or if not enough energy can be dissipated through this, a dump load.
Communication.
Fair Isle is home to two GSM 900 MHz base stations operated by Vodafone and O2.
Emergency services.
Fair Isle has a fire station equipped with a single fire appliance, and staffed by a retained fire crew of local volunteers. It was originally part of the Highlands and Islands Fire and Rescue Service, which was absorbed into the national Scottish Fire and Rescue Service on 1 April 2013. A locally organised volunteer fire brigade was formed in 1996 by island residents. This was later absorbed into the statutory fire service, with professional training provided, and the local service designated a retained fire crew. The first purpose-built fire engine was stationed to the island in 2002. In October 2011 a contract for the construction of a £140,000 purpose-built fire station was awarded to Shetland company Ness Engineering, who completed the construction and equipping of the fire station, including its connection to the island power and water supplies, and the installation of a rain-water harvesting system within the building. The new fire station was officially opened on 14 March 2013.
There is a small Coastguard cliff-rescue team on the island. Like the fire service, the Coastguard is a retained (volunteer) emergency service. The Fair Isle Coastguard cliff rescue team were the first British Coastguard unit to be equipped with a quadbike. The quadbike is painted in H M Coastguard livery, with reflective Battenburg markings and has an optional equipment trailer.
There are no emergency medical services on Fair Isle. Routine medical care is provided by a community nurse. In the event of accident and emergency the community nurse provides first aid until casualties can be removed to Shetland Mainland, usually by fixed-wing air ambulance. In severe weather conditions the Coastguard helicopter can sometimes undertake medical evacuations when the air ambulance is grounded.
Transport.
Air.
Fair Isle Airport serves the island with flights to Tingwall Airport near Lerwick, and weekly to Sumburgh. Private aircraft use the facility and scheduled flights arrive twice daily, three days a week. There is a small terminal building, but facilities are otherwise very limited. Fire cover is provided by the island fire service.
There is also a helipad at the South Fair Isle lighthouse, for official use by the Northern Lighthouse Board and Coastguard helicopters.
Sea.
There are two main harbours (north harbour and south harbour), both formed naturally. The north harbour is the main route for goods, provisions, and Royal Mail postal services arriving at and departing from the island. The ferry "Good Shepherd IV" plies between Fair Isle north harbour and Grutness on Shetland Mainland.
Road.
A road network connects the populated areas of the island, along its full length.
Education.
Fair Isle has one primary school, with two classrooms. There is a full-time head teacher, and a part-time assistant teacher. The number of pupils varies over time, but is generally between 5 and 10. Islanders of secondary school age are generally educated off-island, on Shetland Mainland, where they board in halls of residence, returning to the island during holiday periods.
Religion.
Christianity is the only formally organised religion on Fair Isle. There are two churches, one Methodist, and one Church of Scotland (Presbyterian). The Methodist Church has a resident non-stipendiary minister, who reports to a full-time minister on Shetland Mainland. The Methodist Church was constructed in 1886. The Church of Scotland church was built in 1892.
Wartime military role.
During the Second World War, the Royal Air Force built a radar station on top of Ward Hill 712 ft during the battle of the Atlantic. The ruined buildings and nissen huts are still present.
On 17 January 1941, a German Heinkel He 111 bomber, modified as a meteorological aircraft, crashed on the island; wreckage remains on the crash-site to the present day.
The aircraft had been flying on a routine weather reconnaissance flights from its base at Oldenburg in Germany. It was intercepted by RAF Hawker Hurricane fighters from 3 Squadron, based at RAF Sumburgh; both of the aircraft's engines were damaged and several of the five crew were wounded. The pilot managed to make a crash-landing on Fair Isle to avoid ditching his crippled aircraft in the sea. Two crew died and three survived. The dead crew were buried in the island's churchyard; the survivors were detained by the islanders and remained for several days until weather conditions allowed them to be taken off the island by means of the Shetland Lifeboat.
Climate.
Fair Isle experiences an oceanic climate (Köppen "Cfb", bordering on a subpolar oceanic climate ("Cfc"), with cool summers and mild winters. This is especially pronounced due to its location far from any sizeable landmass; Fair Isle has the smallest overall temperature range (least continental) of any weather station in the British Isles: an absolute maximum of 20.2 C and an absolute minimum of -5.6 C since 1951. This 60+ year temperature span is actually smaller than many places in inland southern England will record within a given three-month period. 
The lowest temperature recorded in recent years was -4.6 C in February 2010. Rainfall, at under 1000 mm is lower than one might expect for somewhere often in the main path of Atlantic depressions. This is explained by a lack of heavy convective rainfall during spring and summer months due to the absence of warm surface conditions.
Fair Isle's ocean moderation is so strong that areas on the same latitudes in the Scandinavian inland less than 1000 kilometres to the east have average summer highs 2–3 degrees higher than Fair Isle's all-time record heat, for example the Norwegian capital of Oslo and the Swedish capital of Stockholm. The –5 all-time low is uniquely mild for European locations on the 59th parallel north. The winter daily means are comparable to many areas as far south in the British Isles as south-central England, due to the extreme maritime moderation.

</doc>
<doc id="11520" url="http://en.wikipedia.org/wiki?curid=11520" title="Four Feather Falls">
Four Feather Falls

Four Feather Falls was the third puppet TV show produced by Gerry Anderson for Granada Television. It was based on an idea by Barry Gray, who also wrote the show's music. The series was the first to use an early version of Anderson's Supermarionation puppetry. Thirty-nine 13-minute episodes were produced, broadcast by Granada from February until November 1960. The setting is the late 19th-century fictional Kansas town of Four Feather Falls, where the hero of the series, Tex Tucker, is a sheriff. The four feathers of the title refers to four magical feathers given to Tex by the Indian chief Kalamakooya as a reward for saving his grandson: two allowed Tex's guns to swivel and fire without being touched whenever he was in danger, and two conferred the power of speech on Tex's horse and dog.
Tex's speaking voice was provided by Nicholas Parsons, and his singing voice by Michael Holliday. The series has never been repeated on British television, but it was released on DVD in 2005.
Production.
American Western television shows such as "Wagon Train" and "Gunsmoke" were popular with British audiences, therefore Gerry Anderson and his business partner Arthur Provis decided to make a cowboy series, based on an idea offered to them by Barry Gray. Anderson considered the puppets with static heads, made by Christine Glanville for his earlier productions, to be unacceptable because the viewer could not tell which character was talking unless its puppet moved up or down. Anderson's aim was to make the puppets look as realistic as possible, the beginning of the Supermarionation puppetry process, although that term was not coined until his next series, "Supercar".
The puppets' papier-mâché heads were replaced by interchangeable hollow fibre glass heads with internal rods that could move the eyes from side to side. The heads also contained sound-activated solenoids, which allowed the puppets' lips to move automatically in synchronisation with the dialogue. The electronics of the day required more space than would be available in a human-scale head, therefore all the puppets in "Four Feather Falls" had oversized heads.
Except for the pilot episode, which was made in AP Films' studios at Islet Park, the series was produced in a converted warehouse in the Slough Trading Estate. The cast assembled to record each script without seeing the puppets, much like recording a radio series; synchronisation of each character's speech with the movement of its puppet's mouth was performed later. The show was filmed in black and white. Its tight budget precluded the use of sophisticated special effects, and less-costly alternatives were used. For example, to achieve the effect of muzzle flashes, small specks of black paint were carefully applied to the 35 mm negatives so they would appear as white flashes on the finished prints. The wires used to control the puppets were eight feet long and made of tungsten, an improvement on the curtain wire used in the two earlier series, and were only 1/200 of an inch thick. Being shiny, the wires had to be blackened. The puppets were made one-third life size with the puppeteers on a bridge eight feet above the set. The horses moved by being pulled along on a trolley, which meant the viewer never saw their feet when they were moving.
Continuity for the series was provided by Sylvia Thamm who married Gerry Anderson.
Plot.
The series is set in the fictitious late 19th-century Western town of Four Feather Falls, Kansas, and features the adventures of its sheriff, Tex Tucker. In the first episode, Grandpa Twink relates the story of how it all began to grandson, Little Jake. Tex is riding up from the valley and comes across a lost and hungry Indian boy, Makooya and saves him. Tex is given four magic feathers by the boy's grandfather, chief Kalamakooya, as a reward for saving his grandson. Two of the feathers allow his guns to swivel and fire automatically (often while Tex's hands are raised), and the other two allow his horse, Rocky, and his dog, Dusty, to speak. As Tex, his horse, and dog are very thirsty, Kalamakooya also makes a waterfall where there had been no water before, and so when the town was built it was named after Tex's feathers and the waterfall.
The characters of the town are Grandpa Twink, who does little but rest in a chair; his grandson Little Jake, the only child in town; Ma Jones, who runs the town store; Doc Haggerty; Slim Jim, the bartender of the Denison saloon; Marvin Jackson, the bank manager; and Dan Morse, the telegraphist. Other characters appeared from time to time for only one episode, often just visiting town. The villains included Pedro, who was introduced in the first show and Fernando, who first appeared in the second episode as a sidekick and someone Pedro could blame when things went wrong, as they always did. Big Ben was another villain who appeared from time to time, as did Red Scalp, a renegade Indian. Other villains only appeared in single episodes.
Episodes List.
Only one series of 39 episodes was produced:
Syndication.
The series has not been repeated or rerun in Britain since its original broadcast. In December 2004 it was announced that the rights had been acquired by Network Distributing, and it was released on three Region 2 DVDs in May 2005. It is the only Supermarionation series not yet released to DVD in North America as of January 2006. Sylvia Anderson wrote two British children's annuals based on the show, published by Collins in 1960 and 1961. The first book featured a short text story based on the pilot episode of the TV series.
In Pop Culture.
The fictional TV show Woody's Roundup from the 1999 Disney Pixar film Toy Story 2 was inspired by Four Feather Falls.
Music.
The show's music and song lyrics were composed by Barry Gray. Michael Holliday provided Tex's singing voice, and Tommy Reilly performed the harmonica pieces. The best known song to come out of the series was "Four Feather Falls", sung in some episodes by Michael Holliday in the style of Bing Crosby and sometimes incorrectly described as the theme song to the series. The closing theme song was "Two Gun Tex of Texas." Holliday was paid £2000 for his singing work on the pilot episode, equivalent to about £38,000 as of 2010, a significant part of the show's £6000 budget. In all, Holliday recorded six songs for the series: "Four Feather Falls", "The Phantom Rider", "The Rick-Rick-A-Rackety Train", "Happy Hearts and Friendly Faces", "My Home Town", and "Two Gun Tex of Texas".
Cast.
Denise Bryer had worked with Anderson on "The Adventures of Twizzle", and he wanted her to play some of the voices in "Four Feather Falls". Anderson visited Bryer at her home with some scripts and asked her husband, Nicholas Parsons, to help by reading some of the other parts, including the sheriff Tex Tucker. Anderson liked Parsons' interpretation and offered him the job of providing Tex's speaking voice.
References.
Notes
Citations
Bibliography
</dl>

</doc>
<doc id="11522" url="http://en.wikipedia.org/wiki?curid=11522" title="Fly-by-wire">
Fly-by-wire

Fly-by-wire (FBW) is a system that replaces the conventional manual flight controls of an aircraft with an electronic interface. The movements of flight controls are converted to electronic signals transmitted by wires (hence the fly-by-wire term), and flight control computers determine how to move the actuators at each control surface to provide the ordered response. The fly-by-wire system also allows automatic signals sent by the aircraft's computers to perform functions without the pilot's input, as in systems that automatically help stabilize the aircraft, or prevent unsafe operation of the aircraft outside of its performance envelope.
Development.
Mechanical and hydro-mechanical flight control systems are relatively heavy and require careful routing of flight control cables through the aircraft by systems of pulleys, cranks, tension cables and hydraulic pipes. Both systems often require redundant backup to deal with failures, which increases weight. Both have limited ability to compensate for changing aerodynamic conditions. Dangerous characteristics such as stalling, spinning and pilot-induced oscillation (PIO), which depend mainly on the stability and structure of the aircraft concerned rather than the control system itself, can still occur with these systems.
The term "fly-by-wire" implies a purely electrically signaled control system. It is used in the general sense of computer-configured controls, where a computer system is interposed between the operator and the final control actuators or surfaces. This modifies the manual inputs of the pilot in accordance with control parameters.
Side-sticks, centre sticks, or conventional flight control yokes can be used to fly FBW aircraft.
Basic operation.
Command.
Fly-by wire systems are quite complex, but their operation can be explained in simple terms. When a pilot moves the control column (or sidestick), a signal is sent to a computer (analogous to moving a game controller) the signal is sent through multiple wires (channels) to ensure that the signal reaches the computer. A 'Triplex' is when there are three channels being used. In an Analog system, the computer receives the signals, performs a calculation (adds the signal voltages and divides by the number of signals received to find the mean average voltage) and adds another channel. These four 'Quadruplex' signals are then sent to the control surface actuator, and the surface begins to move. Potentiometers in the actuator send a signal back to the computer (usually a negative voltage) reporting the position of the actuator. When the actuator reaches the desired position, the two signals (incoming and outgoing) cancel each other out and the actuator stops moving (completing a feedback loop). In a Digital Fly By Wire Flight Control System complex software interprets digital signals from the pilots control input sensors and performs calculations based on the Flight Control Laws programmed into the Flight Control Computers and input from the Air Data Inertial Reference Units and other sensors. The computer then commands the flight control surfaces to adopt a configuration that will achieve the desired flight path. 
Automatic stability systems.
Fly-by-wire control systems allow aircraft computers to perform tasks without pilot input. Automatic stability systems operate in this way. Gyroscopes fitted with sensors are mounted in an aircraft to sense movement changes in the pitch, roll and yaw axes. Any movement (from straight and level flight for example) results in signals to the computer, which automatically moves control actuators to stabilize the aircraft.
Safety and redundancy.
Aircraft systems may be quadruplexed (four independent channels) to prevent loss of signals in the case of failure of one or even two channels. High performance aircraft that have fly-by-wire controls (also called CCVs or Control-Configured Vehicles) may be deliberately designed to have low or even negative stability in some flight regimes, the rapid-reacting CCV controls compensating for the lack of natural stability.
Pre-flight safety checks of a fly-by-wire system are often performed using built-in test equipment (BITE). On programming the system, either by the pilot or groundcrew, a number of control movement steps are automatically performed. Any failure will be indicated to the crews.
Some aircraft, the Panavia Tornado for example, retain a very basic hydro-mechanical backup system for limited flight control capability on losing electrical power; in the case of the Tornado this allows rudimentary control of the stabilators only for pitch and roll axis movements.
Weight saving.
A FBW aircraft can be lighter than a similar design with conventional controls. This is partly due to the lower overall weight of the system components, and partly because the natural stability of the aircraft can be relaxed, slightly for a transport aircraft and more for a maneuverable fighter, which means that the stability surfaces that are part of the aircraft structure can therefore be made smaller. These include the vertical and horizontal stabilizers (fin and tailplane) that are (normally) at the rear of the fuselage. If these structures can be reduced in size, airframe weight is reduced. The advantages of FBW controls were first exploited by the military and then in the commercial airline market. The Airbus series of airliners used full-authority FBW controls beginning with their A320 series, see A320 flight control (though some limited FBW functions existed on A310). Boeing followed with their 777 and later designs.
Electronic fly-by-wire systems can respond flexibly to changing aerodynamic conditions, by tailoring flight control surface movements so that aircraft response to control inputs is appropriate to flight conditions. Electronic systems require less maintenance, whereas mechanical and hydraulic systems require lubrication, tension adjustments, leak checks, fluid changes, etc. Placing circuitry between pilot and aircraft can enhance safety. For example, the control system can try to prevent a stall, or it can stop the pilot from over stressing the airframe.
The main concern with fly-by-wire systems is reliability. While traditional mechanical or hydraulic control systems usually fail gradually, the loss of all flight control computers could immediately render the aircraft uncontrollable. For this reason, most fly-by-wire systems incorporate either redundant computers (triplex, quadruplex etc.), some kind of mechanical or hydraulic backup or a combination of both. A "mixed" control system such as the latter is not desirable and modern FBW aircraft normally avoid it by having more independent FBW channels, thereby reducing the possibility of overall failure to minuscule levels that are acceptable to the independent regulatory and safety authority responsible for aircraft design, testing and certification before operational service.
History.
Electronic signalling of the control surfaces was first tested in the 1930s, on the Soviet Tupolev ANT-20. This replaced long runs of mechanical and hydraulic connections with electrical ones.
The first pure electronic fly-by-wire aircraft with no mechanical or hydraulic backup was the Apollo Lunar Landing Research Vehicle (LLRV), first flown in 1964.
The first non-experimental aircraft that was designed and flown (in 1958) with a fly-by-wire flight control system was the Avro Canada CF-105 Arrow, a feat not repeated with a production aircraft until Concorde in 1969. This system also included solid-state components and system redundancy, was designed to be integrated with a computerised navigation and automatic search and track radar, was flyable from ground control with data uplink and downlink, and provided artificial feel (feedback) to the pilot.
In the UK the two seater Avro 707B was flown with a Fairey system with mechanical backup in the early to mid-60s. The programme was curtailed when the airframe ran out of flight time.
The first digital fly-by-wire fixed-wing aircraft without a mechanical backup to take to the air (in 1972) was an F-8 Crusader, which had been modified electronically by NASA of the United States as a test aircraft. This was preceded in 1964 by the LLRV which pioneered fly-by-wire flight with no mechanical backup. Control was through a digital computer with three analogue backup channels. In the USSR the Sukhoi T-4 also flew. At about the same time in the United Kingdom a trainer variant of the British Hawker Hunter fighter was modified at the British Royal Aircraft Establishment with fly-by-wire flight controls for the right-seat pilot. This was test-flown, with the left-seat pilot having conventional flight controls for safety reasons, and with the capability for him to override and turn off the fly-by-wire system. It flew in April 1972.
Analog systems.
All "fly-by-wire" flight control systems eliminate the complexity, the fragility, and the weight of the mechanical circuit of the hydromechanical or electromechanical flight control systems. Fly-by-wire replace those with electronic circuits. The control mechanisms in the cockpit now operate signal transducers, which in turn generate the appropriate electronic commands. These are next processed by an electronic controller, either an analog one, or more modernly, a digital one. Aircraft and spacecraft autopilots are now part of the electronic controller.
The hydraulic circuits are similar except that mechanical servo valves are replaced with electrically controlled servo valves, operated by the electronic controller. This is the simplest and earliest configuration of an analog fly-by-wire flight control system. In this configuration, the flight control systems must simulate "feel". The electronic controller controls electrical feel devices that provide the appropriate "feel" forces on the manual controls. This was used in Concorde, the first production fly-by-wire airliner.
In more sophisticated versions, analog computers replaced the electronic controller. The canceled 1950s Canadian supersonic interceptor, the Avro Canada CF-105 Arrow, employed this type of system. Analog computers also allowed some customization of flight control characteristics, including relaxed stability. This was exploited by the early versions of F-16, giving it impressive maneuverability.
Digital systems.
A digital fly-by-wire flight control system is similar to its analog counterpart. However, the signal processing is done by digital computers and the pilot literally can "fly-via-computer". This also increases the flexibility of the flight control system, since the digital computers can receive input from any aircraft sensor (such as the altimeters and the pitot tubes). This also increases the electronic stability, because the system is less dependent on the values of critical electrical components in an analog controller.
The computers sense position and force inputs from pilot controls and aircraft sensors. They solve differential equations to determine the appropriate command signals that move the flight controls to execute the intentions of the pilot.
The programming of the digital computers enable flight envelope protection. In this aircraft designers precisely tailor an aircraft's handling characteristics, to stay within the overall limits of what is possible given the aerodynamics and structure of the aircraft. For example, the computer in flight envelope protection mode can try to prevent the aircraft from being handled dangerously by preventing pilots from exceeding preset limits on the aircraft's flight-control envelope, such as those that prevent stalls and spins, and which limit airspeeds and g forces on the airplane. Software can also be included that stabilize the flight-control inputs to avoid pilot-induced oscillations.
Since the flight-control computers continuously "fly" the aircraft, pilot's workloads can be reduced. Also, in military and naval applications, it is now possible to fly military aircraft that have relaxed stability. The primary benefit for such aircraft is more maneuverability during combat and training flights, and the so-called "carefree handling" because stalling, spinning and other undesirable performances are prevented automatically by the computers.
Digital flight control systems enable inherently unstable combat aircraft, such as the Lockheed F-117 Nighthawk and the Northrop Grumman B-2 Spirit flying wing to fly in usable and safe manners.
Legislation.
The Federal Aviation Administration (FAA) of the United States has adopted the RTCA/DO-178B, titled "Software Considerations in Airborne Systems and Equipment Certification", as the certification standard for aviation software. Any safety-critical component in a digital fly-by-wire system including applications of the laws of aeronautics and computer operating systems will need to be certified to DO-178B Level A, which is applicable for preventing potential catastrophic failures.
Nevertheless, the top concern for computerized, digital, fly-by-wire systems is reliability, even more so than for analog electronic control systems. This is because the digital computers that are running software are often the only control path between the pilot and aircraft's flight control surfaces. If the computer software crashes for any reason, the pilot may be unable to control an aircraft. Hence virtually all fly-by-wire flight control systems are either triply or quadruply redundant in their computers and electronics. These have three or four flight-control computers operating in parallel, and three or four separate data buses connecting them with each control surface.
Redundancy.
If one of the flight-control computers crashes, or is damaged in combat, or suffers from "insanity" caused by electromagnetic pulses, the others overrule the faulty one (or even two of them), they continue flying the aircraft safely, and they can either turn off or re-boot the faulty computers. Any flight-control computer whose results disagree with the others is ruled to be faulty, and it is either ignored or re-booted. (In other words, it is voted-out of control by the others.)
In addition, most of the early digital fly-by-wire aircraft also had an analog electrical, a mechanical, or a hydraulic back-up flight control system. The Space Shuttle has, in addition to its redundant set of four digital computers running its primary flight-control software, a fifth back-up computer running a separately developed, reduced-function, software flight-control system – one that can be commanded to take over in the event that a fault ever affects all of the computers in the other four. This back-up system serves to reduce the risk of total flight-control-system failure ever happening because of a general-purpose flight software fault that has escaped notice in the other four computers.
For airliners, flight-control redundancy improves their safety, but fly-by-wire control systems also improve economy in flight because they are lighter, and they eliminate the need for many mechanical, and heavy, flight-control mechanisms. Furthermore, most modern airliners have computerized systems that control their jet engine throttles, air inlets, fuel storage and distribution system, in such a way to minimize their consumption of jet fuel. Thus, digital control systems do their best to reduce the cost of flights.
Airbus/Boeing.
Airbus and Boeing commercial airplanes differ in their approaches in using fly-by-wire systems. In Airbus airliners, the flight-envelope control system always retains ultimate flight control when flying under normal law, and it will not permit the pilots to fly outside these performance limits unless flying under alternate law. However, in the event of multiple failures of redundant computers, the A320 does have a mechanical back-up system for its pitch trim and its rudder. The A340-600 has a purely electrical (not electronic) back-up rudder control system, and beginning with the new A380 airliner, all flight-control systems have back-up systems that are purely electrical through the use of a so-called "three-axis Backup Control Module" (BCM)
With the Boeing 777 model airliners, the two pilots can completely override the computerized flight-control system to permit the aircraft to be flown beyond its usual flight-control envelope during emergencies. Airbus's strategy, which began with the Airbus A320, has been continued on subsequent Airbus airliners.
Engine digital control.
The advent of FADEC (Full Authority Digital Engine Control) engines permits operation of the flight control systems and autothrottles for the engines to be fully integrated. On modern military aircraft other systems such as autostabilization, navigation, radar and weapons system are all integrated with the flight control systems. FADEC allows maximum performance to be extracted from the aircraft without fear of engine misoperation, aircraft damage or high pilot workloads.
In the civil field, the integration increases flight safety and economy. The Airbus A320 and its fly-by-wire brethren are protected from dangerous situations such as low-speed stall or overstressing by flight envelope protection. As a result, in such conditions, the flight control systems commands the engines to increase thrust without pilot intervention. In economy cruise modes, the flight control systems adjust the throttles and fuel tank selections more precisely than all but the most skillful pilots. FADEC reduces rudder drag needed to compensate for sideways flight from unbalanced engine thrust. On the A330/A340 family, fuel is transferred between the main (wing and center fuselage) tanks and a fuel tank in the horizontal stabilizer, to optimize the aircraft's center of gravity during cruise flight. The fuel management controls keep the aircraft's center of gravity accurately trimmed with fuel weight, rather than drag-inducing aerodynamic trims in the elevators.
Further developments.
Fly-by-optics.
Fly-by-optics is sometimes used instead of fly-by-wire because it offers a higher data transfer rate, immunity to electromagnetic interference, and lighter weight. In most cases, the cables are just changed from electrical to optical fiber cables. Sometimes it is referred to as "fly-by-light" due to its use of fiber optics. The data generated by the software and interpreted by the controller remain the same.
Power-by-wire.
Having eliminated the mechanical transmission circuits in fly-by-wire flight control systems, the next step is to eliminate the bulky and heavy hydraulic circuits. The hydraulic circuit is replaced by an electrical power circuit. The power circuits power electrical or self-contained electrohydraulic actuators that are controlled by the digital flight control computers. All benefits of digital fly-by-wire are retained.
The biggest benefits are weight savings, the possibility of redundant power circuits and tighter integration between the aircraft flight control systems and its avionics systems. The absence of hydraulics greatly reduces maintenance costs. This system is used in the Lockheed Martin F-35 Lightning II and in Airbus A380 backup flight controls. The Boeing 787 will also incorporate some electrically operated flight controls (spoilers and horizontal stabilizer), which will remain operational with either a total hydraulics failure and/or flight control computer failure.
Fly-by-wireless.
Wiring adds a considerable amount of weight to an aircraft; therefore, researchers are exploring implementing fly-by-wireless solutions. Fly-by-wireless systems are very similar to fly-by-wire systems, however, instead of using a wired protocol for the physical layer a wireless protocol is employed.
In addition to reducing weight, implementing a wireless solution has the potential to reduce costs throughout an aircraft's life cycle. For example, many key failure points associated with wire and connectors will be eliminated thus hours spent troubleshooting wires and connectors will be reduced. Furthermore, engineering costs could potentially decrease because less time would be spent on designing wiring installations, late changes in an aircraft's design would be easier to manage, etc.
Intelligent flight control system.
A newer flight control system, called intelligent flight control system (IFCS), is an extension of modern digital fly-by-wire flight control systems. The aim is to intelligently compensate for aircraft damage and failure during flight, such as automatically using engine thrust and other avionics to compensate for severe failures such as loss of hydraulics, loss of rudder, loss of ailerons, loss of an engine, etc. Several demonstrations were made on a flight simulator where a Cessna-trained small-aircraft pilot successfully landed a heavily damaged full-size concept jet, without prior experience with large-body jet aircraft. This development is being spearheaded by NASA Dryden Flight Research Center. It is reported that enhancements are mostly software upgrades to existing fully computerized digital fly-by-wire flight control systems.
Accidents.
In the crash of Indonesia AirAsia Flight 8501, the Flight Augmentation Computer, which is a part of the fly-by-wire system in Airbus aircraft, was one of the focuses of investigation. The computer was suffering from maintenance faults over a week before it was suggested that after trying to reset this device, pilots pulled a circuit-breaker to cut its power moments before its crash.

</doc>
<doc id="11523" url="http://en.wikipedia.org/wiki?curid=11523" title="Falklands War">
Falklands War

The Falklands War (Spanish: "Guerra de las Malvinas"), also known as the Falklands Conflict, Falklands Crisis, and the "Guerra del Atlántico Sur" (Spanish for "South Atlantic War"), was a ten-week war between Argentina and the United Kingdom over two British overseas territories in the South Atlantic: the Falkland Islands and South Georgia and the South Sandwich Islands. It began on Friday 2 April 1982 when Argentina invaded and occupied the Falkland Islands (and, the following day, South Georgia and the South Sandwich Islands) in an attempt to establish the sovereignty it had long claimed over them. On 5 April, the British government dispatched a naval task force to engage the Argentine Navy and Air Force before making an amphibious assault on the islands. The conflict lasted 74 days and ended with the Argentine surrender on 14 June 1982, returning the islands to British control. In total, 649 Argentine military personnel, 255 British military personnel, and three Falkland Islanders died during the hostilities.
The conflict was the most serious and violent episode in the protracted confrontation over the territories' sovereignty. Argentina asserted (and maintains to this day) that the islands are Argentinian territory, and the Argentine government thus characterised its military action as the reclamation of its own territory. The British government regarded the action as an invasion of a territory that had been a Crown colony since 1841. Falkland Islanders, who have inhabited the islands since the early 19th century, are predominantly descendants of British settlers, and favour British sovereignty. Neither state, however, officially declared war (both sides did declare the Islands areas a war zone and officially recognised that a state of war existed between them) and hostilities were almost exclusively limited to the territories under dispute and the area of the South Atlantic where they lie.
The conflict has had a strong impact in both countries and has been the subject of various books, articles, films, and songs. Patriotic sentiment ran high in Argentina, but the outcome prompted large protests against the ruling military government, hastening its downfall. In the United Kingdom, the Conservative Party government, bolstered by the successful outcome, was re-elected the following year. The cultural and political weight of the conflict has had less effect in Britain than in Argentina, where it remains a continued topic for discussion.
Relations between the United Kingdom and Argentina were restored in 1989 following a meeting in Madrid, Spain, at which the two countries' governments issued a joint statement. No change in either country's position regarding the sovereignty of the Falkland Islands was made explicit. In 1994, Argentina's claim to the territories was added to its constitution.
Lead-up to the conflict.
In the period leading up to the war – and, in particular, following the transfer of power between the military dictators General Jorge Rafael Videla and General Roberto Eduardo Viola late in March 1981 – Argentina had been in the midst of a devastating economic stagnation and large-scale civil unrest against the military "junta" that had been governing the country since 1976. In December 1981 there was a further change in the Argentine military regime bringing to office a new "junta" headed by General Leopoldo Galtieri (acting president), Brigadier Basilio Lami Dozo and Admiral Jorge Anaya. Anaya was the main architect and supporter of a military solution for the long-standing claim over the islands, calculating that the United Kingdom would never respond militarily.
By opting for military action, the Galtieri government hoped to mobilise the long-standing patriotic feelings of Argentines towards the islands, and thus divert public attention from the country's chronic economic problems and the regime's ongoing human rights violations. Such action would also bolster its dwindling legitimacy. The newspaper "La Prensa" speculated in a step-by-step plan beginning with cutting off supplies to the Islands, ending in direct actions late in 1982, if the UN talks were fruitless.
The ongoing tension between the two countries over the islands increased on 19 March when a group of Argentine scrap metal merchants (actually infiltrated by Argentine marines) raised the Argentine flag at South Georgia, an act that would later be seen as the first offensive action in the war. The Royal Navy ice patrol vessel HMS "Endurance" was dispatched from Stanley to South Georgia in response, subsequently leading to the invasion of South Georgia by Argentine forces on 3 April. The Argentine military junta, suspecting that the UK would reinforce its South Atlantic Forces, ordered the invasion of the Falkland Islands to be brought forward to 2 April.
Britain was initially taken by surprise by the Argentine attack on the South Atlantic islands, despite repeated warnings by Royal Navy captain Nicholas Barker and others. Barker believed that Defence Secretary John Nott's 1981 review (in which Nott described plans to withdraw the "Endurance", Britain's only naval presence in the South Atlantic) sent a signal to the Argentines that Britain was unwilling, and would soon be unable, to defend its territories and subjects in the Falklands.
Argentine invasion.
On 2 April 1982, The Argentine forces mounted amphibious landings off the Falkland Islands, following the civilian occupation of South Georgia on 19 March, before the Falklands War began. The invasion was met with a nominal defence organised by the Falkland Islands' Governor Sir Rex Hunt, giving command to Major Mike Norman of the Royal Marines. The events of the invasion included the landing of Lieutenant Commander Guillermo Sanchez-Sabarots' Amphibious Commandos Group, the attack on Moody Brook barracks, the engagement between the troops of Hugo Santillan and Bill Trollope at Stanley, and the final engagement and surrender at Government House.
Initial British response.
Word of the invasion first reached Britain from Argentine sources. A Ministry of Defence operative in London had a short telex conversation with Governor Hunt's telex operator, who confirmed that Argentines were on the island and in control. Later that day, BBC journalist Laurie Margolis was able to speak with an islander at Goose Green via amateur radio, who confirmed the presence of a large Argentine fleet and that Argentine forces had taken control of the island. "Operation Corporate" was the codename given to the British military operations in the Falklands War. The commander of task force operations was Admiral Sir John Fieldhouse. Operations lasted from 1 April 1982 to 20 June 1982.
The British undertook a series of military operations as a means of recapturing the Falklands from Argentine occupation. The British government had taken action prior to the 2 April invasion. In response to events on South Georgia the submarines HMS "Splendid" and HMS "Spartan" were ordered to sail south on 29 March, whilst the stores ship Royal Fleet Auxiliary (RFA) "Fort Austin" was dispatched from the Western Mediterranean to support HMS "Endurance". Lord Carrington had wished to send a third submarine but the decision was deferred due to concerns about the impact on operational commitments. Coincidentally on 26 March, the submarine HMS "Superb" left Gibraltar and it was assumed in the press it was heading south. There has since been speculation that the effect of those reports was to panic the Argentine junta into invading the Falklands before nuclear submarines could be deployed.
The following day, during a crisis meeting headed by the Prime Minister Margaret Thatcher, the Chief of the Naval Staff, Admiral Sir Henry Leach, advised them that "Britain could and should send a task force if the islands are invaded". On 1 April Leach sent orders to a Royal Navy force carrying out exercises in the Mediterranean to be prepared to sail south. Following the invasion on 2 April, after an emergency meeting of the cabinet, approval was given for the formation of a task force to retake the islands. This was backed in an emergency session of the House of Commons the next day.
On 6 April, the British Government set up a War Cabinet to provide day-to-day political oversight of the campaign. This was the critical instrument of crisis management for the British with its remit being to "keep under review political and military developments relating to the South Atlantic, and to report as necessary to the Defence and Overseas Policy Committee." Until it was dissolved on 12 August, the War Cabinet met at least daily. Although Margaret Thatcher is described as dominating the War Cabinet, Lawrence Freedman notes in the "Official History of the Falklands Campaign" that she did not ignore opposition or fail to consult others. However, once a decision was reached she "did not look back".
Position of third party countries.
On the evening of 3 April, the United Kingdom's United Nations ambassador Sir Anthony Parsons put a draft resolution to the United Nations Security Council. The resolution, which condemned the hostilities and demanded immediate Argentine withdrawal from the Islands, was adopted by the council the following day as United Nations Security Council Resolution 502, which passed with ten votes in support, one against (Panama) and four abstentions (China, the Soviet Union, Poland and Spain). The UK received further political support from the Commonwealth of Nations and the European Economic Community. The EEC also provided economic support by imposing economic sanctions on Argentina. Argentina itself was politically backed by a majority of countries in Latin America and some members of the Non-Aligned Movement. On 20 May 1982 the Prime Minister of New Zealand, Rob Muldoon, announced that he would make HMNZS "Canterbury", a Leander class frigate, available for use where the British thought fit to release a Royal Navy vessel for the Falklands.
The war was an unexpected event in a world strained by the Cold War and the North–South divide. The response of some countries was the effort to mediate the crisis and later as the war began, the support (or criticism) based in terms of anti-colonialism, political solidarity, historical relationships or realpolitik. In other cases it was only verbal support.
The United States was concerned by the prospect of Argentina turning to the Soviet Union for support, and initially tried to mediate an end to the conflict. However, when Argentina refused the US peace overtures, US Secretary of State Alexander Haig announced that the United States would prohibit arms sales to Argentina and provide material support for British operations. Both Houses of the US Congress passed resolutions supporting the US action siding with the United Kingdom.
The US provided the United Kingdom with military equipment ranging from submarine detectors to the latest missiles. President Ronald Reagan approved the Royal Navy's request to borrow the Sea Harrier-capable amphibious assault ship if the British lost an aircraft carrier. The United States Navy developed a plan to help the British man the ship with American military contractors, likely retired sailors with knowledge of the "Iwo Jima"‍ '​s systems. France provided dissimilar aircraft training so Harrier pilots could train against the French aircraft used by Argentina. French and British intelligence also worked to prevent Argentina from obtaining more Exocet missiles on the international market, while at the same time Peru attempted to purchase 12 missiles for Argentina, in a failed secret operation. Chile gave support to Britain in the form of intelligence about Argentine military and early warning radar. Throughout the war, Argentina was afraid of a Chilean military intervention in Patagonia and kept some of her best mountain regiments away from the Falklands near the Chilean border as a precaution.
In recent years it has become known that a listening post located in Fauske, Norway was vital in giving the British intelligence information regarding Argentinian fleet locations. The listening post was designated Fauske II by Norway. The information was "stolen" from Soviet spy satellites which were the only space assets having the South Atlantic under coverage. Western powers such as the United States and the UK did not have their own satellite presence in this area at the time. A high ranking British military source claimed that the intelligence the British got from the Fauske II post as "Incredibly vital":
When the war broke out, we had almost no intelligence information from this area. It was here we got help from the Norwegians, who gave us a stream of information about the Argentinian warships positions. The information came to us all the time and straight to our war headquarters at Northwood. The information was continuously updated and told us exactly where the Argentinian ships were.
While France overtly backed the United Kingdom, a French technical team remained in Argentina throughout the war. French government sources have said the French team was engaged in intelligence-gathering; however, it simultaneously provided direct material support to the Argentines, identifying and fixing faults in Exocet missile launchers. According to the book "Operation Israel", advisers from Israel Aerospace Industries were already in Argentina and continued their work during the conflict. The book also claims that Israel sold weapons and drop tanks in a secret operation in Peru. Peru also openly sent "Mirages, pilots and missiles" to Argentina during the war. Peru had earlier transferred ten Hercules transport planes to Argentina soon after the British Task Force had set sail in April 1982. Nick van der Bijl records that after the Argentine defeat at Goose Green, Venezuela and Guatemala offered to send paratroops to the Falklands. Through Libya, under Muammar Gaddafi, Argentina received 20 launchers and 60 SA-7 missiles, as well as machine guns, mortars and mines; all in all, the load of four trips of two Boeing 707 of the AAF, refuelled in Recife with the knowledge and consent of the Brazilian government. Some of these clandestine logistics operations were mounted by the Soviet Union.
British Task Force.
The British government had no contingency plan for an invasion of the islands, and the task force was rapidly put together from whatever vessels were available. The nuclear submarine "Conqueror" set sail from France on 4 April, whilst the two aircraft carriers "Invincible" and "Hermes", in the company of escort vessels, left Portsmouth only a day later. Upon its return to Southampton from a world cruise on 7 April, the ocean liner was requisitioned and set sail two days later with 3 Commando Brigade aboard. The ocean liner "Queen Elizabeth 2" was also requisitioned and left Southampton on 12 May with 5th Infantry Brigade on board. The whole task force eventually comprised 127 ships: 43 Royal Navy vessels, 22 Royal Fleet Auxiliary ships and 62 merchant ships.
The retaking of the Falkland Islands was considered extremely difficult: the main constraint being the disparity in deployable air cover. The British had a total of 42 aircraft (28 Sea Harriers and 14 Harrier GR.3s) available for air combat operations, against approximately 122 serviceable jet fighters, of which about 50 were employed as air superiority fighters and the remainder as strike aircraft, in Argentina's air forces during the war. The US Navy considered a successful counter-invasion by the British to be "a military impossibility".
By mid-April, the Royal Air Force had set up the airbase of RAF Ascension Island, co-located with Wideawake Airfield (USA) on the mid-Atlantic British overseas territory of Ascension Island, including a sizeable force of Avro Vulcan B Mk 2 bombers, Handley Page Victor K Mk 2 refuelling aircraft, and McDonnell Douglas Phantom FGR Mk 2 fighters to protect them. Meanwhile the main British naval task force arrived at Ascension to prepare for active service. A small force had already been sent south to recapture South Georgia.
Encounters began in April; the British Task Force was shadowed by Boeing 707 aircraft of the Argentine Air Force during their travel to the south. Several of these flights were intercepted by Sea Harriers outside the British-imposed exclusion zone; the unarmed 707s were not attacked because diplomatic moves were still in progress and the UK had not yet decided to commit itself to armed force. On 23 April a Brazilian commercial Douglas DC-10 from VARIG Airlines en route to South Africa was intercepted by British Harriers who visually identified the civilian plane.
Recapture of South Georgia and the attack on "Santa Fe".
The South Georgia force, "Operation Paraquet", under the command of Major Guy Sheridan RM, consisted of Marines from 42 Commando, a troop of the Special Air Service (SAS) and Special Boat Service (SBS) troops who were intended to land as reconnaissance forces for an invasion by the Royal Marines. All were embarked on RFA "Tidespring". First to arrive was the "Churchill"-class submarine HMS "Conqueror" on 19 April, and the island was over-flown by a radar-mapping Handley Page Victor on 20 April.
The first landings of SAS troops took place on 21 April, but—with the southern hemisphere autumn setting in—the weather was so bad that their landings and others made the next day were all withdrawn after two helicopters crashed in fog on Fortuna Glacier. On 23 April, a submarine alert was sounded and operations were halted, with "Tidespring" being withdrawn to deeper water to avoid interception. On 24 April, the British forces regrouped and headed in to attack.
On 25 April, after resupplying the Argentine garrison in South Georgia, the submarine ARA "Santa Fe" was spotted on the surface by a Westland Wessex HAS Mk 3 helicopter from HMS "Antrim", which attacked the Argentine submarine with depth charges. HMS "Plymouth" launched a Westland Wasp HAS.Mk.1 helicopter, and HMS "Brilliant" launched a Westland Lynx HAS Mk 2. The Lynx launched a torpedo, and strafed the submarine with its pintle-mounted general purpose machine gun; the Wessex also fired on "Santa Fe" with its GPMG. The Wasp from HMS "Plymouth" as well as two other Wasps launched from HMS "Endurance" fired AS-12 ASM antiship missiles at the submarine, scoring hits. "Santa Fe" was damaged badly enough to prevent her from diving. The crew abandoned the submarine at the jetty at King Edward Point on South Georgia.
With "Tidespring" now far out to sea and the Argentine forces augmented by the submarine's crew, Major Sheridan decided to gather the 76 men he had and make a direct assault that day. After a short forced march by the British troops and a naval bombardment demonstration by two Royal Navy vessels ("Antrim" and "Plymouth"), the Argentine forces surrendered without resistance. The message sent from the naval force at South Georgia to London was, "Be pleased to inform Her Majesty that the White Ensign flies alongside the Union Jack in South Georgia. God Save the Queen." The Prime Minister, Margaret Thatcher, broke the news to the media, telling them to "Just rejoice at that news, and congratulate our forces and the Marines!"
Black Buck raids.
On 1 May British operations on the Falklands opened with the "Black Buck 1" attack (of a series of five) on the airfield at Stanley. A Vulcan bomber from Ascension flew on an 8000 nmi round trip dropping conventional bombs across the runway at Stanley and back to Ascension. The mission required repeated refuelling, and required several Victor tanker aircraft operating in concert, including tanker to tanker refuelling. The overall effect of the raids on the war is difficult to determine, and the raids consumed precious tanker resources from Ascension, but also prevented Argentina from stationing fast jets on the islands.
The raids did minimal damage to the runway, and damage to radars was quickly repaired. s of 2014[ [update]] the Royal Air Force Web site still states that all the three bombing missions had been successful, but historian Lawrence Freedman, who had access to classified documents, said in a 2005 book that the subsequent bombing missions were failures. Argentine sources said that the Vulcan raids influenced Argentina to withdraw some of its Mirage IIIs from Southern Argentina to the Buenos Aires Defence Zone. This was later described as propaganda by Falklands veteran Commander Nigel Ward. The effect of this action was, however, watered down when British officials made clear that there would be no strikes on air bases in Argentina.
Of the five Black Buck raids, three were against Stanley Airfield, with the other two anti-radar missions using Shrike anti-radiation missiles.
Escalation of the air war.
The Falklands had only three airfields. The longest and only paved runway was at the capital, Stanley, and even that was too short to support fast jets (although an arrestor gear was fitted in April to support Skyhawks). Therefore, the Argentines were forced to launch their major strikes from the mainland, severely hampering their efforts at forward staging, combat air patrols and close air support over the islands. The effective loiter time of incoming Argentine aircraft was low, and they were later compelled to overfly British forces in any attempt to attack the islands.
The first major Argentine strike force comprised 36 aircraft (A-4 Skyhawks, IAI Daggers, English Electric Canberras, and Mirage III escorts), and was sent on 1 May, in the belief that the British invasion was imminent or landings had already taken place. Only a section of Grupo 6 (flying IAI Dagger aircraft) found ships, which were firing at Argentine defences near the islands. The Daggers managed to attack the ships and return safely.
This greatly boosted morale of the Argentine pilots, who now knew they could survive an attack against modern warships, protected by radar ground clutter from the Islands and by using a late Pop up profile. Meanwhile, other Argentine aircraft were intercepted by BAE Sea Harriers operating from HMS "Invincible". A Dagger and a Canberra were shot down.
Combat broke out between Sea Harrier FRS Mk 1 fighters of No. 801 Naval Air Squadron and Mirage III fighters of Grupo 8. Both sides refused to fight at the other's best altitude, until two Mirages finally descended to engage. One was shot down by an AIM-9L Sidewinder air-to-air missile (AAM), while the other escaped but was damaged and without enough fuel to return to its mainland air base. The plane made for Stanley, where it fell victim to friendly fire from the Argentine defenders.
As a result of this experience, Argentine Air Force staff decided to employ A-4 Skyhawks and Daggers only as strike units, the Canberras only during the night, and Mirage IIIs (without air refuelling capability or any capable AAM) as decoys to lure away the British Sea Harriers. The decoying would be later extended with the formation of the Escuadrón Fénix, a squadron of civilian jets flying 24 hours-a-day simulating strike aircraft preparing to attack the fleet. On one of these flights, an Air Force Learjet was shot down, killing the squadron commander, Vice Commodore Rodolfo De La Colina, the highest-ranking Argentine officer to die in the war.
Stanley was used as an Argentine strongpoint throughout the conflict. Despite the Black Buck and Harrier raids on Stanley airfield (no fast jets were stationed there for air defence) and overnight shelling by detached ships, it was never out of action entirely.
Stanley was defended by a mixture of surface-to-air missile (SAM) systems (Franco-German Roland and British Tigercat) and Swiss-built Oerlikon 35 mm twin anti-aircraft cannons. Lockheed Hercules transport night flights brought supplies, weapons, vehicles, and fuel, and airlifted out the wounded up until the end of the conflict.
The only Argentine Hercules shot down by the British was lost on 1 June when TC-63 was intercepted by a Sea Harrier in daylight when it was searching for the British fleet north-east of the islands after the Argentine Navy retired its last SP-2H Neptune due to airframe attrition.
Various options to attack the home base of the five Argentine Etendards at Río Grande were examined and discounted (Operation Mikado), subsequently five Royal Navy submarines lined up, submerged, on the edge of Argentina's 12 nmi territorial limit to provide early warning of bombing raids on the British task force.
Sinking of ARA "General Belgrano".
Two British naval task forces (one of surface vessels and one of submarines) and the Argentine fleet were operating in the neighbourhood of the Falklands and soon came into conflict. The first naval loss was the World War II-vintage Argentine light cruiser ARA "General Belgrano". The nuclear-powered submarine HMS "Conqueror" sank "General Belgrano" on 2 May. Three hundred and twenty-three members of "General Belgrano"‍ '​s crew died in the incident.
Over 700 men were rescued from the open ocean despite cold seas and stormy weather. The losses from "General Belgrano" totalled nearly half of the Argentine deaths in the Falklands conflict and the loss of the ship hardened the stance of the Argentine government.
Regardless of controversies over the sinking, due to disagreement on the exact nature of the Maritime Exclusion Zone and whether "General Belgrano" had been returning to port at the time of the sinking, it had a crucial strategic effect: the elimination of the Argentine naval threat. After her loss, the entire Argentine fleet, with the exception of the conventional submarine ARA "San Luis", returned to port and did not leave again during the fighting.
The two escorting destroyers and the battle group centred on the aircraft carrier ARA "Veinticinco de Mayo" both withdrew from the area, ending the direct threat to the British fleet that their pincer movement had represented.
In a separate incident later that night, British forces engaged an Argentine patrol gunboat, the ARA "Alferez Sobral", that was searching for the crew of the Argentine Air Force Canberra light bomber shot down on 1 May.
Two Royal Navy Lynx helicopters fired four Sea Skua missiles at her. Badly damaged and with eight crew dead, "Alferez Sobral" managed to return to Puerto Deseado two days later. The Canberra's crew were never found.
Sinking of HMS "Sheffield".
On 4 May, two days after the sinking of "Belgrano", the British lost the Type 42 destroyer HMS "Sheffield" to fire following an Exocet missile strike from the Argentine 2nd Naval Air Fighter/Attack Squadron.
"Sheffield" had been ordered forward with two other Type 42s to provide a long-range radar and medium-high altitude missile picket far from the British carriers. She was struck amidships, with devastating effect, ultimately killing 20 crew members and severely injuring 24 others. The ship was abandoned several hours later, gutted and deformed by the fires that continued to burn for six more days. She finally sank outside the Maritime Exclusion Zone on 10 May.
The incident is described in detail by Admiral Sandy Woodward in his book "One Hundred Days", Chapter One. Woodward was a former commanding officer of "Sheffield".
The tempo of operations increased throughout the second half of May as United Nations attempts to mediate a peace were rejected by the British, who felt that any delay would make a campaign impractical in the South Atlantic storms. The destruction of "Sheffield" (the first Royal Navy ship sunk in action since World War II) had a profound impact on the British public, bringing home the fact that the "Falklands Crisis", as the BBC News put it, was now an actual "shooting war".
British special forces operations.
Given the threat to the British fleet posed by the Etendard-Exocet combination, plans were made to use SAS troops to attack the home base of the five Etendards at Río Grande, Tierra del Fuego.
The operation was codenamed "Mikado". The operation was later scrapped, after acknowledging its chances of success were limited, and replaced the use of C-130s with a plan to lead HMS "Onyx" to drop SAS operatives several miles offshore at night for them to make their way to the coast aboard rubber inflatables and proceed to destroy Argentina's remaining Exocet stockpile.
An SAS reconnaissance team was dispatched to carry out preparations for a seaborne infiltration. A Westland Sea King helicopter carrying the assigned team took off from HMS "Invincible" on the night of 17 May, but bad weather forced it to land 50 mi from its target and the mission was aborted. The pilot flew to Chile, landed south of Punta Arenas, and dropped off the SAS team. The helicopter's crew of three then destroyed the aircraft, surrendered to Chilean police on 25 May, and were repatriated to the UK after interrogation. The discovery of the burnt-out helicopter attracted considerable international attention. Meanwhile, the SAS team crossed and penetrated deep into Argentina, but cancelled their mission after the Argentines suspected an SAS operation and deployed some troops to search for them. The SAS men were able to return to Chile, and took a civilian flight back to the UK.
On 14 May the SAS carried out a raid on Pebble Island on the Falklands, where the Argentine Navy had taken over a grass airstrip for FMA IA 58 Pucará light ground-attack aircraft and Beechcraft T-34 Mentors, which resulted with the destruction of several aircraft.
Land battles.
Landing at San Carlos—Bomb Alley.
During the night on 21 May the British Amphibious Task Group under the command of Commodore Michael Clapp (Commodore, Amphibious Warfare – COMAW) mounted "Operation Sutton", the amphibious landing on beaches around San Carlos Water, on the northwestern coast of East Falkland facing onto Falkland Sound. The bay, known as "Bomb Alley" by British forces, was the scene of repeated air attacks by low-flying Argentine jets.
The men of 3 Commando Brigade were put ashore as follows: 2nd Battalion, Parachute Regiment (2 Para) from the RORO ferry "Norland" and 40 Commando Royal Marines from the amphibious ship HMS "Fearless" were landed at San Carlos (Blue Beach), 3rd Battalion, Parachute Regiment (3 Para) from the amphibious ship HMS "Intrepid" were landed at Port San Carlos (Green Beach) and 45 Commando from RFA "Stromness" were landed at Ajax Bay (Red Beach). Notably the waves of eight LCUs and eight LCVPs were led by Major Ewen Southby-Tailyour, who had commanded the Falklands detachment NP8901 from March 1978 to 1979. 42 Commando on the ocean liner was a tactical reserve. Units from the Royal Artillery, Royal Engineers, etc. and armoured reconnaissance vehicles were also put ashore with the landing craft, the Round table class LSL and mexeflote barges. Rapier missile launchers were carried as underslung loads of Sea Kings for rapid deployment.
By dawn the next day they had established a secure beachhead from which to conduct offensive operations. From there Brigadier Julian Thompson's plan was to capture Darwin and Goose Green before turning towards Port Stanley.
Now, with the British troops on the ground, the Argentine Air Force began the night bombing campaign against them using Canberra bomber planes until the last day of the war (14 June).
At sea, the paucity of the British ships' anti-aircraft defences was demonstrated in the sinking of HMS "Ardent" on 21 May, HMS "Antelope" on 24 May, and MV "Atlantic Conveyor" (struck by two AM39 Exocets) on 25 May along with a vital cargo of helicopters, runway-building equipment and tents. The loss of all but one of the Chinook helicopters being carried by the Atlantic Conveyor was a severe blow from a logistics perspective.
Also lost on this day was HMS "Coventry", a sister to "Sheffield", whilst in company with HMS "Broadsword" after being ordered to act as decoy to draw away Argentine aircraft from other ships at San Carlos Bay. HMS "Argonaut" and HMS "Brilliant" were badly damaged. However, many British ships escaped being sunk because of weaknesses of the Argentine pilots' bombing tactics described below.
To avoid the highest concentration of British air defences, Argentine pilots released ordnance from very low altitude, and hence their bomb fuzes did not have sufficient time to arm before impact. The low release of the retarded bombs (some of which had been sold to the Argentines by the British years earlier) meant that many never exploded, as there was insufficient time in the air for them to arm themselves. A simple free-fall bomb will, during a low altitude release, impact almost directly below the aircraft which is then within the lethal fragmentation zone of the resulting explosion.
A retarded bomb has a small parachute or air brake that opens to reduce the speed of the bomb to produce a safe horizontal separation between the two. The fuze for a retarded bomb requires a minimum time over which the retarder is open to ensure safe separation. The pilots would have been aware of this, but due to the high concentration levels required to avoid SAMs and Anti-Aircraft Artillery (AAA), as well as any British Sea Harriers, many failed to climb to the necessary release point. The Argentinian forces solved the problem by fitting improvised retarding devices, allowing the pilots to effectively employ low-level bombing attacks on 8 June.
In his autobiographical account of the Falklands War, Admiral Woodward blamed the BBC World Service for disclosing information that led the Argentines to change the retarding devices on the bombs. The World Service reported the lack of detonations after receiving a briefing on the matter from a Ministry of Defence official. He describes the BBC as being more concerned with being "fearless seekers after truth" than with the lives of British servicemen. Colonel 'H'. Jones levelled similar accusations against the BBC after they disclosed the impending British attack on Goose Green by 2 Para.
Thirteen bombs hit British ships without detonating. Lord Craig, the retired Marshal of the Royal Air Force, is said to have remarked: "Six better fuses and we would have lost" although "Ardent" and "Antelope" were both lost despite the failure of bombs to explode.
The fuzes were functioning correctly, and the bombs were simply released from too low an altitude.
 The Argentines lost 22 aircraft in the attacks.
Battle of Goose Green.
From early on 27 May until 28 May 2 Para, (approximately 500 men) with artillery support from 8 (Alma) Commando Battery, Royal Artillery, approached and attacked Darwin and Goose Green, which was held by the Argentine 12th Infantry Regiment.
After a tough struggle that lasted all night and into the next day, the British won the battle; in all, 17 British and 47 Argentine soldiers were killed. In total 961 Argentine troops (including 202 Argentine Air Force personnel of the "Condor" airfield) were taken prisoner.
The BBC announced the taking of Goose Green on the BBC World Service before it had actually happened. It was during this attack that Lieutenant Colonel H. Jones, the commanding officer of 2 Para was killed at the head of his battalion while charging into the well-prepared Argentine positions. He was posthumously awarded the Victoria Cross.
With the sizeable Argentine force at Goose Green out of the way, British forces were now able to break out of the San Carlos beachhead. On 27 May, men of 45 Cdo and 3 Para started a loaded march across East Falkland towards the coastal settlement of Teal Inlet.
Special forces on Mount Kent.
Meanwhile, 42 Commando prepared to move by helicopter to Mount Kent. Unknown to senior British officers, the Argentine generals were determined to tie down the British troops in the Mount Kent area, and on 27 and 28 May they sent transport aircraft loaded with Blowpipe surface-to-air missiles and commandos (602nd Commando Company and 601st National Gendarmerie Special Forces Squadron) to Stanley. This operation was known as Operation AUTOIMPUESTA (Self-Determination-Initiative).
For the next week, the SAS and the Mountain and Arctic Warfare Cadre (M&AWC) of 3 Commando Brigade waged intense patrol battles with patrols of the volunteers' 602nd Commando Company under Major Aldo Rico, normally 2nd in Command of the 22nd Mountain Infantry Regiment. Throughout 30 May, Royal Air Force Harriers were active over Mount Kent. One of them, Harrier "XZ963", flown by Squadron Leader Jerry Pook—in responding to a call for help from D Squadron, attacked Mount Kent's eastern lower slopes, and that led to its loss through small-arms fire. Pook was subsequently awarded the Distinguished Flying Cross.
The Argentine Navy used their last AM39 Exocet missile attempting to attack HMS "Invincible" on 30 May. There are Argentine claims that the missile struck; however the British have denied this, some citing that HMS "Avenger" shot it down. When "Invincible" returned to the UK after the war she showed no signs of missile damage.
On 31 May, the M&AWC defeated Argentine Special Forces at the Battle of Top Malo House. A 13-strong Argentine Army Commando detachment (Captain José Vercesi's 1st Assault Section, 602nd Commando Company) found itself trapped in a small shepherd's house at Top Malo.
The Argentine commandos fired from windows and doorways and then took refuge in a stream bed 200 m from the burning house.
Completely surrounded, they fought 19 M&AWC marines under Captain Rod Boswell for forty-five minutes until, with their ammunition almost exhausted, they elected to surrender.
Three Cadre members were badly wounded. On the Argentine side there were two dead including Lieutenant Ernesto Espinoza and Sergeant Mateo Sbert (who were decorated for their bravery). Only five Argentines were left unscathed. As the British mopped up Top Malo House, down from Malo Hill came Lieutenant Fraser Haddow's M&AWC patrol, brandishing a large Union Flag. One wounded Argentine soldier, Lieutenant Horacio Losito, commented that their escape route would have taken them through Haddow's position.
601st Commando tried to move forward to rescue 602nd Commando Company on Estancia Mountain. Spotted by 42 Commando, they were engaged with 81mm mortars and forced to withdraw to Two Sisters mountain. The leader of 602nd Commando Company on Estancia Mountain realised his position had become untenable and after conferring with fellow officers ordered a withdrawal.
The Argentine operation also saw the extensive use of helicopter support to position and extract patrols; the 601st Combat Aviation Battalion also suffered casualties. At about 11.00 am on 30 May, an Aerospatiale SA-330 Puma helicopter was brought down by a shoulder-launched Stinger surface-to-air missile (SAM) fired by the SAS in the vicinity of Mount Kent. Six National Gendarmerie Special Forces were killed and eight more wounded in the crash.
As Brigadier Thompson commented, "It was fortunate that I had ignored the views expressed by Northwood HQ that reconnaissance of Mount Kent before insertion of 42 Commando was superfluous.
Had D Squadron not been there, the Argentine Special Forces would have caught the Commando before de-planing and, in the darkness and confusion on a strange landing zone, inflicted heavy casualties on men and helicopters."
Bluff Cove and Fitzroy.
By 1 June, with the arrival of a further British troops of the 5th Infantry Brigade, the new British divisional commander, Major General Jeremy Moore RM, had sufficient force to start planning an offensive against Stanley.
During this build-up, the Argentine air assaults on the British naval forces continued, killing 56. Of the dead, 32 were from the Welsh Guards on RFA "Sir Galahad" and RFA "Sir Tristram" on 8 June. According to Surgeon-Commander Rick Jolly of the Falklands Field Hospital, more than 150 men suffered burns and injuries of some kind in the attack, including, famously, Simon Weston.
The Guards were sent to support an advance along the southern approach to Stanley. On 2 June a small advance party of 2 Para moved to Swan Inlet house in a number of Army Westland Scout helicopters. Telephoning ahead to Fitzroy, they discovered the area clear of Argentines and (exceeding their authority) commandeered the one remaining RAF Chinook helicopter to frantically ferry another contingent of 2 Para ahead to Fitzroy (a settlement on Port Pleasant) and Bluff Cove (a settlement on Port Fitzroy).
This uncoordinated advance caused planning nightmares for the commanders of the combined operation, as they now found themselves with a 30 mi string of indefensible positions on their southern flank. Support could not be sent by air as the single remaining Chinook was already heavily oversubscribed. The soldiers could march, but their equipment and heavy supplies would need to be ferried by sea.
Plans were drawn up for half the Welsh Guards to march light on the night of 2 June, whilst the Scots Guards and the second half of the Welsh Guards were to be ferried from San Carlos Water in the Landing Ship Logistics (LSL) "Sir Tristram" and the landing platform dock (LPD) "Intrepid" on the night of 5 June. "Intrepid" was planned to stay one day and unload itself and as much of "Sir Tristram" as possible, leaving the next evening for the relative safety of San Carlos. Escorts would be provided for this day, after which "Sir Tristram" would be left to unload using a Mexeflote (a powered raft) for as long as it took to finish.
Political pressure from above to not risk the LPD forced Commodore Clapp to alter this plan. Two lower-value LSLs would be sent, but without suitable beaches on which to land, "Intrepid"'s landing craft would need to accompany them to unload. A complicated operation across several nights with "Intrepid" and her sister ship "Fearless" sailing half-way to dispatch their craft was devised.
The attempted overland march by half the Welsh Guards failed, possibly as they refused to march light and attempted to carry their equipment. They returned to San Carlos and were landed directly at Bluff Cove when "Fearless" dispatched her landing craft. "Sir Tristram" sailed on the night of 6 June and was joined by "Sir Galahad" at dawn on 7 June. Anchored 1200 ft apart in Port Pleasant, the landing ships were near Fitzroy, the designated landing point.
The landing craft should have been able to unload the ships to that point relatively quickly, but confusion over the ordered disembarcation point (the first half of the Guards going direct to Bluff Cove) resulted in the senior Welsh Guards infantry officer aboard insisting his troops be ferried the far longer distance directly to Port Fitzroy/Bluff Cove. The alternative was for the infantrymen to march via the recently repaired Bluff Cove bridge (destroyed by retreating Argentine combat engineers) to their destination, a journey of around seven miles (11 km).
On "Sir Galahad"‍ '​s stern ramp there was an argument about what to do. The officers on board were told they could not sail to Bluff Cove that day. They were told they had to get their men off ship and onto the beach as soon as possible as the ships were vulnerable to enemy aircraft. It would take 20 minutes to transport the men to shore using the LCU and Mexeflote. They would then have the choice to walk the 7 miles to Bluff Cove or wait until dark to sail there. The officers on board said they would remain on board until dark and then sail. They refused to take their men off the ship. They possibly doubted that the bridge had been repaired due to the presence on board "Sir Galahad" of the Royal Engineer Troop whose job it was to repair the bridge. The Welsh Guards were keen to rejoin the rest of their Battalion who were potentially facing the enemy without their support. They had also not seen any enemy aircraft since landing at San Carlos and may have been overconfident in the air defences. Ewen Southby-Tailyour gave a direct order for the men to leave the ship and go to the beach. The order was ignored.
The longer journey time of the landing craft taking the troops directly to Bluff Cove and the squabbling over how the landing was to be performed caused enormous delay in unloading. This had disastrous consequences. Without escorts, having not yet established their air defence, and still almost fully laden, the two LSLs in Port Pleasant were sitting targets for two waves of Argentine A-4 Skyhawks.
The disaster at Port Pleasant (although often known as Bluff Cove) would provide the world with some of the most sobering images of the war as TV news video footage showed Navy helicopters hovering in thick smoke to winch survivors from the burning landing ships.
British casualties were 48 killed and 115 wounded. Three Argentine pilots were also killed. The air strike delayed the scheduled British ground attack on Stanley by two days. However, Argentine General Mario Menendez, commander of Argentine forces in the Falklands, was told that 900 British soldiers had died. He expected that the losses would cause enemy morale to drop and the British assault to stall.
Fall of Stanley.
On the night of 11 June, after several days of painstaking reconnaissance and logistic build-up, British forces launched a brigade-sized night attack against the heavily defended ring of high ground surrounding Stanley. Units of 3 Commando Brigade, supported by naval gunfire from several Royal Navy ships, simultaneously attacked in the Battle of Mount Harriet, Battle of Two Sisters, and Battle of Mount Longdon. Mount Harriet was taken at a cost of 2 British and 18 Argentine soldiers. At Two Sisters, the British faced both enemy resistance and friendly fire, but managed to capture their objectives. The toughest battle was at Mount Longdon. British forces were bogged down by assault rifle, mortar, machine gun, artillery fire, sniper fire, and ambushes. Despite this, the British continued their advance.
During this battle, 13 were killed when HMS "Glamorgan", straying too close to shore while returning from the gun line, was struck by an improvised trailer-based Exocet MM38 launcher taken from the destroyer ARA "Seguí" by Argentine Navy technicians. On the same day, Sergeant Ian McKay of 4 Platoon, B Company, 3 Para died in a grenade attack on an Argentine bunker, which earned him a posthumous Victoria Cross.
After a night of fierce fighting, all objectives were secured. Both sides suffered heavy losses.
The night of 13 June saw the start of the second phase of attacks, in which the momentum of the initial assault was maintained. 2 Para with CVRT support from The Blues and Royals, captured Wireless Ridge at the Battle of Wireless Ridge, with the loss of 3 British and 25 Argentine lives, and the 2nd battalion, Scots Guards captured Mount Tumbledown at the Battle of Mount Tumbledown, which cost 10 British and 30 Argentine lives.
With the last natural defence line at Mount Tumbledown breached, the Argentine town defences of Stanley began to falter. In the morning gloom, one company commander got lost and his junior officers became despondent. Private Santiago Carrizo of the 3rd Regiment described how a platoon commander ordered them to take up positions in the houses and "if a Kelper resists, shoot him", but the entire company did nothing of the kind.
A ceasefire was declared on 14 June and the commander of the Argentine garrison in Stanley, Brigade General Mario Menéndez surrendered to Major General Jeremy Moore the same day.
Recapture of South Sandwich Islands.
On 20 June the British retook the South Sandwich Islands (which involved accepting the surrender of the Southern Thule Garrison at the "Corbeta Uruguay" base), and declared hostilities to be over.
Argentina had established Corbeta Uruguay in 1976, but prior to 1982 the United Kingdom had contested the existence of the Argentine base only through diplomatic channels.
Casualties.
In total 907 were killed during the 74 days of the conflict:
Of the 86 Royal Navy personnel, 22 were lost in HMS "Ardent", 19 + 1 lost in HMS "Sheffield", 19 + 1 lost in HMS "Coventry" and 13 lost in HMS "Glamorgan".
Fourteen naval cooks were among the dead, the largest number from any one branch in the Royal Navy.
Thirty-three of the British Army's dead came from the Welsh Guards, 21 from the 3rd Battalion, the Parachute Regiment, 18 from the 2nd Battalion, the Parachute Regiment, 19 from the Special Air Service, 3 from Royal Signals and 8 from each of the Scots Guards and Royal Engineers. The 1st battalion/7th Duke of Edinburgh's Own Gurkha Rifles lost one man killed.
Two more British deaths may be attributed to Operation Corporate, bringing the total to 260:
There were Argentine and 777 British non-fatal casualties.
Further information about the field hospitals and hospital ships is at Ajax Bay and List of hospitals and hospital ships of the Royal Navy. On the Argentine side beside the Military Hospital at Port Stanley, the Argentine Air Force Mobile Field Hospital was deployed at Comodoro Rivadavia.
Red Cross Box.
Before British offensive operations began, the British and Argentine governments agreed to establish an area on the high seas where both sides could station hospital ships without fear of attack by the other side. This area, a circle 20 nautical miles in diameter, was referred to as the Red Cross Box (), about 45 mi north of Falkland Sound). Ultimately, the British stationed four ships (HMS "Hydra", HMS "Hecla" and HMS "Herald" and the primary hospital ship "Uganda") within the box, while the Argentinians stationed three ("Almirante Irizar", "Bahia Paraiso" and "Puerto Deseado").
The hospital ships were non-warships converted to serve as hospital ships. The three British naval vessels were survey vessels and "Uganda" was a passenger liner. "Almirante Irizar" was an icebreaker, "Bahia Paraiso" was an Antarctic supply transport and "Puerto Deseado" was a survey ship. The British and Argentine vessels operating within the Box were in radio contact and there was some transfer of patients between the hospital ships. For example, the British hospital ship SS "Uganda" on four occasions transferred patients to an Argentinian hospital ship. The British naval hospital ships operated as casualty ferries, carrying casualties from both sides from the Falklands to "Uganda" and operating a shuttle service between the Red Cross Box and Montevideo.
Throughout the conflict officials of the International Committee of the Red Cross (ICRC) conducted inspections to verify that all concerned were abiding by the rules of the Geneva Convention. On 12 June some personnel transferred from the Argentine hospital ship to the British ships by helicopter. Argentine naval officers also inspected the British casualty ferries in the estuary of the River Plate.
British casualty evacuation.
"Hydra" worked with "Hecla" and "Herald", to take casualties from "Uganda" to Montevideo, Uruguay, where a fleet of Uruguayan ambulances would meet them. RAF VC10 aircraft then flew the casualties to the UK for transfer to the Princess Alexandra Royal Air Force Hospital at RAF Wroughton, near Swindon.
Aftermath.
This brief war brought many consequences for all the parties involved, besides the considerable casualty rate and large materiel loss, especially of shipping and aircraft, relative to the deployed military strengths of the opposing sides.
In the United Kingdom, Margaret Thatcher's popularity increased. The success of the Falklands campaign was widely regarded as the factor in the turnaround in fortunes for the Conservative government, who had been trailing behind the SDP-Liberal Alliance in the opinion polls for months before the conflict began, but after the success in the Falklands the Conservatives returned to the top of the opinion polls by a wide margin and went on to win the following year's general election by a landslide. Subsequently, Defence Secretary Nott's proposed cuts to the Royal Navy were abandoned.
The islanders subsequently had full British citizenship restored in 1983, their lifestyle improved by investments Britain made after the war and by the liberalisation of economic measures that had been stalled through fear of angering Argentina. In 1985, a new constitution was enacted promoting self-government, which has continued to devolve power to the islanders.
In Argentina, the Falklands War meant that a possible war with Chile was avoided. Further, Argentina returned to a democratic government in the 1983 general election, the first free general election since 1973.
It also had a major social impact, destroying the military's image as the "moral reserve of the nation" that they had maintained through most of the 20th century.
Various figures have been produced for the number of veterans who have committed suicide since the war. Some studies have estimated that 264 British veterans and 350–500 Argentine veterans have committed suicide since 1982. However, a detailed study of British veterans of the war commissioned by the UK Ministry of Defence found that only 95 had died from "intentional self-harm and events of undetermined intent (suicides and open verdict deaths)", a ratio no higher than that of the general population.
Military analysis.
Militarily, the Falklands conflict remains the largest air-naval combat operation between modern forces since the end of the Second World War. As such, it has been the subject of intense study by military analysts and historians. The most significant "lessons learned" include: the vulnerability of surface ships to anti-ship missiles and submarines, the challenges of co-ordinating logistical support for a long-distance projection of power, and reconfirmation of the role of tactical air power, including the use of helicopters.
In 1986 the BBC broadcast the "Horizon" programme, "In the Wake of HMS Sheffield", which discussed lessons learned from the conflict, along with measures since taken to implement them, such as stealth ships and close-in weapons systems.
Memorials.
In addition to memorials on the islands, there is a memorial in the crypt of St Paul's Cathedral, London to the British war dead. In Argentina, there is a memorial at Plaza San Martín in Buenos Aires, in Rosario, and in Ushuaia.
During the war, British dead were put into plastic body bags and buried in mass graves. After the war the bodies were recovered; 14 were reburied at Blue Beach Military Cemetery and 64 were returned to Britain.
Many of the Argentine dead are buried in the Argentine Military Cemetery west of the Darwin Settlement. The government of Argentina declined an offer by Britain to have the bodies repatriated to the mainland.
Minefields.
As of 2011 there were 113 uncleared minefields on the Falkland Islands and unexploded ordnance (UXOs) covering an area of 13 sqkm. Of this area, 5.5 sqkm on the Murrell Peninsula were classified as being "suspected minefields" – the area had been heavily pastured for the previous 25 years without incident. It was estimated that these minefields had anti-personnel mines and anti-tank mines. No human casualties from mines or UXO have been reported in the Falkland Islands since 1984, and no civilian mine casualties have ever occurred on the islands. The UK reported six military personnel were injured in 1982 and a further two injured in 1983. Most military accidents took place while clearing the minefields in the immediate aftermath of the 1982 conflict or in the process of trying to establish the extent of the minefield perimeters, particularly where no detailed records existed.
On 9 May 2008, the Falkland Islands Government asserted that the minefields which represent 0.1% of the available farmland on the islands "present no long term social or economic difficulties for the Falklands" and that the impact of clearing the mines would cause more problems than containing them. However, the British Government, in accordance with its commitments under the Mine Ban Treaty has a commitment to clear the mines by the end of 2019.
In May 2012, it was announced that 3.7 sqkm of Stanley Common (which lies between the Stanley – Mount Pleasant road and the shoreline) was made safe and had been opened to the public, opening up a 3 km stretch of coastline and a further two kilometres of shoreline along Mullet's Creek.
Press and publicity.
Argentina.
Selected war correspondents were regularly flown to Port Stanley in military aircraft to report on the war. Back in Buenos Aires newspapers and magazines faithfully reported on "the heroic actions of the largely conscript army and its successes".
Officers from the intelligence services were attached to the newspapers and 'leaked' information confirming the official communiqués from the government. The glossy magazines "Gente" and "Siete Días" swelled to sixty pages with colour photographs of British warships in flames – many of them faked – and bogus eyewitness reports of the Argentine commandos' guerrilla war on South Georgia (6 May) and an already dead Pucará pilot's attack on HMS "Hermes" (Lt. Daniel Antonio Jukic had been killed at Goose Green during a British air strike on 1 May). Most of the faked photos actually came from the tabloid press. One of the best remembered headlines was "Estamos ganando" ("We're winning") from the magazine "Gente", that would later use variations of it.
The Argentine troops on the Falkland Islands could read "Gaceta Argentina"—a newspaper intended to boost morale among the servicemen. Some of its untruths could easily be unveiled by the soldiers who recovered corpses.
The "Malvinas course" united the Argentines in a patriotic atmosphere that protected the junta from critics, and even opponents of the military government supported Galtieri; Ernesto Sabato said: "Don't be mistaken, Europe; it is not a dictatorship who is fighting for the Malvinas, it is the whole Nation. Opponents of the military dictatorship, like me, are fighting to extirpate the last trace of colonialism." The "Madres de Plaza de Mayo" were even exposed to death threats from ordinary people.
HMS "Invincible" was repeatedly sunk in the Argentine press, and on 30 April 1982 the Argentine magazine "Tal Cual" showed Prime Minister Thatcher with an eyepatch and the text: "Pirate, witch and assassin. Guilty!" Three British reporters sent to Argentina to cover the war from the Argentine perspective were jailed until the end of the war.
United Kingdom.
Seventeen newspaper reporters, two photographers, two radio reporters and three television reporters with five technicians sailed with the Task Force to the war. The Newspaper Publishers' Association selected them from among 160 applicants, excluding foreign media.
The hasty selection resulted in the inclusion of two journalists among the war reporters who were interested only in Queen Elizabeth II's son Prince Andrew, who was serving in the conflict. The Prince flew a helicopter on multiple missions including anti-surface warfare, Exocet missile decoy and casualty evacuation.
Merchant vessels had the civilian Inmarsat uplink, which enabled written telex and voice report transmissions via satellite. had a facsimile machine that was used to upload 202 pictures from the South Atlantic over the course of the war. The Royal Navy leased bandwidth on the US Defense Satellite Communications System for worldwide communications.
Television demands a thousand times the data rate of telephone, but the Ministry of Defence was unsuccessful in convincing the US to allocate more bandwidth.
TV producers suspected that the enquiry was half-hearted; since the Vietnam War television pictures of casualties and traumatised soldiers were recognised as having negative propaganda value.
However the technology only allowed uploading a single frame per 20 minutes – and only if the military satellites were allocated 100% to television transmissions. Videotapes were shipped to Ascension Island, where a broadband satellite uplink was available, resulting in TV coverage being delayed by three weeks.
The press was very dependent on the Royal Navy, and was censored on site. Many reporters in the UK knew more about the war than those with the Task Force.
The Royal Navy expected Fleet Street to conduct a Second World War-style positive news campaign but the majority of the British media, especially the BBC, reported the war in a neutral fashion. These reporters referred to "the British troops" and "the Argentinian troops" instead of "our lads" and the "Argies". The two main tabloid papers presented opposing viewpoints: "The Daily Mirror" was decidedly anti-war, whilst "The Sun" became well known for headlines such as "Stick It Up Your Junta!", which, along with the reporting in other tabloids, led to accusations of xenophobia
 and jingoism.
 "The Sun" was condemned for its "Gotcha" headline following the sinking of the ARA "General Belgrano".
Cultural impact.
There were wide-ranging influences on popular culture in both the UK and Argentina, from the immediate postwar period to the present. The then elderly Argentinian writer Jorge Luis Borges described the war as "a fight between two bald men over a comb". The words "yomp" and "Exocet" entered the British vernacular as a result of the war. The Falklands War also provided material for theatre, film and TV drama and influenced the output of musicians. In Argentina, the military government banned the broadcasting of music in the English language, giving way to the rise of local rock musicians.
Bibliography.
</dl>
External links.
 #if: 
 #if:  
 |, 
 #if: 
 }}{{
 #if: 
 #if: 
 | ()
 |{{
 #if: 
 #if: 
 | {{#if:||}}{{
 #if: 
 #if: 
 #if: {{
 #if: Informe RattenbachReport Rattenbach: Report of the commission for analysis and evaluation of responsibility in the conflict `South Atlantic`
 #if: 
 #if: 
 #switch: 
 #if: 
 #if: 
 |{{
 #switch: 
 #if: 
 #if: 
 |: {{
 #if: Informe RattenbachReport Rattenbach: Report of the commission for analysis and evaluation of responsibility in the conflict `South Atlantic`
 #if: 
 #if: 
 #switch: 
 #if: 
 #if: 
 |{{
 #switch: 
 #if: 
 #if: 
 
 #if:  
 |{{
 #if: Rey
 }} {{Citation/make link
 | 1={{
 #if: 
 #if: 
 #if: 
 |{{
 #if: 
 | 2="  
 #if:| []
 #if: 
 }}{{
 #if: 
 }}{{
 #if: 
 }}{{
 #if: 
 }}{{
 #if: 
 | ( ed.)
 #if: 
 }}{{
 #if: 
 #if: 
 |,
 #if: Rey
 |{{
 #if: 
 #if:
}}{{
 #if: 
 #ifeq: | 
 |{{
 #if: 
 #if: Rey
 | (published )
 |{{
 #if: 
 | (published )
}}{{
 #if: 
 |{{
 #if: {{
 #if: Informe RattenbachReport Rattenbach: Report of the commission for analysis and evaluation of responsibility in the conflict `South Atlantic`
 #if: 
 #if: 
 #switch: 
 #if: 
 #if: 
 |{{
 #switch: 
 #if: 
 #if: 
 |, {{
 #if: Informe RattenbachReport Rattenbach: Report of the commission for analysis and evaluation of responsibility in the conflict `South Atlantic`
 #if: 
 #if: 
 #switch: 
 #if: 
 #if: 
 |{{
 #switch: 
 #if: 
 #if: 
 #if: 
 #if: 
 #if: 
 #if: 
 #if: 
 #if: 
 #if: 
 #if: 
 #if: 
 #if: 
 #if: 
 #if: 
 #if: 
 #if: 
 #if: 
 #if: 
 #if: 
 #if: 
}}{{
 #if:
 | , {{#ifeq: | no
 | {{#if:
 |{{Citation/make link||{{#ifeq:|.|A|a}}rchived}} from the original
 |{{#ifeq:|.|A|a}}rchived
 | {{#ifeq:|.|A|a}}rchived{{#if:
 }}{{#if:| on }}{{
 |. {{citation error|nocat=
 #if:  
 |, {{
 #if: 
 |
 |, {{
 #if: 
 |
 }}{{
 #if: 
 | {{#ifeq:|,|, r|. R}}etrieved 
}}{{#if:
}}{{#if:
}}{{#if:
}}<span
 class="Z3988"
 title="ctx_ver=Z39.88-2004&rft_val_fmt={{urlencode:info:ofi/fmt:kev:mtx:}}{{
 #if: 
 |journal&rft.genre=article&rft.atitle={{urlencode:  
 |book{{
 #if: 
 |&rft.genre=bookitem&rft.btitle={{urlencode:}}&rft.atitle={{urlencode:  
 |&rft.genre=book&rft.btitle={{urlencode:  
 #if: Rey |&rft.aulast={{urlencode:Rey}}{{
 }}{{
 #if: Rey |&rft.au={{urlencode:Rey}}{{
 }}{{
 #if: Rattenbach |&rft.au={{urlencode:Rattenbach}}{{
 }}{{
 #if: Vago |&rft.au={{urlencode:Vago}}{{
 }}{{
 #if: Boffi |&rft.au={{urlencode:Boffi}}{{
 }}{{
 #if: De Bustamante |&rft.au={{urlencode:De Bustamante}}{{
 }}{{
 #if: Cabrera |&rft.au={{urlencode:Cabrera}}{{
 }}{{
 #if: |&rft.au={{urlencode:}}{{
 }}{{
 #if: |&rft.au={{urlencode:}}{{
 }}{{
 #if: |&rft.au={{urlencode:}}{{
 }}{{
 #if: {{
 #if: Informe RattenbachReport Rattenbach: Report of the commission for analysis and evaluation of responsibility in the conflict `South Atlantic`
 #if: 
 #if: 
 #switch: 
 #if: 
 #if: 
 |{{
 #switch: 
 #if: 
 #if: 
 |&rft.pages={{urlencode: {{
 #if: Informe RattenbachReport Rattenbach: Report of the commission for analysis and evaluation of responsibility in the conflict `South Atlantic`
 #if: 
 #if: 
 #switch: 
 #if: 
 #if: 
 |{{
 #switch: 
 #if: 
 #if: 
 }}{{
 }}&rfr_id=info:sid/en.wikipedia.org:{{FULLPAGENAMEE}}"> 
 |IncludedWorkTitle = 
 |IncludedWorkURL = 
 |Other = 
 |Edition = 
 |Place = 
 |PublicationPlace = 
 |Publisher = Wikisource
 |PublicationDate = 
 |EditorSurname1 = 
 |EditorSurname2 = 
 |EditorSurname3 = 
 |EditorSurname4 = 
 |EditorGiven1 = 
 |EditorGiven2=
 |EditorGiven3=
 |EditorGiven4=
 |Editorlink1=
 |Editorlink2=
 |Editorlink3=
 |Editorlink4=
 |language = Spanish
 |format = 
 |ARXIV=
 |ASIN=
 |BIBCODE=
 |DOI=
 |DoiBroken=
 |ISBN=
 |ISSN=
 |JFM=
 |JSTOR=
 |LCCN=
 |MR=
 |OCLC=
 |OL=
 |OSTI=
 |PMC=
 |Embargo=1010-10-10
 |PMID=
 |RFC=
 |SSRN=
 |ZBL=
 |ID=
 |AccessDate=
 |DateFormat=none
 |quote = 
 |laysummary = 
 |laydate = 
 |Ref=
 |Sep = .
 |PS = .
 |AuthorSep = ; 
 |NameSep = , 
 |Trunc = 2
 |amp = 

</doc>
<doc id="11524" url="http://en.wikipedia.org/wiki?curid=11524" title="Fahrenheit">
Fahrenheit

Fahrenheit (symbol °F) is a temperature scale based on one proposed in 1724 by the German physicist Daniel Gabriel Fahrenheit (1686–1736), after whom the scale is named. On Fahrenheit's original scale the lower defining point was the lowest temperature to which he could reproducibly cool brine (defining 0 degrees), while the highest was that of the average human core body temperature (defining 100 degrees). There exist several stories on the exact original definition of his scale; however, some of the specifics have been presumed lost or exaggerated with time. The scale is now usually defined by two fixed points: the temperature at which water freezes into ice is defined as 32 degrees, and the boiling point of water is defined to be 212 degrees, a 180-degree separation, as defined at sea level and standard atmospheric pressure.
By the end of the 20th century, most countries used the Celsius scale, rather than the Fahrenheit scale, with 0° and 100° being water's freezing and boiling points on the Celsius scale. Fahrenheit remains the official scale for the following countries and territories: the Bahamas, Belize, the Cayman Islands, Palau, and the United States and its associated territories of Puerto Rico, the U.S. Virgin Islands, American Samoa (Guam uses equally both Celsius and Fahrenheit scales). Canada retains it as a supplementary scale that can be used alongside Celsius.
The Rankine temperature scale was based upon the Fahrenheit temperature scale, with its zero representing absolute zero instead.
Definition and conversions.
On the Fahrenheit scale, the freezing point of water is 32 degrees Fahrenheit (°F) and the boiling point is 212 °F (at standard atmospheric pressure). This puts the boiling and freezing points of water exactly 180 degrees apart. Therefore, a degree on the Fahrenheit scale is 1⁄180 of the interval between the freezing point and the boiling point. On the Celsius scale, the freezing and boiling points of water are 100 degrees apart. A temperature interval of 1 °F is equal to an interval of 5⁄9 degrees Celsius. The Fahrenheit and Celsius scales intersect at −40° (−40 °F and −40 °C represent the same temperature).
Absolute zero is −273.15 °C or −459.67 °F. The "Rankine" temperature scale uses degree intervals of the same size as those of the Fahrenheit scale, except that absolute zero is 0 R—the same way that the "Kelvin" temperature scale matches the Celsius scale, except that absolute zero is 0 K.
The Fahrenheit scale uses the symbol ° to denote a point on the temperature scale (as does Celsius) and the letter F to indicate the use of the Fahrenheit scale ("e.g." "Gallium melts at 85.5763 °F"), as well as to denote a difference between temperatures or an uncertainty in temperature ("e.g." "The output of the heat exchanger experiences an increase of 72 °F" and "Our standard uncertainty is ±5 °F").
A rough conversion between degrees Celsius and degrees Fahrenheit is as follows:
This formula gives an answer correct to within 1 °C for 0 °F (−17.8 °C) and within 4 °C for 100 °F (37.8 °C).
For an accurate conversion, the following formulas can be applied:
Fahrenheit to Celsius : (°F − 32) ÷ 1.8 =°C
Celsius to Fahrenheit : (°C × 1.8) + 32 =°F
History.
Fahrenheit proposed his temperature scale in 1724, basing it on three reference points of temperature. In his initial scale (which is not the final Fahrenheit scale), the zero point is determined by placing the thermometer in brine: he used a mixture of ice, water, and ammonium chloride, a salt, at a 1:1:1 ratio. This is a frigorific mixture which stabilizes its temperature automatically: that stable temperature was defined as 0 °F (−17.78 °C). The second point, at 32 degrees, was a mixture of ice and water without the ammonium chloride at a 1:1 ratio. The third point, 96 degrees, was approximately the human body temperature, then called "blood-heat".
According to a story and trivia questions in Germany, Fahrenheit actually chose the lowest air temperature measured in his hometown Danzig in winter 1708/09 as 0 °F, and only later had the need to be able to make this value reproducible using brine. This is one explanation given why 0 °F is −17.78 °C, but the ammonium chloride cooling temperature actually is −3 °C, whereas that of NaCl is −21.1 °C; the other explanation is that he did not have a good enough brine solution to obtain the eutectic equilibrium exactly (i.e. he might have had a mixture of salts, or it had not fully dissolved). In any case, the definition of the Fahrenheit scale has changed since.
According to a letter Fahrenheit wrote to his friend Herman Boerhaave, his scale was built on the work of Ole Rømer, whom he had met earlier. In Rømer's scale, brine freezes at zero, water freezes and melts at 7.5 degrees, body temperature is 22.5, and water boils at 60 degrees. Fahrenheit multiplied each value by four in order to eliminate fractions and increase the granularity of the scale. He then re-calibrated his scale using the melting point of ice and normal human body temperature (which were at 30 and 90 degrees); he adjusted the scale so that the melting point of ice would be 32 degrees and body temperature 96 degrees, so that 64 intervals would separate the two, allowing him to mark degree lines on his instruments by simply bisecting the interval six times (since 64 is 2 to the sixth power).
Fahrenheit observed that water boils at about 212 degrees using this scale. Later, other scientists decided to redefine the scale slightly to make the freezing point exactly 32 °F, and the boiling point exactly 212 °F or 180 degrees higher. It is for this reason that normal human body temperature is approximately 98° (oral temperature) on the revised scale (whereas it was 90° on Fahrenheit's multiplication of Rømer, and 96° on his original scale).
Usage.
The Fahrenheit scale was the primary temperature standard for climatic, industrial and medical purposes in English-speaking countries until the 1960s. In the late 1960s and 1970s, the Celsius scale replaced Fahrenheit in almost all of those countries—with the notable exception of the United States—typically during their metrication process.
Fahrenheit is used in the Bahamas, Belize, the Cayman Islands, Palau, and the United States and associated territories of American Samoa and the U.S. Virgin Islands for everyday applications (although Puerto Rico and Guam use Celsius alongside Fahrenheit as well). For example, U.S. weather forecasts, food cooking, and freezing temperatures are typically given in degrees Fahrenheit. Scientists, such as meteorologists, use Celsius or Kelvin in all countries.
Early in the twentieth century, Halsey and Dale suggested that the resistance to the use of centigrade (now Celsius) system in the U.S. included the larger size of each degree Celsius and the lower zero point in the Fahrenheit system.
Canada has passed legislation favoring the International System of Units, while also maintaining legal definitions for traditional Canadian imperial units. Canadian weather reports are conveyed using degrees Celsius with occasional reference to Fahrenheit especially for cross-border broadcasts. Virtually all Canadian ovens make legal use of the Fahrenheit scale. Thermometers, both digital and analog, sold in Canada usually employ both the Celsius and Fahrenheit scales. Also, in some instances (swimming pool temperature or cooking temperatures in Québec for example), temperatures are still expressed in Fahrenheit.
Within the European Union, it is mandatory to use kelvins or degrees Celsius when quoting temperature for "economic, public health, public safety and administrative" purposes, though degrees Fahrenheit may be used alongside degrees Celsius as a supplementary unit. For example, the laundry symbols used in the United Kingdom follow the recommendations of ISO 3758:2005 showing the temperature of the washing machine water in degrees Celsius only. The equivalent label in North America uses one to six dots to denote temperature with an optional temperature in degrees Celsius.
Within the unregulated sector, such as journalism, the use of Fahrenheit in the United Kingdom follows no fixed pattern with degrees Fahrenheit often appearing alongside degrees Celsius. "The Daily Mail", on its daily weather page, quotes Celsius first, followed by Fahrenheit in brackets, "The Daily Telegraph" does not mention Fahrenheit on its daily weather page while "The Times" also has an all-metric daily weather page but has a Celsius-to-Fahrenheit conversion table. When publishing news stories, much of the UK press adopted a convention of using degrees Celsius in headlines relating to low temperatures and Fahrenheit for high temperatures. In February 2006, the writer of an article in "The Times" suggested that the rationale was one of emphasis: "−6 °C" sounds colder than "21 °F" and "94 °F" sounds more impressive than "34 °C".
Unicode representation of symbol.
The Fahrenheit symbol has its own Unicode character: "℉"(U+2109). This is a compatibility character encoded for roundtrip compatibility with legacy CJK encodings (which included it to conform to layout in square ideographic character cells) and vertical layout. Use of compatibility characters is discouraged by the Unicode Consortium. The ordinary degree sign (U+00B0) followed by the Latin letter F ("°F") is thus the preferred way of recording the symbol for "degree Fahrenheit".

</doc>
<doc id="11525" url="http://en.wikipedia.org/wiki?curid=11525" title="Florence">
Florence

Florence (; Italian: "Firenze" ], alternative obsolete form: "Fiorenza"; Latin: "Florentia") is the capital city of the Italian region of Tuscany and of the province of Florence. It is the most populous city in Tuscany, with approximately 380,000 inhabitants, expanding to over 1,520,000 in the metropolitan area.
Florence is famous for its history: a centre of medieval European trade and finance and one of the wealthiest cities of the time, it is considered the birthplace of the Renaissance, and has been called "the Athens of the Middle Ages". A turbulent political history includes periods of rule by the powerful Medici family, and numerous religious and republican revolutions. From 1865 to 1871 the city was the capital of the recently established Kingdom of Italy.
The Historic Centre of Florence attracts millions of tourists each year, and Euromonitor International ranked the city as the world's 89th most visited in 2012, with 1.8 million visitors. It was declared a World Heritage Site by UNESCO in 1982. The city is noted for its culture, Renaissance art and architecture and monuments. The city also contains numerous museums and art galleries, such as the Uffizi Gallery and the Palazzo Pitti, and still exerts an influence in the fields of art, culture and politics. Due to Florence's artistic and architectural heritage, it has been ranked by "Forbes" as one of the most beautiful cities in the world.
Florence is an important city in Italian fashion, being ranked in the top 50 fashion capitals of the world; furthermore, it is a major national economic centre, as a tourist and industrial hub. In 2008, the city had the 17th highest average income in Italy.
History.
Florence originated as a Roman city, and later, after a long period as a flourishing trading and banking medieval commune, it was the birthplace of the Italian Renaissance (or the "Florentine Renaissance"). According to the "Encyclopædia Britannica", it was politically, economically, and culturally one of the most important cities in Europe and the world from the 14th to 16th centuries.
The language spoken in the city during the 14th century was, and still is, accepted as the Italian language. Almost all the writers and poets in Italian literature of the "golden age" are in some way connected with Florence, leading ultimately to the adoption of the Florentine dialect, above all the local dialects, as a literary language of choice.
Starting from the late Middle Ages, Florentine money—in the form of the gold florin—financed the development of industry all over Europe, from Britain to Bruges, to Lyon and Hungary. Florentine bankers financed the English kings during the Hundred Years War, as well as the papacy, including the construction of their provisional capital of Avignon and, after their return to Rome, the reconstruction and Renaissance embellishment of the latter.
Florence was home to the Medici, one of history's most important noble families. Lorenzo de' Medici was considered a political and cultural mastermind of Italy in the late 15th century. Two members of the family were popes in the early 16th century: Leo X and Clement VII. Catherine de Medici married king Henry II of France and, after his death in 1559, reigned as regent in France. The Medici reigned as Grand Dukes of Tuscany, starting with Cosimo I de' Medici in 1569 and ending with the death of Gian Gastone de' Medici in 1737.
Roman origins.
Florence was established by Lucius Cornelius Sulla in 80 BC as a settlement for his veteran soldiers and was named originally "Fluentia", owing to the fact that it was built between two rivers, which was later corrupted to "Florentia". It was built in the style of an army camp with the main streets, the "cardo" and the "decumanus", intersecting at the present "Piazza della Repubblica". Situated at the "Via Cassia", the main route between Rome and the north, and within the fertile valley of the Arno, the settlement quickly became an important commercial centre.
In centuries to come, the city experienced turbulent periods of Ostrogothic rule, during which the city was often troubled by warfare between the Ostrogoths and the Byzantines, which may have caused the population to fall to as few as 1,000 people. Peace returned under Lombard rule in the 6th century. Florence was conquered by Charlemagne in 774 and became part of the Duchy of Tuscany, with Lucca as capital. The population began to grow again and commerce prospered. In 854, Florence and Fiesole were united in one county.
Second millennium.
Margrave Hugo chose Florence as his residency instead of Lucca at about 1000 AD. The Golden Age of Florentine art began around this time. In 1013, construction began on the Basilica di San Miniato al Monte. The exterior of the baptistery was reworked in Romanesque style between 1059, and 1128. This period also saw the eclipse of Florence's formerly powerful rival Pisa (defeated by Genoa in 1284 and subjugated by Florence in 1406), and the exercise of power by the mercantile elite following an anti-aristocratic movement, led by Giano della Bella, that resulted in a set of laws called the Ordinances of Justice (1293).
Middle Ages and Renaissance.
Rise of the Medici.
Of a population estimated at 94,000 before the Black Death of 1348, about 25,000 are said to have been supported by the city's wool industry: in 1345 Florence was the scene of an attempted strike by wool combers ("ciompi"), who in 1378 rose up in a brief revolt against oligarchic rule in the Revolt of the Ciompi. After their suppression, Florence came under the sway (1382–1434) of the Albizzi family, bitter rivals of the Medici.
In the 15th century, Florence was among the largest cities in Europe, considered rich and economically successful. Life was not idyllic for all residents though, among whom there were great disparities in wealth. Cosimo de' Medici was the first Medici family member to essentially control the city from behind the scenes. Although the city was technically a democracy of sorts, his power came from a vast patronage network along with his alliance to the new immigrants, the "gente nuova" (new people). The fact that the Medici were bankers to the pope also contributed to their ascendancy. Cosimo was succeeded by his son Piero, who was, soon after, succeeded by Cosimo's grandson, Lorenzo in 1469. Lorenzo was a great patron of the arts, commissioning works by Michelangelo, Leonardo da Vinci and Botticelli. Lorenzo was an accomplished musician and brought composers and singers to Florence, including Alexander Agricola, Johannes Ghiselin, and Heinrich Isaac. By contemporary Florentines (and since), he was known as "Lorenzo the Magnificent" (Lorenzo il Magnifico).
Following the death of Lorenzo de' Medici in 1492, he was succeeded by his son Piero II. When the French king Charles VIII invaded northern Italy, Piero II chose to resist his army. But when he realized the size of the French army at the gates of Pisa, he had to accept the humiliating conditions of the French king. These made the Florentines rebel and they expelled Piero II. With his exile in 1494, the first period of Medici rule ended with the restoration of a republican government.
Savonarola and Machiavelli.
During this period, the Dominican monk Girolamo Savonarola had become prior of the San Marco monastery in 1490. He was famed for his penitential sermons, lambasting what he viewed as widespread immorality and attachment to material riches. He blamed the exile of the Medicis as the work of God, punishing them for their decadence. He seized the opportunity to carry through political reforms leading to a more democratic rule. But when Savonarola publicly accused Pope Alexander VI of corruption, he was banned from speaking in public. When he broke this ban, he was excommunicated. The Florentines, tired of his extreme teachings, turned against him and arrested him. He was convicted as a heretic and burned at the stake on the Piazza della Signoria on 23 May 1498.
A second individual of unusually acute insight was Niccolò Machiavelli, whose prescriptions for Florence's regeneration under strong leadership have often been seen as a legitimization of political expediency and even malpractice. In other words, Machiavelli was a sort of political thinker, perhaps most renowned for his political handbook, titled The Prince, which is about ruling and the exercise of power. Commissioned by the Medici, Machiavelli also wrote the Florentine Histories, the history of the city. Florentines drove out the Medici for a second time and re-established a republic on 16 May 1527. Restored twice with the support of both Emperor and Pope, the Medici in 1537 became hereditary dukes of Florence, and in 1569 Grand Dukes of Tuscany, ruling for two centuries. In all Tuscany, only the Republic of Lucca (later a Duchy) and the Principality of Piombino were independent from Florence.
18th and 19th centuries.
The extinction of the Medici dynasty and the accession in 1737 of Francis Stephen, duke of Lorraine and husband of Maria Theresa of Austria, led to Tuscany's temporary inclusion in the territories of the Austrian crown. It became a secundogeniture of the Habsburg-Lorraine dynasty, who were deposed for the House of Bourbon-Parma in 1801, themselves deposed in December 1807 when Tuscany was annexed by France. Florence was the prefecture of the French département of Arno from 1808 to the fall of Napoleon in 1814. The Habsburg-Lorraine dynasty was restored on the throne of Tuscany at the Congress of Vienna but finally deposed in 1859. Tuscany became a region of the Kingdom of Italy in 1861.
Florence replaced Turin as Italy's capital in 1865 and, in an effort to modernise the city, the old market in the Piazza del Mercato Vecchio and many medieval houses were pulled down and replaced by a more formal street plan with newer houses. The Piazza (first renamed Piazza Vittorio Emmanuele II, then Piazza della Repubblica, the present name) was significantly widened and a large triumphal arch was constructed at the west end. This development was unpopular and was prevented from continuing by the efforts of several British and American people living in the city. A museum recording the destruction stands nearby today.
The country's second capital city was superseded by Rome six years later, after the withdrawal of the French troops made its addition to the kingdom possible.
20th century.
After doubling during the 19th century, Florence's population was to triple in the 20th, resulting from growth in tourism, trade, financial services and industry.
During World War II the city experienced a year-long German occupation (1943–1944) and was declared an open city. The Allied soldiers who died driving the Germans from Tuscany are buried in cemeteries outside the city (Americans about nine kilometres (9 km) south of the city, British and Commonwealth soldiers a few kilometres east of the centre on the right bank of the Arno). In 1944, the retreating Germans demolished the bridges along the Arno linking the district of Oltrarno to the rest of the city, making it difficult for the British troops to cross. However, at the last moment Charle Steinhauslin, at the time consulate of 26 countries in Florence, convinced the German general in Italy that the Ponte Vecchio was not to be destroyed due to its historical value.
Instead, an equally historic area of streets directly to the south of the bridge, including part of the Corridoio Vasariano, was destroyed using mines. Since then the bridges have been restored to their original forms using as many of the remaining materials as possible, but the buildings surrounding the Ponte Vecchio have been rebuilt in a style combining the old with modern design. Shortly before leaving Florence, as they knew that they would soon have to retreat, the Germans executed many freedom fighters and political opponents publicly, in streets and squares including the Piazza Santo Spirito.
At the end of World War II in Europe, in May 1945, the U.S. Army's Information and Educational Branch was ordered to establish an overseas university campus for demobilized American service men and women in Florence, Italy. The first American University for service personnel was established in June 1945 at the School of Aeronautics in Florence, Italy. Some 7,500 soldier-students were to pass through the University during its four one-month sessions (see G. I. American Universities).
In November 1966, the Arno flooded parts of the centre, damaging many art treasures. Around the city there are tiny placards on the walls noting where the flood waters reached at their highest point.
Geography.
Florence lies in a basin formed by the hills of Careggi, Fiesole, Settignano, Arcetri, Poggio Imperiale and Bellosguardo (Florence). The Arno river and three other minor rivers flow through it.
Climate.
Florence has a humid subtropical climate ("Cfa"), slightly tending to Mediterranean ("Csa"). It has hot summers with moderate or light rainfall and cool, damp winters. As Florence lacks a prevailing wind, summer temperatures are higher than along the coast. Rainfall in summer is convectional, while relief rainfall dominates in the winter, with some snow. The highest officially recorded temperature was 42.6 °C on 26 July 1983 and the lowest was -23.2 °C on 12 January 1985.
Government.
The legislative body of the municipality is the City Council ("Consiglio Comunale"), which is composed of 36 councillors elected every five years with a proportional system, contextually to the mayoral elections. The executive body is the City Committee ("Giunta Comunale"), composed by 7 assessors, that is nominated and presieded over by a directly elected Mayor. The current mayor of Florence is Dario Nardella.
The municipality of Florence is subdivided into five administrative Boroughs ("Quartieri"). Each Borough is governed by a Council ("Consiglio") and a President, elected contextually to the city Mayor. The urban organization is governed by the Italian Constitution (art. 114). The Boroughs have the power to advise the Mayor with nonbinding opinions on a large spectrum of topics (environment, construction, public health, local markets) and exercise the functions delegated to them by the City Council; in addition they are supplied with an autonomous founding in order to finance local activities. The Boroughs are:
All of the five boroughs are governed by the Democratic Party.
A mayor of Florence was the current Italian Prime Minisiter, Matteo Renzi, who served as mayor from 2009 to 2014.
Main sights.
Florence is known as the "cradle of the Renaissance" ("la culla del Rinascimento") for its monuments, churches, and buildings. The best-known site of Florence is the domed cathedral of the city, Santa Maria del Fiore, known as "The Duomo", whose dome was built by Filippo Brunelleschi. The nearby Campanile (partly designed by Giotto) and the Baptistery buildings are also highlights. The dome, 600 years after its completion, is still the largest dome built in brick and mortar in the world. In 1982, the historic centre of Florence (Italian: "centro storico di Firenze") was declared a World Heritage Site by the UNESCO. The centre of the city is contained in medieval walls that were built in the 14th century to defend the city. At the heart of the city, in Piazza della Signoria, is Bartolomeo Ammanati's Fountain of Neptune (1563–1565), which is a masterpiece of marble sculpture at the terminus of a still functioning Roman aqueduct.
The layout and structure of Florence in many ways harkens back to the Roman era, where it was designed as a garrison settlement. Nevertheless, the majority of the city was built during the Renaissance. Despite the strong presence of Renaissance architecture within the city, traces of medieval, Baroque, Neoclassical and modern architecture can be found. The Palazzo Vecchio as well as the Duomo, or the city's Cathedral, are the two buildings which dominate Florence's skyline.
The River Arno, which cuts through the old part of the city, is as much a character in Florentine history as many of the people who lived there. Historically, the locals have had a love-hate relationship with the Arno – which alternated between nourishing the city with commerce, and destroying it by flood.
One of the bridges in particular stands out — the Ponte Vecchio ("Old Bridge"), whose most striking feature is the multitude of shops built upon its edges, held up by stilts. The bridge also carries Vasari's elevated corridor linking the Uffizi to the Medici residence (Palazzo Pitti). Although the original bridge was constructed by the Etruscans, the current bridge was rebuilt in the 14th century. It is the only bridge in the city to have survived World War II intact. It is the first example in the western world of a bridge built using segmental arches, that is, arches less than a semicircle, to reduce both span-to-rise ratio and the numbers of pillars to allow lesser encumbrance in the riverbed (being in this much more successful than the Roman Alconétar Bridge).
The church of San Lorenzo contains the Medici Chapel, the mausoleum of the Medici family—the most powerful family in Florence from the 15th to the 18th century. Nearby is the Uffizi Gallery, one of the finest art museums in the world – founded on a large bequest from the last member of the Medici family.
The Uffizi is located at the corner of Piazza della Signoria, a site important for being the centre of Florence's civil life and government for centuries. The Palazzo della Signoria facing it is still home of the municipal government. The Loggia dei Lanzi provided the setting for all the public ceremonies of the republican government. Many significant episodes in the history of art and political changes were staged here, such as:
The Piazza della Signoria is the location of a number of statues by other sculptors such as Donatello, Giambologna, Ammannati and Cellini, although some have been replaced with copies to preserve the originals.
Monuments, museums and religious buildings.
Florence contains several palaces and buildings from various eras. The Palazzo Vecchio is the town hall of Florence and also an art museum. This large Romanesque crenellated fortress-palace overlooks the Piazza della Signoria with its copy of Michelangelo's David statue as well the gallery of statues in the adjacent Loggia dei Lanzi. Originally called the "Palazzo della Signoria", after the Signoria of Florence, the ruling body of the Republic of Florence, it was also given several other names: "Palazzo del Popolo", "Palazzo dei Priori", and "Palazzo Ducale", in accordance with the varying use of the palace during its long history. The building acquired its current name when the Medici duke's residence was moved across the Arno to the Palazzo Pitti. It is linked to the Uffizi and the Palazzo Pitti through the Corridoio Vasariano.
Palazzo Medici Riccardi, designed by Michelozzo di Bartolomeo for Cosimo il Vecchio, of the Medici family, is another major edifice, and was built between 1445 and 1460. It was well known for its stone masonry that includes rustication and ashlar. Today it is the head office of the Florence province and hosts museums and the Riccardiana Library. The Palazzo Strozzi, an example of civil architecture with its rusticated stone, was inspired by the Palazzo Medici, but with more harmonious proportions. Today the palace is used for international expositions like the annual antique show (founded as the Biennale del'Antiquariato in 1959), fashion shows and other cultural and artistic events. Here also is the seat of the Istituto Nazionale del Rinascimento and the noted Gabinetto Vieusseux, with the library and reading room. Aside from these palaces and buildings, there are several others, including the Palazzo Rucellai, designed by Leon Battista Alberti between 1446 and 1451 and executed, at least in part, by Bernardo Rossellino; the Palazzo Davanzati, which houses the museum of the Old Florentine House; the Palazzo delle Assicurazioni Generali, designed in the Neo-Renaissance style in 1871; the Palazzo Spini Feroni, in Piazza Santa Trinita, a historic 13th-century private palace, owned since the 1920s by shoe-designer Salvatore Ferragamo; as well as various others, including the Palazzo Borghese, the Palazzo di Bianca Cappello, the Palazzo Antinori, and the Royal building of Santa Maria Novella.
Florence contains numerous museums and art galleries where some of the world's most important works of art are held. The city is one of the best preserved Renaissance centres of art and architecture in the world and has a high concentration of art, architecture and culture. In the ranking list of the 15 most visited Italian art museums, 2/3 are represented by Florentine museums. The Uffizi is one of these; one of the most famous and important art galleries in the world, it has a very large collection of international and Florentine art. The gallery is articulated in many halls, cataloged by schools and chronological order. Engendered by the Medici family's artistic collections through the centuries, it houses works of art by various painters and artists. The Vasari Corridor is another gallery, built connecting the Palazzo Vecchio with the Pitti Palace passing by the Uffizi and over the Ponte Vecchio. The Galleria dell' Accademia houses a Michelangelo collection, including the David. It has a collection of Russian icons and works by various artists and painters. Furthermore, other museums and galleries include the Bargello, which concentrates on sculpture works by artists including Donatello, Giambologna and Michelangelo; the Palazzo Pitti, containing part of the Medici family's former private collection. In addition to the Medici collection, the palace's galleries contain many Renaissance works, including several by Raphael and Titian, large collections of costumes, ceremonial carriages, silver, porcelain and a gallery of modern art dating from the 18th century. Adjoining the palace are the Boboli Gardens, elaborately landscaped and with numerous sculptures.
There are several different churches and religious buildings in Florence. The cathedral is the Santa Maria del Fiore. The San Giovanni Baptistery is located in front of the cathedral, and is decorated by numerous artists, notably by Lorenzo Ghiberti with the "Gates of Paradise". Other churches in Florence include the Basilica of Santa Maria Novella, located in Santa Maria Novella square (near the Firenze Santa Maria Novella railway station) which contains works by Masaccio, Paolo Uccello, Filippino Lippi and Domenico Ghirlandaio; the Basilica of Santa Croce, the principal Franciscan church in the city, which is situated on the Piazza di Santa Croce, about 800 metres south east of the Duomo, and is the burial place of some of the most illustrious Italians, such as Michelangelo, Galileo, Machiavelli, Foscolo, Gentile, Rossini, and Marconi, thus it is known also as the Temple of the Italian Glories (Tempio dell'Itale Glorie); the Basilica of San Lorenzo, which is one of the largest churches in the city, situated at the centre of Florence's main market district, and the burial place of all the principal members of the Medici family from Cosimo il Vecchio to Cosimo III; Santo Spirito, in the Oltrarno quarter, facing the square with the same name; Orsanmichele, whose building was constructed on the site of the kitchen garden of the monastery of San Michele, now demolished; Santissima Annunziata, a Roman Catholic basilica and the mother church of the Servite order; Ognissanti, which was founded by the lay order of the Umiliati, and is among the first examples of Baroque architecture built in the city; the Santa Maria del Carmine, in the Oltrarno district of Florence, which is the location of the Brancacci Chapel, housing outstanding Renaissance frescoes by Masaccio and Masolino da Panicale, later finished by Filippino Lippi; the Medici Chapel, in the San Lorenzo; as well as several others, including Santa Trinita, San Marco, Santa Felicita, Badia Fiorentina, San Gaetano, San Miniato al Monte, Florence Charterhouse, and Santa Maria del Carmine. The city additionally contains the Orthodox Russian church of Nativity, and the Great Synagogue of Florence, built in the 19th century.
Additionally, Florence contains various theatres and cinemas. The Odeon Cinema of the Palazzo dello Strozzino is one of the oldest movie theatres in the city. Established from 1920 to 1922 in a wing of the Palazzo dello Strozzino, it used to be called the "Cinema Teatro Savoia" (Savoy Cinema-Theatre), yet was later called "Odeon". The Teatro della Pergola, located in the centre of the city on the eponymous street, is an opera house built in the 17th century. Another theatreis the Teatro Comunale (or "Teatro del Maggio Musicale Fiorentino"), originally built as the open-air amphitheatre, the "Politeama Fiorentino Vittorio Emanuele", which was inaugurated on 17 May 1862 with a production of Donizetti's "Lucia di Lammermoor" and which seated 6,000 people. There are several other theatres, such as the Saloncino Castinelli, the Teatro Puccini, the Teatro Verdi, the Teatro Goldoni and the Teatro Niccolini.
Squares, streets and parks.
Aside from such monuments, Florence contains numerous major squares ("piazze") and streets. The Piazza della Repubblica is a square in the city centre, location of the cultural cafes and bourgeois palaces. Among the square's cafes (like Caffè Gilli, Paszkowski or the Hard Rock Cafè), the Giubbe Rosse cafe has long been a meeting place for artists and writers, notably those of Futurism. The Piazza Santa Croce is another; dominated by the Basilica of Santa Croce, it is a rectangular square in the centre of the city where the Calcio Fiorentino is played every year. Furthermore, there is the Piazza Santa Trinita, a square near the Arno that mark the end of the Via de' Tornabuoni street.
Other squares include the Piazza San Marco, the Piazza Santa Maria Novella, the Piazza Beccaria and the Piazza della Libertà. The centre additionally contains several streets. Such include the Via Camillo Cavour, one of the main roads of the northern area of the historic centre; the Via Ghibellina, one of central Florence's longest streets; the Via dei Calzaiuoli, one of most central streets of the historic centre of the which links "Piazza del Duomo" to "Piazza della Signoria", winding parallel to via Roma and "Piazza della Repubblica"; the Via de' Tornabuoni, a luxurious street in the city centre that goes from Antinori square to ponte Santa Trinita, across Piazza Santa Trinita, characterised by the presence of fashion boutiques; the Viali di Circonvallazione, 6-lane boulevards surrounding the northern part of the historic centre; as well as others, such as Via Roma, Via degli Speziali, Via de' Cerretani, and the Viale dei Colli.
Florence also contains various parks and gardens. Such include the Boboli Gardens, the Parco delle Cascine, the Giardino Bardini and the Giardino dei Semplici, amongst others.
Demographics.
In 1200 the city was home to 50,000 people. By 1300 the population of the city proper was 120,000, with an additional 300,000 living in the Contado. Between 1500 and 1650 the population was around 70,000.
s of 31 2010[ [update]], the population of the city proper is 370,702, while Eurostat estimates that 696,767 people live in the urban area of Florence. The Metropolitan Area of Florence, Prato and Pistoia, constituted in 2000 over an area of roughly 4800 km2, is home to 1.5 million people. Within Florence proper, 46.8% of the population was male in 2007 and 53.2% were female. Minors (children aged 18 and less) totalled 14.10 percent of the population compared to pensioners, who numbered 25.95 percent. This compares with the Italian average of 18.06 percent (minors) and 19.94 percent (pensioners). The average age of Florence resident is 49 compared to the Italian average of 42. In the five years between 2002 and 2007, the population of Florence grew by 3.22 percent, while Italy as a whole grew by 3.56 percent. The birth rate of Florence is 7.66 births per 1,000 inhabitants compared to the Italian average of 9.45 births.
As of 2009, 87.46% of the population was Italian. An estimated 6,000 Chinese live in the city. The largest immigrant group came from other European countries (mostly Romanians and Albanians): 3.52%, East Asia (mostly Chinese and Filipino): 2.17%, the Americas: 1.41%, and North Africa (mostly Moroccan): 0.9%.
Economy.
Tourism is, by far, the most important of all industries and most of the Florentine economy relies on the money generated by international arrivals and students studying in the city. Manufacturing and commerce, however, still remain highly important. Florence is also Italy's 17th richest city in terms of average workers' earnings, with the figure being €23,265 (the overall city's income is that of €6,531,204,473), coming after Mantua, yet surpassing Bolzano.
In 2013, Florence was listed as the second best world city by "Condé Nast Traveler".
Industry, commerce and services.
Florence is a major production and commercial centre in Italy, where the Florentine industrial complexes in the suburbs produce all sorts of goods, from furniture, rubber goods, chemicals, and food. However, traditional and local products, such as antiques, handicrafts, glassware, leatherwork, art reproductions, jewelry, souvenirs, elaborate metal and iron-work, shoes, accessories and high fashion clothes also dominate a fair sector of Florence's economy. The city's income relies partially on services and commercial and cultural interests, such as annual fairs, theatrical and lyrical productions, art exhibitions, festivals and fashion shows, such as the Calcio Fiorentino. Heavy industry and machinery also take their part in providing an income. In Nuovo Pignone, numerous factories are still present, and small-to medium industrial businesses are dominant. The Florence-Prato-Pistoia industrial districts and areas were known as the 'Third Italy' in the 1990s, due to the exports of high-quality goods and automobile (especially the Vespa) and the prosperity and productivity of the Florentine entrepreneurs. Some of these industries even rivaled the traditional industrial districts in Emilia-Romagna and Veneto due to high profits and productivity.
Tourism.
Tourism is the most significant industry in central Florence. From April to October, tourists outnumber local population. Tickets to the Uffizi and Accademia museums are regularly sold out and large groups regularly fill the basilicas of Santa Croce and Santa Maria Novella, both of which charge for entry. In 2010, readers of "Travel + Leisure" magazine ranked the city as their third favourite tourist destination. Studies by Euromonitor International have concluded that cultural and history-oriented tourism is generating significantly increased spending throughout Europe.
Florence is believed to have the greatest concentration of art (in proportion to its size) in the world. Thus, cultural tourism is particularly strong, with world-renowned museums such as the Uffizi selling over 1.6 million tickets a year. The city's convention centre facilities were restructured during the 1990s and host exhibitions, conferences, meetings, social forums, concerts and other events all year.
Florence has approximately 35,000 hotel beds and 23,000 other accommodation facilities (campsites, guesthouses, youth hostels and farmhouses), giving potential for overall stays to exceed 10 million visitor/nights a year. Visitors also include thousands of day-trippers brought in by cruise ships (to Livorno) and by road and rail. In 2007, the city ranked as the world's 59th most visited city, with over 1.729 million arrivals for the year. It has been estimated that just under one-third of tourists are Italians, the remainder comprising Americans (20%), Germans (13%), Japanese (8%), Britons (7.8%), French (5.7%) and Spaniards (5%).
Food and wine production.
Food and wine have long been an important staple of the economy. Florence is the most important city in Tuscany, one of the great wine-growing regions in the world. The Chianti region is just south of the city, and its Sangiovese grapes figure prominently not only in its Chianti Classico wines but also in many of the more recently developed Supertuscan blends. Within 32 km to the west is the Carmignano area, also home to flavorful sangiovese-based reds. The celebrated Chianti Rufina district, geographically and historically separated from the main Chianti region, is also few kilometres east of Florence. More recently, the Bolgheri region (about 150 km southwest of Florence) has become celebrated for its "Super Tuscan" reds such as Sassicaia and Ornellaia.
Culture.
Art.
Florence has a legendary artistic heritage. Cimabue and Giotto, the fathers of Italian painting, lived in Florence as well as Arnolfo and Andrea Pisano, renewers of architecture and sculpture; Brunelleschi, Donatello and Masaccio, forefathers of the Renaissance, Ghiberti and the Della Robbias, Filippo Lippi and Angelico; Botticelli, Paolo Uccello and the universal genius of Leonardo da Vinci and Michelangelo.
Their works, together with those of many other generations of artists, are gathered in the several museums of the town: the Uffizi Gallery, the Palatina gallery with the paintings of the "Golden Ages", the Bargello with the sculptures of the Renaissance, the museum of San Marco with Fra Angelico's works, the Academy, the chapels of the Medicis Buonarroti's house with the sculptures of Michelangelo, the following museums: Bardini, Horne, Stibbert, Romano, Corsini, The Gallery of Modern Art, the Museo dell'Opera del Duomo, the museum of Silverware and the museum of Precious Stones.
Great monuments are the landmarks of Florentine artistic culture: the Florence Baptistery with its mosaics; the Cathedral with its sculptures, the medieval churches with bands of frescoes; public as well as private palaces: Palazzo Vecchio, Palazzo Pitti, Palazzo Medici Riccardi, Palazzo Davanzati; monasteries, cloisters, refectories; the "Certosa". In the archeological museum includes documents of Etruscan civilization. In fact the city is so rich in art that some first time visitors experience the Stendhal syndrome as they encounter its art for the first time.
Florentine architects such as Filippo Brunelleschi (1377–1466) and Leon Battista Alberti (1404–1472) were among the fathers of both Renaissance and Neoclassical architecture.
The cathedral, topped by Brunelleschi's dome, dominates the Florentine skyline. The Florentines decided to start building it – late in the 13th century, without a design for the dome. The project proposed by Brunelleschi in the 14th century was the largest ever built at the time, and the first major dome built in Europe since the two great domes of Roman times – the Pantheon in Rome, and Hagia Sophia in Constantinople. The dome of Santa Maria del Fiore remains the largest brick construction of its kind in the world. In front of it is the medieval Baptistery. The two buildings incorporate in their decoration the transition from the Middle Ages to the Renaissance. In recent years, most of the important works of art from the two buildings – and from the nearby Giotto's Campanile, have been removed and replaced by copies. The originals are now housed in the Museum dell'Opera del Duomo, just to the east of the Cathedral.
Florence has large numbers of art-filled churches, such as San Miniato al Monte, San Lorenzo, Santa Maria Novella, Santa Trinita, Santa Maria del Carmine, Santa Croce, Santo Spirito, the Annunziata, Ognissanti and numerous others.
Artists associated with Florence range from Arnolfo di Cambio and Cimabue to Giotto, Nanni di Banco, and Paolo Uccello; through Lorenzo Ghiberti, and Donatello and Massaccio and the della Robbia family; through Fra Angelico and Botticelli and Piero della Francesca, and on to Michelangelo and Leonardo da Vinci. Others include Benvenuto Cellini, Andrea del Sarto, Benozzo Gozzoli, Domenico Ghirlandaio, Filippo Lippi, Bernardo Buontalenti, Orcagna, Pollaiuolo, Filippino Lippi, Verrocchio, Bronzino, Desiderio da Settignano, Michelozzo, the Rossellis, the Sangallos, and Pontormo. Artists from other regions who worked in Florence include Raphael, Andrea Pisano, Giambologna, Il Sodoma and Peter Paul Rubens.
The Uffizi and the Pitti Palace are two of the most famous picture galleries in the world. Two superb collections of sculpture are in the Bargello and the Museum of the Works of the Duomo. They are filled with the creations of Donatello, Verrochio, Desiderio da Settignano, Michelangelo and others. The Galleria dell'Accademia has Michelangelo's David – perhaps the most well-known work of art anywhere, plus the unfinished statues of the slaves Michelangelo created for the tomb of Pope Julius II. Other sights include the medieval city hall, the Palazzo della Signoria (also known as the Palazzo Vecchio), the Archeological Museum, the Museum of the History of Science, the Palazzo Davanzatti, the Stibbert Museum, St. Marks, the Medici Chapels, the Museum of the Works of Santa Croce, the Museum of the Cloister of Santa Maria Novella, the Zoological Museum ("La Specola"), the Bardini, and the Museo Horne. There is also a collection of works by the modern sculptor, Marino Marini, in a museum named after him. The Strozzi Palace is the site of special exhibits.
Language.
Florentine ("fiorentino"), spoken by inhabitants of Florence and its environs, is a Tuscan dialect and the immediate parent language to modern Italian.
Its vocabulary and pronunciation are largely identical to standard Italian, though the hard "c" [k] between two vowels (as in "ducato") is pronounced as a fricative [h], similar to an English "h". This gives Florentines a highly recognizable accent (the so-called gorgia toscana). Other traits include using a form of the subjunctive mood last commonly used in medieval times, a frequent usage in everyday speech of the modern subjunctive, and a shortened pronunciation of the definite article, [i] instead of "il".
Dante, Petrarch, and Boccaccio pioneered the use of the vernacular instead of the Latin used for most literary works at the time.
Literature.
Despite Latin being the main language of the courts and the Church, writers such as Dante Alighieri and many others used their own language, the Florentine dialect, in composing their works. The oldest literary pieces written in vernacular language go as far back as the 13th century. Florence's literature fully blossomed in the 14th century, when not only Dante with his "Divine Comedy" (1306–1321) and Petrarch, but also poets such as Guido Cavalcanti and Lapo Gianni composed their most important works. Dante's masterpiece is the "Divine Comedy", which mainly deals with the poet himself taking an allegoric and moral tour of Hell, Purgatory and finally Heaven, during which he meets numerous mythological or real characters of his age or before. He is first guided by the Roman poet Virgil, whose non-Christian beliefs damned him to Hell. Later on he is joined by Beatrice, who guides him through Heaven.
In the 14th century, Petrarch and Giovanni Boccaccio led the literary scene in Florence after Dante's death in 1321. Petrarch was an all-rounder writer, author and poet, but was particularly known for his "Canzoniere", or the Book of Songs, where he conveyed his unremitting love for Laura. His style of writing has since become known as "Petrarchism". Boccaccio was better known for his "Decameron", a slightly grim story of Florence during the 1350s bubonic plague, known as the Black Death, when some people fled the ravaged city to an isolated country mansion, and spent their time there recounting stories and novellas taken from the medieval and contemporary tradition. All of this is written in a series of 100 distinct novellas.
In the 16th century, during the Renaissance, Florence was the hometown of political writer and philosopher Niccolò Machiavelli, whose ideas on how rulers should govern the land, detailed in "The Prince", spread across European courts and enjoyed enduring popularity for centuries. These principles became known as "Machiavellianism".
Music.
Florence became a musical centre during the Middle Ages and music and the performing arts remain an important part of its culture. During the Renaissance there were four kinds of musical patronage in the city with respect to both sacred and secular music: state, corporate, church, and private. and it was here that the Florentine Camerata convened in the mid-16th century and experimented with setting tales of Greek mythology to music and staging the result—in other words, the first operas, setting the wheels in motion not just for the further development of the operatic form, but for later developments of separate "classical" forms such as the symphony.
Opera was invented in Florence in the late 16th century.
Composers and musicians who have lived in Florence include Piero Strozzi (1550 – after 1608), Giulio Caccini (1551–1618) and Mike Francis (1961–2009).
Cinema.
Florence has been a setting for numerous works of fiction and movies, including the novels and associated films, such as "Light in the Piazza", "Calmi Cuori Appassionati", "Hannibal", "A Room with a View", "Tea with Mussolini" and "Virgin Territory". The city is home to renowned Italian actors and actresses, such as Roberto Benigni, Leonardo Pieraccioni and Vittoria Puccini.
Cuisine.
Florentine food grows out of a tradition of peasant eating rather than rarefied high cooking. The majority of dishes are based on meat. The whole animal was traditionally eaten; tripe, ("trippa") and ("lampredotto") were once regularly on the menu and still are sold at the food carts stationed throughout the city. Antipasti include "crostini toscani", sliced bread rounds topped with a chicken liver-based pâté, and sliced meats (mainly prosciutto and salame, often served with melon when in season). The typically saltless Tuscan bread, obtained with natural levain frequently features in Florentine courses, especially in its soups, "ribollita" and "pappa al pomodoro", or in the salad of bread and fresh vegetables called "panzanella" that is served in summer. The "bistecca alla fiorentina" is a large (the customary size should weigh around 1200 grams – "40 oz.") – the "date" steak – T-bone steak of Chianina beef cooked over hot charcoal and served very rare with its more recently derived version, the "tagliata", sliced rare beef served on a bed of arugula, often with slices of Parmesan cheese on top. Most of these courses are generally served with local olive oil, also a prime product enjoying a worldwide reputation. <br> Among the desserts, "schiacciata alla fiorentina" ("white flatbread cake") is one of the most popular; it is a very soft cake, prepared with extremely simple ingredients as it is peculiar of the florentine cuisine, and it is typically eaten on Carnival time.
Research activity.
Research institutes and university departments are located within the Florence area and within two campuses at
Polo di Novoli and Polo Scientifico di Sesto Fiorentino as well as in the Research Area of Consiglio Nazionale delle Ricerche.
Science and discovery.
Florence has been an important scientific centre for centuries, notably during the Renaissance with scientists such as Leonardo da Vinci.
Florentines were one of the driving forces behind the Age of Discovery. Florentine bankers financed Henry the Navigator and the Portuguese explorers who pioneered the route around Africa to India and the Far East. It was a map drawn by the Florentine Paolo dal Pozzo Toscanelli, a student of Brunelleschi, that Columbus used to sell his "enterprise" to the Spanish monarchs, and which he used on his first voyage. Mercator's "Projection" is a refined version of Toscanelli's – taking into account the Americas, of which the Florentine was, obviously, ignorant.
Galileo and other scientists pioneered the study of optics, ballistics, astronomy, anatomy, and so on. Pico della Mirandola, Leonardo Bruni, Machiavelli, and many others laid the groundwork for our understanding of political science.
Fashion.
By the year 1300 Florence had become a center of textile production in Europe. Many of the rich families in Renaissance Florence were major purchasers of locally produced fine clothing, and the specialists of fashion in the economy and culture of Florence during that period is often underestimated. Florence is regarded by some as the birthplace and earliest center of the modern (post World War Two) fashion industry in Italy. The Florentine "soirées" of the early 1950s organized by Giovanni Battista Giorgini were events where several now-famous Italian designers participated in group shows and first garnered international attention. Florence has served as the home of the Italian fashion company Salvatore Ferragamo since 1928. Gucci, Roberto Cavalli, and Emilio Pucci are also headquartered in Florence. Other major players in the fashion industry such as Prada and Chanel have large offices and stores in Florence or its outskirts. Florence's main upscale shopping street is Via de' Tornabuoni, where major luxury fashion houses and jewelry labels, such as Armani and Bulgari, have their elegant boutiques. Via del Parione and Via Roma are other streets that are also well known for their high-end fashion stores.
Historical evocations.
"Scoppio del Carro".
The "Scoppio del Carro" ("Explosion of the Cart") is a celebration of the First Crusade. During the day of Easter, a cart, which the Florentines call the "Brindellone" and which is led by four white oxen, is taken to the Piazza del Duomo between the Baptistery of St. John the Baptist ("Battistero di San Giovanni") and the Florence Cathedral ("Santa Maria del Fiore"). The cart is connected by a rope to the interior of the church. Near the cart there is a model of a dove, which, according to legend, is a symbol of good luck for the city: at the end of the Easter mass, the dove emerges from the nave of the Duomo and ignites the fireworks on the cart.
"Calcio Storico".
"Calcio Storico Fiorentino" ("Historic Florentine Football"), sometimes called "Calcio in costume", is a traditional sport, regarded as a forerunner of soccer, though the actual gameplay most closely resembles rugby. The event originates from the Middle Ages, when the most important Florentine nobles amused themselves playing while wearing bright costumes. The most important match was played on 17 February 1530, during the siege of Florence. That day Papal troops besieged the city while the Florentines, with contempt of the enemies, decided to play the game notwithstanding the situation. The game is played in the Piazza di Santa Croce. A temporary arena is constructed, with bleachers and a sand-covered playing field. A series of matches are held between four teams representing each "quartiere "(quarter) of Florence during late June and early July. There are four teams: Azzurri (light blue), Bianchi (white), Rossi (red) and Verdi (green). The Azzurri are from the quarter of Santa Croce, Bianchi from the quarter of Santo Spirito, Verdi are from San Giovanni and Rossi from Santa Maria Novella.
Transport.
The principal public transport network within the city is run by the bus company, with tickets available at local tobacconists, bars and newspaper stalls. Individual tickets, or a pass called the Carta Agile with multiple rides (10, 21 or 35), may be used on ATAF&Li-nea buses, Tramvia, and 2nd class local trains but only within city railway stations. Once on the bus, tickets must be stamped (or swiped for the Carta Agile) using the machines on board, unlike train tickets which must be validated before boarding. The main bus station is next to Santa Maria Novella railway station. Trenitalia runs trains between the railway stations within the city, and to other destinations around Italy and Europe. The central railway station, Santa Maria Novella railway station, is located about 500 m northwest of the Piazza del Duomo. There are two other important stations: Campo Di Marte and Rifredi. Most bundled routes are Firenze—Pisa, Firenze—Viareggio and Firenze-Arezzo (along the main line to Rome). Other local railways connect Florence with Borgo San Lorenzo in the Mugello area (Faentina railway) and Siena.
Long distance 10 km buses are run by the SITA, Copit, CAP companies. The transit companies also accommodate travellers from the Amerigo Vespucci Airport, which is five kilometres (5 km) west of the city centre, and which has scheduled services run by major European carriers.
The centre of the city is closed to through-traffic, although buses, taxis and residents with appropriate permits are allowed in. This area is commonly referred to as the ZTL ("Zona Traffico Limitato"), which is divided into five subsections. Residents of one section, therefore, will only be able to drive in their district and perhaps some surrounding ones. Cars without permits are allowed to enter after 7.30 pm, or before 7.30 am. The rules shift during the tourist-filled summers, putting more restrictions on where one can get in and out.
In an effort to reduce air pollution and car traffic in the city, a multi-line tram network called "Tramvia" is under construction. The first line began operation on 14 February 2010 and connects Florence's primary intercity railway station (Santa Maria Novella) with the southwestern suburb of Scandicci. This line is 7.4 km long and has 14 stops. The construction of a second line began on 5 November 2011, construction was stopped due to contractors' difficulties but should restart in a few months, completion is now previewed in 2017. This second line will connect Florence's airport with the city centre. A third line (from Santa Maria Novella to the Careggi area, where are the most important hospitals of Florence) has gained governmental approval, its construction will follow the second line's timeline.
Railway station.
Firenze Santa Maria Novella railway station is the main national and international railway station in Florence and is used by 59 million people every year. The building, designed by Giovanni Michelucci, was built in the "Italian Rationalism" style and it is one of the major rationalist buildings in Italy. It is located in "Piazza della Stazione", near the Fortezza da Basso (a masterpiece of the military Renaissance architecture) and the Viali di Circonvallazione, and in front of the Basilica of Santa Maria Novella's apse, from which it takes its name.
A new high-speed rail station is under construction and is contracted to be operational by 2015. It is planned to be connected to Vespucci airport, Santa Maria Novella railway station, and to the city centre by the second line of Tramvia. The architectural firms Foster + Partners and Lancietti Passaleva Giordo and Associates designed this new rail station.
Airport.
Florence Airport, Peretola is one of two main airports in the Tuscany region, the other being Galileo Galilei International Airport in Pisa.
Sport.
Florence is represented by ACF Fiorentina, who play in Serie A, the top league of Italian football. They play their games at the Stadio Artemio Franchi, which currently holds 47,282. The city is home of Coverciano, the main training ground of the Italian national team, and the technical department of the Italian Football Federation.
Florence was selected to host the 2013 UCI World Road Cycling Championships.
International relations.
Twin towns and sister cities.
Florence is twinned with:
Sources.
</dl>
External links.
 

</doc>
<doc id="11526" url="http://en.wikipedia.org/wiki?curid=11526" title="Quotient group">
Quotient group

In mathematics, specifically group theory, a quotient group (or factor group) is a group obtained by aggregating similar elements of a larger group using an equivalence relation that preserves the group structure. For example, the cyclic group of addition modulo "n" can be obtained from the integers by identifying elements that differ by a multiple of "n" and defining a group structure that operates on each such class (known as a congruence class) as a single entity.
In a quotient of a group, the equivalence class of the identity element is always a normal subgroup of the original group, and the other equivalence classes are precisely the cosets of that normal subgroup. The resulting quotient is written "G" / "N", where "G" is the original group and "N" is the normal subgroup. (This is pronounced ""G" mod "N"," where "mod" is short for modulo.)
Much of the importance of quotient groups is derived from their relation to homomorphisms. The first isomorphism theorem states that the image of any group "G" under a homomorphism is always isomorphic to a quotient of "G". Specifically, the image of "G" under a homomorphism "φ": "G" → "H" is isomorphic to "G" / ker("φ") where ker("φ") denotes the kernel of "φ".
The dual notion of a quotient group is a subgroup, these being the two primary ways of forming a smaller group from a larger one. Any normal subgroup has a corresponding quotient group, formed from the larger group by eliminating the distinction between elements of the subgroup. In category theory, quotient groups are examples of quotient objects, which are dual to subobjects. For other examples of quotient objects, see quotient ring, quotient space (linear algebra), quotient space (topology), and quotient set.
Definition and illustration.
Given a group "G" and a subgroup "H", and an element "a" in "G", then one can consider the corresponding left coset : "aH":={ "ah" : "h" in "H" }. Cosets are a natural class of subsets of a group; for example consider the abelian group "G" of integers, and the subgroup "H" of even integers. Then there are exactly two cosets: "0 + H", which are the even integers, and "1 + H", which are the odd integers (here we are using additive notation for the binary operation instead of multiplicative notation). 
For a general subgroup "H", it is desirable to define a compatible group operation on the set of all possible cosets, { "aH" : "a" in "G" }. This is possible exactly when "H" is a normal subgroup, as we will see below. A subgroup "N" of a group "G" is normal if and only if the coset equality "aN" = "Na" holds for all "a" in "G". A normal subgroup of "G" is denoted "N" ◁ "G". 
Definition.
Let "N" be a normal subgroup of a group "G". We define the set "G"/"N" to be the set of all left cosets of "N" in "G", i.e., "G"/"N" = { "aN" : "a" ∈ "G" }. Define an operation on "G"/"N" as follows. For each "aN" and "bN" in "G"/"N", the product of "aN" and "bN" is ("aN")("bN"). This defines an operation on "G"/"N", because we have the following equalities of subsets of "G":
Here we have used in an important way that "N" is a normal subgroup. One checks that this operation on "G"/"N" is associative, has identity element "N", and the inverse of an element "aN" of "G"/"N" is "a"−1"N". Therefore, the set "G"/"N" together with the operation defined above forms a group; this is known as the quotient group of "G" by "N".
Because of the normality of "N", the left cosets and right cosets of "N" in "G" are equal, and so we could have instead defined "G"/"N" to be the set of right cosets of "N" in "G".
Example: Addition modulo 6.
For example, consider the group with addition modulo 6: "G" = {0, 1, 2, 3, 4, 5}. Consider the subgroup "N" = {0, 3}, which is normal because "G" is abelian. Then set of (left) cosets is of size three:
The binary operation defined above makes this set into a group, known as the quotient group, which in this case is isomorphic to the cyclic group of order 3.
Motivation for the name "quotient".
The reason "G"/"N" is called a quotient group comes from division of integers. When dividing 12 by 3 one obtains the answer 4 because one can regroup 12 objects into 4 subcollections of 3 objects. The quotient group is the same idea, however we end up with a group for a final answer instead of a number because groups have more structure than an arbitrary collection of objects.
To elaborate, when looking at "G"/"N" with "N" a normal subgroup of "G", the group structure is used to form a natural "regrouping". These are the cosets of "N" in "G". Because we started with a group and normal subgroup, the final quotient contains more information than just the number of cosets (which is what regular division yields), but instead has a group structure itself.
Examples.
Consider the group of integers Z (under addition) and the subgroup 2Z consisting of all even integers. This is a normal subgroup, because Z is abelian. There are only two cosets: the set of even integers and the set of odd integers; therefore, the quotient group Z/2Z is the cyclic group with two elements. This quotient group is isomorphic with the set { 0, 1 } with addition modulo 2; informally, it is sometimes said that Z/2Z "equals" the set { 0, 1 } with addition modulo 2.
A slight generalization of the last example. Once again consider the group of integers Z under addition. Let "n" be any positive integer. We will consider the subgroup "nZ of Z consisting of all multiples of "n". Once again "nZ is normal in Z because Z is abelian. The cosets are the collection {"nZ, 1+"nZ, ..., ("n"−2)+"nZ, ("n"−1)+"nZ}. An integer "k" belongs to the coset "r"+"nZ, where "r" is the remainder when dividing "k" by "n". The quotient Z/"nZ can be thought of as the group of "remainders" modulo "n". This is a cyclic group of order "n".
The twelfth roots of unity, which are points on the unit circle, form a multiplicative abelian group "G", shown on the picture on the right as colored balls with the number at each point giving its complex argument. Consider its subgroup "N" made of the fourth roots of unity, shown as red balls. This normal subgroup splits the group into three cosets, shown in red, green and blue. One can check that the cosets form a group of three elements (the product of a red element with a blue element is blue, the inverse of a blue element is green, etc.). Thus, the quotient group "G"/"N" is the group of three colors, which turns out to be the cyclic group with three elements.
Consider the group of real numbers R under addition, and the subgroup Z of integers. The cosets of Z in R are all sets of the form "a"+Z, with 0 ≤ "a" < 1 a real number. Adding such cosets is done by adding the corresponding real numbers, and subtracting 1 if the result is greater than or equal to 1. The quotient group R/Z is isomorphic to the circle group S1, the group of complex numbers of absolute value 1 under multiplication, or correspondingly, the group of rotations in 2D about the origin, i.e., the special orthogonal group SO(2). An isomorphism is given by "f"("a"+Z) = exp(2"πia") (see Euler's identity).
If "G" is the group of invertible 3 × 3 real matrices, and "N" is the subgroup of 3 × 3 real matrices with determinant 1, then "N" is normal in "G" (since it is the kernel of the determinant homomorphism). The cosets of "N" are the sets of matrices with a given determinant, and hence "G"/"N" is isomorphic to the multiplicative group of non-zero real numbers.
Consider the abelian group Z4 = Z/4Z (that is, the set { 0, 1, 2, 3 } with addition modulo 4), and its subgroup { 0, 2 }. The quotient group Z4/{ 0, 2 } is { { 0, 2 }, { 1, 3 } }. This is a group with identity element { 0, 2 }, and group operations such as { 0, 2 } + { 1, 3 } = { 1, 3}. Both the subgroup { 0, 2 } and the quotient group { { 0, 2 }, { 1, 3 } } are isomorphic with Z2.
Consider the multiplicative group formula_1. The set "N" of "n"th residues is a multiplicative subgroup isomorphic to formula_2. Then "N" is normal in "G" and the factor group "G"/"N" has the cosets "N", (1+"n")"N", (1+"n")2N, ..., (1+"n")"n"−1N. The Pallier cryptosystem is based on the conjecture that it is difficult to determine the coset of a random element of "G" without knowing the factorization of "n".
Properties.
The quotient group "G"/"G" is isomorphic to the trivial group (the group with one element), and "G"/{"e"} is isomorphic to "G".
The order of "G"/"N", by definition the number of elements, is equal to |"G" : "N"|, the index of "N" in "G". If "G" is finite, the index is also equal to the order of "G" divided by the order of "N". Note that "G"/"N" may be finite, although both "G" and "N" are infinite (e.g. Z/2Z).
There is a "natural" surjective group homomorphism "π" : "G" → "G"/"N", sending each element "g" of "G" to the coset of "N" to which "g" belongs, that is: "π"("g") = "gN". The mapping "π" is sometimes called the "canonical projection of G onto G/N". Its kernel is "N".
There is a bijective correspondence between the subgroups of "G" that contain "N" and the subgroups of "G"/"N"; if "H" is a subgroup of "G" containing "N", then the corresponding subgroup of "G"/"N" is "π"("H"). This correspondence holds for normal subgroups of "G" and "G"/"N" as well, and is formalized in the lattice theorem.
Several important properties of quotient groups are recorded in the fundamental theorem on homomorphisms and the isomorphism theorems.
If "G" is abelian, nilpotent, solvable, cyclic or finitely generated, then so is "G"/"N".
If "H" is a subgroup in a finite group "G", and the order of "H" is one half of the order of "G", then "H" is guaranteed to be a normal subgroup, so "G"/"H" exists and is isomorphic to "C"2. This result can also be stated as "any subgroup of index 2 is normal", and in this form it applies also to infinite groups. Furthermore, if "p" is the smallest prime number dividing the order of a finite group, "G", then if "G"/"H" has order "p", "H" must be a normal subgroup of "G". 
Given "G" and a normal subgroup "N", then "G" is a group extension of "G"/"N" by "N". One could ask whether this extension is trivial or split; in other words, one could ask whether "G" is a direct product or semidirect product of "N" and "G"/"N". This is a special case of the extension problem. An example where the extension is not split is as follows: Let "G" = Z4 = {0,1,2,3}, and "N" = { 0, 2 }, which is isomorphic to Z2. Then "G"/"N" is also isomorphic to Z2. But Z2 has only the trivial automorphism, so the only semi-direct product of "N" and "G"/"N" is the direct product. Since Z4 is different from Z2 × Z2, we conclude that "G" is not a semi-direct product of "N" and "G"/"N".
Quotients of Lie groups.
If "G" is a Lie group and "N" is a normal Lie subgroup of "G", the quotient "G" / "N" is also a Lie group. In this case, the original group "G" has the structure of a fiber bundle (specifically, a principal "N"-bundle), with base space "G" / "N" and fiber "N".
For a non-normal Lie subgroup "N", the space "G" / "N" of left cosets is not a group, but simply a differentiable manifold on which "G" acts. The result is known as a homogeneous space.

</doc>
<doc id="11527" url="http://en.wikipedia.org/wiki?curid=11527" title="Fundamental theorem on homomorphisms">
Fundamental theorem on homomorphisms

In abstract algebra, the fundamental theorem on homomorphisms, also known as the fundamental homomorphism theorem, relates the structure of two objects between which a homomorphism is given, and of the kernel and image of the homomorphism.
The homomorphism theorem is used to prove the isomorphism theorems.
Group theoretic version.
Given two groups "G" and "H" and a group homomorphism "f" : "G"→"H", let "K" be a normal subgroup in "G" and φ the natural surjective homomorphism "G"→"G"/"K" (where "G"/"K" is a quotient group). If "K" is a subset of ker("f") then there exists a unique homomorphism "h":"G"/"K"→"H" such that "f" = "h" φ.
In other words, the natural projection φ is universal among homomorphisms on "G" that map "K" to the identity element.
The situation is described by the following commutative diagram:
By setting "K" = ker("f") we immediately get the first isomorphism theorem.
Other versions.
Similar theorems are valid for monoids, vector spaces, modules, and rings.

</doc>
<doc id="11528" url="http://en.wikipedia.org/wiki?curid=11528" title="FCO">
FCO

FCO may mean:

</doc>
<doc id="11529" url="http://en.wikipedia.org/wiki?curid=11529" title="Fermion">
Fermion

In particle physics, a fermion (a name coined by Paul Dirac from the surname of Enrico Fermi) is any particle characterized by Fermi–Dirac statistics. These particles obey the Pauli exclusion principle. Fermions include all quarks and leptons, as well as any composite particle made of an odd number of these, such as all baryons and many atoms and nuclei. Fermions differ from bosons, which obey Bose–Einstein statistics.
A fermion can be an elementary particle, such as the electron, or it can be a composite particle, such as the proton. According to the spin-statistics theorem in any reasonable relativistic quantum field theory, particles with integer spin are bosons, while particles with half-integer spin are fermions.
Besides this spin characteristic, fermions have another specific property: they possess conserved baryon or lepton quantum numbers. Therefore what is usually referred as the spin statistics relation is in fact a spin statistics-quantum number relation.
As a consequence of the Pauli exclusion principle, only one fermion can occupy a particular quantum state at any given time. If multiple fermions have the same spatial probability distribution, then at least one property of each fermion, such as its spin, must be different. Fermions are usually associated with matter, whereas bosons are generally force carrier particles, although in the current state of particle physics the distinction between the two concepts is unclear.
Composite fermions, such as protons and neutrons, are the key building blocks of everyday matter. Weakly interacting fermions can also display bosonic behavior under extreme conditions, such as superconductivity.
Elementary fermions.
The Standard Model recognizes two types of elementary fermions, quarks and leptons. In all, the model distinguishes 24 different fermions. There are six quarks (up quark, down quark, strange quark, charm quark, bottom quark, and top quark) and six leptons (electron, electron neutrino, muon, muon neutrino, tau particle, tau neutrino), each with a corresponding antiparticle.
Mathematically, fermions come in three types - Weyl fermions (massless), Dirac fermions (massive), and Majorana fermions (each its own antiparticle).
Most Standard Model fermions are believed to be Dirac fermions, although it is unknown at this time whether the neutrino is a Dirac or a Majorana fermion. Dirac fermions can be treated as a combination of two Weyl fermions.:106
Composite fermions.
Composite particles (such as hadrons, nuclei, and atoms) can be bosons or fermions depending on their constituents. More precisely, because of the relation between spin and statistics, a particle containing an odd number of fermions is itself a fermion. It will have half-integer spin.
Examples include the following:
The number of bosons within a composite particle made up of simple particles bound with a potential has no effect on whether it is a boson or a fermion.
Fermionic or bosonic behavior of a composite particle (or system) is only seen at large (compared to size of the system) distances. At proximity, where spatial structure begins to be important, a composite particle (or system) behaves according to its constituent makeup.
Fermions can exhibit bosonic behavior when they become loosely bound in pairs. This is the origin of superconductivity and the superfluidity of helium-3: in superconducting materials, electrons interact through the exchange of phonons, forming Cooper pairs, while in helium-3, Cooper pairs are formed via spin fluctuations.
The quasiparticles of the fractional quantum Hall effect are also known as composite fermions, which are electrons with an even number of quantized vortices attached to them.
Skyrmions.
In a quantum field theory, there can be field configurations of bosons which are topologically twisted. These are coherent states (or solitons) which behave like a particle, and they can be fermionic even if all the constituent particles are bosons. This was discovered by Tony Skyrme in the early 1960s, so fermions made of bosons are named skyrmions after him.
Skyrme's original example involved fields which take values on a three-dimensional sphere, the original nonlinear sigma model which describes the large distance behavior of pions. In Skyrme's model, reproduced in the large N or string approximation to quantum chromodynamics (QCD), the proton and neutron are fermionic topological solitons of the pion field.
Whereas Skyrme's example involved pion physics, there is a much more familiar example in quantum electrodynamics with a magnetic monopole. A bosonic monopole with the smallest possible magnetic charge and a bosonic version of the electron will form a fermionic dyon.
The analogy between the Skyrme field and the Higgs field of the electroweak sector has been used to postulate that all fermions are skyrmions. This could explain why all known fermions have baryon or lepton quantum numbers and provide a physical mechanism for the Pauli exclusion principle.

</doc>
<doc id="11530" url="http://en.wikipedia.org/wiki?curid=11530" title="Fred Savage">
Fred Savage

Fredrick Aaron "Fred" Savage (born July 9, 1976) is an American actor, director, and producer. He is best known for his role as Kevin Arnold in the American television series "The Wonder Years". He has earned several awards and nominations, such as People's Choice Awards and Young Artist Awards.
Early life.
Savage was born in Highland Park, Illinois, the son of Joanne and Lewis Savage, who was an industrial real estate broker and consultant. His brother is actor Ben Savage, and his sister is actress/musician Kala Savage. His grandparents were Jewish immigrants from Poland, Ukraine, Germany, and Latvia.
Education.
Savage was educated at Brentwood School, a private co-educational day school in Brentwood, in the Westside area of Los Angeles County in California. He graduated from Stanford University in 1999, with a bachelor's degree in English and as a member of Sigma Alpha Epsilon.
Life and career.
Savage's first screen performance was in the television show "Morningstar/Eveningstar", at age 9. He then appeared onscreen in "The Boy Who Could Fly", "Dinosaurs!", and several television shows, including "The Twilight Zone" and "Crime Story" before gaining national attention as the grandson in the 1987 film "The Princess Bride" opposite Peter Falk.
In 1988, Savage appeared as Kevin Arnold on "The Wonder Years", the role for which he is best known, and for which he received two Golden Globe nominations and two Emmy nominations for Outstanding Lead Actor in a Comedy Series. At the age of thirteen he was the youngest actor ever to receive these honors. He remained on the show until it ended in 1993. During this period, he appeared in several films, most notably "Vice Versa" (1988), and also starred in "Little Monsters". After "The Wonder Years", Savage primarily did guest and supporting roles, such as the show "Boy Meets World" (which starred his brother Ben) and in the film "Austin Powers in Goldmember" as The Mole.
Savage has lent his voice to several animated projects, including "Family Guy", "Kim Possible", "Justice League Unlimited", "Oswald", and "". His two lead roles since "The Wonder Years" were on the short-lived sitcoms "Working" and "Crumbs".
Savage appeared as a serial rapist on a 2003 episode of "" and as a womanizing professor on "Boy Meets World". He ranked at #27 on VH1's "100 Greatest Kid Stars".
In July 2008, Savage guest-starred in the web series "The Rascal" on Crackle.
Behind-the-scenes career.
In 1999, Savage began his directing career in which he helmed episodes of over a dozen television series. His credits include "Boy Meets World", "Drake & Josh" and "Ned's Declassified" for Nickelodeon, as well as "That's So Raven", "Hannah Montana" and "Wizards of Waverly Place" for Disney Channel.
Besides directing several episodes, Savage co-produced the Disney Channel Original Series "Phil of the Future". In 2007, he was nominated for a Directors Guild award for the "Phil" episode "Not-So-Great-Great Grandpa".
Savage has served as a producer for several episodes of "It's Always Sunny in Philadelphia", "Friends with Benefits", "Party Down", "Phil of the Future", and "Happy Endings".
In 2007, he made his feature film directing debut with the film "Daddy Day Camp".
Personal life.
Savage is married to his childhood friend, Jennifer Lynn Stone. They have two sons and a daughter.

</doc>
<doc id="11531" url="http://en.wikipedia.org/wiki?curid=11531" title="Futurians">
Futurians

The Futurians were a group of science fiction fans, many of whom became editors and writers as well. The Futurians were based in New York City and were a major force in the development of science fiction writing and science fiction fandom in the years 1937-1945.
Origins of the group.
As described in Isaac Asimov's autobiography "In Memory Yet Green", the Futurians spun off from the Greater New York Science Fiction Club (headed by Sam Moskowitz, later an influential SF editor and historian) over ideological differences, with the Futurians wishing to take a more overt political stance. Other sources indicate that Donald A. Wollheim was pushing for a more left-wing direction with a goal of leading fandom toward a political ideal, all of which Moskowitz resisted. As a result, Wollheim broke off from the Greater New York group and founded the Futurians in September, 1938. The fans following Moskowitz reorganized into the Queens Science Fiction Club.
Frederik Pohl, in his autobiography "The Way the Future Was", said that the origin of the Futurians lay with the Science Fiction League founded by Hugo Gernsback in 1934, the local New York City chapter of which was called the "Brooklyn Science Fiction League" or BSFL, headed by G. G. Clark.
Wollheim, John Michel, and Robert A. W. Lowndes were also members of the BSFL. Along with Pohl, the four started calling themselves the "Quadrumvirate". Pohl, commenting about that time, said "we four marched from Brooklyn to the sea, leaving a wide scar of burned out clubs behind us. We changed clubs the way Detroit changes tailfins, every year had a new one, and last year's was junk".
There were several club names during that period, before finally settling on the Futurians. In 1935 there was the "East New York Science Fiction League" (ENYSFL), later the "Independent League for Science Fiction" (ILSF). In 1936 came the International Cosmos Science Club (ICSC), which also involved Will Sykora. Pohl then says that "on reflection 'Cosmos' seemed to take in a bit more territory than was justified, so we changed it to the International Scientific Association (it wasn't International either, but then it also wasn't scientific)". The ISA then was renamed New York Branch-International Scientific Association (NYB-ISA).
In 1937, after the falling-out with Will Sykora and others, the "Quadrumvirate" went on to found the Futurians. Will Sykora then founded the Queens Science Fiction League with Sam Moskowitz and James V. Taurasi. Later, the QSFL changed into New Fandom. Pohl said as the conflicts between New Fandom and the Futurians were "Addicted to Feuds", that "No CIA nor KGB ever wrestled so valiantly for the soul of an emerging nation as New Fandom and the Futurians did for science fiction".
Most of the group's members also had professional ambitions within science fiction and related fields, and collectively were very effective at achieving this goal, as the roster of members suggests. At one point in the earliest 1940s, approximately half of all the pulp sf and fantasy magazines in the U.S. were being edited by Futurians: Frederik Pohl at the Popular Publications offshoot Fictioneers, Inc. ("Astonishing Stories" and "Super-Science Stories"); Robert Lowndes at Columbia Publications, most notably with "Science Fiction" and "Future Fiction" (though through the decade to come, Lowndes's responsibilities would expand to other types of fiction magazine in the chain), and Donald Wollheim at the very marginal Albing Publications with the short-lived, micro-budgeted "Cosmic Stories" and "Stirring Science Stories" (Wollheim soon moved on to Avon Books; Doë "Leslie Perri" Baumgardt also worked on a romance fiction title for Albing). Most of these projects had small editorial budgets, and relied in part, or occasionally entirely, on contributions from fellow Futurians for their contents.
Political tendencies.
At the time the Futurians were formed, Donald Wollheim was strongly attracted by communism and believed that followers of science fiction "should actively work for the realization of the scientific world-state as the only genuine justification for their activities and existence". It was to this end that Wollheim formed the Futurians, and many of its members were in some degree interested in the political applications of science fiction. Members of the Futurians, including Wollheim, Michel, Lowndes, and Cohen briefly became interested in Technocracy, a utopian movement led by Howard Scott, and attended a study course, although they later dismissed Scott as a "crackpot".
Hence the group included supporters of Trotskyism, like Judith Merril and others who would have been deemed far left for the era (Frederik Pohl became a member of the Communist Party in 1936, but later quit in 1939). On the other hand several members were political moderates or apolitical, and in the case of James Blish arguably right-wing. Damon Knight in "The Futurians" indicates that Blish at that time felt Fascism was interesting in theory, if repellent as it was then being practised. More solid evidence is that Blish admired the work of Oswald Spengler.
Pohl, in his autobiography, "The Way the Future Was", said Wollheim voted for Republican Presidential Candidate Alfred Landon in 1936.

</doc>
<doc id="11532" url="http://en.wikipedia.org/wiki?curid=11532" title="First Fandom">
First Fandom

First Fandom is an association of experienced science fiction fans.
In 1958 a number of fans at Midwestcon realized amid table-talk that they all had been active in fandom for more than 20 years. This inspired the creation of an organization for longstanding fans under the initial chairmanship of Robert A. Madle. Originally only those fans who were known to have been active in fandom before the cutoff date, January 1, 1938, were eligible. Such fannish activity (or "fanac") including writing to letter columns in science fiction magazines, having been published in fanzines, or having participated in science fiction oriented clubs, or just generally doing fannish things.
The term itself is an oblique reference to Olaf Stapledon's classic science fiction epic "Last and First Men". In this book the stages of mankind are enumerated. Thus early 1950s historian of fandom Jack Speer began to label successive generations of fans as First Fandom, Second Fandom, Third Fandom, and so forth... all the way to Seventh Fandom and beyond.
Currently the organization allows several classes of membership. For example, a "Dinosaur" is a member who was active before the first Worldcon (World Science Fiction Convention) held on July 4, 1939, while "Associate Membership" requires provable activity in fandom for more than three decades.
First Fandom annually presents its Hall of Fame Award and Sam Moskowitz Archive Award for excellence in science fiction collecting. at the beginning of the Hugo Awards Ceremony at the World Science Fiction Convention.
There is an analogous informal society in Finnish fandom called the "Dinosaur Club"; the cutoff being the first major Finnish con Kingcon.
References.
1. Nebula Science Fiction 1959.

</doc>
<doc id="11536" url="http://en.wikipedia.org/wiki?curid=11536" title="Fianna Fáil">
Fianna Fáil

 
Fianna Fáil , also known as Fianna Fáil, The Republican Party, is a centrist to centre-right and conservative political party in the Republic of Ireland. Originally an Irish republican party, it was founded on 23 March 1926 after a split in Sinn Féin on the issue of abstentionism. Fianna Fáil's name is traditionally translated into English as "Soldiers of Destiny", although a more accurate rendition would be "Warriors of Fál" ("Fál" being a legendary name for Ireland). Historically, Fianna Fáil has been seen as to the left of Fine Gael and to the right of Sinn Féin and the Labour Party and is generally seen as a classic "catch all" populist party - representing a broad range of people from all social classes. Fianna Fáil has led governments including parties of the centre-left (Labour and the Green Party) and of the centre-right (the now-defunct Progressive Democrats). It has been led by Micheál Martin since January 2011.
From the formation of the first Fianna Fáil government on 9 March 1932 until the election of 2011, the party was in power for 61 of 79 years. Its longest continuous period in office was 15 years and 11 months (March 1932–February 1948). Its single longest period out of office, in that time, has been 4 years and 4 months (March 1973–July 1977). Seven of the party's eight leaders have served as Taoiseach. It was the largest party in Dáil Éireann at every general election from the 1932 general election until the 2011 general election, when it suffered the worst defeat of a sitting government in the history of the Irish state. This loss was described as "historic" in its proportions, and saw its electoral support base diminished by 75%, as a reaction to the intervention, and in the running of the Irish economy, by the International Monetary Fund and the European Central Bank in November 2010. After the February 2011 election, it moved from being the largest party to the third-largest party in the 31st Dáil.
Fianna Fáil joined the Alliance of Liberals and Democrats for Europe (ALDE) party on 16 April 2009, and the party's MEPs sat in the ALDE Group during the 7th European Parliament term from June 2009 to 1 July 2014. The party is an observer affiliate of the Liberal International.
The party is also organised in Northern Ireland but has yet to contest an election there.
History.
Fianna Fáil was founded by Éamon de Valera when he and a number of other members split from Sinn Féin when his motion — which called for elected members be allowed to take their seats in the Dáil if and when the controversial oath of allegiance was removed — failed to pass at the Sinn Féin Ard Fheis in 1926.
De Valera led anti-Treaty Sinn Féin during the Irish Civil War (1922–23) before resigning from the party in protest at the party's hard-line policy of abstentionism, the refusal to accept the legitimacy of the Free State or Dáil Éireann. Though his new party, Fianna Fáil, was also opposed to the Treaty settlement, it adopted a different approach of aiming to republicanise the Irish Free State. As far as the party's economic policies are concerned, the Fianna Fáil's platform of economic autarky had appeal among the farmers, working-class people and the poor, whilst initially alienating more affluent classes.
Organisation and structure.
Fianna Fáil's success was credited by "The Irish Times" to its local structure. The basic unit was the "cumann" (branch) which were then grouped into "comhairle ceantair" (district branch) and a "comhairle dáil ceantair" (constituency branch) in every constituency. At the party's height, it boasted 3,000 cumainn, an average of 75 per constituency. The party claimed 55,000 members in 2004, a figure which Eoin O'Malley, a political scientist, considers exaggerated compared to membership figures for other parties.
However since the early 1990s the cumann structure was weakened. As every cumann was entitled to three votes to selection conventions irrespective of size, a large number of cumainn became in effect "paper cumainn" only used to ensure an aspiring or sitting candidate got enough votes. Another problem arose with the emergence of parallel organisations grouped around candidates or elected officials. Supporters and election workers for a particular candidate were loyal to a candidate and not to the party. If the candidate was to leave the party, through either resignation, retirement or defeat at election, the candidate's supporters would often depart. Although this phenomenon was nothing new, (the most famous example being Neil Blaney's "Donegal Mafia") it increased significantly from the early 1990s particularly in the Dublin Region with former Taoiseach Bertie Ahern's "Drumcondra mafia" and the separate groups supporting Tom Kitt and Séamus Brennan in Dublin South largely separate from the official party structure.
Since the 2007 election, the party's structure has significantly weakened. This was in part exacerbated by significant infighting between candidates in the run up to the 2011 general election. The Irish Times estimated that half of its 3,000 cumainn are effectively moribund. This fraction rises in Dublin with the exception of Dublin West, the former seat of both Brian Lenihan, Snr and Brian Lenihan, Jnr.
Ideology.
Fianna Fáil is seen as a typical catch-all party. R. Ken Carty wrote of Fianna Fáil and Fine Gael that they were 'heterogeneous in their bases of support, relatively undifferentiated in terms of policy or programme, and remarkably stable in their support levels'. Evidence from expert surveys, opinion polls and candidate surveys all fail to identify strong distinctions between the two largest parties, Fianna Fáil and Fine Gael. Many point to Ireland's civil war politics and feel that the basis for the division is the disagreement about the strategy to achieve a united Ireland. Kevin Byrne and political scientist Eoin O'Malley rejected this and have argued that the differences between the two parties goes much further back in Irish history. They linked the parties to different nationalist traditions (Irish Enlightenment and Gaelic Nationalist) which in turn could be linked to migrations of Anglo-Norman and new English into Ireland and the 'native' Gaelic population.
The party's name and logo incorporates the words 'The Republican Party'. According to Fianna Fáil, "Republican here stands both for the unity of the island and a commitment to the historic principles of European republican philosophy, namely liberty, equality and fraternity."
Leadership and president.
Although the posts of leader and party president of Fianna Fáil are separate, with the former elected by the Parliamentary Party and the latter elected by the Ardfheis (thus allowing for the posts to be held by different people, in theory), in practice they have always been held by the one person. However, as the Ardfheis may have already been held in any given year by the time a new leader is elected, the selection of the new party president might not take place until the next year.
The following are the terms of office as party leader and as Taoiseach:
Ógra Fianna Fáil.
Fianna Fáil's youth wing is called Ógra Fianna Fáil. Formed in 1975, it plays an active role in recruiting new members and supporting election campaigns. Ógra also plays an important role in the party organisation where it currently has five representatives on the Ard Chomhairle (National Executive).
Senator Thomas Byrne was the last nominated head or Cathaoirleach (Chairperson) of Ógra Fianna Fáil, before the youth wing introduced widespread oganisational reform following the heavy electoral defeat suffered by the whole party in 2011.
Fianna Fáil and Northern Politics.
On 17 September 2007 Fianna Fáil announced that the party would, for the first time, organise in Northern Ireland.
The then Foreign Minister Dermot Ahern was asked to chair a committee on the matter: "In the period ahead Dermot Ahern will lead efforts to develop that strategy for carrying through this policy, examining timescales and structures. We will act gradually and strategically. We are under no illusions. It will not be easy. It will challenge us all. But I am confident we will succeed."
The party embarked on its first ever recruitment drive north of the border in September 2007 in northern universities, and established two 'Political Societies', the William Drennan Cumann in Queens University, Belfast, and the Watty Graham Cumann in UU Magee, Derry, which subsequently became official units of Fianna Fáil's youth wing, attaining full membership and voting rights, and attained official voting delegates at the 2012 Árd Fheis.
Bertie Ahern announced on 7 December 2007 that Fianna Fáil had been registered in Northern Ireland by the UK Electoral Commission.
The Party's Ard Fheis in 2009 unanimously passed a motion to organise in Northern Ireland by establishing forums, rather than cumainn, in each of the North's six counties. In December 2009, Fianna Fáil secured its first Northern Assembly MLA when Gerry McHugh, an independent MLA, announced he had joined the party. Mr. McHugh confirmed that although he had joined the party, he would continue to sit as an independent MLA. In June 2010, Fianna Fáil opened its first official office in the North in Crossmaglen, Co. Armagh. The then Taoiseach Brian Cowen officially oepened the office, accompanied by Ministers Éamon Ó Cuív and Dermot Ahern and Deputies Rory O’Hanlon and Margaret Conlon. Discussing the party's slow development towards all-Ireland politics, Mr. Cowen observed: "We have a very open and pragmatic approach. We are a constitutional republican party and we make no secret of the aspirations on which this party was founded. It has always been very clear in our mind what it is we are seeking to achieve, that is to reconcile this country and not being prisoners of our past history. To be part of a generation that will build a new Ireland, an Ireland of which we can all be proud.".
There has been speculation about an eventual merger with the Social Democratic and Labour Party (SDLP), formerly the main Irish nationalist party in the Northern Ireland, but now smaller than Sinn Féin. This has been met with a negative reaction with former Deputy Leader of the SDLP, Seamus Mallon, stating he would be opposed to any such merger. The former leader of the SDLP, Margaret Ritchie, has also stated publicly that she opposes any merger famously announcing to the Labour Party Conference that such a merger would not happen on her "watch". At the 2010 Irish Labour Party conference she further criticised Fianna Fáil's record in government and also the National Asset Management Agency On 23 February 2008, it was announced that a former UUP councillor, Colonel Harvey Bicker, had joined Fianna Fáil.
Fianna Fáil has registered with the UK Electoral Commission and is technically a recognised party in Northern Ireland. However, it has not officially contested any elections in Northern Ireland. At the party's 2014 Ard Fheis, a motion was passed without debate to stand candidates for election north of the border for the first time in 2019.
Fianna Fail did have a member elected to the old Northern Ireland House of Commons in 1933 when Eamon DeValera was elected in South Down.
In European institutions.
In the European Parliament from 1999 to 2009, Fianna Fáil was a leading member of Union for Europe of the Nations (UEN), a small national-conservative and Eurosceptic parliamentary group. European political commentators had often noted substantive ideological differences between the party and its colleagues, whose strongly conservative stances had at times prompted domestic criticism of Fianna Fáil. Fianna Fáil MEPs had previously been an attached to the European Progressive Democrats (1973–1984), European Democratic Alliance (1984–1995), and Union for Europe (1995–1999) groups before the creation of UEN.
Party headquarters, over the objections of some MEPs, had made several attempts to sever the party's links to the European right, including an aborted 2004 agreement to join the European Liberal Democrat and Reform (ELDR) Party, with whom it already sat in the Council of Europe under the Alliance of Liberals and Democrats for Europe (ALDE) banner. On 27 February 2009, Taoiseach Brian Cowen announced that Fianna Fáil proposed to join the ELDR Party and intended to sit with them in the Alliance of Liberals and Democrats for Europe (ALDE) Group in the European Parliament after the 2009 European elections. The change was made official on 17 April 2009, when FF joined the ELDR Party.
In October 2009, it was reported that Fianna Fáil had irritated its new Liberal colleagues by failing to vote for the motion on press freedom in Italy (resulting in its defeat by a majority of one in the Parliament) and by trying to scupper their party colleagues' initiative for gay rights. In January 2010, a report by academic experts writing for the votewatch.eu site found that FF "do not seem to toe the political line" of the ALDE Group "when it comes to budget and civil liberties" issues.
In the 2014 European elections, Fianna Fáil received 22.3% of first-preference votes but only returned a single MEP, a reduction in representation of two MEPs from the previous term. This was due to a combination of the party's vote further dropping in Dublin and a two candidate strategy in the Midlands North West constituency, which backfired, resulting in sitting MEP Pat the Cope Gallagher losing his seat. On 23 June 2014, returning MEP Brian Crowley announced that he intended to sit with the European Conservatives and Reformists (ECR) rather than the ALDE group during the upcoming 8th term of the European parliament. The following day on 24 June 2014 Crowley had the Fianna Fáil party whip withdrawn.

</doc>
<doc id="11539" url="http://en.wikipedia.org/wiki?curid=11539" title="Fujiwara clan">
Fujiwara clan

 
Fujiwara clan (藤原氏, Fujiwara-uji or Fujiwara-shi), descending from the Nakatomi clan and through him Ame-no-Koyane-no-Mikoto, was a powerful family of regents in Japan. 
The clan originated when the founder, Nakatomi no Kamatari (614–669), was rewarded by Emperor Tenji with the honorific "Fujiwara", which evolved as a surname for Kamatari and his descendants. In time, Fujiwara became known as a clan name. 
The Fujiwara dominated the Japanese politics of Heian period (794–1185) through the monopoly of regent positions, "sesshō" and "kampaku". The family's primary strategy for central influence was through the marrying of Fujiwara daughters to emperors. Through this, the Fujiwara would gain influence over the next emperor who would, according to Japanese family tradition, owe loyalty to his grandfather.
As abdicated Emperors took over power by exercising "insei" (院政, cloistered rule) at the end of 11th century, then followed by the rise of warrior class, the Fujiwara gradually lost its control over mainstream politics.
Beyond the 12th century, they continued to monopolize the titles of sesshō and kampaku for much of the time until the system was abolished in the Meiji era. Though their influence declined, the clan remained close advisors to the succeeding Emperors.
Asuka/Nara period.
The Fujiwara clan's political influence was initiated during the Asuka period. Nakatomi no Kamatari, a member of the lower-nobility Nakatomi family led a coup against the Soga in 645 and initiated a series of sweeping government reforms that would be known as the Taika Reform. In 668 Emperor Tenji (reigned 668–671), bestowed the "kabane" Fujiwara no Ason (藤原朝臣) on Kamatari. The surname passed to the descendants of Fujiwara no Fuhito (659–720), the second son and heir of Kamatari, who was prominent at the court of several emperors and empresses during the early Nara period. He made his daughter Miyako a concubine of Emperor Mommu. Her son, Prince Obito became Emperor Shōmu. Fuhito succeeded in making another of his daughters, Kōmyōshi, the empress consort of Emperor Shōmu. She was the first empress (like Empress Wu in China) consort of Japan who was not a daughter of the imperial family itself. Fuhito had four sons; and each of them became the progenitor of a cadet branch of the clan: 
Among them, the Hokke came to be considered as the leaders of the entire clan.
Heian period.
During the Heian period of Japanese history, the Hokke managed to establish a hereditary claim to the position of regent, either for an underage emperor ("sesshō") or for an adult one ("kampaku"). Some prominent Fujiwaras occupied these positions more than once, and for more than one emperor. Lesser members of the Fujiwara were court nobles, provincial governors and vice governors, members of the provincial aristocracy, and samurai. The Fujiwara was one of the four great families that dominated Japanese politics during the Heian Period (794–1185), and the most important of them at that time. The others were the Tachibana, the Taira and the Minamoto. The Fujiwara exercised tremendous power, especially during the period of regency governments in 10th and 11th centuries, having many emperors as practically puppet monarchs.
The Fujiwara dominated the government of Japan 794–1160. There is no clear starting point of their dominance. However, their domination of civil administration was lost by the establishment of the first shogunate (i.e., Kamakura shogunate) under Minamoto no Yoritomo in 1192. 
Fujiwara princes initially served as highest ministers of the imperial Court ("kampaku") and regents ("sesshō") for underage monarchs. The Fujiwara were the proverbial "power behind the throne" for centuries. Apparently they never aspired to supplant the imperial dynasty. Instead, the clan's influence stemmed from its matrimonial alliances with the imperial family. Because consorts of crown princes, younger sons, and emperors were generally Fujiwara women, the male heads of the Fujiwara house were often the father-in-law, brother-in-law, uncle, or maternal grandfather of the emperor. The family reached the peak of its power under Fujiwara no Michinaga (966–1027), a longtime "kampaku" who was the grandfather of three emperors, the father of six empresses or imperial consorts, and the grandfather of seven additional imperial consorts; it is no exaggeration to say that it was Michinaga who ruled Japan during this period, not the titular Emperors.
Fujiwara regime in the Heian period.
The Fujiwara Regency was the main feature of government of the entire Heian era. Kyoto (Heian-kyō) was geopolitically a better seat of government; with good river access to the sea, it could be reached by land routes from the eastern provinces.
Just before the move to the Heian-kyō, the Emperor had abolished universal conscription in 8 and soon local, private militaries came into being. The Fujiwara, Taira, and Minamoto were among the most prominent families supported by the new military class.
In the ninth and tenth centuries, much authority was lost to the great families, who disregarded the Chinese-style land and tax systems imposed by the government in Kyoto. Stability came to Heian Japan, but, even though succession was ensured for the Imperial family through heredity, power again concentrated in the hands of one noble family, the Fujiwara.
Family administrations now became public institutions. As the most powerful family, the Fujiwara governed Japan and determined the general affairs of state, such as succession to the throne. Family and state affairs were thoroughly intermixed, a pattern followed among other families, monasteries, and even the imperial family.
As the Soga had taken control of the throne in the sixth century, the Fujiwara by the ninth century had intermarried with the imperial family, and one of their members was the first head of the Emperor's Private Office. Another Fujiwara became regent for his grandson, then a minor emperor, and yet another was appointed "kampaku" (regent for an adult emperor). Toward the end of the ninth century, several emperors tried, but failed, to check the Fujiwara. For a time, however, during the reign of Emperor Daigo (897–930), the Fujiwara regency was suspended as he ruled directly.
Nevertheless, the Fujiwara were not demoted by Emperor Daigo but actually became stronger during his reign. Central control of Japan had continued to decline, and the Fujiwara, along with other great families and religious foundations, acquired ever larger "shōen" and greater wealth during the early tenth century. By the early Heian period, the "shōen" had obtained legal status, and the large religious establishments sought clear titles in perpetuity, waiver of taxes, and immunity from government inspection of the "shōen" they held. Those people who worked the land found it advantageous to transfer title to shōen holders in return for a share of the harvest. People and lands were increasingly beyond central control and taxation, a de facto return to conditions before the Taika Reform.
Within decades of Emperor Daigo's death, the Fujiwara had absolute control over the court. By the year 1000, Fujiwara no Michinaga was able to enthrone and dethrone emperors at will. Little authority was left for traditional officialdom, and government affairs were handled through the Fujiwara family's private administration. The Fujiwara had become what historian George B. Sansom has called "hereditary dictators."
The Fujiwara presided over a period of cultural and artistic flowering at the imperial court and among the aristocracy. There was great interest in graceful poetry and vernacular literature. Japanese writing had long depended on Chinese ideograms ("kanji"), but these were now supplemented by "kana", two types of phonetic Japanese script: "katakana", a mnemonic device using parts of Chinese ideograms; and "hiragana", a cursive form of "kanji" writing and an art form in itself. "Hiragana" gave written expression to the spoken word and, with it, to the rise in Japan's famous vernacular literature, much of it written by court women who had not been trained in Chinese as had their male counterparts. Three late tenth century and early eleventh century women presented their views of life and romance at the Heian court in "Kagerō Nikki" ("The Gossamer Years") by "the mother of Michitsuna", "Makura no Sōshi" ("The Pillow Book") by Sei Shōnagon, and "Genji Monogatari" ("Tale of Genji") by Murasaki Shikibu (herself a Fujiwara). Indigenous art also flourished under the Fujiwara after centuries of imitating Chinese forms. Vividly colored "yamato-e" (Japanese style) paintings of court life and stories about temples and shrines became common in the mid and late Heian periods, setting patterns for Japanese art to this day.
Decline in food production, growth of the population, and competition for resources among the great families all led to the gradual decline of Fujiwara power and gave rise to military disturbances in the mid-tenth and eleventh centuries. Members of the Fujiwara, Taira, and Minamoto families—all of whom had descended from the imperial family—attacked one another, claimed control over vast tracts of conquered land, set up rival regimes, and generally broke the peace of Japan.
The Fujiwara controlled the throne until the reign of Emperor Go-Sanjō (1068–73), the first emperor not born of a Fujiwara mother since the ninth century. Emperor Go-Sanjō, determined to restore imperial control through strong personal rule, implemented reforms to curb Fujiwara influence. He also established an office to compile and validate estate records with the aim of reasserting central control. Many "shōen" were not properly certified, and large landholders, like the Fujiwara, felt threatened with the loss of their lands. Emperor Go-Sanjō also established the "In no chō", or Office of the Cloistered Emperor, which was held by a succession of emperors who abdicated to devote themselves to behind-the-scenes governance, or "insei" (Cloistered rule).
The "In no chō" filled the void left by the decline of Fujiwara power. Rather than being banished, the Fujiwara were mostly retained in their old positions of civil dictator and minister of the center while being bypassed in decision making. In time, many of the Fujiwara were replaced, mostly by members of the rising Minamoto family. While the Fujiwara fell into disputes among themselves and formed northern and southern factions, the insei system allowed the paternal line of the imperial family to gain influence over the throne. The period from 1086 to 1156 was the age of supremacy of the "In no chō" and of the rise of the military class throughout the country. Military might rather than civil authority dominated the government.
A struggle for succession in the mid-twelfth century gave the Fujiwara an opportunity to regain their former power. Fujiwara no Yorinaga sided with the retired emperor in a violent battle in 1158 against the heir apparent, who was supported by the Taira and Minamoto. In the end, the Fujiwara were destroyed, the old system of government supplanted, and the "insei" system left powerless as bushi took control of court affairs, marking a turning point in Japanese history. Within a year, the Taira and Minamoto clashed, and a twenty-year period of Taira ascendancy began. The Taira were seduced by court life and ignored problems in the provinces. Finally, Minamoto Yoritomo (1147–1199) rose from his headquarters at Kamakura (in the Kantō region, southwest of modern Tokyo) to defeat the Taira, and with them the child emperor Emperor Antoku they controlled, in the Genpei War (1180–1185).
After this downfall, the younger branches of the Fujiwara clan turned their focus from politics to the arts, producing any number of literary luminaries like Fujiwara no Shunzei or Fujiwara no Teika.
Descent.
Only forty years after Michinaga's death, his Fujiwara heirs were not able to prevent the ascension of Emperor Go-Sanjō (reigned 1068–1073), the first emperor since Emperor Uda whose mother was not a Fujiwara. The system of government by retired emperor ("daijō tennō") (cloistered rule) beginning from 1087 further weakened the Fujiwara's control over the Imperial Court.
The Fujiwara-dominated Heian period approached its end along disturbances of 12th century. The dynastic struggle known as the Hōgen Disturbance ("Hōgen no Ran") led to the Taira emerging as the most powerful clan in 1156. During the Heiji Disturbance ("Heiji no Ran") in 1160 the Taira defeated the coalition of Fujiwara and Minamoto forces. This defeat marked the end of the Fujiwara's dominance.
Fission.
During the 13th century, the Fujiwara northern house ("Hokke") was split into the five regent houses: Konoe, Takatsukasa, Kujō, Nijō and Ichijō. They had a "monopoly" to the offices of "sesshō" and "kampaku", and served in turn. The political power had shifted away from the court nobility in Kyoto to the new warrior class in the countryside. However, Fujiwara princes remained close advisors, regents and ministers to the emperors for centuries, even until the 20th century (Prince Konoe and Morihiro Hosokawa). As such, they had a certain political power and much influence, as often the rival warriors and later bakufu sought their alliance. Oda Nobunaga and his sister Oichi were descended from the Taira and Fujiwara clans; regent Toyotomi Hideyoshi and shogun Tokugawa Ieyasu were related by marriage to the Fujiwara clan. Empress Shōken, wife of Emperor Meiji, was a descendant of the Fujiwara clan and, through Gracia Hosokawa, of the Minamoto clan.
Until the marriage of the Crown Prince Hirohito (Emperor Shōwa) to Princess Nagako of Kuni (posthumously Empress Kōjun) in January 1924, the principal consorts of emperors and crown princes had always been recruited from one of the Sekke Fujiwara. Imperial princesses were often married to Fujiwara lords – throughout a millennium at least. As recently as Emperor Shōwa's third daughter, the late former Princess Takanomiya (Kazoku), and Prince Mikasa's elder daughter, the former Princess Yasuko, married into Takatsukasa and Konoe families, respectively. Likewise a daughter of the last Tokugawa Shogun married a second cousin of Emperor Shōwa.

</doc>
<doc id="11542" url="http://en.wikipedia.org/wiki?curid=11542" title="Federalism">
Federalism

Federalism is a political concept in which a "group" of members are bound together by covenant (Latin: "foedus", covenant) with a governing representative head. The term "federalism" is also used to describe a system of government in which sovereignty is constitutionally divided between a central governing authority and constituent political units (such as states or provinces). Federalism is a system based upon democratic rules and institutions in which the power to govern is shared between national and provincial/state governments, creating what is often called a federation. The term federalist describes several political beliefs around the world. Also, it may refer to the concept of parties; its members or supporters called themselves Federalists.
European vs. American Federalism.
In Europe, "Federalist" is sometimes used to describe those who favor a common federal government, with distributed power at regional, national and supranational levels. Most European federalists want this development to continue within the European Union. European federalism originated in post-war Europe; one of the more important initiatives was Winston Churchill's speech in Zurich in 1946.
In the United States, federalism originally referred to belief in a stronger central government. When the U.S. Constitution was being drafted, the Federalist Party supported a stronger central government, while "Anti-Federalists" wanted a weaker central government. This is very different from the modern usage of "federalism" in Europe and the United States. The distinction stems from the fact that "federalism" is situated in the middle of the political spectrum between a confederacy and a unitary state. The U.S. Constitution was written as a reaction to the Articles of Confederation, under which the United States was a loose confederation with a weak central government. 
In contrast, Europe has a greater history of unitary states than North America, thus European "federalism" argues for a weaker central government, relative to a unitary state. The modern American usage of the word is much closer to the European sense. As the power of the Federal government has increased, some people have perceived a much more unitary state than they believe the Founding Fathers intended. Most people politically advocating "federalism" in the United States argue in favor of limiting the powers of the federal government, especially the judiciary (see Federalist Society, New Federalism).
In Canada, federalism typically implies opposition to sovereigntist movements (most commonly Quebec separatism).
The governments of Argentina, Australia, Brazil, India, and Mexico, among others, are also organized along federalist principles.
Federalism may encompass as few as two or three internal divisions, as is the case in Belgium or Bosnia and Herzegovina. In general, two extremes of federalism can be distinguished: at one extreme, the strong federal state is almost completely unitary, with few powers reserved for local governments; while at the other extreme, the national government may be a federal state in name only, being a confederation in actuality.
In 1999, the Government of Canada established the Forum of Federations as an international network for exchange of best practices among federal and federalizing countries. Headquartered in Ottawa, the Forum of Federations partner governments include Australia, Brazil, Canada, Ethiopia, Germany, India, Mexico, Nigeria, and Switzerland.
Some Christian denominations are organized on federalist principles; in these churches this is known as "ecclesiastic" or "theological federalism".
Examples of federalism.
Australia.
On January 1, 1901 the Australian nation emerged as a federation. The Australian continent was colonized by the United Kingdom in 1788, which subsequently established six self-governing colonies there. In the 1890s the governments of these colonies all held referendums on becoming a unified, self-governing "Commonwealth" within the British Empire. When all the colonies voted in favour of federation, the Federation of Australia commenced, resulting in the establishment of the Commonwealth of Australia in 1901. The model of Australian federalism adheres closely to the original model of the United States of America, though through a Westminster system.
Brazil.
In Brazil, the fall of the monarchy in 1889 by a military "coup d'état" led to the rise of the presidential system, headed by Deodoro da Fonseca. Aided by well-known jurist Ruy Barbosa, Fonseca established federalism in Brazil by decree, but this system of government would be confirmed by every Brazilian constitution since 1891, although some of them would distort some of the federalist principles. The 1937 Constitution, for example, granted the federal government the authority to appoint State Governors (called interventors) at will, thus centralizing power in the hands of President Getúlio Vargas. Brazil also uses the Fonseca system to regulate interstate trade.Brazil is one of the biggest federal government. Patrick ocallaghan is the one who started federalism.
The Brazilian Constitution of 1988 introduced a new component to the ideas of federalism, including municipalities as federal entities. Brazilian municipalities are now invested with some of the traditional powers usually granted to states in federalism, and although they are not allowed to have a Constitution, they are structured by an organic law.
Canada.
In Canada, the system of federalism is described by the division of powers between the federal parliament and the country's provincial governments. Under the Constitution Act (previously known as the British North America Act) of 1867, specific powers of legislation are allotted. Section 91 of the constitution gives rise to federal authority for legislation, whereas section 92 gives rise to provincial powers.
For matters not directly dealt with in the constitution, the federal government retains residual powers; however, conflict between the two levels of government, relating to which level has legislative jurisdiction over various matters, has been a longstanding and evolving issue. Areas of contest include legislation with respect to regulation of the economy, taxation, and natural resources.
Colombia.
In 1858 the unitary government of Colombia, then known as the Republic of New Granada, was dissolved and replaced by the Granadine Confederation, a decentralized federal state. While the Colombian Civil War (1860–1862) resulted in the dismantling of the fledgling confederation, the United States of Colombia that replaced it operated on similarly federal theories, though their actual policies generally differed. Today, however, the Republic of Colombia is a unitary constitutional republic.
India.
The Government of India (referred to as the "Union Government") was established by the Constitution of India, and is the governing authority of a "federal union" of 29 states and 7 union territories.
The government of India is based on a tiered system, in which the Constitution of India delineates the subjects on which each tier of government has executive powers. The Constitution originally provided for a two-tier system of government, the Union Government (also known as the Central Government), representing the Union of India, and the State governments. Later, a third tier was added in the form of Panchayats and Municipalities. In the current arrangement, The Seventh Schedule of the Indian Constitution delimits the subjects of each level of governmental jurisdiction, dividing them into three lists:
Asymmetric federalism.
A distinguishing aspect of Indian federalism is that unlike many other forms of federalism, it is asymmetric. Article 370 makes special provisions for the state of Jammu and Kashmir as per its Instrument of Accession. Article 371 makes special provisions for the states of Andhra Pradesh, Arunachal Pradesh, Assam, Goa, Mizoram, Manipur, Nagaland and Sikkim as per their accession or state-hood deals. Also one more aspect of Indian federalism is system of President's Rule in which the central government (through its appointed Governor) takes control of state's administration for certain months when no party can form a government in the state or there is violent disturbance in the state.
Coalition politics.
Although the Constitution does not say so, India is now a multilingual federation. India has a multi-party system,with political allegiances frequently based on linguistic, regional and caste identities, necessitating coalition politics, especially at the Union level.
South Africa.
By the definition of most political scientists, South Africa counts as a federal state in practice.
Federalism in Europe.
Several federal systems exist in Europe, such as in Switzerland, Austria, Germany, Belgium, Bosnia and Herzegovina and the European Union. Germany and the EU offer the only examples in the world where members of the federal "upper houses" (the Bundesrat and the Council) are neither elected nor appointed but comprise delegates of the governments of their constituents.
Modern Germany abandoned federalism only during Nazism (1933–1945) and in East Germany during from 1952 to 1990. Adolf Hitler viewed federalism as an obstacle to his goals. As he wrote in "Mein Kampf", "National Socialism must claim the right to impose its principles on the whole German nation, without regard to what were hitherto the confines of federal states." Accordingly, the idea of a strong, centralized government has negative associations in German politics, although prior to 1919 or 1933, many social democrats and liberals favored centralization in principle.
In Britain, an Imperial Federation was once seen as ("inter alia") a method of solving the Home Rule problem in Ireland; federalism has long been proposed as a solution to the "Irish Problem", and more lately, to the "West Lothian question".
French Revolution.
During the French Revolution, especially in 1793, "federalism" had an entirely different meaning. It was a political movement to weaken the central government in Paris by devolving power to the provinces.
European Union.
Following the end of World War II, several movements began advocating a European federation, such as the Union of European Federalists or the European Movement, founded in 1948. Those organizations exercised influence in the European unification process, but never in a decisive way. In 2011 also a European political party calling for the creation of a federal Europe was established, the European Federalist Party. Hard for political parties to agree.
Although the drafts of both the Maastricht treaty and the Treaty establishing a Constitution for Europe mentioned federalism, the representatives of the member countries (all of whom would have to agree to the term) never adopted it. The strongest advocates of European federalism have been Germany, Italy, Belgium and Luxembourg while those historically most strongly opposed have been the United Kingdom and France; while other countries that have never campaigned specifically for a particular means of governance in Europe are considered as federalists. Some would consider this the case with states such as Spain, Portugal, Greece, and Hungary. In recent times the French government has become increasingly pro-European Union, while countries like the Czech Republic have taken on the roles of primary opponents to a stronger EU.
Those uncomfortable using the “F” word in the EU context should feel free to refer to it as a quasi-federal or federal-like system. Nevertheless, for the purposes of the analysis here, the EU has the necessary attributes of a federal system. It is striking that while many scholars of the EU continue to resist analyzing it as a federation, most contemporary students of federalism view the EU as a federal system (See for instance, Bednar, Filippov et al., McKay, Kelemen, Defigueido and Weingast). (R. Daniel Kelemen)
Russian Federation.
The post-Imperial nature of Russian subdivision of government changed towards a generally autonomous model which began with the establishment of the USSR (of which Russia was governed as part). It was liberalized in the aftermath of the Soviet Union, with the reforms under Boris Yeltsin preserving much of the Soviet structure while applying increasingly liberal reforms to the governance of the constituent republics and subjects (while also coming into conflict with Chechen secessionist rebels during the Chechen War). Some of the reforms under Yeltsin were scaled back by Vladimir Putin.
All of Russia's subdivisional entities are known as subjects, with some smaller entities, such as the republics enjoying more autonomy than other subjects on account of having an extant presence of a culturally non-Russian ethnic minority or, in some cases, majority.
United States.
Federalism in the United States is the evolving relationship between state governments and the federal government of the United States. American government has evolved from a system of dual federalism to one of associative federalism. In "Federalist No. 46," James Madison asserted that the states and national government "are in fact but different agents and trustees of the people, constituted with different powers." Alexander Hamilton, writing in "Federalist No. 28," suggested that both levels of government would exercise authority to the citizens' benefit: "If their [the peoples'] rights are invaded by either, they can make use of the other as the instrument of redress." ()
Because the states were preexisting political entities, the U.S. Constitution did not need to define or explain federalism in any one section but it often mentions the rights and responsibilities of state governments and state officials in relation to the federal government. The federal government has certain "express powers" (also called "enumerated powers") which are powers spelled out in the Constitution, including the right to levy taxes, declare war, and regulate interstate and foreign commerce. In addition, the "Necessary and Proper Clause" gives the federal government the "implied power" to pass any law "necessary and proper" for the execution of its express powers. Other powers—the "reserved powers"—are reserved to the people or the states. The power delegated to the federal government was significantly expanded by the Supreme Court decision in McCulloch v. Maryland (1819), amendments to the Constitution following the Civil War, and by some later amendments—as well as the overall claim of the Civil War, that the states were legally subject to the final dictates of the federal government.
The Federalist Party of the United States was opposed by the Democratic-Republicans, including powerful figures such as Thomas Jefferson. The Democratic-Republicans mainly believed that: the Legislature had too much power (mainly because of the Necessary and Proper Clause) and that they were unchecked; the Executive had too much power, and that there was no check on the executive; a dictator would arise; and that a bill of rights should be coupled with the constitution to prevent a dictator (then believed to eventually be the president) from exploiting or tyrannizing citizens. The federalists, on the other hand, argued that it was impossible to list all the rights, and those that were not listed could be easily overlooked because they were not in the official bill of rights. Rather, rights in specific cases were to be decided by the judicial system of courts.
After the American Civil War, the federal government increased greatly in influence on everyday life and in size relative to the state governments. Reasons included the need to regulate businesses and industries that span state borders, attempts to secure civil rights, and the provision of social services. The federal government acquired no substantial new powers until the acceptance by the Supreme Court of the Sherman Anti-Trust Act.
From 1938 until 1995, the U.S. Supreme Court did not invalidate any federal statute as exceeding Congress' power under the Commerce Clause. Most actions by the federal government can find some legal support among the express powers, such as the Commerce Clause, whose applicability has been narrowed by the Supreme Court in recent years. In 1995 the Supreme Court rejected the Gun-Free School Zones Act in the Lopez decision, and also rejected the civil remedy portion of the Violence Against Women Act of 1994 in the "United States v. Morrison" decision. Recently, the Commerce Clause was interpreted to include marijuana laws in the "Gonzales v. Raich" decision.
Dual federalism holds that the federal government and the state governments are co-equals, each sovereign.
However, since the Civil War Era, the national courts often interpret the federal government as the final judge of its own powers under dual federalism. The establishment of Native American governments (which are separate and distinct from state and federal government) exercising limited powers of sovereignty, has given rise to the concept of "bi-federalism."
Venezuela.
The Federal War ended in 1863 with the signing of the Treaty of Coche by both the centralist government of the time and the Federal Forces. The United States of Venezuela were subsequently incorporated under a "Federation of Sovereign States" upon principles borrowed from the Articles of Confederation of the United States of America. In this Federation, each State had a "President" of its own that controlled almost every issue, even the creation of "State Armies," while the Federal Army was required to obtain presidential permission to enter any given state.
However, more than 140 years later, the original system has gradually evolved into a quasi-centralist form of government. While the 1999 Constitution still defines Venezuela as a Federal Republic, it abolished the Senate, transferred competences of the States to the Federal Government and granted the President of the Republic vast powers to intervene in the States and Municipalities.
Federalism with two components.
Belgium.
Federalism in the Kingdom of Belgium is an evolving system. Belgian federalism reflects both the linguistic communities (French and Dutch, and to a lesser extent German) and the economic regions (Brussels, Flanders and Wallonia). These correspond to the language areas in Belgium. Although officially there are three language areas, for all practical purposes only two languages are relevant on the federal level, Dutch and French:
On one hand, this means that the Belgian political landscape, generally speaking, consists of only two components: the Dutch-speaking population represented by Dutch-language political parties, and the majority populations of Wallonia and Brussels, represented by their French-speaking parties. The Brussels region emerges as a third component. This specific dual form of federalism, with the special position of Brussels, consequently has a number of political issues—even minor ones—that are being fought out over the Dutch/French-language political division. With such issues, a final decision is possible only in the form of a compromise. This tendency gives this dual federalism model a number of traits that generally are ascribed to confederalism, and makes the future of Belgian federalism contentious.
On the other hand, Belgian federalism is federated with three components. An affirmative resolution concerning Brussels' place in the federal system passed in the parliaments of Wallonia and Brussels. These resolutions passed against the desires of Dutch-speaking parties, who are generally in favour of a federal system with two components (i.e. the Dutch and French Communities of Belgium). However, the Flemish representatives in the Parliament of the Brussels Capital-Region voted in favour of the Brussels resolution, with the exception of one party. The chairman of the Walloon Parliament stated on July 17, 2008 that, "Brussels would take an attitude". Brussels' parliament passed the resolution on July 18, 2008:
This aspect of Belgian federalism helps to explain the difficulties of partition; Brussels, with its importance, is linked to both Wallonia and Flanders and vice versa. This situation, however, does not erase the traits of a confederation in the Belgian system.
Other examples.
Current examples of two-sided federalism:
Historical examples of two-sided federalism include:
Proposed federalism.
It has been proposed in several unitary states to establish a federal system, for various reasons.
China.
China is the largest unitary state in the world by both population and land area. Although China has had long periods of central rule for centuries, it is often argued that the unitary structure of the Chinese government is far too unwieldy to effectively and equitably manage the country's affairs. On the other hand, Chinese nationalists are suspicious of decentralization as a form of secessionism and a backdoor for national disunity; still others argue that the degree of autonomy given to provincial-level officials in the People's Republic of China amounts to a "de facto" federalism.
Libya.
Shortly after the 2011 Libyan civil war, some in the eastern region of the country (Cyrenaica) began to call for the new regime to be federal, with the traditional three regions of Libya (Cyrenaica, Tripolitania, and Fezzan) being the constituent units. A group calling itself the Cyrenaican Transitional Council issued a declaration of autonomy on 6 March 2012; this move was rejected by the National Transitional Council in Tripoli.
Philippines.
The Philippines is a unitary state with some powers devolved to Local Government Units (LGUs) under the terms of the Local Government Code. There is also one autonomous region, the Autonomous Region of Muslim Mindanao. Over the years various modifications have been proposed to the Constitution of the Philippines, including possible transition to a federal system as part of a shift to a parliamentary system. In 2004, Philippine President Gloria Macapagal Arroyo established the Consultative Commission which suggested such a Charter Change but no action was taken by the Philippine Congress to amend the 1987 Constitution.
Spain.
Spain is a unitary state with a relatively 'high' level of decentralisation (i.e., a regional state). Federalism is accepted by parties, such as Podemos, United Left and, more recently, Spanish Socialist Workers' Party . The Spanish Socialist party -traditionally a guaranty of centralism in recent Spanish democratic era, as confirmed in the years of centralism developed during Felipe González's government- has recently considered the idea of building a Federal Spain, in part, due to the increase of the Spanish peripheral nationalisms and the Catalan proposal of self-determination referenda for creating a Catalan State in Catalonia, either independent or within Spain.
United Kingdom.
The United Kingdom has traditionally been governed as a unitary state by the Westminster Parliament in London. Instead of adopting a federal model, the UK has relied on gradual devolution to decentralise political power. Devolution in the UK began with the Government of Ireland Act 1914 which granted home rule to Ireland as a constituent country of the former United Kingdom of Great Britain and Ireland. Following the partition of Ireland in 1921 which saw the creation of the sovereign Irish Free State (which eventually evolved into the modern day Republic of Ireland), Northern Ireland retained its devolved government through the Parliament of Northern Ireland, the only part of the UK to have such a body at this time. This body was suspended in 1972 and Northern Ireland was governed by direct rule during the period of conflict known as The Troubles.
In modern times, a process of devolution in the United Kingdom has decentralised power once again. Since the 1997 referendums in Scotland and Wales and the Good Friday Agreement in Northern Ireland, three of the four constituent countries of the UK now have some level of autonomy. Government has been devolved to the Scottish Parliament, the National Assembly for Wales and the Northern Ireland Assembly. England does not have its own parliament and English affairs continue to be decided by the Westminster Parliament. In 1998 a set of eight unelected Regional assemblies, or chambers, was created to support the English Regional Development Agencies, but these were abolished between 2008 and 2010. The Regions of England continue to be used in certain governmental administrative functions.
Critics of devolution often cite the West Lothian Question, which refers to the voting power of non-English MPs on matters affecting only England in the UK Parliament. Scottish and Welsh nationalism have been increasing in popularity, and since the Scottish independence referendum, 2014 there has been a wider debate about the UK adopting a federal system with each of the four home nations having its own, equal devolved legislatures and law-making powers.
UK federal government was proposed as early as 1912 by the Member of Parliament for Dundee, Winston Churchill, in the context of the legislation for Irish Home Rule. In a speech in Dundee on 12 September, he proposed that England should also be goverend by regional parliaments, with power devolved to areas such as Lancashire, Yorkshire, the Midlands and London as part of a federal system of government.
Federalism as the anarchist and libertarian socialist mode of political organization.
Anarchists are against the State but are not against political organization or "governance"—so long as it is self-governance utilizing direct democracy. The mode of political organization preferred by anarchists, in general, is federalism or confederalism. However, the anarchist definition of federalism tends to differ from the definition of federalism assumed by pro-state political scientists. The following is a brief description of federalism from section I.5 of "An Anarchist FAQ":
Christian Church.
Federalism also finds expression in ecclesiology (the doctrine of the church). For example, presbyterian church governance resembles parliamentary republicanism (a form of "political federalism") to a large extent. In Presbyterian denominations, the local church is ruled by elected elders, some of which are ministerial. Each church then sends representatives or commissioners to presbyteries and further to a general assembly. Each greater level of assembly has ruling authority over its constituent members. In this governmental structure, each component has some level of sovereignty over itself. As in "political federalism", in presbyterian ecclesiology there is shared sovereignty.
Other ecclesiologies also have significant representational and federalistic components, including the more anarchic congregational ecclesiology, and even in more hierarchical episcopal ecclesiology.
Some Christians argue that the earliest source of political federalism (or federalism in human institutions; in contrast to theological federalism) is the ecclesiastical federalism found in the Bible. They point to the structure of the early Christian Church as described (and to many, prescribed) in the New Testament. This is particularly demonstrated in the Council of Jerusalem, described in Acts chapter 15, where the Apostles and elders gathered together to govern the Church; the Apostles being representatives of the universal Church, and elders being such for the local church. To this day, elements of federalism can be found in almost every Christian denomination, some more than others.
Constitutional structure.
Division of powers.
In a federation, the division of power between federal and regional governments is usually outlined in the constitution. It is in this way that the right to self-government of the component states is usually constitutionally entrenched. Component states often also possess their own constitutions which they may amend as they see fit, although in the event of conflict the federal constitution usually takes precedence.
In almost all federations the central government enjoys the powers of foreign policy and national defense. Were this not the case a federation would not be a single sovereign state, per the UN definition. Notably, the states of Germany retain the right to act on their own behalf at an international level, a condition originally granted in exchange for the Kingdom of Bavaria's agreement to join the German Empire in 1871. Beyond this the precise division of power varies from one nation to another.
The constitutions of Germany and the United States provide that all powers not specifically granted to the federal government are retained by the states. The Constitution of some countries like Canada and India, on the other hand, state that powers not explicitly granted to the provincial governments are retained by the federal government. Much like the US system, the Australian Constitution allocates to the Federal government (the Commonwealth of Australia) the power to make laws about certain specified matters which were considered too difficult for the States to manage, so that the States retain all other areas of responsibility. Under the division of powers of the European Union in the Lisbon Treaty, powers which are not either exclusively of European competence or shared between EU and state are retained by the constituent states.
Where every component state of a federation possesses the same powers, we are said to find 'symmetric federalism'. Asymmetric federalism exists where states are granted different powers, or some possess greater autonomy than others do. This is often done in recognition of the existence of a distinct culture in a particular region or regions. In Spain, the Basques and Catalans, as well as the Galicians, spearheaded a historic movement to have their national specificity recognized, crystallizing in the "historical communities" such as Navarre, Galicia, Catalonia, and the Basque Country. They have more powers than the later expanded arrangement for other Spanish regions, or the Spain of the autonomous communities (called also the "coffee for everyone" arrangement), partly to deal with their separate identity and to appease peripheral nationalist leanings, partly out of respect to specific rights they had held earlier in history. However, strictly speaking Spain is not a federalism, but a decentralized administrative organization of the state.
It is common that during the historical evolution of a federation there is a gradual movement of power from the component states to the centre, as the federal government acquires additional powers, sometimes to deal with unforeseen circumstances. The acquisition of new powers by a federal government may occur through formal constitutional amendment or simply through a broadening of the interpretation of a government's existing constitutional powers given by the courts.
Usually, a federation is formed at two levels: the central government and the regions (states, provinces, territories), and little to nothing is said about second or third level administrative political entities. Brazil is an exception, because the 1988 Constitution included the municipalities as autonomous political entities making the federation tripartite, encompassing the Union, the States, and the municipalities. Each state is divided into municipalities ("municípios") with their own legislative council ("câmara de vereadores") and a mayor ("prefeito"), which are partly autonomous from both Federal and State Government. Each municipality has a "little constitution", called "organic law" ("lei orgânica"). Mexico is an intermediate case, in that municipalities are granted full-autonomy by the federal constitution and their existence as autonomous entities ("municipio libre", "free municipality") is established by the federal government and cannot be revoked by the states' constitutions. Moreover, the federal constitution determines which powers and competencies belong exclusively to the municipalities and not to the constituent states. However, municipalities do not have an elected legislative assembly.
Federations often employ the paradox of being a union of states, while still being states (or having aspects of statehood) in themselves. For example, James Madison (author of the US Constitution) wrote in Federalist Paper No. 39 that the US Constitution "is in strictness neither a national nor a federal constitution; but a composition of both. In its foundation, it is federal, not national; in the sources from which the ordinary powers of the Government are drawn, it is partly federal, and partly national..." This stems from the fact that states in the US maintain all sovereignty that they do not yield to the federation by their own consent. This was reaffirmed by the Tenth Amendment to the United States Constitution, which reserves all powers and rights that are not delegated to the Federal Government as left to the States and to the people.
Organs of government.
The structures of most federal governments incorporate mechanisms to protect the rights of component states. One method, known as 'intrastate federalism', is to directly represent the governments of component states in federal political institutions. Where a federation has a bicameral legislature the upper house is often used to represent the component states while the lower house represents the people of the nation as a whole. A federal upper house may be based on a special scheme of apportionment, as is the case in the senates of the United States and Australia, where each state is represented by an equal number of senators irrespective of the size of its population.
Alternatively, or in addition to this practice, the members of an upper house may be indirectly elected by the government or legislature of the component states, as occurred in the United States prior to 1913, or be actual members or delegates of the state governments, as, for example, is the case in the German Bundesrat and in the Council of the European Union. The lower house of a federal legislature is usually directly elected, with apportionment in proportion to population, although states may sometimes still be guaranteed a certain minimum number of seats.
In Canada, the provincial governments represent regional interests and negotiate directly with the central government. A First Ministers conference of the prime minister and the provincial premiers is the de facto highest political forum in the land, although it is not mentioned in the constitution.
Federations often have special procedures for amendment of the federal constitution. As well as reflecting the federal structure of the state this may guarantee that the self-governing status of the component states cannot be abolished without their consent. An amendment to the constitution of the United States must be ratified by three-quarters of either the state legislatures, or of constitutional conventions specially elected in each of the states, before it can come into effect. In referendums to amend the constitutions of Australia and Switzerland it is required that a proposal be endorsed not just by an overall majority of the electorate in the nation as a whole, but also by separate majorities in each of a majority of the states or cantons. In Australia, this latter requirement is known as a "double majority".
Some federal constitutions also provide that certain constitutional amendments cannot occur without the unanimous consent of all states or of a particular state. The US constitution provides that no state may be deprived of equal representation in the senate without its consent. In Australia, if a proposed amendment will specifically impact one or more states, then it must be endorsed in the referendum held in each of those states. Any amendment to the Canadian constitution that would modify the role of the monarchy would require unanimous consent of the provinces. The German Basic Law provides that no amendment is admissible at all that would abolish the federal system.
Federalism as a political philosophy.
The meaning of "federalism", as a political movement, and of what constitutes a 'federalist', varies with country and historical context. Movements associated with the establishment or development of federations can exhibit either centralising or decentralising trends. For example, at the time those nations were being established, factions known as "federalists" in the United States and Australia advocated the formation of strong central government. Similarly, in European Union politics, federalists mostly seek greater EU integration. In contrast, in Spain and in post-war Germany, federal movements have sought decentralisation: the transfer of power from central authorities to local units. In Canada, where Quebec separatism has been a political force for several decades, the "federalist" impulse aims to keep Quebec inside Canada.
Federalism as a concept: history.
The "Oxford English Dictionary" first records the English word "federalism" as occurring in print in 1793 with reference to French politics,
though "anti-federalism" appears as early as 1788.

</doc>
<doc id="11543" url="http://en.wikipedia.org/wiki?curid=11543" title="Firmin Abauzit">
Firmin Abauzit

Firmin Abauzit (1679–1767) was a French scholar who worked on physics, theology and philosophy, and served as librarian in Geneva (Switzerland) during his final 40 years. Abauzit is also notable for proofreading or correcting the writings of Isaac Newton and other scholars.
Biography.
Firmin Abauzit was born of Huguenot parents November 11, 1679 at Uzès, in Languedoc. His father died when he was but two years of age; and when, on the revocation of the Edict of Nantes in 1685, the authorities took steps to have him educated in the Roman Catholic faith, his mother contrived his escape.
For two years his brother and he lived as fugitives in the mountains of the Cévennes, but they at last reached Geneva, where their mother afterwards joined them on escaping from the imprisonment in which she was held from the time of their flight. Abauzit at an early age acquired great proficiency in languages, physics, and theology.
In 1698, he traveled to Germany, then to Holland, where he became acquainted with Pierre Bayle, Pierre Jurieu and Jacques Basnage. Proceeding to England, he was introduced to Sir Isaac Newton, who found in him one of the earliest defenders, against Castel of his discoveries. Newton corrected in the second edition of his "Principia" an error pointed out by Abauzit, and, when sending him the "Commercium Epistolicum," said, "You are well worthy to judge between Gottfried Leibniz and me."
The reputation of Abauzit induced William III to request him to settle in England, but he did not accept the king's offer, preferring to return to Geneva. 
There, from 1715 he rendered valuable assistance to a society that had been formed for translating the New Testament into French. He declined the offer of the chair of philosophy at the University of Geneva in 1723. He assisted in the French language New Testament in 1726. In 1727, he was granted citizenship in Geneva, and he accepted the office of honorary librarian to Geneva, the city of his adoption. It was while he was in Geneva in his later years that he authored many of his works. Here also was the city of his death past the age of 87, on March 20, 1767.
Legacy.
Abauzit was a man of great learning and of wonderful versatility. Whatever chanced to be discussed, it used to be said of Abauzit that he seemed to have made it a subject of particular study. Rousseau, who was jealously sparing of his praises, addressed to him, in his "Julie, ou la nouvelle Héloïse", a fine panegyric; and when a stranger flatteringly told Voltaire he had come to see a great man, the philosopher asked him if he had seen Abauzit. Among his acquaintances, Abauzit claimed Rousseau, Voltaire, Newton, and Bayle.
Little remains of the labours of this intellectual giant, his heirs having, it is said, destroyed the papers that came into their possession, because their own religious opinions were different. A few theological, archaeological, and astronomical articles from his pen appeared in the "Journal Helvetique" and elsewhere, and he contributed several papers to Rousseau's "Dictionnaire de musique" (1767). He wrote a work throwing doubt on the canonical authority of the Apocalypse, which called forth a reply from Dr Leonard Twells, and was published in Denis Diderot's "Encyclopédie". He also edited and made valuable additions to Jacob Spon's "Histoire de la republique de Geneve". A collection of his writings was published at Geneva in 1770 ("Oeuvres de feu M. Abauzit"), and another at London in 1773 ("Oeuvres diverses de M. Abauzit").

</doc>
<doc id="11544" url="http://en.wikipedia.org/wiki?curid=11544" title="French Foreign Legion">
French Foreign Legion

The French Foreign Legion (French: "Légion étrangère" (]), "L.É.") is a military service wing of the French Army established in 1831, unique because it was exclusively created for foreign nationals willing to serve in the French Armed Forces. Commanded by French officers, it is also open to French citizens, who amounted to 24% of the recruits as of 2007. The Foreign Legion is today known as a unit whose training focuses not only on traditional military skills but also on its strong "esprit de corps". As its men come from different countries with different cultures, this is a way to strengthen them enough to work as a team. Consequently, training is often described as not only physically challenging, but also very stressful psychologically. A soldier who becomes injured during a battle for France can immediately apply for French citizenship under a provision known as "Français par le sang versé" ("French by spilled blood"). As of 2008 members come from 140 countries.
The Foreign Legion was primarily used to protect and expand the French colonial empire during the 19th century. The Foreign Legion was stationed in Algeria, where it took part in the pacification and development of the colony. The FFL were deployed in a number of conflicts, including the First Carlist War in 1835, the Crimean War in 1854, the Second Italian War of Independence in 1859, the French intervention in Mexico in 1863, the Franco-Prussian War in 1870, the Tonkin Campaign and Sino–French War in 1883, supporting growth of the French colonial empire in Sub-Saharan Africa and pacifying Algeria, the Second Franco-Dahomean War in 1892, the Second Madagascar expedition in 1895, and the Mandingo Wars in 1894.
In World War I, the Foreign Legion fought in many critical battles on the Western Front. The Foreign Legion played a smaller role in World War II than in World War I, though having a part in the Norwegian, Syrian and North African campaigns. During the First Indochina War (1946–54), the Foreign Legion saw its numbers swell. The FFL lost a large number of men in the catastrophic Battle of Dien Bien Phu. During the Algerian War of Independence (1954–62), the Foreign Legion was brought to the brink of extinction after some officers, men, and the highly decorated 1st Foreign Parachute Regiment (1REP) took part in the Generals' putsch. Notable operations included the Suez Crisis, the Battle of Algiers and various offensives launched by General Maurice Challe including Operations Oranie and Jumelles.
In the 1960s and 1970s, the Legion had a new role as a rapid deployment force to preserve French interests – not only in its former African colonies but in other nations as well; it also returned to its roots of being a unit always ready to be sent to hot-spots all around the world. Some notable operations include: the Chadian–Libyan conflict in 1969–72 (the first time that the Legion was sent in operations after the Algerian War), 1978–79, and 1983–87; Kolwezi in what is now the Democratic Republic of the Congo in May 1978; Rwanda in 1990–94; and the Côte d'Ivoire (the Ivory Coast) in 2002 to the present. In 1990, the Foreign Legion were sent to the Persian Gulf as a part of Opération Daguet. In the 1990s, the Foreign Legion helped with the evacuation of French citizens and foreigners in Rwanda, Gabon and Zaire. The Foreign Legion was also deployed in Cambodia, Somalia, Sarajevo, Bosnia and Herzegovina. In the mid- to late-1990s, the Foreign Legion was deployed in the Central African Republic, Congo-Brazzaville and in Kosovo. In the 2000s, the Foreign Legion was deployed in Operation Enduring Freedom in Afghanistan, Operation Licorne in Côte d'Ivoire, the EUFOR Tchad/RCA in Chad, and Operation Serval in the Northern Mali conflict
Other nations have tried to emulate the French Foreign Legion model. There have been units composed of foreign recruits in China, Israel, the Dutch Koninklijk Nederlandsch-Indische Leger (KNIL), the Rhodesian Bush War of the 1960s and 1970s, and Russia and Spain. Beyond its reputation as an elite unit often engaged in serious fighting, the recruitment practices of the French Foreign Legion have also led to a somewhat romanticised view of it being a place for disgraced or "wronged" men looking to leave behind their old lives and start new ones. This view of the legion is common in literature, and has been used for dramatic effect in many films, not the least of which are several adaptations of the novel "Beau Geste".
History.
The French Foreign Legion was created by Louis Philippe, the King of the French, on 10 March 1831. The purpose of the Foreign Legion was to remove disruptive elements from society and put them to use fighting the enemies of France. Recruits included failed revolutionaries from the rest of Europe, soldiers from the disbanded Swiss and German mercenary regiments of the Bourbon monarchy, and troublemakers in general, both foreign and French. The Royal Ordinance for the establishment of the new regiment specified that the foreigners recruited could only serve outside France. The French expeditionary force that had occupied Algiers in 1830 was in need of reinforcements and the Legion was accordingly transferred in detachments from Toulon to Algeria.
The Foreign Legion was primarily used, as part of the "Armée d'Afrique", to protect and expand the French colonial empire during the 19th century, but it also fought in almost all French wars including the Franco-Prussian War, World War I and World War II. The Foreign Legion has remained an important part of the French Army, surviving three Republics, the Second French Empire, two World Wars, the rise and fall of mass conscript armies, the dismantling of the French colonial empire, and the loss of the Foreign Legion's base, Algeria.
Conquest of Algeria (1830–1847).
Created to fight "outside mainland France", the Foreign Legion was stationed in Algeria, where it took part in the pacification and development of the colony, notably by drying the marshes in the region of Algiers. The Foreign Legion was initially divided into six "national battalions" (Swiss, Poles, Germans, Italians, Spanish, and Dutch-Belgian). Smaller national groups, such as the ten Englishmen recorded in December 1832, appear to have been placed randomly.
In late 1831, the first legionnaires landed in Algeria, the country that would be the Foreign Legion's homeland for 130 years and shape its character. The early years in Algeria were hard on the legion because it was often sent to the worst postings and received the worst assignments, and its members were generally uninterested in the new colony of the French. The Legion served alongside the Battalions of Light Infantry of Africa, formed in 1832, which was a penal military unit made up of men with prison records who still had to do their military service or soldiers with serious disciplinary problems.
The Foreign Legion's first service in Algeria came to an end after only four years, as it was needed elsewhere.
Spain (1835–1839).
To support Isabella's claim to the Spanish throne against her uncle, the French government decided to send the Foreign Legion to Spain. On 28 June 1835, the unit was handed over to the Spanish government. The Foreign Legion landed at Tarragona on 17 August with around 1,400 who were quickly dubbed "Los Argelinos" (the Algerians) by locals because of their previous posting.
The Foreign Legion's commander immediately dissolved the national battalions to improve the "esprit de corps". Later, he also created three squadrons of lancers and an artillery battery from the existing force to increase independence and flexibility. The Foreign Legion was dissolved on 8 December 1838, when it had dropped to only 500 men. The survivors returned to France, many reenlisting in the new Foreign Legion along with many of their former Carlist enemies.
Crimean War (1853–1856).
On 9 June 1854, the French ship "Jean Bart" embarked four battalions of the Foreign Legion for the Crimean Peninsula. A further battalion was stationed at Gallipoli as brigade depot. Eight companies drawn from both regiments of the Foreign Legion took part in the Battle of Alma (20 September 1854). Reinforcements brought the Legion contingent up to brigade strength. As the "Foreign Brigade", it served in the Siege of Sevastopol, during the winter of 1854–1855.
The lack of equipment was particularly challenging and cholera hit the Allied expeditionary force. Nevertheless, the "bellies of leather" (the nickname given to the legionnaires by the Russians because of the large cartridge pouches that they wore attached to their waist belts), performed well. On 21 June 1855, the Third Battalion, left Corsica for the Crimea.
On 8 September the final assault was launched on Sevastopol, and two days later, the Second Foreign Regiment, flags and band playing ahead, marched through the streets of Sevastopol. Although initial reservations had been expressed about whether the Legion should be used outside Africa, the Crimean experience established its suitability for service in European warfare, as well as making a cohesive single entity of what had previously been two separate foreign regiments. Total Legion casualties in the Crimea were 1,703 killed and wounded.
Campaign of Italy (1859).
Like the rest of the "Army of Africa", the Foreign Legion took part in the campaign of Italy. Two foreign regiments, associated with the 2nd Regiment of Zouaves, were part of the Second Brigade of the Second Division of Mac Mahon's Corps. The Foreign Legion acquitted itself particularly well against the Austrians at the battle of Magenta (4 June 1859) and at the Battle of Solferino (24 June). The losses were significant and the Second Foreign Regiment lost Colonel Chabrière, its commanding officer. In gratitude, the city of Milan awarded, in 1909, the "commemorative medal of deliverance", which still adorns the regimental flags of the Second Regiment.
Mexico (1863–1867).
It was in Mexico on 30 April 1863 that the Legion earned its legendary status. A company led by Captain Jean Danjou, numbering 62 soldiers and 3 officers, was escorting a convoy to the besieged city of Puebla when it was attacked and besieged by two thousand loyalists, organised in two battalions of infantry and cavalry, numbering 1,200 and 800 respectively. The patrol was forced to make a defence in Hacienda Camarón, and despite the hopelessness of the situation, fought nearly to the last man. When only six survivors remained, out of ammunition, a bayonet charge was conducted in which three of the six were killed. The remaining three wounded men were brought before the Mexican general, who allowed them to return to France as an honor guard for the body of Captain Danjou. The captain had a wooden hand, which was stolen during the battle; it was later returned to the Legion and is now kept in a case in the Legion Museum at Aubagne, and paraded annually on Camerone Day. It is the Foreign Legion's most precious relic.
During the Mexican Campaign, 6,654 French died. Among these losses, 1,918 of the deaths were from a single regiment of the Legion, a fact that testifies to the importance of the Legion's role in the campaign.
Franco-Prussian War (1870–1871).
According to French law, the Foreign Legion was not to be used within Metropolitan France except in the case of a national invasion, and was consequently not a part of Napoleon III's Imperial Army that capitulated at Sedan. With the defeat of the Imperial Army, the Second French Empire fell and the Third Republic was created.
The new Third Republic was desperately short of trained soldiers following Sedan, so the Foreign Legion was ordered to provide a contingent. On 11 October 1870 two provisional battalions disembarked at Toulon, the first time the Foreign Legion had been deployed in France itself. It attempted to lift the Siege of Paris by breaking through the German lines. It succeeded in retaking Orléans, but failed to break the siege. In January 1871, France capitulated but civil war soon broke out, which led to revolution and the short-lived Paris Commune. The Foreign Legion participated in the suppression of the Commune, which was crushed with great bloodshed.
Tonkin campaign and Sino-French War (1883–1888).
The Foreign Legion's First Battalion (Lieutenant-Colonel Donnier) was sent to Tonkin in the autumn of 1883, during the period of undeclared hostilities that preceded the Sino–French War (August 1884 to April 1885), and formed part of the attack column that stormed the western gate of Son Tay on 16 December. The Second and Third Infantry Battalions ("chef de bataillon" Diguet and Lieutenant-Colonel Schoeffer) were also deployed to Tonkin shortly afterwards, and were present in all the major campaigns of the Sino-French War. Two Foreign Legion companies led the defence at the celebrated Siege of Tuyên Quang (24 November 1884 to 3 March 1885). In January 1885 the Foreign Legion's 4th Battalion ("chef de bataillon" Vitalis) was deployed to the French bridgehead at Keelung (Jilong) in Formosa (Taiwan), where it took part in the later battles of the Keelung Campaign. The battalion played an important role in Colonel Jacques Duchesne's offensive in March 1885 that captured the key Chinese positions of La Table and Fort Bamboo and disengaged Keelung.
In December 1883, during a review of the Second Legion Battalion on the eve of its departure for Tonkin to take part in the Bắc Ninh Campaign, General François de Négrier pronounced a famous "mot": "Vous, légionnaires, vous êtes soldats pour mourir, et je vous envoie où l’on meurt!" ('You, Legionnaires, you are soldiers in order to die, and I'm sending you to where one dies!')
Colonisation of Africa.
As part of the Army of Africa, the Foreign Legion contributed to the growth of the French colonial empire in Sub-Saharan Africa. Simultaneously, the Legion took part to the pacification of Algeria, plagued by various tribal rebellions and razzias.
Second Franco-Dahomean War (1892–1894).
In 1892, King Behanzin was threatening the French protectorate of Porto-Novo in modern-day Benin and France decided to intervene. A battalion, led by commandant Faurax, was formed from two companies of the First Foreign Regiment and two others from the second regiment. From Cotonou, the legionnaires marched to seize Abomey, the capital of the Kingdom of Dahomey. Two and a half months were needed to reach the city, at the cost of repeated battles against the Dahomean warriors, especially the Amazons of the King. King Behanzin surrendered and was captured by the legionnaires in January 1894.
Second Madagascar expedition (1894–1895).
In 1895, a battalion, formed by the First and Second Foreign Regiments, was sent to the Kingdom of Madagascar, as part of an expeditionary force whose mission was to conquer the island. The foreign battalion formed the backbone of the column launched on Antananarivo, the capital of Madagascar. After a few skirmishes, the Queen Ranavalona III promptly surrendered. The Foreign Legion lost 226 men, of whom only a tenth died in actual fighting. Others, like much of the expeditionary force, died from tropical diseases. Despite the success of the expedition, the quelling of sporadic rebellions would take another eight years until 1905, when the island was completely pacified by the French under Joseph Gallieni. During that time, insurrections against the Malagasy Christians of the island, missionaries and foreigners were particularly terrible. Queen Ranavalona III was deposed on January 1897 and was exiled to Algiers in Algeria, where she died in 1917.
Mandingo War (1898).
From 1882 until his capture, Samori Ture, ruler of the Wassoulou Empire, fought the French colonial army, defeating them on several occasions, including a notable victory at Woyowayanko (2 April 1882), in the face of French heavy artillery. Nonetheless, Samori was forced to sign several treaties ceding territory to the French between 1886 and 1889. Samori began a steady retreat, but the fall of other resistance armies, particularly Babemba Traoré at Sikasso, permitted the colonial army to launch a concentrated assault against his forces. A battalion of two companies from the 2nd Foreign Regiment was created in early 1894 to pacify the Niger. The Legionnaires' victory at the fortress of Ouilla and police patrols in the region accelerated the submission of the tribes. On 29 September 1898, Samori Ture was captured by the French Commandant Gouraud and exiled to Gabon, marking the end of the Wassoulou Empire.
World War I.
In World War I, the Foreign Legion fought in many critical battles on the Western Front, including Artois, Champagne, Somme, Aisne, and Verdun (in 1917), and also suffered heavy casualties during 1918. The Foreign Legion was also in the Dardanelles and Macedonian front, and was highly decorated for its efforts. Many young foreigners, including Americans like Fred Zinn, volunteered for the Foreign Legion when the war broke out in 1914. There were marked differences between such idealistic volunteers and the hardened mercenaries of the old Legion, as the poet Alan Seeger pointed out, making assimilation difficult. Nevertheless, the old and the new men of the Foreign Legion fought and died in vicious battles on the Western front, including Belloy-en-Santerre during the Battle of the Somme, where Seeger, after being mortally wounded by machine-gun fire, cheered on the rest of his advancing battalion.
As most European countries and the US were drawn into the war, many of the newer "duration only" volunteers who managed to survive the first years of the war were generally released from the Foreign Legion to join their respective national armies. Citizens of the Central Powers serving with the Foreign Legion on the outbreak of war were normally posted to garrisons in North Africa to avoid problems of divided loyalties.
Between the World Wars.
While at the close of the World War I, the Foreign Legion's prestige was at a high, the Foreign Legion itself had suffered greatly in the trenches of the war. In 1919, the government of Spain raised the Spanish Foreign Legion and modeled it after the French Foreign Legion. General Jean Mordacq intended to rebuild the Foreign Legion as a larger military formation, doing away with the legion's traditional role as a solely infantry formation. General Mordacq envisioned a Foreign Legion consisting not of regiments, but of divisions with cavalry, engineer, and artillery regiments in addition to the legion's infantry mainstay. In 1920, decrees ordained the establishment of regiments of cavalry and artillery. Immediately following the armistice the Foreign Legion experienced an increase of enlistments. The Foreign Legion began the process of reorganizing and redeploying to Algeria.
The legion also took part in the Rif War of 1920–25.
In 1932, the Foreign Legion consisted of 30,000 men, serving in 6 multi-battalion regiments:
World War II.
The Foreign Legion played a smaller role in World War II than in World War I, though having a part in the Norwegian, Syrian and North African campaigns. The 13th Demi-Brigade, formed for service in Norway, found itself in the UK at the time of the French Armistice (June 1940), was deployed to the British 8th Army in North Africa and won fame in the Battle of Bir Hakeim (1942). Reflecting the divided loyalties of the time, part of the Foreign Legion joined the Free French movement while another part served the Vichy government as well as fighting as part of the Wehrmacht's 90th Light Infantry Division in North Africa. A battle in the Syria–Lebanon Campaign of June 1941 saw legionnaire fighting legionnaire as the 13th Demi-Brigade (D.B.L.E.) clashed with the 6th Foreign Infantry Regiment at Damascus in Syria. Later, a thousand of the rank-and-file of the Vichy Legion unit joined the 13th D.B.L.E. of the Free French forces as a third battalion.
Following the war, many German former soldiers joined the Foreign Legion to pursue a military career, an option no longer possible in Germany, with Germans making up as much as 60 percent of the Legion during the war in Indochina. Contrary to popular belief however, French policy was to exclude former members of the Waffen-SS, and candidates for induction were refused if they exhibited the tell-tale bloodtype tattoo, or even a scar that might be masking it. The high percentage of Germans was contrary to normal policy concerning a single dominant nationality however, and in more recent times Germans make up a much smaller percentage of the Foreign Legion's composition.
First Indochina War.
During the First Indochina War (1946–54), the Foreign Legion saw its numbers swell due to the incorporation of World War II veterans who could not adapt to civilian life. Even so, although the Foreign Legion distinguished itself, it also took a heavy toll during the war: constantly being deployed in operations, it even reached the point that whole units were annihilated in combat, in what was a traditional Foreign Legion battlefield. Units of the legion were also involved in the defence of Dien Bien Phu and lost a large number of men in the battle.
Algerian War.
The Algerian War of Independence (1954–62) was a highly traumatic conflict for the Foreign Legion. Constantly on call throughout the country, heavily engaged in fighting against the National Liberation Front and the Armée de Libération Nationale (ALN), the Foreign Legion was brought to the brink of extinction after some officers, men and the highly decorated 1st Foreign Parachute Regiment (1REP) took part in the Generals' putsch. The 1REP was disbanded by order of President de Gaulle after plans were discovered for the 1REP to parachute into Paris and overthrow the French government. Upon being notified that their regiment was to be disbanded and they were to be reassigned, legionnaires of the 1REP blew up their barracks in Algeria as they departed. Notable operations included the Suez Crisis, the Battle of Algiers and various offensives launched by General Maurice Challe including Operations Oranie and Jumelles.
It was during this time that the Legion acquired its parade song "Non, je ne regrette rien", a 1960 Edith Piaf song that their NCOs, leaving their barracks for re-deployment following the Algiers putsch of 1961, sung. The song has been a part of LE heritage since then.
Post-colonial Africa.
By 1962 the morale of the Legion was at an all-time low; it had lost its traditional and spiritual home (Algeria), elite units had been disbanded, and in addition, many officers and men were arrested or deserted to escape prosecution. President de Gaulle considered disbanding it altogether but after being downsized to 8,000 men and stripped of all heavy weaponry, the Legion was spared, packed up and re-headquartered in metropolitan France.
The Legion now had a new role as a rapid intervention force to preserve French interests not only in its former African colonies but in other nations as well; it was also a return to its roots of being a unit always ready to be sent to hot-spots all around the world. Some notable operations include: the Chadian–Libyan conflict in 1969–72 (the first time that the Legion was sent in operations after the Algerian War), 1978–79, and 1983–87; Kolwezi in what is now the Democratic Republic of the Congo in May 1978; Rwanda in 1990–94; and the Côte d'Ivoire (the Ivory Coast) in 2002 to the present.
Gulf War.
In September 1990, the First Foreign Cavalry Regiment, the Second Foreign Infantry Regiment, and the Second Foreign Engineer Regiment were sent to the Persian Gulf as a part of Opération Daguet. The Legion force, comprising 27 different nationalities, was attached to the French 6th Light Armoured Brigade, whose mission was to protect the Coalition's left flank.
After the four-week air campaign, coalition forces launched the ground offensive. They quickly penetrated deep into Iraq, with the Legion taking the Al Salman Airport, meeting little resistance. The war ended after a hundred hours of fighting on the ground, which resulted in very light casualties for the Legion.
Membership.
Historically, the American film industry portrayed the Foreign Legion as, in the words of Neil Tweedie of "The Daily Telegraph", having "a reputation as a haven for cut-throats, crooks and sundry fugitives from justice" and also having many men escaping failed romances. Tweedie said that since the legion had asked few questions of its new recruits, it became "an ideal repository for the scum of the earth." As of 2008, according to Tweedie, the "image as a haven for ne'er-do-wells is largely out of date" since the legion now conducts extensive background checks via Interpol.
The Foreign Legion is the only unit of the French Army open to people of any nationality. Most legionnaires still come from European countries but a growing percentage comes from Latin America. Most of the Foreign Legion's commissioned officers are French with approximately 10% being former Legionnaires who have risen through the ranks.
Legionnaires were, in the past, forced to enlist under a pseudonym ("declared identity"). This disposition exists in order to allow people who want to start their lives over to enlist, and the French Foreign Legion held the belief that it was more fair to make all new recruits use declared identities. French citizens can enlist under a declared, fictitious, foreign citizenship (generally, a francophone one, often that of Belgium, Canada or Switzerland). As of 20 September 2010, new recruits may enlist under their real identities or under declared identities. Recruits who do enlist with declared identities may, after one year's service, regularise their situations under their true identities. After serving in the Foreign Legion for three years, a legionnaire may apply for French citizenship. He must be serving under his real name, must no longer have problems with the authorities, and must have served with "honour and fidelity". Furthermore, a soldier who becomes injured during a battle for France can immediately apply for French citizenship under a provision known as "Français par le sang versé" ("French by spilled blood").
While the Foreign Legion historically did not accept women in its ranks, there was one official female member, Briton Susan Travers, who joined Free French Forces during World War II and became a member of the Foreign Legion after the war, serving in Vietnam during the First Indochina War. Women were barred from service until 2000, which then-French Defence Minister Alain Richard had stated that he wanted to take the level of female recruitment in the Legion to 20% by 2020. But at this time, no woman has been known to have joined the Legion.
The Foreign Legion on occasion inducts honorary members into its ranks. During the siege of Dien Bien Phu this honour was granted to General Christian de Castries, Colonel Pierre Langlais, Geneviève de Galard ("The Angel of Dien Bien Phu") and Marcel Bigeard, the Officer in Command of the 6th BPC. Norman Schwarzkopf, Jr. was also an honorary member.
Membership by country.
As of 2008 members come from 140 countries. The majority of enlisted men originate from outside of France, while the majority of the officer corps consists of Frenchmen. Many recruits originate from Eastern Europe and Latin America. Neil Tweedie of "The Daily Telegraph" said that Germany traditionally provided many recruits, "somewhat ironically given the Legion's bloody role in two world wars." He added that "Brits, too, have played their part, but there was embarrassment recently when it emerged that many British applicants were failing selection due to endemic unfitness."
Original nationalities of the Foreign Legion reflect the events in history at the time they join. Many former Wehrmacht personnel joined in the wake of WWII as many soldiers returning to civilian life found it hard to find reliable employment. Jean-Denis Lepage reports that "The Foreign Legion discreetly recruited from German P.O.W. camps", but adds that the number of these recruits has been subsequently exaggerated. Bernard B. Fall, who was a supporter of the French government, writing in the context of the First Indochina War, questioned the notion that the Foreign Legion was mainly German at that time, calling it:
[a] canard…with the sub-variant that all those Germans were at least SS generals and other much wanted war criminals. As a rule, and in order to prevent any particular nation from making the Foreign Legion into a Praetorian Guard, any particular national component is kept at about 25 percent of the total. Even supposing (and this was the case, of course) that the French recruiters, in the eagerness for candidates would sign up Germans enlisting as Swiss, Austrian, Scandinavian and other nationalities of related ethnic background, it is unlikely that the number of Germans in the Foreign Legion ever exceeded 35 percent. Thus, without making an allowance for losses, rotation, discharges, etc., the maximum number of Germans fighting in Indochina at any one time reached perhaps 7,000 out of 278,000. As to the ex-Nazis, the early arrivals contained a number of them, none of whom were known to be war criminals. French intelligence saw to that.<br>
Since, in view of the rugged Indochinese climate, older men without previous tropical experience constituted more a liability than an asset, the average age of the Foreign Legion enlistees was about 23. At the time of the battle of Dien Bien Phu, any legionnaire of that age group was at the worst, in his "Hitler Youth" shorts when the [Third] Reich collapsed.
The Foreign Legion accepts people enlisting under a nationality that is not their own. A proportion of the Swiss and Belgians are actually likely to be Frenchmen who wish to avoid detection. In addition many Alsatians are said to have joined the Foreign Legion when Alsace was part of the German Empire, and may have been recorded as German while considering themselves French.
Regarding recruitment conditions within the Foreign Legion, see the official page (in English) dedicated to the subject: With regard to age limits, recruits can be accepted from ages ranging from 17 ½ (with parental consent) to 40 years old.
Countries that allow post-Foreign Legion contract.
In the Commonwealth Realms, its collective provisions provide for nationals to commute between armies in training or other purposes. Moreover, this 'blanket provision' between member-states cannot exclude others for it would seem inappropriate to single out individual countries, that is, France in relation to the Legion. For example, Australia and New Zealand may allow post-Legion enlistment providing the national has commonwealth citizenship. Britain allows post-Legion enlistment. Canada allows post-Legion enlistment in its ranks with a completed five-year contract. 
In the European Union framework, post Legion enlistment is less clear. Denmark, Norway, Germany and Portugal allow post-Legion enlistment while The Netherlands has constitutional articles that forbid it. [Rijkswet op het Nederlanderschap, Artikel 15, lid 1e, (In Dutch:)] (that is: one can lose his Dutch nationality by accepting a foreign nationality or can lose his Dutch nationality by serving in the army of a foreign state that is engaged in a conflict against the Dutch Kingdom or one of its allies). The European Union twin threads seem to be recognized dual nationality status or restricting constitutional article. 
The United States allows post-FFL enlistment in its National Guard, and career soldiers, up to the rank of captain only and to green card holders. Second Lieutenant Lawrence J. Franks Jr. was sentenced to four years in prison and dismissal from the U.S. Army on charges of conduct unbecoming of an officer and desertion, as he disappeared from Fort Drum, N.Y. in 2009 and reappeared in 2014. During this time, he served with distinction in the Legion under the assumed name Christopher Flaherty.
Israel allows post-Legion enlistment. The Swiss jail or fine their nationals for joining the Legion due to Switzerland's neutrality.
One of the biggest national groups in the Legion are Poles. Polish law basically allows service in a foreign army, but only after written permission from the Ministry of National Defense. Most soldiers do not actually apply for permission, but only a few have been prosecuted on this account and generally they get probation.
Ranks.
Soldats du rang (Ordinary Legionnaires).
All volunteers in the French Foreign Legion begin their careers as basic legionnaires with one in four eventually becoming a "sous-officier" (non-commissioned officer). On joining, a new recruit receives a monthly salary of €1,200 in addition to food and lodgings. He is also given his own new rifle, which according to the lore of the "Legion" must never be left on a battlefield. Promotion is concurrent with the ranks in the French Army.
^ †: No further promotions are given to non-French Legionnaires on attaining the rank of "Caporal Chef".
Table note: Command insignia in the Foreign Legion use gold lace or braid indicating foot troops in the French Army. But the "Légion étrangère" service color is green (for the now-defunct colonial "Armée d'Afrique") instead of red (regular infantry). Its diamond-shaped regimental patch (or "Écusson") has three borders (indicating a Colonial unit), rather than one (Regulars) or two (Reserves); its grenade insignia has seven flames rather than the usual five.
"Sous-officiers" (non-commissioned officers).
"Sous-officiers" (NCOs) account for 25% of the current Foreign Legion's total manpower.
^ ‡: Since 1 January 2009, the French military rank of "major" has been attached to the sous-officiers. Prior to this, "Major" was an independent rank between NCOs and commissioned officers. It is an executive position within a regiment or demi-brigade responsible for senior administration, standards and discipline.
Officiers (commissioned officers).
Most officers are seconded from the French Army though roughly 10% are former non-commissioned officers promoted from the ranks.
"Chevrons d'ancienneté" (chevrons of seniority).
The Foreign Legion remains the only branch of the French Army that still uses chevrons to indicate seniority. Each gold chevron, which are only used by ordinary legionnaires and noncommissioned officers, denotes five years with the Legion. They are worn beneath the rank insignia.
Traditions of the Legion.
As the Foreign Legion is composed of soldiers of different nationalities and backgrounds, it needed to develop an intense Esprit de Corps, which is carried out by the development of camaraderie, specific traditions, the high sense of loyalty of its legionnaires, the quality of their training and the pride of being a soldier of an élite unit.
Code of Honour.
Every trainee must know by heart the "Legionnaire's Code of Honour". They spend many hours learning it, reciting it, and then getting the vocal synchronisation together:
Mottoes.
Honneur et Fidélité.
Unlike any other French unit, the motto of the Foreign Legion's regimental flags is not "Honneur et Patrie" (Honour and Fatherland) but "Honneur et Fidélité" (Honour and Fidelity).
Legio Patria Nostra.
"Legio Patria Nostra" ("The Legion is our Fatherland") is the motto of the Foreign Legion. The adoption of the Foreign Legion as a new fatherland does not imply the repudiation by the legionnaire of his first nationality. The French Foreign Legion respects the original fatherland of the legionnaires who are totally free to preserve their nationalities. The Foreign Legion even asks the agreement of any legionnaire who could be sent in a military operation where his country of origin would be committed.
Pioneers of the Foreign Legion.
The "Pionniers" (pioneers) are the combat engineers and a traditional unit of the Foreign Legion. The sapper traditionally sport large beards, wear leather aprons and gloves and hold axes. The sappers were very common in the French Army and in other European armies during the Napoleonic Era but progressively disappeared in the 19th century, except in the Foreign Legion.
In the French Army, since the 18th century, every infantry regiment included a small detachment of pioneers. In addition to undertaking road building and entrenchment work, such units were tasked with using their axes and shovels to clear obstacles under enemy fire opening the way for the rest of the infantry. The danger of such missions was recognised by allowing certain privileges, such as being authorised to wear beards.
The current pioneer platoon of the Foreign Legion is provided by the Legion depot and headquarters regiment for public ceremonies. The unit has reintroduced the symbols of the Napoleonic sappers: the beard, the axe, the leather apron, the crossed-axes insignia and the leather gloves. When parades of the Foreign Legion are opened by this unit, it is to commemorate the traditional role of the sappers "opening the way" for the troops.
Marching step.
Also notable is the marching pace of the Foreign Legion. In comparison to the 116-step-per-minute pace of other French units, the Foreign Legion has an 88-step-per-minute marching speed. It is also referred to by Legionnaires as the "crawl". This can be seen at ceremonial parades and public displays attended by the Foreign Legion, particularly while parading in Paris on 14 July (Bastille Day Military Parade). Because of the impressively slow pace, the Foreign Legion is always the last unit marching in any parade. The Foreign Legion is normally accompanied by its own band, which traditionally plays the march of any one of the regiments comprising the Foreign Legion, except that of the unit actually on parade. The regimental song of each unit and "Le Boudin" is sung by legionnaires standing at attention. Also, because the Foreign Legion must always stay together, it does not break formation into two when approaching the presidential grandstand, as other French military units do, in order to preserve the unity of the legion.
Contrary to popular belief, the adoption of the Foreign Legion's slow marching speed was not due to a need to preserve energy and fluids during long marches under the hot Algerian sun. Its exact origins are somewhat unclear, but the official explanation is that although the pace regulation does not seem to have been instituted before 1945, it hails back to the slow marching pace of the Ancien Régime, and its reintroduction was a "return to traditional roots". This was in fact, the march step of the Foreign Legion's ancestor units – the "Régiments Étrangers" or Foreign Regiments of the "Ancien Régime" French Army, the "Grande Armée"‍ '​s foreign units, and the pre-1831 foreign regiments.
""Le Boudin".
"Le Boudin"" is the marching song of French Foreign Legion. Other marches include J'avais un camarade and Massari Marie.
Composition.
Previously, the legion was not stationed in mainland France except in wartime. Until 1962, the Foreign Legion headquarters was located in Sidi Bel Abbès, Algeria. Today, some units of the Légion are in Corsica or overseas possessions (mainly in French Guiana, guarding Guiana Space Centre), while the rest are in the south of mainland France. Current headquarters is in Aubagne, France, just outside Marseille.
Disbanded unit and attempted coup.
The 1st Foreign Parachute Regiment (1e Régiment Étranger Parachutiste, 1e REP) was established in 1955 during the Algerian War and disbanded in April 1961 as the entire regiment rose against the French government of Charles de Gaulle (Algiers Putsch), in protest against moves to negotiate an end to the Algerian War and providing Algeria's independence from France.
Following the independence of Algeria in 1962, the Foreign Legion was reduced in numbers but not disbanded, unlike most other units comprising the "Armée d'Afrique": Zouaves, Tirailleurs, Méharistes, Harkis, Goums, Chasseurs d'Afrique and all but one of the Spahi regiments. The effect was to retain the Foreign Legion as a professional force that could be used for military interventions outside France and not involve the politically unpopular use of French conscripts. The subsequent abolition of conscription in France in 2001 and the creation of an entirely professional army might be expected to put the legion's long-term future at risk but as of 2013[ [update]] this has not been the case.
Current deployments.
These are the following deployments:
Note: English names for countries or territories are in parentheses.
Special Forces.
The legion does not have Special operations units under the command of the 1st circle of Special Operations Command, but it has units over various regiments that operate, train, function and are geared like most special operations units.
The 11th parachute brigade and 27th Mountain Infantry Brigade both contain at least one elite commando team for every regiment that is under these brigades, including the French Foreign Legions Second parachute regiment, and Second Foreign Engineer Regiment.
These units are called "Commando Parachute Group" or "GCP" and "Mountain Commando group" or "GCM".
To be part of a GCP or GCM team, a legionnaire must undergo a very strict selection program.
There is also an elite Amphibious EOD and Pathfinding unit that is within 1REG, called "Plongeurs de combat du génie" or "PCG", it was formally known as "DINOPS" or "Detachement d'Intervention Operationnelle Subaquatique"
Recruitment process.
Basic training.
Basic training is conducted in the 4th Foreign Regiment with a duration of 15 weeks:
Uniforms and equipment of the legion.
Uniforms.
From its foundation until World War I the Foreign Legion normally wore the uniform of the French line infantry for parade with a few special distinctions. Essentially this consisted of a dark blue coat (later tunic) worn with red trousers. The field uniform was often modified under the influence of the extremes of climate and terrain in which the Foreign Legion served. Shakos were soon replaced by the light cloth kepi, which was far more suitable for North African conditions. The practice of wearing heavy "capotes" (greatcoats) on the march and "vestes" (short hip-length jackets) as working dress in barracks was followed by the Foreign Legion from its establishment.
One short lived aberration was the wearing of green uniforms in 1856 by Foreign Legion units recruited in Switzerland for service in the Crimean War. In the Crimea itself (1854–59) a hooded coat and red or blue waist sashes were adopted for winter dress, while during the Mexican Intervention (1863–65) straw hats or sombreros were sometimes substituted for the kepi. When the latter was worn it was usually covered with a white "havelock" – the predecessor of the white kepi that was to become a symbol of the Foreign Legion. Foreign Legion units serving in France during the Franco-Prussian War of 1870–71 were distinguishable only by minor details of insignia from the bulk of the French infantry. However subsequent colonial campaigns saw an increasing use of special garments for hot weather wear such as collarless "keo" blouses in Tonkin 1884–85, khaki drill jackets in Dahomey (1892) and drab covered topees worn with all-white fatigue dress in Madagascar (1895).
In the early 20th century the legionnaire wore a red kepi with blue band and piping, dark blue tunic with red collar, red cuff patches, and red trousers. The most distinctive features were the green epaulettes (replacing the red of the line) worn with red woollen fringes; plus the embroidered Foreign Legion badge of a red flaming grenade, worn on the kepi front instead of a regimental number. In the field a light khaki cover was worn over the kepi, sometimes with a protective neck curtain attached. The standard medium-blue double breasted greatcoat ("capote") of the French infantry was worn, usually buttoned back to free the legs for marching. From the 1830s the legionnaires had worn a broad blue woollen sash around the waist, like other European units of the French Army of Africa (such as the Zouaves or the Chasseurs d'Afrique), while indigenous units of the Army of Africa (spahis and tirailleurs) wore red sashes. White linen trousers tucked into short leather leggings were substituted for red serge in hot weather. This was the origin of the "Beau Geste" image.
In barracks a white bleached kepi cover was often worn together with a short dark blue jacket ("veste") or white blouse plus white trousers. The original kepi cover was khaki and due to constant washing turned white quickly. The white or khaki kepi cover was not unique to the Foreign Legion at this stage but was commonly seen amongst other French units in North Africa. It later became particularly identified with the Foreign Legion as the unit most likely to serve at remote frontier posts (other than locally recruited tirailleurs who wore fezzes or turbans). The variances of climate in North Africa led the French Army to the sensible expedient of letting local commanders decide on the appropriate "tenue de jour" (uniform of the day) according to circumstances. Thus a legionnaire might parade or walk out in blue tunic and white trousers in hot weather, blue tunic and red trousers in normal temperatures or wear the blue greatcoat with red trousers under colder conditions. The sash could be worn with greatcoat, blouse or veste but not with the tunic. Epaulettes were a detachable dress item worn only with tunic or greatcoat for parade or off duty wear.
Officers wore the same dark blue (almost black) tunics as those of their colleagues in the French line regiments, except that black replaced red as a facing colour on collar and cuffs. Gold fringed epaulettes were worn for full dress and rank was shown by the number of gold rings on both kepi and cuffs. Trousers were red with black stripes or white according to occasion or conditions. All-white or light khaki uniforms (from as early as the 1890s) were often worn in the field or for ordinary duties in barracks. Non-commissioned officers were distinguished by red or gold diagonal stripes on the lower sleeves of tunics, vestes and greatcoats. Small detachable stripes were buttoned on to the front of the white shirt-like blouse.
Prior to 1914 units in Indo-China wore white or khaki Colonial Infantry uniforms with Foreign Legion insignia, to overcome supply difficulties. This dress included a white sun helmet of a model that was also worn by Foreign Legion units serving in the outposts of Southern Algeria, though never popular with its wearers. During the initial months of World War I, Foreign Legion units serving in France wore the standard blue greatcoat and red trousers of the French line infantry, distinguished only by collar patches of the same blue as the capote, instead of red. After a short period in sky-blue the Foreign Legion adopted khaki with steel helmets, from early 1916. A mustard shade of khaki drill had been worn on active service in Morocco from 1909, replacing the classic blue and white. The latter continued to be worn in the relatively peaceful conditions of Algeria throughout World War I, although increasingly replaced by khaki drill. The pre-1914 blue and red uniforms could still be occasionally seen as garrison dress in Algeria until stocks were used up about 1919.
During the early 1920s plain khaki drill uniforms of a standard pattern became universal issue for the Foreign Legion with only the red and blue kepi (with or without a cover) and green collar braiding to distinguish the Legionnaire from other French soldiers serving in North African and Indo-China. The neck curtain ceased to be worn from about 1915, although it survived in the newly raised Foreign Legion Cavalry Regiment into the 1920s. The white blouse ("bourgeron") and trousers dating from 1882 were retained for fatigue wear until the 1930s.
At the time of the Foreign Legion's centennial in 1931, a number of traditional features were reintroduced at the initiative of the then commander Colonel Rollet. These included the blue sash and green/red epaulettes. In 1939 the white covered kepi won recognition as the official headdress of the Foreign Legion to be worn on most occasions, rather than simply as a means of reflecting heat and protecting the blue and red material underneath. The Third Foreign Infantry Regiment adopted white tunics and trousers for walking-out dress during the 1930s and all Foreign Legion officers were required to obtain full dress uniforms in the pre-war colours of black and red from 1932 to 1939.
During World War II the Foreign Legion wore a wide range of uniform styles depending on supply sources. These ranged from the heavy capotes and Adrian helmets of 1940 through to British battledress and American field uniforms from 1943 to 1945. The white kepi was stubbornly retained whenever possible.
From 1940 until 1963 the Foreign Legion maintained four Saharan Companies ("Compagnies Sahariennes") as part of the French forces used to patrol and police the desert regions to the south of Morocco and Algeria. Special uniforms were developed for these units, modeled on those of the French officered Camel Corps ("Méharistes") having prime responsibility for the Sahara. In full dress these included black or white zouave style trousers, worn with white tunics and long flowing cloaks. The Legion companies maintained their separate identity by retaining their distinctive kepis, sashes and fringed epaulettes.
The white kepis, together with the sash and epaulettes survive in the Foreign Legion's modern parade dress. Since the 1990s the modern kepi has been made wholly of white material rather than simply worn with a white cover. Officers and senior noncommissioned officers still wear their kepis in the pre-1939 colours of dark blue and red. A green tie and (for officers) a green waistcoat recall the traditional branch colour of the Foreign Legion. From 1959 a green beret (previously worn only by the legion's paratroopers) became the universal ordinary duty headdress, with the kepi reserved for parade and off duty wear. Other items of currently worn dress are the standard issue of the French Army.
Equipment.
The Foreign Legion is basically equipped with the same equipment as similar units elsewhere in the French Army. These include:
Emulation by other countries.
Chinese Ever Victorious Army.
The Ever Victorious Army was the name given to a Chinese imperial army in late 19th century. The new force originally comprised about 200 mostly European mercenaries, recruited in the Shanghai area from sailors, deserters and adventurers. Many were dismissed in the summer of 1861, but the remainder became the officers of the Chinese soldiers recruited mainly in and around Sungkiang. The Chinese troops were increased to 3,000 by May 1862, all equipped with Western firearms and equipment by the British authorities in Shanghai. Throughout its four-year existence the Ever Victorious Army was mainly to operate within a thirty mile radius of Shanghai. It was disbanded in May 1864 with 104 foreign officers and 2,288 Chinese soldiers being paid off. The bulk of the artillery and some infantry transferred to the Chinese Imperial forces. It was the first Chinese army trained in European techniques, tactics, and strategy.
Israeli Mahal.
In Israel, Mahal (Hebrew: מח"ל‎, an acronym for "Mitnadvei Ḥutz LaAretz", which means "Volunteers from outside the Land [of Israel]") is a term designating non-Israelis serving in the Israeli military. The term originates with the (approximately) 4,000 both Jewish and non-Jewish volunteers who went to Israel to fight in the 1948 Arab–Israeli War including Aliyah Bet. The original Mahalniks were mostly World War II veterans from American and British armed forces.
Today, there is a program, Garin Tzabar, within the Israeli Ministry of Defense that administers the enlistment of non-Israeli citizens in the country's armed forces. Programs enable foreigners to join the Israel Defense Forces if they are of Jewish descent (which is defined as at least one grandparent).
Netherlands KNIL Army.
Though not named "Foreign Legion", the Dutch Koninklijk Nederlandsch-Indische Leger (KNIL), or Royal Netherlands-Indian Army (in reference to the Dutch East Indies, now Indonesia), was created in 1830, a year before the French Foreign Legion, and is therefore not an emulation but an entirely original idea and had a similar recruitment policy. It stopped being an army of foreigners around 1900 when recruitment was restricted to Dutch citizens and to the indigenous peoples of the Dutch East Indies. The KNIL was finally disbanded on 26 July 1950, seven months after the Netherlands formally recognised Indonesia as a sovereign state, and almost five years after Indonesia declared its independence.
Rhodesian Light Infantry and 7 Independent Company.
During the Rhodesian Bush War of the 1960s and 1970s, the Rhodesian Security Forces enlisted volunteers from overseas on the same pay and conditions of service as locally-based regulars. The vast majority of the Rhodesian Army's foreigners joined the Rhodesian Light Infantry (RLI), a heliborne commando regiment with a glamorous international reputation; this unit became colloquially known as the "Rhodesian foreign legion" as a result, even though foreigners never made up more than about a third of its men. According to Chris Cocks, an RLI veteran, "the RLI was a mirror of the French Foreign Legion, in that recruiters paid little heed as to a man's past and asked no questions. ... And like the Foreign Legion, once in the ranks, a man's past was irrelevant." Just as French Foreign Legionnaires must speak French, the Rhodesian Army required its foreigners to be anglophone. Many of them were professional soldiers, attracted by the regiment's reputation—mostly former British soldiers, or Vietnam veterans from the United States, Australian and New Zealand forces—and these became a key part of the unit. Others, with no military experience, were often motivated to join the Rhodesian Army by anti-communism, or a desire for adventure or to escape the past.
After the Rhodesians' overseas recruiting campaign for English-speakers, started in 1974, proved successful, they began recruiting French-speakers as well, in 1977. These francophone recruits were placed in their own unit, 7 Independent Company, Rhodesia Regiment, which was commanded by French-speaking officers and operated entirely in French. The experiment was not generally considered a success by the Rhodesian commanders, however, and the company was disbanded in early 1978.
Russian "Foreign Legion".
In 2010 the service conditions of the Russian Military have been changed. The actual term "Russian Foreign Legion" is a colloquial expression without any official recognition. Under the plan, foreigners without dual citizenship are able to sign up for five-year contracts and will be eligible for Russian citizenship after serving three years. Experts say the change opens the way for Commonwealth of Independent States citizens to get fast-track Russian citizenship, and counter the effects of Russia's demographic crisis on its army recruitment.
Spanish Foreign Legion.
The Spanish Foreign Legion was created in 1920, in emulation of the French one, and had a significant role in Spain's colonial wars in Morocco and in the Spanish Civil War on the Nationalist side. The Spanish Foreign Legion recruited foreigners until 1986 but unlike its French model, the number of non-Spanish recruits never exceeded 25%, most of these from Latin America. It is now called the "Spanish Legion" and only recruits Spanish nationals.
References in popular culture.
Beyond its reputation as an elite unit often engaged in serious fighting, the recruitment practices of the French Foreign Legion have also led to a somewhat romanticised view of it being a place for disgraced or "wronged" men looking to leave behind their old lives and start new ones. This view of the legion is common in literature, and has been used for dramatic effect in many films, not the least of which are the several versions of "Beau Geste".
Further reading.
</dl>

</doc>
<doc id="11545" url="http://en.wikipedia.org/wiki?curid=11545" title="Feedback">
Feedback

Feedback occurs when outputs of a system are "fed back" as inputs as part of a chain of cause-and-effect that forms a circuit or loop. The system can then be said to "feed back" into itself. The notion of 'cause-and-effect' has to be handled carefully when applied to feedback systems:
In this context, the term "feedback" has also been used as an abbreviation for:
History.
Self-regulating mechanisms have existed since antiquity, and the idea of feedback had started to enter economic theory in Britain by the eighteenth century, but it wasn't at that time recognized as a universal abstraction and so didn't have a name.
The verb phrase "to feed back", in the sense of "returning to an earlier position" in a mechanical process, was in use in the US by the 1860s, and in 1909, Nobel laureate Karl Ferdinand Braun used the term "feed-back" as a noun to refer to (undesired) "coupling" between components of an electronic circuit.
By the end of 1912, researchers using early electronic amplifiers (audions) had discovered that deliberately coupling part of the output signal back to the input circuit would boost the amplification (through regeneration), but would also cause the audion to howl or sing. This action of feeding back of the signal from output to input gave rise to the use of the term "feedback" as a distinct word by 1920.
There has been over the years some dispute as to the best definition of feedback. According to Ashby (1956), mathematicians and theorists interested in the "principles" of feedback mechanisms prefer the definition of "circularity of action", which keeps the theory simple and consistent. For those with more "practical" aims, feedback should be a deliberate effect via some more tangible connection.
Focusing on uses in management theory, Ramaprasad (1983) defines feedback generally as "...information about the gap between the actual level and the reference level of a system parameter" that is used to "alter the gap in some way." He emphasizes that the information by itself is not feedback unless translated into action.
Types.
Positive and negative feedback.
Two types of feedback are termed "positive feedback" and "negative feedback".
As an example of negative feedback, the diagram might represent a cruise control in a car, for example, that matches a target speed such as the speed limit. The controlled system is the car; its input includes the combined torque from the engine and from the changing slope of the road (the disturbance). The car's speed (status) is measured by a speedometer. The error signal is the departure of the speed as measured by the speedometer from the target speed (set point). This measured error is interpreted by the controller to adjust the accelerator, commanding the fuel flow to the engine (the effector). The resulting change in engine torque, the feedback, combines with the torque exerted by the changing road grade to reduce the error in speed, minimizing the road disturbance.
The terms "positive/negative" were first applied to feedback prior to WWII. The idea of positive feedback was already current in the 1920s with the introduction of the regenerative circuit. Friis and Jensen (1924) described regeneration in a set of electronic amplifiers as a case where "the "feed-back" action is positive" in contrast to negative feed-back action, which they mention only in passing. Harold Stephen Black's classic 1934 paper first details the use of negative feedback in electronic amplifiers. According to Black:
According to Mindell (2002) confusion in the terms arose shortly after this:
Even prior to the terms being applied, James Clerk Maxwell had described several kinds of "component motions" associated with the centrifugal governors used in steam engines, distinguishing between those that lead to a continual "increase" in a disturbance or the amplitude of an oscillation, and those that lead to a "decrease" of the same.
Terminology.
The terms positive and negative feedback are defined in different ways within different disciplines.
The two definitions may cause confusion, such as when an incentive (reward) is used to boost poor performance (narrow a gap). Referring to definition 1, some authors use alternative terms, replacing 'positive/negative' with "self-reinforcing/self-correcting", "reinforcing/balancing", "discrepancy-enhancing/discrepancy-reducing" or "regenerative/degenerative" respectively. And for definition 2, some authors advocate describing the action or effect as positive/negative "reinforcement" or "punishment" rather than feedback.
Yet even within a single discipline an example of feedback can be called either positive or negative, depending on how values are measured or referenced.
This confusion may arise because feedback can be used for either "informational" or "motivational" purposes, and often has both a "qualitative" and a "quantitative" component. As Connellan and Zemke (1993) put it:
Limitations of negative and positive feedback.
While simple systems can sometimes be described as one or the other type, many systems with feedback loops cannot be so easily designated as simply positive or negative, and this is especially true when multiple loops are present.
Other types of feedback.
In general, feedback systems can have many signals fed back and the feedback loop frequently contain mixtures of positive and negative feedback where positive and negative feedback can dominate at different frequencies or different points in the state space of a system.
The term bipolar feedback has been coined to refer to biological systems where positive and negative feedback systems can interact, the output of one affecting the input of another, and vice versa.
Some systems with feedback can have very complex behaviors such as chaotic behaviors in non linear systems, while others have much more predictable behaviors, such as are used to make and design digital systems.
Feedback is used extensively in digital systems. For example binary counters and similar devices employ feedback where the current state and inputs are used to calculate a new state which is then fed back and clocked back into the device to update it.
Applications.
Biology.
In biological systems such as organisms, ecosystems, or the biosphere, most parameters must stay under control within a narrow range around a certain optimal level under certain environmental conditions. The deviation of the optimal value of the controlled parameter can result from the changes in internal and external environments. A change of some of the environmental conditions may also require change of that range to change for the system to function. The value of the parameter to maintain is recorded by a reception system and conveyed to a regulation module via an information channel. An example of this is Insulin oscillations.
Biological systems contain many types of regulatory circuits, both positive and negative. As in other contexts, "positive" and "negative" do not imply that the feedback causes "good" or "bad" effects. A negative feedback loop is one that tends to slow down a process, whereas the positive feedback loop tends to accelerate it. The mirror neurons are part of a social feedback system, when an observed action is "mirrored" by the brain—like a self-performed action.
Feedback is also central to the operations of genes and gene regulatory networks. Repressor (see Lac repressor) and activator proteins are used to create genetic operons, which were identified by Francois Jacob and Jacques Monod in 1961 as "feedback loops". These feedback loops may be positive (as in the case of the coupling between a sugar molecule and the proteins that import sugar into a bacterial cell), or negative (as is often the case in metabolic consumption).
On a larger scale, feedback can have a stabilizing effect on animal populations even when profoundly affected by external changes, although time lags in feedback response can give rise to predator-prey cycles.
In zymology, feedback serves as regulation of activity of an enzyme by its direct product(s) or downstream metabolite(s) in the metabolic pathway (see Allosteric regulation).
The hypothalamic–pituitary–adrenal axis is largely controlled by positive and negative feedback, much of which is still unknown.
In psychology, the body receives a stimulus from the environment or internally that causes the release of hormones. Release of hormones then may cause more of those hormones to be released, causing a positive feedback loop. This cycle is also found in certain behaviour. For example, "shame loops" occur in people who blush easily. When they realize that they are blushing, they become even more embarrassed, which leads to further blushing, and so on.
Climate science.
The climate system is characterized by strong positive and negative feedback loops between processes that affect the state of the atmosphere, ocean, and land. A simple example is the ice-albedo positive feedback loop whereby melting snow exposes more dark ground (of lower albedo), which in turn absorbs heat and causes more snow to melt.
Control theory.
Feedback is extensively used in control theory, using a variety of methods including state space (controls), full state feedback (also known as pole placement), and so forth. Note that in the context of control theory, "feedback" is traditionally assumed to specify "negative feedback".
The most common general-purpose controller using a control-loop feedback mechanism is a proportional-integral-derivative (PID) controller. Heuristically, the terms of a PID controller can be interpreted as corresponding to time: the proportional term depends on the "present" error, the integral term on the accumulation of "past" errors, and the derivative term is a prediction of "future" error, based on current rate of change.
Mechanical engineering.
In ancient times, the float valve was used to regulate the flow of water in Greek and Roman water clocks; similar float valves are used to regulate fuel in a carburettor and also used to regulate tank water level in the flush toilet.
The Dutch inventor Cornelius Drebbel (1572-1633) built thermostats (c1620) to control the temperature of chicken incubators and chemical furnaces. In 1745, the windmill was improved by blacksmith Edmund Lee, who added a fantail to keep the face of the windmill pointing into the wind. In 1787, Thomas Mead regulated the rotation speed of a windmill by using a centrifugal pendulum to adjust the distance between the bedstone and the runner stone (i.e., to adjust the load).
The use of the centrifugal governor by James Watt in 1788 to regulate the speed of his steam engine was one factor leading to the Industrial Revolution. Steam engines also use float valves and pressure release valves as mechanical regulation devices. A mathematical analysis of Watt's governor was done by James Clerk Maxwell in 1868.
The "Great Eastern" was one of the largest steamships of its time and employed a steam powered rudder with feedback mechanism designed in 1866 by John McFarlane Gray. Joseph Farcot coined the word "servo" in 1873 to describe steam-powered steering systems. Hydraulic servos were later used to position guns. Elmer Ambrose Sperry of the Sperry Corporation designed the first autopilot in 1912. Nicolas Minorsky published a theoretical analysis of automatic ship steering in 1922 and described the PID controller.
Internal combustion engines of the late 20th century employed mechanical feedback mechanisms such as the vacuum timing advance but mechanical feedback was replaced by electronic engine management systems once small, robust and powerful single-chip microcontrollers became affordable.
Electronic engineering.
The use of feedback is widespread in the design of electronic amplifiers, oscillators, and stateful logic circuit elements such as flip flops and counters. Electronic feedback systems are also very commonly used to control mechanical, thermal and other physical processes.
If the signal is inverted on its way round the control loop, the system is said to have "negative feedback"; otherwise, the feedback is said to be "positive". Negative feedback is often deliberately introduced to increase the stability and accuracy of a system by correcting or reducing the influence of unwanted changes. This scheme can fail if the input changes faster than the system can respond to it. When this happens, the lag in arrival of the correcting signal can result in over-correction, causing the output to oscillate or "hunt". While often an unwanted consequence of system behaviour, this effect is used deliberately in electronic oscillators.
Harry Nyquist contributed the Nyquist plot for assessing the stability of feedback systems. An easier assessment, but less general, is based upon gain margin and phase margin using Bode plots (contributed by Hendrik Bode). Design to ensure stability often involves frequency compensation, one method of compensation being pole splitting.
Electronic feedback loops are used to control the output of electronic devices, such as amplifiers. A feedback loop is created when all or some portion of the output is fed back to the input. A device is said to be operating "open loop" if no output feedback is being employed and "closed loop" if feedback is being used.
When two or more amplifiers are cross-coupled using positive feedback, complex behaviors can be created. These "multivibrators" are widely used and include:
Negative feedback loops.
Negative feedback occurs when the fed-back output signal has a relative phase of 180° with respect to the input signal (upside down). This situation is sometimes referred to as being "out of phase", but that term also is used to indicate other phase separations, as in "90° out of phase". Negative feedback can be used to correct output errors or to desensitize a system to unwanted fluctuations. In feedback amplifiers, this correction is generally for waveform distortion reduction or to establish a specified gain level. A general expression for the gain of a negative feedback amplifier is the asymptotic gain model.
Positive feedback loops.
When the fed-back signal is in phase with the input signal. Under certain gain conditions, positive feedback reinforces the input signal to the point where the output of the device oscillates between its maximum and minimum possible states. Positive feedback may also introduce hysteresis into a circuit. This can cause the circuit to ignore small signals and respond only to large ones. It is sometimes used to eliminate noise from a digital signal. Under some circumstances, positive feedback may cause a device to latch, i.e., to reach a condition in which the output is locked to its maximum or minimum state. This fact is very widely used in digital electronics to make bistable circuits for volatile storage of information.
The loud squeals that sometimes occurs in audio systems, PA systems, and rock music are known as audio feedback. If a microphone is in front of a loudspeaker that it is connected to, sound that the microphone picks up comes out of the speaker, and is picked up by the microphone and re-amplified. If the loop gain is sufficient, howling or squealing at the maximum power of the amplifier is possible.
Oscillator.
An electronic oscillator is an electronic circuit that produces a periodic, oscillating electronic signal, often a sine wave or a square wave. Oscillators convert direct current (DC) from a power supply to an alternating current signal. They are widely used in many electronic devices. Common examples of signals generated by oscillators include signals broadcast by radio and television transmitters, clock signals that regulate computers and quartz clocks, and the sounds produced by electronic beepers and video games.
Oscillators are often characterized by the frequency of their output signal: 
Oscillators designed to produce a high-power AC output from a DC supply are usually called inverters.
There are two main types of electronic oscillator: the linear or harmonic oscillator and the nonlinear or relaxation oscillator.
Flip-flop.
A Flip-flop or latch is a circuit that has two stable states and can be used to store state information. Flip-flops are very typically constructed using feedback that crosses over between two arms of the circuit, to give a circuit that is stateful. The circuit can be made to change state by signals applied to one or more control inputs and will have one or two outputs. It is the basic storage element in sequential logic. Flip-flops and latches are fundamental building blocks of digital electronics systems used in computers, communications, and many other types of systems.
Flip-flops and latches are used as data storage elements. Such data storage can be used for storage of "state", and such a circuit is described as sequential logic. When used in a finite-state machine, the output and next state depend not only on its current input, but also on its current state (and hence, previous inputs). It can also be used for counting of pulses, and for synchronizing variably-timed input signals to some reference timing signal.
Flip-flops can be either simple (transparent or opaque) or clocked (synchronous or edge-triggered). Although the term flip-flop has historically referred generically to both simple and clocked circuits, in modern usage it is common to reserve the term "flip-flop" exclusively for discussing clocked circuits; the simple ones are commonly called "latches"
Using this terminology, a latch is level-sensitive, whereas a flip-flop is edge-sensitive. That is, when a latch is enabled it becomes transparent, while a flip flop's output only changes on a single type (positive going or negative going) of clock edge.
Software.
Feedback loops provide generic mechanisms for controlling the running, maintenance, and evolution of software and computing systems. Feedback-loops are important models in the engineering of adaptive software, as they define the behaviour of the interactions among the control elements over the adaptation process, to guarantee system properties at run-time. Feedback loops and foundations of control theory have been successfully applied to computing systems. In particular, they have been applied to the development of products such as IBM's Universal Database server and IBM Tivoli. From a software perspective, the autonomic (MAPE, monitor analyze plan execute) loop proposed by researchers of IBM is another valuable contribution to the application of feedback loops to the control of dynamic properties and the design and evolution of autonomic software systems.
Video feedback.
Video feedback is the video equivalent of acoustic feedback. It involves a loop between a video camera input and a video output, e.g., a television screen or monitor. Aiming the camera at the display produces a complex video image based on the feedback.
Social sciences.
Economics and finance.
The stock market is an example of a system prone to oscillatory "hunting", governed by positive and negative feedback resulting from cognitive and emotional factors among market participants. For example,
George Soros used the word "reflexivity," to describe feedback in the financial markets and developed an investment theory based on this principle.
The conventional economic equilibrium model of supply and demand supports only ideal linear negative feedback and was heavily criticized by Paul Ormerod in his book "The Death of Economics", which, in turn, was criticized by traditional economists. This book was part of a change of perspective as economists started to recognise that chaos theory applied to nonlinear feedback systems including financial markets.

</doc>
<doc id="11547" url="http://en.wikipedia.org/wiki?curid=11547" title="Furigana">
Furigana

Furigana (振り仮名) is a Japanese reading aid, consisting of smaller kana, or syllabic characters, printed next to a kanji (ideographic character) or other character to indicate its pronunciation. It is one type of ruby text. Furigana is also known as yomigana (読み仮名) or rubi (ルビ) in Japanese. In modern Japanese, it is mostly used to gloss rare kanji, to clarify rare, nonstandard or ambiguous kanji readings, or in children's or learners' materials. Prior to the post-World War II script reforms, it was more widespread.
Furigana is most often written in hiragana, though katakana is used in certain special cases explained later in the article. In vertical text, "tategaki", the furigana is placed to the right of the line of text, while in horizontal text, "yokogaki", it is placed above the line of text, as illustrated below. 
These examples spell the word "kanji", which is made up of two kanji characters: 漢 ("kan", written in hiragana as かん), and 字 ("ji", written in hiragana as じ).
Appearance.
Furigana may be added by character, in which case the furigana characters that correspond to a kanji are centered over that kanji; or by word or phrase, in which case the entire furigana word is centered over several kanji characters, even if the kanji do not represent equal shares of the kana needed to write them. The latter method is more common, especially since some words in Japanese have unique pronunciations ("jukujikun") that are not related to readings of any of the characters the word is written with.
Furigana fonts are generally sized so that two kana characters fit naturally over one kanji; when more kana are required, this is resolved either by adjusting the furigana by using a condensed font (narrowing the kana), or by adjusting the kanji by intercharacter spacing (adding spaces around the kanji). In case an isolated kanji character has a long reading—for example 〜に携わる (where 携 reads たずさ, "tazusa")—the furigana may instead spill over into the space next to the neighboring kana characters, without condensing or changing spacing. Three-kana readings are not uncommon, particularly due to "yōon" with a long vowel, such as ryō (りょう); five kana are required for kokorozashi (志、こころざし) and six for uketamawaru (承る、うけたまわる), the longest of any characters in the Joyo kanji. Very long readings also occur for certain kanji or symbols which have a "gairaigo" reading; the word "centimeter" is generally written as "cm" (with two half-width characters, so occupying one space) and has the seven-kana reading センチメートル (it can also be written as the kanji 糎, though this is very rare); another common example is "%" (the percent sign), which has the five kana reading パーセント. These cause severe spacing problems due to length and these words being used as units (hence closely associated to the preceding figure).
When it is necessary to distinguish between native Japanese "kun'yomi" and Chinese-derived "on'yomi" pronunciations, for example in Kanji dictionaries, the Japanese pronunciations are written in hiragana, and the Chinese ones are written in katakana. However, this distinction is really only important in dictionaries and other reference works. In ordinary prose, the script chosen will usually be hiragana. The one general exception to this is "modern" Chinese place names, personal names, and (occasionally) food names—these will often be written with kanji, and katakana used for the furigana; in more casual writing these are simply written in katakana, as borrowed words. Occasionally this style is also used for loanwords from other languages (especially English). For example, the kanji 一角獣 (literally "one horn beast") might be glossed with katakana ユニコーン, "yunikōn", to show the pronunciation of the loanword "unicorn", which is unrelated to the normal reading of the kanji. Generally, though, such loanwords are just written in straight katakana.
The distinction between regular kana and the smaller character forms, which are used in regular orthography to mark such things as gemination and palatalization, is often not made in furigana: for example, the usual hiragana spelling of the word 却下 ("kyakka") is きゃっか, but in furigana it might be written きやつか. This was especially common in old-fashioned movable type printing when smaller fonts were not available. Nowadays, with computer-based printing systems, this occurs less frequently.
Usage.
Furigana are most commonly used in works for children, who may not have sufficiently advanced reading skills to recognize the kanji, but can understand the word when written phonetically in hiragana. Because children learn hiragana before katakana, in books for very young children, there are hiragana furigana next to the katakana characters. It is common to use furigana on all kanji characters in works for young children. This is called "sōrubi" (総ルビ) in Japanese.
Many children's and shōnen manga use furigana. There are also books with a phonetic guide (mainly in hiragana but sometimes in romaji) for Japanese learners, which may be bilingual or Japanese only. These are popular with foreigners wishing to master Japanese faster and enjoy reading Japanese short stories, novels or articles.
Some websites and tools exist which provide a phonetic guide for Japanese web pages (in hiragana, romaji or kiriji); these are popular with both Japanese children and foreign Japanese learners.
In works aimed at adult Japanese speakers, furigana may be used on a word written in uncommon kanji; in the mass media, they are generally used on words containing non-Jōyō kanji.
Furigana commonly appear alongside kanji names and their romanizations on signs for railway stations, even if the pronunciation of the kanji is commonly known. Furigana also appear often on maps to show the pronunciation of unusual place names.
Prewar, youths would have been almost illiterate if it was not for furigana.
Names.
Japanese names are usually written in kanji. Because there are many possible readings for kanji names, including special name-only readings called nanori, furigana are often used to give the readings of names. On Japanese official forms, where the name is to be written, there is always an adjacent column for the name to be written in furigana. Usually katakana is preferred.
Furigana may also be used for foreign names written in kanji. Chinese and Korean names are the most common examples: Chinese names are usually pronounced with Japanese readings and the pronunciation written in hiragana, while Korean names are usually pronounced with Korean readings and the pronunciation written in katakana. Furigana may also be necessary in the rare case where names are transliterated into kanji from other languages (e.g. soccer star Ruy Ramos and politician Marutei Tsurunen.)
Language learning.
Kanji and kanji compounds are often presented with furigana in Japanese language textbooks for non-native speakers.
Furigana are also often used in foreign language textbooks for Japanese learners to indicate pronunciation. The words are written in the original foreign script, such as hangul for Korean, and furigana is used to indicate the pronunciation. According to Ministry of Education guidelines, and the opinions of educators, the use of Japanese furigana should be avoided in English teaching due to the differences in pronunciation between English and Japanese. For instance, the word "birthdate" might be glossed in furigana as 「バースデイト」, which corresponds to an imperfect pronunciation like "baasudeito".
Punning and double meaning.
Some writers use furigana to represent slang pronunciations, particularly those that would become hard to understand without the kanji to provide their meaning.
Another use is to write the kanji for something which had been previously referenced, but write furigana for "sore" (それ) or "are" (あれ), meaning "that". This means that the actual word used was "that", but the kanji clarify for the reader what "that" refers to.
In karaoke it is extremely common for furigana to be placed on the song lyrics. The song lyrics are often written in kanji pronounced quite differently from the furigana. The furigana version is used for pronunciation.
Also, because the kanji represent meaning while the furigana represent sound, one can combine the two to create puns or indicate meanings of foreign words. One might write the kanji for "blue", but use katakana to write the pronunciation of the English word "blue"; this may be done, for example, in Japanese subtitles on foreign films, where it can help associate the written Japanese with the sounds actually being spoken by the actors, or it may be used in a translation of a work of fiction to enable the translator to preserve the original sound of a proper name (such as "Firebolt" in the Harry Potter series) in furigana, while simultaneously indicating its meaning with kanji. A similar practice is used in native fiction to clarify extended meanings. For example, in a work of science fiction, some astronaut could use the word ふるさと, "furusato", meaning "my hometown", when referring to planet Earth. To clarify that for the reader, the word "furusato" (hometown) might be written in hiragana over the kanji for "chikyuu" (Earth).
Other Japanese reading aids.
Okurigana.
Okurigana are kana that appear inline at normal size following kanji stems, typically to complete and to inflect adjectives and verbs. In this use they may also help to disambiguate kanji with multiple readings; for example, 上がる (あがる, "agaru") vs. 上る (のぼる, "noboru"). Unlike furigana, the use of okurigana is a mandatory part of the written language.
Kunten.
In the written style known as "kanbun", which is the Japanese approximation of Classical Chinese, small marks called "kunten" are sometimes added as reading aids. Unlike furigana, which indicate pronunciation, "kunten" indicate Japanese grammatical structures absent from the "kanbun", as well as showing how words should be reordered to fit Japanese sentence structure.
Furikanji.
Furigana are sometimes also used to indicate meaning, rather than pronunciation. Over the foreign text, smaller sized Japanese words, in kana or kanji, corresponding to the "meaning" of the foreign words, effectively translate it in place. While rare now, some late 19th–early 20th century authors used kanji as furigana for loanwords written in katakana. This usage is called "furikanji" (振り漢字) in Japanese, since "furigana implies the use of kana".

</doc>
<doc id="11551" url="http://en.wikipedia.org/wiki?curid=11551" title="Francis II, Holy Roman Emperor">
Francis II, Holy Roman Emperor

Francis II (German: "Franz II., Erwählter Römischer Kaiser") (12 February 1768 – 2 March 1835) was the last Holy Roman Emperor, ruling from 1792 until 6 August 1806, when he dissolved the Holy Roman Empire after the decisive defeat at the hands of the First French Empire led by Napoleon at the Battle of Austerlitz. In 1804, he had founded the Austrian Empire and became Francis I ("Franz I."), the first Emperor of Austria ("Kaiser von Österreich"), ruling from 1804 to 1835, so later he was named the one and only "Doppelkaiser" (double emperor) in history.
For the two years between 1804 and 1806, Francis used the title and style "by the grace of God elected Roman Emperor, ever Augustus, hereditary Emperor of Austria" and he was called the "Emperor of both Germany and Austria". He was also Apostolic King of Hungary and Bohemia as Francis I. He also served as the first president of the German Confederation following its establishment in 1815.
Francis I continued his leading role as an opponent of Napoleonic France in the Napoleonic Wars, and suffered several more defeats after Austerlitz. The proxy marriage of state of his daughter Marie Louise of Austria to Napoleon on 10 March 1810 was arguably his most severe personal defeat. After the abdication of Napoleon following the War of the Sixth Coalition, Austria participated as a leading member of the Holy Alliance at the Congress of Vienna, which was largely dominated by Francis's chancellor Klemens Wenzel, Prince von Metternich culminating in a new European map and the restoration of Francis' ancient dominions (except the Holy Roman Empire which was dissolved). Due to the establishment of the Concert of Europe, which largely resisted popular nationalist and liberal tendencies, Francis became viewed as a reactionary later in his reign.
Early life.
Francis was a son of Emperor Leopold II (1747–1792) and his wife Maria Luisa of Spain (1745–1792), daughter of Charles III of Spain. Francis was born in Florence, the capital of Tuscany, where his father reigned as Grand Duke from 1765–90. Though he had a happy childhood surrounded by his many siblings, his family knew Francis was likely to be a future Emperor (his uncle Joseph had no surviving issue from either of his two marriages), and so in 1784 the young Archduke was sent to the Imperial Court in Vienna to educate and prepare him for his future role.
Emperor Joseph II himself took charge of Francis's development. His disciplinarian regime was a stark contrast to the indulgent Florentine Court of Leopold. The Emperor wrote that Francis was "stunted in growth", "backward in bodily dexterity and deportment", and "neither more nor less than a spoiled mother's child". Joseph concluded that "...the manner in which he was treated for upwards of sixteen years could not but have confirmed him in the delusion that the preservation of his own person was the only thing of importance."
Joseph's martinet method of improving the young Francis were "fear and unpleasantness". The young Archduke was isolated, the reasoning being that this would make him more self-sufficient as it was felt by Joseph that Francis "fail[ed] to lead himself, to do his own thinking". Nonetheless, Francis greatly admired his uncle, if rather feared him. To complete his training, Francis was sent to join an army regiment in Hungary and he settled easily into the routine of military life.
After the death of Joseph II in 1790, Francis's father became Emperor. He had an early taste of power while acting as Leopold's deputy in Vienna while the incoming Emperor traversed the Empire attempting to win back those alienated by his brother's policies. The strain told on Leopold and by the winter of 1791, he became ill. He gradually worsened throughout early 1792; on the afternoon of 1 March Leopold died, at the relatively young age of 44. Francis, just past his 24th birthday, was now Emperor, much sooner than he had expected.
Emperor.
As the leader of the large multi-ethnic Habsburg Empire, Francis felt threatened by Napoleon's social and political reforms, which were being exported throughout Europe with the expansion of the first French Empire. Francis had a fraught relationship with France. His aunt Marie Antoinette, the wife of Louis XVI and Queen consort of France, had been guillotined by the revolutionaries at the beginning of his reign. Francis, on the whole, was indifferent to her fate (she was not close to his father, Leopold, and although Francis had met her, he had been too young at the time to have any memory of his aunt). Georges Danton attempted to negotiate with the Emperor for Marie Antoinette's release, but Francis was unwilling to make any concessions in return.
Later, he led Austria into the French Revolutionary Wars. He briefly commanded the Allied forces during the Flanders Campaign of 1794 before handing over command to his brother Archduke Charles. He was later defeated by Napoleon. By the Treaty of Campo Formio, he ceded the left bank of the Rhine to France in exchange for Venice and Dalmatia. He again fought against France during the Second and Third Coalition, when after meeting a crushing defeat at Austerlitz, he had to agree to the Treaty of Pressburg, weakening the Austrian Empire and reorganizing Germany under a Napoleonic imprint that would be called the Confederation of the Rhine. At this point, he believed his position as Holy Roman Emperor to be untenable, so on 6 August 1806, he abdicated the throne. He had anticipated losing the Holy Roman crown, however. Two years earlier, as a reaction to Napoleon making himself an emperor, he had raised Austria to the status of an empire. Hence, after 1806, he reigned as Francis I, Emperor of Austria.
In 1809, Francis attacked France again, hoping to take advantage of the Peninsular War embroiling Napoleon in Spain. He was again defeated, and this time forced to ally himself with Napoleon, ceding territory to the Empire, joining the Continental System, and wedding his daughter Marie-Louise to the Emperor. The Napoleonic wars drastically weakened Austria and threatened its preeminence among the states of Germany, a position that it would eventually cede to the Kingdom of Prussia.
In 1813, for the fourth and final time, Austria turned against France and joined Great Britain, Russia, Prussia and Sweden in their war against Napoleon. Austria played a major role in the final defeat of France—in recognition of this, Francis, represented by Clemens von Metternich, presided over the Congress of Vienna, helping to form the Concert of Europe and the Holy Alliance, ushering in an era of conservatism in Europe. The German Confederation, a loose association of Central European states was created by the Congress of Vienna in 1815 to organize the surviving states of the Holy Roman Empire. The Congress was a personal triumph for Francis, who hosted the assorted dignitaries in comfort, though Francis undermined his allies Tsar Alexander and Frederick William III of Prussia by negotiating a secret treaty with the restored French king Louis XVIII.
The federal Diet met at Frankfurt under Austrian presidency (in fact the Habsburg Emperor was represented by an Austrian "presidential envoy").
Domestic policy.
The violent events of the French Revolution impressed themselves deeply into the mind of Francis (as well as all other European monarchs), and he came to distrust radicalism in any form. In 1794, a "Jacobin" conspiracy was discovered in the Austrian and Hungarian armies. The leaders were put on trial, but the verdicts only skirted the perimeter of the conspiracy. Francis's brother Alexander Leopold (at that time Palatine of Hungary) wrote to the Emperor admitting "Although we have caught a lot of the culprits, we have not really got to the bottom of this business yet." Nonetheless, two officers heavily implicated in the conspiracy were hanged and gibbeted, while numerous others were sentenced to imprisonment (many of whom died from the conditions).
Francis was from his experiences suspicious and set up an extensive network of police spies and censors to monitor dissent (in this he was following his father's lead, as the Grand Duchy of Tuscany had the most effective secret police in Europe). Even his family did not escape attention. His brothers, the Archdukes Charles and Johann had their meetings and activities spied upon. Censorship was also prevalent. The author Franz Grillparzer, a Habsburg patriot, had one play suppressed solely as a "precautionary" measure. When Grillparzer met the censor responsible, he asked him what was objectionable about the work. The censor replied, "Oh, nothing at all. But I thought to myself, 'One can never tell'."
In military affairs Francis had allowed his brother, the Archduke Charles, extensive control over the army during the Napoleonic wars. Yet, distrustful of allowing any individual too much power, he otherwise maintained the separation of command functions between the Hofkriegsrat and his field commanders. In the later years of his reign he limited military spending, requiring it not exceed forty millions florins per year; because of inflation this resulted in inadequate funding, with the army's share of the budget shrinking from half in 1817 to only twenty-three percent in 1830.
Francis presented himself as an open and approachable monarch (he regularly set aside two mornings each week to meet his imperial subjects, regardless of status, by appointment in his office, even speaking to them in their own language), but his will was sovereign. In 1804, he had no compunction about announcing that through his authority as Holy Roman Emperor, he declared he was now Emperor of Austria (at the time a geographical term that had little resonance). Two years later, Francis personally wound up the moribund Holy Roman Empire of the German Nation. Both actions were of dubious constitutional legality.
Later years.
On 2 March 1835, 43 years and a day after his father's death, Francis died in Vienna of a sudden fever aged 67, in the presence of many of his family and with all the religious comforts. His funeral was magnificent, with his Viennese subjects respectfully filing past his coffin in the chapel of Hofburg Palace for three days. Francis was interred in the traditional resting place of Habsburg monarchs, the Kapuziner Imperial Crypt in Vienna's Neue Markt Square. He is buried in tomb number 57, surrounded by his four wives.
Francis left a main point in the political testament he left for his son and heir Ferdinand to, "Preserve unity in the family and regard it as one of the highest goods." In many portraits (particularly those painted by Peter Fendi) he was portrayed as the patriarch of a loving family, surrounded by his children and grandchildren.
After 1806 he used the titles: "We, Francis the First, by the grace of God Emperor of Austria; King of Jerusalem, Hungary, Bohemia, Dalmatia, Croatia, Slavonia, Galicia and Lodomeria; Archduke of Austria; Duke of Lorraine, Salzburg, Würzburg, Franconia, Styria, Carinthia and Carniola; Grand Duke of Cracow; Grand Prince of Transylvania; Margrave of Moravia; Duke of Sandomir, Masovia, Lublin, Upper and Lower Silesia, Auschwitz and Zator, Teschen and Friule; Prince of Berchtesgaden and Mergentheim; Princely Count of Habsburg, Gorizia and Gradisca and of the Tirol; and Margrave of Upper and Lower Lusatia and in Istria".
Marriages.
Francis II married four times:
Children.
From his first wife Elisabeth of Württemberg, one daughter, and his second wife Maria Teresa of the Two Sicilies, eight daughters and four sons:
Children of Francis II
References.
Books.
</dl>

</doc>
<doc id="11552" url="http://en.wikipedia.org/wiki?curid=11552" title="Frederick Abel">
Frederick Abel

Sir Frederick Augustus Abel, 1st Baronet KCB, FRS (17 July 1827 – 6 September 1902) was an English chemist.
Education.
Born in London as son of Johann Leopold Abel, Abel studied chemistry at the Royal Polytechnic Institution and in 1845 became one of the original 26 students of A. W. von Hofmann at the Royal College of Chemistry. In 1852 he was appointed lecturer in chemistry at the Royal Military Academy, Woolwich, succeeding Michael Faraday, who had held that post since 1829.
Early career.
From 1854 until 1888 Abel served as ordnance chemist at the Chemical Establishment of the Royal Arsenal at Woolwich, establishing himself as the leading British authority on explosives. Three years later was appointed chemist to the War Department and chemical referee to the government. During his tenure of this office, which lasted until 1888, he carried out a large amount of work in connection with the chemistry of explosives.
Notable work.
One of the most important of his investigations had to do with the manufacture of guncotton, and he developed a process, consisting essentially of reducing the nitrated cotton to fine pulp, which enabled it to be safely manufactured and at the same time yielded the product in a form that increased its usefulness. This work to an important extent prepared the way for the "smokeless powders" which came into general use towards the end of the 19th century; cordite, the type adopted by the British government in 1891, was invented jointly by him and Sir James Dewar. He and Dewar were unsuccessfully sued by Alfred Nobel over infringement of Nobel's patent for a similar explosive called ballistite, the case finally being resolved in the House of Lords in 1895. He also extensively researched the behaviour of black powder when ignited, with the Scottish physicist Sir Andrew Noble. At the request of the British government, he devised the Abel test, a means of determining the flash point of petroleum products. His first instrument, the open-test apparatus, was specified in an Act of Parliament in 1868 for officially specifying petroleum products. It was superseded in August 1879 by the much more reliable Abel close-test instrument. Under the leadership of Sir Frederick Abel, first, Guncotton was developed at Waltham Abbey Royal Gunpowder Mills, patented in 1865, then, the propellant Cordite, patented in 1889. In electricity Abel studied the construction of electrical fuses and other applications of electricity to warlike purposes, and his work on problems of steel manufacture won him in 1897 the Bessemer medal of the Iron and Steel Institute, of which from 1891 to 1893 he was president.
Leadership and honours.
He was president of the Institution of Electrical Engineers (then the Society of Telegraph Engineers) in 1877. He became a fellow of the Royal Society in 1860, he was a Commander of the Bath (CB) by 13 February 1879, he was knighted on 20 April 1883 and received a Royal Medal in 1887. He took an important part in the work of the Inventions Exhibition (London) in 1885, and in 1887 became organizing secretary and first director of the Imperial Institute, a position he held till his death in 1902. He was Rede Lecturer and received an honorary doctorate from Cambridge University in 1888. He was upgraded to a Knight Commander of the Bath (KCB) on 3 February 1891, created a baronet, of Cadogan Place in the Parish of Chelsea in the County of London, on 25 May 1893 and made a Knight Grand Cross of the Royal Victorian Order (GCVO) on 8 March 1901. Abel died in September 1902, aged 75, and was buried in Nunhead Cemetery, London. The baronetcy became extinct on his death.
Books.
He also wrote several important articles in the ninth edition of the Encyclopædia Britannica.

</doc>
<doc id="11554" url="http://en.wikipedia.org/wiki?curid=11554" title="Fugazi (disambiguation)">
Fugazi (disambiguation)

Fugazi may refer to:

</doc>
<doc id="11555" url="http://en.wikipedia.org/wiki?curid=11555" title="Fluorescence">
Fluorescence

Fluorescence is the emission of light by a substance that has absorbed light or other electromagnetic radiation. It is a form of luminescence. In most cases, the emitted light has a longer wavelength, and therefore lower energy, than the absorbed radiation. The most striking examples of fluorescence occur when the absorbed radiation is in the ultraviolet region of the spectrum, and thus invisible to the human eye, and the emitted light is in the visible region.
Fluorescence has many practical applications, including mineralogy, gemology, chemical sensors (fluorescence spectroscopy), fluorescent labelling, dyes, biological detectors, cosmic-ray detection, and, most commonly, fluorescent lamps. Fluorescence also occurs frequently in nature in some minerals and in various biological states in many branches of the animal kingdom.
History.
An early observation of fluorescence was described in 1560 by Bernardino de Sahagún and in 1565 by Nicolás Monardes in the infusion known as "lignum nephriticum" (Latin for "kidney wood"). It was derived from the wood of two tree species, "Pterocarpus indicus" and "Eysenhardtia polystachya". The chemical compound responsible for this fluorescence is matlaline, which is the oxidation product of one of the flavonoids found in this wood.
In 1819, Edward D. Clarke and in 1822 René Just Haüy described fluorescence in fluorites, Sir David Brewster described the phenomenon for chlorophyll in 1833 and Sir John Herschel did the same for quinine in 1845.
In his 1852 paper on the "Refrangibility" (wavelength change) of light, George Gabriel Stokes described the ability of fluorspar and uranium glass to change invisible light beyond the violet end of the visible spectrum into blue light. He named this phenomenon "fluorescence" : "I am almost inclined to coin a word, and call the appearance "fluorescence", from fluor-spar [i.e., fluorite], as the analogous term "opalescence" is derived from the name of a mineral." The name was derived from the mineral fluorite (calcium difluoride), some examples of which contain traces of divalent europium, which serves as the fluorescent activator to emit blue light. In a key experiment he used a prism to isolate ultraviolet radiation from sunlight and observed blue light emitted by an ethanol solution of quinine exposed by it.
Physical principles.
Photochemistry.
Fluorescence occurs when an orbital electron of a molecule, atom or nanostructure relaxes to its ground state by emitting a photon of light after being excited to a higher quantum state by some type of energy:
Excitation: formula_1
Fluorescence (emission): formula_2
Here formula_3 is a generic term for photon energy with h = Planck's constant and formula_4 = frequency of light. The specific frequencies of exciting and emitted light are dependent on the particular system.
State S0 is called the ground state of the fluorophore (fluorescent molecule) and S1 is its first (electronically) excited state.
A molecule, S1, can relax by various competing pathways. It can undergo "non-radiative" relaxation in which the excitation energy is dissipated as heat (vibrations) to the solvent. Excited organic molecules can also relax via conversion to a triplet state, which may subsequently relax via phosphorescence or by a secondary non-radiative relaxation step.
Relaxation of an S1 state can also occur through interaction with a second molecule through fluorescence quenching. Molecular oxygen (O2) is an extremely efficient quencher of fluorescence just because of its unusual triplet ground state.
In most cases, the emitted light has a longer wavelength, and therefore lower energy, than the absorbed radiation. However, when the absorbed electromagnetic radiation is intense, it is possible for one electron to absorb two photons; this two-photon absorption can lead to emission of radiation having a shorter wavelength than the absorbed radiation. The emitted radiation may also be of the same wavelength as the absorbed radiation, termed "resonance fluorescence".
Molecules that are excited through light absorption or via a different process (e.g. as the product of a reaction) can transfer energy to a second 'sensitized' molecule, which is converted to its excited state and can then fluoresce.
Quantum yield.
The fluorescence quantum yield gives the efficiency of the fluorescence process. It is defined as the ratio of the number of photons emitted to the number of photons absorbed.
The maximum fluorescence quantum yield is 1.0 (100%); each photon absorbed results in a photon emitted. Compounds with quantum yields of 0.10 are still considered quite fluorescent. Another way to define the quantum yield of fluorescence, is by the rate of excited state decay:
where formula_7 is the rate constant of spontaneous emission of radiation and
is the sum of all rates of excited state decay. Other rates of excited state decay are caused by mechanisms other than photon emission and are, therefore, often called "non-radiative rates", which can include:
dynamic collisional quenching, near-field dipole-dipole interaction (or resonance energy transfer), internal conversion, and intersystem crossing. Thus, if the rate of any pathway changes, both the excited state lifetime and the fluorescence quantum yield will be affected.
Fluorescence quantum yields are measured by comparison to a standard. The quinine salt "quinine sulfate" in a sulfuric acid solution is a common fluorescence standard.
Lifetime.
The fluorescence lifetime refers to the average time the molecule stays in its excited state before emitting a photon. Fluorescence typically follows first-order kinetics:
where formula_10 is the concentration of excited state molecules at time formula_11, formula_12 is the initial concentration and formula_13 is the decay rate or the inverse of the fluorescence lifetime. This is an instance of exponential decay. Various radiative and non-radiative processes can de-populate the excited state. In such case the total decay rate is the sum over all rates:
where formula_15 is the total decay rate, formula_16 the radiative decay rate and formula_17 the non-radiative decay rate. It is similar to a first-order chemical reaction in which the first-order rate constant is the sum of all of the rates (a parallel kinetic model). If the rate of spontaneous emission, or any of the other rates are fast, the lifetime is short. For commonly used fluorescent compounds, typical excited state decay times for photon emissions with energies from the UV to near infrared are within the range of 0.5 to 20 nanoseconds. The fluorescence lifetime is an important parameter for practical applications of fluorescence such as fluorescence resonance energy transfer and Fluorescence-lifetime imaging microscopy.
Jablonski diagram.
The Jablonski diagram describes most of the relaxation mechanisms for excited state molecules. The diagram alongside shows how fluorescence occurs due to the relaxation of certain excited electrons of a molecule.
Fluorescence anisotropy.
Fluorophores are more likely to be excited by photons if the transition moment of the fluorophore is parallel to the electric vector of the photon. The polarization of the emitted light will also depend on the transition moment. The transition moment is dependent on the physical orientation of the fluorophore molecule. For fluorophores in solution this means that the intensity and polarization of the emitted light is dependent on rotational diffusion. Therefore, anisotropy measurements can be used to investigate how freely a fluorescent molecule moves in a particular environment.
Fluorescence anisotropy can be defined quantitatively as 
where formula_19 is the emitted intensity parallel to polarization of the excitation light and formula_20 is the emitted intensity perpendicular to the polarization of the excitation light.
Fluorence.
Strongly fluorescent pigments often have an unusual appearance which is often described colloquially as a "neon color." This phenomenon was termed "Farbenglut" by Hermann von Helmholtz and "fluorence" by Ralph M. Evans. It is generally thought to be related to the high brightness of the color relative to what it would be as a component of white. Fluorescence shifts energy in the incident illumination from shorter wavelengths to longer (such as blue to yellow) and thus can make the fluorescent color appear brighter (more saturated) than it could possibly be by reflection alone.
Rules.
There are several general rules that deal with fluorescence. Each of the following rules has exceptions but they are useful guidelines for understanding fluorescence (these rules do not necessarily apply to two-photon absorption).
Kasha–Vavilov rule.
The Kasha–Vavilov rule dictates that the quantum yield of luminescence is independent of the wavelength of exciting radiation. This occurs because excited molecules usually decay to the lowest vibrational level of the excited state before fluorescence emission takes place. The Kasha–Vavilov rule does not always apply and is violated severely in many simple molecules. A somewhat more reliable statement, although still with exceptions, would be that the fluorescence spectrum shows very little dependence on the wavelength of exciting radiation.
Mirror image rule.
For many fluorophores the absorption spectrum is a mirror image of the emission spectrum. This is known as the mirror image rule and is related to the Franck–Condon principle which states that electronic transitions are vertical, that is energy changes without distance changing as can be represented with a vertical line in Jablonski diagram. This means the nucleus does not move and the vibration levels of the excited state resemble the vibration levels of the ground state.
Stokes shift.
In general, emitted fluorescent light has a longer wavelength and lower energy than the absorbed light. This phenomenon, known as Stokes shift, is due to energy loss between the time a photon is absorbed and when it is emitted. The causes and magnitude of Stokes shift can be complex and are dependent on the fluorophore and its environment. However, there are some common causes. It is frequently due to non-radiative decay to the lowest vibrational energy level of the excited state. Another factor is that the emission of fluorescence frequently leaves a fluorophore in a higher vibrational level of the ground state.
Fluorescence in nature.
There are many natural compounds that exhibit fluorescence, and they have a number of applications. Some deep-sea animals, such as the greeneye, use fluorescence.
Biofluorescence vs. bioluminescence vs. biophosphorescence.
Biofluorescence.
Biofluorescence is the absorption of electromagnetic wavelengths from the visible light spectrum by fluorescent proteins in a living organism, and the reemission of that light at a lower energy level. This causes the light that is absorbed to be a different color than the light that is re-emitted. Stimulating light excites an electron, raising energy to an unstable level. This instability is unfavorable, so the energized electron is returned to a stable state almost as immediately as it becomes unstable. This return to stability corresponds with the release of excess energy in the form of fluorescent light. This emission of light is only observable when the stimulant light is still providing light to the organism/object and is typically yellow, orange, red, green, or purple. Biofluorescence is often confused with the following forms of biotic light, bioluminescence and biophosphorescence.
Bioluminescence.
Bioluminescence differs from biofluorescence in that it is the natural production of light by chemical reactions within an organism, whereas biofluorescence is the absorption and reemission of light from the environment.
Biophosphorescence.
Biophosphorescence is similar to biofluorescence in its requirement of light wavelengths as a provider of excitation energy. The difference here lies in the relative stability of the energized electron. Unlike with biofluorescence, here the electron retains stability, emitting light that continues to “glow-in-the-dark” even long after the stimulating light source has been removed.
Mechanisms of biofluorescence.
Epidermal chromatophores.
Pigment cells that exhibit fluorescence are called fluorescent chromatophores, and function somatically similar to regular chromatophores. These cells are dendritic, and contain pigments called fluorosomes. These pigments contain fluorescent proteins are activated by K+ (potassium) ions, and it is their movement, aggregation, and dispersion within the fluorescent chromatophore that cause directed fluorescence patterning. Fluorescent cells are innervated the same as other chromatphores, like melanophores, pigment cells that contain melanin. Short term fluorescent patterning and signaling is controlled by the nervous system. Fluorescent chromatophores can be found in the skin (e.g. in fish) just below the epidermis, amongst other chromatophores.
Epidermal fluorescent cells in fish also respond to hormonal stimuli by the α–MSH and MCH hormones much the same as melanophores. This suggests that fluorescent cells may be have color changes throughout the day that coincide with their circadian rhythm. Fish may also be sensitive to cortisol induced stress responses to environmental stimuli, such as interaction with a predator or engaging in a mating ritual.
Phylogenetics.
Evolutionary origins.
It is suspected by some scientists that GFPs and GFP like proteins began as electron donors activated by light. These electrons were then used for reactions requiring light energy. Functions of fluorescent proteins, such as protection from the sun, conversion of light into different wavelengths, or for signaling are thought to have evolved secondarily.
The incidence of fluorescence across the tree of life is widespread, and has been studied most extensively in a phylogenetic sense in fish. The phenomenon appears to have evolved multiple times in multiple taxa such as in the anguilliformes (eels), gobioidei (gobies and cardinalfishes), and tetradontiformes (triggerfishes), along with the other taxa discussed later in the article. Fluorescence is highly genotypically and phenotypically variable even within ecosystems, in regards to the wavelengths emitted, the patterns displayed, and the intensity of the fluorescence. Generally, the species relying upon camouflage exhibit the greatest diversity in fluorescence, likely because camouflage is one of the most common uses of fluorescence.
Adaptive functions.
Currently, relatively little is known about the functional significance of fluorescence and fluorescent proteins. However, it is suspected that biofluorescence may serve important functions in signaling and communication, mating, lures, camouflage, UV protection and antioxidation, photoacclimation, dinoflagellate regulation, and in coral health.
Aquatic biofluorescence.
Water absorbs light of long wavelengths, so less light from these wavelengths reflects back to reach the eye. Therefore, warm colors from the visual light spectrum appear less vibrant at increasing depths. Water scatters light of shorter wavelengths, meaning cooler colors dominate the visual field in the photic zone. Light intensity decreases 10 fold with every 75 m of depth, so at depths of 75 m, light is 10% as intense as it is on the surface, and is only 1% as intense at 150 m as it is on the surface. Because the water filters out the wavelengths and intensity of water reaching certain depths, different proteins, because of the wavelengths and intensities of light they are capable of absorbing, are better suited to different depths. Theoretically, some fish eyes can detect light as deep as 1000 m. At these depths of the aphotic zone, the only sources of light are organisms themselves, giving off light through chemical reactions in a process called bioluminescence.
Fluorescence is simply defined as the absorption of electromagnetic radiation at one wavelength and its reemission at another, lower energy wavelength. Thus any type of fluorescence depends on the presence of external sources of light. Biologically functional fluorescence is found in the photic zone, where there is not only enough light to cause biofluorescence, but enough light for other organisms to detect it. The visual field in the photic zone is naturally blue, so colors of fluorescence can be detected as bright reds, oranges, yellows, and greens. Green is the most commonly found color in the biofluorescent spectrum, yellow the second most, orange the third, and red is the rarest. Fluorescence can occur in organisms in the aphotic zone as a byproduct of that same organism’s bioluminescence. Some biofluorescence in the aphotic zone is merely a byproduct of the organism’s tissue biochemistry and does not have a functional purpose. However, some cases of functional and adaptive significance of biofluorescence in the aphotic zone of the deep ocean is an active area of research.
Photic zone.
Fish.
Bony fishes living in shallow water, due to living in a colorful environment, generally have good color vision. Thus, in shallow-water fishes, red, orange, and green fluorescence most likely serves as a means of communication with conspecifics, especially given the great phenotypic variance of the phenomenon.
Many fish that exhibit biofluorescence, such as sharks, lizardfish, scorpionfish, wrasses, and flatfishes, also possess yellow intraocular filters. Yellow intraocular filters in the lenses and cornea of certain fishes function as long-pass filters, thus enabling the species that possess them to visualize and potentially exploit fluorescence to enhance visual contrast and patterns that are unseen to other fishes and predators that lack this visual specialization. Fishes that possess the necessary yellow intraocular filters for visualizing biofluorescence potentially exploit a light signal from members of it or a similar functional role. Biofluorescent patterning was especially prominent in cryptically patterned fishes possessing complex camouflage, and that many of these lineages also possess yellow long-pass intraocular filters that could enable visualization of such patterns.
Another adaptive use of fluorescence is to generate red light from the ambient blue light of the photic zone to aid vision. Red light can only be seen across short distances due to attenuation of red light wavelengths by water. Many fish species that fluoresce are small, group-living, or benthic/aphotic, and have conspicuous patterning. This patterning is caused by fluorescent tissue and is visible to other members of the species, however the patterning is invisible at other visual spectra. These intraspecific fluorescent patterns also coincide with intra-species signaling. The patterns present in ocular rings to indicate directionality of an individual’s gaze, and along fins to indicate directionality of an individual’s movement. Current research suspects that this red fluorescence is used for private communication between members of the same species. Due to the prominence of blue light at ocean depths, red light and light of longer wavelengths are muddled, and many predatory reef fish have little to no sensitivity for light at these wavelengths. Fish such as the fairy wrasse that have developed visual sensitivity to longer wavelengths are able to display red fluorescent signals that give a high contrast to the blue environment and are conspicuous to conspecifics in short ranges, yet are relatively invisible to other common fish that have reduced sensitivities to long wavelengths. Thus, fluorescence can be used as adaptive signaling and intra-species communication in reef fish.
Additionally, it is suggested that fluorescent tissues that surround an organism’s eyes are used to convert blue light from the photic zone or green bioluminescence in the aphotic zone into red light to aid vision.
Coral.
Fluorescence serves a wide variety of functions in coral. Fluorescent proteins in corals may contribute to photosynthesis by converting otherwise unusable wavelengths of light into ones for which the coral’s symbiotic algae are able to conduct photosynthesis. Also, the proteins may fluctuate in number as more or less light becomes available as a means of photoacclimation. Similarly, these fluorescent proteins may possess antioxidant capacities to eliminate oxygen radicals produced by photosynthesis. Finally, through modulating photosynthesis, the fluorescent proteins may also serve as a means of regulating the activity of the coral’s photosynthetic algal symbionts.
Cephalopods.
"Alloteuthis subulata" and "Loligo vulgaris", two types of nearly transparent squid, have fluorescent spots above their eyes. These spots reflect incident light, which may serve as a means of camouflage, but also for signaling to other squids for schooling purposes.
Jellyfish.
Another, well-studied example of biofluorescence in the ocean is the hydrozoan Aequorea victoria. This jellyfish lives in the photic zone off the west coast of North America and was identified as a carrier of green fluorescent protein (GFP) by Osamu Shimomura. The gene for these green fluorescent proteins has been isolated and is scientifically significant because it is widely used in genetic studies to indicate the expression of other genes.
Mantis shrimp.
Several species of mantis shrimp, which are stomatopod crustaceans, including "Lysiosquillina glabriuscula", have yellow fluorescent markings along their antennal scales and carapace (shell) that males present during threat displays to predators and other males. The display involves raising the head and thorax, spreading the striking appendages and other maxillipeds, and extending the prominent, oval antennal scales laterally, which makes the animal appear larger and accentuates its yellow fluorescent markings. Furthermore, as depth increases, mantis shrimp fluorescence accounts for a greater part of the visible light available. During mating rituals, mantis shrimp actively fluoresce, and the wavelength of this fluorescence matches the wavelengths detected by their eye pigments.
Aphotic zone.
Siphonophores.
"Siphonophorae" is an order of marine animals from the phylum Hydrozoa that are consist of a specialized medusoid and polyp zooid. Some siphonophores, including the genus Erenna that live in the aphotic zone between depths of 1600 m and 2300 m, exhibit yellow to red fluorescence in the photophores of their tentacle-like tentilla. This fluorescence occurs as a by-product of bioluminescence from these same photophores. The siphonophores exhibit the fluorescence in a flicking pattern that is used as a lure to attract prey.
Dragonfish.
The predatory deep-sea dragonfish "Malacosteus niger", the closely related "Aristostomias" genus and the species "Pachystomias microdon" are capable of harnessing the blue light emitted from their own bioluminescence to generate red biofluorescence from suborbital photophores. This red fluorescence is invisible to other animals, which allows these dragonfish extra light at dark ocean depths without attracting or signaling predators.
Terrestrial biofluorescence.
Butterflies.
Swallowtail ("Papilio") butterflies have complex systems for emitting fluorescent light. Their wings contain pigment-infused crystals that provide directed fluorescent light. These crystals function to produce fluorescent light best when they absorb radiance from sky-blue light (wavelength about 420 nm). The wavelengths of light that the butterflies see the best correspond to the absorbance of the crystals in the butterfly's wings. This likely functions to enhance the capacity for signaling.
Parrots.
Parrots have fluorescent plumage that may be used in mate signaling. A study using mate-choice experiments on budgerigars ("Melopsittacus undulates") found compelling support for fluorescent sexual signaling, with both males and females significantly preferring birds with the fluorescent experimental stimulus. This study suggests that the fluorescent plumage of parrots is not simply a by-product of pigmentation, but instead an adapted sexual signal. Considering the intricacies of the pathways that produce fluorescent pigments, there may be significant costs involved. Therefore, individuals exhibiting strong fluorescence may be honest indicators of high individual quality, since they can deal with the associated costs.
Arachnids.
Spiders fluoresce under UV light and possess a huge diversity of fluorophores. Remarkably, spiders are the only known group in which fluorescence is “taxonomically widespread, variably expressed, evolutionarily labile, and probably under selection and potentially of ecological importance for intraspecific and interspecific signaling.” A study by Andrews et al. (2007) reveals that fluorescence has evolved multiple times across spider taxa, with novel fluorophores evolving during spider diversification. In some spiders, ultraviolet cues are important for predator-prey interactions, intraspecific communication, and camouflaging with matching fluorescent flowers. Differing ecological contexts could favor inhibition or enhancement of fluorescence expression, depending upon whether fluorescence helps spiders be cryptic or makes them more conspicuous to predators. Therefore, natural selection could be acting on expression of fluorescence across spider species.
Scorpions also fluoresce.
Flowers.
The "Mirabilis jalapa" flower contains violet, fluorescent betacyanins and yellow, fluorescent betaxanthins. Under white light, parts of the flower containing only betaxanthins appear yellow, but in areas where both betaxanthins and betacyanins are present, the visible fluorescence of the flower is faded due to internal light-filtering mechanisms. Fluorescence was previously suggested to play a role in pollinator attraction, however, it was later found that the visual signal by fluorescence is negligible compared to the visual signal of light reflected by the flower.
Abiotic fluorescence.
Gemology, mineralogy and geology.
Gemstones, minerals, may have a distinctive fluorescence or may fluoresce differently under short-wave ultraviolet, long-wave ultraviolet, visible light, or X-rays.
Many types of calcite and amber will fluoresce under shortwave UV, longwave UV and visible light. Rubies, emeralds, and diamonds exhibit red fluorescence under long-wave UV, blue and sometimes green light; diamonds also emit light under X-ray radiation.
Fluorescence in minerals is caused by a wide range of activators. In some cases, the concentration of the activator must be restricted to below a certain level, to prevent quenching of the fluorescent emission. Furthermore, the mineral must be free of impurities such as iron or copper, to prevent quenching of possible fluorescence. Divalent manganese, in concentrations of up to several percent, is responsible for the red or orange fluorescence of calcite, the green fluorescence of willemite, the yellow fluorescence of esperite, and the orange fluorescence of wollastonite and clinohedrite. Hexavalent uranium, in the form of the uranyl cation, fluoresces at all concentrations in a yellow green, and is the cause of fluorescence of minerals such as autunite or andersonite, and, at low concentration, is the cause of the fluorescence of such materials as some samples of hyalite opal. Trivalent chromium at low concentration is the source of the red fluorescence of ruby. Divalent europium is the source of the blue fluorescence, when seen in the mineral fluorite. Trivalent lanthanides such as terbium and dysprosium are the principal activators of the creamy yellow fluorescence exhibited by the yttrofluorite variety of the mineral fluorite, and contribute to the orange fluorescence of zircon. Powellite (calcium molybdate) and scheelite (calcium tungstate) fluoresce intrinsically in yellow and blue, respectively. When present together in solid solution, energy is transferred from the higher-energy tungsten to the lower-energy molybdenum, such that fairly low levels of molybdenum are sufficient to cause a yellow emission for scheelite, instead of blue. Low-iron sphalerite (zinc sulfide), fluoresces and phosphoresces in a range of colors, influenced by the presence of various trace impurities.
Crude oil (petroleum) fluoresces in a range of colors, from dull-brown for heavy oils and tars through to bright-yellowish and bluish-white for very light oils and condensates. This phenomenon is used in oil exploration drilling to identify very small amounts of oil in drill cuttings and core samples.
Organic liquids.
Organic solutions such anthracene or stilbene, dissolved in benzene or toluene, fluoresce with ultraviolet or gamma ray irradiation. The decay times of this fluorescence are of the order of nanoseconds, since the duration of the light depends on the lifetime of the excited states of the fluorescent material, in this case anthracene or stilbene.
Atmosphere.
Fluorescence is observed in the atmosphere when the air is under energetic electron bombardment. In cases such as the natural aurora, high-altitude nuclear explosions, and rocket-borne electron gun experiments, the molecules and ions formed have a fluorescent response to light.
Applications of fluorescence.
Lighting.
The common fluorescent lamp relies on fluorescence. Inside the glass tube is a partial vacuum and a small amount of mercury. An electric discharge in the tube causes the mercury atoms to emit ultraviolet light. The tube is lined with a coating of a fluorescent material, called the "phosphor", which absorbs the ultraviolet and re-emits visible light. Fluorescent lighting is more energy-efficient than incandescent lighting elements. However, the uneven spectrum of traditional fluorescent lamps may cause certain colors to appear different than when illuminated by incandescent light or daylight. The mercury vapor emission spectrum is dominated by a short-wave UV line at 254 nm (which provides most of the energy to the phosphors), accompanied by visible light emission at 436 nm (blue), 546 nm (green) and 579 nm (yellow-orange). These three lines can be observed superimposed on the white continuum using a hand spectroscope, for light emitted by the usual white fluorescent tubes. These same visible lines, accompanied by the emission lines of trivalent europium and trivalent terbium, and further accompanied by the emission continuum of divalent europium in the blue region, comprise the more discontinuous light emission of the modern trichromatic phosphor systems used in many compact fluorescent lamp and traditional lamps where better color rendition is a goal.
Fluorescent lights were first available to the public at the 1939 New York World's Fair. Improvements since then have largely been better phosphors, longer life, and more consistent internal discharge, and easier-to-use shapes (such as compact fluorescent lamps). Some high-intensity discharge (HID) lamps couple their even-greater electrical efficiency with phosphor enhancement for better color rendition.
White light-emitting diodes (LEDs) became available in the mid-1990s as LED lamps, in which blue light emitted from the semiconductor strikes phosphors deposited on the tiny chip. The combination of the blue light that continues through the phosphor and the green to red fluorescence from the phosphors produces a net emission of white light.
Glow sticks sometimes utilize fluorescent materials to absorb light from the chemiluminescent reaction and emit light of a different color.
Analytical chemistry.
Many analytical procedures involve the use of a fluorometer, usually with a single exciting wavelength and single detection wavelength. Because of the sensitivity that the method affords, fluorescent molecule concentrations as low as 1 part per trillion can be measured.
Fluorescence in several wavelengths can be detected by an array detector, to detect compounds from HPLC flow. Also, TLC plates can be visualized if the compounds or a coloring reagent is fluorescent. Fluorescence is most effective when there is a larger ratio of atoms at lower energy levels in a Boltzmann distribution. There is, then, a higher probability of excitement and release of photons by lower-energy atoms, making analysis more efficient.
Spectroscopy.
Usually the setup of a fluorescence assay involves a light source, which may emit many different wavelengths of light. In general, a single wavelength is required for proper analysis, so, in order to selectively filter the light, it is passed through an excitation monochromator, and then that chosen wavelength is passed through the sample cell. After absorption and re-emission of the energy, many wavelengths may emerge due to Stokes shift and various electron transitions. To separate and analyze them, the fluorescent radiation is passed through an emission monochromator, and observed selectively by a detector.
Biochemistry and medicine.
Fluorescence in the life sciences is used generally as a non-destructive way of tracking or analysis of biological molecules by means of the fluorescent emission at a specific frequency where there is no background from the excitation light, as relatively few cellular components are naturally fluorescent (called intrinsic or autofluorescence).
In fact, a protein or other component can be "labelled" with an extrinsic fluorophore, a fluorescent dye that can be a small molecule, protein, or quantum dot, finding a large use in many biological applications.
The quantification of a dye is done with a spectrofluorometer and finds additional applications in:
Forensics.
Fingerprints can be visualized with fluorescent compounds such as ninhydrin. Blood and other substances are sometimes detected by fluorescent reagents, like fluorescein. Fibers, and other materials that may be encountered in forensics or with a relationship to various collectibles, are sometimes fluorescent.
Mechanical engineering.
Fluorescent penetrant inspection is used to find cracks and other defects on the surface of a part. Dye tracing, using fluorescent dyes, is used to find leaks in liquid and gas plumbing systems.
Signage.
Fluorescent colors are frequently used in signage, particularly road signs. Fluorescent colors are generally recognizable at longer ranges than their non-fluorescent counterparts, with fluorescent orange being particularly noticeable. This property has led to its frequent use in safety signs and labels.
Optical brighteners.
Fluorescent compounds are often used to enhance the appearance of fabric and paper, causing a "whitening" effect. A white surface treated with an optical brightener can emit more visible light than that which shines on it, making it appear brighter. The blue light emitted by the brightener compensates for the diminishing blue of the treated material and changes the hue away from yellow or brown and toward white. Optical brighteners are used in laundry detergents, high brightness paper, cosmetics, high-visibility clothing and more.

</doc>
<doc id="11556" url="http://en.wikipedia.org/wiki?curid=11556" title="Fundamental theorem of arithmetic">
Fundamental theorem of arithmetic

In number theory, the fundamental theorem of arithmetic, also called the unique factorization theorem or the unique-prime-factorization theorem, states that every integer greater than 1 either is prime itself or is the product of prime numbers, and that this product is unique, up to the order of the factors. For example,
1200 = 24 × 31 × 52 = 3 × 2 × 2 × 2 × 2 × 5 × 5 = 5 × 2 × 3 × 2 × 5 × 2 × 2 = etc.
The theorem is stating two things: first, that 1200 "can" be represented as a product of primes, and second, no matter how this is done, there will always be four 2s, one 3, two 5s, and no other primes in the product.
The requirement that the factors be prime is necessary: factorizations containing composite numbers may not be unique (e.g. 12 = 2 × 6 = 3 × 4).
This theorem is one of the main reasons for which 1 is not considered as a prime number: if 1 would be prime, the factorization would not be unique, as, for example, 2 = 2×1 = 2×1×1 = ...
History.
Book VII, propositions 30 and 32 of Euclid's Elements is essentially the statement and proof of the fundamental theorem.
 If two numbers by multiplying one another make some
number, and any prime number measure the product, it will
also measure one of the original numbers.
 — Euclid, "Elements Book VII, Proposition 30"
Proposition 30 is referred to as Euclid's lemma. And it is the key in the proof of the fundamental theorem of arithmetic.
 Any composite number is measured by some prime number.
 — Euclid, "Elements Book VII, Proposition 31"
Proposition 31 is derived from proposition 30.
 Any number either is prime or is measured by some prime number.
 — Euclid, "Elements Book VII, Proposition 32"
Proposition 32 is derived from proposition 31.
Article 16 of Gauss' "Disquisitiones Arithmeticae" is an early modern statement and proof employing modular arithmetic.
Applications.
Canonical representation of a positive integer.
Every positive integer "n" > 1 can be represented in exactly one way as a product of prime powers:
where "p"1 < "p"2 < ... < "p"k are primes and the α"i" are positive integers.
This representation is called the canonical representation of "n", or the standard form of "n".
Note that factors "p"0 = 1 may be inserted without changing the value of "n" (e.g. 1000 = 23×30×53).<br>In fact, any positive integer can be uniquely represented as an infinite product taken over all the positive prime numbers,
where a finite number of the "n""i" are positive integers, and the rest are zero. Allowing negative exponents provides a canonical form for positive rational numbers.
Arithmetic operations.
The canonical representation, when it is known, is convenient for easily computing products, gcd, and lcm:
However, as Integer factorization of large integers is much harder than computing their product, gcd or lcm, these formulas have, in practice, a limited usage.
Arithmetical functions.
Many arithmetical functions are defined using the canonical representation. In particular, the values of additive and multiplicative functions are determined by their values on the powers of prime numbers.
Proof.
The proof uses Euclid's lemma ("Elements" VII, 30): if a prime "p" divides the product of two natural numbers "a" and "b", then "p" divides "a" or "p" divides "b" (or both).
Existence.
We need to show that every integer greater than 1 is a product of primes.
By induction: assume it is true for all numbers between 1 and "n". If "n" is prime, there is nothing more to prove (a prime is a trivial product of primes, a "product" with only one factor). Otherwise, there are integers "a" and "b", where "n" = "ab" and 1 < "a" ≤ "b" < "n".
By the induction hypothesis,
"a" = "p"1"p"2..."p""j"
and
"b" = "q"1"q"2..."q""k" are products of primes. But then
"n" = "ab" = "p"1"p"2..."p""j""q"1"q"2..."q""k" is a product of primes.
Uniqueness.
Assume that "s" > 1 is the product of prime numbers in two different ways:
We must show "m" = "n" and that the "q""j" are a rearrangement of the "p""i".
By Euclid's lemma, "p"1 must divide one of the "q""j"; relabeling the "q""j" if necessary, say that "p"1 divides "q"1. But "q"1 is prime, so its only divisors are itself and 1. Therefore, "p"1 = "q"1, so that
Reasoning the same way, "p"2 must equal one of the remaining "q""j". Relabeling again if necessary, say "p"2 = "q"2. Then
This can be done for each of the "m" "p""i"'s, showing that "m" ≤ "n" and every "p""i" is a "q""j". Applying the same argument with the formula_9's and formula_10's reversed shows "n" ≤ "m" (hence "m" = "n") and every "q""j" is a "p""i".
Elementary proof of uniqueness.
The fundamental theorem of arithmetic can also be proved without using Euclid's lemma, as follows:
Assume that "s" > 1 is the smallest positive integer which is the product of prime numbers in two different ways. If "s" were prime then it would factor uniquely as itself, so there must be at least two primes in each factorization of "s":
If any "p""i" = "q""j" then, by cancellation, "s"/"p""i" = "s"/"q""j" would be a positive integer greater than 1 with two distinct factorizations. But "s"/"p""i" is smaller than "s", meaning "s" would not actually be the smallest such integer. Therefore every "p""i" must be distinct from every "q""j".
Without loss of generality, take "p"1 < "q"1 (if this is not already the case, switch the "p" and "q" designations.) Consider
and note that 1 < "q"2 ≤ "t" < "s". Therefore "t" must have a unique prime factorization. By rearrangement we see,
Here "u" = (("p"2 ... "p""m") - ("q"2 ... "q""n")) is positive, for if it were negative or zero then so would be its product with "p""1", but that product equals "t" which is positive. So "u" is either 1 or factors into primes. In either case, "t" = "p"1"u" yields a prime factorization of "t", which we know to be unique, so "p"1 appears in the prime factorization of "t".
If ("q"1 - "p"1) equaled 1 then the prime factorization of "t" would be all "q"'s, which would preclude "p"1 from appearing. Thus ("q"1 - "p"1) is not 1, but is positive, so it factors into primes: ("q"1 - "p"1) = ("r"1 ... "r""h"). This yields a prime factorization of
which we know is unique. Now, "p"1 appears in the prime factorization of "t", and it is not equal to any "q", so it must be one of the "r"'s. That means "p"1 is a factor of ("q"1 - "p"1), so there exists a positive integer "k" such that "p"1"k" = ("q"1 - "p"1), and therefore
But that means "q"1 has a proper factorization, so it is not a prime number. This contradiction shows that "s" does not actually have two different prime factorizations. As a result, there is no smallest positive integer with multiple prime factorizations, hence all positive integers greater than 1 factor uniquely into primes.
Generalizations.
The first generalization of the theorem is found in Gauss's second monograph (1832) on biquadratic reciprocity. This paper introduced what is now called the ring of Gaussian integers, the set of all complex numbers "a" + "bi" where "a" and "b" are integers. It is now denoted by formula_16 He showed that this ring has the four units ±1 and ±"i", that the non-zero, non-unit numbers fall into two classes, primes and composites, and that (except for order), the composites have unique factorization as a product of primes.
Similarly, in 1844 while working on cubic reciprocity, Eisenstein introduced the ring formula_17, where formula_18   formula_19 is a cube root of unity. This is the ring of Eisenstein integers, and he proved it has the six units formula_20 and that it has unique factorization.
However, it was also discovered that unique factorization does not always hold. An example is given by formula_21. In this ring one has
Examples like this caused the notion of "prime" to be modified. In formula_21 it can be proven that if any of the factors above can be represented as a product, e.g. 2 = "ab", then one of "a" or "b" must be a unit. This is the traditional definition of "prime". It can also be proven that none of these factors obeys Euclid's lemma; e.g.
2 divides neither (1 + √−5) nor (1 − √−5) even though it divides their product 6. In algebraic number theory 2 is called irreducible in formula_21 (only divisible by itself or a unit) but not prime in in formula_21 (if it divides a product it must divide one of the factors). The mention of formula_21 is required because 2 is prime and irreducible in formula_27 Similarly, 5 is prime and irreducible in formula_28 and not prime nor irreducible in formula_29 Using these definitions it can be proven that in any ring a prime must be irreducible. Euclid's classical lemma can be rephrased as "in the ring of integers formula_28 every irreducible is prime". This is also true in formula_31 and formula_32 but not in formula_29
The rings where every irreducible is prime are called unique factorization domains. As the name indicates, the fundamental theorem of arithmetic is true in them. Important examples are polynomial rings over the integers or over a field, Euclidean domains and principal ideal domains.
In 1843 Kummer introduced the concept of ideal number, which was developed further by Dedekind (1876) into the modern theory of ideals, special subsets of rings. Multiplication is defined for ideals, and the rings in which they have unique factorization are called Dedekind domains.
There is a version of unique factorization for ordinals, though it requires some additional conditions to ensure uniqueness.
References.
The "Disquisitiones Arithmeticae" has been translated from Latin into English and German. The German edition includes all of his papers on number theory: all the proofs of quadratic reciprocity, the determination of the sign of the Gauss sum, the investigations into biquadratic reciprocity, and unpublished notes.
The two monographs Gauss published on biquadratic reciprocity have consecutively numbered sections: the first contains §§ 1–23 and the second §§ 24–76. Footnotes referencing these are of the form "Gauss, BQ, § "n"". Footnotes referencing the "Disquisitiones Arithmeticae" are of the form "Gauss, DA, Art. "n"".
These are in Gauss's "Werke", Vol II, pp. 65–92 and 93–148; German translations are pp. 511–533 and 534–586 of the German edition of the "Disquisitiones".

</doc>
<doc id="11558" url="http://en.wikipedia.org/wiki?curid=11558" title="Flamenco">
Flamenco

Flamenco (]) is a form of Spanish folk music and dance from the region of Andalusia in southern Spain. It includes "cante" (singing), "toque" (guitar playing), "baile" (dance) and "jaleo", which refers to the vocalizations and rhythmic sounds of "palmas" (handclapping) and "pitos" (finger snapping) that encourage performers to excel. First mentioned in literature in 1774, the genre is thought to have grown out of Andalusian and Romani music and dance styles. Flamenco is often associated with the gitanos (Romani people of Spain) and a number of famous flamenco artists are of this ethnicity. Flamenco music was first recorded in the late 18th century but the genre underwent a dramatic development in the late 19th century.
In recent years flamenco has become popular all over the world and is taught in many countries. In Japan there are more flamenco academies than there are in Spain. On November 16, 2010 UNESCO declared flamenco one of the Masterpieces of the Oral and Intangible Heritage of Humanity.
Etymology.
There are many suggestions for the origin of the word "flamenco" as a musical term (summarized below) but no solid evidence for any of them. The word was not recorded as a musical and dance term until the late 18th century.
The Spanish word "flamenco" can mean "flamingo" – referring to the bird, but originally meaning "flame-coloured" – but also "Flemish", i.e. someone or something related to Flanders. The word "flamenco" came to be used for arrogant or flamboyant behaviour in general, which could possibly have come to be applied to the Gitano players and performers.
A theory proposed by Andalusian historian Blas Infante in his 1933 book "Orígenes de lo Flamenco y Secreto del Cante Jondo" suggests that the word "flamenco" comes from the Hispano-Arabic term "fellah mengu", meaning "expelled peasant"; Infante argued that this term referred to the ethnic Andalusians of the Islamic faith, the Moriscos, who in order to avoid forced exile and religious persecution, joined with the Roma newcomers.
The settings.
Flamenco occurs in four main settings:
"Palos".
"Palos" (formerly known as "cantes") are flamenco styles, classified by criteria such as rhythmic pattern, mode, chord progression, stanzaic form and geographic origin. There are over 50 different "palos" although some are rarely performed; only about a dozen of these palos are commonly played. Some are sung unaccompanied while others usually have guitar or other accompaniment. Some forms are danced while others are not. Some are reserved for men and others for women while some may be performed by either, though these traditional distinctions are breaking down: the "Farruca", for example, once a male dance, is now commonly performed by women too.
"Palos" traditionally fall into three classes: the most serious is known as "cante jondo" (or "cante grande"), while lighter, frivolous forms are called "cante chico". Forms that do not fit either category are classed as "cante intermedio". "Cante jondo" has clear traces of Arabic and Spanish folk melodies, as well as vestiges of Byzantine, Christian and Jewish religious music.
Music.
Structure.
A typical flamenco recital with voice and guitar accompaniment, comprises a series of pieces (not exactly “songs”) in different palos. Each song of a set of verses (called "copla", "tercio", or "letras"), which are punctuated by guitar interludes called "falsetas". The guitarist also provides a short introduction which sets the tonality, compás and tempo of the cante. In some palos, these falsetas are also played with certain structure too; for example, the typical sevillanas is played in an AAB pattern, where A and B are the same falseta with only a slight difference in the ending.
Harmony.
Flamenco uses the Flamenco mode (which can also be described as the modern Phrygian mode ("modo frigio"), or a harmonic version of that scale with a major 3rd degree), in addition to the major and minor scales commonly used in modern western music. The Phrygian mode occurs in "palos" such as soleá, most bulerías, siguiriyas, tangos and tientos.
A typical chord sequence, usually called the "Andalusian cadence" may be viewed as in a modified Phrygian: in E the sequence is Am–G–F–E. According to Manolo Sanlúcar "E" is here the tonic, F has the harmonic function of dominant while Am and G assume the functions of subdominant and mediant respectively.
Guitarists tend to use only two basic inversions or "chord shapes" for the tonic chord (music), the open 1st inversion E and the open 3rd inversion A, though they often transpose these by using a capo. Modern guitarists such as Ramón Montoya, have introduced other positions: Montoya himself started to use other chords for the tonic in the modern Dorian sections of several "palos"; F sharp for "tarantas", B for "granaínas" and A flat for the "minera". Montoya also created a new "palo" as a solo for guitar, the "rondeña" in C sharp with "scordatura". Later guitarists have further extended the repertoire of tonalities, chord positions and "scordatura".
There are also "palos" in major mode; most cantiñas and alegrías, guajiras, some "bulerías" and "tonás", and the "cabales" (a major type of "siguiriyas"). The minor mode is restricted to the "Farruca", the "milongas" (among "cantes de ida y vuelta"), and some styles of "tangos, bulerías", etc. In general traditional palos in major and minor mode are limited harmonically to two-chord (tonic–dominant) or three-chord (tonic–subdominant–dominant) progressions. (Rossy 1998:92) However modern guitarists have introduced chord substitution, transition chords, and even modulation.
"Fandangos" and derivative "palos" such as "malagueñas", "tarantas" and "cartageneras) are bimodal": guitar introductions are in Phrygian mode while the singing develops in major mode, modulating to Phrygian at the end of the stanza. (Rossy 1998:92)
Melody.
Dionisio Preciado, quoted by Sabas de Hoces established the following characteristics for the melodies of flamenco singing:
Musicologist Hipólito Rossy adds the following characteristics (Rossy 1997: 97):
Compás.
Compás is the Spanish word for metre or time signature (in classical music theory). It also refers to the rhythmic cycle, or layout, of a "palo".
The compás is fundamental to flamenco. Without it, there is no flamenco. Compás is most often translated as rhythm but it demands far more precise interpretation than other Western styles of music. If there is no guitarist available, the compás is rendered through hand clapping ("palmas") or by hitting a table with the knuckles. The guitarist uses techniques like strumming ("rasgueado") or tapping the soundboard ("golpe"). Changes of chords emphasize the most important downbeats.
Flamenco uses three basic counts or measures: Binary, Ternary and a form of a twelve-beat cycle that is unique to flamenco. There are also free-form styles including, among others, the tonás, saetas, malagueñas, tarantos, and some types of fandangos.
There are three types of 12-beat rhythms, which vary in their layouts, or use of accentuations: soleá, seguiriya and bulería.
The Bulerías is the emblematic palo of flamenco: today its 12-beat cycle is most often played with accents on the 3rd, 7th, 8th, 10th and 12th beats. The accompanying "palmas" are played in groups of 6 beats, giving rise to a multitude of counter-rhythms and percussive voices within the 12 beat compás.
Forms of flamenco expression.
Toque (guitar).
The origins, history and importance of the flamenco guitar is covered in the main Wikipedia entry for the Flamenco guitar
Cante (song).
The origins, history and importance of the cante is covered in the main Wikipedia entry for the cante flamenco.
Baile (dance).
"El baile flamenco" is known for its emotional intensity, proud carriage, expressive use of the arms and rhythmic stamping of the feet (cf. tap dance). As with any dance form, many different styles of flamenco have developed.
In the twentieth century, flamenco danced informally at gitano (Roma) weddings and celebrations in Spain was considered the most "authentic" form of flamenco. There is less virtuoso technique in gitano flamenco, but the music and steps are fundamentally the same. The arms are noticeably different from classical flamenco, curving around the head and body rather than extending, often with a bent elbow.
"Flamenco puro" is considered the form of performance flamenco closest to its gitano influences. In this style, the dance is always performed solo, and is improvised rather than choreographed. Some purists frown on castanets (even though they can be seen in many early 20th century photos of flamenco dancers).
"Classical flamenco" is the style most frequently performed by Spanish flamenco dance companies, tending to exhibit more clearly the characteristics derived from the Seguidilla, a traditional Spanish dance. It is danced largely in a proud and upright way. For women, the back is often held in a marked back bend. Unlike the more gitano influenced styles, there is little movement of the hips, the body is tightly held and the arms are long, like a ballet dancer. In fact many of the dancers in these companies have trained in ballet as well as flamenco. Flamenco has both influenced and been influenced by ballet, as evidenced by the fusion of the two created by 'La Argentinita' in the early part of the twentieth century and later, by Joaquín Cortés.
In the 1950s Jose Greco was one of most famous male Flamenco dancers, performing on stage worldwide and on television including the Ed Sullivan Show, and reviving the art almost singlehandedly.
Modern flamenco is a highly technical dance style requiring years of study. The emphasis for both male and female performers is on lightning-fast footwork performed with absolute precision. In addition, the dancer may have to dance while using props such as castanets, shawls and fans.
"Flamenco nuevo" is a recent style in flamenco, characterized by pared-down costumes (the men often dance bare-chested, and the women in plain jersey dresses). Props such as castanets, fans and shawls are rarely used. Dances are choreographed and include influences from other dance styles.
The flamenco most foreigners are familiar with is a style that was developed as a spectacle for tourists. To add variety, group dances are included and even solos are more likely to be choreographed. The frilly, voluminous spotted dresses are derived from a style of dress worn for the Sevillanas at the annual Feria in Seville.
In traditional flamenco, young people are not considered to have the emotional maturity to adequately convey the "duende" (soul) of the genre. Therefore unlike other dance forms, where dancers turn professional early to take advantage of youth and strength, many flamenco dancers do not hit their peak until their thirties and will continue to perform into their fifties and beyond.

</doc>
<doc id="11561" url="http://en.wikipedia.org/wiki?curid=11561" title="Father Christmas">
Father Christmas

Father Christmas is the traditional British name for a figure associated with Christmas, a forerunner of Santa Claus. The term is also used in many English-speaking countries outside the United Kingdom. A similar figure with the same name (in other languages) exists in several other countries, including Canada and France ("Père Noël"), Spain ("Papá Noel", "Padre Noel"), almost all Hispanic South America ("Papá Noel"), Brazil ("Papai Noel"), Portugal ("Pai Natal"), Italy ("Babbo Natale"), Armenia ("Dzmer Papik"), India ("Christmas Father"), Andorra ("Pare Noel"), Romania ("Moş Crăciun"), Turkey ("Noel Baba"), Hungary ("Télapó") and Bulgaria ("Dyado Koleda", "Grandfather Christmas").
Although he has a quite different origin, in the English-speaking world, Father Christmas is now associated with the development in the United States of Santa Claus, and most people consider them to be different names for the same figure. In English Canada and French Canada, Santa Claus and "Père Noël" are the same character. In Brazil, the figure of a Father Christmas as an old embodiment of Christmas unrelated to modern Santa Claus is virtually nonexistent, having been completely replaced by "Papai Noel", which, despite of keeping that name and etymology, is exactly the same figure of Santa Claus currently known in the US.
History.
In England the earliest known personification of Christmas does not describe him as old, nor refer to him as 'father'. A carol attributed to Richard Smart, Rector of Plymtree from 1435 to 1477, takes the form of a sung dialogue between a choir and a figure representing Christmas, variously addressed as "Nowell", "Sir Christemas" and "my lord Christemas". He does not distribute presents to children but is associated with adult celebrations. Giving news of Christ's birth, Christmas encourages everyone to eat and drink: "Buvez bien par toute la campagnie,/Make good cheer and be right merry." However, the specific depiction of Christmas as a merry old man emerged in the early 17th century. The rise of puritanism had led to increasing condemnation of the traditions handed down from pre-Reformation times, especially communal feasting and drinking. As debate intensified, those writing in support of the traditional celebrations often personified Christmas as a venerable, kindly old gentleman, given to good cheer but not excess. They referred to this personification as "Christmas", "Old Christmas" or "Father Christmas".
Ben Jonson in "Christmas his Masque", dating from December 1616, notes the rising tendency to disparage the traditional forms of celebration. His character 'Christmas' therefore appears in outdated fashions, "attir'd in round Hose, long Stockings, a close Doublet, a high crownd Hat with a Broach, a long thin beard, a Truncheon, little Ruffes, white shoes, his Scarffes, and Garters tyed crosse", and announces "Why Gentlemen, doe you know what you doe? ha! would you ha'kept me out? Christmas, old Christmas?" Later, in a masque by Thomas Nabbes, "The Springs Glorie" produced in 1638, "Christmas" appears as "an old reverend gentleman in furred gown and cap".
During the mid-17th century, the debate about the celebration of Christmas became politically charged, with Royalists adopting a pro-Christmas stance and radical puritans striving to ban the festival entirely. Early in 1646 an anonymous satirical author wrote "The Arraignment, Conviction and Imprisoning of Christmas", in which a Royalist lady is frantically searching for Father Christmas: this was followed months later by the Royalist poet John Taylor's "The Complaint of Christmas", in which Father Christmas mournfully visits puritan towns but sees "...no sign or token of any Holy Day". A book dating from the time of the Commonwealth, "The Vindication of CHRISTMAS or, His Twelve Yeares' Observations upon the Times" (London, 1652), involved "Old Christmas" advocating a merry, alcoholic Christmas and casting aspersions on the charitable motives of the ruling Puritans. In a similar vein, a humorous pamphlet of 1686 by Josiah King presents Father Christmas as the personification of festive traditions pre-dating the puritan commonwealth. He is described as an elderly gentleman of cheerful appearance, "who when he came look't so smug and pleasant, his cherry cheeks appeared through his thin milk white locks, like (b)lushing Roses vail'd with snow white Tiffany". His character is associated with feasting, hospitality and generosity to the poor rather than the giving of gifts.
This tradition continued into the following centuries, with "Old Father Christmas" being evoked in 1734 in the pamphlet "Round About Our Coal Fire", as "Shewing what Hospitality was in former Times, and how little of it there remains at present", a rebuke to "stingy" gentry. A writer in "Time's Telescope" (1822) states that in Yorkshire at eight o'clock on Christmas Eve the bells greet "Old Father Christmas" with a merry peal, the children parade the streets with drums, trumpets, bells, (or in their absence, with the poker and shovel, taken from their humble cottage fire), the yule candle is lighted, and; "High on the cheerful fire. Is blazing seen th' enormous Christmas brand." A letter to "The Times" in 1825, warning against poultry-dealers dishonestly selling off sub-standard geese at Christmas time, is jokingly signed "Father Christmas".
In these early references, Father Christmas, although invariably an old and cheerful man, is mainly associated with adult feasting and drinking rather than the giving of presents. Since the mid-Victorian era however, Father Christmas has gradually merged with the pre-modern gift-giver St Nicholas (Dutch Sinterklaas, hence Santa Claus) and associated folklore. Nowadays in the UK, the figure is often called Santa Claus but also often referred to as Father Christmas: the two names are synonyms. In Europe, the figure is usually translated as Father Christmas ("Père Noël, Papá Noel, Padre Noel", etc.) rather than "Santa Claus" and is often said to reside in the mountains of Korvatunturi in Lapland Province, Finland.
Under the Marxist-Leninist doctrine of state atheism in the Soviet Union, after its foundation in 1917, Christmas celebrations—along with other religious holidays—were prohibited as a result of the Soviet antireligious campaign. The League of Militant Atheists encouraged school pupils to campaign against Christmas traditions, among them being Father Christmas and the Christmas tree, as well as other Christian holidays, including Easter; the League established an antireligious holiday to be the 31st of each month as a replacement. The winter holidays concentrated on New Year's Day and Father Christmas was replaced by Ded Moroz, who also brought gifts to the children. The Christmas tree was replaced by the Winter tree which was decorated similarly.
Current folklore.
Father Christmas often appears as a large man, often around seventy years old. He is dressed in a red suit trimmed with white fur, often girdled with a wide black belt, a matching hat or hood, often long and floppy in nature, and dark boots. Often he carries a large brown sack filled with toys on his back. It has been said that the red suit only appeared after the Coca Cola company started an advertising campaign depicting a red suited Father Christmas in the 1930s. However, the red suit was used long before, including by American illustrator Thomas Nast.
Father Christmas comes down the chimney to put presents under the Christmas tree or in children's rooms, in their stockings. Some families leave a glass of sherry or mulled wine, mince pies, biscuits, or chocolate and a carrot for his reindeer near the stocking(s) as a present for him. In modern homes without chimneys he uses alternative means to enter the home, such as a magical key that unlocks all doors. In some homes children write Christmas lists (of wished-for presents) and send them up the chimney or post them. He is often said to live at the North Pole.
In literature.
Father Christmas appears in many English-language works of fiction, including J. R. R. Tolkien's "Father Christmas Letters" (written between 1920 and 1942, first published in 1976), C. S. Lewis's "The Lion, the Witch and the Wardrobe" (1950), Raymond Briggs's "Father Christmas" (1973), Debbie Macomber's "There's Something About Christmas" (2005), Robin Jones Gunn's "Father Christmas Series" (2007), Catherine Spencer's "A Christmas to Remember" (2007), and Richard Paul Evans's "The Gift" (2007).

</doc>
<doc id="11563" url="http://en.wikipedia.org/wiki?curid=11563" title="Federal jurisdiction (United States)">
Federal jurisdiction (United States)

The United States of America is a federal republic governed by the U.S. Constitution containing fifty states and a federal district which elect the president, and having other territories and possessions in its national jurisdiction. This government is known as the Union, the United States, or the federal government. Federal jurisdiction refers to the legal scope of the government's powers. Under the Constitution and various treaties, the legal jurisdiction of the United States includes territories and territorial waters.
Legislative Branch.
One aspect of federal jurisdiction is the extent of legislative power. Under the Constitution, Congress has power to legislate only in the areas that are delegated to it. Under clause 17 however, Congress has power to "exercise exclusive Legislation in all cases whatsoever" over the federal district (Washington, D.C.) and other territory ceded to the federal government by the states, such as for military installations. 
Federal jurisdiction in this sense is important in criminal law because federal law does not supersede state criminal law. Congress has enacted the Assimilative Crimes Act ( ), which provides that any act that would have been a crime under the laws of the state in which a federal enclave is situated is also a federal crime. As most such enclaves are occupied by the military, military law is especially concerned with these enclaves, especially the issue of establishing who has jurisdiction and what type of jurisdiction. In such areas, the federal government may have proprietary jurisdiction (rights as landowner), concurrent jurisdiction (with federal and state law applicable), or exclusive jurisdiction over the land where an act was committed. Courts-martial involving military members subject to the Uniform Code of Military Justice apply regardless of location.
Article Four of the United States Constitution also states that the Congress has the power to enact laws "respecting the Territory or other Property belonging to the United States." Federal jurisdiction exists over any territory thus subject to laws enacted by the Congress.
Judicial branch.
The American legal system includes both state courts and federal courts. State courts hear cases involving state law, and such federal laws as are not restricted to hearing in federal courts. Federal courts may only hear cases where federal jurisdiction can be established. Specifically, the court must have both subject-matter jurisdiction over the matter of the claim and personal jurisdiction over the parties.
The Federal Courts are courts of limited jurisdiction, meaning that they only exercise powers granted to them by the Constitution and Federal Laws. There are several forms of subject-matter jurisdiction, but the two most commonly appealed to are federal-question jurisdiction and diversity jurisdiction. Federal question jurisdiction is available when the plaintiff raises a claim that arises under the laws, treaties, or Constitution of the United States, as opposed to claims arising under state law. By the "Well-Pleaded Complaint" rule, federal question jurisdiction is not available if the federal issue arises only as a defense to a state-law claim. Diversity jurisdiction, on the other hand, is available regarding state-law claims if every plaintiff is from a different state from every defendant (the requirement for so-called complete or total diversity) and the amount in controversy exceeds $75,000.
If a Federal Court has subject matter jurisdiction over one or more of the claims in a case, it has discretion to exercise ancillary jurisdiction over other state law claims. 
The Supreme Court has "cautioned that ... Court[s] must take great care to 'resist the temptation' to express preferences about [certain types of cases] in the form of jurisdictional rules. Judges must strain to remove the influence of the merits from their jurisdictional rules. The law of jurisdiction must remain apart from the world upon which it operates".
Generally, when a case has successfully overcome the hurdles of standing, Case or Controversy and State Action, it will be heard by a trial court. The non-governmental party may raise claims or defenses relating to alleged constitutional violation(s) by the government. If the non-governmental party loses, the constitutional issue may form part of the appeal. Eventually, a petition for certiorari may be sent to the Supreme Court. If the Supreme Court grants certiorari and accepts the case, it will receive written briefs from each side (and any amici curiae or friends of the court—usually interested third parties with some expertise to bear on the subject) and schedule oral arguments. The Justices will closely question both parties. When the Court renders its decision, it will generally do so in a single majority opinion and one or more dissenting opinions. Each opinion sets forth the facts, prior decisions, and legal reasoning behind the position taken. The majority opinion constitutes binding precedent on all lower courts; when faced with very similar facts, they are bound to apply the same reasoning or face reversal of their decision by a higher court.

</doc>
<doc id="11564" url="http://en.wikipedia.org/wiki?curid=11564" title="Fossil Record">
Fossil Record

Fossil Record is a biannual peer-reviewed scientific journal covering palaeontology. It was established in 1998 as the Mitteilungen aus dem Museum für Naturkunde in Berlin, Geowissenschaftliche Reihe and originally published on behalf of the Museum für Naturkunde by Wiley-VCH; since 2014 it has been published by Copernicus Publications. The editors-in-chief are Martin Aberhan, Dieter Korn, and Florian Witzmann (Museum für Naturkunde).
Abstracting and indexing.
The journal is abstracted and indexed in the Science Citation Index Expanded, BIOSIS Previews, The Zoological Record, and Scopus. According to the "Journal Citation Reports", the journal has a 2013 impact factor of 0.913.

</doc>
<doc id="11569" url="http://en.wikipedia.org/wiki?curid=11569" title="Frequency modulation synthesis">
Frequency modulation synthesis

In audio and music, frequency modulation synthesis (or FM synthesis) is a form of audio synthesis where the timbre of a simple waveform (such as a square, triangle, or sawtooth) is changed by modulating its frequency with a modulator frequency that is also in the audio range, resulting in a more complex waveform and a different-sounding tone that can also be described as "gritty" if it is a thick and dark timbre. The frequency of an oscillator is altered or distorted, "in accordance with the amplitude of a modulating signal." 
FM synthesis can create both harmonic and inharmonic sounds. For synthesizing harmonic sounds, the modulating signal must have a harmonic relationship to the original carrier signal. As the amount of frequency modulation increases, the sound grows progressively more complex. Through the use of modulators with frequencies that are non-integer multiples of the carrier signal (i.e. non harmonic), atonal and tonal bell-like and percussive sounds can easily be created.
FM synthesis using analog oscillators may result in pitch instability, however, FM synthesis can also be implemented digitally, the latter proving to be more 'reliable' and is currently seen as standard practice. As a result, digital FM synthesis (using the more frequency-stable phase modulation variant) was the basis of Yamaha's groundbreaking DX7, which brought FM to the forefront of synthesis in the mid-1980s.
History.
The technique of the digital implementation of frequency modulation, which was developed by John Chowning (, cited in ) at Stanford University in 1967-68, was patented in 1975 and later licensed to Yamaha.
The implementation commercialized by Yamaha ( or ) is actually based on phase modulation, but the results end up being equivalent mathematically, with phase modulation simply making the implementation resilient against undesirable drift in frequency of carrier waves due to self-modulation or due to DC bias in the modulating wave.
As noted earlier, FM synthesis was the basis of some of the early generations of digital synthesizers from Yamaha, with Yamaha's flagship DX7 synthesizer being ubiquitous throughout the 1980s and several other models by Yamaha providing variations and evolutions of FM synthesis.
Yamaha had patented its hardware implementation of FM in the 1980s, allowing it to nearly monopolize the market for that technology until the mid-1990s. Casio developed a related form of synthesis called phase distortion synthesis, used in its CZ range of synthesizers. It had a similar (but slightly differently derived) sound quality to the DX series. Don Buchla implemented FM on his instruments in the mid-1960s, prior to Yamaha's patent. His 158, 258 and 259 dual oscillator modules had a specific FM control voltage input, and the model 208 (Music Easel) had a modulation oscillator hard-wired to allow FM as well as AM of the primary oscillator. These early applications used analog oscillators, and this capability was also followed by other modular synthesizers and portable synthesizers including Minimoog and ARP Odyssey.
With the expiration of the Stanford University FM patent in 1995, digital FM synthesis can now be implemented freely by other manufacturers. The FM synthesis patent brought Stanford $20 million before it expired, making it (in 1994) "the second most lucrative licensing agreement in Stanford's history". FM today is mostly found in software-based synths such as FM8 by Native Instruments or Sytrus by Image-Line, but it has also been incorporated into the synthesis repertoire of some modern digital synthesizers, usually coexisting as an option alongside other methods of synthesis such as subtractive, sample-based synthesis, additive synthesis, and other techniques. The degree of complexity of the FM in such hardware synths may vary from simple 2-operator FM, to the highly flexible 6-operator engines of the Korg Kronos and Alesis Fusion, to creation of FM in extensively modular engines such as those in the latest synthesisers by Kurzweil Music Systems.
New hardware synths specifically marketed for their FM capabilities have not been seen since the Yamaha SY99 and FS1R, and even those marketed their highly powerful FM abilities as counterparts to sample-based synthesis and formant synthesis respectively. However, well-developed FM synthesis options are a feature of Nord Lead synths manufactured by Clavia, the Alesis Fusion range, and the Korg Oasys and Kronos. Various other synthesizers offer limited FM abilities to supplement their main engines.
Spectral analysis.
The spectrum generated by FM synthesis with one modulator is expressed as follows:
For modulation signal formula_1, the carrier signal is
If we were to ignore the constant phase terms on the carrier formula_3 and the modulator formula_4, finally we would get the following expression, as seen on and :
where formula_6 are angular frequencies (formula_7) of carrier and modulator, formula_8 is frequency modulation index, and amplitudes formula_9  is  formula_10-th , respectively.

</doc>
<doc id="11572" url="http://en.wikipedia.org/wiki?curid=11572" title="Font (disambiguation)">
Font (disambiguation)

Font may mean:

</doc>
<doc id="11574" url="http://en.wikipedia.org/wiki?curid=11574" title="Friedrich Bessel">
Friedrich Bessel

Friedrich Wilhelm Bessel (]; 22 July 1784 – 17 March 1846) was a German astronomer, mathematician (systematizer of the Bessel functions, which were discovered by Daniel Bernoulli). He was the first astronomer who determined reliable values for the distance from the sun to another star by the method of parallax.
Although he left school at the age of 14, he was appointed in January 1810 as director of the Königsberg Observatory by King Frederick William III of Prussia. On the recommendation of fellow mathematician and physicist Carl Gauss he was awarded an honorary doctor degree from the University of Göttingen in March 1811.
Bessel won the Gold Medal of the Royal Astronomical Society in 1829 and 1841. The asteroid 1552 Bessel was named in his honour.
Life and work.
Bessel was born in Minden, administrative center of Minden-Ravensberg, as second son of a civil servant. At the age of 14 Bessel was apprenticed to the import-export concern Kulenkamp at Bremen. The business's reliance on cargo ships led him to turn his mathematical skills to problems in navigation. This in turn led to an interest in astronomy as a way of determining longitude.
Bessel came to the attention of a major figure of German astronomy at the time, Heinrich Wilhelm Olbers, by producing a refinement on the orbital calculations for Halley's Comet in 1804, using old observation data taken from Thomas Harriot and Nathaniel Torporley in 1607.
Two years later Bessel left Kulenkamp and became Johann Hieronymus Schröter's assistant at Lilienthal Observatory near Bremen. There he worked on James Bradley's stellar observations to produce precise positions for some 3,222 stars.
In January 1810, at the age of 25, Bessel was appointed director of the new founded Königsberg Observatory by King Frederick William III of Prussia. There he published tables of atmospheric refraction derived from Bradley's observations, which won him the Lalande Prize from the French Academy of Sciences in 1811. While the observatory was still in construction Bessel elaborated the "Fundamenta Astronomiae" based on Bradley's observations.
The Königsberg Observatory began operation in 1813. Starting in 1819, Bessel determined the position of over 50,000 stars using a meridian circle from Reichenbach, assisted by some of his qualified students. The most prominent of them was Friedrich Wilhelm Argelander.
With this work under his belt, Bessel was able to achieve the feat for which he is best remembered today: he is credited with being the first to use parallax in calculating the distance to a star. Astronomers had believed for some time that parallax would provide the first accurate measurement of interstellar distances—in fact, in the 1830s there was a fierce competition between astronomers to be the first to measure a stellar parallax accurately. In 1838 Bessel won the race, announcing that 61 Cygni had a parallax of 0.314 arcseconds; which, given the diameter of the Earth's orbit, indicated that the star is 10.3 ly away. Given the current measurement of 11.4 ly, Bessel's figure had an error of 9.6%. Nearly at the same time Friedrich Georg Wilhelm Struve and Thomas Henderson measured the parallaxes of Vega and Alpha Centauri.
As well as helping determine the parallax of 61 Cygni, Bessel's precise measurements allowed him to notice deviations in the motions of Sirius and Procyon, which he deduced must be caused by the gravitational attraction of unseen companions.
His announcement of Sirius's "dark companion" in 1844 was the first correct claim of a previously unobserved companion by positional measurement, and eventually led to the discovery of Sirius B.
An additional responsibility of Bessel at Königsberg was geodesy.
Bessel published a method for solving the
geodesic problem;
he was responsible for the survey of East Prussia which joined the Prussian and Russian triangulation networks;
and he obtained an estimate of increased accuracy for the figure of the Earth,
nowadays referred to as the Bessel ellipsoid.
Despite lacking a university education, Bessel was a major figure in astronomy during his lifetime. He was elected a fellow of the Royal Society, a foreign member of the Royal Swedish Academy of Sciences in 1823, and the largest crater in the Moon's Mare Serenitatis is named Bessel after him. Bessel's work in 1840 contributed in some degree to the discovery of Neptune. In 1832, he was elected a Foreign Honorary Member of the American Academy of Arts and Sciences. Bessel won the Gold Medal of the Royal Astronomical Society in 1829 and 1841.
In the second decade of the 19th century while studying the dynamics of 'many-body' gravitational systems, Bessel developed what are now known as Bessel functions. Critical for the solution of certain differential equations, these functions are used throughout both classical and quantum physics. Even in the absence of any work in astronomy, Bessel's role in developing the functions which now bear his name would have, by itself, placed him among the most significant and influential mathematicians of the 19th century.
Bessel is responsible for the correction to the formula for the sample variance estimator named in his honour. This is the use of the factor "n-1" in the denominator of the formula, rather than just "n". This occurs when the "sample mean" rather than the "population mean" is used to centre the data and since the sample mean is a linear combination of the data the residual to the sample mean overcounts the number of degrees of freedom by the number of constraint equations — in this case one.
In 1842 Bessel took part in the annual meeting of the British Association for the Advancement of Science in Manchester, accompanied by the geophysicist Georg Adolf Erman and the mathematician Carl Gustav Jacob Jacobi.
After several months of illness Bessel died in March 1846 at his observatory from retroperitoneal fibrosis. This was several months short of the discovery of Neptune in the fall of that year, by his colleagues at Berlin Observatory.
Family.
Bessel married Johanna, the daughter of the chemist and pharmacist Karl Gottfried Hagen who was the uncle of the physician and biologist Hermann August Hagen and the hydraulic engineer Gotthilf Hagen, the latter also Bessel's student and assistant from 1816 to 1818.
Bessel had two sons and three daughters. His eldest daughter, Marie, married Georg Adolf Erman, member of the scholar family Erman. One of their sons was the renowned egyptologist Adolf Erman.

</doc>
<doc id="11577" url="http://en.wikipedia.org/wiki?curid=11577" title="FSB">
FSB

FSB may refer to:

</doc>
<doc id="11579" url="http://en.wikipedia.org/wiki?curid=11579" title="Fermi paradox">
Fermi paradox

The Fermi paradox (or Fermi's paradox) is the apparent contradiction between high estimates of the probability of the existence of extraterrestrial civilization and humanity's lack of contact with, or evidence for, such civilizations. The basic points of the argument, made by physicists Enrico Fermi and Michael H. Hart, are:
According to this line of thinking, the Earth should already have been colonized, or at least visited. But Fermi saw no convincing evidence of this, nor of signs of intelligence (see Empirical resolution attempts) elsewhere in our galaxy or (to the extent it would be detectable) elsewhere in the observable universe. Hence Fermi's question, "Where is everybody?"
Overview.
The age of the universe and its vast number of stars suggest that unless the Earth is very atypical, extraterrestrial life should be common. In an informal discussion in 1950, the physicist Enrico Fermi questioned why, if a multitude of advanced extraterrestrial civilizations exists in the Milky Way galaxy, evidence such as spacecraft or probes is not seen. A more detailed examination of the implications of the topic began with a paper by Michael H. Hart in 1975,
and it is sometimes referred to as the Fermi–Hart paradox. Other common names for the same phenomenon are "Fermi's question" ("Where are they?"), the "Fermi Problem", the "Great Silence", and "silentium universi" (Latin for "silence of the universe").
There have been attempts to resolve the Fermi paradox by locating evidence of extraterrestrial civilizations, along with proposals that such life could exist without human knowledge. Counterarguments suggest that intelligent extraterrestrial life does not exist or occurs so rarely or briefly that humans will never make contact with it.
Starting with Hart, a great deal of effort has gone into developing scientific hypotheses about, and possible models of, extraterrestrial life, and the Fermi paradox has become a theoretical reference point in much of this work. The problem has spawned numerous scholarly works addressing it directly, while questions that relate to it have been addressed in fields as diverse as astronomy, biology, ecology, and philosophy. The emerging field of astrobiology has brought an interdisciplinary approach to the Fermi paradox and the question of extraterrestrial life.
Basis.
The Fermi paradox is a conflict between an argument of scale and probability and a lack of evidence. A more complete definition could be stated thus:
The apparent size and age of the universe suggest that many technologically advanced extraterrestrial civilizations ought to exist. However, this hypothesis seems inconsistent with the lack of observational evidence to support it.
The first aspect of the paradox, "the argument by scale", is a function of the raw numbers involved: there are an estimated 200–400 billion (2–4 ×1011) stars in the Milky Way and 70 sextillion (7×1022) in the visible universe. Even if intelligent life occurs on only a minuscule percentage of planets around these stars, there might still be a great number of civilizations extant in the Milky Way galaxy alone. This argument also assumes the mediocrity principle, which is an argument from probability that we should not expect the Earth to be special, but merely a typical planet, subject to the same laws, effects, and likely outcomes as any other world.
The second cornerstone of the Fermi paradox is a rejoinder to the argument by scale: given intelligent life's ability to overcome scarcity, and its tendency to colonize new habitats, it seems likely that at least some civilizations would be technologically advanced, seek out new resources in space and then colonize first their own star system and subsequently the surrounding star systems. Since there is no conclusive or certifiable evidence on Earth or elsewhere in the known universe of other intelligent life after 13.8 billion years of the universe's history, we have the conflict requiring a resolution. Some examples of possible resolutions are that intelligent life is rarer than we think, that our assumptions about the general development or behavior of intelligent species are flawed, or, more radically, that our current scientific understanding of the nature of the universe or reality itself is seriously incomplete.
The Fermi paradox can be asked in two ways. The first is, "Why are no aliens or their artifacts physically here?" If interstellar travel is possible, even the "slow" kind nearly within the reach of Earth technology, then it would only take from 5 million to 50 million years to colonize the galaxy. This is a relatively small amount of time on a geological scale, let alone a cosmological one. Since there are many stars older than the Sun, or since intelligent life might have evolved earlier elsewhere, the question then becomes why the galaxy has not been colonized already. Even if colonization is impractical or undesirable to all alien civilizations, large-scale "exploration" of the galaxy is still possible using various means of exploration and theoretical probes. However, no signs of either colonization or exploration have been generally acknowledged.
Travel times may well explain the lack of physical presence on Earth of alien inhabitants of far away galaxies, but a sufficiently advanced civilization could potentially be observable over a significant fraction of the size of the observable universe. Even if such civilizations are rare, the scale argument indicates they should exist somewhere at some point during the history of the universe, and since they could be detected from far away over a considerable period of time, many more potential sites for their origin are within range of our observation. However, no incontrovertible signs of such civilizations have been detected.
It is unclear whether the paradox is stronger for our galaxy or for the universe as a whole.
Name.
In 1950, while working at Los Alamos National Laboratory, Fermi had a casual conversation while walking to lunch with colleagues Emil Konopinski, Edward Teller and Herbert York. The men discussed a recent spate of UFO reports and an Alan Dunn cartoon facetiously blaming the disappearance of municipal trashcans on marauding aliens. They then had a more serious discussion regarding the chances of humans observing faster-than-light travel by some material object within the next ten years. Teller thinks Fermi directed the question at him, asking "Edward, what do you think? How probable is it that within the next ten years we shall have clear evidence of a material object moving faster than light?" Teller answered one in a million. Teller remembers Fermi said, "This is much too low. The probability is more like ten percent" [the probability of a 'Fermi miracle']. Konopinski did not remember the exact numbers "except that they changed rapidly as Teller and Fermi bounced arguments off each other."
The conversation shifted to other subjects, until during lunch Fermi suddenly exclaimed, "Where are they?" (alternatively, "Where is everybody?"). Teller remembers, "The result of his question was general laughter because of the strange fact that in spite of Fermi's question coming from the clear blue, everybody around the table seemed to understand at once that he was talking about extraterrestrial life."
Edward Teller further remembers, "I do not believe that much came of this conversation, except perhaps a statement that the distances to the next location of living beings may be very great and that, indeed, as far as our galaxy is concerned, we are living somewhere in the sticks, far removed from the metropolitan area of the galactic center." Herbert York recollects that Fermi then made a series of rapid calculations using estimated figures. (Fermi was known for his ability to make good estimates from first principles and minimal data, see Fermi problem.) York writes that Enrico Fermi "followed up with a series of calculations on the probability of earth-like planets, the probability of life given an earth, the probability of humans given life, the likely rise and duration of high technology, and so on. He concluded on the basis of such calculations that we ought to have been visited long ago and many times over." If so, Fermi anticipated and pre-dated many of the elements that went into the Drake equation.
Alternative names.
Although Fermi's name is most commonly associated with the paradox, he was neither the first nor the last to ask the question.
An earlier implicit mention was by Konstantin Tsiolkovsky in an unpublished manuscript from 1933. He noted "people deny the presence of intelligent beings on the planets of the universe" because "(i) if such beings exist they would have visited Earth, and (ii) if such civilisations existed then they would have given us some sign of their existence." This was not a paradox for others, who took this to imply the absence of ETs, but it was for him, since he himself was a strong believer in extraterrestrial life and the possibility of space travel. Therefore he speculated that mankind is not yet ready for higher beings to contact us. That Tsiolkovsky himself may not have been the first to discover the paradox is suggested by his above-mentioned reference to other people's reasons for denying the existence of Extraterrestrial Civilisations (ETCs).
In addition, others re-discovered the paradox after Fermi, but before it was popularized. In 2002, Stephen Webb pointed out that "It has been independently discovered four times: it might more properly be called the Tsiolkovsky-Fermi-Viewing-Hart paradox."
Drake equation.
The theories and principles in the Drake equation are closely related to the Fermi paradox. The equation was formulated by Frank Drake in 1961, a decade after the objections raised by Enrico Fermi, in an attempt to find a systematic means to evaluate the numerous probabilities involved in the existence of alien life. The speculative equation factors in: the rate of star formation in the galaxy; the fraction of stars with planets and the number per star that are habitable; the fraction of those planets which develop life, the fraction of intelligent life, and the further fraction of detectable technological intelligent life; and finally the length of time such civilizations are detectable. The fundamental problem is that the last four terms (fraction of planets with life, odds life becomes intelligent, odds intelligent life becomes detectable, and detectable lifetime of civilizations) are completely unknown. We have only one example, rendering statistical estimates impossible, and even the example we have is subject to a strong anthropic bias.
A deeper objection is that the very form of the Drake equation assumes that civilizations arise and then die out within their original star systems. If interstellar colonization is possible, then this assumption is invalid, and the equations of population dynamics would apply instead.
The Drake equation has been used by both optimists and pessimists with wildly differing results. Carl Sagan, using optimistic numbers, suggested as many as one million communicating civilizations in the Milky Way in 1966, though he later suggested that the actual number could be far smaller. Frank Tipler and John D Barrow used pessimistic numbers and concluded that the average number of civilizations in a galaxy is much less than one. Frank Drake himself has commented that the Drake equation is unlikely to settle the Fermi paradox; instead it is just a way of "organizing our ignorance" on the subject.
Empirical resolution attempts.
One obvious way to resolve the Fermi paradox would be to find conclusive evidence of extraterrestrial intelligence. Efforts to find such evidence have been made since 1960, and several are ongoing. As human beings do not possess interstellar travel capability, such searches are being remotely carried out at great distances and rely on analysis of very subtle evidence. This limits possible discoveries to civilizations which alter their environment in a detectable way, or produce effects that are observable at a distance, such as radio emissions. It is very unlikely that non-technological civilizations will be detectable from Earth in the near future.
One difficulty in searching is avoiding an overly anthropocentric viewpoint. Conjecture on the type of evidence likely to be found often focuses on the types of activities that humans have performed, or likely would perform given more advanced technology. Intelligent aliens might avoid these "expected" activities, or perform activities dissimilar to those of humans.
Mainstream astronomy and SETI.
There are two ways that astronomy might find evidence of an extraterrestrial civilization. One is that conventional astronomers, studying stars, planets, and galaxies, might serendipitously observe some phenomenon that cannot be explained without positing an intelligent civilization as the source. This has been suspected several times. Pulsars, when first discovered, were called little green men (LGM), because of the precise repetition of their pulses (they rival the best atomic clocks). Likewise Seyfert galaxies were suspected to be "industrial accidents" because their enormous and directed energy output had no initial explanation. Eventually, natural explanations not involving intelligent life have been found for all such observations to date, but the possibility of discovery remains. Proposed examples include asteroid mining that would change the appearance of debris disks around stars, spectral lines from nuclear waste disposal in stars, or large-scale use of solar power changing the light curve of planets measured near eclipse.
The other way astronomy might settle the Fermi paradox is through a search specifically dedicated to finding evidence of life.
Radio emissions.
Radio technology and the ability to construct a radio telescope are presumed to be a natural advance for technological species, theoretically creating effects that might be detected over interstellar distances.
Sensitive observers of the Solar System, for example, would note unusually intense radio waves for a G2 star due to Earth's television and telecommunication broadcasts. In the absence of an apparent natural cause, alien observers might infer the existence of a terrestrial civilization. It should be noted however that even much more sensitive radio telescopes than those currently available on Earth would not be able to detect non-directional radio signals even at a fraction of a light year, so it is questionable whether any such signals could be detected by an extraterrestrial civilization.
Therefore, the careful searching of radio emissions from space for non-natural signals may lead to the detection of alien civilizations. Such signals could be either "accidental" by-products of a civilization, or deliberate attempts to communicate, such as the Communication with Extraterrestrial Intelligence's Arecibo message. A number of astronomers and observatories have attempted and are attempting to detect such evidence, mostly through the SETI organization, although other approaches, such as
optical SETI, also exist.
Several decades of SETI analysis have not revealed any main sequence stars with unusually bright or meaningfully repetitive radio emissions, although there have been several candidate signals. On August 15, 1977 the "Wow! signal" was picked up by The Big Ear radio telescope. However, the Big Ear only looked at each point on the sky for 72 seconds, and re-examinations of the same spot have found nothing. In 2003, Radio source SHGb02+14a was isolated by SETI@home analysis, although it has largely been discounted by further study. There are numerous technical assumptions underlying SETI that may cause human beings to miss radio emissions with present search techniques; these are discussed below.
Direct planetary observation.
Detection and classification of exoplanets has come out of recent refinements in mainstream astronomical instruments and analysis. While this is a new field in astronomy—the first published paper claiming to have discovered an exoplanet was released in 1989—it is possible that planets which are likely able to support life will be found in the near future.
Direct evidence for the existence of life may eventually be observable, such as the detection of biotic signature gases (such as methane and oxygen)—or even the industrial air pollution of a technologically advanced civilization—in an exoplanet's atmosphere by means of spectrographic analysis. With improvements in our observational capabilities, it may eventually even be possible to detect direct evidence such as that which humanity produces (see right).
However, exoplanets are rarely directly observed (the first claim to have done so was made in 2004); rather, their existence is usually inferred from the effects they have on the stars they orbit. This means that usually only the mass and orbit of an exoplanet can be deduced. This information, along with the stellar classification of its sun, and educated guesses as to its composition (usually based on the mass of the planet, and its distance from its sun), allows only for rough approximations of the planetary environment.
Prior to 2009, methods for exoplanet detection were not likely to detect life-bearing Earth-like worlds. Methods such as gravitational microlensing can detect the presence of "small" worlds, potentially even smaller than the Earth, but can only detect such worlds for very brief moments of time, and no follow-up is possible. Other methods such as radial velocity, astrometry, and the transit method allow prolonged observations of exoplanet effects, but only work with worlds that are many times the mass of Earth, at least when performed while looking through the atmosphere. These seem unlikely candidates to harbor Earth-like life. However, exoplanet detection and classification is a very active sub-discipline in astronomy, with 424 such planets being detected between 1988 and 2010, and the first possibly terrestrial planet discovered within a star's habitable zone being found in 2007. New refinements in exoplanet detection methods, and use of existing methods from space, (such as the Kepler Mission, launched in 2009) are starting to (as of 2014) detect and characterize terrestrial-size planets, and determine if they are within the habitable zones of their stars. Such observational refinements may allow us to better gauge how common potentially habitable worlds are. Using methods like the Drake equation with this data would therefore allow a much better idea of how common life in the universe might be; this would have a profound influence over the expectations behind the Fermi paradox itself.
Alien constructs.
Probes, colonies, and other artifacts.
As noted, given the size and age of the universe, and the relative rapidity at which dispersion of intelligent life can in principle occur, evidence of alien colonization attempts might plausibly be discovered. Evidence of exploration not containing extraterrestrial life, such as probes and information gathering devices, may also await discovery.
Some theoretical exploration techniques such as the Von Neumann probe (a self-replicating device) could exhaustively explore a galaxy the size of the Milky Way in as little as half a million years, with comparatively little investment in materials and energy relative to the results. If even a single civilization in the Milky Way attempted this, such probes could spread throughout the entire galaxy. Evidence of such probes might be found in the Solar System—perhaps in the asteroid belt where raw materials would be plentiful and easily accessed (not within a deep gravity well).
Another possibility for contact with an alien probe—one that would be trying to find human beings—is an alien Bracewell probe. Such a device would be an autonomous space probe whose purpose is to seek out and communicate with alien civilizations (as opposed to Von Neumann probes, which are usually described as purely exploratory). These were proposed as an alternative to carrying a slow speed-of-light dialogue between vastly distant neighbours. Rather than contending with the long delays a radio dialogue would suffer, a probe housing an artificial intelligence would seek out an alien civilization to carry on a close range communication with the discovered civilization. The findings of such a probe would still have to be transmitted to the home civilization at light speed, but an information-gathering dialogue could be conducted in real time.
Since the 1950s, direct exploration has been carried out on a small fraction (Freitas estimates 10−5 to 10−11) of the Solar System and no evidence that it has ever been visited by alien colonists, or probes, has been discovered. Detailed exploration of areas of the Solar System where resources would be plentiful—such as the asteroids, the Kuiper belt, the Oort cloud and the planetary ring systems—may yet produce evidence of alien exploration, though these regions are vast and difficult to investigate. There have been preliminary efforts in this direction in the form of the SETA (Search for Extraterrestrial Artifacts) and SETV (Search for Extraterrestrial Visitation) projects to search for extraterrestrial artifacts or other evidence of extraterrestrial visitation within the Solar System. There have also been attempts to signal, attract, or activate alleged Bracewell probes in Earth's local vicinity, including by scientists Robert Freitas and Francisco Valdes. Many of the projects that fall under this umbrella are considered "fringe" science by astronomers and none of the projects has located any artifacts.
Should alien artifacts be discovered, even here on Earth, they may not be recognizable as such. The products of an alien mind and an advanced alien technology might not be perceptible or recognizable as artificial constructs. Exploratory devices in the form of bio-engineered life forms created through synthetic biology would presumably disintegrate after a point, leaving no evidence; an alien information gathering system based on molecular nanotechnology could be all around us at this very moment, completely undetected. The same might be true of civilizations that actively hide their investigations from us, for possible reasons described further in this article. Also, Clarke's third law suggests that an alien civilization well in advance of humanity's might have means of investigation that are not yet conceivable to human beings.
Advanced stellar-scale artifacts.
In 1959, Freeman Dyson observed that every developing human civilization constantly increases its energy consumption, and, theoretically, a civilization of sufficient age would require "all" the energy produced by its star. The Dyson Sphere was the thought experiment that he derived as a solution: a shell or cloud of objects enclosing a star to harness as much radiant energy as possible. Such a feat of astroengineering would drastically alter the observed spectrum of the star involved, changing it at least partly from the normal emission lines of a natural stellar atmosphere to that of a black body radiation, probably with a peak in the infrared. Dyson himself speculated that advanced alien civilizations might be detected by examining the spectra of stars and searching for such an altered spectrum.
Since then, several other theoretical stellar-scale megastructures have been proposed, but the central idea remains that a highly advanced civilization—Type II or greater on the Kardashev scale—could alter its environment enough so as to be detectable from interstellar distances.
However, such constructs may be more difficult to detect than originally thought. Dyson spheres might have different emission spectra depending on the desired internal environment; life based on high-temperature reactions may require a high temperature environment, with resulting "waste radiation" in the visible spectrum, not the infrared. Additionally, a variant of the Dyson sphere has been proposed which would be difficult to observe from any great distance; a Matrioshka brain is a series of concentric spheres, each radiating less energy per area than its inner neighbour. The outermost sphere of such a structure could be close to the temperature of the interstellar background radiation, and thus be all but invisible.
There have been some preliminary attempts to find evidence of the existence of Dyson spheres or other large Type-II or Type-III Kardashev scale artifacts that would alter the spectra of their core stars. These surveys have not located anything yet, though they are still incomplete. Similarly, direct observation of thousands of galaxies has shown no explicit evidence of artificial construction or modifications.
Explaining the paradox hypothetically.
Certain theoreticians accept that the apparent absence of evidence implies the absence of extraterrestrials and attempt to explain why. Others offer possible frameworks in which the silence may be explained without ruling out the possibility of such life, including assumptions about extraterrestrial behaviour and technology. Each of these hypothesized explanations is essentially an argument for decreasing the value of one or more of the terms in the Drake equation. The arguments are not, in general, mutually exclusive. For example, it could be both that life is rare and that technical civilizations are short lived, or many other combinations of the explanations below.
Few, if any, other civilizations currently exist.
One explanation is that the human civilization "is" alone (or very nearly so) in the galaxy. Several theories along these lines have been proposed, explaining why intelligent life might be either very rare, or very short lived. Implications of these hypotheses are examined as the Great Filter.
No other civilizations have arisen.
Those who believe that extraterrestrial intelligent life does not exist argue that the conditions needed for life—or at least complex life—to evolve are rare or even unique to Earth. This is known as the "Rare Earth" hypothesis, which attempts to resolve the Fermi paradox by rejecting the mediocrity principle, and asserting that Earth is not typical, but unusual or even unique. While a unique Earth has historically been assumed on philosophical or religious grounds, the Rare Earth Hypothesis uses quantifiable and statistical arguments to argue that multicellular life is exceedingly rare in the universe because Earth-like planets are themselves exceedingly rare or many improbable coincidences have converged to make complex life on Earth possible. It is possible that complex life may evolve through other mechanisms than those found specifically here on Earth, but the fact that in the history of life on the Earth only one species has developed a civilization to the point of being capable of space flight and radio technology lends more credence to the idea of technologically advanced civilizations being rare in the universe.
For example, the emergence of intelligence may have been an evolutionary accident. Geoffrey Miller proposes that human intelligence is the result of runaway sexual selection, which takes unpredictable directions. Steven Pinker, in his book "How the Mind Works", cautions that the idea that evolution of life (once it has reached a certain minimum complexity) is bound to produce intelligent beings relies on the fallacy of the "ladder of evolution": Since evolution does not strive for a goal but just happens, it uses the adaptation most useful for a given ecological niche, and the fact that, on Earth, this led to technological intelligence only once so far may suggest that this outcome of natural selection is rare and hence by no means a certain development of the evolution of a tree of life.
Another hypothesis along these lines is that, even if conditions needed for life are common in the universe, the initial abiogenesis on a potentially life-bearing planet – the formation of life itself – the existence of a complex array of molecules that are simultaneously capable of reproduction, extraction of base components from the environment, and obtaining energy in a form that can be used to maintain the reaction, might ultimately be very rare.
Additionally, in the non-directional meandering from initial life to humans, other low-probability happenings may have been the transition from prokaryotic cells to eukaryotic cells (with separate nucleus, organelles, specialization, and a cytoskeleton allowing the cell to take on various shapes) and the transition from single-cellular life to multicellular life, which was recorded in the Cambrian Explosion of 530 million years ago when significant numbers of organisms evolved hard body parts, although multicellular life perhaps first started to evolve a couple of hundred million years before that. Single celled life emerged c. 3.5 billion years ago, and for most of Earth's history and for reasons not fully understood there have only been single-celled creatures. And even fundamental conditions such as the chemical composition of the nursery nebula from which a planetary system forms could have unusual or detrimental consequences for the emergence and survival of life.
And there are many other potential branching points. For example, perhaps the transition from ocean creatures to land-dwelling creatures crucially depends on an unusually large moon. Many astronomers refer to our Earth-Moon pairing as a double planet. This ratio between parent and satellite is rare in our planetary system. There is no observational data on the numbers of "double planets" in other planetary systems. The size of Earth's moon has several consequences that could be advantageous to the development of life:
It is also possible that intelligence is common, but industrial civilization is not. For example, the rise of industrialism on Earth was driven by the presence of convenient energy sources such as fossil fuels. If such energy sources are rare or nonexistent elsewhere, then it may be far more difficult for an intelligent alien race to advance technologically to the point where humans could communicate with it. There may also be other unique factors on which our civilization is dependent. For example, in a planet covered with water, where intelligent life takes the form of creatures similar to dolphins, it may be difficult or impossible to discover fire or forge metals.
Another possibility is that Earth is the first planet in the Milky Way on which industrial civilization can arise. However, critics note that, according to current understanding, many Earth-like planets were created many billions of years prior to Earth, so this explanation requires repudiation of the mediocrity principle.
Insofar as the Rare Earth Hypothesis privileges life on Earth and its process of formation, it is a variant of the anthropic principle. The variant of the anthropic principle states the universe seems uniquely suited towards developing human intelligence. This philosophical stance opposes not only the mediocrity principle, but also the wider Copernican principle, which suggests there is no privileged location in the universe.
Opponents dismiss both Rare Earth and the anthropic principle as tautological—if a condition must exist in the universe for human life to arise, then the universe must already meet that condition, as human life exists—and as an argument from incredulity or lack of imagination. According to this analysis, the Rare Earth hypothesis confuses a description of how life on Earth arose with a uniform conclusion of how life "must" arise. While the probability of the specific conditions on Earth being widely replicated is low, we do not know what complex life may require in order to evolve.
It is the nature of intelligent life to destroy itself.
This is the argument that technological civilizations may usually or invariably destroy themselves before or shortly after developing radio or space flight technology. Possible means of annihilation include nuclear war, biological warfare or accidental contamination, climate change, nanotechnological catastrophe, ill-advised physics experiments, a badly programmed super-intelligence, or a Malthusian catastrophe after the deterioration of a planet's ecosphere. This general theme is explored both in fiction and in mainstream scientific hypothesizing. Indeed, there are probabilistic arguments which suggest that human extinction may occur sooner rather than later. In 1966, Sagan and Shklovskii speculated that technological civilizations will either tend to destroy themselves within a century of developing interstellar communicative capability or master their self-destructive tendencies and survive for billion-year timescales. Self-annihilation may also be viewed in terms of thermodynamics: insofar as life is an ordered system that can sustain itself against the tendency to disorder, the "external transmission" or interstellar communicative phase may be the point at which the system becomes unstable and self-destructs.
From a Darwinian perspective, self-destruction would be an ironic outcome of evolutionary success. The evolutionary psychology that developed during the competition for scarce resources over the course of human evolution has left the species subject to aggressive, instinctual drives. These compel humanity to consume resources, extend longevity, and to reproduce—in part, the very motives that led to the development of technological society. It seems likely that intelligent extraterrestrial life would evolve in a similar fashion and thus face the same possibility of self-destruction. And yet, to provide a good answer to Fermi's Question, self-destruction by technological species (or "any" sociological explanation) would have to be a near universal occurrence. Otherwise, the few civilizations to which it does not apply would colonize the galaxy.
This argument does not require the civilization to entirely self-destruct, only to become once again non-technological. In other ways it could persist and even thrive according to evolutionary standards, which postulate producing offspring as the sole goal of life—not "progress", be it in terms of technology or even intelligence.
It is the nature of intelligent life to destroy others.
Another possibility is that an intelligent species beyond a certain point of technological capability will destroy other intelligence as it appears, as is exemplified by the theorised extermination of Neanderthals by early humans. The idea that something, or someone, is destroying intelligent life in the universe has been well explored in science fiction and scientific literature. A species might undertake such extermination out of expansionist motives, paranoia, or simple aggression. In 1981, cosmologist Edward Harrison argued that such behavior would be an act of prudence: an intelligent species that has overcome its own self-destructive tendencies might view any other species bent on galactic expansion as a kind of virus. It has also been suggested that a successful alien species would be a superpredator, as is "Homo sapiens".
This hypothesis requires at least one civilization to have arisen in the past, and the first civilization would not have faced this problem. However, it could still be that Earth is alone now. Like exploration, the extermination of other civilizations might be carried out with self-replicating spacecraft. Under such a scenario, even if a civilization that created such machines were to disappear, the probes could outlive their creators, destroying civilizations far into the future.
This scenario reduces the number of visible civilizations in two ways, by destroying some civilizations, and by forcing others to remain quiet, under fear of discovery so we would see no signs of them, making their lack of interaction a choice. This may also make it impossible for life to evolve in regions of the universe close to a developed civilization, assuring that any new civilizations will start off far away from preexisting ones.
Life is periodically destroyed by naturally occurring events.
On Earth, there have been numerous major extinction events that destroyed the majority of complex species alive at the time. The extinction of the dinosaurs is the best known example. These are believed to be caused by events such as impact from a large meteorite, massive volcanic eruptions, or astronomical events such as gamma ray bursts. It may be the case that such extinction events are common throughout the universe and periodically destroy intelligent life (or at least destroy their civilizations) before the species is able to develop the technology to communicate with other species.
Inflation hypothesis and the youngness argument.
Cosmologist Alan Guth proposed a multi-verse solution to the Fermi paradox. In this scenario, using the synchronous gauge probability distribution, young universes exceedingly outnumber older ones (by a factor of e1037 for every second of age). Therefore, averaged over all universes, universes with civilizations will almost always have just one, the first to develop. However, Guth notes "Perhaps this argument explains why SETI has not found any signals from alien civilizations, but I ﬁnd it more plausible that it is merely a symptom that the synchronous gauge probability distribution is not the right one."
They do exist, but we see no evidence.
It may be that technological extraterrestrial civilizations exist but that human beings cannot communicate with them because of constraints such as problems of scale or technology. Perhaps their nature is too alien for meaningful communication or their methods of communication are too alien to even be recognized as technology. Even on our own planet, there are immense differences between a blue whale and a common ant. The differences may be even greater between human beings and members of extraterrestrial civilizations. Perhaps, also, they may not wish to communicate with us.
Communication is improbable due to problems of scale.
Intelligent civilizations are too far apart in space or time.
It may be that non-colonizing technologically capable alien civilizations exist, but that they are simply too far apart for meaningful two-way communication. If two civilizations are separated by several thousand light years, it is very possible that one or both cultures may become extinct before meaningful dialogue can be established. Human searches may be able to detect their existence, but communication will remain impossible because of distance. This problem might be ameliorated somewhat if contact/communication is made through a Bracewell probe. In this case at least one partner in the exchange may obtain meaningful information. Alternatively, a civilization may simply broadcast its knowledge, and leave it to the receiver to make what they may of it. This is similar to the transmission of information from ancient civilizations to the present, and humanity has undertaken similar activities like the Arecibo message, which could transfer information about Earth's intelligent species, even if it never yields a response (or does not yield a response in time for humanity to receive it). It is also possible that archaeological evidence of past civilizations may be detected through deep space observations—especially if they left behind large artifacts such as Dyson spheres.
The problem of distance is compounded by the fact that timescales affording a "window of opportunity" for detection or contact might be quite small. Advanced civilizations may periodically arise and fall throughout our galaxy, but this may be such a rare event, relatively speaking, that the odds of two or more such civilizations existing at the same time are low. There may have been intelligent civilizations in the galaxy before the emergence of intelligence on Earth, and there may be intelligent civilizations after its extinction, but it is possible that human beings are the only intelligent civilization in existence "now". The term "now" is somewhat complicated by the finite speed of light and the nature of spacetime under relativity. Assuming that an extraterrestrial intelligence is not able to travel to our vicinity at faster-than-light speeds, in order to detect an intelligence 1,000 light-years distant, that intelligence will need to have been active 1,000 years ago. Strictly speaking, only the portions of the universe lying within the past light cone of Earth need be considered, since any civilizations outside it could not be detected. Another issue is the possibly very small length of time (even in historical timescales) that a civilization might be "loudly" broadcasting material that could be reasonably detected (see below).
A related argument holds that other civilizations exist, and are transmitting and exploring, but their signals and probes simply have not arrived yet. However, critics have noted that this is unlikely, since it requires that humanity's advancement has occurred at a very special point in time, while the Milky Way is in transition from empty to full. This is a tiny fraction of the life of a galaxy under ordinary assumptions and calculations resulting from them, so the likelihood that we're in the midst of this transition is considered low in the paradox. Work on the theory of neocatastrophism, wherein galactic and even super-galactic dynamics are seen as possibly frequently injurious to extant biospheres in a way that is roughly analogous to the way geological and climatological catastrophes have occasionally set back biological developments on Earth, might be given as a partial, if not full, resolution to the paradox, as advanced species might well be fragile to major events at a pace that would argue against a short transition.
It is too expensive to spread physically throughout the galaxy.
Many assumptions about the ability of an alien culture to colonize other stars are based on the idea that interstellar travel is technologically feasible. While the current understanding of physics rules out the possibility of faster than light travel (apart from such theoretical concepts as the Alcubierre drive), it appears that there are no major theoretical barriers to the construction of "slow" interstellar ships, even though the engineering required is considerably beyond present capabilities. This idea underlies the concept of the Von Neumann probe and the Bracewell probe as evidence of extraterrestrial intelligence.
It is possible, however, that present scientific knowledge cannot properly gauge the feasibility and costs of such interstellar colonization. Theoretical barriers may not yet be understood and the cost of materials and energy for such ventures may be so high as to make it unlikely that any civilization could afford to attempt it. Even if interstellar travel and colonization are possible, they may be difficult, leading to a colonization model based on percolation theory. Colonization efforts may not occur as an unstoppable rush, but rather as an uneven tendency to "percolate" outwards, within an eventual slowing and termination of the effort given the enormous costs involved and the fact that colonies will inevitably develop a culture and civilization of their own. Colonization may thus occur in "clusters," with large areas remaining uncolonized at any one time.
A similar argument holds that interstellar physical travel may be possible, but is much more expensive than interstellar communication. Furthermore, to an advanced civilization, travel itself may be replaced by communication, through mind uploading and similar technologies. Therefore the first civilization may have physically explored or colonized the galaxy, but subsequent civilizations find it cheaper, faster, and easier to get information through contacting existing civilizations rather than physically exploring or traveling themselves. In this scenario, since there is little or no physical travel, and directed communications are hard to see except to the intended receiver, there could be many technical and interacting civilizations with few signs visible across interstellar distances.
Another economic argument is that although advanced virtual civilizations — possibly en route developmentally to a Matrioshka Brain — could engage in travel to other star systems, they choose not to. This is not due to a lack of curiosity, but more through a set of energy-information economic choices, whereby in an information market predicated on available stellar energy and planetary matter for building more computing capacity, the most successful virtual intelligences have to remain central to the star. Energy and proximity (and therefore wireless communication bandwidth and speed) are much greater closer to the matter and energy sources of the star, and larger planets, and so to be successful requires focus on their home planetary system. In this scenario, economic incentives to travel out of a star system are inhibited.
Human beings have not been searching long enough.
Humanity's ability to detect and comprehend intelligent extraterrestrial life has existed for only a very brief period—from 1937 onwards, if the invention of the radio telescope is taken as the dividing line—and "Homo sapiens" is a geologically recent species. The whole period of modern human existence to date (about 200,000 years) is a very brief period on a cosmological scale, while radio transmissions have only been propagated since 1895. Thus it remains possible that human beings have neither been searching long enough to find other intelligences, nor been in existence long enough to be found.
One million years ago there would have been no humans for any extraterrestrial emissaries to meet. For each further step back in time, there would have been increasingly fewer indications to such emissaries that intelligent life would develop on Earth. In a large and already ancient universe, a space-faring alien species may well have had many other more promising worlds to visit and revisit. Even if alien emissaries visited in more recent times, they may have been interpreted by early human cultures as supernatural entities.
This hypothesis is more plausible if alien civilizations tend to stagnate or die out, rather than expand. In addition, "the probability of a site never being visited, even [with an] infinite time limit, is a non-zero value." Thus, even if intelligent life expands elsewhere, it remains statistically possible that such extraterrestrial life might never discover Earth.
Communication is improbable for technical reasons.
Radio wave communication may be realistically impossible, as waves of the electromagnetic variety that we use to communicate appear to be the fastest moving waves, and the only kind that can move through a vacuum, but would still take thousands of years or more to reach the receiving end. Another possibility is that extraterrestrials may use a form of communication that our devices can't detect, or simply are made not to.
Humans are not listening properly.
There are some assumptions that underlie the SETI search programs that may cause searchers to miss signals that are present. For example, the radio searches to date would completely miss highly compressed data streams (which would be almost indistinguishable from "white noise" to anyone who did not understand the compression algorithm). Extraterrestrials might also use frequencies that scientists have decided are unlikely to carry signals, or do not penetrate our atmosphere (e.g., gamma rays), or use modulation strategies that are not being looked for. The signals might be at a data rate that is too fast for our electronics to handle, or too slow to be recognized as attempts at communication. "Simple" broadcast techniques might be employed, but sent from non-main sequence stars which are searched with lower priority; current programs assume that most alien life will be orbiting Sun-like stars.
The greatest problem is the sheer size of the radio search needed to look for signals (effectively spanning the entire visible universe), the limited amount of resources committed to SETI, and the sensitivity of modern instruments. SETI estimates, for instance, that with a radio telescope as sensitive as the Arecibo Observatory, Earth's television and radio broadcasts would only be detectable at distances up to 0.3 light years. Clearly detecting an Earth type civilization at great distances is difficult. A signal is much easier to detect if the signal energy is limited to either a narrow range of frequencies (narrowband transmissions), or directed at a specific part of the sky. Such signals can be detected at ranges of hundreds to tens of thousands of light-years distance. However this means that detectors must be listening to an appropriate range of frequencies, and be in that region of space to which the beam is being sent. Many SETI searches, starting with the venerable Project Cyclops, go so far as to assume that extraterrestrial civilizations will be broadcasting a deliberate signal (like the Arecibo message), in order to be found.
Thus to detect alien civilizations through their radio emissions, Earth observers either need more sensitive instruments or must hope for fortunate circumstances: that the broadband radio emissions of alien radio technology are much stronger than our own (e.g., gamma-ray bursts); that one of SETI's programs is listening to the correct frequencies from the right regions of space; or that aliens are sending focused transmissions such as the Arecibo message in our general direction.
Aliens aren't monitoring Earth because Earth is not superhabitable.
The Milky Way contains billions of worlds that may support life. Listening for radio signals from all planets may be too complex, or may require too many separate telescopes and monitoring devices. If that is the case, aliens may focus on superhabitable planets, and ignore marginally habitable planets such as the Earth.
Civilizations broadcast detectable radio signals only for a brief period of time.
It may be that alien civilizations are detectable through their radio emissions for only a short time, reducing the likelihood of spotting them. There are two possibilities in this regard: civilizations outgrow radio through technological advance or, conversely, resource depletion cuts short the time in which a species broadcasts.
The first idea, that civilizations advance beyond radio, is based in part on the "fiber optic objection": the use of high power radio with low-to-medium gain (i.e., non-directional) antennas for long-distance transmission is wasteful of spectrum, yet this "waste" is precisely what makes these systems conspicuous at interstellar distances. Humans are moving to directional or guided transmission channels such as electrical cables, optical fibers, narrow-beam microwave and lasers, and conventional radio with non-directional antennas is increasingly reserved for low-power, short-range applications such as cell phones and Wi-Fi networks. These signals are far less detectable from space. Analog television, developed in the mid-20th century, contains strong carriers to aid reception and demodulation. Carriers are spectral lines that are very easily detected yet do not convey any information beyond their highly artificial nature. Nearly every SETI project is looking for carriers for just this reason, and UHF TV carriers are the most conspicuous and artificial signals from Earth that could be detected at interstellar distances. But advances in technology are replacing analog TV with digital television which uses spectrum more efficiently by eliminating or reducing components such as carriers that make them so conspicuous. Using our own experience as an example, we could set the date of radio-visibility for Earth as December 12, 1901, when Guglielmo Marconi sent radio signals from Cornwall, England, to Newfoundland, Canada. Visibility is now ending, or at least becoming orders of magnitude more difficult, as analog TV is being phased out. And so, if our experience is typical, a civilization remains radio-visible for approximately a hundred years. So a civilization may have been very visible from 1325 to 1483, but we were just not listening at that time. This is essentially the solution, "Everyone is listening, no one is sending."
More hypothetically, advanced alien civilizations evolve beyond broadcasting at all in the electromagnetic spectrum and communicate by principles of physics we don't yet understand. Some scientists have hypothesized that advanced civilizations may send neutrino signals. If such signals exist they could be detectable by neutrino detectors that are now under construction. If stable wormholes could be created and used for communications then interstellar broadcasts would become largely redundant. Thus it may be that other civilizations would only be detectable for a relatively short period of time between the discovery of radio and the switch to more efficient technologies.
One counter to this argument is that although broadcast communication may become difficult to detect, other uses for radio such as radar and power transmission cannot be replaced by low power technologies or fiber optics. These will potentially remain visible even after broadcast emission are replaced by less observable technology.
A different argument is that resource depletion will soon result in a decline in technological capability. Human civilization has been capable of interstellar radio communication for only a few decades and is already rapidly depleting fossil fuels and confronting possible problems such as peak oil. It may only be a few more decades before energy becomes too expensive, and the necessary electronics and computers too difficult to manufacture, for us to continue the search. If the same conditions regarding energy supplies hold true for other civilizations, then radio technology may be a short-lived phenomenon. Unless two civilizations happen to be near each other and develop the ability to communicate at the same time it would be virtually impossible for any one civilization to "talk" to another.
Critics of the resource depletion argument point out that alternate energy sources exist, such as solar power, which are renewable and have enormous potential relative to technical barriers. For depletion of fossil fuels to end the "technological phase" of a civilization, some form of technological regression would have to invariably occur, preventing the exploitation of renewable energy sources.
They tend to experience a technological singularity.
Another possibility is that technological civilizations invariably experience a technological singularity and attain a posthuman (or more properly, post-biological) character. Hypothetical civilizations of this sort may have advanced drastically enough to render communication impossible. The intelligences of a post-singularity civilization might require more information exchange than is possible through interstellar communication, for example. Or perhaps any information humanity might provide would appear elementary, and thus they do not try to communicate, any more than human beings attempt to talk to ants—even though we do ascribe a form of intelligence to them. For example, a superintelligent civilization might consist of an advanced megastructure such as a Matrioshka brain or a black hole and communicate using neutrinos or by gamma-ray bursts at bandwidths that exceed our receiving capabilities.
Even more extreme forms of post-singularity have been suggested, particularly in fiction: beings that divest themselves of physical form, create massive artificial virtual environments, transfer themselves into these environments through mind uploading, and exist totally within virtual worlds, ignoring the external physical universe. Surprisingly early treatments, such as Lewis Padgett's short story "Mimsy were the Borogoves" (1943), suggest a migration of advanced beings out of the presently known physical universe into a different and presumably more agreeable alternative one.
The transcension hypothesis of singularity scholar John Smart proposes that the evolutionary development of accelerating change may require complex systems to inhabit increasingly local domains of space and time, leading post-singularity civilizations to black-hole-like domains, and nonlocal access to other universal intelligence. A powerful ethical injunction against sending self-replicating probes or broadcasting messages prior to transcension might emerge if such one-way messaging would provably reduce the evolutionary diversity of all civilizations receiving the messages, as they would no longer transcend in their own unique way. Smart proposes tests of the hypothesis via future high-sensitivity radio and optical SETI searches, including regular ending of passive EM signals from Earth-like planets once they reach their technological singularities, and later optical transition of these planets to black-hole-like objects.
They are too busy online.
It may be that intelligent alien life forms cause their own "increasing disinterest" in the outside world. Perhaps any sufficiently advanced society will develop highly engaging media and entertainment well before the capacity for advanced space travel, and that the rate of appeal of these social contrivances is destined, because of their inherent reduced complexity, to overtake any desire for complex, expensive endeavors such as space exploration and communication. Once any sufficiently advanced civilization becomes able to master its environment, and most of its physical needs are met through technology, various "social and entertainment technologies", including virtual reality, are postulated to become the primary drivers and motivations of that civilization.
They are too alien.
Another possibility is that human theoreticians have underestimated how much alien life might differ from that on Earth. Aliens may be psychologically unwilling to attempt to communicate with human beings. Perhaps human mathematics is parochial to Earth and not shared by other life, though others argue this can only apply to abstract math since the math associated with physics must be similar (in results, if not in methods.)
Physiology might also cause a communication barrier. In "Contact", Carl Sagan briefly speculated that an alien species might have a thought process orders of magnitude slower (or faster) than humans. Such a species could conceivably speak so slowly that it requires years to say even a simple phrase like "Hello". A message broadcast by that species might well seem like random background noise to humans, and therefore go undetected.
They are non-technological.
It may be that at least some civilizations of intelligent beings are not technological, perhaps because it is difficult in their environment, or because they choose not to, or for other reasons yet unknown. Such civilizations would be very hard for humans to detect. While there are remote sensing techniques which could perhaps detect life-bearing planets without relying on the signs of technology, none of them has any ability to tell if any detected life is intelligent. Not even any theoretical methods for doing so have been proposed, short of an actual physical visit by an astronaut or probe. This is sometimes referred to as the "algae vs. alumnae" problem.
The evidence is being suppressed.
It is theoretically possible that SETI groups are not reporting positive detections, or governments have been blocking extraterrestrial signals or suppressing publication of detections. This response might be attributed to National Security and Trade Interests from the potential use of advanced extraterrestrial technology or weapons. It has been suggested that the detection of an extraterrestrial radio signal or technology could well be the most highly classified military information that exists. Claims that this has already happened are common in the popular press, but the scientists involved report the opposite experience – the press becomes informed and interested in a potential detection even before a signal can be confirmed. Another issue is the diverse number of organisations and governments involved in science activities that might chance upon detections, of which SETI forms only a small part. Numerous conspiracy theories have been proposed, including the possibility of extraterrestrial life at Area 51.
They choose not to interact with us.
In these scenarios, alien civilizations exist that are technically capable of contacting Earth, but explicitly choose not to do so.
This is the official position of the Earth today; we listen (SETI), but except for a few small efforts, do not explicitly transmit.
Of course if all, or even most, civilizations act the same way, the galaxy could be full of civilizations eager for contact, but everyone is listening and no one is transmitting. This is the so-called "SETI Paradox".
They don't agree among themselves.
Official policy within SETI community is that "[no] response to a signal or other evidence of extraterrestrial intelligence should be sent until appropriate international consultations have taken place." However, given the possible impact of any reply it may be very difficult to obtain any consensus on "Who speaks for Earth?" and "What should we say?" Other civilizations might suffer from this same lack of consensus, and therefore send no messages at all.
Earth is deliberately not contacted (the zoo hypothesis).
The zoo hypothesis states that superintelligent extraterrestrial life exists and does not contact life on Earth to allow for its natural evolution and development.
These ideas are perhaps most plausible if there is a relatively universal cultural or legal policy among a plurality of extraterrestrial civilizations necessitating isolation with respect to alien life. In a Universe without a hegemonic power, random civilizations with independent principles would, in all likelihood, make contact. This makes a crowded Universe with clearly defined rules seem more plausible.
This theory may break down under the uniformity of motive flaw: all it takes is a single culture or civilization to decide to act contrary to the imperative within our range of detection for it to be abrogated, and the probability of such a violation increases with the number of civilizations. However, perhaps a sufficiently technologically and socially advanced civilization would be capable of enforcing rules.
T. W. Hair has done Monte Carlo analysis of the inter-arrival times between civilizations in the galaxy based on common astrobiological assumptions that suggest that since the initial civilization would have such a commanding lead over the later arrivals, it may have established what we call "zoo hypothesis" as a galactic/universal norm and the resultant "paradox" by a cultural founder effect with or without the continued activity of the founder.
In the fictional works of "Star Trek", the Prime Directive prohibits contact with a species until they develop interstellar travel technology in order to minimize influencing their cultural development.
Earth is purposely isolated (planetarium hypothesis).
A related idea is that, beyond a certain distance, the perceived universe is a simulated reality. The planetarium hypothesis holds that beings may have created this simulation so that the universe appears to be empty of other life.
It is dangerous to communicate.
An alien civilization might feel it is too dangerous to communicate, either for us or for them. After all, when very different civilizations have met on Earth, the results have often been disastrous for one side or the other, and the same may well apply to interstellar contact. Even contact at a safe distance could lead to infection by computer code or even ideas themselves.
Perhaps prudent civilizations actively hide not only from us but from everyone, out of fear of other civilizations.
The Fermi paradox itself is what prevents communication.
Perhaps the Fermi paradox itself—or the alien equivalent of it—is the ultimate reason for any civilization to avoid contact with other civilizations, even if no other obstacles existed. From any one civilization's point of view, it would be unlikely for them to be the first ones to make first contact. Therefore it is likely that previous civilizations faced fatal problems with first contact. So perhaps every civilization keeps quiet because of the possibility that there is a real reason for others to do so.
They are here unobserved.
It may be that intelligent alien life forms not only exist, but are already present here on Earth. They are not detected because they do not wish it, human beings are technically unable to, or because societies refuse to admit to the evidence. Several variations of this idea have been proposed:
Carl Sagan and Iosif Shklovsky argued for serious consideration of "paleocontact" with extraterrestrials in the early historical era, and for examination of myths and religious lore for evidence of such contact. Sagan and Shklovsky noted that many or most religions were founded by men who claimed contact with supernatural entities who bestowed wisdom, guidance and technology, citing the fish-god Oannes as a particularly salient example.
It is possible that a life form technologically advanced enough to travel to Earth might also be sufficiently advanced to exist here undetected. In this view, the aliens have arrived on Earth, or in our solar system, and are observing the planet, while concealing their presence. Observation could conceivably be conducted in a number of ways that would be very difficult to detect. For example, a complex system of microscopic monitoring devices constructed via molecular nanotechnology could be deployed on Earth and remain undetected, or sophisticated instruments could conduct passive monitoring from elsewhere while concealing themselves with stealth technologies that need not be much more advanced than current terrestrial ones.
UFO researchers note that the Fermi Paradox arose within the context of a wave of UFO reports, yet Fermi, Teller, York and Konopinski apparently dismissed the possibility that flying saucers might be extraterrestrial – despite then-contemporary US Air Force investigations that judged a small portion of UFO reports as inexplicable by contemporary technology. Mainstream scientific publications have occasionally addressed the possibility of extraterrestrial contact, but the scientific community in general has given little serious attention to claims of unidentified flying objects or to the extraterrestrial hypothesis. Given that UFO investigators argue compelling evidence supports the reality of UFOs as anomalies, but that extant UFO evidence does not support an extraterrestrial origin, it is suggested that closer examination of UFO data may support or falsify the Fermi paradox or the extraterrestrial hypothesis of UFO origins: "Any refusal of interest [by mainstream scientists] in investigating the UFO phenomenon, using an ETI [extraterrestrial intelligence] concept as one working hypothesis, should surely be astonishing." Others however argue that the lack of solid photographic evidence, despite billions of cell-phone, dashboard, and surveillance cameras, indicates that pursuing UFO reports is unlikely to be fruitful.
This extraterrestrial hypothesis was jokingly suggested in response to Fermi's paradox by his fellow physicist, the Hungarian Leó Szilárd, who suggested to Fermi that extraterrestrials "are already among us—but they call themselves Hungarians", a humorous reference to the peculiar Hungarian language, unrelated to most other languages spoken in Europe.
A more serious view than Szilard's joke suggests that the aliens may already be here because we may all be aliens who arrived here long ago as microbes from outer space, from whom all life on Earth may be descended, as a result of theories such as Svante Arrhenius's theory of panspermia, and Francis Crick's Directed panspermia speculation, as well as speculations that the discovery of Martian meteorites on Earth may mean that we all ultimately arrived here long ago as microbes from Mars (a process known as Lithopanspermia). However that would still leave the question of why advanced non-microbial aliens haven't arrived here more recently.
In science fiction and other media.
Many, perhaps most, of the serious explanations for the Fermi Paradox have appeared in science fiction literature, along with many that are not so serious. Less commonly the Fermi Paradox appears in other media. Examples include:
External links.
Listen to this article (3 parts) · 
This audio file was created from a revision of the "Fermi paradox" article dated 2008-05-29, and does not reflect subsequent edits to the article. ()
More spoken articles

</doc>
