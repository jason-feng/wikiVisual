<doc id="8322" url="http://en.wikipedia.org/wiki?curid=8322" title="December 17">
December 17

December 17 is the day of the year in the Gregorian calendar.

</doc>
<doc id="8324" url="http://en.wikipedia.org/wiki?curid=8324" title="Difference engine">
Difference engine

A difference engine is an automatic mechanical calculator designed to tabulate polynomial functions. The name derives from the method of divided differences, a way to interpolate or tabulate functions by using a small set of polynomial coefficients. Most mathematical functions commonly used by engineers, scientists and navigators, including logarithmic and trigonometric functions, can be approximated by polynomials, so a difference engine can compute many useful tables of numbers.
The historical difficulty in producing error-free tables by teams of mathematicians and human "computers" spurred Charles Babbage's desire to build a mechanism to automate the process.
History.
J. H. Müller, an engineer in the Hessian army, conceived of the idea of a difference machine. This was described in a book published in 1786, but Johnson was unable to obtain funding to progress with the idea.
On June 14, 1822, Charles Babbage proposed the use of such a machine in a paper to the Royal Astronomical Society, entitled "Note on the application of machinery to the computation of astronomical and mathematical tables". This machine used the decimal number system and was powered by cranking a handle. The British government was interested, since producing tables was time consuming and expensive and they hoped the difference engine would make the task more economical.
In 1823, the British government gave Babbage £1700 to start work on the project. Although Babbage's design was technically feasible, no one had built a mechanical device to such exacting standards before, so the engine proved to be much more expensive than anticipated. By the time the government killed the project in 1842, they had given Babbage over £17,000, without receiving a working engine. What Babbage did not, or was unwilling to, recognize was that the government was interested in economically produced tables, not the engine itself. The other issue that undermined the government’s confidence in the difference engine was Babbage had moved on to an analytical engine. By developing something better, Babbage had rendered the difference engine useless in the eyes of the government.
Babbage went on to design his much more general analytical engine, but later produced an improved "Difference Engine No. 2" design, between 1847 and 1849. Babbage was able to take advantage of ideas developed for the analytical engine to make the new difference engine calculate more quickly while using fewer parts. Inspired by Babbage's difference engine plans, Per Georg Scheutz built several difference engines from 1855 onwards, one of which was sold to the British government in 1859. Martin Wiberg improved Scheutz's construction but used his device only for producing and publishing printed logarithmic tables.
During the 1980s, Allan G. Bromley, an associate professor at the University of Sydney, Australia, studied Babbage's original drawings for the Difference and Analytical Engines at the Science Museum library in London. This work led the Science Museum to construct a working difference engine No. 2 from 1989 to 1991, under Doron Swade, the then Curator of Computing. This was to celebrate the 200th anniversary of Babbage's birth in 2001. In 2000, the printer which Babbage originally designed for the difference engine was also completed. The conversion of the original design drawings into drawings suitable for engineering manufacturers' use revealed some minor errors in Babbage's design (possibly introduced as a protection in case the plans were stolen), which had to be corrected. Once completed, both the engine and its printer worked flawlessly, and still do. The difference engine and printer were constructed to tolerances achievable with 19th-century technology, resolving a long-standing debate whether Babbage's design would actually have worked. (One of the reasons formerly advanced for the non-completion of Babbage's engines had been that engineering methods were insufficiently developed in the Victorian era.)
The printer's primary purpose is to produce stereotype plates for use in printing presses, which it does by pressing type into soft plaster to create a flong. Babbage intended that the Engine's results be conveyed directly to mass printing, having recognized that errors in previous tables were not the result of human calculating mistakes but from error in the manual typesetting process. The printer's paper output is mainly a means of checking the Engine's performance.
In addition to funding the construction of the output mechanism for the Science Museum's Difference Engine No. 2, Nathan Myhrvold commissioned the construction of a second complete Difference Engine No. 2, which is currently on exhibit at the Computer History Museum in Mountain View, California.
Operation.
The difference engine consists of a number of columns, numbered from 1 to N. The machine is able to store one decimal number in each column. The machine can only add the value of a column "n" + 1 to column "n" to produce the new value of "n". Column "N" can only store a constant, column 1 displays (and possibly prints) the value of the calculation on the current iteration.
The engine is programmed by setting initial values to the columns. Column 1 is set to the value of the polynomial at the start of computation. Column 2 is set to a value derived from the first and higher derivatives of the polynomial at the same value of X. Each of the columns from 3 to "N" is set to a value derived from the formula_1 first and higher derivatives of the polynomial.
Timing.
In the Babbage design, one iteration (i.e., one full set of addition and carry operations) happens for each rotation of the main shaft. Odd and even columns alternately perform an addition in one cycle. The sequence of operations for column formula_2 is thus:
Steps 1,2,3,4 occur for every odd column, while steps 3,4,1,2 occur for every even column.
While Babbage's original design placed the crank directly on the main shaft, it was later realized that the force required to crank the machine would have been too great for a human to handle comfortably. Therefore, the two models that were built incorporate a 4:1 reduction gear at the crank, and four revolutions of the crank are required to perform one full cycle.
Steps.
Each iteration creates a new result, and is accomplished in four steps corresponding to four complete turns of the handle shown at the far right in the picture below. The four steps are:
Subtraction.
The engine represents negative numbers as ten's complements. Subtraction amounts to addition of a negative number. This works in the same manner that modern computers perform subtraction, known as two's complement.
Method of differences.
The principle of a difference engine is Newton's method of divided differences. If the initial value of a polynomial (and of its finite differences) is calculated by some means for some value of X, the difference engine can calculate any number of nearby values, using the method generally known as the method of finite differences. For example, consider the quadratic polynomial
with the goal of tabulating the values "p"(0), "p"(1), "p"(2), "p"(3), "p"(4), and so forth. The table below is constructed as follows: the second column contains the values of the polynomial, the third column contains the differences of the two left neighbors in the second column, and the fourth column contains the differences of the two neighbors in the third column:
The numbers in the third values-column are constant. In fact, by starting with any polynomial of degree "n", the column number "n" + 1 will always be constant. This is the crucial fact behind the success of the method.
This table was built from left to right, but it is possible to continue building it from right to left down a diagonal in order to compute more values. To calculate "p"(5) use the values from the lowest diagonal. Start with the fourth column constant value of 4 and copy it down the column. Then continue the third column by adding 4 to 11 to get 15. Next continue the second column by taking its previous value, 22 and adding the 15 from the third column. Thus "p"(5) is 22 + 15 = 37. In order to compute "p"(6), we iterate the same algorithm on the "p"(5) values: take 4 from the fourth column, add that to the third column's value 15 to get 19, then add that to the second column's value 37 to get 56, which is "p"(6). This process may be continued ad infinitum. The values of the polynomial are produced without ever having to multiply. A difference engine only needs to be able to add. From one loop to the next, it needs to store 2 numbers—in this example (the last elements in the first and second columns). To tabulate polynomials of degree "n", one needs sufficient storage to hold "n" numbers.
Babbage's difference engine No. 2, finally built in 1991, could hold 8 numbers of 31 decimal digits each and could thus tabulate 7th degree polynomials to that precision. The best machines from Scheutz could store 4 numbers with 15 digits each.
Initial values.
The initial values of columns can be calculated by first manually calculating N consecutive values of the function and by backtracking, i.e. calculating the required differences.
Col formula_6 gets the value of the function at the start of computation formula_7. Col formula_8 is the difference between formula_9 and formula_7…
If the function to be calculated is a polynomial function, expressed as
the initial values can be calculated directly from the constant coefficients "a"0, "a"1,"a"2, …, "an" without calculating any data points. The initial values are thus:
Use of derivatives.
Many commonly used functions are analytic functions, which can be expressed as power series, for example as a Taylor series. The initial values can be calculated to any degree of accuracy; if done correctly the engine will give exact results for first N steps. After that, the engine will only give an approximation of the function.
The Taylor series expresses the function as a sum obtained from its derivatives at one point. For many functions the higher derivatives are trivial to obtain; for instance, the sine function at 0 has values of 0 or formula_19 for all derivatives. Setting 0 as the start of computation we get the simplified Maclaurin series
The same method of calculating the initial values from the coefficients can be used as for polynomial functions. The polynomial constant coefficients will now have the value
Curve fitting.
The problem with the methods described above is that errors will accumulate and the series will tend to diverge from the true function. A solution which guarantees a constant maximum error is to use curve fitting. A minimum of N values are calculated evenly spaced along the range of the desired calculations. Using a curve fitting technique like Gaussian reduction an N-1th degree polynomial interpolation of the function is found. With the optimized polynomial, the initial values can be calculated as above.
Further reading.
</dl>

</doc>
<doc id="8326" url="http://en.wikipedia.org/wiki?curid=8326" title="Draupnir">
Draupnir

In Norse mythology, Draupnir (Old Norse "the dripper") is a gold ring possessed by the god Odin with the ability to multiply itself: Every ninth night eight new rings 'drip' from Draupnir, each one of the same size and weight as the original.
Draupnir was forged by the dwarven brothers Brokkr and Eitri (or Sindri). Brokkr and Eitri made this ring as one of a set of three gifts which included Mjöllnir and Gullinbursti. They made these gifts in accordance with a wager Loki made saying that Brokk and Eitri could not make better gifts than the three made by the Sons of Ivaldi. In the end Mjöllnir, Thor's hammer, won the contest for Brokkr and Eitri. Loki used a loophole to get out of the wager for his head (the wager was for Loki's head only, but he argued that, to remove his head, they would have to injure his neck, which was not in the bargain) and Brokkr punished him by sealing his lips shut with wire.
The ring was placed by Odin on the funeral pyre of his son Baldr:
The ring was subsequently retrieved by Hermóðr. It was offered as a gift by Freyr's servant Skírnir in the wooing of Gerðr, which is described in the poem "Skírnismál".
Draupnir in popular culture.
"DRAUPNIR" was revealed as the password to a website that Neal Caffrey and Mozzie used to view their stolen Nazi U-boat treasure in "Taking Account", the seventh episode of the third season of "White Collar".
Draupnir is represented as a card in the Yu-Gi-Oh Trading Card Game. It has an effect that mimics the multiplication ability of the mythological version. If it is destroyed by another card's effect, you can add another "Nordic Relic" card to your hand. The art represents it as an arm brace, with another brace seemingly growing from it, once again mimicking the story.
References.
</dl>

</doc>
<doc id="8328" url="http://en.wikipedia.org/wiki?curid=8328" title="Divergence">
Divergence

In vector calculus, divergence is a vector operator that measures the magnitude of a vector field's source or sink at a given point, in terms of a signed scalar. More technically, the divergence represents the volume density of the outward flux of a vector field from an infinitesimal volume around a given point.
For example:
consider air as it is heated or cooled. The relevant vector field for this example is the velocity of the moving air at a point. If air is heated in a region it will expand in all directions such that the velocity field points outward from that region. Therefore the divergence of the velocity field in that region would have a positive value, as the region is a source. If the air cools and contracts, the divergence has a negative value, as the region is a sink.
Definition of divergence.
In physical terms, the divergence of a three-dimensional vector field is the extent to which the vector field flow behaves like a source or a sink at a given point. It is a local measure of its "outgoingness"—the extent to which there is more exiting an infinitesimal region of space than entering it. If the divergence is nonzero at some point then there must be a source or sink at that position. (Note that we are imagining the vector field to be like the velocity vector field of a fluid (in motion) when we use the terms flow, sink and so on.)
More rigorously, the divergence of a vector field F at a point "p" is defined as the limit of the net flow of F across the smooth boundary of a three-dimensional region "V" divided by the volume of "V" as "V" shrinks to "p". Formally,
where |"V" | is the volume of "V", "S"("V") is the boundary of "V", and the integral is a surface integral with n being the outward unit normal to that surface. The result, div F, is a function of "p". From this definition it also becomes explicitly visible that div F can be seen as the "source density" of the flux of F.
In light of the physical interpretation, a vector field with constant zero divergence is called "incompressible" or "solenoidal" – in this case, no net flow can occur across any closed surface.
The intuition that the sum of all sources minus the sum of all sinks should give the net flow outwards of a region is made precise by the divergence theorem.
Application in Cartesian coordinates.
Let "x, y, z" be a system of Cartesian coordinates in 3-dimensional Euclidean space, and let i, j, k be the corresponding basis of unit vectors.
The divergence of a continuously differentiable vector field F = "U" i + "V" j + "W" k is equal to the scalar-valued function:
Although expressed in terms of coordinates, the result is invariant under orthogonal transformations, as the physical interpretation suggests.
The common notation for the divergence ∇ · F is a convenient mnemonic, where the dot denotes an operation reminiscent of the dot product: take the components of ∇ (see del), apply them to the components of F, and sum the results. Because applying an operator is different from multiplying the components, this is considered an abuse of notation.
The divergence of a continuously differentiable second-order tensor field formula_3 is a first-order tensor field:
Cylindrical coordinates.
For a vector expressed in cylindrical coordinates as
where ea is the unit vector in direction a, the divergence is
Spherical coordinates.
In spherical coordinates, with formula_7 the angle with the "z" axis and formula_8 the rotation around the "z" axis, the divergence reads
Decomposition theorem.
It can be shown that any stationary flux v(r) which is at least two times continuously differentiable in formula_10 and vanishes sufficiently fast for |r| → ∞ can be decomposed into an "irrotational part" E(r) and a "source-free part" B(r). Moreover, these parts are explicitly determined by the respective "source-densities" (see above) and "circulation densities" (see the article Curl):
For the irrotational part one has
with
The source-free part, B, can be similarly written: one only has to replace the "scalar potential" Φ(r) by a "vector potential" A(r) and the terms −∇Φ by +∇×A, and the source-density div v
by the circulation-density ∇×v.
This "decomposition theorem" is in fact a by-product of the stationary case of electrodynamics. It is a special case of the more general Helmholtz decomposition which works in dimensions greater than three as well.
Properties.
The following properties can all be derived from the ordinary differentiation rules of calculus. Most importantly, the divergence is a linear operator, i.e.
for all vector fields F and G and all real numbers "a" and "b".
There is a product rule of the following type: if formula_14 is a scalar valued function and F is a vector field, then
or in more suggestive notation
Another product rule for the cross product of two vector fields F and G in three dimensions involves the curl and reads as follows:
or
The Laplacian of a scalar field is the divergence of the field's gradient:
The divergence of the curl of any vector field (in three dimensions) is equal to zero: 
If a vector field F with zero divergence is defined on a ball in R3, then there exists some vector field G on the ball with F = curl(G). For regions in R3 more complicated than this, the latter statement might be false (see Poincaré lemma). The degree of "failure" of the truth of the statement, measured by the homology of the chain complex
(where the first map is the gradient, the second is the curl, the third is the divergence) serves as a nice quantification of the complicatedness of the underlying region "U". These are the beginnings and main motivations of de Rham cohomology.
Relation with the exterior derivative.
One can express the divergence as a particular case of the exterior derivative, which takes a 2-form to a 3-form in R3.
Define the current two form 
It measures the amount of "stuff" flowing through a surface per unit time in a "stuff fluid" of density formula_26 moving with local velocity F. Its exterior derivative formula_27 is then given by
Thus, the divergence of the vector field F can be expressed as:
Here the superscript formula_30 is one of the two musical isomorphisms, and formula_31 is the Hodge dual. Note however that working with the current two form itself and the exterior derivative is usually easier than working with the vector field and divergence, because unlike the divergence, the exterior derivative commutes with a change of (curvilinear) coordinate system.
Generalizations.
The divergence of a vector field can be defined in any number of dimensions. If 
in a Euclidean coordinate system where formula_33 and formula_34, define
The appropriate expression is more complicated in curvilinear coordinates.
In the case of one dimension, a "vector field" is simply a regular function, and the divergence is simply the derivative.
For any "n", the divergence is a linear operator, and it satisfies the "product rule"
for any scalar-valued function formula_37.
The divergence can be defined on any manifold of dimension "n" with a volume form (or density) formula_38 e.g. a Riemannian or Lorentzian manifold. Generalising the construction of a two form for a vector field on formula_39, on such a manifold a vector field "X" defines a "n"−1 form formula_40 obtained by contracting "X" with formula_38. The divergence is then the function defined by
Standard formulas for the Lie derivative allow us to reformulate this as
This means that the divergence measures the rate of expansion of a volume element as we let it 
flow with the vector field.
On a Riemannian or Lorentzian manifold the divergence with respect to the metric volume form
can be computed in terms of the Levi Civita connection formula_44
where the second expression is the contraction of the vector field valued 1-form formula_46 with itself and the last expression is the traditional coordinate expression used by physicists.
An equivalent expression without using connection is
where formula_48 is the metric and formula_49 denotes partial derivative with respect to coordinate formula_50.
Divergence can also be generalised to tensors. In Einstein notation, the divergence of a contravariant vector formula_51 is given by
where formula_53 is the covariant derivative.
Equivalently, some authors define the divergence of any mixed tensor by using the "musical notation #":
If "T" is a ("p","q")-tensor ("p" for the contravariant vector and "q" for the covariant one), then we define the "divergence of T" to be the ("p","q"−1)-tensor
formula_54
that is we trace the covariant derivative on the "first two" covariant indices.

</doc>
<doc id="8334" url="http://en.wikipedia.org/wiki?curid=8334" title="December 18">
December 18

December 18 is the day of the year in the Gregorian calendar.

</doc>
<doc id="8336" url="http://en.wikipedia.org/wiki?curid=8336" title="Decision problem">
Decision problem

In computability theory and computational complexity theory, a decision problem is a question in some formal system with a yes-or-no answer, depending on the values of some input parameters. Decision problems typically appear in mathematical questions of decidability, that is, the question of the existence of an effective method to determine the existence of some object or its membership in a set; some of the most important problems in mathematics are undecidable.
For example, the problem "given two numbers "x" and "y", does "x" evenly divide "y"?" is a decision problem. The answer can be either 'yes' or 'no', and depends upon the values of "x" and "y". A method for solving a decision problem, given in the form of an algorithm, is called a decision procedure for that problem. A decision procedure for the decision problem "given two numbers "x" and "y", does "x" evenly divide "y"?" would give the steps for determining whether "x" evenly divides "y", given "x" and "y". One such algorithm is long division, taught to many school children. If the remainder is zero the answer produced is 'yes', otherwise it is 'no'. A decision problem which can be solved by an algorithm, such as this example, is called "decidable".
The field of computational complexity categorizes "decidable" decision problems by how difficult they are to solve. "Difficult", in this sense, is described in terms of the computational resources needed by the most efficient algorithm for a certain problem. The field of recursion theory, meanwhile, categorizes "undecidable" decision problems by Turing degree, which is a measure of the noncomputability inherent in any solution. Decision problems are closely related to function problems, which can have answers that are more complex than a simple 'yes' or 'no'. A corresponding function problem is "given two numbers "x" and "y", what is "x" divided by "y"?". They are also related to optimization problems, which are concerned with finding the "best" answer to a particular problem. There are standard techniques for transforming function and optimization problems into decision problems, and vice versa, that do not significantly change the computational difficulty of these problems. For this reason, research in computability theory and complexity theory have typically focused on decision problems.
Definition.
A "decision problem" is any arbitrary yes-or-no question on an infinite set of inputs. Because of this, it is traditional to define the decision problem equivalently as: the set of inputs for which the problem returns "yes".
These inputs can be natural numbers, but may also be values of some other kind, such as strings over the binary alphabet {0,1} or over some other finite set of symbols. The subset of strings for which the problem returns "yes" is a formal language, and often decision problems are defined in this way as formal languages.
Alternatively, using an encoding such as Gödel numberings, any string can be encoded as a natural number, via which a decision problem can be defined as a subset of the natural numbers.
Examples.
A classic example of a decidable decision problem is the set of prime numbers. It is possible to effectively decide whether a given natural number is prime by testing every possible nontrivial factor. Although much more efficient methods of primality testing are known, the existence of any effective method is enough to establish decidability.
Decidability.
A decision problem "A" is called "decidable" or "effectively solvable" if "A" is a recursive set. A problem is called "partially decidable", "semidecidable", "solvable", or "provable" if "A" is a recursively enumerable set. Problems that are not decidable are called "undecidable".
The halting problem is an important undecidable decision problem; for more examples, see list of undecidable problems.
Complete problems.
Decision problems can be ordered according to many-one reducibility and related feasible reductions such as polynomial-time reductions. A decision problem "P" is said to be "complete" for a set of decision problems "S" if "P" is a member of "S" and every problem in "S" can be reduced to "P". Complete decision problems are used in computational complexity to characterize complexity classes of decision problems. For example, the Boolean satisfiability problem is complete for the class NP of decision problems under polynomial-time reducibility.
Equivalence with function problems.
A function problem consists of a partial function "f"; the informal "problem" is to compute the values of "f" on the inputs for which it is defined.
Every function problem can be turned into a decision problem; the decision problem is just the graph of the associated function. (The graph of a function "f" is the set of pairs ("x","y") such that "f"("x") = "y".) If this decision problem were effectively solvable then the function problem would be as well. This reduction does not respect computational complexity, however. For example, it is possible for the graph of a function to be decidable in polynomial time (in which case running time is computed as a function of the pair ("x","y") ) when the function is not computable in polynomial time (in which case running time is computed as a function of "x" alone). The function "f"("x") = "2""x" has this property.
Every decision problem can be converted into the function problem of computing the characteristic function of the set associated to the decision problem. If this function is computable then the associated decision problem is decidable. However, this reduction is more liberal than the standard reduction used in computational complexity (sometimes called polynomial-time many-one reduction); for example, the complexity of the characteristic functions of an NP-complete problem and its co-NP-complete complement is exactly the same even though the underlying decision problems may not be considered equivalent in some typical models of computation.

</doc>
<doc id="8339" url="http://en.wikipedia.org/wiki?curid=8339" title="Domain Name System">
Domain Name System

The Domain Name System (DNS) is a hierarchical distributed naming system for computers, services, or any resource connected to the Internet or a private network. It associates various information with domain names assigned to each of the participating entities. Most prominently, it translates domain names, which can be easily memorized by humans, to the numerical IP addresses needed for the purpose of computer services and devices worldwide. The Domain Name System is an essential component of the functionality of most Internet services because it is the Internet's primary directory service.
The Domain Name System distributes the responsibility of assigning domain names and mapping those names to IP addresses by designating authoritative name servers for each domain. Authoritative name servers are assigned to be responsible for their supported domains, and may delegate authority over sub-domains to other name servers. This mechanism provides distributed and fault tolerant service and was designed to avoid the need for a single central database.
The Domain Name System also specifies the technical functionality of the database service which is at its core. It defines the DNS protocol, a detailed specification of the data structures and data communication exchanges used in DNS, as part of the Internet Protocol Suite. Historically, other directory services preceding DNS were not scalable to large or global directories as they were originally based on text files, prominently the HOSTS.TXT resolver. DNS has been in wide use since the 1980s.
The Internet maintains two principal namespaces, the domain name hierarchy and the Internet Protocol (IP) address spaces. The Domain Name System maintains the domain name hierarchy and provides translation services between it and the address spaces. Internet name servers and a communication protocol implement the Domain Name System. A DNS name server is a server that stores the DNS records for a domain name; a DNS name server responds with answers to queries against its database.
The most common types of records stored in the DNS database are those dealing with a DNS zone's authority authority (SOA), IP addresses (A and AAAA), SMTP mail exchangers (MX), name servers (NS), pointers for reverse DNS lookups (PTR), and domain name aliases (CNAME). Although not intended to be a general purpose database, DNS can store records for other types of data for either automatic machine lookups for things like DNSSEC records, or for human queries like responsible person (RP) records. For a complete list of DNS record types, see the List of DNS record types. As a general purpose database, DNS has also seen use in combating unsolicited email (spam) by using a real-time blackhole list stored in a DNS database. Whether for Internet naming or for general purpose uses, the DNS database is traditionally stored in a structured zone file.
Function.
An often-used analogy to explain the Domain Name System is that it serves as the phone book for the Internet by translating human-friendly computer hostnames into IP addresses. For example, the domain name www.example.com translates to the addresses 93.184.216.119 (IPv4) and 2606:2800:220:6d:26bf:1447:1097:aa7 (IPv6). Unlike a phone book, the DNS can be quickly updated, allowing a service's location on the network to change without affecting the end users, who continue to use the same host name. Users take advantage of this when they use meaningful Uniform Resource Locators (URLs), and e-mail addresses without having to know how the computer actually locates the services.
History.
Using a simpler, more memorable name in place of a host's numerical address dates back to the ARPANET era. The Stanford Research Institute (now SRI International) maintained a text file named HOSTS.TXT that mapped host names to the numerical addresses of computers on the ARPANET. Host operators obtained copies of the master file. The rapid growth of the emerging network required an automated system for maintaining the host names and addresses.
Paul Mockapetris designed the Domain Name System at the University of California, Irvine in 1983, and wrote the first implementation at the request of Jon Postel from ISI. The Internet Engineering Task Force published the original specifications in RFC 882 and RFC 883 in November 1983, which have remained the standard for naming Internet hosts.
In 1984, four UC Berkeley students—Douglas Terry, Mark Painter, David Riggle, and Songnian Zhou—wrote the first Unix name server implementation, called the Berkeley Internet Name Domain (BIND) Server. In 1985, Kevin Dunlap of DEC substantially revised the DNS implementation. Mike Karels, Phil Almquist, and Paul Vixie have maintained BIND since then. BIND was ported to the Windows NT platform in the early 1990s. BIND was widely distributed, especially on Unix systems, and is still the most widely used DNS software on the Internet.
In November 1987, RFC 1034 and RFC 1035 superseded the 1983 DNS specifications. Several additional Request for Comments have proposed extensions to the core DNS protocols.
Structure.
Domain name space.
The domain name space consists of a tree of domain names. Each node or leaf in the tree has zero or more "resource records", which hold information associated with the domain name. The tree sub-divides into "zones" beginning at the root zone. A DNS zone
may consist of only one domain, or may consist of many domains and sub-domains, depending on the administrative authority delegated to the manager.
Administrative responsibility over any zone may be divided by creating additional zones. Authority is said to be "delegated" for a portion of the old space, usually in the form of sub-domains, to another name server and administrative entity. The old zone ceases to be authoritative for the new zone.
Domain name syntax.
The definitive descriptions of the rules for forming domain names appear in RFC 1035, RFC 1123, and RFC 2181.
A domain name consists of one or more parts, technically called "labels", that are conventionally concatenated, and delimited by dots, such as example.com.
Internationalized domain names.
The limited set of ASCII characters permitted in the DNS prevented the representation of names and words of many languages in their native alphabets or scripts. To make this possible, ICANN approved the Internationalizing Domain Names in Applications (IDNA) system, by which user applications, such as web browsers, map Unicode strings into the valid DNS character set using Punycode. In 2009 ICANN approved the installation of internationalized domain name country code top-level domains. In addition, many registries of the existing top level domain names (TLD)s have adopted the IDNA system.
Name servers.
The Domain Name System is maintained by a distributed database system, which uses the client–server model. The nodes of this database are the name servers. Each domain has at least one authoritative DNS server that publishes information about that domain and the name servers of any domains subordinate to it. The top of the hierarchy is served by the root name servers, the servers to query when looking up ("resolving") a TLD.
Authoritative name server.
An "authoritative" name server is a name server that gives answers that have been configured by an original source, for example, the domain administrator or by dynamic DNS methods, in contrast to answers that were obtained via a regular DNS query to another name server. An authoritative-only name server only returns answers to queries about domain names that have been specifically configured by the administrator.
In other words, an authoritative name server lets recursive name servers know what DNS data (the IPv4 IP, the IPv6 IP, a list of incoming mail servers, etc.) a given host name (such as "www.example.com") has. As just one example, the authoritative name server for "example.com" tells recursive name servers that "www.example.com" has the IPv4 IP address 192.0.43.10.
An authoritative name server can either be a "master" server or a "slave" server. A master server is a server that stores the original ("master") copies of all zone records. A slave server uses an automatic updating mechanism of the DNS protocol in communication with its master to maintain an identical copy of the master records.
A set of authoritative name servers has to be assigned for every DNS zone. An NS record about addresses of that set must be stored in the parent zone and servers themselves (as self-reference).
When domain names are registered with a domain name registrar, their installation at the domain registry of a top level domain requires the assignment of a "primary" name server and at least one "secondary" name server. The requirement of multiple name servers aims to make the domain still functional even if one name server becomes inaccessible or inoperable. The designation of a primary name server is solely determined by the priority given to the domain name registrar. For this purpose, generally only the fully qualified domain name of the name server is required, unless the servers are contained in the registered domain, in which case the corresponding IP address is needed as well.
Primary name servers are often master name servers, while secondary name servers may be implemented as slave servers.
An authoritative server indicates its status of supplying definitive answers, deemed "authoritative", by setting a software flag (a protocol structure bit), called the "Authoritative Answer" ("AA") bit in its responses. This flag is usually reproduced prominently in the output of DNS administration query tools (such as dig) to indicate "that the responding name server is an authority for the domain name in question."
Operation.
Address resolution mechanism.
Domain name resolvers determine the domain name servers responsible for the domain name in question by a sequence of queries starting with the right-most (top-level) domain label.
The process entails:
The diagram illustrates this process for the host www.wikipedia.org.
The mechanism in this simple form would place a large operating burden on the root servers, with every search for an address starting by querying one of them. Being as critical as they are to the overall function of the system, such heavy use would create an insurmountable bottleneck for trillions of queries placed every day. In practice caching is used in DNS servers to overcome this problem, and as a result, root name servers actually are involved with very little of the total traffic.
Recursive and caching name server.
In theory, authoritative name servers are sufficient for the operation of the Internet. However, with only authoritative name servers operating, every DNS query must start with recursive queries at the root zone of the Domain Name System and each user system would have to implement resolver software capable of recursive operation.
To improve efficiency, reduce DNS traffic across the Internet, and increase performance in end-user applications, the Domain Name System supports DNS cache servers which store DNS query results for a period of time determined in the configuration (time-to-live) of the domain name record in question.
Typically, such "caching" DNS servers, also called "DNS caches", also implement the recursive algorithm necessary to resolve a given name starting with the DNS root through to the authoritative name servers of the queried domain. With this function implemented in the name server, user applications gain efficiency in design and operation.
As one example, if a client wants to know the address for "www.example.com", it will send, to a recursive caching name server, a DNS request stating "I would like the IPv4 address for 'www.example.com'." The recursive name server will then query authoritative name servers until it gets an answer to that query (or return an error if it's not possible to get an answer)--in this case 192.0.43.10.
The combination of DNS caching and recursive functions in a name server is not mandatory; the functions can be implemented independently in servers for special purposes.
Internet service providers typically provide recursive and caching name servers for their customers. In addition, many home networking routers implement DNS caches and recursors to improve efficiency in the local network.
DNS resolvers.
The client side of the DNS is called a DNS resolver. It is responsible for initiating and sequencing the queries that ultimately lead to a full resolution (translation) of the resource sought, e.g., translation of a domain name into an IP address.
A DNS query may be either a non-recursive query or a recursive query:
The resolver, or another DNS server acting recursively on behalf of the resolver, negotiates use of recursive service using bits in the query headers.
Resolving usually entails iterating through several name servers to find the needed information. However, some resolvers function more simply by communicating only with a single name server. These simple resolvers (called "stub resolvers") rely on a recursive name server to perform the work of finding them.
Circular dependencies and glue records.
Name servers in delegations are identified by name, rather than by IP address. This means that a resolving name server must issue another DNS request to find out the IP address of the server to which it has been referred. If the name given in the delegation is a subdomain of the domain for which the delegation is being provided, there is a circular dependency. In this case the name server providing the delegation must also provide one or more IP addresses for the authoritative name server mentioned in the delegation. This information is called "glue". The delegating name server provides this glue in the form of records in the "additional section" of the DNS response, and provides the delegation in the "authority section" of the response.
For example, if the authoritative name server for example.org is ns1.example.org, a computer trying to resolve www.example.org first resolves ns1.example.org. Since ns1 is contained in example.org, this requires resolving example.org first, which presents a circular dependency. To break the dependency, the name server for the top level domain org includes glue along with the delegation for example.org. The glue records are address records that provide IP addresses for ns1.example.org. The resolver uses one or more of these IP addresses to query one of the domain's authoritative servers, which allows it to complete the DNS query.
Record caching.
The DNS Resolution Process reduces the load on individual servers by "caching" DNS request records for a period of time after a response. This entails the local recording and subsequent consultation of the copy instead of initiating a new request upstream. The time for which a resolver caches a DNS response is determined by a value called the time to live (TTL) associated with every record. The TTL is set by the administrator of the DNS server handing out the authoritative response. The period of validity may vary from just seconds to days or even weeks.
As a noteworthy consequence of this distributed and caching architecture, changes to DNS records do not propagate throughout the network immediately, but require all caches to expire and refresh after the TTL. RFC 1912 conveys basic rules for determining appropriate TTL values.
Some resolvers may override TTL values, as the protocol supports caching for up to 68 years or no caching at all. Negative caching, i.e. the caching of the fact of non-existence of a record, is determined by name servers authoritative for a zone which must include the Start of Authority (SOA) record when reporting no data of the requested type exists. The value of the "minimum" field of the SOA record and the TTL of the SOA itself is used to establish the TTL for the negative answer.
Reverse lookup.
A reverse lookup is a query of the DNS for domain names when the IP address is known. Multiple domain names may be associated with an IP address. The DNS stores IP addresses in the form of domain names as specially formatted names in pointer (PTR) records within the infrastructure top-level domain arpa. For IPv4, the domain is in-addr.arpa. For IPv6, the reverse lookup domain is ip6.arpa. The IP address is represented as a name in reverse-ordered octet representation for IPv4, and reverse-ordered nibble representation for IPv6.
When performing a reverse lookup, the DNS client converts the address into these formats before querying the name for a PTR record following the delegation chain as for any DNS query. For example, assuming the IPv4 address 208.80.152.2 is assigned to Wikimedia, it is represented as a DNS name in reverse order: 2.152.80.208.in-addr.arpa. When the DNS resolver gets a pointer (PTR) request, it begins by querying the root servers, which point to the servers of American Registry for Internet Numbers (ARIN) for the 208.in-addr.arpa zone. ARIN's servers delegate 152.80.208.in-addr.arpa to Wikimedia to which the resolver sends another query for 2.152.80.208.in-addr.arpa, which results in an authoritative response.
Client lookup.
Users generally do not communicate directly with a DNS resolver. Instead DNS resolution takes place transparently in applications such as web browsers, e-mail clients, and other Internet applications. When an application makes a request that requires a domain name lookup, such programs send a resolution request to the DNS resolver in the local operating system, which in turn handles the communications required.
The DNS resolver will almost invariably have a cache (see above) containing recent lookups. If the cache can provide the answer to the request, the resolver will return the value in the cache to the program that made the request. If the cache does not contain the answer, the resolver will send the request to one or more designated DNS servers. In the case of most home users, the Internet service provider to which the machine connects will usually supply this DNS server: such a user will either have configured that server's address manually or allowed DHCP to set it; however, where systems administrators have configured systems to use their own DNS servers, their DNS resolvers point to separately maintained name servers of the organization. In any event, the name server thus queried will follow the process outlined above, until it either successfully finds a result or does not. It then returns its results to the DNS resolver; assuming it has found a result, the resolver duly caches that result for future use, and hands the result back to the software which initiated the request.
Broken resolvers.
Some large ISPs have configured their DNS servers to violate rules, such as by disobeying TTLs, or by indicating that a domain name does not exist just because one of its name servers does not respond.
Some applications, such as web browsers, maintain an internal DNS cache to avoid repeated lookups via the network. This practice can add extra difficulty when debugging DNS issues, as it obscures the history of such data. These caches typically use very short caching times on the order of one minute.
Internet Explorer represents a notable exception: versions up to IE 3.x cache DNS records for 24 hours by default. Internet Explorer 4.x and later versions (up to IE 8) decrease the default time out value to half an hour, which may be changed in corresponding registry keys.
Other applications.
The Domain Name System includes several other functions:
DNS message format.
There are two types of DNS messages: queries and replies, and they both have the same format. Each message consists of a header and four sections: question, answer, authority, and additional. The header field "flags" controls the content of these four sections but the structure of all DNS messages are the same.
The header section contains the fields: Identification, Flags, Number of questions, Number of answers, Number of authority resource records (RRs), and Number of additional RRs. The identification field consists of 16-bits which identifies the query. The DNS client can match a reply with a query using this field. The flag field consists of four bits. The first bit indicates if the message is a query (0) or a reply (1). The second bit is set (only in reply messages) if a DNS server is authoritative for the queried hostname. The third bit is set to (1) when the client wants to send a recursive query. The fourth bit is set (1) in a reply if the replying DNS server supports recursion, since not all DNS servers are configured to do this task. The question section has a name field which is the hostname that is being queried for and a type-field that indicates the type (A, AAAA, MX, etc.) that you want to resolve. The answer section has the resource records of the queried name. There can be multiple records if the hostname has multiple IP addresses associated with it.
QR: Query/Response
OPCODE: Operation Code
AA: Authoritative Answer
TC: Truncated
RD: Recursion Desired
RA: Recursion Available
Z: Zero (Reserved)
AD: Authenticated Data
CD: Checking Disabled
RCODE: Return Code
Protocol transport.
DNS primarily uses User Datagram Protocol (UDP) on port number 53 to serve requests. DNS queries consist of a single UDP request from the client followed by a single UDP reply from the server. The Transmission Control Protocol (TCP) is used when the response data size exceeds 512 bytes, or for tasks such as zone transfers. Some resolver implementations use TCP for all queries.
DNS resource records.
A resource record (RR) is the basic data element in the domain name system. Each record has a type (A, MX, etc.), an expiration time limit, a class, and some type-specific data. Resource records of the same type define a resource record set (RRset). The order of resource records in a set, returned by a resolver to an application, is undefined, but often servers implement round-robin ordering to achieve Global Server Load Balancing. DNSSEC, however, works on complete resource record sets in a canonical order.
When sent over an IP network, all records use the common format specified in RFC 1035:
"NAME" is the fully qualified domain name of the node in the tree. On the wire, the name may be shortened using label compression where ends of domain names mentioned earlier in the packet can be substituted for the end of the current domain name. A free standing "@" is used to denote the current origin.
"TYPE" is the record type. It indicates the format of the data and it gives a hint of its intended use. For example, the "A" record is used to translate from a domain name to an IPv4 address, the "NS" record lists which name servers can answer lookups on a DNS zone, and the "MX" record specifies the mail server used to handle mail for a domain specified in an e-mail address.
"RDATA" is data of type-specific relevance, such as the IP address for address records, or the priority and hostname for MX records. Well known record types may use label compression in the RDATA field, but "unknown" record types must not (RFC 3597).
The "CLASS" of a record is set to IN (for "Internet") for common DNS records involving Internet hostnames, servers, or IP addresses. In addition, the classes Chaos (CH) and Hesiod (HS) exist. Each class is an independent name space with potentially different delegations of DNS zones.
In addition to resource records defined in a zone file, the domain name system also defines several request types that are used only in communication with other DNS nodes ("on the wire"), such as when performing zone transfers (AXFR/IXFR) or for EDNS (OPT).
Wildcard DNS records.
The domain name system supports wildcard DNS records which specify names that start with the "asterisk label", '*', e.g., *.example. DNS records belonging to wildcard domain names specify rules for generating resource records within a single DNS zone by substituting whole labels with matching components of the query name, including any specified descendants.
For example, in the DNS zone "x.example", the following configuration specifies that all subdomains, including subdomains of subdomains, of "x.example" use the mail exchanger "a.x.example". The records for "a.x.example" are needed to specify the mail exchanger. As this has the result of excluding this domain name and its subdomains from the wildcard matches, all subdomains of "a.x.example" must be defined in a separate wildcard statement.
The role of wildcard records was refined in RFC 4592, because the original definition in RFC 1034 was incomplete and resulted in misinterpretations by implementers.
Protocol extensions.
The original DNS protocol had limited provisions for extension with new features. In 1999, Paul Vixie published in RFC 2671 an extension mechanism, called Extension mechanisms for DNS (EDNS) that introduced optional protocol elements without increasing overhead when not in use. This was accomplished through the OPT pseudo-resource record that only exists in wire transmissions of the protocol, but not in any zone files. Initial extensions were also suggested (EDNS0), such as increasing the DNS message size in UDP datagrams.
Dynamic zone updates.
Dynamic DNS updates use the UPDATE DNS opcode to add or remove resource records dynamically from a zone data base maintained on an authoritative DNS server. The feature is described in RFC 2136. This facility is useful to register network clients into the DNS when they boot or become otherwise available on the network. Since a booting client may be assigned a different IP address each time from a DHCP server, it is not possible to provide static DNS assignments for such clients.
Security issues.
Originally, security concerns were not major design considerations for DNS software or any software for deployment on the early Internet, as the network was not open for participation by the general public. However, the expansion of the Internet into the commercial sector in the 1990s changed the requirements for security measures to protect data integrity and user authentication.
Several vulnerability issues were discovered and exploited by malicious users. One such issue is DNS cache poisoning, in which data is distributed to caching resolvers under the pretense of being an authoritative origin server, thereby polluting the data store with potentially false information and long expiration times (time-to-live). Subsequently, legitimate application requests may be redirected to network hosts operated with malicious intent.
DNS responses are traditionally not cryptographically signed, leading to many attack possibilities; the Domain Name System Security Extensions (DNSSEC) modify DNS to add support for cryptographically signed responses. DNSCurve has been proposed as an alternative to DNSSEC. Other extensions, such as TSIG, add support for cryptographic authentication between trusted peers and are commonly used to authorize zone transfer or dynamic update operations.
Some domain names may be used to achieve spoofing effects. For example, paypal.com and paypa1.com are different names, yet users may be unable to distinguish them in a graphical user interface depending on the user's chosen typeface. In many fonts the letter "l" and the numeral "1" look very similar or even identical. This problem is acute in systems that support internationalized domain names, since many character codes in ISO 10646, may appear identical on typical computer screens. This vulnerability is occasionally exploited in phishing.
Techniques such as forward-confirmed reverse DNS can also be used to help validate DNS results.
Domain name registration.
The right to use a domain name is delegated by domain name registrars which are accredited by the Internet Corporation for Assigned Names and Numbers (ICANN) or other organizations such as OpenNIC, that are charged with overseeing the name and number systems of the Internet. In addition to ICANN, each top-level domain (TLD) is maintained and serviced technically by an administrative organization, operating a registry. A registry is responsible for maintaining the database of names registered within the TLD it administers. The registry receives registration information from each domain name registrar authorized to assign names in the corresponding TLD and publishes the information using a special service, the WHOIS protocol.
ICANN publishes the complete list of TLD registries and domain name registrars. Registrant information associated with domain names is maintained in an online database accessible with the WHOIS service. For most of the more than 290 country code top-level domains (ccTLDs), the domain registries maintain the WHOIS (Registrant, name servers, expiration dates, etc.) information. For instance, DENIC, Germany NIC, holds the DE domain data. Since about 2001, most gTLD (Generic top-level domain) registries have adopted this so-called "thick" registry approach, i.e. keeping the WHOIS data in central registries instead of registrar databases.
For COM and NET domain names, a "thin" registry model is used. The domain registry (e.g., VeriSign) holds basic WHOIS data (i.e., registrar and name servers, etc.) One can find the detailed WHOIS (registrant, name servers, expiry dates, etc.) at the registrars.
Some domain name registries, often called "network information centers" (NIC), also function as registrars to end-users. The major generic top-level domain registries, such as for the domains COM, NET, ORG, INFO, use a registry-registrar model consisting of many domain name registrars. In this method of management, the registry only manages the domain name database and the relationship with the registrars. The "registrants" (users of a domain name) are customers of the registrar, in some cases through additional layers of resellers.
Internet standards.
The Domain Name System is defined by Request for Comments (RFC) documents published by the Internet Engineering Task Force (Internet standards). The following is a list of RFCs that define the DNS protocol.

</doc>
<doc id="8340" url="http://en.wikipedia.org/wiki?curid=8340" title="David Letterman">
David Letterman

David Michael Letterman (born April 12, 1947) is an American television host, comedian, writer, producer, and actor. He hosts the late night television talk show "Late Show with David Letterman", broadcast on CBS. Letterman has been a fixture on late night television since the February 1, 1982 debut of "Late Night with David Letterman" on NBC. In 1996, David Letterman was ranked No. 45 on "TV Guide"‍ '​s 50 Greatest TV Stars of All Time. In 2013, Letterman surpassed friend and mentor Johnny Carson as the longest-serving late night talk show host in TV history, at 31 years. On April 3, 2014, Letterman announced he would retire in 2015. He will host the "Late Show" for the last time on May 20, 2015. CBS announced that Stephen Colbert, comedian, writer and host of Comedy Central's "The Colbert Report" since 2005, will take his place.
Letterman is also a television and film producer. His company, Worldwide Pants, produces his show and formerly produced "The Late Late Show with Craig Ferguson". Worldwide Pants has also produced several prime-time comedies, the most successful of which was "Everybody Loves Raymond", currently in syndication.
Early life and career.
Letterman was born in Indianapolis, Indiana. His father, Harry Joseph Letterman (April 15, 1915 – February 13, 1973), was a florist. His mother, Dorothy Letterman (née Hofert, now Dorothy Mengering), a church secretary, has been an occasional figure on the show, usually at holidays and birthdays. His mother is of German descent, and his father had English, Scots-Irish, and German ancestry.
He lived on the north side of Indianapolis (Broad Ripple area), not far from Speedway, Indiana, and the Indianapolis Motor Speedway, and he enjoyed collecting model cars, including racers. In 2000, he told an interviewer for "Esquire" that, while growing up, he admired his father's ability to tell jokes and be the life of the party. Harry Joseph Letterman survived a heart attack at age 36, when David was a young boy. The fear of losing his father was constantly with Letterman as he grew up. The elder Letterman died of a second heart attack at age 57.
Letterman attended his hometown's Broad Ripple High School at the same time as Marilyn Tucker (future wife of Dan Quayle) and worked as a stock boy at the local Atlas Supermarket. According to the "Ball State Daily News", he originally had wanted to attend Indiana University, but his grades were not good enough, so he instead attended Ball State University, in Muncie, Indiana. He is a member of the Sigma Chi fraternity, and he graduated in 1969 from what was then the Department of Radio and Television. A self-described average student, Letterman later endowed a scholarship for what he called "C students" at Ball State.
Though he registered for the draft and passed his physical after graduating from college, he was not drafted for service in Vietnam because of receiving a draft lottery number of 352 (out of 366).
Letterman began his broadcasting career as an announcer and newscaster at the college's student-run radio station—WBST—a 10-watt campus station which now is part of Indiana Public Radio. He was fired for treating classical music with irreverence. He then became involved with the founding of another campus station—WAGO-AM 570 (now WWHI, 91.3).
He credits Paul Dixon, host of the "Paul Dixon Show", a Cincinnati-based talk show also shown in Indianapolis while he was growing up, for inspiring his choice of career:
I was just out of college [in 1969], and I really didn't know what I wanted to do. And then all of a sudden I saw him doing it [on TV]. And I thought: That's really what I want to do!
Weatherman.
Letterman began his career as a radio talk show host on WNTS (AM), and on Indianapolis television station WLWI (now called WTHR) as an anchor, and weatherman. He received some attention for his unpredictable on-air behavior, which included congratulating a tropical storm for being upgraded to a hurricane and predicting hail stones "the size of canned hams." He would also occasionally report the weather and the day's very high and low temps for fictitious cities ("Eight inches of snow in Bingree and surrounding areas") while on another occasion saying that a state border had been erased. ("From space you can see the border between Indiana and Ohio has been erased. I'm not in favor of this.") He also starred in a local kiddie show, made wisecracks as host of a late night TV show called "Freeze-Dried Movies" (he once acted out a scene from "Godzilla" using plastic dinosaurs), and hosted a talk show that aired early on Saturday mornings called "Clover Power," in which he interviewed 4-H members about their projects.
In 1971, Letterman appeared as a pit road reporter for ABC Sports' tape-delayed coverage of the Indianapolis 500. Letterman was initially introduced as Chris Economaki in his job as a corner reporter. Letterman interviewed Mario Andretti, who had just crashed out of the race.
Move to Los Angeles.
In 1975, encouraged by his then-wife Michelle and several of his Sigma Chi fraternity brothers, Letterman moved to Los Angeles, California, with hope of becoming a comedy writer. He and Michelle packed their belongings in his pickup truck and headed west. He still owns that truck today. In Los Angeles, he began performing comedy at The Comedy Store. Jimmie Walker saw him on stage; with an endorsement from George Miller, Letterman joined a group of comedians whom Walker hired to write jokes for his stand-up act, a group that at various times would also include Jay Leno, Paul Mooney, Robert Schimmel, Richard Jeni, Louie Anderson, Elayne Boosler, Byron Allen, Jack Handey, and Steve Oedekerk.
By the summer of 1977, Letterman was a writer and regular on the six-week summer series "The Starland Vocal Band Show", broadcast on CBS. He hosted a 1977 pilot for a game show entitled "The Riddlers" (that was never picked up), and co-starred in the Barry Levinson-produced comedy special "Peeping Times" that aired in January 1978. Later that year, Letterman was a cast member on Mary Tyler Moore's variety show, "Mary". Letterman made a guest appearance on "Mork & Mindy" (as a parody of EST leader Werner Erhard) and appearances on game shows such as "The $20,000 Pyramid", "The Gong Show", "Hollywood Squares", "Password Plus" and "Liar's Club", as well as talk shows such as "The Mike Douglas Show". He was also screen tested for the lead role in the 1980 film "Airplane!", a role that eventually went to Robert Hays.
His dry, sarcastic humor caught the attention of scouts for "The Tonight Show Starring Johnny Carson", and Letterman was soon a regular guest on the show. Letterman became a favorite of Carson's and was a regular guest host for the show beginning in 1978. Letterman credits Carson as the person who influenced his career the most.
NBC.
Morning show.
On June 23, 1980, Letterman was given his own morning comedy show on NBC, "The David Letterman Show". It was originally 90 minutes long, but was shortened to 60 minutes in August 1980. The show was a critical success, winning two Emmy Awards, but was a ratings disappointment and was canceled in October 1980.
"Late Night with David Letterman".
NBC kept Letterman under contract to try him in a different time slot. "Late Night with David Letterman" debuted February 1, 1982; the first guest on the first show was Bill Murray. Murray later went on to become one of Letterman's most recurrent guests and also guested on the show's 30th anniversary episode, aired January 31, 2012. The show ran Monday through Thursday at 12:30 a.m. Eastern Time, immediately following "The Tonight Show Starring Johnny Carson" (a Friday night broadcast was added in June 1987). It was seen as being edgy and unpredictable, and soon developed a cult following (particularly among college students). Letterman's reputation as an acerbic interviewer was borne out in verbal sparring matches with Cher (who even called him an asshole on the show), Shirley MacLaine, Charles Grodin, and Madonna. The show also featured comedy segments and running characters, in a style heavily influenced by the 1950s and 1960s programs of Steve Allen. Although Ernie Kovacs is often cited as an influence on the show, Letterman has denied this.
The show often featured quirky, genre-mocking regular features, including "Stupid Pet Tricks" (which had its origins on Letterman's morning show), Stupid Human Tricks, dropping various objects off the roof of a five-story building, demonstrations of unorthodox clothing (such as suits made of Alka-Seltzer, Velcro and suet), a recurring Top 10 list, the Monkey-Cam (and the Audience Cam), a facetious letter-answering segment, several "Film[s] by My Dog Bob" in which a camera was mounted on Letterman's own dog (often with comic results) and Small Town News, all of which would eventually move with Letterman to CBS.
Other memorable moments included Letterman using a bullhorn to interrupt a live interview on "The Today Show", announcing that he was the NBC News president while not wearing any pants; and staging "elevator races", complete with commentary by NBC Sports' Bob Costas. In one infamous appearance, in 1982, Andy Kaufman (who was already wearing a neck brace) appeared; interrupting Al Roker on WNBC-TV's broadcast of "Live at Five" by walking into their studio (which occupied the same floor of 30 Rockefeller Plaza as Letterman's studio) to be slapped and knocked to the ground by professional wrestler Jerry Lawler (though Lawler and Kaufman's friend Bob Zmuda later revealed that the event was staged). In another memorable exchange, sex expert Dr. Ruth Westheimer included cucumbers in a list of handy sex objects that women could find at home. The following night, guest Ted Koppel asked Letterman "May I insert something here?" and Letterman responded "OK, as long as it's not a cucumber."
CBS.
"Late Show with David Letterman".
In 1992, Johnny Carson retired, and many fans believed that Letterman would become host of "The Tonight Show". When NBC instead gave the job to Jay Leno, Letterman departed NBC to host his own late-night show on CBS, opposite "The Tonight Show" at 11:30 p.m., called the "Late Show with David Letterman". The new show debuted on August 30, 1993 and was taped at the historic Ed Sullivan Theater, where Ed Sullivan broadcast his eponymous variety series from 1948 to 1971. For Letterman's arrival, CBS spent $8 million in renovations. In addition to that cost, CBS also signed Letterman to a lucrative three-year, $14 million/year contract, doubling his "Late Night" salary. The total cost for everything (renovations, negotiation right paid to NBC, signing Letterman, announcer Bill Wendell, Shaffer, the writers and the band) was over $140 million.
But while the expectation was that Letterman would retain his unique style and sense of humor with the move, "Late Show" was not an exact replica of his old NBC program. Recognizing the more formal mood (and wider audience) of his new time slot and studio, Letterman eschewed his trademark blazer with khaki pants and white sneakers wardrobe combination in favor of expensive shoes, tailored suits and light-colored socks. The monologue was lengthened. Paul Shaffer and the "World's Most Dangerous Band" followed Letterman to CBS, but they added a brass section and were rebranded the "CBS Orchestra" as a short monologue and a small band were mandated by Carson while Letterman occupied the 12:30 slot. Additionally, because of intellectual property disagreements, Letterman was unable to import many of his "Late Night" segments verbatim, but he sidestepped this problem by simply renaming them (the "Top Ten List" became the "Late Show Top Ten", "Viewer Mail" became the "CBS Mailbag", etc.)
Popularity.
The main competitor of "The Late Show" is NBC's "The Tonight Show", which was hosted by Jay Leno for 21 years, but from June 1, 2009, to January 22, 2010, was hosted by Conan O'Brien. In 1993 and 1994, "The Late Show" consistently gained higher ratings than "The Tonight Show". But in 1995, ratings dipped and Leno's show consistently beat Letterman's in the ratings from the time that Hugh Grant came on Leno's show after Grant's arrest for soliciting a prostitute; Leno typically attracted about 5 million nightly viewers between 1999 and 2009. "The Late Show" lost nearly half its audience during its competition with Leno, attracting 7.1 million viewers nightly in its 1993–94 season and about 3.8 million per night as of Leno's departure in 2009. In the final months of his first stint as host of "The Tonight Show", Leno beat Letterman in the ratings by a 1.3 million viewer margin (5.2 million to 3.9 million), and "Nightline" and "The Late Show" were virtually tied. Once O'Brien took over "Tonight", however, Letterman closed the gap in the ratings. O'Brien initially drove the median age of "Tonight Show" viewers from 55 to 45, with most older viewers opting to watch "The Late Show" instead.
Following Leno's return to "The Tonight Show", however, Leno regained his lead.
Letterman's shows have garnered both critical and industry praise, receiving 67 Emmy Award nominations, winning 12 times in his first 20 years in late night television. From 1993 to 2009, Letterman ranked higher than Leno in the annual Harris Poll of "Nation's Favorite TV Personality" 12 times. For example, in 2003 and 2004 Letterman ranked second in that poll, behind only Oprah Winfrey, a year that Leno was ranked fifth. Leno was higher than Letterman on that poll three times during the same period, in 1998, 2007, and 2008.
Hosting the Academy Awards.
On March 27, 1995, Letterman acted as the host for the 67th Academy Awards ceremony. Critics blasted Letterman for what they deemed a poor hosting of the Oscars, noting that his irreverent style undermined the traditional importance and glamor of the event. In a joke about their unusual names (inspired by a celebrated comic essay in "The New Yorker", "Yma Dream" by Thomas Meehan), he started off by introducing Uma Thurman to Oprah Winfrey, and then both of them to Keanu Reeves: "Oprah...Uma. Uma...Oprah," "Have you kids met Keanu?" This and many of his other jokes fell flat. Although Letterman attracted the highest ratings to the annual telecast since 1983, many felt that the bad publicity garnered by Letterman's hosting caused a decline in the "Late Show"'s ratings.
Letterman recycled the apparent debacle into a long-running gag. On his first show after the Oscars, he joked, "Looking back, I had no idea that thing was being televised." He lampooned his stint two years later, during Billy Crystal's opening Oscar skit, which also parodied the plane-crashing scenes from that year's chief nominated film, "The English Patient".
For years afterward, Letterman recounted his hosting the Oscars, although the Academy of Motion Picture Arts and Sciences continued to hold Letterman in high regard and they had invited him to host the Oscars again. On September 7, 2010, he made an appearance on the premiere of the 14th season of "The View", and confirmed that he had been considered for hosting again.
Heart surgery hiatus.
On January 14, 2000, a routine check-up revealed that an artery in Letterman's heart was severely obstructed. He was rushed to emergency surgery for a quintuple bypass.
During the initial weeks of his recovery, reruns of the "Late Show" were shown and introduced by friends of Letterman including Drew Barrymore, Ray Romano, Robin Williams, Bonnie Hunt, Megan Mullally, Bill Murray, Regis Philbin, Charles Grodin, Nathan Lane, Julia Roberts, Bruce Willis, Jerry Seinfeld, Martin Short, Steven Seagal, Hillary Rodham Clinton, Danny DeVito, Steve Martin, and Sarah Jessica Parker.
Subsequently, while still recovering from surgery, Letterman revived the late night tradition that had virtually disappeared on network television during the 1990s of 'guest hosts' by allowing Bill Cosby, Kathie Lee Gifford (recommended by Regis Philbin, who was asked first but had no time in his schedule), Dana Carvey, Janeane Garofalo, and others to host new episodes of "The Late Show". Cosby—the show's first guest host—refused to sit at Letterman's desk out of respect, using the couch instead; Garofalo followed suit, using a set of grade-school desks instead.
Upon his return to the show on February 21, 2000, Letterman brought all but one of the doctors and nurses on stage who had participated in his surgery and recovery (with extra teasing of a nurse who had given him bed baths—"This woman has seen me naked!"), including Dr. O. Wayne Isom and physician Louis Aronne, who frequently appears on the show. In a show of emotion, Letterman was nearly in tears as he thanked the health care team with the words "These are the people who saved my life!" The episode earned an Emmy nomination. For a number of episodes, Letterman continued to crack jokes about his bypass, including saying, "Bypass surgery: it's when doctors surgically create new blood flow to your heart. A bypass is what happened to me when I didn't get "The Tonight Show!" It's a whole different thing." In a later running gag he lobbied his home state of Indiana to rename the freeway circling Indianapolis (I-465) "The David Letterman Bypass." He also featured a montage of faux news coverage of his bypass surgery, which included a clip of Letterman's heart for sale on the Home Shopping Network. Letterman became friends with his doctors and nurses. In 2008, a "Rolling Stone" interview stated "he hosted a doctor and nurse who'd helped perform the emergency quintuple-bypass heart surgery that saved his life in 2000. 'These are people who were complete strangers when they opened my chest,' he says. 'And now, eight years later, they're among my best friends.' "
Additionally, Letterman invited the band Foo Fighters to play "Everlong", introducing them as "my favorite band, playing my favorite song." During a later Foo Fighters appearance, Letterman said that Foo Fighters had been in the middle of a South American tour which they canceled to come play on his comeback episode.
Letterman again handed over the reins of the show to several guest hosts (including Bill Cosby, Brad Garrett, Elvis Costello, John McEnroe, Vince Vaughn, Will Ferrell, Bonnie Hunt, Luke Wilson and bandleader Paul Shaffer) in February 2003, when he was diagnosed with a severe case of shingles. Later that year, Letterman made regular use of guest hosts—including Tom Arnold and Kelsey Grammer—for new shows broadcast on Fridays. In March 2007, Adam Sandler—who had been scheduled to be the lead guest—served as a guest host while Letterman was ill with a stomach virus.
Re-signing with CBS.
In March 2002, as Letterman's contract with CBS neared expiration, ABC offered him the time slot for long-running news program "Nightline" with Ted Koppel. Letterman was interested as he believed he could never match Leno's ratings at CBS due to Letterman's complaint of weaker lead-ins from the network's late local news programs, but was reluctant to replace Koppel. Letterman addressed his decision to re-sign on the air, stating that he was content at CBS and that he had great respect for Koppel.
On December 4, 2006, CBS revealed that Letterman signed a new contract to host "The Late Show with David Letterman" through the fall of 2010. "I'm thrilled to be continuing on at CBS," said Letterman. "At my age you really don't want to have to learn a new commute." Letterman further joked about the subject by pulling up his right pants leg, revealing a tattoo, presumably temporary, of the ABC logo.
"Thirteen years ago, David Letterman put CBS late night on the map and in the process became one of the defining icons of our network," said Leslie Moonves, president and CEO of CBS Corporation. "His presence on our air is an ongoing source of pride, and the creativity and imagination that the "Late Show" puts forth every night is an ongoing display of the highest quality entertainment. We are truly honored that one of the most revered and talented entertainers of our time will continue to call CBS 'home.'"
According to a 2007 article in "Forbes" magazine, Letterman earned $40 million a year. A 2009 article in "The New York Times", however, said his salary was estimated at $32 million per year. In June 2009, Letterman's Worldwide Pants and CBS reached agreement to continue the "Late Show" until at least August 2012. The previous contract had been set to expire in 2010, and the two-year extension is shorter than the typical three-year contract period negotiated in the past. Worldwide Pants agreed to lower its fee for the show, though it had remained a "solid moneymaker for CBS" under the previous contract.
On the February 3, 2011, edition of the "Late Show", during an interview with Howard Stern, Letterman said he would continue to do his talk show for "maybe two years, I think."
In April 2012, CBS announced it had extended its contract with Letterman through 2014. His contract was subsequently extended to 2015.
Retirement.
During the taping of his April 3, 2014 show, David Letterman announced that he had informed CBS president Leslie Moonves that he will be retiring from hosting "The Late Show" by May 20, 2015. It was announced soon after that comedian and political satirist Stephen Colbert would succeed Letterman.
Notable exchanges and incidents.
NBC and Johnny Carson.
In spite of Johnny Carson's clear intention to pass his title to Letterman, NBC selected Jay Leno to host "The Tonight Show" after Carson's departure. Letterman maintained a close relationship with Carson through his break with NBC. Three years after he left for CBS, HBO produced a made-for-television movie called "The Late Shift", based on a book by "New York Times" reporter Bill Carter, chronicling the battle between Letterman and Leno for the coveted "Tonight Show" hosting spot.
Carson later made a few cameo appearances as a guest on Letterman's show. Carson's final television appearance came May 13, 1994, on a "Late Show" episode taped in Los Angeles, when he made a surprise appearance during a 'Top 10 list' segment. The audience went wild as Letterman stood up and proudly invited Carson to sit at his desk. The applause was so protracted that Carson was unable to say anything, and he finally returned backstage as the applause continued. (It was later explained that Carson had laryngitis, though Carson can be heard talking to Letterman during his appearance.)
In early 2005, it was revealed that Carson occasionally sent jokes to Letterman, who used these jokes in his monologue; according to CBS senior vice president Peter Lassally (a one-time producer for both men), Carson got "a big kick out of it." Letterman would do a characteristic Johnny Carson golf swing after delivering one of Carson's jokes. In a tribute to Carson, all of the opening monologue jokes during the first show following Carson's death were written by Carson.
Lassally also claimed that Carson had always believed Letterman, not Leno, to be his "rightful successor." During the early years of the "Late Show"‍ '​s run, Letterman occasionally used some of Carson's trademark bits, including "Carnac the Magnificent" (with Paul Shaffer as Carnac), "Stump the Band", and the "Week in Review."
Oprah Winfrey.
Oprah Winfrey appeared on Letterman's show when he was hosting NBC's "Late Night" on May 2, 1989. Following that appearance, the two had a 16-year feud which according to Letterman started when he and his girlfriend decided to skip out on a bill, tricking the waiter into thinking Oprah agreed to pay it.
The feud apparently ended in 2005 when Winfrey appeared on CBS's "Late Show with David Letterman" on December 2, in an event Letterman jokingly referred to as "the Super Bowl of Love".
Winfrey and Letterman also appeared together in a "Late Show" promo that aired during CBS's coverage of Super Bowl XLI in February 2007, with the two sitting next to each other on the couch watching the game. Since the game was played between the Indianapolis Colts and Chicago Bears, the Indianapolis-born Letterman wears a Peyton Manning jersey, while Winfrey—who tapes her show in Chicago—is in a Brian Urlacher jersey. On September 10, 2007, Letterman made his first appearance on "The Oprah Winfrey Show" at Madison Square Garden in New York City. He shared pictures of his son and future wife, Regina Lasko.
Three years later, during CBS's coverage of Super Bowl XLIV, the two appeared again in a "Late Show" promo, this time with Winfrey sitting on a couch between Letterman and Jay Leno. This time Letterman was wearing the retired No. 70 jersey of Colts' Hall of Fame and Letterman regular guest, Art Donovan. The appearance was Letterman's idea: Leno flew to New York City on an NBC corporate jet, sneaking into the Ed Sullivan Theater during the "Late Show"'s February 4 taping wearing a disguise, meeting Winfrey and Letterman at a living room set created in the theater's balcony where they taped their promo.
Winfrey interviewed Letterman in January 2013 on "Oprah's Next Chapter". Winfrey and Letterman discussed their feud during the interview and Winfrey revealed that she had had a "terrible experience" while appearing on Letterman's show years earlier. Letterman could not recall the incident but apologized.
2007–2008 writers' strike.
The Late Show went off air for eight weeks during the months of November and December because of the Writers Guild of America strike. Letterman's production company—Worldwide Pants—was the first company to make an individual agreement with the WGA, thus allowing his show to come back on air on January 2, 2008. On his first episode since being off air, he surprised the viewing audience with his newly grown beard, which signified solidarity with the strike. His beard was shaved off during the show on January 7, 2008.
Palin joke.
On June 8 and June 9, 2009, Letterman told a sexually themed joke on his show each night about a daughter of Sarah Palin. Palin was in New York City at the time with her fourteen-year-old daughter, Willow, and the jokes were said to be aimed at the daughter, never named, who was visiting New York City with her mother. Palin criticized the jokes, saying in a statement posted on the internet that "I doubt he'd ever dare make such comments about anyone else's daughter," and "laughter incited by sexually perverted comments made by a 62-year-old male celebrity aimed at a 14-year-old girl" is "disgusting." On June 10, Letterman responded to the controversy on his show by stating that the jokes were meant to be about Palin's eighteen-year-old daughter, Bristol, whose pregnancy as an unmarried teenager had caused controversy during the 2008 Presidential election, and that "(t)hese are not jokes made about (Palin's) 14-year-old daughter. I would never, never make jokes about raping or having sex of any description with a 14-year-old girl." His remarks did not put an end to the public criticism, however, with the National Organization for Women, who supported Palin in a statement, noting he had given only "something of an apology." With the controversy not subsiding, Letterman addressed the issue again on his June 15 show, faulting himself for the error and apologizing "especially to the two daughters involved, Bristol and Willow, and also to the governor and her family and everybody else who was outraged by the joke."
Al-Qaeda death threat.
On August 17, 2011, it was reported that a Muslim militant had posted a death threat against Letterman on a website frequented by Al-Qaeda supporters, calling on American Muslims to kill Letterman for making a joke about the death of an Al-Qaeda leader killed in a drone strike in Pakistan in June 2011. In his show on August 22, Letterman joked about the threat, saying "State Department authorities are looking into this. They're not taking this lightly. They're looking into it. They're questioning, they're interrogating, there's an electronic trail—but everybody knows it's Leno."
Appearances in other media.
Letterman appeared in issue 239 of the Marvel comic book "The Avengers", in which the title characters are guests on "Late Night". A parody of Letterman, named "David Endochrine," is gassed to death along with his bandleader named "Paul" and their audience in Frank Miller's "The Dark Knight Returns".
Letterman appeared in the pilot episode of the short-lived 1986 series "Coach Toast", and he appears with a bag over his head as a guest on Bonnie Hunt's ca. 1993 sitcom "The Building". He also appears in "The Simpsons", as himself in a couch gag when The Simpsons find themselves (and the couch) in "Late Night with David Letterman." He had a cameo in the feature film "Cabin Boy", with Chris Elliott, who worked as a writer on Letterman's show. In this and other appearances, Letterman is listed in the credits as "Earl Hofert", the name of Letterman's maternal grandfather. He also appeared as himself in the Howard Stern biographical film "Private Parts" as well as the 1999 Andy Kaufman biopic "Man on the Moon", in a few episodes of Garry Shandling's 1990s TV series "The Larry Sanders Show" and in "The Abstinence", a 1996 episode of the sitcom "Seinfeld". Letterman also made an uncredited appearance in the first episode of the third season of the sitcom The Nanny.
Letterman provided vocals for the Warren Zevon song "Hit Somebody" from "My Ride's Here", and provided the voice for Butt-head's father in the 1996 animated film "Beavis and Butt-head Do America".
In 2010, a documentary "Dying to Do Letterman" was released directed by Joke Fincioen and Biagio Messina featuring Steve Mazan, a stand up comic, who has cancer and wants to appear on the Letterman Show. The film won Best Documentary and Jury Awards at the Cinequest Film Festival. Steve Mazan published a same-titled book (full title, "Dying to Do Letterman: Turning Someday into Today") about his own saga.
Known for rarely giving interviews, Letterman appeared as a guest on CNN's "Piers Morgan Tonight" on May 29, 2012, where he was interviewed by Regis Philbin, the guest host and long-time friend. Philbin again interviewed Letterman (and Shaffer) while guest-hosting CBS' "The Late Late Show" (between the tenures of Craig Ferguson and James Corden) on January 27, 2015.
In June 2013, he appeared in the second episode of season two of "Comedians in Cars Getting Coffee".
On November 5, 2013, Letterman and Bruce McCall published a fiction satire book titled "This Land Was Made for You and Me (But Mostly Me)". ISBN 0-399-16368-9
Other projects.
Worldwide Pants.
Letterman started his own production company—Worldwide Pants Incorporated—which produced his show and several others, including "Everybody Loves Raymond", "The Late Late Show", and two television series for Bonnie Hunt. Worldwide Pants also produced the dramedy program "Ed", which aired on NBC from 2000–2004. It was Letterman's first association with NBC since he left the network in 1993. During "Ed's" run, the star, Tom Cavanagh, appeared as a guest on "The Late Show" several times.
In 2005, Worldwide Pants produced its first feature film, "Strangers with Candy", which was a prequel to the Comedy Central TV series of the same title. In 2007, Worldwide Pants produced the ABC comedy series, "Knights of Prosperity".
Worldwide Pants made significant news in December 2007 when it was announced that Letterman's company had independently negotiated its own contract with the Writers Guild of America, East, thus allowing Letterman, Craig Ferguson, and their writers to return to work, while the union continued its strike against production companies, networks and studios who had not reached an agreement.
Record company.
In late April 2010, several music industry websites reported that Letterman started a record label named Clear Entertainment/C.E. Music and signed his first artist, Runner Runner. Lucy Walsh announced on her MySpace page that she has been signed by Letterman and Clear Entertainment/C.E. Music and is working on her album.
Rahal Letterman Lanigan Racing.
Rahal Letterman Lanigan Racing (RLLR) is an auto racing team that currently races in the American Le Mans Series, and full-time in the Verizon IndyCar Series. It is co-owned by 1986 Indianapolis 500 winner Bobby Rahal, businessman Mike Lanigan, and Letterman himself, and is based in Hilliard, Ohio. The team won the 2004 Indianapolis 500 with driver Buddy Rice.
Charitable foundation.
The Letterman Foundation for Courtesy and Grooming is a private foundation through which Letterman has donated millions of dollars to charities and other non-profits in Indiana and Montana, celebrity-affiliated organizations such as Paul Newman's Hole in the Wall Gang Camp, universities such as Ball State, and other organizations such as the American Cancer Society, Salvation Army, and Doctors Without Borders.
Personal life.
Marriages, relationships, and family.
In 1969, Letterman married Michelle Cook; the marriage ended by divorce in 1977. He also had a relationship with former head writer and producer on "Late Night", Merrill Markoe. Markoe was the mind behind several "Late Night" staples, such as "Stupid Pet/Human Tricks".
Letterman and Regina Lasko started dating in 1986, while he was still living with Markoe. He has a son, Harry Joseph Letterman (born on November 3, 2003), with her. Harry is named after Letterman's father. In 2005, police discovered a plot to kidnap Harry Letterman and ransom him for $5 million. Kelly Frank, a house painter who had worked for Letterman, was charged in the conspiracy.
Letterman and Lasko wed on March 19, 2009, during a quiet courthouse civil ceremony in Choteau, Montana, where he purchased a ranch in 1999. Letterman announced the marriage during the taping of his March 23 show, shortly after congratulating Bruce Willis for getting married the previous week. Letterman told the audience he nearly missed the ceremony because his truck became stuck in mud two miles from their house. The family resides in North Salem, New York, on a 108-acre estate.
Letterman suffers from tinnitus (ringing in the ears), which is a symptom of hearing loss. On the "Late Show" in 1996, Letterman talked about his tinnitus in an interview he did with actor William Shatner, who has severe tinnitus himself, caused from an on-set explosion. Letterman said at first he could not figure out where the noise in his head was coming from and that he hears constant noises and ringing in his ears 24 hours a day.
Letterman no longer drinks alcohol, and has on more than one occasion said that he had once been a "horrible alcoholic" and had begun drinking around the age of 13 until the age of 34, in 1981: "I was drunk 80% of the time... I loved it. I was one of those guys, I looked around, and everyone else had stopped drinking and I couldn't understand why." When he is shown on "The Late Show" (or, before that, on "Late Night") drinking what appears to be alcohol, it is actually substituted with apple juice by the crew. In 2015, he said that "For years and years and years – 30, 40 years – I was anxious, and hypochondriacal, and an alcoholic, and many, many other things that made me different from other people." He became calmer through a combination of transcendental meditation low doses of medication, along with transcendental meditation.
Letterman has implied that he is a Lutheran.
Stalker.
Beginning in May 1988, Letterman was stalked by Margaret Mary Ray, a woman suffering from schizophrenia. She stole his Porsche, camped out on his tennis court, and repeatedly broke into his house. Her exploits drew national attention, with Letterman occasionally joking about her on his show, although he never referred to her by name. After she committed suicide in October 1998, Letterman told the "New York Times" that he had great compassion for her. A spokesperson for Letterman said: "This is a sad ending to a confused life."
Blackmail attempt and revelation of affairs.
On his October 1, 2009, show, Letterman announced that he had been the victim of a blackmail attempt by someone threatening to reveal that he had had sex with several of his female employees, and at the same time, he confirmed that he had had such relationships. He stated that three weeks earlier (on September 9, 2009) someone had left a package in his car with material he said he would write into a screenplay and a book if Letterman did not pay him $2 million. Letterman said that he contacted the Manhattan District Attorney's office, ultimately cooperating with them to conduct a sting operation involving giving the man a phony check. Subsequently, Robert J. "Joe" Halderman, a producer of the CBS true crime journalism series "48 Hours", was arrested after trying to deposit the check. He was indicted by a Manhattan grand jury and pleaded not guilty to a charge of attempted grand larceny on October 2, 2009. Eventually, on March 9, 2010, he pleaded guilty to this same felony and served a 6-month jail sentence, followed by probation and community service.
A central figure in the case and one of the women with whom Letterman had had a sexual relationship was his longtime personal assistant Stephanie Birkitt, who often appeared with him on his show. She had also worked for "48 Hours". Until a month prior to the revelations, she had shared a residence with Halderman, who allegedly had copied her personal diary and used it, along with private emails, in the blackmail package.
In the days following the initial announcement of the affairs and the arrest, several prominent women, including Kathie Lee Gifford, co-host of NBC's "Today Show", and NBC news anchor Ann Curry questioned whether Letterman's affairs with subordinates created an unfair working environment. A spokesman for Worldwide Pants said that the company's sexual harassment policy did not prohibit sexual relationships between managers and employees. According to business news reporter Eve Tahmincioglu, "CBS suppliers are supposed to follow the company's business conduct policies" and the CBS 2008 Business Conduct Statement states that "If a consenting romantic or sexual relationship between a supervisor and a direct or indirect subordinate should develop, CBS requires the supervisor to disclose this information to his or her Company's Human Resources Department...".
On October 3, 2009, a former CBS employee, Holly Hester, announced that she and Letterman had engaged in a year-long "secret" affair in the early 1990s while she was his intern and a student at New York University.
On October 5, 2009, Letterman devoted a segment of his show to a public apology to his wife and staff. Three days later, Worldwide Pants announced that Birkitt had been placed on a "paid leave of absence" from the "Late Show". On October 15, CBS News announced that the company's Chief Investigative Correspondent, Armen Keteyian, had been assigned to conduct an "in-depth investigation" into Halderman's blackmail of Letterman.
Awards and honors.
David Letterman Communication and Media Building.
On September 7, 2007, Letterman visited his "alma mater", Ball State University in Muncie, Indiana, for the dedication of a communications facility named in his honor for his dedication to the university. The $21 million, 75000 sqft David Letterman Communication and Media Building opened for the 2007 fall semester. Thousands of Ball State students, faculty, and local residents welcomed Letterman back to Indiana. Letterman's emotional speech touched on his struggles as a college student and his late father, and also included the "top ten good things about having your name on a building", finishing with, "if reasonable people can put my name on a $21 million building, anything is possible." Over many years Letterman "has provided substantial assistance to [Ball State's] Department of Telecommunications, including an annual scholarship that bears his name."
At the same time, Letterman also received a Sagamore of the Wabash award given by Indiana Governor Mitch Daniels, which recognizes distinguished service to the state of Indiana.
Awards.
In his capacities as either a writer, producer, performer, or as part of a writing team, Letterman is among the most nominated people in Emmy Award history with 52 nominations, winning two Daytime Emmys and ten Primetime Emmys since 1981. His nomination record is second only to producer Jac Venza, who holds the record for the most Emmy nominations for an individual (57). Letterman was nominated every year from 1984 to 2010. He won four American Comedy Awards and in 2011 became the first recipient of the Johnny Carson Award for Comedic Excellence at The Comedy Awards.
Letterman was a recipient of the 2012 Kennedy Center Honors, where he was called "one of the most influential personalities in the history of television, entertaining an entire generation of late-night viewers with his unconventional wit and charm."

</doc>
<doc id="8341" url="http://en.wikipedia.org/wiki?curid=8341" title="Delroy Lindo">
Delroy Lindo

Delroy George Lindo (born November 18, 1952) is an English actor and theatre director. Lindo has been nominated for the Tony and Screen Actors Guild awards and has won a Satellite Award. He is perhaps best known for his roles in a trio of Spike Lee films, especially as West Indian Archie in Lee's "Malcolm X" (1992) and Woody Carmichael in "Crooklyn" (1994), Catlett in "Get Shorty", Arthur Rose in "The Cider House Rules", and Detective Castlebeck in "Gone in 60 Seconds" (2000). Lindo starred as Alderman Ronin Gibbons in the TV series "The Chicago Code" (2011), and as Winter on the series "Believe," which premiered in 2014.
Early life.
Delroy Lindo was born in 1952 in Eltham, south-east London, the son of Jamaican parents who had migrated to England. He was brought up in nearby Lewisham and got interested in acting as a child in a Nativity play. His mother was a nurse and his father worked in various jobs. As a teenager, he and his mother moved to Toronto, Canada. When he was sixteen, they moved to San Francisco. At the age of 24, Lindo started acting studies at the American Conservatory Theater, graduating in 1979.
Career.
Lindo's movie debut came in 1976 with the British comedy "Find The Lady", followed by two other roles in films, including an Army Sergeant in "More American Graffiti" (1979). 
He quit film for 10 years to concentrate on theatre acting. In 1982 he debuted on Broadway in ""Master Harold"...and the Boys," directed by the play's South African author Athol Fugard. By 1988 Lindo had earned a Tony nomination for his portrayal of Herald Loomis in August Wilson's "Joe Turner's Come and Gone".
Lindo returned to film in the 1990s, acting alongside Rutger Hauer and Joan Chen in the cult science fiction movie "Salute of the Jugger" (1990), which has become a cult classic. Although he had turned down Spike Lee for a role in his debut "Do the Right Thing", Lee cast him as Woody Carmichael in the drama "Crooklyn" (1994), which brought him notice. Together with his other roles with Lee - as the West Indian Archie, a psychotic gangster, in "Malcolm X", and a starring role as a neighbourhood drug dealer in "Clockers" - he became established in his film career. 
Other films in which he has starring roles are Barry Sonnenfeld's "Get Shorty" (1995), Ron Howard's "Ransom" (1996), and "Soul of the Game" (1996), as the baseball player Satchel Paige. As a character actor, Lindo has readily taken on roles as treacherous bad guys as well as those of trustworthy professionals. 
In 1998 Lindo co-starred as African-American explorer Matthew Henson, in the TV movie "Glory & Honor", directed by Kevin Hooks. It portrayed his nearly 20-year partnership with Commander Robert Peary in Arctic exploration and their effort to find the Geographic North Pole in 1909. He received a Satellite Award as best actor. Lindo continues to work in television and was most recently seen on the short-lived NBC drama "Kidnapped".
Lindo played an angel in the comedy film "A Life Less Ordinary" (1997), in which Dan Hedaya played the angel Gabriel, and Lindo's boss. He guest-starred on "The Simpsons" in the episode "Brawl in the Family", playing a similar character named Gabriel. 
Lindo had a small role in the 1995 science fiction/action film "Congo," playing the corrupt Captain Wanta. Lindo was not credited for the role, but one of his lines in the film, "Stop eating my sesame cake!", has become an internet meme.
In the British film, "Wondrous Oblivion" (2003), directed by Paul Morrison, he starred as Dennis Samuels, the father of a Jamaican immigrant family in London in the 1950s; he coaches his children and the son of a neighbour Jewish family in cricket, earning their admiration in a time of strained social relations. Lindo said he made the film in honor of his parents, who had similarly moved to London in those years.
In 2007, Lindo began an association with Berkeley Repertory Theatre in Berkeley, California, when he directed Tanya Barfield's play "The Blue Door". In the fall of 2008, Lindo revisited August Wilson's play, "Joe Turner's Come and Gone", directing a production at the Berkeley Rep. In 2010, he played the role of elderly seer Bynum in David Lan's production of "Joe Turner" at the Young Vic Theatre in London.

</doc>
<doc id="8343" url="http://en.wikipedia.org/wiki?curid=8343" title="David Janssen">
David Janssen

David Janssen (March 27, 1931 – February 13, 1980) was an American film and television actor who is best known for his starring role as Dr. Richard Kimble in the television series "The Fugitive" (1963–1967). Janssen also had the title roles in three other series: "Richard Diamond, Private Detective"; "Harry O"; and "O'Hara, U.S. Treasury".
In 1996 "TV Guide" ranked him number 36 on its 50 Greatest TV Stars of All Time list.
Early life.
Janssen was born as David Harold Meyer in Naponee, a village in Franklin County in southern Nebraska, to Harold Edward Meyer, a banker (May 12, 1906 – November 4, 1990) and Berniece Graf (May 11, 1910 – November 26, 1995). Janssen was of Irish and Jewish descent. Following his parents' divorce in 1935, his mother moved with five-year-old David to Los Angeles, California, and later married Eugene Janssen (February 18, 1918 – March 30, 1996) in 1940 in Los Angeles. Young David used his stepfather's name after he entered show business as a child.
He attended Fairfax High School in Los Angeles. His first film part was at the age of thirteen, and by the age of twenty-five he had appeared in twenty films and served two years as an enlisted man in the United States Army. During his Army days, Janssen became friends with fellow enlistees Martin Milner and Clint Eastwood while posted at Fort Ord, California.
Acting career.
Janssen appeared in many television series before he landed programs of his own. In 1956, he and Peter Breck appeared in John Bromfield's syndicated series "Sheriff of Cochise" in the episode "The Turkey Farmers". Later, he guest starred on NBC's medical drama "The Eleventh Hour" in the role of Hal Kincaid in the 1962 episode "Make Me a Place", with series co-stars Wendell Corey and Jack Ging. He joined friend Martin Milner in a 1962 episode of "Route 66" as the character Kamo in the episode "One Tiger to a Hill."
Janssen starred in four television series of his own:
At the time, the final episode of "The Fugitive" held the record for the greatest number of American homes with television sets to watch a series finale, at 72 percent in August 1967.
His films include "To Hell and Back", the biography of Audie Murphy, who was the most decorated American soldier of World War II; John Wayne's Vietnam war film "The Green Berets"; opposite Gregory Peck in the space story "Marooned", in which Janssen played an astronaut sent to rescue three stranded men in space, and "The Shoes of the Fisherman", as a television journalist in Rome reporting on the election of a new Pope (Anthony Quinn).
He starred as a Los Angeles police detective trying to clear himself in the killing of an apparently innocent doctor in the 1968 film "Warning Shot".
Janssen played an alcoholic in the 1977 TV movie "A Sensitive, Passionate Man", which co-starred Angie Dickinson, and an engineer who devises an unbeatable system for blackjack in the 1978 made-for-TV movie "Nowhere to Run", co-starring Stefanie Powers and Linda Evans. Janssen's impressively husky voice was used to good effect as the narrator for the TV mini-series "Centennial" (1978–79); he also appeared in the final episode.
Though Janssen's scenes were cut from the final release, he also appeared as a journalist in the film "Inchon", which he accepted to work with Laurence Olivier who played General Douglas MacArthur. At the time of his death, Janssen had just begun filming a television movie playing the part of Father Damien, the priest who dedicated himself to the leper colony on the island of Molokai, Hawaii. The part was eventually reassigned to actor Ken Howard of the CBS series "The White Shadow".
Personal life.
Janssen was married twice. His first marriage was to model and interior decorator Ellie Graham, whom he married in Las Vegas on August 25, 1958. They divorced in 1968. In 1975, he married actress and model . They remained married until Janssen's death.
Death.
Janssen died of a sudden heart attack in the early morning of February 13, 1980, at his home in Malibu, California at age 48. At the time of his death, Janssen was filming the television movie "Father Damien". Janssen was buried at the Hillside Memorial Park Cemetery in Culver City, California. A non-denominational funeral was held at the Jewish chapel of the cemetery on February 17. Suzanne Pleshette delivered the eulogy at the request of Janssen's widow. Johnny Carson, Rod Stewart and Gregory Peck were among Janssen's pallbearers. Honorary pallbearers included Jack Lemmon, George Peppard, James Stewart and Danny Thomas. Los Angeles coroner Thomas Noguchi reportedly found high levels of morphine, cocaine, and alcohol in Janssen's body.
For his contribution to the television industry, David Janssen has a star on the Hollywood Walk of Fame located on the 7700 block of Hollywood Boulevard.

</doc>
<doc id="8344" url="http://en.wikipedia.org/wiki?curid=8344" title="Docetism">
Docetism

In Christian terminology, docetism (from the Greek δοκεῖν/δόκησις "dokeĩn" (to seem) /"dókēsis" (apparition, phantom), according to Norbert Brox, is defined narrowly as "the doctrine according to which the phenomenon of Christ, his historical and bodily existence, and thus above all the human form of Jesus, was altogether mere semblance without any true reality." Broadly it is taken as the belief that Jesus only seemed to be human, and that his human form was an illusion. The word Δοκηταί "Dokētaí" (illusionists) referring to early groups who denied Jesus' humanity, first occurred in a letter by Bishop Serapion of Antioch (197–203), who discovered the doctrine in the Gospel of Peter, during a pastoral visit to a Christian community using it in Rhosus, and later condemned it as a forgery.
It appears to have arisen over theological contentions concerning the meaning, figurative or literal, of a sentence from the Gospel of John: "the Word was made Flesh".
Docetism was unequivocally rejected at the First Council of Nicaea in 325 and is regarded as heretical by the Catholic Church, Orthodox Church, and many others.
Definitions.
Docetism is broadly defined as any teaching that claims that Jesus' body was either absent or illusory. The term ‘docetic’ should be used with caution, since its use is rather nebulous. For Robert Price "docetism", together with "encratism", "Gnosticism", and "adoptionism" has been employed "far beyond what historically descriptive usage would allow". Two varieties were widely known. In one version as in Marcionism, Christ was so divine he could not have been human, since God lacked a material body, which therefore could not physically suffer. Jesus only appeared to be a flesh-and-blood man, his body was a phantasm. Other groups who were accused of docetism held that Jesus was a man in the flesh, but Christ was a separate entity, who entered Jesus’s body in the form of a dove at his baptism, empowered him to perform miracles, and abandoned him on his death on the cross.
Christology and theological implications.
Docetism's origin within Christianity is obscure. Ernst Käsemann controversially defined the Christology of St John’s Gospel as “naïve docetism” in 1968. The ensuing debate reached an impasse as awareness grew that the very term ‘docetism’ like ‘gnosticism’ was difficult to define within the religio-historical framework of the debate. It has occasionally been argued that its origins were in heterodox Judaism or Oriental and Grecian philosophies. The alleged connection with Jewish Christianity would have reflected Jewish Christian concerns with the inviolability of (Jewish) monotheism. Docetic opinions seem to have circulated from very early times, 1 John 4:2 appearing explicitly to reject them. Some 1st century Christian groups developed docetic interpretations partly as a way to make Christian teachings more acceptable to pagan ways of thinking of divinity.
In his critique of the theology of Clement of Alexandria, Photius in his Myriobiblon held that Clement’s views reflected a quasi-docetic view of the nature of Christ, writing that "[Clement] hallucinates that the Word was not incarnate but only seems to be." (ὀνειροπολεῖ καὶ μὴ σαρκωθῆναι τὸν λόγον ἀλλὰ δόξαι.) In Clement’s time some disputes contended over whether Christ assumed the ‘psychic’ flesh of mankind as heirs to Adam, or the ‘spiritual’ flesh of the resurrection. 
Docetism largely died out during the first millennium AD.
The opponents against whom Ignatius of Antioch inveighs are often taken to be Monophysite docetists. In his letter to the Smyrnaeans, 7:1, written around 110 AD, he writes:
They abstain from the Eucharist and from prayer, because they confess not the Eucharist to be the flesh of our Saviour Jesus Christ, which suffered for our sins, and which the Father, of His goodness, raised up again. They who deny the gift of God are perishing in their disputes". 
While these characteristics fit a Monophysite framework, a slight majority of scholars consider that Ignatius was waging a polemic on two distinct fronts, one Jewish, the other docetic, while a distinct minority holds that he is concerned with a group that commingled Judaism and docetism. Other possibilities are that he was merely opposed to Christians who lived Jewishly, or deny that docetism threatened the church, or that his critical remarks were directed at an Ebionite or Cerinthian possessionist Christology, where God descended and took possession of Jesus' body.
Islam and docetism.
The Qur'an has a docetic Christology, viewing Jesus as a divine illuminator rather than the redeemer (as he is viewed in Christianity). However, the Islamic docetism is not focused on the general life and person of Jesus or the Christ. In Islam "the Christ" ("al-masīḥ") is not generally viewed as distinct from humanity nor a special spirit being as in docetism or some gnosticisms. Islamic docetism focuses on a denial of the crucifixion of Jesus. 
Sura 4:157–158 reads:
And because of their saying: We slew the Messiah, Jesus son of Mary, Allah's messenger — they slew him not nor crucified him, but it appeared so unto them; and lo! those who disagree concerning it are in doubt thereof; they have no knowledge thereof save pursuit of a conjecture; they slew him not for certain. But Allah took him up unto Himself. Allah was ever Mighty, Wise.
Docetism and Christ myth theory.
Since Arthur Drews published his "The Christ Myth" (Die Christusmythe) in 1909, occasional connections have been drawn between the modern idea that Christ was a myth and docetist theories. Shailer Mathews called Drews' theory a "modern docetism". Frederick Cornwallis Conybeare thought any connection to be based on a misunderstanding of docetism. The idea recurred in Classicist Michael Grant's 1977 review of the evidence for Jesus, who compared modern scepticism about an historical Jesus to the ancient docetic idea that Jesus only "seemed" to come into the world "in the flesh". Modern theories did away with "seeming".
References.
</dl>

</doc>
<doc id="8347" url="http://en.wikipedia.org/wiki?curid=8347" title="Greek drachma">
Greek drachma

Drachma (₯; Greek: δραχμή ], ]; pl. "drachmae" or "drachmas") was the currency used in Greece during several periods in its history:
It was also a small unit of weight.
Ancient drachma.
The name "drachma" is derived from the verb δράσσομαι ("drássomai", "(I) grasp"). It is believed that the same word with the meaning of ""handful" or "handle"" is found in Linear B tablets of the Mycenean Pylos. Initially a drachma was a fistful (a "grasp") of six "oboloí" or "obeloí" (metal sticks, literally "spits") used as a form of currency as early as 1100 BC and being a form of "bullion": bronze, copper, or iron ingots denominated by weight. A hoard of over 150 rod-shaped obeloi were uncovered at Heraion of Argos in Peloponnese. Six of them are displayed at the Numismatic Museum of Athens.
It was the standard unit of silver coinage at most ancient Greek mints, and the name 'obol' was used to describe a coin that was one-sixth of a drachma. The notion that "drachma" derived from the word for fistful was recorded by Herakleides of Pontos (387-312 BC) who was informed by the priests of Heraion that Pheidon, king of Argos, dedicated rod-shaped obeloi to Heraion. Similar information about Pheidon's obeloi was also recorded at the Parian Chronicle.
Ancient Greek coins normally had distinctive names in daily use. The Athenian tetradrachm was called owl, the Aeginetic stater was called chelone, the Corinthian stater was called "hippos" (horse) an so on. Each city would mint its own and have them stamped with recognizable symbols of the city, known as badge in numismatics, along with suitable inscriptions, and they would often be referred to either by the name of the city or of the image depicted. The exact exchange value of each was determined by the quantity and quality of the metal, which reflected on the reputation of each mint.
Among the Greek cities that used the drachma were: Abdera, Abydos, Alexandria, Aetna, Antioch, Athens, Chios, Cyzicus, Corinth, Ephesus, Eretria, Gela, Catana, Kos, Maronia, Naxos, Pella, Pergamum, Rhegion, Salamis, Smyrni, Sparta, Syracuse, Tarsus, Thasos, Tenedos, Troy and more.
The 5th century BC Athenian "tetradrachm" ("four drachmae") coin was perhaps the most widely used coin in the Greek world prior to the time of Alexander the Great (along with the Corinthian stater). It featured the helmeted profile bust of Athena on the obverse (front) and an owl on the reverse (back). In daily use they were called γλαῦκες "glaukes" (owls), hence the proverb Γλαῦκ’ Ἀθήναζε, 'an owl to Athens', referring to something that was in plentiful supply, like 'coals to Newcastle'. The reverse is featured on the national side of the modern Greek 1 euro coin.
Drachmae were minted on different weight standards at different Greek mints. The standard that came to be most commonly used was the Athenian or Attic one, which weighed a little over 4.3 grams.
After Alexander the Great's conquests, the name "drachma" was used in many of the Hellenistic kingdoms in the Middle East, including the Ptolemaic kingdom in Alexandria. The Arabic unit of currency known as "dirham" (in the Arabic language, درهم), known from pre-Islamic times and afterwards, inherited its name from the drachma or didrachm (δίδραχμον, 2 drachmae); the dirham is still the name of the official currencies of Morocco and the United Arab Emirates. The Armenian dram also derives its name from the drachma.
Value.
It is difficult to estimate comparative exchange rates with modern currency because the range of products produced by economies of centuries gone by were different from today, which makes purchasing power parity (PPP) calculations very difficult; however, some historians and economists have estimated that in the 5th century BC a drachma had a rough value of 25 U.S. dollars (in the year 1990 – equivalent to 41 USD in 2009), whereas classical historians regularly say that in the heyday of ancient Greece (the fifth and fourth centuries) the daily wage for a skilled worker or a hoplite was one drachma, and for a heliast (juror) half a drachma since 425 BC.
Modern commentators derived from Xenophon that half a drachma per day (360 days per year) would provide "a comfortable subsistence" for "the poor citizens" (for the head of a household in 355 BC). Earlier in 422 BC, we also see in Aristophanes ("Wasps", line 300-302) that the daily half-drachma of a juror is just enough for the daily subsistence of a family of three.
A modern person might think of one drachma as the rough equivalent of a skilled worker's daily pay in the place where they live, which could be as low as $1 USD, or as high as $100 USD, depending on the country.
Fractions and multiples of the drachma were minted by many states, most notably in Ptolemaic Egypt, which minted large coins in gold, silver and bronze.
Notable Ptolemaic coins included the gold "pentadrachm" and "octadrachm", and silver "tetradrachm", "decadrachm" and "pentakaidecadrachm". This was especially noteworthy as it would not be until the introduction of the Guldengroschen in 1486 that coins of substantial size (particularly in silver) would be minted in significant quantities.
For the Roman successors of the drachma, see Roman provincial coins.
Denominations of Ancient Greek drachma.
The weight of the silver drachma was approximately 4.3 grams, although weights varied significantly from one city-state to another. It was divided into six obols of 0.72 grams, which were subdivided into four tetartemoria of 0.18 grams, one of the smallest coins ever struck, approximately 5 - 7mm in diameter.
Historic currency divisions.
Minae and talents were never actually minted: they represented weight measures used for commodities (e.g. grain) as well as metals like silver or gold. The New Testament mentions both didrachma and, by implication, tetradrachma in context of the Temple tax. Luke's Gospel includes a parable told by Jesus of a woman with 10 drachmae, who lost one and searched her home until she found it. 
Modern drachma.
First modern drachma.
The drachma was reintroduced in May 1832, soon before the establishment of the modern state of Greece (with the exception of the subdivision Taurus). It replaced the "phoenix" at par. The drachma was subdivided into 100 lepta.
Coins.
The first coinage consisted of copper denominations of 1, 2, 5 and 10 lepta, silver denominations of ¼, ½, 1 and 5 drachmae and a gold coin of 20 drachmae. The drachma coin weighed 4.5 g and contained 90% silver, with the 20-drachma coin containing 5.8 g of gold.
In 1868, Greece joined the Latin Monetary Union and the drachma became equal in weight and value to the French franc. The new coinage issued consisted of copper coins of 1, 2, 5 and 10 lepta, with the 5- and 10-lepta coins bearing the names "obolos" (ὀβολός) and "diobolon" (διώβολον), respectively; silver coins of 20 and 50 lepta, 1, 2 and 5 drachmae and gold coins of 5, 10 and 20 drachmae. (Very small numbers of 50- and 100-drachma coins in gold were also issued.)
In 1894, cupro-nickel 5-, 10- and 20-lepta coins were introduced. No 1-lepton or 2-lepta coin had been issued since the late 1870s. Silver coins of 1 and 2 drachmae were last issued in 1911, and no coins were issued between 1912 and 1922, during which time the Latin Monetary Union collapsed due to World War I.
Between 1926 and 1930, a new coinage was introduced for the new Hellenic Republic, consisting of cupro-nickel coins in denominations of 20 lepta, 50 lepta, 1 drachma, and 2 drachmae; nickel coins of 5 drachmae; and silver coins of 10 and 20 drachmae. These were the last coins issued for the first modern drachma, and none were issued for the second.
Notes.
Notes were issued by the National Bank of Greece from 1841 until 2001 when the Greece joined the Euro. Early denominations ranged from 10 to 500 drachmae. Smaller denominations (1, 2, 3 and 5 drachmae) were issued from 1885, with the first 5-drachma notes being made by cutting 10-drachma notes in half. 
When Greece finally achieved its independence from the Ottoman Empire in 1828, the phoenix was introduced as the monetary unit; its use was short-lived, however, and in 1832 the phoenix was replaced by the drachma, adorned with the image of King Otto of Greece, who reigned as modern Greece’s first king from 1832 to 1862. The drachma was divided into 100 lepta. In 2002 the drachma ceased to be legal tender after the euro, the monetary unit of the European Union, became Greece’s sole currency.
Between 1917 and 1920, the Greek government issued paper money in denominations of 10 lepta, 50 lepta, 1 drachma, 2 drachmae, and 5 drachmae. The National Bank of Greece introduced 1000-drachma notes in 1901, and the Bank of Greece introduced 5000-drachma notes in 1928. The Greek government again issued notes between 1940 and 1944, in denominations ranging from 50 lepta to 20 drachmae.
During the German-Italian occupation of Greece from 1941 to 1944, catastrophic hyperinflation and Nazi looting of the Greek treasury caused much higher denominations to be issued, culminating in 100,000,000,000-drachma notes in 1944.
Second modern drachma.
In November 1944, after Greece was liberated from Germany, old drachmae were exchanged for new ones at the rate of 50,000,000,000 to 1. Only paper money was issued. The government issued notes of 1, 5, 10 and 20 drachmae, with the Bank of Greece issuing 50-, 100-, 500-, 1000-, 5000-, and 10,000-drachma notes. This drachma also suffered from high inflation. The government later issued 100-, 500-, and 1000-drachma notes, and the Bank of Greece issued 20,000-and 50,000-drachma notes.
Third modern drachma.
In 1953, in an effort to halt inflation, Greece joined the Bretton Woods system. In 1954, the drachma was revalued at a rate of 1000 to 1. The new currency was pegged at 30 drachmae = 1 United States dollar. In 1973, the Bretton Woods System was abolished; over the next 25 years the official exchange rate gradually declined, reaching 400 drachmae to 1 U. S. dollar. On 1 January 2002, the Greek drachma was officially replaced as the circulating currency by the euro, and it has not been legal tender since 1 March 2002.
Third modern drachma coins.
The first issue of coins minted in 1954 consisted of holed aluminium 5-, 10- and 20-lepta pieces, with 50-lepta, 1-, 2-, 5- and 10-drachma pieces in cupro-nickel. A silver 20-drachma piece was issued in 1960, replacing the 20-drachma banknote. Coins in denominations from 50 lepta to 20 drachmae carried a portrait of King Paul (1947–1964). New coins were introduced in 1966, ranging from 50 lepta to 10 drachmae, depicting King Constantine II (1964–1974). The reverse of all coins was altered in 1971 to reflect the military junta which was in power from 1967 to 1974. This design included a soldier standing in front of the flames of the rising phoenix.
A 20-drachmae coin in cupro-nickel with an image of Europa on the obverse was issued in 1973. In the latter part of 1973, several new coin types were introduced: unholed aluminium (10 and 20 lepta), nickel-brass (50 lepta, 1 drachma, and 2 drachmae) and cupro-nickel (5, 10, and 20 drachmae). These provisional coins carried the design of the phoenix rising from the flame on the obverse, and used the country's new designation as the "Hellenic Republic", replacing the coins also issued in 1973 as the Kingdom of Greece with King Constantine II's portrait. A new series of all 8 denominations was introduced in 1976 carrying images of early national heroes on the smaller values.
Cupro-nickel 50-drachmae coins were introduced in 1980. In 1986, nickel-brass 50-drachma coins were introduced, followed by copper 1- and 2-drachma pieces in 1988 and nickel-brass coins of 20 and 100 drachmae in 1990. In 2000, a set of 6 themed 500-drachma coins was issued to commemorate the 2004 Athens Olympic Games.
Coins in circulation at the time of the adoption of the euro were
Post Euro Drachma (XGD).
On Bloomberg terminals, Post Euro Drachma (XGD) was shown. According to Bloomberg, this was just "an internal function which is set up to test." 
Banknotes.
The first issues of banknotes were in denominations of 10, 20 and 50 drachmae, soon followed by 100, 500 and 1000 drachmae by 1956. 5000-drachma notes were introduced in 1984, followed by 10,000-drachma notes in 1995 and 200-drachma notes in 1997.
Banknotes in circulation at the time of the adoption of the euro were
Encoding.
In Unicode, the currency symbol is . A special Attic numeral represents a value of one drachma: .
Restoration.
The Drachmi Greek Democratic Movement Five Stars which was founded in 2013, aims to restore the Drachma, as Greece's currency.

</doc>
<doc id="8349" url="http://en.wikipedia.org/wiki?curid=8349" title="Denarius">
Denarius

In the Roman currency system, the denarius ( ; plural: denarii ) was a small silver coin first minted about 211 BC during the Second Punic War. It became the most common coin produced for circulation but was slowly debased in weight and silver content until its replacement by the double denarius, called the antoninianus, early in the 3rd century AD. The word "denarius" is derived from the Latin "dēnī" "containing ten", as its value was 10 asses, although in the middle of the 2nd century BC it was recalibrated so that it was now worth sixteen asses or four sestertii. It is the origin of several modern words such as the currency name dinar and the Italian common noun for money: "denaro". Its symbol is 𐆖.
History.
A predecessor of the denarius was first struck in 269 BC, five years before the first Punic War with an average weight of 6.8 grams,or 1⁄48 of a Roman pound. Contact with the Greeks prompted a need for silver coinage in addition to the bronze currency that the Romans were using during that time. The predecessor of the denarius was a Greek-styled silver coin, very similar to the didrachm and drachma struck in Metapontion and other Greek cities in southern Italy. These coins were inscribed for Rome but closely resemble their Greek counterparts. They were most likely used for trade purposes and were seldom used in Rome.
The first distinctively Roman silver coin appeared around 225 BC. Classic historians sometimes called these coins denarii in the past, but they are classified by modern numismatists as "quadrigati", which is derived from the quadriga, or four-horse chariot, on the reverse, and which with a two-horse chariot or biga was the prototype for the most common designs used on Roman silver coins for the next 150 years.
Rome overhauled its coinage around 211 BC and introduced the denarius alongside a short-lived denomination called the victoriatus. This denarius contained an average 4.5 grams, or 1⁄72 of a Roman pound of silver. It formed the backbone of Roman currency throughout the Roman republic.
The denarius began to undergo slow debasement toward the end of the republican period. Under the rule of Augustus, (63 BC-AD 14) its silver content fell to 3.9 grams (a theoretical weight of 1⁄84 of a Roman pound). It remained at nearly this weight until the time of Nero (AD 37-68), when it was reduced to 1⁄96 of a pound, or 3.4 grams. Debasement of the coin's silver content continued after Nero. Later Roman emperors reduced its content to 3 grams around the late third century.
The value at its introduction was 10 asses, giving the denarius its name, which translates as "containing ten". In about 141 BC, it was re-tariffed at 16 asses, to reflect the decrease in weight of the as. The denarius continued to be the main coin of the Roman Empire until it was replaced by the antoninianus in the middle of the third century. The last issuance of this coin occurred in bronze form by Aurelian, between AD 270 and 275, and in the first years of the reign of Diocletian. For more details, see 'Denarius', in "A Dictionary of Ancient Roman Coins", by John R. Melville-Jones (1990).
Comparisons and silver content.
It is problematic to give even rough comparative values for money from before the 20th century, as the range of products and services available for purchase was very different. Classical historians often say that in the late Roman Republic and early Roman Empire (~27BC) the daily wage for an unskilled laborer and common soldier was 1 denarius (with no tax deductions) or about US$20 in bread. During the republic, legionary pay was 112.5 denarii per year, later doubled by Julius Caesar to 225 denarii, with soldiers having to pay for their own food and arms. In contrast, centurions received considerably higher pay; under Augustus, the lowest ranking centurion was paid 3,750 denarii and the highest ranking, 15,000 denarii.
The silver content of the denarius under the Roman Empire (After Nero) was about 50 grains, 3.24 grams, or 1⁄10 (0.105ozt) troy ounce. In June 6, 2011, this corresponded to approximately US$3.62 in value if the silver were 0.999 pure.
The fineness of the silver content varied with political and economic circumstances. From a purity of greater than 90% silver in the first century A.D., the denarius fell to under 60% purity by the end of the second century A.D., and plummeted to 5% purity by the end of the third century A.D. By the reign of Gallienus, the antoninianus was a copper coin with a thin silver wash.
By comparison, a laborer earning the minimum wage in the United States in January 2014 made US$58 for an 8-hour day, before taxes (utilizing the mode value of $7.25 per hour, which was true then in 20 states) and a labourer earning the minimum wage in the United Kingdom in 2014 made GBP£52 for an 8-hour day, before taxes.
Influence.
Even after the denarius was no longer regularly issued, it continued to be used as a unit of account, and the name was applied to later Roman coins in a way that is not understood. The Arabs who conquered large parts of the land that once belonged to the Eastern Roman Empire issued their own gold dinar. The lasting legacy of the denarius can be seen in the use of "d" as the abbreviation for the British penny prior to 1971. It survived in France as the name of a coin, the denier. The denarius also survives in the common Arabic name for a currency unit, the "dinar" used from pre-Islamic times, and still used in several modern Arabic-speaking nations. The major currency unit in former Principality of Serbia, Kingdom of Serbia and former Yugoslavia was "dinar", and it is still used in present-day Serbia. The Macedonian currency "denar" is also derived from the Roman denarius. The Italian word "denaro", the Spanish word "dinero", the Portuguese word "dinheiro", and the Slovene word "denar", all meaning money, are also derived from Latin "denarius".
Value.
The gold "aureus" seems to have been a "currency of account," a denomination not commonly seen in daily transactions due to its high value. Numismatists think that the aureus was used to pay bonuses to the legions at the accession of new emperors. It was valued at 25 denarii.
1 gold aureus = 2 gold quinarii = 25 silver denarii = 50 silver quinarii = 100 bronze sestertii = 200 bronze dupondii = 400 copper asses = 800 copper semisses = 1600 copper quadrantes
In the New Testament, the gospels refer to the denarius as a day's wage for a common laborer (Matthew 20:2, John 12:5). and in the Book of Revelation, a choinix (or quart) of wheat and three quarts of barley were each valued at one denarius. 

</doc>
<doc id="8350" url="http://en.wikipedia.org/wiki?curid=8350" title="House of della Rovere">
House of della Rovere

Della Rovere is a noble family of Italy. Coming from modest beginnings in Savona, Liguria, the family rose to prominence through nepotism and ambitious marriages arranged by two Della Rovere popes, Francesco della Rovere, who ruled as Pope Sixtus IV (1471–1484) and his nephew Giuliano (Pope Julius II, 1503–1513). Pope Sixtus IV is known for having built the Sistine Chapel, which is named for him. The Basilica San Pietro in Vincoli in Rome is the family church of the della Rovere.
Guidobaldo da Montefeltro adopted Francesco Maria I della Rovere, his sister's child and nephew of Pope Julius II. Guidobaldo I, who was heirless, called Francesco Maria at his court, and named him as heir of the Duchy of Urbino in 1504, this through the intercession of Julius II. In 1508, Francesco Maria inherited the duchy thereby starting the line of Rovere Dukes of Urbino. That dynasty ended in 1626 when Pope Urban VIII incorporated Urbino into the papal dominions. As compensation to the last sovereign duke, the title only could be continued by Francesco Maria II, and after his death by his heir, Federico Ubaldo.
Vittoria, last descendant of the della Rovere family (she was the only child of Federico Ubaldo), married Ferdinando II de' Medici, Grand Duke of Tuscany. They had two children: Cosimo III, Tuscany's longest reigning monarch, and Francesco Maria de' Medici, a prince of the Church.
Family tree.
Dotted lines indicate duplicates (where a person appears more than once in the tree).<br>
Small caps text indicates the surname of the children (regardless of number) of a union.<br>
All persons have the surname Della Rovere unless otherwise indicated.

</doc>
<doc id="8351" url="http://en.wikipedia.org/wiki?curid=8351" title="David Mamet">
David Mamet

David Alan Mamet (; born November 30, 1947) is an American playwright, essayist, screenwriter, and film director. As a playwright, Mamet has won a Pulitzer Prize and received Tony nominations for "Glengarry Glen Ross" (1984) and "Speed-the-Plow" (1988). As a screenwriter, he has received Oscar nominations for "The Verdict" (1982) and "Wag the Dog" (1997). Mamet's books include: "The Old Religion" (1997), a novel about the lynching of Leo Frank; "Five Cities of Refuge: Weekly Reflections on Genesis, Exodus, Leviticus, Numbers and Deuteronomy" (2004), a Torah commentary with Rabbi Lawrence Kushner; "The Wicked Son" (2006), a study of Jewish self-hatred and antisemitism; "Bambi vs. Godzilla", a commentary on the movie business; "The Secret Knowledge: On the Dismantling of American Culture" (2011), a commentary on cultural and political issues; and "Three War Stories" (2013), a trio of novellas about the physical and psychological effects of war.
Feature films which Mamet both wrote and directed include "Redbelt" (2008), "The Spanish Prisoner" (1997), "House of Games" (1987) (which won Best Film and Best Screenplay awards at the 1987 Venice Film Festival and "Film of the Year" for the 1989 London Critics Circle Film Awards), "Spartan" (2004), "Heist" (2001), "State and Main" (2000) (Winner of a Best Acting - Ensemble award from the National Board of Review), "The Winslow Boy" (1999), and "Oleanna" (1994). This was accompanied by "Homicide" (1991) (nominated for the Palme d'Or at 1991 Cannes Film Festival and won a "Screenwriter of the Year" award for Mamet from the London Critics Circle Film Awards and Best Cinematography for Roger Deakins from the Los Angeles Film Critics Association Awards), "Things Change" (1988) (which won the Volpi Cup for Best Actor at 1988 Venice Film Festival for Don Ameche and Joe Mantegna), and most recently the 2013 HBO film "Phil Spector", starring Al Pacino as Spector with Helen Mirren and Jeffrey Tambor. His drama "Glengarry Glen Ross", in 1992, was adapted by Mamet into a film version which also received an Academy Award nomination.
Mamet has also written the screenplays for such films as "The Verdict" (1982), directed by Sidney Lumet, "The Postman Always Rings Twice" (1981), directed by Bob Rafelson, "The Untouchables" (1987) directed by Brian De Palma, "Hoffa" (1992), "Ronin" (1998), "Wag The Dog" (1997), "The Edge" (1997), and "Hannibal" (2001). Mamet was also the executive producer and frequent writer for the TV show "The Unit."
Early life.
Mamet was born in 1947 in Chicago to Jewish parents, Lenore June (née Silver), a teacher, and Bernard Morris Mamet, an attorney. One of his first jobs was as a busboy at Chicago's The Second City. He was educated at the progressive Francis W. Parker School and at Goddard College in Plainfield, Vermont. At the Chicago Public Library Foundation 20th anniversary fundraiser in 2006, though, Mamet announced "My alma mater is the Chicago Public Library. I got what little educational foundation I got in the third-floor reading room, under the tutelage of a Coca-Cola sign".
Career.
Theater.
Mamet is a founding member of the Atlantic Theater Company; he first gained acclaim for a trio of off-Broadway plays in 1976, "The Duck Variations," "Sexual Perversity in Chicago," and "American Buffalo." He was awarded the Pulitzer Prize in 1984 for "Glengarry Glen Ross," which received its first Broadway revival in the summer of 2005. His play "Race", which opened on Broadway on December 6, 2009 and featured James Spader, David Alan Grier, Kerry Washington, and Richard Thomas in the cast, received mixed reviews. His play "The Anarchist", starring Patti LuPone and Debra Winger, in her Broadway debut, opened on Broadway on November 13, 2012 in previews and was scheduled to close on December 16, 2012.
In 2002, Mamet was inducted into the American Theatre Hall of Fame. Mamet later received the PEN/Laura Pels International Foundation for Theater Award for Grand Master of American Theater in 2010.
Film.
Mamet's feature films, which he both wrote and directed, include in chronological order: his feature directorial debut "House of Games" (1987) (which won Best Film and Best Screenplay awards at the 1987 Venice Film Festival and "Film of the Year" for the 1989 London Critics Circle Film Awards), "Things Change" (1988), "Homicide" (1991) (nominated for the Palme d'Or at 1991 Cannes Film Festival and won a "Screenwriter of the Year" award for Mamet from the London Critics Circle Film Awards and Best Cinematography from Roger Deakins from the Los Angeles Film Critics Association Awards), "Oleanna" (1994), "The Spanish Prisoner" (1997), "The Winslow Boy" (1999), "State and Main" (2000), "Heist" (2001), "Spartan" (2004), "Redbelt" (2008), and in 2012 a bio-pic TV movie "Phil Spector" about the American record producer and songwriter Phil Spector starring Al Pacino as Spector, as well as Helen Mirren and Jeffrey Tambor. His latest feature-length film, a thriller titled "Blackbird", is slated for release in 2015. "Blackbird" will star James Badge Dale as “a military major who is trying to discover the truth about the political secrets of a woman’s grandfather who worked for the U.S. special ops during the 1960s,” according to Deadline.com.
Mamet has also written the screenplays for such classic films as "The Verdict" (1982), directed by Sidney Lumet, "The Postman Always Rings Twice" (1981), "The Untouchables" (1987) directed by Brian De Palma, "Hoffa" (1992), "The Edge" (1997), "Wag The Dog" (1997), "Ronin" (1998), and "Hannibal" (2001).
Mamet's first produced screenplay was the 1981 production of "The Postman Always Rings Twice" (directed by Bob Rafelson), based upon James M. Cain's novel. He received an Academy Award nomination one year later for his first script, "The Verdict", written in the late 1970s. He also wrote the screenplay for "The Untouchables."
In 1987, Mamet made his film directing debut with "House of Games", starring his then-wife, Lindsay Crouse, and a host of longtime stage associates. He uses friends as actors, especially in one early scene in the movie, which featured Vermont poker playing friends. He is quoted as saying, "It was my first film as a director and I needed support, so I stacked the deck." Two of the four poker friends included in the film were fellow Goddard College graduates Allen Soule and Bob Silverstein. Three of Mamet's own films, "House of Games", "The Spanish Prisoner", and "Heist," have involved the world of con artists.
Mamet adapted "Glengarry Glen Ross" for the cinema in 1992, writing an additional part (including the monologue "Coffee's for closers") for Alec Baldwin.
Mamet remains a writer and director, and has assembled an informal repertory company for his films, including Crouse, William H. Macy, Joe Mantegna, Rebecca Pidgeon, and Ricky Jay, as well as some of the aforementioned poker associates. Mamet has funded his own films with payments he receives for credited and uncredited rewrites of typically big-budget films. For instance, Mamet did a rewrite of the script for "Ronin" under the pseudonym "Richard Weisz" and turned in an early version of a script for "Malcolm X" that director Spike Lee rejected. In 2000, Mamet directed a film version of "Catastrophe," a one-act play by Samuel Beckett featuring Harold Pinter and John Gielgud (in his final screen performance). In 2008, he directed and wrote the mixed martial arts movie "Redbelt," about a martial arts instructor tricked into fighting in a professional bout. Mamet teamed up with his wife Rebecca Pidgeon to adapt the novel "Come Back to Sorrento" as a screenplay. The film was in development during 2010. He is also director of the TV film "Phil Spector".
In "On Directing Film," Mamet asserts that directors should focus on getting the point of a scene across, rather than simply following a protagonist, or adding visually beautiful or intriguing shots. Films should create order from disorder in search of the objective.
Books.
In 1990 Mamet published "The Hero Pony", a 55-page collection of poetry. He has also published a series of short plays, monologues and three novels, "The Village" (1994), "The Old Religion" (1997), and "Wilson: A Consideration of the Sources" (2000). He has written several non-fiction texts, and children's stories. In 2004 he published a lauded version of the classical Faust story, "Faustus", however, the play, when staged in San Francisco during the spring of 2004, was not well received by critics. On May 1, 2010, Mamet released a graphic novel "The Trials of Roderick Spode (The Human Ant)".
On June 2, 2011, "The Secret Knowledge: On the Dismantling of American Culture", Mamet's book detailing his conversion from modern liberalism to "a reformed liberal" was released.
Mamet published "Three War Stories", a collection of novellas, on November 11, 2013. In an interview with Newsmax TV, Mamet said he wanted to write about war, despite never having served. Moreover, the book allowed Mamet to free characters that had occupied his mind for years. On the subject of characters as a reason for writing, Mamet told the host, “You want to get these guys out of your head. You just want them to stop talking to you."
Television and radio.
Mamet wrote the "Wasted Weekend" episode of "Hill Street Blues" that aired in 1987. His then-wife, Lindsay Crouse, appeared in numerous episodes (including that one) as Officer McBride. Mamet is also the creator, producer and frequent writer of the television series "The Unit", where he wrote a well-circulated to the writing staff. He directed a third season episode of "The Shield" with Shawn Ryan. In 2007, Mamet directed two television commercials for Ford Motor Company. The two 30-second ads featured the Ford Edge and were filmed in Mamet's signature style of fast-paced dialogue and clear, simple imagery. Mamet's sister, Lynn, is a producer and writer for television shows, such as "The Unit" and "Law & Order".
Mamet has contributed several dramas to BBC Radio through Jarvis & Ayres Productions, including an adaptation of "Glengarry Glen Ross" for BBC Radio 3 and new dramas for BBC Radio 4. The comedy "Keep Your Pantheon, (or On the Whole I'd Rather Be in Mesopotamia)" was aired in 2007.
Other media and political views.
Since May 2005 he has been a contributing blogger at "The Huffington Post", drawing satirical cartoons with themes including political strife in Israel. In a 2008 article for the "Village Voice" headlined "Why I Am No Longer a 'Brain-Dead Liberal" he revealed that he had gradually rejected political correctness and progressivism and embraced conservatism. Mamet has spoken in interviews of changes in his views, highlighting his agreement with free market theorists such as Friedrich Hayek the historian Paul Johnson, and economist Thomas Sowell, whom Mamet called "one of our greatest minds".
During promotion of a book, Mamet was criticized for claiming that the British people had "a taint of anti-semitism", claiming they "want to give [Israel] away". In the same interview, Mamet went on to say that "there are famous dramatists and novelists [in the UK] whose works are full of anti-Semitic filth", but that he could not specify to whom he was referring for fear of litigation. He is known for his pro-Israel positions; in his book "The Secret Knowledge" he claimed that "Israelis would like to live in peace within their borders; the Arabs would like to kill them all".
In November 2012 Mamet penned an article for the "The Jewish Journal of Greater Los Angeles" imploring fellow Jewish Americans to vote for Republican nominee Mitt Romney.
January 29, 2013 Mamet wrote an essay for "Newsweek" in which he argued against gun control laws, writing that "[i]t was intended to guard us against this inevitable decay of government that the Constitution was written. Its purpose was and is not to enthrone a Government superior to an imperfect and confused electorate, but to protect us from such a government."
Critical reception of Mamet.
"Mamet speak".
Mamet's style of writing dialogue, marked by a cynical, street-smart edge, precisely crafted for effect, is so distinctive that it has come to be called "Mamet speak." Mamet has recognized an association of his edgy narrative style by noting his debt to Harold Pinter, to whom he dedicated "Glengarry Glen Ross". He often uses italics and quotation marks to highlight particular words and to draw attention to his characters' frequent manipulation and deceitful use of language. His characters frequently interrupt one another, their sentences trail off unfinished, and their dialogue overlaps. Moreover, certain expressions and figures of speech are deliberately misrepresented to show that the character is not paying close attention to every detail of his dialogue (e.g., "or so forth" instead of "and so forth"). Mamet himself has criticized his (and other writers') tendency to write "pretty" at the expense of sound, logical plots.
When asked how he developed his style for writing dialogue, Mamet said, "In my family, in the days prior to television, we liked to while away the evenings by making ourselves miserable, based solely on our ability to speak the language viciously. That's probably where my ability was honed."
One instance of Mamet's dialogue style can be found in "Glengarry Glen Ross", in which two down-on-their-luck real estate salesmen are considering stealing from their employer's office. George Aaronow and Dave Moss equivocate on the meaning of "talk" and "speak", turning language and meaning to deceptive purposes:
Mamet dedicated "Glengarry Glen Ross" to Harold Pinter, who was instrumental in its being first staged at the Royal National Theatre, (London) in 1983, and whom Mamet has acknowledged as an influence on its success, and on his other work.
Mamet and gender issues.
Arthur Holmberg in his 2014 book "David Mamet and Male Friendship", has reconsidered the gender issue in many of Mamet's plays throughout his career by asserting a prominent and recurrent reversed sexual orientation of portrayed male gender preferences.
Personal life.
Mamet and actress Lindsay Crouse were married in 1977 and divorced in 1990. He and Crouse have two children, Willa and Zosia. Willa is a professional photographer and Zosia is an actress. Mamet has been married to actress and singer-songwriter Rebecca Pidgeon since 1991. They have two children, Clara and Noah.
Works.
Mamet is credited as writer of these works except where noted.

</doc>
<doc id="8352" url="http://en.wikipedia.org/wiki?curid=8352" title="December 6">
December 6

December 6 is the day of the year in the Gregorian calendar.

</doc>
<doc id="8353" url="http://en.wikipedia.org/wiki?curid=8353" title="December 5">
December 5

December 5 is the day of the year in the Gregorian calendar.

</doc>
<doc id="8354" url="http://en.wikipedia.org/wiki?curid=8354" title="December 4">
December 4

December 4 is the day of the year in the Gregorian calendar.

</doc>
<doc id="8355" url="http://en.wikipedia.org/wiki?curid=8355" title="December 3">
December 3

December 3 is the day of the year in the Gregorian calendar.

</doc>
<doc id="8356" url="http://en.wikipedia.org/wiki?curid=8356" title="December 2">
December 2

December 2 is the day of the year in the Gregorian calendar.

</doc>
<doc id="8357" url="http://en.wikipedia.org/wiki?curid=8357" title="December 1">
December 1

December 1 is the day of the year in the Gregorian calendar.

</doc>
<doc id="8359" url="http://en.wikipedia.org/wiki?curid=8359" title="December 24">
December 24

December 24 is the day of the year in the Gregorian calendar.

</doc>
<doc id="8360" url="http://en.wikipedia.org/wiki?curid=8360" title="December 26">
December 26

December 26 is the day of the year in the Gregorian calendar.

</doc>
<doc id="8361" url="http://en.wikipedia.org/wiki?curid=8361" title="Definable real number">
Definable real number

A real number "a" is first-order definable in the language of set theory, without parameters, if there is a formula "φ" in the language of set theory, with one free variable, such that "a" is the unique real number such that "φ(a)" holds in the standard model of set theory (see Kunen 1980:153). 
For the purposes of this article, such reals will be called simply definable numbers. This should not be understood to be standard terminology.
Note that this definition cannot be expressed in the language of set theory itself.
General facts.
Assuming they form a set, the definable numbers form a field containing all the familiar real numbers such as 0, 1, π, "e", et cetera. In particular, this field contains all the numbers named in the mathematical constants article, and all algebraic numbers (and therefore all rational numbers). However, most real numbers are not definable: the set of all definable numbers is countably infinite (because the set of all logical formulas is) while the set of real numbers is uncountably infinite (see Cantor's diagonal argument). As a result, most real numbers have no description (in the same sense of "most" as 'most real numbers are not rational').
The field of definable numbers is not complete; there exist cauchy sequences of definable numbers whose limit is not definable (since every real number is the limit of a sequence of rational numbers). However, if the sequence itself is definable in the sense that we can specify a single formula for all its terms, then its limit will necessarily be a definable number.
While every computable number is definable, the converse is not true: the numeric representations of the Halting problem, Chaitin's constant, the truth set of first order arithmetic, and 0# are examples of numbers that are definable but not computable. Many other such numbers are known.
One may also wish to talk about definable complex numbers: complex numbers which are uniquely defined by a logical formula. However, whether this is possible depends on how the field of complex numbers is derived in the first place: it may not be possible to distinguish a complex number from its conjugate (say, 3+i from 3-i), since it is impossible to find a property of one that is not also a property of the other, without falling back on the underlying set-theoretic definition. Assuming we can define at least one nonreal complex number, however, a complex number is definable if and only if both its real part and its imaginary part are definable. The definable complex numbers also form a field if they form a set.
The related concept of "standard" numbers, which can only be defined within a finite time and space, is used to motivate axiomatic internal set theory, and provide a workable formulation for illimited and infinitesimal number. Definitions of the hyper-real line within non-standard analysis (the subject area dealing with such numbers) overwhelmingly include the usual, uncountable set of real numbers as a subset.
Notion does not exhaust "unambiguously described" numbers.
Not every number that we would informally say has been unambiguously described, is definable in the above sense. For example, if we can enumerate all such definable numbers by the Gödel numbers of their defining formulas then we can use Cantor's diagonal argument to find a particular real that is not first-order definable in the same language. The argument can be made as follows:
Suppose that in a mathematical language L, it is possible to enumerate all of the defined numbers in L. Let this enumeration be defined by the function G: W → R, where G(n) is the real number described by the nth description in the sequence. Using the diagonal argument, it is possible to define a real number x, which is not equal to G(n) for any n. This means that there is a language L' that defines x, which is undefinable in L.
Other notions of definability.
The notion of definability treated in this article has been chosen primarily for definiteness, not on the grounds that it's more useful or interesting than other notions. Here we treat a few others:
Definability in other languages or structures.
Language of arithmetic.
The language of arithmetic has symbols for 0, 1, the successor operation, addition, and multiplication, intended to be interpreted in the usual way over the natural numbers. Since no variables of this language range over the real numbers, we cannot simply copy the earlier definition of definability. Rather, we say that a real "a" is definable in the language of arithmetic (or arithmetical) if its Dedekind cut can be defined as a predicate in that language; that is, if there is a first-order formula "φ" in the language of arithmetic, with two free variables, such that
2nd-order language of arithmetic.
The second-order language of arithmetic is the same as the first-order language, except that variables and quantifiers are allowed to range over sets of naturals. A real that is second-order definable in the language of arithmetic is called analytical.
Definability with ordinal parameters.
Sometimes it is of interest to consider definability "with parameters"; that is, to give a definition relative to another object that remains undefined. For example, a real "a" (or for that matter, any set "a") is called ordinal definable if there is a first-order formula "φ" in the language of set theory, with "two" free variables, and an ordinal γ, such that "a" is the unique object such that "φ"("a",γ) holds (in V).
The other sorts of definability thus far considered have only countably many defining formulas, and therefore allow only countably many definable reals. This is not true for ordinal definability, because an ordinal definable real is defined not only by the formula "φ", but also by the ordinal γ. In fact it is consistent with ZFC that "all" reals are ordinal-definable, and therefore that there are uncountably many ordinal-definable reals. However it is also consistent with ZFC that there are only countably many ordinal-definable reals.
References.
 

</doc>
<doc id="8362" url="http://en.wikipedia.org/wiki?curid=8362" title="Diego de Almagro">
Diego de Almagro

Diego de Almagro, (c. 1475 – July 8, 1538), also known as El Adelantado and El Viejo (The Elder), was a Spanish conquistador and a companion and later rival of Francisco Pizarro. He participated in the Spanish conquest of Peru and is credited as the first European discoverer of Chile.
Almagro lost his left eye battling with coastal natives in the New World. In 1525 he joined the Pizarro brothers and Hernándo de Luque at Panama for the conquest of Peru.
Early years.
Diego de Almagro was born and raised in Almagro, Ciudad Real, Spain.
Arrival in America.
Diego de Almagro arrived in the New World on June 30, 1514, under the expedition that Ferdinand II of Aragon had sent under the guidance of Pedrarias Dávila. The expedition had landed in the city of Santa María la Antigua del Darién, Panama, where many other future conquistadors had already arrived, among them Francisco Pizarro.
There are not many details of Almagro's activities during this period, but it is known that he accompanied various sailors who departed from the city of Darien between 1514 and 1515. Almagro eventually returned and settled in Darien, where he was granted an encomienda. He built a house and made a living from agriculture.
Almagro undertook his first conquest on November 1515, commanding 260 men as he founded Villa del Acla, named after the Indian place. Due to illness he had to leave behind this mission to the licenciate Gaspar de Espinosa.
Espinosa decided to undertake a new expedition, which departed in December of 1515 with 200 men, including Almagro and Francisco Pizarro, who for the first time was designated as a captain. During this expedition, which lasted 14 months, Almagro, Pizarro and Hernando de Luque became close friends.
Also during this time Almagro established a friendship with Vasco Núñez de Balboa, who was in charge of Acla. Almagro wanted to have a ship built with the remaining materials of the Espinosa expedition, to be finished on the coast of the "Great South Sea," as the Pacific Ocean was first called by the Spanish. Current historians do not believe that Almagro was expected to participate in Balboa's expedition and probably returned to Darien.
Almagro took part in the various expeditions that took place in the Gulf of Panama, taking part again in Espinosa's parties. Espinosa was supported by using Balboa's ships. Almagro was recorded as a witness on the lists of natives whom Espinosa ordered to be carried. Almagro remained as an early settler in the newly founded city of Panama. For four years he stayed there, working at the management of his properties and those of Pizarro. He took Ana Martínez, an indigenous woman, as a common-law wife. In this period, his first son, el "Mozo", was born to them.
Conquest of Peru.
By 1524 an association of conquest regarding South America was formalized among Almagro, Pizarro and Luque.:24 By the beginning of August 1524, they had received the requisite permission to discover and conquer lands further south. Almagro would remain in Panama to recruit men and gather supplies for the expeditions led by Pizarro.:92-102 
After several expeditions to South America, Pizarro secured his stay in Peru with the "Capitulation" on 6 July 1529.:133 During Pizarro's continued exploration of Incan territry, he and his men succeeded in defeating the Incan army under Emperor Atahualpa during the Battle of Cajamarca in 1532. Almagro joined Pizarro soon afterward, bringing more men and arms.:219-222,233
After Peru fell to the Spanish, both Pizarro and Almagro initially worked together in the founding of new cities to consolidate their dominions. As such, Pizarro dispatched Almagro to pursue Quizquiz, fleeing to the Inca Empire's northern city of Quito. Their fellow conquistador Sebastián de Belalcázar, who had gone forth without Pizarro's approval, had already reached Quito and witnessed the destruction of the city by Inca general Rumiñawi. The Inca warrior had ordered the city to be burned and its gold to be buried at an undisclosed location where the Spanish could never find it. The arrival of Pedro de Alvarado from Guatemala, in search of Inca gold further complicated the situation for Almagro and Belalcázar. Alvarado's presence, however, did not last long as he left South America in exchange for monetary compensation from Pizarro.:223-227
In an attempt to claim Quito ahead of Belalcázar, in August 1534 Almagro founded a city on the shores of Laguna de Colta (Colta Lake) in the foothills of Chimborazo, some 90 miles south of present-day Quito, and named it "Santiago de Quito." Four months later would come the foundation of the Peruvian city of Trujillo, which Almagro named as "Villa Trujillo de Nueva Castilla" (the Village of Trujillo in New Castille) in honor of Francisco Pizarro's birthplace, Trujillo in Extremadura, Spain. These events were the height of the Pizarro-Almagro friendship, which historians describe as one of the last events in which their friendship soon faded and entered a period of turmoil for the control of the Incan capital of Cuzco.
Conflict with Pizarro.
After splitting the treasure of Inca emperor Atahualpa, both Pizarro and Almagro left towards Cuzco and took the city in 1533. However, Almagro's friendship with Pizarro showed signs of deterioration in 1526 when Pizarro, in the name of the rest of the conquistadors, called forth the "Capitulacion de Toledo" law in which King Charles I of Spain had laid out his authorization for the conquest of Peru and the awards every conquistador would receive from it. Long before, however, each conquistador had promised to equally split the benefits. Pizarro managed to have a larger stake and awards for himself. Despite this, Almagro still obtained an important fortune for his services, and the King awarded him in November 1532 the noble title of "Don" and he was assigned a personal coat of arms.
Although by this time Diego de Almagro had already acquired sufficient wealth in the conquest of Peru and was living a luxurious life in Cuzco, the prospect of conquering the lands further south was very attractive to him. Given that the dispute with Pizarro over Cuzco had kept intensifying, Almagro spent a great deal of time and money equipping a company of 500 men for a new exploration south of Peru.
By 1534 the Spanish crown had determined to split the region in two parallel lines, forming the governorship of "Nueva Castilla" (from the 1° to the 14° latitude, close to Pisco), and that of "Nueva Toledo" (from the 14° to the 25° latitude, in Taltal, Chile), assigning the first to Francisco Pizarro and the second to Diego de Almagro. The crown had previously assigned Almagro the governorship of Cuzco, and as such Almagro was heading there when Charles V divided the territory between Nueva Castilla and Nueva Toledo. This might have been the reason why Almagro did not immediately confront Pizarro for Cuzco, and promptly decided to embark on his new quest for the discovery of the riches of Chile.
Discovery of Chile.
The preparations.
Charles V had given Diego a grant extending two hundred leagues south of Francisco Pizarro's. Francisco and Diego concluded a new contract on 12 June 1535, in which they agreed to share future discoveries equally. Diego raised an expedition for Chile, expecting it "would lead to even greater riches than they had found in Peru.":230,233-234 Almagro prepared the way by sending ahead three of his Spanish soldiers, the religious chief of the Inca empire, "Willaq Umu," and Paullo Topa, brother of "Manco Inca Yupanqui." Almagro sent Juan de Saavedra forward with one hundred and fifty men, and soon followed them with additional forces.:230,233-234
Following the Inca Trail and crossing the Andes.
Almagro left Cuzco on July 3, 1535 with his supporters and stopped at Moina until the 20th of that month. Meanwhile, Francisco Pizarro's brother, Juan Pizarro, had arrested Inca Manco Inca Yupanqui, further complicating Almagro's plans as it heavily increased the dissatisfaction of the Indians submitted to Spanish rule. Not having formally been appointed governor of any territories in the Capitulation of Toledo in 1528, however, forcing him to declare himself "adelantado" (governor) of Nueva Toledo, or southern Peru and present-day Chile. Some sources suggest Almagro received such a requirement in 1534 by the Spanish king and was officially declared governor of New Toledo.
Once he left Moina, Almagro followed the Inca trail followed by 750 Spaniards deciding to join him in quest for the gold lost in the ransom of Atahualpa, which had mainly benefited the Pizarro brothers and their supporters. After crossing the Bolivian mountain range and traveling past Lake Titicaca, Almagro arrived on the shores of the Desaguadero River and finally set up camp in Tupiza. From there, the expedition stopped at Chicoana and then turned to the southeast to cross the Andes mountains.
The expedition turned out to be a difficult and exhausting endeavor. The hardest phase was the crossing of the Andes cordillera: the cold, hunger and tiredness meant the death of various Spaniards and natives, but mainly slaves who were not accustomed to such rigorous climate.:252-253 
Upon this point, Almagro determined everything was a failure. He ordered a small group under Rodrigo Orgonez on a reconnaissance of the country to the south.:253 
By luck, these men found the Valley of Copiapó, where a Spaniard called Gonzalo Calvo Barrientos, a Spaniard whom Pizarro had expelled from Peru for stealing objects the Inca had offered for his ransom, had already established a friendship with the local natives. There, in the valley of the river Copiapó, Almagro took official possession of Chile and claimed it in the name of King Charles V.
Dismayed in Chile.
Almagro promptly initiated the exploration of the new territory, starting up the valley the Aconcagua River, where he was well received by the natives. However, the intrigues of his interpreter, Felipillo, who had previously helped Pizarro in dealing with "Atahualpa", almost thwarted Almagro's efforts. Felipillo had secretly urged the local natives to attack the Spanish, but they desisted, not understanding the dangers that they posed. Almagro directed Gómez de Alvarado along with 100 horsemen and 100 foot to continue the exploration, which ended in the confluence of the Ñuble and Itata rivers. The Battle of Reinohuelén between the Spanish and hostile Mapuche Indians forced the explorers to return to the north. 
Almagro's own reconnaissance of the land and the bad news of Gómez de Alvarado's encounter with the fierce Mapuche, along with the bitter cold winter that settled ferociously upon them, only served to confirm that everything had failed. He never found gold or the cities which Incan scouts had told him lay ahead, only communities of the indigenous population who lived from subsistence agriculture. Local tribes put up fierce resistance to the Spanish forces. The exploration of the territories of Nueva Toledo, which lasted 2 years, was marked by a complete failure for Almagro. Despite this, at first he thought staying and founding a city would serve well for his honor. The initial optimism that led Almagro to bring his son he had with the indigenous Panamanian Ana Martínez to Chile had faded. 
Some historians have suggested that, but for the urging of his senior explorers, Almagro would probably have stayed permanently in Chile. He was urged to return to Peru and this time take definitive possession of Cuzco, so as to consolidate an inheritance for his son. Dismayed with his experience in the south, Almagro made plans of return to Peru. He never officially founded a city in the territory of what is now Chile.:254
The withdrawal of the Spanish from valleys of Chile was violent: Almagro authorized his soldiers to ransack the natives' properties, leaving their soil desolate. In addition, the Spanish soldiers took natives captive to serve as slaves. The locals were captured, tied together, and forced to carry the heavy loads belonging to the conquistadors.
Return to Peru.
After the exhausting crossing of the Atacama Desert, mainly due to the weather conditions, Almagro finally reached Cuzco, Peru, in 1537.:254 According to some authors, it was during this time that the Spanish term "roto" (torn), used by Peruvians to refer to Chileans, was first coined. Almagro's disappointed troops returned to Cuzco with their "torn clothes" due to the extensive and laborious passage on foot by the Atacama Desert.
After his return, Almagro was surprised to learn of the Inca Manco's rebellion. Almagro sent an embassy to the Inca, but they mistrusted all of the Spaniards by this time. Hernando Pizarro's men formed an uneasy truce with Almagro's men, surveying to determine the boundaries of their leaders' royal grants. They needed to determine in which portion the city of Cuzco was located. However, Almagro's troops quickly took the city and imprisoned the Pizarro brothers, Hernando and Gonzalo, on the night of 8 April 1537.:254-256
After occupying Cuzco, Almagro confronted an army sent by Francisco Pizarro to liberate his brothers. Alonso de Alvarado commanded it and was defeated during the Battle of Abancay on July 12, 1537.:257 He and some of his men were imprisoned. Later, Gonzalo Pizarro and Alvarado escaped prison. Subsequent negotiations between Francisco Pizarro and Almagro concluded with the liberation of Hernando, the third Pizzarro brother, in return for conceding control and administration of Cuzco to Almagro. Pizarro never intended to give up the city permanently, but was buying time to organize an army strong enough to defeat Almagro's troops.:260-262
During this time Almagro fell ill, and Pizarro and his brothers grabbed the opportunity to defeat him and his followers. The Almagristas were defeated at Las Salinas in April 1538, with Orgóñez being killed on the field of battle. Almagro fled to Cuzco, still in the hands of his loyal supporters, but found only temporary refuge; the forces of the Pizarro brothers entered the city without resistance. Once captured, Almagro was humiliated by Hernando Pizarro and his requests to appeal to the King were ignored. 
As Almagro begged for his life, Hernando responded::262-268
"-he was surprised to see Lamagro demean himself in a manner so unbecoming a brave cavalier, that his fate was no worse than had befallen many a soldier before him; and that, since God had given him the grace to be a Christian, he should employ his remaining moments in making up his account with Heaven!"
Almagro was condemned to death and executed by "garrote" in his dungeon, and then decapitated, on July 8, 1538. His corpse was taken to the public Plaza Mayor of Cuzco, where a herald proclaimed his crimes. Hernan Ponce de Leon took his body and buried him in the church of Our Lady of Mercy in Cuzco.:269
El Mozo.
Diego de Almagro II (1520–1542), known as "El Mozo" (The Lad), son of Diego de Almagro I, whose mother was an Indian girl of Panama, became the foil of the conspirators who had put Pizarro to the sword. Pizarro was murdered on June 26, 1541; the conspirators promptly proclaimed the lad Almagro Governor of Peru. From various causes, all of the conspirators either died or were killed except for one, who was executed after the lad Almagro gave an order. The lad Almagro fought the desperate battle of Chupas on September 16, 1542, escaped to Cuzco, but was arrested, immediately condemned to death, and executed in the great square of the city.

</doc>
<doc id="8363" url="http://en.wikipedia.org/wiki?curid=8363" title="Divinity">
Divinity

In religious terms, divinity or godhead is the state of things that come from a supernatural power or deity, such as a god, supreme being, Creator god or spirits, and are therefore regarded as sacred and holy.
Such things are regarded as "divine" due to their transcendental origins, and/or because their attributes or qualities are superior or supreme relative to things of the Earth. Divine things are regarded as eternal and based in truth, while material things are regarded as ephemeral and based in illusion. Such things that may qualify as "divine" are apparitions, visions, prophecies, miracles, and in some views also the soul, or more general things like resurrection, immortality, grace, and salvation. Otherwise what is or is not divine may be loosely defined, as it is used by different belief systems.
The root of the word "divine" is literally "godly" (from the Latin "deus", cf. "Dyaus", closely related to Greek "zeus", "div" in Persian and "deva" in Sanskrit), but the use varies significantly depending on which deity is being discussed. This article outlines the major distinctions in the conventional use of the terms.
For specific related academic terms, see Divinity (academic discipline), or Divine (Anglican).
Usages.
Divinity as a quality has two distinct usages:
Overlap occurs between these usages because deities or godly entities are often identical with and/or identified by the powers and forces that are credited to them — in many cases a deity is merely a power or force personified — and these powers and forces may then be extended or granted to mortal individuals. For instance, Jehovah is closely associated with storms and thunder throughout much of the Old Testament. He is said to speak in thunder, and thunder is seen as a token of his anger. This power was then extended to prophets like Moses and Samuel, who caused thunderous storms to rain down on their enemies. (See and 1 Samuel 12:18.)
Divinity always carries connotations of goodness, beauty, beneficence, justice, and other positive, pro-social attributes. In monotheistic faiths there is an equivalent cohort of malefic supranormal beings and powers, such as demons, devils, afreet, etc., which are not conventionally referred to as divine; "demonic" is often used instead. Pantheistic and polytheistic faiths make no such distinction; gods and other beings of transcendent power often have complex, ignoble, or even irrational motivations for their acts. Note that while the terms "demon" and "demonic" are used in monotheistic faiths as antonyms to "divine", they are in fact derived from the Greek word "daimón" (δαίμων), which itself translates as "divinity".
There are three distinct usages of "divinity" and "divine" in religious discourse:
Entity.
In monotheistic faiths, the word "divinity" is often used to refer to the singular God central to that faith. Often the word takes the definite article and is capitalized — "the Divinity" — as though it were a proper name or definitive honorific. 
"Divine" — capitalized — may be used as an adjective to refer to the manifestations of such a Divinity or its powers: e.g. "basking in the Divine presence..."
The terms "divinity" and "divine" — uncapitalized, and lacking the definite article — are sometimes used as to denote 'god(s) or certain other beings and entities which fall short of godhood but lie outside the human realm. These include (by no means an exhaustive list):
Divine force or power.
As previously noted, divinities are closely related to the transcendent force(s) or power(s) credited to them, so much so that in some cases the powers or forces may themselves be invoked independently. This leads to the second usage of the word "divine" (and a less common usage of "divinity"): to refer to the operation of transcendent power in the world.
In its most direct form, the operation of transcendent power implies some form of divine intervention. For pan- and polytheistic faiths this usually implies the direct action of one god or another on the course of human events. In Greek legend, for instance, it was Poseidon (god of the sea) who raised the storms which blew Odysseus' craft off course on his return journey, and Japanese tradition holds that a god-sent wind saved them from Mongol invasion. Prayers or propitiations are often offered to specific gods of pantheisms to garner favorable interventions in particular enterprises: e.g. safe journeys, success in war, or a season of bountiful crops. Many faiths around the world — from Japanese Shinto and Chinese traditional religion, to certain African practices and the faiths derived from those in the Caribbean, to Native American beliefs — hold that ancestral or household spirits offer daily protection and blessings. In monotheistic religions, divine intervention may take very direct forms: miracles, visions, or intercessions by blessed figures.
Transcendent force or power may also operate through more subtle and indirect paths. Monotheistic faiths generally support some version of divine providence, which acknowledges that the divinity of the faith has a profound but unknowable plan always unfolding in the world. Unforeseeable, overwhelming, or seemingly unjust events are often thrown on 'the will of the Divine', in deferences like the Muslim "inshallah" ('as God wills it') and Christian 'God works in mysterious ways'. Often such faiths hold out the possibility of divine retribution as well, where the divinity will unexpectedly bring evil-doers to justice through the conventional workings of the world; from the subtle redressing of minor personal wrongs, to such large-scale havoc as the destruction of Sodom and Gomorrah or the biblical Great Flood. Other faiths are even more subtle: the doctrine of "karma" shared by Buddhism and Hinduism is a divine law similar to divine retribution but without the connotation of punishment: our acts, good or bad, intentional or unintentional, reflect back on us as part of the natural working of the universe. Philosophical Taoism also proposes a transcendent operant principle — transliterated in English as "tao" or "dao", meaning 'the way' — which is neither an entity or a being per se, but reflects the natural ongoing process of the world. Modern western mysticism and new age philosophy often use the term 'the Divine' as a noun in this latter sense: a non-specific principle and/or being that gives rise to the world, and acts as the source or wellspring of life. In these latter cases the faiths do not promote deference, as happens in monotheisms; rather each suggests a path of action that will bring the practitioner into conformance with the divine law: "ahimsa" — 'no harm' — for Buddhist and Hindu faiths; "de" or "te" — 'virtuous action' — in Taoism; and any of numerous practices of peace and love in new age thinking.
Mortals.
In the third usage, extensions of divinity and divine power are credited to living, mortal individuals. Political leaders are known to have claimed actual divinity in certain early societies — the ancient Egyptian Pharaohs being the premier case — taking a role as objects of worship and being credited with superhuman status and powers. More commonly, and more pertinent to recent history, leaders merely claim some form of divine mandate, suggesting that their rule is in accordance with the will of God. The doctrine of the divine right of kings was introduced as late as the 17th century, proposing that kings rule by divine decree; Japanese Emperors ruled by divine mandate until the inception of the Japanese constitution after World War II
Less politically, most faiths have any number of people that are believed to have been touched by divine forces: saints, prophets, heroes, oracles, martyrs, and enlightened beings, among others. Saint Francis of Assisi, in Catholicism, is said to have received instruction directly from God and it is believed that he grants plenary indulgence to all who confess their sins and visit his chapel on the appropriate day. In Greek mythology, Achilles' mother bathed him in the river Styx to give him immortality, and Hercules — as the son of Zeus — inherited near-godly powers. In religious Taoism, Lao Tsu is venerated as a saint with his own powers. Various individuals in the Buddhist faith, beginning with Siddhartha, are considered to be enlightened, and in religious forms of Buddhism they are credited with divine powers. Muhammad and Christ, in their respective traditions, are each said to have performed divine miracles.
In general, mortals with divine qualities are carefully distinguished from the deity or deities in their religion's main pantheon. Even the Christian faith, which generally holds Christ to be identical to God, distinguishes between God the Father and Christ the begotten Son. There are, however, certain esoteric and mystical schools of thought, present in many faiths — Sufis in Islam, Gnostics in Christianity, Advaitan Hindus, Zen Buddhists, as well as several non-specific perspectives developed in new age philosophy — which hold that all humans are in essence divine, or unified with the Divine in a non-trivial way. Such divinity, in these faiths, would express itself naturally if it were not obscured by the social and physical worlds we live in; it needs to be brought to the fore through appropriate spiritual practices.
Christianity.
In traditional Christian theology, the concept and nature of divinity always has its source ultimately from God himself. It's the state or quality of being divine, and the term can denote Godly nature or character. In Hebrew, the terms would usually be "el", "elohim", and in Greek usually "theos", or "theias". The divinity in the Bible is considered the Godhead itself, or God in general. Or it may have reference to a deity. Even angels in the Psalms are considered divine or "elohim", as spirit beings, in God's form. Redeemed Christians, when taken to heaven as immortalized born-again believers, according to Biblical verses, are said to partake of the "divine nature". (Psalm 8:5; Hebrews 2:9; 2 Peter 1:4)
In the Christian Greek Scriptures of the Bible, the Greek word θεῖον ("theion") in the Douay Version, is translated as "divinity". Examples are below:
The word translated as either "deity", "Godhead", or "divinity" in the Greek New Testament is also the Greek word θεότητος ("theotētos"), and the one Verse that contains it is this:
Colossians 2:9<br>
The word "divine" in the New Testament is the Greek word θείας ("theias"), and is the adjective form of "divinity". Biblical examples from the King James Bible are below:
Latter-day Saints.
The most prominent conception of divine entities in The Church of Jesus Christ of Latter-day Saints (LDS Church) is the Godhead, a divine council of three distinct beings: Elohim (the Father), Jehovah (the Son, or Jesus), and the Holy Spirit. Joseph Smith described a nontrinitarian Godhead, with God the Father and Jesus Christ each having individual physical bodies, and the Holy Spirit as a distinct personage with a spirit body. Smith also introduced the existence of a Heavenly Mother in the King Follett Discourse, but very little is acknowledged or known beyond her existence.
Mormons hold a belief in the divine potential of humanity; Smith taught a form of divinization where mortal men and women can become like god through salvation and exaltation. Lorenzo Snow succinctly summarized this using a couplet, which is often repeated within the LDS Church: "As man now is, God once was: As God now is, man may be."

</doc>
<doc id="8367" url="http://en.wikipedia.org/wiki?curid=8367" title="Depth of field">
Depth of field

In optics, particularly as it relates to film and photography, depth of field (DOF), also called "focus range" or "effective focus range", is the distance between the nearest and farthest objects in a scene that appear acceptably sharp in an image. Although a lens can precisely focus at only one distance at a time, the decrease in sharpness is gradual on each side of the focused distance, so that within the DOF, the unsharpness is imperceptible under normal viewing conditions.
In some cases, it may be desirable to have the entire image sharp, and a large DOF is appropriate. In other cases, a small DOF may be more effective, emphasizing the subject while de-emphasizing the foreground and background. In cinematography, a large DOF is often called deep focus, and a small DOF is often called shallow focus.
Circle of confusion criterion for depth of field.
Precise focus is possible at only one distance; at that distance, a point object will produce a point image. At any other distance, a point object is "defocused", and will produce a blur spot shaped like the aperture, which for the purpose of analysis is usually assumed to be circular. When this circular spot is sufficiently small, it is indistinguishable from a point, and appears to be in focus; it is rendered as "acceptably sharp". The diameter of the circle increases with distance from the point of focus; the largest circle that is indistinguishable from a point is known as the "acceptable circle of confusion", or informally, simply as the "circle of confusion". The acceptable circle of confusion is influenced by visual acuity, viewing conditions, and the amount by which the image is enlarged (Ray 2000, 52–53). The increase of the circle diameter with defocus is gradual, so the limits of depth of field are not hard boundaries between sharp and unsharp.
For a 35 mm motion picture, the image area on the negative is roughly 22 mm by 16 mm (0.87 in by 0.63 in). The limit of tolerable error is usually set at 0.05 mm (0.002 in) diameter. For 16 mm film, where the image area is smaller, the tolerance is stricter, 0.025 mm (0.001 in). Standard depth-of-field tables are constructed on this basis, although generally 35 mm productions set it at 0.025 mm (0.001 in). Note that the acceptable circle of confusion values for these formats are different because of the relative amount of magnification each format will need in order to be projected on a full-sized movie screen. (A table for 35 mm still photography would be somewhat different since more of the film is used for each image and the amount of enlargement is usually much less.)
Object field methods.
Traditional depth-of-field formulas and tables assume equal circles of confusion for near and far objects. Some authors, such as Merklinger (1992), have suggested that distant objects often need to be much sharper to be clearly recognizable, whereas closer objects, being larger on the film, do not need to be so sharp. The loss of detail in distant objects may be particularly noticeable with extreme enlargements. Achieving this additional sharpness in distant objects usually requires focusing beyond the hyperfocal distance, sometimes almost at infinity. For example, if photographing a cityscape with a traffic bollard in the foreground, this approach, termed the "object field method" by Merklinger, would recommend focusing very close to infinity, and stopping down to make the bollard sharp enough. With this approach, foreground objects cannot always be made perfectly sharp, but the loss of sharpness in near objects may be acceptable if recognizability of distant objects is paramount.
Other authors (Adams 1980, 51) have taken the opposite position, maintaining that slight unsharpness in foreground objects is usually more disturbing than slight unsharpness in distant parts of a scene.
Moritz von Rohr also used an object field method, but unlike Merklinger, he used the conventional criterion of a maximum circle of confusion diameter in the image plane, leading to unequal front and rear depths of field.
Factors affecting depth of field.
Several other factors, such as subject matter, movement, camera-to-subject distance, lens focal length, selected lens "f"-number, format size, and circle of confusion criteria also influence when a given defocus becomes noticeable. The combination of focal length, subject distance, and format size defines magnification at the film / sensor plane.
DOF is determined by subject magnification at the film / sensor plane and the selected lens aperture or "f"-number. For a given "f"-number, increasing the magnification, either by moving closer to the subject or using a lens of greater focal length, decreases the DOF; decreasing magnification increases DOF. For a given subject magnification, increasing the "f"-number (decreasing the aperture diameter) increases the DOF; decreasing "f"-number decreases DOF.
If the original image is enlarged to make the final image, the circle of confusion in the original image must be smaller than that in the final image by the ratio of enlargement. Cropping an image and enlarging to the same size final image as an uncropped image taken under the same conditions is equivalent to using a smaller format under the same conditions, so the cropped image has less DOF. (Stroebel 1976, 134, 136–37).
When focus is set to the hyperfocal distance, the DOF extends from half the hyperfocal distance to infinity, and the DOF is the largest possible for a given "f"-number.
Relationship of DOF to format size.
The comparative DOFs of two different format sizes depend on the conditions of the comparison. The DOF for the smaller format can be either more than or less than that for the larger format. In the discussion that follows, it is assumed that the final images from both formats are the same size, are viewed from the same distance, and are judged with the same circle of confusion criterion. (Derivations of the effects of format size are given under Derivation of the DOF formulas.)
"Same picture" for both formats<br>When the "same picture" is taken in two different format sizes from the same distance at the same "f"-number with lenses that give the same angle of view, and the final images (e.g., in prints, or on a projection screen or electronic display) are the same size, DOF is, to a first approximation, inversely proportional to format size (Stroebel 1976, 139). Though commonly used when comparing formats, the approximation is valid only when the subject distance is large in comparison with the focal length of the larger format and small in comparison with the hyperfocal distance of the smaller format.
Moreover, the larger the format size, the longer a lens will need to be to capture the same framing as a smaller format. In motion pictures, for example, a frame with a 12 degree horizontal field of view will require a 50 mm lens on 16 mm film, a 100 mm lens on 35 mm film, and a 250 mm lens on 65 mm film. Conversely, using the same focal length lens with each of these formats will yield a progressively wider image as the film format gets larger: a 50 mm lens has a horizontal field of view of 12 degrees on 16 mm film, 23.6 degrees on 35 mm film, and 55.6 degrees on 65 mm film. Therefore, because the larger formats require longer lenses than the smaller ones, they will accordingly have a smaller depth of field. Compensations in exposure, framing, or subject distance need to be made in order to make one format look like it was filmed in another format.
Same focal length for both formatsMany small-format digital SLR camera systems allow using many of the same lenses on both full-frame and "cropped format" cameras. If, for the same focal length setting, the subject distance is adjusted to provide the "same field of view" at the subject, at the same "f"-number and final-image size, the smaller format has "greater" DOF, as with the "same picture" comparison above. If pictures are taken from the "same distance" using the same "f"-number, same focal length, and the final images are the same size, the smaller format has "less" DOF. If pictures taken from the same subject distance using the same focal length, are given the "same enlargement", both final images will have the "same" DOF. The pictures from the two formats will differ because of the different angles of view. If the larger format is cropped to the captured area of the smaller format, the final images will have the same angle of view, have been given the same enlargement, and have the same DOF.
Same DOF for both formats<br>In many cases, the DOF is fixed by the requirements of the desired image. For a given DOF and field of view, the required "f"-number is proportional to the format size. For example, if a 35 mm camera required f/11, a 4×5 camera would require f/45 to give the same DOF. For the same ISO speed, the exposure time on the 4×5 would be sixteen times as long; if the 35 camera required 1/250 second, the 4×5 camera would require 1/15 second. The longer exposure time with the larger camera might result in motion blur, especially with windy conditions, a moving subject, or an unsteady camera.
Adjusting the "f"-number to the camera format is equivalent to maintaining the same absolute aperture diameter; when set to the same absolute aperture diameters, both formats have the same DOF.
Comparison of fast standard lenses in the four main formats when used for portraiture with appropriate circles of confusion to produce an uncropped image at 10x8 inches to be viewed at 25 cm show that the following settings with similar aperture diameters produce similar DoF:
For any of these, doubling the f-number will approximately double the depth of field.
Camera movements and DOF.
When the lens axis is perpendicular to the image plane, as is normally the case, the plane of focus (POF) is parallel to the image plane, and the DOF extends between parallel planes on either side of the POF. When the lens axis is not perpendicular to the image plane, the POF is no longer parallel to the image plane; the ability to rotate the POF is known as the Scheimpflug principle. Rotation of the POF is accomplished with camera movements (tilt, a rotation of the lens about a horizontal axis, or swing, a rotation about a vertical axis). Tilt and swing are available on most view cameras, and are also available with specific lenses on some small- and medium-format cameras.
When the POF is rotated, the near and far limits of DOF are no longer parallel; the DOF becomes wedge-shaped, with the apex of the wedge nearest the camera (Merklinger 1993, 31–32; Tillmanns 1997, 71). With tilt, the height of the DOF increases with distance from the camera; with swing, the width of the DOF increases with distance.
In some cases, rotating the POF can better fit the DOF to the scene, and achieve the required sharpness at a smaller f-number. Alternatively, rotating the POF, in combination with a small f-number, can minimize the part of an image that is within the DOF.
Effect of lens aperture.
For a given subject framing and camera position, the DOF is controlled by the lens aperture diameter, which is usually specified as the f-number, the ratio of lens focal length to aperture diameter. Reducing the aperture diameter (increasing the f-number) increases the DOF because the circle of confusion is shrunk directly and indirectly by reducing the light hitting the outside of the lens which is focused to a different point than light hitting the inside of the lens due to spherical aberration caused by the construction of the lens; however, it also reduces the amount of light transmitted, and increases diffraction, placing a practical limit on the extent to which DOF can be increased by reducing the aperture diameter.
Motion pictures make only limited use of this control; to produce a consistent image quality from shot to shot, cinematographers usually choose a single aperture setting for interiors and another for exteriors, and adjust exposure through the use of camera filters or light levels. Aperture settings are adjusted more frequently in still photography, where variations in depth of field are used to produce a variety of special effects.
Digital techniques affecting DOF.
The advent of digital technology in photography has provided additional means of controlling the extent of image sharpness; some methods allow extended DOF that would be impossible with traditional techniques, and some allow the DOF to be determined after the image is made.
Focus stacking is a digital image processing technique which combines multiple images taken at different focus distances to give a resulting image with a greater depth of field than any of the individual source images. Available programs for multi-shot DOF enhancement include Adobe Photoshop, Syncroscopy AutoMontage, PhotoAcute Studio, Helicon Focus and CombineZ. Getting sufficient depth of field can be particularly challenging in macro photography. The images to the right illustrate the extended DOF that can be achieved by combining multiple images.
Wavefront coding is a method that convolves rays in such a way that it provides an image where fields are in focus simultaneously with all planes out of focus by a constant amount.
A plenoptic camera uses a microlens array to capture 4D light field information about a scene.
Colour apodization is a technique combining a modified lens design with image processing to achieve an increased depth of field. The lens is modified such that each colour channel has a different lens aperture. For example the red channel may be f/2.4, green may be f/2.4, whilst the blue channel may be f/5.6. Therefore the blue channel will have a greater depth of field than the other colours. The image processing identifies blurred regions in the red and green channels and in these regions copies the sharper edge data from the blue channel. The result is an image that combines the best features from the different f-numbers, (Kay 2011).
In 2013, Nokia implemented DOF control in some of its high-end smartphones, called Refocus, which can change a picture's depth of field after the picture is taken. It works best when there are close-up and distant objects in the frame.
Diffraction and DOF.
If the camera position and image framing (i.e., angle of view) have been chosen, the only means of controlling DOF is the lens aperture. Most DOF formulas imply that any arbitrary DOF can be achieved by using a sufficiently large f-number. Because of diffraction, however, this isn't really true. Once a lens is stopped down to where most aberrations are well corrected, stopping down further will decrease sharpness in the plane of focus. At the DOF limits, however, further stopping down decreases the size of the defocus blur spot, and the overall sharpness may still increase. Eventually, the defocus blur spot becomes negligibly small, and further stopping down serves only to decrease sharpness even at DOF limits (Gibson 1975, 64). There is thus a tradeoff between sharpness in the POF and sharpness at the DOF limits. But the sharpness in the POF is always greater than that at the DOF limits; if the blur at the DOF limits is imperceptible, the blur in the POF is imperceptible as well.
For general photography, diffraction at DOF limits typically becomes significant only at fairly large f-numbers; because large f-numbers typically require long exposure times, motion blur may cause greater loss of sharpness than the loss from diffraction. The size of the diffraction blur spot depends on the effective f-number formula_1, however, so diffraction is a greater issue in close-up photography, and the tradeoff between DOF and overall sharpness can become quite noticeable (Gibson 1975, 53; Lefkowitz 1979, 84).
Lens DOF scales.
Many lenses for small- and medium-format cameras include scales that indicate the DOF for a given focus distance and f-number; the 35 mm lens in the image above is typical. That lens includes distance scales in feet and meters; when a marked distance is set opposite the large white index mark, the focus is set to that distance. The DOF scale below the distance scales includes markings on either side of the index that correspond to f-numbers. When the lens is set to a given f-number, the DOF extends between the distances that align with the f-number markings.
Zone focusing.
When the 35 mm lens above is set to f/11 and focused at approximately 1.3 m, the DOF (a "zone" of acceptable sharpness) extends from 1 m to 2 m. Conversely, the required focus and f-number can be determined from the desired DOF limits by locating the near and far DOF limits on the lens distance scale and setting focus so that the index mark is centered between the near and far distance marks. The required f-number is determined by finding the markings on the DOF scale that are closest to the near and far distance marks (Ray 1994, 315). For the 35 mm lens above, if it were desired for the DOF to extend from 1 m to 2 m, focus would be set so that index mark was centered between the marks for those distances, and the aperture would be set to f/11.
The focus so determined would be about 1.3 m, the approximate harmonic mean of the near and far distances. See the section Focus and "f"-number from DOF limits for additional discussion.
If the marks for the near and far distances fall outside the marks for the largest f-number on the DOF scale, the desired DOF cannot be obtained; for example, with the 35 mm lens above, it is not possible to have the DOF extend from 0.7 m to infinity. The DOF limits can be determined visually, by focusing on the farthest object to be within the DOF and noting the distance mark on the lens distance scale, and repeating the process for the nearest object to be within the DOF.
Some distance scales have markings for only a few distances; for example, the 35 mm lens above shows only 3 ft and 5 ft on its upper scale. Using other distances for DOF limits requires visual interpolation between marked distances. Since the distance scale is nonlinear, accurate interpolation can be difficult. In most cases, English and metric distance markings are not coincident, so using both scales to note focused distances can sometimes lessen the need for interpolation. Many autofocus lenses have smaller distance and DOF scales and fewer markings than do comparable manual-focus lenses, so that determining focus and f-number from the scales on an autofocus lens may be more difficult than with a comparable manual-focus lens. In most cases, determining these settings using the lens DOF scales on an autofocus lens requires that the lens or camera body be set to manual focus.
On a view camera, the focus and f-number can be obtained by measuring the "focus spread" and performing simple calculations. The procedure is described in more detail in the section Focus and f-number from DOF limits. Some view cameras include DOF calculators that indicate focus and f-number without the need for any calculations by the photographer (Tillmanns 1997, 67–68; Ray 2002, 230–31).
Hyperfocal distance.
The hyperfocal distance is the nearest focus distance at which the DOF extends to infinity; focusing the camera at the hyperfocal distance results in the largest possible depth of field for a given f-number (Ray 2000, 55). Focusing "beyond" the hyperfocal distance does not increase the far DOF (which already extends to infinity), but it does decrease the DOF in front of the subject, decreasing the total DOF. Some photographers consider this wasting DOF; however, see Object field methods above for a rationale for doing so. Focusing on the hyperfocal distance is a special case of zone focusing in which the far limit of DOF is at infinity.
If the lens includes a DOF scale, the hyperfocal distance can be set by aligning the infinity mark on the distance scale with the mark on the DOF scale corresponding to the f-number to which the lens is set. For example, with the 35 mm lens shown above set to f/11, aligning the infinity mark with the '11' to the left of the index mark on the DOF scale would set the focus to the hyperfocal distance.
Limited DOF: selective focus.
Depth of field can be anywhere from a fraction of a millimeter to virtually infinite. In some cases, such as landscapes, it may be desirable to have the entire image sharp, and a large DOF is appropriate. In other cases, artistic considerations may dictate that only a part of the image be in focus, emphasizing the subject while de-emphasizing the background, perhaps giving only a suggestion of the environment (Langford 1973, 81). For example, a common technique in melodramas and horror films is a closeup of a person's face, with someone just behind that person visible but out of focus. A portrait or close-up still photograph might use a small DOF to isolate the subject from a distracting background. The use of limited DOF to emphasize one part of an image is known as "selective focus", "differential focus" or "shallow focus".
Although a small DOF implies that other parts of the image will be unsharp, it does not, by itself, determine "how" unsharp those parts will be. The amount of background (or foreground) blur depends on the distance from the plane of focus, so if a background is close to the subject, it may be difficult to blur sufficiently even with a small DOF. In practice, the lens f-number is usually adjusted until the background or foreground is acceptably blurred, often without direct concern for the DOF.
Sometimes, however, it is desirable to have the entire subject sharp while ensuring that the background is sufficiently unsharp. When the distance between subject and background is fixed, as is the case with many scenes, the DOF and the amount of background blur are not independent. Although it is not always possible to achieve both the desired subject sharpness and the desired background unsharpness, several techniques can be used to increase the separation of subject and background.
For a given scene and subject magnification, the background blur increases with lens focal length. If it is not important that background objects be unrecognizable, background de-emphasis can be increased by using a lens of longer focal length and increasing the subject distance to maintain the same magnification. This technique requires that sufficient space in front of the subject be available; moreover, the perspective of the scene changes because of the different camera position, and this may or may not be acceptable.
The situation is not as simple if it is important that a background object, such as a sign, be unrecognizable. The magnification of background objects also increases with focal length, so with the technique just described, there is little change in the recognizability of background objects. However, a lens of longer focal length may still be of some help; because of the narrower angle of view, a slight change of camera position may suffice to eliminate the distracting object from the field of view.
Although tilt and swing are normally used to maximize the part of the image that is within the DOF, they also can be used, in combination with a small f-number, to give selective focus to a plane that isn't perpendicular to the lens axis. With this technique, it is possible to have objects at greatly different distances from the camera in sharp focus and yet have a very shallow DOF. The effect can be interesting because it differs from what most viewers are accustomed to seeing.
Near:far distribution.
The DOF beyond the subject is always greater than the DOF in front of the subject. When the subject is at the hyperfocal distance or beyond, the far DOF is infinite, so the ratio is 1:∞; as the subject distance decreases, near:far DOF ratio increases, approaching unity at high magnification. For large apertures at typical portrait distances, the ratio is still close to 1:1. The oft-cited rule that 1/3 of the DOF is in front of the subject and 2/3 is beyond (a 1:2 ratio) is true only when the subject distance is 1/3 the hyperfocal distance.
Optimal f-number.
As a lens is stopped down, the defocus blur at the DOF limits decreases but diffraction blur increases. The presence of these two opposing factors implies a point at which the combined blur spot is minimized (Gibson 1975, 64); at that point, the f-number is optimal for image sharpness.
If the final image is viewed under normal conditions (e.g., an 8″×10″ image viewed at 10″), it may suffice to determine the f-number using criteria for minimum required sharpness, and there may be no practical benefit from further reducing the size of the blur spot. But this may not be true if the final image is viewed under more demanding conditions, e.g., a very large final image viewed at normal distance, or a portion of an image enlarged to normal size (Hansma 1996). Hansma also suggests that the final-image size may not be known when a photograph is taken, and obtaining the maximum practicable sharpness allows the decision to make a large final image to be made at a later time.
Determining combined defocus and diffraction.
Hansma (1996) and Peterson (1996) have discussed determining the combined effects of defocus and diffraction using a root-square combination of the individual blur spots. Hansma's approach determines the f-number that will give the maximum possible sharpness; Peterson's approach determines the minimum f-number that will give the desired sharpness in the final image, and yields a maximum focus spread for which the desired sharpness can be achieved. In combination, the two methods can be regarded as giving a maximum and minimum f-number for a given situation, with the photographer free to choose any value within the range, as conditions (e.g., potential motion blur) permit. Gibson (1975), 64) gives a similar discussion, additionally considering blurring effects of camera lens aberrations, enlarging lens diffraction and aberrations, the negative emulsion, and the printing paper. Couzin (1982), 1098) gave a formula essentially the same as Hansma's for optimal "f"-number, but did not discuss its derivation.
Hopkins (1955), Stokseth (1969), and Williams and Becklund (1989) have discussed the combined effects using the modulation transfer function. Conrad's (PDF), and Jacobson's discuss the use of Hopkins's method specifically in regard to DOF.
Other applications.
Photolithography.
In semiconductor photolithography applications, depth of field is extremely important as integrated circuit layout features must be printed with high accuracy at extremely small size. The difficulty is that the wafer surface is not perfectly flat, but may vary by several micrometres. Even this small variation causes some distortion in the projected image, and results in unwanted variations in the resulting pattern. Thus photolithography engineers take extreme measures to maximize the optical depth of field of the photolithography equipment. To minimize this distortion further, semiconductor manufacturers may use chemical mechanical polishing to make the wafer surface even flatter before lithographic patterning.
Ophthalmology and optometry.
A person may sometimes experience better vision in daylight than at night because of an increased depth of field due to constriction of the pupil (i.e., miosis).
DOF formulas.
The basis of these formulas is given in the section Derivation of the DOF formulae; refer to the diagram in that section for illustration of the quantities discussed below.
Hyperfocal distance.
Let formula_2 be the lens focal length,
formula_3 be the lens f-number, and formula_4 be the
circle of confusion for a given image format. The
hyperfocal distance formula_5 is given by
Moderate-to-large distances.
Let formula_7 be the distance at which the camera is focused (the
"subject distance"). When formula_7 is large in comparison with the
lens focal length, the distance formula_9 from the
camera to the near limit of DOF and the distance formula_10
from the camera to the far limit of DOF are
and
The depth of field formula_13 is
Substituting for formula_5 and rearranging, DOF can be expressed as
Thus, for a given image format, depth of field is determined
by three factors: the focal length of the lens, the f-number of the
lens opening (the aperture), and the camera-to-subject distance.
When the subject distance is the hyperfocal distance,
and
For formula_19, the far limit of DOF is at infinity and the DOF
is infinite; of course, only objects at or beyond the near limit of DOF
will be recorded with acceptable sharpness.
Close-up.
When the subject distance formula_7 approaches the focal length, using the formulas given above can result in significant errors. For close-up work, the hyperfocal distance has little applicability, and it usually is more convenient to express DOF in terms of image magnification. Let formula_21 be the magnification; when the subject distance is small in
comparison with the hyperfocal distance,
so that for a given magnification, DOF is independent of focal length. Stated otherwise, for the same subject magnification, at the same "f"-number, all focal lengths
used on a given image format give approximately the same DOF. This statement is true "only" when the subject distance is small in comparison with the hyperfocal distance, however.
The discussion thus far has assumed a symmetrical lens for which the
entrance and exit pupils coincide with the front and rear nodal planes, and for which the pupil magnification (the ratio of exit pupil diameter to that of the entrance pupil) is unity. Although this assumption usually is reasonable for large-format lenses, it
often is invalid for medium- and small-format lenses.
When formula_23, the DOF for an asymmetrical lens is
where formula_25 is the pupil magnification. When the
pupil magnification is unity, this equation reduces to that for a
symmetrical lens.
Except for close-up and macro photography, the effect of lens asymmetry is minimal. At unity magnification, however, the errors from neglecting the
pupil magnification can be significant. Consider a telephoto lens with formula_26 and a retrofocus wide-angle lens with formula_27, at formula_28. The asymmetrical-lens formula gives formula_29 and formula_30, respectively. The symmetrical-lens formula gives formula_31 in either case. The errors are −33% and 33%, respectively.
Focus and f-number from DOF limits.
For given near and far DOF limits formula_9 and formula_10, the required f-number is smallest when focus is set to
the harmonic mean of the near and far distances. When the subject distance is large in comparison with the lens focal length, the required f-number is
When the far limit of DOF is at infinity,
and
In practice, these settings usually are determined on the image side of the lens, using measurements on the bed or rail with a view camera, or using lens DOF scales on manual-focus lenses for small- and medium-format cameras. If formula_38 and formula_39 are the image distances that correspond to the near and far limits of DOF,
the required f-number is minimized when the image distance
formula_40 is
In practical terms, focus is set to halfway between the near and far
image distances. The required f-number is
The image distances are measured from the camera's image plane to the
lens's image nodal plane, which is not always easy to locate. In most cases, focus and f-number can be determined with sufficient accuracy using the approximate formulas above, which require only the difference between the near and far image distances; view camera users sometimes refer to the difference formula_43 as the "focus spread" (Hansma 1996, 55). Most lens DOF scales are based on the same concept.
The focus spread is related to the depth of focus. Ray (2000, 56) gives two definitions of the latter. The first is the tolerance of the position of the image plane for which an object remains acceptably sharp; the second is that the limits of depth of focus are the image-side conjugates of the near and far limits of DOF. With the first definition, focus spread and depth of focus are usually close in value though conceptually different. With the second definition, focus spread and depth of focus are the same.
Foreground and background blur.
If a subject is at distance formula_7 and the foreground or background is at distance formula_45, let the distance between the subject and the foreground or background be indicated by
The blur disk diameter formula_47 of a detail at distance formula_48 from the subject can be expressed as a function of the subject magnification formula_49, focal length formula_2, f-number formula_3 or alternatively the diameter of the entrance pupil formula_52 (often called the aperture) according to
The minus sign applies to a foreground object, and the plus sign applies to a background object.
The blur increases with the distance from the subject; when formula_54, the detail
is within the depth of field, and the blur is imperceptible. If the detail is only slightly outside the DOF, the blur may be only barely perceptible.
For a given subject magnification, f-number, and distance from the subject of the foreground or background detail, the degree of detail blur varies with the lens focal length. For a background detail, the blur increases with focal length; for a foreground detail, the blur decreases with focal length. For a given scene, the positions of the subject, foreground, and background usually are fixed, and the distance between subject and the foreground or background remains constant regardless of the camera position; however, to maintain constant magnification, the subject distance must vary if the focal length is changed. For small distance between the foreground or background detail, the effect of focal length is small; for large distance, the effect can be significant. For a reasonably distant background detail, the blur disk diameter is
depending only on focal length.
The blur diameter of foreground details is very large if the details are close to the lens.
The magnification of the detail also varies with focal length; for a given detail, the ratio of the blur disk diameter to imaged size of the detail is independent of focal length, depending only on the detail size and its distance from the subject. This ratio can be useful when it is important that the background be recognizable (as usually is the case in evidence or surveillance photography), or unrecognizable (as might be the case for a pictorial photographer using selective focus to isolate the subject from a distracting background). As a general rule, an object is recognizable if the blur disk diameter is one-tenth to one-fifth the size of the object or smaller (Williams 1990, 205), and unrecognizable when the blur disk diameter is the object size or greater.
The effect of focal length on background blur is illustrated in van Walree's article on .
Practical complications.
The distance scales on most medium- and small-format lenses indicate
distance from the camera's image plane. Most DOF formulas, including those in this article, use the object distance
formula_7 from the lens's front nodal plane, which often is not easy to
locate. Moreover, for many zoom lenses and internal-focusing non-zoom lenses, the location of the front nodal plane, as well as focal length, changes with subject distance. When the subject distance is large in comparison with the lens focal length, the exact location of the front nodal plane is not critical; the distance is essentially the same whether measured from the front of the lens, the image plane, or the actual nodal
plane. The same is not true for close-up photography; at unity magnification, a slight error in the location of the front nodal plane can result in a DOF error greater than the errors from any approximations in the DOF equations.
The asymmetrical lens formulas require knowledge of the pupil magnification, which usually is not specified for medium- and small-format lenses. The pupil magnification can be estimated by looking
into the front and rear of the lens and measuring the diameters of the apparent apertures, and computing the ratio of rear diameter to front diameter (Shipman 1977, 144). However, for many zoom lenses and internal-focusing non-zoom lenses, the pupil magnification changes with subject distance, and several measurements may be required.
Limitations.
Most DOF formulas, including those discussed in this article, employ
several simplifications:
The lens designer cannot restrict analysis to Gaussian optics and cannot
ignore lens aberrations. However, the requirements of practical
photography are less demanding than those of lens design, and despite the
simplifications employed in development of most DOF formulas, these
formulas have proven useful in determining camera settings that result in
acceptably sharp pictures. It should be recognized that DOF limits are not
hard boundaries between sharp and unsharp, and that there is little point
in determining DOF limits to a precision of many significant figures.
Derivation of the DOF formulae.
DOF limits.
A symmetrical lens is illustrated at right. The subject, at distance
formula_7, is in focus at image distance formula_40. Point objects
at distances formula_59 and formula_60 would be
in focus at image distances formula_61 and formula_62, respectively; at image distance formula_40, they are imaged
as blur spots. The depth of field is controlled by the aperture stop
diameter formula_52; when the blur spot diameter is equal to the
acceptable circle of confusion formula_4, the near and far limits
of DOF are at formula_60 and formula_59. From
similar triangles,
and
It usually is more convenient to work with the lens f-number
than the aperture diameter; the f-number formula_3 is
related to the lens focal length formula_2 and the aperture diameter
formula_52 by
substitution into the previous equations gives
Rearranging to solve for formula_75 and formula_76 gives
and
The image distance formula_40 is related to an object distance
formula_7 by the thin lens equation
applying this to formula_82 and formula_61 gives
and
solving for formula_40, formula_82, and formula_61 in these three equations, substituting into the two previous equations, and rearranging gives the near and far limits of DOF:
and
Hyperfocal distance.
Solving for the focus distance formula_7 and setting the far limit of DOF
formula_10 to infinity gives
where formula_5 is the hyperfocal distance. Setting the subject
distance to the hyperfocal distance and solving for the near limit of DOF
gives
For any practical value of formula_5, the focal length is negligible
in comparison, so that
Substituting the approximate expression for hyperfocal distance into the
formulas for the near and far limits of DOF gives
and
Combining, the depth of field formula_13 is
Hyperfocal magnification.
Magnification formula_21 can be expressed as
at the hyperfocal distance, the magnification formula_104 then is
Substituting formula_106 for formula_5 and simplifying gives
DOF in terms of magnification.
It is sometimes convenient to express DOF in terms of magnification formula_21. Substituting
and
into the formula for DOF and rearranging gives
after Larmore (1965), 163).
DOF vs. focal length.
Multiplying the numerator and
denominator of the exact formula above by
gives
If the "f"-number and circle of confusion are constant,
decreasing the focal length formula_2 increases the second term in the
denominator, decreasing the denominator and increasing the value of the
right-hand side, so that a shorter focal length gives greater DOF.
The term in parentheses in the denominator is the hyperfocal magnification
formula_104, so that
A subject distance is decreased, the subject magnification increases, and eventually
becomes large in comparison with the hyperfocal magnification.
Thus the effect of focal length is greatest near the hyperfocal distance, and
decreases as subject distance is decreased. However, the near/far
perspective will differ for different focal lengths, so the difference in
DOF may not be readily apparent.
When formula_23, formula_119, and
so that for a given magnification, DOF is essentially independent of focal length.
Stated otherwise, for the same subject magnification and the same "f"-number, all focal lengths for
a given image format give approximately the same DOF. This
statement is true only when the subject distance is small in comparison
with the hyperfocal distance, however.
Moderate-to-large distances.
When the subject distance is large in comparison with the lens focal length,
and
so that
For formula_19, the far limit of DOF is at infinity and the DOF
is infinite; of course, only objects at or beyond the near limit of DOF
will be recorded with acceptable sharpness.
Close-up.
When the subject distance formula_7 approaches the lens focal length,
the focal length no longer is negligible, and the approximate formulas
above cannot be used without introducing significant error. At close
distances, the hyperfocal distance has little applicability, and it usually
is more convenient to express DOF in terms of magnification. The distance
is small in comparison with the hyperfocal distance, so the simplified formula
can be used with good accuracy. For a given magnification,
DOF is independent of focal length.
Near:far DOF ratio.
From the "exact" equations for near and far limits of DOF, the DOF in front of the subject is
and the DOF beyond the subject is
The near:far DOF ratio is
This ratio is always less than unity; at moderate-to-large subject distances, formula_130, and
When the subject is at the hyperfocal distance or beyond, the far DOF is infinite, and the near:far ratio is zero. It's commonly stated that approximately 1/3 of the DOF is in front of the subject and approximately 2/3 is beyond; however, this is true only when formula_132.
At closer subject distances, it's often more convenient to express the DOF ratio in terms of the magnification
substitution into the "exact" equation for DOF ratio gives
As magnification increases, the near:far ratio approaches a limiting value of unity.
DOF vs. format size.
When the subject distance is much less than hyperfocal, the total DOF is given to good approximation by
When additionally the magnification is small compared to unity, the value of formula_21 in the numerator can be neglected, and the formula further simplifies to
The DOF ratio for two different formats is then
Essentially the same approach is described in Stroebel (1976), 136–39).
"Same picture" for both formats.
The results of the comparison depend on what is assumed. One approach is to assume that essentially the same picture is taken with each format and enlarged to produce the same size final image, so the subject distance remains the same, the focal length is adjusted to maintain the same angle of view, and to a first approximation, magnification is in direct proportion to some characteristic dimension of each format. If both pictures are enlarged to give the same size final images with the same sharpness criteria, the circle of confusion is also in direct proportion to the format size. Thus if formula_139 is the characteristic dimension of the format,
With the same "f"-number, the DOF ratio is then
so the DOF ratio is in inverse proportion to the format size. This ratio is approximate, and breaks down in the macro range of the larger format (the value of formula_21 in the numerator is no longer negligible) or as distance approaches the hyperfocal distance for the smaller format (the DOF of the smaller format approaches infinity).
If the formats have approximately the same aspect ratios, the characteristic dimensions can be the format diagonals; if the aspect ratios differ considerably (e.g., 4×5 vs. 6×17), the dimensions must be chosen more carefully, and the DOF comparison may not even be meaningful.
If the DOF is to be the same for both formats the required "f"-number is in direct proportion to the format size:
Adjusting the "f"-number in proportion to format size is equivalent to using the same absolute aperture diameter for both formats, discussed in detail below in Use of absolute aperture diameter.
Same focal length for both formats.
If the same lens focal length is used in both formats, magnifications can be maintained in the ratio of the format sizes by adjusting subject distances; the DOF ratio is the same as that given above, but the images differ because of the different perspectives and angles of view.
If the same DOF is required for each format, an analysis similar to that above shows that the required "f"-number is in direct proportion to the format size.
Another approach is to use the same focal length with both formats at the same subject distance, so the magnification is the same, and with the same "f"-number,
so the DOF ratio is in "direct" proportion to the format size. The perspective is the same for both formats, but because of the different angles of view, the pictures are not the same.
Cropping.
Cropping an image and enlarging to the same size final image as an uncropped image taken under the same conditions is equivalent to using a smaller format; the cropped image requires greater enlargement and consequently has a smaller circle of confusion. A cropped then enlarged image has less DOF than the uncropped image.
Use of absolute aperture diameter.
The aperture diameter is normally given in terms of the "f"-number because all lenses set to the same "f"-number give approximately the same image illuminance (Ray 2002, 130), simplifying exposure settings. In deriving the basic DOF equations, formula_145 can be substituted for the absolute aperture diameter formula_52, giving the DOF in terms of the absolute aperture diameter:
after Larmore (1965), 163). When the subject distance formula_7 is small in comparison with the hyperfocal distance, the second term in the denominator can be neglected, leading to
With the same subject distance and angle of view for both formats, formula_150, and
so the DOFs are in inverse proportion to the absolute aperture diameters. When the diameters are the same, the two formats have the same DOF. Von Rohr (1906) made this same observation, saying "At this point it will be sufficient to note that all these formulae involve quantities relating exclusively to the entrance-pupil and its position with respect to the object-point, whereas the focal length of the transforming system does not enter into them." Lyon's describes an approach very similar to that of von Rohr.
Using the same absolute aperture diameter for both formats with the "same picture" criterion is equivalent to adjusting the "f"-number in proportion to the format sizes, discussed above under "Same picture" for both formats
Focus and f-number from DOF limits.
Object-side relationships.
The equations for
the DOF limits can be combined to eliminate formula_152 and solve for
the subject distance. For given near and far DOF limits
formula_9 and formula_10, the
subject distance is
the harmonic mean of the near and far distances. The equations for DOF limits also can be combined to eliminate
formula_7 and solve for the required f-number, giving
When the subject distance is large in comparison with the lens focal
length, this simplifies to
When the far limit of DOF is at infinity, the equations for formula_7 and formula_3 give indeterminate results. But if all terms in the numerator and denominator on the right-hand side of the equation for formula_7 are divided by formula_162, it is seen that when formula_162 is at infinity,
Similarly, if all terms in the numerator and denominator on the right-hand side of the equation for formula_3 are divided by formula_162, it is seen that when formula_162 is at infinity,
Image-side relationships.
Most discussions of DOF concentrate on the object side of the lens,
but the formulas are simpler and the measurements usually easier to make on the
image side. If the basic image-side equations
and
are combined and solved for the image distance formula_40, the result is
the harmonic mean of the near and far image distances. The basic image-side equations can also be combined and solved for formula_3, giving
The image distances are measured from the camera's image plane to the
lens's image nodal plane, which is not always easy to locate. The harmonic mean is always less than the arithmentic mean, but when the difference between the near and far image distances is reasonably small, the two means are close to equal, and focus can be set with sufficient accuracy using
This formula requires only the "difference"
formula_43 between the near and far image distances.
View camera users often refer to this difference as the "focus spread";
it usually is measured on the bed or focusing rail.
Focus is simply set to halfway between the near and far image distances.
Substituting formula_177 into the equation for formula_3 and rearranging gives
One variant of the thin-lens equation is formula_180, where formula_21 is the magnification; substituting this into the equation for formula_3 gives
At moderate-to-large subject distances, formula_21 is small compared to unity, and the
f-number can often be determined with sufficient accuracy using
For close-up photography, the magnification cannot be ignored, and the f-number should be determined using the first approximate formula.
As with the approximate formula for formula_40, the approximate formulas for
formula_3 require only the focus spread
formula_43 rather than the absolute image distances.
When the far limit of DOF is at infinity, formula_189.
On manual-focus small- and medium-format lenses, the focus and f-number
usually are determined using the lens DOF scales, which
often are based on the approximate equations above.
Foreground and background blur.
If the equation for the far limit of DOF is solved for formula_4, and the far distance
replaced by an arbitrary distance formula_45, the blur disk diameter
formula_47 at that distance is
When the background is at the far limit of DOF, the blur disk diameter is equal to the circle
of confusion formula_4, and the blur is just imperceptible. The diameter of the background
blur disk increases with the distance to the background. A similar relationship holds for the
foreground; the general expression for a defocused object at distance formula_45 is
For a given scene, the distance between the subject and a foreground or background object is usually
fixed; let that distance be represented by
then
or, in terms of subject distance,
with the minus sign used for foreground objects and the plus sign used for background objects.
For a relatively distant background object,
In terms of subject magnification, the subject distance is
so that, for a given f-number and subject magnification,
Differentiating formula_47 with respect to formula_2 gives
With the plus sign, the derivative is everywhere positive,
so that for a background object, the blur disk size increases with focal length.
With the minus sign, the derivative is everywhere negative,
so that for a foreground object, the blur disk size decreases with focal length.
The magnification of the defocused object also varies with focal length; the magnification of the
defocused object is
where formula_207 is the image distance of the subject. For a defocused object
with some characteristic dimension formula_208, the imaged size of that object is
The ratio of the blur disk size to the imaged size of that object then is
so for a given defocused object, the ratio of the blur disk diameter to object size
is independent of focal length, and depends only on the object size and its distance from the subject.
Asymmetrical lenses.
This discussion thus far has assumed a symmetrical lens for which the
entrance and exit pupils coincide with the object and image
nodal planes, and for which the pupil magnification is unity.
Although this assumption usually is reasonable for large-format lenses, it
often is invalid for medium- and small-format lenses.
For an asymmetrical lens, the DOF ahead of the subject distance and the
DOF beyond the subject distance are given by
and
where formula_25 is the pupil magnification.
Combining gives the total DOF:
When formula_23, the second term in the denominator becomes
small in comparison with the first, and (Shipman 1977, 147)
When the pupil magnification is unity, the equations for asymmetrical
lenses reduce to those given earlier for symmetrical lenses.
Effect of lens asymmetry.
Except for close-up and macro photography, the effect of lens asymmetry is
minimal. A slight rearrangement of the last equation gives
As magnification decreases, the formula_218 term becomes smaller in
comparison with the formula_219 term, and eventually the effect of
pupil magnification becomes negligible.
References.
</dl>

</doc>
<doc id="8368" url="http://en.wikipedia.org/wiki?curid=8368" title="Dumnonii">
Dumnonii

The Dumnonii or Dumnones were British who inhabited Dumnonia, the area now known as Devon and Cornwall in the farther parts of the South West peninsula of Britain, from at least the Iron Age up to the early Saxon period. They were bordered to the east by the Durotriges.
Etymology.
William Camden, in his 1607 edition of "Britannia", describes Cornwall and Devon as being two parts of the same 'country' which:
was in ancient time inhabited by those Britains whom Solinus called Dunmonii, Ptolomee Damnonii, or (as we find in some other copies) more truly Danmonii. ... . But... the Country of this nation is at this day divided into two parts, known by later names of Cornwall and Denshire [Devonshire] ... The near or hithermore region of the Danmonians that I spake of is now commonly called Denshire, [or] by the Cornish-Britains 'Dewnan', and by the Welsh Britains 'Duffneint', that is, 'low valleys', for that the people dwell for the most part beneath in Vales; by the English Saxons [it is known as] 'Deven-schire', whereof grew the Latin name 'Devonia', and by that contraction which the vulgar people useth, 'Denshire'.
Camden had learnt some Welsh during the course of his studies and it would appear that he is the origin of the interpretation of Dumnonii as "deep valley dwellers" from his understanding of the Welsh of his time. John Rhys later theorized that the tribal name was derived from the name of a goddess, "Domnu", probably meaning "the goddess of the deep". The proto-Celtic root *dubno- or *dumno- meaning "the deep" or "the earth" (or alternatively meaning "dark" or "gloomy") appears in personal names such as Dumnorix and Dubnovellaunus. Another group with a similar name but with no known links were the Fir Domnann of Connacht.
The Roman name of the town of Exeter, "Isca Dumnoniorum" ("Isca of the Dumnonii"), contains the root "*iska-" "water" for "Water of the Dumnonii". The Latin name suggests that the city was already an "oppidum", or walled town, on the banks on the River Exe before the foundation of the Roman city, in about AD 50. The Dumnonii gave their name to the English county of Devon, and their name is represented in Britain's two extant Brythonic languages as "Dewnans" in Cornish and "Dyfnaint" in Welsh. Amédée Thierry ("Histoire des Gaulois", 1828), one of the inventors of the "historic race" of Gauls, could confidently equate them with the Cornish ("les Cornouailles").
Victorian historians often referred to the tribe as the Damnonii, which is also the name of another people from lowland Scotland, although there are no known links between the two populations.
Language.
The people of Dumnonia spoke a Southwestern Brythonic dialect similar to the forerunner of more recent Cornish and Breton. Irish immigrants, the Déisi, are evidenced by the Ogham-inscribed stones they have left behind, confirmed and supplemented by toponymical studies. The stones are sometimes inscribed in Latin, sometimes in both scripts. Tristram Risdon suggested the continuance of a Brythonic dialect in the South Hams, Devon, as late as the 14th century, in addition to its use in Cornwall.
Territory.
Ptolemy's 2nd century "Geography" places the Dumnonii to the west of the Durotriges. The name "purocoronavium" that appears in the Ravenna Cosmography implies the existence of a sub-tribe called the Cornavii or Cornovii, perhaps the ancestors of the Cornish people.
In the sub-Roman period a Brythonic kingdom called Dumnonia emerged, covering the entire peninsula, although it is believed by some to have effectively been a collection of sub-kingdoms.
A kingdom of Domnonée (and of Cornouaille alongside) was established in the province of Armorica directly across the English Channel, thought to have been founded by Briton immigrants, fleeing from Saxon invaders.
Settlements.
Isca Dumnoniorum.
The Latin name for Exeter is Isca Dumnoniorum ("Water of the Dumnonii"). This oppidum (a Latin term meaning an important town) on the banks of the River Exe certainly existed prior to the foundation of the Roman city in about AD 50. "Isca" is derived from a Brythonic word for flowing water, which was given to the River Exe.
Isca Dumnoniorum originated with a settlement that developed around the Roman fortress of the Legio II Augusta and is one of the four "poleis" (cities) attributed to the tribe by Ptolemy. It is also listed in two routes of the late 2nd century Antonine Itinerary.
A legionary bath-house was built inside the fortress sometime between 55 and 60 and underwent renovation shortly afterwards (c. 60-65) but by c. 68 (perhaps even 66) the legion had transferred to a newer fortress at Gloucester. This saw the dismantling of the Isca fortress, and the site was then abandoned. Around AD 75, work on the "civitas forum" and "basilica" had commenced on the site of the former "principia" and by the late 2nd century the "civitas" walls had been completed. They were 3 metres thick and 6 metres high and enclosed exactly the same area as the earlier fortress. However by the late 4th century the "civitas" was in decline.
 Next to these [the Durotriges], but more to the west, are the Dumnoni, whose towns are:Voliba 14°45 52°00Uxella 15°00 52°45Tamara 15°00 52°15Isca, where is located Legio II Augusta 17°30 52°45.
—Ptolemy, "Geography" II.ii.
Other settlements.
As well as Isca Dumnoniorum, Ptolemy's 2nd century "Geography" names three other towns:
The Ravenna Cosmography includes the last two names (in slightly different forms, as "Tamaris" and "Uxelis"), and adds several more names which may be settlements in the territory. These include:
Other Romano-British sites in Dumnonia include:
New settlements continued to be built throughout the Roman period, including sites at Chysauster and Trevelgue Head. The style is native in form with no Romanised features. Near Padstow, a Roman site of some importance now lies buried under the sands on the opposite side of the Camel estuary near St. Enodoc's Church, and may have been a western coastal equivalent of a Saxon Shore Fort. At Magor Farm in Illogan, near Camborne, an archaeological site has been identified as being a villa.
Archaeology.
The Dumnonii are thought to have occupied relatively isolated territory in Cornwall, Devon, Somerset and possibly part of Dorset. Their cultural connections, as expressed in their ceramics, were with the peninsula of Armorica across the Channel, rather than with the southeast of Britain. They do not seem to have been politically centralised: coins are relatively rare, none of them locally minted, and the structure, distribution and construction of Bronze Age and Iron Age hill forts, "rounds" and defensible farmsteads in the south west point to a number of smaller tribal groups living alongside each other.
Dumnonia is noteworthy for its many settlements that have survived from the Romano-British period, but also for its lack of a villa system. Local archaeology has revealed instead the isolated enclosed farmsteads known locally as "rounds". These seem to have survived the Roman abandonment of Britain, but were subsequently replaced, in the 6th and 7th centuries, by the unenclosed farms taking the Brythonic toponymic "tre-".
As in most other Brythonic areas, Iron Age hill forts, such as Hembury Castle, were refortified for the use of chieftains or kings. Other high-status settlements such as Tintagel seem to have been reconstructed during this period. Post-Roman imported pottery has been excavated from many sites across the region, and the apparent surge in late 5th century Mediterranean and/or Byzantine imports is yet to be explained satisfactorily.
Industries.
Apart from fishing and agriculture, the main economic resource of the Dumnonii was tin mining. The area of Dumnonia had been mined since ancient times, and the tin was exported from the ancient trading port of Ictis (St Michael's Mount). Tin extraction (mainly by streaming) had existed here from the early Bronze Age around the 22nd century BC. West Cornwall, around Mount's Bay, was traditionally thought to have been visited by metal traders from the eastern Mediterranean
During the first millennium BC trade became more organised, first with the Phoenicians, who settled Gades (Cadiz) around 1100 BC, and later with the Greeks, who had settled Massilia (Marseilles) and Narbo (Narbonne) around 600 BC. Smelted Cornish tin was collected at Ictis whence it was conveyed across the Bay of Biscay to the mouth of the Loire and then to Gades via the Loire and Rhone valleys. It went then through the Mediterranean Sea in ships to Gades.
During the period c. 500-450 BC, the tin deposits seem to have become more important, and fortified settlements appear such as at Chun Castle and Kenidjack Castle, to protect both the tin smelters and mines.
The earliest account of Cornish tin mining was written by Pytheas of Massilia late in the 4th century BC after his circumnavigation of the British Isles. Underground mining was described in this account, although it cannot be determined when it had started. Pytheas's account was noted later by other writers including Pliny the Elder and Diodorus Siculus.
It is likely that tin trade with the Mediterranean was later on under the control of the Veneti. Britain was one of the places proposed for the "Cassiterides", that is Tin Islands. Tin working continued throughout Roman occupation although it appears that output declined because of new supplies brought in from the deposits discovered in Iberia (Spain and Portugal). However when these supplies diminished, production in Dumnonia increased and appears to have reached a peak during the 3rd century AD.
Sub-Roman and post-Roman Dumnonia.
The Sub-Roman or Post-Roman history of Dumnonia comes from a variety of sources and is considered exceedingly difficult to interpret given that historical fact, legend and confused pseudo-history are compounded by a variety of sources in Middle Welsh and Latin. The main sources available for discussion of this period include Gildas's "De Excidio Britanniae" and Nennius's "Historia Brittonum", the "Annales Cambriae", "Anglo-Saxon Chronicle", William of Malmesbury's "Gesta Regum Anglorum" and "De Antiquitate Glastoniensis Ecclesiae", along with texts from the "Black Book of Carmarthen" and the "Red Book of Hergest", and Bede's "Historia ecclesiastica gentis Anglorum" as well as "The Descent of the Men of the North" ("Bonedd Gwŷr y Gogledd", in Peniarth MS 45 and elsewhere) and the "Book of Baglan".

</doc>
<doc id="8372" url="http://en.wikipedia.org/wiki?curid=8372" title="Declaration of independence">
Declaration of independence

A declaration of independence or declaration of statehood is an assertion by a defined territory that it is independent and constitutes a state. Such places are usually declared from part or all of the territory of another nation or failed nation, or are breakaway territories from within the larger state. In 2010, UN's International Court of Justice ruled in an advisory opinion in Kosovo that "International law contains no prohibition on declarations of independence", though the state from which the territory wishes to secede may regard the declaration as rebellion, which may lead to a war of independence or a constitutional settlement to resolve the crisis. Not all declarations of independence succeed in the formation of an independent state.

</doc>
<doc id="8373" url="http://en.wikipedia.org/wiki?curid=8373" title="Drag racing">
Drag racing

Drag Racing is a type of motor racing in which automobiles or motorcycles (usually specially prepared for the purpose) compete, usually two at a time, to be first to cross a set finish line. The race follows a short, straight course from a standing start over a measured distance, most commonly ¼ mile (1,320 ft), with a shorter 3/16 mile 10 feet (1,000 ft) for nitromethane powered Top Fuel dragsters and funny cars, while 660 ft (1/8 mi) is also popular in some circles. Electronic timing and speed sensing systems have been used to record race results since the 1960s.
Drag racing has existed in both street racing and regulated motorsport forms since automobiles and motorcycles were developed. The street racing form, which is illegal, is covered elsewhere; this article covers the legal sport.
Basics of drag racing.
Before each race (commonly known as a pass), each driver is allowed to perform a burnout, which heats the driving tires and lays rubber down at the beginning of the track, improving traction. Each driver then lines up (or stages) at the starting line.
Races are started electronically by a system known as a "Christmas tree". The Christmas tree consists of a column of six lights for each driver/lane, one blue, then three amber, one green, and one red, connected to light beams on the track. The blue is split into two halves. When the first light beam is broken by the vehicle's front tire(s) indicates that the driver has pre-staged (approximately 7 in from the starting line), lights the first half of the blue circle, and then stages (at the starting line), which lights up the second half of the blue circle, and also the corresponding bar in the middle of that circle. 
Once the first competitor trips the staged beam, the tree is automatically activated, and the opponent will have up to seven seconds to stage or a red light and automatic timed-out disqualification occurs instantly. Otherwise, when both drivers are staged the tree will start the race between .8 and 1.3 seconds after the race is staged, with the time randomly selected by the Autostart system, which causes the three large amber lights to illuminate, followed by the green one. There are two standard light sequences: either the three amber lights flash simultaneously, followed 0.4 seconds later by the green light (a Pro tree), or the amber lights in sequence from top to bottom, 0.5 seconds apart, followed 0.5 seconds later by the green light (a Sportsman tree, or full tree). If the front tires leave from a stage beam (stage turn off) before the green light illuminates, the red light for that driver's lane illuminates instead, indicating disqualification (unless a more serious violation occurs). Once a driver commits a red-light foul (also known as "redlighting"), the other driver can also commit a foul start by leaving the line too early but still win, having left later. The green light automatically is illuminated on the opposite side of the red-lighting driver. Should both drivers leave after the green light illuminates, the one leaving first is said to have a "holeshot advantage".
Except where a breakout rule is in place, the winner is the first vehicle to cross the finish line (and therefore the driver with the lowest total reaction time and elapsed time). The elapsed time is a measure of performance only; it does not necessarily determine the winner. Because elapsed time does not include reaction time and each lane is timed individually, a car with a slower elapsed time can actually win if that driver's holeshot advantage exceeds the elapsed time difference. In heads-up racing, this is known as a "holeshot win". In categories where a breakout rule (some dial-in categories are this way, but Junior Dragster, Super Comp, Super Gas, Super Stock, and Stock most notably) is in effect, if a competitor is faster than their predetermined time, that competitor loses. If both are faster than their predetermined time, the competitor closer to that time wins. Regardless, a red light foul is worse than a breakout, except in Junior Dragster where exceeding the absolute limit is a cause for disqualification.
Several measurements are taken for each race: reaction time, elapsed time, and speed. Reaction time is the period from the green light illuminating to the vehicle leaving the starting line. Elapsed time is the period from the vehicle leaving the starting line to crossing the finish line. Speed is measured through a speed trap covering the final 66 ft to the finish line, indicating average speed of the vehicle during the run last 66 feet (20m).
In the standard racing format, the losing car and driver are removed from the contest, while the winner goes on to race other winners, until only one is left, based on a traditional bracket system (typically 4, 8, or 16 car brackets). In standard formats, the pairings are based on the lowest elapsed times. In bracket racing without a breakout (such as NHRA Competition Eliminator), pairings are based on times compared to their index (faster than index for class is better). In bracket racing with a breakout (Stock, Super Stock, but also the NHRA's Super classes), the closest to the index is favourable.
A popular alternative to the standard eliminations format is the Chicago Style format (also called the Three Round format in Australia), named for the US 30 Dragstrip in suburban Gary, Indiana where a midweek meet will feature this format. All entered cars participate in one qualifying round, and then are paired for the elimination round. The two fastest times among winners from this round will participate in the championship round. Depending on the organisation, the next two fastest times may play in a third, then fifth, and so forth, in consolation rounds.
Racing organization.
North America.
The National Hot Rod Association (NHRA) oversees the majority of drag racing events in North America. The next largest organization is the International Hot Rod Association (IHRA). Nearly all drag strips are associated with one sanctioning body or the other.
Besides NHRA and IHRA, there are niche organizations for muscle cars and nostalgia vehicles. The Nostalgia Drag Racing League (NDRL) based in Brownsburg, IN, runs a series of 1/4 mile (400m) drag races in the Midwest for 1979 and older nostalgic appearing cars, with four classes of competition running in an index system. Pro 7.0 and Pro 7.50 run heads up 200 mile per hour (320 kilometre per hour) passes, while Pro Comp and Pro Gas run 8.0 to 10.0 indices. NDRL competition vehicles typically include Front Engine Dragsters, Altereds, Funny Cars, early Pro Stock clones, Super Stocks and Gassers.
The National Electric Drag Racing Association (NEDRA) races electric vehicles against high performance gasoline-powered vehicles such as Dodge Vipers or classic muscle cars in 1/4 and 1/8 mile (400m   200m) races. The current electric drag racing record is 6.940 seconds at 201.37 mph (324.0736 kph) for a quarter mile (400m). Another niche organization is the VWDRC which run a VW-only championship with vehicles running under 7 seconds.
Prior to the founding of the NHRA and IHRA, smaller organizations sanctioned drag racing in the early years.
Australia.
The first Australian Nationals event was run in 1965 at Riverside raceway, near Melbourne. The Australian National Drag Racing Association (ANDRA) was established in 1973, and today they claim they are the "best in the world outside the United States". ANDRA sanctions races throughout Australia and throughout the year at all levels, from Junior Dragster to Top Fuel.
The ANDRA Pro Series is for professional drivers and riders and includes Top Fuel, Top Alcohol, Top Doorslammer (similar to the USA Pro Modified class), Pro Stock (using 400 cubic inch engines (6.5 litres)), Top Bike and Pro Stock Motorcycle. ANDRA is the only organisation that officially sanctions ¼ mile drag racing for Top Fuel.
The Rocket Allstars Racing Series is for sportsman drivers and riders and includes Competition, Super Stock, Super Compact, Competition Bike, Supercharged Outlaws, Modified, Super Sedan, Modified Bike, Super Street and Junior Dragster.
Broadcasting is provided on SBS Speedweek.
Europe.
Drag racing was imported to Europe by American NATO troops during the Cold War. Races were held in West Germany beginning in the 1960s at the airbases at Ramstein and Sembach and in the UK at various airstrips and racing circuits before the opening of Europe's first permanent drag strip at Santa Pod Raceway in 1966.
The FIA organises a Europe-wide four wheeled championship for the Top Fuel, Top Methanol Dragster, Top Methanol Funny Car, Pro Modified and Pro Stock classes. FIM Europe organises a similar championship for bike classes. In addition, championships are run for sportsman classes in many countries throughout Europe by the various national motorsport governing bodies.
New Zealand.
Drag racing in New Zealand started in the 1960s. The New Zealand Hot Rod Association (NZHRA) sanctioned what is believed to have been the first drag meeting at an open cut coal mine at Kopuku, south of Auckland, sometime in 1966. In 1973, the first and only purpose built drag strip opened in Meremere by the Pukekohe Hot Rod Club. In April 1993 the governance of drag racing was separated from the NZHRA and the New Zealand Drag Racing Association (NZDRA) was formed. In 2014, New Zealand's second purpose built drag strip - Masterton Motorplex - opened.
The first New Zealand Drag Racing Nationals was held in the 1966/67 season at Kopuku, near Auckland.
There are now two governing bodies operating drag racing in New Zealand with the sanctioning both of New Zealands major tracks at Ruapuna () on the South Island and in the North Island.
South America.
A lot of countries in South America race use 200 meters unlike United states and places like Australia who use the 400 meters 1/4 mile.
Organized drag racing in Colombia is Club G3's responsibility, which is a private organization. The events take part at Autódromo de Tocancipá.
Caribbean.
Curaçao
On the island of Curaçao, organization of drag racing events is handled by the Curaçao Autosport Foundation (FAC)
All racing events, including street legal competitions, happen at the Curaçao International Raceway.
South Asia.
Organized drag racing is rapidly growing in India. "Autocar India" organised the country's first drag race meet in Mumbai in 2002.
Drag racing is also gaining popularity in Pakistan, with private organizations organizing such events. The Bahria Town housing project recently organized a drag racing event in Rawalpindi, with the help of some of the country's best drivers.
Sri Lanka has seen an immense growth in Drag racing through legal meets held by the Ceylon Motor Sports Club, an FiA sanctioned body. In recent years, exotic cars and Japanese power houses have been taking part in these popular events.
Middle East.
 is the home of Motorsports in the Middle East. QRC provides access to the best drag strip and drift skid pad in the world, which allows participants to unleash the power of their cars and bikes in a safe and controlled environment. QRC with the help of the fine Racing Organizations wish to establish common rules and seeks parity amongst classes within the Gulf Region. The goal of the QRC is to help, along with the other organizations to promote World Wide Awareness of the sport of Drag Racing & Drifting.
Driver can compete in a number of competitions including ADRL, QATAR MILE, NATIONAL STREET DRAG CHAMPIONSHIP, QATAR DRIFT CHAMPIONSHIP, FREESTYLE DRIFT and SEALINE SAND DRAGS.
South Africa.
Drag racing is an established sport in South Africa, with a number of strips around the country including Tarlton International Raceway and ODI Raceway. Drag racing is controlled by Motorsport South Africa and all drivers are required to hold a valid Motorsport South Africa license. Drivers can compete in a number of categories including Top Eliminator, Senior Eliminator, Super Competition Eliminator, Competition Eliminator, Pro Street Bikes, Superbike Eliminator, Supersport Shootout (motorcycle), Street Modified, and Factory Stock.
Classes.
There are hundreds of classes in drag racing, each with different requirements and restrictions on things such as weight, engine size, body style, modifications, and many others. NHRA and IHRA share some of these classes, but many are solely used by one sanctioning body or the other. The NHRA boasts over 200 classes, while the IHRA has fewer. Some IHRA classes have multiple sub-classes in them to differentiate by engine components and other features. There is even a class for aspiring youngsters, Junior Dragster, which typically uses an eighth-mile track, also favored by VW racers.
In 1997, the FIA (cars) and UEM (bikes) began sanctioning drag racing in Europe with a fully established European Drag Racing Championship, in cooperation (and rules compliance) with NHRA. The major European drag strips include Santa Pod Raceway in Podington, England; Alastaro Circuit, Finland; Mantorp Park, Sweden; Gardermoen Raceway, Norway and the Hockenheimring in Germany. The major difference is the nitro-class distance, which is 300 meters at some tracks, although the NHRA and FIA are likely to discuss the distance change in the future.
There is a somewhat arbitrary definition of what constitutes a "professional" class. The NHRA includes 5 pro classes; Top Fuel, Funny Car, Pro Stock, Pro Modified and Pro Stock Motorcycle. The FIA features a different set of 5 pro classes; Top Fuel, Top Methanol Dragster, Top Methanol Funny Car, Pro Modified and Pro Stock. Other sanctioning bodies have similarly different definitions. A partial list of classes includes:
A complete listing of all classes can be found on the respective NHRA and IHRA official websites.
The UEM also has a different structure of professional categories with Top Fuel Bike, Super Twin Top Fuel Bike, and Pro Stock Bike contested, leaving the entire European series with a total of 8 professional categories.
To allow different cars to compete against each other, some competitions are raced on a handicap basis, with faster cars delayed on the start line enough to theoretically even things up with the slower car. This may be based on rule differences between the cars in stock, super stock, and modified classes, or on a competitor's chosen "dial-in" in bracket racing.
Dial-in.
A "dial-in" is a time the driver estimates it will take his or her car to cross the finish line, and is generally displayed on one or more windows so the starter can adjust the starting lights on the tree accordingly. The slower car will then get a head start equal to the difference in the two dial-ins, so if both cars perform perfectly, they would cross the finish line dead even. If either car goes faster than its dial-in (called breaking out), it is disqualified regardless of who has the lower elapsed time; if both cars break out, the one who breaks out by the smallest amount wins. However, if a driver had jump-started (red light) or crossed a boundary line, both violations override any break out (except in some classes with an absolute break out rule such as Junior classes). This eliminates any advantage from putting a slower time on the windshield to get a head start. The effect of the bracket racing rules is to place a premium on consistency of performance of the driver and car rather than on raw speed, in that victory goes to the driver able to precisely predict elapsed time, whether it is fast or slow. This in turn makes victory much less dependent on large infusions of money, and more dependent on skill. Therefore, bracket racing is popular with casual weekend racers. Many of these recreational racers will drive their vehicles to the track, race them, and then simply drive them home. As most tracks host only one NHRA national event, and two or three regional events (smaller tours, car shows, "etc.") annually, on most weekends these tracks host local casual and weekend racers. Organizationally, however, the tracks are run according to the rules of either the NHRA or the IHRA with regional points and a championship on the line. Even street vehicles must pass a safety inspection prior to being allowed to race.
External links.
 Media related to at Wikimedia Commons

</doc>
<doc id="8375" url="http://en.wikipedia.org/wiki?curid=8375" title="Draugr">
Draugr

The draugr or draug (Old Norse: "draugr", plural draugar; modern Icelandic: "draugur", Faroese: "dreygur" and Norwegian, Swedish and Danish draugen), also called aptrganga or aptrgangr, literally "again-walker" (Icelandic: "afturganga") is an undead creature from Norse mythology, a subset of Germanic mythology.
The Old Norse meaning of the word is a revenant."The will appears to be strong, strong enough to draw the "hugr" [animate will] back to one's body. These reanimated individuals were known as "draugar". However, though the dead might live again, they could also die again. "Draugar" die a "second death" as Chester Gould calls it, when their bodies decay, are burned, dismembered or otherwise destroyed. Draugar live in their graves, often guarding treasure buried with them in their burial mound. They are animated corpses - unlike ghosts they have a corporeal body with similar physical abilities as in life. Older literature makes clear distinctions between sea-draugar and land-draugar.
Traits.
Draugar possess superhuman strength, can increase their size at will, and carry the unmistakable stench of decay. "The appearance of a "draugr" was that of a dead body: swollen, blackened and generally hideous to look at." They are undead figures from Norse and Icelandic mythology that appear to retain some semblance of intelligence. They exist either to guard their treasure, wreak havoc on living beings, or torment those who had wronged them in life. The draugr's ability to increase its size also increased its weight, and the body of the draugr was described as being extremely heavy. Thorolf of Eyrbyggja saga was "uncorrupted, and with an ugly look about him... swollen to the size of an ox," and his body was so heavy that it could not be raised without levers. They are also noted for the ability to rise from the grave as wisps of smoke and "swim" through solid rock, which would be useful as a means of exiting their graves.
In folklore, draugar slay their victims through various methods including crushing them with their enlarged forms, devouring their flesh, devouring them whole in their enlarged forms, indirectly killing them by driving them mad, and by drinking their blood. Animals feeding near the grave of a draugr may be driven mad by the creature's influence. They may also die from being driven mad. Thorolf, for example, caused birds that flew over his bowl barrow to drop dead. Draugar are also noted as being able to drive living people insane.
The draugr's victims were not limited to trespassers in its howe. The roaming undead decimated livestock by running the animals to death while either riding them or pursuing them in some hideous, half-flayed form. Shepherds, whose duties to their flocks left them out of doors at night time, were also particular targets for the hunger and hatred of the undead:
[T]he oxen which had been used to haul Thorolf's body were ridden to death by demons, and every single beast that came near his grave went raving mad and howled itself to death. The shepherd at Hvamm often came racing home with Thorolf after him. One day that Fall neither sheep nor shepherd came back to the farm.
Draugar are noted for having numerous magical abilities (referred to as "trollskap") resembling those of living witches and wizards such as shape-shifting, controlling the weather and seeing into the future. Among the creatures that a draugr may turn into are a seal, a great flayed bull, a grey horse with a broken back but no ears or tail and a cat that would sit upon a sleeper's chest and grow steadily heavier until the victim suffocated. The draugr Þráinn (Thrain) shape-shifted into a "cat-like creature" ("kattakyn") in "Hrómundar saga Gripssonar":
Then Thrain turned himself into a troll, and the barrow was filled with a horrible stench; and he stuck his claws into the back of Hromund's neck, tearing the flesh from his bones...
Draugar have the ability to enter into the dreams of the living, "but it generally happens even so that they leave beside the living person some gift, by which, on awakening, the living person may be assured of the tangible nature of the visit." Draugar also have the ability to curse a victim, as shown in the Grettis saga, where Grettir is cursed to be unable to become any stronger. Draugar also brought disease to a village and could create temporary darkness in daylight hours. While the draugr certainly preferred to be active during the night, it did not appear to be vulnerable to sunlight like some other revenants.
A draugr's presence may be shown by a great light that glowed from the mound like foxfire. This fire would form a barrier between the land of the living and the land of the dead. The draugr could also move magically through the earth, swimming through solid stone as does Killer-Hrapp:
Then Olaf tried to rush Hrapp, but Hrapp sank into the ground where he had been standing and that was the end of their encounter.
Some draugar are immune to weapons, and only a hero has the strength and courage needed to stand up to so formidable an opponent. In legends the hero would often have to wrestle the draugr back to his grave, thereby defeating him, since weapons would do no good. A good example of this kind of fight is found in "Hrómundar saga Gripssonar". Although iron could injure a draugr, as is the case with many supernatural creatures, it would not be sufficient to stop it. Sometimes the hero is required to dispose of the body in unconventional ways. The preferred method is to cut off the draugr's head, burn the body, and dump the ashes in the sea; the emphasis being on making absolutely sure the draugr was dead and gone.
The draugar were said to be either "hel-blár" ("blue-death") or, conversely, "nár-fölr" ("corpse-pale"). The "blue-death" color was not actually grey but was a dark blue or maroon hue that covered the entire body. Glámr, the undead shepherd of "Grettis saga", was reported to be dark blue in color and in Laxdæla saga, the bones of a dead sorceress who had appeared in dreams were dug up and found to be "blue and evil looking."
The resting place of the draugr was a tomb that served much as a workable home for the creature. Draugar are able to leave this dwelling place and visit the living during the night. Such visits are supposed to be universally horrible events that often end in death for one or more of the living, which would then warrant the exhumation of the draugr by a hero.
The motivation of the actions of a draugr was primarily jealousy and greed. The greed of a draugr causes it to viciously attack any would-be grave robbers, but the draugr also expresses an innate jealousy of the living, stemming from a longing for the things of the life it once had. This idea is clearly expressed in "Friðþjófs saga", where a dying king declared:
My howe shall stand beside the firth. And there shall be but a short distance between mine and Thorsteinn's, for it is well that we should call to one another.
This desire for the friendship experienced in life is one example of the manifestation of this aspect of the draugr. Draugar also exhibit an immense and nearly insatiable appetite, as shown in the encounter of Aran and Asmund, sword brothers who made an oath that if one should die, the other would sit vigil with him for three days inside the burial mound. When Aran died, Asmund brought his own possessions into the barrow: banners, armor, hawk, hound, and horse. Then Asmund set himself to wait the agreed upon three days:
During the first night, Aran got up from his chair and killed the hawk and hound and ate them. On the second night he got up again from his chair, and killed the horse and tore it into pieces; then he took great bites at the horse-flesh with his teeth, the blood streaming down from his mouth all the while he was eating... The third night Asmund became very drowsy, and the first thing he knew, Aran had got him by the ears and torn them off.
Creation of draugar.
After a person’s death, the main indication that the person will become a draugr is that the corpse is not in a horizontal position. In most cases, the corpse is found in an upright or sitting position, and this is an indication that the dead might return. Any mean, nasty, or greedy person can become a draugr. As noted by Ármann, “most medieval Icelandic ghosts are evil or marginal people. If not dissatisfied or evil, they are unpopular”. This is the prime way that draugar share characteristics with ghosts, since any person can become a ghost.
In many Western mythologies, ghosts are generally people with unfinished business or those who are so evil their spirit makes an impact on the place they lived. Ghosts and draugar refuse to follow the prescribed path of death, selfishly staying on Earth when they are supposed to move on. This is easily understandable because, “selfishness is an important attribute of every ghost, and therefore it is no wonder that ghosts tend to be people who were troublesome during their lifetime”.
However, unlike ghosts, draugar can also come about through infection by another draugr such as in the story of Glámr. When Glámr arrives in the haunted valley in "Grettis saga", "the previous evil spirits are relegated to the sidelines and, when Glámr is found dead, they disappear, whereas he takes over their role as ghost of the valley." Although Glámr is an arguably marginal character to begin with, it is only after his fight with the first malignant spirit that the first spirit leaves the valley, and Glámr takes its place wreaking havoc. Similarly, in "Eyrbyggja saga", a shepherd is killed by a draugr and rises the next night as one himself.
Means of prevention.
Traditionally, a pair of open iron scissors were placed on the chest of the recently deceased, and straws or twigs might be hidden among their clothes. The big toes were tied together or needles were driven through the soles of the feet in order to keep the dead from being able to walk. Tradition also held that the coffin should be lifted and lowered in three different directions as it was carried from the house to confuse a possible draugr's sense of direction.
The most effective means of preventing the return of the dead was believed to be the corpse door. A special door was built, through which the corpse was carried feet-first with people surrounding it so the corpse couldn't see where it was going. The door was then bricked up to prevent a return. It is speculated that this belief began in Denmark and spread throughout the Norse culture. The belief was founded on the idea that the dead could only leave through the way they entered.
In "Eyrbyggja saga", the draugar infesting the home of the Icelander Kiartan were driven off by holding a "door-doom". One by one the draugar were summoned to the door-doom and given judgment and were forced out of the home by this legal method. The home was then purified with holy water to ensure they never came back.
Similar creatures.
A variation of the draugr is the "haugbui". The haugbui (from Old Norse "haugr"' "howe, barrow, tumulus") was a mound-dweller, the dead body living on within its tomb. The notable difference between the two was that the haugbui is unable to leave its grave site and only attacks those that trespass upon their territory.
The haugbui was rarely found far from its burial place and is a type of undead commonly found in Norse saga material. The creature is said to either swim alongside boats or sail around them in a partially submerged vessel, always on their own. In some accounts, witnesses portray them as shapeshifters who take on the appearance of seaweed or moss-covered stones on the shoreline.
The words "dragon" and "draugr" are not linguistically related. However, both the serpent and the spirit serve as jealous guardians of the graves of kings or ancient civilizations. Dragons that act as draugar appear in "Beowulf" as well as in some of the heroic lays of the "Poetic Edda" (in the form of Fafnir).
Folklore.
Icelandic Sagas.
One of the best-known draugar is Glámr, who is defeated by the hero in "Grettis saga". After Glámr dies on Christmas Eve, "people became aware that Glámr was not resting in peace. He wrought such havoc that some people fainted at the sight of him, while others went out of their minds". After an mundane battle, Grettir eventually gets Glámr on his back. Just before Grettir kills him, Glámr curses Grettir because "Glámr was endowed with more evil force than most other ghosts", and thus he was able to speak and leave Grettir with his curse after his death.
A somewhat ambivalent, alternative view of the draugr is presented by the example of Gunnar Hámundarson in "Njál's saga":
It seemed as though the howe was agape, and that Gunnar had turned within the howe to look upwards at the moon. They thought that they saw four lights within the howe, but not a shadow to be seen. Then they saw that Gunnar was merry, with a joyful face.
In the "Eyrbyggja saga", a shepherd is assaulted by a blue-black draugr. The shepherd's neck is broken during the ensuing scuffle. The shepherd rises the next night as a draugr.
Recent.
In more recent Scandinavian folklore, the draug (the modern spelling used in Denmark, Norway, and Sweden) is often identified with the spirits of mariners drowned at sea. The creature is said to possess a distinctly human form, with the exception that its head is composed entirely of seaweed. In other tellings, the draug is described as being a headless fisherman, dressed in oilskin and sailing in half a boat (the Norwegian municipality of Bø, Nordland has the half-boat in its coat-of-arms). This trait is common in the northernmost part of Norway, where life and culture was based on fishing more than anywhere else. The reason for this may be that the fishermen often drowned in great numbers, and the stories of restless dead coming in from sea were more common up north than anywhere else in the country.
A recorded legend from Trøndelag tells how a cadaver lying on a beach became the object of a quarrel between the two types of draug (headless and seaweed-headed). A similar source even tells of a third type, the "gleip", known to hitch themselves to sailors walking ashore and make them slip on the wet rocks.
But, though the draug usually presages death, there is an amusing account in Northern Norway of a northerner who managed to outwit him:
It was Christmas Eve, and Ola went down to his boathouse to get the keg of brandy he had bought for the holidays. When he got in, he noticed a draugr sitting on the keg, staring out to sea. Ola, with great presence of mind and great bravery (it might not be amiss to state that he already had done some drinking), tiptoed up behind the draugr and struck him sharply in the small of the back, so that he went flying out through the window, with sparks hissing around him as he hit the water. Ola knew he had no time to lose, so he set off at a great rate, running through the churchyard which lay between his home and the boathouse. As he ran, he cried, "Up, all you Christian souls, and help me!" Then he heard the sound of fighting between the ghosts and the draugr, who were battling each other with coffin boards and bunches of seaweed. The next morning, when people came to church, the whole yard was strewn with coffin covers, boat boards, and seaweed. After the fight, which the ghosts won, the draugr never came back to that district.
Literature.
The modern and popular connection between the draug and the sea can be traced back to the author Jonas Lie and the story-teller Regine Nordmann, as well as the drawings of Theodor Kittelsen, who spent some years living in Svolvær. Up north, the tradition of sea-draugs is especially vivid.
Arne Garborg describes land-draugs coming fresh from the graveyards, and the term "draug" is even used of vampires. The notion of draugs who live in the mountains is present in the poetic works of Henrik Ibsen ("Peer Gynt"), and Aasmund Olavsson Vinje. The Nynorsk translation of "The Lord of the Rings" used the term for both Nazgûl and the dead men of Dunharrow.
The term "draug" has come to be used to describe any type of revenant in Nordic folklore.

</doc>
<doc id="8376" url="http://en.wikipedia.org/wiki?curid=8376" title="Day">
Day

A day is a unit of time. In common usage, it is an interval equal to 24 hours. It also can mean the consecutive period of time during which the Sun is above the horizon of a location, also known as daytime. The period of time measured from local noon to the following local noon is called a "solar day".
Several definitions of this universal human concept are used according to context, need and convenience. In 1967, the second was redefined in terms of the wavelength of light, and it became the SI base unit of time. The unit of measurement for time called "day", redefined in 1967 as 86,400 SI seconds and symbolized "d", is not an SI unit, but it is accepted for use with SI.
A civil day is usually also 86,400 seconds, plus or minus a possible leap second in Coordinated Universal Time UTC, and, in some locations, occasionally plus or minus an hour when changing from or to daylight saving time. The word "day" may also refer to a day of the week or to a calendar date, as in answer to the question "On which day?" "Day" also refers to the part of the day that is not night — also known as "daytime". The life patterns of humans and many other species are related to Earth's solar day and the cycle of day and night (see circadian rhythms).
The average length of a solar day on Earth is about 86,400 seconds (24 hours) and there are about 365.2422 solar days in one mean tropical year. Because celestial orbits are not perfectly circular, and thus objects travel at different speeds at various positions in their orbit, a solar day is not the same length of time throughout the orbital year. A "day", understood as the span of time it takes for the Earth to make one entire rotation
with respect to the celestial background or a distant star (assumed to be fixed), is called "stellar day". This period of rotation is about 4 minutes less than 24 hours (23 hours 56 minutes and 4.1 seconds) and there are about 366.2422 in one mean tropical year (one more stellar day than the number of solar days). Mainly due to tidal effects, the Earth's rotational period is not constant, resulting in further minor variations for both solar days and stellar "days". Other planets and moons also have stellar and solar days.
Introduction.
Besides the day of 24 hours (86,400 seconds), the word "day" is used for several different spans of time based on the rotation of the Earth around its axis. An important one is the solar day, defined as the time it takes for the sun to return to its culmination point (its highest point in the sky). Because the Earth orbits the Sun elliptically as the Earth spins on an inclined axis, this period can be up to 7.9 seconds more than (or less than) 24 hours. On average over the year this day is equivalent to 24 hours (86,400 seconds).
A day, in the sense of daytime that is distinguished from night-time, is commonly defined as the period during which sunlight directly reaches the ground, assuming that there are no local obstacles. The length of daytime averages slightly more than half of the 24-hour day. Two effects make daytime on average longer than nights. The Sun is not a point, but has an apparent size of about 32 minutes of arc. Additionally, the atmosphere refracts sunlight in such a way that some of it reaches the ground even when the Sun is below the horizon by about 34 minutes of arc. So the first light reaches the ground when the centre of the Sun is still below the horizon by about 50 minutes of arc. The difference in time depends on the angle at which the Sun rises and sets (itself a function of latitude), but can amount to around seven minutes.
Ancient custom has a new day start at either the rising or setting of the Sun on the local horizon (Italian reckoning, for example) The exact moment of, and the interval between, two sunrises or two sunsets depends on the geographical position (longitude as well as latitude), and the time of year. This is the time as indicated by ancient hemispherical sundials.
A more constant day can be defined by the Sun passing through the local meridian, which happens at local noon (upper culmination) or midnight (lower culmination). The exact moment is dependent on the geographical longitude, and to a lesser extent on the time of the year. The length of such a day is nearly constant (24 hours ± 30 seconds). This is the time as indicated by modern sundials.
A further improvement defines a fictitious mean Sun that moves with constant speed along the celestial equator; the speed is the same as the average speed of the real Sun, but this removes the variation over a year as the Earth moves along its orbit around the Sun (due to both its velocity and its axial tilt).
The Earth's day has increased in length over time. This phenomenon is due to tides raised by the Moon which slow Earth's rotation. Because of the way the second is defined, the mean length of a day is now about 86,400.002 seconds, and is increasing by about 1.7 milliseconds per century (an average over the last 2,700 years. See tidal acceleration for details. The length of one day has been estimated as 21.9 hours 620 million years ago from rhythmites (alternating layers in sandstone). The length of day for the Earth or Proto-Earth before the event which created our moon by an impact is yet unknown.
Etymology.
The term comes from the Old English "dæg", with its cognates such as "dagur" in Icelandic, "Tag" in German, and "dag" in Norwegian, Danish, Swedish and Dutch. "Day" is the 98th most common word in English according to AskOxford.com.
International System of Units (SI).
A day, symbol "d", is defined as 86,400 seconds. The second is the unit of time in SI units.
A day on the UTC time standard can include a negative or positive leap second, and can therefore have a length of 86,399 or 86,401 seconds.
The International Bureau of Weights and Measures (BIPM) currently defines a second as … the duration of 9 192 631 770 periods of the radiation corresponding to the transition between two hyperfine levels of the ground state of the caesium 133 atom.
This makes the SI-based day last exactly 794,243,384,928,000 of those periods.
Decimal and metric time.
In the 19th century it had also been suggested to make a decimal fraction (1⁄10,000 or 1⁄100,000) of an astronomic day the base unit of time. This was an afterglow of decimal time and calendar, which had been given up already for its difficulty to comply with familiar units. The still most successful candidate is the "centiday" = 14.4 minutes, as a shorter quarter of an hour and also close to the SI target kilosecond and old Chinese ke.
Astronomy.
A day of exactly 86,400 SI seconds is the astronomical unit of time (the second is not preferred in astronomy).
For a given planet, there are three types of day defined in astronomy:
For Earth, the stellar day and the sidereal day are nearly of the same length and about 3 minutes 56 seconds shorter than the solar day. Relative to the fixed stars, the Earth spins just over 366 times upon its axis during one complete orbit. The Earth's orbit around the Sun reduces (by one) the number of transits the Sun makes across the Earth's sky in a sidereal year.
Colloquial.
The word refers to various relatedly defined ideas, including the following:
Civil day.
For civil purposes a common clock time has been defined for an entire region based on the mean local solar time at some central meridian. Such time zones began to be adopted about the middle of the 19th century when railroads with regular schedules came into use, with most major countries having adopted them by 1929. For the whole world, 40 such time zones are now in use. The main one is "world time" or Coordinated Universal Time (UTC).
The present common convention has the civil day starting at midnight, which is near the time of the lower culmination of the mean Sun on the central meridian of the time zone. Such a day may be referred to as a Calendar day.
A day is commonly divided into 24 hours of 60 minutes of 60 seconds each.
Leap seconds.
To keep the civil day aligned with the apparent movement of the Sun, positive or negative leap seconds may be inserted.
A civil clock day is typically 86,400 SI seconds long, but will be 86,401 s or 86,399 s long in the event of a leap second.
Leap seconds are announced in advance by the International Earth Rotation and Reference Systems Service which measures the Earth's rotation and determines whether a leap second is necessary. Leap seconds occur only at the end of a UTC month, and have only ever been inserted at the end of June 30 or December 31.
Boundaries of the day.
For most diurnal animals, the day naturally begins at dawn and ends at sunset. Humans, with our cultural norms and scientific knowledge, have employed several different conceptions of the day's boundaries. The Jewish day begins at either sunset or at nightfall (when three second-magnitude stars appear). Medieval Europe followed this tradition, known as Florentine reckoning: in this system, a reference like "two hours into the day" meant "two hours after sunset" and thus times during the evening need to be shifted back one calendar day in modern reckoning. Days such as Christmas Eve, Halloween, and the Eve of Saint Agnes are the remnants of the older pattern when holidays began the evening before. Present common convention is for the civil day to begin at midnight, that is 00:00 (inclusive), and last a full 24 hours until 24:00 (exclusive).
In ancient Egypt, the day was reckoned from sunrise to sunrise. Muslims fast from daybreak to sunset each day of the month of Ramadan. The "Damascus Document", copies of which were also found among the Dead Sea scrolls, states regarding Sabbath observance that "No one is to do any work on Friday "from the moment that the sun's disk stands distant from the horizon by the length of its own diameter"," presumably indicating that the monastic community responsible for producing this work counted the day as ending shortly before the sun had begun to set. 
In many cultures, nights are named after the previous day. For example,"Friday night" usually means the entire night between Friday and Saturday. This difference from the civil day often leads to confusion. Events starting at midnight are often announced as occurring the day before. TV-guides tend to list nightly programs at the previous day, although programming a VCR requires the strict logic of starting the new day at 00:00 (to further confuse the issue, VCRs set to the 12-hour clock notation will label this "12:00 AM"). Expressions like "today", "yesterday" and "tomorrow" become ambiguous during the night.
Validity of tickets, passes, etc., for a day or a number of days may end at midnight, or closing time, when that is earlier. However, if a service (e.g. public transport) operates from for example, 6:00 to 1:00 the next day (which may be noted as 25:00), the last hour may well count as being part of the previous day (also for the arrangement of the timetable). For services depending on the day ("closed on Sundays", "does not run on Fridays", and so on) there is a risk of ambiguity. As an example, for the Nederlandse Spoorwegen (Dutch Railways), a day ticket is valid 28 hours, from 0:00 to 28:00 (that is, 4:00 the next day). To give another example, the validity of a pass on London Regional Transport services is until the end of the "transport day"—that is to say, until 4:30 am on the day after the "expiry" date stamped on the pass.
24 hours vs daytime.
To distinguish between a full day and daytime, the word "nychthemeron" (from Greek for a night and a day) may be used in English for the former, or more colloquially the term "24 hours". In other languages, the latter is also often used. Other languages also have a separate word for a full day, such as ' in Finnish, ' in Estonian, ' in Swedish, ' in Danish, ' in Norwegian, ' in Icelandic, ' in Dutch, ' in Polish, ' ("sutki") in Russian, ' ("sutki") in Belarusian, ' ("doba") in Ukrainian, ' in Bulgarian and in Hebrew. In Italian, "giorno" is used to indicate a full day, while "dì" means daytime. In ancient India, "Ahoratra" is used to represent a full day. In Spanish, "singladura" is used, but only as a marine unit of length, being the distance covered in 24 hours.

</doc>
<doc id="8377" url="http://en.wikipedia.org/wiki?curid=8377" title="Database">
Database

A database is an integrated and organized collection of logically related records or files or data that are stored in a computer system which consolidates records previously stored in a separate files into a common pool of data records that provides data for many applications. The data is typically organized to model aspects of reality in a way that supports processes requiring information, such as modelling the availability of rooms in hotels in a way that supports finding a hotel with vacancies.
Database management systems (DBMS) are computer software applications that interact with the user, other applications, and the database itself to capture and analyze data. A general-purpose DBMS is designed to allow the definition, creation, querying, update, and administration of databases. Well-known DBMSs include MySQL, PostgreSQL, Microsoft SQL Server, Oracle, Sybase and IBM DB2. A database is not generally portable across different DBMSs, but different DBMS can interoperate by using standards such as SQL and ODBC or JDBC to allow a single application to work with more than one DBMS. Database management systems are often classified according to the database model that they support; the most popular database systems since the 1980s have all supported the relational model as represented by the SQL language. Sometimes a DBMS is loosely referred to as a 'database'.
Terminology and overview.
Formally, a "database" refers to a set of related data and the way it is organized. Access to this data is usually provided by a "database management system" (DBMS) consisting of an integrated set of computer software that allows users to interact with one or more databases and provides access to all of the data contained in the database (although restrictions may exist that limit access to particular data). The DBMS provides various functions that allow entry, storage and retrieval of large quantities of information as well as provides ways to manage how that information is organized.
Because of the close relationship between them, the term "database" is often used casually to refer to both a database and the DBMS used to manipulate it.
Outside the world of professional information technology, the term "database" is often used to refer to any collection of related data (such as a spreadsheet or a card index). This article is concerned only with databases where the size and usage requirements necessitate use of a database management system.
Existing DBMSs provide various functions that allow management of a database and its data which can be classified into four main functional groups:
Both a database and its DBMS conform to the principles of a particular database model. "Database system" refers collectively to the database model, database management system, and database.
Physically, database servers are dedicated computers that hold the actual databases and run only the DBMS and related software. Database servers are usually multiprocessor computers, with generous memory and RAID disk arrays used for stable storage. RAID is used for recovery of data if any of the disks fail. Hardware database accelerators, connected to one or more servers via a high-speed channel, are also used in large volume transaction processing environments. DBMSs are found at the heart of most database applications. DBMSs may be built around a custom multitasking kernel with built-in networking support, but modern DBMSs typically rely on a standard operating system to provide these functions. Since DBMSs comprise a significant economical market, computer and storage vendors often take into account DBMS requirements in their own development plans.
Databases and DBMSs can be categorized according to the database model(s) that they support (such as relational or XML), the type(s) of computer they run on (from a server cluster to a mobile phone), the query language(s) used to access the database (such as SQL or XQuery), and their internal engineering, which affects performance, scalability, resilience, and security
Applications.
Databases are used to support internal operations of organizations and to underpin online interactions with customers and suppliers (see Enterprise software).
Databases are used to hold administrative information and more specialized data, such as engineering data or economic models. Examples of database applications include computerized library systems, flight reservation systems and computerized parts inventory systems.
Application areas of DBMS
1. Banking: For customer information, accounts, and loans, and banking transactions.
2. Airlines: For reservations and schedule information. Airlines were among the first to use
databases in a geographically distributed manner - terminals situated around the world
accessed the central database system through phone lines and other data networks.
3. Universities: For student information, course registrations, and grades.
4. Credit card transactions: For purchases on credit cards and generation of monthly
statements.
5. Telecommunication: For keeping records of calls made, generating monthly bills,
maintaining balances on prepaid calling cards, and storing information about the
communication networks.
6. Finance: For storing information about holdings, sales, and purchases of financial
instruments such as stocks and bonds.
7. Sales: For customer, product, and purchase information.
8. Manufacturing: For management of supply chain and for tracking production of items in
factories, inventories of items in warehouses / stores, and orders for items.
9. Human resources: For information about employees, salaries, payroll taxes and benefits,
and for generation of paychecks.
General-purpose and special-purpose DBMSs.
A DBMS has evolved into a complex software system and its development typically requires thousands of person-years of development effort. Some general-purpose DBMSs such as Adabas, Oracle and DB2 have been undergoing upgrades since the 1970s. General-purpose DBMSs aim to meet the needs of as many applications as possible, which adds to the complexity. However, the fact that their development cost can be spread over a large number of users means that they are often the most cost-effective approach. However, a general-purpose DBMS is not always the optimal solution: in some cases a general-purpose DBMS may introduce unnecessary overhead. Therefore, there are many examples of systems that use special-purpose databases. A common example is an email system that performs many of the functions of a general-purpose DBMS such as the insertion and deletion of messages composed of various items of data or associating messages with a particular email address; but these functions are limited to what is required to handle email and don't provide the user with the all of the functionality that would be available using a general-purpose DBMS.
Many other databases have application software that accesses the database on behalf of end-users, without exposing the DBMS interface directly. Application programmers may use a wire protocol directly, or more likely through an application programming interface. Database designers and database administrators interact with the DBMS through dedicated interfaces to build and maintain the applications' databases, and thus need some more knowledge and understanding about how DBMSs operate and the DBMSs' external interfaces and tuning parameters.
History.
Following the technology progress in the areas of processors, computer memory, computer storage and computer networks, the sizes, capabilities, and performance of databases and their respective DBMSs have grown in orders of magnitude. The development of database technology can be divided into three eras based on data model or structure: navigational, SQL/relational, and post-relational.
The two main early navigational data models were the hierarchical model, epitomized by IBM's IMS system, and the CODASYL model (network model), implemented in a number of products such as IDMS.
The relational model, first proposed in 1970 by Edgar F. Codd, departed from this tradition by insisting that applications should search for data by content, rather than by following links. The relational model employs sets of ledger-style tables, each used for a different type of entity. Only in the mid-1980s did computing hardware become powerful enough to allow the wide deployment of relational systems (DBMSs plus applications). By the early 1990s, however, relational systems dominated in all large-scale data processing applications, and as of 2015[ [update]] they remain dominant : Oracle, mySQL and SQL server are the top DBMS. The dominant database language, standardised SQL for the relational model, has influenced database languages for other data models.
Object databases were developed in the 1980s to overcome the inconvenience of object-relational impedance mismatch, which led to the coining of the term "post-relational" and also the development of hybrid object-relational databases.
The next generation of post-relational databases in the late 2000s became known as NoSQL databases, introducing fast key-value stores and document-oriented databases. A competing "next generation" known as NewSQL databases attempted new implementations that retained the relational/SQL model while aiming to match the high performance of NoSQL compared to commercially available relational DBMSs.
1960s, navigational DBMS.
The introduction of the term "database" coincided with the availability of direct-access storage (disks and drums) from the mid-1960s onwards. The term represented a contrast with the tape-based systems of the past, allowing shared interactive use rather than daily batch processing. The Oxford English dictionary cites a 1962 report by the System Development Corporation of California as the first to use the term "data-base" in a specific technical sense.
As computers grew in speed and capability, a number of general-purpose database systems emerged; by the mid-1960s a number of such systems had come into commercial use. Interest in a standard began to grow, and Charles Bachman, author of one such product, the Integrated Data Store (IDS), founded the "Database Task Group" within CODASYL, the group responsible for the creation and standardization of COBOL. In 1971 the Database Task Group delivered their standard, which generally became known as the "CODASYL approach", and soon a number of commercial products based on this approach entered the market.
The CODASYL approach relied on the "manual" navigation of a linked data set which was formed into a large network. Applications could find records by one of three methods:
Later systems added B-Trees to provide alternate access paths. Many CODASYL databases also added a very straightforward query language. However, in the final tally, CODASYL was very complex and required significant training and effort to produce useful applications.
IBM also had their own DBMS in 1968, known as Information Management System (IMS). IMS was a development of software written for the Apollo program on the System/360. IMS was generally similar in concept to CODASYL, but used a strict hierarchy for its model of data navigation instead of CODASYL's network model. Both concepts later became known as navigational databases due to the way data was accessed, and Bachman's 1973 Turing Award presentation was "The Programmer as Navigator". IMS is classified as a hierarchical database. IDMS and Cincom Systems' TOTAL database are classified as network databases. IMS remains in use as of 2014[ [update]].
1970s, relational DBMS.
Edgar Codd worked at IBM in San Jose, California, in one of their offshoot offices that was primarily involved in the development of hard disk systems. He was unhappy with the navigational model of the CODASYL approach, notably the lack of a "search" facility. In 1970, he wrote a number of papers that outlined a new approach to database construction that eventually culminated in the groundbreaking "A Relational Model of Data for Large Shared Data Banks".
In this paper, he described a new system for storing and working with large databases. Instead of records being stored in some sort of linked list of free-form records as in CODASYL, Codd's idea was to use a "table" of fixed-length records, with each table used for a different type of entity. A linked-list system would be very inefficient when storing "sparse" databases where some of the data for any one record could be left empty. The relational model solved this by splitting the data into a series of normalized tables (or "relations"), with optional elements being moved out of the main table to where they would take up room only if needed. Data may be freely inserted, deleted and edited in these tables, with the DBMS doing whatever maintenance needed to present a table view to the application/user.
 
The relational model also allowed the content of the database to evolve without constant rewriting of links and pointers. The relational part comes from entities referencing other entities in what is known as one-to-many relationship, like a traditional hierarchical model, and many-to-many relationship, like a navigational (network) model. Thus, a relational model can express both hierarchical and navigational models, as well as its native tabular model, allowing for pure or combined modeling in terms of these three models, as the application requires.
For instance, a common use of a database system is to track information about users, their name, login information, various addresses and phone numbers. In the navigational approach all of these data would be placed in a single record, and unused items would simply not be placed in the database. In the relational approach, the data would be "normalized" into a user table, an address table and a phone number table (for instance). Records would be created in these optional tables only if the address or phone numbers were actually provided.
Linking the information back together is the key to this system. In the relational model, some bit of information was used as a "key", uniquely defining a particular record. When information was being collected about a user, information stored in the optional tables would be found by searching for this key. For instance, if the login name of a user is unique, addresses and phone numbers for that user would be recorded with the login name as its key. This simple "re-linking" of related data back into a single collection is something that traditional computer languages are not designed for.
Just as the navigational approach would require programs to loop in order to collect records, the relational approach would require loops to collect information about any "one" record. Codd's solution to the necessary looping was a set-oriented language, a suggestion that would later spawn the ubiquitous SQL. Using a branch of mathematics known as tuple calculus, he demonstrated that such a system could support all the operations of normal databases (inserting, updating etc.) as well as providing a simple system for finding and returning "sets" of data in a single operation.
Codd's paper was picked up by two people at Berkeley, Eugene Wong and Michael Stonebraker. They started a project known as INGRES using funding that had already been allocated for a geographical database project and student programmers to produce code. Beginning in 1973, INGRES delivered its first test products which were generally ready for widespread use in 1979. INGRES was similar to System R in a number of ways, including the use of a "language" for data access, known as QUEL. Over time, INGRES moved to the emerging SQL standard.
IBM itself did one test implementation of the relational model, PRTV, and a production one, Business System 12, both now discontinued. Honeywell wrote MRDS for Multics, and now there are two new implementations: Alphora Dataphor and Rel. Most other DBMS implementations usually called "relational" are actually SQL DBMSs.
In 1970, the University of Michigan began development of the MICRO Information Management System based on D.L. Childs' Set-Theoretic Data model. Micro was used to manage very large data sets by the US Department of Labor, the U.S. Environmental Protection Agency, and researchers from the University of Alberta, the University of Michigan, and Wayne State University. It ran on IBM mainframe computers using the Michigan Terminal System. The system remained in production until 1998.
Integrated approach.
In the 1970s and 1980s attempts were made to build database systems with integrated hardware and software. The underlying philosophy was that such integration would provide higher performance at lower cost. Examples were IBM System/38, the early offering of Teradata, and the Britton Lee, Inc. database machine.
Another approach to hardware support for database management was ICL's CAFS accelerator, a hardware disk controller with programmable search capabilities. In the long term, these efforts were generally unsuccessful because specialized database machines could not keep pace with the rapid development and progress of general-purpose computers. Thus most database systems nowadays are software systems running on general-purpose hardware, using general-purpose computer data storage. However this idea is still pursued for certain applications by some companies like Netezza and Oracle (Exadata).
Late 1970s, SQL DBMS.
IBM started working on a prototype system loosely based on Codd's concepts as "System R" in the early 1970s. The first version was ready in 1974/5, and work then started on multi-table systems in which the data could be split so that all of the data for a record (some of which is optional) did not have to be stored in a single large "chunk". Subsequent multi-user versions were tested by customers in 1978 and 1979, by which time a standardized query language – SQL – had been added. Codd's ideas were establishing themselves as both workable and superior to CODASYL, pushing IBM to develop a true production version of System R, known as "SQL/DS", and, later, "Database 2" (DB2).
Larry Ellison's Oracle started from a different chain, based on IBM's papers on System R, and beat IBM to market when the first version was released in 1978.
Stonebraker went on to apply the lessons from INGRES to develop a new database, Postgres, which is now known as PostgreSQL. PostgreSQL is often used for global mission critical applications (the .org and .info domain name registries use it as their primary data store, as do many large companies and financial institutions).
In Sweden, Codd's paper was also read and Mimer SQL was developed from the mid-1970s at Uppsala University. In 1984, this project was consolidated into an independent enterprise. In the early 1980s, Mimer introduced transaction handling for high robustness in applications, an idea that was subsequently implemented on most other DBMSs.
Another data model, the entity–relationship model, emerged in 1976 and gained popularity for database design as it emphasized a more familiar description than the earlier relational model. Later on, entity–relationship constructs were retrofitted as a data modeling construct for the relational model, and the difference between the two have become irrelevant.
1980s, on the desktop.
The 1980s ushered in the age of desktop computing. The new computers empowered their users with spreadsheets like Lotus 1-2-3 and database software like dBASE. The dBASE product was lightweight and easy for any computer user to understand out of the box. C. Wayne Ratliff the creator of dBASE stated: "dBASE was different from programs like BASIC, C, FORTRAN, and COBOL in that a lot of the dirty work had already been done. The data manipulation is done by dBASE instead of by the user, so the user can concentrate on what he is doing, rather than having to mess with the dirty details of opening, reading, and closing files, and managing space allocation." dBASE was one of the top selling software titles in the 1980s and early 1990s.
1980s, object-oriented.
The 1980s, along with a rise in object-oriented programming, saw a growth in how data in various databases were handled. Programmers and designers began to treat the data in their databases as objects. That is to say that if a person's data were in a database, that person's attributes, such as their address, phone number, and age, were now considered to belong to that person instead of being extraneous data. This allows for relations between data to be relations to objects and their attributes and not to individual fields. The term "object-relational impedance mismatch" described the inconvenience of translating between programmed objects and database tables. Object databases and object-relational databases attempt to solve this problem by providing an object-oriented language (sometimes as extensions to SQL) that programmers can use as alternative to purely relational SQL. On the programming side, libraries known as object-relational mappings (ORMs) attempt to solve the same problem.
2000s, NoSQL and NewSQL.
The next generation of post-relational databases in the 2000s became known as NoSQL databases, including fast key-value stores and document-oriented databases.
XML databases are a type of structured document-oriented database that allows querying based on XML document attributes. XML databases are mostly used in enterprise database management, where XML is being used as the machine-to-machine data interoperability standard. XML database management systems include commercial software MarkLogic and Oracle Berkeley DB XML, and a free use software Clusterpoint Distributed XML/JSON Database. All are enterprise software database platforms and support industry standard ACID-compliant transaction processing with strong database consistency characteristics and high level of database security.
NoSQL databases are often very fast, do not require fixed table schemas, avoid join operations by storing denormalized data, and are designed to scale horizontally. The most popular NoSQL systems include MongoDB, Couchbase, Riak, Memcached, Redis, CouchDB, Hazelcast, Apache Cassandra and HBase, which are all open-source software products.
In recent years there was a high demand for massively distributed databases with high partition tolerance but according to the CAP theorem it is impossible for a distributed system to simultaneously provide consistency, availability and partition tolerance guarantees. A distributed system can satisfy any two of these guarantees at the same time, but not all three. For that reason many NoSQL databases are using what is called eventual consistency to provide both availability and partition tolerance guarantees with a reduced level of data consistency.
NewSQL is a class of modern relational databases that aims to provide the same scalable performance of NoSQL systems for online transaction processing (read-write) workloads while still using SQL and maintaining the ACID guarantees of a traditional database system. Such databases include ScaleBase, Clustrix, EnterpriseDB, MemSQL, NuoDB and VoltDB.
Research.
Database technology has been an active research topic since the 1960s, both in academia and in the research and development groups of companies (for example IBM Research). Research activity includes theory and development of prototypes. Notable research topics have included models, the atomic transaction concept and related concurrency control techniques, query languages and query optimization methods, RAID, and more.
The database research area has several dedicated academic journals (for example, "ACM Transactions on Database Systems"-TODS, "Data and Knowledge Engineering"-DKE) and annual conferences (e.g., ACM SIGMOD, ACM PODS, VLDB, IEEE ICDE).
Examples.
One way to classify databases involves the type of their contents, for example: bibliographic, document-text, statistical, or multimedia objects. Another way is by their application area, for example: accounting, music compositions, movies, banking, manufacturing, or insurance. A third way is by some technical aspect, such as the database structure or interface type. This section lists a few of the adjectives used to characterize different kinds of databases.
Design and modeling.
The first task of a database designer is to produce a conceptual data model that reflects the structure of the information to be held in the database. A common approach to this is to develop an entity-relationship model, often with the aid of drawing tools. Another popular approach is the Unified Modeling Language. A successful data model will accurately reflect the possible state of the external world being modeled: for example, if people can have more than one phone number, it will allow this information to be captured. Designing a good conceptual data model requires a good understanding of the application domain; it typically involves asking deep questions about the things of interest to an organisation, like "can a customer also be a supplier?", or "if a product is sold with two different forms of packaging, are those the same product or different products?", or "if a plane flies from New York to Dubai via Frankfurt, is that one flight or two (or maybe even three)?". The answers to these questions establish definitions of the terminology used for entities (customers, products, flights, flight segments) and their relationships and attributes.
Producing the conceptual data model sometimes involves input from business processes, or the analysis of workflow in the organization. This can help to establish what information is needed in the database, and what can be left out. For example, it can help when deciding whether the database needs to hold historic data as well as current data.
Having produced a conceptual data model that users are happy with, the next stage is to translate this into a schema that implements the relevant data structures within the database. This process is often called logical database design, and the output is a logical data model expressed in the form of a schema. Whereas the conceptual data model is (in theory at least) independent of the choice of database technology, the logical data model will be expressed in terms of a particular database model supported by the chosen DBMS. (The terms "data model" and "database model" are often used interchangeably, but in this article we use "data model" for the design of a specific database, and "database model" for the modelling notation used to express that design.)
The most popular database model for general-purpose databases is the relational model, or more precisely, the relational model as represented by the SQL language. The process of creating a logical database design using this model uses a methodical approach known as normalization. The goal of normalization is to ensure that each elementary "fact" is only recorded in one place, so that insertions, updates, and deletions automatically maintain consistency.
The final stage of database design is to make the decisions that affect performance, scalability, recovery, security, and the like. This is often called "physical database design". A key goal during this stage is data independence, meaning that the decisions made for performance optimization purposes should be invisible to end-users and applications. Physical design is driven mainly by performance requirements, and requires a good knowledge of the expected workload and access patterns, and a deep understanding of the features offered by the chosen DBMS.
Another aspect of physical database design is security. It involves both defining access control to database objects as well as defining security levels and methods for the data itself.
Models.
A database model is a type of data model that determines the logical structure of a database and fundamentally determines in which manner data can be stored, organized, and manipulated. The most popular example of a database model is the relational model (or the SQL approximation of relational), which uses a table-based format.
Common logical data models for databases include:
An object-relational database combines the two related structures.
Physical data models include:
Other models include:
External, conceptual, and internal views.
A database management system provides three views of the database data:
While there is typically only one conceptual (or logical) and physical (or internal) view of the data, there can be any number of different external views. This allows users to see database information in a more business-related way rather than from a technical, processing viewpoint. For example, a financial department of a company needs the payment details of all employees as part of the company's expenses, but does not need details about employees that are the interest of the human resources department. Thus different departments need different "views" of the company's database.
The three-level database architecture relates to the concept of "data independence" which was one of the major initial driving forces of the relational model. The idea is that changes made at a certain level do not affect the view at a higher level. For example, changes in the internal level do not affect application programs written using conceptual level interfaces, which reduces the impact of making physical changes to improve performance.
The conceptual view provides a level of indirection between internal and external. On one hand it provides a common view of the database, independent of different external view structures, and on the other hand it abstracts away details of how the data is stored or managed (internal level). In principle every level, and even every external view, can be presented by a different data model. In practice usually a given DBMS uses the same data model for both the external and the conceptual levels (e.g., relational model). The internal level, which is hidden inside the DBMS and depends on its implementation (see Implementation section below), requires a different level of detail and uses its own types of data structure types.
Separating the "external", "conceptual" and "internal" levels was a major feature of the relational database model implementations that dominate 21st century databases.
Languages.
Database languages are special-purpose languages, which do one or more of the following:
Database languages are specific to a particular data model. Notable examples include:
A database language may also incorporate features like:
Performance, security, and availability.
Because of the critical importance of database technology to the smooth running of an enterprise, database systems include complex mechanisms to deliver the required performance, security, and availability, and allow database administrators to control the use of these features.
Storage.
Database storage is the container of the physical materialization of a database. It comprises the "internal" (physical) "level" in the database architecture. It also contains all the information needed (e.g., metadata, "data about the data", and internal data structures) to reconstruct the "conceptual level" and "external level" from the internal level when needed. Putting data into permanent storage is generally the responsibility of the database engine a.k.a. "storage engine". Though typically accessed by a DBMS through the underlying operating system (and often utilizing the operating systems' file systems as intermediates for storage layout), storage properties and configuration setting are extremely important for the efficient operation of the DBMS, and thus are closely maintained by database administrators. A DBMS, while in operation, always has its database residing in several types of storage (e.g., memory and external storage). The database data and the additional needed information, possibly in very large amounts, are coded into bits. Data typically reside in the storage in structures that look completely different from the way the data look in the conceptual and external levels, but in ways that attempt to optimize (the best possible) these levels' reconstruction when needed by users and programs, as well as for computing additional types of needed information from the data (e.g., when querying the database).
Some DBMSs support specifying which character encoding was used to store data, so multiple encodings can be used in the same database.
Various low-level database storage structures are used by the storage engine to serialize the data model so it can be written to the medium of choice. Techniques such as indexing may be used to improve performance. Conventional storage is row-oriented, but there are also column-oriented and correlation databases.
Materialized views.
Often storage redundancy is employed to increase performance. A common example is storing "materialized views", which consist of frequently needed "external views" or query results. Storing such views saves the expensive computing of them each time they are needed. The downsides of materialized views are the overhead incurred when updating them to keep them synchronized with their original updated database data, and the cost of storage redundancy.
Replication.
Occasionally a database employs storage redundancy by database objects replication (with one or more copies) to increase data availability (both to improve performance of simultaneous multiple end-user accesses to a same database object, and to provide resiliency in a case of partial failure of a distributed database). Updates of a replicated object need to be synchronized across the object copies. In many cases the entire database is replicated.
Security.
Database security deals with all various aspects of protecting the database content, its owners, and its users. It ranges from protection from intentional unauthorized database uses to unintentional database accesses by unauthorized entities (e.g., a person or a computer program).
Database access control deals with controlling who (a person or a certain computer program) is allowed to access what information in the database. The information may comprise specific database objects (e.g., record types, specific records, data structures), certain computations over certain objects (e.g., query types, or specific queries), or utilizing specific access paths to the former (e.g., using specific indexes or other data structures to access information). Database access controls are set by special authorized (by the database owner) personnel that uses dedicated protected security DBMS interfaces.
This may be managed directly on an individual basis, or by the assignment of individuals and privileges to groups, or (in the most elaborate models) through the assignment of individuals and groups to roles which are then granted entitlements. Data security prevents unauthorized users from viewing or updating the database. Using passwords, users are allowed access to the entire database or subsets of it called "subschemas". For example, an employee database can contain all the data about an individual employee, but one group of users may be authorized to view only payroll data, while others are allowed access to only work history and medical data. If the DBMS provides a way to interactively enter and update the database, as well as interrogate it, this capability allows for managing personal databases.
Data security in general deals with protecting specific chunks of data, both physically (i.e., from corruption, or destruction, or removal; e.g., see physical security), or the interpretation of them, or parts of them to meaningful information (e.g., by looking at the strings of bits that they comprise, concluding specific valid credit-card numbers; e.g., see data encryption).
Change and access logging records who accessed which attributes, what was changed, and when it was changed. Logging services allow for a forensic database audit later by keeping a record of access occurrences and changes. Sometimes application-level code is used to record changes rather than leaving this to the database. Monitoring can be set up to attempt to detect security breaches.
Transactions and concurrency.
Database transactions can be used to introduce some level of fault tolerance and data integrity after recovery from a crash. A database transaction is a unit of work, typically encapsulating a number of operations over a database (e.g., reading a database object, writing, acquiring lock, etc.), an abstraction supported in database and also other systems. Each transaction has well defined boundaries in terms of which program/code executions are included in that transaction (determined by the transaction's programmer via special transaction commands).
The acronym ACID describes some ideal properties of a database transaction: Atomicity, Consistency, Isolation, and Durability.
Migration.
A database built with one DBMS is not portable to another DBMS (i.e., the other DBMS cannot run it). However, in some situations it is desirable to move, migrate a database from one DBMS to another. The reasons are primarily economical (different DBMSs may have different total costs of ownership or TCOs), functional, and operational (different DBMSs may have different capabilities). The migration involves the database's transformation from one DBMS type to another. The transformation should maintain (if possible) the database related application (i.e., all related application programs) intact. Thus, the database's conceptual and external architectural levels should be maintained in the transformation. It may be desired that also some aspects of the architecture internal level are maintained. A complex or large database migration may be a complicated and costly (one-time) project by itself, which should be factored into the decision to migrate. This in spite of the fact that tools may exist to help migration between specific DBMSs. Typically a DBMS vendor provides tools to help importing databases from other popular DBMSs.
Building, maintaining, and tuning.
After designing a database for an application, the next stage is building the database. Typically an appropriate general-purpose DBMS can be selected to be utilized for this purpose. A DBMS provides the needed user interfaces to be utilized by database administrators to define the needed application's data structures within the DBMS's respective data model. Other user interfaces are used to select needed DBMS parameters (like security related, storage allocation parameters, etc.).
When the database is ready (all its data structures and other needed components are defined) it is typically populated with initial application's data (database initialization, which is typically a distinct project; in many cases using specialized DBMS interfaces that support bulk insertion) before making it operational. In some cases the database becomes operational while empty of application data, and data is accumulated during its operation.
After the database is created, initialised and populated it needs to be maintained. Various database parameters may need changing and the database may need to be tuned (tuning) for better performance; application's data structures may be changed or added, new related application programs may be written to add to the application's functionality, etc.
Backup and restore.
Sometimes it is desired to bring a database back to a previous state (for many reasons, e.g., cases when the database is found corrupted due to a software error, or if it has been updated with erroneous data). To achieve this a backup operation is done occasionally or continuously, where each desired database state (i.e., the values of its data and their embedding in database's data structures) is kept within dedicated backup files (many techniques exist to do this effectively). When this state is needed, i.e., when it is decided by a database administrator to bring the database back to this state (e.g., by specifying this state by a desired point in time when the database was in this state), these files are utilized to restore that state.
Other.
Other DBMS features might include:
Further reading.
</dl>

</doc>
<doc id="8378" url="http://en.wikipedia.org/wiki?curid=8378" title="Dipole">
Dipole

In physics, there are several kinds of dipole:
Dipoles can be characterized by their dipole moment, a vector quantity. For the simple electric dipole given above, the electric dipole moment points from the negative charge towards the positive charge, and has a magnitude equal to the strength of each charge times the separation between the charges. (To be precise: for the definition of the dipole moment, one should always consider the "dipole limit", where e.g. the distance of the generating charges should "converge" to 0, while simultaneously the charge strength should "diverge" to infinity in such a way that the product remains a positive constant.)
For the current loop, the magnetic dipole moment points through the loop (according to the right hand grip rule), with a magnitude equal to the current in the loop times the area of the loop.
In addition to current loops, the electron, among other fundamental particles, has a magnetic dipole moment. This is because it generates a magnetic field that is identical to that generated by a very small current loop. However, the electron's magnetic moment is not due to a current loop, but is instead an intrinsic property of the electron. It is also possible that the electron has an "electric" dipole moment, although this has not yet been observed (see electron electric dipole moment for more information).
A permanent magnet, such as a bar magnet, owes its magnetism to the intrinsic magnetic dipole moment of the electron. The two ends of a bar magnet are referred to as poles (not to be confused with monopoles), and may be labeled "north" and "south". In terms of the Earth's magnetic field, these are respectively "north-seeking" and "south-seeking" poles, that is if the magnet were freely suspended in the Earth's magnetic field, the north-seeking pole would point towards the north and the south-seeking pole would point twards the south. The dipole moment of the bar magnet points from its magnetic south to its magnetic north pole. The north pole of a bar magnet in a compass points north. However, this means that Earth's geomagnetic north pole is the "south" pole (south-seeking pole) of its dipole moment, and vice versa.
The only known mechanisms for the creation of magnetic dipoles are by current loops or quantum-mechanical spin since the existence of magnetic monopoles has never been experimentally demonstrated.
The term comes from the Greek δίς ("dis"), "twice" and πόλος ("pòlos"), "axis".
Classification.
A "physical dipole" consists of two equal and opposite point charges: in the literal sense, two poles. Its field at large distances (i.e., distances large in comparison to the separation of the poles) depends almost entirely on the dipole moment as defined above. A "point (electric) dipole" is the limit obtained by letting the separation tend to 0 while keeping the dipole moment fixed. The field of a point dipole has a particularly simple form, and the order-1 term in the multipole expansion is precisely the point dipole field.
Although there are no known magnetic monopoles in nature, there are magnetic dipoles in the form of the quantum-mechanical spin associated with particles such as electrons (although the accurate description of such effects falls outside of classical electromagnetism). A theoretical magnetic "point dipole" has a magnetic field of exactly the same form as the electric field of an electric point dipole. A very small current-carrying loop is approximately a magnetic point dipole; the magnetic dipole moment of such a loop is the product of the current flowing in the loop and the (vector) area of the loop.
Any configuration of charges or currents has a 'dipole moment', which describes the dipole whose field is the best approximation, at large distances, to that of the given configuration. This is simply one term in the multipole expansion when the total charge ("monopole moment") is 0 — as it "always" is for the magnetic case, since there are no magnetic monopoles. The dipole term is the dominant one at large distances: Its field falls off in proportion to 1/"r"3, as compared to 1/"r"4 for the next (quadrupole) term and higher powers of 1/"r" for higher terms, or 1/"r"2 for the monopole term.
Molecular dipoles.
Many molecules have such dipole moments due to non-uniform distributions of positive and negative charges on the various atoms. Such is the case with polar compounds like hydrogen fluoride (HF), where electron density is shared unequally between atoms. Therefore, a molecule's dipole is an electric dipole with an inherent electric field which should not be confused with a magnetic dipole which generates a magnetic field.
The physical chemist Peter J. W. Debye was the first scientist to study molecular dipoles extensively, and, as a consequence, dipole moments are measured in units named "debye" in his honor.
For molecules there are three types of dipoles:
More generally, an induced dipole of "any" polarizable charge distribution "ρ" (remember that a molecule has a charge distribution) is caused by an electric field external to "ρ". This field may, for instance, originate from an ion or polar molecule in the vicinity of "ρ" or may be macroscopic (e.g., a molecule between the plates of a charged capacitor). The size of the induced dipole is equal to the product of the strength of the
external field and the dipole polarizability of "ρ".
Dipole moment values can be obtained from measurement of the dielectric constant. Some typical gas phase values in debye units are:
KBr has one of the highest dipole moments because it is a very ionic molecule (which only exists as a molecule in the gas phase).
 The overall dipole moment of a molecule may be approximated as a vector sum of bond dipole moments. As a vector sum it depends on the relative orientation of the bonds, so that from the dipole moment information can be deduced about the molecular geometry.
For example the zero dipole of CO2 implies that the two C=O bond dipole moments cancel so that the molecule must be linear. For H2O the O-H bond moments do not cancel because the molecule is bent. For ozone (O3) which is also a bent molecule, the bond dipole moments are not zero even though the O-O bonds are between similar atoms. This agrees with the Lewis structures for the resonance forms of ozone which show a positive charge on the central oxygen atom. 
An example in organic chemistry of the role of geometry in determining dipole moment is the "cis" and "trans" isomers of 1,2-dichloroethene. In the cis isomer the two polar C-Cl bonds are on the same side of the C=C double bond and the molecular dipole moment is 1.90 D. In the trans isomer, the dipole moment is zero because the two C-Cl bond are on opposite sides of the C=C and cancel (and the two bond moments for the much less polar C-H bonds also cancel).
Another example of the role of molecular geometry is boron trifluoride, which has three polar bonds with a difference in electronegativity greater than the traditionally cited threshold of 1.7 for ionic bonding. However, due to the equilateral triangular distribution of the fluoride ions about the boron cation center, the molecule as a whole does not exhibit any identifiable pole: one cannot construct a plane that divides the molecule into a net negative part and a net positive part.
Quantum mechanical dipole operator.
Consider a collection of "N" particles with charges "qi" and position vectors r"i". For instance, this collection may be a molecule consisting of electrons, all with charge −"e", and nuclei with charge "eZi", where "Zi" is the atomic number of the "i" th nucleus.
The dipole observable (physical quantity) has the quantum mechanical dipole operator:
Notice that this definition is valid only for non-charged dipoles, i.e. total charge equal to zero.
Atomic dipoles.
A non-degenerate (S-state) atom can have only a zero permanent dipole. This fact follows quantum mechanically from the inversion symmetry of atoms. All 3 components of the dipole operator are antisymmetric under inversion with respect to the nucleus,
where formula_3 is the dipole operator and formula_4 is the inversion operator.
The permanent dipole moment of an atom in a non-degenerate state (see degenerate energy level) is given as the expectation (average) value of the dipole operator,
where formula_6 is an S-state, non-degenerate, wavefunction, which
is symmetric or antisymmetric under inversion: formula_7.
Since the product of the wavefunction (in the ket) and its complex conjugate (in the bra) is always symmetric under inversion and its inverse,
it follows that the expectation value changes sign under inversion. We used here the fact that
formula_9, being a symmetry operator, is unitary:
formula_10 and by definition
the Hermitian adjoint formula_11 may be moved from bra to ket and then becomes formula_12.
Since the only quantity that is equal to minus itself is the zero, the expectation value vanishes,
In the case of open-shell atoms with degenerate energy levels, one could define a dipole moment by the aid of the first-order Stark effect. This gives a non-vanishing dipole (by definition proportional to a non-vanishing first-order Stark shift) only if some of the wavefunctions belonging to the degenerate energies have opposite parity; i.e., have different behavior under inversion. This is a rare occurrence, but happens for the excited H-atom, where 2s and 2"p" states are "accidentally" degenerate (see article Laplace–Runge–Lenz vector for the origin of this degeneracy) and have opposite parity (2s is even and 2p is odd).
Field of a static magnetic dipole.
Magnitude.
The far-field strength, "B", of a dipole magnetic field is given by
where
Conversion to cylindrical coordinates is achieved using and
where "ρ" is the perpendicular distance from the "z"-axis. Then,
Vector form.
The field itself is a vector quantity:
where
This is "exactly" the field of a point dipole, "exactly" the dipole term in the multipole expansion of an arbitrary field, and "approximately" the field of any dipole-like configuration at large distances.
Magnetic vector potential.
The vector potential A of a magnetic dipole is
with the same definitions as above.
Field from an electric dipole.
The electrostatic potential at position r due to an electric dipole at the origin is given by:
where
This term appears as the second term in the multipole expansion of an arbitrary electrostatic potential Φ(r). If the source of Φ(r) is a dipole, as it is assumed here, this term is the only non-vanishing term in the multipole expansion of Φ(r). The electric field from a dipole can be found from the gradient of this potential:
where E is the electric field and "δ"3 is the 3-dimensional delta function. This is formally identical to the magnetic H field of a point magnetic dipole with only a few names changed.
Torque on a dipole.
Since the direction of an electric field is defined as the direction of the force on a positive charge, electric field lines point away from a positive charge and toward a negative charge.
When placed in an electric or magnetic field, equal but opposite forces arise on each side of the dipole creating a torque τ:
for an electric dipole moment p (in coulomb-meters), or
for a magnetic dipole moment m (in ampere-square meters).
The resulting torque will tend to align the dipole with the applied field, which in the case of an electric dipole, yields a potential energy of
The energy of a magnetic dipole is similarly
Dipole radiation.
In addition to dipoles in electrostatics, it is also common to consider an electric or magnetic dipole that is oscillating in time. It is an extension, or a more physical next-step, to spherical wave radiation.
In particular, consider a harmonically oscillating electric dipole, with angular frequency ω and a dipole moment formula_27 along the formula_28 direction of the form
In vacuum, the exact field produced by this oscillating dipole can be derived using the retarded potential formulation as:
formula_30
formula_31
For formula_32, the far-field takes the simpler form of a radiating "spherical" wave, but with angular dependence embedded in the cross-product:
The time-averaged Poynting vector
formula_35
is not distributed isotropically, but concentrated around the directions lying perpendicular to the dipole moment, as a result of the non-spherical electric and magnetic waves. In fact, the spherical harmonic function (formula_36) responsible for such "donut-shaped" angular distribution is precisely the formula_37 "p" wave.
The total time-average power radiated by the field can then be derived from the Poynting vector as
Notice that the dependence of the power on the fourth power of the frequency of the radiation is in accordance with the Rayleigh scattering, and the underlying effects why the sky consists of mainly blue colour.
A circular polarized dipole is described as a superposition of two linear dipoles.

</doc>
<doc id="8386" url="http://en.wikipedia.org/wiki?curid=8386" title="Dynamics">
Dynamics

Every object experiences some form of motion which is the result of different forces acting on the object. Dynamics is the study of the forces which are responsible for this motion.
Dynamics (from Greek δυναμικός "dynamikos" "powerful", from δύναμις "dynamis" "power") may refer to:

</doc>
<doc id="8387" url="http://en.wikipedia.org/wiki?curid=8387" title="Draught beer">
Draught beer

Draught beer, also spelt draft, is beer served from a cask or keg rather than from a bottle or can. Canned draught is beer served from a pressurised container containing a widget. Smooth flow (also known as cream flow, nitrokeg or smooth) is the name brewers give to draught beers pressurised with a partial nitrogen gas blend.
Etymology and usage.
Until Joseph Bramah patented the beer engine in 1785, beer was served directly from the barrel and carried to the customer. The Old English word for "carry" or "pull" was "dragan" which developed into a series of related words, including "drag", "draw" and "draught". By extension, the word for carrying or drawing a beer came to mean the serving of the beer and, in some senses, the act of drinking or a drink of beer itself, regardless of serving method. By the time Bramah's beer pumps became popular, the use of the term "draught" to refer to the act of serving beer was well established and transferred easily to beer served via the hand pumps.
"Draught" is the usual spelling in the United Kingdom, Ireland and Australia. "Draft" is the usual spelling in North America, although it may be spelt both ways in Canada and Australia, depending on the origin of the beer. "Draught" and "draft" can each be pronounced or depending on the region the speaker is from.
History.
In 1691, an article in the "London Gazette" mentioned John Lofting, who held a patent for a fire engine: "The said patentee has also projected a very useful engine for starting of beer, and other liquors which will draw from 20 to 30 barrels an hour, which are completely fixed with brass joints and screws at reasonable rates".
In the early 20th century, draught beer started to be served from pressurised containers. Artificial carbonation was introduced in the United Kingdom in 1936, with Watney’s experimental pasteurised beer Red Barrel. Though this method of serving beer did not take hold in the U.K. until the late 1950s, it did become the favoured method in the rest of Europe, where it is known by such terms as "en pression". The carbonation method of serving beer subsequently spread to the rest of the world; by the early 1970s the term "draught beer" almost exclusively referred to beer served under pressure as opposed to the traditional cask or barrel beer.
In Britain, the Campaign for Real Ale was founded in 1971 to protect traditional - unpressurised beer and brewing methods. The group devised the term "real ale" to differentiate between beer served from the cask and beer served under pressure. The term "real ale" has since been expanded to include bottle-conditioned beer.
Keg beer.
Keg beer is a term for beer which is served from a pressurised keg. Keg beer is often filtered and/or pasteurised, both of which are processes that render the yeast inactive.
A tap hole near the edge of the top, and a spile hole on the side used for conditioning the unfiltered and unpasteurised beer. A keg has a single opening in the centre of the top to which a flow pipe is attached. Kegs are artificially pressurised after fermentation with carbon dioxide or a mixture of carbon dioxide and nitrogen gas.
"Keg" has become a term of contempt used by some, particularly in Britain, since the 1960s when pasteurised draught beers started replacing traditional cask beers.
Keg beer was replacing traditional cask ale in all parts of the UK, primarily because it requires less care to handle. Since 1971, the Campaign for Real Ale (CAMRA) has conducted a consumer campaign on behalf of those who prefer traditional cask beer. CAMRA has lobbied the British Parliament to ensure support for cask ale and microbreweries have sprung up to serve those consumers who prefer traditional cask beer.
Pressurised CO2 in the keg's headspace maintains carbonation in the beer. The CO2 pressure varies depending on the amount of CO2 already in the beer and the keg storage temperature. Occasionally the CO2 gas is blended with nitrogen gas. CO2 / nitrogen blends are used to allow a higher operating pressure in complex dispensing systems.
Nitrogen is used under high pressure when dispensing dry stouts (such as Guinness) and other creamy beers because it displaces CO2 to (artificially) form a rich tight head and a less carbonated taste. This makes the beer feel smooth on the palate and gives a foamy appearance. Premixed bottled gas for creamy beers is usually 75% nitrogen and 25% CO2. This premixed gas which only works well with creamy beers is often referred to as Guinness Gas, Beer Gas, or Aligal. Using "Beer Gas" with other beer styles can cause the last 5% to 10% of the beer in each keg to taste very flat and lifeless.
In the UK, the term keg beer would imply the beer is pasteurised, in contrast to unpasteurised cask beer. Some of the newer microbreweries may offer a nitro keg stout which is filtered but not pasteurised.
Storage and serving temperature.
Cask beer should be stored and served at a cellar temperature of 12°C (54°F). Once a cask is opened, it should be consumed within three days. Keg beer is given additional cooling just prior to being served either by flash coolers or a remote cooler in the cellar. This chills the beer down to temperatures between 3°C and 8°C.
Canned and bottled "draught".
The words "draft" and "draught" have been used as marketing terms to describe canned or bottled beers, implying that they taste and appear like beers from a cask or keg. Commercial brewers use this as a marketing tool although it is incorrect to call any beer not drawn from a cask or keg "draught". Two examples are Miller Genuine Draft, a pale lager which is produced using a patented cold filtering system, and Guinness stout in patented "Draught-flow" cans and bottles. Guinness is an example of beers that use a nitrogen widget to create a smooth beer with a very dense head. Guinness has recently replaced the widget system from their bottled "draught" beer with a coating of cellulose fibres on the inside of the bottle. Statements indicate a new development in bottling technology enables the mixture of nitrogen and carbon dioxide to be present in the beer without using a widget, making it according to Guinness "more drinkable" from the bottle.
In some countries such as Japan, the term "draft" applied to canned or bottled beer indicates that the beer is not pasteurised (though it may be filtered), giving it a fresher taste but shorter shelf life than conventional packaged beers.

</doc>
<doc id="8388" url="http://en.wikipedia.org/wiki?curid=8388" title="Director">
Director

Director may refer to:

</doc>
<doc id="8389" url="http://en.wikipedia.org/wiki?curid=8389" title="Major depressive disorder">
Major depressive disorder

Major depressive disorder (MDD) (also known as clinical depression, major depression, unipolar depression, or unipolar disorder; or as recurrent depression in the case of repeated episodes) is a mental disorder characterized by a pervasive and persistent low mood that is accompanied by low self-esteem and by a loss of interest or pleasure in normally enjoyable activities. The term "depression" is used in a number of different ways. It is often used to mean this syndrome but may refer to other mood disorders or simply to a low mood. Major depressive disorder is a disabling condition that adversely affects a person's family, work or school life, sleeping and eating habits, and general health. In the United States, around 3.4% of people with major depression commit suicide, and up to 60% of people who commit suicide had depression or another mood disorder.
The diagnosis of major depressive disorder is based on the patient's self-reported experiences, behavior reported by relatives or friends, and a mental status examination. There is no laboratory test for major depression, although physicians generally request tests for physical conditions that may cause similar symptoms. The most common time of onset is between the ages of 20 and 30 years, with a later peak between 30 and 40 years.
Typically, people are treated with antidepressant medication and, in many cases, also receive counseling, particularly cognitive behavioral therapy (CBT). Medication appears to be effective, but the effect may only be significant in the most severely depressed. Hospitalization may be necessary in cases with associated self-neglect or a significant risk of harm to self or others. A minority are treated with electroconvulsive therapy (ECT). The course of the disorder varies widely, from one episode lasting weeks to a lifelong disorder with recurrent major depressive episodes. Depressed individuals have shorter life expectancies than those without depression, in part because of greater susceptibility to medical illnesses and suicide. It is unclear whether medications affect the risk of suicide. Current and former patients may be stigmatized.
The understanding of the nature and causes of depression has evolved over the centuries, though this understanding is incomplete and has left many aspects of depression as the subject of discussion and research. Proposed causes include psychological, psycho-social, hereditary, evolutionary and biological factors. Long-term substance abuse may cause or worsen depressive symptoms. Psychological treatments are based on theories of personality, interpersonal communication, and learning. Most biological theories focus on the monoamine chemicals serotonin, norepinephrine and dopamine, which are naturally present in the brain and assist communication between nerve cells. This cluster of symptoms (syndrome) was named, described and classified as one of the mood disorders in the 1980 edition of the American Psychiatric Association's diagnostic manual.
Symptoms and signs.
Major depression significantly affects a person's family and personal relationships, work or school life, sleeping and eating habits, and general health. Its impact on functioning and well-being has been compared to that of chronic medical conditions such as diabetes.
A person having a major depressive episode usually exhibits a very low mood, which pervades all aspects of life, and an inability to experience pleasure in activities that were formerly enjoyed. Depressed people may be preoccupied with, or ruminate over, thoughts and feelings of worthlessness, inappropriate guilt or regret, helplessness, hopelessness, and self-hatred. In severe cases, depressed people may have symptoms of psychosis. These symptoms include delusions or, less commonly, hallucinations, usually unpleasant. Other symptoms of depression include poor concentration and memory (especially in those with melancholic or psychotic features), withdrawal from social situations and activities, reduced sex drive, and thoughts of death or suicide. Insomnia is common among the depressed. In the typical pattern, a person wakes very early and cannot get back to sleep. Hypersomnia, or oversleeping, can also happen. Some antidepressants may also cause insomnia due to their stimulating effect.
A depressed person may report multiple physical symptoms such as fatigue, headaches, or digestive problems; physical complaints are the most common presenting problem in developing countries, according to the World Health Organization's criteria for depression. Appetite often decreases, with resulting weight loss, although increased appetite and weight gain occasionally occur. Family and friends may notice that the person's behavior is either agitated or lethargic. Older depressed people may have cognitive symptoms of recent onset, such as forgetfulness, and a more noticeable slowing of movements. Depression often coexists with physical disorders common among the elderly, such as stroke, other cardiovascular diseases, Parkinson's disease, and chronic obstructive pulmonary disease.
Depressed children may often display an irritable mood rather than a depressed mood, and show varying symptoms depending on age and situation. Most lose interest in school and show a decline in academic performance. They may be described as clingy, demanding, dependent, or insecure. Diagnosis may be delayed or missed when symptoms are interpreted as normal moodiness. Depression may also coexist with attention-deficit hyperactivity disorder (ADHD), complicating the diagnosis and treatment of both.
Comorbidity.
Major depression frequently co-occurs with other psychiatric problems. The 1990–92 "National Comorbidity Survey" (US) reports that 51% of those with major depression also suffer from lifetime anxiety. Anxiety symptoms can have a major impact on the course of a depressive illness, with delayed recovery, increased risk of relapse, greater disability and increased suicide attempts. American neuroendocrinologist Robert Sapolsky similarly argues that the relationship between stress, anxiety, and depression could be measured and demonstrated biologically. There are increased rates of alcohol and drug abuse and particularly dependence, and around a third of individuals diagnosed with ADHD develop comorbid depression. Post-traumatic stress disorder and depression often co-occur.
Depression and pain often co-occur. One or more pain symptoms are present in 65% of depressed patients, and anywhere from 5 to 85% of patients with pain will be suffering from depression, depending on the setting; there is a lower prevalence in general practice, and higher in specialty clinics. The diagnosis of depression is often delayed or missed, and the outcome worsens. The outcome can also worsen if the depression is noticed but completely misunderstood.
Depression is also associated with a 1.5- to 2-fold increased risk of cardiovascular disease, independent of other known risk factors, and is itself linked directly or indirectly to risk factors such as smoking and obesity. People with major depression are less likely to follow medical recommendations for treating and preventing cardiovascular disorders, which further increases their risk of medical complications. In addition, cardiologists may not recognize underlying depression that complicates a cardiovascular problem under their care.
Causes.
The biopsychosocial model proposes that biological, psychological, and social factors all play a role in causing depression. The diathesis–stress model specifies that depression results when a preexisting vulnerability, or diathesis, is activated by stressful life events. The preexisting vulnerability can be either genetic, implying an interaction between nature and nurture, or schematic, resulting from views of the world learned in childhood.
Depression may be directly caused by damage to the cerebellum as is seen in cerebellar cognitive affective syndrome.
These interactive models have gained empirical support. For example, researchers in New Zealand took a prospective approach to studying depression, by documenting over time how depression emerged among an initially normal cohort of people. The researchers concluded that variation among the serotonin transporter (5-HTT) gene affects the chances that people who have dealt with very stressful life events will go on to experience depression. To be specific, depression may follow such events, but seems more likely to appear in people with one or two short alleles of the 5-HTT gene. In addition, a Swedish study estimated the heritability of depression—the degree to which individual differences in occurrence are associated with genetic differences—to be around 40% for women and 30% for men, and evolutionary psychologists have proposed that the genetic basis for depression lies deep in the history of naturally selected adaptations. A substance-induced mood disorder resembling major depression has been causally linked to long-term drug use or drug abuse, or to withdrawal from certain sedative and hypnotic drugs.
Biological.
Monoamine hypothesis.
Most antidepressant medications increase the levels of one or more of the monoamines—the neurotransmitters serotonin, norepinephrine and dopamine—in the synaptic cleft between neurons in the brain. Some medications affect the monoamine receptors directly.
Serotonin is hypothesized to regulate other neurotransmitter systems; decreased serotonin activity may allow these systems to act in unusual and erratic ways. According to this "permissive hypothesis", depression arises when low serotonin levels promote low levels of norepinephrine, another monoamine neurotransmitter. Some antidepressants enhance the levels of norepinephrine directly, whereas others raise the levels of dopamine, a third monoamine neurotransmitter. These observations gave rise to the monoamine hypothesis of depression. In its contemporary formulation, the monoamine hypothesis postulates that a deficiency of certain neurotransmitters is responsible for the corresponding features of depression: "Norepinephrine may be related to alertness and energy as well as anxiety, attention, and interest in life; [lack of] serotonin to anxiety, obsessions, and compulsions; and dopamine to attention, motivation, pleasure, and reward, as well as interest in life." The proponents of this theory recommend the choice of an antidepressant with mechanism of action that impacts the most prominent symptoms. Anxious and irritable patients should be treated with SSRIs or norepinephrine reuptake inhibitors, and those experiencing a loss of energy and enjoyment of life with norepinephrine- and dopamine-enhancing drugs.
Besides the clinical observations that drugs that increase the amount of available monoamines are effective antidepressants, recent advances in psychiatric genetics indicate that phenotypic variation in central monoamine function may be marginally associated with vulnerability to depression. Despite these findings, the cause of depression is not simply monoamine deficiency. In the past two decades, research has revealed multiple limitations of the monoamine hypothesis, and its explanatory inadequacy has been highlighted within the psychiatric community. A counterargument is that the mood-enhancing effect of MAO inhibitors and SSRIs takes weeks of treatment to develop, even though the boost in available monoamines occurs within hours. Another counterargument is based on experiments with pharmacological agents that cause depletion of monoamines; while deliberate reduction in the concentration of centrally available monoamines may slightly lower the mood of unmedicated depressed patients, this reduction does not affect the mood of healthy people. The monoamine hypothesis, already limited, has been further oversimplified when presented to the public as a mass marketing tool, usually phrased as a "chemical imbalance".
In 2003 a gene-environment interaction (GxE) was hypothesized to explain why life stress is a predictor for depressive episodes in some individuals, but not in others, depending on an allelic variation of the serotonin-transporter-linked promoter region (5-HTTLPR); a 2009 meta-analysis showed stressful life events were associated with depression, but found no evidence for an association with the 5-HTTLPR genotype. Another 2009 meta-analysis agreed with the latter finding. A 2010 review of studies in this area found a systematic relationship between the method used to assess environmental adversity and the results of the studies; this review also found that both 2009 meta-analyses were significantly biased toward negative studies, which used self-report measures of adversity.
Other hypotheses.
MRI scans of patients with depression have revealed a number of differences in brain structure compared to those who are not depressed. Recent meta-analyses of neuroimaging studies in major depression reported that, compared to controls, depressed patients had increased volume of the lateral ventricles and adrenal gland and smaller volumes of the basal ganglia, thalamus, hippocampus, and frontal lobe (including the orbitofrontal cortex and gyrus rectus). Hyperintensities have been associated with patients with a late age of onset, and have led to the development of the theory of vascular depression.
There may be a link between depression and neurogenesis of the hippocampus, a center for both mood and memory. Loss of hippocampal neurons is found in some depressed individuals and correlates with impaired memory and dysthymic mood. Drugs may increase serotonin levels in the brain, stimulating neurogenesis and thus increasing the total mass of the hippocampus. This increase may help to restore mood and memory. Similar relationships have been observed between depression and an area of the anterior cingulate cortex implicated in the modulation of emotional behavior. One of the neurotrophins responsible for neurogenesis is brain-derived neurotrophic factor (BDNF). The level of BDNF in the blood plasma of depressed subjects is drastically reduced (more than threefold) as compared to the norm. Antidepressant treatment increases the blood level of BDNF. Although decreased plasma BDNF levels have been found in many other disorders, there is some evidence that BDNF is involved in the cause of depression and the mechanism of action of antidepressants.
There is some evidence that major depression may be caused in part by an overactive hypothalamic-pituitary-adrenal axis (HPA axis) that results in an effect similar to the neuro-endocrine response to stress. Investigations reveal increased levels of the hormone cortisol and enlarged pituitary and adrenal glands, suggesting disturbances of the endocrine system may play a role in some psychiatric disorders, including major depression. Oversecretion of corticotropin-releasing hormone from the hypothalamus is thought to drive this, and is implicated in the cognitive and arousal symptoms.
The hormone estrogen has been implicated in depressive disorders due to the increase in risk of depressive episodes after puberty, the antenatal period, and reduced rates after menopause. On the converse, the premenstrual and postpartum periods of low estrogen levels are also associated with increased risk. Sudden withdrawal of, fluctuations in or periods of sustained low levels of estrogen have been linked to significant mood lowering. Clinical recovery from depression postpartum, perimenopause, and postmenopause was shown to be effective after levels of estrogen were stabilized or restored.
Other research has explored potential roles of molecules necessary for overall cellular functioning: cytokines. The symptoms of major depressive disorder are nearly identical to those of sickness behavior, the response of the body when the immune system is fighting an infection. This raises the possibility that depression can result from a maladaptive manifestation of sickness behavior as a result of abnormalities in circulating cytokines. The involvement of pro-inflammatory cytokines in depression is strongly suggested by a meta-analysis of the clinical literature showing higher blood concentrations of IL-6 and TNF-α in depressed subjects compared to controls. These immunological abnormalities may cause excessive prostaglandin E₂ production and likely excessive COX-2 expression. Abnormalities in how indoleamine 2,3-dioxygenase enzyme activates as well as the metabolism of tryptophan-kynurenine may lead to excessive metabolism of tryptophan-kynurenine and lead to increased production of the neurotoxin quinolinic acid, contributing to major depression. NMDA activation leading to excessive glutamatergic neurotransmission, may also contribute.
Psychological.
Various aspects of personality and its development appear to be integral to the occurrence and persistence of depression, with negative emotionality as a common precursor. Although depressive episodes are strongly correlated with adverse events, a person's characteristic style of coping may be correlated with his or her resilience. In addition, low self-esteem and self-defeating or distorted thinking are related to depression. Depression is less likely to occur, as well as quicker to remit, among those who are religious. It is not always clear which factors are causes and which are effects of depression; however, depressed persons that are able to reflect upon and challenge their thinking patterns often show improved mood and self-esteem.
American psychiatrist Aaron T. Beck, following on from the earlier work of George Kelly and Albert Ellis, developed what is now known as a cognitive model of depression in the early 1960s. He proposed that three concepts underlie depression: a triad of negative thoughts composed of cognitive errors about oneself, one's world, and one's future; recurrent patterns of depressive thinking, or "schemas"; and distorted information processing. From these principles, he developed the structured technique of cognitive behavioral therapy (CBT). According to American psychologist Martin Seligman, depression in humans is similar to learned helplessness in laboratory animals, who remain in unpleasant situations when they are able to escape, but do not because they initially learned they had no control.
Attachment theory, which was developed by English psychiatrist John Bowlby in the 1960s, predicts a relationship between depressive disorder in adulthood and the quality of the earlier bond between the infant and the adult caregiver. In particular, it is thought that "the experiences of early loss, separation and rejection by the parent or caregiver (conveying the message that the child is unlovable) may all lead to insecure internal working models ... Internal cognitive representations of the self as unlovable and of attachment figures as unloving [or] untrustworthy would be consistent with parts of Beck's cognitive triad". While a wide variety of studies has upheld the basic tenets of attachment theory, research has been inconclusive as to whether self-reported early attachment and later depression are demonstrably related.
Depressed individuals often blame themselves for negative events, and, as shown in a 1993 study of hospitalized adolescents with self-reported depression, those who blame themselves for negative occurrences may not take credit for positive outcomes. This tendency is characteristic of a depressive attributional, or pessimistic explanatory style. According to Albert Bandura, a Canadian social psychologist associated with social cognitive theory, depressed individuals have negative beliefs about themselves, based on experiences of failure, observing the failure of social models, a lack of social persuasion that they can succeed, and their own somatic and emotional states including tension and stress. These influences may result in a negative self-concept and a lack of self-efficacy; that is, they do not believe they can influence events or achieve personal goals.
An examination of depression in women indicates that vulnerability factors—such as early maternal loss, lack of a confiding relationship, responsibility for the care of several young children at home, and unemployment—can interact with life stressors to increase the risk of depression. For older adults, the factors are often health problems, changes in relationships with a spouse or adult children due to the transition to a care-giving or care-needing role, the death of a significant other, or a change in the availability or quality of social relationships with older friends because of their own health-related life changes.
The understanding of depression has also received contributions from the psychoanalytic and humanistic branches of psychology. From the classical psychoanalytic perspective of Austrian psychiatrist Sigmund Freud, depression, or "melancholia", may be related to interpersonal loss and early life experiences. Existential therapists have connected depression to the lack of both meaning in the present and a vision of the future.
Social.
Poverty and social isolation are associated with increased risk of mental health problems in general. Child abuse (physical, emotional, sexual, or neglect) is also associated with increased risk of developing depressive disorders later in life. Such a link has good face validity given that it is during the years of development that a child is learning how to become a social being. Abuse of the child by the caregiver is bound to distort the developing personality and create a much greater risk for depression and many other debilitating mental and emotional states. Disturbances in family functioning, such as parental (particularly maternal) depression, severe marital conflict or divorce, death of a parent, or other disturbances in parenting are additional risk factors. In adulthood, stressful life events are strongly associated with the onset of major depressive episodes. In this context, life events connected to social rejection appear to be particularly related to depression. Evidence that a first episode of depression is more likely to be immediately preceded by stressful life events than are recurrent ones is consistent with the hypothesis that people may become increasingly sensitized to life stress over successive recurrences of depression.
The relationship between stressful life events and social support has been a matter of some debate; the lack of social support may increase the likelihood that life stress will lead to depression, or the absence of social support may constitute a form of strain that leads to depression directly. There is evidence that neighborhood social disorder, for example, due to crime or illicit drugs, is a risk factor, and that a high neighborhood socioeconomic status, with better amenities, is a protective factor. Adverse conditions at work, particularly demanding jobs with little scope for decision-making, are associated with depression, although diversity and confounding factors make it difficult to confirm that the relationship is causal.
Depression can be caused by prejudice. This can occur when people hold negative self-stereotypes about themselves. This "deprejudice" can be related to a group membership (e.g., Me-Gay-Bad) or not (Me-Bad). If someone has prejudicial beliefs about a stigmatized group and then becomes a member of that group, they may internalize their prejudice and develop depression. For example, a boy growing up in the United States may learn the negative stereotype that gay men are immoral. When he grows up and realizes he is gay, he may direct this prejudice inward on himself and become depressed. People may also show prejudice internalization through self-stereotyping because of negative childhood experiences such as verbal and physical abuse.
Evolutionary.
From the standpoint of evolutionary theory, major depression is hypothesized, in some instances, to increase an individual's reproductive fitness. Evolutionary approaches to depression and evolutionary psychology posit specific mechanisms by which depression may have been genetically incorporated into the human gene pool, accounting for the high heritability and prevalence of depression by proposing that certain components of depression are adaptations, such as the behaviors relating to attachment and social rank. Current behaviors can be explained as adaptations to regulate relationships or resources, although the result may be maladaptive in modern environments.
From another viewpoint, a counseling therapist may see depression not as a biochemical illness or disorder but as "a species-wide evolved suite of emotional programs that are mostly activated by a perception, almost always over-negative, of a major decline in personal usefulness, that can sometimes be linked to guilt, shame or perceived rejection". This suite may have manifested in aging hunters in humans' foraging past, who were marginalized by their declining skills, and may continue to appear in alienated members of today's society. The feelings of uselessness generated by such marginalization could in theory prompt support from friends and kin. In addition, in a manner analogous to that in which physical pain has evolved to hinder actions that may cause further injury, "psychic misery" may have evolved to prevent hasty and maladaptive reactions to distressing situations.
Drug and alcohol use.
Very high levels of substance abuse occur in the psychiatric population, especially alcohol, sedatives and cannabis. Depression and other mental health problems can have a substance induced cause; making a differential or dual diagnosis regarding whether mental ill-health is substance related or not or co-occurring is an important part of a psychiatric evaluation. According to the DSM-IV, a diagnosis of mood disorder cannot be made if the cause is believed to be due to "the direct physiological effects of a substance"; when a syndrome resembling major depression is believed to be caused immediately by substance abuse or by an adverse drug reaction, it is referred to as, "substance-induced mood disturbance". Alcoholism or excessive alcohol consumption significantly increases the risk of developing major depression. Like alcohol, the benzodiazepines are central nervous system depressants; this class of medication is commonly used to treat insomnia, anxiety, and muscular spasms. Similar to alcohol, benzodiazepines increase the risk of developing major depression. This increased risk of depression may be due in part to the adverse or toxic effects of sedative-hypnotic drugs including alcohol on neurochemistry, such as decreased levels of serotonin and norepinephrine, or activation of immune mediated inflammatory pathways in the brain. Chronic use of benzodiazepines also can cause or worsen depression, or depression may be part of a protracted withdrawal syndrome. About a quarter of people recovering from alcoholism experience anxiety and depression, which can persist for up to 2 years. Methamphetamine abuse is also commonly associated with depression.
Diagnosis.
Clinical assessment.
A diagnostic assessment may be conducted by a suitably trained general practitioner, or by a psychiatrist or psychologist, who records the person's current circumstances, biographical history, current symptoms, and family history. The broad clinical aim is to formulate the relevant biological, psychological, and social factors that may be impacting on the individual's mood. The assessor may also discuss the person's current ways of regulating mood (healthy or otherwise) such as alcohol and drug use. The assessment also includes a mental state examination, which is an assessment of the person's current mood and thought content, in particular the presence of themes of hopelessness or pessimism, self-harm or suicide, and an absence of positive thoughts or plans. Specialist mental health services are rare in rural areas, and thus diagnosis and management is left largely to primary-care clinicians. This issue is even more marked in developing countries. The mental health examination may include the use of a rating scale such as the Hamilton Rating Scale for Depression or the Beck Depression Inventory. The score on a rating scale alone is insufficient to diagnose depression to the satisfaction of the DSM or ICD, but it provides an indication of the severity of symptoms for a time period, so a person who scores above a given cut-off point can be more thoroughly evaluated for a depressive disorder diagnosis. Several rating scales are used for this purpose. Screening programs have been advocated to improve detection of depression, but there is evidence that they do not improve detection rates, treatment, or outcome.
Primary-care physicians and other non-psychiatrist physicians have difficulty diagnosing depression, in part because they are trained to recognize and treat physical symptoms, and depression can cause myriad physical (psychosomatic) symptoms. Non-psychiatrists miss two-thirds of cases and unnecessarily treat other patients.
Before diagnosing a major depressive disorder, in general a doctor performs a medical examination and selected investigations to rule out other causes of symptoms. These include blood tests measuring TSH and thyroxine to exclude hypothyroidism; basic electrolytes and serum calcium to rule out a metabolic disturbance; and a full blood count including ESR to rule out a systemic infection or chronic disease. Adverse affective reactions to medications or alcohol misuse are often ruled out, as well. Testosterone levels may be evaluated to diagnose hypogonadism, a cause of depression in men.
Subjective cognitive complaints appear in older depressed people, but they can also be indicative of the onset of a dementing disorder, such as Alzheimer's disease. Cognitive testing and brain imaging can help distinguish depression from dementia. A CT scan can exclude brain pathology in those with psychotic, rapid-onset or otherwise unusual symptoms. In general, investigations are not repeated for a subsequent episode unless there is a medical indication.
No biological tests confirm major depression. Biomarkers of depression have been sought to provide an objective method of diagnosis. There are several potential biomarkers, including Brain-Derived Neurotrophic Factor and various functional MRI techniques. One study developed a decision tree model of interpreting a series of fMRI scans taken during various activities. In their subjects, the authors of that study were able to achieve a sensitivity of 80% and a specificity of 87%, corresponding to a negative predictive value of 98% and a positive predictive value of 32% (positive and negative likelihood ratios were 6.15, 0.23, respectively). However, much more research is needed before these tests could be used clinically.
DSM-IV-TR and ICD-10 criteria.
The most widely used criteria for diagnosing depressive conditions are found in the American Psychiatric Association's revised fourth edition of the "Diagnostic and Statistical Manual of Mental Disorders" (DSM-IV-TR), and the World Health Organization's "International Statistical Classification of Diseases and Related Health Problems" (ICD-10), which uses the name "depressive episode" for a single episode and "recurrent depressive disorder" for repeated episodes. The latter system is typically used in European countries, while the former is used in the US and many other non-European nations, and the authors of both have worked towards conforming one with the other.
Both DSM-IV-TR and ICD-10 mark out typical (main) depressive symptoms. ICD-10 defines three typical depressive symptoms (depressed mood, anhedonia, and reduced energy), two of which should be present to determine depressive disorder diagnosis. According to DSM-IV-TR, there are two main depressive symptoms—depressed mood and anhedonia. At least one of these must be present to make a diagnosis of major depressive episode.
Major depressive disorder is classified as a mood disorder in DSM-IV-TR. The diagnosis hinges on the presence of single or recurrent major depressive episodes. Further qualifiers are used to classify both the episode itself and the course of the disorder. The category Depressive Disorder Not Otherwise Specified is diagnosed if the depressive episode's manifestation does not meet the criteria for a major depressive episode. The ICD-10 system does not use the term "major depressive disorder" but lists very similar criteria for the diagnosis of a depressive episode (mild, moderate or severe); the term "recurrent" may be added if there have been multiple episodes without mania.
Major depressive episode.
A major depressive episode is characterized by the presence of a severely depressed mood that persists for at least two weeks. Episodes may be isolated or recurrent and are categorized as mild (few symptoms in excess of minimum criteria), moderate, or severe (marked impact on social or occupational functioning). An episode with psychotic features—commonly referred to as "psychotic depression"—is automatically rated as severe. If the patient has had an episode of mania or markedly elevated mood, a diagnosis of bipolar disorder is made instead. Depression without mania is sometimes referred to as "unipolar" because the mood remains at one emotional state or "pole".
DSM-IV-TR excludes cases where the symptoms are a result of bereavement, although it is possible for normal bereavement to evolve into a depressive episode if the mood persists and the characteristic features of a major depressive episode develop. The criteria have been criticized because they do not take into account any other aspects of the personal and social context in which depression can occur. In addition, some studies have found little empirical support for the DSM-IV cut-off criteria, indicating they are a diagnostic convention imposed on a continuum of depressive symptoms of varying severity and duration: Excluded are a range of related diagnoses, including dysthymia, which involves a chronic but milder mood disturbance; recurrent brief depression, consisting of briefer depressive episodes; minor depressive disorder, whereby only some symptoms of major depression are present; and adjustment disorder with depressed mood, which denotes low mood resulting from a psychological response to an identifiable event or stressor.
Subtypes.
The DSM-IV-TR recognizes five further subtypes of MDD, called "specifiers", in addition to noting the length, severity and presence of psychotic features:
Differential diagnoses.
To confer major depressive disorder as the most likely diagnosis, other potential diagnoses must be considered, including dysthymia, adjustment disorder with depressed mood, or bipolar disorder. Dysthymia is a chronic, milder mood disturbance in which a person reports a low mood almost daily over a span of at least two years. The symptoms are not as severe as those for major depression, although people with dysthymia are vulnerable to secondary episodes of major depression (sometimes referred to as "double depression"). Adjustment disorder with depressed mood is a mood disturbance appearing as a psychological response to an identifiable event or stressor, in which the resulting emotional or behavioral symptoms are significant but do not meet the criteria for a major depressive episode. Bipolar disorder, also known as "manic–depressive disorder", is a condition in which depressive phases alternate with periods of mania or hypomania. Although depression is currently categorized as a separate disorder, there is ongoing debate because individuals diagnosed with major depression often experience some hypomanic symptoms, indicating a mood disorder continuum.
Other disorders need to be ruled out before diagnosing major depressive disorder. They include depressions due to physical illness, medications, and substance abuse. Depression due to physical illness is diagnosed as a mood disorder due to a general medical condition. This condition is determined based on history, laboratory findings, or physical examination. When the depression is caused by a substance abused including a drug of abuse, a medication, or exposure to a toxin, it is then diagnosed as a substance-induced mood disorder.
Prevention.
Behavioral interventions, such as interpersonal therapy and cognitive-behavioral therapy, are effective at preventing new onset depression. Because such interventions appear to be most effective when delivered to individuals or small groups, it has been suggested that they may be able to reach their large target audience most efficiently through the Internet.
However, an earlier meta-analysis found preventive programs with a competence-enhancing component to be superior to behavior-oriented programs overall, and found behavioral programs to be particularly unhelpful for older people, for whom social support programs were uniquely beneficial. In addition, the programs that best prevented depression comprised more than eight sessions, each lasting between 60 and 90 minutes, were provided by a combination of lay and professional workers, had a high-quality research design, reported attrition rates, and had a well-defined intervention.
The Netherlands mental health care system provides preventive interventions, such as the "Coping with Depression" course (CWD) for people with sub-threshold depression. The course is claimed to be the most successful of psychoeducational interventions for the treatment and prevention of depression (both for its adaptability to various populations and its results), with a risk reduction of 38% in major depression and an efficacy as a treatment comparing favorably to other psychotherapies. Preventative efforts may result in decreases in rates of the condition of between 22 and 38%.
Management.
The three most common treatments for depression are psychotherapy, medication, and electroconvulsive therapy. Psychotherapy is the treatment of choice (over medication) for people under 18. The UK National Institute for Health and Care Excellence (NICE) 2004 guidelines indicate that antidepressants should not be used for the initial treatment of mild depression, because the risk-benefit ratio is poor. The guidelines recommend that antidepressants treatment in combination with psychosocial interventions should be considered for:
The guidelines further note that antidepressant treatment should be continued for at least six months to reduce the risk of relapse, and that SSRIs are better tolerated than tricyclic antidepressants.
American Psychiatric Association treatment guidelines recommend that initial treatment should be individually tailored based on factors including severity of symptoms, co-existing disorders, prior treatment experience, and patient preference. Options may include pharmacotherapy, psychotherapy, electroconvulsive therapy (ECT), transcranial magnetic stimulation (TMS) or light therapy. Antidepressant medication is recommended as an initial treatment choice in people with mild, moderate, or severe major depression, and should be given to all patients with severe depression unless ECT is planned.
Treatment options are much more limited in developing countries, where access to mental health staff, medication, and psychotherapy is often difficult. Development of mental health services is minimal in many countries; depression is viewed as a phenomenon of the developed world despite evidence to the contrary, and not as an inherently life-threatening condition. A 2014 Cochrane review found insufficient evidence to determine the effectiveness of psychological versus medical therapy in children.
Psychotherapy.
Psychotherapy can be delivered, to individuals, groups, or families by mental health professionals, including psychotherapists, psychiatrists, psychologists, clinical social workers, counselors, and suitably trained psychiatric nurses. With more complex and chronic forms of depression, a combination of medication and psychotherapy may be used. A 2012 review found psychotherapy to be better than no treatment but not other treatments. A 2014 Cochrane review found that work-directed interventions combined with clinical interventions helped to reduce sick days taken by people with depression.
Cognitive behavioral therapy (CBT) currently has the most research evidence for the treatment of depression in children and adolescents, and CBT and interpersonal psychotherapy (IPT) are preferred therapies for adolescent depression. In people under 18, according to the National Institute for Health and Clinical Excellence, medication should be offered only in conjunction with a psychological therapy, such as CBT, interpersonal therapy, or family therapy. Cognitive behavioral therapy has also been shown to reduce the number of sick days taken by people with depression, when used in conjunction with primary care.
Psychotherapy has been shown to be effective in older people. Successful psychotherapy appears to reduce the recurrence of depression even after it has been terminated or replaced by occasional booster sessions.
The most-studied form of psychotherapy for depression is CBT, which teaches clients to challenge self-defeating, but enduring ways of thinking (cognitions) and change counter-productive behaviors. Research beginning in the mid-1990s suggested that CBT could perform as well or as better than antidepressants in patients with moderate to severe depression. CBT may be effective in depressed adolescents, although its effects on severe episodes are not definitively known. Several variables predict success for cognitive behavioral therapy in adolescents: higher levels of rational thoughts, less hopelessness, fewer negative thoughts, and fewer cognitive distortions. CBT is particularly beneficial in preventing relapse.
Several variants of cognitive behavior therapy have been used in those with depression, the most notable being rational emotive behavior therapy, and mindfulness-based cognitive therapy. Mindfulness based stress reduction programs may reduce depression symptoms. Mindfulness programs also appear to be a promising intervention in youth.
Psychoanalysis is a school of thought, founded by Sigmund Freud, which emphasizes the resolution of unconscious mental conflicts. Psychoanalytic techniques are used by some practitioners to treat clients presenting with major depression. A more widely practiced, eclectic technique, called psychodynamic psychotherapy, is loosely based on psychoanalysis and has an additional social and interpersonal focus. In a meta-analysis of three controlled trials of Short Psychodynamic Supportive Psychotherapy, this modification was found to be as effective as medication for mild to moderate depression.
Logotherapy, a form of existential psychotherapy developed by Austrian psychiatrist Viktor Frankl, addresses the filling of an "existential vacuum" associated with feelings of futility and meaninglessness. It is posited that this type of psychotherapy may be useful for depression in older adolescents.
Antidepressants.
Conflicting results have arisen from studies look at the effectiveness of antidepressants in people with acute mild to moderate depression. Stronger evidence supports the usefulness of antidepressants in the treatment of depression that is chronic (dysthymia) or severe.
While small benefits were found researchers Irving Kirsch and Thomas Moore state they may be due to issues with the trials rather than a true effect of the medication. In a later publication, Kirsch concluded that the overall effect of new-generation antidepressant medication is below recommended criteria for clinical significance. Similar results were obtained in a meta analysis by Fornier.
A review commissioned by the National Institute for Health and Care Excellence concluded that there is strong evidence that SSRIs have greater efficacy than placebo on achieving a 50% reduction in depression scores in moderate and severe major depression, and that there is some evidence for a similar effect in mild depression. Similarly, a Cochrane systematic review of clinical trials of the generic antidepressant amitriptyline concluded that there is strong evidence that its efficacy is superior to placebo.
In 2014 the U.S. FDA published a systematic review of all antidepressant maintenance trials submitted to the agency between 1985 and 2012. The authors concluded that maintenance treatment reduced the risk of relapse by 52% compared to placebo, and that this effect was primarily due to recurrent depression in the placebo group rather than a drug withdrawal effect.
To find the most effective antidepressant medication with minimal side-effects, the dosages can be adjusted, and if necessary, combinations of different classes of antidepressants can be tried. Response rates to the first antidepressant administered range from 50–75%, and it can take at least six to eight weeks from the start of medication to remission. Antidepressant medication treatment is usually continued for 16 to 20 weeks after remission, to minimize the chance of recurrence, and even up to one year of continuation is recommended. People with chronic depression may need to take medication indefinitely to avoid relapse.
Selective serotonin reuptake inhibitors (SSRIs) are the primary medications prescribed, owing to their relatively mild side-effects, and because they are less toxic in overdose than other antidepressants. Patients who do not respond to one SSRI can be switched to another antidepressant, and this results in improvement in almost 50% of cases. Another option is to switch to the atypical antidepressant bupropion. Venlafaxine, an antidepressant with a different mechanism of action, may be modestly more effective than SSRIs. However, venlafaxine is not recommended in the UK as a first-line treatment because of evidence suggesting its risks may outweigh benefits, and it is specifically discouraged in children and adolescents.
For adolescent depression, fluoxetine is recommended Antidepressants appear to have only slight benefit in children. There is also insufficient evidence to determine effectiveness in those with depression complicated by dementia. Any antidepressant can cause low serum sodium levels (also called hyponatremia); nevertheless, it has been reported more often with SSRIs. It is not uncommon for SSRIs to cause or worsen insomnia; the sedating antidepressant mirtazapine can be used in such cases.
Irreversible monoamine oxidase inhibitors, an older class of antidepressants, have been plagued by potentially life-threatening dietary and drug interactions. They are still used only rarely, although newer and better-tolerated agents of this class have been developed. The safety profile is different with reversible monoamine oxidase inhibitors such as moclobemide where the risk of serious dietary interactions is negligible and dietary restrictions are less strict.
For children, adolescents, and probably young adults between 18 and 24 years old, there is a higher risk of both suicidal ideations and suicidal behavior in those treated with SSRIs. For adults, it is unclear whether SSRIs affect the risk of suicidality. One review found no connection; another an increased risk; and a third no risk in those 25–65 years old and a decrease risk in those more than 65. A black box warning was introduced in the United States in 2007 on SSRI and other antidepressant medications due to increased risk of suicide in patients younger than 24 years old. Similar precautionary notice revisions were implemented by the Japanese Ministry of Health.
Other medications.
There is some evidence that fish oil supplements containing high levels of eicosapentaenoic acid (EPA) to docosahexaenoic acid (DHA) may be effective in major depression, but other meta-analysis of the research conclude that positive effects may be due to publication bias. There is some preliminary evidence that COX-2 inhibitors have a beneficial effect on major depression. Lithium appears effective at lowering the risk of suicide in those with bipolar disorder and unipolar depression to nearly the same levels as the general population. There is a narrow range of effective and safe dosages of lithium thus close monitoring may be needed. Low-dose thyroid hormone may be added to existing antidepressants to treat persistent depression symptoms in people who have tried multiple courses of medication.
Electroconvulsive therapy.
Electroconvulsive therapy (ECT) is a standard psychiatric treatment in which seizures are electrically induced in patients to provide relief from psychiatric illnesses.:1880 ECT is used with informed consent as a last line of intervention for major depressive disorder.
A round of ECT is effective for about 50% of people with treatment-resistant major depressive disorder, whether it is unipolar or bipolar. Followup treatment is still poorly studied, but about half of people who respond, relapse with twelve months.
Aside from effects in the brain, the general physical risks of ECT are similar to those of brief general anesthesia.:259 Immediately following treatment, the most common adverse effects are confusion and memory loss. ECT is considered one of the least harmful treatment options available for severely depressed pregnant women.
A usual course of ECT involves multiple administrations, typically given two or three times per week until the patient is no longer suffering symptoms ECT is administered under anesthetic with a muscle relaxant. Electroconvulsive therapy can differ in its application in three ways: electrode placement, frequency of treatments, and the electrical waveform of the stimulus. These three forms of application have significant differences in both adverse side effects and symptom remission. After treatment, drug therapy is usually continued, and some patients receive maintenance ECT.
ECT appears to work in the short term via an anticonvulsant effect mostly in the frontal lobes, and longer term via neurotrophic effects primarily in the medial temporal lobe.
Other.
Bright light therapy reduces depression symptom severity, with benefit was found for both seasonal affective disorder and for nonseasonal depression, and an effect similar to those for conventional antidepressants. For non-seasonal depression, adding light therapy to the standard antidepressant treatment was not effective. For non-seasonal depression where light was used mostly in combination with antidepressants or wake therapy a moderate effect was found, with response better than control treatment in high-quality studies, in studies that applied morning light treatment, and with people who respond to total or partial sleep deprivation. Both analyses noted poor quality, short duration, and small size of most of the reviewed studies.
There is a small amount of evidence that skipping a night's sleep may help. Physical exercise is recommended for management of mild depression, and has a moderate effect on symptoms. It is equivalent to the use of medications or psychological therapies in most people. In the older people it does appear to decrease depression. In unblinded, non-randomized observational studies Smoking cessation has benefits in depression as large as or larger than those of medications. Cognitive behavioral therapy and occupational programs (including modification of work activities and assistance) have been shown to be effective in reducing sick days taken by workers with depression.
Prognosis.
Major depressive episodes often resolve over time whether or not they are treated. Outpatients on a waiting list show a 10–15% reduction in symptoms within a few months, with approximately 20% no longer meeting the full criteria for a depressive disorder. The median duration of an episode has been estimated to be 23 weeks, with the highest rate of recovery in the first three months.
Studies have shown that 80% of those suffering from their first major depressive episode will suffer from at least 1 more during their life, with a lifetime average of 4 episodes. Other general population studies indicate that around half those who have an episode recover (whether treated or not) and remain well, while the other half will have at least one more, and around 15% of those experience chronic recurrence. Studies recruiting from selective inpatient sources suggest lower recovery and higher chronicity, while studies of mostly outpatients show that nearly all recover, with a median episode duration of 11 months. Around 90% of those with severe or psychotic depression, most of whom also meet criteria for other mental disorders, experience recurrence.
Recurrence is more likely if symptoms have not fully resolved with treatment. Current guidelines recommend continuing antidepressants for four to six months after remission to prevent relapse. Evidence from many randomized controlled trials indicates continuing antidepressant medications after recovery can reduce the chance of relapse by 70% (41% on placebo vs. 18% on antidepressant). The preventive effect probably lasts for at least the first 36 months of use.
Those people experiencing repeated episodes of depression require ongoing treatment in order to prevent more severe, long-term depression. In some cases, people must take medications for long periods of time or for the rest of their lives.
Cases when outcome is poor are associated with inappropriate treatment, severe initial symptoms that may include psychosis, early age of onset, more previous episodes, incomplete recovery after 1 year, pre-existing severe mental or medical disorder, and family dysfunction as well.
Depressed individuals have a shorter life expectancy than those without depression, in part because depressed patients are at risk of dying by suicide. However, they also have a higher rate of dying from other causes, being more susceptible to medical conditions such as heart disease. Up to 60% of people who commit suicide have a mood disorder such as major depression, and the risk is especially high if a person has a marked sense of hopelessness or has both depression and borderline personality disorder. The lifetime risk of suicide associated with a diagnosis of major depression in the US is estimated at 3.4%, which averages two highly disparate figures of almost 7% for men and 1% for women (although suicide attempts are more frequent in women). The estimate is substantially lower than a previously accepted figure of 15%, which had been derived from older studies of hospitalized patients.
Depression is often associated with unemployment and poverty. Major depression is currently the leading cause of disease burden in North America and other high-income countries, and the fourth-leading cause worldwide. In the year 2030, it is predicted to be the second-leading cause of disease burden worldwide after HIV, according to the World Health Organization. Delay or failure in seeking treatment after relapse, and the failure of health professionals to provide treatment, are two barriers to reducing disability.
Epidemiology.
Depression is a major cause of morbidity worldwide. It is believed to currently affect approximately 298 million people as of 2010 (4.3% of the global population). Lifetime prevalence varies widely, from 3% in Japan to 17% in the US. In most countries the number of people who have depression during their lives falls within an 8–12% range. In North America, the probability of having a major depressive episode within a year-long period is 3–5% for males and 8–10% for females. Population studies have consistently shown major depression to be about twice as common in women as in men, although it is unclear why this is so, and whether factors unaccounted for are contributing to this. The relative increase in occurrence is related to pubertal development rather than chronological age, reaches adult ratios between the ages of 15 and 18, and appears associated with psychosocial more than hormonal factors.
People are most likely to suffer their first depressive episode between the ages of 30 and 40, and there is a second, smaller peak of incidence between ages 50 and 60. The risk of major depression is increased with neurological conditions such as stroke, Parkinson's disease, or multiple sclerosis, and during the first year after childbirth. It is also more common after cardiovascular illnesses, and is related more to a poor outcome than to a better one. Studies conflict on the prevalence of depression in the elderly, but most data suggest there is a reduction in this age group. Depressive disorders are more common to observe in urban than in rural population and the prevalence is in groups with stronger socioeconomic factors i.e. homelessness.
History.
The Ancient Greek physician Hippocrates described a syndrome of melancholia as a distinct disease with particular mental and physical symptoms; he characterized all "fears and despondencies, if they last a long time" as being symptomatic of the ailment. It was a similar but far broader concept than today's depression; prominence was given to a clustering of the symptoms of sadness, dejection, and despondency, and often fear, anger, delusions and obsessions were included.
The term "depression" itself was derived from the Latin verb "deprimere", "to press down". From the 14th century, "to depress" meant to subjugate or to bring down in spirits. It was used in 1665 in English author Richard Baker's "Chronicle" to refer to someone having "a great depression of spirit", and by English author Samuel Johnson in a similar sense in 1753. The term also came into use in physiology and economics. An early usage referring to a psychiatric symptom was by French psychiatrist Louis Delasiauve in 1856, and by the 1860s it was appearing in medical dictionaries to refer to a physiological and metaphorical lowering of emotional function. Since Aristotle, melancholia had been associated with men of learning and intellectual brilliance, a hazard of contemplation and creativity. The newer concept abandoned these associations and through the 19th century, became more associated with women.
Although "melancholia" remained the dominant diagnostic term, "depression" gained increasing currency in medical treatises and was a synonym by the end of the century; German psychiatrist Emil Kraepelin may have been the first to use it as the overarching term, referring to different kinds of melancholia as "depressive states".
Sigmund Freud likened the state of melancholia to mourning in his 1917 paper "Mourning and Melancholia". He theorized that objective loss, such as the loss of a valued relationship through death or a romantic break-up, results in subjective loss as well; the depressed individual has identified with the object of affection through an unconscious, narcissistic process called the "libidinal cathexis" of the ego. Such loss results in severe melancholic symptoms more profound than mourning; not only is the outside world viewed negatively but the ego itself is compromised. The patient's decline of self-perception is revealed in his belief of his own blame, inferiority, and unworthiness. He also emphasized early life experiences as a predisposing factor. Adolf Meyer put forward a mixed social and biological framework emphasizing "reactions" in the context of an individual's life, and argued that the term "depression" should be used instead of "melancholia". The first version of the DSM (DSM-I, 1952) contained "depressive reaction" and the DSM-II (1968) "depressive neurosis", defined as an excessive reaction to internal conflict or an identifiable event, and also included a depressive type of manic-depressive psychosis within Major affective disorders.
In the mid-20th century, researchers theorized that depression was caused by a chemical imbalance in neurotransmitters in the brain, a theory based on observations made in the 1950s of the effects of reserpine and isoniazid in altering monoamine neurotransmitter levels and affecting depressive symptoms.
The term "unipolar" (along with the related term "bipolar") was coined by the neurologist and psychiatrist Karl Kleist, and subsequently used by his disciples Edda Neele and Karl Leonhard.
The term "Major depressive disorder" was introduced by a group of US clinicians in the mid-1970s as part of proposals for diagnostic criteria based on patterns of symptoms (called the "Research Diagnostic Criteria", building on earlier Feighner Criteria), and was incorporated into the DSM-III in 1980. To maintain consistency the ICD-10 used the same criteria, with only minor alterations, but using the DSM diagnostic threshold to mark a "mild depressive episode", adding higher threshold categories for moderate and severe episodes. The ancient idea of "melancholia" still survives in the notion of a melancholic subtype.
The new definitions of depression were widely accepted, albeit with some conflicting findings and views. There have been some continued empirically based arguments for a return to the diagnosis of melancholia. There has been some criticism of the expansion of coverage of the diagnosis, related to the development and promotion of antidepressants and the biological model since the late 1950s.
Society and culture.
People's conceptualizations of depression vary widely, both within and among cultures. "Because of the lack of scientific certainty," one commentator has observed, "the debate over depression turns on questions of language. What we call it—'disease,' 'disorder,' 'state of mind'—affects how we view, diagnose, and treat it." There are cultural differences in the extent to which serious depression is considered an illness requiring personal professional treatment, or is an indicator of something else, such as the need to address social or moral problems, the result of biological imbalances, or a reflection of individual differences in the understanding of distress that may reinforce feelings of powerlessness, and emotional struggle.
The diagnosis is less common in some countries, such as China. It has been argued that the Chinese traditionally deny or somatize emotional depression (although since the early 1980s, the Chinese denial of depression may have modified drastically). Alternatively, it may be that Western cultures reframe and elevate some expressions of human distress to disorder status. Australian professor Gordon Parker and others have argued that the Western concept of depression "medicalizes" sadness or misery. Similarly, Hungarian-American psychiatrist Thomas Szasz and others argue that depression is a metaphorical illness that is inappropriately regarded as an actual disease. There has also been concern that the DSM, as well as the field of descriptive psychiatry that employs it, tends to reify abstract phenomena such as depression, which may in fact be social constructs. American archetypal psychologist James Hillman writes that depression can be healthy for the soul, insofar as "it brings refuge, limitation, focus, gravity, weight, and humble powerlessness." Hillman argues that therapeutic attempts to eliminate depression echo the Christian theme of resurrection, but have the unfortunate effect of demonizing a soulful state of being.
Historical figures were often reluctant to discuss or seek treatment for depression due to social stigma about the condition, or due to ignorance of diagnosis or treatments. Nevertheless, analysis or interpretation of letters, journals, artwork, writings, or statements of family and friends of some historical personalities has led to the presumption that they may have had some form of depression. People who may have had depression include English author Mary Shelley, American-British writer Henry James, and American president Abraham Lincoln. Some well-known contemporary people with possible depression include Canadian songwriter Leonard Cohen and American playwright and novelist Tennessee Williams. Some pioneering psychologists, such as Americans William James and John B. Watson, dealt with their own depression.
There has been a continuing discussion of whether neurological disorders and mood disorders may be linked to creativity, a discussion that goes back to Aristotelian times. British literature gives many examples of reflections on depression. English philosopher John Stuart Mill experienced a several-months-long period of what he called "a dull state of nerves", when one is "unsusceptible to enjoyment or pleasurable excitement; one of those moods when what is pleasure at other times, becomes insipid or indifferent". He quoted English poet Samuel Taylor Coleridge's "Dejection" as a perfect description of his case: "A grief without a pang, void, dark and drear, / A drowsy, stifled, unimpassioned grief, / Which finds no natural outlet or relief / In word, or sigh, or tear." English writer Samuel Johnson used the term "the black dog" in the 1780s to describe his own depression, and it was subsequently popularized by depression sufferer former British Prime Minister Sir Winston Churchill.
Social stigma of major depression is widespread, and contact with mental health services reduces this only slightly. Public opinions on treatment differ markedly to those of health professionals; alternative treatments are held to be more helpful than pharmacological ones, which are viewed poorly. In the UK, the Royal College of Psychiatrists and the Royal College of General Practitioners conducted a joint Five-year Defeat Depression campaign to educate and reduce stigma from 1992 to 1996; a MORI study conducted afterwards showed a small positive change in public attitudes to depression and treatment.
External links.
Listen to this article ()
This audio file was created from a revision of the "Major depressive disorder" article dated 2014-10-06, and does not reflect subsequent edits to the article. ()
More spoken articles

</doc>
<doc id="8391" url="http://en.wikipedia.org/wiki?curid=8391" title="Diana (mythology)">
Diana (mythology)

In Roman mythology, Diana (lt. "heavenly" or "divine") was the goddess of the hunt, the moon and childbirth, being associated with wild animals and woodland, and having the power to talk to and control animals. She was equated with the Greek goddess Artemis, though she had an independent origin in Italy. Diana was worshipped in ancient Roman religion and is revered in Roman Neopaganism and Stregheria. Dianic Wicca, a largely feminist form of the practice, is named for her. Diana was known to be the virgin goddess of childbirth and women. She was one of the three maiden goddesses, Diana, Minerva and Vesta, who swore never to marry.
Oak groves were especially sacred to her. According to mythology (in common with the Greek religion and their deity Artemis), Diana was born with her twin brother Apollo on the island of Delos, daughter of Jupiter and Latona. Diana made up a triad with two other Roman deities: Egeria the water nymph, her servant and assistant midwife; and Virbius, the woodland god.
Etymology.
Diana (pronounced with long 'ī' and 'ā') is an adjectival form developed from an ancient *"divios", corresponding to later 'divus', 'dius', as in Dius Fidius, Dea Dia and in the neuter form "dium" meaning the sky.
It is rooted in Indoeuropean *d(e)y(e)w, meaning bright sky or daylight, from which also derived the name of Vedic god Dyaus and the Latin deus, (god), "dies", (day, daylight), and " diurnal", (daytime).
On the Tablets of Pylos a theonym διϝια ("diwia") is supposed as referring to a deity precursor of Artemis. Modern scholars mostly accept the identification.#redirect 
The ancient Latin writers Varro and Cicero considered the etymology of Dīāna as allied to that of "dies" and connected to the shine of the Moon.
Mythology.
The persona of Diana is complex and contains a number of archaic features. According to Georges Dumézil it falls into a particular subset of celestial gods, referred to in histories of religion as "frame gods". Such gods, while keeping the original features of celestial divinities, i.e. transcendent heavenly power and abstention from direct rule in worldly matters, did not share the fate of other celestial gods in Indoeuropean religions—that of becoming "dei otiosi" or gods without practical purpose, since they did retain a particular sort of influence over the world and mankind.
The celestial character of Diana is reflected in her connection with light, inaccessibility, virginity, and her preference for dwelling on high mountains and in sacred woods.
Diana therefore reflects the heavenly world ("diuum" means sky or open air) in its sovereignty, supremacy, impassibility, and indifference towards such secular matters as the fates of mortals and states. At the same time, however, she is seen as active in ensuring the succession of kings and in the preservation of humankind through the protection of childbirth.
These functions are apparent in the traditional institutions and cults related to the goddess.
According to Dumezil the forerunner of all "frame gods" is an Indian epic hero who was the image (avatar) of the Vedic god Dyaus. Having renounced the world, in his roles of father and king, he attained the status of an immortal being while retaining the duty of ensuring that his dynasty is preserved and that there is always a new king for each generation.
The Scandinavian god Heimdallr performs an analogous function: he is born first and will die last. He too gives origin to kingship and the first king, bestowing on him regal prerogatives.
Diana, although a female deity, has exactly the same functions, preserving mankind through childbirth and royal succession.
F. H. Pairault in her essay on Diana qualifies Dumézil's theory as "impossible to verify".
Dumezil's interpretation appears deliberately to ignore that of James G. Frazer, who links Diana with the male god Janus as a divine couple. This looks odd as Dumézil's definition of the concept of "frame god" would fit well the figure of Janus. Frazer identifies the two with the supreme heavenly couple Jupiter-Juno and additionally ties in these figures to the overarching Indoeuropean religious complex. This regality is also linked to the cult of trees, particularly oaks.
In this interpretative schema, the institution of the Rex Nemorensis and related ritual should be seen as related to the theme of the dying god and the kings of May.
Physical description.
As a goddess of hunting, Diana often wears a short tunic and hunting boots. She is often portrayed holding a bow, and carrying a quiver on her shoulder, accompanied by a deer or hunting dogs. Like Venus, she was portrayed as beautiful and youthful. The crescent moon, sometimes worn as a diadem, is a major attribute of the goddess.
Worship.
Diana was initially just the hunting goddess, associated with wild animals and woodlands. She also later became a moon goddess, supplanting Titan goddess Luna. She also became the goddess of childbirth and ruled over the countryside. Catullus wrote a poem to Diana in which she has more than one alias: Latonia, Lucina, Iuno, Trivia, Luna.
In Rome the cult of Diana should have been almost as old as the city itself as Varro mentions her in the list of deities to whom king Titus Tatius vowed a shrine. It is noteworthy that the list includes Luna and Diana Lucina as separate entities.
Another testimony to the high antiquity of her cult is to be found in the "lex regia" of king Tullus Hostilius that condemns those guilty of incest to the "sacratio" to the goddess.
Diana was worshipped at a festival on August 13, when King Servius Tullius, himself born a slave, dedicated her temple on the Aventine Hill in the mid-6th century BC. Being placed on the Aventine, and thus outside the "pomerium", meant that Diana's cult essentially remained a "foreign" one, like that of Bacchus; she was never officially "transferred" to Rome as Juno was after the sack of Veii. It seems that her cult originated in Aricia, where her priest, the Rex Nemorensis remained. There the simple open-air fane was held in common by the Latin tribes, which Rome aspired to weld into a league and direct. Diana of the wood was soon thoroughly Hellenized, "a process which culminated with the appearance of Diana beside Apollo in the first "lectisternium" at Rome". Diana was regarded with great reverence and was a patroness of lower-class citizens, called plebeians, and slaves; slaves could receive asylum in her temples. This fact is of difficult interpretation. Georg Wissowa proposed the explanation that it might be because the first slaves of the Romans must have been Latins of the neighbouring tribes. However in Ephesus too there was the same custom of the asylum (ασυλιον).
According to Françoise Hélène Pairault's study, historical and archaeological evidence point to the fact that both Diana of the Aventine and Diana Nemorensis were the product of the direct or indirect influence of the cult of Artemis spread by the Phoceans among the Greek towns of Campania Cuma and Capua, which in turn passed it over to the Etruscans and the Latins by the 6th and 5th centuries BC.
The origin of the ritual of the rex Nemorensis should have to be traced to the legend of Orestes and Iphigenia more than that of Hippolitos. The formation of the Latin League led by Laevius (or Baebius) Egerius happened under the influence of an alliance with the tyrant of Cuma Aristodemos and is probably connected to the political events at end of the 6th century narrated by Livy and Dionysius, such as the siege of Aricia by Porsenna's son Arruns. It is remarkable that the composition of this league does not reflect that of the Latin people who took part in the Latiar or Feriae Latinae given by Pliny and it has not as its leader the "rex Nemorensis" but a "dictator Latinus". It should thence be considered a political formation and not a traditional society founded on links of blood.
It looks as if the confrontation happened between two groups of Etruscans who fought for supremacy, those from Tarquinia, Vulci and Caere (allied with the Greeks of Capua) and those of Clusium. This is reflected in the legend of the coming of Orestes to Nemi and of the inhumation of his bones in the Roman Forum near the temple of Saturn. The cult introduced by Orestes at Nemi is apparently that of the Artemis Tauropolos. The literary amplification reveals a confused religious background: different Artemis were conflated under the epithet. As far as Nemi's Diana is concerned there are two different versions, by Strabo and Servius Honoratus. Strabo's version looks to be the most authoritative as he had access to first hand primary sources on the sanctuaries of Artemis, i.e. the priest of Artemis Artemidoros of Ephesus. The meaning of "Tauropolos" denotes an Asiatic goddess with lunar attributes, lady of the herds. The only possible "interpretatio graeca" of high antiquity concerning "Diana Nemorensis" could have been the one based upon this ancient aspect of deity of light, master of wildlife. "Tauropolos" is an ancient epithet attached to Hecate, Artemis and even Athena. According to the legend Orestes founded Nemi together with Iphigenia. At Cuma the Sybil is the priestess of both Phoibos and Trivia. Hesiod and Stesichorus tell the story according to which after her death Iphigenia was divinised under the name of Hecate, fact which would support the assumption that Artemis Tauropolos had a real ancient alliance with the heroine, who was her priestess in Taurid and her human paragon. This religious complex is in turn supported by the triple statue of Artemis-Hecate. A coin minted by P. Accoleius Lariscolus in 43 BC has been acknowledged as representing the archaic statue of Diana Nemorensis. It represents Artemis with the bow at one extremity, Luna-Selene with flowers at the other and a central deity not immediately identifiable, all united by a horizontal bar.
The iconographical analysis allows the dating of this image to the 6th century at which time there are Etruscan models. Two heads found in the sanctuary and the Roman theatre at Nemi, which have a hollow on their back, lend support to this interpretation of an archaic Diana Trivia, in whom three different elements are associated. The presence of a Hellenised Diana at Nemi should be related to the presence of the cult in Campania, as Diana "Tifatina" was appelled "Trivia" in an imperial age inscription which mentions a "flamen Virbialis" dedicated by "eques" C. Octavius Verus. Cuma too had a cult of a chthonic Hecate and certainly had strict contacts with Latium. The theological complex present in Diana looks very elaborated and certainly Hellenic, while an analogous Latin concept of Diana Trivia seems uncertain, as Latin sources reflect a Hellenised character of the goddess.
Though some Roman patrons ordered marble replicas of the specifically Anatolian "Diana" of Ephesus, where the Temple of Artemis stood, Diana was usually depicted for educated Romans in her Greek guise. If she is accompanied by a deer, as in the "Diana of Versailles" ("illustration, above right") this is because Diana was the patroness of hunting. The deer may also offer a covert reference to the myth of Acteon (or Actaeon), who saw her bathing naked. Diana transformed Acteon into a stag and set his own hunting dogs to kill him.
Worship of Diana is mentioned in the Bible. In Acts of the Apostles, Ephesian metal smiths who felt threatened by Saint Paul’s preaching of Christianity, jealously rioted in her defense, shouting “"Great is Diana of the Ephesians!"” (Acts 19:28, New English Bible). After the city secretary (γραμματεύς) quieted the crowd, he said, “"Men of Ephesus, what person is there who does not know that the city of the Ephesians is the keeper (guardian) of the temple of the great Diana and of her image that fell from heaven ?"" (Acts 19:36)
Sanctuaries.
Diana was an ancient goddess common to all Latin tribes. Therefore many sanctuaries were dedicated to her in the lands inhabited by Latins. The first one is supposed to have been near Alba Longa before the town was destroyed by the Romans.
The Arician wood sanctuary near the lake of Nemi was Latin confederal as testified by the dedicatory epigraph quoted by Cato.
She had a shrine in Rome on the Aventine hill, according to tradition dedicated by king Servius Tullius. Its location is remarkable as the Aventine is situated outside the pomerium, i.e. original territory of the city, in order to comply with the tradition that Diana was a goddess common to all Latins and not exclusively of the Romans.
Other sanctuaries we know about are listed below:
Legacy.
In religion.
Diana's cult has been related in Early Modern Europe to the cult of Nicevenn (a.k.a. Dame Habond, Perchta, Herodiana, etc.). She was related to myths of a female Wild Hunt.
Wicca.
Today there is a branch of Wicca named for her, which is characterized by an exclusive focus on the feminine aspect of the Divine. Diana's name is also used as the third divine name in a Wiccan energy chant- "Isis Astarte Diana Hecate Demeter Kali Inanna".
Stregheria.
In Italy the old religion of Stregheria embraced the goddess Diana as Queen of the Witches; witches being the wise women healers of the time. Diana was said to have created the world of her own being having in herself the seeds of all creation yet to come. It was said that out of herself she divided the darkness and the light, keeping for herself the darkness of creation and creating her brother Apollo, the light. Diana was believed to have loved and ruled with her brother Apollo, the god of the Sun.
In language.
Both the Romanian words for "fairy" "Zânǎ" and Sânzianǎ, the Leonese and Portuguese word for "water nymph" "xana", and the Spanish word for "shooting target" and "morning call" ("diana") seem to come from the name of Diana.
In the arts.
Since the Renaissance the myth of Diana has often been represented in the visual and dramatic arts, including the opera "L'arbore di Diana". In the 16th century, Diana's image figured prominently at the châteaus of Fontainebleau, Chenonceau, & at Anet, in deference to Diane de Poitiers, mistress of Henri of France. At Versailles she was incorporated into the Olympian iconography with which Louis XIV, the Apollo-like "Sun King" liked to surround himself. Diana is also a character in the 1876 Léo Delibes ballet "Sylvia". The plot deals with Sylvia, one of Diana's nymphs and sworn to chastity, and Diana's assault on Sylvia's affections for the shepherd Amyntas.
In painting and sculpture.
Diana has been one of the most popular themes in art. Painters like Titian, Peter Paul Rubens, François Boucher, Nicholas Poussin made use of her myth as a major theme. Most depictions of Diana in art featured the stories of Diana and Actaeon, or Callisto,or depicted her resting after hunting. Some famous work of arts with a Diana theme are :
In "beaux arts".
Beaux Arts architecture and garden design (late 19th and early 20th centuries) used classic references in a modernized form. Two of the most popular of the period were of Pomona (goddess of orchards) as a metaphor for Agriculture, and Diana, representing Commerce, which is a perpetual hunt for advantage and profits.

</doc>
<doc id="8396" url="http://en.wikipedia.org/wiki?curid=8396" title="December 11">
December 11

December 11 is the day of the year in the Gregorian calendar.

</doc>
<doc id="8397" url="http://en.wikipedia.org/wiki?curid=8397" title="Danny Elfman">
Danny Elfman

Daniel Robert "Danny" Elfman (born May 29, 1953) is an American composer, record producer, and actor. He is known as the lead singer and songwriter for the rock band Oingo Boingo, from 1976 to 1995 and later for scoring music for television and film and creating "The Simpsons" main title theme as well as the 1989 "Batman" film theme. He has scored the majority of his long-time friend Tim Burton's films.
Elfman re-entered the film industry in 1976, initially as an actor. He made his film scoring debut in 1982 for the film "Forbidden Zone" directed by his older brother Richard Elfman. He has since been nominated for four Academy Awards and won a Grammy Award for Best Instrumental Composition Written for a Motion Picture, Television or Other Visual Media for Tim Burton's "Batman" and an Emmy Award for his "Desperate Housewives" theme. Elfman was honored with the Richard Kirk Award at the 2002 BMI Film and TV Awards. The award is given annually to a composer who has made significant contributions to film and television music.
Early life and career.
Danny Elfman was born in Los Angeles, California, the son of Blossom Elfman (née Bernstein), a writer and teacher, and Milton Elfman, a teacher who was in the Air Force. Elfman grew up in a Jewish family. He was raised in a racially mixed community in the Baldwin Hills area of Los Angeles. He spent much of his time in the local movie theatre, adoring the music of such film composers as Bernard Herrmann and Franz Waxman. Stating that he hung out with the "band geeks" in high school, he started a ska band. After dropping out of high school, he followed his brother Richard to France, where he performed with Le Grand Magic Circus, an avant-garde musical theater group. Violin in tow, Elfman next journeyed to Africa where he traveled through Ghana, Mali, and Upper Volta, absorbing new musical styles, including the Ghanaian highlife genre which would eventually influence his own music. 
He contracted malaria during his one-year stay and was often sick. Eventually he returned home to the United States, where he began to take Balinese music lessons at CalArts. During this time, he was romantically involved with Kim Gordon, who would later go on to form Sonic Youth. He was never officially a student at the institute; nonetheless, the instructor encouraged him to continue learning. Elfman stated, "He just laughed, and said, 'Sit. Play.' I continued to sit and play for a couple years." At this time, his brother was forming a new musical theater group.
Oingo Boingo.
In 1972 Richard Elfman founded the American new wave band/performance art group, originally called The Mystic Knights of the Oingo Boingo. They played several shows throughout the 1970s until Richard Elfman left the band to become a filmmaker. As a send-off to the band's original concept, Richard Elfman created the film "Forbidden Zone" based on their stage performances. Danny Elfman composed his first score for the film and played the role of Satan (the other band members played his minions). By the time the movie was completed, they had taken the name Oingo Boingo and begun recording and touring as a rock group. From 1976 and on, it was led by Danny Elfman, until 1995 when they suddenly retired. The semi-theatrical music and comedy troupe had transformed into a ska-influenced new wave band in 1979, and then changed again towards a more guitar-oriented rock sound, in the late 1980s.
Elfman and Tim Burton.
In 1985, Tim Burton and Paul Reubens invited Elfman to write the score for their first feature film, "Pee-wee's Big Adventure". Elfman was apprehensive at first because of his lack of formal training, but with orchestration assistance from Oingo Boingo guitarist and arranger Steve Bartek, he achieved his goal of emulating the mood of such composers as Nino Rota and Bernard Herrmann. In the booklet for the first volume of "Music for a Darkened Theatre", Elfman described the first time he heard his music played by a full orchestra as one of the most thrilling experiences of his life. Elfman immediately developed a rapport with Burton and has gone on to score all but two of Burton's major studio releases: "Ed Wood" which was under production while Elfman and Burton were having a serious disagreement, and "". Elfman also provided the singing voice for Jack Skellington in Tim Burton's "The Nightmare Before Christmas" and the voices of both Barrel and the "Clown with the Tear-Away Face". Years later he provided the voice for Bonejangles the skeleton in "Corpse Bride".
Burton has said of his relationship with Elfman: "We don't even have to talk about the music. We don't even have to intellectualize – which is good for both of us, we're both similar that way. We're very lucky to connect" (Breskin, 1997).
Musical influences.
Modern classicist composers, including Béla Bartók, Philip Glass, Lou Harrison, Carl Orff, Harry Partch, Sergei Prokofiev, Maurice Ravel, Erik Satie, Igor Stravinsky, and Pyotr Ilyich Tchaikovsky have influenced the style of Elfman's music. Elfman cited his first time noticing film music being when he heard Bernard Hermann's score to "The Day the Earth Stood Still" as an eleven-year-old and being a fan of film music since then. Other influences based in film music include Erich Wolfgang Korngold, Max Steiner, David Tamkin, and Franz Waxman. Also, Nino Rota served as a significant influence and was the main inspiration for Elfman's score to "Pee-wee's Big Adventure".
Hearing damage.
When asked during a 2007 phone-in interview on XETRA-FM if he ever had any notions of performing in an Oingo Boingo reunion, Elfman immediately rejected the idea and stated that in the last few years with the band he had begun to develop significant and irreversible hearing damage as a result of his continuous exposure to the high noise levels involved in performing in a rock band. He went on to say that he believes his hearing damage is partially due to a genetic predisposition to hearing loss, and that he will never return to the stage for fear of worsening not only his condition but also that of his band mates. 
Recent works.
Elfman recently composed the music for the Cirque du Soleil Show Iris, which was performed at the Dolby Theatre in Hollywood. The production began on July 21, 2011, and ended on January 19, 2013. This is Elfman's most significant non-film work since he composed "Serenada Schizophrana" for the American Composers Orchestra. It was conducted by John Mauceri on its recording and by Steven Sloane at its premiere at Carnegie Hall in New York City on February 23, 2005. After its premiere, it was recorded in studio and released onto SACD on October 3, 2006. The meeting with Mauceri proved fruitful as the composer was encouraged then to write a new concert piece for Mauceri and the Hollywood Bowl Orchestra. Elfman composed an "overture to a non-existent musical" and called the piece "The Overeager Overture". He also continues to compose his film scores in addition to these other projects. In November 2010, it was reported that Danny Elfman is writing the music for a planned musical based on the life of Harry Houdini. But, as of January 2012, he was no longer attached to the project.
In October 2013, Elfman returned to the stage to sing his vocal parts to a handful of "Nightmare Before Christmas" songs as part of a concert titled "Danny Elfman's Music from the Films of Tim Burton". He composed for the 2013 hit film "Oz the Great and Powerful".
Elfman recently composed additional music for the Marvel superhero film "".
Personal life.
Elfman has three children: Lola, born in 1979; Mali, born in 1984; and Oliver, born in 2005. On November 29, 2003, Elfman married film actress Bridget Fonda. In 1997 he scored "A Simple Plan" – his only score for one of her films to date (although he did compose a cue for the film "Army of Darkness", in which Fonda has a cameo). He is the uncle of actor Bodhi Elfman, who is married to actress Jenna Elfman.
Political views.
Describing his politics during the 1980s, Elfman said, "I'm not a doomist. My attitude is always to be critical of what's around you, but not ever to forget how lucky we are. I've traveled around the world. I left thinking I was a revolutionary. I came back real right-wing patriotic. Since then, I've kind of mellowed in between." In 2008, he expressed support for Barack Obama and said that "Sarah Palin was my worst nightmare."
Awards and nominations.
American Film Institute.
Elfman's scores for "Batman" and "Edward Scissorhands" were nominated for AFI's 100 Years of Film Scores:

</doc>
<doc id="8398" url="http://en.wikipedia.org/wiki?curid=8398" title="Dimension">
Dimension

In physics and mathematics, the dimension of a mathematical space (or object) is informally defined as the minimum number of coordinates needed to specify any point within it. Thus a line has a dimension of one because only one coordinate is needed to specify a point on it – for example, the point at 5 on a number line. A surface such as a plane or the surface of a cylinder or sphere has a dimension of two because two coordinates are needed to specify a point on it – for example, both a latitude and longitude are required to locate a point on the surface of a sphere. The inside of a cube, a cylinder or a sphere is three-dimensional because three coordinates are needed to locate a point within these spaces.
In classical mechanics, space and time are different categories and refer to absolute space and time. That conception of the world is a four-dimensional space but not the one that was found necessary to describe electromagnetism. The four dimensions of spacetime consist of events that are not absolutely defined spatially and temporally, but rather are known relative to the motion of an observer. Minkowski space first approximates the universe without gravity; the pseudo-Riemannian manifolds of general relativity describe spacetime with matter and gravity. Ten dimensions are used to describe string theory, and the state-space of quantum mechanics is an infinite-dimensional function space.
The concept of dimension is not restricted to physical objects. High-dimensional spaces frequently occur in mathematics and the sciences. They may be parameter spaces or configuration spaces such as in Lagrangian or Hamiltonian mechanics; these are abstract spaces, independent of the physical space we live in.
In mathematics.
In mathematics, the dimension of an object is an intrinsic property independent of the space in which the object is embedded. For example, a point on the unit circle in the plane can be specified by two Cartesian coordinates, but a single polar coordinate (the angle) would be sufficient, so the circle is 1-dimensional even though it exists in the 2-dimensional plane. This "intrinsic" notion of dimension is one of the chief ways the mathematical notion of dimension differs from its common usages.
The dimension of Euclidean "n"-space E"n"is "n". When trying to generalize to other types of spaces, one is faced with the question "what makes E"n" "n"-dimensional?" One answer is that to cover a fixed ball in E"n" by small balls of radius "ε", one needs on the order of "ε"−"n" such small balls. This observation leads to the definition of the Minkowski dimension and its more sophisticated variant, the Hausdorff dimension, but there are also other answers to that question. For example, the boundary of a ball in E"n" looks locally like E"n"-1 and this leads to the notion of the inductive dimension. While these notions agree on E"n", they turn out to be different when one looks at more general spaces.
A tesseract is an example of a four-dimensional object. Whereas outside mathematics the use of the term "dimension" is as in: "A tesseract "has four dimensions"", mathematicians usually express this as: "The tesseract "has dimension 4"", or: "The dimension of the tesseract "is" 4".
Although the notion of higher dimensions goes back to René Descartes, substantial development of a higher-dimensional geometry only began in the 19th century, via the work of Arthur Cayley, William Rowan Hamilton, Ludwig Schläfli and Bernhard Riemann. Riemann's 1854 Habilitationsschrift, Schläfli's 1852 "Theorie der vielfachen Kontinuität", Hamilton's 1843 discovery of the quaternions and the construction of the Cayley algebra marked the beginning of higher-dimensional geometry.
The rest of this section examines some of the more important mathematical definitions of the dimensions.
Dimension of a vector space.
The dimension of a vector space is the number of vectors in any basis for the space, i.e. the number of coordinates necessary to specify any vector. This notion of dimension (the cardinality of a basis) is often referred to as the "Hamel dimension" or "algebraic dimension" to distinguish it from other notions of dimension.
Manifolds.
A connected topological manifold is locally homeomorphic to Euclidean "n"-space, and the number "n" is called the manifold's dimension. One can show that this yields a uniquely defined dimension for every connected topological manifold.
For connected differentiable manifolds, the dimension is also the dimension of the tangent vector space at any point.
In geometric topology, the theory of manifolds is characterized by the way dimensions 1 and 2 are relatively elementary, the high-dimensional cases "n" > 4 are simplified by having extra space in which to "work"; and the cases "n" = 3 and 4 are in some senses the most difficult. This state of affairs was highly marked in the various cases of the Poincaré conjecture, where four different proof methods are applied.
Varieties.
The dimension of an algebraic variety may be defined in various equivalent ways. The most intuitive way is probably the dimension of the tangent space at any regular point. Another intuitive way is to define the dimension as the number of hyperplanes that are needed in order to have an intersection with the variety that is reduced to a finite number of points (dimension zero). This definition is based on the fact that the intersection of a variety with a hyperplane reduces the dimension by one unless if the hyperplane contains the variety.
An algebraic set being a finite union of algebraic varieties, its dimension is the maximum of the dimensions of its components. It is equal to the maximal length of the chains formula_1 of sub-varieties of the given algebraic set (the length of such a chain is the number of "formula_2").
Each variety can be considered as an algebraic stack, and its dimension as variety agrees with its dimension as stack. There are however many stacks which do not correspond to varieties, and some of these have negative dimension. Specifically, if "V" is a variety of dimension "m" and "G" is an algebraic group of dimension "n" acting on "V", then the quotient stack ["V"/"G"] has dimension "m"−"n".
Krull dimension.
The Krull dimension of a commutative ring is the maximal length of chains of prime ideals in it, a chain of length "n" being a sequence formula_3 of prime ideals related by inclusion. It is strongly related to the dimension of an algebraic variety, because of the natural correspondence between sub-varieties and prime ideals of the ring of the polynomials on the variety.
For an algebra over a field, the dimension as vector space is finite if and only if its Krull dimension is 0.
Lebesgue covering dimension.
For any normal topological space "X", the Lebesgue covering dimension of "X" is defined to be n if "n" is the smallest integer for which the following holds: any open cover has an open refinement (a second open cover where each element is a subset of an element in the first cover) such that no point is included in more than "n" + 1 elements. In this case dim . For "X" a manifold, this coincides with the dimension mentioned above. If no such integer "n" exists, then the dimension of "X" is said to be infinite, and one writes dim . Moreover, "X" has dimension −1, i.e. dim if and only if "X" is empty. This definition of covering dimension can be extended from the class of normal spaces to all Tychonoff spaces merely by replacing the term "open" in the definition by the term "functionally open".
Inductive dimension.
An inductive definition of dimension can be created as follows. Consider a discrete set of points (such as a finite collection of points) to be 0-dimensional. By dragging a 0-dimensional object in some direction, one obtains a 1-dimensional object. By dragging a 1-dimensional object in a "new direction", one obtains a 2-dimensional object. In general one obtains an ("n" + 1)-dimensional object by dragging an "n"-dimensional object in a "new" direction.
The inductive dimension of a topological space may refer to the "small inductive dimension" or the "large inductive dimension", and is based on the analogy that ("n" + 1)-dimensional balls have "n"-dimensional boundaries, permitting an inductive definition based on the dimension of the boundaries of open sets.
Hausdorff dimension.
For structurally complicated sets, especially fractals, the Hausdorff dimension is useful. The Hausdorff dimension is defined for all metric spaces and, unlike the dimensions considered above, can also attain non-integer real values. The box dimension or Minkowski dimension is a variant of the same idea. In general, there exist more definitions of fractal dimensions that work for highly irregular sets and attain non-integer positive real values. Fractals have been found useful to describe many natural objects and phenomena.
Hilbert spaces.
Every Hilbert space admits an orthonormal basis, and any two such bases for a particular space have the same cardinality. This cardinality is called the dimension of the Hilbert space. This dimension is finite if and only if the space's Hamel dimension is finite, and in this case the above dimensions coincide.
In physics.
Spatial dimensions.
Classical physics theories describe three physical dimensions: from a particular point in space, the basic directions in which we can move are up/down, left/right, and forward/backward. Movement in any other direction can be expressed in terms of just these three. Moving down is the same as moving up a negative distance. Moving diagonally upward and forward is just as the name of the direction implies; "i.e.", moving in a linear combination of up and forward. In its simplest form: a line describes one dimension, a plane describes two dimensions, and a cube describes three dimensions. (See Space and Cartesian coordinate system.)
Time.
A temporal dimension is a dimension of time. Time is often referred to as the "fourth dimension" for this reason, but that is not to imply that it is a spatial dimension. A temporal dimension is one way to measure physical change. It is perceived differently from the three spatial dimensions in that there is only one of it, and that we cannot move freely in time but subjectively move in one direction.
The equations used in physics to model reality do not treat time in the same way that humans commonly perceive it. The equations of classical mechanics are symmetric with respect to time, and equations of quantum mechanics are typically symmetric if both time and other quantities (such as charge and parity) are reversed. In these models, the perception of time flowing in one direction is an artifact of the laws of thermodynamics (we perceive time as flowing in the direction of increasing entropy).
The best-known treatment of time as a dimension is Poincaré and Einstein's special relativity (and extended to general relativity), which treats perceived space and time as components of a four-dimensional manifold, known as spacetime, and in the special, flat case as Minkowski space.
Additional dimensions.
In physics, three dimensions of space and one of time is the accepted norm. However, there are theories that attempt to unify the four fundamental forces by introducing more dimensions. Most notably, superstring theory requires 10 spacetime dimensions, and originates from a more fundamental 11-dimensional theory tentatively called M-theory which subsumes five previously distinct superstring theories. To date, no experimental or observational evidence is available to confirm the existence of these extra dimensions. If extra dimensions exist, they must be hidden from us by some physical mechanism. One well-studied possibility is that the extra dimensions may be "curled up" at such tiny scales as to be effectively invisible to current experiments. Limits on the size and other properties of extra dimensions are set by particle experiments such as those at the Large Hadron Collider.
At the level of quantum field theory, Kaluza–Klein theory unifies gravity with gauge interactions, based on the realization that gravity propagating in small, compact extra dimensions is equivalent to gauge interactions at long distances. In particular when the geometry of the extra dimensions is trivial, it reproduces electromagnetism. However at sufficiently high energies or short distances, this setup still suffers from the same pathologies that famously obstruct direct attempts to describe quantum gravity. Therefore these models still require a UV completion, of the kind that string theory is intended to provide. Thus Kaluza-Klein theory may be considered either as an incomplete description on its own, or as a subset of string theory model building.
In addition to small and curled up extra dimensions, there may be extra dimensions that instead aren't apparent because the matter associated with our visible universe is localized on a (3 + 1)-dimensional subspace. Thus the extra dimensions need not be small and compact but may be large extra dimensions. D-branes are dynamical extended objects of various dimensionalities predicted by string theory that could play this role. They have the property that open string excitations, which are associated with gauge interactions, are confined to the brane by their endpoints, whereas the closed strings that mediate the gravitational interaction are free to propagate into the whole spacetime, or "the bulk". This could be related to why gravity is exponentially weaker than the other forces, as it effectively dilutes itself as it propagates into a higher-dimensional volume.
Some aspects of brane physics have been applied to cosmology. For example, brane gas cosmology attempts to explain why there are three dimensions of space using topological and thermodynamic considerations. According to this idea it would be because three is the largest number of spatial dimensions where strings can generically intersect. If initially there are lots of windings of strings around compact dimensions, space could only expand to macroscopic sizes once these windings are eliminated, which requires oppositely wound strings to find each other and annihilate. But strings can only find each other to annihilate at a meaningful rate in three dimensions, so it follows that only three dimensions of space are allowed to grow large given this kind of initial configuration.
Extra dimensions are said to be universal if all fields are equally free to propagate within them.
Networks and dimension.
Some complex networks are characterized by fractal dimensions. The concept of dimension can be generalized to include networks embedded in space. The dimension characterize their spatial constraints.
In literature.
Perhaps the most basic way the word "dimension" is used in literature is as a hyperbolic synonym for "feature", "attribute", "aspect" or "magnitude". Frequently the hyperbole is quite literal as in "He's so two-dimensional", meaning that one can see at a glance what he "is". This contrasts with three-dimensional objects, which have an interior that is hidden from view and a back that can only be seen with further examination.
Science fiction texts often mention the concept of "dimension" when referring to parallel or alternate universes or other imagined planes of existence. This usage is derived from the idea that to travel to parallel/alternate universes/planes of existence one must travel in a direction/dimension besides the standard ones. In effect, the other universes/planes are just a small distance away from our own, but the distance is in a fourth (or higher) spatial (or non-spatial) dimension, not the standard ones.
One of the most heralded science fiction stories regarding true geometric dimensionality, and often recommended as a starting point for those just starting to investigate such matters, is the 1884 novella "Flatland" by Edwin A. Abbott. Isaac Asimov, in his foreword to the Signet Classics 1984 edition, described "Flatland" as "The best introduction one can find into the manner of perceiving dimensions."
The idea of other dimensions was incorporated into many early science fiction stories, appearing prominently, for example, in Miles J. Breuer's "The Appendix and the Spectacles" (1928) and Murray Leinster's "The Fifth-Dimension Catapult" (1931); and appeared irregularly in science fiction by the 1940s. Classic stories involving other dimensions include Robert A. Heinlein's "—And He Built a Crooked House" (1941), in which a California architect designs a house based on a three-dimensional projection of a tesseract; and Alan E. Nourse's "Tiger by the Tail" and "The Universe Between" (both 1951). Another reference is Madeleine L'Engle's novel "A Wrinkle In Time" (1962), which uses the fifth dimension as a way for "tesseracting the universe" or "folding" space in order to move across it quickly. The fourth and fifth dimensions were also a key component of the book "The Boy Who Reversed Himself" by William Sleator.
In philosophy.
Immanuel Kant, in 1783, wrote: "That everywhere space (which is not itself the boundary of another space) has three dimensions and that space in general cannot have more dimensions is based on the proposition that not more than three lines can intersect at right angles in one point. This proposition cannot at all be shown from concepts, but rests immediately on intuition and indeed on pure intuition "a priori" because it is apodictically (demonstrably) certain."
"Space has Four Dimensions" is a short story published in 1846 by German philosopher and experimental psychologist Gustav Fechner under the pseudonym "Dr. Mises". The protagonist in the tale is a shadow who is aware of and able to communicate with other shadows, but who is trapped on a two-dimensional surface. According to Fechner, this "shadow-man" would conceive of the third dimension as being one of time. The story bears a strong similarity to the "Allegory of the Cave" presented in Plato's "The Republic" (c. 380 BC).
Simon Newcomb wrote an article for the "Bulletin of the American Mathematical Society" in 1898 entitled "The Philosophy of Hyperspace". Linda Dalrymple Henderson coined the term "hyperspace philosophy", used to describe writing that uses higher dimensions to explore metaphysical themes, in her 1983 thesis about the fourth dimension in early-twentieth-century art. Examples of "hyperspace philosophers" include Charles Howard Hinton, the first writer, in 1888, to use the word "tesseract"; and the Russian esotericist P. D. Ouspensky.
See also.
Topics by dimension.
Zero
One
Two
Three
Four
Higher dimensions in mathematics
Infinite

</doc>
<doc id="8400" url="http://en.wikipedia.org/wiki?curid=8400" title="Duodecimal">
Duodecimal

The duodecimal system (also known as base 12 or dozenal) is a positional notation numeral system using twelve as its base. In this system, the number ten may be written as "A", "T", or "X", and the number eleven as "B" or "E". Another common notation, introduced by Sir Isaac Pitman, is to use a rotated "2" (2) for ten and a reversed "3" (3) for eleven. The number twelve (that is, the number written as "12" in the base ten numerical system) is instead written as "10" in duodecimal (meaning "1 dozen and 0 units", instead of "1 ten and 0 units"), whereas the digit string "12" means "1 dozen and 2 units" (i.e. the same number that in decimal is written as "14"). Similarly, in duodecimal "100" means "1 gross", "1000" means "1 great gross", and "0.1" means "1 twelfth" (instead of their decimal meanings "1 hundred", "1 thousand", and "1 tenth").
The number twelve, a superior highly composite number, is the smallest number with four non-trivial factors (2, 3, 4, 6), and the smallest to include as factors all four numbers (1 to 4) within the subitizing range. As a result of this increased factorability of the radix and its divisibility by a wide range of the most elemental numbers (whereas ten has only two non-trivial factors: 2 and 5, with neither 3 nor 4), duodecimal representations fit more easily than decimal ones into many common patterns, as evidenced by the higher regularity observable in the duodecimal multiplication table. As a result, duodecimal has been described as the optimal number system. Of its factors, 2 and 3 are prime, which means the reciprocals of all 3-smooth numbers (such as 2, 3, 4, 6, 8, 9...) have a terminating representation in duodecimal. In particular, the five most elementary fractions (1⁄2, 1⁄3, 2⁄3, 1⁄4 and 3⁄4) all have a short terminating representation in duodecimal (0.6, 0.4, 0.8, 0.3 and 0.9, respectively), and twelve is the smallest radix with this feature (because it is the least common multiple of 3 and 4). This all makes it a more convenient number system for computing fractions than most other number systems in common use, such as the decimal, vigesimal, binary, octal and hexadecimal systems. Although the trigesimal system (where the reciprocals of all 5-smooth numbers terminate) does even better in this respect, this is at the cost of an unwieldy multiplication table and a much larger number of symbols to memorize.
Origin.
Languages using duodecimal number systems are uncommon. Languages in the Nigerian Middle Belt such as Janji, Gbiri-Niragu (Gure-Kahugu), Piti, and the Nimbia dialect of Gwandara; the Chepang language of Nepal and the Mahl language of Minicoy Island in India are known to use duodecimal numerals. In fiction, J. R. R. Tolkien's Elvish languages can express numbers either decimally (in Quenya, "maquanótië" "hand-counting" or *"quaistanótië" "tenth-counting") or duodecimally (presumably *"rastanótië" "dozen-counting")
Germanic languages have special words for 11 and 12, such as "eleven" and "twelve" in English. However, they are considered to come from Proto-Germanic *"ainlif" and *"twalif" (respectively "one left" and "two left"), both of which were decimal.
Historically, units of time in many civilizations are duodecimal. There are twelve signs of the zodiac, twelve months in a year, and the Babylonians had twelve hours in a day (although at some point this was changed to 24). Traditional Chinese calendars, clocks, and compasses are based on the twelve Earthly Branches. There are 12 inches in an imperial foot, 12 troy ounces in a troy pound, 12 old British pence in a shilling, 24 (12×2) hours in a day, and many other items counted by the dozen, gross (144, square of 12) or great gross (1728, cube of 12). The Romans used a fraction system based on 12, including the uncia which became both the English words "ounce" and "inch". Pre-decimalisation, Ireland and the United Kingdom used a mixed duodecimal-vigesimal currency system (12 pence = 1 shilling, 20 shillings or 240 pence to the pound sterling or Irish pound), and Charlemagne established a monetary system that also had a mixed base of twelve and twenty, the remnants of which persist in many places.
The importance of 12 has been attributed to the number of lunar cycles in a year, and also to the fact that humans have 12 finger bones (phalanges) on one hand (three on each of four fingers). It is possible to count to 12 with your thumb acting as a pointer, touching each finger bone in turn. A traditional finger counting system still in use in many regions of Asia works in this way, and could help to explain the occurrence of numeral systems based on 12 and 60 besides those based on 10, 20 and 5. In this system, the one (usually right) hand counts repeatedly to 12, displaying the number of iterations on the other (usually left), until five dozens, i. e. the 60, are full.
Places.
In a duodecimal place system, ten can be written as 2, ᘔ, or ↊ (an inverted digit two); eleven can be written as 3, Ɛ, or ↋ (an inverted digit three); and twelve is written as 10. For alternative symbols, see below.
According to this notation, duodecimal 50 expresses the same quantity as decimal 60 (= five times twelve), duodecimal 60 is equivalent to decimal 72 (= six times twelve = half a gross), duodecimal 100 has the same value as decimal 144 (= twelve times twelve = one gross), etc.
Comparison to other numeral systems.
The number 12 has six factors, which are 1, 2, 3, 4, 6, and 12, of which 2 and 3 are prime. The decimal system has only four factors, which are 1, 2, 5, and 10; of which 2 and 5 are prime. Vigesimal adds two factors to those of ten, namely 4 and 20, but no additional prime factor. Although twenty has 6 factors, 2 of them prime, similarly to twelve, it is also a much larger base (i.e. the digit set and the multiplication table are much larger). Binary has only two factors, 1 and 2, the latter being prime. Hexadecimal has five factors, adding 4, 8 and 16 to those of 2, but no additional prime. Trigesimal is the smallest system that has three different prime factors (all of the three smallest primes: 2, 3 and 5) and it has eight factors in total (1, 2, 3, 5, 6, 10, 15, and 30). Sexagesimal—which the ancient Sumerians and Babylonians among others actually used—adds the four convenient factors 4, 12, 20, and 60 to this but no new prime factors. The smallest system that has four different prime factors is base 210 and the pattern follows the primorials. In all base systems, there are similarities to the representation of multiples of numbers which are one less than the base.
Conversion tables to and from decimal.
To convert numbers between bases, one can use the general conversion algorithm (see the relevant section under positional notation). Alternatively, one can use digit-conversion tables. The ones provided below can be used to convert any duodecimal number between 0.01 and ƐƐƐ,ƐƐƐ.ƐƐ to decimal, or any decimal number between 0.01 and 999,999.99 to duodecimal. To use them, the given number must first be decomposed into a sum of numbers with only one significant digit each. For example:
123,456.78 = 100,000 + 20,000 + 3,000 + 400 + 50 + 6 + 0.7 + 0.08
This decomposition works the same no matter what base the number is expressed in. Just isolate each non-zero digit, padding them with as many zeros as necessary to preserve their respective place values. If the digits in the given number include zeroes (for example, 102,304.05), these are, of course, left out in the digit decomposition (102,304.05 = 100,000 + 2,000 + 300 + 4 + 0.05). Then the digit conversion tables can be used to obtain the equivalent value in the target base for each digit. If the given number is in duodecimal and the target base is decimal, we get:
 100,000 + 20,000 + 3,000 + 400 + 50 + 6 + 0.7 + 0.08 = 248,832 + 41,472 + 5,184 + 576 + 60 + 6 + 0.583333333333... + 0.055555555555...
Now, because the summands are already converted to base ten, the usual decimal arithmetic is used to perform the addition and recompose the number, arriving at the conversion result:
 Duodecimal -----> Decimal
 100,000 = 248,832
 20,000 = 41,472
 3,000 = 5,184
 400 = 576
 50 = 60
 + 6 = + 6
 0.7 = 0.583333333333...
 0.08 = 0.055555555555...
 123,456.78 = 296,130.638888888888...
That is, 123,456.78 equals 296,130.638 ≈ 296,130.64
If the given number is in decimal and the target base is duodecimal, the method is basically same. Using the digit conversion tables:
 100,000 + 20,000 + 3,000 + 400 + 50 + 6 + 0.7 + 0.08 = 49,ᘔ54 + Ɛ,6ᘔ8 + 1,8ᘔ0 + 294 + 42 + 6 + 0.849724972497249724972497... + 0.0Ɛ62ᘔ68781Ɛ05915343ᘔ0Ɛ62...
However, in order to do this sum and recompose the number, now the addition tables for the duodecimal system have to be used, instead of the addition tables for decimal most people are already familiar with, because the summands are now in base twelve and so the arithmetic with them has to be in duodecimal as well. In decimal, 6 + 6 equals 12, but in duodecimal it equals 10; so, if using decimal arithmetic with duodecimal numbers one would arrive at an incorrect result. Doing the arithmetic properly in duodecimal, one gets the result:
 Decimal -----> Duodecimal
 100,000 = 49,ᘔ54
 20,000 = Ɛ,6ᘔ8
 3,000 = 1,8ᘔ0
 400 = 294
 50 = 42
 + 6 = + 6
 0.7 = 0.849724972497249724972497...
 0.08 = 0.0Ɛ62ᘔ68781Ɛ05915343ᘔ0Ɛ62...
 123,456.78 = 5Ɛ,540.943ᘔ0Ɛ62ᘔ68781Ɛ05915343ᘔ...
That is, 123,456.78 equals 5Ɛ,540.943ᘔ0Ɛ62ᘔ68781Ɛ059153... ≈ 5Ɛ,540.94
Fractions and irrational numbers.
Fractions.
Duodecimal fractions may be simple:
or complicated:
As explained in recurring decimals, whenever an irreducible fraction is written in radix point notation in any base, the fraction can be expressed exactly (terminates) if and only if all the prime factors of its denominator are also prime factors of the base. Thus, in base-ten (= 2×5) system, fractions whose denominators are made up solely of multiples of 2 and 5 terminate: 1⁄8 = 1⁄(2×2×2), 1⁄20 = 1⁄(2×2×5) and 1⁄500 = 1⁄(2×2×5×5×5) can be expressed exactly as 0.125, 0.05 and 0.002 respectively. 1⁄3 and 1⁄7, however, recur (0.333... and 0.142857142857...). In the duodecimal (= 2×2×3) system, 1⁄8 is exact; 1⁄20 and 1⁄500 recur because they include 5 as a factor; 1⁄3 is exact; and 1⁄7 recurs, just as it does in decimal.
Recurring digits.
The Dozenal Society of America argues that factors of 3 are more commonly encountered in real-life division problems than factors of 5. Thus, in practical applications, the nuisance of repeating decimals is encountered less often when duodecimal notation is used. Advocates of duodecimal systems argue that this is particularly true of financial calculations, in which the twelve months of the year often enter into calculations.
However, when recurring fractions "do" occur in duodecimal notation, they are less likely to have a very short period than in decimal notation, because 12 (twelve) is between two prime numbers, 11 (eleven) and 13 (thirteen), whereas ten is adjacent to the composite number 9. Nonetheless, having a shorter or longer period doesn't help the main inconvenience that one does not get a finite representation for such fractions in the given base (so rounding, which introduces inexactitude, is necessary to handle them in calculations), and overall one is more likely to have to deal with infinite recurring digits when fractions are expressed in decimal than in duodecimal, because one out of every three consecutive numbers contains the prime factor 3 in its factorization, whereas only one out of every five contains the prime factor 5. All other prime factors, except 2, are not shared by either ten or twelve, so they do not
influence the relative likeliness of encountering recurring digits (any irreducible fraction that contains any of these other factors in its denominator will recur in either base). Also, the prime factor 2 appears twice in the factorization of twelve, whereas only once in the factorization of ten; which means that most fractions whose denominators are powers of two will have a shorter, more convenient terminating representation in duodecimal than in decimal representation (e.g. 1/(22) = 0.25 dec = 0.3 duod; 1/(23) = 0.125 dec = 0.16 duod; 1/(24) = 0.0625 dec = 0.09 duod; 1/(25) = 0.03125 dec = 0.046 duod; etc.).
Values in bold indicate that value is exact.
The duodecimal period length of 1/"n" are
The duodecimal period length of 1/("n"th prime) are
Smallest prime with duodecimal period "n" are
Irrational numbers.
As for irrational numbers, none of them have a finite representation in "any" of the rational-based positional number systems (such as the decimal and duodecimal ones); this is because a rational-based positional number system is essentially nothing but a way of expressing quantities as a sum of fractions whose denominators are powers of the base, and by definition no "finite" sum of rational numbers can ever result in an irrational number. For example, 123.456 = 1 × 102 + 2 × 101 + 3 × 100 + 4 × 1/101 + 5 × 1/102 + 6 × 1/103 (this is also the reason why fractions that contain prime factors in their denominator not in common with those of the base do not have a terminating representation in that base). Moreover, the infinite series of digits of an irrational number does not exhibit a pattern of repetition; instead, the different digits succeed in a seemingly random fashion. The following chart compares the first few digits of the decimal and duodecimal representation of several of the most important algebraic and transcendental irrational numbers. Some of these numbers may be perceived as having fortuitous patterns, making them easier to memorize, when represented in one base or the other.
The first few digits of the decimal and duodecimal representation of another important number, the Euler–Mascheroni constant (the status of which as a rational or irrational number is not yet known), are:
Advocacy and "dozenalism".
The case for the duodecimal system was put forth at length in F. Emerson Andrews' 1935 book "New Numbers: How Acceptance of a Duodecimal Base Would Simplify Mathematics". Emerson noted that, due to the prevalence of factors of twelve in many traditional units of weight and measure, many of the computational advantages claimed for the metric system could be realized "either" by the adoption of ten-based weights and measure "or" by the adoption of the duodecimal number system.
Rather than the symbols "A" for ten and "B" for eleven as used in hexadecimal notation and vigesimal notation (or "T" and "E" for ten and eleven), he suggested in his book and used a script X and a script E, formula_1 (U+1D4B3) and (U+2130), to represent the digits ten and eleven respectively, because, at least on a page of Roman script, these characters were distinct from any existing letters or numerals, yet were readily available in printers' fonts. He chose formula_1 for its resemblance to the Roman numeral X, and as the first letter of the word "eleven".
Another popular notation, introduced by Sir Isaac Pitman, is to use a rotated 2 (ᘔ) (resembling a script "τ" for "ten") to represent ten and a rotated or horizontally flipped 3 (Ɛ) to represent eleven. This is the convention commonly employed by the Dozenal Society of Great Britain and has the advantage of being easily recognizable as digits because of their resemblance in shape to existing digits. On the other hand, the Dozenal Society of America adopted for some years the convention of using a sextile ⚹ for ten and a hash ⌗ for eleven. The reason was that the symbol ⚹ resembles a struck-through X, whereas the symbol ⌗ resembles a doubly-struck-through 11, and both symbols are already present in telephone dials. However, critics pointed out these symbols do not look anything like digits. Some other systems write 10 as Φ (a combination of 1 and 0) and eleven as a cross of two lines (+, x, or † for example).
Problems with these symbols are evident, most notably that most of them cannot be represented in the seven-segment display of most calculator displays ( being an exception, although "E" is used on calculators to indicate an error message). However, 10 and 11 do fit, both within a single digit (11 fits as is, whereas the 10 has to be tilted sideways, resulting in a character that resembles an O with a macron, ō or o). A and B also fit (although B must be represented as lowercase "b" and as such, 6 must have a bar over it to distinguish the two figures) and are used on calculators for bases higher than ten.
Other problems relate to the current usage of most of the proposed symbols as variables or quantities in physics and mathematics. Of particular concern to mathematicians is formula_1 which has ubiquitous usage as an unknown quantity in algebra.
In "Little Twelvetoes", American television series "Schoolhouse Rock!" portrayed an alien child using base-twelve arithmetic, using "dek", "el" and "doh" as names for ten, eleven and twelve, and Andrews' script-X and script-E for the digit symbols. ("Dek" is from the prefix "deca", "el" being short for "eleven" and "doh" an apparent shortening of "dozen".)
The Dozenal Society of America and the Dozenal Society of Great Britain promote widespread adoption of the base-twelve system. They use the word "dozenal" instead of "duodecimal" because the latter comes from Latin roots that express twelve in base-ten terminology.
The renowned mathematician and mental calculator Alexander Craig Aitken was an outspoken advocate of the advantages and superiority of duodecimal over decimal:
The duodecimal tables are easy to master, easier than the decimal ones; and in elementary teaching they would be so much more interesting, since young children would find more fascinating things to do with twelve rods or blocks than with ten. Anyone having these tables at command will do these calculations more than one-and-a-half times as fast in the duodecimal scale as in the decimal. This is my experience; I am certain that even more so it would be the experience of others.—A. C. Aitken, in "The Listener", January 25, 1962
But the final quantitative advantage, in my own experience, is this: in varied and extensive calculations of an ordinary and not unduly complicated kind, carried out over many years, I come to the conclusion that the efficiency of the decimal system might be rated at about 65 or less, if we assign 100 to the duodecimal.—A. C. Aitken, "The Case Against Decimalisation" (Edinburgh / London: Oliver & Boyd, 1962)
In Leo Frankowski's Conrad Stargard novels, Conrad introduces a duodecimal system of arithmetic at the suggestion of a merchant, who is accustomed to buying and selling goods in dozens and grosses, rather than tens or hundreds. He then invents an entire system of weights and measures in base twelve, including a clock with twelve hours in a day, rather than twenty-four hours.
In Lee Carroll's "Kryon: Alchemy of the Human Spirit", a chapter is dedicated to the advantages of the duodecimal system. The duodecimal system is supposedly suggested by Kryon (a fictional entity believed in by New Age circles) for all-round use, aiming at better and more natural representation of nature of the Universe through mathematics. An individual article "Mathematica" by James D. Watt (included in the above publication) exposes a few of the unusual symmetry connections between the duodecimal system and the golden ratio, as well as provides numerous number symmetry-based arguments for the universal nature of the base-12 number system.
Duodecimal metric systems.
Systems of measurement proposed by dozenalists include:
Duodecimal digits on computerized writing systems.
 <br> 
In March 2013, a proposal was submitted to include the digit forms for ten and eleven propagated by the Dozenal Societies of Great Britain and America in the Unicode Standard. Of these, the British forms were accepted for encoding as characters at code points U+218A turned digit two (↊) and U+218B turned digit three (↋). They will be included in the Unicode 8.0 release expected in June 2015.
Also, the turned digits two and three are available in LaTeX as codice_1 and codice_2.

</doc>
<doc id="8401" url="http://en.wikipedia.org/wiki?curid=8401" title="David Hayes Agnew">
David Hayes Agnew

David Hayes Agnew (November 24, 1818 – March 22, 1892) was an American surgeon.
Biography.
Agnew was born on November 24, 1818 in Lancaster County, Pennsylvania. He graduated from the medical department of the University of Pennsylvania in 1838, and a few years later set up in practice at Philadelphia and became a lecturer at the Philadelphia School of Anatomy. He married Margaret Irwin in 1841. He also helped found the Irwin & Agnew Iron Foundry in 1846. 
In 1852, he bought and revived the Philadelphia School of Anatomy, where he continued to work through 1862. 
He was appointed surgeon at the Philadelphia Hospital in 1854 and was the founder of its pathological museum.
For 26 years (1863–1889) he was connected with the medical faculty of the medical school of the University of Pennsylvania, being elected professor of operative surgery in 1870 and professor of the principles and practice of surgery in the following year. From 1865 to 1884—except for a brief interval—he was a surgeon at the Pennsylvania Hospital.
In 1889, he became the subject of the largest painting ever made by the Philadelphia artist Thomas Eakins, called "The Agnew Clinic", in which he is shown conducting a mastectomy operation before a gallery of students and doctors. The artist can also be found to the right of the painting.
During the American Civil War he was consulting surgeon in the Mower Army Hospital, near Philadelphia, and acquired considerable reputation for his operations in cases of gunshot wounds. He attended as operating surgeon when President Garfield was fatally wounded by the bullet of an assassin in 1881.
He was the author of several works, the most important being "The Principles and Practice of Surgery" (1878–1883). 
He died at Philadelphia on March 22, 1892, and is buried in West Laurel Hill Cemetery.

</doc>
<doc id="8402" url="http://en.wikipedia.org/wiki?curid=8402" title="Diving">
Diving

Diving is the sport of jumping or falling into water from a platform or springboard, sometimes while performing acrobatics. Diving is an internationally recognized sport that is part of the Olympic Games. In addition, unstructured and non-competitive diving is a recreational pastime.
Diving is one of the most popular Olympic sports with spectators. Competitors possess many of the same characteristics as gymnasts and dancers, including strength, flexibility, kinaesthetic judgment and air awareness. Some professional divers were originally gymnasts or dancers as both the sports have similar characteristics to diving.
History.
Plunging.
Although diving has been a popular pastime across the world since ancient times, the first modern diving competitions were held in England in the 1880s. The exact origins of the sport are unclear, though it likely derives from the act of diving at the start of swimming races. The 1904 book "Swimming" by Ralph Thomas notes English reports of plunging records dating back to at least 1865. The 1877 edition to "British Rural Sports" by John Henry Walsh makes note of a "Mr. Young" plunging 56 feet in 1870, and also states that 25 years prior, a swimmer named Drake could cover 53 feet.
The English Amateur Swimming Association (at the time called the Swimming Association of Great Britain) first started a "plunging championship" in 1883. The Plunging Championship was discontinued in 1937.
Fancy diving.
Diving into a body of water had also been a method used by gymnasts in Germany and Sweden since the early 19th century. The soft landing allowed for more elaborate gymnastic feats in midair as the jump could be made at a greater distance. This tradition evolved into 'fancy diving', while diving as a preliminary to swimming became known as 'Plain diving'.
In England, the practice of high diving – diving from a great height – gained popularity; the first diving stages were erected at the Highgate Ponds at a height of 15 feet in 1893 and the first world championship event, the National Graceful Diving Competition, was held there by the Royal Life Saving Society in 1895. The event consisted of standing and running dives from either 15 or 30 feet.
It was at this event that the Swedish tradition of fancy diving was introduced to the sport by the athletes Otto Hagborg and C F Mauritzi. They demonstrated their acrobatic techniques from the 10m diving board at Highgate Pond and stimulated the establishment of the Amateur Diving Association in 1901, the first organization devoted to diving in the world (later amalgamated with the Amateur Swimming Association). Fancy diving was formally introduced into the championship in 1903.
Olympic era.
Plain diving was first introduced into the Olympics at the 1904 event. The 1908 Olympics in London added 'fancy diving' and introduced elastic boards rather than fixed platforms. Women were first allowed to participate in the diving events for the 1912 Olympics in Stockholm.
In the 1928 Olympics, 'plain' and 'fancy' diving was amalgamated into one event – 'Highboard Diving'. The diving event was first held indoors in the Empire Pool for the 1934 British Empire Games and 1948 Summer Olympics in London.
Competitive diving.
Most diving competitions consist of three disciplines: 1 m and 3 m springboards, and the platform. Competitive athletes are divided by gender, and often by age group. In platform events, competitors are allowed to perform their dives on either the five, seven and a half (generally just called seven), nine, or ten meter towers. In major diving meets, including the Olympic Games and the World Championships, platform diving is from the 10 meter height.
Divers have to perform a set number of dives according to established requirements, including somersaults and twists. Divers are judged on whether and how well they completed all aspects of the dive, the conformance of their body to the requirements of the dive, and the amount of splash created by their entry to the water. A possible score out of ten is broken down into three points for the takeoff (meaning the hurdle), three for the flight (the actual dive), and three for the entry (how the diver hits the water), with one more available to give the judges flexibility.
The raw score is multiplied by a difficulty factor, derived from the number and combination of movements attempted. The diver with the highest total score after a sequence of dives is declared the winner.
Synchronized diving.
Synchronized diving was adopted as an Olympic sport in 2000. Two divers form a team and perform dives simultaneously. The dives are identical. It used to be possible to dive opposites, also known as a pinwheel, but this is no longer part of competitive synchronized diving. For example, one diver would perform a forward dive and the other an inward dive in the same position, or one would do a reverse and the other a back movement. In these events, the diving would be judged both on the quality of execution and the synchronicity – in timing of take-off and entry, height and forward travel.
Scoring the dive.
There are rules governing the scoring of a dive. Usually a score considers three elements of the dive: the approach, the flight, and the entry. The primary factors affecting the scoring are:
To reduce the subjectivity of scoring in major meets, panels of five or seven judges are assembled. If five judges then the highest and lowest scores are discarded and the middle three are summed and multiplied by the "degree of difficulty" (DD), which is determined from a combination of the moves undertaken, in which position and from what height. In major international events, there are seven judges in which case the highest and lowest scores are again discarded and the middle five are summed, then ratioed by 3⁄5, and multiplied by the DD, so as to provide consistent comparison with 5-judge events. Accordingly, it is extremely difficult for one judge to manipulate scores.
This seven-judge procedure has been modified as of the 2012 London Olympics: rather than eliminating one high and one low award and then reducing the total by 3⁄5 as in previous international events, the two highest awards and the two lowest are disregarded, leaving three to be summed and multiplied by the difficulty rating.
There is a general misconception about scoring and judging. In serious meets, the absolute score is somewhat meaningless. It is the relative score, not the absolute score that wins meets. Accordingly, good judging implies consistent scoring across the dives. Specifically, if a judge consistently gives low scores for all divers, or consistently gives high scores for the same divers, the judging will yield fair relative results and will cause divers to place in the correct order. However, absolute scores have significance to the individual divers. Besides the obvious instances of setting records, absolute scores are also used for rankings and qualifications for higher level meets.
In synchronised diving events, there is a panel of seven, nine, or eleven judges; two or three to mark the execution of one diver, two or three to mark the execution of the other, and the remaining three or five to judge the synchronisation. The execution judges are positioned two on each side of the pool, and they score the diver which is nearer to them. The 2012 London Olympics saw the first use of eleven judges.
The score is computed similarly to the scores from other diving events, but has been modified starting with the 2012 London Olympics for the use of the larger judging panels. Each group of judges will have the highest and lowest scores dropped, leaving the middle score for each diver's execution and the three middle scores for synchronization. The total is then weighted by 3⁄5 and multiplied by the DD. The result is that the emphasis is on the synchronization of the divers.
The synchronisation scores are based on:
The judges may also disqualify the diver for certain violations during the dive, including:
Competitive strategy.
To win dive meets, divers create a dive list in advance of the meet. To win the meet the diver must accumulate more points than other divers. Often, simple dives with low DDs will look good to spectators but will not win meets. The competitive diver will attempt the highest DD dives possible with which they can achieve consistent, high scores. If divers are scoring 8 or 9 on most dives, it may be a sign of their extreme skill, or it may be a sign that their dive list is not competitive, and they may lose the meet to a diver with higher DDs and lower scores.
In competition, divers must submit their lists beforehand, and once past a deadline (usually when the event is announced or shortly before it begins) they cannot change their dives. If they fail to perform the dive announced, even if they physically cannot execute the dive announced or if they perform a more difficult dive, they will receive a score of zero. Under exceptional circumstances, a redive may be granted, but these are exceedingly rare (usually for very young divers just learning how to compete, or if some event outside the diver's control has caused them to be unable to perform-such as a loud noise).
In the Olympics or other highly competitive meets, many divers will have nearly the same list of dives as their competitors. The importance for divers competing at this level is not so much the DD, but how they arrange their list. Once the more difficult rounds of dives begin it is important to lead off with a confident dive to build momentum. They also tend to put a very confident dive in front of a very difficult dive to ensure that they will have a good mentality for the difficult dive. Most divers have pre-dive and post-dive rituals that help them either maintain or regain focus. Coaches also play a role in this aspect of the sport. Many divers rely on their coaches to help keep their composure during the meet. In a large meet coaches are rarely allowed on the deck to talk to their athlete so it is common to see coaches using hand gestures or body movements to communicate.
There are some American meets which will allow changes of the position of the dive even after the dive has been announced immediately before execution, but these are an exception to the rules generally observed internationally.
Generally, NCAA rules allow for dives to be changed while the diver is on the board, but the diver must request the change directly after the dive is announced. This applies especially in cases where the wrong dive is announced. If the diver pauses during his or her hurdle to ask for a change of dive, it will be declared a balk (when the diver stops mid-hurdle) and the change of dive will not be permitted.
Under FINA law, no dive may be changed after the deadline for the dive-sheet to be submitted (generally a period ranging from one hour to 24 hours, depending on the rulings made by the event organiser).
It is the diver's responsibility to ensure that the dive-sheet is filled in correctly, and also to correct the referee or announcer before the dive if they describe it incorrectly. If a dive is performed which is as submitted but not as (incorrectly) announced, it is declared failed and scores zero according to a strict reading of the FINA law. But in practice, a re-dive would usually be granted in these circumstances.
Governance.
The global governing body of diving is FINA, which also governs swimming, synchronized swimming, water polo and open water swimming. Almost invariably, at national level, diving shares a governing body with the other aquatic sports.
This is frequently a source of political friction as the committees are naturally dominated by swimming officials who do not necessarily share or understand the concerns of the diving community. Divers often feel, for example, that they do not get adequate support over issues like the provision of facilities. Other areas of concern are the selection of personnel for the specialised Diving committees and for coaching and officiating at events, and the team selection for international competitions.
There are sometimes attempts to separate the governing body as a means to resolve these frustrations, but they are rarely successful. For example, in the UK the Great Britain Diving Federation was formed in 1992 with the intention of taking over the governance of Diving from the ASA (Amateur Swimming Association). Although it initially received widespread support from the diving community, the FINA requirement that international competitors had to be registered with their National Governing Body was a major factor in the abandonment of this ambition a few years later.
Since FINA refused to rescind recognition of the ASA as the British governing body for all aquatic sports including diving, this meant that the elite divers had to belong to ASA-affiliated clubs to be eligible for selection to international competition.
In the United States scholastic diving is almost always part of the school's swim team. Diving is a separate sport in Olympic and Club Diving. The NCAA will separate diving from swimming in special diving competitions after the swim season is completed.
Safety.
Despite the apparent risk, the statistical incidence of injury in supervised training and competition is extremely low.
The majority of accidents that are classified as 'diving-related' are incidents caused by individuals jumping from structures such as bridges or piers into water of inadequate depth. Many accidents also occur when divers do not account for rocks and logs in the water. Because of this many beaches and pools prohibit diving in shallow waters or when a lifeguard is not on duty.
After an incident in Washington state in 1993, most US and other pool builders are reluctant to equip a residential swimming pool with a diving springboard so home diving pools are much less common these days. In the incident, 14-year-old Shawn Meneely made a "suicide dive" (his hands at his sides – so his head hit the bottom first) in a private swimming pool and became a tetraplegic. The lawyers for the family, Jan Eric Peterson and Fred Zeder, successfully sued the diving board manufacturer, the pool builder, and the National Spa and Pool Institute over the inappropriate depth of the pool.
The NSPI had specified a minimum depth of 7 ft 6 in (2.29 m) which proved to be insufficient in the above case. The pool into which Meneely dived was not constructed to the published standards. The standards had changed after the diving board was installed on the non-compliant pool by the homeowner. But the courts held that the pool "was close enough" to the standards to hold NSPI liable. The multi-million dollar lawsuit was eventually resolved in 2001 for US$6.6 million ($8 million after interest was added) in favor of the plaintiff. The NSPI was held to be liable, and was financially strained by the case. It filed twice for Chapter 11 bankruptcy protection and was successfully reorganized into a new swimming pool industry association.
In competitive diving, FINA takes regulatory steps to ensure that athletes are protected from the inherent dangers of the sport. For example, they impose restrictions according to age on the heights of platforms which divers may compete on.
Group D divers have only recently been allowed to compete on the tower. In the past, the age group could compete only springboard, to discourage children from taking on the greater risks of tower diving. Group D tower was introduced to counteract the phenomenon of coaches pushing young divers to compete in higher age categories, thus putting them at even greater risk.
However, some divers may safely dive in higher age categories to dive on higher platforms. Usually this occurs when advanced Group C divers wish to compete on the 10 m.
Points on pool depths in connection with safety:
Dive groups.
There are six "groups" into which dives are classified: "Forward, Back, Inward, Reverse, Twist," and "Armstand". The latter applies only to Platform competitions, whereas the other five apply to both Springboard and Platform.
Dive positions.
During the flight of the dive, one of four positions is assumed:
These positions are referred to by the letters A, B, C and D respectively.
Additionally, some dives can be started in a flying position. The body is kept straight with the arms extended to the side, and the regular dive position is assumed at about half the dive.
Difficulty is rated according to the Degree of Difficulty of the dives. Some divers may find pike easier in a flip than tuck, and most find straight the easiest in a front/back dive, although it is still rated the most difficult because of the risk of overrotation.
Dive numbers.
In competition, the dives are referred to by a schematic system of three- or four-digit numbers. The letter to indicate the position is appended to the end of the number.
The first digit of the number indicates the dive group as defined above.
For groups 1 to 4, the number consists of three digits and a letter of the alphabet. The third digit represents the number of half-somersaults. The second digit is either 0 or 1, with 0 representing a normal somersault, and 1 signifying a "flying" variation of the basic movement (i.e. the first half somersault is performed in the straight position, and then the pike or tuck shape is assumed). No flying dive has been competed at a high level competition for many years.
For example:
For Group 5, the dive number has 4 digits. The first digit indicates that it is a twisting dive. The second digit indicates the group (1–4) of the underlying movement; the third digit indicates the number of half-somersaults, and the fourth indicates the number of half-twists.
For example:
For Group 6 – Armstand – the dive number has either three or four digits: Three digits for dives without twist and four for dives with twists.
In non-twisting armstand dives, the second digit indicates the direction of rotation (0 = no rotation, 1 = forward, 2 = backward, 3 = reverse, 4 = inward) and the third digit indicates the number of half-somersaults. Inward-rotating armstand dives have never been performed, and are generally regarded as physically impossible.
For example:
For twisting Armstand dives, the dive number again has 4 digits, but rather than beginning with the number 5, the number 6 remains as the first digit, indicating that the "twister" will be performed from an Armstand. The second digit indicates the direction of rotation – as above, the third is the number of half-somersaults, and the fourth is the number of half-twists:
e.g. 6243D – armstand back double-somersault with one and a half twists in the free position
All of these dives come with DD (degree of difficulty) this is an indication of how difficult/complex a dive is. The score that the dive receives is multiplied by the DD (also known as tariff) to give the dive a final score. Before a diver competes they must decide on a "list" this is a number of optional dives and compulsory dives. The optionals come with a DD limit. this means that a diver must select X number of dives and the combined DD limit must be no more than the limit set by the competition/organisation etc.
Until the mid-1990s the tariff was decided by the FINA diving committee, and divers could only select from the range of dives in the published tariff table. Since then, the tariff is calculated by a formula based on various factors such as the number of twist and somersaults, the height, the group etc., and divers are free to submit new combinations. This change was implemented because new dives were being invented too frequently for an annual meeting to accommodate the progress of the sport.
Mechanics of diving.
At the moment of take-off, two critical aspects of the dive are determined, and cannot subsequently be altered during the execution. One is the trajectory of the dive, and the other is the magnitude of the angular momentum.
The speed of rotation – and therefore the total amount of rotation – may be varied from moment to moment by changing the shape of the body, in accordance with the law of conservation of angular momentum.
The center of mass of the diver follows a parabolic path in free-fall under the influence of gravity (ignoring the effects of air resistance, which are negligible at the speeds involved).
Trajectory.
Since the parabola is symmetrical, the travel away from the board as the diver passes it is twice the amount of the forward travel at the peak of the flight. Excessive forward distance to the entry point is penalized when scoring a dive, but obviously an adequate clearance from the diving board is essential on safety grounds.
The greatest possible height that can be achieved is desirable for several reasons:
Control of rotation.
The magnitude of angular momentum remains constant throughout the dive, but since
and the moment of inertia is larger when the body has an increased radius, the speed of rotation may be increased by moving the body into a compact shape, and reduced by opening out into a straight position.
Since the tucked shape is the most compact, it gives the most control over rotational speed, and dives in this position are easier to perform. Dives in the straight position are hardest, since there is almost no scope for altering the speed, so the angular momentum must be created at take-off with a very high degree of accuracy. (A small amount of control is available by moving the position of the arms and by a slight hollowing of the back).
The opening of the body for the entry does not stop the rotation, but merely slows it down. The vertical entry achieved by expert divers is largely an illusion created by starting the entry slightly short of vertical, so that the legs are vertical as they disappear beneath the surface. A small amount of additional tuning is available by 'entry save' techniques, whereby underwater movements of the upper body and arms against the viscosity of the water affect the position of the legs.
Twisting.
Dives with multiple twists and somersaults are some of the most spectacular movements, as well as the most challenging to perform.
The rules state that twisting 'must not be generated manifestly on take-off'. Consequently, divers must use some of the somersaulting angular momentum to generate twisting movements. The physics of twisting can be explained by looking at the components of the angular momentum vector.
As the diver leaves the board, the total angular momentum vector is horizontal, pointing directly to the left for a forward dive for example. For twisting rotation to exist, it is necessary to tilt the body sideways after takeoff, so that there is now a small component of this horizontal angular momentum vector along the body's long axis. The tilt can be seen in the photo.
The tilting is done by the arms, which are outstretched to the sides just before the twist. When one arm is moved up and the other is moved down (like turning a big steering wheel), the body reacts by tilting to the side, which then begins the twisting rotation. At the completion of the required number of twist rotations, the arm motion is reversed (the steering wheel is turned back), which removes the body's tilt and stops the twisting rotation.
An alternative explanation is that the moving arms have precession torque on them which set the body into twisting rotation. Moving the arms back produces opposite torque which stops the twisting rotation.
Entry.
The rules state that the body should be vertical, or nearly so, for entry. Strictly speaking, it is physically impossible to achieve a literally vertical position throughout the entry as there will inevitably still be some rotational momentum while the body is entering the water. Divers therefore attempt to create the illusion of being vertical, especially when performing rapidly rotating multiple somersault movements. One technique is to allow the upper body to enter slightly short of vertical so that the continuing rotation leaves the final impression of the legs entering vertically. Another is to use "entry save" movements of scooping the upper body underwater in the direction of rotation so as to counteract the rotation of the legs.
The arms must be beside the body for feet-first dives, which are typically competed only on the 1m springboard and only at fairly low levels of competition, and extended forwards in line for "head-first" dives, which are much more common competitively. It used to be common for the hands to be interlocked with the fingers extended towards the water, but a different technique has become favoured during the last few decades. Now the usual practice is for one hand to grasp the other with palms down to strike the water with a flat surface. This creates a vacuum between the hands, arms and head which, with a vertical entry, will pull down and under any splash until deep enough to have minimal effect on the surface of the water (the so-called "rip entry").
Once a diver is completely under the water they may choose to roll or scoop in the same direction their dive was rotating to pull their legs into a more vertical position. Apart from aesthetic considerations, it is important from a safety point of view that divers reinforce the habit of rolling in the direction of rotation, especially for forward and inward entries. Especially when diving from the higher levels, attempting to re-surface in the opposite direction can cause hyperextention back injuries.
By country.
United States.
Summer diving.
In the United States, summer diving is usually limited to one meter diving at community or country club pools. Some pools organize to form intra-pool competitions. These competitions are usually designed to accommodate all school-age children. One of the largest and oldest summer leagues in the United States is found in the Northern Virginia area where teams from 47 pools compete against each other every summer. NVSL-Dive annually holds the Wally Martin 3-Meter Championship and concludes the season with its Individual All Stars Championship. In addition, NVSL-Dive annually hosts the largest one-day dive meet in the world, with over 350 developmental divers in NVSL's "Cracker Jack" Invitational! Champions from each of these events have gone on to compete at the collegiate and Olympic levels.
High school diving.
In the United States scholastic diving at the high school level is usually limited to one meter diving (but some schools use three meter springboards.). Scores from those one meter dives contribute to the swim team's overall score. High school diving and swimming concludes their season with a state competition. Depending on the state and the number of athletes competing in the state, certain qualifications must be achieved to compete in the state's championship meet. There are often regional championships and district championships which are necessary to compete in before reaching the state meet to narrow the field to only the most competitive athletes. Most state championship meets consist of eleven dives. The eleven dives are usually split up between two categories: five required (voluntary) dives and six optional dives.
Club diving.
In the United States, pre-college divers interested in three meter or tower diving should consider a club sanctioned by USA Diving or AAU Diving. There is a group called Future Championship. Top club divers are usually called "junior Olympic", or JO divers. JO divers compete for spots on national teams. Divers over the age of 19 years of age cannot compete in these events as a JO diver.
USA Diving sanctions one East-West one and three meter event in the winter time with an Eastern champion and Western champion determined. In the summer USA Diving sanctions a national event with tower competitions offered. USA Diving is sanctioned by the United States Olympic Committee for selecting team representatives for international diving competitions including the Olympic Games.
AAU Diving sanctions one national event per year in the summer. AAU competes on the one, three, and tower to determine the All-American team.
College diving.
In the United States scholastic diving at the college level requires one and three meter diving. Scores from the one and three meter competition contribute to the swim team's overall meet score. College divers interested in tower diving may compete in the NCAA separate from swim team events. NCAA Divisions II and III do not usually compete platform; if a diver wishes to compete platform in college, he or she must attend a Division I school.
Each division also has rules on the number of dives in each competition. Division II schools compete with 10 dives in competition whereas Division III schools compete with 11. Division I schools only compete with 6 dives in competition. These 6 dives consist of either 5 optionals and 1 voluntary, or 6 optionals. If the meet is a 5 optional meet, then the divers will perform 1 optional from each category (Front, Back, Inward, Reverse, and Twister) and then 1 voluntary from the category of their choice. The voluntary in this type of meet is always worth a DD (Degree of Difficulty) of 2.0 even if the real DD is worth more or less on a DD sheet. In a 6 optional meet, the divers will yet again perform one dive from each category, but this time they will perform a 6th optional from the category of their choosing, which is worth its actual DD from the DD sheet.
The highest level of collegiate competition is the NCAA Division 1 Swimming and Diving Championship. Events at the championship include 1 meter springboard, 3 meter springboard, and platform, as well as various swimming individual and relay events. The points scored by swimmers and divers are combined to determine a team swimming & diving champion. To qualify for a diving event at the NCAA championships, a competitor must first finish in the top three at one of five zone championships, which are held after the various conference championship meets. A diver who scores at least 310 points on the 3 meter springboard and 300 points on the 1 meter springboard in a 6 optional meet can participate in the particular zone championship corresponding to the geographic region in which his or her school lies.
A number of colleges and universities offer scholarships to men and women who have competitive diving skills. These scholarships are usually offered to divers with age-group or club diving experience.
The NCAA limits the number of years a college student can represent any school in competitions. The limit is four years, but could be less under certain circumstances.
Masters' Diving.
Divers who continue diving past their college years can compete in Masters' Diving programs. Masters' diving programs are frequently offered by college or club programs.
Masters' Diving events are normally conducted in age-groups of 5 or 10 years, and attract competitors of a wide range of ages and experience (many, indeed, are newcomers to the sport); the oldest competitor in a Masters' Diving Championship was Viola Krahn, who at the age of 101 was the first person in any sport, male or female, anywhere in the world, to compete in an age-group of 100+ years in a nationally organized competition.
Britain.
In Britain, diving competitions on all boards run throughout the year. National Masters' Championships are held two or three times per year.
Republic of Ireland.
In the Republic of Ireland facilities are limited to one pool at the National Aquatic Centre in Dublin. runs out of this facility.
National Championships.
National Championships take place late in the year, usually during November. The competition is held at the National Aquatic Centre in Dublin and consists of four events:
Canada.
In Canada, elite competitive diving is regulated by DPC (Diving Plongeon Canada), although the individual provinces also have organizational bodies. The main competitive season runs from February to July, although some competitions may be held in January or December, and many divers (particularly international level athletes) will train and compete year round.
Most provincial level competitions consist of events for 6 age groups (Groups A, B, C, D, E, and Open) for both genders on each of the three board levels. These age groups roughly correspond to those standardized by FINA, with the addition of a youngest age group for divers 9 and younger, Group E, which does not compete nationally and does not have a tower event (although divers of this age may choose to compete in Group D). The age group Open is so called because divers of any age, including those over 18, may compete in these events, so long as their dives meet a minimum standard of difficulty.
Although Canada is internationally a fairly strong country in diving, the vast majority of Canadian high schools and universities do not have diving teams, and many Canadian divers accept athletic scholarships from American colleges.
Adult divers who are not competitive at an elite level may compete in masters diving. Typically, masters are either adults who never practiced the sport as children or teenagers, or former elite athletes who have retired but still seek a way to be involved in the sport. Many diving clubs have masters teams in addition to their primary competitive ones, and while some masters dive only for fun and fitness, there are also masters competitions, which range from the local to world championship level.
National Championships.
Divers can qualify to compete at the age group national championships, or junior national championships, in their age groups as assigned by FINA up to the age of 18. This competition is held annually in July. Qualification is based on achieving minimum scores at earlier competitions in the season, although athletes who place very highly at a national championship will be automatically qualified to compete at the next. Divers must qualify at two different competitions, at least one of which must be a level 1 competition, i.e. a competition with fairly strict judging patterns. Such competitions include the Polar Bear Invitational in Winnipeg, the Sting in Victoria, and the Alberta Provincial Championships in Edmonton or Calgary. The qualifying scores are determined by DPC according to the results of the preceding year's national competition, and typically do not have much variation from year to year.
Divers older than 18, or advanced divers of younger ages, can qualify for the senior national championships, which are held twice each year, once roughly in March and once in June or July. Once again, qualification is based on achieving minimum scores at earlier competitions (in this case, within the 12 months preceding the national championships, and in an Open age group event), or high placements in previous national championships or international competitions. It is no longer the case that divers may use results from age group events to qualify for senior nationals, or results from Open events to qualify for age group nationals.
Non-competitive diving.
Diving is also popular as a non-competitive activity. Such diving usually emphasizes the airborne experience, and the height of the dive, but does not emphasize what goes on once the diver enters the water. The ability to dive underwater can be a useful emergency skill, and is an important part of watersport and navy safety training. Entering water from a height is an enjoyable leisure activity, as is underwater swimming.
Such non-competitive diving can occur indoors and outdoors. Outdoor diving typically takes place from cliffs or other rock formations either into fresh or salt water. However, man-made diving platforms are sometimes constructed in popular swimming destinations. Outdoor diving requires knowledge of the water depth and currents as conditions can be dangerous.
High Diving.
A recently developing section of the sport is "High Diving" (e.g. see 2013 World Aquatics Championships), conducted in open air locations, usually from improvised platforms up to 27 m high (as compared with 10 m as used in Olympic and World Championship events). Entry to the water is invariably feet-first to avoid the risk of injury that would be involved in head-first entry from that height. The final half-somersault is almost always performed backwards, enabling the diver to spot the entry point and control their rotation.

</doc>
<doc id="8406" url="http://en.wikipedia.org/wiki?curid=8406" title="Dative case">
Dative case

The dative case (abbreviated dat, or sometimes d when it is a core argument) is a grammatical case generally used to indicate the noun to which something is given, as in "Nate Egan gave Drew Majors a drink". Here, Drew Majors is an indirect dative.
In general, the dative marks the indirect object of a verb, although in some instances, the dative is used for the direct object of a verb pertaining directly to an act of giving something. This may be a tangible object (e.g., "a book" or "a tapestry"), or an intangible abstraction (e.g., "an answer" or "help").
Sometimes the dative has functions unrelated to giving. In Scottish Gaelic and Irish, the term "dative case" is misleadingly used in traditional grammars to refer to the prepositional case-marking of nouns following simple prepositions and the definite article. In Georgian, the dative case also marks the subject of the sentence with some verbs and some tenses. This is called the dative construction.
The dative was common among early Indo-European languages and has survived to the present in the Balto-Slavic branch and the Germanic branch, among others. It also exists in similar forms in several non-Indo-European languages, such as the Uralic family of languages, and Altaic languages. In some languages, the dative case has assimilated the functions of other now-extinct cases. In Ancient Greek, the dative has the functions of the Proto-Indo-European locative and instrumental as well as those of the original dative.
Under the influence of English, which uses the preposition "to" for both indirect objects ("give to") and directions of movement ("go to"), the term "dative" has sometimes been used to describe cases that in other languages would more appropriately be called lative.
Etymology.
"Dative" comes from Latin "cāsus datīvus" ("case for giving"), a translation of Greek δοτικὴ πτῶσις, "dotikē ptôsis" ("inflection for giving"), from its use with the verb "didónai" "to give". Dionysius Thrax in his Art of Grammar also refers to it as "epistaltikḗ" "for sending (a letter)", from the verb "epistéllō" "send to", a word from the same root as epistle.
English.
The Old English language, current until approximately sometime after the time of the Norman Conquest in 1066, had a dative case; however, the English case system gradually fell into disuse during the Middle English period, when in pronouns, the accusative and dative merged into a single oblique case that was also used for all prepositions. This conflation of case in Middle and Modern English has led most modern grammarians to discard the "accusative" and "dative" labels as obsolete, often using the term "objective" for oblique.
Set expressions.
While the dative case is no longer very common in modern English usage, it survives in a few set expressions. One good example is the word "methinks", with the meaning "it seems to me". It survives in this fixed form from the days of Old English (having undergone, however, phonetic changes with the rest of the language), in which it was constructed as "[it]" + "me" (the dative case of the personal pronoun) + "thinks" (i.e., "seems", < Old English thyncan, "to seem", a verb closely related to the verb thencan, "to think", but distinct from it in Old English; later it merged with "think" and lost this meaning).
The dative case also survives, albeit rarely, in the ethic dative, used to express one's interest in a matter. This only occurs with pronouns. For instance, in the phrase, "cry me a river," "me" is used not only to express the recipient of the action but the form is used sarcastically in American English to express the speaker's disinterest in the action.
Relic pronouns.
The pronoun whom is a remnant of the dative case in English, descending from the Old English dative pronoun "hwām" (as opposed to the nominative "who", which descends from Old English "hwā") — though "whom" "also" absorbed the functions of the Old English accusative pronoun "hwone". It is also cognate to the word ""wem" (the dative form of "wer"") in German. The OED defines all classical uses of the word "whom" in situations where the indirect object "is not known" – in effect, indicating the anonymity of the indirect object.
Likewise, some of the object forms of personal pronouns are remnants of Old English datives. For example, "him" goes back to the Old English dative "him" (accusative was "hine"), and "her" goes back to the dative "hire" (accusative was "hīe"). These pronouns are not proper datives anymore in modern English, because they are also used for functions of the accusative.
Modern English.
In Modern English, an indirect object is often expressed with a prepositional phrase of "to" or "for". If there is a direct object, the indirect object can be expressed by being placed between the verb and the direct object. For example, "He gave that to me" and "He built a snowman for me" are the same as "He gave me that" and "He built me a snowman". Here, the object pronoun "me" has the same function as a dative pronoun in a language that distinguishes accusative and dative cases.
German.
In general, the dative is used to mark the indirect object of a German sentence. For example:
In English, the first sentence may be rendered: "I sent "the man" the book." The indirect object here is marked by standing in front of the direct object. The normal word order in German is also to put the dative in front of the accusative (as in the example above). However, since the German dative is marked in form, it can also be put "after" the accusative: "Ich schickte das Buch dem Mann(e)".
Certain German prepositions require the dative: "aus", "außer", "bei", "entgegen", "mit", "nach", "seit", "von", "zu", and "gegenüber". Other prepositions ("an", "auf", "hinter", "in", "neben", "über", "unter", "vor", and "zwischen") may be used with dative (indicating current location), or accusative (indicating direction toward something). "Das Buch liegt auf dem Tisch(e)" (dative: the book is lying on the table), but "Ich lege das Buch auf den Tisch" (accusative: I put the book onto the table).
In addition the four prepositions "wegen" ("because of"), "trotz" ("in spite of"), "[an]statt" ("in place of") and "während" ("during"), which require the genitive in modern formal language, are most commonly used with the dative in colloquial German. For example, "because of the weather" is expressed as "wegen dem Wetter" instead of the formally correct "wegen des Wetters". Other prepositions requiring the genitive in formal language, are combined with "von" ("of") in colloquial style, e.g. "außerhalb vom Garten" instead of "außerhalb des Gartens" ("outside the garden").
Note that the concept of an indirect object may be rendered by a prepositional phrase. In this case, the noun's or pronoun's case is determined by the preposition, NOT by its function in the sentence. Consider this sentence: 
Here, the subject, "Ich", is in the nominative case, the direct object, "das Buch", is in the accusative case, and "zum Verleger" is in the dative case, since "zu" always requires the dative ("zum" is a contraction of "zu" + "dem"). However:
In this sentence, "Freund" is the indirect object, but, because it follows "an" (direction), the accusative is required, not the dative.
All of the articles change in the dative case.
Some German verbs require the dative for their direct objects. Common examples include "folgen", "helfen", and "antworten". In each case, the direct object of the verb is rendered in dative. For example:
These verbs cannot be used in normal passive constructions, because German allows these only for verbs with accusative objects. It is therefore ungrammatical to say: *"Ich werde geholfen." "I am helped." Instead a special construction called "impersonal passive" must be used: "Mir wird geholfen", literally: "To me is helped." A colloquial (non-standard) and rarely used way to form the passive voice for dative verbs is the following: "Ich kriege geholfen", or: "Ich bekomme geholfen", literally: "I get helped". The use of the verb "to get" here reminds us that the dative case has something to do with giving and receiving. In German, help is not something you "perform on" somebody, but rather something you "offer" them.
The dative case is also used with reflexive ("sich") verbs when specifying what part of the self the verb is being done to:
Cf. the respective "accord in French: "Les enfants se sont lavés" ("the children have washed themselves") vs. "Les enfants se sont lavé" [uninflected] "les mains" ("... their hands").
German can use two datives to make sentences like: "Sei mir meinem Sohn(e) gnädig!" "For my sake, have mercy on my son!" Literally: "Be to me to my son merciful." The first dative "mir" ("to me") expresses the speaker's commiseration (much like the "dativus ethicus" in Latin, see below). The second dative "meinem Sohn(e)" ("to my son") names the actual object of the plea. Mercy is to be given "to" the son "for" or "on behalf of" his mother/father.
Adjective endings also change in the dative case. There are three possible inflection possibilities depending on what precedes the adjective. They most commonly use "weak inflection" when preceeded by a definite article (the), "mixed inflection" after an indefinite article (a/an), and "strong inflection" when a quantity is indicated (many green apples).
Latin.
Except the main case ("Dativus"), there are several other kinds:
Greek.
In addition to its main function as the "Dativus", the dative case has other functions in Classical Greek:
The articles in the Greek dative are
Nouns as well as adjectives receive suffixes. These vary according to the declension.
Slavic languages.
In Russian, the dative case is used to indicate the indirect object of an action (that to which something is given, thrown, read, etc.). In the instance where a person is the goal of motion, dative is used instead of accusative to indicate motion toward. This is usually achieved with the preposition "κ" + destination in dative case; "К врачу", meaning "to the doctor."
Dative is also the necessary case taken by certain prepositions when expressing certain ideas. For instance, when the preposition "по" is used to mean "along," its object is always in dative case, as in "По бокам", meaning "along the sides."
Other Slavic languages apply the dative case (and the other cases) more or less the same way as does Russian, some languages may use the dative in other ways. The following examples are from Polish:
Other kinds of dative case are also used in Serbo-Croatian language: "Dativus finalis" (Titaniku u pomoć "to Titanic's rescue"), "Dativus commodi/incommodi" (Operi svojoj majci suđe "Wash the dishes for your mother"), "Dativus possessivus" (Ovcama je dlaka gusta "Sheep's hair is thick"), "Dativus ethicus" (Шта ми ради Бони? "What is Boni doing? (I am especially interested in what it is)") and Dativus auctoris (Izgleda mi okej "It seems okay to me").
Unusual in other Indo-European branches but common among Slavic languages, endings of nouns and adjectives are different based on grammatical function. Other factors are gender and number. In some cases, the ending may not be obvious, even when those three factors (function, gender, number) are considered. For example, in Polish, 'syn' ("son") and 'ojciec' ("father") are both masculine singular nouns, yet appear as "syn → synowi and "ojciec → ojcu in the dative.
Baltic languages.
Both Lithuanian and Latvian have a distinct dative case in the system of nominal declensions.
Lithuanian nouns preserve Indo-European inflections in the dative case fairly well: (o-stems) vaikas -> sg. vaikui, pl. vaikams; (ā-stems) ranka -> sg. rankai, pl. rankoms; (i-stems) viltis -> sg. vilčiai, pl. viltims; (u-stems) sūnus -> sg. sūnui, pl. sūnums; (consonant stems) vanduo -> sg. vandeniui, pl. vandenims.
Adjectives in the dative case receive pronominal endings (this might be the result of a more recent development): tas geras vaikas -> sg. tam geram vaikui, pl. tiems geriems vaikams.
The dative case in Latvian underwent further simplifications - the original masculine endings of "both" nouns and adjectives have been replaced with pronominal inflections: tas vīrs -> sg. tam vīram, pl. tiem vīriem. Also, the final "s" in all Dative forms has been dropped. The only exception is personal pronouns in the plural: mums (to us), jums (to you). Note that in colloquial Lithuanian the final "s" in the dative is often omitted, as well: time geriem vaikam.
In both Latvian and Lithuanian, the main function of the dative case is to render the indirect object in a sentence: (lt) aš duodu vyrui knygą; (lv) es dodu [duodu] vīram grāmatu - "I am giving a book to the man".
The dative case can also be used with gerundives to indicate an action preceding or simultaneous with the main action in a sentence: (lt) jam įėjus, visi atsistojo - "when he walked in, everybody stood up", lit. "to him having walked in, all stood up"; (lt) jai miegant, visi dirbo - "while she slept, everybody was working", lit. "to her sleeping, all were working".
In modern standard Lithuanian, Dative case is not required by prepositions, although in many dialects it is done frequently: (dial.) iki (+D) šiai dienai, (stand.) iki (+G) šios dienos - "up until this day".
In Latvian, the dative case is taken by several prepositions in the singular and all prepositions in the plural (due to peculiar historical changes): sg. bez (+G) tevis "(without thee)" ~ pl. bez (+D) jums "(without you)"; sg. pa (+A) ceļu "(along the road)" ~ pl. pa (+D) ceļiem "(along the roads)".
Armenian.
In modern Eastern Armenian, the dative is attained by adding any article to the genitive:
"dog" = շուն
GEN > շան "(of the dog; dog's)" with no articles
DAT > շանը or շանն "(to the dog)" with definite articles (-ն if preceding a vowel)
DAT > մի շան "(to a dog)" with indefinite article
DAT > շանս "(to my dog)" with 1st person possessive article
DAT > շանդ "(to your dog)" with 2nd person possessive article
There is a general tendency to view -ին as the standard dative suffix, but only because that is its most productive (and therefore common) form. The suffix -ին as a dative marker is nothing but the standard, most common, genitive suffix -ի accompanied by the definite article -ն. But the dative case encompasses indefinite objects as well, which will not be marked by -ին:
Definite DAT > Ես գիրքը տվեցի տղային: "(I gave the book to the boy)"
Indefinite DAT> Ես գիրքը տվեցի մի տղայի: "(I gave the book to a boy)"
The main function of the dative marking in Armenian is to indicate the receiving end of an action, more commonly the indirect object which in English is preceded by the preposition "to". In the use of "giving" verbs like "give, donate, offer, deliver, sell, bring..." the dative marks the recipient. With communicative verbs like "tell, say, advise, explain, ask, answer..." the dative marks the listener. Other verbs whose indirect objects are marked by the dative case in Armenian are "show, reach, look, approach..."
Eastern Armenian also uses the dative case to mark the time of an event, in the same way English uses the preposition "at", as in "Meet me at nine o' clock."
Sanskrit.
The term "dative" is grammatically similar to the Sanskrit word "datta". "Datta" means "gift" or "the act of giving". The dative case is the fourth in the usual procedure in the declension of nouns (chaturthi-vibhakti).
Non-Indo-European languages.
Hungarian.
As with many other languages, the dative case is used in Hungarian to show the indirect object of a verb. For example, "Dánielnek adtam ezt a könyvet" (I gave this book to Dániel).
It has two suffixes, -nak and -nek; the correct is selected by vowel harmony. The personal dative pronouns follow the -nek version: "nekem", "neked", etc.
This case is also used to express "for" in certain circumstances, such as "I bought a gift for Mother".
In possessive constructions the nak/nek endings are also used but this is NOT the dative form (rather, the attributive or possessive case)
Finnish.
Finnish does not have a separate dative case. However, the allative case can fulfill essentially the same role as dative, beyond its primary meaning of directional movement (that is, going somewhere or approaching someone). For example: "He lahjoittivat kaikki rahansa köyhille (They donated all their money to the poor.)
Tsez.
In the Northeast Caucasian languages, such as Tsez, the dative also takes the functions of the lative case in marking the direction of an action. By some linguists, they are still regarded as two separate cases in those languages, although the suffixes are exactly the same for both cases. Other linguists list them separately only for the purpose of separating syntactic cases from locative cases. An example with the ditransitive verb "show" (literally: "make see") is given below:
The dative/lative is also used to indicate possession, as in the example below, because there is no such verb as "to have".
As in the examples above, the dative/lative case usually occurs in combination with another suffix as poss-lative case; this should not be regarded as a separate case, however, as many of the locative cases in Tsez are constructed analytically; hence, they are, in fact, a combination of two case suffixes. See Tsez language#Locative case suffixes for further details.
Verbs of perception or emotion (like "see", "know", "love", "want") also require the logical subject to stand in the dative/lative case. Note that in this example the "pure" dative/lative without its POSS-suffix is used.

</doc>
<doc id="8407" url="http://en.wikipedia.org/wiki?curid=8407" title="Dodecahedron">
Dodecahedron

In geometry, a dodecahedron (Greek δωδεκάεδρον, from δώδεκα "dōdeka" "twelve" + ἕδρα "hédra" "base", "seat" or "face") is any polyhedron with twelve flat faces, but usually a regular dodecahedron is meant, which is one of the five Platonic solids. It is composed of twelve regular pentagonal faces, with three meeting at each vertex, and is represented by the Schläfli symbol {5,3}. It has 20 vertices, 30 edges and 160 diagonals (60 face diagonals, 100 space diagonals). Its dual polyhedron is the icosahedron, with Schläfli symbol {3,5}.
The pyritohedron is an irregular pentagonal dodecahedron, having the same topology as the regular one but pyritohedral symmetry. The rhombic dodecahedron has octahedral symmetry. There are a large number of other dodecahedra.
Regular dodecahedron.
Dimensions.
If the edge length of a regular dodecahedron is "a", the radius of a circumscribed sphere (one that touches the dodecahedron at all vertices) is
and the radius of an inscribed sphere (tangent to each of the dodecahedron's faces) is
while the midradius, which touches the middle of each edge, is
These quantities may also be expressed as
where "φ" is the golden ratio.
Note that, given a regular pentagonal dodecahedron of edge length one, "ru" is the radius of a circumscribing sphere about a cube of edge length "φ", and "ri" is the apothem of a regular pentagon of edge length "φ".
Area and volume.
The surface area "A" and the volume "V" of a regular dodecahedron of edge length "a" are:
Two-dimensional symmetry projections.
The "dodecahedron " has two special orthogonal projections, centered, on vertices and pentagonal faces, correspond to the A2 and H2 Coxeter planes.
In perspective projection, viewed above a pentagonal face, the dodecahedron can be seen as a linear-edged schlegel diagram, or stereographic projection as a spherical polyhedron. These projections are also used in showing the four-dimensional 120-cell, a regular 4-dimensional polytope, constructed from 120 dodecahedra, projecting it down to 3-dimensions.
Spherical tiling.
The dodecahedron can also be represented as a spherical tiling.
Cartesian coordinates.
The following Cartesian coordinates define the vertices of a dodecahedron centered at the origin and suitably scaled and oriented:
where is the golden ratio (also written "τ") ≈ 1.618. The edge length is . The containing sphere has a radius of √3.
Space filling with cube and bilunabirotunda.
Regular dodecahedra fill the space with cubes and bilunabirotundae, Johnson solid 91, in the ratio of 1 to 1 to 3. The dodecahedra alone make a lattice of edge-to-edge pyritohedra. The bilunabirotundae fill the rhombic gaps. Each cube meets six bilunabirotundae in three orientations.
Geometric relations.
The "regular dodecahedron" is the third in an infinite set of truncated trapezohedra which can be constructed by truncating the two axial vertices of a pentagonal trapezohedron.
The stellations of the dodecahedron make up three of the four Kepler–Poinsot polyhedra.
A rectified dodecahedron forms an icosidodecahedron.
The regular dodecahedron has icosahedral symmetry Ih, Coxeter group [5,3], order 120, with an abstract group structure of "A"5 × "Z"2.
Icosahedron vis-à-vis dodecahedron.
When a dodecahedron is inscribed in a sphere, it occupies more of the sphere's volume (66.49%) than an icosahedron inscribed in the same sphere (60.54%).
A regular dodecahedron with edge length 1 has more than three and a half times the volume of an icosahedron with the same length edges (7.663... compared with 2.181...), which ratio is approximately 3.51246117975, or in exact terms: (3/5)(3"φ" +1) or (1.8"φ" + .6).
A regular dodecahedron has 12 faces and 20 vertices, whereas a regular icosahedron has 20 faces and 12 vertices. Both have 30 edges.
Nested cube.
A cube can be embedded within a regular dodecahedron, affixed to eight of its equidistant vertices, in five different positions. In fact, five cubes may overlap and interlock inside the dodecahedron to result in the compound of five cubes.
The ratio of the edge of a regular dodecahedron to the edge of a cube embedded inside such a dodecahedron is 1 : "φ", or ("φ" − 1) : 1.
The ratio of a regular dodecahedron's volume to the volume of a cube embedded inside such a dodecahedron is 1 : 2/(2 + "φ"), or (1 + "φ"/2) : 1, or (5+√5) : 4.
For example, an embedded cube with a volume of 64 (and edge length of 4), will nest within a regular dodecahedron of volume 64 + 32"φ" (and edge length of 4"φ" − 4).
Thus, the difference in volume between the encompassing regular dodecahedron and the enclosed cube is always one half the volume of the cube times "φ".
From these ratios are derived simple formulas for the volume of a regular dodecahedron with edge length "a" in terms of the golden mean:
The dodecahedron's golden frame.
Golden ratio rectangles of ratio "φ" + 1 : 1 and "φ" to 1 also fit perfectly within a regular dodecahedron. In proportion to this golden rectangle, an enclosed cube's edge is "φ", when the long length of the rectangle is "φ" + 1 (or "φ"2) and the short length is 1 (the edge shared with the dodecahedron).
In addition, the center of each face of the dodecahedron form three intersecting golden rectangles.
Related polyhedra and tilings.
The regular dodecahedron is topologically related to a series of tilings by vertex figure "n"3.
The dodecahedron can be transformed by a truncation sequence into its dual, the icosahedron:
The regular dodecahedron is a member of a sequence of otherwise non-uniform polyhedra and tilings, composed of pentagons with face configurations (V3.3.3.3."n"). (For "n" > 6, the sequence consists of tilings of the hyperbolic plane.) These face-transitive figures have (n32) rotational symmetry.
Vertex arrangement.
The dodecahedron shares its vertex arrangement with four nonconvex uniform polyhedra and three uniform polyhedron compounds.
Five cubes fit within, with their edges as diagonals of the dodecahedron's faces, and together these make up the regular polyhedral compound of five cubes. Since two tetrahedra can fit on alternate cube vertices, five and ten tetrahedra can also fit in a dodecahedron.
Stellations.
The 3 stellations of the dodecahedron are all regular (nonconvex) polyhedra: (Kepler–Poinsot polyhedra)
Dodecahedral graph.
The skeleton of the dodecahedron (the vertices and edges) form a graph. It is one of 5 Platonic graphs, each a skeleton of its Platonic solid.
This graph can also be constructed as the generalized Petersen graph "G"(10, 2). The high degree of symmetry of the polygon is replicated in the properties of this graph, which is distance-transitive, distance-regular, and symmetric. The automorphism group has order 120. The vertices can be colored with 3 colors, as can the edges, and the diameter is 5.
The dodecahedral graph is Hamiltonian—there is a cycle containing all the vertices. Indeed, this name derives from a mathematical game invented in 1857 by William Rowan Hamilton, the icosian game. The game's object was to find a Hamiltonian cycle along the edges of a dodecahedron.
Pyritohedron.
A pyritohedron is a dodecahedron with pyritohedral (Th) symmetry. Like the regular dodecahedron, it has twelve identical pentagonal faces, with three meeting in each of the 20 vertices. However, the pentagons are not necessarily regular, so the structure normally has no fivefold symmetry axes. Its 30 edges are divided into two sets – containing 24 and 6 edges of the same length.
Although regular dodecahedra do not exist in crystals, the distorted, pyritohedron form occurs in the crystal pyrite, and it may be an inspiration for the discovery of the regular Platonic solid form.
Crystal pyrite.
Its name comes from one of the two common crystal forms of pyrite, the other one being cubical.
Cartesian coordinates.
The coordinates of the eight vertices of the original cube are:
The coordinates of the 12 vertices of the cross-edges are:
where "h" is the height of the wedge-shaped "roof" above the faces of the cube. When "h" = 1, the six cross-edges degenerate to points and a rhombic dodecahedron is formed. When "h" = 0, the cross-edges are absorbed in the facets of the cube, and the pyritohedron reduces to a cube. When "h" = (√5 − 1)/2, the inverse of the golden ratio, the result is a regular dodecahedron.
Geometric freedom.
The pyritohedron has a geometric degree of freedom with limiting cases of a cubic convex hull at one limit of colinear edges, and a rhombic dodecahedron as the other limit as 6 edges are degenerated to length zero. The regular dodecahedron represents a special intermediate case where all edges and angles are equal.
Rhombic dodecahedra.
The rhombic dodecahedron is a zonohedron with twelve rhombic faces and octahedral symmetry. It is dual to the quasiregular cuboctahedron (an Archimedean solid) and occurs in nature as a crystal form. The rhombic dodecahedron packs together to fill space.
The rhombic dodecahedron has several stellations, the first of which is also a spacefiller.
Another important rhombic dodecahedron has twelve faces congruent to those of the rhombic triacontahedron, i.e. the diagonals are in the ratio of the golden ratio. It is also a zonohedron and was described by Bilinski in 1960. This figure is another spacefiller, and can also occur in non-periodic spacefillings along with the rhombic triacontahedron, the rhombic icosahedron and rhombic hexahedra.
Other dodecahedra.
There are 6,384,634 topologically distinct "convex" dodecahedra, excluding mirror images, having at least 8 vertices. (Two polyhedra are "topologically distinct" if they have intrinsically different arrangements of faces and vertices, such that it is impossible to distort one into the other simply by changing the lengths of edges or the angles between edges or faces.)
Topologically distinct dodecahedra include:
History and uses.
Dodecahedral objects have found some practical applications, and have also played a role in the visual arts and in philosophy.
Iamblichus states that Hippasus, a Pythagorean, perished in the sea, because he boasted that he first divulged "the sphere with the twelve pentagons." In "Theaetetus", a dialogue of Plato, Plato was able to prove that there are just five uniform regular solids; they later became known as the platonic solids. Timaeus (c. 360 B.C.), as a personage of Plato's dialogue, associates the other four platonic solids with the four classical elements, adding that there is a fifth solid pattern which, though commonly associated with the dodecahedron, is never directly mentioned as such; "this God used in the delineation of the universe." Aristotle also postulated that the heavens were made of a fifth element, which he called aithêr ("aether" in Latin, "ether" in American English).
Dodecahedra have been used as dice and probably also as divinatory devices. During the hellenistic era, small, hollow bronze Roman dodecahedra were made and have been found in various Roman ruins in Europe. Their purpose is not certain.
In 20th-century art, dodecahedra appear in the work of M.C. Escher, such as his lithographs "Reptiles" (1943) and "Gravitation" (1952). In Salvador Dalí's painting "The Sacrament of the Last Supper" (1955), the room is a hollow dodecahedron.
In modern role-playing games, the dodecahedron is often used as a twelve-sided die, one of the more common polyhedral dice. Some quasicrystals have dodecahedral shape (see figure). Some regular crystals such as garnet and diamond are also said to exhibit "dodecahedral" habit, but this statement actually refers to the rhombic dodecahedron shape.
Immersive Media, a camera manufacturing company, has made the Dodeca 2360 camera, the world's first 360°, full motion camera which captures high-resolution video from every direction simultaneously at more than 100 million pixels per second or 30 frames per second. It is based on dodecahedron.
The popular puzzle game Megaminx is in the shape of a dodecahedron.
In the children's novel "The Phantom Tollbooth", the Dodecahedron appears as a character in the land of Mathematics. Each of his faces wears a different expression—"e.g." happy, angry, sad—which he swivels to the front as required to match his mood.
Dodecahedron is the name of an avant-garde black metal band from Netherlands.
Shape of the universe.
Various models have been proposed for the global geometry of the universe. In addition to the primitive geometries, these proposals include the Poincaré dodecahedral space, a positively curved space consisting of a dodecahedron whose opposite faces correspond (with a small twist). This was proposed by Jean-Pierre Luminet and colleagues in 2003 and an optimal orientation on the sky for the model was estimated in 2008.
In Bertrand Russell's 1954 short story "THE MATHEMATICIAN'S NIGHTMARE: The Vision of Professor Squarepunt," the number 5 said: "I am the number of fingers on a hand. I make pentagons and pentagrams. And but for me dodecahedra could not exist; and, as everyone knows, the universe is a dodecahedron. So, but for me, there could be no universe."

</doc>
<doc id="8408" url="http://en.wikipedia.org/wiki?curid=8408" title="Darwin, Northern Territory">
Darwin, Northern Territory

Darwin 
is the capital city of the Northern Territory, Australia. Situated on the Timor Sea, Darwin is the largest city in the sparsely populated Northern Territory, with a population of 136,245. It is the smallest and most northerly of the Australian capital cities, and acts as the Top End's regional centre. Darwin was originally a pioneer outpost.
Darwin's proximity to South East Asia makes it an important Australian gateway to countries such as Indonesia and East Timor. The Stuart Highway begins in Darwin, ending at Port Augusta in South Australia. The city itself is built on a low bluff overlooking the harbour. Its suburbs spread out over some area, beginning at Lee Point in the north and stretching to Berrimah in the east. Past Berrimah, the Stuart Highway goes on to Darwin's satellite city, Palmerston, and its suburbs. The Darwin region, like the rest of the Top End, has a tropical climate, with a wet and a dry season. The city is noted for its consistently warm to hot climate, all throughout the year. Prone to cyclone activity during the wet season, Darwin experiences heavy monsoonal downpours and spectacular lightning shows. During the dry season, the city is met with blue skies and gentle sea breezes from the picturesque harbour.
The greater Darwin area is the ancestral home of the Larrakia people. On 9 September 1839, sailed into Darwin harbour during its surveying of the area. John Clements Wickham named the region "Port Darwin" in honour of their former shipmate Charles Darwin, who had sailed with them on the ship's previous voyage which had ended in October 1836. The settlement there became the town of Palmerston in 1869, and was renamed Darwin in 1911. Having been almost entirely rebuilt twice, once due to Japanese air raids during World War II, and again after being devastated by Cyclone Tracy in 1974, the city is one of Australia's most modern capitals.
History.
The Aboriginal people of the Larrakia language group are the traditional custodians and the first inhabitants of the greater Darwin area. They had trading routes with Southeast Asia (see Macassan contact with Australia), and imported goods from as far afield as South and Western Australia. Established songlines penetrated throughout the country, allowing stories and histories to be told and retold along the routes.
The Dutch visited Australia's northern coastline in the 1600s, and created the first European maps of the area. This accounts for the Dutch names in the area, such as Arnhem Land and Groote Eylandt. The first British person to see Darwin harbour appears to have been Lieutenant John Lort Stokes of on 9 September 1839. The ship's captain, Commander John Clements Wickham, named the port after Charles Darwin, the British naturalist who had sailed with them both on the earlier second expedition of the "Beagle". In the early 1870s Darwin felt the effects of a gold rush at Pine Creek after employees of the Australian Overland Telegraph Line found gold while digging holes for telegraph poles.
In 1859 the colony of Queensland was excised from New South Wales and initially included the area of the Northern Territory. Four years later in 1863, the Northern Territory was annexed from Queensland by the colony of South Australia. On 5 February 1869, George Goyder, the Surveyor-General of South Australia, established a small settlement of 135 people at Port Darwin. Goyder named the settlement Palmerston, after the British Prime Minister Lord Palmerston. In 1870, the first poles for the Overland Telegraph were erected in Darwin, connecting Australia to the rest of the world. The discovery of gold by employees of the Australian Overland Telegraph Line digging holes for telegraph poles at Pine Creek in the 1880s spawned a gold rush which further boosted the young colony's development.
In early 1875 Darwin's European population had grown to approximately 300 because of the gold rush. On 17 February 1875 the left Darwin "en route" for Adelaide. The approximately 88 passengers and 34 crew (surviving records vary) included government officials, circuit-court judges, Darwin residents taking their first furlough, and miners. While travelling south along the north Queensland coast, the "Gothenburg" encountered a cyclone-strength storm and was wrecked on a section of the Great Barrier Reef. Only 22 men survived, while between 98 and 112 people perished. Many passengers who perished were Darwin residents and news of the tragedy severely affected the small community, which reportedly took several years to recover.
1900 to present.
Darwin became the city's official name in 1911.
The period between 1911 and 1919 was filled with political turmoil, particularly with trade union unrest, which culminated on 17 December 1918. Led by Harold Nelson, some 1000 demonstrators marched to Government House at Liberty Square in Darwin where they burnt an effigy of the Administrator of the Northern Territory John Gilruth and demanded his resignation. The incident became known as the 'Darwin Rebellion'. Their grievances were against the two main Northern Territory employers: Vestey's Meatworks and the federal government. Both Gilruth and the Vestey company left Darwin soon afterwards.
Around 10,000 Australian and other Allied troops arrived in Darwin at the outset of World War II, in order to defend Australia's northern coastline. On 19 February 1942 at 0957, 188 Japanese warplanes attacked Darwin in two waves. It was the same fleet that had bombed Pearl Harbor, though a considerably larger number of bombs were dropped on Darwin than on Pearl Harbor. The attack killed at least 243 people and caused immense damage to the town. These were by far the most serious attacks on Australia in time of war, in terms of fatalities and damage. They were the first of many raids on Darwin.
Despite this major attack, Darwin's development was furthered considerably during the war, with sealed roads constructed connecting the region to Alice Springs in the south and Mount Isa in the south-east, and Manton Dam built in the south to provide the city with water. On Australia Day (26 January) 1959, Darwin was granted city status.
On 25 December 1974, Darwin was struck by Cyclone Tracy, which killed 71 people and destroyed over 70% of the town's buildings, including many old stone buildings such as the Palmerston Town Hall, which could not withstand the lateral forces generated by the strong winds. After the disaster, 30,000 people of a then population of 43,000 were evacuated, in what turned out to be the biggest airlift in Australia's history. The town was subsequently rebuilt with newer materials and techniques during the late 1970s by the Darwin Reconstruction Commission, led by former Brisbane Lord Mayor Clem Jones. A satellite city of Palmerston was built 20 km south of Darwin in the early 1980s.
On 17 September 2003 the Adelaide–Darwin railway was completed, with the opening of the Alice Springs-Darwin standard gauge line.
Geography.
Darwin lies in the Northern Territory, on the Timor Sea. The city proper occupies a low bluff overlooking Darwin Harbour, flanked by Frances Bay to the east and Cullen Bay to the west. The remainder of the city is flat and low-lying, and coastal areas are home to recreational reserves, extensive beaches, and excellent fishing.
Darwin is closer to the capitals of five other countries than to the capital of Australia: Darwin is 3137 km away from Canberra. Dili (East Timor) is 656 km, Port Moresby (Papua New Guinea) is 1818 km, Jakarta (Indonesia) is 2700 km, Bandar Seri Begawan (Brunei) is 2607 km, and Melekeok (Palau) is 2247 km from Darwin.
Even Malaysia and Singapore are only slightly farther away at 3350 km, as is Manila (Philippines) at 3206 km, and Honiara (Solomon Islands) at 3198 km. Ambon, Indonesia, is only 881 km away from Darwin.
Along with its importance as a gateway to Asia, Darwin also acts as an access point for the Kakadu National Park, Arnhem Land, and northerly islands such as Groote Eylandt and the Tiwi Islands. As the largest city in the area, it provides services for these remote settlements.
City and suburbs.
Darwin and its suburbs spread in an approximately triangular shape, with the older south-western suburbs—and the city itself—forming one corner, the newer northern suburbs in another, and the eastern suburbs, progressing towards Palmerston, forming the third.
The older part of Darwin is separated from the newer northern suburbs by Darwin International Airport and Royal Australian Air Force Base. Palmerston is a satellite city 20 km south of Darwin that was established in the 1980s and is one of the fastest growing municipalities in Australia. The rural areas of Darwin including Howard Springs, Humpty Doo and Berry Springs are experiencing strong growth.
Darwin's central business district is bounded by Daly Street in the north-west, McMinn Street in the north-east, Mitchell Street on the south-west and Bennett Street on the south-east. The CBD has been the focus of a number of major projects, including the billion dollar redevelopment of the Stokes Hill wharf waterfront area including a convention centre with seating for 1500 people and approximately 4000 m2 of exhibition space. The development will also include hotels, residential apartments and public space. The city's main industrial areas are along the Stuart Highway going towards Palmerston, centred on Winnellie. The largest shopping precinct in the area is Casuarina Square.
The most expensive residential areas stand along the coast in suburbs such as Larrakeyah and Brinkin, despite the slight risk these low-lying regions face during cyclones and higher tides. The inner northern suburbs of Millner and Coconut Grove and the eastern suburb of Karama are home to lower-income households, although low-income Territory Housing units are scattered throughout the metropolitan area. The suburb of Lyon was an addition to the Northern Suburbs. Development and constructor took place in 2009 and 2010 and became home for a number of affluent Darwin residents and local/recently posted military families above the rank of Sergeant or Flying Officer.
Climate.
Darwin has a tropical savanna climate (Köppen "Aw") with distinct wet and dry seasons and the average maximum temperature is remarkably similar all year round. The dry season runs from about May to September, during which nearly every day is warm and sunny, and afternoon humidity averages around 30%.
There is very little rainfall between May and September. In the coolest months of June and July, the daily minimum temperature may dip as low as 14 °C, but very rarely lower, and a temperature lower than 10 °C has never been recorded in the city centre. Outer suburbs away from the coast however can occasionally record temperatures as low as 5 °C in the dry season. For an exceedingly lengthy 147 day period during the 2012 dry season, from 5 May to 29 September, Darwin recorded no precipitation whatsoever. Prolonged periods of no precipitation are common in the dry season in Northern Australia (particularly in the Northern Territory and northern regions of Western Australia) although a no-rainfall event of this extent is rare. The 3pm dewpoint average in the wet season is at around 24.0 °C.
The highest temperature recorded in Darwin was 40.4 °C on 17 October 1892 at the Darwin Post Office station, while the lowest was 10.4 °C on 29 July 1942 at the Darwin Airport station, which is further from the coast and routinely records cooler temperatures than the post office station which is located in Darwin's CBD. The lowest maximum temperature on record was 18.4 °C on 3 June 1904 while the highest minimum was 30.7 °C on 18 January 1928.
The wet season is associated with tropical cyclones and monsoon rains. The majority of rainfall occurs between December and March (the southern hemisphere summer), when thunderstorms are common and afternoon relative humidity averages over 70 percent during the wettest months. It does not rain every day during the wet season, but most days are warm to hot with plentiful cloud cover; January averages under 6 hours of bright sunshine daily. Darwin's highest Bureau of Meteorology verified daily rainfall total is 367.6 mm, which fell when Cyclone Carlos bore down on the Darwin area on 16 February 2011. February 2011 was also Darwin's wettest month ever recorded, with 1110.2 mm recorded for the month at the airport.
The hottest month is November, just before the onset of the main rain season. Because of its long dry season, Darwin has the most daily average sunshine hours (8.4) of any Australian capital with the most sunshine from April to November. The sun passes directly overhead in mid October and mid February. Climatically Darwin has more in common with Manila than Sydney because it sits well inside the tropical zone.
Darwin occupies one of the most lightning-prone areas in Australia. On 31 January 2002 an early-morning squall line produced over 5,000 cloud-to-ground lightning strikes within a 60 km radius of Darwin alone – about three times the amount of lightning that Perth, Western Australia, experiences on average in an entire year.
Demographics.
In 2006, the largest ancestry groups in Darwin were, Australian (42,221 or 36.9%), English (29,766 or 26%), Irish (9,561 or 8.3%), Scottish (7,815 or 6.8%), Chinese (3,502 or 3%), Greek (2,828 or 2.4%), and Italian (2,367 or 2%)
Darwin's population is notable for the highest proportional population of Aborigines of any Australian capital city. In the 2006 census 10,259 (9.7 per cent) of Darwin's population was Aboriginal.
Darwin's population changed after the Second World War. Darwin, like many other Australian cities, experienced influxes from Europe, with significant numbers of Italians and Greeks during the 1960s and 1970s. Darwin also started to experience an influx from other European countries, which included the Dutch, Germans, and many others. A significant percentage of Darwin's residents are recent immigrants from South East Asia (Asian Australians were 9.3% of Darwin's population in 2001).
Darwin's population comprises people from many ethnic backgrounds. The 2006 Census revealed that the most common places of birth for overseas migrants were the United Kingdom (3.4 per cent), New Zealand (2.1 per cent), the Philippines (1.4 per cent) and East Timor (0.9 per cent). 18.3 percent of the city's population was born overseas, which is less than the Australian average of 22%.
Darwin has a youthful population with an average age of 33 years (compared to the national average of around 37 years) assisted to a large extent by the military presence and the fact that many people opt to retire elsewhere.
The most common languages spoken in Darwin after English are Greek, Italian, Indonesian, Vietnamese and Cantonese.
Religion.
Darwin is essentially a multicultural secular city, however, Christianity has the most adherents in Darwin with 56,613 followers accounting for 49.5 per cent of the population of the city. The largest denominations of Christianity are Roman Catholicism (24,538 or 21.5 per cent), Anglicanism (14,028 or 12.3 per cent) and Greek Orthodox (2,964 or 2.6 per cent). Buddhists, Muslims, Hindus and Jews account for 3.2 per cent of Darwin's population. There were 26,695 or 23.3 per cent of people professing no religion.
Population growth.
Darwin is one of the fastest growing capital cities in Australia, with an annual growth rate of 2.6 per cent since the 2006 census. In recent years, the Palmerston and Litchfield parts of the Darwin statistical division have recorded the highest growth in population of any Northern Territory local government area and by 2016 Litchfield could overtake Palmerston as the second largest municipality in metropolitan Darwin. It is predicted by 2021 that the combined population of both Palmerston and Litchfield would be 101,546 people.
Law and government.
The Darwin City Council (Incorporated under the Northern Territory Local Government Act 1993) governs the City of Darwin which takes in the CBD and the suburbs. The Darwin City Council has governed the City of Darwin since 1957. The Darwin City Council consists of 13 elected members, the Lord Mayor and 12 aldermen.
The City of Darwin electorate is organised into four electoral units or wards. The names of the wards are Chan, Lyons, Richardson, and Waters. The constituents of each ward are directly responsible for electing three aldermen. Constituents of all wards are directly responsible for electing the Lord Mayor of Darwin. The mayor is Katrina Fong Lim after council elections in March 2012.
The rest of the Darwin area is divided into 2 local government areas. One of these is designated as a City, and the second, which is on the city's outer fringe, has the title of Shire. These areas have elected councils which are responsible for functions delegated to them by the Northern Territory Government, such as planning and garbage collection.
The Legislative Assembly of the Northern Territory convenes in Darwin in the Northern Territory Parliament House. Government House, the official residence of the Administrator of the Northern Territory, is located on The Esplanade.
Also located on the Esplanade is the . Darwin has a also which is located on the corner of Cavenagh and Bennett Streets quite close to the Darwin City Council Chambers.
Darwin's police force are members of the Northern Territory Police Force. Darwin's Mitchell Street, with its numerous pubs, clubs and other entertainment venues, is policed by the CitySafe Unit. The CitySafe unit was recently credited with reducing violent crime in and around Darwin City. Darwin has a long record of alcohol abuse and violent crime with 6000 assaults in 2009, of which 350 resulted in broken jaws and noses – more than anywhere else in the world, according to the Royal Darwin Hospital.
Economy.
The two largest economic sectors are mining and tourism. Mining and energy industry production exceeds $2.5 billion per annum. The most important mineral resources are gold, zinc and bauxite, along with manganese and many others. The energy production is mostly off shore with oil and natural gas from the Timor Sea, although there are significant uranium deposits near Darwin. Tourism employs 8% of Darwin residents, and is expected to grow as domestic and international tourists are now spending time in Darwin during the Wet and Dry seasons. Federal spending is a major contributor to the local economy as well.
The military presence that is maintained both within Darwin, and the wider Northern Territory, is a substantial source of employment. The continued involvement of the Australian Army in the stabilisation of East Timor has swelled the military population of Darwin to over 11,000 individuals as of 2001. There is also a substantial United Nations presence in Darwin, since Darwin serves as the staging centre for UN workers and contractors en route to nearby East Timor.
Darwin's importance as a port is expected to grow, due to the increased exploitation of petroleum in the nearby Timor Sea, and to the completion of the railway link and continued expansion in trade with Asia.
During 2005, a number of major construction projects started in Darwin. One is the redevelopment of the Wharf Precinct, which includes a large convention and exhibition centre, apartment housing including Outrigger Pandanas and Evolution on Gardiner, retail and entertainment outlets including a large wave pool and safe swimming lagoon. The Chinatown project has also started with plans to construct multi-level carparks, Chinese-themed retail and dining outlets.
Education.
Education is overseen territory-wide by the Department of Education and Training (DET), whose role is to continually improve education outcomes for all students, with a focus on Indigenous students.
Preschool, primary and secondary.
Darwin is served by a number of public and private schools that cater to local and overseas students. Over 16,500 primary and secondary students are enrolled in schools in Darwin, with 10,524 students attending primary education, and 5,932 students attending secondary education. There are over 12,089 students enrolled in government schools and 2,124 students enrolled in independent schools.
There were 9,764 students attending schools in the City of Darwin area. 6,045 students attended primary schools and 3,719 students attended secondary schools. There are over 7,161 students enrolled in government schools and 1,108 students enrolled in independent schools. There are over 35 primary and pre – schools, and 12 secondary schools including both government and non-government. Most schools in the city are secular, but there are a small number of Christian, Catholic and Lutheran institutions. Students intending to complete their secondary education can work towards either the Northern Territory Certificate of Education or the International Baccalaureate (only offered at Kormilda College). Schools have been restructured into Primary, Middle and High schools since the beginning of 2007.
Tertiary and vocational.
Darwin's largest University is the Charles Darwin University, which is the central provider of tertiary education in the Northern Territory. It covers both vocational and academic courses, acting as both a university and an Institute of TAFE. There are over 5,500 students enrolled in tertiary and further education courses.
Recreation and culture.
Events and festivals.
On 1 July, Territorians celebrate Territory Day. This is the only day of the year, apart from the Chinese New Year, when fireworks are permitted. In Darwin, the main celebrations occur at Mindil Beach, where a large firework display is commissioned by the government.
Weekly markets include Mindil Beach Sunset Markets (Thursdays and Sundays during the dry season), Parap Market, Nightcliff Market and Rapid Creek market. Mindil Beach Sunset Markets are very popular with locals and tourists alike and feature food, souvenirs, clothes and local performing artists.
The Darwin Festival held annually, includes comedy, dance, theatre, music, film and visual art and the NT Indigenous Music Awards. Other festivals include the Glenti, which showcases Darwin's large Greek community, and India@Mindil, a similar festival held by the smaller Indian community. The Chinese New Year is also celebrated with great festivity, highlighting the Asian influence in Darwin.
The Seabreeze festival, which first started in 2005, is held on the second week of May in the suburb of Nightcliff. It offers the opportunity for local talent to be showcased and a popular event is Saturday family festivities along the Nightcliff foreshore which is one of Darwin's most popular fitness tracks.
The Speargrass Festival is held annually the week prior to July's first full moon and celebrates the alternative Top End lifestyle. The festival activities include music, screening of locally produced films, screen printing, basket weaving, sweat lodge, water slides, human pyramid, hot tub, frisbee golf, spear throwing, Kubb competition, bingo, communal organic cooking, morning yoga, meditation, greasy pig and healing circles. The festival occurs at the Speargrass property, 50 km northeast of Pine Creek.
The Darwin beer-can regatta, held in August, celebrates Darwin's love affair with beer and contestants' race boats made exclusively of beer cans. Also in Darwin during the month of August, are the Darwin Cup horse race, and the Rodeo and Mud Crab Tying Competition.
The World Solar Challenge race attracts teams from around the world, most of which are fielded by universities or corporations although some are fielded by high schools. The race has a 20-year history spanning nine races, with the inaugural event taking place in 1987.
Arts and entertainment.
The Darwin Symphony Orchestra was first assembled in 1989, and has performed throughout the Territory. The Darwin Theatre Company is a locally produced professional theatre production company, performing locally and nationally.
The Darwin Entertainment Centre is the city's main concert venue and hosts theatre and orchestral performances. Other theatres include the Darwin Convention Centre, opened in July 2008. The Darwin Convention Centre is part of the $1.1 billion Darwin Waterfront project.
Darwin's only casino opened in 1981 as the Diamond Beach Casino, it later became the MGM Grand Darwin, before it changed to Skycity Darwin after Skycity Entertainment Group purchased the hotel in 2004.
The Northern Territory Museum and Art Gallery (MAGNT) in Darwin gives an overview of the history of the area, including exhibits on Cyclone Tracy and the boats of the Pacific Islands. The MAGNT also organises the annual Telstra National Aboriginal and Torres Strait Islander Art Award, the oldest and most prestigious Indigenous art award in Australia. The MAGNT also manages the Defence of Darwin Experience, a multi-media installation that tells the story of the Japanese air raids on Darwin during World War II.
The Darwin Festival and the Darwin Fringe Festival are annual events. A range of art galleries including specialised Aboriginal art galleries are a feature of Darwin.
Local and visiting musical bands can be heard at venues including the Darwin Entertainment Centre, The Vic Hotel, Happy Yess, and Brown's Mart. A yearly music festival, Bass in the Grass, is very popular with youth from the surrounding area. Artists such as Jessica Mauboy and The Groovesmiths call Darwin home.
There have been no major films set in Darwin; however, some scenes for Australia by Baz Luhrmann and Black Water were both shot in Darwin in 2007
Mitchell Street in the central business district is lined with nightclubs, takeaways, and restaurants. This is the city's entertainment hub. There are several smaller theatres, three cinema complexes (CBD, Casuarina, and Palmerston), and the Deckchair Cinema. This is an open-air cinema which operates through the dry season, from April to October, and screens independent and arthouse films.
Recreation.
The city has many kilometres of wide, unpolluted beaches, including the Casuarina Beach and well renowned Mindil Beach, home of the Mindil Beach markets. Darwin City Council has designated an area of Casuarina Beach as a free beach which offers a designated nudist beach area since 1976.
Swimming in the sea during the months of October–May should be avoided due to the presence of deadly box jellyfish, known locally as stingers.
Saltwater crocodiles are very common in all waterways surrounding Darwin and are even occasionally found swimming in Darwin Harbour and on local beaches.
Fishing is one of the recreations of Darwin locals. Visitors from around the world flock to Darwin aiming to catch the prized barramundi, an iconic fish for the region. The Mary River, Daly River, South and East Alligator River are just a few of the water bodies where the barramundi thrive.
Blue-water fishing is also available off the coast of Darwin; Spanish mackerel, Black Jewfish, queenfish, snapper and other varieties are all found in the area and accessible in a day trip from Darwin. Lake Alexander is a man-made swimming lake which is located at East Point Reserve. It is generally considered crocodile and jellyfish safe, however a freak outbreak of non-deadly jellyfish in 2003 caused its closure for a brief period of time. 
The Darwin Surf Lifesaving Club operates long boats and surf skis and provides events and lifesaving accreditations.
Parks and gardens.
Darwin has extensive parks and gardens. These include the George Brown Darwin Botanic Gardens, East Point Reserve, Casuarina Coastal Reserve, Charles Darwin National Park, Knuckey Lagoons Conservation Reserve, Leanyer Recreation Park, the Nightcliff Foreshore, Bicentennial Park and the Jingili Water Gardens.
Sports.
The Marrara Sports Complex near the airport has stadiums for Aussie Rules (TIO Stadium), cricket, rugby union, basketball (and indoor court sports), soccer, athletics and field hockey. Every two years since 1991 (excluding 2003 due to the SARS outbreak), Darwin has played host to the Arafura Games, a major regional sporting event. In July 2003, the city hosted its first international test cricket match between Australia and Bangladesh, followed by Australia and Sri Lanka in 2004.
Australian-rules football is played all year round. Melbourne's Western Bulldogs Australian Football League side plays one home game at Marrara Oval each year. The ATSIC Aboriginal All-Stars also participate in the AFL pre-season competition. In 2003, a record crowd of 17,500 attended a pre-season game between the All-Stars and Carlton Football Club at Marrara.
Rugby League and Rugby Union club competitions are played in Darwin each year, organised by the NTRL and NTRU respectively. The Heineken Hottest 7s in the World tournament is hosted in Darwin each January, with Rugby Sevens club teams from countries including Australia, New Zealand, Papua New Guinea, Malaysia, and Singapore competing. Darwin's Hottest 7s is the richest Rugby 7s tournament in the Southern Hemisphere.
Darwin hosts a round of the V8 Supercars every year bringing thousands of motorsports fans to the Hidden Valley Raceway. Also located Hidden Valley, adjacent to the road racing circuit, is Darwin's Dirt track racing venue, Northline Speedway. The speedway has hosted a number of Australian Championships over the years for different categories including Sprintcars, Speedcars, and Super Sedans.
The Darwin Cup culminating on the first Monday of August is a very popular horse race event for Darwin and draws large crowds every year to Fannie Bay Racecourse. While it is not as popular as the Melbourne Cup, it does draw a crowd and, in 2003, Sky Racing began televising most of the races. The Darwin Cup day is a public holiday for the Northern Territory (Picnic Day public holiday).
Media.
Darwin's major newspapers are the "Northern Territory News" (Monday – Saturday), "The Sunday Territorian" (Sunday), and the national daily, "The Australian" (Monday–Friday) and "The Weekend Australian" (Saturday), all published by News Limited. Free weekly community newspapers include the "Darwin Sun", the "Litchfield Sun", and "Palmerston Sun"; all published by a News Limited subsidiary.
Five free-to-air channels service Darwin. Commercial television channels are provided by Southern Cross Darwin (Seven Network affiliate), Channel Nine Darwin (formerly branded as Channel 8) and Darwin Digital Television (Network Ten relay), which launched on 28 April 2008. The two Government owned national broadcast services in Darwin are the ABC and SBS. Subscription Television (Pay TV) service Austar is available via cable in the Darwin region.
Darwin has radio stations on both AM and FM frequencies. ABC stations include ABC News Radio (102.5FM), ABC Local Radio (105.7FM), ABC Radio National (657AM), ABC Classic FM (107.3FM) and Triple J (103.3FM). SBS (100.9FM) also broadcasts its national radio network to Darwin.
Darwin has two commercial radio stations Hot 100 and Mix 104.9. Other stations in Darwin include university-based station 104.1 Territory FM, dance music station KIK FM 91.5, Italian-language channel Rete Italia 1611AM, community based stations includes Radio Larrakia 94.5 and Yolngu Radio 1530AM and Rhema FM 97.7.
Infrastructure.
Health.
The Government of the Northern Territory Department of Health and Families oversees one public hospital in the Darwin metropolitan region. The Royal Darwin Hospital, located in Tiwi, is the city's major teaching and referral hospital, and the largest in the Northern Territory.
There is one major private hospital Darwin Private Hospital located at Tiwi, adjacent to the Royal Darwin Hospital.
Transport.
The Territory's services are managed by the Department of Lands and Planning, Public Transport Division. Darwin has a bus network serviced by a range of contracted bus operators, which provides transport to the main suburbs of Darwin.
Darwin has no commuter rail system, however long distance passenger rail services do operate out of the city. The Alice Springs to Darwin rail line was completed in 2003 linking Darwin to Adelaide. The first service ran in 2004. The Ghan passenger train service from Adelaide via Alice Springs and Katherine runs two to three times per week depending on the season.
Darwin International Airport, located in the suburb of Marrara, is Darwin's only airport, which shares its runways with the Royal Australian Air Force's RAAF Base Darwin.
Darwin can be reached via the Stuart Highway which runs the length of the Northern Territory from Darwin through Katherine, Tennant Creek, Alice Springs and on to Adelaide. Other major roads in Darwin include, Tiger Brennan Drive, Amy Johnson Avenue, Dick Ward Drive, Bagot Road, Trower Road and McMillans Road. Bus service in the greater Darwin area is served by Darwinbus.
Ferries leave from Port Darwin to island locations, mainly for tourists. A ferry service to the Tiwi Islands, the "Arafura Pearl" operates from Cullen Bay.
Darwin has a new deepwater port, East Arm Wharf, which opened in 2000. It has 754-meters of wharfline and is capable of handling Panamax-sized ships of a maximum length of 274 meters and a DWT of up to 80,000 tonnes.
Utilities.
Water storage, supply and Power for Darwin is managed by Power and Water Corporation, which is owned by the Government of the Northern Territory. The corporation is also responsible for management of sewage and the major water catchments in the region. Water is mainly stored in the largest dam, The Darwin River Dam which holds up to 90% of Darwin's water supply. For many years, Darwin's principal water supply came from Manton Dam.
Darwin, its suburbs, Palmerston and Katherine are powered by the Channel Island Power Station, The largest power plant in the Northern Territory.
A new power plant, the Weddell Power Station, is near completion. The first two generators came on line in 2008–09. The third generator is due to be completed in 2011–12. When the power station is fully operational, it will add 30% capacity to Darwin's power supply.
Tourism.
Tourism is one of Darwin's largest industries. Tourism is a major industry and employment sector for the Northern Territory.
In 2005/06, 1.38 million people visited the Northern Territory. They stayed for 9.2 million nights and spent over $1.5 billion.
The tourism industry directly employed 8,391 Territorians in June 2006 and when indirect employment is included, tourism typically accounts for more than 14,000 jobs across the Territory.
Darwin is a hub for tours to Kakadu National Park, Litchfield National Park and Katherine Gorge.
The Territory is traditionally divided into the wet and dry, but there are up to six traditional seasons in Darwin.
It is warm and sunny from May to September. Humidity rises during the green season, from October to April bringing thunderstorms and monsoonal rains which rejuvenates the landscape. Tourism is largely seasonal with most tourists visiting during the cooler dry season which runs from April to September.
Aviation history.
Darwin has played host to many of aviation's early pioneers. On 10 December 1919 Captain Ross Smith and his crew landed in Darwin and won a £10,000 Prize from the Australian Government for completing the first flight from London to Australia in under thirty days. Smith and his Crew flew a Vickers Vimy, G-EAOU and landed on an airstrip that has now become Ross Smith Avenue.
Other aviation pioneers include Amy Johnson, Amelia Earhart, Sir Charles Kingsford Smith and Bert Hinkler. The original QANTAS Empire Airways Ltd Hangar, part of the original Darwin Civil Aerodrome in Parap, is now a museum and still bears scars from the bombing of Darwin during World War II.
Darwin was home to Australian and US pilots during the war, with air strips being built in and around Darwin. Today Darwin provides a staging ground for military exercises.
Darwin was a compulsory stop over/check point in the London to Melbourne Centenary Air Race in 1934. The official name of the race was the MacRobertson Air Race. Winners of the great race were Tom Campbell Black and C. W. A. Scott.
The following is an excerpt from "Time" magazine, 29 October 1934, Volume XXIV, Number 18.
 Third Day. Biggest sensation of the race came just before dawn on the third day, when burly Lieutenant Scott and dapper Captain Black flew their scarlet Comet into Darwin. They had covered the last 300 miles over water on one motor, risked death landing on a field made soggy by the first rain in seven months. Said sandy-haired Lieutenant Scott: "We've had a devil of a trip." But they had flown 9000 miles in two days, had broken the England to Australia record of 162 hr. in the unbelievable time of 52hr. 33 min., were only 2000 miles from their goal at Melbourne.
The Australian Aviation Heritage Centre is located approximately 8 km from the City centre on the Stuart Highway and is one of only two places outside the United States where a B52 bomber (on permanent loan from the United States Air Force) is on public display.
US military presence.
On 16 November 2011, Prime Minister Julia Gillard and President Barack Obama announced that the United States would station troops in Australia for the first time since World War II. The agreement between the United States and Australia would involve a contingent of 250 Marines arriving in Darwin in 2012, with the total number rising to a maximum of 2,500 troops by 2017 on six-month rotations as well as a supporting air element including F-22 Raptors, F-35 Joint Strike Fighters and KC-135 refuelers. China and Indonesia have expressed concern about the decision. Some analysts have argued that an expanded U.S. presence could pose a threat to security, a view defence analyst Paul Dibb rejects, noting the deterrent effect of an offshore U.S. military presence in the 1999 East Timorese crisis which dissuaded Indonesia from directly attacking Australian peacekeepers.
Gillard announced that the first 200 U.S. Marines had arrived in Darwin from Hawaii on late 3 April 2012. In 2013, further news of other expansion vectors was aired in USA media, with no comment or confirmation from Australian authorities. The agreement between the two governments remains hidden from public scrutiny. Marine numbers based in Darwin have increased to more than 1150 troops by 2014.
Darwin hosts biennial multi-nation exercises named "Pitch Black"; in 2014 this involved military personnel from Australia, Singapore, Thailand, United Arab Emirates, and the United States.

</doc>
<doc id="8409" url="http://en.wikipedia.org/wiki?curid=8409" title="Dictator">
Dictator

A dictator is a ruler who wields absolute authority. A state ruled by a dictator is called a dictatorship. The word originated as the title of a magistrate in ancient Rome appointed by the Senate to rule the republic in times of emergency (see Roman dictator and "justitium").
Like the term "tyrant" (which was originally a respectable Ancient Greek title), and to a lesser degree "autocrat", "dictator" came to be used almost exclusively as a non-titular term for oppressive, even abusive rule, yet had rare modern titular use.
In modern usage, the term "dictator" is generally used to describe a leader who holds and/or abuses an extraordinary amount of personal power, especially the power to make laws without effective restraint by a legislative assembly. Dictatorships are often characterised by some of the following traits: suspension of elections and of civil liberties; proclamation of a state of emergency; rule by decree; repression of political opponents without abiding by rule of law procedures; these include single-party state, and cult of personality.
The term "dictator" is comparable to#redirect but not synonymous with#redirect the ancient concept of a tyrant; initially "tyrant", like "dictator", did not carry negative connotations. A wide variety of leaders coming to power in a number of different kinds of regimes, such as military juntas, single-party states and civilian governments under personal rule, have been described as dictators. They may hold left or right-wing views, or can even be apolitical.
Roman origin.
In the Roman Republic the term "Dictator" did not have the negative meaning it has later assumed. Rather, a Dictator was a person given sole power (unlike the normal Roman republican practice, where rule was divided between two equal Consuls) for a specific limited period, in order to deal with an emergency. At the end of his term, the Dictator was supposed to hand power over to the normal Consular rule and give account of his actions#redirect and Roman dictators usually did.
The term started to get its modern negative meaning with Cornelius Sulla's ascension to the dictatorship following Sulla's second civil war, making himself the first Dictator in more than a century (during which the office was ostensibly abolished) as well as "de facto" eliminating the time limit and need of senatorial acclamation, although he avoided a major constitutional crisis by resigning the office after about one year due to poor health, dying shortly after. Caesar followed the example in 49 BC and in February 44 BC was proclaimed "Dictator perpetuo", "Dictator in perpetuity", officially doing away with any limitations on his power, which he kept until his assassination the following month.
Garibaldi as a positive dictator.
Still, even in the 19th Century, the term "Dictator" did not always have negative connotations. For example, the Italian revolutionary Garibaldi, during his famous Expedition of the Thousand in 1860, proclaimed himself "Dictator of Sicily", which did not prevent him from being extremely popular in Italian and international public opinion. His usage of the term was clearly derived from the original Roman sense#redirect i.e., a person taking power for a limited time in order to deal with an emergency (in this case, the need to unite Italy) and with the task done Garibaldi handed over power to the government of Victor Emmanuel II of Italy. A few years later, during the Polish January Uprising of 1863, General Romuald Traugutt also bore the title of "Dictator" as an official and positive designation - possibly directly influenced by the then fresh example of Garibaldi.
Garibaldi's case was, however, an exception. In general, the term "dictator" came to be a negative term, not a title used by rulers to call themselves but a term used by the foes of an oppressive ruler. Such was the case with Maximillien Robespierre, whose supporters knew him as "The Incorruptible", while his opponents called him "dictateur sanguinaire", French for "bloodthirsty dictator".
Modern era.
In popular usage in western nations, "dictatorship" is often associated with brutality and oppression. As a result, it is often also used as a term of abuse for political opponents. The term has also come to be associated with megalomania. Many dictators create a cult of personality and have come to favor increasingly grandiloquent titles and honours for themselves. For instance, Idi Amin Dada, who had been a British army lieutenant prior to Uganda's independence from Britain in October 1962, subsequently styled himself as ""His Excellency, President for Life, Field Marshal Al Hadji Doctor[A] Idi Amin Dada, ,[B] , Conqueror of the British Empire in Africa in General and Uganda in Particular"". In the movie "The Great Dictator" (1940), Charlie Chaplin satirized not only Adolf Hitler but the institution of dictatorship itself.
The association between the dictator and the military is a common one; many dictators take great pains to emphasize their connections with the military and often wear military uniforms. In some cases, this is perfectly legitimate; Francisco Franco was a lieutenant general in the Spanish Army before he became Chief of State of Spain; Manuel Noriega was officially commander of the Panamanian Defense Forces. In other cases, the association is mere pretense.
Modern use in formal titles.
Because of the negative associations, modern leaders very rarely (if ever) use the term in their formal titles. In the 19th century, however, official use was more common:
Human rights abuses.
Under the dictatorship of Soviet leader Joseph Stalin, tens of millions of people were executed, starved to death or imprisoned in Gulag forced-labour camps.
Pol Pot became leader of Cambodia in 1975. In all, an estimated 1.7 million people (out of a population of 7 million) died due to the policies of his three-year dictatorship. As a result, Pol Pot is sometimes described as "the Hitler of Cambodia" and "a genocidal tyrant". Hun Sen is widely viewed as a dictator that has assumed authoritarian power in Cambodia using violence and intimation and corruption to maintain his power base. 
The International Criminal Court issued an arrest warrant for Sudan's military dictator Omar al-Bashir over alleged war crimes in Darfur.
Dictators in game theory.
In social choice theory, the notion of a dictator is formally defined as a person who can achieve any feasible social outcome he/she wishes. The formal definition yields an interesting distinction between two different types of dictators.
Note that these definitions disregard some alleged dictators who are not interested in the actual achieving of social goals, as much as in propaganda and controlling public opinion. Monarchs and military dictators are also excluded from these definitions, because their rule relies on the consent of other political powers (the barons or the army).

</doc>
<doc id="8410" url="http://en.wikipedia.org/wiki?curid=8410" title="Decibel">
Decibel

The decibel (dB) is a logarithmic unit used to express the ratio between two values of a physical quantity, often power or intensity. One of these quantities is often a reference value, and in this case the decibel can be used to express the absolute level of the physical quantity, as in the case of sound pressure. The number of decibels is ten times the logarithm to base 10 of the ratio of two power quantities, or of the ratio of the squares of two field amplitude quantities. One decibel is one tenth of one bel, named in honor of Alexander Graham Bell. The bel is seldom used without the "deci-" prefix.
The definition of the decibel is based on the measurement of power in telephony of the early 20th century in the Bell System in the United States. Today, the unit is used for a wide variety of measurements in science and engineering, most prominently in acoustics, electronics, and control theory. In electronics, the gains of amplifiers, attenuation of signals, and signal-to-noise ratios are often expressed in decibels. The decibel confers a number of advantages, such as the ability to conveniently represent very large or small numbers, and the ability to carry out multiplication of ratios by simple addition and subtraction. By contrast, use of the decibel complicates operations of addition and subtraction.
A change in power by a factor of 10 corresponds to a 10 dB change in level. A change in power by a factor of two approximately corresponds to a 3 dB change. A change in voltage by a factor of 10 results in a change in power by a factor of 100 and corresponds to a 20 dB change. A change in voltage ratio by a factor of two approximately corresponds to a 6 dB change.
The decibel symbol is often qualified with a suffix that indicates which reference quantity has been used or some other property of the quantity being measured. For example, dBm indicates a reference power of one milliwatt, while dBu is referenced to approximately 0.775 volts RMS.
In the International System of Quantities, the decibel is defined as a unit of measurement for quantities of type level or level difference, which are defined as the logarithm of the ratio of power- or field-type quantities.
History.
The decibel originates from methods used to quantify signal losses in telephone circuits. These losses were originally measured in units of "Miles of Standard Cable" (MSC), where 1 MSC corresponded to the loss of power over a 1 mile (approximately 1.6 km) length of standard telephone cable at a frequency of 5000 radians per second (795.8 Hz), and roughly matched the smallest attenuation detectable to the average listener. Standard telephone cable was defined as "a cable having uniformly distributed resistance of 88 ohms per loop mile and uniformly distributed shunt capacitance of .054 microfarad per mile" (approximately 19 gauge).
The "transmission unit" (TU) was devised by engineers of the Bell Telephone Laboratories in the 1920s to replace the MSC. 1 TU was defined as ten times the base-10 logarithm of the ratio of measured power to a reference power level.
The definitions were conveniently chosen such that 1 TU approximately equaled 1 MSC (specifically, 1.056 TU = 1 MSC). In 1928, the Bell system renamed the TU the decibel,
being one tenth of a newly defined unit for the base-10 logarithm of the power ratio. It was named the "bel", in honor of their founder and telecommunications pioneer Alexander Graham Bell.
The bel is seldom used, as the decibel was the proposed working unit.
The naming and early definition of the decibel is described in the NBS Standard's Yearbook of 1931:
 Since the earliest days of the telephone, the need for a unit in which to measure the transmission efficiency of telephone facilities has been recognized. The introduction of cable in 1896 afforded a stable basis for a convenient unit and the "mile of standard" cable came into general use shortly thereafter. This unit was employed up to 1923 when a new unit was adopted as being more suitable for modern telephone work. The new transmission unit is widely used among the foreign telephone organizations and recently it was termed the "decibel" at the suggestion of the International Advisory Committee on Long Distance Telephony.
The decibel may be defined by the statement that two amounts of power differ by 1 decibel when they are in the ratio of 100.1 and any two amounts of power differ by N decibels when they are in the ratio of 10N(0.1). The number of transmission units expressing the ratio of any two powers is therefore ten times the common logarithm of that ratio. This method of designating the gain or loss of power in telephone circuits permits direct addition or subtraction of the units expressing the efficiency of different parts of the circuit...
Standards.
In April 2003, the International Committee for Weights and Measures (CIPM) considered a recommendation for the decibel's inclusion in the International System of Units (SI), but decided not to adopt the decibel as an SI unit. However, the decibel is recognized by other international bodies such as the International Electrotechnical Commission (IEC) and International Organization for Standardization (ISO). The IEC permits the use of the decibel with field quantities as well as power and this recommendation is followed by many national standards bodies, such as NIST, which justifies the use of the decibel for voltage ratios. The term "field quantity" is deprecated by ISO, which favors root-power. In spite of their widespread use, suffixes (such as in dBA or dBV) are not recognized by the IEC or ISO.
Definition.
The ISO Standard 80000-3:2006 defines the following quantities. The decibel (dB) is one tenth of the bel (B): 1 B = 10 dB. The bel is (1/2) ln(10) nepers (Np): 1 B = (1/2) ln(10) Np = ln(√10) Np. The neper is the change in the level of a field quantity when the field quantity changes by a factor of e, that is 1 Np = ln(e) = 1 (thereby relating all of the units as nondimensional natural log of field-quantity ratios, 1 dB = 0.11513…, 1 B = 1.1513…). Finally, the level of a quantity is the logarithm of the ratio of the value of that quantity to a reference value of the same quantity.
Therefore, the bel represents the logarithm of a ratio between two power quantities of 10:1, or the logarithm of a ratio between two field quantities of √10:1.
Two signals that differ by one decibel have a power ratio of 101/10 which is approximately 1.25892, and an amplitude (field) ratio of 101/20 (1.12202).
Although permissible, the bel is rarely used with other SI unit prefixes than "deci". It is preferred to use "hundredths of a decibel" rather than "millibels".
The method of calculation of a ratio in decibels depends on whether the measured property is a "power quantity" or a "field quantity"; see Field, power, and root-power quantities for details.
Power quantities.
When referring to measurements of "power" quantities, a ratio can be expressed as a level in decibels by evaluating ten times the base-10 logarithm of the ratio of the measured quantity to the reference level. Thus, the ratio of "P" (measured power) to "P"0 (reference power) is represented by "L""P", that ratio expressed in decibels, which is calculated using the formula:
The base-10 logarithm of the ratio of the two power levels is the number of bels. The number of decibels is ten times the number of bels (equivalently, a decibel is one-tenth of a bel). "P" and "P"0 must measure the same type of quantity, and have the same units before calculating the ratio. If "P" = "P"0 in the above equation, then "L""P" = 0. If "P" is greater than "P"0 then "L""P" is positive; if "P" is less than "P"0 then "L""P" is negative.
Rearranging the above equation gives the following formula for "P" in terms of "P"0 and "L""P":
Field quantities.
When referring to measurements of field quantities, it is usual to consider the ratio of the squares of "F" (measured field) and "F"0 (reference field). This is because in most applications power is proportional to the square of field, and it is desirable for the two decibel formulations to give the same result in such typical cases. Thus, the following definition is used:
The formula may be rearranged to give
Similarly, in electrical circuits, dissipated power is typically proportional to the square of voltage or current when the impedance is held constant. Taking voltage as an example, this leads to the equation:
where "V" is the voltage being measured, "V"0 is a specified reference voltage, and "G"dB is the power gain expressed in decibels. A similar formula holds for current.
The term "root-power quantity" is introduced by ISO Standard 80000-1:2009 as a substitute of "field quantity". The term "field quantity" is deprecated by that standard.
Conversions.
Since logarithm differences measured in these units are used to represent power ratios and field ratios, the values of the ratios represented by each unit are also included in the table.
Examples.
All of these examples yield dimensionless answers in dB because they are relative ratios expressed in decibels. The unit dBW is often used to denote a ratio for which the reference is 1 W, and similarly dBm for a 1 mW reference point.
(31.62 V/1 V)2 ≈ 1 kW/1 W, illustrating the consequence from the definitions above that "G"dB has the same value, 30 dB, regardless of whether it is obtained from powers or from amplitudes, provided that in the specific system being considered power ratios are equal to amplitude ratios squared.
A change in power ratio by a factor of 10 is a change of 10 dB. A change in power ratio by a factor of two is approximately a change of 3 dB. More precisely, the factor is 103/10, or 1.9953, about 0.24% different from exactly 2. Similarly, an increase of 3 dB implies an increase in voltage by a factor of approximately √2, or about 1.41, an increase of 6 dB corresponds to approximately four times the power and twice the voltage, and so on. In exact terms the power ratio is 106/10, or about 3.9811, a relative error of about 0.5%.
Properties.
The decibel has the following properties:
Advantages and disadvantages.
Disadvantages.
According to several articles published in "Electrical Engineering" and the "Journal of the Acoustical Society of America", the decibel suffers from the following disadvantages:
Hickling concludes "Decibels are a useless affectation, which is impeding the development of noise control as an engineering discipline".
Another disadvantage is that quantities in decibels are not necessarily additive, thus being "of unacceptable form for use in dimensional analysis".
For the same reason that decibels excel at multiplicative operations (e.g., antenna gain), they are awkward when dealing with additive operations. Peters (2013, p. 13) provides several examples:
Uses.
Acoustics.
The decibel is commonly used in acoustics as a unit of sound pressure level. The reference pressure in air is set at the typical threshold of perception of an average human and there are common comparisons used to illustrate different levels of sound pressure. Sound pressure is a field quantity, therefore the field version of the unit definition is used:
where "p"ref is the standard reference sound pressure of 20 micropascals in air or 1 micropascal in water.
The human ear has a large dynamic range in audio reception. The ratio of the sound intensity that causes permanent damage during short exposure to the quietest sound that the ear can hear is greater than or equal to 1 trillion (1012). Such large measurement ranges are conveniently expressed in logarithmic scale: the base-10 logarithm of 1012 is 12, which is expressed as a sound pressure level of 120 dB re 20 micropascals. Since the human ear is not equally sensitive to all sound frequencies, noise levels at maximum human sensitivity, somewhere between 2 and 4 kHz, are factored more heavily into some measurements using frequency weighting. (See also Stevens' power law.)
Electronics.
In electronics, the decibel is often used to express power or amplitude ratios (gains), in preference to arithmetic ratios or percentages. One advantage is that the total decibel gain of a series of components (such as amplifiers and attenuators) can be calculated simply by summing the decibel gains of the individual components. Similarly, in telecommunications, decibels denote signal gain or loss from a transmitter to a receiver through some medium (free space, waveguide, coaxial cable, fiber optics, etc.) using a link budget.
The decibel unit can also be combined with a suffix to create an absolute unit of electric power. For example, it can be combined with "m" for "milliwatt" to produce the "dBm". Zero dBm is the level corresponding to one milliwatt, and 1 dBm is one decibel greater (about 1.259 mW).
In professional audio specifications, a popular unit is the dBu. The dBu is a root mean square (RMS) measurement of voltage that uses as its reference approximately 0.775 VRMS. Chosen for historical reasons, the reference value is the voltage level which delivers 1 mW of power in a 600 ohm resistor, which used to be the standard reference impedance in telephone circuits.
Optics.
In an optical link, if a known amount of optical power, in dBm (referenced to 1 mW), is launched into a fiber, and the losses, in dB (decibels), of each electronic component (e.g., connectors, splices, and lengths of fiber) are known, the overall link loss may be quickly calculated by addition and subtraction of decibel quantities.
In spectrometry and optics, the blocking unit used to measure optical density is equivalent to −1 B.
Video and digital imaging.
In connection with video and digital image sensors, decibels generally represent ratios of video voltages or digitized light levels, using 20 log of the ratio, even when the represented optical power is directly proportional to the voltage or level, not to its square, as in a CCD imager where response voltage is linear in intensity.
Thus, a camera signal-to-noise ratio or dynamic range of 40 dB represents a power ratio of 100:1 between signal power and noise power, not 10,000:1.
Sometimes the 20 log ratio definition is applied to electron counts or photon counts directly, which are proportional to intensity without the need to consider whether the voltage response is linear.
However, as mentioned above, the 10 log intensity convention prevails more generally in physical optics, including fiber optics, so the terminology can become murky between the conventions of digital photographic technology and physics. Most commonly, quantities called "dynamic range" or "signal-to-noise" (of the camera) would be specified in 20 log dBs, but in related contexts (e.g. attenuation, gain, intensifier SNR, or rejection ratio) the term should be interpreted cautiously, as confusion of the two units can result in very large misunderstandings of the value.
Photographers also often use an alternative base-2 log unit, the f-stop, and in software contexts these image level ratios, particularly dynamic range, are often loosely referred to by the number of bits needed to represent the quantity, such that 60 dB (digital photographic) is roughly equal to 10 f-stops or 10 bits, since 103 is nearly equal to 210.
Suffixes and reference values.
Suffixes are commonly attached to the basic dB unit in order to indicate the reference value against which the decibel measurement is taken. For example, dBm indicates power measurement relative to 1 milliwatt.
In cases such as this, where the numerical value of the reference is explicitly and exactly stated, the decibel measurement is called an "absolute" measurement, in the sense that the exact value of the measured quantity can be recovered using the formula given earlier. If the numerical value of the reference is not explicitly stated, as in the dB gain of an amplifier, then the decibel measurement is purely relative.
The SI does not permit attaching qualifiers to units, whether as suffix or prefix, other than standard SI prefixes. Therefore, even though the decibel is accepted for use alongside SI units, the practice of attaching a suffix to the basic dB unit, forming compound units such as dBm, dBu, dBA, etc., is not. The proper way, according to the IEC 60027-3, is either as "L""x" (re "x"ref) or as "L""x"/"x"ref, where "x" is the quantity symbol and "x"ref is the value of the reference quantity, e.g., "L""E" (re 1 μV/m) = "L""E"/(1 μV/m) for the electric field strength "E" relative to 1 μV/m reference value.
Outside of documents adhering to SI units, the practice is very common as illustrated by the following examples. There is no general rule, with various discipline-specific practices. Sometimes the suffix is a unit symbol ("W","K","m"), sometimes it is a transliteration of a unit symbol ("uV" instead of μV for microvolt), sometimes it is an acronym for the unit's name ("sm" for square meter, "m" for milliwatt), other times it is a mnemonic for the type of quantity being calculated ("i" for antenna gain with respect to an isotropic antenna, "λ" for anything normalized by the EM wavelength), or otherwise a general attribute or identifier about the nature of the quantity ("A" for A-weighted sound pressure level). The suffix is often connected with a dash (dB-Hz), with a space (dB HL), with no intervening character (dBm), or enclosed in parentheses, dB(sm).
Voltage.
Since the decibel is defined with respect to power, not amplitude, conversions of voltage ratios to decibels must square the amplitude, or use the factor of 20 instead of 10, as discussed above.
dBV
dBu or dBv
dBmV
dBμV or dBuV
Acoustics.
Probably the most common usage of "decibels" in reference to sound level is dB SPL, sound pressure level referenced to the nominal threshold of human hearing: The measures of pressure (a field quantity) use the factor of 20, and the measures of power (e.g. dB SIL and dB SWL) use the factor of 10.
dB SPL
An RMS sound pressure of one pascal corresponds to a level of 94 dB SPL.
dB SIL
dB SWL
dB(A), dB(B), and dB(C)
dB HL or dB hearing level is used in audiograms as a measure of hearing loss. The reference level varies with frequency according to a minimum audibility curve as defined in ANSI and other standards, such that the resulting audiogram shows deviation from what is regarded as 'normal' hearing.
dB Q is sometimes used to denote weighted noise level, commonly using the ITU-R 468 noise weighting
Audio electronics.
dBm
dBFS
dBTP
Radar.
dBZ
dBsm
Antenna measurements.
dBi
dBd
dBiC
dBq
dBsm
dBm−1
Other measurements.
dB-Hz
dBov or dBO
dBr
dBrn
dBrnC
dBK
dB/K
Related units.
Np or cNp
Fractions.
Attenuation constants, in fields such as optical fiber communication and radio propagation path loss, are often expressed as a fraction or ratio to distance of transmission. "dB/m" means decibels per meter, "dB/mi" is decibels per mile, for example. These quantities are to be manipulated obeying the rules of dimensional analysis, e.g., a 100-meter run with a 3.5 dB/km fiber yields a loss of 0.35 dB = 3.5 dB/km × 0.1 km.

</doc>
<doc id="8411" url="http://en.wikipedia.org/wiki?curid=8411" title="Darwinism">
Darwinism

Darwinism is a theory of biological evolution developed by Charles Darwin and others, stating that all species of organisms arise and develop through the natural selection of small, inherited variations that increase the individual's ability to compete, survive, and reproduce. Also called Darwinian theory, it originally included the broad concepts of transmutation of species or of evolution which gained general scientific acceptance when Charles Robert Darwin published "On the Origin of Species", including concepts which predated Darwin's theories, but subsequently referred to specific concepts of natural selection, the Weismann barrier or in genetics the central dogma of molecular biology. Though it usually refers strictly to biological evolution, the term has been used by creationists to refer to the origin of life, and has even been applied to concepts of cosmic evolution, both of which have no connection to Darwin's work. It is therefore considered the belief and acceptance of Darwin's, and his predecessors, work in place of other theories including divine design and extraterrestrial origins.
The term was coined by Thomas Henry Huxley in April 1860, and was used to describe evolutionary concepts in general, including earlier concepts such as Spencerism. Many of the proponents of Darwinism at that time, including Huxley, had reservations about the significance of natural selection, and Darwin himself gave credence to what was later called Lamarckism. The strict neo-Darwinism of August Weismann gained few supporters in the late 19th century. During this period, which has been called "the eclipse of Darwinism", scientists proposed various alternative evolutionary mechanisms which eventually proved untenable. The development of the modern evolutionary synthesis from the 1930s to the 1950s, incorporating natural selection with population genetics and Mendelian genetics, revived Darwinism in an updated form.
While the term has remained in use amongst scientific authors when referring to modern evolutionary theory, it has increasingly been argued that it is an inappropriate term for modern evolutionary theory. For example, Darwin was unfamiliar with the work of Gregor Mendel, and as a result had only a vague and inaccurate understanding of heredity. He naturally had no inkling of yet more recent developments and, like Mendel himself, knew nothing of genetic drift for example. In the United States, the term "Darwinism" is often used by creationists as a pejorative term in reference to beliefs such as atheistic naturalism, but in the United Kingdom the term has no negative connotations, being freely used as a shorthand for the body of theory dealing with evolution, and in particular, evolution by natural selection.
Conceptions of Darwinism.
While the term "Darwinism" had been used previously to refer to the work of Erasmus Darwin in the late 18th century, the term as understood today was introduced when Charles Darwin's 1859 book "On the Origin of Species" was reviewed by Thomas Henry Huxley in the April 1860 issue of the "Westminster Review". Having hailed the book as, "a veritable Whitworth gun in the armoury of liberalism" promoting scientific naturalism over theology, and praising the usefulness of Darwin's ideas while expressing professional reservations about Darwin's gradualism and doubting if it could be proved that natural selection could form new species, Huxley compared Darwin's achievement to that of Copernicus in explaining planetary motion:
 What if the orbit of Darwinism should be a little too circular? What if species should offer residual phenomena, here and there, not explicable by natural selection? Twenty years hence naturalists may be in a position to say whether this is, or is not, the case; but in either event they will owe the author of "The Origin of Species" an immense debt of gratitude... And viewed as a whole, we do not believe that, since the publication of Von Baer's "Researches on Development," thirty years ago, any work has appeared calculated to exert so large an influence, not only on the future of Biology, but in extending the domination of Science over regions of thought into which she has, as yet, hardly penetrated.
Another important evolutionary theorist of the same period was Peter Kropotkin who, in his book "", advocated a conception of Darwinism counter to that of Huxley. His conception was centred around what he saw as the widespread use of co-operation as a survival mechanism in human societies and animals. He used biological and sociological arguments in an attempt to show that the main factor in facilitating evolution is cooperation between individuals in free-associated societies and groups. This was in order to counteract the conception of fierce competition as the core of evolution, which provided a rationalisation for the dominant political, economic and social theories of the time; and the prevalent interpretations of Darwinism, such as those by Huxley, who is targeted as an opponent by Kropotkin. Kropotkin's conception of Darwinism could be summed up by the following quote:
 In the animal world we have seen that the vast majority of species live in societies, and that they find in association the best arms for the struggle for life: understood, of course, in its wide Darwinian sense – not as a struggle for the sheer means of existence, but as a struggle against all natural conditions unfavourable to the species. The animal species, in which individual struggle has been reduced to its narrowest limits, and the practice of mutual aid has attained the greatest development, are invariably the most numerous, the most prosperous, and the most open to further progress. The mutual protection which is obtained in this case, the possibility of attaining old age and of accumulating experience, the higher intellectual development, and the further growth of sociable habits, secure the maintenance of the species, its extension, and its further progressive evolution. The unsociable species, on the contrary, are doomed to decay.
 — Peter Kropotkin, "Mutual Aid: A Factor of Evolution (1902), Conclusion."
19th-century usage.
"Darwinism" soon came to stand for an entire range of evolutionary (and often revolutionary) philosophies about both biology and society. One of the more prominent approaches, summed in the 1864 phrase "survival of the fittest" by the philosopher Herbert Spencer, later became emblematic of Darwinism even though Spencer's own understanding of evolution (as expressed in 1857) was more similar to that of Jean-Baptiste Lamarck than to that of Darwin, and predated the publication of Darwin's theory in 1859. What is now called "Social Darwinism" was, in its day, synonymous with "Darwinism" — the application of Darwinian principles of "struggle" to society, usually in support of anti-philanthropic political agenda. Another interpretation, one notably favoured by Darwin's half-cousin Francis Galton, was that "Darwinism" implied that because natural selection was apparently no longer working on "civilized" people, it was possible for "inferior" strains of people (who would normally be filtered out of the gene pool) to overwhelm the "superior" strains, and voluntary corrective measures would be desirable — the foundation of eugenics.
In Darwin's day there was no rigid definition of the term "Darwinism," and it was used by opponents and proponents of Darwin's biological theory alike to mean whatever they wanted it to in a larger context. The ideas had international influence, and Ernst Haeckel developed what was known as Darwinismus in Germany, although, like Spencer's "evolution", Haeckel's "Darwinism" had only a rough resemblance to the theory of Charles Darwin, and was not centred on natural selection at all. In 1886 Alfred Russel Wallace went on a lecture tour across the United States, starting in New York and going via Boston, Washington, Kansas, Iowa and Nebraska to California, lecturing on what he called "Darwinism" without any problems.
Other uses.
The term "Darwinism" is often used in the United States by promoters of creationism, notably by leading members of the intelligent design movement, as an epithet to attack evolution as though it were an ideology (an "ism") of philosophical naturalism, or atheism. For example, Phillip E. Johnson makes this accusation of atheism with reference to Charles Hodge's book "What Is Darwinism?". However, unlike Johnson, Hodge confined the term to exclude those like Asa Gray who combined Christian faith with support for Darwin's natural selection theory, before answering the question posed in the book's title by concluding: "It is Atheism." Creationists use the term "Darwinism", often pejoratively, to imply that the theory has been held as true only by Darwin and a core group of his followers, whom they cast as dogmatic and inflexible in their belief. In the 2008 movie "" which promotes intelligent design, Ben Stein refers to scientists as Darwinists. Reviewing the film for "Scientific American", John Rennie says "The term is a curious throwback, because in modern biology almost no one relies solely on Darwin's original ideas... Yet the choice of terminology isn't random: Ben Stein wants you to stop thinking of evolution as an actual science supported by verifiable facts and logical arguments and to start thinking of it as a dogmatic, atheistic ideology akin to Marxism." 
However, "Darwinism" is also used neutrally within the scientific community to distinguish modern evolutionary theories, sometimes called "Neo-Darwinism", from those first proposed by Darwin. "Darwinism" also is used neutrally by historians to differentiate his theory from other evolutionary theories current around the same period. For example, "Darwinism" may be used to refer to Darwin's proposed mechanism of natural selection, in comparison to more recent mechanisms such as genetic drift and gene flow. It may also refer specifically to the role of Charles Darwin as opposed to others in the history of evolutionary thought — particularly contrasting Darwin's results with those of earlier theories such as Lamarckism or later ones such as the modern synthesis.
In political discussions in the United States, the term is mostly used by its enemies. "It's a rhetorical device to make evolution seem like a kind of faith, like 'Maoism,'" says Harvard biologist E.O. Wilson. He adds, "Scientists don't call it 'Darwinism'." In the United Kingdom the term often retains its positive sense as a reference to natural selection, and for example Richard Dawkins wrote in his collection of essays "A Devil's Chaplain", published in 2003, that as a scientist he is a Darwinist.
In his 1995 book "Darwinian Fairytales", Australian philosopher David Stove used the term "Darwinism" in a different sense than the above examples. Describing himself as non-religious and as accepting the concept of natural selection as a well-established fact, Stove nonetheless attacked what he described as flawed concepts proposed by some "Ultra-Darwinists". Stove alleged that by using weak or false "ad hoc" reasoning, these Ultra-Darwinists used evolutionary concepts to offer explanations that were not valid (e.g., Stove suggested that sociobiological explanation of altruism as an evolutionary feature was presented in such a way that the argument was effectively immune to any criticism.) Philosopher Simon Blackburn wrote a rejoinder to Stove, though a subsequent essay by Stove's protegee James Franklin's suggested that Blackburn's response actually "confirms Stove's central thesis that Darwinism can 'explain' anything."
References.
</dl>

</doc>
<doc id="8412" url="http://en.wikipedia.org/wiki?curid=8412" title="Doraemon">
Doraemon

Doraemon (Japanese: ドラえもん) is a Japanese manga series written and illustrated by the manga writing team Fujiko Fujio. The series has also been adapted into a successful anime series and media franchise. The story revolves around a robotic cat named Doraemon, who travels back in time from the 22nd century to aid a pre-teen boy named Nobita Nobi (野比のび太, Nobi Nobita).
The Doraemon manga series was first published in December 1969 in six different magazines. A total of 1,345 stories were created in the original series, which are published by Shogakukan under the Tentōmushi (てんとう虫) manga brand, extending to forty-five volumes. The volumes are collected in the Takaoka Central Library in Toyama, Japan, where Fujiko Fujio was born. Turner Broadcasting System bought the rights to the Doraemon anime series in the mid-1980s for a US English-language release, but canceled it without explanation before broadcasting any episodes. In July 2013 it was announced that the manga would be released digitally in English via the Amazon Kindle e-book service. It is one of the best-selling manga in the world, having sold over 100 million copies.
Awards for Doraemon include the Japan Cartoonists Association Award for excellence in 1973, the first Shogakukan Manga Award for children's manga in 1982, and the first Osamu Tezuka Culture Award in 1997. In March 2008 Japan's Foreign Ministry appointed Doraemon as the nation's first "anime ambassador." Ministry spokesman explained the novel decision as an attempt to help people in other countries understand Japanese anime better and to deepen their interest in Japanese culture." The Foreign Ministry action confirms that Doraemon has come to be considered a Japanese cultural icon. In India, its Hindi translation has been telecasted , where the anime version is the highest-rated Kids show, it won the best Kids Show award at the Nickelodeon Kids' Choice Awards India. In 2002 the anime character was acclaimed as an "Asian Hero" in a special feature survey conducted by "Time Asia" magazine. An edited English dub distributed by TV Asahi aired on Disney XD in the United States starting on July 7, 2014 at 12:30 PM, 11:30 AM (Central).
Name.
The name "Doraemon" can be roughly translated to "stray." "Dora" derives from "dora neko" (brazen or stray cat, どら猫), and is a corruption of "nora" (stray). "Emon" 衛門、右衛門 is an archaic component of male given names like Goemon. "Dora" is not derived from "dora" 銅鑼, meaning gong, but rather a pun on that and the fact that Doraemon loves dorayaki. The name "Doraemon" (ドラえもん) is stylized as an unusual mixture of Katakana (ドラ 'dora') and Hiragana (えもん 'emon').
Plot.
Doraemon is sent back in time by a young boy named Sewashi Nobi to improve the circumstances of his grandfather, Nobita, so that his descendants may enjoy a better future. In the original timeline, Nobita experienced nothing but misery and misfortune manifested in the form of very poor grades and bullying throughout his life. This culminates in the burning down of a future business he sets up which leaves his family line beset with financial problems. In order to alter history and better the Nobi family's fortunes, Sewashi initially wanted to send a super-robot to protect Nobita, but with his meager allowance he could only afford an imperfectly-made factory-rejected toy: an anthropomorphic robot cat called Doraemon.
Doraemon has a pocket from which he produces gadgets, medicines, and tools from the future. Some of the gadgets are based on real Japanese household devices with fanciful twists, but most are completely science fiction. Thousands of gadgets have been featured in the series with such as the "bamboo-copter", a small head accessory that allows flight and the "Anywhere Door," a door that opens up to any place the user wishes.
Nobita's closest friend is Shizuka Minamoto, who also serves as his romantic interest. They are tormented by the bully Takeshi Goda, nicknamed "Gian," and the cunning and arrogant Suneo Honekawa. A typical story consists of Doraemon using one of his gadgets in order to assist Nobita in various ways, often causing more trouble than he was trying to solve.
Media.
Manga.
In December 1969 the "Doraemon" manga appeared in six different children's monthly magazines published by Shogakukan. The magazines were aimed at children from nursery school to fourth grade. In 1977 "CoroCoro Comic" was launched as the flagship magazine of "Doraemon."
Since the debut of "Doraemon" in 1969, the stories have been selectively collected into forty-five books published from 1974 to 1996. Shogakukan published a "master works" collection consisting of Twenty volumes between July 24, 2009 and September 25, 2012.
In addition, Doraemon has appeared in a variety of manga series by Shōgakukan. In 2005 Shōgakukan published a series of five more manga volumes under the title "Doraemon+" ("Doraemon Plus"), which were not found in the forty-five Tentōmushi pipi volumes. On December 1, 2014, a sixth volume of "Doraemon Plus" was published. This was the first volume for eight years.
Ten volumes of the series were available in a bi-lingual edition by Shogakukan English Comics.
In July 2013, Fujiko Fujio Productions announced that they would be collaborating with ebook publisher Voyager Japan and localization company AltJapan Co., Ltd. to release an English language version of the "Doraemon" manga in full-color digitally via the Amazon Kindle platform in North America. Shogakukan released the first volume in November 2013. This English version incorporates a variety of changes to character names; Nobita is "Noby," Shizuka is "Sue", Suneo is "Sneech," and Gian is "Big G," while dorayaki is "Yummy Bun/Fudgy Pudgy Pie."
Anime.
Television series.
After a brief and unpopular animated series in 1973 by Nippon Television, "Doraemon" remained fairly exclusive in manga form until 1979 when a newly formed animation studio, Shin-Ei Animation (Now owned by TV Asahi) produced an anime series of "Doraemon." This series became incredibly popular, and ended with 1,787 episodes on March 25, 2005.
Celebrating the anniversary of the franchise, a new "Doraemon" series began airing on TV Asahi on April 15, 2005 with new voice actors and staff, and updated character designs. On May 12, 2014, TV Asahi Corporation announced an agreement with The Walt Disney Company to bring the 2005 series to the Disney XD television channel in the United States beginning in the summer of that year. Besides using the name changes that were used in AltJapan's English adaptation of the original manga, other changes and edits have also been made to make the show more relatable to an American audience, such as Japanese text being replaced with English text on certain objects like signs and graded papers, and items such as yen notes being replaced by US dollar bills. Confirmed cast members of the new American adaptation include veteran anime voice actress Mona Marshall in the title role of Doraemon and Johnny Yong Bosch of "Power Rangers" and "Bleach" fame as Noby. The English dub is produced by Bang Zoom! Entertainment.
Feature films.
In 1980, Toho released the first of a series of annual feature length animated films based on the lengthly special volumes published annually. Unlike the anime and manga (some based on the stories in select volumes), they are more action-adventure oriented and have more of a shōnen demographic, taking the familiar characters of "Doraemon" and placing them in a variety of exotic and perilous settings. Nobita and his friends have visited the age of the dinosaurs, the far reaches of the galaxy, the heart of darkest Africa (where they encountered a race of sentient bipedal dogs), the depths of the ocean, and a world of magic. Some of the films are based on legends such as Atlantis, and on literary works including "Journey to the West" and "Arabian Nights." Some films also have serious themes, especially on environmental topics and the use of technology. Overall, the films have a somewhat darker tone in their stories, unlike the manga and anime.
With the 2013 film, "", Doraemon has surpassed Godzilla in terms of overall ticket sales for a film franchise as Toho's most lucrative movie property. The 33 year series (1980-2013) has sold a combined 100 million tickets vs. the 50 year Godzilla series (1954-2004), which sold a combined 99 million tickets.
Video games.
There are a total of 63 Japanese-only video games ranging from platformer games to RPG games, which began with the Emerson's Arcadia 2001 system. Doraemon can also be seen in Namco's popular "Taiko no Tatsujin" rhythm game series like "Taiko no Tatsujin" (11 - 14 only), ', "Taiko no Tatsujin Wii", "Taiko no Tatsujin Plus", and '. The Chinese version of Microsoft's "3D Movie Maker" contained a Doraemon-themed expansion pack.
Musical.
"Doraemon the Musical: Nobita and the Animal Planet" (舞台版ドラえもん のび太とアニマル惑星(プラネット)｣。, Butaiban Doraemon: Nobita to Animaru Puranetto) was a 2008 musical based on the 1990 anime film . It debuted at Tokyo Metropolitan Art Space on September 4, 2008 running through September 14. Wasabi Mizuta voiced Doraemon.
Reception.
More than 100 million copies of the manga have been sold.
Doraemon was awarded the first Shogakukan Manga Award for children's manga in 1982. In 1997, it was awarded the first Osamu Tezuka Culture Award. In 2008, the Japanese Ministry of Foreign Affairs appointed Doraemon as the first anime cultural ambassador. On 22 April 2002, on the special issue of "Asian Hero" in "TIME Magazine", Doraemon was selected as one of the 22 Asian Heroes. Being the only anime character selected, Doraemon was described as "The Cuddliest Hero in Asia". In 2005, the Taiwan Society of New York selected "Doraemon" as a culturally significant work of Japanese otaku pop-culture in its exhibit "Little Boy: The Arts of Japan's Exploding Subculture", curated by renowned artist Takashi Murakami.
Jason Thompson praised the "silly situations" and "old fashioned, simple artwork", with Doraemon's expression and comments adding to the "surrounding elementary-school mischief".
On September 3, 2012, Doraemon was granted official residence in the city of Kawasaki, one hundred years before he was born.
Legacy.
A Fujiko F Fujio museum opened in Kawasaki on September 3, 2011, featuring Doraemon as the star of the museum.
As one of the oldest, continuously running icons, Doraemon is a recognizable character in this contemporary generation. Nobita, the show's protagonist, is a break from other characters typically portrayed as special or extraordinary, and this portrayal has been seen as reasons of its appeal as well as the contrary: especially in the United States.
ESP Guitars, have made several Doraemon guitars aimed at Children.
In late 2011, Shogakukan and Toyota joined forces to create a series of live-action commercials as part of Toyota's ReBorn ad campaign. The commercials depict the characters nearly 20 years older. Hollywood actor Jean Reno plays Doraemon.
Doraemon has become a prevalent part of popular culture in Japan. Newspapers also regularly make references to Doraemon and his pocket as something with the ability to satisfy all wishes. Other characters in the series are also referenced frequently on TV shows if their cast resembles them.
Doraemon appears in appeals for charity. TV Asahi launched the "Doraemon Fund" charity fund to raise money for natural disasters.
Doraemon, Nobita, and the other characters also appear in various educational manga. Doraemon is also mentioned in several anime and manga by other manga artists.

</doc>
<doc id="8414" url="http://en.wikipedia.org/wiki?curid=8414" title="Dartmoor Preservation Association">
Dartmoor Preservation Association

The Dartmoor Preservation Association (DPA), was founded in 1883. It is a charity which provides an independent viewpoint on the current issues affecting Dartmoor and performs conservation work on archaeological sites. It opposes military training in the Dartmoor National Park, and seeks to preserve and increase public access to the Moor.
Under the chairmanship of Lady Sylvia Sayer the DPA won the battle to halt a massive reservoir in the Swincombe Valley. More recently the author John Bainbridge worked as chief executive and led the campaign which saved Shaugh Moor and the Blackabrook Valley from china clay mining and waste tipping.
In recent years Bainbridge has been highly critical of the dumbing-down and more pro-establishment stance of the DPA.

</doc>
<doc id="8418" url="http://en.wikipedia.org/wiki?curid=8418" title="Dartmouth College">
Dartmouth College

Dartmouth College, commonly referred to as Dartmouth ( ), is a private Ivy League research university located in Hanover, New Hampshire, United States. It consists of a liberal arts college, the Geisel School of Medicine, the Thayer School of Engineering, and the Tuck School of Business, as well as 19 graduate programs in the arts and sciences. Incorporated as the "Trustees of Dartmouth College," it is one of the nine Colonial Colleges founded before the American Revolution. With an undergraduate enrollment of 4,276 and a total student enrollment of 6,342 (as of 2013), Dartmouth is the smallest university in the Ivy League.
Dartmouth College was established in 1769 by Eleazar Wheelock, a Congregational minister. After a long period of financial and political struggles, Dartmouth emerged in the early 20th century from relative obscurity.
Dartmouth's somewhat-isolated rural 269 acre campus is in the Upper Valley region of New Hampshire. Participation in athletics and the school's Greek system is strong. Dartmouth's 34 varsity sports teams compete in the Ivy League conference of the NCAA Division I. Students are well known for preserving a variety of strong campus traditions.
History.
Dartmouth was founded by Eleazar Wheelock, a Puritan minister from Columbia, Connecticut, who had previously sought to establish a school to train Native Americans as missionaries. Wheelock's ostensible inspiration for such an establishment resulted from his relationship with Mohegan Indian Samson Occom. Occom became an ordained minister after studying under Wheelock from 1743 to 1747, and later moved to Long Island to preach to the Montauks.
Wheelock founded Moor's Indian Charity School in 1755. The Charity School proved somewhat successful, but additional funding was necessary to continue school's operations, and Wheelock sought the help of friends to raise money. Occom, accompanied by the Reverend Nathaniel Whitaker, traveled to England in 1766 to raise money from churches. With these funds, they established a trust to help Wheelock. The head of the trust was a Methodist named William Legge, 2nd Earl of Dartmouth.
Although the fund provided Wheelock ample financial support for the Charity School, Wheelock had trouble recruiting Indians to the institution, primarily because its location was far from tribal territories. In seeking to expand the school into a college, Wheelock relocated it to Hanover, in the Province of New Hampshire. The move from Connecticut followed a lengthy and sometimes frustrating effort to find resources and secure a charter. The Royal Governor of New Hampshire, John Wentworth, provided the land upon which Dartmouth would be built and on December 13, 1769, issued the charter in the name of King George III establishing the College. That charter created a college "for the education and instruction of Youth of the Indian Tribes in this Land in reading, writing & all parts of Learning which shall appear necessary and expedient for civilizing & christianizing Children of Pagans as well as in all liberal Arts and Sciences and also of English Youth and any others." The reference to educating Native American youth was included to connect Dartmouth to the Charity School and enable use of the Charity School's unspent trust funds. Named for William Legge, 2nd Earl of Dartmouth—an important supporter of Eleazar Wheelock's earlier efforts but who, in fact, opposed creation of the College and never donated to it—Dartmouth is the nation's ninth oldest college and the last institution of higher learning established under Colonial rule. The College granted its first degrees in 1771.
Given the limited success of the Charity School, however, Wheelock intended his new college as one primarily for whites. Occom, disappointed with Wheelock's departure from the school's original goal of Indian Christianization, went on to form his own community of New England Indians called Brothertown Indians in New York.
In 1819, Dartmouth College was the subject of the historic Dartmouth College case, which challenged New Hampshire's 1816 attempt to amend the college's royal charter to make the school a public university. An institution called Dartmouth University occupied the college buildings and began operating in Hanover in 1817, though the college continued teaching classes in rented rooms nearby. Daniel Webster, an alumnus of the class of 1801, presented the College's case to the Supreme Court, which found the amendment of Dartmouth's charter to be an illegal impairment of a contract by the state and reversed New Hampshire's takeover of the college. Webster concluded his peroration with the famous words: "It is, Sir, as I have said, a small college. And yet there are those who love it."
Dartmouth emerged onto the national academic stage at the turn of the 20th century. Prior to this period, the college had clung to traditional methods of instruction and was relatively poorly funded. Under President William Jewett Tucker (1893–1909), Dartmouth underwent a major revitalization of facilities, faculty, and the student body, following large endowments such as the $10,000 given by Dartmouth alumnus and law professor John Ordronaux. 20 new structures replaced antiquated buildings, while the student body and faculty both expanded threefold. Tucker is often credited for having "refounded Dartmouth" and bringing it into national prestige. Presidents Ernest Fox Nichols (1909–16) and Ernest Martin Hopkins (1916–45) continued Tucker's trend of modernization, further improving campus facilities and introducing selective admissions in the 1920s. John Sloan Dickey, serving as president from 1945 until 1970, strongly emphasized the liberal arts, particularly public policy and international relations.
During World War II, Dartmouth was one of 131 colleges and universities nationally that took part in the V-12 Navy College Training Program which offered students a path to a navy commission.
In 1970, longtime professor of mathematics and computer science John George Kemeny became president of Dartmouth. Kemeny oversaw several major changes at the college. Dartmouth, previously serving as a men's institution, began admitting women as full-time students and undergraduate degree candidates in 1972 amid much controversy. At about the same time, the college adopted its "Dartmouth Plan" of academic scheduling, permitting the student body to increase in size within the existing facilities. In 1988, Dartmouth's alma mater song's lyrics changed from "Men of Dartmouth" to "Dear old Dartmouth".
During the 1990s, the college saw a major academic overhaul under President James O. Freedman and a controversial (and ultimately unsuccessful) 1999 initiative to encourage the school's single-sex Greek houses to go coed. The first decade of the 21st century saw the commencement of the $1.3 billion Campaign for the Dartmouth Experience, the largest capital fundraising campaign in the college's history, which surpassed $1 billion in 2008. The mid- and late first decade of the 21st century have also seen extensive campus construction, with the erection of two new housing complexes, full renovation of two dormitories, and a forthcoming dining hall, life sciences center, and visual arts center. In 2004, Booz Allen Hamilton selected Dartmouth College as a model of institutional endurance "whose record of endurance has had implications and benefits for all American organizations, both academic and commercial," citing "Trustees of Dartmouth College v. Woodward" and Dartmouth's successful self-reinvention in the late 19th century.
Since the election of a number of petition-nominated trustees to the Board of Trustees starting in 2004, the role of alumni in Dartmouth governance has been the subject of ongoing conflict. President James Wright announced his retirement in February 2008 and was replaced by Harvard University professor and physician Jim Yong Kim on July 1, 2009.
In May 2010 Dartmouth joined the Matariki Network of Universities (MNU) together with Durham University (UK), Queen's University (Canada), University of Otago (New Zealand), University of Tübingen (Germany), University of Western Australia (Australia) and Uppsala University (Sweden).
Dartmouth's close association and involvement in the development of the downhill skiing industry is featured in the 2010 book "Passion for Skiing" as well as the 2013 documentary based on the book "Passion for Snow".
Academics, administration, and ranking.
Dartmouth, a liberal arts institution, offers a four-year Bachelor of Arts and ABET-accredited Bachelor of Engineering degree to undergraduate students. The college boasts 39 academic departments offering 56 major programs, while students are free to design special majors or engage in dual majors. In 2008, the most popular majors were economics, government, history, psychological and brain sciences, English, biology, and engineering sciences. The Government Department, whose prominent professors include Stephen Brooks, Richard Ned Lebow, and William Wohlforth, was ranked the top solely undergraduate political science program in the world by researchers at the London School of Economics in 2003. The Economics Department, whose prominent professors include David Blanchflower and Andrew Samwick, also holds the distinction as the top-ranked bachelor's-only economics program in the world.
Dartmouth was ranked 11th among undergraduate programs at national universities by "U.S. News & World Report" in its 2015 rankings. Dartmouth's strength in undergraduate education is highlighted by "U.S. News & World Report" when in 2009, 2010, 2011, 2012,and 2013 it ranked Dartmouth first in undergraduate teaching at national universities. It also ranked first in High School Counselor Rankings in 2012. The college ranks number seven in "The Wall Street Journal"'s ranking of top feeder schools. The 2006 Carnegie Foundation classification listed Dartmouth as the only "majority-undergraduate", "arts-and-sciences focus[ed]", "research university" in the country that also had "some graduate coexistence" and "very high research activity." Internationally, Dartmouth College was ranked 113th in the world in the 2012 QS World University Rankings.
In 2012, 23,110 students applied for approximately 1,100 places, and 9.4% of applicants were admitted. Of those admitted whose high schools reported a class rank, 93.8% were ranked in the top 10% of their high school graduating class, 43.8% were valedictorians, and 12.7% were salutatorians. The mean SAT scores of admitted students by section were 736 for critical reading, 741 for math, and 743 for writing.
Dartmouth meets 100% of students' demonstrated financial need in order to attend the College, and currently admits all students, including internationals, on a need-blind basis. Beginning in the 2008–2009 academic year, Dartmouth instituted a new financial aid policy extending need-blind admission to international students and replaced all student loans with scholarships and grants. Students from families with a combined annual income of less than $75,000 are not charged any tuition. However, in early 2010, the College announced that it would re-introduce loans to its financial aid packages beginning in the 2011–2012 school year due to its changed financial situation.
In order to graduate, a student must complete 35 total courses, eight to ten of which are typically part of a chosen major program. Other requirements for graduation include the completion of ten "distributive requirements" in a variety of academic fields, proficiency in a foreign language, and completion of a writing class and first-year seminar in writing. Many departments offer honors programs requiring students seeking that distinction to engage in "independent, sustained work," culminating in the production of a thesis. In addition to the courses offered in Hanover, Dartmouth offers 57 different off-campus programs, including Foreign Study Programs, Language Study Abroad programs, and Exchange Programs.
Through the Graduate Studies program, Dartmouth grants doctorate and master's degrees in 19 Arts & Sciences graduate programs. Although the first graduate degree, a PhD in classics, was awarded in 1885, many of the current PhD programs have only existed since the 1960s. Furthermore, Dartmouth is home to three professional schools: the Geisel School of Medicine (established 1797), Thayer School of Engineering (1867) — which also serves as the undergraduate department of engineering sciences — and Tuck School of Business (1900). With these professional schools and graduate programs, conventional American usage would accord Dartmouth the label of "Dartmouth University"; however, because of historical and nostalgic reasons (such as "Dartmouth College v. Woodward"), the school uses the name "Dartmouth College" to refer to the entire institution.
Dartmouth employs a total of 607 tenured or tenure-track faculty members, including the highest proportion of female tenured professors among the Ivy League universities. Faculty members have been at the forefront of such major academic developments as the Dartmouth Conferences, the Dartmouth Time Sharing System, Dartmouth BASIC, and Dartmouth ALGOL 30. In 2005, sponsored project awards to Dartmouth faculty research amounted to $169 million.
Dartmouth serves as the host institution of the University Press of New England, a university press founded in 1970 that is supported by a consortium of schools that also includes Brandeis University, the University of New Hampshire, Northeastern University, Tufts University and the University of Vermont.
The Dartmouth Plan.
Dartmouth functions on a quarter system, operating year-round on four ten-week academic terms. The Dartmouth Plan (or simply "D-Plan") is an academic scheduling system that permits the customization of each student's academic year. All undergraduates are required to be in residence for the fall, winter, and spring terms of their freshman and senior years, as well as the summer term of their sophomore year. However, students may petition to alter this plan so that they may be off during Freshman, Senior, or sophomore Summer During all terms, students are permitted to choose between studying on-campus, studying at an off-campus program, or taking a term off for vacation, outside internships, or research projects. The typical course load is three classes per term, and students will generally enroll in classes for 12 total terms over the course of their academic career.
The D-Plan was instituted in the early 1970s at the same time that Dartmouth began accepting female undergraduates. It was initially devised as a plan to increase the enrollment without enlarging campus accommodations, and has been described as "a way to put 4,000 students into 3,000 beds." Although new dormitories have been built since, the number of students has also increased and the D-Plan remains in effect. It was modified in the 1980s in an attempt to reduce the problems of lack of social and academic continuity.
Board of Trustees.
Dartmouth is governed by a Board of Trustees comprising the college president ("ex officio"), the state governor ("ex officio"), 13 trustees nominated and elected by the board (called "charter trustees"), and eight trustees nominated by alumni and elected by the board ("alumni trustees"). The nominees for alumni trustee are determined by a poll of the members of the Association of Alumni of Dartmouth College, selecting from among names put forward by the Alumni Council or by alumni petition.
Although the board elected its members from the two sources of nominees in equal proportions between 1891 and 2007, the board decided in 2007 to add several new members, all charter trustees. In the controversy that followed the decision, the Association of Alumni filed a lawsuit, although it later withdrew the action. In 2008, the Board added five new charter trustees.
Campus.
"This is what a college is supposed to look like."
 — Dwight D. Eisenhower, 1953 
Dartmouth College is situated in the rural town of Hanover, New Hampshire, located in the Upper Valley along the Connecticut River in New England. Its 269 acre campus is centered on a 5 acre "Green", a former field of pine trees cleared in 1771. Dartmouth is the largest private landowner of the town of Hanover, and its total landholdings and facilities are worth an estimated $434 million. In addition to its campus in Hanover, Dartmouth owns 4500 acre of Mount Moosilauke in the White Mountains and a 27000 acre tract of land in northern New Hampshire known as the Second College Grant.
Dartmouth's campus buildings vary in age from Wentworth and Thornton Halls of the 1820s (the oldest surviving buildings constructed by the college) to new dormitories and mathematics facilities completed in 2006. Most of Dartmouth's buildings are designed in the Georgian American colonial style, a theme which has been preserved in recent architectural additions. The College has actively sought to reduce carbon emissions and energy usage on campus, earning it the grade of A- from the Sustainable Endowments Institute on its College Sustainability Report Card 2008.
Academic facilities.
The college's creative and performing arts facility is the Hopkins Center for the Arts ("the Hop"). Opened in 1962, the Hop houses the College's drama, music, film, and studio arts departments, as well as a woodshop, pottery studio, and jewelry studio which are open for use by students and faculty. The building was designed by the famed architect Wallace Harrison, who would later design the similar-looking façade of Manhattan's Metropolitan Opera House at Lincoln Center. Its facilities include two theaters and one 900-seat auditorium. The Hop is also the location of all student mailboxes ("Hinman boxes") and the Courtyard Café dining facility. The Hop is connected to the Hood Museum of Art, arguably North America's oldest museum in continuous operation, and the Loew Auditorium, where films are screened.
In addition to its 19 graduate programs in the arts and sciences, Dartmouth is home to three separate graduate schools. The Geisel School of Medicine is located in a complex on the north side of campus and includes laboratories, classrooms, offices, and a biomedical library. The Dartmouth–Hitchcock Medical Center, located several miles to the south in Lebanon, New Hampshire, contains a 396-bed teaching hospital for the Medical School. The Thayer School of Engineering and the Tuck School of Business are both located at the end of Tuck Mall, west of the center of campus and near the Connecticut River. The Thayer School presently comprises two buildings; Tuck has seven academic and administrative buildings, as well as several common areas. The two graduate schools share a library, the Feldberg Business & Engineering Library.
Dartmouth's nine libraries are all part of the collective Dartmouth College Library, which comprises 2.48 million volumes and 6 million total resources, including videos, maps, sound recordings, and photographs. Its specialized libraries include the Biomedical Libraries, Evans Map Room, Feldberg Business & Engineering Library, Jones Media Center, Kresge Physical Sciences Library, Paddock Music Library, Rauner Special Collections Library, and Sherman Art Library. Baker-Berry Library is the main library at Dartmouth, comprising Baker Memorial Library (opened 1928) and Berry Library (opened 2000). Located on the northern side of the Green, Baker's 200 ft tower is an iconic symbol of the College.
Athletic facilities.
Dartmouth's original sports field was the Green, where students played cricket and old division football during the 19th century. Today, two of Dartmouth's athletic facilities are located in the southeast corner of campus. The center of athletic life is the Alumni Gymnasium, which includes the Karl Michael Competition Pool and the Spaulding Pool, a state of the art fitness center, a weight room, and a 1/13th-mile (123 m) indoor track. Attached to Alumni Gymnasium is the Berry Sports Center, which contains basketball and volleyball courts (Leede Arena), as well as the Kresge Fitness Center. Behind the Alumni Gymnasium is Memorial Field, a 15,600-seat stadium overlooking Dartmouth's football field and track. The nearby Thompson Arena, designed by Italian engineer Pier Luigi Nervi and constructed in 1975, houses Dartmouth's ice rink. Also visible from Memorial Field is the 91800 sqft Nathaniel Leverone Fieldhouse, home to the indoor track. The new softball field, Dartmouth Softball Park, was constructed in 2012, sharing parking facilities with Thompson arena.
Dartmouth's other athletic facilities in Hanover include the Friends of Dartmouth Rowing Boathouse and the old rowing house storage facility (both located along the Connecticut River), the Hanover Country Club, Dartmouth's oldest remaining athletic facility (established in 1899), and the Corey Ford Rugby Clubhouse. The college also maintains the Dartmouth Skiway, a 100 acre skiing facility located over two mountains near the Hanover campus in Lyme Center, New Hampshire, that serves as the winter practice grounds for the nationally dominant Dartmouth ski team.
Housing and student life facilities.
Instead of ungrouped dormitories or residential colleges, Dartmouth has nine residential communities located throughout campus. The dormitories vary in design from modern to traditional Georgian styles, and room arrangements range from singles to quads and apartment suites. Since 2006, the College has guaranteed housing for students during their freshman and sophomore years. More than 3,000 students elect to live in housing provided by College.
Campus meals are served by Dartmouth Dining Services, which operates 11 dining establishments around campus. Four of them are located at the center of campus in the Class of 1953 Commons, formerly Thayer Dining Hall.
The Collis Center is the center of student life and programming, serving as what would be generically termed the "student union" or "campus center." It contains a café, study space, common areas, and a number of administrative departments, including the Academic Skills Centre. Robinson Hall, next door to both Collis and Thayer, contains the offices of a number of student organizations including the Dartmouth Outing Club and "The Dartmouth" daily newspaper.
Trees and grounds.
A notable feature of the Dartmouth campus is its many trees, particularly American elms. Unfortunately, like American elms throughout the United States, the elm trees at Dartmouth have been affected by Dutch elm disease and damaged by storms and other environmental conditions. However, because the college is committed to maintaining the campus aesthetic, the trees are well cared-for, and new plantings replace diseased or damaged trees that must be removed. Dartmouth's graduate community newsletter reported in October 2014 that there are still approximately 200 elm trees on campus, making it the most common species at Dartmouth.
Student life.
In 2006, "The Princeton Review" ranked Dartmouth third in its "Quality of Life" category, and sixth for having the "Happiest Students." Athletics and participation in the Greek system are the most popular campus activities. In all, Dartmouth offers more than 350 organizations, teams, and sports. The school is also home to a variety of longstanding traditions and celebrations.
Student groups.
Dartmouth's more than 200 student organizations and clubs cover a wide range of interests. In 2007, the college hosted eight academic groups, 17 cultural groups, two honor societies, 30 "issue-oriented" groups, 25 performing groups, 12 pre-professional groups, 20 publications, and 11 recreational groups. Notable student groups include the nation's largest and oldest collegiate outdoors club, the Dartmouth Outing Club, which includes the nationally recognized Big Green Bus; the campus's oldest and most prestigious a cappella group, The Dartmouth Aires; the controversial conservative newspaper "The Dartmouth Review"; and "The Dartmouth", arguably the nation's oldest university newspaper. "The Dartmouth" describes itself as "America's Oldest College Newspaper, Founded 1799."
Partially because of Dartmouth's rural, isolated location, the Greek system dating from the 1840s is one of the most popular social outlets for students. Dartmouth is home to 32 recognized Greek houses: 17 fraternities, 12 sororities, and three coeducational organizations. In 2007, roughly 70% of eligible students belonged to a Greek organization; since 1987, students have not been permitted to join Greek organizations until their sophomore year. Dartmouth College was among the first institutions of higher education to desegregate fraternity houses in the 1950s, and was involved in the movement to create coeducational Greek houses in the 1970s. In the early first decade of the 21st century, campus-wide debate focused on a Board of Trustees recommendation that Greek organizations become "substantially coeducational"; this attempt to change the Greek system eventually failed. The fraternities have an extensive history of hazing and alcohol abuse, leading to police raids and accusations of sexual harassment.
Dartmouth also has a number of secret societies, which are student- and alumni-led organizations often focused on preserving the history of the college and initiating service projects. Most prominent among them is the Sphinx society, housed in a prominent Egyptian tomb-like building near the center of campus. The Sphinx has been the subject of numerous rumors as to its facilities, practices, and membership.
The college has an additional classification of social/residential organizations known as undergraduate societies.
Athletics.
Approximately 20% of students participate in a varsity sport, and nearly 80% participate in some form of club, varsity, intramural, or other athletics. In 2007, Dartmouth College fielded 34 intercollegiate varsity teams: 16 for men, 16 for women, and coeducational sailing and equestrian programs. Dartmouth's athletic teams compete in the National Collegiate Athletic Association (NCAA) Division I eight-member Ivy League conference; some teams also participate in the Eastern College Athletic Conference (ECAC). As is mandatory for the members of the Ivy League, Dartmouth College does not offer athletic scholarships. In addition to the traditional American team sports (football, basketball, baseball, and ice hockey), Dartmouth competes at the varsity level in many other sports including track and field, sailing, tennis, rowing, soccer, skiing, and lacrosse.
The college also offers 26 club and intramural sports such as fencing, rugby, water polo, figure skating, boxing, volleyball, ultimate frisbee, and cricket, leading to a 75% participation rate in athletics among the undergraduate student body. The Dartmouth Fencing Team, despite being entirely self-coached, won the USACFC club national championship in 2014. The Dartmouth Men's Rugby Team, founded in 1951, has been ranked among the best collegiate teams in that sport over many years. The figure skating team won the national championship five straight times from 2004 through 2008. In addition to the academic requirements for graduation, Dartmouth requires every undergraduate to complete a 50 yd swim and three terms of physical education.
Technology.
Technology plays an important role in student life, as Dartmouth has been ranked as one of the most technologically advanced colleges in the world (as in "Newsweek"'s 2004 ranking of "Hottest for the Tech-Savvy" and Yahoo!'s 1998 "Wired Colleges" list). BlitzMail, the campus e-mail network, plays a tremendous role in social life, as students tend to use it for communication in lieu of cellular phones or instant messaging programs. Student reliance on BlitzMail (known colloquially as "Blitz," which functions as both noun and verb) is reflected by the presence of about 100 public computer terminals intended specifically for BlitzMail use. Since 1991, Dartmouth students have been required to own a personal computer.
In 2001, Dartmouth became the first Ivy League institution to offer entirely ubiquitous wireless internet access. With over 1,400 access points, the network is available throughout all college buildings as well as in most public outdoor spaces. Other technologies being pioneered include College-wide Video-on-Demand and VoIP rollouts.
Native Americans at Dartmouth.
It is often pointed out that the charter of Dartmouth College, granted to Eleazar Wheelock in 1769, proclaims that the institution was created "for the education and instruction of Youth of the Indian Tribes in this Land in reading, writing and all parts of Learning... as well as in all liberal Arts and Sciences; and also of English Youth and any others." However, Wheelock primarily intended the college to educate White youth, and the few Native students that attended Dartmouth experienced much difficulty in an institution ostensibly dedicated to their education. The funds for the Charity School for Native Americans that preceded Dartmouth College were raised primarily by the efforts of a Native American named Samson Occom, and at least some of those funds were used to help found the college.
The college graduated only 19 Native Americans during its first two hundred years. In 1970, the college established Native American academic and social programs as part of a "new dedication to increasing Native American enrollment." Since then, Dartmouth has graduated over 700 Native American students from over 200 different tribes, more than the other seven Ivy League universities combined.
Traditions.
Dartmouth is well known for its fierce school spirit and many traditions. The college functions on a quarter system, and one weekend each term is set aside as a traditional celebratory event, known on campus as "big weekends" or "party weekends". In the fall term, Homecoming (officially called Dartmouth Night) is marked by a bonfire on the Green constructed by the freshman class. Winter term is celebrated by Winter Carnival, a tradition started in 1911 by the Dartmouth Outing Club to promote winter sports. In the spring, Green Key is a weekend mostly devoted to campus parties and celebration.
The summer term was formerly marked by Tubestock, an unofficial tradition in which the students used wooden rafts and inner tubes to float on the Connecticut River. Begun in 1986, Tubestock met its demise in 2006 when Hanover town ordinances and a lack of coherent student protest conspired to defeat the popular tradition. The Class of 2008, during their summer term on campus in 2006, replaced the defunct Tubestock with Fieldstock. This new celebration includes a barbecue, live music, and the revival of the 1970s and 1980s tradition of racing homemade chariots around the Green. Unlike Tubestock, Fieldstock is funded and supported by the College.
Another longstanding tradition is four-day, student-run Dartmouth Outing Club trips for incoming freshmen, begun in 1935. Each trip concludes at the Moosilauke Ravine Lodge. In 2011, over 96% of freshmen elected to participate.
Insignia and other representations.
Motto and song.
Dartmouth's motto, chosen by Eleazar Wheelock, is "Vox clamantis in deserto". The Latin motto is literally translated as "The voice of one crying in the wilderness", but is more often rendered as "A voice crying in the wilderness", which attempts to translate the synecdoche of the phrase. The phrase appears five times in the Bible and is a reference to the college's location on what was once the frontier of European settlement. Richard Hovey's "Men of Dartmouth" was elected as the best of Dartmouth's songs in 1896, and became the school's official song in 1926. The song was retitled to "Alma Mater" in the 1980s when its lyrics were changed to refer to women as well as men.
Seal.
Dartmouth's 1769 royal charter required the creation of a seal for use on official documents and diplomas. The college's founder Eleazar Wheelock designed a seal for his college bearing a striking resemblance to the seal of the Society for the Propagation of the Gospel, a missionary society founded in London in 1701, in order to maintain the illusion that his college was more for mission work than for higher education. Engraved by a Boston silversmith, the seal was ready by commencement of 1773. The trustees officially accepted the seal on August 25, 1773, describing it as:
An Oval, circumscribed by a Line containing SIGILL: COL: DARTMUTH: NOV: HANT: IN AMERICA 1770. within projecting a Pine Grove on the Right, whence proceed Natives towards an Edifice two Storey on the left; which bears in a Label over the Grove these Words "vox clamantis in deserto" the whole supported by Religion on the Right and Justice on the Left, and bearing in a Triangle irradiate, with the Hebrew Words [El Shaddai], agreeable to the above Impression, be the common Seal under which to pass all Diplomas or Certificates of Degrees, and all other Affairs of Business of and concerning Dartmouth College.
On October 28, 1926, the trustees affirmed the charter's reservation of the seal for official corporate documents alone. The College Publications Committee commissioned noted typographer W. A. Dwiggins to create a line drawing version of the seal in 1940 that saw widespread use. Dwiggins' design was modified during 1957 to change the date from "1770" to "1769", to accord with the date of the college charter. The trustees commissioned a new set of dies with a date of "1769" to replace the old dies, now badly worn after almost two hundred years of use. The 1957 design continues to be used under trademark number 2305032.
Shield.
On October 28, 1926, the trustees approved a "Dartmouth College Shield" for general use. Artist and engraver W. Parke Johnson designed this emblem on the basis of the shield that is depicted at the center of the original seal. This design does not survive. On June 9, 1944, the trustees approved another coat of arms based on the shield part of the seal, this one by Canadian artist and designer Thoreau MacDonald. That design was used widely and, like Dwiggins' seal, had its date changed from "1770" to "1769" around 1958. That version continues to be used under trademark registration number 3112676 and others.
College designer John Scotford made a stylized version of the shield during the 1960s, but it did not see the success of MacDonald's design. The shield appears to have been used as the basis of the shield of Dartmouth Medical School, and it has been reproduced in sizes as small as 20 micrometers across. The design has appeared on Rudolph Ruzicka's Bicentennial Medal (Philadelphia Mint, 1969) and elsewhere.
Nickname, symbol, and mascot.
Dartmouth has never had an official mascot. The nickname "The Big Green," originating in the 1860s, is based on students' adoption of a shade of forest green ("Dartmouth Green") as the school's official color in 1866. Beginning in the 1920s, the Dartmouth College athletic teams were known by their unofficial nickname "the Indians", a moniker that probably originated among sports journalists. This unofficial mascot and team name was used until the early 1970s, when its use came under criticism. In 1974, the Trustees declared the "use of the [Indian] symbol in any form to be inconsistent with present institutional and academic objectives of the College in advancing Native American education." Some alumni and students, as well as the conservative student newspaper, "The Dartmouth Review", have sought to return the Indian symbol to prominence, but never succeeded in doing so.
Various student initiatives have been undertaken to adopt a new mascot, but none has become "official". One proposal devised by the college humor magazine the "Dartmouth Jack-O-Lantern" was Keggy the Keg, an anthropomorphic beer keg who makes occasional appearances at college sporting events. Despite student enthusiasm for Keggy, the mascot has received approval from only the student government. In November 2006, student government attempted to revive the "Dartmoose" as a potential replacement amid renewed controversy surrounding the former Indian mascot.
Alumni.
Dartmouth's alumni are known for their devotion to the college. Most start by giving to the Senior Class Gift. According to a 2008 article in "The Wall Street Journal", Dartmouth graduates also earn higher median salaries at least 10 years after graduation than alumni of any other American university surveyed.
By 2008, Dartmouth had graduated 238 classes of students and has over 60,000 living alumni in a variety of fields.
Nelson A. Rockefeller, 41st Vice President of the United States and 49th Governor of New York, graduated "cum laude" from Dartmouth with a degree in economics in 1930. Over 164 Dartmouth graduates have served in the United States Senate and United States House of Representatives, such as Massachusetts statesman Daniel Webster. Cabinet members of American presidents include Attorney General Amos T. Akerman, Secretary of Defense James V. Forrestal, Secretary of Labor Robert Reich, former Secretary of the Treasury Henry Paulson, and former Secretary of the Treasury Timothy Geithner. C. Everett Koop was the Surgeon General of the United States under President Ronald Reagan. Two Dartmouth alumni have served as justices on the Supreme Court of the United States: Salmon P. Chase and Levi Woodbury. Eugene Norman Veasey (class of 1954) served as the Chief Justice of Delaware. The 46th and current Governor of Pennsylvania Tom Wolf is also a Dartmouth alumnus.
In literature and journalism, Dartmouth has produced thirteen Pulitzer Prize winners: Thomas M. Burton, Richard Eberhart, Dan Fagin, Robert Frost, Paul Gigot, Frank Gilroy, Jake Hooker, Nigel Jaquiss, Joseph Rago, Martin J. Sherwin, David K. Shipler, David Shribman, and Justin Harvey Smith.
Other authors and media personalities include ABC Senior White House correspondent Jake Tapper, novelist and founding editor of "The Believer" Heidi Julavits, "Dean of rock critics" Robert Christgau, National Book Award winner Louise Erdrich, novelist/screenwriter Budd Schulberg, political analyst Dinesh D'Souza, radio talk show host Laura Ingraham, commentator Mort Kondracke, and journalist James Panero. Norman Maclean, a former professor at the University of Chicago and author of "A River Runs Through It and Other Stories", graduated from Dartmouth in 1924. Theodor Geisel, better known as children's author Dr. Seuss, was a member of the class of 1925.
In the area of religion and theology, Dartmouth alumni include priests and ministers Ebenezer Porter, Jonathan Clarkson Gibbs, Caleb Sprague Henry, Arthur Whipple Jenks, Solomon Spalding, and Joseph Tracy; and rabbis Marshall Meyer, Arnold Resnicoff, and David E. Stern. Hyrum Smith, brother of Mormon Prophet Joseph Smith, attended the college in his teens. He was Patriarch of the LDS Church.
Dartmouth alumni in academia include Stuart Kauffman and Jeffrey Weeks, both recipients of MacArthur Fellowships (commonly called "genius grants"). Dartmouth has also graduated three Nobel Prize winners: Owen Chamberlain (Physics, 1959), K. Barry Sharpless (Chemistry, 2001), and George Davis Snell (Physiology or Medicine, 1980). Educators include the current chancellor of the University of California, San Diego Marye Anne Fox (PhD. in Chemistry, 1974), founding president of Vassar College Milo Parker Jewett, founder and first president of Bates College Oren B. Cheney, founder and first president of Kenyon College Philander Chase, first professor of Wabash College Caleb Mills, and former president of Union College Charles Augustus Aiken. Nine of Dartmouth's 17 presidents were alumni of the College.
Dartmouth alumni serving as CEOs or company presidents and executives include Charles Alfred Pillsbury, founder of the Pillsbury Company and patriarch of the Pillsbury family, Sandy Alderson (San Diego Padres), John Donahoe (eBay), Louis V. Gerstner, Jr. (IBM), Charles E. Haldeman (Putnam Investments), Donald J. Hall, Sr. (Hallmark Cards), Jeffrey R. Immelt (General Electric), Gail Koziara Boudreaux (United Health Care), Grant Tinker (NBC), and Brian Goldner (Hasbro).
In film, entertainment, and television, Dartmouth is represented by Budd Schulberg, Academy Award-winning screenwriter of "On the Waterfront", Michael Phillips, who won the Academy Award for best picture as co-producer of "The Sting", Rachel Dratch, a cast member of "Saturday Night Live", Shonda Rhimes creator of "Grey's Anatomy, Private Practice" and "Scandal", Chris Meledandri Executive Producer of "Ice Age", "Horton Hears a Who!", and "Despicable Me", and the titular character of "Mister Rogers' Neighborhood", Fred Rogers. Other notable film and television figures include Sarah Wayne Callies ("Prison Break"), Emmy Award winner Michael Moriarty, Andrew Shue of "Melrose Place", Aisha Tyler of "Friends" and "24", Connie Britton of "Spin City", "The West Wing" and "Friday Night Lights", and Mindy Kaling of "The Office" and "The Mindy Project".
A number of Dartmouth alumni have found success in professional sports. In baseball, Dartmouth alumni include All-Star and three-time Gold Glove winner and manager Brad Ausmus and All-Star Mike Remlinger. Professional football players include former Miami Dolphins quarterback Jay Fiedler, linebacker Reggie Williams, three-time Pro Bowler Nick Lowery, quarterback Jeff Kemp, and Tennessee Titans tight end Casey Cramer. Dartmouth has also produced a number of Olympic competitors. Adam Nelson won the silver medal in the shotput in the 2000 Sydney Olympics and the gold medal at the 2004 Athens Olympics to go along with his gold medal in the 2005 World Championships in Athletics in Helsinki. Kristin King and Sarah Parsons were members of the United States' 2006 bronze medal-winning ice hockey team. Cherie Piper, Gillian Apps, and Katie Weatherston were among Canada's ice hockey gold medalists in 2006.
Dick Durrance and Tim Caldwell competed for the United States in skiing in the 1936 and 1976 Winter Olympics, respectively. Arthur Shaw, Earl Thomson, Edwin Myers, Marc Wright, Adam Nelson, Gerry Ashworth, and Vilhjálmur Einarsson have all won medals in track and field events. Former heavyweight rower Dominic Seiterle is a member of the Canadian national rowing team and won a gold medal at the 2008 Summer Olympics in the men's 8+ event.
Alumni income.
According to Payscale, Dartmouth College alums have among the highest average starting salaries ($58,200) in the United States, as well as the second-highest average income ten years after graduation ($123,000), placing after Harvey Mudd College and tying with Princeton University. Most recently in 2010, Payscale also ranked Dartmouth first in producing CEOs of for-profit companies, out of all undergraduate programs at United States universities.
In popular culture.
Dartmouth College has appeared in or been referenced by a number of popular media. Most notably, the 1978 comedy film "National Lampoon's Animal House" was co-written by Chris Miller '63, and is based loosely on a series of stories he wrote about his fraternity days at Dartmouth. In a CNN interview, John Landis said the movie was "based on Chris Miller's real fraternity at Dartmouth", Alpha Delta Phi. Dartmouth's Winter Carnival tradition was the subject of the 1939 film "Winter Carnival" starring Ann Sheridan and written by Budd Schulberg '36 and F. Scott Fitzgerald.
Further reading.
</dl>

</doc>
<doc id="8419" url="http://en.wikipedia.org/wiki?curid=8419" title="Dartmouth, Devon">
Dartmouth, Devon

Dartmouth is a town and civil parish in the English county of Devon. It is a tourist destination set on the western bank of the estuary of the River Dart, which is a long narrow tidal ria that runs inland as far as Totnes. It lies within the South Devon Area of Outstanding Natural Beauty and South Hams District, and had a population of 5,512 in 2001, reducing to 5,064 at the 2011 census There are two electoral wards in the "Dartmouth" area(Townstal & Kingswear). Their combined population at the above census was 6,822.
History.
Dartmouth was of strategic importance as a deep-water port for sailing vessels. The port was used as the sailing point for the Crusades of 1147 and 1190, and Warfleet Creek, close to Dartmouth Castle is supposed by some to be named for the vast fleets which assembled there. Dartmouth was a home of the Royal Navy from the reign of Edward III and was twice surprised and sacked during the Hundred Years' War, after which the mouth of the estuary was closed every night with a great chain. The narrow mouth of the Dart is protected by two fortified castles, Dartmouth Castle and Kingswear Castle. Originally Dartmouth's only wharf was Bayard's Cove, a relatively small area protected by a fort at the southern end of the town.
In 1373 Geoffrey Chaucer visited and among the pilgrims in his Canterbury Tales
Notwithstanding Dartmouth's connections with the crown and respectable society, it was a major base for privateering in medieval times. John Hawley or Hauley, a licensed privateer and sometime mayor of Dartmouth is reputed to be a model for Chaucer's "schipman".
The earliest street in Dartmouth to be recorded by name (in the 13th century) is Smith Street. Several of the houses on the street are originally late 16th century or early 17th century and probably rebuilt on the site of earlier medieval dwellings. The street name undoubtedly derives from the smiths and shipwrights who built and repaired ships here when the tidal waters reached as far as this point. Smith Street was also the site of the town pillory in medieval times.
St Saviour's Church was constructed in 1335 and consecrated in 1372. It contains a pre-Reformation oak rood screen built in 1480 and several monuments including the tomb of John Hawley (d. 1408) and his two wives, covered with a large brass plate effigy of all three. A large medieval ironwork door is decorated with two leopards of the Plantagenets and is possibly the original portal. Although it is dated "1631", this is thought to be the date of a subsequent refurbishment coincidental with major renovations of the church in the 17th century. The gallery of the church is decorated with the heraldic crests of prominent local families and is reputed to be constructed of timbers from ships captured during the defeat of the Spanish Armada, although this has not been categorically substantiated.
In 1592 the "Madre de Deus", a Portuguese treasure ship captured by the English in the Azores, docked at Dartmouth Harbour. It attracted all manner of traders, dealers, cutpurses and thieves and by the time Sir Walter Raleigh arrived to reclaim the Crown's share of the loot, a cargo estimated at half a million pounds had been reduced to £140,000. Still, ten freighters were needed to carry the treasure to London.
Henry Hudson put in to Dartmouth on his return from North America, and was arrested for sailing under a foreign flag. The Pilgrim Fathers put in to Dartmouth's Bayard's Cove, en route from Southampton to America. They rested a while before setting off on their journey in the "Mayflower" and the "Speedwell" on 20 August 1620. About 300 miles west of Land's End, upon realising that the "Speedwell" was unseaworthy, it returned to Plymouth. The "Mayflower" departed alone to complete the crossing to Cape Cod. Dartmouth's sister city is Dartmouth, Massachusetts.
The town contains many medieval and Elizabethan streetscapes and is a patchwork of narrow lanes and stone stairways. A significant number of the historic buildings are listed. One of the most obvious is the Butterwalk, built 1635 to 1640. Its intricately carved wooden fascia is supported on granite columns. Charles II held court in the Butterwalk whilst sheltering from storms in 1671 in a room which now forms part of Dartmouth Museum. Much of the interior survives from that time.
The Royal Castle Hotel was built in 1639 on the then new quay. The building was re-fronted in the 19th century, and as the new frontage is itself listed, it is not possible to see the original which lies beneath. A claimant for the oldest building is a former merchant's house in Higher Street, now a Good Beer Guide listed public house called "the Cherub", built circa 1380. Agincourt House (next to the Lower Ferry) is also 14th century.
Dartmouth sent numerous ships to join the English fleet that attacked the Spanish Armada, including the Roebuck, Crescent and Hart. The Nuestra Señora del Rosario, the Spanish Armada's "payship" commanded by Admiral Pedro de Valdés, was captured along with all its crew by Sir Francis Drake. It was reportedly anchored in the River Dart for more than a year and the crew were used as labourers on the nearby Greenway Estate which was the home of Sir Humphrey Gilbert and his half-brother Sir Walter Raleigh. Greenway was later the home of Dame Agatha Christie.
The remains of a fort at Gallants Bower just outside the town are some of the best preserved remains of a Civil War defensive structure. The fort was built by Royalist occupation forces in c. 1643 to the south east of the town, with a similar fort at Mount Ridley on the opposite slopes of what is now Kingswear. The Parliamentarian General Fairfax attacked from the north in 1646, taking the town and forcing the Royalists to surrender, after which Gallants Bower was demolished.
19th century.
The made-up embankment which today extends the whole length of the town's riverbank is the result of 19th century land reclamation, started in earnest when the town played host to a large number of prisoners of war from the Napoleonic Wars which formed a captive workforce. Before this, what is now the town centre was almost entirely tidal mud flats.
The Royal National Lifeboat Institution opened the Dart Lifeboat Station at the Sand Quay in 1878, but it was closed in 1896. In all this time only one effective rescue was made by the lifeboat.
20th century.
In the latter part of World War II the town was a base for American forces and one of the departure points for Utah Beach in the D Day landings. Slipways and harbour improvements were also constructed. Much of the surrounding countryside and notably Slapton Sands was closed to the public while it was used by US troops for practise landings and manoeuvres. 
21st century.
Dart Lifeboat Station was opened in 2007, the first time that a lifeboat had been stationed in the town since 1896. It has initially been kept in a temporary building in Coronation Park.
In 2010, a fire seriously damaged numerous historical properties in Fairfax Place and Higher Street. Several were Tudor and Grade I or Grade II listed buildings.
Governance.
The town was an ancient borough, incorporated by Edward III, known formally as Clifton-Dartmouth-Hardness, and consisting of the three parishes of "St Petrox", "St Saviour" and "Townstall", and incorporating the hamlets of Ford, Old Mill and Norton. It was reformed under the Municipal Corporations Act 1835. The town returned two members of parliament from the 13th century until 1835, after which one MP was elected until the town was disenfranchised in 1868. It remained a municipal borough until 1974, when it was merged into the South Hams district, and became a successor parish of Dartmouth with a town council.
Dartmouth Town Council is the lowest of three tiers of local government. It consists of 16 councillors representing the two wards of Clifton and Townstall. At the second tier, Dartmouth forms part of the Dartmouth and Kingswear ward of South Hams District Council, which returns three councillors. At the upper tier of local government Dartmouth and Kingswear Electoral Division elects one member to Devon County Council.
Culture and tourism.
The Port of Dartmouth Royal Regatta takes place annually over three days at the end of August. The event sees the traditional regatta boat races along with markets, fun fairs, community games, air displays including the Red Arrows and fireworks. A Royal Navy guard ship is present at the event.
Bayard's Cove has been used in several television productions, including "The Onedin Line" a popular BBC television drama series that ran from 1971 to 1980.
Notable tourist attractions include the Dartmouth Royal Naval College, Dartmouth Castle and the Dartmouth Steam Railway which terminates at Kingswear on the opposite bank of the river.
Boat cruises to nearby places along the coast (such as Torbay and Salcombe) and up the river (to Totnes, Dittisham and the Greenway Estate) are provided by several companies. The paddlesteamer PS Kingswear Castle returned to the town in 2013.
Climate.
The nearest Met Office weather station is Slapton, about 5 miles south-south west of Dartmouth and a similar distance from the coast. As with the rest of the British Isles and South West England, the area experiences a maritime climate with warm summers and mild winters - this is particularly pronounced due to its position near the coast - extremes range from a record low of just -8.0 C in January 1987 up to a record high of 30.5 C during June 1976.
Transport.
Dartmouth is linked to Kingswear, on the other side of the River Dart, by three ferries. The Higher Ferry and the Lower Ferry are both vehicular ferries. The Passenger Ferry, as its name suggests, carries only passengers, principally to connect with the Paignton and Dartmouth Steam Railway at Kingswear station. The nearest bridge across the Dart is in Totnes, some 11 mi away by road.
The A379 road runs through Dartmouth, linking the town to Slapton and Kingsbridge to the southwest and to Torbay to the east across the Higher Ferry. The A3122 connects Dartmouth to a junction with the A381, and hence to both Totnes and a more direct route to Kingsbridge.
First Devon & Cornwall provides local town bus services and links to, Plymouth, Kingsbridge. As well as Stagecoach Gold provides a luxury bus service to Torquay via Totnes and Paignton. In addition Stagecoach Devon provides links to the Torbay resorts of Brixham, Paignton and Torquay from Kingswear via the ferry.
No railway has ever run to Dartmouth, but the town does have a railway station, although it is now a restaurant. The railway line to Kingswear was opened in 1864, the original plans for the Dartmouth and Torbay Railway line took the line across a bridge and into the town. Opposition from local seamen and merchants saw the route diverted to Kingswear on the opposite side of the river, but this occurred after the station had been built at Dartmouth. The railway terminated at a station called "Kingswear for Dartmouth" (now on the Paignton and Dartmouth Steam Railway) and a ferry took passengers across the river to the station at Dartmouth railway station, which had a dedicated pontoon. British Railways closed the line to mainline passenger trains in 1973, but it re-opened as a heritage line and has run as one ever since.
Education.
Royal Naval College.
The town is home to the Royal Navy's officer training college (Britannia Royal Naval College), where all officers of the Royal Navy and many foreign naval officers are trained.
Schools.
Dartmouth has one secondary school — formerly (Dartmouth Community College) now Dartmouth Academy — an all-through school for those aged 3–18, and two primary schools: (Dartmouth Primary school (now part of Dartmouth Academy) and St John the Baptist R.C. Primary School). Dartmouth Community College and Dartmouth Primary School are part of the Dartmouth Learning Campus; as from September 2007, Dartmouth Community College is part of a federation with Dartmouth Primary School and Nursery, meaning that the two schools share one governing body for pupils aged 1 to 19. Dartmouth also has a pre-school in the centre of town, established for over 40 years and based in the old Victorian school rooms at South Ford Road. It provides care for 2- to 5-year-olds and is run as a charitable organisation.
Sport and leisure.
Dartmouth has a Non-League football club Dartmouth A.F.C. who play at Long Cross.
Dartmouth also hosts the annual "World Indoor Rally Championship", based on Slot car racing in the late summer.
At the end of August and early September there is the annual Port of Dartmouth Royal Regatta.
Since 1905 Dartmouth has had a greenhouse as part of the Royal Avenue Gardens. In May 2013 this building, used for the previous 10 years by Dartmouth in Bloom, a not-for-profit organisation affiliated with Britain in Bloom, was closed as structurally unsound. There are proposals to restore the greenhouse to its prior Edwardian style.
Notable residents.
Thomas Newcomen, the inventor of the atmospheric engine – the first successful steam-powered pumping engine – was born in Dartmouth in 1663. The location of his house in Lower Street is marked with a plaque, although the building itself was demolished (and elements incorporated into local architect Thomas Lidstone's house on Ridge Hill) in the 19th century to make way for a new road which was named after Newcomen. An 18th-century working Newcomen steam engine is on display in the town.
The town was home to the civil engineer and calculating prodigy George Parker Bidder (1806–1878), who is notable for his work on railways over much of the world, as well as the docks of the East End in the Port of London. Bidder served on the town council, and his expertise was instrumental in draining the area which is now the centre of the town. He also undertook pioneering work with Samuel Lake on steam trawling whilst living in the town. Bidder died at his home at Paradise Point near Warfleet Creek and is buried at nearby Stoke Fleming.
Flora Thompson lived in Above Town between 1928 and 1940, writing "Lark Rise" and "Over to Candleford" during this time. The books were later combined into a single volume with the later "Candleford Green" to form the well-known "Lark Rise to Candleford". She is buried at Longcross Cemetery.
The stage and film actress Rachel Kempson (1910–2003) was born in Dartmouth. She was the wife of Sir Michael Redgrave and mother of Vanessa, Lynn and Corin, and published her autobiography, "Life Among the Redgraves", in 1988.
Gordon Onslow Ford (1912–2003), a leading British surrealist painter, attended the Royal Naval College.
Sir John Harvey Jones (1924-2008), Businessman and television presenter, attended the Royal Naval College.
Christopher Robin Milne, son of A.A. Milne, after whom the character Christopher Robin in the Winnie-the-Pooh books was named, used to own the Harbour Bookshop. The bookshop was reported as facing closure in September 2011 and the report was fulfilled.
Many local businesses with amusingly appropriate names were commemorated in a special edition of the card game Happy Families produced locally in 1987, created to raise funds locally. A copy is held in Dartmouth Museum.
Theodore Veale, recipient of the Victoria Cross

</doc>
<doc id="8420" url="http://en.wikipedia.org/wiki?curid=8420" title="Dodo">
Dodo

The dodo ("Raphus cucullatus") is an extinct flightless bird that was endemic to the island of Mauritius, east of Madagascar in the Indian Ocean. Its closest genetic relative was the also extinct Rodrigues solitaire, the two forming the subfamily Raphinae of the family of pigeons and doves. The closest extant relative of the dodo is the Nicobar pigeon. A white dodo was once incorrectly thought to have existed on the nearby island of Réunion.
Subfossil remains show the dodo was about 1 m tall and may have weighed 10.6 - in the wild. The dodo's appearance in life is evidenced only by drawings, paintings, and written accounts from the 17th century. Because these vary considerably, and because only some illustrations are known to have been drawn from live specimens, its exact appearance in life remains unresolved. Similarly, little is known with certainty about its habitat and behaviour. It has been depicted with brownish-grey plumage, yellow feet, a tuft of tail feathers, a grey, naked head, and a black, yellow, and green beak. It used gizzard stones to help digest its food, which is thought to have included fruits, and its main habitat is believed to have been the woods in the drier coastal areas of Mauritius. One account states its clutch consisted of a single egg. It is presumed that the dodo became flightless because of the ready availability of abundant food sources and a relative absence of predators on Mauritius.
The first recorded mention of the dodo was by Dutch sailors in 1598. In the following years, the bird was hunted by sailors, their domesticated animals, and invasive species introduced during that time. The last widely accepted sighting of a dodo was in 1662. Its extinction was not immediately noticed, and some considered it to be a mythical creature. In the 19th century, research was conducted on a small quantity of remains of four specimens that had been brought to Europe in the early 17th century. Among these is a dried head, the only soft tissue of the dodo that remains today. Since then, a large amount of subfossil material has been collected from Mauritius, mostly from the Mare aux Songes swamp. The extinction of the dodo within less than a century of its discovery called attention to the previously unrecognised problem of human involvement in the disappearance of entire species. The dodo achieved widespread recognition from its role in the story of "Alice in Wonderland", and it has since become a fixture in popular culture, often as a symbol of extinction and obsolescence. It is frequently used as a mascot on Mauritius.
Taxonomy.
The dodo was variously declared a small ostrich, a rail, an albatross, or a vulture, by early scientists. In 1842, Johannes Theodor Reinhardt proposed that dodos were ground pigeons, based on studies of a dodo skull he had discovered in the royal Danish collection at Copenhagen. This view was met with ridicule, but was later supported by Hugh Edwin Strickland and Alexander Gordon Melville in their 1848 monograph "The Dodo and Its Kindred", which attempted to separate myth from reality. After dissecting the preserved head and foot of the specimen at the Oxford University Museum and comparing it with the few remains then available of the extinct Rodrigues solitaire ("Pezophaps solitaria") they concluded that the two were closely related. Strickland stated that although not identical, these birds shared many distinguishing features of the leg bones, otherwise known only in pigeons.
Strickland and Melville established that the dodo was anatomically similar to pigeons in many features. They pointed to the very short keratinous portion of the beak, with its long, slender, naked basal part. Other pigeons also have bare skin around their eyes, almost reaching their beak, as in dodos. The forehead was high in relation to the beak, and the nostril was located low on the middle of the beak and surrounded by skin, a combination of features shared only with pigeons. The legs of the dodo were generally more similar to those of terrestrial pigeons than of other birds, both in their scales and in their skeletal features. Depictions of the large crop hinted at a relationship with pigeons, in which this feature is more developed than in other birds. Pigeons generally have very small clutches, and the dodo is said to have laid a single egg. Like pigeons, the dodo lacked the vomer and septum of the nostrils, and it shared details in the mandible, the zygomatic bone, the palate, and the hallux. The dodo differed from other pigeons mainly in the small size of the wings and the large size of the beak in proportion to the rest of the cranium.
Throughout the 19th century, several species were classified as congeneric with the dodo, including the Rodrigues solitaire and the Réunion solitaire, as "Didus solitarius" and "Raphus solitarius", respectively ("Didus" and "Raphus" being names for the dodo genus used by different authors of the time). An atypical 17th-century description of a dodo and bones found on Rodrigues, now known to have belonged to the Rodrigues solitaire, led Abraham Dee Bartlett to name a new species, "Didus nazarenus", in 1852. Based on solitaire remains, it is now a synonym of that species. Crude drawings of the red rail of Mauritius were also misinterpreted as dodo species, "Didus broeckii" and "Didus herberti".
Etymology.
One of the original names for the dodo was the Dutch "Walghvogel", first used in the journal of Vice Admiral Wybrand van Warwijck, who visited Mauritius during the Second Dutch Expedition to Indonesia in 1598. "Walghe" means "tasteless", "insipid", or "sickly", and "vogel" means "bird". The name was translated into German as "Walchstök" or "Walchvögel", by Jakob Friedlib. The original Dutch report titled "Waarachtige Beschryving" was lost, but the English translation survived:
 On their left hand was a little island which they named Heemskirk Island, and the bay it selve they called Warwick Bay ... Here they taried 12. daies to refresh themselues, finding in this place great quantity of foules twice as bigge as swans, which they call Walghstocks or Wallowbirdes being very good meat. But finding an abundance of pigeons & popinnayes [parrots], they disdained any more to eat those great foules calling them Wallowbirds, that is to say lothsome or fulsome birdes.
Of the said Pidgeons and Popiniayes they found great plenty being very fat and good meate, which they could easily take and kil euen with little stickes: so tame they are by reason ý the Isle is not inhabited, neither be the liuing creatures therein accustomed to the sight of men.
Another account from that voyage, perhaps the first to mention the dodo, states that the Portuguese referred to them as penguins. The meaning may not have been derived from "penguin" (the Portuguese referred to them as "fotilicaios" at the time), but from "pinion", a reference to the small wings. The crew of the Dutch ship "Gelderland" referred to the bird as "Dronte" (meaning "swollen") in 1602, a name that is still used in some languages. This crew also called them "griff-eendt" and "kermisgans", in reference to fowl fattened for the Kermesse festival in Amsterdam, which was held the day after they anchored on Mauritius.
The etymology of the word "dodo" is unclear. Some ascribe it to the Dutch word "dodoor" for "sluggard", but it is more probably related to "Dodaars", which means either "fat-arse" or "knot-arse", referring to the knot of feathers on the hind end. The first record of the word "Dodaars" is in Captain Willem Van West-Zanen's journal in 1602. The English writer Sir Thomas Herbert was the first to use the word "dodo" in print in his 1634 travelogue, claiming it was referred to as such by the Portuguese, who had visited Mauritius in 1507. Another Englishman, Emmanuel Altham, had used the word in a 1628 letter, in which he also claimed the origin was Portuguese. The name "dodar" was introduced into English at the same time as dodo, but was only used until the 18th century. As far as is known, the Portuguese never mentioned the bird. Nevertheless, some sources still state that the word "dodo" derives from the Portuguese word "doudo" (currently "doido"), meaning "fool" or "crazy". It has also been suggested that "dodo" was an onomatopoeic approximation of the bird's call, a two-note pigeon-like sound resembling "doo-doo".
The Latin name "cucullatus" ("hooded") was first used by Juan Eusebio Nieremberg in 1635 as "Cygnus cucullatus", in reference to Carolus Clusius's 1605 depiction of a dodo. In his 18th-century classic work "Systema Naturae", Carl Linnaeus used "cucullatus" as the specific name, but combined it with the genus name "Struthio" (ostrich). Mathurin Jacques Brisson coined the genus name "Raphus" (referring to the bustards) in 1760, resulting in the current name "Raphus cucullatus". In 1766, Linnaeus coined the new binomial "Didus ineptus" (meaning "inept dodo"). This has become a synonym of the earlier name because of nomenclatural priority.
Evolution.
For many years the dodo and the Rodrigues solitaire were placed in a family of their own, the Raphidae (formerly Dididae), because their exact relationships with other pigeons were unresolved. Each was also placed in its own monotypic family (Raphidae and Pezophapidae, respectively), as it was thought that they had evolved their similar features independently. Osteological and molecular data has since led to the dissolution of the family Raphidae, and the dodo and solitaire are now placed in their own subfamily, Raphinae, in the family Columbidae.
Comparison of mitochondrial cytochrome "b" and 12S rRNA sequences isolated from a dodo tarsal and a Rodrigues solitaire femur confirmed their close relationship and their placement within the Columbidae. The genetic evidence was interpreted as showing the Southeast Asian Nicobar pigeon to be their closest living relative, followed by the crowned pigeons of New Guinea and the superficially dodo-like tooth-billed pigeon from Samoa. The generic name of the latter is "Didunculus" ("little dodo"), and it was called "Dodlet" by Richard Owen. The following cladogram, from Shapiro and colleagues (2002), shows the dodo's closest relationships within the Columbidae, a clade consisting of generally ground-dwelling island endemics.
A similar cladogram was published in 2007, inverting the placement of "Goura" and "Dicunculus" and including the pheasant pigeon and the thick-billed ground pigeon at the base of the clade. Based on behavioural and morphological evidence, Jolyon C. Parish proposed that the dodo and Rodrigues solitaire should be placed in the Gourinae subfamily along with the "Groura" pigeons and others, in agreement with the genetic evidence. In 2014, DNA of the only known specimen of the recently extinct spotted green pigeon ("Caloenas maculata") was analysed, and it was found to be a close relative of the Nicobar pigeon, and thus also the dodo and Rodrigues solitaire.
The 2002 study indicated that the ancestors of the dodo and the solitaire diverged around the Paleogene-Neogene boundary. The Mascarene Islands (Mauritius, Réunion, and Rodrigues), are of volcanic origin and are less than 10 million years old. Therefore, the ancestors of both birds probably remained capable of flight for a considerable time after the separation of their lineage. The ancestors of the raphines may have dispersed from Southeast Asia by island hopping. The lack of mammalian herbivores competing for resources on these islands allowed the solitaire and the dodo to attain very large sizes. The DNA obtained from the Oxford specimen is degraded, and no usable DNA has been extracted from subfossil remains, so these findings still need to be independently verified. The dodo lost the ability to fly owing to the lack of mammalian predators on Mauritius. Another large, flightless pigeon, the Viti Levu giant pigeon ("Natunaornis gigoura"), was described in 2001 from subfossil material from Fiji. It was only slightly smaller than the dodo and the solitaire, and it too is thought to have been related to the crowned pigeons.
Description.
As no complete dodo specimens exist, its external appearance, such as plumage and colouration, is hard to determine. Illustrations and written accounts of encounters with the dodo between its discovery and its extinction (1598–1662) are the primary evidence for its external appearance. According to most representations, the dodo had greyish or brownish plumage, with lighter primary feathers and a tuft of curly light feathers high on its rear end. The head was grey and naked, the beak green, black and yellow, and the legs were stout and yellowish, with black claws. The bird was sexually dimorphic: males were larger and had proportionally longer beaks. The beak was up to 23 cm in length and had a hooked point.
Subfossil remains and remnants of the birds that were brought to Europe in the 17th century show that they were very large birds, 1 m tall, and possibly weighing up to 23 kg. The higher weights have been attributed to birds in captivity; weights in the wild were estimated to have been in the range 10.6 -. A later estimate gives an average weight as low as 10.2 kg. This has been questioned, and there is still some controversy. It has been suggested that the weight depended on the season, and that individuals were fat during cool seasons, but less so during hot. A study of the few remaining feathers on the Oxford specimen head showed that they were pennaceous rather than plumaceous (downy) and most similar to those of other pigeons.
Many of the skeletal features that distinguish the dodo and the Rodrigues solitaire, its closest relative, from pigeons have been attributed to their flightlessness. The pelvic elements were thicker than those of flighted pigeons to support the higher weight, and the pectoral region and the small wings were paedomorphic, meaning that they were underdeveloped and retained juvenile features. The skull, trunk and pelvic limbs were peramorphic, meaning that they changed considerably with age. The dodo shared several other traits with the Rodrigues solitaire, such as features of the skull, pelvis, and sternum, as well as their large size. It differed in other aspects, such as being more robust and shorter than the solitaire, having a larger skull and beak, a rounded skull roof, and smaller orbits. The dodo's neck and legs were proportionally shorter, and it did not possess an equivalent to the knob present on the solitaire's wrists.
Contemporary descriptions.
Most contemporary descriptions of the dodo are found in ship's logs and journals of the Dutch East India Company vessels that docked in Mauritius when the Dutch Empire ruled the island. These records were used as guides for future voyages. Few contemporary accounts are reliable, as many seem to be based on earlier accounts, and none were written by scientists.
One of the earliest accounts, from van Warwijck's 1598 journal, describes the bird thus:
 Blue parrots are very numerous there, as well as other birds; among which are a kind, conspicuous for their size, larger than our swans, with huge heads only half covered with skin as if clothed with a hood. These birds lack wings, in the place of which 3 or 4 blackish feathers protrude. The tail consists of a few soft incurved feathers, which are ash coloured. These we used to call 'Walghvogel', for the reason that the longer and oftener they were cooked, the less soft and more insipid eating they became. Nevertheless their belly and breast were of a pleasant flavour and easily masticated.
One of the most detailed descriptions is by Sir Thomas Herbert in "A Relation of Some Yeares Travaille into Afrique and the Greater Asia" from 1634:
 First here only and in Dygarrois [Rodrigues, likely referring to the solitaire] is generated the Dodo, which for shape and rareness may antagonize the Phoenix of Arabia: her body is round and fat, few weigh less than fifty pound. It is reputed more for wonder than for food, greasie stomackes may seeke after them, but to the delicate they are offensive and of no nourishment. Her visage darts forth melancholy, as sensible of Nature's injurie in framing so great a body to be guided with complementall wings, so small and impotent, that they serve only to prove her bird. The halfe of her head is naked seeming couered with a fine vaile, her bill is crooked downwards, in midst is the trill [nostril], from which part to the end tis a light green, mixed with pale yellow tincture; her eyes are small and like to Diamonds, round and rowling; her clothing downy feathers, her train three small plumes, short and inproportionable, her legs suiting her body, her pounces sharpe, her appetite strong and greedy. Stones and iron are digested, which description will better be conceived in her representation.
Contemporary depictions.
The travel journal of the Dutch ship "Gelderland" (1601–1603), rediscovered in the 1860s, contains the only known sketches of living or recently killed specimens drawn on Mauritius. They have been attributed to the professional artist Joris Joostensz Laerle, who also drew other now-extinct Mauritian birds, and to a second, less refined artist. Apart from these sketches, it is unknown how many of the twenty or so 17th-century illustrations of the dodos were drawn from life or from stuffed specimens, which affects their reliability.
All post-1638 depictions appear to be based on earlier images, around the time reports mentioning dodos became rarer. Differences in the depictions led authors such as Anthonie Cornelis Oudemans and Masauji Hachisuka to speculate about sexual dimorphism, ontogenic traits, seasonal variation, and even the existence of different species, but these theories are not accepted today. Because details such as markings of the beak, the form of the tail feathers, and colouration vary from account to account, it is impossible to determine the exact morphology of these features, whether they signal age or sex, or if they even reflect reality. Dodo specialist Julian Hume argued that the nostrils of the living dodo would have been slits, as seen in the "Gelderland", Cornelis Saftleven, Crocker Art Gallery, and Ustad Mansur images. According to this claim, the gaping nostrils often seen in paintings indicate that taxidermy specimens were used as models.
The traditional image of the dodo is of a very fat and clumsy bird, but this view may be exaggerated. The general opinion of scientists today is that many old European depictions were based on overfed captive birds or crudely stuffed specimens. It has also been suggested that the images might show dodos with puffed feathers, as part of display behaviour. The Dutch painter Roelant Savery was the most prolific and influential illustrator of the dodo, having made at least ten depictions, often showing it in the lower corners. A famous painting of his from 1626, now called "Edwards's Dodo" as it was once owned by the ornithologist George Edwards, has since become the standard image of a dodo. It is housed in the Natural History Museum, London. The image shows a particularly fat bird and is the source for many other dodo illustrations.
An Indian Mughal painting rediscovered in St. Petersburg in the 1950s shows a dodo along with native Indian birds. It depicts a slimmer, brownish bird, and its discoverer A. Iwanow and dodo specialist Julian Hume regard it as one of the most accurate depictions of the living dodo; the surrounding birds are clearly identifiable and depicted with appropriate colouring. It is believed to be from the 17th century and has been attributed to artist Ustad Mansur. The bird depicted probably lived in the menagerie of Mughal Emperor Jahangir, located in Surat, where English traveller Peter Mundy also claimed to have seen dodos. In 2014, another Indian illustration of a dodo was reported, but it was found to be derivative of a 1836 German illustration.
Behaviour and ecology.
Little is known of the behaviour of the dodo, as most contemporary descriptions are very brief. Based on weight estimates, it has been suggested the male could reach the age of 21, and the female 17. Studies of the cantilever strength of its leg bones indicate that it could run quite fast. Unlike the Rodrigues solitaire, there is no evidence that the dodo used its wings in intraspecific combat. Though some dodo bones have been found with healed fractures, it had weak pectoral muscles and more reduced wings in comparison. The dodo may instead have used its large, hooked beak in territorial disputes. Since Mauritius receives more rainfall and has less seasonal variation than Rodrigues, which would have affected the availability of resources on the island, the dodo would have less reason to evolve aggressive territorial behaviour. The Rodrigues solitaire was therefore probably the more aggressive of the two.
The preferred habitat of the dodo is unknown, but old descriptions suggest that it inhabited the woods on the drier coastal areas of south and west Mauritius. This view is supported by the fact that the Mare aux Songes swamp is close to the sea in south-eastern Mauritius. Such a limited distribution across the island could well have contributed to its extinction. A 1601 map from the "Gelderland" journal shows a small island off the coast of Mauritius where dodos were caught. Julian Hume has suggested this island was in Tamarin Bay, on the west coast of Mauritius. Subfossil bones have also been found inside caves in highland areas, indicating that it once occurred on mountains. Work at the Mare aux Songes swamp has shown that its habitat was dominated by tambalacoque and "Pandanus" trees and endemic palms.
Many endemic species of Mauritius became extinct after the arrival of humans, so the ecosystem of the island is badly damaged and hard to reconstruct. Before humans arrived, Mauritius was entirely covered in forests, but very little remains of them today, because of deforestation. The surviving endemic fauna is still seriously threatened. The dodo lived alongside other recently extinct Mauritian birds such as the flightless red rail, the broad-billed parrot, the Mascarene grey parakeet, the Mauritius blue pigeon, the Mauritius owl, the Mascarene coot, the Mauritian shelduck, the Mauritian duck, and the Mauritius night heron. Extinct Mauritian reptiles include the saddle-backed Mauritius giant tortoise, the domed Mauritius giant tortoise, the Mauritian giant skink, and the Round Island burrowing boa. The small Mauritian flying fox and the snail "Tropidophora carinata" lived on Mauritius and Réunion, but vanished from both islands. Some plants, such as "Casearia tinifolia" and the palm orchid, have also become extinct.
Diet.
A 1631 Dutch document, rediscovered in 1887 but now lost, is the only account of the dodo's diet and also mentions that it used its beak for defence:
 These mayors are superb and proud. They displayed themselves to us with stiff and stern faces, and wide-open mouths. Jaunty and audacious of gait, they would scarcely move a foot before us. Their war weapon was their mouth, with which they could bite fiercely; their food was fruit; they were not well feathered but abundantly covered with fat. Many of them were brought onboard to the delight of us all.
In addition to fallen fruits, the dodo probably subsisted on nuts, seeds, bulbs, and roots. It has also been suggested that the dodo might have eaten crabs and shellfish, like their relatives the crowned pigeons. Its feeding habits must have been versatile, since captive specimens were probably given a wide range of food on the long sea journeys. Anthonie Oudemans suggested that as Mauritius has marked dry and wet seasons, the dodo probably fattened itself on ripe fruits at the end of the wet season to survive the dry season, when food was scarce; contemporary reports describe the bird's "greedy" appetite. France Staub suggested that they mainly fed on palm fruits, and he attempted to correlate the fat-cycle of the dodo with the fruiting regime of the palms.
Several contemporary sources state that the dodo used gizzard stones to aid digestion. The English writer Sir Hamon L'Estrange witnessed a live bird in London and described it as follows:
 About 1638, as I walked London streets, I saw the picture of a strange looking fowle hung out upon a clothe and myselfe with one or two more in company went in to see it. It was kept in a chamber, and was a great fowle somewhat bigger than the largest Turkey cock, and so legged and footed, but stouter and thicker and of more erect shape, coloured before like the breast of a young cock fesan, and on the back of a dunn or dearc colour. The keeper called it a Dodo, and in the ende of a chymney in the chamber there lay a heape of large pebble stones, whereof hee gave it many in our sight, some as big as nutmegs, and the keeper told us that she eats them (conducing to digestion), and though I remember not how far the keeper was questioned therein, yet I am confident that afterwards she cast them all again.
It is not known how the young were fed, but related pigeons provide crop milk. Contemporary depictions show a large crop, which was probably used to add space for food storage and to produce crop milk. It has been suggested that the maximum size attained by the dodo and the solitaire was limited by the amount of crop milk they could produce for their young during early growth.
In 1973, the tambalacoque, also known as the dodo tree, was thought to be dying out on Mauritus, to which it is endemic. There were supposedly only 13 specimens left, all estimated to be about 300 years old. Stanley Temple hypothesised that it depended on the dodo for its propagation, and that its seeds would germinate only after passing through the bird's digestive tract. He claimed that the tambalacoque was now nearly coextinct because of the disappearance of the dodo. Temple overlooked reports from the 1940s that found that tambalacoque seeds germinated, albeit very rarely, without being abraded during digestion. Others have contested his hypothesis and suggested that the decline of the tree was exaggerated, or seeds were also distributed by other extinct animals such as "Cylindraspis" tortoises, fruit bats or the broad-billed parrot. According to Wendy Strahm and Anthony Cheke, two experts in the ecology of the Mascarene Islands, the tree, while rare, has germinated since the demise of the dodo and numbers several hundred, not 13 as claimed by Temple, hence discrediting Temple's view as to the dodo and the tree's sole survival relationship.
It has been suggested that the broad-billed parrot may have depended on dodos and "Cylindraspis" tortoises to eat palm fruits and excrete their seeds, which became food for the parrots. "Anodorhynchus" macaws depended on now-extinct South American megafauna in the same way, but now rely on domesticated cattle for this service.
Reproduction.
As it was flightless and terrestrial and there were no mammalian predators or other kinds of natural enemy on Mauritius, the dodo probably nested on the ground. The account by François Cauche from 1651 is the only description of the egg and the call:
 I have seen in Mauritius birds bigger than a Swan, without feathers on the body, which is covered with a black down; the hinder part is round, the rump adorned with curled feathers as many in number as the bird is years old. In place of wings they have feathers like these last, black and curved, without webs. They have no tongues, the beak is large, curving a little downwards; their legs are long, scaly, with only three toes on each foot. It has a cry like a gosling, and is by no means so savoury to eat as the Flamingos and Ducks of which we have just spoken. They only lay one egg which is white, the size of a halfpenny roll, by the side of which they place a white stone the size of a hen's egg. They lay on grass which they collect, and make their nests in the forests; if one kills the young one, a grey stone is found in the gizzard. We call them "Oiseaux de Nazaret". The fat is excellent to give ease to the muscles and nerves.
Cauche's account is problematic, since it also mentions that the bird he was describing had three toes and no tongue, unlike dodos. This led some to believe that Cauche was describing a new species of dodo ("Didus nazarenus"). The description was most probably mingled with that of a cassowary, and Cauche's writings have other inconsistencies. A mention of a "young ostrich" taken on board a ship in 1617 is the only other reference to a possible juvenile dodo. An egg claimed to be that of a dodo is stored in the museum of East London, South Africa. It was donated by Marjorie Courtenay-Latimer, whose great aunt had received it from a captain who claimed to have found it in a swamp on Mauritius. In 2010, the curator of the museum proposed using genetic studies to determine its authenticity. It may instead be an aberrant ostrich egg.
Because of the possible single-egg clutch and the bird's large size, it has been proposed that the dodo was K-selected, meaning that it produced a low number of altricial offspring, which required parental care until they matured. Some evidence, including the large size and the fact that tropical and frugivorous birds have slower growth rates, indicates that the bird may have had a protracted development period. The fact that no juvenile dodos have been found in the Mare aux Songes swamp, where most dodo remains have been excavated, may indicate that they produced little offspring, that they matured rapidly, that the breeding grounds were far away from the swamp, or that the risk of miring was seasonal.
Relationship with humans.
Mauritius had previously been visited by Arab vessels in the Middle Ages and Portuguese ships between 1507 and 1513, but was settled by neither. No records of dodos by these are known, although the Portuguese name for Mauritius, "Cerne (swan) Island", may have been a reference to dodos. The Dutch Empire acquired Mauritius in 1598, renaming it after Maurice of Nassau, and it was used for the provisioning of trade vessels of the Dutch East India Company henceforward. The earliest known accounts of the dodo were provided by Dutch travelers during the Second Dutch Expedition to Indonesia, led by admiral Jacob van Neck in 1598. They appear in reports published in 1601, which also contain the first published illustration of the bird. Since the first sailors to visit Mauritius had been at sea for a long time, their interest in these large birds was mainly culinary. The 1602 journal by Willem Van West-Zanen of the ship "Bruin-Vis" mentions that 24–25 dodos were hunted for food, which were so large that two could scarcely be consumed at mealtime, their remains being preserved by salting. An illustration made for the 1648 published version of this journal, showing the killing of dodos, a dugong, and possibly a Mascarene grey parakeet, was captioned with a Dutch poem, here in Hugh Strickland's 1848 translation:
 <poem>
For food the seamen hunt the flesh of feathered fowl,
They tap the palms, and round-rumped dodos they destroy,
The parrot's life they spare that he may peep and howl,
And thus his fellows to imprisonment decoy.</poem>
Some early travellers found dodo meat unsavoury, and preferred to eat parrots and pigeons, others described it as tough but good. Some hunted dodos only for their gizzards, as this was considered the most delicious part of the bird. Dodos were easy to catch, but hunters had to be careful not to be bitten by their powerful beaks.
The appearance of the dodo and the red rail led Peter Mundy to speculate, 230 years before Charles Darwin's theory of evolution:
 Of these 2 sorts off fowl afforementionede, For oughtt wee yett know, Not any to bee Found out of this Iland, which lyeth aboutt 100 leagues From St. Lawrence. A question may bee demaunded how they should bee here and Not elcewhere, beeing soe Farer From other land and can Neither fly or swymme; whither by Mixture off kindes producing straunge and Monstrous formes, or the Nature of the Climate, ayer and earth in alltring the First shapes in long tyme, or how.
Dodos transported abroad.
The dodo was found interesting enough that living specimens were sent to Europe and the East. The number of transported dodos that reached their destinations alive is uncertain, and it is unknown how they relate to contemporary depictions and the few non-fossil remains in European museums. Based on a combination of contemporary accounts, paintings, and specimens, Julian Hume has inferred that at least eleven transported dodos reached their destinations alive.
Hamon L'Estrange's description of a dodo that he saw in London in 1638 is the only account that specifically mentions a live specimen in Europe. In 1626 Adriaen van de Venne drew a dodo that he claimed to have seen in Amsterdam, but he did not mention if it was alive, and his depiction is reminiscent of Savery's "Edwards's Dodo". Two live specimens were seen by Peter Mundy in Surat, India, between 1628 and 1634, one of which may have been the individual painted by Ustad Mansur around 1625. In 1628, Emmanuel Altham visited Mauritius and sent a letter to his brother in England:
 Right wo and lovinge brother, we were ordered by ye said councell to go to an island called Mauritius, lying in 20d. of south latt., where we arrived ye 28th of May; this island having many goates, hogs and cowes upon it, and very strange fowles, called by ye portingalls Dodo, which for the rareness of the same, the like being not in ye world but here, I have sent you one by Mr. Perce, who did arrive with the ship William at this island ye 10th of June. [In the margin of the letter] Of Mr. Perce you shall receive a jarr of ginger for my sister, some beades for my cousins your daughters, and a bird called a Dodo, if it live.
Whether the dodo survived the journey is unknown, and the letter was destroyed by fire in the 19th century.
The earliest known picture of a dodo specimen in Europe is from a c. 1610 collection of paintings depicting animals in the royal menagerie of Emperor Rudolph II in Prague. This collection includes paintings of other Mauritian animals as well, including a red rail. The dodo, which may be a juvenile, seems to have been dried or embalmed, and had probably lived in the emperor's zoo for a while together with the other animals. That whole stuffed dodos were present in Europe indicates they had been brought alive and died there; it is unlikely that taxidermists were on board the visiting ships, and spirits were not yet used to preserve biological specimens. Most tropical specimens were preserved as dried heads and feet.
One dodo was reportedly sent as far as Nagasaki, Japan in 1647, but it was long unknown whether it arrived. Contemporary documents first published in 2014 proved the story, and showed that it had arrived alive. It was meant as a gift, and, despite its rarity, was considered of equal value to a white deer and a bezoar stone. It is the last recorded live dodo in captivity.
Extinction.
Like many animals that evolved in isolation from significant predators, the dodo was entirely fearless of humans. This fearlessness and its inability to fly made the dodo easy prey for sailors. Although some scattered reports describe mass killings of dodos for ships' provisions, archaeological investigations have found scant evidence of human predation. Bones of at least two dodos were found in caves at Baie du Cap that sheltered fugitive slaves and convicts in the 17th century, which would not have been easily accessible to dodos because of the high, broken terrain. The human population on Mauritius (an area of 1,860 km2) never exceeded 50 people in the 17th century, but they introduced other animals, including dogs, pigs, cats, rats, and crab-eating macaques, which plundered dodo nests and competed for the limited food resources. At the same time, humans destroyed the forest habitat of the dodos. The impact of the introduced animals on the dodo population, especially the pigs and macaques, is currently considered more severe than that of hunting. Rats were perhaps not much of a threat to the nests, since dodos would have been used to dealing with local land crabs.
It has been suggested that the dodo may already have been rare or localised before the arrival of humans on Mauritius, since it would have been unlikely to become extinct so rapidly if it had occupied all the remote areas of the island. A 2005 expedition found subfossil remains of dodos and other animals killed by a flash flood. Such mass mortalities would have further jeopardised a species already in danger of becoming extinct.
Some controversy surrounds the date of their extinction. The last widely accepted record of a dodo sighting is the 1662 report by shipwrecked mariner Volkert Evertsz of the Dutch ship "Arnhem", who described birds caught on a small islet off Mauritius, now suggested to be Amber Island:
 These animals on our coming up to them stared at us and remained quiet where they stand, not knowing whether they had wings to fly away or legs to run off, and suffering us to approach them as close as we pleased. Amongst these birds were those which in India they call Dod-aersen (being a kind of very big goose); these birds are unable to fly, and instead of wings, they merely have a few small pins, yet they can run very swiftly. We drove them together into one place in such a manner that we could catch them with our hands, and when we held one of them by its leg, and that upon this it made a great noise, the others all on a sudden came running as fast as they could to its assistance, and by which they were caught and made prisoners also.
The dodos on this islet may not necessarily have been the last members of the species. The last claimed sighting of a dodo was reported in the hunting records of Isaac Johannes Lamotius in 1688. Statistical analysis of these records by Roberts and Solow gives a new estimated extinction date of 1693, with a 95% confidence interval of 1688–1715. The authors also pointed out that because the last sighting before 1662 was in 1638, the dodo was probably already quite rare by the 1660s, and thus a disputed report from 1674 by an escaped slave cannot be dismissed out of hand.
Anthony Cheke pointed out that some descriptions after 1662 use the names "Dodo" and "Dodaers" when referring to the red rail, indicating that they had been transferred to it after the disappearance of the dodo itself. Cheke therefore points to the 1662 description as the last credible observation. A 1668 account by English traveller John Marshall, who used the names "Dodo" and "Red Hen" interchangeably for the red rail, mentioned that the meat was "hard", which echoes the description of the meat in the 1681 account. Even the 1662 account has been questioned by Errol Fuller, as the reaction to distress cries matches what was described for the red rail. Until this explanation was proposed, a description of "dodos" from 1681 was thought to be the last account, and that date still has proponents. Recently accessible Dutch manuscripts indicate that no dodos were seen by settlers in 1664–1674. It is unlikely the issue will ever be resolved, unless late reports mentioning the name alongside a physical description are rediscovered. The IUCN Red List accepts Cheke's rationale for choosing the 1662 date, taking all subsequent reports to refer to red rails. In any case, the dodo was probably extinct by 1700, about a century after its discovery in 1598. The Dutch left Mauritius in 1710, but by then the dodo and most of the large terrestrial vertebrates there had become extinct.
Even though the rareness of the dodo was reported already in the 17th century, its extinction was not recognised until the 19th century. This was partly because, for religious reasons, extinction was not believed possible until later proved so by Georges Cuvier, and partly because many scientists doubted that the dodo had ever existed. It seemed altogether too strange a creature, and many believed it a myth. The bird was first used as an example of human-induced extinction in "Penny Magazine" in 1833.
Physical remains.
17th-century specimens.
The only extant remains of dodos taken to Europe in the 17th century are a dried head and foot in the Oxford University Museum of Natural History, a foot once housed in the British Museum but now lost, a skull in the University of Copenhagen Zoological Museum, and an upper jaw and leg bones in the National Museum, Prague. The last two were rediscovered and identified as dodo remains in the mid-19th century. Several stuffed dodos were also mentioned in old museum inventories, but none are known to have survived. Apart from these remains, a dried foot, which belonged to the Dutch professor Pieter Pauw, was mentioned by Carolus Clusius in 1605. Its provenance is unknown, and it is now lost, but it may have been collected during the Van Neck voyage.
The only known soft tissue remains, the Oxford head (specimen OUM 11605) and foot, belonged to the last known stuffed dodo, which was first mentioned as part of the Tradescant collection in 1656 and was moved to the Ashmolean Museum in 1659. It has been suggested that this might be the remains of the bird that Hamon L'Estrange saw in London. Many sources state that the museum burned the stuffed dodo around 1755 because of severe decay, saving only the head and leg. Statute 8 of the museum states "That as any particular grows old and perishing the keeper may remove it into one of the closets or other repository; and some other to be substituted." The deliberate destruction of the specimen is now believed to be a myth; it was removed from exhibition to preserve what remained of it. This remaining soft tissue has since degraded further; the head was dissected by Strickland and Melville, separating the skin from the skull in two halves. The foot is in a skeletal state, with only scraps of skin and tendons. Very few feathers remain on the head. It is probably a female, as the foot is 11% smaller and more gracile than that of the London specimen, yet appears to be fully grown.
The dried London foot, first mentioned in 1665, and transferred to the British Museum in the 18th century, was displayed next to Savery's "Edwards's Dodo" painting until the 1840s, and it too was dissected by Strickland and Melville. It was not posed in a standing posture, which suggests that it was severed from a fresh specimen, not a mounted one. By 1896 it was mentioned as being without its integuments, and only the bones are believed to remain today, though its present whereabouts are unknown.
The Copenhagen skull (specimen ZMUC 90-806) is known to have been part of the collection of Bernardus Paludanus in Enkhuizen until 1651, when it was moved to the museum in Gottorf Castle, Schleswig. After the castle was occupied by Danish forces in 1702, the museum collection was assimilated into the Royal Danish collection. The skull was rediscovered by J. T. Reinhardt in 1840. Based on is history, it may be the oldest known surviving remains of a dodo brought to Europe in the 17th century. It is 13 mm shorter than the Oxford skull, and may have belonged to a female. It was mummified, but the skin has perished.
The front part of a skull (specimen NMP P6V-004389) and some leg bones in the National Museum of Prague were found in 1850 among the remains of the Böhmisches Museum. It may be what remains of one of the stuffed dodos known to have been at the menagerie of Emperor Rudolph II, possibly the specimen painted by Hoefnagel or Savery there.
Subfossil specimens.
Until 1860, the only known dodo remains were the four incomplete 17th-century specimens. Philip Burnard Ayres found the first subfossil bones in 1860, which were sent to Richard Owen at the British Museum, who did not publish the findings. In 1863, Owen requested the Mauritian Bishop Vincent Ryan to spread word that he should be informed if any dodo bones were found. In 1865, George Clark, the government schoolmaster at Mahébourg, finally found an abundance of subfossil dodo bones in the swamp of Mare aux Songes in Southern Mauritius, after a 30-year search inspired by Strickland and Melville's monograph. In 1866, Clark explained his procedure to "The Ibis", an ornithology journal: he had sent his coolies to wade through the centre of the swamp, feeling for bones with their feet. At first they found few bones, until they cut away herbage that covered the deepest part of the swamp, where they found many fossils. The swamp yielded the remains of over 300 dodos, but very few skull and wing bones, possibly because the upper bodies were washed away or scavenged while the lower body was trapped. The situation is similar to many finds of moa remains in New Zealand marshes. Most dodo remains from the Mare aux Songes have a medium to dark brown colouration.
Clark's reports about the finds rekindled interest in the bird. Sir Richard Owen and Alfred Newton both wanted to be first to describe the post-cranial anatomy of the dodo, and Owen bought a shipment of dodo bones originally meant for Newton, which led to rivalry between the two. Owen described the bones in "Memoir on the Dodo" in October 1866, but erroneously based his reconstruction on the "Edwards's Dodo" painting by Savery, making it too squat and obese. In 1869 he received more bones and corrected its stance, making it more upright. Newton moved his focus to the Réunion solitaire instead. The remaining bones not sold to Owen or Newton were auctioned off or donated to museums. In 1889, Théodor Sauzier was commissioned to explore the "historical souvenirs" of Mauritius and find more dodo remains in the Mare aux Songes. He was successful, and also found remains of other extinct species.
In October 2005, after a hundred years of neglect, a part of the Mare aux Songes swamp was excavated by an international team of researchers. To prevent malaria, the British had covered the swamp with hard core during their rule over Mauritius, which had to be removed. Many remains were found, including bones of at least 17 dodos in various stages of maturity (though no juveniles), and several bones obviously from the skeleton of one individual bird, which have been preserved in their natural position. These findings were made public in December 2005 in the Naturalis museum in Leiden. 63% of the fossils found in the swamp belonged to turtles of the extinct "Cylindraspis" genus, and 7.1% belonged to dodos, which had been deposited within several centuries, 4,000 years ago. Subsequent excavations suggested that dodos and other animals became mired in the Mare aux Songes while trying to reach water during a long period of severe drought about 4,200 years ago. Furthermore, cyanobacteria thrived in the conditions created by the excrements of animals gathered around the swamp, which died of intoxication, dehydration, trampling, and miring. Though many small skeletal elements were found during the recent excavations of the swamp, few were found during the 19th century, probably owing to the employment of less refined methods when collecting. In June 2007, adventurers exploring a cave in Mauritius discovered the most complete and best-preserved dodo skeleton ever found. The specimen was nicknamed "Fred" after the finder.
Louis Etienne Thirioux, an amateur naturalist at Port Louis, also found many dodo remains around 1900 from several locations. They included the first articulated specimen, which is also the only subfossil dodo found outside the Mare aux Songes, and the only remains of a juvenile specimen, a now lost tarsometatarsus. The former specimen was found in 1904 in a cave near Le Pouce mountain, and is the only complete skeleton of an individual dodo, and includes the only preserved kneecaps of the bird. Thirioux donated it to the Museum Desjardins (now Natural History Museum at Mauritius Institute), where it is still on display. In 2014, this specimen was the basis for the first 3-D reconstruction of a complete dodo skeleton, by using 3-D laser scanning technology. The reconstruction was displayed in Berlin at the 74th Annual Meeting of the Society of Vertebrate Palaeontology.
Worldwide, 26 museums have significant holdings of dodo material, almost all found in the Mare aux Songes. The Natural History Museum, American Museum of Natural History, Cambridge University Museum of Zoology, the Senckenberg Museum, and others have almost complete skeletons, assembled from the dissociated subfossil remains of several individuals. In 2011, a wooden box containing dodo bones from the Edwardian era was rediscovered at the Grant Museum at University College London during preparations for a move. They had been stored with crocodile bones until then.
The white dodo.
The supposed "white dodo" (or "solitaire") of Réunion is now considered an erroneous conjecture based on contemporary reports of the Réunion ibis and 17th-century paintings of white, dodo-like birds by Pieter Withoos and Pieter Holsteyn that surfaced in the 19th century. The confusion began when Willem Ysbrandtszoon Bontekoe, who visited Réunion around 1619, mentioned fat, flightless birds that he referred to as "Dod-eersen" in his journal, though without mentioning their colouration. When the journal was published in 1646, it was accompanied by an engraving of a dodo from Savery's "Crocker Art Gallery sketch". A white, stocky, and flightless bird was first mentioned as part of the Réunion fauna by Chief Officer J. Tatton in 1625. Sporadic mentions were subsequently made by Sieur Dubois and other contemporary writers.
Baron Edmond de Sélys Longchamps coined the name "Raphus solitarius" for these birds in 1848, as he believed the accounts referred to a species of dodo. When 17th-century paintings of white dodos were discovered by 19th-century naturalists, it was assumed they depicted these birds. Anthonie Cornelis Oudemans suggested that the discrepancy between the paintings and the old descriptions was that the paintings showed females, and that the species was therefore sexually dimorphic. Some authors also believed the birds described were of a species similar to the Rodrigues solitaire, as it was referred to by the same name, or even that there were white species of both dodo and solitaire on the island.
The Pieter Withoos painting, which was discovered first, appears to be based on an earlier painting by Pieter Holsteyn, three versions of which are known to have existed. According to Hume, Cheke, and Valledor de Lozoya, it appears that all depictions of white dodos were based on Roelant Savery's 1611 painting "Landscape with Orpheus and the animals", or on copies of it. The painting shows a whitish specimen and was apparently based on a stuffed specimen then in Prague; a "walghvogel" described as having a "dirty off-white colouring" was mentioned in an inventory of specimens in the Prague collection of the Holy Roman Emperor Rudolf II, to whom Savery was contracted at the time (1607–1611). Savery's several later images all show greyish birds, possibly because he had by then seen another specimen. Cheke and Hume believe the painted specimen was white, owing to albinism. Valledor de Lozoya has instead suggested that the light plumage was a juvenile trait, a result of bleaching of old taxidermy specimens, or simply artistic license.
In 1987, scientists described fossils of a recently extinct species of ibis from Réunion with a relatively short beak, "Borbonibis latipes", before a connection to the solitaire reports had been made. Cheke suggested to one of the authors, Francois Moutou, that the fossils may have been of the Réunion solitaire, and this suggestion was published in 1995. The ibis was reassigned to the genus "Threskiornis", now combined with the specific epithet "solitarius" from the binomial "R. solitarius". Birds of this genus are also white and black with slender beaks, fitting the old descriptions of the Réunion solitaire. No fossil remains of dodo-like birds have ever been found on the island.
Cultural significance.
The dodo's significance as one of the best-known extinct animals and its singular appearance led to its use in literature and popular culture as a symbol of an outdated concept or object, as in the expression "dead as a dodo," which has come to mean unquestionably dead or obsolete. Similarly, the phrase "to go the way of the dodo" means to become extinct or obsolete, to fall out of common usage or practice, or to become a thing of the past. In 1865, the same year that George Clark started to publish reports about excavated dodo fossils, the newly vindicated bird was featured as a character in Lewis Carroll's "Alice's Adventures in Wonderland". It is thought that he included the dodo because he identified with it and had adopted the name as a nickname for himself because of his stammer, which made him accidentally introduce himself as "Do-do-dodgson", his legal surname. The book's popularity made the dodo a well-known icon of extinction. Even before its extinction, the dodo was frequently featured in European literature, and was used as symbol for exotic lands, and of gluttony, due to its apparent fatness.
Today, the dodo appears frequently in works of popular fiction and is used as a mascot for many kinds of products, especially in Mauritius. The dodo appears as a supporter on the coat of arms of Mauritius. It is also used as a watermark on all Mauritian rupee banknotes. A smiling dodo is the symbol of the Brasseries de Bourbon, a popular brewer on Réunion, whose emblem displays the white species once thought to have lived there.
The dodo is used to promote the protection of endangered species by many environmental organisations, such as the Durrell Wildlife Conservation Trust and the Durrell Wildlife Park. In 2011, the nephilid spider "Nephilengys dodo", which inhabits the same woods as the dodo once did, was named after the bird to raise awareness of the urgent need for protection of the Mauritius biota. The name dodo has also been immortalized by scientists naming genetic elements, honoring the dodo's flightless nature. A fruitfly gene within a region of a chromosome required for flying ability was named "dodo". In addition, a defective transposable element family from "Phytophthora infestans" was named "DodoPi" as it contained mutations that eliminated the element's ability to jump to new locations in a chromosome.
In 2009, a previously unpublished 17th-century Dutch illustration of a dodo went for sale at Christie's and was expected to sell for £6,000. It is unknown whether the illustration was based on a specimen or on a previous image. It sold for £44,450.
The poet Hilaire Belloc included the following poem about the dodo in his "Bad Child's Book of Beasts" from 1896:
 <poem>
The Dodo used to walk around,
And take the sun and air.
The sun yet warms his native ground –
The Dodo is not there!
</poem><poem>
The voice which used to squawk and squeak
Is now for ever dumb –
Yet may you see his bones and beak
All in the Mu-se-um.
</poem>
References.
Footnotes.
</dl>
Sources.
</dl>

</doc>
<doc id="8421" url="http://en.wikipedia.org/wiki?curid=8421" title="Sideroxylon grandiflorum">
Sideroxylon grandiflorum

Sideroxylon grandiflorum, known as tambalacoque or dodo tree, is a long-lived tree in the family Sapotaceae, endemic to Mauritius. It is valued for its timber.
The "Sideroxylon grandiflorum" fruit is analogous to the peach. They are both termed drupes because both have a hard endocarp, or pit, surrounding the seed, with the endocarp naturally splitting along a fracture line during germination.
In 1973, it was thought that this species was dying out. There were supposedly only 13 specimens left, all estimated to be about 300 years old. The true age could not be determined because tambalacoque has no growth rings. Stanley Temple hypothesized that the dodo, which became extinct in the 17th century, ate tambalacoque fruits, and only by passing through the digestive tract of the dodo could the seeds germinate. Temple (1977) force-fed seventeen tambalacoque fruits to wild turkeys. Seven of the fruits were crushed by the bird's gizzard. The remaining ten were either regurgitated or passed with the bird's feces. Temple planted the remaining ten fruits and three germinated. Temple did not try to germinate any seeds from control fruits not fed to turkeys so the effect of feeding fruits to turkeys was unclear. Reports made on tambalacoque seed germination by Hill (1941) and King (1946) found the seeds germinated without abrading.
Temple's hypothesis that the tree required the dodo has been contested. Others have suggested the decline of the tree was exaggerated, or that other extinct animals may also have been distributing the seeds, such as tortoises, fruit bats or the broad-billed parrot. Wendy Strahm and Anthony Cheke, two experts in Mascarene ecology, claim that while a rare tree, it has germinated since the demise of the dodo and numbers a few hundred, not 13. The difference in numbers is because young trees are not distinct in appearance and may easily be confused with similar species. The decline of the tree may possibly be due to introduction of domestic pigs and crab-eating macaques and competition with introduced plants. Catling (2001) in a summary cites Owadally and Temple (1979), and Witmer (1991). Hershey (2004) reviewed the flaws in Temple's dodo-tambalacoque hypothesis.
In 2004, Botanical Society of America's Plant Science Bulletin disputed Dr. Temple's research as flawed which published evidence as to why the dodo's extinction did not directly cause the increasing disappearance of young trees including suggestion that tortoises would have been more likely to disperse the seeds than dodo hence discrediting Temple's view as to the dodo and the tree's sole survival relationship.
. This tree is highly valued for its wood in Mauritius, which has led some foresters to scrape the pits by hand to make them sprout and grow.

</doc>
<doc id="8425" url="http://en.wikipedia.org/wiki?curid=8425" title="Dwight Schultz">
Dwight Schultz

William Dwight Schultz (born November 24, 1947) is an American stage, television, film actor and voice artist. He is best known for his roles as Captain "Howling Mad" Murdock on the 1980s action series "The A-Team", and as Reginald Barclay in ', ' and the film "". He is also well known in animation as the mad scientist Dr. Animo in the "Ben 10" series, Chef Mung Daal in the children's cartoon "Chowder", and Eddie the Squirrel in "CatDog".
Early life.
Schultz was born in Baltimore, Maryland. He is an alumnus of Towson University.
Career.
Schultz's breakthrough role was the character of Captain "Howling Mad" Murdock on "The A-Team". Schultz has also appeared in films including "The Fan" (1981) with Broadway Actress Lauren Bacall, and starred in "Fat Man and Little Boy" (1989), as J. Robert Oppenheimer.
He auditioned for the part of Dr. Wayne Fiscus on the television show "St. Elsewhere", but lost out to Howie Mandel.
In the early 1990s, he had a recurring role as Lieutenant Reginald Barclay in '. Schultz reprised the role for a few episodes of ' and the film "".
In November 2009, he confirmed that he (and former A-Team co-star, Dirk Benedict) would have a cameo in the feature film "The A-Team", however, both Schultz's and Benedict's parts were ultimately cut from the film proper, but placed after the credits of the theatrical showing as an easter egg.
He was the host of a conservative talk radio podcast called "Howling Mad Radio", which ended in March 2009. Schultz has also guest hosted for Michael Savage on "The Savage Nation," Jerry Doyle on "The Jerry Doyle Show", and Rusty Humphries on "The Rusty Humphries Show" on numerous occasions.
Personal life.
Schultz married former actress Wendy Fulton ("Bare Essence") in 1983. They have one daughter, Ava (b. 1987), who serves in the Marines. Schultz is a Christian of German descent.
Schultz is a conservative and in 2012 began regular appearances on "The Glazov Gang", an internet political talk show hosted by Jamie Glazov, the managing editor of FrontPage Magazine. He also posts political commentaries and podcasts on his official fansite.

</doc>
<doc id="8429" url="http://en.wikipedia.org/wiki?curid=8429" title="Density">
Density

 
The density, or more precisely, the volumetric mass density, of a substance is its mass per unit volume. The symbol most often used for density is ρ (the lower case Greek letter rho), although the latin letter "D" can also be used. Mathematically, density is defined as mass divided by volume:
where "ρ" is the density, "m" is the mass, and "V" is the volume. In some cases (for instance, in the United States oil and gas industry), density is loosely defined as its weight per unit volume, although this is scientifically inaccurate – this quantity is more specifically called specific weight.
For a pure substance the density has the same numerical value as its mass concentration.
Different materials usually have different densities, and density may be relevant to buoyancy, purity and packaging. Osmium and iridium are the densest known elements at standard conditions for temperature and pressure but certain chemical compounds may be denser.
To simplify comparisons of density across different systems of units, it is sometimes replaced by the dimensionless quantity "relative density" or "specific gravity", i.e. the ratio of the density of the material to that of a standard material, usually water. Thus a relative density less than one means that the substance floats in water.
The density of a material varies with temperature and pressure. This variation is typically small for solids and liquids but much greater for gases. Increasing the pressure on an object decreases the volume of the object and thus increases its density. Increasing the temperature of a substance (with a few exceptions) decreases its density by increasing its volume. In most materials, heating the bottom of a fluid results in convection of the heat from the bottom to the top, due to the decrease in the density of the heated fluid. This causes it to rise relative to more dense unheated material.
The reciprocal of the density of a substance is occasionally called its specific volume, a term sometimes used in thermodynamics. Density is an intensive property in that increasing the amount of a substance does not increase its density; rather it increases its mass.
History.
In a well-known but probably apocryphal tale, Archimedes was given the task of determining whether King Hiero's goldsmith was embezzling gold during the manufacture of a golden wreath dedicated to the gods and replacing it with another, cheaper alloy. Archimedes knew that the irregularly shaped wreath could be crushed into a cube whose volume could be calculated easily and compared with the mass; but the king did not approve of this. Baffled, Archimedes is said to have taken an immersion bath and observed from the rise of the water upon entering that he could calculate the volume of the gold wreath through the displacement of the water. Upon this discovery, he leapt from his bath and ran naked through the streets shouting, "Eureka! Eureka!" (Εύρηκα! Greek "I have found it"). As a result, the term "eureka" entered common parlance and is used today to indicate a moment of enlightenment.
The story first appeared in written form in Vitruvius' "books of architecture", two centuries after it supposedly took place. Some scholars have doubted the accuracy of this tale, saying among other things that the method would have required precise measurements that would have been difficult to make at the time.
From the equation for density ("ρ" = "m" / "V"), mass density has units of mass divided by volume. As there are many units of mass and volume covering many different magnitudes there are a large number of units for mass density in use. The SI unit of kilogram per cubic metre (kg/m3) and the cgs unit of gram per cubic centimetre (g/cm3) are probably the most commonly used units for density.1,000 kg/m3 equals 1 g/cm3. (The cubic centimeter can be alternately called a "millilitre" or a "cc".) In industry, other larger or smaller units of mass and or volume are often more practical and US customary units may be used. See below for a list of some of the most common units of density.
Measurement of density.
Homogeneous materials.
The density at all points of a homogeneous object equals its total mass divided by its total volume. The mass is normally measured with a scale or balance; the volume may be measured directly (from the geometry of the object) or by the displacement of a fluid. To determine the density of a liquid or a gas, a hydrometer, a dasymeter or a Coriolis flow meter may be used, respectively. Similarly, hydrostatic weighing uses the displacement of water due to a submerged object to determine the density of the object.
Heterogeneous materials.
If the body is not homogeneous, then its density varies between different regions of the object. In that case the density around any given location is determined by calculating the density of a small volume around that location. In the limit of an infinitesimal volume the density of an inhomogeneous object at a point becomes: , where dV is an elementary volume at position r. The mass of the body then can be expressed as
Non-compact materials.
In practice, bulk materials such as sugar, sand, or snow contain voids. Many materials exist in nature as flakes, pellets, or granules. 
Voids are regions which contain something other than the considered material. Commonly the void is air, but it could also be vacuum, liquid, solid, or a different gas or gaseous mixture. 
The bulk volume of a material—inclusive of the void fraction—is often obtained by a simple measurement (e.g. with a calibrated measuring cup) or geometrically from known dimensions. 
Mass divided by "bulk" volume determines bulk density. This is not the same thing as volumetric mass density. 
To determine volumetric mass density, one must first discount the volume of the void fraction. Sometimes this can be determined by geometrical reasoning. For the close-packing of equal spheres the non-void fraction can be at most about 74%. It can also be determined empirically. Some bulk materials, however, such as sand, have a "variable" void fraction which depends on how the material is agitated or poured. It might be loose or compact, with more or less air space depending on handling. 
In practice, the void fraction is not necessarily air, or even gaseous. In the case of sand, it could be water, which can be advantageous for measurement as the void fraction for sand saturated in water—once any air bubbles are thoroughly driven out—is potentially more consistent than dry sand measured with an air void. 
In the case of non-compact materials, one must also take care in determining the mass of the material sample. If the material is under pressure (commonly ambient air pressure at the earth's surface) the determination of mass from a measured sample weight might need to account for buoyancy effects due to the density of the void constituent, depending on how the measurement was conducted. In the case of dry sand, sand is so much denser than air that the buoyancy effect is commonly neglected (less than one part in one thousand).
Mass change upon displacing one void material with another while maintaining constant volume can be used to estimate the void fraction, if the difference in density of the two voids materials is reliably known.
Changes of density.
In general, density can be changed by changing either the pressure or the temperature. Increasing the pressure always increases the density of a material. Increasing the temperature generally decreases the density, but there are notable exceptions to this generalization. For example, the density of water increases between its melting point at 0 °C and 4 °C; similar behavior is observed in silicon at low temperatures.
The effect of pressure and temperature on the densities of liquids and solids is small. The compressibility for a typical liquid or solid is 10−6 bar−1 (1 bar = 0.1 MPa) and a typical thermal expansivity is 10−5 K−1. This roughly translates into needing around ten thousand times atmospheric pressure to reduce the volume of a substance by one percent. (Although the pressures needed may be around a thousand times smaller for sandy soil and some clays.) A one percent expansion of volume typically requires a temperature increase on the order of thousands of degrees Celsius.
In contrast, the density of gases is strongly affected by pressure. The density of an ideal gas is
where M is the molar mass, P is the pressure, R is the universal gas constant, and T is the absolute temperature. This means that the density of an ideal gas can be doubled by doubling the pressure, or by halving the absolute temperature.
In the case of volumic thermal expansion at constant pressure and small intervals of temperature the temperature dependence of density is :
where formula_5 is the density at a reference temperature, formula_6 is the thermal expansion coefficient of the material at temperatures close to formula_7.
Density of solutions.
The density of a solution is the sum of mass (massic) concentrations of the components of that solution.
Mass (massic) concentration of each given component ρi in a solution sums to density of the solution.
Expressed as a function of the densities of pure components of the mixture and their volume participation, it allows the determination of excess molar volumes:
provided that there is no interaction between the components.
Knowing the relation between excess volumes and activity coefficients of the components, one can determine the activity coefficients.
Common units.
The SI unit for density is:
Litres and metric tons are not part of the SI, but are acceptable for use with it, leading to the following units:
Densities using the following metric units all have exactly the same numerical value, one thousandth of the value in (kg/m3). Liquid water has a density of about 1 kg/dm3, making any of these SI units numerically convenient to use as most solids and liquids have densities between 0.1 and 20 kg/dm3.
In US customary units density can be stated in:
Imperial units differing from the above (as the Imperial gallon and bushel differ from the US units) in practice are rarely used, though found in older documents. The density of precious metals could conceivably be based on Troy ounces and pounds, a possible cause of confusion.

</doc>
<doc id="8432" url="http://en.wikipedia.org/wiki?curid=8432" title="Dave Barry">
Dave Barry

David McAlister "Dave" Barry (born July 3, 1947) is a Pulitzer Prize-winning American author and columnist, who wrote a nationally syndicated humor column for "The Miami Herald" from 1983 to 2005. He has also written numerous books of humor and parody, as well as comedic novels.
Early life and education.
Barry was born in Armonk, New York where his father, David, was a Presbyterian minister. He was educated at Wampus Elementary School, Harold C. Crittenden Junior High School (both in Armonk), and Pleasantville High School where he was elected "Class Clown" in 1965. He earned a Bachelor of Arts degree in English from Haverford College in 1969.
As an alumnus of a Quaker-affiliated college, he avoided military service during the Vietnam War by registering as a religious conscientious objector. Notwithstanding his father's vocation, Dave decided "early on" that he was an atheist. He said, "The problem with writing about religion is that you run the risk of offending sincerely religious people, and then they come after you with machetes."
Writing career.
Dave Barry began his journalism career in 1971, working as a general assignment reporter for the "Daily Local News" in West Chester, Pennsylvania, near his alma mater, Haverford College. He covered local government and civic events and was promoted to City Editor after about two years. He also started writing a weekly humor column for the paper and began to develop his unique style. He remained at the newspaper through 1974. He then worked briefly as a copy editor at the Associated Press' Philadelphia bureau before joining Burger Associates, a consulting firm. 
At Burger, he taught effective writing to business people. In his own words, he "spent nearly eight years trying to get various businesspersons to...stop writing things like 'Enclosed please find the enclosed enclosures,' but...eventually realized that it was hopeless."
In 1981 he wrote a humorous guest column (about watching the birth of his son) in the "Philadelphia Inquirer", which attracted the attention of Gene Weingarten, then an editor of the "Miami Herald"'s Sunday magazine "Tropic". Weingarten hired Barry as a humor columnist in 1983; Barry's column was syndicated nationally. Barry won a Pulitzer Prize for Commentary in 1988 "for his consistently effective use of humor as a device for presenting fresh insights into serious concerns."
Barry's first novel, "Big Trouble", was published in 1999. The book was adapted into a motion picture directed by Barry Sonnenfeld and starring Tim Allen, Rene Russo, and Patrick Warburton, with a cameo by Barry. The movie was originally due for release in September 2001 but was postponed following the September 11, 2001 attacks because the story involved smuggling a nuclear weapon onto an airplane. The film was released in April 2002.
In response to a column in which Barry mocked the cities of Grand Forks, North Dakota and East Grand Forks, Minnesota for calling themselves the "Grand Cities", Grand Forks named a sewage pumping station after Barry in January 2002. Barry traveled to Grand Forks for the dedication ceremony.
Articles written by Barry have appeared in publications such as "Boating", "Home Office Computing", and "Reader's Digest", in addition to the "Chicken Soup for the Soul" inspirational book series. Two of his articles have been included in the "Best American Sportswriting" series. One of his columns was used as the introduction to the book "Pirattitude!: So You Wanna Be a Pirate? Here's How!" (ISBN 0-451-21649-0), a follow-up to Barry's role in publicizing International Talk Like a Pirate Day. His books have frequently appeared on the "New York Times" Best Seller List.
On October 31, 2004, Dave Barry announced that he would be taking an indefinite leave of absence of at least a year from his weekly column in order to spend more time with his family. In December 2005, Barry said in an interview with "Editor and Publisher" that he would not resume his weekly column, although he would continue such features as his yearly gift guide, his year-in-review feature, and his blog, as well as an occasional article or column.
On Sunday, September 22, 2013, the opening night of the 15th annual Fall for the Book festival in Fairfax, Virginia, Barry was awarded the event's highest honor, the Fairfax Prize honoring outstanding literary achievement and presented by the Fairfax Library Foundation.
"Dave's World" television series.
From 1993 to 1997, CBS broadcast the sitcom "Dave's World" based on the books "Dave Barry Turns 40" and "Dave Barry's Greatest Hits". The show starred Harry Anderson as Barry and DeLane Matthews as his wife Beth. In an early episode, Barry appeared in a cameo role. After four seasons, the program was canceled shortly after being moved from Monday to the "Friday night death slot".
Music.
During college, Barry was in a band called the Federal Duck. While at the "Miami Herald", he and several of his colleagues created a band called the Urban Professionals; with Barry on lead guitar and vocals, they performed an original song called "The Tupperware Song" at the Tupperware headquarters in Orlando, Florida.
Beginning in 1992, Barry played lead guitar in the Rock Bottom Remainders, a rock band made up of published authors. (Remainder is a publishing term for a book that doesn't sell.) The band was founded by Barry's sister-in-law Kathi Kamen Goldmark for an American Booksellers Association convention, and has also included Stephen King, Amy Tan, Ridley Pearson, Scott Turow, Mitch Albom, Roy Blount, Jr., Barbara Kingsolver, Matt Groening, and Barry’s brother Sam, among others. The band's members "are not musically skilled, but they are extremely loud," according to Barry. Several high-profile musicians, including Al Kooper, Warren Zevon, and Roger McGuinn, have performed with the band, and Bruce Springsteen sat in at least once. The band's road tour resulted in the book "Mid-Life Confidential: The Rock Bottom Remainders Tour America with Three Chords and an Attitude". The Rock Bottom Remainders disbanded in 2012 following Goldmark's death from breast cancer.
Other activities.
Beginning in 1984, Barry and "Tropic" editors Gene Weingarten and Tom Shroder have organized the Tropic Hunt (now the Herald Hunt), an annual puzzlehunt in Miami. A Washington, D.C., spinoff, the Post Hunt, began in 2008.
Barry has run several mock campaigns for President of the United States, running on a libertarian platform. He has also written for the Libertarian Party's national newsletter.
The screen adaptation of Barry's book "Dave Barry's Complete Guide to Guys" was released in 2005; it premiered at several film festivals and is available on DVD.
Style.
Barry has defined a sense of humor as "a measurement of the extent to which we realize that we are trapped in a world almost totally devoid of reason. Laughter is how we express the anxiety we feel at this knowledge."
When distinguishing fact from hyperbole, Barry frequently asserts: "I am not making this up." Among his favorite topics are exploding or flaming items (cows, whales, vacuum cleaners, toilets, Pop-Tarts, Barbie dolls, etc.), dogs lacking intelligence, live blogging the television series "24", and amusing government studies. He labels various posts on his blog with long acronyms, such as WBAGNFARB ("would be a good name for a rock band"), poking fun at long internet abbreviations.
He also enjoys making fun of South Florida, where he resides. In "Dave Barry Hits Below the Beltway", he suggested that many of America's problems could be solved if South Florida were literally sawed off from the mainland and disowned by the United States. He has also made fun of the region in "Homes and Other Black Holes" as well as other books. Even his novels "Big Trouble" and "Tricky Business" capitalize heavily in the absurdities that exist only in South Florida. In "Big Trouble", for example, the ridiculous nuances of South Florida are expressed through the experiences of the two hit men, Henry and Leonard. They experience an irritating sports talk show host, a highly incompetent airport security detail, and an attack by a python by the name of Daphne in the same airport before deciding that they never want to return to Florida again. Barry also uses "Big Trouble" to poke fun at the existence of a Russian arms black market, the corrupt political system (Puggy makes a living off being paid to vote), and the incredibly loose labor laws in the region.
The phrase "would be a good name for a rock band" is an observation Barry often applies to phrases that pop up in his writing, such as "The Moos of Derision", "Decomposing Tubers" and "Hearty Polyp Chuckles". In keeping with this, Barry's website contains a fairly sizable list of phrases that he claims would be good names for a rock band.
In his humor books, Barry often cites a humorous phrase or image, which he then mercilessly repeats throughout. Notable examples include the Hawley-Smoot Tariff in "," Buffalo Bob in "Dave Barry Turns 50," and giant prehistoric zucchini in "Dave Barry Hits Below the Beltway", e.g., "Growth of U.S. government according to Alan Greenspan=giant prehistoric zucchini." He continues to reference these things, occasionally with fake subtlety, e.g., "The H*****-S**** T*****".
His novels typically feature numerous initially unrelated subplots, many related to criminal activity, which slowly intertwine over the course of the story. Many critics explicitly compare this style to that of Elmore Leonard, though with a more comedic tone.
Personal life.
Barry married his second wife, Beth Lenox, in 1976. Barry and Lenox worked together at the "Daily Local News", where they began their journalism careers on the same day in September 1971; they had one child, Robert. Barry and Lenox divorced in 1993. In 1996, Barry married "Miami Herald" sportswriter Michelle Kaufman; they had a daughter, Sophie, in 2000. Barry has had dogs named Earnest, Zippy, and now Lucy. All have been mentioned regularly in Barry's columns. 

</doc>
<doc id="8436" url="http://en.wikipedia.org/wiki?curid=8436" title="David Angell">
David Angell

David Lawrence Angell (April 10, 1946 – September 11, 2001) was an American producer of sitcoms. Angell won multiple Emmy Awards as the creator and executive producer, along with Peter Casey and David Lee, of the comedy series "Frasier". Angell and his wife Lynn both died aboard American Airlines Flight 11, the first plane to hit the World Trade Center, during the September 11 attacks.
Early life and education.
Angell was born in West Barrington, Rhode Island to Henry and Mae (née Cooney) Angell. He received a bachelor's degree in English Literature from Providence College. He entered the U.S. Army upon graduation and served at the Pentagon until 1972. He then moved to Boston and worked as a methods analyst at an engineering company and later at an insurance firm in Rhode Island. His brother, the Most Rev. Kenneth Angell, is a Roman Catholic prelate and former Bishop of Burlington, Vermont.
Career.
Angell moved to Los Angeles in 1977. His first script was sold to the producers of the "Annie Flynn" series. Five years later, he sold his second script to "Archie Bunker's Place". In 1983, he joined "Cheers" as a staff writer. In 1985, Angell joined forces with Peter Casey and David Lee as "Cheers" supervising producers/writers. The trio received 37 Emmy Award nominations and won 24 Emmy Awards, including the above-mentioned for "Frasier", as well as an Outstanding Comedy Series Emmy for "Cheers", in 1989, which Angell, Casey, Lee and the series' other producers shared, and Outstanding Writing/Comedy Emmy for "Cheers", which Angell received in 1984. After working together as producers on "Cheers", Angell, Casey and Lee formed Grub Street Productions. In 1990, they created and executive-produced the comedy series "Wings".
Death.
Angell and his wife, Lynn, were among the passengers of American Airlines Flight 11 who were killed in the September 11 attacks, when the plane was hijacked and flown into the North Tower of the World Trade Center in New York City in 2001.
Legacy.
The American Screenwriters Association awards the annual David Angell Humanitarian Award to any individual in the entertainment industry who contributes to global well-being through donations of time, expertise or other support to improve the human condition. 
Season 9, Episode 2, of "Frasier (Don Juan in Hell: Part 2)", airing on September 25, 2001, ended with the memorial tribute, "In living memory of our friends Lynn and David Angell".
At the National 9/11 Memorial, Angell and his wife are memorialized at the North Pool, on Panel N-1, along with other passengers from Flight 11.

</doc>
<doc id="8437" url="http://en.wikipedia.org/wiki?curid=8437" title="Diedrich Hermann Westermann">
Diedrich Hermann Westermann

Diedrich Hermann Westermann (June 24, 1875–May 31, 1956) was a German missionary, Africanist, and linguist. He substantially extended and revised the work of Carl Meinhof, his teacher, although he rejected some of Meinhof's theories only implicitly. Westermann is seen as one of the founders of modern African linguistics. 
He carried out extensive linguistic and anthropological research in the area ranging from Senegal eastwards to the Upper Nile. His linguistic publications cover a wide range of African languages, including the Gbe languages, Nuer, Kpelle, Shilluk, Hausa, and Guang. 
Westermann's comparative work, begun in 1911, initially brought together much of today's Niger–Congo and Nilo-Saharan language phyla under the name Sudanic languages. His most important later publication "Die westlichen Sudansprachen" 1927a divided these into East and West Sudanic languages and laid the basis for what would become Niger–Congo. In this book and a series of associated articles between 1925 and 1928, Westermann both identified a large number of roots that form the basis of our understanding of Niger–Congo and set out the evidence for the coherence of many of the families that constitute it. Much of the classification of African languages associated with Joseph Greenberg actually derives from the work of Westermann.
In 1927 Westermann published a "Practical Orthography of African Languages" which became later known as the "Westermann script". Subsequently he published the influential and oft-reprinted "Practical Phonetics for Students of African Languages" in collaboration with Ida C. Ward (1933).
He was born in Baden near Bremen and also died there.

</doc>
<doc id="8439" url="http://en.wikipedia.org/wiki?curid=8439" title="Diacritic">
Diacritic

A diacritic – also diacritical mark, diacritical point, or diacritical sign – is a glyph added to a letter, or basic glyph. The term derives from the Greek "διακριτικός" ("diakritikós", "distinguishing"), which is composed of the ancient Greek "διά" ("diá", through) and "κρίνω" ("krínein" or "kríno", to separate). "Diacritic" is primarily an adjective, though sometimes used as a noun, whereas "diacritical" is only ever an adjective. Some diacritical marks, such as the acute ( ´ ) and grave ( ` ), are often called "accents". Diacritical marks may appear above or below a letter, or in some other position such as within the letter or between two letters.
The main use of diacritical marks in the Latin script is to change the sound-values of the letters to which they are added. Examples from English are the diaereses in "naïve" and "Noël", which show that the vowel with the diaeresis mark is pronounced separately from the preceding vowel; the acute and grave accents, which can indicate that a final vowel is to be pronounced, as in "saké" and poetic "breathèd"; and the cedilla under the "c" in the borrowed French word "façade", which shows it is pronounced /s/ rather than /k/. In other Latin alphabets, they may distinguish between homonyms, such as the French "là" ("there") versus "la" ("the"), which are both pronounced [la]. In Gaelic type, a dot over a consonant indicates lenition of the consonant in question.
In other alphabetic systems, diacritical marks may perform other functions. Vowel pointing systems, namely the Arabic harakat ( ـَ, ـُ, ـُ, etc.) and the Hebrew niqqud ( ַ, ֶ, ִ, ֹ , ֻ, etc.) systems, indicate sounds (vowels and tones) that are not conveyed by the basic alphabet. The Indic virama ( ् etc.) and the Arabic sukūn ( ـْـ ) mark the absence of a vowel. Cantillation marks indicate prosody. Other uses include the Early Cyrillic titlo ( ◌҃ ) and the Hebrew gershayim ( ״ ), which, respectively, mark abbreviations or acronyms, and Greek diacritical marks, which showed that letters of the alphabet were being used as numerals. In the Hanyu Pinyin official romanization system for Chinese, diacritics are used to mark the tones of the syllables in which the marked vowels occur.
In orthography and collation, a letter modified by a diacritic may be treated either as a new, distinct letter or as a letter–diacritic combination. This varies from language to language, and may vary from case to case within a language.
In some cases, letters are used as "in-line diacritics" in place of ancillary glyphs, because they modify the sound of the letter preceding them, as in the case of the "h" in English "sh" and "th".
Types.
Among the types of diacritic used in alphabets based on the Latin script are:
The tilde, dot, comma, titlo, apostrophe, bar, and colon are sometimes diacritical marks, but also have other uses.
Not all diacritics occur adjacent to the letter they modify. In the Wali language of Ghana, for example, an apostrophe indicates a change of vowel quality, but occurs at the beginning of the word, as in the dialects "’Bulengee" and "’Dolimi". Because of vowel harmony, all vowels in a word are affected, so the scope of the diacritic is the entire word. In abugida scripts, like those used to write Hindi and Thai, diacritics indicate vowels, and may occur above, below, before, after, or around the consonant letter they modify.
The tittle (dot) on the letter "i" of the Latin alphabet originated as a diacritic to clearly distinguish "i" from the minims (downstrokes) of adjacent letters. It first appeared in the 11th century in the sequence "ii" (as in "ingeníí)", then spread to "i" adjacent to "m, n, u", and finally to all lowercase "i"'s. The "j", originally a variant of "i", inherited the tittle. The shape of the diacritic developed from initially resembling today's acute accent to a long flourish by the 15th century. With the advent of Roman type it was reduced to the round dot we have today.
Diacritics specific to non-Latin alphabets.
Greek.
These diacritics are used in addition to the acute, grave, and circumflex accents and the diaeresis:
Korean.
These diacritics, known as Bangjeom (방점;傍點), were used to mark pitch accents in Hangul for Middle Korean. They were written to the left of a syllable in vertical writing and above a syllabler in horizontal writing:  〮, 〯   The Korean government officially revised the romanization of the Korean language in July 2000 to eliminate diacritics.
Non-alphabetic scripts.
Some non-alphabetic scripts also employ symbols that function essentially as diacritics.
Alphabetization or collation.
Different languages use different rules to put diacritic characters in alphabetical order. French treats letters with diacritical marks the same as the underlying letter for purposes of ordering and dictionaries.
The Scandinavian languages, by contrast, treat the characters with diacritics "ä", "ö" and "å" as new and separate letters of the alphabet, and sort them after "z". Usually "ä" is sorted as equal to "æ" (ash) and "ö" is sorted as equal to "ø" (o-slash). Also, "aa", when used as an alternative spelling to "å", is sorted as such. Other letters modified by diacritics are treated as variants of the underlying letter, with the exception that "ü" is frequently sorted as "y".
Languages that treat accented letters as variants of the underlying letter usually alphabetize words with such symbols immediately after similar unmarked words. For instance, in German where two words differ only by an umlaut, the word without it is sorted first in German dictionaries (e.g. "schon" and then "schön", or "fallen" and then "fällen"). However, when names are concerned (e.g. in phone books or in author catalogues in libraries), umlauts are often treated as combinations of the vowel with a suffixed "e"; Austrian phone books now treat characters with umlauts as separate letters (immediately following the underlying vowel).
In Spanish, the grapheme "ñ" is considered a new letter different from "n" and collated between "n" and "o", as it denotes a different sound from that of a plain "n". But the accented vowels "á", "é", "í", "ó", "ú" are not separated from the unaccented vowels "a", "e", "i", "o", "u", as the acute accent in Spanish only modifies stress within the word or denotes a distinction between homonyms, and does not modify the sound of a letter.
For a comprehensive list of the collating orders in various languages, see Collating sequence.
Generation with computers.
Modern computer technology was developed mostly in English-speaking countries, so data formats, keyboard layouts, etc. were developed with a bias favoring English, a language with an alphabet without diacritical marks. This has led to fears internationally that the marks and accents may be made obsolete to facilitate the worldwide exchange of data. Efforts have been made to create internationalized domain names that further extend the English alphabet (e.g., "pokémon.com").
Depending on the keyboard layout, which differs amongst countries, it is more or less easy to enter letters with diacritics on computers and typewriters. Some have their own keys; some are created by first pressing the key with the diacritic mark followed by the letter to place it on. Such a key is sometimes referred to as a dead key, as it produces no output of its own but modifies the output of the key pressed after it.
In modern Microsoft Windows and Linux operating systems, the keyboard layouts "US International" and "UK International" feature dead keys that allow one to type Latin letters with the acute, grave, circumflex, diæresis, tilde, and cedilla found in Western European languages (specifically, those combinations found in the ISO Latin-1 character set) directly: "¨+e" gives "ë", "~+o" gives "õ", etc. On Apple Macintosh computers, there are keyboard shortcuts for the most common diacritics; Option-"e" followed by a vowel places an acute accent, Option-"u" followed by a vowel gives an umlaut, option-"c" gives a cedilla, etc. Diacritics can be composed in most X Window System keyboard layouts, as well as other operating systems, such as Microsoft Windows, using additional software.
On computers, the availability of code pages determines whether one can use certain diacritics. Unicode solves this problem by assigning every known character its own code; if this code is known, most modern computer systems provide a method to input it. With Unicode, it is also possible to combine diacritical marks with most characters.
Languages with letters containing diacritics.
The following languages have letters that contain diacritics that are considered independent letters distinct from those without diacritics.
Diacritics that do not produce new letters.
English.
English is one of the few European languages that does not have many words that contain diacritical marks. Exceptions are unassimilated foreign loanwords, including borrowings from French and, increasingly, Spanish; however, the diacritic is also sometimes omitted from such words. Loanwords that frequently appear with the diacritic in English include "café", "résumé" or "resumé" (a usage that helps distinguish it from the verb "resume"), "soufflé", and "naïveté" (see "English terms with diacritical marks"). In older practice (and even among some orthographically conservative modern writers) one may see examples such as "élite" and "rôle."
English speakers and writers once used the diaeresis more often than now in words such as "coöperation" (from Fr. "coopération"), "zoölogy" (from Grk. "zoologia"), and "seeër" (now more commonly "see-er "or simply" seer"), but this practice has become far less common. "The New Yorker" magazine is a major publication that uses it. 
A few English words, out of context, can only be distinguished from others by a diacritic or modified letter, including exposé, lamé, maté, öre, øre, pâté, and rosé'. The same is true of "résumé," alternately "resumé," but nevertheless it is sometimes spelled "resume" in the US. In a few words, diacritics that did not exist in the original have been added for disambiguation, as in maté (from Sp. and Port. "mate"), saké (the standard Romanization of the Japanese has no accent mark), and Malé (from Dhivehi މާލެ).
The acute and grave accents are occasionally used in poetry and lyrics: the acute to indicate stress overtly where it might be ambiguous ("rébel" vs. "rebél") or nonstandard for metrical reasons ("caléndar"), the grave to indicate that an ordinarily silent or elided syllable is pronounced ("warnèd," "parlìament").
In certain personal names such as "Renée" and "Zoë", often two spellings exist, and the preference will be known only to those close to the person themselves. Even when the name of a person is spelled with a diacritic, like Charlotte Brontë, this may be dropped in less careful sources such as webpages. They also appear in some worldwide company names and/or trademarks such as for instance Nestlé or Citroën.
Other languages.
The following languages have letter-diacritic combinations that are not considered independent letters.
Transliteration.
Several languages that are not written with the Roman alphabet are transliterated, or romanized, using diacritics. Examples:

</doc>
<doc id="8442" url="http://en.wikipedia.org/wiki?curid=8442" title="Digraph">
Digraph

Digraph may refer to:

</doc>
<doc id="8443" url="http://en.wikipedia.org/wiki?curid=8443" title="Didgeridoo">
Didgeridoo

The didgeridoo () (also known as a didjeridu) is a wind instrument developed by Indigenous Australians of northern Australia potentially within the last 1,500 years and still in widespread use today both in Australia and around the world. It is sometimes described as a natural wooden trumpet or "drone pipe". Musicologists classify it as a brass aerophone.
There are no reliable sources stating the didgeridoo's exact age. Archaeological studies of rock art in Northern Australia suggest that the people of the Kakadu region of the Northern Territory have been using the didgeridoo for less than 1,000 years, based on the dating of paintings on cave walls and shelters from this period. A clear rock painting in Ginga Wardelirrhmeng, on the northern edge of the Arnhem Land plateau, from the freshwater period (that was begun 1500 years ago) shows a didgeridoo player and two songmen participating in an Ubarr Ceremony.
A modern didgeridoo is usually cylindrical or conical, and can measure anywhere from 1 to long. Most are around 1.2 m long. Generally, the longer the instrument, the lower its pitch or key. However, flared instruments play a higher pitch than unflared instruments of the same length.
Names and etymology.
There are numerous names for the instrument among the Aboriginal peoples of northern Australia, none of which closely resemble the word "didgeridoo" (see below). Many didgeridoo enthusiasts and some scholars advocate reserving local names for traditional instruments, and this practice has been endorsed by some Aboriginal community organisations. However, in everyday conversation, bilingual Aboriginal people will often use the word "didgeridoo" interchangeably with the instrument's name in their own language.
"Didgeridoo" is considered to be an onomatopoetic word of Western invention. The earliest occurrences of the word in print include a 1919 issue of "Smith's Weekly" where it was referred to as an "infernal didjerry" which "produced but one sound – (phonic) didjerry, didjerry, didjerry and so on ad infinitum", the 1919 "Australian National Dictionary", "The Bulletin" in 1924 and the writings of Herbert Basedow in 1926.
A rival explanation, that didgeridoo is a corruption of the Irish language (Gaelic) phrase "dúdaire dubh" or "dúidire dúth", is controversial. "Dúdaire"/"dúidire" is a noun that may mean, depending on the context, "trumpeter", "hummer", "crooner", "long-necked person", "puffer", "eavesdropper", or "chain smoker", while "dubh" means "black" and "dúth" means "native".
"Yiḏaki" (sometimes spelt "yirdaki") is one of the most commonly used names, although – strictly speaking – it refers to a specific type of instrument made and used by the Yolngu people of north-east Arnhem Land. However, since the passing, in early 2011, of a Manggalili-clan man whose name sounds similar to "yiḏaki", Yolngu themselves now use the synonym "mandapul" to refer to the instrument, out of respect for the deceased.
There are numerous other, regional names for the didgeridoo. The following are some of the more common of these.
Construction.
Authentic Aboriginal didgeridoos are produced in traditionally oriented communities in Northern Australia or by makers who travel to Central and Northern Australia to collect the raw materials. They are usually made from hardwoods, especially the various eucalyptus species that are endemic to the region. Generally the main trunk of the tree is harvested, though a substantial branch may be used instead. Aboriginal didgeridoo craftsmen hunt for suitably hollow live trees in areas with obvious termite activity. Termites attack these living eucalyptus trees, removing only the dead heartwood of the tree, as the living sapwood contains a chemical that repels the insects. Various techniques are employed to find trees with a suitable hollow, including knowledge of landscape and termite activity patterns, and a kind of tap or knock test, in which the bark of the tree is peeled back, and a fingernail or the blunt end of a tool, such as an axe is knocked against the wood to determine if the hollow produces the right resonance.
Once a suitably hollow tree is found, it is cut down and cleaned out, the bark is taken off, the ends trimmed, and the exterior is shaped; this results in a finished instrument. This instrument may be painted or left undecorated. A rim of beeswax may be applied to the mouthpiece end. Traditional instruments made by Aboriginal craftsmen in Arnhem Land are sometimes fitted with a "sugarbag" mouthpiece. This black beeswax comes from wild bees and has a distinctive aroma.
Non-traditional didgeridoos can also be made from PVC piping, non-native hard woods (typically split, hollowed and rejoined), glass, fiberglass, metal, agave, clay, hemp (in the form of a bioplastic named zelfo), and even carbon fibre. These didges typically have an upper inside diameter of around 1.25" down to a bell end of anywhere between two to eight inches and have a length corresponding to the desired key. The mouthpiece can be constructed of beeswax, hardwood or simply sanded and sized by the craftsman. In PVC, an appropriately sized rubber stopper with a hole cut into it is equally acceptable, or to finely sand and buff the end of the pipe to create a comfortable mouthpiece.
Modern didgeridoo designs are distinct from the traditional Australian Aboriginal didgeridoo, and are innovations recognized by musicologists. Didgeridoo design innovation started in the late 20th Century using non-traditional materials and non-traditional shapes.
Decoration.
Many didgeridoos are painted using traditional or modern paints by either their maker or a dedicated artist, however it is not essential that the instrument be decorated. It is also common to retain the natural wood grain with minimal or no decoration. Some modern makers deliberately avoid decoration if they are not of Indigenous Australian descent, or leave the instrument blank for an Indigenous Australian artist to decorate it at a later stage.
Playing the didgeridoo.
The didgeridoo is played with continuously vibrating lips to produce the drone while using a special breathing technique called circular breathing. This requires breathing in through the nose whilst simultaneously expelling stored air out of the mouth using the tongue and cheeks. By use of this technique, a skilled player can replenish the air in their lungs, and with practice can sustain a note for as long as desired. Recordings exist of modern didgeridoo players playing continuously for more than 40 minutes; Mark Atkins on "Didgeridoo Concerto" (1994) plays for over 50 minutes continuously.
Fellow of the British Society Anthony Baines wrote that the didgeridoo functions "...as an aural kaleidoscope of timbres" and that "the extremely difficult virtuoso techniques developed by expert performers find no parallel elsewhere."
More modern approaches to playing the didgeridoo are starting to show up in performances and lessons around the World. One of these techniques involves combining beatboxing with playing the didgeridoo. It was featured on the British children's TV series "Blue Peter".
Physics and operation.
A termite-bored didgeridoo has an irregular shape that, overall, usually increases in diameter towards the lower end. This shape means that its resonances occur at frequencies that are not harmonically spaced in frequency. This contrasts with the harmonic spacing of the resonances in a cylindrical plastic pipe, whose resonant frequencies fall in the ratio 1:3:5 etc. The second resonance of a didgeridoo (the note sounded by overblowing) is usually around an 11th higher than the fundamental frequency (a frequency ratio somewhat less than 3:1).
The vibration produced by the player's lips has harmonics, i.e., it has frequency components falling exactly in the ratio 1:2:3 etc. However, the non-harmonic spacing of the instrument's resonances means that the harmonics of the fundamental note are not systematically assisted by instrument resonances, as is usually the case for Western wind instruments (e.g., in a clarinet, the 1st 3rd and 5th harmonics of the reed are assisted by resonances of the bore, at least for notes in the low range).
Sufficiently strong resonances of the vocal tract can strongly influence the timbre of the instrument.
At some frequencies, whose values depend on the position of the player's tongue, resonances of the vocal tract inhibit the oscillatory flow of air into the instrument.
Bands of frequencies that are not thus inhibited produce formants in the output sound.
These formants, and especially their variation during the inhalation and exhalation phases of circular breathing, give the instrument its readily recognizable sound.
Other variations in the didgeridoo's sound can be made by adding vocalizations to the drone. Most of the vocalizations are related to sounds emitted by Australian animals, such as the dingo or the kookaburra. To produce these sounds, the players simply have to use their vocal folds to produce the sounds of the animals whilst continuing to blow air through the instrument. The results range from very high-pitched sounds to much lower guttural vibrations. Adding vocalizations increases the complexity of the playing.
Cultural significance.
Traditionally and originally, the didgeridoo was primarily played as an accompaniment to ceremonial dancing and singing. However, it was also common for didgeridoos to be played for solo or recreational purposes outside of ceremonial gatherings. For surviving Aboriginal groups of northern Australia, the didgeridoo is still an integral part of ceremonial life, as it accompanies singers and dancers in cultural ceremonies that continue. Today, the majority of didgeridoo playing is for recreational purposes in both Indigenous Australian communities and elsewhere around the world.
Pair sticks, sometimes called "clapsticks" or "bilma", establish the beat for the songs during ceremonies. The rhythm of the didgeridoo and the beat of the clapsticks are precise, and these patterns have been handed down for many generations. In the Wangga genre, the song-man starts with vocals and then introduces "blima" to the accompaniment of didgeridoo.
Gender prohibition.
Traditionally, only men play the didgeridoo and sing during ceremonial occasions, although both men and women may dance. Female didgeridoo players do exist, but their playing takes place in an informal context and is not specifically encouraged by Aboriginal elders. Linda Barwick, an ethnomusicologist, says that though traditionally women have not played the didgeridoo in ceremony, in informal situations there is no prohibition in the Dreaming Law. For example, Jemima Wimalu, a Mara woman from the Roper River is very proficient at playing the didgeridoo and is featured on the record "Aboriginal Sound Instruments" released in 1978. In 1995, musicologist Steve Knopoff observed Yirrkala women performing "djatpangarri" songs that are traditionally performed by men and in 1996, ethnomusicologist Elizabeth MacKinley reported women of the Yanyuwa group giving public performances. On 3 September 2008, however, publisher Harper Collins issued a public apology for its book "The Daring Book for Girls" which openly encouraged girls to play the instrument after Aboriginal academics accused HarperCollins of "extreme cultural insensitivity". Mark Rose, head of the Victorian Aboriginal Education Association, said that encouraging girls to play the instrument was "an extreme faux pas...part of a general ignorance that mainstream Australia has about Aboriginal culture."
While there is no prohibition in the area of the didgeridoo's origin, such restrictions have been applied by other Indigenous communities. The didgeridoo was introduced to the Kimberleys almost a century ago but it is only in the last decade that Aboriginal men have shown adverse reactions to women playing the instrument and prohibitions are especially evident in the South East of Australia. The belief that women are prohibited from playing is widespread among non-Aboriginal people and is also common among Aboriginal communities in Southern Australia; some ethnomusicologists believe that the dissemination of the "Taboo" belief and other misconceptions is a result of commercial agendas and marketing. Tourists generally rely on shop employees for information when purchasing a didgeridoo. Additionally, the majority of commercial didgeridoo recordings available are distributed by multinational recording companies and feature non-Aboriginals playing a New Age style of music with liner notes promoting the instrument's spirituality which misleads consumers about the didgeridoo's secular role in traditional Aboriginal culture.
The Taboo belief is particularly strong among many Indigenous groups in the South East of Australia, where it is forbidden and considered "cultural theft" for non-Indigenous women, and especially performers of "New Age" music regardless of gender, to play or even touch a didgeridoo.
In popular culture.
The didgeridoo also became a role playing instrument in the experimental and avant-garde music scene. Industrial music bands like Test Department generated sounds from this instrument and used them in their industrial performances, linking ecology to industry, influenced by ethnic music and culture.
It is very often used in the music project Naakhum which combines Extreme Metal and Ethnic music.
The acid jazz band Jamiroquai were known for their didgeridoo player Wallis Buchanan. In the early days of the band, many songs explored the theme of ecology and those of native cultures marginalized by colonisation. A notable song featuring a didgeridoo is the band's first single "When You Gonna Learn", which features prominent didgeridoo playing in both the introduction and solo sections. When Wallis Buchanan left the band in 1999, the band chose not to replace him, and simply abandoned the use of the instrument in their music.
The instrument is commonly used by ambient artist Steve Roach as a complement to his produced soundscapes, in both live and recorded formats. It features prominently in his collaborative work "" (with Australian Aboriginal artist David Hudson and cellist Sarah Hopkins) as well as "Dreamtime Return".
It is used in the Indian song "Jaane Kyon" from the film "Dil Chahta Hai".
Chris Brooks, lead singer of the New Zealand hard rock band Like a Storm uses the didgeridoo in some of the band's songs including "Love the Way You Hate Me" from their album "".
Kate Bush made extensive use of the didgeridoo (played by Australian musician Rolf Harris) on her album "The Dreaming", which was written and recorded after a holiday in Australia.
Health benefits.
A 2005 study in the "British Medical Journal" found that learning and practising the didgeridoo helped reduce snoring and obstructive sleep apnea by strengthening muscles in the upper airway, thus reducing their tendency to collapse during sleep. In the study, intervention subjects were trained in and practiced didgeridoo playing, including circular breathing and other techniques. Control subjects were asked not to play the instrument. Subjects were surveyed before and after the study period to assess the effects of intervention.
Selected bibliography.
</dl>

</doc>
<doc id="8449" url="http://en.wikipedia.org/wiki?curid=8449" title="Developmental biology">
Developmental biology

Developmental biology is the study of the process by which animals and plants grow and develop, and is synonymous with ontogeny. In animals most development occurs in embryonic life, but it is also found in regeneration, asexual reproduction and metamorphosis, and in the growth and differentiation of stem cells in the adult organism. In plants, development occurs in embryos, during vegetative reproduction, and in the normal outgrowth of roots, shoots and flowers.
Practical outcomes from the study of animal developmental biology have included in vitro fertilization, now widely used in fertility treatment, the understanding of risks from substances that can damage the fetus (teratogens), and the creation of various animal models for human disease which are useful in research. Developmental Biology has also help to generate modern stem cell biology which promises a number of important practical benefits for human health.
Many of the processes of development are now well understood, and some major textbooks of the subject are 
Perspectives.
The development of a new life is a spectacular process and represents a masterpiece of temporal and spatial control of gene expression. Developmental genetics studies the effect that genes have in a phenotype, given normal or abnormal epigenetic parameters. The findings of developmental biology can help us to understand developmental abnormalities such as chromosomal aberrations that cause Down syndrome. An understanding of the specialization of cells during embryogenesis has provided information on how stem cells specialize into specific tissues and organs. This information has led, for example, to the cloning of specific organs for medical purposes. Another biologically important process that occurs during development is apoptosis—programmed cell death or "suicide." Many developmental models are used to elucidate the physiology and molecular basis of this cellular process. Similarly, a deeper understanding of developmental biology can foster greater progress in the treatment of congenital disorders and diseases, e.g. studying human sex determination can lead to treatment for disorders such as congenital adrenal hyperplasia.
Developmental model organisms.
Often-used model organisms in developmental biology include the following:
Studied phenomena.
Cell differentiation.
Differentiation is the formation of cell types, from what is originally one cell – the zygote or spore. The formation of cell types such as nerve cells occurs with a number of intermediary, less differentiated cell types. A cell stays a certain cell type by maintaining a particular pattern of gene expression. This depends on regulatory genes, e.g. for transcription factors and signaling proteins. These can take part in self-perpetuating circuits in the gene regulatory network, circuits that can involve several cells that communicate with each other. External signals can alter gene expression by activating a receptor, which triggers a signaling cascade that affects transcription factors. For example, the withdrawal of growth factors from myoblasts causes them to stop dividing and instead differentiate into muscle cells.
Embryonic development.
Embryogenesis is the step in the life cycle after fertilization – the development of the embryo, starting from the zygote (fertilized egg). Organisms can differ drastically in how the embryo develops, especially when they belong to different phyla. For example, embryonal development in placental mammals starts with cleavage of the zygote into eight uncommitted cells, which then form a ball (morula). The outer cells become the trophectoderm or trophoblast, which will form in combination with maternal uterine endometrial tissue the placenta, needed for fetal nurturing via maternal blood, while inner cells become the inner cell mass that will form all fetal organs (the bridge between these two parts eventually forms the umbilical cord). In contrast, the fruit fly zygote first forms a sausage-shaped syncytium, which is still one cell but with many cell nuclei.
Patterning is important for determining which cells develop into which organs. This is mediated by signaling between adjacent cells by proteins on their surfaces, and by gradients of signaling secreted molecules. An example is retinoic acid, which forms a gradient in the head to tail direction in animals. Retinoic acid enters cells and activates Hox genes in a concentration-dependent manner – Hox genes differ in how much retinoic acid they require for activation and will thus show differential rostral expression boundaries, in a colinear fashion with their genomic order. As Hox genes code for transcription factors, this causes different activated combinations of both Hox and other genes in discrete anteroposterior transverse segments of the neural tube (neuromeres) and related patterns in surrounding tissues, such as branchial arches, lateral mesoderm, neural crest, skin and endoderm, in the head to tail direction. This is important for e.g. the segmentation of the spine in vertebrates.
Embryonic development does not always proceed correctly, and errors can result in birth defects or miscarriage. Often the reason is genetic (mutation or chromosome abnormality), but there can be environmental influence (like teratogens) or stochastic events. Abnormal development caused by mutation is also of evolutionary interest as it provides a mechanism for changes in body plan ("see evolutionary developmental biology").
Growth.
Growth is the enlargement of a tissue or organism. Growth continues after the embryonal stage, and occurs through cell proliferation, enlargement of cells or accumulation of extracellular material. In plants, growth results in an adult organism that is strikingly different from the embryo. The proliferating cells tend to be distinct from differentiated cells ("see stem cell and progenitor cell"). In some tissues proliferating cells are restricted to specialised areas, such as the growth plates of bones. But some stem cells migrate to where they are needed, such as mesenchymal stem cells which can migrate from the bone marrow to form e.g. muscle, bone or adipose tissue. The size of an organ frequently determines its growth, as in the case of the liver which grows back to its previous size if a part is removed. Growth factors, such as fibroblast growth factors in the animal embryo and growth hormone in juvenile mammals, also control the extent of growth.
Metamorphosis.
Most animals have a larval stage, with a body plan different from that of the adult organism. The larva abruptly develops into an adult in a process called metamorphosis. For example, caterpillars (butterfly larvae) are specialized for feeding whereas adult butterflies (imagos) are specialised for flight and reproduction. When the caterpillar has grown enough, it turns into an immobile pupa. Here, the imago develops from imaginal discs found inside the larva.
Regeneration.
Regeneration is the reactivation of development so that a missing body part grows back. This phenomenon has been studied particularly in salamanders, where the adults can reconstruct a whole limb after it has been amputated. Researchers hope to one day be able to induce regeneration in humans. There is little spontaneous regeneration in adult humans, although the liver is a notable exception. Like for salamanders, the regeneration of the liver involves dedifferentiation of some cells to a more embryonal state. Regeneration can also be studied in planaria. Cutting planaria causes an accumulation of epidermal cells at the site of the cut; a regeneration blastema is then formed from cells lacking differentiation, and differentiation occurs to replace absent parts within one week of the initial cut.
Developmental systems biology.
Computer simulation of multicellular development is a research methodology to understand the function of the very complex processes involved in the development of organisms. This includes simulation of cell signaling, multicell interactions and regulatory genomic networks in development of multicellular structures and processes (see French flag model or for literature). "Minimal genomes" for minimal multicellular organisms may pave the way to understand such complex processes "in vivo".

</doc>
<doc id="8452" url="http://en.wikipedia.org/wiki?curid=8452" title="December 27">
December 27

December 27 is the day of the year in the Gregorian calendar.

</doc>
<doc id="8453" url="http://en.wikipedia.org/wiki?curid=8453" title="Dartmoor wildlife">
Dartmoor wildlife

Dartmoor and the fact that a great deal of it is undisturbed for much of the year is an encouragement to the wildlife.
The more common mammals include: Dartmoor ponies, rabbits, foxes, otters, badgers, grey squirrels, weasels, stoats, hares and deer. Rumours abound of large wild cats such as cougars roaming wild on the moor, but little evidence has been forthcoming and until anything more substantial is available these reports should be filed under the general heading of cryptozoology.
Herds of cattle and domestic sheep can be seen apparently roaming free on the moor. All are owned by farmers and let out to graze. Each is branded - the sheep with a coloured patch on its coat, unique to its owner. The livestock will naturally remain within the territory in which they are released, although walls and cattle grids (a pit in the road covered with metal bars - impassable to hoofed animals) provide an additional level of control.
Dartmoor has given its name to two breeds of sheep - Whiteface Dartmoor and Greyface Dartmoor - which are descended from breeds which have roamed on the moor since at least the 17th century. They are still to be found there, but are now vastly outnumbered by the Scottish Blackface. Less common breeds such as Exmoor Horn and Cheviot are also to be found on Dartmoor. The most common cattle are the Galloway and Aberdeen Angus.
Reptiles include: grass snakes, adders, slow worms and common lizards.
Amphibians include: common frog and common toad.
With its range of high grassy moorland, bogs, farmland and deep wooded valleys, Dartmoor also provides a range of habitats for a variety of birds, some quite rare. With their preferred habitat these include:
Many of the rivers and streams support the fish species commonly to be found in Britain and Ireland; salmon and trout are also to be found in some, though less frequently than in previous times.

</doc>
<doc id="8454" url="http://en.wikipedia.org/wiki?curid=8454" title="Double planet">
Double planet

In astronomy, double planet and binary planet are informal terms used to describe a binary system where both objects are of planetary mass. Though not an official classification, the European Space Agency has referred to the Earth–Moon system as a double planet. The IAU General Assembly in August 2006 considered a proposal that Pluto and Charon be reclassified as a double planet, but the proposal was abandoned.
There are also double minor planets, such as binary asteroids 90 Antiope and binary Kuiper belt objects (KBOs) 79360 Sila–Nunam and 1998 WW31.
Definition of a double planet.
There has been debate on where to draw the line between a double planet and a planet–moon system. In most cases, this is not an issue because most satellites have small masses relative to their planets. In particular, with the exception of the Earth–Moon system, all satellites of planets in the Solar System have masses less than 0.00025 (1⁄4000) the mass of the host planet. The Moon-to-Earth mass ratio is 0.01230 (≈ 1⁄81). In comparison, the Charon-to-Pluto mass ratio is 0.117 (≈ 1⁄9).
Co-accretion definition.
The now-abandoned co-accretion hypothesis of the origin of the Moon is also called the double-planet hypothesis. The idea is that two bodies should be considered a double planet if they accreted together directly from the proto-planetary disk, much as a double star typically forms together. 
Once it was realized that both the Moon and Pluto's Charon likely formed from giant impacts, this parallel was noted when calling them double planets. However, an impact may also produce tiny satellites, such as the small outer satellites of Pluto, so this does not determine where the line should be drawn.
Center-of-mass definition.
A common proposal for a double planet is a system where the center of mass lies outside the primary. This was the basis for the argument that the Pluto–Charon system be considered a double planet when the IAU was debating whether dwarf planets should be considered a class of planet. Under this definition, the Earth–Moon system is not a double planet. However, the center of mass varies with the distance between the bodies. As the Moon migrates outward from Earth, the center of mass of the system will migrate outward as well, until in a few hundred million years Earth will fit the definition. It has been suggested that such a definition would call into question Jupiter's status as a planet, as the center of mass of the Jupiter–Sun system lies outside the surface of the Sun.
Tug-of-war definition.
Isaac Asimov suggested a distinction between planet–moon and double-planet structures based in part on what he called a "tug-of-war" value, which does not consider their relative sizes. This quantity is simply the ratio of the force exerted on the smaller body by the larger (primary) body to the force exerted on the smaller body by the Sun. This can be shown to equal
where mp is the mass of the primary (the larger body), ms is the mass of the Sun, ds is the distance between the smaller body and the Sun, and dp is the distance between the smaller body and the primary. Note that the tug-of-war value does not rely on the mass of the satellite (the smaller body).
This formula actually reflects the relation of the gravitational effects on the smaller body from the larger body and from the Sun. The tug-of-war figure for Saturn's moon Titan is 380, which means that Saturn's hold on Titan is 380 times as strong as the Sun's hold on Titan. Titan's tug-of-war value may be compared with that of Saturn's moon Phoebe, which has a tug-of-war value of just 3.5. So Saturn's hold on Phoebe is only 3.5 times as strong as the Sun's hold on Phoebe. 
Asimov calculated tug-of-war values for several satellites of the planets. He showed that even the largest gas giant, Jupiter, had only a slightly better hold than the Sun on its outer captured satellites, some with tug-of-war values not much higher than one. In nearly every one of Asimov's calculations the tug-of-war value was found to be greater than one, so in those cases the Sun loses the tug-of-war with the planets. The one exception was Earth's Moon, where the Sun wins the tug-of-war with a value of 0.46, which means that Earth's hold on the Moon is less than half that of the Sun's. Asimov included this with his other arguments that Earth and the Moon should be considered a binary planet.
We might look upon the Moon, then, as neither a true satellite of the Earth nor a captured one, but as a planet in its own right, moving about the Sun in careful step with the Earth. From within the Earth–Moon system, the simplest way of picturing the situation is to have the Moon revolve about the Earth; but if you were to draw a picture of the orbits of the Earth and Moon about the Sun exactly to scale, you would see that the Moon's orbit is everywhere concave toward the Sun. It is always "falling toward" the Sun. All the other satellites, without exception, "fall away" from the Sun through part of their orbits, caught as they are by the superior pull of their primary planets – but not the Moon.—Isaac Asimov
See the Path of Earth and Moon around Sun section in the "Orbit of the Moon" article for a more detailed explanation.
Note that this definition of double planet depends on the pair's distance from the Sun. If the Earth–Moon system happened to orbit farther away from the Sun than it does now, then Earth would win the tug of war. For example, at the orbit of Mars, the Moon's tug-of-war value would be 1.05. Also, several tiny moons discovered since Asimov's proposal would qualify as double planets by this argument. Neptune's small outer moons Neso and Psamathe, for example, have tug-of-war values of 0.42 and 0.44, less than that of Earth's Moon. Yet their masses are tiny compared to Neptune's, with an estimated ratio of 1.5×10-9 (1⁄700,000,000) and 0.4×10-9 (1⁄2,500,000,000).

</doc>
<doc id="8456" url="http://en.wikipedia.org/wiki?curid=8456" title="Denaturation (biochemistry)">
Denaturation (biochemistry)

IUPAC definition
 Process of partial or total alteration of the native secondary, and/or tertiary, and/or quaternary structures of proteins or nucleic acids resulting in a loss of "bioactivity".
"Note 1": Modified from the definition given in ref.
"Note 2": Denaturation can occur when proteins and nucleic acids are subjected to elevated temperature or to extremes of pH, or to nonphysiological concentrations of salt, organic solvents, urea, or other chemical agents.
"Note 3": An "enzyme" loses its catalytic activity when it is denaturized.
Denaturation is a process in which proteins or nucleic acids lose the quaternary structure, tertiary structure and secondary structure which is present in their native state, by application of some external stress or compound such as a strong acid or base, a concentrated inorganic salt, an organic solvent (e.g., alcohol or chloroform), radiation or heat. If proteins in a living cell are denatured, this results in disruption of cell activity and possibly cell death. Denatured proteins can exhibit a wide range of characteristics, from conformational change and loss of solubility to aggregation due to the exposure of hydrophobic groups.
This concept is unrelated to denatured alcohol, which is alcohol that has been mixed with additives to make it unsuitable for human consumption.
Common examples.
When food is cooked, some of its proteins become denatured. This is why boiled eggs become hard and cooked meat becomes firm.
A classic example of denaturing in proteins comes from egg whites, which are typically largely egg albumins in water. Fresh from the eggs, egg whites are transparent and liquid. Cooking the thermally unstable whites turns them opaque, forming an interconnected solid mass. The same transformation can be effected with a denaturing chemical. Pouring egg whites into a beaker of acetone will also turn egg whites translucent and solid. The skin that forms on curdled milk is another common example of denatured protein. The cold appetizer known as ceviche is prepared by chemically "cooking" raw fish and shellfish in an acidic citrus marinade, without heat.
Protein denaturation.
Denatured proteins can exhibit a wide range of characteristics, from loss of solubility to protein aggregation."
Background.
Proteins are amino acid polymers. A protein is created by ribosomes that "read" RNA that is encoded by codons in the gene and assemble the requisite amino acid combination from the genetic instruction, in a process known as translation. The newly created protein strand then undergoes posttranslational modification, in which additional atoms or molecules are added, for example copper, zinc, or iron. Once this post-translational modification process has been completed, the protein begins to fold (sometimes spontaneously and sometimes with enzymatic assistance), curling up on itself so that hydrophobic elements of the protein are buried deep inside the structure and hydrophilic elements end up on the outside. The final shape of a protein determines how it interacts with its environment.
When a protein is denatured, secondary and tertiary structures are altered but the peptide bonds of the primary structure between the amino acids are left intact. Since all structural levels of the protein determine its function, the protein can no longer perform its function once it has been denatured. This is in contrast to intrinsically unstructured proteins, which are unfolded in their native state, but still functionally active.
How denaturation occurs at levels of protein structure.
Loss of function.
Most biological substrates lose their biological function when denatured. For example, enzymes lose their activity, because the substrates can no longer bind to the active site, and because amino acid residues involved in stabilizing substrates' transition states are no longer positioned to be able to do so. The denaturing process and the associated loss of activity can be measured using techniques such as dual polarization interferometry, CD, and QCMD.
Reversibility and irreversibility.
In very few cases (unlike egg whites), denaturation is reversible (the proteins can regain their native state when the denaturing influence is removed). This process can be called renaturation. This understanding has led to the notion that all the information needed for proteins to assume their native state was encoded in the primary structure of the protein, and hence in the DNA that codes for the protein, the so-called "Anfinsen's thermodynamic hypothesis". One example of renaturation is that an egg white can be uncooked using vitamin C or sodium borohydride.
Nucleic acid denaturation.
The denaturation of nucleic acids such as DNA due to high temperatures is the separation of a double strand into two single strands, which occurs when the hydrogen bonds between the strands are broken. This process is used during polymerase chain reaction. Nucleic acid strands realign when "normal" conditions are restored during annealing. If the conditions are restored too quickly, the nucleic acid strands may realign imperfectly.
Denaturants.
Acids.
Acidic protein denaturants include:
Bases.
Bases work similarly to acids in denaturation. They include:
Solvents.
Most organic solvents are denaturing, including:
Cross-linking reagents.
Cross-linking agents for proteins include:
Chaotropic agents.
Chaotropic agents include:
Disulfide bond reducers.
Agents that break disulfide bonds by reduction include:

</doc>
<doc id="8459" url="http://en.wikipedia.org/wiki?curid=8459" title="Dwight L. Moody">
Dwight L. Moody

Dwight Lyman Moody (February 5, 1837 – December 22, 1899), also known as D.L. Moody, was an American evangelist and publisher, who founded the Moody Church, Northfield School and Mount Hermon School in Massachusetts (now Northfield Mount Hermon School), the Moody Bible Institute, and Moody Publishers.
Early life.
Dwight Moody was born in Northfield, Massachusetts, to a large family. His father, Edwin J. Moody (1800–1841), a small farmer and stonemason, died at the age of 41, when Dwight was only four years old; his mother was Betsey Moody (née Holton; 1805–1896). They had five sons and a daughter before Dwight's birth, with twins, a boy and a girl, born one month after Edwin's death. His mother struggled to support the family, but even with her best effort, some of her children had to be sent off to work for their room and board. Dwight too was sent off, where he received cornmeal, porridge, and milk three times a day. He complained to his mother, but when she found out that he got all that he wanted to eat, she sent him back. Even during that time she continued to send them to church. Together with his eight siblings he was raised in the Unitarian church. His oldest brother ran away and was not heard from by the family until many years later.
When Moody turned 17, he moved to Boston to work (after many job rejections) in an uncle's shoe store. One of the uncle's requirements was that Moody attend the Congregational Church of Mount Vernon where Dr. Edward Norris Kirk served as the pastor. In April 1855 Moody was then converted to evangelical Christianity when his Sunday school teacher, Edward Kimball, talked to him about how much God loved him. His conversion sparked the start of his career as an evangelist. However, his first application for church membership, in May 1855, was rejected. He was not received as a church member until May 4, 1856. As his teacher, Edward Kimball, stated:
"I can truly say, and in saying it I magnify the infinite grace of God as bestowed upon him, that I have seen few persons whose minds were spiritually darker than was his when he came into my Sunday School class; and I think that the committee of the Mount Vernon Church seldom met an applicant for membership more unlikely ever to become a Christian of clear and decided views of Gospel truth, still less to fill any extended sphere of public usefulness."
The Civil War.
"The first meeting I ever saw him at was in a little old shanty that had been abandoned by a saloon-keeper. Mr. Moody had got the place to hold the meetings in at night. I went there a little late; and the first thing I saw was a man standing up with a few tallow candles around him, holding a negro boy, and trying to read to him the story of the Prodigal Son and a great many words he could not read out, and had to skip. I thought, 'If the Lord can ever use such an instrument as that for His honor and glory, it will astonish me. As a result of his tireless labor, within a year the average attendance at his school was 650, while 60 volunteers from various churches served as teachers. It became so well known that the just-elected President Lincoln visited and spoke at a Sunday School meeting on November 25, 1860."
D. L. Moody "could not conscientiously enlist" in the Union Army during the Civil War, later describing himself as "a Quaker" in this respect. After the Civil War started, he became involved with the United States Christian Commission of the YMCA, and paid nine visits to the battlefront, being present among the Union soldiers after the Battle of Shiloh (a.k.a. Pittsburg Landing) and the Battle of Stones River; he also entered Richmond, Virginia, with the troops of General Grant. On August 28, 1862, he married Emma C. Revell, with whom he had a daughter, Emma Reynolds Moody, and two sons, William Revell Moody and Paul Dwight Moody.
Chicago and the post-Civil War years.
The growing Sunday School congregation needed a permanent home, so Moody started a church in Chicago, the Illinois Street Church.
In June 1871 at an International Sunday School Convention in Indianapolis, Moody met Ira D. Sankey, the gospel singer, with whom he soon began to cooperate and collaborate. In October 1871 the Great Chicago Fire destroyed his church, his home, and the dwellings of most of his members. His family had to flee for their lives, and, as Mr. Moody said, he saved nothing but his reputation and his Bible. His church was rebuilt within three months at a nearby location as the Chicago Avenue Church. His lay follower William Eugene Blackstone was a prominent American Zionist.
In the years after the fire, Moody's wealthy Chicago supporter John V. Farwell tried to persuade him to make his permanent home in Chicago, offering to build a new house for Moody and his family. But the newly famous Moody, also sought by supporters in New York, Philadelphia, and elsewhere, chose the tranquil farm he had purchased next door to his birthplace in Northfield, Massachusetts. He felt he could better recover from his lengthy and exhausting preaching trips in a rural setting. Northfield became an important location in evangelical Christian history in the late 19th century as Moody organized summer conferences which were led and attended by prominent Christian preachers and evangelists from around the world. It was also in Northfield where Moody founded two schools (Northfield School for Girls, founded in 1879, and the Mount Hermon School for Boys, founded in 1881) which later merged into today's co-educational, nondenominational Northfield Mount Hermon School.
England.
During a trip to England in the spring of 1872, he became well known as an evangelist. Literary works published by the Moody Bible Institute have claimed that he was the greatest evangelist of the 19th century. He preached almost a hundred times and came into communion with the Plymouth Brethren. On several occasions he filled stadia of a capacity of 2,000 to 4,000. In the Botanic Gardens Palace a meeting had an audience between 15,000 and 30,000.
That turnout continued throughout 1874 and 1875, with crowds of thousands at all of his meetings. During his visit to Scotland he was helped and encouraged by Andrew A. Bonar. The famous London Baptist preacher, Charles Spurgeon, invited him to speak, and he promoted him as well. When he returned to the US, crowds of 12,000 to 20,000 were as common as they had been in England. President Grant and some of his cabinet officials attended a meeting on January 19, 1876. His evangelistic meetings took place from Boston to New York, throughout New England, and as far as San Francisco, along with other West Coast towns from Vancouver to San Diego.
Moody aided in the work of cross-cultural evangelism by promoting "The Wordless Book," a teaching tool that had been invented by Charles Spurgeon in 1866. In 1875 he added a fourth color to the design of the three-color evangelistic device: gold—to "represent heaven." This "book" has been and is still used to teach uncounted thousands of illiterate people, young and old, around the globe about the gospel message.
Dwight L. Moody visited Britain with Ira D. Sankey, with Moody preaching and Sankey singing. Together they published books of Christian hymns. In 1883 they visited Edinburgh and raised £10,000 for the building of a new home for the Carrubbers Close Mission. Moody later preached at the laying of the foundation stone for what is one of the few buildings on the Royal Mile which continues to be used for its original purpose and is now called the Carrubbers Christian Centre.
Moody greatly influenced the cause of cross-cultural Christian missions after he met Hudson Taylor, a pioneer missionary to China. He actively supported the China Inland Mission and encouraged many of his congregation to volunteer for service overseas.
International acclaim.
His influence was felt among Swedes despite that he was of English heritage, that he never visited Sweden or any other Scandinavian country, and that he never spoke a word of Swedish. Nonetheless he became a hero revivalist among Swedish Mission Friends in Sweden and America.
News of Moody’s large revival campaigns in Great Britain from 1873 through 1875 traveled quickly to Sweden, making “Mr. Moody” a household name in homes of many Mission Friends. Moody’s sermons published in Sweden were distributed in books, newspapers, and colporteur tracts, and they led to the spread of Sweden’s “Moody fever” from 1875 through 1880.
He preached his last sermon on November 16, 1899, in Kansas City, Missouri. Becoming ill, he returned home by train to Northfield. During the preceding several months, friends had observed he had added some 30 lb to his already ample frame. Although his illness was never diagnosed, it has been speculated that he suffered from congestive heart failure. He died on December 22, 1899, surrounded by his family. Already installed as the leader of his Chicago Bible Institute, R. A. Torrey succeeded Moody as its president. Ten years after Moody's death the Chicago Avenue Church was renamed the Moody Church in his honor, and the Chicago Bible Institute was likewise renamed the Moody Bible Institute.

</doc>
<doc id="8460" url="http://en.wikipedia.org/wiki?curid=8460" title="Dieting">
Dieting

Dieting is the practice of eating food in a regulated and supervised fashion to decrease, maintain, or increase body weight. Dieting is often used in combination with physical exercise to lose weight, commonly in those who are overweight or obese. Some people, however, follow a diet to gain weight (usually in the form of muscle). Diets can also be used to maintain a stable body weight.
Diets to promote weight loss are generally divided into four categories: low-fat, low-carbohydrate, low-calorie, and very low calorie. A meta-analysis of six randomized controlled trials found no difference between the main diet types (low calorie, low carbohydrate, and low fat), with a 2–4 kilogram weight loss in all studies. At two years, all calorie-reduced diet types cause equal weight loss irrespective of the macronutrients emphasized. In general, the best diet is one where you find a way to eat fewer calories in any way that you can.
A study published in the APA's journal American Psychologist found that dieting does "not lead to sustained weight loss or health benefits for the majority of people." However, other studies have found that the average individual maintains some weight loss after dieting. Weight loss by dieting, while of benefit to those classified as unhealthy, may slightly increase the mortality rate for individuals who are otherwise healthy.
The first popular diet was "Banting", named after William Banting. In his 1863 pamphlet, "Letter on Corpulence, Addressed to the Public", he outlined the details of a particular low-carbohydrate, low-calorie diet that had led to his own dramatic weight loss.
History.
One of the first dietitians was the English doctor George Cheyne. He himself was tremendously overweight and would constantly eat large quantities of rich food and drink. He began a meatless diet, taking only milk and vegetables, and soon regained his health. He began publicly recommending his diet for everyone suffering from obesity. In 1724, he wrote "An Essay of Health and Long Life", in which he advises exercise and fresh air and avoiding luxury foods.
The Scottish military surgeon, John Rollo, published "Notes of a Diabetic Case" in 1797. It described the benefits of a meat diet for those suffering from diabetes, basing this recommendation on Matthew Dobson's discovery of glycosuria in diabetes mellitus. By means of Dobson's testing procedure (for glucose in the urine) Rollo worked out a diet that had success for what is now called type 2 diabetes.
The first popular diet was "Banting", named after the English undertaker William Banting. In 1863, he wrote a booklet called "Letter on Corpulence, Addressed to the Public", which contained the particular plan for the diet he had successfully followed. His own diet was four meals per day, consisting of meat, greens, fruits, and dry wine. The emphasis was on avoiding sugar, sweet foods, starch, beer, milk and butter. Banting’s pamphlet was popular for years to come, and would be used as a model for modern diets. The pamphlet's popularity was such that the question "Do you bant?" referred to his method, and eventually to dieting in general. His booklet remains in print as of 2007.
The first weight-loss book to promote calorie counting, and the first weight-loss book to become a bestseller, was the 1918 "Diet and Health: With Key to the Calories" by American physician and columnist Lulu Hunt Peters.
The Atkins Diet was suggested by the American nutritionist Robert Atkins in 1958, in a research paper titled "Weight Reduction". Atkins used the study to resolve his own overweight condition and went on to popularize the method in a series of books, starting with "Dr. Atkins' Diet Revolution" in 1972. In his second book, "Dr. Atkins' New Diet Revolution" (2002), he modified parts of the diet but did not alter the original concepts.
Types of diets.
Low-fat diets.
Low-fat diets involve the reduction of the percentage of fat in one's diet. Calorie consumption is reduced because less fat is consumed. Diets of this type include NCEP Step I and II. A meta-analysis of 16 trials of 2–12 months' duration found that low-fat diets (without intentional restriction of caloric intake) resulted in average weight loss of 3.2 kg (7.1 lb) over habitual eating.
Low-carbohydrate diets.
Low carbohydrate diets such as Atkins and Protein Power are relatively high in protein and fats. Low-carbohydrate diets are sometimes "ketogenic" (i.e. they restrict carbohydrate intake sufficiently to cause ketosis).
Low-calorie diets.
Low-calorie diets usually produce an energy deficit of 500–1,000 calories per day, which can result in a 0.5 kilogram (1.1 lb) to 1 kilogram (2.2 lb) weight loss per week. Some of the most commonly used low-calorie diets include DASH diet and Weight Watchers. The National Institutes of Health reviewed 34 randomized controlled trials to determine the effectiveness of low-calorie diets. They found that these diets lowered total body mass by 8% in the short term, over 3–12 months.
Very low-calorie diets.
Very low calorie diets provide 200–800 calories per day, maintaining protein intake but limiting calories from both fat and carbohydrates. They subject the body to starvation and produce an average loss of 1.5–2.5 kilograms (3.3–5.5 lb) per week. "2-4-6-8", a popular diet of this variety, follows a four-day cycle in which only 200 calories are consumed the first day, 400 the second day, 600 the third day, 800 the fourth day, and then totally fasting, after which the cycle repeats. These diets are not recommended for general use as they are associated with adverse side effects such as loss of lean muscle mass, increased risks of gout, and electrolyte imbalances. People attempting these diets must be monitored closely by a physician to prevent complications.
Detox diets.
Detox diets claim to eliminate undesirable "toxins" from the human body rather than claiming to cause weight loss. Many of these use herbs, homeopathic remedies, or celery and other juicy low-calorie vegetables.
Religious diets.
Religious scripture may be a factor in motivating people to adopt a specific diet. For example, the Biblical Book of Daniel (1:2-20, and 10:2-3) refers to a 10 or 21 day avoidance of foods (Daniel Fast) declared unclean by God in the laws of Moses. In modern versions of the Daniel Fast, food choices may be limited to whole grains, fruits, vegetables, pulses, nuts, seeds and oil. The Daniel Fast resembles the vegan diet in that it excludes (fasts from) the consumption of foods of animal origin. The passages strongly suggest that the Daniel Fast will promote good health and mental performance.
Nutrition.
Weight loss diets that manipulate the proportion of macronutrients (low-fat, low-carbohydrate, etc.) have been shown to be more effective than diets that maintain a typical mix of foods with smaller portions and perhaps some substitutions (e.g. low-fat milk, or less salad dressing). Extreme diets may, in some cases, lead to malnutrition.
Heavily processed and fried foods as well as sweets, junk foods, and alcohol should also be avoided in a healthy diet.
Nutritionists also agree on the importance of avoiding fats, especially saturated fats, to reduce weight and to be healthier. They also agree on the importance of reducing salt intake because on commercial street foods such as snacks, biscuits, and bread, among others, already contain ocean-salt, thus contributing to an excess of salt daily intake.
MyPyramid Food Guidance System is the result of extensive research performed by the United States Department of Agriculture to revise the original Food Guide Pyramid. It offers a wide array of personalized options to help individuals make healthy food choices. It also provides advice on physical activity.
One of the most important things to take into consideration when either trying to lose or put on weight is output versus input. It is important to know the amount of energy your body is using every day, so that your intake fits the needs of ones personal weight goal. Someone wanting to lose weight would want a smaller energy intake than what they put out.There is no specific diet everyone should be on, because everyones bodies vary, as do their intake requirements. A more active person will burn more energy and in return need a higher intake. 
How the body eliminates fat.
When the body is expending more energy than it is consuming (e.g. when exercising), the body's cells rely on internally stored energy sources, such as complex carbohydrates and fats, for energy. The first source to which the body turns is glycogen (by glycogenolysis). Glycogen is a complex carbohydrate, 65% of which is stored in skeletal muscles and the remainder; in the liver (totaling about 2,000 kcal in the whole body). It is created from the excess of ingested macronutrients, mainly carbohydrates. When glycogen is nearly depleted, the body begins lipolysis, the mobilization and catabolism of fat stores for energy. In this process, fats; obtained from adipose tissue, or fat cells, are broken down into glycerol and fatty acids, which can be used to generate energy. The primary by-products of metabolism are carbon dioxide and water; carbon dioxide is expelled through the respiratory system.
Weight loss groups.
Some weight loss groups aim to make money, others work as charities. The former include Weight Watchers and Peertrainer. The latter include Overeaters Anonymous and groups run by local organizations.
These organizations' customs and practices differ widely. Some groups are modelled on twelve-step programs, while others are quite informal. Some groups advocate certain prepared foods or special menus, while others train dieters to make healthy choices from restaurant menus and while grocery-shopping and cooking.
Food diary.
A 2008 study published in the American Journal of Preventive Medicine showed that dieters who kept a daily food diary (or diet journal), lost twice as much weight as those who did not keep a food log, suggesting that if you record your eating, you wouldn't eat as many calories.
Medications.
The most recent prescription weight loss medication released is Acomplia (generic name Rimonabant), manufactured by Sanofi Aventis. Used to treat obesity in persons with a BMI (body mass index) of 30 or above, as well as for smoking cessation treatments, Acomplia is still pending FDA approval for use in the United States. Other weight loss medications, like amphetamine, are addictive and consequently are now banned in the US for casual weight loss. Some supplements, including those containing vitamins and minerals, may not be effective for weight loss.
Diuretics.
Diuretics induce weight loss through the excretion of water. Diuretics, which can be used in the forms of medications, supplements, or herbs, reduce overall body weight, but have no effect on an individual's total body fat content. Diuretics can thicken the blood, cause cramping, kidney and liver damage. In a single report, the death of Jacqueline Henson was found to be related to swelling in her brain, which was associated with excessive water consumption over a short period of time, while she was on a special water diet.
Possible weight loss effects of drinking water prior to meals.
A 2009 review found that existing limited evidence suggests that encouraging water consumption and substituting energy-free beverages for energy-containing beverages may facilitate weight management. A 2009 article found that drinking 500 ml of water prior to meals for a 12-week period resulted in increased long-term weight reduction. (References given in main article.)
Fasting.
Lengthy fasting can be dangerous due to the risk of malnutrition and should be carried out under medical supervision. During prolonged fasting or very low calorie diets, the reduction of blood glucose, the preferred energy source of the brain, causes the body to deplete its glycogen stores. Once glycogen is depleted the body begins to fuel the brain using ketones, while also metabolizing body protein (including but not limited to skeletal muscle) to be used to synthesize sugars for use as energy by the rest of the body. Most experts believe that a prolonged fast can lead to muscle wasting although some dispute this. The use of short-term fasting, or various forms of intermittent fasting have been used as a form of dieting to circumvent this issue.
Fasting may refer to the avoidance of specific foods. For example, the modern Daniel Fast resembles the vegan diet because it fasts from foods of animal origin. Meat, dairy, eggs, and fish are replaced by whole grains, fruits, vegetables, pulses, nuts, seeds and oil.
Side effects.
While there are studies that show the health and medical benefits of weight loss, a study in 2005 of around 3000 Finns over an 18-year period showed that weight loss from dieting can result in increased mortality, while those who maintained their weight fared the best. Similar conclusion is drawn by other studies, and although other studies suggest that intentional weight loss has a small benefit for individuals classified as unhealthy, it is associated with slightly increased mortality for healthy individuals and the slightly overweight but not obese. This may reflect the loss of subcutaneous fat and beneficial mass from organs and muscle in addition to visceral fat when there is a sudden and dramatic weight loss.
Low carbohydrate versus low fat.
Many studies have focused on diets that reduce calories via a low-carbohydrate (Atkins diet, Scarsdale diet, Zone diet) diet versus a low-fat diet (LEARN diet, Ornish diet). The Nurses' Health Study, an observational cohort study, found that low carbohydrate diets based on vegetable sources of fat and protein are associated with less coronary heart disease. The same study also found no correlation (with multivariate adjustment) between animal fat intake and coronary heart disease (table 4). A long term study that monitored 43,396 Swedish women however suggests that a low carbohydrate-high protein diet, used on a regular basis and without consideration of the nature of carbohydrates or the source of proteins, are associated with increased risk of cardiovascular disease.
A meta-analysis of randomized controlled trials by the international Cochrane Collaboration in 2002 concluded that fat-restricted diets are no better than calorie restricted diets in achieving long term weight loss in overweight or obese people. A more recent meta-analysis that included randomized controlled trials published after the Cochrane review found that "low-carbohydrate, non-energy-restricted diets appear to be at least as effective as low-fat, energy-restricted diets in inducing weight loss for up to 1 year. However, potential favorable changes in triglyceride and high-density lipoprotein cholesterol values should be weighed against potential unfavorable changes in low-density lipoprotein cholesterol values when low-carbohydrate diets to induce weight loss are considered."
The Women's Health Initiative Randomized Controlled Dietary Modification Trial found that a diet of total fat to 20% of energy and increasing consumption of vegetables and fruit to at least 5 servings daily and grains to at least 6 servings daily resulted in:
Additional recent randomized controlled trials have found that:
The American Diabetes Association released for the first time a recommendation (in its January 2008 Clinical Practice Recommendations) for a low carbohydrate diet to reduce weight for those with or at risk of Type 2 diabetes.
Low glycemic index.
"The glycemic index (GI) factor is a ranking of foods based on their overall effect on blood sugar levels. The diet based around this research is called the Low GI diet. Low glycemic index foods, such as lentils, provide a slower, more consistent source of glucose to the bloodstream, thereby stimulating less insulin release than high glycemic index foods, such as white bread."
The glycemic load is "the mathematical product of the glycemic index and the carbohydrate amount".
In a randomized controlled trial that compared four diets that varied in carbohydrate amount and glycemic index found complicated results:
Diets 2 and 3 lost the most weight and fat mass; however, low density lipoprotein fell in Diet 2 and rose in Diet 3. Thus the authors concluded that the high-carbohydrate, low-glycemic index diet was the most favorable.
A meta-analysis by the Cochrane Collaboration concluded that low glycemic index or low glycemic load diets led to more weight loss and better lipid profiles. "However", the Cochrane Collaboration grouped low glycemic index and low glycemic load diets together and did not try to separate the effects of the load versus the index.

</doc>
<doc id="8461" url="http://en.wikipedia.org/wiki?curid=8461" title="Diet">
Diet

Diet may refer to:
Food.
Diet (nutrition), the sum of the food consumed by an organism or group.

</doc>
<doc id="8463" url="http://en.wikipedia.org/wiki?curid=8463" title="Dubnium">
Dubnium

Dubnium is a chemical element with symbol Db and atomic number 105. It is named after the town of Dubna in Russia, where it was first produced. It is a synthetic element (an element that can be created in a laboratory but is not found in nature) and radioactive; the most stable known isotope, dubnium-268, has a half-life of approximately 28 hours.
In the periodic table of the elements, it is a d-block element and in the transactinide elements. It is a member of the 7th period and belongs to Group 5. Chemistry experiments have confirmed that dubnium behaves as the heavier homologue to tantalum in group 5. The chemical properties of dubnium are characterized only partly. They are similar to those of other group 5 elements.
In the 1960s and 1970s, microscopic amounts of dubnium were produced in laboratories in the former Soviet Union and in California. The priority of the discovery and therefore the naming of the element was disputed between Soviet and American scientists, and it was not until 1997 that IUPAC established "dubnium" as the official name for the element.
History.
Discovery.
Dubnium was reportedly first discovered in 1968 at the Joint Institute for Nuclear Research at Dubna (then in the Soviet Union). Researchers there bombarded an americium-243 target with neon-22 ions. They reported a 9.40 MeV and a 9.70 MeV alpha-activity and assigned the decays to the isotope 260Db or 261Db:
Two years later the Dubna team separated their reaction products by thermal gradient chromatography after conversion to chlorides by interaction with NbCl5. The team identified a 2.2 second spontaneous fission activity contained within a volatile chloride portraying eka-tantalum properties, likely dubnium-261 pentachloride, 261DbCl5.
In the same year, a team led by Albert Ghiorso working at the University of California, Berkeley conclusively synthesized the element by bombarding a californium-249 target with nitrogen-15 ions. The team published a convincing synthesis of 260Db in the reaction between californium-249 target and nitrogen-15 ions and measured the alpha decay of 260Db with a half-life of 1.6 seconds and a decay energy of 9.10 MeV, correlated with the daughter decay of lawrencium-256:
These results by the Berkeley scientists did not confirm the Soviet findings regarding the 9.40 MeV or 9.70 MeV alpha-decay of dubnium-260, leaving only dubnium-261 as possible produced isotope. In 1971, the Dubna team repeated their reaction using an improved set-up and were able to confirm the decay data for 260Db using the reaction:
In 1976, the Dubna team continued their study of the reaction using thermal gradient chromatography and were able to identify the product as dubnium-260 pentabromide, 260DbBr5.
In 1992 the IUPAC/IUPAP Transfermium Working Group assessed the claims of the two groups and concluded that confidence in the discovery grew from results from both laboratories and the claim of discovery should be shared.
Naming controversy.
The Soviet, later Russian, team proposed the name "nielsbohrium" (Ns) in honor of the Danish nuclear physicist Niels Bohr. The American team proposed that the new element should be named "hahnium" (Ha), in honor of the late German chemist Otto Hahn. Consequently "hahnium" was the name that most American and Western European scientists used and appears in many papers published at the time, and "nielsbohrium" was used in the Soviet Union and Eastern Bloc countries.
An element naming controversy erupted between the two groups. The International Union of Pure and Applied Chemistry (IUPAC) thus adopted "unnilpentium" (Unp) as a temporary, systematic element name. Attempting to resolve the issue, in 1994, the IUPAC proposed the name "joliotium" (Jl), after the French physicist Frédéric Joliot-Curie, which was originally proposed by Soviet team for element 102, later named nobelium. The two principal claimants still disagreed about the names of elements 104-106. However, in 1997 they resolved the dispute and adopted the current name, "dubnium" (Db), after the Russian town of Dubna, the location of the Joint Institute for Nuclear Research. It was argued by IUPAC that the Berkeley laboratory had already been recognized several times in the naming of elements (i.e., berkelium, californium, americium) and that the acceptance of the names "rutherfordium" and "seaborgium" for elements 104 and 106 should be offset by recognizing the Russian team's contributions to the discovery of elements 104, 105 and 106.
Chemical properties.
Extrapolated properties.
Element 105 is projected to be the second member of the 6d series of transition metals and the heaviest member of group V in the Periodic Table, below vanadium, niobium and tantalum. Because it is positioned right below tantalum, it may also be called "eka-tantalum". All the members of the group readily portray their oxidation state of +5 and the state becomes more stable as the group is descended. Thus dubnium is expected to form a stable +5 state. For this group, +4 and +3 states are also known for the heavier members and dubnium may also form these reducing oxidation states.
In an extrapolation of the chemistries from niobium and tantalum, dubnium should react with oxygen to form an inert pentoxide, Db2O5. In alkali, the formation of an orthodubnate complex, DbO43-, is expected.
Reaction with the halogens should readily form the pentahalides, DbX5. The pentachlorides of niobium and tantalum exist as volatile solids or monomeric trigonal bipyramidal molecules in the vapour phase. Thus, DbCl5 is expected to be a volatile solid. Similarly, the pentafluoride, DbF5, should be even more volatile.
Hydrolysis of the halides is known to readily form the oxyhalides, MOX3. Thus the halides DbX5 should react with water to form DbOX3.
The reaction with fluoride ion is also well known for the lighter homologues and dubnium is expected to form a range of fluoro-complexes. In particular, reaction of the pentafluoride with HF should form a hexafluorodubnate ion, DbF6-. Excess fluoride should lead to DbF72- and DbOF52-. If eka-tantalum properties are portrayed, higher concentrations of fluoride should ultimately form DbF83- since NbF83- is not known.
Experimental chemistry.
The chemistry of dubnium has been studied for several years using gas thermochromatography. The experiments have studied the relative adsorption characteristics of isotopes of niobium, tantalum and dubnium radioisotopes. The results have indicated the formation of typical group 5 halides and oxyhalides, namely DbCl5, DbBr5, DbOCl3 and DbOBr3. Reports on these early experiments usually refer to dubnium as hahnium.
Nucleosynthesis history.
Cold fusion.
"This section deals with the synthesis of nuclei of dubnium by so-called "cold" fusion reactions. These are processes which create compound nuclei at low excitation energy (~10-20 MeV, hence "cold"), leading to a higher probability of survival from fission. The excited nucleus then decays to the ground state via the emission of one or two neutrons only."
The first attempts to synthesise dubnium using cold fusion reactions were performed in 1976 by the team at FLNR, Dubna using the above reaction. They were able to detect a 5 s spontaneous fission (SF) activity which they assigned to 257Db. This assignment was later corrected to 258Db.
In 1981, the team at GSI studied this reaction using the improved technique of correlation of genetic parent-daughter decays. They were able to positively identify 258Db, the product from the 1n neutron evaporation channel.
In 1983, the team at Dubna revisited the reaction using the method of identification of a descendant using chemical separation. They succeeded in measuring alpha decays from known descendants of the decay chain beginning with 258Db. This was taken as providing some evidence for the formation of dubnium nuclei.
The team at GSI revisited the reaction in 1985 and were able to detect 10 atoms of 257Db.
After a significant upgrade of their facilities in 1993, in 2000 the team measured 120 decays of 257Db, 16 decays of 256Db and decay of 258Db in the measurement of the 1n, 2n and 3n excitation functions. The data gathered for 257Db allowed a first spectroscopic study of this isotope and identified an isomer, 257mDb, and a first determination of a decay level structure for 257Db.
The reaction was used in spectroscopic studies of isotopes of mendelevium and einsteinium in 2003–2004.
This reaction was studied by Yuri Oganessian and the team at Dubna in 1983. They observed a 2.6 s SF activity tentatively assigned to 256Db. Later results suggest a possible reassignment to 256Rf, resulting from the ~30% EC branch in 256Db.
This reaction was studied by Yuri Oganessian and the team at Dubna in 1983. They observed a 1.6 s activity with a ~80% alpha branch with a ~20% SF branch. The activity was tentatively assigned to 255Db. Later results suggest a reassignment to 256Db.
The team at Dubna also studied this reaction in 1976 and were again able to detect the 5 s SF activity, first tentatively assigned to 257Db and later to 258Db.
In 2006, the team at LBNL reinvestigated this reaction as part of their odd-Z projectile program. They were able to detect 258Db and 257Db in their measurement of the 1n and 2n neutron evaporation channels.
The team at Dubna also studied this reaction in 1976 but this time they were unable to detect the 5 s SF activity, first tentatively assigned to 257Db and later to 258Db. Instead, they were able to measure a 1.5 s SF activity, tentatively assigned to 255Db.
The team at Dubna also studied this reaction in 1976 and were again able to detect the 5 s SF activity, first tentatively assigned to 257Db and later to 258Db.
Hot fusion.
"This section deals with the synthesis of nuclei of dubnium by so-called "hot" fusion reactions. These are processes which create compound nuclei at high excitation energy (~40-50 MeV, hence "hot"), leading to a reduced probability of survival from fission and quasi-fission. The excited nucleus then decays to the ground state via the emission of 3-5 neutrons."
There are very limited reports that this rare reaction using a P-31 beam was studied in 1989 by Andreyev et al. at the FLNR. One source suggests that no atoms were detected whilst a better source from the Russians themselves indicates that 258Db was synthesised in the 5n channel with a yield of 120 pb.
In 2006, as part of their study of the use of uranium targets in superheavy element synthesis, the LBNL team led by Ken Gregorich studied the excitation functions for the 4n and 5n channels in this new reaction.
This reaction was first studied by Andreyev et al. at the FLNR, Dubna in 1992. They were able to observe 258Db and 257Db in the 5n and 6n exit channels with yields of 450 pb and 75 pb, respectively.
The first attempts to synthesise dubnium were performed in 1968 by the team at the Flerov Laboratory of Nuclear Reactions (FLNR) in Dubna, Russia. They observed two alpha lines which they tentatively assigned to 261Db and 260Db.
They repeated their experiment in 1970 looking for spontaneous fission. They found a 2.2 s SF activity which they assigned to 261Db.
In 1970, the Dubna team began work on using gradient thermochromatography in order to detect dubnium in chemical experiments as a volatile chloride. In their first run they detected a volatile SF activity with similar adsorption properties to NbCl5 and unlike HfCl4. This was taken to indicate the formation of nuclei of dvi-niobium as DbCl5. In 1971, they repeated the chemistry experiment using higher sensitivity and observed alpha decays from an dvi-niobium component, taken to confirm the formation of 260Db. The method was repeated in 1976 using the formation of bromides and obtained almost identical results, indicating the formation of a volatile, dvi-niobium-like DbBr5.
In 2000, Chinese scientists at the Institute of Modern Physics (IMP), Lanzhou, announced the discovery of the previously unknown isotope 259Db formed in the 4n neutron evaporation channel. They were also able to confirm the decay properties for 258Db.
This reaction was first studied in 1999 at the Paul Scherrer Institute (PSI) in order to produce 262Db for chemical studies. Just 4 atoms were detected with a cross section of 260 pb.
Japanese scientists at JAERI studied the reaction further in 2002 and determined yields for the isotope 262Db during their efforts to study the aqueous chemistry of dubnium.
Following from the discovery of 260Db by Albert Ghiorso in 1970 at the University of California (UC), the same team continued in 1971 with the discovery of the new isotope 262Db. They also observed an unassigned 25 s SF activity, probably associated with the now-known SF branch of 263Db.
In 1990, a team led by Kratz at LBNL definitively discovered the new isotope 263Db in the 4n neutron evaporation channel.
This reaction has been used by the same team on several occasions in order to attempt to confirm an electron capture (EC) branch in 263Db leading to long-lived 263Rf (see rutherfordium).
Following from the discovery of 260Db by Albert Ghiorso in 1970 at the University of California (UC), the same team continued in 1971 with the discovery of the new isotope 261Db.
Following from the discovery of 260Db by Ghiorso in 1970 at LBNL, the same team continued in 1971 with the discovery of the new isotope 261Db.
In 1970, the team at the Lawrence Berkeley National Laboratory (LBNL) studied this reaction and identified the isotope 260Db in their discovery experiment. They used the modern technique of correlation of genetic parent-daughter decays to confirm their assignment.
In 1977, the team at Oak Ridge repeated the experiment and were able to confirm the discovery by the identification of K X-rays from the daughter lawrencium.
In 1988, scientists as the Lawrence Livermore National Laboratory (LLNL) used the asymmetric hot fusion reaction with an einsteinium-254 target to search for the new nuclides 264Db and 263Db. Due to the low sensitivity of the experiment caused by the small Es-254 target,they were unable to detect any evaporation residues (ER).
Decay of heavier nuclides.
Isotopes of dubnium have also been identified in the decay of heavier elements. Observations to date are summarised in the table below:
Isotopes.
Isomerism.
Recent data on the decay of 272Rg has revealed that some decay chains continue through 260Db with extraordinary longer life-times than expected. These decays have been linked to an isomeric level decaying by alpha decay with a half-life of ~19 s. Further research is required to allow a definite assignment.
Evidence for an isomeric state in 258Db has been gathered from the study of the decay of 266Mt and 262Bh. It has been noted that those decays assigned to an electron capture (EC) branch has a significantly different half-life to those decaying by alpha emission. This has been taken to suggest the existence of an isomeric state decaying by EC with a half-life of ~20 s. Further experiments are required to confirm this assignment.
A study of the formation and decay of 257Db has proved the existence of an isomeric state. Initially, 257Db was taken to decay by alpha emission with energies 9.16,9.07 and 8.97 MeV. A measurement of the correlations of these decays with those of 253Lr have shown that the 9.16 MeV decay belongs to a separate isomer. Analysis of the data in conjunction with theory have assigned this activity to a meta stable state, 257mDb. The ground state decays by alpha emission with energies 9.07 and 8.97 MeV. Spontaneous fission of 257m,gDb was not confirmed in recent experiments.
Retracted isotopes.
In 1983, scientists at Dubna carried out a series of supportive experiments in their quest for the discovery of bohrium. In two such experiments, they claimed they had detected a ~1.5 s spontaneous fission activity from the reactions 207Pb(51V,xn) and 209Bi(48Ti,xn). The activity was assigned to 255Db. Later research suggested that the assignment should be changed to 256Db. As such, the isotope 255Db is currently not recognised on the chart of radionuclides and further research is required to confirm this isotope.

</doc>
<doc id="8464" url="http://en.wikipedia.org/wiki?curid=8464" title="Disaccharide">
Disaccharide

A disaccharide or biose is the carbohydrate which is formed when two monosaccharides(simple sugars) undergo a condensation reaction which involves the elimination of a small molecule, such as water, from the functional groups only. Like monosaccharides, disaccharides form an aqueous solution when dissolved in water. Three common references are sucrose, lactose, and maltose.
"Disaccharide" is one of the four chemical groupings of carbohydrates (monosaccharide, disaccharide, oligosaccharide, and polysaccharide).
The most common types of disaccharides-sucrose, lactose, and maltose- have 12 carbon atoms, with the general formula C12H22O11. The differences in the disaccharides are due to atomic arrangements within the molecule.
Classification.
There are two different types of disaccharides: 
Formation.
Disaccharides are formed when two monosaccharides are joined together and a molecule of water is removed, a process known as dehydration reaction. For example; milk sugar (lactose) is made from glucose and galactose whereas the sugar from sugar cane and sugar beets (sucrose) is made from glucose and fructose. Maltose, another notable disaccharide, is made up of two glucose molecules. 
The two monosaccharides are bonded via a dehydration reaction (also called a condensation reaction or dehydration synthesis) that leads to the loss of a molecule of water and formation of a glycosidic bond.
Properties.
The glycosidic bond can be formed between any hydroxyl group on the component monosaccharide. So, even if both component sugars are the same (e.g., glucose), different bond combinations (regiochemistry) and stereochemistry ("alpha-" or "beta-") result in disaccharides that are diastereoisomers with different chemical and physical properties.
Depending on the monosaccharide constituents, disaccharides are sometimes crystalline, sometimes water-soluble, and sometimes sweet-tasting and sticky-feeling.
Common disaccharides.
Maltose, cellobiose, and chitobiose are hydrolysis products of the polysaccharides starch, cellulose, and chitin, respectively.
Less common disaccharides include:

</doc>
<doc id="8465" url="http://en.wikipedia.org/wiki?curid=8465" title="Dactylic hexameter">
Dactylic hexameter

Dactylic hexameter (also known as "heroic hexameter") is a form of meter in poetry or a rhythmic scheme. It is traditionally associated with the quantitative meter of classical epic poetry in both Greek and Latin, and was consequently considered to be "the" Grand Style of classical poetry. The premier examples of its use are Homer's "Iliad" and "Odyssey" and Virgil's "Aeneid".
Structure.
The meter consists of lines made from six ("hex") feet. In strict dactylic hexameter, each of these feet would be a dactyl, but classical meter allows for the substitution of a spondee (two long syllables) in place of a dactyl in most positions. Specifically, the first four feet can either be dactyls or spondees more or less freely. The fifth foot is frequently a dactyl (around 95% of the time in Homer). 
Because of the anceps, the sixth foot can be filled by either a trochee or a spondee. However, because of the strong pause at the end of the line (which prevents elision and correption between lines in the dactylic hexameter), it is traditionally regarded as a spondee. Thus the dactylic line most normally looks as follows:
As in all classical verse forms, the phenomenon of "brevis in longo" is observed, so the last syllable can actually be short or long.
Hexameters also have a primary caesura — a break in sense, much like the function of a comma in prose — at one of several normal positions: After the first syllable in the third foot (the "masculine" caesura); after the second syllable in the third foot if the third foot is a dactyl (the "feminine" caesura); after the first syllable of the fourth foot; or after the first syllable of the second foot (the latter two often occur together in a line, breaking it into three separate units). The first possible caesura that one encounters in a line is considered the main caesura. A masculine caesura can offset a hiatus, causing lengthening of an otherwise light syllable. 
In addition, hexameters have two bridges, places where there very rarely is a break in a word-unit. The first, known as Meyer's Bridge, is in the second foot: if the second foot is a dactyl, the two short syllables generally will be part of the same word-unit. The second, known as Hermann's Bridge, is the same rule in the fourth foot: if the fourth foot is a dactyl, the two short syllables generally will be part of the same word-unit. 
It must be stressed that Meyer's and Hermann's Bridge concern only Homeric verse and are not observed in Latin dactylic hexameter. Even in Homer, these bridges are not prescriptive. The first line of the Iliad violates Meyer's Bridge (Μῆνιν ἄειδε θεὰ Πηληϊάδεω Ἀχιλῆος) since there is a word break between ἄειδε and θεὰ.
Hexameters are frequently enjambed, which helps to create the long, flowing narrative of epic. They are generally considered the most grandiose and formal meter.
An English language example of the dactylic hexameter, in quantitative meter:
As the absurd meaning of this example demonstrates, quantitative meter is extremely difficult to construct in English. Here is an example in normal stress meter (the first line of Longfellow's "Evangeline"):
The "foot" is often compared to a musical measure and the long and short syllables to half notes (minims) and quarter notes (crotchets), respectively.
Homer’s meter.
The hexameter was first used by early Greek poets of the oral tradition, and the most complete extant examples of their works are the "Iliad" and the "Odyssey", which influenced the authors of all later classical epics that survive today. Early epic poetry was also accompanied by music, and pitch changes associated with the accented Greek must have highlighted the melody, though the exact mechanism is still a topic of discussion.
The Homeric poems arrange words in the line so that there is an interplay between the metrical ictus—the first long syllable of each foot—and the natural, spoken accent of words. If these two features of the language coincide too frequently, they overemphasize each other and the hexameter becomes sing-songy. Nevertheless, some reinforcement is desirable so that the poem has a natural rhythm. Balancing these two considerations is what eventually leads to rules regarding the correct placement of the caesura and breaks between words; in general, word breaks occur in the middle of metrical feet, while accent and ictus coincide only near the end of the line.
The first line of Homer’s Iliad—"Sing, goddess, the anger of Peleus’ son Achilles"—provides an example:
Dividing the line into metrical units:
Note how the word endings do not coincide with the end of a metrical foot; for the early part of the line this forces the natural accent of each word to lie in the middle of a foot, playing against the natural rhythm of the ictus. 
This line also includes a masculine caesura after "θεά", a natural break that separates the line into two logical parts. Unlike later writers, Homeric lines more commonly employ the feminine caesura; an example occurs in Iliad I.5 “...and every bird; thus the plan of Zeus came to fulfillment”:
Homer’s hexameters contain a far higher proportion of dactyls than later hexameter poetry. They are also characterised by a laxer following of verse principles that the authors of later epics almost invariably adhered to. For example, Homer allows spondaic fifth feet (albeit not often), whereas many later authors virtually never did. There are also exceptions to Meyer’s Bridge and Hermann’s Bridge in Homer (albeit rare), but such violations are exceedingly rare in a later author like Callimachus.
Homer also altered the forms of words to allow them to fit the hexameter, typically by using a dialectal form: "ptolis" is an epic form used instead of the Attic "polis" wherever it is necessary for the meter. On occasion, the names of characters themselves actually seem to have been altered: the spelling of the name of Homer’s character Polydamas, "Pouludamas", appears to be an alternative rendering of the metrically unviable "Poludamas" (“subduer of many”). 
Finally, even after accepting the various alterations admitted by Homer, some lines remain impossible to scan as they stand now, e.g. Iliad I.108 “not a good word spoken nor brought to pass”:
The first three feet of this line scan spondee-dactyl-spondee, but the fourth foot of -πας ἔπος has three consecutive short syllables. These metrical inconsistencies (along with a knowledge of comparative linguistics) have led scholars to infer the presence of a lost digamma consonant in an old form of that line. In this example, the word ἔπος was originally ϝέπος in Ionian; this consonant lengthens the last syllable of the preceding εἶπας and corrects the apparent defect in the meter. This example demonstrates the oral tradition of the Homeric epics that flourished long before they were written down sometime in the 7th century BC.
In spite of the occasional exceptions in early epic, most of the later rules of hexameter composition have their origins in the methods and practices of Homer.
Latin hexameter.
The hexameter came into Latin as an adaptation from Greek long after the practice of singing the epics had faded. Consequentially, the properties of the meter were learned as specific "rules" rather than as a natural result of musical expression. Also, because the Latin language generally has a higher percentage of long syllables than Greek, it is by nature more spondaic than Greek. These factors caused the Latin hexameter to take on distinct Latin characteristics. 
The earliest example of the use of hexameter in Latin poetry is that of the "Annales" of Ennius, which established the dactylic hexameter as the standard for later Latin epic. Later Republican writers, such as Lucretius, Catullus and even Cicero, wrote their own compositions in the meter and it was at this time that many of the principles of Latin hexameter were firmly established, ones that would govern later writers such as Virgil, Ovid, Lucan, and Juvenal. Virgil's opening line for the Aeneid is a classic example of Latin hexameter: 
As in Greek, lines were arranged such that the metrically long syllables—those occurring at the beginning of a foot—avoided the natural stress of a word. In the first few feet of the meter, meter and stress were expected to clash, while in the final few feet they were expected to resolve and coincide—an effect that gives each line a natural "dum-ditty-dum-dum" ("shave and a haircut") rhythm to close. Such an arrangement is a balance between an exaggerated emphasis on the metre—which would cause the verse to be sing-songy—and the need to provide some repeated rhythmic guide for skilled recitation.
In the following example of Ennius's early Latin hexameter composition, metrical weight ("ictus") falls on the first and last syllables of "certabant"; the ictus is therefore opposed to the natural stress on the second syllable when the word is pronounced. Similarly, the second syllable of the words "urbem" and "Romam" carry the metrical ictus even though the first is naturally stressed in typical pronunciation. In the closing feet of the line, the natural stress that falls on the third syllable of "Remoramne" and the second syllable of "vocarent" coincide with the metrical ictus and produce the characteristic "shave and a haircut" ending:
Like their Greek predecessors, classical Latin poets avoided a large number of word breaks at the ends of foot divisions except between the fourth and fifth, where it was encouraged. In order to preserve the rhythmic close, Latin poets avoided the placement of a single syllable or four-syllable word at the end of a line. The caesura is also handled far more strictly, with Homer's feminine caesura becoming exceedingly rare, and the second-foot caesura always paired with one in the fourth.
One example of the evolution of the Latin verse form can be seen in a comparative analysis of the use of spondees in Ennius' time vs. the Augustan age. The repeated use of the heavily spondaic line came to be frowned upon, as well as the use of a high proportion of spondees in both of the first two feet. The following lines of Ennius would not have been felt admissible by later authors since they both contain repeated spondees at the beginning of consecutive lines:
However, it is from Vergil that the following famous, heavily spondaic line comes:
Virgil and the Augustan poets.
By the age of Augustus, poets like Virgil closely followed the rules of the meter and approached it in a highly rhetorical way, looking for effects that can be exploited in skilled recitation. For example, the following line from the Aeneid (VIII.596) describes the movement of rushing horses and how "a hoof shakes the crumbling field with a galloping sound":
This line is made up of five dactyls and a closing spondee, an unusual rhythmic arrangement that imitates the described action. A similar effect is found in VIII.452, where Virgil describes how the blacksmith sons of Vulcan "take up their arms with great strength one to another" in forging Aeneas' shield: 
The line consists of all spondees except for the usual dactyl in the fifth foot, and is meant to mimic the pounding sound of the work. A third example that mixes the two effects comes from I.42, where Juno pouts that Athena was allowed to use Jove's thunderbolts to destroy Ajax ("she hurled Jove's quick fire from the clouds"): 
This line is nearly all dactyls except for the spondee at "-lata e". This change in rhythm paired with the harsh elision is intended to emphasize the crash of Athena's thunderbolt.
Virgil will occasionally deviate from the strict rules of the meter to produce a special effect. One example from I.105 describing a ship at sea during a storm has Virgil violating metrical standards to place a single-syllable word at the end of the line:
The boat "gives its side to the waves; there comes next in a heap a steep mountain of water." By placing the monosyllable "mons" at the end of the line, Virgil interrupts the usual "shave and a haircut" pattern to produce a jarring rhythm, an effect that echoes the crash of a large wave against the side of a ship.
One final, amusing example that comments on the importance Roman poets placed on their verse rules comes from the Ars Poetica of Horace, line 263:
The line, which lacks a proper caesura, is translated "Not every critic sees an inharmonious verse."
Silver Age and later heroic verse.
The verse innovations of the Augustan writers were carefully imitated by their successors in the Silver Age of Latin Literature. The verse form itself then was little changed, as the quality of a poet's hexameter was judged against the standard set by Virgil and the other Augustan poets, a respect for literary precedent encompassed by the Latin word "aemulatio". Deviations were generally regarded as idiosyncrasies or hallmarks of personal style, and were not imitated by later poets. Juvenal, for example, was fond of occasionally creating verses that placed a sense break between the fourth and fifth foot (instead of in the usual caesura positions), but this technique—known as the bucolic diaeresis—did not catch on with other poets.
In the late empire, writers experimented again by adding unusual restrictions to the standard hexameter. The rhopalic verse of Ausonius is a good example; besides following the standard hexameter pattern, each word in the line is one syllable longer than the previous, e.g.:
Also notable is the tendency among late grammarians to thoroughly dissect the hexameters of Virgil and earlier poets. A treatise on poetry by Diomedes Grammaticus is a good example, as this work (among other things) categorizes dactylic hexameter verses in ways that were later interpreted under the golden line rubric. Independently, these two trends show the form becoming highly artificial—more like a puzzle to solve than a medium for personal poetic expression. 
By the Middle Ages, some writers adopted more relaxed versions of the meter. Bernard of Cluny, for example, employs it in his "De Contemptu Mundi", but ignores classical conventions in favor of accentual effects and predictable rhyme both within and between verses, e.g.:
Not all Medieval writers are so at odds with the Virgilian standard, and with the rediscovery of classical literature, later Medieval and Renaissance writers are far more orthodox, but by then the form had become an academic exercise. Petrarch, for example, devoted much time to his "Africa", a dactylic hexameter epic on Scipio Africanus, but this work was unappreciated in his time and remains little read today. In contrast, Dante decided to write his epic, the "Divine Comedy" in Italian—a choice that defied the traditional epic choice of Latin dactylic hexameters—and produced a masterpiece beloved both then and now.
With the New Latin period, the language itself came to be regarded as a medium only for "serious" and learned expression, a view that left little room for Latin poetry. The emergence of Recent Latin in the 20th century restored classical orthodoxy among Latinists and sparked a general (if still academic) interest in the beauty of Latin poetry. Today, the modern Latin poets who use the dactylic hexameter are generally as faithful to Virgil as Rome's Silver Age poets.

</doc>
<doc id="8466" url="http://en.wikipedia.org/wiki?curid=8466" title="Dorado">
Dorado

Dorado is a constellation in the southern sky. It was named in the late 16th century and is now one of the 88 modern constellations. Its name refers to the dolphinfish ("Coryphaena hippurus"), which is known as "dorado" in Portuguese, although it has also been depicted as a swordfish. Dorado is notable for containing most of the Large Magellanic Cloud, the remainder being in the constellation Mensa. The South ecliptic pole also lies within this constellation.
Even though the name Dorado is not Latin but Portuguese, astronomers give it the Latin genitive form "Doradus" when naming its stars; they are treating it (like the adjacent constellation Argo Navis) as if it were a feminine proper name of Greek origin ending in -ō (like "Io" or "Callisto" or "Argo"), names that have a genitive ending in "-ūs".
History.
Dorado was one of twelve constellations named by Petrus Plancius from the observations of Pieter Dirkszoon Keyser and Frederick de Houtman, and it first appeared on a 35-cm diameter celestial globe published in 1597 (or 1598) in Amsterdam by Plancius with Jodocus Hondius. Its first depiction in a celestial atlas was in Johann Bayer's "Uranometria" of 1603 where it was also named Dorado. Dorado has been represented historically as a dolphinfish and a swordfish; the latter depiction is inaccurate. It has also been represented as a goldfish. The constellation was also known in the 17th and 18th century as Xiphias, the swordfish, first attested in Johannes Kepler's edition of Tycho Brahe's star list in the "Rudolphine Tables" of 1627. The name "Dorado" ultimately become dominant and was adopted by the IAU.
Notable features.
Stars.
Alpha Doradus is a blue-white star of magnitude 3.3, 176 light-years from Earth. It is the brightest star in Dorado. Beta Doradus is a notably bright Cepheid variable star. It is a yellow-tinged supergiant star that has a minimum magnitude of 4.1 and a maximum magnitude of 3.5. 1040 light-years from Earth, Beta Doradus has a period of 9 days and 20 hours.
R Doradus is one of the many variable stars in Dorado. S Dor, 9.721 hypergiant in the Large Magellanic Cloud, is the prototype of S Doradus variable stars. The variable star R Doradus 5.73 has the largest known[ [update]] apparent size of any star. Gamma Doradus is the prototype of the Gamma Doradus variable stars.
Supernova 1987A was the closest supernova to occur since the invention of the telescope. SNR 0509-67.5 is the remnant of an unusually energetic Type 1a supernova from about 400 years ago.
HE 0437-5439 is a hypervelocity star escaping from the Milky Way/Magellanic Cloud system.
Dorado is also the location of the South Ecliptic pole, which lies near the fish's head. The pole was called "Polus Doradinalis" by Willem Jansson Blaeu.
Deep-sky objects.
Because Dorado contains part of the Large Magellanic Cloud, it is rich in deep sky objects. The Large Magellanic Cloud, 1,000 light-years in diameter, is a satellite galaxy of the Milky Way, located at a distance of 179,000 light-years. It has been deformed by its gravitational interactions with the larger Milky Way. In 1987, it became host to SN 1987A, the first supernova of 1987 and the closest since 1604. This 25,000 light-year wide galaxy contains over 10,000 million stars. All coordinates given are for Epoch J2000.0.
Equivalents.
In Chinese astronomy, the stars of Dorado are located in two of Xu Guangqi's Southern Asterisms (近南極星區, "Jìnnánjíxīngōu"): the White Patches Attached (夾白, "Jiābái") and the Goldfish (金魚, "Jīnyú").
External links.
Coordinates: 

</doc>
<doc id="8467" url="http://en.wikipedia.org/wiki?curid=8467" title="Draco (lawgiver)">
Draco (lawgiver)

Draco (; Greek: Δράκων, "Drakōn"; fl. c. 7th century BC) was the first legislator of Athens in Ancient Greece. He replaced the prevailing system of oral law and blood feud by a written code to be enforced only by a court. Draco's written law became known for its harshness, with the adjective "draconian" referring to similarly unforgiving rules or laws.
Life.
During the 39th Olympiad, in 622 or 621 BC, Draco established the legal code with which he is identified.
Little is known about his life. He may have belonged to the Greek nobility of the Attica, with which the 10th-century Suda text records him as contemporaneous, prior to the period of the Seven Sages of Greece. It also relates a folkloric story of his death in the Aeginetan theatre. In a traditional ancient Greek show of approval, his supporters "threw so many hats and shirts and cloaks on his head that he suffocated, and was buried in that same theatre".
Draconian constitution.
The laws (θεσμοί - "thesmoi") he laid down were the first written constitution of Athens. So that no one would be unaware of them, they were posted on wooden tablets (ἄξονες - "axones"), where they were preserved for almost two centuries, on steles of the shape of three-sided pyramids (κύρβεις - "kyrbeis"). The tablets were called "axones", perhaps because they could be pivoted along the pyramid's axis, to read any side.
The constitution featured several major innovations:
The laws, however, were particularly harsh. For example, any debtor whose status was lower than that of his creditor was forced into slavery. The punishment was more lenient for those owing debt to a member of a lower class. The death penalty was the punishment for even minor offences, such as "stealing a cabbage". Concerning the liberal use of the death penalty in the Draconic code, Plutarch states: "It was a lot for himself, when asked why he had fixed the punishment of death for most offences, answered that he considered these lesser crimes to deserve it, and he had no greater punishment for more important ones."
All his laws were repealed by Solon in the early 6th century BC, with the exception of the homicide law.
Law of Homicide.
After much debate from the Athenians, it was decided to revise the laws, including the homicide law, in 409 B.C. The homicide law is a highly fragmented inscription, but it does state that it is up to the victim’s relatives to prosecute a killer. According to the preserved part of the inscription, unintentional homicides receive a sentence of exile, while intentional murders are punishable by death. Apart from the inscriptions very little is known about Draco’s background or the nature of most of his laws. However, the significance of his work was prevalent when most of his laws were successfully abolished by Solon.
Council of Four Hundred.
Draco introduced the lot-chosen Council of Four Hundred —distinct from the Areopagus—which evolved in later constitutions to play a large role in Athenian democracy. Aristotle notes that Draco, while having the laws written, merely legislated for an existing unwritten Athenian constitution, such as setting exact qualifications for eligibility for office.
Draco extended the franchise to all free men who could furnish themselves with a set of military equipment. They elected the Council of Four Hundred from among their number; nine Archons and the Treasurers were drawn from persons possessing an unencumbered property of not less than ten "minas", the generals ("strategoi") and commanders of cavalry ("hipparchoi") from those who could show an unencumbered property of not less than a hundred "minas", and had children born in lawful wedlock over ten years of age. Thus, in the event of their death, their estate could pass to a competent heir. These officers were required to hold to account the "prytanes" (councillors), "strategoi" (generals) and "hipparchoi" (cavalry officers) of the preceding year until their accounts had been audited. "The Council of Areopagus was guardian of the laws, and kept watch over the magistrates to see that they executed their offices in accordance with the laws. Any person who felt himself wronged might lay an information before the Council of Areopagus, on declaring what law was broken by the wrong done to him. But, as has been said before, loans were secured upon the persons of the debtors, and the land was in the hands of a few."

</doc>
<doc id="8468" url="http://en.wikipedia.org/wiki?curid=8468" title="Determinant">
Determinant

In linear algebra, the determinant is a useful value that can be computed from the elements of a square matrix. The determinant of a matrix "A" is denoted det("A"), det "A", or |"A"|.
In the case of a 2 × 2 matrix, the specific formula for the determinant is simply the upper left element times the lower right element, minus the product of the other two elements. Similarly, suppose we have a 3 × 3 matrix "A", and we want the specific formula for its determinant |"A"|:
Each determinant of a 2 × 2 matrix in this equation is called a "minor" of the matrix "A". The same sort of procedure can be used to find the determinant of a 4 × 4 matrix, the determinant of a 5 × 5 matrix, and so forth.
Determinants occur throughout mathematics. For example, a matrix is often used to represent the coefficients in a system of linear equations, and the determinant is used to solve those equations. The use of determinants in calculus includes the Jacobian determinant in the change of variables rule for integrals of functions of several variables. Determinants are also used to define the characteristic polynomial of a matrix, which is essential for eigenvalue problems in linear algebra. Sometimes, determinants are used merely as a compact notation for expressions that would otherwise be unwieldy to write down.
It can be proved that any matrix has a unique inverse if its determinant is nonzero. Various other theorems can be proved as well, including that the determinant of a product of matrices is always equal to the product of determinants; and, the determinant of a Hermitian matrix is always real.
Definition.
There are various ways to define the determinant of a square matrix "A", i.e. one with the same number of rows and columns. Perhaps the simplest way to express the determinant is by considering the elements in the top row and the respective minors; starting at the left, multiply the element by the minor, then subtract the product of the next element and its minor, and alternate adding and subtracting such products until all elements in the top row have been exhausted. For example, here is the result for a 4 × 4 matrix:
Another way to define the determinant is expressed in terms of the columns of the matrix. If we write an "n" × "n" matrix "A" in terms of its column vectors
where the formula_10 are vectors of size "n", then the determinant of "A" is defined so that
where "b" and "c" are scalars, "v" is any vector of size "n" and "I" is the identity matrix of size "n". These equations say that the determinant is a linear function of each column, that interchanging adjacent columns reverses the sign of the determinant, and that the determinant of the identity matrix is 1. These properties mean that the determinant is an alternating multilinear function of the columns that maps the identity matrix to the underlying unit scalar. These suffice to uniquely calculate the determinant of any square matrix. Provided the underlying scalars form a field (more generally, a commutative ring with unity), the definition below shows that such a function exists, and it can be shown to be unique.
Equivalently, the determinant can be expressed as a sum of products of entries of the matrix where each product has "n" terms and the coefficient of each product is −1 or 1 or 0 according to a given rule: it is a polynomial expression of the matrix entries. This expression grows rapidly with the size of the matrix (an "n" × "n" matrix contributes "n"! terms), so it will first be given explicitly for the case of 2 × 2 matrices and 3 × 3 matrices, followed by the rule for arbitrary size matrices, which subsumes these two cases.
Assume "A" is a square matrix with "n" rows and "n" columns, so that it can be written as
The entries can be numbers or expressions (as happens when the determinant is used to define a characteristic polynomial); the definition of the determinant depends only on the fact that they can be added and multiplied together in a commutative manner.
The determinant of "A" is denoted as det("A"), or it can be denoted directly in terms of the matrix entries by writing enclosing bars instead of brackets:
2 × 2 matrices.
The determinant of a 2 × 2 matrix is defined by
If the matrix entries are real numbers, the matrix "A" can be used to represent two linear maps: one that maps the standard basis vectors to the rows of "A", and one that maps them to the columns of "A". In either case, the images of the basis vectors form a parallelogram that represents the image of the unit square under the mapping. The parallelogram defined by the rows of the above matrix is the one with vertices at (0, 0), ("a", "b"), ("a" + "c", "b" + "d"), and ("c", "d"), as shown in the accompanying diagram. The absolute value of "ad" − "bc" is the area of the parallelogram, and thus represents the scale factor by which areas are transformed by "A". (The parallelogram formed by the columns of "A" is in general a different parallelogram, but since the determinant is symmetric with respect to rows and columns, the area will be the same.)
The absolute value of the determinant together with the sign becomes the "oriented area" of the parallelogram. The oriented area is the same as the usual area, except that it is negative when the angle from the first to the second vector defining the parallelogram turns in a clockwise direction (which is opposite to the direction one would get for the identity matrix).
Thus the determinant gives the scaling factor and the orientation induced by the mapping represented by "A". When the determinant is equal to one, the linear mapping defined by the matrix is equi-areal and orientation-preserving.
The object known as the "bivector" is related to these ideas. In 2D, it can be interpreted as an "oriented plane segment" formed by imagining two vectors each with origin (0, 0), and coordinates ("a", "b") and ("c", "d"). The bivector magnitude (denoted ("a", "b") ∧ ("c", "d")) is the "signed area", which is also the determinant "ad" − "bc".
3 × 3 matrices.
The determinant of a 3 × 3 matrix is defined by
The rule of Sarrus is a mnemonic for the 3 × 3 matrix determinant: the sum of the products of three diagonal north-west to south-east lines of matrix elements, minus the sum of the products of three diagonal south-west to north-east lines of elements, when the copies of the first two columns of the matrix are written beside it as in the illustration. This scheme for calculating the determinant of a 3 × 3 matrix does not carry over into higher dimensions.
"n" × "n" matrices.
The determinant of a matrix of arbitrary size can be defined by the Leibniz formula or the Laplace formula.
The Leibniz formula for the determinant of an "n" × "n" matrix "A" is
Here the sum is computed over all permutations σ of the set {1, 2, ..., "n"}. A permutation is a function that reorders this set of integers. The value in the "i"th position after the reordering σ is denoted σ"i". For example, for "n" = 3, the original sequence 1, 2, 3 might be reordered to σ = [2, 3, 1], with σ1 = 2, σ2 = 3, and σ3 = 1. The set of all such permutations (also known as the symmetric group on "n" elements) is denoted S"n". For each permutation σ, sgn(σ) denotes the signature of σ, a value that is +1 whenever the reordering given by σ can be achieved by successively interchanging two entries an even number of times, and −1 whenever it can be achieved by an odd number of such interchanges.
In any of the formula_17 summands, the term
is notation for the product of the entries at positions ("i", σ"i"), where "i" ranges from 1 to "n":
For example, the determinant of a 3 × 3 matrix "A" ("n" = 3) is
Levi-Civita symbol.
It is sometimes useful to extend the Leibniz formula to a summation in which not only permutations, but all sequences of "n" indices in the range 1, ..., "n" occur, ensuring that the contribution of a sequence will be zero unless it denotes a permutation. Thus the totally antisymmetric Levi-Civita symbol formula_21 extends the signature of a permutation, by setting formula_22 for any permutation σ of "n", and formula_23 when no permutation σ exists such that formula_24 for formula_25 (or equivalently, whenever some pair of indices are equal). The determinant for an "n" × "n" matrix can then be expressed using an "n"-fold summation as
or using two epsilon symbols as
where now each "ir" and each "jr" should be summed over 1, ..., "n".
Properties of the determinant.
The determinant has many properties. Some basic properties of determinants are
Property 5 says that the determinant on "n" × "n" matrices is homogeneous of degree "n". These properties can be used to facilitate the computation of determinants by simplifying the matrix to the point where the determinant can be determined immediately. Specifically, for matrices with coefficients in a field, properties 11 and 12 can be used to transform any matrix into a triangular matrix, whose determinant is given by property 6; this is essentially the method of Gaussian elimination.
For example, the determinant of
can be computed using the following matrices:
Here, "B" is obtained from "A" by adding −1/2×the first row to the second, so that det("A") = det("B"). "C" is obtained from "B" by adding the first to the third row, so that det("C") = det("B"). Finally, "D" is obtained from "C" by exchanging the second and third row, so that det("D") = −det("C"). The determinant of the (upper) triangular matrix "D" is the product of its entries on the main diagonal: (−2) · 2 · 4.5 = −18. Therefore, det("A") = −det("D") = +18.
Multiplicativity and matrix groups.
The determinant of a matrix product of square matrices equals the product of their determinants:
Thus the determinant is a "multiplicative map". This property is a consequence of the characterization given above of the determinant as the unique "n"-linear alternating function of the columns with value 1 on the identity matrix, since the function M"n"("K") → "K" that maps "M" ↦ det("AM") can easily be seen to be "n"-linear and alternating in the columns of "M", and takes the value det("A") at the identity. The formula can be generalized to (square) products of rectangular matrices, giving the Cauchy–Binet formula, which also provides an independent proof of the multiplicative property.
The determinant det("A") of a matrix "A" is non-zero if and only if "A" is invertible or, yet another equivalent statement, if its rank equals the size of the matrix. If so, the determinant of the inverse matrix is given by
In particular, products and inverses of matrices with determinant one still have this property. Thus, the set of such matrices (of fixed size "n") form a group known as the special linear group. More generally, the word "special" indicates the subgroup of another matrix group of matrices of determinant one. Examples include the special orthogonal group (which if "n" is 2 or 3 consists of all rotation matrices), and the special unitary group.
Laplace's formula and the adjugate matrix.
Laplace's formula expresses the determinant of a matrix in terms of its minors. The minor "M""i","j" is defined to be the determinant of the ("n"−1) × ("n"−1)-matrix that results from "A" by removing the "i"th row and the "j"th column. The expression (−1)"i"+"j""M""i","j" is known as cofactor. The determinant of "A" is given by
Calculating det("A") by means of that formula is referred to as expanding the determinant along a row or column. For the example 3 × 3 matrix
Laplace expansion along the second column ("j" = 2, the sum runs over "i") yields:
However, Laplace expansion is efficient for small matrices only.
The adjugate matrix adj("A") is the transpose of the matrix consisting of the cofactors, i.e.,
Sylvester's determinant theorem.
Sylvester's determinant theorem states that for "A", an "m" × "n" matrix, and "B", an "n" × "m" matrix (so that "A" and "B" have dimensions allowing them to be multiplied in either order):
where "I""m" and "I""n" are the "m" × "m" and "n" × "n" identity matrices, respectively.
From this general result several consequences follow.
Properties of the determinant in relation to other notions.
Relation to eigenvalues and trace.
Let formula_43 be an arbitrary formula_44 matrix of complex numbers with eigenvalues formula_45, formula_46, ... formula_47. (Here it is understood that an eigenvalue with algebraic multiplicities formula_48 occurs formula_48 times in this list.) Then the determinant of formula_43 is the product of all eigenvalues:
The product of all non-zero eigenvalues is referred to as pseudo-determinant.
Conversely, determinants can be used to find the eigenvalues of the matrix "A": they are the solutions of the characteristic equation
where "I" is the identity matrix of the same dimension as "A". 
An Hermitian matrix is positive definite if all its eigenvalues are positive. Sylvester's criterion asserts that this is equivalent to the determinants of the submatrices
being positive, for all "k" between 1 and "n".
The trace tr("A") is by definition the sum of the diagonal entries of "A" and also equals the sum of the eigenvalues. Thus, for complex matrices "A",
or, for real matrices "A",
Here exp("A") denotes the matrix exponential of "A", because every eigenvalue λ of "A" corresponds to the eigenvalue exp(λ) of exp("A"). In particular, given any logarithm of "A", that is, any matrix "L" satisfying
the determinant of "A" is given by
For example, for "n" = 2, "n" = 3, and "n" = 4, respectively,
cf. Cayley-Hamilton theorem. Such expressions are deducible from Newton's identities.
In the general case,
where the sum is taken over the set of all integers "kl" ≥ 0 satisfying the equation
This formula can also be used to find the determinant of a matrix "AIJ" with multidimensional indices "I" = (i1,i2...,ir) and "J" = (j1,j2...,jr). The product and trace of such matrices are defined in a natural way as
An arbitrary dimension "n" identity can be obtained from the Mercator series expansion of the logarithm when formula_64
where "I" is the identity matrix. The sum and the expansion of the exponential only need to go up to "n" instead of ∞, since the determinant cannot exceed "O"("An").
Upper and lower bounds.
For a positive definite matrix "A", the trace operator gives the following tight lower and upper bounds on the log determinant
with equality if and only if formula_67. This relationship can be derived via the formula for the KL-divergence between two multivariate normal distributions.
Cramer's rule.
For a matrix equation
the solution is given by Cramer's rule:
where "A""i" is the matrix formed by replacing the "i"th column of "A" by the column vector "b". This follows immediately by column expansion of the determinant, i.e.
where the vectors formula_10 are the columns of "A". The rule is also implied by the identity
It has recently been shown that Cramer's rule can be implemented in O("n"3) time, which is comparable to more common methods of solving systems of linear equations, such as LU, QR, or singular value decomposition.
Block matrices.
Suppose "A", "B", "C", and "D" are matrices of dimension "n" × "n", "n" × "m", "m" × "n", and "m" × "m", respectively. Then
This can be seen from the Leibniz formula, or from a decomposition like (for the former case)
When "A" is invertible, one has
as can be seen by employing the decomposition
When "D" is invertible, a similar identity with formula_77 factored out can be derived analogously, that is,
When the blocks are square matrices of the same order further formulas hold. For example, if "C" and "D" commute (i.e., "CD" = "DC"), then the following formula comparable to the determinant of a 2 × 2 matrix holds:
When "A" = "D" and "B" = "C", the blocks are square matrices of the same order and the following formula holds (even if "A" and "B" do not commute)
When "D" is a 1×1 matrix, "B" is a column vector, and "C" is a row vector then
Derivative.
By definition, e.g., using the Leibniz formula, the determinant of real (or analogously for complex) square matrices is a polynomial function from R"n" × "n" to R. As such it is everywhere differentiable. Its derivative can be expressed using Jacobi's formula:
where adj("A") denotes the adjugate of "A". In particular, if "A" is invertible, we have
Expressed in terms of the entries of "A", these are
Yet another equivalent formulation is
using big O notation. The special case where formula_86, the identity matrix, yields
This identity is used in describing the tangent space of certain matrix Lie groups.
If the matrix A is written as formula_88 where a, b, c are vectors, then the gradient over one of the three vectors may be written as the cross product of the other two:
Abstract algebraic aspects.
Determinant of an endomorphism.
The above identities concerning the determinant of products and inverses of matrices imply that similar matrices have the same determinant: two matrices "A" and "B" are similar, if there exists an invertible matrix "X" such that "A" = "X"−1"BX". Indeed, repeatedly applying the above identities yields
The determinant is therefore also called a similarity invariant. The determinant of a linear transformation
for some finite-dimensional vector space "V" is defined to be the determinant of the matrix describing it, with respect to an arbitrary choice of basis in "V". By the similarity invariance, this determinant is independent of the choice of the basis for "V" and therefore only depends on the endomorphism "T".
Exterior algebra.
The determinant of a linear transformation "A" : "V" → "V" of an "n"-dimensional vector space "V" can be formulated in a coordinate-free manner by considering the "n"th exterior power Λ"n""V" of "V". "A" induces a linear map
As Λ"n""V" is one-dimensional, the map Λ"n"A is given by multiplying with some scalar. This scalar coincides with the determinant of "A", that is to say
This definition agrees with the more concrete coordinate-dependent definition. This follows from the characterization of the determinant given above. For example, switching two columns changes the sign of the determinant; likewise, permuting the vectors in the exterior product "v"1 ∧ "v"2 ∧ "v"3 ∧ ... ∧ "v""n" to "v"2 ∧ "v"1 ∧ "v"3 ∧ ... ∧ "v""n", say, also changes its sign.
For this reason, the highest non-zero exterior power Λ"n"("V") is sometimes also called the determinant of "V" and similarly for more involved objects such as vector bundles or chain complexes of vector spaces. Minors of a matrix can also be cast in this setting, by considering lower alternating forms Λ"k""V" with "k" < "n".
Transformation on alternating multilinear "n"-forms.
The vector space "W" of all alternating multilinear "n"-forms on an "n"-dimensional vector space "V" has dimension one. To each linear transformation "T" on "V" we associate a linear transformation "T"′ on "W", where for each "w" in "W" we define ("T"′"w")("x"1, ..., "x""n") = "w"("Tx"1, ..., "Tx""n"). As a linear transformation on a one-dimensional space, "T"′ is equivalent to a scalar multiple. We call this scalar the determinant of "T".
Square matrices over commutative rings and abstract properties.
The determinant can also be characterized as the unique function
from the set of all "n" × "n" matrices with entries in a field "K" to this field satisfying the following three properties: first, "D" is an "n"-linear function: considering all but one column of "A" fixed, the determinant is linear in the remaining column, that is
for any column vectors "v"1, ..., "v""n", and "w" and any scalars (elements of "K") "a" and "b". Second, "D" is an alternating function: for any matrix "A" with two identical columns . Finally, "D"("I""n") = 1. Here "I""n" is the identity matrix.
This fact also implies that every other "n"-linear alternating function "F": M"n"("K") → "K" satisfies
This definition can also be extended where "K" is a commutative ring "R", in which case a matrix is invertible if and only if its determinant is a invertible element in "R". For example, a matrix "A" with entries in Z, the integers, is invertible (in the sense that there exists an inverse matrix with integer entries) if the determinant is +1 or −1. Such a matrix is called unimodular.
The determinant defines a mapping
between the group of invertible "n" × "n" matrices with entries in "R" and the multiplicative group of units in "R". Since it respects the multiplication in both groups, this map is a group homomorphism. Secondly, given a ring homomorphism "f": "R" → "S", there is a map GL"n"("R") → GL"n"("S") given by replacing all entries in "R" by their images under "f". The determinant respects these maps, i.e., given a matrix "A" = ("a""i","j") with entries in "R", the identity
holds. For example, the determinant of the complex conjugate of a complex matrix (which is also the determinant of its conjugate transpose) is the complex conjugate of its determinant, and for integer matrices: the reduction modulo "m" of the determinant of such a matrix is equal to the determinant of the matrix reduced modulo "m" (the latter determinant being computed using modular arithmetic). In the more high-brow parlance of category theory, the determinant is a natural transformation between the two functors GL"n" and (⋅)×. Adding yet another layer of abstraction, this is captured by saying that the determinant is a morphism of algebraic groups, from the general linear group to the multiplicative group,
Generalizations and related notions.
Infinite matrices.
For matrices with an infinite number of rows and columns, the above definitions of the determinant do not carry over directly. For example, in the Leibniz formula, an infinite sum (all of whose terms are infinite products) would have to be calculated. Functional analysis provides different extensions of the determinant for such infinite-dimensional situations, which however only work for particular kinds of operators.
The Fredholm determinant defines the determinant for operators known as trace class operators by an appropriate generalization of the formula
Another infinite-dimensional notion of determinant is the functional determinant.
Related notions for non-commutative rings.
For square matrices with entries in a non-commutative ring, there are various difficulties in defining determinants analogously to that for commutative rings. A meaning can be given to the Leibniz formula provided that the order for the product is specified, and similarly for other ways to define the determinant, but non-commutativity then leads to the loss of many fundamental properties of the determinant, for instance the multiplicative property or the fact that the determinant is unchanged under transposition of the matrix. Over non-commutative rings, there is no reasonable notion of a multilinear form (existence of a nonzero bilinear form with a regular element of "R" as value on some pair of arguments implies that "R" is commutative). Nevertheless various notions of non-commutative determinant have been formulated, which preserve some of the properties of determinants, notably quasideterminants and the Dieudonné determinant. It may be noted that if one considers certain specific classes of matrices with non-commutative elements, then there are examples where one can define the determinant and prove linear algebra theorems that are very similar to their commutative analogs. Examples include quantum groups and "q"-determinant, Capelli matrix and Capelli determinant, super-matrices and Berezinian; Manin matrices is the class of matrices which is most close to matrices with commutative elements.
Further variants.
Determinants of matrices in superrings (that is, Z2-graded rings) are known as Berezinians or superdeterminants.
The permanent of a matrix is defined as the determinant, except that the factors sgn(σ) occurring in Leibniz's rule are omitted. The immanant generalizes both by introducing a character of the symmetric group S"n" in Leibniz's rule.
Calculation.
Determinants are mainly used as a theoretical tool. They are rarely calculated explicitly in numerical linear algebra, where for applications like checking invertibility and finding eigenvalues the determinant has largely been supplanted by other techniques. Nonetheless, explicitly calculating determinants is required in some situations, and different methods are available to do so.
Naive methods of implementing an algorithm to compute the determinant include using the Leibniz formula or Laplace's formula. Both these approaches are extremely inefficient for large matrices, though, since the number of required operations grows very quickly: it is of order "n"! ("n" factorial) for an "n" × "n" matrix "M". For example, Leibniz's formula requires calculating "n"! products. Therefore, more involved techniques have been developed for calculating determinants.
Decomposition methods.
Given a matrix "A", some methods compute its determinant by writing "A" as a product of matrices whose determinants can be more easily computed. Such techniques are referred to as decomposition methods. Examples include the LU decomposition, the QR decomposition or the Cholesky decomposition (for positive definite matrices). These methods are of order O("n"3), which is a significant improvement over O("n"!)
The LU decomposition expresses "A" in terms of a lower triangular matrix "L", an upper triangular matrix "U" and a permutation matrix "P":
The determinants of "L" and "U" can be quickly calculated, since they are the products of the respective diagonal entries. The determinant of "P" is just the sign formula_103 of the corresponding permutation (which is +1 for an even number of permutations and is −1 for an uneven number of permutations). The determinant of "A" is then
Moreover, the decomposition can be chosen such that "L" is a unitriangular matrix and therefore has determinant 1, in which case the formula further simplifies to
Further methods.
If the determinant of "A" and the inverse of "A" have already been computed, the matrix determinant lemma allows to quickly calculate the determinant of "A" + "uv"T, where "u" and "v" are column vectors.
Since the definition of the determinant does not need divisions, a question arises: do fast algorithms exist that do not need divisions? This is especially interesting for matrices over rings. Indeed algorithms with run-time proportional to "n"4 exist. An algorithm of Mahajan and Vinay, and Berkowitz is based on closed ordered walks (short "clow"). It computes more products than the determinant definition requires, but some of these products cancel and the sum of these products can be computed more efficiently. The final algorithm looks very much like an iterated product of triangular matrices.
If two matrices of order "n" can be multiplied in time "M"("n"), where "M"("n") ≥ "n""a" for some "a" > 2, then the determinant can be computed in time O("M"("n")). This means, for example, that an O("n"2.376) algorithm exists based on the Coppersmith–Winograd algorithm.
Algorithms can also be assessed according to their bit complexity, i.e., how many bits of accuracy are needed to store intermediate values occurring in the computation. For example, the Gaussian elimination (or LU decomposition) methods is of order O("n"3), but the bit length of intermediate values can become exponentially long. The Bareiss Algorithm, on the other hand, is an exact-division method based on Sylvester's identity is also of order "n"3, but the bit complexity is roughly the bit size of the original entries in the matrix times "n".
History.
Historically, determinants were used long before matrices: originally, a determinant was defined as a property of a system of linear equations. The determinant "determines" whether the system has a unique solution (which occurs precisely if the determinant is non-zero). In this sense, determinants were first used in the Chinese mathematics textbook "The Nine Chapters on the Mathematical Art" (九章算術, Chinese scholars, around the 3rd century BCE). In Europe, 2 × 2 determinants were considered by Cardano at the end of the 16th century and larger ones by Leibniz.
In Japan, Seki Takakazu (関 孝和) is credited with the discovery of the resultant and the determinant (at first in 1683, the complete version no later than 1710). In Europe, Cramer (1750) added to the theory, treating the subject in relation to sets of equations. The recurrence law was first announced by Bézout (1764).
It was Vandermonde (1771) who first recognized determinants as independent functions. Laplace (1772) gave the general method of expanding a determinant in terms of its complementary minors: Vandermonde had already given a special case. Immediately following, Lagrange (1773) treated determinants of the second and third order. Lagrange was the first to apply determinants to questions of elimination theory; he proved many special cases of general identities.
Gauss (1801) made the next advance. Like Lagrange, he made much use of determinants in the theory of numbers. He introduced the word determinant (Laplace had used "resultant"), though not in the present signification, but rather as applied to the discriminant of a quantic. Gauss also arrived at the notion of reciprocal (inverse) determinants, and came very near the multiplication theorem.
The next contributor of importance is Binet (1811, 1812), who formally stated the theorem relating to the product of two matrices of "m" columns and "n" rows, which for the special case of "m" = "n" reduces to the multiplication theorem. On the same day (November 30, 1812) that Binet presented his paper to the Academy, Cauchy also presented one on the subject. (See Cauchy–Binet formula.) In this he used the word determinant in its present sense, summarized and simplified what was then known on the subject, improved the notation, and gave the multiplication theorem with a proof more satisfactory than Binet's. With him begins the theory in its generality.
The next important figure was Jacobi (from 1827). He early used the functional determinant which Sylvester later called the Jacobian, and in his memoirs in "Crelle" for 1841 he specially treats this subject, as well as the class of alternating functions which Sylvester has called "alternants". About the time of Jacobi's last memoirs, Sylvester (1839) and Cayley began their work.
The study of special forms of determinants has been the natural result of the completion of the general theory. Axisymmetric determinants have been studied by Lebesgue, Hesse, and Sylvester; persymmetric determinants by Sylvester and Hankel; circulants by Catalan, Spottiswoode, Glaisher, and Scott; skew determinants and Pfaffians, in connection with the theory of orthogonal transformation, by Cayley; continuants by Sylvester; Wronskians (so called by Muir) by Christoffel and Frobenius; compound determinants by Sylvester, Reiss, and Picquet; Jacobians and Hessians by Sylvester; and symmetric gauche determinants by Trudi. Of the textbooks on the subject Spottiswoode's was the first. In America, Hanus (1886), Weld (1893), and Muir/Metzler (1933) published treatises.
Applications.
Linear independence.
As mentioned above, the determinant of a matrix (with real or complex entries, say) is zero if and only if the column vectors (or the row vectors) of the matrix are linearly dependent. Thus, determinants can be used to characterize linearly dependent vectors. For example, given two linearly independent vectors "v"1, "v"2 in R3, a third vector "v"3 lies in the plane spanned by the former two vectors exactly if the determinant of the 3 × 3 matrix consisting of the three vectors is zero. The same idea is also used in the theory of differential equations: given "n" functions "f"1("x"), ..., "f""n"("x") (supposed to be "n" − 1 times differentiable), the Wronskian is defined to be
It is non-zero (for some "x") in a specified interval if and only if the given functions and all their derivatives up to order "n"−1 are linearly independent. If it can be shown that the Wronskian is zero everywhere on an interval then, in the case of analytic functions, this implies the given functions are linearly dependent. See the Wronskian and linear independence.
Orientation of a basis.
The determinant can be thought of as assigning a number to every sequence of "n" vectors in R"n", by using the square matrix whose columns are the given vectors. For instance, an orthogonal matrix with entries in R"n" represents an orthonormal basis in Euclidean space. The determinant of such a matrix determines whether the orientation of the basis is consistent with or opposite to the orientation of the standard basis. If the determinant is +1, the basis has the same orientation. If it is −1, the basis has the opposite orientation.
More generally, if the determinant of "A" is positive, "A" represents an orientation-preserving linear transformation (if "A" is an orthogonal 2 × 2 or 3 × 3 matrix, this is a rotation), while if it is negative, "A" switches the orientation of the basis.
Volume and Jacobian determinant.
As pointed out above, the absolute value of the determinant of real vectors is equal to the volume of the parallelepiped spanned by those vectors. As a consequence, if "f": R"n" → R"n" is the linear map represented by the matrix "A", and "S" is any measurable subset of R"n", then the volume of "f"("S") is given by |det("A")| times the volume of "S". More generally, if the linear map "f": R"n" → R"m" is represented by the "m" × "n" matrix "A", then the "n"-dimensional volume of "f"("S") is given by:
By calculating the volume of the tetrahedron bounded by four points, they can be used to identify skew lines. The volume of any tetrahedron, given its vertices a, b, c, and d, is (1/6)·|det(a − b, b − c, c − d)|, or any other combination of pairs of vertices that would form a spanning tree over the vertices.
For a general differentiable function, much of the above carries over by considering the Jacobian matrix of "f". For
the Jacobian is the "n" × "n" matrix whose entries are given by
Its determinant, the Jacobian determinant appears in the higher-dimensional version of integration by substitution: for suitable functions "f" and an open subset "U" of R'"n" (the domain of "f"), the integral over "f"("U") of some other function φ: R"n" → R"m" is given by
The Jacobian also occurs in the inverse function theorem.
Vandermonde determinant (alternant).
Third order
In general, the "n"th-order Vandermonde determinant is 
where the right-hand side is the continued product of all the differences that can be formed from the "n"("n"−1)/2 pairs of numbers taken from "x"1, "x"2, ..., "x""n", with the order of the differences taken in the reversed order of the suffixes that are involved.
Circulants.
Second order
Third order
where ω and ω2 are the complex cube roots of 1. In general, the "n"th-order circulant determinant is
where ω"j" is an "n"th root of 1.

</doc>
<doc id="8470" url="http://en.wikipedia.org/wiki?curid=8470" title="David Ricardo">
David Ricardo

David Ricardo (18 April 1772 – 11 September 1823) was a British political economist. He was one of the most influential of the classical economists, along with Thomas Malthus, Adam Smith, and James Mill. Perhaps his most important legacy is his theory of comparative advantage, which suggests that a nation should concentrate its resources solely in industries where it is "most" internationally competitive and trade with other countries to obtain products no longer produced nationally. In essence, Ricardo promoted the idea of extreme industry specialization by nations, to the point of dismantling internationally competitive and otherwise profitable industries. Ricardo took as a given the existence of a national industry policy aimed at promoting some industries to the detriment of others. For Ricardo some form of Central Economic Planning was a necessity. Ricardo's theory of comparative advantage has been challenged by, among others, Joan Robinson and Piero Sraffa, but remains the cornerstone of the argument in favour of international free trade. Comparative Advantage was the theoretical forerunner of the push towards globalization via increased international trade which is the guiding theme in the economic policy programme currently promoted by the OECD and the World Trade Organization, where it is assumed that increased international trade will lead to economic prosperity. The results of the implementation of this type of policy agenda are increasingly controversial. Although his influence on economics has been considerable Ricardo actually began his professional life as a broker and financial market speculator. He amassed a considerable personal fortune, largely from financial market manipulation. Once retired he bought a seat in the U.K. Parliament. He held his parliamentary seat for the last four years of his life. Ricardo died at the age of 51.
Personal life.
Born in London, England, Ricardo was the third of 17 children of a Sephardic Jewish family of Portuguese origin who had recently relocated from the Dutch Republic. His father, Abraham Ricardo, was a successful stockbroker. He began working with his father at the age of 14. At age 21, Ricardo eloped with a Quaker, Priscilla Anne Wilkinson, and, against his father's wishes, he became a Christian. This religious difference resulted in estrangement from his family, and he was led to adopt a position of independence. His father disowned him and his mother apparently never spoke to him again.
Following his estrangement from his father he started a successful business as a broker with the support of Lubbocks and Forster, an eminent banking house. He made the bulk of his fortune as a result of speculation on the outcome of the Battle of Waterloo, using methods which today would result in prosecution for . Prior to the battle, Ricardo to convey early results of the outcome, he then deliberately created the mistaken impression the French had won by openly selling British securities. A market panic ensued. Following this panic he moved to buy British securities at a steep discount. The Sunday Times reported in Ricardo’s obituary, published on 14 September 1823, that during the Battle of Waterloo Ricardo "netted upwards of a million sterling", a huge sum at the time. Following this trading coup, he retired. He purchased Gatcombe Park, an estate in Gloucestershire, now owned by Princess Anne, the Princess Royal. He was appointed High Sheriff of Gloucestershire for 1818–19.
Some years into retirement Ricardo became keen to enter Parliament and in August 1818 he secured Lord Portarlington’s borough for £4,000, as part of the terms of a loan of £25,000. As a result Ricardo entered the House of Commons, representing Portarlington, an Irish rotten borough. He was 47 years of age. He held the seat until his death four years later.
Ricardo was a close friend of James Mill. Other notable friends included Jeremy Bentham and Thomas Malthus, with whom Ricardo had a considerable debate (in correspondence) over such things as the role of landowners in a society. He also was a member of Malthus' Political Economy Club, and a member of the King of Clubs. He was one of the original members of The Geological Society. His sister was author Sarah Ricardo-Porter (e.g., "Conversations in Arithmetic").
Death and legacy.
Ten years after retiring and four years after entering Parliament Ricardo died from an infection of the middle ear that spread into the brain and induced septicaemia. He was 51.
He had eight children, including three sons, of whom Osman Ricardo (1795–1881; MP for Worcester 1847–1865) and another David Ricardo (1803–1864, MP for Stroud 1832–1833), became Members of Parliament, while the third, Mortimer Ricardo, served as an officer in the Life Guards and was a deputy lieutenant for Oxfordshire.
Ricardo is buried in an ornate grave in the churchyard of Saint Nicholas in Hardenhuish, now a suburb of Chippenham, Wiltshire. The inscription on his grave reads: "A Jew, born in Holland, he was one of the first free traders and a famous Radical in his day." At the time of his death his fortune was estimated at about £600,000.
Ideas.
Ricardo became interested in economics after reading Adam Smith's "The Wealth of Nations" in 1799. He wrote his first economics article at age 37. Ricardo's idea became accepted in England and have become orthodox economic ideas in the modern western world where the government is seen as having a determining role in economic development.
He was also an abolitionist, speaking at a meeting of the Court of the East India Company in March 1823, where he said he regarded slavery as stain on the character of the nation. His sister, Hanna, had married David Samuda who owned a substantial number of slaves in Jamaica.
Comparative advantage.
Between 1500 and 1750 most economists advocated Mercantilism which promoted the idea of international trade for the purpose of gaining bullion by running a trade surplus with other countries. Ricardo challenged the idea that the purpose of trade was merely to accumulate gold or silver. With "comparative advantage" Ricardo argued in favour of industry specialisation and free trade. He attempted to prove, using simple mathematics, that industry specialization combined with free international trade always produces positive results. This theory expanded on the concept of absolute advantage.
Ricardo argued that there is mutual national benefit from trade even if one country is more competitive in every area than its trading counterpart and that a nation should concentrate resources only on industries where it had a comparative advantage, that is in those industries in which it has the greatest competitive edge. Ricardo suggested that national industries which were, in fact, profitable and internationally competitive should be jettisoned in favour of the most competitive industries. Ricardo's theory of comparative advantage assumes the existence of an industry and trade policy at a national level. It does not presume that business decisions are or should be made independently by entrepreneurs on the basis of viability or profit.
Ricardo attempted to prove, using a simple numerical example, that international trade is always beneficial. Paul Samuelson called the numbers used in Ricardo's numerical example dealing with trade between England and Portugal the "four magic numbers". "In spite of the fact that the Portuguese could produce both cloth and wine with less amount of labor, Ricardo suggested that "theoretically" both countries benefit from trade with each other."
As Joan Robinson subsequently pointed out in reality following an opening of free trade with England, Portugal endured centuries of economic underdevelopment: "the imposition of free trade on Portugal killed off a promising textile industry and left her with a slow-growing export market for wine, while for England, exports of cotton cloth led to accumulation, mechanisation and the whole spiralling growth of the industrial revolution". Robinson argued that Ricardo's example required that economies were in static equilibrium positions with full employment and that there could not be a trade deficit or a trade surplus. These conditions, she wrote, were not relevant to the real world. She also argued that Ricardo's theory did not take into account that some countries may be at different levels of development and that this raised the prospect of 'unequal exchange' which might hamper a country's development, as we saw in the case of Portugal.
Protectionism.
Like Adam Smith, Ricardo was an opponent of protectionism for national economies, especially for agriculture. He believed that the British "Corn Laws"—tariffs on agricultural products—ensured that less-productive domestic land would be harvested and rents would be driven up . Thus, profits would be directed toward landlords and away from the emerging industrial capitalists. Since Ricardo believed landlords tended to squander their wealth on luxuries, rather than invest, he believed that the Corn Laws were leading to the stagnation of the British economy. In 1846, his nephew John Lewis Ricardo, MP for Stoke-on-Trent, advocated free trade and the repeal of the Corn Laws.
Modern empirical analysis of the Corn Laws yield mixed results. Parliament repealed the Corn Laws in 1846.
Criticism of the Ricardian theory of trade.
Ricardo's argument in favour of free trade has been attacked by those who believe trade restriction can be necessary. Utsa Patnaik claims that Ricardian theory of international trade contains a logical fallacy. Ricardo assumed that in both countries two goods are producible and actually are produced, but developed and underdeveloped countries often trade those goods which are not producible in their own country. For example, many Northern countries do not produce tropical fruits. In these cases, one cannot define which country has comparative advantage.
Critics also argue that Ricardo's theory of comparative advantage is flawed in that it assumes production is continuous and absolute. In the real world, events outside the realm of human control (e.g. natural disasters) can disrupt production. In this case, specialisation could cripple a country that depends on imports from foreign, naturally disrupted countries. For example, if an industrially based country trades its manufactured goods with an agrarian country in exchange for agricultural products, a natural disaster in the agricultural country (e.g. drought) may cause an industrially based country to starve.
The development economist Ha-Joon Chang challenges the argument that free trade benefits every country:
Ricardo’s theory is absolutely right—within its narrow confines. His theory correctly says that, "accepting their current levels of technology as given", it is better for countries to specialize in things that they are relatively better at. One cannot argue with that. His theory fails when a country wants to acquire more advanced technologies—that is, when it wants to develop its economy. It takes time and experience to absorb new technologies, so technologically backward producers need a period of protection from international competition during this period of learning. Such protection is costly, because the country is giving up the chance to import better and cheaper products. However, it is a price that has to be paid if it wants to develop advanced industries. Ricardo’s theory is, thus seen, for those who accept the "status quo" but not for those who want to change it.
Value theory.
Ricardo's most famous work is his "Principles of Political Economy and Taxation" (1817). Ricardo opens the first chapter with a statement of the labor theory of value. His labour theory of value required several assumptions:
Ricardo himself realized that the second and third assumptions were quite unrealistic and hence admitted two exceptions to his labour theory of value:
Ricardo continued to work on his value theory to the end of his life.
Rent.
Ricardo is responsible for developing theories of rent, wages, and profits. He defined rent as "the difference between the produce obtained by the employment of two equal quantities of capital and labor." Ricardo believed that the process of economic development, which increased land utilization and eventually led to the cultivation of poorer land, principally benefited landowners. According to Ricardo, such premium over "real social value" that is reaped due to ownership constitutes value to an individual but is at best a paper monetary return to "society". The portion of such purely individual benefit, and exclusively that portion, that accrues to scarce resources such as land or gold, over and above any socially beneficial exchange, Ricardo labels "rent".
Ricardo concluded that a tax on land value, equivalent to a tax on the land rent, minus the improvements, was the only form of taxation that would not lead to price increases. Land itself has no cost of production, because it is not produced by humans. Thus, the price is not determined by the cost, but only by the best available rent-free alternative, not by the tax burdens of the person claiming exclusive use.
Malthus's criticism and Extrapolation of the problem of Ricardian Rent.
In attempting to demonstrate that Ricardian Rent constitutes value for nothing Ricardo was neglecting Say's Law that all savings by-definition-equals investment. Malthus suggested that rent, however misplaced, constitutes a prime source of savings and investment for the future.
Ricardian equivalence.
Another idea associated with Ricardo is Ricardian equivalence, an argument suggesting that in some circumstances a government's choice of how to pay for its spending ("i.e.," whether to use tax revenue or issue debt and run a deficit) might have no effect on the economy. Ricardo notes that the proposition is theoretically implied in the presence of intertemporal optimisation by rational tax-payers: but that since tax-payers do not act so rationally, the proposition fails to be true in practice. Thus, while the proposition bears his name, he does not seem to have believed it. Economist Robert Barro is responsible for its modern prominence.
Ricardo's theories of wages and profits.
Several authorities consider that Ricardo is the source of the concepts behind the so-called Iron Law of Wages, according to which wages naturally tend to a subsistence level. Others dispute the assignment to Ricardo of this idea.
In his "Theory of Profit", Ricardo stated that as real wages increase, real profits decrease because the revenue from the sale of manufactured goods is split between profits and wages. He said in his "Essay on Profits", "Profits depend on high or low wages, wages on the price of necessaries, and the price of necessaries chiefly on the price of food."
His influence and intellectual legacy.
David Ricardo's ideas had a tremendous influence on later developments in economics. US economists rank Ricardo as the second most influential economic thinker, behind Adam Smith, prior to the twentieth century.
Ricardo became the theoretical father of classical political economy. However, Schumpeter coined an expression "Ricardian vice", which indicates that rigorous logic does not provide a good economic theory. This criticism applies also to most neoclassical theories, which make heavy use of mathematics, but are, according to him, theoretically unsound, because the conclusion being drawn does not logically follow from the theories used to defend it.
Ricardian socialists.
Ricardo's writings fascinated a number of early socialists in the 1820s, who thought his value theory had radical implications. They argued that, in view of labor theory of value, labor produces the entire product, and the profits capitalists get are a result of exploitations of workers. These include Thomas Hodgskin, William Thompson, John Francis Bray, and Percy Ravenstone.
Georgists.
Georgists believe that rent, in the sense that Ricardo used, belongs to the community as a whole. Henry George was greatly influenced by Ricardo, and often cited him, including in his most famous work, Progress and Poverty from 1879. In the preface to the fourth edition, he wrote: "What I have done in this book, if I have correctly solved the great problem I have sought to investigate, is, to unite the truth perceived by the school of Smith and Ricardo to the truth perceived by the school of Proudhon and Lasalle; to show that laissez faire (in its full true meaning) opens the way to a realization of the noble dreams of socialism; to identify social law with moral law, and to disprove ideas which in the minds of many cloud grand and elevating perceptions."
Neo-Ricardians.
After the rise of the 'neoclassical' school, Ricardo's influence declined temporarily. It was Piero Sraffa, the editor of the Collected Works of David Ricardo and the author of seminal "Production of Commodities by Means of Commodities", who resurrected Ricardo as the originator of another strand of economics thought, which was effaced with the arrival of the neoclassical school. The new interpretation of Ricardo and Sraffa's criticism against the marginal theory of value gave rise to a new school, now named neo-Ricardian or Sraffian school. Major contributors to this school includes Luigi Pasinetti (1930–), Pierangelo Garegnani (1930–2011), Ian Steedman (1941–), Geoffrey Harcourt (1931–), Heinz Kurz (1946–), Neri Salvadori (1951–), Pier Paolo Saviotti (–) among others. See also Neo-Ricardianism. The Neo-Ricardian school is sometimes seen to be a component of Post-Keynesian economics.
Neo-Ricardian trade theory.
Inspired by Piero Sraffa, a new strand of trade theory emerged and was named neo-Ricardian trade theory. The main contributors include Ian Steedman and Stanley Metcalfe. They have criticised neoclassical international trade theory, namely the Heckscher–Ohlin model on the basis that the notion of capital as primary factor has no method of measuring it before the determination of profit rate (thus trapped in a logical vicious circle). This was a second round of the Cambridge capital controversy, this time in the field of international trade.
Evolutionary growth theory.
Several distinctive groups have sprung out of the neo-Ricardian school. One is the evolutionary growth theory, developed notably by Luigi Pasinetti, J.S. Metcalfe, Pier Paolo Saviotti, and Koen Frenken and others.
Pasinetti argued that the demand for any commodity came to stagnate and frequently decline, demand saturation occurs. Introduction of new commodities (goods and services) is necessary to avoid economic stagnation.
Contemporary theories.
Ricardo's idea was even expanded to the case of continuum of goods by Dornbusch, Fischer, and Samuelson This formulation is employed for example by Matsuyama and others.
Ricardian trade theory ordinarily assumes that the labour is the unique input. This is a deficiency as intermediate goods are a great part of international trade. The situation changed greatly after the appearance of Yoshinori Shiozawa's seminal work of 2007.
Yeats found that 30% of world trade in manufacturing is intermediate inputs. Bardhan and Jafee found that intermediate inputs occupy 37 to 38% in the imports to the US for the years from 1992 to 1997, whereas the percentage of intrafirm trade grew from 43% in 1992 to 52% in 1997.
Unequal Exchange.
Chris Edward includes Emmanuel's Unequal Exchange theory among variations of neo-Ricardian trade theory. Arghiri Emmanuel argued that the Third World is poor because of the international exploitation of labour.
The unequal exchange theory of trade has been influential to the (new) dependency theory.
Publications.
Ricardo's publications included:
His works and writings were collected in:

</doc>
<doc id="8471" url="http://en.wikipedia.org/wiki?curid=8471" title="Delphinus">
Delphinus

Delphinus is a constellation in the northern sky, close to the celestial equator. Its name is Latin for dolphin. Delphinus was one of the 48 constellations listed by the 2nd century astronomer Ptolemy, and it remains among the 88 modern constellations recognized by the International Astronomical Union. It is one of the smaller constellations, ranked 69th in size.
Delphinus' brightest stars form a distinctive asterism that can easily be recognized. It is bordered (clockwise from north) by Vulpecula the fox, Sagitta the arrow, Aquila the eagle, Aquarius the water-carrier, Equuleus the foal and Pegasus the flying horse.
Notable features.
Stars.
Delphinus does not have any bright stars; its brightest star is of magnitude 3.8. The main asterism in Delphinus is Job's Coffin, formed from the four brightest stars: Alpha, Beta, Gamma, and Delta Delphini. Alpha and Beta Delphini are named Sualocin and Rotanev, respectively. When read backwards, they read as Nicolaus Venator, the Latinized name of Palermo Observatory's former director, Niccolò Cacciatore. However, Delphinus is in a rich Milky Way star field.
Alpha Delphini, called Sualocin, is a blue-white hued main sequence star of magnitude 3.8, 241 light-years from Earth. Beta Delphini, called Rotanev, is a close binary star and the brightest in Delphinus, divisible in only large amateur telescopes. To the unaided eye, it appears to be a white star of magnitude 3.6. It has a period of 27 years and is 97 light-years from Earth. Gamma Delphini is a celebrated binary star among amateur astronomers. The primary is a gold-colored star of magnitude 4.3 and the secondary is a yellow-tinged star of magnitude 5.1. 102 light-years away, the components of Gamma Delphini are divisible in a small amateur telescope. The secondary, also described as green, is 10 arcseconds from the primary. Struve 2725, called the "Ghost Double", is a pair that appears similar to a dimmer Gamma Delphini. Its components of magnitudes 7.6 and 8.4 are separated by 6 arcseconds and are 15 arcminutes from Gamma Delphini itself.
There are several dimmer stars in Delphinus. Delta Delphini is a type A7 IIIp star of magnitude 4.43. Epsilon Delphini, called Deneb Dulfim, meaning "tail of the Dolphin", is a star of spectral class B6 III and magnitude 4.
Delphinus is also home to several variable stars. R Delphini is a Mira-type variable star with a period of 285.5 days. Its magnitude ranges between a maximum of 7.6 and a minimum of 13.8.
Rho Aquilae moved across the border into Delphinus in 1992.
HR Delphini was a nova that brightened to magnitude 3.5 in December 1967. On 14 August 2013, a possible nova was discovered by amateur astronomer Koichi Itagaki, initially labelled PNV J20233073+2046041, now labelled Nova Delphini 2013.
Deep-sky objects.
Because it is in a rich Milky Way star field, Delphinus has several deep-sky objects. NGC 6891 is a planetary nebula of magnitude 10.5. NGC 6934 is a globular cluster of magnitude 9.75. At a distance of about 185,000 light-years, the globular cluster NGC 7006 is extremely remote. It is also fairly dim at magnitude 11.5.
Mythology.
Delphinus is associated with two stories from Greek mythology.
According to the first Greek god Poseidon wanted to marry Amphitrite, a beautiful nereid. She, however, wanting to protect her virginity, fled to the Atlas mountains. Her suitor then sent out several searchers, among them a certain Delphinus. Delphinus accidentally stumbled upon her and was able to persuade Amphitrite to accept Poseidon's wooing. Out of gratitude the god placed the image of a dolphin among the stars.
The second story tells of the Greek poet Arion of Lesbos (7th century BC), who was saved by a dolphin. He was a court musician at the palace of Periander, ruler of Corinth. Arion had amassed a fortune during his travels to Sicily and Italy. On his way home from Tarentum his wealth caused the crew of his ship to conspire against him. Threatened with death, Arion asked to be granted a last wish which the crew granted: he wanted to sing a dirge. This he did, and while doing so, flung himself into the sea. There, he was rescued by a dolphin which had been charmed by Arion's music. The dolphin carried Arion to the coast of Greece and left.
Equivalents.
In Chinese astronomy, the stars of Delphinus are located within "the Black Tortoise of the North" (北方玄武, "Běi Fāng Xuán Wǔ").
In Polynesia, two cultures recognized Delphinus as a constellation. On Pukapuka, it was called "Te Toloa" and in the Tuamotus, it was called "Te Uru-o-tiki".
Namesakes.
USS Delphinus (AF-24) and USS Delphinus (PHM-1), two United States Navy ships, are named after the constellation.
See also.
Delphinus (Chinese astronomy)
External links.
Coordinates: 

</doc>
<doc id="8472" url="http://en.wikipedia.org/wiki?curid=8472" title="Disk storage">
Disk storage

Disk storage is a general category of storage mechanisms where data are recorded by various electronic, magnetic, optical, or mechanical changes to a surface layer of one or more rotating disks. A disk drive is a device implementing such a storage mechanism and is usually distinguished from the disk medium. Notable types are the hard disk drive (HDD) containing a non-removable disk, the floppy disk drive (FDD) and its removable floppy disk, and various optical disc drives and associated optical disc media.
Disk and disc are used interchangeably except where trademarks preclude one usage, e.g. the Compact Disc logo. The choice of a particular form is frequently historical, as in IBM's usage of the "disk" form beginning in 1956 with the "IBM 350 disk storage unit".
Background.
Audio information was originally recorded by analog methods (see Sound recording and reproduction). Similarly the first video disc used an analog recording method. In the music industry, analog recording has been mostly replaced by digital optical technology where the data are recorded in a digital format with optical information.
The first commercial digital disk storage device was the IBM 350 which shipped in 1956 as a part of the IBM 305 RAMAC computing system. The random-access, low-density storage of disks was developed to complement the already used sequential-access, high-density storage provided by tape drives using magnetic tape. Vigorous innovation in disk storage technology, coupled with less vigorous innovation in tape storage, has reduced the difference in acquisition cost per terabyte between disk storage and tape storage; however, the total cost of ownership of data on disk including power and management remains larger than that of tape.
Disk storage is now used in both computer storage and consumer electronic storage, e.g., audio CDs and video discs (standard DVD and Blu-ray).
Access methods.
Digital disk drives are block storage devices. Each disk is divided into logical blocks (collection of sectors). Blocks are addressed using their logical block addresses (LBA). Read from or writing to disk happens at the granularity of blocks.
Originally the disk capacity was quite low and has been improved in one of several ways. Improvements in mechanical design and manufacture allowed smaller and more precise heads, meaning that more tracks could be stored on each of the disks. Advancements in data compression methods permitted more information to be stored in each of the individual sectors.
The drive stores data onto cylinders, heads, and sectors. The sectors unit is the smallest size of data to be stored in a hard disk drive and each file will have many sectors units assigned to it. The smallest entity in a CD is called a frame, which consists of 33 bytes and contains six complete 16-bit stereo samples (two bytes × two channels × six samples = 24 bytes). The other nine bytes consist of eight CIRC error-correction bytes and one subcode byte used for control and display.
The information is sent from the computer processor to the BIOS into a chip controlling the data transfer. This is then sent out to the hard drive via a multi-wire connector. Once the data are received onto the circuit board of the drive, they are translated and compressed into a format that the individual drive can use to store onto the disk itself. The data are then passed to a chip on the circuit board that controls the access to the drive. The drive is divided into sectors of data stored onto one of the sides of one of the internal disks. An HDD with two disks internally will typically store data on all four surfaces.
The hardware on the drive tells the actuator arm where it is to go for the relevant track and the compressed information is then sent down to the head which changes the physical properties, optically or magnetically for example, of each byte on the drive, thus storing the information. A file is not stored in a linear manner, rather, it is held in the best way for quickest retrieval.
Rotation speed and track layout.
Mechanically there are two different motions occurring inside the drive. One is the rotation of the disks inside the device. The other is the side-to-side motion of the head across the disk as it moves between tracks.
There are two types of disk rotation methods:
Track positioning also follows two different methods across disk storage devices. Storage devices focused on holding computer data, e.g., HDDs, FDDs, Iomega zip drives, use concentric tracks to store data. During a sequential read or write operation, after the drive accesses all the sectors in a track it repositions the head(s) to the next track. This will cause a momentary delay in the flow of data between the device and the computer. In contrast, optical audio and video discs use a single spiral track that starts at the inner most point on the disc and flows continuously to the outer edge. When reading or writing data there is no need to stop the flow of data to switch tracks. This is similar to vinyl records except vinyl records started at the outer edge and spiraled in toward the center.
Interfaces.
The disk drive interface is the mechanism/protocol of communication between the rest of the system and the disk drive itself. Storage devices intended for desktop and mobile computers typically use ATA (PATA) and SATA interfaces. Enterprise systems and high-end storage devices will typically use SCSI, SAS, and FC interfaces in addition to some use of SATA.

</doc>
<doc id="8474" url="http://en.wikipedia.org/wiki?curid=8474" title="Arthur Wellesley, 1st Duke of Wellington">
Arthur Wellesley, 1st Duke of Wellington

Field Marshal Arthur Wellesley, 1st Duke of Wellington, KG GCB GCH PC FRS (1 May 1769 – 14 September 1852), was an Anglo-Irish soldier and statesman, a native of Ireland belonging to the Protestant Ascendancy, and one of the leading military and political figures of 19th-century Britain. His defeat of Napoleon at Waterloo in 1815 put him in the top rank of Britain's military heroes. In 2002 he was number 15 in the BBC's poll of the 100 Greatest Britons.
Wellesley was commissioned as an ensign in the British Army in 1787. Serving in Ireland as aide-de-camp to two successive Lords Lieutenant of Ireland he was also elected as a Member of Parliament in the Irish House of Commons. A colonel by 1796, Wellesley saw action in the Netherlands and in India, where he fought in the Fourth Anglo-Mysore War at the Battle of Seringapatam. He was appointed governor of Seringapatam and Mysore in 1799 and as a newly appointed major-general won a decisive victory over the Maratha Confederacy at the Battle of Assaye in 1803.
Wellesley rose to prominence as a general during the Peninsular campaign of the Napoleonic Wars, and was promoted to the rank of field marshal after leading the allied forces to victory against the French at the Battle of Vitoria in 1813. Following Napoleon's exile in 1814, he served as the ambassador to France and was granted a dukedom. During the Hundred Days in 1815, he commanded the allied army which, together with a Prussian army under Blücher, defeated Napoleon at the Battle of Waterloo. Wellesley's battle record is exemplary; he ultimately participated in some 60 battles during the course of his military career.
Wellesley is famous for his adaptive defensive style of warfare, resulting in several victories against a numerically superior force while minimising his own losses. He is regarded as one of the greatest defensive commanders of all time, and many of his tactics and battle plans are still studied in military academies around the world.
After ending his active military career, Wellesley returned to politics. He was twice British prime minister as part of the Tory party: from 1828 to 1830 and for a little less than a month in 1834. He oversaw the passage of the Catholic Relief Act 1829, but opposed the Reform Act 1832. He continued as one of the leading figures in the House of Lords until his retirement and remained Commander-in-Chief of the British Army until his death.
Early life and education.
Wellesley was born into a wealthy Anglo-Irish aristocratic family in the Kingdom of Ireland as Hon. Arthur Wesley, the third of five surviving sons (fourth otherwise) to The 1st Earl of Mornington and his wife Anne, the eldest daughter of The 1st Viscount Dungannon. He was most likely born at their townhouse, 24 Upper Merrion Street, Dublin, now The Merrion Hotel. His biographers mostly follow the contemporary newspaper evidence in saying he was born 1 May 1769, the day he was baptised. His mother, Anne, Countess of Mornington, recalled in 1815 that he had been born at 6 Merrion Street, Dublin. Other places which have been put forward as the location of his birth include Mornington House (the house which used to be next door) - as his father had asserted, the Dublin packet boat and the mansion in the family estate of Athy (consumed in the fires of 1916) - as the Duke apparently put on his 1851 census return.
He spent most of his childhood at his family's two homes, the first a large house in Dublin and the second, Dangan Castle, 3 mi north of Summerhill on the Trim Road in County Meath. In 1781, Arthur's father died and his eldest brother Richard inherited his father's earldom.
He went to the diocesan school in Trim when at Dangan, Mr. Whyte's Academy when in Dublin, and Brown's School in Chelsea when in London. He then enrolled at Eton, where he studied from 1781 to 1784. His loneliness there caused him to hate it, and makes it highly unlikely that he actually said, "The Battle of Waterloo was won on the playing fields of Eton". Moreover, Eton had no playing fields at the time. In 1785, a lack of success at Eton, combined with a shortage of family funds due to his father's death, forced the young Wellesley and his mother to move to Brussels. Until his early twenties, Arthur continued to show little sign of distinction and his mother grew increasingly concerned at his idleness, stating, "I don't know what I shall do with my awkward son Arthur".
A year later, Arthur enrolled in the French Royal Academy of Equitation in Angers, where he progressed significantly, becoming a good horseman and learning French, which was later to prove very useful. Upon returning to England in late 1786, he astonished his mother with his improvement.
Military career.
Early career.
Despite his new promise he had yet to find a job and his family was still short of money, so upon the advice of his mother, his brother Richard asked his friend The 4th Duke of Rutland (then Lord Lieutenant of Ireland) to consider Arthur for a commission in the army. Soon after, on 7 March 1787 he was gazetted ensign in the 73rd Regiment of Foot. In October, with the assistance of his brother, he was assigned as aide-de-camp, on ten shillings a day (twice his pay as an ensign), to the new Lord Lieutenant of Ireland Lord Buckingham. He was also transferred to the new 76th Regiment forming in Ireland and on Christmas Day, 1787, was promoted to lieutenant. During his time in Dublin his duties were mainly social; attending balls, entertaining guests and providing advice to Buckingham. While in Ireland, he overextended himself in borrowing due to his occasional gambling, but in his defence stated that "I have often known what it was to be in want of money, but I have never got helplessly into debt".
On 23 January 1788, he transferred into the 41st Regiment of Foot, then again on 25 June 1789, still a lieutenant, he transferred to the 12th (Prince of Wales's) Regiment of (Light) Dragoons and, according to military historian Richard Holmes, he also dipped a reluctant toe into politics. Shortly before the general election of 1789, he went to the "rotten borough" of Trim to speak against the granting of the title "Freeman" of Dublin to the parliamentary leader of the Irish Patriot Party, Henry Grattan. Succeeding, he was later nominated and duly elected as a Member of Parliament for Trim in the Irish House of Commons. Because of the limited suffrage at the time, he sat in a parliament where at least two-thirds of the members owed their election to the landowners of fewer than a hundred boroughs. Wellesley continued to serve at Dublin Castle, voting with the government in the Irish parliament over the next two years. On 30 January 1791 he became a captain and was transferred to the 58th Regiment of Foot.
On 31 October, he transferred to the 18th Light Dragoons and it was during this period that he grew increasingly attracted to Kitty Pakenham, the daughter of Edward Pakenham, 2nd Baron Longford. She was described as being full of 'gaiety and charm'. In 1793, he sought her hand, but was turned down by her brother Thomas, Earl of Longford, who considered Wellesley to be a young man, in debt, with very poor prospects. An aspiring amateur musician, Wellesley, devastated by the rejection, burnt his violins in anger, and resolved to pursue a military career in earnest. Gaining further promotion (largely by purchasing his rank, which was common in the British Army at the time), he became a major in the 33rd Regiment in 1793. A few months later, in September, his brother lent him more money and with it he purchased a lieutenant-colonelcy in the 33rd.
Netherlands.
In 1793, the Duke of York was sent to Flanders in command of the British contingent of an allied force destined for the invasion of France. In 1794, the 33rd regiment was sent to join the force and Wellesley, having just purchased his majority on 30 April 1793, set sail from Cork for Flanders in June, destined for his first real battle experience. Three months later on 30 September 1793 he purchased the lieutenant colonelcy of his regiment. During the campaign he rose to command a brigade and in September Wellesley's unit came under fire just east of Breda, just before the Battle of Boxtel. For the latter part of the campaign, during the winter, his unit defended the line of the Waal River, during which time he became ill for a while, owing to the damp environment. Though the campaign was to prove unsuccessful, with the Duke of York's force returning in 1795, Wellesley was to learn several valuable lessons, including the use of steady fire lines against advancing columns and of the merits of supporting sea-power. He concluded that many of the campaign's blunders were due to the faults of the leaders and the poor organisation at headquarters. He remarked later of his time in the Netherlands that "At least I learned what not to do, and that is always a valuable lesson".
Returning to England in March 1795, he was returned as a Member of Parliament for Trim for a second time. He hoped to be given the position of secretary of war in the new Irish government but the new lord-lieutenant, Lord Camden, was only able to offer him the post of Surveyor-General of the Ordnance. Declining the post, he returned to his regiment, now at Southampton preparing to set sail for the West Indies. After seven weeks at sea, a storm forced the fleet back to Poole, England. The 33rd was given time to convalesce and a few months later, Whitehall decided to send the regiment to India. Wellesley was promoted full colonel by seniority on 3 May 1796 and a few weeks later set sail for Calcutta with his regiment.
India.
Arriving in Calcutta in February 1797 he spent several months there, before being sent on a brief expedition to the Philippines, where he established a list of new hygiene precautions for his men to deal with the unfamiliar climate. Returning in November to India, he learnt that his elder brother Richard, now known as Lord Mornington, had been appointed as the new Governor-General of India.
In 1798, he changed the spelling of his surname to "Wellesley"; up to this time he was still known as Wesley, which his eldest brother considered the ancient and proper spelling.
Fourth Anglo-Mysore War.
As part of the campaign to extend the rule of the British East India Company, the Fourth Anglo-Mysore War broke out in 1798 against the Sultan of Mysore, Tipu Sultan. Arthur's brother Richard ordered that an armed force be sent to capture Seringapatam and defeat Tipu. Under the command of General Harris, some 24,000 troops were dispatched to Madras (to join an equal force being sent from Bombay in the west). Arthur and the 33rd sailed to join them in August.
After extensive and careful logistic preparation (which would become one of Wellesley's main attributes) the 33rd left with the main force in December and travelled across 250 mi of jungle from Madras to Mysore. On account of his brother, during the journey, Wellesley was given an additional command, that of chief advisor to the Nizam of Hyderabad's army (sent to accompany the British force). This position was to cause friction among many of the senior officers (some of whom were senior to Wellesley). Much of this friction was put to rest after the Battle of Mallavelly, some 20 mi from Seringapatam, in which Harris's army attacked a large part of the sultan's army. During the battle, Wellesley led his men, in a line of battle of two ranks, against the enemy to a gentle ridge and gave the order to fire. After an extensive repetition of volleys, followed by a bayonet charge, the 33rd, in conjunction with the rest of Harris's force, forced Tipu's infantry to retreat.
Seringapatam.
Immediately after their arrival at Seringapatam on 5 April 1799, the Battle of Seringapatam began and Wellesley was ordered to lead a night attack on the village of Sultanpettah, adjacent to the fortress to clear the way for the artillery. Because of the enemy's strong defensive preparations, and the darkness, with the resulting confusion, the attack failed with 25 casualties. Wellesley suffered a minor injury to his knee from a spent musket-ball. Although they would re-attack successfully the next day, after time to scout ahead the enemy's positions, the affair had an impact on Wellesley. He resolved "never to attack an enemy who is preparing and strongly posted, and whose posts have not been reconnoitered by daylight".
Lewin Bentham Bowring gives this alternative account:
One of these groves, called the Sultanpet Tope, was intersected by deep ditches, watered from a channel running in an easterly direction about a mile from the fort. General Baird was directed to scour this grove and dislodge the enemy, but on his advancing with this object on the night of the 5th, he found the tope unoccupied. The next day, however, the Mysore troops again took possession of the ground, and as it was absolutely necessary to expel them, two columns were detached at sunset for the purpose. The first of these, under Colonel Shawe, got possession of a ruined village, which it successfully held. The second column, under Colonel Wellesley, on advancing into the tope, was at once attacked in the darkness of night by a tremendous fire of musketry and rockets. The men, floundering about amidst the trees and the water-courses, at last broke, and fell back in disorder, some being killed and a few taken prisoners. In the confusion Colonel Wellesley was himself struck on the knee by a spent ball, and narrowly escaped falling into the hands of the enemy.
A few weeks later, after extensive artillery bombardment, a breach was opened in the main walls of the fortress of Seringapatam. An attack led by Major-General Baird secured the fortress. Wellesley secured the rear of the advance, posting guards at the breach and then stationed his regiment at the main palace. After hearing news of the death of the Tipu Sultan, Wellesley was the first at the scene to confirm his death, checking his pulse. Over the coming day, Wellesley grew increasingly concerned over the lack of discipline among his men, who drank and pillaged the fortress and city. To restore order, several soldiers were flogged and four hanged.
After battle and the resulting end of the war, the main force under General Harris left Seringapatam and Wellesley, aged 30, stayed behind to command the area as the new Governor of Seringapatam and Mysore. He was promoted to brigadier-general on 17 July 1801. He took residence within the Sultan's summer palace and reformed the tax and justice systems in his province to maintain order and prevent bribery. He also hunted down the mercenary 'King' Dhoondiah Waugh, who had escaped from prison in Seringapatam during the battle. Wellesley, with command of four regiments, defeated Dhoondiah's larger rebel force, along with Dhoondiah himself who was killed in the battle. He paid for the future upkeep of Dhoondiah's orphaned son.
While in India, Wellesley was ill for a considerable time, first with severe diarrhoea from the water and then with fever, followed by a serious skin infection caused by trichophyton. He received good news when in September 1802 he learnt that he had been promoted to the rank of major-general. Wellesley had been gazetted on 29 April 1802, but the news took several months to reach him by sea. He remained at Mysore until November when he was sent to command an army in the Second Anglo-Maratha War.
Second Anglo-Maratha War.
When he determined that a long defensive war would ruin his army, Wellesley decided to act boldly to defeat the numerically larger force of the Maratha Empire. With the logistic assembly of his army complete (24,000 men in total) he gave the order to break camp and attack the nearest Maratha fort on 8 August 1803. The fort surrendered on 12 August after an infantry attack had exploited an artillery-made breach in the wall. With the fort now in British control Wellesley was able to extend control southwards to the river Godavari.
Assaye.
Splitting his army into two forces, to pursue and locate the main Marathas army, (the second force, commanded by Colonel Stevenson was far smaller) Wellesley was preparing to rejoin his forces on 24 September. His intelligence, however, reported the location of the Marathas' main army, between two rivers near Assaye. If he waited for the arrival of his second force, the Marathas would be able to mount a retreat, so Wellesley decided to launch an attack immediately.
On 23 September, Wellesley led his forces over a ford in the river Kaitna and the Battle of Assaye commenced. After crossing the ford the infantry was reorganised into several lines and advanced against the Maratha infantry. Wellesley ordered his cavalry to exploit the flank of the Maratha army just near the village. During the battle Wellesley himself came under fire; two of his horses were shot from under him and he had to mount a third. At a crucial moment, Wellesley regrouped his forces and ordered Colonel Maxwell (later killed in the attack) to attack the eastern end of the Maratha position while Wellesley himself directed a renewed infantry attack against the centre.
An officer in the attack wrote of the importance of Wellesley's personal leadership: "The General was in the thick of the action the whole time ... I never saw a man so cool and collected as he was ... though I can assure you, 'til our troops got the order to advance the fate of the day seemed doubtful ..." With some 6,000 Marathas killed or wounded, the enemy was routed, though Wellesley's force was in no condition to pursue. British casualties were heavy: the British losses were counted as 409 soldiers being killed out of which 164 were Europeans and the remaining 245 were Indian; a further 1,622 British soldiers were wounded and 26 soldiers were reported missing (the British casualty figures were taken from Wellesley's own despatch). Wellesley was troubled by the loss of men and remarked that he hoped "I should not like to see again such loss as I sustained on 23 September, even if attended by such gain". Years later, however, he remarked that Assaye was the best battle he ever fought.
Argaum and Gawilghur.
Despite the damage done to the Maratha army, the battle did not end the war. A few months later in November, Wellesley attacked a larger force near Argaum, leading his army to victory again, with an astonishing 5,000 enemy dead at the cost of only 361 British casualties. A further successful attack at the fortress at Gawilghur, combined with the victory of General Lake at Delhi forced the Maratha to sign a peace settlement at Anjangaon (not concluded until a year later) called as the Treaty of Surji-Anjangaon.
Military historian Richard Holmes remarked that Wellesley's experiences in India had an important influence on his personality and military tactics, teaching him much about military matters that would prove vital to his success in the Peninsular War. These included a strong sense of discipline through drill and order, the use of diplomacy to gain allies, and the vital necessity for a secure supply line. He also established a high regard for the acquisition of intelligence through scouts and spies. His personal tastes also developed, including dressing himself in white trousers, a dark tunic, with Hessian boots and black cocked hat (that later became synonymous as his style).
Leaving India.
Wellesley had grown tired of his time in India, remarking "I have served as long in India as any man ought who can serve anywhere else". In June 1804 he applied for permission to return home and as a reward for his service in India he was made a Knight of the Bath in September. While in India, Wellesley had amassed a fortune of £42,000 (considerable at the time), consisting mainly of prize money from his campaign. When his brother's term as Governor-General of India ended in March 1805, the brothers returned together to England on HMS "Howe". Arthur, coincidentally, stopped on his voyage at the little island of Saint Helena and stayed in the same building to which Napoleon I would later be exiled.
Back in Britain.
Wellesley then served in the abortive Anglo-Russian expedition to north Germany in 1805, taking a brigade to Elbe. Upon this return from the campaign, Wellesley received good news; owing to his new title and status, Kitty Pakenham's family had consented to his marrying her. Wellesley and Kitty were married in Dublin on 10 April 1806. The marriage would later prove to be unsatisfactory and the two would spend years apart while Wellesley was campaigning. Kitty grew depressed, while Wellesley found solace elsewhere. and He then took a period of extended leave from the army and was elected as a Tory member of the British parliament for Rye in January 1806. A year later, he was elected MP for Newport on the Isle of Wight and was then appointed to serve as Chief Secretary for Ireland, under the Duke of Richmond. At the same time, he was made a privy counsellor. While in Ireland, he gave a verbal promise that the remaining Penal Laws would be enforced with great moderation, perhaps an indication of his later willingness to support Catholic Emancipation.
War on Denmark.
Wellesley was in Ireland in May 1807 when he heard of the British expedition to Denmark. He decided to go, stepping down from his political appointments and was appointed to command an infantry brigade in the Second Battle of Copenhagen which took place in August. He fought at the Køge, during which the men under his command took 1,500 prisoners, with Wellesley later present during the surrender.
By 30 September, he had returned to England and was raised to the rank of lieutenant general on 25 April 1808. In June 1808 he accepted the command of an expedition of 9,000 men. Preparing to sail for an attack on the Spanish colonies in South America (to assist the Latin American patriot Francisco de Miranda) his force was instead ordered to sail for Portugal, to take part in the Peninsular Campaign and rendezvous with 5,000 troops from Gibraltar.
To the Peninsula.
Ready for battle, he left Cork on 12 July 1808 to participate in the war against French forces in the Iberian Peninsula, with his skills as a commander tested and developed. According to the historian Robin Neillands, "Wellesley had by now acquired the experience on which his later successes were founded. He knew about command from the ground up, about the importance of logistics, about campaigning in a hostile environment. He enjoyed political influence and realised the need to maintain support at home. Above all, he had gained a clear idea of how, by setting attainable objectives and relying on his own force and abilities, a campaign could be fought and won."
Peninsular War.
1808.
Wellesley defeated the French at the Battle of Roliça and the Battle of Vimeiro in 1808 but was superseded in command immediately after the latter battle. General Dalrymple then signed the controversial Convention of Sintra, which stipulated that the British Royal Navy transport the French army out of Lisbon with all their loot, and insisted on the association of the only available government minister, Wellesley.
Dalrymple and Wellesley were recalled to Britain to face a Court of Enquiry. Wellesley had agreed to sign the preliminary armistice, but had not signed the convention, and was cleared.
Meanwhile, Napoleon himself entered Spain with his veteran troops to put down the revolt; the new commander of the British forces in the Peninsula, Sir John Moore, died during the Battle of Corunna in January 1809.
Although overall the land war with France was not going well from a British perspective, the Peninsula was the one theatre where they, with the Portuguese, had provided strong resistance against France and her allies. This contrasted with the disastrous Walcheren expedition, which was typical of the mismanaged British operations of the time. Wellesley submitted a memorandum to Lord Castlereagh on the defence of Portugal. He stressed its mountainous frontiers and advocated Lisbon as the main base because the Royal Navy could help to defend it. Castlereagh and the cabinet approved the memo, appointed him head of all British forces in Portugal.
1809.
Wellesley arrived in Lisbon on 22 April 1809 onboard HMS "Surveillante", after narrowly escaping shipwreck. Reinforced, he took to the offensive. In the Second Battle of Porto he crossed the Douro river in a daylight "coup de main", and routed Marshal Soult's French troops in Porto.
With Portugal secured, Wellesley advanced into Spain to unite with General Cuesta's forces. The combined allied force prepared for an assault on Victor's I Corps at Talavera, 23 July. Cuesta, however, was reluctant to agree, and was only persuaded to advance on the following day. The delay allowed the French to withdraw, but Cuesta sent his army headlong after Victor, and found himself faced by almost the entire French army in New Castile—Victor had been reinforced by the Toledo and Madrid garrisons. The Spanish retreated precipitously, necessitating the advance of two British divisions to cover their retreat.
The next day, 27 July, at the Battle of Talavera the French advanced in three columns and were repulsed several times throughout the day by Wellesley, but at a heavy cost to the British force. In the aftermath Marshal Soult's army was discovered to be advancing south, threatening to cut Wellesley off from Portugal. Wellesley moved east on 3 August to block it, leaving 1,500 wounded in the care of the Spanish, intending to confront Soult before finding out that the French were in fact 30,000 strong. The British commander sent the Light Brigade on a dash to hold the bridge over the Tagus River at Almaraz. With communications and supply from Lisbon secured for now, Wellesley considered joining with Cuesta again but found out that his Spanish ally had abandoned the British wounded to the French and was thoroughly uncooperative, promising and then refusing to supply the British forces, aggravating Wellesley and causing considerable friction between the British and their Spanish allies. The lack of supplies, coupled with the threat of French reinforcement (including the possible inclusion of Napoleon himself) in the spring, led to the British deciding to retreat into Portugal.
1810.
In 1810, a newly enlarged French army under Marshal André Masséna invaded Portugal. British opinion both at home and in the army was negative and there were suggestions that they must evacuate Portugal. Instead, Wellington first slowed the French down at Buçaco; he then prevented them from taking the Lisbon Peninsula by the construction of his massive earthworks, the Lines of Torres Vedras, which had been assembled in complete secrecy and had flanks guarded by the Royal Navy. The baffled and starving French invasion forces retreated after six months. Wellington's pursuit was frustrated by a series of reverses inflicted by Marshal Ney in a much-lauded rear guard campaign.
1811.
In 1811, Masséna returned toward Portugal to relieve Almeida; Wellington narrowly checked the French at the Battle of Fuentes de Onoro. Simultaneously, his subordinate, Viscount Beresford, fought Soult's 'Army of the South' to a mutual bloody standstill at the Battle of Albuera in May. Wellington was promoted to full General on 31 July for his services. The French abandoned Almeida, slipping away from British pursuit, but retained the twin Spanish fortresses of Ciudad Rodrigo and Badajoz, the 'Keys' guarding the roads through the mountain passes into Portugal. For his actions for the Portuguese cause, Wellesley was conferred the title of Count of Vimeiro, in the Peerage of Portugal.
1812.
In 1812, Wellington finally captured Ciudad Rodrigo by a rapid movement as the French went into winter quarters, storming it before they could react. He then moved south quickly, besieged the fortress of Badajoz for a month and captured it during one bloody night. On viewing the aftermath of the Storming of Badajoz, Wellington lost his composure and cried at the sight of the bloody carnage in the breaches.
His army now was a veteran British force reinforced by units of the retrained Portuguese army. Campaigning in Spain, he routed the French at the Battle of Salamanca, taking advantage of a minor French mispositioning. The victory liberated the Spanish capital of Madrid. As reward, he was created "Earl" and then "Marquess of Wellington" and given command of all Allied armies in Spain. Wellington attempted to take the vital fortress of Burgos, which linked Madrid to France. But failure, due in part to a lack of siege guns, forced him into a headlong retreat with the loss of over 2,000 casualties.
The French abandoned Andalusia, and combined the troops of Soult and Marmont. Thus combined, the French outnumbered the British, putting the British forces in a precarious position. Wellington withdrew his army and, joined with the smaller corps commanded by Rowland Hill, began to retreat to Portugal. Marshal Soult declined to attack.
In 1812, Wellesley was granted the titles of Marquis of Torres Vedras and Duke of Vitória, both in Portuguese nobility, by decree of Queen Maria I of Portugal, for his actions in the name of the Portuguese nation.
1813.
In 1813, Wellington led a new offensive, this time against the French line of communications. He struck through the hills north of Burgos, the Tras os Montes, and switched his supply line from Portugal to Santander on Spain's north coast; this led to the French abandoning Madrid and Burgos. Continuing to outflank the French lines, Wellington caught up with and smashed the army of King Joseph Bonaparte in the Battle of Vitoria, for which he was promoted to field marshal on 21 June. He personally led a column against the French centre, while other columns commanded by Sir Thomas Graham, Rowland Hill and the Earl of Dalhousie looped around the French right and left (this battle became the subject of Beethoven's opus 91, "Wellington's Victory"). The British troops broke ranks to loot the abandoned French wagons instead of pursuing the beaten foe. This gross abandonment of discipline caused an enraged Wellington to write in a famous dispatch to Earl Bathurst, "We have in the service the scum of the earth as common soldiers".
Although later, when his temper had cooled, he extended his comment to praise the men under his command saying that though many of the men were, "the scum of the earth; it is really wonderful that we should have made them to the fine fellows they are".
After taking the small fortresses of Pamplona, Wellington invested San Sebastián but was frustrated by the obstinate French garrison, losing 693 dead and 316 captured in a failed assault and suspending the siege at the end of July. Soult's relief attempt was blocked by the Spanish Army of Galicia at San Marcial, allowing the Allies to consolidate their position and tighten the ring around the city, which fell in September after a second spirited defence. Wellington then forced Soult's demoralised and battered army into a fighting retreat into France, punctuated by battles at the Pyrenees, Bidassoa and Nivelle. Wellington invaded southern France, winning at the Nive and Orthez. Wellington's final battle against his rival Soult occurred at Toulouse, where the Allied divisions were badly mauled storming the French redoubts, losing some 4,600 men. Despite this momentary victory, news arrived of Napoleon's defeat and abdication and Soult, seeing no reason to continue the fighting, agreed on a ceasefire with Wellington, allowing Soult to evacuate the city.
Aftermath.
Hailed as the conquering hero by the British, Wellington was created "Duke of Wellington", a title still held by his descendants (as he did not return to England until the Peninsular War was over, he was awarded all his patents of nobility in a unique ceremony lasting a full day). Although Wellesley spent nearly six years driving the French Army from Spain and removing Joseph Bonaparte from the Spanish throne, he has received little recognition in Spain: history, as taught in Spanish schools, minimises his contribution and those of the British and Portuguese soldiers that fought with him. He received some recognition during his lifetime (the title of "Duque de Ciudad Rodrigo") and the Spanish King Ferdinand VII allowed him to keep part of the works of art from the Royal Collection which he had recovered from the French. His equestrian portrait features prominently in the Monument to the Battle of Vitoria, in present-day Vitoria-Gasteiz.
His popularity in Britain was due to his image and his appearance as well as to his military triumphs. His victory fit well with the passion and intensity of the Romantic movement, with its emphasis on individuality. His personal style had an impact on the fashions on Britain at the time: his tall, lean figure and his plumed black hat and grand yet classic uniform and white trousers became very popular.
In late 1814, the Prime Minister wanted him to take command in Canada and with the assignment of winning the War of 1812 against the United States. Wellington replied that he would go to America, but he believed that he was needed more in Europe. He stated:
I think you have no right, from the state of war, to demand any concession of territory from America... You have not been able to carry it into the enemy's territory, notwithstanding your military success, and now undoubted military superiority, and have not even cleared your own territory on the point of attack. You cannot on any principle of equality in negotiation claim a cession of territory except in exchange for other advantages which you have in your power... Then if this reasoning be true, why stipulate for the uti possidetis? You can get no territory: indeed, the state of your military operations, however creditable, does not entitle you to demand any.
The Prime Minister agreed with Wellington and speeded up the negotiations that ended the war with no boundary changes through the Treaty of Ghent.
He was appointed ambassador to France, then took Lord Castlereagh's place as first plenipotentiary to the Congress of Vienna, where he strongly advocated allowing France to keep its place in the European balance of power. On 2 January 1815 the title of his Knighthood of the Bath was converted to Knight Grand Cross upon the expansion of that order.
Waterloo campaign.
On 26 February 1815, Napoleon escaped from Elba and returned to France. He regained control of the country by May and faced a renewed alliance against him. Wellington left Vienna for what became known as the Waterloo Campaign. He arrived in Belgium to take command of the British-German army and their allied Dutch-Belgians, all stationed alongside the Prussian forces of Gebhard Leberecht von Blücher.
Napoleon's strategy was to isolate the Allied and Prussian armies, and annihilate each one separately before the Austrians and Russians arrived. In doing so the vast superiority in numbers of the Coalition would be greatly diminished. He would then seek the possibility of a peace with Austria and Russia.
The French invaded Belgium, defeated the Prussians at Ligny, and fought an indecisive battle with Wellington at the Battle of Quatre Bras. These events compelled the Anglo-Allied army to retreat to a ridge on the Brussels road, just south of the small town of Waterloo. On 17 June, a torrential rain soaked in, hampering movement. The next day, on 18 June, the Battle of Waterloo was fought. This was the first time Wellington had encountered Napoleon, and he commanded an Anglo-Dutch-German army that consisted of approximately 73,000 troops, 26,000 (36 percent) of whom were British.
Battle.
The Battle of Waterloo commenced with a diversionary attack on Hougoumont by a division of French soldiers. After a barrage of 80 cannons the first French infantry attack was launched by Comte D'Erlon's I Corps. D'Erlon's troops advanced through the Allied centre, resulting in Allied troops in front of the ridge retreating in disorder through the main position. D'Erlon's corps stormed the most fortified Allied position, La Haye Sainte, but failed to take it. An Allied division under Thomas Picton met the remainder of D'Erlon's corps head to head, engaging them in an infantry duel in which Picton fell. During this struggle Lord Uxbridge launched two of his cavalry brigades at the enemy, catching the French infantry off guard, driving them to the bottom of the slope, and capturing two French Imperial Eagles. The charge, however, over-reached itself, and the British cavalry, crushed by fresh French horsemen hurled at them by Napoleon, were driven back, suffering tremendous losses.
A little before 16:00, Marshal Ney noted an apparent exodus from Wellington's centre. He mistook the movement of casualties to the rear for the beginnings of a retreat, and sought to exploit it. Ney at this time had few infantry reserves left, as most of the infantry had been committed either to the futile Hougoumont attack or to the defence of the French right. Ney therefore tried to break Wellington's centre with a cavalry charge alone.
At about 16:30, the first Prussian corps arrived. Commanded by Freiherr von Bülow, IV Corps arrived as the French cavalry attack was in full spate. Bülow sent the 15th Brigade to link up with Wellington's left flank in the Frichermont-La Haie area while the brigade's horse artillery battery and additional brigade artillery deployed to its left in support. Napoleon sent Lobau's corps to intercept the rest of Bülow's IV Corps proceeding to Plancenoit. The 15th Brigade sent Lobau's corps into retreat to the Plancenoit area. Von Hiller's 16th Brigade also pushed forward with six battalions against Plancenoit. Napoleon had dispatched all eight battalions of the Young Guard to reinforce Lobau, who was now seriously pressed by the enemy. Napoleon's Young Guard counter-attacked and, after very hard fighting, secured Plancenoit, but were themselves counter-attacked and driven out. Napoleon then resorted to sending two battalions of the Middle/Old Guard into Plancenoit and after ferocious fighting they recaptured the village.
The French cavalry attacked the British infantry squares many times, each at heavy cost to the French but with few British casualties. Ney himself was displaced from his horse four times. Eventually it became obvious, even to Ney, that cavalry alone were achieving little. Belatedly, he organised a combined-arms attack, using Bachelu's division and Tissot's regiment of Foy's division from Reille's II Corps plus those French cavalry that remained in a fit state to fight. This assault was directed along much the same route as the previous heavy cavalry attacks.
Meanwhile at approximately the same time as Ney's combined-arms assault on the centre-right of Wellington's line, Napoleon ordered Ney to capture La Haye Sainte at whatever the cost. Ney accomplished this with what was left of D'Erlon's corps soon after 18:00. Ney then moved horse artillery up towards Wellington's centre and began to destroy the infantry squares at short-range with canister. This all but destroyed the 27th (Inniskilling) Regiment, and the 30th and 73rd Regiments suffered such heavy losses that they had to combine to form a viable square. Wellington's centre was now on the verge of collapse and wide open to an attack from the French. Luckily for Wellington, Pirch I's and Zieten's corps of the Prussian Army were now at hand. Zieten's corps permitted the two fresh cavalry brigades of Vivian and Vandeleur on Wellington's extreme left to be moved and posted behind the depleted centre. Pirch I Corps then proceeded to support Bülow and together they regained possession of Plancenoit, and once more the Charleroi road was swept by Prussian round shot. The value of this reinforcement at this particular moment can hardly be overestimated.
The French army now fiercely attacked the Coalition all along the line with the culminating point being reached when Napoleon sent forward the Imperial Guard at 19:30. The attack of the Imperial Guards was mounted by five battalions of the Middle Guard, and not by the Grenadiers or Chasseurs of the Old Guard. Marching through a hail of canister and skirmisher fire and severely outnumbered, the 3,000 or so Middle Guardsmen advanced to the west of La Haye Sainte and proceeded to separate into three distinct attack forces. One, consisting of two battalions of Grenadiers, defeated the Coalition's first line and marched on. Chassé's relatively fresh Dutch division was sent against them and Allied artillery fired into the victorious Grenadiers' flank. This still could not stop the Guard's advance, so Chassé ordered his first brigade to charge the outnumbered French, who faltered and broke.
Further to the west, 1,500 British Foot Guards under Maitland were lying down to protect themselves from the French artillery. As two battalions of Chasseurs approached, the second prong of the Imperial Guard's attack, Maitland's guardsmen rose and devastated them with point-blank volleys. The Chasseurs deployed to counter-attack, but began to waver. A bayonet charge by the Foot Guards then broke them. The third prong, a fresh Chasseur battalion, now came up in support. The British guardsmen retreated with these Chasseurs in pursuit, but the latter were halted as the 52nd Light Infantry wheeled in line onto their flank and poured a devastating fire into them and then charged. Under this onslaught they too broke.
The last of the Guard retreated headlong. A ripple of panic passed through the French lines as the astounding news spread: ""La Garde recule. Sauve qui peut"!" ("The Guard retreats. Save yourself if you can!"). Wellington then stood up in Copenhagen's stirrups, and waved his hat in the air to signal an advance of the Allied line just as the Prussians were overrunning the French positions to the east. What remained of the French army then abandoned the field in disorder. Wellington and Blücher met at the inn of La Belle Alliance, on the north-south road which bisected the battlefield, and it was agreed that the Prussians should pursue the retreating French army back to France. The Treaty of Paris was signed on 20 November 1815.
Controversy.
Much historical discussion has been made about Napoleon's decision to send 33,000 troops under Marshal Grouchy to intercept the Prussians, but—having defeated Blücher at Ligny on 16 June and forced the Allies to retreat in divergent directions—Napoleon may have been strategically astute in a judgement that he would have been unable to beat the combined Allied forces on one battlefield. Wellington's comparable strategic gamble was to leave 17,000 troops and artillery, mostly Dutch and Belgian, 8.1 mi away at Halle, north-west of Mont-Saint-Jean, in case of a French advance up the Mons-Hal-Brussels road.
Political career.
Wellington entered politics again, when he was appointed Master-General of the Ordnance in the Tory government of Lord Liverpool on 26 December 1818. He also became Governor of Plymouth on 9 October 1819. He was appointed Commander-in-Chief of the British Army on 22 January 1827 and Constable of the Tower of London on 5 February 1827.
Prime Minister.
Along with Robert Peel, Wellington became an increasingly influential member of the Tory party, and in 1828 he resigned as Commander-in-Chief and became Prime Minister of the United Kingdom.
During his first seven months as prime minister he chose not to live in the official residence at 10 Downing Street, finding it too small. He moved in only because his own home, Apsley House, required extensive renovations. During this time he was largely instrumental in the foundation of King's College London. On 20 January 1829 Wellington was appointed Lord Warden of the Cinque Ports.
As prime minister, Wellington was conservative, fearing the anarchy of the French Revolution would spread to England.
Catholic Emancipation.
The highlight of his term was Catholic Emancipation; the granting of almost full civil rights to Catholics in the United Kingdom. The change was prompted by the landslide by-election win of Daniel O'Connell, an Irish Catholic proponent of emancipation, who was elected despite not being legally allowed to sit in Parliament.
In the House of Lords, facing stiff opposition, Wellington spoke for Catholic Emancipation, giving one of the best speeches of his career. He was Irish, and later governed the country, so had some understanding of the grievances of the Catholic communities there; as Chief Secretary, he had given an undertaking that the remaining Penal Laws would only be enforced as "mildly" as possible. The Catholic Relief Act 1829 was passed with a majority of 105. Many Tories voted against the Act, and it passed only with the help of the Whigs. Wellington had threatened to resign as Prime Minister if the King (George IV) did not give his Royal Assent.
The Earl of Winchilsea accused the Duke of, "an insidious design for the infringement of our liberties and the introduction of Popery into every department of the State". Wellington responded by immediately challenging Winchilsea to a duel. On 21 March 1829, Wellington and Winchilsea met on Battersea fields. When it came time to fire, the Duke took aim and Winchilsea kept his arm down. The Duke fired wide to the right. Accounts differ as to whether he missed on purpose, an act known in dueling as a "delope". Wellington claimed he did. However, he was noted for his poor aim and reports more sympathetic to Winchilsea claimed he had aimed to kill. Winchilsea did not fire, a plan he and his second almost certainly decided upon before the duel. Honour was saved and Winchilsea wrote Wellington an apology.
The nickname "Iron Duke" originates from this period, when he experienced a high degree of personal and political unpopularity. Its repeated use in "Freeman's Journal" throughout June 1830 appears to bear reference to his resolute political will, with taints of disapproval from its Irish editors. His residence at Apsley House was targeted by a mob of demonstrators on 27 April 1831 and again on 12 October, leaving his windows smashed. Iron shutters were installed in June 1832 to prevent further damage by crowds angry over rejection of the Reform Bill, which he strongly opposed.
Wellington's government fell in 1830. In the summer and autumn of that year, a wave of riots swept the country. The Whigs had been out of power for most years since the 1770s, and saw political reform in response to the unrest as the key to their return. Wellington stuck to the Tory policy of no reform and no expansion of suffrage, and as a result lost a vote of no confidence on 15 November 1830.
The Reform Act.
The Whigs introduced the first Reform Bill while Wellington and the Tories worked to prevent its passage. The bill passed in the British House of Commons, but was defeated in the House of Lords. An election followed in direct response, and the Whigs were returned with an even larger majority. A second Reform Act was introduced, and defeated in the same way, and another wave of near insurrection swept the country. During this time, Wellington was greeted by a hostile reaction from the crowds at the opening of the Liverpool and Manchester Railway. The Whig Government fell in 1832 and Wellington was unable to form a Tory Government partly because of a run on the Bank of England. This left King William IV no choice but to restore Earl Grey to the premiership. Eventually the bill passed the House of Lords after the King threatened to fill that House with newly created Whig peers if it were not. Wellington was never reconciled to the change; when Parliament first met after the first election under the widened franchise, Wellington is reported to have said "I never saw so many shocking bad hats in my life".
Jewish Emancipation.
During debate on the Jewish Civil Disabilities Repeal Bill, Wellington, who opposed the Bill, stated in Parliament on 1 August 1833: "... this is a Christian country and a Christian legislature, and that the effect of this measure would be to remove that peculiar character." And "I see no ground whatever for passing the Bill; and shall, therefore, vote against it." The Bill was defeated, 104 votes against, and 54 for.
Conservative Government.
Wellington was gradually superseded as leader of the Tories by Robert Peel, while the party evolved into the Conservatives. When the Tories were returned to power in 1834, Wellington declined to become Prime Minister and Peel was selected instead. However, Peel was in Italy at that time and for three weeks in November and December 1834, Wellington acted as interim leader, taking the responsibilities of Prime Minister and most of the other ministries. In Peel's first cabinet (1834–1835), Wellington became Foreign Secretary, while in the second (1841–1846) he was a Minister without Portfolio and Leader of the House of Lords. Wellington was also re-appointed Commander-in-Chief of the British Army on 15 August 1842 following the resignation of Lord Hill.
Retirement.
Wellington retired from political life in 1846, although he remained Commander-in-Chief, and returned briefly to the spotlight in 1848 when he helped organise a military force to protect London during that year of European revolution.
The Conservative Party had split over the Repeal of the Corn Laws in 1846, with Wellington and most of the former Cabinet still supporting Peel, but most of the MPs led by Lord Derby supporting a protectionist stance. Early in 1852 Wellington, by then very deaf, gave Derby's first government its nickname by shouting "Who? Who?" as the list of inexperienced Cabinet Ministers was read out in the House of Lords.
He became Chief Ranger and Keeper of Hyde Park and St. James's Park on 31 August 1850. He was also colonel of the 33rd Regiment of Foot from 1 February 1806 and colonel of the Grenadier Guards from 22 January 1827.
Kitty died of cancer in 1831; despite their generally unhappy relations, which had led to an effective separation, Wellington was said to have been greatly saddened by her death, his one comfort being that after "half a lifetime together, they had come to understand each other at the end". He had found consolation for his unhappy marriage in his warm friendship with the diarist Harriet Arbuthnot, wife of his colleague Charles Arbuthnot. Harriet's death in the cholera epidemic of 1834 was almost as great a blow to Wellington as it was to her husband. The two widowers spent their last years together at Aspley House.
Death and funeral.
Wellington died at Walmer Castle in Deal on 14 September 1852. This was his residence as Lord Warden of the Cinque Ports. Walmer Castle was said to have been his favourite residence. He was found to be unwell on that morning and was aided from his military campaign bed (the same one he used throughout his historic military career) and seated in his chair where he passed away. His death was recorded as being due to the after effects of a stroke culminating in a series of seizures. He was aged 83.
Although in life he hated travelling by rail (after witnessing the death of William Huskisson, one of the first railway accident casualties), his body was then taken by train to London, where he was given a state funeral—one of only a handful of British subjects to be honoured in that way (other examples are Lord Nelson and Winston Churchill)—and the last heraldic state funeral to be held in Britain. The funeral took place on 18 November 1852. At his funeral there was hardly any space to stand because of the number of people attending, and the effusive praise given him in Tennyson's "Ode on the Death of the Duke of Wellington" attests to his stature at the time of his death. He was buried in a sarcophagus of luxulyanite in St Paul's Cathedral next to Lord Nelson. A bronze memorial was sculpted by Alfred Stevens, and features two intricate supports: "Truth tearing the tongue out of the mouth of False-hood", and "Valour trampling Cowardice underfoot". Stevens did not live to see it placed in its home under one of the great arches of the Cathedral.
Wellington's casket was decorated with banners which were made for his funeral procession. Originally, there was one from Prussia, which was removed during World War I and never reinstated.
Most of the book "A Biographical Sketch of the Military and Political Career of the Late Duke of Wellington" by Weymouth newspaper proprietor Joseph Drew is a detailed contemporary account of his death, lying in state and funeral.
After his death Irish and English newspapers disputed whether Wellington had been born an Irishman or Englishman. During his life he had openly disliked being referred to as an "Irishman".
Owing to its links with Wellington, as the former commanding officer and colonel of the regiment, the title "33rd (The Duke of Wellington's) Regiment" was granted to the 33rd Regiment of Foot, on 18 June 1853 (the 38th anniversary of the Battle of Waterloo) by Queen Victoria.
Personality.
Wellington always rose early, he "couldn't bear to lie awake in bed," even if the army was not on the march. Even when he returned to civilian life after 1815, he slept in a camp bed, reflecting his lack of regard for creature comforts—it remains on display in Walmer Castle. General Miguel de Álava complained that Wellington said so often that the army would march "at daybreak" and dine on "cold meat", that he began to dread those two phrases. While on campaign, he seldom ate anything between breakfast and dinner. During the retreat to Portugal in 1811, he subsisted, to the despair of his staff who dined with him, on "cold meat and bread". He was, however, renowned for the quality of the wine he drank and served, often drinking a bottle with his dinner—not a great quantity by the standards of his day.
He rarely showed emotion in public, and often appeared condescending to those less competent or less well-born than himself (which was nearly everyone). However, Álava was a witness to an incident just before the Battle of Salamanca. Wellington was eating a chicken leg while observing the manoeuvres of the French army through a spyglass. He spotted an overextension in the French left flank, and realised he could launch a successful attack there. He threw the drumstick in the air and shouted "Les français sont perdus!" ("The French are lost!"). Another time, after the Battle of Toulouse, when an aide brought him the news of Napoleon's abdication, he broke into an impromptu flamenco dance, spinning around on his heels and clicking his fingers.
Despite his famous stern countenance and iron-handed discipline (he was said to disapprove of soldiers cheering as "too nearly an expression of opinion"), Wellesley cared for his men; he refused to pursue the French after the battles of Porto and Salamanca, foreseeing an inevitable cost to his army in chasing a diminished enemy through rough terrain. The only time he ever showed grief in public was after the storming of Badajoz; he cried at the sight of the British dead in the breaches. In this context, his famous dispatch after the Battle of Vitoria calling them the "scum of the earth" can be seen to be fuelled as much by disappointment at their breaking ranks as by anger. He expressed his grief openly the night after Waterloo before his personal physician, and later with his family; unwilling to be congratulated for his victory he broke down in tears, his fighting spirit diminished by the high cost of the battle and great personal loss.
Viva Montgomerie, niece to the third Duke of Wellington, relates an anecdote that Holman, valet to the duke, often recalled how his master never spoke to servants unless he was obliged to, preferring instead to write his orders on a note pad on his dressing-table. Holman, incidentally, was said to greatly resemble Napoleon.
In 1822 he had had an operation to improve the hearing of the left ear. The result, however, was that he became permanently deaf on that side. It is claimed that he was "... never quite well afterwards".
Wellington had a "vigorous sexual appetite" and many amorous liaisons during his marriage to Kitty. He enjoyed the company of intellectual and attractive women for many decades, particularly after the Battle of Waterloo and his subsequent Ambassadorial position in Paris. The British press lampooned this side of the national hero. In 1824 one liaison came back to haunt him, when Wellington received a letter from a publisher offering to refrain from issuing an edition of the rather racy memoirs of one of his mistresses, Harriette Wilson, in exchange for financial consideration. It is said that the Duke promptly returned the missive, after scrawling across it, "Publish and be damned". However, Hibbert notes in his biography that the letter can be found among the Duke's papers, with nothing written on it. That Wellington "did" reply is certain, and the tone of a further letter from the publisher, quoted by Longford, suggests that he had refused, in the strongest language, to submit to blackmail.
He was also a remarkably practical man, who spoke concisely. In 1851, when it was discovered that there were a great many sparrows flying about in the Crystal Palace just before the Great Exhibition was to open, his advice to Queen Victoria was "Sparrowhawks, ma'am".
Wellington has often been portrayed as a defensive general, even though many, perhaps most, of his battles were offensive (Argaum, Assaye, Oporto, Salamanca, Vitoria, Toulouse). But for most of the Peninsular War, where he earned his fame, his troops lacked the numbers for an attack.
Meeting Lord Nelson.
In September 1805, the then Major-General Wellesley, newly returned from his campaigns in India and not yet particularly well-known to the public, reported to the office of the Secretary for War to request a new assignment. In the waiting room, he met Vice-Admiral Horatio Nelson, already a legendary figure after his victories at the Nile and Copenhagen, and who was briefly in England after months chasing the French Toulon fleet to the West Indies and back. Some 30 years later, Wellington recalled a conversation that Nelson began with him which Wellesley found "almost all on his side in a style so vain and silly as to surprise and almost disgust me". Nelson left the room to inquire who the young general was and on his return switched to a very different tone, discussing the war, the state of the colonies and the geopolitical situation as between equals. On this second discussion Wellington recalled, "I don't know that I ever had a conversation that interested me more". This was the only time that the two men met; Nelson was killed at his great victory at Trafalgar just seven weeks later.
Wellesley and Colley / Cowley heritage.
The earliest mention of the "Welles-lieghs" dates from 1180, around a settlement still known as Wellesley Farm. The family had been granted lands to the south of Wells, Somerset for their 'Passive acceptance of the Norman conquest of England of 1066. An early member Stephen De Wellesley who married Alice (De Caille) from Yorkshire Eng. of the family relocated to Ireland during 1172, in the role of a Standard Bearer to Henry II. The surname "Wesley" was adopted from a childless wealthy cousin, Garret Westley. In 1728, Wellington's paternal grandfather Richard Colley, a landlord who lived at Rahin near Carbury, County Kildare, changed his surname to Wesley.
The Colley or Cowley family had lived in that part of Kildare since the time of Wellington's ancestor, Sir Henry Colley or Cowley, who died before 2 October 1584. Sir Henry in his lifetime possessed Carbury Castle, in north-west Kildare, starting with a 21-year lease in 1554.
Colley is a surname of English origin. However, Colley or Cowley is also an Anglicised form of Mac Amhalghaidh, a family who were lords of Cálraighe in Chalaid in what is now County Westmeath. This family were claimed descent from the 5th-century Irish king, Niall of the Nine Hostages, and had the following genealogy ("m" indicates "son of"):
Amlaibh m Amlaibh m Muircertaigh m Aedha Finn m Maghnusa m Muircertaigh m Domnaill m Floinn m Aedha m Amhlaibh m Fergail m Con Coiccriche m Forannain m Suibhne m Domnaill m Ruairc m Cathusaigh m Aedha m Cuinn m Maoil Fhothaid m Criomthainn m Brenainn m Briain m Maine m Nell Noigiallaigh.
The weight of evidence is that Wellington's family originated from John Cooley born abt. 1400 & was the Lord of Glaston, Rutlandshire England and his son Walter born 1440 came to Drogheda, Ireland about 1500. Walters son Robert Cowley who became Master of the Rolls in Ireland died in 1546 leaving a son, Walter Cowley, Principal Solicitor for Ireland, who appears to have been father to Sir Henry. Henry Colley married Katherine Cusack, daughter of Sir Thomas Cusack, Lord Chancellor of Ireland which began the Colley-Wellesley connection, since Sir Thomas was the son of John & Alison de Wellesley Cusack.
Titles and tributes.
Wellington received numerous awards and honours during and after his lifetime, including statues and monuments raised in his honour. He held a wide range of titles, and had various buildings and places named after him around the world which still stand today.
Nicknames.
The Iron Duke.
This commonly used nickname originally related to his consistent political resolve rather than to any particular incident. In various cases its editorial use appears to be disparaging. It is likely that its use became more widespread after an incident in 1832 in which he installed metal shutters to prevent rioters breaking windows at Apsley House. The term may have been made increasingly popular by "Punch" cartoons published in 1844–45.
Wellington had various other nicknames:
In addition:

</doc>
<doc id="8476" url="http://en.wikipedia.org/wiki?curid=8476" title="Disk operating system">
Disk operating system

Disk Operating System (specifically) and disk operating system (generically), most often reveal themselves in abbreviated form as DOS, refer to an operating system software used in most computers that provides the abstraction and management of secondary storage devices and the information on them (e.g., file systems for organizing files of all sorts). Such software is referred to as a "disk" operating system when the storage devices it manages are made of rotating platters, such as floppy disks or hard disks.
In the early days of microcomputers, computer memory space was often limited, so the disk operating system was an extension of the operating system. This component was only loaded if needed. Otherwise, disk access would be limited to low-level operations such as reading and writing disks at the sector-level.
In some cases, the "disk operating system" component (or even the operating system) was known as "DOS".
Sometimes, a "disk operating system" can refer to the entire operating system if it is loaded off a disk and supports the abstraction and management of disk devices. Examples include DOS/360. On the PC compatible platform, an entire family of operating systems was called "DOS".
History.
In the early days of computers, there were no disk drives, floppies or modern flash storage devices. Early storage devices such as delay lines, punched cards, paper tape, magnetic tape, and magnetic drums were used instead. And in the early days of microcomputers, paper tape or audio cassette tape (see Kansas City standard) or nothing were used instead. In the latter case, program and data entry was done at front panel switches directly into memory or through a computer terminal / keyboard, sometimes controlled by a read-only memory (ROM) BASIC interpreter; when power was turned off after running the program, the information so entered vanished.
Both hard disks and floppy disk drives require software to manage rapid access to block storage of sequential and other data. When microcomputers rarely had expensive disk drives of any kind, the need to have software to manage such devices (the disks) carried much status. To have one or the other was a mark of distinction and prestige, and so was having the Disk sort of an Operating System. As prices for both disk hardware and operating system software decreased, there were many such microcomputer systems.
Mature versions of the Commodore, SWTPC, Atari and Apple home computer systems all featured a disk operating system (actually called 'DOS' in the case of the Commodore 64 ("CBM DOS"), Atari 800 ("Atari DOS"), and Apple II machines ("Apple DOS")), as did (at the other end of the hardware spectrum, and much earlier) IBM's System/360, 370 and (later) 390 series of mainframes (e.g., DOS/360: Disk Operating System / 360" and DOS/VSE: Disk Operating System / Virtual Storage Extended"). Most home computer DOS'es were stored on a floppy disk always to be booted at start-up, with the notable exception of Commodore, whose DOS resided on ROM chips in the disk drives themselves (the computer itself had no DOS, just a form of a BIOS for communicating with peripherals). The Lt. Kernal hard disk subsystem for the Commodore 64 and Commodore 128 models stored its DOS on the disk, as is the case with modern systems, and loaded the DOS into RAM at boot time.
In large machines there were other disk operating systems, such as IBM's VM, DEC's RSTS / RT-11 / VMS / TOPS-10 / TWENEX, MIT's ITS / CTSS, Control Data's assorted NOS variants, Harris's Vulcan, Bell Labs' Unix, and so on. In microcomputers, SWTPC's 6800 and 6809 machines used TSC's FLEX disk operating system, Radio Shack's TRS-80 machines used TRS-DOS, their Color Computer used OS-9, and most of the Intel 8080 based machines from IMSAI, MITS (makers of the legendary Altair 8800), Cromemco, North Star, etc., used the CP/M-80 disk operating system. See list of operating systems.
Usually, a disk operating system was loaded from a disk. Only a very few comparable DOSes were stored elsewhere than floppy disks; among these exceptions were the British BBC Micro's optional Disc Filing System, DFS, offered as a kit with a disk controller chip, a ROM chip, and a handful of logic chips, to be installed inside the computer; and Commodore's CBM DOS, located in a ROM chip in each disk drive.
Disk operating systems that were the main OS.
Some disk operating systems were the operating system for the entire computer system.

</doc>
<doc id="8477" url="http://en.wikipedia.org/wiki?curid=8477" title="Dual">
Dual

Dual may refer to:

</doc>
