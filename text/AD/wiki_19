<doc id="45854" url="http://en.wikipedia.org/wiki?curid=45854" title="Uffizi">
Uffizi

The Uffizi Gallery (Italian: Galleria degli Uffizi, ]) is an art museum in Italy. It is located in Florence, and is one of the oldest and most famous art museums in the world.
History.
The building of Uffizi was begun by Giorgio Vasari in 1560 for Cosimo I de' Medici so as to accommodate the offices of the Florentine magistrates, hence the name "uffizi", "offices". The construction was later continued by Alfonso Parigi and Bernardo Buontalenti and completed in 1581. The "cortile" (internal courtyard) is so long and narrow, and open to the Arno at its far end through a Doric screen that articulates the space without blocking it, that architectural historians treat it as the first regularized streetscape of Europe. Vasari, a painter and architect as well, emphasised its perspective length by the matching facades' continuous roof cornices, and unbroken cornices between storeys and the three continuous steps on which the palace-fronts stand. The niches in the piers that alternate with columns filled with sculptures of famous artists in the XIX century.
The Uffizi brought together under one roof the administrative offices, the Tribunal and the Archivio di Stato, the state archive. The project that was planned by Cosimo I de' Medici, Grand Duke of Tuscany to arrange prime works of art in the Medici collections on the piano nobile was effected by Francis I of Tuscany, who commissioned Buontalenti the famous Tribuna degli Uffizi that united a selection of the outstanding masterpieces in the collection in an ensemble that was a star attraction of the Grand Tour.
Over the years, further parts of the palace evolved into a display place for many of the paintings and sculpture collected by the House of Medici or commissioned by them. According to Vasari, who was not only the architect of the Uffizi but also the author of "Lives of the Artists", published in 1550 and 1568, artists such as Leonardo da Vinci and Michelangelo gathered at the Uffizi "for beauty, for work and for recreation."
After the house of Medici was extinguished, the art treasures remained in Florence by terms of the famous "Patto di famiglia" negotiated by Anna Maria Luisa, the last Medici heiress; it formed one of the first modern museums. The gallery had been open to visitors by request since the sixteenth century, and in 1765 it was officially opened to the public.
Because of its huge collection, some of its works have in the past been transferred to other museums in Florence—for example, some famous statues to the Bargello. A project is currently underway to expand the museum's exhibition space in 2006 from some 6,000 metres² (64,000 ft²) to almost 13,000 metres² (139,000 ft²), allowing public viewing of many artworks that have usually been in storage.
In 1993, a car bomb exploded in Via dei Georgofili and damaged parts of the palace, killing five people. The most severe damage was to the Niobe room and classical sculptures and neoclassical interior of which have been restored, although its frescoes were damaged beyond repair. The identity of the bomber or bombers are unknown, although it was almost certainly attributable to the Sicilian Mafia who were engaged in a period of terrorism at that time.
Today, the Uffizi is one of the most popular tourist attractions of Florence. In high season (particularly in July), waiting times can be up to five hours.
In early August 2007, Florence was caught with a large rainstorm, and the Gallery was partially flooded, with water leaking through the ceiling, and the visitors had to be evacuated. There was a much more significant flood in 1966 which damaged most of the art collections in Florence severely, including the Uffizi.
Here is a selection from the painting collection:
The collection also contains some ancient sculptures, such as the "Arrotino" and the "Two Wrestlers".

</doc>
<doc id="45856" url="http://en.wikipedia.org/wiki?curid=45856" title="Monastery">
Monastery

A monastery is the building or complex of buildings comprising the domestic quarters and workplace(s) of monastics, whether monks or nuns, and whether living in communities or alone (hermits). The monastery generally includes a place reserved for prayer which may be a chapel, church or temple, and may also serve as an oratory.
Monasteries may vary greatly in size, comprising a small dwelling accommodating only a hermit, or in the case of communities anything from a single building housing only one senior and two or three junior monks or nuns, to vast complexes and estates housing tens or hundreds. A monastery complex typically comprises a number of buildings which include a church, dormitory, cloister, refectory, library, and infirmary. Depending on the location, the monastic order and the occupation of its inhabitants, the complex may also include a wide range of buildings that facilitate self-sufficiency and service to the community. These may include a hospice, a school and a range of agricultural and manufacturing buildings such as a barn, a forge or a brewery.
In English usage, the term "monastery" is generally used to denote the buildings of a community of monks. In modern usage "convent" tends to be applied only to institutions of female monastics (nuns), particularly communities of teaching or nursing Religious Sisters. Historically, a convent denoted a house of friars, (reflecting the Latin), now more commonly called a "friary". Various religions may apply these terms in more specific ways.
Etymology.
The word "monastery" comes from the Greek word "μοναστήριον", neut. of "μοναστήριος" – "monasterios" from "μονάζειν" – "monazein" "to live alone" from the root "μόνος" – "monos" "alone" (originally all Christian monks were hermits); the suffix "-terion" denotes a "place for doing something". The earliest extant use of the term "monastērion" is by the 1st century AD Jewish philosopher Philo in "On The Contemplative Life," ch. III.
In England the word "monastery" was also applied to the habitation of a bishop and the cathedral clergy who lived apart from the lay community. Most cathedrals were not monasteries, and were served by canons secular, which were communal but not monastic. However some were run by monastic orders, such as York Minster. Westminster Abbey was for a short time a cathedral, and was a Benedictine monastery until the Reformation, and its Chapter preserves elements of the Benedictine tradition. See the entry cathedral. They are also to be distinguished from collegiate churches, such as St George's Chapel, Windsor.
Terms.
In most of this article, the term "monastery" is used generically to refer to any of a number of types of religious community. In the Roman Catholic religion and to some extent in certain other branches of Buddhism, there is a somewhat more specific definition of the term and many related terms.
Buddhist monasteries are generally called vihara (Pali language). Viharas may be occupied by males or females, and in keeping with common English usage, a vihara populated by females may often be called a nunnery or a convent. However, vihara can also refer to a temple. In Tibetan Buddhism, monasteries are often called gompa. In Thailand, Laos and Cambodia, a monastery is called a wat.
A monastery may be an abbey (i.e., under the rule of an abbot), or a priory (under the rule of a prior), or conceivably a hermitage (the dwelling of a hermit). It may be a community of men (monks) or of women (nuns). A charterhouse is any monastery belonging to the Carthusian order. In Eastern Christianity a very small monastic community can be called a skete, and a very large or important monastery can be given the dignity of a lavra.
The great communal life of a Christian monastery is called cenobitic, as opposed to the anchoretic (or anchoritic) life of an anchorite and the eremitic life of a hermit. There has also been, mostly under the Osmanli occupation of Greece and Cyprus, an "idiorrhythmic" lifestyle where monks come together but being able to own things individually and not being obliged to work for the common good.
In Hinduism monasteries are called matha, mandir, koil, or most commonly an ashram.
Jains use the Buddhist term vihara.
Monastic life.
In most religions the life inside monasteries is governed by community rules that stipulate the gender of the inhabitants and require them to remain celibate and own little or no personal property. The degree to which life inside a particular monastery is socially separate from the surrounding populace can also vary widely; some religious traditions mandate isolation for purposes of contemplation removed from the everyday world, in which case members of the monastic community may spend most of their time isolated even from each other. Others focus on interacting with the local communities to provide services, such as teaching, medical care, or evangelism. Some monastic communities are only occupied seasonally, depending both on the traditions involved and the local weather, and people may be part of a monastic community for periods ranging from a few days at a time to almost an entire lifetime.
The life within the walls of a monastery may be supported in several ways: by manufacturing and selling goods, often agricultural products, by donations or alms, by rental or investment incomes, and by funds from other organizations within the religion, which in the past formed the traditional support of monasteries. There has been a long tradition of Christian monasteries providing hospitable, charitable and hospital services. Monasteries have often been associated with the provision of education and the encouragement of scholarship and research, which has led to the establishment of schools and colleges and the association with universities. Christian monastic life has adapted to modern society by offering computer services, accounting services and management as well as modern hospital and educational administration.
Buddhism.
Buddhist monasteries, known as vihara, emerged sometime around the 4th century BC, from the practice of vassa, the retreat undertaken by Buddhist monks and nuns during the South Asian rainy season. To prevent wandering monks from disturbing new plant growth or becoming stranded in inclement weather, Buddhist monks and nuns were instructed to remain in a fixed location for the roughly three-month period typically beginning in mid-July. Outside of the "vassa" period, monks and nuns both lived a migratory existence, wandering from town to town begging for food. These early fixed "vassa" retreats were held in pavilions and parks that had been donated to the "sangha" by wealthy supporters. Over the years, the custom of staying on property held in common by the "sangha" as a whole during the "vassa" retreat evolved into a more cenobitic lifestyle, in which monks and nuns resided year round in monasteries.
In India, Buddhist monasteries gradually developed into centres of learning where philosophical principles were developed and debated; this tradition is currently preserved by monastic universities of Vajrayana Buddhists, as well as religious schools and universities founded by religious orders across the Buddhist world. In modern times, living a settled life in a monastery setting has become the most common lifestyle for Buddhist monks and nuns across the globe.
Whereas early monasteries are considered to have been held in common by the entire "sangha", in later years this tradition diverged in a number of countries. Despite "vinaya" prohibitions on possessing wealth, many monasteries became large land owners, much like monasteries in medieval Christian Europe. In China, peasant families worked monastic-owned land in exchange for paying a portion of their yearly crop to the resident monks in the monastery, just as they would to a feudal landlord. In Sri Lanka and Tibet, the ownership of a monastery often became vested in a single monk, who would often keep the property within the family by passing it on to a nephew who ordained as a monk. In Japan, where civil authorities permitted Buddhist monks to marry, being the head of a temple or monastery sometimes became a hereditary position, passed from father to son over many generations.
Forest monasteries – most commonly found in the Theravada traditions of Southeast Asia and Sri Lanka – are monasteries dedicated primarily to the study of Buddhist meditation, rather than scholarship or ceremonial duties. Forest monasteries often function like early Christian monasteries, with small groups of monks living an essentially hermit-like life gathered loosely around a respected elder teacher. While the wandering lifestyle practised by the Buddha and his disciples continues to be the ideal model for forest tradition monks in Thailand and elsewhere, practical concerns- including shrinking wilderness areas, lack of access to lay supporters, dangerous wildlife, and dangerous border conflicts- dictate that more and more 'meditation' monks live in monasteries, rather than wandering.
Tibetan Buddhist monasteries are sometimes known as lamaseries and the monks are sometimes (mistakenly) known as lamas. H. P. Blavatsky's Theosophical Society named its initial New York City meeting place "the Lamasery."
Some famous Buddhist monasteries include:
A further list of Buddhist monasteries is available at the list of Buddhist temples
Trends in Buddhist monasticism.
Some of the largest monasteries in the world are Buddhist. Drepung Monastery in Tibet housed around 10,000 monks prior to the Chinese invasion. Today its relocated monastery in India houses around 8,000.
Christianity.
According to tradition, Christian monasticism began in Egypt with St. Anthony. Originally, all Christian monks were hermits seldom encountering other people. But because of the extreme difficulty of the solitary life, many monks failed, either returning to their previous lives, or becoming spiritually deluded.
A transitional form of monasticism was later created by Saint Amun in which "solitary" monks lived close enough to one another to offer mutual support as well as gathering together on Sundays for common services.
It was St. Pachomios who developed the idea of having monks live together and worship together under the same roof (Coenobitic Monasticism). Some attribute his mode of communal living to the barracks of the Roman Army in which Pachomios served as a young man. Soon the Egyptian desert blossomed with monasteries, especially around Nitria (Wadi El Natrun), which was called the "Holy City". Estimates are that upwards of 50,000 monks lived in this area at any one time.
Hermitism never died out though, but was reserved only for those advanced monks who had worked out their problems within a cenobitic monastery.
The idea caught on, and other places followed:
Western Medieval Europe.
The life of prayer and communal living was one of rigorous schedules and self-sacrifice. Prayer was their work, and the Office prayers took up much of a monk's waking hours – Matins, Lauds, Prime, Terce, daily Mass, Sext, None, Vespers, and Compline. In between prayers, monks were allowed to sit in the cloister and work on their projects of writing, copying, or decorating books. These would have been assigned based on a monk's abilities and interests. The non-scholastic types were assigned to physical labour of varying degrees.
The main meal of the day took place around noon, often taken at a refectory table, and consisted of the most simple and bland foods i.e., poached fish, boiled oats. While they ate, scripture would be read from a pulpit above them. Since no other words were allowed to be spoken, monks developed communicative gestures. Abbots and notable guests were honoured with a seat at the high table, while everyone else sat perpendicular to that in the order of seniority. This practice remained when some monasteries became universities after the first millennium, and can still be seen at Oxford University and Cambridge University.
Monasteries were important contributors to the surrounding community. They were centres of intellectual progression and education. They welcomed aspiring priests to come study and learn, allowing them even to challenge doctrine in dialogue with superiors. The earliest forms of musical notation are attributed to a monk named Notker of St Gall, and was spread to musicians throughout Europe by way of the interconnected monasteries. Since monasteries offered respite for weary pilgrim travellers, monks were obligated also to care for their injuries or emotional needs. Over time, lay people started to make pilgrimages "to" monasteries instead of just using them as a stop over. By this time, they had sizeable libraries that attracted learned tourists. Families would donate a son in return for blessings. During the plagues, monks helped to till the fields and provide food for the sick.
A Warming House is a common part of a medieval monastery, where monks went to warm themselves. It was often the only room in the monastery where a fire was lit.
Catholic religious orders.
A number of distinct monastic orders developed within Roman Catholicism.
While in English most mendicant Orders use the monastic terms of monastery or priory, in the Latin languages, the term used by the friars for their houses is convent, from the Latin "conventus", e.g., (Italian: "convento") or (French: "couvent"), meaning "gathering place". The Franciscans rarely use the term "monastery" at present, preferring to call their house a "friary".
Orthodox Christianity.
In the Eastern Orthodox Church, both monks and nuns follow a similar ascetic discipline, and even their religious habit is the same (though nuns wear an extra veil, called the "apostolnik"). Unlike Roman Catholic monasticism, the Orthodox do not have separate religious orders, but a single monastic form throughout the Orthodox Church. Monastics, male or female, live away from the world, in order to pray for the world.
Monasteries vary from the very large to the very small. There are three types of monastic houses in the Orthodox Church:
One of the great centres of Orthodox monasticism is Mount Athos in Greece, which, like the Vatican State, is self-governing. It is located on an isolated peninsula approximately 20 mi long and 5 mi wide, and is administered by the heads of the 20 monasteries. Today the population of the Holy Mountain is around 2,200 men only and can only be visited by men with special permission granted by both the Greek government and the government of the Holy Mountain itself.
Oriental Orthodox Churches.
The Oriental Orthodox Churches, distinguished by their Miaphysite beliefs consist of the Armenian Apostolic Church, the Coptic Orthodox Church of Alexandria (whose Patriarch, is considered first among equals for the following churches), as well as the Ethiopian Orthodox Church, the Eritrean Orthodox Church, the Indian Orthodox Church, and the Syriac Orthodox Church of Antioch. The now extinct Caucasian Albanian Church also fell under this group.
The monasteries of St. Macarius ("Deir Abu Makaria") and St. Anthony ("Deir Mar Antonios") are the oldest monasteries in the world and under the patronage of the Patriarch of the Coptic Orthodox Church.
Other Christian communities.
The last years of the 18th century marked in the Christian Church the beginnings of growth of monasticism among Protestant denominations. The centrus of this movement was in the United States and Canada beginning with the Shaker Church, which was founded in England and then moved to the United States. In the 19th century many of these monastic societies were founded as Utopian communities based on the monastic model in many cases. Aside from the Shakers, there were the Amanna, the Anabaptists et al. Many did allow marriage but most had a policy of celibacy and communal life in which members shared all things communally and disavowed personal ownership.
In the 19th-century monasticism was revived in the Church of England, leading to the foundation of such institutions as the House of the Resurrection, Mirfield (Community of the Resurrection), Nashdom Abbey (Benedictine), Cleeve Priory (Community of the Glorious Ascension) and Ewell Monastery (Cistercian), Benedictine orders, Franciscan orders and the Orders of the Holy Cross, Order of St. Helena. Other Protestant Christian denominations also engage in monasticism, particularly Lutherans in Europe and North America. For example, the Benedictine order of the Holy Cross at St Augustine's House in Michigan is a Lutheran order of monks and there are Lutheran religious communities in Sweden and Germany. In the 1960s, experimental monastic groups were formed in which both men and women were members of the same house and also were permitted to be married and have children—these were operated on a communal form. The Jewish Kibutz is a form of monasticism operating on a communal basis.
Trends in Christian monasticism.
The number of dedicated monastics in any religion has waxed and waned due to many factors. There have been Christian monasteries such as "The Cappadocian Caves" that used to shelter upwards of 5,000 monks, or St Pantelaimon's Monastery on the Mount Athos in Greece, which has held up to 3,000 monks. Today those numbers have dwindled and the entire population of the "Holy Mountain" may be 2,000.
Some Orthodox monastic leaders that are critical of monasteries that are too large, arguing that they become institutions and lose the intensity of spiritual training that can better be achieved when an elder has only 2 or 3 disciples. On the Mount Athos there are areas such as the Skete of St Anne, which could be considered as monastic entities but are small "Sketes" (monastic houses containing one elder and 2 or 3 disciples) who come together in one church for services.
There is a growing Christian neo-monasticism, particularly among evangelical Christians. Established upon at least some of the customary monastic principles, they have attracted many who seek to live in relationship with other, or who seek to live in an intentionally focused lifestyle, such as a focus upon simplicity or pacifism. Some include rites, noviciate periods in which a newly interested person can test out living and sharing of resources, while others are more pragmatic, providing a sense of family in addition to a place to live in.
Hinduism.
From the times of the Vedas people following monastic ways of life have been in existence in the Indian sub-continent. In what is now called Hinduism, monks have existed for a long time, and with them, their respective monasteries, called mathas. Most famous among them are the chatur-amnaya mathas established by Adi Shankara which formed the nodal centres of under whose guidance the ancient Order of Vedantic monks were re-organised under ten names Dashanami Sampradaya, Ashta matha (Eight monasteries) of Udupi founded by Madhvacharya (Madhwa acharya) a dwaitha philosopher.
Sufism.
Islam prohibits monasticism which is referred to in the Quran as "an invention". However, the term "Sufi" is applied to Muslim mystics who, as a means of achieving union with Allah, adopted ascetic practices including wearing a garment made of coarse wool called "sf". The term "Sufism" comes from "sf" meaning the person, who wears "sf". But in the course of time, Sufi has come to designate all Muslim believers in mystic union.
In the roots of Sufi philosophy there are influences of neoplatonist and other philosophies. Many of the practices of Orthodox Christian hermits and desert-dwellers were imitated in Sufism's growth in the center of the former-Christian lands of the Middle East. Ascetic practices within the Sufi philosophy were also associated with Buddhism. The notion of purification (cleaning one's soul from all evil things and trying to reach Nirvana and to become immortal in Nirvana) plays an important role in Buddhism. The same idea shows itself in the belief of "fanaa" (union with God) in Sufi philosophy.

</doc>
<doc id="45857" url="http://en.wikipedia.org/wiki?curid=45857" title="Hurwitz polynomial">
Hurwitz polynomial

In mathematics, a Hurwitz polynomial, named after Adolf Hurwitz, is a polynomial whose coefficients are positive real numbers and whose roots (zeros) are located in the left half-plane of the complex plane or on the "jω" axis, that is, the real part of every root is zero or negative. The term is sometimes restricted to polynomials whose roots have real parts that are strictly negative, excluding the axis (i.e., a Hurwitz stable polynomial).
A polynomial function "P"("s") of a complex variable "s" is said to be Hurwitz if the following conditions are satisfied:
Hurwitz polynomials are important in control systems theory, because they represent the characteristic equations of stable linear systems. Whether a polynomial is Hurwitz can be determined by solving the equation to find the roots, or from the coefficients without solving the equation by the Routh–Hurwitz stability criterion.
Examples.
A simple example of a Hurwitz polynomial is the following:
The only real solution is −1, as it factors to
Properties.
For a polynomial to be Hurwitz, it is necessary but not sufficient that all of its coefficients be positive. A necessary and sufficient condition that a polynomial is Hurwitz is that it passes the Routh–Hurwitz stability criterion. A given polynomial can be efficiently tested to be Hurwitz or not by using the Routh continued fraction expansion technique.
The properties of Hurwitz polynomials are:

</doc>
<doc id="45858" url="http://en.wikipedia.org/wiki?curid=45858" title="Intellectual capital">
Intellectual capital

Intellectual capital is the combined value of its people (Human Capital), the value inherent in its relationships (Relational capital), and everything that is left when the people go home (Structural capital), of which Intellectual property is but one sub-component. The term became widely used in academia in an attempt to account for the value of intangible assets on company's balance sheets. A second branch that has survived in academia and was largely adopted in large corporations was focused on the recycling of knowledge via Knowledge management, It has since became more widely known in the context of assessing the wealth of organizations. A metric for its value is the amount by which the market value of a firm exceeds its tangible (physical and financial) assets minus liabilities. This contrasts with physical and financial forms of capital; all three make up the value of an enterprise. Measuring the real value and the total performance of intellectual capital's components is a critical part of running a company in the knowledge economy and Information Age. Understanding the intellectual capital in an enterprise allows leveraging of its intellectual assets. For a corporation, the result will optimize its stock price.
Classification.
Intellectual capital is normally classified as follows:
Exploitation.
For a business, translating the potential of its intellectual capital is crucial. Works that focus on the subset, namely the patents, copyrights, and trade secrets ignore the benefits of their use with the business. The term "intellectual capital" is not yet common; other terms include "intangible assets". In order to profit from intellectual capital, knowledge management has become a task for management. Often, intellectual capital, or at least rights to it, are moved off-shore for exploitation, which entails risks that are hard to value. The transfer of rights to intellectual capital to offshore subsidiaries is a major enabler of corporate tax avoidance.
Audit.
An intellectual capital audit is an audit of a company’s intellectual capital to monitor and oversee the intellectual capital of a firm in order to capitalize on intellectual capital already within the company, and to identify opportunities to increase the intellectual capital of the company.

</doc>
<doc id="45859" url="http://en.wikipedia.org/wiki?curid=45859" title="Corte, Haute-Corse">
Corte, Haute-Corse

Corte (] ; ], Corsican "Corti") is a commune in the Haute-Corse department of France on the island of Corsica. It is the fourth-largest commune in Corsica (after Ajaccio, Bastia, and Porto-Vecchio).
Administration.
Corte is a subprefecture of the Haute-Corse department.
History.
Corte was the capital of the Corsican independent state during the period of Pasquale Paoli.
During World War I, German prisoners of war were kept in the Citadel.
Sights.
Sites of interest include the Fortress ("A citadella"), the Museum of Corsica ("Museu di a Corsica"), and the University of Corsica ("Università di Corsica").
Transport.
National roads lead to Ajaccio and Bastia.
Corte is also linked to Ajaccio, Bastia and Calvi by the Chemin de fer de la Corse (Corsican Railway), and is served by trains running between Ajaccio and Calvi, and Ajaccio and Bastia.
Climate.
Corte has a mediterranean climate, sometimes alpine during the winter, with 52 summer days and 56 frost days.
Education.
Corte has become a major university town in Corsica since the Pasquale Paoli University opened up again in 1980s.
Personalities.
Corte was the birthplace of Joseph Bonaparte (1768–1844), the eldest brother of the French Emperor Napoleon I, who made him King of Naples (1806–1808) and Spain (1808–1813).

</doc>
<doc id="45862" url="http://en.wikipedia.org/wiki?curid=45862" title="Raster image processor">
Raster image processor

A raster image processor (RIP) is a component used in a printing system which produces a raster image also known as a bitmap. The bitmap is then sent to a printing device for output. The input may be a page description in a high-level page description language such as PostScript, Portable Document Format, XPS or another bitmap of higher or lower resolution than the output device. In the latter case, the RIP applies either smoothing or interpolation algorithms to the input bitmap to generate the output bitmap.
Raster image processing is the process and the means of turning vector digital information such as a PostScript file into a high-resolution raster image.
Originally RIPs were a rack of electronic hardware which received the page description via some interface (e.g. RS-232) and generated a "hardware bitmap output" which was used to enable or disable each pixel on a real-time output device such as an optical film recorder.
A RIP can be implemented either as a software component of an operating system or as a firmware program executed on a microprocessor inside a printer, though for high-end typesetting, standalone hardware RIPs are sometimes used. Ghostscript and GhostPCL are examples of software RIPs. Every PostScript printer contains a RIP in its firmware.
Earlier RIPs retained backward compatibility with photosetters so they supported the older languages. So, for example Linotype RIPs supported CORA (RIP30).
Stages of RIP.
A RIP chip is used in laser printers to communicate raster images to a laser.

</doc>
<doc id="45864" url="http://en.wikipedia.org/wiki?curid=45864" title="Giulio Racah">
Giulio Racah

Giulio (Yoel) Racah (Hebrew: ג'וליו (יואל) רקח‎; February 9, 1909 – August 28, 1965) was an Italian–Israeli physicist and mathematician.
Biography.
Born in Florence, Italy, he took his degree from the University there in 1930, and later studied in Rome with Enrico Fermi. In 1937 he was appointed Professor of Physics at the University of Pisa. In 1939, due to application of Anti-Jewish laws in Italy, Racah immigrated to the British Mandate of Palestine, and was appointed Professor of Theoretical Physics at the Hebrew University of Jerusalem, where he was later Dean of the Faculty of Sciences, and finally Rector and acting President. The physics institute at the Hebrew University is named "The Racah Institute of Physics".
In the Israeli War of Independence, Racah served as deputy commander of the Israeli forces defending Mount Scopus.
Racah's research was mainly in the fields of quantum physics and atomic spectroscopy. He first devised a systematic general procedure for classifying the energy levels of open shell atoms, which remains to this day the accepted technique for practical calculations of atomic structure. This formalism was described in a monograph coauthored by his cousin Ugo Fano ("Irreducible Tensorial Sets", 1959).
Racah died at the age of 56, apparently asphyxiated by gas from a faulty heater.
Awards.
In 1958, Racah was awarded the Israel Prize in exact sciences.
See also.
The crater Racah on the Moon is named after him.

</doc>
<doc id="45866" url="http://en.wikipedia.org/wiki?curid=45866" title="Amaya">
Amaya

Amaya may refer to:

</doc>
<doc id="45868" url="http://en.wikipedia.org/wiki?curid=45868" title="National Center for Supercomputing Applications">
National Center for Supercomputing Applications

National Center for Supercomputing Applications
 
The National Center for Supercomputing Applications (NCSA) is an American state-federal partnership to develop and deploy national-scale cyberinfrastructure that advances science and engineering. NCSA operates as a unit of the University of Illinois at Urbana-Champaign, 
and provides high-performance computing resources to researchers across the country. Support for NCSA comes from the National Science Foundation,
the state of Illinois, the University of Illinois, business and industry partners, and other federal agencies.
NCSA provides leading-edge computing, data storage, and visualization resources. NCSA computational and data environment implements a multi-architecture hardware strategy, deploying both clusters and shared memory systems to support high-end users and communities on the architectures best-suited to their requirements. Nearly 1,360 scientists, engineers and students used the computing and data systems at NCSA to support research in more than 830 projects.
NCSA is led by astrophysicist Ed Seidel.
History.
NCSA is one of the five original centers in the National Science Foundation's Supercomputer Centers Program.
Larry Smarr wrote a proposal to address the future needs of scientific research. Seven other University of Illinois professors joined as co-principal investigators, and many others provided descriptions of what could be accomplished if the proposal were accepted. Known as the Black Proposal (after the color of its cover), it was submitted to the NSF in 1983. It met the NSF's mandate and its contents immediately generated excitement. However, the NSF had no organization in place to support it, and the proposal itself did not contain a clearly defined home for its implementation.
The NSF established an Office of Scientific Computing in 1984 and, with strong congressional support, it quickly announced a national competition that would fund a set of supercomputer centers like the one described in the Black Proposal. 
The result was that four supercomputer centers would be chartered (Cornell, Illinois, Princeton, and San Diego), with a fifth (Pittsburgh) added later.
The Black Proposal was approved in 1985 and marked the foundation of NCSA, with $42,751,000 in funding from 1 January 1985 through 31 December 1989. This was also noteworthy in that the NSF's action of approving an unsolicited proposal was unprecedented. NCSA opened its doors in January 1986.
In 2007, NCSA was awarded a grant from the National Science Foundation to build "Blue Waters", a supercomputer capable of performing quadrillions of calculations per second, a level of performance known as petascale.
The Black Proposal.
The 'Black Proposal' was a short, ten-page proposal for the creation of a supercomputing center which eventually led to funding from the National Science Foundation (NSF) to create supercomputing centers, including the National Center for Supercomputing Applications (NCSA) at the University of Illinois. In this sense, the significant role played by the U.S. Government in funding the Center, and the first widely popular web browser (NCSA's Mosaic) cannot be denied.
The Black Proposal described the limitations on any scientific research that required computer capabilities, and it described a future world of productive scientific collaboration, centered on universal computer access, where technical limitations on scientific research would not exist. Significantly, it expressed a clear vision of how to get from the present to the future. The proposal was titled "A Center for Scientific and Engineering Supercomputing", and was ten pages long.
The proposal's vision of the computing future were then unusual or non-existent, but elements of it are now commonplace, such as visualization, workstations, high-speed I/O, data storage, software engineering, and close collaboration with the multi-disciplinary user community.
Modern readers of the Black Proposal may gain insight into a world that no longer exists. Today's computers are easy to use, and the web is omnipresent. Employees in high-tech endeavors are given supercomputer accounts simply because they are employees. Computers are universally available and can be used by almost anyone of any age, applicable to almost anything.
At the time the proposal was written, computers were available to almost no one. For scientists who needed computers in their research, access was difficult if available at all. The effect on research was crippling. Reading publications from that time gives no hint that scientists were required to learn the arcane technical details of whatever computer facilities were available to them, a time-consuming limitation on their research, and an exceedingly tedious distraction from their professional interests.
The implementation of the Black Proposal had a primary role in shaping the computer technology of today, and its impact on research (both scientific and otherwise) has been profound. The proposal's description of the leading edge of scientific research may be sobering, and the limitations on computer usage at major universities may be surprising. A comprehensive list of the world's supercomputers shows the best resources that were then available. The thrust of the proposal may seem obvious now, but was then novel.
The National Science Foundation announced funding for the supercomputer centers in 1985; 
the first supercomputer at NCSA came online in January 1986.
NCSA quickly came to the attention of the worldwide scientific community with the release of NCSA Telnet in 1986. A number of other tools followed, and like NCSA Telnet, all were made available to everyone at no cost. In 1993, NCSA released the Mosaic web browser, the first popular graphical Web browser, which played an important part in expanding the growth of the World Wide Web. NCSA Mosaic was written by Marc Andreessen and Eric Bina, who went on to develop the Netscape Web browser. Mosaic was later licensed to Spyglass, Inc. which provided the foundation for Internet Explorer. The server-complement was called NCSA HTTPd, which later became known as Apache HTTP Server.
Other notable contributions by NCSA were the black hole simulations supporting the development of LIGO in 1992, the tracking of the Hale-Bopp Comet in 1997, and the creation of a PlayStation 2 Cluster in 2003.
Facilities.
Initially, NCSA's administrative offices were in the Water Resources Building and employees were scattered across the campus. NCSA is now headquartered within its own building directly north of the Siebel Center for Computer Science, on the site of a former baseball field, Illini Field. NCSA's supercomputers are at the National Petascale Computing Facility.
Movies/Visualization.
NCSA's visualization department is internationally well-known. Donna Cox, leader of the Advanced Visualization Laboratory at NCSA and a professor in the School of Art and Design at the University of Illinois at Urbana-Champaign, and her team created thrilling visualizations for the Oscar-nominated IMAX film "Cosmic Voyage," the PBS NOVA episodes "Hunt for the Supertwister" and "Runaway Universe," as well as Discovery Channel documentaries and pieces for CNN and NBC Nightly News. Cox and NCSA worked with the American Museum of Natural History to produce high-resolution visualizations for the Hayden Planetarium's 2000 Millennium show, "Passport to the Universe," and for "The Search for Life: Are We Alone?" She produced visualizations for the Hayden's "Big Bang Theatre" and worked with the Denver Museum of Nature and Science to produce high-resolution data-driven visualizations of terabytes of scientific data for "Black Holes: The Other Side of Infinity," a digital dome program on black holes.
Private Business Partners.
Referred to as the Industrial Partners program when it began in 1986, NCSA's collaboration with major corporations ensured that its expertise and emerging technologies would be relevant to major challenges outside of the academic world, as those challenges arose. Business partners had no control over research or the disposition of its results, but they were well-situated to be early adopters of any benefits of the research. The program is now called the Private Sector Program.
Past and current business partners include:

</doc>
<doc id="45870" url="http://en.wikipedia.org/wiki?curid=45870" title="Ladin language">
Ladin language

Ladin ( or ; Ladin: "Ladin", Italian: "Ladino", German: "Ladinisch") is a Romance language consisting of a group of dialects (which some consider part of a unitary Rhaeto-Romance language) mainly spoken in the Dolomite Mountains in Northern Italy in South Tyrol, the Trentino and the province of Belluno. It presents connections with the Swiss Romansh and Friulian.
The precise extension of the Ladin language area is the subject of scholarly debates. A more narrow perspective includes only the dialects of the valleys around the Sella group, wider definitions comprise the dialects of adjacent valleys in the Province of Belluno and even dialects spoken in the northwestern Trentino.
A standard written variety of Ladin ("Ladin Dolomitan") has been developed by the Office for Ladin Language Planning as a common communication tool across the whole Ladin-speaking region, but it is not popular among Ladin speakers.
Ladin should not be confused with Ladino (also called Judeo-Spanish), which, although also Romance, is more closely tied to Spanish.
Geographic distribution.
Ladin is recognized as a minority language in 54 Italian municipalities belonging to the provinces of South Tyrol, Trentino and Belluno. It is not possible to assess the exact number of Ladin speakers, because only in the provinces of South Tyrol and Trentino are the inhabitants asked to identify their native language in the general census of the population, which takes place every ten years.
South Tyrol.
In the 2011 census, 20,548 inhabitants of South Tyrol declared Ladin as their native language. Ladin is an officially recognised language, taught in schools and used in public offices (in written as well as spoken form). The following municipalities of South Tyrol have a majority of Ladin speakers:
Trentino.
In the 2011 census, 18,550 inhabitants of Trentino declared Ladin as their native language. It is prevailing in the following municipalities of Trentino in the Fassa Valley, where Ladin is recognized as a minority language:
The Nones language in the Non Valley and the related Solandro language found in the Sole Valley are Gallo-Romance languages and often grouped together into a single linguistic unit due to their similarity. They are spoken in 38 municipalities, but have no official status. Their more precise classification is uncertain. Both dialects show a strong resemblance to Trentinian dialect and Eastern Lombard, and scholars debate whether they are Ladin dialects or not.
About 23% of the inhabitants from Val di Non and 1.5% from Val di Sole declared Ladin as their native language at the 2011 census. The number of Ladin speakers in those valleys amounts to 8,730, outnumbering the native speakers in the Fassa Valley. In order to stress the difference between the dialects in Non and Fassa valleys, it has been proposed to distinguish between "ladins dolomitiches" (Dolomitic Ladinians) and "ladins nonejes" (Non Valley Ladinians) at the next census.
Belluno.
As there is no linguistic census in Belluno, the number of Ladin speakers can only be estimated. Around 3000 speakers are estimated to live in the part of the province of Belluno that used to be a part of the County of Tyrol until 1918: Cortina d'Ampezzo, Colle Santa Lucia, Livinallongo del Col di Lana.
Provincial administration of Belluno has enacted to identify Ladin as a minority language in additional municipalities. Those are: Agordo, Alleghe, Auronzo di Cadore, Borca di Cadore, Calalzo di Cadore, Canale d'Agordo, Cencenighe Agordino, Cibiana di Cadore, Comelico Superiore, Danta di Cadore, Domegge di Cadore, Falcade, Forno di Zoldo, Gosaldo, La Valle Agordina, Lozzo di Cadore, Ospitale di Cadore, Perarolo di Cadore, Pieve di Cadore, Rivamonte Agordino, Rocca Pietore, San Nicolò di Comelico, San Pietro di Cadore, San Tomaso Agordino, San Vito di Cadore, Santo Stefano di Cadore, Selva di Cadore, Taibon Agordino, Vallada Agordina, Valle di Cadore, Vigo di Cadore, Vodo di Cadore, Voltago Agordino, Zoldo Alto, Zoppè di Cadore. Ladinity in the province of Belluno is more ethnic than linguistic. The varieties spoken by Ladin municipalities are Venetian alpine dialects, grammatically no different to those spoken in municipalities that did not declare themselves as Ladin. Their language is called "Ladino Bellunese".
All Ladin dialects spoken in Belluno, including those in the former Tyrolean territories, enjoy a varying degree of influence by Venetian.
History.
The name derives from Latin, because Ladin is originally a vulgar Latin language left over from the Romanized Alps. Ladin is often attributed to be a relic of vulgar Latin dialects associated with Rhaeto-Romance languages. Whether a proto-Romance language ever existed is controversially discussed amongst linguists and historians, a debate known as "Questione Ladina". Starting in the 6th century, the Bavarii started moving in from the north, while from the south Gallo-Italic languages started pushing in, which further shrank the original extent of the Ladin area. Only in the more remote mountain valleys did Ladin survive among the isolated populations.
Starting in the very early Middle Ages, the area was mostly ruled by the County of Tyrol or the Bishopric of Brixen, both belonging to the realms of the Austrian Habsburg rulers. The area of Cadore was under the rule of the Republic of Venice. During the period of the Holy Roman Empire of the German Nation and, after 1804, the Austrian Empire, the Ladins underwent a process of Germanization.
After the end of World War I in 1918, Italy annexed the southern part of Tyrol, including the Ladin areas. The Italian nationalist movement of the 19th and 20th centuries regarded Ladin as an "Italian dialect", a notion rejected by various Ladin exponents and associations, despite their having been counted as Italians by the Austrian authorities as well. The programme of Italianization, professed by fascists such as Ettore Tolomei and Benito Mussolini, added further pressure on the Ladin communities to subordinate their identities to Italian. This included changing Ladin place names into the Italian pronunciation according to Tolomei's "Prontuario dei nomi locali dell'Alto Adige".
Following the end of World War II, the Gruber-De Gasperi Agreement of 1946 between Austria and Italy introduced a level of autonomy for Trentino and South Tyrol, but did not include any provisions for the Ladin language. Only in the second autonomy statute for South Tyrol in 1972 was Ladin recognized as a partially official language.
Status.
Ladin is officially recognised in Trentino and South Tyrol by provincial and national law. Italy signed the European Charter for Regional or Minority Languages of 1991, but has not ratified it so far. The charter calls for minority rights to be respected and minority languages, to which Ladin belongs, to be appropriately protected and promoted. Starting in the 1990s, the Italian parliament and provincial assembly have passed laws and regulations protecting the Ladin language and culture. A cultural institute was founded to safeguard and educate in the language and culture. School curricula were adapted in order to teach in Ladin, and street signs are being changed to bilingual.
Ladin is recognized as a protected language also in the Province of Belluno in Veneto region according to State Law 482/1999. In comparison with South Tyrol and Trentino, the wishes of the Ladins have barely been addressed by the regional government. In a popular referendum in October 2007, the inhabitants of Cortina d'Ampezzo overwhelmingly voted to leave Veneto and return to South Tyrol. The redrawing of the provincial borders would return Cortina d'Ampezzo, Livinallongo del Col di Lana and Colle Santa Lucia to South Tyrol, to which they traditionally belonged when part of the County of Tyrol or the Bishopric of Brixen.
Although the Ladin communities are spread out over three neighbouring regions, the "Union Generala di Ladins dles Dolomites" is asking that they be reunited. The Ladin Autonomist Union and the Fassa Association run on a Ladin list and have sought more rights and autonomy for Ladin speakers. Ladins are also guaranteed political representations in the assemblies of Trentino and South Tyrol due to a reserved seats system.
In South Tyrol, in order to reach a fair allocation of jobs in public service, a system called "ethnic proportion" was established in the 1970s. Every ten years, when the general census of population takes place, each citizen has to identify with a linguistic group. The results determine how many potential positions in public service are allocated for each linguistic group. This has theoretically enabled Ladins to receive guaranteed representation in the South Tyrolean civil service according to their numbers.
The recognition of minority languages in Italy has been criticised since the implementation of the State Law 482/1999, especially due to alleged financial benefits. This applies also to Ladin language, especially in the province of Belluno.
Subdivisions.
A possible subdivision of Ladin language identifies six major groups.
Athesian Group of the Sella.
The dialects of the Athesian group (from the river Adige Basin) of the Sella are spoken in South Tyrol:
The South Tyrolean dialects are the ones which preserverd the original Ladin characteristics better than all others.
Trentinian Group of the Sella.
The following Ladin dialects are spoken in the Fassa Valley in Trentino:
82,8% of the inhabitants of Fassa Valley are natively Ladin speaking; the Ladin language in Fassa is influenced by Trentinian dialects.
Agordino Group of the Sella.
In the Province of Belluno the following dialects are considered as part of the Agordino group:
Ampezzan Group.
Spoken in Cortina d'Ampezzo ("Anpezo"), similar to Cadorino dialect.
Even in Valle di Zoldo (from Forno-Fôr upwards) there are elements of the Ampezzan Group.
Cadorino Group.
Spoken in Cadore and Comelico and best known as Cadorino dialect.
Nones and Solandro Group.
In Western Trentino, in Non Valley, Val di Sole, Val di Peio, Val di Rabbi and part of Val Rendena, detached from the dolomitic area, dialects are spoken that are often considered as Ladin language (Anaunic Ladin), but enjoy strong influences from Trentinian an Eastern Lombard dialects.
Sample texts.
Lord's Prayer.
The first part of the 'Lord's Prayer' in Standard Ladin, Latin and Italian for comparison:
Phonology of Standard Ladin.
Standard Ladin has the following phonemes:
Vowels.
The vowel phonemes of Standard Ladin are shown in the table below:
The [ɜ] vowel, spelled ⟨ë⟩, as in Urtijëi (  ), occurs in some local dialects but is not included in Standard Ladin.

</doc>
<doc id="45871" url="http://en.wikipedia.org/wiki?curid=45871" title="Loudspeaker">
Loudspeaker

A loudspeaker (or loud-speaker or speaker) is an electroacoustic transducer; a device which converts an electrical audio signal into a corresponding sound. The first crude loudspeakers were invented during the development of telephone systems in the late 1800s, but electronic amplification by vacuum tube beginning around 1912 made loudspeakers truly practical. By the 1920s they were used in radios, phonographs, public address systems and theatre sound systems for talking motion pictures.
The most widely-used type of speaker today is the dynamic speaker, invented in 1925 by Edward W. Kellogg and Chester W. Rice. The dynamic speaker operates on the same basic principle as a dynamic microphone, but in reverse, to produce sound from an electrical signal. When an alternating current electrical audio signal input is applied through the voice coil, a coil of wire suspended in a circular gap between the poles of a permanent magnet, the coil is forced to move rapidly back and forth due to Faraday's law of induction, which causes a diaphragm (usually conically shaped) attached to the coil to move back and forth, pushing on the air to create sound waves. Besides this most common method, there are several alternative technologies that can be used to convert an electrical signal into sound.
Speakers are typically housed in an enclosure which is often a rectangular or square box made of wood or sometimes plastic. Where high fidelity reproduction of sound is required, multiple loudspeakers may be mounted in the same enclosure, each reproducing a part of the audible frequency range "(picture at right)". In this case the individual speakers are referred to as "drivers" and the entire unit is called a loudspeaker. Miniature loudspeakers are found in devices such as radio and TV receivers, and many forms of music players. Larger loudspeaker systems are used for music, sound reinforcement in theatres and concerts, and in public address systems.
Terminology.
The term "loudspeaker" may refer to individual transducers (known as "drivers") or to complete speaker systems consisting of an enclosure including one or more drivers.
To adequately reproduce a wide range of frequencies with even coverage, most loudspeaker systems employ more than one driver, particularly for higher sound pressure level or maximum accuracy. Individual drivers are used to reproduce different frequency ranges. The drivers are named subwoofers (for very low frequencies); woofers (low frequencies); mid-range speakers (middle frequencies); tweeters (high frequencies); and sometimes supertweeters, optimized for the highest audible frequencies. The terms for different speaker drivers differ, depending on the application. In two-way systems there is no mid-range driver, so the task of reproducing the mid-range sounds falls upon the woofer and tweeter. Home stereos use the designation "tweeter" for the high frequency driver, while professional concert systems may designate them as "HF" or "highs". When multiple drivers are used in a system, a "filter network", called a crossover, separates the incoming signal into different frequency ranges and routes them to the appropriate driver. A loudspeaker system with "n" separate frequency bands is described as ""n"-way speakers": a two-way system will have a woofer and a tweeter; a three-way system employs a woofer, a mid-range, and a tweeter. Loudspeakers were described as "dynamic" to distinguish them from the earlier moving iron speaker, or speakers using piezoelectric or electrostatic systems as opposed to a voice coil that moves through a steady magnetic field.
History.
Johann Philipp Reis installed an electric loudspeaker in his "telephone" in 1861; it was capable of reproducing clear tones, but also could reproduce muffled speech after a few revisions. Alexander Graham Bell patented his first electric loudspeaker (capable of reproducing intelligible speech) as part of his telephone in 1876, which was followed in 1877 by an improved version from Ernst Siemens. During this time, Thomas Edison was issued a British patent for a system using compressed air as an amplifying mechanism for his early cylinder phonographs, but he ultimately settled for the familiar metal horn driven by a membrane attached to the stylus. In 1898, Horace Short patented a design for a loudspeaker driven by compressed air; he then sold the rights to Charles Parsons, who was issued several additional British patents before 1910. A few companies, including the Victor Talking Machine Company and Pathé, produced record players using compressed-air loudspeakers. However, these designs were significantly limited by their poor sound quality and their inability to reproduce sound at low volume. Variants of the system were used for public address applications, and more recently, other variations have been used to test space-equipment resistance to the very loud sound and vibration levels that the launching of rockets produces.
The modern design of moving-coil (also called "dynamic") drivers was established by Oliver Lodge in 1898. The first practical application of moving-coil loudspeakers was established by Danish engineer Peter L. Jensen and Edwin Pridham, in Napa, California. Jensen was denied patents. Being unsuccessful in selling their product to telephone companies, in 1915 they changed strategy to public address, and named their product Magnavox. Jensen was, for years after the invention of the loudspeaker, a part owner of The Magnavox Company.
The moving-coil principle commonly used today in direct radiators was patented in 1924 by Chester W. Rice and Edward W. Kellogg. The key difference between previous attempts and the patent by Rice and Kellogg is the adjustment of mechanical parameters so that the fundamental resonance of the moving system is below the frequency where the cone's radiation impedance becomes uniform.
About this same period, Walter H. Schottky invented the first ribbon loudspeaker together with Dr. Erwin Gerlach.
These first loudspeakers used electromagnets, because large, powerful permanent magnets were generally not available at a reasonable price. The coil of an electromagnet, called a field coil, was energized by current through a second pair of connections to the driver. This winding usually served a dual role, acting also as a choke coil, filtering the power supply of the amplifier that the loudspeaker was connected to. AC ripple in the current was attenuated by the action of passing through the choke coil. However, AC line frequencies tended to modulate the audio signal going to the voice coil and added to the audible hum.
In the 1930s, loudspeaker manufacturers began to combine two and three bandpasses' worth of drivers in order to increase frequency response and sound pressure level. In 1937, the first film industry-standard loudspeaker system, "The System for Theatres" (a two-way system), was introduced by Metro-Goldwyn-Mayer. It used four 15″ low-frequency drivers, a crossover network set for 375 Hz, and a single multi-cellular horn with two compression drivers providing the high frequencies. John Kenneth Hilliard, James Bullough Lansing, and Douglas Shearer all played roles in creating the system. At the 1939 New York World's Fair, a very large two-way public address system was mounted on a tower at Flushing Meadows. The eight 27″ low-frequency drivers were designed by Rudy Bozak in his role as chief engineer for Cinaudagraph. High-frequency drivers were likely made by Western Electric.
Altec Lansing introduced the "604", which became their most famous coaxial Duplex driver, in 1943. It incorporated a high-frequency horn that sent sound through the middle of a 15-inch woofer for near-point-source performance. Altec's "Voice of the Theatre" loudspeaker system arrived in the marketplace in 1945, offering better coherence and clarity at the high output levels necessary in movie theaters. The Academy of Motion Picture Arts and Sciences immediately began testing its sonic characteristics; they made it the film house industry standard in 1955. In 1954, Edgar Villchur developed the acoustic suspension principle of loudspeaker design in Cambridge, Massachusetts. This allowed for better bass response from loudspeakers mounted in smaller cabinets. He and his partner Henry Kloss formed the Acoustic Research company to manufacture and market speaker systems using this principle. Subsequently, continuous developments in enclosure design and materials led to significant audible improvements. The most notable improvements in modern speakers are improvements in cone materials, the introduction of higher-temperature adhesives, improved permanent magnet materials, improved measurement techniques, computer-aided design, and finite element analysis.
Driver design - Dynamic loudspeakers.
The most common type of driver, commonly called a dynamic loudspeaker, uses a lightweight diaphragm, or "cone", connected to a rigid "basket", or "frame", via a flexible suspension, commonly called a "spider", that constrains a voice coil to move axially through a cylindrical magnetic gap. When an electrical signal is applied to the voice coil, a magnetic field is created by the electric current in the voice coil, making it a variable electromagnet. The coil and the driver's magnetic system interact, generating a mechanical force that causes the coil (and thus, the attached cone) to move back and forth, thereby reproducing sound under the control of the applied electrical signal coming from the amplifier. The following is a description of the individual components of this type of loudspeaker.
The diaphragm is usually manufactured with a cone- or dome-shaped profile. A variety of different materials may be used, but the most common are paper, plastic, and metal. The ideal material would 1) be rigid, to prevent uncontrolled cone motions; 2) have low mass, to minimize starting force requirements and energy storage issues; 3) be well damped, to reduce vibrations continuing after the signal has stopped with little or no audible ringing due to its resonance frequency as determined by its usage. In practice, all three of these criteria cannot be met simultaneously using existing materials; thus, driver design involves trade-offs. For example, paper is light and typically well damped, but is not stiff; metal may be stiff and light, but it usually has poor damping; plastic can be light, but typically, the stiffer it is made, the poorer the damping. As a result, many cones are made of some sort of composite material. For example, a cone might be made of cellulose paper, into which some carbon fiber, Kevlar, glass, hemp or bamboo fibers have been added; or it might use a honeycomb sandwich construction; or a coating might be applied to it so as to provide additional stiffening or damping.
The chassis, frame, or basket, is designed to be rigid, avoiding deformation that could change critical alignments with the magnet gap, perhaps causing the voice coil to rub against the sides of the gap. Chassis are typically cast from aluminum alloy, or stamped from thin steel sheet, although molded plastic and damped plastic compound baskets are becoming common, especially for inexpensive, low-mass drivers. Metallic chassis can play an important role in conducting heat away from the voice coil; heating during operation changes resistance, causes physical dimensional changes, and if extreme, may even demagnetize permanent magnets.
The suspension system keeps the coil centered in the gap and provides a restoring (centering) force that returns the cone to a neutral position after moving. A typical suspension system consists of two parts: the "spider", which connects the diaphragm or voice coil to the frame and provides the majority of the restoring force, and the "surround", which helps center the coil/cone assembly and allows free pistonic motion aligned with the magnetic gap. The spider is usually made of a corrugated fabric disk, impregnated with a stiffening resin. The name comes from the shape of early suspensions, which were two concentric rings of Bakelite material, joined by six or eight curved "legs." Variations of this topology included the addition of a felt disc to provide a barrier to particles that might otherwise cause the voice coil to rub. The German firm Rulik still offers drivers with uncommon spiders made of wood.
The cone surround can be rubber or polyester foam, or a ring of corrugated, resin coated fabric; it is attached to both the outer diaphragm circumference and to the frame. These different surround materials, their shape and treatment can dramatically affect the acoustic output of a driver; each class and implementation having advantages and disadvantages. Polyester foam, for example, is lightweight and economical, but is degraded by exposure to ozone, UV light, humidity and elevated temperatures, limiting its useful life to about 15 years.
The wire in a voice coil is usually made of copper, though aluminum—and, rarely, silver—may be used. The advantage of aluminum is its light weight, which raises the resonant frequency of the voice coil and allows it to respond more easily to higher frequencies. A disadvantage of aluminum is that it is not easily soldered, and so connections are instead often crimped together and sealed. These connections can corrode and fail in time. Voice-coil wire cross sections can be circular, rectangular, or hexagonal, giving varying amounts of wire volume coverage in the magnetic gap space. The coil is oriented co-axially inside the gap; it moves back and forth within a small circular volume (a hole, slot, or groove) in the magnetic structure. The gap establishes a concentrated magnetic field between the two poles of a permanent magnet; the outside of the gap being one pole, and the center post (called the pole piece) being the other. The pole piece and backplate are often a single piece, called the poleplate or yoke.
Modern driver magnets are almost always permanent and made of ceramic, ferrite, Alnico, or, more recently, rare earth such as neodymium and samarium cobalt. A trend in design—due to increases in transportation costs and a desire for smaller, lighter devices (as in many home theater multi-speaker installations)—is the use of the last instead of heavier ferrite types. Very few manufacturers still produce electrodynamic loudspeakers with electrically powered field coils, as was common in the earliest designs. When high field-strength permanent magnets became available, Alnico, an alloy of aluminum, nickel, and cobalt became popular, since it dispensed with the power supply problems of field-coil drivers. Alnico was used almost exclusively until about 1980. Alnico magnets can be partially degaussed (i.e., demagnetized) by accidental 'pops' or 'clicks' caused by loose connections, especially if used with a high power amplifier. This damage can be reversed by "recharging" the magnet.
After 1980, most (but not quite all) driver manufacturers switched from Alnico to ferrite magnets, which are made from a mix of ceramic clay and fine particles of barium or strontium ferrite. Although the energy per kilogram of these ceramic magnets is lower than Alnico, it is substantially less expensive, allowing designers to use larger yet more economical magnets to achieve a given performance.
The size and type of magnet and details of the magnetic circuit differ, depending on design goals. For instance, the shape of the pole piece affects the magnetic interaction between the voice coil and the magnetic field, and is sometimes used to modify a driver's behavior. A "shorting ring", or Faraday loop, may be included as a thin copper cap fitted over the pole tip or as a heavy ring situated within the magnet-pole cavity. The benefits of this complication is reduced impedance at high frequencies, providing extended treble output, reduced harmonic distortion, and a reduction in the inductance modulation that typically accompanies large voice coil excursions. On the other hand, the copper cap requires a wider voice-coil gap, with increased magnetic reluctance; this reduces available flux, requiring a larger magnet for equivalent performance.
Driver design—including the particular way two or more drivers are combined in an enclosure to make a speaker system—is both an art and science. Adjusting a design to improve performance is done using some combination of magnetic, acoustic, mechanical, electrical, and material science theory, and tracked with high precision measurements, and with the observations of experienced listeners. A few of the issues speaker and driver designers must confront are distortion, radiation lobing, phase effects, off-axis response, and crossover complications. Designers can use an anechoic chamber to ensure the speaker can be measured independently of room effects, or any of several electronic techniques that, to some extent, substitute for such chambers. Some developers eschew anechoic chambers in favor of specific standardized room setups intended to simulate real-life listening conditions.
Fabrication of finished loudspeaker systems has become segmented, depending largely on price, shipping costs, and weight limitations. High-end speaker systems, which are typically heavier (and often larger) than economic shipping allows outside local regions, are usually made in their target market region and can cost $140,000 or more per pair. The lowest-priced speaker systems and most drivers are manufactured in China or other low-cost manufacturing locations.
Driver types.
Individual electrodynamic drivers provide optimal performance within a limited frequency range. Multiple drivers (e.g., subwoofers, woofers, mid-range drivers, and tweeters) are generally combined into a complete loudspeaker system to provide performance beyond that constraint.
Full-range drivers.
A full-range driver is a speaker designed to be used alone to reproduce an audio channel without the help of other drivers, and therefore must cover the entire audio frequency range. These drivers are small, typically 3 to in diameter to permit reasonable high frequency response, and carefully designed to give low-distortion output at low frequencies, though with reduced maximum output level. Full-range (or more accurately, wide-range) drivers are most commonly heard in public address systems, in televisions (although some models are suitable for hi-fi listening), small radios, intercoms, some computer speakers, etc. In hi-fi speaker systems, the use of wide-range drive units can avoid undesirable interactions between multiple drivers caused by non-coincident driver location or crossover network issues. Fans of wide-range driver hi-fi speaker systems claim a coherence of sound due to the single source and a resulting lack of interference, and likely also to the lack of crossover components. Detractors typically cite wide-range drivers' limited frequency response and modest output abilities (most especially at low frequencies), together with their requirement for large, elaborate, expensive enclosures—such as transmission lines, quarter wave resonators or horns—to approach optimum performance. With the advent of neodymium drivers, low cost quarter wave transmission lines are made possible and are increasingly made availably commercially.
Full-range drivers often employ an additional cone called a "whizzer": a small, light cone attached to the joint between the voice coil and the primary cone. The whizzer cone extends the high-frequency response of the driver and broadens its high frequency directivity, which would otherwise be greatly narrowed due to the outer diameter cone material failing to keep up with the central voice coil at higher frequencies. The main cone in a whizzer design is manufactured so as to flex more in the outer diameter than in the center. The result is that the main cone delivers low frequencies and the whizzer cone contributes most of the higher frequencies. Since the whizzer cone is smaller than the main diaphragm, output dispersion at high frequencies is improved relative to an equivalent single larger diaphragm.
Limited-range drivers, also used alone, are typically found in computers, toys, and clock radios. These drivers are less elaborate and less expensive than wide-range drivers, and they may be severely compromised to fit into very small mounting locations. In these applications, sound quality is a low priority. The human ear is remarkably tolerant of poor sound quality, and the distortion inherent in limited-range drivers may enhance their output at high frequencies, increasing clarity when listening to spoken word material.
Subwoofer.
A subwoofer is a woofer driver used only for the lowest part of the audio spectrum: typically below 200 Hz for consumer systems, below 100 Hz for professional live sound, and below 80 Hz in THX-approved systems. Because the intended range of frequencies is limited, subwoofer system design is usually simpler in many respects than for conventional loudspeakers, often consisting of a single driver enclosed in a suitable box or enclosure. Since sound in this frequency range can easily bend around corners by diffraction, the speaker aperture does not have to face the audience, and subwoofers are often mounted in the bottom of the enclosure facing the floor for convenience.
To accurately reproduce very low bass notes without unwanted resonances (typically from cabinet panels), subwoofer systems must be solidly constructed and properly braced; good speakers are typically quite heavy. Many subwoofer systems include power amplifiers and electronic subsonic (sub)-filters, with additional controls relevant to low-frequency reproduction. These variants are known as "active" or "powered" subwoofers. In contrast, "passive" subwoofers require external amplification. In typical installations, subwoofers are physically separated from the rest of the transducers. Because of propagation delay, their output is slightly out of phase with the rest of the sound. Consequently, a subwoofer's power amp should have a phase-delay adjustment (approximately 1 ms of delay is required for each additional foot of separation from the listener).
Woofer.
A woofer is a driver that reproduces low frequencies. The driver combines with the enclosure design to produce suitable low frequencies (see speaker enclosure for the design choices available). Some loudspeaker systems use a woofer for the lowest frequencies, sometimes well enough that a subwoofer is not needed. Additionally, some loudspeakers use the woofer to handle middle frequencies, eliminating the mid-range driver. This can be accomplished with the selection of a tweeter that can work low enough that, combined with a woofer that responds high enough, the two drivers add coherently in the middle frequencies.
Mid-range driver.
A mid-range speaker is a loudspeaker driver that reproduces middle frequencies. Mid-range driver diaphragms can be made of paper or composite materials, and can be direct radiation drivers (rather like smaller woofers) or they can be compression drivers (rather like some tweeter designs). If the mid-range driver is a direct radiator, it can be mounted on the front baffle of a loudspeaker enclosure, or, if a compression driver, mounted at the throat of a horn for added output level and control of radiation pattern.
Tweeter.
A tweeter is a high-frequency driver that reproduces the highest frequencies in a speaker system. A major problem in tweeter design is achieving wide angular sound coverage (off-axis response), since high frequency sound tends to leave the speaker in narrow beams. Soft-dome tweeters are widely found in home stereo systems, and horn-loaded compression drivers are common in professional sound reinforcement. Ribbon tweeters have gained popularity in recent years, as their output power has been increased to levels useful for professional sound reinforcement, and their output pattern is wide in the horizontal plane, a pattern that has convenient applications in concert sound.
Coaxial drivers.
A coaxial driver is a loudspeaker driver with two or several combined concentric drivers. Coaxial drivers have been produced by many companies, such as Altec, Tannoy, Pioneer, KEF, SEAS, B&C Speakers, BMS, Cabasse and Genelec.
<br style=clear:right>
Loudspeaker system design.
Crossover.
Used in multi-driver speaker systems, the crossover is a subsystem that separates the input signal into different frequency ranges suited to each driver. The drivers receive power only in their usable frequency range (the range they were designed for), thereby reducing distortion in the drivers and interference between them. No crossover can be perfect (i.e., absolute block at the edges of the passband, no amplitude variation within the passband, no phase changes across the frequency band boundaries the crossover establishes, ..), so this is an idealized description.
Crossovers can be "passive" or "active". A passive crossover is an electronic circuit that uses a combination of one or more resistors, inductors, or non-polar capacitors. These parts are formed into carefully designed networks and are most often placed between the full frequency-range power amplifier and the loudspeaker drivers to divide the amplifier's signal into the necessary frequency bands before being delivered to the individual drivers. Passive crossover circuits need no external power beyond the audio signal itself, but have disadvantages: high cost, large components (inductors and capacitors), limited ability to adjust the circuit as desired due to limited choice of high power level components, etc. They also cause substantial overall signal loss and a significant reduction in damping factor between the voice coil and the crossover. An active crossover is an electronic filter circuit that divides the signal into individual frequency bands "before" power amplification, thus requiring at least one power amplifier for each bandpass. Passive filtering may also be used in this way before power amplification, but it is an uncommon solution, being less flexible than active filtering. Any technique that uses crossover filtering followed by amplification is commonly known as bi-amping, tri-amping, quad-amping, and so on, depending on the minimum number of amplifier channels. Some loudspeaker designs use a combination of passive and active crossover filtering, such as a passive crossover between the mid- and high-frequency drivers and an active crossover between the low-frequency driver and the combined mid- and high frequencies.
Passive crossovers are commonly installed inside speaker boxes and are by far the most usual type of crossover for home and low-power use. In car audio systems, passive crossovers may be in a separate box, necessary to accommodate the size of the components used. Passive crossovers may be simple for low-order filtering, or complex to allow steep slopes such as 18 or 24 dB per octave. Passive crossovers can also be designed to compensate for undesired characteristics of driver, horn, or enclosure resonances, and can be tricky to implement, due to component interaction. Passive crossovers, like the driver units that they feed, have power handling limits, have insertion losses (10% is often claimed), and change the load seen by the amplifier. The changes are matters of concern for many in the hi-fi world. When high output levels are required, active crossovers may be preferable. Active crossovers may be simple circuits that emulate the response of a passive network, or may be more complex, allowing extensive audio adjustments. Some active crossovers, usually digital loudspeaker management systems, may include facilities for precise alignment of phase and time between frequency bands, equalization, and dynamics (compression and limiting) control.
Some hi-fi and professional loudspeaker systems now include an active crossover circuit as part of an onboard amplifier system. These speaker designs are identifiable by their need for AC power in addition to a signal cable from a pre-amplifier. This active topology may include driver protection circuits and other features of a digital loudspeaker management system. Powered speaker systems are common in computer sound (for a single listener) and, at the other end of the size spectrum, in modern concert sound systems, where their presence is significant and steadily increasing.
Enclosures.
Most loudspeaker systems consist of drivers mounted in an enclosure, or cabinet. The role of the enclosure is to prevent sound waves emanating from the back of a driver from interfering destructively with those from the front. The sound waves emitted from the back are 180° out of phase with those emitted forward, so without an enclosure they typically cause cancellations which significantly degrade the level and quality of sound at low frequencies.
The simplest driver mount is a flat panel (i.e., baffle) with the drivers mounted in holes in it. However, in this approach, sound frequencies with a wavelength longer than the baffle dimensions are canceled out, because the antiphase radiation from the rear of the cone interferes with the radiation from the front. With an infinitely large panel, this interference could be entirely prevented. A sufficiently large sealed box can approach this behavior.
Since panels of infinite dimensions are impossible, most enclosures function by containing the rear radiation from the moving diaphragm. A sealed enclosure prevents transmission of the sound emitted from the rear of the loudspeaker by confining the sound in a rigid and airtight box. Techniques used to reduce transmission of sound through the walls of the cabinet include thicker cabinet walls, lossy wall material, internal bracing, curved cabinet walls—or more rarely, visco-elastic materials (e.g., mineral-loaded bitumen) or thin lead sheeting applied to the interior enclosure walls.
However, a rigid enclosure reflects sound internally, which can then be transmitted back through the loudspeaker diaphragm—again resulting in degradation of sound quality. This can be reduced by internal absorption using absorptive materials (often called "damping"), such as glass wool, wool, or synthetic fiber batting, within the enclosure. The internal shape of the enclosure can also be designed to reduce this by reflecting sounds away from the loudspeaker diaphragm, where they may then be absorbed.
Other enclosure types alter the rear sound radiation so it can add constructively to the output from the front of the cone. Designs that do this (including "bass reflex", "passive radiator", "transmission line", etc.) are often used to extend the effective low-frequency response and increase low-frequency output of the driver.
To make the transition between drivers as seamless as possible, system designers have attempted to time-align (or phase adjust) the drivers by moving one or more driver mounting locations forward or back so that the acoustic center of each driver is in the same vertical plane. This may also involve tilting the face speaker back, providing a separate enclosure mounting for each driver, or (less commonly) using electronic techniques to achieve the same effect. These attempts have resulted in some unusual cabinet designs.
The speaker mounting scheme (including cabinets) can also cause diffraction, resulting in peaks and dips in the frequency response. The problem is usually greatest at higher frequencies, where wavelengths are similar to, or smaller than, cabinet dimensions. The effect can be minimized by rounding the front edges of the cabinet, curving the cabinet itself, using a smaller or narrower enclosure, choosing a strategic driver arrangement, using absorptive material around a driver, or some combination of these and other schemes.
Wiring connections.
Most loudspeakers use two wiring points to connect to the source of the signal (for example, to the audio amplifier or receiver). This is usually done using binding posts or spring clips on the back of the enclosure. If the wires for the left and right speakers (in a stereo setup) are not connected "in phase" with each other (the + and − connections on the speaker and amplifier should be connected + to + and − to −), the loudspeakers are out of phase. Given identical signals, motion in one cone is in the opposite direction of the other. This typically causes monophonic material in a stereo recording to be canceled out, reduced in level, and made more difficult to localize, all due to destructive interference of the sound waves. The cancellation effect is most noticeable at frequencies where the speakers are separated by a quarter wavelength or less; low frequencies are affected the most. This type of wiring error does not damage speakers, but is not optimal.
Wireless speakers.
Wireless speakers are very similar to traditional (wired) loudspeakers, but they receive audio signals using radio frequency (RF) waves rather than over audio cables. There is normally an amplifier integrated in the speaker's cabinet because the RF waves alone are not enough to drive the speaker. This integration of amplifier and loudspeaker is known as an active loudspeaker. Manufacturers of these loudspeakers design them to be as lightweight as possible while producing the maximum amount of audio output efficiency.
Wireless speakers still need power, so require a nearby AC power outlet, or possibly batteries. Only the wire to the amplifier is eliminated.
Specifications.
Speaker specifications generally include:
and optionally:
Electrical characteristics of dynamic loudspeakers.
The load that a driver presents to an amplifier consists of a complex electrical impedance—a combination of resistance and both capacitive and inductive reactance, which combines properties of the driver, its mechanical motion, the effects of crossover components (if any are in the signal path between amplifier and driver), and the effects of air loading on the driver as modified by the enclosure and its environment. Most amplifiers' output specifications are given at a specific power into an ideal resistive load; however, a loudspeaker does not have a constant resistance across its frequency range. Instead, the voice coil is inductive, the driver has mechanical resonances, the enclosure changes the driver's electrical and mechanical characteristics, and a passive crossover between the drivers and the amplifier contributes its own variations. The result is a load resistance that varies fairly widely with frequency, and usually a varying phase relationship between voltage and current as well, also changing with frequency. Some amplifiers can cope with the variation better than others can.
To make sound, a loudspeaker is driven by modulated electrical current (produced by an amplifier) that pass through a "speaker coil" which then (through inductance) magnetizes the coil, creating a magnetic field. The electrical current variations that pass through the speaker are thus converted to varying magnetic forces, which move the speaker diaphragm, which thus forces the driver to produce air motion that is similar to the original signal from the amplifier.
Electromechanical measurements.
Examples of typical measurements are: amplitude and phase characteristics vs. frequency; impulse response under one or more conditions (e.g., square waves, sine wave bursts, etc.); directivity vs. frequency (e.g., horizontally, vertically, spherically, etc.); harmonic and intermodulation distortion vs. sound pressure level (SPL) output, using any of several test signals; stored energy (i.e., ringing) at various frequencies; impedance vs. frequency; and small-signal vs. large-signal performance. Most of these measurements require sophisticated and often expensive equipment to perform, and also good judgment by the operator, but the raw sound pressure level output is rather easier to report and so is often the only specified value—sometimes in misleadingly exact terms. The sound pressure level (SPL) a loudspeaker produces is measured in decibels (dBspl).
Efficiency vs. sensitivity.
Loudspeaker efficiency is defined as the sound power output divided by the electrical power input. Most loudspeakers are inefficient transducers; only about 1% of the electrical energy sent by an amplifier to a typical home loudspeaker is converted to acoustic energy. The remainder is converted to heat, mostly in the voice coil and magnet assembly. The main reason for this is the difficulty of achieving proper impedance matching between the acoustic impedance of the drive unit and the air it radiates into. (At low frequencies, improving this match is the main purpose of speaker enclosure designs). The efficiency of loudspeaker drivers varies with frequency as well. For instance, the output of a woofer driver decreases as the input frequency decreases because of the increasingly poor match between air and the driver.
Driver ratings based on the SPL for a given input are called sensitivity ratings and are notionally similar to efficiency. Sensitivity is usually defined as so many decibels at 1 W electrical input, measured at 1 meter (except for headphones), often at a single frequency. The voltage used is often 2.83 VRMS, which is 1 watt into an 8 Ω (nominal) speaker impedance (approximately true for many speaker systems). Measurements taken with this reference are quoted as dB with 2.83 V @ 1 m.
The sound pressure output is measured at (or mathematically scaled to be equivalent to a measurement taken at) one meter from the loudspeaker and on-axis (directly in front of it), under the condition that the loudspeaker is radiating into an infinitely large space and mounted on an infinite baffle. Clearly then, sensitivity does not correlate precisely with efficiency, as it also depends on the directivity of the driver being tested and the acoustic environment in front of the actual loudspeaker. For example, a cheerleader's horn produces more sound output in the direction it is pointed by concentrating sound waves from the cheerleader in one direction, thus "focusing" them. The horn also improves impedance matching between the voice and the air, which produces more acoustic power for a given speaker power. In some cases, improved impedance matching (via careful enclosure design) lets the speaker produce more acoustic power.
A driver with a higher maximum power rating cannot necessarily be driven to louder levels than a lower-rated one, since sensitivity and power handling are largely independent properties. In the examples that follow, assume (for simplicity) that the drivers being compared have the same electrical impedance, are operated at the same frequency within both driver's respective pass bands, and that power compression and distortion are low. For the first example, a speaker 3 dB more sensitive than another produces double the sound power (is 3 dB louder) for the same power input. Thus, a 100 W driver ("A") rated at 92 dB for 1 W @ 1 m sensitivity puts out twice as much acoustic power as a 200 W driver ("B") rated at 89 dB for 1 W @ 1 m when both are driven with 100 W of input power. In this particular example, when driven at 100 W, speaker A produces the same SPL, or loudness as speaker B would produce with 200 W input. Thus, a 3 dB increase in sensitivity of the speaker means that it needs half the amplifier power to achieve a given SPL. This translates into a smaller, less complex power amplifier—and often, to reduced overall system cost.
It is typically not possible to combine high efficiency (especially at low frequencies) with compact enclosure size and adequate low frequency response. One can, for the most part, choose only two of the three parameters when designing a speaker system. So, for example, if extended low-frequency performance and small box size are important, one must accept low efficiency. This rule of thumb is sometimes called Hofmann's Iron Law (after J.A. Hofmann, the "H" in KLH).
Listening environment.
The interaction of a loudspeaker system with its environment is complex and is largely out of the loudspeaker designer's control. Most listening rooms present a more or less reflective environment, depending on size, shape, volume, and furnishings. This means the sound reaching a listener's ears consists not only of sound directly from the speaker system, but also the same sound delayed by traveling to and from (and being modified by) one or more surfaces. These reflected sound waves, when added to the direct sound, cause cancellation and addition at assorted frequencies (e.g., from resonant room modes), thus changing the timbre and character of the sound at the listener's ears. The human brain is very sensitive to small variations, including some of these, and this is part of the reason why a loudspeaker system sounds different at different listening positions or in different rooms.
A significant factor in the sound of a loudspeaker system is the amount of absorption and diffusion present in the environment. Clapping one's hands in a typical empty room, without draperies or carpet, produces a zippy, fluttery echo due both to a lack of absorption and to reverberation (that is, repeated echoes) from flat reflective walls, floor, and ceiling. The addition of hard surfaced furniture, wall hangings, shelving and even baroque plaster ceiling decoration changes the echoes, primarily because of diffusion caused by reflective objects with shapes and surfaces having sizes on the order of the sound wavelengths. This somewhat breaks up the simple reflections otherwise caused by bare flat surfaces, and spreads the reflected energy of an incident wave over a larger angle on reflection.
Placement.
In a typical rectangular listening room, the hard, parallel surfaces of the walls, floor and ceiling cause primary acoustic resonance nodes in each of the three dimensions: left-right, up-down and forward-backward. Furthermore, there are more complex resonance modes involving three, four, five and even all six boundary surfaces combining to create standing waves. Low frequencies excite these modes the most, since long wavelengths are not much affected by furniture compositions or placement. The mode spacing is critical, especially in small and medium size rooms like recording studios, home theaters and broadcast studios. The proximity of the loudspeakers to room boundaries affects how strongly the resonances are excited as well as affecting the relative strength at each frequency. The location of the listener is critical, too, as a position near a boundary can have a great effect on the perceived balance of frequencies. This is because standing wave patterns are most easily heard in these locations and at lower frequencies, below the Schroeder frequency – typically around 200–300 Hz, depending on room size.
Directivity.
Acousticians, in studying the radiation of sound sources have developed some concepts important to understanding how loudspeakers are perceived. The simplest possible radiating source is a point source, sometimes called a simple source. An ideal point source is an infinitesimally small point radiating sound. It may be easier to imagine a tiny pulsating sphere, uniformly increasing and decreasing in diameter, sending out sound waves in all directions equally, independent of frequency.
Any object radiating sound, including a loudspeaker system, can be thought of as being composed of combinations of such simple point sources. The radiation pattern of a combination of point sources is not the same as for a single source, but depends on the distance and orientation between the sources, the position relative to them from which the listener hears the combination, and the frequency of the sound involved. Using geometry and calculus, some simple combinations of sources are easily solved; others are not.
One simple combination is two simple sources separated by a distance and vibrating out of phase, one miniature sphere expanding while the other is contracting. The pair is known as a doublet, or dipole, and the radiation of this combination is similar to that of a very small dynamic loudspeaker operating without a baffle. The directivity of a dipole is a figure 8 shape with maximum output along a vector that connects the two sources and minimums to the sides when the observing point is equidistant from the two sources, where the sum of the positive and negative waves cancel each other. While most drivers are dipoles, depending on the enclosure to which they are attached, they may radiate as monopoles, dipoles (or bipoles). If mounted on a finite baffle, and these out of phase waves are allowed to interact, dipole peaks and nulls in the frequency response result. When the rear radiation is absorbed or trapped in a box, the diaphragm becomes a monopole radiator. Bipolar speakers, made by mounting in-phase monopoles (both moving out of or into the box in unison) on opposite sides of a box, are a method of approaching omnidirectional radiation patterns.
In real life, individual drivers are complex 3D shapes such as cones and domes, and they are placed on a baffle for various reasons. A mathematical expression for the directivity of a complex shape, based on modeling combinations of point sources, is usually not possible, but in the far field, the directivity of a loudspeaker with a circular diaphragm is close to that of a flat circular piston, so it can be used as an illustrative simplification for discussion. As a simple example of the mathematical physics involved, consider the following:
the formula for far field directivity of a flat circular piston in an infinite baffle is 
where , is the pressure on axis, is the piston radius, is the wavelength (i.e. ) is the angle off axis and is the Bessel function of the first kind.
A planar source radiates sound uniformly for low frequencies' wavelengths longer than the dimensions of the planar source, and as frequency increases, the sound from such a source focuses into an increasingly narrower angle. The smaller the driver, the higher the frequency where this narrowing of directivity occurs. Even if the diaphragm is not perfectly circular, this effect occurs such that larger sources are more directive. Several loudspeaker designs approximate this behavior. Most are electrostatic or planar magnetic designs.
Various manufacturers use different driver mounting arrangements to create a specific type of sound field in the space for which they are designed. The resulting radiation patterns may be intended to more closely simulate the way sound is produced by real instruments, or simply create a controlled energy distribution from the input signal (some using this approach are called monitors, as they are useful in checking the signal just recorded in a studio). An example of the first is a room corner system with many small drivers on the surface of a 1/8 sphere. A system design of this type was patented and produced commercially by Professor Amar Bose—the 2201. Later Bose models have deliberately emphasized production of both direct and reflected sound by the loudspeaker itself, regardless of its environment. The designs are controversial in high fidelity circles, but have proven commercially successful. Several other manufacturers' designs follow similar principles.
Directivity is an important issue because it affects the frequency balance of sound a listener hears, and also the interaction of the speaker system with the room and its contents. A very directed speaker (i.e., on an axis perpendicular to the speaker face) may result in a reverberant field lacking in high frequencies, giving the impression the speaker is deficient in treble even though it measures well on axis (e.g., "flat" across the entire frequency range). Speakers with very wide, or rapidly increasing directivity at high frequencies, can give the impression that there is too much treble (if the listener is on axis) or too little (if the listener is off axis). This is part of the reason why on-axis frequency response measurement is not a complete characterization of the sound of a given loudspeaker.
Other driver designs.
Other driver types that depart from the most commonly used direct radiating electro-dynamic driver mounted in an enclosure include:
Horn loudspeakers.
Horn loudspeakers are the oldest form of loudspeaker system. The use of horns as voice-amplifying megaphones dates at least to the 17th century, and horns were used in mechanical gramophones as early as 1857. Horn loudspeakers use a shaped waveguide in front of or behind the driver to increase the directivity of the loudspeaker and to transform a small diameter, high pressure condition at the driver cone surface to a large diameter, low pressure condition at the mouth of the horn. This increases the sensitivity of the loudspeaker and focuses the sound over a narrower area. The size of the throat, mouth, the length of the horn, as well as the area expansion rate along it must be carefully chosen to match the drive to properly provide this transforming function over a range of frequencies (every horn performs poorly outside its acoustic limits, at both high and low frequencies). The length and cross-sectional mouth area required to create a bass or sub-bass horn require a horn many feet long. 'Folded' horns can reduce the total size, but compel designers to make compromises and accept increased complication such as cost and construction. Some horn designs not only fold the low frequency horn, but use the walls in a room corner as an extension of the horn mouth. In the late 1940s, horns whose mouths took up much of a room wall were not unknown amongst hi-fi fans. Room sized installations became much less acceptable when two or more were required.
A horn loaded speaker can have a sensitivity as high as 110 dB at 2.83 volts (1 watt at 8 ohms) at 1 meter. This is a hundredfold increase in output compared to a speaker rated at 90 dB sensitivity, and is invaluable in applications where high sound levels are required or amplifier power is limited.
Piezoelectric speakers.
Piezoelectric speakers are frequently used as beepers in watches and other electronic devices, and are sometimes used as tweeters in less-expensive speaker systems, such as computer speakers and portable radios. Piezoelectric speakers have several advantages over conventional loudspeakers: they are resistant to overloads that would normally destroy most high frequency drivers, and they can be used without a crossover due to their electrical properties. There are also disadvantages: some amplifiers can oscillate when driving capacitive loads like most piezoelectrics, which results in distortion or damage to the amplifier. Additionally, their frequency response, in most cases, is inferior to that of other technologies. This is why they are generally used in single frequency (beeper) or non-critical applications.
Piezoelectric speakers can have extended high frequency output, and this is useful in some specialized circumstances; for instance, sonar applications in which piezoelectric variants are used as both output devices (generating underwater sound) and as input devices (acting as the sensing components of underwater microphones). They have advantages in these applications, not the least of which is simple and solid state construction that resists seawater better than a ribbon or cone based device would.
In 2013, Kyocera introduced piezoelectric ultra-thin medium-size film speakers with only 1 milimeter of thickness and 7 grams of weight for their 55" OLED televisions and they hope the speakers will also be used in PCs and tablets. Besides medium-size, there are also large and small sizes which can all produce relatively the same quality of sound and volume within 180 degrees. The highly responsive speaker material provides better clarity than traditional TV speakers.
Magnetostatic loudspeakers.
Instead of a voice coil driving a speaker cone, a magnetostatic speaker uses an array of metal strips bonded to a large film membrane. The magnetic field produced by signal current flowing through the strips interacts with the field of permanent bar magnets mounted behind them. The force produced moves the membrane and so the air in front of it. Typically, these designs are less efficient than conventional moving-coil speakers.
Magnetostrictive speakers.
Magnetostrictive transducers, based on magnetostriction, have been predominantly used as sonar ultrasonic sound wave radiators, but their use has spread also to audio speaker systems. Magnetostrictive speaker drivers have some special advantages: they can provide greater force (with smaller excursions) than other technologies; low excursion can avoid distortions from large excursion as in other designs; the magnetizing coil is stationary and therefore more easily cooled; they are robust because delicate suspensions and voice coils are not required. Magnetostrictive speaker modules have been produced by Fostex and FeONIC and subwoofer drivers have also been produced.
Electrostatic loudspeakers.
Electrostatic loudspeakers use a high voltage electric field (rather than a magnetic field) to drive a thin statically charged membrane. Because they are driven over the entire membrane surface rather than from a small voice coil, they ordinarily provide a more linear and lower-distortion motion than dynamic drivers. They also have a relatively narrow dispersion pattern that can make for precise sound-field positioning. However, their optimum listening area is small and they are not very efficient speakers. They have the disadvantage that the diaphragm excursion is severely limited because of practical construction limitations—the further apart the stators are positioned, the higher the voltage must be to achieve acceptable efficiency. This increases the tendency for electrical arcs as well as increasing the speaker's attraction of dust particles. Arcing remains a potential problem with current technologies, especially when the panels are allowed to collect dust or dirt and are driven with high signal levels.
Electrostatics are inherently dipole radiators and due to the thin flexible membrane are less suited for use in enclosures to reduce low frequency cancellation as with common cone drivers. Due to this and the low excursion capability, full range electrostatic loudspeakers are large by nature, and the bass rolls off at a frequency corresponding to a quarter wavelength of the narrowest panel dimension. To reduce the size of commercial products, they are sometimes used as a high frequency driver in combination with a conventional dynamic driver that handles the bass frequencies effectively.
Electrostatics are usually driven through a step-up transformer that multiplies the voltage swings produced by the power amplifier. This transformer also multiplies the capacitive load that is inherent in electrostatic transducers, which means the effective impedance presented to the power amplifiers varies widely by frequency. A speaker that is nominally 8 ohms may actually present a load of 1 ohm at higher frequencies, which is challenging to some amplifier designs.
Ribbon and planar magnetic loudspeakers.
A ribbon speaker consists of a thin metal-film ribbon suspended in a magnetic field. The electrical signal is applied to the ribbon, which moves with it to create the sound. The advantage of a ribbon driver is that the ribbon has very little mass; thus, it can accelerate very quickly, yielding very good high-frequency response. Ribbon loudspeakers are often very fragile—some can be torn by a strong gust of air. Most ribbon tweeters emit sound in a dipole pattern. A few have backings that limit the dipole radiation pattern. Above and below the ends of the more or less rectangular ribbon, there is less audible output due to phase cancellation, but the precise amount of directivity depends on ribbon length. Ribbon designs generally require exceptionally powerful magnets, which makes them costly to manufacture. Ribbons have a very low resistance that most amplifiers cannot drive directly. As a result, a step down transformer is typically used to increase the current through the ribbon. The amplifier "sees" a load that is the ribbon's resistance times the transformer turns ratio squared. The transformer must be carefully designed so that its frequency response and parasitic losses do not degrade the sound, further increasing cost and complication relative to conventional designs.
Planar magnetic speakers (having printed or embedded conductors on a flat diaphragm) are sometimes described as ribbons, but are not truly ribbon speakers. The term planar is generally reserved for speakers with roughly rectangular flat surfaces that radiate in a bipolar (i.e., front and back) manner. Planar magnetic speakers consist of a flexible membrane with a voice coil printed or mounted on it. The current flowing through the coil interacts with the magnetic field of carefully placed magnets on either side of the diaphragm, causing the membrane to vibrate more or less uniformly and without much bending or wrinkling. The driving force covers a large percentage of the membrane surface and reduces resonance problems inherent in coil-driven flat diaphragms.
Bending wave loudspeakers.
Bending wave transducers use a diaphragm that is intentionally flexible. The rigidity of the material increases from the center to the outside. Short wavelengths radiate primarily from the inner area, while longer waves reach the edge of the speaker. To prevent reflections from the outside back into the center, long waves are absorbed by a surrounding damper. Such transducers can cover a wide frequency range (80 Hz to 35,000 Hz) and have been promoted as being close to an ideal point sound source. This uncommon approach is being taken by only a very few manufacturers, in very different arrangements.
The Ohm Walsh loudspeakers use a unique driver designed by Lincoln Walsh, who had been a radar development engineer in WWII. He became interested in audio equipment design and his last project was a unique, one-way speaker using a single driver. The cone faced down into a sealed, airtight enclosure. Rather than move back-and-forth as conventional speakers do, the cone rippled and created sound in a manner known in RF electronics as a "transmission line". The new speaker created a cylindrical sound field. Lincoln Walsh died before his speaker was released to the public. The Ohm Acoustics firm has produced several loudspeaker models using the Walsh driver design since then.
The German firm, Manger, has designed and produced a bending wave driver that at first glance appears conventional. In fact, the round panel attached to the voice coil bends in a carefully controlled way to produce full range sound. Josef W. Manger was awarded with the "Diesel Medal" for extraordinary developments and inventions by the German institute of inventions.
Flat panel loudspeakers.
There have been many attempts to reduce the size of speaker systems, or alternatively to make them less obvious. One such attempt was the development of "exciter" transducer coils mounted to flat panels to act as sound sources, most accurately called exciter/panel drivers. These can then be made in a neutral color and hung on walls where they are less noticeable than many speakers, or can be deliberately painted with patterns, in which case they can function decoratively. There are two related problems with flat panel techniques: first, a flat panel is necessarily more flexible than a cone shape in the same material, and therefore moves as a single unit even less, and second, resonances in the panel are difficult to control, leading to considerable distortions. Some progress has been made using such lightweight, rigid, materials such as Styrofoam, and there have been several flat panel systems commercially produced in recent years.
Heil air motion transducers.
Oskar Heil invented the air motion transducer in the 1960s. In this approach, a pleated diaphragm is mounted in a magnetic field and forced to close and open under control of a music signal. Air is forced from between the pleats in accordance with the imposed signal, generating sound. The drivers are less fragile than ribbons and considerably more efficient (and able to produce higher absolute output levels) than ribbon, electrostatic, or planar magnetic tweeter designs.
ESS, a California manufacturer, licensed the design, employed Heil, and produced a range of speaker systems using his tweeters during the 1970s and 1980s. Lafayette Radio, a large US retail store chain, also sold speaker systems using such tweeters for a time. There are several manufacturers of these drivers (at least two in Germany—one of which produces a range of high-end professional speakers using tweeters and mid-range drivers based on the technology) and the drivers are increasingly used in professional audio. Martin Logan produces several AMT speakers in the US. GoldenEar Technologies incorporates them in its entire speaker line.
Plasma arc speakers.
Plasma arc loudspeakers use electrical plasma as a radiating element. Since plasma has minimal mass, but is charged and therefore can be manipulated by an electric field, the result is a very linear output at frequencies far higher than the audible range. Problems of maintenance and reliability for this approach tend to make it unsuitable for mass market use. In 1978 Alan E. Hill of the Air Force Weapons Laboratory in Albuquerque, NM, designed the Plasmatronics Hill Type I, a tweeter whose plasma was generated from helium gas. This avoided the ozone and nitrous oxide produced by RF decomposition of air in an earlier generation of plasma tweeters made by the pioneering DuKane Corporation, who produced the Ionovac (marketed as the Ionofane in the UK) during the 1950s. Currently, there remain a few manufacturers in Germany who use this design, and a do-it-yourself design has been published and has been available on the Internet.
A less expensive variation on this theme is the use of a flame for the driver, as flames contain ionized (electrically charged) gases.
Digital speakers.
Digital speakers have been the subject of experiments performed by Bell Labs as far back as the 1920s. The design is simple; each bit controls a driver, which is either fully 'on' or 'off'. Problems with this design have led manufacturers to abandon it as impractical for the present. First, for a reasonable number of bits (required for adequate sound reproduction quality), the physical size of a speaker system becomes very large. Secondly, due to inherent analog digital conversion problems, the effect of aliasing is unavoidable, so that the audio output is "reflected" at equal amplitude in the frequency domain, on the other side of the sampling frequency, causing an unacceptably high level of ultrasonics to accompany the desired output. No workable scheme has been found to adequately deal with this.
The term "digital" or "digital-ready" is often used for marketing purposes on speakers or headphones, but these systems are not digital in the sense described above. Rather, they are conventional speakers that can be used with digital sound sources (e.g., optical media, MP3 players, etc.), as can any conventional speaker.
Transparent ionic conduction speaker.
In 2013, a research team introduced Transparent ionic conduction speaker which a 2 layers transparent conductive gel and a layer of transparent rubber in between to make high voltage and high actuation work to reproduce good sound quality. The speaker is suitable for robotics, mobile computing and adaptive optics fields.
Thermoacoustic speakers.
In 2008, researchers of Tsinghua University demonstrated a thermoacoustic loudspeaker of carbon nanotube thin film, whose working mechanism is a thermoacoustic effect. Sound frequency electrical currents are used to periodically heat the CNT and thus result in sound generation in the surrounding air. The CNT thin film loudspeaker is transparent, stretchable and flexible.
In 2013, researchers of Tsinghua University further present a thermoacoustic earphone of carbon nanotube thin yarn and a thermoacoustic surface-mounted device. They are both fully integrated devices and compatible with Si-based semiconducting technology.

</doc>
<doc id="45873" url="http://en.wikipedia.org/wiki?curid=45873" title="Assured destruction">
Assured destruction

In military strategy, assured destruction is where behaviors or choices are deterred because they will lead to overwhelming punitive consequences. It was most often discussed as mutually assured destruction (MAD), assuming there are exactly two parties in the conflict. The concept of assured destruction occasionally arises also in the death penalty debate and biotechnology debate.
For an assured destruction strategy to be successful:
The examples of attempts to establish the conditions for assured destruction include:
When the concept of assured destruction is applied in the doctrine of law, it is often criticized by proponents of the restorative justice and transformative justice approaches, who point out that assured destruction doctrines are rarely implemented with rigor or integrity of due process. This contributes to the controversy of the death penalty debate. 
Psychologists, notably B. F. Skinner, are of the opinion that promises of punishment seem to play little or no role in deterrence of adult behavior.
Assured destruction tactics are not to be confused with "insurance" tactics such as retaliatory trade tariffs that are merely intended to compensate the aggrieved or to return conditions to the pre-existing "level playing field".

</doc>
<doc id="45876" url="http://en.wikipedia.org/wiki?curid=45876" title="Pre-emptive nuclear strike">
Pre-emptive nuclear strike

In nuclear strategy, a first strike is a preemptive surprise attack employing overwhelming force. First strike capability is a country's ability to defeat another nuclear power by destroying its arsenal to the point where the attacking country can survive the weakened retaliation while the opposing side is left unable to continue war. The preferred methodology is to attack the opponent's strategic nuclear weapon facilities (missile silos, submarine bases, bomber airfields), command and control sites, and storage depots first. The strategy is called counterforce.
Overview.
During the Cold War period, both superpowers, NATO and the Eastern Bloc, built massive nuclear arsenals, aimed, to a large extent, at each other. However, they were never used, as after a time, leaders on both sides of the Iron Curtain realized that global thermonuclear war would not be in either power's interest, as it would probably lead to the destruction of both sides, and possibly nuclear winter or other extinction level events. Therefore, at times, both sides refrained from deploying systems capable of unanswerable nuclear strikes against either side. However, in both nations, there were interests that benefited from the development and maintenance of first-strike weapons systems: what U.S. President Dwight Eisenhower termed the military-industrial complex; these forces encouraged the constant development of weapons systems of greater accuracy, power, and destruction. In addition, each side doubted the other side's commitment to not deploy first-strike weapons, or even in the event of their deployment, to not strike first. Some first-strike weapons were deployed; however like most nuclear weapons, they were never used.
Of the nuclear powers, only the People's Republic of China and the Republic of India have declarative, unqualified, unconditional no-first-use policies. In 1982, at a special session of the General Assembly of United Nations, the USSR pledged not to use nuclear weapons first, regardless of whether its opponents possessed nuclear weapons or not. This pledge was later abandoned by post-Soviet Russia to compensate the overwhelming conventional weapon superiority enjoyed by NATO. The United States has a partial, qualified no-first-use policy, stating that they will not use nuclear weapons against states that do not possess nuclear weapons or other weapons of mass destruction.
Large-scale missile defense systems are not first-strike weapons, but certain critics view them as first-strike enabling weapons. U.S. President Ronald Reagan's proposed Strategic Defense Initiative, if it had ever been deployed (and proven successful), would have undermined the fundamental premise of mutual assured destruction (the inevitable outcome of equal and unacceptable destruction for both sides in the event of nuclear war), removing the incentive for the US not to strike first.
These proposed defense systems, intended to lessen the risk of devastating nuclear war, would lead to it, according to these critics. Indeed, according to game theory, the side not building large-scale missile defenses would have an incentive to launch a pre-emptive first strike while such a strike could still get through.
Historical background.
"First-strike attack", the use of a nuclear first strike capability, was greatly feared during the Cold War between NATO and the Soviet Bloc. At various points, fear of a first strike attack existed on both sides. Misunderstood changes in posture and well understood changes in technology used by either side often led to speculation regarding the enemy's intentions.
1948-1961.
In the immediate aftermath of World War II, the leadership of the Soviet Union feared the United States would use its nuclear superiority to its advantage, as from 1945 to 1948 the U.S. was the only state possessing nuclear weapons. The USSR countered by rapidly developing their own nuclear weapons, surprising the US with their first test in 1949. In turn, the U.S. countered by developing the vastly more powerful thermonuclear weapon, testing their first hydrogen bomb in 1952 at Ivy Mike, but the USSR quickly countered by testing their own thermonuclear weapons, with a test in 1953 of a semi-thermonuclear weapon of the Sloika design, and in 1956, with the testing of Sakharov's Third Idea – equivalent to the Castle Bravo device. Meanwhile, tensions between the two nations rose as 1956 saw the suppression of Hungary by the Soviets; the U.S. and European nations drew certain conclusions from that event, while in the U.S., a powerful social backlash was afoot, prompted by Senator Joseph McCarthy, the House Un-American Activities Committee, and Julius and Ethel Rosenberg, two atomic spies. This atmosphere was further inflamed by the 1957 launch of Sputnik, which led to fears of Communists attacking from space, as well as concerns that if the Soviets could launch a device into orbit, they could equally cause a device to re-enter the atmosphere and impact any part of the planet. John F. Kennedy capitalized on this situation by emphasizing the Bomber gap and the Missile Gap, areas in which the Soviets were (inaccurately) perceived as leading the United States, while heated Soviet rhetoric, including Soviet Premier Nikita Khrushchev's famous threat that "We will bury you!" to Western ambassadors added to political pressure. The 1960 U-2 incident, involving Francis Gary Powers, as well as the Berlin Crisis, along with the test of the Tsar Bomba, escalated tensions still further.
Cuban Missile Crisis.
This escalating situation came to a head with the Cuban Missile Crisis of 1962. The arrival of Soviet missiles in Cuba was conducted by the Soviets on the rationale that the US already had nuclear missiles stationed in Turkey, as well as the desire by Fidel Castro to increase his power, his freedom of action, and to protect his government from US-initiated prejudicial resolution of ideological disputes through the use of military force, such as had been attempted during the Bay of Pigs Invasion in April 1961. During the crisis, Fidel Castro wrote Khrushchev a letter about the prospect that the "imperialists" would be "extremely dangerous" if they responded militarily to the Soviet stationing of nuclear missiles aimed at US territory, less than 90 miles away in Cuba. The following quotation from the letter suggests that Castro was calling for a Soviet first strike against the US if it responded militarily to the placement of nuclear missiles aimed at the US in Cuba:
The Cuban Missile Crisis resulted in Khrushchev publicly agreeing to remove the missiles from Cuba, while Kennedy secretly agreed to remove his country's missiles from Turkey. Both sides in the Cold War realized how close they came to nuclear war over Cuba, and decided to seek a reduction of tensions, resulting in US-Soviet détente for most of the 1960s and 1970s.
Nonetheless, this reduction of tensions only applied to the US and the USSR. Recently declassified interviews with high level former Soviet nuclear and military-industrial planners reveal that Fidel Castro continued to favour nuclear options, even during the later Cold War – according to former Soviet General Danilevich, "(...in the early 1980s...) Cuban leader Fidel Castro pressed the USSR to take a tougher line against the United States, including possible nuclear strikes. The Soviet Union, in response, sent experts to spell out for Castro the ecological consequences for Cuba of nuclear strikes on the United States. Castro, according to the General, was quickly convinced to the undesirability of such outcomes."
1970s/1980s.
However, tensions were inflamed again in the late 1970s and early 1980s with the Soviet invasion of Afghanistan, the Soviet deployment of the SS-20 Saber and the SS-18 Satan, and the decision of NATO to deploy the new Pershing II IRBM as well as the Tomahawk Ground Launched Cruise Missile, along with U.S. President Ronald Reagan's talk of 'limited' nuclear war. This increased Soviet fears that NATO was planning an attack. NATO's deployment of these missiles was a response to the Soviet deployment of the SS-20 Saber, which could hit most European NATO bases within minutes of launch. These mutual deployments led to a destabilizing strategic situation, which was exacerbated by malfunctioning U.S. and Soviet missile launch early warning systems, a Soviet intelligence gap that prevented the Soviets from getting a "read" on the strategic intentions of U.S. leaders, as well as inflammatory U.S. rhetoric combined with classical Soviet mistrust of the NATO powers. This culminated in a war scare that occurred during 1983 due to the inopportune timing of a NATO exercise called Able Archer, which was a simulation of a NATO nuclear attack on the Soviet Union; this exercise happened to occur during a massive Soviet intelligence mobilization called VRYAN, that was designed to discover intentions of NATO to initiate a nuclear first-strike. This poor timing drove the world very close to nuclear war, possibly even closer than the Cuban Missile Crisis over 20 years before.
Post-Cold War.
Subsequent events caused the fears of nuclear attack on both sides to diminish significantly, as the tensions between the superpowers decreased, and have remained—at least in nuclear terms—comparatively low. However, the present indicates that this might be changing. Relations between the two have recently fallen to new post–Cold War lows, and events have illustrated that the world may be heading back towards a more tense situation in terms of nuclear armament and use, possibly even to a first strike. Talk that has been characterized as "reckless" has been rife amongst certain U.S. politicians who favor the development of new nuclear weapons (such as through the Complex 2030 program) or new uses for old weapons, such as by using them as nuclear bunker busters, even against non-nuclear states. The military invasion of Iraq was seen by the Russian leadership as indicating potential U.S. disrespect for what the Russian leadership views as international law. The U.S. missile defense program has proven to be the primary persistent obstacle to better relations with Russia, which views the placement of U.S. missile defense systems in Eastern Europe for defense against "the Iranian threat" similarly to how the U.S. would view placement of Russian missile defense systems in, for example, Cuba, for Russian defense against "the insidious Asian". The assassination of a British citizen by alleged operatives of the Russian government using Polonium-210, a radioactive poison, as well as the alleged dioxin poisoning of the President of the Ukraine, has raised tensions between Russia and the West, with some commentators in Western nations regarding the poisonings as an indicator of the character and true intentions of the Kremlin. Western nations view Russian bellicosity and belligerence as having markedly increased as of late, with tests of new nuclear-capable missiles occurring on a regular basis, military conflicts with neighboring states, claims of a Russian "sphere of influence" on the perimeter of the old Soviet Union, the rise of ultra-nationalist "Putin Youth" groups, aggressive politicization of and threats of withdrawal of natural gas supplies to Europe should the Europeans not make certain policy concessions, and even threats of a nuclear first strike against Poland have been heard to be made by certain Russian generals.
Even with these developments, recent events in both nations have served to restrain rhetoric and action in the direction of strategic destabilization, and have encouraged the possibility of stabilizing developments. Both the US and Russia have suffered economic problems as a result of the recent economic crisis and both are seeking to retrench policies that are viewed as potentially costly or reckless between the two. Russia's military development is no longer backed and inflated by the record-high natural gas and oil prices that formerly allowed massive sums to be poured into military spending while US arms buildups are no longer encouraged by the previous Administration. Indeed, the correlation of forces and means between the two suggests the possibility of a potential reciprocal nuclear weapon drawdown to low levels consistent with minimum credible deterrence – and, beyond that – to ultimate levels comparable with the nuclear force levels of the other great powers – achievable within the next decade. Both nations have begun to realize the core truth of the post–Cold War era that, if the strategic reality, as described by the words of Ronald Reagan, is that "Nuclear war cannot be won and must not be fought", then large nuclear weapons stockpiles have no positive use, are expensive, and can lead to dangerous destabilization. The possibility of a peace with honor of strategic equals between Russia and the US may now be possible.
Still, strategic problems remain in other areas. Other nations have engaged in policies that are regarded as potentially destabilizing. Officials in the People's Republic of China recently tested an anti-satellite missile, leading to widespread international concern, as anti-satellite missiles are viewed as threats to nuclear-launch warning systems, which could facilitate a first strike; further, tensions amid the Chinese governments over Taiwan have been rife in recent years; in addition, the PRC is reportedly pursuing modernization of their nuclear forces. Israel has made threats of the use of weapons, including those of a non-conventional character, while the former administration in the U.S. has refused to "take options off the table" (including the "nuclear option"), in the nuclear dispute with Iran, which is widely viewed as pursuing a clandestine nuclear weapons program, and well known for their desire for the destruction of Israel (c.f. "The World Without Israel") and extreme dislike for the United States (c.f. regular political rallies in Tehran calling for "Death to America!"). The unpredictable North Korean government has tested (or, more likely, partially fizzled) a nuclear device, and has historically threatened to turn Seoul into a "sea of fire", or most recently, "ashes", in response to unspecified, but always imminent, U.S. or South Korean "aggression" against it. The foreign relations of Pakistan and India remain unstable, but are now exacerbated by the nuclear arsenals of both states, as well as the rise of political parties promoting Hindu nationalism in India, and the rise of al-Qaeda Islamism in Pakistan, as well as intercommunal strife—ranging from the demolition of a historic mosque by communal hooligans with worshipers inside to a terrorist assault on Hindu shrines—could set off a nuclear war.
Historical analysis.
Neither side sought nuclear conflict, even though it threatened to break out on multiple occasions. What both sides had, however, was a deep and continuing fear that the other nation was seeking to start a nuclear conflict, or, at least, thought such a conflict was "winnable" and would not be deterred by the threat of nuclear war. This led to both sides adopting aggressive, confrontational military and nuclear strategies that were misinterpreted and countered by the other side, furthering distrust. These strategies led to destabilization of the strategic situation to the point where the two major war scares of the Cold War occurred: the Cuban Missile Crisis and the Able Archer/VRYAN crisis. Though neither side intended to start a nuclear war, and, in fact, were extremely concerned about the possibility of it, neither side adopted strategies to calm things down, so sure were they of their adversaries' bad faith.
U.S. military strategy (at least in Europe) was confined to responses to potential Soviet aggression against NATO countries. Soviet military theory was dominated by the theory of the "deep operation" – a large-scale combined-arms offensive into enemy-held territory – rather than a nuclear offensive. Soviet conventional superiority, shown by the fact that the Soviet Union certainly was prepared for war in Europe, having massed armored, mechanized, artillery, and air forces poised along the Inner German and Czech borders, led by the dreaded Third Shock Army of the Soviet Union, caused NATO to consider the use of tactical nuclear weapons to stop the "steamroller" of the Red Army if they decided to take a drive through the Fulda Gap or an amble through the North German Plain. NATO's position changed in the 1970s and 1980s, in favor of trying to stop a Soviet offensive through the employment, at least initially, of a doctrine involving non-nuclear AirLand Battle to try to buy time to either throw back the invader or work out the issues at hand through diplomacy. Both sides, however, were willing to use nuclear weapons, if necessary, to not lose the war at hand. Although neither side was actively pursuing a first-strike policy—since the time of Khrushchev, the leaders of orthodox communism believed that "peaceful coexistence" with the "imperialist" powers was possible—both sides relied on military strategies that could have still caused a general nuclear war.
Ideological determinism also played a role. President Ronald Reagan of the United States, at least before the Able Archer/VRYAN crisis, believed that everybody, including the Soviet Union, was completely aware of the United States' good intentions, even when he bellicosely declared that the USSR was an "evil empire" and (more jokingly) that the "bombing begins in 5 minutes" while encouraging the military to conduct threatening exercises, such as sneaking a Carrier Battle Group through the GIUK Gap and sending nuclear-capable bombers towards the territory of the USSR. Chairman Yuri Andropov of the Soviet Union had similar, distorted views; he believed that the Western Allies, and the U.S., in particular, were fascist states, whose leaders had territorial designs against the Soviet Motherland on the scale of Napoleon, at the least, and Adolf Hitler, at the worst; in addition, to counter the "fascists", he incited his military-industrial complex to build weapons such as the SS-20 MIRV IRBM and the SS-18 Satan MIRV ICBM, which the NATO countries reasonably viewed as a Soviet sword against their throats, and caused reaction through development of equivalent or superior weapons systems.
When the superpowers drew close to the edge of the nuclear abyss during both the Cuban Missile Crisis and the Able Archer/VRYAN Crisis, they learned and grew from their mistakes and miscalculations that led them to be within view of mutual assured destruction. Andropov was followed as Soviet leader by Konstantin Chernenko, who in turn was followed by Mikhail Gorbachev, and Gorbachev brought a far less hostile, ideological, and reflexively skeptical approach to the relations between the superpowers, helping to build an atmosphere of trust between the two. Reagan had a figurative conversion on the road to Damascus regarding nuclear weapons and (especially) ICBMs following this crisis, discarding his preconceived notions of general Soviet bad faith, leading him to come full circle and famously declare that "Nuclear war cannot be won and must not be fought". These new attitudes on both sides nearly brought about the disarmament and destruction of ICBMs, long-range SLBMs, and, possibly even nuclear weapons themselves at a groundbreaking disarmament summit between Gorbachev and Reagan at Reykjavík in 1986. (The sticking point causing agreement to be unreachable was the SDI Program, just as missile defense continues to be a thorn in the side of the Russians today.) However, progress was made; the INF Treaty, the Conventional Forces in Europe Treaty, and the START Treaty could be said to be the result of the change in leaders and leaders' attitudes that the Able Archer/VRYAN crisis facilitated, just as the Non-Proliferation Treaty and the Partial Test Ban Treaty, as well as U.S.-Soviet détente, could be considered to be the sons and daughters of the Cuban Missile Crisis. Still, both crises were dangerous times catalyzed by dangerous political and military mistakes caused by dangerous policies instituted by leaders who let their fear get the better of their judgment and reasoning. Thankfully for those who lived, and those who now live, these mistakes never caused a first strike to come to pass.
Likely first strike weapons systems.
Because of the low accuracy (Circular error probable) of early generation Intercontinental ballistic missiles (and especially Submarine-launched ballistic missiles), counterforce strikes were initially only possible against very large, undefended targets like bomber airfields and naval bases. Later generation missiles with much improved accuracy made counterforce attacks against the opponent's hardened military facilities (like missile silos and command and control centers) possible. This is due to the inverse-square law, which predicts that the amount of energy dispersed from a single point release of energy (such as a thermonuclear blast) dissipates by the inverse of the square of distance from the single point of release. The result is that the power of a nuclear explosion to rupture hardened structures is greatly decreased by the distance from the impact point of the nuclear weapon. So a near-direct hit is generally necessary, as only diminishing returns are gained by increasing bomb power.
Anti-first-strike countermeasures.
According to the theory of nuclear deterrence and mutually assured destruction, full countervalue retaliation would be the likely fate for anyone who unleashed a first strike. So as to maintain credible deterrence, the nuclear-weapons states have taken measures to give their enemies reason to believe that a first strike would lead to unacceptable results.
The main strategy here relies on creating doubt among enemy strategists regarding nuclear capacity, weapons characteristics, facility and infrastructure vulnerability, early warning systems, intelligence penetration, strategic plans, and political will. In terms of military capabilities, the aim is to create the impression of the maximum possible force and survivability, leading the enemy to make increased estimates of the probability of a disabling counterstrike; while in terms of strategy and politics, the aim is to cause the enemy to believe that such a second strike would be forthcoming in the event of a nuclear attack.
Second strike.
One of the main reasons to deter first-strike, is the possibility that the victim of the first-strike will launch a retaliatory second-strike on the attacker.
Increasing SSBN deployment.
Nuclear-powered ballistic missile submarines (SSBNs) carrying submarine-launched ballistic missiles (SLBMs), commonly known as "boomers" in the US and "bombers" in the UK, are widely considered the most survivable component of the nuclear triad. The depths of the ocean are extremely large, and nuclear submarines are highly mobile, very quiet, have virtually unlimited range, and can generate their own oxygen and potable water; in essence, their undersea endurance is limited only by food supply. It is unlikely that any conceivable opponent of any nuclear power deploying ballistic missile submarines could locate and neutralize every ballistic missile submarine before it could launch a retaliatory strike, in the event of war. Therefore, to increase the percentage of nuclear forces surviving a first strike, a nation can simply increase SSBN deployment, as well as deployment of reliable communications links with SSBNs.
Hardening or mobilizing land-based nuclear assets.
In addition, land-based ICBM silos can be hardened. No missile launch facility can really defend against a direct nuclear hit, but a sufficiently hardened silo could defend against a near miss, especially if the detonation is not from a multimegaton thermonuclear weapon. In addition, ICBMs can be placed on road or rail-mobile launchers (RT-23 Molodets, RT-2PM2 Topol-M, DF-31, MGM-134 Midgetman), which can then be moved around; as an enemy has nothing fixed to aim at, this increases their survivability.
Increasing alert state and readiness.
The effectiveness of a first strike is contingent upon the aggressor's ability to immediately deplete its enemy's retaliatory capacity to a level that would make a second strike impossible, mitigable, or strategically undesirable. Intelligence and early warning systems increase the probability that the enemy will have the time to launch its own strike before its warmaking capacity has been significantly reduced, thus rendering a first strike pointless. Alert states such as DEFCON conditions, apart from serving a purpose in the internal management of a country's military, can have the effect of advising a potential aggressor that an escalation towards first strike has been detected, and therefore that effective retaliatory strikes could be made in the event of an attack.
Maintaining survivable C4ISTAR links.
Looking Glass, Nightwatch, and TACAMO are U.S. airborne nuclear command posts, and represent survivable communication links with U.S. nuclear forces. In the event of significant political-military tensions between the nuclear powers, they would take to the skies, and provide survivable communications in the event of enemy attack. They are capable of the full exercise of all available MAOs (Major Attack Options), as well as the full SIOP, in the event of a first strike, or the destruction of the NCA. They can directly initiate launch of all U.S. ICBMs via radio and satellite communication, signal SLBMs to launch, and send bombers on their strike missions. In addition to these airborne assets, the U.S. government has several command and control bunkers, the most famous of which is NORAD, tunneled a few thousand feet into the granite of Cheyenne Mountain Complex, outside of Colorado Springs, Colorado, which is believed to be capable of withstanding and continuing to operate after a nuclear direct hit. Other U.S. C4ISTAR bunkers include an installation called Site R, located at Raven Rock, Pennsylvania, which is believed to be the Pentagon's relocation site if Washington, D.C. is destroyed, as well as Mount Weather, in Virginia, which is believed to be the relocation site for top Executive Branch officials. The Greenbrier in West Virginia was once the site of the Supreme Court of the United States and Congress' relocation bunker; however, it is no longer a secret and is now a tourist attraction.
The Russians also have equivalent or superior capabilities in this area; they have a system called SPRN (СПРН), which is capable of detecting nuclear launches and providing early warning, so that any such strike would not be undetected until it is too late. But their unique and special capability can be found with their Dead Hand fail-deadly computerized nuclear release system, based at Mount Yamantaw in the Urals. Apparently, Dead Hand, named for either the Dead Man's Hand in poker, or the Dead Man's Switch in dangerous or deadly machinery, can be turned on in the event that the Russian leadership fears a nuclear attack. Allegedly, once Dead Hand is activated, if it detects a loss of communications with Moscow as well as nuclear detonations inside of Russian territory, it can give final authority for the release of nuclear weapons to military officers in a bunker under Mt. Yamantaw, who can then, if they so determine, launch Russia's arsenal. Mt. Yamantaw is believed to be able to withstand multiple direct nuclear detonations.
Decreasing tensions by mutual adoption of a minimum credible deterrent posture.
Instead of relying on sophisticated communications links and launch-on-warning postures, the French, British, and Chinese have chosen to assume different nuclear postures more suited to minimum credible deterrence, or the capability to inflict unacceptable losses so as to prevent the use of nuclear weapons against them, rather than pursuing types of nuclear weapons suitable to first-strike use.
The People's Republic of China is believed to pursue a minimum credible deterrent/second strike strategy with regards to the United States. This may or may not be true with regards to the PRC's stance vis a vis Russia, as the majority of Chinese nuclear platforms are non-intercontinental, and are deployed on the Russian-Chinese border. Unlike the relations of the United States and the PRC, the PRC and Russia have had military conflicts in the past. In recent years, the PRC has improved its early-warning systems and renovated certain of its platforms for intercontinental strike; this may be due to the U.S. missile defense system (it may not be, however). In general, it appears that the PRC's leaders do not greatly fear a first strike (due to their posture of merely inflicting unacceptable losses upon an adversary as opposed to the U.S./Russian policy of trying to "win" a nuclear war); in any event, the Chinese arsenal is considered sufficient to ensure that such a first strike would not go unavenged.
The United Kingdom and France possess sophisticated nuclear weapons platforms; however their nuclear strategies are minimum credible deterrent-based. Each possesses ballistic missile submarines armed with intercontinental submarine-launched ballistic missiles to ensure a devastating second strike retaliation anywhere in the world. France also possesses a number of nuclear capable fighter aircraft. Both countries' nuclear policies are believed to be that of effective deterrence towards a would be nuclear strike against themselves, NATO, European Union members and other allies.
Destabilizing role of land-based MIRVed ICBMs.
MIRVed land-based ICBMs are generally considered suitable for a first strike or a counterforce strike, due to:
Unlike a decapitation strike or a countervalue strike, a counterforce strike might result in a potentially more constrained retaliation. Though the Minuteman III of the mid-1960s was MIRVed with 3 warheads, heavily MIRVed vehicles threatened to upset the balance; these included the SS-18 Satan which was deployed in 1976, and was considered to threaten Minuteman III silos, which led some neoconservatives to conclude a Soviet first strike was being prepared for. This led to the development of the aforementioned Pershing II, the Trident I and Trident II, as well as the MX missile, and the B-1 Lancer.
MIRVed land-based ICBMs are considered destabilizing because they tend to put a premium on striking first. When a missile is MIRVed, it is able to carry many warheads (up to 8 in existing U.S. missiles, limited by New START, though Trident II is capable of carrying up to 12) and deliver them to separate targets. If it is assumed that each side has 100 missiles, with 5 warheads each, and further that each side has a 95 percent chance of neutralizing the opponent's missiles in their silos by firing 2 warheads at each silo, then the attacking side can reduce the enemy ICBM force from 100 missiles to about 5 by firing 40 missiles with 200 warheads, and keeping the rest of 60 missiles in reserve. As such, this type of weapon was intended to be banned under the START II agreement, however the START II agreement was never activated, and neither Russia nor the USA has adhered to the agreement.
Destabilizing role of missile defense.
Any defense system against nuclear missiles such as SDI will be more effective against limited numbers of missiles launched. At very small numbers of targets, each defensive asset will be able to take multiple shots at each warhead, and a high kill ratio could be achieved easily. As the number of targets increases, the defensive network becomes "saturated" as each asset must target and destroy more and more warheads in the same window of time. Eventually the system will reach a maximum number of targets destroyed and after this point all additional warheads will penetrate the defenses. This leads to several destabilizing effects.
First, a state that is not building similar defenses may be encouraged to attack before the system is in place, essentially starting the war while there is no clear advantage instead of waiting until they will be at a distinct disadvantage after the defenses are completed. Second, one of the easiest ways to counter any proposed defenses is to simply build more warheads and missiles, reaching that saturation point sooner and hitting targets through a strategy of attrition. Third, and most importantly, since defenses are more effective against small numbers of warheads, a nation with a defense system is actually encouraged to engage in a counterforce first strike. The smaller retaliatory strike is then more easily destroyed by the defense system than a full attack would be. This undermines the doctrine of MAD by discrediting a nation's ability to punish any aggressor with a lethal retaliatory second strike.

</doc>
<doc id="45877" url="http://en.wikipedia.org/wiki?curid=45877" title="Sigmoid">
Sigmoid

Sigmoid means resembling the lower-case Greek letter sigma (ς) or the Latin letter S. Specific uses include:

</doc>
<doc id="45879" url="http://en.wikipedia.org/wiki?curid=45879" title="Line printer">
Line printer

The line printer is an impact printer in which one line of text is printed at a time. They are mostly associated with unit record equipment and the early days of digital computing, but the technology is still in use. Print speeds of 600 lines-per-minute (approximately 10 pages per minute) were achieved in the 1950s, later increasing to as much as 1200 lpm. Line printers print a complete line at a time and have speeds in the range of 150 to 2500 lines per minute. The different types of line printers are drum printers and chain printers.
Designs.
Five principal designs existed:
Drum printer.
In a typical drum printer design, a fixed font character set is engraved onto the periphery of a number of print wheels, the number matching the number of columns (letters in a line) the printer could print. The wheels, joined to form a large drum (cylinder), spin at high speed and paper and an inked ribbon is stepped (moved) past the print position. As the desired character for each column passes the print position, a hammer strikes the paper from the rear and presses the paper against the ribbon and the drum, causing the desired character to be recorded on the continuous paper. Because the drum carrying the letterforms (characters) remains in constant motion, the strike-and-retreat action of the hammers had to be very fast. Typically, they were driven by voice coils mounted on the moving part of the hammer.
Often the character sequences are staggered around the drum, shifting with each column. This obviates the situation whereby all of the hammers fire simultaneously when printing a line that consists of the same character in all columns, such as a complete line of dashes ("----").
Lower-cost printers did not use a hammer for each column. Instead, a hammer was provided for every other column and the entire hammer bank was arranged to shift left and right, driven by another voice coil. For this style of printer, two complete revolutions of the character drum were required with one revolution being used to print all the "odd" columns and another revolution being used to print all of the "even" columns. But in this way, only half (plus one) the number of hammers, magnets, and the associated channels of drive electronics were required.
At least one low-cost printer, made by CDC, achieved the same end by moving the paper laterally while keeping the hammer bank at rest.
Dataproducts was a typical vendor of drum printers, often selling similar models with both a full set of hammers (and delivering, for example 600 lines-per-minute of output) and a half set of hammers (delivering 300 LPM).
Chain (train) printer.
Chain printers (also known as train printers) placed the type on moving bars (a horizontally-moving chain). As with the drum printer, as the correct character passed by each column, a hammer was fired from behind the paper. Compared to drum printers, chain printers had the advantage that the type chain could usually be changed by the operator. A further advantage was that vertical registration of characters in a line was much improved over drum printers, which needed extremely precise hammer timing to achieve a reasonably straight line of print. By selecting chains that had a smaller character set (for example, just numbers and a few punctuation marks), the printer could print much faster than if the chain contained the entire upper- and lower-case alphabet, numbers, and all special symbols. This was because, with many more instances of the numbers appearing in the chain, the time spent waiting for the correct character to "pass by" was greatly reduced. Common letters and symbols would appear more often on the chain, according to the frequency analysis of the likely input. It was also possible to play primitive tunes on these printers by timing the nonsense of the printout to the sequence on the chain, a rather primitive piano. IBM was probably the best-known chain printer manufacturer and the IBM 1403 is probably the most famous example of a chain printer.
Band printer.
Band printers are a variation of chain printers, where a thin steel band is used instead of a chain, with the characters embossed on the band. Again, a selection of different bands were generally available with a different mix of characters so a character set best matched to the characters commonly printed could be chosen. Dataproducts was a well known manufacturer of band printers, with their B300, B600, and B1000 range, the model number representing the lines per minute rate of the printer. (The B300 was effectively a B600 with only half the number of hammers—one per two character positions. The hammer bank moved back and forth one character position, requiring two goes to print all characters on each line.)
Bar printer.
Bar printers were similar to chain printers but were slower and less expensive. Rather than a chain moving continuously in one direction, the characters were on fingers mounted on a bar that moved left-to-right and then right-to-left in front of the paper. An example was the IBM 1443.
In all three designs, timing of the hammers (the so-called "flight time") was critical, and was adjustable as part of the servicing of the printer. For drum printers, incorrect timing of the hammer resulted in printed lines that wandered vertically, albeit with characters correctly aligned horizontally in their columns. For train and bar printers, incorrect timing of the hammers resulted in characters shifting horizontally, albeit on vertically-level printed lines.
Most drum, chain, and bar printers were capable of printing up to 132 columns, but a few designs could only print 80 columns and some other designs as many as 160 columns.
Comb printer.
Comb printers, also called line matrix printers, represent the fourth major design. These printers were a hybrid of dot matrix printing and line printing. In these printers, a comb of hammers printed a portion of a row of pixels at one time (for example, every eighth pixel). By shifting the comb back and forth slightly, the entire pixel row could be printed (continuing the example, in eight cycles). The paper then advanced and the next pixel row was printed. Because far less printhead motion was involved than in a conventional dot matrix printer, these printers were much faster than dot matrix printers and were competitive in speed with formed-character line printers while also being able to print dot-matrix graphics as well as variable-sized characters.
Printronix and TallyGenicom are well-known vendors of comb printers.
Because all of these printing methods were noisy, lineprinters of all designs were enclosed in sound-absorbing cases of varying sophistication.
Wheel printers.
In 1949 IBM introduced the IBM 407 Accounting Machine with a wheel print mechanism that could print 150 alphanumeric lines a minute. Each of the 120 print positions had its own type wheel which rotated under electromechanical control. Once all were in position, print hammers struck the wheels against a ribbon and the paper. The 407 or its wheel line printer mechanism was attached to a variety of early IBM computers, including the IBM 650, most members of the IBM 700/7000 series and the IBM 1130, the last introduced in 1965.
Paper (forms) handling.
All line printers used continuous form paper provided in boxes of continuous fan-fold forms rather than cut-sheets. The paper was usually perforated to tear into cut sheets if desired and was commonly printed with alternating white and light-green areas, allowing the reader to easily follow a line of text across the page. This was the iconic "green bar" or "music-ruled" form that dominated the early computer age. Pre-printed forms were also commonly used (for printing cheques, invoices, etc.). A common task for the system operator was to change from one paper form to another as one print job completed and another was to begin. Some lineprinters had covers that opened automatically when the printer required attention.
Standard "green bar" page sizes included portrait-format pages of 8½ × 11 inches, usually printed at 80 columns by 66 lines (at 6 lines per inch) or 88 lines (at 8 LPI), and landscape-format pages of 14 × 11 inches, usually printed at 132 columns by 66 or 88 lines. Also common were landscape-format pages of 14 × 8½ inches, allowing for 132 columns by 66 lines (at 8 LPI) on a more compact page.
These continuous forms were advanced through the printer by means of "tractors" (sprockets or sprocket belts). Depending on the sophistication of the printer, there might simply be two tractors at the top of the printer (pulling the paper) or tractors at the top and bottom (thereby maintaining paper tension within the printer). The horizontal position of the tractors was usually adjustable to accommodate different forms. The earliest printers by IBM used a hydraulic motor to move the forms. In later line printers, High-speed servomechanisms usually drove the tractors, allowing very rapid positioning of the paper, both for advancing line-by-line and slewing to the top of the next form. The faster line printers, of necessity, also used "stackers" to re-fold and stack the fan-fold forms as they emerged from the printer.
The high-speed motion of the paper often developed large electrostatic charges. Line printers frequently used a variety of discharge brushes and active (corona discharge-based) static eliminators to discharge these accumulated charges.
Many printers supported ASA carriage control characters which provided a limited degree of control over the paper, by specifying how far to advance the paper between printed lines. Various means of providing vertical tabulation were provided, ranging from a paper carriage control tape loop to fully electronic (software-controllable) tab simulation.
Origins.
Tabulators built by the U.S. Census Bureau for the 1910 census could print their results. Prior to that, tabulator operators had to write down totals from counter wheels onto tally sheets. IBM developed a series of printing accounting machines, beginning in 1920. The 285 Numeric Printing Tabulator could read 150 cards per minute. The 405, introduced in 1934, could print at 80 lines per minute. It had 88 type bars, one for each print position, with 43 alphanumeric bars on the left, followed by 45 numeric-only bars. The IBM 402 series, introduced after World War II, had a similar print arrangement and was used by IBM in early computing devices, including the IBM Card-Programmed Electronic Calculator.
An early drum printer was the "Potter Flying Typewriter", in 1952. "Instead of working laboriously, one character at a time, it prints whole lines at once, 300 lines per minute, on a paper band. ... Heart of the machine is a continuously spinning disk with the necessary letters and numbers on its rim. ... As the disk revolves, 80 electrically operated hammers tap the back of the paper against an inked ribbon in contact with the disk, thus printing the proper characters in the proper places on the line." 
Current applications.
While the limited character set, fixed character spacing, and relatively poor print quality make impact line printers unsuitable for correspondence, books, and other applications requiring high print quality, the technology is cost-effective and remains in limited use in a number of applications such as printing box labels, medium volume accounting and other large business applications.
The names of the codice_1 and codice_2 commands in Unix were derived from the term "line printer". Analogously, many other systems call their printing devices "LP", "LPT", or some similar variant, whether these devices are in fact line printers or other types of printers. These references served to distinguish formatted final output from normal interactive output from the system, which in many cases in line printer days was also printed on paper (as by a teletype) but not by a line printer. Lineprinters printed characters, letters and numbers line by line.

</doc>
<doc id="45882" url="http://en.wikipedia.org/wiki?curid=45882" title="Trento">
Trento

Trento ] (anglicized as Trent, local dialects: "Trènt"; German: "Trient") is an Italian city located in the Adige River valley in Trentino-Alto Adige/Südtirol. It is the capital of Trentino ("Tyrol" or "Welschtirol"). In the 16th century, the city was the location of the Council of Trent.
Trento is an educational, scientific, financial and political centre in Trentino-Alto Adige/Südtirol, in Tyrol and Northern Italy in general. The University of Trento ranks highly out of Italy's top 30 colleges, coming 1st in the Italian Ministry of Education, Universities and Research ranking, 2nd according to Census ranking and 5th in the "Il Sole 24 Ore" ranking of Italian universities. The city contains a picturesque Medieval and Renaissance historic centre, with ancient buildings such as Trento Cathedral and the Castello del Buonconsiglio.
Together with other Alpine towns Trento engages in the Alpine Town of the Year Association for the implementation of the Alpine Convention to achieve sustainable development in the Alpine Arc. 
Trento was awarded Alpine Town of the Year 2004.
Modern-day Trento is a cosmopolitan city, with highly developed and organized modern social services. The city often ranks extremely highly out of all 103 Italian cities for quality of life, standard of living, and business and job opportunities, coming 1st, 6th and 2nd respectively. Trento is also one of the nation's wealthiest and most prosperous, with its province being one of the richest in Italy, although poorer than its neighbours Lombardy and South Tyrol, with a GDP per capita of €29,500 and a GDP (nominal) of €14.878 billion.
Geography.
The township of Trento encompasses the town centre as well as many suburbs of extremely varied geographical and population conditions (from the industrial suburb of Gardolo, just north of the city, to tiny mountain hamlets on Monte Bondone). Various distinctive suburbs still retain their traditional identity of rural or mountain villages.
Trento lies in a wide glacial valley called the Adige valley just south of the Alps foothill range Dolomite Mountains, where the Fersina River and Avisio rivers join the Adige River (the second longest river in Italy). River Adige is one of the three main south-flowing Alpine rivers; its broadly curving course alongside Trento was straightened in 1850. The valley is surrounded by mountains, including Vigolana (2,150 m), Monte Bondone (2,181 m), Paganella (2,124 m), Marzola (1,747 m) and Monte Calisio (1,096 m). Nearby lakes include Lake Caldonazzo, Lake Levico, Lake Garda and Lake Toblino.
History.
The origins of this city on the river track to Bolzano and the low Alpine passes of Brenner and the Reschen Pass over the Alps are disputed. Some scholars maintain it was a Rhaetian settlement: the Adige area was however influenced by neighbouring populations, including the (Adriatic) Veneti, the Etruscans and the Gauls (a Celtic people). According to other theories, the latter did instead found the city during the fourth century BC.
Trento was conquered by the Romans in the late 1st century BC, after several clashes with the Rhaetian tribes. Before the Romans, Trent was a Celtic village. In reality, the name derives from "Trent", which is a tribute to the Celtic god of the waters (because of the river Adige). The Romans gave their settlement the name "Tridentum" and is a tribute to the Roman god Neptune (Tri Dentum, meaning 'Three Teeth' because of the three hills that surround the city: the "Doss Trent", "Sant'Agata" and "San Rocco"). The Latin name is the source of the adjective Tridentine. On the old townhall a Latin inscription is still visible: "Montes argentum mihi dant nomenque Tridentum" ("Mountains give me silver and the name of Trento"), attributed to Fra' Bartolomeo da Trento (died in 1251). Tridentum became an important stop on the Roman road that led from Verona to Innsbruck.
After the fall of the Western Roman Empire, the independent bishopric of Trento was ruled by Ostrogoths, Byzantines, Lombards and Franks, finally becoming part of the Holy Roman Empire. In 1027, Emperor Conrad II created the Prince-Bishops of Trento, who wielded both temporal and religious powers. In the following centuries, however, the sovereignty was divided between the Bishopric of Trent and the County of Tyrol (from 1363 part of the Habsburg monarchy). Around 1200, Trento became a mining center of some significance: silver was mined from the Monte Calisio - Khalisperg, and Prince-Bishop Federico Wanga issued the first mining code of the alpine region.
In the 14th century, the region of Trent was part of the Austrian rule. The dukes of Austria (Habsburg Family) were also the counts of Tyrol and dominated the region for six centuries (1918).
A dark episode in the history of Trento was the Trent blood libel. When a three-year-old Christian boy, Simonino, later known as Simon of Trent, disappeared in 1475 on the eve of Good Friday, the city's small Jewish community was accused of killing him and draining his blood for Jewish ritual purposes. Eight Jews were tortured and burned at the stake, and their families forced to convert to Christianity. The bishop of Trent, Johannes Hinderbach, had Simonino canonized and published the first book printed in Trent, "Story of a Christian Child Murdered at Trent," embellished with 12 woodcuts. In a governmental ceremony in the 1990s, Trent apologized to the Jewish community for this dark episode and unveiled a plaque commemorating the formal apology.
In the 16th century Trento became notable for the Council of Trent (1545–1563) which gave rise to the Counter-Reformation. The adjective "Tridentine" (as in "Tridentine Mass") literally means pertaining to Trento, but can also refer to that specific event. Among the notable prince bishops of this time were Bernardo Clesio (who ruled the city 1514-1539, and managed to steer the Council to Trento) and Cristoforo Madruzzo (who ruled in 1539-1567), both able European politicians and Renaissance humanists, who greatly expanded and embellished the city.
During this period, and as an expression of this Humanism, Trento was also known as the site of a Jewish printing press. In 1558 Cardinal Madruzzo granted the privilege of printing Hebrew books to Joseph Ottolengo, a German rabbi. The actual printer was Jacob Marcaria, a local physician; after his death in 1562 the activity of the press of Riva di Trento ceased. Altogether thirty-four works were published in the period 1558 to 1562, most of them bearing the coat of arms of Madruzzo.
Prince-bishops ruled Trento until the Napoleonic era, when it bounced around among various states. Under the reorganization of the Holy Roman Empire in 1802, the Bishopric was secularized and annexed to the Habsburg territories. The Treaty of Pressburg in 1805 ceded Trent to Bavaria, and the Treaty of Schönbrunn four years later gave it to Napoleon's Kingdom of Italy.
The population resisted French domination with gunfights. The resistance leader was Andreas Hofer. During his youth he lived in the Italian Tyrol, where he learned the Italian language. When Hofer recovered Trento for the Austrians (1809), he was welcomed with enthusiasm by the population of Trento. Approximately 4.000 Trentinian volunteers ("Sìzzeri" or "Schützen") died in battle against the French and Bavarian troops. In 1810 Hofer was captured and brought to Mantua, and was shot by French soldiers on the express order of Napoleon.
With Napoleon's defeat in 1814, Trento was again annexed by the Habsburg Empire. The church government was finally extinguished, Trento now being governed by the secular government of Tyrol. In the next decades Trento experienced a modernization of administration and economy with the first railroad in the Adige valley opening in 1859.
During the late 19th century, Trento and Trieste, cities with ethnic Italian majorities still belonging to the Austrians, became icons of the Italian irredentist movement. Benito Mussolini briefly joined the staff of a local newspaper in 1908, but he left the city because they could not create an anti-Italian group.
The nationalist cause led Italy into World War I. Damiano Chiesa and the deputy in the Austrian parliament Cesare Battisti were two well-known local irredentists who had joined the Italian army to fight against Austria-Hungary with the aim of bringing the territory of Trento into the new Kingdom of Italy. The two men were taken prisoners at the nearby southern front. They were put on trial for high treason and executed in the courtyard of Castello del Buonconsiglio.
The region was greatly affected during the war, and some of its fiercest battles were fought on the surrounding mountains. After World War I, Trento and its Italian-speaking province, along with Bolzano (Bozen) and the part of Tyrol that stretched south of the Alpine watershed (which was, in the main, German speaking), were annexed by Italy.
In 1943, Mussolini was deposed and Italy surrendered to the Allies, who had invaded southern Italy via Sicily. German troops promptly invaded northern Italy and the provinces of Trento, Belluno and South Tyrol became part of the Operation Zone of the Alpine Foothills, annexed to Greater Germany. Some German-speakers wanted revenge upon Italian-speakers living in the area, but were mostly prevented by the occupying Nazis, who still considered Mussolini head of the Italian Social Republic and wanted to preserve good relations with the Fascists. From November 1944 to April 1945, Trento was bombed as part of the so-called "Battle of the Brenner." War supplies from Germany to support the Gothic Line were for the most part routed through the rail line through the Brenner pass. Over 6,849 sorties were flown over targets from Verona to the Brenner Pass with 10,267 tons of bombs dropped. Parts of the city were hit by the Allied bombings, including the church of S. Maria Maggiore, the Church of the Annunciation and several bridges over the Adige river. In spite of the bombings, most of the medieval and renaissance town center was spared. It was finally liberated in 3 May 1945.
In 1947 Trento became the host of the Rally Stella Alpina.
Starting from the 1950s the region has enjoyed prosperous growth, thanks in part to its special autonomy from the central Italian government.
Society and economy.
The city owes much of its unique economy to its position along the main communication route between Italy and Northern Europe and to the Adige river which prior to its diversion in the mid-19th century ran through the center of the city. The Adige river was formerly a navigable river and one of the main commercial routes in the Alps. The original course of the river is now covered by the Via Torre Vanga, Via Torre Verde and the Via Alessandro Manzoni.
As late as the Second World War, Trento depended on wine-making and silk. The manufacturing industry installed in the post-war period has been mostly dismantled. Today Trento thrives on commerce, services, tourism, high-quality agriculture and food industry (including wine, fruit), as a research and conference center thanks to a small but renowned university 
and internationally renowned research centers such as Fondazione Bruno Kessler , active in both fundamental and applied research, the , the Centre for Computational and Systems Biology and ECT* , active in theoretical nuclear studies and part of FBK, and as logistics and transportation thoroughfare.
Valued pink and white porphyry is still excavated from some surrounding areas (Pila). This stone can be seen in many of Trento's buildings, both new and old.
The city has two long-running annual sporting events: the Giro al Sas (a 10 km professional road running competition) was first held in the city in 1907 and continues to the present, while the Giro del Trentino is an annual road cycling race which the city has hosted every year since 1963.
Politics.
The administrative elections of May 3, 2009 were won by a center-left coalition. Results are the following (only parties with more than 4% are listed):
Current mayor is Alessandro Andreatta, of the Partito Democratico, elected with 64.42% of the votes.
Main sights.
Although off the beaten path of mass tourism, Trento offers rather interesting monuments. Its architecture has a unique feel, with both Italian Renaissance and Germanic influences. The city center is small, and most Late-Medieval and Renaissance buildings have been restored to their original pastel colours and wooden balconies. Part of the medieval city walls is still visible in Piazza Fiera, along with a circular tower. Once, these walls encircled the whole town and were connected to the Castello del Buonconsiglio.
The main monuments of the city include:
Trento also sports modernist architecture, including the train station and the central post office, both by rationalist architect Angiolo Mazzoni. In particular, the train station (1934–36) is considered a landmark building of Italian railways architecture and combines many varieties of local stone with the most advanced building materials of the time: glass, reinforced concrete, metal. The post office was once decorated with colored windows by Fortunato Depero, but these were destroyed during bombings in World War II. Other buildings of that time include the Grand Hotel (by G. Lorenzi) with some guest rooms furnished with futurist furniture by Depero, and the "R. Sanzio" Primary School built in 1931–34 and designed by Adalberto Libera.
An aeronautical museum ("Museo dell'Aeronautica Gianni Caproni") is located in Mattarello, near Trento Airport.
The "Museo Tridentino di Scienze Naturali" (Trent Museum of Natural Sciences), a museum of natural history and science, is located in the city center.
Trento's surroundings are known for the mountain landscapes, and are the destination of both summer and winter tourism.
The , located on Monte Bondone in "Le Viote", was founded in 1938. Trento is also the venue of a 
Notable natives.
In addition to the aforementioned Bernardo Clesio and Cristoforo Madruzzo, Giacomo Aconzio was born in Trento. Kurt von Schuschnigg was born in Riva del Garda, in the Trentino region. Other notable natives of Trento include:
Transport.
The A22-E45 highway connects Trento to Verona and to Bolzano, Innsbruck and Munich.
Trento railway station, opened in 1859, forms part of the Brenner railway (Verona–Innsbruck), which is the main rail connection between Italy and Germany. The station is also a junction with the Valsugana railway, which connects Trento to Venice. Trento has several other railway stations, including Trento FTM railway station, terminus of the Trento-Malè-Marilleva railway (FTM).
Bus or train services operate to the main surrounding valleys: Fassa, Fiemme, Gudicarie, Non, Primiero, Rendena, Sole, Tesino, Valsugana.
The public transport network within the city consists of 20 bus lines operated by Trentino Trasporti and a funicular service to Sardagna. The various railway stations within Trento's city limits are integrated into the public transport network.
Demographics.
In 2007, there were 112,637 people residing in Trento, of whom 48% were male and 52% were female. Minors (children ages 18 and younger) totalled 18.01 percent of the population compared to pensioners who number 19.37 percent. This compares with the Italian average of 18.06 percent (minors) and 19.94 percent (pensioners). The average age of Trento residents is 41 compared to the Italian average of 42. In the five years between 2002 and 2007, the population of Trento grew by 5.72 percent, while Italy as a whole grew by 3.56 percent. The current birth rate of Trento is 9.61 births per 1,000 inhabitants compared to the Italian average of 9.45 births.
As of 2006, 92.68% of the population was Italian. The largest immigrant group came from other European countries (mostly Albania, Romania): 4.13%, North Africa: 1.08%, and the Americas: 0.85%.
Trento Informa (a magazine distributed by the "comune") reports that in 2011 there were 117,190 people residing in Trento, of whom 48.5% aged between 45 and 65. The average age was 43.1 years. 13,535 (11.5%) were foreigners.
International relations.
Twin towns - Sister cities.
Trento is twinned with:
Districts of Trento are twinned with:
"Frazioni".
Frazioni or subdivisions of Trento:

</doc>
<doc id="45883" url="http://en.wikipedia.org/wiki?curid=45883" title="Cathedral">
Cathedral

A cathedral (French "cathédrales" from Latin. "cathedra", "seat" from the Greek "kathedra" (καθέδρα), seat, bench, from "kata" "down" + "hedra" seat, base, chair) is a Christian church which contains the seat of a bishop, thus serving as the central church of a diocese, conference, or episcopate. The counterpart term for such a church in German is "Dom" from Latin "domus ecclesiae" or "domus episcopalis"; also Italian Duomo, Dutch "Domkerk" and cognates in many other European languages. Churches with the function of "cathedral" are specific to those Christian denominations with an episcopal hierarchy, such as the Roman Catholic, Anglican, Orthodox, and some Lutheran and Methodist churches. Church buildings embodying the functions of a cathedral first appear in Italy, Gaul, Spain and North Africa in the 4th century, but cathedrals did not become universal within the Western Catholic Church until the 12th century, by which time they had developed architectural forms, institutional structures and legal identities distinct from parish churches, monastic churches and episcopal residences.
In respect of the church buildings in the Greek Orthodox Church and Russian Orthodox Church, the English word "cathedral" commonly translates "Katholikon" and "Sobor" respectively, both terms having a meaning of "assembly"; but this title is also applied to monastic and other major churches without episcopal responsibilities. When the church at which an archbishop or "metropolitan" presides is specifically intended, the term "kathedrikos naos" (literally: "cathedral church") is used.
Following the Protestant Reformation, the Christian church in several parts of Western Europe, such as Scotland, the Netherlands, certain Swiss Cantons and parts of Germany, adopted a Presbyterian polity that did away with bishops altogether. Where ancient cathedral buildings in these lands are still in use for congregational worship, they generally retain the title and dignity of "cathedral", maintaining and developing distinct cathedral functions, but void of hierarchical supremacy. From the 16th century onwards, but especially since the 19th century, churches originating in Western Europe have undertaken vigorous programmes of missionary activity, leading to the founding of large numbers of new dioceses with associated cathedral establishments of varying forms in Asia, Africa, Australasia, Oceania and the Americas. In addition, both the Catholic Church and Orthodox churches have formed new dioceses within formerly Protestant lands for converts and migrant co-religionists. Consequently, it is not uncommon to find Christians in a single city being served by three or more cathedrals of differing denominations.
Where a parish church serves temporarily as the cathedral of a diocese, this is termed a Pro-cathedral. The cathedral church of an Archbishop or Metropolitan bishop is termed a "Metropolitan cathedral".
As cathedrals are often particularly impressive edifices, the term "cathedral" is often applied colloquially to any large and impressive church, regardless of whether it functions as a cathedral, such as the Crystal Cathedral in California or the Arctic Cathedral in Tromsø, Norway. Ironically the Crystal Cathedral was recently purchased by the Catholic Church and has since been converted into a genuine Cathedral.
Definition.
The word cathedral is derived from the Greek word cathedra ("seat" or "chair"), and refers to the presence and prominence of the bishop's or archbishop's chair or throne, raised above both clergy and laity, and originally located facing the congregation from behind the High Altar. In the ancient world the chair, on a raised dais, was the distinctive mark of a teacher or rhetor and thus symbolises the bishop's role as teacher. A raised throne within a basilican hall was also definitive for a Late Antique presiding magistrate; and so the "cathedra" also symbolises the bishop's role in governing his diocese.
The epsicopal throne embodies the principle that only a bishop makes a cathedral, and this still applies even in those churches that no longer have bishops, but retain cathedral dignity and functions in ancient churches over which bishops formerly presided. But the throne can also embody the principle that a cathedral makes a bishop; both specifically, in that the bishop is elected within the cathedral and is inaugurated by being enthroned within the cathedral by acclamation of clergy and laity; and also generally, in that the bishops' essential qualifications of regular prayer, higher learning and musical worship were for many centuries, primarily accessible through cathedral functions. In this there is a distinction between those church traditions, predominantly those of Orthodox Christianity but formerly also including Celtic churches in Ireland, Scotland and Wales, whose bishops came to be made in monasteries; and those church traditions whose bishops have tended predominantly to arise through the ranks of cathedral clergy.
History and organization.
Origins and characteristics of the first cathedrals.
The history of cathedrals starts in the year 313, when the emperor Constantine the Great personally adopted Christianity and initiated the Peace of the Church. Indeed, in strict terminology, there could not have been "cathedrals" before that date, as before the 4th century there were no Christian "cathedrae"; bishops were never seated when leading congregational worship, but instead presided standing on a raised platform or "pulpitum". In the third century, the phrase "ascending the platform", "ad pulpitum venire" becomes the standard term for Christian ordination. During the siege of Dura Europos in 256, a complete Christian house church, or "domus ecclesiae" was entombed in a defensive bank, surviving when excavated, in places to wall-top height. The Dura church had been converted out of a large urban courtyard house of standard form, in which two rooms had been knocked together to make an assembly hall, capable of holding 60-75 standing; while a tank had been inserted in a room on the opposite side of the courtyard as a baptistery, with rich wall paintings above it. The large room was indeed found to have a raised pulptum at one end, big enough for one person in turn to read, preach and preside from; but too low to have been surmounted by a throne, and too small to have contained an altar. Otherwise the large room had no decoration or distinctive features at all. 
In 269, soon after Dura fell to the Persian army, a body of clerics assembled a charge sheet against the bishop of Antioch, Paul of Samosata, in the form of an open letter. Amongst the accusations was that Paul, who had received the civil rank of "ducenarius" due to contacts in the imperial court, had improperly erected an enclosure, or "secretum", for himself in the church of Antioch; that within this enclosure he had erected a throne from which he presided in worship; and that he had trained a female choir to sing hymns of his own devising. These practices were all condemned as innovations, improperly importing the symbols of his secular Roman magistracy into church ritual; while presumptuously and blasphemously asserting that the person of the bishop in eucharistic worship is seated in the place of Christ himself. Still in a hundred years, all bishops in the Mediterranean world had cathedrals, all sat on thrones within an enclosed sanctuary space, and all had established trained choirs to enhance eucharistic worship.
The driving principle underlying this change was the acceptance by bishops, more or less willingly, of an imperial invitation to adopt and maintain the duties, dignity and insignia proper to a public magistrate. Characteristically a Roman magistrate presided from a raised throne in a large, richly decorated and aisled rectangular hall called a "basilica"; and now bishops would do the same. The earliest of these new basilican cathedrals of which substantial remains are still visible (and maybe amongst the very earliest to be built) is below the Cathedral of Aquileia on the northern tip of the Adriatic sea. Dated from a mosaic inscription between 313 and 319, the complex consisted of two parallel east-west aisled halls of similar size; with a third smaller north-south cross-hall connecting them, which has been interpreted as the presence hall of the "episcopium" or bishop's residence. The three halls create an open courtyard, in which was originally located a separate baptistery. Surviving from both large basilican halls are rich mosaic pavements showing (amongst other scenes) Jonah and the Whale, and a series of, mainly female, donor portraits. It appears that similar cathedrals of double-basilica and baptistry were soon afterwards erected in Milan, Trier and Pavia; but that subsequently single-basilican churches became the more common cathedral model.
Constantine's declaration of imperial favour towards Christianity transformed all aspects of Christian life in the Roman Empire. From being a minority religion, largely confined to urban areas and restricted social groupings, and subject to official hostility and occasional persecution; Christianity acquired greatly expanded numbers of potential adherents of all classes, initially still within city areas, but eventually extending out to the "pagus", the city's rural hinterland. The consequence was a radical expansion in the buildings, funding and personnel of associated Church establishments throughout the 4th century. The first cathedrals represent this expansion in material form.
Cathedral buildings.
The location and layout of the first cathedrals varied substantially from city to city, although most, as at Aquileia, tended to be sited within the city walls but away from the urban centre; but certain elements are almost always found.
The Basilica.
Basilican halls had previously been characteristic of major civic complexes and military headquarters buildings; but now became the standard structure for accommodating large Christian congregations. From now on, the term basilica denotes any substantial church building. These new basilicas were wholly different in scale from earlier Christian assembly halls, as they were also different in form from any Roman non-Christian temple or religious structure. The halls were longitudinal, aisled, and flooded with light from large clerestory windows. Floors and walls were richly decorated with mosaic and inlay – usually in abstract or floral patterns. The two original double basilicas at Aquileia had both been about 37m by 17m in size, but within 30 years one hall was quadrupled to 73m by 31m. This expanded basilica now demonstrated three additional features that became characteristic of early cathedrals; an enclosure at the eastern end of the church surrounding the altar; a "synthronos" east of the altar facing west, and consisting of a raised dais with a centrally place bishop's throne and benches either side for the clergy of his "familia"; and a paritioned off "narthex" at the western end into which "catechumens" would withdraw during the central act of the Eucharistic liturgy.
The Baptistery.
The baptistery in the Dura church was about 1m square and 1m deep; baptismal candidates could stand in it, but could not be immersed. In the new cathedrals, as had been the case before, only bishops baptised; and ceremonies were held not more than twice a year to allow for suitable periods of instruction. So baptisteries needed to be greatly increased in size, with associated accommodation to ensure privacy in undressing, anointing and redressing; and the baptismal tank, commonly octagonal, was now fully deep enough for total immersion, and wide enough to accommodate both the candidate and an assisting male or female deacon. Baptisteries commonly adopted centralised plan forms derived from funerary chapels; and are invariably separate from the congregational basilica.
The Episcopium.
No one lived in the house church at Dura; such residential facilities as the latrine and kitchen were removed in the conversion. But cathedral complexes always included an episcopal residence. Prominent amongst the charges that had been directed against Paul of Samosata had been his alleged over-familiarity with pious women. As was common, Paul had been married when elected bishop; and again, as was universally expected for a bishop, he had then ceased sexual contact with his wife and no longer cohabited with her. But his accusers charged that, by continuing to associate with other women (even without any indication of actual impropriety) he was creating an unacceptable potential for scandal. To avoid similar such occasions arising, it was necessary for the new cathedrals to create male-only living quarters for the bishop and his entire establishment; and since, in churches in the West, all presbyters and deacons were also expected to live apart from their wives after ordination, these living quarters, the "episcopium", were necessarily substantial in extent. In addition to eating and sleeping quarters for ordained boys and men, the episcopium also commonly provided private dining halls for the hospitality expected of the bishop's enhanced social status, a private oratory or chapel for the bishop, and often a bath house.
Cathedral Finances.
Just as the episcopal residence was integral within the complex of cathedral buildings, so too there was no distinction between episcopal, diocesan and cathedral property and endowments. In principle, all diocesan income was paid into a common fund, and divided into four fixed shares for each main area of expenditure; the Bishop himself; the cathedral clergy; the fabric and lighting of cathedral and city churches; and charitable donations. Many diocese already held substantial endowments, but income increased enormously with the Peace of the Church; partly due to imperial subsidies in kind, but mainly from private bequests and regular private benefactions (often called 'first fruits'); although at this date, tithe was never paid to the church. In addition, many individual landowners supported private chapels and oratories on their own property; and endowed independent charitable institutions, and eventually monasteries and nunneries too.
The bishop's share.
Augustine of Hippo estimated his personal income as being 20 times that of his father, a minor civil servant; and Augustine was by no means the wealthiest bishop in North Africa. But in accepting from Constantine the status of civil magistrates, bishops were now also committed to substantial expenditure to maintain their new style and status; and also to fulfil the associated duties, for instance in employing qualified legal assessors to support them when sitting as civil judges.
The clergy share.
All ordained clerics attached to the cathedral, both male and female, were paid through stipends from the general fund. This applied both to the clergy working directly within the cathedral itself, and also to the clergy, called "canonici" attached to churches founded by the bishop within the city. From the end of the 4th century, as the mission of the church extended more into rural areas, 'baptistery churches' were founded in more distant villages, so that rural populations could receive the bishop's baptism locally; and the clergy in these churches also counted as "canonici" and drew a regular stipend.
The fabric share.
Plentiful donor inscriptions show that most new church building programmes; mosaics, roofs, furnishings, were financed by private donations. The costs of maintenance and lighting, however, fell on the general fund. This also applied to the churches, known as "tituli", served directly by the bishop's clergy, generally also including any surviving house churches from the period before the Peace of the Church and the rural baptistery churches; but not to the chapels, called "parochiae", established by rural landowners for the convenience of their tenants. The bishop, in respect of his civil status, was expected to contribute to public works of general benefit; aqueducts, bridges, watercourses.
The charitable share.
In all cities, bishops dedicated substantial sums to the support of widows, orphans and the poor. Such donations had been a strong feature of the church in earlier centuries, but tended then to be specifically directed to the Christian needy. Now the charitable compass became general. Bishops were especially expected to take responsibility for raising ransom funds, where local persons had fallen captive. In addition, it was expected that each diocese would support a "xenodochium", a hostel for the homeless and strangers.
Cathedral Personnel.
Just as the status of the bishop was transfomed at the Peace of the Church; so too was that of the male clergy. With the bishop now resident in the "episcopium" the other male clergy came to be recognised as his formal "familia", in mark of which male clergy now received the tonsure by shaving of their heads; this being originally a Roman badge of adoption. The early church had recognised the orders of bishop, presbyter (priest) and deacon, but a range of minor orders had since grown up in addition; and all were tonsured. These orders now tended to be understood as clerical 'ranks', equivalent to those in the military, such that the male clergy are now often referred to as a "clerical militia". And as in the Roman military or civil service, promotion was expected to follow the pinciple of "cursus honorum", rising through the ranks, with the expectation that ideally, a minimum period would be served in each. The female orders of virgin, widow and (female) deacon remained explicitly outside the bishop's familia; and so they did not receive the tonsure and nor did they progress through the "cursus honorum". But all orders of cathedral clergy, male and female, increased dramatically in numbers. Around 540 Justinian ordered that the clerical payroll of Hagia Sophia should be strictly limited to 60 presbyters, 100 male deacons, 90 subdeacons, 110 lectors, 25 singers, 100 doorkeepers and 40 female deacons; 525 in all.
The Bishop.
Bishops were at the head of the local church; but not explicitly within the "cursus honorum", as appointment was by election from the local clergy and people. Not surprisingly, the clergy tended to favour appointment of bishops from within the ranks of cathedral presbyters; but local lay choice often tended rather to outsiders, either a spectacular holy man, hermit or ascetic; or otherwise a senior civil servant or diplomat, who might have favourable contacts to exploit at court. But most bishops came from the "curial" class, that is those holding the hereditary rank of decurion with the obligation to serve on the city council, as only persons of this class and above would be likely to have a full rhetorical education in Greek and Latin grammar; without which it was not possible for a boy raised with a knowledge only of Late Antique vernacular speech to express himself in approved classical linguistic forms.
The Presbyters; and Archpriest.
It was expected that the normal president at both the eucharist and at baptism would be the bishop; who would celebrate in the cathedral and in titular churches in turn. But in practice, the bishop needed deputies for eucharistic worship, and also for the Divine Office of daily prayer, and this duty fell to the presbyters. The bishop selected a senior presbyter as Archpriest, who acted as his official deputy in all ritual matters and as head of the familia. The Archpriest was also responsible for the cathedral grammar school. After the 5th century, there were no longer state-supported secular teachers of rhetoric and grammar in the West (other than in parts of Italy), and so the church would have to educate its own.
The male Deacons and Subdeacons; and Archdeacon.
Just as the presbyters deputised for the bishop in ritual matters, so the deacons deputised in administrative and financial matters, especially in the raising and delivering of charity. At the head of the diaconate was the archdeacon; the bishop's main deputy in managerial affairs. Originally inferior in rank to the archpriest, the archdeacon by the sixth century had established clear pre-eminence. Subdeacons assisted the deacons, but unlike them were allowed to marry after ordination; consequently many clerics stopped the cursus honorum at this point, and it was not unusual for a subdeacon to be elected bishop; and even Pope.
The Doorkeepers, Exorcists, Lectors and Acolytes; and Primicerius.
In practice, the first three of these orders tended to be given together, and were typically applied to boys as young as seven. These boy lectors were too young for the grammar school, but were valued as choristers, and so were included in the "Schola Cantorum" or choir school. Originally under the responsibility of the deacons, the organisation of choirs was reformed by Pope Gregory the Great, who introduced the office of "primicerius" or head cantor for this purpose. This proved a vital reform; as without any comprehensive system of musical notation, the only way that sacred music could be maintained and passed on was through professional choirs of sound musical training undertaking cathedral worship – and such skills are not guaranteed to be present in high-ranking ecclesiastics.
Women's orders: Virgins, Widows and female Deacons.
These orders had been of considerable importance in earlier centuries; but tended to be sidelined in cathedrals from the 4th century onwards. So long as adult baptism continued as a regular occurrence, female deacons would continue to be needed for that service; but otherwise the main factor maintaining these orders was a knock-on effect from the rule of continence applied to bishops, presbyters and deacons. When a man became ordained, and moved into the episcopium with the rest of the bishops "familia"; then there would usually also be a requirement for support to their mothers, wives and daughters; and the orders of widows and virgins respectively continued largely for this purpose.
Functions of the first cathedrals.
Notwithstanding wide differences over time in institutional structures and wider historical contexts; the key functions established for the first cathedrals have tended to remain as distinctive cathedral functions down the centuries; a regular cycle of choral prayer; providing a forum for civic leadership; a commitment to higher learning; and the promotion and dissemination of music.
Rule of the clergy.
Early Middle Ages: religious communities.
The history of the body of clergy attached to the cathedral church is obscure, and in each case local considerations affected its development, however the main features were more or less common to all.
Originally the bishop and cathedral clergy formed a kind of religious community, which, while not in the true sense a monastery, was nevertheless often called a "monasterium", the word not having the restricted meaning which it afterwards acquired. In this lies the reason for the apparent anomaly that churches like York Minster and Lincoln Cathedral, which never had any monks attached to them, have inherited the name of minster or monastery. In these early communities the clergy often lived apart in their own dwellings, and were not infrequently married.
In the 8th century Chrodegang, Bishop of Metz (743-766), compiled a code of rules for the clergy of the cathedral churches, which, though widely accepted in Germany and other parts of the continent, gained little acceptance in England.
According to Chrodegang's rule, the cathedral clergy were to live under a common roof, occupy a common dormitory and submit to the authority of a special officer. The rule of Chrodegang was, in fact, a modification of the Benedictine rule. Gisa, a native of Lorraine, who was bishop of Wells from 1061 to 1088, introduced it into England, and imposed its observance on the clergy of his cathedral church, but it was not followed for long there, or elsewhere in England.
Late Middle Ages: monastic and secular cathedrals.
During the 10th and 11th centuries, the cathedral clergy became more definitely organised and were divided into two classes. One was that of a monastic establishment of some recognised order of monks, often the Benedictines, while the other class was that of a college of clergy, bound by no vows except those of their ordination, but governed by a code of statutes or canons: hence the name of "canon". In this way arose the distinction between the monastic and secular cathedral churches. Outside Great Britain, monastic cathedrals are known only at Monreale in Sicily and Downpatrick in Ireland.
In the case of monastic cathedral churches, the internal government was that of the religious order to which the chapter belonged and all the members kept perpetual residence.
The alternative of this was the cathedral ruled by a secular chapter; the dignities of provost, dean, precentor, chancellor, treasurer, etc., came into being for the regulation and good order of the church and its services, while the non-residence of the canons, rather than their perpetual residence, became the rule, and led to their duties being performed by a body of "vicars", who officiated for them at the services of the church.
Reformation.
Prior to the Reformation all cathedrals of Western Europe were of the Roman Catholic Church. In England, much of the structure of the monastic and cathedral system was reconstituted during the English Reformation. Although the cathedrals were retained by the now independent and established Church of England, the monastic cathedral chapters were dissolved by King Henry VIII and, with the exceptions of Bath and Coventry, were refounded by him as chapters of canons with a dean as the head and other clergy as minor canons.
In Germany and other parts of Europe, with the spread of the Lutheran Church, some ancient churches, like Nidaros Cathedral, Norway, and Lübeck Cathedral, Germany, became the seats of Protestant bishops, as in England. Many new churches were built which serve the regional administrative function of a cathedral. However, not all churches that function as the seat of a bishop are known as "cathedral", the custom varying from place to place, according to local tradition. Some are simply designated "church", as occurs at Budolfi Church, the Lutheran cathedral of Aalborg in Denmark.
Roles within the cathedral.
Provost.
In most of Europe, the earliest head of a secular church seems to have been the provost ("praepositus", "probst", etc.), who was charged not only with the internal regulation of the church and oversight of the members of the chapter and control of the services, but was also the steward or seneschal of the lands and possessions of the church. The latter often mainly engaged his attention, to the neglect of his domestic and ecclesiastical duties, and complaints were soon raised that the provost was too much mixed in worldly affairs, and was too frequently absent from his spiritual duties.
This led, in many cases, to the institution of a new officer called the "dean", who had charge of that portion of the provost's duties which related to the internal discipline of the chapter and the services of the church.
In some cases, the office of provost was abolished, but in others it was continued: the provost, who was occasionally an archdeacon as well, remaining head of the chapter. This arrangement was most commonly followed in Germany. In England the provost was almost unknown. Bishop Gisa introduced a provost as head of the chapter of Wells Cathedral, but the office was afterwards subordinated to the other dignities and the provost became simply the steward of certain of the prebendal lands. The provost of the collegiate church of Beverley Minster was the most notable instance of such an officer in England, but at Beverley he was an external officer with authority in the government of the church, no stall in the choir and no vote in chapter.
In Germany and Scandinavia, and in a few of the cathedral churches in the south of France, the provost was the ordinary head of the cathedral chapter, but the office was not common elsewhere. As regards France, of 136 cathedral churches existing at the Revolution, 38 only, and those either on the borders of Germany or in the extreme south, had a provost as the head of the chapter. In others the provost existed as a subordinate officer. There were two provosts at Autun, and Lyon and Chartres had four each, all as subordinate officers.
Secular chapter.
The normal constitution of the chapter of a secular cathedral church comprised four dignitaries (there might be more), in addition to the canons. These are the dean, the precentor, the chancellor and the treasurer. These four dignitaries, occupying the four corner stalls in the choir, are called in many of the statutes the "quatuor majores personae" of the church.
Dean.
The role of dean (from "decanus") seems to have derived its designation from the Benedictine "dean" who had ten monks under his charge. The role of dean came into existence to supply the place of the provost in the internal management of the church and chapter. In England every secular cathedral church was headed by a dean who was originally elected by the chapter and confirmed in office by the bishop. The dean is president of the chapter, and within the cathedral has charge of the performance of the services, taking specified portions of them by statute on the principal festivals. The dean sits in the chief stall in the choir, which is usually at the west end of the south side.
Precentor.
Next to the dean (as a rule) is the precentor ("primicerius", "cantor", etc.), whose special duty is that of regulating the musical portion of the services. The precentor presides in the dean's absence, and occupies the corresponding stall on the north side, although there are exceptions to this rule, where, as at St Paul's, the archdeacon of the cathedral city ranks second and occupies what is usually the precentor's stall.
Chancellor.
The third dignitary is the chancellor ("scholasticus", "écoldtre", "capiscol", "magistral", etc.), who must not be confounded with the chancellor of the diocese. The chancellor of the cathedral church is charged with the oversight of its schools, ought to read divinity lectures, and superintend the lections in the choir and correct slovenly readers. The chancellor is often the secretary and librarian of the chapter. In the absence of the dean and precentor, the chancellor is president of the chapter, and within the cathedral is usually assigned the easternmost stall, on the dean's side of the choir.
Treasurer.
The fourth dignitary is the treasurer ("custo", "sacrisla", "cheficier") who is guardian of the fabric, and of all the furniture and ornaments of the church, and whose duty was to provide bread and wine for the Eucharist, and candles and incense. The treasurer also regulated such matters as the ringing of the bells. The treasurer's stall is opposite to that of the chancellor.
Additional clergy.
In many cathedral churches are additional dignitaries, as the praelector, subdean, vice-chancellor, succentor-canonicorum, and others, whose roles came into existence to supply the places of the other absent dignitaries, for non-residence was the fatal blot of the secular churches, and in this they contrasted very badly with the monastic churches, where all the members were in continuous residence. Besides the dignitaries there were the ordinary canons, each of whom, as a rule, held a separate prebend or endowment, besides receiving his share of the common funds of the church.
For the most part the canons also speedily became non-resident, and this led to the distinction of residentiary and non-residentiary canons, till in most churches the number of resident canons became definitely limited in number, and the non-residentiary canons, who no longer shared in the common funds, became generally known as prebendaries only, although by their non-residence they did not forfeit their position as canons, and retained their votes in chapter like the others.
This system of non-residence led also to the institution of vicars choral, each canon having his own vicar, who sat in his stall in his absence, and when the canon was present, in the stall immediately below, on the second form. The vicars had no place or vote in chapter, and, though irremovable except for offences, were the servants of their absent canons whose stalls they occupied, and whose duties they performed. Outside Britain they were often called demi-prebendaries. As time went on the vicars were themselves often incorporated as a kind of lesser chapter, or college, under the supervision of the dean and chapter.
Relationship of chapter and bishop.
There was no distinction between the monastic cathedral chapters and those of the secular canons, in their relation to the bishop or diocese. In both cases the chapter was the bishop's consilium which he was bound to consult on all important matters and without doing so he could not act. Thus, a judicial decision of a bishop needed the confirmation of the chapter before it could be enforced. He could not change the service books, or "use" of the church or diocese, without capitular consent, and there are episcopal acts, such as the appointment of a diocesan chancellor, or vicar general, which still need confirmation by the chapter, but the older theory of the chapter as the bishop's council in ruling the diocese has become a thing of the past, in Europe.
In its corporate capacity the chapter takes charge sede vacante of a diocese. In England, however (except as regards Salisbury and Durham), this custom has never obtained, the two archbishops having, from time immemorial, taken charge of the vacant dioceses in their respective provinces. When, however, either of the sees of Canterbury or York is vacant the chapters of those churches take charge, not only of the diocese, but of the province as well, and incidentally, therefore, of any of the dioceses of the province which may be vacant at the same time.
Functions of a cathedral.
The role of the cathedral is chiefly to serve God in the community, through its hierarchical and organisational position in the church structure. The building itself, by its physical presence, symbolises both the glory of God and of the church. A cathedral, its bishop and dignitaries have traditional functions which are mostly religious in nature, but may also be closely associated with the civil and communal life of the city and region.
Symbolic functions of the cathedral building.
The cathedral is frequently the most imposing building, and one of the most ancient buildings in its town. The great size and splendor of the cathedral may be out of all proportion to the town itself. The money and talents expended on the building are seen as honoring God, and may also demonstrate both the devotion and the status of the patrons.
Cathedrals are very often oriented east/west, so that the worshipers look towards the rising sun, symbolizing the Risen Christ. The architectural form of the building most frequently has the ground plan of a cross. This form is both functional and symbolic, its symbolism referring to the cross on which Jesus was crucified. The form is liturgically functional as it allows the building to be divided into sections where different activities take place, or that are occupied by different people, such as the clergy, the choir and the laity.
The main body of the building, making the longer arm of the cross, is called the nave, and is where worshipers congregate; the term is from the Latin word for ship. The cathedral is symbolically a ship bearing the people of God through the storms of life. The nave is also used for major processions, which gather or enter at the furthest door (liturgically generally called the West Door). The aisles on each side of the nave facilitate the movement of people within the building, without disrupting worshipers in the central space.
The arms of the cross are called the transepts and often contain a number of chapels. Farthest from the main entry is the "sanctuary" where the Blessed Sacrament is laid on the altar or communion table for the consecration. "Sanctuary" means "Holy Place". The word has passed into modern English with an altered meaning because traditionally a criminal who could gain access to this area without capture was thereby given the sanctuary of the church.
Cathedral buildings of the Western European tradition symbolize the progression of the Christian soul towards Salvation. Many cathedrals of Eastern European tradition are centrally planned. These churches are almost always domed. The symbolism in these cathedral structures is of the hierarchy of Earth and Heaven, and often reveals its meaning through the internal decoration of the building with frescoes or mosaics.
Religious functions.
Apart from its organisational function as the seat of the bishop, and the meeting place for the chapter of the diocese, the cathedral has a liturgical function in offering daily church services. Most cathedrals have at least three services of worship every day, often taking the form of matins, Holy Communion and an evening service which is often sung by the precentor and choir. There are often additional services on Sunday. Cathedrals generally have an area dedicated to the performance of choral services and with seating specifically for the choir and dignitories of the church and town. This part of the building is called the Choir or Quire, and is generally located between the sanctuary and the nave. Because music often plays an important part in the performance of the liturgy, cathedrals generally have a pipe organ to accompany the choir.
Cathedrals always have a font or water basin at which the rite of Baptism is performed, in which a person is formally accepted into the Christian church. The font is often placed towards the door because the Baptism signifies entry into the community of the church. In some cathedrals, most particularly in Italy, the rite of Baptism is performed in a separate building.
One of the functions of the cathedral is the reading and expounding upon the Holy Scripture. The cathedral generally has a lectern from which the scripture is read. This often takes the form of an eagle of brass or carved wood which supports the book on its outstretched wings and is the symbol of John the Evangelist. However, some cathedrals retain elaborate medieval structures on either side of the church, one for the reading of the Gospel and the other for the reading of the Epistle.
The function of expounding on the scriptures is traditionally performed from the pulpit which is generally constructed in such a way that the voice of the preacher is projected out to the congregation. The pulpit is often decorated with the winged figures of a man, a lion, a bull and an eagle, representing the Gospel writers, Matthew, Mark, Luke and John.
The services that are held within the cathedral follow an annual cycle. The designated scriptural readings for each day of the church's year establish a pattern which alternates periods of introspection and penitence with periods of celebration, and is punctuated by the two great celebrations of Christmas and Easter.
Many cathedrals are places of pilgrimage to which people travel in order to worship or venerate a holy object or the reliquary of a saint. Many cathedrals are regarded as places that have provided rewarding religious experiences, where prayers have been answered or miracles have taken place. Pilgrimage was particularly popular in the late medieval period. Some cathedrals such as Santiago de Compostela continue to attract pilgrims.
Civic and social functions.
The formal cathedral services are linked to the cycle of the year and respond to the seasons of the Northern Hemisphere, Christmas falling in the winter and Easter in the spring. Cathedrals often hold a service of thanksgiving called Harvest Festival in the autumn.
Births, marriages and deaths are often celebrated by services at cathedrals and the cathedral often acts as a repository of local history by recording these events. The cathedral marks times of national and local civic celebration and sadness with special services. The funerals of those famous within the community are invariably held at cathedrals. People who have served the community or the church are often buried within the cathedral with which they are associated. Alternatively, they may be commemorated by a memorial. Some cathedrals, such as Aachen and Rheims are the traditional coronation places of monarchs.
Another civic function of the cathedral is the imparting of significant civil information. Announcements may be to the populace from the steps of the cathedral, or within the cathedral itself.
Most cathedrals have a bell or bells. These are used to announce that a service is soon to take place. They are also used to convey information and celebration. The ringing of peals signifies a time of rejoicing, such as a wedding. An extended ringing of peals or "changes" conveys a time of great civic celebration. The slow tolling of the deepest bell signifies a death or disaster. Many cathedrals have a clock with associated chimes which announce the time. The bells of a cathedral are traditionally used to signal the outbreak and the ending of war.
Cathedrals are often associated with significant secular organisations such as the office of the local mayor and council, the local court, the local regiment, schools, sporting organisations and service clubs. The cathedral often has its own school, primarily for the education of choristers, but often including other children as well.
The cathedral, often being a large building, serves as a meeting place for many people. The cathedral often forms a centre of different activities related to community service, youth activities, study, music and decorative arts.
Cathedral buildings.
Cathedral buildings, especially those dating from the Medieval period, are frequently the grandest of churches in the diocese (and country). The ancient cathedrals of England, of Northern France, Belgium, Spain, Portugal, Germany and Sicily, the Baroque cathedrals of South America, and many individual cathedrals from Italy and other parts of Europe, are among the largest and finest religious buildings. Many are renowned for their architecture or their decorative features such as sculpture, stained glass and frescos.
While cathedral buildings, in general, tend to be large, size and grandeur have rarely been essential requirements. Early Celtic and Saxon cathedrals tended to be of diminutive size, as is the Byzantine so-called "Little Metropole Cathedral" of Athens. In Italy, with a few notable exceptions such as Florence Cathedral and Milan Cathedral, cathedrals are numerous and are often similar in form and size to monastic or large parish churches. In modern times, where functionality is the foremost consideration, a cathedral church may be a modest structure.
Cathedrals of monastic foundation, and some of secular clergy have cloisters which traditionally provided an open area where secular activities took place protected from wind and rain. Some cathedrals also have a chapter house where the chapter could meet. In England, where these buildings have survived, they are often octagonal. A cathedral may front onto the main square of a town, as in Florence, or it may be set in a walled "close" as at Canterbury. There may be a number of associated monastic or clergy buildings, a bishop's palace and often a school to educate the choristers.
Artworks, treasures and tourism.
Many cathedral buildings are very famous for their architecture and have local and national significance, both artistically and historically. Many are listed among the UNESCO World Heritage Sites.
Many cathedrals, because of their large size and the fact that they often have towers, spires or domes, have until the 20th century, been the major landmarks in cities or in views across the countryside. With highrise building, civil action has been taken in some cases, such as the Cologne Cathedral to prevent the vista of the cathedral from being spoiled.
Because many cathedrals took centuries to build and decorate, they constitute a major artistic investment for the city in which they stand. Not only may the building itself be architecturally significant, but the church often houses treasures such as stained glass, stone and wood statues, historic tombs, richly carved furniture and objects of both artistic and religious significance such as reliquaries. Moreover, the cathedral often plays a major role in telling the story of the town, through its plaques, inscriptions, tombs, stained glass and paintings.
For these reasons, tourists have travelled to cathedrals for hundreds of years. Many cathedrals cater for tourists by charging a fee to any visitors outside service times or requesting a donation or making a charge to take photos. Cathedrals which are particularly popular tourist venues sometimes provide guides, leaflets, souvenirs and cafes.

</doc>
<doc id="45884" url="http://en.wikipedia.org/wiki?curid=45884" title="Leeuwarden">
Leeuwarden

Leeuwarden (], Stadsfries: "Liwwadden", Frisian: "Ljouwert", ]) is the capital city of the Frisian province of Friesland in the Netherlands. It is situated in the northern part of the country.
Etymology.
The name "Leeuwarden" (or older spelling variants) first came into use for Nijehove, the most important one of the three villages that later merged into one, in the early 9th century (Villa Lintarwrde c. 825).
There is much uncertainty about the origin of the city's name. Historian and archivist Wopke Eekhoff summed up a total of over 200 different spelling variants, of which "Leeuwarden" (Dutch), "Liwwadden" (Stadsfries) and "Ljouwert" (West Frisian) are still in use.
The second syllable is easily explained. "Warden", Frisian/Dutch for an artificial dwelling hill, is a designation of terps, reflecting the historical situation.
The first part of the name, "leeuw", means lion in modern standard Dutch. This interpretation corresponds with the coat of arms adopted by the city, which features a heraldic lion. However, modern standard Dutch was not used in this region in the Middle Ages, when the city was called "Lintarwrde". Some scholars argue that the name of the city is derived from "leeu-", a corruption of "luw-" (Dutch for sheltered from the wind, cf. the maritime term Leeward) or from "lee-" (a Dutch word for water circulation). The last one suits the watery province of Fryslân.
History.
The area has been occupied since the 10th century (although recently, remains of houses dating back to the 2nd century AD were discovered during a dig near the Oldehove), and was granted a city charter in 1285. Situated along the Middelzee, it was an active trade centre, until the waterway silted up in the 15th century. In 1901 the city had a population of 32,203.
Famous natives of Leeuwarden include stadtholder William IV of Orange, graphic artist M. C. Escher, and dancer-spy Mata Hari, as well as the theologian Dr. N.H. Gootjes.
During World War II, after extensive occupation by the German forces, on 15 April 1945, the Royal Canadian Dragoons, disobeying direct orders, charged into the heavily defended city and defeated the Germans, who were driven out by the next day. On that day, the Royal Canadian Dragoons still fly the flag of the city of Leeuwarden wherever they are stationed.
On Saturday 19 October 2013, a fire broke out in a clothes shop on a busy pedestrian street. The fire started late in the afternoon and destroyed over 15 shops and flats. Everyone on the street was evacuated as the blaze damaged dozens of properties. A 24-year-old man who was living in one of the flats died because the fire was not under control until Sunday morning. Due to this the fire burnt all through the night. The man called the fire brigade, before collapsing because the services could not reach him. The birthplace of Mata Hari was destroyed. The firemen took 4 and a half hours to put out the fire.
Heraldry.
The coat of arms of Leeuwarden is the official symbol of the municipality of Leeuwarden. It consists of a blue escutcheon, a golden lion and a crown. The fact Leeuwarden carries a lion in its seal seems logical, considering that "Leeuw" is Dutch for "Lion". However, it is very plausible the oldest name of the city conceals an indication of water rather than an animal. Some sources tell the lion had been called into life after the name became official. It is also possible the coat of arms was a gift to the city from the powerful "Minnema" family.
Geography.
Population centres.
Leeuwarden consists of 19 population centres as of 1 January 2014 when parts of the former municipality of Boarnsterhim were added to Leeuwarden.
Culture.
Architecture.
Well-known buildings in the city centre include the "Kanselarij" (the former chancellery), the Stadhouderlijk hof, former residence of the stadtholders of Friesland, the "Waag" (old trade centre of the city), the church of Saint Boniface church and the leaning tower "Oldehove". The tallest building in the city is the 115 metre tall Achmeatoren (Achmea insurance tower).
Leeuwarden is also the site of the country's largest cattle market, and on Ascension Day, the largest flower market in the Netherlands is held here. The "Froskepôlemolen" is the last surviving windmill of over 130 known to have stood in Leeuwarden. The remains of the "Cammingha-Buurstermolen" were demolished in 2000. The bases of two other windmills, "Wielinga-Stam" and "De Haan" also survive.
Sport.
Leeuwarden is the starting and finishing point for the celebrated Elfstedentocht, a 200 km-long speed skating race over the Frisian waterways that is held when winter conditions in the province allow. As of 2015, it last took place in January 1997, preceded by the races of 1986 and 1985. In 1986 the Dutch king Willem-Alexander participated in the Eleven cities tour, with the pseudonym W.A. van Buren, which is the pseudonym of the royal family of The Netherlands. The city's local football team, Cambuur Leeuwarden plays in the Eredivisie. In the season 2005/06, the club narrowly escaped bankruptcy. Its "Cambuurstadion" opened in 1995. The football team has proposed plans for a new stadium in the east side of the city, which will cost €35 million. The city's basketball team, Aris Leeuwarden plays in the Dutch Basketball League since 2004.
European capital of Culture.
On September 6, 2013 Leeuwarden was voted European Capital of Culture for the year 2018.
Politics.
Leeuwarden, as capital of the province of Friesland, is seat of the provincial authorities.
Sister cities.
Leeuwarden has a sister city:
Transport.
Train routes with starting number of the train number series:
There are also bus lines:
And there are citybuses. Most buslines are operated by Arriva and a few (line 10,13,14 and 320) are operated by Qbuzz
Education.
Leeuwarden has a number of respected universities of applied science (HBO in Dutch), such as the Van Hall Instituut (agricultural and life sciences), the (hotel management, economical and media management) and the (economical, technical and arts).
Although the city has no scientific university, several dependencies are located here, including the Wageningen University, Universiteit Twente and the Rijksuniversiteit Groningen. About 16,000 students, among them an increasing number of foreign students, study at technical schools. Besides higher education, the city is also home to three regional vocational schools ("MBO"): the ', ' and .

</doc>
<doc id="45890" url="http://en.wikipedia.org/wiki?curid=45890" title="1260s BC">
1260s BC


</doc>
<doc id="45891" url="http://en.wikipedia.org/wiki?curid=45891" title="Fermat pseudoprime">
Fermat pseudoprime

In number theory, the Fermat pseudoprimes make up the most important class of pseudoprimes that come from Fermat's little theorem.
Definition.
Fermat's little theorem states that if "p" is prime and "a" is coprime to "p", then "a""p"−1 − 1 is divisible by "p". For an integer "a" > 1, if a composite integer "x" divides "a""x"−1 − 1, then "x" is called a Fermat pseudoprime to base "a". In other words, a composite integer is a Fermat pseudoprime to base "a" if it successfully passes Fermat primality test for the base "a". It follows that if "x" is a Fermat pseudoprime to base "a", then "x" is coprime to "a".
The smallest base-2 Fermat pseudoprime is 341. It is not a prime, since it equals 11·31, but it satisfies Fermat's little theorem: 2340 ≡ 1 (mod 341) and thus passes 
Fermat primality test for the base 2.
Pseudoprimes to base 2 are sometimes called Poulet numbers, after the Belgian mathematician Paul Poulet, Sarrus numbers, or Fermatians (sequence in OEIS).
A Fermat pseudoprime is often called a pseudoprime, with the modifier Fermat being understood.
An integer "x" that is a Fermat pseudoprime for all values of "a" that are coprime to "x" is called a Carmichael number.
Variations.
Some sources use variations of the definition, for example to only allow odd numbers to be pseudoprimes. 
Every odd number "q" satisfies formula_1 for formula_2. This trivial case is excluded in the definition of a Fermat pseudoprime given by Crandall and Pomerance:
Properties.
Distribution.
There are infinitely many pseudoprimes to a given base (in fact, infinitely many strong pseudoprimes (see Theorem 1 of
and infinitely many Carmichael numbers
, but they are rather rare.
There are only three pseudoprimes to base 2 below 1000, 245 below one million, and only 21853 less than 25·109 (see Table 1 of ).
Starting at 17·257, the product of consecutive Fermat numbers is a base-2 pseudoprime, and so are all Fermat composite and Mersenne composite.
Factorizations.
The factorizations of the 60 Poulet numbers up to 60787, including 13 Carmichael numbers (in bold), are in the below table.
A Poulet number all of whose divisors "d" divide 2"d" − 2 is called a super-Poulet number. There are infinitely many Poulet numbers which are not super-Poulet Numbers.
Smallest Fermat pseudoprimes.
The smallest pseudoprime for each base "a" ≤ 200 is given in the following table; the colors mark the number of prime factors. Unlike in the definition at the start of the article, pseudoprimes below "a" are excluded in the table. (For that to allow pseudoprimes below "a", see  , and it is 4, 341, 91, 15, 4, 35, 6, 9, 4, 9, 10, 65, 4, 15, 14, 15, 4, 25, 6, 21, 4, 21, 22, 25, 4, 9, 26, 9, 4, 49, 6, 25, 4, 15, 9, 35, 4, 39, 38, 39, 4, 205, 6, 9, 4, 9, 46, 49, 4, 21, 10, 51, 4, 55, 6, 15, 4, 57, 15, 341, 4, 9, 62, 9, 4, 65, 6, 25, 4, 69, 9, 85, 4, 15, 74, 15, 4, 77, 6, 9, 4, 9, 21, 85, 4, 15, 86, 87, 4, 91, 6, 21, 4, 15, 91, 65, 4, 9, 14, 9, 4, 133, 6, 15, 4, 15, 9, 91, 4, 111, 10, 65, 4, 91, 6, 9, 4, 9, 15, 77, 4, 33, 85, 15, 4, 25, 6, 49, ...)
First few Fermat pseudoprimes in base "a" (up to 10000).
For more information (base 31 to 100), see   to  , and for all bases up to 150, see , this page does not define "n" is a pseudoprime to a base congruent to 1 or -1 (mod "n")
Which bases "b" make "n" a Fermat pseudoprime?
The following is a list about all base "b" < "n" which "n" is a Fermat pseudoprime (all composite number is a pseudoprime to base 1, and for "b" > "n", the solutions are just shifted by "k"*"n" for "k" > 0), if a composite number "n" is not listed in the list (or "n" is in the sequence = 1, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24, 26, 30, 32, 34, 36, 38, 40, 42, 44, 46, 48, 50, 54, 56, 58, 60, 62, 64, 68, 72, 74, 78, 80, 82, 84, 86, 88, 90, 92, 94, 96, 98, 100, 102, 104, 106, 108, 110, 114, 116, 118, 120, 122, 126, 128, 132, 134, 136, 138, 140, 142, 144, 146, 150, ... ), then "n" is a pseudoprime only in base 1, or the bases which congruent to 1 (mod "n") (that is, the number of the values of "b" is 1), these "n"s are up to 150)
For more information ("n" = 151 to 5000), see , this page does not define "n" is a pseudoprime to a base congruent to 1 or -1 (mod "n"). Note that when "p" is a prime, "p"2 is a Fermat pseudoprime to base "b" if and only if "p" is a Wieferich prime to base "b". For example, 10932 = 1194649 is a Fermat pseudoprime to base 2, and that 112 = 121 is a Fermat pseudoprime to base 3.
The number of the values of "b" for "n" are (For "n" prime, the number of the values of "b" must be "n" - 1, since all "b" satisfy the Fermat little theorem)
The least base "b" > 1 which "n" is a pseudoprime to base "b" (or prime number) are
The number of the values of "b" for "n" must divides formula_5("n"), or ("n") = 1, 1, 2, 2, 4, 2, 6, 4, 6, 4, 10, 4, 12, 6, 8, 8, 16, 6, 18, 8, 12, 10, 22, 8, 20, 12, 18, 12, 28, 8, 30, 16, 20, 16, 24, 12, 36, 18, 24, 16, 40, 12, 42, 20, 24, 22, 46, 16, 42, 20, ... (The quotient can be any natural number, and the quotient = 1 if and only if "n" is a prime or a Carmichael number (561, 1105, 1729, 2465, 2821, 6601, 8911, 10585, 15841, ... ), the quotient = 2 if and only if "n" is in the sequence: 4, 6, 15, 91, 703, 1891, 2701, 11305, 12403, 13981, 18721, ... )
The least number with "n" values of "b" are (or 0 if no such number exists)
Weak pseudoprimes.
A composite number "n" which satisfy that "bn" = "b" (mod "n") is called weak pseudoprime to base "b", the least weak pseudoprime to base "b" are
If we require that "n" > "b", they are
Euler–Jacobi pseudoprimes.
Another approach is to use more refined notions of pseudoprimality, e.g. strong pseudoprimes or Euler–Jacobi pseudoprimes, for which there are no analogues of Carmichael numbers. This leads to probabilistic algorithms such as the Solovay–Strassen primality test, the Baillie-PSW primality test, and the Miller–Rabin primality test, which produce what are known as industrial-grade primes. Industrial-grade primes are integers for which primality has not been "certified" (i.e. rigorously proven), but have undergone a test such as the Miller–Rabin test which has nonzero, but arbitrarily low, probability of failure.
Applications.
The rarity of such pseudoprimes has important practical implications. For example, public-key cryptography algorithms such as RSA require the ability to quickly find large primes. The usual algorithm to generate prime numbers is to generate random odd numbers and test them for primality. However, deterministic primality tests are slow. If the user is willing to tolerate an arbitrarily small chance that the number found is not a prime number but a pseudoprime, it is possible to use the much faster and simpler Fermat primality test.

</doc>
<doc id="45893" url="http://en.wikipedia.org/wiki?curid=45893" title="Michigan Technological University">
Michigan Technological University

Michigan Technological University (commonly referred to as Michigan Tech, MTU, or simply Tech) is a public research university located in Houghton, Michigan, United States. Its main campus sits on 925 acre on a bluff overlooking Portage Lake. Michigan Tech was founded in 1885 as the first post-secondary institution in the Upper Peninsula of Michigan, and was created to train mining engineers to operate the local copper mines.
Science, technology, forestry and business have been added to the numerous engineering disciplines, and Michigan Tech now offers more than 130 degree programs through its five colleges and schools. "US News and World Report" ranked Michigan Tech's undergraduate program 116th in the nation based on peer assessment, student selectivity, financial resources and other factors. Michigan Tech was also rated among the "Best in the Midwest" by The Princeton Review.
Michigan Tech's athletic teams are nicknamed the Huskies and compete primarily in the NCAA Division II Great Lakes Intercollegiate Athletic Conference (GLIAC). The men's hockey team competes in Division I as a member of the Western Collegiate Hockey Association (WCHA), and has won three national championships. The women's basketball team were national runners-up in 2011.
History.
Michigan Tech was founded in 1885 as the Michigan Mining School. After much agitation by Jay Abel Hubbell, the state legislature established the school to train mining engineers. Hubbell donated land for the school's first buildings. The school started with four faculty members and twenty-three students. It was housed in the Houghton Fire Hall from 1886 through 1889. A few years after the school's creation, enrollment grew to such a point that its name no longer reflected its purpose. The name was then changed to the Michigan College of Mines in 1897. This name lasted through World War I until 1925, but by this time the school had begun offering a wider variety of degrees and once again decided to change its name to the Michigan College of Mining and Technology in 1927. By 1931 enrollment had reached nearly 600. During the next few years, due to the Great Depression, money was scarce, causing department heads and even the president of the university, William Hotchkiss, to take pay cuts. Grover C. Dillman was president from 1935 to 1956. During this time, the school underwent many notable changes: a few of these include the construction of the Memorial Union Building and purchase of an ice rink and golf course. Around 1948, enrollment passed 2000 students total. In 1956, J. Robert Van Pelt became the new president of the university. He restarted many PhD programs and created a focus on research. This included the school's first analog computation class in 1956–1957. In the final years of his presidency, the school changed from a college to a university, changing its name a final time to "Michigan Technological University". The change from the Michigan College of Mining and Technology was necessary for two reasons, according to Van Pelt. First, the college had expanded too greatly and the current name was no longer an accurate title. Also, including "mining" in the name of the college was misleading. The name Michigan Technological University was chosen in order to retain the nickname of Michigan Tech that had already been in use since 1927. Although engineering still accounts for some 59 percent of all enrollment as of fall 2010, the University now offers more than 130-degree programs. Along with the new name, Michigan Technological University, the school gained new constitutional status in 1964. The new status gave responsibility for control of the university to its Board of Control rather than legislature.
Campus.
The main Michigan Tech campus is located mainly on US 41 in Houghton, Michigan. It is the safest campus in Michigan, and the third safest in the United States according to Reader's Digest. The main part of campus is relatively small, and can be traversed in about 10 minutes. Many of the buildings are tall, reducing the physical size of the campus and giving the impression of being a park of high-rise office buildings. In addition, the offices of the Michigan Tech Fund are located in the Citizens Bank Building in Hancock. The Lakeshore Center in downtown Houghton houses the offices of Human Relations, Vice President for Research and other departments.
Faculty are involved in several distance education programs with clients such as General Motors.
The Portage Lake Golf Course opened for play in April 1902. In 1945 the members could no longer support the needs of the course and sold it to Michigan Tech for one dollar. Since then many improvements have been made such as the addition of another nine holes in 1969. Then in 1984 the new clubhouse was constructed. In 1996 a sprinkler system was installed to modernize the course and keep it playable. The Portage Lake Golf Course is located two miles (3 km) southeast of campus.
Academics.
Michigan Tech offers more than 130 undergraduate and graduate degrees in engineering, natural and physical sciences, computing, business and economics, technology, environmental studies, arts, humanities, and social sciences. The university is divided into five schools and colleges. The average overall ACT scores for incoming students is 26.4 in fall 2010, compared to 21.2 nationally. The College of Engineering's environmental engineering and mechanical engineering enrollments rank in the top ten nationally. The electrical engineering department uses an innovative "DSP First" curriculum found at only a few leading universities.
Michigan Tech has also developed an alternative program to provide students with engineering and other design experience called the Enterprise program. Enterprises develop engineering skills by allowing students to work in business-like environments on real-world projects while completing their education. Enterprises include Nanotechnology Innovations, Hybrid Transportation, Aerospace, Blue Marble Security, Husky Game Development, Boardsports Technologies, and Wireless Communications Enterprises.
Student body.
The student body consists of more than 7,000 graduate and undergraduate students (Fall 2011) and more than 450 academic faculty (Fall 2010). As is historically true of engineering institutions, female enrollment at Michigan Tech is low. The male to female student ratio was 22:1 in 1960; since 1980 it has remained around 3:1. Michigan Tech's admissions office has enlisted female students and faculty to contact every admitted female applicant via telephone or personal letter in an attempt to increase female enrollment. In this last semester, Fall 2012, female enrollment has risen for the 6th straight year to reach an all-time high of 1,837 students. This pulls women up to 26.1%. The Fall 2010 freshman class had a ratio of 3.1:1.
Michigan Tech students are primarily from Michigan, Wisconsin, Minnesota, and Illinois. The student body is approximately 75.4% European-American/Non-Hispanic, 14.2% International, 1.6% Hispanic, 1.5% percent African American, 1.0% Asian, 0.6% Native American, 1.0% Multiracial, 0.1% Pacific Islander, and the remaining 4.5% was not supplied. The university has recently focused on achieving a more diverse student body, in terms of ethnicity, gender, and areas of study. A key step in this effort was the recent introduction of several new academic majors, including psychology, biochemistry and molecular biology, Cheminformatics, communication and culture studies, pharmaceutical chemistry, exercise science, sound design, audio production, and theater and entertainment technology.
Research.
Michigan Tech ranked 172nd of 600 US colleges and universities in research and development expenditures in 2007. Research expenditures exceeded $50 million in 2009.
Student life.
Students attending Michigan Technological University have a wide range of activities to participate in, whether or not they are living in the residence halls. In addition to the various small interest groups which form throughout the year, they participate in Greek Life, Student Organizations, and the Enterprise Program; many organize and attend varsity day events, such as K-Day, the Parade of Nations, and the Winter Carnival (which also attracts alumni from across the country); furthermore, there are motivational drives to raise student activity levels and involvement in the school community, typically for those without membership in a student organization.
Student organizations.
Michigan Tech currently recognizes more than two hundred student organizations, including:
Greek life.
Michigan Tech is currently host to thirteen fraternities, including three international fraternities and three local fraternities. Additionally, there are eight sororities on campus, including four local sororities.
Athletics.
As the school mascot is the husky (specifically, Blizzard T. Husky), the school's sports teams are known as the "Huskies". Michigan Tech competes in the NCAA's Division II Great Lakes Intercollegiate Athletic Conference. The men's hockey team competes in Division I as a member of the Western Collegiate Hockey Association. Michigan Tech owns a downhill ski/snowboard hill, Mont Ripley, just across Portage Lake from campus, and maintains extensive cross-country ski trails (used for mountain biking in summer).
School songs.
Michigan Tech has both an official fight song and an official Alma Mater. At most sporting events, however, both the "Engineer's Song" and "In Heaven There Is No Beer" are played by the Huskies Pep Band, and many students consider these to be the unofficial school songs. The "Blue Skirt Waltz" is played at home ice hockey games and is called the "Copper Country Anthem." During the song, the fans join arms and swing back and forth to the music.
People.
There are over 68,000 Michigan Tech alumni living in all 50 states and over 100 countries. Some notable alumni include:

</doc>
<doc id="45896" url="http://en.wikipedia.org/wiki?curid=45896" title="The Stranger (novel)">
The Stranger (novel)

The Outsider or The Stranger (French: L’Étranger) is a novel by Albert Camus published in 1942. Its theme and outlook are often cited as exemplars of Camus's philosophy of the absurd and existentialism, though Camus personally rejected the latter label.
The titular character is Meursault, an indifferent French Algerian ("a citizen of France domiciled in North Africa, a man of the Mediterranean, an "homme du midi" yet one who hardly partakes of the traditional Mediterranean culture") who, after attending his mother's funeral, apathetically kills an Arab man whom he recognises in French Algiers. The story is divided into two parts: Meursault's first-person narrative view before and after the murder, respectively.
In January 1955, Camus said, "I summarized "The Stranger" a long time ago, with a remark I admit was highly paradoxical: 'In our society any man who does not weep at his mother's funeral runs the risk of being sentenced to death.' I only meant that the hero of my book is condemned because he does not play the game."
Plot.
Part one.
Meursault learns of his mother's death. At her funeral, he expresses none of the expected emotions of grief. When asked if he wishes to view the body, he says no, and, instead, smokes and drinks coffee in front of the coffin. Rather than expressing his feelings, he only comments to the reader about the others at the funeral. He later encounters Marie, a former employee of his firm. The two become re-acquainted, go swimming, watch a comedy film and begin to have a sexual relationship, despite the fact that his mother's funeral took place the day before. In the next few days, he helps his friend and neighbour, Raymond Sintès, take revenge on a Moorish girlfriend suspected of infidelity. For Raymond, Meursault agrees to write a letter to his girlfriend, with the sole purpose of inviting her over so that Raymond can have sex with her but spit in her face at the last minute as emotional revenge. Meursault sees no reason not to help him, and it pleases Raymond. He does not express concern that Raymond's girlfriend is going to be emotionally hurt, as he believes Raymond's story that she has been unfaithful, and he himself is both somewhat drunk and characteristically unfazed by any feelings of empathy. In general, he considers other people either interesting or annoying or feels nothing of them at all.
The letter works: the girlfriend returns, but the situation escalates when she slaps Raymond after he tries to kick her out, and Raymond beats her. Raymond is taken to court where Meursault testifies that she had been unfaithful, and Raymond is let off with a warning. After this, the girlfriend's brother and several Arab friends begin trailing Raymond. Raymond invites Meursault and Marie to a friend's beach house for the weekend, and when there, they encounter the spurned girlfriend's brother and an Arab friend; these two confront Raymond and wound him with a knife during a fist fight. Later, walking back along the beach alone and now armed with a revolver he took from Raymond so that Raymond would not do anything rash, Meursault encounters the Arab. Meursault is now disoriented on the edge of heatstroke, and when the Arab flashes his knife at him, Meursault shoots. Despite killing the Arab man with the first gunshot, he shoots the corpse four more times after a brief pause. He does not divulge to the reader any specific reason for his crime or emotions he experiences at the time, if any, aside from the fact that he was bothered by the heat and bright sunlight.
Part two.
Meursault is incarcerated, and explains his arrest, time in prison, and upcoming trial. His general detachment makes living in prison very tolerable, especially after he gets used to the idea of not being able to go places whenever he wants to and no longer being able to satisfy his sexual desires with Marie. He passes the time sleeping, or mentally listing the objects he owned back in his apartment building. At the trial, Meursault's quietness and passivity is seen as demonstrative of his seeming lack of remorse or guilt by the prosecuting attorney, and so the attorney concentrates more upon Meursault's inability or unwillingness to cry at his mother's funeral than on the actual murder. The attorney pushes Meursault to tell the truth but never comes through and later, on his own, Meursault explains to the reader that he simply was never really able to feel any remorse or personal emotions for any of his actions in life. The dramatic prosecutor theatrically denounces Meursault to the point that he claims Meursault must be a soulless monster, incapable of remorse and that he thus deserves to die for his crime. Although Meursault's attorney defends him and later tells Meursault that he expects the sentence to be light, Meursault is alarmed when the judge informs him of the final decision: that he will be decapitated publicly.
In prison, while awaiting the execution of his death sentence by the guillotine, Meursault meets with a chaplain, but rejects his proffered opportunity of turning to God, explaining that God is a waste of his time. Although the chaplain persists in attempting to lead Meursault from his atheism (or, perhaps more precisely, his apatheism), Meursault finally accosts him in a rage, with a climactic outburst on his frustrations and the absurdity of the human condition and his personal anguish at the meaninglessness of his existence without respite. At the beginning of his outrage he mentions other people in anger, that they have no right to judge him for his actions or for who he is, and no one has the right to judge someone else. Meursault ultimately grasps the universe's indifference towards humankind which allows him to come to terms with his execution.
Characters.
Meursault is a French Algerian who learns of his mother's death by telegram. Meursault's indifference to the news of his mother's death demonstrates some emotional detachment from his environment. There are multiple instances throughout the novel where significant moments do not have an emotional impact on Meursault. He doesn't show emotion to the fact that his mother is dead, Marie loves him, or that he killed someone. Another aspect of Meursault is that he is a truthful person. He always speaks his mind and does not care how other people see him. However, he may have committed perjury by providing hearsay testimony on behalf of his neighbor, Raymond. He is regarded as a stranger to society due to his indifference.
Raymond Sintès is the neighbor of Meursault who beats his mistress which causes a conflict with the Arabs. He brings Meursault into the conflict which ultimately results in Meursault killing the Arab. Raymond can be a foil character of Meursault in that he takes action while Meursault is indifferent. Raymond and Meursault seem to develop a bond as the story goes on, ending with Raymond Sintes testifying for Meursault during his trial. Raymond also believes that he can control people - he assaults a woman because he believes she cheated and he insists Meursault is his friend after a simple favor from Meursault.
Marie Cardona is a typist in the same workplace as Meursault. A day after Meursault's mother's funeral she meets him at a public beach, which sparks their relationship. She asks if Meursault loves her but Meursault replies that he doesn't think so. He still agrees to marry her prior to the murder and his arrest. Marie, like Meursault, enjoys physical contact in their relationship through the act of sex. She represents the enjoyable life Meursault wants and her pleasing aesthetic is one of the things that Meursault misses in jail.
Masson is the owner of the beach house where Raymond takes Marie and Meursault. Masson is a carefree person who simply likes to live his life and be happy. He wants to live life without restrictions.
Salamano is an old man who routinely takes his dog out for walks. He abuses the dog but is attached to it. When he loses his dog, he is distressed and asks Meursault for advice. Meursault does not offer helpful advice and Salamano acknowledges that his life has changed.
The Arabs. Includes the mistress of Raymond. None of the Arabs were named in "The Stranger".
The Arab He is shot by Meursault on a beach of colonial Algiers. "The Arab" was given an identity and a whole novel by the Algerian journalist and novelist Kamel Daoud in his 2013 novel Meursault, Counter-inquiry.
On the surface, "L’Etranger" gives the appearance of being an extremely simple though carefully planned and written book. In reality, it is a dense and rich creation, full of undiscovered meanings and formal qualities. It would take a book at least the length of the novel to make a complete analysis of meaning and form and the correspondences of meaning and form, in "L’Etranger".
Viggiani 586
English translations from the French.
The Librairie Gallimard first published the original French-language novel in 1942. British author Stuart Gilbert first translated "L’Étranger" to English in 1946; for more than thirty years his version was read as the standard English translation. In 1982, the British publisher Hamish Hamilton published a second translation, by Joseph Laredo, that Penguin Books bought in 1983 and reprinted in the Penguin Classics line in 2000. In 1988, a third translation, by the American Matthew Ward, was published, by Random House Inc., in the Vintage International line of Vintage Books. Because Camus was influenced by the American literary style, the 1988 translation was Americanised. A translation by Sandra Smith, entitled "The Outsider", was published by Penguin in 2013.
A critical difference of translation is in the connotation of the original French emotion in the story's key sentence: "I laid my heart open to the benign indifference of the universe" in Gilbert's versus Laredo's "I laid my heart open to the gentle indifference of the universe" (original French: "la tendre indifférence du monde" = literally, "the tender indifference of the world"), although in the Penguin Classics 2000 reprint of Laredo's translation, "gentle" was subsequently changed to "benign". The ending lines between the two aforementioned translations differ as well, from "on the day of my execution there should be a huge crowd of spectators and that they should greet me with howls of execration," to " with cries of hatred", respectively, a significant scene that serves as a foil to the prior "indifference of the world". In French, the triad is "cris de haine", which Ward's transliteral interpretation ("with cries of hate") is closest to in terms of phonics. Gilbert's interpretation takes the liberty of juxtaposing "execration" with "execution".
In popular culture.
The 1995 song "Noch koroche dnya" ("Night is Shorter than Day") by the Russian heavy metal band Aria is based on Meursault's encounter with the chaplain in the final scene of the novel. It is also narrated from Meursault's first-person perspective and includes (in Russian) the line, "The cries of hate will be my reward / Upon my death, I will not be alone."
The 1979 first single "Killing an Arab" by The Cure was recorded at the same time as their first LP in the UK, "Three Imaginary Boys" (1979) but not included on the album. However, it was included on the band's first US album, "Boys Don't Cry" (1980). Composer Robert Smith has said that the song "was a short poetic attempt at condensing my impression of the key moments in "L'Étranger (The Stranger)" by Albert Camus" (Cure News number 11, October 1991).
The passage in which Meursault accepts his impending execution was read over the end of the song "Asa Phelps Is Dead" by The Lawrence Arms; read by guitarist Chris McCaughan, the excerpt parallels certain themes in the song's lyrics by bassist Brendan Kelly.
The lead singer, Rody Walker of the Canadian progressive metal band Protest The Hero has the quotation 'It is better to burn than to disappear' as his first tattoo on his right arm. This quotation is not in the Original. It is most likely the result of a prank. 
In "The Sopranos" episode "D-Girl", Anthony Soprano Jr tells his parents that life is absurd, that the hypothetical death of his friends would be "interesting," and that there is no God. Tony and Carmela ask where this is coming from. Meadow Soprano appears at this moment and explains that Anthony was assigned "The Stranger" in English class, stating "This is education."
In the 1990 film "Jacob's Ladder," Tim Robbins' character can be seen reading "The Stranger" during the subway scene at the beginning of the movie.
In the 2012 film Life of Pi, the titular character of Pi can be seen reading a French language copy of "The Stranger" in a flashback scene to his youth in Pondicherry, India.
In the first episode of the 2014 HBO Series The Leftovers, Tom Garvey can be seen in the middle of the night reading an English version "The Stranger", translated by Matthew Ward.
In the tenth episode of the 2014 WGN America Series Manhattan, the character Ida is seen returning a copy of the book to Elodie and comments on the book "I thought it would be racy" .
In the first season of American Horror Story, in the second episode, Violet is seen reading The Stranger in bed when her mother brings her a cupcake.
The Joe Iconis song, Kevin, deals with a young man who feels completely detached from his surroundings. The refrain states, "I can't feel a thing anymore. It's all been done before. And everything's a horrible bore. And living is a terrible chore. You know that it's true. There's nothing new to do in Brooklyn anymore". The near the end of the song, testing his apathy, the singer randomly strangles a stranger, killing her and dumping her body in an alley. However, he is "still numb". 

</doc>
<doc id="45900" url="http://en.wikipedia.org/wiki?curid=45900" title="1270s BC">
1270s BC


</doc>
<doc id="45903" url="http://en.wikipedia.org/wiki?curid=45903" title="The Man in the High Castle">
The Man in the High Castle

The Man in the High Castle (1962) is an alternate history novel by American writer Philip K. Dick. The novel is set in 1962, fifteen years after the end of a fictional longer Second World War (1939–1947). It concerns intrigues between the victorious Axis Powers—Imperial Japan and Nazi Germany—as they rule over the former U.S., as well as daily life under the resulting totalitarian Fascist and imperialistic rule. Reported inspirations for the work include Ward Moore's alternate Civil War history, "Bring the Jubilee" (1953), various classic World War II histories, and the "I Ching" (which is referenced in the novel). The novel includes the construction of a novella within the novel that constitutes an alternate history within this alternate history (wherein the Allied Powers defeat the Axis Powers, though in a manner distinct from this actual historical outcome). "The Man in the High Castle" won a Science Fiction Achievement Award (Hugo Award) in 1963. It has since been translated into many languages, and a recent pilot episode of a television adaptation (January 15, 2015) from Amazon Studios has been greenlighted to run as a series. Various further short works by the same author are reported to serve as followup information (short of constituting an actual sequel).
Plot summary.
Background.
Giuseppe Zangara's assassination of U.S. President Franklin D. Roosevelt in 1934 led to the weak governments of John Nance Garner (formerly FDR's Vice President), and subsequently of Republican John W. Bricker in 1941. Both politicians failed to lead the country to recovery from the Great Depression and also maintained the country's isolationist policy against participating in the Second World War; thus, the U.S. had insufficient military capabilities to assist the United Kingdom and the Soviet Union against Nazi Germany, or to defend itself against Japan in the Pacific.
In 1941, the Nazis conquered the USSR and then exterminated most of its Slavic peoples; the few whom they allowed to live were confined to reservations. In the Pacific, the Japanese destroyed the entire U.S. Navy fleet in a decisive, definitive attack on Pearl Harbor; thereafter, the superior Japanese military conquered Hawaii, Australia, New Zealand and Oceania during the early 1940s. Afterward, the Axis Powers, attacking from opposite coasts, conquered the coastal United States and, by 1947, the United States and other remaining Allied forces had all surrendered to the Axis.
Japan established the puppet Pacific States of America out of Alaska, California, Hawaii, Oregon, parts of Nevada and Washington as part of the Greater East Asian Co-Prosperity Sphere. The remaining Mountain, Great Plains and Southwestern states became the Rocky Mountain States, a buffer between the PSA and the remaining USA, now a Nazi puppet state in the style of Vichy France. Having defeated the Allies of World War II, the Third Reich and Imperial Japan became the world's superpowers and consequently embarked upon a Cold War.
One of the core narrative elements, (Operation Dandelion), is centered on a preemptive Nazi nuclear strike on the Japanese Home Islands. The Nazis "have the hydrogen bomb" and the ability to wipe out the Home Islands. Their nuclear energy capabilities also fuel extremely fast air travel and the colonization of the moon, Venus, and Mars.
After Adolf Hitler's syphilitic incapacitation, Martin Bormann, as Nazi Party Chancellor, assumes power as "Führer" of Germany. Bormann proceeds to create a colonial empire to increase Germany's "Lebensraum" by using technology to drain the Mediterranean Sea and convert it into farmland (see Atlantropa), while Arthur Seyss-Inquart also oversees the colonization of Africa and extermination of most of its inhabitants. Meanwhile, the Reich sends spaceships to colonize Mars and other parts of the Solar System.
Soon after the novel begins, "Führer" Bormann dies, initiating an internal power struggle between Joseph Goebbels, Reinhard Heydrich, Hermann Göring, and other top Nazis to succeed him as "Reichskanzler".
Characters.
"The Man in the High Castle" focuses on a loose collection of characters. Some of them know each other, while others are connected in more indirect ways as they all cope with living under totalitarianism. Three characters guide their lives based on the "I Ching":
Others believe different things:
Storylines.
The narrative storylines of the plot alternate among those of the characters, providing a broad picture of quotidian life in totalitarian America:
Story-within-the-story.
Several characters in "The Man in the High Castle" read the popular novel "The Grasshopper Lies Heavy", by Hawthorne Abendsen, whose title, putatively, derives from the Bible verse: "The grasshopper shall be a burden" (). Thus, "The Grasshopper Lies Heavy" constitutes a novel within a novel, wherein Abendsen writes of an alternate universe where the Axis powers lost WWII (1939–1947). For this reason, the Germans have banned it in the occupied U.S. Nevertheless, it is a widely read book in the Pacific and its publication is legal in the neutral countries.
"The Grasshopper Lies Heavy" postulates that President Franklin D. Roosevelt survives assassination and forgoes re-election in 1940, honoring George Washington's two-term limit. The next president, Rexford Tugwell, removes the U.S. Pacific fleet from Pearl Harbor, Hawaii, saving it from Japanese attack, which ensures that the U.S. enters World War II a well-equipped naval power. Great Britain retains most of its military-industrial strength, contributing more to the Allied war effort, leading to Field Marshal Erwin Rommel's defeat in North Africa; the British advance through the Caucasus to guide the Soviets to victory in the Battle of Stalingrad; Italy reneges on its membership in the Axis Powers and betrays them; British armor and the Red Army jointly conquer Berlin; and, at the end of the war, the Nazi leaders—including Adolf Hitler—are tried for their war crimes; the "Führer"'s last words are "Deutsche, hier steh' ich" ("Germans, here I stand"), in imitation of the priest Martin Luther.
Post-war, Churchill remains Britain's leader and, because of its military-industrial might, the British Empire does not collapse; the USA establishes strong business relations with Chiang Kai-shek's right-wing regime in China, after vanquishing the Communist Mao Zedong. The British Empire becomes racist and more expansionist post-war, while the U.S. outlaws Jim Crow, resolving its racism by the 1950s. Both changes provoke racialist-cultural tensions between the US and the UK, leading them to a Cold War for global hegemony between the two vaguely liberal, democratic, capitalist societies. Although the end of the novel is never depicted in the text, one character claims the book ends with the British Empire eventually defeating the US, becoming the world's only superpower.
The "I Ching" as literary device.
Phillip K. Dick used the "I Ching" to make decisions crucial to the plot of "The Man in the High Castle", and The "I Ching" is otherwise prominent in it. 
In the novel's representations, Eastern religions, cultural practices, and ideologies have spread to the fictional former U.S.A. as a result of Japan's cultural hegemony over the Pacific Coast. A number of Japanese and some American characters consult it, and then act in response to it; specifically, for instance, "The Man in the High Castle", Hawthorne Abendsen, consults it while writing "The Grasshopper Lies Heavy." As well, at story's end, Juliana Frink queries it in Abendsen's presence: "Why did it write "The Grasshopper Lies Heavy"?" and "What is the reader to learn from the novel?" The "I Ching" replies with Hexagram 61 ([中孚] zhōng fú) Chung Fu, "Inner Truth", describing the "true" state of the world. Every character in "The Man in the High Castle" is living a false reality; by implication, so is everyone in the non-fictional geopolitical world (where Great Britain declined and the U.S. became supreme).
Themes.
The interpretation and confusion of true and false realities is the principal theme of "The Man in the High Castle"; it is explored several ways:
The authorial Dick asks: "Who, and what, are the agents behind this interpenetration of true and false realities?" and "Why do those agents desire that the artifice of said realities be recognized?" These thematic questions also feature in the novels "Ubik", "VALIS", and "Flow My Tears, the Policeman Said".
"The Man in the High Castle" deals with: justice and injustice (Frink flees Nazi racist persecution); gender and power (the relationship between Juliana and Joe); the shame of cultural inferiority and identity (Childan's new-found confidence in American culture via his limited nostalgia and obsession with antiques); and the "effects" of fascism and racism upon "culture" (the devaluation of life under Nazi world totalitarianism and the presumptions of Japanese, German, and American racial superiority), cf. cultural hegemony.
Inspirations.
Later, Dick explained he conceived "The Man in the High Castle" when reading "Bring the Jubilee" (1953), by Ward Moore, which occurs in an alternate twentieth-century U.S. wherein the Confederate States of America won the American Civil War in the 1860s. In the acknowledgments, he mentions other influences: "The Rise and Fall of the Third Reich" (1960), by William L. Shirer; "Hitler: A Study in Tyranny" (1962), by Alan Bullock; "The Goebbels Diaries" (1948), Louis P. Lochner, translator; "Foxes of the Desert" (1960), by Paul Carrell; and the "I Ching" (1950), Richard Wilhelm, translator.
The acknowledgments have three references to traditional Japanese and Tibetan poetic forms; (i) volume one of the "Anthology of Japanese Literature" (1955), edited by Donald Keene, from which is cited the "haiku" on page 48; (ii) from "Zen and Japanese Culture" (1955), by Daisetz Teitaro Suzuki, from which is cited a "waka" on page 135; and (iii) the "Tibetan Book of the Dead" (1960), edited by W. Y. Evans-Wentz.
Nathanael West's "Miss Lonelyhearts" (1933) is also mentioned in the text, written before the Roosevelt assassination divergence point that separated the world of "The Man in the High Castle" from our own. In this novella, "Miss Lonelyhearts" is a male newspaper journalist who writes anonymous responses as an agony aunt to forlorn readers during the height of the Great Depression; hence, "Miss Lonelyhearts" tries to find consolation in religion, casual sex, rural vacations and work, none of which provide him with the sense of authenticity and engagement with the outside world that he needs. West's book is about the elusive quality of interpersonal relationships and quest for personal meaning at a time of political turmoil within the United States; given this, its underlying narrative design may be seen as a "mise en abyme" that parallels that of "The Man in the High Castle".
Reception.
Avram Davidson praised the novel as "a superior work of fiction", citing Dick's use of the "I Ching" as "fascinating". Davidson concluded that "It's all here—extrapolation, suspense, action, art, philosophy, plot, [and] character."
Adaptations.
Audiobook.
An audiobook version of "The Man in the High Castle" was released in 2008 by Blackstone Audio. The audiobook, read by Tom Weiner, is unabridged and runs approximately 8.5 hours over 7 CDs. A previous "Man in the High Castle" audiobook—read by George Guidall, unabridged, approximately 9.5 hours over 7 audio cassettes—was released in 1997.
Television.
In October 2010, it was announced that the BBC would co-produce a four-part TV adaptation of "The Man in the High Castle" for BBC One together with Headline Pictures, FremantleMedia Enterprises and Scott Free Films. Ridley Scott, who directed "Blade Runner", a loose adaptation of another Dick novel, "Do Androids Dream of Electric Sheep?", was to act as executive producer of the adaptation by Howard Brenton.
In February 2013, "Variety" reported that SyFy was adapting the book as a four-part miniseries, with Ridley Scott and Frank Spotnitz as executive producers, co-produced with Scott Free Prods., Headline Pictures and Electric Shepherd Prods.
In October 2014, "Deadline" and the "Yakima Herald" reported that Amazon's film production unit began filming the pilot episode of "The Man in the High Castle" in Roslyn, Washington, for a new television drama to air on the Amazon Prime web video streaming service.
The pilot episode was released by Amazon Studios on January 15, 2015, and was Amazon's "most watched pilot ever" according to Amazon Studios' vice president, Roy Price. Adi Robertson of , reporting on a press release from Amazon, writes that the pilot had been greenlit by Amazon to run as a series, describing it as being "set in an America that's been colonized by Japan and Germany after Axis powers won World War II," and as "deeply flawed, but… decent-looking and [a] moderately faithful adaptation of Philip K. Dick's 1962 novel." The greenlighting was also reported by "The Hollywood Reporter", and other venues.
Sequel.
In a 1976 interview, Dick said he planned to write a sequel novel to "The Man in the High Castle": "And so there's no real ending on it. I like to regard it as an open ending. It will segue into a sequel sometime." Dick said that he had "started several times to write a sequel", but progressed little, because he was too disturbed by his original research for "The Man in the High Castle" and could not mentally bear "to go back and read about Nazis again." He suggested that the sequel would be a collaboration with another author: "Somebody would have to come in and help me do a sequel to it. Someone who had the stomach for the stamina to think along those lines, to get into the head; if you're going to start writing about Reinhard Heydrich, for instance, you have to get into his face. Can you imagine getting into Reinhard Heydrich's face?"
Two chapters of the proposed sequel were published in a collection of essays about Dick titled "The Shifting Realities of Philip K. Dick". The chapters describe Gestapo officers reporting to Nazi Party officials about their time-travel visits to a parallel world in which the Nazi conquest has failed, but which contains nuclear weapons, available for the stealing by the Nazis back to their world. "Ring of Fire", describing the emergence of a hybrid Japanese–American culture, was a working title for the novel.
On occasion, Dick said that 1967's "The Ganymede Takeover" began as a sequel to "The Man in the High Castle", but that it did not coalesce as such; specifically, the Ganymedans occupying the Earth began as the Imperial Japanese occupying the conquered U.S.
Dick's novel "Radio Free Albemuth" also is reported to have started as a sequel to "The Man in the High Castle". Dick described the plot of this early version of "Radio Free Albemuth"—then titled "VALISystem A"—writing: "... a divine and loving ETI [extraterrestrial intelligence] ... help[s] Hawthorne Abendsen, the protagonist-author in ["The Man in the High Castle"], continue on in his difficult life after the Nazi secret police finally got to him... VALISystem A, located in deep space, sees to it that nothing, absolutely nothing, can prevent Abendsen from finishing his novel." The novel eventually evolved into a new story unrelated to "The Man in the High Castle." Dick ultimately abandoned the book; it went unpublished during his lifetime, though portions of it were salvaged and used for 1981's "VALIS." The full book was not published until 1985, three years after Dick's death.
Awards.
The acclaim afforded this novel was a career highpoint for Dick; as noted in his 1982 obituary in "The New York Times," "The Man in the High Castle" won a Science Fiction Achievement Award (Hugo Award) in 1963,
Further reading.
</dl>

</doc>
<doc id="45906" url="http://en.wikipedia.org/wiki?curid=45906" title="Exponential distribution">
Exponential distribution

In probability theory and statistics, the exponential distribution (a.k.a. negative exponential distribution) is the probability distribution that describes the time between events in a Poisson process, i.e. a process in which events occur continuously and independently at a constant average rate. It is a particular case of gamma distribution. It is the continuous analogue of the geometric distribution, and it has the key property of being memoryless. In addition to being used for the analysis of Poisson processes, it is found in various other contexts.
Note that the exponential distribution is not the same as the class of exponential families of distributions, which is a large class of probability distributions that includes the exponential distribution as one of its members, but also includes the normal distribution, binomial distribution, gamma distribution, Poisson, and many others.
Characterization.
Probability density function.
The probability density function (pdf) of an exponential distribution is
Alternatively, this can be defined using the Heaviside step function, "H"("x").
Here λ > 0 is the parameter of the distribution, often called the "rate parameter". The distribution is supported on the interval [0, ∞). If a random variable "X" has this distribution, we write "X" ~ Exp(λ).
The exponential distribution exhibits infinite divisibility.
Cumulative distribution function.
The cumulative distribution function is given by
Alternatively, this can be defined using the Heaviside step function, "H"("x").
Alternative parameterization.
A commonly used alternative parametrization is to define the probability density function (pdf) of an exponential distribution as
where β > 0 is mean, standard deviation, and scale parameter of the distribution, the reciprocal of the "rate parameter", λ, defined above. In this specification, β is a "survival parameter" in the sense that if a random variable "X" is the duration of time that a given biological or mechanical system manages to survive and "X" ~ Exp(β) then E["X"] = β. That is to say, the expected duration of survival of the system is β units of time. The parametrization involving the "rate" parameter arises in the context of events arriving at a rate λ, when the time between events (which might be modeled using an exponential distribution) has a mean of β = λ−1.
The alternative specification is sometimes more convenient than the one given above, and some authors will use it as a standard definition. This alternative specification is not used here. Unfortunately this gives rise to a notational ambiguity. In general, the reader must check which of these two specifications is being used if an author writes ""X" ~ Exp(λ)", since either the notation in the previous (using λ) or the notation in this section (here, using "β" to avoid confusion) could be intended. An example of this notational switch: reference uses λ for β.
Properties.
Mean, variance, moments and median.
The mean or expected value of an exponentially distributed random variable "X" with rate parameter λ is given by
In light of the examples given above, this makes sense: if you receive phone calls at an average rate of 2 per hour, then you can expect to wait half an hour for every call.
The variance of "X" is given by
so the standard deviation is equal to the mean.
The moments of "X", for "n" = 1, 2, ..., are given by
The median of "X" is given by
where ln refers to the natural logarithm. Thus the absolute difference between the mean and median is
in accordance with the .
Memorylessness.
An exponentially distributed random variable "T" obeys the relation
When "T" is interpreted as the waiting time for an event to occur relative to some initial time, this relation implies that, if "T" is conditioned on a failure to observe the event over some initial period of time "s", the distribution of the remaining waiting time is the same as the original unconditional distribution. For example, if an event has not occurred after 30 seconds, the conditional probability that occurrence will take at least 10 more seconds is equal to the unconditional probability of observing the event more than 10 seconds relative to the initial time.
The exponential distribution and the geometric distribution are the only memoryless probability distributions.
The exponential distribution is consequently also necessarily the only continuous probability distribution that has a constant Failure rate.
Quantiles.
The quantile function (inverse cumulative distribution function) for Exp(λ) is
The quartiles are therefore:
And as a consequence the interquartile range is ln(3)/λ.
Kullback–Leibler divergence.
The directed Kullback–Leibler divergence of formula_13 ('approximating' distribution) from formula_14 ('true' distribution) is given by
Maximum entropy distribution.
Among all continuous probability distributions with support formula_16 and mean formula_17, the exponential distribution with formula_18 has the largest differential entropy. In other words, it is the maximum entropy probability distribution for a random variate formula_19 which is greater than zero and for which formula_20 is fixed.
Distribution of the minimum of exponential random variables.
Let "X"1, ..., "X""n" be independent exponentially distributed random variables with rate parameters λ1, ..., λ"n". Then
is also exponentially distributed, with parameter
This can be seen by considering the complementary cumulative distribution function:
The index of the variable which achieves the minimum is distributed according to the law
Note that
is not exponentially distributed.
Parameter estimation.
Suppose a given variable is exponentially distributed and the rate parameter λ is to be estimated. Among the estimators of λ, the maximum likelihood estimator (MLE) and the uniformly minimum variance unbiased estimator (UMVUE) are formula_26 and formula_27, respectively. The one that minimizes the expected mean squared error is formula_28.
Maximum likelihood.
The likelihood function for λ, given an independent and identically distributed sample "x" = ("x"1, ..., "x""n") drawn from the variable, is:
where:
is the sample mean.
The derivative of the likelihood function's logarithm is:
Consequently the maximum likelihood estimate for the rate parameter is:
Although this is "not" an unbiased estimator of formula_33, formula_34 "is" an unbiased MLE estimator of formula_35 where formula_36 is the scale parameter defined in the 'Alternative parameterization' section above and the distribution mean.
Confidence intervals.
The 100(1 − α)% confidence interval for the rate parameter of an exponential distribution is given by:
which is also equal to:
where χ2"p","v" is the 100("p") percentile of the chi squared distribution with "v" degrees of freedom, n is the number of observations of inter-arrival times in the sample, and x-bar is the sample average. A simple approximation to the exact interval endpoints can be derived using a normal approximation to the "χ"2"p","v" distribution. This approximation gives the following values for a 95% confidence interval:
This approximation may be acceptable for samples containing at least 15 to 20 elements.
Bayesian inference.
The conjugate prior for the exponential distribution is the gamma distribution (of which the exponential distribution is a special case). The following parameterization of the gamma probability density function is useful:
The posterior distribution "p" can then be expressed in terms of the likelihood function defined above and a gamma prior:
Now the posterior density "p" has been specified up to a missing normalizing constant. Since it has the form of a gamma pdf, this can easily be filled in, and one obtains:
Here the parameter α can be interpreted as the number of prior observations, and β as the sum of the prior observations.
The posterior mean here is:
Generating exponential variates.
A conceptually very simple method for generating exponential variates is based on inverse transform sampling: Given a random variate "U" drawn from the uniform distribution on the unit interval (0, 1), the variate
has an exponential distribution, where "F" −1 is the quantile function, defined by
Moreover, if "U" is uniform on (0, 1), then so is 1 − "U". This means one can generate exponential variates as follows:
Other methods for generating exponential variates are discussed by Knuth and Devroye.
The ziggurat algorithm is a fast method for generating exponential variates.
A fast method for generating a set of ready-ordered exponential variates without using a sorting routine is also available.
Related distributions.
Other related distributions:
Applications of exponential distribution.
Occurrence of events.
The exponential distribution occurs naturally when describing the lengths of the inter-arrival times in a homogeneous Poisson process.
The exponential distribution may be viewed as a continuous counterpart of the geometric distribution, which describes the number of Bernoulli trials necessary for a "discrete" process to change state. In contrast, the exponential distribution describes the time for a continuous process to change state.
In real-world scenarios, the assumption of a constant rate (or probability per unit time) is rarely satisfied. For example, the rate of incoming phone calls differs according to the time of day. But if we focus on a time interval during which the rate is roughly constant, such as from 2 to 4 p.m. during work days, the exponential distribution can be used as a good approximate model for the time until the next phone call arrives. Similar caveats apply to the following examples which yield approximately exponentially distributed variables:
Exponential variables can also be used to model situations where certain events occur with a constant probability per unit length, such as the distance between mutations on a DNA strand, or between roadkills on a given road.
In queuing theory, the service times of agents in a system (e.g. how long it takes for a bank teller etc. to serve a customer) are often modeled as exponentially distributed variables. (The arrival of customers for instance is also modeled by the Poisson distribution if the arrivals are independent and distributed identically.) The length of a process that can be thought of as a sequence of several independent tasks follows the Erlang distribution (which is the distribution of the sum of several independent exponentially distributed variables).
Reliability theory and reliability engineering also make extensive use of the exponential distribution. Because of the "memoryless" property of this distribution, it is well-suited to model the constant hazard rate portion of the bathtub curve used in reliability theory. It is also very convenient because it is so easy to add failure rates in a reliability model. The exponential distribution is however not appropriate to model the overall lifetime of organisms or technical devices, because the "failure rates" here are not constant: more failures occur for very young and for very old systems.
In physics, if you observe a gas at a fixed temperature and pressure in a uniform gravitational field, the heights of the various molecules also follow an approximate exponential distribution, known as the Barometric formula. This is a consequence of the entropy property mentioned below.
In hydrology, the exponential distribution is used to analyze extreme values of such variables as monthly and annual maximum values of daily rainfall and river discharge volumes.
Prediction.
Having observed a sample of "n" data points from an unknown exponential distribution a common task is to use these samples to make predictions about future data from the same source. A common predictive distribution over future samples is the so-called plug-in distribution, formed by plugging a suitable estimate for the rate parameter λ into the exponential density function. A common choice of estimate is the one provided by the principle of maximum likelihood, and using this yields the predictive density over a future sample "x""n"+1, conditioned on the observed samples "x" = ("x"1, ..., "xn") given by
The Bayesian approach provides a predictive distribution which takes into account the uncertainty of the estimated parameter, although this may depend crucially on the choice of prior.
A predictive distribution free of the issues of choosing priors that arise under the subjective Bayesian approach is
which can be considered as
The accuracy of a predictive distribution may be measured using the distance or divergence between the true exponential distribution with rate parameter, λ0, and the predictive distribution based on the sample "x". The Kullback–Leibler divergence is a commonly used, parameterisation free measure of the difference between two distributions. Letting Δ(λ0||"p") denote the Kullback–Leibler divergence between an exponential with rate parameter λ0 and a predictive distribution "p" it can be shown that
where the expectation is taken with respect to the exponential distribution with rate parameter λ0 ∈ (0, ∞), and ψ( · ) is the digamma function. It is clear that the CNML predictive distribution is strictly superior to the maximum likelihood plug-in distribution in terms of average Kullback–Leibler divergence for all sample sizes "n" > 0.

</doc>
<doc id="45907" url="http://en.wikipedia.org/wiki?curid=45907" title="Beyond This Horizon">
Beyond This Horizon

Beyond This Horizon is a science fiction novel by Robert A. Heinlein. It was originally published as a two-part serial in "Astounding Science Fiction" (April, May 1942, under the pseudonym Anson MacDonald) and then as a single volume by Fantasy Press in 1948.
Overview.
The novel depicts a world where genetic selection for increased health, longevity, and intelligence has become so widespread that the unmodified 'control naturals' are a carefully managed and protected minority. Dueling and the carrying of arms is a socially accepted way of maintaining civility in public; a man can wear distinctive clothing to show his unwillingness to duel, but this results in an inferior social status. The world has become an economic utopia; the "economic dividend" is so high that work has become optional. The chief economic problem is in fact using up the economic surplus: many high-quality goods actually cost "less" than those of lower quality. Many people use lower-quality goods as status symbols. The government invests heavily in scientific research, but this has the side effect of further increasing productivity a decade or more later, so long-term projects with no expected economic return are favored above anything but medical research, on the theory that longer lifespans will consume more surplus.
The story's protagonist, Hamilton Felix (surname first), is the archetypal superman. Felix possesses a superhuman physique, an intellect to match it, and can expect to live centuries without any form of medical assistance. Authorities aware of his genetic makeup consider him to be the most advanced human in existence—the "star line". However, he lacks eidetic memory, which disqualifies him for what many consider to be humanity's most important occupation: that of an "encyclopedic synthesist", one who analyzes the sum total of human knowledge for untapped potential. As such, he finds his life—and the society he lives in—to be enjoyable but meaningless. However, when one of these synthesists seeks him out, inquiring when he plans to continue his line, he finds himself drawn into an adventure which not only gives him purpose but convinces him that his society is worth saving after all.
Major themes in the novel are reincarnation, the immortality of the soul, and telepathy. Hamilton Felix is the product of generations of genetic engineering. He is almost but not quite the perfect human. In the second half of the book his genetically engineered son is born. The son is the climax of generations of genetic engineering and selective breeding, and is a genetically perfect human. As the son grows he begins to develop almost superhuman mental abilities and a surprising telepathic ability. As the novel draws to a close, it becomes apparent that the son senses that Hamiton Felix's second child, a daughter, is the reincarnation of a wise elderly government official who foresaw her own death and arranged to die shortly before Felix's daughter was born. This official understood that the soul is reincarnated, and in preparation for her own death and reincarnation she was instrumental in the genetic engineering of the son and daughter.
Reception.
Boucher and McComas characterized "Beyond This Horizon" as among "the finest science fiction novels of the modern crop." P. Schuyler Miller reviewed the novel favorably, saying "in true Heinlein manner the basic theme of the book smashes the screen of action only in the closing pages."

</doc>
<doc id="45908" url="http://en.wikipedia.org/wiki?curid=45908" title="Rocket Ship Galileo">
Rocket Ship Galileo

Rocket Ship Galileo is a science fiction novel by Robert A. Heinlein, published in 1947, about three teenagers who participate in a pioneering flight to the Moon. It was the first in the Heinlein juveniles, a long and successful series of science fiction novels published by Scribner's. The novel was originally envisioned as the first of a series of books called "Young Rocket Engineers". It was initially rejected by publishers, because going to the moon was "too far out".
Plot summary.
After World War II, three teenage boy rocket experimenters are recruited by one boy's uncle, Dr. Cargraves, a Nobel Prize-winning physicist who had worked on the Manhattan Project, to refit a conventionally powered surplus "mail rocket". It is to be converted to run on a thorium nuclear pile which boils zinc as a propellant. They use a cleared area in a military weapons test range in the desert for their work, despite prying and sabotage attempts by unknown agents.
Upon completion of the modifications, they stock the rocket, which they name the "Galileo", and take off for the Moon, taking approximately 3 days to arrive. After establishing a semi-permanent structure based on a Quonset hut, they claim the moon on behalf of the United Nations.
As they set up a radio to communicate with the Earth they pick up a local transmission, the sender of which promises to meet them. Instead, their ship is bombed. Fortunately, they are able to hole up undetected in their hut and succeed in ambushing the other ship when it lands, capturing the pilot. They discover that there is a Nazi base on the Moon. They bomb it from their captured ship and land. One survivor is found, revived, and questioned.
The boys also find evidence of an ancient lunar civilization, and postulate that the craters of the moon were formed not by impacts from space, but by nuclear bombs that destroyed the alien race.
When the base's Nazi leader shoots the pilot in order to silence him, Cargraves convenes a trial and finds him guilty of murder. Cargraves prepares to execute the prisoner by ejecting him into vacuum, mostly as a bluff for information on how to fly the base's spaceship. The Nazi capitulates in the airlock and teaches them how to fly the ship back to Earth.
The boys radio the location of the hidden Nazi base on Earth to the authorities, leading to its destruction; they return as heroes.
Adaptations.
The 1950 movie "Destination Moon" was loosely based on "Rocket Ship Galileo", and Heinlein was one of three co-authors of the script. The film's plot also resembles that of "The Man Who Sold the Moon", which Heinlein wrote in 1949 but did not publish until 1951.
Critical reception.
Surveying Heinlein's juvenile novels, Jack Williamson noted that while "Rocket Ship Galileo" remains "readable, with Heinlein's familiar themes already emerging," it was a "sometimes fumbling experiment. ... The plot is often trite, and the characters are generally thin stereotypes." Robert Wilfred Franson said that "Heinlein wants there always to be young people of the right mind and character to seize such opportunities. His novels went a long way toward educating such a class of people, and still are doing so." Andrew Baker wrote: "'Rocket Ship Galileo' shares with numerous works composed before the advent of the actual Space Program a gross underestimation of the huge costs and investment of resources needed for any jaunt outside Earth's gravitational field. (...) The idea of private people (boys in this case) being able to just take off to the Moon on their own can ultimately be traced - like so many Science Fiction themes - to the fertile mind of H.G. Wells and to the two English gentlemen quietly taking off to the Moon in 'The First Men in the Moon'. (...) The politics of 'Galileo' are still those of the World War II anti-Nazi Alliance, not of the emerging Cold War. Had it been written a few years later, the villains would have likely been Russian Communists".

</doc>
<doc id="45912" url="http://en.wikipedia.org/wiki?curid=45912" title="Space Cadet">
Space Cadet

Space Cadet is a 1948 science fiction novel by Robert A. Heinlein about Matt Dodson, who joins the Space Patrol to help preserve peace in the Solar System. The story translates the standard military academy story into outer space: a boy from Iowa goes to officer school, sees action and adventure, shoulders responsibilities far beyond his experience, and becomes a man. It was published as the second of the series of Heinlein juveniles and inspired the Tom Corbett, Space Cadet media empire, including the 1950s television series and radio show which made "Space Cadet" a household phrase whose meaning later shifted in popular culture.
Plot summary.
In 2075, teenager Matt Dodson applies to join the prestigious Space Patrol. After a number of physical, mental, and ethical tests, he is accepted as a cadet. He makes friends with fellow recruits William 'Tex' Jarman, Venus-born Oscar Jensen, and Pierre Armand from Ganymede. His first roommate is Girard Burke, the arrogant son of a wealthy spaceship builder. They are transported to the orbiting school ship PRS "James Randolph" for further training.
Burke eventually either resigns or is asked to leave, and goes into the merchant service, but the remainder do well enough to be assigned to working Patrol ships. Dodson, Jarman and Jensen ship out on the "Aes Triplex". Their first real mission is to help search for a missing research vessel, the "Pathfinder", in the Asteroid Belt. They find it, but all aboard are dead, the unlucky victims of a fast-moving meteor that punctured the ship when the armored outer airlock door was open. Before the accident, a researcher on the "Pathfinder" had found evidence that the planet which blew up to form the asteroids was inhabited by an intelligent species, and that the explosion had been artificial. The captain of the "Aes Triplex" transfers half the crew to the repaired "Pathfinder" so that they can take the ship and the news of the startling discovery back to Earth quickly. With the remainder (including all three cadets), he continues his patrol.
Then, he receives an urgent message to investigate an incident on Venus. He sends Lieutenant Thurlow and the cadets to the planet's surface. The lander touches down on a sinkhole, barely giving the crew enough time to get out before it disappears in the mud. With Thurlow comatose, injured when the lander fell over, Jensen assumes command. He contacts the sentient usually-friendly Venerians, but the entire party is taken captive. They soon find out why.
These particular natives had never seen human beings before, until old classmate Burke showed up in a prospecting ship. He had taken the matriarch of the local clan hostage when she refused to give him permission to exploit a rich deposit of radioactive ores. The locals promptly attacked the ship and killed his crew; Burke managed to send a message for help before being taken prisoner.
Jensen skillfully gains the matriarch's trust and convinces her that they are honorable and civilized, unlike Burke, and the Patrolmen are released. Neither the lander nor Burke's ship is flightworthy. To their amazement, she takes the stranded humans to the carefully preserved "Astarte", the legendary first ship to set out for Venus over a century before and thought to have been lost en route. According to the log, the crew perished from disease. With the help of the natives, the cadets recommission the ship and fly it back to (human) civilization at Venus's South Pole colony. Dodson is initially disappointed when they are not treated as heroes—but then he realizes that what they accomplished was simply what was expected of Patrolmen.
Themes.
The Space Patrol is entrusted by the worldwide Earth government with a monopoly on nuclear weapons, and is expected to maintain a credible threat to drop them on Earth from orbit as a deterrent against breaking the peace. Matt, on a visit home, causes a family argument when his parents refuse to believe that the Patrol—and especially their son—would actually bomb Iowa.
The cadets are expected to renounce their loyalty to their respective countries and replace it by a wider allegiance to humanity as a whole and to the sentient species of the Solar System. They are told the stories of four Patrol heroes/martyrs who exemplify this quality. One of them, Rivera, leaves orders to annihilate his hometown if he is held captive there during negotiations. Heinlein later expanded another of these anecdotes into "The Long Watch".
The young, idealistic Matt feels that he should be able, if the need arose, to emulate Rivera and destroy his own Iowa hometown. His father tells him such a need would never arise, since the Patrol's cosmopolitan allegiance is little more than a sham and in fact it is controlled by the "North American Federation" and serves its interests. Later, Matt's mentor in the Patrol makes him understand that if such an unlikely dilemma should arise, his commanding officer would lock him in his room rather than expect him to participate in the attack. The mentor uses this scenario to force Matt to confront the personal and political issues involved in the institutional control of atomic weapons in a more mature way.
Written almost a decade before the U.S. Civil Rights Movement, and at a time when non-white characters were almost entirely absent from science fiction, the book also explores the theme of racism, both literally, in discussions about the cosmopolitan racial makeup of the (all-male) Patrol, and metaphorically, in its description of conflict with the Venerians. Venus is described as intensely hot and (incorrectly, as is now known) swampy, but habitable. The Venerians are at first thought to be primitive, but it is later revealed that they have a high level of technological sophistication, though developed along radically different lines than that of humans.
There is also a subplot revolving around the issue of what it means to be a good soldier. Discouraged by the intellectual demands of his Patrol training, and attracted to the glamor and esprit de corps of the Marines, Matt requests a transfer, but is dissuaded by his mentor. The mentor, dividing human motivations into three types, explains that the Patrol, which has the responsibility of holding the ultimate weapon and keeping overall peace, is manned by a certain sort of person, the man of ideals (its motto is "Quis custodiet ipsos custodes?)." In contrast, the Marines, the service branch who deal with ordinary military affairs, are trained to prize unquestioning loyalty and bravery as the highest ideals, and are deliberately recruited from the type of person who seeks glory and excitement. Matt belongs to the former category. The Merchant service, by implication, is for a third category, those motivated by economic concerns—which is where Burke fits in.
The novel contains an early description of a mobile phone: 
Matt dug a candy bar out of his pouch, split it and gave half to Jarman, who accepted it gratefully. "You're a pal, Matt, I've been living on my own fat ever since breakfast -- and that's risky. Say your telephone is sounding."
"Oh!" Matt fumbled in his pouch and got out his phone. Hello?"
 Later it is stated that the phone "was limited by its short range to the neighborhood of an earth-side [i.e. terrestrial] relay office.”
Critical reception.
Surveying Heinlein's juvenile novels, Jack Williamson characterized "Space Cadet" as "a long step forward. ... The characters are stronger [and] the background is carefully built, original, and convincing, the story suspenseful enough." Williamson noted that Heinlein was "perfecting the "bildungsroman" form that shapes the whole series."
P. Schuyler Miller gave the book a favorable review as "a first-rate historical novel of the near future," saying "So subtly has the scientific detail been interwoven with plot and action that the reader never realizes how painstakingly it has been worked out."
Adaptations.
The novel inspired Joseph Greene of Grosset & Dunlap to develop the "Tom Corbett, Space Cadet" comic books, television series, radio show, comic strip, and novels that were popular in the early 1950s. Greene had originally submitted a radio script for "Tom Ranger and the Space Cadets" on January 16, 1946, but it remained unperformed when Heinlein's novel was published.
As Greene had submitted his radio script for "Tom Ranger and the Space Cadets" on January 16, 1946, prior to Robert A. Heinlein's 1948 Space Cadet but Heinlein influenced the evolution of "Tom Ranger" into "Tom Corbett" and launched his student astronaut title's common mention, they share credit for the popularity of both formal and later slang uses of "space cadet."
The movie "Star Trek" (2009) has a similar story, in which a boy from Iowa goes to space officer school, sees action and adventure in space, shoulders responsibilities far beyond his experience, and becomes a man.
In Popular Culture.
The "Tom Corbett, Space Cadet" television series and radio show made "space cadet" a household phrase. By 1955, Jackie Gleason spoke the phrase on "The Honeymooners" television show in an episode called 'TV or not to TV', original air date October 1, 1955.
The popular meanings of "space cadet" later shifted in popular culture away from astronaut-in-training to indicate, by the 1960s, an "eccentric person disconnected with reality" (often implying an intimacy with hallucinogenic drugs) although by the 2010s, drug abuse was rarely implied by this phrase, nor was low intelligence implied; "space cadet" was more simply associated with "spacing out," wandering from present concerns, especially of others present, and being a "space case" with its alliterative rhyme. Both the "trainee astronaut" and "person regarded as being out of touch with reality" entered the Oxford Dictionary for English language, though by 2014 Oxford notes that in American English, the phrase had also recouped the positive connotations originally meant by Heinlein and Joseph Greene, the Tom Corbett, Space Cadet writer: "An enthusiast for space travel, typically a young person."

</doc>
<doc id="45913" url="http://en.wikipedia.org/wiki?curid=45913" title="Red Planet">
Red Planet

Red Planet is a nickname for the planet Mars, due to its surface color.
It may also refer to:

</doc>
<doc id="45915" url="http://en.wikipedia.org/wiki?curid=45915" title="Humpty Dumpty">
Humpty Dumpty

Humpty Dumpty is a character in an English nursery rhyme, probably originally a riddle and one of the best known in the English-speaking world. Though not explicitly described, he is typically portrayed as an anthropomorphic egg. The first recorded versions of the rhyme date from late eighteenth century England and the tune from 1870 in James William Elliott's "National Nursery Rhymes and Nursery Songs". Its origins are obscure and several theories have been advanced to suggest original meanings.
The character of Humpty Dumpty was popularised in the United States by actor George L. Fox (1825–77). As a character and literary allusion he has appeared or been referred to in a large number of works of literature and popular culture, particularly Lewis Carroll's "Through the Looking-Glass" (1872). The rhyme is listed in the Roud Folk Song Index as No. 13026.
Lyrics and melody.
The rhyme is one of the best known and most popular in the English language. The most common modern text is:
<poem>Humpty Dumpty sat on a wall,
Humpty Dumpty had a great fall.
All the king's horses and all the king's men
Couldn't put Humpty together again.</poem>
It is a single quatrain, with external rhymes that follow the pattern of AABB and with a trochaic metre, which is common in nursery rhymes. The melody commonly associated with the rhyme was first recorded by the composer and nursery rhyme collector James William Elliott in his "National Nursery Rhymes and Nursery Songs" (London, 1870). The Roud Folk Song Index, which catalogues folk songs and their variations by number, classifies the song as 13026.
Origins.
The earliest known version was published in Samuel Arnold's "Juvenile Amusements" in 1797, with the lyrics:
<poem>Humpty Dumpty sat on a wall,
Humpty Dumpty had a great fall.
Four-score Men and Four-score more,
Could not make Humpty Dumpty where he was before.</poem>
A manuscript addition to a copy of "Mother Goose's Melody" published in 1803 has the modern version with a different last line: "Could not set Humpty Dumpty up again". It was published in 1810 in a version of "Gammer Gurton's Garland" as:
<poem>
Humpty Dumpty sate ["sic"] on a wall,
Humpti Dumpti ["sic"] had a great fall;
Threescore men and threescore more,
Cannot place Humpty dumpty as he was before.
</poem>
In 1842 James Orchard Halliwell published a collected version as;
<poem>
Humpty Dumpty lay in a beck.
With all his sinews around his neck;
Forty Doctors and forty wrights
Couldn't put Humpty Dumpty to rights!
</poem>
According to the "Oxford English Dictionary" the term "humpty dumpty" referred to a drink of brandy boiled with ale in the seventeenth century. The riddle probably exploited, for misdirection, the fact that "humpty dumpty" was also eighteenth-century reduplicative slang for a short and clumsy person. The riddle may depend on the assumption that, whereas a clumsy person falling off a wall might not be irreparably damaged, an egg would be. The rhyme is no longer posed as a riddle, since the answer is now so well known. Similar riddles have been recorded by folklorists in other languages, such as "Boule Boule" in French, "Lille Trille" in Swedish and Norwegian and "Runtzelken-Puntzelken" or "Humpelken-Pumpelken" in different parts of Germany; although none is as widely known as Humpty Dumpty is in English.
Meaning.
The rhyme does not explicitly state that the subject is an egg, possibly because it may have been originally posed as a riddle. There are also various theories of an original "Humpty Dumpty". One, advanced by Katherine Elwes Thomas in 1930 and adopted by Robert Ripley, posits that Humpty Dumpty is King Richard III of England, depicted in Tudor histories, and particularly in Shakespeare's play, as humpbacked and who was defeated, despite his armies at Bosworth Field in 1485. However, the term "humpback" was not recorded until the eighteenth century, and no direct evidence linking the rhyme with the historical figure has been advanced.
The suggestion that Humpty Dumpty was a "tortoise" siege engine, an armoured frame, used unsuccessfully to approach the walls of the Parliamentary held city of Gloucester in 1643 during the Siege of Gloucester in the English Civil War, was put forward in 1956 by Professor David Daube in "The Oxford Magazine" of 16 February 1956, on the basis of a contemporary account of the attack, but without evidence that the rhyme was connected. The theory, part of an anonymous series of articles on the origin of nursery rhymes, was widely acclaimed in academia, but was derided by others as "ingenuity for ingenuity's sake" and declared to be a spoof. The link was nevertheless popularised by a children's opera "All the King's Men" by Richard Rodney Bennett, first performed in 1969.
From 1996 the website of the Colchester tourist board attributed the origin of the rhyme to a cannon recorded as used from the church of St Mary-at-the-Wall by the Royalist defenders in the siege of 1648. In 1648 Colchester was a walled town with a castle and several churches and was protected by the city wall. The story given was that a large cannon, which the website claimed was colloquially called Humpty Dumpty, was strategically placed on the wall. A shot from a Parliamentary cannon succeeded in damaging the wall beneath Humpty Dumpty which caused the cannon to tumble to the ground. The Royalists, or Cavaliers, "all the King's men", attempted to raise Humpty Dumpty on to another part of the wall, but because the cannon was so heavy "All the King's horses and all the King's men couldn't put Humpty together again". In his 2008 book "Pop Goes the Weasel: The Secret Meanings of Nursery Rhymes" author Albert Jack claimed that there were two other verses supporting this claim. Elsewhere he claimed to have found them in an "old dusty library, [in] an even older book", but did not state what the book was or where it was found. It has been pointed out that the two additional verses are not in the style of the seventeenth century, or the existing rhyme, and that they do not fit with the earliest printed version of the rhyme, which do not mention horses and men.
In "Through the Looking-Glass".
Humpty appears in Lewis Carroll's "Through the Looking-Glass" (1872), where he discusses semantics and pragmatics with Alice.
    "I don't know what you mean by 'glory,' " Alice said. 
    Humpty Dumpty smiled contemptuously. "Of course you don't—till I tell you. I meant 'there's a nice knock-down argument for you!' "
    "But 'glory' doesn't mean 'a nice knock-down argument'," Alice objected.
    "When "I" use a word," Humpty Dumpty said, in rather a scornful tone, "it means just what I choose it to mean—neither more nor less."
    "The question is," said Alice, "whether you "can" make words mean so many different things."
    "The question is," said Humpty Dumpty, "which is to be master—that's all."
    Alice was too much puzzled to say anything, so after a minute Humpty Dumpty began again. "They've a temper, some of them—particularly verbs, they're the proudest—adjectives you can do anything with, but not verbs—however, "I" can manage the whole lot! Impenetrability! That's what "I" say!"
This passage was used in Britain by Lord Atkin in his dissenting judgement in the seminal case "Liversidge v. Anderson" (1942), where he protested about the distortion of a statute by the majority of the House of Lords. It also became a popular citation in United States legal opinions, appearing in 250 judicial decisions in the Westlaw database as of 19 April 2008[ [update]], including two Supreme Court cases ("TVA v. Hill" and "Zschernig v. Miller").
It has been suggested by A. J. Larner that Carroll's Humpty Dumpty had prosopagnosia on the basis of his description of his finding faces hard to recognise. 
    "The face is what one goes by, generally," Alice remarked in a thoughtful tone.
    "That's just what I complain of," said Humpty Dumpty. "Your face is the same as everybody has—the two eyes,—" (marking their places in the air with his thumb) "nose in the middle, mouth under. It's always the same. Now if you had the two eyes on the same side of the nose, for instance—or the mouth at the top—that would be "some" help."
In popular culture.
Humpty Dumpty has become a highly popular nursery rhyme character. American actor George L. Fox (1825–77) helped to popularise the character in nineteenth-century stage productions of pantomime versions, music and rhyme. The character is also a common literary allusion, particularly to refer to a person in an insecure position, something that, once broken, would be difficult to reconstruct, or a short and fat person. In addition to his appearance in "Through the Looking-Glass" as a character, Humpty Dumpty has been used in a large range of literary works, including L. Frank Baum's "Mother Goose in Prose" (1901), where the rhyming riddle is devised by the daughter of the king, having witnessed Humpty's "death" and her father's soldiers' efforts to save him. In Neil Gaiman's early short story "The Case of the Four and Twenty Blackbirds", the Humpty Dumpty story is turned into a film noir-style hardboiled crime story, involving also Cock Robin, the Queen of Hearts, Little Bo Peep, Old Mother Hubbard and other characters from popular nursery rhymes. Robert Rankin used Humpty Dumpty as one victim of a serial fairy-tale character murderer in "The Hollow Chocolate Bunnies of the Apocalypse" (2002). Jasper Fforde included Humpty Dumpty in two of his novels, "The Well of Lost Plots" (2003) and "The Big Over Easy" (2005), which use him respectively as a ringleader of dissatisfied nursery rhyme characters threatening to strike and as the victim of a murder.
The rhyme has also been used as a reference in more serious literary works, including as a recurring motif of the Fall of Man in James Joyce's 1939 novel "Finnegans Wake". Robert Penn Warren's 1946 American novel "All the King's Men", the story of populist politician Willie Stark's rise to the position of governor and eventual fall, based on the career of the corrupt Louisiana Senator Huey Long, won the 1947 Pulitzer Prize. It was made into a film "All the King's Men", which won the 1949 Academy Award for best motion picture. This was echoed in Carl Bernstein and Bob Woodward's book "All the President's Men", about the Watergate scandal, referring to the failure of the President's staff to repair the damage once the scandal had leaked out. It was filmed as "All the President's Men" in 1976, starring Robert Redford and Dustin Hoffman. Similarly, Humpty Dumpty is referred to in Paul Auster's 1985 novel "City of Glass", when two characters discuss him as "the purest embodiment of the human condition" and quote extensively from "Through the Looking Glass".
It has also been used as a common motif in popular music, including Hank Thompson's "Humpty Dumpty Heart" (1948), The Monkees' "All the King's Horses" (1966), Aretha Franklin's "All the King's Horses" (1972). and Travis's "The Humpty Dumpty Love Song" (2001). In jazz, Ornette Coleman and Chick Corea wrote different compositions, both incidentally titled "Humpty Dumpty" (in Corea's case, however, it is a part of a concept album inspired by Lewis Carroll, called "The Mad Hatter", 1978). The song "GodEatGod" by Marilyn Manson on the assassination of John F. Kennedy contains a line "Dear John and all the King's men can't put your head together again", in reference to Humpty Dumpty.
In science.
Humpty Dumpty has been used to demonstrate the second law of thermodynamics. The law describes a process known as entropy, a measure of the number of specific ways in which a system may be arranged, often taken to be a measure of "disorder". The higher the entropy, the higher the disorder. After his fall, and subsequent shattering, the inability to put him together again is representative of this principle, as it would be highly unlikely, though not impossible, to return him to his earlier state of lower entropy, as the entropy of an isolated system never decreases.

</doc>
<doc id="45918" url="http://en.wikipedia.org/wiki?curid=45918" title="Between Planets">
Between Planets

Between Planets is a science fiction novel by Robert A. Heinlein, originally serialized in "Blue Book" magazine in 1951 as "Planets in Combat". It was published in hardcover that year by Scribner's as part of the Heinlein juveniles.
Plot summary.
A young man named Don Harvey leaves his dude ranch high school on Earth to go to his scientist parents on Mars. He visits an old family friend who asks him to deliver a ring to his father, but they are both later arrested by security forces. Harvey is released and given his ring back, after it has been examined; he is told that his friend has died of "heart failure." It is only later that he realizes that all deaths can be described that way.
Harvey boards a shuttle to a space station orbiting the Earth. The station doubles as a transshipment terminus and a military base, armed with missiles to keep restive nations in check. On the trip up, he befriends one of his fellow passengers, a Venusian "dragon" named Sir Isaac Newton. Sir Isaac is a renowned physicist who can speak English using a portable device.
Harvey gets caught up in the Venusian war of independence when the station is captured by the colonials in a surprise raid. Most of the other travelers are sent back to Earth, while a few decide to join the rebels. Harvey is in a quandary. The spaceship to Mars has been confiscated, but he remains determined to get there, by way of Venus if necessary. Because he was born in space, with one parent from Venus and the other from Earth, he claims Venusian citizenship; more importantly, Sir Isaac vouches for him. He is allowed to tag along, which turns out to be very fortunate for Harvey. The rebels blow up the station to stir up trouble for the Earth government. When the shuttle returns to Earth with its radios disabled, the military assumes it has been booby-trapped and destroys it, killing all aboard.
On his arrival on Venus, Harvey finds that his Earth-backed money is now worthless. A banker lends him money, telling him to pay it forward. He gets a job washing dishes for his keep for Charlie, a Chinese immigrant who runs a small restaurant. He befriends a young woman, Isobel, when he tries to send a message to his parents. However, communication with Mars has been cut due to the hostilities. Harvey settles in to wait out the war, when the war comes to him.
Earth sends a military force to put down the rebellion. The Venusian ships are destroyed in orbit and the ground forces are routed. Charlie is killed resisting the occupying soldiers. Harvey is rounded up and questioned by a senior security officer, who is very eager to get his hands on Harvey's ring. Luckily, Harvey had given it to Isobel for safekeeping and he does not know where she is or whether she is even alive. Before he can be interrogated with drugs, he escapes and joins the Venusian guerrilla forces.
Harvey becomes an effective commando. In time, he is tracked down by the leaders of the resistance, who turn out to also be looking for the ring. Isobel and her father (who is an important member of the rebels) are safe at the very base where Harvey is taken.
The seemingly valueless ring turns out to be carrying the secret of scientific breakthroughs resulting from archeological studies of an extinct alien civilization on Mars. With Sir Isaac's assistance, it is used to build an advanced spaceship that is much faster than any other vessel in existence, with revolutionary weapons and defenses also derived from the new technology. As the only combat veteran with knowledge of the ship, christened "Little David", Harvey is recruited for its maiden voyage, manning a self-destruct mechanism, with strict orders to blow up the ship if it is in danger of being captured. "Little David" intercepts and defeats a group of warships on their way to Mars to crush the revolt there. Afterwards, Harvey is probably reunited with his parents, although the story ends before then.
Astronomy.
Like many science fiction works of its period, the novel depicts both Venus and Mars as suitable for human habitation. Since no interplanetary space probes had been launched at the time, neither the extreme pressure and temperature at the surface of Venus, nor the extremely low atmospheric pressure at the surface of Mars, were known to science. Even the length of the day on Venus was not yet known.
Reception.
Groff Conklin reviewed the novel favorably, calling it "a magnificently real and vivid Picture of the Possible." Boucher and McComas named it among the best sf novels of 1951, characterizing it as "more mature than most 'adult' science fiction.". P. Schuyler Miller praised the novel as "very smoothly and logically put together," although he noted that it lacked the level of "elaboration of background detail" that he expected from Heinlein."
Surveying Heinlein's juvenile novels, Jack Williamson characterized "Between Planets" as "mov[ing] the series still farther from its juvenile origins toward grownup concerns." Although describing the plot as "pretty traditional space opera," he praised the novel for its "ably drawn" characters, its "well-imagined" background, and its "story told with zest." Williamson also noted that Heinlein closed the novel "with a vigorous statement of his unhappiness with 'the historical imperative'" leading to the loss of individual freedom as governmental organizations grew."
Cartoon.
"Between Planets" was serialized in "Boys' Life" magazine in 1978 as a monthly cartoon series. The story took some liberties — for instance, the "Dragons" of Venus were portrayed as humanoids and the planets' names were changed — but the spirit of the story was relatively faithful.

</doc>
<doc id="45919" url="http://en.wikipedia.org/wiki?curid=45919" title="Academy Award for Best Dance Direction">
Academy Award for Best Dance Direction

The Academy Awards for Best Dance Direction (1935-1937 only)

</doc>
<doc id="45920" url="http://en.wikipedia.org/wiki?curid=45920" title="Augusta, Maine">
Augusta, Maine

Augusta is the capital of the U.S. state of Maine and the county seat of Kennebec County.
The city's population was 19,136 at the 2010 census, making it the third-smallest state capital (after Montpelier, Vermont and Pierre, South Dakota) and the eighth-largest city in Maine. Located on the Kennebec River at the head of tide, Augusta is home to the University of Maine at Augusta.
History.
The area was first explored by the ill-fated Popham Colony in September 1607. It was first inhabited by English settlers from the Plymouth Colony in 1629 as a trading post on the Kennebec River. The settlement was known by its Indian name—Cushnoc (or Coussinoc or Koussinoc), meaning "head of tide." Fur trading was at first profitable, but with Indian uprisings and declining revenues, the Plymouth Colony sold the Kennebec Patent in 1661. Cushnoc would remain unoccupied for the next 75 years. This area was inhabited by the Canibas Indians. During the 17th century they were on friendly terms with the English settlers in the region.
A hotbed of Abenaki hostility toward British settlements was located further up the Kennebec at Norridgewock. In 1722, the tribe and its allies attacked Fort Richmond (now Richmond) and destroyed Brunswick. In response, Norridgewock was sacked in 1724 during Dummer's War, when English forces gained tentative control of the Kennebec. In 1754, a blockhouse named Fort Western (now the oldest wooden fort in America), was built at Cushnoc on the eastern bank. It was intended as a supply depot for Fort Halifax upriver, as well as to protect its own region. In 1775, Benedict Arnold and his 1,100 troops would use Fort Western as a staging area before continuing their journey up the Kennebec to the Battle of Quebec.
Cushnoc was incorporated as part of Hallowell in 1771. Known as "the Fort," it was set off and incorporated by the Massachusetts General Court in February 1797 as Harrington. In August, however, the name changed to Augusta after Augusta Dearborn, daughter of Henry Dearborn. In 1799, it became county seat for newly created Kennebec County. Maine became a state in 1820 and Augusta was designated its capital in 1827. The Maine State Legislature continued meeting in Portland, however, until completion in 1832 of the new Maine State House designed by Charles Bulfinch. Augusta was chartered as a city in 1849. After being named the state capital and the introduction of new industry, the city flourished. In 1840 and 1850, the city ranked among the 100 largest urban populations. The next decade, however, the city was quickly bypassed by rapidly growing metropolises in the Midwest.
Excellent soil provided for agriculture, and water power from streams provided for industry. In 1837, a dam was built across the Kennebec where the falls drop 15 feet at the head of tide. By 1838, 10 sawmills were contracted. With the arrival of the Kennebec & Portland Railroad in 1851, Augusta became an even more productive mill town. In 1883, the property of A. & W. Sprague Company was purchased by the Edwards Manufacturing Company, which erected extensive brick mills for manufacturing cotton textiles. In the late 19th century, a paper and pulp plant was constructed. Other Augusta firms produced lumber, sash, doors, window shutters, broom handles, stone cutters' tools, shoes, headstones, ice and furniture. The city developed as a publishing and shipping center. Today, government and post-secondary education are important businesses.
In the 19th century, Augusta got a regular steamboat service and the railroad. The city installed gas lights in 1859. A telephone service was available in 1880 and a local hospital in 1898. In the early 20th century, Augusta built two movie houses and a film production studio.
For much of Augusta's history, the central business district was on and near Water Street on the west bank of the Kennebec River. The street, laid out in the late 1700s, was also the location of many of the government buildings. As the city grew and spread out the local government buildings moved further away from the business district. Many fires damaged this concentrated area, including one significant fire in 1865 that destroyed nearly 100 buildings. In 1890, the first trolley line began operation down Water Street, connecting Augusta with Gardiner and Hallowell to the south. In 1932, buses replaced the trolley line. With the completion of the Maine Turnpike and Interstate 95 in 1955, local commercial developments began to move away from Water Street and closer to the highway.
Since the 1980s, there has been an attempt by city officials to revitalize the downtown area. Surviving mill and factory buildings have been redeveloped into housing. The dam on the Kennebec was removed in 1999 and the area around the dam has been turned into a city park. The city hall and other local government departments were relocated to the eastern bank of the river in the 1980s.
Since the mid-eighteenth century, there has been a military presence in Augusta. Fort Western has not had troops garrisoned there since the 1790s, but in 1828, the U.S. Government built an arsenal to protect their interests from Britain. During the Civil War, Augusta was a rendezvous point for soldiers traveling to the front. Many of the soldiers camped on the green in front of the capitol building. In 1862, Camp E.D. Keyes was established in the northwestern portion of the city. During World War I, Camp Keyes was used as a mobilization and training camp for soldiers. The camp eventually became a headquarters for the Maine National Guard. In 1929, the state legislature approved the placement of the Augusta State Airport next to the camp. As the airport grew, the use of the camp as a training facility was no longer possible. Today, it is still used for administrative and logistical purposes by the National Guard.
Geography.
Augusta is located at , making it the easternmost state capital in the United States. According to the United States Census Bureau, the city has a total area of 58.03 sqmi, of which 55.13 sqmi is land and 2.90 sqmi is water. Augusta is drained by Bond's Brook, Woromontogus Stream and the Kennebec River.
Roads.
The city is crossed by Interstate 95, U.S. Route 201, State Route 11, U.S. Route 202, State Route 9, State Route 3, State Route 100, State Route 27, State Route 8, State Route 104, and State Route 105.
Bordering.
Augusta borders the towns of Manchester to its west, Sidney and Vassalboro to its north, Windsor to its east, Chelsea to its south, and the city of Hallowell to its southwest.
Climate.
Augusta's climate is classified as a humid continental climate (Köppen: Dfb). Summers are typically warm, rainy, and humid, while winters are cold, windy, and snowy. Spring and fall are usually mild, but conditions are widely varied, depending on wind direction and jet stream positioning.
The hottest month is July, with an average high temperature of 80 °F. The coldest month is January, with an average low of 10 °F. Most snowfall occurs from December through March. There is usually little or no snow in April and November, and snow is rare in May and October.
Demographics.
2010 census.
As of the census of 2010, there were 19,136 people, 8,802 households, and 4,490 families residing in the city. The population density was 347.1 PD/sqmi. There were 9,756 housing units at an average density of 177.0 /sqmi. The racial makeup of the city was 94.1% White, 1.1% African American, 0.7% Native American, 1.5% Asian, 0.1% Pacific Islander, 0.4% from other races, and 2.3% from two or more races. Hispanic or Latino of any race were 1.8% of the population.
There were 8,802 households of which 23.0% had children under the age of 18 living with them, 35.2% were married couples living together, 11.8% had a female householder with no husband present, 4.0% had a male householder with no wife present, and 49.0% were non-families. 39.8% of all households were made up of individuals and 13.6% had someone living alone who was 65 years of age or older. The average household size was 2.08 and the average family size was 2.76.
The median age in the city was 43.2 years. 18.3% of residents were under the age of 18; 8.1% were between the ages of 18 and 24; 26% were from 25 to 44; 29.4% were from 45 to 64; and 18% were 65 years of age or older. The gender makeup of the city was 48.6% male and 51.4% female.
2000 census.
As of the census of 2000, there were 18,560 people, 8,565 households, and 4,607 families residing in the city. The population density was 335.1 people per square mile (129.4/km²). There were 9,480 housing units at an average density of 171.2 per square mile (66.1/km²). The racial makeup of the city was 96.21% White, 0.50% Black or African American, 0.48% Native American, 1.35% Asian, 0.01% Pacific Islander, 0.16% from other races, and 1.3% from two or more races. 0.86% of the population were Hispanic or Latino of any race.
There were 8,565 households out of which 24.3% had children under the age of 18 living with them, 39.1% were married couples living together, 10.9% had a female householder with no husband present, and 46.2% were non-families. 38.3% of all households were made up of individuals and 14.2% had someone living alone who was 65 years of age or older. The average household size was 2.10 and the average family size was 2.77.
In the city, the population was spread out with 20.5% under the age of 18, 8.7% from 18 to 24, 28.3% from 25 to 44, 24.8% from 45 to 64, and 17.7% who were 65 years of age or older. The median age was 40 years. For every 100 females there were 89.9 males. For every 100 females age 18 and over, there were 87.5 males.
The median income for a household in the city was $29,921, and the median income for a family was $42,230. Males had a median income of $31,209 versus $22,548 for females. The per capita income for the city was $19,145. About 11.4% of families and 15.0% of the population were below the poverty line, including 19.2% of those under age 18 and 9.8% of those age 65 or over.
Government.
Local government.
Augusta is governed by a mayor and council-manager system. The City Council oversees all City government activities and establishes the legislative policies of the City, adopts and amends ordinances and local laws, appropriates municipal resources, and sets the tax rate. The City Manager serves as the chief executive officer and purchasing agent of the city. The mayor presides at all meetings of the council, and is recognized ceremonially as the official head of the city.
The city maintains a police department remarkable for having not had an officer killed in the line of duty for over a century.
Political makeup.
Augusta has historically been Democratic. In the 2012 presidential election, Barack Obama received 5,192 of the votes to Mitt Romney's 3,339. The City has not voted for a Republican presidential candidate since the Republican landslide of 1988. Democrats are the majority political affiliation in all four voting wards, and there are more unenrolled voters than Republicans in the City.
Education.
There are five public schools, one private school, one college (the University of Maine at Augusta), and two public libraries in Augusta.
Farrington, Gilbert, Hussey, and Lincoln are the four public elementary schools that are spread throughout the city. Cony High School is the public high school that serves students in grades 7–12 from Augusta and the surrounding towns. St. Michaels is the private Catholic school that children from Augusta and surround towns may attend for tuition.
Media.
Television.
Augusta is part of the , and receives most of that market's channels. WCBB channel 10, licensed to Augusta, is the local television outlet for the Maine Public Broadcasting Network.

</doc>
<doc id="45921" url="http://en.wikipedia.org/wiki?curid=45921" title="Starman Jones">
Starman Jones

Starman Jones is a 1953 science fiction novel by Robert A. Heinlein about a farm boy who wants to go to the stars. It was first published by Charles Scribner's Sons as part of the Heinlein juveniles series.
Plot summary.
Max Jones works the family farm in the Ozark Mountains. With his father dead and his stepmother remarrying a man he detests, Max runs away from home, taking his uncle's astrogation manuals.
Most occupations are tightly controlled by guilds with hereditary memberships. One such is the Astrogators Guild. Since his uncle had been a member and had no children, Max hopes that before he died, his uncle had named him his heir. He begins hitchhiking towards Earthport to find out. Along the way, he finds a friendly face in hobo Sam Anderson, who later alludes to being a deserter from the Imperial Marines. Sam feeds Max and offers advice, though he later departs with Max's valuable manuals.
At the guild's headquarters, Max is disappointed to find that he had not been named as an heir, but he is returned his uncle's substantial security deposit for his manuals. Max learns that Sam had tried to claim the deposit for himself.
By chance, he runs into an apologetic Sam. With Max's money, Sam is able to finagle them a one way job/trip aboard a starship using forged papers. Max signs on as a steward's mate third class, and then he absorbs the contents of the Stewards' Guild manual using his eidetic memory. Among his duties is caring for several animals, including passengers' pets. When passenger Eldreth "Ellie" Coburn visits her pet, an alien, semi-intelligent "spider puppy" that Max has befriended, she learns that he can play three-dimensional chess, and challenges him to a game. A champion player, she diplomatically lets him win. Meanwhile, Sam manages to rise to the position of master-at-arms.
When, through Ellie's machinations, the ship's officers discover that Max had learned astrogation from his uncle, Max is promoted to the command deck. Under the tutelage of Chief Astrogator Hendrix and Chief Computerman Kelly, he becomes a probationary apprentice chartsman, then a probationary astrogator. In a meeting with Hendrix, Max reluctantly admits to faking his record to get into space. Hendrix defers the matter until their return to Earth. The "Asgard" then departs for Halcyon, a human colony planet orbiting Nu Pegasi.
When Hendrix dies, the astrogation department is left dangerously shorthanded. The aging captain tries to take his place, but is not up to the task. When Max detects an error in his real-time calculations leading up to a transition, neither the captain nor Assistant Astrogator Simes believe him, and the ship becomes lost.
They locate a habitable world, and the passengers become colonists. Meanwhile, the crew continues to try to figure out where they are and whether they can return to Earth. Unfortunately, it turns out the planet is already inhabited by intelligent centaur-like beings. Max and Ellie are captured, but Ellie's pet is able to guide Sam to them. They escape, though Sam is killed covering their retreat.
Upon his return, Max is informed that the captain has died. Simes tried to illegally take command and was killed by Sam, leaving Max as the only remaining astrogator. To make matters worse, Simes hid or destroyed the astrogation manuals.
Vastly outnumbered by the hostile natives, the humans are forced to attempt a perilous return to known space by reversing the erroneous transition. Max must not only pilot the ship; he must supply the missing astrogation tables from his eidetic memory. To add to his burdens, the remaining officers inform Max that he must take charge, as only an astrogator can be the captain. The pressure is immense, but Max succeeds and the ship returns to known space.
Max pays heavy fines for breaking their regulations, but becomes a member of the Astrogators Guild. However, he loses any chance for a relationship with Eldreth: she returns home to marry her boyfriend. Max accepts this with mixed feelings, but looks forward to his new career.
Reception.
Groff Conklin found the novel to be "a richly textured and thoroughly mature tale." Boucher and McComas praised it for its "good character-development, rousing adventure-telling, and brilliant creation of several forms of extra-Terrestrial life." P. Schuyler Miller ranked it "close to the the ["sic?"] best in mainline science fiction."
"New York Times" reviewer Villiers Gerson declared "Starman Jones" to be "superior science-fiction. ... carefully plotted, lucidly and beautifully written."
Surveying Heinlein's juvenile novels, Jack Williamson described "Starman Jones" as "a classic example of the "bildungsroman" pattern" and noted that "with its bold symbolism, the book makes a universal appeal." Despite "coincidence and occasional melodrama" in the plotting, Williamson concluded that "the novel is a fine juvenile [which] reflects hopes and fears we all have known."
Literary significance and criticism.
This book is notable among the Heinlein juveniles in being the first to be set outside the solar system, but more significantly for its attempt to fold in, in a subtle way, the political commentary and social speculation that had suffused his earlier pulp fiction. Labor unions, which had been treated negatively in "The Roads Must Roll", are here subjected to even more severe and categorical criticism, where a significant portion of the plot revolves around Max's attempts to enter the closed guild system of the spacelines' officers and crew. This is constantly contrasted against the virtuous and free life of the mythologized yeoman farmer: Max starts out as a farm boy, intends to jump ship along with Sam to find freedom as a farmer on a freshly colonized planet, and near the end of the book is part of an abortive attempt to settle a previously undiscovered planet.
As in much of the popular fiction that Heinlein would have been familiar with in his youth (e.g., "Tarzan" and "The Virginian"), the theme is that the wilderness acts as a magnifying glass to amplify the inherent differences between the best and the worst of the human race. Max triumphs mainly because of his noble character. The same theme is seen to a lesser extent in the other characters, some of whom reveal their flaws (Simes and the Captain), and some of whom rise to the occasion (Sam, minor characters such as the rich Daiglers, and Ellie, who proves not only highly intelligent, but resourceful and fiercely independent).
Max's eidetic memory does save the day at the end of the book, but earlier, Hendrix explicitly tells Max that his unusual memory was much less important than careful hard work at astrogation. Max ends the book having learned valuable lessons about life. While he gains from having broken guild rules, he also accepts the consequences of his actions.
Heinlein makes a special distinction in the book between Max's eidetic memory, and the perhaps more well-known photographic memory. He has Max explain that he cannot simply glance at something and have it memorized; as in the case of the astrogation and Stewards' Guild manuals, he must actually read them as would anyone else, but then the knowledge is perfectly retained in his memory.
The book has a strong feeling of verisimilitude because so much of it is based on Heinlein's real-life experiences. Heinlein, who intended as a young man to become an astronomer, describes Max as a boy who can tell time by looking at the position of the stars in the sky, and who becomes an astrogator. Heinlein had also been a U.S. naval officer.
Another outstanding quality of the book is its superior architecture. A common criticism of Heinlein's novels is that they are episodic, or have weak or rushed endings. "Starman Jones" has a smooth and logical progression as we watch Max grow from a hillbilly farmer through many stages to a mature young man. The storyline is genre bildungsroman.
The technology of the story reflects the era in which it was written. The book depicts a civilization that travels between star systems with the aid of electronic computers, but they have to be programmed on the spot, and elementary computing operations, such as calculating trigonometric functions and logarithms, and converting between decimal and binary numbers, must be done by looking up values in books of tables. The binary numbers are input using switches, with the results showing as binary values using lights. Heinlein, writing in the days when computers were big, clunky, and rare, did not fully explore their potential in this story, which he did in later stories.
The transitions that transport a ship from one star system to another are effected by holding the ship at just under light speed until it reaches precisely the right location and then accelerating it over, causing it to reappear at a congruent location that may be hundreds of light years away in ordinary space. The idea of congruence, nicely explained by Max using a folded scarf, is sound mathematics (though it is not known physics).
Adaptation to other media.
Although Heinlein rarely permitted dramatic adaptations of his work, he authorized Douglas L Lieberman to stage "Starman Jones" at the Goodman Children's Theater in Chicago. Written and directed by Lieberman, the 2-act play ran for 25 performances in 1972. The title role was played by Charles Fleischer, who later performed the voice of Roger Rabbit in Hollywood. In 1974, Avon Books published the script as part of the anthology "Contemporary Children's Theater" edited by Betty Jean Lifton.
Heinlein's reply to "Gulliver's Travels".
The later part, taking place on the planet of the centaurs—intelligent, horselike carnivores who dominate all other fauna on the planet including deformed human-like creatures—is evidently intended as Heinlein's commentary on and antithesis to the fourth part of Jonathan Swift's "Gulliver's Travels".
In the original, Gulliver is stranded in a country dominated by civilised horses, the Houyhnhnms, finds them much superior to humans, and identifies European humans with the degenerate Yahoos which the Houyhnhnms in his view justifiably dominate. The experience leaves Gulliver permanently misanthropic, even on his return to England feeling a yearning for the civilised Houyhnhnms and having nothing but contempt and loathing for the uncouth yahoos around him (including himself).
Heinlein, to the contrary, has little good to say of the cruel centaurs, who not only butcher and eat their yahoos (and would like to add the Earth variety to their menu) but also practice systematic euthanasia towards old and weak members of their own species. While the planet's local humans are just as degenerate and subservient as Swift's yahoos, which they strongly resemble, Max and his fellow Earth humans are brave and resourceful, at their best in fighting the centaurs.
Clearly, Swift's idea of having another species domesticate mankind was anathema to Heinlein (who did not hesitate to point out weaknesses of both human and alien characters in his works), and this part of the book expresses his vociferous rebuttal.

</doc>
<doc id="45922" url="http://en.wikipedia.org/wiki?curid=45922" title="Geometric distribution">
Geometric distribution

\!</math>
In probability theory and statistics, the geometric distribution is either of two discrete probability distributions:
Which of these one calls "the" geometric distribution is a matter of convention and convenience.
These two different geometric distributions should not be confused with each other. Often, the name "shifted" geometric distribution is adopted for the former one (distribution of the number "X"); however, to avoid ambiguity, it is considered wise to indicate which is intended, by mentioning the support explicitly.
It’s the probability that the first occurrence of success requires "k" number of independent trials, each with success probability p. If the probability of success on each trial is "p", then the probability that the "k"th trial (out of "k" trials) is the first success is
for "k" = 1, 2, 3, ...
The above form of geometric distribution is used for modeling the number of trials until the first success. By contrast, the following form of geometric distribution is used for modeling number of failures until the first success:
for "k" = 0, 1, 2, 3, ...
In either case, the sequence of probabilities is a geometric sequence.
For example, suppose an ordinary die is thrown repeatedly until the first time a "1" appears. The probability distribution of the number of times it is thrown is supported on the infinite set { 1, 2, 3, ... } and is a geometric distribution with "p" = 1/6.
Moments and cumulants.
The expected value of a geometrically distributed random variable "X" is 1/"p" and the variance is (1 − "p")/"p"2:
Similarly, the expected value of the geometrically distributed random variable "Y = X − 1" (where Y corresponds to the pmf listed in the right column) is q/"p" = (1 − "p")/"p", and its variance is (1 − "p")/"p"2:
Let "μ" = (1 − "p")/"p" be the expected value of "Y". Then the cumulants formula_24 of the probability distribution of "Y" satisfy the recursion
"Outline of proof:" That the expected value is (1 − "p")/"p" can be shown in the following way. Let "Y" be as above. Then
Parameter estimation.
For both variants of the geometric distribution, the parameter "p" can be estimated by equating the expected value with the sample mean. This is the method of moments, which in this case happens to yield maximum likelihood estimates of "p".
Specifically, for the first variant let "k" = "k"1, ..., "k""n" be a sample where "k""i" ≥ 1 for "i" = 1, ..., "n". Then "p" can be estimated as
In Bayesian inference, the Beta distribution is the conjugate prior distribution for the parameter "p". If this parameter is given a Beta("α", "β") prior, then the posterior distribution is
The posterior mean E["p"] approaches the maximum likelihood estimate formula_29 as "α" and "β" approach zero.
In the alternative case, let "k"1, ..., "k""n" be a sample where "k""i" ≥ 0 for "i" = 1, ..., "n". Then "p" can be estimated as
The posterior distribution of "p" given a Beta("α", "β") prior is
Again the posterior mean E["p"] approaches the maximum likelihood estimate formula_29 as "α" and "β" approach zero.
Other properties.
formula_35
Related distributions.
Since: formula_48

</doc>
<doc id="45927" url="http://en.wikipedia.org/wiki?curid=45927" title="Podkayne of Mars">
Podkayne of Mars

Podkayne of Mars is a science fiction novel by Robert A. Heinlein, originally serialised in "Worlds of If" (November 1962, January, March 1963), and published in hardcover in 1963. The novel is about a teenage girl named Podkayne "Poddy" Fries and her younger, asocial genius brother, Clark, who leave their home on Mars to take a trip on a spaceliner to visit Earth, accompanied by their uncle.
This book, along with "Starship Troopers", shows Heinlein moving away from his old, comfortable territory of juvenile science fiction novels. Both books were written for a publisher expecting to market a juvenile science fiction novel, and both raised serious objections from the publisher.
Plot summary.
The book is a first-person narrative in the form of Podkayne's diaries. Podkayne is 15 in Earth years (a bit over eight Martian years) while her genius younger brother Clark is 11 earth years (6 martian years). Due to the unscheduled "uncorking" (birth) of their three test-tube babies, Podkayne's parents cancel a much-anticipated trip to Earth. Disappointed, Podkayne confesses her misery to her uncle, Senator Tom Fries, an elder statesman of the Mars government. Tom arranges for Clark and Podkayne, escorted by himself, to get upgraded passage on a luxury liner to Earth.
During boarding, Clark is asked by a customs official "Anything to declare?" and facetiously answers "Two kilos of happy dust!" As he anticipated, his seemingly flippant remark gets him taken away and searched, just in time to divert attention away from Podkayne's luggage, where he has hidden a package he was paid to smuggle aboard. Podkayne suspects the reason behind her brother's behavior, but cannot prove it. Clark was told it was a present for the captain, but is far too cynical to be taken in. He later carefully opens the package and finds a nuclear bomb, which he, in typical Clark-fashion, disarms and keeps.
Much of the description of the voyage is based on Heinlein's own experiences as a naval officer and world traveler. Clark's ploy is taken from a real-life incident, related in Heinlein's "Tramp Royale", in which his wife answers the same question with "heroin" substituted for the fictitious, but equally illegal, happy dust.
Once aboard, they are befriended by "Girdie", an attractive, capable, experienced woman left impoverished by her late husband. Much to Podkayne's surprise, the normally very self-centered Clark contracts a severe case of puppy love.
The liner makes a stop at Venus, which is depicted as a latter-day Las Vegas gone ultra-capitalistic. The planet is controlled by a single corporation; the dream of most of the frantically enterprising residents is to earn enough to buy a single share in it, which guarantees lifelong financial security. Just about anything goes, as long as one can pay for it. The penalty for murder is a fine paid to the corporation for the victim's estimated value plus his projected future earnings. On a less serious level, Heinlein anticipated, by over forty years, television ads in taxicabs (in the book, holographic), which have since been implemented in taxicabs in major cities worldwide.
The Fries are given VIP treatment by the Venus Corporation and Podkayne is escorted by Dexter Cunha, the Chairman's dashing son. She begins to realize that Tom is much more than just her pinochle-playing uncle. When Clark vanishes and even the corporation is unable to find him, Tom reveals that he is on a secret diplomatic mission, and the children have been his protective coloration—Tom appearing to be a doddering uncle escorting two young people on a tour of the solar system rather than the accredited representative to a vital conference on Luna that he is. Clark has been kidnapped by functionaries of a political faction opposed to Tom.
Podkayne makes an ill-judged attempt to rescue Clark by herself and falls into the kidnappers' clutches as well—only to find her uncle caught too. The captors' scheme is to use the children to blackmail the uncle into doing their bidding at the Luna conference. Clark quickly realizes that once Uncle Tom is released, no matter what happens, their kidnappers will have little reason to keep their prisoners alive. He is prepared, however: he engineers an escape, kills his captors, and forgets to disable the nuclear bomb he had intended to go off only if they failed in their escape.
Two versions of the ending.
In Heinlein's original ending, Podkayne is killed. This did not please his publisher, who demanded and got a rewrite over the author's bitter objections. In a letter to Lurton Blassingame, his literary agent, Heinlein complained that it would be like "revising Romeo and Juliet to let the young lovers live happily ever after." He also declared that changing the end "isn't real life, because in real life, not everything ends happily."
In the original ending, after they escape from the kidnappers to a safe distance, Podkayne remembers that a semi-intelligent Venerian "fairy" baby has been left behind, and returns to rescue it. When the bomb that Clark leaves for the kidnappers blows up, Podkayne is killed, shielding the young fairy with her body. Clark takes over the narrative for the last chapter. The story ends with a hint of hope for him, as he admits his responsibility for what happened to Podkayne — that he "fubbed it, mighty dry" — then shows some human feeling by regretting his inability to cry and describes his plan to raise the fairy himself.
In the revised version, Podkayne is badly injured by the bomb, but not fatally. Uncle Tom, in a phone conversation with Podkayne's father, blames the parents — especially the mother — for neglecting the upbringing of the children. Uncle Tom feels that Clark is dangerous and maladjusted, and attributes this to the mother giving priority to her career. Clark still takes over as the narrator, and, again, regrets that Podkayne was hurt and plans to take care of the fairy, this time because Podkayne will want to see it when she is better.
The 1995 Baen edition includes both endings (which differ only on the last page), Jim Baen's own edited postlude to the story, and a collection of readers' essays giving their opinions about which ending is better. Most of these readers favored the sad ending, partly because they felt Heinlein should have been free to create his own story, and partly because they believed that the changed ending turned a tragedy into a mere adventure, and not a very well constructed one at that.
Podkayne appears in Heinlein's later novel "The Number of the Beast", attending the party at the end along with many other Heinlein characters from previous books.

</doc>
<doc id="45929" url="http://en.wikipedia.org/wiki?curid=45929" title="Dark Angel (TV series)">
Dark Angel (TV series)

Dark Angel is an American biopunk/cyberpunk science fiction television series created by James Cameron and Charles H. Eglee and starring Jessica Alba in her breakthrough role. The show premiered in the United States on the Fox network on October 3, 2000, and was canceled after two seasons. The series chronicles the life of Max Guevara (X5-452), a genetically-enhanced super-soldier who escapes from a covert government biotech/military facility as a child. In a post-apocalyptic Seattle, she tries to lead some semblance of a normal life, while eluding capture by government agents and searching for her genetically-enhanced brothers and sisters scattered in the aftermath of their escape.
The program is set in Seattle, Washington, and was filmed in Vancouver, British Columbia, at Lions Gate Studios.
Overview.
In 2009, a genetically enhanced, 9-year-old female super-soldier who calls herself Max Guevara (Jessica Alba) escapes along with eleven others like herself from a secret government institution, codenamed "Manticore", where they were born, raised and trained to be soldiers and assassins. On June 1, 2009, months after Max's escape, terrorists detonate an electromagnetic pulse weapon in the atmosphere over the U.S., which destroys the vast majority of computer and communication systems, throwing the country into chaos.
The first season begins ten years later in 2019, as it follows the life of the now 19-year-old Max as she struggles to search for her "Manticore" brothers and sisters. In a United States which is now barely more than a Third World nation, she tries to live her life, evade capture, and learn to trust and love. She becomes involved with Logan Cale (Michael Weatherly), an underground cyber-journalist with the alias Eyes Only, who recruits her to help fight corruption in the post-Pulse world, while at the same time she makes a living as a bicycle messenger at a courier company named Jam Pony along with her friends Original Cindy (Valarie Rae Miller), Herbal Thought (Alimi Ballard), and Sketchy (Richard Gunn). Other X-5s are periodically introduced, most significantly Zack (William Gregory Lee), the unit leader. The "Manticore" hunt for the escaped X-5s is led by Colonel Donald Lydecker (John Savage), who is ousted at the end of the season by the even more ruthless Elizabeth Renfro (Nana Visitor).
In the second season of the show, the tone changes as Max and Logan bring down "Manticore" and free all the transgenics within. Two others become main characters: Alec (Jensen Ackles), a fellow X-5 who joins Jam Pony, and (Kevin Durand), a transgenic with canine DNA. Max later learns that Joshua was the first transgenic created by Manticore's founder Sandeman. It becomes apparent that "Manticore" produced many different animal mixes as well as other experiments with unique abilities. A major theme in the second season is the discovery of an even more deadly enemy than Lydecker or Renfro, namely a millennia-old breeding cult similar in structure to the Illuminati. This has resulted in humans even more formidable than the Manticore-produced transgenics, and even some with strong telekinetic powers. Ames White (Martin Cummins), a government agent introduced early in the second season trying to eliminate the loose transgenics, is revealed to be a member of the cult. When a strange message written in Max's genetic code makes an appearance on her skin, it is revealed that Sandeman is a renegade from the breeding cult and Ames White is his son, who is still loyal to the cult and hates his father's transgenic creations with a passion. The second season ends before Sandeman's plan for Max can be revealed.
Planned storylines.
In the DVD commentary for the series finale episode "Freak Nation", executive producer and co-creator Charles H. Eglee detailed what was planned for season 3. It was to bring together the storylines of season 1 (Manticore) and season 2 (ancient blood cult) and reveal the mythology of "Dark Angel". As detailed by Charles H. Eglee:
Many thousands of years ago, Earth passed through a comet's tail which deposited viral material that killed 97% of the human race. Some people survived that had a genetic predisposition, some kind of antibody or immunity. The great pyramids in Egypt were actually genetic repositories, preserving the DNA of the survivors, built by an ancient blood cult that passed on this genetic immunity to selected members to keep this antibody against the return of the comet (which was due to happen in Season 3). Everybody else would perish, and the members of the cult would inherit the earth and rebuild civilization.
Sandeman, Max's creator, jumped from the cult to give this genetic immunity to the rest of humanity, believing that everybody deserved the cure. The other cult members deemed Sandeman a heretic and a threat, undermining their goals of rebuilding humanity in their own image.
Max was going to be the savior of the human race. Sandeman finally found out how to give this genetic immunity to everyone through Max. There were multiple ideas of how to spread Max's immunity to humanity, including an air burst that would disperse the antibody through the atmosphere, or attaching the immunity to a common cold virus (he detailed how a scene would show Original Cindy sneezing as part of the beginning of the immunity spread).
Series writer Moira Dekker also spoke on the DVD commentary that Logan's transfusion that allowed him to use his legs once again at the end of season 2 would begin to fail during season 3.
Cast and characters.
Main characters.
The following characters were featured in the opening credits of the program.
The 12 original escapees.
The following characters escaped in the original 2009 escape from Manticore. They were only featured throughout season 1. Ben (from episode 1x18) and Alec (from season 2) were twins. Max also has a clone Sam who appeared in episode 2x19.
Three other characters were mentioned as being in Max's group but didn't participate in the escape for various reasons. These included:
Music.
Score.
The score for "Dark Angel" was composed and conducted by Joel McNeely.
The pilot episode's score was available in part on the original official (and now defunct) website darkangeltheseries.com. A few tracks were later released by Joel McNeely on his blog. The track "Bicycle Ride" was used in the end credits for the duration of the series.
The aforementioned pilot score was released in full as part of the original publicity press kit, titled "Dark Angel: Complete Score from the Dark Angel Pilot". This 37-track CD was for promotional use only and not for resale.
Production.
Background to series.
Director James Cameron had planned to make a film of the comic book character "Spider-Man". Unable to do so, Cameron moved to television and created the story of Max, a new superheroine. "Dark Angel" was influenced by cyberpunk, current superhero genres, and third-wave feminism.
Broadcast history.
The first season of the show premiered on Fox on Tuesday, October 3, 2000. The show aired on Tuesday nights after "That '70s Show" and "Titus" during the 2000–2001 television season
The following season, however, Fox moved "Dark Angel" to Friday nights preceding the network's new series "Pasadena" in order to try to reverse their string of bad luck with the Friday night death slot curse and to give the network's new series "24" a better time period during the week. Their efforts to improve Friday nights were unsuccessful though as "Pasadena" failed to find an audience and was canceled before the end of its first season on the night, while "Dark Angel" saw its second season audience drop by nearly 4 million viewers and was subsequently canceled. The final episode of the series aired on May 3, 2002 as a special 90-minute episode (which also marked James Cameron's dramatic TV directing debut).
Though canceled due to low ratings in its second season, "Dark Angel" has been syndicated on the Sci-Fi Channel and the El Rey Network in the United States and E4 in the United Kingdom; the series has also been shown in the UK on Syfy and the Horror Channel. In 2003, both seasons of the show were released on DVD.
DVD releases.
20th Century Fox released Seasons 1 and 2 of "Dark Angel" on DVD in Regions 1 and 2 in 2003, as six-disc sets packaged in cardboard sleeves containing three DVD cases each of two discs. Both seasons were re-released in Region 1 on June 5, 2007, with slim packaging consisting of one plastic case containing all six discs (which were unchanged in content and cosmetics). Region 2 also saw both seasons released in the new slim format.
The Region 1 releases contain several special features, including commentaries, bloopers, deleted scenes and featurettes. Region 2 releases contain fewer bonus features, but the episodes are presented in anamorphic widescreen, while Region 1 releases are fullscreen.
Alleged plagiarism.
After the show's release the Argentine artists Carlos Trillo and Carlos Meglia, creators of the Argentinian comic book series "Cybersix", filed a lawsuit against Cameron and Fox for plagiarism. "Cybersix" was created by Trillo (writer) and Meglia (penciler) in the early 90's for the European market, and appeared in Spanish in November 1993; an animated TV series based on the comic strip was released in 1999. Trillo and Meglia accused "Dark Angel" of stealing most of the plot from the comic and its most recognizable elements. In a 2007 interview Trillo stated that he and Meglia were not able to carry on with the lawsuit due to lack of financial resources, so they dropped it, although the issue is still a matter of controversy:
Spinoffs.
Written by Max Allan Collins, a trilogy of novels expands upon the "Dark Angel" television series.

</doc>
<doc id="45930" url="http://en.wikipedia.org/wiki?curid=45930" title="Index fossil">
Index fossil

Index fossils (also known as guide fossils, indicator fossils or zone fossils) are fossils used to define and identify geologic periods (or faunal stages). They work on the premise that, although different sediments may look different depending on the conditions under which they were laid down, they may include the remains of the same species of fossil. If the species concerned were short-lived (in geological terms, lasting a few hundred thousand years), then it is certain that the sediments in question were deposited within that narrow time period. The shorter the lifespan of a species, the more precisely different sediments can be correlated, and so rapidly evolving types of fossils are particularly valuable. The best index fossils are common, easy-to-identify at species level, and have a broad distribution—otherwise the likelihood of finding and recognizing one in the two sediments is minor.
Ammonites fit these demands well, and are the best-known fossils that have been widely used for this. Other important groups that provide index fossils are the corals, graptolites, brachiopods, trilobites, and echinoids (sea urchins). Conodonts may be identified by experts using light microscopy such that they can be used to index a given sample with good resolution. Fossilized teeth of mammals have also been used.
Geologists use both large fossils (called macrofossils) and microscopic fossils (called microfossils) for this process, known as biostratigraphy. Macrofossils have the advantage of being easy to see in the field, but they are rarer, and microfossils are very commonly used by oil prospectors and other industries interested in mineral resources when accurate knowledge of the age of the rocks being looked at is needed.
The series of deposits that spans the occurrence of a particular index fossil, is often referred to as that fossil's zone, enabling to relate different faunas through time. An example would be to say that "Mesolenellus hyperborea" occurs in the late "Nevadella"-zone.
How index fossils are used.
"Imagine an E.L. Doctorow novel in which Alfred Tennyson, William Tweed, Abner Doubleday, Jim Bridger, and Martha Jane Canary sit down to a dinner prepared by Rutherford B. Hayes. ... a geologist could quickly decide -- as could anyone else -- that the dinner must have occurred in the middle 1870s, because Canary was 18 when the decade began, Tweed became extinct in 1878, and the biographies of the others do not argue with these limits." -- John McPhee, "Basin and Range" (1981).

</doc>
<doc id="45936" url="http://en.wikipedia.org/wiki?curid=45936" title="Spirit possession">
Spirit possession

Spirit possession is a term for the belief that animas, demons, extraterrestrials, gods, or spirits can take control of a human body. The concept of spirit possession exists in many religions, including Christianity, Buddhism, Haitian Vodou, Wicca, Hinduism, Islam and Southeast Asian and African traditions. Depending on the cultural context in which it is found, possession may be considered voluntary or involuntary and may be considered to have beneficial or detrimental effects to host. Within possession cults, the belief that one is possessed by spirits is more common among women than men.
African traditions.
Democratic Republic of the Congo.
See Zebola
Ethiopia.
Gurage people.
Among the Gurage people of Ethiopia, spirit possession is a common belief. Wiliam A. Shack postulated that it is caused by Gurange cultural attitudes about food and hunger, while they have a plentiful food supply, cultural pressures that force the Gurange to either share it to meet social obligations, or hoard it and eat it secretly cause feelings of anxiety. Distinctions are drawn between spirits that strictly possess men, spirits that possess women, and spirits that possess victims of either sex. A ritual illness that only affects men is believed to be caused by a spirit called "awre". This affliction presents itself by loss of appetite, nausea, and attacks from severe stomach pains. If it persists the victim may enter a trancelike stupor, in which he sometimes regains consciousness long enough to take food and water. Breathing is often labored. Seizures and trembling overcome the patient, and in extreme cases, partial paralysis of the extremities.
If the victim does not recover naturally, a traditional healer, or "sagwara", is summoned. Once the "sagwara" has determined the spirit's name through the use of divination, he prescribes a routine formula to exorcise the spirit. This is not a permanent cure, however, it is believed to allow the victim to form a relationship with the spirit. Nevertheless, the victim is subject to chronic repossession, which is treated by repeating the formula. This formula involves the preparation and consumption of a dish of ensete, butter, and red pepper. During this ritual, the victim's head is covered with a drape, and he eats the ensente ravenously while other ritual participants participate by chanting. The ritual ends when the possessing spirit announces that it is satisfied. Shack notes that the victims are overwhelmingly poor men, and that women are not as food-deprived as men are due to ritual activities that involve food redistribution and consumption. Shack postulates that the "awre" serves to bring the possessed man to the center of social attention, and to relieve his anxieties over his inability to gain prestige from redistributing food, which is the primary way in which Gurange men gain status in their society.
Sidama people.
The belief in spirit possession is part of their native culture of the Sidama people of southwest Ethiopia. Anthropologists Irene and John Hamer postulated that it is a form of compensation for being deprived within Sidama society, although they do not draw from I.M Lewis (see Cultural anthropology section under Scientific views). The majority of the possessed are women whose spirits demand luxury goods to alleviate their condition, but men can be possessed as well. Possessed individuals of both sexes can become healers due to their condition. Hamer and Hamer suggest that this is a form of compensation among deprived men in the deeply competitive society of the Sidama, for if a man cannot gain prestige as an orator, warrior, or farmer, he may still gain prestige as a spirit healer. Women are sometimes accused of faking possession, but men never are.
Kenya.
Digo people.
The Digo people of Kenya refer to the spirits that supposedly possess them as "shaitani". These "shaitani" typically demand luxury items to make the patient well again. Despite the fact that men sometimes accuse women of faking the possessions in order to get luxury items, attention, and sympathy, they do generally regard spirit possession as a genuine condition, and view victims of it as being ill through no fault of their own. However, men sometimes suspect women of actively colluding with spirits in order to be possessed.
Giriama people.
The Giriama people of coastal Kenya believe in spirit possession.
Mayotte.
In Mayotte, approximately 25% of the adult population, and five times as many women as men, enter trance states in which they are supposedly possessed by certain identifiable spirits who maintain stable and coherent identities from one possession to the next.
Mozambique.
In Mozambique, a new belief in spirit possession appeared after the Mozambican Civil War. These spirits, called "gamba", are said to be identified as dead soldiers, and allegedly overwhelmingly possess women. Prior to the war, spirit possession was limited to certain families and was less common.
South Africa.
A belief in spirit possession appears among the Xesibe, a Xhosa speaking people from Transkei, South Africa. The majority of the supposedly possessed are married women. The condition of spirit possession among them is called "inwatso". Those who develop the condition of "inwatso" are regarded as having a special calling to divine the future. They are first treated with sympathy, and then with respect as they allegedly develop their abilities to foretell the future.
Tanzania.
The Sukuma people of Tanzania believe in spirit possession.
Uganda.
In Uganda, a woman named Alice Auma was reportedly possessed by the spirit of a male Italian soldier named Lakwena, meaning messenger. She had ultimately led a failed insurrection against governmental forces.
Zanzibar.
A now extinct spirit possession cult existed among the Hadimu women of Zanzibar, revering a spirit called "kitimiri". This cult described in an 1869 account by a French missionary. The cult faded by the 1920s and was virtually unknown by the 1960s.
Zār cult.
In Sudan and certain other East African cultures the Zār cult conducts ethnomedical healing ceremonies involving possession, typically of Muslim women by a Zār spirit.
African diasporic traditions.
Haitian Vodou.
In Haitian Vodou and related African diaspora traditions, one way that those who participate or practice can have a spiritual experience is by being possessed by the "Loa" (or "lwa"). When the "loa" descends upon a practitioner, the practitioner's body is being used by the spirit, according to the tradition. Some spirits are believed to be able to give prophecies of upcoming events or situations pertaining to the possessed one, also called "Chwal" or the "Horse of the Spirit." Practitioners describe this as a beautiful but very tiring experience. Most people who are possessed by the spirit describe the onset as a feeling of blackness or energy flowing through their body as if they were being electrocuted. According to Vodou believers, when this occurs, it is a sign that a possession is about to take place.
According to tradition, the practitioner has no recollection of the possession and in fact when the possessing spirit leaves the body, the possessed one is tired and wonders what has happened during the possession. It is also believed that there are those who feign possessions because they want attention or a feeling of importance, because those who are possessed carry a high importance in ceremony. Often, a "chwal" will undergo some form of trial or testing to make sure that the possession is allegedly genuine. As an example, someone possessed by one of the Guédé spirits may be offered "piment", a liqueur made by steeping twenty-one chili peppers in "kleren", a potent alcoholic beverage. If the "chwal" consumes the "piment" without showing any evidence of pain or discomfort, the possession is regarded as genuine.
Umbanda.
The concept of spirit possession is also found in Umbanda, an Afro-Brazilian folk religion. According to tradition, one such possessing spirit is Pomba Gira, who possesses both women and effeminate males.
Asian traditions.
Buddhism.
According to the Indian medical literature and Tantric Buddhist scriptures, most of the "seizers," or those that threaten the lives of young children, appear in animal form: cow, lion, fox, monkey, horse, dog, pig, cat, crow, pheasant, owl, and snake. But apart from these "nightmare shapes," it is believed the impersonation or incarnation of animals could in some circumstances also be highly beneficial, according to Michel Strickmann.
Ch'i Chung-fu, a Chinese gynecologist writing early in the thirteenth century, wrote that in addition to five sorts of falling frenzy classified according to their causative factors, there were also four types of other frenzies distinguished by the sounds and movements given off by the victim during his seizure: cow, horse, pig, and dog frenzies.
In Tibetan Buddhism, a practise of getting into a not yet born body is phowa. Marpa Lotsawa, Dharma Dodey a son of Marpa, Dogyü Gyatsho, and Khyung Mo Rinpoche are said to have done phowa.
East-Asian religions.
Certain sects of Taoism, Korean shamanism, Shinto, some Japanese new religious movements, and other East-Asian religions feature the idea of spirit possession. Some sects feature shamans who supposedly become possessed, or mediums who allegedly channel beings' supernatural power, or enchanters who it is said imbue or foster spirits within objects, like samurai swords. Hong Kong film Super Normal II (大迷信1993) shows the famous story of a woman in Taiwan who possesses a dead body to live her predeterminated remaining life. She is still working in the Zhen Tian Temple in Yunlin.
Chinese traditions.
See Chinese spirit possession, Shi (personator)
Indian traditions.
Rajasthan.
The concept of spirit possession exists in the culture of modern Rajasthan. Some of the spirits allegedly possessing Rajasthanis are seen as good and beneficial, while others are seen as malevolent. The good spirits are said to include murdered royalty, the underworld god Bhaironji, and Muslim saints & fakirs. Bad spirits are believed to include perpetual debtors who die in debt, stillborn infants, deceased widows, and foreign tourists. The supposedly possessed individual is referred to as a "ghorala", or "mount". Possession, even if by a benign spirit, is regarded as undesirable, as it is seen to entail loss of self-control, and violent emotional outbursts.
Tamil.
Tamil women in India are said to experience possession by "pey" spirits. According to tradition, these spirits overwhelmingly possess new brides, are usually identified as the ghosts of young men who died while romantically or sexually frustrated, and are ritually exorcised.
Indonesian traditions.
Bali.
The animist traditions of the island of Bali (Indonesia) include a practice called "sanghyang", induction of voluntary possession trance states for specific purposes. Roughly similar to voluntary possession in Vaudon (Voodoo), "sanghyang" is considered a sacred state in which hyangs (deities) or helpful spirits temporarily inhabit the bodies of participants. The purpose of "sanghyang" is believed to be to cleanse people and places of evil influences and restore spiritual balance. Thus, it is often referred to as an exorcism ceremony.
Sulawesi.
The women of the Bonerate people of Sulawesi, Indonesia practice a possession-trance ritual in which they smother glowing embers with their bare feet at the climax.
Japanese traditions.
See Misaki
Malaysian traditions.
Female workers in Malaysian factories have allegedly become possessed by spirits, and factory owners generally regard it as “mass hysteria” and an intrusion of irrational and archaic beliefs into a modern setting.
The anthropologist Aihwa Ong noted that spirit possession beliefs in Malaysia were typically held by older, married women, whereas the female factory workers are typically young and unmarried. She connects this to the rapid industrialization and modernization of Malaysia. Ong argued that spirit possession is a traditional way of rebelling against authority without punishment, and suggests that it is a means of protesting the untenable working conditions and sexual harassment that the women were compelled to endure.
Sri Lankan traditions.
The Coast Veddas, a social group within the minority group of Sri Lankan Tamil people in Eastern Province, Sri Lanka, enter trances during religious festivals in which they are regarded as being possessed by a spirit. Although they speak a dialect of Tamil, during trances they will sometimes use a mixed language that contains words from the Vedda language.
Oceanic traditions.
Melanesia.
The Urapmin people of the New Guinea Highlands practice a form of group possession known as the "spirit disco" (Tok Pisin: "spirit disko"). Men and women gather in church buildings, dancing in circles and jumping up and down while women sing Christian songs; this is called "pulling the [Holy] spirit" (Tok Pisin: "pulim spirit", Urap: "Sinik dagamin"). The songs' melodies are borrowed from traditional women's songs sung at drum dances (Urap: "wat dalamin"), and the lyrics are typically in Telefol or other Mountain Ok languages. If successful, some dancers will "get the spirit" (Tok Pisin: "kisim spirit"), flailing wildly and careening about the dance floor. After an hour or more, those possessed will collapse, the singing will end, and the spirit disco will end with a prayer and, if there is time, a Bible reading and sermon. The body is believed to normally be "heavy" (Urapmin: "ilum") with sin, and possession is the process of the Holy Spirit throwing the sins from one's body, making the person "light" ("fong") again. This is a completely new ritual for the Urapmin, who have no indigenous tradition of spirit-possession.
Micronesia.
The concept of spirit possession appears in Chuuk State, one of the four states of Federated States of Micronesia. Although Chuuk is an overwhelmingly Christian society, traditional beliefs in spirit possession by the dead still exist, usually held by women, and "events" are usually brought on by family conflicts. The supposed spirits, speaking through the women, typically admonish family members to treat each other better.
Christianity.
Roman Catholic doctrine states that angels are non-corporeal, spiritual beings with intelligence and will. Fallen angels, or demons, are able to "demonically possess" individuals without the victim's knowledge or consent, leaving them morally blameless.
Islam.
No verses in the Quran clearly support stories of spirit possession. One verse in the Quran describes the behavior of those who earn interest on borrowings, acting as if they were possessed or controlled by a satanic touch. Muslims are told to "seek refuge in Allah from the accursed devil" but the meaning of this prayer relates to the fear Muslims should have of the wrath of God, as the purpose of Shaitan is to mislead humans and make them disobey God. It is also stated in the Quran that the devil has no power of influence over those who God has guided. In the Quran, these facts are referred in:
Judaism.
Although forbidden in the Hebrew Bible, magic was widely practiced in the late Second Temple Period and well documented in the period following the destruction of the Temple into the 3rd, 4th, and 5th centuries C.E. In Jewish folklore, a Dybbuk is a disembodied spirit that wanders restlessly until it inhabits the body of a living person. The Baal Shem could expel the harmful dybbuk through exorcism.
Jewish magical papyri were inscriptions on amulets, ostraca and incantation bowls used in Jewish magical practices against shedim and other unclean spirits.
Wicca.
Wiccans believe in voluntary possession by the Goddess, connected with the sacred ceremony of Drawing Down the Moon. The high priestess solicits the Goddess to possess her and speak through her.
Scientific views.
Cultural anthropology.
The anthropologist I.M. Lewis noted that women are more likely to be involved in spirit possession cults than men are, and postulated that such cults act as a means of compensation for their exclusion from other spheres within their respective cultures.
Physical anthropology.
Anthropologists Alice B. Kehoe and Dody H. Giletti argued that the reason that women are more commonly seen in Afro-Eurasian spirit possession cults is because of deficiencies in thiamine, tryptophan-niacin, calcium, and vitamin D. They argued that a combination of poverty and food taboos cause this problem, and that it is exacerbated by the strains of pregnancy and lactation. They postulated that the involuntary symptoms of these deficiencies affecting their nervous systems have been institutionalized as spirit possession.
Psychology.
Spirit possession is not recognized as a psychiatric or medical diagnosis by the DSM-IV or the ICD-10. People alleged to be possessed by spirits sometimes exhibit symptoms similar to those associated with mental illnesses such as psychosis, hysteria, mania, Tourette's syndrome, epilepsy, schizophrenia, or dissociative identity disorder, including involuntary, uncensored behavior, and an extra-human, extra-social aspect to the individual's actions. In cases of dissociative identity disorder in which the alter personality is questioned as to its identity, 29% are reported to identify themselves as demons. Physicians regard this as a mental disease called demonomania or demonopathy, a monomania in which the patient believes that he or she is possessed by one or more demons.

</doc>
<doc id="45938" url="http://en.wikipedia.org/wiki?curid=45938" title="General equilibrium theory">
General equilibrium theory

In economics, general equilibrium theory attempts to explain the behavior of supply, demand, and prices in a whole economy with several or many interacting markets, by seeking to prove that a set of prices exists that will result in an overall (or "general") equilibrium. General equilibrium theory contrasts to "partial" equilibrium, which only analyzes single markets. As with all models, this is an abstraction from a real economy; it is proposed as being a useful model, both by considering equilibrium prices as long-term prices and by considering actual prices as deviations from equilibrium.
General equilibrium theory both studies economies using the model of equilibrium pricing and seeks to determine in which circumstances the assumptions of general equilibrium will hold. The theory dates to the 1870s, particularly the work of French economist Léon Walras in his pioneering 1874 work "Elements of Pure Economics".
Overview.
It is often assumed that agents are price takers, and under that assumption two common notions of equilibrium exist: Walrasian (or competitive) equilibrium, and its generalization; a price equilibrium with transfers.
Broadly speaking, general equilibrium tries to give an understanding of the whole economy using a "bottom-up" approach, starting with individual markets and agents. Macroeconomics, as developed by the Keynesian economists, focused on a "top-down" approach, where the analysis starts with larger aggregates, the "big picture". Therefore, general equilibrium theory has traditionally been classified as part of microeconomics.
The difference is not as clear as it used to be, since much of modern macroeconomics has emphasized microeconomic foundations, and has constructed general equilibrium models of macroeconomic fluctuations. General equilibrium macroeconomic models usually have a simplified structure that only incorporates a few markets, like a "goods market" and a "financial market". In contrast, general equilibrium models in the microeconomic tradition typically involve a multitude of different goods markets. They are usually complex and require computers to help with numerical solutions.
In a market system the prices and production of all goods, including the price of money and interest, are interrelated. A change in the price of one good, say bread, may affect another price, such as bakers' wages. If bakers differ in tastes from others, the demand for bread might be affected by a change in bakers' wages, with a consequent effect on the price of bread. Calculating the equilibrium price of just one good, in theory, requires an analysis that accounts for all of the millions of different goods that are available.
The first attempt in neoclassical economics to model prices for a whole economy was made by Léon Walras. Walras' "Elements of Pure Economics" provides a succession of models, each taking into account more aspects of a real economy (two commodities, many commodities, production, growth, money). Some think Walras was unsuccessful and that the later models in this series are inconsistent.
In particular, Walras's model was a long-run model in which prices of capital goods are the same whether they appear as inputs or outputs and in which the same rate of profits is earned in all lines of industry. This is inconsistent with the quantities of capital goods being taken as data. But when Walras introduced capital goods in his later models, he took their quantities as given, in arbitrary ratios. (In contrast, Kenneth Arrow and Gérard Debreu continued to take the initial quantities of capital goods as given, but adopted a short run model in which the prices of capital goods vary with time and the own rate of interest varies across capital goods.)
Walras was the first to lay down a research program much followed by 20th-century economists. In particular, the Walrasian agenda included the investigation of when equilibria are unique and stable.(Walras' Lesson 7 shows neither uniqueness, nor stability, nor even existence of an equilibrium is guaranteed.)
Walras also proposed a dynamic process by which general equilibrium might be reached, that of the tâtonnement or groping process.
The tâtonnement process is a model for investigating stability of equilibria. Prices are announced (perhaps by an "auctioneer"), and agents state how much of each good they would like to offer (supply) or purchase (demand). No transactions and no production take place at disequilibrium prices. Instead, prices are lowered for goods with positive prices and excess supply. Prices are raised for goods with excess demand. The question for the mathematician is under what conditions such a process will terminate in equilibrium where demand equates to supply for goods with positive prices and demand does not exceed supply for goods with a price of zero. Walras was not able to provide a definitive answer to this question (see Unresolved Problems in General Equilibrium below).
In partial equilibrium analysis, the determination of the price of a good is simplified by just looking at the price of one good, and assuming that the prices of all other goods remain constant. The Marshallian theory of supply and demand is an example of partial equilibrium analysis. Partial equilibrium analysis is adequate when the first-order effects of a shift in the demand curve do not shift the supply curve. Anglo-American economists became more interested in general equilibrium in the late 1920s and 1930s after Piero Sraffa's demonstration that Marshallian economists cannot account for the forces thought to account for the upward-slope of the supply curve for a consumer good.
If an industry uses little of a factor of production, a small increase in the output of that industry will not bid the price of that factor up. To a first-order approximation, firms in the industry will experience constant costs, and the industry supply curves will not slope up. If an industry uses an appreciable amount of that factor of production, an increase in the output of that industry will exhibit increasing costs. But such a factor is likely to be used in substitutes for the industry's product, and an increased price of that factor will have effects on the supply of those substitutes. Consequently, Sraffa argued, the first-order effects of a shift in the demand curve of the original industry under these assumptions includes a shift in the supply curve of substitutes for that industry's product, and consequent shifts in the original industry's supply curve. General equilibrium is designed to investigate such interactions between markets.
Continental European economists made important advances in the 1930s. Walras' proofs of the existence of general equilibrium often were based on the counting of equations and variables. Such arguments are inadequate for non-linear systems of equations and do not imply that equilibrium prices and quantities cannot be negative, a meaningless solution for his models. The replacement of certain equations by inequalities and the use of more rigorous mathematics improved general equilibrium modeling.
Modern concept of general equilibrium in economics.
The modern conception of general equilibrium is provided by a model developed jointly by Kenneth Arrow, Gérard Debreu, and Lionel W. McKenzie in the 1950s. Debreu presents this model in "Theory of Value" (1959) as an axiomatic model, following the style of mathematics promoted by Nicolas Bourbaki. In such an approach, the interpretation of the terms in the theory (e.g., goods, prices) are not fixed by the axioms.
Three important interpretations of the terms of the theory have been often cited. First, suppose commodities are distinguished by the location where they are delivered. Then the Arrow-Debreu model is a spatial model of, for example, international trade.
Second, suppose commodities are distinguished by when they are delivered. That is, suppose all markets equilibrate at some initial instant of time. Agents in the model purchase and sell contracts, where a contract specifies, for example, a good to be delivered and the date at which it is to be delivered. The Arrow–Debreu model of intertemporal equilibrium contains forward markets for all goods at all dates. No markets exist at any future dates.
Third, suppose contracts specify states of nature which affect whether a commodity is to be delivered: "A contract for the transfer of a commodity now specifies, in addition to its physical properties, its location and its date, an event on the occurrence of which the transfer is conditional. This new definition of a commodity allows one to obtain a theory of [risk] free from any probability concept..."
These interpretations can be combined. So the complete Arrow–Debreu model can be said to apply when goods are identified by when they are to be delivered, where they are to be delivered and under what circumstances they are to be delivered, as well as their intrinsic nature. So there would be a complete set of prices for contracts such as "1 ton of Winter red wheat, delivered on 3rd of January in Minneapolis, if there is a hurricane in Florida during December". A general equilibrium model with complete markets of this sort seems to be a long way from describing the workings of real economies, however its proponents argue that it is still useful as a simplified guide as to how a real economies function.
Some of the recent work in general equilibrium has in fact explored the implications of incomplete markets, which is to say an intertemporal economy with uncertainty, where there do not exist sufficiently detailed contracts that would allow agents to fully allocate their consumption and resources through time. While it has been shown that such economies will generally still have an equilibrium, the outcome may no longer be Pareto optimal. The basic intuition for this result is that if consumers lack adequate means to transfer their wealth from one time period to another and the future is risky, there is nothing to necessarily tie any price ratio down to the relevant marginal rate of substitution, which is the standard requirement for Pareto optimality. Under some conditions the economy may still be constrained Pareto optimal, meaning that a central authority limited to the same type and number of contracts as the individual agents may not be able to improve upon the outcome, what is needed is the introduction of a full set of possible contracts. Hence, one implication of the theory of incomplete markets is that inefficiency may be a result of underdeveloped financial institutions or credit constraints faced by some members of the public. Research still continues in this area.
Properties and characterization of general equilibrium.
Basic questions in general equilibrium analysis are concerned with the conditions under which an equilibrium will be efficient, which efficient equilibria can be achieved, when an equilibrium is guaranteed to exist and when the equilibrium will be unique and stable.
First Fundamental Theorem of Welfare Economics.
The First Fundamental Welfare Theorem asserts that market equilibria are Pareto efficient. In a pure exchange economy, a sufficient condition for the first welfare theorem to hold is that preferences be locally nonsatiated. The first welfare theorem also holds for economies with production regardless of the properties of the production function. Implicitly, the theorem assumes complete markets and perfect information. In an economy with externalities, for example, it is possible for equilibria to arise that are not efficient.
The first welfare theorem is informative in the sense that it points to the sources of inefficiency in markets. Under the assumptions above, any market equilibrium is tautologically efficient. Therefore, when equilibria arise that are not efficient, the market system itself is not to blame, but rather some sort of market failure.
Second Fundamental Theorem of Welfare Economics.
While every equilibrium is efficient, it is clearly not true that every efficient allocation of resources will be an equilibrium. However, the second theorem states that every efficient allocation can be supported by some set of prices. In other words, all that is required to reach a particular outcome is a redistribution of initial endowments of the agents after which the market can be left alone to do its work. This suggests that the issues of efficiency and equity can be separated and need not involve a trade-off. The conditions for the second theorem are stronger than those for the first, as consumers' preferences now need to be convex (convexity roughly corresponds to the idea of diminishing rates of marginal substitution, or to preferences where "averages are better than extrema"). Further up, the Second Fundamental Theorem of Equilibrium Analysis leads to Perfect Equilibrium Analysis (Enrico Gallo Modena, 2013) where market forces join together planned economies in a perfect bound.
Existence.
Even though every equilibrium is efficient, neither of the above two theorems say anything about the equilibrium existing in the first place. To guarantee that an equilibrium exists, it suffices that consumer preferences be convex (although with enough consumers this assumption can be relaxed both for existence and the second welfare theorem). Similarly, but less plausibly, convex feasible production sets suffice for existence; convexity excludes economies of scale.
Proofs of the existence of equilibrium traditionally rely on fixed-point theorems such as Brouwer fixed-point theorem for functions (or, more generally, the Kakutani fixed-point theorem for set-valued functions). In fact, the converse holds, according to Uzawa's derivation of Brouwer’s fixed point theorem from Walras's law. Following Uzawa's theorem, many mathematical economists consider proving existence a deeper result than proving the two Fundamental Theorems.
Another method of proof of existence, global analysis, uses Sard's lemma and the Baire category theorem; this method was pioneered by Gérard Debreu and Stephen Smale.
Nonconvexities in large economies.
Starr (1969) applied the Shapley–Folkman–Starr theorem to prove that even without convex preferences there exists an approximate equilibrium. The Shapley–Folkman–Starr results bound the distance from an "approximate" economic equilibrium to an equilibrium of a "convexified" economy, when the number of agents exceeds the dimension of the goods. Following Starr's paper, the Shapley–Folkman–Starr results were "much exploited in the theoretical literature", according to Guesnerie,:112 who wrote the following:
some key results obtained under the convexity assumption remain (approximately) relevant in circumstances where convexity fails. For example, in economies with a large consumption side, nonconvexities in preferences do not destroy the standard results of, say Debreu's theory of value. In the same way, if indivisibilities in the production sector are small with respect to the size of the economy, [ . . . ] then standard results are affected in only a minor way.:99
To this text, Guesnerie appended the following footnote:
The derivation of these results in general form has been one of the major achievements of postwar economic theory.:138
In particular, the Shapley-Folkman-Starr results were incorporated in the theory of general economic equilibria and in the theory of market failures and of public economics.
Uniqueness.
Although generally (assuming convexity) an equilibrium will exist and will be efficient, the conditions under which it will be unique are much stronger. While the issues are fairly technical the basic intuition is that the presence of wealth effects (which is the feature that most clearly delineates general equilibrium analysis from partial equilibrium) generates the possibility of multiple equilibria. When a price of a particular good changes there are two effects. First, the relative attractiveness of various commodities changes; and second, the wealth distribution of individual agents is altered. These two effects can offset or reinforce each other in ways that make it possible for more than one set of prices to constitute an equilibrium.
A result known as the Sonnenschein–Mantel–Debreu theorem states that the aggregate excess demand function inherits only certain properties of individual's demand functions, and that these (Continuity, Homogeneity of degree zero, Walras' law and boundary behavior when prices are near zero) are the only real restriction one can expect from an aggregate excess demand function: any such function can be rationalized as the excess demand of an economy. In particular uniqueness of equilibrium should not be expected.
There has been much research on conditions when the equilibrium will be unique, or which at least will limit the number of equilibria. One result states that under mild assumptions the number of equilibria will be finite (see regular economy) and odd (see index theorem). Furthermore if an economy as a whole, as characterized by an aggregate excess demand function, has the revealed preference property (which is a much stronger condition than revealed preferences for a single individual) or the gross substitute property then likewise the equilibrium will be unique. All methods of establishing uniqueness can be thought of as establishing that each equilibrium has the same positive local index, in which case by the index theorem there can be but one such equilibrium.
Determinacy.
Given that equilibria may not be unique, it is of some interest to ask whether any particular equilibrium is at least locally unique. If so, then comparative statics can be applied as long as the shocks to the system are not too large. As stated above, in a regular economy equilibria will be finite, hence locally unique. One reassuring result, due to Debreu, is that "most" economies are regular.
Work by Michael Mandler (1999) has challenged this claim. The Arrow–Debreu–McKenzie model is neutral between models of production functions as continuously differentiable and as formed from (linear combinations of) fixed coefficient processes. Mandler accepts that, under either model of production, the initial endowments will not be consistent with a continuum of equilibria, except for a set of Lebesgue measure zero. However, endowments change with time in the model and this evolution of endowments is determined by the decisions of agents (e.g., firms) in the model. Agents in the model have an interest in equilibria being indeterminate:
"Indeterminacy, moreover, is not just a technical nuisance; it undermines the price-taking assumption of competitive models. Since arbitrary small manipulations of factor supplies can dramatically increase a factor's price, factor owners will not take prices to be parametric.":17
When technology is modeled by (linear combinations) of fixed coefficient processes, optimizing agents will drive endowments to be such that a continuum of equilibria exist:
"The endowments where indeterminacy occurs systematically arise through time and therefore cannot be dismissed; the Arrow-Debreu-McKenzie model is thus fully subject to the dilemmas of factor price theory.":19
Critics of the general equilibrium approach have questioned its practical applicability based on the possibility of non-uniqueness of equilibria. Supporters have pointed out that this aspect is in fact a reflection of the complexity of the real world and hence an attractive realistic feature of the model.
Stability.
In a typical general equilibrium model the prices that prevail "when the dust settles" are simply those that coordinate the demands of various consumers for various goods. But this raises the question of how these prices and allocations have been arrived at, and whether any (temporary) shock to the economy will cause it to converge back to the same outcome that prevailed before the shock. This is the question of stability of the equilibrium, and it can be readily seen that it is related to the question of uniqueness. If there are multiple equilibria, then some of them will be unstable. Then, if an equilibrium is unstable and there is a shock, the economy will wind up at a different set of allocations and prices once the convergence process terminates. However stability depends not only on the number of equilibria but also on the type of the process that guides price changes (for a specific type of price adjustment process see Walrasian auction). Consequently some researchers have focused on plausible adjustment processes that guarantee system stability, i.e., that guarantee convergence of prices and allocations to some equilibrium. When more than one stable equilibrium exists, where one ends up will depend on where one begins.
Unresolved problems in general equilibrium.
Research building on the Arrow–Debreu–McKenzie model has revealed some problems with the model. The Sonnenschein–Mantel–Debreu results show that, essentially, any restrictions on the shape of excess demand functions are stringent. Some think this implies that the Arrow–Debreu model lacks empirical content. At any rate, Arrow–Debreu–McKenzie equilibria cannot be expected to be unique, or stable.
A model organized around the tâtonnement process has been said to be a model of a centrally planned economy, not a decentralized market economy. Some research has tried to develop general equilibrium models with other processes. In particular, some economists have developed models in which agents can trade at out-of-equilibrium prices and such trades can affect the equilibria to which the economy tends. Particularly noteworthy are the Hahn process, the Edgeworth process and the Fisher process.
The data determining Arrow-Debreu equilibria include initial endowments of capital goods. If production and trade occur out of equilibrium, these endowments will be changed further complicating the picture.
In a real economy, however, trading, as well as production and consumption, goes
on out of equilibrium. It follows that, in the course of convergence to equilibrium (assuming that occurs), endowments change. In turn this changes the set of equilibria. Put more succinctly, the set of equilibria is path dependent... [This path dependence]
makes the calculation of equilibria corresponding to the initial state of the system essentially irrelevant. What matters is the equilibrium that the economy will reach from given initial endowments, not the equilibrium that it would have been in, given initial endowments, had prices happened to be just right
(Franklin Fisher).
The Arrow–Debreu model in which all trade occurs in futures contracts at time zero requires a very large number of markets to exist. It is equivalent under complete markets to a sequential equilibrium concept in which spot markets for goods and assets open at each date-state event (they are not equivalent under incomplete markets); market clearing then requires that the entire sequence of prices clears all markets at all times. A generalization of the sequential market arrangement is the temporary equilibrium structure, where market clearing at a point in time is conditional on expectations of future prices which need not be market clearing ones.
Although the Arrow–Debreu–McKenzie model is set out in terms of some arbitrary numéraire, the model does not encompass money. Frank Hahn, for example, has investigated whether general equilibrium models can be developed in which money enters in some essential way. One of the essential questions he introduces, often referred to as the Hahn's problem is : "Can one construct an equilibrium where money has value?" The goal is to find models in which existence of money can alter the equilibrium solutions, perhaps because the initial position of agents depends on monetary prices.
Some critics of general equilibrium modeling contend that much research in these models constitutes exercises in pure mathematics with no connection to actual economies. "There are endeavors that now pass for the most desirable kind of economic contributions although they are just plain mathematical exercises, not only without any economic substance but also without any mathematical value." Georgescu-Roegen cites as an example a paper that assumes more traders in existence than there are points in the set of real numbers.
Although modern models in general equilibrium theory demonstrate that under certain circumstances prices will indeed converge to equilibria, critics hold that the assumptions necessary for these results are extremely strong. As well as stringent restrictions on excess demand functions, the necessary assumptions include perfect rationality of individuals; complete information about all prices both now and in the future; and the conditions necessary for perfect competition. However some results from experimental economics suggest that even in circumstances where there are few, imperfectly informed agents, the resulting prices and allocations may wind up resembling those of a perfectly competitive market (although certainly not a stable general equilibrium in all markets).
Frank Hahn defends general equilibrium modeling on the grounds that it provides a negative function. General equilibrium models show what the economy would have to be like for an unregulated economy to be Pareto efficient.
Computing general equilibrium.
Until the 1970s general equilibrium analysis remained theoretical. With advances in computing power and the development of input-output tables, it became possible to model national economies, or even the world economy, and attempts were made to solve for general equilibrium prices and quantities empirically.
Applied general equilibrium (AGE) models were pioneered by Herbert Scarf in 1967, and offered a method for solving the Arrow–Debreu General Equilibrium system in a numerical fashion. This was first implemented by John Shoven and John Whalley (students of Scarf at Yale) in 1972 and 1973, and were a popular method up through the 1970s. In the 1980s however, AGE models faded from popularity due to their inability to provide a precise solution and its high cost of computation. Also, Scarf's method was proven non-computable to a precise solution by Velupillai (2006).
Computable general equilibrium (CGE) models surpassed and replaced AGE models in the mid-1980s, as the CGE model was able to provide relatively quick and large computable models for a whole economy, and was the preferred method of governments and the World Bank. CGE models are heavily used today, and while 'AGE' and 'CGE' is used inter-changeably in the literature, Scarf-type AGE models have not been constructed since the mid-1980s, and the CGE literature at current is "not" based on Arrow-Debreu and General Equilibrium Theory as discussed in this article. CGE models, and what is today referred to as AGE models, are based on static, simultaneously solved, macro balancing equations (from the standard Keynesian macro model), giving a precise and explicitly computable result.
Other schools.
General equilibrium theory is a central point of contention and influence between the neoclassical school and other schools of economic thought, and different schools have varied views on general equilibrium theory. Some, such as the Keynesian and Post-Keynesian schools, strongly reject general equilibrium theory as "misleading" and "useless"; others, such as the Austrian school, show more influence and acceptance of general equilibrium thinking, though the extent is debated. Other schools, such as new classical macroeconomics, developed from general equilibrium theory.
Keynesian and Post-Keynesian.
Keynesian and Post-Keynesian economists, and their Underconsumptionist predecessors criticize general equilibrium theory specifically, and as part of criticisms of neoclassical economics generally. Specifically, they argue that general equilibrium theory is neither accurate nor useful, that economies are not in equilibrium, that equilibrium may be slow and painful to achieve, and that modeling by equilibrium is "misleading", and that the resulting theory is not a useful guide, particularly for understanding of economic crises.
Let us beware of this dangerous theory of equilibrium which is supposed to be automatically established. A certain kind of equilibrium, it is true, is reestablished in the long run, but it is after a frightful amount of suffering.—Simonde de Sismondi, "New Principles of Political Economy," vol. 1 (1819), 20-21.
The long run is a misleading guide to current affairs. In the long run we are all dead. Economists set themselves too easy, too useless a task if in tempestuous seasons they can only tell us that when the storm is past the ocean is flat again.—John Maynard Keynes, "A Tract on Monetary Reform," 1923, Ch. 3
It is as absurd to assume that, for any long period of time, the variables in the economic organization, or any part of them, will "stay put," in perfect equilibrium, as to assume that the Atlantic Ocean can ever be without a wave.—Irving Fisher, "The Debt-Deflation Theory of Great Depressions," 1933, p. 339
Robert Clower and others have argued for a reformulation of theory toward disequilibrium analysis to incorporate how monetary exchange fundamentally alters the representation of an economy as though a barter system.
More methodologically, it is argued that general equilibrium is a fundamentally "static" analysis, rather than a "dynamic" analysis, and thus is misleading and inapplicable. The theory of dynamic stochastic general equilibrium seeks to address this criticism.
Austrian economics.
Whether Austrian economics supports or rejects general equilibrium theory and the precise relationship is unclear. Different Austrian economists have advocated differing positions, which have changed as Austrian economics developed over time. Some new classical economists argue that the work of Friedrich Hayek in the 1920s and 1930s was in the general equilibrium tradition and was a precursor to business cycle equilibrium theory. Others argue that while there are clear influences of general equilibrium on Hayek's thought, and that he used it in his early work, he came to substantially reject it in his later work, post 1937. It is also argued by some that Friedrich von Wieser, along with Hayek, worked in the general equilibrium tradition, while others reject this, finding influences of general equilibrium on the Austrian economists superficial.
New classical macroeconomics.
While general equilibrium theory and neoclassical economics generally were originally microeconomic theories, New classical macroeconomics builds a macroeconomic theory on these bases. In new classical models, the macroeconomy is assumed to be at its unique equilibrium, with full employment and potential output, and that this equilibrium is assumed to always have been achieved via price and wage adjustment (market clearing). The best-known such model is Real Business Cycle Theory, in which business cycles are considered to be largely due to changes in the real economy, unemployment is not due to the failure of the market to achieve potential output, but due to equilibrium potential output having fallen and equilibrium unemployment having risen.
Socialist economics.
Within socialist economics, a sustained critique of general equilibrium theory (and neoclassical economics generally) is given in "Anti-Equilibrium", based on the experiences of János Kornai with the failures of Communist central planning.
Empirical economics.
This school takes as the starting point a discussion of scientific research methodology. The neoclassical theories, including the general equilibrium and DSGE varieties, adopt the hypothetico-axiomatic approach, which is based on posing axioms and adding assumptions. Based on this, theoretical models are developed which apply only to the theoretical worlds thus created. This is characterised as the 'deductive methodology'. By contrast, the empirical approach to economics adopts the 'inductive methodology', whereby the same method is employed in economics as in the natural sciences: The starting point is the compilation of observable facts. The data and facts may be suggestive of patterns and relationships: hypotheses and theories are thus formulated, which are then empirically tested, rejected, modified or not rejected. Concerning the question of market equilibrium, this approach argues that the requirements for market equilibrium are so stringent that we know for sure that it cannot apply to the world we live in: markets are thus likely to always be in a state of disequilibrium. Hence the short side principle applies, rendering quantities more important and indicating that agents on the short side can exert allocation power that enables them to extract benefits not reflected in prices. The approach has been particularly successful in incorporating money and credit into economic models, such as in the form of the Quantity Theory of Credit developed by Richard Werner.

</doc>
<doc id="45939" url="http://en.wikipedia.org/wiki?curid=45939" title="Primary color">
Primary color

Primary colors are sets of colors that can be combined to make a useful range of colors. For human applications, three primary colors are usually used, since human color vision is trichromatic.
For additive combination of colors, as in overlapping projected lights or in CRT displays, the primary colors normally used are red, green, and blue. For a subtractive combination of colors, as in mixing of pigments or dyes, such as in printing, the primaries normally used are magenta, yellow, and cyan, though the set of red, yellow, and blue is popular among artists.
See RGB color model, CMYK color model, and RYB color model for more on these popular sets of primary colors.
Any particular choice for a given set of primary colors is derived from the spectral sensitivity of each of the human cone photoreceptors; three colors that fall within each of the sensitivity ranges of each of the human cone cells are red, green, and blue. Other sets of colors can be used, though not all will well-approximate the full range of color perception. For example, an early color photographic process, autochrome, typically used orange, green, and violet primaries. However, unless negative amounts of a color are allowed the gamut will be restricted by the choice of primaries.
The combination of any two primary colors creates a secondary color.
The most commonly used additive color primaries are the secondary colors of the most commonly used subtractive color primaries, and vice versa.
Biological basis.
Primary colors are not a fundamental property of light but are related to the physiological response of the eye to light. Fundamentally, light is a continuous spectrum of the wavelengths that can be detected by the human eye, an infinite-dimensional stimulus space. However, the human eye normally contains only three types of color receptors, called cone cells. Each color receptor responds to different ranges of the color spectrum. Humans and other species with three such types of color receptors are known as trichromats. These species respond to the light stimulus via a three-dimensional sensation, which generally can be modeled as a mixture of three primary colors.
Before the nature of colorimetry and visual physiology were well understood, scientists such as Thomas Young, James Clerk Maxwell, and Hermann von Helmholtz expressed various opinions about what should be the three primary colors to describe the three primary color sensations of the eye. Young originally proposed red, green, and violet, and Maxwell changed violet to blue; Helmholtz proposed "a slightly purplish red, a vegetation-green, slightly yellowish (wavelength about 5600 tenth-metres), and an ultramarine-blue (about 4820)". In modern understanding, human cone cells do not correspond precisely to a specific set of primary colors, as each cone type responds to a range of color wavelengths.
Species with different numbers of receptor cell types would have color vision requiring a different number of primaries. For example, for species known as tetrachromats, with four different color receptors, one would use four primary colors. Since humans can only see to 380 nanometers (violet), but tetrachromats can see into the ultraviolet to about 300 nanometers, this fourth primary color for tetrachromats is located in the shorter-wavelength range.
Many birds and marsupials are tetrachromats, and it has been suggested that some human females are tetrachromats as well, having an extra variant version of the long-wave (L) cone type.
The peak response of human color receptors varies, even among individuals with "normal" color vision; in non-human species this polymorphic variation is even greater, and it may well be adaptive.
Most placental mammals other than primates have only two types of color receptors and are therefore dichromats; to them, there are only two primary colors.
It would be incorrect to assume that the world "looks tinted" to an animal (or human) with anything other than the human standard of three color receptors. To an animal (or human) born that way, the world would look normal to it, but the animal's ability to detect and discriminate colors would be different from that of a human with normal color vision. If a human and an animal both look at a natural color, they see it as natural; however, if both look at a color reproduced via primary colors, such as on a color television screen, the human may see it as matching the natural color, while the animal does not, since the primary colors have been chosen to suit human capabilities.
Additive primaries.
Media that combine emitted lights to create the sensation of a range of colors are using the additive color system. Typically, the primary colors used are red, green, and blue.
Television and other computer and video displays are a common example of the use of additive primaries and the RGB color model. The exact colors chosen for the primaries are a technological compromise between the available phosphors (including considerations such as cost and power usage) and the need for large color triangle to allow a large gamut of colors. The ITU-R BT.709-5/sRGB primaries are typical.
Additive mixing of red and green light produces shades of yellow, orange, or brown. Mixing green and blue produces shades of cyan, and mixing red and blue produces shades of purple, including magenta. Mixing nominally equal proportions of the additive primaries results in shades of grey or white; the color space that is generated is called an RGB color space.
The CIE 1931 color space defines "monochromatic" primary colors with wavelengths of 435.8 nm (violet), 546.1 nm (green) and 700 nm (red). The corners of the color triangle are therefore on the spectral locus, and the triangle is about as big as it can be. No real display device uses such primaries, as the extreme wavelengths used for violet and red result in a very low luminous efficiency.
Recent developments in primary colors.
Color practice technology is usefully contrasted with color theory science because science assumes perfect conditions, whereas commercially available products must deliver impressive results at affordable prices. Some recent TV and computer displays are starting to add a fourth "primary" of yellow, often in a four-point square pixel area, to get brighter pure yellows and larger color gamut.
Even the four-primary technology does not yet reach the range of colors the human eye is theoretically capable of perceiving (as defined by the sample-based estimate called the Pointer Gamut), with 4-primary LED prototypes providing typically about 87% and 5-primary prototypes about 95%. Several firms, including Samsung and Mitsubishi, have demonstrated LED displays with five or six "primaries", or color LED point light sources per pixel. A recent academic literature review claims a gamut of 99% can be achieved with 5-primary LED technology.
While technology for achieving a wider gamut appears to be within reach, other issues remain, for example affordability, dynamic range, brilliance. An even bigger problem is that there exists hardly any source material recorded in this wider gamut, nor is it possible to somehow recover this information in existing pictures, as it was never stored. Regardless, industry is still exploring a wide variety of "primary" active light sources (per pixel) with the goal of matching the capability of human color perception within a broadly affordable price. One example of a potentially affordable, but yet unproven active light hybrid places a LED screen over a plasma light screen, each with different "primaries". Because both LED and plasma technologies are many decades old (plasma pixels going back to the 1960s) and because sales are verging on a billion, both have become so affordable that they could be combined.
Subtractive primaries.
Media that use reflected light and colorants to produce colors are using the subtractive color method of color mixing.
CMYK color model, or four-color printing.
In the printing industry, to produce the varying colors the subtractive primaries cyan, magenta, and yellow are applied together in varying amounts. Before the color names "cyan" and "magenta" were in common use, these primaries were often known as blue-green and purple, or in some circles as blue and red, respectively, and their exact color has changed over time with access to new pigments and technologies.
Mixing yellow and cyan produces green colors; mixing yellow with magenta produces reds, and mixing magenta with cyan produces blues. In theory, mixing equal amounts of all three pigments should produce grey, resulting in black when all three are applied in sufficient density, but in practice they tend to produce muddy brown colors. For this reason, and to save ink and decrease drying times, a fourth pigment, black, is often used in addition to cyan, magenta, and yellow.
The resulting model is the so-called CMYK color model. The abbreviation stands for cyan, magenta, yellow, and key—black is referred to as the "key" color, a shorthand for the "key printing plate" that impressed the artistic detail of an image, usually in black ink.
In practice, colorant mixtures in actual materials such as paint tend to be more complex. Brighter or more saturated colors can be created using natural pigments instead of mixing, and natural properties of pigments can interfere with the mixing. For example, mixing magenta and green in acrylic creates a dark cyan—something which would not happen if the mixing process were perfectly subtractive.
In the subtractive model, adding white to a color, whether by using less colorant or by mixing in a reflective white pigment such as zinc oxide, does not change the color's hue but does reduce its saturation. Subtractive color printing works best when the surface or paper is white, or close to it.
A system of subtractive color does not have a simple chromaticity gamut analogous to the RGB color triangle, but a gamut that must be described in three dimensions. There are many ways to visualize such models, using various 2D chromaticity spaces or in 3D color spaces.
History.
RYB color model.
RYB (red, yellow, and blue) is a historical set of colors. It is primarily used in art and art education, particularly painting. It predates modern scientific color theory.
RYB make up the primary colors in a painter's color wheel; the secondary colors VOG (violet, orange, and green) make up another triad. Triads are formed by 3 equidistant colors on a particular color wheel; neither RYB nor VOG is equidistant on a perceptually uniform color wheel, but rather have been "defined" to be equidistant in the RYB wheel.
Painters have long used more than three "primary" colors in their palettes—and at one point considered red, yellow, blue, and green to be the "four" primaries. Red, yellow, blue, and green are still widely considered the four psychological primary colors, though red, yellow, and blue are sometimes listed as the "three" psychological primaries, with black and white occasionally added as a fourth and fifth.
During the 18th century, as theorists became aware of Isaac Newton's scientific experiments with light and prisms, red, yellow, and blue became the canonical primary colors—supposedly the fundamental sensory qualities that are blended in the perception of all physical colors and equally in the physical mixture of pigments or dyes. This theory became dogma, despite abundant evidence that red, yellow, and blue primaries cannot mix all other colors, and has survived in color theory to the present day.
Using red, yellow, and blue as primaries yields a relatively small gamut, in which, among other problems, colorful greens, cyans, purples, and magentas are impossible to mix, because red, yellow, and blue do not correspond to the subtractive primaries dictated by human color vision. For this reason, modern three- or four-color printing processes, as well as color photography, use cyan, yellow, and magenta as primaries instead. Since cyan pigment absorbs red light, magenta absorbs green, and yellow absorbs blue, they each allow the other two light primaries to be reflected (or transmitted) and reach the eye. Thus when two of them are mixed, they do not absorb so much of the spectrum as to produce black, which is the absence of light. Most painters include colors in their palettes which cannot be mixed from yellow, red, and blue paints, and thus do not fit within the RYB color model. Some who do use a three-color palette opt for the cyan, yellow, and magenta used by printers, and others paint with 6 or more colors to widen their gamuts. The cyan, magenta, and yellow used in printing are sometimes known as "process blue," "process red," and "process yellow."
Psychological primaries.
The opponent process is a color theory that states that the human visual system interprets information about color by processing signals from cones and rods in an antagonistic manner. The three types of cones have some overlap in the wavelengths of light to which they respond, so it is more efficient for the visual system to record "differences" between the responses of cones, rather than each type of cone's individual response. The opponent color theory suggests that there are three opponent channels: red versus green, blue versus yellow, and black versus white. Responses to one color of an opponent channel are antagonistic to those of the other color. The theory states that the particular colors considered by an observer to be uniquely representative of the concepts red, yellow, green, blue, white, and black might be called "psychological primary colors", because any other color could be described in terms of some combination of these.

</doc>
<doc id="45943" url="http://en.wikipedia.org/wiki?curid=45943" title="Swastika">
Swastika

The swastika (also known as the gammadion cross, cross cramponnée, or manji) is a symbol that generally takes the form of an equilateral cross, with its four legs bent at 90 degrees (as a Chinese character: 卐 or 卍). It is considered to be a very sacred and auspicious symbol in Hinduism, Buddhism and Jainism.
It appears as a decorative element in various cultures since at least the Neolithic, and is mostly known as a symbol in Indian religions, denoting "auspiciousness", adopted as such in pre-WWI-Europe and later, and most notably, by the Nazi Party and Nazi Germany.
Because of its use in Nazism, in many Western countries the swastika is stigmatized, while it remains commonly used as a religious symbol in Hinduism and Buddhism.
The word "swastika" derives from the Sanskrit "svastika" "lucky or auspicious object".
The older term "gammadion cross" derives mainly from its appearance, which is identical to four Greek gamma letters affixed to each other.
Names.
The word "swastika" has been in use in English since the 1870s, replacing "gammadion" (from Greek γαμμάδιον).
It was loaned from the Sanskrit term "svastika" (Devanagari: स्वस्तिक), meaning any lucky or auspicious object, and in particular a mark made on persons and things to denote auspiciousness, or any piece of luck or well-being.
It is composed of "su-" meaning "good, well" and "asti" "being"; the suffix "-ka" either forms a diminutive or intensifies the verbal meaning, and "suastika" might thus be translated literally as "that which is associated with well-being," corresponding to "lucky charm" or "thing that is auspicious."
The word does not occur in Vedic Sanskrit. As noted by Monier-Williams in his Sanskrit-English dictionary, according to Alexander Cunningham, its shape represents a monogram formed by interlacing of the letters of the auspicious words "su-astí" ("svasti") written in Ashokan characters.
Other names for the symbol include:
Symbol in various scripts.
The swastika has been a standardized Chinese character "卍" () and as such entered various other East Asian languages such as Japanese where the symbol is called "卍" (Hepburn: manji) or "卍字" (manji).
The swastika is included as part of the Chinese script and has Unicode encodings U+534D 卍 (left-facing) and U+5350 卐 (right-facing); the latter has a mapping in the original Big5 character set, but the former does not (although it is in Big5+). In Unicode 5.2, four swastika symbols were added to the Tibetan block: , , and 
Geometry.
Geometrically, the swastika can be regarded as an irregular icosagon or 20-sided polygon. The proportions of the Nazi swastika were fixed based on a 5 × 5 diagonal grid.
Characteristic is the 90° rotational symmetry and chirality, hence the absence of reflectional symmetry, and the existence of two versions of swastikas that are each other's mirror image.
The mirror-image forms are often described as:
Origin hypotheses.
The earliest known object with swastika-motifs is a bird from the tusk of a mammoth from the paleolithic settlement of Mezine, Ukraine dated to 10,000 BCE.
Among the earliest cultures utilizing swastika is the neolithic Vinča culture of South-East Europe (see Vinča symbols). More extensive use of the Swastika can be traced to Ancient India, during the Indus Valley Civilization.
The swastika is a repeating design, created by the edges of the reeds in a square basket-weave. Other theories attempt to establish a connection via cultural diffusion or an explanation along the lines of Carl Jung's collective unconscious.
The genesis of the swastika symbol is often treated in conjunction with cross symbols in general, such as the sun cross of pagan Bronze Age religion. Beyond its certain presence in the "proto-writing" symbol systems emerging in the Neolithic, nothing certain is known about the symbol's origin. There are nevertheless a number of speculative hypotheses. One hypothesis is that the cross symbols and the swastika share a common origin in simply symbolizing the sun. Another hypothesis is that the 4 arms of the cross represent 4 aspects of nature - the sun, wind, water, soil. Some have said the 4 arms of cross are four seasons, where the division for 90-degree sections correspond to the solstices and equinoxes. The Hindus represent it as the Universe in our own spiral galaxy in the fore finger of Lord Vishnu. This carries most significance in establishing the creation of the Universe and the arms as 'kal' or time, a calendar that is seen to be more advanced than the lunar calendar where the seasons drift from calendar year to calendar year. The luni-solar solution for correcting season drift was to intercalate an extra month in certain years to restore the lunar cycle to the solar-season cycle. The Star of David is thought to originate as a symbol of that calendar system, where the two overlapping triangles are seen to form a partition of 12 sections around the perimeter with a 13th section in the middle, representing the 12 and sometimes 13 months to a year. As such, the Christian cross, Jewish hexagram star and the Muslim crescent moon are seen to have their origins in different views regarding which calendar system is preferred for marking holy days. Groups in higher latitudes experience the seasons more strongly, offering more advantage to the calendar represented by the swastika/cross. (Note relation to the sun cross.)
According to Reza Assasi, Swastika is a geometric pattern in the sky representing the north ecliptic pole centred to Zeta Draconis. He argues that this primitive astrological symbol was later called the four-horse chariot of Mithra in ancient Iran and represented the centre of Ecliptic in the star map and also demonstrates that in Iranian mythology, the cosmos was believed to be pulled by four heavenly horses revolving around a fixed centre on clockwise direction possibly because of a geocentric understanding of an astronomical phenomenon called axial precession. He suggests that this notion was transmitted to the west and flourished in Roman mithraism in which this symbol appears in Mithraic iconography and astrological representations.
Carl Sagan in his book "Comet" (1985) reproduces Han period Chinese manuscript (the "Book of Silk", 2nd century BC) that shows comet tail varieties: most are variations on simple comet tails, but the last shows the comet nucleus with four bent arms extending from it, recalling a swastika. Sagan suggests that in antiquity a comet could have approached so close to Earth that the jets of gas streaming from it, bent by the comet's rotation, became visible, leading to the adoption of the swastika as a symbol across the world.
Bob Kobres in (1992) contends that the swastika like comet on the Han Dynasty silk comet atlas was labeled a "long tailed pheasant star" (Di-Xing) because of its resemblance to a or Kobres goes on to suggest an association of mythological birds and comets also outside China.
In "Life's Other Secret" (1999), Ian Stewart suggests the ubiquitous swastika pattern arises when parallel waves of neural activity sweep across the visual cortex during states of altered consciousness, producing a swirling swastika-like image, due to the way quadrants in the field of vision are mapped to opposite areas in the brain.
Alexander Cunningham suggested that the Buddhist use of the shape arose from a combination of Brahmi characters abbreviating the words "su astí".
Archeological record.
The earliest swastika known has been found in Mezine, Ukraine. It is carved on late paleolithic figurine of mammoth ivory, being dated as early as about 10,000 BC. It has been suggested this swastika may be a stylized picture of a stork in flight and not the true swastika that is in use today.
In England, neolithic or Bronze Age stone carvings of the symbol have been found on Ilkley Moor.
Mirror-image swastikas (clockwise and anti-clockwise) have been found on ceramic pottery in the Devetashka cave, Bulgaria, dated 6,000 B.C.
Some of the earliest archaeological evidences of Swastika in the Indian subcontinent can be dated to 3,000 BCE. Swastikas have also been found on pottery in archaeological digs in Africa, in the area of Kush and on pottery at the Jebel Barkal temples, in Iron Age designs of the northern Caucasus (Koban culture), and in Neolithic China in the Majiabang, Dawenkou and Xiaoheyan cultures.
Other Iron Age attestations of the swastika can be associated with Indo-European cultures such as the Indo-Iranians, Celts, Greeks, Germanic peoples and Slavs.
The swastika is also seen in Egypt during the Coptic period. Textile number T.231-1923 held at the V&A Museum in London includes small swastikas in its design. This piece was found at Qau-el-Kebir, near Asyut, and is dated between AD300-600.
The "Tierwirbel" (the German for "animal whorl" or "whirl of animals") is a characteristic motif in Bronze Age Central Asia, the Eurasian Steppe, and later also in Iron Age Scythian and European (Baltic and Germanic) culture, showing rotational symmetric arrangement of an animal motif, often four birds' heads. Even wider diffusion of this "Asiatic" theme has been proposed, to the Pacific and even North America (especially Moundville).
Worldwide use.
Asia.
In Asia, the swastika symbol first appears in the archaeological record around 3000 BC in the Indus Valley Civilization. It also appears in the Bronze and Iron Age cultures around the Black Sea and the Caspian Sea. In all these cultures the swastika symbol does not appear to occupy any marked position or significance, but appears as just one form of a series of similar symbols of varying complexity. In the Zoroastrian religion of Persia, the swastika was a symbol of the revolving sun, infinity, or continuing creation. It rose to importance in Buddhism during the Mauryan Empire and in Hinduism with the decline of Buddhism in India during the Gupta Empire. With the spread of Buddhism, the Buddhist swastika reached Tibet and China. The symbol was also introduced to Balinese Hinduism by Hindu kings. The use of the swastika by the Bön faith of Tibet, as well as Chinese Taoism, can also be traced to Buddhist influence. In Thailand, the word "Sawaddi" is normally used as a greeting which simply means "hello"; Sawaddi-ka (feminine) and Sawaddi-krup (masculine). "Sawaddi" derives from the Sanskrit word "swasti" and its meaning is a combination of the words: prosperity, luck, security, glory, and good.
Hinduism.
The swastika is well-recognized as an important Hindu symbol. It represents God (the Brahman) in his universal manifestation, and energy ("Shakti"). It represents the four directions of the world (the four faces of Brahma). It also represents the Purushartha: Dharma (natural order), Artha (wealth), Kama (desire), and Moksha (liberation). The swastika symbol is traced with sindoor during Hindu religious rites.
Among the Hindus of Bengal, it is common to see the name "swastika" (Bengali: স্বস্তিক "shostik") applied to a slightly different symbol, which has the same significance as the common swastika, that looks like a stick figure of a human being. Right-facing swastika in the decorative Hindu form is used to evoke the Shakti.
Buddhism.
Buddhism originated in the 5th century BC and spread throughout the Indian subcontinent. In the 3rd century BC (Maurya Empire).
Known as a "yungdrung" in ancient Tibet, it was a graphical representation of eternity.
Jainism.
Jainism gives even more prominence to the swastika as a tantra than Hinduism does. It is a symbol of the seventh tīrthaṅkara, Suparśvanātha. In the Śvētāmbara tradition, it is also one of the aṣṭamaṅgala. All Jain temples and holy books must contain the swastika and ceremonies typically begin and end with creating a swastika mark several times with rice around the altar. Jains use rice to make a swastika in front of statues and then put an offering on it, usually a ripe or dried fruit, a sweet (Hindi: मिठाई miṭhāī), or a coin or currency note. The four arms of the swastika symbolize the four places where a soul could be reborn in the cycle of birth and death - svarga "heaven", naraka "hell", manushya "humanity" or "tiryancha" "as flora or fauna" - before the soul attains moksha "salvation" as a siddha, having ended the cycle of birth and death and become free and omniscient.
Other East Asian traditions.
The paired swastika symbols are included, at least since the Liao Dynasty (AD 907–1125), as part of the Chinese writing system (卍 and 卐) and are variant characters for 萬 or 万 ("wàn" in Mandarin, "man" in Korean, Cantonese and Japanese, "vạn" in Vietnamese) meaning "all" or "eternity" (lit. myriad). The swastika marks the beginning of many Buddhist scriptures. In East Asian countries, the left-facing character is often used as symbol for Buddhism and marks the site of a Buddhist temple on maps.
In Chinese, Japanese, and Korean the swastika is also a homonym of the number 10,000, and is commonly used to represent the whole of Creation, e.g. 'the myriad things' in the Dao De Jing. During the Chinese Tang Dynasty, Empress Wu Zetian (684-704) decreed that the swastika would also be used as an alternative symbol of the Sun.
When the Chinese writing system was introduced to Japan in the 8th century, the swastika was adopted into the Japanese language and culture, with the meaning remained unchanged but slight change on its pronunciation. It is commonly referred as the "manji" (lit. Man-character). Since the Middle Ages, it has been used as a "mon" by various Japanese families such as Tsugaru clan, Hachisuka clan or around 60 clans that belong to Tokugawa clan. On Japanese maps, a swastika (left-facing and horizontal) is used to mark the location of a Buddhist temple. The right-facing "manji" is often referred to as the "gyaku manji" (逆卍, lit. "reverse "manji"") or "migi manji" (右卍, lit. "right "manji""), and can also be called "kagi jūji" (鉤十字, literally "hook cross").
In Chinese and Japanese art, the swastika is often found as part of a repeating pattern. One common pattern, called "sayagata" in Japanese, comprises left- and right-facing swastikas joined by lines. As the negative space between the lines has a distinctive shape, the sayagata pattern is sometimes called the "key fret"" motif in English.
As a pottery graph of unknown provision and meaning the swastika-like sign is known in Chinese Neolithic culture (2400–2000 BCE, Liu wan 柳湾, Qinghai province).
Armenia.
In Armenia swastika is called "arevakhach" and "kerkhach" (Armenian: կեռխաչ) and is the ancient symbol of eternity and eternal light (i.e. God). Swastikas in Armenia were founded on petroglyphs. During the bronze age it was depicted on cauldrons, belts, medallions and other items. Among the oldest petroglyphs is the seventh letter of the Armenian alphabet - "E" (which means "is" or "to be") - depicted as half-swastika.
Swastikas can also be seen on early Medieval churches and fortresses, including the principal tower in Armenia's historical capital city of Ani. The same symbol can be found on Armenian carpets, cross-stones (khachkar) and in medieval manuscripts, as well as on modern monuments (symbol of eternity).
Europe.
In Bronze Age Europe, the "Sun cross" (a three- or four-armed hooked cross in a circle) appears frequently, often interpreted as a solar symbol. Swastika shapes have been found on numerous artifacts from Iron Age Europe - Armenian Arevakhach(Armenian: Արևախաչ, արև arev "sun" + խաչ xač "cross", "sun cross"), Greco-Roman, Illyrian, Etruscan, Baltic, Celtic, Germanic, Slavic.
Greco-Roman antiquity.
Ancient Greek architectural, clothing and coin designs are replete with single or interlinking swastika motifs. There are also gold plate fibulae from the 8th century BC decorated with an engraved swastika. Related symbols in classical Western architecture include the cross, the three-legged triskele or triskelion and the rounded lauburu. The swastika symbol is also known in these contexts by a number of names, especially "gammadion", or rather the tetra-gammadion. The name gammadion comes from the fact that it can be seen as being made up of four Greek gamma (Γ) letters. Ancient Greek priestesses would tattoo the symbol, along with the tetraskelion, on their bodies. Ancient Greek architectural designs are replete with the interlinking symbol.
In Greco-Roman art and architecture, and in Romanesque and Gothic art in the West, isolated swastikas are relatively rare, and the swastika is more commonly found as a repeated element in a border or tessellation. The swastika often represented perpetual motion, reflecting the design of a rotating windmill or watermill. A meander of connected swastikas makes up the large band that surrounds the Augustan Ara Pacis. A design of interlocking swastikas is one of several tessellations on the floor of the cathedral of Amiens, France. A border of linked swastikas was a common Roman architectural motif, and can be seen in more recent buildings as a neoclassical element. A swastika border is one form of meander, and the individual swastikas in such a border are sometimes called "Greek keys". There have also been swastikas found on the floors of Pompeii.
Celts.
The bronze frontispiece of a ritual pre-Christian (c. 350-50 BC) shield found in the River Thames near Battersea Bridge (hence "Battersea Shield") is embossed with 27 swastikas in bronze and red enamel. An Ogham stone found in Anglish, Co Kerry, Ireland (CIIC 141) was modified into an early Christian gravestone, and was decorated with a cross pattée and two swastikas. The Book of Kells (ca. 800) contains swastika-shaped ornamentation. At the Northern edge of Ilkley Moor in West Yorkshire, there is a swastika-shaped pattern engraved in a stone known as the Swastika Stone.
The figure in the foreground of the picture is a 20th-century replica; the original carving can be seen a little farther away, at left of center.
Germanic Iron Age.
The swastika shape (also called a "fylfot") appears on various Germanic Migration Period and Viking Age artifacts, such as the 3rd century Værløse Fibula from Zealand, Denmark, the Gothic spearhead from Brest-Litovsk, today in Belarus, the 9th century Snoldelev Stone from Ramsø, Denmark, and numerous Migration Period bracteates drawn left-facing or right-facing.
The pagan Anglo-Saxon ship burial at Sutton Hoo, England, contained numerous items bearing the swastika, now housed in the collection of the Cambridge Museum of Archaeology and Anthropology. The Swastika is clearly marked on a hilt and sword belt found at Bifrons in Kent, in a grave of about the 6th century.
Hilda Ellis Davidson theorized that the swastika symbol was associated with Thor, possibly representing his hammer Mjolnir - symbolic of thunder - and possibly being connected to the Bronze Age sun cross. Davidson cites "many examples" of the swastika symbol from Anglo-Saxon graves of the pagan period, with particular prominence on cremation urns from the cemeteries of East Anglia. Some of the swastikas on the items, on display at the Cambridge Museum of Archaeology and Anthropology, are depicted with such care and art that, according to Davidson, it must have possessed special significance as a funerary symbol. The runic inscription on the 8th-century Sæbø sword has been taken as evidence of the swastika as a symbol of Thor in Norse paganism.
Illyrians.
Swastika was widespread among the Illyrians, symbolizing the Sun. The Sun cult was the main Illyrian cult, and the Sun was represented by a swastika in clockwise motion, and it stood for the movement of the Sun.
Slavic.
The "Słoneczko" (lit. "little sun") is an Early Slavic pagan symbol of the sun. It was engraved on wooden monuments built near the final resting places of fallen Slavs to represent eternal life. The symbol was first seen in a collection of Early Slavic symbols and architectural features drawn and compiled by Polish painter Stanisław Jakubowski, which he named "Prasłowiańskie motywy architektoniczne" (Polish: "Early Slavic Architectural Motifs"). His work of art was published in 1923, by a publishing house that was then based in the Dębniki district of Kraków. Symbol can also be found on embroidery and pottery in most Slavic countries.
In contemporary times, "Słoneczko" has become known in Russia as Коловрат (Kolovrat - lit. "spinning wheel"). Russian neopagans have adopted it as a traditional symbol of the pre-Christian Slavic faith. The neopagans say that Коловрат is a native Russian name for the swastika as a solar symbol. However, according to the historian and theologian Роман Багдасаров (Roman Bagdasarov), no known historical sources referring to the swastika as "Kolovrat" have been discovered in Russia.
Коловрат has also been appropriated by nationalist organizations and Neo-Nazis in Russia, who claim it is an ancient symbol that is exclusive to the East Slavs.
Similar words to Коловрат in other Slavic languages include the Polish "Kołowrót" and the Slovak "Kolovrátok", both of which are used solely to describe the wheel and axle and usually have no connotations with the symbol originally known in Polish as "Słoneczko".
Sami.
An object very much like a hammer or a double axe is depicted among the magical symbols on the drums of Sami shamans, used in their religious ceremonies before Christianity was established. The name of the Sami thunder god was Horagalles, thought to be derived from "Old Man Thor" ("Þórr karl"). Sometimes on the drums, a male figure with a hammer-like object in either hand is shown, and sometimes it is more like a cross with crooked ends, or a swastika.
Medieval and early modern Europe.
In Christianity, the swastika is used as a hooked version of the Christian Cross, the symbol of Christ's victory over death. Some Christian churches built in the Romanesque and Gothic eras are decorated with swastikas, carrying over earlier Roman designs. Swastikas are prominently displayed in a mosaic in the St. Sophia church of Kiev, Ukraine dating from the 12th century. They also appear as a repeating ornamental motif on a tomb in the Basilica of St. Ambrose in Milan.
A ceiling painted in 1910 in the church of St Laurent in Grenoble has many swastikas. It can be visited today because the church became the archaeological museum of the city. A proposed direct link between it and a swastika floor mosaic in the Cathedral of Our Lady of Amiens, which was built on top of a pagan site at Amiens, France in the 13th century, is considered unlikely. The stole worn by a priest in the 1445 painting of the Seven Sacraments by Rogier van der Weyden presents the swastika form simply as one way of depicting the cross. Swastikas also appear on the vestments on the effigy of Bishop William Edington (d. 1366) in Winchester Cathedral, as can be seen at .
In the Polish First Republic the symbol of the swastika was also popular with the nobility. According to chronicles, the Rus' prince Oleg, who in the 9th century attacked Constantinople, nailed his shield (which had a large red swastika painted on it) to the city's gates. Several noble houses, e.g. Boreyko, Borzym, and Radziechowski from Ruthenia, also had Swastikas as their coat of arms. The family reached its greatness in the 14th and 15th centuries and its crest can be seen in many heraldry books produced at that time.
The Swastika was also a heraldic symbol, for example on the Boreyko coat of arms, used by noblemen in Poland and Ukraine. In the 19th century the swastika was one of the Russian empire's symbols; it was even placed in coins as a background to the Russian eagle.
Freemasons also gave the swastika symbol importance. In medieval Northern European Runic Script, a counter-clockwise swastika denotes the letter 'G,' and could stand for the important Freemason terms God, Great Architect of the Universe, or Geometry.
A swastika can be seen on stonework at Valle Crucis Abbey, near Llangollen.
Early 20th-century Europe.
Swastikas on the wedding dress as symbols of luck, British colony, 1910
In the Western world, the symbol experienced a resurgence following the archaeological work in the late 19th century of Heinrich Schliemann, who discovered the symbol in the site of ancient Troy and associated it with the ancient migrations of Proto-Indo-Europeans, whose proto-language was not incidentally termed "Proto-Indo-Germanisch" by German language historians. He connected it with similar shapes found on ancient pots in Germany, and theorized that the swastika was a "significant religious symbol of our remote ancestors", linking Germanic, Greek and Indo-Iranian cultures. By the early 20th century, it was used worldwide and was regarded as a symbol of good luck and success.
The work of Schliemann soon became intertwined with the "völkisch" movements, for which the swastika was a symbol of the "Aryan race", a concept that came to be equated by theorists such as Alfred Rosenberg with a Nordic master race originating in northern Europe. Since its adoption by the Nazi Party of Adolf Hitler, the swastika has been associated with Nazism, fascism, racism in its (white supremacy) form, the Axis powers in World War II, and the Holocaust in much of the West. The swastika remains a core symbol of Neo-Nazi groups, and is used regularly by activist groups.
The Benedictine choir school at Lambach Abbey, Upper Austria, which Hitler attended for several months as a boy, had a swastika chiseled into the monastery portal and also the wall above the spring grotto in the courtyard by 1868. Their origin was the personal coat of arms of Abbot Theoderich Hagn of the monastery in Lambach, which bore a golden swastika with slanted points on a blue field. The Lambach swastika is probably of Medieval origin.
Denmark.
The Danish brewery company Carlsberg Group used the swastika as a logo from the 19th Century until the middle of the 1930s when it was discontinued because of association with the Nazi Party in neighbouring Germany. The swastika carved on elephants at the entrance gates of the company's headquarters in Copenhagen in 1901 can still be seen today.
Ireland.
The Swastika Laundry was a laundry founded in 1912, located on Shelbourne Road, Ballsbridge, a district of Dublin, Ireland. In the fifties Heinrich Böll came across a van belonging to the company while he was staying in Ireland, leading to some awkward moments before he realized the company was older than Nazism and totally unrelated to it. The chimney of the boiler-house of the laundry still stands, but the laundry has been redeveloped.
Finnish folklore.
In Finland the swastika was often used in traditional folk art products, as a decoration or magical symbol on textiles and wood. The swastika was also used by the Finnish Air Force until 1945, and is still used in air force flags.
The tursaansydän is used by scouts in some instances and a student organization. The village of Tursa uses the tursaansydän as a kind of a certificate of authenticity on products made there. Traditional textiles are still being made with swastikas as parts of traditional ornaments.
Swastika in Finnish military.
The Finnish Air Force uses the swastika as an emblem, introduced in 1918. The type of swastika adopted by the air-force was the symbol of luck for the Swedish count Eric von Rosen, who donated one of its earliest aircraft; he later became a prominent figure in the Swedish nazi-movement.
The swastika was also used by the women's paramilitary organization Lotta Svärd, which was banned in 1944 in accordance with the Moscow Armistice between Finland and the allied Soviet Union and Britain.
The President of Finland is the grand master of the Order of the White Rose. According to the protocol, the president shall wear the Grand Cross of the White Rose with collar on formal occasions. The original design of the collar, decorated with 9 swastikas, dates from 1918, and was designed by the artist Akseli Gallen-Kallela. The Grand Cross with the swastika collar has been awarded 41 times to foreign heads of state. To avoid misunderstandings, the swastika decorations were replaced by fir crosses at the decision of president Urho Kekkonen in 1963 after it became known that the President of France Charles De Gaulle was uncomfortable with the swastika collar.
Also a design by Gallen-Kallela from 1918, the Cross of Liberty has a swastika pattern in its arms. The Cross of Liberty is depicted in the upper left corner of the standard of the President of Finland.
In December 2007, a silver replica of the WWII period Finnish air defence's relief ring decorated with a swastika became available as a part of a charity campaign.
The original war time idea was that the public swap their precious metal rings for the State air defence's relief ring, made of iron.
Latvia.
Latvia adopted the swastika, called the Ugunskrusts ("fire cross"), for its air force in 1918/1919 and continued its use until 1940. The cross itself was maroon on a white background, mirroring the colors of the Latvian flag. Earlier versions pointed counter-clockwise, while later versions pointed clock-wise and eliminated the white background.
North America.
The swastika motif is found in some traditional Native American art and iconography. Historically, the design has been found in excavations of Mississippian-era sites in the Ohio and Mississippi River valleys, and on objects associated with the Southeastern Ceremonial Complex (S.E.C.C.). It is also widely used by a number of southwestern tribes, most notably the Navajo, and plains nations such as the Dakota. Among various tribes, the swastika carries different meanings. To the Hopi it represents the wandering Hopi clan; to the Navajo it is one symbol for the whirling log ("tsil no'oli"), a sacred image representing a legend that is used in healing rituals. A brightly colored First Nations saddle featuring swastika designs is on display at the Royal Saskatchewan Museum in Canada.
A swastika shape is a symbol in the culture of the Kuna people of Kuna Yala, Panama. In Kuna tradition it symbolizes the octopus that created the world, its tentacles pointing to the four cardinal points.
In February 1925 the Kuna revolted vigorously against Panamanian suppression of their culture, and in 1930 they assumed autonomy. The flag they adopted at that time is based on the swastika shape, and remains the official flag of Kuna Yala. A number of variations on the flag have been used over the years: red top and bottom bands instead of orange were previously used, and in 1942 a ring (representing the traditional Kuna nose-ring) was added to the center of the flag to distance it from the symbol of the Nazi party.
The symbol for the 45th Infantry Division of the United States Army, before the 1930s, was a red square with a yellow swastika, a tribute to the large Native American population in the southwestern United States.
The town of Swastika, Ontario, Canada is named after the symbol.
As the symbol of Nazism.
In the wake of widespread popular usage, the Nazi Party ("Nationalsozialistische Deutsche Arbeiterpartei" or "NSDAP") formally adopted the swastika (in German: "Hakenkreuz" [hook-cross]) in 1920. This was used on the party's flag, badge, and armband.
In his 1925 work "Mein Kampf," Adolf Hitler writes that: "I myself, meanwhile, after innumerable attempts, had laid down a final form; a flag with a red background, a white disk, and a black swastika in the middle. After long trials I also found a definite proportion between the size of the flag and the size of the white disk, as well as the shape and thickness of the swastika."
When Hitler created a flag for the Nazi Party, he sought to incorporate both the swastika and "those revered colors expressive of our homage to the glorious past and which once brought so much honor to the German nation." (Red, white, and black were the colors of the flag of the old German Empire.) He also stated: "As National Socialists, we see our program in our flag. In red, we see the social idea of the movement; in white, the nationalistic idea; in the swastika, the mission of the struggle for the victory of the Aryan man, and, by the same token, the victory of the idea of creative work."
The swastika was also understood as "the symbol of the creating, effecting life" ("das Symbol des schaffenden, wirkenden Lebens") and as "race emblem of Germanism" ("Rasseabzeichen des Germanentums").
The use of the swastika was incorporated by Nazi theorists with their conjecture of Aryan cultural descent of the German people. Following the Nordicist version of the Aryan invasion theory, the Nazis claimed that the early Aryans of India, from whose Vedic tradition the swastika sprang, were the prototypical white invaders. The concept of racial hygiene was an ideology central to Nazism, though it is now considered unscientific. For Alfred Rosenberg, the Aryans of India were both a model to be imitated and a warning of the dangers of the spiritual and racial "confusion" that, he believed, arose from the close proximity of races. Thus, they saw fit to co-opt the sign as a symbol of the Aryan master race. The use of the swastika as a symbol of the Aryan race dates back to writings of Emile Burnouf. Following many other writers, the German nationalist poet Guido von List believed it to be a uniquely Aryan symbol.
Before the Nazis, the swastika was already in use as a symbol of German "völkisch" nationalist movements ("Völkische Bewegung"). In "Deutschland Erwache" (ISBN 0-912138-69-6), Ulric of England [sic] says:
[...] what inspired Hitler to use the swastika as a symbol for the NSDAP was its use by the Thule Society (German: Thule-Gesellschaft) since there were many connections between them and the DAP ... from 1919 until the summer of 1921 Hitler used the special Nationalsozialistische library of Dr. Friedrich Krohn, a very active member of the "Thule-Gesellschaft" ... Dr. Krohn was also the dentist from Sternberg who was named by Hitler in "Mein Kampf" as the designer of a flag very similar to one that Hitler designed in 1920 ... during the summer of 1920, the first party flag was shown at Lake Tegernsee ... these home-made ... early flags were not preserved, the "Ortsgruppe München" (Munich Local Group) flag was generally regarded as the first flag of the Party.
José Manuel Erbez says:
The first time the swastika was used with an Aryan meaning was on December 25, 1907, when the self-named Order of the New Templars, a secret society founded by [Adolf Joseph] Jörg Lanz von Liebenfels, hoisted at Werfenstein Castle (Austria) a yellow flag with a swastika and four fleurs-de-lys.
However, Liebenfels was drawing on an already established use of the symbol.
On March 14, 1933, shortly after Hitler's appointment as Chancellor of Germany, the NSDAP flag was hoisted alongside Germany's national colors. It was adopted as the sole national flag on September 15, 1935 (see Nazi Germany).
The swastika was used for badges and flags throughout Nazi Germany, particularly for government and military organizations, but also for "popular" organizations such as the "Reichsbund Deutsche Jägerschaft" (German Hunting Society).
While the DAP and the NSDAP had used both right-facing and left-facing swastikas, the right-facing swastika was used consistently from 1920 onwards. Ralf Stelter notes that the swastika flag used on land had a right-facing swastika on both sides, while the ensign (naval flag) had it printed through so that a left-facing swastika would be seen when looking at the ensign with the flagpole to the right. Nazi ensigns had a through and through image, so both versions were present, one on each side, but the Nazi flag on land was right-facing on both sides and at a 45° rotation.
Several variants are found:
There were attempts to amalgamate Nazi and Hindu use of the swastika, notably by the French writer Savitri Devi who declared Hitler an Avatar of Vishnu (see Nazi mysticism).
Post-WWII stigmatization.
Origins.
Because of its use by Nazi Germany, the swastika since the 1930s has been largely associated with Nazism and white supremacy in most Western countries.
As a result, all of its use, or its use as a Nazi or hate symbol is prohibited in some countries, including Germany. Because of the stigma attached to the symbol, many buildings that have contained the symbol as decoration have had the symbol removed.
Germany.
The German and Austrian postwar criminal code makes the public showing of the "Hakenkreuz" (the swastika), the sigrune, the Celtic cross (specifically the variations used by the White-Power-Activists), the wolfsangel, the odal rune and the SS skull illegal, except for scholarly reasons (and - in the case of the odal rune - as the insignia of the rank of sergeant major, "Hauptfeldwebel", in the modern German Bundeswehr). It is also censored from the reprints of 1930s railway timetables published by the Reichsbahn. The eagle remains, but appears to be holding a solid black circle between its talons. The swastikas on Hindu, Buddhist, and Jain temples are exempt, as religious symbols cannot be banned in Germany.
A German fashion company was investigated for using traditional British-made folded leather buttons after complaints that they resembled swastikas. In response, Esprit destroyed two hundred thousand catalogues.
A controversy was stirred by the decision of several police departments to begin inquiries against anti-fascists. In late 2005 police raided the offices of the punk rock label and mail order store "Nix Gut Records" and confiscated merchandise depicting crossed-out swastikas and fists smashing swastikas. In 2006 the Stade police department started an inquiry against anti-fascist youths using a placard depicting a person dumping a swastika into a trashcan. The placard was displayed in opposition to the campaign of right-wing nationalist parties for local elections.
On Friday, March 17, 2006, a member of the Bundestag, Claudia Roth reported herself to the German police for displaying a crossed-out swastika in multiple demonstrations against Neo-Nazis, and subsequently got the Bundestag to suspend her immunity from prosecution. She intended to show the absurdity of charging anti-fascists with using fascist symbols: "We don't need prosecution of non-violent young people engaging against right-wing extremism." On March 15, 2007, the Federal Court of Justice of Germany (Bundesgerichtshof) held that the crossed-out symbols were "clearly directed against a revival of national-socialist endeavors", thereby settling the dispute for the future.
Attempt to ban in the European Union.
The European Union's Executive Commission proposed a European Union-wide anti-racism law in 2001, but European Union states failed to agree on the balance between prohibiting racism and freedom of expression. An attempt to ban the swastika across the EU in early 2005 failed after objections from the British Government and others. In early 2007, while Germany held the European Union presidency, Berlin proposed that the European Union should follow German Criminal Law and criminalize the denial of the Holocaust and the display of Nazi symbols including the swastika, which is based on the Ban on the Symbols of Unconstitutional Organisations Act. This led to an opposition campaign by Hindu groups across Europe against a ban on the swastika. They pointed out that the swastika has been around for 5,000 years as a symbol of peace. The proposal to ban the swastika was dropped by Berlin from the proposed European Union wide anti-racism laws on January 29, 2007.
Media.
In 2010, Microsoft officially spoke out against the use of the swastika in the first-person shooter "". In "Black Ops", players are allowed to customize their name tags to represent, essentially, whatever they want. The swastika can be created and used, but Stephen Toulouse, director of Xbox Live policy and enforcement, stated that players with the symbol on their name tag will be banned (if someone reports as inappropriate) from Xbox Live.
In the Indiana Jones Stunt Spectacular in Disney Hollywood Studios in Orlando, Florida, the swastikas on German trucks, aircraft and actor uniforms in the reenactment of a scene from "Raiders of the Lost Ark" were removed in 2004. The swastika has been replaced by a stylized Greek Cross. "Sin City" character Miho occasionally uses shurikens shaped like a swastika as assassination tools.
Satirical use.
A book featuring "120 Funny Swastika Cartoons" was published in 2008 by New York Cartoonist Sam Gross. The author said he created the cartoons in response to excessive news coverage given to Swastika vandals, that his intent "...is to reduce the Swastika to something humorous."
The powerful symbolism acquired by the swastika has often been used in graphic design and propaganda as a means of drawing Nazi comparisons; examples include the cover of Stuart Eizenstat's 2003 book "Imperfect Justice", publicity materials for Constantin Costa-Gavras's 2002 film "Amen.", and a billboard that was erected opposite the U.S. Interests Section in Havana, Cuba, in 2004, which juxtaposed images of the Abu Ghraib torture and prisoner abuse pictures with a swastika.
Misinterpretation over imported Asian products in Western countries.
At the end of 20th century, and early 21st century, confusion and controversy has occurred when consumer goods bearing the Buddhist symbol have been exported to North America, and mistakenly interpreted by Western consumers as a Nazi symbol.
When a ten-year-old boy in Lynbrook, New York, bought a set of Pokémon cards imported from Japan in 1999, two of the cards contained the left-facing Buddhist "Manji" symbol. The boy's parents misinterpreted the symbol as a Nazi swastika, which is right-facing with 45 degree rotation, and filed a complaint to the manufacturer. It also caused a lot of concern amongst fans from Jewish communities. Nintendo of America announced that the cards would be discontinued, explaining that what was acceptable in one culture was not necessarily so in another; their action was welcomed by the Anti-Defamation League who recognised that there was no intention to be offensive but said that international commerce meant that "isolating [the Swastika] in Asia would just create more problems."
In 2002, Christmas crackers containing plastic toy red pandas sporting swastikas were pulled from shelves after complaints from consumers in Canada. The manufacturer, based in China, explained the symbol was presented in a traditional sense and not as a reference to the Nazis, and apologized to the customers for the cross-cultural mixup. In 2007, Spanish fashion chain Zara withdrew a handbag from its stores after a customer in Britain complained swastikas were embroidered on it. The bags were made by a supplier in India and inspired by commonly used Hindu symbols, which include the swastika.
Contemporary use in Asia.
South Asia.
In South Asia, the swastika is omnipresent as a symbol of wealth and good fortune. In India and Nepal, electoral ballot papers are stamped with a round swastika-like pattern (to ensure that the accidental ink imprint on the other side of a folded ballot paper can be correctly identified as such). Many businesses and other organisations, such as the Ahmedabad Stock Exchange and the Nepal Chamber of Commerce, use the swastika in their logos. The red swastika was suggested as an emblem of International Red Cross and Red Crescent Movement in India and Sri Lanka, but the idea was not implemented. Swastikas are fairly ubiquitous in Indian and Nepalese cities, located on buses, buildings, auto-rickshaws, and clothing. The swastika continues to be prominently used in Hindu religious ceremonies and temples, and is recognised as a Hindu religious symbol, sometimes used to evoke the Shakti in tantric rituals.
In India, Swastik and Swastika, with their spelling variants, are common first names for males and females respectively, e.g. Swastika Mukherjee. Also, the Seal of Bihar contains two swastikas.
East Asia.
In the Sinosphere, countries and regions that were historically influenced by the culture of China, such as Taiwan, Japan, Hong Kong, Korea, Vietnam, Singapore and China itself, the symbol is most commonly associated with Buddhism. They are commonly found in Buddhist temples, religious artifacts, texts related to Buddhism and schools founded by Buddhist religious groups.
The Red Swastika Society, a syncretic religious group that aspires to unify Taoism, Confucianism, and Buddhism, runs two schools in Hong Kong ( and ) and one in Singapore (Red Swastika School). All of them incorporated the Swastika in their school logo to signify the society's aspiration with philanthropy and moral education.
The swastika is also used in maps to denote a temple. For example, the symbol is designated by the Survey Act and related Japanese governmental rules to denote a Buddhist temple on Japanese maps.
Hirosaki City in Aomori Prefecture designates this symbol as its official flag, which stemmed from its use in the emblem of Tsugaru clan, the lord of Hirosaki Domain in Edo era. See also the section East Asian traditions in this article.
Central Asia.
In 2005, authorities in Tajikistan called for the widespread adoption of the swastika as a national symbol. President Emomali Rahmonov declared the swastika an Aryan symbol and 2006 to be "the year of Aryan culture," which would be a time to "study and popularize Aryan contributions to the history of the world civilization, raise a new generation (of Tajiks) with the spirit of national self-determination, and develop deeper ties with other ethnicities and cultures."
New religious movements.
Besides the use as a religious symbol in Buddhism, Hinduism and Jainism, which can be traced to pre-modern traditions, the swastika is also used by a number of new religious movements established in the modern period.
Bibliography.
</dl>
External links.
Listen to this article ()
This audio file was created from a revision of the "Swastika" article dated 2005-04-20, and does not reflect subsequent edits to the article. ()
More spoken articles

</doc>
<doc id="45945" url="http://en.wikipedia.org/wiki?curid=45945" title="Lower Canada">
Lower Canada

The Province of Lower Canada (French: "province du Bas-Canada") was a British colony on the lower Saint Lawrence River and the shores of the Gulf of Saint Lawrence (1791–1841). It covered the southern portion of the modern-day Province of Quebec, Canada, and the Labrador region of the modern-day Province of Newfoundland and Labrador (until the Labrador region was transferred to Newfoundland in 1809).
Lower Canada consisted of part of the former French colony of New France, populated mainly by French Canadians, which was ceded to Great Britain after that Empire's victory in the Seven Years' War, also called the French and Indian War in the United States. Other parts of New France ceded to Britain became the Colonies of Nova Scotia, New Brunswick, and Prince Edward Island.
The Province of Lower Canada was created by the "Constitutional Act of 1791" from the partition of the British colony of the Province of Quebec (1763–91) into the Province of Lower Canada and the Province of Upper Canada. The prefix "lower" in its name refers to its geographic position farther downriver from the headwaters of the St. Lawrence River than its contemporary Upper Canada, present-day southern Ontario.
The Colony/Province was abolished in 1841, when it and the adjacent Upper Canada were united into the Province of Canada.
Rebellion.
Like Upper Canada, there was significant political unrest. 22 years after the invasion by the Americans in the War of 1812, a rebellion now challenged the British rule of the predominantly French population. After the Patriote Rebellion in the Rebellions of 1837-1838 were crushed by the British Army and Loyal volunteers, the "1791 Constitution" was suspended on 27 March 1838 and a special council was appointed to administer the Colony. An abortive attempt by revolutionary Robert Nelson to declare a Republic of Lower Canada was quickly thwarted.
The provinces of Lower Canada and Upper Canada were combined as the United Province of Canada in 1841, when The Union Act of 1840 came into force. Their separate Legislatures were combined into a single Parliament with equal representation for both constituent parts, even if Lower Canada had more population.
Constitution.
The Province of Lower Canada inherited the mixed set of French and English institutions that existed in the Province of Quebec during the 1763–91 period and which continued to exist later in Canada-East (1841–67) and ultimately in the current Province of Quebec (1867–).

</doc>
<doc id="45948" url="http://en.wikipedia.org/wiki?curid=45948" title="Saint Lawrence River">
Saint Lawrence River

The Saint Lawrence River (French: "Fleuve Saint-Laurent"; Tuscarora: "Kahnawáʼkye"; Mohawk: "Kaniatarowanenneh", meaning "big waterway") is a large river in the middle latitudes of North America. The Saint Lawrence River flows in a roughly north-easterly direction, connecting the Great Lakes with the Atlantic Ocean and forming the primary drainage conveyor of the Great Lakes Basin. It traverses the Canadian provinces of Quebec and Ontario, and is part of the international boundary between Ontario, Canada, and New York State in the United States. This river also provides the basis of the commercial Saint Lawrence Seaway.
Geography.
The St. Lawrence River begins at the outflow of Lake Ontario and flows through Gananoque, Brockville, Morristown, Ogdensburg, Massena, Cornwall, Montreal, Trois-Rivières, and Quebec City before draining into the Gulf of Saint Lawrence, one of the largest estuaries in the world. The estuary begins at the eastern tip of Île d'Orléans, just downstream from Quebec City. The river becomes tidal around Quebec City.
The St. Lawrence River runs 3058 km from the farthest headwater to the mouth and 1197 km from the outflow of Lake Ontario. The farthest headwater is the North River in the Mesabi Range at Hibbing, Minnesota. Its drainage area, which includes the Great Lakes, the world's largest system of freshwater lakes, is 1344200 km2, of which 839200 km2 is in Canada and 505000 km2 is in the United States. The basin covers parts of Ontario and Quebec in Canada, parts of Illinois, Indiana, Minnesota, New York, Ohio, Pennsylvania, Vermont, and Wisconsin, and the entirety of the state of Michigan in the United States. The average discharge below the Saguenay River is 16800 m3/s. At Quebec City, it is 12101 m3/s. The average discharge at the river's source, the outflow of Lake Ontario, is 7410 m3/s.
The St Lawrence River includes Lake Saint-Louis south of Montreal, Lake Saint Francis at Salaberry-de-Valleyfield and Lac Saint-Pierre east of Montreal. It encompasses four archipelagoes: the Thousand Islands chain near Kingston, Ontario; the Hochelaga Archipelago, including the Island of Montreal and Île Jésus (Laval); the Lake St. Pierre Archipelago (classified biosphere world reserve by the UNESCO in 2000) and the smaller Mingan Archipelago. Other islands include Île d'Orléans near Quebec City and Anticosti Island north of the Gaspé. It is the second longest river in Canada.
Lake Champlain and the Ottawa, Richelieu, Saguenay, and Saint-François rivers drain into the St. Lawrence.
The St. Lawrence River is in a seismically active zone where fault reactivation is believed to occur along late Proterozoic to early Palaeozoic normal faults related to the opening of Iapetus Ocean. The faults in the area are rift related and are called the Saint Lawrence rift system.
The St. Lawrence Valley is a physiographic province of the larger Appalachian division, containing the Champlain and Northern physiographic section.
History.
Though European mariners, such as John Cabot, the brothers Gaspar and Miguel Corte-Real, and Alonso Sanchez in the 15th century and the Norse 500 years still earlier, explored the Gulf of St. Lawrence the first European explorer known to have sailed up the St. Lawrence River itself was Jacques Cartier. At that time, the land along the river was inhabited by the St. Lawrence Iroquoians. Donnacona, an Iroquoian chief, had two sons who helped Cartier explore the area during his second trip to Canada in 1535. As Cartier arrived in the estuary on St. Lawrence's feast day, he named it the "Gulf of St. Lawrence". The St. Lawrence River is partly within the U.S. and as such is that country's sixth oldest surviving European place-name.
The earliest regular Europeans in the area were the Basques, who came to the St Lawrence Gulf and River in pursuit of whales from the early 16th century. The Basque whalers and fishermen traded with native Americans and set up settlements, leaving vestiges all over the coast of eastern Canada and deep into the Saint Lawrence River. Basque commercial and fishing activity reached its peak before the "Armada Invencible"'s disaster (1588), when the Spanish Basque whaling fleet was confiscated by King Philip II of Spain and largely destroyed. Initially, the whaling galleons from Labourd were not affected by the Spanish defeat.
Until the early 17th century, the French used the name "Rivière du Canada" to designate the Saint Lawrence upstream to Montreal and the Ottawa River after Montreal. The Saint Lawrence River served as the main route for European exploration of the North American interior, first pioneered by French explorer Samuel de Champlain.
Control of the river was crucial to British strategy to capture New France in the Seven Years' War. Having captured Louisbourg in 1758, the British sailed up to Quebec the following year thanks to charts drawn up by James Cook. British troops were ferried via the St. Lawrence to attack the city from the west, which they successfully did at the Battle of the Plains of Abraham. The river was used again by the British to defeat the French siege of Quebec under the Chevalier de Lévis in 1760. 
Because of the virtually impassable Lachine Rapids, the St. Lawrence was once continuously navigable only as far as Montreal. Opened in 1825, the Lachine Canal was the first to allow ships to pass the rapids. An extensive system of canals and locks, known as the Saint Lawrence Seaway, was officially opened on 26 June 1959 by Elizabeth II (representing Canada) and President Dwight D. Eisenhower (representing the United States). The Seaway now permits ocean-going vessels to pass all the way to Lake Superior.
During the Second World War, the Battle of the St. Lawrence involved submarine and anti-submarine actions throughout the lower St. Lawrence River and the entire Gulf of Saint Lawrence, Strait of Belle Isle and Cabot Strait from May to October 1942, September 1943, and again in October and November 1944. During this time, German U-boats sank several merchant marine ships and three Canadian warships.
In the late 1970s, the river was the subject of a successful ecological campaign (called "Save the River"), originally responding to planned development by the United States Army Corps of Engineers. The campaign was organized, among others, by Abbie Hoffman.
Sources.
The source of the North River in the Mesabi Range in Minnesota (Seven Beaver Lake) is considered to be the source of the Saint Lawrence River. Because it crosses so many lakes, the water system frequently changes its name. From source to mouth, the names are:
The Saint Lawrence River also passes through Lake Saint-Louis and Lake Saint-Pierre in Quebec.
Works.
The St. Lawrence River is at the heart of many Quebec novels (Anne Hébert's "Kamouraska", Réjean Ducharme's "L'avalée des avalés"), poems (in works of Pierre Morency, Bernard Pozier), and songs (Leonard Cohen's "Suzanne", Michel Rivard's "L'oubli", Joe Dassin's "Dans les yeux d'Émilie"), and André Gagnon's "Le Saint-Laurent"). The river was the setting for the Canadian television drama series Seaway. The river has also been portrayed in paintings, notably by the Group of Seven. In addition, the river is the namesake of Saint-Laurent Herald at the Canadian Heraldic Authority.
In 1980 Jacques Cousteau traveled to Canada to make two films on the St. Lawrence River and the Great Lakes, "Cries from the Deep" and "St. Lawrence: Stairway to the Sea".
Saint Lawrence River in art.
The Italian painter Vittorio Miele dedicated several works to the Saint Lawrence River.
Further reading.
</dl>

</doc>
<doc id="45949" url="http://en.wikipedia.org/wiki?curid=45949" title="Academy Award for Best Assistant Director">
Academy Award for Best Assistant Director

In the first year of this award it referred to no specific film.

</doc>
<doc id="45951" url="http://en.wikipedia.org/wiki?curid=45951" title="Minimal deterrence">
Minimal deterrence

In nuclear strategy, minimal deterrence (also called minimum deterrence) is an application of deterrence theory in which a state possesses no more nuclear weapons than is necessary to deter an adversary from attacking. Pure minimal deterrence is a doctrine of no first use, holding that the only mission of nuclear weapons is to deter a nuclear adversary by making the cost of a first strike unacceptably high. To present a credible deterrent, there must be the assurance that any attack would trigger a retaliatory strike. In other words, minimal deterrence requires rejecting a counterforce strategy in favor of pursuing survivable force that can be used in a countervalue second strike.
While the United States and the Soviet Union each developed robust first- and second-strike capabilities during the Cold War, the People's Republic of China pursued a doctrine of minimal nuclear deterrence. Assuming that decision-makers make cost-benefit analyses when deciding to use force, China's doctrine calls for acquiring a nuclear arsenal only large enough to destroy an adversary’s "strategic points" in such a way that the expected costs of a first strike outweigh the anticipated benefits. Both India and Pakistan have also adopted this strategy, which they term Minimum Credible Deterrence.
Minimal deterrence represents one way of solving the security dilemma and avoiding an arms race. Decision-makers often feel pressured to expand their arsenals when they perceive them to be vulnerable to an adversary’s first strike, especially when both sides seek to achieve the advantage. Eliminating this perceived vulnerability reduces the incentive to produce more and advanced weapons. For example, the United States’ nuclear force exceeds the requirements of minimal deterrence, and is structured to strike numerous targets in multiple countries and to have the ability to conduct successful counterforce strikes with high confidence. In response to this, China continues to modernize its nuclear forces because its leaders are concerned about the survivability of their arsenal in the face of the United States’ advances in strategic reconnaissance, precision strike, and missile defense.
One disadvantage of minimal deterrence is that it requires an accurate understanding of the level of damage an adversary finds unacceptable, especially if that understanding changes over time so that a previously credible deterrent is no longer credible. A minimal deterrence strategy must also account for the nuclear firepower that would be "lost" or "neutralized" during an adversary’s counterforce strike. Additionally, a minimal deterrence capability may embolden a state when it confronts a superior nuclear power, as has been observed in the relationship between China and the United States. Finally, while pursuing minimal deterrence during arms negotiations allows states to make reductions without becoming vulnerable, further reductions may be undesirable once minimal deterrence is reached because they will increase a state’s vulnerability and provide an incentive for an adversary to secretly expand its nuclear arsenal.

</doc>
<doc id="45955" url="http://en.wikipedia.org/wiki?curid=45955" title="Clanging">
Clanging

In psychology and psychiatry, clanging refers to a mode of speech characterized by association of words based upon sound rather than concepts. For example, this may include compulsive rhyming or alliteration without apparent logical connection between words. This is associated with the irregular thinking apparent in psychotic mental illnesses (e.g. schizophrenia).
Clanging refers specifically to behavior that is situationally inappropriate. While a poet rhyming is not evidence of mental illness, disorganized speech that impedes the patient's ability to communicate is a disorder in itself, often seen in schizophrenia.

</doc>
<doc id="45958" url="http://en.wikipedia.org/wiki?curid=45958" title="Mutual assured destruction">
Mutual assured destruction

Mutual assured destruction, or mutually assured destruction (MAD), is a doctrine of military strategy and national security policy in which a full-scale use of high-yield weapons of mass destruction by two or more opposing sides would cause the complete annihilation of both the attacker and the defender (see Pre-emptive nuclear strike and Second strike). It is based on the theory of deterrence where the threat of using strong weapons against the enemy prevents the enemy's use of those same weapons. The strategy is a form of Nash equilibrium in which neither side, once armed, has any incentive to initiate a conflict or to disarm.
Theory.
The MAD doctrine assumes that each side has enough nuclear weaponry to destroy the other side and that either side, if attacked for any reason by the other, would retaliate without fail with equal or greater force. The expected result is an immediate irreversible escalation of hostilities resulting in both combatants' mutual, total and assured destruction. The doctrine requires that neither side construct shelters on a massive scale, such as there are in Switzerland. Switzerland would actually survive a nuclear attack surprisingly well. If the US were to construct a similar system of shelters, it would violate the MAD doctrine and destabilize the situation, because it would not need to fear the consequences of a Soviet second strike. The same principle is invoked against missile defense.
The doctrine further assumes that neither side will dare to launch a first strike because the other side will launch on warning (also called fail-deadly) or with surviving forces (a second strike), resulting in unacceptable losses for both parties. The payoff of the MAD doctrine was and still is expected to be a tense but stable global peace.
The primary application of this doctrine started during the Cold War (1940s to 1991) in which MAD was seen as helping to prevent any direct full-scale conflicts between the United States and the Soviet Union while they engaged in smaller proxy wars around the world. It was also responsible for the arms race, as both nations struggled to keep nuclear parity, or at least retain second-strike capability. Although the Cold War ended in the early 1990s, the MAD doctrine continues to be applied.
Proponents of MAD as part of U.S. and USSR strategic doctrine believed that nuclear war could best be prevented if neither side could expect to survive a full-scale nuclear exchange as a functioning state. Since the credibility of the threat is critical to such assurance, each side had to invest substantial capital in their nuclear arsenals even if they were not intended for use. In addition, neither side could be expected or allowed to adequately defend itself against the other's nuclear missiles. This led both to the hardening and diversification of nuclear delivery systems (such as nuclear missile silos, ballistic missile submarines, and nuclear bombers kept at fail-safe points) and to the Anti-Ballistic Missile Treaty.
This MAD scenario is often referred to as nuclear deterrence. The term "deterrence" was first used in this context after World War II; prior to that time, its use was limited to legal terminology.
History.
Pre-1945.
Perhaps the earliest reference to the concept comes from the English author Wilkie Collins, writing at the time of the Franco-Prussian War in 1870: "I begin to believe in only one civilizing influence—the discovery one of these days of a destructive agent so terrible that War shall mean annihilation and men's fears will force them to keep the peace".
After his 1867 invention of dynamite, Alfred Nobel stated that "The day when two army corps can annihilate each other in one second, all civilized nations, it is to be hoped, will recoil from war and discharge their troops."
In 1937, Nikola Tesla published "The Art of Projecting Concentrated Non-dispersive Energy through the Natural Media", a treatise concerning charged particle beam weapons. Tesla described his device as a "superweapon that would put an end to all war."
Echoes of the doctrine can be found in the first document which outlined how the atomic bomb was a practical proposition. In March 1940, the Frisch-Peierls memorandum anticipated deterrence as the principal means of combating an enemy with nuclear weapons.
Early Cold War.
In August 1945, the United States accepted the surrender of Japan after the nuclear attacks on Hiroshima and Nagasaki. Four years later, on August 29, 1949, the Soviet Union detonated its own nuclear device. At the time, both sides lacked the means to effectively use nuclear devices against each other. However, with the development of aircraft like the American Convair B-36 and the Soviet Tupolev Tu-95, both sides were gaining a greater ability to deliver nuclear weapons into the interior of the opposing country. The official nuclear policy of the United States became one of "massive retaliation", as coined by President Dwight D. Eisenhower's Secretary of State John Foster Dulles, which called for massive attack against the Soviet Union if they were to invade Europe, regardless of whether it was a conventional or a nuclear attack.
By the time of the 1962 Cuban Missile Crisis, both the United States and the Soviet Union had developed the capability of launching a nuclear-tipped missile from a submerged submarine, which completed the "third leg" of the "nuclear triad" weapons strategy necessary to fully implement the MAD doctrine. Having a three-branched nuclear capability eliminated the possibility that an enemy could destroy all of a nation's nuclear forces in a first-strike attack; this, in turn, ensured the credible threat of a devastating retaliatory strike against the aggressor, increasing a nation's nuclear deterrence.
Two doomsday devices.
The strategy of Mutually Assured Destruction and the acronym MAD are due to John von Neumann (1903–1957) and his taste for humorous acronyms, another example being his MANIAC computer. He was, among other things, an inventor of game theory, a cold war strategist, and chairman of the Intercontinental ballistic missile Committee until his death in 1957. See also John von Neumann#Mutual assured destruction.
The RAND corporation futurist and cold war strategist Herman Kahn (1922–1982) believed that although MAD was useful as a metaphor, when pushed to its logical conclusion it became absurd. In his 1960 book "On Thermonuclear War" he advocated a more reasoned approach to nuclear warfare and was misunderstood by some of his critics to be a nuclear war hawk in his writings. (He did however hold a profound belief in the possibility of success in the event of a nuclear war.) He invented the concept of the Doomsday Machine as an "idealized (almost caricaturized) device" to illustrate the danger of taking MAD to its extreme. He writes, "I used to be wary of discussing the concept for fear that some colonel would get out a General Operating Requirement or Development Planning Objective for the device".
The 1964 film "Dr. Strangelove" parodies some of Kahn's work, and the titular character makes parodic references to Kahn's research, as in this quote from the film: "Under the authority granted me as director of weapons research and development, I commissioned last year a study of this project [of a doomsday machine] by the Bland Corporation. Based on the findings of the report, my conclusion was that this idea was not a practical deterrent, for reasons which, at this moment, must be all too obvious."
Sometime in the 1980s, a second, but real, doomsday device, called The Dead Hand, entered the picture in the Soviet Union. Unlike Kahn's device, it was not based on radioactive cobalt, but it was self-activated and could not be stopped.
Strategic Air Command.
Beginning in 1955, the United States Strategic Air Command (SAC) kept one-third of its bombers on alert, with crews ready to take off within fifteen minutes and fly to designated targets inside the Soviet Union and destroy them with nuclear bombs in the event of a Soviet first-strike attack on the United States. In 1961, President John F. Kennedy increased funding for this program and raised the commitment to 50 percent of SAC aircraft.
During periods of increased tension in the early 1960s, SAC kept part of its B-52 fleet airborne at all times, to allow an extremely fast retaliatory strike against the Soviet Union in the event of a surprise attack on the United States. This program continued until 1990 when the bomber wings were placed on quick reaction ground alert and were able to take off within a few minutes. SAC also maintained the National Emergency Airborne Command Post (NEACP, pronounced "kneecap"), also known as "Looking Glass," which consisted of several EC-135s, one of which was airborne at all times from 1961 through 1990. During the Cuban missile crisis the bombers were dispersed to several different airfields, and also were sometimes airborne. For example, some were sent to Wright Patterson, which normally didn't have B-52s.
During the height of the tensions between the US and the USSR in the 1960s, two popular films were made dealing with what could go terribly wrong with the policy of keeping nuclear-bomb carrying airplanes at the ready: "Dr. Strangelove" (1964) and "Fail Safe" (1964).
Retaliation capability (second strike).
The strategy of MAD was fully declared in the early 1960s, primarily by United States Secretary of Defense Robert McNamara. In McNamara's formulation there was the very real danger that a nation with nuclear weapons could attempt to eliminate another nation's retaliatory forces with a surprise, devastating first strike and theoretically "win" a nuclear war relatively unharmed. True second-strike capability could only be achieved when a nation had a "guaranteed" ability to fully retaliate after a first-strike attack.
The United States had achieved an early form of second-strike capability by fielding continual patrols of strategic nuclear bombers, with a large number of planes always in the air, on their way to or from fail-safe points close to the borders of the Soviet Union. This meant the United States could still retaliate, even after a devastating first-strike attack. The tactic was expensive and problematic because of the high cost of keeping enough planes in the air at all times and the possibility they would be shot down by Soviet anti-aircraft missiles before reaching their targets. In addition, as the idea of a missile gap existing between the US and the Soviet Union developed, there was increasing priority being given to ICBMs over bombers.
It was only with the advent of ballistic missile submarines, starting with the "George Washington" class in 1959, that a genuine survivable nuclear force became possible and a retaliatory second strike capability guaranteed.
The deployment of fleets of ballistic missile submarines established a guaranteed second-strike capability because of their stealth and by the number fielded by each Cold War adversary—it was highly unlikely that all of them could be targeted and preemptively destroyed (in contrast to, for example, a missile silo with a fixed location that could be targeted during a first strike). Given their long range, high survivability and ability to carry many medium- and long-range nuclear missiles, submarines were credible and effective means for full-scale retaliation even after a massive first strike.
This deterrence strategy and program has continued into the 21st century, with nuclear submarines carrying Trident II ballistic missiles as one leg of the U.S. strategic nuclear deterrent and as the sole deterrent of the United Kingdom. The USA's other such deterrent comprises the intercontinental ballistic missiles (ICBM)s on alert in the continental United States. Ballistic missile submarines are also operated by the navies of China, France, India and Russia.
The U.S. Department of Defense anticipates a continued need for a sea-based strategic nuclear force. The first of the current Ohio-class SSBNs are expected to be retired by 2029, meaning that a platform must already be seaworthy by that time. A replacement may cost over $4 billion per unit compared to the USS "Ohio"‍ '​s $2 billion. The U.S. Navy is exploring two options. The first is a variant of the "Virginia"-class nuclear attack submarines. The second is a dedicated SSBN, either with a new hull or based on an overhaul of the current "Ohio".
ABMs threaten MAD.
In the 1960s both the Soviet Union (A-35 anti-ballistic missile system) and the United States (LIM-49 Nike Zeus) developed anti-ballistic missile systems. Had such systems been able to effectively defend against a retaliatory second strike, MAD would have been undermined, because a superpower could launch a first strike without fearing the consequences of a retaliatory second strike. See also Strategic Defense Initiative.
MIRVs.
MIRVs as counter against ABM.
The multiple independently targetable re-entry vehicle (MIRV) was another weapons system designed specifically to aid with the MAD nuclear deterrence doctrine. With a MIRV payload, one ICBM could hold many separate warheads. MIRVs were first created by the United States in order to counterbalance Soviet anti-ballistic missile systems around Moscow. Since each defensive missile could only be counted on to destroy one offensive missile, making each offensive missile have, for example, three warheads (as with early MIRV systems) meant that three times as many defensive missiles were needed for each offensive missile. This made defending against missile attacks more costly and difficult. One of the largest U.S. MIRVed missiles, the LGM-118A Peacekeeper, could hold up to 10 warheads, each with a yield of around 300 ktonTNT—all together, an explosive payload equivalent to 230 Hiroshima-type bombs. The multiple warheads made defense untenable with the technology available, leaving only the threat of retaliatory attack as a viable defensive option. MIRVed land-based ICBMs tend to put a premium on striking first. Therefore, the START II agreement banned this type of weapon.
In the event of a Soviet conventional attack on Western Europe, NATO planned to use tactical nuclear weapons. The Soviet Union countered this threat by issuing a statement that any use of nuclear weapons (tactical or otherwise) against Soviet forces would be grounds for a full-scale Soviet retaliatory strike (massive retaliation). Thus it was generally assumed that any combat in Europe would end with apocalyptic conclusions.
Land-based MIRVed ICBMs threaten MAD.
MIRVed land-based ICBMs are generally considered suitable for a first strike (inherently counterforce) or a counterforce second strike, due to:
Unlike a decapitation strike or a countervalue strike, a counterforce strike might result in a potentially more constrained retaliation. Though the Minuteman III of the mid-1960s was MIRVed with three warheads, heavily MIRVed vehicles threatened to upset the balance; these included the SS-18 Satan which was deployed in 1976, and was considered to threaten Minuteman III silos, which led some neoconservatives to conclude a Soviet first strike was being prepared for. This led to the development of the aforementioned Pershing II, the Trident I and Trident II, as well as the MX missile, and the B-1 Lancer.
MIRVed land-based ICBMs are considered destabilizing because they tend to put a premium on striking first. When a missile is MIRVed, it is able to carry many warheads (up to eight in existing U.S. missiles, limited by New START, though Trident II is capable of carrying up to 12) and deliver them to separate targets. If it is assumed that each side has 100 missiles, with five warheads each, and further that each side has a 95 percent chance of neutralizing the opponent's missiles in their silos by firing two warheads at each silo, then the attacking side can reduce the enemy ICBM force from 100 missiles to about five by firing 40 missiles with 200 warheads, and keeping the rest of 60 missiles in reserve. As such, this type of weapon was intended to be banned under the START II agreement; however, the START II agreement was never brought into force, and neither Russia nor the United States ratified the agreement.
Late Cold War.
The original U.S. MAD doctrine was modified on July 25, 1980, with U.S. President Jimmy Carter's adoption of "countervailing strategy" with Presidential Directive 59. According to its architect, Secretary of Defense Harold Brown, "countervailing strategy" stressed that the planned response to a Soviet attack was no longer to bomb Soviet population centers and cities primarily, but first to kill the Soviet leadership, then attack military targets, in the hope of a Soviet surrender before total destruction of the Soviet Union (and the United States). This modified version of MAD was seen as a winnable nuclear war, while still maintaining the possibility of assured destruction for at least one party. This policy was further developed by the Reagan administration with the announcement of the Strategic Defense Initiative (SDI, nicknamed "Star Wars"), the goal of which was to develop space-based technology to destroy Soviet missiles before they reached the United States.
SDI was criticized by both the Soviets and many of America's allies (including Prime Minister of the United Kingdom Margaret Thatcher) because, were it ever operational and effective, it would have undermined the "assured destruction" required for MAD. If the United States had a guarantee against Soviet nuclear attacks, its critics argued, it would have first-strike capability, which would have been a politically and militarily destabilizing position. Critics further argued that it could trigger a new arms race, this time to develop countermeasures for SDI. Despite its promise of nuclear safety, SDI was described by many of its critics (including Soviet nuclear physicist and later peace activist Andrei Sakharov) as being even more dangerous than MAD because of these political implications. Supporters also argued that SDI could trigger a new arms race, forcing the USSR to spend an increasing proportion of GDP on defense—something which has been claimed to have been an indirect cause of the eventual collapse of the Soviet Union.
Proponents of ballistic missile defense (BMD) argue that MAD is exceptionally dangerous in that it essentially offers a single course of action in the event of nuclear attack: full retaliatory response. The fact that nuclear proliferation has led to an increase in the number of nations in the "nuclear club", including nations of questionable stability (e.g. Pakistan and North Korea), and that a nuclear nation might be hijacked by a despot or other person or persons who might use nuclear weapons without sane regard for the consequences, presents a strong case for proponents of BMD who seek a policy which both protects against attack, but also does not require an escalation into what might become global nuclear war. Russia continues to have a strong public distaste for Western BMD initiatives, presumably because proprietary operative BMD systems could exceed their technical and financial resources and therefore degrade their larger military standing and sense of security in a post-MAD environment. Russian refusal to accept invitations to participate in NATO BMD may be indicative of the lack of an alternative to MAD in current Russian war fighting strategy due to dilapidation of conventional forces after the breakup of the Soviet Union.
Post-Cold War.
After the fall of the Soviet Union, the Russian Federation emerged as a sovereign entity encompassing most of the territory of the former USSR. Relations between the United States and this new power have been less tense than they had been with its predecessor. Tensions also decreased between the United States and China.
The administration of U.S. President George W. Bush withdrew from the Anti-Ballistic Missile Treaty in June 2002, claiming that the limited national missile defense system which they proposed to build was designed only to prevent nuclear blackmail by a state with limited nuclear capability and was not planned to alter the nuclear posture between Russia and the United States.
While relations have improved and an intentional nuclear exchange is more unlikely, the decay in Russian nuclear capability in the post-Cold War era may have had an effect on the continued viability of the MAD doctrine. An article by Keir Lieber and Daryl Press stated that the United States could carry out a nuclear first strike on Russia and would "have a good chance of destroying every Russian bomber base, submarine, and ICBM." This was attributed to reductions in Russian nuclear stockpiles and the increasing inefficiency and age of that which remains. Lieber and Press argued that the MAD era is coming to an end and that the United States is on the cusp of global nuclear primacy.
However, in a follow-up article in the same publication, others criticized the analysis, including Peter Flory, the U.S. Assistant Secretary of Defense for International Security Policy, who began by writing "The essay by Keir Lieber and Daryl Press contains so many errors, on a topic of such gravity, that a Department of Defense response is required to correct the record." Regarding reductions in Russian stockpiles, another response stated that "a similarly one-sided examination of [reductions in] U.S. forces would have painted a similarly dire portrait".
A situation in which the United States might actually be expected to carry out a "successful" attack is perceived as a disadvantage for both countries. The strategic balance between the United States and Russia is becoming less stable, and the objective, technical possibility of a first strike by the United States is increasing. At a time of crisis, this instability could lead to an accidental nuclear war. For example, if Russia feared a U.S. nuclear attack, Moscow might make rash moves (such as putting its forces on alert) that would provoke a U.S. preemptive strike.
An outline of current U.S. nuclear strategy toward both Russia and other nations was published as the document "Essentials of Post–Cold War Deterrence" in 1995.
Official policy.
Whether MAD was the officially accepted doctrine of the United States military during the Cold War is largely a matter of interpretation. The United States Air Force, for example, has retrospectively contended that it never advocated MAD as a sole strategy, and that this form of deterrence was seen as one of numerous options in U.S. nuclear policy. Former officers have emphasized that they never felt as limited by the logic of MAD (and were prepared to use nuclear weapons in smaller-scale situations than "assured destruction" allowed), and did not deliberately target civilian cities (though they acknowledge that the result of a "purely military" attack would certainly devastate the cities as well). MAD was implied in several U.S. policies and used in the political rhetoric of leaders in both the United States and the USSR during many periods of the Cold War.
 To continue to deter in an era of strategic nuclear equivalence, it is necessary to have nuclear (as well as conventional) forces such that in considering aggression against our interests any adversary would recognize that no plausible outcome would represent a victory or any plausible definition of victory. To this end and so as to preserve the possibility of bargaining effectively to terminate the war on acceptable terms that are as favorable as practical, if deterrence fails initially, we must be capable of fighting successfully so that the adversary would not achieve his war aims and would suffer costs that are unacceptable, or in any event greater than his gains, from having initiated an attack.
 — President Jimmy Carter in 1980, ""
The doctrine of MAD was officially at odds with that of the USSR, which had, contrary to MAD, insisted survival was possible. The Soviets believed they could win not only a strategic nuclear war, which they planned to absorb with their extensive civil defense planning, but also the conventional war that they predicted would follow after their strategic nuclear arsenal had been depleted. Official Soviet policy, though, may have had internal critics towards the end of the Cold War, including some in the USSR's own leadership.
 "Nuclear use would be catastrophic."
 — 1981, the Soviet General Staff
Criticism.
The doctrine of nuclear deterrence depends on several challengeable assumptions:

</doc>
<doc id="45959" url="http://en.wikipedia.org/wiki?curid=45959" title="Nuclear strategy">
Nuclear strategy

Nuclear strategy involves the development of doctrines and strategies for the production and use of nuclear weapons.
As a sub-branch of military strategy, nuclear strategy attempts to match nuclear weapons as means to political ends. In addition to the actual use of nuclear weapons whether in the battlefield or strategically, a large part of nuclear strategy involves their use as a bargaining tool.
Some of the issues considered within nuclear strategy include:
Many strategists argue that nuclear strategy differs from other forms of military strategy because the immense and terrifying power of the weapons makes their use in seeking victory in a traditional military sense impossible.
Perhaps counterintuitively, an important focus of nuclear strategy has been determining how to prevent and deter their use, a crucial part of mutual assured destruction.
In the context of nuclear proliferation and maintaining the balance of power, states also seek to prevent other states from acquiring nuclear weapons as part of nuclear strategy.
Nuclear deterrent composition.
The doctrine of mutual assured destruction (MAD) assumes that a nuclear deterrent force must be credible and survivable. That is, each deterrent force must survive a first strike with sufficient capability to effectively destroy the other country in a second strike. Therefore, a first strike would be suicidal for the launching country.
In the late 1940s and 1950s as the Cold War developed, the United States and Soviet Union pursued multiple delivery methods and platforms to deliver nuclear weapons. Three types of platforms proved most successful and are collectively called a "nuclear triad". These are air-delivered weapons (bombs or missiles), ballistic missile submarines (usually nuclear-powered and called SSBNs), and intercontinental ballistic missiles (ICBMs), usually deployed in land-based hardened missile silos or on vehicles. 
Although not considered part of the deterrent forces, all of the nuclear powers deployed large numbers of tactical nuclear weapons in the Cold War. These could be delivered by virtually all platforms capable of delivering large conventional weapons.

</doc>
<doc id="45960" url="http://en.wikipedia.org/wiki?curid=45960" title="Cloaking device">
Cloaking device

A cloaking device is a theoretical or fictional stealth technology that can cause objects, such as spaceships or individuals, to be partially or wholly invisible to parts of the electromagnetic (EM) spectrum. However, over the entire spectrum, a cloaked object scatters more than an uncloaked object.
Fictional cloaking devices have been used as plot devices in various media for many years.
Developments in scientific research show that real-world cloaking devices can obscure objects from at least one wavelength of EM emissions. Scientists already use artificial materials called metamaterials to bend light around an object.
Conceptual origins.
Inspired in part by the 1958 film "Run Silent, Run Deep", "" screenwriter Paul Schneider imagined cloaking as a space-travel analog of a submarine submerging, and employed it in the 1966 "Star Trek" episode "Balance of Terror". Another "Star Trek" screenwriter, D.C. Fontana, coined the term "cloaking device" for the 1968 episode "The Enterprise Incident".
Writers and game designers have since incorporated cloaking devices into many other science-fiction narratives, including "Doctor Who", "Star Wars", and "Stargate".
Scientific experimentation.
An operational, non-fictional cloaking device might be an extension of the basic technologies used by stealth aircraft, such as radar-absorbing dark paint, optical camouflage, cooling the outer surface to minimize electromagnetic emissions (usually infrared), or other techniques to minimize other EM emissions, and to minimize particle emissions from the object. The use of certain devices to jam and confuse remote sensing devices would greatly aid in this process, but are more properly referred to as "active camouflage". Alternatively, metamaterials provide the theoretical possibility of making electromagnetic radiation pass freely around the 'cloaked' object.
Metamaterial research.
Optical metamaterials have featured in several recent proposals for invisibility schemes. "Metamaterials" refers to materials that owe their refractive properties to the way they are structured, rather than the substances that compose them. Using transformation optics it is possible to design the optical parameters of a "cloak" so that it guides light around some region, rendering it invisible over a certain band of wavelengths. These spatially varying optical parameters do not correspond to any natural material, but may be implemented using metamaterials. There are several theories of cloaking, giving rise to different types of invisibility.
In 2014, scientists demonstrated good cloaking performance in murky water, demonstrating that an object shrouded in fog can disappear completely when appropriately coated with metamaterial. This is due to the random scattering of light, such as that which occurs in clouds, fog, milk, frosted glass, etc., combined with the properties of the metamaterial coating. When light is diffused, a thin coat of metamaterial around an object can make it essentially invisible under a range of lighting conditions.
Active camouflage.
"Active camouflage" (or "adaptive camouflage") is a group of camouflage technologies which would allow an object (usually military in nature) to blend into its surroundings by use of panels or coatings capable of changing color or luminosity. Active camouflage can be seen as having the potential to become the perfection of the art of camouflaging things from visual detection.
"Optical camouflage" is a kind of active camouflage in which one wears a fabric which has an image of the scene directly behind the wearer projected onto it, so that the wearer appears invisible. The drawback to this system is that, when the cloaked wearer moves, a visible distortion is often generated as the 'fabric' catches up with the object's motion. The concept exists for now only in theory and in proof-of-concept prototypes, although many experts consider it technically feasible.
It has been reported that the British Army has tested an invisible tank. Mercedes demonstrated an invisible car using LED and camera in 2012.
Plasma stealth.
Plasma at certain density ranges absorbs certain bandwidths of broadband waves, potentially rendering an object invisible. However, generating plasma in air is too expensive and a feasible alternative is generating plasma between thin membranes instead. The Defense Technical Information Center is also following up research on plasma reducing RCS technologies. A plasma cloaking device was patented in 1991.
Metascreen.
A prototype Metascreen is a claimed cloaking device, which is just few micrometers thick and to a limited extent can hide 3D objects from microwaves in their natural environment, in their natural positions, in all directions, and from all of the observer's positions. It was prepared at the University of Texas, Austin by Professor Andrea Alù.
The metascreen consisted of a 66 micrometre thick polycarbonate film supporting an arrangement of 20 micrometer thick copper strips that resembled a fishing net. In the experiment, when the metascreen was hit by 3.6 GHz microwaves, it re-radiated microwaves of the same frequency that were out of phase, thus cancelling out reflections from the object being hidden. The device only cancelled out the scattering of microwaves in the first order. The same researchers published a paper on "plasmonic cloaking" the previous year.
Howell/Choi cloaking device.
University of Rochester physics professor John Howell and graduate student Joseph Choi have announced a scalable cloaking device which uses common optical lenses to achieve visible light cloaking on the macroscopic scale, known as the "Rochester Cloak". The device consists of a series of four lenses which direct light rays around objects which would otherwise occlude the optical pathway.
Cloaking in Mechanics.
The concepts of cloaking are not limited to optics but can also be transferred to other fields of Physics. For example it was possible to cloak acoustics for certain frequency's as well as touching in mechanics. This renders an object "invisible" to sound or even hides it from touching.
References.
</dl>

</doc>
<doc id="45963" url="http://en.wikipedia.org/wiki?curid=45963" title="Analytic language">
Analytic language

An analytic language is a language that conveys grammatical relationships without using inflectional morphemes. A grammatical construction can similarly be called analytic if it uses unbound morphemes, which are separate words, and/or word order. Analytic languages are in contrast to synthetic languages.
A related concept is the isolating language, which is about a low number of morphemes per word, taking into account derivational morphemes as well. A purely isolating language would be analytic by necessity, lacking inflectional morphemes by definition. However, the reverse is not necessarily true: a language can have derivational morphemes while lacking inflectional morphemes. For example, Mandarin has many compound words, giving it a moderately high ratio of morphemes per word, yet since it has almost no inflectional affixes at all to convey grammatical relationships it is a very analytic language.
The term "analytic" is commonly used in a relative rather than an absolute sense. English has lost much of the inflectional morphology of Proto-Indo-European, Proto-Germanic and Old English over the centuries and has not gained any new inflectional morphemes in the meantime, making it more analytic than most Indo-European languages. For example, while Proto-Indo-European had inflections for eight cases in its nouns, English has lost most of them, conserving only the genitive (possessive) -'s.
For comparison, nouns in Russian inflect for at least six cases, most of them descended from Proto-Indo-European cases, whose functions English translates using other strategies like prepositions, verbal voice and word order instead.
However, English is also not totally analytic in its nouns as it does use inflections for number, e.g. "one day, three days; one boy, four boys". Mandarin has, in contrast, no inflections in its nouns at all: compare 一天 yī tiān 'one day', 三天 sān tiān 'three days' (literally "three day"); 一个男孩 yī ge nánhái 'one boy' (lit. "one [entity of] male child"), 四个男孩 sì ge nánhái 'four boys' (lit. "four [entity of] male child").

</doc>
<doc id="45964" url="http://en.wikipedia.org/wiki?curid=45964" title="Chuck Berry">
Chuck Berry

Charles Edward Anderson "Chuck" Berry (born October 18, 1926) is an American guitarist, singer and songwriter, and one of the pioneers of rock and roll music. With songs such as "Maybellene" (1955), "Roll Over Beethoven" (1956), "Rock and Roll Music" (1957) and "Johnny B. Goode" (1958), Berry refined and developed rhythm and blues into the major elements that made rock and roll distinctive, with lyrics focusing on teen life and consumerism and utilizing guitar solos and showmanship that would be a major influence on subsequent rock music.
Born into a middle-class family in St. Louis, Missouri, Berry had an interest in music from an early age and gave his first public performance at Sumner High School. While still a high school student he was arrested, and served a prison sentence for armed robbery from 1944 to 1947. After his release, Berry settled into married life and worked at an automobile assembly plant. By early 1953, influenced by the guitar riffs and showmanship techniques of blues player T-Bone Walker, Berry began performing with the Johnnie Johnson Trio. His break came when he traveled to Chicago in May 1955, and met Muddy Waters, who suggested he contact Leonard Chess of Chess Records. With Chess he recorded "Maybellene"—Berry's adaptation of the country song "Ida Red"—which sold over a million copies, reaching number one on Billboard's Rhythm and Blues chart. By the end of the 1950s, Berry was an established star with several hit records and film appearances to his name as well as a lucrative touring career. He had also established his own St. Louis-based nightclub, called Berry's Club Bandstand. But in January 1962, Berry was sentenced to three years in prison for offenses under the Mann Act—he had transported a 14-year-old girl across state lines.
After his release in 1963, Berry had more hits in the mid 60's, including "No Particular Place to Go," "You Never Can Tell," and "Nadine." By the mid-1970s, he was more in demand as a nostalgic live performer, playing his past hits with local backup bands of variable quality. In 1979 he served 120 days in prison for tax evasion.
Berry was among the first musicians to be inducted into the Rock and Roll Hall of Fame on its opening in 1986, with the comment that he "laid the groundwork for not only a rock and roll sound but a rock and roll stance." Berry is included in several "Rolling Stone" "Greatest of All Time" lists, including being ranked fifth on their 2004 list of the 100 Greatest Artists of All Time. The Rock and Roll Hall of Fame's 500 Songs that Shaped Rock and Roll included three of Berry's songs: "Johnny B. Goode," "Maybellene," and "Rock and Roll Music."
Early life (1926–54).
Born in St. Louis, Missouri, Berry was the fourth child in a family of six. He grew up in the north St. Louis neighborhood known as The Ville, an area where many middle class St. Louis people lived at the time. His father, Henry, was a contractor and deacon of a nearby Baptist church, his mother Martha a certified public school principal. His middle class upbringing allowed him to pursue his interest in music from an early age and he gave his first public performance in 1941 while still at Sumner High School. Just three years later, in 1944, while still at Sumner High School, he was arrested and convicted of armed robbery after robbing three shops in Kansas City and then stealing a car at gunpoint with some friends. Berry's own account in his autobiography is that his car broke down and he then flagged down a passing car and stole it at gunpoint with a non-functional pistol. Berry was sent to the Intermediate Reformatory for Young Men at Algoa, near Jefferson City, Missouri, where he formed a singing quartet and did some boxing. The singing group became competent enough that the authorities allowed it to perform outside the detention facility.
After his release from prison on his 21st birthday in 1947, Berry married Themetta "Toddy" Suggs on October 28, 1948, who gave birth to Darlin Ingrid Berry on October 3, 1950. Berry supported his family doing a number of jobs in St. Louis: working briefly as a factory worker at two automobile assembly plants, as well as being janitor for the apartment building where he and his wife lived. Afterwards he trained as a beautician at the Poro College of Cosmetology, founded by Annie Turnbo Malone. He was doing well enough by 1950 to buy a "small three room brick cottage with a bath" in Whittier Street, which is now listed as the Chuck Berry House on the National Register of Historic Places.
By the early 1950s, Berry was working with local bands in the clubs of St. Louis as an extra source of income. He had been playing the blues since his teens, and he borrowed both guitar riffs and showmanship techniques from blues player T-Bone Walker, as well as taking guitar lessons from his friend Ira Harris that laid the foundation for his guitar style.
Apprenticeship with Johnnie Johnson.
By early 1953 Berry was performing with Johnnie Johnson's trio, starting a long-time collaboration with the pianist. Although the band played mostly blues and ballads, the most popular music among whites in the area was country. Berry wrote, "Curiosity provoked me to lay a lot of our country stuff on our predominantly black audience and some of our black audience began whispering 'who is that black hillbilly at the Cosmo?' After they laughed at me a few times they began requesting the hillbilly stuff and enjoyed dancing to it."
Berry's calculated showmanship, along with mixing country tunes with R&B tunes, and singing in the style of Nat King Cole to the music of Muddy Waters, brought in a wider audience, particularly affluent white people.
Signing with Chess: "Maybellene" to "Come On" (1955–62).
In May 1955, Berry traveled to Chicago where he met Muddy Waters, who suggested he contact Leonard Chess of Chess Records. Berry thought his blues material would be of most interest to Chess, but to his surprise it was an old country and western recording by Bob Wills, entitled "Ida Red" that got Chess's attention. Chess had seen the rhythm and blues market shrink and was looking to move beyond it, and he thought Berry might be the artist for that purpose. So on May 21, 1955 Berry recorded an adaptation of "Ida Red"—"Maybellene"—which featured Johnnie Johnson on piano, Jerome Green (from Bo Diddley's band) on the maracas, Jasper Thomas on the drums and Willie Dixon on the bass. "Maybellene" sold over a million copies, reaching number one on Billboard's Rhythm and Blues chart and number five on the September 10, 1955 Billboard Best Sellers in Stores chart.
At the end of June 1956, his song "Roll Over Beethoven" reached number 29 on the "Billboard Top 100" chart, and Berry toured as one of the "Top Acts of '56." He and Carl Perkins became friends. Perkins said that "I knew when I first heard Chuck that he'd been affected by country music. I respected his writing; his records were very, very great." As they toured, Perkins discovered that Berry not only liked country music, but knew about as many songs as he did. Jimmie Rodgers was one of his favorites. "Chuck knew every Blue Yodel and most of Bill Monroe's songs as well," Perkins remembered. "He told me about how he was raised very poor, very tough. He had a hard life. He was a good guy. I really liked him."
In late 1957, Berry took part in Alan Freed's "Biggest Show of Stars for 1957" United States tour with the Everly Brothers, Buddy Holly, and others. He also guest starred on ABC's "The Guy Mitchell Show", having sung his hit song "Rock 'n' Roll Music." The hits continued from 1957 to 1959, with Berry scoring over a dozen chart singles during this period, including the top 10 US hits "School Days," "Rock and Roll Music," "Sweet Little Sixteen," and "Johnny B. Goode". He appeared in two early rock and roll movies. The first was "Rock Rock Rock," (1956) in which he sings "You Can't Catch Me." He had a speaking role as himself in "Go, Johnny, Go!" (1959) along with Alan Freed, and performs his songs "Johnny B. Goode," "Memphis, Tennessee," and "Little Queenie." His performance of "Sweet Little Sixteen" at the Newport Jazz Festival in 1958 is captured in the motion picture "Jazz on a Summer's Day".
By the end of the 1950s, Berry was a high-profile established star with several hit records and film appearances to his name, as well as a lucrative touring career. He had opened a racially integrated St. Louis-based nightclub, called Berry's Club Bandstand, and was investing in real estate. But in December 1959, Berry was arrested under the Mann Act after questionable allegations that he had sexual intercourse with a 14-year-old Apache waitress, Janice Escalante, whom he had transported over state lines to work as a hat check girl at his club. After an initial two-week trial in March 1960, Berry was convicted, fined $5,000, and sentenced to five years in prison. Berry's appeal that the judge's comments and attitude were racist and prejudiced the jury against him was upheld, and a second trial was heard in May and June 1961, which resulted in Berry being given a three-year prison sentence. After another appeal failed, Berry served one and one half years in prison from February 1962 to October 1963. Berry had continued recording and performing during the trials, though his output had slowed down as his popularity declined; his final single released before being imprisoned was "Come On".
"Nadine" and move to Mercury (1963–69).
When Berry was released from prison in 1963, he was able to return to recording and performing due to the British invasion acts of the 1960s—most notably the Beatles and the Rolling Stones—having kept up an interest in his music by releasing cover versions of his songs; along with other bands reworking his songs, such as the Beach Boys 1963 hit "Surfin' U.S.A." based on Berry's "Sweet Little Sixteen". In 1964–65 Berry released eight singles, including three, "No Particular Place to Go" (a humorous reworking of "School Days" concerning the introduction of car seat belts), "You Never Can Tell", and the rocking "Nadine," which achieved commercial success, reaching the top 20 of the Billboard 100. Between 1966 and 1969 Berry released five albums on the Mercury label, including his first live album "Live at Fillmore Auditorium" in which he was backed by the Steve Miller Band.
While this was not a successful period for studio work, Berry was still a top concert draw. In May 1964, he did a successful tour of the UK, but when he returned in January 1965 his behavior was erratic and moody, and his touring style of using unrehearsed local backing bands and a strict non-negotiable contract was earning him a reputation as a difficult yet unexciting performer. He also played at large events in North America, such as the Schaefer Music Festival in New York City's Central Park in July 1969, and the Toronto Rock and Roll Revival festival in October.
Back to Chess: "My Ding-a-Ling" to White House concert (1970–79).
Berry helped give life to a subculture ... Even "My Ding-a-Ling", a fourth-grade wee-wee joke that used to mortify true believers at college concerts, permitted a lot of twelve-year-olds new insight into the moribund concept of "dirty" when it hit the airwaves ...
Robert Christgau
Berry returned to Chess from 1970 to 1973. There were no hit singles from the 1970 album "Back Home", then in 1972 Chess released a live recording of "My Ding-a-Ling," a novelty song which Berry had recorded in a different version on his 1968 LP "From St. Louie to Frisco" as "My Tambourine". The track became Berry's only number one single. A live recording of "Reelin' And Rockin'" was also issued as a follow-up single that same year and would prove to be Berry's final top-40 hit in both the US and the UK. Both singles were featured on the part-live/part-studio album "The London Chuck Berry Sessions" which was one of a series of London Sessions albums which included other Chess mainstay artists Muddy Waters and Howlin' Wolf. Berry's second tenure with Chess ended with the 1975 album "Chuck Berry", after which he did not make a studio record until 1979's "Rock It" for Atco Records, his last studio album to date.
In the 1970s Berry toured on the basis of his earlier successes. He was on the road for many years, carrying only his Gibson guitar, confident that he could hire a band that already knew his music no matter where he went. AllMusic has said that in this period his "live performances became increasingly erratic, ... working with terrible backup bands and turning in sloppy, out-of-tune performances" which "tarnished his reputation with younger fans and oldtimers" alike. Among the many bandleaders performing a backup role with Berry were Bruce Springsteen and Steve Miller when each was just starting his career. Springsteen related in the video "Hail! Hail! Rock 'n' Roll" that Berry did not even give the band a set list and just expected the musicians to follow his lead after each guitar intro. Berry neither spoke to nor thanked the band after the show. Nevertheless, Springsteen backed Berry again when he appeared at the concert for the Rock and Roll Hall of Fame in 1995. At the request of Jimmy Carter, Berry performed at the White House on June 1, 1979.
Berry's type of touring style, traveling the "oldies" circuit in the 1970s (where he was often paid in cash by local promoters) added ammunition to the Internal Revenue Service's accusations that Berry was a chronic income tax evader. Facing criminal sanction for the third time, Berry pleaded guilty to tax evasion and was sentenced to four months in prison and 1,000 hours of community service—doing benefit concerts—in 1979.
Still on the road (1980–present).
Berry continued to play 70 to 100 one-nighters per year in the 1980s, still traveling solo and requiring a local band to back him at each stop. In 1986, Taylor Hackford made a documentary film, "Hail! Hail! Rock 'n' Roll", of a celebration concert for Berry's sixtieth birthday, organized by Keith Richards. Eric Clapton, Etta James, Julian Lennon, Robert Cray and Linda Ronstadt, among others, appeared with Berry on stage and film. During the concert, Berry played a Gibson ES-355, the luxury version of the ES-335 that he favored on his 1970s tours. Richards played a black Fender Telecaster Custom, Cray a Fender Stratocaster and Clapton a Gibson ES 350T, the same guitar Berry used on his early recordings.
In the late 1980s, Berry bought a restaurant in Wentzville, Missouri, called The Southern Air, and in 1990 he was sued by several women who claimed that he had installed a video camera in the ladies' bathroom. Berry claimed that he had the camera installed to catch red-handed a worker who was suspected of stealing from the restaurant. Though his guilt was never proven in court, Berry opted for a class action settlement with 59 women. Berry's biographer, Bruce Pegg, estimated that it cost Berry over $1.2 million plus legal fees. It was during this time that he began using Wayne T. Schoeneberg as his legal counsel. Reportedly, a police raid on his house did find videotapes of women using the restroom, and one of the women was a minor. Also found in the raid were 62 grams of marijuana. Felony drug and child-abuse charges were filed. In order to avoid the child-abuse charges, Berry agreed to plead guilty to misdemeanor possession of marijuana. He was given a six-month suspended jail sentence, two years' unsupervised probation, and ordered to donate $5,000 to a local hospital.
In November 2000, Berry again faced legal charges when he was sued by his former pianist Johnnie Johnson, who claimed that he co-wrote over 50 songs, including "No Particular Place to Go", "Sweet Little Sixteen" and "Roll Over Beethoven", that credit Berry alone. The case was dismissed when the judge ruled that too much time had passed since the songs were written.
In 2008, Berry toured Europe, with stops in Sweden, Norway, Finland, the United Kingdom, the Netherlands, Ireland, Switzerland, Poland and Spain. In mid-2008, he played at Virgin Festival in Baltimore, Maryland. He presently lives in Ladue, Missouri, approximately 10 miles west of St. Louis. During a New Year's Day 2011 concert in Chicago, Berry, suffering from exhaustion, passed out and had to be helped off stage. Berry usually performs one Wednesday each month at Blueberry Hill, a restaurant and bar located in the Delmar Loop neighborhood in St. Louis.
Legacy.
While no individual can be said to have invented rock and roll, Chuck Berry comes the closest of any single figure to being the one who put all the essential pieces together. It was his particular genius to graft country & western guitar licks onto a rhythm & blues chassis in his very first single, "Maybellene."
Rock and Roll Hall of Fame
A pioneer of rock music, Berry was a significant influence on the development of both the music and the attitude associated with the rock music lifestyle. With songs such as "Maybellene" (1955), "Roll Over Beethoven" (1956), "Rock and Roll Music" (1957) and "Johnny B. Goode" (1958), Berry refined and developed rhythm and blues into the major elements that made rock and roll distinctive, with lyrics successfully aimed to appeal to the early teenage market by using graphic and humorous descriptions of teen dances, fast cars, high-school life, and consumer culture, and utilizing guitar solos and showmanship that would be a major influence on subsequent rock music. His records are a rich storehouse of the essential lyrical, showmanship and musical components of rock and roll; and, in addition to the Beatles and the Rolling Stones, a large number of significant popular-music performers have recorded Berry's songs. Though not technically accomplished, his guitar style is distinctive—he incorporated electronic effects to mimic the sound of bottleneck blues guitarists, and drew on the influence of guitar players such as Charlie Christian and T-Bone Walker to produce a clear and exciting sound that many later guitar musicians would acknowledge as a major influence in their own style. Berry's showmanship has been influential on other rock guitar players, particularly his one-legged hop routine, and the "duck walk", which he first used as a child when he walked "stooping with full-bended knees, but with my back and head vertical" under a table to retrieve a ball and his family found it entertaining; he used it when "performing in New York for the first time and some journalist branded it the duck walk."
The rock critic Robert Christgau considers him "the greatest of the rock and rollers," while John Lennon said, "if you tried to give rock and roll another name, you might call it 'Chuck Berry'." Ted Nugent said "If you don't know every Chuck Berry lick, you can't play rock guitar."
Among the honors Berry has received, have been the Grammy Lifetime Achievement Award in 1984, the Kennedy Center Honors in 2000, and being named seventh on "Time" magazine's 2009 list of the 10 best electric guitar players of all-time. On May 14, 2002, Berry was honored as one of the first BMI Icons at the 50th annual BMI Pop Awards. He was presented the award along with BMI affiliates Bo Diddley and Little Richard. In August 2014, Berry was made a laureate of the Polar Music Prize.
Berry is included in several "Rolling Stone" "Greatest of All Time" lists. In September 2003, the magazine named him number 6 in their list of the "100 Greatest Guitarists of All Time". This was followed in November of the same year by his compilation album "The Great Twenty-Eight" being ranked 21st in the Rolling Stone's 500 Greatest Albums of All Time. The following year, in March 2004, Berry was ranked fifth out of "The Immortals – The 100 Greatest Artists of All Time". In December 2004, six of his songs were included in the "Rolling Stone's 500 Greatest Songs of All Time", namely "Johnny B. Goode" (#7), "Maybellene" (#18), "Roll Over Beethoven" (#97), "Rock and Roll Music" (#128), "Sweet Little Sixteen" (#272) and "Brown Eyed Handsome Man" (#374). In June 2008, his song "Johnny B. Goode" ranked first place in the "100 Greatest Guitar Songs of All Time".

</doc>
<doc id="45966" url="http://en.wikipedia.org/wiki?curid=45966" title="No first use">
No first use

No first use (NFU) refers to a pledge or a policy by a nuclear power not to use nuclear weapons as a means of warfare unless first attacked by an adversary using nuclear weapons. Earlier, the concept had also been applied to chemical and biological warfare.
China declared its NFU policy in 1964, and has since maintained this policy. India articulated its policy of no first use of nuclear weapons in 2003.
NATO has repeatedly rejected calls for adopting NFU policy, arguing that preemptive nuclear strike is a key option, in order to have a credible deterrent that could compensate for the overwhelming conventional weapon superiority enjoyed by the Soviet Army in the Eurasian land mass. In 1993, Russia dropped a pledge given by the former Soviet Union not to use nuclear weapons first. In 2000, a Russian military doctrine stated that Russia reserves the right to use nuclear weapons "in response to a large-scale conventional aggression". This is because the balance of forces was reversed, NATO now is enjoying a clear superiority in conventional weapons.
Countries pledging no-first-use.
China.
China became the first nation to propose and pledge NFU policy when it first gained nuclear capabilities in 1964, stating "not to be the first to use nuclear weapons at any time or under any circumstances". During the Cold War, China decided to keep the size of its nuclear arsenal small rather than compete in an international arms race with the United States and the Soviet Union.<ref name=S/1995/265></ref> China has repeatedly re-affirmed its no-first-use policy in recent years, doing so in 2005, 2008, 2009 and again in 2011. China has also consistently called on the United States to adopt a no-first-use policy, to reach a NFU agreement bilaterally with China, and to conclude an NFU agreement among the five nuclear weapon states. The United States has repeatedly refused these calls.
India.
India adopted a "no first use policy" after its nuclear tests in 1998. A speech by India's then NSA Shivshankar Menon at National Defence College in New Delhi on October 21, 2010 changed the wording from "no first use" to "no first use against non-nuclear weapon states", although some argued that this was not a substantive change but "an innocent typographical or lexical error in the text of the speech." India’s current PM Modi has in the run up to the recent general elections reiterated commitment to no first use policy. In April 2013 Shyam Saran, convener of the National Security Advisory Board, affirmed that regardless of the size of a nuclear attack against India, be it a Tactical nuclear weapon or a Strategic nuclear weapon, India will retaliate massively. This was in response to reports that Pakistan had developed a tactical battlefield nuclear weapon, in an attempt to nullify an Indian "no first use" retaliatory doctrine.
Countries pledging to use nuclear weapons only defensively.
Pakistan, Russia, the United Kingdom, the United States, and France say they will use nuclear weapons against either nuclear or non-nuclear states only in the case of invasion or other attack against their territory or against one of their allies. Historically, NATO military strategy, taking into account the numerical superiority of Warsaw Pact conventional forces, assumed that the use of tactical nuclear weapons would have been required in defeating a Soviet invasion.
At a NATO summit in April 1999, Germany proposed that NATO adopt a no-first-use policy, but the proposal was rejected.
United Kingdom.
In March 2002, British defence secretary Geoff Hoon stated that the UK was prepared to use nuclear weapons against "rogue states" such as Iraq if they ever used "weapons of mass destruction" against British troops in the field. This policy was restated in February 2003.
United States.
The United States has refused to adopt a no-first-use policy, saying that it "reserves the right to use" nuclear weapons first in the case of conflict. The U.S. doctrine for the use of nuclear weapons was revised most recently in the Nuclear Posture Review, released April 6, 2010. The 2010 Nuclear Posture review reduces the role of U.S. nuclear weapons, stating that
"The fundamental role of U.S. nuclear weapons, which will continue as long as nuclear weapons exist, is to deter nuclear attack on the United States, our allies, and partners."
The U.S. doctrine also includes the following assurance to other states:
"The United States will not use or threaten to use nuclear weapons against non-nuclear weapons states that are party to the NPT and in compliance with their nuclear non-proliferation obligations."
For states eligible for this assurance, the United States would not use nuclear weapons in response to a chemical or biological attack, but states that those responsible for such an attack would be held accountable and would face the prospect of a devastating conventional military response. Even for states not eligible for this assurance, the United States would consider the use of nuclear weapons only in extreme circumstances to defend the vital interests of the United States or its allies and partners. The Nuclear Posture Review also notes:
"It is in the U.S. interest and that of all other nations that the nearly 65-year record of nuclear non-use be extended forever."
This supersedes the doctrine of the Bush Administration set forth in "Doctrine for Joint Nuclear Operations" and written under the direction of Air Force General Richard B. Myers, chairman of the Joint Chiefs of Staff. The new doctrine envisions commanders requesting presidential approval to use nuclear weapons to preempt an attack by a nation or a terrorist group using weapons of mass destruction. The draft also includes the option of using nuclear weapons to destroy known enemy stockpiles of nuclear, biological, or chemical weapons.
Pakistan.
Pakistan refuses to adopt a "no-first-use" doctrine, indicating that it would strike India with nuclear weapons even if India did not use such weapons first. Pakistan's asymmetric nuclear posture has significant influence on India's decision ability to retaliate, as shown in 2001 and 2008 crises, when non-state actors carried out deadly terrorist attacks on India, only to be met with a relatively subdued response from India. A military spokesperson stated that "Pakistan's threat of nuclear first-use deterred India from seriously considering conventional military strikes."
Pakistan's National Security Advisor Sartaj Aziz defended the policy of first use. Aziz stated that Pakistan's first use doctrine is entirely deterrent in nature. He explained that it was effective after the 2001 Indian Parliament attack and argued that if Pakistan had a no-first use policy, there would have been a major war between the two countries.
Israel.
Although Israel does not officially confirm or deny having nuclear weapons, the country is widely believed to be in possession of them. Its continued ambiguous stance puts it in a difficult position since to issue a statement pledging 'no first use' would confirm their possession of nuclear weapons.
Israel has said that it "would not be the first country in the Middle East to formally introduce nuclear weapons into the region."
If Israel's very existence is threatened, some speculate that Israel would use a "Samson Option," a "last resort" deterrence strategy of massive retaliation with nuclear weapons, should the state of Israel be substantially damaged and/or near destruction.

</doc>
<doc id="45967" url="http://en.wikipedia.org/wiki?curid=45967" title="Richard Burton">
Richard Burton

Richard Burton, CBE (; 10 November 1925 – 5 August 1984) was a Welsh stage and cinema actor noted for his mellifluous baritone voice and his great acting talent.
Establishing himself as a formidable Shakespearean actor in the 1950s, with a memorable performance of Hamlet in 1964, Burton was called "the natural successor to Olivier" by critic and dramaturg Kenneth Tynan. An alcoholic, Burton's failure to live up to those expectations disappointed critics and colleagues and fueled his legend as a great thespian wastrel.
Burton was nominated seven times for an Academy Award without ever winning. He was a recipient of BAFTA, Golden Globe and Tony Awards for Best Actor. In the mid-1960s Burton ascended into the ranks of the top box office stars, and by the late 1960s was one of the highest-paid actors in the world, receiving fees of $1 million or more plus a share of the gross receipts.
Burton remains closely associated in the public consciousness with his second wife, actress Elizabeth Taylor. The couple's turbulent relationship was rarely out of the news.
Childhood and education.
Richard Burton was born Richard Walter Jenkins in the village of Pontrhydyfen, Neath Port Talbot, Wales. He grew up in a working class, Welsh-speaking household, the 12th of 13 children. His father, also named Richard Walter Jenkins, was a short, robust coal miner, a "twelve-pints-a-day man" who sometimes went off on drinking and gambling sprees for weeks. Burton later claimed, by family telling, that "He looked very much like me ... That is, he was pockmarked, devious, and smiled a great deal when he was in trouble. He was, also, a man of extraordinary eloquence, tremendous passion, great violence.":23
Burton was less than two years old in 1927 when his mother, Edith Maude (née Thomas), died on 31 October 1927 at age 44 after giving birth to her 13th child. His sister Cecilia and her husband Elfed took him into their Presbyterian mining family in nearby Port Talbot (an English-speaking steel town). Burton said later that his sister became "more mother to me than any mother could have ever been ... I was immensely proud of her ... she felt all tragedies except her own". Burton's father would occasionally visit the homes of his grown daughters but was otherwise absent.:7, 10 Also important in young Burton's life was Ifor (Ivor), his brother, 19 years his senior. A miner and rugby player, Ifor "ruled the household with the proverbial firm hand".:7
Burton showed a talent for English and Welsh literature at grammar school, demonstrating an excellent memory, though his consuming interest was sports – rugby (in fact famous Welsh centre Bleddyn Williams said in his autobiography that Burton could have gone far as a player), cricket, and table tennis He later said, "I would rather have played for Wales at Cardiff Arms Park than Hamlet at the Old Vic.":17 He earned pocket money by running messages, hauling horse manure, and delivering newspapers. He started to smoke at the age of 8 and drink regularly at 12.:25–26
Inspired by his schoolmaster, Philip H. Burton, he excelled in school productions, his first being "The Apple Cart".:29 Philip Burton could not legally adopt young Richard due to their age difference; Burton was one year short of the minimum twenty years required.:47 Richard Jenkins (as the young man was still known) displayed early-on an excellent speaking and singing voice, winning an Eisteddfod prize as a boy soprano. He left school at age 16 for full-time work. He worked for the local wartime Co-operative committee, handing out supplies in exchange for coupons, but then considered other professions for his future, including boxing, religion and singing.:27
When he joined the Port Talbot Squadron of the Air Training Corps as a cadet, he re-encountered Burton, his former teacher, who was the commander. He joined a youth drama group led by Leo Lloyd, a steel worker and avid amateur thespian, who taught him the fundamentals of acting. Burton, who recognised the youth's talent, then adopted him as his ward and Richard returned to school. Being older than most of the other boys, he was very attractive to some of the girls.:30–31 Philip Burton later said, "Richard was my son to all intents and purposes. I was committed to him.":34 Philip Burton tutored his charge intensely in school subjects, and also worked at developing the youth's acting voice, including outdoor voice drills which improved his projection.:38
In 1943, at age 18, Richard Burton (who had taken his teacher's surname but would not change it by deed poll for several years:41), was allowed into Exeter College, Oxford, for a special term of six months study, made possible because he was an air force cadet obligated to later military service. He subsequently served in the RAF (1944–1947) as a navigator. Burton's eyesight was too poor for him to be considered pilot-material.
Early acting career.
In the 1940s and early 1950s Burton worked on stage and in cinema in the United Kingdom. Before his war service with the Royal Air Force, he starred as Professor Higgins in a YMCA production of "Pygmalion". He earned his first professional acting fees with radio parts for the BBC.:35 He had made his professional acting debut in Liverpool and London, appearing in "Druid's Rest", a play by Emlyn Williams (who also became a guru), but his career was interrupted by conscription in 1944.:44 Early on as an actor, he developed the habit of carrying around a book-bag filled with novels, dictionaries, a complete Shakespeare, and books of quotations, history, and biography, and he enjoyed solving crossword puzzles. Burton could, given any line from Shakespeare's works, recite from memory the next several minutes of lines. His love of language was paramount, as he famously stated years later, with a tearful Elizabeth Taylor at his side, "The only thing in life is language. Not love. Not anything else.":43
In 1947, after his discharge from the RAF, Burton went to London to seek his fortune. He immediately signed up with a theatrical agency to make himself available for casting calls.:45 His first film was "The Last Days of Dolwyn", set in a Welsh village about to be drowned to provide a reservoir. His reviews praised him for his "acting fire, manly bearing, and good looks.":48
Burton met his future wife, the young actress Sybil Williams, on the set, and they married in February 1949. They had two daughters, but divorced in 1963 after Burton's widely reported affair with Elizabeth Taylor. In the years of his marriage to Sybil, Burton appeared in the West End in a highly successful production of "The Lady's Not for Burning", alongside Sir John Gielgud and Claire Bloom, in both the London and New York productions. He had small parts in various British films: "Now Barabbas Was A Robber"; "Waterfront" (1950) with Robert Newton; "The Woman with No Name" (1951); and a bigger part as a smuggler in "Green Grow the Rushes", a B-movie.:70–71
Reviewers took notice of Burton: "He has all the qualifications of a leading man that the British film industry so badly needs at this juncture: youth, good looks, a photogenic face, obviously alert intelligence, and a trick of getting the maximum of attention with a minimum of fuss.":51 In the 1951 season at Stratford, he gave a critically acclaimed performance and achieved stardom as Prince Hal in Shakespeare's "Henry IV, Part 1" opposite Anthony Quayle's Falstaff. Philip Burton arrived at Stratford to help coach his former charge, noting in his memoir that Quayle and Richard Burton had their differences about the interpretation of the Prince Hal role. Richard Burton was already demonstrating the same independence and competitiveness as an actor that he displayed off-stage in drinking, sport, or story-telling.:73
Kenneth Tynan said of Burton's performance, "His playing of Prince Hal turned interested speculation to awe almost as soon as he started to speak; in the first intermission local critics stood agape in the lobbies.":51 Suddenly, Richard Burton had fulfilled his guardian's wildest hopes and was admitted to the post-War British acting circle which included Anthony Quayle, John Gielgud, Michael Redgrave, Hugh Griffith and Paul Scofield. He even met Humphrey Bogart, a fellow hard drinker, who sang his praises back in Hollywood.:56 Lauren Bacall recalled, "Bogie loved him. We all did. You had no alternative." Burton bought the first of many cars and celebrated by increasing his drinking.:73–74 The following year, Burton signed a five-year contract with Alexander Korda at £100 a week, launching his Hollywood career.
Hollywood and later career.
In 1952, Burton successfully made the transition to a Hollywood star; on the recommendation of Daphne du Maurier, he was given the leading role in "My Cousin Rachel" opposite Olivia de Havilland.:59 Burton arrived on the Hollywood scene at a time when the studios were struggling. Television's rise was drawing viewers away and the studios looked to new stars and new film technology to staunch the bleeding. 20th Century Fox negotiated with Korda to borrow him for this film and a further two at $50,000 a film. The film was a critical success. It established Burton as a Hollywood leading man and earned him his first Academy Award nomination and the Golden Globe Award for New Star of the Year – Actor. In "Desert Rats" (1953), Burton plays a young English captain in the North African campaign during World War II who takes charge of a hopelessly out-numbered Australian unit against the indomitable Field Marshal Erwin Rommel (James Mason). Mason, another actor known for his distinctive voice and excellent elocution, became a friend of Burton's and introduced the new actor to the Hollywood crowd. In short order, he met Judy Garland, Greta Garbo, Stewart Granger, Jean Simmons, Deborah Kerr, and Cole Porter, and Burton met up again with Humphrey Bogart.:82 At a party, he met a pregnant Elizabeth Taylor (then married to Michael Wilding) whose first impression of Burton was that "he was rather full of himself. I seem to remember that he never stopped talking, and I had given him the cold fish eye.":60
The following year he created a sensation by starring in "The Robe," the first film to premiere in the wide-screen process CinemaScope, earning another Oscar nomination. He replaced Tyrone Power, who was originally cast in the role of Marcellus, a noble but decadent Roman in command of the detachment of Roman soldiers that crucified Jesus Christ. Haunted by his guilt from this act, he is eventually led to his own conversion. Marcellus' Greek slave (played by Victor Mature) guides him as a spiritual teacher, and his wife (played by Jean Simmons) follows his lead, although it will mean both their deaths. The film marked a resurgence in Biblical blockbusters.:85 Burton was offered a seven-year, $1 million contract by Darryl F. Zanuck at Fox, but he turned it down, though later the contract was revived and he agreed to it.:87 It has been suggested that remarks Burton made about blacklisting Hollywood while filming "The Robe" may have explained his failure to ever win an Oscar, despite receiving seven nominations.
In 1954, Burton took his most famous radio role, as the narrator in the original production of Dylan Thomas's "Under Milk Wood", a role he would reprise in the film version twenty years later. He was also the narrator, as Winston Churchill, in the highly successful 1960 television documentary series "The Valiant Years.":90
Stage career.
Burton was still juggling theatre with film, playing Hamlet and Coriolanus at the Old Vic theatre in 1953 and alternating the roles of Iago and Othello with the Old Vic's other rising matinee idol John Neville. Hamlet was a challenge that both terrified and attracted him, as it was a role many of his peers in the British theatre had undertaken, including John Gielgud and Laurence Olivier.:93 Bogart, on the other hand, warned him as Burton left Hollywood, "I never knew a man who played Hamlet who didn't die broke.":67 Once again, Philip Burton provided expert coaching. Claire Bloom played Ophelia, and their work together led to a turbulent affair.:94 His reviews in "Hamlet" were good but he received stronger praise for Coriolanus. His fellow actor Robert Hardy said, "His Coriolanus is quite easily the best I've ever seen" but Hamlet was "too strong".:93
Burton appeared on Broadway, receiving a Tony Award nomination for "Time Remembered" (1958) and winning the award for playing King Arthur in the musical "Camelot" (1960), directed by Moss Hart and written by Alan Jay Lerner and Frederick Loewe.:67 Julie Andrews, fresh from her triumph in "My Fair Lady," played Guenevere to Burton's King Arthur, with Robert Goulet as Lancelot completing the love triangle. The production was troubled, with both Loewe and Hart falling ill, numerous revisions upsetting the schedule and the actors, and the pressure- building due to great expectations and huge advance sales. The show's running time was nearly five hours. Burton took it all in his stride and calmed people down with statements like "Don't worry, love." Burton's intense preparation and competitive desire served him well. He was generous and supportive to others who were suffering in the maelstrom. According to Lerner, "he kept the boat from rocking, and "Camelot" might never have reached New York if it hadn't been for him.":93 As in the play, both male stars were enamoured of their leading lady, newly married Andrews. When Goulet turned to Burton for advice, Burton had none to offer, but later he admitted, "I tried everything on her myself. I couldn't get anywhere either.":94 Burton's reviews were excellent, "Time" magazine stated that Burton "gives Arthur the skilful and vastly appealing performance that might be expected from one of England's finest young actors." The show's album was a major seller. The Kennedys, newly in the White House, also enjoyed the play and invited Burton for a visit, establishing the link of the idealistic young Kennedy administration with Camelot.
He then put his stage career on hold to concentrate on film, although he received a third Tony Award nomination when he reprised his Hamlet under John Gielgud's direction in 1964 in a production that holds the record for the longest run of the play in Broadway history (136 performances).:148 The performance was immortalised both on record and in a film, which played in US theatres for a week in 1964, as well as being the subject of books written by cast members William Redfield and Richard L. Sterne. Burton took the role on just after his marriage to Taylor. Since Burton disliked wearing period clothing, Gielgud conceived a production in a "rehearsal" setting with a half-finished set and actors wearing their street clothes (carefully selected while the production really was in rehearsal). Burton's basic reading of Hamlet, which displeased some theatre-goers, was of a complex manic-depressive personality, though during the long run he varied his performance considerably, as a self-challenge and to keep his acting fresh. On the whole, Burton had good reviews. "Time" said that Burton "put his passion into Hamlet's language rather than the character. His acting is a technician's marvel. His voice has gem-cutting precision.":144 The opening night party was a lavish affair, attended by six hundred celebrities who paid homage to the couple. The most successful aspect of the production was generally considered to be Hume Cronyn's performance as Polonius, winning Cronyn the only Tony Award he would ever receive in a competitive category.
After his Hamlet, Burton did not return to the stage for twelve years. He did, however, accept the role of Humbert Humbert in Alan Jay Lerner's musical adaptation of "Lolita" entitled "Lolita, My Love" but withdrew and was replaced by his friend and fellow Welshman John Neville. His performance as psychiatrist Martin Dysart in Equus won him a special Tony Award in 1976 for his appearance, but he had to make "" – a film he hated – before Hollywood producers would allow him to repeat his role in the 1977 film version. His final starring stage performance was in a critically reviled 1983 production of Noël Coward's "Private Lives", opposite his ex-wife Elizabeth Taylor. Most reviewers dismissed the production as a transparent attempt to capitalise on the couple's celebrity, although they grudgingly praised Burton as having the closest connection to Coward's play of anyone in the cast.
Hollywood career in the 1950s and 1960s.
In terms of critical success, Burton's Hollywood roles throughout the 1950s did not live up to the early promise of his debut. Burton returned to Hollywood to star in "Prince of Players", another historical Cinemascope film, this time concerning Edwin Booth, the famous American actor and brother of Abraham Lincoln's assassin, John Wilkes Booth. A weak script undermined a valiant effort by Burton, although the view of director Philip Dunne was that "The fire and intensity were there, but that was all. He hadn't yet mastered the tricks of the great movie stars, such as Gary Cooper.":71 Next came "Alexander the Great" (1956), written, directed, and produced by Robert Rossen, with Burton in the title role, on loan to United Artists, again with Claire Bloom co-starring. Contrary to Burton's expectations, the "intelligent epic" was a wooden, slow-paced flop.:75
In "The Rains of Ranchipur", Burton plays a noble Hindu doctor who attempts the spiritual recovery of an adulteress (Lana Turner). Critics felt that the film lacked star chemistry, with Burton having difficulty with the accent, and relied too heavily on Cinemascope special effects including an earthquake and a collapsing dam. Burton returned to the theatre in "Henry V" and "Othello", alternating the roles of Iago and Othello. He and Sybil then moved to Switzerland to avoid high British taxes and to try to build a nest-egg, for themselves and for Burton's family.:75 He returned to film again in "Sea Wife", shot in Jamaica and directed by Roberto Rossellini. A young Joan Collins (then called by the tabloids "Britain's bad girl") plays a nun shipwrecked on an island with three men. But Rossellini was let go after disagreements with Zanuck. According to Collins, Burton had a "take-the-money-and-run attitude" toward the film.:75–77
Then in 1958, he was offered the part of Jimmy Porter, "an angry young man" role, in the film version of John Osborne's play "Look Back in Anger", a gritty drama about middle-class life in the British Midlands, directed by Tony Richardson, again with Claire Bloom as co-star. Though it didn't do well commercially (many critics felt Burton, at 33, looked too old for the part) and Burton's Hollywood box-office aura seemed to be diminishing, Burton was proud of the effort and wrote to his mentor Philip Burton, "I promise you that there isn't a shred of self-pity in my performance. I am for the first time ever looking forward to seeing a film in which I play".:125 Next came "The Bramble Bush" and "Ice Palace" in 1960, neither important to Burton's career.
After playing King Arthur in "Camelot" on Broadway for six months, Burton replaced Stephen Boyd as Mark Antony in the troubled production "Cleopatra" (1963). Twentieth Century-Fox's future appeared to hinge on what became the most expensive movie ever made until then, reaching almost $40 million.:97 The film proved to be the start of Burton's most successful period in Hollywood; he would remain among the top 10 box-office earners for the next four years. During the filming, Burton met and fell in love with Elizabeth Taylor, who was married to Eddie Fisher. The two would not be free to marry until 1964 when their respective divorces were complete. On their first meeting on the set, Burton said "Has anyone ever told you that you're a very pretty girl?" Taylor later recalled, "I said to myself, "Oy gevalt", here's the great lover, the great wit, the great intellectual of Wales, and he comes out with a line like that.":103 In their first scenes together, he was shaky and missing his lines, and she soothed and coached him. Soon the affair began in earnest and Sybil, seeing this as more than a passing fling with a leading lady, was unable to bear it. She fled the set, first for Switzerland, then for London.
The gigantic scale of the troubled production, Taylor's bouts of illness and fluctuating weight, the off-screen turbulence—all generated enormous publicity, which by-and-large the studio embraced. Zanuck stated, "I think the Taylor-Burton association is quite constructive for our organization.":118But not necessarily for Burton. "Make up your mind, dear heart", cabled Laurence Olivier to him at this time. "Do you want to be a great actor or a household word?" Burton replied "Both". The six-hour film was cut to under four, eliminating many of Burton's scenes, but the result was viewed the same—a film long on spectacle dominated by the two hottest stars in Hollywood. Their private lives turned out to be an endless source of curiosity for the media, and their marriage was also the start of a series of on-screen collaborations. Eventually, the film did well enough to recoup its great cost.
Burton played Taylor's tycoon husband in "The V.I.P.s", an all-star film set in the VIP lounge of London Airport which proved to be a box-office hit. Then Burton portrayed the archbishop martyred by Henry II in the title role of "Becket", turning in an effective, restrained performance, contrasting with Peter O'Toole's manic portrayal of Henry.:130
In 1964, Burton triumphed as defrocked Episcopal priest Dr. T. Lawrence Shannon in Tennessee Williams' "The Night of the Iguana" directed by John Huston, a film which became another critical and box-office success. Richard Burton's performance in "The Night of the Iguana" may be his finest hour on the screen, and in the process helped put the town of Puerto Vallarta on the map (the Burtons later bought a house there). Part of Burton's success was due to how well he varied his acting with the three female characters, each of whom he tries to seduce differently: Ava Gardner (the randy hotel owner), Sue Lyon (the nubile American tourist), and Deborah Kerr (the poor, repressed artist).:135
Against his family's advice, Burton married Elizabeth Taylor on Sunday 15 March 1964, in Montreal. Ever optimistic, Taylor proclaimed, "I'm so happy you can't believe it. This marriage will last forever".:140 At the hotel in Boston, the rabid crowd clawed at the newlyweds, Burton's coat was ripped and Taylor's ear was bloodied when someone tried to steal one of her earrings.:142
After an interruption playing "Hamlet" on Broadway, Burton returned to film as British spy Alec Leamas in "The Spy Who Came in from the Cold". Burton and Taylor continued making films together though the next one "The Sandpiper" (1965) was poorly received. Following that, he and Taylor had great success in Mike Nichols's film (1966) of the Edward Albee play "Who's Afraid of Virginia Woolf?", in which a bitter erudite couple spend the evening trading vicious barbs in front of their horrified and fascinated guests, played by George Segal and Sandy Dennis. Burton was not the first choice for the role of Taylor's husband. Jack Lemmon was offered the role first, but when he backed off, Jack Warner, with Taylor's insistence, agreed on Burton and paid him his price. Albee preferred Bette Davis and James Mason, fearing that the Burtons' strong screen presence would dominate the film.:155, 163 Nichols, in his directorial debut, managed the Burtons brilliantly. The script, adapted from Albee's play by Hollywood veteran Ernest Lehman, broke new ground for its raw language and harsh depiction of marriage. Although all four actors received Oscar nominations for their roles in the film (the film received a total of thirteen), only Taylor and Dennis went on to win. So immersed had the Burtons become in the roles of George and Martha over the months of shooting that, after the wrap, Richard Burton said, "I feel rather lost.":142 Later the couple would state that the film took its toll on their relationship, and that Taylor was "tired of playing Martha" in real life.:206
Their lively version of Shakespeare's "The Taming of the Shrew" (1967), directed by Franco Zeffirelli, was a notable success. Later collaborations, however, "The Comedians" (1967), "Boom!" (1968), and the Burton-directed "Doctor Faustus" (1967) (which had its genesis from a theatre production he staged and starred in at the Oxford University Dramatic Society) were critical and commercial failures. Another box office failure was the 1969 movie "Staircase", in which he and his "Cleopatra" co-star Rex Harrison appeared as a bickering homosexual couple. His fee for "Staircase", $1.25 million (equivalent to approximately $ in today's funds) plus a share of the gross, made him the highest-paid actor in the world.
He did enjoy a final commercial blockbuster with Clint Eastwood in the 1968 World War II picture "Where Eagles Dare", a major hit in 1969, for which he received a $1 million fee plus a share of the gross. His last film of the decade, "Anne of the Thousand Days" (1969), was a commercial and critical disappointment. In spite of those failures, it performed remarkably well at that year's Academy awards (receiving ten nominations, including one for Burton's performance as Henry VIII), which many thought to be largely the result of an expensive advertising campaign by Universal Studios.
Later career.
Because of Burton and Taylor's extravagant spending and his support of his family and others (42 people at one point), Burton agreed to work in mediocre films, which hurt his career. He recognised his financial need to do so, and that in the New Hollywood era of cinema, neither he nor Taylor would be paid as well as at the height of their stardom. Films he made during this period included "Bluebeard" (1972), "Hammersmith Is Out" (1972), "The Klansman" (1974), and "" (1977). He did enjoy one major critical success in the 1970s in the film version of his stage hit "Equus", winning the Golden Globe Award as well as an Academy Award nomination. Public sentiment towards his perennial frustration at not winning an Oscar made many pundits consider him the favourite to finally win the award, but on Oscar Night he lost to Richard Dreyfuss in "The Goodbye Girl".
In 1976 Burton received a Grammy in the category of Best Recording for Children for his narration of "The Little Prince" by Antoine de Saint-Exupéry. He also found success in 1978, when he narrated "Jeff Wayne's Musical Version of The War of the Worlds". His distinctive performance became a necessary part of the concept album – so much so that a hologram of Burton was used to narrate the live stage show (touring in 2006, 2007, 2009 and 2010) of the musical. In 2011, however, Liam Neeson was cast in the part for a "next generation" rerecording, and subsequently also replaced Burton as the hologram character in the stage show.
Burton had an international box-office hit with "The Wild Geese" (1978), an adventure tale about mercenaries in Africa. The film was a success in the UK and Europe but had only limited distribution in the U.S. owing to the collapse of the studio that funded it and the lack of an American star in the movie. He returned to films with "The Medusa Touch" (1978), "Circle of Two" (1980), and the title role in "Wagner" (1983), a role he said he was born to play, after his success in "Equus". His last film performance, as O'Brien in "Nineteen Eighty-Four", was critically acclaimed, though he was not the first choice for the part. According to the film's director, Michael Radford, Paul Scofield was originally contracted to play the part, but had to withdraw due to a broken leg, then Sean Connery, Marlon Brando and Rod Steiger were all approached before Burton was cast. He had "heard stories" about Burtons heavy drinking, which had concerned the producers.
At the time of his death, Burton was preparing to film "Wild Geese II", the sequel to "The Wild Geese", which was eventually released in 1985. Burton was to reprise the role of Colonel Faulkner, while his friend Sir Laurence Olivier was cast as Rudolf Hess. After his death, Burton was replaced by Edward Fox, and the character changed to Faulkner's younger brother.
Oscars.
He was nominated six times for an Academy Award for Best Actor and once for an Academy Award for Best Supporting Actor – but he never won. His first nomination, for "My Cousin Rachel" (1952), was for Best Supporting Actor. His subsequent nominations all came in the Best Actor category.
He was nominated as Best Actor for "The Robe" in 1954, but did not receive another nomination until 1965, for "Becket", at which time he was one of the most famous actors in the world, due to his relationship with Elizabeth Taylor. Considered a favorite in the 1966 and '67 contests for "The Spy Who Came in from the Cold" (1965) and "Who's Afraid of Virginia Woolf?" (1966), he lost to Lee Marvin and Paul Scofield, respectively. His performance in "Anne of the Thousand Days" (1969) was bested by John Wayne in "True Grit" and his comeback performance in "Equus" (1977) was topped by Richard Dreyfuss in "The Goodbye Girl".
In contrast to the Oscars, where he was an also-ran, Burton was a recipient of BAFTA, Golden Globe and Tony Awards for Best Actor.
From 1982, he and "Becket" co-star Peter O'Toole shared the record for the male actor with the most nominations (7) for a competitive acting Oscar without ever winning. In 2007, O'Toole was nominated for an eighth time (and subsequently lost), for "Venus" (however, O'Toole received an Academy Honorary Award in 2003).
Television.
Burton rarely appeared on television, although he gave a memorable performance as Caliban in a televised production of "The Tempest" for The Hallmark Hall of Fame in 1960. Later appearances included the television film "Divorce His – Divorce Hers" (1973) opposite then-wife Elizabeth Taylor (a prophetic title, since their first marriage would be dissolved less than a year later), a remake of the classic film "Brief Encounter" (1974) that was considered vastly inferior to the 1945 original, and a critically applauded performance as Winston Churchill in "The Gathering Storm" (1974). "Wagner", a film he made about the life of Richard Wagner (noted for having the only onscreen teaming of Laurence Olivier, John Gielgud and Ralph Richardson in the same scenes) was shown as a television miniseries in 1983 after failing to achieve a theatrical release in most countries due to its nine-hour running time. Burton enjoyed a personal triumph in the American television miniseries "Ellis Island" in 1984, receiving a posthumous Emmy Award nomination for his final television performance.
Television played an important part in the fate of his Broadway appearance in "Camelot." When the show's run was threatened by disappointing reviews, Burton and co-star Julie Andrews appeared on "The Ed Sullivan Show" to perform the number "What Do The Simple Folk Do?". The television appearance renewed public interest in the production and extended its Broadway run.
Burton showed a subtle flair for comedy in a 1970 guest appearance with Elizabeth Taylor on the sitcom "Here's Lucy", where he recited, in a plumber's uniform, a haunting excerpt of a speech from Shakespeare's "Richard II". He later parodied this role in an episode of the television show "The Fall Guy".
In 1997, archive footage of Burton was used in the first episode of the television series "Conan."
Books and articles.
In 1964 Burton wrote a brief memoir of his childhood, "A Christmas Story". Set in a small mining town in Wales, this "smart and deeply felt" story is told from the perspective of a young, motherless boy on the night before Christmas. It was published in 1968, and is written in the tradition of "A Child's Christmas in Wales" by Dylan Thomas—an author Burton refers to in his first sentence, which begins, "There were not many white Christmases in our part of Wales in my childhood..."
Burton kept a written record of his experiences and thoughts in the form of a daily journal or a private diary. This began when he was 14 years old, and it continued, though he would sometimes set the project aside. It was eventually published posthumously in 2012 as "The Richard Burton Diaries".
Burton occasionally though rarely wrote magazine articles, including his article that appeared in "Look Magazine" in 1969, "Who Cares About Wales? I Do."
Personal life and views.
Burton was married five times and he had four children. From 1949 until their divorce in 1963, he was married to Welsh actress/producer Sybil Williams, with whom he had two daughters, Katherine "Kate" Burton (born 10 September 1957) and Jessica Burton (born 1959). He was married twice, consecutively, to actress Elizabeth Taylor, from 15 March 1964 to 26 June 1974 and from 10 October 1975 to 29 July 1976. Their first wedding took place in Montreal, and their second wedding occurred, 16 months after their divorce, in Chobe National Park in Botswana. In 1964, the couple adopted a daughter from Germany, Maria Burton (born 1 August 1961). Burton adopted Taylor's daughter by the late producer Mike Todd, Elizabeth Frances "Liza" Todd Burton (born 6 August 1957).
The relationship Burton and Taylor portrayed in the film "Who's Afraid of Virginia Woolf?" was popularly likened to their real-life marriage. Burton disagreed with others about Taylor's famed beauty, saying that calling her "the most beautiful woman in the world is absolute nonsense. She has wonderful eyes, but she has a double chin and an overdeveloped chest, and she's rather short in the leg." In August 1976, a month after his second divorce from Taylor, Burton married model Suzy Miller, the former wife of Formula 1 Champion James Hunt; the marriage ended in divorce in 1982. From 1983 until his death in 1984, Burton was married to make-up artist Sally Hay. In 1957 he became a tax exile, moving to Switzerland, where he lived until his death. In 1968 Burton's elder brother, Ifor, slipped and fell, breaking his neck, after a lengthy drinking session with Burton at the actor's second home in Céligny, Switzerland. The injury left him paralysed from the neck down. His younger brother Graham Jenkins opined it may have been guilt over this that caused Burton to start drinking very heavily, particularly after Ifor died in 1973.
In a February 1975 interview with his friend David Lewin he said he "tried" homosexuality. He also suggested that perhaps all actors were latent homosexuals, and "we cover it up with drink". In 2000, Ellis Amburn's biography of Elizabeth Taylor suggested that Burton had an affair with Laurence Olivier and tried to seduce Eddie Fisher, although this was strongly denied by Burton's younger brother Graham Jenkins.
Burton was a heavy smoker from the time he was just eight years old; and by his own admission in a December 1977 interview with Sir Ludovic Kennedy, #redirect Burton was smoking 60–100 cigarettes per day. According to his younger brother, as stated in Graham Jenkins's 1988 book "Richard Burton: My Brother", he smoked at least a hundred cigarettes a day. His father, also a heavy drinker, refused to acknowledge his son's talents, achievements and acclaim. In turn, Burton declined to attend his funeral, in 1957. Burton's father died from a cerebral haemorrhage, in January 1957, at age 81.
Burton admired and was inspired by the actor and dramatist Emlyn Williams. He employed his son, Brook Williams, as his personal assistant and adviser and he was given small roles in some of the films in which Burton starred.
Burton was banned permanently from BBC productions in November 1974 for writing two newspaper articles questioning the sanity of Winston Churchill and others in power during World War II – Burton reported hating them "virulently" for the alleged promise to wipe out all Japanese people on the planet. The publication of these articles coincided with what would have been Churchill's centenary, and came after Burton had played him in a favourable light in "A Walk with Destiny", with considerable help from the Churchill family. Politically Burton was a lifelong socialist, although he was never as heavily involved in politics as his close friend Stanley Baker. He admired Democratic Senator Robert F. Kennedy and once got into a sonnet-quoting contest with him. In 1973 Burton agreed to play Josip Broz Tito in a film biography, since he admired the Yugoslav leader. While filming in Yugoslavia he publicly proclaimed that he was a communist, saying he felt no contradiction between earning vast sums of money for films and holding left-wing views since "unlike capitalists, I don't exploit other people."
Burton courted further controversy in 1976 when he wrote an unsolicited article for "The Observer" about his friend and fellow Welsh thespian Stanley Baker, who had recently died from pneumonia at the age of 48; the article upset Baker's widow with its depiction of her late husband as an uncultured womaniser.
Melvyn Bragg, in the notes of his "Richard Burton: A Life", says that Burton told Laurence Olivier around 1970 of his own (unfulfilled) plans to make his own film of "Macbeth" with Elizabeth Taylor, knowing that this would hurt Olivier because he had failed to gain funding for his own cherished film version more than a decade earlier.
On his religious views, Burton was an atheist, stating, "I wish I could believe in a God of some kind but I simply cannot."
Health issues.
Burton was an alcoholic who reportedly nearly died in 1974 from an excess of drinking. According to biographer Robert Sellers, "At the height of his boozing in the mid-70s he was knocking back three to four bottles of hard liquor a day."
After drinking himself nearly to death during the shooting of "The Klansman" (1974), Burton was dried out at Saint John's Health Center in Santa Monica, California. Burton allegedly was so inebriated while making the picture that many of his scenes had to be filmed with him sitting or lying down due to his inability to stand. In some scenes, he appears to slur his words or speak incoherently. According to his own diaries, subsequently he used Antabuse to try to stop his excessive drinking, which he blamed for wrecking his marriage to Elizabeth Taylor. Burton himself said of the time leading up to his near loss of life, "I was fairly sloshed for five years. I was up there with John Barrymore and Robert Newton. The ghosts of them were looking over my shoulder."
Burton said that he turned to the bottle for solace "to burn up the flatness, the stale, empty, dull deadness that one feels when one goes offstage."
The 1988 biography of Burton by Melvyn Bragg provides a detailed description of the many health issues that plagued Burton throughout his life. In his youth, Burton was a star athlete and well known for his athletic abilities and strength.
By the age of 41 he had declined so far in health that his arms were by his own admission thin and weak. He suffered from bursitis, possibly aggravated by faulty treatment, arthritis, dermatitis, cirrhosis of the liver, and kidney disease, as well as developing, by his mid-forties, a pronounced limp. How much of this was due to his intake of alcohol is impossible to ascertain, according to Bragg, because of Burton's reluctance to be treated for alcohol addiction; however, in 1974, Burton spent six weeks in a clinic to recuperate from a period during which he had been drinking three bottles of vodka a day. He was also a regular smoker, with an intake of between three and five packs a day for most of his adult life. Health issues continued to plague him until his death of a stroke at the age of 58.
Death.
Burton died at age 58 from a brain haemorrhage on 5 August 1984 at his home in Céligny, Switzerland, and is buried there. Although his death was sudden, his health had been declining for several years, and he suffered from constant and severe neck pain. He had been warned that his liver was enlarged as early as March 1970, and had been diagnosed with cirrhosis of the liver and kidney disease in April 1981. Burton was buried in a red suit, a tribute to his Welsh roots, and with a copy of Dylan Thomas' poems. He and Taylor had discussed being buried together; his widow Sally purchased the plot next to Burton's and erected a large headstone across both, presumably to prevent Taylor from being buried there.
Awards and nominations.
For his contribution to motion pictures, Richard Burton has a star on the Hollywood Walk of Fame located at 6336 Hollywood Boulevard. Due to his theater work, Burton is also a member of the American Theatre Hall of Fame.

</doc>
<doc id="45968" url="http://en.wikipedia.org/wiki?curid=45968" title="Tom Jones (singer)">
Tom Jones (singer)

Sir Thomas Jones Woodward, OBE (born 7 June 1940), known by his stage name Tom Jones, is a Welsh singer. He became one of the most popular vocalists to emerge from the mid-1960s. Since then he has sung nearly every form of popular music — pop, rock, R&B, show tunes, country, dance, soul and gospel — and sold over 100 million records.
Jones has had thirty-six Top 40 hits in the United Kingdom and nineteen in the United States; some of his notable songs include "It's Not Unusual", "What's New Pussycat", "Delilah", "Green, Green Grass of Home", "She's a Lady", "Kiss" and "Sex Bomb".
Having been awarded an OBE in 1999, Jones received a knighthood from Queen Elizabeth II for "services to music" in 2006. Jones has received numerous other awards throughout his career, including the Grammy Award for Best New Artist in 1966, an MTV Video Music Award in 1989 and two Brit Awards – winning Best British Male, in 2000, and Outstanding Contribution to Music, in 2003.
Early life.
Tom Jones was born Thomas Jones Woodward, at 57 Kingsland Terrace, Treforest, Pontypridd in Glamorgan, South Wales. His parents were Thomas Woodward (died 5 October 1981), a coal miner, and Freda Jones (died 7 February 2003). Three of his grandparents were of English origin: his paternal grandfather, James Woodward, was an ironmonger's haulier from Gloucestershire, and his paternal grandmother was from Wiltshire. His maternal grandfather was Welsh, and his maternal grandmother, Ada Jones, was born in Pontypridd, to parents from Somerset and Wiltshire.
Jones began singing at an early age: He would regularly sing at family gatherings, weddings and in his school choir. Jones did not like school or sports, but gained confidence through his singing talent. At 12 he was diagnosed with tuberculosis. Many years later he said: "I spent two years in bed recovering. It was the worst time of my life." During convalescence he could do little else but listen to music and draw.
Jones' bluesy singing style developed out of the sound of American soul music. His early influences included blues and R&B singers Little Richard, Solomon Burke, Jackie Wilson and Brook Benton, as well as Elvis Presley, whom Jones idolised and with whom he would later become good friends.
In March 1957 Jones married his high school girlfriend, Melinda Trenchard when they were expecting a child together, both aged 16. The couple's son, Mark, was born in the month following their wedding. To support his young family Jones took a job working in a glove factory and was later employed in construction.
Career.
Rise to fame.
Jones, whose voice has been described as a "full-throated, robust baritone", became the frontman for Tommy Scott and the Senators, a Welsh beat group, in 1963. They soon gained a local following and reputation in South Wales. In 1964 the group recorded several solo tracks with producer Joe Meek, who took them to various labels, but they had little success. Later that year Decca producer Peter Sullivan saw Tommy Scott and the Senators performing in a club and directed them to manager Phil Solomon, but the partnership was short-lived.
The group continued to play gigs at dance halls and working men's clubs in South Wales and one night, at the Top Hat in Cwmtillery, Wales, Jones was spotted by Gordon Mills, a London-based manager who also originally hailed from South Wales. Mills became Jones' manager and took the young singer to London, and also renamed him Tom Jones, to exploit the popularity of the Academy Award winning 1963 film.
Eventually Mills got Jones a recording contract with Decca. His first single, "Chills and Fever", was released in late 1964. It did not chart, but the follow-up, "It's Not Unusual" became an international hit after offshore pirate radio station Radio Caroline promoted it. The following year would be the most prominent of Jones' career, making him one of the most popular vocalists of the British Invasion. In early 1965 "It's Not Unusual" reached #1 in the United Kingdom and the top ten in the United States. During 1965 Mills secured a number of film themes for Jones to record, including the themes for the film "What's New Pussycat?" (written by Burt Bacharach and Hal David) and for the James Bond film "Thunderball". Jones was also awarded the Grammy Award for Best New Artist for 1966. In Hollywood, Jones met Elvis Presley for the first time who he recalls singing his song as he walked towards him on set.
In 1966 Jones' popularity began to slip somewhat, causing Mills to reshape the singer's image into that of a crooner. Jones also began to sing material that appealed to a wider audience such as the big country hit "Green, Green Grass of Home". The strategy worked and Jones returned to the top of the charts in the United Kingdom and began hitting the Top 40 again in the United States. For the remainder of the decade he scored a string of hits on both sides of the Atlantic, including "I'll Never Fall in Love Again", "I'm Coming Home", and "Delilah" which all reached #2 in the UK chart.
Las Vegas.
In 1967 Jones performed in Las Vegas for the first time, at the Flamingo. His performances and style of dress (increasingly featuring his open, half-unbuttoned shirts and tight trousers) became part of his stage act. He soon chose to record less, instead concentrating on his lucrative club performances. At Caesars Palace his shows were a knicker-hurling frenzy of sexually charged adulation and good-time entertainment. Women started throwing hotel room keys onto the stage. Jones and his idol Elvis Presley met in 1965 at the Paramount film stage, when Elvis was filming "Paradise, Hawaiian Style". They became good friends, spending more and more time together in Las Vegas and duetting until the early hours at Presley's private Las Vegas suite. The friendship endured until Presley's death in 1977. Jones' guitarist between 1969 and 1974 was Big Jim Sullivan, who also met and formed a friendship with Presley.
Jones played at least one week in Las Vegas every year until 2011.
Television and lawsuits.
Jones had an internationally successful television variety show titled "This Is Tom Jones" from 1969 to 1971. The ATV-produced show, which was worth a reported $9m to Jones over three years, was broadcast by ITV in the UK and by ABC in America. As a result of the show, Jones was nominated in 1969 for a Golden Globe for "best actor". From 1980 to 1981 he had a second television variety show, the eponymous "Tom Jones", that was produced in Vancouver, Canada and lasted for 24 episodes.
In recent years both television shows have been the subject of litigation with the original license holder C/F International. As of December 2004 C/F International was a secured judgment creditor of Classic World Productions and its principal, Darryl Payne, for approximately one million US dollars, and was the principal secured creditor at the time of the subsequent bankruptcy filing by the company. C/F International's action against Classic World Productions and owner Darryl Payne was based on unpaid royalties from "This Is Tom Jones", and related recordings. "This Is Tom Jones" is currently sold on DVD by Time Life rather than by Classic World Productions or C/F International.
C/F International's rights to later Tom Jones material were also disputed. In March 2007 Tom Jones and Tom Jones Enterprises sued C/F International to stop the company from licensing sound recordings made from the 1981 "Tom Jones" series. It was contended that any rights that C/F International had to license the "Tom Jones" show did not include the right to make and license separate recordings of the performances on the show and that any rights that C/F International had in the "Tom Jones" show no longer existed because of numerous breaches of contract. Examples of contentious CDs are "Live on the Tom Jones Show", released in 2006, and "Greatest Hits Live", originally issued by C/F International in 1981 and later licensed to, and CD-issued by, Prism Leisure Corporation as "30 Greatest Hits – Live in Concert").
Jones appeared on 31 December 1969, on the BBC's review of the 1960s music scene, "Pop Go The Sixties", performing "Delilah" (in a telerecording of an earlier appearance on "Top of the Pops").
In 1970, Jones teamed up with Raquel Welch and Producer/Choreographer David Winters of Winters-Rosen Productions for the television special "Raquel!". The multi-million dollar television song and dance extravaganza was filmed around the world and included production numbers of classic songs from the era, lavish costumes and guest performances from Jones, John Wayne and Bob Hope.
Decline and resurgence.
In the 1970s Jones toured with the female singing groups Quiet Elegance and The Blossoms as his backing groups. He had a number of hit singles, including "She's a Lady", "Till", and "The Young New Mexican Puppeteer", but in the mid-1970s his popularity declined although he did have a big hit in 1976 with "Say You'll Stay Until Tomorrow" which went to No. 1 on the US country chart and No. 15 on the Billboard Hot 100.
In the early 1980s Jones started to record country music. From 1980 to 1986 he had nine songs in the US country top 40 yet failed to crack the top 100 in the UK or the Billboard Hot 100. After Jones' manager Gordon Mills died of cancer on 29 July 1986, Jones' son Mark became his manager. In 1987, Tom Jones re-entered the singles chart with "A Boy From Nowhere", which went to No. 2 in the United Kingdom. The following year he covered Prince's "Kiss" with Art of Noise. The song reached No. 5 in the UK and No. 31 in the US. The video for "Kiss" was much seen on MTV and VH1, and won the MTV Video Music Award for Breakthrough Video.
Jones received a star on the Hollywood Walk of Fame in 1989, located at 6608 Hollywood Boulevard, Los Angeles, California in front of Frederick's of Hollywood. In 1992 he made his first appearance at the UK's Glastonbury Festival and in 1993 he appeared as himself on episodes of "The Fresh Prince of Bel-Air" and "The Simpsons".
Jones signed with Interscope Records in 1993 and released the album "The Lead And How To Swing It". The first single, "If I Only Knew", went to No. 11 in the UK. Jones performed the song at the 1994 MTV Europe Music Awards, which he also served as host for. In 1997, Jones did the soundtrack for the comedy film "The Full Monty", recording "You Can Leave Your Hat On".
In 1999 Jones released the album "Reload", a collection of cover duets with artists such as the Cardigans, Natalie Imbruglia, Cerys Matthews, Van Morrison, Mousse T, Portishead, Stereophonics and Robbie Williams. The album went to No. 1 in the UK and sold over 4 million copies worldwide. Five singles from "Reload" hit the UK top 40. The single "Sex Bomb" was released in early 2000 and became the biggest single from the album, reaching #3 in the UK Singles Chart.
Into the 21st century.
United States President Bill Clinton invited Jones to perform on New Year's Eve at the 2000 millennium celebrations in Washington, D.C.. Throughout 2000 Jones garnered a number of honours for his work including a BRIT Award for Best British Male. He was also hired as the new voice of Australia's National Rugby League, singing in an advertisement to market the 2000 season.
In 2002 Jones released the album "Mr. Jones", which was produced by Wyclef Jean. The album and the first single, "Tom Jones International", were top 40 hits in the UK.
Jones received the Brit Award for Outstanding Contribution to Music in 2003. The following year, he teamed up with pianist Jools Holland and released "Tom Jones & Jools Holland", a roots rock 'n' roll album. It peaked at No. 5 in the UK.
On 28 May 2005, in celebration of his approaching 65th birthday, Jones returned to his homeland to perform a concert in Ynysangharad Park, Pontypridd before a crowd of about 20,000. This was his first performance in Pontypridd since 1964. That same year the BBC reported that Jones was Wales' wealthiest entertainer, having amassed a fortune of £175 million. Jones collaborated with English-born Australian pop singer John Farnham in 2005 and released the live album "John Farnham & Tom Jones - Together In Concert". The following year Jones worked with Chicane and released the dance track "Stoned in Love", which went to No. 7 in the UK Singles Chart.
Jones, who was awarded an OBE in 1999, was knighted by Elizabeth II in 2006 at Buckingham Palace for his services to music. "When you first come into show business and get a hit record, it is the start of something", Jones said. "As time goes by it just gets better. This is the best thing I have had. It's a wonderful feeling, a heady feeling."
2007–2009.
On 1 July 2007 Jones was among the invited artists who performed at Wembley Stadium at the Concert for Diana, joined on stage by guitarist Joe Perry of Aerosmith and British soul singer Joss Stone. In addition to performing some of his own songs the group covered Arctic Monkeys' "I Bet You Look Good on the Dancefloor". Jones, a boxing fan, has performed national anthems before a number of boxing matches. He sang "God Save the Queen", the United Kingdom's national anthem, before the Floyd Mayweather Jr.-Ricky Hatton fight in 2007; he sang "Hen Wlad Fy Nhadau", the Welsh national anthem, at the fight between fellow Welshman Joe Calzaghe and Bernard Hopkins in 2008; and he sang "God Save the Queen" before the Manny Pacquiao-Ricky Hatton fight in 2009.
In 2008 he released "24 Hours" on S-Curve Records, his first album of new material to be issued in the US for over 15 years. Jones, who was still performing over 200 dates a year as he approached his 70th birthday, set out on a world tour to promote the album. "The fire is still in me. Not to be an oldie, but a goodie. I want to be a contender", Jones said. In 2008 also Tom Jones was inducted into the Hit Parade Hall of Fame. On 16 November 2008 Jones was invited to perform on BBC's "Strictly Come Dancing". He performed the debut single from "24 Hours", "If He Should Ever Leave You", which was named the 9th best song of 2008 by Spinner. One of the songs from "24 Hours", "Give a Little Love", would later be featured in the first trailer for "Little Fockers".
In February 2009 he did an exclusive Take-Away Show with Vincent Moon, performing three songs live in front of a camera in a New York hotel room. In 2009 Jones was voted "Sexiest Man In The World" in the Hungarian magazine "Periodika".
In March 2009 Jones went to the top of the UK Music Charts for the third time in his career thanks to a cover of "Islands in the Stream", sung with Ruth Jones, Rob Brydon and Robin Gibb, who co-wrote the original with his brothers Barry and Maurice. The song, inspired by BBC's hit sitcom "Gavin and Stacey", was released in aid of Comic Relief and reached No. 1 in March 2009.
In 2009 he ditched his hair dye and declared he'd moved onto a new stage in his life: "Over Christmas, I always take a month off and let my hair go and don't even shave. Normally it comes out like salt and pepper, which I hated, but this year it grew out a silver colour, so I kept it, because it's more distinguished", he said.
2010–present.
On 5 June 2010 a performance at Norwich City F.C.'s Carrow Road stadium, two days before he celebrated his 70th birthday, was cancelled due to incomplete improvements to the stadium. Jones announced that his new album "Praise & Blame" would be released on 26 July 2010. The album, produced by Ethan Johns (who has previously worked with Kings of Leon, Rufus Wainwright and Laura Marling), would include covers of songs by Bob Dylan, John Lee Hooker and Billy Joe Shaver, and feature such guest musicians as Booker T.
On Jones' 70th birthday, 7 June 2010, the single "Burning Hell", a cover of the John Lee Hooker classic, from the forthcoming "Praise & Blame" album, was released. In July 2010 it was reported that David Sharpe, vice-president of Island Records (to whom Jones had moved, from EMI, for £1.5m in October 2009), had emailed colleagues demanding that they "pull back this project immediately or get my money back" and asking if the record had been "a sick joke". Jones later attacked Sharpe and revealed that he was furious about the leaked email. By 2010, Jones had sold over 100 million records.
In July 2010 Jones appeared on the penultimate episode of "Friday Night with Jonathan Ross" and performed "Burning Hell". In August 2010, "Praise & Blame" debuted at #2 on the UK album chart.
On 11 September 2010 Jones performed for an audience of 50,000 at the "Help for Heroes" charity concert at Twickenham Stadium performing "Strange Things Are Happening Every Day" and his classic hit "Green Green Grass of Home". On 22 September, Jones appeared on the "Late Show with David Letterman" at the Ed Sullivan Theater in New York.
In May 2011 Jones appeared as guest vocalist on the debut album "Let Them Talk" by Hugh Laurie. On 15 May 2011 he appeared alongside Laurie in the UK ITV series "Perspectives", singing music from the album in New Orleans. On 25 May 2011, he appeared on " American Idol " after a medley of his hits performed by the American Idol "Top 13".
Jones released a single on 19 March 2012, produced by former White Stripes frontman Jack White, called "Evil". The single was first made available through independent record stores in 7" vinyl on 5 March. An exclusive three-coloured vinyl was also sold at only one shop – Spillers Records in Cardiff. The shop, from which Jones bought records as a schoolboy in the 1950s and early 1960s, was founded in 1894 and is listed in "Guinness World Records" as the oldest record shop in the world.
Since March 2012 Jones has been a coach on the BBC talent show "The Voice UK". He mentored Leanne Mitchell to win the first series. 
In May 2012 Jones released the album "Spirit in the Room" on Island Records/Universal Records. The track listing included covers of songs by Paul McCartney, Paul Simon, Leonard Cohen and Richard and Linda Thompson, Blind Willie Johnson, Tom Waits and The Low Anthem.
On 4 June 2012, Jones performed at the Queen's Diamond Jubilee Concert in front of Buckingham Palace, singing "Delilah" and "Mama Told Me Not to Come".
On 18 August 2012, Jones performed a fifty-minute set at the V Festival’s Weston Park site in Staffordshire. On 9 September 2012, Jones headlined at BBC Radio 2's Live in Hyde Park festival.
In May 2014 Jones opened for Morrissey at a special show in the US. On 27 September 2014 Jones performed at the Australian Football League's pre game entertainment for the 2014 Grand Final along with Ed Sheeran.
Personal life.
Jones has remained married to Melinda since 1957, despite his many well-publicised infidelities. The couple have one son, Mark Woodward (1957). At the height of his fame, Jones claims that he had sex with up to 250 groupies a year. His philandering once led Melinda to physically assault him. After reading about one infidelity in a newspaper, she punched and kicked Jones, but he did not fight back; "I took it", he said. Jones has had affairs with well-known women, including Mary Wilson of the Supremes and former Miss World Marjorie Wallace. Cassandra Peterson, better known as Elvira, Mistress of the Dark, claims that she lost her virginity to Jones.
One affair resulted in the birth of a son. In October 1987, while on tour in the United States, Jones had a brief relationship with model Katherine Berkery, who then discovered she was pregnant. After a legal battle that included DNA testing, a United States' court ruled in 1989 that Jones was the boy's father. Jones denied the court's findings, until finally, in 2008, he admitted they were true. He has shown no interest in meeting his son, Jonathan Berkery.
On his accountant's advice, Jones moved to the United States in 1974 to avoid Britain's newly introduced 83% marginal top rate of tax, buying Dean Martin's former mansion in the East Gate Old Bel Air in Los Angeles. In 2009, after 35 years in the United States, Jones revealed that he and Melinda were planning to move back to the United Kingdom. "I've had a great time living in Los Angeles", Jones said, "but after all these years, we think now is the time to move home". On "The Chris Moyles Show" on 27 July 2009, he said he still lives in Los Angeles and will remain there for the foreseeable future, but he still frequently visits the United Kingdom.
Miscellaneous.
Space and Cerys Matthews released "The Ballad of Tom Jones", a song about a fighting couple who are calmed down by listening to Jones' music on the radio. The song reached No. 4 in the UK in 1998.
Compositions.
Tom Jones wrote or co-wrote the following songs: "And I Tell the Sea", "Looking Out My Window", "Feel the Rain" from the 2002 "Mr. Jones" album, "Jezebel", "The Letter", "Younger Days", "Tom Jones International", "Holiday", "The Road", "24 Hours", "Seasons", "We Got Love", "Seen That Face", "Give a Little Love", "If He Should Ever Leave You", "Whatever it Takes", and "Traveling Shoes" from the 2012 album "Spirit in the Room".

</doc>
<doc id="45969" url="http://en.wikipedia.org/wiki?curid=45969" title="Joan Crawford">
Joan Crawford

Joan Crawford (born Lucille Fay LeSueur; March 23, 1904 - some sources list 1905, 1906 or 1908 – May 10, 1977) was an American film and television actress who started as a dancer and stage chorine.
Beginning her career as a dancer in traveling theatrical companies before debuting as a chorine (a chorus girl) on Broadway, Crawford signed a motion picture contract with Metro-Goldwyn-Mayer in 1925. In the 1930s, Crawford's fame rivaled, and later outlasted, MGM colleagues Norma Shearer and Greta Garbo. Crawford often played hardworking young women who find romance and success. These stories were well received by Depression-era audiences and were popular with women. Crawford became one of Hollywood's most prominent movie stars and one of the highest paid women in the United States, but her films began losing money and by the end of the 1930s she was labeled "Box Office Poison". But her career gradually improved in the early 1940s, and she made a major comeback in 1945 by starring in "Mildred Pierce", for which she won the Academy Award for Best Actress.
In 1955, she became involved with the Pepsi-Cola Company through her marriage to company Chairman Alfred Steele. After his death in 1959, Crawford was elected to fill his vacancy on the board of directors but was forcibly retired in 1973. She continued acting in film and television regularly through the 1960s, when her performances became fewer; after the release of the British horror film "Trog" in 1970, Crawford retired from the screen. Following a public appearance in 1974, after which unflattering photographs were published, Crawford withdrew from public life and became increasingly reclusive until her death in 1977.
Crawford married four times. Her first three marriages ended in divorce; the last ended with the death of husband Alfred Steele. She adopted five children, one of whom was reclaimed by his birth mother. Crawford's relationships with her two older children, Christina and Christopher, were acrimonious. Crawford disinherited the two and, after Crawford's death, Christina wrote a "tell-all" memoir, "Mommie Dearest", in which she alleged a lifelong pattern of physical and emotional abuse perpetrated by Crawford and stated that Joan only cared for her career and manipulated her four children for publicity reasons.
Early life.
Crawford was born Lucille Fay LeSueur in San Antonio, Texas on March 23, 1904, 1905 or 1906, the third child of Thomas E. LeSueur (died January 2, 1938), a laundry laborer, and Anna Bell Johnson (died August 15, 1958). She was of French Huguenot, Swedish, and Irish ancestry. Her elder siblings were Daisy (ƒ 1902), who died before Lucille's birth, and Hal. Thomas LeSueur abandoned the family a few months before Crawford's birth but reappeared in Abilene, Texas in 1930 as a 62-year-old construction laborer. Crawford's mother subsequently married Henry J. Cassin (born circa 1867 – died October 25, 1922). This marriage is listed in census records as Crawford's mother's first marriage, calling into question whether Thomas LeSueur and Anna Bell Johnson were ever legally wed. The family lived in Lawton, Oklahoma, where Cassin, a minor impresario, ran the Ramsey Opera House. Despite his own relatively minor status as an impresario, Cassin managed to get such diverse and noted performers as Anna Pavlova and Eva Tanguay during his career. Young Lucille was reportedly unaware that Cassin, whom she called "Daddy", was not her biological father until her brother Hal told her. Lucille preferred the nickname "Billie" as a child and she loved watching vaudeville acts perform on the stage of her stepfather's theatre. The instability of her family life affected her education and her schooling never formally progressed beyond elementary school.
Her ambition was to be a dancer. However, one day, in an attempt to escape piano lessons to play with friends, she leaped from the front porch of her home and cut her foot deeply on a broken milk bottle. She had three operations and was unable to attend elementary school for 18 months.. She eventually fully recovered and returned to dancing. Cassin was accused of embezzlement and although acquitted in court, was blacklisted in Lawton, and the family moved to Kansas City, Missouri around 1916. Cassin was first listed in the City Directory in 1917, living at 403 East Ninth Street. A Catholic, Cassin placed Crawford at St. Agnes Academy in Kansas City. Later, after her mother and stepfather broke up, she stayed on at St. Agnes as a work student, were she spent far more time working, primarily cooking and cleaning, rather than being able to study academically She then went to Rockingham Academy, also as a work student. While attending Rockingham she began dating and had her first serious relationship, with a trumpet player named Ray Sterling, who reportedly inspired her to begin challenging herself academically. In 1922, she registered at Stephens College in Columbia, Missouri, giving her year of birth as 1906. She attended Stephens for only a few months before withdrawing after she realized she was not prepared for college. 
Career.
Early career.
Under the name Lucille LeSueur, Crawford began dancing in the choruses of traveling revues and was spotted dancing in Detroit by producer Jacob J. Shubert. Shubert put her in the chorus line for his 1924 show, "Innocent Eyes", at the Winter Garden Theatre on Broadway in New York City. While appearing in "Innocent Eyes" Crawford met a saxophone player named James Welton. The two were allegedly married in 1924 and lived together for several months, although this supposed marriage was never mentioned in later life by Crawford. She wanted additional work and approached Loews Theaters publicist Nils Granlund. Granlund secured a position for her with producer Harry Richmond's act and arranged for her to do a screen test which he sent to producer Harry Rapf in Hollywood. Stories have persisted that Crawford further supplemented her income by appearing in one or more stag, or soft-core pornographic, films, although this has been disputed. Rapf notified Granlund on December 24, 1924 that Metro-Goldwyn-Mayer (or MGM for short) had offered Crawford a contract at $75 a week. Granlund immediately wired LeSueur – who had returned to her mother's home in Kansas City – with the news; she borrowed $400 for travel expenses. She departed Kansas City on December 26 and arrived in Culver City, California on January 1, 1925.
Credited as Lucille LeSueur, her first film was "Lady of the Night" in 1925, as the body double for MGM's most-popular female star, Norma Shearer. She also appeared in "The Circle" and "Pretty Ladies" (both 1925), starring comedienne ZaSu Pitts. This was soon followed by equally small and unbilled roles in two other 1925 successes, "The Only Thing" and "The Merry Widow". MGM publicity head Pete Smith recognized her ability to become a major star, but felt her name sounded fake; he told studio head Louis B. Mayer that her last name—LeSueur—reminded him of a sewer. Smith organized a contest called "Name the Star" in "Movie Weekly" to allow readers to select her new stage name. The initial choice was "Joan Arden" but, after another actress was found to have prior claim to that name, the alternate surname "Crawford" became the choice. Crawford later said that she wanted her first name to be pronounced "Jo-Anne", and that she hated the name Crawford because it sounded like "craw fish", but also admitted she "liked the security" that went with the name.
Self-promotion and early successes.
Growing increasingly frustrated over the size and quality of the parts she was given, Crawford embarked on a campaign of self-promotion. As MGM screenwriter Frederica Sagor Maas recalled, "No one decided to make Joan Crawford a star. Joan Crawford became a star because Joan Crawford decided to become a star." She began attending dances in the afternoons and evenings at hotels around Hollywood, where she often won dance competitions with her performances of the Charleston and the Black Bottom.
Her strategy worked, and MGM cast her in the film where she first made an impression on audiences, Edmund Goulding's "Sally, Irene and Mary" (1925). From the beginning of her career, Crawford considered Norma Shearer—the studio's most-popular actress—her professional nemesis. Since Shearer was married to MGM Head of Production Irving Thalberg, she had the first choice of scripts and had more control than other stars in what films she would and would not make. Crawford was quoted to have said, "How can I compete with Norma? She sleeps with the boss!" In 1926, Crawford was named one of the WAMPAS Baby Stars along with Mary Astor, Dolores del Río, Janet Gaynor, and Fay Wray among others. That same year, she starred in "Paris", co-starring Charles Ray. Within a few years, she became the romantic female lead to many of MGM's top male stars, including Ramón Novarro, John Gilbert, William Haines, and Tim McCoy. Crawford appeared in "The Unknown" (1927), starring Lon Chaney, Sr. who played a carnival knife thrower with no arms. Crawford played his skimpily-clad young carnival assistant whom he hopes to marry. She stated that she learned more about acting from watching Chaney work than from anyone else in her career. "It was then," she said, "I became aware for the first time of the difference between standing in front of a camera, and acting." Also in 1927, she appeared alongside her close friend, William Haines, in "Spring Fever", which was the first of three movies the duo made together.
In 1928, Crawford starred opposite Ramón Novarro in "Across to Singapore", but it was her role as Diana Medford in "Our Dancing Daughters" (1928) that catapulted her to stardom. The role established her as a symbol of modern 1920s-style femininity which rivaled Clara Bow, the original It girl, then Hollywood's foremost flapper. A stream of hits followed "Our Dancing Daughters", including two more flapper-themed movies, in which Crawford embodied for her legion of fans (many of whom were women) an idealized vision of the free-spirited, all-American girl. F. Scott Fitzgerald wrote of Crawford:Joan Crawford is doubtless the best example of the flapper, the girl you see in smart night clubs, gowned to the apex of sophistication, toying iced glasses with a remote, faintly bitter expression, dancing deliciously, laughing a great deal, with wide, hurt eyes. Young things with a talent for living.
On June 3, 1929, Crawford married Douglas Fairbanks, Jr. at Saint Malachy's Roman Catholic Church (known as "The Actors' Chapel" due to its proximity to Broadway theatres) in Manhattan, although neither was Catholic. Fairbanks was the son of Douglas Fairbanks and the stepson of Mary Pickford, who were considered Hollywood royalty. Fairbanks Sr. and Pickford were opposed to the marriage and did not invite the couple to their home, Pickfair, for eight months after the marriage. The relationship between Crawford and Fairbanks, Sr. eventually warmed; she called him "Uncle Doug" and he called her "Billie", her old childhood nickname. Following that first invitation, Crawford and Fairbanks, Jr. became more frequent guests, which was hard on Crawford. While the Fairbanks men played golf together, Crawford was left either with Pickford or alone.
To rid herself of her Southwestern accent, Crawford tirelessly practiced diction and elocution. She said:If I were to speak lines, it would be a good idea, I thought, to read aloud to myself, listen carefully to my voice quality and enunciation, and try to learn in that manner. I would lock myself in my room and read newspapers, magazines and books aloud. At my elbow I kept a dictionary. When I came to a word I did not know how to pronounce, I looked it up and repeated it correctly fifteen times.
Transition to sound and continued success.
After the release of "The Jazz Singer" in 1927—the first major Hollywood movie with synchronized sound—sound films, or talkies as they became nicknamed, were all the rage. The transition from silent to sound panicked many—if not all—involved with the film industry; many silent film stars found themselves unemployable because of their undesirable voices and hard-to-understand accents or simply because of their refusal to make the transition to talkies. Many studios and stars avoided making the transition as long as possible, especially MGM, which was the last studio to switch over to sound. "The Hollywood Revue of 1929" (1929) was one of the studio's first all-sound films, and their first attempt to showcase their stars' ability to make the transition from silent to sound. Crawford was among the dozen or more MGM stars included in the movie; she sang the song "Got a Feeling for You" during the film's first act. Her first starring role in an all-sound feature-length film was in "Untamed" in 1929, co-starring Robert Montgomery. Despite the success of the film at the box office, it received mixed reviews from critics, who noted that while Crawford seemed nervous at making the transition to sound, also noted that she had become one of the most-popular actresses in the world.
Crawford made a successful transition to talkies in the late 1920s. "Montana Moon" (1930), an uneasy mix of Western clichés and music, teamed her with John Mack Brown and Ricardo Cortez. Although the film had problems with censors, it was a major success at the time of its release. "Our Blushing Brides" (1930), co-starring Robert Montgomery and Anita Page, was the final installment in the so-called "Our Dancing Daughters" franchise. It was a greater success–both critically and financially–than her previous talkies, and became one of her personal favorites. Her next movie, "Paid" (1930), paired her with Robert Armstrong and was another success. During the early sound era, MGM began to place Crawford in more sophisticated-type roles, rather than continuing to promote her flapper-inspired persona of the silent era.
In 1931, MGM cast Crawford in five films. Three of them teamed her opposite the studio's biggest male star and King of Hollywood, Clark Gable. "Dance, Fools, Dance", released in February 1931, was the film pairing of Crawford and Gable. Their second movie together, "Laughing Sinners", released in May 1931, was directed by Harry Beaumont and also co-starred Neil Hamilton. "Possessed", their third film together, released in October, was directed by Clarence Brown. These films were immensely popular with audiences, and were generally well received by critics, stapling Crawford's position as one of MGM's top female stars of the decade, along with Norma Shearer, Greta Garbo, and Jean Harlow. Her only other notable film of 1931, "This Modern Age", was released in August, and despite unfavorable reviews, was a moderate success.
MGM next cast her in the film "Grand Hotel", directed by Edmund Goulding. As the studio's first all-star production, Crawford co-starred opposite Greta Garbo, John and Lionel Barrymore, and Wallace Beery among others. Receiving third billing, she played the middle-class stenographer to Beery's controlling general director. Crawford later admitted to being nervous during the filming of the movie because she was working with "very big stars", and that she was disappointed that she had no scenes with the "divine Garbo". "Grand Hotel" was released in April 1932 to critical and commercial success. It was the highest-grossing movie of the year, and won the Academy Award for Best Picture. Crawford achieved continued success in "Letty Lynton" (1932). Soon after this movie's release, a plagiarism suit forced MGM to withdraw it. It has never been shown on television or made available on home video, and is therefore considered the "lost" Crawford film. The gown with large ruffled sleeves, designed by Adrian, which Crawford wore in the movie, became a popular style that same year, and was even copied by Macy's. On a loan out to United Artists, she played prostitute Sadie Thompson in "Rain" (1932), a film version of John Colton's 1923 play. Actress Jeanne Eagels played the role on stage and Gloria Swanson had originated the part on screen in the 1928 film version. Crawford's performance was panned and the film was not a success.
Despite the failure of "Rain", in 1932 the publishing of the first "Top Ten Money Making Stars Poll" placed Crawford third in popularity at the box office, behind only Marie Dressler and Janet Gaynor. She remained on the list for the next several years, last appearing on it in 1936. In May 1933, Crawford divorced Fairbanks. Crawford cited "grievous mental cruelty", claiming Fairbanks had "a jealous and suspicious attitude" toward her friends and that they had "loud arguments about the most trivial subjects" lasting "far into the night". Following her divorce, she was again teamed with Clark Gable and Franchot Tone and a pre-Hollywood fame Fred Astaire in the hit "Dancing Lady" (1933), in which she received top billing. She next played the title role in "Sadie McKee" (1934) opposite Gene Raymond and Franchot Tone. Crawford was paired with Gable for the fifth time in "Chained" (1934) and for the sixth time in "Forsaking All Others" (1934). Crawford's films of this era were some of the most-popular and highest-grossing films of the mid-1930s.
In 1935, Crawford married Franchot Tone, a stage actor from New York who planned to use his film salary to finance his theatre group. Tone and Crawford appeared together in "Today We Live" (1933) and were immediately drawn to each other, although Crawford was hesitant about entering into another romance so soon after her split from Fairbanks. The couple built a small theatre at Crawford's Brentwood home and put on productions of classic plays for select groups of friends. Before and during their marriage, Crawford worked to promote Tone's Hollywood career, but Tone was ultimately not interested in being a movie star and Crawford eventually wearied of the effort. Tone began drinking and physically abusing Crawford; she filed for divorce, which was granted in 1939. Crawford and Tone eventually reconciled their friendship and Tone even proposed in 1964 that they remarry. When Tone died in 1968, Crawford arranged for him to be cremated and his ashes scattered at Muskoka Lakes, Canada.
Crawford continued her reign as a popular movie actress well into the mid-1930s. "No More Ladies" (1935) co-starred Robert Montgomery and then-husband Franchot Tone, and was a success. Crawford had long pleaded with MGM's head Louis B. Mayer to cast her in more dramatic roles, and although he was reluctant, he cast her in the sophisticated comedy-drama "I Live My Life" (1935), directed by W.S. Van Dyke. It was well received by critics and made a larger profit than the studio had expected. She next starred in the period film "The Gorgeous Hussy" (1936), opposite Robert Taylor and Lionel Barrymore as well as Tone, a critical and box office success, become one of Crawford's biggest hits of the decade. "Love on the Run" (1936), a romantic comedy directed by W.S. Van Dyke, was her seventh film co-starring Clark Gable. It was, at the time of its release, called "a lot of happy nonsense" by critics, but a financial success nonetheless.
Box Office Poison.
Crawford was proclaimed the first "Queen of the Movies" in 1937 by "Life" magazine. Despite this, and even though she remained a respected MGM actress and her film still earned profits, her popularity declined in the late 1930s. In 1937, she unexpectedly slipped from seventh to fortieth place at the box office, and her public popularity also began to wane. Richard Boleslawski's comedy-drama "The Last of Mrs. Cheyney" (1937) teamed her opposite William Powell for the first time; it was also her first film in years to lose money at the box office. She co-starred opposite Franchot Tone for the seventh and final time in "The Bride Wore Red" (1937). The film was generally unfavorably reviewed by the majority of critics, with one critic calling it the "same ole rags-to-riches story" Crawford had been making for years. It also ran a financial loss, becoming one of MGM's biggest failures of the year. "Mannequin" did, as the "New York Times" stated, "restore Crawford to her throne as queen of the working girls". Most other reviews were positive, and the film managed to generate a minor profit, but it did not resurrect Crawford's popularity.
On May 3, 1938, Crawford—along with MGM colleagues Greta Garbo, Norma Shearer, Luise Rainer, and John Barrymore, as well as Katharine Hepburn, Fred Astaire, Dolores del Río and others—was dubbed "Box Office Poison" in an open letter in the "Independent Film Journal". The list was submitted by Harry Brandt, president of the Independent Theatre Owners Association of America. Brandt stated that while these stars had "unquestioned" dramatic abilities, their high salaries did not reflect in their ticket sales, thus hurting the movie exhibitors involved. Her follow-up movie, "The Shining Hour" (1938), co-starring Margaret Sullavan and Melvyn Douglas, was well received by critics, but a box office flop.
She made a comeback with her role as home-wrecker Crystal Allen in "The Women" in 1939. A year later, she broke from formula, playing the unglamorous role of Julie in "Strange Cargo" (1940), her eighth and final film with Clark Gable. She later starred as a facially disfigured blackmailer in "A Woman's Face" (1941), a remake of the Swedish film "En kvinnas ansikte" which had starred Ingrid Bergman in the lead role three years earlier. While the film was only a moderate box office success, her performance was hailed by many critics. 
Crawford adopted her first child, a daughter, in 1940. Because she was single, California law prevented her from adopting within the state so she arranged the adoption through an agency in Las Vegas. The child was temporarily called Joan until Crawford changed her name to Christina. She married actor Phillip Terry on July 21, 1942 after a six-month courtship. Together the couple adopted a son whom they named Christopher, but his birth mother reclaimed the child. They adopted another boy, whom they named Phillip Terry, Jr.
After the marriage ended in 1946, Crawford changed the child's name to Christopher Crawford. After 18 years, Crawford's contract with MGM was terminated by mutual consent on June 29, 1943. In lieu of the last film remaining under her contract, MGM bought her out for $100,000. During World War II she was a member of American Women's Voluntary Services.
Move to Warner Brothers.
For $500,000, Crawford signed with Warner Brothers for a three movie deal and was placed on the payroll on July 1, 1943. Her first film for the studio was "Hollywood Canteen" (1944), an all-star morale-booster film that teamed her with several other top movie stars at the time. Crawford said one of the main reasons she signed with Warner Brothers was because she wanted to play the character "Mattie" in a proposed 1944 film version of Edith Wharton's novel "Ethan Frome" (1911).
She wanted to play the title role in "Mildred Pierce" (1945), but Bette Davis was the studio's first choice. However, Davis turned the role down. Director Michael Curtiz did not want Crawford to play the part, claiming Davis could be replaced with Barbara Stanwyck, Olivia de Havilland, or Joan Fontaine. However, Warner Brothers went against Curtiz's wishes and cast Crawford in the film. Throughout the entire production of the movie, Curtiz criticized Crawford. He has been quoted as having told Jack Warner, "She comes over here with her high-hat airs and her goddamn shoulder pads... why should I waste my time directing a has-been?" Curtiz demanded Crawford prove her suitability by taking a screen test. After the test, Curtiz agreed to Crawford's casting. "Mildred Pierce" was a resounding critical and commercial success. It epitomized the lush visual style and the hard-boiled film noir sensibility that defined Warner Bros. movies of the late 1940s, earning Crawford the Academy Award for Best Actress in a Leading Role.
The success of "Mildred Pierce" revived Crawford's movie career. For several years, she reigned as one of the most respected and most successful actresses in Hollywood. In 1946, she starred opposite John Garfield in "Humoresque", a romantic drama of a love affair between an older woman and a younger man. She starred alongside Van Heflin in "Possessed" (1947), for which she received a second Academy Award nomination, although she did not win. In "Daisy Kenyon" (1947), she appeared opposite Dana Andrews and Henry Fonda, and in "Flamingo Road" (1949) she played a carnival dancer opposite Zachary Scott and David Brian. She made a cameo appearance in "It's a Great Feeling" (1949), poking fun at her own screen image. In 1950, she starred in the film noir, "The Damned Don't Cry!", and starred in "Harriet Craig".
After the completion of "This Woman Is Dangerous" (1952), a film Crawford called her "worst", she asked to be released from her Warner Brothers contract. By this time she felt Warners was losing interest in her and she decided it was time to move on. Later that same year, she received her third and final Academy Award nomination for "Sudden Fear" for RKO Radio Pictures. In 1953, she appeared in her final film for MGM, "Torch Song". The movie received favorable reviews and moderate success at the box office. 
Crawford adopted two more children in 1947, identical twins whom she named Cindy and Cathy.
Radio and television.
Crawford worked in the radio series "The Screen Guild Theater" on January 8, 1939; "Good News"; "Baby", broadcast March 2, 1940 on Arch Oboler's "Lights Out"; "The Word" on "Everyman's Theater" (1941); "Chained" on the "Lux Radio Theater" and Norman Corwin's "Document A/777" (1948). She appeared in episodes of anthology television series in the 1950s and, in 1959, made a pilot for her series, "The Joan Crawford Show".
Al Steele and Pepsi Cola Company.
Crawford married her fourth and final husband, Alfred Steele, at the Flamingo Hotel in Las Vegas on May 10, 1955. Crawford and Steele met at a party in 1950 when Steele was an executive at PepsiCo. They renewed their acquaintance at a New Year's Eve party in 1954. Steele by that time had become President of Pepsi Cola. Alfred Steele would later be named Chairman of the Board and Chief Executive Officer of Pepsi Cola. She traveled extensively on behalf of Pepsi following the marriage. She estimated that she traveled over 100,000 miles for the company.
Steele died of a heart attack in April 1959. Crawford was initially advised that her services were no longer required. After she told the story to Louella Parsons, Pepsi reversed its position and Crawford was elected to fill the vacant seat on the board of directors.
Crawford received the sixth annual "Pally Award", which was in the shape of a bronze Pepsi bottle. It was awarded to the employee making the most significant contribution to company sales. In 1973, Crawford was forced to retire from the company at the behest of company executive Don Kendall, whom Crawford had referred to for years as "Fang".
Later career.
After her Academy Award nominated performance in 1952's "Sudden Fear", Crawford continued to work steadily throughout the rest of the decade. In 1954, she starred in "Johnny Guitar", a camp western film, co-starring Sterling Hayden and Mercedes McCambridge. She also starred in "Female on the Beach" (1955) with Jeff Chandler, and in "Queen Bee" (1955) alongside John Ireland. The following year, she starred opposite a young Cliff Robertson in "Autumn Leaves" (1956) and filmed a leading role in "The Story of Esther Costello" (1957), co-starring Rossano Brazzi. Crawford, who had been left near-penniless following Alfred Steele's death accepted a small role in "The Best of Everything" (1959). Although she was not the star of the film, she received positive reviews. Crawford would later name the role as being one of her personal favorites. However, by the early 1960s, Crawford's status in motion pictures had declined considerably.
Crawford starred as Blanche Hudson, an old, wheelchair-bound former A-list movie star in conflict with her psychotic sister, in the highly successful psychological thriller "What Ever Happened to Baby Jane?" (1962). Despite the actresses' earlier tensions, Crawford reportedly suggested Bette Davis for the role of Jane. The two stars maintained publicly that there was no feud between them. The director, Robert Aldrich, explained that Davis and Crawford were each aware of how important the film was to their respective careers and commented, "It's proper to say that they really detested each other, but they behaved absolutely perfectly." After filming was completed, their public comments against each other propelled their animosity into a lifelong feud. The film was a huge success, recouping its costs within 11 days of its nationwide release, and temporarily revived Crawford's career. Davis was nominated for an Academy Award for her performance as Jane Hudson. Crawford secretly contacted each of the other Oscar nominees in the category (Katharine Hepburn, Geraldine Page and Anne Bancroft, all East Coast-based actresses), to let them know that if they could not attend the ceremony, she would be happy to accept the Oscar on their behalf; all agreed. Both Davis and Crawford were backstage when the absent Anne Bancroft was announced as the winner, and Crawford accepted the award on her behalf. Davis claimed for the rest of her life that Crawford had campaigned against her, a charge Crawford denied. 
That same year, Crawford starred as Lucy Harbin in William Castle's horror mystery "Strait-Jacket" (1964). Robert Aldrich cast Crawford and Davis in "Hush... Hush, Sweet Charlotte" (1964). After a purported campaign of harassment by Davis on location in Louisiana, Crawford returned to Hollywood and entered a hospital. After a prolonged absence, during which Crawford was accused of feigning illness, Aldrich was forced to replace her with Olivia de Havilland. Crawford claimed to be devastated, saying ""I heard the news of my replacement over the radio, lying in my hospital bed" ... I cried for 9 hours."" Crawford nursed grudges against Davis and Aldrich for the rest of her life, saying of Aldrich, "He is a man who loves evil, horrendous, vile things", to which Aldrich replied, "If the shoe fits, wear it, and I am very fond of Miss Crawford."
In 1965 she played Amy Nelson in "I Saw What You Did" (1965), another William Castle vehicle. She starred as Monica Rivers in Herman Cohen's horror thriller film "Berserk!" (1967). After the film's release, Crawford guest-starred as herself on "The Lucy Show". The episode, "Lucy and the Lost Star", first aired on February 26, 1968. Crawford struggled during rehearsals and drank heavily on-set, leading series star Lucille Ball to suggest replacing her with Gloria Swanson. However, Crawford was letter-perfect the day of the show, which included dancing the Charleston, and received two standing ovations from the studio audience.
In October 1968, Crawford's 29-year-old daughter, Christina (who was then acting in New York on the CBS soap opera "The Secret Storm"), needed immediate medical attention for a ruptured ovarian tumor. Until Christina was well enough to return, Crawford offered to play her role, to which producer Gloria Monty readily agreed. Although Crawford did well in rehearsal, she lost her composure while taping and the director and producer were left to struggle to piece together the necessary footage.
Crawford's appearance in the 1969 television film "Night Gallery" (which served as pilot to the series that followed), marked one of Steven Spielberg's earliest directing jobs. She made a cameo appearance as herself in the first episode of the situation comedy "The Tim Conway Show", which aired on January 30, 1970. She starred on the big screen one final time, playing Dr. Brockton in Herman Cohen's science fiction horror film "Trog" (1970), rounding out a career spanning 45 years and more than eighty motion pictures. Crawford made three more television appearances, as Stephanie White in a 1970 episode ("The Nightmare") of "The Virginian" and as Joan Fairchild (her final performance) in a 1972 episode ("Dear Joan: We're Going to Scare You to Death") of "The Sixth Sense".
Final years.
In 1970, Crawford was presented with the Cecil B. DeMille Award by John Wayne at the Golden Globes, which was telecast from the Coconut Grove at The Ambassador Hotel in Los Angeles. She also spoke at Stephens College, which she had attended for four months in 1922.
Crawford published her autobiography, "A Portrait of Joan", co-written with Jane Kesner Ardmore, in 1962 through Doubleday. Crawford's next book, "My Way of Life", was published in 1971 by Simon and Schuster. Those expecting a racy tell-all were disappointed, although Crawford's meticulous ways were revealed in her advice on grooming, wardrobe, exercise, and even food storage. Upon her death there was found in her apartment photographs of John F. Kennedy, for whom she had reportedly voted in the 1960 presidential election.
In September 1973, Crawford moved from apartment 22-G next door to a smaller apartment, 22-H, at the Imperial House. Her last public appearance was September 23, 1974, at a party honoring her old friend Rosalind Russell at New York's Rainbow Room. Russell was suffering from breast cancer and arthritis at the time. When Crawford saw the unflattering photos that appeared in the papers the next day, she said, "If that's how I look, then they won't see me anymore." Crawford cancelled all public appearances, began declining interviews and left her apartment less and less.
Dental-related issues, including surgery which left her needing round-the-clock nursing care, plagued her from 1972 until mid-1975. While on antibiotics for this problem in October 1974, her drinking caused her to black out, slip and strike her face. The incident scared her enough to give up drinking and smoking, although she insisted it was because of her return to Christian Science. The incident is recorded in a series of letters sent to her insurance company held in the stack files on the 3rd floor of the New York Public Library for the Performing Arts; it is also documented by Carl Johnnes in his biography of the actress, "Joan Crawford: The Last Years".
Death and legacy.
On May 8, 1977, Crawford gave away her beloved Shih Tzu "Princess Lotus Blossom", being too weak to care for it. She died two days later at her New York apartment from a heart attack, while also reportedly ill with pancreatic cancer. A funeral was held at Campbell Funeral Home, New York, on May 13, 1977. In her will, which was signed October 28, 1976, Crawford bequeathed to her two youngest children, Cindy and Cathy, $77,500 each from her $2,000,000 estate. She explicitly disinherited the two eldest, Christina and Christopher, writing "It is my intention to make no provision herein for my son Christopher or my daughter Christina for reasons which are well known to them." She left money to her favorite charities: the U.S.O. of New York; the Motion Picture Home, of which she had been a founder; the American Cancer Society; the Muscular Dystrophy Association; the American Heart Association; and the Wiltwyck School for Boys.
A memorial service was held for Crawford at All Souls' Unitarian Church on Lexington Avenue in New York on May 16, 1977, and was attended by, among others, her old Hollywood friend Myrna Loy. Another memorial service, organized by George Cukor, was held on June 24 in the Samuel Goldwyn Theater at the Academy of Motion Picture Arts and Sciences in Beverly Hills. Crawford was cremated and her ashes were placed in a crypt with her fourth and final husband, Alfred Steele, in Ferncliff Cemetery, Hartsdale, New York.
Joan Crawford's hand and footprints are immortalized in the forecourt of Grauman's Chinese Theater on Hollywood Boulevard in Hollywood. She has a star on the Hollywood Walk of Fame at 1750 Vine Street. "Playboy" listed Crawford as #84 of the "100 Sexiest Women of the 20th century". Crawford was also voted the tenth greatest female star in the history of American cinema by the American Film Institute.
"Mommie Dearest".
In November 1978, Christina Crawford published "Mommie Dearest", which contained allegations that her late adoptive mother was emotionally and physically abusive to Christina and her brother Christopher and how Joan Crawford adopted her children as a scheme to become famous instead of parenting. Many of Crawford's friends and co-workers, including Van Johnson, Ann Blyth, Marlene Dietrich, Myrna Loy, Katharine Hepburn, Cesar Romero, Gary Gray, Betty Barker (Joan's secretary for nearly fifty years), Douglas Fairbanks Jr. (Crawford's first husband), and Crawford's other daughters — Cathy and Cindy — denounced the book, categorically denying any abuse. But others, including Betty Hutton, Helen Hayes, James MacArthur (Hayes' son), June Allyson, Liz Smith, Rex Reed, and Vincent Sherman stated that they had witnessed the abuse. Joan Crawford's secretary, Jeri Binder Smith, confirmed Christina's account.
"Mommie Dearest" became a bestseller and was made into the 1981 biography film "Mommie Dearest", starring Faye Dunaway as Crawford.
Sources.
</dl>
Further reading.
</dl>

</doc>
<doc id="45971" url="http://en.wikipedia.org/wiki?curid=45971" title="Pentecost">
Pentecost

Pentecost (Ancient Greek: Πεντηκοστή [ἡμέρα], "Pentēkostē [hēmera]", "the fiftieth [day]") is the Greek name for the Feast of Weeks, a prominent feast in the calendar of ancient Israel celebrating the giving of the Law on Sinai. This feast is still celebrated in Judaism as Shavuot. 
Later, in the Christian liturgical year, it became a feast commemorating the descent of the Holy Spirit upon the Apostles and other followers of Jesus Christ (120 in all), as described in the Acts of the Apostles 2:1–31. For this reason, Pentecost is sometimes described by some Christians today as the "Birthday of the Church".
In the Eastern church, Pentecost can also refer to the whole fifty (50) days between Easter and Pentecost, hence the book containing the liturgical texts for Paschaltide is called the Pentecostarion. The feast is also called White Sunday, or "Whitsunday", especially in England, where the following Monday was traditionally a public holiday. Pentecost is celebrated fifty days (i.e. 49 days with the first day counted, seven weeks) after Easter Sunday, hence its name. Pentecost falls on the tenth day after Ascension Thursday (which falls 40 days after Easter).
The Pentecostal movement of Christianity derives its name from the New Testament event.
Old Testament.
Pentecost is the old Greek and Latin name for the Jewish harvest festival, or Festival of Weeks (Hebrew חג השבועות "Hag haShavuot" or "Shevuot", literally "Festival of Weeks"), which can be found in the Hebrew Bible. Shavuot is called the Festival of Weeks (Hebrew: חג השבועות, chag ha-Shavuot, Exodus 34:22, Deuteronomy 16:10 ); Festival of Reaping (Hebrew: חג הקציר, chag ha-Katsir, Exodus 23:16 ), and Day of the First Fruits (Hebrew יום הביכורים, Yom ha-Bikkurim, Numbers 28:26 ).
Extra-Biblical and Post-Biblical Jewish Texts.
The Talmud refers to Shavuot as "Atzeret" (Hebrew: עצרת, literally, "refraining" or "holding back"), referring to the prohibition against work on this holiday and to the conclusion of the holiday and season of Passover. Since Shavuot occurs 50 days after Passover, Hellenistic Jews gave it the name Pentecost.(πεντηκοστή, "fiftieth day").
According to Jewish tradition, Pentecost commemorates God giving the Ten Commandments at Mount Sinai fifty days after the Exodus. The Talmud derives this from a calculation based on Biblical Texts.
There is a Jewish tradition that David was born and died on Pentecost. This may be why, in Peter's speech found in Acts 2, he explains the current happenings using David's tomb and some of his quotes (Acts 2:29"ff"). 
New Testament.
The biblical narrative of Pentecost is given in the second chapter of the Book of Acts. Present were about one hundred and twenty followers of Christ (Acts 1:15), including the Twelve Apostles (i.e. the Eleven faithful disciples and Matthias who was Judas' replacement) (Acts 1:13, 26), his mother Mary, various other women disciples and his brothers (Acts 1:14).
Their reception of the Holy Spirit in the Upper Room is recounted in Acts 2:1–6:
While those on whom the Spirit had descended were speaking in many languages, the Apostle Peter stood up with the eleven and proclaimed to the crowd that this event was the fulfillment of the prophecy ("I will pour out my spirit"). In Acts 2:17, it reads: "'And in the last days,' God says, 'I will pour out my spirit upon every sort of flesh, and your sons and your daughters will prophesy and your young men will see visions and your old men will dream dreams." He also mentions (2:15) that it was the third hour of the day (about 9:00 AM). Acts 2:41 then reports: "Then they that gladly received his word were baptized: and the same day there were added unto them about three thousand souls."
Peter stated that this event was the beginning of a continual outpouring that would be available to all believers from that point on, Jews and Gentiles alike.
Location of the first Pentecost.
Traditional interpretation holds that the Descent of the Holy Spirit took place in the Upper Room, or Cenacle, while celebrating the day of Pentecost (Shavuot). The Upper Room was first mentioned in Luke 22:12–13 ( ""And he shall shew you a large upper room furnished: there make ready. And they went, and found as he had said unto them: and they made ready the passover"."). This Upper Room was to be the location of the Last Supper and the institution of Holy Communion. The next mention of an Upper Room is in Acts 1:13–14, the continuation of the Luke narrative, authored by the same biblical writer.
Here the disciples and women wait and they gave themselves up to constant prayer: "And when they were come in, they went up into an upper room, where abode both Peter, and James, and John, and Andrew, Philip, and Thomas, Bartholomew, and Matthew, James the son of Alphaeus, and Simon Zelotes, and Judas the brother of James. These all continued with one accord in prayer and supplication, with the women, and Mary the mother of Jesus, and with his brethren."
Then, in Acts 2:1–2, ""And when the day of Pentecost was fully come, they were all with one accord in one place. And suddenly there came a sound from heaven as of a rushing mighty wind, and it filled all the house where they were sitting."," "They" refers to the aforementioned disciples, and it includes the women. The "place" referring to the same Upper Room where these persons had """continued" with one accord in prayer and supplication". "
Date.
According to the current Jewish Calendar, the date of Pentecost is fifty days from Passover. In Jewish antiquity dates were disputed, as in the Dead Sea scrolls or in the Mishnah.
In Christian tradition Pentecost is part of the Moveable Cycle of the ecclesiastical year. According to Christian tradition, Pentecost is always seven weeks after Easter Sunday; that is to say, 50 days after Easter (inclusive of Easter Day). In other words, it falls on the eighth Sunday, counting Easter Day. The date of Easter may be calculated using a procedure known as Computus.
Since the date of Easter is calculated differently in the East and West (see Easter controversy), in most years the two traditions celebrate Pentecost on different days (though in some years the celebrations will coincide, as in 2010, 2011, and 2014). In the West, the earliest possible date is May 10 (as in 1818 and 2285), and the latest possible date June 13 (as in 1943 and 2038). In the East, this range of possible dates presently corresponds from May 23 to June 26 on the Gregorian calendar.
Liturgical celebration.
Eastern churches.
In the Eastern Orthodox Church, Pentecost is one of the Orthodox Great Feasts and is considered to be the highest ranking Great Feast of the Lord, second in rank only to Easter/Resurrection Sunday/Passover. The service is celebrated with an All-night Vigil on the eve of the feast day, and the Divine Liturgy on the day of the feast itself. Orthodox churchess are often decorated with greenery and flowers on this feast day, and the celebration is intentionally similar to the Jewish holiday of Shavuot, which celebrates the giving of the Mosaic Law.
The feast itself lasts three days. The first day is known as "Trinity Sunday"; the second day is known as "Spirit Monday" (or "Monday of the Holy Spirit"); and the third day, Tuesday, is called the "Third Day of the Trinity." The Afterfeast of Pentecost lasts for one week, during which fasting is not permitted, even on Wednesday and Friday. In the Orthodox Tradition, the liturgical color used at Pentecost is green, and the clergy and faithful carry flowers and green branches in their hands during the services.
An extraordinary service called the Kneeling Prayer, is observed on the night of Pentecost. This is a Vespers service to which are added three sets of long poetical prayers, the composition of Saint Basil the Great, during which everyone makes a full prostration, touching their foreheads to the floor (prostrations in church having been forbidden from the day of Pascha (Easter) up to this point). Uniquely, these prayers include a petition for all of those in hell, that they may be granted relief and even ultimate release from their confinement, if God deems this possible.
All of the remaining days of the ecclesiastical year, until the preparation for the next Great Lent are named for the day after Pentecost on which they occur (for example, the 13th Tuesday After Pentecost).
The Second Monday after Pentecost is the beginning of the Apostles' Fast (which continues until the Feast of Saints Peter and Paul on June 29). Theologically, Orthodox do not consider Pentecost to be the "birthday" of the Church; they see the Church as having existed before the creation of the world (cf. "The Shepherd of Hermas")
The Orthodox icon of the feast depicts the Twelve Apostles seated in a semicircle (sometimes the Theotokos (Virgin Mary) is shown sitting in the center of them). At the top of the icon, the Holy Spirit, in the form of tongues of fire, is descending upon them. At the bottom is an allegorical figure, called "Kosmos", which symbolizes the world. Although Kosmos is crowned with earthly glory he sits in the darkness caused by the ignorance of God. He is holding a towel on which have been placed 12 scrolls, representing the teaching of the Twelve Apostles.
In the ancient "Coptic Orthodox Church of Alexandria", Pentecost is one of the seven Major "Lord's Feasts". It is celebrated at the time of ninth hour (3:00pm) on the Sunday of Pentecost by a special three-segment prayer known as the "Office of Genuflection (Kneeling Prayer)". This feast is followed with the "Apostles Fast" which has a fixed end date on the fifth of the Coptic month of Epip [which currently falls on July 12, which is equivalent to June 29, due to the current 13-day Julian-Gregorian calendar offset]. The fifth of Epip is the commemoration of the Martyrdom of St. Peter and Paul.
Western churches.
The liturgical celebrations of Pentecost in Western churches are as rich and varied as those in the East. The main sign of Pentecost in the West is the color red. It symbolizes joy and the fire of the Holy Spirit.
Priests or ministers, and choirs wear red vestments, and in modern times, the custom has extended to the lay people of the congregation wearing red clothing in celebration as well. Red banners are often hung from walls or ceilings to symbolize the blowing of the "mighty wind" and the free movement of the Spirit.
The celebrations may depict symbols of the Holy Spirit, such as the dove or flames, symbols of the church such as Noah's Ark and the Pomegranate, or especially within Protestant churches of Reformed and Evangelical traditions, words rather than images naming for example, the gifts and Fruits of the Spirit. Red flowers at the altar/preaching area, and red flowering plants such as geraniums around the church are also typical decorations for Pentecost masses/services. These symbolize the renewal of life, the coming of the warmth of summer, and the growth of the church at and from the first Pentecost.
These flowers often play an important role in the ancestral rites, and other rites, of the particular congregation. For example, in both Protestant and Catholic churches, the plants brought in to decorate for the holiday may be each "sponsored" by individuals in memory of a particular loved one, or in honor of a living person on a significant occasion, such as their Confirmation day.
In the German speaking lands, in Central Europe, and wherever the people of these nations have wandered, green branches are also traditionally used to decorate churches for Pentecost. Birch is the tree most typically associated with this practice in Europe, but other species are employed in different climates.
The singing of Pentecost hymns is also central to the celebration in the Western tradition. Hymns such as Martin Luther's "Komm, Heiliger Geist, Herre Gott" (Come, Holy Spirit, God and Lord), Charles Wesley's "Spirit of Faith Come Down" and "Come Holy Ghost Our Hearts Inspire" or Hildegard von Bingen's "O Holy Spirit Root of Life" are popular. Some traditional hymns of Pentecost make reference not only to themes relating to the Holy Spirit or the church, but to folk customs connected to the holiday as well, such as the decorating with green branches.
Consider "Oh that I had a Thousand Voices" (""O daß ich tausend Zungen hätte") by German, Johann Mentzer Verse 2: "Ye forest leaves so green and tender, that dance for joy in summer air"…" or "O Day Full of Grace" (""Den signede Dag") by Dane, N. F. S. Grundtvig verse 3: "Yea were every tree endowed with speech and every leaflet singing"…". In the Roman Catholic Church, Veni Sancte Spiritus is the sequence hymn for the Day of Pentecost. This has been translated into many languages and is sung in many denominations today. See also Veni Creator Spiritus.
Trumpeters or brass ensembles are often specially contracted to accompany singing and provide special music at Pentecost services, recalling the Sound of the mighty wind. While this practice is common among a wide spectrum of Western denominations (Eastern Churches do not employ instrumental accompaniment in their worship) it is particularly typical, and distinctive to the heritage of the Moravian Church.
Another custom is reading the appointed Scripture lessons in multiple foreign languages recounting the speaking in tongues recorded in .
In the Middle Ages, cathedrals and great churches throughout Western Europe were fitted with a peculiar architectural feature known as a Holy Ghost hole; a small circular opening in the roof that symbolized the entrance of Holy Spirit into the midst of the assembled worshippers. At Pentecost, these Holy Ghost holes would be decorated with flowers, and sometimes a dove figure lowered through into the church while the story of the Pentecost was read. Holy Ghost holes can still be seen today in European churches such as Canterbury Cathedral.
Similarly, a large two dimensional dove figure would be, and in some places still are, cut out of wood, painted and decorated with flowers, to be lowered over the people, particularly during the singing of the sequence hymn, or Veni Creator Spiritus. In other places, particularly Sicily and the Italian peninsula, rose petals were and are thrown from the galleries over the congregation calling to mind the tongues of fire. In modern times, this practice has been revived, and interestingly adapted as well, to include the strewing of origami doves from above, or suspending them – sometimes by the hundreds – from the ceiling.
In some cases, red fans, or red handkerchiefs are distributed to the assembled worshippers to be waved during the procession, etc. Other congregations have incorporated the use of red balloons, signifying the "Church's Birthday" into their festivities. These may be carried by worshippers, used to decorate the sanctuary, or released all at once.
Fasting, baptisms, and confirmations.
For some Protestants, the nine days between Ascension Day, and Pentecost are set aside as a time of fasting, and world-wide prayer in honor of the disciples' time of prayer and unity awaiting the Holy Spirit. Similarly among Roman Catholics, special Pentecost Novenas are held. The Pentecost Novena is considered the first Novena, all other Novenas offered in preparation of various festivals and Saints days deriving their practice from those original nine days of prayer observed by the disciples of Christ.
While the Eve of Pentecost was traditionally a day of fasting for Catholics, today's canon law no longer requires it. Both Catholics and Protestants may hold spiritual retreats, prayer vigils and litanies in the days leading up to Pentecost. In some cases vigils on the Eve of Pentecost may last all night. Pentecost is also one of the occasions specially appointed for the Lutheran Litany to be sung.
From the early days of Western Christianity, Pentecost became one of the days set aside to celebrate Baptism. In Northern Europe Pentecost was preferred even over Easter for this rite, as the temperatures in late spring might be supposed to be more conducive to outdoor immersion as was then the practice. It is proposed that the term Whit Sunday derives from the custom of the newly baptized wearing white clothing, and from the white vestments worn by the clergy in English liturgical uses. The holiday was also one of the three days each year (along with Christmas and Easter) Roman Catholics were required to confess and receive the sacrament of Holy Communion in order to remain in good church standing.
Holy Communion is likewise often a feature of the Protestant observance of Pentecost as well. It is one of the relatively few Sundays some Reformed denominations may offer the communion meal, and is one of the days of the year specially appointed among Moravians for the celebration of their Love Feasts. Ordinations are celebrated across a wide array of Western denominations at Pentecost, or near to it. In some denominations, for example the Lutheran Church, even if an ordination or consecration of a deaconess is not celebrated on Pentecost, the liturgical color will invariably be red, and the theme of the service will be the Holy Spirit.
Above all, Pentecost is a day for the Confirmation celebrations of young people. Flowers, the wearing of white robes, or white dresses recalling Baptism, rites such as the laying on of hands, and vibrant singing play prominent roles on these joyous occasions, the blossoming of Spring forming an equal analogy with the blossoming of youth.
The typical image of Pentecost in the West is that of the Virgin Mary seated centrally and prominently among the disciples, with flames resting on the crowns of their heads. Occasionally parting clouds suggesting the action of the "mighty wind", rays of light, and/or the Dove, are also depicted. Of course, the Western iconographic style is less static and stylized than that of the East, and other very different representations have been produced, and in some cases have achieved great fame, such as the Pentecosts by Titian, Giotto and el Greco.
Paul already in the 1st century notes the importance of this festival to the early Christian communities. (See: & ) Since the lifetime of some who may have been eyewitnesses, annual celebrations of the descent of the Holy Spirit have been observed. Before the Second Vatican Council Pentecost Monday as well was a Holy Day of Obligation during which the Catholic Church addressed the newly baptized and confirmed. Since that time however Pentecost Monday is no longer solemnized.
Nevertheless Pentecost remains an official church festival in many Protestant churches, such as the (Lutheran) Church of Sweden, the Evangelical Lutheran Church of Finland, and others. In the Byzantine Catholic Rite Pentecost Monday is no longer a Holy Day of Obligation, but rather a simple holy day. In the Roman Catholic Church, as at Easter, the liturgical rank of Monday and Tuesday of Pentecost week is a Double of the First Class and across many Western denominations, Pentecost is celebrated with an octave culminating on Trinity Sunday.
Marking the festival's importance, in several denominations, such as the Lutheran, Episcopal and United Methodist churches (and formerly in the Roman Catholic Church), all the Sundays from the holiday itself until the next Advent in late November or December are designated the 2nd, 3rd, Nth, Sunday after Pentecost, etc. Throughout the year, in Roman Catholic piety, the Pentecost is the third of the Glorious Mysteries of the Holy Rosary, as well as being one of the Stations of the Resurrection, or Via Lucis.
In some Evangelical and Pentecostal churches, where there is less emphasis on the liturgical year, Pentecost may still be one of the greatest celebrations in the year, such as in Germany or Romania. In other cases, Pentecost may be ignored as a holy day in these churches. In many evangelical churches in the United States, the secular holiday, Mother's Day, may be more celebrated than the ancient and biblical feast of Pentecost. Some evangelicals and Pentecostals are observing the liturgical calendar and observe Pentecost as a day to teach the Gifts of the Holy Spirit.
Across denominational lines Pentecost has been an opportunity for Christians to honor the role of the Holy Spirit in their lives, and celebrate the birth of the church in an ecumenical context.
Classical compositions for Pentecost.
The Lutheran church of the Baroque observed three days of Pentecost. Some composers wrote sacred cantatas to be performed in the church services of these days. Johann Sebastian Bach composed several cantatas for days of Pentecost, including ""Erschallet, ihr Lieder, erklinget, ihr Saiten!" BWV 172" in 1714 and "Also hat Gott die Welt geliebt", BWV 68 in 1725. Gottfried Heinrich Stölzel wrote cantatas such as "Werdet voll Geistes" (Get full of spirit) in 1737. Mozart composed an antiphon "Veni Sancte Spiritus" in 1768.
Olivier Messiaen composed an organ mass "Messe de la Pentecôte" in 1949/50. In 1964 Fritz Werner wrote an oratorio for Pentecost "Veni, sancte spiritus" (Come, Holy Spirit) on the sequence "Veni sancte spiritus", and Jani Christou wrote "Tongues of Fire", a Pentecost oratorio. Richard Hillert wrote a "Motet for the Day of Pentecost" for choir, vibraphone, and prepared electronic tape in 1969. Violeta Dinescu composed "Pfingstoratorium", an oratorio for Pentecost for five soloists, mixed chorus and small orchestra in 1993.
Customs and traditions.
In Italy it was customary to scatter rose petals from the ceiling of the churches to recall the miracle of the fiery tongues; hence in Sicily and elsewhere in Italy Whitsunday is called "Pasqua rosatum". The Italian name "Pasqua rossa" comes from the red colours of the vestments used on Whitsunday.
In France it was customary to blow trumpets during Divine service, to recall the sound of the mighty wind which accompanied the Descent of the Holy Spirit.
In the north west of England, church and chapel parades called Whit Walks take place at Whitsun (sometimes on Whit Friday, the Friday after Whitsun). Typically, the parades contain brass bands and choirs; girls attending are dressed in white. Traditionally, Whit Fairs (sometimes called Whitsun Ales) took place. Other customs such as morris dancing and cheese rolling are also associated with Whitsun.
In Finland there is a saying known virtually by everyone which translates as "if one has no sweetheart until Pentecost, he/she will not have it during the whole summer."
Public holiday.
Since Pentecost itself is on a Sunday, it is automatically a public holiday in Christian countries.
Pentecost Monday is a public holiday in many European countries including Austria, Belgium, Cyprus, Denmark, France, Germany, Greece, Hungary, Iceland, Luxembourg, the Netherlands, Norway, Portugal, Romania (since 2008), (most parts of) Switzerland, Ukraine and also in the African nations Senegal, Benin and Togo.
In Sweden it was also a public holiday, but Pentecost Monday (Annandag Pingst) was replaced by Swedish National Day on June 6, by a government decision on December 15, 2004. In Italy and Malta, it is no longer a public holiday. It was a public holiday in Ireland until 1973, when it was replaced by Early Summer Holiday on the first Monday in June. In the United Kingdom the day is known as Whit Monday, and was a bank holiday until 1967 when it was replaced by the Spring Bank Holiday on the last Monday in May. In France, following reactions to the implementation of the "Journée de solidarité envers les personnes âgées", Pentecost Monday has been reestablished as a holiday (but a "working holiday") on May 3, 2005.
Literary allusions.
According to legend, King Arthur always gathered all his knights at the round table for a feast and a quest on Pentecost:
"So ever the king had a custom that at the feast of Pentecost in especial, afore other feasts in the year, he would not go that day to meat until he had heard or seen of a great marvel."
German poet Johann Wolfgang von Goethe declared Pentecost "das liebliche Fest" – the lovely Feast, in a selection by the same name in his Reineke Fuchs.
"Pfingsten, das liebliche Fest", speaks of Pentecost as a time of greening and blooming in fields, woods, hills, mountains, bushes and hedges, of birds singing new songs, meadows sprouting fragrant flowers, and of festive sunshine gleaming from the skies and coloring the earth – iconic lines idealizing the Pentecost holidays in the German-speaking lands.
Further, Goethe records an old peasant proverb relating to Pentecost in his "Sankt-Rochus-Fest zu Bingen"
 – "Ripe strawberries at Pentecost mean a good wine crop."
Alexandre Dumas, père mentions of Pentecost in Twenty Years After (French: Vingt ans après), the sequel to The Three Musketeers. A meal is planned for the holiday, to which La Ramée, second in command of the prison, is invited, and by which contrivance, the Duke is able to escape. He speaks sarcastically of the festival to his jailor, foreshadowing his escape : "Now, what has Pentecost to do with me? Do you fear, say, that the Holy Ghost may come down in the form of fiery tongues and open the gates of my prison?"
William Shakespeare mentions Pentecost in a line from Romeo and Juliet Act 1, Scene V. At the ball at his home, Capulet speaks in refuting an overestimate of the time elapsed since he last danced: "What, man? 'Tis not so much, 'tis not so much! 'Tis since the nuptial of Lucentio, Come Pentecost as quickly as it will, Some five-and-twenty years, and then we mask'd." Note here the allusion to the tradition of mumming, Morris dancing and wedding celebrations at Pentecost.

</doc>
<doc id="45975" url="http://en.wikipedia.org/wiki?curid=45975" title="Whatì">
Whatì

Whatì[] (from the Dogrib language meaning "Marten Lakes"), officially the Tłı̨chǫ Community Government of Whatì is a First Nations community in the North Slave Region of the Northwest Territories, Canada. Whatì is located by Lac La Martre, about 164 km northwest of the territorial capital of Yellowknife.
History.
With rich and varied wildlife, the area has long been a favoured hunting ground of the Tłı̨chǫ (Dogrib Dene) Aboriginal people. The North West Company established a trading post there in 1793, and many natives began settling there permanently, while they continued to hunt and fish in the area. With the establishment of a trading post at Fort Rae on Great Slave Lake in the late 19th century, most regional trading was accomplished at the HBC and free traders posts there. A trading post at Lac La Martre was not again established until the 1920s. 
On 1 January 1996, the community officially changed its name from Lac La Martre to the Tłı̨chǫ name "Wha Ti", meaning "Marten Lake," the same meaning as the French and then on 4 August 2005 to the current spelling. Other traditional Tli Cho names for the settlement include Tsoti[] ('fouled water lake') and Mine Go Kola[] ('net fishing with houses').
Demographics.
At the 2011 census the population was 492, an increase of 7.0% over the 2006 census. In 2006 there were 435 Aboriginal people all of which were North American Indians. In 2012 the Government of the Northwest Territories reported that the population was 519 with an average yearly growth rate of 0.4% from 2001.
Economy.
While trapping, hunting, and fishing continue to be the main economic activities in this traditional community, efforts have been made to develop tourism as well. A fishing lodge was opened, and many tourists come to see the abundant wildlife, including black bears, Barren-ground Caribou, Gray Wolves, and eagles. The community takes especial pride in the fact that no alcohol is allowed there.
Whatì is part of the Tlicho Government.

</doc>
<doc id="45976" url="http://en.wikipedia.org/wiki?curid=45976" title="Compromise of 1850">
Compromise of 1850

The Compromise of 1850 was a package of five separate bills passed by the United States Congress in September 1850, which defused a four-year political confrontation between slave and free states regarding the status of territories acquired during the Mexican-American War (1846–1848). The compromise, drafted by Whig Senator Henry Clay of Kentucky and brokered by Clay and Democratic Senator Stephen Douglas of Illinois, reduced sectional conflict. Controversy arose over the Fugitive Slave provision. The Compromise was greeted with relief, although each side disliked specific provisions.
The Compromise became possible after the sudden death of President Zachary Taylor, who, although a slaveowner, had favored excluding slavery from the Southwest. Whig leader Henry Clay designed a compromise, which failed to pass in early 1850, due to opposition by both pro-slavery southern Democrats, led by John C. Calhoun, and anti-slavery northern Whigs. Upon Clay's instruction, Douglas then divided Clay's bill into several smaller pieces and narrowly won their passage over the opposition of those with stronger views on both sides.
Background.
Soon after the start of the Mexican War, when the extent of the territories to be acquired was still unclear, the question of whether to allow slavery in those territories polarized the Northern and Southern United States in the most bitter sectional conflict up to this time. Since Texas was a slave state, not only the residents of that State, but the pro- and anti-slavery camps on a national scale had an interest in the size of the state of Texas. Texas claimed land north of the 36°30' demarcation line for slavery set by the 1820 Missouri Compromise.
The Texas Annexation resolution had required that if any new states were formed out of Texas’ lands, those north of the Missouri Compromise line would become free states.
Senator Joseph Underwood referred to "the threatened civil war, unless we appease the hot bloods of Texas."
According to historian Mark Stegmaier, "The Fugitive Slave Act, the abolition of the slave trade in the District of Columbia, the admission of California as a free state, and even the application of the formula of popular sovereignty to the territories were all less important than the least remembered component of the Compromise of 1850--the statute by which Texas relinquished its claims to much of New Mexico in return for federal assumption of the debts."
Stegmaier also refers to "the principal Southern demand for a division of California at the line of 35° north latitude" and says that "Southern extremists made clear that a congressionally mandated division of California figured uppermost on their agenda."
During the deadlock of four years, the Second Party System broke up, Mormon pioneers settled Utah, the California Gold Rush settled northern California, and New Mexico under a federal military government turned back Texas's attempt to assert control over territory Texas claimed as far west as the Rio Grande. The eventual Compromise of 1850 preserved the Union, but only for another decade.
Various proposals.
Proposals during 1846–50 on the division of the Southwest included:
Final proposed compromise.
On January 29, 1850, Whig Senator Henry Clay gave a speech which called for compromise on the issues dividing the Union. However, Clay's specific proposals for achieving a compromise, including his idea for Texas' boundary, were not adopted in a single bill. Upon Clay's urging, Senator Stephen A. Douglas, Democrat of Illinois, divided Clay's bill into several smaller bills, and passed each separately. When he instructed Douglas, Clay was nearly dead and unable to guide the congressional debate any further. The Compromise came to coalesce around a plan dividing Texas at its present-day boundaries, creating territorial governments with "popular sovereignty" (without the Wilmot Proviso) for New Mexico and Utah, admitting California as a free state, abolishing the slave trade in the District of Columbia, and enacting a new fugitive slave law.
The Compromise of 1850 was formally proposed by Clay and guided to passage by Douglas over Northern Whig and Southern Democrat opposition. It was enacted September 1850:
View of Seward and Northern Whigs.
Most Northern Whigs, led by William Henry Seward who delivered his famous "Higher Law" speech during the controversy, opposed the Compromise as well because it would not have applied the Wilmot Proviso to the western territories and because of the newly strengthened fugitive slave act, which would have pressed ordinary citizens into duty on slave-hunting patrols. This provision was inserted by Democratic Virginia Senator James M. Mason to entice border-state Whigs, who faced the greatest danger of losing slaves as fugitives but who were lukewarm on general sectional issues related to the South into supporting Texas's land claims.
Zachary Taylor avoided the issue as the Whig candidate during the 1848 U.S. presidential election but then as President attempted to sidestep the entire controversy by pushing to admit California and New Mexico as free states immediately, avoiding the entire territorial process and thus the Wilmot Proviso question. Taylor's stand was unpopular among Southerners and surprised them because Taylor was a Southerner.
Northern Democrats and Southern Whigs supported the Compromise. Southern Whigs, many of whom were from the border states, supported the stronger fugitive slave law.
Debate and results.
On April 17, a "Committee of Thirteen" agreed on the border of Texas as part of Clay's plan. The dimensions were later changed. That same day, during debates on the measures in the Senate, Vice President Millard Fillmore and Senator Benton verbally sparred, with Fillmore charging that the Missourian was "out of order." During the heated debates, Compromise floor leader Henry S. Foote of Mississippi drew a pistol on Senator Benton.
In early June, nine slave holding Southern states sent delegates to the Nashville Convention to determine their course of action should the compromise take hold. While some delegates preached secession, eventually the moderates ruled, and they proposed a series of compromises, including extending the geographic dividing line designated by the Missouri Compromise of 1820 to the Pacific Coast.
The various bills were initially combined into one "omnibus" bill. Despite Clay's efforts, it failed in a crucial vote on July 31, opposed by southern Democrats and by northern, anti-slavery Whigs. He announced on the Senate floor the next day that he intended to persevere and pass each individual part of the bill. The 73-year-old Clay, however, was physically exhausted as the effects of the tuberculosis that would eventually kill him began to take its toll. Clay left the Senate to recuperate in Newport, Rhode Island, while Stephen A. Douglas wrote the separate bills and guided them through the Senate.
The situation had been changed by the sudden death of President Taylor and the accession of Vice President Millard Fillmore to the presidency, on July 9, 1850. President Fillmore, anxious to find a quick solution to the conflict in Texas over the border with New Mexico, which threatened to become armed conflict between Texas militia and Federal soldiers, reversed the administration's position late in July and threw its support to the compromise measures. The Northern Democrats held together and supported each of the bills and gained Whigs or Southern Democrats to pass each one. All passed and were signed by Fillmore between September 9 and September 20, 1850.
Clay was still given much of the credit for the Compromise's success. It quieted the controversy between Northerners and Southerners over the expansion of slavery and delayed secession and civil war for another decade. Senator Henry S. Foote of Mississippi, who had suggested the creation of the Committee of Thirteen, later said, "Had there been one such man in the Congress of the United States as Henry Clay in 1860–'61 there would, I feel sure, have been no civil war."
Implications.
The Compromise in general proved widely popular politically, as both parties committed themselves in their platforms to the finality of the Compromise on sectional issues. The strongest opposition in the South occurred in the states of South Carolina, Georgia, Alabama, and Mississippi, but unionists soon prevailed, spearheaded by Georgians Alexander Stephens, Robert Toombs, and Howell Cobb and the creation of the Georgia Platform. This peace was broken only by the divisive Kansas-Nebraska Act of 1854 introduced by Stephen Douglas, which had the effect of repealing the Missouri Compromise and led directly to the formation of the Republican Party, whose capture of the national government in 1860 led directly to the secession crisis of 1860-61.
Many historians argue that the Compromise played a major role in postponing the American Civil War for a decade, during which time the Northwest was growing more wealthy and more populous, and was being brought into closer relations with the Northeast. During that decade, the Whig Party had completely broken down, being replaced with the new Republican Party dominant in the North and the Democrats in the South. But others argue that the Compromise only made more obvious pre-existing sectional divisions and laid the groundwork for future conflict. In this view, the Fugitive Slave Law helped polarize North and South, as shown in the enormous reaction to Harriet Beecher Stowe's novel "Uncle Tom's Cabin". The passage of the Fugitive Slave Law aroused feelings of bitterness in the North. Furthermore, the Compromise of 1850 led to a breakdown in the spirit of compromise in the United States in the antebellum period, directly before the Civil War. The Compromise exemplifies this spirit, but the deaths of influential senators who worked on the compromise, primarily Henry Clay and Daniel Webster, contributed to this feeling of increasing disparity between the North and South.
The delay of hostilities for ten years allowed the free economy of the northern states to continue to industrialize. The southern states, to a large degree based on slave labor and cash crop production, lacked the ability to industrialize heavily. By 1860, the northern states had added many more miles of railroad, steel production, modern factories, and population to the advantages it possessed in 1850. The North was better able to supply, equip, and man its armed forces, an advantage that would prove decisive in the later stages of the war.
Issues.
Three major types of issues were addressed by the Compromise of 1850, to wit: a variety of boundary issues; status of territory issues; and the issue of slavery. While capable of analytical distinction, the boundary and territory issues were actually included in the overarching issue of slavery. Pro- and anti-slavery interests were each concerned with both the amount of land on which slavery was permitted and with the number of States which respectively would be in the slave or free camps. Since Texas was a slave state, not only the residents of that state, but the pro- and anti-slavery camps on a national scale had an interest in the size of the state of Texas.
The general solution that was adopted by the Compromise of 1850 was to transfer a considerable part of the territory claimed by the state of Texas to the federal government, to formally organize two new territories, the Territory of New Mexico and the Territory of Utah, which expressly would be allowed to locally determine whether they would become slave or free territories, to add another free state to the Union (California), adopt a severe measure to recover slaves who had escaped to a free state or free territory (the Fugitive Slave Law), and to abolish the slave trade in the District of Columbia.
Texas.
The independent Republic of Texas won the decisive Battle of San Jacinto (April 21, 1836) against Mexico and captured Mexican president Antonio Lopez de Santa Anna. He signed the Treaties of Velasco, which recognized the Rio Grande as the boundary of the Republic of Texas. The treaties were repudiated by the government of Mexico which insisted it was sovereign over Texas and promised to reclaim the lost territories. To the extent that there was a de facto recognition, Mexico treated the Nueces River as its northern boundary control. A huge, largely unsettled area lay between the two rivers. Neither Mexico nor the Republic of Texas had the military strength to effectively assert its territorial claim. On December 29, 1845, the Republic of Texas was annexed to the United States and became the 28th state. Texas was staunchly committed to slavery, with its constitution making illegal the unauthorized emancipation of slaves by their owners. With this annexation the United States inherited the territorial claims of the former Republic of Texas against Mexico. The territorial claim to the area between the Nueces River and the Rio Grande and Mexican resistance to it led to the Mexican-American War. On February 2, 1848, that war was concluded by the Treaty of Guadalupe Hidalgo. Among the provisos of the Treaty was the recognition by Mexico of the area between the Nueces River and the Rio Grande being a part of the United States.
The Republic of Texas had claimed ownership of the eastern half of present-day New Mexico, along with sections of Colorado, Kansas and Wyoming, but Texas had never effectively controlled the area, which was dominated by hostile Indian tribes (see Comancheria). However, the federal government now controlled the area after 1846. The Compromise of 1850 solved the problem by setting the present boundaries of Texas in return for $10 million in federal bonds paid to the state of Texas.
The state of Texas was heavily burdened with debt, which had been contracted during its struggles as the Republic of Texas. The federal government agreed to pay $10 million of bonds in trade for the transfer of a large portion of the claimed area of the state of Texas to the territory of the federal government and for the relinquishment of various claims which Texas had upon the federal government. (These bonds bore interest at the rate of 5%, which interest was collectible by Texas every six months, and the principal was redeemable at the end of fourteen years.)
The Constitution (Article IV, Section 3) does not permit Congress to unilaterally reduce the territory of any state, so the first part of the Compromise of 1850 had to take the form of an offer to the Texas State Legislature, rather than a unilateral enactment. The Texas State Legislature did ratify the bargain and in due course the transfer of a large swath of land from the state of Texas to the federal government was accomplished. Texas was allowed to keep the following portions of the erstwhile disputed land: that which is south of the 32nd parallel, and that which is south of the 36°30' parallel north and east of the 103rd meridian west. The rest of the land which had been disputed between Mexico and the Republic of Texas was transferred to federal government.
New Mexico and Utah Territories.
The first law of the Compromise of 1850 also organized the Territory of New Mexico. The second law, also enacted September 9, 1850, organized the Territory of Utah.
Some of the land had been claimed by the Republic of Texas. The Treaty of Guadalupe Hidalgo made no mention of the claims of the Republic of Texas; Mexico simply agreed to a Mexico-U.S. border south of both the "Mexican Cession" and the Republic of Texas claims. Before the Compromise of 1850, this disputed land had been claimed but never controlled by the state of Texas. Of importance in 1850 was land included in present-day eastern New Mexico.
From the Mexican Cession, the New Mexico Territory received most of the present-day state of Arizona, most of the western part of the present-day state of New Mexico, and the southern tip of present-day Nevada (south of the 37th parallel). From Texas, the territory received most of present-day eastern New Mexico, a portion of present-day Colorado (east of the crest of the Rocky Mountains, west of the 103rd meridian, and south of the 38th parallel), and a small portion of present-day Wyoming.
From the Mexican Cession, the Utah Territory received present-day Utah, most of present-day Nevada (everything north of the 37th parallel), a major part of present-day Colorado (everything west of the crest of the Rocky Mountains), and a small part of present-day Wyoming. This included the newly founded colony at Salt Lake of Brigham Young. From Texas, the Utah Territory received most of present day eastern New Mexico, and some of present-day Colorado that is east of the crest of the Rocky Mountains.
A key provision of each of the laws respectively organizing the Territory of New Mexico and the Territory of Utah was that slavery would be either permitted or prohibited as a local option (Popular Sovereignty). This was an important repudiation of the idea behind the Wilmot Proviso (which never passed Congress); it would have forbidden slavery in any territory acquired from Mexico.
California.
California also became part of the U.S. as a result of the Mexican Cession. After the Mexican War, California was essentially run by military governors. President James K. Polk tried to get Congress to officially establish a territorial government in California, but the increasing North vs. South debates prevented this. The South wanted to extend slave territory to Southern California and to the Pacific coast, while the North did not.
Starting in late 1848, Americans and foreigners of many different countries rushed into California for the California Gold Rush, exponentially increasing the population. In response to growing demand for a better more representative government, a Constitutional Convention was held in 1849. The delegates there unanimously outlawed slavery. They had no interest in extending the Missouri Compromise Line through California and splitting the state; the lightly populated southern half never had slavery and was heavily Hispanic.
The third statute of the Compromise of 1850 allowed California to be admitted to the Union, undivided, as a free state on September 9, 1850.
Fugitive Slave Law.
The fourth statute of the Compromise of 1850, enacted September 18, 1850, is informally known as the Fugitive Slave Law or the Fugitive Slave Act of 1850. (It bolstered the Fugitive Slave Act of 1793.) The new version of the Fugitive Slave Law required federal judicial officials in all states and federal territories, including in those states and territories in which slavery was prohibited, to actively assist with the return of escaped slaves to their masters in the states and territories permitting slavery. Any federal marshal or other official who did not arrest an alleged runaway slave was liable to a fine of $1,000. Law-enforcement officials everywhere in the United States had a duty to arrest anyone suspected of being a fugitive slave on no more evidence than a claimant's sworn testimony of ownership. The suspected slave could not ask for a jury trial or testify on his or her own behalf. In addition, any person aiding a runaway slave by providing food or shelter was to be subject to six months' imprisonment and a $1,000 fine. Officers capturing a fugitive slave were entitled to a fee for their work.
In addition to federal officials, the ordinary citizens of free states could be summoned to join a posse and be required to assist in the capture and/or custody and/or transportation of the alleged escaped slave. This particular law was so rigorously pro-slavery as to prohibit the admission of the testimony of a person accused of being an escaped slave into evidence at the judicial hearing to determine the status of the accused escaped slave. Thus, if a freedman were claimed to be an escaped slave under the Fugitive Slave Law he or she could not resist his or her return to slavery by truthfully telling his or her own actual history.
The Fugitive Slave Act was essential to meet Southern demands. In terms of public opinion in the North the critical provision was that ordinary citizens were required to aid slave catchers. Many northerners deeply resented this requirement that they personally aid and abet slavery. Resentment towards this act continued to heighten tensions between the North and South, as inflamed by abolitionists such as Harriet Beecher Stowe. Her book "Uncle Tom's Cabin" stressed the horrors of recapturing escaped slaves, and outraged Southerners.
Banning slave trade in the District of Columbia.
The fifth law, enacted on September 20, 1850, prohibited the slave trade (but not slavery itself) in the District of Columbia. Southerners in Congress were unanimous in opposing this provision, which was seen as a concession to the abolitionists, but were outvoted.

</doc>
<doc id="45978" url="http://en.wikipedia.org/wiki?curid=45978" title="Ergative">
Ergative

The term ergative is used in grammar in three different meanings:

</doc>
<doc id="45979" url="http://en.wikipedia.org/wiki?curid=45979" title="Victoria Beckham">
Victoria Beckham

Victoria Caroline Beckham ("née" Adams; born 17 April 1974) is an English businesswoman, fashion designer, model and singer. In the late 1990s, Beckham rose to fame with the all-female pop group Spice Girls and was dubbed Posh Spice by the July 1996 issue of the British music magazine "Top of the Pops". After the Spice Girls split, she was signed to Virgin Records and Telstar Records and had four UK Top 10 singles. Her first release, "Out of Your Mind", reached Number 2 in the UK Singles Chart.
Beckham has participated in five official documentaries and reality shows about her, including "Being Victoria Beckham", "The Real Beckhams", and "". She has since made a cameo appearance in an episode of "Ugly Betty", and been a guest judge on "Project Runway", "Germany's Next Topmodel", and "American Idol". She is married to David Beckham and they have four children. As of 2014, the couple's joint wealth is estimated at £380 million.
In the past decade, Beckham has become an internationally recognised style icon and fashion designer. Following high-profile collaborations with other brands, she launched an eponymous label in 2008 and a lower-priced (diffusion) label in 2011. The Victoria Beckham label was named designer brand of the year in the UK in 2011; in 2012 the brand was assessed as the star performer in the Beckham family's business interests. Writing in the "Daily Telegraph" in 2011, Belinda White noted that the transition from WAG to fashion designer had been more successful than most had predicted, saying: "She has gathered a significant celebrity following and won over the scathing fashion pack who now clamour for a ticket to her bi-annual show at New York Fashion Week."
Early life.
Beckham was born at the Princess Alexandra Hospital in Harlow, Essex and raised in Goffs Oak, Hertfordshire. She is the first of three children born to Jacqueline Doreen (née Cannon), a former insurance clerk and hairdresser, and Anthony William Adams, who worked as an electronics engineer. They founded an electronics wholesale business which allowed a comfortable upbringing for Victoria and her sister Louise and brother Christian Adams.
In 1980, she watched the musical film "Fame" and subsequently made the decision to pursue a musical career. Jacqueline and Anthony Adams enrolled her at Jason Theatre School. In 1991, Beckham entered Laine Theatre Arts in Epsom, Surrey and studied dance and modelling. Beckham attended St. Mary's High School in Cheshunt, where she was embarrassed by her family's wealth and often begged her father not to drop her off outside the school in their Rolls Royce. Eventually, she became a member of a band called Persuasion.
Fashion career.
Beckham made a guest appearance on the catwalk for Maria Grachvogel in 2000, marking her debut as a model at London Fashion Week. Beckham also acted as a British ambassador for Dolce and Gabbana and was briefly the face of Rocawear in 2003. Beckham designed a limited-edition fashion line for Rock & Republic called VB Rocks in 2004, consisting mainly of jeans for the high end of the market, retailing at approximately $300 in the US.
On 16 January 2006, Beckham walked the runway for Roberto Cavalli at Milan Fashion Week, and was for a period exclusively dressed by him for red-carpet and social events. For the March 2006 issue of "Harper's Bazaar", Beckham acted as fashion editor when she styled her close friend, Katie Holmes, for a fashion shoot. She has admitted to a personal love of sunglasses, saying "I'm quite obsessed with sunglasses. I collect vintage Guccis and Carreras – they can make virtually any outfit look cool." After Beckham's departure from Rock & Republic, in September 2006, she furthered her fashion ventures by launching her own denim label, dvb Style. Beckham then launched a new official website, dvbstyle.com to promote her fashion work.
On 14 June 2007, Beckham launched dvb Denim collection in New York at Saks Fifth Avenue, along with unveiling her eyewear range in the United States for the first time. In the same month, Beckham made her first appearance at London's annual Graduate Fashion Week as a judge alongside Glenda Bailey (editor-in-chief of "Harper's Bazaar") and Lanvin's Alber Elbaz, to choose the winner of the River Island Gold Award, worth £20,000. In August 2007, Intimately Beckham perfume was launched into US stores, one of more than 20 perfumes she and David Beckham have introduced over the years. In September 2007 her cosmetics line V-Sculpt was launched in Tokyo. In a 2007 appearance at an LA Galaxy press conference, Beckham is credited with having popularised Roland Mouret's 'moon dress' and his brand, and Beckham was also the face of Marc Jacobs for his Spring 2008 collection.
Beckham has been on many magazine covers during her career, including "I-D" in 2004 and "W" in 2007. Her first "Vogue" appearance was the April 2008 British edition. This was followed by the Indian and Russian editions of the magazine.
Launch of fashion label.
Beckham's eponymous label was launched in September 2008 in a low-key presentation. By 2011, it had grown into a fixture of New York Fashion Week and a lower-priced Victoria by Victoria Beckham label was introduced. In the first quarter of 2011-12, it was predicted to generate annual sales of more than £60 million. Known initially for its dresses, the range has expanded into separates and luxury handbags selling at up to £18,000. Alongside the main fashion line and diffusion range, the Victoria Beckham brand still includes separate denim, eyeware and fragrance lines. In November 2011, Victoria Beckham won Designer Brand of the Year at the British Fashion Awards.
In September 2012, Victoria Beckham was the most talked about designer on Twitter during New York Fashion Week, also acquiring 57,000 new followers during the shows according to research by The Whispr Group.
Writing in "The Independent" in February 2014, Alexander Fury described how Victoria Beckham had made the transition from novelty to respected designer, citing her recent guest editorship of French "Vogue" and forthcoming participation in a panel discussion with the dean of Parsons design school in New York. The article concluded that the brand's sales were down to the appeal of the designs themselves, not the celebrity association.
Music career.
1994–2000: Spice Girls.
Beckham auditioned for a March 1993 advertisement in "The Stage" which required girls who were "street smart, extrovert, ambitious and able to sing and dance". In 1994, Beckham joined the all-female group, the Spice Girls. In the recordings before her marriage, she is credited with her maiden name as Victoria Adams. The group's first single was called "Wannabe" (1996), and she worked alongside Geri Halliwell, Emma Bunton, Melanie Brown and Melanie Chisholm. It went to number one in the United Kingdom and United States, and another 29 countries. It was followed by nine further number one singles from their albums "Spice", "Spiceworld" and "Forever". Each member of the group received a nickname from the media. Beckham was named "Posh Spice". The group was one of the most successful pop acts of the 1990s, selling over fifty-five million records worldwide. After the release of their third album, "Forever", which charted at number two in the UK, was far less successful than their previous two albums, and the Spice Girls stopped recording, concentrating concentrated on their solo careers in regards to their foreseeable future.
2000–02: "Victoria Beckham".
On 14 August 2000, Beckham released her first solo single, "Out of Your Mind" in collaboration with Dane Bowers and Truesteppers. The week of release coincided with the release of "Groovejet (If This Ain't Love)" by Spiller featuring Sophie Ellis-Bextor, resulting in a chart battle dubbed 'Posh vs. Posher' by the tabloids. Before the single's release, on 8 July 2000, Beckham made her public solo debut at London's Hyde Park at a concert to raise money for the Prince's Trust charity. She sang "Out of Your Mind" to a 100,000-strong audience. Beckham then signed a recording contract with her group label Virgin Records. Her next single as a solo artist, "Not Such An Innocent Girl", was released on 17 September 2001. Again, she faced competition in another hugely hyped chart battle, this time with Kylie Minogue's single "Can't Get You Out of My Head". Despite a huge promotional campaign, Beckham was outsold eight to one, and her single debuted at number 6. Beckham's eponymous debut album, which was released on 1 October 2001, reached Number 10 in the UK album chart. The album cost a reputed £5 million to produce and it sold a modest 50,000 copies.
The second and final single to be released from the album was "A Mind of Its Own" on 11 February 2002. The single reached number 6 in the UK and sold 56,500 copies. Rumours soon spread that Beckham was to be dropped by her label for not charting in the Top Three. These were strongly refuted at the time. Beckham commented "You know what newspapers are like, they just like to put all the negative stuff in, but as far as I'm concerned and the record company is concerned it is all great." A third single, "I Wish", was promoted but never materialised. The single version was a remix featuring Robbie Craig, and was performed on TV on "Friday Night's All Wright". Following the announcement of Beckham's second pregnancy, the single was shelved. Beckham was reportedly dropped by Virgin Records along with fellow Spice Girls Emma Bunton and Melanie B,; but a statement from her publicist denied reports, stating: "No-one has been dropped. The Virgin deal has come to a natural end and both parties have decided not to continue."
2002–04: Unreleased albums and end of solo career.
In 2002, Beckham signed a contract with Telstar Records and 19 Management worth £1.5 million. Beckham then began recording a pop-influenced album, "Open Your Eyes", which yielded the single "Let Your Head Go", but she allegedly chose not to release it after being disappointed with the results. Instead of pop, Beckham wanted a more urban sound and worked with urban producer Damon Dash to work on the R&B and hip hop influenced album "Come Together". When Dash was first asked why he recorded with Beckham, he stated: "Because I see how much she gets photographed over here." A Dash-produced track "It's That Simple" featuring M.O.P. premiered on radio stations in July 2003, generating mixed reviews. Beckham's first single with Telstar, "Let Your Head Go" / "This Groove", was released in the UK on 29 December 2003, following heavy promotion and many TV appearances across the Christmas period with the video being directed by Andy Hylton. The single charted at number three in the UK. This double A-side lifted "Let Your Head Go" from Beckham's earlier pop-inspired work with "This Groove" one of her hip hop and R&B songs and remains Beckham's last single release to date. Outside of the UK, Damon Dash had plans for Beckham in the US, including a potential release of "Let Your Head Go / This Groove" under the name of "Posh Spice Victoria Beckham". The release was proposed for sometime between March to May 2004, but never eventuated.
With the UK media describing her solo music career a failure, combined with a rumoured fall-out between Dash and Fuller, her hip hop album, "Come Together", was not released. Beckham's final attempt at a solo career came with the announcement of a new single "My Love Is for Real", in which she switched back from urban music to pop. She was dismissed from Telstar when the company became bankrupt, and gave up music to focus her fashion career.
2007–12: Return of the Spice Girls.
In 2007, the Spice Girls reformed and announced plans to embark upon a reunion tour, from which they were said to have earned £10 million each (approximately $20 million). Victoria had previously stated that she and her former Spice colleagues were enjoying their solo careers in various fields, saying "We're all still doing our own thing." Their "Greatest Hits" album was released in early November 2007 and the tour began on 2 December 2007. At its advent, Beckham said "I wanted my children to see that Mummy was a pop star. It was the last opportunity for them to stand in a crowd full of people screaming for the Spice Girls." When Beckham had her hair coloured brown for the tour, she stated that her sons immediately reacted by saying "Oh my goodness, it's Posh Spice. She's back." She was the only member of the group not to sing a solo song on the tour, instead posing in the style of a fashion show on a makeshift catwalk, whereas the others each performed a number from their solo careers.
Film-maker Bob Smeaton directed an official film of the tour titled "Spice Girls: Giving You Everything", which was first aired on Fox8 in Australia. It later aired in the UK on 31 December 2007 on BBC One. As well as their sell-out tour, the Spice Girls were contracted to appear in Tesco advertisements, for which they were paid £1 million each.
In October 2009, reports suggested that the Spice Girls were to star in a reality show in which they would cast female actors to play their roles in a musical. The following year, Judy Craymer teamed up with the Spice Girls and Simon Fuller to start developing a Spice Girls musical titled "Viva Forever". On 26 June 2012, all five Spice Girls were in attendance at a press conference in London to promote the launch of Viva Forever: The Musical. The musical is due to open at the West End's Piccadilly Theatre on 11 December 2012. On 12 August 2012, after much speculation, Beckham and the Spice Girls performed a medley of "Wannabe" and "Spice Up Your Life" at the 2012 Summer Olympics closing ceremony, reuniting solely for the event. Their performance was the most tweeted moment of Olympics closing ceremony with over 116,000 tweets on Twitter per minute.
Television.
Beckham has shot five official documentaries. The first, dated 11 January 2000, was called "Victoria's Secrets", a programme only shown in the UK on Channel 4. It involved Beckham being followed by cameras while also discussing and interviewing other British celebrities, such as Elton John.
The second, "Being Victoria Beckham", was broadcast in March 2002 and saw Beckham discussing her career as a solo artist with the release of her first album, and also showed her at various photo shoots and recording sessions. The documentary attracted a strong audience of 8.83 million, coming top in its timeslot. One critic described her as "so clearly level-headed, happy with her not inconsiderable lot and seemingly unfazed by the madly intrusive nature of her monumentally ridiculous fame". The third, "The Real Beckhams", aired on 24 December 2003 on ITV1 and focused on the Beckhams' move to Madrid from London after David Beckham was signed to Real Madrid. It also featured Victoria Beckham re-launching her solo career and showed her mocking the tabloid stories she reads in the paper every day. The special received an audience of 6.10 million viewers and was later released on DVD on 2 February 2004.
The fourth was titled "Full Length & Fabulous: The Beckhams' 2006 World Cup Party", and followed Victoria and David Beckham organising and making preparations to host a 2006 World Cup Party at a marquee in the grounds of their mansion in Hertfordshire, which aimed to raise money for their charity. Two tickets to attend the ball were auctioned on-line for charity, and sold for £103,000. The documentary aired on 28 May 2006 and showed the event itself, where the menu was designed especially by friend and chef Gordon Ramsay and the charity auction was hosted by Graham Norton. Ramsay catered for 600 guests, with the aid of 40 chefs and 100 waiting staff. The ITV documentary attracted an average of 7.56 million viewers.
To document Victoria Beckham's preparations for her family's move to the US, she signed a deal with NBC for six episodes of a half-hour unscripted reality TV series. Despite original plans for six episodes, the show was cut to a one-hour special only as there "just wasn't enough (material) for a series." The show, called "", aired on 16 July 2007 in the US and Canada. It was heavily scrutinised by the American media and critics, with "The New York Post" describing it as "an orgy of self-indulgence" and also describing Beckham as "vapid and condescending". The programme was the third-most-watched programme in its time-slot and received viewing figures of 4.9 million in the US, beaten by a repeat of "Wife Swap" and two sitcoms. The programme aired in Britain on 17 July 2007 on ITV with 3.84 million viewers tuning in. The programme was produced by Simon Fuller who managed her and the Spice Girls on their come-back tour.
In July 2007, it was announced that Beckham would shortly begin filming a cameo appearance as herself in an episode of the second season of ABC's TV series "Ugly Betty". The episode, "A Nice Day for a Posh Wedding", aired on 9 November 2007 in the United States and on 23 November in the United Kingdom. Despite her forays into television, Beckham has denied plans to embark upon a Hollywood movie career. In February 2008, it was revealed that Beckham would be the guest judge for the finale of fourth season of "Project Runway", which aired on 5 March 2008 in the US.
It was reported in October 2007 that Beckham had turned down the opportunity to appear in "". She stated in an interview: "[I was] asked to be in the "Sex and the City" film, which I would have loved to have done, but because I am in full-on Spice Girls rehearsal mode, unfortunately, I can't do it."
Books.
On 13 September 2001, Beckham released her first book, "Learning to Fly". The title was taken from a line in a song from the musical "Fame", which Beckham had enjoyed as a child. The verse that inspired the title was: "I'm gonna live forever, I'm gonna learn how to fly". The autobiography documents her childhood, time during the Spice Girls, her marriage and family life, as well as her career at the time. She describes her eating disorder associated with the need to be slim. "Learning to Fly" became the third best-selling non-fiction title of 2001 and the total UK sales stand at more than 500,000 copies. When the book was first released, it went to Number 1 in the book charts after four weeks of release, relegating Robbie Williams' book to second place. A high-profile guest appearance on "Parkinson", watched by nine million people, helped to promote the book. "Hello!", "The Daily Mail" and "The Mail on Sunday" joined to buy the rights to preview and serialise the book before its publication. The figure paid was thought to be near £1 million.
Beckham was quoted by a Spanish journalist in 2005 as saying: "I've never read a book in my life". She later explained this was a mistranslation from the original Spanish in which the interview was printed, saying she actually stated that she never had time to finish reading a book because she was always too busy looking after her children.
Beckham's second book, a fashion advice guide titled "That Extra Half an Inch: Hair, Heels and Everything in Between", was published on 27 October 2006. "That Extra Half an Inch: Hair, Heels and Everything in Between" includes tips from Beckham on fashion, style and beauty, and also contains photography by Mario Testino, Annie Leibovitz and Steven Meisel. The book became another best-seller, and has sold 400,000 copies in Britain alone since it was published in hardcover. The rights have since been sold to the United States, the Netherlands, Japan, Portugal, Lithuania, Russia, and most recently China.
Power and influence.
In 2007, it was reported that Beckham was the 52nd richest woman in Britain and the 19th richest person in Britain with husband David, with an estimated joint wealth of £112 million ($225 million). According to "The Guardian", Beckham Ventures, a company linked to the Victoria Beckham fashion business, was the best performing brand in the family's three businesses in 2012, coming close to matching turnover in a sister company that promotes the David Beckham brand.
In 2010, Beckhams's charity work with Save the Children earned her a nomination for the Do Something With Style Award, an awards show, produced by VH1. She is a patron of the Elton John AIDS Foundation. Beckham promotes faux/synthetic furs. Her stand against the fur industry generated praise from animal rights organisations, including PETA. Beckham has stated that she is "supportive of its [PETA's] high-profile anti-fur campaigns," and pledged "never to work with fur in any of her own fashion collections". In February 2013, she was assessed as one of the 100 most powerful women in the UK in the fashion category by "Woman's Hour" on BBC Radio 4.
In 2014 Beckham joined the Ban Bossy campaign as a spokesperson advocating leadership roles for girls.
Personal life.
Beckham began a relationship with Corey Haim in 1995, which ended on mutual terms.
In 1997, she started dating footballer David Beckham after they met at a charity football match, prompting him to request a meeting with her. Of their initial meeting, she said, "I didn't really know who he was. I was never into football." The couple announced their engagement in 1998 and were dubbed "Posh and Becks" by the media.
Marriage.
On 4 July 1999 they were married by the Bishop of Cork, Paul Colton, at Luttrellstown Castle, Ireland. The wedding attracted much media coverage. Beckham's team-mate, Gary Neville, was the best man, and the couple's four-month-old son Brooklyn was the ring bearer. Most of the media were kept away from the ceremony as an exclusive deal with "OK!" magazine had been arranged, but photographs were released showing the Beckhams sitting on golden thrones. Victoria wore a diamond coronet created for her by jewellery designer Slim Barrett. A total of 437 staff were employed for the wedding reception, which was estimated to have cost £500,000 (US$823,650).
The couple bought what became their most famous home for £2.5 million in 1999; the property, which is set in 24 acre of land, was given a £3 million renovation and was subsequently dubbed Beckingham Palace by the media.
Children.
Victoria and David Beckham have four children: sons Brooklyn Joseph (born 4 March 1999, Westminster, London), Romeo James (born 1 September 2002, Westminster, London), Cruz David (born 20 February 2005, Madrid, Spain); and daughter Harper Seven (born 10 July 2011, Los Angeles). Elton John and David Furnish are reportedly the godparents of Brooklyn and Romeo, and their godmother is Elizabeth Hurley.
Alleged kidnap and death threats.
In January 2000, a tip-off to Scotland Yard detectives exposed a plot to kidnap Victoria and Brooklyn Beckham and hold them at a house in Hampstead, London. The family was then moved to a secret location, but no arrests were made. Later in March 2000, she received a death threat prior to performing at the Brit Awards with the Spice Girls, and in the show's rehearsal, a red laser light appeared on her chest and she was rushed off stage. After a fire door was found to be lodged open, it was thought that there had been an assassin there, and Beckham later revealed that she was terrified by the experience. In November 2002, five people were arrested after another plot for her kidnap was infiltrated by a tabloid newspaper. All charges were dropped after a witness was deemed unreliable.

</doc>
<doc id="45985" url="http://en.wikipedia.org/wiki?curid=45985" title="George Michael">
George Michael

Georgios Kyriacos Panayiotou (born 25 June 1963), widely known by his stage name George Michael, is an English singer, songwriter, multi-instrumentalist and record producer. Michael rose to superstardom during the 1980s and 1990s with his style of post-disco dance-pop. He has also been characterised as a blue-eyed soul singer, although his material draws more from middle-of-the-road pop than soul music.
As one of the world's best-selling music artists, Michael has sold more than 100 million records worldwide as of 2010. His 1987 debut solo album, "Faith", has sold more than 20 million copies worldwide and made several records and achievements in the United States. Michael has garnered seven number one singles in the UK and eight number one hits on the "Billboard" Hot 100 in the US. In 2008, "Billboard" magazine ranked Michael the 40th most successful artist on the "Billboard" Hot 100 Top All-Time Artists list.
Michael has won numerous music awards throughout his 30-year career, including three Brit Awards—winning Best British Male twice, four MTV Video Music Awards, four Ivor Novello Awards, three American Music Awards, and two Grammy Awards from eight nominations.
In 2004, the Radio Academy named Michael as the most played artist on British radio between the period of 1984–2004. The documentary "A Different Story" was released in 2005; it covered his personal life and professional career. In 2006, George Michael announced his first tour in 15 years, the worldwide 25 Live tour, spanning three individual tours over the course of three years (2006, 2007 and 2008).
Early life.
Michael was born Georgios Kyriacos Panayiotou (Greek: Γεώργιος Κυριάκος Παναγιώτου) in East Finchley, North London. His father, Kyriacos Panayiotou, a Cypriot restaurateur, moved to England in the 1950s and changed his name to Jack Panos. Michael's mother, Lesley Angold (née Harrison, 1937–1997), was an English dancer. Michael spent the majority of his childhood in Kingsbury, North West London, in the home his parents bought soon after his birth, where he attended Kingsbury High School. While in his early teens, the family moved to Radlett, Hertfordshire. There Michael attended the Bushey Meads School in the neighbouring town of Bushey, where he met Andrew Ridgeley. The two had the same career ambition of being musicians. Michael would busk on the London Underground, performing songs such as "'39" by Queen.
His involvement in the music business began with his working as a DJ, playing at clubs and local schools around Bushey, Stanmore and Watford. This was followed by the formation of a short-lived ska band called The Executive with Ridgeley, Ridgeley's brother Paul, Andrew Leaver, and David Mortimer (aka David Austin).
Musical career.
1981–1986: Wham!
Michael first found success after forming the duo Wham! with Andrew Ridgeley in 1981. The band's first album "Fantastic" reached No. 1 in the UK in 1983 and produced a series of top 10 singles including "Young Guns", "Wham Rap!" and "Club Tropicana". Their second album, "Make It Big" reached No. 1 on the charts in the US. Singles from that album included "Wake Me Up Before You Go-Go" (No. 1 in the UK and US), "Freedom", "Everything She Wants", and "Careless Whisper" which reached No. 1 in nearly 25 countries, including the UK and US, and was Michael's first solo effort as a single.
Michael sang on the original Band Aid recording of "Do They Know It's Christmas?" (which became the UK Christmas number one) and donated the profits from "Last Christmas/Everything She Wants" to charity. In addition, he contributed background vocals to David Cassidy's 1985 hit "The Last Kiss", as well as Elton John's 1985 successes "Nikita" and "Wrap Her Up". Michael cited Cassidy as a major career influence and interviewed Cassidy for David Litchfield's Ritz Newspaper.
Wham!'s tour of China in April 1985, the first visit to China by a Western popular music act, generated worldwide media coverage, much of it centred on Michael. Before Wham!'s appearance in China, many kinds of music in the country were forbidden. The audience included members of the Chinese government, and Chinese television presenter, Kan Lijun, who was the on stage host, spoke of Wham!'s historic performance; "No-one had ever seen anything like that before. All the young people were amazed and everybody was tapping their feet. Of course the police weren't happy and they were scared there would be riots." The tour was documented by film director Lindsay Anderson and producer Martin Lewis in their film "Foreign Skies: Wham! In China".
With the success of Michael's solo singles, "Careless Whisper" (1984) and "A Different Corner" (1986), rumours of an impending break up of Wham! intensified. The duo officially separated during the summer of 1986, after releasing a farewell single, "The Edge of Heaven" and a singles compilation, "The Final", plus a sell-out concert at Wembley Stadium that included the world premiere of the China film. The Wham! partnership ended officially with the commercially successful single "The Edge of Heaven", which reached No. 1 on the UK chart in June 1986.
Solo career.
The beginning of his solo career, during early 1987, was a duet with Aretha Franklin. "I Knew You Were Waiting" was a one-off project that helped Michael achieve an ambition by singing with one of his favourite artists, and it scored number one on both the UK Singles Chart and the US "Billboard" Hot 100 upon its release.
For Michael, it became his third consecutive solo number one in the UK from three releases, after 1984's "Careless Whisper" (though the single was actually from the Wham! album "Make It Big") and 1986's "A Different Corner". The single was also the first Michael had recorded as a solo artist which he had not written himself. The co-writer, Simon Climie, was unknown at the time, although he would have success as a performer with the band Climie Fisher in 1988.
Michael and Aretha Franklin won a Grammy Award in 1988 for Best R&B Performance – Duo or Group with Vocal for the song.
1987–1989: "Faith".
During the autumn of 1987, Michael released his first solo album, "Faith". In addition to playing a large number of instruments on the album, he wrote and produced every track on the recording, except for one, which he co-wrote.
The first single released from the album was "I Want Your Sex", during the summer of 1987. The song was banned by many radio stations in the UK and US, due to its sexually suggestive lyrics. MTV would broadcast the video, featuring celebrity make-up artist Kathy Jeung in a basque and suspenders, only during the late night hours. Michael argued that the act was beautiful if the sex was monogamous. Michael even recorded a brief prologue for the video in which he said: "This song is not about casual sex." One of the racier scenes involved Michael writing the words "explore monogamy" on his partner's back in lipstick. Some radio stations played a toned-down version of the song, "I Want Your Love," which was mainly the word "love" replacing "sex."<ref name="sex/love"> Total 80s Remix, 22 February 1999. Retrieved 21 April 2011.</ref>
When "I Want Your Sex" reached the US charts, "American Top 40" host Casey Kasem refused to say the song's title, referring to it only as "the new single by George Michael." In the US, the song was also sometimes listed as "I Want Your Sex (from "Beverly Hills Cop II")", since the song was featured on the soundtrack of the movie. Despite censorship and radio play problems, "I Want Your Sex" reached No. 2 on the US "Billboard" Hot 100 and No. 3 in the UK.
The second single, "Faith", was released during October 1987, just a few weeks before the album. "Faith" would become one of his most popular songs. The song hit No. 1 on the "Billboard" Hot 100 in the US and maintained that position for four consecutive weeks. It also reached No. 2 in the UK Singles Chart. The famous video provided some definitive images of the 1980s music industry in the process—Michael in shades, leather jacket, cowboy boots, and Levi's jeans, playing a guitar near a classic-design jukebox.
On 30 October, "Faith" was released in the UK and in several markets worldwide. In the United States, the album had 51 non-consecutive weeks in the top 10 of "Billboard" 200, including 12 weeks at No. 1. "Faith" had many successes, with four singles ("Faith", "Father Figure", "One More Try", and "Monkey") reaching No. 1 in the US. "Faith" was certified Diamond by the RIAA for sales of 10 million copies in the US. To date, global sales of "Faith" are more than 25 million units. The album was highly acclaimed by music critics, with AllMusic journalist Steve Huey describing "Faith" as a "superbly crafted mainstream pop/rock masterpiece" and "one of the finest pop albums of the '80s". In a review by "Rolling Stone" magazine, journalist Mark Coleman commended most of the songs on the album, which he said "displays Michael's intuitive understanding of pop music and his increasingly intelligent use of his power to communicate to an ever-growing audience."
In 1988, Michael embarked on a world tour. The nightly set list included from the Wham! era "Everything She Wants" and "I'm Your Man", as well as covers of "Lady Marmalade" or "Play That Funky Music". In Los Angeles, Michael was joined on stage by Aretha Franklin for "I Knew You Were Waiting". It was the second highest grossing event of 1988, earning $17.7 million. In February 1989, "Faith" won the Grammy Award for Album of the Year at the 31st Grammy Awards. At the 1989 MTV Video Music Awards on 6 September in Los Angeles, Michael received the Video Vanguard Award.
According to Michael in his film, "A Different Story", success did not make him happy and he started to think there was something wrong in being an idol for millions of teenage girls. The whole "Faith" process (promotion, videos, tour, awards) left him exhausted, lonely and frustrated, and far from his friends and family. In 1990, he told his record company Sony that, for his second album, he did not want to do promotions like the one for "Faith".
1990–1992: "Listen Without Prejudice".
"Listen Without Prejudice Vol. 1" was released in September 1990. For this album, Michael tried to create a new reputation as a serious-minded artist; the title is an indication of his desire to be taken more seriously as a songwriter. Michael refused to make any kind of promotion for this album, including no music videos for the singles released. The first single, "Praying for Time", with lyrics concerning social ills and injustice, was released in August 1990 to critical acclaim. James Hunter of "Rolling Stone" magazine described the song as "a distraught look at the world's astounding woundedness. Michael offers the healing passage of time as the only balm for physical and emotional hunger, poverty, hypocrisy and hatred." The song was an instant success, reaching No. 1 on the US "Billboard" Hot 100 and No. 6 in the UK despite the absence of a video. A video was released shortly thereafter, consisting of the lyrics on a dark background. Michael did not appear in this video or any subsequent videos for the album.
The second single "Waiting for That Day" was an acoustic-heavy single, released as an immediate follow-up to "Praying For Time". It reached No. 23 in the UK and No. 27 in the US. in October 1990. The album was released in Europe on 3 September 1990 (and one week later in the United States). It reached No. 1 in the UK Albums Chart and peaked at No. 2 on the US "Billboard" 200. It spent a total of 88 weeks on the UK Albums Chart and was certified 4 times Platinum by the BPI. The album produced 5 UK singles, which were released quickly, within an at eight-month period: "Praying for Time", "Waiting for That Day", "Freedom! '90", "Heal the Pain", and "Cowboys and Angels" (the latter being his only single not to chart in the UK top 40).
"Freedom '90" was the second of only two of its singles to be supported by a music video (the other being the Michael-less "Praying for Time"). The song alludes to his struggles with his artistic identity, and prophesied his efforts shortly thereafter to end his recording contract with Sony Music. As if to prove the song's sentiment, Michael refused to appear in the video (directed by David Fincher), and instead recruited supermodels Naomi Campbell, Linda Evangelista, Christy Turlington, Tatjana Patitz, and Cindy Crawford to appear in and lip sync in his stead. It also featured the reduction of his sex symbol status. It had contrasting fortunes on each side of the Atlantic—a No. 8 success on the "Billboard" Hot 100 in the US, but only No. 28 on the UK Singles Chart.
"Mother's Pride" gained significant radio play in the US during the first Persian Gulf War during 1991, often with radio stations mixing in callers' tributes to soldiers with the music. It reached No. 46 on "Billboard" Hot 100 with only airplay. In the end, "Listen Without Prejudice Vol. 1" sold approximately 8 million copies.
At the 1991 Brit Awards, "Listen Without Prejudice Vol. 1" won the award for Best British Album. Later in 1991, Michael embarked on the "Cover to Cover tour" in Japan, England, the US, and Brazil, where he performed at "Rock in Rio". In the audience in Rio, he saw and later met Anselmo Feleppa, the man who would become his partner. The tour was not a proper promotion for "Listen Without Prejudice Vol. 1". Rather, it was more about Michael singing his favourite cover songs. Among his favourites was "Don't Let the Sun Go Down on Me", a 1974 song by Elton John; Michael and John had performed the song together at the Live Aid concert in 1985, and again for Michael's concert at London's Wembley Arena on 25 March 1991, where the duet was recorded. The single was released at the end of 1991 and reached No. 1 in both the UK and US.
In the meantime, the expected follow-up album, "Listen Without Prejudice Vol. 2", was scrapped due to Michael's lawsuit with Sony. Among Michael's complaints was that Sony had not completely supported the release of his second album, resulting in its poor performance in the US as compared to "Faith". Sony responded that Michael's refusal to appear in promotional videos had caused the bad response. Michael ended the idea for "Listen Without Prejudice Vol. 2" and donated three songs to the charity project "Red Hot + Dance", for the Red Hot Organization which raised money for AIDS awareness, while a fourth track "Crazyman Dance" was the B-side of 1992's "Too Funky". Michael donated the royalties from "Too Funky" to the same cause.
"Too Funky" was a commercial success, reaching No. 4 in the UK singles chart and No. 10 in the US "Billboard" Hot 100. It did not appear on any George Michael studio album, although later it was included on his solo collections "" in 1998 and "Twenty Five" in 2006. The video featured Michael (sporadically) as a director filming supermodels Linda Evangelista, Beverly Peele, Tyra Banks, Estelle Lefébure and Nadja Auermann at a fashion show.
1993: "Five Live".
"George Michael was the best. There's a certain note in his voice when he did "Somebody to Love" that was pure Freddie." 
—Queen guitarist Brian May on Michael's performance at the Freddie Mercury Tribute Concert.
George Michael performed at The Freddie Mercury Tribute Concert on 20 April 1992 at London's Wembley Stadium. The concert was a tribute to the life of the late Queen frontman, Freddie Mercury, with the proceeds going to AIDS research. In his last ever radio interview Mercury had praised Michael adding that he loved his track "Faith". Michael performed "'39", "These Are the Days of Our Lives" with Lisa Stansfield and "Somebody to Love". The performance of the latter was released on the "Five Live" EP.
"Five Live", released in 1993 for Parlophone in the UK and Hollywood Records in the US, features five—and in some countries, six—tracks performed by George Michael, Queen, and Lisa Stansfield."Somebody to Love" and "These Are the Days of Our Lives" were recorded at the Freddie Mercury Tribute Concert. "Killer", "Papa Was a Rollin' Stone", and "Calling You" were all live performances recorded during his "Cover to Cover Tour" from 1991. Michael's performance of "Somebody to Love" was hailed as "one of the best performances of the tribute concert". The idea of having George Michael take over as full-time lead singer of Queen was even given serious consideration.
All proceeds from the sale of the EP benefited the Mercury Phoenix Trust. Sales of the EP were very strong through Europe, where it debuted at number 1 in the UK and several European countries. Chart success in the United States was less spectacular, where it peaked at number 40 on the "Billboard" 200 ("Somebody to Love" reached No.30 on the US "Billboard" Hot 100).
1994–1997: "Older".
During November 1994, after a long period of seclusion, George Michael appeared at the first MTV Europe Music Awards show, where he gave a performance of a brand-new song, "Jesus to a Child". The song was a melancholy tribute to his lover, Anselmo Feleppa, who had died in March 1993.
The song was Michael's first self-penned success in his homeland in almost four years; it entered the UK singles chart at No. 1 and No. 7 on "Billboard" in the same month of release. It was also Michael's longest UK Top 40 single, at almost seven minutes long. The exact identity of the song's subject—and the nature of Michael's relationship with Feleppa—was shrouded in innuendo and speculation, as Michael had not confirmed he was homosexual and did not do so until 1998. The video for "Jesus to a Child" was a picture of images recalling loss, pain and suffering. Michael consistently dedicates the song to Feleppa before performing it live.
The second single, released in April 1996, was "Fastlove", an energetic tune about wanting gratification and fulfilment without commitment. The song was somewhat unusual for a popular song, in that it did not have a defined chorus and that the single version was nearly five minutes long. "Fastlove" was supported by a futuristic virtual reality-related video. It scored No. 1 in the UK singles chart, spending three weeks at the top spot. In the US, "Fastlove" peaked at No. 8, his most recent single to reach the top 10 on the US charts. Following "Fastlove", Michael finally released "Older", his first studio album in six years and only the third in his ten-year solo career. The album's US and Canada release was particularly notable as it was the first album released by David Geffen's (now-defunct) DreamWorks Records.
Older was particularly notable for the release of its six singles. Each of them reached the UK Top 3, a record for the most singles in the British Top 3 released from a single album. At the time of release of the album's fifth single, "Star People '97", chart specialist James Masterton noted George Michael's success on the singles charts, writing: "George Michael nonetheless makes an impressive Top 3 entry with this single. The Older album has now proved itself to be far and away his most commercially successful recording ever. Five singles now lifted and every single one has been a Top 3 hit. Compare this with the two Top 3 hits produced by "Faith" and "Listen Without Prejudice's" scant total of one Top Tenner and one single which missed the Top 40 altogether. This sustained single success has, of course, been achieved with a little help from marketing tricks such as remixes – or in this case a new recording of the album track which gives it a much-needed transformation into a deserved commercial smash."
In 1996, Michael was voted Best British Male, at the MTV Europe Music Awards and the Brit Awards; and at the British Academy's Ivor Novello Awards, he was awarded the prestigious title of 'Songwriter of The Year' for the third time. Michael performed a concert at Three Mills Studios, London, for "MTV Unplugged". It was his first long performance in years, and in the audience was Michael's mother. The next year, she died of cancer.
1998: "Ladies & Gentlemen: The Best of George Michael".
"Ladies & Gentlemen: The Best of George Michael" was Michael's first solo greatest hits collection released in 1998. The collection of 28 songs (29 songs are included on the European and Australian release) are separated into two halves, with each containing a particular theme and mood. The first CD, titled "For the Heart", predominantly contains Michael's successful ballads, while the second CD, "For the Feet", consists mainly of his popular dance tunes. It was released through Sony Music Entertainment as a condition of severing contractual ties with the label.
The album is notable for containing a large number of compilation tracks and duets that had not previously appeared on his albums, including his duet with Aretha Franklin, "I Knew You Were Waiting (For Me)"; "Desafinado", a duet in Portuguese with Brazilian legendary singer Astrud Gilberto; and the Elton John duet "Don't Let the Sun Go Down on Me".
"Ladies & Gentlemen" was an instant success, peaking at number one on the UK Albums Chart for 8 weeks. It has spent over 200 weeks in the UK Charts, and it is the 38th best-selling album of all time in the UK. It is certified 7 times platinum in the United Kingdom and Multi-Platinum in the United States, and it's George Michael's most commercially successful album in his homeland having sold more than 2.8 million copies. To date, the album has reached worldwide sales of approximately 15 million copies.
The first single of the album, "Outside" was a humorous song about his arrest for soliciting a policeman in a public restroom. "As", his duet with Mary J. Blige, was released as the second single in many territories around the world. Both singles reached the top 5 in the UK Singles Chart.
1999: "Songs from the Last Century".
"Songs from the Last Century" is a studio album of cover tracks. It was released in 1999 and was the final George Michael album to be released through Virgin Records. To date, the album has peaked the lowest of his solo effort. The album debuted at number 157 on the American "Billboard" 200 albums chart, which was also the album's peak position. It was also his lowest-charting album in the UK, becoming his only solo effort not to reach number 1. It peaked at number 2 in the UK Albums Chart. It consists of old standards, plus new interpretations of more recent popular songs such as "Roxanne", "The First Time Ever I Saw Your Face"; and the Frank Sinatra classic "Where or When". Each of the 11 tracks was co-produced by Phil Ramone and George Michael.
2000–2005: "Patience".
In 2000, Michael worked on the hit single "If I Told You That" with Whitney Houston, a song which was meant to feature Michael Jackson, initially. Michael co-produced on the single along with American producer Rodney Jerkins. It was also Michael's second consecutive duet.
Michael began working on what would be his fifth studio album, spending two years in the recording studio. His first single "Freeek!", taken from the new album, was successful in Europe going to number one in Italy, Portugal, Spain and Denmark in 2002 and reaching the top 10 in the UK and the top 5 in Australia. It made 22 charts around the world. However, his next single "Shoot the Dog" proved to be highly controversial when released in July 2002. It was highly critical of George W. Bush and Tony Blair in the leadup to the 2003 invasion of Iraq. It reached number one in Denmark and made the top 5 in most European charts. However, in Britain it peaked at only number 12 in the UK Singles Chart.
In February 2003 George Michael unexpectedly recorded another song in protest against the looming Iraq war, Don McLean's The Grave. The original was written by McLean in 1971 and was a protest against the Vietnam War. Michael performed the song on numerous top rated TV shows including "Top of the Pops" and "So Graham Norton". The video featured extensively on MTV. It was released as part of the War Child charity album "Hope". Michael also performed the song on long-running British chart show "Top of the Pops" on BBC Television on 7 March 2003, introduced by the writer and stand-up comedian (and fan of George Michael) Ben Elton. It was Michael's first appearance on the show since 1986, when he performed "The Edge of Heaven" as one half of Wham!. He ran into conflict with the show's producers for an anti-war, anti Blair T-shirt worn by some members of his band.
In response, McLean issued a statement, through his website, praising George Michael's recording: "I am proud of George Michael for standing up for life and sanity. I am delighted that he chose a song of mine to express these feelings. We must remember that the Wizard is really a cowardly old man hiding behind a curtain with a loud microphone. It takes courage and a song to pull the curtain open and expose him. Good Luck George."
On 17 November 2003, George Michael re-signed with Sony Music, the company he had left in 1995 after a legal battle. When Michael's fifth studio album, "Patience", was released in 2004, it was critically acclaimed and considered the album of George Michael's comeback to the spotlight in the new millennium. It went straight to number 1 on the UK Albums Chart, and became one of the fastest selling albums in the UK, selling over 200,000 copies in the first week alone. In Australia it reached number 2 on 22 March. It reached the Top 5 on most European charts, and peaked at number 12 in the United States, selling over 500,000 copies to earn a Gold certification from the RIAA. To date the album had sold around 7 million copies worldwide and spawned four (of six) new hit singles.
"Amazing", the third single from the album, became a number one hit in Europe. When Michael appeared on "The Oprah Winfrey Show" on 26 May 2004, to promote the album, he performed "Amazing", along with his classic songs "Father Figure" and "Faith". On the show Michael spoke of his arrest, revealing his homosexuality, and his resumption of public performances. He allowed Oprah's crew inside his home outside of London. The fourth single taken off the album was "Flawless", which used the sample of The Ones' original dance hit "Flawless". It was a dance hit in Europe as well as North America, reaching no.1 on the "Billboard" Hot Dance Club Play and became Michael's last number one single on the United States Dance chart.
In November 2004, Sony released the fifth single – "Round Here". It was the least successful single taken from "Patience" when it stalled the UK charts at no. 32. In 2005, "John and Elvis Are Dead" was released as the sixth and final single from the album; it was released as a download single and was therefore unable to chart in the United Kingdom.
Michael told BBC Radio 1 on 10 March 2004 that future music that he puts out will be available for download, with fans encouraged to make a donation to charity.
2005–2010: "Twenty Five" and concert tours.
"Twenty Five" was George Michael's second greatest hits album, celebrating the 25th anniversary of his music career. Released in November 2006 by Sony BMG, it debuted at no.1 in the UK.
The album contains songs chiefly from George Michael's solo career but also from his earlier days in Wham! It comes in two formats: two CDs or a limited edition three-CD set. The 2-CD set contained 26 tracks, including four recorded with Wham! and three new songs: "An Easier Affair"; "This Is Not Real Love" (a duet with Mutya Buena, formerly of Sugababes, which peaked at No.15 in the UK Charts); and a new version of "Heal the Pain" recorded with Paul McCartney. The limited edition three-CD version contains an additional 14 lesser known tracks, including one from Wham! and another completely new song, "Understand".
"Twenty Five" was released in North America on 1 April 2008 as a 29-song, two-CD set featuring several new songs (including duets with Paul McCartney and Mary J. Blige and a song from the short-lived TV series Eli Stone) in addition to many of Michael's successful songs from both his solo and Wham! career. To commemorate the "Twenty Five" album, George Michael toured North America for the first time in 17 years, playing large venues in major cities including New York, Los Angeles, St. Paul/Minneapolis, Tampa/St. Pete, Chicago and Dallas. The DVD version of "Twenty Five" contains 40 videos on two discs, including seven with Wham!.
During the 2005 Live 8 concert at Hyde Park, London, Michael joined Paul McCartney on stage, harmonising on The Beatles classic "Drive My Car". Michael was one of several remixers commissioned in 1990 to work on dance mixes for Bananarama's "Tripping on Your Love". Bananarama covered "Careless Whisper" for their "Exotica" album in 2001, and the track was also released as a single in France.
In 2006, Michael started his first tour in 15 years, 25 Live. The tour began in Barcelona, Spain, on 23 September and finished in December at Wembley Arena in England. According to his website, the 80-show tour was seen by 1.3 million fans. On 12 May 2007 in Coimbra, Portugal, he began the European "25 Live Stadium Tour 2007", including London and Athens, and ending on 4 August 2007 in Belfast, Northern Ireland. There were 29 tour dates (as of 21 April 2007) across Europe. On 9 June 2007 Michael became the first artist to perform live at the newly renovated Wembley Stadium in London, where he was later fined £130,000 for over-running the programme for 13 minutes.
On 25 March 2008, a third part of the 25 Live Tour was announced for North America. This part included 21 dates in the United States and Canada. This was Michael's first tour of North America in 17 years. Following news of Michael's North American tour, "Twenty Five" was released in North America on 1 April 2008 as a 29-song, 2-CD set featuring several new songs (including duets with Paul McCartney and Mary J. Blige and a song from the short-lived TV series, "Eli Stone") in addition to many of Michael's successful songs from both his solo and Wham! career. In addition, a companion 2-disc DVD of 40 videos was also made available.
Michael made his American acting debut by playing a guardian angel to Jonny Lee Miller's character on "Eli Stone", a TV series that was broadcast in the United States. In addition to performing on the show as himself and as "visions", each episode of the show's first season was named after a song of his. Michael appeared on the 2008 finale show of "American Idol" on 21 May singing "Praying for Time". When asked what he thought Simon will say of his performance, he replied "I think he'll probably tell me I shouldn't have done a George Michael song. He's told plenty of people that in the past, so I think that'd be quite funny." On 1 December, Michael performed in Abu Dhabi in the United Arab Emirates, as part of the 37th National Day Celebrations.
On 25 December 2008, Michael released a new track "December Song" on his website for free. It was hoped that fans who download the song would donate money to charity. Though the song is not available any more on his website, it remains available on file sharing networks and on 29 October 2009 the BBC said that George Michael was to join the race for the UK Christmas number one as a remastered version of "December Song" would go on sale on 13 December. The popularity of the single was boosted by a promotional appearance that Michael made on "The X Factor", where he performed the song with David Austin playing piano.
At the end of 2009, Michael announced, after months of speculation, that he would be performing shows in the Australian cities of Melbourne, Perth and Sydney, his first concerts in Australia since 1988. On 20 February 2010, Michael performed his first show in Perth at the Burswood dome to an audience of 15,000.
On 5 March 2010, Michael confirmed that he would be a guest performer at the Sydney Gay and Lesbian Mardi Gras After Party, where he performed at 1 am, followed by Kelly Rowland at 3 am.
On 2 March 2011, Michael announced the release of his cover version of New Order's 1987 hit "True Faith" in aid of the charity Comic Relief. Michael released a cover of Stevie Wonder's 1972 song, "You and I" on 15 April 2011, as an MP3 gift to Prince William and Catherine Middleton on the occasion of their wedding on 29 April 2011.
Although the MP3 was released for free download, Michael appealed that those who do download the special track that make a contribution to "The Prince William & Miss Catherine Middleton Charitable Gift Fund".
2011–2014: "Symphonica" and concert tours.
On 11 May 2011, the Symphonica Tour was announced. Only European dates were released. The first show on the tour was performed at the Prague State Opera House on 22 August. In October 2011, Michael was announced as one of the final nominees for the Songwriter's Hall of Fame. In November, he had to cancel the remainder of the tour as he became severely ill with pneumonia in Vienna, Austria.
Michael told fans over Twitter in January 2012 that he did not think his vocal cords would be ready for performance "till the summer", and that the tour will probably take place in September of that year, and may include previously unheard songs. In February 2012, two months after leaving hospital, Michael made a surprise appearance at the 2012 Brit Awards at London's O2 Arena, where he received a standing ovation, and presented Adele the award for Best British Album.
On 19 June 2012, George Michael released a single "White Light" in order the celebrate the 30 years since the release of Wham Rap. The single also contains a cover version of "Song to the Siren", and two remixes.
Michael's album "Symphonica" was released on 17 March 2014, and became his 7th solo number one album in the UK, and 9th overall including his Wham! chart-toppers. The album was produced by Phil Ramone (his last production credit) and Michael.
Personal life.
Sexuality.
At the age of 19, Michael told Andrew Ridgeley and close friends that he was bisexual. Michael also told one of his two sisters, but he was advised by friends not to tell his parents about his sexuality. In a 1999 interview with "The Advocate", Michael told the Editor in Chief, Judy Wieder, that it was "falling in love with a man that ended his conflict over bisexuality." "I never had a moral problem with being gay," Michael told Wieder. "I thought I had fallen in love with a woman a couple of times. Then I fell in love with a man, and realized that none of those things had been love."
In 2007, Michael said he had hidden the fact he was gay because of worries over what effect it might have on his mother.
Speaking about his time with Wham! in the 1980s, Michael said: "I used to sleep with women quite a lot in the Wham! days but never felt it could develop into a relationship because I knew that, emotionally, I was a gay man. I didn't want to commit to them but I was attracted to them. Then I became ashamed that I might be using them." In 2009, Michael said: "My depression at the end of Wham! was because I was beginning to realise I was gay, not bisexual."
Relationships.
Michael established a relationship with Anselmo Feleppa, a male Brazilian dress designer, whom he had met at the 1991 concert Rock in Rio. Six months into their relationship, Feleppa discovered that he had HIV. Michael later said: "It was terrifying news. I thought I could have the disease too. I couldn't go through it with my family because I didn't know how to share it with them – they didn't even know I was gay." In 1993, Feleppa died of an AIDS-related brain haemorrhage.
Michael's single "Jesus to a Child" is a tribute to Feleppa (he consistently dedicates it to him before performing it live), as is his 1996 album "Older". In 2008, speaking about the loss of his partner Feleppa, Michael said: "It was a terribly depressing time. It took about three years to grieve, then after that I lost my mother. I felt almost like I was cursed."
In 1996, Michael entered into a long-term relationship with Kenny Goss, a former flight attendant, cheerleader coach and sportswear executive from Dallas. They had homes in Dallas and an £8 million mansion in Highgate, North London. In late November 2005, it was reported that Michael and Goss would register their relationship as a civil partnership in the UK, but because of negative publicity and his upcoming tour, they postponed it to a later date.
On 22 August 2011, the opening night of his Symphonica world tour, Michael announced that he and Goss had split two years earlier. Goss was present at Michael's British sentencing for driving under the influence of marijuana on 14 September 2010.
Anonymous sex.
Questions of Michael's sexual orientation persisted in public until 7 April 1998, when he was arrested for "engaging in a lewd act" in a public restroom of the Will Rogers Memorial Park in Beverly Hills, California. In 2007, Michael said "that hiding his sexuality made him feel 'fraudulent', and his eventual outing, when he was arrested [...] in 1998, was a subconsciously deliberate act."
Michael was arrested by an undercover policeman named Marcelo Rodríguez, in a sting operation using so-called "pretty police." In an MTV interview, Michael stated: "I got followed into the restroom and then this cop—I didn't know it was a cop, obviously—he started playing this game, which I think is called, 'I'll show you mine, you show me yours, and then when you show me yours, I'm going to nick you!"
After pleading "no contest" to the charge, Michael was fined US$810 and sentenced to 80 hours of community service. Soon afterwards, Michael made a video for his single "Outside", which satirised the public toilet incident and featured men dressed as policemen kissing. Rodríguez claimed that this video "mocked" him, and that Michael had slandered him in interviews. In 1999, he brought a US$10 million court case in California against the singer. The court dismissed the case, but an Appellate court reinstated the case on 3 December 2002. The court then ruled Rodríguez, as a public official, could not legally recover damages for emotional distress.
After the incident, Michael became explicit about his sexuality and his relationship with Kenny Goss which began in June 1996.
On 23 July 2006, Michael was again accused of engaging in anonymous public sex, this time at London's Hampstead Heath. The anonymous partner was stated (wrongly, as it turned out) to be 58-year-old Norman Kirtland, an unemployed van driver. Despite stating that he intended to sue both the "News of the World" tabloid who supposedly photographed the incident and Norman Kirtland for slander, Michael stated that he cruises for anonymous sex and that this was not an issue in his relationship with partner Kenny Goss.
Drugs.
On 26 February 2006, Michael was arrested for possession of Class C drugs, an incident that he described as "my own stupid fault, as usual." He was cautioned by the police and released.
Michael was arrested in Cricklewood, North-West London, after motorists reported a car obstructing the road at traffic lights. He pleaded guilty on 8 May 2007 to driving while unfit through drugs. He was banned from driving for two years, and sentenced to community service.
During September 2007, on "Desert Island Discs", he said that his cannabis use was a problem; he wished he could smoke less of it and was constantly trying to do so.
On 19 September 2008, Michael was arrested in a public toilet in the Hampstead Heath area of London for possession of Class A and C drugs. He was taken to the police station and cautioned for controlled substance possession.
On 5 December 2009, in an interview with "The Guardian", Michael explained he had cut back on cannabis and now smokes only 'seven or eight' spliffs per day instead of the 25 he used to smoke.
In the early hours of Sunday 4 July 2010 Michael was returning from the Gay Pride parade. The singer was spotted on CCTV driving into the front of a Snappy Snaps store in Hampstead, North London and was arrested on suspicion of being unfit to drive. On 12 August, London's Metropolitan Police said he was "charged with possession of cannabis and with driving while unfit through drink or drugs". It was reported that Michael had also been taking the prescription medication Amitriptyline.
On 24 August 2010, the singer pleaded guilty at Highbury Corner Magistrates' Court in London after admitting driving under the influence of drugs and on 14 September 2010 at the same court, was sentenced to eight weeks in prison, a fine, and a five-year ban from driving. Michael was released from Highpoint Prison in Suffolk on 11 October 2010, after serving four weeks.
Politics.
"To call us [Wham!] Thatcherite was so simplistic, basically saying that if you've got a deep enough tan and made a bit of money then you've got to be a Thatcherite." 
—Labour voters throughout the 1980s, Michael distanced himself from Thatcher's Conservative Party.
During the reign of Margaret Thatcher as the Conservative Prime Minister of the United Kingdom throughout the 1980s, Michael voted Labour.
Michael wrote "Shoot the Dog", a song critical about the friendly relationship between the British and American governments, in particular Tony Blair and George W. Bush, with their involvement in the Iraq War. Michael voiced his concern about the lack of public consultation in the UK regarding the War on Terror: "On an issue as enormous as the possible bombing of Iraq, how can you represent us when you haven't asked us what we think?".
During 2000, Michael joined Melissa Etheridge, Garth Brooks, Queen Latifah, the Pet Shop Boys, and k.d. lang, to perform in Washington, D.C. as part of 'Equality Rocks' – a concert to benefit the Human Rights Campaign.
In 2007, the £1.45 million piano that John Lennon used to write "Imagine" was sent by Michael around the US on a "peace tour," having it on display at places where violence had taken place, such as Dallas' Dealey Plaza, where US President John. F. Kennedy was shot.
He devoted his 2007 concert in Sofia, Bulgaria, from his "Twenty Five Tour" to the Bulgarian nurses prosecuted in the HIV trial in Libya. On 17 June 2008, Michael said he was thrilled by California's legalisation of same-sex marriage, calling the move "way overdue."
Charity.
In November 1984, Michael joined other British and Irish pop stars of the era and formed Band Aid, singing on the charity song "Do They Know It's Christmas?" for famine relief in Ethiopia. This single became the UK Christmas number one in December 1984, holding Michael's own song, "Last Christmas" by Wham!, at No. 2. "Do They Know It's Christmas?" sold 3.75 million copies in the UK and became the biggest selling single in UK Chart history, a title it held until 1997 when it was overtaken by Elton John's "Candle in the Wind 1997", released in tribute to Princess Diana following her death (Michael would attend Diana's funeral with Elton John). Michael donated the royalties from "Last Christmas" to Band Aid and subsequently sang with Elton John at Live Aid (the Band Aid charity concert) in 1985.
In 1988, George Michael took part in the Nelson Mandela 70th Birthday Tribute at Wembley Stadium in London together with many other singers (such Annie Lennox and Sting), performing "Sexual healing".
In 2003 he paired up with Ronan Keating on the "Who Wants to be a Millionaire?" and won £32,000, after having their original £64,000 winnings halved after missing the £125,000 question.
The proceeds from the single "Don't Let the Sun Go Down on Me" were divided among 10 different charities for children, AIDS and education. He is also a patron of the Elton John AIDS Foundation.
Michael is supporting a campaign to help raise US$32 million (GBP15 million) for terminally ill children.
In early 2011, Michael made You and I, a cover of a Stevie Wonder song, a free download on his website; he did so under the proviso that those that download it make a donation to a charity from those listed.
Assets.
Between the years 2006 and 2008, according to reports, Michael earned £48.5 million ($97 million) from the 25 Live tour alone. He reportedly earns millions more for private concerts that he periodically does, such as for billionaires Vladimir Potanin and Philip Green. According to the "Sunday Times" Rich List 2011 of the wealthiest British musicians, Michael is worth £90 million in currency alone. In July 2014, Michael was revealed to be a celebrity investor in a tax avoidance scheme called Liberty.
Memoirs.
In 1991 Michael released an autobiography titled "Bare" through Penguin Books, which he co-wrote with writer Tony Parsons. The over-200-page book covers various aspects of his life, including details of his relationship with a former girlfriend.
Health troubles.
On 26 October 2011, George Michael cancelled a performance at London's Royal Albert Hall due to a viral infection. On 21 November 2011, a hospital in Vienna admitted Michael after he had complained of chest pains while at a hotel just two hours before his performance at a venue there for his Symphonica Tour. The singer was later confirmed to have suffered from pneumonia and, until 1 December, was in an intensive care unit. While Michael appeared to be "in good spirits" and responded well to treatment following his admittance, hospital officials said on 25 November that his condition had "worsened overnight." This development led to cancellations and postponements of Michael's remaining 2011 performances, which mainly had been scheduled for the United Kingdom.
On 1 December 2011, doctors at the hospital in which George Michael had stayed announced that the singer was "steadily improving" and that he had moved out of the intensive care ward. On 21 December 2011, the hospital discharged Michael. On 23 December 2011, Michael made a public speech outside his house in Highgate, London, in which he stated that the staff at the Vienna General Hospital had saved his life and that he would gratuitously perform a concert specifically for that staff. While making the speech, he became emotional and breathless. During the speech, he also mentioned that he had undergone a tracheotomy. He also revealed that, after waking from the coma, he had a temporary West Country accent.
In May 2013, George Michael sustained a head injury when he impacted after falling from his moving automobile on the M1 motorway, near St Albans in Hertfordshire, and received an airlift to a hospital.

</doc>
<doc id="45990" url="http://en.wikipedia.org/wiki?curid=45990" title="Grandfather paradox">
Grandfather paradox

The grandfather paradox is a proposed paradox of time travel first described by the science fiction writer Nathaniel Schachner in his short story "Ancestral Voices" and by René Barjavel in his 1943 book "Future Times Three". The paradox is described as follows: the time traveller goes back in time and kills his grandfather before his grandfather meets his grandmother. As a result, the time traveller is never born. But, if he was never born, then he is unable to travel through time and kill his grandfather, which means the traveller would then be born after all, and so on.
Despite the name, the grandfather paradox does not exclusively regard the impossibility of one's own birth. Rather, it regards any action that eliminates the cause or means of traveling back in time. The paradox's namesake example is merely the most commonly thought of when one considers the whole range of possible actions. Another example would be using scientific knowledge to invent a time machine, then going back in time and (whether through murder or otherwise) impeding a scientist's work that would eventually lead to the invention of the time machine. An equivalent paradox is known (in philosophy) as autoinfanticide, going back in time and killing oneself as a baby.
Assuming the causal link between the time traveller's present and future, the grandfather paradox that disrupts that link may be regarded as impossible (thus precluding the arbitrary alteration of one's fate). However, a number of hypotheses have been postulated to avoid the paradox, such as the idea that the past is unchangeable, so the grandfather must have already survived the attempted killing (as stated earlier); or the time traveller creates—or joins—an alternate timeline or parallel universe in which the traveller was never born.
A variant of the grandfather paradox is the Hitler paradox or Hitler's murder paradox, a fairly frequent trope in science fiction, in which the protagonist travels back in time to murder Adolf Hitler before he can instigate World War II. Rather than necessarily physically preventing time travel, the action removes any "reason" for the travel, along with any knowledge that the reason ever existed, thus removing any point in travelling in time in the first place. Additionally, the consequences of Hitler's existence are so monumental and all-encompassing that for anyone born in the decades after World War II, it is likely that the grandfather paradox would directly apply in some way.
Scientific theories.
Novikov self-consistency principle.
The Novikov self-consistency principle expresses one view on how backwards time travel could be possible without a danger of paradoxes. According to this hypothesis, the only possible time lines are those entirely self-consistent—so anything a time traveller does in the past must have been part of history all along, and the time traveller can never do anything to prevent the trip back in time from happening, since this would represent an inconsistency. Nicholas J. J. Smith argues, for example, that if some time traveller killed the child who lived at his old address, this would ipso facto necessitate that the child was not the time traveller's younger self, nor the younger self of anyone alive in the time frame that the time traveller came from. This could be extrapolated further into the possibility that the child's death led to the family moving away, which in turn led to the time traveller's family moving into the house guaranteeing that the house later became the home the time traveller would then grow up in, forming a predestination paradox.
Seth Lloyd and other researchers at MIT have proposed an expanded version of the Novikov principle, according to which probability bends to prevent paradoxes from occurring. Outcomes would become stranger as one approaches a forbidden act, as the universe must favor improbable events to prevent impossible ones.
It might be argued that the ordinary concept of human "free will" is equivalent to this sort of time-travel paradox, for if one could travel back in time to change a future relative to "that" past space time interval, then how would that be distinguishable, in principle, from the everyday choices and decisions considered to be freely made within "any" space time frame taken as the "present"?
One might build a more plausible case for the prohibition of classical time-travel simply by considering how it might violate several conservation laws by the duplication of matter along a single space time line and perhaps require a near-universal redistribution of mass-energy.
Parallel universes.
There could be "an ensemble of parallel universes" such that when the traveller kills the grandfather, the act took place in (or resulted in the creation of) a parallel universe where the traveller's counterpart never exists as a result. However, his prior existence in the original universe is unaltered. Succinctly, this explanation states that: if time travel is possible, then multiple versions of the future exist in parallel universes. This theory would also apply if a person went back in time to shoot himself, because in the past he would be dead as in the future he would be alive and well.
Examples of parallel universes postulated in physics are:
Theories in science fiction.
Nonexistence theory.
According to this theory, if someone were to do something in the past that would cause their nonexistence, upon returning to the future, they would find themselves in a world where the effects of (and chain reactions thereof) their actions are not present, as the person never existed. Through this theory, they would still exist, though. Two well-known examples of this are found in "It's A Wonderful Life" and "Roswell That Ends Well".
Parallel universes resolution.
The idea of preventing paradoxes by supposing that the time traveller is taken to a parallel universe while his original history remains intact, which is discussed above in the context of science, is also common in science fiction—see Time travel as a means of creating historical divergences.
Restricted action resolution.
Another resolution, of which the Novikov self-consistency principle can be taken as an example, holds that if one were to travel back in time, the laws of nature (or other intervening cause) would simply forbid the traveller from doing anything that could later result in their time travel not occurring. For example, a shot fired at the traveller's grandfather misses, the gun jams or misfires, the grandfather is injured but not killed, or the person killed turns out to be not the real grandfather. No action the traveller takes to affect or change history can ever succeed, as some form of "bad luck" or coincidence always prevents the outcome. In effect, the traveller cannot change history. Often in fiction, the time traveller does not merely fail to prevent the actions, but in fact precipitates them (see predestination paradox), usually by accident.
This theory might lead to concerns about the existence of free will (in this model, free will may be an illusion, or at least not unlimited). This theory also assumes that causality must be constant: i.e. that nothing can occur in the absence of cause, whereas some theories hold that an event may remain constant even if its initial cause was subsequently eliminated.
Closely related but distinct is the notion of the time line as self-healing. The time-traveller's actions are like throwing a stone in a large lake; the ripples spread, but are soon swamped by the effect of the existing waves. For instance, a time traveller could assassinate a politician who led his country into a disastrous war, but the politician's followers would then use his murder as a pretext for the war, and the emotional effect of that would cancel out the loss of the politician's charisma. Or the traveller could prevent a car crash from killing a loved one, only to have the loved one killed by a mugger, fall down the stairs, choke on a meal, etc. In the 2002 film "The Time Machine", this scenario is shown where the main character builds a time machine to save his fiance from being killed by a mugger, only for her to die in a car crash instead; as he learns from a trip to the future, he cannot save her with the machine or he would never have been inspired to build the machine so that he could go back and save her in the first place.
In some stories it is only the event that precipitated the time traveller's decision to travel back in time that cannot be substantially changed, in others all attempted changes "heal" in this way, and in still others the universe can heal most changes but not sufficiently drastic ones. This is also the explanation advanced by "The Doctor Who Role Playing Game", which supposes that time is like a stream; you can dam it, divert it, or block it, but the overall direction resumes after a period of conflict.
It also may not be clear whether the time traveller altered the past or precipitated the future he remembers, such as a time traveller who goes back in time to persuade an artist— whose single surviving work is famous— to hide the rest of the works to protect them. If, on returning to his time, he finds that these works are now well-known, he knows he has changed the past. On the other hand, he may return to a future exactly as he remembers, except that a week after his return, the works are found. Were they actually destroyed, as he believed when he traveled in time, and has he preserved them? Or was their disappearance occasioned by the artist's hiding them at his urging, and the skill with which they were hidden, and so the long time to find them, stemmed from his urgency?
Bad Wolf Resolution.
A resolution to the Hitler's Murder paradox is that the murderer traveled back in time in order to kill Hitler because he discovered a note telling him to do so. Then after killing Hitler, the murderer writes a note to himself telling him to travel back in time to kill Hitler. This results in the murderer effectively writing a note to his relative past self. A more well known example is the Doctor Who story arc of the same name.
Destruction resolution.
Some science fiction stories suggest that any paradox would destroy the universe, or at least the parts of space and time affected by the paradox. The plots of such stories tend to revolve around preventing paradoxes, such as .
A less destructive alternative of this theory suggests the death of the time traveller whether the history is altered or not; an example would be in the first part of the "Back to the Future" trilogy, where the lead character's alteration of history results in a risk of his own disappearance, and he has to fix the alteration to preserve his own existence. In this theory, killing one's grandfather would result in the disappearance of oneself, history would erase all traces of the person's existence, and the death of the grandfather would be caused by another means (say, another existing person firing the gun); thus, the paradox would never occur from a historical viewpoint.
Temporal Modification Negation Theory.
While stating that if time travel is possible it would be impossible to violate the grandfather paradox, it goes further to state that any action taken that itself negates the time travel event cannot occur. The consequences of such an event would in some way negate that event, be it by either voiding the memory of what one is doing before doing it, by preventing the action in some way, or even by destroying the universe among other possible consequences. It states therefore that to successfully change the past one must do so incidentally.
For example, if one tried to stop the murder of one's parents, he would fail. On the other hand, if one traveled back and did something else that as a result prevented the death of someone else's parents, then such an event would be successful, because the reason for the journey and therefore the journey itself remains unchanged preventing a paradox.
In addition, if this event had some colossal change in the history of mankind, and such an event would not void the ability or purpose of the journey back, it would occur, and would hold. In such a case, the memory of the event would immediately be modified in the mind of the time traveller.
An example of this would be for someone to travel back to observe life in Austria in 1887 and while there shoot five people, one of which was one of Hitler's parents. Hitler would therefore never have existed, but since this would not prevent the invention of the means for time travel, or the purpose of the trip, then such a change would hold. But for it to hold, every element that influenced the trip must remain unchanged. The Third Reich would not exist and the world we know today would be completely different. This would void someone convincing another party to travel back to kill the people without knowing who they are and making the time line stick, because by being successful, they would void the first party's influence and therefore the second party's actions.
These issues are treated humorously in an episode of "Futurama" in which Fry travels back in time and inadvertently causes his grandfather Enos's death before Enos marries his grandmother. Fry's distraught grandmother then seduces him, and Fry learns that he is his own grandfather.
Other considerations.
Consideration of the grandfather paradox has led some to the idea that time travel is by its very nature paradoxical and therefore logically impossible, on the same order as round squares. For example, the philosopher Bradley Dowden made this sort of argument in the textbook "Logical Reasoning", where he wrote:
But, some philosophers and scientists believe that time travel into the past need not be logically impossible provided that there is no possibility of changing the past, as suggested, for example, by the Novikov self-consistency principle. Bradley Dowden himself revised the view above after being convinced of this in an exchange with the philosopher Norman Swartz.
Consideration of the possibility of backwards time travel in a hypothetical universe described by a Gödel metric led famed logician Kurt Gödel to assert that time might itself be a sort of illusion. He seems to have been suggesting something along the lines of the block time view in which time does not really "flow" but is just another dimension like space, with all events at all times being fixed within this 4-dimensional "block".
See also.
Listen to this article ()
This audio file was created from a revision of the "Grandfather paradox" article dated 2012-04-30, and does not reflect subsequent edits to the article. ()
More spoken articles

</doc>
<doc id="45995" url="http://en.wikipedia.org/wiki?curid=45995" title="Building">
Building

A building is a man-made structure with a roof and walls standing more or less permanently in one place, such as a house or factory. Buildings come in a variety of shapes, sizes and functions, and have been adapted throughout history for a wide number of factors, from building materials available, to weather conditions, to land prices, ground conditions, specific uses and aesthetic reasons. To better understand the term "building" compare the list of nonbuilding structures.
Buildings serve several needs of society – primarily as shelter from weather, security, living space, privacy, to store belongings, and to comfortably live and work. A building as a shelter represents a physical division of the (a place of comfort and safety) and the "outside" (a place that at times may be harsh and harmful).
Ever since the first cave paintings, buildings have also become objects or canvasess of artistic expression. In recent years, interest in sustainable planning and building practices has also become an intentional part of the design process of many new buildings.
Definitions.
The word "building" is both a noun and a verb: the structure itself and the act of making it. As a noun, a building is 'a structure that has a roof and walls and stands more or less permanently in one place'; "there was a three-storey building on the corner"; "it was an imposing edifice". In the broadest interpretation a fence or wall is a building However, the word "structure" is used more broadly than "building" including natural and man-made formations and does not necessarily have walls. Structure is more likely to be used for a fence. Sturgis' Dictionary included that "[building] differs from Architecture [sic] in excluding all idea of artistic treatment; and it differs from Construction [sic] in the idea of excluding scientific or highly skilful treatment." As a verb, building is the act of construction.
"Structural height" in technical usage is the height to the highest architectural detail on building from street-level. Depending on how they are classified, spires and masts may or may not be included in this height. Spires and masts used as antennas are not generally included. The definition of a "low-rise vs. a high-rise" building is a matter of debate, but generally three storeys or less is considered low-rise.
History.
A report by Shinichi Fujimura of a shelter built 500 000 years ago is doubtful since Fujimura was later found to have faked many of his findings. Supposed remains of huts found at the Terra Amata site in Nice purportedly dating from 200 000 to 400 000 years ago have also been called into question. (See Terra Amata.) There is clear evidence of home-building from around 18 000 BC. Buildings became common during the Neolithic (see Neolithic architecture).
Types.
Residential.
Single-family residential buildings are most often called houses or homes. Residential buildings containing more than one dwelling unit are called a duplex, apartment building to differentiate them from 'individual' houses. A condominium is an apartment that the occupant owns rather than rents. Houses may also be built in pairs (semi-detached), in terraces where all but two of the houses have others either side; apartments may be built round courtyards or as rectangular blocks surrounded by a piece of ground of varying sizes. Houses which were built as a single dwelling may later be divided into apartments or bedsitters; they may also be converted to another use e.g. an office or a shop.
Building types may range from huts to multi-million dollar high-rise apartment blocks able to house thousands of people. Increasing settlement density in buildings (and smaller distances between buildings) is usually a response to high ground prices resulting from many people wanting to live close to work or similar attractors. Other common building materials are brick, concrete or combinations of either of these with stone.
Residential buildings have different names for there use depending if they are seasonal include holiday cottage (vacation home) or timeshare; size such as a cottage or great house; value such as a shack or mansion; manner of construction such as a log home or mobile home; proximity to the ground such as earth sheltered house, stilt house, or tree house. Also if the residents are in need of special care such as a nursing home, orphanage or prison; or in group housing like barracks or dormitorys.
Historically many people lived in communal buildings called longhouses, smaller dwellings called pit-houses and houses combined with barns sometimes called housebarns.
Buildings are defined to be substantial, permanent structures so other dwelling forms such as houseboats, yurts, and motorhomes are dwellings but not buildings.
Multi-storey.
A Multi-storey is a building that has multiple floors above ground in the building.
Multi-storey buildings aim to increase the floor area of the building without increasing the area of the land the building is built on, hence saving land and, in most cases, money (depending on material used and land prices in the area). The building with the most stories is the Burj Khalifa, with 162.
Creation.
The practice of designing, constructing, and operating buildings is most usually a collective effort of different groups of professionals and trades. Depending on the size, complexity, and purpose of a particular building project, the project team may include:
Regardless of their size or intended use, all buildings in the US must comply with zoning ordinances, building codes and other regulations such as fire codes, life safety codes and related standards.
Vehicles—such as trailers, caravans, ships and passenger aircraft—are treated as "buildings" for life safety purposes.
Building services.
Physical plant.
Any building requires a certain amount of internal infrastructure to function, which includes such elements like heating / cooling, power and telecommunications, water and wastewater etc. Especially in commercial buildings (such as offices or factories), these can be extremely intricate systems taking up large amounts of space (sometimes located in separate areas or double floors / false ceilings) and constitute a big part of the regular maintenance required.
Conveying systems.
Systems for transport of people within buildings:
Systems for transport of people between interconnected buildings:
Building damage.
Buildings may be damaged during the construction of the building or during maintenance. There are several other reasons behind building damage like accidents such as storms, explosions and subsidence caused by mining or poor foundations. Buildings also may suffer from fire damage and flooding in special circumstances. They may also become dilapidated through lack of proper maintenance or alteration work improperly carried out.

</doc>
<doc id="45998" url="http://en.wikipedia.org/wiki?curid=45998" title="McDonnell Douglas F/A-18 Hornet">
McDonnell Douglas F/A-18 Hornet

The McDonnell Douglas (now Boeing) F/A-18 Hornet is a twin-engine supersonic, all-weather carrier-capable multirole combat jet, designed as both a fighter and attack aircraft (F/A designation for Fighter/Attack). Designed by McDonnell Douglas and Northrop, the F/A-18 was derived from the latter's YF-17 in the 1970s for use by the United States Navy and Marine Corps. The Hornet is also used by the air forces of several other nations. The U.S. Navy's Flight Demonstration Squadron, the Blue Angels, has used the Hornet since 1986.
The F/A-18 has a top speed of Mach 1.8 (1,034 knots, 1,190 mph or 1,915 km/h at 40,000 ft or 12,190 m). It can carry a wide variety of bombs and missiles, including air-to-air and air-to-ground, supplemented by the 20 mm M61 Vulcan cannon. It is powered by two General Electric F404 turbofan engines, which give the aircraft a high thrust-to-weight ratio. The F/A-18 has excellent aerodynamic characteristics, primarily attributed to its leading edge extensions (LEX). The fighter's primary missions are fighter escort, fleet air defense, Suppression of Enemy Air Defenses (SEAD), air interdiction, close air support and aerial reconnaissance. Its versatility and reliability have proven it to be a valuable carrier asset, though it has been criticized for its lack of range and payload compared to its earlier contemporaries, such as the Grumman F-14 Tomcat in the fighter and strike fighter role, and the Grumman A-6 Intruder and LTV A-7 Corsair II in the attack role.
The Hornet saw its first combat action in 1986 during the 1986 United States bombing of Libya and subsequently participated in 1991 Gulf War and 2003 Iraq War. The F/A-18 Hornet provided the baseline design for the Boeing F/A-18E/F Super Hornet, a larger, evolutionary redesign of the F/A-18. 
Development.
Origins.
The U.S. Navy started the Naval Fighter-Attack, Experimental (VFAX) program to procure a multirole aircraft to replace the Douglas A-4 Skyhawk, the A-7 Corsair II, and the remaining McDonnell Douglas F-4 Phantom IIs, and to complement the F-14 Tomcat. Vice Admiral Kent Lee, then head of Naval Air Systems Command (NAVAIR), was the lead advocate for the VFAX against strong opposition from many Navy officers, including Vice Admiral William D. Houser, deputy chief of naval operations for air warfare – the highest ranking naval aviator.
In August 1973, Congress mandated that the Navy pursue a lower-cost alternative to the F-14. Grumman proposed a stripped F-14 designated the F-14X, while McDonnell Douglas proposed a naval variant of the F-15, but both were nearly as expensive as the F-14. That summer, Secretary of Defense Schlesinger ordered the Navy to evaluate the competitors in the Air Force's Lightweight Fighter (LWF) program, the General Dynamics YF-16 and Northrop YF-17. The Air Force competition specified a day fighter with no strike capability. In May 1974, the House Armed Services Committee redirected $34 million from the VFAX to a new program, the Navy Air Combat Fighter (NACF), intended to make maximum use of the technology developed for the LWF program.
Redesigning the YF-17.
Though the YF-16 won the LWF competition, the Navy was skeptical that an aircraft with one engine and narrow landing gear could be easily or economically adapted to carrier service, and refused to adopt an F-16 derivative. On 2 May 1975 the Navy announced its selection of the YF-17. Since the LWF did not share the design requirements of the VFAX, the Navy asked McDonnell Douglas and Northrop to develop a new aircraft from the design and principles of the YF-17. On 1 March 1977 Secretary of the Navy W. Graham Claytor announced that the F-18 would be named "Hornet".
Northrop had partnered with McDonnell Douglas as a secondary contractor on NACF to capitalize on the latter's experience in building carrier aircraft, including the widely used F-4 Phantom II. On the F-18, the two companies agreed to evenly split component manufacturing, with McDonnell Douglas conducting final assembly. McDonnell Douglas would build the wings, stabilators, and forward fuselage; while Northrop would build the center and aft fuselage and vertical stabilizers. McDonnell Douglas was the prime contractor for the naval versions, and Northrop would be the prime contractor for the F-18L land-based version which Northrop hoped to sell on the export market.
The F-18, initially known as McDonnell Douglas Model 267, was drastically modified from the YF-17. For carrier operations, the airframe, undercarriage, and tailhook were strengthened, folding wings and catapult attachments were added, and the landing gear widened. To meet Navy range and reserves requirements, McDonnell increased fuel capacity by 4460 lb, by enlarging the dorsal spine and adding a 96 gallon fuel tank to each wing. A "snag" was added to the wing's leading edge and stabilators to prevent an Aeroelastic flutter discovered in the F-15 stabilator. The wings and stabilators were enlarged, the aft fuselage widened by 4 in, and the engines canted outward at the front. These changes added 10000 lb to the gross weight, bringing it to 37000 lb. The YF-17's control system was replaced with a fully digital fly-by-wire system with quadruple-redundancy, the first to be installed in a production fighter.
Originally, it was planned to acquire a total of 780 aircraft of three variants: the single seat F-18A fighter and A-18A attack aircraft, differing only in avionics; and the dual-seat TF-18A, which retained full mission capability of the F-18 with a reduced fuel load. Following improvements in avionics and multifunction displays, and a redesign of external stores stations, the A-18A and F-18A were able to be combined into one aircraft. Starting in 1980, the aircraft began to be referred to as the F/A-18A, and the designation was officially announced on 1 April 1984. The TF-18A was redesignated F/A-18B.
Northrop's F-18L.
Northrop developed the F-18L as a potential export aircraft. Since it was not strengthened for carrier service, it was expected to be lighter and better performing, and a strong competitor to the F-16 Fighting Falcon then being offered to American allies. The F-18L's maximum gross weight was 7700 lb (approximately 30%) lighter than the F/A-18A, via lighter landing gear, lack of wing folding mechanism, reduced part thickness in areas, and lower fuel-carrying capacity. Though the aircraft retained a lightened tailhook, the most obvious external difference was removed "snags" on the leading edge of the wings and stabilators. It still retained 71% commonality with the F/A-18 by parts weight, and 90% of the high-value systems, including the avionics, radar, and electronic countermeasure suite, though alternatives were offered. Unlike the F/A-18, the F-18L carried no fuel in its wings and lacked weapons stations on the intakes. It had three underwing pylons on each side instead.
The F/A-18L version followed to coincide with the US Navy's F/A-18A as a land-based export alternative. This was essentially an F/A-18A lightened by approximately 2500 to; weight was reduced by removing the folding wing and associated actuators, by implementing a simpler landing gear (single wheel nose gear and cantilever oleo main gear), and change to a land-based tail-hook. The revised F/A-18L included wing fuel tanks and fuselage stations of the F/A-18A. Its weapons capacity would increase from 13700 to; largely due to the addition of a third underwing pylon and strengthened wingtips (11 stations in total vs 9 stations of the F/A-18A). Compared to the F-18L, the outboard weapons pylons are moved closer to the wingtip missile rails. Because of the strengthened non-folding wing, the wingtip missile rails were designed to carry either the AIM-7 Sparrow or Skyflash medium-range air-to-air missiles, in addition to the AIM-9 Sidewinder as found on the F/A-18A. The F/A-18L was strengthened for a 9 g design load factor compared to the F/A-18A's 7.5 g factor.
The partnership between McDonnell Douglas and Northrop soured over competition for foreign sales for the two models. Northrop felt that McDonnell Douglas would put the F/A-18 in direct competition with the F-18L. In October 1979, Northrop filed a series of lawsuits charging that McDonnell was using Northrop technology developed for the F-18L for foreign sales in violation of their agreement, and asked for a moratorium on foreign sales of the Hornet via McDonnell Douglas. The case was resolved in 1985 when McDonnell agreed to pay Northrop $50 million for complete rights to the design, with no admission of wrongdoing. By then Northrop had ceased work on the F-18L, and most export orders were captured by the F-16 or the F/A-18.
Into production.
During flight testing, the snag on the leading edge of the stabilators was filled in, and the gap between the Leading edge extensions (LEX) and the fuselage mostly filled in. The gaps, called the boundary layer air discharge (BLAD) slots, controlled the vortices generated by the LEX and presented clean air to the vertical stabilizers at high angles of attack, but they also generated a great deal of parasitic drag, worsening the problem of the F/A-18's inadequate range. McDonnell filled in 80% of the gap, leaving a small slot to bleed air from the engine intake. This may have contributed to early problems with fatigue cracks appearing on the vertical stabilizers due to extreme Structural loads, resulting in a short grounding in 1984 until the stabilizers were strengthened. Starting in May 1988, a small vertical fence was added to the top of each LEX to broaden the vortices and direct them away from the vertical stabilizers. This also provided a minor increase in controllability as a side effect. F/A-18s of early versions had a problem with insufficient rate of roll, exacerbated by the insufficient wing stiffness, especially with heavy underwing ordnance loads.
The first production F/A-18A flew on 12 April 1980. After a production run of 380 F/A-18As (including the nine assigned to flight systems development), manufacture shifted to the F/A-18C in September 1987.
Improvements and design changes.
In the 1990s, the U.S. Navy faced the need to replace its aging A-6 Intruders, and A-7 Corsair IIs with no replacement in development. To answer this deficiency, the Navy commissioned development of the F/A-18E/F Super Hornet. Despite its designation, it is not just an upgrade of the F/A-18 Hornet, but rather, a new, larger airframe using the design concepts of the Hornet.
Hornets and Super Hornets will serve complementary roles in the U.S. Navy carrier fleet until the Hornet A-D models are completely replaced by the F-35C Lightning II. The Marines have chosen to extend the use of certain of their F/A-18s up to 10000 flight hours, due to delays in the F-35B version.
Design.
The F/A-18 is a twin engine, mid wing, multi-mission tactical aircraft. It is highly maneuverable, owing to its good thrust to weight ratio, digital fly-by-wire control system, and leading edge extensions (LEX). The LEX allow the Hornet to remain controllable at high angles of attack. The trapezoidal wing has a 20-degree sweepback on the leading edge and a straight trailing edge. The wing has full-span leading edge flaps and the trailing edge has single-slotted flaps and ailerons over the entire span.
Canted vertical stabilizers are another distinguishing design element, one among several other such elements that enable the Hornet's excellent high angle of attack ability include oversized horizontal stabilators, oversized trailing edge flaps that operate as flaperons, large full-length leading edge slats, and flight control computer programming that multiplies the movement of each control surface at low speeds and moves the vertical rudders inboard instead of simply left and right. The Hornet's normally high angle of attack performance envelope was put to rigorous testing and enhanced in the NASA F-18 High Alpha Research Vehicle (HARV). NASA used the F-18 HARV to demonstrate flight handling characteristics at high angle-of-attack (alpha) of 65–70 degrees using thrust vectoring vanes. F/A-18 stabilators were also used as canards on NASA's F-15S/MTD.
The Hornet was among the first aircraft to heavily use multi-function displays, which at the switch of a button allow a pilot to perform either fighter or attack roles or both. This "force multiplier" ability gives the operational commander more flexibility to employ tactical aircraft in a fast-changing battle scenario. It was the first Navy aircraft to incorporate a digital multiplexing avionics bus, enabling easy upgrades.
The Hornet is also notable for having been designed to reduce maintenance, and as a result has required far less downtime than its heavier counterparts, the F-14 Tomcat and the A-6 Intruder. Its mean time between failures is three times greater than any other Navy strike aircraft, and requires half the maintenance time. Its General Electric F404 engines were also innovative in that they were designed with operability, reliability and maintainability first. The engine, while unexceptional in rated performance, demonstrates exceptional robustness under various conditions and is resistant to stall and flameout. The F404 engine connects to the airframe at only 10 points and can be replaced without special equipment; a four-person team can remove the engine within 20 minutes.
The engine air inlets of the Hornet, like that of the F-16, are of a simpler "fixed" design, while those of the F-4, F-14, and F-15 have variable geometry or variable intake ramp air inlets. This is a speed limiting factor in the Hornet design. Instead, the Hornet uses bleed air vents on the inboard surface of the engine air intake ducts to slow and reduce the amount of air reaching the engine. While not as effective as variable geometry, the bleed air technique functions well enough to achieve near Mach number 2 speeds, which is within the designed mission requirements.
A 1989 USMC study found that single-seat fighters were well suited to air-to-air combat missions while dual-seat fighters were favored for complex strike missions against heavy air and ground defenses in adverse weather—the question being not so much as to whether a second pair of eyes would be useful, but as to having the second crewman sit in the same fighter or in a second fighter. Single-seat fighters that lacked wingmen were shown to be especially vulnerable.
Operational history.
United States.
Entry into service.
McDonnell Douglas rolled out the first F/A-18A on 13 September 1978, in blue-on-white colors marked with "Navy" on the left and "Marines" on the right. Its first flight was on 18 November. In a break with tradition, the Navy pioneered the "principal site concept" with the F/A-18, where almost all testing was done at Naval Air Station Patuxent River, instead of near the site of manufacture, and using Navy and Marine Corps test pilots instead of civilians early in development. In March 1979, Lt. Cdr. John Padgett became the first Navy pilot to fly the F/A-18.
Following trials and operational testing by VX-4 and VX-5, Hornets began to fill the Fleet Replacement Squadrons (FRS) VFA-125, VFA-106, and VMFAT-101, where pilots are introduced to the F/A-18. The Hornet entered operational service with Marine Corps squadron VMFA-314 at MCAS El Toro on 7 January 1983, and with Navy squadron VFA-25 in March 1983, replacing F-4s and A-7Es, respectively.
The initial fleet reports were complimentary, indicating that the Hornet was extraordinarily reliable, a major change from its predecessor, the F-4J. Other squadrons that switched to F/A-18 are VFA-146 "Blue diamonds", and VFA-147 "Argonauts". In January 1985, the VFA-131 "Wildcats" and the VFA-132 "Privateers" moved from Naval Air Station Lemoore, California to Naval Air Station Cecil Field, Florida, and became the Atlantic Fleet's first F/A-18 squadrons.
The US Navy's Blue Angels Flight Demonstration Squadron switched to the F/A-18 Hornet in 1986, when it replaced the A-4 Skyhawk. The Blue Angels perform in F/A-18A, B, C, and D models at air shows and other special events across the US and worldwide. Blue Angels pilots must have 1,350 hours and an aircraft carrier certification. The two-seat B and D models are typically used to give rides to VIPs, but can also fill in for other aircraft in the squadron in a normal show, if the need arises.
Combat operations.
The F/A-18 first saw combat action in April 1986, when VFA-131, VFA-132, VMFA-314, and VMFA-323 Hornets from USS "Coral Sea" flew SEAD missions against Libyan air defenses during Operation Prairie Fire and an attack on Benghazi as part of Operation El Dorado Canyon.
During the Gulf War of 1991, the Navy deployed 106 F/A-18A/C Hornets and Marine Corps deployed 84 F/A-18A/C/D Hornets. F/A-18 pilots were credited with two kills during the Gulf War, both MiG-21s. On 17 January, the first day of the war, U.S. Navy pilots Lieutenant Commander Mark I. Fox and his wingman, Lieutenant Nick Mongilio were sent from USS "Saratoga" in the Red Sea to bomb an airfield in southwestern Iraq. While en route, they were warned by an E-2C of approaching MiG-21 aircraft. The Hornets shot down the two MiGs with AIM-7 and AIM-9 missiles in a brief dogfight. The F/A-18s, each carrying four 2000 lb bombs, then resumed their bombing run before returning to "Saratoga".
The Hornet's survivability was demonstrated when a Hornet took hits in both engines and flew 125 mi back to base. It was repaired and flying within a few days. F/A-18s flew 4,551 sorties with 10 Hornets damaged including two losses. The two losses were U.S. Navy F/A-18s and their pilots were lost. On 17 January 1991, Lieutenant Commander Scott Speicher of VFA-81 was shot down and killed in the crash of his aircraft. An unclassified summary of a 2001 CIA report suggests that Speicher's aircraft was shot down by a missile fired from an Iraqi Air Force aircraft, most likely a MiG-25. The other F/A-18, piloted by Lieutenant Robert Dwyer was lost over the North Persian Gulf after a successful mission to Iraq; he was officially listed as killed in action, body not recovered.
As the A-6 Intruder was retired in the 1990s, its role was filled by the F/A-18. The F/A-18 demonstrated its versatility and reliability during Operation Desert Storm, shooting down enemy fighters and subsequently bombing enemy targets with the same aircraft on the same mission. It broke records for tactical aircraft in availability, reliability, and maintainability.
Both U.S. Navy F/A-18A/C models and Marine F/A-18A/C/D models were used continuously in Operation Southern Watch and over Bosnia and Kosovo in the 1990s. U.S. Navy Hornets flew during Operation Enduring Freedom in 2001 from carriers operating in the North Arabian Sea. Both the F/A-18A/C and newer F/A-18E/F variants were used during Operation Iraqi Freedom in 2003, operating from aircraft carriers as well from an air base in Kuwait. Later in the conflict USMC A+, C, and primarily D models operated from bases within Iraq.
An F/A-18C was accidentally downed in a friendly fire incident by a Patriot missile when a pilot tried to evade two missiles fired at him and crashed. Two others collided over Iraq in May 2005. In January 2007, two Navy F/A-18E/F Super Hornets collided in midair and crashed in the Persian Gulf.
Non-U.S. service.
Though U.S. Navy aircraft have generally not sold well on the export market, the F/A-18 has been purchased and is in operation with several foreign air services. Export Hornets are typically similar to U.S. models of a similar manufacture date. Since none of the customers operate aircraft carriers, all export models have been sold without the automatic carrier landing system, and Royal Australian Air Force further removed the catapult attachment on the nose gear. Except for Canada, all export customers purchased their Hornets through the U.S. Navy, via the U.S. Foreign Military Sales (FMS) Program, where the Navy acts as the purchasing manager but incurs no financial gain or loss. Canada is the largest Hornet operator outside of the U.S.
Australia.
The Royal Australian Air Force purchased 57 F/A-18A fighters and 18 F/A-18B two-seat trainers to replace its Dassault Mirage IIIOs. Numerous options were considered for the replacement, notably the F-15A Eagle, the F-16 Falcon, and the then new F/A-18 Hornet. The F-15 was discounted because the version offered had no ground-attack capability. The F-16 was considered unsuitable largely due to having only one engine. Australia selected the F/A-18 in October 1981. Original differences between the Australian and US Navy's standard F/A-18 were the removed nose wheel tie bar for catapult launch (later re-fitted with a dummy version to remove nose wheel shimmy), addition of a high frequency radio, an Australian fatigue data analysis system, an improved video and voice recorder, and the use of ILS/VOR (Instrument Landing System/Very High Frequency Omnidirectional Range) instead of the carrier landing system.
The first two aircraft were produced in the US, with the remainder assembled in Australia at Government Aircraft Factories. F/A-18 deliveries to the RAAF began on 29 October 1984, and continued until May 1990. In 2001, Australia deployed four aircraft to Diego Garcia, in an air defense role, during coalition operations against the Taliban in Afghanistan. In 2003, 75 Squadron deployed 14 F/A-18s to Qatar as part of Operation Falconer and these aircraft saw action during the invasion of Iraq. Australia had 71 Hornets in service in 2006, after four were lost to crashes.
The fleet was upgraded beginning in the late 1990s to extend their service lives to 2015. They were expected to be retired then and replaced by the F-35 Lightning II.
Several of the Australian Hornets have had refits applied to extend their service lives until the planned retirement date of 2020. In addition to the F/A-18A and F/A-18B Hornets, Australia has purchased 24 F/A-18F Super Hornets, with deliveries beginning in 2009.
In March 2015 six F/A-18As from No. 75 Squadron were deployed to the Middle East as part of Operation Okra, replacing a detachment of Super Hornets.
Canada.
Canada was the first export customer for the Hornet, replacing the CF-104 Starfighter (air reconnaissance and strike), the McDonnell CF-101 Voodoo (air interception) and the CF-116 Freedom Fighter (ground attack). The Canadian Forces Air Command ordered 98 A models (Canadian designation CF-188A/CF-18A) and 40 B models (designation CF-188B/CF-18B).
In 1991, Canada committed 26 CF-18s to the Gulf War, based in Qatar. These aircraft primarily provided Combat Air Patrol duties, although late in the air war began to perform air strikes on Iraqi ground targets. On 30 January 1991, two CF-18s on CAP detected and attacked an Iraqi TNC-45 patrol boat. The vessel was repeatedly strafed and damaged by 20mm cannon fire, but an attempt to sink the ship with an air-to-air missile failed. The ship was subsequently sunk by American aircraft, but the Canadian CF-18s received partial credit for its destruction. In June 1999, 18 CF-18s were deployed to Aviano AB, Italy, where they participated in both the air-to-ground and air-to-air roles in the former Yugoslavia.
62 CF-18A and 18 CF-18B aircraft took part in the Incremental Modernization Project which was completed in two phases. The program was launched in 2001 and the last updated aircraft was delivered in March 2010. The aims were to improve air-to-air and air-to-ground combat abilities, upgrade sensors and the defensive suite, and replace the datalinks and communications systems on board the CF-18 from the F/A-18A and F/A-18B standard to the current F/A-18C and F/A-18D standard.
In July 2010 the Canadian government announced plans to replace the remaining CF-18 fleet with 65 F-35 Lightning IIs, with deliveries scheduled to start in 2016.
Finland.
The Finnish Air Force ("Suomen ilmavoimat") ordered 64 F-18C/Ds (57 C models, seven D models). All F-18D were built at St Louis, and then all F-18C were assembled in Finland. Delivery of the aircraft started in November 1995 until August 2000. The Hornet replaced the MiG-21bis and Saab 35 Draken in Finnish service. The Finnish Hornets were initially to be used only for air defense, hence the F-18 designation. The F-18C includes the ASPJ (Airborne-Self-Protection-Jammer) jamming pod ALQ-165. The US Navy later included the ALQ-165 on their F/A-18E/F Super Hornet procurement.
One fighter was destroyed in a mid-air collision in 2001. A damaged F-18C, nicknamed "Frankenhornet", was rebuilt into a F-18D using the forward section of a Canadian CF-18B that was purchased. The modified fighter crashed during a test flight in January 2010, due to a faulty tailplane servo cylinder.
Finland is upgrading its fleet of F-18s with new avionics, including helmet mounted sights (HMS), new cockpit displays, sensors and standard NATO data link. Several of the remaining Hornets are going to be fitted to carry air-to-ground ordnance such as the AGM-158 JASSM, in effect returning to the original F/A-18 multi-role configuration. The upgrade includes also the procurement and integration of new AIM-9X Sidewinder and AIM-120C-7 AMRAAM air-to-air missiles. This Mid-Life Upgrade (MLU) is estimated to cost between €1–1.6 billion and work is scheduled to be finished by 2016. After the upgrades the aircraft are to remain in active service until 2020–2025. In October 2014 the Finnish broadcaster Yle announced that consideration was being given to the replacement of the Hornet.
Kuwait.
The Kuwait Air Force ("Al Quwwat Aj Jawwaiya Al Kuwaitiya") ordered 32 F/A-18C and eight F/A-18D Hornets in 1988. Delivery started in October 1991 until August 1993. The F/A-18C/Ds replaced A-4KU Skyhawk. Kuwait Air Force Hornets have flown missions over Iraq during Operation Southern Watch in the 1990s. They have also participated in military exercises with the air forces of other Gulf nations. Kuwait had 39 F/A-18C/D Hornets in service in 2008.
Malaysia.
The Royal Malaysian Air Force ("Tentera Udara Diraja Malaysia") has eight F/A-18Ds. Delivery of the aircraft started in March 1997 until August 1997. The air force split their order between the F/A-18 and the Mikoyan MiG-29. Three Hornets were employed together with five UK-made BAE Hawk 208 in an airstrike on the Royal Security Forces of the Sultanate of Sulu and North Borneo terrorist hideout on 5 March 2013, occupying part of Borneo, just before the joint forces of Malaysian Army and Royal Malaysia Police operatives launched an assault in the 2013 Lahad Datu standoff. This was the first shot fired in combat by the Malaysian Hornets.
Spain.
The Spanish Air Force ("Ejército del Aire") ordered 60 EF-18A model and 12 EF-18B model Hornets (the "E" standing for "España", Spain), named respectively as C.15 and CE.15 by Spanish AF. Delivery of the Spanish version started on 22 November 1985 until July 1990. These fighters were upgraded to F-18A+/B+ standard, close to F/A-18C/D (plus version includes later mission and armament computers, databuses, data-storage set, new wiring, pylon modifications and software, new abilities as AN/AAS-38B NITE Hawk targeting FLIR pods).
In 1995 Spain obtained 24 ex-USN F/A-18A Hornets, with six more on option. These were delivered from December 1995 until December 1998. Before delivery, they were modified to EF-18A+ standard. This was the first sale of USN surplus Hornets.
Spanish Hornets operate as an all-weather interceptor 60% of the time and as an all-weather day/night attack aircraft for the remainder. In case of war, each of the front-line squadrons would take a primary role: 121 is tasked with tactical air support and maritime operations; 151 and 122 are assigned to all-weather interception and air combat roles; and 152 is assigned the SEAD mission. Air refueling is provided by KC-130Hs and Boeing 707TTs. Pilot conversion to EF-18 is centralized in 153 Squadron (Ala 15). Squadron 462's role is air defense of the Canary Islands, being responsible for fighter and attack missions from Gando AB.
Spanish Air Force EF-18 Hornets have flown Ground Attack, SEAD, combat air patrol (CAP) combat missions in Bosnia and Kosovo, under NATO command, in Aviano detachment (Italy). They shared the base with Canadian and USMC F/A-18s. Six Spanish Hornets had been lost in accidents by 2003.
Over Yugoslavia, eight EF-18s, based at Aviano AB, participated in bombing raids in Operation Allied Force in 1999. Over Bosnia, they also performed missions for air-to-air combat air patrol, close air support air-to-ground, photo reconnaissance, forward air controller-airborne, and tactical air controller-airborne. Over Libya, four Spanish Hornets participated in enforcing a no-fly zone.
Switzerland.
The Swiss Air Force purchased 26 C models and eight D models. Delivery of the aircraft started in January 1996 until December 1999. Two D models had been lost in crashes as of 2013.[]
In late 2007, Switzerland requested to be included in F/A-18C/D Upgrade 25 Program, to extend the useful life of its F/A-18C/Ds. The program includes significant upgrades to the avionics and mission computer, 20 ATFLIR surveillance and targeting pods, and 44 sets of AN/ALR-67v3 ECM equipment. In October 2008 the Swiss Hornet fleet reached the 50,000 flight hour milestone.
Potential operators.
The F/A-18C and F/A-18D were considered by the French Navy ("Marine Nationale") during the 1980s for deployment on their aircraft carriers "Clemenceau" and "Foch" and again in the 1990s for the later nuclear-powered "Charles de Gaulle", in the event that the Dassault Rafale M was not brought into service when originally planned.
Austria, Chile, Czech Republic, Hungary, Philippines, Poland, and Singapore evaluated the Hornet but did not purchase it. Thailand ordered four C and four D model Hornets but the Asian financial crisis in the late 1990s resulted in the order being canceled. The Hornets were completed as F/A-18Ds for the U.S. Marine Corps.
The F/A-18A and F-18L land-based version competed for a fighter contract from Greece in the 1980s. The Greek government chose F-16 and Mirage 2000 instead.
Variants.
A/B.
The "F/A-18A" is the single-seat variant and the "F/A-18B" is the two-seat variant. The space for the two-seat cockpit is provided by a relocation of avionics equipment and a 6% reduction in internal fuel; two-seat Hornets are otherwise fully combat-capable. The B-model is used primarily for training.
In 1992, the original Hughes AN/APG-65 radar was replaced with the Hughes (now Raytheon) AN/APG-73, a faster and more capable radar. A-model Hornets that have been upgraded to the AN/APG-73 are designated "F/A-18A+".
C/D.
The "F/A-18C" is the single-seat variant and the "F/A-18D" is the two-seat variant. The D-model can be configured for training or as an all-weather strike craft. The "missionized" D model's rear seat is configured for a Marine Corps Naval Flight Officer who functions as a Weapons and Sensors Officer to assist in operating the weapons systems. The F/A-18D is primarily operated by the U.S. Marine Corps in the night attack and Forward Air Controller (Airborne) (FAC(A)) roles.
The F/A-18C and D models are the result of a block upgrade in 1987 incorporating upgraded radar, avionics, and the capacity to carry new missiles such as the AIM-120 AMRAAM air-to-air missile and AGM-65 Maverick and AGM-84 Harpoon air-to-surface missiles. Other upgrades include the Martin-Baker NACES (Navy Aircrew Common Ejection Seat), and a self-protection jammer. A synthetic aperture ground mapping radar enables the pilot to locate targets in poor visibility conditions. C and D models delivered since 1989 also have improved night attack abilities, consisting of the Hughes AN/AAR-50 thermal navigation pod, the Loral AN/AAS-38 NITE Hawk FLIR (forward looking infrared array) targeting pod, night vision goggles, and two full-color (formerly monochrome) multi-function display (MFDs) and a color moving map.
In addition, 60 D-model Hornets are configured as the night attack "F/A-18D (RC)" with ability for reconnaissance. These could be outfitted with the ATARS electro-optical sensor package that includes a sensor pod and equipment mounted in the place of the M61 cannon.
Beginning in 1992, the F404-GE-402 enhanced performance engine, providing approximately 10% more maximum static thrust became the standard Hornet engine. Since 1993, the AAS-38A NITE Hawk added a designator/ranger laser, allowing it to self-mark targets. The later AAS-38B added the ability to strike targets designated by lasers from other aircraft.
Production of the C- and D- models ended in 2000. The last F/A-18C was assembled in Finland and delivered to the Finnish Air Force in August 2000. The last F/A-18D was delivered to the U.S. Marine Corps in August 2000.
E/F Super Hornet.
The single-seat "F/A-18E" and two-seat "F/A-18F Super Hornets" carry over the name and design concept of the original F/A-18, but have been extensively redesigned. The Super Hornet has a new, 25% larger airframe, larger rectangular air intakes, more powerful GE F414 engines based on F/A-18's F404, and upgraded avionics suite. Like the Marine Corps' F/A-18D, the Navy's F/A-18F carries a Naval Flight Officer as a second crew member in a Weapons Systems Officer (WSO) role. The Super Hornet is also operated by Australia.
G Growler.
The EA-18G Growler is an electronic warfare version of the two-seat F/A-18F, which entered production in 2007. The Growler is replacing the Navy's EA-6B Prowler and carries a Naval Flight Officer as a second crewman in an Electronic Countermeasures Officer (ECMO) role. 
Export variants.
"These designations are not part of 1962 United States Tri-Service aircraft designation system."
Notable appearances in media.
Hornets make frequent appearances in action movies and military novels. The Hornet was featured in the film "Independence Day" and "Behind Enemy Lines" as well as in 1998's "Godzilla". The Hornet has a major role in Jane's "US Navy Fighters" (1994), Jane's "Fighters Anthology" (1997) and "Jane's F/A-18 Simulator" computer simulators.
References.
Bibliography.
</dl>

</doc>
<doc id="45999" url="http://en.wikipedia.org/wiki?curid=45999" title="Gecko (software)">
Gecko (software)

Gecko is a web browser engine used in many applications developed by Mozilla Foundation and the Mozilla Corporation (notably the Firefox web browser including its mobile version and their e-mail client Thunderbird), as well as in many other open source software projects. Gecko is free and open-source software subject to the terms of the Mozilla Public License version 2.
It is designed to support open Internet standards, and is used by different applications to display web pages and, in some cases, an application's user interface itself (by rendering XUL). Gecko offers a rich programming API that makes it suitable for a wide variety of roles in Internet-enabled applications, such as web browsers, content presentation, and client/server.
Gecko is written in C++ and is cross-platform, and runs on various operating systems including BSDs, Linux, OS X, Solaris, OS/2, AIX, OpenVMS, and Microsoft Windows. Its development is now overseen by the Mozilla Foundation.
History.
Development of the layout engine now known as Gecko began at Netscape in 1997, following the company's purchase of DigitalStyle. The existing Netscape rendering engine, originally written for Netscape Navigator 1.0 and upgraded through the years, was slow, did not comply well with W3C standards, had limited support for dynamic HTML and lacked features such as incremental reflow (when the layout engine rearranges elements on the screen as new data is downloaded and added to the page). The new layout engine was developed in parallel with the old, with the intention being to integrate it into Netscape Communicator when it was mature and stable. At least one more major revision of Netscape was expected to be released with the old layout engine before the switch.
After the launch of the Mozilla project in early 1998, the new layout engine code was released under an open-source license. Originally unveiled as "Raptor", the name had to be changed to "NGLayout" (next generation layout) due to trademark problems. Netscape later rebranded NGLayout as "Gecko". While Mozilla Organization (the forerunner of the Mozilla Foundation) initially continued to use the NGLayout name (Gecko was a Netscape trademark), eventually the Gecko branding won out.
In October 1998, Netscape announced that its next browser would use Gecko (which was still called NGLayout at the time) rather than the old layout engine, requiring large parts of the application to be rewritten. While this decision was popular with web standards advocates, it was largely unpopular with Netscape developers, who were unhappy with the six months given for the rewrite. It also meant that most of the work done for Netscape Communicator 5.0 (including development on the Mariner improvements to the old layout engine) had to be abandoned. Netscape 6, the first Netscape release to incorporate Gecko, was released in November 2000 (the name Netscape 5 was never used).
As Gecko development continued, other applications and embedders began to make use of it. America Online, by this time Netscape's parent company, eventually adopted it for use in CompuServe 7.0 and AOL for Mac OS X (these products had previously embedded Internet Explorer). However, with the exception of a few betas, Gecko was never used in the main Microsoft Windows AOL client.
On July 15, 2003, AOL laid off the remaining Gecko developers and the Mozilla Foundation (formed on the same day) became the main steward of Gecko development. Today, Gecko is developed by employees of the Mozilla Corporation, employees of companies that contribute to the Mozilla project, and volunteers.
Standards support.
From the outset, Gecko was designed to support open Internet standards. Some of the standards Gecko supports include:
Gecko also partially supports SVG 1.1.
In order to support web pages designed for legacy versions of Netscape and Internet Explorer, Gecko supports DOCTYPE switching. Documents with a modern DOCTYPE are rendered in standards compliance mode, which follows the W3C standards strictly. Documents that have no DOCTYPE or an older DOCTYPE are rendered in quirks mode, which emulates some of the non-standard oddities of Netscape Communicator 4.x; however, some of the 4.x features (such as layers) are not supported.
Gecko also has limited support for some non-standard Internet Explorer features, such as the marquee element and the codice_1 property (though pages explicitly testing for codice_1 will be told it is not supported). While this increases compatibility with many documents designed only for Internet Explorer, some purists argue that it harms the cause of standards evangelism.
Usage.
Gecko is primarily used in web browsers, the earliest being Netscape 6 and Mozilla Suite (later renamed SeaMonkey). It is also used in other Mozilla web browser derivatives such as Firefox and Firefox for mobile and the implementation of the Internet Explorer-clone that is part of Wine. Mozilla also uses it in their Thunderbird email-client and their Firefox OS.
Other web browsers using Gecko include Airfox, Waterfox, K-Meleon, Lunascape, Pale Moon, Portable Firefox, Conkeror, Classilla, TenFourFox, HP Secure Web Browser, Oxygen and Sylera (for mobile).
Other products using Gecko include Conkeror, Oxygen, Nightingale, Instantbird and Google's picture-organization software Picasa (for Linux).
DevHelp, a GTK+/GNOME browser for API documentation, used Gecko for rendering documents.
Gecko is also used by Sugar for the OLPC XO-1 computer. Gecko is used as a complete implementation of the XUL (XML User Interface Language). Gecko currently defines the XUL specification.
Products that have historically used Gecko include Songbird, Epiphany (now known as Web and no longer using Gecko), Sunbird (calendar), and other web browsers including Swiftfox, Flock, Galeon, Camino, Minimo, Beonex Communicator, Kazehakase, and MicroB.
After Gecko 2.0, the version number was bumped to 5.0 to match Firefox 5, and from then on has been kept in sync with the major version number for both Firefox and Thunderbird, to reflect the fact that it is no longer a separate component.
Criticism.
In the past, Gecko had slower market share adoption due to the complexity of the Gecko code, which aimed to provide much more than just an HTML renderer for web browsers.
Mozilla's engineering efforts since then have addressed many of these historical weaknesses.
The Gecko engine also provides a versatile XML-based user interface rendering framework called XUL that was used extensively in mail, newsgroup, and other programs. Another reason for much of the complexity in Gecko is the use of XPCOM, a cross-platform component model. However, its use has been scaled back.
On Windows and similar platforms, Gecko depends on non-free compilers. Thus, FOSS distributions of Linux can not include the Gecko package used in the Windows compatibility layer Wine.

</doc>
<doc id="46000" url="http://en.wikipedia.org/wiki?curid=46000" title="Alexandru Ioan Cuza">
Alexandru Ioan Cuza

 
Alexandru Ioan Cuza (], or Alexandru Ioan I, also anglicised as Alexander John Cuza; 20 March 1820 – 15 May 1873) was Prince of Moldavia, Prince of Wallachia, and later Domnitor (ruler) of the Romanian Principalities. He was a prominent figure of the Revolution of 1848 in Moldavia. He initiated a series of reforms that contributed to the modernization of Romanian society and of state structures.
Early life.
Born in Bârlad, Cuza belonged to the traditional boyar class in Moldavia, being the son of Ispravnic Ioan Cuza (who was also a landowner in Fălciu County) and his wife Sultana (or Soltana), a member of the Cozadini family of Phanariote origins. Alexander received an urbane European education, becoming an officer in the Moldavian Army (rising to the rank of colonel). He married Elena Rosetti in 1844.
In 1848, known as the year of European revolutions, Moldavia and Wallachia fell into revolt. The Moldavian unrest was quickly suppressed, but in Wallachia the revolutionaries took power and governed during the summer ("see 1848 Wallachian revolution"). Young Cuza played a prominent enough part so as to establish his liberal credentials during the Moldavian episode and to be shipped to Vienna as a prisoner, where he made his escape with British support.
Returned during the reign of Prince Grigore Alexandru Ghica, he became Moldavia's minister of war in 1858 representing also Galați in the ad hoc Divan at Iași. Cuza was acting freely under the guarantees of the European Powers in the eve of the Crimean War for a recognition of the Prince of Moldavia. Cuza was a prominent speaker in the debates and strongly advocated the union of Moldavia and Walachia. In default of a foreign prince, he was nominated as a candidate in both principalities by the pro-unionist Partida Națională (profiting of an ambiguity in the text of the Treaty of Paris). Cuza was finally elected as Prince of Moldavia on 17 January 1859 (5 January Julian) and, after "street pressure" changed the vote in Bucharest, also Prince of Wallachia, on 5 February 1859 (24 January Julian). He received the firman from the Sultan on 2 December 1861 during a visit to Istanbul.
He was recipient of the Order of Medjidie, Order of Osmanieh, Order of Saints Maurice and Lazarus and Order of the Redeemer. 
Although he and his wife Elena Rosetti had no children, she raised as her own children his two sons from his mistress Elena Maria Catargiu-Obrenović: Alexandru Al. Ioan Cuza (1864–1889), and Dimitrie Cuza (1865–1888 "suicide").
Reign.
Diplomatic efforts.
Thus Cuza achieved a de facto union of the two principalities. The Powers backtracked, Napoleon III of France remaining supportive, while the Austrian ministry withheld approval of such a union at the Congress of Paris (18 October 1858); partly as a consequence, Cuza's authority was not recognized by his nominal suzerain, Abdülaziz, the Sultan of the Ottoman Empire, until 23 December 1861, (and, even then, the union was only accepted for the duration of Cuza's rule).
The union was formally declared three years later, on 5 February 1862, (24 January Julian), the new country bearing the name of Romania, with Bucharest as its capital city.
Cuza invested his diplomatic actions in gaining further concessions from the Powers: the sultan's assent to a single unified parliament and cabinet for Cuza's lifetime, in recognition of the complexity of the task. Thus, he was regarded as the political embodiment of a unified Romania.
Reforms.
Assisted by his councilor Mihail Kogălniceanu, an intellectual leader of the 1848 revolution, Cuza initiated a series of reforms that contributed to the modernization of Romanian society and of state structures.
 
His first measure addressed a need for increasing the land resources and revenues available to the state, by "secularizing" (confiscating) monastic assets in 1863. Probably more than a quarter of Romania's farmland was controlled by untaxed Eastern Orthodox "Dedicated Monasteries", which supported Greek and other foreign monks in shrines such as Mount Athos and Jerusalem (a substantial drain on state revenues). Cuza got his parliament's backing to expropriate these lands. He offered compensation to the Greek Orthodox Church, but Sophronius III, the Patriarch of Constantinople, refused to negotiate; after several years, the Romanian government withdrew its offer and no compensation was ever paid. State revenues thereby increased without adding any domestic tax burden.
The land reform, liberating peasants from the last corvées, freeing their movements and redistributing some land (1864), was less successful. In attempting to create a solid support base among the peasants, Cuza soon found himself in conflict with the group of Conservatives. A liberal bill granting peasants title to the land they worked was defeated. Then the Conservatives responded with a bill that ended all peasant dues and responsibilities, but gave landlords title to all the land. Cuza vetoed it, then held a plebiscite to alter the Paris Convention (the virtual constitution), in the manner of Napoleon III.
His plan to establish universal manhood suffrage, together with the power of the Domnitor to rule by decree, passed by a vote of 682,621 to 1,307. He consequently governed the country under the provisions of "Statutul dezvoltător al Convenției de la Paris" ("Statute expanding the Paris Convention"), an organic law adopted on 15 July 1864. With his new plenary powers, Cuza then promulgated the Agrarian Law of 1863. Peasants received title to the land they worked, while landlords retained ownership of one third. Where there was not enough land available to create workable farms under this formula, state lands (from the confiscated monasteries) would be used to give the landowners compensation.
Despite the attempts by Lascăr Catargiu's cabinet to force a transition in which some corvées were to be maintained, Cuza's reform marked the disappearance of the boyar class as a privileged group, and led to a channeling of energies into capitalism and industrialization; at the same time, however, land distributed was still below necessities, and the problem became stringent over the following decades – as peasants reduced to destitution sold off their land or found that it was insufficient for the needs of their growing families.
Cuza's reforms also included the adoption of the Criminal Code and the Civil Code based on the Napoleonic code (1864), a Law on Education, establishing tuition-free, compulsory public education for primary schools (1864; the system, nonetheless, suffered from drastic shortages in allocated funds; illiteracy was eradicated about 100 years later, during the communist regime). He founded the University of Iași (1860) and the University of Bucharest (1864), and helped develop of a modern, European-style Romanian Army, under a working relationship with France. He is the founder of Romanian Naval Forces.
Downfall and exile.
Cuza failed in his effort to create an alliance of prosperous peasants and a strong liberal prince, ruling as a benevolent authoritarian in the style of Napoleon III. Having to rely on a decreasing group of hand-picked bureaucrats, Cuza began facing a mounting opposition after his land reform bill, with liberal landowners voicing concerns over his ability to represent their interests. Along with financial distress, there was an awkward scandal that revolved around his mistress, Maria Catargi-Obrenović, and popular discontent culminated in a coup d'état.
Cuza was forced to abdicate by the so-called "monstrous coalition" of Conservatives and Liberals. At four o'clock on the morning of 22 February 1866, a group of military conspirators broke into the palace, and compelled the prince to sign his abdication. On the following day they conducted him safely across the frontier.
His successor, Prince Karl of Hohenzollern-Sigmaringen, was proclaimed Domnitor as Carol I of Romania on 20 April 1866. The election of a foreign prince with ties to an important princely house, legitimizing Romanian independence (which Carol came to do after the Russo-Turkish War of 1877–1878), had been one of the liberal aims in the revolution of 1848.
Despite the participation of Ion Brătianu and other future leaders of the Liberal Party in the overthrow of Cuza, he remained a hero to the radical and republican wing, who, as Francophiles, had an additional reason to oppose a Prussian monarch; anti-Carol riots in Bucharest during the Franco-Prussian War ("see History of Bucharest") and the coup attempt known as the Republic of Ploiești in August 1870, the conflict was eventually resolved by the compromise between Brătianu and Carol, with the arrival of a prolonged and influential Liberal cabinet.
Cuza spent the remainder of his life in exile, chiefly in Paris, Vienna and Wiesbaden, accompanied by his wife, his mistress, and his two sons. He died in Heidelberg. His remains were buried in his residence in Ruginoasa, but were moved to the Trei Ierarhi Cathedral in Iași after World War II.

</doc>
<doc id="46001" url="http://en.wikipedia.org/wiki?curid=46001" title="Web browser engine">
Web browser engine

A web browser engine (sometimes called layout engine or rendering engine) is a software component that takes marked up content (such as HTML, XML, image files, etc.) and formatting information (such as CSS, XSL, etc.) and displays the formatted content on the screen. It draws onto the content area of a window, which is displayed on a monitor or a printer. A layout engine is typically embedded in web browsers, e-mail clients, e-book readers, on-line help systems or other applications that require the displaying (and editing) of web content. Engines may wait for all data to be received before rendering a page, or may begin rendering before all data are received. This can result in pages changing as more data is received, such as images being filled in or a flash of unstyled content if rendering begins before formatting information is received.
Examples.
KDE's open-source KHTML engine is used in KDE's Konqueror web browser and was the basis for WebKit, the rendering engine in Apple's Safari and Google's Chrome web browsers, which is now the most widely used browser engine according to StatCounter. Current versions of Chromium/Chrome (except iOS version) and Opera are based on Blink, a fork of WebKit.
Gecko, the Mozilla project's open-source web browser engine, is used by a variety of products derived from the Mozilla code base, including the Firefox web browser, the Thunderbird e-mail client, and SeaMonkey internet suite.
Trident, the web browser engine from Internet Explorer, is used by many applications on the Microsoft Windows platform, such as netSmart, Outlook Express, some versions of Microsoft Outlook, and the mini-browsers in Winamp and RealPlayer.
Opera Software's proprietary Presto engine is licensed to a number of other software vendors, and was used in Opera's own web browser until it was switched to Blink in 2013.
MARTHA (layout engine) is a proprietary software engine developed with Java by RealObjects. The vendor prefix for MARTHA is codice_1
Technical operation.
The first web browsers were monolithic. They used various techniques inherited from text processing, such as regular expressions, to parse HTML into a visual representation. Later they adopted a more modular approach and were split into a host application and an engine.
This modular approach has the advantage that it then becomes easy to embed web-browser engines in a variety of applications. For example, the same engine used by a web browser can be used by an email client to display HTML email. On-line help systems integrated in applications have largely moved from using custom formats to using standard HTML displayed with a web-browser engine. The EPUB 3 e-book standard uses a layout engine to render XHTML and CSS.

</doc>
<doc id="46002" url="http://en.wikipedia.org/wiki?curid=46002" title="Pax Americana">
Pax Americana

Pax Americana (Latin for "American Peace") is a term applied to the historical concept of relative peace in the Western Hemisphere and later the Western world resulting from the preponderance of power enjoyed by the United States beginning around the middle of the 20th century. Although the term finds its primary utility in the latter half of the 20th century, it has been used in various places and eras, such as the post-Civil War era in North America, and regionally in the Americas at the start of the 20th century.
"Pax Americana" is primarily used in its modern connotations to refer to the peace among great powers established after the end of World War II in 1945, also called the long peace. In this modern sense, it has come to indicate the military and economic position of the United States in relation to other nations. For example the Marshall Plan, which spent $13 billion to rebuild the economy of Western Europe, has been seen as "the launching of the pax americana."
The Latin term derives from "Pax Romana" of the Roman Empire, which in turn inspired the phrases "Pax Britannica" for the British Empire, and "Pax Mongolica" for the Mongol Empire.
Early period.
The first articulation of a "Pax Americana" occurred after the end of the American Civil War with reference to the peaceful nature of the North American geographical region, and was abeyant at the commencement of the First World War. Its emergence was concurrent with the development of the idea of American exceptionalism. This view holds that the U.S. occupies a special niche among developed nations in terms of its national credo, historical evolution, political and religious institutions, and unique origins. The concept originates from Alexis de Tocqueville, who asserted that the then-50-year-old United States held a special place among nations because it was a country of immigrants and the first modern democracy. From the establishment of the United States after the American Revolution until the Spanish–American War, the foreign policy of the United States had a regional, instead of global, focus. The Pax Americana, which the Union enforced upon the states of central North America, was a factor in the United States' national prosperity. The larger states were surrounded by smaller states, but these had no anxieties: no standing armies to require taxes and hinder labor; no wars or rumors of wars that would interrupt trade; there is not only peace, but security, for the Pax Americana of the Union covered all the states within the federal constitutional republic. According to the Oxford English Dictionary, the first time the phrase appeared in print was in the August 1894 issue of "Forum": "The true cause for exultation is the universal outburst of patriotism in support of the prompt and courageous action of President Cleveland in maintaining the supremacy of law throughout the length and breadth of the land, in establishing the "pax Americana"."
With the rise of the New Imperialism in the Western hemisphere at the end of the 19th century, debates arose between imperialist and isolationist factions in the U.S. Here, "Pax Americana" was used to connote the peace across the United States and, more widely, as a Pan-American peace under the aegis of the Monroe Doctrine. Those who favored traditional policies of avoiding foreign entanglements included labor leader Samuel Gompers and steel tycoon Andrew Carnegie. American politicians such as Henry Cabot Lodge, William McKinley, and Theodore Roosevelt advocated an aggressive foreign policy, but the administration of President Grover Cleveland was unwilling to pursue such actions. On January 16, 1893, U.S. diplomatic and military personnel conspired with a small group of individuals to overthrow the constitutional government of the Kingdom of Hawaii and establish a Provisional Government and then a republic. On February 15, they presented a treaty for annexation of the Hawaiian Islands to the U.S. Senate, but opposition to annexation stalled its passage. The United States finally opted to annex Hawaii by way of the Newlands Resolution in July 1898.
After its victory in the Spanish–American War of 1898 and the subsequent acquisition of Cuba, Puerto Rico, the Philippines, and Guam, the United States had gained a colonial empire. By ejecting Spain from the Americas, the United States shifted its position to an uncontested regional power, and extended its influence into Southeast Asia and Oceania. Although U.S. capital investments within the Philippines and Puerto Rico were relatively small, these colonies were strategic outposts for expanding trade with Latin America and Asia, particularly China. In the Caribbean area, the United States established a sphere of influence in line with the Monroe Doctrine, not explicitly defined as such, but recognized in effect by other governments and accepted by at least some of the republics in that area. The events around the start of the 20th century demonstrated that the United States undertook an obligation, usual in such cases, of imposing a "Pax Americana". As in similar instances elsewhere, this Pax Americana was not quite clearly marked in its geographical limit, nor was it guided by any theoretical consistency, but rather by the merits of the case and the test of immediate expediency in each instance. Thus, whereas the United States enforced a peace in much of the lands southward from the Nation and undertook measures to maintain internal tranquility in such areas, the United States on the other hand withdrew from interposition in Mexico.
European powers largely regarded these matters as the concern of the United States. Indeed, the nascent Pax Americana was, in essence, abetted by the policy of the United Kingdom, and the preponderance of global sea power which the British Empire enjoyed by virtue of the strength of the Royal Navy. Preserving the freedom of the seas and ensuring naval dominance had been the policy of the British since victory in the Napoleonic Wars. As it was not in the interests of the United Kingdom to permit any European power to interfere in Americas, the Monroe Doctrine was indirectly aided by the Royal Navy. British commercial interests in South America, which comprised a valuable component of the Informal Empire that accompanied Britain's imperial possessions, and the economic importance of the United States as a trading partner, ensured that intervention by Britain's rival European powers could not engage with the Americas.
The United States lost its Pacific and regionally bounded nature towards the end of the 19th century. The government adopted protectionism after the Spanish–American War and built up the navy, the "Great White Fleet", to expand the reach of U.S. power. When Theodore Roosevelt became President in 1901, he accelerated a foreign policy shift away from isolationism towards foreign intervention which had begun under his predecessor, William McKinley. The Philippine–American War arose from the ongoing Philippine Revolution against imperialism. Interventionism found its formal articulation in the 1904 Roosevelt Corollary to the Monroe Doctrine, proclaiming the right of the United States to intervene in the affairs of weak states in the Americas in order to stabilize them, a moment that underlined the emergent U.S. regional hegemony.
Interwar period.
The United States had been criticized for not taking up the hegemonic mantle following the disintegration of "Pax Britannica" before the First World War and during the interwar period due to the absence of established political structures, such as the World Bank or United Nations which would be created after World War II, and various internal policies, such as protectionism. Though, the United States participated in the Great War, according to Woodrow Wilson, to:
[...] to vindicate the principles of peace and justice in the life of the world as against selfish and autocratic power and to set up amongst the really free and self-governed peoples of the world such a concert of purpose and of action as will henceforth insure the observance of those principles.
[...] for democracy, for the right of those who submit to authority to have a voice in their own government, for the rights and liberties of small nations, for a universal dominion of right by such a concert of free peoples as shall bring peace and safety to all nations and make the world itself at last free.
The United States' entry into the Great War marked the abandonment of the traditional American policy of isolation and independence of world politics. Not at the close of the Civil War, not as the result of the Spanish War, but in the Interwar period did the United States become a part of the international system. With this global reorganization from the Great War, there were those in the American populace that advocated an activist role in international politics and international affairs by the United States. Activities that were initiated did not fall into political-military traps and, instead, focused on economic-ideological approaches that would increase the American Empire and general worldwide stability. Following the prior path, a precursor to the United Nations and a league to enforce peace, the League of Nations, was proposed by Woodrow Wilson. This was rejected by the American Government in favor of more economic-ideological approaches and the United States did not join the League. Additionally, there were even proposals of extending the Monroe Doctrine to Great Britain put forth to prevent a second conflagration on the European theater. Ultimately, the United States' proposals and actions did not stop the factors of European nationalism spawned by the previous war, the repercussions of Germany's defeat, and the failures of the Treaty of Versailles from plunging the globe into a Second World War.
Between World War I and World War II, America also sought to continue to preserve "Pax America" as a corollary to the Monroe Doctrine. Some sought the peaceful and orderly evolution of existing conditions in the western hemisphere and nothing by immediate changes. Before 1917, the position of the United States government and the feelings of the nation in respect to the "Great War" initially had properly been one of neutrality. Its interests remained untouched, and nothing occurred of a nature to affect those interests.
The average American's sympathies, on the other hand, if the feelings of the vast majority of the nation had been correctly interpreted, was with the Allied (Entente) Powers. The population of the United States was revolted at the ruthlessness of the Prussian doctrine of war, and German designs to shift the burden of aggression encountered skeptical derision. The American populace saw themselves safeguarding liberal peace in the Western World. To this end, the American writer Roland Hugins stated:
The truth is that the United States is the only high-minded Power left in the world. It is the only strong nation that has not entered on a career of imperial conquest, and does not want to enter on it. [...] There is in America little of that spirit of selfish aggression which lies at the heart of militarism. Here alone exists a broad basis for "a new passionate sense of brotherhood, and a new scale of human values." We have a deep abhorrence of war for war's sake; we are not enamored of glamour or glory. We have a strong faith in the principle of self-government. We do not care to dominate alien peoples, white or colored; we do not aspire to be the Romans of tomorrow or the "masters of the world." The idealism of Americans centers in the future of America, wherein we hope to work out those principles of liberty and democracy to which we are committed This political idealism, this strain of pacifism, this abstinence from aggression and desire to be left alone to work out our own destiny, has been manifest from the birth of the republic. We have not always followed our light, but we have never been utterly faithless to it.
It was observed during this time that the initial defeat of Germany opened a moral recasting of the world. The battles between Germans and Allies were seen as far less battles between different nations than they represent the contrast between Liberalism and reaction, between the aspirations of democracy and the Wilhelminism gospel of iron.
Modern period.
The modern "Pax Americana" era is cited by both supporters and critics of U.S. foreign policy after World War II. However, from 1946 to 1992 "Pax americana" is considered a partial international order, as it applied only to capitalist block countries, being preferable for some authors to speak about a "Pax americana et sovietica". Many commentators and critics focus on American policies from 1992 to the present, and as such, it carries different connotations depending on the context. For example, it appears three times in the 90 page document, "Rebuilding America's Defenses," by the Project for the New American Century, but is also used by critics to characterize American dominance and hyperpower as imperialist in function and basis. From about the mid-1940s until 1991, U.S. foreign policy was dominated by the Cold War, and characterized by its significant international military presence and greater diplomatic involvement. Seeking an alternative to the isolationist policies pursued after World War I, the United States defined a new policy called containment to oppose the spread of communism.
The modern "Pax Americana" may be seen as similar to the period of peace in Rome, "Pax Romana". In both situations, the period of peace was 'relative peace'. During both "Pax Romana" and "Pax Americana" wars continued to occur, but it was still a prosperous time for both Western and Roman civilizations. It is important to note that during these periods, and most other times of relative tranquility, the peace that is referred to does not mean complete peace. Rather, it simply means that the civilization prospered in their military, agriculture, trade, and manufacturing.
"Pax Britannica" heritage.
From the end of the Napoleonic Wars in 1815 until World War I in 1914, the United Kingdom played the role of hegemon, where the balance of power was the main aim. It was also in this time that the British Empire became the largest empire of all time. The global superiority of British military and commerce was guaranteed by dominance of a Europe lacking in strong nation-states, and the presence of the Royal Navy on all of the world's oceans and seas. In 1905, the Royal Navy was superior to any two navies combined in the world. It provided services such as suppression of piracy and slavery. In this era of peace, though, there were several wars between the major powers: the Crimean War, the Franco-Austrian War, the Austro-Prussian War, the Franco-Prussian War, and the Russo-Japanese War, as well as numerous other wars.
During the British hegemony, America developed close ties with Britain, evolving into what has become known as a "special relationship" between the two. The many commonalities shared with the two nations (such as language and history) drew them together as allies. Under the managed transition of the British Empire to the Commonwealth of Nations, members of the British government, such as Harold Macmillan, liked to think of Britain's relationship with America as similar to that of a progenitor Greece to America's Rome. Throughout the years, both have been active in North American, Middle Eastern, and Asian countries.
Late 20th century.
After the Second World War, no armed conflict emerged among major Western nations themselves, and no nuclear weapons were used in open conflict. The United Nations was also soon developed after World War II to help keep peaceful relations between nations and establishing the veto power for the permanent members of the UN Security Council, which included the United States.
In the second half of the 20th century, the USSR and USA superpowers were engaged in the Cold War, which can be seen as a struggle between hegemonies for global dominance. After 1945, the United States enjoyed an advantageous position with respect to the rest of the industrialized world. Post–World War II economic expansion was then responsible for half of global industrial output, held 80 percent of the world's gold reserves, and was the world's sole nuclear power. The catastrophic destruction of life, infrastructure, and capital during the Second World War had exhausted the imperialism of the Old World, victor and vanquished alike. The largest economy in the world at the time, the United States recognized that it had come out of the war with its domestic infrastructure virtually unscathed and its military forces at unprecedented strength. Military officials recognized the fact that Pax Americana had been reliant on the effective United States air power, just as the instrument of Pax Britannica a century earlier was its sea power. In addition, a "unipolar moment" was seen to have occurred following the collapse of the Soviet Union.
The term "Pax Americana" was explicitly used by John F. Kennedy in the 1960s, who advocated against the idea, arguing that the Soviet bloc was composed of human beings with the same individual goals as Americans and that such a peace based on "American weapons of war" was undesirable:
"I have, therefore, chosen this time and place to discuss a topic on which ignorance too often abounds and the truth too rarely perceived. And that is the most important topic on earth: peace. What kind of peace do I mean and what kind of a peace do we seek? Not a "Pax Americana" enforced on the world by American weapons of war. Not the peace of the grave or the security of the slave. I am talking about genuine peace, the kind of peace that makes life on earth worth living, and the kind that enables men and nations to grow, and to hope, and build a better life for their children -- not merely peace for Americans but peace for all men and women, not merely peace in our time but peace in all time.
Beginning around the Vietnam War, the 'Pax Americana' term had started to be used by the critics of American Imperialism. Here in the late 20th century conflict between the Soviet Union and the United States, the charge of "Neocolonialism" was often aimed at Western involvement in the affairs of the Third World and other developing nations.
Contemporary power.
The modern "Pax Americana" derives partly from the direct influence of the United States, but as significantly or more so from international institutions backed by American financing and diplomacy. The United States invested heavily in programs such as the Marshall Plan and in the reconstruction of Japan, economically cementing defense ties that owed increasingly to the establishment of the Iron Curtain/Eastern Bloc and the widening of the Cold War.
But in the best position to take advantage of free trade, culturally indisposed to traditional empires, and alarmed by the rise of communism in China and the detonation of the first Soviet atom bomb, the historically non-interventionist U.S. also took a keen interest in developing multilateral institutions which would maintain a favorable world order among them. The International Monetary Fund and International Bank for Reconstruction and Development (World Bank), part of the Bretton Woods system of international financial management was developed and, until the early 1970s, the existence of a fixed exchange rate to the US dollar. The General Agreement on Tariffs and Trade (GATT) was developed and consists of a protocol for normalization and reduction of trade tariffs.
Other programs and organizations also helped further American power or state policy. North Atlantic Treaty Organisation (NATO), a collective security agreement of Atlantic powers, the mutual defense treaties with Japan and South Korea, and to a far lesser extent the Southeast Asia Treaty Organization (SEATO). With the fall of the Iron Curtain, the demise of the notion of a "Pax Sovietica", and the end of the Cold War, the U.S. maintained significant contingents of armed forces in Europe and East Asia.
The institutions behind the Pax Americana and the rise of the United States unipolar power have persisted into the early 21st century. The ability of the United States to act as "the world's policeman" has been constrained by its own citizens' historic aversion to foreign wars. Though there has been calls for the continuation of military leadership, as stated in "Rebuilding America's Defenses":
The American peace has proven itself peaceful, stable, and durable. It has, over the past decade, provided the geopolitical framework for widespread economic growth and the spread of American principles of liberty and democracy. Yet no moment in international politics can be frozen in time; even a global "Pax Americana" will not preserve itself. [... What is required is] a military that is strong and ready to meet both present and future challenges; a foreign policy that boldly and purposefully promotes American principles abroad; and national leadership that accepts the United States’ global responsibilities.
This is reflected in the research of American exceptionalism, which shows that "there is some indication for [being a leader of an "American peace"] among the [U.S.] public, but very little evidence of unilateral attitudes". It should be noted that resentments have arisen at a country's' dependence on American military protection, due to disagreements with United States foreign policy or the presence of American military forces.
In the "post-communism" world of the 21st-century, the French Socialist politician Hubert Védrine describes the USA as a hegemonic hyperpower, while the U.S. political scientists John Mearsheimer and Joseph Nye counter that the USA is not a “true” hegemony, because it does not have the resources to impose a proper, formal, global rule; despite its political and military strength, the USA is economically equal to Europe, thus, cannot rule the international stage. Several other countries are either emerging or re-emerging as powers, such as China, Russia, India, and the European Union.
American imperialism.
"American imperialism" is a term referring to outcomes or ideological elements of United States foreign policy. Since the start of the cold war, the United States has economically and/or diplomatically supported friendly foreign governments, including many that overtly violated the civil and human rights of their own citizens and residents. American imperialism concepts were initially a product of capitalism critiques and, later, of theorists opposed to what they take to be aggressive United States policies and doctrines. Although there are various views of the imperialist nature of the United States, which describe many of the same policies and institutions as evidence of imperialism, explanations for imperialism vary widely. In spite of such literature, the historians Archibald Paton Thorton and Stuart Creighton Miller argue against the very coherence of the concept. Miller argues that the overuse and abuse of the term "imperialism" makes it nearly meaningless as an analytical concept.
More specifically, critics of American influence contend that the Bush Doctrine of advancing democracy throughout all the world is all that is needed to justify the term "American Imperialism". On the other hand, advocates of American influence define imperialism as colonialism to some degree and claim protectionism, rather than imperialism, as the rationale for recent American international behavior. Such people emphasize that American history of returning governance back to indigenous people, supporting decolonization, and insisting on a rejection of previous isolationist policies, do not constitute the embrace of imperialism.
Regardless, it is acknowledged that American isolationism subsided only after major shocks associated with the Spanish-American War and the two world wars. Critics such as Howard Zinn and Noam Chomsky argue that the United States has sought, or has found itself forced into, a quasi-imperialist role by its status as the world's sole superpower.
As to the "isolationist" history of the United States, it mainly applies to the global stage; the United States has not been isolationist with respect to the Western Hemisphere, which fell within its sphere of influence, and pursued military interventions within this region of the world. Though relative peace existed in the Western world, the United States and its allies have been involved in various regional wars, such as the Korean War, the Vietnam War, the Gulf War, the Yugoslav wars, the Afghanistan War and the Iraq War. The United States also maintained espionage and covert operations in various other areas, such as Latin America in the 1980s.
Democratic peace theory.
The increasing peacefulness during the various incarnations of Pax Americana has been attributed to the ongoing spread of democracy. Democratic peace theory hold that democracies rarely, or never, make war on one another and results in a "Pax Universalis".
Further reading.
</dl>

</doc>
<doc id="46003" url="http://en.wikipedia.org/wiki?curid=46003" title="Common Language Runtime">
Common Language Runtime

The Common Language Runtime (CLR), the virtual machine component of Microsoft's .NET framework, manages the execution of .NET programs. A process known as just-in-time compilation converts compiled code into machine instructions which the computer's CPU then executes. The CLR provides additional services including memory management, type safety, exception handling, garbage collection, security and thread management. All programs written for the .NET framework, regardless of programming language, are executed by the CLR. All versions of the .NET framework include CLR.
CLR implements the Virtual Execution System (VES) as defined in the Common Language Infrastructure (CLI) standard, initially developed by Microsoft itself. A public standard defines the Common Language Infrastructure specification.
Benefits.
The runtime provides the following benefits:

</doc>
<doc id="46004" url="http://en.wikipedia.org/wiki?curid=46004" title="Common Intermediate Language">
Common Intermediate Language

Common Intermediate Language (CIL, pronounced either "sil" or "kil") (formerly called Microsoft Intermediate Language or MSIL) is the lowest-level human-readable programming language defined by the Common Language Infrastructure (CLI) specification and is used by the .NET Framework and Mono. Languages which target a CLI-compatible runtime environment compile to CIL, which is assembled into an object code that has a bytecode-style format. CIL is an object-oriented assembly language, and is entirely stack-based. Its bytecode is translated into native code or — most commonly — executed by a virtual machine.
CIL was originally known as Microsoft Intermediate Language (MSIL) during the beta releases of the .NET languages. Due to standardization of C# and the Common Language Infrastructure, the bytecode is now officially known as CIL.
In an independent usage, CIL also refers to the C Intermediate Language, a simplified transformation of C used for further analysis.
General information.
During compilation of CLI programming languages, the source code is translated into CIL code rather than into platform- or processor-specific object code. CIL is a CPU- and platform-independent instruction set that can be executed in any environment supporting the Common Language Infrastructure, such as the .NET runtime on Windows, or the cross-platform Mono runtime. In theory, this eliminates the need to distribute different executable files for different platforms and CPU types. CIL code is verified for safety during runtime, providing better security and reliability than natively compiled executable files.
The execution process looks like this:
Instructions.
CIL bytecode has instructions for the following groups of tasks:
Computational model.
The Common Intermediate Language is object-oriented and stack-based. That means that data are pushed on a stack instead of pulled from registers as in most CPU architectures.
In x86 it might look like this:
The corresponding code in IL can be rendered as this:
Here are two locals that are pushed on the stack. When the add-instruction is called the operands get popped and the result is pushed. The remaining value is then popped and stored in the first local.
Object-oriented concepts.
This extends to object-oriented concepts as well. You may create objects, call methods and use other types of members such as fields.
CIL is designed to be object-oriented and every method needs (with some exceptions) to reside in a class. So does this static method:
This method does not require any instance of Foo to be declared because it is static. That means it belongs to the class and it may then be used like this in C#:
In CIL:
Instance classes
An instance class contains at least one constructor and some instance members. This class has a set of methods representing actions of a Car-object.
Creating objects
In C# class instances are created like this:
And these statements are roughly the same as these instructions:
Invoking instance methods
Instance methods are invoked like the one that follows:
In CIL:
Metadata.
CLI records information about compiled classes as Metadata. Like the type library in the Component Object Model, this enables applications to support and discover the interfaces, classes, types, methods, and fields in the assembly. The process of reading such metadata is called "reflection".
Metadata can be data in the form of " attributes". Attributes can be custom made by extending from the codice_1 class. This is a very powerful feature. It allows the creator of the class the ability to adorn it with extra information that consumers of the class can use in various meaningful ways depending on the application domain.
Example.
Below is a basic Hello, World program written in CIL. It will display the string "Hello, world!".
The following code is more complex in number of opcodes.
"This code can also be compared with the corresponding code in the article about Java bytecode."
In CIL syntax it looks like this:
This is just a representation of how CIL looks like near VM-level. When compiled the methods are stored in tables and the instructions are stored as bytes inside the assembly, which is a Portable Executable (PE).
Generation.
A CIL assembly and instructions are generated by either a compiler or a utility called the "IL Assembler" (ILAsm) that is shipped with the execution environment.
Assembled IL can also be disassembled into code again using the "IL Disassembler" (ILDASM). There are other tools such as .NET Reflector that can decompile IL into a high-level language (e. g. C# or Visual Basic). This makes IL a very easy target for reverse engineering. This trait is shared with Java bytecode. However, there are tools that can obfuscate the code, and do it so that the code cannot be easily readable but still be runnable.
Execution.
Just-in-time compilation.
Just-in-time compilation (JIT) involves turning the byte-code into code immediately executable by the CPU. The conversion is performed gradually during the program's execution. JIT compilation provides environment-specific optimization, runtime type safety, and assembly verification. To accomplish this, the JIT compiler examines the assembly metadata for any illegal accesses and handles violations appropriately.
Ahead-of-time compilation.
CLI-compatible execution environments also come with the option to do an Ahead-of-time compilation (AOT) of an assembly to make it execute faster by removing the JIT process at runtime.
In the .NET Framework there is a special tool called the Native Image Generator (NGEN) that performs the AOT. In Mono there is also an option to do an AOT.
Pointer instructions - C++/CLI.
A huge difference from Java's bytecode is that CIL comes with ldind, stind, ldloca, and many call instructions which are enough for data/function pointers manipulation needed to compile C/C++ code into CIL.
The corresponding code in IL can be rendered as this:

</doc>
<doc id="46006" url="http://en.wikipedia.org/wiki?curid=46006" title="Freedom of religion">
Freedom of religion

Freedom of religion or freedom of belief is a principle that supports the freedom of an individual or community, in public or private, to manifest religion or belief in teaching, practice, worship, and observance; the concept is generally recognized also to include the freedom to change religion or not to follow any religion. The freedom to leave or discontinue membership in a religion or religious group—in religious terms called "apostasy"—is also a fundamental part of religious freedom, covered by Article 18 of United Nations' 1948 Universal Declaration of Human Rights.
Freedom of religion is considered by many people and nations to be a fundamental human right. In a country with a state religion, freedom of religion is generally considered to mean that the government permits religious practices of other sects besides the state religion, and does not persecute believers in other faiths.
History.
Historically, "freedom of religion" has been used to refer to the tolerance of different theological systems of belief, while "freedom of worship" has been defined as freedom of individual action. Each of these have existed to varying degrees. While many countries have accepted some form of religious freedom, this has also often been limited in practice through punitive taxation, repressive social legislation, and political disenfranchisement. Compare examples of individual freedom in Italy or the Muslim tradition of dhimmis, literally "protected individuals" professing an officially tolerated non-Muslim religion.
In Antiquity, a syncretic point of view often allowed communities of traders to operate under their own customs. When street mobs of separate quarters clashed in a Hellenistic or Roman city, the issue was generally perceived to be an infringement of community rights.
Cyrus the Great established the Achaemenid Empire ca. 550 BC, and initiated a general policy of permitting religious freedom throughout the empire, documenting this on the Cyrus Cylinder.
Some of the historical exceptions have been in regions where one of the revealed religions has been in a position of power: Judaism, Zoroastrianism, Christianity and Islam. Others have been where the established order has felt threatened, as shown in the trial of Socrates in 399 BC or where the ruler has been deified, as in Rome, and refusal to offer token sacrifice was similar to refusing to take an oath of allegiance. This was the core for resentment and the persecution of early Christian communities.
Freedom of religious worship was established in the Buddhist Maurya Empire of ancient India by Ashoka the Great in the 3rd century BC, which was encapsulated in the Edicts of Ashoka.
Greek-Jewish clashes at Cyrene in 73 AD and 117 AD and in Alexandria in 115 AD provide examples of cosmopolitan cities as scenes of tumult.
Muslim world.
Following a period of fighting lasting around a hundred years before 620 AD which mainly involved Arab and Jewish inhabitants of Medina (then known as "Yathrib"), religious freedom for Muslims, Jews and pagans were declared by Muhammad in the Constitution of Medina. The Islamic Caliphate later guaranteed religious freedom under the conditions that non-Muslim communities accept "dhimmi" (second class) status and their adult males pay the "jizya" tax as a substitute for the "zakat" paid by Muslim citizens.
Religious pluralism existed in classical Islamic ethics and Sharia law, as the religious laws and courts of other religions, including Christianity, Judaism and Hinduism, were usually accommodated within the Islamic legal framework, as seen in the early Caliphate, Al-Andalus, Indian subcontinent, and the Ottoman Millet system. In medieval Islamic societies, the "qadi" (Islamic judges) usually could not interfere in the matters of non-Muslims unless the parties voluntarily choose to be judged according to Islamic law, thus the "dhimmi" communities living in Islamic states usually had their own laws independent from the Sharia law, such as the Jews who would have their own "Halakha" courts.
Dhimmis were allowed to operate their own courts following their own legal systems in cases that did not involve other religious groups, or capital offences or threats to public order. Non-Muslims were allowed to engage in religious practices that was usually forbidden by Islamic law, such as the consumption of alcohol and pork, as well as religious practices which Muslims found repugnant, such as the Zoroastrian practice of incestuous "self-marriage" where a man could marry his mother, sister or daughter. According to the famous Islamic legal scholar Ibn Qayyim (1292–1350), non-Muslims had the right to engage in such religious practices even if it offended Muslims, under the conditions that such cases not be presented to Islamic Sharia courts and that these religious minorities believed that the practice in question is permissible according to their religion.
India.
Religious freedom and the right to worship freely were practices that had been appreciated and promoted by most ancient Indian dynasties. As a result, people fleeing religious persecution in other parts of the world including Christians, Jews, Bahá'í Faith and Zoroastrians fled to India as a place of refuge to enjoy religious freedom.
Ancient Jews fleeing from persecution in their homeland 2,500 years ago settled in India and never faced anti-Semitism. Freedom of religion edicts have been found written during Ashoka the Great's reign in the 3rd century BC. Freedom to practise, preach and propagate any religion is a constitutional right in Modern India. Most major religious festivals of the main communities are included in the list of national holidays.
Although India is an 80% Hindu country, three out of the twelve presidents of India have been Muslims.
Many scholars and intellectuals believe that India's predominant religion, Hinduism, has long been a most tolerant religion. Rajni Kothari, founder of the Centre for the Study of Developing Societies has written, "[India] is a country built on the foundations of a civilisation that is fundamentally non-religious."
The Dalai Lama, the Tibetan leader in exile said that religious tolerance of 'Aryabhoomi,' a reference to India found in Mahabharata, has been in existence in this country from thousands of years. "Not only Hinduism, Jainism, Buddhism, Sikhism which are the native religions but also Christianity and Islam have flourished here. Religious tolerance is inherent in Indian tradition," the Dalai Lama said.
Freedom of religion in the Indian subcontinent is exemplified by the reign of King Piyadasi (304 BC to 232 BC) (Ashoka). One of King Ashoka's main concerns was to reform governmental institutes and exercise moral principles in his attempt to create a just and humane society. Later he promoted the principles of Buddhism, and the creation of a just, understanding and fair society was held as an important principle for many ancient rulers of this time in the East.
The importance of freedom of worship in India was encapsulated in an inscription of Ashoka:
King Piyadasi (Ashok) dear to the Gods, honours all sects, the ascetics (hermits) or those who dwell at home, he honours them with charity and in other ways. But the King, dear to the Gods, attributes less importance to this charity and these honours than to the vow of seeing the reign of virtues, which constitutes the essential part of them. For all these virtues there is a common source, modesty of speech. That is to say, one must not exalt one's creed discrediting all others, nor must one degrade these others without legitimate reasons. One must, on the contrary, render to other creeds the honour befitting them.
The initial entry of Islam into South Asia came in the first century after the death of the Islamic Prophet Muhammad. When around 1210 AD the Islamic Sultanates invaded India from the north-west, gradually the principle of freedom of religion deteriorated in this part of the world. They were subsequently replaced by another Islamic invader in the form of Babur. The Mughal empire was founded by the Mongol leader Babur in 1526, when he defeated Ibrahim Lodi, the last of the Delhi Sultans at the First Battle of Panipat. The word "Mughal" is the Indo-Iranian version of Mongol.
On the main Asian continent, the Mongols were tolerant of religions. People could worship as they wished freely and openly, though the formation of 2 nations i.e. Pakistan and Bangladesh has been on basis of religious intolerance.
After arrival of Europeans, Christians in zeal to convert local as per belief in conversion as service of God, have also been seen to fall into frivolous methods since their arrival. Though by and large there are hardly any reports of law and order disturbance from mobs with Christian beliefs except perhaps in the north eastern region of India.
Freedom of religion in contemporary India is a fundamental right guaranteed under Article 25 of the nation's constitution. Accordingly every citizen of India has a right to profess, practice and propagate their religions peacefully. Vishwa Hindu Parishad counters this argument by saying that evangelical Christians are forcefully (or through money) converting rural, illiterate populations and they are only trying to stop this.
In September 2010, Indian state Kerala's State Election Commissioner announced that "Religious heads cannot issue calls to vote for members of a particular community or to defeat the nonbelievers". The Catholic Church comprising Latin, Syro-Malabar and Syro-Malankara rites used to give clear directions to the faithful on exercising their franchise during elections through pastoral letters issued by bishops or council of bishops. The pastoral letter issued by Kerala Catholic Bishops' Council (KCBC) on the eve of the poll urged the faithful to shun atheists.
Even today, most Indians celebrate all religious festivals with equal enthusiasm and respect. Hindu festivals like Deepavali and Holi, Muslim festivals like Eid al-Fitr, Eid-Ul-Adha, Muharram, Christian festivals like Christmas and other festivals like Buddha Purnima, Mahavir Jayanti, Gur Purab etc. are celebrated and enjoyed by all Indians.
Europe.
Religious intolerance.
Most Roman Catholic kingdoms kept a tight rein on religious expression throughout the Middle Ages. Jews were alternately tolerated and persecuted, the most notable examples of the latter being the expulsion of all Jews from Spain in 1492. Some of those who remained and converted were tried as heretics in the Inquisition for allegedly practicing Judaism in secret. Despite the persecution of Jews, they were the most tolerated non-Catholic faith in Europe.
However, the latter was in part a reaction to the growing movement that became the Reformation. As early as 1380, John Wycliffe in England denied transubstantiation and began his translation of the Bible into English. He was condemned in a Papal Bull in 1410, and all his books were burned.
In 1414, Jan Hus, a Bohemian preacher of reformation, was given a safe conduct by the Holy Roman Emperor to attend the Council of Constance. Not entirely trusting in his safety, he made his will before he left. His forebodings proved accurate, and he was burned at the stake on 6 July 1415. The Council also decreed that Wycliffe's remains be disinterred and cast out. This decree was not carried out until 1429.
After the fall of the city of Granada, Spain, in 1492, the Muslim population was promised religious freedom by the Treaty of Granada, but that promise was short-lived. In 1501, Granada's Muslims were given an ultimatum to either convert to Christianity or to emigrate. The majority converted, but only superficially, continuing to dress and speak as they had before and to secretly practice Islam. The Moriscos (converts to Christianity) were ultimately expelled from Spain between 1609 (Castile) and 1614 (rest of Spain), by Philip III.
Martin Luther published his famous 95 Theses in Wittenberg on 31 October 1517. His major aim was theological, summed up in the three basic dogmas of Protestantism:
In consequence, Luther hoped to stop the sale of indulgences and to reform the Church from within. In 1521, he was given the chance to recant at the Diet of Worms before Charles V, Holy Roman Emperor, then only 19. After he refused to recant, he was declared heretic. Partly for his own protection, he was sequestered on the Wartburg in the possessions of Frederick III, Elector of Saxony, where he translated the New Testament into German. He was excommunicated by Papal Bull in 1521.
However, the movement continued to gain ground in his absence and spread to Switzerland. Huldrych Zwingli preached reform in Zürich from 1520 to 1523. He opposed the sale of indulgences, celibacy, pilgrimages, pictures, statues, relics, altars, and organs. This culminated in outright war between the Swiss cantons that accepted Protestantism and the Catholics. The Catholics were victorious, and Zwingli was killed in battle in 1531. The Catholic cantons were magnanimous in victory.
The defiance of Papal authority proved contagious, and in 1533, when Henry VIII of England was excommunicated for his divorce and remarriage to Anne Boleyn, he promptly established a state church with bishops appointed by the crown. This was not without internal opposition, and Thomas More, who had been his Lord Chancellor, was executed in 1535 for opposition to Henry.
In 1535, the Swiss canton of Geneva became Protestant. In 1536, the Bernese imposed the reformation on the canton of Vaud by conquest. They sacked the cathedral in Lausanne and destroyed all its art and statuary. John Calvin, who had been active in Geneva was expelled in 1538 in a power struggle, but he was invited back in 1540.
The same kind of seesaw back and forth between Protestantism and Catholicism was evident in England when Mary I of England returned that country briefly to the Catholic fold in 1553 and persecuted Protestants. However, her half-sister, Elizabeth I of England was to restore the Church of England in 1558, this time permanently, and began to persecute Catholics again. The King James Bible commissioned by King James I of England and published in 1611 proved a landmark for Protestant worship, with official Catholic forms of worship being banned.
In France, although peace was made between Protestants and Catholics at the Treaty of Saint Germain in 1570, persecution continued, most notably in the Massacre of Saint Bartholomew's Day on 24 August 1572, in which thousands of Protestants throughout France were killed. A few years before, at the "Michelade" of Nîmes in 1567, Protestants had massacred the local Catholic clergy.
Early steps and attempts in the way of tolerance.
The Norman Kingdom of Sicily under Roger II was characterized by its multi-ethnic nature and religious tolerance. Normans, Jews, Muslim Arabs, Byzantine Greeks, Lombards, and native Sicilians lived in harmony. Rather than exterminate the Muslims of Sicily, Roger II's grandson Emperor Frederick II of Hohenstaufen (1215—1250) allowed them to settle on the mainland and build mosques. Not least, he enlisted them in his – Christian – army and even into his personal bodyguards
Bohemia (present-day Czech Republic) enjoyed religious freedom between 1436 and 1520, and became one of the most liberal countries of the Christian world during that period of time. The so-called Basel Compacts of 1436 declared the freedom of religion and peace between Catholics and Utraquists. In 1609 Emperor Rudolf II granted Bohemia greater religious liberty with his Letter of Majesty. The privileged position of the Catholic Church in the Czech kingdom was firmly established after the Battle of White Mountain in 1620. Gradually freedom of religion in Bohemian lands came to an end and Protestants fled or were expelled from the country. A devout Catholic, Emperor Ferdinand II forcibly converted Austrian and Bohemian Protestants.
In the meantime, in Germany Philip Melanchthon drafted the Augsburg Confession as a common confession for the Lutherans and the free territories. It was presented to Charles V in 1530.
In the Holy Roman Empire, Charles V agreed to tolerate Lutheranism in 1555 at the Peace of Augsburg. Each state was to take the religion of its prince, but within those states, there was not necessarily religious tolerance. Citizens of other faiths could relocate to a more hospitable environment.
In France, from the 1550s, many attempts to reconcile Catholics and Protestants and to establish tolerance failed because the State was too weak to enforce them. It took the victory of prince Henry IV of France, who had converted into Protestantism, and his accession to the throne, to impose religious tolerance formalized in the Edict of Nantes in 1598. It would remain in force for over 80 years until its revocation in 1685 by Louis XIV of France. Intolerance remained the norm until Louis XVI, who signed the Edict of Versailles (1787), then the constitutional text of 24 December 1789, granting civilian rights to Protestants. The French Revolution then abolished state religion and confiscated all Church property, turning intolerance against Catholics.
Early laws and legal guarantees for religious freedom.
In 1558, the Transylvanian Diet of Torda declared free practice of both the Catholic and Lutheran religions, but prohibited Calvinism. Ten years later, in 1568, the Diet extended the freedom to all religions, declaring that "It is not allowed to anybody to intimidate anybody with captivity or expelling for his religion". However, it was more than a religious tolerance, it declared the equality of the religions. The emergence in social hierarchy wasn't depend on the religion of the person thus Transylvania had also Catholic and Protestant monarchs (Princes). The lack of state religion was unique for centuries in Europe. Therefore, the Edict of Torda is considered by mostly Hungarian historians as the first legal guarantee of religious freedom in Christian Europe.
 ACT OF RELIGIOUS TOLERANCE AND FREEDOM OF CONSCIENCE: 
His majesty, our Lord, in what manner he – together with his realm – legislated in the matter of religion at the previous Diets, in the same matter now, in this Diet, reaffirms that in every place the preachers shall preach and explain the Gospel each according to his understanding of it, and if the congregation like it, well. If not, no one shall compel them for their souls would not be satisfied, but they shall be permitted to keep a preacher whose teaching they approve. Therefore none of the superintendents or others shall abuse the preachers, no one shall be reviled for his religion by anyone, according to the previous statutes, and it is not permitted that anyone should threaten anyone else by imprisonment or by removal from his post for his teaching. For faith is the gift of God and this comes from hearing, which hearings is by the word of God.
 — Diet at Torda, 1568 : King John Sigismund
In the Union of Utrecht (20 January 1579), personal freedom of religion was declared in the struggle between the Northern Netherlands and Spain. The Union of Utrecht was an important step in the establishment of the Dutch Republic (from 1581 to 1795). Under Calvinist leadership, the Netherlands became the most tolerant country in Europe. It granted asylum to persecuted religious minorities, e.g. French Huguenots, English Dissenters, and Jews who had been expelled from Spain and Portugal. The establishment of a Jewish community in the Netherlands and New Amsterdam (present-day New York) during the Dutch Republic is an example of religious freedom. When New Amsterdam surrendered to the English in 1664, freedom of religion was guaranteed in the Articles of Capitulation. It benefitted also the Jews who had landed on Manhattan Island in 1654, fleeing Portuguese persecution in Brazil. During the 18th century, other Jewish communities were established at Newport, Rhode Island, Philadelphia, Charleston, Savannah, and Richmond.
Intolerance of dissident forms of Protestantism also continued, as evidenced by the exodus of the Pilgrims, who sought refuge, first in the Netherlands, and ultimately in America, founding Plymouth Colony in Massachusetts in 1620. William Penn, the founder of Philadelphia, was involved in a case which had a profound effect upon future American laws and those of England. In a classic case of jury nullification the jury refused to convict William Penn of preaching a Quaker sermon, which was illegal. Even though the jury was imprisoned for their acquittal, they stood by their decision and helped establish the freedom of religion.
Poland.
Poland has a long tradition of religious freedom. The right to worship freely was a basic right given to all inhabitants of the Commonwealth throughout the 15th and early 16th century, however, complete freedom of religion was officially recognized in Poland in 1573 during the Warsaw Confederation. Poland kept religious freedom laws during an era when religious persecution was an everyday occurrence in the rest of Europe.
The General Charter of Jewish Liberties known as the Statute of Kalisz was issued by the Duke of Greater Poland Boleslaus the Pious on 8 September 1264 in Kalisz. The statute served as the basis for the legal position of Jews in Poland and led to creation of the Yiddish-speaking autonomous Jewish nation until 1795. The statute granted exclusive jurisdiction of Jewish courts over Jewish matters and established a separate tribunal for matters involving Christians and Jews. Additionally, it guaranteed personal liberties and safety for Jews including freedom of religion, travel, and trade. The statute was ratified by subsequent Polish Kings: Casimir III of Poland in 1334, Casimir IV of Poland in 1453 and Sigismund I of Poland in 1539. The Commonwealth set a precedent by allowing Jews to become ennobled.
United States.
Most of the early colonies were generally not tolerant of dissident forms of worship, with Maryland being one of the exceptions. For example, Roger Williams found it necessary to found a new colony in Rhode Island to escape persecution in the theocratically dominated colony of Massachusetts. The Puritans of the Massachusetts Bay Colony were the most active of the New England persecutors of Quakers, and the persecuting spirit was shared by Plymouth Colony and the colonies along the Connecticut river. In 1660, one of the most notable victims of the religious intolerance was English Quaker Mary Dyer, who was hanged in Boston, Massachusetts for repeatedly defying a Puritan law banning Quakers from the colony. As one of the four executed Quakers known as the Boston martyrs, the hanging of Dyer on the Boston gallows marked the beginning of the end of the Puritan theocracy and New England independence from English rule, and in 1661 King Charles II explicitly forbade Massachusetts from executing anyone for professing Quakerism.
Freedom of religion was first applied as a principle of government in the founding of the colony of Maryland, founded by the Catholic Lord Baltimore, in 1634. Fifteen years later (1649), the Maryland Toleration Act, drafted by Lord Baltimore, provided: "No person or persons...shall from henceforth be any waies troubled, molested or discountenanced for or in respect of his or her religion nor in the free exercise thereof." The Maryland Toleration Act was repealed during the Cromwellian Era with the assistance of Protestant assemblymen and a new law barring Catholics from openly practicing their religion was passed. In 1657, the Catholic Lord Baltimore regained control after making a deal with the colony's Protestants, and in 1658 the Act was again passed by the colonial assembly. This time, it would last more than thirty years, until 1692 when, after Maryland's Protestant Revolution of 1689, freedom of religion was again rescinded. In addition, in 1704, an Act was passed "to prevent the growth of Popery in this Province", preventing Catholics from holding political office. Full religious toleration would not be restored in Maryland until the American Revolution, when Maryland's Charles Carroll of Carrollton signed the American Declaration of Independence.
Rhode Island (1636), Connecticut (1636), New Jersey, and Pennsylvania (1682)—founded by Protestants Roger Williams, Thomas Hooker, and William Penn, respectively—combined the democratic form of government which had been developed by the Puritans and the Separatist Congregationalists in Massachusetts with religious freedom. These colonies became sanctuaries for persecuted religious minorities. Catholics and later on Jews also had full citizenship and free exercise of their religions. Williams, Hooker, Penn, and their friends were firmly convinced that freedom of conscience was the will of God. Williams gave the most profound argument: As faith is the free work of the Holy Spirit, it cannot be forced on a person. Therefore strict separation of church and state has to be kept. Pennsylvania was the only colony that retained unlimited religious freedom until the foundation of the United States in 1776. It was the inseparable connection between democracy, religious freedom, and the other forms of freedom which became the political and legal basis of the new nation. In particular, Baptists and Presbyterians demanded the disestablishment of state churches - Anglican and Congregationalist - and the protection of religious freedom.
Reiterating Maryland's and the other colonies' earlier colonial legislation, the Virginia Statute for Religious Freedom, written in 1779 by Thomas Jefferson, proclaimed:
[N]o man shall be compelled to frequent or support any religious worship, place, or ministry whatsoever, nor shall be enforced, restrained, molested, or burthened in his body or goods, nor shall otherwise suffer, on account of his religious opinions or belief; but that all men shall be free to profess, and by argument to maintain, their opinions in matters of religion, and that the same shall in no wise diminish, enlarge, or affect their civil capacities.
Those sentiments also found expression in the First Amendment of the national constitution, part of the United States' Bill of Rights: "Congress shall make no law respecting an establishment of religion, or prohibiting the free exercise thereof..."
The United States formally considers religious freedom in its foreign relations. The International Religious Freedom Act of 1998 established the United States Commission on International Religious Freedom which investigates the records of over 200 other nations with respect to religious freedom, and makes recommendations to submit nations with egregious records to ongoing scrutiny and possible economic sanctions. Many human rights organizations have urged the United States to be still more vigorous in imposing sanctions on countries that do not permit or tolerate religious freedom.
Canada.
Freedom of religion in Canada is a constitutionally protected right, allowing believers the freedom to assemble and worship without limitation or interference. Canadian law goes further, requiring that private citizens and companies provide reasonable accommodation to those, for example, with strong religious beliefs. The Canadian Human Rights Act allows an exception to reasonable accommodation with respect to religious dress, such as a Sikh turban, when there is a "bona fide" occupational requirement, such as a workplace requiring a hard hat.
International.
On 25 November 1981, the United Nations General Assembly passed the "Declaration on the Elimination of All Forms of Intolerance and of Discrimination Based on Religion or Belief". This declaration recognizes freedom of religion as a fundamental human right in accordance with several other instruments of international law, but the international community has not passed any binding legal instruments that guarantee the right to freedom of religion.
Contemporary debates.
Theistic, non-theistic and atheistic beliefs.
In 1993, the UN's human rights committee declared that article 18 of the International Covenant on Civil and Political Rights "protects theistic, non-theistic and atheistic beliefs, as well as the right not to profess any religion or belief." The committee further stated that "the freedom to have or to adopt a religion or belief necessarily entails the freedom to choose a religion or belief, including the right to replace one's current religion or belief with another or to adopt atheistic views." Signatories to the convention are barred from "the use of threat of physical force or penal sanctions to compel believers or non-believers" to recant their beliefs or convert. Despite this, minority religions still are still persecuted in many parts of the world.
Within the United States, the Freedom From Religion Foundation argues that the United States Constitution not only prohibits the intrusion of religion into the processes of government, but also guarantees equal rights to citizens who choose not to follow any religion. Conservative sociopolitical commentator Bryan Fischer has responded: "The Constitution guarantees freedom of religion, not freedom from religion."
Liberal secular.
Adam Smith, in his book "The Wealth of Nations" (using an argument first put forward by his friend and contemporary David Hume), states that in the long run it is in the best interests of society as a whole and the civil magistrate (government) in particular to allow people to freely choose their own religion, as it helps prevent civil unrest and reduces intolerance. So long as there are enough different religions and/or religious sects operating freely in a society then they are all compelled to moderate their more controversial and violent teachings, so as to be more appealing to more people and so have an easier time attracting new converts. It is this free competition amongst religious sects for converts that ensures stability and tranquillity in the long run. 
Smith also points out that laws that prevent religious freedom and seek to preserve the power and belief in a particular religion will, in the long run, only serve to weaken and corrupt that religion, as its leaders and preachers become complacent, disconnected and unpractised in their ability to seek and win over new converts:
The interested and active zeal of religious teachers can be dangerous and troublesome only where there is either but one sect tolerated in the society, or where the whole of a large society is divided into two or three great sects; the teachers of each acting by concert, and under a regular discipline and subordination. But that zeal must be altogether innocent, where the society is divided into two or three hundred, or, perhaps, into as many thousand small sects, of which no one could be considerable enough to disturb the public tranquillity. The teachers of each sect, seeing themselves surrounded on all sides with more adversaries than friends, would be obliged to learn that candour and moderation which are so seldom to be found among the teachers of those great sects.
Hinduism.
Hinduism is one of the more open-minded religions when it comes to religious freedom. It respects the right of everyone to reach God in their own way. Hindus believe in different ways to preach attainment of God and religion as a philosophy and hence respect all religions as equal. One of the famous Hindu sayings about religion is: "Truth is one; sages call it by different names."
Judaism.
Judaism includes multiple streams, such as Orthodox, Reform Judaism, Conservative Judaism, Reconstructionist Judaism, Jewish Renewal and Humanistic Judaism. Israel, viewed as the Jewish homeland, has been evaluated in research by the Pew organization as having "high" government restrictions on religion. The government recognizes only Orthodox Judaism in certain matters of personal status, and marriages can only be performed by religious authorities. The government provides the greatest funding to Orthodox Judaism, even though adherents represent a minority of citizens. Jewish women have been arrested at the Western Wall for praying and singing while wearing religious garments the Orthodox feel should be reserved for men. Women of the Wall have organized to promote religious freedom at the Wall. In November 2014, a group of 60 non-Orthodox rabbinical students were told they would not be allowed to pray in the Knesset synagogue because it is reserved for Orthodox. Rabbi Joel Levy, director of the Conservative Yeshiva in Jerusalem, said that he had submitted the request on behalf of the students and saw their shock when the request was denied. He noted: "paradoxically, this decision served as an appropriate end to our conversation about religion and state in Israel." MK Dov Lipman expressed the concern that many Knesset workers are unfamiliar with non-Orthodox and American practices and would view "an egalitarian service in the synagogue as an affront."
Christianity.
 According to the Catholic Church in the Vatican II document on religious freedom, "Dignitatis Humanae", "the human person has a right to religious freedom", which is described as "immunity from coercion in civil society". This principle of religious freedom "leaves untouched traditional Catholic doctrine on the moral duty of men and societies toward the true religion." In addition, this right "is to be recognized in the constitutional law whereby society is governed and thus it is to become a civil right."
Prior to this, Pope Pius IX had written a document called the "Syllabus of Errors. "The Syllabus was made up of phrases and paraphrases from earlier papal documents, along with index references to them, and presented as a list of "condemned propositions". It does not explain why each particular proposition is wrong, but it cites earlier documents to which the reader can refer for the Pope's reasons for saying each proposition is false. Among the statements included in the Syllabus are: "[It is an error to say that] Every man is free to embrace and profess that religion which, guided by the light of reason, he shall consider true" (15); "[It is an error to say that] In the present day it is no longer expedient that the Catholic religion should be held as the only religion of the State, to the exclusion of all other forms of worship" (77); "[It is an error to say that] Hence it has been wisely decided by law, in some Catholic countries, that persons coming to reside therein shall enjoy the public exercise of their own peculiar worship" (78).
Some Orthodox Christians, especially those living in democratic countries, support religious freedom for all, as evidenced by the position of the Ecumenical Patriarchate. Many Protestant Christian churches, including some Baptists, Churches of Christ, Seventh-day Adventist Church and main line churches have a commitment to religious freedoms. The Church of Jesus Christ of Latter-day Saints also affirms religious freedom.
However others, such as African scholar Makau Mutua, have argued that Christian insistence on the propagation of their faith to native cultures as an element of religious freedom has resulted in a corresponding denial of religious freedom to native traditions and led to their destruction. As he states in the book produced by the Oslo Coalition on Freedom of Religion or Belief, "Imperial religions have necessarily violated individual conscience and the communal expressions of Africans and their communities by subverting African religions."
In their book "Breaking India", Rajiv Malhotra and Aravindan Neelakandan discussed the "US Church" funding activities in India, such as the popularly advertised campaigns to "save" poor children by feeding, clothing, and educating them, with the book arguing that the funds collected were being used not so much for the purposes indicated to sponsors, but for indoctrination and conversion activities. They suggest that India is the prime target of a huge enterprise—a "network" of organizations, individuals, and churches—that, they argue, seem intensely devoted to the task of creating a separatist identity, history, and even religion for the vulnerable sections of India. They suggest that this nexus of players includes not only church groups, government bodies, and related organizations, but also private think tanks and academics.
Joel Spring has written about the Christianization of the Roman Empire:
Christianity added new impetus to the expansion of empire. Increasing the arrogance of the imperial project, Christians insisted that the Gospels and the Church were the only valid sources of religious beliefs. Imperialists could claim that they were both civilizing the world and spreading the true religion. By the 5th century, Christianity was thought of as co-extensive with the "Imperium romanum". This meant that to be human, as opposed to being a natural slave, was to be "civilized" and Christian. Historian Anthony Pagden argues, "just as the "civitas"; had now become coterminous with Christianity, so to be human—to be, that is, one who was 'civil', and who was able to interpret correctly the law of nature—one had now also to be Christian." After the fifteenth century, most Western colonialists rationalized the spread of empire with the belief that they were saving a barbaric and pagan world by spreading Christian civilization.
Islam.
Conversion to Islam is simple (cf. shahada), but Muslims are forbidden to convert from Islam to another religion (cf. Apostasy in Islam). Certain Muslim-majority countries are known for their restrictions on religious freedom, highly favoring Muslim citizens over non-Muslim citizens. Other countries having the same restrictive laws tend to be more liberal when imposing them. Even other Muslim-majority countries are secular and thus do not regulate religious belief.
Some Islamic theologians quote the Qur'an ("There is no compulsion in religion"[] and "Say: O you who reject faith, I do not worship what you worship, nor do you worship what I worship...To you be your religion, and to me be mine"[], i.e., Sura Al-Kafirun) to show scriptural support for religious freedom.
Quran , referring to the war against Pagans during the Battle of Badr in Medina, indicates that Muslims are only allowed to fight against those who intend to harm them (right of self-defense) and that if their enemies surrender, they must also stop because God does not like those who transgress limits.
In Bukhari:V9 N316, Jabir ibn 'Abdullah narrated that a Bedouin accepted Islam and then when he got a fever he demanded that Muhammad to cancel his pledge (allow him to renounce Islam). Muhammad refused to do so. The Bedouin man repeated his demand once, but Muhammad once again refused. Then, he (the Bedouin) left Medina. Muhammad said, "Madinah is like a pair of bellows (furnace): it expels its impurities and brightens and clear its good." In this narration, there was no evidence demonstrating that Muhammad ordered the execution of the Bedouin for wanting to renounce Islam.
In addition, Quran , which is believed to be God's final revelation to Muhammad, states that Muslims are to fear God and not those who reject Islam, and Quran  states that one is accountable only for one's own actions. Therefore, it postulates that in Islam, in the matters of practising a religion, it does not relate to a worldly punishment, but rather these actions are accountable to God in the afterlife. Thus, this supports the argument against the execution of apostates in Islam.
However, on the other hand, some Muslims support the practice of executing apostates who leave Islam, as in Bukhari:V4 B52 N260; "The Prophet said, 'If a Muslim discards his religion, kill him.'"
In Iran, the constitution recognizes four religions whose status is formally protected: Zoroastrianism, Judaism, Christianity, and Islam.
The constitution, however, also set the groundwork for the institutionalized persecution of Bahá'ís,
who have been subjected to arrests, beatings, executions, confiscation and destruction of property, and the denial of civil rights and liberties, and the denial of access to higher education. There is no freedom of conscience in Iran, as converting from Islam to any other religion is forbidden.
In Egypt, a 16 December 2006 judgment of the Supreme Administrative Council created a clear demarcation between recognized religions – Islam, Christianity and Judaism – and all other religious beliefs; no other religious affiliation is officially admissible. The ruling leaves members of other religious communities, including Bahá'ís, without the ability to obtain the necessary government documents to have rights in their country, essentially denying them of all rights of citizenship. They cannot obtain ID cards, birth certificates, death certificates, marriage or divorce certificates, and passports; they also cannot be employed, educated, treated in public hospitals or vote, among other things. See Egyptian identification card controversy.
Changing religion.
Among the most contentious areas of religious freedom is the right of an individual to change or abandon his or her own religion (apostasy), and the right to evangelize individuals seeking to convince others to make such a change.
Other debates have centered around restricting certain kinds of missionary activity by religions. Many Islamic states, and others such as China, severely restrict missionary activities of other religions. Greece, among European countries, has generally looked unfavorably on missionary activities of denominations others than the majority church and proselytizing is constitutionally prohibited.
A different kind of critique of the freedom to propagate religion has come from non-Abrahamic traditions such as the African and Indian. African scholar Makau Mutua criticizes religious evangelism on the ground of cultural annihilation by what he calls "proselytizing universalist faiths" (Chapter 28: Proselytism and Cultural Integrity, page 652):
...the (human) rights regime incorrectly assumes a level playing field by requiring that African religions compete in the marketplace of ideas. The rights corpus not only forcibly imposes on African religions the obligation to compete—a task for which as nonproselytizing, noncompetitive creeds they are not historically fashioned—but also protects the evangelizing religions in their march towards universalization ... it seems inconceivable that the human rights regime would have intended to protect the right of certain religions to destroy others.
Some Indian scholars have similarly argued that the right to propagate religion is not culturally or religiously neutral.
In Sri Lanka, there have been debates regarding a bill on religious freedom that seeks to protect indigenous religious traditions from certain kinds of missionary activities. Debates have also occurred in various states of India regarding similar laws, particularly those that restrict conversions using force, fraud or allurement.
In 2008, Christian Solidarity Worldwide, a Christian human rights non-governmental organisation which specializes in religious freedom, launched an in-depth report on the human rights abuses faced by individuals who leave Islam for another religion. The report is the product of a year long research project in six different countries. It calls on Muslim nations, the international community, the UN and the international media to resolutely address the serious violations of human rights suffered by apostates.
Apostasy in Islam.
In Islam, apostasy is called "ridda" ("turning back") and is considered to be a profound insult to God. A person born of Muslim parents that rejects Islam is called a ""murtad fitri" (natural apostate), and a person that converted to Islam and later rejects the religion is called a "murtad milli"" (apostate from the community).
In Islamic law (Sharia), the consensus view is that a male apostate must be put to death unless he suffers from a mental disorder or converted under duress, for example, due to an imminent danger of being killed. A female apostate must be either executed, according to Shafi'i, Maliki, and Hanbali schools of Sunni Islamic jurisprudence (fiqh), or imprisoned until she reverts to Islam as advocated by the Sunni Hanafi school and by Shi'a scholars.
Ideally, the one performing the execution of an apostate must be an imam. At the same time, all schools of Islamic jurisprudence agree that any Muslim can kill an apostate without punishment.
However, while almost all scholars agree about the punishment, many disagree on the allowable time to retract the apostasy. Many scholars push this as far as allowing the apostate till he/she dies. Thus, practically making the death penalty just a theoretical statement/exercise. S. A. Rahman, a former Chief Justice of Pakistan, argues that there is no indication of the death penalty for apostasy in the Qur'an.
Secular law.
Religious practice may also conflict with secular law, creating debates on religious freedom. For instance, even though polygamy is permitted in Islam, it is prohibited in secular law in many countries. This raises the question of whether prohibiting the practice infringes on the beliefs of certain Muslims. The US and India, both constitutionally secular nations, have taken two different views of this. In India, polygamy is permitted, but only for Muslims, under Muslim Personal Law. In the US, polygamy is prohibited for all. This was a major source of conflict between the early LDS Church and the United States until the Church amended its position on practicing polygamy.
Similar issues have also arisen in the context of the religious use of psychedelic substances by Native American tribes in the United States as well as other Native practices.
In 1955, Chief Justice of California Roger J. Traynor neatly summarized the American position on how freedom of religion cannot imply freedom from law: "Although freedom of conscience and the freedom to believe are absolute, the freedom to act is not." But with respect to the religious use of animals within secular law and those acts, the US Supreme Court decision in the case of the "Church of Lukumi Babalu Aye v. City of Hialeah" in 1993 upheld the right of Santeria adherents to practice ritual animal sacrifice, with Justice Anthony Kennedy stating in the decision: "religious beliefs need not be acceptable, logical, consistent or comprehensible to others in order to merit First Amendment protection" (quoted by Justice Kennedy from the opinion by Justice Burger in "Thomas v. Review Board of the Indiana Employment Security Division" 450 U.S. (1981)).
Children's rights.
The law in Germany provides the term of "religious majority" ("Religiöse Mündigkeit") with a minimum age for minors to follow their own religious beliefs even if their parents don't share those or don't approve. Children 14 and older have the unrestricted right to enter or exit any religious community. Children 12 and older cannot be compelled to change to a different belief. Children 10 and older have to be heard before their parents change their religious upbringing to a different belief. There are similar laws in Austria and in Switzerland.
International Religious Freedom Day.
27 October is International Religious Freedom Day, in commemoration of the execution of the Boston martyrs for their religious convictions 1659–1661. The US proclaimed 16 January Religious Freedom Day.
Modern concerns.
In its 2011 annual report, the "United States Commission on International Religious Freedom" designated fourteen nations as "countries of particular concern". The commission chairman commented that these are nations whose conduct marks them as the world's worst religious freedom violators and human rights abusers. The fourteen nations designated were Burma, China, Egypt, Eritrea, Iran, Iraq, Nigeria, North Korea, Pakistan, Saudi Arabia, Sudan, Turkmenistan, Uzbekistan, and Vietnam. Other nations on the commission's watchlist include Afghanistan, Belarus, Cuba, India, Indonesia, Laos, Russia, Somalia, Tajikistan, Turkey, and Venezuela.
There are concerns about the restrictions on public religious dress in some European countries (including the Hijab, Kippah, and Christian cross). Article 18 of the UN International Covenant on Civil and Political Rights limits restrictions on freedom to manifest one's religion or beliefs to those necessary to protect public safety, order, health, or morals or the fundamental rights and freedoms of others. Freedom of religion as a legal concept is related to, but not identical with, religious toleration, separation of church and state, or secular state ("laïcité").
Social hostilities and government restrictions.
The Pew Research Center has performed studies on international religious freedom between 2009 and 2015, compiling global data from 16 governmental and non-governmental organizations–including the United Nations, the United States State Department, and Human Rights Watch–and representing over 99.5 percent of the world's population. In 2009, nearly 70 percent of the world's population lived in countries classified as having heavy restrictions on freedom of religion. This concerns restrictions on religion originating from government prohibitions on free speech and religious expression as well as social hostilities undertaken by private individuals, organisations and social groups. Social hostilities were classified by the level of communal violence and religion-related terrorism.
While most countries provided for the protection of religious freedom in their constitutions or laws, only a quarter of those countries were found to fully respect these legal rights in practice. In 75 countries governments limit the efforts of religious groups to proselytise and in 178 countries religious groups must register with the government. In 2013, Pew classified 30% of countries as having restrictions that tend to target religious minorities, and 61% of countries have social hostilities that tend to target religious minorities.
The countries in North and South America reportedly had some of the lowest levels of "government" and "social" restrictions on religion, while The Middle East and North Africa were the regions with the highest. Saudi Arabia, Pakistan and Iran were the countries that top the list of countries with the "overall" highest levels of restriction on religion. Topping the Pew government restrictions index were Saudi Arabia, Iran, Uzbekistan, China, Egypt, Burma, Maldives, Eritrea, Malaysia and Brunei.
Of the world's 25 most populous countries, Iran, Egypt, Indonesia and Pakistan had the most restrictions, while Brazil, Japan, Italy, South Africa, the UK, and the US had some of the lowest levels, as measured by Pew. 
Vietnam and China were classified as having high "government" restrictions on religion but were in the moderate or low range when it came to "social" hostilities. Nigeria, Bangladesh and India were high in "social" hostilities but moderate in terms of "government" actions.
Restrictions on religion across the world increased between mid-2009 and mid-2010, according to a 2012 study by the Pew Research Center. Restrictions in each of the five major regions of the world increased—including in the Americas and sub-Saharan Africa, the two regions where overall restrictions previously had been declining. In 2010, Egypt, Nigeria, the Palestinian territories, Russia, and Yemen were added to the "very high" category of social hostilities. The five highest social hostility scores were for Pakistan, India, Sri Lanka, Iraq, and Bangladesh. In 2015, Pew published that social hostilities declined in 2013, but Harassment of Jews increased.
Further reading.
</dl>

</doc>
<doc id="46007" url="http://en.wikipedia.org/wiki?curid=46007" title="Moldavia">
Moldavia

 |style="width:1.0em; padding:0 0 0 0.6em;"| - 
 |style="padding-left:0;text-align:left;"| 1346–1353 (first)
Moldavia (Romanian: "Moldova" ]) is a geographic and historical region and former principality in Eastern Europe, corresponding to the territory between the Eastern Carpathians and the Dniester river. An initially independent and later autonomous state, it existed from the 14th century to 1859, when it united with Wallachia as the basis of the modern Romanian state; at various times, the state included the regions of Bessarabia (with the Budjak) and all of Bukovina. The western half of Moldavia is now part of Romania, the eastern side belongs to the Republic of Moldova, while the northern and south-eastern parts are territories of Ukraine.
Name and etymology.
The original and short-lived reference to the region was "Bogdania", after Bogdan I, the founding figure of the principality. The names "Moldavia" and "Moldova" are derived from the name of the Moldova River; however, the etymology is not known and there are several variants:
In several early references, "Moldavia" is rendered under the composite form "Moldo-Wallachia" (in the same way Wallachia may appear as "Hungro-Wallachia"). Ottoman Turkish references to Moldavia included "Boğdan Iflak" (meaning "Bogdan's Wallachia") and "Boğdan" (and occasionally "Kara-Boğdan" - "Black Bogdania"). See also names in other languages.
The name of the region in other languages include French: "Moldavie", German: "Moldau", Hungarian: "Moldva", Russian: Молдавия, "Moldaviya", Turkish: "Boğdan Prensliği", Greek: Μολδαβία.
History.
Early Middle Ages.
The Bolohoveni, a Vlach population, is mentioned by the Hypatian Chronicle in the 13th century. The chronicle shows that this land is bordered on the principalities of Halych, Volhynia and Kiev. Archaeological research also identified the location of 13th-century fortified settlements in this region. Alexandru V. Boldur identified Voscodavie, Voscodavti, Voloscovti, Volcovti, Volosovca and their other towns and villages between the middle course of the rivers Nistru/Dniester and Nipru/Dnieper. The Bolohoveni disappeared from chronicles after their defeat in 1257 by Daniil Romanovich's troops.
In the early 13th century, the "Brodniks", a possible Slavic–Vlach vassal state of Halych, were present, alongside the Vlachs, in much of the region's territory (towards 1216, the Brodniks are mentioned as in service of Suzdal).
On the border between Halych and the Brodniks, in the 11th century, a Viking by the name of "Rodfos" was killed in the area by Vlachs who supposedly betrayed him. In 1164, the future Byzantine Emperor Andronikos I Komnenos, was taken prisoner by Vlach shepherds around the same region.
High Middle Ages.
Later in the 13th century, King Charles I of Hungary attempted to expand his realm and the influence of the Catholic Church eastwards after the fall of Cuman rule, and ordered a campaign under the command of Phynta de Mende (1324). In 1342 and 1345, the Hungarians were victorious in a battle against Tatar-Mongols; the conflict was resolved by the death of Jani Beg, in 1357. The Polish chronicler Jan Długosz mentioned Moldavians (under the name "Wallachians") as having joined a military expedition in 1342, under King Władysław I, against the Margraviate of Brandenburg.
In 1353, Dragoș, mentioned as a Vlach "Knyaz" in Maramureș, was sent by Louis I to establish a line of defense against the Golden Horde forces of Mongols on the Siret River. This expedition resulted in a polity vassal to Hungary, centered around Baia ("Târgul Moldovei" or "Moldvabánya").
Bogdan of Cuhea, another Vlach voivode from Maramureş who had fallen out with the Hungarian king, crossed the Carpathians in 1359, took control of Moldavia, and succeeded in removing Moldavia from Hungarian control. His realm extended north to the Cheremosh River, while the southern part of Moldavia was still occupied by the Tatar Mongols.
After first residing in Baia, Bogdan moved Moldavia's seat to Siret (it was to remain there until Petru Muşat moved it to Suceava; it was finally moved to Iași under Alexandru Lăpușneanu - in 1565). The area around Suceava, roughly correspondent to future Bukovina, formed one of the two administrative divisions of the new realm, under the name "Ţara de Sus" (the "Upper Land"), whereas the rest, on both sides of the Prut river, formed "Ţara de Jos" (the "Lower Land").
Disfavored by the brief union of Angevin Poland and Hungary (the latter was still the country's overlord), Bogdan's successor Lațcu accepted conversion to Roman Catholicism around 1370, but his gesture was to remain without consequences. Despite remaining officially Eastern Orthodox and culturally connected with the Byzantine Empire after 1382, princes of the House of Bogdan-Mușat entered a conflict with the Constantinople Patriarchy over control of appointments to the newly founded Moldavian Metropolitan seat; Patriarch Antony IV even cast an anathema over Moldavia after Roman I expelled his appointee back to Byzantium. The crisis was finally settled in favor of the Moldavian princes under Alexander I. Nevertheless, religious policy remained complex: while conversions to faiths other than Orthodox were discouraged (and forbidden for princes), Moldavia included sizable Roman Catholic communities (Germans and Magyars), as well as non-Chalcedonic Armenians; after 1460, the country welcomed Hussite refugees (founders of Ciuburciu and, probably, Huși).
The principality of Moldavia covered the entire geographic region of Moldavia. In various periods, various other territories were politically connected with the Moldavian principality. This is the case of the province of Pokuttya, the fiefdoms of Cetatea de Baltă and Ciceu (both in Transylvania) or, at a later date, the territories between the Dniester and the Bug rivers.
Petru I profited from the end of the Hungarian-Polish union, and moved the country closer to the Jagiellon realm, becoming a vassal of Władysław II on September 26, 1387. This gesture was to have unexpected consequences: Petru supplied the Polish ruler with funds needed in the war against the Teutonic Knights, and was granted control over Pokuttya until the debt was to be repaid; as this is not recorded to have been carried out, the region became disputed by the two states, until it was lost by Moldavia in the Battle of Obertyn (1531). Prince Petru also expanded his rule southwards to the Danube Delta, and established a frontier with Wallachia; his brother Roman I conquered the Hungarian-ruled Cetatea Albă in 1392, giving Moldavia an outlet to the Black Sea, before being toppled from the throne for supporting Fyodor Koriatovych in his conflict with Vytautas the Great of Lithuania. Under Stephen I, growing Polish influence was challenged by Sigismund of Hungary, whose expedition was defeated at Ghindăoani in 1385; however, Stephen disappeared in mysterious circumstances, and the throne was soon occupied by Iuga Ologul (Vytautas' favorite).
Alexander I, although brought to the throne in 1400 by the Hungarians (with assistance from Mircea I of Wallachia), shifted his allegiances towards Poland (notably engaging Moldavian forces on the Polish side in the Battle of Grunwald and the Siege of Marienburg), and placed his own choice of rulers in Wallachia. His reign was one of the most successful in Moldavia's history, but also saw the very first confrontation with the Ottoman Turks at Cetatea Albă in 1420, and later even a conflict with the Poles. A deep crisis was to follow Alexandru's long reign, with his successors battling each other in a succession of wars that divided the country until the murder of Bogdan II and the ascension of Peter III Aaron in 1451. Nevertheless, Moldavia was subject to further Hungarian interventions after that moment, as Matthias Corvinus deposed Aron and backed Alexăndrel to the throne in Suceava. Petru Aron's rule also signified the beginning of Moldavia's Ottoman Empire allegiance, as the ruler agreed to pay tribute to Sultan Mehmed II.
Late Middle Ages.
Under Stephen the Great, who took the throne and subsequently came to an agreement with Kazimierz IV of Poland in 1457, the state reached its most glorious period. Stephen blocked Hungarian interventions in the Battle of Baia, invaded Wallachia in 1471, and dealt with Ottoman reprisals in a major victory (the 1475 Battle of Vaslui); after feeling threatened by Polish ambitions, he also attacked Galicia and resisted Polish reprisals in the Battle of the Cosmin Forest (1497). However, he had to surrender Chilia (Kiliya) and Cetatea Albă (Bilhorod-Dnistrovskyi), the two main fortresses in the Budjak, to the Ottomans in 1484, and in 1498 he had to accept Ottoman suzerainty, when he was forced to agree to continue paying tribute to Sultan Bayezid II. Following the taking of Hotin (Khotyn) and Pokuttya, Stephen's rule also brought a brief extension of Moldavian rule into Transylvania: Cetatea de Baltă and Ciceu became his fiefs in 1489.
Early Modern Era and Renaissance.
Under Bogdan III the One-Eyed, Ottoman overlordship was confirmed in the shape that would rapidly evolve into control over Moldavia's affairs. Peter IV Rareș, who reigned in the 1530s and 1540s, clashed with the Habsburg Monarchy over his ambitions in Transylvania (losing possessions in the region to George Martinuzzi), was defeated in Pokuttya by Poland, and failed in his attempt to extricate Moldavia from Ottoman rule – the country lost Bender to the Ottomans, who included it in their Silistra Eyalet.
A period of profound crisis followed. Moldavia stopped issuing its own coinage circa 1520, under Prince Ştefăniţă, when it was confronted with rapid depletion of funds and rising demands from the Porte. Such problems became endemic when the country, brought into the Great Turkish War, suffered the impact of the stagnation of the Ottoman Empire; at one point, during the 1650s and 1660s, princes began relying on counterfeit coinage (usually copies of Swedish riksdalers, as was that issued by Eustratie Dabija). The economic decline was accompanied by a failure to maintain state structures: the feudal-based Moldavian military forces were no longer convoked, and the few troops maintained by the rulers remained professional mercenaries such as the "seimeni".
However, Moldavia and the similarly affected Wallachia remained both important sources of income for the Ottoman Empire and relatively prosperous agricultural economies (especially as suppliers of grain and cattle – the latter was especially relevant in Moldavia, which remained an under-populated country of pastures). In time, much of the resources were tied to the Ottoman economy, either through monopolies on trade which were only lifted in 1829, after the Treaty of Adrianople (which did not affect all domains directly), or through the raise in direct taxes - the one demanded by the Ottomans from the princes, as well as the ones demanded by the princes from the country's population. Taxes were directly proportional with Ottoman requests, but also with the growing importance of Ottoman appointment and sanctioning of princes in front of election by the boyars and the boyar Council – "Sfatul boieresc" (drawing in a competition among pretenders, which also implied the intervention of creditors as suppliers of bribes). The fiscal system soon included taxes such as the "văcărit" (a tax on head of cattle), first introduced by Iancu Sasul in the 1580s.
The economic opportunities offered brought about a significant influx of Greek and Levantine financiers and officials, who entered a stiff competition with the high boyars over appointments to the Court. As the manor system suffered the blows of economic crises, and in the absence of salarisation (which implied that persons in office could decide their own income), obtaining princely appointment became the major focus of a boyar's career. Such changes also implied the decline of free peasantry and the rise of serfdom, as well as the rapid fall in the importance of low boyars (a traditional institution, the latter soon became marginal, and, in more successful instances, added to the population of towns); however, they also implied a rapid transition towards a monetary economy, based on exchanges in foreign currency. Serfdom was doubled by the much less numerous slave population ("robi"), composed of migrant Roma and captured Nogais.
The conflict between princes and boyars was to become exceptionally violent – the latter group, who frequently appealed to the Ottoman court in order to have princes comply with its demands, was persecuted by rulers such as Alexandru Lăpușneanu and John III. Ioan Vodă's revolt against the Ottomans ended in his execution (1574). The country descended into political chaos, with frequent Ottoman and Tatar incursions and pillages. The claims of Muşatins to the crown and the traditional system of succession were ended by scores of illegitimate reigns; one of the usurpers, Ioan Iacob Heraclid, was a Protestant Greek who encouraged the Renaissance and attempted to introduce Lutheranism to Moldavia.
In 1595, the rise of the Movileşti boyars to the throne with Ieremia Movilă coincided with the start of frequent anti-Ottoman and anti-Habsburg military expeditions of the Polish–Lithuanian Commonwealth into Moldavian territory (see "Moldavian Magnate Wars"), and rivalries between pretenders to the Moldavian throne encouraged by the three competing powers. 
The Wallachian prince Michael the Brave, after previously taking over Transylvania, also deposed Prince Ieremia Movilă, in 1600, and managed to become the first Prince to rule over Moldavia, Wallachia, and Transylvania; the episode ended in Polish conquests of lands down to Bucharest, soon ended by the outbreak of the Polish–Swedish War and the reestablishment of Ottoman rule. Polish incursions were dealt a blow by the Ottomans during the 1620 Battle of Cecora, which also saw an end to the reign of Gaspar Graziani.
The following period of relative peace saw the more prosperous and prestigious rule of Vasile Lupu, who took the throne as a boyar appointee in 1637, and began battling his rival Gheorghe Ştefan, as well as the Wallachian prince Matei Basarab – however, his invasion of Wallachia with the backing of Cossack Hetman Bohdan Khmelnytsky ended in disaster at the Battle of Finta (1653). A few years later, Moldavia was occupied for two short intervals by the anti-Ottoman Wallachian prince Constantin Șerban, who clashed with the first ruler of the Ghica family, George Ghica. In the early 1680s, Moldavian troops under George Ducas intervened in right-bank Ukraine and assisted Mehmed IV in the Battle of Vienna, only to suffer the effects of the Great Turkish War.
Phanariots (1711–1822).
During the late 17th century, Moldavia became the target of the Russian Empire's southwards expansion, inaugurated by Peter the Great during the Russo-Turkish War of 1710-1711; Prince Dimitrie Cantemir's siding with Peter and open anti-Ottoman rebellion, ended in defeat at Stănileşti, provoked Sultan Ahmed III's reaction, and the official discarding of recognition of local choices for princes, imposing instead a system which relied solely on Ottoman approval – the Phanariote epoch, inaugurated by the reign of Nicholas Mavrocordatos. 
Short and frequently ended through violence, Phanariote rules were usually marked by political corruption, intrigue, and high taxation, as well as by sporadic incursions of Habsburg and Russian armies deep into Moldavian territory; nonetheless, they also saw attempts at legislative and administrative modernization inspired by The Enlightenment (such as Constantine Mavrocordatos' decision to salarize public offices, to the outrage of boyars, and the abolition of serfdom in 1749, as well as Scarlat Callimachi's "Code"), and signified a decrease in Ottoman demands after the threat of Russian annexation became real and the prospects of a better life led to waves of peasant emigration to neighboring lands. The effects of Ottoman control were also made less notable after the 1774 Treaty of Küçük Kaynarca allowed Russia to intervene in favour of Ottoman subjects of the Eastern Orthodox faith - leading to campaigns of petitioning by the Moldavian boyars against princely policies.
In 1712, Hotin was taken over by the Ottomans, and became part of a defensive system that Moldavian princes were required to maintain, as well as an area for Islamic colonization (the Laz community). 
Fragmentation.
In 1775, Moldavia lost to the Habsburg Empire its northwestern part, which became known as Bukovina. For Moldavia, it meant both an important territorial loss and a major blow to the cattle trade (as the region stood on the trade route to Central Europe). 
The 1792 Treaty of Jassy forced the Ottoman Empire to cede all of its holdings in what is now Transnistria to Russian Empire, which made Russian presence much more notable, given that the Empire acquired a common border with Moldavia. The first effect of this was the cession of the eastern half of Moldavia (later known as Bessarabia) to the Russian Empire, in 1812.
Organic Statute, 1848 revolution.
Phanariote rules were officially ended after the 1821 occupation of the country by Alexander Ypsilantis's Filiki Eteria during the Greek War of Independence; the subsequent Ottoman retaliation brought the rule of Ioan Sturdza, considered as the first one of a new system – especially since, in 1826, the Ottomans and Russia agreed to allow for the election by locals of rulers over the two Danubian Principalities, and convened on their mandating for seven-year terms. In practice, a new fundament to reigns in Moldavia was created by the Russo-Turkish War (1828–1829), and a period of Russian domination over the two countries which ended only in 1856: begun as a military occupation under the command of Pavel Kiselyov, Russian domination gave Wallachia and Moldavia, which were not removed from nominal Ottoman control, the modernizing "Organic Statute" (the first document resembling a constitution, as well as the first one to regard both principalities). After 1829, the country also became an important destination for immigration of Ashkenazi Jews from the Kingdom of Galicia and Lodomeria and areas of Russia ("see History of the Jews in Romania and Sudiţi").
The first Moldavian rule established under the Statute, that of Mihail Sturdza, was nonetheless ambivalent: eager to reduce abuse of office, Sturdza introduced reforms (the abolition of slavery, secularization, economic rebuilding), but he was widely seen as enforcing his own power over that of the newly instituted consultative Assembly. A supporter of the union of his country with Wallachia and of Romanian Romantic nationalism, he obtained the establishment of a customs union between the two countries (1847) and showed support for radical projects favored by low boyars; nevertheless, he clamped down with noted violence the Moldavian revolutionary attempt in the last days of March 1848. Grigore Alexandru Ghica allowed the exiled revolutionaries to return to Moldavia c. 1853, which led to the creation of the National Party ("Partida Naţională"), a trans-boundary group of radical union supporters which campaigned for a single state under a foreign dynasty.
Slavery.
Slavery (Romanian: "robie") was part of the social order from before the founding of the Principality of Moldavia, until it was abolished in stages during the 1840s and 1850s. Most of the slaves were of Roma (Gypsy) ethnicity. There were also slaves of Tatar ethnicity, probably prisoners captured from the wars with the Nogai and Crimean Tatars. The institution of slavery was first attested in a 1470 Moldavian document, through which Prince Stephen the Great frees Oană, a Tatar slave who had fled to Jagiellon Poland.
The exact origins of slavery are not known, as it was a common practice in medieval Europe. As in the Byzantine Empire, the Roma were held as slaves of the state, of the boyars or of the monasteries. Historian Nicolae Iorga associated the Roma people's arrival with the 1241 Mongol invasion of Europe and considered their slavery as a vestige of that era; he believed that the Romanians took the Roma as slaves from the Mongols and preserved their status to control their labor. Other historians consider that the Roma were enslaved while captured during the battles with the Tatars. The practice of enslaving prisoners may also have been taken from the Mongols. The ethnic identity of the "Tatar slaves" is unknown, they could have been captured Tatars of the Golden Horde, Cumans, or the slaves of Tatars and Cumans. While it is possible that some Romani people were slaves or auxiliary troops of the Mongols or Tatars, most of them came from south of the Danube, demonstrating that slavery a widespread practice. The Tatar slaves, smaller in numbers, were eventually merged into the Roma population.
Traditionally, Roma slaves were divided into three categories. The smallest was owned by the "hospodars", and went by the Romanian-language name of "ţigani domneşti" ("Gypsies belonging to the lord"). The two other categories comprised "ţigani mănăstireşti" ("Gypsies belonging to the monasteries"), who were the property of Romanian Orthodox and Greek Orthodox monasteries, and "ţigani boiereşti" ("Gypsies belonging to the boyars"), who were enslaved by the category of landowners.
The abolition of slavery was carried out following a campaign by young revolutionaries who embraced the liberal ideas of the Enlightenment. In 1844, Moldavian Prince Mihail Sturdza proposed a law on the freeing of slaves owned by the church and state. By the 1850s, the movement gained support from almost the whole of Romanian society. In December 1855, following a proposal by Prince Grigore Alexandru Ghica, a bill drafted by Mihail Kogălniceanu and Petre Mavrogheni was adopted by the Divan; the law emancipated all slaves to the status of taxpayers (citizens).
Support for the abolitionists was reflected in Romanian literature of the mid-19h century. The issue of the Roma slavery became a theme in the literary works of various liberal and Romantic intellectuals, many of whom were active in the abolitionist camp. The Romanian abolitionist movement was also influenced by the much larger movement against Black slavery in the United States through press reports and through a translation of Harriet Beecher Stowe's "Uncle Tom's Cabin". Translated by Theodor Codrescu and first published in Iași in 1853, under the name "Coliba lui Moşu Toma sau Viaţa negrilor în sudul Statelor Unite din America" (which translates back as "Uncle Toma's Cabin or the Life of Blacks in the Southern United States of America"), it was the first American novel to be published in Romanian. The foreword included a study on slavery by Mihail Kogălniceanu.
Union with Wallachia.
Russian domination ended abruptly after the Crimean War, when the Treaty of Paris passed the two principalities under the tutelage of Great European Powers (together with Russia and the Ottoman overlord, power-sharing included the United Kingdom of Great Britain and Ireland, the Austrian Empire, the French Empire, the Kingdom of Piedmont-Sardinia, and Prussia). Due to Austrian and Ottoman opposition and British reserves, the union program as demanded by radical campaigners was debated intensely. In September 1857, given that "Caimacam" Nicolae Vogoride had perpetrated fraud in elections in Moldavia in July, the Powers allowed the two states to convene ad-hoc divans, which were to decide a new constitutional framework; the result showed overwhelming support for the union, as the creation of a liberal and neutral state. After further meetings among leaders of tutor states, an agreement was reached (the "Paris Convention"), whereby a limited union was to be enforced – separate governments and thrones, with only two bodies (a Court of Cassation and a Central Commission residing in Focșani); it also stipulated that an end to all privilege was to be passed into law, and awarded back to Moldavia the areas around Bolhrad, Cahul, and Izmail.
However, the Convention failed to note whether the two thrones could not be occupied by the same person, allowing "Partida Naţională" to introduce the candidacy of Alexandru Ioan Cuza in both countries. On January 17 (January 5, 1859 Old Style), in Iași, he was elected prince of Moldavia by the respective electoral body. After street pressure over the much more conservative body in Bucharest, Cuza was elected in Wallachia as well (February 5/January 24). Exactly three years later, after diplomatic missions that helped remove opposition to the action, the formal union created the United Principalities (the basis of modern Romania) and instituted Cuza as "Domnitor" (all legal matters were clarified after the replacement of the prince with Carol of Hohenzollern-Sigmaringen in April 1866, and the creation of an independent Kingdom of Romania in 1881) - this officially ending the existence of the Principality of Moldavia.
Geography.
Geographically, Moldavia is limited by the Carpathian Mountains to the West, the Cheremosh River to the North, the Dniester River to the East and the Danube and Black Sea to the South. The Prut River flows approximately through its middle from north to south.
Of late 15th century Moldavia, with an area of approximately 97000 km2, the biggest part and the core of the former principality is located in Romania (47.5%), followed by the Republic of Moldova (30.5%) and Ukraine (22%). This represents 88% of the Republic of Moldova's surface, 19.5% of Romania's surface, and 3.5% of Ukraine's surface.
The region is mostly hilly, with a range of mountains in the west, and plain areas in the southeast. Moldavia's highest altitude is Ineu peak (2,279m), which is also the westernmost point of the region.
Population.
Historical population.
Contemporary historians estimate the populatian of the Moldavian Principality in the 15th century, at between 250,000 - 600,000 people, but an extensive catagraphy was first conducted in 1769-1774. In 1848, the northwestern part, annexed in 1775 by the Habsburg Empire, Bukovina, had a population of 377,571; in 1856, the eastern half of Moldavia, Bessarabia, annexed in 1812 by the Russian Empire, had a population of 990,274, while the population of Moldavia proper (the western half), in 1859, was 1,463,927.
Current population.
According to Romanian Census (2002), Moldovan Census (2004) and Ukrainian Census (2001) data, the region has a total population of approximately 9,700,000 inhabitants, 48% of them living in Romania, 36% in Moldova and 16% in Ukraine, distributed among the ethnic groups as follows:
1
2
Cities.
The largest cities (as per last censuses) in the Moldavia region are:
Education.
In 1562, the so-called Schola Latina (a Latin Academic College) was founded in Cotnari, near Iași, a school which marked the beginnings of the organized humanistic education institutions in Moldavia. 
The first institute of higher learning that functioned on the territory of Romania was Academia Vasiliană (1640), founded by Prince Vasile Lupu as a "Higher School for Latin and Slavonic Languages", followed by the Princely Academy, in 1707. The first high education structure in Romanian language was established in the autumn of 1813, when Gheorghe Asachi laid the foundations of a class of engineers, its activities taking place within the Greek Princely Academy.
After 1813, other moments marked the development of higher education in Romanian language, regarding both humanities and the technical science. Academia Mihăileană, founded in 1835 by Prince Mihail Sturdza, is considered the first Romanian superior institute. In 1860, three faculties part of the Academia Mihăileană formed the nucleus for the newly established University of Iași, the first Romanian modern university.

</doc>
<doc id="46014" url="http://en.wikipedia.org/wiki?curid=46014" title="Gary Numan">
Gary Numan

Gary Anthony James Webb (born 8 March 1958), better known by his stage name Gary Numan, is an English singer, songwriter, musician and record producer. Born in Hammersmith, London, he first entered the music industry as the lead singer of the new wave band Tubeway Army. After releasing two albums with the band, Numan released his debut solo album "The Pleasure Principle" in 1979. Most widely known for his chart-topping hits "Are 'Friends' Electric?" and "Cars", Numan achieved his peak of mainstream popularity in the late 1970s and early 1980s, but maintains a loyal cult following.
Numan, whose signature sound consists of heavy synthesizer hooks fed through guitar effects pedals, is considered a pioneer of commercial electronic music.
Early life and education.
Born in Hammersmith, England, Gary Anthony James Webb was the son of a British Airways bus driver based at Heathrow Airport. Webb was educated at Town Farm Junior School in Stanwell, Surrey and Ashford County Grammar School, then Slough Grammar School, Berkshire and Brooklands Technical College, Surrey. He joined the Air Training Corps as a teenager. He then briefly did various jobs including fork lift truck driver, air conditioning ventilator fitter, and clerk in an accounts department. When Numan was 15 years old, his father bought him a Gibson Les Paul guitar, which he regards as his most treasured possession. He played in various bands, including Mean Street and The Lasers, before forming Tubeway Army with his uncle, Jess Lidyard, and Paul Gardiner. His initial pseudonym was "Valerian", probably in reference to the hero in French science fiction comic series "Valérian and Laureline". Later he picked the name "Numan" from an advert in the Yellow Pages for a plumber named A. Neumann.
Career.
1970s.
Tubeway Army.
Numan rose to prominence at the end of the 1970s as front man, writer, and producer for Tubeway Army. After recording an album's worth of punk-influenced demo tapes (released in 1984 as "The Plan"), he was signed by Beggars Banquet Records in 1978 and quickly released two singles, "That's Too Bad" and "Bombers", neither of which charted.
A self-titled, new wave-oriented debut album later that same year sold out its limited run and introduced Numan's fascination with dystopian science fiction and synthesizers. Tubeway Army's third single, the dark-themed and slow-paced "Down in the Park" (1979), also failed to chart, but it would prove to be one of Numan's most enduring and oft-covered songs. It was featured with other contemporary hits on the soundtrack for the movie "Times Square", and a live version of the song can be seen in the movie "Urgh! A Music War". Following exposure in a television advertisement for Lee Cooper jeans with the jingle "Don't be a Dummy", Tubeway Army released the single "Are 'Friends' Electric?" in May 1979. The single took seven weeks before finally reaching No. 1 at the end of June; the parent album "Replicas" simultaneously reached No. 1.
As Gary Numan.
A few months later Numan found success in the charts on both sides of the Atlantic with "Cars", which peaked at No. 1 in the UK in 1979, No. 1 in Canada and No. 9 in the US in 1980. "Cars" and the 1979 album "The Pleasure Principle" were both released under Numan's own stage name. The album reached number one in the UK, and a sell-out tour ('The Touring Principle') followed; the concert video it spawned is often cited as the first full-length commercial music video release. "The Pleasure Principle" was a rock album with no guitars; instead, Numan used synthesizers fed through guitar effects pedals to achieve a distorted, phased, metallic tone. A second single from the album, "Complex", made it to No. 6 in the UK charts.
Personality and style.
Around this time, Numan also developed his style. According to Numan, this was an unintentional result of acne; before an appearance on "Top of the Pops", he had "spots everywhere, so they slapped about half an inch of white makeup on me before I'd even walked in the door. And my eyes were like pissholes in the snow, so they put black on there. My so-called image fell into place an hour before going on the show". His "wooden" stage presence was, in his words, a result of extreme self-consciousness and lack of "showmanship". During this period, Numan generated an army of fans calling themselves "Numanoids", providing him with a fanbase which maintained their support through the latter half of the 1980s, when his fortunes began to fall precipitously.
He later said that he, "Got really hung up with this whole thing of not feeling, being cold about everything, not letting emotions get to you, or presenting a front of not feeling".
1980s.
In 1980, Gary Numan topped the album charts for a third time with "Telekon", with the singles "We Are Glass", "" released prior to the album reaching No. 5 and No. 6. "This Wreckage" taken from the album in December also entered the Top 20. "Telekon", the final studio album that Numan retrospectively termed the "Machine" section of his career, reintroduced guitars to Numan's music and featured a wider range of synthesizers. The same year he embarked on his second major tour ("The Teletour") with an even more elaborate stage show than The Touring Principle the previous year. He announced his retirement from touring with a series of sell-out concerts at Wembley Arena in April 1981, supported by experimental musician Nash the Slash and Shock, a rock/mime/burlesque troupe whose members included Barbie Wilde, Tik and Tok, and Carole Caplin. A live two album set from the 1979 and 1980 tours released at this time reached No. 2 in the charts. Both albums, also individually released as Living Ornaments '79 and Living Ornaments '80 also charted. The decision to retire would be short-lived.
Departing from the pure electro-pop that he had been associated with, Numan began experimenting with jazz, funk, and ethereal, rhythmic pop. His first album after his 1981 farewell concerts was "Dance" (1981). The album charted as high as No. 3 on the UK charts, with an eight-week chart run and produced one hit single ("She's Got Claws") reaching No. 6. The album featured several distinguished guest players; Mick Karn (bass, saxophone) and Rob Dean (guitar) of Japan, Roger Mason (keyboards) of Models, and Roger Taylor (drums) of Queen.
With his former backing band, Chris John Payne (Keyboards, Viola), Russell Bell (Guitar), and Ced Sharpley (Drums) now reformed as Dramatis, Numan contributed vocals to the minor hit "Love Needs No Disguise" from the album "For Future Reference" and lent vocals to the first single release by his long-term right-hand man Paul Gardiner, "Stormtrooper In Drag", which also made the charts. However, Numan's career had begun to experience a gradual decline, and he was eclipsed initially by acts such as Adam Ant, and later by The Human League, Duran Duran and Depeche Mode. Each album also saw a new "image", none of which captured the public's imagination to nearly the same extent as the lonely android of 1979.
The album "I, Assassin" (1982) fared less well than "Dance". Despite producing one Top 10 and two Top 20 singles, the album peaked at No. 8 with a six-week chart run. Numan supported the album with a concert tour in America in late 1982 (where he was living as a tax exile), which were his first series of live shows since his farewell at Wembley.
"Warriors" (1983) further developed Numan's jazz-influenced style and featured contributions from avant-garde musician Bill Nelson (who fell out with Numan during recording and chose to be uncredited as the album's co-producer), and saxophonist Dick Morrissey (who would play on most of Numan's albums until 1991). The album peaked at No. 12, produced two hit singles including the Top 20 title track and, like "I, Assassin", spent six weeks in the charts. "Warriors" was the last album Numan recorded for Beggars Banquet Records, and was supported by a 40-date UK tour (again with support from robotic mime and music duo Tik and Tok) – Numan's first live tour in the UK since his Wembley appearances in 1981.
Numan subsequently issued a series of albums and singles on his own record label, Numa. As the decade continued, he tried to recapture his former chart glory with less distinguished albums, some of which were stylistically derivative of artists like Robert Palmer and Prince.
The first album released on Numa, 1984’s "Berserker" was also notable for being Numan's first foray into music computers/samplers, in this case the PPG Wave. "Berserker" moved away from the fluid, fretless sound that characterised Numan's previous three albums, featuring instead harder-edged electric bass and drum sounds. The album was also accompanied by a striking new blue-and-white visual image (including Numan himself with blue hair), a tour, a live album/video/EP, and the title track reached the UK Top 40 when released as a single. Despite this, the album divided critics and fans and commercially it was Numan’s least successful release to that point.
Numan's next album, "The Fury" (1985), charted slightly higher than "Berserker" breaking the top 30. Again, the album heralded a change of image, this time featuring Numan in a white suit and red bow tie. Four singles were released from the album, all reaching the UK Top 50.
Collaborations with Bill Sharpe of Shakatak helped little, though two singles that the duo recorded did see chart action: "Change Your Mind", reached No. 17 in 1985, and "No More Lies" reached No. 35 in 1988. Numa Records, which had been launched in a flurry of idealistic excitement, folded after the release of Numan's 1986 album "Strange Charm", though the album did contain two top 30 hits (Numan's highest singles chart placings since 1983). In addition to Numa Records' commercial failure, Numan's own fortune amassed since the late 1970s, which he estimated at £4.5 million, was drained. Numan then signed to IRS Records though his final studio album of the 1980s, "Metal Rhythm" (1988), also sold relatively poorly. For its American release, the record label changed the album's title to "New Anger" after the album's lead single, changed the album colour from black to blue, and remixed several of its tracks against Numan's wishes. In 1989, the Sharpe and Numan album "Automatic" was released through Polydor Records, though this too failed to garner much commercial success, briefly entering the charts.
1990s.
In 1991, Gary Numan ventured into film-scoring by co-composing the music for "The Unborn" with Michael R. Smith (the score was later released as an instrumental album in 1995, "Human"). After "Outland" (1991), another critical and commercial disappointment and his second and last studio album with IRS, Numan reactivated Numa Records, under which he would release his next two albums. By 1994, Numan decided to stop attempting to crack the pop market and concentrate instead on exploring more personal themes, including his vocal atheism. His future wife Gemma encouraged him to strip away the influences of the more recent years. Numan re-evaluated his career and veered toward a harsher, more industrial direction with his songwriting on the album "Sacrifice" — for the first time he played almost all the instruments himself. The move was critically well-received, as Numan's harder and darker sound emerged just as Numan-influenced bands like Nine Inch Nails were enjoying their first rush of fame. The influence was two-way; Numan claimed that Nine Inch Nails' song "Closer" is his favourite hit single of all time, and influenced his music. "Sacrifice" was the last album Numan made before shutting down Numa Records permanently. His next two albums, "Exile" (1997) and "Pure" (2000), were well received and significantly helped to restore his critical reputation. Numan toured the U.S. in support of "Exile", his first stateside concerts since the early 1980s.
2000s.
Gary Numan had become acknowledged and respected by his peers, with such musicians as Dave Grohl (of Foo Fighters and Nirvana), Trent Reznor (of Nine Inch Nails), and Marilyn Manson proclaiming his work an influence and recording cover versions of old Numan hits. The band Basement Jaxx had a huge hit in 2002 with "Where's Your Head At?", which relied on a sample of Numan's "M.E." – from "The Pleasure Principle" – for its hook. Fear Factory produced a cover of "Cars" (featuring a prominent guest appearance by Numan himself) for the digipak version of their album "Obsolete". Nine Inch Nails covered the song "Metal" on The Fragile remix album "Things Falling Apart" as did Afrika Bambaataa (with Numan himself) on the album "Dark Matter Moving at the Speed of Light". "Cars" remains Numan's most enduring song; it was a hit again in 1987 (remixed by Zeus B. Held) and 1996, in the latter case thanks to an appearance in an advert for Carling beer. In 2000 DJ Armand Van Helden sampled the track and mixed it up in his single "Koochy" which conquered the dancefloors. In 2002, UK pop trio Sugababes scored a No. 1 with "Freak Like Me" – a mashup of Adina Howard's "Freak Like Me" and "Are Friends Electric?" by Numan's Tubeway Army.
Other musicians, and at least one comedian, who have sung Numan's praises in recent years include Beck, Grant Nicholas, Tricky, Audio Antihero, Damon Albarn & Matt Sharp, Jarvis Cocker, Queens of the Stone Age, Noel Fielding, Phil Oakey from The Human League, John Foxx, Andy McCluskey from OMD and Afrika Bambaataa. "Cars" was featured on the soundtrack for the blockbuster 2002 videogame ' as part of the new wave radio station Wave 103, although it did not appear on the soundtrack CD release for the game. "Are Friends Electric" appeared on EA's game ' in 2006.
In 2002, Numan enjoyed chart success once again with the single "Rip", reaching No. 29 in the UK chart and in 2003 with the Gary Numan vs Rico single "Crazier", which reached No. 13 in the UK chart. Rico also worked on the remix album "Hybrid" which featured reworkings of older songs in a more contemporary industrial style as well as new material. Other artists and producers who contributed on these remixes included Curve, Flood, Andy Gray, Alan Moulder, New Disease, and Sulpher. 2003 also saw Numan performing the vocals on a track named "Pray For You" on the Plump DJs album "Eargasm", which was well received. In 2004 Numan took control of his own business affairs again, launching the label Mortal Records and releasing a series of live DVDs. In late 2005, Numan announced on his website that recording would begin on his new album in January 2006, with Ade Fenton co-producing. The album, "Jagged", was duly released on 13 March 2006 and saw Numan back in the UK album charts. An album launch gig took place at The Forum, London on 18 March followed by UK, European and US tours in support of the release. Numan also launched a "Jagged" website to showcase the new album, and made plans to have his 1981 farewell concert (previously released as "Micromusic" on VHS) issued on DVD by November 2006 as well as releasing the DVD version of the "Jagged" album launch gig. Numan undertook a "Telekon" 'Classic Album' tour in the UK in December 2006.
On 6 November 2006, Numan took part in the Sky1 reality show "The Race". It pitted ten celebrities (five male, five female) against each other in a series of Formula One-style car races. These races were held at Silverstone over the next five days, and varied in racing styles, ultimately culminating in one final Grand Prix race on Sunday, 12 November. Numan did win on the overall leaderboard, though he lost the final race to AC/DC lead singer Brian Johnson.
Numan contributed vocals to four tracks on the April 2007 release of the debut solo album by Ade Fenton "Artificial Perfect" on his new industrial/electronic label Submission, including songs "The Leather Sea", "Slide Away", "Recall", and the first single to be taken from the album, "Healing". The second single to be released in the UK was "The Leather Sea" on 30 July 2007, which charted.
He sold out a fifteen-date UK & Ireland tour in Spring 2008 during which he performed his 1979 number one album "Replicas" in full, and all the Replicas-era music including B-sides. The highly successful tour also raised Numan's profile in the media again due to the fact that it coincided with his 30th anniversary in the music business.
In November 2007, Numan confirmed via his website that work on a new album, with the working title of "Splinter", would be under way throughout 2008, after finishing an alternate version of "Jagged" (called "Jagged Edge") and the CD of unreleased songs from his previous three albums (confirmed to be titled "Dead Son Rising" on 1 December 2008 via official mailing list message). He wrote that "Splinter" was likely to be released in early 2010.
In a September 2009 interview with The Quietus, Numan says that he and Trent Reznor plan to make music together.
2010s.
Gary Numan was set to perform a small number of American live dates in April 2010, including a Coachella Festival appearance in California, but had to cancel because air travel in Europe was halted by the Icelandic volcanic ash cloud. As a result, the tour was not only postponed but expanded, and his Pleasure Principle 30th Anniversary Tour's American and Mexican dates began on 17 October 2010, at Firestone Live in Orlando, Florida.
Numan toured Australia in May 2011 performing his seminal album The Pleasure Principle in its entirety to celebrate its thirtieth anniversary. Joining him on tour was Australian electronic band Severed Heads, coming out of retirement especially for the shows.
Numan lent his vocals to the track "My Machines" on Battles's 2011 album "Gloss Drop". He has been chosen by Battles to perform at the ATP Nightmare Before Christmas festival that they co-curate in December 2011 in Minehead, England. Numan's new album "Dead Son Rising" was released on 16 September 2011 which had a full UK tour split in two halves, 15–21 September and 7–11 December, Both parts were supported by Welsh soloist Jayce Lewis in an interview during the tour; Gary praised the Welshman to being the best supporting act ever in his 30 years of touring, later documenting the tour in a Tour diary and publicly inviting Jayce to join him for an American tour in 2012.
Numan also provided narration for Voltaire's short film "Odokuro" in 2011.
While working on a new album due for release in 2013, Numan said "The one I’m working on now which I’m trying to get out in the middle of next year. It’s very heavy, very aggressive and very dark. There are elements of Dead Son Rising in that, but it’s much further along that particular road." 
The new album, "Splinter (Songs From A Broken Mind)", was released to critical acclaim worldwide on 14 October 2013. The album reached the UK Top 20, his first album to do so for 30 years. It was promoted by an extensive US, Canada, UK & Ireland tour which continued in 2014 to include Israel, New Zealand, Australia and Europe. A further US leg took place in late 2014.
In June 2014 Numan collaborated with Welshman Jayce Lewis and his Protafield project on the track "Redesign" featured on Protafield's "Nemesis" Album 
Numan also provided vocals for the song "Long Way Down" composed by Masafumi Takada and Rich Dickerson for The Evil Within video game. The game was released on 14 October 2014. Select tracks from the soundtrack were in included on a CD as an Amazon exclusive pre-order bonus which featured "Long Way Down".
Numan performed a sold-out, one-off live show in London in November 2014 at the Hammersmith Apollo supported by Gang Of Four and it is anticipated that this show will be released on DVD in 2015.
Numan, in collaboration with Ade Fenton released the in 2015, his first foray into film scoring since 1995's Human.
Gary Numan plays the Royal Festival Hall, London on 20 March 2015 as part of Convergence which showcases visual art and music pioneers that deploy technology in diverse and innovative ways.
On April 29, 2015, Numan announced via his Facebook page that he began writing songs for the follow-up album to "Splinter (Songs from a Broken Mind)". 
Personal life.
Gary Numan is a positive atheist and has incorporated anti-religious motifs and images in his music. He was an outspoken supporter of the Conservative Party and of Margaret Thatcher after her inauguration as Prime Minister. He later expressed regret for giving his public support, calling it "a noose around my neck". He has previously said that he considers himself neither left-wing nor right-wing and that he does not support Tony Blair or David Cameron. Numan also said, "I'm not socialist, I know that. I don't believe in sharing my money."
In 1997, Numan married a member of his fan club, Gemma O'Neill, a native of Sidcup. Numan used to reside with his family in East Sussex, until he moved to Los Angeles in October 2012. He published his autobiography, "Praying to the Aliens", in 1997 (updated edition 1998), in collaboration with Steve Malins. (Malins also wrote the liner notes for most of the CD reissues of Numan's albums in the late 1990s, as well as executive producing the "Hybrid" album in 2003.)
At age 15, after a series of outbursts in which Numan would "smash things up, scream and shout, get in people's faces and break stuff", he was prescribed antidepressants and anxiolytics. Numan's wife later suggested he had Asperger syndrome. In a 2001 interview, he said: "Polite conversation has never been one of my strong points. Just recently I actually found out that I'd got a mild form of Asperger's syndrome which basically means I have trouble interacting with people. For years, I couldn't understand why people thought I was arrogant, but now it all makes more sense".
Following the apparent harassment of his wife while his family was walking on a High Street in his local area, and his feelings following the 2011 London Riots Numan filed papers to emigrate to the United States Santa Monica, California. Numan said "Every village and town in England has a bunch of thugs running around in it. The riots were the nail in the coffin".
In the September 2011 Q&A section of Numan's official web site, in answer to the question "Is it true you now hate England and want to leave?" he replied, "No, that’s utter rubbish." He explained that he had "never been abused in my local high street," and has "made no firm decision about leaving the UK" but thugs are helping make such a decision, pointing out that the rioting "makes us look like a country of ignorant savages, beating up people already injured, pretending to help while stealing their things, hitting old men, killing them." He went on to explain that soundtracks may be a logical step, as he gets older and since "in the UK we have no meaningful film industry to speak of," a move to the U.S. might be more reasonable. He concluded by saying his family are highest priority and, "If I see somewhere that seems safer, happier, and will give them a better life than the UK, I’ll take them there if I possibly can."

</doc>
<doc id="46015" url="http://en.wikipedia.org/wiki?curid=46015" title="Psion Organiser">
Psion Organiser

The Psion Organiser was the brand name of a range of pocket computer developed by the British company Psion in the 1980s. The Organiser I (launched in 1984) and Organiser II (launched in 1986) had a characteristic hard plastic sliding cover protecting a 6x6 keyboard with letters arranged alphabetically.
The Organiser II can be considered the first usable PDA in that it combined an electronic diary and searchable address database in a small, portable device.
Production of consumer hand-held devices by Psion has now ceased; the company, after corporate changes, now concentrates on hardware and software for industrial and commercial data collection applications.
On an episode of The Gadget Show (first aired on 30 March 2009), the Psion was pitted against the BlackBerry for a place on the show's Hall of Fame. Whilst the Psion was highly praised as a device that pioneered portable computing, the accolade was ultimately given (by host Jon Bentley) to the BlackBerry.
Organiser I.
Launched in 1984, the Psion Organiser was the "World's first practical pocket computer". Based on an 8-bit Hitachi 6301-family processor, running at 0.9 MHz, with 4kB of ROM and 2kB of static RAM, and had a single-row monochrome LCD screen. The size with the case closed is 142 x 78 x 29.3 mm, and the weight is 225 grams.
"BYTE"‍ '​s reviewer described the Organiser's software as a "clever design ... for fast and foolproof use". He approved of the consistent user interface across applications, and reported that without documentation he was able to figure out how to do everything except program in 15 minutes. The machine provided a simple flat-file database, calculator and clock, and had no operating system. The Organiser I supported removable storage write-once devices which used EPROM storage. The machine could host two of these so-called DATAPAKs (or simply PAKs), to which it could write data but which needed to be removed from the machine and erased by being exposed to ultraviolet light before they could be re-used. As Psion had patented the use of EPROMS as storage device it was impossible for other device manufacturers to copy this unusual approach to mobile storage.
Software supplied on DATAPAK included a crude programming language called POPL, in which end-users could write their own programs. Software DATAPAKs titled Science, Maths and Finance contained the POPL programming language editor, interpreter and runtime and extended the built-in calculator by adding named functions. These DATAPAKs also contained different sets of application programs written in the POPL language.
A far more sophisticated programming tool was later made available with the implementation of the Forth programming language, but was available to registered professional developers rather than end users. The Psion Forth Development System for the Organiser I was a powerful set of IBM PC-based cross-development tools for producing Forth application programs, including a Forth compiler. The Forth system on the Organiser I itself had a compiler to intermediate code, interpreter and runtime, and had a number of unusual design features one being that it could interpret - that is, read and execute - Forth intermediate code directly in place on a DATAPAK, rather than needing to copy it into precious RAM first, despite the DATAPAKs not being execute-in-place memory-mapped.
Software developed by Psion as part of the Organiser I project and application software after its launch was written in 6301 assembler language, in POPL, and in other custom-designed languages. Assembler language development at Psion itself was carried out using cross-development tools, including a cross assembler and linker, all of which ran on a DEC VAX.
Application developers writing in 6301 assembler struggled with the small amount of RAM (2k), and the lack of an operating system. Another difficulty for developers was with the performance limitations of the earliest DATAPAKs which used a serial-access internal architecture, as opposed to random access. Retrieving, for example, byte 2000 from a DATAPAK meant issuing successive hardware commands to either step from the current read position one address place at time until position 2000 was reached or in the worst case resetting the read position to zero and then issuing a step-forward command 2000 times.
The Hitachi 6301 processor is an enhanced development based on the Motorola 6801 implemented in CMOS, with a number of extra instructions, various hardware system-on-single chip facilities on-chip, power management and support for a sleep state. The particular variant chosen also had 4KiB of masked ROM on-chip, so an external ROM was not needed on the board.
Having fully static RAM and a processor whose clock could be frozen without losing state meant spectacular battery life, measured in weeks or even months. Minimal battery consumption was aided by the processor being frozen whenever there was no work to do, plus a deeper sleep mode which turned off the display.
The machine lacked a full independently battery-backed, date-time real-time hardware clock, instead it had a simple hardware counter. While the machine was sleeping, the counter counted 1024 seconds and then woke the machine very briefly so that software could add 1024 seconds to a record of the time held in RAM. This meant that when sleeping the machine woke very, very fleetingly every 17m 4s.
The original 1984 price was £99 (GBP) and $199 (CAD) and included one Datapak and one software DATAPAK, the "Utility" pack. This latter adds scientific and trigonometric functions to the otherwise basic calculator routines.
Organiser II.
In 1986, the successful Organiser II introduced a number of hardware improvements, a better keyboard and display, a much larger ROM and either 8K or 16K of battery-backed RAM, and featured a capable newly designed single-tasking operating system. The first Organiser II models featured a two-line display. The new model supported a number of different types of improved DATAPAKs containing either EPROM or battery-backed RAM storage each storing between 8k and 128k of data. Later flashpaks (EEPROM) and RAMpaks were added to the range, capable of storing up to 256k on each extension slot.
The machine had vastly more application functionality, including a number of built-in application programs, an easy to use database, a diary and an alarm clock and featured end-user programmability in the form of the successful Organiser Programming Language (OPL), a BASIC-like language which was compiled to intermediate code, in contrast to the interpreters which were commonly available for other consumer computers of the time. More advanced users could reach into the system machine code routines either via direct machine code, or via calls from OPL, and could manipulate the built-in address database as well as create their own.
The Organiser II was widely used for commercial applications in companies such as Marks and Spencer, where it was used on the shop floor, and in the world's first large scale application of mobile technology in government where over 3000 were used for benefit calculations by the Employment Services department of the UK government.
The Organiser II also had an external device slot into which various plug-in modules could be fitted, including a device which provided an RS232 port (called 'CommsLink') thus enabling it to communicate with other devices or computers. This "top slot" also supported various other hardware additions, such as telephone dialers, a speech synthesiser, barcode reader and even a dedicated thermal printer. This latter was used by several banks as a counter-top exchange rate calculator for some years. As it was easy to get hardware specifications, numerous bespoke devices were developed by small companies such as A/D converters and even an interface to the entire range of Mitutoyo measuring equipment, allowing it to be used in quality control for various car manufacturers. Later models in the Organiser II range offered other hardware improvements, with 4-line displays, and also models were introduced with 32, 64 and 96KB RAM.
Subsequent hand-held devices.
The name "Organiser" was not used for later Psion handhelds, such as the "SIBO" family Psion Series 3 and the 32-bit Psion Series 5 machines which were of a clamshell design with a QWERTY keyboard. In terms of hardware architecture and operating system, these had no links to the earlier "Organiser" range, other than the end user programming language which shared a great deal of structure with OPL.
The "SIBO" family name stood for "SIxteen Bit Organiser" and the improved version of the OPL language (with window and focus controls) was at the root of what was later sold as the Symbian operating system, which until 2010 was the most widely used OS in smartphones, being in 2011 displaced by Google's Android OS. This change was more significant than appeared at the time. The consumer level 'high' programming language still shares features with OPL, but the developer toolkits were from then on focused on programmers familiar with C and only the Symbian operating system remains.
The first similar device made in the USA didn't appear until 1985 and was manufactured by Validec.

</doc>
<doc id="46016" url="http://en.wikipedia.org/wiki?curid=46016" title="Psion (company)">
Psion (company)

Psion was a designer and manufacturer of mobile handheld computers for commercial and industrial applications. The company was headquartered in London, England with major operations in Mississauga, Ontario, Canada and additional company offices in Europe, the United States, Asia, Latin America, and the Middle East. It was a public company listed on the London Stock Exchange (LSE: ) and was once a constituent of the FTSE 100 Index.
Psion's operational business was formed in September 2000 from a merger of Psion and Canadian-based Teklogix Inc. and is a global provider of solutions for mobile computing and wireless data collection. The Group's products and services include rugged mobile hardware, secure wireless networks, robust software, professional services and support programs. Psion works with its clients in the area of new and emerging technologies including image capture, voice recognition and RFID. Psion has customers in more than 80 countries around the world, as well as operations in 14 countries.
Formed in 1980, Psion achieved its first successes as a consumer hardware company that developed the revolutionary Psion Organiser as well as a whole range of more advanced, clamshell-design Personal Digital Assistants. Psion closed, or disposed of, all its previous operations and is now focused on rugged mobile computing solutions. It withdrew from the consumer devices marketplace in 2001. It was announced on 15 June 2012 that Motorola Solutions had agreed to buy the company for $200 million.
History.
Early development.
Psion was established in 1980 as a software house with a close relationship with Sinclair Research. The company developed games and other software for the ZX81 and ZX Spectrum home computers, released under the Sinclair/Psion brand. Psion’s games for the ZX Spectrum included Chess, Chequered Flag, Flight Simulation and the Horace series. 
Early software releases for the ZX Spectrum included titles such as VU-Calc, VU-File and VU-3D along with dozens of other titles.
The company name is an acronym standing for "Potter Scientific Instruments", after the company's founder, David Potter. The acronym PSI was already in use elsewhere in the world so "ON" was added to make the name PSION unique. David Potter remained managing director until 1999 and was chairman of the company until late 2009.
In early 1983, Sinclair approached Psion regarding the development of a suite of office applications for the forthcoming Sinclair QL personal computer. Psion were already working on a project in this area and the QL was launched in 1984, bundled with "Quill", "Archive", "Abacus" and "Easel"; respectively a word processor, database, spreadsheet and business graphics application. These were later ported to MS-DOS, collectively called "PC-Four", or "Xchange" in an enhanced version.
The Psion Organiser.
1984 also marked Psion’s first foray into hardware; the Psion Organiser, an early handheld computer, in appearance resembling a pocket calculator with an alphanumeric keyboard. In 1986, the vastly improved Psion Organiser II was released. Its success led the company into a decade long period of "Psion" Computer and operating system development. It included a simple-to-use database programming language, OPL, which sparked a large independent software market. In 1987, Psion began development of its "SIBO" ("SIxteen Bit Organiser") family of devices and its own new multitasking operating system called EPOC to run its PDA products. It is often rumoured that EPOC stands for "Electronic Piece Of Cheese" however Colly Myers, who was Symbian's CEO from founding until 2002, said in an interview that it stood for 'epoch' and nothing more. This development effort produced the clamshell QWERTY-based Psion Series 3 palmtops (1993–98), which sold in the hundreds of thousands, and the Psion MC-series laptops, which sold poorly compared to the DOS-based laptops of the era.
A second effort, dubbed Project Protea, produced the Psion Series 5 for sale in 1997, a completely new product from the 32-bit hardware upwards through the OS, UI, and applications. It is still remembered for its high quality keyboard which, despite its size, allowed for touch-typing. However, the new feel of the product, and the removal of certain familiar quirks, alienated loyal Series 3 users, who tended to stick with their PDAs rather than upgrade. In 1999, Psion released the Psion Series 7, which was much like a larger version of the Series 5, followed by the very similar Psion netBook.
Psion was being challenged by the arrival of cheaper PDAs such as the Palm Pilot, and PocketPCs running Microsoft’s Windows CE. All of Psion's earlier devices had monochrome screens, but in 2003, it released a color-screen Netbook Pro running Windows CE .NET 4.2 instead of EPOC.
Software.
The 32-bit EPOC developed by Project Protea resulted in the eventual formation of Symbian Ltd. in June 1998 in conjunction with Nokia, Ericsson and Motorola. The OS was renamed the Symbian Operating System and was envisioned as the base for a new range of smartphones. Psion gave 130 key staff to the new company and retained a 31% shareholding in the spun-out business. The Symbian operating system as of 2007[ [update]] powered around 125 million mobile phones such as the Sony Ericsson P900 series.
The development of new and updated products by Psion slowed after the Symbian spin-off. Other products failed or had limited success — a Psion Siemens' GSM device, a Series 5 based STB, the Wavefinder DAB radio, an attempt to add Dragon's speech recognition software to a PDA, Ericsson cancelled a Series 5MX derived smartphone project in 2001.
Psion had sold its sole manufacturing plant in 1999 and started to withdraw from its PDA markets in late 2001, shedding 250 of 1,200 staff and writing-off £40 million. The PDA, which was once a niche market, had become a global horizontal marketplace where it was difficult for Psion to compete. The final blow for Psion's Organiser and PDA business came in January 2001 when Motorola pulled out of a joint project with Psion, Samsung, and Parthus, to create "Odin", an ARM-based PDA-phone.
In 2000, Psion acquired Teklogix in Canada for £240 million, and merged its business-to-business division, Psion Enterprise, with the newly acquired company. Teklogix was re-branded Psion Teklogix. This division now forms the core of Psion Plc's business. 
In 2002, Psion created a new division called Psion Software. This business developed push email solutions for Symbian smartphones, Microsoft Exchange and Lotus Notes. This business was sold to Visto (USA) in 2003. 
In 2004, Psion announced its intention to dispose of the company's remaining Symbian shareholding to Nokia, as they no longer regarded it as a core part of their strategy.
2010 onward.
Psion intends to tailor and customize modular variants of its products through its online community, . Launched in March 2010, Ingenuity Working had more than 35,000 visitors per month within its first six months.
In January 2011, the company refreshed its corporate identity and developed a new logo, which it describes as an icon. It claims it did this to "demonstrate its new business model in action and to signal that it is no longer a consumer products company, which was symbolized by the old Psion logo".
At the same time it removed Teklogix from its operating company name to create a "clear, unifying, global identity".
Psion and the term "Netbook".
Psion registered the trademark "NETBOOK" in various territories, including European Union and , which was applied for on 18 December 1996 and registered by USPTO on 21 November 2000. They used this trademark for the Psion netBook product, discontinued in November 2003, and from October 2003, the NETBOOK PRO, later also discontinued.
Intel started using the term "netbook" in March 2008 as a generic term to describe "small laptops that are designed for wireless communication and access to the Internet", believing they were "not offering a branded line of computers here" and "see no naming conflict".
In response to the growing use of the term, on 23 December 2008 Psion Teklogix sent cease and desist letters to various parties including enthusiast website(s) demanding they no longer use the term "netbook".
In early 2009, Intel sued Psion Teklogix (US & Canada) and Psion (UK) in the Federal Court, seeking a cancellation of the trademark and an order enjoining Psion from asserting any trademark rights in the term "netbook", a declarative judgement regarding their use of the term, attorneys' fees, costs and disbursements and "such other and further relief as the Court deems just and proper". The suit was settled out of court, and on June 2, 2009 Psion announced that the company was withdrawing all of its trademark registrations for the term "Netbook" and that Psion agreed to "waive all its rights against third parties in respect of past, current or future use" of the term.
Similar marks have been recently rejected by the USPTO citing a "likelihood of confusion" under section 2(d), including 'G NETBOOK' ( rejected 31 October 2008), MSI's 'WIND NETBOOK' () and Coby Electronics' 'COBY NETBOOK' ( rejected 13 January 2009)
Psion and Linux.
Psion PLC had a lengthy, but distant, interest in Linux as an operating system on its electronic devices. In 1998, it supported the Linux7K project that had been initiated by Ed Bailey at Red Hat, which was to port Linux to its Series 5 personal computer. The project was named after the
Cirrus Logic PS-7110 chip of the Series 5. Although this project was one of the earliest attempts to port Linux to a handheld computer, it did not come to fruition for Psion. The project soon transitioned to an informal open source project at Calcaria.net that kept the name Linux7K. After the project transitioned again to sourceforge.net, the project's name was changed to a more general name "PsiLinux", and more recently to "". The project has developed Linux kernels and filesystems for the Revo, Series 5 and 5MX, and Series 7 and netBook.
In 2003–4, Psion Teklogix and its founder David Potter expressed interest in Linux as the operating system for its devices as it divested from Symbian. However, the only result of that interest was Linux as the operating system on a limited number of custom NetBook Pros designed for a hospital setting.
The Embeddable Linux Kernel Subset project has produced a small subset of Linux that runs on Psion Series 3 PDAs.
PDAs.
All these PDAs except the Psion netpad have a small keyboard, which excepting the Organiser and Workabout was of the standard QWERTY layout, or a regional variation thereof.

</doc>
<doc id="46019" url="http://en.wikipedia.org/wiki?curid=46019" title="1490s BC">
1490s BC


</doc>
<doc id="46021" url="http://en.wikipedia.org/wiki?curid=46021" title="Rambouillet Agreement">
Rambouillet Agreement

The Rambouillet Agreement was a proposed peace agreement between the Federal Republic of Yugoslavia and a delegation representing the Albanian majority population of Kosovo. It was drafted by the North Atlantic Treaty Organisation (NATO) and named for Chateau Rambouillet, where it was initially proposed. The significance of the agreement lies in the fact that Yugoslavia refused to accept it, which NATO used as justification to start the Kosovo War. Belgrade's rejection was based on the argument that the agreement contained provisions for Kosovo's autonomy that went further than the Serbian/Yugoslav government saw as reasonable.
Negotiations.
The biggest problem for both sides was that the Albanians were unwilling to accept a solution that would retain Kosovo as part of Serbia, whilst the Serbs did not want to see the pre-1990 status quo restored, and they were implacably opposed to any international role in the governance of the province, including the offer of a face-saving measure wherein blue-helmeted UN peacekeeping troops would be used instead of NATO troops. The negotiations thus became somewhat a game of musical chairs, each side trying to avoid being blamed for the breakdown of the talks. To add to the farce, the NATO Contact Group countries were desperate to avoid having to make good on their threat of force—Greece and Italy were opposed to the idea. Consequently, when the talks failed to achieve an agreement by the original deadline of 19 February, they were extended by another month.
The two paragraphs above, however, are partially contradicted by the historical evidence. In particular, the statement by the co-chairmen on 23 February 1999 that the negotiations "have led to a consensus on substantial autonomy for Kosovo, including on mechanisms for free and fair elections to democratic institutions, for the governance of Kosovo, for the protection of human rights and the rights of members of national communities; and for the establishment of a fair judicial system". They went on to say that "a political framework is now in place" leaving the further work of finalizing "the implementation Chapters of the Agreement, including the modalities of the invited international civilian and military presence in Kosovo".
In the end, on 18 March 1999, the Albanian, American and British delegation signed what became known as the 'Rambouillet Accords' while the Serbian and Russian delegations refused. The accords called for NATO administration of Kosovo as an autonomous province within Yugoslavia; a force of 30,000 NATO troops to maintain order in Kosovo; an unhindered right of passage for NATO troops on Yugoslav territory, including Kosovo; and immunity for NATO and its agents to Yugoslav law.
In commentary released to the press, former United States Secretary of State Henry Kissinger declared that:
The Rambouillet text, which called on Serbia to admit NATO troops throughout Yugoslavia, was a provocation, an excuse to start bombing. Rambouillet is not a document that an angelic Serb could have accepted. It was a terrible diplomatic document that should never have been presented in that form.—Henry Kissinger, "Daily Telegraph", 28 June 1999
Events proceeded rapidly after the failure at Rambouillet. The international monitors from the OSCE withdrew on 22 March, for fear of the monitors' safety ahead of the anticipated bombing by NATO. On 23 March, the Serbian assembly accepted the principle of "autonomy" for Kosovo and non-military part of the agreement. The Serbian side initially had no objections to appendix B of the Agreement – which had been drafted by NATO officers in the expectation that the parties to the agreement would whittle it down – but appendix B was later used as a reason for the failure of talks, characterising it as "NATO occupation".
NATO leaders had expected that a brief bombing campaign would lead to Serb forces withdrawing from Kosovo, hence ending the humanitarian crisis; but Milošević may have gambled that his government and armed forces could withstand a few days of bombing without serious harm.
Further reading.
Weller, Marc. . "International Affairs (Royal Institute of International Affairs 1944–)", Vol. 75, No. 2 (Apr. 1999), pp. 211–251.

</doc>
