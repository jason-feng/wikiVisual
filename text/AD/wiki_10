<doc id="44354" url="http://en.wikipedia.org/wiki?curid=44354" title="Carole Lombard">
Carole Lombard

Carole Lombard (born Jane Alice Peters; October 6, 1908 – January 16, 1942) was an American film actress. She was particularly noted for her highly neurotic, energetic and often off-beat roles in the screwball comedies of the 1930s. She was the highest-paid star in Hollywood in the late 1930s.
Lombard was born into a wealthy family in Fort Wayne, Indiana, on October 6, 1908. She attended Virgil Junior High School, where she excelled in sports, and while playing baseball caught the attention of the film director Allan Dwan, which led to her screen debut in "A Perfect Crime" (1921). In October 1924, at the age of 16, she signed a contract with the Fox Film Corporation, and got her first break the following year opposite Edmund Lowe in the successful drama "Marriage in Transit". She was dropped by Fox after a car accident that left a scar on her face. Lombard appeared in 15 short films of Pathé Exchange between September 1927 and March 1929, and then began appearing in feature films such as "High Voltage" and "The Racketeer". After a successful one-off appearance opposite Warner Baxter in Fox's "The Arizona Kid", she signed a contract with Paramount Pictures who cast her in the Buddy Rogers comedy "Safety in Numbers" (1930).
Lombard began appearing in comedies with William Powell such as "Man of the World" and "Ladies Man", and married him in June 1931. The marriage to Powell increased Lombard's fame, and the two would continue to occasionally star together throughout the 1930s, despite being divorced in 1933. Lombard starred alongside Clark Gable (whom she married in 1939) in "No Man of Her Own" (1932) and George Raft in "Bolero" (1934), where her dance skills were praised. After roles in successful films such as "Twentieth Century" (1934), "Hands Across the Table" (1935), which was the first of four comedies made with Fred MacMurray, "The Princess Comes Across" (1936), "My Man Godfrey" (1936), which won her an Academy Award nomination opposite Powell, "Swing High, Swing Low" (1937), and "Nothing Sacred" (1937), Lombard had become the highest-paid actress in Hollywood and one of its most popular stars. Eager to win an Oscar, by the end of the decade she began to move away from comedies towards more serious roles, appearing opposite James Stewart in the drama "Made for Each Other" (1939) and alongside Cary Grant in the romance "In Name Only" (1939). Her role as a nurse in "Vigil in the Night" was her most notable attempt to win an Oscar but didn't receive a nomination. Lombard returned to comedy in Alfred Hitchcock's "Mr. & Mrs. Smith" in 1941.
Lombard's career was cut short when she died at the age of 33 in an aircraft crash on Mount Potosi, Nevada while returning from a World War II War Bond tour. Her final film, Ernst Lubitsch's "To Be or Not to Be" (1942), a satire about Nazism and the war, was in post-production at the time of her death. Today she is remembered as one of the definitive actresses of the screwball comedy genre and American comedy, and ranks among the American Film Institute's greatest stars of all time. The World War II Liberty Ship "SS Carole Lombard" and the Carole Lombard Memorial Bridge over the St. Mary's River in Fort Wayne were named after her.
Early years.
Childhood.
Lombard was born in Fort Wayne, Indiana, on October 6, 1908. Christened with the name Jane Alice Peters, she was the third and youngest child of Frederic Peters (1875–1935) and Elizabeth "Bessie" Knight Peters (1877–1942). Her older brothers, each of whom she was close to both growing up and in adulthood, were Frederic Jr. (1902-1979) and Stuart (1906-1956). Lombard's parents both descended from wealthy families and her early years were lived in comfort, with the biographer Robert Matzen calling it her "silver spoon period". The marriage between her parents was strained, however, and in October 1914, her mother took the children and moved to Los Angeles. Although the couple did not divorce, the separation was permanent. Her father's continued financial support allowed the family to live without worry, if not with the same affluence they had enjoyed in Indiana, and they settled into an apartment near Venice Boulevard in Los Angeles.
Described by her biographer Wes Gehring as "a free-spirited tomboy", the young Lombard was passionately involved in sports and enjoyed watching movies. At Virgil Junior High School, she participated in tennis, volleyball, and swimming, and won trophies for her achievements in athletics. At the age of 12, this hobby unexpectedly landed Lombard her first screen role. While playing baseball with friends, she caught the attention of the film director Allan Dwan, who later recalled seeing "a cute-looking little tomboy ... out there knocking the hell out of the other kids, playing better baseball than they were. And I needed someone of her type for this picture." With the encouragement of her mother, Lombard happily took a small role in the melodrama "A Perfect Crime" (1921). She was on set for two days, playing the sister of Monte Blue. Dwan later commented, "She ate it up".
Aspiring actress, Fox (1921–26).
"A Perfect Crime" was not widely distributed, but the brief experience spurred Lombard and her mother to look for more film work. The teenager attended several auditions, but none were successful. While appearing as the queen of Fairfax High School's May Day Carnival at the age of 15, she was scouted by an employee of Charlie Chaplin and offered a screen test to appear in his film "The Gold Rush" (1925). Lombard was not given the role, but it raised Hollywood's awareness of the aspirant-actress. Her test was seen by the Vitagraph Film Company, who expressed an interest in signing her to a contract. Although this did not materialize, the condition that she adopt a new first name ("Jane" was considered too dull) lasted with Lombard throughout her career. She selected the name "Carol" after a girl she played tennis with in middle school.
In October 1924, shortly after these disappointments, 16-year-old Lombard was signed to a contract with the Fox Film Corporation. How this came about is uncertain: in her lifetime, it was reported that a director for the studio scouted her at a dinner party, but more recent evidence suggests that Lombard's mother contacted Louella Parsons, the gossip columnist, who then got her a screen test. According to the biographer Larry Swindell, it was Lombard's beauty that convinced Winfield Sheehan, head of the studio, to sign her to a $75-per-week contract. The teenager abandoned her schooling to embark on this new career. Fox were happy to use the name Carol, but unlike Vitagraph they disliked her surname. From this point she became "Carol Lombard", the new name taken from a family friend.
The majority of Lombard's appearances with Fox were bit parts in low-budget westerns and adventure films. She later commented on her dissatisfaction with these roles: "All I had to do was simper prettily at the hero and scream with terror when he battled with the villain." She fully enjoyed the other aspects of film work, however, such as photo-shoots, costume fittings, and socializing with actors on the studio set. Lombard embraced the flapper lifestyle and became a regular at the Coconut Grove nightclub, where she won several Charleston dance competitions.
In March 1925, Fox gave Lombard a leading role in the drama "Marriage in Transit", opposite Edmund Lowe. Her performance was well-received, with a reviewer for "Motion Picture News" writing that she displayed, "good poise and considerable charm." Despite this, the studio heads were unconvinced that Lombard was leading lady material, and her one-year contract was not renewed. Gehring has suggested that a facial scar she obtained in an automobile accident was a factor in this decision. Fearing that the scar—which ran across her cheek—would ruin her career, the 17-year-old had an early plastic surgery procedure to make it less visible. For the remainder of her career, Lombard learned to hide the mark with make-up and careful lighting.
Breakthrough.
Sennett and Pathé (1927–29).
After a year without work, Lombard obtained a screen test for the "King of Comedy" Mack Sennett. She was offered a contract, and although she initially had reservations about performing in slapstick comedies, the actress joined his company as one of the "Sennett Bathing Beauties". She appeared in 15 short films between September 1927 and March 1929, and greatly enjoyed her time at the studio. It gave Lombard her first experiences in comedy and provided valuable training for her future work in the genre. In 1940, she called her Sennett years "the turning point of [my] acting career."
Sennett's productions were distributed by Pathé Exchange, and in 1928 the company began casting Lombard in feature films. She had prominent roles in "Show Folks" and "Ned McCobb's Daughter", where reviewers noted that she made a "good impression" and was "worth watching". The following year, Pathé elevated Lombard from a supporting player to a leading lady. Her success in Raoul Walsh's 1928 picture "Me, Gangster", opposite June Collyer and Don Terry on his film debut, finally eased the pressure her family had been putting on her to succeed. In Howard Higgin's "High Voltage", her first talking picture, she played a sheriff's daughter stranded with a group during a snow storm. Her next film, the comedy "Big News", cast her opposite Robert Armstrong and was a critical and commercial success. Lombard was reunited with Armstrong for the crime–drama "The Racketeer", released in late 1929. The review in "Film Daily" wrote, "Carol Lombard proves a real surprise, and does her best work to date. In fact this is the first opportunity she has had to prove that she has the stuff to go over."
Paramount, Powell marriage (1930–33).
In 1930, Lombard returned to Fox for a one-off role in the western "The Arizona Kid". It was a big release for the studio, starring the popular actor Warner Baxter, in which Lombard received third billing. Following the success of the film, Paramount Pictures recruited Lombard and signed her to a $350-per-week contract (gradually increasing to $3,500-per-week by 1936). They cast her in the Buddy Rogers comedy "Safety in Numbers", and one critic observed of her work, "Lombard proves [to be] an ace comedienne." For her second assignment, "Fast and Loose" with Miriam Hopkins, Paramount mistakenly credited the actress as "Carole Lombard". She decided she liked this spelling and it became her permanent screen name.
Lombard appeared in five films throughout 1931, beginning with the Frank Tuttle comedy "It Pays to Advertise". Her next two films, "Man of the World" and "Ladies Man", both featured William Powell, Paramount's top male star. Lombard had been a fan of the actor before they met, attracted to his good looks and debonair screen persona, and they were soon in a relationship. The differences between the pair have been noted by biographers: she was 22, carefree, and famously foul-mouthed, while he was 38, intellectual, and sophisticated. Despite their disparate personalities, Lombard married Powell on June 6, 1931, at her Beverly Hills home. Talking to the media, she argued for the benefits of "love between two people who are diametrically different", claiming that their relationship allowed for a "perfect see-saw love".
The marriage to Powell increased Lombard's fame, while she continued to please critics with her work in "Up Pops the Devil" and "I Take this Woman" (both 1931). In reviews for the latter film, which co-starred Gary Cooper, several critics predicted that Lombard was set to become a major star. She went on to appear in five films throughout 1932. "No One Man" and "Sinners in the Sun" were not successful, but Edward Buzzell's romantic picture "Virtue" was well received. After featuring in the drama "No More Orchids", Lombard was cast as the wife of a con-artist in "No Man of Her Own". Her co-star for the picture was Clark Gable, who was rapidly becoming one of Hollywood's top celebrities. The film was a critical and commercial success, and Wes Gehring writes that it was "arguably Lombard's finest film appearance" to that point. It was the only picture that Gable and Lombard, future husband and wife, made together. There was no romantic interest at this time however, as she recounted to Garson Kanin: "[we] did all kinds of hot love scenes ... and I never got any kind of tremble out of him at all."
In August 1933, Lombard and Powell divorced after 26 months of marriage, although they remained very good friends until Lombard's death. At the time she blamed it on their careers, but in a 1936 interview she admitted that this "had little to do with the divorce. We were just two completely incompatible people." She appeared in five films that year, beginning with the drama "From Hell to Heaven" and continuing with "Supernatural", her only horror vehicle. After a small role in "The Eagle and the Hawk", a war film starring Fredric March and Cary Grant, she starred in two melodramas: "Brief Moment", which critics enjoyed, and "White Woman", where she was paired with Charles Laughton.
Hollywood star.
Screwball beginnings (1934–35).
The year 1934 marked a high point in Lombard's career. She began with Wesley Ruggles's musical drama "Bolero", where she and George Raft showcased their dancing skills in an extravagantly-staged performance to Maurice Ravel's "Boléro". Before filming began, she was offered the lead female role in "It Happened One Night", but turned it down because of scheduling conflicts with this production. "Bolero" was favorably received, while her next film, the musical comedy "We're Not Dressing" with Bing Crosby, was a box office hit.
Lombard was then recruited by the director Howard Hawks, a second cousin, to star in his screwball comedy film "Twentieth Century" which proved a watershed in her career and made her a major star. Hawks had seen the actress inebriated at a party, where he found her to be "hilarious and uninhibited and just what the part needed", and she was cast opposite John Barrymore. In "Twentieth Century", Lombard played an actress who is pursued by her former mentor, a flamboyant Broadway impresario. Hawks and Barrymore were unimpressed with her work in rehearsals, finding that she was "acting" too hard and giving a stiff performance. The director encouraged Lombard to relax, be herself, and act on her instincts. She responded well to this tutoring, and reviews for the film commented on her unexpectedly "fiery talent"—"a Lombard like no Lombard you've ever seen". The "Los Angeles Times"' critic felt that she was "entirely different" from her formerly cool, "calculated" persona, adding, "she vibrates with life and passion, abandon and diablerie".
The next films Lombard appeared in were Henry Hathaway's "Now and Forever" (1934), featuring Gary Cooper and the new child star Shirley Temple, and "Lady by Choice" (1934), which was a critical and commercial success. "The Gay Bride" (1934) placed her opposite Chester Morris in a gangster comedy, but this outing was panned by critics. After reuniting with George Raft for another dance picture, "Rumba" (1935), Lombard was given the opportunity to repeat the screwball success of "Twentieth Century". In Mitchell Leisen's "Hands Across the Table" (1935), she portrayed a manicurist in search of a rich husband, played by Fred MacMurray. Critics praised the film, and "Photoplay"'s reviewer stated that Lombard had reaffirmed her talent for the genre. It is remembered as one of her best films, and the pairing of Lombard and MacMurray proved so successful that they made three more pictures together.
Continued success (1936–37).
Lombard's first film of 1936 was "Love Before Breakfast", described by Gehring as ""The Taming of the Shrew", screwball style". In William K. Howard's "The Princess Comes Across", her second comedy with MacMurray, she played a budding actress who wins a film contract by masquerading as a Swedish princess. The performance was considered a satire of Greta Garbo, and was widely praised by critics. Lombard's success continued as she was recruited by Universal Studios to star in the screwball comedy "My Man Godfrey" (1936). William Powell, who was playing the titular Godfrey, insisted on her being cast as the female lead; despite their divorce, the pair remained friendly and Powell felt she would be perfect in the role of Irene, a zany heiress who employs a "forgotten man" as the family butler. The film was directed by Gregory LaCava, who knew Lombard personally and advised that she draw on her "eccentric nature" for the role. She worked hard on the performance, particularly with finding the appropriate facial expressions for Irene. "My Man Godfrey" was released to great acclaim and was a box office hit. It received six nominations at the 9th Academy Awards, including Lombard for Best Actress. Biographers cite it as her finest performance, and Frederick Ott says it "clearly established [her] as a comedienne of the first rank."
By 1937, Lombard was one of Hollywood's most popular actresses, and also the highest-paid star in Hollywood following the deal which Myron Selznick negotiated with Paramount that brought her $450,000, 
more than five times the salary of the U.S. President.
As her salary was widely reported in the press, Lombard stated that 80 percent of her earnings went in taxes but that she was happy to help improve her country. The comments earned her much positive publicity, and President Franklin D. Roosevelt sent her a personal letter of thanks.
Her first release of the year was Leisen's "Swing High, Swing Low", a third pairing with MacMurray. The film focused on a romance between two cabaret performers, and was a critical and commercial success. It had been primarily a drama, with occasional moments of comedy, but for her next project Lombard returned to the screwball genre. The producer David O. Selznick was eager to make a comedy with the actress, impressed by her work in "My Man Godfrey", and hired Ben Hecht to write an original screenplay for her. "Nothing Sacred", directed by William Wellman and co-starring Fredric March, satirized the journalism industry and "the gullible urban masses", with Lombard playing a small-town girl who pretends to be dying and finds her story exploited by a New York reporter. Marking her only appearance in Technicolor, the film was highly praised and was one of Lombard's personal favorites.
Lombard continued with screwball comedies, next starring in what Swindell calls one of her "wackiest" films, "True Confession" (1937). She played a compulsive liar who wrongly confesses to murder. Lombard loved the script and was excited about the project, which reunited her with John Barrymore and was her final appearance with MacMurray. Her prediction that it "smacked of a surefire success" proved accurate, as critics responded positively and it was popular at the box office.
Gable marriage, dramatic efforts (1938–40).
"True Confession" was the last film Lombard made on her Paramount contract, and she remained an independent performer for the rest of her career. Her next film was made at Warner Bros., where she played a famous actress in Mervyn LeRoy's "Fools for Scandal" (1938). The comedy met with scathing reviews and was a commercial failure, with Swindell calling it "one of the most horrendous flops of the thirties".
"Fools for Scandal" was the only film Lombard made in 1938. By this time, she was devoted to a relationship with Clark Gable. Four years after their teaming on "No Man of Her Own", the pair had reunited at a Hollywood party and began a romance early in 1936. The media took great interest in their partnership and frequently questioned if they would wed. Gable was separated from his wife, Rhea Langham, but she did not want to grant him a divorce. As his relationship with Lombard became serious, Langham eventually agreed to a settlement worth half a million dollars. The divorce was finalized in March 1939, and Gable and Lombard eloped in Kingman, Arizona on 29 March. The couple—both lovers of the outdoors—bought a 20-acre ranch in Encino, California, where they kept barnyard animals and enjoyed hunting trips. Almost immediately, Lombard wanted to start a family, but her attempts failed: after two miscarriages and numerous trips to fertility specialists, she was unable to have children.
While continuing with a slower work-rate, Lombard decided to move away from comedies and return to dramatic roles. In 1939 she appeared in a second David O. Selznick production, "Made for Each Other", which paired her with James Stewart to play a couple facing domestic difficulties. Reviews for the film were highly positive, and praised Lombard's dramatic effort; financially, it was a disappointment. Lombard's next appearance came opposite Cary Grant in the John Cromwell romance "In Name Only" (1939), a credit she personally negotiated with RKO Radio Pictures upon hearing of the script and Grant's involvement. The role mirrored her recent experiences, as she played a woman in love with a married man whose wife refuses to divorce. She was paid $150,000 for the film, continuing her status as one of Hollywood's highest-paid actresses, and it was a moderate success.
Lombard was eager to win an Academy Award, and selected her next project—from several possible scripts—with the expectation that it would bring her the trophy. "Vigil in the Night" (1940), directed by George Stevens, featured Lombard as a nurse who faces a series of personal difficulties. Although the performance was praised she did not get her nomination, as the sombre mood of the picture turned audiences away and box-office returns were poor. Despite the realization that she was best suited to comedies, Lombard completed one more drama: "They Knew What They Wanted" (1940), co-starring Charles Laughton, which was mildly successful.
Final roles (1941–1942).
Accepting that "my name doesn't sell tickets to serious pictures", Lombard returned to comedy for the first time in three years to film "Mr. & Mrs. Smith" (1941), about a couple who learn that their marriage is invalid, with Robert Montgomery. Lombard was influential in bringing Alfred Hitchcock, whom she knew through David O. Selznick, to direct one of his most atypical films. It was a commercial success, as audiences were happy with what Swindell calls "the belated happy news ... that Carole Lombard was a screwball once more."
It was nearly a year before Lombard committed to another film, as she focused instead on her home and marriage. Determined that her next film be "an unqualified smash hit", she was also careful in selecting a new project. Through her agent, Lombard heard of Ernst Lubitsch's upcoming film: "To Be or Not to Be", a dark comedy that satirized the Nazi takeover of Poland. The actress had long wanted to work with Lubitsch, her favorite comedy director, and felt that the material—although controversial—was a worthy subject. Lombard accepted the role of actress Maria Tura, despite it being a smaller part than she was used to, and was given top-billing over the film's lead, Jack Benny. Filming took place in the fall of 1941, and was reportedly one of the happiest experiences of Lombard's career.
Death.
When the U.S. entered World War II at the end of 1941, Lombard traveled to her home state of Indiana for a war bond rally with her mother, Bess Peters, and Clark Gable's press agent, Otto Winkler. Lombard was able to raise over $2 million in defense bonds in a single evening. Her party had initially been scheduled to return to Los Angeles by train, but Lombard was anxious to reach home more quickly and wanted to fly by a scheduled airline. Her mother and Winkler were both afraid of flying and insisted they follow their original travel plans. Lombard suggested they flip a coin; they agreed and Lombard won the toss.
In the early morning hours of January 16, 1942, Lombard, her mother, and Winkler boarded a Transcontinental and Western Air Douglas DST aircraft to return to California. After refueling in Las Vegas, TWA Flight 3 took off at 7:07 p.m. and approximately 13 minutes later, crashed into "Double Up Peak" near the 8300 ft level of Potosi Mountain, 32 smi southwest of Las Vegas. All 22 aboard, Lombard and her mother included, plus 15 army servicemen, were killed instantly.
Aftermath.
Gable was flown to Las Vegas after learning of the tragedy to claim the bodies of his wife, mother-in-law, and Winkler, who aside from being his press agent had been a close friend. Lombard's funeral was held on January 21 at Forest Lawn Memorial Park Cemetery in Glendale, California. She was interred beside her mother under the name of Carole Lombard Gable. Despite remarrying twice following her death, Gable chose to be interred beside Lombard when he died in 1960.
Lombard's final film, "To Be or Not to Be" (1942), directed by Ernst Lubitsch and co-starring Jack Benny, a satire about Nazism and World War II, was in post-production at the time of her death. The film's producers decided to cut part of the film in which Lombard's character asks, "What can happen on a plane?" out of respect for the circumstances surrounding her death. When the film was released, it received mixed reviews, particularly about its controversial content, but Lombard's performance was hailed as the perfect send-off to one of 1930s Hollywood's most important stars.
At the time of her death, Lombard had been scheduled to star in the film "They All Kissed the Bride"; when production started, she was replaced by Joan Crawford. Crawford donated all of her salary for the film to the Red Cross, which had helped extensively in the recovery of bodies from the air crash.
Shortly after Lombard's death, Gable, who was inconsolable and devastated by his loss, joined the United States Army Air Forces. Lombard had asked him to do that numerous times after the United States had entered World War II. After officer training, Gable headed a six-man motion picture unit attached to a B-17 bomb group in England to film aerial gunners in combat, flying five missions himself. In December 1943, the United States Maritime Commission announced that a Liberty ship named after Carole Lombard would be launched. Gable attended the launch of the SS "Carole Lombard" on January 15, 1944, the two-year anniversary of Lombard's record-breaking war bond drive. The ship was involved in rescuing hundreds of survivors from sunken ships in the Pacific and returning them to safety.<br>
In 1962, Mrs. Jill Winkler Rath, widow of publicist Otto Winkler, filed an unsuccessful lawsuit for $100,000 against the $2,000,000 estate of Clark Gable in connection with Winkler's death in the plane crash with Carole Lombard. The suit was dismissed in Los Angeles Superior Court. Mrs. Rath, in her action, claimed Gable promised to provide financial aid for her if she would not bring suit against the airline involved. However, Mrs. Rath stated, she later learned that Gable settled his claim against the airline for $10. He did so because he did not want to repeat his grief in court and subsequently provided her no financial aid in his will.
Assessment and legacy.
Author Robert D. Matzen has cited Lombard as "among the most commercially successful and admired film personalities in Hollywood in the 1930s", and feminist writer June Sochen believes that Lombard "demonstrated great knowledge of the mechanics of film making". George Raft, her co-star in "Bolero" was extremely fond of the actress, remarking "I truly loved Carole Lombard. She was the greatest girl that ever lived and we were the best of pals. Completely honest and outspoken, she was liked by everyone".
Lombard was particularly noted for the zaniness of her performances, described as a "natural prankster, a salty tongued straight-shooter, a feminist precursor and one of the few stars who was beloved by the technicians and studio functionaries who worked with her". "Life" magazine noted that her film personality transcended to real life, "her conversation, often brilliant, is punctuated by screeches, laughs, growls, gesticulations and the expletives of a sailor's parrot". Graham Greene praised the "heartbreaking and nostalgic melodies" of her faster-than-thought delivery. "Platinum blonde, with a heart-shaped face, delicate, impish features and a figure made to be swathed in silver lamé, Lombard wriggled expressively through such classics of hysteria as "Twentieth Century" and "My Man Godfrey"."
In 1999, the American Film Institute ranked Lombard 23rd on its list of the 50 greatest American female screen legends, and she has a star on the Hollywood Walk of Fame, at 6930 Hollywood Blvd. Lombard received one Academy Award for Best Actress nomination, for "My Man Godfrey". Actresses who have portrayed her in films include Jill Clayburgh in "Gable and Lombard" (1976), Sharon Gless in "" (1980), Denise Crosby in "Malice in Wonderland" (1985), Anastasia Hille in "RKO 281" (1999) and Vanessa Gray in "Lucy" (2003).
Lombard's Fort Wayne childhood home has been designated a historic landmark. The city named the nearby bridge over the St. Mary's River the Carole Lombard Memorial Bridge.
References.
Bibliography.
</dl>

</doc>
<doc id="44356" url="http://en.wikipedia.org/wiki?curid=44356" title="Peter the Great">
Peter the Great

Peter the Great (Russian: Пётр Вели́кий, "Pyotr Velikiy"; ]), Peter I (Russian: Пётр I, "Pyotr I"; ]) or Pyotr Alexeyevich (Russian: Пётр Алексе́евич; ]; 9 June [O.S. 30 May] 1672 – 8 February [O.S. 28 January] 1725) ruled the Tsardom of Russia and later the Russian Empire from 7 May (O.S. 27 April) until his death, jointly ruling before 1696 with his half-brother. Through a number of successful wars he expanded the Tsardom into a much larger empire that became a major European power. He led a cultural revolution that replaced some of the traditionalist and medieval social and political systems with ones that were modern, scientific, westernized, and based on The Enlightenment. Peter's reforms made a lasting impact on Russia and many institutions of Russian government traced their origins to his reign.
Title.
The imperial title of Peter the Great was the following:
Life.
Early years.
From an early age, Peter's education (commissioned by Tsar Alexis I) was put in the hands of several tutors, most notably Nikita Zotov, Patrick Gordon, and Paul Menesius. On 29 January 1676, Tsar Alexis died, leaving the sovereignty to Peter's elder half-brother, the weak and sickly Feodor III. Throughout this period, the government was largely run by Artamon Matveev, an enlightened friend of Alexis, the political head of the Naryshkin family and one of Peter's greatest childhood benefactors. This position changed when Feodor died in 1682. As Feodor did not leave any children, a dispute arose between the Naryshkin and Miloslavsky families over who should inherit the throne. Peter's other half-brother, Ivan V, was next in line for the throne, but he was chronically ill and of infirm mind. Consequently, the Boyar Duma (a council of Russian nobles) chose the 10-year-old Peter to become Tsar with his mother as regent. This arrangement was brought before the people of Moscow, as ancient tradition demanded, and was ratified. Sophia Alekseyevna, one of Alexis' daughters from his first marriage, led a rebellion of the Streltsy (Russia's elite military corps) in April–May 1682. In the subsequent conflict some of Peter's relatives and friends were murdered, including Matveev, and Peter witnessed some of these acts of political violence.
The Streltsy made it possible for Sophia, the Miloslavskys (the clan of Ivan) and their allies, to insist that Peter and Ivan be proclaimed joint Tsars, with Ivan being acclaimed as the senior. Sophia acted as regent during the minority of the sovereigns and exercised all power. For seven years, she ruled as an autocrat. A large hole was cut in the back of the dual-seated throne used by Ivan and Peter. Sophia would sit behind the throne and listen as Peter conversed with nobles, while feeding him information and giving him responses to questions and problems. This throne can be seen in the Kremlin Armoury in Moscow.
Peter was not particularly concerned that others ruled in his name. He engaged in such pastimes as shipbuilding and sailing, as well as mock battles with his toy army. Peter's mother sought to force him to adopt a more conventional approach, and arranged his marriage to Eudoxia Lopukhina in 1689. The marriage was a failure, and ten years later Peter forced his wife to become a nun and thus freed himself from the union.
By the summer of 1689, Peter planned to take power from his half-sister Sophia, whose position had been weakened by two unsuccessful Crimean campaigns. When she learned of his designs, Sophia conspired with the leaders of the Streltsy, who continually aroused disorder and dissent. Peter, warned by the Streltsy, escaped in the middle of the night to the impenetrable monastery of Troitse-Sergiyeva Lavra; there he slowly gathered adherents who perceived he would win the power struggle. She was eventually overthrown, with Peter I and Ivan V continuing to act as co-tsars. Peter forced Sophia to enter a convent, where she gave up her name and her position as a member of the royal family.
Still, Peter could not acquire actual control over Russian affairs. Power was instead exercised by his mother, Natalya Naryshkina. It was only when Nataliya died in 1694 that Peter became an independent sovereign. Formally, Ivan V remained a co-ruler with Peter, although he was ineffective. Peter became the sole ruler when Ivan died in 1696.
Peter grew to be extremely tall as an adult, especially for the time period. Standing at 6 ft 8 in (203 cm) in height, the Russian tsar was literally head and shoulders above his contemporaries both in Russia and throughout Europe. Peter, however, lacked the overall proportional heft and bulk generally found in a man that size. Both Peter's hands and feet were small, and his shoulders were narrow for his height; likewise, his head was small for his tall body. Added to this were Peter's noticeable facial tics, and he may have suffered from "petit mal", a form of epilepsy.
Early reign.
Peter implemented sweeping reforms aimed at modernizing Russia. Heavily influenced by his advisors from Western Europe, Peter reorganized the Russian army along modern lines and dreamed of making Russia a maritime power. He faced much opposition to these policies at home, but brutally suppressed any and all rebellions against his authority: Streltsy, Bashkirs, Astrakhan, and the greatest civil uprising of his reign, the Bulavin Rebellion. Peter implemented social modernization in an absolute manner by requiring courtiers, state officials, and the military to shave their beards and adopt modern clothing styles. One means of achieving this end was the introduction of taxes for long beards and robes in September 1698.
To improve his nation's position on the seas, Peter sought to gain more maritime outlets. His only outlet at the time was the White Sea at Arkhangelsk. The Baltic Sea was at the time controlled by Sweden in the north, while the Black Sea and the Caspian Sea were controlled by the Ottoman Empire and Safavid Empire respectively in the south. Peter attempted to acquire control of the Black Sea; to do so he would have to expel the Tatars from the surrounding areas. As part of an agreement with Poland which ceded Kiev to Russia, Peter was forced to wage war against the Crimean Khan and against the Khan's overlord, the Ottoman Sultan. Peter's primary objective became the capture of the Ottoman fortress of Azov, near the Don River. In the summer of 1695 Peter organized the Azov campaigns to take the fortress, but his attempts ended in failure. Peter returned to Moscow in November of that year and began building a large navy. He launched about thirty ships against the Ottomans in 1696, capturing Azov in July of that year. On 12 September 1698, Peter officially founded the first Russian Navy base, Taganrog.
Peter knew that Russia could not face the Ottoman Empire alone. In 1697 he traveled incognito to Europe on an 18-month journey with a large Russian delegation–the so-called "Grand Embassy"—to seek the aid of the European monarchs. Peter's hopes were dashed; France was a traditional ally of the Ottoman Sultan, and Austria was eager to maintain peace in the east while conducting its own wars in the west. Peter, furthermore, had chosen the most inopportune moment; the Europeans at the time were more concerned about who would succeed the childless Spanish King Charles II than about fighting the Ottoman Sultan.
The "Grand Embassy", although failing to complete the mission of creating an anti-Ottoman alliance, continued. While visiting the Netherlands, Peter learned much about life in Western Europe. He studied shipbuilding in Zaandam (the house he lived in is now a museum, the Czar Peter House) and Amsterdam, where he visited, among others, the upper-class de Wilde family. Jacob de Wilde, a collector-general with the Admiralty of Amsterdam, had a well-known collection of art and coins, and de Wilde's daughter Maria de Wilde made an engraving of the meeting between Peter and her father, providing visual evidence of "the beginning of the West European classical tradition in Russia". According to Roger Tavernier, Peter the Great later acquired de Wilde's collection. Thanks to the mediation of Nicolaas Witsen, mayor of Amsterdam and expert on Russia, the Tsar was given the opportunity to gain practical experience in the largest shipyard in the world, belonging to the Dutch East India Company, for a period of four months. The Tsar helped with the construction of an East Indiaman especially laid down for him: "Peter and Paul". During his stay the Tsar engaged many skilled workers such as builders of locks, fortresses, shipwrights, and seamen—including Cornelis Cruys, a vice-admiral who became, under Franz Lefort, the Tsar's advisor in maritime affairs. He later put his knowledge of shipbuilding to use in helping build Russia's navy. Peter paid a visit to Frederik Ruysch, who taught him how to draw teeth and catch butterflies. Ludolf Bakhuysen, a painter of seascapes and Jan van der Heyden the inventor of the fire hose, received Peter, who was keen to learn and pass on his knowledge to his countrymen. On 16 January 1698 Peter organized a farewell party and invited Johan Huydecoper van Maarsseveen, who had to sit between Lefort and the Tsar and drink.
In England Peter met with King William III, visited Greenwich and Oxford, was painted by Sir Godfrey Kneller, and saw a Royal Navy Fleet Review at Deptford. He travelled to the city of Manchester to learn the techniques of city-building he would later use to great effect at Saint Petersburg. The Embassy next went to Leipzig, Dresden, and Vienna. He spoke with August the Strong and Leopold I, Holy Roman Emperor.
Peter's visit was cut short in 1698, when he was forced to rush home by a rebellion of the Streltsy. The rebellion was, however, easily crushed before Peter returned home from England; of the Tsar's troops, only one was killed. Peter nevertheless acted ruthlessly towards the mutineers. Over 1,200 of the rebels were tortured and executed, and Peter ordered that their bodies be publicly exhibited as a warning to future conspirators. The Streltsy were disbanded, and the individual they sought to put on the Throne—Peter's half-sister Sophia—was forced to become a nun.
In 1698 Peter sent a delegation to Malta under boyar Boris Sheremetev, to observe the training and abilities of the Knights of Malta and their fleet. Sheremetev investigated the possibility of future joint ventures with the Knights, including action against the Turks and the possibility of a future Russian naval base.
Peter's visits to the West impressed upon him the notion that European customs were in several respects superior to Russian traditions. He commanded all of his courtiers and officials to cut off their long beards—causing his Boyars, who were very fond of their beards, great upset—and wear European clothing. Boyars who sought to retain their beards were required to pay an annual beard tax of one hundred rubles. He also sought to end arranged marriages, which were the norm among the Russian nobility, because he thought such a practice was barbaric and led to domestic violence, since the partners usually resented each other.
In 1699 Peter changed the date of the celebration of the new year from 1 September to 1 January. Traditionally, the years were reckoned from the purported creation of the World, but after Peter's reforms, they were to be counted from the birth of Christ. Thus, in the year 7207 of the old Russian calendar, Peter proclaimed that the Julian Calendar was in effect and the year was 1700.
Great Northern War.
Peter made a temporary peace with the Ottoman Empire that allowed him to keep the captured fort of Azov, and turned his attention to Russian maritime supremacy. He sought to acquire control of the Baltic Sea, which had been taken by the Swedish Empire a half-century earlier. Peter declared war on Sweden, which was at the time led by King Charles XII. Sweden was also opposed by Denmark-Norway, Saxony, and the Polish-Lithuanian Commonwealth.
 Russia was ill-prepared to fight the Swedes, and their first attempt at seizing the Baltic coast ended in disaster at the Battle of Narva in 1700. In the conflict, the forces of Charles XII used a blinding snowstorm to their advantage. After the battle, Charles XII decided to concentrate his forces against the Polish-Lithuanian Commonwealth, which gave Peter time to reorganize the Russian army. At the end of February 1701 he met with Polish King Augustus II the Strong in Biržai, where the rulers, after several days of drinking, arranged a cannon shooting competition, won by the Polish King.
 As the Poles and Lithuanians fought against the Swedes, Peter founded the city of Saint Petersburg (Germanically named after Saint Peter the Apostle) in Ingermanland (province of Swedish empire, which he had captured) in 1703. He forbade the building of stone edifices outside Saint Petersburg, which he intended to become Russia's capital, so that all stonemasons could participate in the construction of the new city.
Following several defeats, the Polish King August II abdicated in 1706. Swedish king Charles XII turned his attention to Russia, invading it in 1708. After crossing into Russia, Charles defeated Peter at Golovchin in July. In the Battle of Lesnaya, Charles suffered his first loss after Peter crushed a group of Swedish reinforcements marching from Riga. Deprived of this aid, Charles was forced to abandon his proposed march on Moscow.
Charles XII refused to retreat to Poland or back to Sweden, instead invading Ukraine. Peter withdrew his army southward, destroying along the way any property that could assist the Swedes. Deprived of local supplies, the Swedish army was forced to halt its advance in the winter of 1708–1709. In the summer of 1709, they resumed their efforts to capture Ukraine, culminating in the Battle of Poltava on 27 June. The battle was a decisive defeat for the Swedish forces, ending Charles' campaign in Ukraine and forcing him into exile in the Ottoman Empire. In Poland, August II was restored as King.
Peter, overestimating the support he would receive from his Balkan allies, attacked the Ottoman Empire, initiating the Russo-Turkish War of 1710. Normally, the Boyar Duma would have exercised power during his absence. Peter, however, mistrusted the boyars; he instead abolished the Duma and created a Senate of ten members. Peter's campaign in the Ottoman Empire was disastrous, and in the ensuing peace treaty (Treaty of Pruth), Peter was forced to return the Black Sea ports he had seized in 1697. In return, the Sultan expelled Charles XII.
Peter's northern armies took the Swedish province of Livonia (the northern half of modern Latvia, and the southern half of modern Estonia), driving the Swedes into Finland. In 1714 the Russian fleet won the Battle of Gangut. Most of Finland was occupied by the Russians. In 1716 and 1717, the Tsar revisited the Netherlands, and went to see Herman Boerhaave. He continued his travel to the Austrian Netherlands and France. The Tsar's navy was so powerful that the Russians could penetrate Sweden. Peter also obtained the assistance of the Electorate of Hanover and the Kingdom of Prussia. Still, Charles XII refused to yield, and not until his death in battle in 1718 did peace become feasible. After the battle near Åland, Sweden made peace with all powers but Russia by 1720. In 1721 the Treaty of Nystad ended what became known as the Great Northern War. Russia acquired Ingria, Estonia, Livonia, and a substantial portion of Karelia. In turn, Russia paid two million Riksdaler and surrendered most of Finland. The Tsar retained some Finnish lands close to Saint Petersburg, which he had made his capital in 1712.
Later years.
Peter's last years were marked by further reform in Russia. On 22 October 1721, soon after peace was made with Sweden, he was officially proclaimed "Emperor of All Russia". Some proposed that he take the title "Emperor of the East", but he refused. Gavrila Golovkin, the State Chancellor, was the first to add "the Great, Father of His Country, Emperor of All the Russias" to Peter's traditional title Tsar following a speech by the archbishop of Pskov in 1721.
Peter's imperial title was recognized by Augustus II of Poland, Frederick William I of Prussia, and Frederick I of Sweden, but not by the other European monarchs. In the minds of many, the word "emperor" connoted superiority or pre-eminence over kings. Several rulers feared that Peter would claim authority over them, just as the Holy Roman Emperor had claimed suzerainty over all Christian nations.
During Peter's reign the Russian Orthodox Church was reformed. The traditional leader of the Church was the Patriarch of Moscow. In 1700, when the office fell vacant, Peter refused to name a replacement, allowing the Patriarch's Coadjutor (or deputy) to discharge the duties of the office. In 1721 Peter followed the advice of Feofan Prokopovich and created the Holy Synod, a council of ten clergymen, to take the place of the Patriarch and Coadjutor. Peter implemented a law that stipulated that no Russian man could join a monastery before the age of 50. He felt that too many able Russian men were being wasted on clerical work when they could be joining his new and improved army. In 18th-century Russia, few people lived to over a half century; therefore very few men became monks during Peter's reign, much to the dismay of the Russian Church.
In 1718 Peter investigated why the ex Swedish province of Livonia was so orderly. He discovered that the Swedes spent as much administering Livonia (300 times smaller than his empire) as he spent on the entire Russian bureaucracy. He was forced to dismantle the province's government.
In 1722 Peter created a new order of precedence known as the Table of Ranks. Formerly, precedence had been determined by birth. To deprive the Boyars of their high positions, Peter directed that precedence should be determined by merit and service to the Emperor. The Table of Ranks continued to remain in effect until the Russian monarchy was overthrown in 1917. Peter decided that all of the children of the nobility should have some early education, especially in the areas of sciences. Therefore, on 28 February 1714, he issued a decree calling for compulsory education, which dictated that all Russian 10- to 15-year-old children of the nobility, government clerks, and lesser-ranked officials, must learn basic mathematics and geometry, and should be tested on it at the end of their studies.
Peter introduced new taxes to fund improvements in Saint Petersburg. He abolished the land tax and household tax, and replaced them with a poll tax. The taxes on land and on households were payable only by individuals who owned property or maintained families; the new head taxes, however, were payable by serfs and paupers. By this same time, the once powerful Persian Safavid Empire to its neighbouring south was heavily declining. Making advantage of the profitable situation, Peter launched the Russo-Persian War (1722-1723) otherwise known as "The Persian Expedition of Peter the Great" by the Russian histographers, in order to increase Russian influence in the Caucasus and Caspian Sea. After considerable successes and the capture of many provinces and cities in the Caucasus and northern mainland Persia, the Safavids were forced to hand over the territories to Russia. However, 9 years later all territories would be ceded back to Persia, now led by the charismatic and military genius Nader Shah, as part of the Treaty of Resht and the Russo-Persian alliance against the Ottoman Empire.
In 1725 the construction of Peterhof, a palace near Saint Petersburg, was completed. Peterhof (Dutch for "Peter's Court") was a grand residence, becoming known as the "Russian Versailles".
Marriages and family.
Peter the Great had two wives, with whom he had fourteen children; three of them survived to adulthood. Peter's mother selected his first wife, Eudoxia Lopukhina, with the advice of other nobles in 1689. This was consistent with previous Romanov tradition by choosing a daughter of a minor noble. This was done to prevent fighting between the stronger noble houses and to bring in fresh blood to the family. He also had a mistress from Germany, Anna Mons. Upon his return from his European tour in 1698, Peter sought to end his unhappy marriage. He divorced the Tsaritsa and forced her into joining a convent. The Tsaritsa had borne Peter three children, although only one, the Tsarevich Alexei, had survived past his childhood.
He took Martha Skavronskaya as a mistress some time between 1702 and 1704. Martha converted to the Russian Orthodox Church and took the name Catherine. Though no record exists, Catherine and Peter are described as having married secretly between 23 Oct and 1 Dec 1707 in St. Petersburg. Peter valued Catherine and married her again (this time officially) at Saint Isaac's Cathedral in Saint Petersburg on 9 February 1712.
His eldest child and heir, Alexei, was suspected of being involved in a plot to overthrow the Emperor. Alexei was tried and confessed under torture during questioning conducted by a secular court. He was convicted and sentenced to be executed. The sentence could be carried out only with Peter's signed authorization, and Alexei died in prison, as Peter hesitated before making the decision. Alexei's death most likely resulted from injuries suffered during his torture. Alexei's mother Eudoxia had also been punished; she was dragged from her home and tried on false charges of adultery. A similar fate befell Peter's mistress, Anna Mons, in 1704.
In 1724 Peter had his second wife, Catherine, crowned as Empress, although he remained Russia's actual ruler. All of Peter's male children had died.
Issue.
By his two wives, he had fourteen children. These included three sons named "Pavel" and three sons named "Peter", all of whom died in infancy.
Death.
In the winter of 1723, Peter, whose overall health was never robust, began having problems with his urinary tract and bladder. In the summer of 1724 a team of doctors performed surgery releasing upwards of four pounds of blocked urine. Peter remained bedridden until late autumn. In the first week of October, restless and certain he was cured, Peter began a lengthy inspection tour of various projects. According to legend, in November, at Lakhta along the Finnish Gulf to inspect some ironworks, Peter saw a group of soldiers drowning near shore and, wading out into near-waist deep water, came to their rescue.
This icy water rescue is said to have exacerbated Peter's bladder problems and caused his death. The story, however, has been viewed with skepticism by some historians, pointing out that the German chronicler Jacob von Stählin is the only source for the story, and it seems unlikely that no one else would have documented such an act of heroism. This, plus the interval of time between these actions and Peter's death seems to preclude any direct link.
In early January 1725, Peter was struck once again with uremia. Legend has it that before lapsing into unconsciousness Peter asked for a paper and pen and scrawled an unfinished note that read: "Leave all to ..." and then, exhausted by the effort, asked for his daughter Anna to be summoned.
Peter died between four and five in the morning 8 February 1725. An autopsy revealed his bladder to be infected with gangrene. He was fifty-two years, seven months old when he died, having reigned forty-two years.
Popular culture.
Peter has been featured in many books, plays, films, and games, including the poems "The Bronze Horseman", "Poltava" and the unfinished novel "Peter the Great's Negro", all by Alexander Pushkin. The former dealt with a The Bronze Horseman, an equestrian statue raised in Peter's honour. Alexey Nikolayevich Tolstoy wrote a biographical historical novel about him, named "Pëtr I", in the 1930s.

</doc>
<doc id="44359" url="http://en.wikipedia.org/wiki?curid=44359" title="Gary Cooper">
Gary Cooper

Gary Cooper (born Frank James Cooper; May 7, 1901 – May 13, 1961) was an American film actor known for his natural, authentic, and understated acting style and screen performances. His career spanned thirty-six years, from 1925 to 1961, and included leading roles in eighty-four feature films. He was a major movie star from the end of the silent film era through the end of the golden age of Classical Hollywood. His screen persona appealed strongly to both men and women, and his range of performances included roles in most major movie genres. Cooper's ability to project his own personality onto the characters he played contributed to his appearing natural and authentic on screen. The screen persona he sustained throughout his career represented the ideal American hero.
Cooper began his career as a film extra and stunt rider and soon landed acting roles. After establishing himself as a Western hero in his early silent films, Cooper became a movie star in 1929 with his first sound picture "The Virginian". In the early 1930s, he expanded his heroic image to include more cautious characters in adventure films and dramas such as "A Farewell to Arms" (1932) and "The Lives of a Bengal Lancer" (1935). During the height of his career, Cooper portrayed a new type of hero—a champion of the common man—in films such as "Mr. Deeds Goes to Town" (1936), "Meet John Doe" (1941), "Sergeant York" (1941), "The Pride of the Yankees" (1942), and "For Whom the Bell Tolls" (1943). In the post-war years, he portrayed more mature characters at odds with the world in films such as "The Fountainhead" (1949) and "High Noon" (1952). In his final films, Cooper played non-violent characters searching for redemption in films such as "Friendly Persuasion" (1956) and "Man of the West" (1958).
Cooper had romantic relationships early in his career with several leading actresses, including Clara Bow and Lupe Vélez. He married New York debutante Veronica Balfe in 1933, and the couple had one daughter. Their marriage was interrupted by a three-year separation precipitated by Cooper's love affair with Patricia Neal. Cooper's twenty-year friendship with Ernest Hemingway was grounded in their mutual love for the outdoors. Cooper's other close friends included Howard Hawks, Joel McCrea, and James Stewart. Cooper received five Academy Award nominations for Best Actor, winning twice, for "Sergeant York" and "High Noon". He also received an Academy Honorary Award for his career achievements in 1961. He was one of the top ten film personalities for twenty-three consecutive years, and was one of the top money-making stars for eighteen years. The American Film Institute (AFI) ranked Cooper eleventh on its list of the fifty greatest male screen legends.
Early life.
Frank James Cooper was born on May 7, 1901, at 730 Eleventh Avenue in Helena, Montana to English immigrants Alice (née Brazier, 1873–1967) and Charles Henry Cooper (1865–1946). His father emigrated to Montana from Houghton Regis, Bedfordshire and became a prominent lawyer, rancher, and eventually a Montana Supreme Court justice. His mother emigrated from Gillingham, Kent and married Charles in Montana. In 1906, Charles purchased the 600 acre Seven-Bar-Nine cattle ranch about 50 mi north of Helena near the town of Craig on the Missouri River. Frank and his older brother Arthur spent their summers there and learned to ride horses, hunt, and fish. In April 1908, the Hauser Dam failed and flooded the Missouri River valley along portions of the Cooper property, but Cooper and his family were able to evacuate in time. Cooper attended Central Grade School in Helena.
In the summer of 1909, Alice, wanting her sons to have an English education, accompanied them to England and enrolled them in Dunstable Grammar School in Bedfordshire, where Cooper was educated from 1910 to 1912. At Dunstable, Cooper studied Latin and French, and took several courses in English history. While he managed to adapt to the discipline of an English school and learned the requisite social graces, he never adjusted to the rigid class structure and formal Eton collars he was forced to wear. After completing confirmation classes, Cooper was baptized into the Anglican Church on December 3, 1911, at the Church of All Saints in Houghton Regis. Cooper's mother accompanied her sons back to the United States in August 1912, and Cooper resumed his education at Johnson Grammar School in Helena.
At the age of fifteen, Cooper injured his hip in a car accident and returned to the Seven-Bar-Nine ranch to recuperate by horseback riding at the recommendation of his doctor. The misguided therapy left him with his characteristic stiff, off-balanced walk and slightly angled riding style. After attending Helena High School for two years, he left school in 1918 and returned to the family ranch to help raise their five hundred head of cattle and work full-time as a cowboy. In 1919, his father arranged for his son to complete his high school education at Gallatin County High School in Bozeman, Montana. His English teacher, Ida Davis, encouraged him to focus on academics, join the school's debating team, and get involved in dramatics. His parents would later credit her for helping their son complete high school, and Cooper confirmed, "She was the woman partly responsible for me giving up cowboy-ing and going to college."
In 1920, while still attending high school, Cooper took three art courses at Montana Agricultural College. His interest in art was inspired years earlier by the Western paintings of Charles Marion Russell and Frederic Remington. Cooper especially admired and studied Russell's "Lewis and Clark Meeting Indians at Ross' Hole" (1910), which still hangs in the state capitol building in Helena. In 1922, Cooper enrolled in Grinnell College in Iowa to continue his art education. Cooper did well academically in most of his courses, but was not accepted to the school's drama club. His drawings and watercolors were exhibited throughout the dormitory, and he was named art editor for the college yearbook. During the summers of 1922 and 1923, Cooper worked at Yellowstone National Park as a tour guide driving the yellow open-top buses. Despite a promising first eighteen months at Grinnell, he left college suddenly in February 1924, spent a month in Chicago looking for work as an artist, and then returned to Helena, where he sold editorial cartoons to the "Independent", a local newspaper.
In the autumn of 1924, Cooper's father left the Montana Supreme Court bench and moved with his wife to Los Angeles to administer the estates of two relatives. At his father's request, Cooper joined his parents in California on Thanksgiving Day, November 27, 1924. In the coming weeks, after working a series of unpromising jobs, Cooper met two friends from Montana, Jim Galeen and Jim Calloway, who were working as film extras and stunt riders in low-budget Western films for the small movie studios on Poverty Row on Gower Street. They introduced him to another Montana cowboy, rodeo champion Jay "Slim" Talbot, who took him to see a casting director who offered him work. With the goal of saving enough money to pay for a professional art course, Cooper decided to try his hand at working as a film extra for five dollars a day, and as a stunt rider for twice that amount.
Career.
Silent films, 1925–28.
In early 1925, Cooper began his film career working in silent pictures such as "The Thundering Herd" and "Wild Horse Mesa" with Jack Holt, "Riders of the Purple Sage" and "The Lucky Horseshoe" with Tom Mix, and "The Trail Rider" with Buck Jones. He worked for several Poverty Row studios, including Famous Players-Lasky and Fox Film Corporation. While his skills as a horseman led to steady work in Westerns, Cooper found the stunt work "tough and cruel", sometimes resulting in injury to the horses and riders. Hoping to move beyond the risky stunt work and obtain acting roles, Cooper paid for a screen test and hired casting director Nan Collins to work as his agent. Knowing that other actors were using the name "Frank Cooper", Collins suggested he change his first name to "Gary" after her hometown of Gary, Indiana. Cooper liked the name immediately.
Cooper also found work in a variety of non-Western films, appearing, for example, as a masked Cossack in "The Eagle" (1925), as a Roman guard in "Ben-Hur" (1925), and as a flood survivor in "The Johnstown Flood" (1926). Gradually, he began to land credited roles that offered him more screen time, in films such as "Tricks" (1925), in which he played the film's antagonist, and the short film "Lightnin' Wins" (1926). As a featured player, he began to attract the attention of major film studios. On June 1, 1926, Cooper signed a contract with Samuel Goldwyn Productions for fifty dollars a week.
Cooper's first important film role was in "The Winning of Barbara Worth" (1926) with Ronald Colman and Vilma Bánky. In the film, Cooper plays a young engineer, Abe Lee, who helps a rival suitor save the woman he loves and her town from an impending dam disaster. Cooper's experience living among the Montana cowboys gave his performance an "instinctive authenticity", according to biographer Jeffrey Meyers. The film premiered on October 14 and was a major success. Critics singled out Cooper as a "dynamic new personality" and future star. Goldwyn rushed to offer the actor a long-term contract, but Cooper held out for a better deal—finally signing a five-year contract with Jesse L. Lasky at Paramount Pictures for $175 a week. In 1927, with help from established movie star Clara Bow, Cooper landed high-profile roles in "Children of Divorce" and "Wings", the latter being the first film to win an Academy Award for Best Picture. That year, Cooper also appeared in his first starring roles in "Arizona Bound" and "Nevada"—both films directed by John Waters.
In 1928, Paramount paired Cooper with a youthful Fay Wray in "The Legion of the Condemned" and "The First Kiss"—advertising them as the studio's "glorious young lovers". Their on-screen chemistry failed to generate much excitement with audiences. With each new film, Cooper's acting skills improved and his popularity continued to grow, especially among female movie-goers. During this time, he was earning as much as $2,750 per film and receiving a thousand fan letters a week. Looking to exploit Cooper's growing audience appeal, the studio placed him opposite popular leading ladies such as Evelyn Brent in "Beau Sabreur", Florence Vidor in "Doomsday", and Esther Ralston in "Half a Bride". That year, Cooper also made "Lilac Time" with Colleen Moore for First National Pictures, his first movie with synchronized music and sound effects. It became one of the most commercially successful films of 1928.
Hollywood stardom, 1929–35.
Cooper became a major movie star in 1929 with the release of his first sound picture, "The Virginian", which was directed by Victor Fleming and co-starred Mary Brian and Walter Huston. Based on the popular novel by Owen Wister, "The Virginian" was one of the first sound films to define the Western code of honor and helped establish many of the conventions of the Western movie genre that have lasted to the present day. According to biographer Jeffrey Meyers, the romantic image of the tall, handsome, and shy cowboy hero who embodied male freedom, courage, and honor was created in large part by Cooper in the film. Unlike some silent film actors who had trouble adapting to the new sound medium, Cooper transitioned naturally, with his "deep and clear" and "pleasantly drawling" voice, which was perfectly suited for the characters he portrayed on screen, also according to Meyers. Looking to capitalize on Cooper's growing popularity, Paramount cast him in several Westerns and wartime dramas in 1930, including "Only the Brave", "The Texan", "Seven Days' Leave", "A Man from Wyoming", and "The Spoilers".
One of the more important performances in Cooper's early career was his portrayal of a sullen legionnaire in Josef von Sternberg's 1930 film "Morocco" with Marlene Dietrich in her introduction to American audiences. During production, von Sternberg focused his energies on Dietrich and treated Cooper dismissively. Tensions came to a head after von Sternberg yelled directions at Cooper in German. The 6 ft actor approached the 5 ft director, physically picked him up by the collar and said, "If you expect to work in this country you'd better get on to the language we use here." Despite the tensions on the set, Cooper produced "one of his best performances", according to Thornton Delehanty of the "New York Evening Post". In 1931, after returning to the Western genre in Zane Grey's "Fighting Caravans" with French actress Lili Damita, Cooper appeared in the Dashiell Hammett crime film "City Streets" playing a westerner who gets involved with big-city gangsters in order to save the woman he loves. Cooper concluded the year with appearances in two unsuccessful films: "I Take This Woman" with Carole Lombard, and "His Woman" with Claudette Colbert. The demands and pressures of making ten films in two years left Cooper exhausted and in poor health, suffering from anemia and jaundice. He had lost 30 lb during that period, and felt lonely, isolated, and depressed by his sudden fame and wealth. In May 1931, Cooper left Hollywood and sailed to Algiers and then Italy, where he lived for the next year.
During his time abroad, Cooper stayed with the Countess Dorothy di Frasso at the Villa Madama in Rome, where she taught him about good food and vintage wines, how to read Italian and French menus, and how to socialize among Europe's nobility and upper classes. After guiding him through the great art museums and galleries of Italy, she accompanied him on a ten-week big-game hunting safari on the slopes of Mount Kenya in East Africa, where he was credited with over sixty kills, including two lions, a rhinoceros, and various antelopes. His safari experience in Africa had a profound influence on Cooper and intensified his love of the wilderness. After returning to Europe, he and the countess set off on a Mediterranean cruise of the Italian and French Rivieras. Rested and rejuvenated by his year-long exile, a healthy Cooper returned to Hollywood in April 1932 and negotiated a new contract with Paramount for two films per year, a salary of $4,000 a week, and director and script approval.
In 1932, after completing "Devil and the Deep" with Tallulah Bankhead to fulfill his old contract, Cooper appeared in "A Farewell to Arms", the first film adaptation of an Ernest Hemingway novel. Co-starring Helen Hayes, a leading New York theatre star and Academy Award winner, and Adolphe Menjou, the film presented Cooper with one of his most ambitious and challenging dramatic roles, playing an American ambulance driver wounded in Italy who falls in love with an English nurse during World War I. Critics praised his highly intense and emotional performance, and the film became one of the year's most commercially successful pictures. In 1933, after making "Today We Live" with Joan Crawford and "One Sunday Afternoon" with Fay Wray, Cooper appeared in the Ernst Lubitsch comedy film "Design for Living", based on the successful Noël Coward play. Co-starring Miriam Hopkins and Fredric March, the film received mixed reviews and did not do well at the box office. Cooper's performance—playing an American artist in Europe competing with his playwright friend for the affections of a beautiful woman—was singled out for its versatility and revealed his genuine ability to do light comedy. Cooper changed his name legally to "Gary Cooper" in August 1933.
In 1934, Cooper was loaned out to MGM for the Civil War drama film "Operator 13" with Marion Davies, about a beautiful Union spy who falls in love with a Confederate soldier. Despite Richard Boleslawski's imaginative direction and George J. Folsey's lavish cinematography, the film did poorly at the box office. Back at Paramount, Cooper appeared in his first of seven films by director Henry Hathaway, "Now and Forever", with Carole Lombard and Shirley Temple. In the film, he plays a confidence man who tries to sell his daughter to the relatives who raised her, but is eventually won over by the adorable girl. Impressed by Temple's intelligence and charm, Cooper developed a close rapport with her, both on and off screen. The film was a box-office success.
The following year, Cooper was loaned out to Samuel Goldwyn Productions to appear in King Vidor's romance film "The Wedding Night" with Anna Sten, who was being groomed as "another Garbo". In the film, Cooper plays an alcoholic novelist who retreats to his family's New England farm where he meets and falls in love with a beautiful Polish neighbor. Cooper delivered a performance of surprising range and depth, according to biographer Larry Swindell. Despite receiving generally favorable reviews, the film was not popular with American audiences, who may have been offended by the film's depiction of an extramarital affair and its tragic ending. That same year, Cooper appeared in two Henry Hathaway films: the melodrama "Peter Ibbetson" with Ann Harding, about a man caught up in a dream world created by his love for a childhood sweetheart, and the adventure film "The Lives of a Bengal Lancer", about a daring British officer and his men who defend their stronghold at Bengal against rebellious local tribes. While the former was more successful in Europe than in the United States, the latter was nominated for six Academy Awards and became one of Cooper's most popular and successful adventure films. Hathaway had the highest respect for Cooper's acting ability, calling him "the best actor of all of them".
American folk hero, 1936–43.
From "Mr. Deeds" to "The Real Glory".
The year 1936 marked an important turning point in Cooper's career. After making Frank Borzage's romantic comedy film "Desire" with Marlene Dietrich at Paramount—delivering a performance considered by some contemporary critics as one of his finest—Cooper returned to Poverty Row for the first time since his early silent film days to make Frank Capra's screwball comedy "Mr. Deeds Goes to Town" with Jean Arthur for Columbia Pictures. In the film, Cooper plays the character of Longfellow Deeds, a quiet, innocent writer of greeting cards who inherits a fortune, leaves behind his idyllic life in Vermont, and travels to New York where he faces a world of corruption and deceit. Capra and screenwriter Robert Riskin were able to use Cooper's well-established screen persona as the "quintessential American hero"—a symbol of honesty, courage, and goodness—to create a new type of "folk hero" for the common man. Commenting on Cooper's impact on the character and the film, Capra observed:
As soon as I thought of Gary Cooper, it wasn't possible to conceive anyone else in the role. He could not have been any closer to my idea of Longfellow Deeds, and as soon as he could think in terms of Cooper, Bob Riskin found it easier to develop the Deeds character in terms of dialogue. So it just had to be Cooper. Every line in his face spelled honesty. Our Mr. Deeds had to symbolize uncorruptibility, and in my mind Gary Cooper was that symbol.
Both "Desire" and "Mr. Deeds" opened in April 1936 to critical praise and were major box-office successes. In his review in "The New York Times", Frank Nugent wrote that Cooper was "proving himself one of the best light comedians in Hollywood". For his performance in "Mr. Deeds", Cooper received his first Academy Award nomination for Best Actor.
Cooper appeared in two other Paramount films in 1936. In Lewis Milestone's adventure film "The General Died at Dawn" with Madeleine Carroll, he plays an American soldier of fortune in China who helps the peasants defend themselves against the oppression of a cruel warlord. Written by playwright Clifford Odets, the film was a critical and commercial success. In Cecil B. DeMille's sprawling frontier epic "The Plainsman"—his first of four films with the director—Cooper portrays Wild Bill Hickok in a highly fictionalized version of the opening of the American western frontier. The film was an even greater box-office hit than its predecessor, due in large part to Jean Arthur's definitive depiction of Calamity Jane and Cooper's inspired portrayal of Hickock as an enigmatic figure of "deepening mythic substance". That year, Cooper appeared for the first time on the "Motion Picture Herald" exhibitor's poll of top ten film personalities, where he would remain for the next twenty-three years.
In late 1936, while Paramount was preparing a new contract for Cooper that would raise his salary to $8,000 a week, Cooper signed a contract with Samuel Goldwyn for six films over six years with a minimum guarantee of $150,000 per picture. Paramount brought suit against Goldwyn and Cooper, and the court ruled that Cooper's new Goldwyn contract afforded the actor sufficient time to also honor his Paramount agreement. Cooper continued to make films with both studios, and by 1939 the United States Treasury reported that Cooper was the country's highest wage earner, at $482,819 (<br>{Inflation} - Amount must not have "" prefix: 482819.  equivalent to $ in 2015).
In contrast to his output the previous year, Cooper appeared in only one picture in 1937, Henry Hathaway's adventure film "Souls at Sea". A critical and box-office failure, Cooper referred to it as his "almost picture", saying, "It was almost exciting, and almost interesting. And I was almost good." In 1938, he appeared in Archie Mayo's biographical film "The Adventures of Marco Polo". Plagued by production problems and a weak screenplay, the film became Goldwyn's biggest failure to that date, losing $700,000. During this period, Cooper turned down several important roles, including the role of Rhett Butler in "Gone with the Wind". Cooper was producer David O. Selznick's first choice for the part. He made several overtures to the actor, but Cooper had doubts about the project, and did not feel suited to the role. Cooper later admitted, "It was one of the best roles ever offered in Hollywood ... But I said no. I didn't see myself as quite that dashing, and later, when I saw Clark Gable play the role to perfection, I knew I was right."
Back at Paramount, Cooper returned to a more comfortable genre in Ernst Lubitsch's romantic comedy "Bluebeard's Eighth Wife" (1938) with Claudette Colbert. In the film, Cooper plays a wealthy American businessman in France who falls in love with an impoverished aristocrat's daughter and persuades her to become his eighth wife. Despite the clever screenplay by Charles Brackett and Billy Wilder, and solid performances by Cooper and Colbert, audiences had trouble accepting Cooper in the role of a shallow philanderer. For many of his fans, Cooper had become "Mr. Deeds incarnate". In the fall of 1938, Cooper appeared in H. C. Potter's romantic comedy "The Cowboy and the Lady" with Merle Oberon, about a sweet-natured rodeo cowboy who falls in love with the wealthy daughter of a presidential hopeful, believing her to be a poor, hard-working lady's maid. The efforts of three directors and several eminent screenwriters could not salvage what could have been a fine vehicle for Cooper. While more successful than its predecessor, the film was Cooper's fourth consecutive box-office failure.
In the next two years, Cooper was more discerning about the roles he accepted and made four successful large-scale adventure and cowboy films. In William A. Wellman's adventure film "Beau Geste" (1939), he plays one of three daring English brothers who join the French Foreign Legion in the Sahara to fight local tribes. Filmed in the same Mojave Desert locations as the original 1926 version with Ronald Colman, "Beau Geste" provided Cooper with magnificent sets, exotic settings, high-spirited action, and a role tailored to his personality and screen persona. This was the last film in Cooper's contract with Paramount. In Henry Hathaway's "The Real Glory" (1939), he plays a military doctor who accompanies a small group of American Army officers to the Philippines to help the Christian Filipinos defend themselves against Muslim radicals. Many film critics praised Cooper's performance, including author and film critic Graham Greene who recognized that he "never acted better".
From "The Westerner" to "For Whom the Bell Tolls".
Cooper returned to the Western genre in William Wyler's "The Westerner" (1940) with Walter Brennan and Doris Davenport, about a drifting cowboy who defends homesteaders against Roy Bean, a corrupt judge known as the "law west of the Pecos". Screenwriter Niven Busch relied on Cooper's extensive knowledge of Western history while working on the script. The film received positive reviews and did well at the box-office, with reviewers praising the performances of the two lead actors. That same year, Cooper appeared in his first all-Technicolor feature, Cecil B. DeMille's adventure film "North West Mounted Police" (1940). In the film, Cooper plays a Texas Ranger who pursues an outlaw into western Canada where he joins forces with the Royal Canadian Mounted Police who are after the same man, a leader of the North-West Rebellion. While not as popular with critics as its predecessor, the film was another box-office success—the sixth-highest grossing film of 1940.
The early 1940s were Cooper's prime years as an actor. In a relatively short period, he appeared in five critically successful and popular films that produced some of his finest performances. When Frank Capra offered him the lead role in "Meet John Doe" before Robert Riskin even developed the script, Cooper accepted his friend's offer, saying, "It's okay, Frank, I don't need a script." In the film, Cooper plays Long John Willoughby, a down-and-out bush-league pitcher hired by a newspaper to pretend to be a man who promises to commit suicide on Christmas Eve to protest all the hypocrisy and corruption in the country. Considered by some critics to be Capra's best film at the time, "Meet John Doe" was received as a "national event" with Cooper appearing on the front page of "Time" magazine on March 3, 1941. In his review in the "New York Herald Tribune", Howard Barnes called Cooper's performance a "splendid and utterly persuasive portrayal" and praised his "utterly realistic acting which comes through with such authority". Bosley Crowther, in "The New York Times", wrote, "Gary Cooper, of course, is 'John Doe' to the life and in the whole—shy, bewildered, non-aggressive, but a veritable tiger when aroused."
That same year, Cooper made two films with director and good friend Howard Hawks. In the biographical film "Sergeant York", Cooper portrays war hero Alvin C. York, one of the most decorated American soldiers in World War I. The film chronicles York's early backwoods days in Tennessee, his religious conversion and subsequent piety, his stand as a conscientious objector, and finally his heroic actions at the Battle of the Argonne Forest, which earned him the Medal of Honor. Initially, Cooper was nervous and uncertain about playing a living hero, so he traveled to Tennessee to visit York at his home, and the two quiet men established an immediate rapport and discovered they had much in common. Inspired by York's encouragement, Cooper delivered a performance that Howard Barnes of the "New York Herald Tribune" called "one of extraordinary conviction and versatility", and that Archer Winston of the "New York Post" called "one of his best". After the film's release, Cooper was awarded the Distinguished Citizenship Medal by the Veterans of Foreign Wars for his "powerful contribution to the promotion of patriotism and loyalty". York admired Cooper's performance and helped promote the film for Warner Bros. "Sergeant York" became the top-grossing film of the year and was nominated for eleven Academy Awards. Accepting his first Academy Award for Best Actor from his friend James Stewart, Cooper said, "It was Sergeant Alvin York who won this award. Shucks, I've been in the business sixteen years and sometimes dreamed I might get one of these. That's all I can say ... Funny when I was dreaming I always made a better speech."
Cooper concluded the year back at Goldwyn with Howard Hawks to make the romantic comedy "Ball of Fire" with Barbara Stanwyck. In the film, Cooper plays a shy linguistics professor who leads a team of seven scholars who are writing an encyclopedia. While researching slang, he meets Stanwyck's flirtatious burlesque stripper Sugerpuss O'Shea who blows the dust off their staid life of books. The screenplay by Charles Brackett and Billy Wilder provided Cooper the opportunity to exercise the full range of his light comedy skills. In his review for the "New York Herald Tribune", Howard Barnes wrote that Cooper handled the role with "great skill and comic emphasis" and that his performance was "utterly delightful". Though small in scale, "Ball of Fire" was one of the top-grossing films of the year—Cooper's fourth consecutive picture to make the top twenty.
Cooper's only film appearance in 1942 was also his last under his Goldwyn contract. In Sam Wood's biographical film "The Pride of the Yankees", Cooper portrays baseball star Lou Gehrig who established a record with the New York Yankees for playing in 2,130 consecutive games. Cooper was reluctant to play the seven-time All-Star, who only died the previous year from amyotrophic lateral sclerosis—now commonly called "Lou Gehrig's disease". Beyond the challenges of effectively portraying such a popular and nationally recognized figure, Cooper knew very little about baseball and was not left-handed like Gehrig. After Gehrig's widow visited the actor and expressed her desire that he portray her husband, Cooper accepted the role that covered a twenty-year span of Gehrig's life—his early love of baseball, his rise to greatness, his loving marriage, and his struggle with illness, culminating in his farewell speech at Yankee Stadium on July 4, 1939 before 62,000 fans. Cooper quickly learned the physical movements of a baseball player and developed a fluid, believable swing. The handedness issue was solved by reversing the print for certain batting scenes. The film was one of the year's top ten pictures and received eleven Academy Award nominations, including Best Picture and Best Actor (Cooper's third).
Soon after the publication of Ernest Hemingway's novel "For Whom the Bell Tolls", Paramount paid $150,000 for the film rights with the express intent of casting Cooper in the lead role of Robert Jordan, an American explosives expert who fights alongside the Republican loyalists during the Spanish Civil War. The original director, Cecil B. DeMille, was replaced by Sam Wood who brought in Dudley Nichols for the screenplay. After the start of principal photography in the Sierra Nevada in late 1942, Ingrid Bergman was brought in to replace ballerina Vera Zorina as the female lead—a change supported by Cooper and Hemingway. The love scenes between Bergman and Cooper were "rapturous" and passionate. Howard Barnes in the "New York Herald Tribune" wrote that both actors performed with "the true stature and authority of stars". While the film distorted the novel's original political themes and meaning, "For Whom the Bell Tolls" was a critical and commercial success and received ten Academy Award nominations, including Best Picture and Best Actor (Cooper's fourth).
Cooper did not serve in the military during World War II due to his age and health, but like many of his colleagues, he got involved in the war effort by entertaining the troops. In June 1943, he visited military hospitals in San Diego, and often appeared at the Hollywood Canteen serving food to the servicemen. In late 1943, Cooper undertook a 23000 mi tour of the South West Pacific with actresses Una Merkel and Phyllis Brooks, and accordionist Andy Arcari. Traveling on a B-24A Liberator bomber, the group toured the Cook Islands, Fiji, New Caledonia, Queensland, Brisbane—where General Douglas MacArthur told Cooper he was watching "Sergeant York" in a Manila theater when Japanese bombs began falling—New Guinea, Jayapura, and throughout the Solomon Islands. The group often shared the same sparse living conditions and K-rations as the troops. Cooper met with the servicemen and women, visited military hospitals, introduced his attractive colleagues, and participated in occasional skits. The shows concluded with Cooper's moving recitation of Lou Gehrig's farewell speech. When he returned to the United States, he visited military hospitals throughout the country. Cooper later called his time with the troops the "greatest emotional experience" of his life.
Mature roles, 1944–52.
In 1944, Cooper appeared in Cecil B. DeMille's wartime adventure film "The Story of Dr. Wassell" with Laraine Day—his third movie with the director. In the film, Cooper plays American doctor and missionary Corydon M. Wassell, who leads a group of wounded sailors through the jungles of Java to safety. Despite receiving poor reviews, "Dr. Wassell" was one of the top-grossing films of the year. With his Goldwyn and Paramount contracts now concluded, Cooper decided to remain independent and formed his own production company, International Pictures, with Leo Spitz, William Goetz, and Nunnally Johnson. The fledgling studio's first offering was Sam Wood's romantic comedy "Casanova Brown" with Teresa Wright, about a man who learns his soon-to-be ex-wife is pregnant with his child, just as he is about to marry another woman. The film received poor reviews, with the "New York Daily News" calling it "delightful nonsense", and Bosley Crowther, in "The New York Times", criticizing Cooper's "somewhat obvious and ridiculous clowning". The film was barely profitable. In 1945, Cooper starred in and produced Stuart Heisler's Western comedy "Along Came Jones" with Loretta Young for International. In this lighthearted parody of his past heroic image, Cooper plays comically inept cowboy Melody Jones who is mistaken for a ruthless killer. Audiences embraced Cooper's character, and the film was one of the top box-office pictures of the year—a testament to Cooper's still vital audience appeal. It was also International's biggest financial success during its brief history before being sold off to Universal Studios in 1946.
Cooper's career during the post-war years drifted in new directions as American society was changing. While he still played conventional heroic roles, his films now relied less on his heroic screen persona and more on novel stories and exotic settings. In November 1945, Cooper appeared in Sam Wood's nineteenth century period drama "Saratoga Trunk" with Ingrid Bergman, about a Texas cowboy and his relationship with a beautiful fortune-hunter. Filmed in early 1943, the movie's release was delayed for two years due to the increased demand for war movies. Despite poor reviews, "Saratoga Trunk" did well at the box office and became one of Paramount's top money-makers of the year. Cooper's only film in 1946 was Fritz Lang's romantic thriller "Cloak and Dagger", about a mild-mannered physics professor recruited by the OSS during the last years of World War II to investigate the German atomic bomb program. Playing a part loosely based on physicist J. Robert Oppenheimer, Cooper was uneasy with the role and was unable to convey the "inner sense" of the character. The film received poor reviews and was a box-office failure. In 1947, Cooper appeared in Cecil B. DeMille's epic adventure film "Unconquered" with Paulette Goddard, about a Virginia militiaman who defends settlers against an unscrupulous gun trader and hostile Indians on the Western frontier during the eighteenth century. The film received mixed reviews, but even long-time DeMille critic James Agee acknowledged the picture had "some authentic flavor of the period". This last of four films made with DeMille was Cooper's most lucrative, earning the actor over $300,000 in salary and percentage of profits. "Unconquered" would be his last unqualified box-office success for the next five years.
In 1948, after making Leo McCarey's romantic comedy "Good Sam", Cooper sold his company to Universal Studios and signed a long-term contract with Warner Bros. that gave him script and director approval and a guaranteed $295,000 per picture. His first film under the new contract was King Vidor's drama "The Fountainhead" (1949) with Patricia Neal and Raymond Massey. In the film, Cooper plays an idealistic and uncompromising architect who struggles to maintain his integrity and individualism in the face of societal pressures to conform to popular standards. Based on the novel by Ayn Rand who also wrote the screenplay, the film reflects her Objectivist philosophy and attacks the concepts of altruism and collectivism while promoting the virtues of selfishness and individualism. For most critics, Cooper was hopelessly miscast in the role of Howard Roark. In his review for "The New York Times", Bosley Crowther concluded he was "Mr. Deeds out of his element". Cooper returned to his element in Delmer Daves' war drama "Task Force" (1949), about a retiring rear admiral who reminisces about his long career as a naval aviator and his role in the development of aircraft carriers. Cooper's performance and the Technicolor newsreel footage supplied by the United States Navy made the film one of Cooper's most popular during this period. In the next two years, Cooper made four poorly received films: Michael Curtiz' period drama "Bright Leaf" (1950), Stuart Heisler's Western melodrama "Dallas" (1950), Henry Hathaway's wartime comedy "You're in the Navy Now" (1951), and Raoul Walsh's Western action film "Distant Drums" (1951).
Cooper's most important film during the post-war years was Fred Zinnemann's Western drama "High Noon" (1952) with Grace Kelly for United Artists. In the film, Cooper plays retiring sheriff Will Kane who is preparing to leave town on his honeymoon when he learns that an outlaw he helped put away and his three henchmen are returning to seek their revenge. Unable to gain the support of the frightened townspeople, and abandoned by his young bride, Kane nevertheless stays to face the outlaws alone. During the filming, Cooper was in poor health and in considerable pain from stomach ulcers. His ravaged face and discomfort in some scenes "photographed as self-doubt", according to biographer Hector Arce, and contributed to the effectiveness of his performance. Considered one of the first "adult" Westerns for its theme of moral courage, "High Noon" received enthusiastic reviews for its artistry, with "Time" magazine placing it in the ranks of "Stagecoach" and "The Gunfighter". Bosley Crowther, in "The New York Times", wrote that Cooper was "at the top of his form", and John McCarten, in "The New Yorker", wrote that Cooper was never more effective. The film earned $3.75 million in the United States and $18 million worldwide. Following the example of his friend James Stewart, Cooper accepted a lower salary in exchange for a percent of the profits, and ended up making $600,000. Cooper's understated performance was widely praised, and earned him his second Academy Award for Best Actor.
Later films, 1953–61.
After appearing in André de Toth's Civil War drama "Springfield Rifle" (1952)—a standard Warner Bros. film that was overshadowed by the success of its predecessor—Cooper made four films outside the United States. In Mark Robson's drama "Return to Paradise" (1953), Cooper plays an American wanderer who liberates the inhabitants of a Polynesian island from the puritanical rule of a misguided pastor. Cooper endured spartan living conditions, long hours, and ill health during the three-month location shoot on the island of Upolu in Western Samoa. Despite its beautiful cinematography, the film received poor reviews. Cooper's next three films were shot in Mexico. In Hugo Fregonese's action adventure film "Blowing Wild" (1953) with Barbara Stanwyck, he plays a wildcatter in Mexico who gets involved with an oil company executive and his unscrupulous wife with whom he once had an affair. In 1954, Cooper appeared in Henry Hathaway's Western drama "Garden of Evil" with Susan Hayward, about three soldiers of fortune in Mexico hired to rescue a woman's husband. That same year, he appeared in Robert Aldrich's Western adventure "Vera Cruz" with Burt Lancaster. In the film, Cooper plays an American adventurer hired by Emperor Maximilian I to escort a countess to Vera Cruz during the Mexican Rebellion of 1866. All of these films received poor reviews but did well at the box-office. For his work in "Vera Cruz", Cooper earned $1.4 million in salary and percent of the gross.
During this period, Cooper struggled with health problems. As well as his ongoing treatment for ulcers, he suffered a severe shoulder injury during the filming of "Blowing Wild" when he was hit by metal fragments from a dynamited oil well. During the filming of "Vera Cruz", he reinjured his hip falling from a horse, and was burned when Lancaster fired his rifle too close and the wadding from the blank shell pierced his clothing. In 1955, he appeared in Otto Preminger's biographical war drama "The Court-Martial of Billy Mitchell", about the World War I general who tried to convince government officials of the importance of air power, and was court-martialed after blaming the War Department for a series of air disasters. Some critics felt that Cooper was miscast, and that his dull, tight-lipped performance did not reflect Mitchell's dynamic and caustic personality. In 1956, Cooper was more effective playing a gentle Indiana Quaker in William Wyler's Civil War drama "Friendly Persuasion" with Dorothy McGuire. Like "Sergeant York" and "High Noon", the film addresses the conflict between religious pacifism and civic duty. For his performance, Cooper received his second Golden Globe nomination for Best Motion Picture Actor. The film was nominated for six Academy Awards, was awarded the Palme d'Or at the 1957 Cannes Film Festival, and went on to earn $8 million worldwide.
In 1957, Cooper traveled to France to make Billy Wilder's romantic comedy "Love in the Afternoon" with Audrey Hepburn and Maurice Chevalier. In the film, Cooper plays a middle-aged American playboy in Paris who pursues and eventually falls in love with a much younger woman. Despite receiving some positive reviews—including from Bosley Crowther who praised the film's "charming performances"—most reviewers concluded that Cooper was simply too old for the part. While audiences may not have welcomed seeing Cooper's heroic screen image tarnished by his playing an aging roué trying to seduce an innocent young girl, the film was still a box-office success. The following year, Cooper appeared in Philip Dunne's romantic drama "Ten North Frederick" In the film, which was based on the novel by John O'Hara, Cooper plays an attorney whose life is ruined by a double-crossing politician and his own secret affair with his daughter's young roommate. While Cooper brought "conviction and controlled anguish" to his performance, according to biographer Jeffrey Meyers, it was not enough to save what Bosley Crowther called a "hapless film".
Despite his ongoing health problems and several operations for ulcers and hernias, Cooper continued to work in action films. In 1958, he appeared in Anthony Mann's Western drama "Man of the West" (1958) with Julie London and Lee J. Cobb, about a reformed outlaw and killer who is forced to confront his violent past when the train he is riding in is held up by his former gang members. The film has been called Cooper's "most pathological Western", with its themes of impotent rage, sexual humiliation, and sadism. According to biographer Jeffrey Meyers, Cooper, who struggled with moral conflicts in his personal life, "understood the anguish of a character striving to retain his integrity ... [and] brought authentic feeling to the role of a tempted and tormented, yet essentially decent man". Mostly ignored by critics at the time, the film is now well-regarded by film scholars and is considered Cooper's last great film.
After his Warner Bros. contract ended, Cooper formed his own production company, Baroda Productions, and made three unusual films in 1959 about redemption. In Delmer Daves' Western drama "The Hanging Tree", Cooper plays a frontier doctor who saves a criminal from a lynch mob, and later tries to exploit his sordid past. Cooper delivered a "powerful and persuasive" performance of an emotionally scarred man whose need to dominate others is transformed by the love and sacrifice of a woman. In Robert Rossen's historical adventure "They Came to Cordura" with Rita Hayworth, he plays an army officer who is found guilty of cowardice and assigned the degrading task of recommending soldiers for the Medal of Honor during the Pancho Villa Expedition of 1916. While Cooper received positive reviews, "Variety" and "Films in Review" felt he was too old for the part. In Michael Anderson's action drama "The Wreck of the Mary Deare" with Charlton Heston, Cooper plays a disgraced merchant marine officer who decides to stay aboard his sinking cargo ship in order to prove the vessel was deliberately scuttled and to redeem his good name. Like its two predecessors, the film was physically demanding. Cooper, who was a trained scuba diver, did most of his own underwater scenes. Biographer Jeffrey Meyers observed that in all three roles, Cooper effectively conveyed the sense of lost honor and desire for redemption—what Joseph Conrad in "Lord Jim" called the "struggles of an individual trying to save from the fire his idea of what his moral identity should be".
Personal life.
Marriage and family.
Cooper was formally introduced to his future wife, twenty-year-old New York debutante Veronica Balfe, on Easter Sunday 1933 at a party given by her uncle, art director Cedric Gibbons. Called "Rocky" by her family and friends, she grew up on Park Avenue and attended finishing schools. Her stepfather was Wall Street tycoon Paul Shields. Cooper and Rocky were quietly married at her parents' Park Avenue residence on December 15, 1933. According to his friends, the marriage had a positive impact on Cooper, who turned away from past indiscretions and took control of his life. Athletic and a lover of the outdoors, Rocky shared many of Cooper's interests, including riding, skiing, and skeet-shooting. She organized their social life, and her wealth and social connections provided Cooper access to New York high society. Cooper and his wife owned homes in the Los Angeles area in Encino (1933–36), Brentwood (1936–53), and Holmby Hills (1954–61), and owned a vacation home in Aspen, Colorado (1949–53). Their daughter Maria Veronica Cooper was born on September 15, 1937.
By all accounts, Cooper was a patient and affectionate father, teaching Maria to ride a bicycle, play tennis, ski, and ride horses. Sharing many of her parents' interests, she accompanied them on their travels and was often photographed with them. Like her father, she developed a love for art and drawing. As a family they vacationed together in Sun Valley, Idaho, spent time at Rocky's parents' country house in Southampton, New York, and took frequent trips to Europe. Cooper and Rocky were legally separated on May 16, 1951, when Cooper moved out of their home. For over two years, they maintained a fragile and uneasy family life with their daughter. Cooper moved back into their home in November 1953, and their formal reconciliation occurred in February 1954.
Romantic relationships.
Prior to his marriage, Cooper had a series of romantic relationships with leading actresses, beginning in 1927 with Clara Bow, who advanced his career by helping him get one of his first leading roles in "Children of Divorce". Bow was also responsible for getting Cooper a role in "Wings", which generated an enormous amount of fan mail for the young actor. In 1928, he had a relationship with another experienced actress, Evelyn Brent, whom he met while filming "Beau Sabreur". In 1929, while filming "The Wolf Song", Cooper began an intense affair with Lupe Vélez, which was the most important romance of his early life. During their two years together, Cooper also had brief affairs with Marlene Dietrich while filming "Morocco" in 1930 and with Carole Lombard while making "I Take This Woman" in 1931. During his year abroad in 1931–32, Cooper had an affair with the married Countess Dorothy di Frasso, while staying at her Villa Madama in Rome.
After he was married in December 1933, Cooper remained faithful to his wife until the summer of 1942, when he began an affair with Ingrid Bergman during the production of "For Whom the Bell Tolls". Their relationship lasted through the completion of filming "Saratoga Trunk" in June 1943. In 1948, after finishing work on "The Fountainhead", Cooper began an affair with actress Patricia Neal, his co-star. At first they kept their affair discreet, but eventually it became an open secret in Hollywood, and Cooper's wife confronted him with the rumors, which he admitted were true. He also confessed that he was in love with Neal, and continued to see her. Cooper and his wife were legally separated in May 1951, but he did not seek a divorce. Neal ended their relationship in late December 1951. During his three-year separation from his wife, Cooper had affairs with Grace Kelly, Lorraine Chanel, and Gisèle Pascal.
Friendships, interests, and character.
Cooper's twenty-year friendship with Ernest Hemingway began at Sun Valley in October 1940. The previous year, Hemingway drew upon Cooper's image when he created the character of Robert Jordan for the novel "For Whom the Bell Tolls". The two shared a passion for the outdoors, and for years they hunted duck and pheasant, and skied together in Sun Valley. Both men admired the work of Rudyard Kipling—Cooper kept a copy of the poem "If—" in his dressing room—and retained as adults Kipling's sense of boyish adventure. As well as admiring Cooper's hunting skills and knowledge of the outdoors, Hemingway believed his character matched his screen persona, once telling a friend, "If you made up a character like Coop, nobody would believe it. He's just too good to be true." They saw each other often, and their friendship remained strong through the years.
"For me the really satisfying things I do are offered me, free, for nothing. Ever go out in the fall and do a little hunting? See the frost on the grass and the leaves turning? Spend a day in the hills alone, or with good companions? Watch a sunset and a moonrise? Notice a bird in the wind? A stream in the woods, a storm at sea, cross the country by train, and catch a glimpse of something beautiful in the desert, or the farmlands? Free to everybody ..."
Gary Cooper
Cooper's social life generally centered on sports, outdoor activities, and dinner parties with his family and friends from the film industry, including directors Henry Hathaway, Howard Hawks, William Wellman, and Fred Zinnemann, and actors Joel McCrea, James Stewart, Barbara Stanwyck, and Robert Taylor. As well as hunting, Cooper enjoyed riding, fishing, skiing, and later in life, scuba diving. He never abandoned his early love for art and drawing, and over the years, he and his wife acquired a private collection of modern paintings, including works by Pierre-Auguste Renoir, Paul Gauguin, and Georgia O'Keeffe. Cooper owned several works by Pablo Picasso, whom he met in 1956. Cooper had a lifelong passion for automobiles, with a collection that included a 1930 Duesenberg.
Cooper was naturally reserved and introspective, and loved the solitude of outdoor activities. Not unlike his screen persona, his communication style frequently consisted of long silences with an occasional "yup" and "shucks". He once said, "If others have more interesting things to say than I have, I keep quiet." According to his friends, Cooper could also be an articulate, well-informed conversationalist on topics ranging from horses, guns, and Western history to film production, sports cars, and modern art. He was modest and unpretentious, frequently downplaying his acting abilities and career accomplishments. His friends and colleagues described him as charming, well-mannered, and thoughtful, with a lively boyish sense of humor. Cooper maintained a sense of propriety throughout his career and never misused his movie star status—never sought special treatment or refused to work with a director or leading lady. His close friend Joel McCrea recalled, "Coop never fought, he never got mad, he never told anybody off that I know of; everybody that worked with him liked him."
Political views.
Cooper was a conservative Republican like his father, and voted for Calvin Coolidge in 1924, Herbert Hoover in 1928 and 1932, and campaigned for Wendell Willkie in 1940. When Franklin D. Roosevelt ran for an unprecedented fourth presidential term in 1944, Cooper campaigned for Thomas E. Dewey and criticized Roosevelt for being dishonest and adopting "foreign" ideas. In a radio address that he paid for himself just prior to the election, Cooper said, "I disagree with the New Deal belief that the America all of us love is old and worn-out and finished—and has to borrow foreign notions that don't even seem to work any too well where they come from ... Our country is a young country that just has to make up its mind to be itself again." He also attended a Republican rally at the Los Angeles Memorial Coliseum that drew 93,000 Dewey supporters.
Cooper was one of the founding members of the Motion Picture Alliance for the Preservation of American Ideals, a conservative organization dedicated, according to its statement of principles, to preserving the "American way of life" and opposing communism and fascism. The organization—whose membership included Walt Disney, Clark Gable, Ronald Reagan, Barbara Stanwyck, and John Wayne—pressured the United States Congress to investigate communist influence in the motion picture industry. On October 23, 1947, Cooper appeared before the House Un-American Activities Committee (HUAC) and was asked if he had observed any "communistic influence" in Hollywood. Cooper recounted statements he'd heard suggesting that the Constitution was out of date and that Congress was an unnecessary institution—comments that Cooper said he found to be "very un-American". He also testified that he had rejected several scripts because he thought they were "tinged with communist ideas". Unlike some other witnesses, Cooper did not name any individuals during his testimony.
Religion.
Cooper was baptized in the Anglican Church in December 1911 in England, and was raised in the Episcopal Church in the United States. While he was never an observant Christian during his adult life, many of his friends believed he had a deeply spiritual side.
On June 26, 1953, Cooper accompanied his wife and daughter, who were devout Catholics, to Rome, where they had an audience with Pope Pius XII. Cooper and his wife were still separated at the time, but the papal visit marked the beginning of their gradual reconciliation. In the coming years, Cooper contemplated his mortality and his personal behavior, and started discussing Catholicism with his family. He began attending church with them regularly, and met with their parish priest, who offered Cooper spiritual guidance. After several months of study, Cooper was baptized as a Roman Catholic on April 9, 1959, before a small group of family and friends at the Church of the Good Shepherd in Beverly Hills.
Final year and death.
On April 14, 1960, Cooper underwent surgery at Massachusetts General Hospital in Boston for prostate cancer after it had metastasized to his colon. He fell ill again on May 31 and underwent further surgery at Lebanon Hospital in Los Angeles in early June to remove a malignant tumor from his large intestine. After recuperating over the summer, Cooper took his family on vacation to the south of France before traveling to England in the fall to make his last film, "The Naked Edge". In December 1960, he worked on the NBC television documentary "The Real West", which was part of the company's "Project 20" series. On December 27, his wife learned from their family doctor that Cooper's cancer had spread to his lungs and bones and was inoperable. His family decided not to tell him immediately.
On January 9, 1961, Cooper attended a dinner given in his honor at the Friars Club hosted by Frank Sinatra and Dean Martin. Attended by many of his industry friends, the dinner concluded with a brief speech by Cooper who said, "The only achievement I'm proud of is the friends I've made in this community." In mid-January, Cooper took his family to Sun Valley for their last vacation together. Cooper and Hemingway hiked through the snow together for the last time. On February 27, after returning to Los Angeles, Cooper learned that he was dying. He later told his family, "We'll pray for a miracle; but if not, and that's God's will, that's all right too." On April 17, Cooper watched the Academy Awards ceremony on television and saw his good friend James Stewart, who had presented Cooper with his first Oscar years earlier, accept on Cooper's behalf an honorary award for lifetime achievement—his third Oscar. Speaking to Cooper, an emotional Stewart said, "Coop, I want you to know I'll get it to you right away. With it goes all the friendship and affection and the admiration and deep respect of all of us. We're very, very proud of you, Coop." The following day, newspapers around the world announced the news that Cooper was dying. In the coming days he received numerous messages of appreciation and encouragement, including telegrams from Pope John XXIII and Queen Elizabeth II, and a phone call from President John F. Kennedy.
On May 4, Cooper, in his last public statement, said, "I know that what is happening is God's will. I am not afraid of the future." He received the last rites on May 12. Cooper died quietly the following day, Saturday, May 13, 1961, at 12:47 pm, less than a week after his sixtieth birthday. A requiem mass was held on May 18 at the Church of the Good Shepherd, attended by many of Cooper's friends, including James Stewart, Henry Hathaway, Joel McCrea, Audrey Hepburn, Jack Warner, John Ford, John Wayne, Edward G. Robinson, Frank Sinatra, Dean Martin, Randolph Scott, Walter Pidgeon, Bob Hope, and Marlene Dietrich. Cooper was buried in the Grotto of Our Lady of Lourdes in Holy Cross Cemetery in Culver City, California. In May 1974, after his family relocated to New York, Cooper's remains were exhumed and reburied in Sacred Hearts Cemetery in Southampton, New York. His grave is marked by a three-ton boulder from a Montauk quarry.
Acting style and reputation.
"Naturalness is hard to talk about, but I guess it boils down to this: You find out what people expect of your type of character and then you give them what they want. That way, an actor never seems unnatural or affected no matter what role he plays."
Gary Cooper
Cooper's acting style consisted of three essential characteristics: his ability to project elements of his own personality onto the characters he portrayed, to appear natural and authentic in his roles, and to underplay and deliver restrained performances calibrated for the camera and the screen. Acting teacher Lee Strasberg once observed: "The simplest examples of Stanislavsky's ideas are actors such as Gary Cooper, John Wayne, and Spencer Tracy. They try not to act but to be themselves, to respond or react. They refuse to say or do anything they feel not to be consonant with their own characters." Film director François Truffaut ranked Cooper among "the greatest actors" because of his ability to deliver great performances "without direction". This ability to project elements of his own personality onto his characters produced a continuity across his performances to the extent that critics and audiences were convinced that he was simply "playing himself".
Cooper's ability to project his personality onto his characters played an important part in his appearing natural and authentic on screen. Actor John Barrymore said of Cooper, "This fellow is the world's greatest actor. He does without effort what the rest of us spend our lives trying to learn—namely, to be natural." Charles Laughton, who played opposite Cooper in "Devil and the Deep" agreed, "In truth, that boy hasn't the least idea how well he acts ... He gets at it from the inside, from his own clear way of looking at life." William Wyler, who directed Cooper in two films, called him a "superb actor, a master of movie acting". In his review of Cooper's performance in "The Real Glory", Graham Greene wrote, "Sometimes his lean photogenic face seems to leave everything to the lens, but there is no question here of his not acting. Watch him inoculate the girl against cholera—the casual jab of the needle, and the dressing slapped on while he talks, as though a thousand arms had taught him where to stab and he doesn't have to think anymore."
Cooper's style of underplaying before the camera surprised many of his directors and fellow actors. Even in his earliest feature films, he recognized the camera's ability to pick up slight gestures and facial movements. Commenting on Cooper's performance in "Sergeant York", director Howard Hawks observed, "He worked very hard and yet he didn't seem to be working. He was a strange actor because you'd look at him during a scene and you'd think ... this isn't going to be any good. But when you saw the rushes in the projection room the next day you could read in his face all the things he'd been thinking." Sam Wood, who directed Cooper in four films, had similar observations about Cooper's performance in "Pride of the Yankees", noting, "What I thought was underplaying turned out to be just the right approach. On the screen he's perfect, yet on the set you'd swear it's the worst job of acting in the history of motion pictures." His fellow actors also admired his abilities as an actor. Commenting on her two films playing opposite Cooper, actress Ingrid Bergman concluded, "The personality of this man was so enormous, so overpowering—and that expression in his eyes and his face, it was so delicate and so underplayed. You just didn't notice it until you saw it on the screen. I thought he was marvelous; the most underplaying and the most natural actor I ever worked with."
Career assessment and legacy.
Cooper's career spanned thirty-six years, from 1925 to 1961. During that time, he appeared in eighty-four feature films in a leading role. He was a major movie star from the end of the silent film era to the end of the golden age of Classical Hollywood. His natural and authentic acting style appealed powerfully to both men and women, and his range of performances included roles in most major movie genres, including Westerns, war films, adventure films, drama films, crime films, romance films, comedy films, and romantic comedy films. He appeared on the "Motion Picture Herald" exhibitor's poll of top ten film personalities for twenty-three consecutive years, from 1936 to 1958. According to Quigley's annual poll, Cooper was one of the top money-making stars for eighteen years, appearing in the top ten in 1936–37, 1941–49, and 1951–57. He topped the list in 1953. In Quigley's list of all-time money-making stars, Cooper is listed fourth, after John Wayne, Clint Eastwood, and Tom Cruise. At the time of his death, it was estimated that his films grossed well over $200 million (equal to $ today).
In over half of his feature films, Cooper portrayed Westerners, soldiers, pilots, sailors, and explorers—all men of action. In the rest he played a wide range of characters, included doctors, professors, artists, architects, clerks, and baseball players. Cooper's heroic screen image changed with each period of his career. In his early films, he played the young naive hero sure of his moral position and trusting in the triumph of simple virtues ("The Virginian"). After becoming a major star, his Western screen persona was replaced by a more cautious hero in adventure films and dramas ("A Farewell to Arms"). During the height of his career, from 1936 to 1943, he played a new type of hero—a champion of the common man willing to sacrifice himself for others ("Mr. Deeds", "Meet John Doe", and "For Whom the Bell Tolls"). In the post-war years, Cooper attempted broader variations on his screen image, which now reflected a hero increasingly at odds with the world who must face adversity alone ("The Fountainhead" and "High Noon"). In his final films, Cooper's hero rejects the violence of the past, and seeks to reclaim lost honor and find redemption ("Friendly Persuasion" and "Man of the West"). The screen persona he developed and sustained throughout his career represented the ideal American hero—a tall, handsome, and sincere man of steadfast integrity who emphasized action over intellect, and combined the heroic qualities of the romantic lover, the adventurer, and the common man.
On February 6, 1960, Cooper was awarded a star on the Hollywood Walk of Fame at 6243 Hollywood Boulevard for his contribution to the film industry. He was also awarded a star on the sidewalk outside the Ellen Theater in Bozeman, Montana. On May 6, 1961, he was awarded the French Order of Arts and Letters in recognition of his significant contribution to the arts. On July 30, 1961, he was posthumously awarded the David di Donatello Special Award in Italy for his career achievements. In 1966, he was inducted into the Hall of Great Western Performers at the National Cowboy & Western Heritage Museum in Oklahoma City. The American Film Institute (AFI) ranked Cooper eleventh on its list of the fifty greatest male screen legends. Three of his characters—Will Kane, Lou Gehrig, and Sergeant York—made AFI's list of the one hundred greatest heroes and villains, all of them as heroes. His Lou Gehrig line, "Today, I consider myself the luckiest man on the face of the earth.", is ranked by AFI as the thirty-eighth greatest movie quote of all time. More than a half century after his death, Cooper's enduring legacy, according to biographer Jeffrey Meyers, is his image of the ideal American hero preserved in his film performances. Charlton Heston once observed, "He projected the kind of man Americans would like to be, probably more than any actor that's ever lived."
Filmography.
The following is a list of feature films in which Cooper appeared in a leading role.
References.
Bibliography.
</dl>

</doc>
<doc id="44361" url="http://en.wikipedia.org/wiki?curid=44361" title="Congo River">
Congo River

The Congo River (also known as the Zaire River; French: "(le) fleuve Congo / Zaïre"; Portuguese: "rio Congo / Zaire") is a river in Africa and the world's deepest river with measured depths in excess of 220 m. It is the second largest river in the world by discharge (after the Amazon).
The Congo-Chambeshi river has an overall length of 4700 km, which makes it the ninth longest river (in terms of discharge, the Chambeshi is a tributary of the Lualaba River, Lualaba being the name of the Congo River upstream of the Boyoma Falls, extending for 1,800 km).
Measured along the Lualaba, the Congo River has a total length of 4370 km, 
The Congo Basin has a total area of about 4 million km2, or 13% of the entire African landmass.
Name.
The Congo river got its name from the Kingdom of Kongo which was situated on the left banks of the river estuary. The kingdom is in turn named for its Bantu population, in the 17th century reported as "Esikongo". South of the Kongo kingdom proper lay the similarly named Kakongo kingdom, mentioned in 1535. 
Abraham Ortelius in his world map of 1564 labels as "Manicongo" the city at the mouth of the river.
The tribal names in "kongo" possibly derive from a word for a public gathering or tribal assembly.
The name "Zaire" is from a Portuguese adaptation of a Kikongo word "nzere" ("river"), a truncation of "nzadi o nzere" ("river swallowing rivers"),
The river was known as "Zaire" during the 16th and 17th centuries;
"Congo" seems to have replaced "Zaire" gradually in English usage during the 18th century, and "Congo" 
is the preferred English name in 19th-century literature, although references to "Zahir" or "Zaire" as the name used by the natives (i.e. derived from Portuguese usage) remained common.
The Democratic Republic of the Congo and the Republic of the Congo are named after it, as was their predecessor state, the Republic of the Congo (Léopoldville), which had gained independence in 1960 from the Belgian Congo. 
The state of Zaire during 1971–1997 was also named for the river, after its French (and Portuguese) name.
Basin and course.
The Congo's drainage basin covers 4014500 km2. The Congo's discharge at its mouth ranges from 23000 to, with an average of 41000 m3/s.
The river and its tributaries flow through the Congo rainforest, the second largest rain forest area in the world, second only to the Amazon Rainforest in South America. The river also has the second-largest flow in the world, behind the Amazon; the third-largest drainage basin of any river, behind the Amazon and Plate rivers; and is one of the deepest rivers in the world, at depths greater than 220 m. Because its drainage basin includes areas both north and south of the equator, its flow is stable, as there is always at least one part of the river experiencing a rainy season.
The sources of the Congo are in the highlands and mountains of the East African Rift, as well as Lake Tanganyika and Lake Mweru, which feed the Lualaba River, which then becomes the Congo below Boyoma Falls. The Chambeshi River in Zambia is generally taken as the source of the Congo in line with the accepted practice worldwide of using the longest tributary, as with the Nile River.
The Congo flows generally northwards from Kisangani just below the Boyoma falls, then gradually bends southwestwards, passing by Mbandaka, joining with the Ubangi River, and running into the Pool Malebo (Stanley Pool). Kinshasa (formerly Léopoldville) and Brazzaville are on opposite sides of the river at the Pool, where the river narrows and falls through a number of cataracts in deep canyons (collectively known as the Livingstone Falls), running by Matadi and Boma, and into the sea at the small town of Muanda.
The Congo River Basin is one of the distinct physiographic sections of the larger Mid-African province, which in turn is part of the larger African massive physiographic division.
Tributaries.
"Sorted in order from the mouth heading upstream."
Downstream of Kinshasa, there are no important tributaries.
Upstream of Boyoma Falls near Kisangani, the river Congo is known as the Lualaba River.
Economic importance.
Although the Livingstone Falls prevent access from the sea, nearly the entire Congo is readily navigable in sections, especially between Kinshasa and Kisangani. Large river steamers worked the river until quite recently. The Congo River still is a lifeline in a land with few roads or railways.
Railways now bypass the three major falls, and much of the trade of Central Africa passes along the river, including copper, palm oil (as kernels), sugar, coffee, and cotton. The river is also potentially valuable for hydroelectric power, and the Inga Dams below Pool Malebo are first to exploit the Congo river.
Hydro-electric power.
The Congo River is the most powerful river in Africa. During the rainy season over 50000 m3 of water per second flow into the Atlantic Ocean. Opportunities for the Congo River and its tributaries to generate hydropower are therefore enormous. Scientists have calculated that the entire Congo Basin accounts for thirteen percent of global hydropower potential. This would provide sufficient power for all of sub-Saharan Africa's electricity needs.
Currently there are about forty hydropower plants in the Congo Basin. The largest is the Inga Falls dam, about 200 km southwest of Kinshasa. The prestigious Inga Project was launched in the early 1970s and at that time the first dam was completed. The plan as originally conceived called for the construction of five dams that would have had a total generating capacity of 34,500 megawatts. To date only two dams have been built, which are the Inga I and Inga II, with a total of fourteen turbines.
In February 2005, South Africa's state-owned power company, Eskom, announced a proposal to increase the capacity of the Inga dramatically through improvements and the construction of a new hydroelectric dam. The project would bring the maximum output of the facility to 40 GW, twice that of China's Three Gorges Dam.
It is feared that these new hydroelectric dams could lead to the extinction of many of the fish species that are endemic to the river.
Natural history.
The current course of the Congo River formed 1.5-2 million years BP, during the Pleistocene.
The Congo's formation may have led to the allopatric speciation of the bonobo and the common chimpanzee from their most recent common ancestor. The bonobo is endemic to the humid forests in the region, as are other iconic species like the Allen's swamp monkey, dryas monkey, aquatic genet, okapi and Congo peafowl.
In terms of aquatic life, the Congo River Basin has a very high species richness, and among the highest known concentrations of endemics. Until now, almost 700 fish species have been recorded from the Congo River Basin, and large sections remain virtually unstudied. Due to this and the great ecological differences between the regions in the basin, it is often divided into multiple ecoregions (instead of treating it as a single ecoregion). Among these ecoregions, the Lower Congo Rapids alone has more than 300 fish species, including approximately 80 endemics while the southwestern part (Kasai Basin) alone has more than 200 fish species, of which about a quarter are endemic. The dominant fish families–at least in parts of the river–are Cyprinidae (carp/cyprinids, such as "Labeo simpsoni"), Mormyridae (elephantfishes), Alestidae (African tetras), Mochokidae (squeaker catfishes), and Cichlidae (cichlids). Among the natives in the river is the huge, highly carnivorous giant tigerfish. Two of the more unusual endemic cichlids are the whitish (non-pigmented) and blind "Lamprologus lethops", which is believed to live as deep as 160 m below the surface, and "Heterochromis multidens", which appears to be more closely related to cichlids of the Americas than other Africa cichlid. There are also numerous endemic frogs and snails. Several hydroelectric dams are planned on the river, and these may lead to the extinction of many of the endemics.
Several species of turtles, and the slender-snouted, Nile and dwarf crocodile are native to the Congo River Basin. African manatees inhabit the lower parts of the river.
Exploration.
The entire Congo basin is populated by Bantu peoples, divided into several hundred ethnic or tribal groups (see ethnic groups of the Democratic Republic of the Congo). Bantu expansion is estimated to have reached the Middle Congo by about 500 BC, and the Upper Congo by the beginning of the Common Era. Remnants of the aboriginal population displaced by the Bantu migration, Pygmies/"Abatwa" of the Ubangian phylum, remain in the remote forest areas of the Congo basin.
The Kingdom of Kongo was formed around 1400 on the left banks of the lower Congo River. Its territorial control along the river remained limited to what corresponds to the modern Bas-Congo province. European exploration of the Congo begins in 1482, when Portuguese explorer Diogo Cão discovered the river estuary (likely in August 1482), which he marked by a Padrão, or stone pillar (still existing, but only in fragments) erected on Shark Point. Cão also sailed up the river for a short distance, establishing contact with the Kingdom of Congo. The course of the river remained unknown throughout the early modern period.
The upper Congo basin runs west of the Albertine Rift. Its connection to the Congo was unknown until 1877. 
The extreme northeast of the Congo basin was reached by the Nilotic expansion at some point between the 15th and 18th centuries, by the ancestors of the Southern Luo speaking Alur people.
Francisco de Lacerda following the Zambezi reached the uppermost part of the Congo basin (the Kazembe in the upper Luapula basin) in 1796.
The upper Congo River, known as the Lualaba was first reached by the Arab slave trade by the 19th century. Nyangwe was founded as a slavers' outpost around 1860.
David Livingstone was the first European to reach Nyangwe in 1871. Livingstone proposed to prove that the Lualaba connected to the Nile, but on 15 July, he witnessed a massacre of about 400 Africans by Arab slavers in Nyangwe, which experience left him too horrified and shattered to continue his mission to find the sources of the Nile, so he turned back to Lake Tanganyika.
The middle reaches of the Congo remained unexplored from either the east or west, until Henry Morton Stanley's expedition of 1876/7. 
At the time one of the last open questions of the exploration of Africa (or indeed of the world)
whether the Lualaba river fed the Nile (Livingstone's theory), the Congo or even the Niger. 
Financed in 1874, Stanley's first trans-Africa exploration
started in Zanzibar, and reached the Lualaba on 17 October 1876. 
Overland he reached Nyangwe, the centre of a lawless area containing cannibal tribes at which Tippu Tip based his trade in slaves. Stanley managed to hire a force from Tippu Tip, to guard him for the next 150 km or so, for 90 days. The party left Nyangwe overland through the dense Matimba forest. On 19 November they reached the Lualaba again. Since the going through the forest was so heavy, Tippu Tip turned around with his party on December 28, leaving Stanley on his own, with 143 people, including 8 children and 16 women. They had 23 canoes. His first encounter with a local tribe was with the cannibal Wenya. In total Stanley would report 32 unfriendly meetings on the river, some violent, even though he attempted to negotiate a peaceful thoroughfare. But the tribes were wary as their only experience of outsiders was of slave traders, and they could not understand his motive of exploration.
On 6 January 1877, after 400 mi, they reached Boyoma Falls (called Stanley Falls for some time after), consisting of seven cataracts spanning 60 mi which they had to pass overland. It took them to 7 February to reach the end of the Falls. Here Stanley learned that the river was called "Ikuta Yacongo", proving to him that he had reached the Congo, and that the Lualaba did not feed the Nile.
From this point, the tribes were no longer cannibals, but possessed firearms, apparently as a result of Portuguese influence. Some four weeks and 1200 mi later he reached Stanley Pool (now Pool Malebo), the site of the present day cities Kinshasa and Brazzaville. Further downstream were the Livingstone Falls, misnamed as Livingstone had never been on the Congo: a series of 32 falls and rapids with a fall of 900 ft over 220 mi. 
On 15 March they started the descent of the falls, which took five months and cost numerous lives. From the Isangile Falls, five falls from the foot, they beached the canoes and "Lady Alice" and left the river, aiming for the Portuguese outpost of Boma via land. On 3 August they reached the hamlet Nsada. From there Stanley sent four men with letters forward to Boma, asking for food for his starving people. On 7 August relief came, being sent by representatives from the Liverpool trading firm Hatton & Cookson. On 9 August they reached Boma, 1,001 days since leaving Zanzibar on November 12, 1874. The party then consisted of 108 people, including three children born during the trip. Most probably (Stanley's own publications give inconsistent figures), he lost 132 people through disease, hunger, drowning, killing and desertion.
Kinshasa was founded as a trading post by Henry Morton Stanley in 1881 and named Léopoldville in honor of Leopold II of Belgium. The Congo basin was claimed by Belgium as Congo Free State in 1885.

</doc>
<doc id="44363" url="http://en.wikipedia.org/wiki?curid=44363" title="Wien's displacement law">
Wien's displacement law

Wien's displacement law states that the black body radiation curve for different temperatures peaks at a wavelength inversely proportional to the temperature. The shift of that peak is a direct consequence of the Planck radiation law which describes the spectral brightness of black body radiation as a function of wavelength at any given temperature. However it had been discovered by Wilhelm Wien several years before Max Planck developed that more general equation, and describes the entire shift of the spectrum of black body radiation toward shorter wavelengths as temperature increases.
Formally, Wien's displacement law states that the spectral radiance of black body radiation per unit wavelength, peaks at the wavelength λmax given by: 
where "T" is the absolute temperature in kelvin. "b" is a constant of proportionality called "Wien's displacement constant", equal to ., or more conveniently to obtain wavelength in micrometers, b≈2900 μm·K. If one is considering the peak of black body emission per unit frequency or per proportional bandwidth, one must use a different proportionality constant. However the form of the law remains the same: the peak wavelength is inversely proportional to temperature (or the peak frequency is directly proportional to temperature).
Wien's displacement law may be referred to as "Wien's law", a term which is also used for the Wien approximation.
Examples.
Wien's displacement law is relevant to some everyday experiences:
Discovery.
The law is named for Wilhelm Wien, who derived it in 1893 based on a thermodynamic argument. Wien considered adiabatic expansion of a cavity containing waves of light in thermal equilibrium. He showed that under slow expansion or contraction, the energy of light reflecting off the walls changes in exactly the same way as the frequency. A general principle of thermodynamics is that a thermal equilibrium state, when expanded very slowly stays in thermal equilibrium. The adiabatic principle allowed Wien to conclude that for each mode, the adiabatic invariant energy/frequency is only a function of the other adiabatic invariant, the frequency/temperature. A modern variant of Wien's derivation can be found in the textbook by Wannier.
The consequence is that the shape of the black body radiation function (which was not yet understood) would shift proportionally in frequency (or inversely proportionally in wavelength) with temperature. When Max Planck later formulated the correct black body radiation function it did not include Wien's constant "b" explicitly. Rather, Planck's constant "h" was created and introduced into his new formula. From Planck's constant "h" and the Boltzmann constant "k", Wien's constant "b" can be obtained.
Frequency-dependent formulation.
For spectral flux considered per unit frequency formula_2 (in hertz), Wien's displacement law describes a peak emission at the optical frequency formula_3 given by:
where "α" ≈ 2.821439... is a constant resulting from the numerical solution of the maximization equation, "k" is the Boltzmann constant, "h" is the Planck constant, and "T" is the temperature (in kelvins). This frequency, it must be emphasized, does "not" correspond to the wavelength from the earlier formula which considered the peak emission "per unit wavelength".
Derivation from Planck's Law.
Planck's law for the spectrum of black body radiation predicts the Wien displacement law and may be used to numerically evaluate the constant relating temperature and peak wavelength (or frequency). According to one form of that law, the black body spectral radiance (power per emitting area per solid angle "per unit wavelength") is given by: 
Differentiating "u"(λ,"T") with respect to λ and setting the derivative equal to zero gives
which can be simplified to give
By defining:
the equation becomes one in that single variable:
The numerical solution to this equation is x = 4.965114231.
Solving for the wavelength λ in units of nanometers, and using kelvins for the temperature yields:
The form of Wien's displacement law in terms of maximum radiance per unit "frequency" is derived using similar methods, but starting with the form of Planck's law expressed in those terms rather than wavelength. The effective result is to substitute 3 for 5 in the equation for the peak wavelength. This is solved with "x" = 2.821439372.
Using the value "4" in this equation solves for the wavelength of the peak in the spectral radiance expressed in radiance "per proportional bandwidth", perhaps a fairer way of presenting "wavelength of peak emission." That is solved as "x" = 3.920690395. The important point of Wiens law, however, is that "any" such wavelength marker, including the median wavelength (or the wavelength below which a specified percentage of the emission occurs) is proportional to the reciprocal of temperature.

</doc>
<doc id="44364" url="http://en.wikipedia.org/wiki?curid=44364" title="Black body">
Black body

A black body (also, blackbody) is an idealized physical body that absorbs all incident electromagnetic radiation, regardless of frequency or angle of incidence. A white body is one with a "rough surface [that] reflects all incident rays completely and uniformly in all directions."
A black body in thermal equilibrium (that is, at a constant temperature) emits electromagnetic radiation called black-body radiation. The radiation is emitted according to Planck's law, meaning that it has a spectrum that is determined by the temperature alone (see figure at right), not by the body's shape or composition.
A black body in thermal equilibrium has two notable properties:
An approximate realization of a black surface is a hole in the wall of a large enclosure (see below). Any light entering the hole is reflected indefinitely or absorbed inside and is unlikely to re-emerge, making the hole a nearly perfect absorber. The radiation confined in such an enclosure may or may not be in thermal equilibrium, depending upon the nature of the walls and the other contents of the enclosure.
Real materials emit energy at a fraction—called the emissivity—of black-body energy levels. By definition, a black body in thermal equilibrium has an emissivity of . A source with lower emissivity independent of frequency often is referred to as a gray body.
Construction of black bodies with emissivity as close to one as possible remains a topic of current interest. 
In astronomy, the radiation from stars and planets is sometimes characterized in terms of an effective temperature, the temperature of a black body that would emit the same total flux of electromagnetic energy.
Definition.
The idea of a black body originally was introduced by Gustav Kirchhoff in 1860 as follows:
A more modern definition drops the reference to "infinitely small thicknesses":
Idealizations.
This section describes some concepts developed in connection with black bodies.
Cavity with a hole.
A widely used model of a black surface is a small hole in a cavity with walls that are opaque to radiation. Radiation incident on the hole will pass into the cavity, and is very unlikely to be re-emitted if the cavity is large. The hole is not quite a perfect black surface — in particular, if the wavelength of the incident radiation is longer than the diameter of the hole, part will be reflected. Similarly, even in perfect thermal equilibrium, the radiation inside a finite-sized cavity will not have an ideal Planck spectrum for wavelengths comparable to or larger than the size of the cavity.
Suppose the cavity is held at a fixed temperature "T" and the radiation trapped inside the enclosure is at thermal equilibrium with the enclosure. The hole in the enclosure will allow some radiation to escape. If the hole is small, radiation passing in and out of the hole has negligible effect upon the equilibrium of the radiation inside the cavity. This escaping radiation will approximate black-body radiation that exhibits a distribution in energy characteristic of the temperature "T" and does not depend upon the properties of the cavity or the hole, at least for wavelengths smaller than the size of the hole. See the figure in the Introduction for the spectrum as a function of the frequency of the radiation, which is related to the energy of the radiation by the equation "E"="hf", with "E" = energy, "h" = Planck's constant, "f" = frequency.
At any given time the radiation in the cavity may not be in thermal equilibrium, but the second law of thermodynamics states that if left undisturbed it will eventually reach equilibrium, although the time it takes to do so may be very long. Typically, equilibrium is reached by continual absorption and emission of radiation by material in the cavity or its walls. Radiation entering the cavity will be "thermalized"; by this mechanism: the energy will be redistributed until the ensemble of photons achieves a Planck distribution. The time taken for thermalization is much faster with condensed matter present than with rarefied matter such as a dilute gas. At temperatures below billions of Kelvin, direct photon–photon interactions are usually negligible compared to interactions with matter. Photons are an example of an interacting boson gas, and as described by the H-theorem, under very general conditions any interacting boson gas will approach thermal equilibrium.
Transmission, absorption, and reflection.
A body's behavior with regard to thermal radiation is characterized by its transmission τ, absorption α, and reflection ρ.
The boundary of a body forms an interface with its surroundings, and this interface may be rough or smooth. A nonreflecting interface separating regions with different refractive indices must be rough, because the laws of reflection and refraction governed by the Fresnel equations for a smooth interface require a reflected ray when the refractive indices of the material and its surroundings differ. A few idealized types of behavior are given particular names:
An opaque body is one that transmits none of the radiation that reaches it, although some may be reflected. That is, τ=0 and α+ρ=1
A transparent body is one that transmits all the radiation that reaches it. That is, τ=1 and α=ρ=0.
A gray body is one where α, ρ and τ are uniform for all wavelengths. This term also is used to mean a body for which α is temperature and wavelength independent.
A white body is one for which all incident radiation is reflected uniformly in all directions: τ=0, α=0, and ρ=1.
For a black body, τ=0, α=1, and ρ=0. Planck offers a theoretical model for perfectly black bodies, which he noted do not exist in nature: besides their opaque interior, they have interfaces that are perfectly transmitting and non-reflective.
Kirchhoff's perfect black bodies.
Kirchhoff in 1860 introduced the theoretical concept of a perfect black body with a completely absorbing surface layer of infinitely small thickness, but Planck noted some severe restrictions upon this idea. Planck noted three requirements upon a black body: the body must (i) allow radiation to enter but not reflect; (ii) possess a minimum thickness adequate to absorb the incident radiation and prevent its re-emission; (iii) satisfy severe limitations upon scattering to prevent radiation from entering and bouncing back out. As a consequence, Kirchhoff's perfect black bodies that absorb all the radiation that falls on them cannot be realized in an infinitely thin surface layer, and impose conditions upon scattering of the light within the black body that are difficult to satisfy.
Realizations.
A realization of a black body is a real world, physical embodiment. Here are a few.
Cavity with a hole.
In 1898, Otto Lummer and Ferdinand Kurlbaum published an account of their cavity radiation source. Their design has been used largely unchanged for radiation measurements to the present day. It was a hole in the wall of a platinum box, divided by diaphragms, with its interior blackened with iron oxide. It was an important ingredient for the progressively improved measurements that led to the discovery of Planck's law. A version described in 1901 had its interior blackened with a mixture of chromium, nickel, and cobalt oxides.
Near-black materials.
There is interest in blackbody-like materials for camouflage and radar-absorbent materials for radar invisibility. They also have application as solar energy collectors, and infrared thermal detectors. As a perfect emitter of radiation, a hot material with black body behavior would create an efficient infrared heater, particularly in space or in a vacuum where convective heating is unavailable. They are also useful in telescopes and cameras as anti-reflection surfaces to reduce stray light, and to gather information about objects in high-contrast areas (for example, observation of planets in orbit around their stars), where blackbody-like materials absorb light that comes from the wrong sources.
It has long been known that a lamp-black coating will make a body nearly black. An improvement on lamp-black is found in manufactured carbon nanotubes. Nano-porous materials can achieve refractive indices nearly that of vacuum, in one case obtaining average reflectance of 0.045%. In 2009, a team of Japanese scientists created a material called nanoblack which is close to an ideal black body, based on vertically aligned single-walled carbon nanotubes. This absorbs between 98% and 99% of the incoming light in the spectral range from the ultra-violet to the far-infrared regions.
Another example of a nearly perfect black material is super black, made by chemically etching a nickel–phosphorus alloy.
Stars and planets.
A star or planet often is modeled as a black body, and electromagnetic radiation emitted from these bodies as black-body radiation. The figure shows a highly schematic cross-section to illustrate the idea. The photosphere of the star, where the emitted light is generated, is idealized as a layer within which the photons of light interact with the material in the photosphere and achieve a common temperature "T" that is maintained over a long period of time. Some photons escape and are emitted into space, but the energy they carry away is replaced by energy from within the star, so that the temperature of the photosphere is nearly steady. Changes in the core lead to changes in the supply of energy to the photosphere, but such changes are slow on the time scale of interest here. Assuming these circumstances can be realized, the outer layer of the star is somewhat analogous to the example of an enclosure with a small hole in it, with the hole replaced by the limited transmission into space at the outside of the photosphere. With all these assumptions in place, the star emits black-body radiation at the temperature of the photosphere.
Using this model the effective temperature of stars is estimated, defined as the temperature of a black body that yields the same surface flux of energy as the star. If a star were a black body, the same effective temperature would result from any region of the spectrum. For example, comparisons in the "B" (blue) or "V" (visible) range lead to the so-called "B-V" color index, which increases the redder the star, with the Sun having an index of +0.648 ± 0.006. Combining the "U" (ultraviolet) and the "B" indices leads to the "U-B" index, which becomes more negative the hotter the star and the more the UV radiation. Assuming the Sun is a type G2 V star, its "U-B" index is +0.12. The two indices for two types of stars are compared in the figure with the effective surface temperature of the stars assuming they are black bodies. It can be seen that there is only a rough correlation. For example, for a given "B-V" index from the blue-visible region of the spectrum., the curves for both types of star lie below the corresponding black-body "U-B" index that includes the ultraviolet spectrum, showing that both types of star emit less ultraviolet light than a black body with the same "B-V" index. It is perhaps surprising that they fit a black body curve as well as they do, considering that stars have greatly different temperatures at different depths. For example, the Sun has an effective temperature of 5780 K, which can be compared to the temperature of the photosphere of the Sun (the region generating the light), which ranges from about 5000 K at its outer boundary with the chromosphere to about 9500 K at its inner boundary with the convection zone approximately 500 km deep.
Black holes.
A black hole is a region of spacetime from which nothing escapes. Around a black hole there is a mathematically defined surface called an event horizon that marks the point of no return. It is called "black" because it absorbs all the light that hits the horizon, reflecting nothing, making it almost an ideal black body (radiation with a wavelength equal to or larger than the radius of the hole may not be absorbed, so black holes are not perfect black bodies). Physicists believe that to an outside observer, black holes have a non-zero temperature and emit radiation with a nearly perfect black-body spectrum, ultimately evaporating. The mechanism for this emission is related to vacuum fluctuations in which a virtual pair of particles is separated by the gravity of the hole, one member being sucked into the hole, and the other being emitted. The energy distribution of emission is described by Planck's law with a temperature "T":
where "c" is the speed of light, ℏ is the reduced Planck constant, "kB" is Boltzmann's constant, "G" is the gravitational constant and "M" is the mass of the black hole. These predictions have not yet been tested either observationally or experimentally.
Cosmic microwave background radiation.
The big bang theory is based upon the cosmological principle, which states that on large scales the Universe is homogeneous and isotropic. According to theory, the Universe approximately a second after its formation was a near-ideal black body in thermal equilibrium at a temperature above 1010 K. The temperature decreased as the Universe expanded and the matter and radiation in it cooled. The cosmic microwave background radiation observed today is "the most perfect black body ever measured in nature". It has a nearly ideal Planck spectrum at a temperature of about 2.7K. It departs from the perfect isotropy of true black-body radiation by an observed anisotropy that varies with angle on the sky only to about one part in 100,000.
Radiative cooling.
The integration of Planck's law over all frequencies provides the total energy per unit of time per unit of surface area radiated by a black body maintained at a temperature "T", and is known as the Stefan–Boltzmann law:
where "σ" is the Stefan–Boltzmann constant, "σ" ≈ 5.67 × 10−8 W/(m2K4). To remain in thermal equilibrium at constant temperature "T", the black body must absorb or internally generate this amount of power P over the given area A.
The cooling of a body due to thermal radiation is often approximated using the Stefan–Boltzmann law supplemented with a "gray body" emissivity "ε ≤ 1" ("P/A" = "εσT"4). The rate of decrease of the temperature of the emitting body can be estimated from the power radiated and the body's heat capacity. This approach is a simplification that ignores details of the mechanisms behind heat redistribution (which may include changing composition, phase transitions or restructuring of the body) that occur within the body while it cools, and assumes that at each moment in time the body is characterized by a single temperature. It also ignores other possible complications, such as changes in the emissivity with temperature, and the role of other accompanying forms of energy emission, for example, emission of particles like neutrinos.
If a hot emitting body is assumed to follow the Stefan–Boltzmann law and its power emission "P" and temperature "T" is known, this law can be used to estimate the dimensions of the emitting object, because the total emitted power is proportional to the area of the emitting surface. In this way it was found that X-ray bursts observed by astronomers originated in neutron stars with a radius of about 10 km, rather than black holes as originally conjectured. It should be noted that an accurate estimate of size requires some knowledge of the emissivity, particularly its spectral and angular dependence.
References.
Bibliography.
</dl>

</doc>
<doc id="44365" url="http://en.wikipedia.org/wiki?curid=44365" title="Typewriter">
Typewriter

A typewriter is a mechanical or electromechanical machine for writing in characters similar to those produced by printer's movable type by means of keyboard-operated types striking a ribbon to transfer ink or carbon impressions onto paper. Typically one character is printed on each keypress. The machine prints characters by making ink impressions of type elements similar to the sorts used in movable type letterpress printing.
After their invention in the 1860s, typewriters quickly became indispensable tools for practically all writing other than personal correspondence. They were widely used by professional writers, in offices, and for business correspondence in private homes. By the end of the 1980s, word processors and personal computers had largely displaced typewriters in most of these uses in the Western world, but as of the 2010s the typewriter is still prominent in many parts of the world, including India.
Notable typewriter manufacturers included E. Remington and Sons, IBM, Imperial Typewriters, Oliver Typewriter Company, Olivetti, Royal Typewriter Company, Smith Corona, Underwood Typewriter Company, Adler and .
History.
Although many modern typewriters have one of several similar designs, their invention was incremental, developed by numerous inventors working independently or in competition with each other over a series of decades. As with the automobile, telephone, and telegraph, a number of people contributed insights and inventions that eventually resulted in ever more commercially successful instruments. Historians have estimated that some form of typewriter was invented 52 times as thinkers tried to come up with a workable design.
Early innovations.
In 1575 an Italian printmaker, Francesco Rampazzetto, invented the 'scrittura tattile', a machine to impress letters in papers.
In 1714, Henry Mill obtained a patent in Britain for a machine that, from the patent, appears to have been similar to a typewriter. The patent shows that this machine was actually created: "[he] hath by his great study and paines & expence invented and brought to perfection an artificial machine or method for impressing or transcribing of letters, one after another, as in writing, whereby all writing whatsoever may be engrossed in paper or parchment so neat and exact as not to be distinguished from print; that the said machine or method may be of great use in settlements and public records, the impression being deeper and more lasting than any other writing, and not to be erased or counterfeited without manifest discovery."
In 1802 Italian Agostino Fantoni developed a particular typewriter to enable his blind sister to write.
In 1808 Italian Pellegrino Turri invented a typewriter. He also invented carbon paper to provide the ink for his machine.
In 1823 Italian Pietro Conti di Cilavegna invented a new model of typewriter, the "tachigrafo", also known as "tachitipo".
In 1829, William Austin Burt patented a machine called the "Typographer" which, in common with many other early machines, is listed as the "first typewriter". The Science Museum (London) describes it merely as "the first writing mechanism whose invention was documented," but even that claim may be excessive, since Turri's invention pre-dates it. Even in the hands of its inventor, this machine was slower than handwriting. Burt and his promoter John D. Sheldon never found a buyer for the patent, so the invention was never commercially produced. Because the typographer used a dial, rather than keys, to select each character, it was called an "index typewriter" rather than a "keyboard typewriter." Index typewriters of that era resemble the squeeze-style embosser from the 1970s more than they resemble the modern keyboard typewriter.
By the mid-19th century, the increasing pace of business communication had created a need for mechanization of the writing process. Stenographers and telegraphers could take down information at rates up to 130 words per minute, whereas a writer with a pen was limited to a maximum of 30 words per minute (the 1853 speed record).
From 1829 to 1870, many printing or typing machines were patented by inventors in Europe and America, but none went into commercial production.
Charles Thurber developed multiple patents, of which his first in 1843 was developed as an aid to the blind, such as the 1845 Chirographer.
In 1855, the Italian Giuseppe Ravizza created a prototype typewriter called "Cembalo scrivano o macchina da scrivere a tasti" ("Scribe harpsichord, or machine for writing with keys"). It was an advanced machine that let the user see the writing as it was typed.
In 1861, Father Francisco João de Azevedo, a Brazilian priest, made his own typewriter with basic materials and tools, such as wood and knives. In that same year the Brazilian emperor D. Pedro II, presented a gold medal to Father Azevedo for this invention. Many Brazilian people as well as the Brazilian federal government recognize Fr. Azevedo as the inventor of the typewriter, a claim that has been the subject of some controversy. In 1865, John Pratt, of Centre, Alabama, built a machine called the "Pterotype" which appeared in an 1867 "Scientific American" article and inspired other inventors. Between 1864 and 1867 Peter Mitterhofer, a carpenter from South Tyrol (then part of Austria) developed several models and a fully functioning prototype typewriter in 1867.
Hansen Writing Ball.
In 1865, Rev. Rasmus Malling-Hansen of Denmark invented the Hansen Writing Ball, which went into commercial production in 1870 and was the first commercially sold typewriter. It was a success in Europe and was reported as being used in offices in London as late as 1909. Malling-Hansen used a solenoid escapement to return the carriage on some of his models which makes him a candidate for the title of inventor of the first "electric" typewriter. According to the book "Hvem er skrivekuglens opfinder?" (English: "Who is the inventor of the Writing Ball?"), written by Malling-Hansen's daughter, Johanne Agerskov, in 1865, Malling-Hansen made a porcelain model of the keyboard of his writing ball and experimented with different placements of the letters to achieve the fastest writing speed. Malling-Hansen placed the letters on short pistons that went directly through the ball and down to the paper. This, together with the placement of the letters so that the fastest writing fingers struck the most frequently used letters, made the Hansen Writing Ball the first typewriter to produce text substantially faster than a person could write by hand. The Hansen Writing Ball was produced with only upper case characters.
Malling-Hansen developed his typewriter further through the 1870s and 1880s and made many improvements, but the writing head remained the same. On the first model of the writing ball from 1870, the paper was attached to a cylinder inside a wooden box. In 1874, the cylinder was replaced by a carriage, moving beneath the writing head. Then, in 1875, the well-known "tall model" was patented, which was the first of the writing balls that worked without electricity. Malling-Hansen attended the world exhibitions in Vienna in 1873 and Paris in 1878 and he received the first-prize for his invention at both exhibitions.
Sholes and Glidden Type-writer.
The first typewriter to be commercially successful was invented in 1868 by Americans Christopher Latham Sholes, Carlos Glidden and Samuel W. Soule in Milwaukee, Wisconsin, although Sholes soon disowned the machine and refused to use, or even to recommend it. The working prototype was made by the machinist Matthias Schwalbach. The patent (US 79,265) was sold for $12,000 to Densmore and Yost, who made an agreement with E. Remington and Sons (then famous as a manufacturer of sewing machines) to commercialize the machine as the "Sholes and Glidden Type-Writer". This was the origin of the term "typewriter". Remington began production of its first typewriter on March 1, 1873, in Ilion, New York. It had a QWERTY keyboard layout, which because of the machine's success, was slowly adopted by other typewriter manufacturers. As with most other early typewriters, because the type bars strike upwards, the typist could not see the characters as they were typed.
Standardization.
By about 1910, the "manual" or "mechanical" typewriter had reached a somewhat standardized design. There were minor variations from one manufacturer to another, but most typewriters followed the concept that each key was attached to a typebar that had the corresponding letter molded, in reverse, into its striking head. When a key was struck briskly and firmly, the typebar hit a ribbon (usually made of inked fabric), making a printed mark on the paper wrapped around a cylindrical platen. The platen was mounted on a carriage that moved left or right, automatically advancing the typing position horizontally after each character was typed. The paper, rolled around the typewriter's platen, was then advanced vertically by the "carriage return" lever (at the far left, or sometimes on the far right) into position for each new line of text.
Some ribbons were inked in black and red stripes, each being half the width and the entire length of the ribbon. A lever on most machines allowed switching between colors, which was useful for bookkeeping entries where negative amounts had to be in red.
Frontstriking.
In most of the early typewriters, the type bars struck upward against the paper, pressed against the bottom of the platen, so the typist could not see the text as it was typed. What was typed was not visible until a carriage return caused it to scroll into view. The difficulty with any other arrangement was ensuring the type bars fell back into place reliably when the key was released. This was eventually achieved with various ingenious mechanical designs and so-called "visible typewriters" which used frontstriking, in which the type bars struck forward against the front side of the platen, became standard. One of the first was the Daugherty Visible, introduced in 1893, which also introduced the four-bank keyboard that became standard, although the Underwood which came out two years later was the first major typewriter with these features. However, older "nonvisible" models continued in production to as late as 1915.
Shift key.
A significant innovation was the shift key, introduced with the Remington No. 2 in 1878. This key physically "shifted" either the basket of typebars, in which case the typewriter is described as "basket shift", or the paper-holding carriage, in which case the typewriter is described as "carriage shift". Either mechanism caused a different portion of the typebar to come in contact with the ribbon/platen. The result is that each typebar could type two different characters, cutting the number of keys and typebars in half (and simplifying the internal mechanisms considerably). The obvious use for this was to allow letter keys to type both upper and lower case, but normally the number keys were also duplexed, allowing access to special symbols such as percent (%) and ampersand (&). With the shift key, manufacturing costs (and therefore purchase price) were greatly reduced, and typist operation was simplified; both factors contributed greatly to mass adoption of the technology. Certain models, such as the Barlet, had a double shift so that each key performed three functions. These little three-row machines were portable and could be used by journalists.
However, because the shift key required more force to push (its mechanism was moving a much larger mass than other keys), and was operated by the "pinky" finger (normally the weakest finger on the hand), it was difficult to hold the shift down for more than two or three consecutive strokes. The "shift lock" key (the precursor to the modern caps lock) allowed the shift operation to be maintained indefinitely.
Character sizes.
In English-speaking countries, the commonplace typewriters printing fixed-width characters were standardized to print six horizontal lines per vertical inch, and had either of two variants of character width, called "pica" for ten characters per horizontal inch and "elite" for twelve. This differs from the use of these terms in printing, where they refer to the height of the characters on the page ("pica" making for ten horizontal lines per vertical inch).
"Noiseless" designs.
In the early part of the 20th century, a typewriter was marketed under the name "Noiseless" and advertised as "silent". It was developed by Wellington Parker Kidder and the first model was marketed by the Noiseless Typewriter Company in 1917. An agreement with Remington in 1924 saw production transferred to Remington, and a further agreement in 1929 allowed Underwood to produce it as well. It failed to sell well, leading some observers to the conclusion that the "clickety-clack" of the typical typewriter was a consumer preference. A more likely reason is that the claims of silent operation were simply untrue.
In a conventional typewriter the type bar reaches the end of its travel simply by striking the ribbon and paper. A "noiseless" typewriter has a complex lever mechanism that decelerates the typebar mechanically before pressing it against the ribbon and paper in an attempt to dampen the noise. It was not particularly successful; it certainly reduced the high-frequency content of the sound, rendering it more of a "clunk" than a "clack" and arguably less intrusive, but such advertising claims as "A machine that can be operated a few feet away from your desk — And not be heard" were not true.
Electric designs.
Although electric typewriters would not achieve widespread popularity until nearly a century later, the basic groundwork for the electric typewriter was laid by the Universal Stock Ticker, invented by Thomas Edison in 1870. This device remotely printed letters and numbers on a stream of paper tape from input generated by a specially designed typewriter at the other end of a telegraph line.
Early electric models.
The first electric typewriter was produced by the Blickensderfer Manufacturing Company, of Stamford, Connecticut, in 1902. Like the manual Blickensderfer typewriters it used a cylindrical typewheel rather than individual typebars. It was not a commercial success, which may have been because at the time electricity had not been standardized and voltage differed from city to city. The next step in the development of the electric typewriter came in 1910, when Charles and Howard Krum filed a patent for the first practical teletypewriter. The Krums' machine, named the Morkrum Printing Telegraph, used a typewheel rather than individual typebars. This machine was used for the first commercial teletypewriter system on Postal Telegraph Company lines between Boston and New York City in 1910.
James Fields Smathers of Kansas City invented what is considered the first practical power-operated typewriter in 1914. In 1920, after returning from Army service, he produced a successful model and in 1923 turned it over to the Northeast Electric Company of Rochester for development. Northeast was interested in finding new markets for their electric motors and developed Smathers's design so that it could be marketed to typewriter manufacturers, and from 1925 Remington Electric typewriters were produced powered by Northeast's motors.
After some 2,500 electric typewriters had been produced, Northeast asked Remington for a firm contract for the next batch. However, Remington was engaged in merger talks which would eventually result in the creation of Remington Rand and no executives were willing to commit to a firm order. Northeast instead decided to enter the typewriter business for itself, and in 1929 produced the first Electromatic Typewriter.
In 1928, Delco, a division of General Motors, purchased Northeast Electric, and the typewriter business was spun off as Electromatic Typewriters, Inc. In 1933, Electromatic was acquired by IBM, which then spent $1 million on a redesign of the Electromatic Typewriter, launching the IBM Electric Typewriter Model 01 in 1935. By 1958 IBM was deriving 8% of its revenue from the sale of electric typewriters.
In 1931, an electric typewriter was introduced by Varityper Corporation. It was called the "Varityper", because a narrow cylinder-like wheel could be replaced to change the font.
Electrical typewriter designs removed the "direct" mechanical connection between the keys and the element that struck the paper. Not to be confused with later "electronic" typewriters, electric typewriters contained only a single electrical component: the motor. Where the keystroke had previously moved a typebar directly, now it engaged mechanical linkages that directed mechanical power from the motor into the typebar.
In 1941, IBM announced the Electromatic Model 04 electric typewriter, featuring the revolutionary concept of proportional spacing. By assigning varied rather than uniform spacing to different sized characters, the Type 4 recreated the appearance of a printed page, an effect that was further enhanced by a typewriter ribbon innovation that produced clearer, sharper words on the page. The proportional spacing feature became a staple of the IBM Executive series typewriters.
IBM Selectric.
IBM and Remington Rand electric typewriters were the leading models until IBM introduced the IBM Selectric typewriter in 1961, which replaced the typebars with a spherical element (or typeball) slightly smaller than a golf ball, with reverse-image letters molded into its surface. The Selectric used a system of latches, metal tapes, and pulleys driven by an electric motor to rotate the ball into the correct position and then strike it against the ribbon and platen. The typeball moved laterally in front of the paper, instead of the previous designs using a platen-carrying carriage moving the paper across a stationary print position.
Due to the physical similarity, the typeball was sometimes referred to as a "golfball". The typeball design had many advantages, especially the elimination of "jams" (when more than one key was struck at once and the typebars became entangled) and in the ability to change the typeball, allowing multiple fonts to be used in a single document.
The IBM Selectric became a commercial success, dominating the office typewriter market for at least two decades. IBM also gained an advantage by marketing more heavily to schools than did Remington, with the idea that students who learned to type on a Selectric would later choose IBM typewriters over the competition in the workplace as businesses replaced their old manual models. By the 1970s, IBM had succeeded in establishing the Selectric as the de facto standard typewriter in mid- to high-end office environments, replacing the raucous "clack" of older typebar machines with the quieter sound of gyrating typeballs.
Later models of IBM Executives and Selectrics replaced inked fabric ribbons with "carbon film" ribbons that had a dry black or colored powder on a clear plastic tape. These could be used only once, but later models used a cartridge that was simple to replace. A side effect of this technology was that the text typed on the machine could be easily read from the used ribbon, raising issues where the machines were used for preparing classified documents (ribbons had to be accounted for to ensure that typists did not carry them from the facility).
A variation known as "Correcting Selectrics" introduced a correction feature, where a sticky tape in front of the carbon film ribbon could remove the black-powdered image of a typed character, eliminating the need for little bottles of white dab-on correction fluid and for hard erasers that could tear the paper. These machines also introduced selectable "pitch" so that the typewriter could be switched between pica type (10 characters per inch) and elite type (12 per inch), even within one document. Even so, all Selectrics were monospaced—each character and letterspace was allotted the same width on the page, from a capital "W" to a period. Although IBM had produced a successful typebar-based machine with five levels of proportional spacing, called the IBM Executive, proportional spacing was not provided with the Selectric typewriter or its successors the Selectric II and Selectric III.
The only fully electromechanical Selectric Typewriter with fully proportional spacing and which used a Selectric type element was the expensive Selectric Composer, which was capable of right-margin justification and was considered a typesetting machine rather than a typewriter.
In addition to its electronic successors, the Magnetic Tape Selectric Composer (MT/SC), the Mag Card Selectric Composer, and the Electronic Selectric Composer, IBM also made electronic typewriters with proportional spacing using the Selectric element that were considered typewriters or word processors instead of typesetting machines.
The first of these was the relatively obscure Mag Card Executive, which used 88-character elements. Later, some of the same typestyles used for it were used on the 96-character elements used on the IBM Electronic Typewriter 50 and the later models 65 and 85.
By 1970, as offset printing began to replace letterpress printing, the Composer would be adapted as the output unit for a typesetting system. The system included a computer-driven input station to capture the key strokes on magnetic tape and insert the operator's format commands, and a Composer unit to read the tape and produce the formatted text for photo reproduction.
Selectric mechanisms were widely incorporated into computer terminals in the 1960s and 1970s, as they possessed obvious advantages:
The IBM 2741 terminal was a popular example of a Selectric-based computer terminal, and similar mechanisms were employed as the console devices for many IBM System/360 computers. These mechanisms used "ruggedized" designs compared to those in standard office typewriters.
Later electric models.
Some of IBM's advances were later adopted in less expensive machines from competitors. For example, Smith-Corona electric typewriters of the 1970s used interchangeable ribbon cartridges, including fabric, film, erasing, and two-color versions. At about the same time, the advent of photocopying meant that carbon copies and erasers were less and less necessary; only the original need be typed, and photocopies made from it.
Typewriter/printer hybrids.
Towards the end of the commercial popularity of typewriters in the 1970s, a number of hybrid designs combining features of printers were introduced. These often incorporated keyboards from existing models of typewriters and printing mechanisms of dot-matrix printers. The generation of teleprinters with impact pin-based printing engines was not adequate for the demanding quality required for typed output, and alternative thermal transfer technologies used in thermal label printers had become technically feasible for typewriters.
IBM produced a series of typewriters called Thermotronic with letter-quality output and correcting tape along with printers tagged Quietwriter. Brother extended the life of their typewriter product line with similar products. The development of these proprietary printing engines provided the vendors with exclusive markets in consumable ribbons and the ability to use standardized printing engines with varying degrees of electronic and software sophistication to develop product lines. Although these changes reduced prices—and greatly increased the convenience—of typewriters, the technological disruption posed by word processors left these improvements with only a short-term low-end market. To extend the life of these products, many examples were provided with communication ports to connect them to computers as printers.
Electronic typewriters.
The final major development of the typewriter was the "electronic" typewriter. Most of these replaced the typeball with a plastic or metal daisy wheel mechanism (a disk with the letters molded on the outside edge of the "petals"). The daisy wheel concept first emerged in printers developed by Diablo Systems in the 1970s. In 1981, Xerox Corporation, who by then had bought Diablo Systems, introduced a line of Electronic Typewriters incorporating this technology (the Memorywriter product line). For a time, these products were quite successful as their plastic daisy-wheel was much simpler and cheaper than the metal typeball and their electronic memory and display allowed the user to easily see errors and correct them before they were actually printed. One problem with the plastic daisy wheel was that they were not always durable. To solve this problem, more durable metal daisy wheels were made available (but at a slightly higher price). These and similar electronic typewriters were in essence dedicated word processors with either single line LCD displays or multi-line CRT displays, built-in line editors in ROM, a spelling and grammar checker, a few kilobytes of internal RAM and optional cartridge, magnetic card or diskette external memory-storage devices for storing text and even document formats. Text could be entered a line or paragraph at a time and edited using the display and built-in software tools before being committed to paper. Unlike the Selectrics and earlier models, these really were "electronic" and relied on integrated circuits and multiple electromechanical components. These typewriters were sometimes called "display typewriters", "dedicated word processors" or "word-processing typewriters", though the latter term was also frequently applied to less sophisticated machines that featured only a tiny, sometimes just single-row display. Sophisticated models were also called "word processors", though today that term almost always denotes a type of software program. Manufacturers of such machines included Brother (Brother WP1 and WP500 etc., where WP stood for word processor), Canon (Canon Cat), Smith-Corona (PWP, i.e. Personal Word Processor line) and Philips/Magnavox (VideoWriter).
End of an era.
The 1970s and early 1980s were a time of transition for typewriters and word processors. At one point in time, most small-business offices would be completely old-style, while large corporations and government departments would already be all new-style; other offices would have a mixture. The pace of change was so rapid that it was common for clerical staff to have to learn several new systems, one after the other, in just a few years. While such rapid change is commonplace today, and is taken for granted, this was not always so; in fact, typewriting technology changed very little in its first 80 or 90 years.
Due to falling sales, IBM sold its typewriter division in 1990 to Lexmark, completely exiting from a market it once dominated.
The increasing dominance of personal computers, desktop publishing, the introduction of low-cost, truly high-quality, laser and inkjet printer technologies, and the pervasive use of web publishing, e-mail and other electronic communication techniques have largely replaced typewriters in the United States. Still, as of 2009[ [update]], typewriters continued to be used by a number of government agencies and other institutions in the USA, where they are primarily used to fill preprinted forms. According to a Boston typewriter repairman quoted by "The Boston Globe", "Every maternity ward has a typewriter, as well as funeral homes".
A fairly major typewriter user is the City of New York, which in 2008 purchased several thousands typewriters, mostly for use by the New York Police Department, at the total cost of $982,269. Another $99,570 was spent in 2009 for the maintenance of the existing typewriters. New York police officers would use the machines to type property and evidence vouchers on carbon paper forms.
A rather specialized market for typewriters exists due to the regulations of many correctional systems in the USA, where prisoners are prohibited from having computers or telecommunication equipment, but are allowed to own typewriters. The Swintec corporation (headquartered in Moonachie, New Jersey), which, as of 2011, still produced typewriters at its overseas factories (in Japan, Indonesia, and/or Malaysia), manufactures a variety of typewriters for use in prisons, made of clear plastic (to make it harder for prisoners to hide prohibited items inside it). As of 2011, the company had contracts with prisons in 43 US states.
In April 2011, Godrej and Boyce, a Mumbai-based manufacturer of mechanical typewriters, closed its doors, leading to a flurry of erroneous news reports that the "world's last typewriter factory" had shut down. The reports were quickly debunked.
In November 2012, Brother's UK factory manufactured what it claimed to be the last typewriter ever made in the UK; the typewriter was donated to the London Science Museum.
Russian typewriters use Cyrillic, which has made the ongoing Azerbaijani reconversion from Cyrillic to Roman alphabet more difficult. In 1997, the government of Turkey offered to donate western typewriters to the Republic of Azerbaijan in exchange for more zealous and exclusive promotion of the Roman alphabet for the Azerbaijani language; this offer, however, was declined.
In Latin America and Africa, mechanical typewriters are still common because they can be used without electrical power. In Latin America, the typewriters used are most often Brazilian models – Brazil continues to produce mechanical (Facit) and electronic (Olivetti) typewriters to the present day.
Correction technologies.
According to the standards taught in secretarial schools in the mid-20th century, a business letter was supposed to have no mistakes and no visible corrections. Accuracy was prized as much as speed. Indeed, typing speeds, as scored in proficiency tests and typewriting speed competitions, included a deduction of ten words for every mistake. Corrections were, of course, necessary, and many methods were developed.
In practice, several methods would often be combined. For example, if six extra copies of a letter were needed, the fluid-corrected original would be photocopied, but only for the two recipients getting "c.c."s; the other four copies, the less-important file copies that stayed in various departments at the office, would be cheaper, hand-erased, less-distinct bond paper copies or even "flimsies" of different colors (tissue papers interleaved with black carbon paper) that were all typed as a "carbon pack" at the same time as the original.
In informal applications such as personal letters where low priority was placed on the appearance of the document, or conversely in highly formal applications in which it was important that any corrections be obvious, the backspace key could be used to back up over the error and then overstrike it with hyphens, slashes, Xs, or the like. 
Typewriter erasers.
The traditional erasing method involved the use of a special "typewriter eraser" made of hard rubber that contained an abrasive material. Some were thin, flat disks, pink or gray, approximately 2 in in diameter by ⅛ inch (3.2 mm) thick, with a brush attached from the center, while others looked like pink pencils, with a sharpenable eraser at the "lead" end and a stiff nylon brush at the other end. Either way, these tools made possible erasure of individual typed letters. Business letters were typed on heavyweight, high-rag-content bond paper, not merely to provide a luxurious appearance, but also to stand up to erasure. Typewriter eraser brushes were necessary for clearing eraser crumbs and paper dust, and using the brush properly was an important element of typewriting skill; if erasure detritus fell into the typewriter, a small buildup could cause the typebars to jam in their narrow supporting grooves.
Eraser shield.
Erasing a set of carbon copies was particularly difficult, and called for the use of a device called an "eraser shield" (a thin stainless-steel rectangle about 2 by with several tiny holes in it) to prevent the pressure of erasing on the upper copies from producing carbon smudges on the lower copies. To correct copies, typists had to go from carbon copy to carbon copy, trying not to get their fingers dirty as they leafed through the carbon papers, and moving and repositioning the eraser shield and eraser for each copy.
Erasable bond.
Paper companies produced a special form of typewriter paper called "erasable bond" (for example, Eaton's Corrasable Bond). This incorporated a thin layer of material that prevented ink from penetrating and was relatively soft and easy to remove from the page. An ordinary soft pencil eraser could quickly produce perfect erasures on this kind of paper. However, the same characteristics that made the paper erasable made the characters subject to smudging due to ordinary friction and deliberate alteration after the fact, making it unacceptable for business correspondence, contracts, or any archival use.
Correction fluid.
In the 1950s and 1960s, correction fluid made its appearance, under brand names such as Liquid Paper, Wite-Out and Tipp-Ex; it was invented by Bette Nesmith Graham. Correction fluid was a kind of opaque, white, fast-drying paint that produced a fresh white surface onto which, when dry, a correction could be retyped. However, when held to the light, the covered-up characters were visible, as was the patch of dry correction fluid (which was never perfectly flat, and never a perfect match for the color, texture, and luster of the surrounding paper). The standard trick for solving this problem was photocopying the corrected page, but this was possible only with high quality photocopiers. Not surprisingly, given the demand, photocopier quality improved quickly.
Dry correction.
Dry correction products (such as correction paper) under brand names such as "Ko-Rec-Type" were introduced in the 1970s and functioned like white carbon paper. A strip of the product was placed over the letters needing correction, and the incorrect letters were retyped, causing the black character to be overstruck with a white overcoat. Similar material was soon incorporated in carbon-film electric typewriter ribbons; like the traditional two-color black-and-red inked ribbon common on manual typewriters, a black and white correcting ribbon became commonplace on electric typewriters. But the black or white coating could be partly rubbed off with handling, so such corrections were generally not acceptable in legal documents.
The pinnacle of this kind of technology was the IBM Electronic Typewriter series. These machines, and similar products from other manufacturers, used a separate correction ribbon and a character memory. With a single keystroke, the typewriter was capable of automatically backspacing and then overstriking the previous characters with minimal marring of the paper. White cover-up ribbons were used with fabric ink ribbons, or an alternate premium design featured plastic lift-off correction ribbons which were used with carbon film typing ribbons. This latter technology actually lifted the carbon film forming a typed letter, leaving nothing more than a flattened depression in the surface of the paper, with the advantage that no color matching of the paper was needed.
Legacy.
Keyboard layouts.
QWERTY.
The 1874 Sholes & Glidden typewriters established the "QWERTY" layout for the letter keys. During the period in which Sholes and his colleagues were experimenting with this invention, other keyboard arrangements were apparently tried, but these are poorly documented. The QWERTY layout of keys has become the de facto standard for English-language typewriter and computer keyboards. Other languages written in the Latin alphabet sometimes use variants of the QWERTY layouts, such as the French AZERTY, the Italian QZERTY and the German QWERTZ layouts.
The QWERTY layout is not the most efficient layout possible for the English language, since it requires a touch-typist to move his or her fingers between rows to type the most common letters.
One popular but widely debunked explanation for the QWERTY arrangement is that it was designed to reduce the likelihood of internal clashing of typebars by placing commonly used combinations of letters farther from each other inside the machine. This allowed the user to type faster without jamming. In a mechanical typewriter, the arrangement of typebars is tied to the arrangement of the keys, and two adjacent bars are much more likely to clash if struck together or in a rapid sequence.
Another story is that the QWERTY layout allowed early typewriter salesmen to impress their customers by being able to easily type out the example word "typewriter" without having learned the full keyboard layout , because "typewriter" can be spelled purely on the top row of the keyboard. It's also the longest common English word that can be typed using purely the first row of keys; some longer English words exist but they are quite uncommon.
Other layouts.
A number of radically different layouts such as Dvorak have been proposed to reduce the perceived inefficiencies of QWERTY, but none have been able to displace the QWERTY layout; their proponents claim considerable advantages, but so far none has been widely used. The Blickensderfer typewriter with its DHIATENSOR layout may have possibly been the first attempt at optimizing the keyboard layout for efficiency advantages.
Many non-Latin alphabets have keyboard layouts that have nothing to do with QWERTY. The Russian layout, for instance, puts the common trigrams ыва, про, and ить on adjacent keys so that they can be typed by rolling the fingers. The Greek layout, on the other hand, is a variant of QWERTY.
Typewriters were also made for East Asian languages with thousands of characters, such as Chinese or Japanese. They were not easy to operate, but professional typists used them for a long time until the development of electronic word processors and laser printers in the 1980s. See the "Gallery" at the end of this article for pictures of East Asian mechanical typewriters.
On modern keyboards, the exclamation point is the shifted character on the 1 key, a direct result of the historical fact that these were the last characters to become "standard" on keyboards. Holding the spacebar pressed down usually suspended the carriage advance mechanism (a so-called "dead key" feature), allowing one to superimpose multiple keystrikes on a single location. The ¢ symbol (meaning cents) was located above the number 6 on electric typewriters, while ASCII computer keyboards have ^ instead.
Typewriter conventions.
A number of typographical conventions originate from the widespread use of the typewriter, based on the characteristics and limitations of the typewriter itself. For example, the QWERTY keyboard typewriter did not include keys for the en dash and the em dash. To overcome this limitation, users typically typed more than one adjacent hyphen to approximate these symbols. This typewriter convention is still sometimes used today, even though modern computer word processing applications can input the correct en and em dashes for each font type. Other examples of typewriter practices that are sometimes still used in desktop publishing systems include inserting a double space at the end of a sentence, and the use of straight quotes (or "dumb quotes") as quotation marks and prime marks. The practice of underlining text in place of italics and the use of all capitals to provide emphasis are additional examples of typographical conventions that derived from the limitations of the typewriter keyboard that still carry on today.
Many older typewriters did not include a separate key for the numeral 1 or the exclamation point, and some even older ones also lacked the numeral zero. Typists who trained on these machines learned the habit of using the lowercase letter l ("ell") for the digit 1, and the uppercase O for the zero. A cents symbol (¢) was created by combining (over-striking) a lower case 'c' with a slash character (typing 'c', then backspace, then '/'). Similarly, the exclamation point was created by combining an apostrophe and a period. These characters were omitted to simplify design and reduce manufacturing and maintenance costs; they were chosen specifically because they were "redundant" and could be recreated using other keys.
Computer jargon.
Some terminology from the typewriter age has survived into the personal computer era. Examples include:
In the above listing, the two-letter codes in parentheses are abbreviations for the ASCII characters derived from typewriter usage.
Early social effects.
When Remington started marketing typewriters, the company assumed the machine would not be used for composing but for transcribing dictation, and that the person typing would be a woman. The 1800s Sholes and Glidden typewriter had floral ornamentation on the case.
Women's roles in the World Wars, both One and Two, put more women into the workforce replacing men. In the United States, women often started in the professional workplace as typists. Questions about morals made a salacious businessman making sexual advances to a female typist into a cliché of office life, appearing in vaudeville and movies. .
The "Tijuana bibles" — adult comic books produced in Mexico for the American market, starting in the 1930s — often featured women typists. In one panel, a businessman in a three-piece suit, ogling his secretary’s thigh, says, "Miss Higby, are you ready for—ahem!—er—dictation?"
Forensic examination.
Typewritten documents may be examined by forensic document examiners. This is done primarily to determine 1) the make and/or model of the typewriter used to produce a document, or 2) whether or not a particular suspect typewriter might have been used to produce a document. In some situations, an ink or correction ribbon may also be examined.
The determination of a make and/or model of typewriter is a 'classification' problem and several systems have been developed for this purpose. These include the original Haas Typewriter Atlases (Pica version) and (Non-Pica version) and the TYPE system developed by Dr. Philip Bouffard, the Royal Canadian Mounted Police's Termatrex Typewriter classification system, and the Interpol's Typewriter classification system, among others.
Because of the tolerances of the mechanical parts, slight variation in the alignment of the letters and their uneven wear, each typewriter has an individual "signature" or "fingerprint", which may permit a typewritten document to be traced back to the typewriter on which it was produced. For devices utilizing replaceable components, such as a typeball element, any association may be restricted to a specific element, rather than to the typewriter as a whole.
The earliest reference in fictional literature to the potential identification of a typewriter as having produced a document was by Sir Arthur Conan Doyle who wrote "A Case of Identity" in 1891. In non-fiction, the first document examiner to describe how a typewriter might be identified was William E. Hagan who wrote, in 1894, "All typewriter machines, even when using the same kind of type, become more or less peculiar by use as to the work done by them". Other early discussions of the topic were provided by A. S. Osborn in his 1908 treatise, "Typewriting as Evidence", and again in his 1929 textbook, "Questioned Documents". A modern description of the examination procedure is laid out in ASTM Standard E2494-08 (Standard Guide for Examination of Typewritten Items).
Typewriter examination was used in the Leopold and Loeb and Alger Hiss cases. In the Eastern Bloc, typewriters (together with printing presses, copy machines, and later computer printers) were a controlled technology, with secret police in charge of maintaining files of the typewriters and their owners. In the Soviet Union, the First Department of each organization sent data on organization's typewriters to the KGB. This posed a significant risk for dissidents and samizdat authors. In Romania, according to State Council Decree No. 98 of March 28, 1983, owning a typewriter, both by businesses or by private persons, was subject to an approval given by the local police authorities. People previously convicted of any crime or those who because of their behaviour were considered to be "a danger to public order or to the security of the state" were refused approval. In addition, once a year, typewriter owners had to take the typewriter to the local police station, where they would be asked to type down a sample of all the typewriter's characters. It was also forbidden to borrow, lend, or repair typewriters other than at the places that had been authorized by the police.
The ribbon can be read vertically, although only if it has not been typed over more than once. This can be very hard to do as it does not include spaces, but can be done, giving even a typewriter a "memory".

</doc>
<doc id="44366" url="http://en.wikipedia.org/wiki?curid=44366" title="Where the Heart Is (2000 film)">
Where the Heart Is (2000 film)

Where the Heart Is is a 2000 drama/romance film directed by Matt Williams, in his film directing debut. The movie stars Natalie Portman, Stockard Channing, Ashley Judd, and Joan Cusack with supporting roles done by James Frain, Dylan Bruno, Keith David, and Sally Field. The screenplay, written by Lowell Ganz and Babaloo Mandel, is based on the best-selling novel by Billie Letts which is based on the story of Julian Tempelsman, who was born in Costco.
The film follows five years in the life Novalee Nation, a pregnant 17-year-old who is abandoned by her boyfriend at a Wal-Mart in a small Oklahoma town. She secretly moves into the Wal-Mart store where she eventually gives birth to her baby, which attracts media attention. With the help of friends, she makes a new life for herself in the town.
Plot.
At seventeen years old and seven months pregnant, Novalee Nation (Natalie Portman) sets off on a road trip from Tennessee to California with her ignorant, trailer trash boyfriend, Willy Jack Pickens (Dylan Bruno). His car is a dilapidated 1963 Plymouth with a leaking fuel line and no floor, which he bought for $80. While driving through Sequoyah, Oklahoma, Willy Jack wakes up Novalee due to her snoring and then asks where shoes are upon seeing that she's barefoot due to them falling out of the hole in the car upon removal due to her feet being swollen (a side effect of pregnancy). Novalee then asks Willy to stop at the local Wal-Mart so that she can go to the bathroom and buy some replacement shoes. When Novalee reaches out for her change at the checkout, the sum of $5.55 sends her into a panic as she believes that the number 5 is a bad omen. She runs barefoot outside to discover that Willy has taken off without her.
Returning to the store upon trying on the flip flops she bought, Novalee meets Thelma "Sister" Husband (Stockard Channing), a woman who runs the Welcome Wagon in town. Novalee also meets a photographer named Moses Whitecotton (Keith David) who advises her to give her baby a strong name. Later that evening, Novalee feels sick and runs into the bathroom again to vomit. When she comes out again, she discovers that the store is closed. She soon figures out how to live undetected in the Wal-Mart.
Willy Jack Pickens gets into trouble with the law for helping a 14-year-old girl named Jolene (Alicia Godwin) who did some looting and he is arrested. When in jail, he ends up as a cellmate of Tommy Reynolds (David Alvarado), and Willy Jack composes a country song.
Novalee manages to live at the store for several weeks. Novalee visits the library and meets Forney Hull (James Frain) who looks after his librarian sister Mary Elizabeth (Margaret Hoard) whose health has been ruined by alcoholism. Novalee visits Sister Husband where she agrees to let Novalee grow the Buck Eye Tree that she gave Novalee in her yard.
Novalee wakes up during a thunderstorm when she starts feeling pain in her abdomen. Her water breaks leaving puddles at her bare feet. While attempting to mop it up, she goes into labor. As she collapses, she notices that she is in Aisle 5 so she makes a big effort to move to the next aisle. At this moment, Forney (who saw her go into the store at closing time) jumps through a plate-glass window and helps deliver her baby offscreen.
Novalee wakes up in the hospital to find she is a media celebrity for giving birth in a Wal-Mart. She befriends her nurse Lexie Coop (Ashley Judd) and tells her that her daughter's name will be Americus. Lexie reveals that she is a single woman with four children by three different men. Novalee's mother Mama Lil (Sally Field), who abandoned her as a child, has seen her on television and appears at the hospital. Her mother says the two women can get an apartment together, takes the $500 that Novalee received as a gift from the President of Wal-Mart, and agrees to pick up Novalee and Americus the next morning. Her mother never shows up and Sister Husband comes to pick up Novalee and offers to let Novalee and the baby live at her house.
Novalee enjoys her life at Sister Husband's, becomes friends with Forney, and works at Wal-Mart. One night, while Novalee and Forney are getting Christmas trees, Forney remarks that Americus is 5 months old that day. Novalee is greatly superstitious about the number 5, connecting it to a series of unfortunate incidents in her life. She panics and rushes home, to find out that Americus has been kidnapped. Novalee remembers that, in the hospital, she received a card from Mississippi saying her baby was an abomination under God because she was born out of wedlock. The police quickly apprehend a vehicle with Mississippi plates and Americus is found safe in a nativity scene outside a church.
Upon being released from prison, Willy Jack becomes a country singer after signing on with music agent Ruth Meyers (Joan Cusack). It takes awhile for him to get a song on the radio.
Three years pass, and Novalee begins a career as a photographer with the help of Moses. When a tornado blows through Sequoyah, Sister Husband is killed and their home is destroyed. After the funeral, one of Sister Husband's friends from AA informs Novalee that she is the beneficiary of Sister's estate. Novalee builds a new home for herself and Americus on Sister's land.
Willy has a brief look at Novalee when she is in Las Vegas to accept her award for her picture of Americus after the tornado. After a recent performance, Willy is confronted at his hotel room by Ruth who tells him that Tommy Reynolds is suing him for taking credit for a song that the cellmate "claimed to have written" and declares that their deal is off.
One day, Novalee receives a call from Lexie's oldest child. She rushes over to find Lexie bruised and battered. Lexie tells Novalee that her latest boyfriend had gone to her house and tried to molest her two oldest children, when Lexie returned home from work early and caught him. Lexie later dates a local exterminator named Ernie (Bob Coonrad) whom she does not like at first, but later falls in love with after learning that he gave his ex-wife his restored 1967 Chevy Camaro in exchange for custody of his step-daughter whom he adopted as his own daughter. They get married, and Lexie tells Novalee that she's pregnant at the reception.
When Forney’s sister passes away and he does not appear at the funeral, Novalee finds him in a hotel and comforts him. After they sleep together, Forney says he loves her and wants to get a factory job and stay with her. Novalee lies and says she does not love him, which frees him to return to Bowdoin College in Maine.
After some drinking upon returning to Sequoyah, Willy Jack hallucinates near a train station and falls backwards onto the train tracks as a train is approaching.
On Americus's 5th birthday, Novalee picks up a newspaper and reads a story about a double amputee being robbed of his wheelchair. The man proves to be Willy Jack. Novalee visits Willy Jack in the hospital and tells him about what happened to her. Willy Jack admits that he lied to her when he told her that he didn't feel their baby's heartbeat the day he left her behind at Wal-Mart five years earlier. Willy Jack says he wishes he could go back and undo the lie, because of how one lie can change your whole life. Willy Jack explains that people lie because they're "scared, crazy, or just mean".
Novalee realizes that she made a similar mistake in lying to Forney. She drives Willy Jack home to Tennessee and then continues to Maine to find Forney at college. Novalee admits to him that she lied and that she really loves him and they return to Oklahoma to get married in their Wal-Mart.
Differences between novel and film.
There are some parts in the film that are different from the novel:
Music.
Original music for the film was produced by Mason Daring. A soundtrack of the original music was released by RCA Records, as well as a music compilation soundtrack featuring songs used in the film by artists such as Emmylou Harris, Lyle Lovett, Martina McBride, and John Hiatt.
The song "That's the Beat of a Heart" was performed by The Warren Brothers and Sara Evans. A music video was made for the song, which is included as a bonus extra on the DVD release, and features a number of scenes from the film.
Reception.
The film received mostly negative reviews, and holds a score of 30 (out of 100) on Metacritic and a 35% approval rating on Rotten Tomatoes, with the general consensus that the film's "poor script and messy plot undermines the decent cast."
The film opened in theaters in the United States on April 28, 2000. "Where the Heart Is" accumulated (USD)$8,292,939 in its opening weekend, opening at number 4.
The film went on to make $33,772,838 at the North American box office, and an additional $7,090,880 internationally for a worldwide total of $40,863,718.

</doc>
<doc id="44368" url="http://en.wikipedia.org/wiki?curid=44368" title="Transom">
Transom

Transom may refer to:

</doc>
<doc id="44369" url="http://en.wikipedia.org/wiki?curid=44369" title="Treble">
Treble

Treble may refer to:
In music:
In other uses:

</doc>
<doc id="44370" url="http://en.wikipedia.org/wiki?curid=44370" title="Trefoil">
Trefoil

Trefoil (from Latin "trifolium", "three-leaved plant", French "trèfle", Italian "trifoglio", German "Dreiblatt" and "Dreiblattbogen", Dutch "klaver" same as clubs) is a graphic form composed of the outline of three overlapping rings used in architecture and Christian symbolism. The term is also applied to other symbols of three-fold shape.
Architecture.
Ornamentation.
Trefoil is a term in Gothic architecture given to the ornamental foliation or cusping introduced in the heads of window-lights, tracery, panellings, etc., in which the center takes the form of a three-lobed leaf (formed from three partially overlapping circles). One of the earliest examples is in the plate tracery at Winchester (1222–1235). The fourfold version of an architectural trefoil is a quatrefoil.
A simple trefoil shape in itself can be symbolic of the Trinity, while a trefoil combined with an equilateral triangle was also a moderately common symbol of the Christian Trinity during the late Middle Ages in some parts of Europe. Two forms of this are shown below:
A dove, symbolic of the Holy Spirit, is sometimes depicted within the outlined form of the trefoil combined with a triangle.
Architectural layout.
In architecture and archaeology, trefoil describes a layout or floorplan consisting of three apses in clover-leaf shape, as for example in the Megalithic temples of Malta.
Particularly in church architecture, such a layout may be called a "triconchos".
Heraldry.
The heraldic "trefoil" is a stylized clover. It should not be confused with the figure named in French heraldry "tiercefeuille", which is a stylized flower with three petals. It differs from the heraldic trefoil in being not slipped. It could be translated as "threefoil".
Symbols.
Symmetrical Trefoils are particularly popular as warning symbols. If a box containing hazardous material is moved around and shifted into different positions, it is still easy to recognize the symbol. Easily stenciled symbols are also favored.
While the green trefoil is considered by many to be the symbol of Ireland, the harp has much greater officially recognized status. Therefore shamrocks generally do not appear on Irish coins or postage stamps.
A trefoil is also part of the logo for Adidas Originals, which also includes three stripes.

</doc>
<doc id="44371" url="http://en.wikipedia.org/wiki?curid=44371" title="Triton (moon)">
Triton (moon)

Triton is the largest moon of the planet Neptune, discovered on October 10, 1846, by English astronomer William Lassell. It is the only large moon in the Solar System with a retrograde orbit, which is an orbit in the opposite direction to its planet's rotation. At 2700 km in diameter, it is the seventh-largest moon in the Solar System. Because of its retrograde orbit and composition similar to Pluto's, Triton is thought to have been captured from the Kuiper belt. Triton has a surface of mostly frozen nitrogen, a mostly water ice crust, an icy mantle and a substantial core of rock and metal. The core makes up two-thirds of its total mass. Triton has a mean density of 2.061 g/cm3 and is composed of approximately 15–35% water ice.
Triton is one of the few moons in the Solar System known to be geologically active. As a consequence, its surface is relatively young, with a complex geological history revealed in intricate cryovolcanic and tectonic terrains. Part of its crust is dotted with geysers thought to erupt nitrogen. Triton has a tenuous nitrogen atmosphere less than 1/70,000 the pressure of Earth's atmosphere at sea level.
Discovery and naming.
Triton was discovered by British astronomer William Lassell on October 10, 1846, just 17 days after the discovery of Neptune.
A brewer by trade, Lassell began making mirrors for his amateur telescope in 1820. When John Herschel received news of Neptune's discovery, he wrote to Lassell suggesting he search for possible moons. Lassell did so and discovered Triton eight days later. Lassell also claimed to have discovered rings. Although Neptune was later confirmed to have rings, they are so faint and dark that it is doubtful that he actually saw them.
Triton is named after the Greek sea god Triton (Τρίτων), the son of Poseidon (the Greek god comparable to the Roman Neptune). The name was first proposed by Camille Flammarion in his 1880 book "Astronomie Populaire", although it was not officially adopted until many decades later. Until the discovery of the second moon Nereid in 1949, Triton was commonly known as simply "the satellite of Neptune". Lassell did not name his own discovery, although he suggested names a few years after his subsequent discovery of an eighth moon of Saturn (Hyperion).
Orbit and rotation.
Triton is unique among all large moons in the Solar System for its retrograde orbit around its planet ("i.e.", it orbits in a direction opposite to the planet's rotation). Most of the outer irregular moons of Jupiter and Saturn also have retrograde orbits, as do some of Uranus's outer moons. However, these moons are all much more distant from their primaries, and are small in comparison; the largest of them (Phoebe) has only 8% of the diameter (and 0.03% of the mass) of Triton.
Triton's orbit is associated with two tilts, the inclination of Neptune's spin to Neptune's orbit, 30°, and the inclination of Triton's orbit to Neptune's spin, 157° (an inclination over 90° indicates retrograde motion). Triton's orbit precesses forward relative to Neptune's spin with a period of about 678 Earth years (4.1 Neptunian years), making its Neptune-orbit-relative inclination vary between 127° and 180° and past, to 173°. That inclination is currently 130°; Triton's orbit is now near its maximum departure from coplanarity with Neptune's.
Triton is in synchronous rotation with Neptune; it keeps one face oriented toward the planet at all times. Its equator is almost exactly aligned with its orbital plane. At the present time, Triton's rotational axis is about 40° from Neptune's orbital plane, and hence at some point during Neptune's year each pole points fairly close to the Sun, almost like the poles of Uranus. As Neptune orbits the Sun, Triton's polar regions take turns facing the Sun, resulting in seasonal changes as one pole, then the other, moves into the sunlight. Such changes have recently been observed.
Triton's revolution around Neptune has become a nearly perfect circle with an eccentricity of almost zero. Viscoelastic damping from tides alone is not thought to be capable of circularizing Triton's orbit in the time since the origin of the system, and gas drag from a prograde debris disc is likely to have played a substantial role. Tidal interactions also cause Triton's orbit, which is already closer to Neptune than the Moon's is to Earth, to gradually decay further; predictions are that some 3.6 billion years from now, Triton will pass within Neptune's Roche limit. This will result in either a collision with Neptune's atmosphere or the breakup of Triton, forming a ring system similar to that found around Saturn.
Capture.
Moons in retrograde orbits cannot form out of the same region of the solar nebula as the planets they orbit, so Triton must have been captured from elsewhere. It might therefore have originated in the Kuiper belt, a ring of small icy objects extending outwards from just inside the orbit of Neptune to about 50 AU from the Sun. Thought to be the point of origin for the majority of short-period comets observed from Earth, the belt is also home to several large, planet-like bodies including Pluto, which is now recognized as the largest in a population of Kuiper belt objects (the plutinos) locked in orbital step with Neptune. Triton is only slightly larger than Pluto and nearly identical in composition, which has led to the hypothesis that the two share a common origin.
The proposed capture of Triton may explain several features of the Neptunian system, including the extremely eccentric orbit of Neptune's moon Nereid and the scarcity of moons as compared to the other gas giants. Triton's initially eccentric orbit would have intersected orbits of irregular moons and disrupted those of smaller regular moons, dispersing them through gravitational interactions.
Triton's eccentric post-capture orbit would have also resulted in tidal heating of its interior, which would have kept Triton liquid for a billion years; this inference is supported by evidence of differentiation in Triton's interior. This source of internal heat disappeared following circularization of the orbit.
Two types of mechanisms have been proposed for Triton's capture. To be gravitationally captured by a planet, a passing body must lose sufficient energy to be slowed down to a speed less than that required to escape. An early theory of how Triton may have been slowed was by collision with another object, either one that happened to be passing by Neptune (which is unlikely), or a moon or proto-moon in orbit around Neptune (which is more likely). A more recent hypothesis suggests that, before its capture, Triton was part of a binary system. When this binary encountered Neptune, it interacted in such a way that the binary dissociated, with one portion of the binary expelled, and the other, Triton, becoming bound to Neptune. This event is more likely for more massive companions. Similar mechanisms have been proposed for the capture of Mars's moons. This hypothesis is supported by several lines of evidence, including binaries being very common among the large Kuiper belt objects. The event was brief but gentle, saving Triton from collisional disruption. Events like this may have been common during the formation of Neptune, or later when it migrated outward.
Physical characteristics.
Triton is the seventh largest moon and sixteenth largest object in the Solar System, and is modestly larger than the dwarf planets Pluto and Eris. It comprises more than 99.5% of all the mass known to orbit Neptune, including the planet's rings and thirteen other known moons, and is also more massive than all known moons in the Solar System smaller than itself combined. It has a radius, density (2.061 g/cm3), temperature and chemical composition similar to those of Pluto.
As with Pluto, 55% of Triton's surface is covered with frozen nitrogen, with water ice comprising 15–35% and dry ice (frozen carbon dioxide) forming the remaining 10–20%. Trace ices include 0.1% methane and 0.05% carbon monoxide. There could also be ammonia on the surface if ammonia dihydrate is present as suspected in the lithosphere. Triton's density implies it is probably about 30–45% water ice, with the remainder being rocky material. Triton's surface area is 23 million km2, which is 4.5% of Earth, or 15.5% of Earth's land area. Triton has a considerably high albedo, reflecting 60–95% of the sunlight that reaches it. By comparison, the Moon reflects only 11%. Triton's reddish colour is thought to be the result of methane ice, which is converted to tholins under bombardment from ultraviolet radiation.
Because Triton's surface indicates a long history of melting, models of its interior posit that Triton is differentiated, like Earth, into a solid core, a mantle and a crust. Water, the most abundant volatile in the Solar System, comprises Triton's mantle, which lies over a core of rock and metal. There is enough rock in Triton's interior for radioactive decay to power convection in the mantle. The heat may even be sufficient to maintain a subterranean ocean similar to that which is hypothesized to exist underneath the surface of Europa. If present, a layer of liquid water would suggest the possibility of life.
Atmosphere.
Triton has a tenuous nitrogen atmosphere, with trace amounts of carbon monoxide and small amounts of methane near the surface. Like Pluto's atmosphere, the atmosphere of Triton is thought to have resulted from evaporation of nitrogen from its surface. The surface temperature is at least () because Triton's nitrogen ice is in the warmer, hexagonal crystalline state, and the phase transition between hexagonal and cubic nitrogen ice occurs at that temperature. An upper limit in the low 40s (K) can be set from vapor pressure equilibrium with nitrogen gas in Triton's atmosphere. This temperature range is colder than Pluto's average equilibrium temperature of (). Triton's surface atmospheric pressure is only about 1.4– (0.014–).
Turbulence at Triton's surface creates a troposphere (a "weather region") rising to an altitude of 8 km. Streaks on Triton's surface left by geyser plumes suggest that the troposphere is driven by seasonal winds capable of moving material of over a micrometre in size. Unlike other atmospheres, Triton's lacks a stratosphere, and instead has a thermosphere from altitudes of 8 to 950 km, and an exosphere above that. The temperature of Triton's upper atmosphere, at , is higher than that at the surface, due to heat absorbed from solar radiation and Neptune's magnetosphere. A haze permeates most of Triton's troposphere, thought to be composed largely of hydrocarbons and nitriles created by the action of sunlight on methane. Triton's atmosphere also possesses clouds of condensed nitrogen that lie between 1 and 3 km from the surface.
In 1997, observations from Earth were made of Triton's limb as it passed in front of stars. These observations indicated the presence of a denser atmosphere than was deduced from "Voyager 2" data. Other observations have shown an increase in temperature by 5% from 1989 to 1998. These observations indicate Triton is approaching an unusually warm summer season that happens only once every few hundred years. Theories for this warming include a change of frost patterns on Triton's surface and a change in ice albedo, which would allow more heat to be absorbed. Another theory argues the changes in temperature are a result of deposition of dark, red material from geological processes. Because Triton's Bond albedo is among the highest within the Solar System, it is sensitive to small variations in spectral albedo.
Surface features.
All detailed knowledge of the surface of Triton was acquired in a single encounter by the "Voyager 2" spacecraft in 1989. The 40% of Triton's surface imaged by "Voyager" revealed blocky outcrops, ridges, troughs, furrows, hollows, plateaus, icy plains and few craters. Triton is relatively flat; its observed topography never varies beyond a kilometer. There are relatively few impact craters on Triton. Recent analysis of crater density and distribution has suggested that in geological terms, Triton's surface is extremely young, with regions varying from an estimated 50 million years old to just an estimated 6 million years old.
Cryovolcanism.
Triton is geologically active; its surface is young and has relatively few impact craters. Although Triton is made of various ices, its subsurface processes are similar to those that produce volcanoes and rift valleys on Earth, but with water and ammonia lavas as opposed to liquid rock. Triton's entire surface is cut by complex valleys and ridges, probably the result of tectonics and icy volcanism. The vast majority of surface features on Triton are endogenic—the result of internal geological processes rather than external processes such as impacts. Most are volcanic and extrusive in nature, rather than tectonic.
The "Voyager 2" probe observed a handful of geyser-like eruptions of invisible nitrogen gas and entrained dust from beneath the surface of Triton in plumes up to 8 km high. Triton is thus, along with Earth, Io, and Enceladus, one of the few bodies in the Solar System on which active eruptions of some sort have been observed. (Venus, Mars, Europa, Titan, and Dione may also be volcanically active.) The best-observed examples were named Hili and Mahilani (after a Zulu water sprite and a Tongan sea spirit, respectively).
All the geysers observed were located between 50° and 57°S, the part of Triton's surface close to the subsolar point. This indicates that solar heating, although very weak at Triton's great distance from the Sun, plays a crucial role. It is thought that the surface of Triton probably consists of a translucent layer of frozen nitrogen overlying a darker substrate, which creates a kind of "solid greenhouse effect". Solar radiation passes through the surface ice, slowly heating and vaporizing subsurface nitrogen until enough gas pressure accumulates for it to erupt through the crust. A temperature increase of just 4 K above the ambient surface temperature of 37 K could drive eruptions to the heights observed. Although commonly termed "cryovolcanic", this nitrogen plume activity is distinct from Triton's larger scale cryovolcanic eruptions, as well as volcanic processes on other worlds, which are powered by the internal heat of the body in question. Analogous plumes of gaseous CO2 are thought to erupt from the south polar cap of Mars each spring.
Each eruption of a Triton geyser may last up to a year, driven by the sublimation of about 100 e6m3 of nitrogen ice over this interval; dust entrained may be deposited up to 150 km downwind in visible streaks, and perhaps much farther in more diffuse deposits. Voyager's images of Triton's southern hemisphere show many such streaks of dark material. Between 1977 and the "Voyager" flyby in 1989, Triton shifted from a reddish colour, similar to Pluto, to a far paler hue, suggesting that in the intervening decade lighter nitrogen frosts had covered older reddish material. The eruption of volatiles from Triton's equator and their deposition at the poles may redistribute enough mass over the course of 10,000 years to cause polar wander.
Polar cap, plains and ridges.
Triton's south polar region is covered by a highly reflective cap of frozen nitrogen and methane sprinkled by impact craters and openings of geysers. Little is known about the north pole because it was on the night side during the "Voyager 2" encounter. However, it is thought that Triton must also have a north polar ice cap.
The high plains found on Triton's eastern hemisphere, such as Cipango Planum, cover over and blot out older features, and are therefore almost certainly the result of icy lava washing over the previous landscape. The plains are dotted with pits, such as Leviathan Patera, which are probably the vents from which this lava emerged. The composition of the lava is unknown, although a mixture of ammonia and water is suspected.
Four roughly circular "walled plains" have been identified on Triton. They are the flattest regions so far discovered, with a variance in altitude of less than 200 m. They are thought to have formed from eruption of icy lava. The plains near Triton's eastern limb are dotted with black spots, the "maculae". Some maculae are simple dark spots with diffuse boundaries, and other comprise a dark central patch surrounded by a white halo with sharp boundaries. Typical diameter of maculae is about 100 km and width of halo is between 20 and 30 km. Some speculate the maculae are outliers of the south polar cap, which retreats in summer.
There are extensive ridges and valleys in complex patterns across Triton's surface, probably the result of freeze–thaw cycles. Many also appear to be tectonic in nature and may result from extension or strike-slip faulting. There are long double ridges of ice with central troughs bearing a strong resemblance to Europan lineae (although they have a larger scale), and which may have a similar origin, possibly shear heating from strike-slip motion along faults caused by diurnal tidal stresses experienced before Triton's orbit was fully circularized. These faults with parallel ridges expelled from the interior cross complex terrain with valleys in the equatorial region. The ridges and furrows, or "sulci," such as Yasu Sulci, Ho Sulci, and Lo Sulci, are thought to be of intermediate age in Triton's geological history, and in many cases to have formed concurrently. They tend to be clustered in groups or "packets".
Cantaloupe terrain.
Triton's western hemisphere consists of a strange series of fissures and depressions known as "cantaloupe terrain" because of its resemblance to the skin of a cantaloupe melon. Although it has few craters, it is thought that this is the oldest terrain on Triton. It probably covers much of Triton's western half.
Cantaloupe terrain, which is mostly dirty water ice, is known to exist only on Triton. It contains depressions 30–40 km in diameter. The depressions ("cavi") are probably not impact craters because they are all of similar size and have smooth curves. The leading hypothesis for their formation is diapirism, the rising of "lumps" of less dense material through a stratum of denser material. Alternative hypotheses include formation by collapses, or by flooding caused by cryovolcanism.
Impact craters.
Due to constant erasure and modification by ongoing geological activity, impact craters on Triton's surface are relatively rare. A census of Triton's craters imaged by "Voyager 2" found only 179 that were incontestably of impact origin, compared with 835 observed for Uranus's moon Miranda, which has only three percent of Triton's surface area. The largest crater observed on Triton thought to have been created by an impact is a 27 km-diameter feature called Mazomba. Although larger craters have been observed, they are generally thought to be volcanic in nature.
The few impact craters on Triton are almost all concentrated in the leading hemisphere—that facing the direction of the orbital motion—with the majority concentrated around the equator between 30° and 70° longitude, resulting from material swept up from orbit around Neptune. Because it orbits with one side permanently facing the planet, astronomers expect that Triton should have fewer impacts on its trailing hemisphere, due to impacts on the leading hemisphere being more frequent and more violent. However, because "Voyager 2" imaged only 40% of Triton's surface, this remains uncertain.
Observation and exploration.
The orbital properties of Triton had been defined with high accuracy in the 19th century. It was found to have a retrograde orbit, at a very high angle of inclination to the plane of Neptune's orbit. The first detailed observations of Triton were not made until 1930. Little was known about the satellite until "Voyager 2" arrived at the end of the 20th century.
Before the arrival of "Voyager 2", astronomers suspected that Triton might have liquid nitrogen seas and a nitrogen/methane atmosphere with a density as much as 30% that of Earth. Like the famous overestimates of the atmospheric density of Mars, this was completely false. As with Mars, a denser atmosphere is postulated for its early history.
The first attempt to measure the diameter of Triton was made by Gerard Kuiper in 1954. He obtained a value of 3,800 km. Subsequent measurement attempts arrived at values ranging from 2,500 to 6,000 km, or from slightly smaller than our Moon to nearly half the diameter of Earth. Data from the approach of "Voyager 2" to Neptune on August 25, 1989, led to a more accurate estimate of Triton's diameter (2,706 km).
In the 1990s, various observations from Earth were made of the limb of Triton using the occultation of nearby stars, which indicated the presence of an atmosphere and an exotic surface. The observations suggest that the atmosphere is denser than the Voyager 2 measurements had indicated.
New concepts for missions to the Neptune system to be conducted in the 2010s have been brought forward by NASA scientists on numerous occasions over the last decades. All of them identified Triton as being a prime target and a separate Triton lander comparable to the Huygens probe for Titan was frequently included in those plans. No efforts aimed at Neptune and Triton went beyond the proposal phase and NASA's funding on missions to the outer Solar System is currently focused on the Jupiter and Saturn systems.
References.
 at WebCite
</ref>

</doc>
<doc id="44372" url="http://en.wikipedia.org/wiki?curid=44372" title="Sermon on the Mount">
Sermon on the Mount

The Sermon on the Mount (anglicized from the Matthean Vulgate Latin section title: "Sermo in monte") is a collection of sayings and teachings of Jesus, which emphasizes his moral teaching found in the Gospel of Matthew (chapters 5, 6 and 7). It is the first of the Five Discourses of Matthew and takes place relatively early in the Ministry of Jesus after he has been baptized by John the Baptist and preached in Galilee.
The Sermon is the longest piece of teaching from Jesus in the New Testament, and has been one of the most widely quoted elements of the Canonical Gospels.
It includes some of the best known teachings of Jesus, such as the Beatitudes, and the widely recited Lord's Prayer. To most believers in Jesus, the Sermon on the Mount contains the central tenets of Christian discipleship.
The is considered to be a focal point that summarizes the teaching of the sermon: "be perfect, as your heavenly Father is perfect", advising his disciples and followers to seek the path towards perfection and the Kingdom of Heaven.
Background and setting.
The Sermon on the Mount is the longest piece of teaching from Jesus in the New Testament, and occupies chapters 5, 6 and 7 of the Gospel of Matthew. The Sermon has been one of the most widely quoted elements of the Canonical Gospels. To most believers in Jesus, the Sermon contains the central tenets of Christian discipleship.
This is the first of the "Five Discourses of Matthew", the other four being Matthew 10, Matthew 13 (1–53), Matthew 18 and the Olivet discourse in Matthew 24.
The Sermon takes place early in the Ministry of Jesus, after he has been baptized by John the Baptist in chapter 3 of Matthew and gathered his first disciples in chapter 4.
Before this episode, Jesus had been "all about Galilee" preaching, as in , and "great crowds followed him" from all around the area. The setting for the sermon is given in -. Jesus sees the multitudes, goes up into the mountain, is followed by his disciples, and begins to preach.
Components.
While the issue of the exact theological structure and composition of the Sermon on the Mount is subject to debate among scholars, specific components within it, each associated with particular teachings, can be identified.
 discusses the Beatitudes. These describe the character of the people of the Kingdom of Heaven, expressed as "blessings". The Greek word most versions of the Gospel render as "blessed," can also be translated "happy". (See of Young's Literal Translation for an example.) In Matthew, there are eight (or nine) blessings, while in Luke there are four, followed by four woes.
In almost all cases the phrases used in the Beatitudes are familiar from an Old Testament context, but in the sermon Jesus gives them new teachings. Together, the Beatitudes present a new set of ideals that focus on love and humility rather than force and exaction; they echo the highest ideals of Jesus' teachings on spirituality and compassion.
In Christian teachings, the Works of Mercy, which have corporal and spiritual components, have resonated with the theme of the Beatitude for mercy. These teachings emphasize that these acts of mercy provide both temporal and spiritual benefits.
 presents the metaphors of Salt and Light. This completes the profile of God's people presented in the beatitudes, and acts as the introduction to the next section.
There are two parts in this section, using the terms "salt of the earth" and Light of the World to refer to the disciples – implying their value. Elsewhere, in , Jesus applies "Light of the World" to himself.
Jesus preaches about hell and what hell is like:
"But I say unto you, That whosoever is angry with his brother without a cause shall be in danger of the judgment: and whosoever shall say to his brother, Raca, shall be in danger of the council: but whosoever shall say, Thou fool, shall be in danger of hell fire." Matthew 5:22 KJV 
The longest discourse in the Sermon is , traditionally referred to as "the Antitheses" or "Matthew's Antitheses" though Gundry disputes that title. In the discourse Jesus fulfills and reinterprets the Old Covenant and in particular its Ten Commandments, contrasting with what "you have heard" from others, e.g. turning the other cheek compared to taking an eye for an eye. According to most interpretations of , , , and , and most Christian views of the Old Covenant, these new interpretations of the Law and Prophets are not opposed to the Old Testament, which was the position of Marcion, but form Jesus' new teachings which bring about salvation, and hence must be adhered to, as emphasized in towards the end of the sermon.
In Matthew 6 Jesus condemns doing what would normally be "good works" simply for recognition and not from the heart, such as those of alms (6:1–4), prayer (6:5–15), and fasting (6:16–18). The discourse goes on to condemn the superficiality of materialism and call the disciples not to worry about material needs, but to "seek" God's kingdom first. Within the discourse on ostentation, Matthew presents an example of correct prayer. Luke places this in a different context. The Lord's prayer (6:9–13) contains parallels to .
The first part of Matthew 7, i.e. deals with judging. Jesus condemns those who judge others before first judging themselves: "Judge not, that ye be not judged."
In the last part in Jesus concludes the sermon by warning against false prophets, and emphasizing that humans are unable to do right ("bear fruit") apart from God.
Teachings and theology.
The teachings of the Sermon on the Mount have been a key element of Christian ethics, and for centuries the sermon has acted as a fundamental recipe for the conduct of the followers of Jesus. Various religious and moral thinkers (e.g. Tolstoy and Gandhi) have admired its message, and it has been one of the main sources of Christian pacifism.
In the 5th century, Saint Augustine began his book "Our Lord's Sermon on the Mount" by stating:
The last verse of chapter 5 of Matthew () is a focal point of the sermon that summarizes its teachings by advising the disciples to seek perfection." The Greek word "telios" used to refer to perfection also implies an end, or destination, advising the disciples to seek the path towards perfection and the Kingdom of God. It teaches that God's children are those who act like God.
The teachings of the sermon are often referred to as the "Ethics of the Kingdom": they place a high level of emphasis on "purity of the heart" and embody the basic standard of Christian righteousness.
Theological structure.
The issue of the theological structure and composition of the Sermon on the Mount remains unresolved. One group of theologians ranging from Saint Augustine in the 5th century to Michael Goulder in the 20th century, see the Beatitudes as the central element of the Sermon. Others such as Bornkamm see the Sermon arranged around the Lord's prayer, while Daniel Patte, closely followed by Ulrich Luz, see a chiastic structure in the sermon. Dale Allison and Glen Stassen have proposed a structure based on triads. Jack Kingsbury and Hans Dieter Betz see the sermon as composed of theological themes, e.g. righteousness or way of life.
Analysis and interpretation.
Interpretations.
The high ethical standards of the sermon have been interpreted in a wide variety of ways by different Christian groups and Craig S. Keener states that at least 36 different interpretations regarding the message of the Sermon exist, which he divides into 8 categories of views:
Comparison with the Sermon on the Plain.
While Matthew groups Jesus' teachings into sets of similar material, the same material is scattered when found in Luke. The Sermon on the Mount may be compared with the similar but more succinct Sermon on the Plain as recounted by the Gospel of Luke (6:17–49), which occurs at the same moment in Luke's narrative, and also features Jesus heading up a mountain, but giving the sermon on the way down at a level spot. Some scholars believe that they are the same sermon, while others hold that Jesus frequently preached similar themes in different places.
Comparison with Buddhist teachings.
Although modern parallels between the teachings of Jesus such as the Sermon on the Mount and some Buddhist teachings have been drawn (by the 14th Dalai Lama for example) these comparisons emerged after missionary contacts in the 19th century, and there is no historically reliable evidence of contacts between Buddhism and Jesus during his life. Modern scholarship has almost unanimously agreed that claims of the travels of Jesus to Tibet, Kashmir or India (see Unknown years of Jesus) and the influence of Buddhism on his teachings are without historical basis.
According to the Perennial Philosophy.
According to perennialist author Frithjof Schuon, the message of the Sermon is a perfect synthesis of the whole Christian tradition. The text has the largest number of perennial and universal doctrines, and spiritual advice of all Scripture. Much of what the Bible readers remembers from it derives from the Sermon. Source of spiritual and moral instructions, the Sermon of the Mount is regarded by the Perennial Philosophy "as the quintessence itself of religion". Perennialism considers the injunctions of the Sermon of the Mount as belonging to the esoteric dimension of Christianity.
References.
</dl>
External links.
</dl>

</doc>
<doc id="44373" url="http://en.wikipedia.org/wiki?curid=44373" title="Triton (mythology)">
Triton (mythology)

Triton (; Greek: Τρίτων "Tritōn") is a mythological Greek god, the messenger of the sea. He is the son of Poseidon and Amphitrite, god and goddess of the sea respectively, and is herald for his father. He is usually represented as a merman, having the upper body of a human and the tail of a fish, "sea-hued", according to Ovid "his shoulders barnacled with sea-shells".
Like his father, Poseidon, he carried a trident. However, Triton's special attribute was a twisted conch shell, on which he blew like a trumpet to calm or raise the waves. Its sound was such a cacophony, that when loudly blown, it put the giants to flight, who imagined it to be the roar of a dark wild beast.
According to Hesiod's "Theogony", Triton dwelt with his parents in a golden palace in the depths of the sea; Homer places his seat in the waters off Aegae. The story of the Argonauts places his home on the coast of Libya. When the Argo was driven ashore in the Gulf of Syrtes Minor, the crew carried the vessel to the "Tritonian Lake", Lake Tritonis, whence Triton, the local deity euhemeristically rationalized by Diodorus Siculus as "then ruler over Libya", welcomed them with a guest-gift of a clod of earth and guided them through the lake's marshy outlet back to the Mediterranean. When the Argonauts were lost in the desert, he guided them to find the passage from the river back to the sea.
Triton was the father of Pallas and foster parent to the goddess Athena. Pallas was killed by Athena accidentally during a sparring fight between the two goddesses. Triton is also sometimes cited as the father of Scylla by Lamia. Triton can sometimes be multiplied into a host of Tritones, "daimones" of the sea.
In the Virgil's "Aeneid", book 6, it is told that Triton killed Misenus, son of Aeolus, by drowning him after he challenged the gods to play as well as he did.
Tritons.
Over time, Triton's class and image came to be associated with a class of mermaid-like creatures, the Tritons (Τρίτωνες), which could be male or female, and usually formed the escort of marine divinities. Tritons were a race of sea gods and goddesses born from Triton. Triton lived with his parents, Poseidon and Amphitrite, who was also known as Celaeno, in a golden palace on the bottom of the sea. According to Homer it was called Aegae. Unlike their ancestor Poseidon who is always fully anthropomorphic in ancient art (this has only changed in modern popular culture), Tritons' lower half is that of a fish, while the top half is presented in a human figure. This is debated often because their appearance is described differently throughout history. Ordinary Tritons were described in detail by the traveller Pausanias (ix. 21).
They are often compared to other Merman/Mermaid like beings, such as Merrows, Selkies, and Sirens. They are also thought of as the aquatic versions of Satyrs. Another description of Tritons is that of the Centaur-Tritons, also known as Ichthyocentaurs who are depicted with two horse's feet in place of arms.
When Pausanias visited the city of Triteia in the second century CE, he was told that the name of the city was derived from an eponymous Triteia, a daughter of Triton, and that it claimed to have been founded by her son (with Ares), one among several mythic heroes named Melanippus ("Black Horse").
Tritons were the trumpeters of the sea, using trumpets made out of a great shell, mostly known as a conch. They would blow this shell throughout the sea to calm the waves, or stir them up, all at the command of Poseidon.
University, college, and high school mascot.
There are numerous universities, colleges, and high schools that use Triton as their mascot. These include the following:
Many club sports teams, such as junior football leagues and numerous swimming leagues, also use the symbol of Triton. 
An example of other uses include Wilfrid Laurier University's orientation week in 2014 that had a colour team named the Green Tritons as part of the weeks events.
Triton since the Renaissance.
The largest moon of the planet Neptune has been given the name Triton, as Neptune is the Roman equivalent of Poseidon.
In Wordsworth's sonnet "The World Is Too Much with Us" (ca 1802, published 1807), the poet regrets the prosaic humdrum modern world, yearning for
<poem style="margin-left: 2em">glimpses that would make me less forlorn;
Have sight of Proteus rising from the sea;
Or hear old Triton blow his wreathèd horn.</poem>
In Jacob Jordaens' 'The Family of the Artist', now in the Prado, Madrid, a Triton is depicted gripping, perhaps crushing, a child with its snake-like tail, a scene watched over by an exotic parrot. The significance of this motif in the context of a painting of domestic happiness is unclear, but it may involve a transfer of functions in that that the child appears to be blowing on the conch shell (referred to above) in order to frighten away those forces that threaten family peace.
A family of large sea snails, the shells of some of which have been used as trumpets since antiquity, are commonly known as "tritons", see Triton (gastropod).
The name Triton is associated in modern industry with tough hard-wearing machines such as the Ford Triton engine and Mitsubishi Triton pickup truck.
King Triton is also depicted in the Disney's "The Little Mermaid" as an undersea king, the father of the title character.

</doc>
<doc id="44380" url="http://en.wikipedia.org/wiki?curid=44380" title="Anna of Russia">
Anna of Russia

Anna Ioannovna (Russian: Анна Иоанновна) (7 February [O.S. 28 January] 1693 – 28 October [O.S. 17 October] 1740) reigned as Empress of Russia from 1730 to 1740. Prior to her accession to the Russian throne, she was the regent of the Duchy of Courland from 1711 until 1730.
Early life.
Anna was born in Moscow to Ivan V and Praskovia Saltykova. She was primarily raised by her mother, a very stern woman. By her orders she was to be raised for the nunnery; she grew up confined to a royal cult of domesticity. This type of confinement was known to not allow for development of personality and explains the cruel tendencies of Anna, who followed in her mother’s footsteps. Her education consisted of French, German, dancing, religious text, and folklore. As she grew older, she was obstinate and had a mean streak, earning her the nickname “Ivan the Terrible.” Her family moved to St. Petersburg under the order of Tsar Peter the Great and this had a significant effect on Anna; she enjoyed the grandeur society.
Peter the Great also arranged her marriage to Frederick William, Duke of Courland in November 1710. With her dowry of 200,000 roubles, Anna was wed in a grand affair. A parody of their wedding was performed soon after by two dwarfs jumping out of pies immediately following the ceremony. Just a few short weeks after the marriage and only twenty miles out of St. Petersburg on the road to Courland, Duke Frederick died. The cause of death was uncertain, attributed to a chill or the effects of alcohol.
Accession.
After her husband died. Anna proceeded to rule Courland (now western Latvia) from 1711 to 1730, with the Russian resident, Peter Bestuzhev, as her adviser (and sometimes lover). She never remarried after the death of her husband, but her enemies said she conducted a love affair with Ernst Johann von Biron for many years.
On the death of Peter II, Emperor of Russia, the Russian Supreme Privy Council under Prince Dmitri Galitzine made Anna Empress in 1730. The Council had hoped that she would feel indebted to the nobles and remain a figurehead at best, and malleable at worst. The Council convinced her to sign conditions to her accession that limited her power. The conditions that were drafted to limit her power included that she could not start war, call for peace, create new taxes, or promote individuals to high ranks. She could not punish nobility without trial, could not grant estates or villages, could not promote anyone, either foreigners or Russians, to court office, and she could not spend the revenue generated by the state. Being raised in a court her entire life, she was very prepared to handle the political structure and knew how to get her way. Instead of complying with the conditions, she dissolved the Privy Council and soon established herself as an autocratic ruler, using her popularity with the imperial guards and lesser nobility.
Policies.
Cadet Corps.
Anna founded the Cadet Corps in 1731, one year after coming to the throne. The Cadet Corps was a group of young boys starting at the age of eight being trained for the military. There was a very rigorous training program and this also included all the schooling that was necessary for someone to be in an important position in the military. As time went on though, the program was later improved by other emperors and empresses, such as Catherine the Great. They began to include the arts and sciences into their schooling, rather than just the knowledge that is considered necessary for only a career in the military.
Academy of Science.
Started by Peter the Great, Anna continued to fund the Academy of Science. The point of this school was to further the sciences in Russia and to help bring the country that was so far behind up to where the Western Countries were. Some of the sciences that were taught were mathematics, astronomy, and botany. The Academy of Science was also responsible for a lot of the expeditions, specifically to the Bering Sea. The Bering Sea Expedition is one of the more famous ones that was done by the Academy of Science. While they were trying to find out if America and Asia had been at one point connected, they also studied Siberia and its people, these studies were used long after they returned from Siberia.
But there were also some troubles for the scientists. Oftentimes, the government and the church would meddle in their funding and their experiments, changing the data to how they wanted to see it.
This school of science was very small, never exceeding a population of twelve students in the university and barely over a hundred in the secondary school. But still it was a huge step forward for education in Russia. Many of the teachers and professors were imported from Germany bringing more of a Western feeling to what the students were learning about. Some of the students to learn from these German professors later became advisors or teachers to some of the future leaders, such as Catherine the Great’s tutor, Adodurov.
During Anna’s reign, the Academy of Science began to include the Arts into their program. For not only was there not a school for the arts yet, but Anna was a firm supporter of the arts. Theater, architecture, engraving, and journalism were all added to the curriculum. During this time, the foundations of what is now the world famous Russian Ballet was laid down as well.
The Secret Office of Investigation.
There have been many rumors since the time of Anna’s reign that Biron had a large impact on this office, but truly it was run by the senator A. I. Ushakov. This office was resurrected during Anna’s reign to punish those for political crimes mostly, but sometimes they would take cases that were not as political. The punishments that came from the crimes that were committed, were often very painful and disgusting. For example, some people that had supposedly been plotting against the government had their noses slit as well as being beaten with the knout.
Nobility.
There is a lot of mention of Germans throughout the reign of Anna. For example, she often gave them ruling positions in her cabinet and other important decision making positions. This was because she had very little trust in the Russians. It was because of this strong German influence in government that many Russians came to resent them.
Anna gave many privileges to those that were considered the nobility. In 1730, she made sure that the law of Peter the Great outlawed states from being subdivided, the primogeniture law, was repealed. Starting in 1731, landlords were responsible for their serfs' taxes and their economic bondage was tightened again. In 1736, when the age of service changed to twenty with a twenty-five year service time, Anna and her government also determined that if the family had more than one son, one could stay behind so that he could work the estate.
Foreign Affairs.
During Anna’s reign, Russia became involved in two major conflicts, the War of the Polish Succession and the Turkish wars. The Turkish Wars were due to her German cabinet member, Osterman, believing that Russia should not have stopped trying to take over more land for themselves. The reason that Russia stopped was due to a treaty, the Peace of Pruth, signed by Peter the Great in 1711. In the end though, all of the land, except for one piece had to be given up, back to the Ottoman Empire. But before the Turkish wars was the War of the Polish Succession. Russia had allied themselves with Charles VI, who was the Holy Roman Emperor at the time, and committed Russia during the War of the Polish Succession. Afterwards, they made Augustus III the king of Poland at the expense of Stanisław Leszczyński and other candidates. Not only were these wars deadly but they cost more money than many of the past military expenditures of Russia combined, causing a lot of stress on the country.
In 1732, on the eve of the Austro-Russian–Turkish War of 1735-39, the government of Anna Ioannovna was forced to cede back all the annexed territories in the North Caucasus, South Caucasus, and northern Persia conquered in the Russo-Persian War of 1722-23 by Peter the Great several years earlier back to Persia, now led by the military genius Nader Shah, as a part of the Treaty of Resht in order to construct an alliance against the Ottoman Empire.
Relationship with Biron.
Anna’s reign is often referred to as “Bironovschina” or “The Age of Biron,” in regards to her German lover Ernest Johann Biron. What separates Anna’s reign from the majority of imperial Russian history is the fact that her courts were almost entirely made up of foreigners, and the majority of whom were German. Historians isolate her rule from Russian history due to long-term prejudice towards Germans. Historians would also argue that Biron not only had a strong influence on Anna’s domestic and foreign policies, but that he also reigned solely at times. Anna was attracted to Biron’s charm and he proved to be a good companion to her after her tragic past love life. But Biron’s name became synonymous with cruelty, terror, and evil, ensuring Anna’s reign with a dark mark. Anna never remarried; as empress of Russia she enjoyed the power she held over all men and viewed marriage as unnecessary.
Westernization.
Anna continued lavish architectural advances in St. Petersburg. Anna completed a waterway that began construction under Peter the Great and called for seafaring ships to accompany this new canal and continue naval expansion. Westernization continued after Peter the Great’s reign in areas of prominent Western culture such as the Academy of Science, cadet corps education, and imperial culture including theater and opera. Although not at the fast-paced speed of Westernization under her Uncle Peter’s reign, it is evident that a culture of the expansion of knowledge continued during Anna’s rule and affected mostly nobility. It is argued that this success in Westernization is due to the efforts of the German court nobility; the foreigners’ impacts are viewed both positively and negatively.
Dark legacy.
Anna’s rule is often overlooked in Russian history due to its unfavorable consequences during the decade. It is often referred to as the “dark era.” A Russian autocrat could not afford to be weak of character, yet Anna’s rule does portray questionable recurring evil instances towards subjects and situations. There were continued issues with serfdom, or peasant and low class slavery, taxation, political dishonesty, and a reign marked by constant fear. Her empire was described by Lefort, the Saxon minister, as being “comparable to a storm threatened ship, manned by a pilot and crew who are all drunk or asleep . . . with no considerable future.” Anna’s war with Turkey, economic issues, and conspiracy revolving around her accession all bring to light an ominous glow of the empress’s reign. Such lavish court life was overshadowed by the thousands of men at war being slaughtered like cattle. It is undeniable she had a vast impact in science and culture, but it came with a price. The positive aspects of Anna’s reign are typically ignored though, and it is important to note that she had no more influence on domestic and foreign relations and policies than any other eighteenth century ruler.
Anna’s reign was almost unidentifiable during the 1730s when compared to any East or West court when it came to the grandeur and lavish display of wealth in the palace. The issue with Anna’s reign derives from her personality flaws. She was known to enjoy hunting animals from the palace windows and on more than a few occasions humiliated individuals with disabilities. On a positive note, she restored the courts in St. Petersburg and brought Russia’s political atmosphere back to where Peter the Great had intended progress.
Death and succession.
Anna was famed for her big cheek, "which, as shown in her portraits", Carlyle says, "was comparable to a Westphalian ham". As her health declined she declared her grandnephew, Ivan VI, should succeed her, and appointed Biron as regent. This was an attempt to secure the line of her father, Ivan V, and exclude descendants of Peter the Great from inheriting the throne.
It was recorded she had an ulcer on her kidneys. She continued having attacks of gout, and as her condition worsened, her health began to fail. Anna died on October 17, 1740, from a terrible kidney stone that made for a slow and painful death. The tsaritsa’s final words focused on Biron. Anna died at the age of 47 of kidney disease. Ivan VI was only a one-year-old baby at the time and his mother, Anna Leopoldovna, was detested for her German counsellors and relations. As a consequence, shortly after Anna's death Elizabeth Petrovna, Peter I's legitimized daughter, managed to gain the favor of the populace, locked Ivan VI in a dungeon and exiled his mother. Anna was buried three months later on January 15, 1741, leaving behind uncertainty for the future of Russia.

</doc>
<doc id="44383" url="http://en.wikipedia.org/wiki?curid=44383" title="Gunderic">
Gunderic

Gunderic (379–428), King of Hasding Vandals (407-418), then King of Vandals and Alans (418–428), led the Hasding Vandals, a Germanic tribe originally residing near the Oder River, to take part in the barbarian invasions of the Western Roman Empire in the fifth century.
History.
He was a son of King Godigisel, the Hasdingi's Vandal king when his people breached the Rhine river frontier of the Empire on the last day of 406. During that year, the Vandals had become heavily involved in a war with the Franks, who were already settled in Gaul as allies of the Romans, and who attempted to keep the Vandals out. Godigisel was killed in the fighting and Gunderic succeeded him.
Gunderic and his people ultimately crossed the Pyrenees into the Iberian Peninsula. With the Hasdingi portion of the Vandals he established the Kingdom in the Roman province of Gallaecia (north-western Iberia). 
Conflicts with the Suebi drove him into Baetica in the south of Hispania, where he joined the surviving Silingi portion of the Vandals. They were later driven out by the Visigoths, along with the Alans and were forced to leave Hispania.
Around 426, Attaces, the king of the Alans, fell in battle against the Visigoths in Hispania, and most of the surviving Alans appealed to Gunderic. Gunderic accepted their request and thus became King of the Vandals and Alans.
Late in his reign, the Vandals themselves began to clash more and more with the Visigoths, often getting the worse of these battles because the Visigoths were so much more numerous. After Gunderic died early in 428, the Vandals elected his half-brother Genseric as his successor, and Genseric left Iberia to the Visigoths in favor of invading Roman Africa. 

</doc>
<doc id="44384" url="http://en.wikipedia.org/wiki?curid=44384" title="TLS">
TLS

TLS may refer to:

</doc>
<doc id="44385" url="http://en.wikipedia.org/wiki?curid=44385" title="Muggle">
Muggle

In the "Harry Potter" book series, a Muggle is a person who lacks any sort of magical ability and was not born into the magical world. Muggles also do not have any magical blood. It differs from the term "Squib", which refers to a person with one or more magical parents yet without any magical ability, and from the term Muggle-born (or the derogatory and offensive "mudblood"), which refers to a person with magical abilities but without magical parents.
Usage in "Harry Potter".
The term "Muggle" is sometimes used in a pejorative manner in the books. Since "Muggle" refers to a person who is a member of the non-magical community, Muggles are simply ordinary human beings rather than witches and wizards. According to the author, J. K. Rowling, a quarter of the annual Hogwarts intake have two nonmagical parents; there have also been some children known to have been born to one magical and one non-magical parent. Children of this mixed parentage are called "half-bloods" (strictly speaking, they are 'Literal Half-bloods'); children with recent Muggle ancestry on the one side or the other are also called half-bloods. The most prominent Muggle-born in the Harry Potter series is Hermione Granger, who had two Muggles of unspecified names as parents. A witch or wizard with all magical heritage is called a pure-blood.
In the "Harry Potter" books, non-magical people are often portrayed as foolish, sometimes befuddled characters, who are completely ignorant of the Wizarding world that exists in their midst. If, by unfortunate means, non-magical people do happen to observe the working of magic, the Ministry of Magic sends Obliviators to cast Memory Charms upon them causing them to forget the event.
Some Muggles, however, know of the wizarding world. These include Muggle parents of magical children, such as Hermione Granger's parents, the Muggle Prime Minister (and his predecessors), the Dursley family (Harry Potter's non-magical and only living relatives), and the non-magical spouses of some witches and wizards.
Rowling has said she created the word "Muggle" from "mug", an English term for someone who is easily fooled. She added the "-gle" to make it sound less demeaning and more "cuddly".
A 'muggle' is, according to Abbott Walter Bower, the author of the "Scotichronicon", "an Englishman's tail". In Alistair Moffat's book, "A History of the Borders from Early Times" it is stated that there was a widely held 13th century belief amongst Scots that Englishmen had tails.
Rowling herself was sued for using the word "muggle" in the Harry Potter books.
Other usages.
The word "muggle", or "muggles", is now used in various contexts in which its meaning is similar to the sense in which it appears in the Harry Potter book series. Generally speaking, it is used by members of a group to describe those outside the group, comparable to "civilian" as used by military personnel. Whereas in the books "muggle" is consistently capitalised, in other uses it is often predominately lowercase.

</doc>
<doc id="44387" url="http://en.wikipedia.org/wiki?curid=44387" title="Socrates of Constantinople">
Socrates of Constantinople

Socrates of Constantinople (Greek: Σωκράτης ὁ Σχολαστικός, b. c. 380; d. after 439), also known as Socrates Scholasticus, was a 5th-century Christian church historian, a contemporary of Sozomen and Theodoret.
He is the author of a "Historia Ecclesiastica" ("Church History", Ἐκκλησιαστική Ἱστορία) which covers the history of late ancient Christianity during the years 305–439.
Life.
He was born at Constantinople. Even in ancient times nothing seems to have been known of his life except what can be gathered from notices in his "Historia Ecclesiastica", which departed from its ostensible model, Eusebius of Caesarea, in emphasizing the place of the emperor in church affairs and in giving secular as well as church history.
Socrates' teachers, noted in his prefaces, were the grammarians Helladius and Ammonius, who came to Constantinople from Alexandria, where they had been pagan priests. A revolt, accompanied by an attack on the pagan temples, had forced them to flee. This attack, in which the Serapeum was vandalized and its library destroyed, is dated about 391.
That Socrates of Constantinople later profited by the teaching of the sophist Troilus is not proven. No certainty exists as to Socrates' precise vocation, though it may be inferred from his work that he was a layman.
In later years he traveled and visited, among other places, Paphlagonia and Cyprus .
The "Historia Ecclesiastica".
The history covers the years 305–439, and experts believe it was finished in 439 or soon thereafter, and certainly during the lifetime of Emperor Theodosius II, i.e., before 450. The purpose of the history is to continue the work of Eusebius of Caesarea (1.1). It relates in simple Greek language what the Church experienced from the days of Constantine to the writer's time. Ecclesiastical dissensions occupy the foreground, for when the Church is at peace, there is nothing for the church historian to relate (7.48.7). In the preface to Book 5, Socrates defends dealing with Arianism and with political events in addition to writing about the church.
The "Historia Ecclesiastica" is one of the few sources of our knowledge of Hypatia, the female mathematician and philosopher of Alexandria.
Socrates' account is in many respects well-balanced. He is careful not to use hyperbolic titles when referring to prominent personalities in Church and State.
He is often assumed to have been a follower of Novatianism, but this is based on the fact that he gives a lot of details about the Novatianists, and speaks of them in generous terms, as he does of Arians and other groups. He speaks of himself as belonging to the Church.
Socrates asserts that he owed the impulse to write his work to a certain Theodorus, who is alluded to in the proemium to the second book as "a holy man of God" and seems therefore to have been a monk or one of the higher clergy. The contemporary historians Sozomen and Theodoret were combined with Socrates in a sixth-century compilation, which has obscured their differences until recently, when their individual portrayals of the series of Christian emperors were distinguished one from another and contrasted by Hartmut Leppin, "Von Constantin dem Großen zu Theodosius II" (Göttingen 1996).
Editions and translations.
The "Historia Ecclesiastica" was first edited in Greek by Robert Estienne, on the basis of "Codex Regius" 1443 (Paris, 1544); a translation into Latin by Johannes Christophorson (1612) is important for its variant readings. The fundamental early modern edition, however, was produced by Henricus Valesius (Henri Valois) (Paris, 1668), who used the "Codex Regius", a Codex Vaticanus, and a Codex Florentinus, and also employed the indirect tradition of Theodorus Lector ("Codex Leonis Alladi").
The text was edited in Patrologia Graeca vol. 67 (online at .
The new critical edition of the text is edited by G.C. Hansen, and published in the series "Die Griechischen Christlichen Schriftsteller" (Berlin:Akademie Verlag) 1995.
An English translation by A. C. Zenos was published in " Nicene and Post-Nicene Fathers", Second Series, Vol. 2. Edited by Philip Schaff and Henry Wace. (Buffalo, NY: Christian Literature Publishing Co., 1890.) (online editions: .
More recently Socrates' History has been published in four bilingual volumes by Pierre Maraval in the "Sources Chrétiennes" collection.
Notes.
 

</doc>
<doc id="44392" url="http://en.wikipedia.org/wiki?curid=44392" title="Andrzej Wajda">
Andrzej Wajda

Andrzej Wajda (]; born 6 March 1926) is a Polish film and theatre director. Recipient of an honorary Oscar, he is possibly the most prominent member of the unofficial "Polish Film School" (active "c." 1955 to 1963). He is known especially for a trilogy of war films: "A Generation" (1954), "Kanał" (1956) and "Ashes and Diamonds" (1958).
Four of his films have been nominated for the Academy Award for Best Foreign Language Film: "The Promised Land" (1975), "The Maids of Wilko" (1979), "Man of Iron" (1981), and "Katyń" (2007).
Early life.
Wajda was born in Suwałki, Poland, the son of Aniela (née Białowąs), a school teacher, and Jakub Wajda, an army officer. Wajda's father was murdered by the Soviets in 1940 in what came to be known as the Katyn massacre. In 1942 he joined the Polish resistance and served in the Armia Krajowa. After the war, he studied to be a painter at Kraków's Academy of Fine Arts before entering the Łódź Film School.
Career.
After Wajda's apprenticeship to director Aleksander Ford, Wajda was given the opportunity to direct his own film. "A Generation" (1955) was one of Wajda's first major films. At the same time Andrzej Wajda began his work as a director in theatre, including such as Michael V. Gazzo's "A Hatful of Rain" (1959), "Hamlet" (1960), and "Two for the Seesaw" (1963) by William Gibson. Wajda made two more increasingly accomplished films, which developed further the anti-war theme of "A Generation": Kanał (1956) (Special Jury Prize at Cannes Film Festival in 1957, shared with Bergman's "The Seventh Seal") and "Ashes and Diamonds" (1958) with Zbigniew Cybulski.
While capable of turning out mainstream commercial fare (often dismissed as "trivial" by his critics[]), Wajda was more interested in works of allegory and symbolism, and certain symbols (such as setting fire to a glass of liquor, representing the flame of youthful idealism that was extinguished by the war) recur often in his films. "Lotna" (1959) is full of surrealistic and symbolic scenes and shots, but he managed to explore other styles, making new wave style "Innocent Sorcerers" (1960) with music by Krzysztof Komeda, starring Roman Polanski and Jerzy Skolimowski (who was also a co-script writer) in the episodes. Then Wajda directed "Samson" (1961), the story of Jacob, a Jewish boy, who wants to survive during the Nazi occupation of Poland. In the mid-1960s Wajda made "The Ashes" (1965) based on the novel by Polish writer Stefan Żeromski and directed several films abroad: "Love at Twenty" (1962), "Siberian Lady Macbeth" (1962) and "Gates To Paradise" (1968).
In 1967, Cybulski was killed in a train accident, whereupon the director articulated his grief with "Everything for Sale" (1968), considered one of his most personal films, using the technique of a film-within-a-film to tell the story of a film maker's life and work.
The following year he directed an ironic satire "Hunting Flies" with the script written by Janusz Głowacki and a television film based upon Stanisław Lem's short story "Roly Poly".
The 1970s were the most lucrative artistic period for Wajda, who made over ten films: "Landscape After the Battle" (1970), "Pilate and Others" (1971), "The Wedding" (1972) – the film version of Polish most famous poetic drama by Stanisław Wyspiański, "The Promised Land" (1974), "Man of Marble" (1976) – the film takes place in two time periods, the first film showing the episodes of Stalinism in Poland, "The Shadow Line" (1976), "Rough Treatment" (the other title: "Without Anesthesia)" (1978), "The Orchestra Conductor" (1980), starring John Gielgud; or two psychological and existential films based upon novels by Polish famous writer Jarosław Iwaszkiewicz – "The Birch Wood" (1970) and "The Maids of Wilko" (1979). "The Birch Wood" was entered into the 7th Moscow International Film Festival where Wajda won the Golden Prize for Direction.
Wajda continued to work in theatre, including "Play Strindberg", Dostoyevsky's "The Possessed" and "Nastasja Filippovna" – the Wajda's version of "The Idiot", "November Night" by Wyspiański, "The Immigrants" by Sławomir Mrożek, "The Danton Affair" or "The Dreams of Reason".
Wajda's later commitment to Poland's burgeoning Solidarity movement was manifested in "Man of Iron" (1981), a thematic sequel to "The Man of Marble", with Solidarity leader Lech Wałęsa appearing as himself in the latter film. The film sequence is loosely based on the life of Anna Walentynowicz, a hero of socialist labor [Stahanovite] turned dissident and alludes to events from real life, such as the recreation in Man of Iron of the firing of Anna Walentynowicz from the shipyard and the underground wedding of Bogdan Borusewicz to Alina Pienkowska. The director's involvement in this movement would prompt the Polish government to force Wajda's production company out of business. For the film, Wajda won the Palme d'Or at the Cannes Film Festival. In 1983 he directed "Danton", starring Gérard Depardieu in the title role, a film set in 1794 (Year Two) dealing with the Post-Revolutionary Terror. Wajda showed how easy revolution can change into terror and starts to "eat its own children". But the film should also be seen in its historical context against the backdrop of the martial law in Poland, which can be referred to as its "Polish ambience." For this film Wajda was honoured by receiving the very prestigious Louis Delluc Award, he also gained a couple of Cesar Awards. In the 1980s he also made some important films like "A Love in Germany" (1983) featuring Hanna Schygulla, "The Chronicle of Amorous Incidents" (1986) an adaptation of Tadeusz Konwicki's novel and "The Possessed" (1988) based on Dostoyevsky's novel, in which it is shown how terrorism begins. In theatre he prepared a very famous interpretation of Dostoyevsky's "Crime and Punishment" (1984) and other unique spectacles such as "Antygone", his sequential "Hamlet" versions or an old Jewish play "The Dybbuk".
In 1989 he was the President of the Jury at the 16th Moscow International Film Festival.
Since 1989.
In 1990 Andrzej Wajda was honoured as the third director, after Federico Fellini and Ingmar Bergman by the European Film Awards for his lifetime achievement. In the early 1990s, he was elected a senator and also appointed artistic director of Warsaw's Teatr Powszechny. He continued to make films set during World War II, including "Korczak" (1990), a story about a Jewish-Polish doctor who takes care of orphan children, in "The Crowned-Eagle Ring" (1993) and "Holy Week" (1995) specifically on Jewish-Polish relations. In 1994 Wajda presented his own film version of Dostoyevsky's novel The Idiot in the movie Nastasja,starring Japanese actor Tamasoburo Bando in double role of Prince Mishkin and Nasstasya, the film was beautifully photographed by Pawel Edelman, who became one of Wajda's great co-workers since that time. In 1996 the director went in a different direction with "Miss Nobody", a coming-of-age drama that explored the darker and more spiritual aspects of a relationship between three high-school girls. In 1999 Wajda presented a great epic film "Pan Tadeusz", based on the art of the Polish 19th-century romantic poet Adam Mickiewicz.
A year later, at the 2000 Academy Awards, Wajda was presented with an honorary Oscar for his contribution to world cinema; he subsequently donated the award to Kraków's Jagiellonian University.
In 2002 Wajda directed the comedy "The Revenge", a film version of his 1980s theatre production, with Roman Polanski in one of the main roles. In February 2006, Wajda received an honorary Golden Bear for lifetime achievement at the Berlin International Film Festival.
In 2007 "Katyń" was released, a well received film about the Katyn massacre, in which Wajda's father was murdered but the director also shows the dramatic situation of those who await for their relatives (mothers, wives and children). The film was nominated for the Best Foreign Language Film Oscar in 2008.
Wajda followed it with "Tatarak" ("Sweet Rush" – 2009) with Krystyna Janda as a main character. It is partly based upon Jarosław Iwaszkiewicz short novel, there is also very important fragment taken from Janda's private life. "Sweet Rush" turns to be a sort of deep, calm and melancholic meditation about death and love. The film is dedicated to Edward Kłosiński, Janda's husband, a cinematographer and a long-time Andrzej Wajda's friend and co-worker who died of cancer the same year. For this film Andrzej Wajda was awarded by Alfred Bauer Prize at The Berlin Film Festival in 2009, recently he also got critics prize – Prix FIPRESCI during European Film Awards Ceremony. "Walesa. Man of Hope" ("Wałęsa. Człowiek z nadziei"), Wajda's biography of Lech Wałęsa, based on a script by Janusz Głowacki and starring Robert Więckiewicz in the title role, had its world premiere at the Venice International Film Festival on 5 Sep 2013.
Andrzej Wajda has founded The Japanese Centre of Art and Technology "Manggha" in Krakow/Cracow (1994) and has also founded (2002) (along with great Polish film maker Wojciech Marczewski) and leads his own film school in which students take part in different film courses led by famous European film makers.
Analysis.
A major figure of world and European cinema after World War II, Wajda made his reputation as a sensitive and uncompromising chronicler of his country's political and social evolution. Once dubbed a symbol for a besieged country, Wajda is known for drawing from Poland's history to suit his tragic sensibility—crafting an oeuvre of work that devastates even as it informs.
Andrzej Wajda's films have a strong visual side, he sometimes made his own versions of Polish and European paintings and he also thinks by the images. He tries to give the right mood and atmosphere of times in which he sets the action and he refers to the paintings of that time as well. He has worked with Polish cinematographers such as Jerzy Lipman, Jerzy Wójcik, Witold Sobociński, Edward Kłosiński, Zygmunt Samosiuk, Sławomir Idziak or Paweł Edelman, he also cooperated with Igor Luther or Robby Muller.
Personal life.
Wajda has been married four times. His third wife was popular actress Beata Tyszkiewicz with whom he has a daughter Karolina (born 1967). His fourth and current wife is theatre costume designer, and actress Krystyna Zachwatowicz.
Awards.
"Man of Iron" won the Palme d'Or at the 1981 Cannes Film Festival. "The Promised Land" won the Golden Prize at the 9th Moscow International Film Festival in 1975.
Four of Wajda's works ("The Promised Land", "The Maids of Wilko", "Man of Iron", and "Katyń )" have been nominated for an Academy Award for Best Foreign Language Film. In 2000, Wajda received an honorary Oscar from the Academy of Motion Picture Arts and Sciences, as another Pole who received the Award after Warner Bros., Leopold Stokowski, Bronisław Kaper, Zbigniew Rybczyński, Janusz Kamiński, Allan Starski, Ewa Braun, Roman Polanski or Jan A. P. Kaczmarek.
"The Orchestra Conductor" was entered into the 30th Berlin International Film Festival, where Andrzej Seweryn won the Silver Bear for Best Actor. In 1988, his film "Les Possédés" was nominated for the Golden Bear at the 38th Berlin International Film Festival. In 1996, his film "Wielki tydzień" won the Silver Bear for an outstanding artistic contribution at the 46th Berlin International Film Festival. The following year, his film "Miss Nobody" won an Honourable Mention at the 47th Berlin International Film Festival.

</doc>
<doc id="44393" url="http://en.wikipedia.org/wiki?curid=44393" title="Claudius Gothicus">
Claudius Gothicus

Claudius II (Latin: "Marcus Aurelius Valerius Claudius Augustus"; May 10, 213 – January 270), commonly known as Claudius Gothicus, was Roman Emperor from 268 to 270. During his reign he fought successfully against the Alamanni and scored a crushing victory against the Goths at the Battle of Naissus. He died after succumbing to a plague (perhaps smallpox) that ravaged the provinces of the Empire.
Early Life And Origin.
Claudius' origin is Illyrian. Born on May 10, 213, he was either from Sirmium in Pannonia Inferior or from Naissus Dardania (in Moesia Superior).
Military Career and rise to power.
Claudius had served with the Roman army for all his adult life, making his way up the military hierarchy until the Emperor Gallienus made him the commander of his elite cavalry force ("hipparchos") and subsequently his military deputy. In September 268 he found himself assigned as a military tribune with the Imperial Army besieging the usurper Aureolus in Milan. His troops then proclaimed him Emperor amid charges, never proven, that he murdered his predecessor Gallienus. However, he soon proved to be less than bloodthirsty, as he asked the Roman Senate to spare the lives of Gallienus' family and supporters. He was less magnanimous toward Rome's enemies, however, and it was to this that he owed his popularity.
It is possible Claudius gained his position and the respect of the soldiers by being physically strong and especially cruel. A legend tells of Claudius knocking out a horse's teeth with one punch. When Claudius performed as a wrestler in the 250s, he supposedly knocked out the teeth of his opponent when his genitalia had been grabbed in the match.
Claudius, like Maximinus Thrax before him, was of barbarian birth. After an interlude of failed aristocratic Roman emperors since Maximinus' death, Claudius was the first in a series of tough soldier-emperors who would eventually restore the Empire from the Crisis of the third century.
The Downfall of Gallienus.
During the 260s, the breakup of the Roman Empire into three distinct governing entities (the core Roman Empire, the Gallic Empire and the Palmyrene Empire) placed the whole Roman imperium into a precarious position. Gallienus was seriously weakened by his failure to defeat Postumus in the West, and the ability of Odaenathus to live with his arrangement with Gallienus in the East. By 268, however, the situation had changed, as Odaenathus was put to death, most likely out of court intrigue, and Gallienus fell victim to a mutiny in his own ranks. Upon the death of Odaenathus, power fell to his younger son, who was dominated by his mother, Zenobia.
Under threat of invasion by multiple tribes, Gallienus' troubles primarily lay with Postumus, whom he could not attack because his attention was required in dealing with Macrianus and the invading "Skythai." After four years of delay, Postumus had established power, but in 265, when Gallienus and his men crossed the Alps, they defeated and besieged Postumus in an (unnamed) Gallic city. When victory appeared to be near, Gallienus made the mistake of approaching the city walls too closely and was gravely injured, compelling him to withdraw the campaign. In the next three years, Gallienus' troubles would only get worse. The "Skythai" successfully invaded the Balkans in the early months of 268, and Aureolus, a commander of the cavalry, declared himself an ally of Postumus and the new emperor in Milan.
At this time, another invasion was taking place. A group called the Herulians navigated through Asia Minor and then into Greece on a naval expedition. Details of these invasions are abstract, as it is nearly impossible to reconstruct the happenings, due to the chain of conflicts initiated by the Herulians in 268. Scholars assume Gallienus' efforts were focused on Aureolus, the officer who betrayed him, and the defeat of the Herulians was left to his successor, Claudius Gothicus.
The death of Gallienus is surrounded by conspiracy and betrayal, as were many emperors' deaths. Different accounts of the incident are recorded, but they agree that senior officials wanted Gallienus dead. According to two accounts, the prime conspirator was Aurelius Heraclianus, the Praetorian Prefect. One version of the story tells of Heraclianus bringing Claudius into the plot while the account given by Historia Augusta exculpates the would-be emperor and adds the prominent general Lucius Aurelius Marcianus into the plot. The removal of Claudius from the conspiracy is due to his later role as the progenitor of the house of Constantine, a fiction of Constantine's time, and may serve to guarantee that the original version from which these two accounts spring was current prior to the reign of Constantine. It is written that while sitting down at dinner, Gallienus was told that Aureolus and his men were approaching the camp. Gallienus rushed to the front lines, ready to give orders, when he was struck down by a commander of his cavalry. In a different and more controversial account, Aureolus forges a document in which Gallienus appears to be plotting against his generals and makes sure it falls into the hands of the emperor's senior staff. In this plot, Aurelian is added as a possible conspirator. The tale of his involvement in the conspiracy might be seen as at least partial justification for the murder of Aurelian himself under circumstances that seem remarkably similar to those in this story.
Whichever story is true, Gallienus was killed in the summer of 268, and Claudius was chosen by the army outside of Milan to succeed him. Accounts tell of people hearing the news of the new Emperor, and reacting by murdering Gallienus' family members until Claudius declared he would respect the memory of his predecessor. Claudius had the deceased emperor deified and buried in a family tomb on the Appian Way. The traitor Aureolus was not treated with the same reverence, as he was killed by his besiegers after a failed attempt to surrender.
The Campaigns of Claudius.
At the time of his Claudius' accession, the Roman Empire was in serious danger from several incursions, both within and outside its borders. The most pressing of these was an invasion of Illyricum and Pannonia by the Goths. Although Gallienus had already inflicted some damage on them at the Battle of Nestus, Claudius, not long after being named Emperor, followed this up by winning his greatest victory, and one of the greatest in the history of Roman arms.
At the Battle of Naissus, Claudius and his legions routed a huge Gothic army. Together with his cavalry commander, the future Emperor Aurelian, the Romans took thousands of prisoners, destroyed the Gothic cavalry as a force, and stormed their laager (a circular alignment of wagons long favored by the Goths). The victory earned Claudius his surname of "Gothicus" (conqueror of the Goths), and that is how he is known to this day. More importantly, the Goths were soon driven back across the Danube River by Aurelian, and nearly a century passed before they again posed a serious threat to the empire.
At the same time, the Alamanni had crossed the Alps and attacked the empire. Claudius responded quickly, routing the Alamanni at the Battle of Lake Benacus in the late fall of 268, a few months after the battle of Naissus. For this he was awarded the title of "Germanicus Maximus." He then turned on the Gallic Empire, ruled by a pretender for the past eight years and encompassing Britain, Gaul, and the Iberian Peninsula. He won several victories and soon regained control of Hispania and the Rhone river valley of Gaul. This set the stage for the ultimate destruction of the Gallic Empire under Aurelian.
However, Claudius did not live long enough to fulfill his goal of reuniting all the lost territories of the empire. Late in 269 he had traveled to Sirmium and was preparing to go to war against the Vandals, who were raiding in Pannonia. However, he fell victim to the Plague of Cyprian (possibly smallpox), and died early in January 270. Before his death, he is thought to have named Aurelian as his successor, though Claudius' brother Quintillus briefly seized power.
The Senate immediately deified Claudius as "Divus Claudius Gothicus".
The Empire and Foreign Affairs Under Claudius.
Claudius was not the only man to reap the benefits of holding high office after the death of Gallienus. Before the rule of Claudius Gothicus, there had only been two emperors from the Balkans, but afterwards there would only be one emperor who did not hail from the provinces of Pannonia, Moesia or Illyricum until the year 378, when Theodosius I from Hispania would take the throne. To comprehend the structure of government during the reign of Claudius, we must look at four inscriptions that deepen our understanding of a new, truncated empire. The first is a dedication to Aurelius Heraclianus, the prefect involved in the conspiracy against Gallienus, from Traianus Mucianus, who also gave a dedication to Heraclianus' brother, Aurelius Appollinaris, who was the equestrian governor of the province of "Thracia" in 267-68 AD. Because these men shared the family name, Marcus Aurelius, a name given to those made citizens by the constitutio Antoniniana, we can understand that these men did not come from the imperial "élite". The third inscription reveals the career of Marcianus, another leading general by the time that Gallienus died. The fourth honors Julius Placidianus, the prefect of the vigiles. While we cannot prove that Heraclianus, Appollinaris, Placidianus, or Marcianus were of Danubian origin themselves, it is clear that none of them were members of the Severan aristocracy, and all of them appear to owe their prominence to their military roles. To these men must be added Marcus Aurelius Aurelianus (the future emperor Aurelian) and Marcus Aurelius Probus (another emperor in waiting), both men of Balkan background, and from families enfranchised in the time of Caracalla.
Although we see a rise in Pannonian, Moesian and Illyrian marshals, and foreigners become notable figures, it would be impractical to think the government could function without help from the traditional classes within the empire. Although their influence was weakened, there were still a number of men with influence from the older aristocracy. Claudius assumed the consulship in 269 with Paternus, a member of the prominent senatorial family, the Paterni, who had supplied consuls and urban prefects throughout Gallienus' reign, and thus were quite influential. In addition, Flavius Antiochianus, one of the consuls of 270, who was an urban prefect the year before, would continue to hold his office for the following year. A colleague of Antiochianus, Virius Orfitus, also the descendant of a powerful family, would continue to hold influence during his father's term as prefect. Aurelian's colleague as consul was another such man, Pomponius Bassus, a member of one of the oldest senatorial families, as was one of the consuls in 272, Junius Veldumnianus.
In his first full year of power, Claudius was greatly assisted by the sudden destruction of the imperium Galliarum. When Ulpius Cornelius Laelianus, a high official under Postumus, declared himself emperor in Germania Superior, in the spring of 269, Postumus defeated him, but in doing so, refused to allow the sack of Mainz, which had served as Laelianus' headquarters. This proved to be his downfall, for out of anger, Postumus' army mutinied and murdered him. Selected by the troops, Marcus Aurelius Marius was to replace Postumus as ruler. Marius' rule did not last long though, as Victorinus, Postumus' praetorian prefect, defeated him. Now emperor of the Gauls, Victorinus was soon in a precarious position, for the Spanish provinces had deserted the Gallic Empire and declared their loyalty to Claudius, while in southern France, Placidianus had captured Grenoble. Luckily, it was there that Placidianus stopped and Victorinus' position stabilized. In the next year, when Autun revolted, declaring itself for Claudius, the central government made no moves to support it. As a result, the city went through a siege, lasting many weeks, until it was finally captured and sacked by Victorinus.
It is still unknown why Claudius did nothing to help the city of Autun, but sources tell us his relations with Palmyra were waning in the course of 270. An obscure passage in the Historia Augusta life of Gallienus states that he had sent an army under Aurelius Heraclianus to the region that had been annihilated by Zenobia. But because Heraclianus was not actually in the east in 268 (instead, at this time, he was involved in the conspiracy of Gallienus' death), we can see that this can not be correct. But the confusion evident in this passage, which also places the bulk of "Skythian" activity during 269 a year earlier, under Gallienus, may stem from a later effort to pile all possible disasters in this year into the reign of the former Emperor. This would keep Claudius' record of being an ancestor of Constantine from being tainted. If this understanding of the sources is correct, it might also be correct to see the expedition of Heraclianus to the east as an event of Claudius' time.
The victories of Claudius over the Goths would not only make him a hero in Latin tradition, but an admirable choice as an ancestor for Constantine, who was born at Naissus, the site of Claudius' victory in 269. Claudius is also held in high esteem by Zonaras, whose Greek tradition seems to have been influenced by Latin. For Zosimus, a more reasoned contemporary view shows him as less grand. Claudius' successes in the year 269 were not continued in his next year as Emperor. As the "Skythai" starved in the mountains or surrendered, the legions pursuing them began to see an epidemic spreading throughout the men. Also, Claudius' unwillingness to do anything at the siege of Autun likely provoked a quarrel with Zenobia.
Although it is not proven that the invasion of Gaul was the breaking point between Claudius and Zenobia, the sequence of events point to the siege as an important factor. The issue at hand was the position that Odaenathus held as corrector totius orientis. Vaballathus, the son of Zenobia, was given this title when Zenobia claimed it for him. From then on, tension between the two empires would only get worse. Aurelius Heraclianus' fabled arrival might have been an effort to reassert central control after the death of Odaenathus, but, if so, it failed. Although coins were never minted with the face of Odaenathus, soon after his death coins were made with image of his son.
Under Zabdas, a Palmyrene army invaded Arabia and moved into Egypt in the late summer. At this time, the prefect of Egypt was Tenagino Probus, described as an able soldier who not only defeated an invasion of Cyrenaica by the nomadic tribes to the south in 269, but also was successful in hunting down "Skythian" ships in the Mediterranean. However, he did not see the same success in Egypt, for a Palmyrene underground, led by Timagenes, undermined Probus, defeated his army, and killed him in a battle near the modern city of Cairo in the late summer of 270.
Generally when a Roman commander is slaughtered it is taken as a sign that a state of war is in existence, and if we can associate the death of Heraclianus in 270, as well as an inscription from Bostra recording the rebuilding of a temple destroyed by the Palmyrene army, then these violent acts could be interpreted the same way. Yet they apparently were not. As David Potter writes, "The coins of Vaballathus avoid claims to imperial power: he remains vir consularis, rex, imperator, dux Romanorum, a range of titles that did not mimic those of the central government. The status vir consularis was, as we have seen, conferred upon Odaenathus; the title rex, or king, is simply a Latin translation of mlk, or king; imperator in this context simply means "victorious general"; and dux Romanorum looks like yet another version of corrector totius orientis" (Potter, 263). These titles suggest that Odaenathus' position, not unlike a king in the Semitic world, was inheritable. In Roman culture, the status gained in procuring a position could be passed on, but not the position itself. It is possible that the thin line between office and the status that accompanied it were dismissed in Palmyrene court, especially when the circumstance worked against the interests of a regime that was able to defeat Persia, which a number of Roman emperors had failed to do. Vaballathus stressed the meanings of titles, because in Palmyrene context, the titles of Odaenathus meant a great deal. When the summer of 270 ended, things were looking very different in the empire than they did a year before. After its success, Gaul was in a state of inactivity and the empire was failing in the east. Insufficient resources plagued the state, as a great deal of silver was used for the antoninianus, which was again diluted.
Religion.
An account written by Aurelius Victor states that Claudius consulted the Sibylline Books prior to his campaigns against the Goths. Hinting that Claudius "revived the tradition of the Decii",
Victor illustrates the senatorial view, which saw Claudius' predecessor, Gallienus, as too relaxed when it came to religious policies.
Links to Constantinian dynasty.
The unreliable "Historia Augusta" reports Claudius and Quintillus having another brother named Crispus and through him a niece, Claudia, who reportedly married Eutropius and was mother to Constantius Chlorus. Some historians suspect this account to be a genealogical fabrication, however, intended to link the family of Constantine I to that of a well-respected emperor.
Saint Valentine.
Claudius Gothicus has been linked to Saint Valentine since the Middle Ages. Contemporary records of his deeds were most probably destroyed during the Diocletianic Persecution on early 4th century and a tale of martydom was recorded in "Passio Marii et Marthae", a work published in the 5th or 6th century. 20th-century historians agree that the accounts from this period are not able to be verified. The legend refers to "Emperor Claudius" but Claudius I did not make any persecution against Christians, so people believe him to be Claudius II even although this emperor spent most of his time warring outside of his territory. The legend was retold in later texts. In the "Nuremberg Chronicle" of 1493 AD, the emperor martyred the Roman priest during a general persecution of Christians. The text states that St. Valentine was beaten with clubs and finally beheaded for giving aid to Christians in Rome. The "Golden Legend" of 1260 AD recounts how St. Valentine refused to deny Christ before the "Emperor Claudius" in 270 AD and as a result was beheaded. Since then, February 14 marks Valentine's Day, a day set aside by the Christian church in memory of the Roman priest and physician.

</doc>
<doc id="44397" url="http://en.wikipedia.org/wiki?curid=44397" title="Defenestrations of Prague">
Defenestrations of Prague

The Defenestrations of Prague (Czech: "Pražská defenestrace", German: "Prager Fenstersturz") were two incidents in the history of Bohemia; there have been more, see below. The first occurred in 1419 and the second in 1618, although the term "Defenestration of Prague" more commonly refers to the later incident. Both helped to trigger prolonged conflict within Bohemia and beyond. Defenestration is the act of throwing someone or something out of a window. 
First Defenestration of Prague.
The First Defenestration of Prague involved the killing of seven members of the city council by a crowd of radical Czech Hussites on 30 July 1419.
Jan Želivský, a Hussite priest at the church of the Virgin Mary of the Snows, led his congregation on a procession through the streets of Prague to the New Town Hall, (Novoměstská radnice) on Charles Square. The town council members had refused to exchange their Hussite prisoners. While they were marching, a stone was thrown at Želivský from the window of the town hall. This enraged the mob and they stormed the town hall. Once inside the hall, the group threw the judge, the burgomaster, and some thirteen members of the town council out of the window and into the street, where they were killed by the fall or dispatched by the mob.
King Wenceslaus IV of Bohemia, upon hearing this news, was stunned and died shortly after, supposedly due to the shock.
The procession was a result of the growing discontent at the contemporary direction of the Church and the inequality between the peasants and the Church's prelates, and the nobility. This discontentment combined with rising feelings of nationalism and increased the influence of radical preachers such as Jan Želivský, influenced by Wycliffe, who saw the current state of the Catholic Church as corrupt. These preachers urged their congregations to action, including taking up arms, to combat these perceived transgressions.
The First Defenestration was thus the turning point between talk and action leading to the prolonged Hussite Wars. The wars broke out shortly afterward and lasted until 1436.
Second Defenestration of Prague.
The Second Defenestration of Prague precipitated the Thirty Years' War.
Background.
In 1555, the Peace of Augsburg had settled religious disputes in the Holy Roman Empire by enshrining the principle of 
"Cuius regio, eius religio", allowing a prince to determine the religion of his subjects. The Kingdom of Bohemia since 1526 had been governed by Habsburg Kings, who did not, however, force their Catholic religion on their largely Protestant subjects. In 1609, Rudolf II, Holy Roman Emperor and King of Bohemia (1576–1612), increased Protestant rights. He was increasingly viewed as unfit to govern, and other members of the Habsburg dynasty declared his younger brother, Matthias, to be family head in 1606. Matthias began to gradually wrest territory from Rudolf, beginning with Hungary. In order to strengthen his hold on Bohemia, Rudolf in 1609 issued the "Letter of Majesty", which granted Bohemia's largely Protestant estates the right to freely exercise their religion, essentially setting up a Protestant Bohemian state church controlled by the estates, "dominated by the towns and rural nobility". Upon Rudolf's death, Matthias succeeded in the rule of Bohemia (1612–1619) and extended his offer of more legal and religious concessions to Bohemia, relying mostly on the advice of his chancellor, Bishop Melchior Klesl.
Conflict was precipitated by two factors: Matthias, already aging and without children, made his cousin Ferdinand of Styria his heir and had him elected king in 1617. Ferdinand was a proponent of the Catholic Counter-Reformation and not likely to be well-disposed to Protestantism or Bohemian freedoms. Bohemian Protestants opposed the royal government as they interpreted Letter of Majesty to extend not only to the land controlled by the nobility or self-governing towns but also to the King's own lands. Whereas Matthias and Klesl were prepared to appease these demands, Ferdinand was not, and in 1618 forced the Emperor to order the cessation of construction of some Protestant chapels on royal land. When the Bohemian estates protested against this order, Ferdinand had their assembly dissolved.
The Defenestration.
On May 23, 1618, four Catholic Lords Regent, Count Jaroslav Borzita z Martinic, Count Vilem Slavata of Chlum, Adam II von Sternberg (who was the supreme burgrave), and Matthew Leopold Popel Lobcowitz (who was the grand prior), arrived at the Bohemian Chancellory at 8:30 am. After preparing the meeting hall, members of the dissolved assembly of the three main Protestant estates gathered at 9:00 am, led by Count Thurn, who had been deprived of his post as Castellan of Karlstadt by the Emperor. The Protestant Lords' agenda was to clarify whether or not the four regents present were responsible for persuading King Matthias to order the cessation of churches on royal land. According to Martiniz himself:
Lord Paul Rziczan read aloud... a letter with the following approximate content: His Imperial Majesty had sent to their graces the lord regents a sharp letter that was, by our request, issued to us as a copy after the original had been read aloud, and in which His Majesty declared all of our lives and honour already forfeit, thereby greatly frightening all three Protestant estates. As they also absolutely intended to proceed with the execution against us, we came to a unanimous agreement among ourselves that, regardless of any loss of life and limb, honour and property, we would stand firm, with all for one and one for all... nor would we be subservient, but rather we would loyally help and protect each other to the utmost, against all difficulties. Because, however, it is clear that such a letter came about through the advice of some of our religious enemies, we wish to know, and hereby ask the lord regents present, if all or some of them knew of the letter, recommended it, and approved of it.
Before the regents gave any answer, they requested that the Protestants give them the opportunity to confer with their superior, Adam von Waldstein, who was not present. If they were given the opportunity, the Protestants would get an official answer to their grievance by the next Friday (this was taking place on the eve of Ascension Day and they all must observe the holy day). The Protestants demanded an immediate answer. Two regents, Adam II von Sternberg and Matthew Leopold Popel Lobcowitz, were declared innocent by the Protestant Estate holders and too pious to have any responsibility in the letter's creation. They in turn were removed from the room; however, before leaving, Adam II von Sternberg made it clear that they "did not advise anything that was contrary to the Letter of Majesty". This left only Count Vilem Slavata of Chlum, Count Jaroslav Borzita of Martinice (who had replaced Thurn as Castellan), known Catholic hard-liners, and Philip Fabricius the secretary to the Regents. They eventually claimed responsibility for the letter and, assuming they were only going to be arrested, welcomed any punishment the Protestants had planned.
Count von Thurn turned to both Martiniz and Slavata and said "you are enemies of us and of our religion, have desired to deprive us of our Letter of Majesty, have horribly plagued your Protestant subjects... and have tried to force them to adopt your religion against their wills or have had them expelled for this reason". Then to the crowd of Protestants, he continued "were we to keep these men alive, then we would lose the Letter of Majesty and our religion... for there can be no justice to be gained from or by them". Soon after, the two Regents were thrown out of the third floor window along with the Regents' secretary, Philipus Fabricius, but survived after falling 70 ft. Catholics maintained the men were saved by angels or by the intercession of the Virgin Mary, who caught them; later Protestant pamphleteers asserted that they survived due to falling onto a dung heap, a story unknown to contemporaries and probably coined in response to divine intervention claims. Philip Fabricius was later ennobled by the emperor and granted the title "Baron von Hohenfall" (literally "Baron of Highfall").
Aftermath.
Immediately after the Defenestration, the Protestant estates and Catholic Habsburgs started gathering allies for war. After the death of Matthias in 1619, Ferdinand II was elected Holy Roman Emperor. At the same time, the Bohemian estates deposed him as King of Bohemia and replaced him with Frederick V, Elector Palatine, a leading Calvinist and son-in-law of the protestant James VI and I, King of Scotland, England and Ireland.
Because they deposed a properly chosen king, the Protestants could not gather the international support they needed for war. Just two years after the Defenestration, Ferdinand and the Catholics regained power in the Battle of White Mountain on November 8, 1620. This became known as the first battle in the Thirty Years' War.
There was plundering and pillaging in Prague for weeks following the Battle. Several months later, twenty-seven nobles and citizens were tortured and executed in the Old Town Square. Twelve of their heads were impaled on iron hooks and hung from the Bridge Tower as a warning. This also contributed to catalyzing the Thirty Years' War.
Further defenestrations.
More events of defenestration have occurred in Prague during its history, but they are not usually called "defenestrations of Prague".
A defenestration (chronologically the second defenestration of Prague, sometimes called "one-and-halfth defenestration") happened on 24 September 1483, when a violent overthrow of the municipal governments of the Old and New Towns ended with throwing the Old-Town portreeve and the bodies of seven killed aldermen out of the windows of the respective town halls.
Sometimes, the name "the third defenestration of Prague" is used, although it has no standard meaning. For example, it has been used to describe the death of Jan Masaryk, who was found below the bathroom window of the building of the Czechoslovak Ministry of Foreign Affairs on 10 March 1948. The official report listed the death as a suicide. However, it was widely believed he was murdered, either by the nascent Communist government in which he served as a non-partisan Foreign Minister, or by the Soviet secret services. A Prague police report in 2004 concluded after forensic research that Masaryk had indeed been thrown out the window to his death. This report was seemingly corroborated in 2006 when a Russian journalist claimed that his mother knew the Russian intelligence officer who threw Masaryk out the window.
References.
An English translation of part of Slavata's report of the incident is printed in Henry Frederick Schwarz, "The Imperial Privy Council in the Seventeenth Century" (Cambridge, Mass.: Harvard University Press, 1943, issued as volume LIII of "Harvard Historical Studies"), pp. 344–347.

</doc>
<doc id="44399" url="http://en.wikipedia.org/wiki?curid=44399" title="Conrad II, Holy Roman Emperor">
Conrad II, Holy Roman Emperor

Conrad II (c. 990 – 4 June 1039), also known as Conrad the Elder, was Emperor of the Holy Roman Empire from 1027 until his death in 1039. The founder of the Salian dynasty of emperors, Conrad also served as King of Germany from 1024, King of Italy from 1026, and King of Burgundy from 1033.
The son of a mid-level nobleman in Franconia, Count Henry of Speyer and Adelaide of Alsace, he inherited the titles of count of Speyer and of Worms as an infant when his father died. Conrad extended his power beyond his inherited lands, receiving the favor of the princes of the Kingdom of Germany. When the Saxon-based Ottonian dynasty of emperors died off with the childless Emperor Henry II, Conrad was elected to succeed him as King in 1024 at the age of 34. Conrad founded his own dynasty of rulers, known as the Salian dynasty, which ruled the Holy Roman Empire for over a century.
Conrad continued the policies and achievements of the Ottonian Henry II regarding the Catholic Church and the affairs of Italy. Conrad continued to build the Church as a center for imperial power, preferring to appoint church bishops over secular lords to important posts across the Empire. Like Henry II before him, Conrad also continued a policy of benign neglect over Italy, especially for the city of Rome. His reign marked a high point of the medieval imperial rule and a relatively peaceful period for the Empire. Following the death of the childish King Rudolph III of Burgundy in 1032, Conrad claimed dominion over the Kingdom of Arles and incorporated it into the Empire. The three kingdoms (Germany, Italy, and Burgundy) formed the basis of the Empire as the "royal triad" ("regna tria").
Early life.
Family background.
The Salian dynasty has its origins with Count Werner V of Worms, a mid-level Frankish noble from Germany's Duchy of Franconia east of the Rhine River. His son, Conrad the Red, succeeded him as Count in 941 and King Otto I of Germany (the future Holy Roman Emperor) appointed him as Duke of Lorraine in 944. He was subsequently married to Liutgarde, one of Otto's daughters, in 947 and became one of the king's closest allies. The relationship was strained, however, when Otto refused to honor a peace treaty Conrad, as Otto's representative, had conducted with the rebellious Berengar II of Italy. Conrad also resented the growing influence of Otto's brother Henry I of Bavaria, which he saw as threatening his own power. In 953 Conrad joined the king's son Liudolf in rebellion against Otto, but the rebellion was defeated and Conrad was stripped of his duchy. Conrad and Otto were soon reconciled, with Conrad fighting for Otto in the great Battle of Lechfeld in 955. Though the Germans were successful in halting the Hungarian invasions of Europe, Conrad lost his life in the battle. Conrad was succeed as Count of Worms in 956 by his son Otto of Worms, a grandson of Otto I. Sometime between 965 and 970 Otto of Worms' oldest son, Henry of Speyer, was born. Little is known of his life as he died the age of 20 between 985 and 990. Conrad II's father was Henry of Speyer, and his mother was Adelaide of Alsace, an area of Upper Lorraine. After Henry's death, Adelaide married a Frankish nobleman. After her remarriage, Adelaide demonstrated no close relationship with her son.
In 978 Emperor Otto II appointed his nephew Otto of Worms as Duke of Carinthia after deposing the rebellious Duke Henry I of Carinthia during the War of the Three Henries. Upon receiving the ducal title, however, Otto lost his position at Worms, which was given to Bishop Hildebald, Otto II's imperial chancellor. When Otto II died suddenly in 983, his infant son Otto III succeeded him, with his mother Theophanu serving as regent. Theophanu sought to reconcile the imperial house with Henry I, restoring him as Duke of Carinthia in 985, with Otto of Worms allowed to regain his ancestral position as Count of Worms. However, Otto was allowed to style himself "Duke of Worms" and his original territory was expanded so as not to diminish his rank. Otto of Worms remained loyal to the new Emperor, receiving rulership of the March of Verona in 955, though the actual Duchy of Carinthia passed to Henry IV of Bavaria. In 996, Otto III appointed Otto of Worms's son Bruno as Pope Gregory V. When Emperor Otto III died in 1002, both Otto of Worms, Conrad's grandfather, and Henry IV were candidates for election as King of Germany. In a compromise, Otto withdrew and received the Duchy of Carinthia from the newly elected Henry IV, who ruled as "Henry II of Germany", in return. As a result, Otto of Worms renounced his holdings in Worms to Bishop Burchard of Worms, a long-time political rival. Buchard assumed care for Conrad, providing his education and upbringing by 1000.
After the early death of his uncle Duke Conrad I of Carinthia, the elder Conrad's infant son, Conrad the Younger, was named Count of Worms by Emperor Henry II while the Duchy of Carinthia passed to Adalbero of Eppenstein due to Conrad the Younger's infancy. Conrad the Younger was placed in Conrad's care.
Adulthood.
Conrad married Gisela of Swabia, a twice widowed duchess, in 1016. Gisela was the daughter of Duke Herman II of Swabia who, in 1002, unsuccessfully claimed the German throne following Emperor Otto III's death, losing the election to Emperor Henry II. Gisela was first married to Count Bruno I of Brunswick the same year. Following Bruno's death around 1010, Gisela married Ernest I of the House of Babenberg. By the marriage, Ernest I inherited the Duchy of Swabia at the death of Gisela's brother Duke Herman III of Swabia in 1012. This marriage produced two sons: Ernest II and Herman. After the death of Ernest I in 1015, Emperor Henry II named Ernest II as Duke of Swabia. As Gisela's new husband, Conrad hoped to serve as regent for his minor stepson in the administration of the duchy, seeing it as an opportunity to increase his own rank and subsequently make a claim for his own duchy. Emperor Henry II blocked this attempt by placing the guardianship of Ernest II, and regency over Swabia, in the hands of Archbishop Poppo of Trier in 1016. This action further strained the already rough relationship between the imperial House of Otto and the Salian family.
Conrad II's hopes of obtaining his own duchy failed, but his marriage to Gisela brought him wealth. Her mother, Gerberga of Burgundy, was the daughter of reigning Burgundian King Conrad of Burgundy and granddaughter of the late Frankish King Louis IV. Gisela also claimed descent from Charlemagne through both her mother and her father. The marriage was problematic because of the familial relationship shared by Gisela and Conrad: both were descendants of Ottonian King Henry I, Henry in the fifth generation and Gisela in the fourth. According to canon law, marriage was not allowed among relatives of the first to seventh generations. Though Conrad's marriage differed little from the usual practice of the time, strict canonists took exception to the marriage and Emperor Henry II used this breach of canonical law to force Conrad into temporary exile. During this exile, Gisela bore Conrad a son, Henry III, on October 28, 1017. Conrad and Emperor Henry II were eventually reconciled, allowing him to return to Germany.
Reign as King.
Royal election.
Emperor Henry II died in 1024. Childless, Henry's death brought the Ottonian dynasty, which had ruled Germany since 919, to an end. Without a clear successor as King of Germany, Henry's widow Cunigunde of Luxembourg served as regent while the German dukes gathered to elect a new king. Cunigunde was assisted by her brothers Bishop Dietrich I of Metz and Duke Henry V of Bavaria. Archbiship Aribo of Mainz, the Primate of Germany, also assisted Cunigunde.
On September 4, 1024, the German princes gathered at Kamba, an historical name for an area on the east banks of the river Rhine River opposite the German town Oppenheim. (Today the position of Kamba is marked by a small monument, which displays Conrad on a horse.) Archbishop Aribo served as the assembly's president. Conrad presented himself before the assembly as a candidate for election, as did his younger cousin Conrad the Younger. Both were descendants from Emperor Otto I by their common grandfather Otto of Worms from his mother Liutgarde, one of Otto's daughters. Although other extended members of the Ottonian dynasty existed, none were seriously considered for election. The chronicler Wipo of Burgundy, Conrad's chaplain, attended the meeting and recorded the election. The Duchy of Saxony adopted a neutral strategy while the Duchy of Lorraine favored the younger Conrad. A majority of the assembled princes favored the elder Conrad, whose seven-year-old son ensured a stable dynasty for the kingdom. As president of the assembly, Archbishop Aribo cast the first vote and supported the elder Conrad. He was joined by the other clergy in supporting the elder Conrad. The secular dukes then cast their votes for the elder Conrad as well. Only Archbishop Pilgrim of Cologne, Duke Gothelo I of Lower Lorraine, and Duke Frederick II of Upper Lorraine refused to support him.
Conrad was crowned King of Germany by Archbishop Aribo in Mainz Cathedral on September 8, 1024 at the age of 34. To mark his election, Conrad commissioned the construction of the Speyer Cathedral in Speyer, near his ancestral home of Worms. Construction began in 1030. Archbishop Aribo, as Archbishop of Mainz, was already the chancellor of Germany. Conrad wanted to reward Archbishop for his electoral support, so he made Aribo chancellor of Italy as well, making Aribo the second most powerful man in the Holy Roman Empire as the Imperial Chancellor. Aribo refused to crown Conrad's wife Gisela as queen due to the violation of canon law. Conrad refused to accept Archbishop Aribo's position. Archbishop Pilgrim of Cologne saw the situation as an opportunity to restore his relationship with the king, after refusing to support Conrad's election, and Archbishop Pilgrim crowned Gisela queen on September 21, 1024. The political reorientation of Pilgrim also weakened the opposition towards the new king.
Early reign.
Conrad inherited a kingdom troubled by numerous problems. The duchies of Saxony and Lorraine were in opposition to his rule, as well as his cousin Conrad of Carinthia. To secure his reign, Conrad went on a tour of Germany, making stops in Augsburg to receive the support of Bishop Bruno, and at Strasbourg to receive the support of Bishop Werner, the brothers of the late Emperor Henry II. Both were appointed to high-ranking offices at Conrad's court. Traveling from Cologne to Aachen, the site of Charlemagne's old capital, Conrad continued the tradition of claiming the right to rule Germany as successor to Charlemagne. Despite the continuance of this Ottonian tradition, the Duchy of Lorraine still did not accept his rule. Conrad then traveled north to Saxony, visiting Abbess Adelaide I of Quedlinburg and Abbess Sophia I of Gandersheim, both daughters of the late Ottonian Emperor Otto II. Their support of Conrad's rule greatly influenced the Saxony nobility. Celebrating Christmas at Minden, the Saxon nobles, led by Duke Bernard II, recognized Conrad as their king after he promised he would respect Saxon law. Conrad and Gisela would remain in Saxony during the winter until March 1025. Upon leaving Saxony, Conrad traveled to the Duchy of Swabia, celebrating Easter at Augsburg. He then traveled to the Duchy of Bavaria to celebrate Pentecost at Regensburg. Conrad next traveled to Zurich near the German-Burgundian border. In 1016, Emepror Henry II forced the childless Burgundian King Rudolph III to name him as his heir. With Henry's death in 1024, Conrad claimed the same rights over Burgundy. This ended his tour of Germany, visiting all major regions of the kingdom within ten months of his election.
Conrad had to address the longstanding "Gandersheim Conflict" upon assuming the German throne. The forty-year conflict stretched back to 989, during the reign of Emperor Otto III, over control of Gandersheim Abbey and its estates. Both the Archbishop of Mainz and the Bishop of Hildesheim claimed authority over the Abbey, including the authority to anoint the Abbey's nuns. Though Otto III eased the tensions between the parties by declaring that both bishops would anoint the Abbess, the conflict continued. Archbishop Aribo of Mainz, the new Primate of Germany, sought to overturn this precedent. Conrad was indebted to Aribo for his support during the royal election and worked to support his ally. In January 1027, the king called a synod at Frankfurt to resolve the dispute, but a conclusion was not reached. Conrad called a second synod in September 1028, which likewise failed to find a solution. Only a third synod in 1030 ended the conflict when Bishop Gotthard of Hildesheim renounced his claims to the monastery in favor of Aribo.
During his travel to Augsburg, a conflict broke out between Conrad and his younger cousin Conrad the Younger. The reasons for the rebellion are not recorded, but the younger Conrad claimed he did not receive some compensation the king promised him for withdrawing from the 1024 election.
Unrest in Italy.
In Bavaria, Conrad was brought into contact with the Italian ruling elite for the first time. In June 1025, Archbishop Aribert of Milan, and other bishops from Northern Italy, traveled north over the Alps to pay homage to Conrad. In exchange for certain privileges in the governing of Italy, Aribert agreed to crown Conrad with the Iron Crown of Lombardy. The situation in Italy was unstable after the death of the Henry II. The secular nobles believed the Italian throne to be vacant, not accepting Conrad's automatic succession as a matter of right. Instead, the secular nobles offered the Italian crown to the Capetian King Robert II of France and his son Hugh Magnus. After he rejected the offer, the secular lords approached Duke William V of Aquitaine. Though initially excited by the offer, William V subsequently rejected it as well.
In addition to the ecclesiastical mission, secular Italian nobles from Pavia also traveled north to Conrad. While Conrad's election did not meet significant obstacles north of the Alps, in Italy, in the aftermath of the death of Emperor Henry II, there were several riots, and some Italian nobles attempted to separate the Kingdom of Italy from the Holy Roman Empire. When the news spread of Henry's death, the citizens of Pavia revolted, destroying the imperial palace, which dated to the Ostrogothic King Theodoric the Great during the 5th century. Though Pavia had lost is position as the seat of royal administration in Italy under the Ottonian dynasty, the palace had been a great symbol of imperial authority in Italy. Pavia, thanks to its strategic location situated on the trade routes from Italy to Burgundy and France, had become an important commercial center. Traders of the lower nobility demanded greater autonomy from imperial control. The nobility saw the mere presence of the imperial palace within the city walls intolerable.
Ambassadors from Pavia traveled north to meet with the German king. According to Conrad's personal cleric Wipo, the Italian kingship was not "durable" with the German throne but instead a mere "personal union". Italy was a separate nation from Germany with its own identity, not a permanent political union. They tried to justify the actions of their fellow citizens, claiming that Pavia had always been loyal to the Italian king, as long as the king was alive, and that the revolt had taken place when the Italian throne was vacant. Therefore, the burning of the palace should be excused. Conrad rejected their argument, however, saying that just as a ship remains after the death of its captain, the Empire remains after the death of the Emperor. The kingship of Italy, according to Conrad, belonged to him as king of Germany as a matter of legal right. Conrad also declared that the palace was property of the Empire, not of the old king, and therefore the new king had the right to punish those responsible. The secular nobles returned to Italy in opposition to Salian rule.
In February 1026, Conrad assembled an army of thousands of armored knights for an expedition into Italy, including troops commanded by both Archbishop Aribo of Mainz and Archbishop Pilgrim of Cologne. Conrad's army marched south, besieging Pavia, but the city walls blocked the attackers. Conrad decided to leave a contingent of soldiers to keep the city under siege, blocking all trade in the area, and continued his campaign. By March 1026, Conrad arrived in Milan and was crowned with the Iron Crown of the Lombards by Archbishop Aribert of Milan as King of the Lombards. From Milan, Conrad traveled to Vercelli, where he celebrated Easter with the aged Bishop Leo of Vercelli, who had been a chief advisor to the late Emperor Otto III. When Leo died a few days later, Archbishop Aribert became the chief supporter of the Salian dynasty in Italy. With Conrad's assistance, Aribert became highest ranking religious figure in Italy and oversaw the expansion of the Basilica of Sant'Ambrogio in Milan. In June 1026, Conrad marched with his army to Ravenna, but quartering his soldiers alongside the Ravennese population caused tension in the city. Conrad marched north to mitigate the risk the summer heat posed to his army. In autumn Conrad left his summer camp in the Po valley and marched to the Burgundian border. Conrad then celebrated Christmas at Ivrea. By the end of winter, the secular nobles of Italy voluntarily ended their opposition to Conrad's reign. Pavia, however, remained in revolt until early 1027 when Abbot Odilo of Cluny brokered a peace deal between the city and Conrad.
Reign as Emperor.
Imperial coronation.
On March 26, 1027, Pope John XIX crowned Conrad and his wife Gisela as Emperor and Empress, respectively, in Old Saint Peter's Basilica in Rome. The coronation was attended by Cnut the Great, King of England, Denmark and Norway, Rudolph III of Burgundy and 70 high-ranking clerics, including the Archbishops of Cologne, Mainz, Trier, Magdeburg, Salzburg, Milan, and Ravenna. Conrad's son and heir Henry also attended. Rudolph's attendance marked an improvement in the relationship between Burgundy and the Holy Roman Empire. During the seven-day coronation ceremony, a rank dispute between the archbishops of Milan and Ravenna arose, with Conrad deciding in favor of Milan. Following the synod, Conrad traveled south to receive homage from the southern Italian states of Principality of Capua, the Principality of Salerno, and the Duchy of Benevento.
After his coronation, Conrad issued decrees to reorganize the monasteries and dioceses of Italy with the particular goal of bringing the church at Venice under Imperial control (see the "Schism of the Three Chapters"). On April 6, 1027, at a synod held in the Lateran Basilica with Pope John XIX, the Emperor resolved the dispute in favor of Old-Aquileia. The Patriarch of Aquleai Poppo had been a loyal supporter of Emperor Henry II, who appointed him as Patriarch in 1020 during the Emperor's campaign to reassert his authority in Italy. Conrad's action placed the church at Grado under Poppo's authority, securing Poppo's loyalty by making him the Emperor's to official in northern Italy. The synod ended the independence of the Grado church and limited the political autonomy of Venice. In so doing, Conrad broke with the policies of his predecessors and revoked Venice's privileged trading status.
Toward the end of May 1027, Conrad returned north to Germany to attend the funeral of Duke Henry V of Bavaria at Regensburg. With the Duchy of Bavaria left vacant, Conrad asserted his right to name a next duke as a matter of royal prerogative, taking the unprecedented decision of naming his 10-year-old son Henry as Duke of Bavaria despite the existence of candidates with a better claim to the Duchy. Never before had the Bavarian Duchy passed to a non-member of the Bavarian ducal family. The young prince assumed the Bavarian dignity on June 24, 1027. Following Henry's appointment, Conrad held court at Regensburg and issued a decree requiring an accounting of all imperial property in the duchy. This required the various counts and bishops to report to Conrad all property they possessed in their castles and abbeys that belonged to the Emperor. Even the Dowager Empress Cunigunde of Luxembourg was required to report to Conrad, with the Emperor even claiming Cunegonde's "wittum" (money and property left to her by her late husband Emperor Henry II) as belonging to him. Conrad's promotion of imperial authority over the ducal succession and his claims to property throughout Bavaria caused tension between him and the German aristocracy, who viewed Conrad's actions as infringing upon their privileges.
Uprising in Swabia.
In 1025, Duke Ernest II of Swabia, Conrad's stepson from his marriage to Gisela of Swabia, rebelled against his stepfather when he was elected king of Germany. By 1026, Conrad had defeated the resistance and Ernest submitted to his reign. Due to the intervention of his mother Gisela, Ernest was allowed to accompany Conrad on his expedition to Italy in 1026. During the expedition, the rebellion led by Conrad of Carinthia and Count Welf II of Swabia continued. Conrad had named Bishop Bruno of Augsburg regent of Germany while he marched south to Italy. When Bruno was defeated by the rebels, Conrad sent Ernest back to Germany in September 1026 to end the revolt. When Ernest returned, he joined the opposition and rebelled against Conrad again. 
Conrad returned to Germany in 1027, after being crowned Emperor, and held court at Augsburg in Swabia, calling upon the rebels to surrender. Ernest, trusting in the number and fidelity of his vassals, rejected the peace officer, and appealed to his Swabian counts to join him in rebellion. According to Wipo of Burgundy, the counts refused, stating that while they had sworn loyalty to Ernest, but they would not rebel against their Emperor. Without the support of the Swabian counts, Ernest, Conrad of Carinthia and Count Welf submitted to Conrad at Worms on September 9, 1027, ending the rebellion. Conrad stripped Ernest of his ducal title and imprisoned him at Giebichenstein Castle in Saxony. Gisela supported Conrad against her son, but did not want Ernest to be entirely humiliated. As a result of his mother's intervention, Conrad allowed Ernest to retain his title while imprisoned, with Gisela serving as regent over the duchy.
In 1028, after Conrad's son Henry was crowned as King of Germany, Gisela again intervened on Ernest's behalf. Conrad pardoned Ernest and released him from prison in 1028, but Gisela retained regency over Swabia. Ernest served as duke in name only. On Easter 1030, Conrad offered to restore Ernest his full powers as Duke of Swabia if he would crack down on the Emperor's enemies there. Ernest's refusal, especially against his friend Count Werner of Kyburg, resulted in his final downfall. Conrad stripped his stepson of his title, declared him a public enemy, and had him excommunicated. Even his mother Gisela did not come to his rescue. Within a few months, both Ernest and Werner were killed in battle against the Bishop of Constance near Falkenstein Castle in the Black Forest. The fall of Ernest greatly weakened the independence of Swabia. Conrad named Ernest's younger brother Herman as the new Duke. Herman was a minor, so Conrad named the Bishop of Constance regent. Eight years later in 1038, Herman was dead and Conrad named his own son Henry as duke, securing imperial control over the duchy.
Conflict with Adalbero.
Conrad had to enforce his royal prerogatives in the Duchy of Carinthia and the Duchy of Swabia. Duke Adalbero of Carinthia had been appointed as duke in 1012 under Emperor Henry II and remained loyal to imperial authority, supporting Conrad's election as German king in 1024. At a synod in Frankfurt in September 1027, Conrad attempted to resolve the decades' long "Gandersheim Conflict". Adalbero accompanied the Emperor and acted as his sword-bearer during the proceeding, indicating Conrad's trust in him. From 1028 on, Adalbero governed his Duchy as an independent state. In particular, he attempted to conduct peaceful relations with the King Stephen I of the Kingdom of Hungary. Under Emperor Henry II, who was the brother-in-law to Stephen, relations between the Empire and Hungary had been friendly. Upon Henry's death in 1024, Conrad adopted a more aggressive policy, prompting border raids into the Empire from Hungary. The raids particularly affected Adalbero's domain of Carinthia, which shared a long border with eastern border with Hungary.
Conrad summoned Adalbero to court at Bamberg on May 18, 1035, to answer an indictment of treason for his actions regarding Hungary. In the presence of the German dukes, Conrad demanded that Adalbero be stripped of all his titles and lands. The dukes hesitated and demanded that Conrad's son Henry, the Germany's co-King and Conrad's designated successor, join the assembly before a decision was made. Henry refused to depose Adalbero, citing an earlier agreement with Adelbero to be his ally in negotiating a settlement between him and his father. Conrad resorted to exhortations, pleas, and threats to convince Henry to support Adalbero's deposition. Henry's support was soon followed by that of the other dukes. Conrad then ordered Adalbero to be removed as Duke and sentenced him and his son to exile. After attacking Conrad's allies in Carinthia, Adalbero fled to his mother's estates in Ebersberg in the Duchy of Bavaria, where he remained until his death in 1039.The duchy of Carinthia remained unoccupied until February 2, 1035, when Conrad named his cousin Conrad the Younger as the new duke. With the appointment, the three southern German duchies of Swabia, Bavaria, and Carinthia were all under the control of Emperor Conrad through his family members (his stepson Herman in Swabia, his son Henry in Bavaria, and his cousin Conrad in Carinthia).
Control of the southern duchies allowed Conrad to continue the process begun under the Ottonian dynasty, centralizing the Emperors authority over the Empire at the expense of the regional dukes. Conrad broke with Ottonian tradition, however, in favoring a more strict means of controlling rebellious vassals. Whereas the Ottonians followed a policy of informal public submission and subsequent reconciliation, Conrad used treason trials to declare rebels as "public enemies" to legitimize his subsequent harsh treatment, as he had done with Ernest II of Swabia and Adalbero. The nobles saw use of these treason trials not as mere power shifts in favor of the Emperor, but as a cruel breach of German tradition.
Policy towards the Church.
Conrad continued the Ottonian dynasty's policy of using the German Church as a vehicle for imperial control. Beginning in the 950s, the Ottonians had favored Church officials over secular nobles for appointment to the Empire's most important offices. Claiming "divine right" to rule the Empire, the Ottonians increasingly viewed themselves as protectors of the Church and thus demanded loyalty from the Church officials. In return, the various bishoprics and abbeys of the Empire were granted extensive landholdings and secular authority, providing immunity from the jurisdiction of the secular nobles. As such, the Church officials reported exclusively to the Emperor, acting as his personal vassals. As the Emperor's vassals, the Church officials were subject to providing two services to him: the "servitium regis" (royal service) and "servitium militum" (military service). Under royal service, the bishops and abbots were required to provide hospitality and accommodations to the Emperor and his court when he arrived. It also required the Church officials to act as quasi-bureaucracy for the Empire. Under military service, the Church was required to supply soldiers for the Emperors' army or to act as diplomats at his direction. Conrad energetically continued this tradition.
In his biography of Conrad, the chronicler Wipo of Burgundy stated the promotion of the Church was of little value to the Emperor. Conrad and the other members of the Salian dynasty had little interest in the founding of new monasteries. Through their hundred-year dynasty, the Salians only founded one: [Limburg Abbey]] which was converted from a fortress to a monastery in 1025. The Ottonians established at least eight in their hundred-year reign. Additionally, the Ottonians were active in the establishment of Church affairs, but Conrad was uninterested, only calling five synods during his reign and usually only to restore peace. Conrad's decisions on Church policy were often left to his wife Gisela of Swabia. When Archbishop Aribo of Mainz, Primate of Germany, died in 1031, Conrad considered both Abbot Bardo of Hersfeld Abbey and the renowned theologian Wazo of Liège, then serving as the dean of the cathedral chapter for the Bishop of Liege. Though Conrad favored Wazo to lead the German Church as Archbishop and Primate, Gisela convinced him to appoint Bardo instead.
Relations with Poland.
War with Mieszko.
Duke Bolesław I of Poland warred with Emperor Henry II three times during the German-Polish Wars from 1002 to 1018. In January 1018, Henry II and Bolesław I signed a peace treaty, known as the Peace of Bautzen, in which the Empire and Poland declared a permanent peace with Bolesław recognizing Henry II as his nominal feudal lord. In return, Henry II granted to Bolesław lands on the Empire's eastern border. To seal the peace, Bolesław I, a widower, reinforced his dynastic bonds with the German nobility by marrying Oda of Meissen, daughter of the Saxon Margrave Eckard I of Meissen. Empire and Poland remained at peace for the remainder of Henry's reign. Henry's death in 1024 gave Bolesław an opportunity to increase his own power. Bolesław took advantage of the interregnum in Germany and crowned himself king on Easter, April 25, 1025. Bolesław was thus the first Polish king as his predecessors had been considered mere "dukes" by both the Empire and the Pope in Rome. Bolesław died within two months of the coronation, most likely due to an illness. Bolesław's son, Mieszko II Lambert, succeeded him as King, being crowned on Christmas Day 1025. Upon assuming the Polish throne, Mieszko expelled his older half-brother Bezprym and his younger brother Otto Bolesławowic. Otto went to Germany to seek Conrad's protection.
Conrad considered the assumption of the title "king" by Mieszko an act of war and a disregard of his imperial authority, but had to address domestic issues before marching against Mieszko. In 1026 Conrad II marched into Italy to assert German authority south of the Alps and to claim the imperial crown from the Pope. In his absence, Duke Ernest II of Swabia, Conrad the Younger, and Duke Frederick II of Upper Lorraine rebelled against his authority. The rebels sought the support of Mieszko, which the Polish king granted and promised to take military action against Conrad. Conrad returned to Germany in mid-1027, putting an end to the rebellion before Mieszko could marshal his forces. In preparations for his own invasion of Poland, Conrad developed a closer relationship with Cnut, King of England and Denmark (whose kingdom lay along the Empire's northern border). Cnut accompanied Conrad to his coronation as emperor in 1027, and Conrad granted authority over the March of Schleswig, the land-bridge between Denmark and Germany.
Fearing a joint German-Danish attack, Mieszko invaded the Empire's March of Lusatia and the territory of the Lutician Federation in 1028. The Lutici were a federation of West Slavic Polabian tribes that developed in the 10th century. Located on the northeast border of Germany, the Lutici were the regular target of German aggression during the early years of the Ottonian dynasty with Emperor Otto I's lieutenants Herman Billung and Gero, subjugating many of the Slavic tribes beginning in the 940s. In 983, as part of the Great Slav Rising, the Lutici initiated an open rebellion. In the ensuing war (983-995), the Lutici succeeded in reclaiming their independence and gained control of the Billung March and Northern March from the Empire. Though Emperor Otto III allied with Duke Bolesław I of Poland to reintegrate them into the Empire, Otto III's death ended the friendly relationship between Poland the Empire. Instead, Bolesław competed with Otto III's successor, Emperor Henry II, for dominion over the Lutici, causing Henry II to ally the Empire with the Lutici against Poland. Under the Peace of Bautzen in 1018, all three parties remained in uneasy peace, with Poland allowed to hold the Empire's Margraviate of Meissen. Of the eastern marches, the Empire only retained the March of Lusatia. Mieszko's 1028 invasion ended the peace. The Lutici sent ambassadors to seek Conrad's protection against Mieszko, which Conrad granted and renewed the German-Lutician alliance.
Seeking to protect the Lutici from Polish invasion, Conrad launched a counter-invasion in 1029 and placed the Polish-held Bautzen under siege. Faced with a potential invasion by Hungary and the failure of the Lutici to provide their promised contingent of troops, Conrad retreated. In 1030, Poland secured an alliance with Hungary, with Stephen I invading Bavaria while Mieszko invaded Saxony. Conrad responded by allying with Yaroslav the Wise, Grand Prince of Kiev, to attack and capture Red Ruthenia on Poland's eastern border. In 1031, Conrad concluded a peace treaty with Hungary by ceding territory in eastern Carinithia to Hungarian control. Freed from the threat of Hungarian attack, the Emperor was able to focus his attention on attacking Poland. Marching on Mieszko in autumn 1031, Conrad laid siege at the Polish held-Bautzen in the Margraviate of Meissen. Mieszko's authority was shaken by the German and Kieven invasions, and the rebellion led by his exiled brother Bezprym. Mieszko surrendered to Conrad in fall 1031. Under the Treaty of Merseburg, Mieszko returned control over the Margraviate of Meissen and the March of Lusatia to the Empire.
Treaty of Merseburg.
Soon after Mieszko concluded peace with the Empire, he was deposed by his half-brother Bezprym. When Mieszko assumed the Polish throne in 1025 he exiled his brother, who fled to the protection of Kievan Rus to the east of Poland. With Meiszko's position weakened by his wars with the Empire, Bezprym, supported by Conrad, persuaded the Kevian Grand Price Yaroslav I the Wise to invade Poland and install Bezprym as the country's ruler. The Kievan invasion was a success. Mieszko fled to the Duchy of Bohemia where he was imprisoned and castrated by Duke Oldrich in retribution for Mieszko's father Bolesław's blinding Duke Boleslaus III, Oldrich's brother, thirty years earlier. Shortly after taking power, Bezprym sent the Polish royal crown and regalia to Conrad, officially renouncing the title "king" in favor of the traditional title "duke" and accepting the overlordship of the Empire over Poland. The Royal crown and regalia were delivered by Mieszko II's wife, Queen Richeza.
Bezprym's reign was short. Bezprym's extreme cruelty caused his half-brother Otto Bolesławowic to lead a conspiracy. Bezprym's own men murdered him in spring 1032, created a power vacuum in Poland. Conrad responded by holding an assembly at Merseburg in 1033 to address the situation. Conrad's wife, the Empress Gisela of Swabia, interceded on Mieszko's behalf and requested he be freed from imprisonment in Bohemia and allowed to regain the Polish throne. Under the terms of the Treaty of Merseburg, Conrad divided Poland between Mieszko, Otto, and another half brother Detric. Mieszko was allowed to retain the title Duke and nominal authority over all of Poland. With a strong central leader to guide it, the treaty significantly increased the Empire's influence over Poland.
The division was short-lived: in 1033 Otto was killed by one of his own men, and Mieszko II took his domains. Shortly after, Mieszko expelled Detric, reuniting the whole country in his hands. Though Mieszko regained his former power, he still had to fight against the nobility and his own subjects. Mieszko did not accept Bezprym's renunciation of the Polish crown and continued to style himself as "King" instead of "Duke". Mieszko II died soon after in 1034, and upon his death, a Pagan reaction in Poland erupted. Subsequently, his wife Richeza and son Casimir I fled to Germany.
Relations with Eastern Europe.
Bohemia.
The Duchy of Bohemia was incorporated into the Holy Roman Empire in 1004 during the German-Polish Wars, which stretched from 1002 to 1018. Emperor Henry II installed Jaromir as Duke of Bohemia and promised protection against Polish aggression in return for incorporation. Jaromir ruled only a smaller territory, however, as Poland occupied the traditional Czech territories of Moravia, Silesia, and Lusatia. In 1012, Jaromir was deposed by his brother Oldrich, who assumed the Bohemian throne for himself. Following the resumption of hostilities between the Empire and Poland in 1028, Oldrich went on the offensive against Poland, reconquering Moravia by 1029, which helped to stabilize his duchy. The war ended in 1031 when Polish King Mieszko II surrendered to Conrad. In the civil war which followed, Meiszko was forced to flee Poland for Bohemia, where Oldrich had him imprisoned and castrated in revenge for the torture Meiszko's father, Bolesław I of Poland, inflicted upon Duke Boleslaus III, Oldrich's brother, thirty years before.
Poland was unable to stabilize in the wake of Mieszko's exile, forcing Conrad to convene an assembly in July 1033 to issue the Treaty of Merseburg which restored Meiszko to the Polish throne. Conrad summoned Oldrich to appear to the assembly, but Oldrich refused. His absence raised the ire of the Emperor and Conrad, busy with securing his succession to the Burgundy throne, charged his son Duke Henry of Bavaria with punishing the recalcitrant Bohemian. At age 17, Henry's march on Bohemia was his first independent military command. The expedition was complete success, with Henry deposing Oldrich and restoring his brother Jaromir to the Bohemian throne, with Oldrich's son Bretislaus I appointed as Count of Moravia. Oldrich was imprisoned in Bavaria but by 1034 was pardoned and allowed to return to Bohemia. Oldrich deposed and blinded Jaromir, reclaimed the Bohemian throne, and exiled his son. While the reason for the conflict between father and son has been lost, it is believed Bretislaus supported Jaromir over his father. Oldrich died suddenly on November 9, 1034, allowing Bretislaus to return from exile. Though Jaromir was offered the throne, he declined in favor of his nephew. Bretislaus was then installed as the new Duke of Bohemia by Conrad.
Hungary.
With Otto III's approval, Stephen was crowned as the first Christian king of Hungary on Christmas Day, 1000. Otto III's successor, Emperor Henry II, was Stephen's brother-in-law by Stephen's marriage to Henry's sister Gisela, furthering the friendly relationship between the Empire and Germany. Under Conrad, however, relations quickly turned hostile as Conrad pursued a more aggressive policy regarding eastern Europe. Conrad II expelled Venetian Doge Otto Orseolo, the husband of Stephen's sister Grimelda of Hungary, from Venice in 1026. Conrad also persuaded the Bavarians to proclaim his own son, Henry, as their duke in 1027, although Stephen's son, Emeric of Hungary, had a strong claim to the Duchy of Bavaria through his mother.
Emperor Conrad planned a marriage alliance with the Byzantine Empire and dispatched one of his advisors, Bishop Werner of Strasbourg, to Constantinople. The bishop seemingly traveled as a pilgrim, but Stephen, who had been informed of his actual purpose, refused to let him enter into his country in the autumn of 1027. Conrad's biographer, Wipo of Burgundy recorded that the Bavarians incited skirmishes along the common Imperial-Hungarian border in 1029, causing a rapid deterioration in relations between the two countries. In 1030, open conflict erupted. Conrad launched an invasion of Hungary, but had to retreat when the Hungarians successfully used scorched earth tactics. Conrad left matters in Hungary to his son Henry, so he could address his problems with his stepson Ernest II, the deposed Duke of Swabia. Henry settled the conflict by 1031 by granting lands between the Leitha River and Fischa River in eastern Bavaria to Hungary. Hungary and the Empire remained at peace from 1031 through to Henry's own reign as Emperor in 1040.
Annexation of Burgundy.
King Rudolph III of Burgundy, ruler of the Kingdom of Arles, had no sons, so Emperor Henry II was able to force the Burgundian ruler to name Henry as Rudolph's successor in 1016. Henry II was Rudolph's nephew, and his closest living male relative, as Henry II was the son of Rudolph's sister Gisela of Burgundy. When Emperor Henry II died in 1024, Rudolph was still alive, sparking a new controversy in the Burgundian succession. Conrad II, as Henry II's successor, claimed he inherited Henry II's rights, but Rudolph disputed his claim. Count Odo II of Blois, who had familial ties to Rudolph, also claimed a right in the succession. Conrad II met Rudolph in August 1027 near Basel to settle the contested succession. Henry II's widowed wife, the Empress Gisela of Burgundy, mediated between the two parties. A settlement was reached that allowed Conrad II to succeed to the Burgundian throne upon Rudolph's death under the same conditions as Henry II. In return, Rudolph was allowed to retain independent rule over his kingdom.
Rudolph died on September 6, 1032, while Conrad was campaigning against Duke Mieszko II of Poland. Having forced Mieszko II to surrender, Conrad marched with his army to Burgundy in the winter of 1032/1033. Count Odo II of Blois, Conrad's former rival for the Burgundian throne, had already invaded the kingdom to secure his rule, controlling large portions of the kingdom's western territories. On February 2, 1033, Conrad arrived at Vaud, where he held an assembly at the abbey of Payerne and was crowned King of Burgundy. Initially, Conrad made little headway against Odo and had to withdraw to Zurich in March. After two large-scale military campaigns in summer 1033 and summer 1034, Conrad defeated Odo. On August 1, 1034, Conrad officially incorporated Burgundy into the Holy Roman Empire at a ceremony held in the Cathedral of Geneva.
Though Burgundy was definitively under imperial control, the kingdom was allowed significant autonomy. Conrad rarely intervened in its affairs following his coronation, returning only in 1038 to name his son Henry as the kingdom's new ruler. The chief importance of the annexation of Burgundy was to augment the influence and dignity of the Emperor himself. Control of Burgundy did benefit the Empire. With Burgundy secured, the Empire controlled the western Alpine passes in Italy, allowing the Empire to secure its hold over Italy by blocking foreign invasions.
Politics.
Conrad formally confirmed the popular legal traditions of Saxony and issued new constitutions for Lombardy. In 1028 at Aachen, he had his son Henry elected and anointed king of Germany. Henry married Gunhilda of Denmark, daughter of King Canute the Great of England, Denmark, and Norway by Emma of Normandy. This was an arrangement that Conrad had made many years prior, when he gave Canute parts of northern Germany to administer. Henry, who would later become Emperor Henry III, became his father's chief counselor.
Conrad campaigned unsuccessfully against Poland in 1028–1030. In 1031, Conrad and the Kievan Rus' forced King Mieszko II, son and heir of Bolesław I, to make peace and return the land that Bolesław had taken from the Empire during the reign of Henry II. Mieszko II was compelled to give up his royal title, and for the remainder of his troubled rule became the Duke of Poland and Conrad's vassal.
In 1029 some Bavarian border conflicts undermined the good relations with Stephen I of Hungary. One year later Conrad launched a campaign against Hungary. The Hungarians successfully used scorched earth tactics, and Conrad had to withdraw his army. Finally, the Hungarian army forced him to surrender at Vienna. After his defeat, Conrad was obliged to cede some border territory to Hungary.
When Rudolph III, King of Burgundy died on February 2, 1032, Conrad claimed the Kingship on the basis of an inheritance that Henry II had extorted from Rudolph in 1006, after Henry invaded Burgundy to enforce his claim in 1016. Despite some opposition, the Burgundian and Provençal nobles paid homage to Conrad in Zürich in 1034. This Kingdom of Burgundy, later known as the Kingdom of Arles under Conrad's successors, corresponded to most of the southeastern quarter of modern France and included western Switzerland, the Franche-Comté, and Dauphiné. It did not include the smaller Duchy of Burgundy to the north, ruled by a cadet branch of the Capetian King of France. (Most of the former Kingdom of Arles was incorporated into France piecemeal over the next centuries, but the King of Arles remained one of the Holy Roman Emperor's subsidiary titles until the dissolution of the Empire in 1806.)
Conrad upheld the rights of the "valvassores" (knights and burghers of the cities) of Italy against Archbishop Aribert of Milan and the local nobles. The nobles, as vassal lords, and the bishop had conspired to rescind rights from the burghers. Conrad restored order with skillful diplomacy and luck.
Late life.
Second Italian expedition.
In 1038, Prince Guaimar IV of Salerno requested that Conrad adjudicate in a dispute over Capua with its Prince Pandulf, whom Conrad had released from imprisonment in 1024, immediately after his coronation. Hearing that Michael IV the Paphlagonian of the Byzantine Empire had received the same request, Conrad went to Southern Italy, to Salerno and Aversa. He appointed Richer, from Germany, as abbot of Monte Cassino, the abbot Theobald being imprisoned by Pandulf. At Troia, he ordered Pandulf to restore stolen property to Monte Cassino. Pandulf sent his wife and son to ask for peace, giving 300 lb of gold and a son and daughter as hostages. The Emperor accepted Pandulf's offer, but the hostage escaped and Pandulf holed up in his outlying castle of Sant'Agata de' Goti. Conrad besieged and took Capua and gave it to Guaimar with the title of Prince. He also recognised Aversa as a county of Salerno under Ranulf Drengot, the Norman adventurer. Pandulf, meanwhile, fled to Constantinople. Conrad thus left the "Mezzogiorno" firmly in Guaimar's hands and loyal, for once, to the Holy Roman Empire.
Death.
During the return trip to Germany an epidemic broke out among the troops. Conrad's daughter-in-law and stepson died. Conrad himself returned safely and held several important courts in Solothurn, Strasbourg, and in Goslar. His son Henry was invested with the kingdom of Burgundy.
A year later in 1039 Conrad fell ill and died of gout in Utrecht. His heart and bowels are buried at the Cathedral of Saint Martin, Utrecht. His body was transferred to Speyer via Cologne, Mainz, and Worms, where the funeral procession made stops. His body is buried at Speyer Cathedral, which was still under construction at this time. During a major excavation in 1900 his sarcophagus was relocated from his original resting place in front of the altar to the crypt, where it is still visible today along with those of seven of his successors.
A biography of Conrad II in chronicle form, "Gesta Chuonradi II imperatoris", was written by his chaplain Wipo of Burgundy, and presented to Henry III in 1046, not long after the latter was crowned.
Family and children.
Conrad married Gisela of Swabia in 1016, the daughter of Duke Herman II of Swabia. They had three children:
Depictions of Conrad II.
The Basilica of Aquileia (northern Italy) contains an apse fresco (c. 1031) showing emperor Conrad II, his wife Gisela of Swabia and Patriarch Poppone of Aquileia.

</doc>
<doc id="44400" url="http://en.wikipedia.org/wiki?curid=44400" title="RV Triton">
RV Triton

The Research Vessel "Triton" is a trimaran vessel owned by Gardline Marine Sciences Limited and a former prototype British warship demonstrator for the UK's Defence Evaluation and Research Agency. She was built as a technology demonstrator ship for the Royal Navy's Future Surface Combatant, and has been used to both prove the viability of the hull-form and as a trials platform for other QinetiQ innovations.
In August 1998, the UK Ministry of Defence (MoD) awarded a contract to Vosper Thornycroft to construct the Trimaran, called RV (research vessel) Triton. The vessel was launched in May 2000 and delivered in August 2000. Triton then began a two-year risk reduction trials programme for the UK MoD and the US Department of Defense. 
Since 2007 the ship has been used by the Australian Customs and Border Protection Service's Customs Marine Unit.
"Triton"‍ '​ name refers to the maritime god Triton who carried the three-pronged spear, the trident, which relates to the vessel's three parallel hulls. The outriggers are thinner and much shorter than the dominant central hull.
Operational history.
DERA and QinetiQ.
"Triton" was designed as a demonstrator to prove that the trimaran concept would work successfully in a large warship. Following her launch in 2000, the ship began an extensive series of trials in 2001, which covered general ship handling, performance, sea-keeping behaviour, but also areas more specific to its design for which the Royal Navy had no experience. For example, a series of docking manoeuvres were undertaken by the pilot boats of HMNB Portsmouth to determine the problems of docking a large trimaran, and the ship underwent underway replenishment alongside HMS "Argyll" and the tanker RFA "Brambleleaf" to ascertain the characteristics of a trimaran and a monohull replenishing at the same time. "Triton" also undertook the first helicopter take off and landing on a trimaran. 
"Triton" was present at the International Festival of the Sea in 2001, but visitors were not permitted on board.
Gardline Marine Sciences.
In January 2005, Triton was sold to Gardline Marine Sciences, a UK company based in Great Yarmouth, Norfolk. Triton was used for hydrographic survey work for the civil hydrography programme (CHP) on behalf of the Maritime and Coastguard Agency (MCA). The vessel was fitted with a sensor suite which includes the Kongsberg Simrad EM1002 multibeam echo-sounder, a GPS attitude / heading system, surface navigation and ultra-short baseline sub-surface acoustic tracking system, Gardline Voyager5 integrated survey system and Caris post-processing system.
Australian Customs.
In December 2006, Gardline contracted "Triton" to the Australian Customs and Border Protection Service to patrol Australia's northern waters as one of the service's fleet of patrol vessels. Australian Customs Vessel "Triton" has been fitted with two .50 calibre heavy machine guns and carries up to 28 armed customs officers. The vessel is also equipped with two 7.3m high-speed rigid hull inflatable boats (RHIBs). The ship arrived from the UK in mid-January 2007 and started operations immediately It is reported that ACV "Triton" has been modified to provide additional accommodation at the expense of ballast, which has apparently reduced the vessel's inherent stability. High stability is less important in the calmer waters of the South Pacific and Indian Oceans.

</doc>
<doc id="44401" url="http://en.wikipedia.org/wiki?curid=44401" title="Brown dwarf">
Brown dwarf

Brown dwarfs are substellar objects not massive enough to sustain hydrogen-1 fusion reactions in their cores, unlike main-sequence stars. They occupy the mass range between the heaviest gas giants and the lightest stars, with an upper limit around 75 to 80 Jupiter masses (MJ). Brown dwarfs heavier than about 13 MJ are thought to fuse deuterium and those above ~65 MJ, fuse lithium as well. Brown dwarfs may be fully convective, with no layers or chemical differentiation by depth.
The defining differences between a very-low-mass brown dwarf and a giant planet (~13 MJ) are currently being debated. One school of thought is based on formation; the other, on the physics of the interior.
Part of the debate concerns whether "brown dwarfs" must, by definition, have experienced fusion at some point in their history.
Stars are categorized by spectral class, with brown dwarfs being designated as types M, L, T, and Y. Despite their name, brown dwarfs are of different colours. Many brown dwarfs would likely appear magenta to the human eye, or possibly orange/red. Brown dwarfs are not very luminous at visible wavelengths.
Some planets are known to orbit brown dwarfs: 2M1207b, MOA-2007-BLG-192Lb, and 2MASS J044144b
At a distance of about 6.5 light years, the nearest known brown dwarf is Luhman 16, a binary system of brown dwarfs discovered in 2013. One brown dwarf, DENIS-P J082303.1-491201 b, from an ultracool binary system, has a mass of about 28 MJ, making it the largest known exoplanet (as of March 2014).
History.
The objects now called "brown dwarfs" were theorized to exist in the 1960s. They were originally called black dwarfs, a classification for dark substellar objects floating freely in space that were not massive enough to sustain hydrogen fusion. However: a) the term black dwarf was already in use to refer to a cold white dwarf; b) red dwarfs fuse hydrogen, and c) these objects may be luminous at visible wavelengths early in their lives. Because of this, alternate names for these objects were proposed, including planetar and substar. But in 1975, Jill Tarter suggested the term "brown dwarf", using brown as an approximate color. This has been the term used in astronomy ever since.
The term black dwarf still refers to a white dwarf that has cooled to the point that it no longer emits significant light.
Early theories concerning the nature of the lowest-mass stars and the hydrogen-burning limit suggested that a Population I object with a mass less than 0.07 solar masses (M☉) or a Population II object less than 0.09 M☉ would never go through normal stellar evolution and would become a completely degenerate star (Kumar 1963). The first self-consistent calculation of the hydrogen-burning minimum mass confirmed a value between 0.08 and 0.07 solar masses for population I objects
(Hayashi and Nakano 1963). The discovery of deuterium-burning down to 0.012 solar masses and the impact of dust formation in the cool outer atmospheres of brown dwarfs in the late 1980s brought these theories into question. However, such objects were hard to find because they emit almost no visible light. Their strongest emissions are in the infrared (IR) spectrum, and ground-based IR detectors were too imprecise at that time to readily identify any brown dwarfs.
Since then, numerous searches by various methods have sought to find these objects. These methods included multi-color imaging surveys around field stars, imaging surveys for faint companions to main-sequence dwarfs and white dwarfs, surveys of young star clusters, and radial velocity monitoring for close companions.
For many years, efforts to discover brown dwarfs were fruitless. In 1988, however, University of California, Los Angeles professors Eric Becklin and Ben Zuckerman identified a faint companion to a star known as GD 165 in an infrared search of white dwarfs. The spectrum of the companion GD 165B was very red and enigmatic, showing none of the features expected of a low-mass red dwarf. It became clear that GD 165B would need to be classified as a much cooler object than the latest M dwarfs then known. GD 165B remained unique for almost a decade until the advent of the Two Micron All Sky Survey (2MASS) when Davy Kirkpatrick, of the California Institute of Technology, and others discovered many objects with similar colors and spectral features.
Today, GD 165B is recognized as the prototype of a class of objects now called "L dwarfs". Although the discovery of the coolest dwarf was highly significant at the time, it was debated whether GD 165B would be classified as a brown dwarf or simply a very-low-mass star, because observationally it is very difficult to distinguish between the two.
Soon after the discovery of GD 165B, other brown-dwarf candidates were reported. Most failed to live up to their candidacy, however, because the absence of lithium showed them to be stellar objects. True stars burn their lithium within a little over 100 Myr, whereas brown dwarfs (which can, confusingly, have temperatures and luminosities similar to true stars) will not. In other words, the detection of lithium in the atmosphere of a candidate object ensures that, as long as it is older than the relatively young age of 100 Myr, it is a brown dwarf.
In 1995, the study of brown dwarfs changed substantially with the discovery of two incontrovertible substellar objects (Teide 1 and Gliese 229B), which were identified by the presence of the 670.8 nm lithium line. The more notable of these objects was the latter, which was found to have a temperature and luminosity well below the stellar range. Remarkably, its near-infrared spectrum clearly exhibited a methane absorption band at 2 micrometres, a feature that had previously only been observed in the atmospheres of giant planets and that of Saturn's moon Titan. Methane absorption is not expected at the temperatures of main-sequence stars. This discovery helped to establish yet another spectral class even cooler than L dwarfs, known as "T dwarfs", for which Gliese 229B is the prototype.
The first confirmed brown dwarf was discovered by Spanish astrophysicists Rafael Rebolo (head of team), Maria Rosa Zapatero Osorio, and Eduardo Martín in 1994. They called this object Teide 1 and it was found in the Pleiades open cluster. The discovery article was submitted to "Nature" in spring 1995, and published on September 14, 1995. "Nature" highlighted "Brown dwarfs discovered, official" in the front page of that issue.
Teide 1 was discovered in images collected by the IAC team on January 6, 1994 using the 80 cm telescope (IAC 80) at Teide Observatory and its spectrum was first recorded in December 1994 using the 4.2 m William Herschel Telescope at Roque de los Muchachos Observatory (La Palma). The distance, chemical composition, and age of Teide 1 could be established because of its membership in the young Pleiades star cluster. Using the most advanced stellar and substellar evolution models at that moment, the team estimated for Teide 1 a mass of 55 MJ, which is clearly below the stellar-mass limit. The object became a reference in subsequent young brown dwarf related works.
In theory, a brown dwarf below 65 MJ is unable to burn lithium by thermonuclear fusion at any time during its evolution. This fact is one of the lithium test principles to examine the substellar nature in low-luminosity and low-surface-temperature astronomical bodies.
High-quality spectral data acquired by the Keck 1 telescope in November 1995 showed that Teide 1 had kept the initial lithium amount of the original molecular cloud from which Pleiades stars formed, proving the lack of thermonuclear fusion in its core. These observations confirmed that Teide 1 is a brown dwarf, as well as the efficiency of the spectroscopic lithium test.
For some time, Teide 1 was the smallest known object outside the Solar System that had been identified by direct observation. Since then, over 1,800 brown dwarfs have been identified, even some very close to Earth like Epsilon Indi Ba and Bb, a pair of brown dwarfs gravitationally bound to a Sun-like star around 12 light-years from the Sun, and Luhman 16, a binary system of brown dwarfs about 6.5 light-years away.
Theory.
Hertzsprung–Russell diagram
Spectral type
Brown dwarfs
White dwarfs
Red dwarfs
Subdwarfs
Main sequence<br>("dwarfs")
Subgiants
Giants
Bright giants
Supergiants
Hypergiants
absolute
magni-
tude
The standard mechanism for star birth is through the gravitational collapse of a cold interstellar cloud of gas and dust. As the cloud contracts it heats due to the Kelvin–Helmholtz mechanism. Early in the process the contracting gas quickly radiates away much of the energy, allowing the collapse to continue. Eventually, the central region becomes sufficiently dense to trap radiation. Consequently, the central temperature and density of the collapsed cloud increases dramatically with time, slowing the contraction, until the conditions are hot and dense enough for thermonuclear reactions to occur in the core of the protostar. For most stars, gas and radiation pressure generated by the thermonuclear fusion reactions within the core of the star will support it against any further gravitational contraction. Hydrostatic equilibrium is reached and the star will spend most of its lifetime fusing hydrogen into helium as a main-sequence star.
If, however, the mass of the protostar is less than about 0.08 M☉, normal hydrogen thermonuclear fusion reactions will not ignite in the core. Gravitational contraction does not heat the small protostar very effectively, and before the temperature in the core can increase enough to trigger fusion, the density reaches the point where electrons become closely packed enough to create quantum electron degeneracy pressure. According to the brown dwarf interior models, typical conditions in the core for density, temperature and pressure are expected to be the following:
This means that the protostar is not massive enough and not dense enough to ever reach the conditions needed to sustain hydrogen fusion. The infalling matter is prevented, by electron degeneracy pressure, from reaching the densities and pressures needed.
Further gravitational contraction is prevented and the result is a "failed star", or brown dwarf that simply cools off by radiating away its internal thermal energy.
Low-mass brown dwarfs vs. high-mass planets.
A remarkable property of brown dwarfs is that they are all roughly the same radius as Jupiter. At the high end of their mass range (60–90 MJ), the volume of a brown dwarf is governed primarily by electron-degeneracy pressure, as it is in white dwarfs; at the low end of the range (10 MJ), their volume is governed primarily by Coulomb pressure, as it is in planets. The net result is that the radii of brown dwarfs vary by only 10–15% over the range of possible masses. This can make distinguishing them from planets difficult.
In addition, many brown dwarfs undergo no fusion; those at the low end of the mass range (under 13 MJ) are never hot enough to fuse even deuterium, and even those at the high end of the mass range (over 60 MJ) cool quickly enough that they no longer undergo fusion after a period of time on the order of 10 million years.
X-ray and infrared spectra are telltale signs. Some brown dwarfs emit X-rays; and all "warm" dwarfs continue to glow tellingly in the red and infrared spectra until they cool to planetlike temperatures (under 1000 K).
Gas giants have some of the characteristics of brown dwarfs. For example, Jupiter and Saturn are both made primarily of hydrogen and helium, like the Sun. Saturn is nearly as large as Jupiter, despite having only 30% the mass. Three of the giant planets in the Solar System (Jupiter, Saturn, and Neptune) emit much more heat than they receive from the Sun. And all four giant planets have their own "planetary systems"—their moons. Brown dwarfs form independently, like stars, but lack sufficient mass to "ignite" as stars do. Like all stars, they can occur singly or in close proximity to other stars. Some orbit stars, which can, like planets, have eccentric orbits.
Currently, the International Astronomical Union considers an object with a mass above the limiting mass for thermonuclear fusion of deuterium (currently calculated to be 13 MJ for objects of solar metallicity) to be a brown dwarf, whereas an object under that mass (and orbiting a star or stellar remnant) is considered a planet.
The 13 Jupiter-mass cutoff is a rule of thumb rather than something of precise physical significance. Larger objects will burn most of their deuterium and smaller ones will burn only a little, and the 13 Jupiter mass value is somewhere in between. The amount of deuterium burnt also depends to some extent on the composition of the object, specifically on the amount of helium and deuterium present and on the fraction of heavier elements, which determines the atmospheric opacity and thus the radiative cooling rate.
The Extrasolar Planets Encyclopaedia includes objects up to 25 Jupiter masses, and the Exoplanet Data Explorer up to 24 Jupiter masses.
Sub-brown dwarf.
A sub-brown dwarf or planetary-mass brown dwarf is an astronomical object formed in the same manner as stars and brown dwarfs (i.e. through the collapse of a gas cloud) but that has a mass below the limiting mass for thermonuclear fusion of deuterium (about 13 MJ).
Some researchers call them free-floating planets whereas others call them planetary-mass brown dwarfs.
Sub-brown dwarfs formed in the manner of stars, through the collapse of a gas cloud (perhaps with the help of photo-erosion) but there is no consensus amongst astronomers on whether the formation process should be taken into account when classifying an object as a planet. Free-floating sub-brown dwarfs can be observationally indistinguishable from rogue planets that originally formed around a star and were ejected from orbit, and on the other hand a sub-brown dwarf formed free-floating in a star cluster may get captured into orbit around a star. A definition for the term "sub-brown dwarf" was put forward by the IAU Working Group on Extra-Solar Planets (WGESP), which defined it as a free-floating body found in young star clusters below the lower mass cut-off of brown dwarfs.
Lower mass limit.
The smallest mass of gas cloud that could collapse to form a sub-brown dwarf is about 1 MJ. This is because to collapse by gravitational contraction requires radiating away energy as heat and this is limited by the opacity of the gas. A 3 MJ candidate is described in the paper.
List of possible planetary-mass brown dwarfs.
There is no consensus whether these companions of stars should be considered sub-brown dwarfs or planets.
There is no consensus whether these companions of brown dwarfs should be considered sub-brown dwarfs or planets.
Observations.
Classification of brown dwarfs.
Spectral class M.
There are brown dwarfs with a spectral class of M6.5 or later. They are also called late-M dwarfs.
Spectral class L.
The defining characteristic of spectral class M, the coolest type in the long-standing classical stellar sequence, is an optical spectrum dominated by absorption bands of titanium(II) oxide (TiO) and vanadium(II) oxide (VO) molecules. However, GD 165B, the cool companion to the white dwarf GD 165, had none of the hallmark TiO features of M dwarfs. The subsequent identification of many field counterparts to GD 165B ultimately led Kirkpatrick and others to the definition of a new spectral class, the L dwarfs, defined in the red optical region not by weakening metal-oxide bands (TiO, VO), but strong metal hydride bands (FeH, CrH, MgH, CaH) and prominent alkali metal lines (Na I, K I, Cs I, Rb I). s of 2013[ [update]], over 900 L dwarfs have been identified, most by wide-field surveys: the Two Micron All Sky Survey (2MASS), the Deep Near Infrared Survey of the Southern Sky (DENIS), and the Sloan Digital Sky Survey (SDSS).
Spectral class T.
As GD 165B is the prototype of the L dwarfs, Gliese 229B is the prototype of a second new spectral class, the T dwarfs. Whereas near-infrared (NIR) spectra of L dwarfs show strong absorption bands of H2O and carbon monoxide (CO), the NIR spectrum of Gliese 229B is dominated by absorption bands from methane (CH4), features that were only found in the giant planets of the Solar System and Titan. CH4, H2O, and molecular hydrogen (H2) collision-induced absorption (CIA) give Gliese 229B blue near-infrared colors. Its steeply sloped red optical spectrum also lacks the FeH and CrH bands that characterize L dwarfs and instead is influenced by exceptionally broad absorption features from the alkali metals Na and K. These differences led Kirkpatrick to propose the T spectral class for objects exhibiting H- and K-band CH4 absorption. s of 2013[ [update]], 355 T dwarfs are known. NIR classification schemes for T dwarfs have recently been developed by Adam Burgasser and Tom Geballe. Theory suggests that L dwarfs are a mixture of very-low-mass stars and sub-stellar objects (brown dwarfs), whereas the T dwarf class is composed entirely of brown dwarfs. Because of the absorption of sodium and potassium in the green part of the spectrum of T dwarfs, the actual appearance of T dwarfs to human visual perception is estimated to be not brown, but the color of magenta coal tar dye. T-class brown dwarfs, such as WISE 0316+4307, have been detected over 100 light-years from the Sun.
Spectral class Y.
There is some doubt as to what, if anything, should be included in the class Y dwarfs. They are expected to be much cooler than T-dwarfs. They have been modelled, though there is no well-defined spectral sequence yet with prototypes.
In 2009, the coolest known brown dwarfs had estimated effective temperatures between 500 and 600 K, and have been assigned the spectral class T9. Three examples are the brown dwarfs CFBDS J005910.90-011401.3, ULAS J133553.45+113005.2, and ULAS J003402.77−005206.7. The spectra of these objects display absorption around 1.55 micrometers. Delorme et al. have suggested that this feature is due to absorption from ammonia and that this should be taken as indicating the T–Y transition, making these objects of type Y0. However, the feature is difficult to distinguish from absorption by water and methane, and other authors have stated that the assignment of class Y0 is premature.
In April 2010, two newly discovered ultracool sub-brown dwarfs (UGPS 0722-05 and SDWFS 1433+35) were proposed as prototypes for spectral class Y0.
In February 2011, Luhman et al. reported the discovery of a ~300 K, 7-Jupiter-mass 'brown-dwarf' companion to a nearby white dwarf. Though of 'planetary' mass, Rodriguez et al. suggest it is unlikely to have formed in the same manner as planets.
Shortly after that, Liu et al. published an account of a "very cold" (~370 K) brown dwarf orbiting another very-low-mass brown dwarf and noted that "Given its low luminosity, atypical colors and cold temperature, CFBDS J1458+10B is a promising candidate for the hypothesized Y spectral class."
In August 2011, scientists using data from NASA's Wide-field Infrared Survey Explorer (WISE) discovered six "Y dwarfs"—star-like bodies with temperatures as cool as the human body.
WISE data has revealed hundreds of new brown dwarfs. Of these, fourteen are classified as cool Ys. One of the Y dwarfs, called WISE 1828+2650, was, as of August 2011, the record holder for the coldest brown dwarf – emitting no visible light at all, this type of object resembles free-floating planets more than stars. WISE 1828+2650 was initially estimated to have an atmospheric temperature cooler than 300 K—for comparison the upper end of room temperature is 298 K (25 °C, 80 °F). Its temperature has since been revised and newer estimates put it in the range of 250 to 400 K (−23–127 °C, −10–260 °F).
In April 2014, WISE 0855−0714 was announced with a temperature profile estimated around 225 to 260 K and a mass of 3 to 10 MJ. It was also unusual in that its observed parallax meant a distance close to 7.2±0.7 light years from the Solar System.
Spectral and atmospheric properties of brown dwarfs.
The majority of flux emitted by L and T dwarfs is in the 1 to 2.5 micrometre near-infrared range. Low and decreasing temperatures through the late M-, L-, and T-dwarf sequence result in a rich near-infrared spectrum containing a wide variety of features, from relatively narrow lines of neutral atomic species to broad molecular bands, all of which have different dependencies on temperature, gravity, and metallicity. Furthermore, these low temperature conditions favor condensation out of the gas state and the formation of grains.
Typical atmospheres of known brown dwarfs range in temperature from 2200 down to 750 K. Compared to stars, which warm themselves with steady internal fusion, brown dwarfs cool quickly over time; more massive dwarfs cool slower than less massive ones.
Observational techniques.
Coronagraphs have recently been used to detect faint objects orbiting bright visible stars, including Gliese 229B.
Sensitive telescopes equipped with charge-coupled devices (CCDs) have been used to search distant star clusters for faint objects, including Teide 1.
Wide-field searches have identified individual faint objects, such as Kelu-1 (30 ly away)
Brown dwarfs are often discovered in surveys to discover extrasolar planets. Methods of detecting extrasolar planets work for brown dwarfs as well, although brown dwarfs are much easier to detect.
Brown dwarf as an X-ray source.
X-ray flares detected from brown dwarfs since 1999 suggest changing magnetic fields within them, similar to those in very-low-mass stars.
With no strong central nuclear energy source, the interior of a brown dwarf is in a rapid boiling, or convective state. When combined with the rapid rotation that most brown dwarfs exhibit, convection sets up conditions for the development of a strong, tangled magnetic field near the surface. The flare observed by Chandra from LP 944-20 could have its origin in the turbulent magnetized hot material beneath the brown dwarf's surface. A sub-surface flare could conduct heat to the atmosphere, allowing electric currents to flow and produce an X-ray flare, like a stroke of lightning. The absence of X-rays from LP 944-20 during the non-flaring period is also a significant result. It sets the lowest observational limit on steady X-ray power produced by a brown dwarf, and shows that coronas cease to exist as the surface temperature of a brown dwarf cools below about 2800K and becomes electrically neutral.
Using NASA's Chandra X-ray Observatory, scientists have detected X-rays from a low-mass brown dwarf in a multiple star system. This is the first time that a brown dwarf this close to its parent star(s) (Sun-like stars TWA 5A) has been resolved in X-rays. "Our Chandra data show that the X-rays originate from the brown dwarf's coronal plasma which is some 3 million degrees Celsius", said Yohko Tsuboi of Chuo University in Tokyo. "This brown dwarf is as bright as the Sun today in X-ray light, while it is fifty times less massive than the Sun", said Tsuboi. "This observation, thus, raises the possibility that even massive planets might emit X-rays by themselves during their youth!"
Recent developments.
The brown dwarf Cha 110913-773444, located 500 light years away in the constellation Chamaeleon, may be in the process of forming a miniature planetary system. Astronomers from Pennsylvania State University have detected what they believe to be a disk of gas and dust similar to the one hypothesized to have formed the Solar System. Cha 110913-773444 is the smallest brown dwarf found to date (8 MJ), and if it formed a planetary system, it would be the smallest known object to have one. Their findings were published in the December 10, 2005 issue of Astrophysical Journal Letters.
Recent observations of known brown dwarf candidates have revealed a pattern of brightening and dimming of infrared emissions that suggests relatively cool, opaque cloud patterns obscuring a hot interior that is stirred by extreme winds. The weather on such bodies is thought to be extremely violent, comparable to but far exceeding Jupiter's famous storms.
On January 8, 2013 astronomers using NASA's Hubble and Spitzer space telescopes probed the stormy atmosphere of a brown dwarf named 2MASS J22282889-431026, creating the most detailed "weather map" of a brown dwarf thus far. It shows wind-driven, planet-sized clouds. The new research is a stepping stone toward a better understanding not only brown dwarfs, but also of the atmospheres of planets beyond the Solar System.
NASA's WISE mission has detected 200 new brown dwarfs. There are actually fewer brown dwarfs in our cosmic neighborhood than previously thought. Rather than one star for every brown dwarf, there may be as many as six stars for every brown dwarf.
Planets around brown dwarfs.
The planetary-mass objects 2M1207b and 2MASS J044144 that are orbiting brown dwarfs at large orbital distances may have formed by cloud collapse rather than accretion and so may be sub-brown dwarfs rather than planets, which is inferred from relatively large masses and large orbits. The first discovery of a low-mass companion orbiting a brown dwarf (ChaHα8) at a small orbital distance using the radial velocity technique paved the way for the detection of planets around brown dwarfs on orbits of a few AU or smaller. However, with a mass ratio between the companion and primary in ChaHα8 of about 0.3, this system rather resembles a binary star. Then, in 2013, the first planetary-mass companion (OGLE-2012-BLG-0358L b) in a relatively small orbit was discovered orbiting a brown dwarf.
Disks around brown dwarfs have been found to have many of the same features as disks around stars; therefore, it is expected that there will be accretion-formed planets around brown dwarfs. Given the small mass of brown dwarf disks, most planets will be terrestrial planets rather than gas giants. If a giant planet orbits a brown dwarf across our line of sight, then, because they have approximately the same diameter, this would give a large signal for detection by transit. The accretion zone for planets around a brown dwarf is very close to the brown dwarf itself, so tidal forces would have a strong effect.
Planets around brown dwarfs are likely to be carbon planets depleted of water.
Habitability.
Habitability for hypothetical planets orbiting brown dwarfs has been studied. Computer models suggesting conditions for these bodies to have habitable planets are very stringent, the habitable zone being narrow and decreasing with time, due to the cooling of the brown dwarf. The orbits there would have to be of "very" low eccentricity (of the order of 10−6) to avoid strong tidal forces that would trigger a greenhouse effect on the planets, rendering them uninhabitable.

</doc>
<doc id="44403" url="http://en.wikipedia.org/wiki?curid=44403" title="Shakers">
Shakers

The United Society of Believers in Christ’s Second Appearing is a religious sect, also known as the Shakers, founded in the 18th century in England, having branched off from a Quaker community. They were known as "Shaking Quakers" because of their ecstatic behavior during worship services. In 1747 women assumed leadership roles within the sect, notably Jane Wardley and Mother Ann Lee. Shakers settled in colonial America, with initial settlements in New Lebanon, New York (called Mount Lebanon after 1861) and what is now Watervliet.
Shakers today are mostly known for their celibate and communal lifestyle, pacifism, and their model of equality of the sexes, which they institutionalized in their society in the 1780s. They are also known for their simple living, architecture and furniture.
During the mid 19th century, an Era of Manifestations resulted in a period of dances, gift drawings and gift songs inspired by spiritual revelations. At its peak in the mid 19th century, there were 6,000 Shaker believers. By 1920, there were only 12 Shaker communities remaining in the United States. There is only one active Shaker village, Sabbathday Lake Shaker Village, which is located in Maine. Their celibacy resulted in the thinning of the Shaker community, and consequently many of the other Shaker settlements are now village museums, like Hancock Shaker Village in Massachusetts.
History.
Origins.
The Shakers were one of a few religious groups formed in 18th century in the Northwest of England; they branched off from a group of Quakers in England. James and Jane Wardley and others left at a time when the Quakers were weaning themselves away from frenetic spiritual expression. The Wardleys formed the Wardley Society, which was also known as the "Shaking Quakers". Future leader Ann Lee and her parents were early members of the sect. This group of "charismatic" Christians became the United Society of Believers in Christ's Second Appearing (USBCSA), or the Shakers. Their belief was based upon spiritualism and included the notion that they received messages from the spirit of God which were expressed during religious revivals. They also experienced what they interpreted as messages from God during silent meditations and became known as "Shaking Quakers" because of the ecstatic nature of their worship services. They believed in the renunciation of sinful acts and that the end of the world was near.
Meetings were first held in Bolton, where the articulate preacher Jane Wardley, urged her followers to:
 Repent. For the kingdom of God is at hand. The new heaven and new earth prophesied of old is about to come. The marriage of the Lamb, the first resurrection, the new Jerusalem descended from above, these are even now at the door. And when Christ appears again, and the true church rises in full and transcendent glory, then all anti-Christian denominations—the priests, the Church, the pope—will be swept away.
Other meetings were then held in Manchester, Meretown (also spelled Mayortown), Chester and other places near Manchester. As their numbers grew, members began to be persecuted, mobbed, and stoned; Lee was imprisoned in Manchester. The members looked to women for leadership, believing that the second coming of Christ would be through a woman. In 1770, Ann Lee was revealed in "manifestation of Divine light" to be the second coming of Christ and was called Mother Ann.
Mother Ann Lee.
Ann Lee joined the Shakers by 1758 and then became the leader of the small community. "Mother Ann," as her followers later called her, claimed numerous revelations regarding the fall of Adam and Eve and its relationship to sexual intercourse. A powerful preacher, she called her followers to confess their sins, give up all their worldly goods, and take up the cross of celibacy and forsake marriage, as part of the renunciation of all "lustful gratifications".
She said:
 I saw in vision the Lord Jesus in his kingdom and glory. He revealed to me the depth of man's loss, what it was, and the way of redemption therefrom. Then I was able to bear an open testimony against the sin that is the root of all evil; and I felt the power of God flow into my soul like a fountain of living water. From that day I have been able to take up a full cross against all the doleful works of the flesh.
Having received a revelation, on May 19, 1774, Ann Lee and eight of her followers sailed from Liverpool for colonial America. Ann and her husband Abraham Stanley, brother William Lee, niece Nancy Lee, James Whittaker, father and son John Hocknell and Richard Hocknell, James Shephard and Mary Partington traveled to colonial America, and except for Abraham Stanley who remarried and settled in Watervliet, New York. Her vision of the Shakers in America was represented in a vision: "I saw a large tree, every leaf of which shone with such brightness as made it appear like a burning torch, representing the Church of Christ, which will yet be established in this land. Unable to "swear" an Oath of Allegiance, as it was against their faith, the members were imprisoned for about six months. Since they were only imprisoned because of their faith, this raised sympathy of citizens and thus helped to spread their religious beliefs. Lee, revealed as the "second coming" of Christ, traveled throughout the eastern states, preaching her gospel views.
Community growth.
Aside from the first community, Mount Lebanon, a number of new Shaker communities formed during the 5-year-period between 1787 and 1792. Also in New York, there was Groveland and Watervliet Shaker Villages. In Massachusetts were Hancock, Harvard; Shirley and Tyringham Shaker Villages. Other locations were Enfield Shaker Villages in Connecticut and New Hampshire; Canterbury; and in Maine the Sabbathday Lake Shaker Village in New Gloucester and Alfred Shaker Historic District.
Joseph Meacham and communalism.
After Ann Lee and James Whittaker died, Joseph Meacham (1742–1796) became the leader of the Shakers in 1787. He had been a New Light Baptist minister in Enfield, Connecticut, and was reputed to have, second only to Mother Ann, the spiritual gift of revelation.
Joseph Meacham brought Lucy Wright (1760–1821) into the Ministry to serve with him and together they developed the Shaker form of communalism (religious communism). By 1793 property had been made a "consecrated whole" in each Shaker community.
Shakers developed written covenants in the 1790. Those who signed the covenant had to confess their sins, consecrate their property and their labor to the society, and live as celibates. If they were married before joining the society, their marriages ended when they joined. A few less-committed Believers lived in "noncommunal orders" as Shaker sympathizers who preferred to remain with their families. The Shakers never forbade marriage for such individuals, but considered it less perfect than the celibate state.
Lucy Wright and westward expansion.
After Joseph Meacham died, Lucy Wright continued Ann Lee's missionary tradition. Shaker missionaries proselytized at revivals, not only in New England and New York, but also farther west. Missionaries such as Issachar Bates and Benjamin Seth Youngs (older brother of Isaac Newton Youngs) gathered hundreds of proselytes into the faith.
Mother Lucy Wright introduced new hymns and dances to make sermons more lively. She also helped write Benjamin S. Youngs’ book "The Testimony of Christ’s Second Appearing" (1808)
Shaker missionaries entered Kentucky and Ohio after the Cane Ridge, Kentucky revival of 1801–1803, which was an outgrowth of the Logan County, Kentucky, Revival of 1800. From 1805 to 1807, they founded Shaker societies at Union Village, Ohio; South Union, Logan County, Kentucky; and Pleasant Hill, Kentucky (in Mercer County, Kentucky). In 1824, the Whitewater Shaker settlement was established in southwestern Ohio. The westernmost Shaker community was located at West Union (called Busro because it was on Busseron Creek) on the Wabash River a few miles north of Vincennes in Knox County, Indiana.
Era of Manifestations.
The Shaker movement was at its height between 1820 and 1860. It was at this time that the sect had its most members, and the period was considered its "golden age". It had expanded from New England to the Midwestern states of Indiana, Kentucky and Ohio. It was during this period that it became known for its furniture design and craftsmanship. In the late 1830s a spiritual revivalism, the Era of Manifestations was born. It was also known as the "period of Mother's work", for the spiritual revelations that were passed from the late Mother Ann Lee.
The expression of "spirit gifts" or messages were realized in "gift drawings" made by Hannah Cohoon, Polly Reed, Polly Collins, and other Shaker sisters. A number of those drawings remain as important artifacts of Shaker folk art.
American Civil War period.
As pacifists, the Shakers did not believe that it was acceptable to kill or harm others, even in time of war. As a result the Civil War brought with it a strange time for the Shaker communities in America. Both Union and Confederate soldiers found their way to the Shaker communities. Shakers tended to sympathize with the Union but they did feed and care for both Union and Confederate soldiers. President Lincoln exempted Shaker males from military service, and they became some of the first conscientious objectors in American history. The end of the Civil War brought large changes to the Shaker communities. One of the most important changes was the postwar economy.
The Shakers had a hard time competing in the industrialized economy that followed the Civil War. With prosperity falling, converts were hard to come by. By the early 20th century the once numerous Shaker communities were failing and closing. Today, in the 21st century, the Shaker community that still exists–the Sabbathday Lake Shaker Community–denies that Shakerism was a failed utopian experiment.
Their message, surviving over two centuries in America, reads in part as follows:
Shakerism is not, as many would claim, an anachronism; nor can it be dismissed as the final sad flowering of 19th century liberal utopian fervor. Shakerism has a message for this present age–a message as valid today as when it was first expressed. It teaches above all else that God is Love and that our most solemn duty is to show forth that God who is love in the World.
Theology.
Dualism.
Shaker theology is based on the idea of the dualism of God as male and female: "So God created him; male and female he created them" (Genesis 1:27). This passage was interpreted as showing the dual nature of the Creator.
First and second coming.
Shakers believed that Jesus, born of a woman, the son of a Jewish carpenter, was the male manifestation of Christ and the first Christian Church; and that Mother Ann, daughter of an English blacksmith, was the female manifestation of Christ and the second Christian Church (which the Shakers believed themselves to be). She was seen as the Bride made ready for the Bridegroom, and in her, the promises of the Second Coming were fulfilled.
Adam's sin was understood to be sex, which was considered to be an act of impurity. Therefore, marriage was done away with in the body of the Believers in the Second Appearance, which was patterned after the Kingdom of God, in which there would be no marriage or giving in marriage. The four highest Shaker virtues were virgin purity; communalism; confession of sin—without which one could not become a Believer; and separation from the world.
Celibacy and children.
Shakers were celibate; procreation was forbidden after they joined the society (except for women who were already pregnant at admission). Children were added to their communities through indenture, adoption, or conversion. Occasionally a foundling was anonymously left on a Shaker doorstep. They welcomed all, often taking in orphans and the homeless. For children, Shaker life was structured, safe, and predictable, with no shortage of adults who cared about their young charges.
When Shaker youngsters, girls and boys, reached the age of 21, they were free to leave or to remain with the Shakers. Unwilling to remain celibate, many chose to leave; today there are thousands of descendants of Shaker-raised seceders.
Gender roles.
Shaker religion valued women and men equally in religious leadership. The church was hierarchical, and at each level women and men shared authority. This was reflective of the Shaker belief that God was both female and male. They believed men and women were equal in the sight of God, and should be treated equally on earth, too. Thus two Elders and two Eldresses formed the Ministry at the top of the administrative structure. Two lower-ranking Elders and two Eldresses led each family, women overseeing women and men overseeing men.
In their temporal labor, Shakers followed traditional gender work-related roles. Their homes were segregated by sex, as were women and men's work areas. Women worked indoors spinning, weaving, cooking, sewing, cleaning, washing, and making or packaging goods for sale. In good weather, groups of Shaker women were outdoors, gardening and gathering wild herbs for sale or home consumption. Men worked in the fields doing farm work and in their shops at crafts and trades. Shakers thus simultaneously valued women’s status in society and realized the importance and difficulty of women's work, not following traditional prejudices that would consider women a "weaker sex" simply to elevate the male, as it was unnecessary in their egalitarian social structure to do so. This also allowed the continuation of church leadership when there was a shortage of men.
Worship.
Shakers worshipped in meetinghouses painted white and unadorned; pulpits and decorations were eschewed as worldly things. In meeting, they marched, sang, danced, and sometimes turned, twitched, jerked, or shouted. The earliest Shaker worship services were unstructured, loud, chaotic and emotional. However, Shakers later developed precisely choreographed dances and orderly marches accompanied by symbolic gestures. Many outsiders disapproved of Shakers' mode of worship without understanding the symbolism of their movements or the content of their songs.
Shaker communities.
The Shakers built more than 20 Shaker communities in the United States. Women and men shared leadership of the Shaker communities. Women preached and received revelations as the Spirit fell upon them. Thriving on the religious enthusiasm of the first and second Great Awakenings, the Shakers declared their messianic, communitarian message with significant response. One early convert observed: “The wisdom of their instructions, the purity of their doctrine, their Christ-like deportment, and the simplicity of their manners, all appeared truly apostolical.” The Shakers represent a small but important Utopian response to the gospel. Preaching in their communities knew no boundaries of gender, social class, or education.
Economics.
The communality of the Believers was an economic success, and their cleanliness, honesty and frugality received the highest praise. All Shaker villages ran farms, using the latest scientific methods in agriculture. They raised most of their own food, so farming, and preserving the produce required to feed them through the winter, had to be priorities. Their livestock were fat and healthy, and their barns were commended for convenience and efficiency.
When not doing farm work, Shaker brethren pursued a variety of trades and hand crafts, many documented by Isaac N. Youngs. When not doing housework, Shaker sisters did likewise, spinning, weaving, sewing, and making sale goods.
Shakers ran a variety of businesses to support their communities. Many Shaker villages had their own tanneries, sold baskets, brushes, bonnets, brooms, fancy goods, and homespun fabric that was known for high quality, but were more famous for their medicinal herbs, garden seeds, apple-sauce, and knitted garments (Canterbury).
The Shaker goal in their temporal labor was perfection. Ann Lee's followers preserved her admonitions about work:
Mother Ann also cautioned them against getting into debt.
Shaker craftsmen were known for a style of Shaker furniture that was plain in style, durable, and functional. Shaker chairs were usually mass-produced because a great number of them were needed to seat all the Shakers in a community.
Around the time of the American Civil War, the Shakers at Mount Lebanon, New York, increased their production and marketing of Shaker chairs. They were so successful that several furniture companies produced their own versions of "Shaker" chairs. Because of the quality of their craftsmanship, original Shaker furniture is costly.
Shakers won respect and admiration for their productive farms and orderly communities. Their industry brought about many inventions like Babbitt metal, the rotary harrow, the circular saw, the clothespin, the Shaker peg, the flat broom, the wheel-driven washing machine, a machine for setting teeth in textile cards, a threshing machine, metal pens, a new type of fire engine, a machine for matching boards, numerous innovations in waterworks, planing machinery, a hernia truss, silk reeling machinery, small looms for weaving palm leaf, machines for processing broom corn, ball-and-socket tilters for chair legs, and a number of other useful inventions.
Shakers were the first large producers of medicinal herbs in the United States, and pioneers in the sale of seeds in paper packets. Brethren grew the crops, but sisters picked, sorted, and packaged their products for sale, so those industries were built on a foundation of women's labor in the Shaker partnership between the sexes.
The Shakers believed in the value of hard work and kept comfortably busy. Mother Ann said, "Labor to make the way of God your own; let it be your inheritance, your treasure, your occupation, your daily calling."
Architecture and furnishings.
The Shakers' dedication to hard work and perfection has resulted in a unique range of architecture, furniture and handicraft styles. They designed their furniture with care, believing that making something well was in itself, "an act of prayer." Before the late 19th century, they rarely fashioned items with elaborate details or extra decoration, but only made things for their intended uses. The ladder-back chair was a popular piece of furniture. Shaker craftsmen made most things out of pine or other inexpensive woods and hence their furniture was light in color and weight.
Early 19th-century Shaker interiors are characterized by an austerity and simplicity. For example, they had a "peg rail," a continuous wooden device like a pelmet with hooks running all along it near the lintel level. They used the pegs to hang up clothes, hats, and very light furniture pieces such as chairs when not in use. The simple architecture of their homes, meeting houses, and barns have had a lasting influence on American architecture and design. There is a collection of furniture and utensils at Hancock Shaker Village outside of Pittsfield, Massachusetts that is famous for its elegance and practicality.
At the end of the 19th century, however, Shakers adopted some aspects of Victorian decor, such as ornate carved furniture, patterned linoleum, and cabbage-rose wallpaper. Examples are on display in the Hancock Shaker Village Trustees' Office, a formerly spare, plain building "improved" with ornate additions such as fish-scale siding, bay windows, porches, and a tower.
Culture.
Artifacts.
By the middle of the 20th century, as the Shaker communities themselves were disappearing, some American collectors whose visual tastes were formed by the stark aspects of the modernist movement found themselves drawn to the spare artifacts of Shaker culture, in which "form follows function" was also clearly expressed. Kaare Klint, an architect and famous furniture designer, used styles from Shaker furniture in his work.
Other artifacts of Shaker culture are their spirit drawings, dances, and songs, which are important genres of Shaker folk art. Doris Humphrey, an innovator in technique, choreography, and theory of dance movement, made a full theatrical art with her dance entitled Dance of The Chosen, which depicted Shaker religious fervor.
Music.
The Shakers composed thousands of songs, and also created many dances; both were an important part of the Shaker worship services. In Shaker society, a spiritual "gift" could also be a musical revelation, and they considered it important to record musical inspirations as they occurred.
Scribes, many of whom had no formal musical training, used a form of music notation called the letteral system. This method used letters of the alphabet, often not positioned on a staff, along with a simple notation of conventional rhythmic values, and has a curious, and coincidental, similarity to some ancient Greek music notation.
Many of the lyrics to Shaker tunes consist of syllables and words from unknown tongues, the musical equivalent of glossolalia. It has been surmised that many of them were imitated from the sounds of Native American languages, as well as from the songs of African slaves, especially in the southernmost of the Shaker communities , but in fact the melodic material is derived from European scales and modes.
Most early Shaker music is monodic, that is to say, composed of a single melodic line with no harmonization. The tunes and scales recall the folksongs of the British Isles, but since the music was written down and carefully preserved, it is "art" music of a special kind rather than folklore. Many melodies are of extraordinary grace and beauty, and the Shaker song repertoire, though still relatively little known, is an important part of the American cultural heritage and of world religious music in general.
Shakers' earliest hymns were shared by word of mouth and letters circulated among their villages. Many Believers wrote out the lyrics in their own manuscript hymnals. In 1813, they published "Millennial Praises", a hymnal containing only lyrics.
In the late 19th century, the Shakers published several hymnbooks with both lyrics and music in conventional four-part harmonies. These works are less strikingly original than the earlier, monodic repertoire.
The surviving Shakers sing songs drawn from both the earlier repertoire and the four part songbooks. They perform all of these unaccompanied, in single-line unison singing. The many recent, harmonized arrangements of older Shaker songs for choirs and instrumental groups mark a departure from traditional Shaker practice.
"Simple Gifts" was composed by Elder Joseph Brackett and originated in the Shaker community at Alfred, Maine in 1848. Many contemporary Christian denominations incorporate this tune into hymnals, under various names, including "Lord of the Dance," adapted in 1963 by English poet and songwriter Sydney Carter.
Some scholars, such as Daniel W. Patterson and Roger Lee Hall, have compiled books of Shaker songs, and groups have been formed to sing the songs and perform the dances.
The most extensive recordings of the Shakers singing their own music were made between 1960 and 1980 and released on a 2-CD set with illustrated booklet, "Let Zion Move: Music of the Shakers." . Other recordings are available of Shaker songs, both documentation of singing by the Shakers themselves, as well as songs recorded by other groups (see external links). Two widely distributed commercial recordings by The Boston Camerata, "Simple Gifts" (1995) and "The Golden Harvest" (2000), were recorded at the Shaker community of Sabbathday Lake, Maine, with active cooperation from the surviving Shakers, whose singing can be heard at several points on both recordings.
Aaron Copland's iconic 1944 ballet score "Appalachian Spring", written for Martha Graham, uses the now famous Shaker tune "Simple Gifts" as the basis of its finale. Given to Graham with the working title "Ballet for Martha," it was named by her for the scenario she had in mind, though Copland often said he was thinking of neither Appalachia nor Spring while he wrote it.
Works inspired by Shaker culture.
Shaker lifestyle and tradition is celebrated in Arlene Hutton's play "As It Is in Heaven", which is a re-creation of a decisive time in the history of the Shakers. The play is written by Arlene Hutton, the pen name of actor/director Beth Lincks. Born in Louisiana and raised in Florida, Lincks was inspired to write the play after visiting the Pleasant Hills Shaker village in Harrodsburg, Kentucky, a restored community that the Shakers occupied for more than a century, before abandoning it in 1927 because of the inability of the sect to attract new converts.
Novelist John Fowles wrote in 1985 "A Maggot", a postmodern historical novel culminating in the birth of Ann Lee, and describing early Shakers in England.
In 2004 the Finnish choreographer Tero Saarinen and Boston Camerata music director Joel Cohen created a live performance work with dance and music entitled "Borrowed Light." While all the music is Shaker song performed in a largely traditional manner, the dance intermingles only certain elements of Shaker practice and belief with Saarinen's original choreographic ideas, and with distinctive costumes and lighting. "Borrowed Light" has been given over 60 performances since 2004 in eight countries, recently (early 2008) in Australia and New Zealand, and most recently (2011) in France, Germany, Finland, the Netherlands, and Belgium. In addition to Doris Humphrey, Martha Graham and Tero Saarinen cited above, choreographers Twyla Tharp (“Sweet Fields,” 1996) and Martha Clarke (“Angel Reapers,” 2011) also set movement to Shaker hymns. Playwright Alfred Uhry collaborated with Martha Clarke on "Angel Reapers" and used Shaker texts as source material. The music of "Angel Reapers" is derived almost entirely from two CD programs by Joel Cohen and the Boston Camerata (assisted by the Shakers of Sabbathday Lake), "Simple Gifts," and "The Golden Harvest."
In 2009, Toronto-based, American-born poet Damian Rogers released her first volume of poetry, "Paper Radio". The lifestyle and philosophy of the Shakers and their matriarch Ann Lee are recurring themes in her work.
Education.
The Shaker educational system was very advanced. The educational subjects included reading, spelling, oration, arithmetic and manners. The boys would attend class during the winter and the girls in the summer. Parents outside of the community respected the Shakers' schooling so much that they often took advantage of schooling that the Shaker villages provided. Parents would drop their child off at the village to be educated, only to return several years later to pick up the children. Those who were removed from the Shaker community by their parents were not the only ones to leave. Once the child reached 21 years of age, they were given the option to remain Shakers. Less than 25 percent of the young adults remained in the community.
Modern-day Shakers.
Turnover was high; the group reached maximum size of about 5,000 full members in 1840, and/or 6,000 believers at the peak of the Shaker movement. There were only 12 Shaker communities left by 1920. The Shaker communities continued to lose members, partly through attrition, since believers did not give birth to children, and also due to economics; hand-made products by Shakers weren't as competitive as mass-produced products and individuals moved to the cities for better livelihoods.
The only remaining active Shaker community in the United States is Sabbathday Lake Shaker Village in Maine, which as of 2010 had one novitiate and only three full members: Sister June Carpenter, Brother Arnold Hadd, and Sister Frances Carr.

</doc>
<doc id="44405" url="http://en.wikipedia.org/wiki?curid=44405" title="Kabala">
Kabala

Kabala can refer to:

</doc>
<doc id="44406" url="http://en.wikipedia.org/wiki?curid=44406" title="Zoroaster">
Zoroaster

Zoroaster ( or , from Greek Ζωροάστρης "Zōroastrēs"), also known as Zarathustra (; Avestan: "𐬰𐬀𐬭𐬀𐬚𐬎𐬱𐬙𐬭𐬀" ("Zaraθuštra"); Persian: زرتشت‎ "Zartosht", زردشت "Zardosht"), was the founder of Zoroastrianism. Though he was a native speaker of Old Avestan and lived in the eastern part of the Iranian Plateau, his birthplace is uncertain. He is credited with the authorship of the Yasna Haptanghaiti as well as the Gathas, hymns which are at the liturgical core of Zoroastrian thinking. Most of his life is known through the Zoroastrian texts.
Avestan, the language spoken by Zoroaster and used for composing the Yasna Haptanghaiti and the Gathas, on archaeological and linguistic grounds, is dated to have been spoken probably in the first half of the 2nd millennium BCE. The Gathas in contrast to the mythological Avesta place the chronology of Zoroaster much later in history, with the most conservative being dated to around the mid-sixth century BCE and the most liberal estimate being c. 1,000 BCE. Arthur Emanuel Christensen dates Zoroaster to c. 625 BCE, but Ebrahim Pourdavoud Herzfeld and Johannes Hertel date Zoroaster as existing between 550–523 BCE.
Etymology.
Zoroaster's name in his native language, Avestan, was probably "Zaraϑuštra". His English name, "Zoroaster", derives from a later (5th century BCE) Greek transcription, "Zōroastrēs" (Ζωροάστρης), as used in Xanthus's "Lydiaca" (Fragment 32) and in Plato's "First Alcibiades" (122a1). This form appears subsequently in the Latin "Zōroastrēs" and, in later Greek orthographies, as "Zōroastris". The Greek form of the name appears to be based on a phonetic transliteration or semantic substitution of the Avestan "zaraϑ-" with the Greek "zōros" (literally "undiluted") and the Avestan "-uštra" with "astron" ("star").
In Avestan, "Zaraϑuštra" is generally accepted to derive from an Old Iranian "*Zaratuštra-"; The element half of the name ("-uštra-") is considered to be the Indo-Iranian root for "camel", the entire name meaning "he who can manage camels".[a]
Reconstructions from later Iranian languages—particularly from the Middle Persian (300 BCE) "Zardusht", which is the form that the name took in the 9th- to 12th-century Zoroastrian texts—suggest that "*Zaratuštra-" might be a zero-grade form of "*Zarantuštra-".
Subject then to whether "Zaraϑuštra" derives from "*Zarantuštra-" or from "*Zaratuštra-", several interpretations have been proposed.[b]
Following "*Zarantuštra-" are:
Following "*Zaratuštra-" are:
A folk etymology of the name is from "zaraϑa", "golden", and the "*uštra", "light" (from the root "uš", "to shine"). In yet another etymological variation, "Zaraϑuštra" is split into two words: "zara", "gold", and "ϑuštra", "friend". Several more etymologies have been proposed, some quite fanciful, but none are factually based.
In Alevi folk tales, commonly in Kurdish or Turkish, he is named "Zerdesht" (kurdish) or "Zerdusht" (Turkish): Heart-Hand (in paintings touching his heart with the right hand) or Gold-Friend (truth friend), one could mention, that it could also mean: Gold-Heart (pure in his heart) or Heart-Friend (speaking truthly).
The interpretation of the "-ϑ-" (/θ/) in Avestan "zaraϑuštra" was for a time itself subjected to heated debate because the "-ϑ-" is an irregular development: As a rule, "*zarat-" (a first element that ends in a dental consonant) should have Avestan "zarat-" or "zarat̰-" as a development from it. Why this is not so for "zaraϑuštra" has not yet been determined. Notwithstanding the phonetic irregularity, that Avestan "zaraϑuštra" with its "-ϑ-" was linguistically an actual form is shown by later attestations reflecting the same basis. All present-day, Iranian-language variants of his name derive from the Middle Iranian variants of "Zarϑošt", which, in turn, all reflect Avestan's fricative "-ϑ-".
Date.
The date of Zoroaster, i.e., the date of composition of the Old Avestan gathas, is unknown. Classical writers such as Plutarch and Diogenes proposed dates prior to 6000 BCE. Dates proposed in scholarly literature diverge widely, between the 18th and the 6th centuries BCE.
Until the late 17th century, Zoroaster was generally dated to about the 6th century BCE, which coincided with both the "Traditional date" (see details below) and historiographic accounts (Ammianus Marcellinus xxiii.6.32, 4th century CE). However, already at the time (late 19th century), the issue was far from settled.
The "Traditional date" originates in the period immediately following Alexander the Great's conquest of the Achaemenid Empire in 330 BCE. The Seleucid kings who gained power following Alexander's death instituted an "Age of Alexander" as the new calendrical epoch. This did not appeal to the Zoroastrian priesthood who then attempted to establish an "Age of Zoroaster". To do so, they needed to establish when Zoroaster had lived, which they accomplished by counting back the length of successive generations until they concluded that Zoroaster must have lived "258 years before Alexander". This estimate then re-appeared in the 9th- to 12th-century texts of Zoroastrian tradition,[c] which in turn gave the date doctrinal legitimacy, especially since it was made plausible also by the observational history of the Pleiades in the Geoponica that indicates Zoroaster as a principal source of some observations. In the early part of the 20th century, this remained the accepted date (subject to the uncertainties of the 'Age of Alexander'[d]) for a number of reputable scholars, among them Hasan Taqizadeh, a recognized authority on the various Iranian calendars, and hence became the date cited by Henning and others.
By the late 19th century, scholars such as Christian Bartholomae and Arthur Emanuel Christensen noted problems with the "Traditional date", namely in the linguistic difficulties that it presented. The Old Avestan language of the Gathas (which are attributed to the founder himself) is still very close to the Sanskrit of the Rigveda. Therefore, it seemed implausible that the Gathas and Rigveda could be more than a few centuries apart, suggesting a date for the oldest surviving portions of the Avesta of roughly the 2nd millennium BCE. A date of 11th or 10th century BCE is sometimes considered among Iranists, who in recent decades found that the social customs described in the Gathas roughly coincide with what is known of other pre-historical peoples of that period. The Gathas describe a society of bipartite (priests and herdsmen/farmers) nomadic pastoralists with tribal structures organized at most as small kingdoms. This contrasts sharply with the view of Zoroaster having lived in an empire, at which time society is attested to have had a tripartite structure (nobility/soldiers, priests, and farmers). Although a slightly earlier date (by a century or two) has been proposed on the grounds that the texts do not reflect the migration onto the Iranian Plateau, it is also possible that Zoroaster lived in one of the rural societies that remained in Central Asia.
Interestingly, Yasnas 5 & 105 describe how "Zoroaster prayed to Anahita for the conversion of King Vištaspa", this provides further evidence that Zoroaster resided during the reign of King Vištaspa; which would corroborate a chronology of late-6th century BCE 
Place.
"Yasna" 9 & 17 cite the Ditya River in Airyanem Vaējah (Middle Persian "Ērān Wēj") as Zoroaster's home and the scene of his first appearance. The Avesta (both Old and Younger portions) does not mention the Achaemenids or of any West Iranian tribes such as the Medes, Persians, or even Parthians.
However, in "Yasna" 59.18, the "zaraϑuštrotema", or supreme head of the Zoroastrian priesthood, is said to reside in 'Ragha'. In the 9th- to 12th-century Middle Persian texts of Zoroastrian tradition, this 'Ragha'—along with many other places—appear as locations in Western Iran. While the land of Media does not figure at all in the Avesta (the westernmost location noted in scripture is Arachosia), the "Būndahišn", or "Primordial Creation," (20.32 and 24.15) puts Ragha in Media (medieval Rai). However, in Avestan, Ragha is simply a toponym meaning "plain, hillside."
Apart from these indications in Middle Persian sources which are open to interpretations, there are a number of other sources. The Greek and Latin sources are divided on the birthplace of Zarathustra. There are many Greek accounts of Zarathustra, referred usually as Persian or Perso-Median Zoroaster. Moreover they have the suggestion that there has been more than one Zoroaster. On the other hand, in post-Islamic sources Shahrastani (1086–1153) an Iranian writer originally from Shahristān, present-day Turkmenistan, proposed that Zoroaster's father was from Atropatene (also in Medea) and his mother was from Rey. Coming from a reputed scholar of religions, this was a serious blow for the various regions who all claimed that Zoroaster originated from "their" homelands, some of which then decided that Zoroaster must then have then been buried in their regions or composed his Gathas there or preached there. Also Arabic sources of the same period and the same region of historical Persia consider Azerbaijan as the birthplace of Zarathustra.
By the late 20th century, most scholars had settled on an origin in Eastern Iran. Gnoli proposed Sistan, Baluchistan (though in a much wider scope than the present-day province) as the homeland of Zoroastrianism; Frye voted for Bactria and Chorasmia; Khlopin suggests the Tedzen Delta in present-day Turkmenistan.
Sarianidi considered the Bactria–Margiana Archaeological Complex region as "the native land of the Zoroastrians and, probably, of Zoroaster himself." Boyce includes the steppes to the west from the Volga. The medieval "from Media" hypothesis is no longer taken seriously, and Zaehner has even suggested that this was a Magi-mediated issue to garner legitimacy, but this has been likewise rejected by Gershevitch and others.
The 2005 "Encyclopedia Iranica" article on the history of Zoroastrianism summarizes the issue with "while there is general agreement that he did not live in western Iran, attempts to locate him in specific regions of eastern Iran, including Central Asia, remain tentative."
Life.
The "Gathas" contain allusions to personal events, such as Zoroaster's triumph over obstacles imposed by competing priests and the ruling class. They also indicate he had difficulty spreading his teachings, and was even treated with ill-will in his mother's hometown. They also describe familiar events such as the marriage of his daughter, at which Zoroaster presided. In the texts of the Younger "Avesta" (composed many centuries after the "Gathas"), Zoroaster is depicted wrestling with the "daeva"s and is tempted by Angra Mainyu to renounce his thinking ("Yasht" 17.19; "Vendidad" 19). The "Spend Nask", the 13th section of the Avesta, is said to have a description of the prophet's life. However, this text has been lost over the centuries, and it survives only as a summary in the seventh book of the 9th-century "Dēnkard". Other 9th- to 12th-century stories of Zoroaster, such as the "Shāhnāmeh", are also assumed to be based on earlier texts, but must be considered as primarily a collection of legends. The historical Zoroaster, however, eludes categorization as a legendary character.
Zoroaster was born into the priestly family of the "Spitamids" and his ancestor "Spitāma" is mentioned several times in the Gathas. His father's name was "Pourušaspa", or "Poroschasp", a noble Persian, and his mother's was Dughdova ("Duγδōuuā"). With his wife, Huvovi ("Hvōvi"), Zoroaster had three sons, Isat Vastar, Uruvat-Nara and Hvare Ciϑra; three daughters, Freni, Pourucista and Triti. His wife, children and a cousin named Maidhyoimangha were his first converts after his illumination from Ahura Mazda at age 30. According to "Yasnas" 5 & 105, Zoroaster prayed to Anahita for the conversion of King Vištaspa, who appears in the "Gathas" as a historic personage. In legends, Vištaspa is said to have had two brothers as courtiers, Frašaōštra and Jamaspa, and to whom Zoroaster was closely related: his wife, Hvōvi, was the daughter of Frashaōštra, while Jamaspa was the husband of his daughter Pourucista. The actual role of intermediary was played by the pious queen Hutaōsa. Apart from this connection, the new prophet relied especially upon his own kindred ("hvaētuš").
Death.
Zoroaster's death is not mentioned in the "Avesta". In "Shahnameh" 5.92, he is said to have been murdered at the altar by the Turanians in the storming of Balkh.
Zoroaster's death was said to have been in Balkh located in present-day Afghanistan during the Holy War between Turan and the Persian empire in 583 BCE. Jamaspa, his son-in-law, then became Zoroaster's successor.
Philosophy.
In the Gathas, Zoroaster sees the human condition as the mental struggle between "aša" (truth) and "druj" (lie). The cardinal concept of "aša"—which is highly nuanced and only vaguely translatable—is at the foundation of all Zoroastrian doctrine, including that of Ahura Mazda (who is "aša"), creation (that is "aša"), existence (that is "aša") and as the condition for free will.
The purpose of humankind, like that of all other creation, is to sustain "aša". For humankind, this occurs through active participation in life and the exercise of constructive thoughts, words and deeds.
Elements of Zoroastrian philosophy entered the West through their influence on Judaism and Middle Platonism and have been identified as one of the key early events in the development of philosophy. Among the classic Greek philosophers, Heraclitus is often referred to as inspired by Zoroaster's thinking.
Zoroaster emphasized the freedom of the individual to choose right or wrong and individual responsibility for one's deeds. This personal choice to accept "aša" or arta (the divine order), and shun "druj" (ignorance and chaos) is one's own decision and not a dictate of Ahura Mazda. For Zarathustra, by thinking good thoughts, saying good words, and doing good deeds (e.g. assisting the needy or doing good works) we increase this divine force "aša" or arta in the world and in ourselves, celebrate the divine order, and we come a step closer on the everlasting road to being one with the Creator. Thus, we are not the slaves or servants of Ahura Mazda, but we can make a personal choice to be his co-workers, thereby refreshing the world and ourselves.
Iconography.
Although a few recent depictions of Zoroaster show the prophet performing some deed of legend, in general the portrayals merely present him in white vestments (which are also worn by present-day Zoroastrian priests). He often is seen holding a "baresman" (Avestan; Middle Persian "barsom"), which is generally considered to be another symbol of priesthood, or with a book in hand, which may be interpreted to be the Avesta. Alternatively, he appears with a mace, the "varza"—usually stylized as a steel rod crowned by a bull's head—that priests carry in their installation ceremony. In other depictions he appears with a raised hand and thoughtfully lifted finger, as if to make a point. Zoroaster is rarely depicted as looking directly at the viewer; instead, he appears to be looking slightly upwards, as if beseeching. Zoroaster is almost always depicted with a beard, this along with other factors bearing similarities to 19th-century portraits of Jesus.
A common variant of the Zoroaster images derives from a Sassanid-era rock-face carving. In this depiction at Taq-e Bostan, a figure is seen to preside over the coronation of Ardashir I or II. The figure is standing on a lotus, with a "baresman" in hand and with a gloriole around his head. Until the 1920s, this figure was commonly thought to be a depiction of Zoroaster, but in recent years is more commonly interpreted to be a depiction of Mithra. Among the most famous of the European depictions of Zoroaster is that of the figure in Raphael's 1509 The School of Athens. In it, Zoroaster and Ptolemy are having a discussion in the lower right corner. The prophet is holding a star-studded globe.
Western civilization.
In classical antiquity.
Although, at the core, the Greeks (in the Hellenistic sense of the term) understood Zoroaster to be the "prophet and founder of the religion of the Iranian peoples" (e.g. Plutarch "Isis and Osiris" 46-7, Diogenes Laertius 1.6–9 and Agathias 2.23-5), "the rest was mostly fantasy". He was set in the impossibly ancient past, six to seven millennia before the Common Era, and was variously a king of Bactria, or a Babylonian (or teacher of Babylonians), and with a biography typical for every Neopythagorean sage, i.e. a mission preceded by ascetic withdrawal and enlightenment.
Most importantly however, was their picture of Zoroaster as the sorcerer-astrologer "non-plus-ultra", and indeed as the "inventor" of both magic and astrology. Deriving from that image, and reinforcing it, was a "mass of literature" attributed to him and that circulated the Mediterranean world from the 3rd century BCE to the end of antiquity and beyond. "The Greeks considered the best wisdom to be exotic wisdom" and "what better and more convenient authority than the distant—temporally and geographically—Zoroaster?"
The language of that literature was predominantly Greek, though at one stage or another various parts of it passed through Aramaic, Syriac, Coptic or Latin. Its ethos and cultural matrix was likewise Hellenistic, and "the ascription of literature to sources beyond that political, cultural and temporal framework represents a bid for authority and a fount of legitimizing "alien wisdom". Zoroaster and the magi did not compose it, but their names sanctioned it." The attributions to "exotic" names (not restricted to magians) conferred an "authority of a remote and revelation wisdom."
Once the magi were associated with magic in Greek imagination, Zoroaster was bound to metamorphose into a magician too. The 1st-century Pliny the Elder names Zoroaster as the inventor of magic ("Natural History" 30.2.3). "However, a principle of the division of labor appears to have spared Zoroaster most of the responsibility for introducing the dark arts to the Greek and Roman worlds." That "dubious honor" went to the "fabulous magus, Ostanes, to whom most of the pseudepigraphic magical literature was attributed." Although Pliny calls him the inventor of magic, the Roman does not provide a "magician's persona" for him. Moreover, the little "magical" teaching that is ascribed to Zoroaster is actually very late, with the very earliest example being from the 14th century.
One factor for the association with astrology was Zoroaster's name, or rather, what the Greeks made of it. Within the scheme of Greek thinking (which was always on the lookout for hidden significances and "real" meanings of words) his name was identified at first with star-worshiping ("astrothytes" "star sacrificer") and, with the "Zo-", even as the "living" star. Later, an even more elaborate mythoetymology evolved: Zoroaster died by the living ("zo-") flux ("-ro-") of fire from the star ("-astr-") which he himself had invoked, and even, that the stars killed him in revenge for having been restrained by him.
Similar ideas about Zoroaster also appear in early Christian literature, beginning with the "Clementine Homilies" 9.4–5, which identifies him with a parallel series of traditions about Nimrod having been the founder of astrology. In this account, Nimrod is killed by lightning and posthumously deified by the Persians as "Zoroaster, on account of the living ("zosan") stream of the star ("asteros") being poured upon him."
The second, and "more serious" factor for the association with astrology was the notion that Zoroaster was a Babylonian. The alternate Greek name for Zoroaster was Zaratas/Zaradas/Zaratos ("cf." Agathias 2.23-5, Clement "Stromata" I.15), which—so Cumont and Bidez—derived from a Semitic form of his name. The Pythagorean tradition considered the mathematician to have studied with Zoroaster in Babylonia (Porphyry "Life of Pythagoras" 12, Alexander Polyhistor apud Clement's "Stromata" I.15, Diodorus of Eritrea, Aristoxenus apud Hippolitus VI32.2). Lydus ("On the Months" II.4) attributes the creation of the seven-day week to "the Babylonians in the circle of Zoroaster and Hystaspes," and who did so because there were seven planets. The Suda's chapter on "astronomia" notes that the Babylonians learned their astrology from Zoroaster. Lucian of Samosata ("Mennipus" 6) decides to journey to Babylon "to ask one of the magi, Zoroaster's disciples and successors," for their opinion.
While the division along the lines of Zoroaster/astrology and Ostanes/magic is an "oversimplification, the descriptions do at least indicate what the works are "not"." They were not expressions of Zoroastrian doctrine, they were not even expressions of what the Greeks and Romans ""imagined" the doctrines of Zoroastrianism to have been." The assembled fragments do not even show noticeable commonality of outlook and teaching among the several authors who wrote under each name.
Almost all Zoroastrian pseudepigrapha is now lost, and of the attested texts—with only one exception—only fragments have survived. Pliny's 2nd- or 3rd-century attribution of "two million lines" to Zoroaster suggest that (even if exaggeration and duplicates are taken into consideration) a formidable pseudepigraphic corpus once existed at the Library of Alexandria. This corpus can safely be assumed to be pseudepigrapha because no one before Pliny refers to literature by "Zoroaster", and on the authority of the 2nd-century Galen of Pergamon and from a 6th-century commentator on Aristotle it is known that the acquisition policies of well-endowed royal libraries created a market for fabricating manuscripts of famous and ancient authors.
The exception to the fragmentary evidence (i.e. reiteration of passages in works of other authors) is a complete Coptic tractate titled "Zostrianos" (after the first-person narrator) discovered in the Nag Hammadi library in 1945. A three-line cryptogram in the colophones following the 131-page treatise identify the work as "words of truth of Zostrianos. God of Truth ["logos"]. Words of Zoroaster." Invoking a "God of Truth" might seem Zoroastrian, but there is otherwise "nothing noticeably Zoroastrian" about the text and "in content, style, ethos and intention, its affinities are entirely with the congeners among the Gnostic tractates."
Among the named works attributed to "Zoroaster" is a treatise "On Nature" ("Peri physeos"), which appears to have originally constituted four volumes (i.e. papyrus rolls). The framework is a retelling of Plato's "Myth of Er", with Zoroaster taking the place of the original hero. While Porphyry imagined Pythagoras listening to Zoroaster's discourse, "On Nature" has the sun in middle position, which was how it was understood in the 3rd century. In contrast, Plato's 4th-century BCE version had the sun in second place above the moon. Ironically, Colotes accused Plato of plagiarizing Zoroaster, and Heraclides Ponticus wrote a text titled "Zoroaster" based on (what the author considered) "Zoroastrian" philosophy in order to express his disagreement with Plato on natural philosophy. With respect to substance and content in "On Nature" only two facts are known: that it was crammed with astrological speculations, and that Necessity ("Ananké") was mentioned by name and that she was in the air.
Another work circulating under the name of "Zoroaster" was the "Asteroskopita" (or "Apotelesmatika"), and which ran to five volumes (i.e. papyrus rolls). The title and fragments suggest that it was an astrological handbook, "albeit a very varied one, for the making of predictions." A third text attributed to Zoroaster is "On Virtue of Stones" ("Peri lithon timion"), of which nothing is known other than its extent (one volume) and that pseudo-Zoroaster "sang" it (from which Cumont and Bidez conclude that it was in verse). Numerous other fragments (preserved in the works of other authors) are attributed to "Zoroaster," but the titles of whose books are not mentioned.
These pseudepigraphic texts aside, some authors did draw on a few genuinely Zoroastrian ideas. The "Oracles of Hystaspes", by "Hystaspes", another prominent magian pseudo-author, is a set of prophecies distinguished from other Zoroastrian pseudepigrapha in that it draws on real Zoroastrian sources. Some allusions are more difficult to assess: in the same text that attributes the invention of magic to Zoroaster, Pliny states that Zoroaster laughed on the day of his birth, although in an earlier place (VII, I), Pliny had sworn in the name of Hercules that no child had ever done so before the 40th day from his birth. This notion of Zoroaster's laughter (like that of "two million verses") also appears in the 9th– to 11th-century texts of genuine Zoroastrian tradition, and for a time it was assumed that the origin of those myths lay with indigenous sources. Pliny also records (VII, XV) that Zoroaster's head had pulsated so strongly that it repelled the hand when laid upon it, a presage of his future wisdom. The Iranians were however just as familiar with the Greek writers. The provenance of other descriptions are clear, so for instance, Plutarch's description of its dualistic theologies: "Others call the better of these a god and his rival a daemon, as, for example, Zoroaster the Magus, who lived, so they record, five thousand years before the siege of Troy. He used to call the one Horomazes and the other Areimanius" ("Isis and Osiris" 46-7).
In the post-classical era.
Zoroaster was known as a sage, magician, and miracle-worker in post-Classical Western culture. Although almost nothing was known of his ideas until the late 18th century, his name was already associated with lost ancient wisdom. However as early as 1643 statements by Sir Thomas Browne are the earliest recorded references to Zoroaster in the English language.
Zoroaster appears as "Sarastro" in Mozart's opera "Die Zauberflöte", which has been noted for its Masonic elements. He is also the subject of the 1749 opera "Zoroastre", by Jean-Philippe Rameau.
Enlightenment writers such as Voltaire promoted research into Zoroastrianism in the belief that it was a form of rational Deism, preferable to Christianity. With the translation of the Avesta by Abraham Anquetil-Duperron, Western scholarship of Zoroastrianism began.
In E. T. A. Hoffmann's novel "", the mage Prosper Alpanus states that Professor Zoroaster was his teacher.
In his seminal work "Also sprach Zarathustra (Thus Spoke Zarathustra)" (1885) the philosopher Friedrich Nietzsche uses the native Iranian name Zarathustra which has a significant meaning[s] as he had used the familiar Greek-Latin name in his earlier works. It is believed that Nietzsche invents a characterization of Zarathustra as the mouthpiece for Nietzsche's own ideas against morality.[f] Richard Strauss's Opus 30, inspired by Nietzsche's book, is also called "Also sprach Zarathustra".
Zoroaster was mentioned by the Irish poet William Butler Yeats. He and his wife were said to have claimed to have contacted Zoroaster through "automatic writing".
The Appellate Division of the Supreme Court of New York has a sculpture of Zoroaster towering over the building on E. 25th St. and Madison Ave in Manhattan, representing the ancient Persian judicial wisdom. The sculpture was made by Edward Clarke Potter in 1896. Also on the south side of the exterior of Rockefeller Memorial Chapel in the campus of the University of Chicago, there is a sculpture of Zoroaster among other prominent religious figures.
The protagonist and narrator of Gore Vidal's 1981 novel "Creation" is described to be the grandson of Zoroaster.
Zarathustra, the mythic hero in Giannina Braschi's 2011 dramatic novel "United States of Banana", joins forces with Shakespeare's Hamlet.
In other religious systems.
In Islam.
Citing the authority of the 8th-century al-Kalbi, the 9th- and 10th-century Sunni historian al-Tabari (i.648) reports that Zaradusht bin Isfiman (an Arabic adaptation of "Zarathustra Spitama") was an inhabitant of Israel and a servant of one of the disciples of the prophet Jeremiah. According to this tale, Zaradusht defrauded his master, who cursed him, causing him to become leprous (cf. Elisha's servant Gehazi in Jewish Scripture). The apostate Zaradusht then eventually made his way to Balkh (present day Afghanistan) where he converted Bishtasb (i.e. Vishtaspa), who in turn compelled his subjects to adopt the religion of the Magians. Recalling other tradition, al-Tabari (i.681–683) recounts that Zaradusht accompanied a Jewish prophet to Bishtasb/Vishtaspa. Upon their arrival, Zaradusht translated the sage's Hebrew teachings for the king and so convinced him to convert (Tabari also notes that they had previously been "Sabi"s) to the Magian religion.
The 12th-century heresiographer al-Shahrastani describes the Majusiya into three sects, the "Kayumarthiya", the "Zurwaniya" and the "Zaradushtiya", among which Al-Shahrastani asserts that only the last of the three were properly followers of Zoroaster. As regards the recognition of a prophet, the Zoroaster has said: "They ask you as to how should they recognize a prophet and believe him to be true in what he says; tell them what he knows the others do not, and he shall tell you even what lies hidden in your nature; he shall be able to tell you whatever you ask him and he shall perform such things which others cannot perform." (Namah Shat Vakhshur Zartust, .5–7. 50–54) Shortly before the advent of the prophet of Islam, [Muhammad], Persia was under the sovereignty of Sasan V. When the companions of the Prophet, on invading Persia, came in contact with the Zoroastrian people and learned these teachings, they at once came to the conclusion that Zoroaster was really a Divinely inspired prophet. Thus they accorded the same treatment to the Zoroastrian people which they did to other "People of the Book". Though the name of Zoroaster is not mentioned in the Qur'an, still he was regarded as one of those prophets whose names have not been mentioned in the Qur'an, for there is a verse in the Qur'an: "And We did send apostles before thee: there are some of them that We have mentioned to thee and there are others whom We have not mentioned to Thee." (40 : 78). Accordingly the Muslims treated the founder of Zoroastrianism as a true prophet and believed in his religion as they did in other inspired creeds, and thus according to the prophecy, protected the Zoroastrian religion. James Darmestar remarked in the translation of Zend Avesta: "When Islam assimilated the Zoroastrians to the People of the Book, it evinced a rare historical sense and solved the problem of the origin of the Avesta." (Introduction to Vendiad. p. 69.)
Ahmadiyya view.
Ahmadi Muslims view Zoroaster as a Prophet of God and describe the expressions of Ahura Mazda, the God of goodness and Ahraman, the God of evil as merely referring to the coexistence of forces of good and evil enabling humans to exercise free will. Mirza Tahir Ahmad, the fourth Caliph of the Ahmadiyya Muslim Community, in his book "Revelation, Rationality, Knowledge & Truth" views Zoroaster as Prophet of God and describes such the expressions to be a concept which is similar to the concepts in Judaism, Christianity and Islam.
In Manichaeism.
Manichaeism considered Zoroaster to be a figure (along with Jesus and the Buddha) in a line of prophets of which Mani (216–276) was the culmination. Zoroaster's ethical dualism is—to an extent—incorporated in Mani's doctrine, which viewed the world as being locked in an epic battle between opposing forces of good and evil. Manicheanism also incorporated other elements of Zoroastrian tradition, particularly the names of supernatural beings; however, many of these other Zoroastrian elements are either not part of Zoroaster's own teachings or are used quite differently from how they are used in Zoroastrianism.
In the Bahá'í Faith.
Zoroaster appears in the Bahá'í Faith as a "Manifestation of God", one of a line of prophets who have progressively revealed the Word of God to a gradually maturing humanity. Zoroaster thus shares an exalted station with Abraham, Moses, Krishna, Jesus, Muhammad, the Báb, and the founder of the Bahá'í Faith, Bahá'u'lláh. Shoghi Effendi, the head of the Bahá'í Faith in the first half of the 20th century, saw Bahá'u'lláh as the fulfillment of a post-Sassanid Zoroastrian prophecy that saw a return of Sassanid emperor Bahram: Shoghi Effendi also stated that Zoroaster lived roughly 1000 years before Jesus.[z]
Notes.
</dl>
Bibliography.
</dl>

</doc>
<doc id="44408" url="http://en.wikipedia.org/wiki?curid=44408" title="Microphone array">
Microphone array

A microphone array is any number of microphones operating in tandem. There are many applications:
Typically, an array is made up of omnidirectional microphones, directional microphones, or a mix of omnidirectional and directional microphones distributed about the perimeter of a space, linked to a computer that records and interprets the results into a coherent form. Arrays may also be formed using numbers of very closely spaced microphones. Given a fixed physical relationship in space between the different individual microphone transducer array elements, simultaneous DSP (digital signal processor) processing of the signals from each of the individual microphone array elements can create one or more "virtual" microphones. Different algorithms permit the creation of virtual microphones with extremely complex virtual polar patterns and even the possibility to steer the individual lobes of the virtual microphones patterns so as to home-in-on, or to reject, particular sources of sound. 
An array of 1020 microphones , the largest in the world, was built by researchers at the MIT Computer Science and Artificial Intelligence Laboratory.
Soundfield microphone.
The Soundfield microphone system is a well established example of the use of a microphone array in professional sound recording.

</doc>
<doc id="44410" url="http://en.wikipedia.org/wiki?curid=44410" title="Conjunctivitis">
Conjunctivitis

Conjunctivitis, also known as pink eye or Madras eye is inflammation of the conjunctiva (the outermost layer of the eye and the inner surface of the eyelids). It is commonly due to an infection (usually viral, but sometimes bacterial) or an allergic reaction.
Conjunctivitis can affect one or both eyes and is the most likely diagnosis in someone with eye redness and discharge (fluid coming from the eye). The affected eye is often "stuck shut" in the morning. Bacterial and viral conjunctivitis are highly contagious, and are transmitted through contact with the discharge. Generally speaking, conjunctivitis will go away on its own and poses no serious health risk. Eye drops can help relieve symptoms and, for bacterial causes, likely reduce the length of the illness if given early.
Classification.
Classification can be either by cause or by extent of the inflamed area.
By extent of involvement.
Blepharoconjunctivitis is the dual combination of conjunctivitis with blepharitis (inflammation of the eyelids).
Keratoconjunctivitis is the combination of conjunctivitis and keratitis (corneal inflammation).
Signs and symptoms.
Red eye (hyperaemia), swelling of conjunctiva (chemosis) and watering (epiphora) of the eyes are symptoms common to all forms of conjunctivitis. However, the pupils should be normally reactive, and the visual acuity normal.
Viral.
Viral conjunctivitis is often associated with an infection of the upper respiratory tract, a common cold, and/or a sore throat. Its symptoms include excessive watering and itching. The infection usually begins with one eye, but may spread easily to the other.
Viral conjunctivitis shows a fine, diffuse pinkness of the conjunctiva, which is easily mistaken for the ciliary infection of Iris (Iritis), but there are usually corroborative signs on microscopy, particularly numerous lymphoid follicles on the tarsal conjunctiva, and sometimes a punctate keratitis.
Some other viruses that can infect the eye include Herpes simplex virus and Varicella zoster.
Allergic.
Allergic conjunctivitis is inflammation of the conjunctiva (the membrane covering the white part of the eye) due to allergy. Allergens differ among patients. Symptoms consist of redness (mainly due to vasodilation of the peripheral small blood vessels), oedema (swelling) of the conjunctiva, itching, and increased lacrimation (production of tears). If this is combined with rhinitis, the condition is termed "allergic rhinoconjunctivitis".
The symptoms are due to release of histamine and other active substances by mast cells, which stimulate dilation of blood vessels, irritate nerve endings, and increase secretion of tears.
Bacterial.
Bacterial conjunctivitis causes the rapid onset of conjunctival redness, swelling of the eyelid, and mucopurulent discharge. Typically, symptoms develop first in one eye, but may spread to the other eye within 2–5 days. Bacterial conjunctivitis due to common pyogenic (pus-producing) bacteria causes marked grittiness/irritation and a stringy, opaque, greyish or yellowish mucopurulent discharge that may cause the lids to stick together, especially after sleep. Severe crusting of the infected eye and the surrounding skin may also occur. The gritty and/or scratchy feeling is sometimes localized enough for patients to insist they must have a foreign body in the eye. The more acute pyogenic infections can be painful. Common bacteria responsible for non-acute bacterial conjunctivitis are Staphylococci and Streptococci.
Bacteria such as "Chlamydia trachomatis" or "Moraxella" can cause a non-exudative but persistent conjunctivitis without much redness. Bacterial conjunctivitis may cause the production of membranes or pseudomembranes that cover the conjunctiva. Pseudomembranes consist of a combination of inflammatory cells and exudates, and are loosely adherent to the conjunctiva, while true membranes are more tightly adherent and cannot be easily peeled away. Cases of bacterial conjunctivitis that involve the production of membranes or pseudomembranes are associated with Neisseria gonorrhoeae, β-hemolytic streptococci, and C. diphtheriae. "Corynebacterium diphtheriae" causes membrane formation in conjunctiva of non-immunized children.
Chemical.
Chemical eye injury is due to either an acidic or alkali substance getting in the eye. Alkalis are typically worse than acidic burns. Mild burns will produce conjunctivitis, while more severe burns may cause the cornea to turn white. Litmus paper is an easy way to rule out the diagnosis by verifying that the pH is within the normal range of 7.0—7.2. Large volumes of irrigation is the treatment of choice and should continue until the pH is 6—8. Local anaesthetic eye drops can be used to decrease the pain.
Irritant or toxic conjunctivitis show primarily marked redness. If due to splash injury, it is often present in only the lower conjunctival sac. With some chemicals, above all with caustic alkalis such as sodium hydroxide, there may be necrosis of the conjunctiva with a deceptively white eye due to vascular closure, followed by sloughing of the dead epithelium. This is likely to be associated with slit-lamp evidence of anterior uveitis.
Other.
Inclusion conjunctivitis of the newborn (ICN) is a conjunctivitis that may be caused by the bacteria "Chlamydia trachomatis", and may lead to acute, purulent conjunctivitis. However, it is usually self-healing.
Conjunctivitis is identified by irritation and redness of the conjunctiva. Except in obvious pyogenic or toxic/chemical conjunctivitis, a slit lamp (biomicroscope) is needed to have any confidence in the diagnosis. Examination of the tarsal conjunctiva is usually more diagnostic than the bulbar conjunctiva.
Causes.
Conjunctivitis when caused by an infection is most commonly caused by a viral infection. Bacterial infections, allergies, other irritants and dryness are also common causes. Both bacterial and viral infections are contagious and passed from person to person, but can also spread through contaminated objects or water.
The most common cause of viral conjunctivitis is adenoviruses (see: Adenoviral keratoconjunctivitis). Herpetic keratoconjunctivitis (caused by herpes simplex viruses) can be serious and requires treatment with acyclovir. Acute hemorrhagic conjunctivitis is a highly contagious disease caused by one of two enteroviruses, Enterovirus 70 and Coxsackievirus A24. These were first identified in an outbreak in Ghana in 1969, and have spread worldwide since then, causing several epidemics.
The most common causes of acute bacterial conjunctivitis are "Staphylococcus aureus", "Streptococcus pneumoniae", and "Haemophilus influenzae". Though very rare, hyperacute cases are usually caused by "Neisseria gonorrhoeae" or "N. meningitidis". Chronic cases of bacterial conjunctivitis are those lasting longer than 3 weeks, and are typically caused by "Staphylococcus aureus", "Moraxella lacunata", or gram-negative enteric flora.
Conjunctivitis may also be caused by allergens such as pollen, perfumes, cosmetics, smoke, dust mites, Balsam of Peru, and eye drops.
An exceptional case of conjunctivitis induced by a trombiculid mite ("Neotrombicula autumnalis") was reported in 2013.
Conjunctivitis is part of the triad of reactive arthritis, which is thought to be caused by autoimmune cross-reactivity following certain bacterial infections. Reactive arthritis is highly associated with HLA-B27. Conjunctivitis is associated with the autoimmune disease relapsing polychondritis.
Diagnosis.
Cultures are not often taken or needed as most cases resolve either with time or typical antibiotics. Swabs for bacterial culture are necessary if the history and signs suggest bacterial conjunctivitis but there is no response to topical antibiotics. Viral culture may be appropriate in epidemic case clusters.
A patch test is used to identify the causative allergen in the case where conjunctivitis is caused by allergy.
Conjunctival scrapes for cytology can be useful in detecting chlamydial and fungal infections, allergy, and dysplasia, but are rarely done because of the cost and the general lack of laboratory staff experienced in handling ocular specimens. Conjunctival incisional biopsy is occasionally done when granulomatous diseases ("e.g.", sarcoidosis) or dysplasia are suspected.
Differential diagnosis.
There are more serious conditions that can present with a red eye such as infectious keratitis, angle closure glaucoma, or iritis. These conditions require the urgent attention of an ophthalmologist. Signs of such conditions include decreased vision, significantly increased sensitivity to light, inability to keep eye open, a pupil that does not respond to light, or a severe headache with nausea. Fluctuating blurring is common, due to tearing and mucoid discharge. Mild photophobia is common. However, if any of these symptoms are prominent, it is important to consider other diseases such as glaucoma, uveitis, keratitis and even meningitis or carotico-cavernous fistula.
A more comprehensive differential diagnosis for the red or painful eye includes: * corneal abrasions
Prevention.
The best effective prevention is hygiene and not rubbing the eyes by infected hands. Vaccination against adenovirus, haemophilus influenzae, pneumococcus, and neisseria meningitidis is also effective.
Management.
Conjunctivitis resolves in 65% of cases without treatment, within two to five days. The prescription of antibiotics is not necessary in most cases.
Viral.
Viral conjunctivitis usually resolves on its own and does not require any specific treatment. Antihistamines (e.g., promethazine) or mast cell stabilizers (e.g., cromolyn) may be used to help with the symptoms. Povidone iodine has been suggested as a treatment, but as of 2008 evidence to support it was poor.
Allergic.
For the allergic type, cool water poured over the face with the head inclined downward constricts capillaries, and artificial tears sometimes relieve discomfort in mild cases. In more severe cases, nonsteroidal anti-inflammatory medications and antihistamines may be prescribed. Persistent allergic conjunctivitis may also require topical steroid drops.
Bacterial.
Bacterial conjunctivitis usually resolves without treatment. Topical antibiotics may be needed only if no improvement is observed after three days. In people who received no antibiotics, recovery was in 4.8 days, with immediate antibiotics it was 3.3 days, and with delayed antibiotics 3.9 days. No serious effects were noted either with or without treatment. As they do speed healing in bacterial conjunctivitis, their use is also reasonable.
In those who wear contact lenses, are immunocompromised, have disease which is thought to be due to chlamydia or gonorrhea, have a fair bit of pain, or who have lots of discharge, antibiotics are recommended. Gonorrhea or chlamydia infections require both oral and topical antibiotics.
When appropriate, the choice of antibiotic varies, differing based on the cause (if known) or the likely cause of the conjunctivitis. Fluoroquinolones, sodium sulfacetamide, or trimethoprim/polymyxin may be used, typically for 7–10 days. Cases of meningococcal conjunctivitis can be treated with systemic penicillin, as long as the strain is sensitive to penicillin.
Chemical.
Conjunctivitis due to chemicals is treated via irrigation with Ringer's lactate or saline solution. Chemical injuries (particularly alkali burns) are medical emergencies, as they can lead to severe scarring and intraocular damage. People with chemically induced conjunctivitis should not touch their eyes, regardless of whether or not their hands are clean, as they run the risk of spreading the condition to another eye.
History.
A former superintendent of the Regional Institute of Ophthalmology in the city of Madras (the present-day Chennai) in India, Kirk Patrick, was the first to have found the adenovirus that caused conjunctivitis, leading to the name Madras eye for the disease.

</doc>
<doc id="44412" url="http://en.wikipedia.org/wiki?curid=44412" title="Sedimentary rock">
Sedimentary rock

Sedimentary rocks are types of rock that are formed by the deposition of material at the Earth's surface and within bodies of water. Sedimentation is the collective name for processes that cause mineral and/or organic particles (detritus) to settle and accumulate or minerals to precipitate from a solution. Particles that form a sedimentary rock by accumulating are called sediment. Before being deposited, sediment was formed by weathering and erosion in a source area, and then transported to the place of deposition by water, wind, ice, mass movement or glaciers which are called agents of denudation.
The sedimentary rock cover of the continents of the Earth's crust is extensive, but the total contribution of sedimentary rocks is estimated to be only 8% of the total volume of the crust. Sedimentary rocks are only a thin veneer over a crust consisting mainly of igneous and metamorphic rocks. Sedimentary rocks are deposited in layers as strata, forming a structure called bedding. The study of sedimentary rocks and rock strata provides information about the subsurface that is useful for civil engineering, for example in the construction of roads, houses, tunnels, canals or other structures. Sedimentary rocks are also important sources of natural resources like coal, fossil fuels, drinking water or ores.
The study of the sequence of sedimentary rock strata is the main source for scientific knowledge about the Earth's history, including palaeogeography, paleoclimatology and the history of life. The scientific discipline that studies the properties and origin of sedimentary rocks is called sedimentology. Sedimentology is part of both geology and physical geography and overlaps partly with other disciplines in the Earth sciences, such as pedology, geomorphology, geochemistry and structural geology.
Genetic classification.
Based on the processes responsible for their formation, sedimentary rocks can be subdivided into four groups: clastic sedimentary rocks, biochemical (or biogenic) sedimentary rocks, chemical sedimentary rocks and a fourth category for "other" sedimentary rocks formed by impacts, volcanism, and other minor processes.
Clastic sedimentary rocks.
Clastic sedimentary rocks are composed of silicate minerals and rock fragments that were transported by moving fluids (as bed load, suspended load, or by sediment gravity flows) and were deposited when these fluids came to rest. Clastic rocks are composed largely of quartz, feldspar, rock (lithic) fragments, clay minerals, and mica; numerous other minerals may be present as accessories and may be important locally.
Clastic sediment, and thus clastic sedimentary rocks, are subdivided according to the dominant particle size (diameter). Most geologists use the Udden-Wentworth grain size scale and divide unconsolidated sediment into three fractions: gravel (>2 mm diameter), sand (1/16 to 2 mm diameter), and mud (clay is <1/256 mm and silt is between 1/16 and 1/256 mm). The classification of clastic sedimentary rocks parallels this scheme; conglomerates and breccias are made mostly of gravel, sandstones are made mostly of sand, and mudrocks are made mostly of mud. This tripartite subdivision is mirrored by the broad categories of rudites, arenites, and lutites, respectively, in older literature.
Subdivision of these three broad categories is based on differences in clast shape (conglomerates and breccias), composition (sandstones), grain size and/or texture (mudrocks).
Conglomerates and breccias.
Conglomerates are dominantly composed of rounded gravel and breccias are composed of dominantly angular gravel.
Sandstones.
Sandstone classification schemes vary widely, but most geologists have adopted the Dott scheme, which uses the relative abundance of quartz, feldspar, and lithic framework grains and the abundance of muddy matrix between these larger grains.
Six sandstone names are possible using descriptors for grain composition (quartz-, feldspathic-, and lithic-) and amount of matrix (wacke or arenite). For example, a quartz arenite would be composed of mostly (>90%) quartz grains and have little/no clayey matrix between the grains, a lithic wacke would have abundant lithic grains (<90% quartz, remainder would have more lithics than feldspar) and abundant muddy matrix, etc.
Although the Dott classification scheme is widely used by sedimentologists, common names like greywacke, arkose, and quartz sandstone are still widely used by nonspecialists and in popular literature.
Mudrocks.
Mudrocks are sedimentary rocks composed of at least 50% silt- and clay-sized particles. These relatively fine-grained particles are commonly transported as suspended particles by turbulent flow in water or air, and deposited as the flow calms and the particles settle out of suspension.
Most authors presently use the term "mudrock" to refer to all rocks composed dominantly of mud. Mudrocks can be divided into siltstones (composed dominantly of silt-sized particles), mudstones (subequal mixture of silt- and clay-sized particles), and claystones (composed mostly of clay-sized particles). Most authors use "shale" as a term for a fissile mudrock (regardless of grain size) although some older literature uses the term "shale" as a synonym for mudrock.
Biochemical sedimentary rocks.
Biochemical sedimentary rocks are created when organisms use materials dissolved in air or water to build their tissue. Examples include:
Chemical sedimentary rocks.
Chemical sedimentary rock forms when mineral constituents in solution become supersaturated and inorganically precipitate. Common chemical sedimentary rocks include oolitic limestone and rocks composed of evaporite minerals such as halite (rock salt), sylvite, barite and gypsum.
"Other" sedimentary rocks.
This fourth miscellaneous category includes rocks formed by Pyroclastic flows, impact breccias, volcanic breccias, and other relatively uncommon processes.
Compositional classification schemes.
Alternatively, sedimentary rocks can be subdivided into compositional groups based on their mineralogy:
Deposition and diagenesis.
Sediment transport and deposition.
Sedimentary rocks are formed when sediment is deposited out of air, ice, wind, gravity, or water flows carrying the particles in suspension. This sediment is often formed when weathering and erosion break down a rock into loose material in a source area. The material is then transported from the source area to the deposition area. The type of sediment transported depends on the geology of the hinterland (the source area of the sediment). However, some sedimentary rocks, like evaporites, are composed of material that formed at the place of deposition. The nature of a sedimentary rock, therefore, not only depends on sediment supply, but also on the sedimentary depositional environment in which it formed.
Diagenesis.
The term diagenesis is used to describe all the chemical, physical, and biological changes, including cementation, undergone by a sediment after its initial deposition, exclusive of surface weathering. Some of these processes cause the sediment to consolidate: a compact, solid substance forms out of loose material. Young sedimentary rocks, especially those of Quaternary age (the most recent period of the geologic time scale) are often still unconsolidated. As sediment deposition builds up, the overburden (or lithostatic) pressure rises, and a process known as lithification takes place.
Sedimentary rocks are often saturated with seawater or groundwater, in which minerals can dissolve or from which minerals can precipitate. Precipitating minerals reduce the pore space in a rock, a process called cementation. Due to the decrease in pore space, the original connate fluids are expelled. The precipitated minerals form a cement and make the rock more compact and competent. In this way, loose clasts in a sedimentary rock can become "glued" together.
When sedimentation continues, an older rock layer becomes buried deeper as a result. The lithostatic pressure in the rock increases due to the weight of the overlying sediment. This causes compaction, a process in which grains mechanically reorganize. Compaction is, for example, an important diagenetic process in clay, which can initially consist of 60% water. During compaction, this interstitial water is pressed out of pore spaces. Compaction can also be the result of dissolution of grains by pressure solution. The dissolved material precipitates again in open pore spaces, which means there is a net flow of material into the pores. However, in some cases a certain mineral dissolves and does not precipitate again. This process, called leaching, increases pore space in the rock.
Some biochemical processes, like the activity of bacteria, can affect minerals in a rock and are therefore seen as part of diagenesis. Fungi and plants (by their roots) and various other organisms that live beneath the surface can also influence diagenesis.
Burial of rocks due to ongoing sedimentation leads to increased pressure and temperature, which stimulates certain chemical reactions. An example is the reactions by which organic material becomes lignite or coal. When temperature and pressure increase still further, the realm of diagenesis makes way for metamorphism, the process that forms metamorphic rock.
Properties.
Color.
The color of a sedimentary rock is often mostly determined by iron, an element with two major oxides: iron(II) oxide and iron(III) oxide. Iron(II) oxide only forms under anoxic circumstances and gives the rock a grey or greenish colour. Iron(III) oxide is often in the form of the mineral hematite and gives the rock a reddish to brownish colour. In arid continental climates rocks are in direct contact with the atmosphere, and oxidation is an important process, giving the rock a red or orange colour. Thick sequences of red sedimentary rocks formed in arid climates are called red beds. However, a red colour does not necessarily mean the rock formed in a continental environment or arid climate.
The presence of organic material can colour a rock black or grey. Organic material is in nature formed from dead organisms, mostly plants. Normally, such material eventually decays by oxidation or bacterial activity. Under anoxic circumstances, however, organic material cannot decay and becomes a dark sediment, rich in organic material. This can, for example, occur at the bottom of deep seas and lakes. There is little water current in such environments, so oxygen from surface water is not brought down, and the deposited sediment is normally a fine dark clay. Dark rocks rich in organic material are therefore often shales.
Texture.
The size, form and orientation of clasts or minerals in a rock is called its texture. The texture is a small-scale property of a rock, but determined many of its large-scale properties, such as the density, porosity or permeability.
Clastic rocks have a 'clastic texture', which means they consist of clasts. The 3D orientation of these clasts is called the fabric of the rock. Between the clasts, the rock can be composed of a matrix or a cement (the latter can consist of crystals of one or more precipitated minerals). The size and form of clasts can be used to determine the velocity and direction of current in the sedimentary environment where the rock was formed; fine, calcareous mud only settles in quiet water while gravel and larger clasts are only deposited by rapidly moving water. The grain size of a rock is usually expressed with the Wentworth scale, though alternative scales are sometimes used. The grain size can be expressed as a diameter or a volume, and is always an average value – a rock is composed of clasts with different sizes. The statistical distribution of grain sizes is different for different rock types and is described in a property called the sorting of the rock. When all clasts are more or less of the same size, the rock is called 'well-sorted', and when there is a large spread in grain size, the rock is called 'poorly sorted'.
The form of clasts can reflect the origin of the rock.
Coquina, a rock composed of clasts of broken shells, can only form in energetic water. The form of a clast can be described by using four parameters:
Chemical sedimentary rocks have a non-clastic texture, consisting entirely of crystals. To describe such a texture, only the average size of the crystals and the fabric are necessary.
Mineralogy.
Most sedimentary rocks contain either quartz (especially siliciclastic rocks) or calcite (especially carbonate rocks). In contrast to igneous and metamorphic rocks, a sedimentary rock usually contains very few different major minerals. However, the origin of the minerals in a sedimentary rock is often more complex than in an igneous rock. Minerals in a sedimentary rock can have formed by precipitation during sedimentation or by diagenesis. In the second case, the mineral precipitate can have grown over an older generation of cement. A complex diagenetic history can be studied by optical mineralogy, using a petrographic microscope.
Carbonate rocks dominantly consist of carbonate minerals like calcite, aragonite or dolomite. Both cement and clasts (including fossils and ooids) of a carbonate rock can consist of carbonate minerals. The mineralogy of a clastic rock is determined by the supplied material from the source area, the manner of transport to the place of deposition and the stability of a particular mineral. The stability of the major rock forming minerals (their resistance to weathering) is expressed by Bowen's reaction series. In this series, quartz is the most stable, followed by feldspar, micas, and other less stable minerals that are only present when little weathering has occurred. The amount of weathering depends mainly on the distance to the source area, the local climate and the time it took for the sediment to be transported there. In most sedimentary rocks, mica, feldspar and less stable minerals have reacted to clay minerals like kaolinite, illite or smectite.
Fossils.
Among the three major types of rock, fossils are most commonly found in sedimentary rock. Unlike most igneous and metamorphic rocks, sedimentary rocks form at temperatures and pressures that do not destroy fossil remnants. Often these fossils may only be visible when studied under a microscope (microfossils) or with a loupe.
Dead organisms in nature are usually quickly removed by scavengers, bacteria, rotting and erosion, but sedimentation can contribute to exceptional circumstances where these natural processes are unable to work, causing fossilisation. The chance of fossilisation is higher when the sedimentation rate is high (so that a carcass is quickly buried), in anoxic environments (where little bacterial activity occurs) or when the organism had a particularly hard skeleton. Larger, well-preserved fossils are relatively rare.
Fossils can be both the direct remains or imprints of organisms and their skeletons. Most commonly preserved are the harder parts of organisms such as bones, shells, and the woody tissue of plants. Soft tissue has a much smaller chance of being preserved and fossilized, and soft tissue of animals older than 40 million years is very rare. Imprints of organisms made while still alive are called trace fossils. Examples are burrows, footprints, etc.
Being part of a sedimentary or metamorphic rock, fossils undergo the same diagenetic processes as rock. A shell consisting of calcite can, for example, dissolve while a cement of silica then fills the cavity. In the same way, precipitating minerals can fill cavities formerly occupied by blood vessels, vascular tissue or other soft tissues. This preserves the form of the organism but changes the chemical composition, a process called permineralization. The most common minerals in permineralization cements are carbonates (especially calcite), forms of amorphous silica (chalcedony, flint, chert) and pyrite. In the case of silica cements, the process is called lithification.
At high pressure and temperature, the organic material of a dead organism undergoes chemical reactions in which volatiles like water and carbon dioxide are expulsed. The fossil, in the end, consists of a thin layer of pure carbon or its mineralized form, graphite. This form of fossilisation is called carbonisation. It is particularly important for plant fossils. The same process is responsible for the formation of fossil fuels like lignite or coal.
Primary sedimentary structures.
Structures in sedimentary rocks can be divided into 'primary' structures (formed during deposition) and 'secondary' structures (formed after deposition). Unlike textures, structures are always large-scale features that can easily be studied in the field. Sedimentary structures can indicate something about the sedimentary environment or can serve to tell which side originally faced up where tectonics have tilted or overturned sedimentary layers.
Sedimentary rocks are laid down in layers called beds or strata. A bed is defined as a layer of rock that has a uniform lithology and texture. Beds form by the deposition of layers of sediment on top of each other. The sequence of beds that characterizes sedimentary rocks is called bedding. Single beds can be a couple of centimetres to several meters thick. Finer, less pronounced layers are called laminae, and the structure it forms in a rock is called lamination. Laminae are usually less than a few centimetres thick. Though bedding and lamination are often originally horizontal in nature, this is not always the case. In some environments, beds are deposited at a (usually small) angle. Sometimes multiple sets of layers with different orientations exist in the same rock, a structure called cross-bedding. Cross-bedding forms when small-scale erosion occurs during deposition, cutting off part of the beds. Newer beds then form at an angle to older ones.
The opposite of cross-bedding is parallel lamination, where all sedimentary layering is parallel. With laminations, differences are generally caused by cyclic changes in the sediment supply, caused, for example, by seasonal changes in rainfall, temperature or biochemical activity. Laminae that represent seasonal changes (similar to tree rings) are called varves. Any sedimentary rock composed of millimeter or finer scale layers can be named with the general term "laminite". Some rocks have no lamination at all; their structural character is called massive bedding.
Graded bedding is a structure where beds with a smaller grain size occur on top of beds with larger grains. This structure forms when fast flowing water stops flowing. Larger, heavier clasts in suspension settle first, then smaller clasts. Though graded bedding can form in many different environments, it is characteristic for turbidity currents.
The bedform (the surface of a particular bed) can be indicative for a particular sedimentary environment, too. Examples of bed forms include dunes and ripple marks. Sole markings, such as tool marks and flute casts, are groves dug into a sedimentary layer that are preserved. These are often elongated structures and can be used to establish the direction of the flow during deposition.
Ripple marks also form in flowing water. There are two types: asymmetric wave ripples and symmetric current ripples. Environments where the current is in one direction, such as rivers, produce asymmetric ripples. The longer flank of such ripples is oriented opposite to the direction of the current. Wave ripples occur in environments where currents occur in all directions, such as tidal flats.
Mudcracks are a bed form caused by the dehydration of sediment that occasionally comes above the water surface. Such structures are commonly found at tidal flats or point bars along rivers.
Secondary sedimentary structures.
Secondary sedimentary structures are structures in sedimentary rocks which formed after deposition. Such structures form by chemical, physical and biological processes inside the sediment. They can be indicators for circumstances after deposition. Some can be used as way up criteria.
Organic presence in a sediment can leave more traces than just fossils. Preserved tracks and burrows are examples of trace fossils (also called ichnofossils). Some trace fossils such as paw prints of dinosaurs or early humans can capture human imagination, but such traces are relatively rare. Most trace fossils are burrows of molluscs or arthropods. This burrowing is called bioturbation by sedimentologists. It can be a valuable indicator of the biological and ecological environment after the sediment was deposited. On the other hand, the burrowing activity of organisms can destroy other (primary) structures in the sediment, making a reconstruction more difficult.
Secondary structures can also have been formed by diagenesis or the formation of a soil (pedogenesis) when a sediment is exposed above the water level. An example of a diagenetic structure common in carbonate rocks is a stylolite. Stylolites are irregular planes where material was dissolved into the pore fluids in the rock. The result of precipitation of a certain chemical species can be colouring and staining of the rock, or the formation of concretions. Concretions are roughly concentric bodies with a different composition from the host rock. Their formation can be the result of localized precipitation due to small differences in composition or porosity of the host rock, such as around fossils, inside burrows or around plant roots. In carbonate rocks such as limestone or chalk, chert or flint concretions are common, while terrestrial sandstones can have iron concretions. Calcite concretions in clay are called septarian concretions.
After deposition, physical processes can deform the sediment, forming a third class of secondary structures. Density contrasts between different sedimentary layers, such as between sand and clay, can result in flame structures or load casts, formed by inverted diapirism. The diapirism causes the denser upper layer to sink into the other layer. Sometimes, density contrast can result or grow when one of the lithologies dehydrates. Clay can be easily compressed as a result of dehydration, while sand retains the same volume and becomes relatively less dense. On the other hand, when the pore fluid pressure in a sand layer surpasses a critical point, the sand can flow through overlying clay layers, forming discordant bodies of sedimentary rock called sedimentary dykes (the same process can form mud volcanoes on the surface).
A sedimentary dyke can also be formed in a cold climate where the soil is permanently frozen during a large part of the year. Frost weathering can form cracks in the soil that fill with rubble from above. Such structures can be used as climate indicators as well as way up structures.
Density contrasts can also cause small-scale faulting, even while sedimentation goes on (syn-sedimentary faulting). Such faulting can also occur when large masses of non-lithified sediment are deposited on a slope, such as at the front side of a delta or the continental slope. Instabilities in such sediments can result in slumping. The resulting structures in the rock are syn-sedimentary folds and faults, which can be difficult to distinguish from folds and faults formed by tectonic forces in lithified rocks.
Sedimentary environments.
The setting in which a sedimentary rock forms is called the sedimentary environment. Every environment has a characteristic combination of geologic processes and circumstances. The type of sediment that is deposited is not only dependent on the sediment that is transported to a place, but also on the environment itself.
A marine environment means the rock was formed in a sea or ocean. Often, a distinction is made between deep and shallow marine environments. Deep marine usually refers to environments more than 200 m below the water surface. Shallow marine environments exist adjacent to coastlines and can extend out to the boundaries of the continental shelf. The water in such environments has a generally higher energy than that in deep environments, because of wave activity. This means coarser sediment particles can be transported and the deposited sediment can be coarser than in deep environments. When the available sediment is transported from the continent, an alternation of sand, clay and silt is deposited. When the continent is far away, the amount of such sediment brought in may be small, and biochemical processes dominate the type of rock that forms. Especially in warm climates, shallow marine environments far offshore mainly see deposition of carbonate rocks. The shallow, warm water is an ideal habitat for many small organisms that build carbonate skeletons. When these organisms die their skeletons sink to the bottom, forming a thick layer of calcareous mud that may lithify into limestone. Warm shallow marine environments also are ideal environments for coral reefs, where the sediment consists mainly of the calcareous skeletons of larger organisms.
In deep marine environments, the water current over the sea bottom is small. Only fine particles can be transported to such places. Typically sediments depositing on the ocean floor are fine clay or small skeletons of micro-organisms. At 4 km depth, the solubility of carbonates increases dramatically (the depth zone where this happens is called the lysocline). Calcareous sediment that sinks below the lysocline dissolve, so no limestone can be formed below this depth. Skeletons of micro-organisms formed of silica (such as radiolarians) still deposit though. An example of a rock formed out of silica skeletons is radiolarite. When the bottom of the sea has a small inclination, for example at the continental slopes, the sedimentary cover can become unstable, causing turbidity currents. Turbidity currents are sudden disturbances of the normally quite deep marine environment and can cause the geologically speaking instantaneous deposition of large amounts of sediment, such as sand and silt. The rock sequence formed by a turbidity current is called a turbidite.
The coast is an environment dominated by wave action. At the beach, dominantly coarse sediment like sand or gravel is deposited, often mingled with shell fragments. Tidal flats and shoals are places that sometimes dry out because of the tide. They are often cross-cut by gullies, where the current is strong and the grain size of the deposited sediment is larger. Where along a coast (either the coast of a sea or a lake) rivers enter the body of water, deltas can form. These are large accumulations of sediment transported from the continent to places in front of the mouth of the river. Deltas are dominantly composed of clastic sediment.
A sedimentary rock formed on the land has a continental sedimentary environment. Examples of continental environments are lagoons, lakes, swamps, floodplains and alluvial fans. In the quiet water of swamps, lakes and lagoons, fine sediment is deposited, mingled with organic material from dead plants and animals. In rivers, the energy of the water is much higher and the transported material consists of clastic sediment. Besides transport by water, sediment can in continental environments also be transported by wind or glaciers. Sediment transported by wind is called aeolian and is always very well sorted, while sediment transported by a glacier is called glacial till and is characterized by very poor sorting.
Aeolian deposits can be quite striking. The depositional environment of the Touchet Formation, located in the Northwestern United States, had intervening periods of aridity which resulted in a series of rhythmite layers. Erosional cracks were later infilled with layers of soil material, especially from aeolian processes. The infilled sections formed vertical inclusions in the horizontally deposited layers of the Touchet Formation, and thus provided evidence of the events that intervened in time among the forty-one layers that were deposited.
Sedimentary facies.
Sedimentary environments usually exist alongside each other in certain natural successions. A beach, where sand and gravel is deposited, is usually bounded by a deeper marine environment a little offshore, where finer sediments are deposited at the same time. Behind the beach, there can be dunes (where the dominant deposition is well sorted sand) or a lagoon (where fine clay and organic material is deposited). Every sedimentary environment has its own characteristic deposits. The typical rock formed in a certain environment is called its sedimentary facies. When sedimentary strata accumulate through time, the environment can shift, forming a change in facies in the subsurface at one location. On the other hand, when a rock layer with a certain age is followed laterally, the lithology (the type of rock) and facies eventually change.
Facies can be distinguished in a number of ways: the most common ways are by the lithology (for example: limestone, siltstone or sandstone) or by fossil content. Coral for example only lives in warm and shallow marine environments and fossils of coral are thus typical for shallow marine facies. Facies determined by lithology are called lithofacies; facies determined by fossils are biofacies.
Sedimentary environments can shift their geographical positions through time. Coastlines can shift in the direction of the sea when the sea level drops, when the surface rises due to tectonic forces in the Earth's crust or when a river forms a large delta. In the subsurface, such geographic shifts of sedimentary environments of the past are recorded in shifts in sedimentary facies. This means that sedimentary facies can change either parallel or perpendicular to an imaginary layer of rock with a fixed age, a phenomenon described by Walther's Law.
The situation in which coastlines move in the direction of the continent is called transgression. In the case of transgression, deeper marine facies are deposited over shallower facies, a succession called onlap. Regression is the situation in which a coastline moves in the direction of the sea. With regression, shallower facies are deposited on top of deeper facies, a situation called offlap.
The facies of all rocks of a certain age can be plotted on a map to give an overview of the palaeogeography. A sequence of maps for different ages can give an insight in the development of the regional geography.
Sedimentary basins.
Places where large-scale sedimentation takes place are called sedimentary basins. The amount of sediment that can be deposited in a basin depends on the depth of the basin, the so-called accommodation space. Depth, shape and size of a basin depend on tectonics, movements within the Earth's lithosphere. Where the lithosphere moves upward (tectonic uplift), land eventually rises above sea level, so that and erosion removes material, and the area becomes a source for new sediment. Where the lithosphere moves downward (tectonic subsidence), a basin forms and sedimentation can take place. When the lithosphere keeps subsiding, new accommodation space keeps being created.
A type of basin formed by the moving apart of two pieces of a continent is called a rift basin. Rift basins are elongated, narrow and deep basins. Due to divergent movement, the lithosphere is stretched and thinned, so that the hot asthenosphere rises and heats the overlying rift basin. Apart from continental sediments, rift basins normally also have part of their infill consisting of volcanic deposits. When the basin grows due to continued stretching of the lithosphere, the rift grows and the sea can enter, forming marine deposits.
When a piece of lithosphere that was heated and stretched cools again, its density rises, causing isostatic subsidence. If this subsidence continues long enough the basin is called a sag basin. Examples of sag basins are the regions along passive continental margins, but sag basins can also be found in the interior of continents. In sag basins, the extra weight of the newly deposited sediments is enough to keep the subsidence going in a vicious circle. The total thickness of the sedimentary infill in a sag basins can thus exceed 10 km.
A third type of basin exists along convergent plate boundaries - places where one tectonic plate moves under another into the asthenosphere. The subducting plate bends and forms a fore-arc basin in front of the overriding plate—an elongated, deep asymmetric basin. Fore-arc basins are filled with deep marine deposits and thick sequences of turbidites. Such infill is called flysch. When the convergent movement of the two plates results in continental collision, the basin becomes shallower and develops into a foreland basin. At the same time, tectonic uplift forms a mountain belt in the overriding plate, from which large amounts of material are eroded and transported to the basin. Such erosional material of a growing mountain chain is called molasse and has either a shallow marine or a continental facies.
At the same time, the growing weight of the mountain belt can cause isostatic subsidence in the area of the overriding plate on the other side to the mountain belt. The basin type resulting from this subsidence is called a back-arc basin and is usually filled by shallow marine deposits and molasse.
Influence of astronomical cycles.
In many cases facies changes and other lithological features in sequences of sedimentary rock have a cyclic nature. This cyclic nature was caused by cyclic changes in sediment supply and the sedimentary environment. Most of these cyclic changes are caused by astronomic cycles. Short astronomic cycles can be the difference between the tides or the spring tide every two weeks. On a larger time-scale, cyclic changes in climate and sea level are caused by Milankovitch cycles: cyclic changes in the orientation and/or position of the Earth's rotational axis and orbit around the Sun. There are a number of Milankovitch cycles known, lasting between 10,000 and 200,000 years.
Relatively small changes in the orientation of the Earth's axis or length of the seasons can be a major influence on the Earth's climate. An example are the ice ages of the past 2.6 million years (the Quaternary period), which are assumed to have been caused by astronomic cycles. Climate change can influence the global sea level (and thus the amount of accommodation space in sedimentary basins) and sediment supply from a certain region. Eventually, small changes in astronomic parameters can cause large changes in sedimentary environment and sedimentation.
Sedimentation rates.
The rate at which sediment is deposited differs depending on the location. A channel in a tidal flat can see the deposition of a few metres of sediment in one day, while on the deep ocean floor each year only a few millimetres of sediment accumulate. A distinction can be made between normal sedimentation and sedimentation caused by catastrophic processes. The latter category includes all kinds of sudden exceptional processes like mass movements, rock slides or flooding. Catastrophic processes can see the sudden deposition of a large amount of sediment at once. In some sedimentary environments, most of the total column of sedimentary rock was formed by catastrophic processes, even though the environment is usually a quiet place. Other sedimentary environments are dominated by normal, ongoing sedimentation.
In many cases, sedimentation occurs slowly. In a desert, for example, the wind deposits siliciclastic material (sand or silt) in some spots, or catastrophic flooding of a wadi may cause sudden deposits of large quantities of detrital material, but in most places eolian erosion dominates. The amount of sedimentary rock that forms is not only dependent on the amount of supplied material, but also on how well the material consolidates. Erosion removes most deposited sediment shortly after deposition.
Stratigraphy.
That new rock layers are above older rock layers is stated in the principle of superposition. There are usually some gaps in the sequence called unconformities. These represent periods where no new sediments were laid down, or when earlier sedimentary layers raised above sea level and eroded away.
Sedimentary rocks contain important information about the history of the Earth. They contain fossils, the preserved remains of ancient plants and animals. Coal is considered a type of sedimentary rock. The composition of sediments provides us with clues as to the original rock. Differences between successive layers indicate changes to the environment over time. Sedimentary rocks can contain fossils because, unlike most igneous and metamorphic rocks, they form at temperatures and pressures that do not destroy fossil remains.
References.
Bibliography.
</dl>

</doc>
<doc id="44417" url="http://en.wikipedia.org/wiki?curid=44417" title="Senate">
Senate

A senate is a deliberative assembly, often the upper house or chamber of a bicameral legislature or parliament. The name comes from the ancient Roman Senate, so-called as an assembly of the senior and thus wiser members of the society or ruling class.
Many countries have an assembly named a "senate", composed of "senators" who may be elected, appointed, have inherited the title, or gained membership by other methods, depending on the country. Modern senates typically serve to provide a chamber of "sober second thought" to consider legislation passed by a lower house, whose members are usually elected.
Overview.
The modern word "senate" is derived from the [Latin] word "senātus" (senate), which comes from "senex", “old man”. The members or legislators of a senate are called senators"'. The Latin word "senator" was adopted into English with no change in spelling. Its meaning is derived from a very ancient form of social organization, in which advisory or decision-making powers are reserved for the eldest men. For the same reason, the word "senate" is correctly used when referring to any powerful authority characteristically composed by the eldest members of a community, as a deliberative body of a faculty in an institution of higher learning is often called a senate. This form adaptation was used to show the power of those in body and for the decision-making process to be thorough, which could take a long period of time. The original senate was the Roman Senate, which lasted until 580 (various efforts to revive it were made in Medieval Rome). In the Eastern Roman Empire, the Byzantine Senate continued until the Fourth Crusade, circa 1202–1204.
Modern democratic states with bicameral parliamentary systems are sometimes equipped with a senate, often distinguished from an ordinary parallel lower house, known variously as the “House of Representatives”, “House of Commons”, “Chamber of Deputies”, “National Assembly”, “Legislative Assembly”, or "House of Assembly", by electoral rules. This may include minimum age required for voters and candidates, proportional or majoritarian or plurality system, and an electoral basis or "collegium". Typically, the senate is referred to as the upper house and has a smaller membership than the lower house. In some federal states senates also exist at the subnational level. In the United States all states with the exception of Nebraska (whose legislature is a unicameral body called the “Legislature” but whose members refer to themselves as “senators”) have a state senate. There is also the US Senate at the federal level. 
Similarly in Argentina, in addition to the Senate at federal level, eight of the country's provinces, Buenos Aires, Catamarca, Corrientes, Entre Ríos, Mendoza, Salta, San Luis (since 1987) and Santa Fe, have bicameral legislatures with a Senate. Córdoba and Tucumán changed to unicameral systems in 2001 and 2003 respectively.
In Australia and Canada, only the upper house of the federal parliament is known as the Senate. All states other than Queensland have an upper house known as a Legislative council. Several Canadian provinces also once had a Legislative Council, but these have all been abolished, the last being Quebec's Legislative council in 1968.
In Germany, the last Senate of a State parliament, the Senate of Bavaria, was abolished in 1999.
Senate membership can be determined either through elections or appointments. For example, elections are held every three years for half the membership of the Australian Senate, the term of a senator being six years. In contrast, members of the Canadian Senate are appointed by the Governor General upon the recommendation of the Prime Minister of Canada, holding the office until they resign, are removed, or retire at the mandatory age of 75. In larger countries, the senate often serves a balancing effect by giving a larger share of power to regions or groups which would otherwise be overwhelmed under strictly popular apportionment.
Alternative meanings.
The terms Senate and Senator, however, do not necessarily refer to a second chamber of a legislature:
Defunct senates.
Notes

</doc>
<doc id="44418" url="http://en.wikipedia.org/wiki?curid=44418" title="Deliberative assembly">
Deliberative assembly

A deliberative assembly is an organization comprising members who use parliamentary procedure to make decisions. In a speech to the electorate at Bristol in 1774, Edmund Burke described the British Parliament as a "deliberative assembly," and the expression became the basic term for a body of persons meeting to discuss and determine common action.
"Robert's Rules of Order Newly Revised" describes certain characteristics of a deliberative assembly, such as each member having an equal vote and the fact that the group meets to determine actions to be taken in the name of the entire group. A deliberative assembly may have different classes of members. Common classes include regular members, ex-officio members, and honorary members.
Types.
"Robert's Rules of Order Newly Revised" identifies several types of deliberative assemblies, including:

</doc>
<doc id="44419" url="http://en.wikipedia.org/wiki?curid=44419" title="Robert's Rules of Order">
Robert's Rules of Order

Robert's Rules of Order is the short title of a book, written by Brig. Gen. Henry Martyn Robert, containing rules of order intended to be adopted as a parliamentary authority for use by a deliberative assembly.
Currently in its eleventh edition and published under the name Robert's Rules of Order Newly Revised (and often referred to using the initialism RONR), it is a widely used parliamentary authority in the English-speaking world.
History and origins.
The first edition of the book, whose full title was "Pocket Manual of Rules of Order for Deliberative Assemblies", was published in February 1876 by then U.S. Army Colonel Henry Martyn Robert (1837–1923) with the short title "Robert's Rules of Order" placed on its cover.
The procedures prescribed by the book were loosely modeled after those used in the United States House of Representatives, with such adaptations as Robert saw fit for use in ordinary societies. The author's interest in parliamentary procedure began in 1863 when he was chosen to preside over a church meeting and, although he accepted the task, felt that he did not have the necessary knowledge of proper procedure.
In his later work as an active member of several organizations, Robert discovered that members from different areas of the country had very different views regarding what the proper parliamentary rules were, and these conflicting views hampered the organizations in their work. He eventually became convinced of the need for a new manual on the subject, one which would enable many organizations to adopt the same set of rules.
Explanation.
The book is designed for use in ordinary societies rather than legislative assemblies, and it is the most commonly adopted parliamentary authority among societies in the United States. The book claims to be a "codification of the present-day general parliamentary law (omitting provisions having no application outside legislative bodies)". This statement does not imply any approbation on the part of the courts, and the "general parliamentary law" is related neither to statutory legal requirements nor to common-law precedent derived from court judgments. As it is widely accepted and based for the most part on long-standing traditions of parliamentary procedure, the current edition of the book is considered a reliable reference. Nevertheless, the provisions of any particular manual are not, as a general matter, legally binding upon an assembly that has not formally adopted it as its parliamentary authority; any such manual can at best be cited as "persuasive". In addition, a number of changes have been made to recent editions, such as provisions dealing with videoconferences, teleconferences, and email, which now makes these editions more than merely codifications of the "present-day general parliamentary law" as existed at the time Robert was originally writing. Governmental institutions such as states and the US Senate and House of Representatives have written and approved their own "rules", most notably "Mason's" rules for California. Each institution has to consider local customs, right to speak laws, etc in adopting their codes.
Subsequent editions and versions.
As Pocket Manual of Rules of Order for Deliberative Assemblies (cover short title: "Robert's Rules of Order")
As Robert's Rules of Order Revised
As Robert's Rules of Order Newly Revised
Robert himself published the first four editions before his death in 1923, the last being the thoroughly revised and expanded fourth edition published as "Robert's Rules of Order Revised" in May 1915. By this time Robert had long been retired from the Army with the rank of brigadier general.
Through a family trust, and later through the Robert's Rules Association, several subsequent editions of Robert's work have been published, including another major revision of the work. The seventh edition, published in February 1970 on the 94th anniversary of the publication of the first edition, was the first under the title "Robert's Rules of Order Newly Revised".
The current edition of the series became effective on September 23, 2011, and entitled "Robert's Rules of Order Newly Revised", Eleventh Edition (2011) (hardback ISBN 978-0-306-82021-2; paperback ISBN 978-0-306-82020-5; leatherbound ISBN 978-0-306-82022-9). This edition states that it:
supersedes all previous editions and is intended automatically to become the parliamentary authority in organizations whose bylaws prescribe "Robert's Rules of Order," "Robert's Rules of Order Revised," "Robert's Rules of Order Newly Revised," or "the current edition of" any of these titles, or the like, without specifying a particular edition.—
 In addition, since the Tenth Edition of "Robert's Rules of Order Newly Revised", a shorter reference guide, "Robert's Rules of Order Newly Revised In Brief", has been published to coincide with the main edition. The most recent edition of this shorter guide, the Second Edition, coincides with the current Eleventh Edition of "Robert's Rules of Order Newly Revised".
Other editions and variations.
Since the copyrights for several of the original editions have expired, numerous other books and manuals have been published incorporating "Robert's Rules of Order" as part of their titles, some of them based on those earlier editions.
The existence of multiple editions and other variations all published as "Robert's Rules of Order" can sometimes cause confusion, as the various publications may differ in some details. If an organization that has adopted "Robert's Rules of Order" does not wish "RONR" to be considered its reference authority, it should adopt another version explicitly, as "RONR" is generally considered by parliamentarians to be the definitive source on the subject.
Application to specific organizations.
In those cases in which the bylaws or other governing documents of an organization refer to "Robert's Rules of Order," the book may be subordinate to other rules, including (in descending order of authority as applicable) law, corporate charter, constitution and/or bylaws, special rules of order and then Robert’s Rules of Order Newly Revised. Standing rules and, finally, custom have the least authority.
Model United Nations.
Robert's Rules of Order are used in Model United Nations conferences. While the chair of each committee in an MUN conference may sometimes deviate from the written rules for educational purposes, the format of the specific committees is mostly based on "Robert's Rules of Order". Special committees, like the Security Council, for example, have specific guidelines on procedure. There are many MUN conferences across the world, mainly run by independent college students like the National Model United Nations. The procedures in each conference vary.
References.
Sources.
</dl>

</doc>
<doc id="44421" url="http://en.wikipedia.org/wiki?curid=44421" title="Legislature">
Legislature

A legislature is the law-making body of a political unit, usually a national government, that has power to enact, amend, and repeal public policy. Laws enacted by legislatures are known as legislation. Legislatures observe and steer governing actions and usually have exclusive authority to amend the budget or budgets involved in the process. The most common names for national legislatures are "parliament" and "congress". The members of a legislature are called legislators. 
Terminology.
Because members of legislatures usually sit together in a specific room to deliberate, seats in that room may be assigned exclusively to members of the legislature. In parliamentary language, the term "seat" is sometimes used to mean that someone is a member of a legislature. For example, to say that a legislature has 100 "seats" means that there are 100 members of the legislature; and saying that someone is "contesting a seat" means they are trying to be elected as a member of the legislature. By extension, the term "seat" is often used in less formal contexts to refer to an electoral district itself, as, for example, in the phrases "safe seat" and "marginal seat".
In parliamentary systems of government, the executive is responsible to the legislature which may remove it with a vote of no confidence. According to the separation of powers doctrine, the legislature in a presidential system is considered an independent and coequal branch of government along with both the judiciary and the executive.
Institutional framework.
A legislature creates a complex interaction between individual members, political parties, committees, rules of parliamentary procedure, and informal norms.
Chambers.
A legislature is composed of one or more deliberative assemblies that separately debate and vote upon bills. These assemblies are normally known as "chambers" or "houses". A legislature with only one house is a unicameral legislature, while a bicameral legislature possesses two separate chambers, usually described as an "upper house" and a "lower house". These usually differ in the duties and powers they exercise – the upper house being more revisionary or advisory in parliamentary systems – and the methods used for the selection of members. Tricameral legislatures are rare; the Massachusetts Governor's Council still exists, but the most recent national example existed in the waning years of caucasian-minority rule in South Africa.
In presidential systems, the powers of the two houses are often similar or equal, while in federations, the upper house typically represents the federation's component states. This is a case with the supranational legislature of the European Union. The upper house may either contain the delegates of state governments – as in the European Union and in Germany and, before 1913, in the United States – or be elected according to a formula that grants equal representation to states with smaller populations, as is the case in Australia and the United States since 1913. In the United States the legislative branch is split into the Senate and the House of Representatives.

</doc>
<doc id="44422" url="http://en.wikipedia.org/wiki?curid=44422" title="Adjara">
Adjara

Adjara (Georgian: აჭარა ]), officially the Autonomous Republic of Adjara (აჭარის ავტონომიური რესპუბლიკა ]), is an autonomous republic of Georgia.
Adjara, located in the southwestern corner of Georgia, is on the eastern end of the Black Sea and is bordered by Turkey to the south. Adjara is a home to the Adjar ethnic subgroup of Georgians.
Adjara is also known as Ajara, Adzhara, Ajaria, Adjaria, Adzharia, Achara, Acharia and Ajaristan. Under the Soviet Union, it was known as the Adjarian Autonomous Soviet Socialist Republic (Adjar ASSR).
History.
Adjara has been part of Colchis and Caucasian Iberia since ancient times. Colonized by Greeks in the 5th century BC, the region fell under Rome in the 2nd century BC. It became part of the region of Egrisi before being incorporated into the unified Georgian Kingdom in the 9th century AD. The Ottomans conquered the area in 1614. The people of Adjara converted to Islam in this period. The Ottomans were forced to cede Adjara to the expanding Russian Empire in 1878.
After a temporary occupation by Turkish and British troops in 1918–1920, Adjara became part of the Democratic Republic of Georgia in 1920. After a brief military conflict in March 1921, Ankara's government ceded the territory to Georgia under Article VI of Treaty of Kars on condition that autonomy is provided for the Muslim population. The Soviet Union established the Adjar Autonomous Soviet Socialist Republic in 1921 in accord with this clause. Thus, Adjara was still a component part of Georgia, but with considerable local autonomy.
After the dissolution of the Soviet Union in 1991, Adjara became part of a newly independent but politically divided Republic of Georgia. It avoided being dragged into the chaos and civil war that afflicted the rest of the country between 1991 and 1993 due largely to the authoritarian rule of its leader Aslan Abashidze. Although he successfully maintained order in Adjara and made it one of the country's most prosperous regions, he was accused of involvement in organised crime—notably large-scale smuggling to fund his government and enrich himself. The central government in Tbilisi had very little say in what went on in Adjara during the presidency of Eduard Shevardnadze.
This changed following the Rose Revolution of 2003 when Shevardnadze was deposed in favour of the reformist opposition leader Mikheil Saakashvili, who pledged to crack down on separatism within Georgia. In the spring of 2004, a major crisis in Adjara erupted as the central government sought to reimpose its authority on the region. It threatened to develop into an armed confrontation. However, Saakashvili's ultimatums and mass protests against Abashidze's autocratic rule forced the Adjaran leader to resign in May 2004, following which he went into exile in Russia. After Abashidze's ousting, a new law was introduced to redefine the terms of Adjara's autonomy. Levan Varshalomidze succeeded Abashidze as the chairman of the government.
For many years, Russia maintained the 12th Military Base (the former 145th Motor Rifle Division) in Batumi. This was a source of great tension with Georgia, which had threatened to block access to the facility. Following talks in March 2005, the Russian government proposed to begin the process of withdrawal later the same year; Russia returned the base to Georgia on November 17, 2007, more than a year ahead of schedule.
In July 2007, the seat of the Georgian Constitutional Court was moved from Tbilisi to Batumi.
Law and government.
The status of the Adjaran Autonomous Republic is defined by Georgia's law on Adjara and the region's new constitution, adopted following the ousting of Aslan Abashidze. The local legislative body is the Parliament. The head of the region's government—the Council of Ministers of Adjara—is nominated by the President of Georgia who also has powers to dissolve the assembly and government and to overrule local authorities on issues where the constitution of Georgia is contravened. Archil Khabadze is the current head of the Adjaran government.
Adjara is subdivided into six administrative units:
Geography and climate.
Adjara is located on the south-eastern coast of the Black Sea and extends into the wooded foothills and mountains of the Lesser Caucasus. It has borders with the region of Guria to the north, Samtskhe-Javakheti to the east and Turkey to the south. Most of Adjara's territory either consists of hills or mountains. The highest mountains rise more than 3,000 m above sea level. Around 60% of Adjara is covered by forests. Many parts of the Meskheti Range (the west-facing slopes) are covered by temperate rain forests.
Adjara is traversed by the northeasterly line of equal latitude and longitude.
Climate.
Adjara is well known for its humid climate (especially along the coastal regions) and prolonged rainy weather, although there is plentiful sunshine during the Spring and Summer months. Adjara receives the highest amounts of precipitation both in Georgia and in the Caucasus. It is also one of the wettest temperate regions in the northern hemisphere. No region along Adjara's coast receives less than 2200 mm of precipitation per year. The west-facing (windward) slopes of the Meskheti Range receive upwards of 4500 mm of precipitation per year. The coastal lowlands receive most of the precipitation in the form of rain (due to the area's subtropical climate). September and October are usually the wettest months. Batumi's average monthly rainfall for the month of September is 410 mm. The interior parts of Adjara are considerably drier than the coastal mountains and lowlands. Winter usually brings significant snowfall to the higher regions of Adjara, where snowfall often reaches several meters. Average summer temperatures are between 22–24 degrees Celsius in the lowland areas and 17–21 degrees Celsius in the highlands. The highest areas of Adjara have lower temperatures. Average winter temperatures are between 4–6 degrees Celsius along the coast while the interior areas and mountains average around -3–2 degrees Celsius. Some of the highest mountains of Adjara have average winter temperatures of -8–(-7) degrees Celsius.
Economy.
Adjara has good land for growing tea, citrus fruits and tobacco. Mountainous and forested, the region has a subtropical climate, and there are many health resorts. Tobacco, tea, citrus fruits, and avocados are leading crops; livestock raising is also important. Industries include tea packing, tobacco processing, fruit and fish canning, oil refining, and shipbuilding.
The regional capital, Batumi, is an important gateway for the shipment of goods heading into Georgia, Azerbaijan and landlocked Armenia. The port of Batumi is used for the shipment of oil from Kazakhstan and Turkmenistan. Its oil refinery handles Caspian oil from Azerbaijan which arrives by pipeline to Supsa port and is transported from there to Batumi by rail. The Adjaran capital is a centre for shipbuilding and manufacturing.
Adjara is the main center of Georgia's coastal tourism industry, having displaced the northwestern province of Abkhazia since that region's "de facto" secession from Georgia in 1993.
Population.
According to the 2014 census, the population of Adjara is 336,077. The Adjarians (Ajars) are an ethnographic group of the Georgian people who speak a group of local dialects known collectively as Adjarian. The written language is Georgian.
The Georgian population of Adjara had been generally known as "Muslim Georgians" until the 1926 Soviet census which listed them as "Ajars" and counted 71,000 of them. Later, they were simply classified under a broader category of Georgians as no official Soviet census asked about religion. Today, calling them "Muslim Georgians" would be a misnomer in any case as Adjarans are now about half Christian (see below).
Ethnic minorities include Russians, Armenians, Pontic Greeks, Abkhaz, etc.
Religion.
The collapse of the Soviet Union and the re-establishment of Georgia's independence accelerated re-Christianisation, especially among the young. However, there are still remaining Sunni Muslim communities in Adjara, mainly in the Khulo district. According to the 2006 estimates by the Department of Statistics of Adjara, 63% are Georgian Orthodox Christians, and 30% Muslim. The remaining are Armenian Christians (2.3%), Roman Catholics (0.2%), and others (6%). 
Traditional public festivals.
Selimoba.
Selimoba is held in Bako village, Khulo Municipality on July 3 and commemorates the life of Selim Khimshiashvili. A concert with the participation of local amateur groups of a folk handicraft products exhibition is held during the festival. It is supported by Ministry of Education, Culture and Sports of Adjara.
Shuamtoba.
Shuamtoba ("inter-mountain festival") is a traditional festival, which is held on the summer mountain pastures of two municipalities (Khulo and Shuakhevi), in the first weekend of every August. Horse racing, folk handicraft products exhibition and a concert involving folk ensembles are held on Shuamtoba.
Machakhloba.
Machakhloba is Machakhela gorge festivity, held in the second half of September. It is a traditional holiday celebrated in Machakhela gorge, Khelvachauri Municipality. Festival begins at the Machakhela rifle monument (at the point of convergence of rivers Machakhela and Chorokhi), continues in the village Machakhispiri and ends in the village Zeda Chkhutuneti.
Kolkhoba.
Kolkhoba is an ancient Laz festival. It is held at the end of August or at the beginning of September in Sarpi village, Khelvachauri District. The myth about Argonauts is performed on stage during the festival.

</doc>
<doc id="44424" url="http://en.wikipedia.org/wiki?curid=44424" title="Metamorphic rock">
Metamorphic rock

Metamorphic rocks arise from the transformation of existing rock types, in a process called metamorphism, which means "change in form". The original rock (protolith) is subjected to heat (temperatures greater than 150 to 200 °C) and pressure (1500 bars), causing profound physical and/or chemical change. The protolith may be a sedimentary rock, an igneous rock or another older metamorphic rock.
Metamorphic rocks make up a large part of the Earth's crust and are classified by texture and by chemical and mineral assemblage (metamorphic facies). They may be formed simply by being deep beneath the Earth's surface, subjected to high temperatures and the great pressure of the rock layers above it. They can form from tectonic processes such as continental collisions, which cause horizontal pressure, friction and distortion. They are also formed when rock is heated up by the intrusion of hot molten rock called magma from the Earth's interior. The study of metamorphic rocks (now exposed at the Earth's surface following erosion and uplift) provides information about the temperatures and pressures that occur at great depths within the Earth's crust.
Some examples of metamorphic rocks are gneiss, slate, marble, schist, and quartzite.
Metamorphic minerals.
Metamorphic minerals are those that form only at the high temperatures and pressures associated with the process of metamorphism. These minerals, known as index minerals, include sillimanite, kyanite, staurolite, andalusite, and some garnet.
Other minerals, such as olivines, pyroxenes, amphiboles, micas, feldspars, and quartz, may be found in metamorphic rocks, but are not necessarily the result of the process of metamorphism. These minerals formed during the crystallization of igneous rocks. They are stable at high temperatures and pressures and may remain chemically unchanged during the metamorphic process. However, all minerals are stable only within certain limits, and the presence of some minerals in metamorphic rocks indicates the approximate temperatures and pressures at which they formed.
The change in the particle size of the rock during the process of metamorphism is called recrystallization. For instance, the small calcite crystals in the sedimentary rock limestone and chalk change into larger crystals in the metamorphic rock marble, or in metamorphosed sandstone, recrystallization of the original quartz sand grains results in very compact quartzite, also known as metaquartzite, in which the often larger quartz crystals are interlocked. Both high temperatures and pressures contribute to recrystallization. High temperatures allow the atoms and ions in solid crystals to migrate, thus reorganizing the crystals, while high pressures cause solution of the crystals within the rock at their point of contact.
Foliation.
The layering within metamorphic rocks is called "foliation" (derived from the Latin word "folia", meaning "leaves"), and it occurs when a rock is being shortened along one axis during recrystallization. This causes the platy or elongated crystals of minerals, such as mica and chlorite, to become rotated such that their long axes are perpendicular to the orientation of shortening. This results in a banded, or foliated rock, with the bands showing the colors of the minerals that formed them.
Textures are separated into foliated and non-foliated categories. Foliated rock is a product of differential stress that deforms the rock in one plane, sometimes creating a plane of cleavage. For example, slate is a foliated metamorphic rock, originating from shale. Non-foliated rock does not have planar patterns of strain.
Rocks that were subjected to uniform pressure from all sides, or those that lack minerals with distinctive growth habits, will not be foliated. Where a rock has been subject to differential stress, the type of foliation that develops depends on the metamorphic grade. For instance, starting with a mudstone, the following sequence develops with increasing temperature: slate is a very fine-grained, foliated metamorphic rock, characteristic of very low grade metamorphism, while phyllite is fine-grained and found in areas of low grade metamorphism, schist is medium to coarse-grained and found in areas of medium grade metamorphism, and gneiss coarse to very coarse-grained, found in areas of high-grade metamorphism. Marble is generally not foliated, which allows its use as a material for sculpture and architecture.
Another important mechanism of metamorphism is that of chemical reactions that occur between minerals without them melting. In the process atoms are exchanged between the minerals, and thus new minerals are formed. Many complex high-temperature reactions may take place, and each mineral assemblage produced provides us with a clue as to the temperatures and pressures at the time of metamorphism.
Metasomatism is the drastic change in the bulk chemical composition of a rock that often occurs during the processes of metamorphism. It is due to the introduction of chemicals from other surrounding rocks. Water may transport these chemicals rapidly over great distances. Because of the role played by water, metamorphic rocks generally contain many elements absent from the original rock, and lack some that originally were present. Still, the introduction of new chemicals is not necessary for recrystallization to occur.
Types of metamorphism.
Contact metamorphism.
Contact metamorphism is the name given to the changes that take place when magma is injected into the surrounding solid rock (country rock). The changes that occur are greatest wherever the magma comes into contact with the rock because the temperatures are highest at this boundary and decrease with distance from it. Around the igneous rock that forms from the cooling magma is a metamorphosed zone called a "contact metamorphism aureole". Aureoles may show all degrees of metamorphism from the contact area to unmetamorphosed (unchanged) country rock some distance away. The formation of important ore minerals may occur by the process of metasomatism at or near the contact zone.
When a rock is contact altered by an igneous intrusion it very frequently becomes more indurated, and more coarsely crystalline. Many altered rocks of this type were formerly called hornstones, and the term "hornfels" is often used by geologists to signify those
fine grained, compact, non-foliated products of contact metamorphism. A shale may become a dark argillaceous hornfels, full of tiny plates of brownish biotite; a marl or impure limestone may change to a grey, yellow or greenish lime-silicate-hornfels or siliceous marble, tough and splintery, with abundant augite, garnet, wollastonite and other minerals in which calcite is an important component. A diabase or andesite may become a diabase hornfels or andesite hornfels with development of new hornblende and biotite and a partial recrystallization of the original feldspar. Chert or flint may become a finely crystalline quartz rock; sandstones lose their clastic structure and are converted into a mosaic of small close-fitting grains of quartz in a metamorphic rock called quartzite.
If the rock was originally banded or foliated (as, for example, a laminated sandstone or a foliated calc-schist) this character may not be obliterated, and a banded hornfels is the product; fossils even may have their shapes preserved, though entirely recrystallized, and in many contact-altered lavas the vesicles are still visible, though their contents have usually entered into new combinations to form minerals that were not originally present. The minute structures, however, disappear, often completely, if the thermal alteration is very profound. Thus small grains of quartz in a shale are lost or blend with the surrounding particles of clay, and the fine ground-mass of lavas is entirely reconstructed.
By recrystallization in this manner peculiar rocks of very distinct types are often produced. Thus shales may pass into cordierite rocks, or may show large crystals of andalusite (and chiastolite), staurolite, garnet, kyanite and sillimanite, all derived from the aluminous content of the original shale. A considerable amount of mica (both muscovite and biotite) is often simultaneously formed, and the resulting product has a close resemblance to many kinds of schist. Limestones, if pure, are often turned into coarsely crystalline marbles; but if there was an admixture
of clay or sand in the original rock such minerals as garnet, epidote, idocrase, wollastonite, will be present. Sandstones when greatly heated may change into coarse quartzites composed of large clear grains of quartz. These more intense stages of alteration are not
so commonly seen in igneous rocks, because their minerals, being formed at high temperatures, are not so easily transformed or recrystallized.
In a few cases rocks are fused and in the dark glassy product minute crystals of spinel, sillimanite and cordierite may separate out. Shales are occasionally thus altered by basalt dikes, and feldspathic sandstones may be completely vitrified. Similar changes may be induced in shales by the burning of coal seams or even by an ordinary furnace.
There is also a tendency for metasomatism between the igneous magma and sedimentary country rock, whereby the chemicals in each are exchanged or introduced into the other. Granites may absorb fragments of shale or pieces of basalt. In that case, hybrid rocks called skarn arise, which don't have the characteristics of normal igneous or sedimentary rocks. Sometimes an invading granite magma permeates the rocks around, filling their joints and planes of bedding, etc., with threads of quartz and feldspar. This is very exceptional but instances of it are known and it may take place on a large scale.
Regional metamorphism.
Regional metamorphism, also known as dynamic metamorphism, is the name given to changes in great masses of rock over a wide area. Rocks can be metamorphosed simply by being at great depths below the Earth's surface, subjected to high temperatures and the great pressure caused by the immense weight of the rock layers above. Much of the lower continental crust is metamorphic, except for recent igneous intrusions. Horizontal tectonic movements such as the collision of continents create orogenic belts, and cause high temperatures, pressures and deformation in the rocks along these belts. If the metamorphosed rocks are later uplifted and exposed by erosion, they may occur in long belts or other large areas at the surface. The process of metamorphism may have destroyed the original features that could have revealed the rock's previous history. Recrystallization of the rock will destroy the textures and fossils present in sedimentary rocks. Metasomatism will change the original composition.
Regional metamorphism tends to make the rock more indurated and at the same time to give it a foliated, shistose or gneissic texture, consisting of a planar arrangement of the minerals, so that platy or prismatic minerals like mica and hornblende have their longest axes arranged parallel to one another. For that reason many of these rocks split readily in one direction along mica-bearing zones (schists). In gneisses, minerals also tend to be segregated into bands; thus there are seams of quartz and of mica in a mica schist, very thin, but consisting essentially of one mineral. Along the mineral layers composed of soft or fissile minerals the rocks will split most readily, and the freshly split specimens will appear to be faced or coated with this mineral; for example, a piece of mica schist looked at facewise might be supposed to consist entirely of shining scales of mica. On the edge of the specimens, however, the white folia of granular quartz will be visible. In gneisses these alternating folia are sometimes thicker and less regular than in schists, but most importantly less micaceous; they may be lenticular, dying out rapidly. Gneisses also, as a rule, contain more feldspar than schists do, and are tougher and less fissile. Contortion or crumbling of the foliation is by no means uncommon; splitting faces are undulose or puckered. Schistosity and gneissic banding (the two main types of foliation) are formed by directed pressure at elevated temperature, and to interstitial movement, or internal flow arranging the mineral particles while they are crystallizing in that directed pressure field.
Rocks that were originally sedimentary and rocks that were undoubtedly igneous may be metamorphosed into schists and gneisses. If originally of similar composition they may be very difficult to distinguish from one another if the metamorphism has been great. A quartz-porphyry, for example, and a fine feldspathic sandstone, may both be metamorphosed into a grey or pink mica-schist.
Metamorphic rock textures.
The five basic metamorphic textures with typical rock types are slaty (includes slate and phyllite; the foliation is called "slaty cleavage"), schistose (includes schist; the foliation is called "schistosity"), gneissose (gneiss; the foliation is called "gneissosity"), granoblastic (includes granulite, some marbles and quartzite), and hornfelsic (includes hornfels and skarn).

</doc>
<doc id="44426" url="http://en.wikipedia.org/wiki?curid=44426" title="National Security Act of 1947">
National Security Act of 1947

The National Security Act of 1947 was a major restructuring of the United States government's military and intelligence agencies following World War II. The majority of the provisions of the Act took effect on September 18, 1947, the day after the Senate confirmed James Forrestal as the first Secretary of Defense. His power was initially limited and it was difficult for him to exercise the authority to make his office effective. This was later changed in the amendment to the act in 1949, creating what was to be the Department of Defense.
The Act merged the Department of War (renamed as the Department of the Army) and the Department of the Navy into the National Military Establishment (NME), headed by the Secretary of Defense. It also created the Department of the Air Force, which separated the Army Air Forces into its own service. Initially, each of the three service secretaries maintained quasi-cabinet status, but the act was amended on August 10, 1949, to ensure their subordination to the Secretary of Defense. At the same time, the NME was renamed as the Department of Defense. The purpose was to unify the Army, Navy, and Air Force into a federated structure.
Aside from the military reorganization, the act established the National Security Council, a central place of coordination for national security policy in the executive branch, and the Central Intelligence Agency, the U.S.'s first peacetime intelligence agency. The council's function was to advise the president on domestic, foreign, and military policies, and to ensure cooperation between the various military and intelligence agencies.
The Joint Chiefs of Staff was officially established under Title II, Section 211 of the original National Security Act of 1947 before Sections 209–214 of Title II were repealed by the law enacting Title 10 and Title 32, United States Code (Act of August 10, 1956, 70A Stat. 676) to replace them.
The act and its changes, along with the Truman Doctrine and the Marshall Plan, were major components of the Truman administration's Cold War strategy.
The bill signing took place aboard Truman's VC-54C presidential aircraft "Sacred Cow", the first aircraft used for the role of Air Force One.

</doc>
<doc id="44427" url="http://en.wikipedia.org/wiki?curid=44427" title="Four Pillars of the Green Party">
Four Pillars of the Green Party

The Four Pillars of the Green Party are a foundational statement of Green politics and form the basis of many worldwide Green parties. Different Green Parties that list the "Four Pillars" phrase them somewhat differently. In general, the four pillars define a Green Party as a political movement that interrelates its philosophy from four different social movements: the environmental movement, the labour movement, the civil rights movement, and the peace movement.
The "Four Pillars" are:
History of the Four Pillars.
The practice of describing Green philosophy via "Four Pillars" began with the German Green Party in 1979-1980. At its founding meeting in 1984, the Green Committees of Correspondence in the United States expanded these into the "Ten Key Values".
For the Australian Greens, they are known as "Ecological sustainability", "Social and economic justice", "Peace and nonviolence", and "Grassroots democracy".
For the German Greens (Die Grünen/Bündnis 90), they are known as "ökologisch", "sozial", "basisdemokratisch" and "gewaltfrei" (latter is "non-violent").
For the Swedish Greens (Miljöpartiet de Gröna), in the 1980s they were called the "Four Solidarities": "Solidarity with the ecological systems", "Solidarity with the people throughout the world", "Solidarity with future generations", and "Solidarity with the underprivileged people in our own country". Today they omit the pillar of Solidarity with the underprivileged, leaving them with the "Three Solidarities": "Solidarity with animals, nature and the ecological system", "Solidarity with future generations", and "Solidarity with all the world’s people."
On the global level, the "Six Principles" of the Global Greens Charter - which at the Global Greens conference of 2001 were arrived upon as a compromise of the North American and European traditions - added Respect for diversity and Sustainability. The Green Party of Canada, in 2002 adopted the "Six Principles" of the Global Greens as its official doctrine.

</doc>
<doc id="44428" url="http://en.wikipedia.org/wiki?curid=44428" title="Chondrus crispus">
Chondrus crispus

Chondrus crispus — commonly called Irish moss or carrageen moss (Irish "carraigín", "little rock") — is a species of red algae which grows abundantly along the rocky parts of the Atlantic coast of Europe and North America. In its fresh condition this protist is soft and cartilaginous, varying in color from a greenish-yellow, through red, to a dark purple or purplish-brown. The principal constituent is a mucilaginous body, made of the polysaccharide carrageenan, which constitutes 55% of its weight. The organism also consists of nearly 10% protein and about 15% mineral matter, and is rich in iodine and sulfur. When softened in water it has a sea-like odour and because of the abundant cell wall polysaccharides it will form a jelly when boiled, containing from 20 to 100 times its weight of water.
Description.
"Chondrus crispus" is a relatively small red alga, reaching up to a little over than 20 cm in length. It grows from a discoid holdfast and branches four or five times in a dichotomous, fan-like manner. The morphology is highly variable, especially the broadness of the thalli. The branches are 2–15 mm broad, firm in texture and dark reddish brown in color bleaching to yellowish in sunlight. The gametophytes (see below) often show a blue iridescence and fertile sporophytes show a spotty pattern. "Mastocarpus stellatus" (Stackhouse) Guiry is a similar species which can be readily distinguished by its strongly channelled and often somewhat twisted thallus. The cystocarpic plants of "Mastocarpus" show reproductive papillae quite distinctively different from "Chondrus". When washed and sun-dried for preservation, it has a yellowish, translucent, horn-like aspect and consistency.
Distribution.
"Chondrus crispus" is common all around the shores of Ireland and Great Britain and can also be found along the coast of Europe including Iceland, the Faroe Islands western Baltic Sea to southern Spain. It is found on the Atlantic coasts of Canada and recorded from California in the United States to Japan. However, any distribution outside the Northern Atlantic needs to be verified.
There are also other species of the same genus in the Pacific Ocean, for example, "C. ocellatus" Holmes, "C. nipponicus" Yendo, "C. yendoi" Yamada "et" Mikami, "C. pinnulatus" (Harvey) Okamura and "C. armatus" (Harvey) Yamada "et" Mikami.
Ecology.
"Chondrus crispus" is found growing on rock from the middle intertidal zone into the subtidal zone, all the way to the ocean floor.
Uses.
"Chondrus crispus" is an industrial source of carrageenan, which is commonly used as a thickener and stabilizer in milk products such as ice cream and processed foods, including lunch meat. In Europe, it is indicated as E407 or E407b. It may also be used as a thickener in calico-printing and for fining beer or wine. Irish moss is frequently mixed with "Mastocarpus stellatus" ("Gigartina mammillosa"), "Chondracanthus acicularis " ("G. acicularis") and other seaweeds with which it is associated in growth. Carrageenan and agar-agar are also used in Asia for gelatin-like desserts, such as almond jelly. Presently, the major source of carrageenan is tropical seaweeds of the genera "Kappaphycus" and "Eucheuma".
In parts of Scotland (where it is known as "(An) Cairgean" in Scottish Gaelic) and Ireland, it is boiled in milk and strained, before sugar and other flavourings such as vanilla, cinnamon, brandy or whisky are added. The end-product is a kind of jelly similar to pannacotta, tapioca, or blancmange. Similarly, in Jamaica and Trinidad and Tobago "Gracilaria" spp is boiled with cinnamon and milk to make a thick drink called Irish Moss that is believed to be an aphrodisiac. In Venezuela it has been used for generations as a home remedy for sore throat and chest congestion, boiled in milk and served with honey before bed.
Irish moss is commonly used as a clarifying agent in the process of brewing (beer), particularly in homebrewing. A small amount is boiled with the wort, attracting proteins and other solids, which is then removed from the mixture after cooling.
Life history.
"Chondrus crispus" undergoes an alternation of generation life cycle common in many species of algae (see figure below). There are two distinct stages: the sexual haploid gametophyte stage and the asexual diploid sporophyte stage. In addition, there is a third stage- the carposporophyte, which is formed on the female gametophyte after fertilization. The male and female gametophytes produce gametes which fuse to form a diploid carposporophyte, which forms carpospores, which develops into the sporophyte. The sporophyte then undergoes meiosis to produce haploid tetraspores (which can be male or female) that develop into gametophytes. The three stages (male, female and sporophyte) are difficult to distinguish when they are not fertile; however, the gametophytes often show a blue iridescence.
Scientific interest.
"Chondrus crispus" is, compared to most other seaweeds, well-investigated scientifically. It has been used as a model species to study photosynthesis, carrageenan biosynthesis, and stress responses.The nuclear genome was sequenced in 2013. The genome size is 105 Mbp and is coding for 9,606 genes. It is characterised by relatively few genes with very few introns. The genes are clustered together, with normally short distances between genes and then large distances between groups of genes.
See also.
Harvey, M.J. & McLachlan, J. 1973. "Chondrus crispus". "Proc. Trans. Nova Scotian Inst. Sci." 27 (Suppl.): 1 - 155.

</doc>
<doc id="44430" url="http://en.wikipedia.org/wiki?curid=44430" title="Glacis">
Glacis

A glacis (; ]) in military engineering is an artificial slope as part of a medieval castle or in early modern fortresses. They may be constructed of earth as a temporary structure or of stone in more permanent structure.
More generally, the term "glacis" can denote any slope, natural or artificial, which fulfils the above requirements. The etymology of this French word suggests a slope made dangerous with ice, hence the relationship with "glacier".
Ancient fortifications.
A glacis could also appear in ancient fortresses, such as the one built at Semna, by the ancient Egyptians. Here it was used them to prevent enemy siege engines from weakening defensive walls.
Ancient British hill forts started to incorporate glacis around 350 BC. Those at Maiden Castle in Dorset were 25 m high.
Medieval fortifications.
Glacis were incorporated into medieval fortifications to strengthen the walls against undermining, to hamper escalades and so that missiles dropped from the battlements would ricochet off the glacis into attacking forces.
Towards the end of the medieval period some castles were modified to make them defensible against cannons. Glacis consisting of earthen slopes faced with stones were placed in front of the curtain walls and bastions (towers) to absorb the impact of cannon shots or to deflect them. Towers were lowered to the same height as the curtain walls and converted into gun platforms.
Early modern European fortifications.
Early modern European fortresses were so constructed as to keep any potential assailant under the fire of the defenders until the last possible moment. On natural, level ground, troops attacking any high work have a degree of shelter from its fire when close up to it; the glacis consists of a slope with a low grade inclined towards the top of the wall. This gave defenders a direct line of sight into the assaulting force, allowing them to efficiently sweep the field with fire from the parapet. Additionally, but secondarily, the bank of earth would shield the walls from being hit directly by cannon fire.
Though defenders on a high ground already have a direct line of sight, a glacis allows defenders to sweep the field more efficiently by minimizing changes to the angle of their guns while firing. Furthermore, the glacis prevents attacking cannons from having a clear shot at the walls of a fortress, as one usually cannot even see the walls until the glacis is crossed and the ditch, bounded on either side by the smooth, masoned scarp and counterscarp, is reached.
Armored vehicles.
The term glacis plate describes the sloped front-most section of the hull of a tank or other armored fighting vehicle. In a head-on-head armored engagement, the glacis plate is the largest and most obvious target available to an enemy gunner. Anti-tank mines which employ a tilt-rod mechanism are also designed to detonate directly underneath the glacis plate. As a result, the glacis plate is generally the thickest, most robust armored section of a tank, followed by the turret face and mantlet.
Geomorphology.
An erosional or depositional landform, with little slope. Erosional glacis occur mostly in arid regions, and result from intense weathering and surface transport via laminar, episodic water flow.

</doc>
<doc id="44431" url="http://en.wikipedia.org/wiki?curid=44431" title="Biafra">
Biafra

 |- class="mergedbottomrow"
 | style="width:1.0em; padding:0 0 0 0.6em;"|  -  ||style="padding-left:0;text-align:left;"| 1967 
 |  km² ( sq mi)
 |- class="mergedbottomrow"
 |- class="mergedbottomrow"
 |- class="mergedbottomrow"
 |- class="mergedbottomrow"
 |style="padding-left:0;text-align:left;"| 1967 est.
 |- class="mergedbottomrow"
 |colspan="2"| Density
 |style="white-space:nowrap;"| /km²  ( /sq mi)
Biafra, officially the Republic of Biafra, was a secessionist state in south-eastern Nigeria that existed from 30 May 1967 to 15 January 1970, taking its name from the Bight of Biafra (the Atlantic bay to its south). The inhabitants were mostly the Igbo people who led the secession due to economic, ethnic, cultural and religious tensions among the various peoples of Nigeria. The creation of the new state that was pushing for recognition was among the causes of the Nigerian Civil War, also known as the Nigerian-Biafran War.
The state was formally recognised by Gabon, Haiti, Côte d'Ivoire, Tanzania, and Zambia. Other nations which did not give official recognition but which did provide support and assistance to Biafra included Israel, France, Spain, Portugal, Rhodesia, South Africa and Vatican City. Biafra also received aid from non-state actors, including Joint Church Aid, Holy Ghost Fathers of Ireland, Caritas International, MarkPress and U.S. Catholic Relief Services.
After two-and-a-half years of war, during which a million civilians had died in fighting and from famine, Biafran forces agreed to a ceasefire with the Nigerian Federal Military Government (FMG), and Biafra was reintegrated into Nigeria.
History.
Secession.
In 1960, Nigeria became independent of the United Kingdom. As with many other new African states, the borders of the country did not reflect earlier ethnic boundaries. Thus the northern Sudan and Sahelian Savannah region of the country is made up of Muslim majority, while the southern population was predominantly Christian and Animist. Furthermore, Nigeria's oil, its primary source of income, was located in the south of the country.
Following independence, Nigeria was divided primarily along ethnic lines with Hausa and Fulani in the north, Yoruba in the south-west, Ijaws in the south and Igbo in the south-east. In January 1966, a group of primarily eastern Igbo led a military coup during which 30 political leaders including Nigeria's Prime Minister, Sir Abubakar Tafawa Balewa, and the Northern premier, Sir Ahmadu Bello, were killed. Nnamdi Azikiwe, the President, of Igbo extraction, and the premier of the southeastern part of the country were not killed.
In July 1966 northern officers and army units staged a counter-coup. Muslim officers named a Christian from a small ethnic group (the Anga) in central Nigeria, General Yakubu "Jack" Gowon, as the head of the Federal Military Government (FMG). The two coups deepened Nigeria's ethnic tensions. In September 1966, approximately 30,000 Igbo were killed in the north, and some Northerners were killed in backlashes in eastern cities.
Now, therefore, I, Lieutenant-Colonel Chukwuemeka Odumegwu Ojukwu, Military Governor of Eastern Nigeria, by virtue of the authority, and pursuant to the principles, recited above, do hereby solemnly proclaim that the territory and region known as and called Eastern Nigeria together with her continental shelf and territorial waters shall henceforth be an independent sovereign state of the name and title of "The Republic of Biafra".
Chukwuemeka Odumegwu Ojukwu
In January 1967, the military leaders and senior police officials of each region met in Aburi, Ghana and agreed on a loose confederation of regions. The Northerners were at odds with the Aburi Accord; Obafemi Awolowo, the leader of the Western Region warned that if the Eastern Region seceded, the Western Region would also, which persuaded the northerners.
After the federal and eastern governments failed to reconcile, on 26 May the Eastern region voted to secede from Nigeria. On 30 May, Chukwuemeka Odumegwu Ojukwu, the Eastern Region's military governor, announced the Republic of Biafra, citing the Easterners killed in the post-coup violence. The large amount of oil in the region created conflict, as oil was a major component of the Nigerian economy. The Eastern region was very ill equipped for war, out-manned, and out-gunned by the military of the remainder of Nigeria. Their advantages included fighting in their homeland and support of most Easterners. The British and Soviet support (especially militarily) of the Nigerian government played a major role in the outcome of the war.
War.
The FMG launched "police measures" to annex the Eastern Region on 6 July 1967. The FMG's initial efforts were unsuccessful;
the Biafrans successfully launched their own offensive, occupying areas in the Mid-Western Region in August 1967. By October 1967,
the FMG had regained the land after intense fighting. In September 1968, the federal army planned what Gowon described as the "final offensive". Initially the final offensive was neutralised by Biafran troops. In the latter stages, a Southern FMG offensive managed to break through the fierce resistance.
On 30 June 1969, the Nigerian government banned all Red Cross aid to Biafra; two weeks later it allowed medical supplies through the front line, but restricted food supplies. Later in October 1969, Ojukwu appealed to the United Nations to mediate a cease-fire. The federal government called for Biafra's surrender. In December, the FMG managed to cut Biafra in half, primarily by the efforts of 3 Marine Commando Division of the Nigerian Army, led by then Colonel Benjamin Adekunle, popularly called "The Black Scorpion", and later by Olusegun Obasanjo. Ojukwu fled to Côte d'Ivoire, leaving his chief of staff, Philip Effiong, to act as the "officer administering the government". Effiong called for a cease-fire 12 January and submitted to the FMG. More than one million people had died in battle or from starvation. Biafra was reabsorbed into Nigeria on 15 January.
Geography.
Biafra comprised over 29848 sqmi of land, with terrestrial borders shared with Nigeria to the north and with Cameroon to the east. Its coast was on the Gulf of Guinea in the south.
The former country's southeast borders the Benue Hills and mountains that lead to Cameroon. Two rivers flow from Biafra into the Gulf of Guinea: the Cross River and the Niger River.
Climate.
Biafra has a tropical climate with two distinct seasons, dry and rainy. From April to October the rainy season takes place, with heavy rain and high humidity. The heaviest rain occurs between June and July with up to 360 mm of rain. The temperature of the region on a clear day is 30 degrees Celsius (86 degrees Fahrenheit) high and 22 degrees Celsius (71.6 degrees Fahrenheit) low. The dry season starts in November and ends in April. The lowest rain level 16 mm in February. The temperature at night reaches 20 °C (68 °F) and in the day has a peak temperature of 36 °C (96.8 °F).
Language.
The English language is spoken throughout Nigeria and carried on into the new state of Biafra. 
The predominant language of Biafra was Igbo. Along with Igbo there were a variety of other languages, including Efik, Annang and Ibibio.
Economy.
An early institution created by the Biafran government was the Bank of Biafra, accomplished under "Decree No. 3 of 1967". The bank carried out all central banking functions including the administration of foreign exchange and the management of the public debt of the Republic. The bank was administered by a governor and four directors; the first governor, who signed on bank notes, was Sylvester Ugoh. A second decree, "Decree No. 4 of 1967", modified the Banking Act of the Federal Republic of Nigeria for the Republic of Biafra.
The bank was first located in Enugu, but due to the ongoing war, the bank was relocated several times.
Biafra attempted to finance the war through foreign exchange. After Nigeria announced their currency would no longer be legal tender (to make way for a new currency), this effort increased. After the announcement, tons of Nigerian bank notes were transported in an effort to acquire foreign exchange. The currency of Biafra had been the Nigerian pound, until the Bank of Biafra started printing out its own notes, the Biafran pound. The new currency went public on 28 January 1968, and the Nigerian pound was not accepted as an exchange unit. The first issue of the bank notes included only 5 shillings notes and 1 pound notes. The Bank of Nigeria exchanged only 30 pounds for an individual and 300 pounds for enterprises in the second half of 1968.
In 1969 new notes were introduced: £10, £5, £1, 10/- and 5/-.
It is estimated that a total of £115–140 million Biafran pounds were in circulation by the end of the conflict, with a population of about 14 million, approximately £10 per person.
Military.
At the beginning of the war Biafra had 3,000 soldiers, but at the end of the war the soldiers totaled 30,000. There was no official support for the Biafran army by another nation throughout the war, although arms were clandestinely acquired. Because of the lack of official support, the Biafrans manufactured many of their weapons locally. A number of Europeans served in the Biafran cause; German born Rolf Steiner was a Lt. Colonel assigned to the 4th Commando Brigade and Welshman Taffy Williams served as a Major until the very end of the conflict.
The Biafrans managed to set up a small yet effective air force. The BAF commanders were Chude Sokey and later Godwin Ezeilo, who had trained with the Royal Canadian Air Force. Early inventory included two B-25 Mitchells, one B-26 Invader (piloted by Polish WWII ace Jan Zumbach, known also as John Brown), a converted DC-3 and one Dove. In 1968 the Swedish pilot Carl Gustaf von Rosen suggested the MiniCOIN project to General Ojukwu. By the spring of 1969, Biafra had assembled five MFI-9Bs in Gabon, calling them "Biafra Babies". They were coloured green, were able to carry six 68 mm anti-armour rockets under each wing and had simple sights. The six aeroplanes were flown by three Swedish pilots and three Biafran pilots. In September 1969, Biafra acquired four ex-Armee de l'Air North American T-6Gs, which were flown successfully to Biafra the following month, with another aircraft lost on the ferry flight. These aircraft flew missions until January 1970 and were flown by Portuguese ex-military pilots.
Legacy.
The international humanitarian organisation Médecins Sans Frontières ("Doctors Without Borders") came out of the suffering in Biafra. During the crisis, French medical volunteers, in addition to Biafran health workers and hospitals, were subjected to attacks by the Nigerian army and witnessed civilians being murdered and starved by the blockading forces. French doctor Bernard Kouchner also witnessed these events, particularly the huge number of starving children, and, when he returned to France, he publicly criticised the Nigerian government and the Red Cross for their seemingly complicit behaviour. With the help of other French doctors, Kouchner put Biafra in the media spotlight and called for an international response to the situation. These doctors, led by Kouchner, concluded that a new aid organisation was needed that would ignore political/religious boundaries and prioritise the welfare of victims.
In their study, "Smallpox and its Eradication", Fenner and colleagues describe how vaccine supply shortages during the Biafra smallpox campaign led to the development of the focal vaccination technique, later adopted worldwide by the World Health Organization, which led to the early and cost effective interruption of smallpox transmission in west Africa and elsewhere.
On 29 May 2000, the Lagos "Guardian" newspaper reported that the now ex-president Olusegun Obasanjo commuted to retirement the dismissal of all military persons who fought for the breakaway state of Biafra during Nigeria's 1967–1970 civil war. In a national broadcast, he said the decision was based on the belief that "justice must at all times be tempered with mercy".
Violence between Christians and Muslims (usually Hausa or Fulani Muslims and various Christian ethnic groups) has been incessant since the end of the civil war in 1970.
In July 2006 the Center for World Indigenous Studies reported that government sanctioned killings were taking place in the southeastern city of Onitsha, because of a shoot-to-kill policy directed toward Biafran loyalists, particularly members of the Movement for the Actualization of the Sovereign State of Biafra (MASSOB).
In 2010, researchers from Karolinska Institutet in Sweden and University of Nigeria, Nsukka, showed that Igbos born in Biafra during the years of the famine were of higher risk of suffering from overweight, hypertension and impaired glucose metabolism compared to controls born a short period after the famine had ended. The findings are in line with the developmental origin of health and disease hypothesis suggesting that malnutrition in early life is a predisposing factor for cardiovascular diseases and diabetes later in life.
Movement to re-secede.
The Movement for the Actualization of the Sovereign State of Biafra (MASSOB) advocates a separate country for the Igbo people of south-eastern Nigeria. They accuse the state of marginalising the Igbo people. MASSOB says it is a peaceful group and advertises a 25-stage plan to achieve its goal peacefully. There are two arms to the government, the Biafra Government in Exile and Biafra Shadow Government. The Nigerian government accuses MASSOB of violence; MASSOB's leader, Ralph Uwazuruike, was arrested in 2005 and is being detained on treason charges; MASSOB is calling for his release. MASSOB is also championing the release of oil militant Mujahid Dokubo-Asari, who is facing similar charges. In 2009, The MASSOB launched "the Biafran International Passport" in response to persistent demand by Biafrans in diaspora.
Meaning of "Biafra" and location.
Little is known about the literal meaning of the word Biafra. The word Biafra most likely derives from the subgroup Biafar or Biafada of the Tenda ethnic group who reside primarily in Guinea-Bissau. Manuel Álvares (1526–1583), a Portuguese Jesuit educator, in his work "Ethiopia Minor and a geographical account of the Province of Sierra Leone", writes about the "Biafar heathen" in chapter 13 of the same book. The word Biafar thus appears to have been a common word in the Portuguese language back in the 16th century.
Historical maps.
Early modern maps of Africa from the 15th–19th centuries, drawn by European cartographers from accounts written by explorers and travellers, reveal some information about Biafra:
Maps indicating the word "Biafara" (sometimes also "Biafares" or "Biafar") with corresponding year:
Maps from the 19th century indicating Biafra as the region around today's Cameroon:

</doc>
<doc id="44433" url="http://en.wikipedia.org/wiki?curid=44433" title="Danish West Indies">
Danish West Indies

 |- class="mergedrow"
 |style="width:1.0em; padding:0 0 0 0.6em;"| - ||style="padding-left:0;text-align:left;"|1756–1766|| 
 |- class="mergedbottomrow"
 | style="width:1.0em; padding:0 0 0 0.6em;"|  -  ||style="padding-left:0;text-align:left;"| 
 |  km² ( sq mi)
 |- class="mergedbottomrow"
 |- class="mergedbottomrow"
 |- class="mergedbottomrow"
 |- class="mergedbottomrow"
 |style="padding-left:0;text-align:left;"| 1911 est.
 |- class="mergedbottomrow"
Danish West Indies, Saint Thomas, 1 dollar (1889)
The Danish West Indies (Danish: "Dansk Vestindien" or "De dansk-vestindiske øer") or Danish Antilles was a Danish colony in the Caribbean, first under the united kingdoms of Denmark-Norway and later, after the 1814 Treaty of Kiel, Denmark alone. The islands were sold to the United States in 1917 under the terms of the Treaty of the Danish West Indies and were organized as the United States Virgin Islands in 1917. The Danish geographical name for the constituent islands is "Jomfruøerne" ( "The Virgin Islands").
The Danish West Indies covered a total area of 185 sqmi and in the 1850s consisted of three main islands: Sankt Thomas with 43 sqmi; Sankt Jan with 42 sqmi; and Sankt Croix with 100 sqmi.
History.
Merchants in Copenhagen asked King Christian IV for permission to establish a West Indian trading company in 1622 but, by the time an eight-year monopoly on trade with the West Indies, Virginia, Brazil, and Guinea was granted on 25 January 1625, the failure of the Danish East India and Iceland Companies and the beginning of Danish involvement in the Thirty Years' War dried up any interested capital. Prince Frederick organized a trading mission to Barbados in 1647 under Gabriel Gomez and the de Casseres brothers, but it and a 1651 expedition of two ships were unsuccessful. It was not until Erik Smit's private 1652 expedition aboard the "Fortuna" proved successful that interest in the West Indies' trade grew into consideration of a new Danish colony.
Smit's 1653 expedition and a separate expedition of five ships were quite successful, but Smit's third found his two vessels captured for a loss of 32,000 rigsdaler. In August two years later, an argosy was destroyed by a hurricane. Smit returned from his fourth expedition in 1663 and formally proposed the settlement of St. Thomas to the king in April 1665. After only three weeks' deliberation, the scheme was approved and Smit named governor. Settlers departed aboard the "Eendragt" on 1 July, but the expedition was ill-starred: the ship hit two large storms and suffered from fire before reaching its destination, where it was raided by English privateers prosecuting the Second Anglo-Dutch War. Smit died of illness, and a second band of privateers stole the ship used to trade with neighboring islands. Following a hurricane and a renewed outbreak of disease, the colony collapsed, with the English departing for the nearby French colony on Sainte-Croix, the Danes fleeing to Saint Christopher and home, and the Dutch assisting their countrymen on Ter Tholen in stealing everything of value, particularly the remaining Danish guns and ammunition.
The Danish formed a Board of Trade in 1668 and secured a commercial treaty with Britain, providing for the unmolested settlement of uninhabited islands, in July of 1670. The Danish West India Company was organized in December and formally chartered by King Christian V the next year on March 11, 1671. Jørgen Iversen Dyppel, a successful trader on Saint Christopher, was made governor and the king provided convicts from his jails and two vessels for the establishment of the colony, the yacht "Den forgyldte Krone" and the frigate "Færøe". "Den forgyldte Krone" was ordered to run ahead and wait but ended up returning to Denmark after the "Færøe" under Capt. Bang was delayed for repairs in Bergen. The "Færøe" completed her mission alone, establishing a settlement on St. Thomas on May 25, 1672. From an original contingent of 190 – 12 officials, 116 company "employees" (indentured servants), and 62 felons and former prostitutes – only 104 remained, 9 having escaped and 77 having died in transit. Another 75 died within the first year, leaving only 29 to carry on the colony.
In 1675, Iversen claimed St. John and placed two men there; in 1684, Governor Esmit granted it to two English merchants from Barbados but their men were chased off the island by two British sloops sent by Governor Stapleton of the British Leeward Islands. Further instructions in 1688 to establish a settlement on St. John seem not to have been acted on until Governor Bredal made an official establishment on March 25, 1718.
The islands quickly became a base for pirates attacking ships in the vicinity and also for the Brandenburg African Company. Governor Lorentz raised enormous taxes upon them and seized warehouses and cargoes of tobacco, sugar, and slaves in 1689 only to have his actions repudiated by the authorities in Copenhagen; his hasty action to seize Crab Island prohibited the Brandenburgers from establishing their own Caribbean colony, however. Possession of the island was subsequently disputed with the Scottish in 1698 and fully lost to the Spanish in 1811.
Danish West Indies, Saint Croix, 2 dalere (1898)
St. Croix was purchased from the French West Indies Company in 1733. In 1754, the islands were sold to the Danish king, Frederick V of Denmark, becoming royal Danish colonies.
At times during the Napoleonic Wars, the islands were occupied by the British; first from March 1801 to March 27, 1802, and then again from December 1807 to November 20, 1815, when they were returned to Denmark.
In the 1850s the Danish West Indies had a total population of about 41,000 people. The government of the islands were under a governor-general, whose jurisdiction extended to the other Danish colonies of the group. However, because the islands formerly belonged to Great Britain the inhabitants were English in customs and in language. The islands of that period consisted of:
On January 17, 1917, the islands were sold to the United States for $25 million ($ in current prices), when the United States and Denmark exchanged their respective treaty ratifications. Danish administration ended March 31, 1917, when the United States took formal possession of the territory and renamed it the United States Virgin Islands.
The United States had been interested in the islands for years because of their strategic position near the approach to the Panama Canal and because of the fear that Germany might seize them to use as U-boat bases during World War I.
Postage stamps.
Denmark issued stamps for the Danish West Indies from 1856 on.
Religion.
The Danish West Indies were inhabited by many different cultures, and each had its own traditions and religions. The king and the church worked closely together to maintain law and order; the church was responsible for people's moral upbringing, and the King led the civil order. There was no state-sponsored religion in Denmark until 1849, but in the Danish West Indies there had always been a great deal of religious freedom. Danish authorities tended to be lenient towards religious beliefs, but required that all citizens had to observe Danish holidays. Freedom of religion was partially granted to help settle the islands, as there was a shortage of willing settlers from Europe. This worked to an extent, seeing that a large proportion of settlers were in fact Dutch and British natives fleeing religious persecution.
In spite of a general tolerance for religion, many African religions were not recognized because they typically revolved around belief in animism and magic, beliefs which were consistently met with scorn, and were regarded as immoral and subservient. A widespread viewpoint was that if you could convert slaves to Christianity, they could have a better life, and many slaves were converted.
Slavery and property rights.
Laws and regulations in the Danish West Indies were based on Denmark's laws, but the local government was allowed to adapt them to match local conditions. For example, things like animals, land, and buildings were regulated according to Danish law, but Danish law did not regulate slavery. Slaves were treated as common property, and therefore did not necessitate specific laws.
In 1733, differentiation between slaves and other property was implied by a regulation that stated that slaves had their own will and thus could behave inappropriately or be disobedient.
The regulation also stated that the authorities were to punish slaves for participating in illegal activity, but many owners punished slaves on their own. There was a general consensus that if the slaves were punished too hard or were malnourished, the slaves would start to rebel. In 1755 Frederick V of Denmark issued more new Regulations, in which slaves were guaranteed the right not to be separated from their children and the right to medical support during periods of illness or old age. However, the colonial government had the ability to amend laws and regulations according to local conditions, and thus the regulations were never enacted in the colony, on grounds that it was more disadvantageous than advantageous.
By 1778, it was estimated that the Danish were bringing about 3,000 Africans to the Danish West Indies yearly for enslavement.
When Denmark abolished slavery in 1848, many plantation owners wanted full reimbursement, on the grounds that their assets were damaged by the loss of the slaves, and by the fact that they would have to pay for labor in the future. The Danish government paid fifty dollars for every slave the plantation owners had owned and recognized that the slaves' release had caused a financial loss for the owners. However, the lives of the former slaves changed very little. Most were hired at the plantations where they had previously worked and were offered one-year contracts, a small hut, a little land and some money. As employees, former slaves were not plantation owners' responsibility and did not receive food from their employers.

</doc>
<doc id="44434" url="http://en.wikipedia.org/wiki?curid=44434" title="Tractor beam">
Tractor beam

A tractor beam is a device with the ability to attract one object to another from a distance. The term was coined by E. E. Smith (an update of his earlier "attractor beam") in his novel Spacehounds of IPC (1931). Since the 1990s, technology and research has laboured to make it a reality, and have had some success on a microscopic level. Another method to realize tractor beams is based on the use of biaxial birefringent media. Less commonly, a similar beam that repels is called a pressor beam or repulsor beam. Gravity impulse and gravity propulsion beams are traditionally areas of research from fringe physics that coincide with the concepts of tractor and repulsor beams.
Physics.
One well-accepted approach to attracting an asteroid towards a spacecraft is the gravity tractor. Essentially, a spacecraft approaches a small asteroid, and then the spacecraft's own gravity pulls the asteroid. The effect is tiny, but over a very long time, provided the asteroid isn't too big, the spacecraft can change the direction of the asteroid by a very small degree. This has been proposed as a way to prevent an asteroid from colliding with the Earth where a several decades long warning is raised as to a future collision.
A force field confined to a collimated beam with clean borders, is one of the principal characteristics of tractor and repulsor beams. Several theories that have predicted repulsive effects, do not fall within the category of tractor and repulsor beams because of the absence of field collimation. For example, Robert L. Forward, Hughes Research Laboratories, Malibu, California, showed general relativity theory allowed the generation of a very brief impulse of a gravity-like repulsive force along the axis of a helical torus containing accelerated condensed matter. The mainstream scientific community has accepted Forward’s work. A variant of Burkhard Heim’s theory by Walter Dröscher, Institut für Grenzgebiete der Wissenschaft (IGW), Innsbruck, Austria, and Jocham Häuser, University of Applied Sciences and CLE GmbH, Salzgitter, Germany, predicted a repulsive force field of gravitophotons could be produced by a ring rotating above a very strong magnetic field. Heim’s theory, and its variants, have been treated by the mainstream scientific community as fringe physics. But, the works by Forward, Dröscher, and Häuser could not be considered as a form of repulsor or tractor beam because the predicted impulses and field effects were not confined to a well defined, collimated region.
The following are a summary of experiments and theories that resemble repulsor and tractor beam concepts:
1960s.
In July 1960, "Missiles and Rockets" reported Martin N. Kaplan, Senior Research Engineer, Electronics Division, Ryan Aeronautical Company, San Diego, had conducted experiments that justified planning for a more comprehensive research program. The article indicated such a program, if successful, would yield either “restricted” or “general” results. It described the “restricted” results as an ability to direct an anti-gravitational force towards or away from a second body.
In 1964, Copenhagen physicists, L. Halpern, Universitetets Institut fűr Teoretisk Fysik, and B. Laurent, Nordisk Institut fűr Teoretisk Atomfysik, indicated general relativity theory and quantum theory allowed the generation and amplification of gravitons in a manner like the LASER. They showed, in principle, gravitational radiation in the form of a beam of gravitons could be generated and amplified by using induced, resonant emissions.
1980s.
According to Paul LaViolette, Starburst Foundation, Schenectady, New York, Eric Dollard, and Guy Obolensky had independently conducted gravity-like beam experiments during the 1980s that had been inspired by observations reported by Nikola Tesla. Those experiments were not reported in peer reviewed journals.
1990s.
In 1992, Russian Professor of Chemistry, Yevgeny Podkletnov, and Nieminen, Tampere University of Technology, Tampere, Finland, discovered weight fluctuations in objects above an electromagnetically levitated, massive, composite superconducting disk. Three years later, Podkletnov reported the results of additional experiments with a toroidal disk superconductor. They reported the weight of the samples would fluctuate between -2.5% and +5.4% as the angular speed of the superconductor increased. Certain combinations of disk angular speeds and electromagnetic frequencies caused the fluctuations to stabilize at a 0.3% reduction. The experiments with the toroidal disk yielded reductions that reached a maximum of 1.9-2.1%. Reports about both sets of experiments stated the weight loss region was cylindrical, extending vertically for at least three meters above the disk. Qualitative observations of an expulsive force at the border of the shielded zone were reported in the Fall of 1995.
Italian physicist Giovanni Modanese, while a Von Humboldt Fellow at the Max Planck Institute for Physics, made the first attempt to provide a theoretical explanation of Podkletnov’s observations. He argued the shielding effect and slight expulsive force at the border of the shielded zone could be explained in terms of induced changes in the local cosmological constant. Modanese described several effects in terms of responses to modifications to the local cosmological constant within the superconductor. Ning Wu, Institute of High Energy Physics, Beijing, China, used the theory of quantum gauge theory of gravity he had developed in 2001 to explain Podkletnov’s observations. Wu’s theory approximated the relative gravity loss as 0.03% (an order of magnitude smaller than the reported range of 0.3 – 0.5%).
Several groups around the world tried to replicate Podkletnov’s gravity shielding observations. According to R. Clive Woods, Department of Electrical and Computer Engineering, Iowa State University, those groups were not able to overcome the extremely challenging technical problems of replicating all aspects of the 1992 experimental conditions. Woods summarised those shortcomings in the following list:
C. S. Unnikrishan, Tata Institute of Fundamental Research, Bombay, India, showed that if the effect had been caused by gravitational shielding, the shape of the shielded region would be similar to a shadow from the gravitational shield. For example, the shape of the shielded region above a disk would be conical. The height of the cone's apex above the disk would vary directly with the height of the shielding disk above the earth. Podkeltnov and Nieminen described the shape of the weight loss region as a cylinder that extended through the ceiling above the cryostat. That factor and others precipitated a recommendation to reclassify the effect as gravitational modification instead of gravitational shielding. Such a reclassification means the region causing the weight modifications can be directed and is not limited to the space above the superconductor.
2000s.
In 2001, Podkeltnov and Modanese reported the generation of a beam of gravity-like impulses. Their paper indicated a high voltage discharge device had been constructed that emitted a horizontal, collimated beam, with sharp borders, of short impulses of a repulsive force field that could penetrate different bodies without any noticeable loss of energy. Subsequently, the apparatus was dubbed an impulse gravity generator. Measurements of the impulses taken three to six meters beyond the emitter and in a building 150 meters away yielded identical results. Analyses of the measurements indicated the impulses briefly caused accelerations one thousand times the rate of gravity.
The gravity impulse generator received further theoretical support from David Maker and Glen A. Robertson, Gravi Atomic Research, Madison, Alabama and Wu. Chris Taylor, Jupiter Research Corporation, Houston, Texas, along with a private individual Robert Hendry and the original theorist Modanese conducted an analysis of the suitability of impulse gravity generators for Earth-to-orbit, interplanetary, and interstellar applications, this was repeated again in 2008 and a United States and European patent was received. In general, mainstream scientific community have treated the impulse gravity generator reports as extremely speculative and controversial. At least one other group based in central Europe has attempted to replicate Podkletnov's gravity impulse generator experiment, but they have elected not to publish their results.
2010s.
A team of scientists at the Australian National University led by Professor Andrei Rode created a device similar to a tractor beam to move small particles 1.5 meters through the air. Rather than create a new gravitational field, however, the device utilizes a doughnut-shaped Laguerre-Gaussian laser beam, which has a high intensity ring of light that surrounds a dark core along the beam axis. This method confines particles to the centre of the beam using photophoresis, whereby illuminated sections of the particle have a higher temperature and thus impart more momentum to air molecules incident on the surface. Owing to this method, it is impossible for such a device to work in space due to lack of air, but Professor Rode states that there are practical applications for the device on Earth such as, for example, the transportation of microscopic hazardous materials and other microscopic objects.
Prof. John Sinko and Dr. Clifford Schlecht researched a form of reversed-thrust laser propulsion as a macroscopic laser tractor beam. Intended applications include remotely manipulating space objects at distances up to about 100 km, removal of space debris, and retrieval of adrift astronauts or tools on-orbit.
In March 2011, Chinese scientists posited that a specific type of Bessel beam (a special kind of laser that that does not diffract at the centre) is capable of creating a pull-like effect on a given microscopic particle, forcing it towards the beam source. The underlining physics is the maximization of forward scattering via interference of the radiation multipoles. They show explicitly that the necessary condition to realize a negative (pulling) optical force is the simultaneous excitation of multipoles in the particle and if the projection of the total photon momentum along the propagation direction is small, attractive optical force is possible. The Chinese scientists suggest this possibility may be implemented for optical micromanipulation.
Functioning tractor beams based on solenoidal modes of light were demonstrated in 2010 by physicists at New York University.
The spiraling intensity distribution in these non-diffracting beams tends to trap illuminated objects and thus helps to 
overcome the radiation pressure that ordinarily would drive them down the optical axis. 
Orbital angular momentum transferred from the solenoid beam's helical wavefronts then 
drives the trapped objects upstream along the spiral. Both Bessel-beam and solenoidal tractor beams are being considered for 
applications in space exploration by NASA.
In 2013, scientists at the Institute of Scientific Instruments (ISI) and the university of St Andrews succeeded in creating a tractor beam that pulls objects on a microscopic level. The new study states that while this technique is new, it may have potential for bio-medical research. 
Professor Zemanek said: “The whole team have spent a number of years investigating various configurations of particles delivery by light. 
Dr Brzobohaty said: “These methods are opening new opportunities for fundamental phonics as well as applications for life-sciences.”
Dr Cizmar said: “Because of the similarities between optical and acoustic particle manipulation we anticipate that this concept will provide inspiration for exciting future studies in areas outside the field of photonics.”
Physicist from the Australian National University successfully built a reversible tractor beam, capable of transporting particles "one fifth of a millimetre in diameter a distance of up to 20 centimetres, around 100 times further than previous experiments." According to Professor Wieslaw Krolikowski, of the Research School of Physics and Engineering, “demonstration of a large scale laser beam like this is a kind of holy grail for laser physicists.” The work was published in Nature in 2014.
Fiction.
Science fiction movies and telecasts normally depict tractor and repulsor beams as audible, narrow rays of visible light that cover a small area of a target. Tractor beams are most commonly used on spaceships and space stations. They are generally used in two ways:
In the latter case, there are usually countermeasures that can be employed against tractor beams. These may include pressor beams (a stronger pressor beam will counteract a weaker tractor beam) or "plane shears" aka "shearing planes" (a device to "cut" the tractor beam and render it ineffective). In some fictional realities, shields can block tractor beams, or the generators can be disabled by sending a large amount of energy back up the beam to its source.
Tractor beams and pressor beams can be used together as a weapon: by attracting one side of an enemy spaceship while repelling the other, one can create severely damaging shear effects in its hull. Another mode of destructive use of such beams is rapid alternating between pressing and pulling force in order to cause structural damage to the ship as well as inflicting lethal forces on its crew.
Two objects being brought together by a tractor beam are usually attracted toward their common centre of gravity. This means that if a small spaceship applies a tractor beam to a large object such as a planet, the ship will be drawn towards the planet, rather than vice versa.
In "Star Trek", tractor beams are imagined to work by placing a target in the focus of a subspace/graviton interference pattern created by two beams from an emitter. When the beams are manipulated correctly the target is drawn along with the interference pattern. The target may be moved toward or away from the emitter by changing the polarity of the beams. Range of the beam affects the maximum mass that can be moved by the emitter, and the emitter subjects its anchoring structure to significant force.
UFO reports.
Mansfield, Ohio.
According to Peter Sturrock’s report of findings by the panel of scientists assembled to review the physical evidence of UFOs, one of the reports of apparent gravitational and/or inertial effects was the Mansfield, Ohio, Case of October 18, 1973. Chapter 29 of Sturrock’s report included the entire investigative report by Jennie Zeidman, former Project Blue Book secretary for J. Allen Hynek. Zeidman’s reports had been prepared for the Center for UFO Studies. Michael D. Swords presented the Mansfield, Ohio, Case to Sturrock’s panel of scientists. According to the testimony of the flight crew and independent ground witnesses, a green light beam from a cigar-shaped UFO had caused an U.S. Army Reserve helicopter to ascend 2,000 feet while its flight controls were in the descend position. Attempts to debunk the early reports of the incident were effectively refuted by researchers. The Mansfield, Ohio, Case has been described as one of the most amazing UFO reports.
Jenny Randles’ summary of the Mansfield, Ohio, Case concluded a tractor beam had been used to cause the rapid ascension of the helicopter. She compared that case with a February 12, 1979, incident that had been investigated by the Yorkshire UFO Society. According to that account, a British Rail worker was transported six feet into the air by a green light beam to avoid potential harm from a passing Harrogate to Leeds train.
Jemgum, Germany.
The compilation of European cases by Illobrand von Ludwiger, Director, Mutual UFO Network – Central European Section, Incorporated (MUFON-CES), included the sightings of two cigar-shaped UFO’s emitting light beams, that seemed to guide the behavior of smaller UFOs. Witnesses in Jemgum, a small village in the northeast corner of Germany, saw the objects through binoculars on March 7, 1977. MUFON-CES investigated the reports and assessed the case with a 99.99% reliability index (a definition of Olsen’s reliability index was given in Appendix A of Ludwiger’s book).

</doc>
<doc id="44435" url="http://en.wikipedia.org/wiki?curid=44435" title="Rostrum">
Rostrum

Rostrum may refer to:

</doc>
<doc id="44436" url="http://en.wikipedia.org/wiki?curid=44436" title="Wilhelm Johannsen">
Wilhelm Johannsen

Wilhelm Johannsen (3 February 1857 – 11 November 1927) was a Danish botanist, plant physiologist, and geneticist. He was born in Copenhagen. While very young, he was apprenticed to a pharmacist and worked in Denmark and Germany beginning in 1872 until passing his pharmacist's exam in 1879. In 1881, he became assistant in the chemistry department at the Carlsberg Laboratory under the chemist Johan Kjeldahl. Johannsen studied the metabolism of dormancy and germination in seeds, tubers and buds. He showed that dormancy could be broken by various anesthetic compounds, such as diethyl ether and chloroform.
In 1892, he was appointed lecturer at Royal Veterinary and Agricultural University and later became professor of botany and plant physiology. He taught plant physiology. His most well-known research concerned so-called "pure lines" of the self-fertile common bean. He was able to show that even in populations homozygous for all traits, i.e. without genetic variation, seed size followed a normal distribution. This was attributable to resource provision to the mother plant and to the position of seeds in pods and of pods on the plant. This led him to coin the terms "phenotype" and "genotype".
His findings led him to oppose contemporary Darwinists, most notably Francis Galton and Karl Pearson, who held the occurrence of normal distributed trait variation in populations as proof of gradual genetic variation on which selection could act. Only with the modern evolutionary synthesis, was it established that variation needed to be heritable to act as the raw material for selection.
The terms "phenotype" and "genotype" were created by Wilhelm Johannsen and first used in his paper "Om arvelighed i samfund og i rene linier" and in his book "Arvelighedslærens Elementer". This book was rewritten, enlarged and translated to German as "Elemente der exakten Erblichkeitslehre". It was in this book Johannsen introduced the term "gene". This term was coined in opposition to the then common "pangene" that stemmed from Darwin's theory of pangenesis. The book became one of the founding texts of genetics.
Also in 1905, Johannsen was appointed professor of plant physiology at the University of Copenhagen, becoming vice-chancellor in 1917. In December 1910, Johannsen was invited to give an address before the American Society of Naturalists. This talk was printed in the American Naturalist. In 1911, he was invited to give a series of four lectures at Columbia University.
Miscellaneous.
Corresponding member of the Academy of Natural Sciences of Philadelphia (elected 1915).
External links.
 

</doc>
<doc id="44437" url="http://en.wikipedia.org/wiki?curid=44437" title="The Great Ziegfeld">
The Great Ziegfeld

The Great Ziegfeld is a 1936 American musical drama film directed by Robert Z. Leonard and produced by Hunt Stromberg. It stars William Powell as the theatrical impresario Florenz "Flo" Ziegfeld, Jr., Luise Rainer as Anna Held, and Myrna Loy as Billie Burke.
The film, shot at MGM Studios in Culver City, California in the fall of 1935, is a fictionalized tribute to Florenz Ziegfeld, Jr. and a cinematic adaption of Broadway's Ziegfeld Follies, with highly elaborate costumes, dances and sets. Many of the performers of the theatrical Ziegfeld Follies were cast in the film as themselves, including Fanny Brice and Harriet Hoctor, and Billie Burke acted as a supervisor for the film. The "A Pretty Girl Is Like a Melody" set alone was reported to have cost US$220,000 (US$ in 2015 dollars), featuring a towering rotating volute of 70 ft diameter with 175 spiral steps, weighing 100 tons. The music to the film was provided by Walter Donaldson, Irving Berlin, and lyricist Harold Adamson, with choreographed scenes. The extravagant costumes were designed by Adrian, taking some 250 tailors and seamstresses six months to prepare them using 50 lb of silver sequins and 12 yd of white ostrich plumes. Over a thousand people were employed in the production of the film, which required 16 reels of film after the cutting.
One of the biggest successes in film in the 1930s and the pride of MGM at the time, it was acclaimed as the greatest musical biography to be made in Hollywood and still remains a standard in musical film making. It won three Academy Awards, including Best Picture for producer Hunt Stromberg, Best Actress for Luise Rainer, and Best Dance Direction for Seymour Felix, and was nominated for four others. Although the film is still praised for its lavish production and as a symbol of glamor and excess during the Golden Age of Hollywood, today "The Great Ziegfeld" is generally seen less favorably and is considered by many critics to be excessively showy and long at just under three hours.
MGM made two more "Ziegfeld" films - one entitled "Ziegfeld Girl" (1941), starring James Stewart, Judy Garland, Hedy Lamarr, and Lana Turner, which recycled some film from "The Great Ziegfeld", and in 1946, "Ziegfeld Follies" by Vincente Minnelli. In 1951, they produced their Technicolor remake of "Show Boat", which Ziegfeld had presented as a stage musical.
Plot.
The son of a highly respected music professor, Florenz "Flo" Ziegfeld, Jr. yearns to make his mark in show business. He begins by promoting Eugen Sandow, the "world's strongest man", at the 1893 Chicago World's Fair, overcoming the competition of rival Billings and his popular attraction, belly dancer Little Egypt, with savvy marketing (allowing women to feel Sandow's muscles).
Ziegfeld returns to his father and young Mary Lou at the Chicago Musical College, and departs to San Francisco, where he and Sandow are deemed frauds for putting on a show in which Sandow faces a lion who falls asleep as soon as it is let out of the cage. Flo travels to England on an ocean liner, where he runs into Billings again who is laughing at a newspaper article denouncing him as a fraud. Flo discovers that Billings is on his way to sign a contract with beautiful French star, Anna Held. Despite losing all his money gambling at Monte Carlo, Flo charms Anna into signing with him instead, pretending that he doesn't know Billings. Anna twice almost sends him away for his rudeness and for being broke, before revealing that she appreciates his honesty. Ziegfeld promises to give her "more publicity than she ever dreams of" and to feature her alongside America's most prominent theatrical performers.
At first, Anna's performance at the Herald Square Theatre is not a success. However, Flo manages to generate publicity by sending 20 gallons of milk to Anna every day for a fictitious milk bath beauty treatment, then refusing to pay the bill. The newspaper stories soon bring the curious to pack his theater, and Ziegfeld introduces eight new performers to back her. Viewers watch her comment on how the milk must make her skin beautiful and the show is a major success. Flo sends Anna flowers and jewelry and a note saying "you were magnificent my wife", and she agrees to marry him, flaunting her new diamonds to her fellow performers.
However, one success is not enough for the showman. He has an idea for an entirely new kind of show featuring a bevy of blondes and brunettes, one that will "glorify" the American girl. The new show, the "Ziegfeld Follies", an opulent production filled with beautiful women and highly extravagant costumes and sets, is a smash hit, and is followed by more versions of the Follies. Ziegfeld tries to make a star out of Audrey Dane, who is plagued with alcoholism and lures Fanny Brice away from vaudeville, showering both with lavish gifts. He gives stagehand Ray Bolger his break as well. Mary Lou, now a young woman, visits Ziegfeld, who doesn't recognize her initially, and hires her as a dancer. The new production upsets Anna, who realizes that Flo's world does not revolve around just her, and she becomes envious of the attention he pays to Audrey. She divorces him after walking in on Flo and a drunk Audrey at the wrong moment. Audrey walks out on Flo and the show after an angry confrontation. Broke, Flo borrows money from Billings for a third time for the new show. Flo meets the red-headed Broadway star Billie Burke and soon marries her. When she hears the news, a heartbroken Anna telephones Flo and pretends to be glad for him. Flo and Billie eventually have a daughter named Patricia.
Flo's new shows are a success, but after a while, the public's taste changes, and people begin to wonder if the times have not passed him by. After a string of negative reviews in the press, Flo overhears three men in a barber's shop saying that he'll "never produce another hit". Stung, he vows to have "four" hits on Broadway at the same time. He achieves his goal, with the hits "Show Boat" (1927), "Rio Rita" (1927), "Whoopee!" (1928), and "The Three Musketeers", and invests over $1 million (US$ in 2015 dollars) of his earnings in the stock market. However, the stock market crash of 1929 bankrupts him, forcing Billie to return to the stage.
Shaken by the reversal of his financial fortunes and the growing popularity of movies over live stage shows, he becomes seriously ill. Billings pays him a friendly visit, and the two men agree to become partners in a new, even grander production of "The Ziegfeld Follies". But the reality is that both men are broke and Ziegfeld realizes this. In the final scene in his apartment overlooking the Ziegfeld Theatre, in a half-delirium, he recalls scenes from several of his hits, exclaiming, "I've got to have more steps, higher, higher", before slumping over dead in his chair.
Production.
Ziegfeld's widow, Billie Burke, was keen to pay off Ziegfeld's debts without filing for bankruptcy, and sold the rights to a biopic of him to Universal Pictures in late 1933. As a result, the film went into the pre-production phase in January 1934. Macguire had initially proposed the biographical film to them in the form of a "filmusical entertainment" set in a "theatrical tradition" and William Powell was cast as Ziegfeld. However, by February 1935, Macguire had fallen into disagreement with Universal over financial problems at the studio, and the entire production, including some already constructed sets and musical arrangements, were sold to MGM for US$300,000 (US$ in 2015 dollars). As part of the deal however, Universal retained the services of Powell for the classic screwball comedy "My Man Godfrey", which was released the same year as "The Great Ziegfeld".
The film was shot at MGM Studios in Culver City, California mostly in the latter half of 1935 under a budget of US$1,500,000 (US$ in 2015 dollars), produced by Hunt Stromberg. The cost exceeded US$2 million (US$ in 2015 dollars) by the end of the production in early 1936, exorbitant for the period, and it was MGM's most expensive film to date after "Ben Hur" (1925). The principal cinematography was shot by Oliver T. Marsh, and George Folsey and Karl Freund were brought in to shoot the Ziegfeld Roof numbers. Ray June shot the "Melody" number and Merritt B. Gerstad is credited for the Hoctor Ballet.
In the advertising for the film, MGM boasted of the film's ostentatious nature, bragging that it was "SO BIG that only MGM could handle it", with its "countless beauties, trained lions, ponies, dogs and other animals". Busby Berkeley, who had led Warner Brothers to become the leading producer of musicals in Hollywood in the 1930s, was a major influence on the producers which had "glamorous, excessive 1930s cinematic musical numbers". The film also came at a time when producers had begun seeing the economic and cultural importance of the cinematic medium in comparison to theater. "Variety" notes that the film producers were likely very concerned with the presentation of the film after production was wrapped up, and that the long length of the film at 176 minutes was understandable in that they probably "wanted to preserve as much footage as possible". William S. Gray was responsible for the editing of the film. Over a thousand people were employed in the production, and "The Great Ziegfeld" required 16 reels of film after the cutting.
By coincidence, Universal's 1936 film version of the Ziegfeld musical "Show Boat", the most faithful of all the film versions of the stage production, was filmed at the same time as "The Great Ziegfeld" and released in the same year.
Screenplay.
The screenplay by William Anthony McGuire was a "novelty" to many audiences who were familiar with the theatrical Broadway shows of the follies. The script, although fictionalized with embellishments needed for the motion picture, did show some accuracies in the life of Ziegfeld. Frank S. Nugent of "The New York Times" said of the script: "What William Anthony McGuire has attempted in his screen play, and with general success, is to encompass not merely the fantastic personal history of Ziegfeld but the cross-sectional story of the development of the Follies, the Midnight Frolic on the New Amsterdam Roof and the other theatrical enterprises floated under the Glorifier's aegis during a span of about forty years. The two biographies—of the man and of his creations—are, naturally, inseparable; but both have been told with such wealth of detail and circumstance (real and imaginative) that even the three-hour film narrative is fragmentary and, in some places, confused."
Although it has some accuracies, "The Great Ziegfeld" takes many key liberties with Ziegfeld's life and the history of the "Follies", resulting in many inaccuracies. The earlier scenes with Sandow, the milk bath advertising scenario, and many other sequences including several of the dramatic ups and downs of the film were fictional. George Gershwin's "Rhapsody in Blue" was never featured in the "Follies", and the number "A Pretty Girl Is Like a Melody" was written for the 1919 "Follies", not the first edition of the revue, as shown in the film. Ray Bolger was never cast in a "Follies" show, and although she was born in the U.S, Billie Burke grew up in England and spoke with a "Mid-Atlantic" accent throughout her life; Loy who portrays her clearly has an American accent in the film. In the film, the last few lines of the song "Ol' Man River" (from "Show Boat") are sung by what sounds like a tenor, while the song was intended for bass Paul Robeson and sung in the original production by bass-baritone Jules Bledsoe. Further, the screenplay also gives the impression that the successful original production of "Show Boat", which Ziegfeld produced, closed because of the Great Depression. In fact "Show Boat" ended its original 1927 run in the spring of 1929 and the stock market crash did not occur until October of that year. It was the 1932 revival of the show (also produced by Ziegfeld shortly before his death), not the original production, that was affected by the Depression. In real life, Ziegeld did not die in his room at the Hotel Warwick (not mentioned) which stood in front of the Ziegfeld Theatre; he actually died in Los Angeles and had not even spent his last years in New York. However, McGuire did capture a number of Ziegfeld's traits, such as sending telegrams to people even in close proximity, his belief that elephants were a symbol of good luck, his exquisite taste in costumes and design, and perfectionism over his productions, especially lighting and rostrum pedestaling. McGuire's script, now in the Henry E. Huntington Library, San Marino, California, is dated to 21 September 1935, probably the date when it was finalized.
Casting.
Initially, the main cast proposed for the film included Marilyn Miller, Gilda Gray, Ann Pennington, and Leon Errol. Featured in the film are William Powell as Ziegfeld, Myrna Loy as Billie Burke, Luise Rainer as Anna Held, Nat Pendleton as Eugen Sandow, and Frank Morgan. Powell admitted to being "amazed" with the film after viewing it and was very grateful at having had the privilege to portray Ziegfeld, considering it to be a very important moment in his career. He said, "After seeing this film I can see that most of the characters I have played before were contrived. They had no 'folks', as the character of Ziegfeld had in this picture. Their father was a pen and their mother was a bottle of ink. Here was a character with flesh, blood and sinews. I felt for the first time in my acting career I had tried the full measure of a man, regardless of my shortcomings in playing him."
Many of the performers of the earlier Broadway version of the Ziegfeld Follies were cast in the film as themselves, including Fanny Brice and Harriet Hoctor, the ballet dancer and contortionist. "The Great Ziegfeld" marked Rainer's second Hollywood film role after "Escapade" (also with Powell). Fanny Brice appears as a comedienne in the abridged song sequence "My Man" and played an effective version of herself in addition to her routine comic role as the funny girl. 
Nat Pendleton, a freestyle wrestler who had won the silver medal at the 1920 Summer Olympics in Antwerp and had appeared alongside Powell in "The Thin Man" (1934), was cast as the circus strongman Eugen Sandow.
Billie Burke objected to her role being cast with another actress (Myrna Loy) since she was also an actress under contract to the studio and could play herself, but the producers concluded that at that point she was not a big enough star to play herself in "The Great Ziegfeld". According to Emily W. Leider however, Burke was not keen on playing her younger self and mentions that Billie Burke's biographer stated that Miriam Hopkins would have been her first choice to play her part, not Loy. Burke herself worked as technical consultant, and although she did not object to Marilyn Miller performing a number, she was influential in the studio's refusal to give her the higher billing and salary she had demanded, which led to Miller walking away from the film. Both Miller and Lillian Lorraine threatened legal action if so much as their names were mentioned in the film. Thus Miller's character was renamed "Sally Manners", and Lorraine's character was renamed "Audrey Dane" (played by Virginia Bruce). In real life, Ziegfeld had reportedly been obsessed with Miller, and was involved in numerous sex scandals. In 1922 Miller had given an interview in which she accused him of "making love to chorus girls" and sending her a diamond ring as "big as her hand"; this essence of Ziegfeld's character is captured in the film. Incidentally, Miller died from toxicity complications after surgery just before the release of the film on 7 April 1936, which led one reviewer writing in "Liberty" to denounce an urban legend which had arisen surrounding the timing of her death, saying, "It’s not true that Marilyn Miller died of a broken heart at not getting the lead in this." Another myth surrounding her untimely death at the age of 37 is that she had contracted syphilis.
Frank Morgan, a stage and film character actor, played the role of promoter Billings in the film. Dennis Morgan, in an uncredited role, performs in "A Pretty Girl Is Like a Melody" (dubbed by Allan Jones). Pat Nixon (then Pat Ryan), the future wife of Richard Nixon and First Lady of the United States, was an extra in the film. Will Rogers had intended to appear in the film but was killed in a plane crash in August 1935. He was played by stand-in A. A. Trimble.
Costumes.
The extravagant costumes, which even Ziegfeld initially considered too flamboyant, were designed by Adrian, who had worked with many of the greatest actresses of the period including Greta Garbo, Norma Shearer, Jeanette MacDonald, Jean Harlow, Katharine Hepburn and Joan Crawford, and later designed for films such as "Marie Antoinette" (1938), "The Women" (1939), and "The Wizard of Oz" (1939). Howard Gutner documents that due to MGM's wealth and the high budget, Adrian was able to indulge in "sheer lavishness" in making the costumes, surpassing anything he had done previously. It took 250 tailors and seamstresses six months to sew the costumes that Adrian had designed for the film, using 50 lb of silver sequins and 12 yd of white ostrich plumes. The costumes worn by women in the film are diverse, varying from "puffy hooped skirts to catlike leopards" to "layers of tulle and chiffron", with the men mostly wearing black tuxedos.
Mise en scène and music.
Leonard, a film director who specialized in melodrama and musicals, anchored the music for the film, working with Walter Donaldson, Irving Berlin, and lyricist Harold Adamson. The extravagant dances and ensemble sequences were choreographed by Seymour Felix and Harold Adamson, including the song sequence of "A Pretty Girl Is Like a Melody" (it was Irving Berlin’s 13th annual edition in 1919). The "A Pretty Girl Is Like a Melody" set, known as the "Wedding Cake", involved several weeks of shooting time and was reported to have cost US$220,000 (US$ in 2015 dollars). As many as 180 performers were involved in the scenes which included singers, dancers and musicians. The sequence presented started with the "Rhapsody in Blue" and concluded with Virginia Bruce descending from the volute as it rotated, a satin curtain being lowered from the top enclosing the volute. The Mauritians, made of rayon silk, measured 4300 yd. Sheldon Hall and Stephen Neale note the theatrical sense that the cinematographers achieved through shooting the sequence in virtually a single take. They mention that "the camera traverses an enormous platform set contained within a curtained proscenium (also enormous)", and that the "set itself revolves to meet the camera, rather than the camera entering the space of the set." Linda Mizejewski, author of a book on the Ziegfeld girls, argues that the Pretty Girl sequence is more than just about being showy; it is symbolic of womanhood which "powerfully visualizes women as the raw material for male aesthetic vision and design". In the film she believes that womanhood is defined by the "young, white, blond and slender" female, which in the sequence are "delineated as the fluffy, artificial tiers of costuming and staging".
The Harriet Hoctor ballet music was scored by Con Conrad to lyrics written by Herb Magidson. The circus ballet was an adaptation from the old Ziegfeld stage shows. "Variety" called the Hoctor ballet "in itself intricate with its maneuverings of six Russian wolfhounds in terp formations", and said that the "A Pretty Girl Is Like a Melody" sequence in the film is a "nifty Berlin tune [which] becomes the fulcrum for one of Frank Skinner's best arrangements as Arthur Lange batons the crescendos into a mad, glittering potpourri of Saint-Saëns and Gershwin, Strauss and Verdi, beautifully blended against the Berlinesque background. It’s a scenic flash which makes the auditor wonder 'What can they do to follow that?' meaning in this or future film production." Juan Antonio Ramírez refers to the wedding cake as a "famous spiral column", citing it as one of the best known pieces of mobile architecture in film, but notes that in design the cake was not exclusive to "The Great Ziegfeld", explaining that a wedding cake, albeit less flamboyant, had appeared in previous films such "The King of Jazz" (1930), "The Kid from Spain" (1932), "Top Hat" (1935), and "Follow the Fleet" (1935). Ramírez describes the film's "Mise en scène" as representing "the last word in flashy vulgarity, Surrealist kitsch, or perhaps both at once".
Finale:
Aftermath.
Farida Mahzar filed a lawsuit against the filmmakers shortly before her death, claiming that they "presented Little Egypt as a lewd character". 14 witnesses who had seen the act at the 1893 Chicago World Fair supported this, although the lawsuit was dropped after Mahzar died from a heart attack. Burke caused much controversy and upset among many of Ziegfeld's friends and colleagues when she sold the rights to a production on Broadway, the "Ziegfeld Follies", also starring Fanny Brice, at the time the film was released in 1936, due to the fact that the show was produced by the Shubert brothers, whom Ziegfeld detested. Worse still for his associates, was that the show was a bigger success than Ziegfeld's last production of the Follies in 1931. The "Ziegfeld Follies" under Vincente Minnelli was initially performed in December 1935, before making its Broadway debut on January 30, 1936. It was performed in Boston and Philadelphia until the production was postponed after Brice collapsed on stage with exhaustion. When it reopened on Broadway in September 1936, five months after the release of the film, it was retitled "The New Ziegfeld Follies of 1936–1937", and was revamped considerably, with changes to the show's humor.
In 1941, Metro-Goldwyn-Mayer produced a sequel entitled "Ziegfeld Girl", starring James Stewart, Judy Garland, Hedy Lamarr, and Lana Turner, which recycled some film from "The Great Ziegfeld". In 1946, MGM made another sequel, "Ziegfeld Follies", directed by Vincente Minnelli, director of the stage show.
Reception.
Box office.
According to MGM records, the film earned a then-massive $3,089,000 in the US and Canada and $1,584,000 elsewhere resulting in a profit of $822,000.
Critical response at the time of release.
The film, which premiered in Los Angeles at the Carthay Circle Theatre, was the first musical film in history for which one of its cast members won an Academy Award. Luise Rainer received the Best Actress Oscar for her portrayal of Ziegfeld's first wife, Anna Held. The film, the pride of MGM at a time when Warner Brothers and RKO Pictures were the leading studios in Hollywood for musical production, was a major commercial and critical success and one of the most successful films of the 1930s, grossing US$4,673,000 (US$ in 2015 dollars) worldwide at the box office. It was acclaimed upon release as the greatest musical biography to be made in Hollywood and still remains a standard in musical film making. At just short of three hours, "The Great Ziegfeld" was also the longest talking film of the time. (D.W. Griffith's "The Birth of a Nation" and "Intolerance", both silent films, had each run over three hours.) TCM has acclaimed the "A Pretty Girl Is Like a Melody" sequence as one of "the most famous musical numbers ever filmed". Thomas S. Hischak has said that the film has rarely been topped for pure showmanship and glamor, and "Variety" considered it an "outstanding picture", a "symbol of a tradition of show business". "Variety" praised the performances of the cast, remarking that as Ziegfeld, William Powell "endows the impersonation with all the qualities of a great entrepreneur and sentimentalist without sacrificing the shades and moods called for" and noting that Luise Rainer is "tops of the femmes with her vivacious Anna Held". Stanley Green cited the "The Great Ziegfeld" as "the first of a number of elaborate show-business screen biographies". Otis Ferguson, writing for "New Republic" magazine, remarked that the "musical numbers seem as irresistible as Ziegfeld himself". The "New York American" said that the film is "pretty nearly everything such an extravaganza should be", with "romance and reality, song and dance, gaiety and beauty, pathos and bathos". "Time" magazine qualified it as "Pretentious, packed with hokum and as richly sentimental as an Irving Berlin lyric, it is, as such, top-notch entertainment." A reviewer for the "Spokane Chronicle" praised the film for its superb acting, writing that "[even] the great producer [Ziegfeld] would have been unable to produce scenes of magnitude and splendor that are given as part of the picture telling his life." Frank S. Nugent of "The New York Times" was also highly praising of the film, noting that it had "more stars than there are in the heavens" and remarking that "the picture achieves its best moments in the larger sequences devoted to the Girls — ballet, chorus and show. At least one of these spectacular numbers, filmed to the music of Irving Berlin's "A Pretty Girl Is Like a Melody," with overtones of "Rhapsody in Blue," never has been equaled on the musical comedy stage or screen." Both "The New York Times" and "Film Daily" rated the film in the "Ten Best" of the year.
However, not all critics were as enthusiastic about the film; Graham Green of the British "Spectator" called it a "huge inflated glass-blown object" and criticized its length, comparing it to the feat of a flagpole sitter. A number of critics, although praising the film in general, felt that Myrna Loy, who appears rather late on in the film, gave a lackluster performance as Billie Burke. Nugent said that "Miss Loy is a stately Bille Burke, and somewhat lacking, we fear, in Miss Burke's effervescence and gaiety", and Cecilia Agner thought she came across as "stilted, like her rigidly waxed and set blonde wig". Harrison Carroll of the "Los Angeles Herald Express", however, sympathized with the difficulty of her role in portraying a prominent living actress, confessing that he was pleased that Loy did not attempt to imitate Burke's mannerisms. Emily W. Leider believes that any of her character flaws were due to a "mushy" script, rather than her performance as an actress.
Critical re-evaluation.
Although the film is still viewed as a symbol of glamor and excess during the Golden Age of Hollywood, 
today the film has more of a mixed reception, with many critics believing that the film relies on its (now-dated) extravagance and is too long; Christopher Null stated that "The Great Ziegfeld" is a "textbook case of how a film can lose its appeal over the years". Since its release the film has been criticized in particular for being unnecessarily lengthy and its overacting (particularly by Rainer), and is occasionally cited as a "prime example of the Academy's fallibility" in a year when other critically acclaimed pictures such as "Mr. Deeds Goes to Town" were released, which some argue was more deserving of Best Picture. The consensus today on the review site Rotten Tomatoes is that although the "biopic is undeniably stylish", it "loses points for excessive length, an overreliance on clichés, and historical inaccuracies", and has a 61% fresh rating. Emily W. Leider claims the film to be "more remarkable for its “legs and tinsel” extravagance than for its excellence." David Parkinson of "Empire" magazine gave the film 3 out of 5 stars and concluded that it "Drags in places and doesn't even try for a true-to-life portrait of the great theatre entrepreneur but it's shiny and big spectacle with impressive choreography." Dave Kehr of the "Chicago Reader" called it "amazingly dull, even with William Powell in the lead and guest appearances by the likes of Ray Bolger and Fanny Brice." Emanuel Levy gave it a C grade and stated that it was "overlong and overblown but ultimately mediocre as a musical movie and as a biopic of the legendary showman." James Berardinelli awarded it 2.5 out of 4 stars and stated that "although some of the production's technical aspects remain impressive, the dramatic elements come across as trite and many of the musical numbers are dated", but said that it was a "reasonably competent - albeit "airbrushed" - presentation of the main character's life."
Accolades.
The seven Academy Award nominations were announced on February 7, 1937, and on March 4, 1937, "The Great Ziegfeld" won three Oscars at the 9th Academy Awards:
Although he was not nominated for an Academy Award for his performance, Powell did receive the Screen Actor's Guild award for Best Actor in a tie with C. Aubrey Smith who was in "Little Lord Fauntleroy". In addition the Guild's Best Actress was given to Luise Rainer.
References.
</dl>

</doc>
<doc id="44438" url="http://en.wikipedia.org/wiki?curid=44438" title="Gosnells">
Gosnells

The name Gosnells may refer to:

</doc>
<doc id="44439" url="http://en.wikipedia.org/wiki?curid=44439" title="Erotic spanking">
Erotic spanking

Erotic spanking is the act of spanking another person for the sexual arousal or gratification of either or both parties. Activities range from a spontaneous smack on bare buttocks during a sexual activity, to occasional sexual roleplay, such as ageplay, to domestic discipline and may involve the use of a hand or the use of a variety of spanking implements, such as a spanking paddle or cane. Erotic spankings are commonly combined with other forms of sexual foreplay. The most common type of erotic spanking is administered on the bare buttocks, but can also be combined with bondage, in order to heighten sexual arousal and feelings of helplessness.
Many cultures describe pain as an aphrodisiac. For example, the Kama Sutra, in particular, goes into specific detail on how to properly strike a partner during sex.
History and literature.
In some cultures, the spanking of women by the male head of the family or by the husband – sometimes called domestic discipline – has been, and sometimes continues to be, a common and approved custom. In those cultures and in those times, it was the belief that the husband, as head of the family, had a right and even the duty to discipline his wife and children when he saw fit, and manuals were available to instruct the husband how to discipline his household. In most western countries, this practice has come to be regarded as unlawful and socially unacceptable wife-beating, domestic violence or abuse. Routine corporal punishment of women by their husbands, however, does still exist in some parts of the developing world, and still occurs in isolated cases in western countries. However, today, spanking of an adult tends to be confined to erotic spanking or to BDSM contexts.
One of the earliest depictions of erotic flagellation is found in the Etruscan Tomb of the Whipping from the fifth century BC, named after its depictions of eroticized flagellation.
Representations of erotic spanking and flagellation make up a large portion of Victorian pornography, for instance "1000 Nudes" by Koetzle.) Hundreds of thousands of engravings, photographs, and literary depictions of spanking and flagellation ("birching") fantasies circulated during the Victorian era, including erotic novellas like "The Whippingham Papers", "The Birchen Bouquet", "Exhibition of Female Flagellants" or the pornographic comic opera "Lady Bumtickler's Revels". Since their deaths, many well-known people have been discovered to have enjoyed spankings for erotic purposes or emotional gratification, including the noted British Army officer T. E. Lawrence ("Lawrence of Arabia"), influential English theatre critic Kenneth Tynan, TV broadcaster Frank Bough, and English writer John Mortimer.
Other examples include the poet Algernon Swinburne, as implied repeatedly in his poetry, and the philosopher Jean-Jacques Rousseau, as detailed in his autobiography "Confessions":
... Miss Lambercier... exerted a
mother's authority, even to inflicting on us... the
punishment of infants... Who would believe this childish discipline, received at eight years
old, from the hands of a woman of thirty,
should influence my propensities,
my desires, my passions, for the rest of my life...
To fall at the feet of an imperious mistress, obey her mandates, or
implore pardon, were for me the most exquisite enjoyments, and the more
my blood was inflamed by the efforts of a lively imagination the more I
acquired the appearance of a whining lover."
According to Dan Savage, journalist Jillian Keenan is "America's most prominent spanking fetishist" today. She has written about erotic spanking for the New York Times, Slate, and Pacific Standard. Keenan has argued that spanking fetishism is a form of sexual orientation, which should not be considered a mental illness.
Practice.
Implements.
A spanking may be carried out with the use of a bare or gloved hand, or with any of a variety of implements, including a paddle, strap, hairbrush, feather duster or belt. Other popular implements are canes, riding crops, whips, switches, birches, sneakers, rolled-up newspapers, rulers or "martinet".
Costume.
A spank skirt or spanking skirt has an additional opening in back designed to expose the buttocks. While the name "spank skirt" suggests that the wearer could be spanked "bare bottom" without removing or repositioning the skirt, this item may be worn for reasons other than spanking, for instance, exposure). Considered fetish wear, spank skirts are typically tight-fitting and made of fetishistic materials (such as leather, PVC or latex). Regardless of the gender of the wearer, spank skirts are usually considered female attire. The male gender role equivalent might be motorcycle chaps.
Other garments associated with spanking as well as humiliation are ruffled or rhumba panties, women's panties with rows of ruffles on the rear panel or outside.
Apparatus.
A spanking bench or spanking horse is a piece of furniture used to position a spankee on, with or without restraints. They come in many sizes and styles, the most popular of which is similar to a sawhorse with a padded top and rings for restraints. The 19th-century British dominatrix Mrs. Theresa Berkley became famous for her invention of the Berkley Horse, a similar form of BDSM apparatus.
Howard Stern's paddle machine, the "Robospanker", has been used on his show to spank numerous guests, including Jessica Jaymes, Jennifer Krum, Haydn Porter, Tabitha Stevens, Victoria Zdrok, and Valentina Vaughn.
Spanking positions.
Spanking can be administered in a number of spanking positions. The choice of position takes into account the spankee's comfort in the position for long periods of time, the spanker's ability to swing at the spankee at a comfortable, natural angle, complete access to the spankee's buttocks, the spanker's control of the spankee's position and ability to read just as necessary, safety, and the amount of strength the top is able to generate from such a position. Positions can also be chosen specifically for added effects such as increased humiliation, elevation and suspension.
References.
Notes
Further reading
External links.
Listen to this article ()
This audio file was created from a revision of the "Erotic spanking" article dated 2010-10-22, and does not reflect subsequent edits to the article. ()
More spoken articles

</doc>
<doc id="44441" url="http://en.wikipedia.org/wiki?curid=44441" title="Pax Romana">
Pax Romana

Pax Romana (Latin for "Roman peace") was the long period of relative peace and minimal expansion by the Roman military force experienced by the Roman Empire after the end of the Final War of the Roman Republic and before the beginning of the Crisis of the Third Century. Since it was established by Augustus, it is sometimes called Pax Augusta. Its span was approximately 206 years (27 BC to 180 AD) according to "Encyclopedia Britannica" or from 70 AD to 192 AD according to "The Cambridge Ancient History".
The Pax Romana is said to have been a "miracle" because prior to it there had never been peace for so many centuries in a given period of human history. According to Walter Goffart however, "peace is not what one finds in it[s pages]". Arthur M. Eckstein writes that the period needs to be seen in contrast with the much more frequent warfare that occurred in the Roman Republic in the 4th and 3rd centuries BC. Eckstein also notes that the incipient Pax Romana appeared during the Republic and that its temporal span varied with geographical region as well: "Although the standard textbook dates for the Pax Romana, the famous “Roman Peace” in the Mediterranean, are 31 BC to AD 250, the fact is that the Roman Peace was emerging in large regions of the Mediterranean at a much earlier date: Sicily after 210 [BC]; peninsular Italy after 200 [BC]; the Po Valley after 190 [BC]; most of Spain after 133 [BC]; North Africa after 100 [BC]; and for ever longer stretches of time in the Greek East".
The first historical record of the term "Pax Romana" appears to be in a writing of Seneca the Younger in 55 AD. The concept was highly influential, being theorized upon and attempted to be copied in subsequent ages. Arnaldo Momigliano noted that ""Pax Romana" is a simple formula for propaganda, but a difficult subject for research."
The pax Romana started after Octavian (Augustus) defeated Mark Antony in the Battle of Actium on 2 September 31 BC. He became princeps, or "first citizen". Lacking a good precedent of successful one-man rule, Augustus created a junta of the greatest military magnates and stood as the front man. By binding together these leading magnates in a coalition, he eliminated the prospect of civil war. The Pax Romana was not immediate, despite the end of the civil wars, because fighting continued in Hispania and in the Alps. Nevertheless, Augustus closed the Gates of Janus (the Roman ceremony to mark world Peace) three times, first in 29 BC and again in 25 BC. The third closure is undocumented, but Inez Scott Ryberg (1949) and Gaius Stern (2006) have persuasively dated the third closure to 13 BC with the Ara Pacis ceremony. At the time of the Ludi Saeculares in 17 BC the concept of Peace was publicized, and in 13 BC was proclaimed when Augustus and Agrippa jointly returned from pacifying the provinces. The Ara Pacis ceremony was no doubt part of this announcement.
Augustus faced a problem making peace an acceptable mode of life for the Romans, who had been at war with one power or another continuously for 200 years. Romans regarded peace not as an absence of war, but the rare situation that existed when all opponents had been beaten down and lost the ability to resist. Augustus' challenge was to persuade Romans that the prosperity they could achieve in the absence of warfare was better for the Empire than the potential wealth and honor acquired when fighting a risky war. Augustus succeeded by means of skillful propaganda. Subsequent emperors followed his lead, sometimes producing lavish ceremonies to close the Gates of Janus, issuing coins with Pax on the reverse, and patronizing literature extolling the benefits of the Pax Romana.
Similar terms and generic notion.
Given the prominence of the concept of the "Pax Romana", historians have coined variants of the term to describe systems of relative peace that have been established, attempted or argued to have existed. Such times have been credited to the British Empire during the 19th century. Some variants include:
More generically, the concept has been referred to as pax imperia, (sometimes spelled as pax imperium) meaning imperial peace, or—less literally—hegemonic peace. Raymond Aron notes that imperial peace—peace achieved through hegemony—sometimes, but not always—can become civil peace. As an example, the German Empire's imperial peace of 1871 (over its internal components like Saxony) slowly evolved into the later German state. As a counter-example, the imperial peace of Alexander the Great's empire dissolved because the Greek city states maintained their political identity and more importantly, embrios of their own armed forces. Aron notes that during the Pax Romana, the Jewish war was a reminder that the overlapping of the imperial institutions over the local ones did not erase them and the overlap was a source of tension and flare-ups. Aron summarizes that "In other words, "imperial peace" becomes civil peace insofar as the memory of the previously independent political units are effaced, insofar as individuals within a pacified zone feel themselves less united to the traditional or local community and more to the conquering state.'
The concept of Pax Romana was highly influential, and attempted to be imitated in the Byzantine Empire as well as in the Christian West, where it morphed into the Peace and Truce of God ("pax Dei" and "treuga Dei"). A theoretician of the imperial peace during the Middle Ages was Dante Aligheri. Dante's works on the topic were analyzed at the beginning of the 20th century by William Mitchell Ramsay in the book "The Imperial Peace; An Ideal in European History" (1913).

</doc>
<doc id="44442" url="http://en.wikipedia.org/wiki?curid=44442" title="Thora Birch">
Thora Birch

Thora Birch (born March 11, 1982) is an American actress. She got her first role at the age of 6 in the short-lived sitcom "Day by Day", before she starred in "Purple People Eater" (1988), for which she received a Young Artist Award for "Best Young Actress Under Nine Years of Age". Birch's profile was raised significantly with major parts in films, such as "All I Want for Christmas" (1991), "Patriot Games" (1992), "Hocus Pocus" (1993), "Monkey Trouble" (1994), "Now and Then" (1995) and "Alaska" (1996).
Her breakthrough role came in 1999 with the Academy Award winning film, "American Beauty". Her performance was well received by both critics and audiences and brought Birch to international recognition. She later played the lead role in "Ghost World" (2001) for which she received a Golden Globe Award nomination for Best Actress – Motion Picture Musical or Comedy. She has since appeared in independent films such as "Dark Corners" (2006), "Train" (2008) and "Winter of Frozen Dreams" (2009).
Early life.
Birch was born in Los Angeles, California, the eldest child of Jack Birch and Carol Connors. Her parents, who were her business managers from the start, are former adult film actors and both appeared in the pornographic film "Deep Throat". Birch is of German Jewish, Scandinavian, and Italian ancestry. The family's original surname was Biersch. Her name Thora is derived from the name of the Norse God of thunder and lightning, Thor. She has a younger brother named Bolt.
Due to their own experience with acting, Birch's parents were reluctant to encourage her in the profession, but were persuaded to show her photograph to agents by a babysitter who noticed her imitating commercials. She had several parts in the late '80s, such as advertisements for Burger King, California Raisins, Quaker Oats and Vlasic Pickles.
Career.
1988–1995.
In 1988, she landed the role of Molly in the short-lived television series "Day By Day". She was billed simply as "Thora". That same year, she won a part in "Purple People Eater" alongside Ned Beatty and Neil Patrick Harris. Her performance won her a Youth In Film Award. Birch played as 'tomboy' Billie Pike in the movie "Paradise", which also starred Don Johnson, Melanie Griffith and Elijah Wood. Her parts during the period of 1991–1995 included the role of Dani in "Hocus Pocus" (1993), as well as "All I Want for Christmas" (1991) and "Monkey Trouble" (1994). She appeared in two Harrison Ford films, "Patriot Games" (1992) and its sequel, "Clear and Present Danger" (1994), where she played Sally Ryan, the daughter of Ford's character Jack Ryan. Birch's performance in the 1995 film "Now and Then" teamed up with Gaby Hoffmann, Christina Ricci, Demi Moore, Rosie O'Donnell, and Melanie Griffith.
1996–2001.
In 1996, she landed a leading role in the adventure film, "Alaska" (1996). After guest-starring appearances in "The Outer Limits", "Promised Land", and "Touched by an Angel", Birch took a break from acting. In 1999, she returned in the made-for-TV film "Night Ride Home" and also took a small uncredited role in the Natalie Portman film "Anywhere but Here".
Later, Birch won critical praise playing the role of Jane Burnham in "American Beauty" and was nominated for a British Academy of Film and Television Arts award. The film itself went on to win the Academy Award for Best Picture. As Birch was 16 at the time she made the film, and thus classified as a minor in the United States, her parents had to approve her brief topless scene in the film. They and child labor representatives were on the set for the shooting of the scene. After supporting roles in "The Smokers" (2000; where Birch was called "a scene-stealer" by "The Hollywood Reporter") and "Dungeons & Dragons" (2000), she landed the lead role alongside Keira Knightley in the horror movie "The Hole" (2001). The film was released in the cinema in the UK, and went direct-to-video in the US almost two years later and gained divided reviews. "BBC.co.uk" wrote: "Given that she has a much leaner role than the one she enjoyed in "American Beauty", the qualities which made her flourish in that multi-Oscar-winner are still abundantly clear".
Birch landed the leading role in "Ghost World" (2001), alongside Scarlett Johansson, Steve Buscemi and Brad Renfro. Her performances gained positive response from film critics. In his review for "The New York Times", A. O. Scott praised her: "Thora Birch, whose performance as Lester Burnham's alienated daughter was the best thing about "American Beauty", plays a similar character here, with even more intelligence and restraint". In his "Chicago Reader" review, Jonathan Rosenbaum wrote, "Birch makes the character an uncanny encapsulation of adolescent agonies without ever romanticizing or sentimentalizing her attitudes, and Clowes and Zwigoff never allow us to patronize her". However, in his review for "The New York Observer", Andrew Sarris disliked Birch's character of Enid and remarked: "I found Enid smug, complacent, cruel, deceitful, thoughtless, malicious and disloyal". She was nominated for a Golden Globe for her performance.
2002–2013.
Birch played Liz Murray in the made-for-TV movie "" (2003), for which she received an Emmy nomination. The next year, she appeared as Karen in "Silver City" (2004), written and directed by John Sayles, which after premiering at that year's Cannes Film Festival, received a mixed reception.
In 2006, Birch starred in the low-budget horror movie "Dark Corners", a film in which she plays a troubled young woman who wakes up one day as a different person—someone who is stalked by creatures. Tony Sullivan, for "Eyeforfilm.co.uk", found Birch "convincing as the two halves of this split personality". She also had the leading role in the 2008 slasher "Train".
She starred alongside Brittany Murphy in the psychological thriller "Deadline". The film first premiered directly-to-video in October 2009 in the U.K. before being released in December in the U.S. Birch revealed in 2014 that she observed a "condition" in regard to Murphy, stating: "But when I worked with her I saw the condition—she twirls her finger next to her head—and I thought, that can't be good." Birch also stated that she was not surprised upon hearing of Murphy's death.
Also in 2009, she starred in the mystery film "Winter of Frozen Dreams". A controversy during filming involving Birch's father and his forced presence during Birch's taping of a sex scene for the film made tabloid headlines. In January 2010, Birch played Sidney Bloom in the Lifetime movie "The Pregnancy Pact".
Birch was cast and scheduled to make her American stage debut in the off Broadway revival of "Dracula", but was fired for the behavior of her father, her manager at the time, who physically threatened one of the show's cast members. Reflecting on the incident in January 2014, Birch revealed that not only was she in a "state of shock," but later accepted that she had upset a lot of people and those around her wanted her to "be not fine."
She appeared as the lead character in 2013's "Petunia", a film that she also produced and one that received a very limited release. About the motion picture, Birch said: "I think it's just something that's a little bit different from your standard summer fare. It's a little bit more intimate. It's also a very modern tale. I think it's actually honest."
2014–present.
With regard to her reduced exposure in the film industry, she insists that she has continuously worked and maintained a career but "it's just that no one was paying attention." However, Birch admitted that she "decided to take a break and live my life, branch out a little, educate myself." In addition to her ongoing acting aspirations, Birch is seeking production support for a screenplay and stated that she wants to "move forward" as part of a life in which she considers herself "really lucky!"

</doc>
<doc id="44443" url="http://en.wikipedia.org/wiki?curid=44443" title="Anti-capitalism">
Anti-capitalism

Anti-capitalism encompasses a wide variety of movements, ideas and attitudes that oppose capitalism. Anti-capitalists, in the strict sense of the word, are those who wish to replace capitalism with another type of economic system.
Socialism.
Socialism advocates public or direct worker ownership and administration of the means of production and allocation of resources, and a society characterized by equal access to resources for all individuals, with an egalitarian method of compensation.
1. A theory or policy of social organisation which aims at or advocates the ownership and control of the means of production, capital, land, property, etc., by the community as a whole, and their administration or distribution in the interests of all.
2. Socialists argue for cooperative/community or state control of the economy, or the "commanding heights" of the economy, with democratic control by the people over the state, although there have been some undemocratic philosophies. "State" or "worker cooperative" ownership is in fundamental opposition to "private" ownership of means of production, which is a defining feature of capitalism. Most socialists argue that capitalism unfairly concentrates power, wealth and profit, among a small segment of society that controls capital and derives its wealth through exploitation.
Socialists argue that the accumulation of capital generates waste through externalities that require costly corrective regulatory measures. They also point out that this process generates wasteful industries and practices that exist only to generate sufficient demand for products to be sold at a profit (such as high-pressure advertisement); thereby creating rather than satisfying economic demand.
Socialists argue that capitalism consists of irrational activity, such as the purchasing of commodities only to sell at a later time when their price appreciates, rather than for consumption, even if the commodity cannot be sold at a profit to individuals in need; they argue that "making money", or accumulation of capital, does not correspond to the satisfaction of demand.
Private ownership imposes constraints on planning, leading to inaccessible economic decisions that result in immoral production, unemployment and a tremendous waste of material resources during crisis of overproduction. According to socialists, private property in the means of production becomes obsolete when it concentrates into centralized, socialized institutions based on private appropriation of revenue (but based on cooperative work and internal planning in allocation of inputs) until the role of the capitalist becomes redundant. With no need for capital accumulation and a class of owners, private property in the means of production is perceived as being an outdated form of economic organization that should be replaced by a free association of individuals based on public or common ownership of these socialized assets. Socialists view private property relations as limiting the potential of productive forces in the economy.
Early socialists (Utopian socialists and Ricardian socialists) criticized capitalism for concentrating power and wealth within a small segment of society. and does not utilise available technology and resources to their maximum potential in the interests of the public.
Anarchist and libertarian socialist criticisms.
For the influential German individualist anarchist philosopher Max Stirner "private property is a spook which "lives by the grace of law" and it "becomes 'mine' only by effect of the law". In other words, private property exists purely "through the protection of the State, through the State's grace." Recognising its need for state protection, Stirner is also aware that "[i]t need not make any difference to the 'good citizens' who protects them and their principles, whether an absolute King or a constitutional one, a republic, if only they are protected. And what is their principle, whose protector they always 'love'? Not that of labour", rather it is "interest-bearing possession . . . labouring capital, therefore . . . labour certainly, yet little or none at all of one's own, but labour of capital and of the -- subject labourers"." French anarchist Pierre Joseph Proudhon opposed government privilege that protects capitalist, banking and land interests, and the accumulation or acquisition of property (and any form of coercion that led to it) which he believed hampers competition and keeps wealth in the hands of the few. The Spanish individualist anarchist Miguel Gimenez Igualada sees "capitalism is an effect of government; the disappearance of government means capitalism falls from its pedestal vertiginously...That which we call capitalism is not something else but a product of the State, within which the only thing that is being pushed forward is profit, good or badly acquired. And so to fight against capitalism is a pointless task, since be it State capitalism or Enterprise capitalism, as long as Government exists, exploiting capital will exist. The fight, but of consciousness, is against the State.".
Within anarchism there emerged a critique of wage slavery which refers to a situation perceived as quasi-voluntary slavery, where a person's livelihood depends on wages, especially when the dependence is total and immediate. It is a negatively connoted term used to draw an analogy between slavery and wage labor by focusing on similarities between owning and renting a person. The term "wage slavery" has been used to criticize economic exploitation and social stratification, with the former seen primarily as unequal bargaining power between labor and capital (particularly when workers are paid comparatively low wages, e.g. in sweatshops), and the latter as a lack of workers' self-management, fulfilling job choices and leisure in an economy. Libertarian socialists believe if freedom is valued, then society must work towards a system in which individuals have the power to decide economic issues along with political issues. Libertarian socialists seek to replace unjustified authority with direct democracy, voluntary federation, and popular autonomy in all aspects of life, including physical communities and economic enterprises. With the advent of the industrial revolution, thinkers such as Proudhon and Marx elaborated the comparison between wage labor and slavery in the context of a critique of societal property not intended for active personal use, Luddites emphasized the dehumanization brought about by machines while later Emma Goldman famously denounced wage slavery by saying: "The only difference is that you are hired slaves instead of block slaves.". American anarchist Emma Goldman believed that the economic system of capitalism was incompatible with human liberty. "The only demand that property recognizes," she wrote in "Anarchism and Other Essays", "is its own gluttonous appetite for greater wealth, because wealth means power; the power to subdue, to crush, to exploit, the power to enslave, to outrage, to degrade." She also argued that capitalism dehumanized workers, "turning the producer into a mere particle of a machine, with less will and decision than his master of steel and iron."
Noam Chomsky contends that there is little moral difference between chattel slavery and renting one's self to an owner or "wage slavery". He feels that it is an attack on personal integrity that undermines individual freedom. He holds that workers should own and control their workplace. Many libertarian socialists argue that large-scale voluntary associations should manage industrial manufacture, while workers retain rights to the individual products of their labor. As such, they see a distinction between the concepts of "private property" and "personal possession". Whereas "private property" grants an individual exclusive control over a thing whether it is in use or not, and regardless of its productive capacity, "possession" grants no rights to things that are not in use.
In addition to individualist anarchist Benjamin Tucker's "big four" monopolies (land, money, tariffs, and patents), Carson argues that the state has also transferred wealth to the wealthy by subsidizing organizational centralization, in the form of transportation and communication subsidies. He believes that Tucker overlooked this issue due to Tucker's focus on individual market transactions, whereas Carson also focuses on organizational issues. The theoretical sections of "Studies in Mutualist Political Economy" are presented as an attempt to integrate marginalist critiques into the labor theory of value. Carson has also been highly critical of intellectual property. The primary focus of his most recent work has been decentralized manufacturing and the informal and household economies. Carson holds that “Capitalism, arising as a new class society directly from the old class society of the Middle Ages, was founded on an act of robbery as massive as the earlier feudal conquest of the land. It has been sustained to the present by continual state intervention to protect its system of privilege without which its survival is unimaginable.” Carson coined the pejorative term "vulgar libertarianism," a phrase that describes the use of a free market rhetoric in defense of corporate capitalism and economic inequality. According to Carson, the term is derived from the phrase "vulgar political economy," which Karl Marx described as an economic order that "deliberately becomes increasingly apologetic and makes strenuous attempts to talk out of existence the ideas which contain the contradictions [existing in economic life]."
Marxism.
"We are, in Marx's terms, 'an ensemble of social relations' and we live our lives at the core of the intersection of a number of unequal social relations based on hierarchically interrelated structures which, together, define the historical specificity of the capitalist modes of production and reproduction and underlay their observable manifestations."—Martha E. Gimenez, "Marxism and Class, Gender and Race: Rethinking the Trilogy"
Marx believed that the capitalist bourgeois and their economists were promoting what he saw as the lie that "The interests of the capitalist and those of the worker are... one and the same"; he believed that they did this by purporting the concept that "the fastest possible growth of productive capital" was best not only for the wealthy capitalists but also for the workers because it provided them with employment.

</doc>
<doc id="44445" url="http://en.wikipedia.org/wiki?curid=44445" title="Greg Bear">
Greg Bear

Gregory Dale "Greg" Bear (born August 20, 1951) is an American science fiction and mainstream author. His work has covered themes of galactic conflict ("Forge of God" books), artificial universes ("The Way" series), consciousness and cultural practices ("Queen of Angels"), and accelerated evolution ("Blood Music", "Darwin's Radio", and "Darwin's Children"). His most recent work is the Forerunner Trilogy, written in the Halo universe. Greg Bear has written 44 books in total. Greg Bear was also one of the five co-founders of the San Diego Comic-Con. 
Early life.
Bear was born in San Diego, California. He attended San Diego State University (1968–73), where he received a Bachelor of Arts degree. At the University, he was a teaching assistant to Elizabeth Chater in her course on science fiction writing, and in later years her friend.
Career.
Bear is often classified as a hard science fiction author, based on the scientific details in his work. Early in his career, he also published work as an artist, including illustrations for an early version of the Star Trek Concordance and covers for "Galaxy" and "F&SF". He sold his first story, "Destroyers", to "Famous Science Fiction" in 1967.
Bear often addresses major questions in contemporary science and culture with fictional solutions. For example, "The Forge of God" offers an explanation for the Fermi paradox, supposing that the galaxy is filled with potentially predatory intelligences and that young civilizations that survive are those that don't attract their attention—by staying quiet. In "Queen of Angels", Bear examines crime, guilt, and punishment in society. He frames these questions around an examination of consciousness and awareness, including the emergent self-awareness of highly advanced computers in communication with humans. In "Darwin's Radio" and "Darwin's Children", he addresses the problem of over-population with a mutation in the human genome making, basically, a new series of humans. The question of cultural acceptance of something new and unavoidable is also brought up.
One of Bear's favorite themes is reality as a function of observers. In "Blood Music", reality becomes unstable as the number of observers—trillions of intelligent single-cell organisms—spirals higher and higher. "Anvil of Stars" (sequel to "The Forge of God") and "Moving Mars" postulate a physics based on information exchange between particles, capable of being altered at the "bit level". (Bear has credited the inspiration for this idea to Frederick Kantor's 1967 treatise "Information Mechanics.") In "Moving Mars", this knowledge is used to remove Mars from the solar system and transfer it to an orbit around a distant star.
"Blood Music" was first published as a short story (1983) and then expanded to a novel (1985). It has also been credited as the first account of nanotechnology in science fiction. More certainly, the short story is the first in science fiction to describe microscopic medical machines and to treat DNA as a computational system capable of being reprogrammed; that is, expanded and modified. In later works, beginning with "Queen of Angels" and continuing with its sequel, "Slant", Bear gives a detailed description of a near-future nanotechnological society. This historical sequence continues with "Heads"—which may contain the first description of a so-called "quantum logic computer"—and with "Moving Mars". This sequence also charts the historical development of self-awareness in AIs. Its continuing character Jill was inspired in part by Robert A. Heinlein's self-aware computer Mycroft HOLMES (High-Optional, Logical, Multi-Evaluating Supervisor) in "The Moon Is a Harsh Mistress".
Bear, Gregory Benford, and David Brin wrote a trilogy of prequel novels to Isaac Asimov's influential "Foundation" trilogy. Bear is credited for the middle book.
While most of Bear's work is science fiction, he has written in other fiction genres. Examples include "Songs of Earth and Power" (fantasy) and "Psychlone" (horror). Bear has described his "Dead Lines", which straddles the line between science fiction and fantasy, as a "high-tech ghost story". He has received many accolades, including five Nebula Awards and two Hugo Awards.
He also serves on the Board of Advisors for the Museum of Science Fiction.
Personal life.
In 1975, Bear married Christina M. Nielson; they divorced in 1981. In 1983, he married Astrid Anderson, the daughter of science fiction author Poul Anderson. They have two children, Erik and Alexandra. They have resided near Seattle, Washington.
He is a deist.
On September 23, 2014, Bear underwent surgery to repair an aortic artery dissection. The procedure included installation of a mechanical aortic valve
Bibliography.
Novels.
Series.
Quantum Logic.
Novels in internal chronology:

</doc>
<doc id="44446" url="http://en.wikipedia.org/wiki?curid=44446" title="Condorcet method">
Condorcet method

A Condorcet method is any election method that elects the candidate that would win by majority rule in all pairings against the other candidates, whenever one of the candidates has that property. A candidate with that property is called a "Condorcet winner" (named for the 18th-century French mathematician and philosopher Marie Jean Antoine Nicolas Caritat, the Marquis de Condorcet, who championed such outcomes). A Condorcet winner doesn't always exist because majority preferences can be like rock-paper-scissors: for each candidate, there can be another that is preferred by some majority (this is known as Condorcet paradox).
Voting methods that always elect the Condorcet winner (when one exists) are the ones that satisfy the Condorcet criterion.
Most Condorcet methods have a single round of voting, in which each voter ranks the candidates from top to bottom. A voter's ranking is often called his or her "order of preference," although it may not match his or her sincere order of preference since voters are free to rank in any order they choose and may have strategic reasons to misrepresent preferences. There are many ways that the votes can be tallied to find a winner, and not all ways will elect the Condorcet winner whenever one exists. The methods that will—the Condorcet methods—can elect different winners when no candidate is a Condorcet winner. Thus the Condorcet methods can differ on which other criteria they satisfy.
The Robert's Rules method for voting on motions and amendments is also a Condorcet method even though the voters do not vote by expressing their orders of preference. There are multiple rounds of voting, and in each round the vote is between two of the alternatives. The loser (by majority rule) of a pairing is eliminated, and the winner of a pairing survives to be paired in a later round against another alternative. Eventually only one alternative remains, and it is the winner. This is analogous to a single-winner tournament; the total number of pairings is one less than the number of alternatives. Since a Condorcet winner will win by majority rule in each of its pairings, it will never be eliminated by Robert's Rules. But this method cannot reveal a voting paradox in which there is no Condorcet winner and a majority prefer an early loser over the eventual winner. A considerable portion of the literature on social choice theory is about the properties of this method since it is widely used and is used by important organizations (legislatures, councils, committees, etc.). It is not practical for use in public elections, however, since its multiple rounds of voting would be very expensive for voters, for candidates, and for governments to administer.
Ramon Llull devised the earliest known Condorcet method in 1299. His method did not have voters express orders of preference; instead, it had a round of voting for each of the possible pairings of candidates. (This was more like the Robert's Rules method except it was analogous to a round-robin tournament instead of a single-elimination tournament.) The winner was the alternative that won the most pairings.
Summary.
For most Condorcet methods, those counts usually suffice to determine the complete order of finish. They always suffice to determine whether there is a Condorcet winner. Additional information may be needed in the event of ties. Ties can be pairings that have no majority, or they can be majorities that are the same size; these ties will be rare when there are many voters. Some Condorcet methods may have other kinds of ties; for example, it would not be rare for two or more candidates to win the same number of pairings, when there is no Condorcet winner.
Definition.
A Condorcet method is a voting system that will always elect the Condorcet winner; this is the candidate whom voters prefer to each other candidate, when compared to them one at a time. This candidate can be found by conducting a series of pairwise comparisons, using the basic procedure described above. For "N" candidates, this requires 1⁄2 "N" ("N" − 1) pairwise hypothetical elections. For example, with 5 candidates there are 10 pairwise comparisons to be made. The family of Condorcet methods is also referred to collectively as Condorcet's method. A voting system that always elects the Condorcet winner when there is one is described by electoral scientists as a system that satisfies the Condorcet criterion.
In certain circumstances an election has no Condorcet winner. This occurs as a result of a kind of tie known as a "majority rule cycle", described by Condorcet's paradox. The manner in which a winner is then chosen varies from one Condorcet method to another. Some Condorcet methods involve the basic procedure described below, coupled with a Condorcet completion method—a method used to find a winner when there is no Condorcet winner. Other Condorcet methods involve an entirely different system of counting, but are classified as Condorcet methods because they will still elect the Condorcet winner if there is one.
It is important to note that not all single winner, ranked voting systems are Condorcet methods. For example, instant-runoff voting and the Borda count do not satisfy the Condorcet criterion.
Basic procedure.
Voting.
In a Condorcet election the voter ranks the list of candidates in order of preference. So, for example, the voter gives a '1' to his first preference, a '2' to his second preference, and so on. In this respect it is the same as an election held under non-Condorcet methods such as instant runoff voting or the single transferable vote. Some Condorcet methods allow voters to rank more than one candidate equally, so that, for example, the voter might express two first preferences rather than just one.
Usually, when a voter does not give a full list of preferences the is assumed, for the purpose of the count, to prefer the candidates he has ranked over all other candidates. Some Condorcet elections permit write-in candidates but, because this can be difficult to implement, software designed for conducting Condorcet elections often does not allow this option.
Finding the winner.
The count is conducted by pitting every candidate against every other candidate in a series of hypothetical one-on-one contests. The winner of each pairing is the candidate preferred by a majority of voters. Unless they tie, there is always a majority when there are only two choices. The candidate preferred by each voter is taken to be the one in the pair that the voter ranks higher on their ballot paper. For example, if Alice is paired against Bob it is necessary to count both the number of voters who have ranked Alice higher than Bob, and the number who have ranked Bob higher than Alice. If Alice is preferred by more voters then she is the winner of that pairing. When all possible pairings of candidates have been considered, if one candidate beats every other candidate in these contests then they are declared the Condorcet winner. As noted above, if there is no Condorcet winner a further method must be used to find the winner of the election, and this mechanism varies from one Condorcet method to another.
Pairwise counting and matrices.
Condorcet methods use pairwise counting. For each possible pair of candidates, one pairwise count indicates how many voters prefer one of the paired candidates over the other candidate, and another pairwise count indicates how many voters have the opposite preference. The counts for all possible pairs of candidates summarize all the preferences of all the voters.
Pairwise counts are often displayed in matrices such as those below. In these matrices each row represents each candidate as a 'runner', while each column represents each candidate as an 'opponent'. The cells at the intersection of rows and columns each show the result of a particular pairwise comparison. Cells comparing a candidate to themselves are left blank.
Imagine there is an election between four candidates: A, B, C and D. The first matrix below records the preferences expressed on a single ballot paper, in which the voter's preferences are (B, C, A, D); that is, the voter ranked B first, C second, A third, and D fourth. In the matrix a '1' indicates that the runner is preferred over the 'opponent', while a '0' indicates that the runner is defeated.
Using a matrix like the one above, one can find the overall results of an election. Each ballot can be transformed into this style of matrix, and then added to all other ballot matrices using matrix addition. The sum of all ballots in an election is called the sum matrix.
Suppose that in the imaginary election there are two other voters. Their preferences are (D, A, C, B) and (A, C, B, D). Added to the first voter, these ballots would give the following sum matrix:
When the sum matrix is found, the contest between each pair of candidates is considered. The number of votes for runner over opponent (runner,opponent) is compared with the number of votes for opponent over runner (opponent,runner) to find the Condorcet winner. In the sum matrix above, A is the Condorcet winner because A beats every other candidate. When there is no Condorcet winner Condorcet completion methods, such as Ranked Pairs and the Schulze method, use the information contained in the sum matrix to choose a winner.
Cells marked '—' in the matrices above have a numerical value of '0', but a dash is used since candidates are never preferred to themselves. The first matrix, that represents a single ballot, is inversely symmetric: (runner,opponent) is ¬(opponent,runner). Or (runner,opponent) + (opponent,runner) = 1. The sum matrix has this property: (runner,opponent) + (opponent,runner) = N for N voters, if all runners were fully ranked by each voter.
Example: Voting on the location of Tennessee's capital.
Imagine that Tennessee is having an election on the location of its capital. The population of Tennessee is concentrated around its four major cities, which are spread throughout the state. For this example, suppose that the entire electorate lives in these four cities and that everyone wants to live as near to the capital as possible.
The candidates for the capital are:
The preferences of the voters would be divided like this:
To find the Condorcet winner every candidate must be matched against every other candidate in a series of imaginary one-on-one contests. In each pairing the winner is the candidate preferred by a majority of voters. When results for every possible pairing have been found they are as follows:
The results can also be shown in the form of a matrix:
As can be seen from both of the tables above, Nashville beats every other candidate. This means that Nashville is the Condorcet winner. Nashville will thus win an election held under any possible Condorcet method.
While any Condorcet method will elect Nashville as the winner, if instead an election based on the same votes were held using first-past-the-post or instant-runoff voting, these systems would select Memphis and Knoxville respectively. This would occur despite the fact that most people would have preferred Nashville to either of those "winners". Condorcet methods make these preferences obvious rather than ignoring or discarding them.
On the other hand, note that in this example Chattanooga also defeats Knoxville and Memphis when paired against those cities. If we changed the basis for defining preference and determined that Memphis voters preferred Chattanooga as a second choice rather than as a third choice, Chattanooga would be the Condorcet winner even though finishing in last place in a first-past-the-post election.
Circular ambiguities.
As noted above, sometimes an election has no Condorcet winner because there is no candidate who is preferred by voters to all other candidates. When this occurs the situation is known as a 'majority rule cycle', 'circular ambiguity', 'circular tie', 'Condorcet paradox', or simply 'cycle'. This situation emerges when, once all votes have been added up, the preferences of voters with respect to some candidates form a circle in which every candidate is beaten by at least one other candidate. For example, if there are three candidates, Candidate Rock, Candidate Scissors, and Candidate Paper, there will be no Condorcet winner if voters prefer Candidate Rock over Candidate Scissors and Scissors over Paper, but also Candidate Paper over Rock. Depending on the context in which elections are held, circular ambiguities may or may not be a common occurrence. Nonetheless there is always the possibility of an ambiguity, and so every Condorcet method must be capable of determining a winner when this occurs. A mechanism for resolving an ambiguity is known as ambiguity resolution or Condorcet completion method.
Circular ambiguities arise as a result of the voting paradox—the result of an election can be intransitive (forming a cycle) even though all individual voters expressed a transitive preference. In a Condorcet election it is impossible for the preferences of a single voter to be cyclical, because a voter must rank all candidates in order and can only rank each candidate once, but the paradox of voting means that it is still possible for a circular ambiguity to emerge.
The idealized notion of a political spectrum is often used to describe political candidates and policies. Where this kind of spectrum exists, and voters prefer candidates who are closest to their own position on the spectrum, there is a Condorcet winner (Black's Single-Peakedness Theorem).
In Condorcet methods, as in most electoral systems, there is also the possibility of an ordinary tie. This occurs when two or more candidates tie with each other but defeat every other candidate. As in other systems this can be resolved by a random method such as the drawing of lots. Ties can also be settled through other methods like seeing which of the tied winners had the most first choice votes, but this and some other non-random methods may re-introduce a degree of tactical voting, especially if voters know the race will be close.
The method used to resolve circular ambiguities is the main difference between Condorcet methods. There are countless ways in which this can be done, but every Condorcet method involves ignoring the majorities expressed by voters in at least some pairwise matchings.
Condorcet methods fit within two categories:
Many one-method systems and some two-method systems will give the same result as each other if there are fewer than 4 candidates in the circular tie, and all voters separately rank at least two of those candidates. These include Smith-Minimax, Ranked Pairs, and Schulze.
Two-method systems.
One family of Condorcet methods consists of systems that first conduct a series of pairwise comparisons and then, if there is no Condorcet winner, fall back to an entirely different, non-Condorcet method to determine a winner. The simplest such methods involve entirely disregarding the results of pairwise comparisons. For example, the Black method chooses the Condorcet winner if it exists, but uses the Borda count instead if there is an ambiguity (the method is named for Duncan Black).
A more sophisticated two-stage process is, in the event of an ambiguity, to use a separate voting system to find the winner but to restrict this second stage to a certain subset of candidates found by scrutinizing the results of the pairwise comparisons. Sets used for this purpose are defined so that they will always contain only the Condorcet winner if there is one, and will always, in any case, contain at least one candidate. Such sets include the
One possible method is to apply instant-runoff voting to the candidates of the Smith set. This method has been described as 'Smith/IRV'.
Single-method systems.
Some Condorcet methods use a single procedure that inherently meets the Condorcet criteria and, without any extra procedure, also resolves circular ambiguities when they arise. In other words, these methods do not involve separate procedures for different situations. Typically these methods base their calculations on pairwise counts. These methods include:
Ranked Pairs and Schulze are procedurally in some sense opposite approaches (although they very frequently give the same results):
Minimax could be considered as more "blunt" than either of these approaches, as instead of removing defeats it can be seen as immediately removing candidates by looking at the strongest defeats (although their victories are still considered for subsequent candidate eliminations).
Kemeny-Young method.
The Kemeny-Young method considers every possible sequence of choices in terms of which choice might be most popular, which choice might be second-most popular, and so on down to which choice might be least popular. Each such sequence is associated with a Kemeny score that is equal to the sum of the pairwise counts that apply to the specified sequence. The sequence with the highest score is identified as the overall ranking, from most popular to least popular.
When the pairwise counts are arranged in a matrix in which the choices appear in sequence from most popular (top and left) to least popular (bottom and right), the winning Kemeny score equals the sum of the counts in the upper-right, triangular half of the matrix (shown here in bold on a green background).
In this example, the Kemeny Score of the sequence Nashville > Chattanooga > Knoxville > Memphis would be 393.
Calculating every Kemeny score requires considerable computation time in cases that involve more than a few choices. However, fast calculation methods based on integer programming allow a computation time in seconds for some cases with as many as 40 choices.
Ranked Pairs.
The order of finish is constructed a piece at a time by considering the (pairwise) majorities one at a time, from largest majority to smallest majority. For each majority, their higher-ranked candidate is placed ahead of their lower-ranked candidate in the (partially constructed) order of finish, except when their lower-ranked candidate has already been placed ahead of their higher-ranked candidate.
For example, suppose the voters' orders of preference are such that 75% rank B over C, 65% rank A over B, and 60% rank C over A. (The three majorities are a rock-paper-scissors cycle.) Ranked Pairs begins with the largest majority, who rank B over C, and places B ahead of C in the order of finish. Then it considers the second largest majority, who rank A over B, and places A ahead of B in the order of finish. At this point, it has been established that A finishes ahead of B and B finishes ahead of C, which implies A also finishes ahead of C. So when Ranked Pairs considers the third largest majority, who rank C over A, their lower-ranked candidate A has already been placed ahead of their higher-ranked candidate C, so C is not placed ahead of A. The order of finish is "A, B, C" and A is the winner.
An equivalent definition is to find the order of finish that minimizes the size of the largest reversed majority. (In the example, the order of finish "A, B, C" reverses the 60% who rank C over A. Any other order of finish would reverse a larger majority.) This definition is useful for simplifying some of the proofs of Ranked Pairs' properties, but the "constructive" definition executes much faster (in small polynomial time).
Schulze method.
The Schulze method resolves votes as follows:
In other words, this procedure repeatedly throws away the weakest pairwise defeat within the top set, until finally the number of votes left over produce an unambiguous decision.
Defeat strength.
Some pairwise methods—including minimax, Ranked Pairs, and the Schulze method—resolve circular ambiguities based on the relative strength of the defeats. There are different ways to measure the strength of each defeat, and these include considering "winning votes" and "margins":
If voters do not rank their preferences for all of the candidates, these two approaches can yield different results. Consider, for example, the following election:
The pairwise defeats are as follows:
Using the winning votes definition of defeat strength, the defeat of B by C is the weakest, and the defeat of A by B is the strongest. Using the margins definition of defeat strength, the defeat of C by A is the weakest, and the defeat of A by B is the strongest.
Using winning votes as the definition of defeat strength, candidate B would win under minimax, Ranked Pairs and the Schulze method, but, using margins as the definition of defeat strength, candidate C would win in the same methods.
If all voters give complete rankings of the candidates, then winning votes and margins will always produce the same result. The difference between them can only come into play when some voters declare equal preferences amongst candidates, as occurs implicitly if they do not rank all candidates, as in the example above.
The choice between margins and winning votes is the subject of scholarly debate. Because all Condorcet methods always choose the Condorcet winner when one exists, the difference between methods only appears when cyclic ambiguity resolution is required. The argument for using winning votes follows from this: Because cycle resolution involves disenfranchising a selection of votes, then the selection should disenfranchise the fewest possible number of votes. When margins are used, the difference between the number of two candidates' votes may be small, but the number of votes may be very large—or not. Only methods employing winning votes satisfy Woodall's plurality criterion.
An argument in favour of using margins is the fact that the result of a pairwise comparison is decided by the presence of more votes for one side than the other and thus that it follows naturally to assess the strength of a comparison by this "surplus" for the winning side. Otherwise, changing only a few votes from the winner to the loser could cause a sudden large change from a large score for one side to a large score for the other. In other words, one could consider losing votes being in fact disenfranchised when it comes to ambiguity resolution with winning votes. Also, using winning votes, a vote containing ties (possibly implicitly in the case of an incompletely ranked ballot) doesn't have the same effect as a number of equally weighted votes with total weight equaling one vote, such that the ties are broken in every possible way (a violation of ), as opposed to margins.
Under winning votes, if two more of the "B" voters decided to vote "BC", the A->C arm of the cycle would be overturned and Condorcet would pick C instead of B. This is an example of "Unburying" or "Later does harm". The margin method would pick C anyway.
Under the margin method, if three more "BC" voters decided to "bury" C by just voting "B", the A->C arm of the cycle would be strengthened and the resolution strategies would end up breaking the C->B arm and giving the win to B. This is an example of "Burying". The winning votes method would pick B anyway.
Related terms.
Other terms related to the Condorcet method are:
Condorcet ranking methods.
Some Condorcet methods produce not just a single winner, but a ranking of all candidates from first to last place. A Condorcet ranking is a list of candidates with the property that the Condorcet winner (if one exists) comes first and the Condorcet loser (if one exists) comes last, and this holds recursively for the candidates ranked between them.
Methods that satisfy this property include:
Comparison with instant runoff and first-past-the-post (plurality).
Many proponents of instant runoff voting (IRV) are attracted by the belief that if their first choice does not win, their vote will be given to their second choice; if their second choice does not win, their vote will be given to their third choice, etc. This sounds perfect, but it is not true for every voter with IRV. If someone voted for a strong candidate, and their 2nd and 3rd choices are eliminated before their first choice is eliminated, IRV gives their vote to their 4th choice candidate, not their 2nd choice. Condorcet voting takes all rankings into account simultaneously, but at the expense of violating the later-no-harm criterion. With IRV, indicating a second choice will never affect your first choice. With Condorcet voting, it is possible that indicating a second choice will cause your first choice to lose.
Plurality voting is simple, and theoretically provides incentives for voters to compromise for centrist candidates rather than throw away their votes on candidates who can't win. Opponents to plurality voting point out that voters often vote for the lesser of evils because they heard on the news that those two are the only two with a chance of winning, not necessarily because those two are the two natural compromises. This gives the media significant election powers. And if voters do compromise according to the media, the post election counts will prove the media right for next time. Condorcet runs each candidate against the other head to head, so that voters elect the candidate who would win the most sincere runoffs, instead of the one they thought they had to vote for.
There are circumstances, as in the examples above, when both instant-runoff voting and the 'first-past-the-post' plurality system will fail to pick the Condorcet winner. In cases where there is a Condorcet Winner, and where IRV does not choose it, a majority would by definition prefer the Condorcet Winner to the IRV winner. Proponents of the Condorcet criterion see it as a principal issue in selecting an electoral system. They see the Condorcet criterion as a natural extension of majority rule. Condorcet methods tend to encourage the selection of centrist candidates who appeal to the median voter. Here is an example that is designed to support IRV at the expense of Condorcet:
B is preferred by a 501-499 majority to A, and by a 502-498 majority to C. So, according to the Condorcet criterion, B should win, despite the fact that very few voters rank B in first place. By contrast, IRV elects C and plurality elects A. The goal of a ranked voting system is for voters to be able to vote sincerely and trust the system to protect their intent. Plurality voting forces voters to do all their tactics before they vote, so that the system does not need to figure out their intent.
The significance of this scenario, of two parties with strong support, and the one with weak support being the Condorcet winner, may be misleading, though, as it is a common mode in plurality voting systems (see Duverger's law), but much less likely to occur in Condorcet or IRV elections, which unlike Plurality voting, punish candidates who alienate a significant block of voters.
Here is an example that is designed to support Condorcet at the expense of IRV:
B would win against either A or C by more than a 65–35 margin in a one-on-one election, but IRV eliminates B first, leaving a contest between the more "polar" candidates, A and C. Proponents of plurality voting state that their system is simpler than any other and more easily understood.
All three systems are susceptible to tactical voting, but the types of tactics used and the frequency of strategic incentive differ in each method.
Potential for tactical voting.
Like most voting methods, Condorcet methods are vulnerable to compromising. That is, voters can help avoid the election of a less-preferred candidate by insincerely raising the position of a more-preferred candidate on their ballot. However, Condorcet methods are only vulnerable to compromising when there is a majority rule cycle, or when one can be created.
Many Condorcet methods are vulnerable to burying. That is, voters can help a more-preferred candidate by insincerely lowering the position of a less-preferred candidate on their ballot.
Example with the Schulze method:
Supporters of Condorcet methods which exhibit this potential problem could rebut this concern by pointing out that pre-election polls are most necessary with plurality voting, and that voters, armed with ranked choice voting, could lie to pre-election pollsters, making it impossible for Candidate A to know whether or how to bury. It is also nearly impossible to predict ahead of time how many supporters of A would actually follow the instructions, and how many would be alienated by such an obvious attempt to manipulate the system.
Evaluation by criteria.
Scholars of electoral systems often compare them using mathematically defined voting system criteria. The criteria which Condorcet methods satisfy vary from one Condorcet method to another. However, the Condorcet criterion implies the majority criterion; the Condorcet criterion is incompatible with independence of irrelevant alternatives, later-no-harm, the participation criterion, and the consistency criterion.
Use of Condorcet voting.
Condorcet methods are not known to be currently in use in government elections anywhere in the world, but a Condorcet method known as Nanson's method was used in city elections in the U.S. town of Marquette, Michigan in the 1920s, and today Condorcet methods are used by a number of private organizations. Organizations which currently use some variant of the Condorcet method are:

</doc>
<doc id="44447" url="http://en.wikipedia.org/wiki?curid=44447" title="The Forge of God">
The Forge of God

The Forge of God is a 1987 science fiction novel by American writer Greg Bear. Earth faces destruction when an inscrutable and overwhelming alien form of life attacks.
"The Forge of God" was nominated for the Nebula Award for Best Novel in 1987, and was also nominated for the Hugo and Locus Awards in 1988.
Plot.
The novel features scenes and events including the discovery of a near-dead alien in the desert, who clearly says in English, "I'm sorry, but there is bad news," and this alien's subsequent interrogation and autopsy; the discovery of an artificial geological formation and its subsequent nuclear destruction by a desperate military; and the Earth's eventual destruction by the mutual annihilation of a piece of neutronium and a piece of antineutronium dropped into Earth's core.
There is another alien faction at work, however, represented on Earth by small spider-like robots that recruit human agents through some form of mind control. They frantically collect all the human data, biological records, tissue samples, seeds, and DNA from the biosphere that they can, and evacuate a handful of people from Earth. In space, this faction's machines combat and eventually destroy the attackers, though not before Earth's fate is sealed. The evacuees eventually settle a newly terraformed Mars while some form the crew of a Ship of the Law to hunt down the home world of the killers, a quest described in the sequel, "Anvil of Stars".
One of the point of view characters is Arthur Gordon, a scientist who, with his wife Francine and son Martin is among those rescued from the destruction of Earth. Some other characters are close to an American president who fails to take action against the threat.
The two books show at least one solution to the Fermi paradox, with electromagnetically noisy civilisations being snuffed out by the arrival of self-replicating machines designed to destroy any potential threat to their (possibly long-dead) creators. (A similar theme is explored in Fred Saberhagen's "Berserker" novels.)
Cultural reference.
It features a character, Lawrence Van Cott, that is modelled on science fiction author Larry Niven, whose full name is "Laurence van Cott Niven".
Movie.
In the early 2000s, "The Forge of God" and "Anvil of Stars", as well as an as-yet-unwritten third book, were optioned by Warner Bros. to be made into movies. It was reported that Stephen Susco worked on a script for "The Forge Of God". In July 2006 Greg Bear mentioned on his website that the movie is "Still under option. Studio engaged in 'silent running.' "
However, in October 2010, Bear commented on his website that Ken Nolan (who wrote the screen adaptation for Ridley Scott's Black Hawk Down film), was actively working on a screenplay.

</doc>
<doc id="44449" url="http://en.wikipedia.org/wiki?curid=44449" title="Blood Music (novel)">
Blood Music (novel)

Blood Music is a science fiction novel by Greg Bear (ISBN 0-7434-4496-5).
It was originally published as a short story in 1983 in the American science fiction magazine Analog Science Fact & Fiction, winning the 1983 Nebula Award for Best Novelette and the 1984 Hugo Award for Best Novelette.
Greg Bear published an expanded version in novel form in 1985. The completed novel was nominated for the Nebula Award in 1985 and for the Hugo, Campbell, and British Science Fiction Awards in 1986.
"Blood Music" deals with themes including biotechnology, nanotechnology (including the grey goo hypothesis), the nature of reality, consciousness and artificial intelligence.
Plot summary.
In the novel, renegade biotechnologist Vergil Ulam creates simple biological computers based on his own lymphocytes. Faced with orders from his nervous employer to destroy his work, he injects them into his own body, intending to smuggle the 'noocytes' (as he calls them) out of the company and work on them elsewhere. Inside Ulam's body, the noocytes multiply and evolve rapidly, altering their own genetic material and quickly becoming self-aware. The nanoscale civilization they construct soon begins to transform Ulam, then others. The people who are infected start to find that genetic faults such as myopia and high blood pressure get fixed. The bumps along the spine as well as the nipples fade. Finally, white stripes and ridges start growing over their bodies. Ulam reports that the cells seem to sing.
Through infection, conversion and assimilation of humans and other organisms the cells eventually aggregate most of the biosphere of North America into a region seven thousand kilometres wide. This civilization, which incorporates both the evolved noocytes and recently assimilated conventional humans, is eventually forced to abandon the normal plane of existence in favor of one in which thought does not require a physical substrate. The reason for the noocytes' inability to remain in this reality is somewhat related to the strong anthropic principle.
The book's structure is titled "inter-phase", "prophase", "metaphase", "anaphase", "telophase" and "interphase." This mirrors the major phases of cell cycle: interphase and mitosis.
Significance.
This book introduces one of Bear's favorite themes - reality as a function of observers. In "Blood Music", reality becomes unstable as the number of observers—trillions of intelligent single-cell organisms—spirals higher and higher.

</doc>
<doc id="44454" url="http://en.wikipedia.org/wiki?curid=44454" title="Battle of Passchendaele">
Battle of Passchendaele

The Battle of Passchendaele, also referred to as the Third Battle of Ypres, was a campaign of the First World War, fought by the Allies of World War I against the German Empire. The battle took place on the Western Front, from July to November 1917, for control of the ridges south and east of the Belgian city of Ypres in West Flanders, as part of a strategy decided by the Allies at conferences in November 1916 and May 1917. Passchendaele lay on the last ridge east of Ypres, 5 mi from a railway junction at Roulers, which was vital to the supply system of the German 4th Army. The next stage of the Allied strategy was an advance to Thourout–Couckelaere, to close the German-controlled railway running through Roulers and Thourout (which did not take place until 1918). Further operations and a British supporting attack along the Belgian coast from Nieuwpoort, combined with an amphibious landing (Operation Hush), were to have reached Bruges and then the Dutch frontier. The resistance of the German 4th Army, unusually wet weather, the onset of winter and the diversion of British and French resources to Italy, following the Austro-German victory at the Battle of Caporetto (24 October – 19 November), enabled the Germans to avoid a general withdrawal, which had seemed inevitable in early October. The campaign ended in November, when the Canadian Corps captured Passchendaele, apart from local attacks in December and the new year. In 1918, the Battle of the Lys and the Fifth Battle of Ypres were fought before the Allies occupied the Belgian coast and reached the Dutch frontier.
A campaign in Flanders was controversial in 1917 and has remained so. The British Prime Minister Lloyd George opposed the offensive, as did General Foch the French Chief of the General Staff. The British commander Field Marshal Sir Douglas Haig, did not receive approval for the Flanders operation from the War Cabinet until 25 July. Matters of dispute by the participants, writers and historians since the war, have included the wisdom of pursuing an offensive strategy in the wake of the Nivelle Offensive, rather than waiting for the arrival of the American armies in France. The choice of Flanders over areas further south or the Italian front, the climate and weather in Flanders, the choice of General Hubert Gough and the Fifth Army to conduct the offensive, debates over the nature of the opening attack and between advocates of shallow and deeper objectives, have also been controversial. The passage of time between the Battle of Messines and the opening attack of the Battles of Ypres, the extent to which the internal troubles of the French armies motivated British persistence in the offensive, the effect of the weather, the decision to continue the offensive in October and the human cost of the campaign on the soldiers of the German and British armies, have also been argued over ever since.
Background.
Flanders 1914–1917.
The Treaty of London (1839) recognized Belgium as an independent and neutral state. The German invasion of Belgium on 4 August 1914, in violation of Article VII of the treaty, was the reason given by the British government for declaring war. British military operations in Belgium began with the arrival of the British Expeditionary Force (BEF) at Mons on 22 August. On 16 October the Belgians, with some French reinforcements, began the defence of the French channel ports and what remained of unoccupied Belgium at the Battle of the Yser. Operations further south in Flanders commenced, after reciprocal attempts by the French and German armies to turn their opponents' northern flank through Picardy, Artois and Flanders, (Race to the Sea) reached Ypres. On 10 October, Lieutenant-General Erich von Falkenhayn, Chief of the General Staff ordered an attack towards Dunkirk and Calais, followed by a turn south to gain a decisive victory. When the offensive failed, Falkenhayn ordered the capture of Ypres to gain a local advantage. By 12 November, the First Battle of Ypres had failed, at a cost of 160,000 German casualties and was stopped on 18 November.
In December 1914, the Admiralty began discussions with the War Office, for a combined operation to occupy the Belgian coast to the Dutch frontier, by an attack along the coast combined with a landing at Ostend. Eventually the British were obliged to participate in the French offensives further south. Large British offensive operations in Flanders were not possible in 1915, due to the consequent lack of resources. The Germans conducted their own Flanders offensive at the Ypres (22 April – 15 May 1915), making the Ypres salient more costly to defend. Sir Douglas Haig succeeded Sir John French as Commander-in-Chief of the BEF on 19 December 1915. A week after his appointment, Haig met Vice-Admiral Sir Reginald Bacon, who emphasised the importance of obtaining control of the Belgian coast, to end the threat posed by German naval forces. Haig was sceptical of a coast operation, believing that a landing from the sea would be far more difficult than anticipated and that an advance along the coast would require so much preparation that the Germans would have ample warning. Haig preferred an advance from Ypres, to bypass the flooded area around the Yser and the coast, before a coastal attack was attempted, to clear the coast to the Dutch border.
In January 1916, Haig ordered General Plumer to plan offensives against Messines Ridge, Lille and Houthoulst Forest. General Rawlinson was also ordered to plan an attack from the Ypres Salient on 4 February. Planning by Plumer continued but the demands of the Battles of Verdun and the Somme absorbed the offensive capacity of the BEF. On 15 and 29 November 1916, Haig met Général d'Armée Joseph Joffre and the other Allies at Chantilly. An offensive strategy to overwhelm the Central Powers was agreed, with attacks planned on the Western, Eastern and Italian fronts, by the first fortnight in February 1917. A meeting in London of the Admiralty and General Staff urged that the Flanders operation be undertaken in 1917 and Joffre replied on 8 December, agreeing to the proposal for a Flanders campaign after the spring offensive. The plan for a year of steady attrition on the Western Front, with the main effort in the summer being made by the BEF, was scrapped by Nivelle and the French government for a decisive battle, to be conducted in February by the French army, with the British contribution becoming a preliminary operation, the Battles of Arras.
Nivelle planned an operation in three parts, preliminary offensives to pin German reserves by the British at Arras and the French between the Somme and the Oise, a French breakthrough offensive on the Aisne, then pursuit and exploitation. The plan was welcomed by Haig with reservations, which he addressed on 6 January. Nivelle agreed to a proviso that if the first two parts of the operation failed to lead to part three, they would be stopped so that the British could move their main forces north for the Flanders offensive, which Haig argued was of great importance to the British government. Haig wrote on 23 January, that it would take six weeks to move British troops and equipment from the Arras front to Flanders and on 14 March he noted that the attack on Messines Ridge could be made in May. On 21 March, he wrote to Nivelle that it would take two months to prepare the attacks from Messines to Steenstraat but that the Messines attack could be ready in 5–6 weeks. On 16 May, Haig wrote that he had divided the Flanders operation into two phases, one to take Messines Ridge and the main attack several weeks later. British determination to clear the Belgian coast took on more urgency, after the Germans resumed unrestricted submarine warfare on 1 February 1917.
Small operations took place in the Ypres salient in 1916, some being German initiatives to distract the Allies from the preparations for the offensive at Verdun and later to try to divert Allied attention from the Battle of the Somme. Other operations were begun by the British, to regain territory or to evict the Germans from ground overlooking their positions. Engagements took place on 12 February at Boesinge and on 14 February at Hooge and Sanctuary Wood. There were actions on 14–15 February and 1–4 March at The Bluff, 27 March – 16 April at the St Eloi Craters and the Battle of Mont Sorrel 2–13 June. In January 1917, the Second Army (II Anzac, IX, X and VIII corps) held the line in Flanders from Laventie to Boesinghe, with eleven divisions and up to two in reserve. There was much trench mortaring, mining and raiding by both sides and from January to May, the Second Army had 20,000 casualties. In May, reinforcements began moving to Flanders from the south, II Corps and 17 divisions had arrived by the end of the month.
Strategic background.
Several British and French operations took place beyond Flanders during the Third Battle of Ypres, intended to assist Allied operations at Ypres, by obstructing the flow of munitions and reinforcements to the 4th Army in Belgium and to exploit opportunities created by the German need to economise elsewhere. German offensives in Russia and against Italy were postponed several times, as the demand for men and munitions in Flanders left little available for other operations and the French army was able to continue its recuperation after the Nivelle Offensive.
Prelude.
Geography and climate.
The front line around Ypres had changed relatively little since the end of the Second Battle of Ypres (22 April – 25 May 1915). The British held the city, while the Germans held the high ground of the Messines–Wytschaete ridge to the south, the lower ridges to the east and the flat ground to the north. The Ypres front was a salient bulging into German positions, overlooked by German artillery on the higher ground. It was difficult for the British forces to gain ground observation of the German rear areas east of the ridges.
In Flanders, sands, gravels and marls predominate, in places covered by silts. The coastal strip is sand but a short way inland, the ground rises to the vale of Ypres, which before 1914 was a flourishing market garden. Ypres is 20 m above sea level; Bixshoote 4 mi to the north is at 8.5 m. To the east the land is at 20 – for several miles, with the Steenbeek river at 15 m near St Julien. There is a low ridge from Messines, 80 m at its highest point, running north-east past "Clapham Junction" at the west end of Gheluvelt plateau (2 1⁄2 miles from Ypres at 65 m and Gheluvelt (above 50 m) to Passchendaele, (5 1⁄2 miles from Ypres at 50 m) declining from there to a plain further north. Gradients vary from negligible, to 1:60 at Hooge and 1:33 at Zonnebeke.
Underneath the soil is London clay, sand and silt; according to the Commonwealth War Graves Commission categories of "sand", "sandy soils" and "well-balanced soils", Messines ridge is well-balanced soil and the ground around Ypres is sandy soil. The ground is drained by many streams, canals and ditches which need regular maintenance. Since 1914 much of the drainage had been destroyed, although some parts had been restored by Land Drainage Companies brought from England. The area was considered by the British to be drier than Loos, Givenchy and Plugstreet Wood further south. A 1989 study of weather data recorded at Lille, 16 mi from Ypres from 1867–1916, showed that August was more often dry than wet, that there was a trend towards dry autumns (September–November) and that average rainfall in October had decreased over the previous fifty years.
British plans for a Flanders campaign.
Preparations for operations in Flanders began in 1915, with the doubling of the Hazebrouck–Ypres rail line and the building of a new line from Bergues–Proven which was doubled in early 1917. Progress on roads, rail lines, railheads and spurs in the Second Army zone was continuous and by mid-1917, gave the area the most efficient supply system of the BEF. Several plans and memoranda for a Flanders offensive were produced between January 1916 and May 1917, in which the writers tried to relate the offensive resources available to the terrain and the likely German defence. In early 1916, the importance of the capture of the Gheluvelt plateau for an advance further north was emphasised by Haig and the army commanders.
On 14 February 1917, Colonel Macmullen of GHQ proposed that the plateau be taken by a mass tank attack, reducing the need for artillery; in April a reconnaissance by Captain G. le Q Martel found that the area was unsuitable for tanks. On 9 February General Rawlinson, commander of the Fourth Army, suggested that Messines Ridge could be taken in one day and that the capture of the Gheluvelt plateau should be fundamental to the attack further north. He suggested that the southern attack from St. Yves to Mont Sorrel should come first and that Mont Sorrel to Steenstraat should be attacked within 48–72 hours. After discussions with Rawlinson and Plumer and the incorporation of Haig's changes, Macmullen submitted his memorandum on 14 February. With amendments the memorandum became the "GHQ 1917" plan.
On 1 May 1917, Haig wrote that the Nivelle Offensive had weakened the German army but that an attempt at a decisive blow would be premature. An offensive at Ypres would continue the wearing-out process, on a front where the Germans could not refuse to fight. Even a partial success would improve the tactical situation in the Ypres salient, reducing the exceptional "wastage" which occurred even in quiet periods. In early May, Haig set the timetable for the Flanders offensive, with 7 June the date for the preliminary attack on Messines Ridge. A week after the Battle of Messines Ridge, Haig gave his objectives to his Army commanders: wearing out the enemy, securing the Belgian coast and connecting with the Dutch frontier by the capture of Passchendaele ridge, followed by an advance on Roulers and Operation Hush, an attack along the coast with an amphibious landing. If manpower and artillery were insufficient, only the first part of the plan might be fulfilled. On 30 April, Haig told Gough the Fifth Army commander, that he would lead the "Northern Operation" and the coastal force, although Cabinet approval for the offensive was not granted until 21 June.
German defences in Flanders.
The 4th Army held a front of 25 mi with three "Groups", composed of corps headquarters and a varying complement of divisions and Group Staden, based on the headquarters of the Guards Reserve Corps was added later. Group Dixmude held 12 mi with four front divisions and two "Eingreif" divisions, Group Ypres held 6 mi from Pilckem to Menin Road with three front divisions and two "Eingreif" divisions and Group "Wijtschate" held a similar length of front south of the Menin road, with three front divisions and three "Eingreif" divisions. The "Eingreif" divisions were stationed behind the Menin and Passchendaele ridges. About 5 mi further back, were four more "Eingreif" divisions and 7 mi beyond them, another two in Oberste Heeresleitung (OHL) reserve.
German anxiety that the British would exploit their victory at Messines by advancing to the Bassevillebeek (Tower Hamlets) spur, beyond the north end of Messines ridge, led Crown Prince Rupprecht on 9 June, to propose a withdrawal to the "Flandern" line in the area east of Messines. Construction of defences in the area began but on 13 June, Colonel Fritz von Lossberg arrived as the new Chief of Staff of the 4th Army. Lossberg rejected the proposed withdrawal to the "Flandern" line and ordered that the current front line east of the "Sehnen" line (Oosttaverne Line) be held rigidly, as the front of a deepened "Flandern Stellung" (Flanders Position), in front of the "Flandern" line. The existing line was to become "Flandern I", with a new "Flandern II" line to be built west of Menin, northwards to Terhand and Passchendaele, at the back of a new "Flandern II Stellung". Construction of "Flandern III" was begun east of Menin to run north to Moorslede.
On 25 June, Erich Ludendorff the First Quartermaster General, suggested to Rupprecht, that Group Ypres should withdraw to the "Wilhelm" (third) line, leaving only outposts in the "Albrecht" (second) line. On 30 June, the army group Chief of Staff, General von Kuhl suggested a withdrawal to "Flandern I" along Passchendaele ridge, meeting the old front line in the north near Langemarck and close to Armentières in the south. Such a withdrawal would avoid a hasty retreat from Pilckem Ridge and force the British into a time-consuming redeployment. Lossberg disagreed, believing that the British would launch a broad front offensive, that the ground east of the "Sehnen" line was easy to defend, that the Menin road ridge could be held, if it was made the "Schwerpunkt" (point of main effort) of the German defensive effort. Pilckem Ridge deprived the British of ground observation over the Steenbeek Valley, while the Germans could see the area from Passchendaele Ridge, allowing German infantry to be supported by observed artillery fire. Lossberg's judgement was accepted and no withdrawal was made.
Messines Ridge: 7–17 June.
The first stage in the British plan, was a preparatory attack on the German positions south of Ypres at Messines Ridge. The German positions had observation over Ypres and unless captured, would enable observed enfilade artillery-fire against a British attack eastwards from the salient. The British attack began on 7 June, preceded by a unique display of military pyrotechnics. Since mid-1915, the British had been covertly digging mines under the German positions on the ridge. By June 1917, 21 mines had been filled with nearly 1000000 lb of explosives. The Germans knew the British were mining and had taken some counter-measures but they were taken by surprise at the extent of the British effort. Two of the mines failed to detonate but 19 went off on 7 June, at 3:10 a.m. British Summer Time. The final objectives were largely gained before dark and the British, in the morning, had fewer losses than the plan anticipated, of up to 50% in the initial attack. As the infantry advanced over the back edge of the ridge, giving targets to German artillery and machine-guns, British artillery was less able to provide covering fire. Fighting continued on the lower slopes, on the east side of the ridge until 14 June. The offensive removed the Germans from the dominating ground on the southern face of the Ypres salient, which the 4th Army had held since 1914.
Kerensky offensive.
The Russian army launched the Kerensky Offensive to honour the agreement struck with its allies, at the Chantilly meeting of 15–16 November 1916. After a brief period of success from 1–19 July the German strategic reserve of six divisions captured Riga from 1–5 September 1917. In Operation Albion (September–October 1917) the Germans took the islands at the mouth of the Gulf of Riga and the British and French commanders on the Western Front, had to reckon on the German western army being strengthened by reinforcements from the Eastern Front, in late 1917. Haig wished to exploit the diversion of German forces in Russia for as long as it continued and urged that the maximum amount of manpower and munitions be committed to the battle in Flanders.
Battles of the Third Ypres campaign.
First phase, July–August.
Haig selected Gough to command the offensive on 30 April and on 10 June, Gough took over the Ypres salient north of Messines Ridge. Gough planned an offensive based on the "GHQ 1917" plan and the instructions he had received from Haig. On the understanding that Haig wanted a more ambitious version, Gough held meetings with his Corps commanders on 6 and 16 June, where the third objective, which included the German "Wilhelm" (third) line a second-day objective, was added to the two objectives due to be taken on the first day. A fourth objective was also given for the first day but was only to be attempted at the discretion of divisional and corps commanders, in places where the German defence had collapsed. An attack of this nature was not a breakthrough operation, because the German defensive position Flandern I lay 10000 – behind the front line and would not be attacked on the first day. The Fifth Army plan was more ambitious than Plumer's earlier version, which had involved an advance of 1000 –. Major-General J. Davidson, Director of Operations at GHQ, wrote in a memorandum that there was "ambiguity as to what was meant by a step-by-step attack with limited objectives" and suggested reverting to a 1750 yd advance, to increase the concentration of British artillery. Gough stressed the need to plan to exploit an opportunity to take ground left temporarily undefended and that this was more likely in the first attack, which would have the benefit of long preparation. After discussions at the end of June, Haig and Plumer the Second Army commander endorsed the Fifth Army plan.
Battle of Pilckem Ridge.
The British attack began at 3:50 a.m. on 31 July; the attack was to commence at dawn but a layer of unbroken low cloud, meant that it was still dark. The main attack of the offensive, by II Corps across the Ghelveult Plateau to the south, confronted the principal German defensive concentration of artillery, ground-holding and "Eingreif" divisions. The attack had most success on the left (north), in front of XIV Corps and the French First Army. In this section of the front, the Entente forces advanced 2500 –, up to the line of the Steenbeek stream. In the centre of the British attack, XVIII Corps and XIX Corps pushed forward to the line of the Steenbeek to consolidate and sent reserve troops towards the Green and Red lines (on the XIX Corps front), an advance of about 4000 yd. Group Ypres counter-attacked the flanks of the British break-in, supported by all available artillery and aircraft at about midday. The German counter-attack was able to drive the three British brigades back to the black line with 70% losses, where the German counter-attack was stopped by mud, artillery and machine-gun fire.
Capture of Westhoek.
II Corps attacked on 10 August, to capture the rest of the black line on the Gheluvelt plateau. The advance succeeded but German artillery fire and infantry counter-attacks isolated the infantry of the 18th Division, which had captured Glencorse Wood. At about 7:00 p.m., German infantry attacked behind a smokescreen and recaptured all but the north-west corner of the wood, only the 25th Division gains on Westhoek Ridge being held. Albrecht von Thaer, Staff Officer at Group Wytshchate, noted that casualties after 14 days in the line averaged 1,500–2,000 men, compared to the Somme 1916 average of 4,000 men and that German troop morale was higher than in 1916.
Battle of Hill 70.
The Battle of Hill 70, was a subsidiary operation by the Canadian Corps against five divisions of the German 6th Army. The battle took place on the outskirts of Lens, Pas-de-Calais, from 15–25 August. Kuhl wrote later that it was a costly defeat and "wrecked" the plan for relieving divisions which had been "fought-out" in Flanders.
Battle of Langemarck.
The battle was fought from 16–18 August; the Fifth Army headquarters was influenced by the effect that delay would have on Operation Hush, which needed the high tides at the end of August or it would have to be postponed for a month. Gough intended the rest of the green line (just beyond the German "Wilhelm" (third) line, from Polygon Wood to Langemarck) to be taken and the Steenbeek crossed further north. In the II Corps area, the disappointment of 10 August was repeated, with the infantry managing to advance, then being isolated by German artillery and (except in the 25th Division area near Westhoek) forced back to their start line, by German counter-attacks. Attempts by the German infantry to advance further, were stopped by British artillery fire with many losses. The advance further north in the XVIII Corps area, retook and held the north end of St Julien and the area south-east of Langemarck, while XIV Corps captured Langemarck and the "Wilhelm" (third) line, north of the Ypres–Staden railway near the Kortebeek. The French First Army conformed, pushing up to the Kortebeek and St. Jansbeck stream west of the northern stretch of the "Wilhelm" (third) line, where it crossed to the east side of the Kortebeek.
Subsidiary operations.
Most of the smaller British attacks from 19–27 August failed to hold ground, although a XVIII Corps attack on 19 August succeeded. Exploiting observation from higher ground to the east, the Germans were able to inflict many losses on the British divisions holding the new line beyond Langemarck. After two fine dry days from 17–18 August, XIX and XVIII Corps began pushing closer to the "Wilhelm" (third) line. On 20 August, an operation by British tanks, artillery and infantry captured strong points along the St. Julien–Poelcappelle road and two days later, more ground was gained by XVIII and XIX Corps, which still left them overlooked by the Germans, in the un-captured part of the "Wilhelm" (third) line. II Corps resumed operations to capture Nonne Bosschen, Glencorse Wood and Inverness Copse around the Menin Road on 22–24 August, which failed with many losses on both sides.
Gough laid down a new infantry formation of skirmish lines to be followed by "worms" on 24 August. Cavan noted that pill-box defences required broad front attacks, so as to engage them simultaneously. The British general offensive intended for 25 August, was delayed because of the failure of previous attacks to hold ground, following the Battle of Langemarck and then postponed due to more bad weather. Attacks on 27 August, were minor operations which were costly and inconclusive. Haig called a halt to operations amidst tempestuous weather.
Second offensive battle of Verdun.
Petain had committed the French Second Army to an attack at Verdun in mid-July, in support of the operations in Flanders. The Second Offensive Battle of Verdun was delayed, partly due to the mutinies which had affected the French army after the failure of the Nivelle Offensive and also because a German attack at Verdun from 28–29 June, which captured some of the ground intended as a jumping-off point for the French attack. A French counter-attack on 17 July re-captured the ground, the Germans regained it on 1 August, then took ground on the east bank on 16 August. The Second Offensive Battle of Verdun began on 20 August and by 9 September, had taken 10,000 prisoners. Fighting continued sporadically into October, adding to the German difficulties on the Western Front and elsewhere. Ludendorff wrote:
 On the left bank, close to the Meuse, one division had failed ... and yet both here and in Flanders everything possible had been done to avoid failure ... The French army was once more capable of the offensive. It had quickly overcome its depression.
 — Ludendorff: Memoirs
yet there was no German counter-attack, because the local "Eingreif" divisions were in Flanders.
Second phase: September–October.
The German 4th Army had defeated the British advance to all of the objectives of 31 July during August but high casualties and sickness caused by the ground conditions, endless bombardments and air attacks worsened the manpower shortage that the German defensive strategy for 1917 was intended to alleviate. Haig transferred command of the offensive to General Plumer, the Second Army commander on 25 August and moved the northern boundary of the Second Army closer to the Ypres–Roulers railway. More heavy artillery was sent to Flanders from the armies further south and placed opposite the Gheluvelt plateau.
Plumer continued the development of British attacking methods, which had also taken place in the Fifth Army, during the slow and costly progress in August, against the German defence-in-depth and the unusually wet weather. After a pause of about three weeks, Plumer intended to capture Gheluvelt plateau in four steps, with six days between each step, to allow time to bring forward artillery and supplies. Each attack was to have limited geographical objectives like the attacks in August, with infantry brigades re-organised to attack the first objective with one battalion each and the final one with two battalions. Plumer arranged for much more medium and heavy artillery to be added to the creeping bombardment, which had been impossible with the amount of artillery available to Gough. The revised attack organisation was intended to have more infantry attacking on narrower fronts, to a shallower depth than the attack of 31 July. The quicker and shorter advances were intended to be consolidated on tactically advantageous ground (particularly on reverse slopes), with the infantry in contact with their artillery and air support, ready to repulse counter-attacks.
The tempo of the operations was intended to add to German difficulties, in replacing tired divisions through the transport bottlenecks behind the German front. The pause in British operations while Plumer moved more artillery into the area of the Gheluvelt plateau, helped to mislead the Germans. Albrecht von Thaer, Staff Officer at Group "Wijtschate" wrote that it was "almost boring". At first, Kuhl doubted that the offensive had ended but by 13 September, had changed his mind. Despite reservations Kuhl allowed two divisions, thirteen heavy batteries and twelve field batteries of artillery, three fighter squadrons and four other air force units to be transferred from the 4th Army.
German defensive changes.
Instead of setting objectives 1 – distant as on 31 July, the British planned an advance of approximately 1500 yd, without the disadvantages of rain soaked ground and poor visibility, encountered in August. The advances were much quicker and the final objective was reached a few hours after dawn, which confounded the German counter-attack divisions. Having crossed 2 mi of mud, the "Eingreif" divisions found the British already established along a new defence line, with the forward battle zone and its weak garrison gone beyond recapture. After the Battle of Menin Road Ridge, the German defensive system was changed, beginning a search for expedients which lasted for the rest of the battle. In August, German front-line divisions had two regiments of three battalions deployed forward, with the third regiment in reserve. The front battalions had needed to be relieved much more frequently than expected, due to the power of British attacks, constant artillery fire and the weather, which caused replacement units to become mixed up with ones holding the front, rather than operate as formed bodies. Reserve regiments had not been able to intervene early enough, leaving front battalions unsupported until "Eingreif" divisions arrived, some hours after the commencement of the attack.
After another severe defeat on 26 September, the German commanders made more changes to the defensive dispositions of the infantry and altered their counter-attack tactics, which had been negated by Plumer's more conservative form of limited attacks. In July and August, German counter-attack ("Eingreif") divisions had engaged in a manner analogous to an advance to contact during mobile operations, which had given the Germans several costly defensive successes. The counter-attacks in September had been assaults on reinforced field positions, due to the restrained nature of British infantry advances. The fine weather in early September, had greatly eased British supply difficulties, especially in the delivery of huge amounts of artillery ammunition. Immediately after their infantry advances, the British had made time to establish a defence in depth, behind standing barrages. The British attacks took place in dry clear weather, with increased air support over the battlefield, for counter-attack reconnaissance, contact patrols and ground-attack operations. Systematic defensive artillery support was forfeited by the Germans, due to uncertainty over the position of their infantry, just when the British infantry benefitted from the opposite. German counter-attacks were defeated with many casualties and on 28 September, Albrecht von Thaer, staff officer at Group Wytschaete, wrote that the experience was "awful" and that he did not know what to do.
Ludendorff ordered a strengthening of forward garrisons by the ground-holding divisions. All machine-guns, including those of the support and reserve battalions of the front line regiments, were sent into the forward zone, to form a cordon of four to eight guns every 250 yd. The ground holding divisions were reinforced by the "Stoss" regiment of an "Eingreif" division being moved up behind each front division, into the artillery protective line behind the forward battle zone, to launch earlier counter-attacks while the British were consolidating. The bulk of the "Eingreif" divisions were to be held back and used for a methodical counter-stroke on the next day or the one after and for counter-attacks and spoiling attacks between British offensives. Further changes of the 4th Army defensive methods were ordered on 30 September. Operations to increase British infantry losses in line with the instructions of 22 September were to continue. Gas bombardments of forward British infantry and artillery positions, were to be increased whenever the winds allowed. Every effort was to be made to induce the British to reinforce their forward positions, where the German artillery could engage them. Between 26 September and 3 October, the Germans attacked at least 24 times. Operation "Hohensturm", a bigger German methodical counter-attack, intended to recapture the area around Zonnebeke was planned for 4 October.
Battle of the Menin Road Ridge.
The British plan for the battle fought from 20–25 September, included more emphasis on the use of heavy and medium artillery, to destroy German concrete pill-boxes and machine-gun nests, which were more numerous in the battle zones being attacked and to engage in more counter-battery fire. The British had 575 heavy and medium and 720 field guns and howitzers, having more than doubled the quantity of artillery available at the Battle of Pilckem Ridge. Aircraft were to be used for systematic air observation of German troop movements, to avoid the failures of previous battles, where too few aircraft crews, had been burdened with too many duties in bad weather.
On 20 September, the Allies attacked on a 14500 yd front and captured most of their objectives, to a depth of about 1500 yd by mid-morning. The Germans made many counter-attacks, beginning around 3:00 p.m. until early evening, all of which failed to gain ground or made only a temporary penetration of the new British positions. The German defence had failed to stop a well-prepared attack made in good weather. Minor attacks took place after 20 September, as both sides jockeyed for position and reorganised their defences. A mutually-costly attack by the Germans on 25 September, recaptured pillboxes at the south western end of Polygon Wood. Next day, the German positions near the wood were swept away in the Battle of Polygon Wood.
Battle of Polygon Wood.
The Second Army altered its Corps frontages soon after the attack of 20 September, for the next effort (26 September – 3 October) so that each attacking division could be concentrated on a 1000 yd front. Roads and light railways were extended to the new front line, to allow artillery and ammunition to be moved forward. The artillery of VIII Corps and IX Corps in the south, simulated preparations for attacks on Zandvoorde and Warneton. At 5.50 a.m. on 26 September, five layers of barrage fired by British artillery and machine-guns began. Dust and smoke thickened the morning mist and the infantry advanced using compass bearings. Each of the three German ground-holding divisions attacked on 26 September, had an "Eingreif" division in support, twice the ratio of 20 September. No ground captured by the British was lost and German counter-attacks managed only to reach ground to which survivors of the front-line divisions had retired.
Third phase: October–November.
Battle of Broodseinde.
The Battle of Broodseinde (4 October), was the last assault launched by Plumer in good weather. The operation aimed to complete the capture of the Gheluvelt Plateau and occupy Broodseinde Ridge. The Germans sought to recapture their defences around Zonnebeke, with a methodical counter-attack also to begin on 4 October. The British attacked along a 14000 yd front. By coincidence, Australian troops from I Anzac Corps met attacking troops from the German 45th Reserve Division in no man's land, when Operation "Hohensturm" commenced simultaneously. The Germans had reinforced their front line, to delay the British capture of their forward positions, until "Eingreif" divisions could intervene, which put more German troops into the area most vulnerable to British artillery. The British inflicted devastating casualties, on the 4th Army divisions opposite.
German defensive changes.
On 7 October, the 4th Army again dispersed its troops in the front defence zone. Reserve battalions moved back behind the artillery protective line and the "Eingreif" divisions were organised to intervene as swiftly as possible once an attack commenced, despite the risk of being devastated by the British artillery. Counter-battery fire to reduce British artillery fire was to be increased, to protect the "Eingreif" divisions as they advanced. All of the German divisions holding front zones were relieved and an extra division brought forward, as the British advances had lengthened the front line. Without the forces necessary for a counter-offensive, south of the Gheluvelt plateau towards Kemmel Hill, Rupprecht began to plan for a slow withdrawal from the Ypres salient, even at the risk of uncovering German positions further north and the Belgian coast.
Battle of Poelcappelle.
The French First Army and British Second and Fifth armies attacked on 9 October, on a 13500 yd front, from south of Broodseinde to St. Jansbeek, to advance half of the distance from Broodseinde ridge to Passchendaele, on the main front, which led to many casualties on both sides. Advances in the north of the attack front were retained by British and French troops but most of the ground taken in front of Passchendaele and on the Becelaere and Gheluvelt spurs was lost to German counter-attacks. General William Birdwood later wrote that the return of heavy rain and mud sloughs, was the main cause of the failure to hold captured ground. Kuhl concluded that the fighting strained German fighting power to the limit but that the German forces managed to prevent a breakthrough, although it was becoming much harder to replace losses.
First Battle of Passchendaele.
The First Battle of Passchendaele on 12 October, was another Allied attempt to gain ground around Passchendaele. Heavy rain and mud again made movement difficult and little artillery could be brought closer to the front. Allied troops were exhausted and morale had fallen. After a modest British advance, German counter-attacks recovered most of the ground lost opposite Passchendaele. There were 13,000 Allied casualties, including 2,735 New Zealanders, 845 of whom had been killed or lay wounded and stranded, in the mud of no-man's-land. In lives lost in a day, this was the worst day in New Zealand history. At a conference on 13 October, Haig and the army commanders agreed that attacks would stop until the weather improved and roads could be extended, to carry more artillery and ammunition forward for better fire support.
Battle of La Malmaison.
After numerous requests from Haig, Petain began the Battle of La Malmaison, a long-delayed French attack on the Chemin des Dames, by Maistre's Sixth Army. The artillery preparation started on 17 October. The German defenders were swiftly defeated, losing 11,157 prisoners and 180 guns, as the French advanced up to 3.7 mi, capturing the village and fort of La Malmaison, gaining control of the Chemin des Dames ridge. The Germans had to withdraw to the north of the Ailette Valley. Haig was pleased with the French success but regretted the delay, which had lessened its effect on the Flanders operations.
Second Battle of Passchendaele.
The British Fifth Army undertook minor operations from 20–22 October, to maintain pressure on the Germans and support the French attack at La Malmaison, while the Canadian Corps prepared for a series of attacks from 26 October – 10 November). The four divisions of the Canadian Corps had been transferred to the Ypres Salient from Lens, to capture Passchendaele and the ridge. The Canadian Corps relieved II Anzac Corps on 18 October and found that the front line was mostly the same as that occupied by the 1st Canadian Division in April 1915. The Canadian Corps operation was to be executed in a series of three limited attacks, on 26 October, 30 October and 6 November. On 26 October, the 3rd Canadian Division captured its objective at Wolf Copse, then swung back its northern flank to link with the adjacent division of the Fifth Army. The 4th Canadian Division captured its objectives but was forced slowly to retire from Decline Copse against German counter-attacks and communication failures between the Canadian and Australian units to the south.
The second stage began on 30 October, to complete the previous stage and gain a base for the final assault on Passchendaele. The attackers on the southern flank quickly captured Crest Farm and sent patrols beyond the final objective into Passchendaele. The attack on the northern flank again met with exceptional German resistance. The 3rd Canadian Division captured Vapour Farm on the Corps boundary, Furst Farm to the west of Meetcheele and the crossroads at Meetcheele but remained short of its objective. During a seven-day pause, the Second Army took over another section of the Fifth Army front adjoining the Canadian Corps. Three rainless days from 3–5 November, eased preparation for the next stage, which began on the morning of 6 November, with the 1st Canadian Division and the 2nd Canadian Division. In fewer than three hours, many units reached their final objectives and Passchendaele was captured. The Canadian Corps launched a final action on 10 November, to gain control of the remaining high ground north of the village near Hill 52 which ended the campaign, apart from a night attack at Passchendaele on 1/2 December, an attack on the Polderhoek Spur on 2 December and some minor operations in the new year.
Aftermath.
Analysis.
In a German General Staff publication, it was written that "Germany had been brought near to certain destruction ("sicheren Untergang") by the Flanders battle of 1917". In his memoirs (1938) Lloyd George wrote, "Passchendaele was indeed one of the greatest disasters of the war ... No soldier of any intelligence now defends this senseless campaign ...". G. C. Wynne wrote that the British had eventually reached Passchendaele Ridge and captured "Flandern I"; beyond them was "Flandern II" and also "Flandern III", which was nearly complete. The German submarine bases on the coast had not been captured but the objective of diverting the Germans from the French further south, while they recovered from the Nivelle Offensive in April, succeeded.
In 1997, Paddy Griffith wrote that the "bite and hold" system kept moving until November, because the BEF had developed a workable system of offensive tactics, against which the Germans ultimately had no answer. A decade later, Sheldon wrote that relative casualty figures were irrelevant, because the German army could not afford heavy losses or to lose the initiative, by being compelled to fight another defensive battle, on ground of the Allies' choosing. The Third Battle of Ypres pinned the German army to Flanders and caused unsustainable casualties. At a conference on 13 October, a scheme of the Third Army for an attack in mid-November was discussed. Byng wanted the operations at Ypres to continue, to hold German troops in Flanders. The Battle of Cambrai began on 20 November, when the British breached the first two parts of the Hindenburg Line, in the first successful mass use of tanks in a combined arms operation.
The experience of the failure to contain the British attacks at Ypres and the drastic reduction in areas of the western front which could be considered "quiet", after the tank and artillery surprise at Cambrai, left the OHL with little choice but to return to a strategy of decisive victory in 1918. On 24 October, the Austro-German 14th Army, under "General der Infanterie" Otto von Below, attacked the Italian Second Army on the Isonzo, at the Battle of Caporetto and in 18 days, inflicted casualties of 650,000 men and 3,000 guns. In fear that Italy might be put out of the war, the French and British Governments offered reinforcements. British and French troops were swiftly moved from 10 November – 12 December but the diversion of resources from the BEF, forced Haig to conclude the 3rd Battle of Ypres short of Westrozebeke, the last substantial attack being made on 10 November.
Casualties.
Various casualty figures have been published, sometimes with acrimony, although the highest estimates for British and German casualties appear to be discredited. In the Official History, Brigadier-General J. E. Edmonds put British casualties at 244,897 and wrote that equivalent German figures were not available, estimating German losses at 400,000. Edmonds considered that 30% needed to be added to German statistics, to make them comparable with British casualty criteria. In 2007, Sheldon wrote that although German casualties from 1 June – 10 November were 217,194, a figure available in Volume III of the "Sanitätsbericht" (1934), Edmonds may not have included them as they did not fit his case. Sheldon recorded 182,396 slightly wounded and sick soldiers "not struck off unit strength", which if included would make 399,590 German losses. The British claim to have taken 24,065 prisoners has not been disputed.
Commemoration.
The Menin Gate Memorial to the Missing. commemorates those of all Commonwealth nations, except New Zealand, who died in the Ypres Salient and have no known grave. In the case of the United Kingdom only casualties before 16 August 1917 are commemorated on the memorial. United Kingdom and New Zealand servicemen who died after that date are named on the memorial at Tyne Cot Cemetery. There are numerous tributes and memorials all over Australia and New Zealand to ANZAC soldiers who died in the battle, including plaques at the Christchurch and Dunedin railway stations. The Canadian Corps participation in the Second Battle of Passchendaele is commemorated with the Passchendaele Memorial located at the former site of the Crest Farm on the south-west fringe of Passchendaele village. One of the newest monuments to be dedicated to the fighting contribution of a group is the Celtic Cross memorial, commemorating the Scottish contributions and efforts in the fighting in Flanders during the Great War. This memorial is located on the Frezenberg Ridge where the Scottish 9th and 15th Divisions, fought during the Battle of Passchendaele. The monument was dedicated by Linda Fabiani, the Minister for Europe of the Scottish Parliament, during the late summer of 2007, the 90th anniversary of the battle.
References.
</dl>
Further reading.
</dl>

</doc>
<doc id="44457" url="http://en.wikipedia.org/wiki?curid=44457" title="Green Card (film)">
Green Card (film)

Green Card is a 1990 romantic comedy film written, produced, directed by Peter Weir and starring Gérard Depardieu and Andie MacDowell. The screenplay focuses on an American woman who enters into a marriage of convenience with a Frenchman so he can obtain a green card and remain in the United States. Depardieu won the Golden Globe Award for Best Actor. The film won the Golden Globe for Best Motion Picture – Musical or Comedy, and was nominated for an Academy Award for Best Original Screenplay.
Plot summary.
Brontë Parrish (MacDowell), a horticulturalist and an environmentalist, enters into a sham marriage with Georges Fauré (Depardieu), an illegal alien from France, so he may obtain a green card. In turn, Brontë uses her fake marriage credentials to rent the apartment of her dreams. After moving in, to explain her spouse's absence, she tells the doorman and neighbors he is conducting musical research in Africa.
Contacted by the Immigration and Naturalization Service for an interview to determine if her marriage is legitimate, Brontë tracks down Georges, who is working as a waiter. Although the two have little time to get their facts straight, the agents who question them appear to be satisfied with their answers. But when one of the agents asks to use the bathroom and Georges directs him to a closet, their suspicions are aroused, and they schedule a full, formal interview to be conducted two days later at their office.
Advised by her attorney she could face criminal charges if their deception is uncovered, Brontë reluctantly invites Georges to move in with her. They try to learn about each other's past and their quirks and habits but quickly find they can barely tolerate each other. Georges is a fiery-tempered selfish slob and smoker who prefers red meat to vegetarian food, while Brontë is shown as an uptight and cold liberal progressive obsessed with her plants and wrapped up in environmental issues.
Brontë's best friend Lauren Adler's parents plan to leave New York City and may donate their trees and plants to the Green Guerrillas, a group overseeing the development of inner city gardens. Brontë is invited to a dinner party to discuss the issue and discovers Georges is there, having been asked by Lauren. He so impresses the Adlers with an impressionistic piano piece set to a poem about children and trees that they agree to donate their plants to the Green Guerrillas. When Brontë's parents later arrive at the apartment for an unannounced visit, Georges pretends to be the handyman.
When Brontë's boyfriend Phil returns from a trip, Georges reveals he is her husband. Brontë angrily kicks Georges out, but the pair nonetheless appear at the immigration interview the next day. The two are questioned separately, and when Georges is caught out by the interviewer, he confesses the marriage is a sham. He agrees to deportation but insists Brontë not be charged for her role in the charade. He lets Brontë believe the interview was a success and the two go their separate ways.
A few days later, Georges invites Brontë to join him at the cafe where they first met. When she notices one of the immigration agents is seated nearby, she realizes Georges is being deported, and finally aware she loves him, tries to stop him from leaving. Georges promises to write every day asking the same question "When are you coming, Cherie?", a line he had also used when describing their fabricated courtship to the INS. Then, Georges is deported back to France, just as they have admitted their love for each other.
Production.
Peter Weir wrote the script, an original, specifically as a vehicle for Gérard Depardieu to introduce him to a wide English-speaking audience.
Partial funding for the film was provided by the Film Finance Corporation Australia and Union Générale Cinématographique. Although the film was set in America and did not feature Australian actors, the fact it was written, directed, filmed, designed and edited by an Australian enabled it to receive funding from the Australian government. This was $3.8 million from the FFC.
The soundtrack includes "River", "Watermark", and "Storms in Africa" by Enya, "Holdin' On" by Soul II Soul, "Oyin Momo Ado" by Babatunde Olatunji, "Surfin' Safari" by The Beach Boys, and "Subway Drums" by Larry Wright.
Reception.
Critical response.
The film earned mixed reviews from critics, as it currently holds a 56% rating on Rotten Tomatoes based on 18 reviews.
Janet Maslin of "The New York Times" called it "as breezily escapist as a film this facile can be" and added, "Ms. MacDowell ... has a lovely, demure ease that makes George's appreciative gaze quite understandable. Mr. Depardieu, in the role that gets him into a New York Yankees cap, proves that he is nothing if not a sport ... He comes to life most fully when he lapses into French or is otherwise momentarily freed from the story's constraints." Roger Ebert of the "Chicago Sun-Times" observed the film "is not blindingly brilliant, and is not an example of the very best work of the director who made "The Year of Living Dangerously" or the actor who starred in "Cyrano de Bergerac". But it is a sound, entertaining work of craftsmanship, a love story between two people whose meet is not as cute as it might have been."
Peter Travers of "Rolling Stone" called the film a "captivating romantic bonbon" and added, "Don't look for the originality and grit that distinguished Weir's Australian films "Picnic at Hanging Rock" and "Gallipoli", "Green Card" has all the heft of a potato chip. But Depardieu's charm recognizes no language barriers, and MacDowell, the revelation of "Sex, Lies, and Videotape", proves a fine, sexy foil." Rita Kempley of the "Washington Post" said, "Like "Ghost" and "Pretty Woman", this romance is blissfully dependent on our staying good and starry-eyed, seduced by the charisma of the leads. And we do, despite its lackadaisical pace and disappointing ending."
"Variety" said, "Although a thin premise endangers its credibility at times, "Green Card" is a genial, nicely played romance." "Time Out London" stated "Weir's first romantic comedy boasts a central relationship which is tentative and hopeful, a mood beautifully realised by Depardieu (venturing into new territory with a major English-speaking role). Complemented by the refined MacDowell, his gracious, generous performance is never dominating, and their exchanges offer unexpected pleasures. In terms of the genre's conventions, Weir likens this film to 'a light meal.' It's one to savour." Channel 4 said, "Weir's film has its fair share of cute moments as the opposites slowly begin to attract, but this is largely over rated stuff, which proved curiously popular with critics on its release. Depardieu does his obnoxious-yet-strangely-lovable act with ease; however, the romantic comedy fixture MacDowell is less convincing."
Box office.
"Green Card" grossed $10,585,060 at the box office in Australia, which is equivalent to $16,725,817 in 2009 dollars.
Home media release.
Touchstone released the film on VHS around 1991 and Touchstone Home Entertainment released the film on Region 1 DVD on 4 March 2003. It is in anamorphic widescreen format with audio tracks in English and French.
"Green Card" was released on DVD by Umbrella Entertainment in February 2004. The DVD is compatible with all region codes and includes special features such as the original theatrical trailer, Umbrella Entertainment trailers, and interviews with Peter Weir, Gérard Depardieu and Andie MacDowell.

</doc>
<doc id="44458" url="http://en.wikipedia.org/wiki?curid=44458" title="Peter Weir">
Peter Weir

Peter Lindsay Weir, AM (; born 21 August 1944) is an Australian film director. He played a leading role in the Australian New Wave cinema (1970-1990) with his films such as the mystery drama "Picnic at Hanging Rock" (1975), the mystery drama-thriller "The Last Wave" (1977) and the historical drama "Gallipoli" (1981). The climax of Weir's early career was the $6 million multi-national production "The Year of Living Dangerously" (1983), starring Mel Gibson, playing opposite the well-known American actress Sigourney Weaver as the female lead. 
After the success of "The Year of Living Dangerously", Weir directed a diverse group of American and international films—many of them major box office hits—including the Academy Award nominated films such as the thriller "Witness" (1985), the drama "Dead Poets Society" (1989), the romantic comedy "Green Card" (1990), the social science fiction comedy-drama "The Truman Show" (1998) and the epic historical drama film "" (2003), which starred Russell Crowe.
Early life and career.
Weir was born in Sydney, the son of Peggy (née Barnsley) and Lindsay Weir, a real estate agent. Weir attended The Scots College and Vaucluse Boys' High School before studying arts and law at the University of Sydney. His interest in film was sparked by his meeting with fellow students, including Phillip Noyce and the future members of the Sydney filmmaking collective Ubu Films. After leaving university in the mid-1960s he joined Sydney television station ATN-7, where he worked as a production assistant on the groundbreaking satirical comedy program "The Mavis Bramston Show". During this period, using station facilities, he made his first two experimental short films, "Count Vim's Last Exercise" and "The Life and Flight of Reverend Buckshotte".
Weir then took up a position with the Commonwealth Film Unit (later renamed Film Australia), for which he made several documentaries, including a short documentary about an underprivileged outer Sydney suburb, "Whatever Happened to Green Valley", in which residents were invited to make their own film segments. Another notable film in this period was the short rock music performance film "Three Directions In Australian Pop Music" (1972), which featured in-concert colour footage of three of the most significant Melbourne rock acts of the period, Spectrum, The Captain Matchbox Whoopee Band and Wendy Saddington. He also directed one section of the three-part, three-director feature film "Three To Go" (1970), which won an AFI award.
After leaving the CFU, Weir made his first major independent film, the short feature "Homesdale" (1971), an offbeat black comedy which co-starred rising young actress Kate Fitzpatrick and musician and comedian Grahame Bond, who came to fame in 1972 as the star of "The Aunty Jack Show"; Weir also played a small role, but this was to be his last significant screen appearance. "Homesdale" and Weir's two aforementioned CFU shorts have been released on DVD. Weir's first full-length feature film was the underground cult classic, "The Cars That Ate Paris" (1975), a low-budget black comedy about the inhabitants of a small country town who deliberately cause fatal car crashes and live off the proceeds. It was a minor success in cinemas but proved very popular on the then-thriving drive-in circuit.
Weir's major breakthrough in Australia and internationally was the lush, atmospheric period mystery "Picnic at Hanging Rock" (1975), made with substantial backing from the state-funded South Australian Film Corporation and filmed on location in South Australia and rural Victoria. Based on the novel by Joan Lindsay, the film relates the purportedly "true" story of a group of students from an exclusive girls' school who mysteriously vanish from a school picnic on Valentine's Day 1900. Widely credited as a key work in the "Australian film renaissance" of the mid-1970s, "Picnic" was the first Australian film of its era to gain both critical praise and be given substantial international theatrical releases. It also helped launch the career of internationally renowned Australian cinematographer Russell Boyd. It was widely acclaimed by critics, many of whom praised it as a welcome antidote to the so-called "ocker film" genre, typified by "The Adventures of Barry McKenzie" and "Alvin Purple".
Weir's next film, "The Last Wave" (1977) was a supernatural thriller about a man who begins to experience terrifying visions of an impending natural disaster. It starred the American actor Richard Chamberlain, who was well-known to Australian and world audiences as the eponymous physician in the popular "Dr. Kildare" TV series, and would later star in the Australian-set major series "The Thorn Birds". "The Last Wave" was a pensive, ambivalent work that expanded on themes from "Picnic", exploring the interactions between the native Aboriginal and European cultures. It co-starred the aboriginal actor David Gulpilil, whose performance won the Golden Ibex (Oscar equivalent) at the Tehran International Festival in 1977, but it was only a moderate commercial success at the time.
Between "The Last Wave" and his next feature, Weir wrote and directed the offbeat low-budget telemovie "The Plumber" (1979). It starred Australian actors Judy Morris and Ivar Kants and was filmed in just three weeks. Inspired by a real-life experience told to him by friends, it is a black comedy about a woman whose life is disrupted by a subtly menacing plumber. Weir scored a major Australian hit and further international praise with his next film, the historical adventure-drama "Gallipoli" (1981). Scripted by the Australian playwright David Williamson, it is regarded as classic Australian cinema. "Gallipoli" was instrumental in making Mel Gibson ("Mad Max") into a major star, although his co-star Mark Lee, who also received high praise for his role, has made relatively few screen appearances since.
The climax of Weir's early career was the $6 million multi-national production "The Year of Living Dangerously" (1983), again starring Mel Gibson, playing opposite top Hollywood female lead Sigourney Weaver in a story about journalistic loyalty, idealism, love and ambition in the turmoil of Sukarno's Indonesia of 1965. It was an adaptation of the novel by Christopher Koch, which was based in part on the experiences of Koch's journalist brother Philip, the ABC's Jakarta correspondent and one of the few western journalists in the city during the 1965 attempted coup. The film also won Linda Hunt (who played a man in the film) an Oscar for Best Actress in a Supporting Role. The film was produced by Jim McElroy, who with his brother Hal McElroy had also (co-)produced Weir's first three films, "The Cars That Ate Paris", "Picnic at Hanging Rock" and "The Last Wave".
On 14 June 1982, Weir was appointed a Member of the Order of Australia (AM) for his service to the film industry. He resides in Sydney with his wife Wendy Stites. They have been married since 1966.
Filmmaking in the United States.
Weir's first American film was the successful thriller "Witness" (1985), the first of two films he made with Harrison Ford, about a boy who sees the murder of an undercover police officer and has to be hidden away in his Amish community to protect him. Child star Lukas Haas received wide praise for his debut film performance; "Witness" also earned Weir his first Oscar nomination as Best Director, and was his first of several films to be nominated for an Academy Award for Best Picture, it later won 2 for Best Film Editing & Best Original Screenplay.
It was followed by the darker, less commercial "The Mosquito Coast" (1986), Paul Schrader's adaptation of Paul Theroux's novel, with Ford playing a man obsessively pursuing his dream to start a new life in the Central American jungle with his family. These dramatic parts provided Harrison Ford with important opportunities to break the typecasting of his career-making roles in the "Star Wars" and "Indiana Jones" series. Both films showed off his ability to play more subtle and substantial characters and he was nominated for a Best Actor Oscar for his work in "Witness", the only Academy Awards recognition in his career. "The Mosquito Coast" is also notable for an impressive performance by the young River Phoenix.
Weir's next film, "Dead Poets Society", was a major international success, with Weir again receiving credit for expanding the acting range of its Hollywood star. Robin Williams was mainly known for his anarchic stand-up comedy and his popular TV role as the wisecracking alien in "Mork & Mindy"; in this film he played an inspirational teacher in a dramatic story about conformity and rebellion at an exclusive New England prep school in the 1950s. The film was nominated for four Oscars, including Best Picture and Best Director for Weir, it later won for Best Original Screenplay and launched the acting careers of young actors Ethan Hawke and Robert Sean Leonard. It became a major box-office hit and is one of Weir's best-known films for mainstream audiences.
Weir's first romantic comedy "Green Card" (1990) was another casting risk. Weir chose French screen icon Gérard Depardieu in the lead—Depardieu's first English-language role—and paired him with American actress Andie MacDowell. "Green Card" was a box-office hit but was regarded as less of a critical success, although it helped Depardieu's path to international fame, and Weir received an Oscar nomination for his original screenplay.
"Fearless" (1993) returned to darker themes and starred Jeff Bridges as a man who believes he has become invincible after surviving a catastrophic air crash. Though well reviewed, particularly the performances of Bridges and Rosie Perez—who received an Oscar nomination for Best Supporting Actress—the film was less commercially successful than Weir's two preceding films. It was entered into the 44th Berlin International Film Festival.
After five years, Weir returned to direct his biggest success to date, "The Truman Show" (1998), a fantasy-satire of the media's control of life. "The Truman Show" was both a box office and a critical success, receiving positive reviews and numerous awards, including three Academy Award nominations: Andrew Niccol for Best Original Screenplay, Ed Harris for Best Actor in a Supporting Role, and Weir himself for Best Director.
In 2003 Weir returned to period drama with "", starring Russell Crowe. A screen adaptation from various episodes in Patrick O'Brian's blockbuster adventure series set during the Napoleonic Wars, it was well received by critics, but only mildly successful with mainstream audiences. Despite another nomination for Best Picture and —for frequent collaborator Russell Boyd's cinematography and for sound effects editing—the film's box office success was moderate ($93 million at the North American Box Office). The film grossed slightly better overseas, gleaning an additional $114 million.
Weir wrote and directed his next film, "The Way Back" (2010), which, as another historical epic, was well received critically but was not a financial success.

</doc>
<doc id="44459" url="http://en.wikipedia.org/wiki?curid=44459" title="Glenn Close">
Glenn Close

Glenn Close (born March 19, 1947) is an American film, television and stage actress. Throughout her long and varied career, she has been consistently acclaimed for her versatility and is widely regarded as one of the finest actresses of her generation. She has won three Emmy Awards, three Tony Awards and received six Academy Award nominations.
Close began her professional stage career in 1974 in "Love for Love", and was mostly a New York stage actress through the rest of the 1970s and early 1980s, appearing in both plays and musicals, including the Broadway productions of "Barnum" in 1980 and "The Real Thing" in 1983, for which she won the Tony Award for Best Actress in a Play. Her first film role was in "The World According to Garp" (1982), which she followed up with supporting roles in "The Big Chill" (1983), and "The Natural" (1984); all three earned her nominations for the Academy Award for Best Supporting Actress. She would later receive nominations for the Academy Award for Best Actress for her performances in "Fatal Attraction" (1987), "Dangerous Liaisons" (1988), and "Albert Nobbs" (2011). In the 1990s, she won two more Tony Awards, for "Death and the Maiden" in 1992 and "Sunset Boulevard" in 1995, while she won her first Emmy Award for the 1995 TV film "".
Close starred as Eleanor of Aquitaine in the 2003 TV film "The Lion in Winter", winning a Golden Globe Award. In 2005, she starred in the drama series "The Shield". Then from 2007 to 2012, she starred as Patty Hewes in the FX drama series "Damages", a role that won her a Golden Globe and two Emmys. She returned to Broadway in November 2014, in a revival of Edward Albee's "A Delicate Balance". Her other films include "Jagged Edge" (1985), "Hamlet" (1990), "Reversal of Fortune" (1990), "101 Dalmatians" (1996), "Paradise Road" (1997), "Air Force One" (1997), "Cookie's Fortune" (1999), "Nine Lives" (2005) and "Guardians of the Galaxy" (2014).
Close is a six-time Academy Award nominee, tying the record for being the actress with the most nominations never to have won (along with Deborah Kerr and Thelma Ritter). In addition, she has been nominated for four Tonys (three wins), fourteen Emmys (three wins), fourteen Golden Globes (two wins), a Drama Desk Award (which she won) and eight Screen Actors Guild Awards (one win). She has also won an Obie award and has been nominated for three Grammy Awards and a BAFTA.
Early life and family.
Close was born in Greenwich, Connecticut, the daughter of socialite Bettine Moore Close and William Taliaferro Close, a doctor who operated a clinic in the Belgian Congo and served as a personal physician to Congo/Zaire President Mobutu Sese Seko. Her father was a descendant of the Taliaferros of Virginia; her paternal grandfather, Edward Bennett Close, a stockbroker and director of the American Hospital Association, was first married to Post Cereals' Marjorie Merriweather Post. Close is also a second cousin once-removed of actress Brooke Shields (Shields's great-grandmother Mary Elsie Moore was a sister of Close's maternal grandfather, Charles Arthur Moore, Jr.).
During her childhood, Close lived with her parents in a stone cottage on her maternal grandfather's estate, in Greenwich. Close has credited her acting abilities to her early years: "I have no doubt that the days I spent running free in the evocative Connecticut countryside with an unfettered imagination, playing whatever character our games demanded, is one of the reasons that acting has always seemed so natural to me." When she was seven years old, her parents joined a "cult group," the Moral Re-Armament (MRA), in which her family remained involved for fifteen years, living in communal centers. Close has stated that the family "struggled to survive the pressures of a culture that dictated everything about how we lived our lives." She spent time in Switzerland when studying at St. George's School in Switzerland (www.stgeorges.ch). Close traveled for several years in the mid-to-late 1960s with an MRA singing group called Up With People, and attended Rosemary Hall (now Choate Rosemary Hall), graduating in 1965.
When she was 22, Close broke away from MRA, attending the College of William & Mary, and double majoring in theatre and anthropology. It was in the College's theatre department that she began to train as a serious actor, under Howard Scammon, W&M's long-time professor of theatre. During her years at school in Williamsburg she also starred in the summer-time outdoor drama, "The Common Glory," written by Pulitzer Prize author Paul Green. She was elected to membership in the honor society of Phi Beta Kappa. Through the years she has returned to W&M to lecture and visit the theatre department. In 1989 she was the commencement speaker at W&M and received an honorary doctor of arts degree.
Career.
Film and television.
Close started her professional stage career in 1974, and her film work in 1982. She has been nominated for six Academy Awards, for Best Actress in "Dangerous Liaisons", "Fatal Attraction", and "Albert Nobbs" and for Best Supporting Actress in "The Natural", "The Big Chill", and "The World According to Garp" (her first film). Her six nominations have her tied with Deborah Kerr and Thelma Ritter as the most nominated actress not to win an Oscar.
After her sixth Oscar nomination, Close was asked about the fact of not having an Oscar, for which she answered: "And I remember being astounded that I met some people who were really kind of almost hyper-ventilating as to whether they were going to win or not [the Oscar], and I have never understood that. Because if you just do the simple math, the amount of people who are in our two unions, the amount of people who in our profession are out of work at any given time, the amount of movies that are made every year, and then you're one of five. How could you possibly think of yourself as a loser?"
In total she has been nominated fourteen times for an Emmy (winning three) and thirteen times at the Golden Globes (winning two).
In 1984, Close starred in the critically acclaimed drama "Something About Amelia", a Golden Globe-winning television movie about a family destroyed by sexual abuse. In 1987 she played the disturbed book editor Alex in "Fatal Attraction", and in 1988 she played the scheming aristocrat The Marquise de Merteuil in "Dangerous Liaisons". She played the role of Sunny von Bülow in the 1990 film "Reversal of Fortune" to critical acclaim.
Close has hosted Saturday Night Live twice, once in 1989 and once in 1992.
In the 1990s, she starred in the highly rated "Hallmark Hall of Fame" television drama "Sarah, Plain and Tall" (1991), as well as its two sequels. She also played the title role in the made-for-TV movie "Serving in Silence: The Margarethe Cammermeyer Story" in 1995, for which she won her first Emmy. She also appeared in the newsroom comedy-drama "The Paper" (1994), Steven Spielberg's "Hook", the alien invasion satire "Mars Attacks!" (1996, as The First Lady), the Disney hit "101 Dalmatians" (1996, as the sinister Cruella de Vil) and its sequel "102 Dalmatians" (2000), and the blockbuster "Air Force One" (1997), as the trustworthy vice president to Harrison Ford's president. In 2001, she starred in a production of Rodgers and Hammerstein's classic musical "South Pacific".
In 2005, Close joined the FX crime series "The Shield", in which she played a no-nonsense precinct captain. She starred in a series of her own for 2007, "Damages" (also on FX) instead of continuing her character on "The Shield". Close won the 2009 Emmy Award for Outstanding Lead Actress in a Drama series for her role in "Damages". In an interview after her win, Close stated that her role of Patty Hewes in the series was the role of her life. Also in 2009, she narrated the environmental film "Home".
In December 2010, Close began filming "Albert Nobbs" in Dublin. She had previously won an Obie in 1982 for her role in the play on stage. She had been working on the film, in which she appeared alongside 101 Dalmatians co-star Mark Williams, for 10 years, and aside from starring in it, she co-wrote the screenplay and produced the film.
In the film, Close played the title role of "Albert Nobbs", a woman living her life as a man in 1800s Ireland after being sexually assaulted as a young girl. For the film, Close sat through hours of makeup to transform herself into a man. While the film itself received mixed reviews, Close and Janet McTeer received rave reviews for their performances. Close's performance was noted for being her most subtle and introverted performance yet and a departure from her other roles. Close received Academy Award, Golden Globe, Screen Actors Guild, and multiple critics nominations for her performance in "Albert Nobbs".
Recently Close along with Viola Davis and Uma Thurman was featured in the Documentary "Love, Marilyn" reading excerpts from Marilyn Monroe's diaries. Critic Stephen Farber has described the film as "One of the most skillful and entertaining summaries of Marilyn's endlessly fascinating rise and fall." Close played Nova Prime Rael in the science fiction film "Guardians of the Galaxy" (2014). In 2014, Glenn Close received good reviews for her role in the independent drama Low Down. Her next projects are the films "Always on My Mind", with Nick Nolte and Laura Dern, and "The Wife", directed by Swedish director Bjorn Rounge.
Stage.
Close has had an extensive career performing in Broadway musicals. One of her most notable roles on stage was Norma Desmond in the Andrew Lloyd Webber production of "Sunset Boulevard", for which Close won a Tony Award, playing the role on Broadway in 1994. Close was also a guest star at the Andrew Lloyd Webber fiftieth birthday party celebration in the Royal Albert Hall in 1998. She appeared as Norma Desmond and performed songs from "Sunset Boulevard". Close has also won Tony Awards in 1984 for "The Real Thing", and in 1992 for "Death and the Maiden". Close performed at Carnegie Hall, narrating the violin concerto "The Runaway Bunny", a concerto for reader, violin and orchestra, composed and conducted by Glen Roven.
Close provided the voice of the "Giant" in the Summer 2012 production of the musical "Into the Woods" at the Delacorte Theater in Central Park. The production also featured Amy Adams as The Baker's Wife and Donna Murphy as The Witch.
In October 2014, Close returns to Broadway in the starring role of Agnes in Pam MacKinnon's revival of Edward Albee's "A Delicate Balance". She stars opposite John Lithgow as Tobias, Martha Plimpton as Julia and Lindsay Duncan as Claire. The production will play the Golden Theatre.
Personal life and causes.
From 1969 to 1971, Close was married to Cabot Wade, a guitarist and songwriter, with whom she had performed during her time at Up with People. From 1979 to 1983 she dated Broadway actor Len Cariou. She was married to businessman James Marlas from 1984 to 1987. Soon afterward, she began a relationship with producer John Starke, whom she had previously met on the set of "The World According to Garp". In 1988 the two had a daughter together, Annie Starke, who is currently an aspiring actress. They separated in 1991.
In 1995 Close was engaged to carpenter Steve Beers, who had worked on "Sunset Boulevard", but the two never married, and they separated in 1999.
In February 2006, Close married executive and venture capitalist David Evans Shaw in Maine.
Close is a second cousin once removed to actress Brooke Shields.
Through her fourth generation great-grandfather Samuel Addams, Close is a third cousin twice removed of cartoonist Charles Addams (1912-1988).
Close is a dog lover and writes a blog for Fetchdog.com, where she interviews other famous people about their relationships with their dogs. Close announced to the public that she has had her DNA sequenced.
Close has donated money to the election campaigns of many Democratic politicians, including Hillary Rodham Clinton, Howard Dean, John Edwards and Barack Obama.
Close was a founder and is chairperson of BringChange2Mind, a US campaign to eradicate the stigma and discrimination surrounding mental illness, supporting her sister Jessie who has bipolar disorder.
During the month of July 2013, Close put up over 380 designer items up for auction on eBay from the wardrobe her character Patty Hewes wore on "Damages". All proceeds were raised to go to her charity BringChange2Mind.

</doc>
<doc id="44460" url="http://en.wikipedia.org/wiki?curid=44460" title="Interpretation of dreams">
Interpretation of dreams

Interpretation of dreams may refer to:

</doc>
<doc id="44463" url="http://en.wikipedia.org/wiki?curid=44463" title="Sophia Loren">
Sophia Loren

Sophia Loren (]; born Sofia Villani Scicolone ]; 20 September 1934) is an Italian film star. She began her career at age 14 after entering a beauty pageant in 1949. Encouraged to enroll in acting lessons, Loren appeared in several bit parts and minor roles until the late 1950s when Loren's five-picture contract with Paramount launched her international career. Notable film appearances around this time include "Houseboat", "That Kind of Woman" and "It Started in Naples".
It was not until her performance as Cesira in Vittorio De Sica's "Two Women" that her talents as an actress were recognized. Loren's performance earned her the Academy Award for Best Actress in 1962 and made her the first artist to win an Oscar for a foreign-language performance. She holds the record for having earned six David di Donatello Awards for Best Actress, the most ever received: "Two Women"; "Yesterday, Today and Tomorrow"; "Marriage Italian-Style" (for which she was nominated for a second Oscar); "Sunflower"; "The Voyage" and "A Special Day". After starting her family in the early 1970s, Loren spent less time on her acting career and chose to make only occasional film appearances. In later years, she has appeared in American films such as "Grumpier Old Men" and "Nine".
Aside from the Academy Award, she has won a Grammy Award, five special Golden Globes, a BAFTA Award, a Laurel Award as well as the Honorary Academy Award in 1991. In 1995, she received the Cecil B. DeMille Award for lifetime achievements, one of many such awards.
Early life.
Loren was born in the Clinica Regina Margherita in Rome, Italy, daughter of Romilda Villani (1910–1991) and Riccardo Scicolone, a construction engineer of noble descent. (Loren wrote in her autobiography that she is entitled to 
call herself Marchesa di Licata Scicolone Murillo.) Riccardo Scicolone refused to marry Villani, leaving Romilda, a piano teacher and aspiring actress, without support. Loren's parents had another child together, her sister Maria, in 1938. Loren has two younger paternal half-brothers, Giuliano and Giuseppe. Romilda, Sofia and Maria lived with Loren's grandmother in Pozzuoli, near Naples.
During World War II, the harbour and munitions plant in Pozzuoli was a frequent bombing target of the Allies. During one raid, as Loren ran to the shelter, she was struck by shrapnel and wounded in the chin. After that, the family moved to Naples, where they were taken in by distant relatives. After the war, Loren and her family returned to Pozzuoli. Loren's grandmother Luisa opened a pub in their living room, selling homemade cherry liquor. Romilda Villani played the piano, Maria sang and Loren waited on tables and washed dishes. The place was popular with the American GIs stationed nearby. When she was 14, Sofia entered a beauty pageant, Miss Italia 1950 and, while not winning, was selected as one of the finalists. Later, she enrolled in acting class and was selected as an extra in Mervyn LeRoy's film "Quo Vadis" (1951), launching her career as a motion picture actress. 
Career.
1950–57 (beginnings and Hollywood stardom).
After being credited professionally as Sofia Lazzaro, she began using her current stage name in "La Favorita" (1952). The new name was a twist on the name of the Swedish actress Märta Torén and was suggested by Goffredo Lombardo or (according to the 2008 DVD) Carlo Ponti. Her first starring role was in "Aida" (1953), for which she received critical acclaim. After playing the lead role in "Two Nights with Cleopatra" (1953), her breakthrough role was in "The Gold of Naples" (1954), directed by Vittorio De Sica. "Too Bad She's Bad", also released in 1954, became the first of many films in which Loren co-starred with Marcello Mastroianni. Over the next three years, she acted in many films, including "Scandal in Sorrento", "Lucky to Be a Woman", "Boy on a Dolphin", "Legend of the Lost" and "The Pride and the Passion".
International fame.
Loren became an international film star following her five-picture contract with Paramount Pictures in 1958. Among her films at this time were "Desire Under the Elms" with Anthony Perkins, based upon the Eugene O'Neill play; "Houseboat", a romantic comedy co-starring Cary Grant; and George Cukor's "Heller in Pink Tights", in which she appeared as a blonde for the first time.
In 1961, she starred in Vittorio De Sica's "Two Women", a stark, gritty story of a mother who is trying to protect her 12-year-old daughter in war-torn Italy. The two end up gang-raped inside a church as they travel back to their home city following cessation of bombings there. Originally cast as the daughter, Loren fought against type and was re-cast as the mother (actress Eleonora Brown would portray the daughter). Loren's performance earned her many awards, including the Cannes Film Festival's best performance prize, and an Academy Award for Best Actress, the first major Academy Award for a non-English-language performance and to an Italian actress. She won 22 international awards for "Two Women". The film proved to be extremely well accepted by the critics and it was a huge commercial success. 
During the 1960s, Loren was one of the most popular actresses in the world, and she continued to make films in the United States and Europe, starring with prominent leading men. In 1964, her career reached its pinnacle when she received $1 million to appear in "The Fall of the Roman Empire". In 1965, she received a second Academy Award nomination for her performance in "Marriage Italian-Style". 
Among Loren's best-known films of this period are Samuel Bronston's epic production of "El Cid" (1961) with Charlton Heston, "The Millionairess" (1960) with Peter Sellers, "It Started in Naples" (1960) with Clark Gable, Vittorio De Sica's triptych "Yesterday, Today, and Tomorrow" (1963) with Marcello Mastroianni, Peter Ustinov's "Lady L" (1965) with Paul Newman, the 1966 classic "Arabesque" with Gregory Peck, and Charlie Chaplin's final film, "A Countess from Hong Kong" (1967) with Marlon Brando.
Loren received four Golden Globe Awards between 1964 and 1977 as "World Film Favorite – Female".
1970–88.
Loren worked less after becoming a mother. During the next decade, most of her roles were in Italian features. During the 1970s, she was paired with Richard Burton in the last De Sica-directed film, "The Voyage" (1974), and a remake of the film "Brief Encounter" (1974). The film had its premiere on US television on 12 November 1974 as part of the Hallmark Hall of Fame series on NBC. In 1976, she starred in "The Cassandra Crossing". It fared extremely well internationally, and was a respectable box office success in US market. She co-starred with Marcello Mastroianni in Ettore Scola's "A Special Day" (1977). This movie was nominated for eleven international awards such as two Oscars (best actor in leading role, best foreign picture). It won a Golden Globe Award and a César Award for best foreign movie. Loren's performance was awarded with a David di Donatello Award, the seventh in her career. The movie was extremely well received by American reviewers and became a box office hit.
Following this success, Loren starred in an American thriller "Brass Target". This movie received mixed reviews, although it was moderately successful in the United States and internationally. In 1978, she won her fourth Golden Globe for "world film favourite". Other movies of this decade were Academy award nominee "Sunflower" (1970) which was a critical success and Arthur Hiller's "Man of La Mancha" (1972), which was a critical and commercial failure despite being nominated for several awards including two Golden Globes Awards. O'Toole and James Coco were nominated for two NBR awards, in addition the NBR listed "Man of La Mancha" in its best ten pictures of 1972 list.
In 1980, after the international success of the biography "Sophia Loren: Living and Loving, Her Own Story" by A. Hotchner, Loren portrayed herself and her mother in a made-for-television biopic adaptation of her autobiography, "Sophia Loren: Her Own Story". Ritza Brown and Chiara Ferrari each portrayed the younger Loren. In 1981, she became the first female celebrity to launch her own perfume, "Sophia", and a brand of eyewear soon followed.
In 1982, while in Italy, she made headlines after serving an 18-day prison sentence on tax evasion charges—a fact that failed to hamper her popularity or career. In fact, Bill Moore, then employed at Pickle Packers International advertising department, sent her a pink pickle-shaped trophy for being "the prettiest lady in the prettiest pickle". In 2013, the supreme court of Italy cleared her of the charges.
She acted infrequently during the 1980s and turned down the role of Alexis Carrington in 1981 for the television series "Dynasty". Although she was set to star in thirteen episodes of CBS's "Falcon Crest" in 1984 as Angela Channing's half-sister Francesca Gioberti, negotiations fell through at the last moment and the role went to Gina Lollobrigida instead. Sophia preferred devoting more time to raising her sons.
Loren has recorded more than two dozen songs throughout her career, including a best-selling album of comedic songs with Peter Sellers; reportedly, she had to fend off his romantic advances. It was partly owing to Sellers's infatuation with Loren that he split with his first wife, Anne Howe. Loren has made it clear to numerous biographers that Sellers's affections were reciprocated only platonically. This collaboration was covered in "The Life and Death of Peter Sellers" where actress Sonia Aquino portrayed Loren. It is said that the song "Where Do You Go To (My Lovely)?" by Peter Sarstedt was inspired by Loren. 
Later career.
In 1991, Loren received the Academy Honorary Award for her contributions to world cinema and was declared "one of the world cinema's treasures". In 1995, she received the Golden Globe Cecil B. DeMille Award.
She presented Federico Fellini with his Honorary Oscar. In 2009, Loren stated on "Larry King Live" that Fellini had planned to direct her in a film shortly before his death in 1993. Throughout the 1990s and 2000s, Loren was selective about choosing her films and ventured into various areas of business, including cookbooks, eyewear, jewelry and perfume. She received a Golden Globe nomination for her performance in Robert Altman's film "Ready to Wear" (1994), co-starring Julia Roberts.
In 1994, a Golden Palm Star on the Palm Springs, California, Walk of Stars was dedicated to her.
In "Grumpier Old Men" (1995), Loren played a femme fatale opposite Walter Matthau, Jack Lemmon and Ann-Margret. The film was a box-office success and became Loren's biggest US hit in years. At the 20th Moscow International Film Festival in 1997, she was awarded an Honorable Prize for contribution to cinema. In 2001, Loren received a Special Grand Prix of the Americas Award at the Montreal World Film Festival for her body of work. She filmed two projects in Canada during this time: the independent film "Between Strangers" (2002), directed by her son Edoardo and co-starring Mira Sorvino, and the television miniseries "Lives of the Saints" (2004).
In 2009, after five years off the set and fourteen years since she starred in a prominent US theatrical film, Loren starred in Rob Marshall's film version of "Nine", based on the Broadway musical that tells the story of a director whose midlife crisis causes him to struggle to complete his latest film; he is forced to balance the influences of numerous formative women in his life, including his deceased mother. Loren was Marshall's first and only choice for the role. The film also stars Daniel Day-Lewis, Penélope Cruz, Kate Hudson, Marion Cotillard and Nicole Kidman. As a part of the cast she received her first nomination for a Screen Actors Guild Award.
In 2010, Loren played her own mother in a two-part Italian television miniseries about her early life, directed by Vittorio Sindoni, entitled "La Mia Casa È Piena di Specchi" (translated "My House Is Full of Mirrors"), based on the memoir written by her sister Maria. In July 2013, it was reported that Loren was to make her film comeback in an Italian adaptation of Jean Cocteau's 1930 play "The Human Voice" (La Voce Umana) which charts the breakdown of a woman who is left by her lover – with her youngest son, Edoardo Ponti, as director. Filming is to take under a month during July in various locations in Italy including Rome and Naples. It will be Loren's first significant feature film since the 2009 film "Nine", which received mixed critical reviews.
Personal life.
Loren's primary residence has been in Geneva, Switzerland since late 2006. She also owns homes in Naples and Rome.
In September 1999, Loren filed a lawsuit against 76 adult websites for posting altered nude photos of her on the internet.
Loren is a huge fan of the football club S.S.C. Napoli. In May 2007, when the team was third in Serie B, she told the "Gazzetta dello Sport" that she would do a striptease if the team won.
Loren posed scantily clad at 72 for the 2007 Pirelli Calendar, along with such actresses as Penélope Cruz and Hilary Swank.
Loren is a Roman Catholic.
Marriage and family.
Loren first met Carlo Ponti, Sr. in 1950 when she was 15 and he was 37. They married on 17 September 1957. However, Ponti was still officially married to his first wife Giuliana under Italian law because Italy did not recognize divorce at that time. The couple had their marriage annulled in 1962 to escape bigamy charges. In 1965, Ponti obtained a divorce from Giuliana in France, allowing him to marry Loren on 9 April 1966.
The couple became French citizens after their application was approved by then French President Georges Pompidou.
They had two children:
Loren's daughters-in-law are Sasha Alexander and Andrea Meszaros. Loren has four grandchildren.
Loren remained married to Carlo Ponti until his death on 10 January 2007 of pulmonary complications.
When asked in a November 2009 interview if she were ever likely to marry again, Loren replied "No, never again. It would be impossible to love anyone else."
In 1962, Loren's sister, Anna Maria Villani Scicolone, married the youngest son of Benito Mussolini, Romano, with whom she had a daughter, the conservative Italian politician Alessandra Mussolini.
Filmography.
Box office rating.
According to box office polls, Loren was voted among the most popular stars with British audiences.

</doc>
<doc id="44464" url="http://en.wikipedia.org/wiki?curid=44464" title="Imereti">
Imereti

Imereti (Georgian: იმერეთი) is a region in Georgia situated along the middle and upper reaches of the Rioni river. It consists of the following Georgian administrative-territorial units:
tcenters include Samtredia, Chiatura (manganese production centre), Tkibuli (coal mining centre), Zestafoni (known for metals production), Vani, Khoni, and Sachkhere. Traditionally, Imereti is an agricultural region, known for its mulberries and grapes.
The 800,000 Imeretians speak a Georgian dialect; they are one of the local culture-groups of the ethnically subdivided Georgian people.
In late antiquity and early Middle Ages the ancient western Georgian kingdom of Egrisi existed on the territory of Imereti. Its king declared Christianity as an official religion of Egrisi in 523 AD. In 975-1466 Imereti was part of the united Georgian Kingdom. Since its disintegration in the 15th century, Imereti was an independent kingdom.
In the 17th-18th centuries the kingdom of Imereti suffered frequent invasions by the Turks and paid patronage to the Ottoman Empire until 1810, when it was occupied and annexed by the Russian Empire. The last King of Imereti was Solomon II (1789-1810).
From 1918–1921, Imereti was part of the independent Democratic Republic of Georgia. Within the USSR, the region was part of the Transcaucasian SFSR from 1922–1936, and part of the Georgian SSR from 1936–1991. Since Georgian independence in 1991, Imereti has been a region in the Republic of Georgia with Kutaisi as the regional capital.
See also.
tcenters include Samtredia, Chiatura (manganese production centre), Tkibuli (coal mining centre), Zestafoni (known for metals production), Vani, Khoni, and Sachkhere. Traditionally, Imereti is an agricultural region, known for its mulberries and grapes.
The 800,000 Imeretians speak a Georgian dialect; they are one of the local culture-groups of the ethnically subdivided Georgian people.
In late antiquity and early Middle Ages the ancient western Georgian kingdom of Egrisi existed on the territory of Imereti. Its king declared Christianity as an official religion of Egrisi in 523 AD. In 975-1466 Imereti was part of the united Georgian Kingdom. Since its disintegration in the 15th century, Imereti was an independent kingdom.
In the 17th-18th centuries the kingdom of Imereti suffered frequent invasions by the Turks and paid patronage to the Ottoman Empire until 1810, when it was occupied and annexed by the Russian Empire. The last King of Imereti was Solomon II (1789-1810).
From 1918–1921, Imereti was part of the independent Democratic Republic of Georgia. Within the USSR, the region was part of the Transcaucasian SFSR from 1922–1936, and part of the Georgian SSR from 1936–1991. Since Georgian independence in 1991, Imereti has been a region in the Republic of Georgia with Kutaisi as the regional capital

</doc>
<doc id="44468" url="http://en.wikipedia.org/wiki?curid=44468" title="Allen G. Thurman">
Allen G. Thurman

Allen Granberry Thurman (November 13, 1813 – December 12, 1895) was a Democratic Representative, Ohio Supreme Court justice, and Senator from Ohio, as well as the nominee of the Democratic Party for Vice President of the United States in 1888.
Early years.
He was born in Lynchburg, Virginia, to Pleasant Thurman and Mary Granberry Allen Thurman. Both his parents were teachers; his father also a Methodist minister. In 1815, his parents emancipated their slaves and moved to Chillicothe, Ohio. He attended the academy run by his mother, and then studied law as an apprentice to his uncle, William Allen (who later became a Senator from Ohio). At the age of eighteen, Thurman worked on a land survey, and at twenty-one became private secretary to the Governor of Ohio, Robert Lucas. In 1835 he was admitted to the Ohio bar and became his uncle's law partner. In 1837 his uncle entered the Senate. On November 14, 1844, Thurman married Mary Dun Thomplins (or Tompkins), and they were the parents of three children.
Career in government.
Congressman.
The same year he was elected to the House of Representatives as its youngest member. He generally supported the majority of the Democrats on all issues except internal improvements, on which he tended to vote with the Whigs. He supported the Polk Administration's conduct of the Mexican-American War, spoke in favor of the 54°40' northern limit to the Oregon territory, and voted for the Wilmot Proviso, which would have banned slavery from the territory gained from Mexico. Ironically, his support for the latter was due to anti-African-American prejudice, as he wanted to reserve this territory for white settlement. After a single two-year term, he left the House voluntarily to resume private law practice.
State Supreme Court Justice.
In 1851 he was elected to a four-year term (February 1852 – February 1856) on the Ohio Supreme Court, the last year as the chief justice. He then returned to private law practice in Columbus. Thurman spoke out against the repeal of the Missouri Compromise and opposed the pro-slavery Lecompton constitution for Kansas. In 1860 he was a supporter of Stephen A. Douglas for President. He never accepted the right of a state to secede, but he felt it was unwise to fight a state that had already left the Union, so during the American Civil War, he was opposed to Lincoln's policies, especially on emancipation. While he supported the war effort, he encouraged compromise and a political settlement.
Candidate for Governor.
In 1867, he ran for Governor of Ohio, on a platform opposed to extending suffrage to blacks, but lost to Rutherford B. Hayes in a close election.
Senator.
The Ohio voters chose a Democratic state legislature, however, which selected Thurman as Senator for the term beginning in 1869. He there became a strong opponent of the Republicans' Reconstruction measures. In 1873 Thurman crafted a strategy that led to Ohio choosing once more a Democratic legislature, and electing Thurman's uncle William Allen as governor. The legislature elected Thurman to another term in the Senate. During the twelve years he served in the Senate, he became the leader of the Democrats in that body. He was known for constant hard work, good preparation, and courteous treatment of his opponents, and other members ranked him among the top three senators of his time, in terms of ability. He came nearest, a Washington correspondent concluded, to "the beau ideal of a Senator of any man on his side of the House. He has fine passing power of cutting up his political opponents, saying a word of encouragement to some Republican when he is down, and scattering the caucuses of the opposite side with a pistol shot." His prepared speeches were clear and cogent, but it was in debate that he showed himself at his most picturesque. "He would wave his red bandana pocket handkerchief like a guidon, give his nose a trumpet-blast, take a fresh pinch of snuff, and dash into the debate, dealing rough blows, and scattering the carefully prepared arguments of his adversaries like chaff," a Washington long-time reporter remembered. He kept up a close friendship with his chief sparring partner on the opposite side, George F. Edmunds of Vermont. Journalists told how at a given signal - a long blow of his nose—he would get ready to exit the Senate so that the two could meet in the Judiciary Committee room to share a liberal amount of Kentucky Bourbon.
"When I speak of the law," Senator Roscoe Conkling of New York once said, "I turn to the Senator as the Mussulman turns towards Mecca. I look to him only as I would look to the common law of England, the world's most copious volume of human jurisprudence." In particular he made himself the critic of giveaways to the large railroad corporations and of Republicans' Reconstruction policies. "A fine juicy roast of land grants is what sends Thurman's tongue a-wagging," wrote one reporter.
In the 1876–1877 electoral college crisis, he helped to arrive at the solution of creating the Electoral Commission to settle the controversy, and ultimately served as one of the members of the commission, as one of the five Senators (one of the two Senate Democrats, and one of the seven Democrats altogether). As a Democrat, he voted with the seven-member minority, in favor of the Samuel J. Tilden electors in all cases, but the Republican majority prevailed in all the votes, and Thurman's 1867 gubernatorial opponent, Rutherford B. Hayes, became President. (One of the House of Representatives' members of the Commission, fellow Ohioan James Garfield, was to become the President four years later, after being chosen by the now-Republican Ohio legislature to succeed Thurman. Both men were lifelong friends.)
"To look at Thurman one would suppose that his favorite reading was "Foxe's Book of the Martyrs' and "Baxter's Saints' Rest,'" a reporter wrote, "for Thurman's face certainly carries a heavier pressure of solemnity to the square inch than any face I ever saw." In fact, he was a wide reader, fond of Voltaire, Chateaubriand, Renan, and the lighter French novels, and colleagues admitted him the best French scholar in the Senate. He had picked up French from one Monsieur Gregoire, a tutor in his childhood, and in retirement continued reading French novels in the original language.
In the Senate, Thurman served on the Judiciary Committee, becoming its chairman when the Democrats won control of the Senate in the 46th Congress. He also became President pro tempore of the Senate briefly, serving as president of the Senate because of the illness of Vice-President William A. Wheeler, before Ohio chose a Republican legislature, which would not reelect Thurman. They first chose Garfield, but on his election to the Presidency, selected John Sherman to succeed Thurman beginning in 1881. Garfield did appoint Thurman as American representative to the international monetary conference in Paris, a selection that Republican senators welcomed: they regretted his departure from among them. It was noted that in twelve years in the chamber, he had never had an angry word with any colleague, and noted, too, that he left the Senate as poor as he had come to it.
Candidate for Vice President.
Thurman spent his retirement reading French novels in the original language, playing whist, and amusing himself with mathematical problems; he had a reputation as one of the best mathematicians in Ohio. He was put forth as a favorite son candidate in the Democratic presidential nominating conventions in 1880 and 1884. In 1888, he was selected by the incumbent president, Grover Cleveland, as his vice presidential running mate, because Vice President Thomas Hendricks had died in office. Democrats turned his red bandana handkerchief into an emblem of the campaign, tying red bandanas to the top of canes in political parades, and manufacturing bandanas with the candidates' faces on them. Thurman's appeal came from his popularity among old-line Democrats, distrustful of Grover Cleveland's liberalism, and his known hostility to railroad monopolists. All the same, Thurman, who had retired from active politics, could not put on an active campaign, and added little to the ticket's chances. The Cleveland-Thurman ticket won more popular votes than the Harrison-Morton ticket, but it did not carry enough electoral votes.
Thurman died at home in Columbus and is buried at Green Lawn Cemetery.

</doc>
<doc id="44469" url="http://en.wikipedia.org/wiki?curid=44469" title="Pluto">
Pluto

Pluto (minor-planet designation: 134340 Pluto) is the second-most massive known dwarf planet, after Eris. It is the largest object in the Kuiper belt and possibly the largest known trans-Neptunian object. It is the tenth-most-massive known body directly orbiting the Sun. Like other Kuiper belt objects, Pluto is primarily made of rock and ice, and is relatively small, about 1⁄6 the mass of the Moon and 1⁄3 its volume. It has an eccentric and highly inclined orbit that takes it from 30 to 49 AU (4.4–7.4 billion km) from the Sun. Hence Pluto periodically comes closer to the Sun than Neptune, but an orbital resonance with Neptune prevents the bodies from colliding. In 2014 it was 32.6 AU from the Sun. Light from the Sun takes about 5.5 hours to reach Pluto at its average distance (39.4 AU).
Discovered in 1930, Pluto was originally considered the ninth planet from the Sun. Its status as a major planet fell into question following further study of it and the outer Solar System over the next 75 years. Starting in 1977 with the discovery of the minor planet Chiron, numerous icy objects similar to Pluto with eccentric orbits were found. The scattered disc object Eris, discovered in 2005, is 27% more massive than Pluto. The understanding that Pluto is only one of several large icy bodies in the outer Solar System prompted the International Astronomical Union (IAU) to formally define "planet" in 2006. This definition excluded Pluto and reclassified it as a member of the new "dwarf planet" category (and specifically as a plutoid). Astronomers who oppose this decision hold that Pluto should have remained classified as a planet, and that other dwarf planets and even moons should be added to the list of planets along with Pluto.
Pluto has five known moons: Charon (the largest, with a diameter just over half that of Pluto), Nix, Hydra, Kerberos, and Styx. Pluto and Charon are sometimes described as a binary system because the barycenter of their orbits does not lie within either body. The IAU has yet to formalise a definition for binary dwarf planets, and Charon is officially classified as a moon of Pluto.
On 14 July 2015, the Pluto system is due to be visited by spacecraft for the first time. The "New Horizons" probe will perform a flyby during which it will attempt to take detailed measurements and images of Pluto and its moons. Afterwards, the probe may visit several other objects in the Kuiper belt.
Discovery.
In the 1840s, using Newtonian mechanics, Urbain Le Verrier predicted the position of the then-undiscovered planet Neptune after analysing perturbations in the orbit of Uranus. Subsequent observations of Neptune in the late 19th century caused astronomers to speculate that Uranus's orbit was being disturbed by another planet besides Neptune.
In 1906, Percival Lowell—a wealthy Bostonian who had founded the Lowell Observatory in Flagstaff, Arizona, in 1894—started an extensive project in search of a possible ninth planet, which he termed "Planet X". By 1909, Lowell and William H. Pickering had suggested several possible celestial coordinates for such a planet. Lowell and his observatory conducted his search until his death in 1916, but to no avail. Unknown to Lowell, on 19 March 1915, surveys had captured two faint images of Pluto, but they were not recognized for what they were. There are fifteen other known prediscoveries, with the oldest made by the Yerkes Observatory on 20 August 1909.
Because of a ten-year legal battle with Constance Lowell, Percival's widow, who attempted to wrest the observatory's million-dollar portion of his legacy for herself, the search for Planet X did not resume until 1929, when its director, Vesto Melvin Slipher, summarily handed the job of locating Planet X to Clyde Tombaugh, a 23-year-old Kansan who had just arrived at the Lowell Observatory after Slipher had been impressed by a sample of his astronomical drawings.
Tombaugh's task was to systematically image the night sky in pairs of photographs, then examine each pair and determine whether any objects had shifted position. Using a machine called a blink comparator, he rapidly shifted back and forth between views of each of the plates to create the illusion of movement of any objects that had changed position or appearance between photographs. On 18 February 1930, after nearly a year of searching, Tombaugh discovered a possible moving object on photographic plates taken on 23 and 29 January of that year. A lesser-quality photograph taken on 21 January helped confirm the movement. After the observatory obtained further confirmatory photographs, news of the discovery was telegraphed to the Harvard College Observatory on 13 March 1930.
Name.
The discovery made headlines across the globe. The Lowell Observatory, which had the right to name the new object, received over 1,000 suggestions from all over the world, ranging from Atlas to Zymal. Tombaugh urged Slipher to suggest a name for the new object quickly before someone else did. Constance Lowell proposed "Zeus", then "Percival" and finally "Constance". These suggestions were disregarded.
The name Pluto, after the god of the underworld, was proposed by Venetia Burney (1918–2009), an eleven-year-old schoolgirl in Oxford, England, who was interested in classical mythology. She suggested it in a conversation with her grandfather Falconer Madan, a former librarian at the University of Oxford's Bodleian Library, who passed the name to astronomy professor Herbert Hall Turner, who cabled it to colleagues in the United States.
The object was officially named on 24 March 1930. Each member of the Lowell Observatory was allowed to vote on a short-list of three: Minerva (which was already the name for an asteroid), Cronus (which had lost reputation through being proposed by the unpopular astronomer Thomas Jefferson Jackson See), and Pluto. Pluto received every vote. The name was announced on 1 May 1930. Upon the announcement, Madan gave Venetia (£ as of 2015), as a reward.
The choice of name was partly inspired by the fact that the first two letters of "Pluto" are the initials of Percival Lowell, and Pluto's astronomical symbol (, unicode U+2647, ♇) is a monogram constructed from the letters 'PL'. Pluto's astrological symbol resembles that of Neptune (), but has a circle in place of the middle prong of the trident ().
The name was soon embraced by wider culture. In 1930, Walt Disney was apparently inspired by it when he introduced for Mickey Mouse a canine companion named Pluto, although Disney animator Ben Sharpsteen could not confirm why the name was given. In 1941, Glenn T. Seaborg named the newly created element plutonium after Pluto, in keeping with the tradition of naming elements after newly discovered planets, following uranium, which was named after Uranus, and neptunium, which was named after Neptune.
Most languages use the name "Pluto" in various transliterations. In Japanese, Houei Nojiri suggested the translation Meiōsei (冥王星, "Star of the King (God) of the Underworld")
, and this was borrowed into Chinese, Korean, and Vietnamese. Some Indian languages use the name Pluto, but others, such as Hindi, use the name of "Yama", the Guardian of Hell in Hindu and Buddhist mythology, as does Vietnamese. Polynesian languages also tend to use the indigenous god of the underworld, as in Maori "Whiro".
Demise of Planet X.
Once found, Pluto's faintness and lack of a resolvable disc cast doubt on the idea that it was Lowell's Planet X. Estimates of Pluto's mass were revised downward throughout the 20th century.
Astronomers initially calculated its mass based on its presumed effect on Neptune and Uranus. In 1931 Pluto was calculated to be roughly the mass of Earth, with further calculations in 1948 bringing the mass down to roughly that of Mars. In 1976, Dale Cruikshank, Carl Pilcher and David Morrison of the University of Hawaii calculated Pluto's albedo for the first time, finding that it matched that for methane ice; this meant Pluto had to be exceptionally luminous for its size and therefore could not be more than 1 percent the mass of Earth. (Pluto's albedo is 1.3–2.0 times greater than that of Earth.)
In 1978, the discovery of Pluto's moon Charon allowed the measurement of Pluto's mass for the first time. Its mass, roughly 0.2% that of Earth, was far too small to account for the discrepancies in the orbit of Uranus. Subsequent searches for an alternative Planet X, notably by Robert Sutton Harrington, failed. In 1992, Myles Standish used data from "Voyager 2"'s 1989 flyby of Neptune, which had revised the planet's total mass downward by 0.5%, to recalculate its gravitational effect on Uranus. With the new figures added in, the discrepancies, and with them the need for a Planet X, vanished. Today, the majority of scientists agree that Planet X, as Lowell defined it, does not exist. Lowell had made a prediction of Planet X's position in 1915 that was fairly close to Pluto's position at that time; Ernest W. Brown concluded soon after Pluto's discovery that this was a coincidence, a view still held today.
Orbit and rotation.
Pluto's orbital period is 248 Earth years. Its orbital characteristics are substantially different from those of the planets, which follow nearly circular orbits around the Sun close to a flat reference plane called the ecliptic. In contrast, Pluto's orbit is highly inclined relative to the ecliptic (over 17°) and highly eccentric (elliptical). This high eccentricity means a small region of Pluto's orbit lies nearer the Sun than Neptune's. The Pluto–Charon barycenter came to perihelion on 5 September 1989, and was last closer to the Sun than Neptune between 7 February 1979, and 11 February 1999.
In the long term, Pluto's orbit is in fact chaotic. Although computer simulations can be used to predict its position for several million years (both forward and backward in time), after intervals longer than the Lyapunov time of 10–20 million years, calculations become speculative: Pluto is sensitive to unmeasurably small details of the Solar System, hard-to-predict factors that will gradually disrupt its orbit.
Relationship with Neptune.
Despite Pluto's orbit appearing to cross that of Neptune when viewed from directly above, the two objects' orbits are aligned so that they can never collide or even approach closely. There are several reasons why.
At the simplest level, one can examine the two orbits and see that they do not intersect. When Pluto is closest to the Sun, and hence closest to Neptune's orbit as viewed from above, it is also the farthest above Neptune's path. Pluto's orbit passes about 8 AU above that of Neptune, preventing a collision. Pluto's ascending and descending nodes, the points at which its orbit crosses the ecliptic, are currently separated from Neptune's by over 21°.
This alone is not enough to protect Pluto; perturbations from the planets (especially Neptune) could alter aspects of Pluto's orbit (such as its orbital precession) over millions of years so that a collision could be possible. Some other mechanism or mechanisms must therefore be at work. The most significant of these is that Pluto lies in the 2:3 mean-motion resonance with Neptune: for every two orbits that Pluto makes around the Sun, Neptune makes three. The two objects then return to their initial positions and the cycle repeats, each cycle lasting about 500 years. This pattern is such that, in each 500-year cycle, the first time Pluto is near perihelion Neptune is over 50° "behind" Pluto. By Pluto's second perihelion, Neptune will have completed a further one and a half of its own orbits, and so will be a similar distance "ahead" of Pluto. Pluto and Neptune's minimum separation is over 17 AU. Pluto comes closer to Uranus (11 AU) than it does to Neptune.
The 2:3 resonance between the two bodies is highly stable, and is preserved over millions of years. This prevents their orbits from changing relative to one another; the cycle always repeats in the same way, and so the two bodies can never pass near to each other. Thus, even if Pluto's orbit were not highly inclined the two bodies could never collide.
Other factors.
Numerical studies have shown that over periods of millions of years, the general nature of the alignment between Pluto and Neptune's orbits does not change. There are several other resonances and interactions that govern the details of their relative motion, and enhance Pluto's stability. These arise principally from two additional mechanisms (besides the 2:3 mean-motion resonance).
First, Pluto's argument of perihelion, the angle between the point where it crosses the ecliptic and the point where it is closest to the Sun, librates around 90°. This means that when Pluto is nearest the Sun, it is at its farthest above the plane of the Solar System, preventing encounters with Neptune. This is a direct consequence of the Kozai mechanism, which relates the eccentricity of an orbit to its inclination to a larger perturbing body—in this case Neptune. Relative to Neptune, the amplitude of libration is 38°, and so the angular separation of Pluto's perihelion to the orbit of Neptune is always greater than 52° (90°–38°). The closest such angular separation occurs every 10,000 years.
Second, the longitudes of ascending nodes of the two bodies—the points where they cross the ecliptic—are in near-resonance with the above libration. When the two longitudes are the same—that is, when one could draw a straight line through both nodes and the Sun—Pluto's perihelion lies exactly at 90°, and hence it comes closest to the Sun at its maximally above Neptune's orbit. This is known as the "1:1 superresonance". All the Jovian planets, particularly Jupiter, play a role in the creation of the superresonance.
To understand the nature of the libration, imagine a polar point of view, looking down on the ecliptic from a distant vantage point where the planets orbit counterclockwise. After passing the ascending node, Pluto is interior to Neptune's orbit and moving faster, approaching Neptune from behind. The strong gravitational pull between the two causes angular momentum to be transferred to Pluto, at Neptune's expense. This moves Pluto into a slightly larger orbit, where it travels slightly slower, according to Kepler's third law. As its orbit changes, this has the gradual effect of changing the perihelion and longitude of Pluto's orbit (and, to a lesser degree, of Neptune). After many such repetitions, Pluto is sufficiently slowed, and Neptune sufficiently speeded up, that Neptune begins to catch up with Pluto at the opposite side of its orbit (near the opposing node to where we began). The process is then reversed, and Pluto loses angular momentum to Neptune, until Pluto is sufficiently speeded up that it begins to catch Neptune again at the original node. The whole process takes about 20,000 years to complete.
Rotation.
Pluto's rotation period, its day, is equal to 6.39 Earth days. Like Uranus, Pluto rotates on its "side" on its orbital plane, with an axial tilt of 120°, and so its seasonal variation is extreme; at its solstices, one-fourth of its surface is in continuous daylight, whereas another fourth is in continuous darkness.
Physical characteristics.
Pluto's distance from Earth makes in-depth investigation difficult. Many details about Pluto will remain unknown until 14 July 2015 and onwards, when the New Horizons spacecraft will fly through the Pluto system, sending data back to Earth for analysis.
Appearance and surface.
Pluto's visual apparent magnitude averages 15.1, brightening to 13.65 at perihelion. To see it, a telescope is required; around 30 cm (12 in) aperture being desirable. It looks star-like and without a visible disk even in large telescopes, because its angular diameter is only 0.11".
The earliest maps of Pluto, made in the late 1980s, were brightness maps created from close observations of eclipses by its largest moon, Charon. Observations were made of the change in the total average brightness of the Pluto–Charon system during the eclipses. For example, eclipsing a bright spot on Pluto makes a bigger total brightness change than eclipsing a dark spot. Computer processing of many such observations can be used to create a brightness map. This method can also track changes in brightness over time.
Current maps have been produced from images from the Hubble Space Telescope (HST), which offers the highest resolution currently available, and show considerably more detail, resolving variations several hundred kilometres across, including polar regions and large bright spots. The maps are produced by complex computer processing, which find the best-fit projected maps for the few pixels of the Hubble images. The two cameras on the HST used for these maps are no longer in service, so these will likely remain the most detailed maps of Pluto until the 2015 flyby of New Horizons.
These maps, together with Pluto's lightcurve and the periodic variations in its infrared spectra, reveal that Pluto's surface is remarkably varied, with large changes in both brightness and color. Pluto is one of the most contrastive bodies in the Solar System, with as much contrast as Saturn's moon Iapetus. The color varies between charcoal black, dark orange and white: Buie et al. term it "significantly less red than Mars and much more similar to the hues seen on Io with a slightly more orange cast".
Pluto's surface has changed between 1994 and 2002–3: the northern polar region has brightened and the southern hemisphere darkened. Pluto's overall redness has also increased substantially between 2000 and 2002. These rapid changes are probably related to seasonal condensation and sublimation of portions of Pluto's atmosphere, amplified by Pluto's extreme axial tilt and high orbital eccentricity.
Spectroscopic analysis of Pluto's surface reveals it to be composed of more than 98 percent nitrogen ice, with traces of methane and carbon monoxide. The face of Pluto oriented toward Charon contains more methane ice, whereas the opposite face contains more nitrogen and carbon monoxide ice.
Surface feature nomenclature.
In anticipation of the forthcoming mapping of Pluto's surface by New Horizons, the International Astronomical Union has decided that its surface features will be given names deriving from the following themes: historic explorers, space missions, spacecraft, scientists and engineers; fictional explorers, travellers, vessels, destinations and origins; authors and artists who have envisioned exploration; and underworlds, underworld beings, and travellers to the underworld. In collaboration with the New Horizons science team, the IAU has invited members of the public to propose names and vote on them before the spacecraft's arrival.
Internal structure.
Observations by the Hubble Space Telescope place Pluto's density at between 1.8 and 2.1 g/cm3, suggesting its internal composition consists of roughly 50–70 percent rock and 30–50 percent ice by mass. Because the decay of radioactive elements would eventually heat the ices enough for the rock to separate from them, scientists expect that Pluto's internal structure is differentiated, with the rocky material having settled into a dense core surrounded by a mantle of ice. The diameter of the core is hypothesized to be approximately , 70% of Pluto's diameter. It is possible that such heating continues today, creating a subsurface ocean layer of liquid water some 100 to 180 km thick at the core–mantle boundary. The DLR "Institute of Planetary Research" calculated that Pluto's density-to-radius ratio lies in a transition zone, along with Neptune's moon Triton, between icy satellites like the mid-sized moons of Uranus and Saturn, and rocky satellites such as Jupiter's Io.
Mass and size.
Pluto's mass is 1.31×1022 kg, less than 0.24 percent that of Earth, and its diameter is , or roughly 66% that of the Moon. Its surface area () is about 10% smaller than that of South America. Pluto's atmosphere complicates determining its true solid size within a certain margin. Pluto's albedo varies from 0.49–0.66.
The discovery of Pluto's satellite Charon in 1978 enabled a determination of the mass of the Pluto–Charon system by application of Newton's formulation of Kepler's third law. Once Charon's gravitational effect was measured, Pluto's true mass could be determined. Observations of Pluto in occultation with Charon allowed scientists to establish Pluto's diameter more accurately, whereas the invention of adaptive optics allowed them to determine its shape more accurately.
Among the objects of the Solar System, Pluto is much less massive than the terrestrial planets, and at less than 0.2 lunar masses, it is also less massive than seven moons: Ganymede, Titan, Callisto, Io, the Moon, Europa and Triton.
Pluto is more than twice the diameter and a dozen times the mass of the dwarf planet Ceres, the largest object in the asteroid belt. It is less massive than the dwarf planet Eris, a trans-Neptunian object discovered in 2005. Given the error bars in the different size estimates, it is currently unknown whether Eris or Pluto has the larger diameter. Both Pluto and Eris are estimated to have solid-body diameters of about 2330 km.
Determinations of Pluto's size are complicated by its atmosphere, and possible hydrocarbon haze. In March 2014, Lellouch, de Bergh et al. published findings regarding methane mixing ratios in Pluto's atmosphere consistent with a Plutonian diameter greater than 2360 km, with a "best guess" of 2368 km, which would make it slightly larger than Eris.
Atmosphere.
Pluto's atmosphere consists of a thin envelope of nitrogen (N2), methane (CH4), and carbon monoxide (CO) gases, which are derived from the ices of these substances on its surface. Its surface pressure ranges from 6.5 to 24 μbar (0.65 to 2.4 Pa). Pluto's elongated orbit is predicted to have a major effect on its atmosphere: as Pluto moves away from the Sun, its atmosphere should gradually freeze out, and fall to the ground. When Pluto is closer to the Sun, the temperature of Pluto's solid surface increases, causing the ices to sublimate into gas. This creates an anti-greenhouse effect; much as sweat cools the body as it evaporates from the surface of the skin, this sublimation cools the surface of Pluto. In 2006, scientists using the Submillimeter Array discovered that Pluto's temperature is about 43 K, 10 K colder than would otherwise be expected.
The presence of methane (CH4), a powerful greenhouse gas, in Pluto's atmosphere creates a temperature inversion, with average temperatures 36 K warmer 10 km above the surface. The lower atmosphere contains a higher concentration of methane than its upper atmosphere.
Evidence of Pluto's atmosphere was first suggested by Noah Brosch and Haim Mendelson of the Wise Observatory in Israel in 1985, and then definitively detected by the Kuiper Airborne Observatory in 1988, from observations of occultations of stars by Pluto. When an object with no atmosphere moves in front of a star, the star abruptly disappears; in the case of Pluto, the star dimmed out gradually. From the rate of dimming, the atmospheric pressure was determined to be 0.15 Pa, roughly 1/700,000 that of Earth.
In 2002, another occultation of a star by Pluto was observed and analysed by teams led by Bruno Sicardy of the Paris Observatory, James L. Elliot of MIT, and Jay Pasachoff of Williams College. Surprisingly, the atmospheric pressure was estimated to be 0.3 pascal, even though Pluto was farther from the Sun than in 1988 and thus should have been colder and had a more rarefied atmosphere. One explanation for the discrepancy is that in 1987 the north (or positive) pole of Pluto came out of shadow for the first time in 120 years, causing extra nitrogen to sublimate from the polar cap. It will take decades for the excess nitrogen to condense out of the atmosphere as it freezes onto the south (or negative) pole's now continuously dark ice cap. Spikes in the data from the same study revealed what may be the first evidence of wind in Pluto's atmosphere. Another stellar occultation was observed by the MIT-Williams College team of James L. Elliot, Jay Pasachoff, and a Southwest Research Institute team led by Leslie A. Young on 12 June 2006, from sites in Australia.
In October 2006, Dale Cruikshank of NASA/Ames Research Center (a "New Horizons" co-investigator) and his colleagues announced the spectroscopic discovery of ethane (C2H6) on Pluto's surface. This ethane is produced from the photolysis or radiolysis (i.e. the chemical conversion driven by sunlight and charged particles) of frozen methane on Pluto's surface and suspended in its atmosphere.
Satellites.
Pluto has five known natural satellites: Charon, first identified in 1978 by astronomer James Christy; Nix and Hydra, both discovered in 2005, Kerberos, discovered in 2011, and Styx, discovered in 2012.
The Plutonian moons are unusually close to Pluto, compared to other observed systems. Moons could potentially orbit Pluto at up to 53% (or 69%, if retrograde) of the Hill radius, the stable gravitational zone of Pluto's influence. For example, Psamathe orbits Neptune at 40% of the Hill radius. In the case of Pluto, only the inner 3% of the zone is known to be occupied by satellites. In the discoverers' terms, the Plutonian system appears to be "highly compact and largely empty", although others have pointed out the possibility of additional objects, including a small ring system.
Charon.
The Pluto–Charon system is noteworthy for being one of the Solar System's few binary systems, defined as those whose barycenter lies above the primary's surface (617 Patroclus is a smaller example, the Sun and Jupiter the only larger one). This and the large size of Charon relative to Pluto have led some astronomers to call it a dwarf double planet. The system is also unusual among planetary systems in that each is tidally locked to the other: Charon always presents the same face to Pluto, and Pluto always presents the same face to Charon: from any position on either body, the other is always at the same position in the sky, or always obscured. This also means that the rotation period of each is equal to the time it takes the entire system to rotate around its common center of gravity. Just as Pluto revolves on its side relative to the orbital plane, so the Pluto–Charon system does also. In 2007, observations by the Gemini Observatory of patches of ammonia hydrates and water crystals on the surface of Charon suggested the presence of active cryo-geysers.
Small moons.
Two additional moons were imaged by astronomers working with the Hubble Space Telescope on 15 May 2005, and received provisional designations of S/2005 P 1 and S/2005 P 2. The International Astronomical Union officially named Pluto's newest moons Nix (or Pluto II, the inner of the two moons, formerly P 2) and Hydra (Pluto III, the outer moon, formerly P 1), on 21 June 2006.
These small moons orbit Pluto at approximately two and three times the distance of Charon: Nix at 48,700 kilometres and Hydra at 64,800 kilometres from the barycenter of the system. They have nearly circular prograde orbits in the same orbital plane as Charon.
Observations of Nix and Hydra to determine individual characteristics are ongoing. Hydra is sometimes brighter than Nix, suggesting either that it is larger or that different parts of its surface may vary in brightness. Their sizes are estimated from albedos. If their albedo is similar to that of Charon (0.35), then their diameters are 46 kilometres for Nix and 61 kilometres for Hydra. Upper limits on their diameters can be estimated by using the albedo of the darkest Kuiper-belt objects (0.04); these bounds are 137 ± 11 km and 167 ± 10 km, respectively. At the larger end of this range, the inferred masses are less than 0.3% that of Charon, or 0.03% that of Pluto.
The discovery of Nix and Hydra suggests that Pluto may possess a variable ring system. Small-body impacts can create debris that can form into a ring system. Data from a deep-optical survey by the Advanced Camera for Surveys on the Hubble Space Telescope suggest that no ring system is present. If such a system exists, it is either tenuous like the rings of Jupiter or is tightly confined to less than 1,000 km in width. Similar conclusions have been made from occultation studies.
A fourth moon, Kerberos, was announced on 20 July 2011. It was detected using NASA's Hubble Space Telescope during a survey searching for rings around Pluto. It has an estimated diameter of 13 to 34 km and is located between the orbits of Nix and Hydra. Kerberos was first seen in a photo taken with Hubble's Wide Field Camera 3 on 28 June. It was confirmed in subsequent Hubble pictures taken on 3 and 18 July.
A fifth moon, Styx, was announced on 7 July 2012, while looking for potential hazards for New Horizons. Styx is believed to have a diameter of between 10 and 25 km and to orbit Pluto at a distance between Charon and Nix.
Near resonances.
Styx, Nix, Kerberos and Hydra are fairly close to 3:1, 4:1, 5:1 and 6:1 mean-motion orbital resonances with Charon, respectively (the ratios approach integral commensurabilities more closely going outward from Pluto). Determining how near any of these orbital period ratios actually is to a true resonance requires accurate knowledge of the satellites' precessions.
Quasi-satellite.
At least one minor body is trapped in the 1:1 commensurability with Pluto, (15810) 1994 JR1, specifically in the quasi-satellite dynamical state. The object has been a quasi-satellite of Pluto for about 100,000 years and it will remain in that dynamical state for perhaps another 250,000 years. Its quasi-satellite behavior is recurrent with a periodicity of 2 million years. There may be additional Pluto co-orbitals.
Origins.
Pluto's origin and identity had long puzzled astronomers. One early hypothesis was that Pluto was an escaped moon of Neptune, knocked out of orbit by its largest current moon, Triton. This notion has been heavily criticized because Pluto never comes near Neptune in its orbit.
Pluto's true place in the Solar System began to reveal itself only in 1992, when astronomers began to find small icy objects beyond Neptune that were similar to Pluto not only in orbit but also in size and composition. This trans-Neptunian population is believed to be the source of many short-period comets. Astronomers now believe Pluto to be the largest member of the Kuiper belt, a somewhat stable ring of objects located between 30 and 50 AU from the Sun. As of 2011, surveys of the Kuiper belt to magnitude 21 were nearly complete and any remaining Pluto-sized objects are expected to be beyond 100 AU from the Sun. Like other Kuiper-belt objects (KBOs), Pluto shares features with comets; for example, the solar wind is gradually blowing Pluto's surface into space, in the manner of a comet. It has been claimed that if Pluto were placed as near to the Sun as Earth, it would develop a tail, as comets do. This claim has been disputed with the argument that Pluto's escape velocity is too high for this to happen.
Though Pluto is the largest of the Kuiper belt objects discovered, Neptune's moon Triton, which is slightly larger than Pluto, is similar to it both geologically and atmospherically, and is believed to be a captured Kuiper belt object. Eris (see below) is about the same size as Pluto (though more massive) but is not strictly considered a member of the Kuiper belt population. Rather, it is considered a member of a linked population called the scattered disc.
A large number of Kuiper belt objects, like Pluto, possess a 2:3 orbital resonance with Neptune. KBOs with this orbital resonance are called "plutinos", after Pluto.
Like other members of the Kuiper belt, Pluto is thought to be a residual planetesimal; a component of the original protoplanetary disc around the Sun that failed to fully coalesce into a full-fledged planet. Most astronomers agree that Pluto owes its current position to a sudden migration undergone by Neptune early in the Solar System's formation. As Neptune migrated outward, it approached the objects in the proto-Kuiper belt, setting one in orbit around itself (Triton), locking others into resonances, and knocking others into chaotic orbits. The objects in the scattered disc, a dynamically unstable region overlapping the Kuiper belt, are believed to have been placed in their current positions by interactions with Neptune's migrating resonances. A computer model created in 2004 by Alessandro Morbidelli of the Observatoire de la Côte d'Azur in Nice suggested that the migration of Neptune into the Kuiper belt may have been triggered by the formation of a 1:2 resonance between Jupiter and Saturn, which created a gravitational push that propelled both Uranus and Neptune into higher orbits and caused them to switch places, ultimately doubling Neptune's distance from the Sun. The resultant expulsion of objects from the proto-Kuiper belt could also explain the Late Heavy Bombardment 600 million years after the Solar System's formation and the origin of the Jupiter trojans. It is possible that Pluto had a near-circular orbit about 33 AU from the Sun before Neptune's migration perturbed it into a resonant capture. The Nice model requires that there were about a thousand Pluto-sized bodies in the original planetesimal disk; these may have included the early Triton and Eris.
Exploration.
Pluto presents significant challenges for spacecraft because of its small mass and large distance from Earth. "Voyager 1" could have visited Pluto, but controllers opted instead for a close flyby of Saturn's moon Titan, resulting in a trajectory incompatible with a Pluto flyby. "Voyager 2" never had a plausible trajectory for reaching Pluto. No serious attempt to explore Pluto by spacecraft occurred until the last decade of the 20th century. In August 1992, JPL scientist Robert Staehle telephoned Pluto's discoverer, Clyde Tombaugh, requesting permission to visit his planet. "I told him he was welcome to it," Tombaugh later remembered, "though he's got to go one long, cold trip." Despite this early momentum, in 2000, NASA cancelled the "Pluto Kuiper Express" mission, citing increasing costs and launch vehicle delays.
After an intense political battle, a revised mission to Pluto, dubbed "New Horizons", was granted funding from the US government in 2003. "New Horizons" was launched successfully on 19 January 2006. The mission leader, S. Alan Stern, confirmed that some of the ashes of Clyde Tombaugh, who died in 1997, had been placed aboard the spacecraft.
In early 2007 the craft made use of a gravity assist from Jupiter. Its closest approach to Pluto will be on 14 July 2015; scientific observations of Pluto will begin 5 months before closest approach and will continue for at least a month after the encounter. "New Horizons" captured its first (distant) images of Pluto in late September 2006, during a test of the Long Range Reconnaissance Imager (LORRI). The images, taken from a distance of approximately 4.2 billion kilometres, confirm the spacecraft's ability to track distant targets, critical for maneuvering toward Pluto and other Kuiper Belt objects.
"New Horizons" will use a remote sensing package that includes imaging instruments and a radio science investigation tool, as well as spectroscopic and other experiments, to characterise the global geology and morphology of Pluto and its moon Charon, map their surface composition and analyse Pluto's neutral atmosphere and its escape rate. "New Horizons" will also photograph the surfaces of Pluto and Charon.
Pluto's small moons, discovered shortly before or after the probes's launch, may present it with unforeseen challenges. Debris from collisions between Kuiper belt objects and the smaller moons, with their relatively low escape velocities, may produce a tenuous dusty ring. Were New Horizons to fly through such a ring system, there would be an increased potential for micrometeoroid damage that could disable the probe.
Timeline of New Horizons Approach to Pluto.
On 4 February 2015, NASA released new images of Pluto (taken on 25 and 27 January) from the approaching probe. New Horizons was more than 203,000,000 km away from Pluto when it began taking the photos, which showed Pluto and its largest moon, Charon.
On 20 March 2015, NASA invited the general public to suggest names to surface features that will be discovered on Pluto and Charon.
On 15 April 2015, Pluto was imaged showing a possible polar cap.
Concepts.
A Pluto orbiter/lander/sample return mission was proposed in 2003. The plan included a twelve-year trip from Earth to Pluto, mapping from orbit, multiple landings, a warm water probe, and possible "in situ" propellant production for another twelve-year trip back to Earth with samples. Power and propulsion would come from the bimodal MITEE nuclear reactor system.
Classification.
After Pluto's place within the Kuiper belt was determined, its official status as a planet became controversial, with many questioning whether Pluto should be considered together with or separately from its surrounding population.
Museum and planetarium directors occasionally created controversy by omitting Pluto from planetary models of the Solar System. The Hayden Planetarium reopened after renovation in 2000 with a model of only eight planets. The controversy made headlines at the time.
In 2002, the KBO 50000 Quaoar was discovered, with a diameter then thought to be roughly 1280 kilometres, about half that of Pluto. In 2004, the discoverers of 90377 Sedna placed an upper limit of 1800 km on its diameter, nearer to Pluto's diameter of 2320 km, although Sedna's diameter was revised downward to less than 1600 km by 2007. Just as Ceres, Pallas, Juno and Vesta eventually lost their planet status after the discovery of many other asteroids, so, it was argued, Pluto should be reclassified as one of the Kuiper belt objects.
On 29 July 2005, the discovery of a new trans-Neptunian object was announced. Named Eris, it is now known to be approximately the same size as Pluto. This was the largest object discovered in the Solar System since Triton in 1846. Its discoverers and the press initially called it the tenth planet, although there was no official consensus at the time on whether to call it a planet. Others in the astronomical community considered the discovery the strongest argument for reclassifying Pluto as a minor planet.
2006: IAU classification.
The debate came to a head in 2006 with an IAU resolution that created an official definition for the term "planet". According to this resolution, there are three main conditions for an object to be considered a 'planet':
Pluto fails to meet the third condition, because its mass is only 0.07 times that of the mass of the other objects in its orbit (Earth's mass, by contrast, is 1.7 million times the remaining mass in its own orbit). The IAU further resolved that Pluto be classified in the simultaneously created dwarf planet category, and that it act as the prototype for the plutoid category of trans-Neptunian objects, in which it would be separately, but concurrently, classified.
On 13 September 2006, the IAU included Pluto, Eris, and the Eridian moon Dysnomia in their Minor Planet Catalogue, giving them the official minor planet designations "(134340) Pluto", "(136199) Eris", and "(136199) Eris I Dysnomia". If Pluto had been given a minor planet name upon its discovery, the number would have been about 1,164 rather than 134,340.
There has been some resistance within the astronomical community toward the reclassification. S. Alan Stern, principal investigator with NASA's "New Horizons" mission to Pluto, publicly derided the IAU resolution, stating that "the definition stinks, for technical reasons". Stern's contention was that by the terms of the new definition Earth, Mars, Jupiter, and Neptune, all of which share their orbits with asteroids, would be excluded. His other claim was that because less than five percent of astronomers voted for it, the decision was not representative of the entire astronomical community. Marc W. Buie, then at Lowell Observatory, voiced his opinion on the new definition on his website and petitioned against the definition. Others have supported the IAU. Mike Brown, the astronomer who discovered Eris, said "through this whole crazy circus-like procedure, somehow the right answer was stumbled on. It's been a long time coming. Science is self-correcting eventually, even when strong emotions are involved."
Researchers on both sides of the debate gathered on 14–16 August 2008, at the Johns Hopkins University Applied Physics Laboratory for a conference that included back-to-back talks on the current IAU definition of a planet. Entitled "The Great Planet Debate", the conference published a post-conference press release indicating that scientists could not come to a consensus about the definition of planet. Just before the conference, on 11 June 2008, the IAU announced in a press release that the term "plutoid" would henceforth be used to describe Pluto and other objects similar to Pluto which have an orbital semimajor axis greater than that of Neptune and enough mass to be of near-spherical shape.
Reaction.
Reception to the IAU decision was mixed. Although many accepted the reclassification, some sought to overturn the decision with online petitions urging the IAU to consider reinstatement. A resolution introduced by some members of the California State Assembly light-heartedly denounced the IAU for "scientific heresy", among other crimes. The U.S. state of New Mexico's House of Representatives passed a resolution in honor of Tombaugh, a longtime resident of that state, which declared that Pluto will always be considered a planet while in New Mexican skies and that 13 March 2007, was Pluto Planet Day. The Illinois State Senate passed a similar resolution in 2009, on the basis that Clyde Tombaugh, the discoverer of Pluto, was born in Illinois. The resolution asserted that Pluto was "unfairly downgraded to a 'dwarf' planet" by the IAU.
Some members of the public have also rejected the change, citing the disagreement within the scientific community on the issue, or for sentimental reasons, maintaining that they have always known Pluto as a planet and will continue to do so regardless of the IAU decision.
In 2006 in its 17th annual words of the year vote, the American Dialect Society voted plutoed as the word of the year. To "pluto" is to "demote or devalue someone or something".

</doc>
<doc id="44472" url="http://en.wikipedia.org/wiki?curid=44472" title="The World According to Garp">
The World According to Garp

The World According to Garp is John Irving's fourth novel. Published in 1978, the book was a bestseller for several years. It was a finalist for the National Book Award for Fiction in 1979, and its first paperback edition won the Award the following year.
A movie adaptation of the novel starring Robin Williams was released in 1982, with a screenplay written by Steve Tesich.
BBC Radio 4's "Classic Serial" broadcast a three-part adaptation of the novel by Linda Marshall Griffiths in January 2014. The production was directed by Nadia Molinari and featured Miranda Richardson as Jenny, Lee Ingleby as Garp, Jonathan Keeble as Roberta and Lyndsey Marshal as Helen.
Plot.
The story deals with the life of T. S. Garp. His mother, Jenny Fields, is a strong-willed nurse who wants a child but not a husband. She encounters a dying ball turret gunner known only as Technical Sergeant Garp, who was severely brain damaged in combat. Jenny nurses Garp, observing his infantile state and almost perpetual autonomic sexual arousal. As a matter of practicality and kindness in making his passing as comfortable as possible and reducing his agitation, she manually gratifies him several times. Unconstrained by convention and driven by practicality and her desire for a child, Jenny uses Garp's semen to impregnate herself and names the resulting son "T. S." (a name derived from "Technical Sergeant", but consisting of just initials). Jenny raises young Garp alone, taking a position at the all-boys Steering School in New England.
Garp grows up, becoming interested in sex, wrestling, and writing fiction—three topics in which his mother has little interest. After his graduation in 1961, his mother takes him to Vienna, where he writes his first novella. At the same time, his mother begins writing her autobiography, "A Sexual Suspect". After they return to Steering, Garp marries Helen, the wrestling coach's daughter, and begins his family, he a struggling writer, she a teacher of English. The publication of "A Sexual Suspect" makes his mother famous. She becomes a feminist icon, as feminists view her book as a manifesto of a woman who does not care to bind herself to a man, and who chooses to raise a child on her own. She nurtures and supports women traumatized by men, among them the Ellen Jamesians, a group of women named after an eleven-year-old girl whose tongue was cut off by her rapists to silence her. The members of the group cut off their own tongues in support of the girl.
Garp becomes a devoted parent, wrestling with anxiety for the safety of his children and a desire to keep them safe from the dangers of the world. He and his family inevitably experience dark and violent events through which the characters change and grow. Garp learns (often painfully) from the women in his life (including transsexual ex-football player Roberta Muldoon), who are struggling to become more tolerant in the face of intolerance. The story contains a great deal of (in the words of Garp's fictional teacher) "lunacy and sorrow", and the sometimes ridiculous chains of events the characters experience still resonate with painful truth.
The novel contains several framed narratives: Garp's first novella, "The Pension Grillparzer"; "Vigilance", a short story; and the first chapter of his novel, "The World According to Bensenhaver". The book also contains some motifs that appear in almost all John Irving novels: bears, New England, Vienna, wrestling, people who are uninterested in having sex, and a complex Dickensian plot that spans the protagonist's whole life. Adultery (another common Irving motif) also plays a large part, culminating in one of the novel's most harrowing and memorable scenes. Another familiar Irving trope, castration anxiety, is present, most obviously in the fate of Michael Milton.
Background.
John Irving's mother, Frances Winslow, had not been married at the time of his conception, and Irving never met his biological father. As a child, he was not told anything about his father, and he baited his mother that unless she gave him some information about his biological father, in his writing he would invent the father and the circumstances of how she got pregnant. Winslow would reply, "Go ahead, dear."
In 1981, "TIme" magazine quoted the novelist's mother as saying, "There are parts of "Garp" that are too explicit for me."
Discussion of main themes.
Death.
Irving concludes the novel by stating, "In the world according to Garp, we are all terminal cases." Indeed, throughout the book, Garp seems to be obsessed with death, both in his writing and in his personal life. Garp remarks in a reading that his novella, "The Pension Grillparzer", features the death of seven of his nine characters. His third novel, "The World According to Bensenhaver", features multiple scenes of death and mutilation. However, Garp's writing merely reflects the broader nature of his obsession with necrosis. Garp irrationally fantasizes about ways his loved ones might die. At one point, Garp rants about his hatred of late-night phone calls—which undoubtedly bring news of a loved one's death. Ironically, several of the people closest to him do die—often in outlandish, even comical ways.
Gender roles.
Unavoidable in "The World According to Garp", and in Garp's own writing itself, is the treatment of extreme feminism. Garp's mother Jenny Fields finds herself amidst elements of the women's rights movement, and, rejecting almost any interaction with men, is the focus of Irving's feminist overtones. Driven home by her adoption of radical feminists and her absurd New England feminist enclave at Dog's Head Harbor, Irving paints a complicated view of the women's movement. Indeed, Irving oscillates a decidedly unsympathetic view of the overzealous Ellen Jamesians, while vesting in the character of Roberta Muldoon a sanguine portrayal of a transsexual—one who ends up becoming Garp's best friend. Garp's relationship to the feminist movement is also muddled. Garp becomes a reluctant representative of the movement with his third—and most widely read—novel. At the same time, however, he is rejected outright by many feminists and Ellen Jamesians for his work's misogynistic tone.
Sexuality.
Garp's world is one where sexuality—replaced in the book with the nomenclature "lust"—is basically a source of trouble and heartache. Garp's earliest feelings of lust, namely those for a girl, Cushie, result in what are ultimately negative feelings for Garp. Garp's second encounter with lust is with an Austrian prostitute, a relationship his mother used as material for national rebuke in her successful autobiography, "A Sexual Suspect". The only character Irving creates without any symptoms of lust is Garp's mother, Jenny Fields, an asexual nurse whose repulsion by sex is highlighted by her conception of Garp himself. As a result, Garp's mother appears as one of the few steady, morally justified characters in the novel, in spite of her having committed rape. Although she does have non-consensual sex with the sergeant, that seems to be the only time when Jenny engages in sexual activity. Irving also disorients Garp's sexual moral compass by having him engage in numerous lurid affairs, by presenting Garp's marriage through an odd sexual quadrangle with another married couple (a similar quadrangle was the primary focus of Irving's previous novel, "The 158-Pound Marriage"), and especially by his depiction of Garp's wife, Helen, who also has extramarital sexual liaisons. Indeed, undoubtedly the most horrifying event in the novel occurs during a scene in which Garp's son (Walt) accidentally is killed and his other son injured because Helen, while attempting to break off her affair with one of her students, agrees to fellatio as a sort of going-away present.

</doc>
<doc id="44473" url="http://en.wikipedia.org/wiki?curid=44473" title="Ctesiphon">
Ctesiphon

Ctesiphon (Persian: تيسفون‎, "Tīsfūn") was the imperial capital of the Parthian Empire and the Sasanian Empire. It was one of the great cities of late ancient Mesopotamia.
Its most conspicuous structure today is the great archway of Ctesiphon.
It was situated on the eastern bank of the Tigris across from where the Greek city of Seleucia stood and northeast of ancient Babylon. Today, the remains of the city lie in Baghdad Governorate, Iraq, approximately 35 km south of the city of Baghdad.
Ctesiphon was the largest city in the world from 570 AD, until its fall in 637 AD, during the Muslim conquests.
Names.
The Latin name Ctesiphon or Ctesifon derives from Ancient Greek "Ktēsiphôn" (Κτησιφῶν), a Hellenized form of a local name that has been reconstructed as "Tisfōn" or "Tisbōn". In Iranian sources of the Sassanid period it is attested in Manichean Parthian, in Sassanid Middle Persian and in Christian Sogdian as Pahlavi "tyspwn", continuing in New Persian as "tīsfūn" (تیسفون).
Syriac sources mention it as "Qṭēsfōn" (ܩܛܝܣܦܘܢ), and in medieval Arabic texts the name is usually "Ṭaysafūn" (طيسفون) or "Qaṭaysfūn" (قطيسفون) in Modern Arabic "al-Mada'in" (المدائن) (literally the cities, referring to the Greater Ctesiphon). "According to Yāqūt [...], quoting Ḥamza, the original form was Ṭūsfūn or Tūsfūn, which was arabicized as Ṭaysafūn." The Armenian name of the city was "Tizbon" (Տիզբոն). Ctesiphon is first mentioned in the Book of Ezra of the Old Testament as Kasfia/Casphia (a derivative of the ethnic name, Cas, and a cognate of Caspian and Qazvin).
Location.
Ctesiphon is located approximately at Al-Mada'in, 32 km southeast of the modern city of Baghdad, Iraq, along the river Tigris. Ctesiphon measured 30 square kilometers (cf. the 13.7 square kilometers of 4th-century imperial Rome).
The archway of Chosroes was once a part of the royal palace in Ctesiphon and is estimated to date between the 3rd and 6th centuries AD. It is located in what is now the Iraqi town of Salman Pak.
History.
Foundation.
Ctesiphon was founded in the late 120s BC. It was built on the site of a military camp established across from Seleucia by Mithridates I of Parthia. The reign of Gotarzes I saw Ctesiphon reach a peak as a political and commercial center. The city became the Empire's capital circa 58 BC during the reign of Orodes II. Gradually, the city merged with the old Hellenistic capital of Seleucia and other nearby settlements to form a cosmopolitan metropolis.
The reason for this westward relocation of the capital could have been in part due to the proximity of the previous capitals (Mithradatkirt, and Hyrcania at Hecatompylos) to the Scythian incursions.
Strabo abundantly describes the foundation of Ctesiphon:
Roman–Persian Wars.
Because of its importance, Ctesiphon was a major military objective for the leaders of the Roman Empire in their eastern wars. The city was captured by Rome five times in its history – three times in the 2nd century alone. The emperor Trajan captured Ctesiphon in 116, but his successor, Hadrian, decided to willingly return Ctesiphon in 117 as part of a peace settlement. The Roman general Avidius Cassius captured Ctesiphon in 164 during another Parthian war, but abandoned it when peace was concluded. In 197, the emperor Septimius Severus sacked Ctesiphon and carried off thousands of its inhabitants, whom he sold into slavery.
Late in the 3rd century, after the Parthians had been supplanted by the Sassanids, the city again became a source of conflict with Rome. In 283, emperor Carus sacked the city uncontested during a period of civil upheaval. In 295, emperor Galerius was defeated outside the city. However, he returned a year later with a vengeance and won a victory which ended in the fifth and final capture of the city by the Romans in 299. He returned it to the Persian king Narses in exchange for Armenia and western Mesopotamia. In c.325 and again in 410, the city, or the Greek colony directly across the river, was the site of church councils for the Church of the East.
Severus Alexander advanced towards Ctesiphon in 233, but as corroborated by Herodian, his armies suffered a humiliating defeat against Ardashir I.
After the conquest of Antioch in 541, Khosrau I built a new city near Ctesiphon for the inhabitants he captured. He called this new city "Weh Antiok Khusrau", or literally, “better than Antioch Khosrau built this.” Local inhabitants of the area called the new city "Rumagan", meaning “town of the Romans” and Arabs called the city "al-Rumiyya". Along with Weh Antiok, Khosrau built a number of fortified cities. Khosrau I deported 292,000 citizens, slaves, and conquered people to the new city of Ctesiphon in 542.
Emperor Julian was killed following a battle outside of the city walls, in 363, during his war against Shapur II. Finally, in 627, the Byzantine Emperor Heraclius surrounded the city, the capital of the Sassanid Empire, leaving it after the Persians accepted his peace terms.
Downfall of the Sasanians and the Islamic conquests.
Ctesiphon fell to the Muslims during the Islamic conquest of Persia in 637 under the military command of Sa'ad ibn Abi Waqqas during the caliphate of Umar. When the Arabs entered the city, the throne hall in Taq Kasra was briefly used as a mosque.
Still, as political and economic fortune had passed elsewhere, the city went into a rapid decline, especially after the founding of the Abbasid capital at Baghdad in the 8th century, and soon became a ghost town. Caliph Al-Mansur took much of the required material for the construction of Baghdad from the ruins of Ctesiphon. He also attempted to demolish the palace and reuse its bricks for his own palace, but he desisted only when the undertaking proved too vast.
It is believed to be the basis for the city of Isbanir in "One Thousand and One Nights".
Modern era.
The ruins of Ctesiphon were the site of a major battle of World War I in November 1915. The Ottoman Empire defeated troops of Britain attempting to capture Baghdad, and drove them back some 40 mi before trapping the British force and compelling it to surrender.
Archaeology.
A German Oriental Society and University of Pennsylvania team led by Oscar Reuther excavated at Ctesiphon in 1928–29 and 1931–32, mainly at Qasr bint al-Qadi on the western part of the site.
In the late 1960s and early 1970s, an Italian team from the University of Turin directed by Antonio Invernizzi and Giorgio Gullini worked at the site, mainly doing restoration at the palace of Khosrau II. In 2013 the Iraqi government contracted to restore the Arch of Ctesiphon as a tourist attraction.

</doc>
<doc id="44474" url="http://en.wikipedia.org/wiki?curid=44474" title="Saturn">
Saturn

 {{plainlist |
 {{plainlist |
 {{plainlist |
 {{plainlist |
 {{plainlist |
 {{plainlist |
 {{plainlist |
 {{plainlist |
 {{plainlist |
 {{plainlist |
 {{plainlist |
Saturn is the sixth planet from the Sun and the second largest in the Solar System, after Jupiter. It is a gas giant with an average radius about nine times that of Earth. Although only one-eighth the average density of Earth, with its larger volume Saturn is just over 95 times more massive. Saturn is named after the Roman god of agriculture, its astronomical symbol ({{Unicode|♄}}) represents the god's sickle.
Saturn's interior is probably composed of a core consisting of iron–nickel and rock (silicon and oxygen compounds), surrounded by a deep layer of metallic hydrogen, an intermediate layer of liquid hydrogen and liquid helium and a gaseous outer layer. Saturn has a pale yellow hue due to ammonia crystals in its upper atmosphere. Electrical current within the metallic hydrogen layer is thought to give rise to Saturn's planetary magnetic field, which is weaker than Earth's, but has a magnetic moment 580 times that of Earth due to Saturn's larger size. Saturn's magnetic field strength is around one-twentieth the strength of Jupiter's. The outer atmosphere is generally bland and lacking in contrast, although long-lived features can appear. Wind speeds on Saturn can reach {{convert|1800|km/h|m/s|abbr=on}}, faster than on Jupiter, but not as fast as those on Neptune.
Saturn has a prominent ring system that consists of nine continuous main rings and three discontinuous arcs and that is composed mostly of ice particles with a smaller amount of rocky debris and dust. Sixty-two moons are known to orbit Saturn, of which fifty-three are officially named. This does not include the hundreds of moonlets comprising the rings. Titan, Saturn's largest and the Solar System's second largest moon, is larger than the planet Mercury and is the only moon in the Solar System to have a substantial atmosphere.
Physical characteristics.
Saturn is a gas giant because it is predominantly composed of hydrogen and helium ('gas'). It lacks a definite surface, though it may have a solid core. Saturn's rotation causes it to have the shape of an oblate spheroid; that is, it is flattened at the poles and bulges at its equator. Its equatorial and polar radii differ by almost 10%: 60,268 km versus 54,364 km, respectively. Jupiter, Uranus, and Neptune, the other giant planets in the Solar System, are also oblate but to a lesser extent. Saturn is the only planet of the Solar System that is less dense than water—about 30% less. Although Saturn's core is considerably denser than water, the average specific density of the planet is 0.69 g/cm3 due to the gaseous atmosphere. Jupiter has 318 times the Earth's mass, while Saturn is 95 times the mass of the Earth, Together, Jupiter and Saturn hold 92% of the total planetary mass in the Solar System.
On 8 January 2015, NASA reported determining the center of the planet Saturn and its family of moons to within {{convert|4|km|mi|abbr=on}}.
Internal structure.
Despite consisting mostly of hydrogen and helium, most of Saturn's mass is not in the gas phase, because hydrogen becomes a non-ideal liquid when the density is above 0.01 g/cm3, which is reached at a radius containing 99.9% of Saturn's mass. The temperature, pressure, and density inside Saturn all rise steadily toward the core, which, in the deeper layers, cause hydrogen to transition into a metal.
Standard planetary models suggest that the interior of Saturn is similar to that of Jupiter, having a small rocky core surrounded by hydrogen and helium with trace amounts of various volatiles. This core is similar in composition to the Earth, but more dense. Examination of Saturn's gravitational moment, in combination with physical models of the interior, allowed French astronomers Didier Saumon and Tristan Guillot to place constraints on the mass of Saturn's core. In 2004, they estimated that the core must be 9–22 times the mass of the Earth, which corresponds to a diameter of about 25,000 km. This is surrounded by a thicker liquid metallic hydrogen layer, followed by a liquid layer of helium-saturated molecular hydrogen that gradually transitions into gas with increasing altitude. The outermost layer spans 1,000 km and consists of a gaseous atmosphere.
Saturn has a hot interior, reaching 11,700 °C at its core, and it radiates 2.5 times more energy into space than it receives from the Sun. Jupiter's thermal energy is generated by the Kelvin–Helmholtz mechanism of slow gravitational compression, but this alone may not be sufficient to explain heat production for Saturn, because it is less massive. An alternative or additional mechanism may be generation of heat through the "raining out" of droplets of helium deep in Saturn's interior. As the droplets descend through the lower-density hydrogen, the process releases heat by friction and leaves Saturn's outer layers depleted of helium. These descending droplets may have accumulated into a helium shell surrounding the core.
Atmosphere.
The outer atmosphere of Saturn contains 96.3% molecular hydrogen and 3.25% helium by volume. The proportion of helium is significantly deficient compared to the abundance of this element in the Sun. The quantity of elements heavier than helium is not known precisely, but the proportions are assumed to match the primordial abundances from the formation of the Solar System. The total mass of these heavier elements is estimated to be 19–31 times the mass of the Earth, with a significant fraction located in Saturn's core region.
Trace amounts of ammonia, acetylene, ethane, propane, phosphine and methane have been detected in Saturn's atmosphere. The upper clouds are composed of ammonia crystals, while the lower level clouds appear to consist of either ammonium hydrosulfide (NH4SH) or water. Ultraviolet radiation from the Sun causes methane photolysis in the upper atmosphere, leading to a series of hydrocarbon chemical reactions with the resulting products being carried downward by eddies and diffusion. This photochemical cycle is modulated by Saturn's annual seasonal cycle.
Cloud layers.
Saturn's atmosphere exhibits a banded pattern similar to Jupiter's, but Saturn's bands are much fainter and are much wider near the equator. The nomenclature used to describe these bands is the same as on Jupiter. Saturn's finer cloud patterns were not observed until the flybys of the Voyager spacecraft during the 1980s. Since then, Earth-based telescopy has improved to the point where regular observations can be made.
The composition of the clouds varies with depth and increasing pressure. In the upper cloud layers, with the temperature in the range 100–160 K and pressures extending between 0.5–2 bar, the clouds consist of ammonia ice. Water ice clouds begin at a level where the pressure is about 2.5 bar and extend down to 9.5 bar, where temperatures range from 185–270 K. Intermixed in this layer is a band of ammonium hydrosulfide ice, lying in the pressure range 3–6 bar with temperatures of 290–235 K. Finally, the lower layers, where pressures are between 10–20 bar and temperatures are 270–330 K, contains a region of water droplets with ammonia in aqueous solution.
Saturn's usually bland atmosphere occasionally exhibits long-lived ovals and other features common on Jupiter. In 1990, the Hubble Space Telescope imaged an enormous white cloud near Saturn's equator that was not present during the Voyager encounters and in 1994, another, smaller storm was observed. The 1990 storm was an example of a Great White Spot, a unique but short-lived phenomenon that occurs once every Saturnian year, roughly every 30 Earth years, around the time of the northern hemisphere's summer solstice. Previous Great White Spots were observed in 1876, 1903, 1933 and 1960, with the 1933 storm being the most famous. If the periodicity is maintained, another storm will occur in about 2020.
The winds on Saturn are the second fastest among the Solar System's planets, after Neptune's. Voyager data indicate peak easterly winds of 500 m/s (1800 km/h). In images from the "Cassini" spacecraft during 2007, Saturn's northern hemisphere displayed a bright blue hue, similar to Uranus. The color was most likely caused by Rayleigh scattering. Infrared imaging has shown that Saturn's south pole has a warm polar vortex, the only known example of such a phenomenon in the Solar System. Whereas temperatures on Saturn are normally −185 °C, temperatures on the vortex often reach as high as −122 °C, believed to be the warmest spot on Saturn.
North pole hexagonal cloud pattern.
A persisting hexagonal wave pattern around the north polar vortex in the atmosphere at about 78°N was first noted in the Voyager images.
The sides of the hexagon are each about {{Convert|13800|km|mi|-2|abbr=on}} long, which is longer than the diameter of the Earth. The entire structure rotates with a period of {{nowrap|10h 39m 24s}} (the same period as that of the planet's radio emissions) which is assumed to be equal to the period of rotation of Saturn's interior. The hexagonal feature does not shift in longitude like the other clouds in the visible atmosphere.
The pattern's origin is a matter of much speculation. Most astronomers believe it was caused by some standing-wave pattern in the atmosphere. Polygonal shapes have been replicated in the laboratory through differential rotation of fluids.
South pole vortex.
HST imaging of the south polar region indicates the presence of a jet stream, but no strong polar vortex nor any hexagonal standing wave. NASA reported in November 2006 that "Cassini" had observed a "hurricane-like" storm locked to the south pole that had a clearly defined eyewall. Eyewall clouds had not previously been seen on any planet other than Earth. For example, images from the Galileo spacecraft did not show an eyewall in the Great Red Spot of Jupiter.
The south pole storm may have been present for billions of years. This vortex is comparable to the size of Earth, and it has winds of 550 km/h.
Other features.
Cassini has observed a series of cloud features nicknamed "String of Pearls" found in northern latitudes. These features are cloud clearings that reside in deeper cloud layers.
Magnetosphere.
Saturn has an intrinsic magnetic field that has a simple, symmetric shape – a magnetic dipole. Its strength at the equator – 0.2 gauss (20 µT) – is approximately one twentieth of that of the field around Jupiter and slightly weaker than Earth's magnetic field. As a result Saturn's magnetosphere is much smaller than Jupiter's. When "Voyager 2" entered the magnetosphere, the solar wind pressure was high and the magnetosphere extended only 19 Saturn radii, or 1.1 million km (712,000 mi), although it enlarged within several hours, and remained so for about three days. Most probably, the magnetic field is generated similarly to that of Jupiter – by currents in the liquid metallic-hydrogen layer called a metallic-hydrogen dynamo. This magnetosphere is efficient at deflecting the solar wind particles from the Sun. The moon Titan orbits within the outer part of Saturn's magnetosphere and contributes plasma from the ionized particles in Titan's outer atmosphere. Saturn's magnetosphere, like Earth's, produces aurorae.
Orbit and rotation.
The average distance between Saturn and the Sun is over 1.4 billion kilometres (9 AU). With an average orbital speed of 9.69 km/s, it takes Saturn 10,759 Earth days (or about {{frac|29|1|2}} years), to finish one revolution around the Sun. The elliptical orbit of Saturn is inclined 2.48° relative to the orbital plane of the Earth. The perihelion and aphelion distances are, respectively, 9.022 and 10.053 au, on average.
The visible features on Saturn rotate at different rates depending on latitude and multiple rotation periods have been assigned to various regions (as in Jupiter's case).
"System I" has a period of 10 h 14 min 00 s (844.3°/d) and encompasses the Equatorial Zone, the South Equatorial Belt and the North Equatorial Belt.
All other Saturnian latitudes, excluding the north and south polar regions, are indicated as "System II" and have been assigned a rotation period of 10 h 38 min 25.4 s (810.76°/d).
The polar regions are considered to have rotation rates similar to System I.
"System III" refers to Saturn's internal rotation rate. Based on radio emissions from the planet in the period of the Voyager flybys, it has been assigned a rotation period of 10 h 39 min 22.4 s (810.8°/d). Because it is close to System II, it has largely superseded it. A precise value for the rotation period of the interior remains elusive. While approaching Saturn in 2004, "Cassini" found that the radio rotation period of Saturn had increased appreciably, to approximately 10 h 45 m 45 s (± 36 s). In March 2007, it was found that the variation of radio emissions from the planet did not match Saturn's rotation rate. This variance may be caused by geyser activity on Saturn's moon Enceladus. The water vapor emitted into Saturn's orbit by this activity becomes charged and creates a drag upon Saturn's magnetic field, slowing its rotation slightly relative to the rotation of the planet.
The latest estimate of Saturn's rotation (as an indicated rotation rate for Saturn as a whole) based on a compilation of various measurements from the "Cassini", "Voyager" and "Pioneer" probes was reported in September 2007 is 10 hours, 32 minutes, 35 seconds.
Planetary rings.
Saturn is probably best known for the system of planetary rings that makes it visually unique. The rings extend from 6,630 km to 120,700 km above Saturn's equator, average approximately 20 meters in thickness and are composed of 93% water ice with traces of tholin impurities and 7% amorphous carbon. The particles that make up the rings range in size from specks of dust up to 10 m. While the other gas giants also have ring systems, Saturn's is the largest and most visible.
There are two main hypotheses regarding the origin of the rings. One hypothesis is that the rings are remnants of a destroyed moon of Saturn. The second hypothesis is that the rings are left over from the original nebular material from which Saturn formed. Some ice in the E ring comes from the moon Enceladus's geyers. 
In the past, astronomers believed the rings formed alongside the planet when it formed billions of years ago. Instead, the age of these planetary rings is probably some hundreds of millions of years.
Beyond the main rings at a distance of 12 million km from the planet is the sparse Phoebe ring, which is tilted at an angle of 27° to the other rings and, like Phoebe, orbits in retrograde fashion.
Some of the moons of Saturn, including Pandora and Prometheus, act as shepherd moons to confine the rings and prevent them from spreading out. Pan and Atlas cause weak, linear density waves in Saturn's rings that have yielded more reliable calculations of their masses.
Natural satellites.
Saturn has at least 150 moons and moonlets, 53 of which have formal names. Titan, the largest, comprises more than 90% of the mass in orbit around Saturn, including the rings. Saturn's second largest moon, Rhea, may have a tenuous ring system of its own, along with a tenuous atmosphere. Many of the other moons are small: 34 are less than 10 km in diameter and another 14 less than 50 km but larger than 10 km. Traditionally, most of Saturn's moons have been named after Titans of Greek mythology. Titan is the only satellite in the Solar System with a major atmosphere in which a complex organic chemistry occurs. It is the only satellite with hydrocarbon lakes.
On 6 June 2013, scientists at the IAA-CSIC reported the detection of polycyclic aromatic hydrocarbons in the upper atmosphere of Titan, a possible precursor for life. On 23 June 2014, NASA claimed to have strong evidence that nitrogen in the atmosphere of Titan came from materials in the Oort cloud, associated with comets, and not from the materials that formed Saturn in earlier times.
Saturn's moon Enceladus, which seems similar in chemical makeup to comets, has often been regarded as a potential habitat for microbial life. Evidence of this possibility includes the satellite's salt-rich particles having an "ocean-like" composition that indicates most of Enceladus's expelled ice comes from the evaporation of liquid salt water.
In April 2014, NASA scientists reported the possible beginning of a new moon, within the A Ring, of the planet Saturn.
History of observation and exploration.
There have been three main phases in the observation and exploration of Saturn. The first era was ancient observations (such as with the naked eye), before the invention of the modern telescopes. Starting in the 17th century progressively more advanced telescopic observations from Earth have been made. The other type is visitation by spacecraft, either by orbiting or flyby. In the 21st century observations continue from the Earth (or Earth-orbiting observatories) and from the "Cassini" orbiter at Saturn.
Ancient observations.
Saturn has been known since prehistoric times. In ancient times, it was the most distant of the five known planets in the Solar System (excluding Earth) and thus a major character in various mythologies. Babylonian astronomers systematically observed and recorded the movements of Saturn. In ancient Roman mythology, the god Saturnus, from which the planet takes its name, was the god of agriculture. The Romans considered Saturnus the equivalent of the Greek god Cronus. The Greeks had made the outermost planet sacred to Cronus, and the Romans followed suit. (In modern Greek, the planet retains its ancient name "Cronus"—Κρόνος: "Kronos".)
The Greek scientist Ptolemy based his calculations of Saturn's orbit on observations he made while the planet was in opposition. In Hindu astrology, there are nine astrological objects, known as Navagrahas. Saturn, one of them, is known as "Shani", judges everyone based on the good and bad deeds performed in life. Ancient Chinese and Japanese culture designated the planet Saturn as the "earth star" ({{lang|zh|土星}}). This was based on Five Elements which were traditionally used to classify natural elements.
In ancient Hebrew, Saturn is called 'Shabbathai'. Its angel is Cassiel. Its intelligence or beneficial spirit is Agiel (layga) and its spirit (darker aspect) is Zazel (lzaz). In Ottoman Turkish, Urdu and Malay, its name is 'Zuhal', derived from Arabic زحل.
European observations (17th–19th centuries).
Saturn's rings require at least a 15-mm-diameter telescope to resolve and thus were not known to exist until Galileo first saw them in 1610. He thought of them as two moons on Saturn's sides. It was not until Christiaan Huygens used greater telescopic magnification that this notion was refuted. Huygens discovered Saturn's moon Titan; Giovanni Domenico Cassini later discovered four other moons: Iapetus, Rhea, Tethys and Dione. In 1675, Cassini discovered the gap now known as the Cassini Division.
No further discoveries of significance were made until 1789 when William Herschel discovered two further moons, Mimas and Enceladus. The irregularly shaped satellite Hyperion, which has a resonance with Titan, was discovered in 1848 by a British team.
In 1899 William Henry Pickering discovered Phoebe, a highly irregular satellite that does not rotate synchronously with Saturn as the larger moons do. Phoebe was the first such satellite found and it takes more than a year to orbit Saturn in a retrograde orbit. During the early 20th century, research on Titan led to the confirmation in 1944 that it had a thick atmosphere – a feature unique among the Solar System's moons.
Modern NASA and ESA probes.
Pioneer 11 flyby.
"Pioneer 11" carried out the first flyby of Saturn in September 1979, when it passed within 20,000 km of the planet's cloud tops. Images were taken of the planet and a few of its moons, although their resolution was too low to discern surface detail. The spacecraft also studied Saturn's rings, revealing the thin F-ring and the fact that dark gaps in the rings are bright when viewed at high phase angle (towards the Sun), meaning that they contain fine light-scattering material. In addition, "Pioneer 11" measured the temperature of Titan.
Voyager flybys.
In November 1980, the "Voyager 1" probe visited the Saturn system. It sent back the first high-resolution images of the planet, its rings and satellites. Surface features of various moons were seen for the first time. "Voyager 1" performed a close flyby of Titan, increasing knowledge of the atmosphere of the moon. It proved that Titan's atmosphere is impenetrable in visible wavelengths, therefore no surface details were seen. The flyby changed the spacecraft's trajectory out from the plane of the Solar System.
Almost a year later, in August 1981, "Voyager 2" continued the study of the Saturn system. More close-up images of Saturn's moons were acquired, as well as evidence of changes in the atmosphere and the rings. Unfortunately, during the flyby, the probe's turnable camera platform stuck for a couple of days and some planned imaging was lost. Saturn's gravity was used to direct the spacecraft's trajectory towards Uranus.
The probes discovered and confirmed several new satellites orbiting near or within the planet's rings, as well as the small Maxwell Gap (a gap within the C Ring) and Keeler gap (a 42 km wide gap in the A Ring).
Cassini–Huygens spacecraft.
On 1 July 2004, the Cassini–Huygens space probe performed the SOI (Saturn Orbit Insertion) maneuver and entered orbit around Saturn. Before the SOI, "Cassini" had already studied the system extensively. In June 2004, it had conducted a close flyby of Phoebe, sending back high-resolution images and data.
"Cassini's" flyby of Saturn's largest moon, Titan, has captured radar images of large lakes and their coastlines with numerous islands and mountains. The orbiter completed two Titan flybys before releasing the Huygens probe on 25 December 2004. Huygens descended onto the surface of Titan on 14 January 2005, sending a flood of data during the atmospheric descent and after the landing. "Cassini" has since conducted multiple flybys of Titan and other icy satellites.
Since early 2005, scientists have been tracking lightning on Saturn. The power of the lightning is approximately 1,000 times that of lightning on Earth.
In 2006, NASA reported that "Cassini" had found evidence of liquid water reservoirs that erupt in geysers on Saturn's moon Enceladus. Images had shown jets of icy particles being emitted into orbit around Saturn from vents in the moon's south polar region. According to Andrew Ingersoll, California Institute of Technology, "Other moons in the Solar System have liquid-water oceans covered by kilometers of icy crust. What's different here is that pockets of liquid water may be no more than tens of meters below the surface." Over 100 geysers have been identified on Enceladus. In May 2011, NASA scientists at an Enceladus Focus Group Conference reported that Enceladus "is emerging as the most habitable spot beyond Earth in the Solar System for life as we know it".
"Cassini" photographs have led to other significant discoveries. They have revealed a previously undiscovered planetary ring, outside the brighter main rings of Saturn and inside the G and E rings. The source of this ring is believed to be the crashing of a meteoroid off two of the moons of Saturn. In July 2006, "Cassini" images provided evidence of hydrocarbon lakes near Titan's north pole, the presence of which were confirmed in January 2007. In March 2007, additional images near Titan's north pole revealed hydrocarbon seas, the largest of which is almost the size of the Caspian Sea. In October 2006, the probe detected an 8,000 km diameter cyclone-like storm with an eyewall at Saturn's south pole.
From 2004 to 2 November 2009, the probe discovered and confirmed 8 new satellites. Its primary mission ended in 2008 when the spacecraft had completed 74 orbits around the planet. The probe's mission was extended to September 2010 and then extended again to 2017, to study a full period of Saturn's seasons.
In April 2013 Cassini sent back images of a hurricane at the planet's north pole 20 times larger than those found on Earth, with winds faster than 530 km/h.
On 19 July 2013, Cassini was pointed towards Earth to capture an image of the Earth and the Moon (and, as well, Venus and Mars) as part of a natural light, multi-image portrait of the entire Saturn system. It was the first time NASA informed the people of Earth that a long-distance photo was being taken in advance.
Observation.
Saturn is the most distant of the five planets easily visible to the naked eye, the other four being Mercury, Venus, Mars and Jupiter. (Uranus and occasionally 4 Vesta are visible to the naked eye in dark skies.) Saturn appears to the naked eye in the night sky as a bright, yellowish point of light with an apparent magnitude of usually between +1 and 0. It takes approximately 29.5 years for the planet to complete an entire circuit of the ecliptic against the background constellations of the zodiac. Most people will require an optical aid (very large binoculars or a small telescope) that magnifies at least 30 times to achieve an image of Saturn's rings, in which clear resolution is present. Twice every Saturnian year (roughly every 15 Earth years), the rings briefly disappear from view, due to the way in which they are angled and because they are so thin. Such a "disappearance" will next occur in 2025, but Saturn will be too close to the Sun for any ring-crossing observation to be possible.
Saturn and its rings are best seen when the planet is at, or near, opposition, the configuration of a planet when it is at an elongation of 180°, and thus appears opposite the Sun in the sky. A Saturnian opposition occurs every year—approximately every 378 days—and results in the planet appearing at its brightest. However, both the Earth and Saturn orbit the Sun on eccentric orbits, which means their distances from the Sun vary over time, and therefore so do their distances from each other, hence varying the brightness of Saturn from one opposition to the other. Also, Saturn appears brighter when the rings are angled such that they are more visible. For example, during the opposition of 17 December 2002, Saturn appeared at its brightest due to a favorable relative to the Earth, even though Saturn was closer to the Earth and Sun in late 2003. 
Also, from time to time Saturn is occulted by the Moon (that is, the Moon covers up Saturn in the sky). As with all the planets in the Solar System, occultations of Saturn occur in “seasons”. Saturnian occultations will take place 12 or more times over a 12-month period, followed by about a five-year period in which no such activity is registered. Australian astronomy experts Hill and Horner explain the seasonal nature of Saturnian occultations:
This is the result of the fact that the moon’s orbit around the Earth is tilted to the orbit of the Earth around the Sun – and so most of the time, the moon will pass above or below Saturn in the sky, and no occultation will occur. It is only when Saturn lies near the point that the moon’s orbit crosses the “plane of the ecliptic” that occultations can happen – and then they occur every time the moon swings by, until Saturn moves away from the crossing point.
See also.
 |1=Saturn
 |3=Solar System

</doc>
<doc id="44475" url="http://en.wikipedia.org/wiki?curid=44475" title="Uranus">
Uranus

Uranus is the seventh planet from the Sun. It has the third-largest planetary radius and fourth-largest planetary mass in the Solar System. Uranus is similar in composition to Neptune, and both have different bulk chemical composition from that of the larger gas giants Jupiter and Saturn. Therefore, astronomers increasingly place them in a separate category called "ice giants". Uranus's atmosphere, although similar to Jupiter's and Saturn's in its primary composition of hydrogen and helium, contains more "ices", such as water, ammonia, and methane, along with traces of other hydrocarbons. It is the coldest planetary atmosphere in the Solar System, with a minimum temperature of 49 K, and has a complex, layered cloud structure, with water thought to make up the lowest clouds, and methane the uppermost layer of clouds. The interior of Uranus is mainly composed of ices and rock.
Uranus is the only planet whose name is derived from a figure from Greek mythology rather than Roman mythology, from the Latinized version of the Greek god of the sky, Ouranos. Like the other giant planets, Uranus has a ring system, a magnetosphere, and numerous moons. The Uranian system has a unique configuration among those of the planets because its axis of rotation is tilted sideways, nearly into the plane of its revolution about the Sun. Its north and south poles therefore lie where most other planets have their equators. In 1986, images from "Voyager 2" showed Uranus as an almost featureless planet in visible light, without the cloud bands or storms associated with the other giant planets. Observations from Earth have shown seasonal change and increased weather activity as Uranus approached its equinox in 2007. The wind speeds on Uranus can reach 250 metres per second (900 km/h, 560 mph).
History.
Though Uranus is visible to the naked eye like the five classical planets, it was never recognized as a planet by ancient observers because of its dimness and slow orbit. Sir William Herschel announced its discovery on March 13, 1781, expanding the known boundaries of the Solar System for the first time in history. Uranus was the first planet discovered with a telescope.
Discovery.
Uranus had been observed on many occasions before its recognition as a planet, but it was generally mistaken for a star. Possibly the earliest known observation was by Hipparchos, who in 128BC may have recorded the planet as a star for his star catalogue that was later incorporated into Ptolemy's Almagest. The earliest definite sighting was in 1690 when John Flamsteed observed it at least six times, cataloguing it as 34 Tauri. The French astronomer Pierre Lemonnier observed Uranus at least twelve times between 1750 and 1769, including on four consecutive nights.
Sir William Herschel observed Uranus on March 13, 1781 from the garden of his house at 19 New King Street in Bath, Somerset, England (now the Herschel Museum of Astronomy), and initially reported it (on April 26, 1781) as a comet. Herschel "engaged in a series of observations on the parallax of the fixed stars", using a telescope of his own design.
He recorded in his journal "In the quartile near ζ Tauri ... either [a] Nebulous star or perhaps a comet". On March 17, he noted, "I looked for the Comet or Nebulous Star and found that it is a Comet, for it has changed its place". When he presented his discovery to the Royal Society, he continued to assert that he had found a comet, but also implicitly compared it to a planet:
"The power I had on when I first saw the comet was 227. From experience I know that the diameters of the fixed stars are not proportionally magnified with higher powers, as planets are; therefore I now put the powers at 460 and 932, and found that the diameter of the comet increased in proportion to the power, as it ought to be, on the supposition of its not being a fixed star, while the diameters of the stars to which I compared it were not increased in the same ratio. Moreover, the comet being magnified much beyond what its light would admit of, appeared hazy and ill-defined with these great powers, while the stars preserved that lustre and distinctness which from many thousand observations I knew they would retain. The sequel has shown that my surmises were well-founded, this proving to be the Comet we have lately observed".
Herschel notified the Astronomer Royal, Nevil Maskelyne, of his discovery and received this flummoxed reply from him on April 23: "I don't know what to call it. It is as likely to be a regular planet moving in an orbit nearly circular to the sun as a Comet moving in a very eccentric ellipsis. I have not yet seen any coma or tail to it".
Although Herschel continued to describe his new object as a comet, other astronomers had already begun to suspect otherwise. Russian astronomer Anders Johan Lexell was the first to compute the orbit of the new object and its nearly circular orbit led him to a conclusion that it was a planet rather than a comet. Berlin astronomer Johann Elert Bode described Herschel's discovery as "a moving star that can be deemed a hitherto unknown planet-like object circulating beyond the orbit of Saturn". Bode concluded that its near-circular orbit was more like a planet than a comet.
The object was soon universally accepted as a new planet. By 1783, Herschel acknowledged this to Royal Society president Joseph Banks: "By the observation of the most eminent Astronomers in Europe it appears that the new star, which I had the honour of pointing out to them in March 1781, is a Primary Planet of our Solar System." In recognition of his achievement, King George III gave Herschel an annual stipend of £200 on condition that he move to Windsor so that the Royal Family could look through his telescopes.
Naming.
Maskelyne asked Herschel to "do the astronomical world the faver ["sic"] to give a name to your planet, which is entirely your own, [and] which we are so much obliged to you for the discovery of". In response to Maskelyne's request, Herschel decided to name the object "Georgium Sidus" (George's Star), or the "Georgian Planet" in honour of his new patron, King George III. He explained this decision in a letter to Joseph Banks:
In the fabulous ages of ancient times the appellations of Mercury, Venus, Mars, Jupiter and Saturn were given to the Planets, as being the names of their principal heroes and divinities. In the present more philosophical era it would hardly be allowable to have recourse to the same method and call it Juno, Pallas, Apollo or Minerva, for a name to our new heavenly body. The first consideration of any particular event, or remarkable incident, seems to be its chronology: if in any future age it should be asked, when this last-found Planet was discovered? It would be a very satisfactory answer to say, 'In the reign of King George the Third'.
Herschel's proposed name was not popular outside Britain, and alternatives were soon proposed. Astronomer Jérôme Lalande proposed that it be named "Herschel" in honour of its discoverer. Swedish astronomer Erik Prosperin proposed the name "Neptune", which was supported by other astronomers who liked the idea to commemorate the victories of the British Royal Naval fleet in the course of the American Revolutionary War by calling the new planet even "Neptune George III" or "Neptune Great Britain". Bode opted for "Uranus", the Latinized version of the Greek god of the sky, Ouranos. Bode argued that just as Saturn was the father of Jupiter, the new planet should be named after the father of Saturn. In 1789, Bode's Royal Academy colleague Martin Klaproth named his newly discovered element uranium in support of Bode's choice. Ultimately, Bode's suggestion became the most widely used, and became universal in 1850 when HM Nautical Almanac Office, the final holdout, switched from using "Georgium Sidus" to "Uranus".
Name.
Uranus is named after the ancient Greek deity of the sky Uranus (Ancient Greek: Οὐρανός), the father of Cronus (Saturn) and grandfather of Zeus (Jupiter), which in Latin became "Ūranus". It is the only planet whose name is derived from a figure from Greek mythology rather than Roman mythology. The adjective of Uranus is "Uranian". The pronunciation of the name "Uranus" preferred among astronomers is , with stress on the first syllable as in Latin "Ūranus," in contrast to the colloquial , with stress on the second syllable and a long "a", though both are considered acceptable.
Uranus has two astronomical symbols. The first to be proposed, ♅, was suggested by Lalande in 1784. In a letter to Herschel, Lalande described it as "un globe surmonté par la première lettre de votre nom" ("a globe surmounted by the first letter of your surname"). A later proposal, ⛢, is a hybrid of the symbols for Mars and the Sun because Uranus was the Sky in Greek mythology, which was thought to be dominated by the combined powers of the Sun and Mars. In Chinese, Japanese, Korean, and Vietnamese, its name is literally translated as the "sky king star" (天王星).
Orbit and rotation.
Uranus orbits the Sun once every 84 Earth years. Its average distance from the Sun is roughly 3 billion km (about 20 AU). The variation of that distance is greater than that of any other planet, at 1.8 AU. The intensity of sunlight reduces quadratically with distance, and therefore on Uranus, at about 20 times the distance from the Sun compared to Earth, it is about 1/400 the intensity of light on Earth. Its orbital elements were first calculated in 1783 by Pierre-Simon Laplace. With time, discrepancies began to appear between the predicted and observed orbits, and in 1841, John Couch Adams first proposed that the differences might be due to the gravitational tug of an unseen planet. In 1845, Urbain Le Verrier began his own independent research into Uranus's orbit. On September 23, 1846, Johann Gottfried Galle located a new planet, later named Neptune, at nearly the position predicted by Le Verrier.
The rotational period of the interior of Uranus is 17 hours, 14 minutes, clockwise (retrograde). As on all giant planets, its upper atmosphere experiences strong winds in the direction of rotation. At some latitudes, such as about 60 degrees south, visible features of the atmosphere move much faster, making a full rotation in as little as 14 hours.
Axial tilt.
Uranus has an axial tilt of 97.77°, so its axis of rotation is approximately parallel with the plane of the Solar System. This gives it seasonal changes completely unlike those of the other major planets. Other planets can be visualized to rotate like tilted spinning tops on the plane of the Solar System, but Uranus rotates more like a tilted rolling ball. Near the time of Uranian solstices, one pole faces the Sun continuously and the other one faces away. Only a narrow strip around the equator experiences a rapid day–night cycle, but with the Sun low over the horizon as in Earth's polar regions. At the other side of Uranus's orbit the orientation of the poles towards the Sun is reversed. Each pole gets around 42 years of continuous sunlight, followed by 42 years of darkness. Near the time of the equinoxes, the Sun faces the equator of Uranus giving a period of day–night cycles similar to those seen on most of the other planets. Uranus reached its most recent equinox on December 7, 2007.
One result of this axis orientation is that, averaged over the Uranian year, the polar regions of Uranus receive a greater energy input from the Sun than its equatorial regions. Nevertheless, Uranus is hotter at its equator than at its poles. The underlying mechanism that causes this is unknown. The reason for Uranus's unusual axial tilt is also not known with certainty, but the usual speculation is that during the formation of the Solar System, an Earth-sized protoplanet collided with Uranus, causing the skewed orientation. Uranus's south pole was pointed almost directly at the Sun at the time of "Voyager 2"'s flyby in 1986. The labelling of this pole as "south" uses the definition currently endorsed by the International Astronomical Union, namely that the north pole of a planet or satellite is the pole that points above the invariable plane of the Solar System, regardless of the direction the planet is spinning. A different convention is sometimes used, in which a body's north and south poles are defined according to the right-hand rule in relation to the direction of rotation. In terms of this system it was Uranus's north pole that was in sunlight in 1986.
Visibility.
From 1995 to 2006, Uranus's apparent magnitude fluctuated between +5.6 and +5.9, placing it just within the limit of naked eye visibility at +6.5. Its angular diameter is between 3.4 and 3.7 arcseconds, compared with 16 to 20 arcseconds for Saturn and 32 to 45 arcseconds for Jupiter. At opposition, Uranus is visible to the naked eye in dark skies, and becomes an easy target even in urban conditions with binoculars. In larger amateur telescopes with an objective diameter of between 15 and 23 cm, Uranus appears as a pale cyan disk with distinct limb darkening. With a large telescope of 25 cm or wider, cloud patterns, as well as some of the larger satellites, such as Titania and Oberon, may be visible.
Internal structure.
Uranus's mass is roughly 14.5 times that of Earth, making it the least massive of the giant planets. Its diameter is slightly larger than Neptune's at roughly four times that of Earth. A resulting density of 1.27 g/cm3 makes Uranus the second least dense planet, after Saturn. This value indicates that it is made primarily of various ices, such as water, ammonia, and methane. The total mass of ice in Uranus's interior is not precisely known, because different figures emerge depending on the model chosen; it must be between 9.3 and 13.5 Earth masses. Hydrogen and helium constitute only a small part of the total, with between 0.5 and 1.5 Earth masses. The remainder of the non-ice mass (0.5 to 3.7 Earth masses) is accounted for by rocky material.
The standard model of Uranus's structure is that it consists of three layers: a rocky (silicate/iron–nickel) core in the centre, an icy mantle in the middle and an outer gaseous hydrogen/helium envelope. The core is relatively small, with a mass of only 0.55 Earth masses and a radius less than 20% of Uranus's; the mantle comprises its bulk, with around 13.4 Earth masses, and the upper atmosphere is relatively insubstantial, weighing about 0.5 Earth masses and extending for the last 20% of Uranus's radius. Uranus's core density is around 9 g/cm3, with a pressure in the center of 8 million bars (800 GPa) and a temperature of about 5000 K. The ice mantle is not in fact composed of ice in the conventional sense, but of a hot and dense fluid consisting of water, ammonia and other volatiles. This fluid, which has a high electrical conductivity, is sometimes called a water–ammonia ocean.
According to research conducted at the University of California, Berkeley, the extreme pressure and temperature deep within Uranus may break up the methane molecules, with the carbon atoms condensing into crystals of diamond that rain down through the mantle like hailstones. Very-high-pressure experiments at the Lawrence Livermore National Laboratory suggest that the base of the mantle may comprise an ocean of liquid diamond, with floating solid 'diamond-bergs'.
The bulk compositions of Uranus and Neptune are different from those of Jupiter and Saturn, with ice dominating over gases, hence justifying their separate classification as ice giants. There may be a layer of ionic water where the water molecules break down into a soup of hydrogen and oxygen ions, and deeper down superionic water in which the oxygen crystallises but the hydrogen ions move freely within the oxygen lattice.
Although the model considered above is reasonably standard, it is not unique; other models also satisfy observations. For instance, if substantial amounts of hydrogen and rocky material are mixed in the ice mantle, the total mass of ices in the interior will be lower, and, correspondingly, the total mass of rocks and hydrogen will be higher. Presently available data does not allow science to determine which model is correct. The fluid interior structure of Uranus means that it has no solid surface. The gaseous atmosphere gradually transitions into the internal liquid layers. For the sake of convenience, a revolving oblate spheroid set at the point at which atmospheric pressure equals 1 bar (100 kPa) is conditionally designated as a "surface". It has equatorial and polar radii of 25 559 ± 4 and 24 973 ± 20 km, respectively. This surface is used throughout this article as a zero point for altitudes.
Internal heat.
Uranus's internal heat appears markedly lower than that of the other giant planets; in astronomical terms, it has a low thermal flux. Why Uranus's internal temperature is so low is still not understood. Neptune, which is Uranus's near twin in size and composition, radiates 2.61 times as much energy into space as it receives from the Sun, but Uranus radiates hardly any excess heat at all. The total power radiated by Uranus in the far infrared (i.e. heat) part of the spectrum is 1.06 ± 0.08 times the solar energy absorbed in its atmosphere. Uranus's heat flux is only 0.042 ± 0.047 W/m2, which is lower than the internal heat flux of Earth of about 0.075 W/m2. The lowest temperature recorded in Uranus's tropopause is 49 K (−224 °C), making Uranus the coldest planet in the Solar System.
One of the hypotheses for this discrepancy suggests that when Uranus was hit by a supermassive impactor, which caused it to expel most of its primordial heat, it was left with a depleted core temperature. Another hypothesis is that some form of barrier exists in Uranus's upper layers that prevents the core's heat from reaching the surface. For example, convection may take place in a set of compositionally different layers, which may inhibit the upward heat transport; perhaps double diffusive convection is a limiting factor.
Atmosphere.
Although there is no well-defined solid surface within Uranus's interior, the outermost part of Uranus's gaseous envelope that is accessible to remote sensing is called its atmosphere. Remote-sensing capability extends down to roughly 300 km below the 1 bar (100 kPa) level, with a corresponding pressure around 100 bar (10 MPa) and temperature of 320 K. The tenuous corona of the atmosphere extends over two planetary radii from the nominal surface, which is defined to lie at a pressure of 1 bar. The Uranian atmosphere can be divided into three layers: the troposphere, between altitudes of −300 and 50 km and pressures from 100 to 0.1 bar (10 MPa to 10 kPa); the stratosphere, spanning altitudes between 50 and 4000 km and pressures of between 0.1 and 10−10 bar (10 kPa to 10 µPa); and the thermosphere/corona extending from 4,000 km to as high as 50,000 km from the surface. There is no mesosphere.
Composition.
The composition of Uranus's atmosphere is different from its bulk, consisting mainly of molecular hydrogen and helium. The helium molar fraction, i.e. the number of helium atoms per molecule of gas, is 0.15 ± 0.03 in the upper troposphere, which corresponds to a mass fraction 0.26 ± 0.05. This value is close to the protosolar helium mass fraction of 0.275 ± 0.01, indicating that helium has not settled in its centre as it has in the gas giants. The third-most-abundant component in Uranus's atmosphere is methane (CH4). Methane has prominent absorption bands in the visible and near-infrared (IR), making Uranus aquamarine or cyan in colour. Methane molecules account for 2.3% of the atmosphere by molar fraction below the methane cloud deck at the pressure level of 1.3 bar (130 kPa); this represents about 20 to 30 times the carbon abundance found in the Sun. The mixing ratio is much lower in the upper atmosphere due to its extremely low temperature, which lowers the saturation level and causes excess methane to freeze out. The abundances of less volatile compounds such as ammonia, water, and hydrogen sulfide in the deep atmosphere are poorly known. They are probably also higher than solar values. Along with methane, trace amounts of various hydrocarbons are found in the stratosphere of Uranus, which are thought to be produced from methane by photolysis induced by the solar ultraviolet (UV) radiation. They include ethane (C2H6), acetylene (C2H2), methylacetylene (CH3C2H), and diacetylene (C2HC2H). Spectroscopy has also uncovered traces of water vapor, carbon monoxide and carbon dioxide in the upper atmosphere, which can only originate from an external source such as infalling dust and comets.
Troposphere.
The troposphere is the lowest and densest part of the atmosphere and is characterized by a decrease in temperature with altitude. The temperature falls from about 320 K at the base of the nominal troposphere at −300 km to 53 K at 50 km. The temperatures in the coldest upper region of the troposphere (the tropopause) actually vary in the range between 49 and 57 K depending on planetary latitude. The tropopause region is responsible for the vast majority of Uranus's thermal far infrared emissions, thus determining its effective temperature of 59.1 ± 0.3 K.
The troposphere is believed to possess a highly complex cloud structure; water clouds are hypothesised to lie in the pressure range of 50 to 100 bar (5 to 10 MPa), ammonium hydrosulfide clouds in the range of 20 to 40 bar (2 to 4 MPa), ammonia or hydrogen sulfide clouds at between 3 and 10 bar (0.3 to 1 MPa) and finally directly detected thin methane clouds at 1 to 2 bar (0.1 to 0.2 MPa). The troposphere is a dynamic part of the atmosphere, exhibiting strong winds, bright clouds and seasonal changes.
Upper atmosphere.
The middle layer of the Uranian atmosphere is the stratosphere, where temperature generally increases with altitude from 53 K in the tropopause to between 800 and 850 K at the base of the thermosphere. The heating of the stratosphere is caused by absorption of solar UV and IR radiation by methane and other hydrocarbons, which form in this part of the atmosphere as a result of methane photolysis. Heat is also conducted from the hot thermosphere. The hydrocarbons occupy a relatively narrow layer at altitudes of between 100 and 300 km corresponding to a pressure range of 10 to 0.1 mbar (1000 to 10 kPa) and temperatures of between 75 and 170 K. The most abundant hydrocarbons are methane, acetylene and ethane with mixing ratios of around 10−7 relative to hydrogen. The mixing ratio of carbon monoxide is similar at these altitudes. Heavier hydrocarbons and carbon dioxide have mixing ratios three orders of magnitude lower. The abundance ratio of water is around 7×10-9. Ethane and acetylene tend to condense in the colder lower part of stratosphere and tropopause (below 10 mBar level) forming haze layers, which may be partly responsible for the bland appearance of Uranus. The concentration of hydrocarbons in the Uranian stratosphere above the haze is significantly lower than in the stratospheres of the other giant planets.
The outermost layer of the Uranian atmosphere is the thermosphere and corona, which has a uniform temperature around 800 to 850 K. The heat sources necessary to sustain such a high level are not understood, as neither the solar UV nor the auroral activity can provide the necessary energy to maintain these temperatures. The weak cooling efficiency due to the lack of hydrocarbons in the stratosphere above 0.1 mBar pressure level may contribute too. In addition to molecular hydrogen, the thermosphere-corona contains many free hydrogen atoms. Their small mass and high temperatures explain why the corona extends as far as 50 000 km, or two Uranian radii, from its surface. This extended corona is a unique feature of Uranus. Its effects include a drag on small particles orbiting Uranus, causing a general depletion of dust in the Uranian rings. The Uranian thermosphere, together with the upper part of the stratosphere, corresponds to the ionosphere of Uranus. Observations show that the ionosphere occupies altitudes from 2 000 to 10 000 km. The Uranian ionosphere is denser than that of either Saturn or Neptune, which may arise from the low concentration of hydrocarbons in the stratosphere. The ionosphere is mainly sustained by solar UV radiation and its density depends on the solar activity. Auroral activity is insignificant as compared to Jupiter and Saturn.
Planetary rings.
The rings are composed of extremely dark particles, which vary in size from micrometres to a fraction of a metre. Thirteen distinct rings are presently known, the brightest being the ε ring. All except two rings of Uranus are extremely narrow – they are usually a few kilometres wide. The rings are probably quite young; the dynamics considerations indicate that they did not form with Uranus. The matter in the rings may once have been part of a moon (or moons) that was shattered by high-speed impacts. From numerous pieces of debris that formed as a result of those impacts, only a few particles survived, in stable zones corresponding to the locations of the present rings.
William Herschel described a possible ring around Uranus in 1789. This sighting is generally considered doubtful, because the rings are quite faint, and in the two following centuries none were noted by other observers. Still, Herschel made an accurate description of the epsilon ring's size, its angle relative to Earth, its red colour, and its apparent changes as Uranus travelled around the Sun. The ring system was definitively discovered on March 10, 1977 by James L. Elliot, Edward W. Dunham, and Jessica Mink using the Kuiper Airborne Observatory. The discovery was serendipitous; they planned to use the occultation of the star SAO 158687 (also known as HD 128598) by Uranus to study its atmosphere. When their observations were analysed, they found that the star had disappeared briefly from view five times both before and after it disappeared behind Uranus. They concluded that there must be a ring system around Uranus. Later they detected four additional rings. The rings were directly imaged when "Voyager 2" passed Uranus in 1986. "Voyager 2" also discovered two additional faint rings, bringing the total number to eleven.
In December 2005, the Hubble Space Telescope detected a pair of previously unknown rings. The largest is located twice as far from Uranus as the previously known rings. These new rings are so far from Uranus that they are called the "outer" ring system. Hubble also spotted two small satellites, one of which, Mab, shares its orbit with the outermost newly discovered ring. The new rings bring the total number of Uranian rings to 13. In April 2006, images of the new rings from the Keck Observatory yielded the colours of the outer rings: the outermost is blue and the other one red.
One hypothesis concerning the outer ring's blue colour is that it is composed of minute particles of water ice from the surface of Mab that are small enough to scatter blue light. In contrast, Uranus's inner rings appear grey.
Magnetosphere.
Before the arrival of "Voyager 2", no measurements of the Uranian magnetosphere had been taken, so its nature remained a mystery. Before 1986, astronomers had expected the magnetic field of Uranus to be in line with the solar wind, because it would then align with Uranus's poles that lie in the ecliptic.
"Voyager"'s observations revealed that Uranus's magnetic field is peculiar, both because it does not originate from its geometric centre, and because it is tilted at 59° from the axis of rotation. In fact the magnetic dipole is shifted from the Uranus's center towards the south rotational pole by as much as one third of the planetary radius. This unusual geometry results in a highly asymmetric magnetosphere, where the magnetic field strength on the surface in the southern hemisphere can be as low as 0.1 gauss (10 µT), whereas in the northern hemisphere it can be as high as 1.1 gauss (110 µT). The average field at the surface is 0.23 gauss (23 µT). In comparison, the magnetic field of Earth is roughly as strong at either pole, and its "magnetic equator" is roughly parallel with its geographical equator. The dipole moment of Uranus is 50 times that of Earth. Neptune has a similarly displaced and tilted magnetic field, suggesting that this may be a common feature of ice giants. One hypothesis is that, unlike the magnetic fields of the terrestrial and gas giants, which are generated within their cores, the ice giants' magnetic fields are generated by motion at relatively shallow depths, for instance, in the water–ammonia ocean. Another possible explanation for the magnetosphere's alignment is that there are oceans of liquid diamond in Uranus's interior that would deter the magnetic field.
Despite its curious alignment, in other respects the Uranian magnetosphere is like those of other planets: it has a bow shock at about 23 Uranian radii ahead of it, a magnetopause at 18 Uranian radii, a fully developed magnetotail, and radiation belts. Overall, the structure of Uranus's magnetosphere is different from Jupiter's and more similar to Saturn's. Uranus's magnetotail trails behind it into space for millions of kilometres and is twisted by its sideways rotation into a long corkscrew.
Uranus's magnetosphere contains charged particles: mainly protons and electrons, with a small amount of H2+ ions. No heavier ions have been detected. Many of these particles probably derive from the hot atmospheric corona. The ion and electron energies can be as high as 4 and 1.2 megaelectronvolts, respectively. The density of low-energy (below 1 kiloelectronvolt) ions in the inner magnetosphere is about 2 cm−3. The particle population is strongly affected by the Uranian moons, which sweep through the magnetosphere, leaving noticeable gaps. The particle flux is high enough to cause darkening or space weathering of their surfaces on an astronomically rapid timescale of 100,000 years. This may be the cause of the uniformly dark colouration of the Uranian satellites and rings. Uranus has relatively well developed aurorae, which are seen as bright arcs around both magnetic poles. Unlike Jupiter's, Uranus's aurorae seem to be insignificant for the energy balance of the planetary thermosphere.
Climate.
At ultraviolet and visible wavelengths, Uranus's atmosphere is bland in comparison to the other giant planets, even to Neptune, which it otherwise closely resembles. When "Voyager 2" flew by Uranus in 1986, it observed a total of ten cloud features across the entire planet. One proposed explanation for this dearth of features is that Uranus's internal heat appears markedly lower than that of the other giant planets. The lowest temperature recorded in Uranus's tropopause is 49 K, making Uranus the coldest planet in the Solar System, colder than Neptune.
Banded structure, winds and clouds.
In 1986, "Voyager 2" found that the visible southern hemisphere of Uranus can be subdivided into two regions: a bright polar cap and dark equatorial bands. Their boundary is located at about −45° of latitude. A narrow band straddling the latitudinal range from −45 to −50° is the brightest large feature on its visible surface. It is called a southern "collar". The cap and collar are thought to be a dense region of methane clouds located within the pressure range of 1.3 to 2 bar (see above). Besides the large-scale banded structure, Voyager 2 observed ten small bright clouds, most lying several degrees to the north from the collar. In all other respects Uranus looked like a dynamically dead planet in 1986. Voyager 2 arrived during the height of Uranus's southern summer and could not observe the northern hemisphere. At the beginning of the 21st century, when the northern polar region came into view, the Hubble Space Telescope (HST) and Keck telescope initially observed neither a collar nor a polar cap in the northern hemisphere. So Uranus appeared to be asymmetric: bright near the south pole and uniformly dark in the region north of the southern collar. In 2007, when Uranus passed its equinox, the southern collar almost disappeared, and a faint northern collar emerged near 45° of latitude.
In the 1990s, the number of the observed bright cloud features grew considerably partly because new high-resolution imaging techniques became available. Most were found in the northern hemisphere as it started to become visible. An early explanation—that bright clouds are easier to identify in its dark part, whereas in the southern hemisphere the bright collar masks them – was shown to be incorrect. Nevertheless there are differences between the clouds of each hemisphere. The northern clouds are smaller, sharper and brighter. They appear to lie at a higher altitude. The lifetime of clouds spans several orders of magnitude. Some small clouds live for hours; at least one southern cloud may have persisted since the Voyager flyby. Recent observation also discovered that cloud features on Uranus have a lot in common with those on Neptune. For example, the dark spots common on Neptune had never been observed on Uranus before 2006, when the first such feature dubbed Uranus Dark Spot was imaged. The speculation is that Uranus is becoming more Neptune-like during its equinoctial season.
The tracking of numerous cloud features allowed determination of zonal winds blowing in the upper troposphere of Uranus. At the equator winds are retrograde, which means that they blow in the reverse direction to the planetary rotation. Their speeds are from −100 to −50 m/s. Wind speeds increase with the distance from the equator, reaching zero values near ±20° latitude, where the troposphere's temperature minimum is located. Closer to the poles, the winds shift to a prograde direction, flowing with Uranus's rotation. Wind speeds continue to increase reaching maxima at ±60° latitude before falling to zero at the poles. Wind speeds at −40° latitude range from 150 to 200 m/s. Because the collar obscures all clouds below that parallel, speeds between it and the southern pole are impossible to measure. In contrast, in the northern hemisphere maximum speeds as high as 240 m/s are observed near +50° latitude.
Seasonal variation.
For a short period from March to May 2004, large clouds appeared in the Uranian atmosphere, giving it a Neptune-like appearance. Observations included record-breaking wind speeds of 229 m/s (824 km/h) and a persistent thunderstorm referred to as "Fourth of July fireworks". On August 23, 2006, researchers at the Space Science Institute (Boulder, Colorado) and the University of Wisconsin observed a dark spot on Uranus's surface, giving astronomers more insight into Uranus's atmospheric activity. Why this sudden upsurge in activity occurred is not fully known, but it appears that Uranus's extreme axial tilt results in extreme seasonal variations in its weather. Determining the nature of this seasonal variation is difficult because good data on Uranus's atmosphere have existed for less than 84 years, or one full Uranian year. Photometry over the course of half a Uranian year (beginning in the 1950s) has shown regular variation in the brightness in two spectral bands, with maxima occurring at the solstices and minima occurring at the equinoxes. A similar periodic variation, with maxima at the solstices, has been noted in microwave measurements of the deep troposphere begun in the 1960s. Stratospheric temperature measurements beginning in the 1970s also showed maximum values near the 1986 solstice. The majority of this variability is believed to occur owing to changes in the viewing geometry.
There are some reasons to believe that physical seasonal changes are happening in Uranus. Although Uranus is known to have a bright south polar region, the north pole is fairly dim, which is incompatible with the model of the seasonal change outlined above. During its previous northern solstice in 1944, Uranus displayed elevated levels of brightness, which suggests that the north pole was not always so dim. This information implies that the visible pole brightens some time before the solstice and darkens after the equinox. Detailed analysis of the visible and microwave data revealed that the periodical changes of brightness are not completely symmetrical around the solstices, which also indicates a change in the meridional albedo patterns. In the 1990s, as Uranus moved away from its solstice, Hubble and ground-based telescopes revealed that the south polar cap darkened noticeably (except the southern collar, which remained bright), whereas the northern hemisphere demonstrated increasing activity, such as cloud formations and stronger winds, bolstering expectations that it should brighten soon. This indeed happened in 2007 when it passed an equinox: a faint northern polar collar arose, and the southern collar became nearly invisible, although the zonal wind profile remained slightly asymmetric, with northern winds being somewhat slower than southern.
The mechanism of these physical changes is still not clear. Near the summer and winter solstices, Uranus's hemispheres lie alternately either in full glare of the Sun's rays or facing deep space. The brightening of the sunlit hemisphere is thought to result from the local thickening of the methane clouds and haze layers located in the troposphere. The bright collar at −45° latitude is also connected with methane clouds. Other changes in the southern polar region can be explained by changes in the lower cloud layers. The variation of the microwave emission from Uranus is probably caused by changes in the deep tropospheric circulation, because thick polar clouds and haze may inhibit convection. Now that the spring and autumn equinoxes are arriving on Uranus, the dynamics are changing and convection can occur again.
Formation.
Many argue that the differences between the ice giants and the gas giants extend to their formation. The Solar System is believed to have formed from a giant rotating ball of gas and dust known as the presolar nebula. Much of the nebula's gas, primarily hydrogen and helium, formed the Sun, and the dust grains collected together to form the first protoplanets. As the planets grew, some of them eventually accreted enough matter for their gravity to hold on to the nebula's leftover gas. The more gas they held onto, the larger they became; the larger they became, the more gas they held onto until a critical point was reached, and their size began to increase exponentially. The ice giants, with only a few Earth masses of nebular gas, never reached that critical point. Recent simulations of planetary migration have suggested that both ice giants formed closer to the Sun than their present positions, and moved outwards after formation (the Nice model).
Moons.
Uranus has 27 known natural satellites. The names of these satellites are chosen from characters in the works of Shakespeare and Alexander Pope. The five main satellites are Miranda, Ariel, Umbriel, Titania, and Oberon. The Uranian satellite system is the least massive among those of the giant planets; the combined mass of the five major satellites would be less than half that of Triton (largest moon of Neptune) alone. The largest of Uranus's satellites, Titania, has a radius of only 788.9 km, or less than half that of the Moon, but slightly more than Rhea, the second-largest satellite of Saturn, making Titania the eighth-largest moon in the Solar System. Uranus's satellites have relatively low albedos; ranging from 0.20 for Umbriel to 0.35 for Ariel (in green light). They are ice–rock conglomerates composed of roughly 50% ice and 50% rock. The ice may include ammonia and carbon dioxide.
Among the Uranian satellites, Ariel appears to have the youngest surface with the fewest impact craters and Umbriel's the oldest. Miranda possesses fault canyons 20 kilometres deep, terraced layers, and a chaotic variation in surface ages and features. Miranda's past geologic activity is believed to have been driven by tidal heating at a time when its orbit was more eccentric than currently, probably as a result of a former 3:1 orbital resonance with Umbriel. Extensional processes associated with upwelling diapirs are the likely origin of Miranda's 'racetrack'-like coronae. Ariel is believed to have once been held in a 4:1 resonance with Titania.
Uranus possesses at least one horseshoe orbiter occupying the Sun–Uranus L3 Lagrangian point—a gravitationally unstable region at 180º in its orbit, 83982 Crantor. Crantor moves inside Uranus's co-orbital region on a complex, temporary horseshoe orbit.
2010 EU65 is also a promising Uranus horseshoe librator candidate.
Exploration.
In 1986, NASA's "Voyager 2" interplanetary probe encountered Uranus. This flyby remains the only investigation of Uranus carried out from a short distance and no other visits are planned. Launched in 1977, "Voyager 2" made its closest approach to Uranus on January 24, 1986, coming within 81,500 kilometres of the cloudtops, before continuing its journey to Neptune. "Voyager 2" studied the structure and chemical composition of Uranus's atmosphere, including its unique weather, caused by its axial tilt of 97.77°. It made the first detailed investigations of its five largest moons and discovered 10 new ones. It examined all nine of the system's known rings and discovered two more. It also studied the magnetic field, its irregular structure, its tilt and its unique corkscrew magnetotail caused by Uranus's sideways orientation.
The possibility of sending the Cassini spacecraft from Saturn to Uranus was evaluated during a mission extension planning phase in 2009. It would take about twenty years to get to the Uranian system after departing Saturn. A Uranus orbiter and probe was recommended by the 2013–2022 Planetary Science Decadal Survey published in 2011; the proposal envisages launch during 2020–2023 and a 13-year cruise to Uranus. A Uranus entry probe could use Pioneer Venus Multiprobe heritage and descend to 1–5 atmospheres. The ESA evaluated a "medium-class" mission called Uranus Pathfinder. A New Frontiers Uranus Orbiter has been evaluated and recommended in the study, "The Case for a Uranus Orbiter". Such a mission is aided by the ease with which a relatively big mass can be sent to the system—over 1500 kg with an Atlas 521 and 12-year journey. For more concepts see Proposed Uranus missions.
In culture.
In astrology, the planet Uranus () is the ruling planet of Aquarius. Because Uranus is cyan and Uranus is associated with electricity, the colour electric blue, which is close to cyan, is associated with the sign Aquarius (see Uranus in astrology).
The chemical element uranium, discovered in 1789 by the German chemist Martin Heinrich Klaproth, was named after the newly discovered planet Uranus.
"Uranus, the Magician" is a movement in Gustav Holst's "The Planets", written between 1914 and 1916.
Operation Uranus was the successful military operation in World War II by the Soviet army to take back Stalingrad and marked the turning point in the land war against the Wehrmacht.
The lines "Then felt I like some watcher of the skies/When a new planet swims into his ken", from John Keats's "On First Looking Into Chapman's Homer", are a reference to Herschel's discovery of Uranus.

</doc>
<doc id="44477" url="http://en.wikipedia.org/wiki?curid=44477" title="Battle of Ad Decimum">
Battle of Ad Decimum

The Battle of Ad Decimum took place on September 13, 533 between the armies of the Vandals, commanded by King Gelimer, and the Byzantine Empire, under the command of general Belisarius. This event and events in the following year are sometimes jointly referred to as the Battle of Carthage, one of several battles to bear that name. The Byzantine victory marked the beginning of the end for the Vandals and began the reconquest of the west under the Emperor Justinian I.
Prelude.
The Vandal Kingdom in North Africa was ruled by King Hilderic. His reign was noteworthy for the kingdom's excellent relations with the Byzantine Empire ruled by emperor Justinian I. Procopius writes that he was "a very particular friend and guest-friend of Justinian, who had not yet come to the throne", noting that Hilderic and Justinian exchanged large presents of money to each other. Hilderic allowed a new Catholic bishop to take office in the Vandal capital of Carthage, and many Vandals began to convert to Catholicism, to the alarm of the Vandal nobility. Hilderic rejected the Arian Christianity that most Vandals followed. However, in 533, Hilderic was overthrown by his cousin Gelimer. Gelimer began persecuting non Arian Vandals, and many fled to the Byzantine Empire.Justinian sent Byzantine general Belisarius to reconquer the former Roman province of North Africa. The Byzantines would march up the coast to Carthage, the Vandal capital.
Preparation.
Ad Decimum (Latin for ""Ten Mile Post", literally "at the tenth""), was simply a marker along the Mediterranean coast 10 mi south of Carthage. Gelimer, with 11,000 men under his command, had advance warning of the approach of Belisarius' 15,000-man army and chose to take a strong position along the road to Carthage near the post marker. He divided his forces, sending 2,000 men under his nephew Gibamund across a salt pan in an effort to flank Belisarius' army, which was advancing in narrow columns along the road. Another Vandal force, under Gelimer's brother Ammatas, was assigned to initiate a holding action at a defile near Ad Decimum. If everything worked well, Gelimer's 7,000-man main body would follow Gibamund around the Byzantine left flank and cut off their retreat.
Battle.
Gibamund failed to accomplish his mission, as a force of Byzantine and Hun mercenaries drove his 2,000-man force off and killed him. Ammatas also failed; he arrived at the defile with his men still strung out along the road back to Carthage, and he too was killed. The Romans pursued his men all the way to the gates of Carthage itself.
Gelimer's main force, however, inflicted serious casualties on the Byzantine troops along the main road. the Byzantine mercenary cavalry was routed by the Vandals, and even though Gelimer was outnumbered, his men were performing well in the fighting. It appeared as though the Vandals would win the battle.
But when Gelimer reached Ammatas's position and discovered that his brother had been killed, by the vanguard of John the Armenian, he became disconsolate and failed to give an order for one more assault — which would probably have destroyed the reeling Roman army and cut off the Huns and Byzantines who had earlier advanced toward Carthage after beating Ammatas and Gibamund. Instead, the Vandal attack was weakened while Gelimer buried his brother on the battlefield. 
Given a respite, Belisarius was able to regroup his forces south of Ad Decimum and launch a counterattack, which drove the Vandals back and soon routed them. Gelimer was forced to abandon Carthage.
Aftermath.
Belisarius camped near the site of the battle, not wanting to be too close to the city at night. The next day he marched on the city, ordering his men not to kill or enslave the population (as was normal practice at the time) because he stated the people were actually Roman citizens under Vandal rule. They found the gates to the city open, and the army was generally welcomed. Belisarius went straight to the palace and sat on the throne of the Vandal King. He then set about rebuilding the fortifications of the city, and his fleet sought shelter in the Lake of Tunis, five miles (8 km) south of Carthage.
After a second defeat at the Battle of Tricamarum later in the year, the Vandal kingdom was all but ended.
References.
</dl>

</doc>
<doc id="44479" url="http://en.wikipedia.org/wiki?curid=44479" title="Respirometer">
Respirometer

A respirometer is a device used to measure the rate of respiration of a living organism by measuring its rate of exchange of oxygen and/or carbon dioxide. They allow investigation into how factors such as age, chemicals or the effect of light affect the rate of respiration. Respirometers are designed to measure respiration either on the level of a whole animal (plant) or on the cellular level. These fields are covered by whole animal and cellular (or mitochondrial) respirometry, respectively. 
A simple whole plant respirometer designed to measure oxygen uptake or CO2 release consists of a sealed container with the living specimen together with a substance to absorb the carbon dioxide given off during respiration, such as soda lime pellets or cotton wads soaked with potassium hydroxide. The oxygen uptake is detected by manometry. Typically, a U-tube manometer is used, which directly shows the pressure difference between the container and the atmosphere. As an organism takes up O2, it generates a proportionate quantity of CO2 (see respiratory quotient), but all the CO2 is absorbed by the soda lime. Therefore all of the drop of pressure in the chamber can be attributed to the drop of O2 partial pressure in the container. The rate of change gives a direct and reasonably accurate reading for the organism's rate of respiration.
As changes in temperature or pressure can also affect the displacement of the manometric fluid, a second respirometer identical to the first except with a dead specimen (or something with the same mass as the specimen in place of the organism) is sometimes set up. Subtracting the displacement of the second respirometer from the first allows for control of these factors.
The set up of modern respirometers is described in more detail under respirometry. A Respirometer may also be called an oxygraph. Suppliers for whole animal respirometers are e.g. , Sable Systems, Qubit Systems, or Challenge Technology; for mitochondrial respirometers Oroboros Instruments, Hansatech Instruments, or YSI.

</doc>
<doc id="44481" url="http://en.wikipedia.org/wiki?curid=44481" title="Tuff">
Tuff

Tuff (from the Italian "tufo") is a type of rock consisting of consolidated volcanic ash ejected from vents during a volcanic eruption. Tuff is sometimes called tufa, particularly when used as construction material, although "tufa" also refers to a quite different rock. Rock that contains greater than 50% tuff is considered tuffaceous. 
Tuff can be classified as either sedimentary or igneous rocks. They are usually studied in the context of igneous petrology, although they are sometimes described using sedimentological terms.
Volcanic ash.
The products of a volcanic eruption are volcanic gases, lava, steam, and tephra. Magma is blown apart when it interacts violently with volcanic gases and steam. Solid material produced and thrown into the air by such volcanic eruptions is called tephra, regardless of composition or fragment size. If the resulting pieces of ejecta are small enough, the material is called volcanic ash, defined as such particles less than 2 mm in diameter, sand-sized or smaller. These particles are small, slaggy pieces of magma and rock that have been tossed into the air by outbursts of steam and other gases; magma may have been torn apart as it became vesicular by the expansion of the gases within it.
Breccias.
Among the loose beds of ash that cover the slopes of many volcanoes, three classes of materials are represented. In addition to true ashes of the kind described above, there are lumps of the old lavas and tuffs forming the walls of the crater, etc., which have been torn away by the violent outbursts of steam, and pieces of sedimentary rocks from the deeper parts of the volcano that were dislodged by the rising lava and are often intensely baked and recrystallized by the heat to which they have been subjected.
In some great volcanic explosions nothing but materials of the second kind were emitted, as at Mount Bandai in Japan in 1888. There have been many eruptions also in which the quantity of broken sedimentary rocks that mingled with the ash is very great; as instances we may cite the volcanoes of the Eifel and the Devonian tuffs, known as "Schalsteins," in Germany. In the Scottish coalfields some old volcanoes are plugged with masses consisting entirely of sedimentary debris: in such a case it is supposed that no lava was ejected, but the cause of the eruption was the sudden liberation and expansion of a large quantity of steam. These accessory or adventitious materials, however, as distinguished from the true ashes, tend to occur in angular fragments; and when they form a large part of the mass the rock is more properly a "volcanic breccia" than a tuff. The ashes vary in size from large blocks twenty feet or more in diameter to the minutest impalpable dust. The large masses are called "volcanic bombs"; they have mostly a rounded, elliptical or pear-shaped form owing to rotation in the air before they solidified. Many of them have ribbed or nodular surfaces, and sometimes they have a crust intersected by many cracks like the surface of a loaf of bread. Any ash in which they are very abundant is called an agglomerate.
In those layers and beds of tuff that have been spread out over considerable tracts of country and which are most frequently encountered among the sedimentary rocks, smaller fragments preponderate greatly and bombs more than a few inches in diameter may be absent altogether. A tuff of recent origin is generally loose and incoherent, but the older tuffs have been, in most cases, cemented together by pressure and the action of infiltrating water, making rocks which, while not very hard, are strong enough to be extensively used for building purposes (e.g. in the neighborhood of Rome). If they have accumulated subaerially, like the ash beds found on Mt. Etna or Vesuvius at the present day, tuffs consist almost wholly of volcanic materials of different degrees of fineness with pieces of wood and vegetable matter, land shells, etc. But many volcanoes stand near the sea, and the ashes cast out by them are mingled with the sediments that are gathering at the bottom of the waters. In this way ashy muds or sands or even in some cases ashy limestones are being formed. As a matter of fact most of the tuffs found in the older formations contain admixtures of clay, sand, and sometimes fossil shells, which prove that they were beds spread out under water.
During some volcanic eruptions a layer of ashes several feet in thickness is deposited over a considerable district, but such beds thin out rapidly as the distance from the crater increases, and ash deposits covering many square miles are usually very thin. The showers of ashes often follow one another after longer or shorter intervals, and hence thick masses of tuff, whether of subaerial or of marine origin, have mostly a stratified character. The coarsest materials or agglomerates show this least distinctly; in the fine beds it is often developed in great perfection.
Igneous rock.
Apart from adventitious material, such as fragments of the older rocks, pieces of trees, etc., the contents of an ash deposit may be described as consisting of more or less crystalline igneous rocks. If the lava within the crater has been at such a temperature that solidification has commenced, crystals are usually present. They may be of considerable size like the grey, rounded leucite crystals found on the sides of Vesuvius. Many of these are very perfect and rich in faces because they grew in a medium that was liquid and not very viscous. Good crystals of augite and olivine are also to be obtained in the ash beds of Vesuvius and of many other volcanoes, ancient and modern. Blocks of these crystalline minerals (anorthite, olivine, augite and hornblende) are common objects in the tuffs of many of the West Indian volcanoes. Where crystals are very abundant the ashes are called "crystal tuffs." In St. Vincent and Martinique in 1902, much of the dust was composed of minute crystals enclosed in thin films of glass because the lava at the moment of eruption had very nearly solidified as a crystalline mass. Some basaltic volcanoes, on the other hand, have ejected great quantities of black glassy scoria, which, after consolidation, weather to a red soft rock known as palagonite; tuffs of this kind occur in Iceland and Sicily. In the Lipari Islands and Hungary there are acid (rhyolitic) tuffs, of pale grey or yellow color, largely composed of lumps and fragments of pumice. Over a large portion of the sea bottom the beds of fine mud contain small, water-worn, rounded pebbles of very spongy volcanic glass; these have been floated from the shore or cast out by submarine volcanoes, and may have travelled for hundreds of miles before sinking; it has been proved by experiment that some kinds of pumice will float on sea-water for more than a year. The deep sea-deposit known as the "red clay" is largely of volcanic origin and might be suitably described as a "submarine tuff-bed."
Welded tuff.
Welded tuff is a pyroclastic rock, of any origin, that was sufficiently hot at the time of deposition to weld together. Strictly speaking, if the rock contains scattered pea-sized fragments or fiamme in it, it is called a welded lapilli-tuff. Welded tuffs (and welded lapilli-tuffs) can be of fallout origin, or deposited from pyroclastic density currents, as in the case of ignimbrites. During welding, the glass shards and pumice fragments adhere together (necking at point contacts), deform, and compact together, resulting in a 'eutaxitic fabric' (see image and contrast with the ash shapes in unwelded tuff).
Welded ignimbrites can be highly voluminous, such as the Lava Creek Tuff erupted from Yellowstone Caldera in Wyoming 640,000 years ago. Lava Creek Tuff is known to be at least 1000 times as large as the deposits of the May 18, 1980 eruption of Mount St. Helens, and it had a Volcanic Explosivity Index (VEI) of 8—greater than any eruption known in the last 10,000 years. The intensity of welding may decrease towards the upper margin of a deposit, towards areas in which the deposit is thinner, and with distance from source. Welded tuff is commonly rhyolitic in composition, but examples of all compositions are known.
Rhyolitic tuff.
For petrographical purposes, tuff is generally classified according to the nature of the volcanic rock of which it consists; this may be the same as the accompanying lavas if any were emitted during an eruption, and if there is a change in the kind of lava which is poured out, the tuffs also indicate this equally clearly. Rhyolite tuffs contain pumiceous, glassy fragments and small scoriae with quartz, alkali feldspar, biotite, etc. Iceland, Lipari, Hungary, the Basin and Range of the American southwest, and New Zealand are among the areas where such tuffs are prominent. The broken pumice is clear and isotropic, and very small particles commonly have crescentic, sickle-shaped, or biconcave outlines, showing that they are produced by the shattering of a vesicular glass, sometimes described as ash-structure. The tiny glass fragments derived from broken pumice are called shards; the glass shards readily deform and flow when the deposits are sufficiently hot, as shown in the accompanying image of welded tuff.
In the ancient rocks of Wales, Charnwood, the Pentland Hills, etc., similar tuffs are known, but in all cases they are greatly changed by silicification (which has filled them with opal, chalcedony and quartz) and by devitrification. The frequent presence of rounded corroded quartz crystals, such as occur in rhyolitic lavas, helps to demonstrate their real nature.
A example of this tuff "Rochlitz Porphyr" can be seen in the Mannerist style sculpted portal outside the chapel entrance in Colditz Castle. The trade name "Rochlitz Porphyr" is the traditional designation for a dimension stone of Saxony with an architectural history over 1,000 years in Germany. The quarries are located near Rochlitz.
Trachyte tuff.
Trachyte tuffs contain little or no quartz but much sanidine or anorthoclase and sometimes oligoclase feldspar, with occasional biotite, augite and hornblende. In weathering they often change to soft red or yellow clay-stones, rich in kaolin with secondary quartz. Recent trachyte tuffs are found on the Rhine (at Siebengebirge), in Ischia, near Naples, Hungary, etc.
Andesitic tuff.
Andesitic tuffs are exceedingly common. They occur along the whole chain of the Cordilleras and Andes, in the West Indies, New Zealand, Japan, etc. In the Lake district, North Wales, Lorne, the Pentland Hills, the Cheviots and many other districts of Great Britain, ancient rocks of exactly similar nature are abundant. In color they are red or brown; their scoriae fragments are of all sizes from huge blocks down to minute granular dust. The cavities are filled up with many secondary minerals, such as calcite, chlorite, quartz, epidote, chalcedony; but in microscopic sections, the nature of the original lava can nearly always be made out from the shapes and properties of the little crystals which occur in the decomposed glassy base. Even in the smallest details, these ancient tuffs have a complete resemblance to the modern ash beds of Cotopaxi, Krakatoa and Mont Pelé.
Basaltic tuff.
Basaltic tuffs are also of widespread occurrence both in districts where volcanoes are now active and in lands where eruptions have long since ended. They are found in Skye, Mull, Antrim and other places, where there are Paleogene volcanic rocks; in Scotland, Derbyshire and Ireland among the carboniferous strata; and among the still older rocks of the Lake District, southern uplands of Scotland and Wales. They are black, dark green or red in colour; vary greatly in coarseness, some being full of round spongy bombs a foot or more in diameter, and, being often submarine, may contain shale, sandstone, grit and other sedimentary material, and are occasionally fossiliferous. Recent basaltic tuffs are found in Iceland, the Faroe Islands, Jan Mayen, Sicily, Sandwich Islands, Samoa, etc. When weathered they are filled with calcite, chlorite, serpentine and, especially where the lavas contain nepheline or leucite, are often rich in zeolites, such as analcite, prehnite, natrolite, scolecite, chabazite, heulandite, etc.
Ultramafic tuff.
Ultramafic tuffs are extremely rare; their characteristic is the abundance of olivine or serpentine and the scarcity or absence of feldspar and quartz. Rare occurrences may include unusual surface deposits of maars of kimberlites of the diamond-fields of southern Africa and other regions. The principal rock of kimberlite is a dark bluish-green serpentine-rich breccia (blue-ground) which when thoroughly oxidized and weathered becomes a friable brown or yellow mass (the "yellow-ground"). These breccias were emplaced as gas–solid mixtures and are typically preserved and mined in diatremes that form intrusive pipe-like structures. At depth, some kimberlite breccias grade into root zones of dikes made of unfragmented rock. At the surface, ultramafic tuffs may occur in maar deposits. Because kimberlites are the most common igneous source of diamonds, the transitions from maar to diatreme to root-zone dikes have been studied in detail. Diatreme-facies kimberlite is more properly called an ultramafic breccia rather than a tuff.
Folding and metamorphism.
In course of time, other changes than weathering may overtake tuff deposits. Sometimes they are involved in folding and become sheared and cleaved. Many of the green slates of the lake district in Cumberland are fine cleaved ashes. In Charnwood Forest also the tuffs are slaty and cleaved. The green color is due to the large development of chlorite. Among the crystalline schists of many regions, green beds or green schists occur, which consist of quartz, hornblende, chlorite or biotite, iron oxides, feldspar, etc., and are probably recrystallized or metamorphosed tuffs. They often accompany masses of epidiorite and hornblende – schists which are the corresponding lavas and sills. Some chlorite-schists also are probably altered beds of volcanic tuff. The "Schalsteins" of Devon and Germany include many cleaved and partly recrystallized ash-beds, some of which still retain their fragmental structure though their lapilli are flattened and drawn out. Their steam cavities are usually filled with calcite, but sometimes with quartz. The more completely altered forms of these rocks are platy, green chloritic schists; in these, however, structures indicating their original volcanic nature only sparingly occur. These are intermediate stages between cleaved tuffs and crystalline schists.
Economic importance.
Tuff's primary economic value is as a building material. In the ancient world, tuff's relative softness meant that it was commonly used for construction where it was available. Tuff is common in Italy, and the Romans used it for many buildings and bridges. For example, the whole port of the island of Ventotene (still in use), was carved out from tuff. The Servian Wall, built to defend the city of Rome in the 4th century BC, is also built almost entirely from tuff. The Romans also cut tuff into small rectangular stones that they used to create walls in a pattern known as opus reticulatum.
The Romans thought bees nested in tuff. The substance is mentioned in the "Aeneid" (Book XII, ln 805).
The peperino, much used at Rome and Naples as a building stone, is a trachyte tuff. Pozzolana also is a decomposed tuff, but of basic character, originally obtained near Naples and used as a cement, but this name is now applied to a number of substances not always of identical character. In the Eifel region of Germany a trachytic, pumiceous tuff called trass has been extensively worked as a hydraulic mortar.
Yucca Mountain nuclear waste repository, a U.S. Department of Energy terminal storage facility for spent nuclear reactor and other radioactive waste, is in tuff and ignimbrite in the Basin and Range Province in Nevada. In Napa valley and Sonoma valley, California, areas made out of tuff are routinely excavated for storage of wine barrels.
Tuff from Rano Raraku was used by the Rapa Nui people of Easter Island to make the vast majority of their famous moai statues.
Tuff is important in Armenian architecture.

</doc>
<doc id="44483" url="http://en.wikipedia.org/wiki?curid=44483" title="David Fabricius">
David Fabricius

David Fabricius (March 9, 1564 – May 7, 1617), was a German pastor who made two major discoveries in the early days of telescopic astronomy, jointly with his eldest son, Johannes Fabricius (1587–1615).
David Fabricius (Latinization of his proper name "David Faber" or "David Goldschmidt") was born at Esens, studied at the University of Helmstedt starting in 1583 and served as pastor for small towns near his birthplace in Frisia (now northwest Germany and northeast Netherlands), at Resterhafe near Dornum in 1584 and at Osteel in 1603. As was common for Protestant ministers of the day, he dabbled in science: his particular interest was astronomy. Fabricius corresponded with astronomer Johannes Kepler.
Fabricius discovered the first known periodic variable star (as opposed to cataclysmic variables, such as novas and supernovas), Mira, in August 1596. At first he believed it to be "just" another nova, as the whole concept of a recurring variable did not exist at the time. When he saw Mira brighten again in 1609, however, it became clear that a new kind of object had been discovered in the sky.
Two years later, his son Johannes Fabricius (1587–1615) returned from university in the Netherlands with telescopes that they turned on the Sun. Despite the difficulties of observing the sun directly, they noted the existence of sunspots, the first confirmed instance of their observation (though unclear statements in East Asian annals suggest that Chinese astronomers may have discovered them with the naked eye previously, and Fabricius may have noticed them himself without a telescope a few years before). The pair soon invented camera obscura telescopy so as to save their eyes and get a better view of the solar disk, and observed that the spots moved. They would appear on the eastern edge of the disk, steadily move to the western edge, disappear, then reappear at the east again after the passage of the same amount of time that it had taken for it to cross the disk in the first place. This suggested that the Sun rotated on its axis, which had been postulated before but never backed up with evidence. Johannes published "Maculis in Sole Observatis, et Apparente earum cum Sole Conversione Narratio" ("Narration on Spots Observed on the Sun and their Apparent Rotation with the Sun") in June 1611. Unfortunately, after Johannes Fabricius' early death at the age of 29, the book remained obscure and was eclipsed (so to speak) by the independent discoveries of and publications about sunspots by Christoph Scheiner in January 1612 and Galileo Galilei in March 1612.
Besides these two discoveries, little else is known about David Fabricius except his unusual manner of death, which occurred at Osteel: after denouncing a local goose thief from the pulpit, the accused man struck him in the head with a shovel and killed him.
Legacy.
Copies of a map he made of Frisia in 1589 are also still extant. He is also name-checked in Jules Verne's "From the Earth to the Moon" as someone who claimed to have seen lunar inhabitants through his telescope, though that particular fact is merely part of Verne's fiction. The large (90-kilometer) crater Fabricius in the Moon's southern hemisphere is named after David Fabricius. In 1895 a monument was erected to his memory in the churchyard at Osteel where he was pastor from 1603 until 1617.

</doc>
<doc id="44486" url="http://en.wikipedia.org/wiki?curid=44486" title="Melvin Defleur">
Melvin Defleur

Melvin Lawrence DeFleur (born April 27, 1923 in Portland, Oregon) is a professor and scholar in the field of communications. His initial field of study was social sciences.
Biography.
DeFleur received his Ph.D. in social psychology from the University of Washington in 1954. His thesis, "Experimental studies of stimulus response relationships in leaflet communication", drew from sociology, psychology, and communication, to study how information diffused through |American communities.
He has taught at Indiana University (1954–1963), the University of Kentucky (1963–1967), Washington State University (1967–1976), the University of New Mexico (1976–1980), the University of Miami (1981–1985), Syracuse University (1987–1994) and the University of Washington before taking his current position as professor of communication at Boston University's Department of Mass Communication, Advertising and Public Relations. In addition, he was a Fulbright Professor to Argentina twice: and was affiliated with the Argentine Sociological Society and the Ibero-Interamerican Sociological Society, for which he served as Secretary General.
DeFleur is married to Margaret DeFleur, Associate Dean for Graduate Studies and Research,
Academic work.
His early work owes a debt to Stuart C. Dodd and George A. Lundberg, sociologists and psychologists. This group applied quantitative measure, statistical data analyses, and descriptive mathematical models used in the physical sciences to the development of sociology (DeFleur & Larsen, 1987).
Another force affected his work: He began his career when the memories of World War II were fresh, and entered into the academic world when the Cold War played a critical role in shaping the United States' political, economic and social atmosphere. Social psychology research added to the knowledge that the United States government and military felt they needed for operating in a new world dynamic (East v. West). For example, the leafleting processes studied by Project Revere were an obvious way to communicate information to a displaced, captive, or isolated population. 
He maintained a sociological focus during the early 1970s, co-writing an introductory sociology textbook that went into several editions. He co-authored a study of discrimination in university hiring practices, particularly in sociology departments (Wolfe et al., 1973), again with a strong emphasis on statistics and survey methods. However, his focus shifted. With the spread of television, he began to study the mass media. Specifically, he researched the effect of television on children's knowledge of occupational roles, and on the factors that influence the content and output of the American broadcasting systems. He and others established a formal definition of social expectations theory, applied to a model to predict that watching television attunes a viewer to social organization patterns of various groups, even if they "have never been members or never will be" (DeFleur & Ball-Rokeach, 1989). Other works examined the potential relationships forged by mass media between the perception of social problems and their portrayal by the media (Hubbard et al., 1975). He wrote of his suggestion of a cultural norms theory in 1970, an idea that, in his estimation, "provided the foundation for the more comprehensive social expectations theory" (DeFleur & Ball-Rokeach, 1989).
In the 1970s and 1980s he continued studies on news diffusion. In reviewing some major studies (DeFleur, 1988), he found that despite emerging technology, word of mouth is still important, and major events that concern a broader population will travel further and faster. His research lead to the creation of the Media Systems Dependency Theory with Sandra Ball-Rokeach in 1976.
DeFleur cites his idea (formed with Timothy Plax) of the language-shaping function of the media as one of four theories on how media shape messages, and what that means for social conduct (DeFleur & Ball-Rokeach, 1989). The other three are the meaning-construction function of the press (Lippmann, 1920s); cultivation theory (Gerbner); the agenda setting function of the press (Shaw and McCombs). His transition from "pure" social psychology to mass communication mirrors the growth of this field. His theories, are widely cited in mass communication studies and in general theoretical surveys. 
He is on the Executive Board of the Center for Global Media Studies at Washington State University, an organization whose motto, "Global Media Cover the World ... We Cover Global Media," connects with the focus of his recent work studying the accuracy of audience recall of news media in a cross-cultural vein (Faccoro & DeFleur, 1993).
Bibliography of DeFleur's Works [Abridged].
Dennis, E. E. & DeFleur, M. L. (2010). Understanding Media in the Digital Age. Allyn & Bacon.

</doc>
<doc id="44488" url="http://en.wikipedia.org/wiki?curid=44488" title="Independent Media Center">
Independent Media Center

The Independent Media Center (also known as Indymedia or IMC) is a global participatory network of journalists that report on political and social issues. It originated during the Seattle anti-WTO protests worldwide in 1999 and remains closely associated with the global justice movement, which criticizes neo-liberalism and its associated institutions. Indymedia uses an open publishing and democratic media process that allows anybody to contribute.
According to its homepage, "Indymedia is a collective of independent media organizations and hundreds of journalists offering grassroots, non-corporate coverage. Indymedia is a democratic media outlet for the creation of radical, accurate, and passionate tellings of truth." Indymedia was founded as an alternative to government and corporate media, and seeks to facilitate people being able to publish their media as directly as possible.
Overview.
The first Indymedia project was started in late November 1999 to report on protests against the WTO meeting that took place in Seattle, Washington, and to act as an alternative media source. This followed a successful experiment in June that year, reporting the events of the Carnival Against Capitalism in London, UK. The Media team there used software and unmediated reports from protest participants. The open publishing script was first developed by video activists in Sydney, Australia.
"Even more importantly, a group of hackers in Sydney, Australia, had written a special piece of software for live updating of the webpage devoted to their local J18 event. Six months later, this “Active Software” would be used in the American city of Seattle, as the foundation of the Indymedia project – a multiperspectival instrument of political information and dialogue for the twenty-first century"
After Seattle the idea and network spread rapidly. By 2002, there were 89 Indymedia websites covering 31 countries (and the Palestinian territories), growing to over 150 by January 2006, not all of them currently active. Indymedia websites publish in a number of languages, including English, Spanish, German, Italian, Portuguese, French, Russian, Arabic and Hebrew.
IMC collectives distribute print, audio, photo, and video media, but are most well known for their open publishing newswires, sites where anyone with internet access can publish news from their own perspective. The content of an IMC is determined by its participants, both the users who post content, and members of the local Indymedia collective who administer the site. While Indymedias worldwide are run autonomously and differ according to the concerns of their users, they share a commitment to provide copyleft content. The general rule is that content on Indymedia sites can be freely reproduced for non-commercial purposes.
Content and focus.
The origins of IMCs themselves came out of protests against the concentrated ownership and perceived biases in corporate media reporting. The first IMC node, attached as it was to the Seattle anti-corporate globalization protests, was seen by activists as an alternative news source to that of the corporate media, which they accused of only showing violence and confrontation, and portraying all protesters negatively.
As a result, between 1999 and 2001, IMC newswires tended to be focused on up-to-the-minute coverage of protests, from local demonstrations to summits where anti-globalization movement protests were occurring, with protest coverage continuing into 2007.
IMC also run a global radio project which aggregates audio RSS feeds from around the world.
Organizational structure.
IMC is formed of local collectives which are expected to be open and inclusive of individuals from a variety of different local anti-capitalist points of view, whether or not these have any definite political philosophy, so that even those without internet access can participate in both content creation and in content consumption. Editorial policies, locally chosen by any Indymedia collective, generally involve removing articles which the Indymedia editors believe promote racism, sexism, hate speech, and homophobia. All Indymedia collectives are expected to have a locally chosen, thoroughly discussed and clearly stated editorial policy for posts to their website.
Criticism.
Views on Israel and Jews.
In a 2002 op-ed, alter-globalisation activist Naomi Klein criticised Indymedia for perpetuating conspiracy theories about the Jews, including supposed involvement with the September 11 attacks and re-posting from the infamous hoax "The Protocols of the Elders of Zion". In the same year, the Swiss edition of Indymedia was accused of anti-Semitism by Aktion Kinder des Holocaust, which unsuccessfully sued them for publishing a Carlos Latuff cartoon of a Jewish boy in the Warsaw Ghetto saying "I am Palestinian," though this was criticized by IMC as an attempt to stifle criticism of Israel in Switzerland.
Google temporarily stopped including some IMCs in Google News searches due to the use of the term "zionazi". Marissa Mayer, at the time the product manager of Google News, explained the removal by describing the term as a "degrading, hateful slur" and refused to index the Bay Area IMC because it had appeared there. While SF Bay Area Indymedia agreed that it "could be considered hate speech", they considered this a double standard due to Google News indexing articles using racist and defamatory language against Arabs and Muslims, such as the term "Islamofascism".
Servers seizures.
Indymedia has had interactions with authorities in USA and UK.
Seizure of servers by the FBI.
On October 7, 2004, the FBI took possession of several server hard drives used by a number of IMCs and hosted by US-based Rackspace Managed Hosting. The servers in question were located in the United Kingdom and managed by the British arm of Rackspace, but some 20 mainly European IMC websites were affected, and several unrelated websites were affected, including the website of a Linux distribution. No reasons were given at first by the FBI and Rackspace for the seizure, in particular IMC was not informed. Rackspace claimed that it was banned from giving further information about the incident. Some, but not all, of the legal documents relating to the confiscation of the servers were unsealed by a Texas district court in August 2005, following legal action by the Electronic Frontier Foundation. The documents revealed that the only action requested by the government was to surrender server log files.
A statement by Rackspace stated that the company had been forced to comply with a court order under the procedures laid out by the Mutual Legal Assistance Treaty, which governs international police co-operation on "international terrorism, kidnapping and money laundering". The investigation that led to the court order was said to have arisen outside of the U.S. Rackspace stated that they were prohibited on giving further detail. Agence France-Presse reported FBI spokesman Joe Parris, who said the incident was not an FBI operation, but that the subpoena had been issued at the request of the Italian and the Swiss governments. Again, no further details on specific allegations were given. UK involvement was denied in an answer given to a parliamentary question posed by Richard Allan, Liberal Democrat MP.
Indymedia pointed out that they were not contacted by the FBI and that no specific information was released on the reasons for seizing the servers. Indymedia also sees the incident in the context of "numerous attacks on independent media by the US Federal Government", including a subpoena to obtain IP logs from Indymedia at the occasion of the Republican National Conference, the shut-down of several community radio stations in the US by the FCC, and a request by the FBI to remove a post on Nantes IMC containing a photograph of alleged undercover Swiss police.
The move was condemned by the International Federation of Journalists, who stated that "The way this has been done smacks more of intimidation of legitimate journalistic inquiry than crime-busting" and called for an investigation. Criticism was also voiced by European civil liberties organisation Statewatch and the World Association of Community Radio Broadcasters (AMARC). Mathew Honan commented in "Salon" that "This kind of thing doesn’t happen to Wolf Blitzer". EFF attorney Kurt Opsahl compared the case with "Steve Jackson Games, Inc. v. United States Secret Service".
In Italy, the federal prosecutor of Bologna Marina Plazzi confirmed that an investigation against Indymedia had been opened because of suspected "support of terrorism", in the context of Italian troops in the Iraqi city of Nasiriyah. The investigation was triggered after 17 members of the coalition government belonging to the right-wing Alleanza Nazionale, including Alessandra Mussolini, demanded that Indymedia be shut down. A senior party member and government official had announced the co-operation with US authorities, and party spokesman Mario Landolfi welcomed the FBI's seizure of the Indymedia servers. Left-wing Italian politicians denounced the move and called for an investigation.
Bristol server seizure.
Not long after the Rackspace affair another server in the UK was seized by police in June 2005. An anonymous post on the Bristol Indymedia server, came to police attention for suggesting an "action" against a freight train carrying new cars as part of a protest against cars and climate change in the run up to that year's Gleneagles G8 summit. The police claimed that the poster broke the law by "incitement to criminal damage", and sought access logs from the server operators. Despite being warned by lawyers that the servers were "journalistic equipment" and subject to special laws, the police proceeded with the seizure and a member of the Bristol Indymedia group was arrested. Indymedia was supported in this matter by the National Union of Journalists, Liberty and Privacy International, along with others. This incident ended several months later with no charges being brought by the police and the equipment returned.
Prior to the original server being returned, Bristol Indymedia was donated a replacement server by local IT co-operative, Bristol Wireless.
Other legal actions in the United States.
On January 30, 2009, one of the system administrators of the server that hosts indymedia.us received a grand jury subpoena from the Southern District of Indiana federal court. The subpoena asked the administrator to provide all "IP addresses, times, and any other identifying information" for every visitor to the site on June 25, 2008. The subpoena also included a gag order that stated that the recipient is "not to disclose the existence of this request unless authorized by the Assistant U.S. Attorney." The administrator of indymedia.us could not have provided the information because Indymedia sites generally do not keep IP address logs. The Electronic Frontier Foundation determined that there was no legal basis for the gag order, and that the subpoena request "violated the SCA's restrictions on what types of data the government could obtain using a subpoena." Under Justice Department guidelines, subpoenas to news media must have the authorization of the attorney general. According to a CBS News blog, the subpoena of indymedia.us was never submitted for review by the Attorney General. On February 25, 2009, a United States Attorney sent a letter to an attorney with the Electronic Frontier Foundation stating that the subpoena had been withdrawn.
Police action against IMC.
On August 15, 2000, the Los Angeles Police Department temporarily shut down the satellite uplink and production studio of the Los Angeles Independent Media Center on its first night of Democratic National Convention coverage, claiming explosives were in a van in the adjacent parking lot.
In July, 2001 at the 27th G8 summit in Genoa, Indymedia journalists were seriously assaulted at the Diaz school where Indymedia had set up a temporary journalism center and radio station. Twenty-nine Italian police officers were indicted for grievous bodily harm, planting evidence and wrongful arrest during a night-time raid on the Diaz School, and thirteen were convicted.
On June 1, 2003, Indymedia journalist Guy Smallman was seriously injured by a police grenade in Geneva. He was covering protests against the G8 summit in nearby Evian for Indymedia and Image Sans Frontière.
Brad Will shooting.
On October 27, 2006, New York–based journalist and indymedia volunteer Bradley Roland Will was killed along with two Mexican protesters in the city of Oaxaca. People had been demonstrating in the city since May as part of an uprising prompted by a teachers strike. Lizbeth Cana, attorney general of Oaxaca, claimed the conflict was caused by the protesters and that the gunmen who engaged them were upset residents from the area. The U.S. ambassador to Mexico, Tony Garza, however, claimed the men may have been local police. Reporters Without Borders condemned the actions of the Mexican government in allowing the accused to go free.
Protesters also allege that the men were police and not local residents. Associated Press alleged that the protesters also had guns, describing the conflict as a "shootout".
Prizes and honors.
In April 2008, in Brazil, IMC and (posthumously) Brad Will received the Medalha Chico Mendes de Resistência ("Chico Mendes Resistance Medal" in Portuguese) from the Brazilian humanitarian group Tortura Nunca Mais ("No more torture" in Portuguese) for their contributions to human rights and a more fair society.

</doc>
<doc id="44490" url="http://en.wikipedia.org/wiki?curid=44490" title="Charles Fort">
Charles Fort

Charles Hoy Fort (August 6, 1874 – May 3, 1932) was an American writer and researcher into anomalous phenomena. Today, the terms Fortean and Forteana are used to characterize various such phenomena. Fort's books sold well and are still in print today. His work continues to inspire people, who call themselves Forteans, and has influenced some areas of science fiction.
Biography.
Charles Hoy Fort was born in 1874 in Albany, New York, of Dutch ancestry. He had two younger brothers, Clarence and Raymond. His grocer father was something of an authoritarian: "Many Parts", Fort's unpublished autobiography, relates several instances of harsh treatment – including physical abuse – by his father. Some observers (such as Fort's biographer Damon Knight) have suggested that Fort's distrust of authority has its roots in his father's treatment. In any case, Fort developed a strong sense of independence in his youth.
As a young man, Fort was a budding naturalist, collecting sea shells, minerals, and birds. Described as curious and intelligent, the young Fort did not excel at school, though he was considered quite a wit and full of knowledge about the world – yet this was a world he only knew through books.
So, at the age of 18, Fort left New York on a world tour to "put some capital in the bank of experience". He travelled through the western United States, Scotland, and England, until falling ill in Southern Africa. Returning home, he was nursed by Anna Filing, a girl he had known from his childhood. They were later married on October 26, 1896. Anna was four years older than Fort and was non-literary, a lover of films and of parakeets. She later moved with her husband to London for two years where they would go to the cinema when Fort wasn't busy with his research. His success as a short story writer was intermittent between periods of terrible poverty and depression.
In 1916, an inheritance from an uncle gave Fort enough money to quit his various day jobs and to write full-time. In 1917, Fort's brother Clarence died; his portion of the same inheritance was divided between Fort and Raymond.
Fort wrote ten novels, although only one, "The Outcast Manufacturers" (1909), was published. Reviews were mostly positive, but the tenement tale was commercially unsuccessful. In 1915, Fort began to write two books, titled "X" and "Y", the first dealing with the idea that beings on Mars were controlling events on Earth, and the second with the postulation of a sinister civilization extant at the South Pole. These books caught the attention of writer Theodore Dreiser, who attempted to get them published, but to no avail. Disheartened by this failure, Fort burnt the manuscripts, but was soon renewed to begin work on the book that would change the course of his life, "The Book of the Damned" (1919), which Dreiser helped to get into print. The title referred to "damned" data that Fort collected, phenomena for which science could not account and that was thus rejected or ignored.
Fort's experience as a journalist, coupled with high wit egged on by a contrarian nature, prepared him for his real-life work, needling the pretensions of scientific positivism and the tendency of journalists and editors of newspapers and scientific journals to rationalize the scientifically incorrect.
Fort and Anna lived in London from 1924 to 1926, having moved there so Fort could peruse the files of the British Museum. Although born in Albany, Fort lived most of his life in the Bronx. He was, like his wife, fond of films, and would often take her from their Ryer Avenue apartment to the nearby movie theater, and would always stop at the adjacent newsstand for an armful of various newspapers. Fort frequented the parks near the Bronx, where he would sift through piles of his clippings. He would often ride the subway down to the main New York Public Library on Fifth Avenue, where he would spend many hours reading scientific journals along with newspapers and periodicals from around the world. Fort also had a small circle of literary friends and they would gather on occasion at various apartments, including his own, to drink and talk, which was tolerated by Anna. Theodore Dreiser would lure him out to meetings with phony telegrams and notes, and the resultant evening would be full of good food, conversation and hilarity. 
Suffering from poor health and failing eyesight, Fort was pleasantly surprised to find himself the subject of a cult following. There was talk of the formation of a formal organization to study the type of odd events related in his books. Clark writes, "Fort himself, who did nothing to encourage any of this, found the idea hilarious. Yet he faithfully corresponded with his readers, some of whom had taken to investigating reports of anomalous phenomena and sending their findings to Fort" (Clark 1998, 235).
Fort distrusted doctors and did not seek medical help for his worsening health. Rather, he focused his energies towards completing "Wild Talents". After he collapsed on May 3, 1932, Fort was rushed to Royal Hospital in The Bronx. Later that same day, Fort's publisher visited him to show the advance copies of "Wild Talents". Fort died only hours afterward, probably of leukemia.
He was interred in the Fort family plot in Albany, New York. His more than 60,000 notes were donated to the New York Public Library.
Fort and the unexplained.
Overview.
Fort's relationship with the study of anomalous phenomena is frequently misunderstood and misrepresented. For over thirty years, Charles Fort sat in the libraries of New York City and London, assiduously reading scientific journals, newspapers, and magazines, collecting notes on phenomena that lay outside the accepted theories and beliefs of the time.
Fort took thousands of notes in his lifetime. In his short story "The Giant, the Insect and The Philanthropic-looking Old Gentleman" (first published by the International Fortean Organization in issue #70 of the "INFO Journal: Science and the Unknown"), Fort spoke of sitting on a park bench at The Cloisters in New York City and tossing some 48,000 notes, not all of his collection by any means, into the wind. This short story is significant because Fort uses his own data collection technique to solve a mystery. He marveled that seemingly unrelated bits of information were, in fact, related. Fort wryly concludes that he went back to collecting data and taking even more notes. The notes were kept on cards and scraps of paper in shoeboxes, in a cramped shorthand of Fort's own invention, and some of them survive today in the collections of the University of Pennsylvania. More than once, depressed and discouraged, Fort destroyed his work, but always began anew. Some of the notes were published, little by little, by the Fortean Society magazine "Doubt" and, upon the death of its editor Tiffany Thayer in 1959, most were donated to the New York Public Library, where they are still available to researchers of the unknown.
From this research, Fort wrote four books. These are "The Book of the Damned" (1919), "New Lands" (1923), "Lo!" (1931) and "Wild Talents" (1932); one book was written between "New Lands" and "Lo!" but it was abandoned and absorbed into "Lo!."
Fort's writing style.
Fort suggests that there is a Super-Sargasso Sea into which all lost things go, and justifies his theories by noting that they fit the data as well as the conventional explanations. As to whether Fort "believes" this theory, or any of his other proposals, he gives us the answer: "I believe nothing of my own that I have ever written." Writer Colin Wilson suspects that Fort took few if any of his "explanations" seriously, and notes that Fort made "no attempt to present a coherent argument". (Wilson, 200) Moreover, Wilson opines that Fort's writing style is "atrocious" (Wilson, 199) and "almost unreadable" (Wilson, 200). Wilson also compares Fort to Robert Ripley, a contemporary writer who found major success hunting oddities, and speculates that Fort's idiosyncratic prose might have kept him from greater popular success.
Jerome Clark writes that Fort was "essentially a satirist hugely skeptical of human beings' – especially scientists' – claims to ultimate knowledge". Clark describes Fort's writing style as a "distinctive blend of mocking humor, penetrating insight, and calculated outrageousness".
Wilson describes Fort as "a patron of cranks" and also argues that running through Fort's work is "the feeling that no matter how honest scientists "think" they are, they are still influenced by various "unconscious" assumptions that prevent them from attaining true objectivity. Expressed in a sentence, Fort's principle goes something like this: People with a psychological need to "believe" in marvels are no more prejudiced and gullible than people with a psychological need "not" to believe in marvels."
Fortean phenomena.
Despite his objections to Fort's writing style, Wilson allows that "the facts are certainly astonishing enough" (Wilson, 200). Examples of the odd phenomena in Fort's books include many of what are variously referred to as occult, supernatural, and paranormal. Reported events include teleportation (a term Fort is generally credited with coining); poltergeist events; falls of frogs, fishes, inorganic materials of an amazing range; unaccountable noises and explosions; spontaneous fires; levitation; ball lightning (a term explicitly used by Fort); unidentified flying objects; unexplained disappearances; giant wheels of light in the oceans; and animals found outside their normal ranges (see phantom cat). He offered many reports of out-of-place artifacts (OOPArts), strange items found in unlikely locations. He also is perhaps the first person to explain strange human appearances and disappearances by the hypothesis of alien abduction and was an early proponent of the extraterrestrial hypothesis, specifically suggesting that strange lights or objects sighted in the skies might be alien spacecraft. Fort also wrote about the interconnectedness of nature and synchronicity.
Many of these phenomena are now collectively and conveniently referred to as Fortean phenomena (or Forteana), whilst others have developed into their own schools of thought: for example, reports of UFOs in ufology and unconfirmed animals (cryptids) in cryptozoology. These 'new disciplines' are not recognized by most scientists or academics.
The Forteans.
Fort's work has inspired very many to consider themselves as Forteans. The first of these was the screenwriter Ben Hecht, who in a review of "The Book of the Damned" declared "I am the first disciple of Charles Fort… henceforth, I am a Fortean". Among Fort's other notable fans were John Cowper Powys, Sherwood Anderson, Clarence Darrow, and Booth Tarkington, who wrote the foreword to "New Lands".
Precisely what is encompassed by "Fortean" is a matter of great debate; the term is widely applied from every position from Fortean purists dedicated to Fort's methods and interests, to those with open and active acceptance of the actuality of paranormal phenomena, a position with which Fort may not have agreed. Most generally, Forteans have a wide interest in unexplained phenomena in wide-ranging fields, mostly concerned with the natural world, and have a developed "agnostic scepticism" regarding the anomalies they note and discuss. For Mr. Hecht as an example, being a Fortean meant hallowing a pronounced distrust of authority in all its forms, whether religious, scientific, political, philosophical or otherwise. It did not, of course, include an actual belief in the anomalous data enumerated in Fort's works.
The Fortean Society was founded at the Savoy-Plaza Hotel in New York City on 26 January 1931 by his friends, many of whom were significant writers such as Theodore Dreiser, Ben Hecht, Alexander Woollcott, and led by fellow American writer Tiffany Thayer, half in earnest and half in the spirit of great good humor, like the works of Fort himself. The board of Founders included Dreiser, Hecht, Booth Tarkington, Aaron Sussman, John Cowper Powys, the former editor of "Puck" Harry Leon Wilson, Woolcott and J. David Stern, publisher of the Philadelphia Record. Active members of the Fortean Society included journalist H.L. Mencken and prominent science fiction writers such as Eric Frank Russell and Damon Knight. Fort, however, rejected the Society and refused the presidency, which went to his close friend writer Theodore Dreiser; he was lured to its inaugural meeting by false telegrams. As a strict non-authoritarian, Fort refused to establish himself as an authority, and further objected on the grounds that those who would be attracted by such a grouping would be spiritualists, zealots, and those opposed to a science that rejected them; it would attract those who "believed" in their chosen phenomena: an attitude exactly contrary to Forteanism. Fort did hold unofficial meetings and had a long history of getting together informally with many of NYC's literati such as Theodore Dreiser and Ben Hecht at their various apartments where they would talk, have a meal and then listen to short reports.
The magazine "Fortean Times" (first published in November 1973), is a proponent of Fortean journalism, combining humour, scepticism, and serious research into subjects which scientists and other respectable authorities often disdain. Another such group is the International Fortean Organization (INFO). INFO was formed in the early 1960s (incorporated in 1965) by brothers, the writers Ron and Paul Willis, who acquired much of the material of the original Fortean Society which had begun in 1932 in the spirit of Charles Fort but which had grown silent by 1959 with the death of Tiffany Thayer. INFO publishes the "INFO Journal: Science and the Unknown" and organizes the FortFest, the world's first, and continuously running, conference on anomalous phenomena dedicated to the spirit of Charles Fort. INFO, since the mid-1960s, also provides audio CDs and filmed DVDs of notable conference speakers (Colin Wilson, John Michell, Graham Hancock, John Anthony West, William Corliss, John Keel, Joscelyn Godwin among many others). Other Fortean societies are also active, notably the Edinburgh Fortean Society in Edinburgh and the Isle of Wight.
Scholarly evaluation.
Fort is acknowledged by religious scholars such as Jeffrey J. Kripal and Joseph P. Laycock as a pioneering theorist of the paranormal who helped define "paranormal" as a discursive category and provided insight into its importance in human experience. Although Fort is consistently critical of the scientific study of abnormal phenomena, he remains relevant today for those who engage in such studies.
Literary influence.
More than a few modern authors of fiction and non-fiction who have written about the influence of Fort are sincere followers of Fort. One of the most notable is British philosopher John Michell who wrote the Introduction to "Lo!", published by John Brown in 1996. Michell says "Fort, of course, made no attempt at defining a world-view, but the evidence he uncovered gave him an 'acceptance' of reality as something far more magical and subtly organized than is considered proper today." Stephen King also uses the works of Fort to illuminate his main characters, notably "It" and "Firestarter". In "Firestarter", the parents of a pyrokinetically gifted child are advised to read Fort's "Wild Talents" rather than the works of baby doctor Benjamin Spock. Loren Coleman is a well-known cryptozoologist, author of "The Unidentified" (1975) dedicated to Fort, and "Mysterious America", which Fortean Times called a Fortean classic. Indeed, Coleman calls himself the first Vietnam era C.O. to base his pacificist ideas on Fortean thoughts. Jerome Clark has described himself as a "sceptical Fortean". Mike Dash is another capable Fortean, bringing his historian's training to bear on all manner of odd reports, while being careful to avoid uncritically accepting "any" orthodoxy, be it that of fringe devotees or mainstream science. Science-fiction writers of note including Philip K. Dick, Robert Heinlein, and Robert Anton Wilson were also fans of the work of Fort.
Fort's work, of compilation and commentary on anomalous phenomena has been carried on by William R. Corliss, whose self-published books and notes bring Fort's collections up to date.
In 1939 Eric Frank Russell first published the novel which became "Sinister Barrier", in which he names Fort explicitly as an influence. Russell included some of Fort's data in the story.
Ivan T. Sanderson, Scottish naturalist and writer, was a devotee of Fort's work, and referenced it heavily in several of his own books on unexplained phenomena, notably "Things" (1967), and "More Things" (1969).
Louis Pauwels and Jacques Bergier's "The Morning of the Magicians" was also heavily influenced by Fort's work and mentions it often.
The noted UK paranormalist, Fortean and ordained priest Lionel Fanthorpe presented the "Fortean TV" series on Channel 4.
Paul Thomas Anderson's popular movie "Magnolia" (1999) has an underlying theme of unexplained events, taken from the 1920s and '30s works of Charles Fort. Fortean author Loren Coleman has written a chapter about this motion picture, entitled "The Teleporting Animals and "Magnolia"", in one of his recent books. The film has many hidden Fortean themes, notably "falling frogs". In one scene, one of Fort's books is visible on a table in a library and there is an end credit thanking him by name.
In the 2011 film "The Whisperer in Darkness", Fort is portrayed by Andrew Leman.
The American crime and science fiction author Frederic Brown included an excerpt from Fort's book "Wild Talents" at the beginning of his novel "Compliments of a Fiend". In that quote Fort speculated about the disappearance of two people named Abrose and wondered "was someone collecting Ambroses?" Brown's novel is centered around the disappearance of a character named Ambrose and the kidnapper calls himself the "Ambrose collector" as an obvious homage to Fort.
Author Donald Jeffries referenced Charles Fort repeatedly in his 2007 novel "The Unreals"
Partial bibliography.
All of Fort's works are available on-line (see External links section below).
External links.
The following online editions of Fort's work, edited and annotated by a Fortean named "Mr. X", are at "Mr. X"'s site :

</doc>
<doc id="44492" url="http://en.wikipedia.org/wiki?curid=44492" title="List of areas in the United States National Park System">
List of areas in the United States National Park System

<onlyinclude>
The National Park System of the United States is the collection of physical properties owned or administered by the National Park Service. This includes all areas designated national parks and most national monuments, as well as several other types of protected areas of the United States.
As of 2015, there are 407 units of the National Park System. However, this number is somewhat misleading. For example, Denali National Park and Preserve is counted as two units, since the same name applies to a national park and an adjacent national preserve. Yet Jean Lafitte National Historical Park and Preserve is counted as one unit, despite its double designation. Counting methodology is rooted in the language of a park's enabling legislation. Elsewhere, Fort Moultrie is not counted as a unit because it is considered a feature of Fort Sumter National Monument.
In addition to areas of the National Park System, the National Park Service also provides technical and financial assistance to several affiliated areas authorized by Congress. Affiliated areas are marked on the lists below.</onlyinclude>
The National Register of Historic Places is administered by the Park Service (with nearly 79,000 entries) and automatically includes all National Park System areas designated due to their historic significance. This includes all National Historical Parks/Historic Sites, National Battlefields/Military Parks, National Memorials, and some National Monuments.
Units are found in all 50 states, in Washington, D.C., and in the U.S. territories of Guam, the Northern Mariana Islands, American Samoa, the U.S. Virgin Islands, and Puerto Rico.
Nearly all units managed by the National Park Service participate in the National Park Passport Stamps program.
 <br> 
 <br> 
 <br> 
 <br> 
 <br> 
 <br> 
 <br> 
 <br> 
 <br> 
 <br> 
 <br> 
 <br> 
 <br> 
 <br> 
 <br> 
 <br> 
 <br> 
 <br> 
 <br> 
 <br> 
 <br> 
 <br> 
 <br> 
 <br> 
 <br> 
 <br> 
 <br> 
 <br> 
 <br> 
 <br> 
 <br> 
 <br> 
 <br> 
 <br> 
 <br> 
 <br> 
 <br> 
 <br> 
 <br> 
 <br> 
 <br> 
 <br> 
 <br> 
 <br> 
 <br> 
 <br> 
 <br> 
 <br> 
 <br> 
 <br> 
 <br> 
 <br> 
 <br> 
 <br> 
 <br> 
 <br> 
 <br> 
 <br> 
National parks of the U.S.
National parks.
Existing national parks.
There are 59 officially-designated national parks in the United States and its dependent areas.
National monuments.
As of 2014, there are 106 U.S. national monuments, of which 78 are administered by the NPS and are listed below. The remaining 28 monuments are administered by 5 other federal agencies. One, Grand Canyon-Parashant National Monument, is jointly administered by the NPS and the BLM.
National preserves.
There are 19 national preserves.
National historical parks.
There are 49 national historical parks.
National historic sites.
The National Park Service administers most of the national historic sites. However, the U.S. Forest Service manages one, Grey Towers National Historic Site, and the Bureau of Land Management manages Fort Craig National Historic Site.
There are 90 national historic sites, of which 78 are NPS units and 12 are affiliated areas.
National memorials.
There are 29 national memorials that are NPS units and five affiliated national memorials.
National recreation areas.
There are 18 national recreation areas administered by the National Park Service.
National seashores.
There are 10 national seashores.
National lakeshores.
There are four national lakeshores, located in Michigan, Indiana, and Wisconsin.
National rivers.
There are 5 national rivers and 10 national wild and scenic rivers administered as distinct units of the National Park System. 
National historic and scenic trails.
These National Park Service trails are part of the larger National Trails System. Only 3 of the trails are considered official units of the park system.
National cemeteries.
Most national cemeteries are administered by the Department of Veterans Affairs, although a few are managed by the National Park Service and the U.S. Army. None of the cemeteries are considered official units of the system; they are all affiliated with other parks.
National heritage areas.
The National Park Service provides limited assistance to national heritage areas, but does not administer them.
Other NPS protected areas and administrative groups.
There are 11 NPS units of other designations, as well as other affiliated areas. The National Mall and national capital parks have many sites, some of which are also units of other designations and some are also national historic sites.
There are also various administrative groups of listed parks, such as Manhattan Sites, National Parks of New York Harbor, and Western Arctic National Parklands. The NPS also owns conservation easements (but not the land itself) for part of the area called the Green Springs National Historic Landmark District.
Disbanded other areas.
In the 1930 and 1940s, the NPS developed dozens of recreational demonstration areas, most of which eventually became national or state parks.

</doc>
<doc id="44495" url="http://en.wikipedia.org/wiki?curid=44495" title="Linear motor">
Linear motor

A linear motor is an electric motor that has had its stator and rotor "unrolled" so that instead of producing a torque (rotation) it produces a linear force along its length. However, linear motors are not necessarily straight. Characteristically, a linear motor's active section has ends, whereas more conventional motors are arranged as a continuous loop.
The most common mode of operation is as a Lorentz-type actuator, in which the applied force is linearly proportional to the current and the magnetic field formula_1.
Many designs have been put forward for linear motors, falling into two major categories, low-acceleration and high-acceleration linear motors. Low-acceleration linear motors are suitable for maglev trains and other ground-based transportation applications. High-acceleration linear motors are normally rather short, and are designed to accelerate an object to a very high speed, for example see the coilgun.
High-acceleration linear motors are typically used in studies of hypervelocity collisions, as weapons, or as mass drivers for spacecraft propulsion. They are usually of the AC linear induction motor (LIM) design with an active three-phase winding on one side of the air-gap and a passive conductor plate on the other side. However, the direct current homopolar linear motor railgun is another high acceleration linear motor design. The low-acceleration, high speed and high power motors are usually of the linear synchronous motor (LSM) design, with an active winding on one side of the air-gap and an array of alternate-pole magnets on the other side. These magnets can be permanent magnets or energized magnets. The Shanghai Transrapid motor is an LSM.
Types.
Induction motor.
In this design, the force is produced by a moving linear magnetic field acting on conductors in the field. Any conductor, be it a loop, a coil or simply a piece of plate metal, that is placed in this field will have eddy currents induced in it thus creating an opposing magnetic field, in accordance with Lenz's law. The two opposing fields will repel each other, thus creating motion as the magnetic field sweeps through the metal.
Synchronous motor.
In this design the rate of movement of the magnetic field is controlled, usually electronically, to track the motion of the rotor. For cost reasons synchronous linear motors rarely use commutators, so the rotor often contains permanent magnets, or soft iron. Examples include coilguns and the motors used on some maglev systems, as well as many other linear motors.
Homopolar.
In this design a large current is passed through a metal sabot across sliding contacts that are fed from two rails. The magnetic field this generates causes the metal to be projected along the rails.
Piezo electric.
Piezoelectric drive is often used to drive small linear motors.
History.
Low acceleration.
The history of linear electric motors can be traced back at least as far as the 1840s, to the work of Charles Wheatstone at King's College in London, but Wheatstone's model was too inefficient to be practical. A feasible linear induction motor is described in the U.S. Patent (1905 - inventor Alfred Zehden of Frankfurt-am-Main), for driving trains or lifts. The German engineer Hermann Kemper built a working model in 1935. In the late 1940s, Dr. Eric Laithwaite of Manchester University, later Professor of Heavy Electrical Engineering at Imperial College in London developed the first full-size working model. In a single sided version the magnetic repulsion forces the conductor away from the stator, levitating it, and carrying it along in the direction of the moving magnetic field. He called the later versions of it magnetic river.
Because of these properties, linear motors are often used in maglev propulsion, as in the Japanese Linimo magnetic levitation train line near Nagoya. However, linear motors have been used independently of magnetic levitation, as in Bombardier's Advanced Rapid Transit systems worldwide and a number of modern Japanese subways, including Tokyo's Toei Oedo Line.
Similar technology is also used in some roller coasters with modifications but, at present, is still impractical on street running trams, although this, in theory, could be done by burying it in a slotted conduit.
Outside of public transportation, vertical linear motors have been proposed as lifting mechanisms in deep mines, and the use of linear motors is growing in motion control applications. They are also often used on sliding doors, such as those of low floor trams such as the Citadis and the Eurotram. Dual axis linear motors also exist. These specialized devices have been used to provide direct "X"-"Y" motion for precision laser cutting of cloth and sheet metal, automated drafting, and cable forming. Most linear motors in use are LIM (linear induction motor), or LSM (linear synchronous motor). Linear DC motors are not used due to higher cost and linear SRM suffers from poor thrust. So for long run in traction LIM is mostly preferred and for short run LSM is mostly preferred.
High acceleration.
High-acceleration linear motors have been suggested for a number of uses.
They have been considered for use as weapons, since current armour-piercing ammunition tends to consist of small rounds with very high kinetic energy, for which just such motors are suitable. Many amusement park roller coasters now use linear induction motors to propel the train at a high speed, as an alternative to using a lift hill. The United States Navy is also using linear induction motors in the Electromagnetic Aircraft Launch System that will replace traditional steam catapults on future aircraft carriers. They have also been suggested for use in spacecraft propulsion. In this context they are usually called mass drivers. The simplest way to use mass drivers for spacecraft propulsion would be to build a large mass driver that can accelerate cargo up to escape velocity, though RLV launch assist like StarTram to low earth orbit has also been investigated.
High-acceleration linear motors are difficult to design for a number of reasons. They require large amounts of energy in very short periods of time. One rocket launcher design calls for 300 GJ for each launch in the space of less than a second. Normal electrical generators are not designed for this kind of load, but short-term electrical energy storage methods can be used. Capacitors are bulky and expensive but can supply large amounts of energy quickly. Homopolar generators can be used to convert the kinetic energy of a flywheel into electric energy very rapidly. High-acceleration linear motors also require very strong magnetic fields; in fact, the magnetic fields are often too strong to permit the use of superconductors. However, with careful design, this need not be a major problem.
Two different basic designs have been invented for high-acceleration linear motors: railguns and coilguns.
Usage.
Linear motors are widely used. One of the major uses of linear motors is for propelling the shuttle in looms.
Linear motors have been used for sliding doors and various similar actuators. Also, they have been used for baggage handing and can even drive large-scale bulk materials transport solutions.
Linear motors are sometimes used to create rotary motion, for example, they have been used at observatories to deal with the large radius of curvature.
A linear motor has been used for accelerating cars for crash tests.
Train propulsion.
Conventional rails.
All applications are in rapid transit.
Both the Kawasaki trains and Bombardier's ART have the active part of the motor in the cars and use overhead wires (Japanese subways) or a third rail (ART) to transfer power to the train.
Amusement rides.
There are many roller coasters throughout the world that use LIMs to accelerate the ride vehicles. The first being "Flight of Fear" at Kings Island and Kings Dominion. Both opened in 1996.
e.g.:

</doc>
<doc id="44498" url="http://en.wikipedia.org/wiki?curid=44498" title="State Council of the People's Republic of China">
State Council of the People's Republic of China

The State Council (), constitutionally synonymous with the Central People's Government () since 1954 (particularly in relation to local governments), is the chief administrative authority of the People's Republic of China. It is chaired by the Premier and includes the heads of each governmental department and agency. Currently, the council has 35 members: the premier, one executive vice premier, three vice premiers, five state councilors (of whom two are also ministers), and 25 additional ministers and chairs of major agencies. In the politics of the People's Republic of China, the Central People's Government forms one of three interlocking branches of power, the others being the Communist Party of China and the People's Liberation Army. The State Council directly oversees the various subordinate People's Governments in the provinces, and in practice maintains membership with the top levels of the Communist Party of China.
Organization.
The State Council meets once every six months. Between meetings it is guided by a Politburo that meets weekly. The standing committee includes the premier, one executive vice premier, three vice premiers, and five other state councilors (one of whom serves as Secretary General of the State Council, and two of whom concurrently serve as ministers).
The vice-premiers and state councilors are nominated by the premier, and appointed by the president with National People's Congress' (NPC) approval. Incumbents may serve two successive five-year terms.
Each vice premier oversees certain areas of administration. Each State Councilor performs duties as designated by the Premier. The secretary-general heads the General Office which handles the day-to-day work of the State Council. The secretary-general has relatively little power and should not be confused with the General Secretary of the Communist Party of China.
Each ministry supervises one sector. Commissions outrank ministries and set policies for and coordinate the related activities of different administrative organs. Offices deal with matters of ongoing concern. Bureaus and administrations rank below ministries.
In addition to the 25 ministries, there are 38 centrally administered government organizations that report directly to the state council. The heads of these organizations attend full meetings of the state committee on an irregular basis.
The State Council is formally responsible to the NPC and its Standing Committee in conducting a wide range of government functions both at the national and at the local levels, and nominally acts by virtue of the NPC's authority. There has been at least one case where the NPC has outright rejected an initiative of the State Council and a few cases where the State Council has withdrawn or greatly modified a proposal in response to NPC opposition.
The State Council and the Communist Party of China are also tightly interlocked. With rare exceptions, State Councilors are high-ranking members of the CCP. Although, as party members, they are supposed to follow party instructions, because they tend to be senior members of the party they also have substantial influence over what those instructions are. This results in a system which is unlike the Soviet practice in which the Party effectively controlled the state. Rather, the party and state are fused at this level of government. The members of the State Council derive their authority from being members of the state, while as members of the Party they coordinate their activities and determine key decisions such as the naming of personnel.
There were attempts to separate the party and state in the late 1980s under Zhao Ziyang and have the Party in charge of formulating policy and the State Council executing policy, but these efforts were largely abandoned in the early 1990s.
As the chief administrative organ of government, its main functions are to formulate administrative measures, issue decisions and orders, and monitor their implementation; draft legislative bills for submission to the NPC or its Standing Committee; and prepare the economic plan and the state budget for deliberation and approval by the NPC. The State Council is the functional center of state power and clearinghouse for government initiatives at all levels. With the government's emphasis on economic modernization, the State Council clearly acquired additional importance and influence.
The State Council controls the Ministry for National Defense but does not control the People's Liberation Army, which is instead controlled by the Central Military Commission.

</doc>
<doc id="44501" url="http://en.wikipedia.org/wiki?curid=44501" title="Cast Away">
Cast Away

Cast Away is a 2000 American adventure drama film directed and produced by Robert Zemeckis and starring Tom Hanks as a FedEx employee stranded on an uninhabited island after his plane crashes in the South Pacific. The film depicts his attempts to survive on the island using remnants of his plane's cargo. The film was a critical and commercial success, and Hanks was nominated for Best Actor in a Leading Role at the 73rd Academy Awards for his performance.
Plot.
In 1995, Chuck Noland (Tom Hanks) is a time-obsessed systems engineer, who travels worldwide resolving productivity problems at FedEx depots. He is in a long-term relationship with Kelly Frears (Helen Hunt), with whom he lives in Memphis, Tennessee. Although the couple wants to get married, Chuck's busy schedule interferes with their relationship. A Christmas with relatives is interrupted when Chuck is summoned to resolve a problem in Malaysia. While flying through a violent storm, his plane crashes into the Pacific Ocean. Chuck escapes the sinking plane and is saved by an inflatable life-raft but loses the raft's emergency locator transmitter. He clings to the life-raft, loses consciousness, and floats all night before being washed up on an island. After he awakens, he explores the island and soon discovers that it is uninhabited.
Several FedEx packages from the crashed plane wash up on the shore, as well as the corpse of one of the pilots (which he buries). He initially tries to signal for rescue and makes an escape attempt with the remnants of his life-raft but cannot pass the powerful surf and the coral reefs surrounding the island. He searches for food, water, shelter, and opens the packages, finding a number of potentially useful items. He leaves one package, with a pair of wings painted on it, unopened. During a first attempt to make fire, Chuck receives a deep wound to his hand. In anger and pain, he throws several objects, including a Wilson volleyball from one of the packages. A short time later he draws a face in the bloody hand print on the ball, names it Wilson, and begins talking to it.
Four years later, Chuck is dramatically thinner, bearded, with longer hair, and wearing a loincloth. He has become adept at spearing fish and making fires. He also has regular conversations and arguments with Wilson, his volleyball friend. A large section from a portable toilet washes up on the island; Chuck uses it as a sail in the construction of a raft. After spending some time building and stocking the raft and deciding when the weather conditions will be optimal (using an analemma he has created in his cave to monitor the time of year), he launches, using the sail to overcome the powerful surf. After some time on the ocean, a storm nearly tears his raft apart. The following day, Wilson falls from the raft and is cast away into the ocean, leaving Chuck overwhelmed by loneliness. Later, a passing cargo ship finds him, drifting.
Upon returning to civilization, Chuck learns that he has long been given up for dead; his family and acquaintances have held a funeral, and Kelly has since married Chuck's dentist and has a daughter. After reuniting with Kelly, the pair profess their love for each other but, realizing a future together would be impossible because of her commitment to her family, they part. Kelly gives Chuck the keys to the car they once shared. After buying a new volleyball, Chuck travels to Canadian, Texas to return the unopened FedEx package to its sender. The house at the address is empty, so he leaves the package at the door with a note saying that the package saved his life. He departs and stops at a remote crossroads. A woman passing by in a pickup truck stops to explain where each road leads. As she drives away, Chuck notices the illustration on her truck is identical to the one on the parcel. Chuck is left looking down each road and then towards the departing woman in the truck, smiling as the wind blows in her direction.
Production.
The film was not shot consecutively. Hanks gained 50 pounds during pre-production to make him look like a pudgy, middle-aged man. After a majority of the film was shot, production was halted for a year so that he could lose the weight and grow his hair and beard to look like he had been living on the island for years. During the year-long hiatus, Zemeckis used the same film crew to make another film, "What Lies Beneath".
"Cast Away" was filmed on Monuriki, one of the Mamanuca Islands in Fiji. It is in a subgroup of the Mamanuca archipelago, which is sited off the coast of Viti Levu, Fiji's largest island. The island became a tourist attraction following the film's release. After Chuck's return, it is identified by Kelly as being "about 600 miles south of the Cook Islands," but there is actually no land between the southern-most Cook Islands of Mangaia and Antarctica.
The film essentially begins and ends in the same location, on the Arrington Ranch in the Texas Panhandle south of the city of Canadian, Texas.
The producers made up a list of seemingly useless items that would be in the packages that Noland recovered: party dress, ice skates, divorce papers, video tapes, and other sundries. They turned this over to a group of survival experts who decided how the protagonist might be able to use them.
Music.
The film's minimal score was composed by Alan Silvestri for which he won a Grammy Award in 2002. The film's soundtrack is most notable for its lack of score and creature sound effects (such as bird song or insect sounds) while Chuck is on the island, which is intended to reinforce the feeling of isolation. "Cast Away" contains no original musical score until Chuck escapes the island. However, there is a Russian choral piece heard near the start of the film that was not composed or even recorded by Silvestri, so it does not appear on the film's soundtrack list. It is a traditional Russian song written by Lev Knipper called "Oh, My Field" ("Polyushko, Polye") and it is available on various collections of Red Army hymns. The tracks in Silvestri's score are as follows:
The official soundtrack CD is an anthology of musical pieces from all films up to that point directed by Zemeckis and scored by Silvestri. The only track from "Cast Away" itself is the theme from the end credits.
FedEx.
FedEx paid no money for product placement in the film. However, they provided access to their facilities (Memphis, Los Angeles and Moscow) as well as airplanes, trucks, uniforms and logistical support. A team of FedEx marketers oversaw production through more than two years of filming. FedEx CEO Fred Smith made an appearance as himself for the scene where Chuck is welcomed back, which was filmed on location at FedEx's home facilities in Memphis, Tennessee. The idea of a story based on a FedEx plane crashing gave the company "a heart attack at first," but the overall story was seen as positive and the company saw an increase in brand awareness in Asia and Europe following the film's release.
Wilson the volleyball.
In the film, Wilson the volleyball serves as Chuck Noland's personified friend and only companion during the five years that Noland spends alone on a deserted island. The character was created by screenwriter William Broyles, Jr. While researching for the film, he consulted with professional survival experts, and then chose to deliberately strand himself for one week on an isolated beach in the Gulf of California, to force himself to search for water and food, and obtain his own shelter. During this time, a volleyball washed up on shore. This was the inspiration for the film's inanimate companion. From a theatrical point of view, Wilson also serves to realistically allow dialogue in a one-person-only situation.
One of the original volleyball props was sold at auction after release of the film for $18,500 to the ex-CEO of FedEx Office, Ken May. At the time of the film's release, Wilson launched its own joint promotion centered on the fact that one of its products was "co-starring" with Tom Hanks. Wilson manufactured a volleyball with a reproduction of the bloodied handprint face on one side. It was sold for a limited time during the film's initial release and continues to be offered on the company's website.
Reception.
"Cast Away" received critical acclaim and has a rating of 90% on Rotten Tomatoes based on 154 reviews with an average rating of 7.4 out of 10 with the consensus "Flawed but fascinating, Cast Away offers an intelligent script, some of Robert Zemeckis' most mature directing, and a showcase performance from Tom Hanks." The film also has a score of 73 on Metacritic based on 32 reviews.
Cast Away opened in 2,774 theaters in North America and grossed $28,883,406 with an average of $10,412 per theater on its opening weekend. For the four day Christmas long holiday weekend, it took in a total of $39,852,075. The film kept performing well and ended up earning $233,632,142 domestically and $196,000,000 internationally for a total of $429,632,142, well above its production budget of $90 million.
In popular culture.
A FedEx commercial during the 2003 Super Bowl parodied the final scene of the film, in which Chuck returns a package to its sender. In this version, the woman answers the door, and when Chuck asks what was in the box, the woman replies: "Just a satellite phone, GPS locator, fishing rod, water purifier, and some seeds. Just silly stuff."
Media executive Lloyd Braun of ABC Studios first suggested the idea of a "Cast Away"-type television series at a dinner party in 2003. Thom Sherman later pitched the idea for "Cast Away – The Series", but never developed the idea. The concept was later developed and pitched with the title "Nowhere", which later turned into the ABC show "Lost".
In the episode "The Odyssey" in the first season of "Arrow", after missing their escape plane and being stranded on the island of Lian Yu, Oliver Queen says to Slade Wilson "I'm stranded on an island, and my only friend is named Wilson".

</doc>
<doc id="44502" url="http://en.wikipedia.org/wiki?curid=44502" title="Allegro (software)">
Allegro (software)

Allegro is a software library for video game development. The functionality of the library includes support for basic 2D graphics, image manipulation, text output, audio output, MIDI music, input and timers, as well as additional routines for fixed-point and floating-point matrix arithmetic, Unicode strings, file system access, file manipulation, data files, and 3D graphics. The library is written in the C programming language and designed to be used with C, C++, or Objective-C, with bindings available for Python, Lua, Scheme, D, Go, and other languages. Allegro comes with extensive documentation and many examples.
Allegro supports Microsoft Windows, Mac OS X, Unix-like systems, Android, and iOS, abstracting their application programming interfaces (APIs) into one portable interface. Previous versions up to 4.4 supported Microsoft Windows, Mac OS X, DOS, BeOS, and various Unix-like systems with (or without) the X Window System. There is also an independent port of Allegro on AmigaOS 4 and MorphOS.
Released under the terms of the zlib license, Allegro is free and open source software.
History.
Initially standing for "Atari Low-Level Game Routines", Allegro was originally created by Shawn Hargreaves for the Atari ST in the early 1990s. However, Shawn abandoned the Atari version as he realized the platform was dying, and reimplemented his work for the Borland C++ and DJGPP compilers in 1995. Support for Borland C++ was dropped in version 2.0, and DJGPP was the only supported compiler. As DJGPP was a DOS compiler, all games which used Allegro therefore used DOS. Around 1998, Allegro branched out into several versions. A port to Microsoft Windows, WinAllegro, was created, and also during this time, a Unix port of Allegro, XwinAllegro, was created. These various ports were brought together during the Allegro 3.9 WIP versions, with Allegro 4.0 being the first stable version of Allegro to support multiple platforms.
Allegro 5.
Current development is focused on the Allegro 5 branch, a complete redesign of both the API and much of the library's internal operation. Effort was made to make the API more consistent and multi-thread safe. By default, the library is now hardware accelerated using OpenGL or DirectX rendering backends where appropriate. Many of the addons that existed as separate projects for Allegro 4 now interface seamlessly with Allegro proper and are bundled with the default installation. Allegro 5 is event driven.
Features.
Allegro provides the following graphic functions:
Addons.
The community of Allegro users have contributed several library extensions to handle things like scrolling tile maps and import and export of various file formats (e.g. PNG, GIF, JPEG images, MPEG video, Ogg, MP3, IT, S3M, XM music, TTF fonts, and more).
Allegro 4.x and below can be used in conjunction with OpenGL by using the library "AllegroGL" which extends Allegro's functionality into OpenGL and therefore the hardware. Allegro 5 natively supports OpenGL.

</doc>
<doc id="44507" url="http://en.wikipedia.org/wiki?curid=44507" title="Chatti">
Chatti

The Chatti (also Chatthi or Catti) were an ancient Germanic tribe whose homeland was near the upper Weser. They settled in central and northern Hesse and southern Lower Saxony, along the upper reaches of the Weser River and in the valleys and mountains of the Eder, Fulda, and Weser River regions, a district approximately corresponding to Hesse-Kassel, though probably somewhat more extensive. According to Tacitus, the Batavians of his time were descended from a part of the Chatti, who left their homeland after an internal quarrel drove them out, to take up new lands at the mouth of the Rhine.
Sources.
Caesar is credited by Martial as having overcome the Chatti in his second book of Epigrams:
"Crete gave a great name, Africa a greater one: 
Scipio the victor has one, and Metellus has the other. 
Germany granted a nobler name when the Rhine had been subdued, 
and even as a boy, Caesar, you were worthy of this name. 
Your brother earned Idumaean triumphs together with your father, 
but the laurel given for the Chatti is totally yours."
While Julius Caesar was well informed about the regions and tribes on the eastern banks of the Rhine, he never mentioned the Chatti by name. He did make note of the Suebi, and suggested that they had previously driven out the Celts to the south of the Hesse-Kassel region in the prior centuries BC. Pliny the Elder, in his "Natural History" grouped the Chatti and Suebi together with the Hermunduri and the Cherusci, calling this group the Hermiones, which is a nation of Germanic tribes mentioned by Tacitus as living in inland Germany. Some commentators believe that Caesar's Suebi were possibly the later Chatti, a branch of the Suebian movement of people who had become more clearly identifiable. If not, then the Chatti may represent a successful resistance to the Suevi, as opposed to the Tencteri, Usipetes, and Ubii who all were forced from homelands in the same region by the Suebic incursions.
The first ancient writer to mention the Chatti is Strabo, some time after 16 AD, who includes the Chatti in a listing of conquered Germanic tribes who were more settled and agricultural, but also poorer, than the nomadic tribes in central and eastern Germania such as the Suebi. They were poor because they had fought the Romans, and had been defeated and plundered. 
For the first century AD, Tacitus provides important information about the Chatti's part in the Germanic wars and certain elements of their culture. He says that:[The Chatti's] settlements begin at the Hercynian forest, where the country is not so open and marshy as in the other cantons into which Germany stretches. They are found where there are hills, and with them grow less frequent, for the Hercynian forest keeps close till it has seen the last of its native Chatti. Hardy frames, close-knit limbs, fierce countenances, and a peculiarly vigorous courage, mark the tribe. For Germans, they have much intelligence and sagacity; they promote their picked men to power, and obey those whom they promote; they keep their ranks, note their opportunities, check their impulses, portion out the day, intrench themselves by night, regard fortune as a doubtful, valour as an unfailing, resource; and what is most unusual, and only given to systematic discipline, they rely more on the general than on the army. Their whole strength is in their infantry, which, in addition to its arms, is laden with iron tools and provisions. Other tribes you see going to battle, the Chatti to a campaign. Seldom do they engage in mere raids and casual encounters. It is indeed the peculiarity of a cavalry force quickly to win and as quickly to yield a victory. Fleetness and timidity go together; deliberateness is more akin to steady courage.
Tacitus also notes that like other Germanic tribes, the Chatti took an interest in traditions concerning haircuts and beards.A practice, rare among the other German tribes, and simply characteristic of individual prowess, has become general among the Chatti, of letting the hair and beard grow as soon as they have attained manhood, and not till they have slain a foe laying aside that peculiar aspect which devotes and pledges them to valour. Over the spoiled and bleeding enemy they show their faces once more; then, and not till then, proclaiming that they have discharged the obligations of their birth, and proved themselves worthy of their country and of their parents. The coward and the unwarlike remain unshorn. The bravest of them also wear an iron ring (which otherwise is a mark of disgrace among the people) until they have released themselves by the slaughter of a foe. Most of the Chatti delight in these fashions. Even hoary-headed men are distinguished by them, and are thus conspicuous alike to enemies and to fellow-countrymen. To begin the battle always rests with them; they form the first line, an unusual spectacle. Nor even in peace do they assume a more civilised aspect. They have no home or land or occupation; they are supported by whomsoever they visit, as lavish of the property of others as they are regardless of their own, till at length the feebleness of age makes them unequal to so stern a valour.
Between the Rhine and the Chatti, Tacitus places the Tencteres and Usipetes, who apparently had been moved since the time of Caesar into the old homeland of the Ubii, who had in turn settled in Cologne. (Caesar had described these three tribes as under pressure from Suebi to their east, and attempting to move across the Rhine.) To the south, Tacitus also says that the Chatti's land is beyond the questionable lands, the so-called tithe lands, or agri decumates, that adventurers from the Roman sides of the Rhine and Danube had been trying to settle. It is possible that at first the Chatti moved into place on the Rhine, in the old territory of the Ubii. Cassius Dio describes Drusus establishing a fort in Chatti territory on the Rhine in 11 BC, and that in 10 BC they moved out of an area where the Romans had permitted them.
To the north of the Chatti, Tacitus places the large area of the Chauci. To the east, the neighbours of the Chatti and Chauci were the Cherusci, who Tacitus describes as excessively peace-loving in his time. (Caesar had described the Suevi, not the Chatti, as living between the Ubii on the Rhine and a forest called the Bacenis, which separated them from the Cherusci. This is why Caesar's Suevi are sometimes thought to be Chatti.)
After the early thirrd century AD, however, the Chatti virtually disappear from the sources and are only called upon as a topical element or when writing about events of the first century. Cassius Dio is most likely not only the first author to mention the Alamanni but also the last one to record a historical appearance of the Chatti. Writing about the Germanic war of Caracalla in 213 AD, he has the emperor fight "Κέννους, Kελτικòν ἔθνος" ("the Kenni, a Celtic people"). This is taken from an excerpt of Dio in the writings of Joannes Xiphilinus, however, whereas the Fragmenta Valesiana refer to the same people as "Chattoi". The usage of "Kελτικός" for Germanic peoples was an archaic tradition among Greek writers.
After Cassius Dio, the name "Chattus" appears among others in a panegyric by Sidonius Apollinaris in the late fifth century, now as a poetic synonym for "Germanus". The last ancient source to mention the Chatti, if only in a quotation of Sulpicius Alexander describing events of the late fourth century, was Gregory of Tours.
Proto-history.
The extremely large timescale of Prehistoric Europe left stone tools and weapons dating from the Paleolithic to the Iron Age that were chronologically ordered and dated in the nineteenth and twentieth centuries. Tribes such as the Chatti, Cimbri, and Langobardi have not been well distinguished until relatively recently.
History.
The Chatti successfully resisted incorporation into the Roman Empire, joining the Cheruscan war leader Arminius' coalition of tribes that annihilated Varus' legions in 9 AD in the Battle of the Teutoburg Forest. Germanicus later, in 15, raided their lands in revenge, but Rome eventually responded to the Chatti's belligerent defense of their independence by building the limes border fortifications along the southern boundary of their lands in central Hesse during the early years of the first century. A major raid by the Chatti into Germania Superior was defeated decisively by the legions in 50 AD.
Roman sources identify the fabled Mattium, beyond the Eder, as the capital of the Chatti. Destroyed by Germanicus, its location is not known today, but generally is assumed to be in the wider neighbourhood of Fritzlar north of the river Eder.
The Chatti eventually became a branch of the much larger neighboring Franks and were incorporated in the kingdom of Clovis I, probably with the Ripuarians, at the beginning of the sixth century. 
In 723, the Anglo-Saxon missionary Winfrid—subsequently called St. Boniface, Apostle of the Germans—proselytizing among the Chatti, felled their sacred tree, Thor's Oak, near Fritzlar, as part of his efforts to compel the conversion of the Chatti and the other northern Germanic tribes to Christianity. 
"Chatti" is probably the origin of the modern regional name "Hesse" through the High German consonant shifts.
Chasuarii and Chattuarii.
Two tribes in northern Germany have names that are sometimes compared to the Chatti. The Chattuarii, whose name appears to mean that they are dwellers upon the Chatti lands, or else Chatti people, lived near the Rhine, probably between IJssel and Lippe. They came to be seen as Franks and apparently moved over the Rhine as a Frankish people, to settle into the corner of land between the Rhine and Maas rivers.
The name of the Chattuarii is in turn, sometimes compared to another people called the Chasuarii mentioned by several classical authors. The Chasuarii were a Germanic tribe mentioned by Tacitus in the "Germania". According to him, they dwelt to the north of the Chamavi and Angrivarii, who dwelt in turn to the north of the Bructeri, between Ems and Weser, however the name of the Chasuarii most often is interpreted to mean "dwellers on the Hase [river]", a tributary to the Ems. The second century geographer Claudius Ptolemy mentions that the Kasouarioi lived to the east of the Abnoba mountains, in the vicinity of Hesse, but this account of northern Europe is thought to contain confusions derived from using different sources.

</doc>
<doc id="44508" url="http://en.wikipedia.org/wiki?curid=44508" title="Warren Sturgis McCulloch">
Warren Sturgis McCulloch

Warren Sturgis McCulloch (November 16, 1898 – September 24, 1969) was an American neurophysiologist and cybernetician, known for his work on the foundation for certain brain theories and his contribution to the cybernetics movement.
Biography.
Warren Sturgis McCulloch was born in Orange, New Jersey, in 1898. He attended Haverford and studied philosophy and psychology at Yale University, where he received an A.B. degree in 1921. He continued to study psychology at Columbia and received a M.A. degree in 1923. Receiving his MD in 1927 from the Columbia University College of Physicians and Surgeons in New York, he undertook an internship at Bellevue Hospital, New York, before returning to academia in 1934. He worked at the Laboratory for Neurophysiology at Yale University from 1934 to 1941, before moving to the Department of Psychiatry at the University of Illinois at Chicago.
From 1952 he worked at the Massachusetts Institute of Technology in Cambridge, Massachusetts. He also worked at Yale University and later at the University of Chicago.
He was a founding member of the American Society for Cybernetics and its second president during 1967–1968. He was a mentor to the British operations research pioneer Stafford Beer.
Warren McCulloch had a remarkable range of interests and talents. In addition to his scientific contributions he wrote poetry (sonnets), and he designed and engineered buildings and a dam at his farm in Old Lyme, Connecticut.
He died in Cambridge in 1969.
Work.
He is remembered for his work with Joannes Gregorius Dusser de Barenne from Yale and later with Walter Pitts from the University of Chicago. Here he provided the foundation for certain brain theories in a number of classic papers, including "A Logical Calculus of the Ideas Immanent in Nervous Activity" (1943) and "How We Know Universals: The Perception of Auditory and Visual Forms" (1947), both published in the Bulletin of Mathematical Biophysics. The former is "widely credited with being a seminal contribution to neural network theory, the theory of automata, the theory of computation, and cybernetics".
Neural network modelling.
In the 1943 paper they attempted to demonstrate that a Turing machine program could be implemented in a finite network of "formal" neurons, (in the event, the Turing Machine contains their model of the brain, but the converse is not true) that the neuron was the base logic unit of the brain. In the 1947 paper they offered approaches to designing "nervous nets" to recognize visual inputs despite changes in orientation or size.
From 1952 he worked at the Research Laboratory of Electronics at MIT, working primarily on neural network modelling. His team examined the visual system of the frog in consideration of McCulloch's 1947 paper, discovering that the eye provides the brain with information that is already, to a degree, organized and interpreted, instead of simply transmitting an image.
Reticular formation.
McCulloch also posited the concept of "poker chip" reticular formations as to how the brain deals with contradictory information in a democratic, somatotopical neural network. His principle of "Redundancy of Potential Command" was developed by von Forster and Pask in their study of Self-organization and by Pask in his Conversation Theory and Interactions of Actors Theory.
Publications.
McCulloch wrote a book and several articles:
Articles, a selection:
Papers published by the Chicago Literary Club:

</doc>
<doc id="44510" url="http://en.wikipedia.org/wiki?curid=44510" title="Childeric I">
Childeric I

Childeric I (French: "Childéric", Latin: "Childericus"; 440 – 481/482) was a Merovingian king of the Salian Franks and the father of Clovis I, who would unite the Franks and found the Merovingian dynasty. 
Career.
Childeric succeeded his father Merovech as king of the Salian Franks, traditionally in 457 or 458. By 457 at the latest he was the ruler of the Franks in the territory covering Tournai and the Lys valley. He may have had power over further territories to the south, but the sources are unclear on this. According to Gregory of Tours, Childeric was exiled at some point, the reason being traditionally given as Frankish unhappiness with Childeric's private life. Gregory further records that the Franks recalled Childeric after 8 years of exile.
In 463 Childeric fought in conjunction with the Roman General Aegidius, the magister militum of northern Gaul based in Soissons, to defeat the Visigoths, who had hoped to extend their dominion along the banks of the Loire River. After the death of Aegidius, Childeric assisted "Comes" ("count") Paul of Angers, together with a mixed band of Gallo-Romans and Franks, in defeating the Goths and taking booty. Saxon raiders under the command of Odoacer reached Angers and captured it, but Childeric and Count Paul retook the city in 469. Childeric, having delivered Angers, followed a Saxon warband to the islands on the Atlantic mouth of the Loire, and massacred them there. In the period around 476 to 481, he and Odoacer were discussing the possibility of an alliance against the Alamanni who wished to invade Italy.
Marriage, children, and death.
Gregory of Tours, in "Libri Historiarum" (Book ii.12), records the story of the expulsion of Childeric by the Salian Franks for seducing their wives. He was exiled for eight years in Thuringia with King Basin and his wife, Queen Basina. He returned only when a faithful servant advised him that he could safely do so by sending him half of a gold piece that Childeric had split with him before his exile. The book also describes his arrival in Tournai with Basina, who had left her husband to be with him. 
Childeric married Basina and they had the following children:
Childeric died in 481 or 482 and was buried in Tournai. His son Clovis succeeded him as king of the Salian Franks.
Tomb.
Childeric's tomb was discovered in 1653 not far from the 12th-century church of Saint-Brice in Tournai, Belgium. Numerous precious objects were found, including jewels of gold and garnet cloisonné, gold coins, a gold bull's head, and a ring with the king's name inscribed. Some 300 golden bees or cicadas were also found which had been placed on the king's cloak. Archduke Leopold William, governor of the Southern Netherlands (today's Belgium), had the find published in Latin. The treasure went first to the Habsburgs in Vienna, then as a gift to Louis XIV, who was not impressed with the treasure and stored it in the royal library, which became the Bibliothèque Nationale de France during the Revolution. Napoleon was more impressed with Childeric's bees and when he was looking for a heraldic symbol to trump the Bourbon fleur-de-lys, he settled on Childeric's bees as symbols of the French Empire.
On the night of November 5–6, 1831, the treasure of Childeric was among 80 kilos of treasure stolen from the Library and melted down for the gold. A few pieces were retrieved from where they had been hidden in the Seine, including two of the bees. The record of the treasure, however, now exists only in the fine engravings made at the time of its discovery and in some reproductions made for the Habsburgs.

</doc>
