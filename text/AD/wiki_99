<doc id="60548" url="http://en.wikipedia.org/wiki?curid=60548" title="Planetarium">
Planetarium

A planetarium (plural planetaria or "planetariums") is a theatre built primarily for presenting educational and entertaining shows about astronomy and the night sky, or for training in celestial navigation.
A dominant feature of most planetaria is the large dome-shaped projection screen onto which scenes of stars, planets and other celestial objects can be made to appear and move realistically to simulate the complex 'motions of the heavens'. The celestial scenes can be created using a wide variety of technologies, for example precision-engineered 'star balls' that combine optical and electro-mechanical technology, slide projector, video and fulldome projector systems, and lasers. Whatever technologies are used, the objective is normally to link them together to provide an accurate relative motion of the sky. Typical systems can be set to display the sky at any point in time, past or present, and often to show the night sky as it would appear from any point of latitude on Earth.
Planetaria range in size from the Hayden Planetarium's 21-meter dome seating 423 people, to three-meter inflatable portable domes where children sit on the floor. Such portable planetaria serve education programs outside of the permanent installations of museums and science centers.
The term "planetarium" is sometimes used generically to describe other devices which illustrate the solar system, such as a computer simulation or an orrery. "Planetarium software" refers to a software application that renders a three-dimensional image of the sky onto a two-dimensional computer screen. The term "planetarian" is used to describe a member of the professional staff of a planetarium.
History.
Early.
Archimedes is attributed with possessing a primitive planetarium device that could predict the movements of the Sun and the Moon and the planets. The discovery of the Antikythera mechanism proved that such devices already existed during antiquity. Campanus of Novara (1220–1296) described a planetary equatorium in his "Theorica Planetarum", and included instructions on how to build one. The Globe of Gottorf built around 1650 had constellations painted on the inside. These devices would today usually be referred to as orreries (named for the Earl of Orrery, an Irish peer: an 18th-century Earl of Orrery had one built). In fact, many planetaria today have what are called projection orreries, which project onto the dome a Sun with planets (usually limited to Mercury up to Saturn) going around it in something close to their correct relative periods.
The small size of typical 18th century orreries limited their impact, and towards the end of that century a number of educators attempted some larger scale simulations of the heavens. The efforts of Adam Walker (1730–1821) and his sons are noteworthy in their attempts to fuse theatrical illusions with educational aspirations. Walker's Eidouranion was the heart of his public lectures or theatrical presentations. Walker's son describes this "Elaborate Machine" as "twenty feet high, and twenty-seven in diameter: it stands vertically before the spectators, and its globes are so large, that they are distinctly seen in the most distant parts of the Theatre. Every Planet and Satellite seems suspended in space, without any support; performing their annual and diurnal revolutions without any apparent cause". Other lecturers promoted their own devices: R E Lloyd advertised his Dioastrodoxon, or Grand Transparent Orrery, and by 1825 William Kitchener was offering his Ouranologia, which was 42 ft in diameter. These devices most probably sacrificed astronomical accuracy for crowd-pleasing spectacle and sensational and awe-provoking imagery.
The oldest, still working planetarium can be found in the Dutch town Franeker. It was built by Eise Eisinga (1744–1828) in the living room of his house. It took Eisinga seven years to build his planetarium, which was completed in 1781.
In 1905 Oskar von Miller (1855–1934) of the Deutsches Museum in Munich commissioned updated versions of a geared orrery and planetarium from M Sendtner, and later worked with Franz Meyer, chief engineer at the Carl Zeiss optical works in Jena, on the largest mechanical planetarium ever constructed, capable of displaying both heliocentric and geocentric motion. This was displayed at the Deutsches Museum in 1924, construction work having been interrupted by the war. The planets travelled along overhead rails, powered by electric motors: the orbit of Saturn was 11.25 m in diameter. 180 stars were projected onto the wall by electric bulbs.
While this was being constructed, von Miller was also working at the Zeiss factory with German astronomer Max Wolf, director of the Landessternwarte Heidelberg-Königstuhl observatory of the University of Heidelberg, on a new and novel design, inspired by Wallace W. Atwood's work at the Chicago Academy of Sciences and by the ideas of Walther Bauersfeld and Rudolf Straubel at Zeiss. The result was a planetarium design which would generate all the necessary movements of the stars and planets inside the optical projector, and would be mounted centrally in a room, projecting images onto the white surface of a hemisphere. In August 1923, the first (Model I) Zeiss planetarium projected images of the night sky onto the white plaster lining of a 16 m hemispherical concrete dome, erected on the roof of the Zeiss works. The first official public showing was at the Deutsches Museum in Munich on October 21, 1923.
After World War II.
When Germany was divided into East and West Germany after the war, the Zeiss firm was also split. Part remained in its traditional headquarters at Jena, in East Germany, and part migrated to West Germany. The designer of the first planetaria for Zeiss, Walther Bauersfeld, also migrated to West Germany with the other members of the Zeiss management team. There he remained on the Zeiss West management team until his death in 1959.
The West German firm resumed making large planetaria in 1954, and the East German firm started making small planetaria a few years later. Meanwhile, the lack of planetarium manufacturers had led to several attempts at construction of unique models, such as one built by the California Academy of Sciences in Golden Gate Park, San Francisco, which operated 1952-2003. The Korkosz brothers built a large projector for the Boston Museum of Science, which was unique in being the first (and for a very long time only) planetarium to project the planet Uranus. Most planetaria ignore Uranus as being at best marginally visible to the naked eye.
A great boost to the popularity of the planetarium worldwide was provided by the Space Race of the 1950s and 60s when fears that the United States might miss out on the opportunities of the new frontier in space stimulated a massive program to install over 1,200 planetaria in U.S. high schools.
Armand Spitz recognized that there was a viable market for small inexpensive planetaria. His first model, the Spitz A, was designed to project stars from a dodecahedron, thus reducing machining expenses in creating a globe. Planets were not mechanized, but could be shifted by hand. Several models followed with various upgraded capabilities, until the A3P, which projected well over a thousand stars, had motorized motions for latitude change, daily motion, and annual motion for Sun, Moon (including phases), and planets. This model was installed in hundreds of high schools, colleges, and even small museums from 1964 to the 1980s.
Japan entered the planetarium manufacturing business in the 1960s, with Goto and Minolta both successfully marketing a number of different models. Goto was particularly successful when the Japanese Ministry of Education put one of their smallest models, the E-3 or E-5 (the numbers refer to the metric diameter of the dome) in every elementary school in Japan.
Phillip Stern, as former lecturer at New York City's Hayden Planetarium, had the idea of creating a small planetarium which could be programmed. His Apollo model was introduced in 1967 with a plastic program board, recorded lecture, and film strip. Unable to pay for this himself, Stern became the head of the planetarium division of Viewlex, a mid-size audio-visual firm on Long Island. About thirty canned programs were created for various grade levels and the public, while operators could create their own or run the planetarium live. Purchasers of the Apollo were given their choice of two canned shows, and could purchase more. A few hundred were sold, but in the late 1970s Viewlex went bankrupt for reasons unrelated to the planetarium business.
During the 1970s, the OmniMax movie system (now known as IMAX Dome) was conceived to operate on planetarium screens. More recently, some planetaria have re-branded themselves as "dome theaters", with broader offerings including wide-screen or "wraparound" films, fulldome video, and laser shows that combine music with laser-drawn patterns.
Learning Technologies Inc. in Massachusetts offered the first easily portable planetarium in 1977. Philip Sadler designed this patented system which projected stars, constellation figures from many mythologies, celestial coordinate systems, and much else, from removable cylinders (Viewlex and others followed with their own portable versions).
When Germany reunified in 1989, the two Zeiss firms did likewise, and expanded their offerings to cover many different size domes.
Computerized planetaria.
In 1983, Evans & Sutherland installed the first planetarium projector displaying computer graphics (Hansen Planetarium, Salt Lake City, Utah)—the Digistar I projector used a vector graphics system to display starfields as well as line art.
The newest generation of planetaria offer a fully digital projection system, using fulldome video technology. This gives the operator great flexibility in showing not only the modern night sky as visible from Earth, but any other image they wish (including the night sky as visible from points far distant in space and time).
A new generation of home planetaria was released in Japan by Takayuki Ohira in cooperation with Sega. Ohira is worldwide known as a mastermind for building portable planetaria used at exhibitions and events such as the Aichi World Expo in 2005. Later, the Megastar star projectors released by Takayuki Ohira were installed in several science museums around the world. Meanwhile, Sega Toys continues to produce the Homestar series intended for home use, however by projecting 10,000 stars on the ceiling makes it semi-professional.
In 2009 and partnered on the project. The goal of the project is to bring sub-$1000 planetaria to small groups of school children as well as provide technology for large public planetaria.
Technology.
Domes.
Planetarium domes range in size from 3 to 35 m in diameter, accommodating from 1 to 500 people. They can be permanent or portable, depending on the application. 
The realism of the viewing experience in a planetarium depends significantly on the dynamic range of the image, i.e., the contrast between dark and light. This can be a challenge in any domed projection environment, because a bright image projected on one side of the dome will tend to reflect light across to the opposite side, "lifting" the black level there and so making the whole image look less realistic. Since traditional planetarium shows consisted mainly of small points of light (i.e., stars) on a black background, this was not a significant issue, but it became an issue as digital projection systems started to fill large portions of the dome with bright objects (e.g., large images of the sun in context). For this reason, modern planetarium domes are often not painted white but rather a mid grey colour, reducing reflection to perhaps 35-50%. This increases the perceived level of contrast.
A major challenge in dome construction is to make seams as invisible as possible. Painting a dome after installation is a major task and, if done properly, the seams can be made almost to disappear.
Traditionally, planetarium domes were mounted horizontally, matching the natural horizon of the real night sky. However, because that configuration requires highly inclined chairs for comfortable viewing "straight up", increasingly domes are being built tilted from the horizontal by between 5 and 30 degrees to provide greater comfort. Tilted domes tend to create a favoured 'sweet spot' for optimum viewing, centrally about a third of the way up the dome from the lowest point. Tilted domes generally have seating arranged 'stadium-style' in straight, tiered rows; horizontal domes usually have seats in circular rows, arranged in concentric (facing center) or epicentric (facing front) arrays.
Planetaria occasionally include controls such as buttons or joysticks in the arm-rests of seats to allow audience feedback that influences the show in real time.
Often around the edge of the dome (the 'cove') are:
Traditionally, planetaria needed many incandescent lamps around the cove of the dome to help audience entry and exit, to simulate sunrise and sunset, and to provide working light for dome cleaning. More recently, solid-state LED lighting has become available that significantly decreases power consumption and reduces the maintenance requirement as lamps no longer have to be changed on a regular basis.
The world's largest mechanical planetarium is located in Monico, Wisconsin. The "Kovac Planetarium". It is 22 feet in diameter and weighs two tons. The globe is made of wood and is driven with a variable speed motor controller. This is the largest mechanical planetarium in the world, larger than the "Atwood Globe" in Chicago (15 feet in diameter) and one third the size of the Hayden.
Some new planetariums now feature a glass floor, which allows spectators to stand near the center of a sphere surrounded by projected images in all directions, giving the impression of floating in outer space. For example, a small planetarium at AHHAA in Tartu, Estonia features such an installation, with special projectors for images below the feet of the audience, as well as above their heads.
Traditional electromechanical/optical projectors.
Traditional planetarium projection apparatus uses a hollow ball with a light inside, and a pinhole for each star, hence the name "star ball". With some of the brightest stars (e.g. Sirius, Canopus, Vega), the hole must be so big to let enough light through that there must be a small lens in the hole to focus the light to a sharp point on the dome. In later and modern planetarium star balls, the individual bright stars often have individual projectors, shaped like small hand-held torches, with focusing lenses for individual bright stars. Contact breakers prevent the projectors from projecting below the 'horizon'.
The star ball is usually mounted so it can rotate as a whole to simulate the Earth's daily rotation, and to change the simulated latitude on Earth. There is also usually a means of rotating to produce the effect of precession of the equinoxes. Often, one such ball is attached at its south ecliptic pole. In that case, the view cannot go so far south that any of the resulting blank area at the south is projected on the dome. Some star projectors have two balls at opposite ends of the projector like a dumbbell. In that case all stars can be shown and the view can go to either pole or anywhere between. But care must be taken that the projection fields of the two balls match where they meet or overlap.
Smaller planetarium projectors include a set of fixed stars, Sun, Moon, and planets, and various nebulae. Larger projectors also include comets and a far greater selection of stars. Additional projectors can be added to show twilight around the outside of the screen (complete with city or country scenes) as well as the Milky Way. Others add coordinate lines and constellations, photographic slides, laser displays, and other images.
Each planet is projected by a sharply focused spotlight that makes a spot of light on the dome. Planet projectors must have gearing to move their positioning and thereby simulate the planets' movements. These can be of these types:-
Despite offering a good viewer experience, traditional star ball projectors suffer several inherent limitations. From a practical point of view, the low light levels require several minutes for the audience to "dark adapt" its eyesight. "Star ball" projection is limited in education terms by its inability to move beyond an earth-bound view of the night sky. Finally, in most traditional projectors the various overlaid projection systems are incapable of proper occultation. This means that a planet image projected on top of a star field (for example) will still show the stars shining through the planet image, degrading the quality of the viewing experience. For related reasons, some planetaria show stars below the horizon projecting on the walls below the dome or on the floor, or (with a bright star or a planet) shining in the eyes of someone in the audience.
However, the new breed of Optical-Mechanical projectors using fiber-optic technology to display the stars show a much more realistic view of the sky.
Digital projectors.
An increasing number of planetaria are using digital technology to replace the entire system of interlinked projectors traditionally employed around a star ball to address some of their limitations. Digital planetarium manufacturers claim reduced maintenance costs and increased reliability from such systems compared with traditional "star balls" on the grounds that they employ few moving parts and do not generally require synchronisation of movement across the dome between several separate systems. Some planetaria mix both traditional opto-mechanical projection and digital technologies on the same dome.
In a fully digital planetarium, the dome image is generated by a computer and then projected onto the dome using a variety of technologies including cathode ray tube, LCD, DLP or laser projectors. Sometimes a single projector mounted near the centre of the dome is employed with a fisheye lens to spread the light over the whole dome surface, while in other configurations several projectors around the horizon of the dome are arranged to blend together seamlessly.
Digital projection systems all work by creating the image of the night sky as a large array of pixels. Generally speaking, the more pixels a system can display, the better the viewing experience. While the first generation of digital projectors were unable to generate enough pixels to match the image quality of the best traditional "star ball" projectors, high-end systems now offer a resolution that approaches the limit of human visual acuity.
LCD projectors have fundamental limits on their ability to project true black as well as light, which has tended to limit their use in planetaria. LCOS and modified LCOS projectors have improved on LCD contrast ratios while also eliminating the “screen door” effect of small gaps between LCD pixels. “Dark chip” DLP projectors improve on the standard DLP design and can offer relatively inexpensive solution with bright images, but the black level requires physical baffling of the projectors. As the technology matures and reduces in price, laser projection looks promising for dome projection as it offers bright images, large dynamic range and a very wide color space.
Show content.
Worldwide, most planetaria provide shows to the general public. Traditionally, shows for these audiences with themes such as "What's in the sky tonight?", or shows which pick up on topical issues such as a religious festival (often the Christmas star) linked to the night sky, have been popular. Pre-recorded and live presentation formats are possible. Live format are preferred by many venues because a live expert presenter can answer on-the-spot questions raised by the audience.
Since the early 1990s, fully featured 3-D digital planetaria have added an extra degree of freedom to a presenter giving a show because they allow simulation of the view from any point in space, not only the earth-bound view which we are most familiar with. This new virtual reality capability to travel through the universe provides important educational benefits because it vividly conveys that space has depth, helping audiences to leave behind the ancient misconception that the stars are stuck on the inside of a giant celestial sphere and instead to understand the true layout of the solar system and beyond. For example, a planetarium can now 'fly' the audience towards one of the familiar constellations such as Orion, revealing that the stars which appear to make up a co-ordinated shape from our earth-bound viewpoint are at vastly different distances from Earth and so not connected, except in human imagination and mythology. For especially visual or spatially aware people, this experience can be more educationally beneficial than other demonstrations.
Music is an important element to fill out the experience of a good planetarium show, often featuring forms of space-themed music, or music from the genres of space music, space rock, or classical music.

</doc>
<doc id="60549" url="http://en.wikipedia.org/wiki?curid=60549" title="Orrery">
Orrery

An orrery is a mechanical model of the solar system that illustrates or predicts the relative positions and motions of the planets and moons, usually according to the heliocentric model. It may also represent the relative sizes of these bodies; but since accurate scaling is often not practical due to the actual large ratio differences, a subdued approximation may be used instead. Though the Greeks had working planetaria, the first orrery that was a planetarium of the modern era was produced in 1704, and one was presented to Charles Boyle, 4th Earl of Orrery — whence came the name. They are typically driven by a clockwork mechanism with a globe representing the Sun at the centre, and with a planet at the end of each of the arms.
History.
Early versions.
According to Cicero, the Roman philosopher who was writing in the first century BC, Posidonius constructed a planetary model.
The Antikythera mechanism, discovered in 1900 in a wreck off the Greek island of Antikythera and extensively studied, exhibited the diurnal motions of the Sun, Moon, and the five known planets. It has been dated between 150 to 100 BC. The Antikythera hand driven mechanism is now considered one of the first orreries, but for many decades was ignored as it was thought to be far too complex to be genuine. It was geocentric and used as a mechanical calculator designed to calculate astronomical positions.
As late as 1650, P. Schirleus built a geocentric planetarium with the Sun as a planet, and with Mercury and Venus revolving around the Sun as its moons.
In "De revolutionibus orbium coelestium", published in Nuremberg in 1543, Nicolaus Copernicus challenged the Western teaching of a geocentric universe in which the Sun revolved daily around the Earth. He observed that some Greek philosophers had proposed a heliocentric universe. This simplified the apparent epicyclic motions of the planets, making it feasible to represent the planets' paths as simple circles. This could be modelled by the use of gears. Tycho Brahe's improved instruments made precise observations of the skies (1576–1601), and from these Johannes Kepler (1621) deduced that planets orbited the Sun in ellipses. In 1687 Isaac Newton explained the cause of elliptic motion in his theory of gravitation.
The modern orrery.
Clock makers George Graham and Thomas Tompion built the first modern orrery around 1704 in England. Graham gave the first model, or its design, to the celebrated instrument maker John Rowley of London to make a copy for Prince Eugene of Savoy. Rowley was commissioned to make another copy for his patron Charles Boyle, 4th Earl of Orrery, from which the device took its name in English. This model was presented to Charles' son John, later the 5th Earl of Cork and 5th Earl of Orrery. Independently, Christiaan Huygens published details of a heliocentric planetary machine in 1703, which he built while resident in Paris between 1665 and 1681. He calculated the gear trains needed to represent a year of 365.242 days, and used that to produce the cycles of the principal planets.
Joseph Wright's painting "A Philosopher giving a Lecture on the Orrery in which a lamp is put in place of the Sun" (ca. 1766), which hangs in Derby Museum and Art Gallery, depicts a group listening to a lecture by a natural philosopher. The Sun in a brass orrery provides the only light in the room. The orrery depicted in the painting has rings, which give it an appearance similar to that of an armillary sphere. The demonstration was thereby able to depict eclipses.
To put this in chronological context, in 1762 John Harrison's marine chronometer first enabled accurate measurement of longitude. In 1766, astronomer Johann Daniel Titius first demonstrated that the mean distance of each planet from the Sun could be represented by the following progression:
That is, 0.4, 0.7, 1.0, 1.6, 2.8, 5.2 ... The numbers refer to astronomical units, the mean distance between Sun and Earth, which is 1.496 x 10⁸ km (93 x 10⁶ miles). The Derby Orrery does not show mean distance, but demonstrated the relative planetary movements.
Eisinga's Planetarium was built from 1774 to 1781 by Eise Eisinga in his home in Franeker, in the Netherlands. It displays the planets across the width of a room's ceiling, and has been in operation almost continually since it was created. This orrery is a planetarium in both senses of the word: a complex machine showing planetary orbits, and a theatre for depicting the planets' movement. Eisinga house was bought by the Dutch Royal family who gave him a pension.
In 1764, Benjamin Martin devised a new type of planetary model, in which the planets were carried on brass arms leading from a series of concentric or coaxial tubes. With this construction it was difficult to make the planets revolve, and to get the moons to turn around the planets. Martin suggested that the conventional orrery should consist of three parts: the planetarium where the planets revolved around the Sun, the tellurion (also "tellurian" or "tellurium") which showed the inclined axis of the Earth and how it revolved around the Sun, and the lunarium which showed the eccentric rotations of the Moon around the Earth. In one orrery, these three motions could be mounted on a common table, separately using the central spindle as a prime mover.
Explanation.
All orreries are "planetariums" or "planetaria" (alternative plural). The term orrery has only existed since 1714. A grand orrery is one that includes the outer planets known at the time of its construction. The word planetarium has been captured, and now usually refers to hemispherical theatres in which images of the night sky are projected onto an overhead surface. Planetariums (orreries) can range widely in size from hand-held to room-sized. An orrery is used to demonstrate the motion of the planets, while a mechanical device used to predict eclipses and transits is called an astrarium.
An orrery should properly include the Sun, the Earth and the Moon (plus optionally other planets.) A model that only includes the Earth, the Moon and the Sun is called a tellurion or tellurium, and one which only includes the Earth and the Moon is a lunarium. A jovilabe is a model of Jupiter and its moons.
A planetarium will show the "orbital period" of each planet and the "rotation rate", as shown in the table above. A tellurion will show the earth with the moon revolving around the sun. It will use the angle of "inclination of the equator" from the table above to show how it rotates around its own axis. It will show the earth's moon, rotating around the earth. A lunarium is designed to show the complex motions of the moon as it revolves around the earth.
Orreries are usually not built to scale. Some fixed Solar System scale models have been built and are often many kilometres in size. Human orreries, where humans move about as the planets, have also been constructed, but most are temporary. There is a permanent human orrery at Armagh Observatory in Northern Ireland, which has the six ancient planets, Ceres, and comets Halley and Encke. Uranus and beyond are also shown, but in a fairly limited way. Another is at Sky's the Limit Observatory and Nature Center in Twentynine Palms, CA. This is a true to scale (20 billion to one), true to position (accurate to within four days) human orrery. The first four planets are relatively close to one another, but the next four require a certain amount of hiking in order to visit them.
A normal mechanical clock could be used to produce an extremely simple orrery with the Sun in the centre, Earth on the minute hand and Jupiter on the hour hand; Earth would make 12 revolutions around the Sun for every 1 revolution of Jupiter. Note however that Jupiter's actual year is 11.86 Earth years long, so this particular example would lose accuracy rapidly. A real orrery would be more accurate and include more planets, and would perhaps make the planets rotate as well.
Projection orreries.
Many planetariums (buildings) have a projection orrery, which projects onto the dome of the planetarium a Sun with either dots or small images of the planets. These usually are limited to the planets from Mercury to Saturn, although some include Uranus. The light sources for the planets are projected onto mirrors which are geared to a motor which drives the images on the dome. Typically the Earth will circle the Sun in one minute, while the other planets will complete an orbit in time periods proportional to their actual motion. Thus Venus, which takes 224.7 days to orbit the Sun, will take 37 seconds to complete an orbit on an orrery, and Jupiter will take 11 minutes, 52 seconds.
Some planetariums have taken advantage of this to use orreries to simulate planets and their moons. Thus Mercury orbits the Sun in 0.24 of an Earth year, while Phobos and Deimos orbit Mars in a similar 4:1 time ratio. Planetarium operators wishing to show this have placed a red cap on the Sun (to make it resemble Mars) and turned off all the planets but Mercury and Earth. Similar tricks can be used to show Pluto and its five moons.
Notable orreries.
Shoemaker John Fulton of Fenwick, Ayrshire, built three between 1823 and 1833. The last is in Glasgow's Kelvingrove Art Gallery and Museum.
The Franeker Planetarium built by a wool carder named Eise Eisinga in his own living room, in the small city of Franeker in Friesland, is in fact an orrery. It was constructed between 1774 to 1781. The "face" of the model looks down from the ceiling of a room, with most of the mechanical works in the space above the ceiling. It is driven by a pendulum clock, which has 9 weights or ponds. The planets move around the model in real time.
An innovative concept is to have people play the role of the moving planets and other Solar System objects. Such a model, called a human orrery, has been laid out with precision at the Armagh Observatory.
Meccano Planetaria.
The first Meccano Orrery was described in June 1918 Meccano Manual, though it is the last quarter of the 20th Century that Alan Partridge, John Nuttall, Pat Briggs and Michael Whiting have experimented with the limitations and possibilities of this medium. There are six methods of building orreries:

</doc>
<doc id="60554" url="http://en.wikipedia.org/wiki?curid=60554" title="Bamburgh">
Bamburgh

Bamburgh ( ) is a large village and civil parish on the coast of Northumberland, England. It has a population of 454.
It is notable for two reasons: the imposing Bamburgh Castle, overlooking the beach, seat of the former Kings of Northumbria, and at present owned by the Armstrong family (see William George Armstrong); and its association with the Victorian heroine, Grace Darling, who is buried there.
Its extensive sandy beach was awarded the Blue Flag rural beach award in 2005. The Bamburgh sandy hills, an area of sand dunes which are a Site of Special Scientific Interest, stand behind the award winning beach. Bamburgh is popular with holidaymakers and is within the Northumberland Coast Area of Outstanding Natural Beauty.
History.
Bamburgh Castle, then called "Din Guardi", may have been the capital of the Brythonic kingdom of Bryneich between about AD 420 and 547. In 547 the castle was taken by the invading Angles led by Ida son of Eoppa and was renamed Bebbanburgh by one of his successors, Æthelfrith, after Æthelfrith's wife Bebba, according to the "Historia Brittonum". From then onwards the castle became the capital of the Anglian kingdom of Bernicia until it merged with its southern neighbour, Deira, in 634. After the two realms united as Northumbria the capital was moved to York.
Bamburgh was again the capital of local Bernician rulers after the Viking destruction of the old Northumbrian kingdom in 867. Initially puppets of the Vikings, they later had more autonomy under either the Vikings or Kings of united England. The rulers of Bernicia held the title of High Reeve of Bamburgh from at least 913 until 1041, when the last was killed by Harthacnut; sometimes – 954–963 and 975–1016 – they also served as Earls of York. The castle was destroyed in a renewed Viking attack in 993 and in 1018 the Lothian part of Bernicia was ceded to Scotland, significantly reducing the area controlled from Bamburgh.
Edward IV ruled all England in 1464, during the Wars of the Roses during which the Percy family was based at Bamburgh Castle.
Thomas Malory considered Bamburgh to be Lancelot's castle Joyous Gard. The Victorian poet Algernon Charles Swinburne agreed and called it "The noblest hold in all the North."
Swinburne swam here, as did the novelist E. M. Forster who adopted the Forsters of Bamb-bra as his ancestors.
St Aidan's Church.
According to Bede, St Aidan built a wooden church outside the castle wall in AD 635, and he died here in AD 652. A wooden beam preserved inside the church is traditionally said to be the one on which he rested as he died.
The present church dates from the late 12th century, though some pre-conquest stonework survives in the north aisle. The chancel, said to be the second longest in the country (60 ft; 18m), was added in 1230; it contains an 1895 reredos in Caen stone by W.S. Hicks, depicting northern saints of the 7th and 8th centuries. There is an effigy of local heroine Grace Darling in the North Aisle. Her memorial is sited in the churchyard in such a position that it can be seen by passing ships.
Bamburgh Lighthouse.
Bamburgh Lighthouse was built by Trinity House in 1910 to guide shipping both passing along the Northumberland coast and in the waters around the Farne Islands. It was extensively modernised in 1975 and is now monitored from the Trinity House Operations and Planning Centre in Harwich. Routine maintenance is carried out by a local attendant. It is the most northerly land-based lighthouse in England.
When originally built, the lamp was mounted on a skeletal steel tower (the footprint of which can still be seen within the compound) which stood alongside the white building which housed an acetylene plant to power the lamp. (A similar arrangement can be seen today at Peninnis Lighthouse.) During electrification in 1975 the tower was removed, and the lantern was placed instead on top of the (now redundant) acetylene building. Keepers' accommodation has never been needed, as the light was automated from the start.

</doc>
<doc id="60555" url="http://en.wikipedia.org/wiki?curid=60555" title="Grace Darling">
Grace Darling

Grace Darling (24 November 1815 – 20 October 1842) was an English lighthouse keeper's daughter, famed for participating in the rescue of survivors from the shipwrecked "Forfarshire" in 1838. The paddlesteamer ran aground on the Farne Islands off the coast of Northumberland in northeast England; nine members of her crew were saved.
Biography.
Grace Horsley Darling was born on 24 November 1815 at her grandfather's cottage in Bamburgh in Northumberland. She was the seventh of nine children (four brothers and four sisters) born to William and Thomasin Darling, and when only a few weeks old she was taken to live on Brownsman Island, one of the Farne Islands, in a small cottage attached to the lighthouse. 
Her father ran the lighthouse (built in 1795) for Trinity House and earned a salary of £70 per annum with a bonus of £10 for satisfactory service. The accommodation was basic and the lighthouse was not in the best position to guide shipping to safety, so in 1826 the family moved to the newly constructed lighthouse on Longstone Island.
Longstone Lighthouse had better accommodation, but the island itself was slightly less hospitable, so William would row back to Brownsman to gather vegetables from their former garden and to feed the animals. The family spent most of their time on the ground floor of the lighthouse which consisted of a large room, heated by a wood stove. The room was their living room, dining room and kitchen in one and had a spiral staircase leading to three bedrooms above and of course the light at the top of the tower. 
In the early hours of 7 September 1838, Darling, looking from an upstairs window of the Longstone Lighthouse on the Farne Islands, spotted the wreck and survivors of the "Forfarshire" on Big Harcar, a nearby low rocky island. The "Forfarshire" had foundered on the rocks and broken in half: one of the halves had sunk during the night.
She and her father William determined that the weather was too rough for the lifeboat to put out from Seahouses (then North Sunderland), so they took a rowing boat (a 21 ft, 4-man Northumberland coble) across to the survivors, taking a long route that kept to the lee side of the islands, a distance of nearly a mile. Darling kept the coble steady in the water while her father helped four men and the lone surviving woman, Mrs. Dawson, into the boat. Although she survived the sinking, Mrs Dawson had lost her two young children during the night. William and three of the rescued men then rowed the boat back to the lighthouse. Darling then remained at the lighthouse while William and three of the rescued crew members rowed back and recovered four more survivors.
Meanwhile the lifeboat had set out from Seahouses but arrived at Big Harcar rock after Darling and her father had completed their rescue operation: all they found were the dead bodies of Mrs Dawson's children and of a vicar. It was too dangerous to return to North Sunderland so they rowed to the lighthouse to take shelter. Darling's brother, William Brooks Darling, was one of the seven fishermen in the lifeboat. The weather deteriorated to the extent that everyone was obliged to remain at the lighthouse for three days before returning to shore.
The "Forfarshire" had been carrying 62 people. The vessel broke in two almost immediately upon hitting the rocks. Those rescued by Darling and her father were from the bow section of the vessel which had been held by the rocks for some time before sinking. All that remained at daybreak was the portside paddlebox casing. Nine other passengers and crew had managed to float off a lifeboat from the stern section before it too sank, and were picked up in the night by a passing Montrose sloop and brought into South Shields that same night.
As news of her role in the rescue reached the public, her combination of bravery and simple virtue set her out as exemplary, and led to an uneasy role as the nation's heroine. Subscriptions and donations totaling over £700 were raised for her, including £50 from Queen Victoria; more than a dozen portrait painters sailed to her island home to capture her likeness, and hundreds of gifts, letters, and even marriage proposals were delivered to her.
Her unexpected wealth and fame were such that the Duke of Northumberland took on a role as her self-appointed guardian and founder of a trust, established to look after the donations offered to her. His personal gifts to her and her family included a timepiece, and a silver teapot.
In 1842, Grace fell ill while visiting the mainland, and was in convalescence with her cousins, the MacFarlanes, in their house in Narrowgate, Alnwick. The Duchess of Northumberland heard of her situation, and arranged for her to be moved to better accommodation close to Alnwick Castle, and tended to the ailing heroine in person as well as providing Grace with the services of the ducal family physician.
Grace's condition declined, however, and in the final stages of her illness she was conveyed to the place of her birth, in Bamburgh. Grace Darling died of tuberculosis in October 1842, aged 26.
Legacy.
Darling is buried with her father and mother in a modest grave in St. Aidan’s churchyard, Bamburgh, where a nearby elaborate cenotaph commemorates her life. A plain stone monument to her was erected in St. Cuthbert’s Chapel on Great Farne Island in 1848.
Darling’s achievement was celebrated in her lifetime: she received a large financial reward in addition to the plaudits of the nation. A number of fictionalised depictions propagated the Grace Darling legend, such as "Grace Darling, or the Maid of the Isles" by Jerrold Vernon (1839), which gave birth to the legend of “the girl with windswept hair”. Her deed was committed to verse by William Wordsworth in his poem "Grace Darling" (1843). A lifeboat with her name was presented to Holy Island. One of a series of Victorian paintings by William Bell Scott at Wallington Hall in Northumberland depicts her rescue. The McManus Galleries in Dundee includes three paintings by Thomas Musgrave Joy which celebrate Grace Darling's deeds with the "Forfarshire".
At Bamburgh, there is a museum dedicated to her achievements and the seafaring life of the region. It re-opened in December 2007 following renovation. The Royal National Lifeboat Institution Mersey class lifeboat at Seahouses bears the name "Grace Darling".
Singer/songwriter Dave Cousins of Strawbs wrote "Grace Darling" (on "Ghosts") in tribute and as a love song. North East musical playwright Dennis A Westgate wrote a musical based on the life of Grace Darling, exploring her life from childhood through to her death in 1842. The premiere was performed by a community theatre company based in York, , July 2010 to help promote Grace Darling and the work of the RNLI.
The children's singing group "The Limeliters" sang a different "Grace Darling" (featuring the refrain "Help, help, came a desperate yelp!") in their 1962 album, recorded live in concert, "Through Children's Eyes".
It was suggested by Richard Armstrong in his 1965 biography "Grace Darling: Maid and Myth" that she may have suffered from a cleft lip. He is the only biographer to put forward this theory, which has been strongly disputed by other experts.

</doc>
<doc id="60556" url="http://en.wikipedia.org/wiki?curid=60556" title="William Armstrong, 1st Baron Armstrong">
William Armstrong, 1st Baron Armstrong

William George Armstrong, 1st Baron Armstrong, CB, FRS (26 November 1810 – 27 December 1900) was an English industrialist who founded the Armstrong Whitworth manufacturing concern on Tyneside. He was also an eminent engineer, scientist, inventor and philanthropist. In collaboration with the architect Richard Norman Shaw, he built Cragside in Northumberland, the first house in the world to be lit by hydroelectricity. He is regarded as the inventor of modern artillery. Armstrong was knighted in 1859 after giving his gun patents to the government. In 1887, in Queen Victoria's golden jubilee year, he was raised to the peerage as Baron Armstrong of Cragside, becoming the first engineer – and, indeed, the first scientist – to join the House of Lords.
Early life.
Armstrong was born in Newcastle upon Tyne, at 9 Pleasant Row, Shieldfield, about a mile from the city centre. Although the house in which he was born no longer exists, an inscribed granite tablet marks the spot on which it once stood. At that time the area, next to the Pandon Dene, was rural. His father, also called William, was a corn merchant on the Newcastle quayside, who rose through the ranks of Newcastle society to become mayor of the town in 1850. An elder sister, Anne, born in 1802, was named after his mother, the daughter of Addison Potter.
Armstrong was educated at private schools in Newcastle and Whickham, near Gateshead, until he was sixteen, when he was sent to Bishop Auckland Grammar School. While there, he often visited the nearby engineering works of William Ramshaw. During his visits he met his future wife, Ramshaw’s daughter Margaret, six years his senior.
Armstrong’s father was set on him following a career in the law, and so he was articled to Armorer Donkin, a solicitor friend of his father’s. He spent five years in London studying law and returned to Newcastle in 1833. In 1835 he became a partner in Donkin’s business and the firm became Donkin, Stable and Armstrong. Armstrong married Margaret Ramshaw in 1835, and they built a house in Jesmond Dene, on the eastern edge of Newcastle. Armstrong worked for eleven years as a solicitor, but during his spare time he showed great interest in engineering.
Change of career.
Armstrong was a very keen angler, and while fishing on the River Dee at Dentdale in the Pennines, he saw a waterwheel in action, supplying power to a marble quarry. It struck Armstrong that much of the available power was being wasted. When he returned to Newcastle, he designed a rotary engine powered by water, and this was built in the High Bridge works of his friend Henry Watson. Unfortunately, little interest was shown in the engine. Armstrong subsequently developed a piston engine instead of a rotary one and decided that it might be suitable for driving a hydraulic crane. In 1846 his work as an amateur scientist was recognized when he was elected a Fellow of the Royal Society.
In 1845 a scheme was set in motion to provide piped water from distant reservoirs to the households of Newcastle. Armstrong was involved in this scheme and he proposed to Newcastle Corporation that the excess water pressure in the lower part of town could be used to power a Quayside crane specially adapted by himself. He claimed that his hydraulic crane could unload ships faster and more cheaply than conventional cranes. The Corporation agreed to his suggestion, and the experiment proved so successful that three more hydraulic cranes were installed on the Quayside.
The success of his hydraulic crane led Armstrong to consider setting up a business to manufacture cranes and other hydraulic equipment. He therefore resigned from his legal practice. Donkin, his legal colleague, supported him in his career move, providing financial backing for the new venture. In 1847 the firm of W.G. Armstrong & Company bought 5.5 acre of land alongside the river at Elswick, near Newcastle, and began to build a factory there. The new company received orders for hydraulic cranes from Edinburgh and Northern Railways and from Liverpool Docks, as well as for hydraulic machinery for dock gates in Grimsby. The company soon began to expand. In 1850 the company produced 45 cranes and two years later, 75. It averaged 100 cranes per year for the rest of the century. In 1850 over 300 men were employed at the works, but by 1863 this had risen to 3,800. The company soon branched out into bridge building, one of the first orders being for the Inverness Bridge, completed in 1855.
Hydraulic accumulator.
Armstrong was responsible for developing the hydraulic accumulator. Where water pressure was not available on site for the use of hydraulic cranes, Armstrong often built high water towers to provide a supply of water at pressure. However, when supplying cranes for use at New Holland on the Humber Estuary, he was unable to do this because the foundations consisted of sand. After much careful thought he produced the hydraulic accumulator, a cast-iron cylinder fitted with a plunger supporting a very heavy weight. The plunger would slowly be raised, drawing in water, until the downward force of the weight was sufficient to force the water below it into pipes at great pressure. The accumulator was a very significant, if unspectacular, invention, which found many applications in the following years.
Armaments.
In 1854, during the Crimean War, Armstrong read about the difficulties the British Army experienced in manoeuvring its heavy field guns. He decided to design a lighter, more mobile field gun, with greater range and accuracy. He built a breech-loading gun with a strong, rifled barrel made from wrought iron wrapped around a steel inner lining, designed to fire a shell rather than a ball. In 1855 he had a five-pounder ready for inspection by a government committee. The gun proved successful in trials, but the committee thought a higher caliber gun was needed, so Armstrong built an 18-pounder on the same design. After trials, this gun was declared to be superior to all its rivals. Armstrong surrendered the patent for the gun to the British government, rather than profit from its design. As a result he was created a Knight Bachelor and in 1859 was presented to Queen Victoria. Armstrong became employed as Engineer of Rifled Ordnance to the War Department. In order to avoid a conflict of interests if his own company were to manufacture armaments, Armstrong created a separate company, called Elswick Ordnance Company, in which he had no financial involvement. The new company agreed to manufacture armaments for the British government and no other. Under his new position, Armstrong worked to bring the old Woolwich Arsenal up to date so that it could build guns designed at Elswick.
However, just when it looked as if the new gun was about to become a great success, a great deal of opposition to the gun arose, both inside the army and from rival arms manufacturers, particularly Joseph Whitworth of Manchester. Stories were publicised that the new gun was too difficult to use, that it was too expensive, that it was dangerous to use, that it frequently needed repair and so on. All of this smacked of a concerted campaign against Armstrong. Armstrong was able to refute all of these claims in front of various government committees, but he found the constant criticism very wearying and depressing. In 1862 the government decided to stop ordering the new gun and return to muzzle loaders. Also, because of a drop in demand, future orders for guns would be supplied from Woolwich, leaving Elswick without new business. Compensation was eventually agreed with the government for the loss of business to the company. Unfortunately, the government would not release the company from its agreement not to sell armaments abroad, so that avenue was closed to it. Eventually, the restriction was relaxed, and the company was able to sell guns to both sides in the American Civil War.
Warships.
In 1864 the two companies, W.G. Armstrong & Company and Elswick Ordnance Company merged to form Sir W.G. Armstrong & Company. Armstrong had resigned from his employment with the War Office, so there was no longer a conflict of interest. The company turned its attention to naval guns. In 1867 Armstrong reached an agreement with Charles Mitchell, a shipbuilder in Low Walker, whereby Mitchells would build warships and Elswick would provide the guns. The first ship, in 1868 was HMS "Staunch", a gunboat.
In 1876, because the 18th-century bridge at Newcastle restricted access by ships to the Elswick works, Armstrong’s company paid for a new Swing Bridge to be built, so that warships could have their guns fitted at Elswick. In 1882 Armstrong’s company merged with Mitchells to form Sir William Armstrong, Mitchell and Co. Ltd. and in 1884 a shipyard opened at Elswick to specialise in warship production. The first vessels produced were the torpedo cruisers "Panther" and "Leopard" for the Austro-Hungarian Navy. The first battleship produced at Elswick was H.M.S "Victoria", launched in 1887. The ship was originally to be named "Renown", but the name was changed in honour of the Queen's Golden Jubilee. Armstrong drove the first and last rivets. The ship was ill-fated, as she was involved in a collision with H.M.S. "Camperdown" in 1893 and sank with the loss of 358 men, including Vice-Admiral Sir George Tryon. An important customer of the Elswick yard was Japan, which took several cruisers, some of which defeated the Russian fleet at the Battle of Tsushima in 1905. It was claimed that every Japanese gun used in the battle was provided by Elswick. Elswick was the only factory in the world that could build a battleship and arm it completely.
The Elswick works continued to prosper, and by 1870 it stretched for three-quarters of a mile along the riverside. The population of Elswick, which was 3,539 in 1851, had increased by 1871 to 27,800. In 1894, Elswick built and installed the steam-driven pumping engines, hydraulic accumulators and hydraulic pumping engines to operate London’s Tower Bridge. In 1897 the company merged with the company of Armstrong’s old rival, Joseph Whitworth, and became Sir W.G. Armstrong, Whitworth & Co Ltd. Whitworth was by this time dead.
Armstrong gathered many excellent engineers at Elswick. Notable among them were Andrew Noble and George Wightwick Rendel, whose design of gun-mountings and hydraulic control of gun-turrets were adopted worldwide. Rendel introduced the cruiser as a naval vessel. There was great rivalry and dislike between Noble and Rendel, which became open after Armstrong’s death.
Cragside.
From 1863 onwards, although Armstrong remained the head of his company, he became less involved in its day-to-day running. He appointed several very able men to senior positions and they continued his work. When he married, he acquired Jesmond Dene House, a house to the west of Jesmond Dene, Newcastle and began to landscape and improve land that he bought within the Dene. In 1860 he paid local architect John Dobson to design a banqueting hall in the Dene. His house close to Newcastle was convenient for his practice as a solicitor and his work as an industrialist, but when he had more spare time he longed for a house in the country.
He had often visited Rothbury as a child, when he was afflicted by a severe cough, and he had fond memories of the area. In 1863 he bought some land in a steep-sided, narrow valley where the Debdon Burn flows towards the River Coquet near Rothbury. He had the land cleared and supervised the building of a house perched on a ledge of rock, overlooking the burn. He also supervised a programme of planting trees and mosses so as to cover the rocky hillside with vegetation. His new house was called Cragside, and over the years Armstrong added to the Cragside estate. Eventually the estate was 1729 acre and had seven million trees planted, together with five artificial lakes and 31 mi of carriage drives. The lakes were used to generate hydro-electricity, and the house was the first in the world to be lit by hydro-electricity, using incandescent lamps provided by the inventor Joseph Swan.
As Armstrong spent less and less time at the Elswick works, he spent more and more time at Cragside, and it became his main home. In 1869 he commissioned the celebrated architect Richard Norman Shaw to enlarge and improve the house, and this was done over a period of 15 years. In 1883 Armstrong gave Jesmond Dene, together with its banqueting hall to the city of Newcastle. He retained his house next to the Dene. Armstrong entertained several eminent guests at Cragside, including the Shah of Persia, the King of Siam, the prime minister of China and the Prince and Princess of Wales.
Later life.
In 1873 he served as High Sheriff of Northumberland. He was elected as the president of the Institution of Civil Engineers in December 1881 and served in that capacity for the next year. He was conferred with Honorary Membership of the Institution of Engineers and Shipbuilders in Scotland in 1884. In 1886 he was persuaded to stand as a Unionist Liberal candidate for Newcastle, but was unsuccessful, coming third in the election. That same year he was presented with the Freedom of the City of Newcastle. In 1887 he was raised to the peerage as Baron Armstrong, of Cragside in the County of Northumberland. His last great project, begun in 1894, was the purchase and restoration of the huge Bamburgh Castle on the Northumberland coast, which remains in the hands of the Armstrong family. His wife, Margaret, died in September 1893, at their house in Jesmond. Armstrong died at Cragside on 27 December 1900, aged ninety. He was buried in Rothbury churchyard, alongside his wife. The couple had no children, and Armstrong’s heir was his great-nephew William Watson-Armstrong. He was succeeded as chairman of the company by his one-time protégée, Andrew Noble.
Such was Armstrong's fame as a gun-maker that he is thought to be a possible model for George Bernard Shaw's arms magnate in "Major Barbara". The title character in Iain Pears' historical-mystery novel "Stone's Fall" also has similarities to Armstrong.
His attitude to armaments.
There is no evidence that Armstrong agonised over his decision to go into armament production. He once said: "If I thought that war would be fomented, or the interests of humanity suffer, by what I have done, I would greatly regret it. I have no such apprehension". He also said: "It is our province, as engineers to make the forces of matter obedient to the will of man; those who use the means we supply must be responsible for their legitimate application".
Views on renewable energy.
Armstrong advocated the use of renewable energy. Stating that coal "was used wastefully and extravagantly in all its applications", he predicted in 1863 that England would cease to produce coal within two centuries. As well as advocating the use of hydroelectricity, he also supported solar power, stating that the solar energy received by 1 acre in tropical areas would "exert the amazing power of 4000 horses acting for nearly nine hours every day"
The benefactor.
Armstrong donated the long wooded gorge of Jesmond Dene to the people of the city of Newcastle upon Tyne in 1883, as well as Armstrong Bridge and Armstrong Park nearby. The University of Newcastle was originally founded by Lord Armstrong in 1871 as the College of Physical Science, later Armstrong College in 1904. He was twice president of the Institution of Mechanical Engineers. Armstrong gave £11,500 towards the building of Newcastle's Hancock Natural History Museum, which was completed in 1882. This was an enormous sum equivalent to over £555,000 in 2010. Lord Armstrong's generosity extended beyond his death. In 1901 his heir, William Watson-Armstrong gave £100,000 (£ in 2015), for the building of the new Royal Victoria Infirmary in Newcastle upon Tyne. Its original 1753 building at Forth Banks near the river Tyne were inadequate and impossible to expand. In 1903 the barony of Armstrong was revived in favour of William Watson-Armstrong.

</doc>
<doc id="60557" url="http://en.wikipedia.org/wiki?curid=60557" title="Emmeline Pankhurst">
Emmeline Pankhurst

Emmeline Pankhurst (born Goulden; 15 July 1858 (Chambers Biographical states 1857)
 – 14 June 1928) was a British political activist and leader of the British suffragette movement who helped women win the right to vote. In 1999 "Time" named Pankhurst as one of the , stating: "she shaped an idea of women for our time; she shook society into a new pattern from which there could be no going back." She was widely criticised for her militant tactics, and historians disagree about their effectiveness, but her work is recognised as a crucial element in achieving women's suffrage in Britain.
Born in Moss Side, Manchester, to politically active parents, Pankhurst was introduced at the age of 8 to the women's suffrage movement. Although her parents encouraged her to prepare herself for life as a wife and mother, she attended the École Normale de Neuilly in Paris. On December 18, 1879 she married Richard Pankhurst, a barrister 24 years her senior known for supporting women's right to vote; they had five children over the next ten years. He supported her activities outside the home, and she founded and became involved with the Women's Franchise League, which advocated suffrage for both married and unmarried women. When that organisation broke apart, she tried to join the left-leaning Independent Labour Party through her friendship with socialist Keir Hardie but was initially refused membership by the local branch on account of her sex. While working as a Poor Law Guardian, she was shocked at the harsh conditions she encountered in Manchester's workhouses.
In 1903, five years after her husband died, Pankhurst founded the Women's Social and Political Union (WSPU), an all-women suffrage advocacy organization dedicated to "deeds, not words." The group identified as independent from – and often in opposition to – political parties. It became known for physical confrontations: its members smashed windows and assaulted police officers. Pankhurst, her daughters, and other WSPU activists were sentenced to repeated prison sentences, where they staged hunger strikes to secure better conditions. As Pankhurst's oldest daughter Christabel took leadership of the WSPU, antagonism between the group and the government grew. Eventually the group adopted arson as a tactic, and more moderate organisations spoke out against the Pankhurst family. In 1913 several prominent individuals left the WSPU, among them Pankhurst's daughters Adela and Sylvia. Emmeline was so furious that she "gave [Adela] a ticket, £20, and a letter of introduction to a suffragette in Australia, and firmly insisted that she emigrate," in which she complied. The family rift was never healed. Sylvia became a socialist.
With the advent of the First World War, Emmeline and Christabel called an immediate halt to militant suffrage activism in support of the British government's stand against the "German Peril." They urged women to aid industrial production and encouraged young men to fight, becoming prominent figures in the white feather movement. In 1918 the Representation of the People Act granted votes to all men over the age of 21 and women over the age of 30. This discrepancy was intended to ensure that men did not become minority voters as a consequence of the huge number of deaths suffered during the First World War.
Pankhurst transformed the WSPU machinery into the Women's Party, which was dedicated to promoting women's equality in public life. In her later years she became concerned with what she perceived as the menace posed by Bolshevism and joined the Conservative Party, and was selected as a Conservative Party candidate for Stepney in 1927. She died on 14 June 1928, only weeks before the Conservative government's Representation of the People Act (1928) extended the vote to all women over 21 years of age on 2 July 1928. She was commemorated two years later with a statue in London's Victoria Tower Gardens.
Family and birth.
Emmeline Goulden was born on 15 July 1858 in the Manchester suburb of Moss Side. Although her birth certificate states otherwise, she believed that her birthday was a day earlier, on Bastille Day. Most biographies, including those written by her daughters, repeat this claim. Feeling a kinship with the female revolutionaries who stormed the Bastille, she said in 1908: "I have always thought that the fact that I was born on that day had some kind of influence over my life." The reason for the discrepancy remains unclear.
The family into which she was born had been steeped in political agitation for generations. Her mother, Sophia Jane Craine, was descended from the Manx people of the Isle of Man and counted among her ancestors men charged with social unrest and slander. In 1881 the Isle of Man was the first country to grant women the right to vote in national elections. Her father, Robert Goulden, came from a modest Manchester merchant family with its own background of political activity. His mother worked with the Anti-Corn Law League, and his father was present at the Peterloo Massacre, when cavalry charged and broke up a crowd demanding parliamentary reform.
Their first son died at the age of two, but the Gouldens had ten other children; Emmeline was the eldest of five daughters. Soon after her birth the family moved to Seedley in Pendleton on the outskirts of Salford, where her father had co-founded a small business. Goulden was active in local politics, serving for several years on the Salford Town Council. He was also an enthusiastic supporter of dramatic organisations including the Manchester Athenaeum and the Dramatic Reading Society. He owned a theatre in Salford for several years, where he played the leads in several plays by William Shakespeare. Pankhurst absorbed an appreciation of drama and theatrics from her father, which she used later in social activism.
Childhood.
The Gouldens included their children in some social activism. As part of the movement to end slavery in the US, Goulden welcomed American abolitionist Henry Ward Beecher when he visited Manchester. Sophia Jane Goulden used the novel "Uncle Tom's Cabin" – written by Beecher's sister Harriet Beecher Stowe – as a regular source of bedtime stories for their sons and daughters. In her 1914 autobiography "My Own Story," Pankhurst recalls visiting a bazaar at a young age to collect money for newly freed slaves in the United States.
Pankhurst began to read books when she was very young – according to one source, at the age of three. She read the "Odyssey" at the age of nine and enjoyed the works of John Bunyan, especially his 1678 story "The Pilgrim's Progress". Another of her favourite books was Thomas Carlyle's three-volume treatise ""; she later said the work "remained all my life a source of inspiration."
Despite her avid consumption of books, however, Emmeline was not given the educational advantages enjoyed by her brothers. Their parents believed that the girls needed most to learn the art of "making home attractive" and other skills desired by potential husbands. The Gouldens deliberated carefully about future plans for their sons' education, but they expected their daughters to marry young and avoid paid work. Although they supported women's suffrage and the general advancement of women in society, the Gouldens believed their daughters incapable of the goals of their male peers. Feigning sleep one evening as her father came into her bedroom, Emmeline Goulden heard him pause and say to himself: "What a pity she wasn't born a lad."
It was through her parents' interest in women's suffrage that Pankhurst was first introduced to the subject. Her mother received and read the "Women's Suffrage Journal", and Pankhurst grew fond of its editor, Lydia Becker. At the age of 14, she returned home from school one day to find her mother on her way to a public meeting about women's voting rights. After learning that Becker would be speaking, she insisted on attending. Pankhurst was enthralled by Becker's address and wrote later: "I left the meeting a conscious and confirmed suffragist."
A year later she arrived in Paris to attend the École Normale de Neuilly. The school provided its female pupils with classes in chemistry and bookkeeping, in addition to traditionally feminine arts such as embroidery. Her roommate was Noémie, the daughter of Henri Rochefort, who had been imprisoned in New Caledonia for his support of the Paris Commune. The girls shared tales of their parents' political exploits, and remained good friends for years. Pankhurst was so fond of Noémie and the school that after graduating she returned with her sister Mary as a parlour boarder. Noémie had married a Swiss painter and quickly found a suitable French husband for her English friend. When Robert Goulden refused to provide a dowry for his daughter, the man withdrew his offer of marriage and Pankhurst returned, miserable, to Manchester.
Marriage and family.
In the autumn of 1878, at the age of 20, Emmeline Goulden met and began a courtship with Richard Pankhurst, a barrister who had advocated women's suffrage – and other causes, including freedom of speech and education reform – for years. Richard, 44 years old when they met, had earlier resolved to remain a bachelor to better serve the public. Their mutual affection was powerful, but the couple's happiness was diminished by the death of his mother the following year. Sophia Jane Goulden chastised her daughter for "throwing herself" at Richard and urged her without success to exhibit more aloofness. Emmeline suggested to Richard that they avoid the legal formalities of marriage by entering into a free union; he objected on the grounds that she would be excluded from political life as an unmarried woman. He noted that his colleague Elizabeth Wolstenholme Elmy had faced social condemnation before she formalised her marriage to Ben Elmy. Emmeline Goulden agreed, and they were wed in St Luke's Church, Pendleton on 18 December 1879.
During the 1880s, living at the Goulden cottage with her parents in Seedley, Emmeline Pankhurst tended to her husband and children, but still devoted time to political activities. Although she gave birth to five children in ten years, both she and Richard believed that she should not be "a household machine." Thus a servant was hired to help with the children as Pankhurst involved herself with the Women's Suffrage Society. Their daughter Christabel was born on 22 September 1880, less than a year after the wedding. Pankhurst gave birth to another daughter, Estelle Sylvia, in 1882 and their son Francis Henry, nicknamed Frank, in 1884. Soon afterwards Richard Pankhurst left the Liberal Party. He began expressing more radical socialist views and argued a case in court against several wealthy businessmen. These actions roused Robert Goulden's ire and the mood in the house became tense. In 1885 the Pankhursts moved to Chorlton-on-Medlock, and their daughter Adela was born. They moved to London the following year, where Richard ran unsuccessfully for election as a Member of Parliament and Pankhurst opened a small fabric shop called Emerson and Company.
In 1888 Francis developed diphtheria and died on 11 September. Overwhelmed with grief, Pankhurst commissioned two portraits of the dead boy but was unable to look at them and hid them in a bedroom cupboard. The family concluded that a faulty drainage system at the back of their house had caused their son's illness. Pankhurst blamed the poor conditions of the neighbourhood, and the family moved to a more affluent middle class district at Russell Square. She was soon pregnant once more and declared that the child was "Frank coming again." She gave birth to a son on 7 July 1889 and named him Henry Francis in honour of his deceased brother.
Pankhurst made their Russell Square home into a centre for grieving sisters, attracting activists of many types. She took pleasure in decorating the house – especially with furnishings from Asia – and clothing the family in tasteful apparel. Her daughter Sylvia later wrote: "Beauty and appropriateness in her dress and household appointments seemed to her at all times an indispensable setting to public work." The Pankhursts hosted a variety of guests including US abolitionist William Lloyd Garrison, Indian MP Dadabhai Naoroji, socialist activists Herbert Burrows and Annie Besant, and French anarchist Louise Michel.
Women's Franchise League.
In 1888 Britain's first nationwide coalition of groups advocating women's right to vote, the National Society for Women's Suffrage (NSWS), split after a majority of members decided to accept organisations affiliated with political parties. Angry at this decision, some of the group's leaders, including Lydia Becker and Millicent Fawcett, stormed out of the meeting and created an alternative organisation committed to the "old rules," called the Great College Street Society after the location of its headquarters. Pankhurst aligned herself with the "new rules" group, which became known as the Parliament Street Society (PSS). Some members of the PSS favoured a piecemeal approach to gaining the vote. Because it was often assumed that married women did not need the vote since their husbands "voted for them," some PSS members felt that the vote for single women and widows was a practical step along the path to full suffrage. When the reluctance within the PSS to advocate on behalf of married women became clear, Pankhurst and her husband helped organise another new group dedicated to voting rights for all women – married and unmarried.
The inaugural meeting of the Women's Franchise League (WFL) was held on 25 July 1889, at the Pankhurst home in Russell Square. William Lloyd Garrison spoke at the meeting, warning the audience that the US abolition movement had been hampered by individuals advocating moderation and patience. Early members of the WFL included Josephine Butler, leader of the Ladies National Association for the Repeal of the Contagious Diseases Acts; the Pankhursts' friend Elizabeth Wolstenholme Elmy; and Harriot Eaton Stanton Blatch, daughter of US suffragist Elizabeth Cady Stanton.
The WFL was considered a radical organisation, since in addition to women's suffrage it supported equal rights for women in the areas of divorce and inheritance. It also advocated trade unionism and sought alliances with socialist organisations. The more conservative group that emerged from the NSWS split spoke out against what they called the "extreme left" wing of the movement. The WFL reacted by ridiculing the "Spinster Suffrage party" and insisting that a wider assault on social inequity was required. The group's radicalism caused some members to leave; both Blatch and Elmy resigned from the WFL. The group fell apart one year later.
Independent Labour Party.
Pankhurst's shop never succeeded and he had trouble attracting business in London. With the family's finances in jeopardy, Richard travelled regularly to northwest England, where most of his clients were. In 1893 the Pankhursts closed the store and returned to Manchester. They stayed for several months in the seaside town of Southport, then moved briefly to the village of Disley and finally settled into a house in Manchester's Victoria Park. The girls were enrolled in Manchester Girls' High School, where they felt confined by the large student population and strictly regimented schedule.
Pankhurst began to work with several political organisations, distinguishing herself for the first time as an activist in her own right and gaining respect in the community. One biographer describes this period as her "emergence from Richard's shadow." In addition to her work on behalf of women's suffrage, she became active with the Women's Liberal Federation (WLF), an auxiliary of the Liberal Party. She quickly grew disenchanted with the group's moderate positions, however, especially its unwillingness to support Irish Home Rule and the aristocratic leadership of Archibald Primrose.
In 1888 Pankhurst had met and befriended Keir Hardie, a socialist from Scotland. He was elected to parliament in 1891 and two years later helped to create the Independent Labour Party (ILP). Excited about the range of issues which the ILP pledged to confront, Pankhurst resigned from the WLF and applied to join the ILP. The local branch refused her admission on the grounds of her gender, but she eventually joined the ILP nationally. Christabel later wrote of her mother's enthusiasm for the party and its organising efforts: "In this movement she hoped there might be the means of righting every political and social wrong."
One of her first activities with the ILP found Pankhurst distributing food to poor men and women through the Committee for the Relief of the Unemployed. In December 1894 she was elected to the position of Poor Law Guardian in Chorlton-on-Medlock. She was appalled by the conditions she witnessed first-hand in the Manchester workhouse:The first time I went into the place I was horrified to see little girls seven and eight years old on their knees scrubbing the cold stones of the long corridors ... bronchitis was epidemic among them most of the time ... I found that there were pregnant women in that workhouse, scrubbing floors, doing the hardest kind of work, almost until their babies came into the world ... Of course the babies are very badly protected ... These poor, unprotected mothers and their babies I am sure were potent factors in my education as a militant.
Pankhurst immediately began to change these conditions, and established herself as a successful voice of reform on the Board of Guardians. Her chief opponent was a passionate man named Mainwaring, known for his rudeness. Recognising that his loud anger was hurting his chances of persuading those aligned with Pankhurst, he kept a note nearby during meetings: "Keep your temper!"
After helping her husband with another unsuccessful parliamentary campaign, Pankhurst faced legal troubles in 1896 when she and two men violated a court order against ILP meetings at Boggart Hole Clough. With Richard's volunteering his time as legal counsel, they refused to pay fines, and the two men spent a month in prison. The punishment was never ordered for Pankhurst, however, possibly because the magistrate feared public backlash against the imprisonment of a woman so respected in the community. Asked by an ILP reporter if she were prepared to spend time in prison, Pankhurst replied: "Oh, yes, quite. It wouldn't be so very dreadful, you know, and it would be a valuable experience." Although ILP meetings were eventually permitted, the episode was a strain on Pankhurst's health and caused loss of income for their family.
Richard's death.
During the struggle at Boggart Hole Clough, Richard Pankhurst began to experience severe stomach pains. He had developed a gastric ulcer, and his health deteriorated in 1897. The family moved briefly to Mobberley, with the hope that country air would help his condition. He soon felt well again, and the family returned to Manchester in the autumn. In the summer of 1898 he suffered a sudden relapse. Pankhurst had taken their oldest daughter Christabel to Corsier, Switzerland, to visit her old friend Noémie. A telegram arrived from Richard, reading: "I am not well. Please come home, my love." Leaving Christabel with Noémie, Pankhurst returned immediately to England. On 5 July, while on a train from London to Manchester, she noticed a newspaper announcing the death of Richard Pankhurst.
The loss of her husband left Pankhurst with new responsibilities and a significant amount of debt. She moved the family to a smaller house, resigned from the Board of Guardians, and was given a paid position as Registrar of Births and Deaths in Chorlton. This work gave her more insight into the conditions of women in the region. She wrote in her autobiography: "They used to tell me their stories, dreadful stories some of them, and all of them pathetic with that patient and uncomplaining pathos of poverty." Her observations of the differences between the lives of men and women, for example in relation to illegitimacy, reinforced her conviction that women needed the right to vote before their conditions could improve. In 1900 she was elected to the Manchester School Board and saw new examples of women suffering unequal treatment and limited opportunities. During this time she also re-opened her store, with the hope that it would provide additional income for the family.
The individual identities of the Pankhurst children began to emerge around the time of their father's death. Before long they were all involved in the struggle for women's suffrage. Christabel enjoyed a privileged status among the daughters, as Sylvia noted in 1931: "She was our mother's favourite; we all knew it, and I, for one, never resented the fact." Christabel did not share her mother's fervour for political work, however, until she befriended the suffrage activists Esther Roper and Eva Gore-Booth. She soon became involved with the suffrage movement and joined her mother at speaking events. Sylvia took lessons from a respected local artist, and soon received a scholarship to the Manchester School of Art. She went on to study art in Florence and Venice. The younger children, Adela and Harry, had difficulty finding a path for their studies. Adela was sent to a local boarding school, where she was cut off from her friends and contracted head lice. Harry also had difficulty at school; he suffered from measles and vision problems.
Women's Social and Political Union.
By 1903 Pankhurst believed that years of moderate speeches and promises about women's suffrage from members of parliament (MPs) had yielded no progress. Although suffrage bills in 1870, 1886, and 1897 had shown promise, each was defeated. She doubted that political parties, with their many agenda items, would ever make women's suffrage a priority. She even broke with the ILP when it refused to focus on Votes for Women. It was necessary to abandon the patient tactics of existing advocacy groups, she believed, in favour of more militant actions. Thus on 10 October 1903 Pankhurst and several colleagues founded the Women's Social and Political Union (WSPU), an organisation open only to women and focused on direct action to win the vote. "Deeds," she wrote later, "not words, was to be our permanent motto."
The group's early militancy took non-violent forms. In addition to making speeches and gathering petition signatures, the WSPU organised rallies and published a newsletter called "Votes for Women." The group also convened a series of "Women's Parliaments" to coincide with official government sessions. When a bill for women's suffrage was filibustered on 12 May 1905, Pankhurst and other WSPU members began a loud protest outside the Parliament building. Police immediately forced them away from the building, where they regrouped and demanded passage of the bill. Although the bill was never resurrected, Pankhurst considered it a successful demonstration of militancy's power to capture attention. Pankhurst declared in 1906: "We are at last recognized as a political party; we are now in the swim of politics, and are a political force."
Before long, all three of her daughters became active with the WSPU. Christabel was arrested after spitting at a policeman during a meeting of the Liberal Party in October 1905; Adela and Sylvia were arrested a year later during a protest outside Parliament. Pankhurst was arrested for the first time in February 1908, when she tried to enter Parliament to deliver a protest resolution to Prime Minister H. H. Asquith. She was charged with obstruction and sentenced to six weeks in prison. She spoke out against the conditions of her confinement, including vermin, meagre food, and the "civilised torture of solitary confinement and absolute silence" to which she and others were ordered. Pankhurst saw imprisonment as a means to publicise the urgency of women's suffrage; in June 1909 she struck a police officer twice in the face to ensure she would be arrested. Pankhurst was arrested seven times before women's suffrage was approved. During her trial on 21 October 1908 she told the court: "We are here not because we are law-breakers; we are here in our efforts to become law-makers."
The exclusive focus of the WSPU on votes for women was another hallmark of its militancy. While other organisations agreed to work with individual political parties, the WSPU insisted on separating itself from – and in many cases opposing – parties which did not make women's suffrage a priority. The group protested against all candidates belonging to the party of the ruling government, since it refused to pass women's suffrage legislation. This brought them into immediate conflict with Liberal Party organisers, particularly since many Liberal candidates supported women's suffrage. (One early target of WSPU opposition was future Prime Minister Winston Churchill; his opponent attributed Churchill's defeat in part to "those ladies who are sometimes laughed at.")
Members of the WSPU were sometimes heckled and derided for spoiling elections for Liberal candidates. On 18 January 1908, Pankhurst and her associate Nellie Martel were attacked by an all-male crowd of Liberal supporters who blamed the WSPU for costing them a recent by-election to the Conservative candidate. The men threw clay, rotten eggs, and stones packed in snow; the women were beaten and Pankhurst's ankle was severely bruised. Similar tensions later formed with Labour. Until party leaders made the vote for women a priority, however, the WSPU vowed to continue its militant activism. Pankhurst and others in the union saw party politics as distracting to the goal of women's suffrage and criticised other organisations for putting party loyalty ahead of women's votes.
As the WSPU gained recognition and notoriety for its actions, Pankhurst resisted efforts to democratise the organisation itself. In 1907 a small group of members led by Teresa Billington-Greig called for more involvement from the rank-and-file suffragettes at the union's annual meetings. In response, Pankhurst announced at a WSPU meeting that elements of the organisation's constitution relating to decision-making were void and cancelled the annual meetings. She also insisted that a small committee chosen by the members in attendance be allowed to co-ordinate WSPU activities. Pankhurst and her daughter Christabel were chosen (along with Mabel Tuke and Emmeline Pethick Lawrence) as members of the new committee. Frustrated, several members including Billington-Greig and Charlotte Despard quit to form their own organisation, the Women's Freedom League. In her 1914 autobiography Pankhurst dismissed criticism of the WSPU's leadership structure:if at any time a member, or a group of members, loses faith in our policy; if any one begins to suggest that some other policy ought to be substituted, or if she tries to confuse the issue by adding other policies, she ceases at once to be a member. Autocratic? Quite so. But, you may object, a suffrage organisation ought to be democratic. Well the members of the W. S. P. U. do not agree with you. We do not believe in the effectiveness of the ordinary suffrage organisation. The W. S. P. U. is not hampered by a complexity of rules. We have no constitution and by-laws; nothing to be amended or tinkered with or quarrelled over at an annual meeting ... The W. S. P. U. is simply a suffrage army in the field.
Tactical intensification.
On 21 June 1908 500,000 activists rallied in Hyde Park to demand votes for women; Asquith and leading MPs responded with indifference. Angered by this intransigence and abusive police activity, some WSPU members increased the severity of their actions. Soon after the rally, twelve women gathered in Parliament Square and tried to deliver speeches for women's suffrage. Police officers seized several of the speakers and pushed them into a crowd of opponents who had gathered nearby. Frustrated, two WSPU members – Edith New and Mary Leigh – went to 10 Downing Street and hurled rocks at the windows of the Prime Minister's home. They insisted their act was independent of WSPU command, but Pankhurst expressed her approval of the action. When a magistrate sentenced New and Leigh to two months' imprisonment, Pankhurst reminded the court of how various male political agitators had broken windows to win legal and civil rights throughout Britain's history.
In 1909 the hunger strike was added to the WSPU's repertoire of resistance. On 24 June Marion Wallace Dunlop was arrested for writing an excerpt from the Bill of Rights (1688 or 1689) on a wall in the House of Commons. Angered by the conditions of the jail, Dunlop went on a hunger strike. When it proved effective, fourteen women imprisoned for smashing windows began to fast. WSPU members soon became known around the country for holding prolonged hunger strikes to protest their incarceration. Prison authorities frequently force-fed the women, using tubes inserted through the nose or mouth. The painful techniques (which, in the case of mouth-feeding, required the use of steel gags to force the mouth open) brought condemnation from suffragists and medical professionals.
These tactics caused some tension between the WSPU and more moderate organisations, which had coalesced into the National Union of Women's Suffrage Societies (NUWSS). That group's leader, Millicent Fawcett, originally hailed WSPU members for their courage and dedication to the cause. By 1912, however, she declared that hunger strikes were mere publicity stunts and that militant activists were "the chief obstacles in the way of success of the suffrage movement in the House of Commons." The NUWSS refused to join a march of women's suffrage groups after demanding without success that the WSPU end its support of property destruction. Fawcett's sister Elizabeth Garrett Anderson later resigned from the WSPU for similar reasons.
Press coverage was mixed; many journalists noted that crowds of women responded positively to speeches by Pankhurst, while others condemned her radical approach to the issue. The "Daily News" urged her to endorse a more moderate approach, and other press outlets condemned the breaking of windows by WSPU members. In 1906 "Daily Mail" journalist Charles Hands referred to militant women using the diminutive term "suffragette" (rather than the standard "suffragist"). Pankhurst and her allies seized the term as their own, and used it to differentiate themselves from moderate groups.
The last half of the century's first decade was a time of sorrow, loneliness and constant work for Pankhurst. In 1907 she sold her home in Manchester and began an itinerant lifestyle, moving from place to place as she spoke and marched for women's suffrage. She stayed with friends and in hotels, carrying her few possessions in suitcases. Although she was energised by the struggle–and found joy in giving energy to others– her constant travelling meant separation from her children, especially Christabel, who had become the national coordinator of the WSPU. In 1909, as Pankhurst planned a speaking tour of the United States, Harry was paralysed after his spinal cord became inflamed. She hesitated to leave the country while he was ill, but she needed money to pay for his treatment and the tour promised to be lucrative. On her return from a successful tour, she sat by Harry's bedside as he died on 5 January 1910. Five days later she buried her son, then spoke before 5,000 people in Manchester. Liberal Party supporters who had come to heckle her remained quiet as she addressed the crowd.
Conciliation, force-feeding, and arson.
After the Liberal losses in the 1910 elections, ILP member and journalist Henry Brailsford helped organise a Conciliation Committee for Women's Suffrage, which gathered 54 MPs from various parties. The group's Conciliation Bill looked to be a narrowly defined but still significant possibility to achieve the vote for women. Thus the WSPU agreed to suspend its support for window-breaking and hunger strikes while it was being negotiated. When it became clear that the bill would not pass, Pankhurst declared: "If the Bill, in spite of our efforts, is killed by the Government, then ... I have to say there is an end to the truce." When it was defeated, Pankhurst led a protest march of 300 women to Parliament Square on 18 November. They were met with aggressive police response, directed by Home Secretary Winston Churchill: officers punched the marchers, twisted arms, and pulled on women's breasts. Although Pankhurst was allowed to enter Parliament, Prime Minister Asquith refused to meet her. The incident became known as Black Friday.
As subsequent Conciliation Bills were introduced, WSPU leaders advocated a halt to militant tactics. In March 1912 the second bill was in jeopardy and Pankhurst joined a fresh outbreak of window-smashing. Extensive property damage led police to raid the WSPU offices. Pankhurst and Emmeline Pethick-Lawrence were tried at the Old Bailey and convicted of conspiracy to commit property damage. Christabel, who by 1912 was the chief coordinator for the organisation, was also wanted by police. She fled to Paris, where she directed WSPU strategy in exile. Inside Holloway Prison Emmeline Pankhurst staged her first hunger strike to improve conditions for other suffragettes in nearby cells; she was quickly joined by Pethick-Lawrence and other WSPU members. She described in her autobiography the trauma caused by force-feeding during the strike: "Holloway became a place of horror and torment. Sickening scenes of violence took place almost every hour of the day, as the doctors went from cell to cell performing their hideous office." When prison officials tried to enter her cell, Pankhurst raised a clay jug over her head and announced: "If any of you dares so much as to take one step inside this cell I shall defend myself."
Pankhurst was spared further force-feeding attempts after this incident, but she continued to violate the law and – when imprisoned – starve herself in protest. During the following two years she was arrested numerous times but was frequently released after several days because of her ill-health. Later, the Asquith government enacted the Cat and Mouse Act, which allowed similar releases for other suffragettes facing ill-health due to hunger strikes. Prison officials recognised the potential public relations disaster that would erupt if the popular WSPU leader were force-fed or allowed to suffer extensively in jail. Still, police officers arrested her during talks and as she marched. She tried to evade police harassment by wearing disguises and eventually the WSPU established a jujutsu-trained female bodyguard squad to physically protect her against the police. She and other escorts were targeted by police, resulting in violent scuffles as officers tried to detain Pankhurst.
In 1912 WSPU members adopted arson as another tactic to win the vote. After Prime Minister Asquith had visited the Theatre Royal in Dublin, suffragette activists Gladys Evans, Mary Leigh, Lizzie Baker and Mabel Capper of Oxford Street, Manchester attempted to cause an explosion using gunpowder and benzine, which resulted in minimal damage. During the same evening Mary Leigh threw an axe at the carriage containing John Redmond, the Lord Mayor, and Prime Minister Asquith. Over the next two years women set fire to a refreshments building in Regent's Park, an orchid house at Kew Gardens, pillar boxes, and a railway carriage. Although Pankhurst confirmed that these women had not been commanded by her or Christabel, they both assured the public that they supported the arsonist suffragettes. There were similar incidents around the country. One WSPU member, for example, put a small hatchet into the Prime Minister's carriage inscribed with the words: "Votes for Women," and other suffragettes used acid to burn the same slogan into golf courses used by MPs. In 1914 Mary Richardson slashed the Rokeby Venus to protest against Pankhurst's imprisonment.
Defection and dismissal.
The WSPU's approval of property destruction led to the departure of several important members. The first were Emmeline Pethick-Lawrence and her husband Frederick. They had long been integral members of the group's leadership but found themselves in conflict with Christabel about the wisdom of such volatile tactics. After returning from a vacation in Canada they found that Pankhurst had expelled them from the WSPU. The pair found the decision appalling, but to avoid a schism in the movement they continued to praise Pankhurst and the organisation in public. Around the same time, Emmeline's daughter Adela left the group. She disapproved of WSPU endorsement of property destruction and felt that a heavier emphasis on socialism was necessary. Adela's relationship with her family – especially Christabel – was also strained as a result.
The deepest rift in the Pankhurst family came in November 1913 when Sylvia spoke at a meeting of socialists and trade unionists in support of labour organiser Jim Larkin. She had been working with the East London Federation of Suffragettes (ELFS), a local branch of the WSPU which had a close relationship with socialists and organised labour. The close connection to labour groups and Sylvia's appearance on stage with Frederick Pethick-Lawrence – who also addressed the crowd – convinced Christabel that her sister was organising a group that might challenge the WSPU in the suffrage movement. The dispute became public, and members of groups including the WSPU, ILP, and ELFS braced themselves for a showdown.
In January Sylvia was summoned to Paris, where Emmeline and Christabel were waiting. Their mother had just returned from another tour of the US, and Sylvia had just been released from prison. All three women were exhausted and stressed, which added considerably to the tension. In her 1931 book "The Suffrage Movement" Sylvia describes Christabel as an unreasonable figure, haranguing her for refusing to toe the WSPU line:She turned to me. "You have your own ideas. We do not want that; we want all our women to take their instructions and walk in step like an army!" Too tired, too ill to argue, I made no reply. I was oppressed by a sense of tragedy, grieved by her ruthlessness. Her glorification of autocracy seemed to me remote indeed from the struggle we were waging, the grim fight even now proceeding in the cells. I thought of many others who had been thrust aside for some minor difference.With their mother's blessing, Christabel ordered Sylvia's group to dissociate from the WSPU. Pankhurst tried to persuade the ELFS to remove the word "suffragettes" from its name, since it was inextricably linked to the WSPU. When Sylvia refused, her mother switched to fierce anger in a letter:You are unreasonable, always have been & I fear always will be. I suppose you were made so! ... Had you chosen a name which we could approve we could have done much to launch you & advertise your society by name. Now you must take your own way of doing so. I am sorry but you make your own difficulties by an incapacity to look at situations from other people's point of view as well as your own. Perhaps in time you will learn the lessons that we all have to learn in life.Adela, unemployed and unsure of her future, had become a worry for Pankhurst as well. She decided that Adela should move to Australia, and paid for her relocation. They never saw one another again.
First World War.
When the First World War began in August 1914, Emmeline and Christabel considered that the threat posed by Germany was a danger to all humanity and that the British government needed the support of all citizens. They persuaded the WSPU to halt all militant suffrage activities until fighting on the European mainland ended. It was no time for dissent or agitation; Christabel wrote later: "This was national militancy. As Suffragists we could not be pacifists at any price." A truce with the government was established, all WSPU prisoners were released, and Christabel returned to London. Emmeline and Christabel along with WSPU leaders Grace Roe and Norah Dacre Fox (later known as Norah Elam) set the WSPU into motion on behalf of the war effort. In her first speech after returning to Britain, Christabel warned of the "German Peril." She urged the gathered women to follow the example of their French sisters, who–while the men fought– "are able to keep the country going, to get in the harvest, to carry on the industries." Emmeline urged men to volunteer for the front lines and, along with Christabel, became a leading figure in the white feather movement. Surviving Pathe newsreel shows Emmeline and Norah Dacre Fox speaking at a large meeting at Trafalgar Square in 1916 on the Rumanian Crisis, urging the government to support Britain's allies in the Balkans.
Sylvia and Adela, meanwhile, did not share their mother's enthusiasm for the war. As committed pacifists, they rejected the WSPU's support for the government. Sylvia's socialist perspective convinced her that the war was another example of capitalist oligarchs exploiting poor soldiers and workers. Adela, meanwhile, spoke against the war in Australia and made public her opposition to conscription. In a short letter, Emmeline told Sylvia: "I am ashamed to know where you and Adela stand." She had a similar impatience for dissent within the WSPU; when long-time member Mary Leigh asked a question during a meeting in October 1915, Pankhurst replied: "[T]hat woman is a pro German and should leave the hall. ... I denounce you as a pro German and wish to forget that such a person ever existed." Some WSPU members were outraged by this sudden rigid devotion to the government, the leadership's perceived abandonment of efforts to win the vote for women, and questions about how funds collected on behalf of suffrage were being managed with regard to the organisation's new focus. Two groups split from the WSPU: The Suffragettes of the Women's Social and Political Union (SWSPU) and the Independent Women's Social and Political Union (IWSPU), each dedicated to maintaining pressure toward women's suffrage.
Pankhurst put the same energy and determination she had previously applied to women's suffrage into patriotic advocacy of the war effort. She organised rallies, toured constantly delivering speeches, and lobbied the government to help women enter the work force while men were overseas fighting. Another issue which concerned her greatly at the time was the plight of so-called war babies, children born to single mothers whose fathers were on the front lines. Pankhurst established an adoption home at Campden Hill designed to employ the Montessori method of childhood education. Some women criticised Pankhurst for offering relief to parents of children born out of wedlock, but she declared indignantly that the welfare of children–whose suffering she had seen firsthand as a Poor Law Guardian–was her only concern. Due to lack of funds, however, the home was soon turned over to Princess Alice. Pankhurst herself adopted four children, whom she renamed Kathleen King, Flora Mary Gordon, Joan Pembridge and Elizabeth Tudor. They lived in London, where–for the first time in many years–she had a permanent home, at Holland Park. Asked how, at the age of 57 and with no steady income, she could take on the burden of bringing up four more children, Pankhurst replied: "My dear, I wonder I didn't take forty."
Russian delegation and Women's Party.
Pankhurst visited North America in 1916 together with the former Secretary of State for Serbia, Čedomilj Mijatović, whose nation had been at the centre of fighting at the start of the war. They toured the United States and Canada, raising money and urging the US government to support Britain and its Canadian and other allies. Two years later, after the US entered the war, Pankhurst returned to the United States, encouraging suffragettes there – who had not suspended their militancy – to support the war effort by sidelining activities related to the vote. She also spoke about her fears of communist insurgency, which she considered a grave threat to Russian democracy.
By June 1917 the Russian Revolution had strengthened the Bolsheviks, who urged an end to the war. Pankhurst's translated autobiography had been read widely in Russia, and she saw an opportunity to put pressure on the Russian people. She hoped to convince them not to accept Germany's conditions for peace, which she saw as a potential defeat for Britain and Russia. UK Prime Minister David Lloyd George agreed to sponsor her trip to Russia, which she took in June. She told one crowd: "I came to Petrograd with a prayer from the English nation to the Russian nation, that you may continue the war on which depends the face of civilisation and freedom." Press response was divided between left and right wings; the former depicted her as a tool of capitalism, while the latter praised her devout patriotism.
In August she met with Alexander Kerensky, the Russian Prime Minister. Although she had been active with the socialist-leaning ILP in years past, Pankhurst had begun to see leftist politics as disagreeable, an attitude which intensified while she was in Russia. The meeting was uncomfortable for both parties; he felt that she was unable to appreciate the class-based conflict driving Russian policy at the time. He concluded by telling her that English women had nothing to teach women in Russia. She later told the "New York Times" that he was the "biggest fraud of modern times" and that his government could "destroy civilisation."
When she returned from Russia, Pankhurst was delighted to find that women's right to vote was finally on its way to becoming a reality. The 1918 Representation of the People Act removed property restrictions on men's suffrage and granted the vote to women over the age of 30 (with several restrictions). As suffragists and suffragettes celebrated and prepared for its imminent passage, a new schism erupted: should women's political organisations join forces with those established by men? Many socialists and moderates supported unity of the sexes in politics, but Emmeline and Christabel Pankhurst saw the best hope in remaining separate. They reinvented the WSPU as the Women's Party, still open only to women. Women, they said, "can best serve the nation by keeping clear of men's party political machinery and traditions, which, by universal consent, leave so much to be desired." The party favoured equal marriage laws, equal pay for equal work, and equal job opportunities for women. These were matters for the post-war era, however. While the fighting continued the Women's Party demanded no compromise in the defeat of Germany; the removal from government of anyone with family ties to Germany or pacifist attitudes; and shorter work hours to forestall labour strikes. This last plank in the party's platform was meant to discourage potential interest in Bolshevism, about which Pankhurst was increasingly anxious.
Post-war activities.
In the years after the 1918 Armistice, Pankhurst continued to promote her nationalist vision of British unity. She maintained a focus on women's empowerment, but her days of fighting with government officialdom were over. She defended the presence and reach of the British Empire: "Some talk about the Empire and Imperialism as if it were something to decry and something to be ashamed of. [I]t is a great thing to be the inheritors of an Empire like ours ... great in territory, great in potential wealth. ... If we can only realise and use that potential wealth we can destroy thereby poverty, we can remove and destroy ignorance." For years she travelled around England and North America, rallying support for the British Empire and warning audiences about the dangers of Bolshevism.
Emmeline Pankhurst also became active in political campaigning again when a bill was passed allowing women to run for the House of Commons. Many Women's Party members urged Pankhurst to stand for election, but she insisted that Christabel was a better choice. She campaigned tirelessly for her daughter, lobbying Prime Minister Lloyd George for his support and at one point delivering a passionate speech in the rain. Christabel lost by a very slim margin to the Labour Party candidate, and the recount showed a difference of 775 votes. One biographer called it "the bitterest disappointment of Emmeline's life." The Women's Party withered from existence soon afterward.
As a result of her many trips to North America, Pankhurst became fond of Canada, stating in an interview that "there seems to be more equality between men and women [there] than in any other country I know." In 1922 she applied for Canadian "permission to land" (a prerequisite to status as a "British Subject with Canadian Domicile") and rented a house in Toronto, where she moved with her four adopted children. She became active with the Canadian National Council for Combating Venereal Diseases (CNCCVD), which worked against the sexual double-standard which Pankhurst considered particularly harmful to women. During a tour of Bathurst, the mayor showed her a new building which would become the Home for Fallen Women. Pankhurst replied: "Ah! Where is your Home for Fallen Men?" Before long, however, she grew tired of long Canadian winters, and she ran out of money. She returned to England in late 1925.
Back in London Emmeline was visited by Sylvia, who had not seen her mother in years. Their politics were by now very different, and Sylvia was living, unmarried, with an Italian anarchist. Sylvia described a moment of familial affection when they met, followed by a sad distance between them. Emmeline's adopted daughter Mary, however, remembered the meeting differently. According to her version, Emmeline set her teacup down and walked silently out of the room, leaving Sylvia in tears. Christabel, meanwhile, had become a convert to Adventism and devoted much of her time to the church. The British press sometimes made light of the varied paths followed by the once indivisible family.
In 1926 Pankhurst joined the Conservative Party and two years later ran as a candidate for Parliament in Whitechapel and St George's. Her transformation from a fiery supporter of the ILP and window-smashing radical to an official Conservative Party member surprised many people. She replied succinctly: "My war experience and my experience on the other side of the Atlantic have changed my views considerably." Her biographers insist that the move was more complex; she was devoted to a programme of women's empowerment and anti-communism. Both the Liberal and Labour parties bore grudges for her work against them in the WSPU, and the Conservative Party had a victorious record after the war and a significant majority. Pankhurst's membership of the Conservative Party may have had as much to do with ensuring her aims of obtaining the vote for women were achieved as with ideology.
Illness and death.
Emmeline Pankhurst's campaign for Parliament was pre-empted by her ill health and a final scandal involving Sylvia. The years of touring, lectures, imprisonment and hunger strikes had taken their toll; fatigue and illness became a regular part of Pankhurst's life. Even more painful, however, was the news in April 1928 that Sylvia had given birth out of wedlock. She had named the child Richard Keir Pethick Pankhurst, in memory of her father, her ILP comrade, and her colleagues from the WSPU respectively. Emmeline was further shocked to see a report from a newspaper in the US that declared that "Miss Pankhurst" – a title usually reserved for Christabel – boasted of her child being a triumph of "eugenics," since both parents were healthy and intelligent. In the article, Sylvia also spoke of her belief that "marriage without legal union" was the most sensible option for liberated women. These offences against the social dignity which Pankhurst had always valued devastated the elderly woman; to make matters worse, many people believed the "Miss Pankhurst" in newspaper headlines referred to Christabel. After hearing the news, Emmeline spent an entire day crying; her campaign for Parliament ended with the scandal.
As her health went downhill, Emmeline Pankhurst moved into a nursing home in Hampstead. She requested that she be treated by the doctor who attended to her during her hunger strikes. His use of the stomach pump had helped her feel better while in prison; her nurses were sure that the shock of such treatment would severely wound her, but Christabel felt obligated to carry out her mother's request. Before the procedure could be carried out, however, she fell into a critical condition from which none expected her to recover. On Thursday 14 June 1928 Pankhurst died, at the age of 69. She was interred in Brompton Cemetery in London.
Legacy.
News of Emmeline Pankhurst's death was announced around the country, and extensively in North America. Her funeral service on 18 June was filled with her former WSPU colleagues and those who had worked beside her in various capacities. The "Daily Mail" described the procession as "like a dead general in the midst of a mourning army." Women wore WSPU sashes and ribbons, and the organisation's flag was carried alongside the Union Flag. Christabel and Sylvia appeared together at the service, the latter with her child. Adela did not attend. Press coverage around the world recognised her tireless work on behalf of women's right to vote – even if they didn't agree on the value of her contributions. The "New York Herald Tribune" called her "the most remarkable political and social agitator of the early part of the twentieth century and the supreme protagonist of the campaign for the electoral enfranchisement of women."
Shortly after the funeral, one of Pankhurst's bodyguards from her WSPU days, Katherine Marshall, began raising funds for a memorial statue. In spring 1930 her efforts bore fruit, and on 6 March her statue in Victoria Tower Gardens was unveiled. A crowd of radicals, former suffragettes, and national dignitaries gathered as former Prime Minister Stanley Baldwin presented the memorial to the public. In his address, Baldwin declared: "I say with no fear of contradiction, that whatever view posterity may take, Mrs. Pankhurst has won for herself a niche in the Temple of Fame which will last for all time." Sylvia was the only Pankhurst daughter in attendance; Christabel, touring North America, sent a telegram which was read aloud. While planning the agenda for the day, Marshall had intentionally excluded Sylvia, who in her opinion had hastened Pankhurst's death.
During the twentieth century Emmeline Pankhurst's value to the movement for women's suffrage was debated passionately, and no consensus was achieved. Her daughters Sylvia and Christabel weighed in with books, scornful and laudatory respectively, about their time in the struggle. Sylvia's 1931 book "The Suffrage Movement" describes her mother's political shift at the start of the First World War as the beginning of a betrayal of her family (especially her father) and the movement. It set the tone for much of the socialist and activist history written about the WSPU and particularly solidified Emmeline Pankhurst's reputation as an unreasonable autocrat. Christabel's "Unshackled: The Story of How We Won the Vote," released in 1959, paints her mother as generous and selfless to a fault, offering herself completely to the most noble causes. It provided a sympathetic counterpart to Sylvia's attacks and continued the polarised discussion; detached and objective assessment has rarely been a part of Pankhurst scholarship.
Recent biographies show that historians differ about whether Emmeline Pankhurst's militancy helped or hurt the movement; however, there is general agreement that the WSPU raised public awareness of the movement in ways that proved essential. Baldwin compared her to Martin Luther and Jean-Jacques Rousseau: individuals who were not the sum total of the movements in which they took part, but who nevertheless played crucial roles in struggles of social and political reform. In the case of Pankhurst, this reform took place in both intentional and unintentional ways. By defying the roles of wife and mother as the docile companion, Pankhurst paved the way for feminists who would later decry her support for empire and sustainable social values.
Emmeline Pankhurst's importance to the United Kingdom was demonstrated again in 1929, when a portrait of her was added to the National Portrait Gallery. The BBC dramatised her life in the 1974 mini-series "Shoulder to Shoulder", with Welsh actress Siân Phillips in the role of Emmeline Pankhurst. In 1987 one of her homes in Manchester was opened as the Pankhurst Centre, an all-women gathering space and museum. In 2002, Pankhurst was placed at number 27 in the BBC's poll of the 100 Greatest Britons.

</doc>
<doc id="60558" url="http://en.wikipedia.org/wiki?curid=60558" title="ARM architecture">
ARM architecture

ARM is a family of instruction set architectures for computer processors developed by British company ARM Holdings, based on a reduced instruction set computing (RISC) architecture.
A RISC-based computer design approach means ARM processors require significantly fewer transistors than typical CISC x86 processors in most personal computers. This approach reduces costs, heat and power use. Such reductions are desirable traits for light, portable, battery-powered devices—&#X200B;including smartphones, laptops, tablet and notepad computers, and other embedded systems. A simpler design facilitates more efficient multi-core CPUs and higher core counts at lower cost, providing improved energy efficiency for servers.
ARM Holdings develops the instruction set and architecture for ARM-based products, but does not manufacture products. The company periodically releases updates to its cores. Current cores from ARM Holdings support a 32-bit address space and 32-bit arithmetic; the ARMv8-A architecture, announced in October 2011, adds support for a 64-bit address space and 64-bit arithmetic. Instructions for ARM Holdings' cores have 32 bits wide fixed-length instructions, but later versions of the architecture also support a variable-length instruction set that provides both 32 and 16 bits wide instructions for improved code density. Some cores can also provide hardware execution of Java bytecodes.
ARM Holdings licenses the chip designs and the ARM instruction set architectures to third parties, who design their own products that implement one of those architectures—&#X200B;including systems-on-chips (SoC) that incorporate memory, interfaces, radios, etc. Currently, the widely used Cortex cores, older "classic" cores, and specialized SecurCore cores variants are available for each of these to include or exclude optional capabilities. Companies that make chips that implement an ARM architecture include Apple, AppliedMicro, Atmel, Broadcom, Cypress Semiconductor, Freescale Semiconductor, Nvidia, NXP, Qualcomm, Samsung Electronics, ST Microelectronics and Texas Instruments. Qualcomm introduced new three-layer 3D chip stacking in their 2014-15 ARM SoCs such as in their first 20 nm 64-bit octa-core.
Globally ARM is the most widely used instruction set architecture in terms of quantity produced. The low power consumption of ARM processors has made them very popular: over 50 billion ARM processors have been produced as of 2014[ [update]], of which 10 billion were produced in 2013 and "ARM-based chips are found in nearly 60 percent of the world’s mobile devices". The ARM architecture (32-bit) is the most widely used architecture in mobile devices, and most popular 32-bit one in embedded systems. In 2005, about 98% of all mobile phones sold used at least one ARM processor. According to ARM Holdings, in 2010 alone, producers of chips based on ARM architectures reported shipments of 6.1 billion ARM-based processors, representing 95% of smartphones, 35% of digital televisions and set-top boxes and 10% of mobile computers.
History.
The British computer manufacturer Acorn Computers first developed the Acorn RISC Machine architecture (ARM) in the 1980s to use in its personal computers. Its first ARM-based products were coprocessor modules for the BBC Micro series of computers. After the successful BBC Micro computer, Acorn Computers considered how to move on from the relatively simple MOS Technology 6502 processor to address business markets like the one that was soon dominated by the IBM PC, launched in 1981. The "Acorn Business Computer" (ABC) plan required that a number of second processors be made to work with the BBC Micro platform, but processors such as the Motorola 68000 and National Semiconductor 32016 were considered unsuitable, and the 6502 was not powerful enough for a graphics based user interface.
According to Sophie Wilson, all the tested processors at that time performed about the same, with about a 4Mb/second bandwidth.
After testing all available processors and finding them lacking, Acorn decided it needed a new architecture. Inspired by white papers on the Berkeley RISC project, Acorn considered designing its own processor. A visit to the Western Design Center in Phoenix, where the 6502 was being updated by what was effectively a single-person company, showed Acorn engineers Steve Furber and Sophie Wilson they did not need massive resources and state-of-the-art research and development facilities.
Wilson developed the instruction set, writing a simulation of the processor in BBC BASIC that ran on a BBC Micro with a second 6502 processor. This convinced Acorn engineers they were on the right track. Wilson approached Acorn's CEO, Hermann Hauser, and requested more resources. Once he had approval, he assembled a small team to implement Wilson's model in hardware.
Acorn RISC Machine: ARM2.
The official "Acorn RISC Machine" project started in October 1983. They chose VLSI Technology as the "silicon partner", as they were a source of ROMs and custom chips for Acorn. Wilson and Furber led the design. They implemented it with a similar efficiency ethos as the 6502. A key design goal was achieving low-latency input/output (interrupt) handling like the 6502. The 6502's memory access architecture had let developers produce fast machines without costly direct memory access hardware.
The first samples of ARM silicon worked properly when first received and tested on 26 April 1985.
The first ARM application was as a second processor for the BBC Micro, where it helped in developing simulation software to finish development of the support chips (VIDC, IOC, MEMC), and sped up the CAD software used in ARM2 development. Wilson subsequently rewrote BBC BASIC in ARM assembly language. The in-depth knowledge gained from designing the instruction set enabled the code to be very dense, making ARM BBC BASIC an extremely good test for any ARM emulator. The original aim of a principally ARM-based computer was achieved in 1987 with the release of the Acorn Archimedes. In 1992, Acorn once more won the Queen's Award for Technology for the ARM.
The ARM2 featured a 32-bit data bus, 26-bit address space and 27 32-bit registers. Eight bits from the program counter register were available for other purposes; the top six bits (available because of the 26-bit address space), served as status flags, and the bottom two bits (available because the program counter was always word-aligned), were used for setting modes. The address bus was extended to 32 bits in the ARM6, but program code still had to lie within the first 64 MB of memory in 26-bit compatibility mode, due to the reserved bits for the status flags. The ARM2 had a transistor count of just 30,000, compared to Motorola's six-year-older 68000 model with around 40,000. Much of this simplicity came from the lack of microcode (which represents about one-quarter to one-third of the 68000) and from (like most CPUs of the day) not including any cache. This simplicity enabled low power consumption, yet better performance than the Intel 80286. A successor, ARM3, was produced with a 4 KB cache, which further improved performance.
Apple, DEC, Intel, Marvell: ARM6, StrongARM, XScale.
In the late 1980s Apple Computer and VLSI Technology started working with Acorn on newer versions of the ARM core. In 1990, Acorn spun off the design team into a new company named Advanced RISC Machines Ltd., which became ARM Ltd when its parent company, ARM Holdings plc, floated on the London Stock Exchange and NASDAQ in 1998.
The new Apple-ARM work would eventually evolve into the ARM6, first released in early 1992. Apple used the ARM6-based ARM610 as the basis for their Apple Newton PDA. In 1994, Acorn used the ARM610 as the main central processing unit (CPU) in their RiscPC computers. DEC licensed the ARM6 architecture and produced the StrongARM. At 233 MHz, this CPU drew only one watt (newer versions draw far less). This work was later passed to Intel as a part of a lawsuit settlement, and Intel took the opportunity to supplement their i960 line with the StrongARM. Intel later developed its own high performance implementation named XScale, which it has since sold to Marvell. Transistor count of the ARM core remained essentially the same size throughout these changes; ARM2 had 30,000 transistors, while ARM6 grew only to 35,000.
Licensing.
Core licence.
ARM Holdings' primary business is selling IP cores, which licensees use to create microcontrollers (MCUs) and CPUs based on those cores. The original design manufacturer combines the ARM core with other parts to produce a complete CPU, typically one that can be built in existing semiconductor fabs at low cost and still deliver substantial performance. The most successful implementation has been the ARM7TDMI with hundreds of millions sold. Atmel has been a precursor design center in the ARM7TDMI-based embedded system.
The ARM architectures used in smartphones, PDAs and other mobile devices range from ARMv5, used in low-end devices, through ARMv6, to ARMv7 in current high-end devices. ARMv7 includes a hardware floating-point unit (FPU), with improved speed compared to software-based floating-point.
In 2009, some manufacturers introduced netbooks based on ARM architecture CPUs, in direct competition with netbooks based on Intel Atom. According to analyst firm IHS iSuppli, by 2015, ARM ICs may be in 23% of all laptops.
ARM Holdings offers a variety of licensing terms, varying in cost and deliverables. ARM Holdings provides to all licensees an integratable hardware description of the ARM core as well as complete software development toolset (compiler, debugger, software development kit) and the right to sell manufactured silicon containing the ARM CPU.
SoC packages integrating ARM's core designs include Nvidia Tegra's first three generations, CSR plc's Quatro family, ST-Ericsson's Nova and NovaThor, Silicon Labs's Precision32 MCU, Texas Instruments's OMAP products, Samsung's Hummingbird and Exynos products, Apple's A4, A5, and A5X, and Freescale's i.MX.
Fabless licensees, who wish to integrate an ARM core into their own chip design, are usually only interested in acquiring a ready-to-manufacture verified IP core. For these customers, ARM Holdings delivers a gate netlist description of the chosen ARM core, along with an abstracted simulation model and test programs to aid design integration and verification. More ambitious customers, including integrated device manufacturers (IDM) and foundry operators, choose to acquire the processor IP in synthesizable RTL (Verilog) form. With the synthesizable RTL, the customer has the ability to perform architectural level optimisations and extensions. This allows the designer to achieve exotic design goals not otherwise possible with an unmodified netlist (high clock speed, very low power consumption, instruction set extensions, etc.). While ARM Holdings does not grant the licensee the right to resell the ARM architecture itself, licensees may freely sell manufactured product such as chip devices, evaluation boards and complete systems. Merchant foundries can be a special case; not only are they allowed to sell finished silicon containing ARM cores, they generally hold the right to re-manufacture ARM cores for other customers.
ARM Holdings prices its IP based on perceived value. Lower performing ARM cores typically have lower licence costs than higher performing cores. In implementation terms, a synthesizable core costs more than a hard macro (blackbox) core. Complicating price matters, a merchant foundry that holds an ARM licence, such as Samsung or Fujitsu, can offer fab customers reduced licensing costs. In exchange for acquiring the ARM core through the foundry's in-house design services, the customer can reduce or eliminate payment of ARM's upfront licence fee.
Compared to dedicated semiconductor foundries (such as TSMC and UMC) without in-house design services, Fujitsu/Samsung charge two- to three-times more per manufactured wafer. For low to mid volume applications, a design service foundry offers lower overall pricing (through subsidisation of the licence fee). For high volume mass-produced parts, the long term cost reduction achievable through lower wafer pricing reduces the impact of ARM's NRE (Non-Recurring Engineering) costs, making the dedicated foundry a better choice.
Architectural licence.
Companies can also obtain an ARM "architectural licence" for designing their own CPU cores using the ARM instruction sets. These cores must comply fully with the ARM architecture.
Cores.
A list of vendors who implement ARM cores in their design (application specific standard products (ASSP), microprocessor and microcontrollers) is provided by ARM Holdings.
Example applications of ARM cores.
ARM cores are used in a number of products, particularly PDAs and smartphones. Some computing examples are the Microsoft Surface, Apple's iPad and ASUS Eee Pad Transformer tablet computers. Others include Apple's iPhone smartphone and iPod portable media player, Canon PowerShot digital cameras, Nintendo DS handheld game consoles and TomTom turn-by-turn navigation systems.
In 2005, ARM Holdings took part in the development of Manchester University's computer, SpiNNaker, which used ARM cores to simulate the human brain.
ARM chips are also used in Raspberry Pi, BeagleBoard, BeagleBone, PandaBoard and other single-board computers, because they are very small, inexpensive and consume very little power.
32-bit architecture.
The 32-bit ARM architecture, such as ARMv7-A, is the most widely used architecture in mobile devices.
Since 1995, the "" has been the primary source of documentation on the ARM processor architecture and instruction set, distinguishing interfaces that all ARM processors are required to support (such as instruction semantics) from implementation details that may vary. The architecture has evolved over time, and version seven of the architecture, ARMv7, defines three architecture "profiles":
Although the architecture profiles were first defined for ARMv7, ARM subsequently defined the ARMv6-M architecture (used by the Cortex M0/M0+/M1) as a subset of the ARMv7-M profile with fewer instructions.
CPU modes.
Except in the M-profile, the 32-bit ARM architecture specifies several CPU modes, depending on the implemented architecture features. At any moment in time, the CPU can be in only one mode, but it can switch modes due to external events (interrupts) or programmatically.
Instruction set.
The original (and subsequent) ARM implementation was hardwired without microcode, like the much simpler 8-bit 6502 processor used in prior Acorn microcomputers.
The 32-bit ARM architecture (and the 64-bit architecture for the most part) includes the following RISC features:
To compensate for the simpler design, compared with processors like the Intel 80286 and Motorola 68020, some additional design features were used:
Arithmetic instructions.
ARM includes integer arithmetic operations for add, subtract, and multiply; some versions of the architecture also support divide operations.
ARM supports 32-bit x 32-bit multiplies with either a 32-bit result or 64-bit result, though Cortex-M0 / M0+ / M1 cores don't support 64-bit results. Some ARM cores also support 16-bit x 16-bit and 32-bit x 16-bit multiplies.
The divide instructions are only included in the following ARM architectures:
Registers.
Registers R0 through R7 are the same across all CPU modes; they are never banked.
R13 and R14 are banked across all privileged CPU modes except system mode. That is, each mode that can be entered because of an exception has its own R13 and R14. These registers generally contain the stack pointer and the return address from function calls, respectively.
Aliases:
The Current Program Status Register (CPSR) has the following 32 bits.
Conditional execution.
Almost every ARM instruction has a conditional execution feature called predication, which is implemented with a 4-bit condition code selector (the predicate). To allow for unconditional execution, one of the four-bit codes causes the instruction to be always executed. Most other CPU architectures only have condition codes on branch instructions.
Though the predicate takes up four of the 32 bits in an instruction code, and thus cuts down significantly on the encoding bits available for displacements in memory access instructions, it avoids branch instructions when generating code for small codice_1 statements. Apart from eliminating the branch instructions themselves, this preserves the fetch/decode/execute pipeline at the cost of only one cycle per skipped instruction.
The standard example of conditional execution is the subtraction-based Euclidean algorithm:
In the C programming language, the loop is:
In ARM assembly, the loop is:
which avoids the branches around the codice_2 and codice_3 clauses.
If codice_4 and codice_5 are equal then neither of the codice_6 instructions will be executed, eliminating the need for a conditional branch to implement the codice_7 check at the top of the loop, for example had codice_8 (less than or equal) been used.
One of the ways that Thumb code provides a more dense encoding is to remove the four bit selector from non-branch instructions.
Other features.
Another feature of the instruction set is the ability to fold shifts and rotates into the "data processing" (arithmetic, logical, and register-register move) instructions, so that, for example, the C statement
could be rendered as a single-word, single-cycle instruction:
This results in the typical ARM program being denser than expected with fewer memory accesses; thus the pipeline is used more efficiently.
The ARM processor also has features rarely seen in other RISC architectures, such as PC-relative addressing (indeed, on the 32-bit ARM the PC is one of its 16 registers) and pre- and post-increment addressing modes.
The ARM instruction set has increased over time. Some early ARM processors (before ARM7TDMI), for example, have no instruction to store a two-byte quantity.
Pipelines and other implementation issues.
The ARM7 and earlier implementations have a three-stage pipeline; the stages being fetch, decode and execute. Higher-performance designs, such as the ARM9, have deeper pipelines: Cortex-A8 has thirteen stages. Additional implementation changes for higher performance include a faster adder and more extensive branch prediction logic. The difference between the ARM7DI and ARM7DMI cores, for example, was an improved multiplier; hence the added "M".
Coprocessors.
The ARM architecture (pre-ARMv8) provides a non-intrusive way of extending the instruction set using "coprocessors" that can be addressed using MCR, MRC, MRRC, MCRR, and similar instructions. The coprocessor space is divided logically into 16 coprocessors with numbers from 0 to 15, coprocessor 15 (cp15) being reserved for some typical control functions like managing the caches and MMU operation on processors that have one.
In ARM-based machines, peripheral devices are usually attached to the processor by mapping their physical registers into ARM memory space, into the coprocessor space, or by connecting to another device (a bus) that in turn attaches to the processor. Coprocessor accesses have lower latency, so some peripherals—for example an XScale interrupt controller—are accessible in both ways: through memory and through coprocessors.
In other cases, chip designers only integrate hardware using the coprocessor mechanism. For example, an image processing engine might be a small ARM7TDMI core combined with a coprocessor that has specialised operations to support a specific set of HDTV transcoding primitives.
Debugging.
All modern ARM processors include hardware debugging facilities, allowing software debuggers to perform operations such as halting, stepping, and breakpointing of code starting from reset. These facilities are built using JTAG support, though some newer cores optionally support ARM's own two-wire "SWD" protocol. In ARM7TDMI cores, the "D" represented JTAG debug support, and the "I" represented presence of an "EmbeddedICE" debug module. For ARM7 and ARM9 core generations, EmbeddedICE over JTAG was a de facto debug standard, though not architecturally guaranteed.
The ARMv7 architecture defines basic debug facilities at an architectural level. These include breakpoints, watchpoints and instruction execution in a "Debug Mode"; similar facilities were also available with EmbeddedICE. Both "halt mode" and "monitor" mode debugging are supported. The actual transport mechanism used to access the debug facilities is not architecturally specified, but implementations generally include JTAG support.
There is a separate ARM "CoreSight" debug architecture, which is not architecturally required by ARMv7 processors.
DSP enhancement instructions.
To improve the ARM architecture for digital signal processing and multimedia applications, DSP instructions were added to the set. These are signified by an "E" in the name of the ARMv5TE and ARMv5TEJ architectures. E-variants also imply T, D, M and I.
The new instructions are common in digital signal processor architectures. They include variations on signed multiply–accumulate, saturated add and subtract, and count leading zeros.
SIMD extensions for multimedia.
Introduced in ARMv6 architecture and known as NEON.
Jazelle.
Jazelle DBX (Direct Bytecode eXecution) is a technique that allows Java Bytecode to be executed directly in the ARM architecture as a third execution state (and instruction set) alongside the existing ARM and Thumb-mode. Support for this state is signified by the "J" in the ARMv5TEJ architecture, and in ARM9EJ-S and ARM7EJ-S core names. Support for this state is required starting in ARMv6 (except for the ARMv7-M profile), though newer cores only include a trivial implementation that provides no hardware acceleration.
Thumb.
To improve compiled code-density, processors since the ARM7TDMI (released in 1994) have featured the "Thumb" instruction set, which have their own state. (The "T" in "TDMI" indicates the Thumb feature.) When in this state, the processor executes the Thumb instruction set, a compact 16-bit encoding for a subset of the ARM instruction set. Most of the Thumb instructions are directly mapped to normal ARM instructions. The space-saving comes from making some of the instruction operands implicit and limiting the number of possibilities compared to the ARM instructions executed in the ARM instruction set state.
In Thumb, the 16-bit opcodes have less functionality. For example, only branches can be conditional, and many opcodes are restricted to accessing only half of all of the CPU's general-purpose registers. The shorter opcodes give improved code density overall, even though some operations require extra instructions. In situations where the memory port or bus width is constrained to less than 32 bits, the shorter Thumb opcodes allow increased performance compared with 32-bit ARM code, as less program code may need to be loaded into the processor over the constrained memory bandwidth.
Embedded hardware, such as the Game Boy Advance, typically have a small amount of RAM accessible with a full 32-bit datapath; the majority is accessed via a 16-bit or narrower secondary datapath. In this situation, it usually makes sense to compile Thumb code and hand-optimise a few of the most CPU-intensive sections using full 32-bit ARM instructions, placing these wider instructions into the 32-bit bus accessible memory.
The first processor with a Thumb instruction decoder was the ARM7TDMI. All ARM9 and later families, including XScale, have included a Thumb instruction decoder.
Thumb-2.
"Thumb-2" technology was introduced in the "ARM1156 core", announced in 2003. Thumb-2 extends the limited 16-bit instruction set of Thumb with additional 32-bit instructions to give the instruction set more breadth, thus producing a variable-length instruction set. A stated aim for Thumb-2 was to achieve code density similar to Thumb with performance similar to the ARM instruction set on 32-bit memory. In ARMv7 this goal can be said to have been met.
Thumb-2 extends the Thumb instruction set with bit-field manipulation, table branches and conditional execution. At the same time, the ARM instruction set was extended to maintain equivalent functionality in both instruction sets. A new "Unified Assembly Language" (UAL) supports generation of either Thumb or ARM instructions from the same source code; versions of Thumb seen on ARMv7 processors are essentially as capable as ARM code (including the ability to write interrupt handlers). This requires a bit of care, and use of a new "IT" (if-then) instruction, which permits up to four successive instructions to execute based on a tested condition, or on its inverse. When compiling into ARM code, this is ignored, but when compiling into Thumb it generates an actual instruction. For example:
All ARMv7 chips support the Thumb instruction set. All chips in the Cortex-A series, Cortex-R series, and ARM11 series support both "ARM instruction set state" and "Thumb instruction set state", while chips in the Cortex-M series support only the Thumb instruction set.
Thumb Execution Environment (ThumbEE).
"ThumbEE" (erroneously called "Thumb-2EE" in some ARM documentation), marketed as (Runtime Compilation Target), was announced in 2005, first appearing in the "Cortex-A8" processor. ThumbEE is a fourth Instruction set state, making small changes to the Thumb-2 extended Thumb instruction set. These changes make the instruction set particularly suited to code generated at runtime (e.g. by JIT compilation) in managed "Execution Environments". ThumbEE is a target for languages such as Java, C#, Perl, and Python, and allows JIT compilers to output smaller compiled code without impacting performance.
New features provided by ThumbEE include automatic null pointer checks on every load and store instruction, an instruction to perform an array bounds check, and special instructions that call a handler. In addition, because it utilises Thumb-2 technology, ThumbEE provides access to registers r8-r15 (where the Jazelle/DBX Java VM state is held). Handlers are small sections of frequently called code, commonly used to implement high level languages, such as allocating memory for a new object. These changes come from repurposing a handful of opcodes, and knowing the core is in the new ThumbEE Instruction set state.
On 23 November 2011, ARM Holdings deprecated any use of the ThumbEE instruction set, and ARMv8 removes support for ThumbEE.
Floating-point (VFP).
"VFP" (Vector Floating Point) technology is an "FPU" (Floating-Point Unit) coprocessor extension to the ARM architecture (implemented differently in ARMv8 - coprocessors not defined there). It provides low-cost single-precision and double-precision floating-point computation fully compliant with the "ANSI/IEEE Std 754-1985 Standard for Binary Floating-Point Arithmetic". VFP provides floating-point computation suitable for a wide spectrum of applications such as PDAs, smartphones, voice compression and decompression, three-dimensional graphics and digital audio, printers, set-top boxes, and automotive applications. The VFP architecture was intended to support execution of short "vector mode" instructions but these operated on each vector element sequentially and thus did not offer the performance of true single instruction, multiple data (SIMD) vector parallelism. This vector mode was therefore removed shortly after its introduction, to be replaced with the much more powerful NEON Advanced SIMD unit.
Some devices such as the ARM Cortex-A8 have a cut-down "VFPLite" module instead of a full VFP module, and require roughly ten times more clock cycles per float operation. Pre-ARMv8 architecture implemented floating-point/SIMD with the coprocessor interface. Other floating-point and/or SIMD units found in ARM-based processors using the coprocessor interface include FPA, FPE, iwMMXt, some of which where implemented in software by trapping but could have been implemented in hardware. They provide some of the same functionality as VFP but are not opcode-compatible with it.
In Debian Linux and derivatives armhf (ARM hard float) refers to the ARMv7 architecture including the additional VFP3-D16 floating-point hardware extension (and Thumb-2) above.
Advanced SIMD (NEON).
The "Advanced SIMD" extension (aka "NEON" or "MPE" Media Processing Engine) is a combined 64- and 128-bit SIMD instruction set that provides standardized acceleration for media and signal processing applications. NEON is included in all Cortex-A8 devices but is optional in Cortex-A9 devices. NEON can execute MP3 audio decoding on CPUs running at 10 MHz and can run the GSM adaptive multi-rate (AMR) speech codec at no more than 13 MHz. It features a comprehensive instruction set, separate register files and independent execution hardware. NEON supports 8-, 16-, 32- and 64-bit integer and single-precision (32-bit) floating-point data and SIMD operations for handling audio and video processing as well as graphics and gaming processing. In NEON, the SIMD supports up to 16 operations at the same time. The NEON hardware shares the same floating-point registers as used in VFP. Devices such as the ARM Cortex-A8 and Cortex-A9 support 128-bit vectors but will execute with 64 bits at a time, whereas newer Cortex-A15 devices can execute 128 bits at a time.
 is ARM's first open source project (from its inception). The Ne10 library is a set of common, useful functions written in both NEON and C (for compatibility). The library was created to allow developers to use NEON optimizations without learning NEON but it also serves as a set of highly optimized NEON intrinsic and assembly code examples for common DSP, arithmetic and image processing routines. The code is available on .
Security extensions (TrustZone).
The Security Extensions, marketed as TrustZone Technology, is in ARMv6KZ and later application profile architectures. It provides a low-cost alternative to adding another dedicated security core to an SoC, by providing two virtual processors backed by hardware based access control. This lets the application core switch between two states, referred to as worlds (to reduce confusion with other names for capability domains), in order to prevent information from leaking from the more trusted world to the less trusted world. This world switch is generally orthogonal to all other capabilities of the processor, thus each world can operate independently of the other while using the same core. Memory and peripherals are then made aware of the operating world of the core and may use this to provide access control to secrets and code on the device.
Typical applications of TrustZone Technology are to run a rich operating system in the less trusted world, and smaller security-specialized code in the more trusted world (named TrustZone Software, a TrustZone optimised version of the Trusted Foundations Software developed by ), allowing much tighter digital rights management for controlling the use of media on ARM-based devices, and preventing any unapproved use of the device. Trusted Foundations Software was acquired by Gemalto. Giesecke & Devrient developed a rival implementation named Mobicore. In April 2012 ARM Gemalto and Giesecke & Devrient combined their TrustZone portfolios into a joint venture Trustonic. Open Virtualization and T6 are open source implementations of the trusted world architecture for TrustZone.
In practice, since the specific implementation details of TrustZone are proprietary and have not been publicly disclosed for review, it is unclear what level of assurance is provided for a given threat model.
No-execute page protection.
As of ARMv6, the ARM architecture supports no-execute page protection, which is referred to as "XN", for "eXecute Never".
Large Physical Address Extension.
The Large Physical Address Extension, which extends the physical address size from 32 bits to 40 bits, was added to the ARMv7-A architecture in 2011.
ARMv8-R.
The ARMv8-R sub-architecture, announced after the ARMv8-A, shares some features except that it is not 64-bit.
64/32-bit architecture.
ARMv8-A.
Announced in October 2011, ARMv8-A (often called ARMv8 although not all variants are 64-bit such as ARMv8-R) represents a fundamental change to the ARM architecture. It adds a 64-bit architecture, named "AArch64", and a new "A64" instruction set. AArch64 provides user-space compatibility with ARMv7-A ISA, the 32-bit architecture, therein referred to as "AArch32" and the old 32-bit instruction set, now named "A32". The Thumb instruction sets are referred to as "T32" and have no 64-bit counterpart. ARMv8-A allows 32-bit applications to be executed in a 64-bit OS, and a 32-bit OS to be under the control of a 64-bit hypervisor. ARM announced their Cortex-A53 and Cortex-A57 cores on 30 October 2012. Apple was the first to release an ARMv8-A compatible core (Apple A7) in a consumer product (iPhone 5S). AppliedMicro, using an FPGA, was the first to demo ARMv8-A. The first ARMv8-A SoC from Samsung is the Exynos 5433 in the Galaxy Note 4, which features two clusters of four Cortex-A57 and Cortex-A53 cores in a big.LITTLE configuration; but it will run only in AArch32 mode.
To both AArch32 and AArch64, ARMv8-A makes VFPv3/v4 and advanced SIMD (NEON) standard. It also adds cryptography instructions supporting AES and SHA-1/SHA-256.
ARMv8.1-A.
In December 2014, ARMv8.1-A, an update with "incremental benefits over v8.0", was announced. The enhancements fall into two categories:
Expected "product introductions mid-2015" with server CPU makers likely to adopt and Apple "will likely jump to the new architecture". "The incremental updates in ARMv8.1-A revolve around memory addressing, security, virtualization and throughput. ARMv8-A code will run on v8.1 cores."
Operating system support.
64-bit operating systems.
Windows applications can be recompiled to run on 32-bit or 64-bit ARM in Linux with Winelib.

</doc>
<doc id="60559" url="http://en.wikipedia.org/wiki?curid=60559" title="Emily Davison">
Emily Davison

Emily Wilding Davison (11 October 1872 – 8 June 1913) was a militant activist who fought for women's suffrage in Britain. She was jailed on nine occasions and force-fed 49 times. She is best known for stepping in front of King George V's horse Anmer at the Epsom Derby on 4 June 1913, suffering fatal injuries. Her funeral on 14 June 1913 was organised by the Women's Social and Political Union (WSPU). Thousands of suffragettes accompanied the coffin and tens of thousands of people lined the streets of London. After a service in Bloomsbury, her coffin was taken by train to the family grave in Morpeth, Northumberland.
Modern historians agree that Davison was trying to disturb the Derby in order to draw attention to her cause, rather than to commit suicide, and 2013 analysis of newsreel has supported the idea that Davison was reaching up to attach a scarf to the bridle of the King's horse. Analysis of newsreel also indicated that her position before she stepped out onto the track would have given her a clear view of the oncoming race, further countering the belief that she ran out in a haphazard way to kill herself.
Early life and education.
Davison was born in Blackheath, London, the daughter of Charles Davison (of Morpeth, Northumberland) and Margaret Davison (of Longhorsley, Northumberland). She had two sisters and a brother; also various half-siblings from her father's first marriage including a half-brother, retired naval captain Henry Jocelyn Davison, who gave evidence at her inquest.
She later attended Kensington High School and won a bursary to Royal Holloway College in 1891 to study literature and modern foreign languages. However, she was forced to drop out in January 1892 because her father died and her mother could not afford the fees of £30 a term. She then became a private governess before becoming a teacher in Edgbaston and Worthing, raising enough money to study Biology, Chemistry, English Language and Literature at St Hugh's College, Oxford. She obtained first-class honours in her final exams, though women were not at that time admitted to degrees at Oxford. Davison then began teaching the daughters of the Moorhouse family in Spratton, Northamptonshire.
Activism.
In 1906, Davison joined the Women's Social and Political Union (WSPU). Formed in 1903 by Emmeline Pankhurst, the WSPU brought together those who felt strongly that militant, confrontational tactics were needed in order to achieve women's suffrage. In 1908, Davison left her teaching post to dedicate herself completely to the movement. In the same year she entered the University of London examinations as an external candidate for a degree in Modern Foreign Languages.
She gained a reputation as a militant and violent campaigner. On her own initiative and without the approval of the WSPU, her actions developed from disrupting meetings to stone throwing and arson. She was arrested and imprisoned for various offences nine times, including a violent attack on a man she mistook for the Chancellor of the Exchequer, David Lloyd George. During many of these prison terms she went on hunger strike and was force-fed.
On 2 April 1911, the night of the 1911 census, Davison hid in a cupboard in St Mary Undercroft, the chapel of the Palace of Westminster, overnight so that on the census form she could legitimately give her place of residence that night as the "House of Commons". Census documents from the year 1911 state that Emily Wilding Davison was found "hiding in the crypt" in the Houses of Parliament. In 1999 a plaque to commemorate the event was set in place by Tony Benn MP.
In June 1912, near the end of a six-month sentence in Holloway Prison for arson, along with dozens of fellow suffragettes who objected to being force-fed, she threw herself down a 10-metre iron staircase. Her intention, as she wrote afterwards, was to stop the suffering of everyone else by carrying out this action. As a result she suffered severe head and spinal damage, causing discomfort for the remaining twelve months of her life.
Injury at Epsom Derby.
On 4 June 1913, Davison attended the Epsom Derby. As the race was underway, she ran on to the track and attempted to grab the bridle of Anmer, the horse owned by King George V. The horse collided with her and she fell to the ground, where she was trampled by its hoofs as it too fell. Meanwhile, the jockey, Herbert Jones, was thrown but had his foot caught in the stirrup. The horse did a somersault, got up, and resumed running the race, dragging the unconscious Jones before his foot came loose. Bystanders unsuccessfully attempted to revive both Davison and Jones, before they were carried off by ambulances.
Davison's purpose in attending the Derby is not clear. She had purchased a return rail ticket and a ticket to a suffragette dance later that day, both of which are now in the collection of the Women's Library in London, which suggests that martyrdom was not her intention. Although it later became clear it was the only type of rail ticket available for purchase, it is noted that she carefully kept the return half in her purse. Further evidence is a postcard she wrote to her sister Laetitia, who lived in France and to whom she was very close, which suggests she was going on holiday a few days after the Derby to visit her sister and her niece.
It is a possibility that she entered the race track in order to attach a flag to Anmer, so that when the horse crossed the finishing line, it would be flying the WSPU flag. According to police reports, two flags were found in her possession. Pathé News captured the incident on film. Film, taken at Tattenham Corner, shows Davison stepping out onto the racecourse just as the leading horses swept by. She was then seen standing in the middle of the racecourse as two more horses passed on the inside of her, and was then knocked to the ground by one of the last few trailing horses, the King's horse Anmer. The film is unclear, but it is possible that by this point she had taken the banner of the WSPU out from where it was concealed in her clothing, with the intention of attaching it to the horse. Eyewitnesses at the time were divided as to her motivation, with many feeling that she had simply intended to cross the track, believing that all horses had passed. Others reported that she had attempted to pull down the King's horse. It is sometimes suggested that a few weeks beforehand Davison and other suffragettes were "practising" grabbing horses in the park near her mother's house in Morpeth and that they drew straws to decide who should be the one to go to Epsom.
Horse racing historian Michael Tanner, in a 2011 TV interview at Epsom, pointed out that, as Davison was standing on the inside of the bend at Tattenham Corner amidst heaving crowds, and with no racetrack commentary as there is today, it would not have been possible to know whether the King's horse had already gone past. In addition, considering the speeds the horses were going, it would not have been possible for her to identify any particular horse even if she had meant to. This suggests that the fact it was the King's horse that she collided with was just a coincidence. Tanner later described the story of her "practising" with galloping horses and "drawing straws" as "folklore at best, pure hokum at worst," emphasising that "by 1913 Davison's modus operandi was acting alone – no one knew of her plans, in Morpeth or elsewhere."
The most recent theory is that she intended to throw a "Votes for Women" sash around the neck of the King's horse to gain publicity for her cause. A sash apparently found at the scene immediately after the collision was recently purchased at auction by author Barbara Gorna, the closest losing bidder being the Jockey Club, and now hangs in the Houses of Parliament. This theory received support from a 2013 examination of the incident, in which forensic experts examined and correlated footage captured by three different newsreel cameras, and determined that Davison was much closer to the start of the bend than had been previously assumed, and so would have had a much clearer view of the oncoming horses than previously thought. It concluded that Davison, who clearly carried in her hand something that could have been the folded "Votes for Women" sash as she ducked under a barrier and onto the course, did intend to attach it to the king's horse, and that there was no question of her deliberately throwing herself under the horse.
However, in his 2013 book "The Suffragette Derby", Tanner examined the provenance of this "sash", which is in fact a scarf, and found it wanting: its original owner, Richard Pittway Burton, was not Epsom's Clerk of the Course, as claimed, but an East End docker with no racing connection whatsoever. Nor, he argued, could the article in Davison's hand be safely identified as a scarf in the first place: the evidence was skewed to suit. In a letter to the "Racing Post" Tanner went on to deplore the reiteration of "several myths" attached to Davison that he had debunked in his book, and expressed deep reservations about the film footage analysis, stressing once more that "from her position wedged tight against the rail, Davison would need to have been on a 20-foot ladder to have seen over the heads of the people to her right and then the leading bunch of nine horses to single out the figure of Anmer hidden behind... she was already ducking under the rail as the first horses passed and had missed two-thirds of the field altogether – which for all she knew may have included Anmer. It was pure chance that she stumbled upon Anmer."
Death.
Davison died four days later in Epsom Cottage Hospital due to a fractured skull and internal injuries caused by the incident. Jones suffered a mild concussion, but allegedly was "haunted by that poor woman's face" for much longer. In 1928, at the funeral of Emmeline Pankhurst, Jones laid a wreath "to do honour to the memory of Mrs Pankhurst and Miss Emily Davison". However, Tanner rejects both this and the inference that the Epsom incident contributed to the jockey's suicide in 1951, having interviewed both of Jones's children for his book: "Their father killed himself 38 years later following the death of his wife and a loneliness brought on by deafness."
Commemoration.
Davison is buried in the churchyard of St. Mary the Virgin, Morpeth, Northumberland, in a family plot where her father was buried (he died 1893). The cemetery is about 7 miles south of Longhorsley, where she had lived with her mother and family. A memorial service, which attracted a great crowd, was held at St. George's church in London on 14 June 1913. Her coffin was brought by train to Morpeth for burial on 15 June. Her gravestone bears the WSPU slogan, "Deeds not words."
On 18 April 2013, a plaque was unveiled at Epsom racecourse to mark the centenary of the death. An Emily Wilding Davison Memorial Campaign was also established ahead of the centenary to campaign for a minute's silence at the 2013 Epsom Derby. However, the campaign failed after the racecourse said that this would be "logistically impossible".
Legacy.
Like other acts of suffragette militancy, Davison’s actions divided public opinion, some admiring her courage, others decrying the disruption of sport, the injury to jockey Herbert Jones, and the slight to the King.
But the direct consequence was to galvanise male political support for suffrage, in the form of the Northern Men's Federation for Women's Suffrage. This initially took the form of a deputation to the Prime Minister Asquith; when this was rebuffed, it became a standing organisation. Its president was the former actress Maud Arncliffe-Sennett. It was mainly composed of town councillors, ministers, lawyers and similar civic figures from Glasgow and Edinburgh, and had little following beyond central Scotland, even in Davison’s Northumberland.
Beyond the Federation it is difficult to distinguish Davison's effect from that of the broader militant tradition in Britain, which continued until the political landscape was changed by the outbreak of World War I.
Emily Davison is the subject of an opera, "Emily" (2013), by the British composer Tim Benjamin. She is also the subject of a song by American rock singer Greg Kihn, whose elegy "Emily Davison" is included on his first album, 1976's "Greg Kihn". 
In 2014, English folk singer, Maz O'Connor, released a track "Derby Day" viewing events as if she were a young boy watching the race while sitting on his father's shoulders. The track is included on her album, "This Willowed Light"

</doc>
<doc id="60560" url="http://en.wikipedia.org/wiki?curid=60560" title="Tetrapod">
Tetrapod

The superclass Tetrapoda (Ancient Greek τετραπόδηs tetrapodēs, "four-footed"), or the tetrapods , comprises the first four-limbed vertebrates and their descendants, including the living and extinct amphibians, reptiles, mammals , and birds. Tetrapods evolved from the lobe-finned fishes about 395 million years ago in the Devonian Period. The specific aquatic ancestors of the tetrapods, and the process by which land colonization occurred, remain unclear, and are areas of active research and debate among palaeontologists at present.
While most species today are terrestrial, the first tetrapods were fully aquatic. Amphibians today generally remain semiaquatic, living the first stage of their lives as fish-like tadpoles. Amniotes evolved about 340 million years ago (crown amniotes 318 mya), and their descendants drove most amphibians to extinction. One population of amniotes diverged into lizards, dinosaurs, birds and their relatives, while another diverged into mammals and their extinct relatives. Several groups of tetrapods, such as the snakes and cetaceans, have lost some or all of their limbs. In addition, many tetrapods have returned to partially aquatic or fully aquatic lives throughout the history of the group (modern examples of fully aquatic tetrapods include cetaceans and sirenians). The first returns to an aquatic lifestyle may have occurred as early as the Carboniferous Period, whereas other returns occurred as recently as the Cenozoic, as in cetaceans, pinnipeds, and several modern amphibians.
The change from a body plan for breathing and navigating in water to a body plan enabling the animal to move on land is one of the most profound evolutionary changes known. It is also becoming increasingly well-understood as a result of more transitional fossil finds and improved phylogenetic analysis.
Definitions.
Tetrapods can be defined in cladistics as the nearest common ancestor of all living amphibians (the lissamphibians) and all living amniotes (reptiles, birds, and mammals), along with all of the descendants of that ancestor. This is a node-based definition (the node being the nearest common ancestor). The group so defined is the crown group, or crown tetrapods. The term tetrapodomorph is used for the stem-based definition: any animal that is more closely related to living amphibians, reptiles, birds, and mammals than to living dipnoi (lungfishes). The group so defined is known as the tetrapod total group.
The definition from paleontology, although more widely used than the cladistic definition, is complex and requires some explanation. Biologists are intensely interested in the question of how the ancestors of amphibians, reptiles, birds, and mammals evolved from fish into animals that can live on land. By the time of the nearest common ancestor (the first crown tetrapod), the transition was largely complete. Thus, the node-based definition is too recent. The stem-based definition has the opposite problem: it goes back too far, to fish with fins showing no signs of sprouting legs. Paleontologists seek an intermediate definition of tetrapod, one that begins at the beginning of the transition to life on land. Unfortunately, the beginning of this transition lies in the middle of a large fossil gap. Thus, paleontologists seek to identify traits in early tetrapods that can be compared with corresponding traits in their fish ancestors to determine which traits are key.
Among the traits that have been considered and rejected because they arose either too early or too late: lungs and the ability to breathe air (far too early), tympanic hearing and the ability to hear high-frequency sounds (far to late), a stiff spine, enabling an animal to walk on land without dragging its body on the ground (a little too late), the evolution of the neck, with the shoulder-girdle attaching to the spine instead of head (also a little too late). For other traits, the order in which the traits evolved is not known. For this reason, the provisional definition proposed by paleontologist Jennifer Clack has gained considerable acceptance: "an animal with four legs bearing digits" (e.g., fingers and toes). This definition is intended to apply only to members of the clade tetrapodomorph, as opposed to the ray-finned fishes, many of which have four legs bearing digits (the Sargassum fish for example).
Biodiversity.
Tetrapoda includes four classes: amphibians, reptiles, mammals, and birds. Overall, the biodiversity of lissamphibians, as well as of tetrapods generally, has grown exponentially over time; the more than 30,000 species living today are descended from a single amphibian group in the Early to Middle Devonian. However, that diversification process was interrupted at least a few times by major biological crises, such as the Permian–Triassic extinction event, which at least affected amniotes. The overall composition of biodiversity was driven primarily by amphibians in the Palaeozoic, dominated by reptiles in the Mesozoic and expanded by the explosive growth of birds and mammals in the Cenozoic. As biodiversity has grown, so has the number of niches that tetrapods have occupied. The first tetrapods were aquatic and fed primarily on fish. Today, the Earth supports a great diversity of tetrapods that live in many habitats and subsist on a variety of diets.
Evolution.
Origin.
Tetrapods evolved from early bony fishes (Osteichthyes), specifically lobe-finned fish (Sarcopterygii), living in freshwater and brackish environments at the beginning of the Devonian period. These fish had many features in common with their cartilaginous ancestors, but also important differences, most notably a swim bladder/lung, a feature lacking in sharks and rays.
The lung/swim bladder originated as an outgrowth of the gut, forming a gas-filled bladder above the digestive system. The primary function of this organ in its primitive form is not entirely certain. It was probably used as a lung for breathing air, but it may have been used for buoyancy instead, or both functions may have been important.
Fleshy lobe-fins supported on bones seem to have been an ancestral trait of all bony fishes (Osteichthyes). The ancestors of the ray-finned fishes (Actinopterygii) evolved their fins in a different direction and developed a swim bladder dedicated to controlling buoyancy. The Tetrapodomorph ancestors of the Tetrapods retained a lung-like swim bladder and further developed their lobe fins. The paired fins had bones distinctly homologous to the humerus, ulna, and radius in the fore-fins and to the femur, tibia, and fibula in the pelvic fins.
While most Tetrapodomorphs were open-water fishes, one group, the Elpistostegalians, adapted to life in the shallows. They evolved flat bodies for movement in very shallow water, and the pectoral and pelvic fins took over as the main propulsion organs. Since the shallows were subject to occasional oxygen deficiency, the ability to breath atmospheric air with the swim bladder became increasingly important.
The first tetrapods probably evolved in the Emsian stage of the Early Devonian from Tetrapodomorph fish living in shallow water environments.
The very earliest tetrapods would have been animals similar to "Acanthostega", with legs and lungs as well as gills, but still primarily aquatic and unsuited to life on land.
Palaeozoic tetrapods.
Devonian tetrapods.
Tetrapods first appeared in the early Devonian period. These early tetrapods would have been animals similar to "Ichthyostega", with legs and lungs as well as gills, but still primarily aquatic and unsuited to life on land. The Devonian tetrapods went through two major bottlenecks during what is known as the Late Devonian extinction. These extinction events led to the disappearance of primitive tetrapods with fish-like features. When tetrapods reappear in the fossil record in early Carboniferous deposits, some 20 million years later, the adult forms are all fully adapted to a terrestrial existence. Why they went to land in the first place is still debated.
Carboniferous tetrapods.
During the early Carboniferous, the number of digits on hands and feet became standardized at five, as lineages with more digits died out. By mid-Carboniferous times, the early tetrapods had radiated into at least three main branches. Modern amphibians are derived from the either the temnospondyls or the lepospondyls (or possibly both), whereas the anthracosaurs were the relatives and ancestors of the amniotes.
The first amniotes are known from the early part of the Late Carboniferous. Amphibians must return to water to lay eggs; in contrast, amniote eggs have a membrane ensuring gas exchange out of water and can therefore be laid on land.
A reptile is defined as any amniote that is neither a mammal nor a bird, so these early amniotes were primitive reptiles.
Amphibians and reptiles were affected by the Carboniferous Rainforest Collapse (CRC), an extinction event that occurred ~300 million years ago. The sudden collapse of a vital ecosystem shifted the diversity and abundance of major groups. Reptiles were more suited to the new conditions. They invaded new ecological niches and began diversifying their diets to include plants and other tetrapods, previously having been limited to insects and fish.
Permian tetrapods.
In the Permian period, in addition to temnospondyl and anthracosaur clades, there were two important clades of amniotes, the sauropsids and the synapsids. The latter were the most important and successful Permian animals.
The end of the Permian saw a major turnover in fauna during the Permian–Triassic extinction event. There was a protracted loss of species, due to multiple extinction pulses. Many of the once large and diverse groups died out or were greatly reduced.
Mesozoic tetrapods.
The diapsids (a subgroup of the sauropsids) began to diversify during the Triassic, leading to the turtles, crocodiles and dinosaurs. In the Jurassic, birds first appeared as a derived clade of theropod dinosaurs, and lizards developed from other diapsids. In the Cretaceous, snakes developed from lizards.
By the late Mesozoic, the large labyrinthodont groups that first appeared during the Paleozoic such as temnospondyls and reptile-like amphibians had gone extinct. Many groups of synapsids, such as anomodonts and therocephalians, that once comprised the dominant terrestrial fauna of the Permian also became extinct during the Mesozoic; however, during the Triassic one group (Cynodontia) gave rise to the mammals, which survived through the Mesozoic to later diversify during the Cenozoic.
Extant (living) tetrapods.
Following the great faunal turnover at the end of the Mesozoic, only six major groups of tetrapods were left, all of which also include many extinct groups:
Classification.
The classification of tetrapods has a long history. Traditionally, tetrapods are divided into four classes based on gross anatomical and physiological traits. Snakes and other legless reptiles are considered tetrapods because they are sufficiently like other reptiles that have a full complement of limbs. Similar considerations apply to caecilians and aquatic mammals. Newer taxonomy is frequently based on cladistics instead, giving a variable number of major "branches" (clades) of the tetrapod family tree.
As is the case throughout evolutionary biology today, there is debate over how to properly classify the groups within Tetrapoda. Traditional biological classification recognizes evolutionary transitions between older groups and descendant groups with markedly different characteristics. For example, the birds, which evolved from the dinosaurs, are defined as a separate group from them, because they represent a distinct new type of physical form and functionality. In phylogenetic nomenclature, in contrast, the newer group is always included in the old. For this school of taxonomy, dinosaurs and birds are not groups in contrast to each other, but rather birds are a sub-type "of" dinosaurs.
History of classification.
The tetrapods, including all large- and medium-sized land animals, have been among the best understood animals since earliest times. By Aristotle's time, the basic division between mammals, birds and egg-laying tetrapods (the "herptiles") was well known, and the inclusion of the legless snakes into this group was likewise recognized. With the birth of modern biological classification in the 18th century, Linnaeus used the same division, with the tetrapods occupying the first three of his six classes of animals. While reptiles and amphibians can be quite similar externally, the French zoologist Pierre André Latreille recognized the large physiological differences at the beginning of the 19th century and split the herptiles into two classes, giving the four familiar classes of tetrapods: amphibians, reptiles, birds and mammals.
Modern classification.
With the basic classification of tetrapods settled, a half a century followed where the classification of living and fossil groups was predominately done by experts working within classes. In the early 1930s, American vertebrate palaeontologist Alfred Romer (1894–1973) produced an overview, drawing together taxonomic work from the various subfields to create an orderly taxonomy in his "Vertebrate Paleontology". This classical scheme with minor variations is still used in works where systematic overview is essential, e.g. Benton (1998) and Knobill and Neill (2006). While mostly seen in general works, it is also still used in some specialist works like Fortuny & al. (2011). The taxonomy down to subclass level shown here is from Hildebrand and Goslow (2001):
This classification is the one most commonly encountered in school textbooks and popular works. While orderly and easy to use, it has come under critique from cladistics. The earliest tetrapods are grouped under Class Amphibia, although several of the groups are more closely related to amniotes than to modern day amphibians. Traditionally, birds are not considered a type of reptile, but crocodiles are more closely related to birds than they are to other reptiles, such as lizards. Birds themselves are thought to be descendents of theropod dinosaurs. Basal non-mammalian synapsids ("mammal-like reptiles") traditionally also sort under Class Reptilia as a separate subclass, but they are more closely related to mammals than to living reptiles. Considerations like these have led some authors to argue for a new classification based purely on phylogeny, disregarding the anatomy and physiology.
Phylogeny of early tetrapod diversification.
Cladogram modified after Ruta, Jeffery & Coates (2003).
All branches are extinct except for Lissamphibia (all modern amphibians) and Amniota (all reptiles, birds, and mammals).
Anatomical features of early tetrapods.
The tetrapod's ancestral fish, tetrapodomorph, possessed similar traits to those inherited by the early tetrapods, including internal nostrils and a large fleshy fin built on bones that could give rise to the tetrapod limb. Their palatal and jaw structures were identical to those of early tetrapods, and their dentition was identical too, with labyrinthine teeth fitting in a pit-and-tooth arrangement on the palate. The paired fins of the early sarcopterygians were smaller than tetrapod limbs, but the skeletal structure was very similar in that the early sarcopterygians had a single proximal bone (analogous to the humerus or femur), two bones in the next segment (forearm or lower leg), and an irregular subdivision of the fin, roughly comparable to the structure of the carpus / tarsus and phalanges of a hand.
The major difference between early sarcopterygians and early tetrapods was in the relative development of the front and back skull portions; the snout is much less developed than in most early tetrapods and the post-orbital skull is exceptionally longer than an amphibian's.
A great many kinds of early tetrapods lived during the Carboniferous period. Therefore, their ancestor would have lived earlier, during the Devonian period. Devonian ichthyostegans were among the earliest of the tetrapods, with a skeleton that is directly comparable to that of rhipidistian ancestors. Early temnospondyls (Late Devonian to Early Mississippian) still had some ichthyostegid features, such as similar skull bone patterns, labyrinthine tooth structure, the fish skull-hinge, pieces of gill structure between the cheek and shoulder, and the vertebral column. They had, however, lost several other fish features, such as the fin rays in the tail.
To propagate in the terrestrial environment, animals had to overcome certain challenges. Their bodies needed additional support, because buoyancy was no longer a factor. They needed a new method of respiration to extract atmospheric oxygen, instead of oxygen dissolved in water. Animals had to develop new means of locomotion to traverse distances between waterholes. Water retention was now important, since it was no longer the living matrix, and could be lost easily to the environment. Finally, animals needed new sensory input systems to have any ability to function reasonably on land.
Skull.
The most notable characteristics that make a tetrapod's skull different from a fish's are the relative frontal and rear portion lengths. The fish had a long rear portion while the front was short; the orbital vacuities were thus located towards the anterior end. In the tetrapod, the front of the skull lengthened, positioning the orbits farther back on the skull. The lacrimal bone was no longer in contact with the frontal, having been separated from it by the prefrontal bone. Also of importance is that the skull was now free to rotate from side to side, independent of the spine, on the newly forming neck.
A diagnostic character of temnospondyls is that the tabular bones (which formed the posterior corners of the skull-table) were separated from the respective left and right parietals by a sutural junction between the postparietals and supratemporals. Also, at the rear of the skull, all bones dorsal to the cleithrum were lost.
The lower jaw of, for example, "Eryops" resembled its early sarcopterygians ancestors in that on the outer surface lay a long dentary that bore teeth. There were also bones below the dentary on the jaw: two splenials, the angular and the surangular. On the inside were usually three coronoids that bore teeth and lay close to the dentary. On the upper jaw was a row of marginal labyrinthine teeth, located on the maxilla and premaxilla. In "Eryops", as in all early amphibians, the teeth were replaced in waves that traveled from the front of the jaw to the back in such a way that every other tooth was mature, and the ones in between were young.
Dentition.
The "labyrinthodonts" had a peculiar tooth structure, from which their name derives—and though not exclusive to the group, the labyrinthine dentition is a useful indicator as to proper classification. The important feature of the tooth is that the enamel and dentine fold into a complicated corrugated pattern when viewed in cross section. This infolding strengthened the tooth and increased wear resistance. Such teeth survived for 100 Ma, first among crossopterygian fish, then stem reptiles. Modern amphibians no longer have this type of dentition, but rather pleurodont teeth, in fewer numbers of the whole group.
Sensory organs.
The difference in density between air and water causes smells (certain chemical compounds detectable by chemoreceptors) to behave differently. An animal first venturing out onto land would have difficulty in locating such chemical signals if its sensory apparatus was designed for aquatic detection.
Fish have a lateral line system that detects pressure fluctuations in the water. Such pressure is non-detectable in air, but grooves for the lateral line sense organs were found on the skull of labyrinthodonts, suggesting a partially aquatic habitat. Modern amphibians, which are semi-aquatic, exhibit this feature whereas it has been retired by the higher vertebrates. The olfactory epithelium would also have to change to detect airborne odors.
In addition to the lateral line organ system, the eye had to change. This change came about because the refractive index of light differs between air and water, so the focal length of the lens altered to function in air. The eye was now exposed to a relatively dry environment rather than being bathed by water, so eyelids developed and tear ducts evolved to produce a liquid to moisten the eyeball.
Hearing.
Animals retained the balancing function of the middle ear from fish ancestry. However, delicate air vibrations could not set up pulsations through the skull as in a proper auditory organ. Typical of most labyrinthodonts, the spiracular gill pouch was retained as the otic notch, closed in by the tympanum, a thin, tight membrane.
The hyomandibula of fish migrated upwards from its jaw supporting position, and was reduced in size to form the stapes. Situated between the tympanum and braincase in an air-filled cavity, the stapes was now capable of transmitting vibrations from the exterior of the head to the interior. Thus the stapes became an important element in an impedance matching system, coupling airborne sound waves to the receptor system of the inner ear. This system had evolved independently within several different amphibian lineages.
The impedance matching ear had to meet certain conditions to work. The stapes had to be perpendicular to the tympanum, small and light enough to reduce its inertia, and suspended in an air-filled cavity. In modern species that are sensitive to over 1 kHz frequencies, the footplate of the stapes is 1/20th the area of the tympanum. However, in early amphibians the stapes was too large, making the footplate area oversized, preventing the hearing of high frequencies. So it appears they could only hear high intensity, low frequency sounds—and the stapes more probably just supported the brain case against the cheek.
Girdles.
The pectoral girdle of early tetrapods, such as "Eryops", was highly developed, with a larger size for both increased muscle attachment to it and to the limbs. Most notably, the shoulder girdle was disconnected from the skull, resulting in improved terrestrial locomotion. The early sarcopterygians cleithrum was retained as the clavicle, and the interclavicle was well-developed, lying on the underside of the chest. In primitive forms, the two clavicles and the interclavical could have grown ventrally in such a way as to form a broad chest plate, although such was not the case in "Eryops". The upper portion of the girdle had a flat, scapular blade, with the glenoid cavity situated below performing as the articulation surface for the humerus, while ventrally there was a large, flat coracoid plate turning in toward the midline.
The pelvic girdle also was much larger than the simple plate found in fishes, accommodating more muscles. It extended far dorsally and was joined to the backbone by one or more specialized sacral ribs. The hind legs were somewhat specialized in that they not only supported weight, but also provided propulsion. The dorsal extension of the pelvis was the ilium, while the broad ventral plate was composed of the pubis in front and the ischium in behind. The three bones met at a single point in the center of the pelvic triangle called the acetabulum, providing a surface of articulation for the femur.
The main strength of the ilio-sacral attachment of "Eryops" was by ligaments, a condition structurally, but not phylogenetically, intermediate between that of the most primitive embolomerous amphibians and early reptiles. The condition that is more usually found in higher vertebrates is that cartilage and the fusion of the sacral ribs to the blade of the ilium are utilized in addition to ligamentous attachments.
Limbs.
The humerus was the largest bone of the arm, its head articulating with the glenoid cavity of the pectoral girdle, distally with the radius and ulna. The radius resided on the inner side of the forearm and rested directly under the humerus, supporting much of the weight, while the ulna was located to the outside of the humerus. The ulna had a head, which muscles pulled on to extend the limb, called the olecranon that extended above the edge of the humerus.
The radius and the ulna articulated with the carpus, which was a proximal row of three elements: the radiale underlying the radius, the ulnare underneath the ulna and an intermedium between the two. A large central element was beneath the last and may have articulated with the radius. There were also three smaller centralia lying to the radial side. Opposite the head of each toe lay a series of five distal carpals. Each digit had a first segment, the metacarpal, lying in the palm region.
The pelvic limb bones were essentially the same as in the pectoral limb, but with different names. The analogue to the humerus was the femur, which was longer and slimmer. The two lower arm bones corresponded to the tibia and fibula of the hind leg, the former being the innermost and the latter the outermost bones. The tarsus is the hind version of the carpus and its bones correspond as well.
Locomotion.
In typical early tetrapod posture, the upper arm and upper leg extended nearly straight horizontal from its body, and the forearm and the lower leg extended downward from the upper segment at a near right angle. The body weight was not centered over the limbs, but was rather transferred 90 degrees outward and down through the lower limbs, which touched the ground. Most of the animal's strength was used to just lift its body off the ground for walking, which was probably slow and difficult. With this sort of posture, it could only make short broad strides. This has been confirmed by fossilized footprints found in Carboniferous rocks.
Feeding.
Early tetrapods had a wide gaping jaw with weak muscles to open and close it. In the jaw were fang-like palatal teeth that, when coupled with the gape, suggests an inertial feeding habit. This is when the amphibian would grasp the prey and, lacking any chewing mechanism, toss the head up and backwards, throwing the prey farther back into the mouth. Such feeding is seen today in the crocodile and alligator. A study of these jaws shows that they were used for feeding underwater, not on land. As it is taken that early tetrapods were not very active, this suggests that they were not predatory. It is more likely that they fed on fish either in the water or on those that became stranded at the margins of lakes and swamps.
The tongue of modern adult amphibians is quite fleshy and attached to the front of the lower jaw, so it is reasonable to speculate that it was fastened in a similar fashion in primitive forms, although it was probably not specialized like it is in a frog.
Respiration.
Modern amphibians breathe by inhaling air into lungs, where oxygen is absorbed. They also breathe through the moist lining of the mouth and skin, known as cutaneous respiration. "Eryops" also inhaled, but its ribs were too closely spaced to suggest that it did this by expanding the rib cage. More likely, it breathed by buccal pumping in which it opened its mouth and nostrils, depressed the hyoid apparatus to expand the oral cavity, closed its mouth and nostrils finally and elevated the floor of the mouth to force air back into the lungs — in other words, it gulped, then swallowed. It probably exhaled by contraction of the elastic tissue in the lung walls. Other special respiratory methods probably existed.
Circulation.
Early tetrapods probably had a three-chambered heart, as do modern amphibians and reptiles, in which oxygenated blood from the lungs and de-oxygenated blood from the respiring tissues enters by separate atria, and is directed via a spiral valve to the appropriate vessel — aorta for oxygenated blood and pulmonary vein for deoxygenated blood. The spiral valve is essential to keeping the mixing of the two types of blood to a minimum, enabling the animal to have higher metabolic rates, and be more active than otherwise.
Ligamentous attachments within the limbs were present in "Eryops", being important because they were the precursor to bony and cartilaginous variations seen in modern terrestrial animals that use their limbs for locomotion.
Of all body parts, the spine was the most affected by the move from water to land. It now had to resist the bending caused by body weight and had to provide mobility where needed. Previously, it could bend along its entire length. Likewise, the paired appendages had not been formerly connected to the spine, but the slowly strengthening limbs now transmitted their support to the axis of the body.

</doc>
<doc id="60562" url="http://en.wikipedia.org/wiki?curid=60562" title="Redlining">
Redlining

Redlining is the practice of, in the United States, denying, or charging more for, services such as banking, insurance, access to health care, or even supermarkets, or denying jobs to residents in particular, often racially determined, areas. The term "redlining" was coined in the late 1960s by John McKnight, a sociologist and community activist. It refers to the practice of marking a red line on a map to delineate the area where banks would not invest; later the term was applied to discrimination against a particular group of people (usually by race or sex) irrespective of geography. 
During the heyday of redlining, the areas most frequently discriminated against were black inner city neighborhoods. For example, in Atlanta in the 1980s, a Pulitzer Prize-winning series of articles by investigative-reporter Bill Dedman showed that banks would often lend to lower-income whites but not to middle- or upper-income blacks. The use of blacklists is a related mechanism also used by redliners to keep track of groups, areas, and people that the discriminating party feels should be denied business or aid or other transactions. In the academic literature, redlining falls under the broader category of credit rationing.
Reverse redlining occurs when a lender or insurer targets minority consumers, not to deny them loans or insurance, but rather to charge them more than could be charged to a comparable majority consumer whose business is more sought after.
History.
Although informal discrimination and segregation had existed in the United States, the specific practice called "redlining" began with the National Housing Act of 1934, which established the Federal Housing Administration (FHA). Racial segregation and discrimination against minorities and minority communities pre-existed this policy. The decay of minority inner city neighborhoods from withheld mortgage capital and difficulty for neighborhoods to attract and retain families able to purchase homes was aggravated by the implementation of this federal policy. In 1935, the Federal Home Loan Bank Board (FHLBB) asked Home Owners' Loan Corporation (HOLC) to look at 239 cities and create "residential security maps" to indicate the level of security for real-estate investments in each surveyed city. Such maps defined many minority neighborhoods in cities as ineligible to receive financing. The maps were based on assumptions about the community, not accurate assessments of an individual's or household's ability to satisfy standard lending criteria. Since African Americans were unwelcome in white neighborhoods, which frequently instituted racial restrictive covenants to keep them out, the policy effectively meant that blacks could not secure mortgage loans at all. At various times the practice also affected other ethnic groups, including Jews, Latinos, and Asians. 
The assumptions in redlining resulted in a large increase in residential racial segregation and urban decay in the United States. Urban planning historians theorize that the maps were used by private and public entities for years afterwards to deny loans to people in black communities. But, recent research has indicated that the HOLC did not redline in its own lending activities, and that the racist language reflected the bias of the private sector and experts hired to conduct the appraisals.
On the maps, the newest areas — those considered desirable for lending purposes — were outlined in blue and known as "Type A". These were typically affluent suburbs on the outskirts of cities. "Type B" neighborhoods were considered "Still Desirable", whereas older "Type C" were labeled "Declining" and outlined in yellow.
"Type D" neighborhoods were outlined in red and were considered the most risky for mortgage support. These neighborhoods tended to be the older districts in the center of cities; often they were also black neighborhoods.
Some redlined maps were also created by private organizations, such as J.M. Brewer's 1934 map of Philadelphia. Private organizations created maps designed to meet the requirements of the Federal Housing Administration's underwriting manual. The lenders had to consider FHA standards if they wanted to receive FHA insurance for their loans. FHA appraisal manuals instructed banks to steer clear of areas with "inharmonious racial groups", and recommended that municipalities enact racially restrictive zoning ordinances, as well as covenants prohibiting black owners.
Urban disinvestment.
Following a National Housing Conference in 1973, a group of Chicago community organizations led by The Northwest Community Organization (NCO) formed National People's Action (NPA), to broaden the fight against disinvestment and mortgage redlining in neighborhoods all over the country.
This organization, led by Chicago housewife Gale Cincotta and Shel Trapp, a professional community organizer, targeted The Federal Home Loan Bank Board, the governing authority over Federally chartered Savings & Loan institutions (S&L) that held at that time the bulk of the country's home mortgages. NPA embarked on an effort to build a national coalition of urban community organizations to pass a national disclosure regulation or law to require banks to reveal their lending patterns.
For many years, urban community organizations had battled neighborhood decay by attacking blockbusting, forcing landlords to maintain properties, and requiring cities to board up and tear down abandoned properties. These actions addressed the short-term issues of neighborhood decline. Neighborhood leaders began to learn that these issues and conditions were symptoms of a disinvestment that was the true, though hidden underlying cause of these problems. They changed their strategy as more data was learned.
With the help of NPA, a coalition of loosely affiliated community organizations began to form. At the Third Annual Housing Conference held in Chicago in 1974, eight hundred delegates representing 25 states and 35 cities attended. The strategy focused on the Federal Home Loan Bank Board (FHLBB), which oversaw S&L's in cities all over the country. 
In 1974 Chicago's Metropolitan Area Housing Association (MAHA), made up of representatives of local organizations, succeeded in having the Illinois State Legislature pass laws mandating disclosure and outlawing redlining. In Massachusetts, organizers allied with NPA confronted a unique situation. Over 90% of home mortgages were held by state-chartered savings banks. A Jamaica Plain neighborhood organization pushed the disinvestment issue into the statewide gubernatorial race. The Jamaica Plain Banking & Mortgage Committee and its citywide affiliate, The Boston Anti-redlining Coalition (BARC), won a commitment from Democratic candidate Michael S. Dukakis to order state-wide disclosure through the Massachusetts State Banking Commission. After Dukakis was elected, his new Banking Commissioner ordered banks to disclose mortgage-lending patterns by zip code. The suspected redlining was revealed.
NPA and its affiliates achieved disclosure of lending practices with the passage of The Home Mortgage Disclosure Act of 1975. The required transparency and review of loan practices began to change lending practices. NPS began to work on reinvestment in areas that had been neglected. Their support helped gain passage in 1977 of the "Community Reinvestment Act".
Impact.
Redlining paralyzed the housing market, lowered property values in certain areas and encouraged landlord abandonment. As abandonment increased, the population density became lower. Abandoned buildings served as havens for drug dealing and other illegal activity, increasing social problems and reluctance of people to invest in these areas.
The film "Revolution '67" examines the practice of redlining that occurred in Newark, New Jersey in the 1960s.
Challenges.
In the United States, the Fair Housing Act of 1968 was passed to fight the practice. It prohibited redlining when the criteria are based on race, religion, sex, familial status, disability, or ethnic origin. The Office of Fair Housing and Equal Opportunity was tasked with administering and enforcing this law. Anyone who suspects that their neighborhood has been redlined is able to file a housing discrimination . The Community Reinvestment Act of 1977 further required banks to apply the same lending criteria in all communities. Although open redlining was made illegal in the 70s through community reinvestment legislation, the practice may have continued in less overt ways. AIDS activists allege redlining of health insurance against the LGBT community in response to the AIDS crisis.
ShoreBank, a community-development bank in Chicago's South Shore neighborhood, was a part of the private-sector fight against redlining. Founded in 1973, ShoreBank sought to combat racist lending practices in Chicago's African-American communities by providing financial services, especially mortgage loans, to local residents. In a 1992 speech, then-Presidential candidate Bill Clinton called ShoreBank "the most important bank in America." On August 20, 2010, the bank was declared insolvent, closed by regulators and most of its assets were acquired by Urban Partnership Bank.
Current issues.
Dan Immergluck writes that in 2002 small businesses in black neighborhoods received fewer loans, even after accounting for business density, business size, industrial mix, neighborhood income, and the credit quality of local businesses. Gregory D. Squires wrote in 2003 that data showed that race continues to affect the policies and practices of the insurance industry. Workers living in American inner cities have more difficulty finding jobs than do suburban workers. Redlining has helped preserve segregated living patterns for blacks and whites in the United States, as discrimination is often contingent on the racial composition of neighborhoods and the race of the applicant. Lending institutions such as Wells Fargo have been shown to treat black mortgage applicants differently when they are buying homes in white neighborhoods than when buying homes in black neighborhoods.
Mortgages.
Reverse redlining occurs when a lender or insurer particularly targets minority consumers, not to deny them loans or insurance, but to charge them more than would be charged to a similarly situated majority consumer, specifically marketing the most expensive and onerous loan products. These communities had largely been ignored by most lenders just a couple of decades earlier. In the 2000s some financial institutions considered black communities as suitable for subprime mortgages. Wells Fargo partnered with churches in black communities, where the pastor would deliver "wealth building" seminars in their sermons, and the bank would make a donation to the church in return for every new mortgage application. Working-class blacks wanted a part of the nation’s home-owning trend.
A survey of two districts of similar incomes, one being largely white and the other largely black, found that bank branches in the black community offered largely subprime loans and almost no prime loans. Studies found out that high-income blacks were almost twice as likely to end up with subprime home-purchase mortgages as did low-income whites. Some loan officers referred to blacks as “mud people” and to subprime lending as “ghetto loans.” A lower savings rate and a distrust of banks, stemming from a legacy of redlining, may help explain why there are fewer branches in minority neighborhoods. In the early 21st century, brokers and telemarketers actively pushed subprime mortgages. A majority of the loans were refinance transactions, allowing homeowners to take cash out of their appreciating property or pay off credit card and other debt.
Several state attorney generals have begun investigating these practices, which may violate fair lending laws. The NAACP filed a class-action lawsuit charging systematic racial discrimination by more than a dozen banks.
Redlining Property Type. Other forms of redlining include the nullification of mortgage loans based on internal bank policies and procedures that fail to recognize complex property types. Co-Op and condo conversions in New York City are one such example. These building types are often made up of legacy rent-controlled and rent-stabilized units or may contain another protected class of tenant. Lenders who practice redlining often cite "sponsor concentration" or "high rental concentration" as an excuse to redline the property type. Such internal policies run counter to state and municipal laws and statutes.
Retail.
Retail redlining is a spatially discriminatory practice among retailers. Taxicab services and delivery food may not serve certain areas, based on their ethnic-minority composition and assumptions about business, rather than data and economic criteria, such as the potential profitability of operating in those areas. Consequently, consumers in these areas are vulnerable to prices set by fewer retailers. They may be exploited by retailers who charge higher prices and/or offer them inferior goods.
Credit cards.
Credit card redlining is a spatially discriminatory practice among credit card issuers, of providing different amounts of credit to different areas, based on their ethnic-minority composition, rather than on economic criteria, such as the potential profitability of operating in those areas. Scholars assess certain policies, such as American Express reducing credit lines of individuals with a record of purchases at retailers frequented by so-called "high-risk" customers, to be akin to redlining.
Insurance.
Racial profiling or redlining has a long history in the property-insurance industry in the United States. From a review of industry underwriting and marketing materials, court documents, and research by government agencies, industry and community groups, and academics, it is clear that race has long affected and continues to affect the policies and practices of the insurance industry. Home-insurance agents may try to assess the ethnicity of a potential customer just by telephone, affecting what services they offer to inquiries about purchasing a home-insurance policy. This type of discrimination is called linguistic profiling. There have also been concerns raised about redlining in the automotive insurance industry. Review of insurance scores based on credit are shown to have unequal results by ethnic group. The Ohio Department of Insurance in the early 21st century allows insurance providers to use maps and collection of demographic data by zip code in determining insurance rates. This practice has been criticized as a kind of redlining. Insurance rates should be related to data about claims.
Student loans.
In December 2007, a class action lawsuit was brought against student loan lending giant Sallie Mae in the United States District Court for the District of Connecticut. The class alleged that Sallie Mae discriminated against African American and Hispanic private student loan applicants.
The case alleged that the factors Sallie Mae used to underwrite private student loans caused a disparate impact on students attending schools with higher minority populations. The suit also alleged that Sallie Mae failed to properly disclose loan terms to private student loan borrowers.
Environmental racism.
Policies related to redlining and urban decay can also act as a form of environmental racism, which in turn have an impact on public health. Urban minority communities may face environmental racism in the form of parks that are smaller, less accessible and of poorer quality than those in more affluent or white areas in some cities. This may have an indirect impact on health, since young people have fewer places to play, and adults have fewer opportunities for exercise.
Robert Wallace writes that the pattern of the AIDS outbreak during the '80s was affected by the outcomes of a program of "planned shrinkage" directed at African-American and Hispanic communities. It was implemented through systematic denial of municipal services, particularly fire protection resources, essential to maintain urban levels of population density and ensure community stability. Institutionalized racism affects general health care as well as the quality of AIDS health intervention and services in minority communities. The over-representation of minorities in various disease categories, including AIDS, is partially related to environmental racism. The national response to the AIDS epidemic in minority communities was slow during the '80s and '90s, showing an insensitivity to ethnic diversity in prevention efforts and AIDS health services.
Liquorlining.
Some service providers target low-income neighborhoods for nuisance sales. When those services are believed to have adverse effects on a community, they may considered to be a form of "reverse redlining." The term "liquorlining" is sometimes used to describe high densities of liquor stores in low income and/or minority communities relative to surrounding areas. High densities of liquor stores are associated with crime and public health issues, which may in turn drive away supermarkets, grocery stores, and other retail outlets, contributing to low levels of economic development. Controlled for income, nonwhites face higher concentrations of liquor stores than do whites.
In Pennsylvania, all alcoholic beverages except beer are sold by state-owned liquor stores. This regulatory regime has prevented liquorlining in Philadelphia, yet the practice exists in lower income neighborhoods.
Further reading.
Hallahan, Kirk. "The Mortgage Redlining Controversy 1972-1975" http://lamar.colostate.edu/~pr/redlining.pdf
Westgate, Michael and Ann Vick., "Gale Force, The Battles For Disclosure and Community Reinvestment", Harvard Book Store, 2nd edition, 2011. ISBN 978-0-615-44901-2

</doc>
<doc id="60563" url="http://en.wikipedia.org/wiki?curid=60563" title="Chancellor of Germany (1949–)">
Chancellor of Germany (1949–)

The Chancellor of the Federal Republic of Germany (known in German as "Bundeskanzler(in)", literally meaning "Federal Chancellor", or "Kanzler" for short) is, under the German 1949 constitution, the head of government of Germany. It is historically a continuation of the office of Chancellor (German: "Kanzler", later "Reichskanzler") that was originally established as the office of Chancellor of the North German Confederation in 1867. The 1949 constitution increased the role of the Chancellor compared to the 1919 Weimar Constitution by making the Chancellor more independent of the influence of the Federal President and granting the Chancellor the right to set the guidelines for all policy areas. The role is generally comparable to that of Prime Minister in other parliamentary democracies.
There have been eight chancellors since 1949. The current Chancellor of Germany is Angela Merkel, who was elected in 2005. She is the first female Chancellor since the establishment of the original office in 1867, and known in German as "Bundeskanzlerin", the feminine form of "Bundeskanzler". Merkel is also the first Chancellor elected since the fall of the Berlin Wall to have been raised in the former East Germany.
History of position.
The office of Chancellor has a long history, stemming back to the Holy Roman Empire. The title was at times used in several states of German-speaking Europe. The power and influence of this office varied strongly over time. Otto von Bismarck in particular had a great amount of power, but it was not until 1949 that the Chancellor was established as the central executive authority of Germany.
Due to his administrative tasks, the head of the chapel of the imperial palace during the Holy Roman Empire was called Chancellor. The Archbishop of Mainz was German Chancellor until the end of the Holy Roman Empire in 1806 while the Archbishop of Cologne was Chancellor of Italy and the Archbishop of Trier of Burgundy. These three Archbishops were also Prince-electors of the empire. Already in medieval times the Chancellor had political power like Willigis of Mainz (Archchancellor 975–1011, regent for Otto III 991–994) or Rainald von Dassel (Chancellor 1156–1162 and 1166–1167) under Frederick I.
The modern office of Chancellor was established with the North German Confederation, of which Otto von Bismarck became Chancellor (German, "Bundeskanzler") in 1867. After unification of Germany in 1871, the office became known in German as "Reichskanzler" ("Reich Chancellor"). Since the adoption of the current constitution of Germany in 1949 the formal title of the office in the German language is once again "Bundeskanzler".
In the now defunct German Democratic Republic (GDR, East Germany), which existed from 7 October 1949 to 3 October 1990 (when the territory of the former GDR was reunified with the Federal Republic of Germany), the position of Chancellor did not exist. The equivalent position was called either Minister President "(Ministerpräsident)" or Chairman of the Council of Ministers of the GDR "(Vorsitzender des Ministerrats der DDR)". (See Leaders of East Germany.)
Role.
West Germany's 1949 constitution, the Basic Law ("Grundgesetz"), invests the Federal Chancellor ("Bundeskanzler") with central executive authority. Since the 1961 election, the two major parties (CDU/CSU and SPD) call their leading candidates for the federal election "chancellor-candidate" ("Kanzlerkandidat"), although this is not an official term and any party can nominate a Kanzlerkandidat (even if there is no chance at all to lead or even become part of a coalition). The Federal Government ("Bundesregierung") consists of the chancellor and his or her cabinet ministers.
The chancellor's authority emanates from the provisions of the Basic Law and from his or her status as leader of the party (or coalition of parties) holding a majority of seats in the "Bundestag" (federal parliament). With the exception of Helmut Schmidt, the chancellor has usually also been chairman of his or her own party. This was the case with Chancellor Gerhard Schröder from 1999 until he resigned the chairmanship of the SPD in 2004.
The first chancellor, Konrad Adenauer, set many precedents that continue today. He arrogated nearly all major decisions to himself, and established the chancellorship as the clear focus of power in Germany. He often treated his ministers as mere extensions of his authority rather than colleagues. While his successors have tended to be less domineering, the chancellor has acquired enough power that Germany is often described as a "chancellor democracy."
The chancellor determines the composition of the Federal Cabinet. The President formally appoints and dismisses cabinet ministers, at the recommendation of the chancellor; no parliamentary approval is needed. According to the Basic Law, the chancellor may set the number of cabinet ministers and dictate their specific duties. Chancellor Ludwig Erhard had the largest cabinet, with twenty-two ministers in the mid-1960s. Helmut Kohl presided over 17 ministers at the start of his fourth term in 1994; the 2002 cabinet, the second of Chancellor Gerhard Schröder, had 13 ministers and the Angela Merkel cabinet as of 22 November 2005 has 15.
Article 65 of the Basic Law sets forth three principles that define how the executive branch functions:
Appointment mechanism.
Every four years, after national elections and the convocation of the newly elected members of the "Bundestag", the chancellor is elected by a majority of the members of the "Bundestag" upon the proposal of the President ("Bundespräsident"). This vote is one of the few cases where a majority of all elected members of the "Bundestag" must be achieved, as opposed to a mere majority of those that are currently assembled. This is referred to as the "Kanzlermehrheit" (chancellor's majority), and is designed to ensure the establishment of a stable government. It has in the past occasionally forced ill or pregnant members to have to attend parliament when a party's majority was only slim.
Unlike regular voting by the "Bundestag", the vote to elect the chancellor is by secret ballot. This is intended to ensure that the chancellor's majority does not depend on members of his or her party only outwardly showing support.
If the nominee of the President is not elected, the "Bundestag" may elect its own nominee within fourteen days. If no-one is elected within this period, the "Bundestag" will attempt an election. If the person with the highest number of votes has a majority, the President must appoint him or her. If the person with the highest number of votes does not have a majority, the President may either appoint them or call new elections for the "Bundestag". As all chancellors have been elected in the first vote as yet (1949–2010) neither of these constitutional provisions has been applied.
The chancellor is the only member of the federal government elected by the "Bundestag". The other cabinet ministers are chosen by the chancellor himself or herself, although they are formally appointed by the President on the chancellor's proposal.
Votes of no-confidence.
Unlike in other parliamentary legislatures, the "Bundestag" cannot remove the chancellor simply with a Motion of No Confidence. Instead, the early removal of a chancellor is only possible when it simultaneously agrees on a successor. In order to garner legislative support in the "Bundestag", the chancellor can also call for a regular Motion of Confidence, either combined with a legislative proposal or as a standalone vote. Only if such a vote fails may the President dissolve the "Bundestag".
This procedure exists to avoid the situation that existed in the Weimar Republic, when votes of no-confidence were over-used or abused by parties.
Style of address.
The correct style of address in German is "Herr Bundeskanzler" (male) or "Frau Bundeskanzlerin" (female). Use of the mixed form "Frau Bundeskanzler" was deprecated by the government in 2004 because it is regarded as impolite.
Living former Chancellors.
There are three living former German Chancellors:
Salary.
Holding the third-highest state office available within the Federal Republic of Germany, the Chancellor of Germany receives €220,000 per annum and a €22,000 bonus, i.e. one and two thirds of Salary Grade B11 (according to § 11 (1) a of the Federal Law on Ministres – Bundesministergesetz, BGBl. 1971 I p. 1166 and attachment IV to the Federal Law on Salaries of Officers – Bundesbesoldungsgesetz, BGBl. 2002 I p. 3020).

</doc>
<doc id="60564" url="http://en.wikipedia.org/wiki?curid=60564" title="Takeru Kobayashi">
Takeru Kobayashi

Takeru Kobayashi (小林 尊, Kobayashi Takeru, born March 15, 1978) is a Japanese competitive eater. He holds several records, including six Guinness Records, for eating hot dogs, meatballs, Twinkies, hamburgers, pizza and pasta.
Competition and records.
Born in Nagano, Japan, Kobayashi set his first record at his rookie appearance on July 4, 2001, when he ate 50 hot dogs in 12 minutes at the Nathan's Coney Island Hot Dog Eating Contest, doubling the previous record of 25. The record was so unexpected that when Kobayashi got to the later numbers, the organizers ran out of signs indicating how many dogs Kobayashi had eaten and had to resort to handwritten signs. Kobayashi would go on to break his own record three times in winning the contest six consecutive times (2001–2006).
In the 2006 Krystal Square Off, Kobayashi's mark of 97 hamburgers was 30 better than his winning total in 2005 and 28 better than the World Record he set in 2004.
At a speed-eating contest in Hong Kong on August 13, 2005, Kobayashi consumed 83 vegetarian jiaozi dumplings in 8 minutes. The next day, he ate 100 roasted pork buns in 12 minutes. Kobayashi also won the 2005 Alka-Seltzer US Open of Competitive Eating, a three-hour IFOCE elimination tournament on ESPN, as well as the Glutton Bowl, a two-hour IFOCE eating special that aired on the Fox Network in 2002. However, on Fox's 2003 show "Man vs. Beast", Kobayashi lost in an eating competition against a 1089-pound Kodiak bear, when he ate 31 bunless hot dogs in 2 minutes and 36 seconds to the bear's 50. In a 2014 interview, Kobayashi claims to have beaten the bear in the rehearsal. (In October 2012, Kobayashi broke the record held by the bear at the Texas state fair.)
On August 5, 2006, Kobayashi set yet another world record at the Johnsonville World Bratwurst Eating Championship in Sheboygan, Wisconsin, by downing 58 bratwurst sausages in 10 minutes, shattering the previous record of 35 set the previous year by Sonya Thomas.
On September 23, 2006, Takeru Kobayashi set the world record at the Phantom Food Festival in Boston, Massachusetts, for eating 41 Summer Shack lobster rolls in 10 minutes, replacing the previous record of 22 rolls. Other world-eating records held by Kobayashi include 17.7 pounds of cow brains in 15 minutes and 20 pounds (9 kg) of rice balls in 30 minutes.
On June 25, 2007, Kobayashi announced on his blog that he seriously injured his jaw during training. He stated that he could only open his jaw about the width of a fingertip. Kobayashi's participation in the July 4, 2007, Nathan's contest continued as scheduled. He was able to eat a personal record 63 hot dogs, though his mark was bettered by Joey Chestnut's 66.
On July 4, 2008, Kobayashi once again competed in the Nathan's contest. He ate 59 hot dogs.
Kobayashi went on to defeat Chestnut, on May 31, 2009, in a Pizza Hut P'Zone competition at Sony Studios in Culver City, California. The competition aired on Spike TV on June 21.
In July 2009, Kobayashi visited Puerto Rico in a special appearance for Taco Bell's Why Pay More Challenge, eating 64 tacos in 15 minutes for a local charity.
On July 4, 2009, he competed again in the Nathan's contest. He ate 64.5 hot dogs and buns.
On September 27, 2009, Kobayashi defeated Chestnut again with a score of 93 (68 Krystals, 5 Big Angus Burgers), earning the $20,000 top prize. Chestnut was second, with 81, and Pat "Deep Dish" Bertoletti finished third, with 76.
On July 4, 2011, Kobayashi competed on the rooftop of a Manhattan bar simultaneously with the Nathan's Contest at Coney Island via a live video simulcast of the event. Kobayashi finished 69 hot dogs, one more than the officially recognized world record. Chestnut told reporters, "I think even Kobayashi would agree that the record still stands at 68. And if he wants to compete with me on the Fourth of July, he knows what he has to do - sign a simple contract and man up".
On September 5, 2011, Kobayashi competed in another hot dog contest in which he consumed 49 hot dogs in 10 minutes.
On January 23, 2012. Kobayashi went on The Wendy Williams Show to set the record for eating the most Twinkies in one minute, for the "Save The Twinkie" campaign, and set a new world record of 14 Twinkies.
On February 3, 2012, Kobayashi set the new Wing Bowl record for eating chicken wings at Wing Bowl XX, held at the Wells Fargo Center in Philadelphia. His total was 337 wings in his first competition in that event.
On August 26, 2012, Kobayashi set the new world record at the New York State Fair in Syracuse for eating 110 hot dogs in 10 minutes.
In October 2012, Kobayashi set the new world record at the Texas State Fair for eating 60 hot dogs in 2 minutes 35 seconds.
On June 30, 2012, Kobayashi revealed the Major League Eating (MLE) contract he was required to sign in order to compete in Nathan's Fourth of July hot dog eating competition. The year-long contract limited him to $40,000 and took away any rights to endorse or engage in anything outside of what MLE mandated.
On July 4, 2012, Kobayashi competed in the Crif Dog Classic. He ate 58.5 hot dogs and buns.
On October 11, 2012, Kobayashi set the new world record at the Gringo Bandito Taco Challenge by eating 106 tacos in 10 minutes.
On July 21, 2013, Kobayashi defended his title at the Gringo Bandito Taco Challenge.
On October 6, 2013, Kobayashi won "LET 'EM EAT" Canada's biggest pizza eating contest for the fourth year in a row.
On August 4, 2014, Kobayashi set the new world record at "LET 'EM EAT" Canada's biggest pizza eating contest by eating 62 slices of pizza (15 and a half pizzas) in 12 minutes.
On September 1, 2014, Kobayashi set the new world record at the Gringo Bandito Taco Challenge by eating 130 tacos in 10 minutes.
Training and techniques.
Kobayashi expands his stomach for a competition by eating larger and larger amounts of food, and then exercises to ensure that fat will not impede expansion of his stomach during a competition.
Kobayashi's official web site gives his height as 173 cm (5 ft 8 in) and his weight as 58 kg (128 lb). However he's weighed as much as 87 kg (192 lb) according to a June 29, 2006 blog entry. As of July 4, 2009, Kobayashi weighed in at 60 kg (132 lb) for the annual Fourth of July hot dog eating competition on Coney Island.
Kobayashi is also known for his trademark body wiggle, referred to by some as the "Kobayashi Shake", to force food down his esophagus and settle more compactly in his stomach. He eats hot dogs by splitting the frankfurter in half, dipping the buns in water, and then stuffing both parts in his mouth. He calls this the Solomon Method.
Arrest and contractual disputes.
July 4, 2010 arrest.
On June 28, 2010, Kobayashi announced he would not compete in the Nathan's Fourth of July Hot Dog Eating Competition. The impasse was reportedly due to the MLE's insistence that Kobayashi signed an exclusive contract with the organization that would prevent him from competing in contests not sanctioned by MLE.
On July 4, 2010, Kobayashi was in attendance at the Nathan's International Hot Dog Eating Contest, watching from the crowd. Wearing a black T-shirt that read "Free Kobi", Kobayashi mingled with the crowd, standing inside a police-barricaded pen just under the stage. After the competition ended, he slipped up the stage stairs and crashed the stage. Although he was initially ushered by security officers up to the stage, one security officer (thought to have been requested by George Shea), quickly ushered him offstage as he resisted vehemently, hanging on to the barricades and fences before being taken into custody. Though some witnesses reported that Kobayashi was attempting to congratulate the winner, Joey Chestnut, co-host and MLE President Richard Shea, stated that "[Kobayashi] tried to jump on stage during the awards ceremony to disrupt it." With the crowd chanting at him, Kobayashi was detained by the NYPD. He was charged with resisting arrest, trespassing, and obstructing government administration and subsequently turned himself into jail awaiting an appearance in Brooklyn Criminal Court.
Kobayashi's interpreter and publicist, Maggie James, said he had originally gone in hopes to cheer on his fellow competitive eaters, but after arriving and the chanting from the fans, he was swooped onto the stage due to the excitement. She said "There's a contract dispute, they weren't giving him his freedom. It was unfair."
Kobayashi told reporters he had a sandwich and a glass of milk while being held. "I am very hungry," he said. "I wish there were hot dogs in jail."
On August 5, 2010 all charges against Kobayashi were dismissed by a judge in Brooklyn. Despite his record six consecutive victories in their annual event, Nathan's removed Kobayashi's image from their "Wall of Fame" in 2011.
After Kobayashi left Nathan's, the hot dog contest lost sponsorship from Old Navy, Heinz Tomato Ketchup, Pepto-Bismol, and was down year-to-year. With an average 0.7 HH U.S. rating, it was off just a tenth of a point from 2012, when it aired on ESPN. ESPN averaged 1.949 million viewers for 2011's Nathan's Famous Hot Dog Eating Contest, but went down 41% to 1.15 million viewers in 2013.
July 4, 2011 competing events.
In 2011, Kobayashi was still barred from the annual Nathan's event due to the contract dispute. On July 4, he competed on the rooftop of a Manhattan bar, 230 Fifth, for the duration of the Coney Island contest. Two official judges from the Athletic Association of NY observed Kobayashi while the live broadcast of the event played next to him on a large television screen. Kobayashi finished a record 69 Nathan's hot dogs, one more than the Nathan's world record and seven more than Chestnut's winning total in the 2011 contest. "I want to remain free to compete in the events that I want to compete in," Kobayashi said. "Today was a great success."
July 4, 2012 competing events.
In 2012, Kobayashi was still barred from the annual Nathan's event due to the contract dispute. Kobayashi ate 58.5 at Crif dog classic, eating a different type hot dog from Nathan's Famous Fourth of July International Hot Dog Eating Contest.
July 4, 2014 competing events.
Kobayashi ate 113 bunless Nathan's hot dogs at 230 Fifth.
Other pursuits.
In 2005, Kobayashi appeared in ESPN sports center commercial.
In 2007, Kobayashi appeared in MasterCard commercial and Coors Light commercial.
In 2008 Kobayashi appeared in Western Canada Lottery Corporation commercial
On May 30, 2009, Kobayashi attended The Spike Guys' Choice Awards.
In November 2010, Kobayashi appeared in a magazine featuring men's clothing published as an offshoot of V magazine, VMAN 20th Winter.
In November 2010, Kobayashi competed against Donkey Kong in a banana eating contest at the Rio-Can Centre in Toronto as part of the launch for Nintendo's Donkey Kong Country Returns.
On July 7, 2011, Kobayashi made a guest appearance at Hewlett Packard event 2011. The other guests were Snoop Dog, Sugar Ray, Dan Finnerty, Third Eye Blind, Candlebox.
In 2011 Kobayashi appeared in TVB commercial.
In Spring 2011, Kobayashi appeared in his first major fashion editorial in Canada's The Block magazine as a model. Additionally, Kobayashi is an aspiring dog trainer, with six labradoodles he calls his "hot dogs." 
On March 20, 2012, Kobayashi appeared in a Jake and Amir video produced by College Humor.
In June 2012, Kobayashi made a Special guest appearance and a taco demonstration at Offspring New Album Release Pop Up Party "Days Go By".
In 2012, Kobayashi appeared in Eight O'Clock Coffee, and Hofmann commercial
In 2012, Kobayashi appeared alongside close childhood friend, Joe Rogan, on a celebrity edition of Fear Factor.
In 2013, Kobayashi appeared in Just-Eat and Thuzio commercials.
Kobayashi has been featured on Late Night with Jimmy Falon, Saturday Night Live, MTV's True Life, MTV After Hours With Josh Horowitz, The Daily Show with Jon Stewart, The Wendy Williams Show and has done original features with Buzzfeed.com, CollegeHumor.com and SI.com, and is a featured user on the foodie mobile and web-based app Foodspotting.
On July 4, 2013, Kobayashi unveiled his new line of all-beef midwestern grain-fed hot dogs, known officially as "Kobi Dogs" at Eventi Hotel in NY.
On September 16, 2014, he appeared in a YouTube video to be competing with a hamster. The video ends in Kobayashi acknowledging his defeat by putting a medal around the hamster's neck.
Kobayashi appears in The Simpsons Game.

</doc>
<doc id="60567" url="http://en.wikipedia.org/wiki?curid=60567" title="President of Germany">
President of Germany

The President of Germany, officially the President of the Federal Republic of Germany, is the head of state of Germany.
Germany has a parliamentary system of government with the Federal Chancellor running the government and the politics of the day. However, the German President has a role which is more than ceremonial with the office being a genuine political office with extensive discretion regarding the way the President exercises his official duties. The Federal President gives direction to general political and societal debates and has some important "reserve powers" in case of political instability (such as those provided for by Article 81 of the Basic Law). 
Under Article 59 (1) of the Basic Law (German Constitution), the Federal President represents the Federal Republic of Germany in matters of international law, concludes treaties with foreign states on its behalf and accredits diplomats. Furthermore, all federal laws must be signed by the President before they can come into effect; however, he can only veto a law that he believes to violate the constitution.
The Federal President, by his actions and public appearances, represents the state itself, its existence, its legitimacy, and unity. The President's office involves an integrative role and the control function of upholding the law and the constitution. It is a matter of political tradition – not legal restrictions – that the Federal President generally does not comment routinely on issues in the news, particularly when there is some controversy among the political parties. This distance from day-to-day politics and daily governmental issues allows the Federal President to be a source of clarification, to influence public debate, to voice criticism, offer suggestions and make proposals. In order to exercise this power, he traditionally acts above party politics.
The current officeholder is Joachim Gauck who was elected on 18 March 2012.
Selection.
The president is elected by secret ballot, without debate, by the Federal Convention which mirrors the aggregated majority situation of the Bundestag and the parliaments of the 16 German federal states. The convention consists of all Bundestag members as well as an equal number of delegates chosen by the legislatures of the "Länder" (states). The delegates of each "Land" to the Federal Convention are elected by the members of the state legislature under a form of proportional representation. However it is not required that "Land" delegates themselves be members of a legislature; often prominent citizens are chosen.
In total, the Federal Convention numbers more than one thousand members. The German constitution, the Basic Law, requires that it be convened no later than thirty days before the expiration of the term of office of the president (which is five years). The body is convened and chaired by the President of the Bundestag. From 1979 to 2009, all these conventions have been held on 23 May, the date of the foundation of the Federal Republic in 1949. However, the two latest elections were held on different dates after the predecessing presidents stepped down before the end of their terms since they had to be held within 30 days of Horst Köhler's and Christian Wulff's resignations in 2010 and 2012 respectively.
In the first two rounds of the election process, the Federal Convention attempts to elect a president by an absolute majority of votes cast. If, after two votes, no single candidate has received this level of support, in the third and final vote the candidate endorsed by a plurality of votes cast is elected. The process of electing the president is usually determined by party politics, the office being in the gift of whichever party, or group of allied parties, can muster a majority in the convention.
Qualifications.
The office of president is open to all Germans who are entitled to vote in Bundestag elections and have reached the age of 40, but no one may serve more than two consecutive five-year terms. The president must not be a member of the federal government or of a legislature at either the federal or state level.
Oath.
On taking office the president must take the following oath, stipulated by Article 56 of the Basic Law, before the assembled members of the Bundestag and Bundesrat (however he or she is permitted to omit the religious references if so desired):
I swear that I will dedicate my efforts to the well-being of the German people, enhance their benefits, avert harm from them, uphold and defend the Constitution and the statutes of the Federation, fulfil my duties conscientiously, and do justice to all. (So help me God.)
Duties and functions.
The Federal President is involved in the formation of the Federal Government and remains in close cooperation with it. Basically the President is free to act on his own accord. However, according to Article 58 of the German constitution, most orders and directives of the Federal President require the countersignature of the Federal Chancellor or the corresponding Federal Minister. This rule ensures the coherence of government action. Therefore, the Federal President also receives the Federal Chancellor regularly for talks on current policy issues. He also holds talks with individual Federal Ministers and other senior officials at his own discretion. The "Head of the Office of the Federal President" represents the President in the meetings of the Federal Cabinet and reports back to the Federal President.
The Federal President's most prominent duties include:
Appointment of the Federal Government.
The Federal President proposes an individual as Federal Chancellor and then, provided he or she is subsequently elected by the Bundestag, appoints him or her to the office. However, the Bundestag is free to disregard the president's proposal and elect another individual to the post, whom the president is then obliged to appoint. The president appoints and dismisses the remaining members of the Federal Government "upon the proposal of the Chancellor." The president can dismiss the Chancellor, but only in the event that the Bundestag passes a Constructive Vote of No Confidence. If this occurs, the president must dismiss the chancellor and appoint the successor requested by the Bundestag.
Other appointments.
The president appoints federal judges, federal civil servants and military officers. All such appointments require the counter-signature of either the chancellor or the relevant cabinet minister.
Dissolution of the Bundestag.
In the event that the Bundestag elects an individual for the office of chancellor by a plurality of votes, rather than a majority, the president can, at his or her discretion, either appoint that individual as chancellor or dissolve the Bundestag, triggering a new election. In the event that a vote of confidence is defeated in the Bundestag, and the incumbent chancellor proposes a dissolution, the president may, at his discretion, dissolve the body within 21 days. As of 2010, this power has only been applied three times in the history of the Federal Republic. In all three occurrences it is doubtful whether the motives for that dissolution were in accordance with the constitution's intentions. Each time the incumbent chancellor called for the vote of confidence with the stated intention of being defeated, in order to be able to call for new elections before the end of their regular term, as the Basic Law does not give the Bundestag a right to dissolve itself. The most recent occurrence was on 1 July 2005, when Chancellor Gerhard Schröder asked for a vote of confidence, which was defeated.
Promulgation of the law.
All federal laws must, after counter-signature, be signed by the president before they can come into effect. Upon signing, the president has to check if the law was passed according to the order mandated by the constitution and/or if the content of the law is constitutional. If not, he or she has the right (and, some argue, the duty) to refuse to sign the law. This has happened rather rarely.
Foreign relations.
The president represents Germany in the World (Art. 59 Basic Law), holds foreign visits and receives foreign dignitaries. He or she also concludes treaties with foreign nations (which do not come into effect until affirmed by the Bundestag), accredits German diplomats and receives the letters of accreditation of foreign diplomats.
Pardons and honours.
According to Article 60 (2) of the German Constitution the Federal President exercises the power to pardon. This means he "has the authority to revoke or commute penal or disciplinary sentences in individual cases. The Federal President cannot, however, issue an amnesty waiving or commuting sentences for a whole category of offences. That requires a law enacted by the German Bundestag in conjunction with the Bundesrat. Due to the federal structure of Germany the Federal President is only responsible for dealing with certain criminal matters (e.g. espionage and terrorism) and disciplinary proceedings against federal civil servants, federal judges and soldiers".
State of legislational emergency.
In the event of a national crisis, the Basic Law designates the president as a mediator. If the Bundestag rejects a motion of confidence, but neither a new chancellor is elected nor the Bundestag is dissolved, the president may, by request of the cabinet, declare a "legislative state of emergency", which is quite different from a conventional state of emergency: If it is declared, during a limited period of time, bills proposed by the cabinet and designated as "urgent", but rejected by the Bundestag, become law nonetheless, if the Bundesrat does pass them. But the legislative state of emergency does not suspend basic human rights nor does it grant the executive branch any exceptional power. Such an emergency has never been declared.
Politics and influence.
Though candidates are usually selected by a political party or parties, the president nonetheless is traditionally expected to refrain from being an active member of any party after assuming office. Every president to date has let his or her party membership rest dormant during his term of office. Presidents have, however, spoken publicly about their personal views on political matters. In some cases, a presidential speech has dominated German political debate for a year or more.
Reserve powers.
According to article 81 of the German constitution the president can declare an "Legislation Emergency" and allow the federal government and the Bundesrat to enact laws without the approval of the Bundestag (lower house of parliament). He also has important decisive power regarding the appointment of a chancellor who was elected by a relative majority only, or the dissolution of the Bundestag under certain circumstances.
It is also theoretically possible, albeit a drastic step which has not happened since 1945, that the president refuses to sign legislation merely because he disagrees with its content, thus vetoing it, or refuse to approve a cabinet appointment. In all cases in which a bill was not signed by the Federal President, all presidents have claimed that the bill in question was manifestly unconstitutional. For example, in the autumn of 2006, President Köhler did so twice within three months. Also, in some cases, a president has signed a law while asking that the political parties refer the case to the Federal Constitutional Court in order to test the law's constitutionality.
Succession.
The Basic Law did not create an office of vice president. If the president is outside of the country, or the position is vacant, the President of the Bundesrat (a position that is rotated among the state premiers on an annual basis) temporarily assumes the powers of the president until a successor is elected without assuming the office of president as such. While doing so, he or she does not continue to exercise the role of chair of the Bundesrat. If the president dies, resigns or is otherwise removed from office, a successor is to be elected within thirty days. This process was triggered for the first time on May 31, 2010, when Horst Köhler resigned the office, as all his predecessors (with the exception of Heinrich Lübke, who announced in 1968 that he would resign the following year, his resignation taking effect after the regular election of his successor and just three months before the scheduled end of his term of office) had served their terms in full. Jens Böhrnsen, Mayor of Bremen and at the time President of the Bundesrat, assumed the powers and duties of head of state.
Impeachment and removal.
While in office the president enjoys immunity from prosecution and cannot be voted out of office or recalled. The only mechanism for removing the president is impeachment by the Bundestag or Bundesrat for willfully violating German law. Once the Bundestag impeaches the president, the Federal Constitutional Court is charged with determining if he or she is guilty of the offence. If the charge is sustained the court has the authority to remove the president from office.
Presidential office and symbols.
Office.
The Office of the Federal President is a supreme federal authority. It organizes the President's work, supports the Federal President in the performance of his duties as Head of State and coordinates his working relationships to other parts of the German government and administration. Its top official, who takes precedence over all other German state secretaries, is the Head of the Office of the Federal President. The office and its staff advises the Federal President, informs him of all developments in domestic and foreign affairs and carries out the instructions of the Federal President or forwards these to the corresponding ministry or authority.
Residences.
The official residence of the Federal President is Bellevue Palace in Berlin. The President's second official residence is the Hammerschmidt Villa in the former capital city of West Germany Bonn.
Transportation.
The Federal President's car is usually black, made in Germany and has the numberplate "0 – 1" with the presidential standard on the right wing of the car. The President also uses a VIP helicopter operated by the Federal Police and VIP aircraft (Bombardier Global 5000, Airbus A319CJ, Airbus A310 or A340) operated by the German Ministry of Defence. When the President is on board, the flight's callsign is „German Airforce 001“.
Presidential standard.
The standard of the President of Germany was adopted on 11 April 1921, and used in this design until 1933. A slightly modified version also existed from 1926, that was used in addition to the 1921 version. In 1933, these versions were both replaced by another modified version, that was used until 1935.
The Weimar-era presidential standard from 1921 was adopted again as presidential standard by a decision by President Theodor Heuss on 20 January 1950, when he also formally adopted other Weimar-era state symbols including the coat of arms. The eagle ("Reichsadler", now called "Bundesadler") in the design that was used in the coat of arms and presidential standard in the Weimar Republic and today was originally introduced by a decision by President Friedrich Ebert on 11 November 1919.
History.
Weimar Republic.
The position of President of Germany was first established by the Weimar Constitution, which was drafted in the aftermath of World War I and the abdication of Emperor Wilhelm II in 1918. In Germany the new head of state was called the "Reichspräsident".
Friedrich Ebert (SPD) served as Germany's first president, followed by Paul von Hindenburg. The office effectively came to an end upon Hindenburg's death in 1934 and its powers merged with those of Chancellor. Adolf Hitler now ruled Germany as "Führer und Reichskanzler", combining his previous positions in party and government. The office however was not abolished and briefly revived at the end of the Second World War when Hitler appointed Grand Admiral Karl Dönitz as his successor as President of Germany. Dönitz signed the surrender to the Allies and was arrested a few days later.
The Weimar Constitution created a semi-presidential system in which power was divided between the president, a cabinet and a parliament. The president enjoyed far greater power than the current president and had an active political role, rather than a largely ceremonial one. The influence of the president also increased greatly as a result of the instability of the Weimar period. The president had authority to appoint the Chancellor and could dismiss the entire cabinet at any time. However it was also necessary for the cabinet to enjoy the confidence of the Reichstag (parliament) because it could be removed by a vote of no confidence. All bills had to receive the signature of the president to become law and, although he did not have an absolute veto on legislation, he could insist that a law be submitted for the approval of voters in a referendum. The president also had authority to dissolve the Reichstag, conduct foreign affairs, and command the armed forces. Article 48 of the constitution also provided the president sweeping powers in the event of a crisis. If there was a threat to "public order and security" he could legislate by decree and suspend civil rights.
The Weimar constitution provided that the president be directly elected and serve a seven-year term. The election involved a form of the two-round system. However the first president was elected by the National Assembly and subsequently only two direct presidential elections actually occurred. These were the election of Paul von Hindenburg in 1925 and his re-election in 1932.
The system created by the Weimar constitution led to a number of problems. In particular, the fact that the president could appoint the cabinet, while the Reichstag had only a power of dismissal, created a high cabinet turn-over as ministers were appointed by the president only to be dismissed by the Reichstag shortly afterwards. Eventually Hindenburg stopped trying to appoint cabinets that enjoyed the confidence of the Reichstag and ruled by means of three "presidential cabinets" ("Präsidialkabinette"). Hindenburg was also able to use his power of dissolution to by-pass the Reichstag. If the Reichstag threatened to censure his ministers or revoke one of his decrees he could simply dissolve the body and be able to govern without its interference until elections had been held. This led to eight Reichstag elections taking place in the 14 years of the Republic's existence; only one parliamentary term, that of 1920–1924, was completed without elections being held early.
German Democratic Republic (East Germany).
Socialist East Germany established the office of a head of state with the title of President of the Republic (German: "Präsident der Republik") in 1949, but abandoned the office with the death of the first president, Wilhelm Pieck, in 1960 in favour of a collective head of state. All government positions of the East German socialist republic, including the presidency, were appointed by the ruling Socialist Unity Party of Germany.
Federal Republic of Germany (West Germany).
With the promulgation of the Grundgesetz in 1949, the office of President (in German: "Bundespräsident") was created in West Germany. Because the reunification of Germany in 1990 was accomplished by the five East German states joining the Federal Republic, the Federal President became the President of all German states.

</doc>
<doc id="60569" url="http://en.wikipedia.org/wiki?curid=60569" title="Rectifier">
Rectifier

A rectifier is an electrical device that converts alternating current (AC), which periodically reverses direction, to direct current (DC), which flows in only one direction. The process is known as rectification. Physically, rectifiers take a number of forms, including vacuum tube diodes, mercury-arc valves, copper and selenium oxide rectifiers, semiconductor diodes, silicon-controlled rectifiers and other silicon-based semiconductor switches. Historically, even synchronous electromechanical switches and motors have been used. Early radio receivers, called crystal radios, used a "cat's whisker" of fine wire pressing on a crystal of galena (lead sulfide) to serve as a point-contact rectifier or "crystal detector".
Rectifiers have many uses, but are often found serving as components of DC power supplies and high-voltage direct current power transmission systems. Rectification may serve in roles other than to generate direct current for use as a source of power. As noted, detectors of radio signals serve as rectifiers. In gas heating systems flame rectification is used to detect presence of a flame.
Because of the alternating nature of the input AC sine wave, the process of rectification alone produces a DC current that, though unidirectional, consists of pulses of current. Many applications of rectifiers, such as power supplies for radio, television and computer equipment, require a "steady" constant DC current (as would be produced by a battery). In these applications the output of the rectifier is smoothed by an electronic filter (usually a capacitor) to produce a steady current.
A more complex circuitry device that performs the opposite function, converting DC to AC, is called an inverter.
Rectifier devices.
Before the development of silicon semiconductor rectifiers, vacuum tube thermionic diodes and copper oxide- or selenium-based metal rectifier stacks were used. With the introduction of semiconductor electronics, vacuum tube rectifiers became obsolete, except for some enthusiasts of vacuum tube audio equipment. For power rectification from very low to very high current, semiconductor diodes of various types (junction diodes, Schottky diodes, etc.) are widely used.
Other devices that have control electrodes as well as acting as unidirectional current valves are used where more than simple rectification is required—e.g., where variable output voltage is needed. High-power rectifiers, such as those used in high-voltage direct current power transmission, employ silicon semiconductor devices of various types. These are thyristors or other controlled switching solid-state switches, which effectively function as diodes to pass current in only one direction.
Rectifier circuits.
Rectifier circuits may be single-phase or multi-phase (three being the most common number of phases). Most low power rectifiers for domestic equipment are single-phase, but three-phase rectification is very important for industrial applications and for the transmission of energy as DC (HVDC).
Single-phase rectifiers.
Half-wave rectification.
In half wave rectification of a single-phase supply, either the positive or negative half of the AC wave is passed, while the other half is blocked. Because only one half of the input waveform reaches the output, mean voltage is lower. Half-wave rectification requires a single diode in a single-phase supply, or three in a three-phase supply. Rectifiers yield a unidirectional but pulsating direct current; half-wave rectifiers produce far more ripple than full-wave rectifiers, and much more filtering is needed to eliminate harmonics of the AC frequency from the output.
The no-load output DC voltage of an ideal half wave rectifier for a sinusoidal input voltage is:
formula_1
Where:
Full-wave rectification.
A full-wave rectifier converts the whole of the input waveform to one of constant polarity (positive or negative) at its output. Full-wave rectification converts both polarities of the input waveform to pulsating DC (direct current), and yields a higher average output voltage. Two diodes and a center tapped transformer, or four diodes in a bridge configuration and any AC source (including a transformer without center tap), are needed. Single semiconductor diodes, double diodes with common cathode or common anode, and four-diode bridges, are manufactured as single components.
For single-phase AC, if the transformer is center-tapped, then two diodes back-to-back (cathode-to-cathode or anode-to-anode, depending upon output polarity required) can form a full-wave rectifier. Twice as many turns are required on the transformer secondary to obtain the same output voltage than for a bridge rectifier, but the power rating is unchanged.
The average and root-mean-square no-load output voltages of an ideal single-phase full-wave rectifier are:
formula_2
Very common double-diode rectifier vacuum tubes contained a single common cathode and two anodes inside a single envelope, achieving full-wave rectification with positive output. The 5U4 and 5Y3 were popular examples of this configuration.
Three-phase rectifiers.
Single-phase rectifiers are commonly used for power supplies for domestic equipment. However, for most industrial and high-power applications, three-phase rectifier circuits are the norm. As with single-phase rectifiers, three-phase rectifiers can take the form of a half-wave circuit, a full-wave circuit using a center-tapped transformer, or a full-wave bridge circuit.
Thyristors are commonly used in place of diodes to create a circuit that can regulate the output voltage. Many devices that provide direct current actually "generate" three-phase AC. For example, an automobile alternator contains six diodes, which function as a full-wave rectifier for battery charging.
Three-phase, half-wave circuit.
An uncontrolled three-phase, half-wave circuit requires three diodes, one connected to each phase. This is the simplest type of three-phase rectifier but suffers from relatively high harmonic distortion on both the AC and DC connections. This type of rectifier is said to have a pulse-number of three, since the output voltage on the DC side contains three distinct pulses per cycle of the grid frequency.
Three-phase, full-wave circuit using center-tapped transformer.
If the AC supply is fed via a transformer with a center tap, a rectifier circuit with improved harmonic performance can be obtained. This rectifier now requires six diodes, one connected to each end of each transformer secondary winding. This circuit has a pulse-number of six, and in effect, can be thought of as a six-phase, half-wave circuit.
Before solid state devices became available, the half-wave circuit, and the full-wave circuit using a center-tapped transformer, were very commonly used in industrial rectifiers using mercury-arc valves. This was because the three or six AC supply inputs could be fed to a corresponding number of anode electrodes on a single tank, sharing a common cathode.
With the advent of diodes and thyristors, these circuits have become less popular and the three-phase bridge circuit has become the most common circuit.
Three-phase bridge rectifier.
For an uncontrolled three-phase bridge rectifier, six diodes are used, and the circuit again has a pulse number of six. For this reason, it is also commonly referred to as a six-pulse bridge.
For low-power applications, double diodes in series, with the anode of the first diode connected to the cathode of the second, are manufactured as a single component for this purpose. Some commercially available double diodes have all four terminals available so the user can configure them for single-phase split supply use, half a bridge, or three-phase rectifier.
For higher-power applications, a single discrete device is usually used for each of the six arms of the bridge. For the very highest powers, each arm of the bridge may consist of tens or hundreds of separate devices in parallel (where very high current is needed, for example in aluminium smelting) or in series (where very high voltages are needed, for example in high-voltage direct current power transmission).
For a three-phase full-wave diode rectifier, the ideal, no-load average output voltage is
formula_3
If thyristors are used in place of diodes, the output voltage is reduced by a factor cos(α):
formula_4
Or, expressed in terms of the line to line input voltage:
formula_5
Where:
The above equations are only valid when no current is drawn from the AC supply or in the theoretical case when the AC supply connections have no inductance. In practice, the supply inductance causes a reduction of DC output voltage with increasing load, typically in the range 10–20% at full load.
The effect of supply inductance is to slow down the transfer process (called commutation) from one phase to the next. As result of this is that at each transition between a pair of devices, there is a period of overlap during which three (rather than two) devices in the bridge are conducting simultaneously. The overlap angle is usually referred to by the symbol μ (or u), and may be 20 30° at full load.
With supply inductance taken into account, the output voltage of the rectifier is reduced to:
formula_6
The overlap angle μ is directly related to the DC current, and the above equation may be re-expressed as:
formula_7
Where:
Twelve-pulse bridge.
Although better than single-phase rectifiers or three-phase half-wave rectifiers, six-pulse rectifier circuits still produce considerable harmonic distortion on both the AC and DC connections. For very high-power rectifiers the twelve-pulse bridge connection is usually used. A twelve-pulse bridge consists of two six-pulse bridge circuits connected in series, with their AC connections fed from a supply transformer that produces a 30° phase shift between the two bridges. This cancels many of the characteristic harmonics the six-pulse bridges produce.
The 30 degree phase shift is usually achieved by using a transformer with two sets of secondary windings, one in star (wye) connection and one in delta connection.
Voltage-multiplying rectifiers.
The simple half wave rectifier can be built in two electrical configurations with the diode pointing in opposite directions, one version connects the negative terminal of the output direct to the AC supply and the other connects the positive terminal of the output direct to the AC supply. By combining both of these with separate output smoothing it is possible to get an output voltage of nearly double the peak AC input voltage. This also provides a tap in the middle, which allows use of such a circuit as a split rail power supply.
A variant of this is to use two capacitors in series for the output smoothing on a bridge rectifier then place a switch between the midpoint of those capacitors and one of the AC input terminals. With the switch open, this circuit acts like a normal bridge rectifier. With the switch closed, it act like a voltage doubling rectifier. In other words, this makes it easy to derive a voltage of roughly 320 V (±15%, approx.) DC from any 120 V or 230 V mains supply in the world, this can then be fed into a relatively simple switched-mode power supply. However, for a given desired ripple, the value of both capacitors must be twice the value of the single one required for a normal bridge rectifier; when the switch is closed each one must filter the output of a half-wave rectifier, and when the switch is open the two capacitors are connected in series with an equivalent value of half one of them.
Cascaded diode and capacitor stages can be added to make a voltage multiplier (Cockroft-Walton circuit). These circuits are capable of producing a DC output voltage potential tens of times that of the peak AC input voltage, but are limited in current capacity and regulation. Diode voltage multipliers, frequently used as a trailing boost stage or primary high voltage (HV) source, are used in HV laser power supplies, powering devices such as cathode ray tubes (CRT) (like those used in CRT based television, radar and sonar displays), photon amplifying devices found in image intensifying and photo multiplier tubes (PMT), and magnetron based radio frequency (RF) devices used in radar transmitters and microwave ovens. Before the introduction of semiconductor electronics, transformerless powered vacuum tube receivers powered directly from AC power sometimes used voltage doublers to generate about 170 VDC from a 100–120 V power line.
Rectifier efficiency.
Rectifier efficiency (η) is defined as the ratio of DC output power to the input power from the AC supply. Even with ideal rectifiers with no losses, the efficiency is less than 100% because some of the output power is AC power rather than DC which manifests as ripple superimposed on the DC waveform. For a half-wave rectifier efficiency is very poor,
Thus maximum efficiency for a half-wave rectifier is,
formula_10
Similarly, for a full-wave rectifier,
formula_11
Efficiency is reduced by losses in transformer windings and power dissipation in the rectifier element itself. Efficiency can be improved with the use of smoothing circuits which reduce the ripple and hence reduce the AC content of the output. Three-phase rectifiers, especially three-phase full-wave rectifiers, have much greater efficiencies because the ripple is intrinsically smaller. In some three-phase and multi-phase applications the efficiency is high enough that smoothing circuitry is unnecessary.
Rectifier losses.
A real rectifier characteristically drops part of the input voltage (a voltage drop, for silicon devices, of typically 0.7 volts plus an equivalent resistance, in general non-linear)—and at high frequencies, distorts waveforms in other ways. Unlike an ideal rectifier, it dissipates some power.
An aspect of most rectification is a loss from the peak input voltage to the peak output voltage, caused by the built-in voltage drop across the diodes (around 0.7 V for ordinary silicon p–n junction diodes and 0.3 V for Schottky diodes). Half-wave rectification and full-wave rectification using a center-tapped secondary produces a peak voltage loss of one diode drop. Bridge rectification has a loss of two diode drops. This reduces output voltage, and limits the available output voltage if a very low alternating voltage must be rectified. As the diodes do not conduct below this voltage, the circuit only passes current through for a portion of each half-cycle, causing short segments of zero voltage (where instantaneous input voltage is below one or two diode drops) to appear between each "hump".
Peak loss is very important for low voltage rectifiers (for example, 12 V or less) but is insignificant in high-voltage applications such as HVDC.
Rectifier output smoothing.
While half-wave and full-wave rectification can deliver unidirectional current, neither produces a constant voltage. Producing steady DC from a rectified AC supply requires a smoothing circuit or filter. In its simplest form this can be just a reservoir capacitor or smoothing capacitor, placed at the DC output of the rectifier. There is still an AC ripple voltage component at the power supply frequency for a half-wave rectifier, twice that for full-wave, where the voltage is not completely smoothed.
Sizing of the capacitor represents a tradeoff. For a given load, a larger capacitor reduces ripple but costs more and creates higher peak currents in the transformer secondary and in the supply that feeds it. The peak current is set in principle by the rate of rise of the supply voltage on the rising edge of the incoming sine-wave, but in practice it is reduced by the resistance of the transformer windings. In extreme cases where many rectifiers are loaded onto a power distribution circuit, peak currents may cause difficulty in maintaining a correctly shaped sinusoidal voltage on the ac supply.
To limit ripple to a specified value the required capacitor size is proportional to the load current and inversely proportional to the supply frequency and the number of output peaks of the rectifier per input cycle. The load current and the supply frequency are generally outside the control of the designer of the rectifier system but the number of peaks per input cycle can be affected by the choice of rectifier design.
A half-wave rectifier only gives one peak per cycle, and for this and other reasons is only used in very small power supplies. A full wave rectifier achieves two peaks per cycle, the best possible with a single-phase input. For three-phase inputs a three-phase bridge gives six peaks per cycle. Higher numbers of peaks can be achieved by using transformer networks placed before the rectifier to convert to a higher phase order.
To further reduce ripple, a capacitor-input filter can be used. This complements the reservoir capacitor with a choke (inductor) and a second filter capacitor, so that a steadier DC output can be obtained across the terminals of the filter capacitor. The choke presents a high impedance to the ripple current. For use at power-line frequencies inductors require cores of iron or other magnetic materials, and add weight and size. Their use in power supplies for electronic equipment has therefore dwindled in favour of semiconductor circuits such as voltage regulators.
A more usual alternative to a filter, and essential if the DC load requires very low ripple voltage, is to follow the reservoir capacitor with an active voltage regulator circuit. The reservoir capacitor must be large enough to prevent the troughs of the ripple dropping below the minimum voltage required by the regulator to produce the required output voltage. The regulator serves both to significantly reduce the ripple and to deal with variations in supply and load characteristics. It would be possible to use a smaller reservoir capacitor (these can be large on high-current power supplies) and then apply some filtering as well as the regulator, but this is not a common strategy. The extreme of this approach is to dispense with the reservoir capacitor altogether and put the rectified waveform straight into a choke-input filter. The advantage of this circuit is that the current waveform is smoother and consequently the rectifier no longer has to deal with the current as a large current pulse, but instead the current delivery is spread over the entire cycle. The disadvantage, apart from extra size and weight, is that the voltage output is much lower – approximately the average of an AC half-cycle rather than the peak.
Applications.
The primary application of rectifiers is to derive DC power from an AC supply (AC to DC converter). Virtually all electronic devices require DC, so rectifiers are used inside the power supplies of virtually all electronic equipment.
Converting DC power from one voltage to another is much more complicated. One method of DC-to-DC conversion first converts power to AC (using a device called an inverter), then uses a transformer to change the voltage, and finally rectifies power back to DC. A frequency of typically several tens of kilohertz is used, as this requires much smaller inductance than at lower frequencies and obviates the use of heavy, bulky, and expensive iron-cored units.
Rectifiers are also used for detection of amplitude modulated radio signals. The signal may be amplified before detection. If not, a very low voltage drop diode or a diode biased with a fixed voltage must be used. When using a rectifier for demodulation the capacitor and load resistance must be carefully matched: too low a capacitance makes the high frequency carrier pass to the output, and too high makes the capacitor just charge and stay charged.
Rectifiers supply polarised voltage for welding. In such circuits control of the output current is required; this is sometimes achieved by replacing some of the diodes in a bridge rectifier with thyristors, effectively diodes whose voltage output can be regulated by switching on and off with phase fired controllers.
Thyristors are used in various classes of railway rolling stock systems so that fine control of the traction motors can be achieved. Gate turn-off thyristors are used to produce alternating current from a DC supply, for example on the Eurostar Trains to power the three-phase traction motors.
Rectification technologies.
Electromechanical.
Before about 1905 when tube type rectifiers were developed, power conversion devices were purely electro-mechanical in design. Mechanical rectification systems used some form of rotation or resonant vibration (e.g. vibrators) driven by electromagnets, which operated a switch or commutator to reverse the current.
These mechanical rectifiers were noisy and had high maintenance requirements. The moving parts had friction, which required lubrication and replacement due to wear. Opening mechanical contacts under load resulted in electrical arcs and sparks that heated and eroded the contacts. They also were not able to handle AC frequencies above several thousand cycles per second.
Synchronous rectifier.
To convert alternating into direct current in electric locomotives, a synchronous rectifier may be used . It consists of a synchronous motor driving a set of heavy-duty electrical contacts. The motor spins in time with the AC frequency and periodically reverses the connections to the load at an instant when the sinusoidal current goes through a zero-crossing. The contacts do not have to "switch" a large current, but they must be able to "carry" a large current to supply the locomotive's DC traction motors.
Vibrating rectifier.
These consisted of a resonant reed, vibrated by an alternating magnetic field created by an AC electromagnet, with contacts that reversed the direction of the current on the negative half cycles. They were used in low power devices, such as battery chargers, to rectify the low voltage produced by a step-down transformer. Another use was in battery power supplies for portable vacuum tube radios, to provide the high DC voltage for the tubes. These operated as a mechanical version of modern solid state switching inverters, with a transformer to step the battery voltage up, and a set of vibrator contacts on the transformer core, operated by its magnetic field, to repeatedly break the DC battery current to create a pulsing AC to power the transformer. Then a second set of rectifier contacts on the vibrator rectified the high AC voltage from the transformer secondary to DC.
Motor-generator set.
A "motor-generator set", or the similar "rotary converter", is not strictly a rectifier as it does not actually "rectify" current, but rather "generates" DC from an AC source. In an "M-G set", the shaft of an AC motor is mechanically coupled to that of a DC generator. The DC generator produces multiphase alternating currents in its armature windings, which a commutator on the armature shaft converts into a direct current output; or a homopolar generator produces a direct current without the need for a commutator. M-G sets are useful for producing DC for railway traction motors, industrial motors and other high-current applications, and were common in many high-power D.C. uses (for example, carbon-arc lamp projectors for outdoor theaters) before high-power semiconductors became widely available.
Electrolytic.
The electrolytic rectifier was a device from the early twentieth century that is no longer used. A home-made version is illustrated in the 1913 book "The Boy Mechanic" but it would only be suitable for use at very low voltages because of the low breakdown voltage and the risk of electric shock. A more complex device of this kind was patented by G. W. Carpenter in 1928 (US Patent 1671970).
When two different metals are suspended in an electrolyte solution, direct current flowing one way through the solution sees less resistance than in the other direction. Electrolytic rectifiers most commonly used an aluminum anode and a lead or steel cathode, suspended in a solution of tri-ammonium ortho-phosphate.
The rectification action is due to a thin coating of aluminum hydroxide on the aluminum electrode, formed by first applying a strong current to the cell to build up the coating. The rectification process is temperature-sensitive, and for best efficiency should not operate above 86 °F (30 °C). There is also a breakdown voltage where the coating is penetrated and the cell is short-circuited. Electrochemical methods are often more fragile than mechanical methods, and can be sensitive to usage variations, which can drastically change or completely disrupt the rectification processes.
Similar electrolytic devices were used as lightning arresters around the same era by suspending many aluminium cones in a tank of tri-ammonium ortho-phosphate solution. Unlike the rectifier above, only aluminium electrodes were used, and used on A.C., there was no polarization and thus no rectifier action, but the chemistry was similar.
The modern electrolytic capacitor, an essential component of most rectifier circuit configurations was also developed from the electrolytic rectifier.
Plasma type.
Mercury-arc.
A rectifier used in high-voltage direct current (HVDC) power transmission systems and industrial processing between about 1909 to 1975 is a "mercury-arc rectifier" or "mercury-arc valve". The device is enclosed in a bulbous glass vessel or large metal tub. One electrode, the cathode, is submerged in a pool of liquid mercury at the bottom of the vessel and one or more high purity graphite electrodes, called anodes, are suspended above the pool. There may be several auxiliary electrodes to aid in starting and maintaining the arc. When an electric arc is established between the cathode pool and suspended anodes, a stream of electrons flows from the cathode to the anodes through the ionized mercury, but not the other way (in principle, this is a higher-power counterpart to flame rectification, which uses the same one-way current transmission properties of the plasma naturally present in a flame).
These devices can be used at power levels of hundreds of kilowatts, and may be built to handle one to six phases of AC current. Mercury-arc rectifiers have been replaced by silicon semiconductor rectifiers and high-power thyristor circuits in the mid 1970s. The most powerful mercury-arc rectifiers ever built were installed in the Manitoba Hydro Nelson River Bipole HVDC project, with a combined rating of more than 1 GW and 450 kV.
Argon gas electron tube.
The General Electric Tungar rectifier was an argon gas-filled electron tube device with a tungsten filament cathode and a carbon button anode. It operated similarly to the thermionic vacuum tube diode, but the gas in the tube ionized during forward conduction, giving it a much lower forward voltage drop so it could rectify lower voltages. It was used for battery chargers and similar applications from the 1920s until lower-cost metal rectifiers, and later semiconductor diodes, supplanted it. These were made up to a few hundred volts and a few amperes rating, and in some sizes strongly resembled an incandescent lamp with an additional electrode.
The 0Z4 was a gas-filled rectifier tube commonly used in vacuum tube car radios in the 1940s and 1950s. It was a conventional full-wave rectifier tube with two anodes and one cathode, but was unique in that it had no filament (thus the "0" in its type number). The electrodes were shaped such that the reverse breakdown voltage was much higher than the forward breakdown voltage. Once the breakdown voltage was exceeded, the 0Z4 switched to a low-resistance state with a forward voltage drop of about 24 V.
Vacuum tube (valve).
The thermionic vacuum tube diode, originally called the Fleming valve, was invented by John Ambrose Fleming in 1904 as a detector for radio waves in radio receivers, and evolved into a general rectifier. It consisted of an evacuated glass bulb with a filament heated by a separate current, and a metal plate anode. The filament emitted electrons by thermionic emission (the Edison effect), discovered by Thomas Edison in 1884, and a positive voltage on the plate caused a current of electrons through the tube from filament to plate. Since only the filament produced electrons, the tube would only conduct current in one direction, allowing the tube to rectify an alternating current.
Vacuum diode rectifiers were widely used in power supplies in vacuum tube consumer electronic products, such as phonographs, radios, and televisions, for example the All American Five radio receiver, to provide the high DC plate voltage needed by other vacuum tubes. "Full-wave" versions with two separate plates were popular because they could be used with a center-tapped transformer to make a full-wave rectifier. Vacuum rectifiers were made for very high voltages, such as the high voltage power supply for the cathode ray tube of television receivers, and the kenotron used for power supply in X-ray equipment. However, compared to modern semiconductor diodes, vacuum rectifiers have high internal resistance due to space charge and therefore high voltage drops, causing high power dissipation and low efficiency. They are rarely able to handle currents exceeding 250 mA owing to the limits of plate power dissipation, and cannot be used for low voltage applications, such as battery chargers. Another limitation of the vacuum tube rectifier is that the heater power supply often requires special arrangements to insulate it from the high voltages of the rectifier circuit.
In musical instrument amplification (especially for electric guitars), the slight delay or "sag" between a signal increase (for instance, when a guitar chord is struck hard and fast) and the corresponding increase in output voltage is a notable effect of tube rectification, and results in compression. The choice between tube rectification and diode rectification is a matter of taste; some amplifiers have both and allow the player to choose.
Solid state.
Crystal detector.
The cat's-whisker detector was the earliest type of semiconductor diode. It consisted of a crystal of some semiconducting mineral, usually galena (lead sulfide), with a light springy wire touching its surface. Invented by Jagadish Chandra Bose and developed by G. W. Pickard around 1906, it served as the radio wave rectifier in the first widely used radio receivers, called crystal radios. Its fragility and limited current capability made it unsuitable for power supply applications. It became obsolete around 1920, but later versions served as microwave detectors and mixers in radar receivers during World War 2.
Selenium and copper oxide rectifiers.
Once common until replaced by more compact and less costly silicon solid-state rectifiers in the 1970s, these units used stacks of metal plates and took advantage of the semiconductor properties of selenium or copper oxide. While selenium rectifiers were lighter in weight and used less power than comparable vacuum tube rectifiers, they had the disadvantage of finite life expectancy, increasing resistance with age, and were only suitable to use at low frequencies. Both selenium and copper oxide rectifiers have somewhat better tolerance of momentary voltage transients than silicon rectifiers.
Typically these rectifiers were made up of stacks of metal plates or washers, held together by a central bolt, with the number of stacks determined by voltage; each cell was rated for about 20 V. An automotive battery charger rectifier might have only one cell: the high-voltage power supply for a vacuum tube might have dozens of stacked plates. Current density in an air-cooled selenium stack was about 600 mA per square inch of active area (about 90 mA per square centimeter).
Silicon and germanium diodes.
In the modern world, silicon diodes are the most widely used rectifiers for lower voltages and powers, and have largely replaced earlier germanium diodes. For very high voltages and powers, the added need for controllability has in practice led to replacing simple silicon diodes with high-power thyristors (see below) and their newer actively gate-controlled cousins.
High power: thyristors (SCRs) and newer silicon-based voltage sourced converters.
In high-power applications, from 1975 to 2000, most mercury valve arc-rectifiers were replaced by stacks of very high power thyristors, silicon devices with two extra layers of semiconductor, in comparison to a simple diode.
In medium-power transmission applications, even more complex and sophisticated voltage sourced converter (VSC) silicon semiconductor rectifier systems, such as insulated gate bipolar transistors (IGBT) and gate turn-off thyristors (GTO), have made smaller high voltage DC power transmission systems economical. All of these devices function as rectifiers.
s of 2009[ [update]] it was expected that these high-power silicon "self-commutating switches," in particular IGBTs and a variant thyristor (related to the GTO) called the integrated gate-commutated thyristor (IGCT), would be scaled-up in power rating to the point that they would eventually replace simple thyristor-based AC rectification systems for the highest power-transmission DC applications.
Current research.
A major area of research is to develop higher frequency rectifiers, that can rectify into terahertz and light frequencies. These devices are used in optical heterodyne detection, which has myriad applications in optical fiber communication and atomic clocks. Another prospective application for such devices is to directly rectify light waves picked up by tiny antenna, called nantennas, to produce DC electric power. It is thought that arrays of nantennas could be a more efficient means of producing solar power than solar cells.
A related area of research is to develop smaller rectifiers, because a smaller device has a higher cutoff frequency. Research projects are attempting to develop a unimolecular rectifier, a single organic molecule that would function as a rectifier.

</doc>
<doc id="60570" url="http://en.wikipedia.org/wiki?curid=60570" title="IBM POWER">
IBM POWER

IBM POWER may refer to:

</doc>
<doc id="60572" url="http://en.wikipedia.org/wiki?curid=60572" title="Visual Instruction Set">
Visual Instruction Set

Visual Instruction Set, or VIS, is a SIMD instruction set extension for SPARC V9 microprocessors developed by Sun Microsystems. There are four versions of VIS: VIS 1, VIS 2, VIS 2+, and VIS 3.
History.
VIS 1 was introduced in 1994 and was first implemented by Sun in their UltraSPARC microprocessor (1995) and by Fujitsu in their SPARC64 GP microprocessors (2000).
VIS 2 was first implemented by the UltraSPARC III. All subsequent UltraSPARC and SPARC64 microprocessors implement the instruction set.
VIS 3 was first implemented in the SPARC T4 microprocessor. 
Differences vs x86.
VIS is not an instruction toolkit like Intel's MMX and SSE. MMX has only 8 registers shared with the FPU stack, while SPARC processors have 32 registers, also aliased to the double-precision (64-bit) floating pointer registers.
As with the SIMD instruction set extensions on RISC processors, VIS strictly conform to the main principle of RISC: keep the instruction set concise and efficient.
This design is very different from comparable extensions on CISC processors, such as MMX, SSE, SSE2, SSE3, SSE4, 3DNow!.
Sometimes, programmers must use several VIS instructions to accomplish an operation that can be done with only one MMX or SSE instruction, but it should be kept in mind that fewer instructions do not automatically result in better performance.
Functionality.
VIS re-uses existing SPARC V9 64-bit floating point registers to hold multiple 8, 16, or 32-bit integer values. In this respect, VIS is more similar to the design of MMX than other SIMD architectures such as SSE/SSE2/AltiVec.
VIS includes a number of operations primarily for graphics support, so most of them are only for integers. These include 3D to 2D conversion, edge processing and pixel distance.
There are four ways to use VIS in code:

</doc>
<doc id="60573" url="http://en.wikipedia.org/wiki?curid=60573" title="Show Low, Arizona">
Show Low, Arizona

Show Low is a city in Navajo County, Arizona, United States. It lies on the Mogollon Rim in east central Arizona, at an elevation of 6,345 feet (1,934 m). The city was established in 1870 and incorporated in 1953. According to the 2010 census, the population of the city was 10,660.
Name and history.
According to the legend, the city's unusual name resulted from a marathon poker game between Corydon E. Cooley and Marion Clark. The two men decided there was not enough room for both of them in their settlement. The two men agreed to let a game of cards decide who was to move. According to the tale, Clark said, "If you can show low, you win." Cooley turned up the deuce of clubs (the lowest possible card) and replied, "Show low it is." The stakes were a 100,000 acre ranch. Show Low's main street is named "Deuce of Clubs" in remembrance.
In 2002, a large forest fire, the Rodeo-Chediski fire, threatened the city and forced an evacuation. The fire was extinguished less than a half mile from the city's border, and Show Low was completely spared. The city is near extensive forests, and is a popular recreational area.
Geography.
Show Low is located at (34.243595, -110.048173).
According to the United States Census Bureau, the city has a total area of 27.9 sqmi, of which, 27.9 sqmi of it is land and 0.1 sqmi of it (0.25%) is water.
Climate.
Winters in Show Low bring highs between 45 °F (7 °C) and 55 °F (13 °C), with lows usually below freezing between November and March, averaging in the 20s December through February, and in the low 30s for November and March.
In the summer, highs in Show Low average approximately 85 °F (29 °C), with an occasional day above 90 °F (32 °C) not uncommon for the city. As the sun sets in the summertime, temperatures plummet dramatically, sometimes upwards of 30 degrees. This nightly temperature swing results in summertime lows typically ranging between 50 °F (10 °C) and 60 °F (16 °C).
Show Low has reached below-freezing temperatures every month at least once in its history except July and August, where temperatures have only reached 38 °F (3 °C) and 37 °F (3 °C) respectively.
Show Low has twice reached 100 °F (38 °C), its record high temperature: once on May 31, 1969, and again on July 14, 2003. Show Low's record low temperature of -25 °F (-32 °C) was set on January 8, 1971.
Show Low averages about 18.3 in of rain per year.
Demographics.
As of the census of 2000, there were 7,695 people, 2,885 households, and 2,117 families residing in the city. The population density was 859 people per square mile (106.6/km²). There were 7186 housing units at an average density of 155.7 per square mile (60.1/km²). The racial makeup of the city was 90.3% White, 0.4% Black or African American, 3.2% Native American, 0.5% Asian, 0.1% Pacific Islander, 3.4% from other races, and 2.2% from two or more races. 9.4% of the population were Hispanic or Latino of any race.
There were 2,885 households out of which 34.8% had children under the age of 18 living with them, 58.2% were married couples living together, 11.1% had a female householder with no husband present, and 26.6% were non-families. 21.9% of all households were made up of individuals and 9.5% had someone living alone who was 65 years of age or older. The average household size was 2.62 and the average family size was 3.04.
In the city the population was spread out with 29.2% under the age of 18, 7.4% from 18 to 24, 24.9% from 25 to 44, 23.5% from 45 to 64, and 15.0% who were 65 years of age or older. The median age was 37 years. For every 100 females there were 95.1 males. For every 100 females age 18 and over, there were 88.5 males.
The median income for a household in the city was $32,356, and the median income for a family was $36,397. Males had a median income of $28,882 versus $24,590 for females. The per capita income for the city was $15,536. About 11.7% of families and 15.0% of the population were below the poverty line, including 23.6% of those under age 18 and 6.0% of those age 65 or over.
Transportation.
Show Low Regional Airport (IATA: SOW, ICAO: KSOW) provides passenger airline service through Great Lakes Airlines to Phoenix and to Denver through Farmington, New Mexico; the airport maintains a single passenger terminal for this purpose. The airport is also commonly used for air cargo, air-taxi, and as a fixed base operator for general aviation.
The city also maintains a minor public transportation operation in conjunction with neighboring Pinetop-Lakeside. Two shuttles service multiple retail, high-traffic, and government offices and also the airport and nearby Hon-Dah casino (57 stops in all).
Education.
Almost all of the city is a part of the Show Low Unified School District. A portion of the city is within the boundaries of the Blue Ridge Unified School District.
Schools that serve the SLUSD portion of the city include Linden Elementary, Nikolaus Homestead Elementary, Whipple Ranch Elementary, White Mountain Institute, Show Low Junior High School, and Show Low High School.
Show Low is home to one of Northland Pioneer College's four regional campuses, the White Mountain Campus.
Economy.
Top employers.
According to the City's 2014 "Comprehensive Annual Financial Report", the top employers in the city are:
References.
 Retrieved July 24, 2009

</doc>
<doc id="60575" url="http://en.wikipedia.org/wiki?curid=60575" title="Cardiac arrest">
Cardiac arrest

Cardiac arrest, also known as cardiopulmonary arrest or circulatory arrest, is a sudden stop in effective blood circulation due to the failure of the heart to contract effectively or at all. Medical personnel may refer to an unexpected cardiac arrest as a sudden cardiac arrest (SCA).
A cardiac arrest is different from (but may be caused by) a myocardial infarction (AKA heart attack), where blood flow to the muscle of the heart is impaired. It is different from congestive heart failure, where circulation is substandard, but the heart is still pumping sufficient blood to sustain life.
Arrested blood circulation prevents delivery of oxygen and glucose to the body. Lack of oxygen and glucose to the brain causes loss of consciousness, which then results in abnormal or absent breathing. Brain injury is likely to happen if cardiac arrest goes untreated for more than five minutes. For the best chance of survival and neurological recovery immediate treatment is important.
Cardiac arrest is a medical emergency that, in certain situations, is potentially reversible if treated early. Unexpected cardiac arrest can lead to death within minutes: this is called sudden cardiac death (SCD). The treatment for cardiac arrest is immediate defibrillation if a "shockable" rhythm is present, while cardiopulmonary resuscitation (CPR) is used to provide circulatory support and/or to induce a "shockable" rhythm.
Classification.
Clinicians classify cardiac arrest into "shockable" versus "non–shockable", as determined by the ECG rhythm. This refers to whether a particular class of cardiac dysrhythmia is treatable using defibrillation. The two "shockable" rhythms are ventricular fibrillation and pulseless ventricular tachycardia while the two "non–shockable" rhythms are asystole and pulseless electrical activity.
Signs and symptoms.
Cardiac arrest is sometimes preceded by certain symptoms such as fainting, fatigue, blackouts, dizziness, chest pain, shortness of breath, weakness, and vomiting. The arrest may also occur with no warning.
When the arrest occurs, the most obvious sign of its occurrence will be the lack of a palpable pulse in the person experiencing it (since the heart has ceased to contract, the usual indications of its contraction such a pulse will no longer be detectable). Certain types of prompt intervention can often reverse a cardiac arrest, but without such intervention the event will almost always lead to death. In certain cases, it is an expected outcome of a serious illness where death is expected.
Also, as a result of inadequate cerebral perfusion, the patient will quickly become unconscious and will have stopped breathing. The main diagnostic criterion to diagnose a cardiac arrest (as opposed to respiratory arrest which shares many of the same features) is lack of circulation; however, there are a number of ways of determining this. Near-death experiences are reported by 10-20% of people who survived cardiac arrest.
Causes.
Coronary heart disease is the leading cause of sudden cardiac arrest. Many other cardiac and non-cardiac conditions also increase one's risk.
Coronary artery disease.
Approximately 60–70% of SCD is related to coronary heart disease. Among adults, ischemic heart disease is the predominant cause of arrest with 30% of people at autopsy showing signs of recent myocardial infarction.
Non-ischemic heart disease.
A number of other cardiac abnormalities can increase the risk of SCD including cardiomyopathy, cardiac rhythm disturbances, hypertensive heart disease, and congestive heart failure.
In a group of military recruits aged 18–35, cardiac anomalies accounted for 51% of cases of SCD, while in 35% of cases the cause remained unknown. Underlying pathology included coronary artery abnormalities (61%), myocarditis (20%), and hypertrophic cardiomyopathy (13%). Congestive heart failure increases the risk of SCD fivefold.
Many additional conduction abnormalities exist that place one at higher risk for cardiac arrest. For instance, long QT syndrome, a condition often mentioned in young people's deaths, occurs in one of every 5000 to 7000 newborns and is estimated to be responsible for 3000 deaths each year compared to the approximately 300,000 cardiac arrests seen by emergency services. These conditions are a fraction of the overall deaths related to cardiac arrest, but represent conditions which may be detected prior to arrest and may be treatable.
Non-cardiac.
About 35% of SCDs are not caused by a heart condition. The most common non-cardiac causes are trauma, bleeding (such as gastrointestinal bleeding, aortic rupture, or intracranial hemorrhage), overdose, drowning and pulmonary embolism. Cardiac arrest can also be caused by poisoning (for example, by the stings of certain jellyfish).
Risk factors.
The risk factors for SCD are similar to those of coronary heart disease and include smoking, lack of physical exercise, obesity, and diabetes, as well as family history.
Hs and Ts.
"Hs and Ts" is the name for a mnemonic used to aid in remembering the possible treatable or reversible causes of cardiac arrest.
Diagnosis.
Cardiac arrest is synonymous with clinical death.
A cardiac arrest is usually diagnosed clinically by the absence of a pulse. In many cases lack of carotid pulse is the gold standard for diagnosing cardiac arrest, but lack of a pulse (particularly in the peripheral pulses) may result from other conditions (e.g. shock), or simply an error on the part of the rescuer. Studies have shown that rescuers often make a mistake when checking the carotid pulse in an emergency, whether they are healthcare professionals or lay persons.
Owing to the inaccuracy in this method of diagnosis, some bodies such as the European Resuscitation Council (ERC) have de-emphasised its importance. The Resuscitation Council (UK), in line with the ERC's recommendations and those of the American Heart Association,
have suggested that the technique should be used only by healthcare professionals with specific training and expertise, and even then that it should be viewed in conjunction with other indicators such as agonal respiration.
Various other methods for detecting circulation have been proposed. Guidelines following the 2000 International Liaison Committee on Resuscitation (ILCOR) recommendations were for rescuers to look for "signs of circulation", but not specifically the pulse. These signs included coughing, gasping, colour, twitching and movement. However, in face of evidence that these guidelines were ineffective, the current recommendation of ILCOR is that cardiac arrest should be diagnosed in all casualties who are unconscious and not breathing normally.
Prevention.
With positive outcomes following cardiac arrest unlikely, an effort has been spent in finding effective strategies to prevent cardiac arrest. With the prime causes of cardiac arrest being ischemic heart disease, efforts to promote a healthy diet, exercise, and smoking cessation are important. For people at risk of heart disease, measures such as blood pressure control, cholesterol lowering, and other medico-therapeutic interventions are used.[#endnote_]
Code teams.
In medical parlance, cardiac arrest is referred to as a "code" or a "crash". This typically refers to "code blue" on the hospital emergency codes. A dramatic drop in vital sign measurements is referred to as "coding" or "crashing", though coding is usually used when it results in cardiac arrest, while crashing might not. Treatment for cardiac arrest is sometimes referred to as "calling a code".
Extensive research has shown that patients in general wards often deteriorate for several hours or even days before a cardiac arrest occurs. This has been attributed to a lack of knowledge and skill amongst ward-based staff, in particular a failure to carry out measurement of the respiratory rate, which is often the major predictor of a deterioration and can often change up to 48 hours prior to a cardiac arrest. In response to this, many hospitals now have increased training for ward-based staff. A number of "early warning" systems also exist which aim to quantify the risk which patients are at of deterioration based on their vital signs and thus provide a guide to staff. In addition, specialist staff are being utilised more effectively in order to augment the work already being done at ward level. These include:
In some medical facilities, the resuscitation team may purposely respond slowly to a patient in cardiac arrest, a practice known as "slow code", or may fake the response altogether for the sake of the patient's family, a practice known as "show code". This is generally done for patients for whom performing CPR will have no medical benefit. Such practices are ethically controversial, and are banned in some jurisdictions.
Implantable cardioverter defibrillators.
A technologically based intervention to prevent further cardiac arrest episodes is the use of an implantable cardioverter-defibrillator (ICD). This device is implanted in the patient and acts as an instant defibrillator in the event of arrhythmia. Note that standalone ICDs do not have any pacemaker functions, but they can be combined with a pacemaker, and modern versions also have advanced features such as anti-tachycardic pacing as well as synchronized cardioversion. A recent study by Birnie et al. at the University of Ottawa Heart Institute has demonstrated that ICDs are underused in both the United States and Canada. An accompanying editorial by Simpson explores some of the economic, geographic, social and political reasons for this. Patients who are most likely to benefit from the placement of an ICD are those with severe ischemic cardiomyopathy (with systolic ejection fractions less than 30%) as demonstrated by the MADIT-II trial.
Management.
Sudden cardiac arrest may be treated via attempts at resuscitation. This is usually carried out based upon basic life support (BLS)/advanced cardiac life support (ACLS), pediatric advanced life support (PALS) or neonatal resuscitation program (NRP) guidelines.
Cardiopulmonary resuscitation.
Cardiopulmonary resuscitation (CPR) is an important part of the management of cardiac arrest. It is recommended that it be started as soon as possible and interrupted as little as possible. The component of CPR which seems to make the greatest difference in most cases is the chest compressions. Correctly performed bystander CPR has been shown to increase survival; however, it is performed in less than 30% of out of hospital arrests as of 2007. If high-quality CPR has not resulted in return of spontaneous circulation and the person's heart rhythm is in asystole, discontinuing CPR and pronouncing the person's death is reasonable after 20 minutes. Exceptions to this include those with hypothermia or who have drowned. Longer durations of CPR may be reasonable in those who have cardiac arrest while in hospital.
Tracheal intubation has not been found to improve survival rates in cardiac arrest and in the prehospital environment may worsen it. A 2009 study found that assisted ventilation may worsen outcomes over placement of an oral airway with passive oxygen delivery.
CPR which involves only chest compressions results in the same outcomes as standard CPR for those who have gone into cardiac arrest due to heart issues. A 2013 review found some evidence that mechanical chest compressions (as performed by a machine) are better than manual chest compressions while a 2011 and 2012 review considered the evidence insufficient. It is unclear if a few minutes of CPR before defibrillation results in different outcomes than immediate defibrillation.
Defibrillation.
Shockable and non–shockable causes of cardiac arrest is based on the presence or absence of ventricular fibrillation or pulseless ventricular tachycardia. The shockable rhythms are treated with CPR and defibrillation.
In addition, there is increasing use of public access defibrillation. This involves placing automated external defibrillators in public places, and training staff in these areas how to use them. This allows defibrillation to take place prior to the arrival of emergency services, and has been shown to lead to increased chances of survival. Some defibrillators even provide feedback on the quality of CPR compressions, encouraging the lay rescuer to press the patient's chest hard enough to circulate blood. In addition, it has been shown that those who have arrests in remote locations have worse outcomes following cardiac arrest.
Medications.
Medications, while included in guidelines, have been shown not to improve survival to hospital discharge following out-of-hospital cardiac arrest. This includes the use of epinephrine, atropine, and amiodarone. Vasopressin overall does not improve or worsen outcomes but may be of benefit in those with asystole especially if used early.
Epinephrine does appear to improve short-term outcomes such as return of spontaneous circulation. Some of the lack of long-term benefit may be related to delays in epinephrine use.
The 2010 guidelines from the American Heart Association no longer contain the association's previous recommendation for using atropine in pulseless electrical activity and asystole due to the lack of evidence for its use. Evidence is insufficient for lidocaine, and amiodarone may be considered in those who continue in ventricular tachycardia or ventricular fibrillation despite defibrillation. Thrombolytics when used generally may cause harm but may be of benefit in those with a pulmonary embolism as the cause of arrest.
Targeted temperature management.
Cooling a person after cardiac arrest who has a return of spontaneous circulation (ROSC) but no return of consciousness improves outcomes. This procedure is called targeted temperature management (previously known as therapeutic hypothermia). People are typically cooled for a 24-hour period, with a target temperature of 32 -. Death rates in the hypothermia group are 35% lower than in those with no temperature management. Complications are generally no greater in those who receive this therapy.
A November 2013 trial found that actively cooling to a temperature of 36 °C results in the same outcomes as 33 °C. This may be because preventing fever, rather than the hypothermia itself, is more important. Other possible reasons could be the long time of >8 hours needed to cool in the 33 °C group and the very high rate of bystander of CPR compared to usual international rates.
Earlier versus later cooling may result in better outcomes. A trial that cooled in the ambulance, however, found no difference compared to starting cooling in-hospital. A registry database found poor neurological outcome increased by 8% with each five-minute delay in initiating TH and by 17% for every 30-minute delay in time to target temperature.
Do not resuscitate.
Some people choose to avoid aggressive measures at the end of life. A do not resuscitate order (DNR) in the form of an advance health care directive makes it clear that in the event of cardiac arrest, the person does not wish to receive cardiopulmonary resuscitation. Other directives may be made to stipulate the desire for intubation in the event of respiratory failure or, if comfort measures are all that are desired, by stipulating that healthcare providers should "allow natural death".
Chain of survival.
Several organisations promote the idea of a chain of survival. The chain consists of the following "links":
If one or more links in the chain are missing or delayed, then the chances of survival drop significantly.
These protocols are often initiated by a code blue, which usually denotes impending or acute onset of cardiac arrest or respiratory failure, although in practice, code blue is often called in less life-threatening situations that require immediate attention from a physician.
Other.
Resuscitation with extracorporeal membrane oxygenation devices has been attempted with better results for in-hospital cardiac arrest (29% survival) than out-of-hospital cardiac arrest (4% survival) in populations selected to benefit most. Cardiac catheterization in those who have survived an out-of-hospital cardiac arrest appears to improve outcomes although high quality evidence is lacking.
The precordial thump may be considered in those with witnessed, monitored, unstable ventricular tachycardia (including pulseless VT) if a defibrillator is not immediately ready for use, but it should not delay CPR and shock delivery or be used in those with unwitnessed out of hospital arrest.
Prognosis.
The survival rate to hospital discharge of people who receive initial emergency care by ambulance is 2%, with 15% experiencing return of spontaneous circulation. However, with defibrillation within 3–5 minutes, the survival rate increases to 30%. Since mortality in case of out-of-hospital cardiac arrest is high, programs were developed to improve survival rate. Although mortality in case of ventricular fibrillation is high, rapid intervention with a defibrillator increases survival rate.
A 1997 review into outcomes following in-hospital cardiac arrest found a survival to discharge of 14% although the range between different studies was 0-28%. In those over the age of 70 who have a cardiac arrest while in hospital, survival to hospital discharge is less than 20%. How well these individuals are able to manage after leaving hospital is not clear.
Survival is mostly related to the cause of the arrest (see above). In particular, people who have suffered hypothermia have an increased survival rate, possibly because the cold protects the vital organs from the effects of tissue hypoxia. Survival rates following an arrest induced by toxins is very much dependent on identifying the toxin and administering an appropriate antidote. A patient who has suffered a myocardial infarction due to a blood clot in the left coronary artery has a lower chance of survival.
A study of survival rates from out-of-hospital cardiac arrest found that 14.6% of those who had received resuscitation by ambulance staff survived as far as admission to hospital. Of these, 59% died during admission, half of these within the first 24 hours, while 46% survived until discharge from hospital. This reflects an overall survival following cardiac arrest of 6.8%. Of these 89% had normal brain function or mild neurological disability, 8.5% had moderate impairment, and 2% suffered major neurological disability. Of those who were discharged from hospital, 70% were still alive four years later.
Epidemiology.
Based on death certificates, sudden cardiac death accounts for about 15% of all death in Western countries (330,000 per year in the United States). The lifetime risk is three times greater in men (12.3%) than women (4.2%) based on analysis of the Framingham Heart Study. However this gender difference disappeared beyond 85 years of age.

</doc>
<doc id="60579" url="http://en.wikipedia.org/wiki?curid=60579" title="Crystal River, Florida">
Crystal River, Florida

Crystal River is a city in Citrus County, Florida, United States. The population was 3,108 in the 2010 census. (3,485 in 2000). According to the U.S Census estimates of 2012, the city had a population of 3,055. The city was incorporated in 1903 and is the self professed "Home of the Manatee". Crystal River Preserve State Park is located nearby, and Crystal River Archaeological State Park is located in the city's northwest side.
Crystal River is at the heart of the Nature Coast of Florida. The city is situated around Kings Bay, which is spring-fed and so keeps a constant 72 F temperature year round. A cluster of 50 springs designated as a first-magnitude system feeds Kings Bay. A first-magnitude system discharges 100 cubic feet or more of water per second, which equals about 64 million gallons of water per day. Because of this discharge amount, the Crystal River Springs group is the second largest springs group in Florida, the first being Spring Creek Springs in Wakulla County near Tallahassee. Kings Bay is home to over 400 manatees during the winter when the water temperature in the Gulf of Mexico cools, and is the only place in the United States where people can legally interact with them in their natural conditions without that interaction being viewed as harassment by law enforcement agencies. Tourism based on watching and swimming with manatee is the fastest growing contribution to the local economy. In 2005 there was a movement to dissolve the city which did not succeed, and the city has since grown by annexation.
Crystal River was home to the Crystal River 3 Nuclear Power Plant. In 2012 the owners, Duke Energy, announced the closure of the plant.
Geography.
Crystal River is located northwest of the center of Citrus County at , on the northeast side of Kings Bay and the Crystal River, an inlet of the Gulf of Mexico. U.S. Routes 19 and 98 pass through the center of the city, leading south 7 mi to Homasassa Springs and north 46 mi to Chiefland. State Road 44 leads east from Crystal River 17 mi to Inverness, the Citrus County seat.
According to the United States Census Bureau, the city of Crystal River has a total area of 17.7 km2. 16.0 km2 of it is land and 1.7 km2 of it 9.35%, is water.
History.
In the Pleistocene era, the land on which Crystal River is located was vastly different from today. The west coast of Florida is thought to have extended an additional 50 to into the Gulf of Mexico. During excavations for the Florida Nuclear Power Plant in 1969, scientists discovered rhinoceros and mastodon bones, as well as the shells of an extremely large armadillo and a large land tortoise.
Around 500 B.C. mound-building Native Americans (possibly Deptford culture) built a settlement along the Crystal River, which in the present day is the Crystal River Archaeological State Park. It was abandoned prior to European colonization for unknown reasons. The obsolete Native American name for Crystal River was "Weewahi Iaca".
Following the Second Seminole War, settlers were encouraged into the area due to the passing of the Armed Occupation Act of 1842 by the United States federal government. Twenty-two men filed for patents for land in Crystal River. By the mid-1800s, families began to settle in the Crystal River area.
Mail was delivered by horse and buggy, and a stagecoach came from Ocala (Fort King) to Crystal River, stopping at the Stage Stand, which today is the Stage Stand Cemetery in Homosassa.
While no land battles were fought in the Crystal River area during the Civil War, there were many instances of skirmishes on the water directly off the coast of the Crystal and Homosassa rivers, as well as near Hickory Island in Yankeetown. By the time of the Civil War, Florida was an important source and supplier of food and other goods such as beef, pork, fish, corn, sugar, cotton, naval stores and salt. The Union was aware of this, and soon after the war began, the Union Navy blockaded the entire coast of Florida.
Following the Civil War, Crystal River grew. People from states to the north began to arrive, attracted by the area's mild climate and the potential of becoming wealthy growing citrus fruits. Early settlers to the area had found wild citrus trees growing in abundance, thanks in part to the Spanish explorers who had brought oranges with them on their ships and had discarded the seeds in the new world. This gave rise to the planting of citrus groves. The "Big Freeze" of 1894-1895 destroyed most of the citrus groves in the county.
A very early industry in the area was the turpentine business. Many of the barges during the Civil War blockade had been carrying turpentine, likely from the turpentine still of William Turner, who resided in Red Level. Other early industry in the Crystal River area included cedar mills. In 1882, James Williams moved his cedar mill to Crystal River, and began operating on King's Bay. The mill produced pencil boards, which were then shipped to Jersey City, New Jersey, by ship, and later on by train. The Dixon Cedar Mill was one of the largest industries in Crystal River, providing employment to many in the area, including women and African Americans.
Crystal River had been part of Hernando County since its inception in 1843. In 1844, the county name changed from "Hernando" to "Benton", in honor of Senator Thomas Hart Benton who had sponsored the Armed Occupation Act of 1842, which had brought settlers to the area. The county name returned to Hernando in 1850.
By the late 1800s, the area along the west side of the county was growing rapidly, and the citizens of the area began to see a need for a new county with a county seat that was easier to reach. In 1887, Hernando County was divided into three parts: Pasco County, Hernando County, and Citrus County. The town of Mannfield was named the temporary county seat for two years. Mannfield was chosen as it was in the geographic center of the new county and was more accessible to citizens. The site for the eventual county seat, Inverness, was decided by a vote in 1891.
Phosphate was discovered in 1889 in the east side of Citrus County, and the phosphate industry grew rapidly. Historians have claimed it to be "one of the richest phosphate deposits in the world." The phosphate industry would boom in Crystal River and Citrus County until 1914, when it could no longer be shipped due to World War I.
In 1888, the railroad reached Crystal River. The arrival of the railroad proved to be a boon; it provided an easier way to ship and receive goods, and it was an easier way for tourists to travel. Sport fishing became a draw for many wealthy northerners.
Crystal River became a town in 1903. It was officially incorporated as a city on July 3, 1923.
Demographics.
As of the census of 2010, there were 3,108 people (2012 Estimate: 3,055), 1,401 households, and 794 families residing in the city. The population density was 455.19 people per square mile (1178.9/km²). There were 2,036 housing units at an average density of 343.4 per square mile (132.5/km²). The racial makeup of the city was 83.4% White, 7.4% Black or African American, 0.30% Native American, 2.1% Asian, 0.10% Pacific Islander, 0% from other races, and 1.6% from two or more races. 5.20% of the population was Hispanic or Latino of any race.
There were 1,401 households out of which 18% had children under the age of 18 living with them, 43.0% were married couples living together, 9.6% had a female householder with no husband present, and 43.3% were non-families. 56.7% of all households were made up of individuals and 19.6% had someone living alone who was 65 years of age or older. The average household size was 2.06 and the average family size was 2.61.
In the city the population was spread out with 15.9% under the age of 18, 3.7% from 18 to 24, 15.7% from 25 to 44, 31% from 45 to 64, and 33.9% who were 65 years of age or older. The median age was 56 years. The population was composed of 1,477 males and 1,631 females.
The median income for a household in the city was $35,503, and the median income for a family was $58,398. Males had a median income of $39,357 versus $25,417 for females. The per capita income for the city was $38,219. About 3.5% of families and 9.9% of the population were below the poverty line, including 12.4% of those under age 18 and 9.5% of those aged 65 or over.
Crystal River Mall opened north of the center of town in 1990.
External links.
 Media related to at Wikimedia Commons

</doc>
<doc id="60582" url="http://en.wikipedia.org/wiki?curid=60582" title="Chancellor of Austria">
Chancellor of Austria

The Federal Chancellor (German: "Bundeskanzler", sometimes shortened to "Kanzler") is the head of government of Austria. In his capacity as chairman of the Austrian Federal Government, the chancellor represents the supreme federal authority of the executive branch. Though formally an equal member of the cabinet, the Chancellor is considered to be the most powerful position in Austrian politics, and as such is the nation's "de facto" chief executive. His official seat is in the Federal Chancellery.
The current Chancellor is Werner Faymann, who was appointed upon the 2008 legislative election. His deputy is Reinhold Mitterlehner acting as Vice-Chancellor of Austria.
History.
The use of the term Chancellor ("Kanzler", derived from Latin: "cancellarius") as head of the chancery writing office can be traced back as far as the ninth century, when under King Louis the German the office of the Archchancellor ("Erzkanzler"), later Imperial Chancellor ("Reichserzkanzler"), was created as a high office on the service of the Holy Roman Emperor. The task was usually fulfilled by the Prince-Archbishops of Mainz as Archchancellors of the German lands.
In the course of the Imperial reform, the Habsburg Emperor Maximilian I in 1498 attempted to counter the spiritual power of the "Reichserzkanzler" with a more secular position of an Imperial Court Chancellor ("Hofkanzler"), but the two became merged. These were also the times when attempts were made to balance Imperial absolutism by the creation of Imperial Governments ("Reichsregiment"), ultimately a failure.
Habsburg Monarchy.
Nevertheless, when Maximilian's grandson Ferdinand I succeeded him as Archduke of Austria in 1521, his elder brother Emperor Emperor Charles V (1519–1556) appointed Mercurino Gattinara as "Grand Chancellor of all the realms and kingdoms of the king" ("Großkanzler aller Länder und Königreiche"). The separate position of an Austrian Court Chancellor appeared as a "Österreichische Hofkanzlei" around 1526, when the Habsburg Monarchy arose with the Bohemian and Hungarian inheritance; it was however once again merged with the equivalent "Reichshofkanzlei" office of the Holy Roman Empire in 1559.
Upon the 1620 Battle of White Mountain and the suppression of the Bohemian revolt, Emperor Ferdinand II had separate Court Chancelleries established in order to strengthen the unity of the Habsburg hereditary lands. Beside a Bohemian and Hungarian chancellery, he created the office of an Austrian chancellor in Vienna, responsible for the Archduchy of Austria proper (i.e. Upper and Lower Austria) with the Inner Austrian territories and Tyrol. Under Emperor Leopold I (1658–1705) the term again became "Hofkanzler" with Johann Paul Freiherr von Hocher (1667–1683), and Theodor von Strattman (1683–1693).
The eighteenth century was dominated by Prince Wenzel Anton of Kaunitz-Rietberg (1753–1792), who was Chancellor to four Habsburg emperors from Maria Theresa to Francis II, with the titles of both "Hofkanzler" and "Staatskanzler". He was succeeded by Johann Philipp von Cobenzl (1792–1793), who was dismissed by Emperor Francis II over the Partition of Poland and was succeeded by Johann Amadeus Francis de Paula (Baron Thugot) (1793–1800). Thugot's chancellorship did not survive the Austrian defeats by the French at the battles of Marengo and Hohenlinden in 1800 and he was replaced by Johan Ludwig Joseph Cobenzl (1800–1805), his predecessor's cousin, but who in turn was dismissed following the Austrian defeat at Austerlitz in 1805.
Austrian Empire.
With the consequent dissolution of the Holy Roman Empire and founding of the Austrian Empire, Francis II abdicated the former Imperial Throne, but remained Emperor Francis I of Austria in 1806. He had replaced Cobenzl with Johan Philip Charles Stadion (1805–1809) the previous year, but his career was in turn cut short in 1809 following yet another Austrian defeat by Napoleon at the Battle of Wagram and subsequent humiliation at the Treaty of Schönbrunn. Prince Klemens von Metternich was appointed by Francis I to the positions of "Hofkanzler" and "Staatskanzler" (1821–1848). However there is some opinion that the Chancellor title was not used between Prince Kaunitz-Rietberg's resignation in 1792 and 1821. 
As the Metternich system had become a synonym for his reactionary politics, the title of a State Chancellor was abolished upon the 1848 revolutions. The position became that of a Minister-President of Austria, equivalent to Prime Minister, with the exception of Count Friedrich Ferdinand von Beust (1867–1871)
the title only re-emerging at the birth of German Austria after World War I in 1918, when Karl Renner was appointed "Staatskanzler". With the enactment of the Constitution of Austria on 10 November 1920, the actual term "Bundeskanzler" was implemented as head of the executive branch of the First Austrian Republic.
Appointment.
The Chancellor is appointed and sworn in by the President. In theory, the President can appoint anyone eligible to be elected to the National Council, essentially meaning any Austrian national over the age of 18. In practice, a Chancellor is unable to govern unless he or she commands the confidence of the National Council. The President is therefore generally expected to appoint the leader of the party with the most seats, and only after he or she has established a coalition in control of a National Council majority.
The Chancellor has no term limits. As a matter of constitutional convention, the Chancellor usually offers his or her resignation to the President upon dissolution of the National Council. The President usually declines and directs the Chancellor and his or her cabinet to operate as a caretaker government until a new National Council is in session and a new majority leader has emerged. In fact, the constitution expressly encourages the President to use a Chancellor as his or her own interim successor.
A Chancellor is typically appointed or dismissed together with his or her ministers. Technically, the President can only appoint ministers as nominated by the Chancellor, so the Chancellor is appointed first. Having been sworn in, the Chancellor presents the President with his or her list of ministers; they will usually have been installed just minutes later. Neither Chancellors nor ministers need to be confirmed by either house of parliament; the appointees are fully capable of discharging the functions of their respective offices immediately after having been sworn in.
In theory, the National Council can force the President to dismiss a Chancellor or a minister through a motion of no confidence. The President is constitutionally required to dismiss a cabinet member the National Council declares it wants gone. Opposition parties will sometimes table motions of no confidence against ministers, and occasionally whole cabinets, in order to demonstrate criticism; these motions are not expected to pass and never do.
Role and powers.
The Chancellor chairs the meetings of the cabinet. The constitution does not vest the Chancellor with the authority to issue directions to ministers; it characterizes his or her role in the cabinet as that of a primus inter pares. The power of the office to set policy derives partly from its inherent prestige, partly from the fact that the President is required to dismiss ministers the Chancellors requests removed, and partly from the Chancellor's position of leadership in the party or coalition controlling the National Council.
Most articles of the constitution that mention the office of Chancellor are tasking the incumbent with notarizing decisions by the President or by various constitutional bodies, with ensuring that these decisions are duly announced to the general public, or with acting as an intermediary between various branches of government. In particular, the Chancellor
The Chancellor also convenes the Federal Assembly if the National Council moves to have the President removed from office, or if the National Council moves to lift the immunity of the President from criminal prosecution. In the former case, the Federal Assembly votes on whether to allow a referendum on the matter. In the latter case, the assent of the Federal Assembly is required for the President's immunity to be rescinded.
Finally, the Chancellor becomes Acting President if the President is incapacitated.

</doc>
<doc id="60583" url="http://en.wikipedia.org/wiki?curid=60583" title="André Campra">
André Campra

André Campra (]; baptized 4 December 1660 in Aix-en-Provence – 29 June 1744 in Versailles) was a French composer and conductor. 
Campra was one of the leading French opera composers in the period between Jean-Baptiste Lully and Jean-Philippe Rameau. He wrote several "tragédies en musique", but his chief claim to fame is as the creator of a new genre, "opéra-ballet". He also wrote three books of cantatas as well as religious music, including a requiem.
Biography.
Campra was the son of Jean-François Campra, a surgeon and violinist from Graglia, in Italy, and of Louise Fabry, from Aix-en-Provence. His father was his first music teacher. On December 3, 1660, he was baptised in the Église de la Madeleine in Aix. He became a choirboy in the Cathédrale Saint-Sauveur in Aix in 1674, and commenced ecclesiastical studies four years later. He was reprimanded by his superiors in 1681 for having taken part in theatrical performances without permission, but was nevertheless made a chaplain on 27 May of that year. 
From 1694 to 1700, he was "maître de musique" (music director) at the cathedral of Notre-Dame de Paris, after having served in a similar capacity in Arles and Toulouse. Campra controversially brought violins into the making of sacred music at Notre-Dame de Paris which at the time was seen as very avant-garde due to their reputation as 'street instruments'.
He began to turn toward the theatre in 1697 and published some theatrical compositions under his brother's name to protect his reputation within the church. In 1700 he gave up his post at Notre-Dame and concentrated on his theatrical music to critical success. By 1705 he was a musical celebrity but this resulted in him becoming a target for negative articles in the press. From 1720 onwards, he returned to the composition of sacred music. Although Campra had obtained critical success he did not have financial security and hence in 1722 he was engaged by the Prince of Conti as "maître de musique" although this appointment was short lived. After the death of the regent, Campra became "sous-maître" at the Royal Chapel in Versailles in 1723. In 1730 he became the "Inspecteur Général" at the Opéra (Royal Academy of Music).
He died at the age of 83.
With his composition of "L'Europe galante" he was the true genius of the "opéra-ballet", a musical genre originated by Pascal Colasse (in his "Ballet des saisons"). Campra also wrote the Rigaudon.
Legacy.
A theme from his 1717 opera "Camille" was used as the basis of the collaborative work "La guirlande de Campra" by seven French composers, written in 1952.
It is likely that his best known, or most often heard, piece is the "Rigaudon" from his opera "Idoménée", in an arrangement for the
pipe organ. It is very frequently used as a wedding processional, and is often recorded in that respect by many organists making musically polyglot recordings of generic "wedding music". 
A state-owned secondary school in the centre of Aix-en-Provence, is named after André Campra, "Collège Campra". There is a statue of Campra inside one of the buildings.
References.
Notes
Sources

</doc>
<doc id="60584" url="http://en.wikipedia.org/wiki?curid=60584" title="Christian Democratic Union of Germany">
Christian Democratic Union of Germany

The Christian Democratic Union of Germany (German: "Christlich Demokratische Union Deutschlands", CDU; ]) is a Christian democratic and liberal-conservative political party in Germany. It is the major catch-all party of the centre-right in German politics. Along with its Bavarian sister party the Christian Social Union in Bavaria (CSU), the CDU forms the CDU/CSU grouping, also known as the Union, in the Bundestag.
The leader of the party, Angela Merkel, is the current Chancellor of Germany. The CDU is a member of the European People's Party (EPP) and sits in the EPP Group in the European Parliament. Internationally, the CDU is a member of the Centrist Democrat International and the International Democrat Union. The CDU is the second-largest political party in Germany by total membership.
History.
Adenauer Era.
Immediately following the collapse of the Nazi dictatorship at the end of World War II, the need for a new political order in Germany was imminent. Simultaneous yet unrelated meetings began occurring throughout Germany, each with the intention of planning a “Christian-democratic party.” The “Christlich-Demokratische Union” was established in Berlin on 26 June 1945, and in Rheinland and Westfalen in September of the same year.
The founding members of the CDU consisted primarily of former members of the Centre Party, German Democratic Party, German National People’s Party, and German People’s Party. Many of these individuals, including CDU-Berlin founder Andreas Hermes and future chancellor of Germany Konrad Adenauer, were imprisoned for the involvement in the German Resistance during the Nazi dictatorship. In the Cold War years, after World War II up to the 1960s, the CDU also attracted conservative, anti-Communist former Nazis and Nazi collaborators into its higher ranks (like Hans Globke and Theodor Oberländer). A prominent anti-Nazi member was theologian Eugen Gerstenmaier who became Acting Chairman of the Foreign Board (1949-1969).
One of the lessons learned from the failure of the Weimar Republic was that disunity among the democratic parties ultimately allowed for the rise of the Nazi Party. It was therefore crucial to create a unified party of Christian Democrats – a Christian Democratic ‘’Union’’. The result of these meetings was the establishment of an inter-confessional (Catholic and Protestant alike) party influenced heavily by the political tradition of liberal conservatism. The CDU experienced considerable success gaining support from the time of its creation in Berlin on 26 June 1945 until its first convention on 21 October 1950, at which Chancellor Adenauer was named the first Chairman of the party.
In the beginning, it was not clear which party would be favored by the victors of the Second World War, but by the end of the 1940s, the governments of the United States and of Britain began to lean toward the CDU and away from the Social Democratic Party of Germany (SPD). The latter was more nationalist and sought German reunification, even at the expense of concessions to the Soviet Union, depicting Adenauer as an instrument of both the Americans and the Vatican. The Western powers appreciated the CDU's moderation, its economic flexibility and its value as an oppositional force to the Communists, which appealed to European voters at the time. Also, Adenauer was trusted by the British.
The party was split over issues of rearmament within the Western alliance and German unification as a neutral state. Adenauer staunchly defended his pro-Western position and outmanoeuvred some of his opponents. He also refused to consider the SPD as a party of the coalition until he felt sure that they shared his anti-Communist position. The principled rejection of a reunification that would alienate Germany from the Western alliance made it harder to attract Protestant voters to the party, as most refugees from the former German territories east of the Oder were of that faith, as were the majority of the inhabitants of East Germany.
Cold War.
The CDU was the dominant party for the first two decades following the establishment of West Germany in 1949. Konrad Adenauer remained the party’s leader until 1963, at which point the former minister of economics Ludwig Erhard replaced him. As the Free Democratic Party (FDP) withdrew from the governing coalition in 1966 due to disagreements over fiscal and economic policy, Erhard was forced to resign. Consequently, a grand coalition with the SPD took over government under CDU Chancellor Kurt Georg Kiesinger.
The SPD quickly gained popularity and succeeded in forming a social-liberal coalition with the FDP following the 1969 federal election, forcing the CDU out of power for the first time in their history. The CDU continued its role as opposition until 1982, when the FDP’s withdrawal from the coalition with the SPD allowed the CDU to regain power. CDU Chairman Helmut Kohl became the new Chancellor of West Germany and his CDU-FDP coalition was confirmed in the 1983 federal election. Public support for the coalition’s work in the process of German reunification was reiterated in the 1990 federal election, in which the CDU-FDP governing coalition experienced a clear victory.
After the collapse of the East German government in 1989, Kohl – supported by the governments of the United States, and (reluctantly) by those of France and the United Kingdom – called for German reunification. On 3 October 1990, the German Democratic Republic (GDR) was abolished and its territory annexed by West Germany. The East German CDU merged with its West German counterpart, and elections were held for the reunified country. Although Kohl was re-elected, the party began losing much of its popularity because of an economic recession in the former GDR and increased taxes in the west. The CDU was, however, able to win the 1994 federal election by a narrow margin due to an economic recovery.
Helmut Kohl served as chairman until the party's electoral defeat in 1998, when he was succeeded by Wolfgang Schäuble; Schäuble resigned in early 2000 as a result of a party financing scandal and was replaced by Angela Merkel, who remains the leader of the CDU to this day. In the 1998 federal election, the CDU polled 28.4% and the CSU 6.7% of the national vote, which was the lowest result for CDU/CSU since 1949. Thus, a Red-Green coalition under the leadership of Gerhard Schröder took power until 2005. In 2002, the CDU and CSU polled slightly higher – 29.5% and 9.0%, respectively – but still lacked the majority needed for a CDU-FDP coalition government.
Merkel Era.
In 2005 early elections were called after the CDU dealt the governing SPD a major blow, winning more than ten state elections, most of which were landslide victories. The resulting grand coalition between the CDU/CSU and the SPD faced a serious challenge stemming from both parties’ demand for the chancellorship. After three weeks of negotiations, however, the two parties reached a deal whereby CDU received the chancellorship while the SPD retained 8 of the 16 seats in the cabinet and a majority of the most prestigious cabinet posts. The coalition deal was approved by both parties at party conferences on November 14. Merkel was confirmed as the first female Chancellor of Germany by the majority of delegates (397 to 217) in the newly assembled Bundestag on 22 November.
Although the CDU/CSU lost support in the 2009 federal elections, the FDP experienced the best election cycle in their history, thereby enabling a CDU/CSU-FDP coalition. This marked the first change of coalition partner by a Chancellor in German history.
The loss of anti-Communism as a political theme, secularization, and the cultural revolutions occurring since the 1960s have challenged the viability of the CDU. In her 2005 campaign, Angela Merkel was unwilling to express explicitly Christian views, while maintaining that her party had never lost its "concept of values". Merkel and Bundestag President Norbert Lammert have been keen to clarify that CDU references to the "dominant culture" imply "tolerance and living together". According to party analyst Stephan Eisel however, her avoiding the values-issue may have had the opposite effect as she failed to mobilize the party's core constituency.
While Adenauer and Erhard co-operated with non-Nazi parties to their right, later the CDU has worked to marginalize its right-wing opposition.
Party platform.
The CDU applying the principles of Christian democracy and emphasising the "Christian understanding of humans and their responsibility toward God." CDU membership consists however of people adhering to a variety of religions as well as non-religious individuals. The CDU's policies derive from political Catholicism, Catholic social teaching and political Protestantism, as well as fiscal conservatism and national conservatism. The CDU was the first proponent of the social market economy, although the party has adopted more liberal economics policies since Helmut Kohl's term in office as the Chancellor of Germany (1982–1998). In terms of foreign policy, the CDU commits itself to European integration and a strong relation with the United States. In the European Union, the party opposes the entry of Turkey into the EU, preferring instead a privileged partnership with Turkey. In addition to citing various human rights violations, the CDU also believes that Turkey's unwillingness to recognise Cyprus as an independent, sovereign state contradicts the EU policy that its members must recognise the existence of one another. Domestically, the CDU emphasises curtailing red tape and the preservation of cultural traditions.
Opponents of the CDU are the Social Democratic Party of Germany (SPD), The Left party and Alliance '90/The Greens. The CDU has however governed in three federal-level and numerous state-level Grand Coalitions with the SPD as well as in state and local-level coalitions with the Alliance '90/The Greens. The CDU rejects coalitions with either far-left or far-right parties.
The Free Democratic Party (FDP), a classical liberal party, is the preferred partner of any CDU government since the CDU and FDP have similar attitudes towards fiscal policy. As a conservative party, the CDU supports stronger punishments of crimes and supports involvement on the part of the Bundeswehr in cases of domestic anti-terrorism offensives. In terms of immigrants, the CDU supports initiatives to integrate immigrants through language courses, and aims to further control immigration. Dual citizenship should only be allowed in exceptional cases.
Internal structure.
Members.
In May 2012, the CDU had 484,397 members. The number has dropped by 3.1% in 2011 and 3.0% in 2010. The members' average age was 59 years. 6% of the Christian Democrats were under 30 years old. A 2007 study by the Konrad Adenauer Foundation showed that 25.4% of members were female and 74.6% male. Female participation was higher in the former East German states with 29.2% compared to 24.8% in the former West German states.
Before 1966, membership totals in CDU organisation were only estimated. The numbers after 1966 are based on the total from 31 December of the previous year.
Party strongholds.
The traditional strongholds of the party are concentrated in rural and Catholic regions such as the Eifel, Münsterland, Sauerland, Fulda district, Emsland, Oldenburger Münsterland, the Thuringia Eichsfeld as well as areas in Nordfriesland, Saxony, Schwaben, Vorpommern, North Saarland, Taunus, and smaller cities such as Baden-Baden, Konstanz, and Pforzheim. There is less support in Bremen, in Brandenburg, and in East Berlin.
Relationship with the CSU.
Both the CDU and the Christian Social Union in Bavaria (CSU) originated after World War II, sharing a concern for the Christian worldview. In the Federal Parliament (Bundestag), the CDU is represented in a common faction with the CSU. This faction is called CDU/CSU or, informally, "the Union;" its basis is a binding agreement known as a "Fraktionsvertrag" between the two parties.
The CDU and CSU share a common youth organisation, the Junge Union.
On issues of federal policies the CDU and CSU do not differ, but they remain legally and organisationally separate parties. The social differences between the CDU and the somewhat more socially conservative CSU have sometimes been a source of conflict in the past. The most notable and serious such incident was in 1976, when the CSU under Franz Josef Strauß ended the alliance with the CDU at a party conference in Wildbad Kreuth. This decision was reversed shortly thereafter when the CDU threatened to run candidates against the CSU in Bavaria.
The relationship of CDU to the CSU has historic parallels to previous Christian democratic parties in Germany, with the Catholic Centre Party having served as a national Catholic party throughout the German Empire and the Weimar Republic with the Bavarian People's Party functioning as the Bavarian variant.
Since its formation, the CSU has been more conservative than the CDU. The CSU and the state of Bavaria decided not to sign the Basic Law for the Federal Republic of Germany, as they insisted on more autonomy for the individual states. The CSU and the free state of Bavaria have a separate police and justice system (distinctive and non-federal), and have actively participated in all political affairs of the German Parliament, the German Government, the German Bundesrat, the parliamentary elections of the German President, the European Parliament, and meetings with Gorbachev in Russia.
Konrad Adenauer Foundation.
The Konrad Adenauer Foundation is the think-tank of the CDU. It is named after the first Chancellor of the Federal Republic of Germany and first president of the CDU. The foundation offers political education, conducts scientific fact-finding research for political projects, grants scholarships to gifted individuals, researches the history of Christian democracy, and supports and encourages European unification, international understanding, and development-policy cooperation. Its annual budget amounts to around 120 million Euro.
Special organizations.
Notable suborganisations of the CDU are:

</doc>
<doc id="60585" url="http://en.wikipedia.org/wiki?curid=60585" title="Social Democratic Party of Germany">
Social Democratic Party of Germany

The Social Democratic Party of Germany (German: "Sozialdemokratische Partei Deutschlands", SPD) is a social-democratic political party in Germany. The party is one of the two major contemporary political parties in Germany, along with the conservative CDU/CSU, and is led by Sigmar Gabriel.
The SPD currently governs at the federal level in a so-called grand coalition with the Christian Democratic Union and the Christian Social Union since December 2013 following the results of the German Federal election of 2013. The party participates in 14 state governments, of which nine are governed by SPD Minister-Presidents.
The SPD is a member of the Party of European Socialists and the Socialist International, and was a founding member of the Progressive Alliance on 22 May 2013. Established in 1863, the SPD is the oldest existent political party represented in German Parliament. It was also one of the first Marxist-influenced parties in the world.
History.
The General German Workers' Association ("Allgemeiner Deutscher Arbeiterverein", ADAV), founded in 1863, and the Social Democratic Workers' Party ("Sozialdemokratische Arbeiterpartei Deutschlands", SDAP), founded in 1869, merged in 1875, under the name Socialist Workers' Party of Germany ("Sozialistische Arbeiterpartei Deutschlands", SAPD). From 1878 to 1890, any grouping or meeting that aimed at spreading socialist principles was banned under the Anti-Socialist Laws, but the party still gained support in elections. In 1890, when the ban was lifted and it could again present electoral lists, the party adopted its current name. In the years leading up to World War I, the party remained ideologically radical in official principle, although many party officials tended to be moderate in everyday politics. By 1912, the party claimed the most votes of any German party.
Despite the agreement of the Second International to oppose the First World War, the SPD voted in favor of war in 1914. In response to this and the Bolshevik Revolution, members of the left and of the far-left of the SPD formed alternative parties, first the Spartacus League, then the Independent Social Democratic Party of Germany and later the Communist Party of Germany. After 1918 the SPD played an important role in the political system of the Weimar Republic, although it took part in coalition governments only in few years (1918–1921, 1923, 1928–1930).Adolf Hitler prohibited the party in 1933 under the Enabling Act - party officials were imprisoned, killed or went into exile. In exile, the party used the name Sopade.
In 1945, the allied occupants in the Western zones initially allowed four parties to be established, which led to the Christian Democratic Union, the Free Democratic Party, the Communist Party of Germany, and the SPD being established. In the Soviet Zone of Occupation, the Soviets forced the Social Democrats to form a common party with the Communists (Socialist Unity Party of Germany or SED). In the Western zones, the Communist Party was later (1956) banned by West Germany's Federal Constitutional Court. Since 1949, in the Federal Republic of Germany, the SPD has been one of the two major parties, with the other being the Christian Democratic Union. From 1969 to 1982 and 1998 to 2005 the Chancellors of Germany were Social Democrats whereas the other years the Chancellors were Christian Democrats.
Party platform.
The SPD was established as a Marxist party in 1875. However, the SPD underwent a major shift in policies reflected in the differences between the Heidelberg Program of 1925, which "called for the transformation of the capitalist system of private ownership of the means of production to social ownership", and the Godesberg Program of 1959, which aimed to broaden its voter base and move its political position toward the centre. After World War II, under the leadership of Kurt Schumacher, the SPD re-established itself as a socialist party, representing the interests of the working class and the trade unions. With the Godesberg Program of 1959, however, the party evolved from a socialist working-class party to a modern social-democratic party working within capitalism.
The current party platform of the SPD espouses the goal of social democracy, which is seen as a vision of a societal arrangement in which freedom and social justice are paramount. According to the party platform, freedom, justice, and social solidarity, form the basis of social democracy. The coordinated social market economy should be strengthened, and its output should be distributed fairly. The party sees that economic system as necessary in order to ensure the affluence of the entire population. The SPD also tries to protect the society's poor with a welfare state. Concurrently, it advocates a sustainable fiscal policy that doesn't place a burden on future generations while eradicating budget deficits. In social policy, the SPD stands for civil and political rights in an open society. In foreign policy, the SPD aims at ensuring global peace by balancing global interests with democratic means. Thus, European integration is one of the main priorities of the SPD. SPD supports economic regulations to limit potential losses for banks and people. They support a common European economic and financial policy, and to prevent speculative bubbles. They support environmentally sustainable growth. 
Internal groupings.
The SPD is mostly composed of members belonging to either of the two main wings: Keynesian social democrats, and the Third Way, moderate social democrats belonging to the Seeheimer Kreis. While the moderate, Seeheimer Kreis social democrats strongly support the Agenda 2010 reformist programs introduced by former Chancellor Gerhard Schröder, the Keynesian social democrats continue to defend classical left-wing policies such as the apology of the welfare state. The classical left-wing of the SPD claims that in recent years the welfare state has been curtailed through reform programs such as the Agenda 2010, Hartz IV and the more economic liberal stance of the SPD, which were endorsed by right-wing social democrats. As a reaction to the Agenda 2010 there was 2005 the ascension of an inner party dissident movement, which leads ultimately to the foundation of the new party Labour and Social Justice – The Electoral Alternative ("Arbeit & soziale Gerechtigkeit - Die Wahlalternative" (WASG)). 
The WASG was later emerged into the party Die Linke ("The Left") 2007. 
Base of support.
Social structure.
Before World War II, as the main non-revolutionary left-wing party, the Social Democrats fared best among non-Catholic workers as well as intellectuals favouring social progressive causes and increased economic equality. Led by Kurt Schumacher after World War II, the SPD initially opposed both the social market economy and Konrad Adenauer's drive towards western integration fiercely, but after Schumacher's death, it accepted the social market economy and Germany's position in the Western alliance in order to appeal to a broader range of voters. It still remains associated with the economic causes of unionised employees and working class voters. In the 1990s, the left and moderate wings of the party drifted apart, culminating in a secession of a significant number of party members, which later joined the socialist party WASG, which later merged into The Left ("Die Linke") party.
Geographic distribution.
Geographically, much of the SPD's current-day support comes from large cities, especially of northern and western Germany and Berlin. The metropolitan area of the Ruhr Area, where coal mining and steel production were once the biggest sources of revenues, have provided a significant base for the SPD in the 20th century. In the state Free Hanseatic City of Bremen, made up of the cities of Bremen and Bremerhaven, the SPD has governed without interruption since 1949. In southern Germany, the SPD typically garners less support except in the largest cities. At the 2009 federal election, the party lost its only constituency in the entire state of Bavaria (in Munich). Small town and rural support comes especially from the traditionally Protestant areas of northern Germany and Brandenburg (with notable exceptions such as Western Pomerania where CDU leader Angela Merkel was re-elected in 2005) and a number of university towns. A striking example of the general pattern is the traditionally Catholic Emsland, where the Social Democrats generally gain a low percentage of votes, whereas the Reformed Protestant region of East Frisia directly to the north, with its strong traditional streak of anti-Catholism, is one of their strongest constituencies. Further south, the SPD also enjoys solid support in northern Hesse (Hans Eichel was mayor of Kassel, then Hesse's minister president, then finance minister in the Schröder administration, while Brigitte Zypries served as Justice Minister), parts of Palatinate (Kurt Beck was party leader until 7 September 2008), the Saarland (political home of one-time candidate for federal chancellor Oskar Lafontaine, defected from the SPD in 1999), and southwestern Baden (Marion Caspers-Merk, Gernot Erler).

</doc>
<doc id="60587" url="http://en.wikipedia.org/wiki?curid=60587" title="Johann Pachelbel">
Johann Pachelbel

Johann Pachelbel (]; baptised September 1, 1653 – buried March 9, 1706) was a German composer, organist and teacher who brought the south German organ tradition to its peak. He composed a large body of sacred and secular music, and his contributions to the development of the chorale prelude and fugue have earned him a place among the most important composers of the middle Baroque era.
Pachelbel's music enjoyed enormous popularity during his lifetime; he had many pupils and his music became a model for the composers of south and central Germany. Today, Pachelbel is best known for the "Canon in D", as well as the "Chaconne in F minor", the "Toccata in E minor" for organ, and the "Hexachordum Apollinis", a set of keyboard variations.
Pachelbel's music was influenced by southern German composers, such as Johann Jakob Froberger and Johann Kaspar Kerll, Italians such as Girolamo Frescobaldi and Alessandro Poglietti, French composers, and the composers of the Nuremberg tradition. He preferred a lucid, uncomplicated contrapuntal style that emphasized melodic and harmonic clarity. His music is less virtuosic and less adventurous harmonically than that of Dieterich Buxtehude, although, like Buxtehude, Pachelbel experimented with different ensembles and instrumental combinations in his chamber music and, most importantly, his vocal music, much of which features exceptionally rich instrumentation. Pachelbel explored many variation forms and associated techniques, which manifest themselves in various diverse pieces, from sacred concertos to harpsichord suites.
Life.
1653–1674: Early youth and education (Nuremberg, Altdorf, Regensburg).
Johann Pachelbel was born in 1653 in Nuremberg into a middle-class family, son of Johann (Hans) Pachelbel (born 1613 in Wunsiedel, Germany), a wine dealer, and his second wife Anna (Anne) Maria Mair. The exact date of Johann's birth is unknown, but since he was baptized on September 1, he may have been born in late August.
During his early youth, Pachelbel received musical training from Heinrich Schwemmer, a musician and music teacher who later became the cantor of St. Sebaldus Church ("Sebalduskirche"). Some sources indicate that Pachelbel also studied with Georg Caspar Wecker, organist of the same church and an important composer of the Nuremberg school, but this is now considered unlikely. In any case, both Wecker and Schwemmer were trained by Johann Erasmus Kindermann, one of the founders of the Nuremberg musical tradition, who had been at one time a pupil of Johann Staden.
Johann Mattheson, whose "Grundlage einer Ehrenpforte" (Hamburg, 1740) is one of the most important sources of information about Pachelbel's life, mentions that the young Pachelbel demonstrated exceptional musical and academic abilities. He received his primary education in St. Lorenz Hauptschule and the "Auditorio Aegediano" in Nuremberg, then on 29 June 1669 he became a student at the University of Altdorf, where he was also appointed organist of St. Lorenz church the same year. Financial difficulties forced Pachelbel to leave the university after less than a year. In order to complete his studies he became a scholarship student, in 1670, at the "Gymnasium Poeticum" at Regensburg. The school authorities were so impressed by Pachelbel's academic qualifications that he was admitted above the school's normal quota.
Pachelbel was also permitted to study music outside the Gymnasium. His teacher was Kaspar ("Caspar") Prentz, once a student of Johann Kaspar Kerll. Since the latter was greatly influenced by Italian composers such as Giacomo Carissimi, it is likely through Prentz that Pachelbel started developing an interest in contemporary Italian music, and Catholic church music in general.
1673–1690: Career (Vienna, Eisenach, Erfurt).
Prentz left for Eichstätt in 1672. This period of Pachelbel's life is the least documented one, so it is unknown whether he stayed in Regensburg until 1673 or left the same year his teacher did; at any rate, by 1673 Pachelbel was living in Vienna, where he became a deputy organist at the famous Saint Stephen Cathedral ("Stephansdom"). At the time, Vienna was the center of the vast Habsburg empire and had much cultural importance; its tastes in music were predominantly Italian. Several renowned cosmopolitan composers worked there, many of them contributing to the exchange of musical traditions in Europe. In particular, Johann Jakob Froberger served as court organist in Vienna until 1657 and was succeeded by Alessandro Poglietti. Georg Muffat lived in the city for some time, and, most importantly, Johann Kaspar Kerll moved to Vienna in 1673. While there, he may have known or even taught Pachelbel, whose music shows traces of Kerll's style. Pachelbel spent five years in Vienna, absorbing the music of Catholic composers from southern Germany and Italy. In some respects, Pachelbel is similar to Haydn, who too served as a professional musician of the "Stephansdom" in his youth and as such was exposed to music of the leading composers of the time.
In 1677, Pachelbel moved to Eisenach, where he found employment as court organist under Kapellmeister Daniel Eberlin (also a native of Nuremberg), in the employ of Johann Georg I, Duke of Saxe-Eisenach. He met members of the Bach family in Eisenach (which was the home city of J. S. Bach's father, Johann Ambrosius Bach), and became a close friend of Johann Ambrosius and tutor to his children. However, Pachelbel spent only one year in Eisenach. In 1678, Bernhard II, Duke of Saxe-Jena, Johann Georg's brother, died and during the period of mourning court musicians were greatly curtailed. Pachelbel was left unemployed. He requested a testimonial from Eberlin, who wrote one for him, describing Pachelbel as a 'perfect and rare virtuoso' – "einen perfekten und raren Virtuosen". With this document, Pachelbel left Eisenach on May 18, 1678.
In June 1678, Pachelbel was employed as organist of the Predigerkirche in Erfurt, succeeding Johann Effler (c. 1640–1711; Effler later preceded Johann Sebastian Bach in Weimar). The Bach family was very well known in Erfurt (where virtually all organists would later be called "Bachs"), so Pachelbel's friendship with them continued here. Pachelbel became godfather to Johann Ambrosius' daughter, Johanna Juditha, taught Johann Christoph Bach (1671–1721), Johann Sebastian's eldest brother, and lived in Johann Christian Bach's (1640–1682) house. Pachelbel remained in Erfurt for 12 years and established his reputation as one of the leading German organ composers of the time during his stay. The chorale prelude became one of his most characteristic products of the Erfurt period, since Pachelbel's contract specifically required him to compose the preludes for church services. His duties also included organ maintenance and, more importantly, composing a large-scale work every year to demonstrate his progress as composer and organist, as every work of that kind had to be better than the one composed the year before.
Johann Christian Bach (1640-1682), Pachelbel's landlord in Erfurt, died in 1682. In June 1684, Pachelbel purchased the house (called "Zur silbernen Tasche", now Junkersand 1) from Johann Christian's widow. In 1686, he was offered a position as organist of the St. Trinitatis church ("Trinitatiskirche") in Sondershausen. Pachelbel initially accepted the invitation but, as a surviving autograph letter indicates, had to reject the offer after a long series of negotiations: it appears that he was required to consult with Erfurt's elders and church authorities before considering any job offers. It seems that the situation had been resolved quietly and without harm to Pachelbel's reputation; he was offered a raise and stayed in the city for four more years.
Pachelbel married twice during his stay in Erfurt. Barbara Gabler, daughter of the Stadt-Major of Erfurt, became his first wife, on 25 October 1681. The marriage took place in the house of the bride's father. Unfortunately, both Barbara and their only son died in October 1683 during a plague. Pachelbel's first published work, a set of chorale variations called "Musicalische Sterbens-Gedancken" ("Musical Thoughts on Death", Erfurt, 1683), was probably influenced by this event.
Ten months later, Pachelbel married Judith Drommer (Trummert), daughter of a coppersmith, on 24 August 1684. They had five sons and two daughters. Two of the sons, Wilhelm Hieronymus Pachelbel and Charles Theodore Pachelbel, also became organ composers; the latter moved to the American colonies in 1734. Another son, Johann Michael, became an instrument maker in Nuremberg and traveled as far as London and Jamaica. One of the daughters, Amalia Pachelbel, achieved recognition as a painter and engraver.
1690–1706: Final years (Stuttgart, Gotha, Nuremberg).
Although Pachelbel was an outstandingly successful organist, composer, and teacher at Erfurt, he asked permission to leave, apparently seeking a better appointment, and was formally released on 15 August 1690, bearing a testimonial praising his diligence and fidelity.
He was employed in less than a fortnight: from 1 September 1690, he was a musician-organist in the Württemberg court at Stuttgart under the patronage of Duchess Magdalena Sibylla. That job was better, but, unfortunately, he lived there only two years before fleeing the French attacks of the War of the Grand Alliance. His next job was in Gotha as the town organist, a post he occupied for two years, starting on 8 November 1692; there he published his first, and only, liturgical music collection: "Acht Chorale zum Praeambulieren" in 1693 ("Erster Theil etlicher Choräle").
When former pupil Johann Christoph Bach married in October 1694, the Bach family celebrated the marriage on 23 October 1694 in Ohrdruf, and invited him and other composers to provide the music; he probably attended – if so, it was the only time J.S. Bach, then nine years old, met Johann Pachelbel.
In his three years in Gotha, he was twice offered positions, in Stuttgart and at Oxford University; he declined both. Meanwhile, in Nuremberg, when the St. Sebaldus Church organist Georg Caspar Wecker (and his possible former teacher) died on 20 April 1695, the city authorities were so anxious to appoint Pachelbel (then a famous Nuremberger) to the position that they officially invited him to assume it without holding the usual job examination or inviting applications from prominent organists from lesser churches. He accepted, was released from Gotha in 1695, and arrived in Nuremberg in summer, with the city council paying his per diem expenses.
Pachelbel lived the rest of his life in Nuremberg, during which he published the chamber music collection "Musicalische Ergötzung", and, most importantly, the "Hexachordum Apollinis" (Nuremberg, 1699), a set of six keyboard arias with variations. Though most influenced by Italian and southern German composers, he knew the northern German school, because he dedicated the "Hexachordum Apollinis" to Dieterich Buxtehude. Also composed in the final years were Italian-influenced concertato Vespers and a set of more than ninety Magnificat fugues.
Johann Pachelbel died at the age of 52, 3 March 1706, and was buried on 9 March; Mattheson cites either 3 March or 7 March 1706 as the death date; yet, it is unlikely that the corpse was allowed to linger unburied so long. Contemporary custom was to bury the dead on the third or fourth post-mortem day; so, either 6 or 7 March 1706 is a likelier death date. He is buried in the St. Rochus Cemetery.
Posthumous influence.
One of the last middle Baroque composers, Pachelbel did not have any considerable influence on most of the famous late Baroque composers, such as George Frideric Handel, Domenico Scarlatti or Georg Philipp Telemann. He did influence Johann Sebastian Bach indirectly; the young Johann Sebastian was tutored by his older brother Johann Christoph Bach, who studied with Pachelbel, but although J.S. Bach's early chorales and chorale variations borrow from Pachelbel's music, the style of northern German composers, such as Georg Böhm, Dieterich Buxtehude, and Johann Adam Reincken, played a more important role in the development of Bach's talent.
Pachelbel was the last great composer of the Nuremberg tradition and the last important southern German composer. Pachelbel's influence was mostly limited to his pupils, most notably Johann Christoph Bach, Johann Heinrich Buttstett, Andreas Nicolaus Vetter, and two of Pachelbel's sons, Wilhelm Hieronymus and Charles Theodore. The latter became one of the first European composers to take up residence in the American colonies and so Pachelbel influenced, although indirectly and only to a certain degree, the American church music of the era. Composer, musicologist and writer Johann Gottfried Walther is probably the most famous of the composers influenced by Pachelbel – he is, in fact, referred to as the "second Pachelbel" in Mattheson's "Grundlage einer Ehrenpforte".
As the Baroque style went out of fashion during the 18th century, the majority of Baroque and pre-Baroque composers were virtually forgotten. Local organists in Nuremberg and Erfurt knew Pachelbel's music and occasionally performed it, but the public and the majority of composers and performers did not pay much attention to Pachelbel and his contemporaries. In the first half of the 19th century, some organ works by Pachelbel were published and several musicologists started considering him an important composer, particularly Philipp Spitta, who was one of the first researchers to trace Pachelbel's role in the development of Baroque keyboard music. Much of Pachelbel's work was published in the early 20th century in the "Denkmäler der Tonkunst in Österreich" series, but it was not until the rise of interest in early Baroque music in the middle of the 20th century and the advent of historically-informed performance practice and associated research that Pachelbel's works began to be studied extensively and again performed more frequently.
Popularity of the Canon in D.
Pachelbel's "Canon in D major", a piece of chamber music scored for three violins and basso continuo and originally paired with a gigue in the same key, experienced a tremendous surge in popularity during the 1970s. This is believed to be due to a recording by Jean-François Paillard in 1970, which made it a universally recognized cultural item. Its visibility was greatly increased by its choice as the theme music for the popular film "Ordinary People". Now one of the most recognized and famous baroque compositions, it has in recent years become extremely popular for use in weddings, rivalling Wagner's "Bridal Chorus".
Works.
During his lifetime, Pachelbel was best known as an organ composer. He wrote more than two hundred pieces for the instrument, both liturgical and secular, and explored most of the genres that existed at the time. Pachelbel was also a prolific vocal music composer: around a hundred of such works survive, including some 40 large-scale works. Only a few chamber music pieces by Pachelbel exist, although he might have composed many more, particularly while serving as court musician in Eisenach and Stuttgart.
Several principal sources exist for Pachelbel's music, although none of them as important as, for example, the Oldham manuscript is for Louis Couperin. Among the more significant materials are several manuscripts that were lost before and during World War II but partially available as microfilms of the Winterthur collection, a two-volume manuscript currently in possession of the Oxford Bodleian library which is a major source for Pachelbel's late work, and the first part of the "Tabulaturbuch" (1692, currently at the Biblioteka Jagiellońska in Kraków) compiled by Pachelbel's pupil Johann Valentin Eckelt, which includes the only known Pachelbel autographs). The Neumeister Collection and the so-called Weimar tablature of 1704 provide valuable information about Pachelbel's school, although they do not contain any pieces that can be confidently ascribed to him.
Currently there is no standard numbering system for Pachelbel's works. Several catalogues are used, by Antoine Bouchard (POP numbers, organ works only), Jean M. Perreault (P numbers, currently the most complete catalogue; organized alphabetically), Hideo Tsukamoto (T numbers, L for lost works; organized thematically) and Kathryn Jane Welter (PC numbers).
Keyboard music.
Much of Pachelbel's liturgical organ music, particularly the chorale preludes, is relatively simple and written for manuals only: no pedal is required. This is partly due to Lutheran religious practice where congregants sang the chorales. Household instruments like virginals or clavichords accompanied the singing, so Pachelbel and many of his contemporaries made music playable using these instruments. The quality of the organs Pachelbel used also played a role: south German instruments were not, as a rule, as complex and as versatile as the north German ones, and Pachelbel's organs must have only had around 15–25 stops on two manuals (compare to Buxtehude's Marienkirche instrument with 52 stops, 15 of them in the pedal). Finally, neither the Nuremberg nor the southern German organ tradition endorsed extensive use of pedals seen in the works by composers of the northern German school.
Only two volumes of Pachelbel's organ music were published and distributed during his lifetime: "Musikalische Sterbens-Gedancken" (Musical Thoughts on Death; Erfurt, 1683) – a set of chorale variations in memory of his deceased wife and child, and "Acht Choräle" (Nuremberg, 1693).
Pachelbel employed white mensural notation when writing out numerous compositions (several chorales, all ricercars, some fantasias); a notational system that uses hollow note heads and omits bar lines (measure delimiters). The system had been widely used since the 15th century but was gradually being replaced in this period by modern notation (sometimes called "black notation"). In most cases Pachelbel used white notation for pieces composed in old-fashioned styles, to provide artistic integrity.
Chorales.
Chorales constitute almost half of Pachelbel's surviving organ works, in part because of his Erfurt job duties which required him to compose chorale preludes on a regular basis. The models Pachelbel used most frequently are the three-part cantus firmus setting, the chorale fugue and, most importantly, a model he invented which combined the two types. This latter type begins with a brief chorale fugue that is followed by a three- or four-part cantus firmus setting. Chorale phrases are treated one at a time, in the order in which they occur; frequently, the accompanying voices anticipate the next phrase by using bits of the melody in imitative counterpoint. An example from "Wenn mein Stündlein vorhanden ist":
The piece begins with a chorale fugue (not shown here) that turns into a four-part chorale setting which starts at bar 35. The slow-moving chorale (the "cantus firmus", i.e., the original hymn tune) is in the soprano, and is highlighted in blue. The lower voices anticipate the shape of the second phrase of the chorale in an imitative fashion (notice the distinctive pattern of two repeated notes). Pachelbel wrote numerous chorales using this model ("Auf meinen lieben Gott", "Ach wie elend ist unsre Zeit", "Wenn mein Stündlein vorhanden ist", etc.), which soon became a standard form.
A distinctive feature of almost all of Pachelbel's chorale preludes is his treatment of the melody: the cantus firmus features virtually no figuration or ornamentation of any kind, always presented in the plainest possible way in one of the outer voices. Pachelbel's knowledge of both ancient and contemporary chorale techniques is reflected in "Acht Choräle zum Praeambulieren", a collection of eight chorales he published in 1693. It included, among other types, several chorales written using outdated models. Of these, "Nun lob, mein Seel, den Herren" is based on the hymn by Johann Gramann, a paraphrase of Psalm 103; it is one of the very few Pachelbel chorales with cantus firmus in the tenor. "Wir glauben all an einen Gott" is a three-part setting with melodic ornamentation of the chorale melody, which Pachelbel employed very rarely. Finally, "Jesus Christus, unser Heiland der von uns" is a typical bicinium chorale with one of the hands playing the unadorned chorale while the other provides constant fast-paced accompaniment written mostly in sixteenth notes. Pachelbel only used the bicinium form in two other pieces.
Fugues.
Pachelbel wrote more than one hundred fugues on free themes. These fall into two categories: some 30 free fugues and around 90 of the so-called Magnificat Fugues. His fugues are usually based on non-thematic material, and are shorter than the later model (of which those of J.S. Bach are a prime example). The contrapuntal devices of stretto, diminution and inversion are not employed in any of them. Nevertheless, Pachelbel's fugues display a tendency towards a more unified, subject-dependent structure which was to become the key element of late Baroque fugues. Given the number of fugues he composed and the extraordinary variety of subjects he used, Pachelbel is regarded as one of the key composers in the evolution of the form. He was also the first major composer to pair a fugue with a preludial movement (a toccata or a prelude) – this technique was adopted by later composers and was used extensively by J.S. Bach.
The Magnificat Fugues were all composed during Pachelbel's final years in Nuremberg. The singing of the Magnificat at Vespers was usually accompanied by the organist, and earlier composers provided examples of Magnificat settings for organ, based on themes from the chant. Pachelbel's fugues, however, are almost all based on free themes and it is not yet understood exactly where they fit during the service. It is possible that they served to help singers establish pitch, or simply act as introductory pieces played before the beginning of the service. There are 95 pieces extant, covering all eight church modes: 23 in "primi toni", 10 in "secundi toni", 11 in "tertii toni", 8 in "quarti toni", 12 in "quinti toni", 10 in "sexti toni", 8 in "septimi toni" and 13 in "octavi toni". Although a few two- and four-voice works are present, most employ three voices (sometimes expanding to four-voice polyphony for a bar or two). With the exception of the three double fugues (primi toni No. 12, sexti toni No. 1 and octavi toni No. 8), all are straightforward pieces, frequently in common time and comparatively short – at an average tempo, most take around a minute and a half to play.
Although most of them are brief, the subjects are extremely varied (see Example 1). Frequently some form of note repetition is used to emphasize a rhythmic (rather than melodic) contour. Many feature a dramatic leap (up to an octave), which may or may not be mirrored in one of the voices sometime during an episode – a characteristic Pachelbel technique, although it was also employed by earlier composers, albeit less pronounced. Minor alterations to the subject between the entries are observed in some of the fugues, and simple countersubjects occur several times. An interesting technique employed in many of the pieces is an occasional resort to "style brisé" for a few bars, both during episodes and in codas. The double fugues exhibit a typical three-section structure: fugue on subject 1, fugue on subject 2, and the counterpoint with simultaneous use of both subjects.
Most of Pachelbel's free fugues are in three or four voices, with the notable exception of two bicinia pieces that were probably intended for teaching purposes. Pachelbel frequently used repercussion subjects of different kinds, with note repetition sometimes extended to span a whole measure (such as in the subject of a G minor fugue, see illustration). Some of the fugues employ textures more suited for the harpsichord, particularly those with broken chord figuration. The three ricercars Pachelbel composed, that are more akin to his fugues than to ricercars by Frescobaldi or Froberger, are perhaps more technically interesting. In the original sources, all three use white notation and are marked alla breve. The polythematic C minor ricercar is the most popular and frequently performed and recorded. It is built on two contrasting themes (a slow chromatic pattern and a lively simplistic motif) which appear in their normal and inverted forms and concludes with both themes appearing simultaneously. The F-sharp minor ricercar uses the same concept and is slightly more interesting musically: the key of F-sharp minor requires a more flexible tuning than the standard meantone temperament of the Baroque era and was therefore rarely used by contemporary composers. This means that Pachelbel may have used his own tuning system, of which little is known. "Ricercare in C major" is probably an early work, mostly in three voices and employing the same kind of writing with consecutive thirds as seen in Pachelbel's toccatas (see below).
Pachelbel's use of repercussion subjects and extensive repeated note passages may be regarded as another characteristic feature of his organ pieces. Extreme examples of note repetition in the subject are found in magnificat fugues: quarti toni No. 4 has eight repeated notes, octavi toni No. 6 has twelve. Also, even a fugue with an ordinary subject can rely on strings of repeated notes, as it happens, for example, in magnificat fugue octavi toni No. 12:
Chaconnes and variations.
Pachelbel's apparent affinity for variation form is evident from his organ works that explore the genre: chaconnes, chorale variations and several sets of arias with variations. The six chaconnes, together with Buxtehude's ostinato organ works, represent a shift from the older chaconne style: they completely abandon the dance idiom, introduce contrapuntal density, employ miscellaneous chorale improvisation techniques, and, most importantly, give the bass line much thematic significance for the development of the piece. Pachelbel's chaconnes are distinctly south German in style; the duple meter C major chaconne (possibly an early work) is reminiscent of Kerll's D minor passacaglia. The remaining five works are all in triple meter and display a wide variety of moods and techniques, concentrating on melodic content (as opposed to the emphasis on harmonic complexity and virtuosity in Buxtehude's chaconnes). The ostinato bass is not necessarily repeated unaltered throughout the piece and is sometimes subjected to minor alterations and ornamentation. The D major, D minor and F minor chaconnes are among Pachelbel's most well-known organ pieces, and the latter is often cited as his best organ work.
In 1699 Pachelbel published "Hexachordum Apollinis" (the title is a reference to Apollo's lyre), a collection of six variations set in different keys. It is dedicated to composers Ferdinand Tobias Richter (a friend from the Vienna years) and Dieterich Buxtehude. Each set follows the "aria and variations" model, arias numbered "Aria prima" through "Aria sexta" ("first" through "sixth"). The final piece, which is also the most well-known today, is subtitled "Aria Sebaldina", a reference to St. Sebaldus Church where Pachelbel worked at the time. Most of the variations are in common time, with Aria Sebaldina and its variations being the only notable exceptions–they are in 3/4 time. The pieces explore a wide range of variation techniques.
Pachelbel's other variation sets include a few arias and an arietta (a short aria) with variations and a few pieces designated as chorale variations. Four works of the latter type were published in Erfurt in 1683 under the title "Musicalische Sterbens-Gedancken" ("Musical Thoughts on Death"), which might refer to Pachelbel's first wife's death in the same year. This was Pachelbel's first published work and it is now partially lost. These pieces, along with Georg Böhm's works, may or may not have influenced Johann Sebastian Bach's early organ partitas.
Toccatas.
About 20 toccatas by Pachelbel survive, including several brief pieces referred to as "toccatinas" in the Perreault catalogue. They are characterized by consistent use of pedal point: for the most part, Pachelbel's toccatas consist of relatively fast passagework in both hands over sustained pedal notes. Although a similar technique is employed in toccatas by Froberger and Frescobaldi's pedal toccatas, Pachelbel distinguishes himself from these composers by having no sections with imitative counterpoint–in fact, unlike most toccatas from the early and middle Baroque periods, Pachelbel's contributions to the genre are not sectional, unless rhapsodic introductory passages in a few pieces (most notably the E minor toccata) are counted as separate sections. Furthermore, no other Baroque composer used pedal point with such consistency in toccatas.
Many of Pachelbel's toccatas explore a single melodic motif, and later works are written in a simple style in which two voices interact over sustained pedal notes, and said interaction – already much simpler than the virtuosic passages in earlier works – sometimes resorts to consecutive thirds, sixths or tenths. Compare the earlier D major toccata, with passages in the typical middle Baroque style, with one of the late C major toccatas:
Sometimes a bar or two of consecutive thirds embellish the otherwise more complex toccata-occasionally there is a whole section written in that manner; and a few toccatas (particularly one of the D minor and one of the G minor pieces) are composed using only this technique, with almost no variation. Partly due to their simplicity, the toccatas are very accessible works; however, the E minor and C minor ones which receive more attention than the rest are in fact slightly more complex.
Fantasias.
Pachelbel composed six fantasias. Three of them (the A minor, C major and one of the two D Dorian pieces) are sectional compositions in 3/2 time; the sections are never connected thematically; the other D Dorian piece's structure is reminiscent of Pachelbel's magnificat fugues, with the main theme accompanied by two simple countersubjects.
The E-flat major and G minor fantasias are variations on the Italian "toccata di durezze e ligature" genre. Both are gentle free-flowing pieces featuring intricate passages in both hands with many accidentals, close to similar pieces by Girolamo Frescobaldi or Giovanni de Macque.
Preludes.
Almost all pieces designated as preludes resemble Pachelbel's toccatas closely, since they too feature virtuosic passagework in one or both hands over sustained notes. However, most of the preludes are much shorter than the toccatas: the A minor prelude (pictured below) only has 9 bars, the G major piece has 10. The only exception is one of the two D minor pieces, which is very similar to Pachelbel's late simplistic toccatas, and considerably longer than any other prelude. The toccata idiom is completely absent, however, in the short "Prelude in A minor":
A texture of similar density is also found in the ending of the shorter D minor piece, where three voices engage in imitative counterpoint. In pairs of preludes and fugues Pachelbel aimed to separate homophonic, improvisatory texture of the prelude from the strict counterpoint of the fugue.
Other keyboard music.
Around 20 dance suites transmitted in a 1683 manuscript (now destroyed) were previously attributed to Pachelbel, but today his authorship is questioned for all but three suites, numbers 29, 32 and 33B in the Seiffert edition. The pieces are clearly not without French influence (but not so much as Buxtehude's) and are comparable in terms of style and technique to Froberger's suites. Seventeen keys are used, including F-sharp minor. Number 29 has all four traditional movements, the other two authentic pieces only have three (no gigue), and the rest follow the classical model (Allemande, Courante, Sarabande, Gigue), sometimes updated with an extra movement (usually less developed), a more modern dance such as a gavotte or a ballet. All movements are in binary form, except for two arias.
Chamber music.
Pachelbel's chamber music is much less virtuosic than Biber's "Mystery Sonatas" or Buxtehude's Opus 1 and Opus 2 chamber sonatas. The famous "Canon in D" belongs to this genre, as it was originally scored for 3 violins and a basso continuo, and paired with a gigue in the same key. The canon is actually more of a chaconne or a passacaglia: it consists of a ground bass over which the violins play a three-voice canon based on a simple theme, the violins' parts form 28 variations of the melody. The gigue which originally accompanied the canon is a simple piece that uses strict fugal writing.
"Musicalische Ergötzung" ("Musical Delight") is a set of six chamber suites for two scordatura violins and basso continuo published sometime after 1695. At the time, scordatura tuning was used to produce special effects and execute tricky passages. However, Pachelbel's collection was intended for amateur violinists, and scordatura tuning is used here as a basic introduction to the technique. Scordatura only involves the tonic, dominant and sometimes the subdominant notes.
Each suite of "Musikalische Ergötzung" begins with an introductory "Sonata" or "Sonatina" in one movement. In suites 1 and 3 these introductory movements are "Allegro" three-voice fughettas and stretti. The other four sonatas are reminiscent of French overtures. They have two "Adagio" sections which juxtapose slower and faster rhythms: the first section uses patterns of dotted quarter and eighth notes in a non-imitative manner. The second employs the violins in an imitative, sometimes homophonic structure, that uses shorter note values. The dance movements of the suites show traces of Italian (in the gigues of suites 2 and 6) and German (allemande appears in suites 1 and 2) influence, but the majority of the movements are clearly influenced by the French style. The suites do not adhere to a fixed structure: the allemande is only present in two suites, the gigues in four, two suites end with a chaconne, and the fourth suite contains two arias.
Pachelbel's other chamber music includes an aria and variations ("Aria con variazioni in A major") and four standalone suites scored for a string quartet or a typical French five-part string ensemble with 2 violins, 2 violas and a violone (the latter reinforces the basso continuo). Of these, the five-part suite in G major ("Partie a 5 in G major") is a variation suite, where each movement begins with a theme from the opening sonatina; like its four-part cousin ("Partie a 4 in G major") and the third standalone suite ("Partie a 4 in F-sharp minor") it updates the German suite model by using the latest French dances such as the gavotte or the ballet. The three pieces mentioned all end with a "Finale" movement. Interestingly, "Partie a 4 in G major" features no figuration for the lower part, which means that it was not a basso continuo and that, as Jean M. Perreault writes, "this work may well count as the first true string quartet, at least within the Germanophone domain."
Vocal music.
Johann Gottfried Walther famously described Pachelbel's vocal works as "more perfectly executed than anything before them". Already the earliest examples of Pachelbel's vocal writing, two arias "So ist denn dies der Tag" and "So ist denn nur die Treu" composed in Erfurt in 1679 (which are also Pachelbel's earliest datable pieces), display impressive mastery of large-scale composition ("So ist denn dies der Tag" is scored for soprano, SATB choir, 2 violins, 3 violas, 4 trumpets, timpani and basso continuo) and exceptional knowledge of contemporary techniques.
These latter features are also found in Pachelbel's Vespers pieces and sacred concertos, large-scale compositions which are probably his most important vocal works. Almost all of them adopt the modern concertato idiom and many are scored for unusually large groups of instruments ("Jauchzet dem Herrn, alle Welt (in C)" uses four trumpets, timpani, 2 violins, 3 violas, violone and basso continuo; "Lobet den Herrn in seinem Heiligtum" is scored for a five-part chorus, two flutes, bassoon, five trumpets, trombone, drums, cymbals, harp, two violins, basso continuo and organ). Pachelbel explores a very wide range of styles: psalm settings ("Gott ist unser Zuversicht"), chorale concertos ("Christ lag in Todesbanden"), sets of chorale variations ("Was Gott tut, das ist wohlgetan"), concerted motets, etc. The ensembles for which these works are scored are equally diverse: from the famous D major Magnificat setting written for a 4-part choir, 4 violas and basso continuo, to the "Magnificat in C major" scored for a five-part chorus, 4 trumpets, timpani, 2 violins, a single viola and two violas da gamba, bassoon, basso continuo and organ.
Pachelbel's large-scale vocal works are mostly written in modern style influenced by Italian Catholic music, with only a few non-concerted pieces and old plainchant cantus firmus techniques employed very infrequently. The string ensemble is typical for the time, three viols and two violins. The former are either used to provide harmonic content in instrumental sections or to double the vocal lines in tutti sections; the violins either engage in contrapuntal textures of varying density or are employed for ornamentation. Distinct features of Pachelbel's vocal writing in these pieces, aside from the fact that it is almost always very strongly tonal, include frequent use of permutation fugues and writing for paired voices. The Magnificat settings, most composed during Pachelbel's late Nuremberg years, are influenced by the Italian-Viennese style and distinguish themselves from their antecedents by treating the canticle in a variety of ways and stepping away from text-dependent composition.
Other vocal music includes motets, arias and two masses. Of the eleven extant motets, ten are scored for two four-part choruses. Most of this music is harmonically simple and makes little use of complex polyphony (indeed, the polyphonic passages frequently feature reduction of parts). The texts are taken from the psalms, except in "Nun danket alle Gott" which uses a short passage from the "Ecclesiastes". The motets are structured according to the text they use. One important feature found in "Gott ist unser Zuversicht" and "Nun danket alle Gott" is that their endings are four-part chorale settings reminiscent of Pachelbel's organ chorale model: the chorale, presented in long note values, is sung by the sopranos, while the six lower parts accompany with passages in shorter note values:
The arias, aside from the two 1679 works discussed above, are usually scored for solo voice accompanied by several instruments; most were written for occasions such as weddings, birthdays, funerals and baptisms. They include both simple strophic and complex sectional pieces of varying degrees of complexity, some include sections for chorus. The concerted "Mass in C major" is probably an early work; the D major "Missa brevis" is a small mass for a SATB choir in three movements (Kyrie, Gloria, Credo). It is simple, unadorned and reminiscent of his motets.

</doc>
<doc id="60588" url="http://en.wikipedia.org/wiki?curid=60588" title="Bill Monroe">
Bill Monroe

William Smith Monroe (; September 13, 1911 – September 9, 1996) was an American mandolinist, singer, and songwriter who created the style of music known as bluegrass. The genre takes its name from his band, the Blue Grass Boys, named for Monroe's home state of Kentucky. Monroe's performing career spanned 69 years as a singer, instrumentalist, composer and bandleader. He is often referred to as the Father of Bluegrass.
Early life.
Monroe was born on his family's farm near Rosine, Kentucky, the youngest of eight children of James Buchanan "Buck" and Malissa (Vandiver) Monroe. His mother and her brother, Pendleton "Pen" Vandiver, were both musically talented, and Monroe and his family grew up playing and singing at home. Bill was of Scottish heritage. Because his older brothers Birch and Charlie already played the fiddle and guitar, Bill Monroe was resigned to playing the less desirable mandolin. He recalled that his brothers insisted he should remove four of the mandolin's eight strings so he would not play too loudly.
Monroe's mother died when he was ten, followed by his father six years later. As his brothers and sisters had moved away, after bouncing among uncles and aunts, Monroe settled in with his disabled uncle Pendleton Vandiver, often accompanying him when Vandiver played the fiddle at dances. This experience inspired one of Monroe's most famous compositions, "Uncle Pen", recorded in 1950, and the 1972 album, "Bill Monroe's Uncle Pen". On that album, Monroe recorded a number of traditional fiddle tunes he had often heard performed by Vandiver. Uncle Pen has been credited with giving Monroe "a repertoire of tunes that sank into Bill's aurally trained memory and a sense of rhythm that seeped into his bones." Also significant in Monroe's musical life was Arnold Shultz, an influential fiddler and guitarist who introduced Monroe to the blues.
Professional career.
In 1929, Monroe moved to Indiana to work at an oil refinery with his brothers Birch and Charlie, and childhood friend and guitarist William "Old Hickory" Hardin. Together with a friend Larry Moore, they formed the "Monroe Brothers", to play at local dances and house parties. Birch Monroe and Larry Moore soon left the group, and Bill and Charlie carried on as a duo, eventually winning spots performing live on radio stations— first in Indiana and then, sponsored by Texas Crystals, on several radio broadcasts in Iowa, Nebraska, South Carolina and North Carolina 1934 to 1936. RCA Victor signed the Monroe Brothers to a recording contract in 1936. They scored an immediate hit single with the gospel song "What Would You Give in Exchange For Your Soul?" and ultimately recorded 60 tracks for Victor's Bluebird label between 1936 and 1938.
After the Monroe Brothers disbanded in 1938, Bill Monroe formed The Kentuckians in Little Rock, Arkansas, but the group only lasted for three months. Monroe then left Little Rock for Atlanta, Georgia, to form the first edition of the Blue Grass Boys with singer/guitarist Cleo Davis, fiddler Art Wooten, and bassist Amos Garren. Bill had wanted "Old Hickory" to become one of the original members of his "Blue Grass Boys", however William Hardin had to decline. In October 1939, he successfully auditioned for a regular spot on the Grand Ole Opry, impressing Opry founder George D. Hay with his energetic performance of Jimmie Rodgers's "Mule Skinner Blues". Monroe recorded that song, along with seven others, at his first solo recording session for RCA Victor in 1940; by this time, the Blue Grass Boys consisted of singer/guitarist Clyde Moody, fiddler Tommy Magness, and bassist Bill Wesbrooks.
While the fast tempos and instrumental virtuosity characteristic of bluegrass music are apparent even on these early tracks, Monroe was still experimenting with the sound of his group. He seldom sang lead vocals on his Victor recordings, often preferring to contribute high tenor harmonies as he had in the Monroe Brothers. A 1945 session for Columbia Records featured an accordion, soon dropped from the band. Most importantly, while Monroe added banjo player David "'Stringbean" Akeman to the Blue Grass Boys in 1942, Akeman played the instrument in a relatively primitive style and was rarely featured in instrumental solos. Monroe's pre-1946 recordings represent a transitional style between the string-band tradition from which he came and the musical innovation to follow.
The "Original Bluegrass Band" and Monroe's heyday as a star.
A key development occurred in Monroe's music with the addition of North Carolina banjo prodigy Earl Scruggs to the Blue Grass Boys in December 1945. Scruggs played the instrument with a distinctive three-finger picking style that immediately caused a sensation among Opry audiences. Scruggs joined a highly accomplished group that included singer/guitarist Lester Flatt, and would soon include fiddler Chubby Wise, and bassist Howard Watts, who often performed under the name "Cedric Rainwater". In retrospect, this lineup of the Blue Grass Boys has been dubbed the "Original Bluegrass Band", as Monroe's music finally included all the elements that characterize the genre, including breakneck tempos, sophisticated vocal harmony arrangements, and impressive instrumental proficiency demonstrated in solos or "breaks" on the mandolin, banjo, and fiddle. By this point, Monroe had acquired the 1923 Gibson F5 model "Lloyd Loar" mandolin which became his trademark instrument for the remainder of his career.
The 28 songs recorded by this version of the Blue Grass Boys for Columbia Records in 1946 and 1947 soon became classics of the genre, including "Toy Heart", "Blue Grass Breakdown", "Molly and Tenbrooks", "Wicked Path of Sin", "My Rose of Old Kentucky", "Little Cabin Home on the Hill", and Monroe's most famous song, "Blue Moon of Kentucky". The last-named was recorded by Elvis Presley in 1954, appearing as the B-side of his first single for Sun Records. Monroe gave his blessing to Presley's rock-and-roll cover of the song, originally a slow ballad in waltz time, and in fact re-recorded it himself with a faster arrangement after Presley's version became a hit. Several gospel-themed numbers are credited to the "Blue Grass Quartet", which featured four-part vocal arrangements accompanied solely by mandolin and guitar – Monroe's usual practice when performing "sacred" songs.
Both Flatt and Scruggs left Monroe's band in early 1948, soon forming their own group, the Foggy Mountain Boys. In 1949, after signing with Decca Records, Monroe entered what has been called the "golden age" of his career with what many consider the classic "high lonesome" version of the Blue Grass Boys, featuring the lead vocals and rhythm guitar of Jimmy Martin, the banjo of Rudy Lyle (replacing Don Reno), and fiddlers such as Merle "Red" Taylor, Charlie Cline, Bobby Hicks and Vassar Clements. This band recorded a number of bluegrass classics, including "My Little Georgia Rose", "On and On", "Memories of Mother and Dad", and "Uncle Pen", as well as instrumentals such as "Roanoke", "Big Mon", "Stoney Lonesome", "Get Up John" and the mandolin feature "Raw Hide". Carter Stanley joined the Blue Grass Boys as guitarist for a short time in 1951 during a period when the Stanley Brothers had temporarily disbanded.
On January 16, 1953 Monroe was critically injured in a two-car wreck. He and "Bluegrass Boys" bass player, Bessie Lee Mauldin, were returning home from a fox hunt north of Nashville. On highway 31-W, near White House, their car was struck by a drunken driver. Monroe, who had suffered injuries to his back, left arm and nose, was rushed to General Hospital in Nashville. It took him almost four months to recover and resume touring. In the meantime Charlie Cline and Jimmy Martin kept the band together.
By the late 1950s, however, Monroe's commercial fortunes had begun to slip. The rise of rock-and-roll and the development of the "Nashville sound" in mainstream country music both represented threats to the viability of bluegrass. While still a mainstay on the Grand Ole Opry, Monroe found diminishing success on the singles charts, and struggled to keep his band together in the face of declining demand for live performances.
The folk revival.
Monroe's fortunes began to improve during the "folk revival" of the early 1960s. Many college students and other young people were beginning to discover Monroe, associating his style more with traditional folk music than with the country-and-western genre with which it had previously been identified. The word "bluegrass" first appeared around this time to describe the sound of Monroe and similar artists such as Flatt and Scruggs, the Stanley Brothers, Reno and Smiley, Jim and Jesse, and the Osborne Brothers. While Flatt and Scruggs immediately recognized the potential for a lucrative new audience in cities and on college campuses in the North, Monroe was slower to respond. Under the influence of Ralph Rinzler, a young musician and folklorist from New Jersey who briefly became Monroe's manager in 1963, Monroe gradually expanded his geographic reach beyond the traditional southern country music circuit. Rinzler was also responsible for a lengthy profile and interview in the influential folk music magazine "Sing Out!" that first publicly referred to Monroe as the "father" of bluegrass. Accordingly, at the first bluegrass festival organized by Carlton Haney at Roanoke, Virginia in 1965, Bill Monroe was the central figure.
The growing national popularity of Monroe's music during the 1960s was also apparent in the increasingly diverse background of musicians recruited into his band. Non-southerners who served as Blue Grass Boys during this period included banjo player Bill Keith and singer/guitarist Peter Rowan from Massachusetts, fiddler Gene Lowinger from New York, banjo player Lamar Grier from Maryland, banjo player Steve Arkin from New York, and singer/guitarist Roland White and fiddler Richard Greene from California.
Later years.
Even after the folk revival faded in the mid-1960s, it left a loyal audience for bluegrass music. Bluegrass festivals became common, with fans often traveling long distances to see a number of different acts over several days of performances.
In 1967 Monroe himself founded an annual bluegrass festival at Bean Blossom in southern Indiana, a park he had purchased in 1951, which routinely attracted a crowd of thousands; a double LP from the festival featuring Monroe, Jimmy Martin, Lester Flatt, and Jim and Jesse was released in 1973. The annual "Bill Monroe Bean Blossom Bluegrass Festival" is now the world's oldest continuously running annual bluegrass festival.
Monroe's compositions during his later period were largely instrumentals, including "Jerusalem Ridge", "Old Dangerfield" (originally spelled Daingerfield after the town in East Texas), and "My Last Days on Earth"; he settled into a new role as a musical patriarch who continued to influence younger generations of musicians. Monroe recorded two albums of duets in the 1980s; the first featured collaborations with country stars such as Emmylou Harris, Waylon Jennings, and the Oak Ridge Boys, while the second paired him with other prominent bluegrass musicians. A 1989 live album celebrated his 50th year on the Grand Ole Opry. Monroe also kept a hectic touring schedule. On April 7, 1990, Monroe performed for Farm Aid IV in Indianapolis, Indiana along with Willie Nelson, John Mellencamp, Neil Young and with many other artists.
Death.
Monroe's last performance occurred on March 15, 1996. He ended his touring and playing career in April, following a stroke. Monroe died on September 9, 1996, in Springfield, Tennessee, only four days before his 85th birthday.
Awards and legacy.
Bill Monroe was made an honorary Kentucky colonel in 1966. He was inducted into the Country Music Hall of Fame in 1970, the Nashville Songwriters Hall of Fame in 1971, and the Rock and Roll Hall of Fame (as an "early influence") in 1997. Jimmie Rodgers, Bob Wills, Hank Williams Sr., and Johnny Cash are the only other performers honored in all three. As the "father of bluegrass", he was also an inaugural inductee into the International Bluegrass Music Hall of Honor in 1991. In 1993, he received the Grammy Lifetime Achievement Award, and he was awarded the National Medal of Arts in 1995. His well-known song "Blue Moon of Kentucky" has been covered not only by bluegrass but also rock and country artists, most notably Elvis Presley, Paul McCartney, and Patsy Cline. In 2003, CMT had Bill Monroe ranked No. 16 on "CMT 40 Greatest Men of Country Music".
Artists that claimed to be influenced by or to be playing the bluegrass genre were often bullied by Bill Monroe. He always considered himself the father and caretaker of bluegrass. He would often say of new bands that did not perform to his standards, "That ain't no part of nothin'."
Even those who question the scope of bluegrass refer to Monroe as a "musical giant" and recognize that "there would be no bluegrass without Bill Monroe."
Artists influenced by Monroe.
More than 150 musicians played in the Blue Grass Boys over the nearly 60 years of Monroe's performing career. Monroe tended to recruit promising young musicians who served an apprenticeship with him before becoming accomplished artists in their own right. Some of Monroe's band members who went on to greater prominence include singer/guitarists Clyde Moody, Lester Flatt, Jack Cook, Mac Wiseman, Jimmy Martin, Carter Stanley, Del McCoury, Peter Rowan, Roland White, Roland Dunn and Doug Green; banjo players Earl Scruggs, Buck Trent Don Reno, Sonny Osborne, and Bill Keith; and fiddlers Tommy Magness, Chubby Wise, Vassar Clements, Byron Berline, Kenny Baker, Bobby Hicks, Gordon Terry, and Glen Duncan. Monroe also regularly performed with flat-picking guitar virtuoso Doc Watson.
Modern bluegrass singer and mandolin player Ricky Skaggs was influenced by Monroe. Skaggs was only six years old, in 1960, when he first got to perform on stage with Monroe and his band at the high school in Martha, KY. He stated, "I think Bill Monroe's importance to American music is as important as someone like Robert Johnson was to blues, or Louis Armstrong. He was so influential: I think he's probably the only musician that had a whole style of music named after his band".
Pseudonyms used by Monroe as a composer.
Joe Ahr; Rupert Jones; Wilbur Jones; Albert Price; James B. Smith; James W. Smith

</doc>
<doc id="60589" url="http://en.wikipedia.org/wiki?curid=60589" title="Grand Ole Opry">
Grand Ole Opry

The Grand Ole Opry is a weekly country-music stage concert in Nashville, Tennessee, which has presented the biggest stars of that genre. Founded on November 28, 1925, by George D. Hay as a one-hour radio "barn dance" on WSM and currently owned and operated by Ryman Hospitality Properties, Inc., it is the longest-running radio broadcast in history, albeit not the longest-running one on a radio network. Dedicated to honoring country music and its history, the Opry showcases a mix of legends and contemporary chart-toppers performing country, bluegrass, folk, gospel, and comedic performances and skits. Considered an American icon, it attracts hundreds of thousands of visitors from around the world and millions of radio and Internet listeners.
The Opry"'"s current primary slogan is "The Show that Made Country Music Famous". Other slogans include "Home of American Music" and "Country’s Most Famous Stage".
In the 1930s the show began hiring professionals and expanded to four hours; and WSM, broadcasting by then with 50,000 watts, made the program a Saturday night musical tradition in nearly 30 states. In 1939, it debuted nationally on NBC Radio. The "Opry" moved to a permanent home, the Ryman Auditorium, in 1943. As it developed in importance, so did the city of Nashville, which became America's "country music capital". The "Grand Ole Opry" holds such significance in Nashville that its name is included on the city/county line signs on all major roadways. The signs read "Music City | Metropolitan Nashville Davidson County | Home of the Grand Ole Opry". 
Membership in the Opry remains one of country music's crowning achievements. Such country music legends as Hank Williams, Patsy Cline, Marty Robbins, Roy Acuff, the Carter family, Bill Monroe, Ernest Tubb, Kitty Wells and Minnie Pearl became regulars on the Opry's stage (although Williams was dismissed in 1952 due to frequent drunkenness). In recent decades, the Opry has hosted such contemporary country stars as Dolly Parton, Garth Brooks, Reba McEntire, Josh Turner, Carrie Underwood, Brad Paisley, Rascal Flatts, Dierks Bentley, Blake Shelton and the Dixie Chicks. Since 1974, the show has been broadcast from the Grand Ole Opry House east of downtown Nashville, and performances have been sporadically televised in addition to the radio programs.
History.
Beginnings.
The Grand Ole Opry started as the "WSM Barn Dance" in the new fifth-floor radio studio of the National Life & Accident Insurance Company in downtown Nashville on November 28, 1925. On October 18, 1925, management began a program featuring "Dr. Humphrey Bate and his string quartet of old-time musicians." On November 2, WSM hired long-time announcer and program director George D. "Judge" Hay, an enterprising pioneer from the "National Barn Dance" program at WLS in Chicago, who was also named the most popular radio announcer in America as a result of his radio work with both WLS and WMC in Memphis, Tennessee. Hay launched the "WSM Barn Dance" with 77-year-old fiddler Uncle Jimmy Thompson on November 28, 1925, which is celebrated as the birth date of the "Grand Ole Opry".
Some of the bands regularly on the show during its early days included Bill Monroe, the Possum Hunters (with Dr. Humphrey Bate), the Fruit Jar Drinkers, the Crook Brothers, the Binkley Brothers' Dixie Clodhoppers, Uncle Dave Macon, Sid Harkreader, Deford Bailey, Fiddlin' Arthur Smith, and the Gully Jumpers.
Judge Hay, however, liked the Fruit Jar Drinkers and asked them to appear last on each show because he wanted to always close each segment with "red hot fiddle playing." They were the second band accepted on "Barn Dance", with the Crook Brothers being the first. When the Opry began having square dancers on the show, the Fruit Jar Drinkers always played for them. In 1926, Uncle Dave Macon, a Tennessee banjo player who had recorded several songs and toured the vaudeville circuit, became its first real star.
Name.
On December 10, 1927 the phrase "Grand Ole Opry" was first uttered on the air. That night, "Barn Dance" followed the NBC Red Network's "Music Appreciation Hour", a program of classical music and selections from Grand Opera presented by classical conductor Walter Damrosch. That night, Damrosch remarked that "there is no place in the classics for realism." In response, Opry presenter George Hay said:
Hay then introduced DeFord Bailey, the man he had dubbed the "Harmonica Wizard", saying:
Bailey then stepped up to the mic to play "The Pan American Blues", his song inspired by the Pan American, an L&N Railroad express/passenger train.
Larger venues.
As audiences for the live show increased, National Life & Accident Insurance's radio venue became too small to accommodate the hordes of fans. They built a larger studio, but it was still not large enough. After several months with no audiences, National Life decided to allow the show to move outside its home offices. In October 1934, the Opry moved into then-suburban Hillsboro Theatre (now the Belcourt); and then on June 13, 1936, to the Dixie Tabernacle in East Nashville. The Opry then moved to the War Memorial Auditorium, a downtown venue adjacent to the State Capitol. A 25-cent admission was charged to try to curb the large crowds, but to no avail. On June 5, 1943, the Opry moved to the Ryman Auditorium.
Top-charting country music acts performed during the Ryman years, including Roy Acuff, called the King of Country Music, Hank Williams, Webb Pierce, Faron Young, Martha Carson, Lefty Frizzell, and many others.
One hour of the "Opry" was nationally-broadcast by the NBC Red Network from 1939 to 1956; for much of its run, it aired one hour after the program that had inspired it, "National Barn Dance". The NBC segment, originally known by the name of its sponsor, "The Prince Albert Show", was first hosted by Acuff, who was succeeded by Red Foley from 1946 to 1954. From October 15, 1955 to September 1956, ABC-TV aired a live, hour-long television version once a month on Saturday nights (sponsored by Ralston-Purina), pre-empting one hour of the then-90-minute "Ozark Jubilee". From 1955–57, Al Gannaway owned and produced both "The Country Show" and "Stars of the Grand Ole Opry," filmed programs syndicated by Flamingo Films. Gannaway's "Stars of the Grand Ole Opry" was the first television show shot in color. 
On October 2, 1954, a teenage Elvis Presley made his only Opry performance. Although the audience reacted politely to his revolutionary brand of rockabilly music, after the show he was told by Opry manager Jim Denny that he ought to return to Memphis to resume his truck-driving career, prompting him to swear never to return.
1960s.
In the 1960s, as the hippie counterculture movement spread, the Opry maintained a strait-laced, conservative image with "longhairs" not being featured on the show. The Byrds were a notable exception. Country-rock pioneer Gram Parsons, who at that time was a member of The Byrds, was in Nashville to work on the band's country-rock album, "Sweetheart of the Rodeo". The band's record label, Columbia Records, had arranged for The Byrds to be allowed to perform at the Ryman on March 15, 1968, a prospect that thrilled Parsons. However, when the band took the stage the audience's response was immediately hostile, resulting in derisive heckling, booing and mocking calls of "tweet, tweet." The Byrds further outraged the Opry establishment by breaking with accepted protocol when they performed Parsons' song "Hickory Wind" instead of the Merle Haggard song "Life in Prison", as had been announced by Tompall Glaser. 
Grand Ole Opry House.
The Ryman Auditorium was home to the "Opry" until 1974. By the late 1960s, National Life & Accident desired a new, larger and more modern home for the long-running radio show. Ryman Auditorium was already 51 years old at the time the "Opry" moved there, was beginning to suffer from disrepair as the downtown neighborhood around it was falling victim to increasing urban decay. Despite these shortcomings, the show's popularity was increasing and its weekly crowds were outgrowing the 3,000-seat venue. The "Opry"'s operators were seeking to build a new air-conditioned theatre with a greater capacity and ample parking in a then-rural area of town, providing visitors a more controlled, safer, and more enjoyable experience. 
National Life & Accident settled on a tract of land (Rudy's Farm) owned by a local sausage manufacturer in the Pennington Bend area of Nashville, nine miles east of downtown. The new "Opry" venue was to be the centerpiece of a grand entertainment complex at that location, which would later come to include Opryland USA Theme Park and Opryland Hotel.
The theme park opened to the public on June 30, 1972, well ahead of the 4,000-seat Opry House, which debuted nearly two years later, on March 16, 1974. 
Opening night, March 16, was attended by sitting U.S. President Richard Nixon, who played a few songs on the piano. To carry on the tradition of the show's run at the Ryman, a six-foot circle of oak was cut from the corner of the Ryman's stage and inlaid into center stage at the new venue. The artists on stage usually stand on the circle as they perform.
When the theme park was closed in 1997 and replaced by the Opry Mills mall in 2000, the Grand Ole Opry House itself was left intact and incorporated into the new facility. 
Currently, the "Grand Ole Opry" plays several times a week between the months of March and October at the Grand Ole Opry House. The show returns to the Ryman (which was renovated in 1994) each year between November and February. This allows the Ryman to remain in regular use during a season with fewer concerts, reduces capacity for the "Opry" during an off-peak tourism season, and also accommodates the "Radio City Christmas Spectacular"'s annual five-week run at the Grand Ole Opry House. 
The Grand Ole Opry House was added to the National Register of Historic Places on January 27, 2015.
2010 flooding.
In May 2010, the Opry House was flooded, along with much of Nashville, due to the Cumberland River overflowing its banks. While repairs were made, the Opry was temporarily housed at alternate venues in Nashville, with the Ryman Auditorium hosting the majority of the shows. Other venues included the TPAC War Memorial Auditorium, another former Opry home; TPAC's Andrew Jackson Hall; Nashville Municipal Auditorium; Allen Arena at Lipscomb University; and the Two Rivers Baptist Church. The Opry returned to the Grand Ole Opry House on September 28, 2010 in a special edition of the Opry entitled "Country Comes Home" that was televised live on Great American Country. The evening was filled with one-of-a-kind Opry moments. Martina McBride and Connie Smith dueted on Smith's signature hit "Once a Day", and other collaborations included Dierks Bentley and Del McCoury ("Roll On Buddy, Roll On"), Josh Turner and Lorrie Morgan ("Golden Ring"), and Montgomery Gentry and Charlie Daniels Band ("Devil Went Down To Georgia"), among others. The show closed with an all-star guitar jam featuring Brad Paisley, Keith Urban, Steve Wariner, Ricky Skaggs, and Marty Stuart.
Broadcasts.
The "Grand Ole Opry" is broadcast live on WSM-AM at 7 p.m. CT on Saturday nights, shortened from a previous time start of 6:30. A similar program, the "Friday Night Opry", airs live on Friday nights. From February through December, the "Tuesday Night Opry" is also aired live. 
The Opry can also be heard live on "Willie's Roadhouse" on channel 59 on Sirius XM Satellite Radio. A condensed radio program, "America's Opry Weekend", is syndicated to stations around the United States. The program is also streamed on WSM's website.
ABC broadcast the Grand Old Opry as a monthly series from 1955–56. PBS televised annual live performances from 1978 to 1981. In 1985, The Nashville Network began airing an edited half-hour version of the program as "Grand Ole Opry Live"; the show moved to Country Music Television (expanding to an hour in the process), and then to the Great American Country (GAC) cable network with its "Opry Live" show currently on hiatus.
Membership.
Being made a member of the Grand Ole Opry, country music's big house, the oldest, most enduring "hall of fame", is to be identified as a member of the elite of country music. In many ways, the artists and repertoire of the Opry defined American country music. Hundreds of performers have entertained as cast members through the years, including new stars, superstars and legends.
Opry membership is not only earned, but must be maintained throughout the artist's career.
Controversies.
In April 1963 Opry management came out with a rule that members had to perform on at least 26 shows a year to keep their membership active. WSM dropped the number of required performances to 20 in January 1964; in 2000 the minimum number of Opry performances was at 12. The minimum number of performances has lessened over the years, but artists offered membership are expected to show a dedication to the Opry with frequent attendance.
Another controversy that raged for years was over allowable instrumentation, especially the use of drums and electrically amplified instruments. Some purists were appalled at the prospect; traditionally a string bass provided the rhythm component in country music and percussion instruments were seldom used. Electric amplification, then new, was regarded as the province of popular music and jazz in 1940s. Though the Opry allowed electric guitars and steel guitars by World War II, the restrictions against drums and horns continued. They caused a conflict when Bob Wills and Pee Wee King defied the show's ban on drums. The restrictions chafed many artists, such as Waylon Jennings, who were popular with the newer and younger fans. These restrictions were largely eliminated over time, alienating many older and traditionalist fans, but probably saving the Opry long-term as a viable ongoing enterprise.
Commercialization.
The company has enforced its trademark on the name "Grand Ole Opry", for which it owns trademark registrations in the United States and in numerous countries around the world. It has taken court action to limit use of the word "opry" (which the organization has not directly trademarked) to members of the Opry and products associated with or licensed by it, and to discourage use of the word in ways that would imply a connection to the Grand Ole Opry. In late 1968, for instance, WSM sued Opry Records, a record label that was independent of WSM, and the court stated that "the record is replete with newspaper and magazine articles and clippings which demonstrate conclusively that the term 'Opry', standing alone as defendant has used it, is constantly used in country and western music circles in referring to plaintiff's 'Grand Ole Opry'." The court also stated "the defendant has appropriated, at its peril, the dominant or salient term in the plaintiff's mark, a term which identified the 'Grand Ole Opry' in the mind of the public many years before the inception of 'Opry Records' – the name adopted by defendant." In another case, the Trademark Trial and Appeal Board granted summary judgment that the term "Opry" is a generic term (and thus no more protected than the words "Grand" or "Ole") but the Federal Circuit court reversed this decision. As recently as 2009, the Trademark Trial and Appeal Board granted judgment against Texas Opry House, LLC, which had filed a trademark application for TEXAS OPRY HOUSE.
In 2004, it was announced that the "Grand Ole Opry" had contracted for the first time with a "presenting sponsor", Cracker Barrel, and the sponsoring company's name would be associated with "Grand Ole Opry" in all its advertising. Humana, Inc., Cracker Barrel, and Dollar General are the present sponsors of the Opry.

</doc>
<doc id="60590" url="http://en.wikipedia.org/wiki?curid=60590" title="Bluegrass music">
Bluegrass music

Bluegrass music is a form of American roots music, and a subgenre of country music. Bluegrass was inspired by the music of Appalachia. It has mixed roots in Irish, Scottish, Welsh, and English traditional music, and also later influenced by the music of African-Americans through incorporation of jazz elements.
Settlers from the United Kingdom and Ireland arrived in Appalachia during the 18th century, and brought with them the musical traditions of their homelands. These traditions consisted primarily of English and Scottish ballads—which were essentially unaccompanied narrative—and dance music, such as Irish reels, which were accompanied by a fiddle. Many older bluegrass songs come directly from the British Isles. Several Appalachian bluegrass ballads, such as "Pretty Saro", "Barbara Allen", "Cuckoo Bird" and "House Carpenter", come from England and preserve the English ballad tradition both melodically and lyrically. Others, such as The Twa Sisters, also come from England; however, the lyrics are about Ireland. Some bluegrass fiddle songs popular in Appalachia, such as "Leather Britches", and "Pretty Polly", have Scottish roots. The dance tune Cumberland Gap may be derived from the tune that accompanies the Scottish ballad Bonnie George Campbell. Other songs have different names in different places; for instance in England there is an old ballad known as "A Brisk Young Sailor Courted Me", but exactly the same song in North American bluegrass is known as "I Wish My Baby Was Born".
In bluegrass, as in some forms of jazz, one or more instruments each takes its turn playing the melody and improvising around it, while the others perform accompaniment; this is especially typified in tunes called breakdowns. This is in contrast to old-time music, in which all instruments play the melody together or one instrument carries the lead throughout while the others provide accompaniment. Breakdowns are often characterized by rapid tempos and unusual instrumental dexterity and sometimes by complex chord changes.
There are three major subgenres of bluegrass and one unofficial subgenre. Traditional bluegrass has musicians playing folk songs, tunes with simple traditional chord progressions, and using only acoustic instruments, with an example being Bill Monroe. Progressive bluegrass groups may use electric instruments and import songs from other genres, particularly rock & roll. Examples include Cadillac Sky and Bearfoot. "Bluegrass gospel" has emerged as a third subgenre, which uses Christian lyrics, soulful three- or four-part harmony singing, and sometimes the playing of instrumentals. A newer development in the bluegrass world is Neo-traditional bluegrass; exemplified by bands such as The Grascals and Mountain Heart, bands from this subgenre typically have more than one lead singer. Bluegrass music has attracted a diverse following worldwide. Bluegrass pioneer Bill Monroe characterized the genre as: "Scottish bagpipes and ole-time fiddlin'. It's Methodist and Holiness and Baptist. It's blues and jazz, and it has a high lonesome sound."
Characteristics.
Instrumentation.
Unlike mainstream country music, bluegrass is traditionally played on acoustic stringed instruments. The fiddle, five-string banjo, guitar, mandolin, and upright bass (string bass) are often joined by the resonator guitar (also referred to as a Dobro) and (occasionally) harmonica or jaw harp. This instrumentation originated in rural dance bands and is the basis on which the earliest bluegrass bands were formed.
The guitar is now most commonly played with a style referred to as flatpicking, unlike the style of seminal bluegrass guitarist Lester Flatt, who used a thumb and finger pick. Banjo players often use the three-finger picking style made popular by Earl Scruggs. Fiddlers frequently play in thirds and fifths, producing a sound that is characteristic to the bluegrass style. Bassists almost always play pizzicato, occasionally adopting the "slap-style" to accentuate the beat. A bluegrass bass line is generally a rhythmic alternation between the tonic and dominant of each chord, with occasional walking bass excursions.
Instrumentation has been an ongoing topic of debate. Traditional bluegrass performers believe the "correct" instrumentation is that used by Bill Monroe's band, the Blue Grass Boys (mandolin, played by Monroe, fiddle, guitar, banjo and bass). Departures from the traditional instrumentation have included accordion, harmonica, piano, autoharp, drums, electric guitar, and electric versions of other common bluegrass instruments, resulting in what has been referred to as "newgrass."
Vocals.
Apart from specific instrumentation, a distinguishing characteristic of bluegrass is vocal harmony featuring two, three, or four parts, often with a dissonant or modal sound in the highest voice (see modal frame), a style described as the "high, lonesome sound." Commonly, the ordering and layering of vocal harmony is called the "stack". A standard stack has a baritone voice at the bottom, the lead in the middle (singing the main melody) and a tenor at the top; although stacks can be altered, especially where a female voice is included. Alison Krauss and Union Station provide a good example of a different harmony stack with a baritone and tenor with a high lead, an octave above the standard melody line, sung by the female vocalist. However, by employing variants to the standard trio vocal arrangement, they were simply following a pattern existing since the early days of the genre. The Stanley Brothers utilized a high baritone part on several of their trios recorded for Columbia records during their time with that label (1950–1953). Mandolin player Pee Wee Lambert sang the high baritone above Ralph Stanley's tenor, both parts above Carter's lead vocal. This trio vocal arrangement was variously used by other groups as well. In the 1960s Flatt and Scruggs often added a fifth part to the traditional quartet parts on gospel songs, the extra part being a high baritone (doubling the baritone part sung in the normal range of that voice; E.P. Tullock [aka Cousin Jake] providing the part). The use of a high lead with the tenor and baritone below it was most famously employed by the Osborne Brothers who first employed it during their time with MGM records in the latter half of the 1950s. This vocal arrangement would be the home aspect of the Osbornes' sound with Bobby's high, clear voice at the top of the vocal stack.
Themes.
Bluegrass tunes can largely be described as narratives on the everyday lives of the people whence the music came. Aside from laments about loves lost, interpersonal tensions and unwanted changes to the region (e.g., the visible effects of mountaintop coal mining), bluegrass vocals frequently reference the hard-scrabble existence of living in Appalachia and other rural areas with modest financial resources. Some protest music has been composed in the bluegrass style, especially concerning the vicissitudes of the Appalachian coal mining industry. Railroading has also been a popular theme, with ballads such as "Wreck of the Old 97" and "Nine Pound Hammer" (from the legend of John Henry) being exemplary.
History.
Creation.
Bluegrass, as a distinct musical form, developed from elements of old-time music and traditional music of the Appalachian region of the United States. The Appalachian region was where many English and Ulster-Scots immigrants settled, bringing with them the musical traditions of their homelands. Hence the sounds of jigs and reels, especially as played on the fiddle, were innate to the developing style. Black musicians infused characteristics of the blues to the mix, and in a development that was key to shaping the bluegrass sound, introduced the iconic banjo to the region.
The music now known as bluegrass was frequently used to accompany a rural dancing style known as buckdancing, flatfooting or clogging. As the bluegrass sound spread to urban areas, listening to it for its own sake increased, especially after the advent of audio recording. In 1948, what would come to be known as bluegrass emerged as a genre within the post-war country/western-music industry, a period of time characterized now as the golden era or wellspring of "traditional bluegrass." From its earliest days, bluegrass has been recorded and performed by professional and amateur musicians alike. Although amateur bluegrass musicians and trends such as "parking-lot picking" are too important to be ignored, it is touring musicians who have set the direction of the style. Radio stations dedicated to bluegrass have also proved influential in advancing the evolution of the style into distinctive subgenres.
Classification.
Bluegrass was initially included in the category of folk music and later changed to hillbilly. In 1948, bluegrass was placed under the country/western heading for radio airplay charting. All four of the seminal bluegrass authors - Artis, Price, Cantwell and Rosenberg - described bluegrass music in detail as originating in style and form, in one form or another, between the 1930s and mid-1940s. However, the term "bluegrass" did not appear formally to describe the music until the late 1950s, and did not appear in Music Index until 1965 (Kretzschmar, 1970). The first entry in Music Index mentioning "bluegrass music" directed the reader to "see Country Music; Hillbilly Music" (Kretzschmar, 1970, p. 91). Music Index maintained this listing for bluegrass music until 1986. The first time bluegrass music had its own entries in Music Index was 1987 (Stratelak, 1988).
The topical and narrative themes of many bluegrass songs are highly reminiscent of folk music. Many songs that are widely considered to be bluegrass are in reality older works legitimately classified as folk or old-time music that are performed in the bluegrass style. The interplay between bluegrass and folk forms has been academically studied. Folklorist Dr. Neil Rosenberg, for example, shows that most devoted bluegrass fans and musicians are familiar with traditional folk songs and old-time music and that these songs are often played at shows, festivals and jams (Rosenberg, 1985).
Origin of name.
"Bluegrass" is a common name given in America for grass of the Poa genus, the most famous being Kentucky bluegrass. The region around Kentucky is sometimes called the Bluegrass region.
Exactly when the word "bluegrass" itself was adopted to label this form of music is not certain, but is believed to be in the late 1950s. It was derived from the name of the seminal Blue Grass Boys band, formed in 1939 with Bill Monroe as its leader. Due to this lineage, Bill Monroe is frequently referred to as the "father of bluegrass".
Monroe's 1946 to 1948 band, which featured banjo prodigy Earl Scruggs, singer-guitarist Lester Flatt, fiddler Chubby Wise and bassist Howard Watts (also known as "Cedric Rainwater")—sometimes called "the original bluegrass band"—created the definitive sound and instrumental configuration that remains a model to this day. By some arguments, while the Blue Grass Boys were the only band playing this music, it was just their unique sound; it could not be considered a musical style until other bands began performing in similar fashion. In 1948, the Stanley Brothers recorded the traditional song "Molly and Tenbrooks" in the Blue Grass Boys' style, arguably the point in time that Bluegrass emerged as a distinct musical form. As Ralph Stanley himself said about the origins of the genre and its name:
"Oh, (Monroe) was the first. But it wasn't called bluegrass back then. It was just called old time mountain hillbilly music. When they started doing the bluegrass festivals in 1965, everybody got together and wanted to know what to call the show, y'know. It was decided that since Bill was the oldest man, and was from the bluegrass state of Kentucky and he had the Blue Grass Boys, it would be called 'bluegrass.'"
First generation.
First generation bluegrass musicians dominated the genre from its beginnings in the mid-1940s through the mid-1960s. This group generally consists of those who were playing during the "Golden Age" in the 1950s, including Bill Monroe and his Blue Grass Boys, the Stanley Brothers, Lester Flatt and Earl Scruggs with the Foggy Mountain Boys, Hylo Brown and The Timberliners, Reno and Smiley, the Sauceman Brothers, Lonesome Pine Fiddlers, Jim and Jesse, Jimmy Martin and the Osborne Brothers, Red Allen (who also recorded with the Osborne Brothers for MGM in the mid-fifties), Mac Wiseman, Mac Martin and the Dixie Travelers, Carl Story and his Rambling Mountaineers, Buzz Busby, The Lilly Brothers, Bill Clifton and Jim Eanes, and the Country Gentlemen - one of the first bands to include material from outside the usual corpus of bluegrass music.
Second generation.
A second generation of bluegrass musicians began performing, composing and recording in the mid-to late-1960s, although many had played in first–generation bands from a young age. Some bluegrass musicians in this group are Jimmy Martin, Doc Watson, J. D. Crowe, Doyle Lawson, Sam Bush, Bela Fleck, John Hartford, Jerry Douglas, Norman Blake, Frank Wakefield, Bill Keith, Del McCoury and Tony Rice. As they refined their craft, the New Grass Revival, Seldom Scene, The Kentucky Colonels, and The Dillards developed progressive bluegrass. In one collaboration, first-generation bluegrass fiddler Vassar Clements, progressive mandolin player David Grisman, Grateful Dead frontman Jerry Garcia (on banjo), and Peter Rowan on lead vocals played in the band called "Old and in the Way". Garcia, Chris Hillman, Dickey Betts of The Allman Brothers Band and others in the 1960s and 1970s helped introduce rock music listeners to progressive and traditional bluegrass. Bush, Grisman, and Clements developed strong jazz elements in most of their playing—Clements liked to refer to his music as "hillbilly jazz"—but each owes much to traditional bluegrass.
Third generation.
Third generation bluegrass developed in the mid-1980s. Bluegrass grew, matured and broadened from the music played in previous years. This generation redefined "mainstream bluegrass". High-quality sound equipment allowed each band member to be miked independently, exemplified by Tony Rice Unit and "The Bluegrass Album Band". Tony Rice showcased elaborate lead guitar solos, and other bands followed. The electric bass became a general, but not universal, alternative to the traditional acoustic bass, though electrification of other instruments continued to meet resistance outside progressive circles. Nontraditional chord progressions also became more widely accepted. On the other hand, this generation saw a renaissance of more traditional songs, played in the newer style. The Johnson Mountain Boys were one of the decade's most popular touring groups, and played strictly traditional bluegrass.
Recent developments.
In recent decades bluegrass music has reached a broader audience. Major mainstream country music performers have recorded bluegrass albums, including Dolly Parton and Patty Loveless, who each released several bluegrass albums. Since the late 1990s, Ricky Skaggs, who began as a bluegrass musician and crossed over to mainstream country in the 1980s, returned to bluegrass with his band Kentucky Thunder. The Coen Brothers' film "O Brother, Where Art Thou?" (2000) has a country and bluegrass soundtrack which won the Grammy Award for Album of the Year in 2002. The documentary and concert film "Down from the Mountain" (2000) featured a live performance by the music artists who participated in the recording of the soundtrack recording.
Contemporary artists such as Chris Thile are continuing the spread of traditional bluegrass music. Famous for playing in the band Nickel Creek when he was young, Thile is now collaborating with varying diverse artists, and continues to play music in the genre. His latest band, Punch Brothers, has progressed contemporary bluegrass music through fusion with other forms and genres.
Meanwhile, festivals such as the Telluride Bluegrass Festival and RockyGrass in Lyons, Colorado, and bands such as the Nederland, Colorado-based Yonder Mountain String Band and Druhá Tráva in the Czech Republic attract large audiences while expanding the range of progressive bluegrass in college jam-band atmospheres, often called "jamgrass." Bluegrass fused with jazz is found in the music of Bela Fleck and The Flecktones, Railroad Earth, Tony Rice, Andy Statman, Sam Bush, Doc Watson, and others.
Subgenres.
There are three major subgenres of bluegrass and one unofficial subgenre.
Traditional bluegrass.
Traditional bluegrass emphasizes the traditional elements; musicians play folk songs, tunes with simple traditional chord progressions, and use only acoustic instruments. Generally, compositions are performed on instruments that were played by Bill Monroe and the Blue Grass Boys in the late 1940s. In the early years, instruments no longer accepted in mainstream bluegrass, such as the accordion, were used. Traditional bands may use their instruments in slightly different ways; for example playing the banjo by the claw-hammer style, or using multiple guitars or fiddles in a band. In this subgenre, the guitar rarely leads but acts as a rhythm instrument, one notable exception being gospel-based songs. Melodies and lyrics tend to be simple, often in G major, and a I-IV-V chord pattern is common. Although traditional bluegrass performers eschew electrically amplified instruments, as used in other forms of popular music, it is common practice to "mike" acoustic instruments during stage performances before larger audiences.
Traditional bluegrass bands such as Ralph Stanley and the Clinch Mountain Boys, Del McCoury, Coyote Hill Bluegrass, Larry Sparks & The Lonesome Ramblers, Ricky Skaggs and Kentucky Thunder, Doyle Lawson and Quicksilver, The Gibson Brothers, and Danny Paisley & The Southern Grass, enjoy nationwide popularity. California mountain bluegrass, a variation on traditional, has enjoyed regional popularity with such bands as Rita Hosking and Cousin Jack.
Progressive bluegrass.
Another major subgenre is progressive bluegrass. Groups may use electric instruments and import songs from other genres, particularly rock & roll. Although a more recent phenomenon, progressive bluegrass has roots going back to one of the earliest bluegrass bands. The banjo and bass duets Earl Scruggs played even in the earliest days of the Foggy Mountain Boys hint at the wild chord progressions to come. The four key distinguishing elements (not always all present) of progressive bluegrass are instrumentation (frequently including electric instruments, drums, piano, and more), songs imported (or styles imitated) from other genres, chord progressions, and lengthy "jam band"-style improvisation. The String Cheese Incident is one band that sometimes mixes a bluegrass tune with a jam band feeling, especially in original tunes like "Dudley's Kitchen". A twist on this genre is combining elements that preceded bluegrass, such as old-time string band music, with bluegrass music.
Bands identified with this subgenre include Greensky Bluegrass, Cadillac Sky, The Dixie Bee-Liners, Skyline, The Greencards, The Dillards, Elephant Revival, Yonder Mountain String Band, Punch Brothers, Railroad Earth, The Infamous Stringdusters, Nu-Blu, and Bearfoot.
Bluegrass Gospel.
"Bluegrass gospel" has emerged as a third subgenre. Many bluegrass artists incorporate gospel music into their repertoire. Distinctive elements of this style include Christian lyrics, soulful three- or four-part harmony singing, and sometimes playing instrumentals subdue. A cappella choruses are popular with bluegrass gospel artists, though the harmony structure differs somewhat from standard barbershop or choir singing. Mainstream bluegrass artists Doyle Lawson & Quicksilver and IIIrd Tyme Out have produced bluegrass gospel music, while The Issacs, Mount Zion, The King James 1611 Boys, and The Churchmen play Bluegrass Gospel exclusively.
Neo-traditional bluegrass.
A newer development in the bluegrass world is Neo-traditional bluegrass. In the 1990s, most bluegrass bands were headed by a solo artist such as Doyle Lawson and Rhonda Vincent, with an accompanying band. Bands playing this subgenre include The Grascals, Mountain Heart, Steep Canyon Rangers, The Dixie Bee-Liners, The SteelDrivers, Pert Near Sandstone, Cadillac Sky, Waterfall Blue Boys, Tall Pines Bluegrass and Cherryholmes, who all—with the exception of Waterfall Blue Boys—have more than one lead singer.
Academic study of bluegrass.
The importance of bluegrass was substantiated when the first college offered a degree in bluegrass music. It was South Plains College in Levelland, Tx. Their alumni include (Banjo) Ben Clark, Kym Warner, Jeremy Garrett, Ron Block, Mike Bub and Stuart Duncan as well as groups like the Hillbenders and Spring Creek. Founded by Alan Munde, Joe Carr and Ed Marsh, it is currently under the direction of Sterling Masat (formerly of the Roys). Glenville State College, in the heart of central West Virginia offers the world's first four-year Bachelor of Arts degree in Bluegrass Music, founded in 2002 by Buddy Griffin, current director Megan Darby. Additional offerings include a Bluegrass Minor and/or Bluegrass Certificate for those who wish to couple various fields of studies while studying and participating in traditional Bluegrass Music. The college bluegrass band is very active on regional and national levels and strives to promote, preserve, and produce traditional and classic bluegrass culture and sound. East Tennessee State University in Johnson City, Tennessee and Morehead State University in Morehead, Kentucky offer comprehensive programs in Bluegrass and Old Time Music leading to the BA degree. The programs are both academic and performance-oriented. Founded by Jack Tottle, the ETSU program boasts many graduates who have gone on to notable professional careers in bluegrass and other forms of country music. These include Tim Stafford (Blue Highway, formerly with Allison Krauss and Union Station), Adam Steffey (The Boxcars, formerly with Allison Krauss and Union Station), Barry Bayles (Union Station) and Kenny Chesney. Raymond McLain, a veteran performer with The McLain Family Band and Jim and Jesse, directs the program at Morehead State University.

</doc>
<doc id="60591" url="http://en.wikipedia.org/wiki?curid=60591" title="Piano player">
Piano player

Piano player may refer to:

</doc>
<doc id="60592" url="http://en.wikipedia.org/wiki?curid=60592" title="Datasaab">
Datasaab

Datasaab was the computer division of, and later a separate company spun off from, aircraft manufacturer Saab in Linköping, Sweden. Its history dates back to December 1954, when Saab got a license to build its own copy of BESK, an early Swedish computer design using vacuum tubes, from Matematikmaskinnämnden (the Swedish governmental board for mathematical machinery). This clone was completed in 1957 and was named SARA. Its computing power was needed for design calculations for the next generation jet fighter Saab 37 Viggen.
Intending to develop a navigational computer to place in an airplane, a team led by Viggo Wentzel came up with an all transistorized prototype computer named D2, completed in 1960, which came to define the company's activities in the following two decades. This development followed two lines. The main purpose was the development of a navigational computer for Viggen. A spinoff was the production of a line of civilian mini and mainframe computers for the commercial market.
The military navigational computer CK37 was completed in 1971 and used in Viggen.
The first civilian model D21 (1962) was sold to several countries and some 30 units were built. After that, several versions with names like D22 (1966), D220, D23, D5, D15, and D16 were developed. When the Swedish government needed 20 computers in the 1960s to calculate taxes, an evaluation between Saab's and IBM's machines proved Saab's better. Later the D5s were used to set up the first and largest bank terminal system for the Nordic banks, a system which was partly in use until the late 1980s.
In 1971, technologies from Standard Radio & Telefon AB (SRT) and Saab were combined to form Stansaab AS, a joint venture that also included the state-owned Swedish Development Company. The company’s primary focus was systems for real-time data applied to commercial and aviation applications.
In 1975, the D23 system was seriously delayed and the solution was a joint company with Sperry UNIVAC. In 1978, this company merged with a division of Saab and became Datasaab. It was later owned by Ericsson, Nokia and ICL.
When Intel sued the competitor UMC for patent infringement over technologies including microcode updates of processors and different parts of the processor working asynchronously, UMC could point to an awarded paper describing how these technologies had been used in the D23 already in 1972. Since Intel's patents were from 1978, that paper would prove prior art and imply that the patents never should have been granted at all. The case was later dropped.
The academic computer society Lysator at Linköping University was founded in 1973 when a donation of an old used D21 was arranged. The company's history has been documented by members of its veteran society, "Datasaabs Vänner" ("Friends of Datasaab"), founded in 1993 to document and spread information about the computer history of Sweden, with focus on the region of Linköping and Datasaab. The society has documented the Datasaab history in five books, and documents and pictures of computer systems and products developed and produced by Datasaab are presented at the society homepage. Since 2004 many Datasaab computers are exhibited at the IT-ceum computer museum in Linköping.
After a series of mergers, the name Datasaab became connected with an incident of illegal technology transfer to the Soviet Union in the late 1970s. This is summarized in a chapter of the book "Techno-Bandits" (1984). A 1973 bid for tender for a civilian air traffic control system at the airports in Moscow, Kiev, and Mineralnye Vody was won by Swedish supplier Stansaab. A contract between Stansaab and Aeroflot was signed in September 1975. However, parts of the delivered system relied on components from the U.S.A., for which the Swedes couldn't get the necessary export licenses. So they bought U.S. components, relabeled them and smuggled them to Moscow using Soviet diplomats. Datasaab separated from Saab in 1978 and joined Stansaab in a new company, Datasaab AB.
Allegedly the air traffic control system did support the Soviet invasion of Afghanistan in December 1979. The smuggling operation was uncovered in October 1980, known as "the Datasaab affair" ("Datasaabaffären"). In early 1981, Datasaab was acquired by Ericsson and became its computing division Ericsson Information Systems. In April 1984 Ericsson was fined US$3.12 million for breach of U.S. export controls, and agreed to pay.

</doc>
<doc id="60594" url="http://en.wikipedia.org/wiki?curid=60594" title="Alamosa, Colorado">
Alamosa, Colorado

The City of Alamosa is the Home Rule Municipality that is the county seat and the most populous municipality of Alamosa County, Colorado, United States. The city population was 8,780 at the 2010 United States Census. The city is the commercial center of the San Luis Valley in south-central Colorado, and is the home of Adams State University.
History.
Alamosa was established in May 1878 by the Denver and Rio Grande Railroad and quickly became an important rail center. The railroad had an extensive construction, repair and shipping facility in Alamosa for many years and headquartered its remaining narrow gauge service here with trackage reaching many points throughout southwest Colorado and northern New Mexico. Alamosa is now a notable tourist town with many nearby attractions, including the Great Sand Dunes National Park and Preserve and Colorado Gators Reptile Park. The town hosts "Summer Fest on the Rio" which occurs the first weekend in June and the Early Iron car show over the Labor Day weekend. The city takes its name from the Spanish adjective "Alamosa", meaning "of cottonwood", for the cottonwood forests which grow along the Rio Grande and throughout town.
Geography.
Alamosa is located at (37.469, −105.874), at the junction of U.S. Routes 160 and 285. According to the United States Census Bureau, the city has a total area of 14.3 km2, of which 14.0 sqkm is land and 0.3 sqkm, or 2.26%, is water.
Alamosa is located along the Rio Grande in the San Luis Valley, in the highest general agricultural land in the United States. The San Luis Valley is the largest intermountain valley in the world, where local farmers specialize in growing cool weather crops. Elevation is about 7500 ft in Alamosa with peaks over 14000 ft within 23 mi of town in the Sangre de Cristo Range.
Climate.
Alamosa features a semi-arid climate (Köppen "BSk", but just avoiding arid designation), with long, cold winters and warm summers, and dry weather year-round. Normals range from a low of −4 °F in January to a high of 82 °F in July. Annual precipitation is only 7.25 in, with summer being the wettest. The aridity depresses mean snowfall to around 32 in, and the median to only 22.3 in.
The altitude and dryness of the air cause day-night temperature differences to be severe year-round. Alamosa’s geography and nighttime temperatures account for it being listed as the coldest city in the contiguous United States, with a record average of 227 nights per year with a minimum temperature of 32 °F or less, and 48.7 nights with minima below 0 F.
Demographics.
As of the census of 2000, there were 7,960 people, 2,974 households, and 1,769 families residing in the city. The population density was 1,995.0 people per square mile (770.3/km²). There were 3,215 housing units at an average density of 805.8 per square mile (311.1/km²). The racial makeup of the city was 68.53% White, 1.41% Black or African American, 2.20% Native American, 0.95% Asian, 0.26% Pacific Islander, 22.36% from other races, and 4.28% from two or more races. 46.80% of the population were Hispanic or Latino of any race.
There were 2,974 households out of which 32.0% had children under the age of 18 living with them, 40.5% were married couples living together, 14.6% had a female householder with no husband present, and 40.5% were non-families. 33.7% of all households were made up of individuals and 11.0% had someone living alone who was 65 years of age or older. The average household size was 2.36 and the average family size was 3.04.
In the city the population was spread out with 24.4% under the age of 18, 21.8% from 18 to 24, 24.8% from 25 to 44, 18.1% from 45 to 64, and 10.9% who were 65 years of age or older. The median age was 28 years. For every 100 females there were 91.4 males. For every 100 females age 18 and over, there were 89.1 males.
The median income for a household in the city was $25,453, and the median income for a family was $33,017. Males had a median income of $27,100 versus $22,671 for females. The per capita income for the city was $15,405. About 18.1% of families and 25.0% of the population were below the poverty line, including 30.4% of those under age 18 and 17.0% of those age 65 or over.
Government.
The city of Alamosa is a Home Rule Municipality like many other Colorado towns. The City Council has six members, four elected from wards and two at large. City Council votes against or for laws. City Council has authority to make, change, and repeal ordinances. The city elects a mayor-at-large on a non-partisan ballot. The current mayor of Alamosa is Josef Lucero.
Education.
Alamosa Public Schools are part of the Alamosa School District RE-11J, and include Alamosa Elementary School, Ortega Middle School, and Alamosa High School. Robert Alejo is the Superintendent of Schools.
Adams State University, Founded in 1921 as a teacher's college, ASU offers both undergraduate and graduate programs. Graduate level programs emphasize teaching and education, art, history and business. Many courses are available online. In 2015, the college reached an all-time high enrollment of 3,701 students. The University's location in Alamosa, with an elevation of about 7,800 ft above sea level, attracts many athletes (especially runners) to the school's athletic program. In 2014, ASU added a cycling program. 
Infrastructure.
Transportation.
Alamosa is on the Rio Grande, which is crossed by two auto bridges, one pedestrian bridge and one rail bridge in town. Auto traffic is served by U.S. Highway 160 running east and west and U.S. Highway 285 and State Highway 17 running north and south. Alamosa is served by the San Luis and Rio Grande Railroad. Great Lakes Airlines makes three daily flights between Denver and Alamosa.
Facilities.
Alamosa is the shopping center for the San Luis Valley and has a WalMart Supercenter, a Walgreens and two supermarkets, Safeway and City Market. There are a number of fast food restaurants, two medical clinics, and a regional hospital, San Luis Valley Regional Medical Center.
Adams State University is located in Alamosa. ASU is a four-year, state-supported university founded in 1921 and offering degrees in several fields including business and education.
Trinidad State Junior College has a campus situated in Alamosa. They offer 2-year degrees in gunsmithing, aquaculture, cosmetology, welding and nursing, as well as traditional arts and sciences classes like English, physics and chemistry.
Alamosa is home of Cattails Golf Course, an 18-hole championship course with a new clubhouse opened in 2008.

</doc>
<doc id="60595" url="http://en.wikipedia.org/wiki?curid=60595" title="John Cawte Beaglehole">
John Cawte Beaglehole

John Cawte Beaglehole OM CMG (13 June 1901 – 10 October 1971) was a New Zealand historian whose greatest scholastic achievement was the editing of James Cook's three journals of exploration, together with the writing of an acclaimed biography of Cook, published posthumously. He had a lifelong association with Victoria University College, which became Victoria University of Wellington, and after his death it named the archival collections after him.
Early life and career.
Beaglehole was born and grew up in Wellington, New Zealand, the second of the four sons of David Ernest Beaglehole, a clerk, and his wife, Jane Butler. His elder brother was Ernest Beaglehole, who became a psychologist and ethnologist. John was educated at Mount Cook School and Wellington College before being enrolled at Victoria University College, Wellington of the University of New Zealand, which later became an independent university, and where he subsequently spent most of his academic career. After his graduation, he was awarded a scholarship to study at the London School of Economics, and left for England in 1926.
After three years of post-graduate study Beaglehole obtained his PhD with a thesis on British colonial history. At this time he was much influenced by left-wing teachers, especially R. H. Tawney and Harold Laski, and on returning to New Zealand he found it difficult to obtain an academic post owing to his radical views. For a time he had various jobs including a spell as a Workers Educational Association lecturer, and had time to develop other enthusiasms including civil rights issues, writing poetry, and music, an interest inherited from his mother. In 1932 he took a temporary position as a lecturer in history at Auckland University College, but within months the position was abolished in a retrenchment by the college council. Many believed the decision was due more to the college's reaction to Beaglehole's reputation (albeit exaggerated) for radicalism. His academic career finally took off in 1934 after the publication of his first major book, "The Exploration of the Pacific", after which he developed his specialist interest in James Cook. He became lecturer, later professor, at the Victoria University College.
He married Elsie Mary Holmes in 1930, and they had three sons.
Editing Cook's journals.
Beaglehole became known internationally for his work on Cook's journals which brought out his great gifts as historian and editor. It was not all desk work among the archives – he also travelled widely in Cook's wake, from Whitby to Tahiti, to Tonga and to the New Hebrides. The four volumes of the journals that emerged between 1955 and 1967 were subsidised by the New Zealand government which also set up a special research post for their author. The sheer size of these tomes, each of them approaching 1,000 pages, may seem disconcerting at first sight, but they are enlivened by Beaglehole's stylish and often witty introductions, intended to set the journals in their contexts. As well as Cook's own journals Beaglehole also printed, either entire or in lengthy extracts, the journals of several of Cook's colleagues on the voyages. The introductions themselves, together with copious footnotes, reveal the breadth of his erudition. They cover many topics, ranging from the structure of Polynesian society to oceanography, navigation, cartography, and much else.
Much of the zoological and botanical notes for Beaglehole's work on James Cook's three voyages were provided by Dr Averil Margaret Lysaght.
Cook's journals themselves had never before been comprehensively and accurately presented to the public, and to do so required enormous research since copies and fragments of the journals and related material were scattered in various archives in London, Australia and New Zealand. For his edition, Beaglehole sought out the various surviving holographs in Cook's own hand in preference to copies by his clerks on board ship, and others. For the first voyage, the voyage of the "Endeavour", he used mainly the manuscript journal held in the National Library of Australia at Canberra. This only came to light in 1923, when the heirs of a Teesside ironmaster, Henry Bolckow, put it up for sale. Bolckow had purchased this manuscript at an earlier auction, in 1868, but had not made his ownership widely known, and consequently it was assumed for many years that no such holograph existed. For the second voyage Beaglehole used two other partial journals in Cook's hand, both of which had the same early history as the "Endeavour" journal. All three had probably once been owned by Cook's widow, and sold by a relation of hers at the 1868 auction. The difference was that the two partial journals from the second voyage were then purchased by the British Museum and not by Bolckow, and hence had long been available for public consultation. And for the third voyage Beaglehole's main source was a journal written, and much revised, by Cook up to early January 1779, a month before he died. What happened to the final month's entries, which must certainly have been made, is uncertain. This, too, is today in the British Library, the successor to the British Museum as a manuscript repository.
All students of Cook owe an enormous debt to Beaglehole for his all-encompassing editorship. So much so, in fact, that today it is difficult to view the subject of Cook except through Beaglehole's perspective. Some recent biographies of Cook have tended to be little else than abbreviated versions of Beaglehole. Nevertheless, it is also clear that Beaglehole’s work is, by and large, a continuation of the long tradition of Cook idealisation, a tradition from which post-Beaglehole scholarship has started to diverge. For Beaglehole, Cook was a heroic figure who could do practically no wrong, and he is scathing about those contemporaries of Cook who ever ventured to criticise his hero, such as Alexander Dalrymple, the geographer, and Johann Reinhold Forster, who accompanied Cook on the second voyage. Recent research has to some extent rehabilitated both Dalrymple and Forster.
Final years.
During his last decade Beaglehole was showered with honorary degrees from universities at home and abroad and other distinctions. Perhaps the most prestigious was the award in 1970 of the British Order of Merit. He was only the second New Zealander ever to receive this award, the first being the nuclear physicist Ernest Rutherford. Just before he died in 1971 Beaglehole was in the process of revising his detailed and authoritative biography of Cook, which was subsequently prepared for publication by his son Tim (currently Chancellor and Emeritus Professor at Victoria).
Archival collections at Victoria University.
Beaglehole's "alma mater", the Victoria University of Wellington, named its archival collections after him, in the reading room of which is displayed his portrait, by W.A. Sutton. The J.C. Beaglehole Room, as it is known, was moved into a completely new space in 2011.

</doc>
<doc id="60598" url="http://en.wikipedia.org/wiki?curid=60598" title="Golden, Colorado">
Golden, Colorado

The historic City of Golden is the Home Rule Municipality that is the county seat of Jefferson County, Colorado, United States. Golden lies along Clear Creek at the base of the Front Range of the Rocky Mountains. Founded during the Pike's Peak Gold Rush on 16 June 1859, the mining camp was originally named Golden City in honor of Thomas L. Golden. Golden City served as the capital of the provisional Territory of Jefferson from 1860 to 1861, and capital of the official Territory of Colorado from 1862 to 1867. In 1867, the territorial capital was moved about 12 mi east to Denver City. The United States Census Bureau estimates that the city population was 18,867 in 2010.
The Colorado School of Mines, offering programs in engineering and science, is located in Golden. Also there are the National Renewable Energy Laboratory, the National Earthquake Information Center, the Coors Brewing Company, CoorsTek, Spyderco, the American Mountaineering Center, and the Colorado Railroad Museum. It is the birthplace of the Jolly Rancher, a candy bought out by the Hershey Foods Corporation. Famous western showman William F. "Buffalo Bill" Cody is buried nearby on Lookout Mountain.
Geography.
Golden lies just north of I-70 and west of Denver at the foot of the Rocky Mountains. Situated between Lookout Mountain and the two Table Mountains, Golden lies within a sheltered valley fed by Clear Creek. Clear Creek flows through town from the west, out of its canyon shared by US 6, and exits the valley it carved between North Table Mountain and South Table Mountain and in which is located the Coors Brewery.
History.
Established as a gold-rush town, Golden City quickly became a leading economic and political center of the region, being a center of trade between the gold fields and the east, a crossroads and gateway of important roads leading to the mountains, and a center of area industry. By the end of 1860, Golden City had been popularly elected the seat of Jefferson County and was capital of the provisional Jefferson Territory. While the town lost much of its populace and leading citizenry during the American Civil War for several reasons (ranging from military to economic), Golden City became capital of the federally recognized Colorado Territory in 1862, continuing as such until 1867.
Golden City became the "Lowell of the West", a regional center of trade and industry that boasted at certain times three flour mills, five smelters, the first railroad into the Colorado mountains, the Coors Brewery, brick works, the only paper mill west of Missouri, clay and coal mines, and more. During the 1870s, it became home to three institutions of higher education, the Colorado University Schools, of which the Colorado School of Mines remains today. Golden was also home to an opera house and seven churches, including Colorado's third (Methodist) church, oldest Baptist church, likely oldest Christian (Disciples of Christ) church, and first Swedish immigrant (Lutheran) church. The town was home to sizable populations of German, Swedish, Italian and Chinese immigrants; five immigrants became mayors of Golden.
Until the early 20th century, Golden maintained a small town population of around 2,500 people. Several industries faded or were destroyed by tragic events, , but others flourished to continue Golden's industrial legacy, including its brewing, brick making, clay mining and porcelain industries. Golden became even more connected through mass transit, with two trolley lines extending to Denver, while the movie theater gradually took the place of the opera house for downtown entertainment. Downtown revitalization efforts began in the 1920s with its first streetscape and ornamental lighting project and urban renewal on its north and east, anchored by new senior high and grade schools. The historic cultural tension between the city's north and south sides gradually eased, and the town successfully endured additional major economic depressions, including the Silver Crash of 1893 and the Great Depression. The School of Mines gained a worldwide academic reputation, Coors rapidly came to the forefront of the national and international brewing and ceramics industries, and the city modernized with a recreation center, paved streets and more.
After World War II Golden boomed, rapidly gaining population, size and economy. In 1959, the town nearly tripled in geographic size overnight when it annexed large properties to the south, including the new Magic Mountain theme park, one of the earliest entertainment attractions of its kind. A number of new subdivisions were built and public infrastructure was modernized, including new buildings for the senior high school, city hall, recreation center, library, museum and central fire and police stations. Also built were new downtown anchors, including department stores and grocery stores, several new church buildings, new county offices, and the Horizon Plan, which transformed the School of Mines.
The decline in the price of petroleum and near simultaneous failure of several downtown anchors placed the central business district into recession in the 1980s, and the downtown was revitalized again through various initiatives, including its second streetscaping project in 1992. In 1993 the old Golden High School building was converted into the American Mountaineering Center, making Golden a research and education hub for mountaineering. The Coors Brewery had become the largest single-site brewery in the world, its Porcelain subsidiary among the foremost of its kind, and Golden became home to the National Renewable Energy Laboratory.
Today Golden has a population of over 18,000 people and is home to more people and businesses of national and international influence than ever before, yet maintains a small-town historic identity. A Golden mailing address may also represent one of several communities in unincorporated Jefferson County to the north and west of Golden, communities undergoing continual residential development of former farm, ranch and mining land and which possess a considerable population.
Demographics.
As of the census of 2010, there were 18,867 people, 7,394 households, and 3,985 families residing in the city. The population density was 2,096.3 inhabitants per square mile (809.7/km²). There were 7,748 housing units at an average density of 860.9 per square mile (332.5/km²). The racial makeup of the city was 90.6% White, 1.2% Black or African American, 0.6% Native American, 3.8% Asian, 0.1% Pacific Islander, 1.4% from other races, and 2.3% from two or more races. 8.2% of the population were Hispanic or Latino of any race.
There were 7,394 households out of which 23.7% had children under the age of 18 living with them, 43.4% were married couples living together, 7.2% had a female householder with no husband present, 3.3% had a male householder with no wife present, and 46.1% were non-families. 31.6% of all households were made up of individuals and 3.2% had someone living alone who was 65 years of age or older. The average household size was 2.24 and the average family size was 2.8.
In the city the population was spread out with 24.7% under the age of 20, 13% from 20 to 24, 27.5% from 25 to 44, 25% from 45 to 64, and 10% who were 65 years of age or older. The median age was 33.9 years. The population was 56.6% male and 43.4% female.
As of the census of 2000, the median income for a household in the city was $49,115, and the median income for a family was $67,414. Males had a median income of $41,822 versus $32,413 for females. The per capita income for the city was $25,257. About 3.5% of families and 11.3% of the population were below the poverty line, including 6.4% of those under age 18 and 7.6% of those age 65 or over.
Government.
Golden is a home rule municipality of the city form of statutory government in Colorado. Its government is a city council/city manager form of leadership which consists of a popularly elected mayor elected by the entire citizenry, two councilors each representing a district comprising one half of the city, and four councilors each representing a ward of which each district is divided into two. These seven members of the city council are each popularly elected from their ward/district/at large and they serve as the governing body of the city. The council hires and supervises the city manager, who hires and supervises the city staff, which handles the daily operations of the city.
Golden's current elected officials are:
The current City Manager is Michael C. Bestor.
Golden was among the first municipally governed cities in Colorado and has one of the oldest continuously functioning governments in the state. To date Golden has held 91 popular elections for municipal officials since its first such election in 1860, including 85 regular elections and 6 special elections in 1860, 1879, 1882, 2005, 2006 and 2008.
Transportation.
City streets.
The main part of Golden is laid out upon a historic street grid system running on an approximately northwest-southeast axis, aligned with Clear Creek upon which the heart of the city was established. Most of these are paved streets with a total 66-foot right of way, including area for sidewalks which in older areas are often separated by a landscaped strip from the street featuring beautiful and historic trees. The only historic street in the grid not named "street" is the main thoroughfare, Washington Avenue, an 80-foot right of way featuring a downtown care streetscape with trees, planters, brick, flagstone and ornamental street lights. Golden's streets are generally numbered on the east-west streets, and named on the north-south streets, and are named after pioneers, American Indian tribes and trees. The streets of the southeasterly part of town are aligned with the Denver metropolitan street grid, which are aligned directly with the true directions of the compass, and they share the names of the Denver grid. Outlying subdivisions of Golden consist of their own, often curvilinear street systems, of various degrees of connection with the rest of the city. Golden has several main thoroughfare street connections to the east which date to the Gold Rush times, including West 44th Avenue, West 32nd Avenue and South Golden Road.
Highways.
Since its beginning, Golden has been at a crossroads of major Colorado thoroughfares. Today Interstate 70 (I-70) runs through the southern part of the city, which connects to the northern terminus of SH 470 which runs to the south. U.S. Highway 6 (US 6), which turns into 6th Avenue, is a historic thoroughfare (built in 1950) which runs east-west through the southern part of the city then curves northward through the western part of Golden, ultimately arriving at the mouth of Clear Creek Canyon. State Highway 93 (SH 93), which traces its roots to the 1860s, continues north through the western part of the city from the canyon and northward towards Boulder. SH 58 bisects Golden on an east-west route between 6th and 7th Streets, and ultimately joins to go up Clear Creek Canyon. West Colfax Avenue, the historic US 40, runs on an approximately northeast-southwest route through the southern end of the city and turns westward up Mt. Vernon Canyon and parallels I-70.
Mass transportation.
The city of Golden is part of the network of the Regional Transportation District which provides bus and light rail service throughout the Denver metropolitan area. Its bus routes 16, 44L and GS connect the city with other points of the Denver metropolitan area and Boulder. The West Corridor (W line) of the FasTracks light rail line, which parallels 6th Avenue into Golden to its terminal at the Jefferson County Government Center, opened to the public April 26, 2013, a modern version of the historic trolley line which Golden interests spearheaded in the 1890s. Although passengers are no longer served by heavy rail, Golden continues to be served by railroad transportation for cargo, and has been continuously since 1870. These lines are owned by the BNSF railroad and serve business interests in the northeastern end of the city. Within the Coors Brewery grounds it becomes the brewery's own in-house railroad. The recreational miniature gauge Rio Golden Railroad serves passengers at Heritage Square.
Airports.
The closest airport to Golden is nearby Rocky Mountain Metropolitan Airport, a general aviation air transport facility located in northeastern Jefferson County. Passenger traffic generally uses Denver International Airport in northeastern Denver.
Education.
Golden, originally home to the second school in Colorado, is today part of the Jefferson County R-1 School District which provides public education throughout Jefferson County, Colorado. The city has five elementary schools, Mitchell, Kyffin, Shelton, Pleasant View and Ralston Elementary in the foothills to the west; one middle school, Bell Middle School; and Colorado's oldest senior high school, Golden High School.
In higher education, Golden features the oldest public university in the state, the Colorado School of Mines, which can be found a few blocks south of downtown Golden situated on a hill overlooking the city. Near Mines is the Mountain Language Institute, an English language school providing classes both in Golden and online.
Culture.
Golden is home to the Jefferson Symphony Orchestra, which performs seasonally at Bunker Auditorium in the Green Center at the Colorado School of Mines, and has performed continuously since 1953. The city is also home to the Foothills Art Center, an art exhibition venue housed in a historic church. Two live theater groups are housed in Golden, including one of only two Denver metro area dinner theater groups, the Heritage Square Music Hall, which has performed since 1986; and the dramatic live theater venue of the Miners Alley Playhouse in downtown Golden, which has performed there since 2001. The 150-year old Buffalo Rose Bar and Grill is the longest surviving Colorado gold rush-era business and remains a popular music venue for touring rock and blues bands. Golden is home to possibly the most museums per capita of any place in Colorado, including the Rocky Mountain Quilt Museum, Colorado Railroad Museum, Colorado School of Mines Geology Museum, Bradford Washburn American Mountaineering Museum, Golden History Center, Astor House Hotel Museum, and the Clear Creek History Park. There is also the Mother Cabrini Shrine.
Golden has several annual events, which include Heart & Soul Month in February, E-Days of the Colorado School of Mines in April (since 1927), two Independence Day fireworks shows sponsored by Heritage Square (since 1971) and the Golden Lions Club (since 1972), the largest event of the year is Buffalo Bill Days in late July (since 1946); the Golden Fine Arts Festival in August (since 1990), Goldenfest in September (since 1978, originally Oktoberfest), and Olde Golden Christmas (since 1972) in November to December.
The American Mountaineering Center is home to the American Alpine Club, The Colorado Mountain Club, and Outward Bound. The Henry S. Hall, Jr. American Alpine Club Library and Colorado Mountain Club Collection is the world's largest repository of mountaineering literature and is internationally known. The American Mountaineering Center is also home to the Bradford Washburn American Mountaineering Museum and hosts many programs and events each year. This premier facility and the town's location near plenty of world class rock climbing, skiing and mountaineering make Golden a center for mountaineering culture.
Sports.
Golden's competitive athletics go back for well over a century and feature public school and collegiate teams and athletes. Golden High School competes in various sports in 4A competition in Colorado, and its football program dates as far back as the 1890s. The Colorado School of Mines competes primarily in NCAA Division II athletics in a variety of sports including football (dating to 1888), baseball and basketball. Clear Creek is also home to a nationally renowned kayak course, and the city is home to the American Mountaineering Center and features noteworthy rock climbing, mountain biking, hiking, and hang gliding opportunities in close proximity. Golden has to date generated three Major League Baseball players, four Olympic competitors and two Olympic medalists.
People of historical interest.
Golden has had a long, rich history spanning nearly one and a half centuries, which includes many who were important in Colorado and American History.
A few people that have been born, lived, or died in the Golden area are:

</doc>
<doc id="60599" url="http://en.wikipedia.org/wiki?curid=60599" title="Denver-Aurora-Lakewood, CO Metropolitan Statistical Area">
Denver-Aurora-Lakewood, CO Metropolitan Statistical Area

Denver is the central city of a conurbation region in the U.S. state of Colorado. The conurbation includes one continuous region consisting of the six central counties of Adams, Arapahoe, Broomfield, Denver, Douglas and Jefferson. The region includes the adjacent county of El Paso in the south and reaches to Fort Collins, Larimer County in the north. The Denver region is part of the Front Range Urban Corridor. 
The United States Office of Management and Budget has delineated the Denver-Aurora-Lakewood, CO Metropolitan Statistical Area consisting of ten Colorado counties: the City and County of Denver, Arapahoe County, Jefferson County, Adams County, Douglas County, the City and County of Broomfield, Elbert County, Park County, Clear Creek County, and Gilpin County. The United States Census Bureau estimates that the population was 2,754,258 as of April 1, 2015, an increase of +8.29% since the 2010 United States Census, and ranking as the 21st most populous metropolitan statistical area of the United States.
The Office of Management and Budget also delineated the more extensive Denver-Aurora Combined Statistical Area comprising the Denver-Aurora-Lakewood Metropolitan Statistical Area, the Boulder Metropolitan Statistical Area, and the Greeley Metropolitan Statistical Area.
The central part of the metropolitan statistical area (MSA) includes Denver and three immediately adjacent counties: Jefferson County to the west, Adams County to the north and east, and Arapahoe County to the south and east. The continuously urbanized area extends northwest into the City and County of Broomfield, bordering Jefferson and Adams counties, and south into Douglas County, adjoining Arapahoe County. Also included in the federally defined MSA are four rural counties: Elbert County on the southeastern prairie and Clear Creek, Gilpin, and Park counties in the Rocky Mountains.
Counties.
The Denver-Aurora-Lakewood Metropolitan Statistical Area comprises ten counties. The sortable table below includes the following information:
Regional cooperation.
The Denver Regional Council of Governments (DRCOG, pronounced Doctor Cog) is a regional planning and inter-governmental coordination organization in a nine-county region. The Scientific and Cultural Facilities District (SCFD) provides funding for scientific and cultural facilities in a seven-county region including:
In addition, the Regional Transportation District (RTD) provides mass transit, including a light rail system. In 2005 the RTD developed a twelve-year comprehensive plan, called "FasTracks", to build and operate rail transit lines and expand and improve bus service throughout the region.
Economy.
The most prosperous parts of the area are in the south, while the most industrialized areas are in the northeast, specifically in the northern part of Denver proper and extending to areas such as Commerce City in Adams County.
Changes in house prices for the area are publicly tracked on a regular basis using the Case–Shiller index; the statistic is published by Standard & Poor's and is also a component of S&P's 10-city composite index of the value of the residential real estate market.
Electricity is provided by Xcel Energy. Cable television is provided by Comcast.
Air quality.
The center of the metropolitan area sits in a valley, the Denver Basin, and suffers from air pollution known colloquially as the "brown cloud", building up if the air is stagnant as it often is in the winter. Severity of pollution in this area has varied enormously over the years. In the late 1980s the area was frequently in violation of multiple National Ambient Air Quality Standards established by the United States Environmental Protection Agency (EPA). The Regional Air Quality Council (RAQC) was formed in 1989 to create plans to address the problem. Through a variety of measures the area's air quality was improved and in 2002 the EPA designated the area in compliance with all federal health-based air quality standards. Denver was the first major city in the United States to reach compliance with all six of these standards after previously violating five of them Since then the EPA introduced a new standard for small particulates and made the existing ozone standard stricter. In 2003 the new ozone standard was frequently exceeded in the area and was occasionally exceeded as far away as Rocky Mountain National Park. The RAQC hopes to implement plans enabling the area to comply with the new standards by 2007.
Sister cities.
Though Arvada, Aurora, Boulder, Brighton, Broomfield, Denver, Lakewood and Longmont have their own individual sister city relationships, the Denver Regional Council of Governments (DRCOG) as a whole has a sister city relationship with the Baghdad Governorate of Iraq.
See also.
Colorado metropolitan areas

</doc>
<doc id="60600" url="http://en.wikipedia.org/wiki?curid=60600" title="Barcode">
Barcode

A barcode is an optical machine-readable representation of data relating to the object to which it is attached. Originally barcodes systematically represented data by varying the widths and spacings of parallel lines, and may be referred to as linear or one-dimensional (1D). Later they evolved into rectangles, dots, hexagons and other geometric patterns in two dimensions (2D). Although 2D systems use a variety of symbols, they are generally referred to as barcodes as well. Barcodes originally were scanned by special optical scanners called barcode readers. Later, scanners and interpretive software became available on devices including desktop printers and smartphones.
An early use of one type of barcode in an industrial context was sponsored by the Association of American Railroads in the late 1960s. Developed by General Telephone and Electronics (GTE) and called KarTrak ACI (Automatic Car Identification), this scheme involved placing colored stripes in various combinations on steel plates which were affixed to the sides of railroad rolling stock. Two plates were used per car, one on each side, with the arrangement of the colored stripes representing things such as ownership, type of equipment, and identification number. The plates were "read" by a trackside scanner located, for instance, at the entrance to a classification yard while the car was moving past. The project was abandoned after about ten years because the system proved unreliable after long-term use in the field.
Barcodes became commercially successful when they were used to automate supermarket checkout systems, a task for which they have become almost universal. Their use has spread to many other tasks that are generically referred to as automatic identification and data capture (AIDC). The very first scanning of the now ubiquitous Universal Product Code (UPC) barcode was on a pack of Wrigley Company chewing gum in June 1974.
Other systems have made inroads in the AIDC market, but the simplicity, universality and low cost of barcodes has limited the role of these other systems until the 2000s (decade), over 40 years after the introduction of the commercial barcode, with the introduction of technologies such as radio frequency identification, or RFID.
History.
In 1948 Bernard Silver, a graduate student at Drexel Institute of Technology in Philadelphia, Pennsylvania, US overheard the president of the local food chain, Food Fair, asking one of the deans to research a system to automatically read product information during checkout. Silver told his friend Norman Joseph Woodland about the request, and they started working on a variety of systems. Their first working system used ultraviolet ink, but the ink faded too easily and was rather expensive.
Convinced that the system was workable with further development, Woodland left Drexel, moved into his father's apartment in Florida, and continued working on the system. His next inspiration came from Morse code, and he formed his first barcode from sand on the beach. "I just extended the dots and dashes downwards and made narrow lines and wide lines out of them." To read them, he adapted technology from optical soundtracks in movies, using a 500-watt incandescent light bulb shining through the paper onto an RCA935 photomultiplier tube (from a movie projector) on the far side. He later decided that the system would work better if it were printed as a circle instead of a line, allowing it to be scanned in any direction.
On 20 October 1949 Woodland and Silver filed a patent application for "Classifying Apparatus and Method", in which they described both the linear and bullseye printing patterns, as well as the mechanical and electronic systems needed to read the code. The patent was issued on 7 October 1952 as . In 1951, Woodland moved to IBM and continually tried to interest IBM in developing the system. The company eventually commissioned a report on the idea, which concluded that it was both feasible and interesting, but that processing the resulting information would require equipment that was some time off in the future.
IBM offered to buy the patent, but its offer was not high enough. Philco purchased their patent in 1962 and then sold it to RCA sometime later.
Collins at Sylvania.
During his time as an undergraduate, David Collins worked at the Pennsylvania Railroad and became aware of the need to automatically identify railroad cars. Immediately after receiving his master's degree from MIT in 1959, he started work at GTE Sylvania and began addressing the problem. He developed a system called "KarTrak" using blue and red reflective stripes attached to the side of the cars, encoding a six-digit company identifier and a four-digit car number. Light reflected off the stripes was fed into one of two photomultipliers, filtered for blue or red.
The Boston and Maine Railroad tested the KarTrak system on their gravel cars in 1961. The tests continued until 1967, when the Association of American Railroads (AAR) selected it as a standard, Automatic Car Identification, across the entire North American fleet. The installations began on 10 October 1967. However, the economic downturn and rash of bankruptcies in the industry in the early 1970s greatly slowed the rollout, and it was not until 1974 that 95% of the fleet was labeled. To add to its woes, the system was found to be easily fooled by dirt in certain applications, which greatly affected accuracy. The AAR abandoned the system in the late 1970s, and it was not until the mid-1980s that they introduced a similar system, this time based on radio tags.
The railway project had failed, but a toll bridge in New Jersey requested a similar system so that it could quickly scan for cars that had purchased a monthly pass. Then the U.S. Post Office requested a system to track trucks entering and leaving their facilities. These applications required special retroreflector labels. Finally, Kal Kan asked the Sylvania team for a simpler (and cheaper) version which they could put on cases of pet food for inventory control.
Computer Identics Corporation.
In 1967, with the railway system maturing, Collins went to management looking for funding for a project to develop a black-and-white version of the code for other industries. They declined, saying that the railway project was large enough and they saw no need to branch out so quickly.
Collins then quit Sylvania and formed Computer Identics Corporation. Computer Identics started working with helium–neon lasers in place of light bulbs, scanning with a mirror to locate the barcode anywhere up to several feet in front of the scanner. This made the entire process much simpler and more reliable, as well as allowing it to deal with damaged labels by reading the intact portions.
Computer Identics Corporation installed one of its first two scanning systems in the spring of 1969 at a General Motors (Buick) factory in Flint, Michigan. The system was used to identify a dozen types of transmissions moving on an overhead conveyor from production to shipping. The other scanning system was installed at General Trading Company's distribution center in Carlstadt, New Jersey to direct shipments to the proper loading bay.
Universal Product Code.
In 1966 the National Association of Food Chains (NAFC) held a meeting where they discussed the idea of automated checkout systems. RCA had purchased rights to the original Woodland patent, attended the meeting and initiated an internal project to develop a system based on the bullseye code. The Kroger grocery chain volunteered to test it.
In mid-1970s, the NAFC established the U.S. Supermarket Ad Hoc Committee on a Uniform Grocery Product Code, which set guidelines for barcode development and created a symbol selection subcommittee to help standardize the approach. In cooperation with consulting firm McKinsey & Co., they developed a standardized 11-digit code to identify any product. The committee then sent out a contract tender to develop a barcode system to print and read the code. The request went to Singer, National Cash Register (NCR), Litton Industries, RCA, Pitney-Bowes, IBM and many others. A wide variety of barcode approaches were studied, including linear codes, RCA's bullseye concentric circle code, starburst patterns and others.
In the spring of 1971 RCA demonstrated their bullseye code at another industry meeting. IBM executives at the meeting noticed the crowds at the RCA booth and immediately developed their own system. IBM marketing specialist Alec Jablonover remembered that the company still employed Woodland, and he established a new facility in North Carolina to lead development.
In July 1972 RCA began an eighteen-month test in a Kroger store in Cincinnati. Barcodes were printed on small pieces of adhesive paper, and attached by hand by store employees when they were adding price tags. The code proved to have a serious problem. During printing, presses sometimes smear ink in the direction the paper is running, rendering the code unreadable in most orientations. A linear code, like the one being developed by Woodland at IBM, however, was printed in the direction of the stripes, so extra ink simply makes the code "taller" while remaining readable, and on 3 April 1973 the IBM UPC was selected by NAFC as their standard. IBM had designed five versions of the UPC symbology for future industry requirements: UPC A, B, C, D, and E.
NCR installed a testbed system at Marsh's Supermarket in Troy, Ohio, near the factory that was producing the equipment. On 26 June 1974, Clyde Dawson pulled a 10-pack of Wrigley's Juicy Fruit gum out of his basket and it was scanned by Sharon Buchanan at 8:01 am. The pack of gum and the receipt are now on display in the Smithsonian Institution. It was the first commercial appearance of the UPC.
In 1971 IBM had assembled a team for an intensive planning session, day after day, 12 to 18 hours a day, to thrash out how the whole system might operate and to schedule a roll-out plan. By 1973 they were meeting with grocery manufacturers to introduce the symbol that would need to be printed on the packaging or labels of all of their products. There were no cost savings for a grocery to use it unless at least 70% of the grocery's products had the barcode printed on the product by the manufacturer. IBM was projecting that 75% would be needed in 1975. Even though that was achieved, there were still scanning machines in fewer than 200 grocery stores by 1977.
Economic studies conducted for the grocery industry committee projected over $40 million in savings to the industry from scanning by the mid-1970s. Those numbers were not achieved in that time-frame and some predicted the demise of barcode scanning. The usefulness of the barcode required the adoption of expensive scanners by a critical mass of retailers while manufacturers simultaneously adopted barcode labels. Neither wanted to move first and results were not promising for the first couple of years, with "Business Week" proclaiming "The Supermarket Scanner That Failed."
Experience with barcode scanning in those stores revealed additional benefits. The detailed sales information acquired by the new systems allowed greater responsiveness to customer needs. This was reflected in the fact that about 5 weeks after installing barcode scanners, sales in grocery stores typically started climbing and eventually leveled off at a 10–12% increase in sales that never dropped off. There also was a 1–2% decrease in operating cost for the stores that enabled them to lower prices to increase market share. It was shown in the field that the return on investment for a barcode scanner was 41.5%. By 1980, 8,000 stores per year were converting.
The global public launch of the barcode was greeted with minor skepticism from conspiracy theorists, who considered barcodes to be an intrusive surveillance technology, and from some Christians who thought the codes hid the number 666, representing the number of the beast. Television host Phil Donahue described barcodes as a "corporate plot against consumers".
Industrial adoption.
In 1981, the United States Department of Defense adopted the use of Code 39 for marking all products sold to the United States military. This system, Logistics Applications of Automated Marking and Reading Symbols (LOGMARS), is still used by DoD and is widely viewed as the catalyst for widespread adoption of barcoding in industrial uses.
Use.
Barcodes such as the UPC have become a ubiquitous element of modern civilization, as evidenced by their enthusiastic adoption by stores around the world; most items other than fresh produce from a grocery store now have UPC barcodes. This helps track items and also reduces instances of shoplifting involving price tag swapping, although shoplifters can now print their own barcodes. In addition, retail chain membership cards (issued mostly by grocery stores and specialty "big box" retail stores such as sporting equipment, office supply, or pet stores) use barcodes to uniquely identify consumers, allowing for customized marketing and greater understanding of individual consumer shopping patterns. At the point of sale, shoppers can get product discounts or special marketing offers through the address or e-mail address provided at registration.
They are widely used in the healthcare and hospital settings, ranging from patient identification (to access patient data, including medical history, drug allergies, etc.) to creating SOAP Notes with barcodes to medication management. They are also used to facilitate the separation and indexing of documents that have been imaged in batch scanning applications, track the organization of species in biology, and integrate with in-motion checkweighers to identify the item being weighed in a conveyor line for data collection.
They can also be used to keep track of objects and people; they are used to keep track of rental cars, airline luggage, nuclear waste, registered mail, express mail and parcels. Barcoded tickets allow the holder to enter sports arenas, cinemas, theatres, fairgrounds, and transportation, and are used to record the arrival and departure of vehicles from rental facilities etc. This can allow proprietors to identify duplicate or fraudulent tickets more easily. Barcodes are widely used in shop floor control applications software where employees can scan work orders and track the time spent on a job. 
Barcodes are also used in some kinds of non-contact 1D and 2D position sensors.
A series of barcodes are used in some kinds of absolute 1D linear encoder. The barcodes are packed close enough together that the reader always has one or two barcodes in its field of view.
As a kind of fiducial marker, the relative position of the barcode in the field of view of the reader gives incremental precise positioning, in some cases with sub-pixel resolution.
The data decoded from the barcode gives the absolute coarse position.
An "address carpet", such as Howell's binary pattern and the Anoto dot pattern, is a 2D barcode designed so that a reader, even though only a tiny portion of the complete carpet is in the field of view of the reader, can find its absolute X,Y position and rotation in the carpet.
Some 2D barcodes embed a hyperlink to a web page. A capable cellphone might be used to read the pattern and browse the linked website, which can help a shopper find the best price for an item in the vicinity. Since 2005, airlines use an IATA-standard 2D barcode on boarding passes (Bar Coded Boarding Pass (BCBP)), and since 2008 2D barcodes sent to mobile phones enable electronic boarding passes.
Some applications for barcodes have fallen out of use. In the 1970s and 1980s, software source code was occasionally encoded in a barcode and printed on paper (Cauzin Softstrip and Paperbyte are barcode symbologies specifically designed for this application), and the 1991 Barcode Battler computer game system used any standard barcode to generate combat statistics.
In the 21st century, many artists have started using barcodes in art, such as Scott Blake's Barcode Jesus, as part of the post-modernism movement.
Symbologies.
The mapping between messages and barcodes is called a "symbology". The specification of a symbology includes the encoding of the single digits/characters of the message as well as the start and stop markers into bars and space, the size of the quiet zone required to be before and after the barcode as well as the computation of a checksum.
Linear symbologies can be classified mainly by two properties:
Some symbologies use interleaving. The first character is encoded using black bars of varying width. The second character is then encoded, by varying the width of the white spaces between these bars. Thus characters are encoded in pairs over the same section of the barcode. Interleaved 2 of 5 is an example of this.
Stacked symbologies repeat a given linear symbology vertically.
The most common among the many 2D symbologies are matrix codes, which feature square or dot-shaped modules arranged on a grid pattern. 2D symbologies also come in circular and other patterns and may
employ steganography, hiding modules within an image (for example, DataGlyphs).
Linear symbologies are optimized for laser scanners, which sweep a light beam across the barcode in a straight line, reading a "slice" of the barcode light-dark patterns. Stacked symbologies are also optimized for laser scanning, with the laser making multiple passes across the barcode.
In the 1990s development of charge coupled device (CCD) imagers to read barcodes was pioneered by Welch Allyn. Imaging does not require moving parts, as a laser scanner does. In 2007, linear imaging had begun to supplant laser scanning as the preferred scan engine for its performance and durability.
2D symbologies cannot be read by a laser as there is typically no sweep pattern that can encompass the entire symbol. They must be scanned by an image-based scanner employing a CCD or other digital camera sensor technology.
Scanners (barcode readers).
The earliest, and still the cheapest, barcode scanners are built from a fixed light and a single photosensor that is manually "scrubbed" across the barcode.
Barcode scanners can be classified into three categories based on their connection to the computer. The older type is the RS-232 barcode scanner. This type requires special programming for transferring the input data to the application program.
"Keyboard interface scanners" connect to a computer using a PS/2 or AT keyboard–compatible adaptor cable (a "keyboard wedge"). The barcode's data is sent to the computer as if it had been typed on the keyboard.
Like the keyboard interface scanner, USB scanners are easy to install and do not need custom code for transferring input data to the application program. On PCs running Windows the HID interface emulates the data merging action of a hardware "keyboard wedge", and the scanner automatically behaves like an additional keyboard.
Many phones are able to decode barcodes using their built-in camera, as well. Google's mobile Android operating system uses both their own Google Goggles application or third party barcode scanners like Scan. Nokia's Symbian operating system features a barcode scanner, while mbarcode is a QR code reader for the Maemo operating system. In the Apple iOS, a barcode reader is not natively included but more than fifty paid and free apps are available with both scanning capabilities and hard-linking to URI. With BlackBerry devices, the App World application can natively scan barcodes and load any recognized Web URLs on the device's Web browser. Windows Phone 7.5 is able to scan barcodes through the Bing search app. However, these devices are not designed specifically for the capturing of barcodes. As a result, they do not decode nearly as quickly or accurately as a dedicated barcode scanner or portable data terminal.
Quality control and verification.
Barcode verification examines scanability and the quality of the barcode in comparison to industry standards and specifications. Barcode verifiers are primarily used by businesses that print and use barcodes. Any trading partner in the supply chain can test barcode quality. It is important to verify a barcode to ensure that any reader in the supply chain can successfully interpret a barcode with a low error rate. Retailers levy large penalties for non-compliant barcodes. These chargebacks can reduce a manufacturer's revenue by 2% to 10%.
A barcode verifier works the way a reader does, but instead of simply decoding a barcode, a verifier performs a series of tests. For linear barcodes these tests are:
2D matrix symbols look at the parameters:
Depending on the parameter, each ANSI test is graded from 0.0 to 4.0 (F to A), or given a pass or fail mark. Each grade is determined by analyzing the scan reflectance profile (SRP), an analog graph of a single scan line across the entire symbol. The lowest of the 8 grades is the scan grade and the overall ISO symbol grade is the average of the individual scan grades. For most applications a 2.5 (C) is the minimum acceptable symbol grade.
Compared with a reader, a verifier measures a barcode's optical characteristics to international and industry standards. The measurement must be repeatable and consistent. Doing so requires constant conditions such as distance, illumination angle, sensor angle and verifier aperture. Based on the verification results, the production process can be adjusted to print higher quality barcodes that will scan down the supply chain.
Barcode verifier standards.
This standard defines the measuring accuracy of a barcode verifier.
This standard defines the quality requirements for barcodes and Matrix Codes (also called Optical Codes).
International standards are available from the International Organization for Standardization (ISO).
These standards are also available from local/national standardization organizations, such as ANSI, BSI, DIN, NEN and others.
Benefits.
In point-of-sale management, barcode systems can provide detailed up-to-date information on the business, accelerating decisions and with more confidence. For example:
Besides sales and inventory tracking, barcodes are very useful in logistics and supply chain management.
Barcode scanners are relatively low cost and extremely accurate compared to key-entry, with only about 1 substitution error in 15,000 to 36 trillion characters entered. The exact error rate depends on the type of barcode.
Types of barcodes.
Linear barcodes.
A first generation, "one dimensional" barcode that is made up of lines and spaces of various widths that create specific patterns.
Matrix (2D) barcodes.
A "matrix code", also termed a "2D barcode" or simply a "2D code", is a two-dimensional way to represent information. It is similar to a linear (1-dimensional) barcode, but can represent more data per unit area.
In popular culture.
In architecture, a building in Lingang New City by German architects Gerkan, Marg and Partners incorporates a barcode design, as does a shopping mall called (the Russian for "barcode") in Narodnaya ulitsa ("People's Street") in the Nevskiy district of St. Petersburg, Russia.
In media, in 2011, the National Film Board of Canada and ARTE France launched a web documentary entitled "Barcode.tv", which allows users to view films about everyday objects by scanning the product's barcode with their iPhone camera.
In professional wrestling, the WWE stable D-Generation X incorporated a barcode into their entrance video, as well as on a T-shirt.
In video games, the protagonist of the "Hitman" video game series has a barcode tattoo on the back of his head.
In the films "Back to the Future Part II" and "The Handmaid's Tale", cars in the future are depicted with barcode licence plates.
In music, Dave Davies of The Kinks released a solo album in 1980, AFL1-3603, which featured a giant barcode on the front cover in place of the musician's head. The album's name was also the barcode number.
The April, 1978 issue of Mad Magazine featured a giant barcode on the cover, with the blurb "[Mad] Hopes this issue jams up every computer in the country...for forcing us to deface our covers with this yecchy UPC symbol from now on!"
References.
Bibliography.
</dl>

</doc>
<doc id="60602" url="http://en.wikipedia.org/wiki?curid=60602" title="210 BC">
210 BC

Year 210 BC was a year of the pre-Julian Roman calendar. At the time it was known as the Year of the Consulship of Marcellus and Laevinus (or, less frequently, year 544 "Ab urbe condita"). The denomination 210 BC for this year has been used since the early medieval period, when the Anno Domini calendar era became the prevalent method in Europe for naming years.
Events.
<onlyinclude>
By place.
China.
</onlyinclude>
Civil war breaks out because of the death of Qin Shi Huangdi.

</doc>
<doc id="60603" url="http://en.wikipedia.org/wiki?curid=60603" title="188 BC">
188 BC

Year 188 BC was a year of the pre-Julian Roman calendar. At the time it was known as the Year of the Consulship of Messalla and Salinator (or, less frequently, year 566 "Ab urbe condita"). The denomination 188 BC for this year has been used since the early medieval period, when the Anno Domini calendar era became the prevalent method in Europe for naming years.
Events.
<onlyinclude>
By place.
Asia Minor.
</onlyinclude>

</doc>
<doc id="60604" url="http://en.wikipedia.org/wiki?curid=60604" title="189 BC">
189 BC

Year 189 BC was a year of the pre-Julian Roman calendar. At the time it was known as the Year of the Consulship of Nobilior and Vulso (or, less frequently, year 565 "Ab urbe condita"). The denomination 189 BC for this year has been used since the early medieval period, when the Anno Domini calendar era became the prevalent method in Europe for naming years.
Events.
<onlyinclude>
By place.
Asia Minor.
</onlyinclude>

</doc>
<doc id="60605" url="http://en.wikipedia.org/wiki?curid=60605" title="Dust storm">
Dust storm

A dust storm or sand storm is a meteorological phenomenon common in arid and semi-arid regions. Dust storms arise when a gust front or other strong wind blows loose sand and dirt from a dry surface. Particles are transported by saltation and suspension, a process that moves soil from one place and deposits it in another.
Drylands around North Africa and the Arabian peninsula are the main terrestrial sources of airborne dust. Also with some contributions from Iran, Pakistan and India into the Arabian Sea, and China's significant storms deposit dust in the Pacific. It has been argued that recently, poor management of the Earth's drylands, such as neglecting the fallow system, are increasing dust storms size and frequency from desert margins and changing both the local and global climate, and also impacting local economies.
The term "sandstorm" is used most often in the context of desert sandstorms, especially in the Sahara Desert, or places where sand is a more prevalent soil type than dirt or rock, when, in addition to fine particles obscuring visibility, a considerable amount of larger sand particles are blown closer to the surface. The term "dust storm" is more likely to be used when finer particles are blown long distances, especially when the dust storm affects urban areas.
Causes.
As the force of wind passing over loosely held particles increases, particles of sand first start to vibrate, then to saltate ("leaps"). As they repeatedly strike the ground, they loosen and break off smaller particles of dust which then begin to travel in suspension. At wind speeds above that which causes the smallest to suspend, there will be a population of dust grains moving by a range of mechanisms: suspension, saltation and creep.
A recent study finds that the initial saltation of sand particles induces a static electric field by friction. Saltating sand acquires a negative charge relative to the ground which in turn loosens more sand particles which then begin saltating. This process has been found to double the number of particles predicted by previous theories. 
Particles become loosely held mainly due to drought or arid conditions, and varied wind causes. Gust fronts may be produced by the outflow of rain-cooled air from an intense thunderstorm. Or, the wind gusts may be produced by a dry cold front, that is, a cold front that is moving into a dry air mass and is producing no precipitation—the type of dust storm which was common during the Dust Bowl years in the U.S. Following the passage of a dry cold front, convective instability resulting from cooler air riding over heated ground can maintain the dust storm initiated at the front.
In desert areas, dust and sand storms are most commonly caused by either thunderstorm outflows, or by strong pressure gradients which cause an increase in wind velocity over a wide area. The vertical extent of the dust or sand that is raised is largely determined by the stability of the atmosphere above the ground as well as by the weight of the particulates. In some cases, dust and sand may be confined to a relatively shallow layer by a low-lying temperature inversion. In other instances, dust (but not sand) may be lifted as high as 20,000 feet (6,100 m) high.
Drought and wind contribute to the emergence of dust storms, as do poor farming and grazing practices by exposing the dust and sand to the wind.
One poor farming practice which contributes to dust storms is dryland farming. Particularly poor dryland farming techniques are intensive tillage or not having established crops or cover crops when storms strike at particularly vulnerable times prior to revegetation. In a semi-arid climate, these practices increase susceptibility to dust storms. However, soil conservation practices may be implemented to control wind erosion.
Physical and environmental effects.
A sandstorm can transport and carry large volumes of sand unexpectedly. Dust storms can carry large amounts of dust, with the leading edge being composed of wall of thick dust as much as 1.6 km high. Dust and sand storms which come off the Sahara Desert are locally known as a simoom or simoon (sîmūm, sîmūn). The "haboob" (həbūb) is a sandstorm prevalent in the region of Sudan around Khartoum, with occurrences being most common in the summer.
The Sahara desert is a key source of dust storms, particularly the Bodélé Depression and an area covering the confluence of Mauritania, Mali, and Algeria.
Saharan dust storms have increased approximately 10-fold during the half-century since the 1950s, causing topsoil loss in Niger, Chad, northern Nigeria, and Burkina Faso. In Mauritania there were just two dust storms a year in the early 1960s, but there are about 80 a year today, according to Andrew Goudie, a professor of geography at Oxford University. Levels of Saharan dust coming off the east coast of Africa in June (2007) were five times those observed in June 2006, and were the highest observed since at least 1999, which may have cooled Atlantic waters enough to slightly reduce hurricane activity in late 2007.
Dust storms have also been shown to increase the spread of disease across the globe. Virus spores in the ground are blown into the atmosphere by the storms with the minute particles then acting like urban smog or acid rain.
Prolonged and unprotected exposure of the respiratory system in a dust storm can also cause silicosis which, if left untreated, will lead to asphyxiation; silicosis is an incurable condition that may also lead to lung cancer. There is also the danger of keratoconjunctivitis sicca ("dry eyes") which, in severe cases without immediate and proper treatment, can lead to blindness.
Economic impact.
Dust storms cause soil loss from the dry lands, and worse, they preferentially remove organic matter and the nutrient-rich lightest particles, thereby reducing agricultural productivity. Also the abrasive effect of the storm damages young crop plants. Dust storms also reduced visibility affecting aircraft and road transportation. In addition dust storms also create problems due to complications of breathing in dust.
Dust can also have beneficial effects where it deposits: Central and South American rain forests get most of their mineral nutrients from the Sahara; iron-poor ocean regions get iron; and dust in Hawaii increases plantain growth. In northern China as well as the mid-western U.S., ancient dust storm deposits known as loess are highly fertile soils, but they are also a significant source of contemporary dust storms when soil-securing vegetation is disturbed.
It has been shown that Saharan soil may have the potential of producing bioavailable iron when illuminated with visible light and also it has some essential macro and micro nutrient elements. In this study the impact of various growth media on development of some bread wheat (Triticum aestivum L.) and durum wheat (Triticum durum L.) cultivars have been investigated. As a four different nutrient media, Hewitt nutrient solution [1], illuminated and non-illuminated Saharan desert soil solutions and distilled water have been utilized. Shoot length (cm.seedling-1), leaf area (cm2 seedling-1) and photosynthetic pigments [chlorophyll a, chlorophyll b and carotenoids, mg ml-1 g fresh weight (g fw)-1] have been determined. The results of this study indicate that, wheat varieties fed by irradiated Saharan soil solution gave comparable results to Hewitt nutrient solution (Yücekutlu et al., 2011).
Extraterrestrial dust storms.
Dust storms are not limited to Earth and have been known to form on other planets such as Mars. These dust storms are much larger and more powerful than dust storms on Earth with wind speeds reaching 100 mph. Martian dust storms are formed when solar heating warms the Martian atmosphere and causes the air to move, lifting dust off the ground. The chance for storms is increased when there are great temperature variations like those seen at the equator during the Martian summer.

</doc>
<doc id="60607" url="http://en.wikipedia.org/wiki?curid=60607" title="211 BC">
211 BC

Year 211 BC was a year of the pre-Julian Roman calendar. At the time it was known as the Year of the Consulship of Maximus and Maximus (or, less frequently, year 543 "Ab urbe condita"). The denomination 211 BC for this year has been used since the early medieval period, when the Anno Domini calendar era became the prevalent method in Europe for naming years.
Events.
<onlyinclude>
By place.
Parthia.
</onlyinclude>

</doc>
<doc id="60608" url="http://en.wikipedia.org/wiki?curid=60608" title="186 BC">
186 BC

Year 186 BC was a year of the pre-Julian Roman calendar. At the time it was known as the Year of the Consulship of Albinus and Philippus (or, less frequently, year 568 "Ab urbe condita"). The denomination 186 BC for this year has been used since the early medieval period, when the Anno Domini calendar era became the prevalent method in Europe for naming years.
Events.
<onlyinclude>
By place.
China.
</onlyinclude>

</doc>
<doc id="60609" url="http://en.wikipedia.org/wiki?curid=60609" title="187 BC">
187 BC

Year 187 BC was a year of the pre-Julian Roman calendar. At the time it was known as the Year of the Consulship of Lepidus and Flaminius (or, less frequently, year 567 "Ab urbe condita"). The denomination 187 BC for this year has been used since the early medieval period, when the Anno Domini calendar era became the prevalent method in Europe for naming years.
Events.
<onlyinclude>
By place.
Egypt.
</onlyinclude>

</doc>
<doc id="60611" url="http://en.wikipedia.org/wiki?curid=60611" title="University of Florida">
University of Florida

The University of Florida (commonly referred to as Florida or UF) is an American public land-grant, sea-grant, and space-grant research university located on a 2000 acre campus in North Central Florida. Howard and Matthew Greene recognized Florida as a Public Ivy in 2001, a publicly funded university considered as providing a quality of education comparable to those of the Ivies. In 2014, U.S. News & World Report ranked Florida as the fourteenth best public university in the United States. It is a senior member of the State University System of Florida and traces its historical origins to 1853, and has operated continuously on its present Gainesville campus since September 1906.
The University of Florida is an elected member of the Association of American Universities (AAU), the association of preeminent North American research universities. The University is classified as a Research University with Very High Research by the Carnegie Foundation for the Advancement of Teaching. The university is accredited by the Southern Association of Colleges and Schools (SACS). Florida Governor Rick Scott and the state Legislature designated the University of Florida as one of two "preeminent" state universities in the spring of 2013. It is the third largest Florida university by student population, and is the eighth largest single-campus university in the United States with 49,913 students enrolled for the fall 2012 semester. The University of Florida is home to sixteen academic colleges and more than 150 research centers and institutes. It offers multiple graduate professional programs—including business administration, engineering, law, dentistry, medicine, and veterinary medicine—on one contiguous campus, and administers 123 master's degree programs and seventy-six doctoral degree programs in eighty-seven schools and departments.
The University of Florida's intercollegiate sports teams, commonly known by their "Florida Gators" nickname, compete in National Collegiate Athletic Association (NCAA) Division I and the Southeastern Conference (SEC). In their 108-year history, the university's varsity sports teams have won 34 national team championships, 28 of which are NCAA titles, and Gator athletes have won 267 individual national championships.
History.
The University of Florida traces its origins to 1853, when the East Florida Seminary, the oldest of the University of Florida's four predecessor institutions, was founded in Ocala, Florida.
On January 6, 1853, Governor Thomas Brown signed a bill that provided public support for higher education in the state of Florida. Gilbert Kingsbury was the first person to take advantage of the legislation, and established the East Florida Seminary, which operated until the outbreak of the Civil War in 1861. The East Florida Seminary was the first state-supported institution of higher learning in Florida.
James Henry Roper, an educator from North Carolina and a state senator from Alachua County, had opened a school in Gainesville, the Gainesville Academy, in 1858. In 1866, Roper offered his land and school to the State of Florida in exchange for the relocation of the East Florida Seminary to Gainesville.
The second major precursor to the University of Florida was the Florida Agricultural College, established at Lake City by Jordan Probst in 1884. Florida Agricultural College became the state's first land-grant college under the Morrill Act. In 1903, the Florida Legislature, desiring to expand the school's outlook and curriculum beyond its agricultural and engineering origins, changed the name of Florida Agricultural College to the "University of Florida," a name that the school would hold for only two years.
"University of the State of Florida".
In 1905, the Florida Legislature passed the Buckman Act, which consolidated the existing publicly supported higher education institutions of the state. The member of the legislature who wrote the act, Henry Holland Buckman, later became the namesake of Buckman Hall, one of the university's oldest buildings. The Buckman Act organized the State University System of Florida and created the Florida Board of Control to govern the system. The act abolished the six pre-existing state-supported institutions of higher education, and consolidated the assets and academic programs of four of them to form the new "University of the State of Florida." The four predecessor institutions consolidated to form the new university included the University of Florida at Lake City (formerly Florida Agricultural College) in Lake City, the East Florida Seminary in Gainesville, the St. Petersburg Normal and Industrial School in St. Petersburg, and the South Florida Military College in Bartow.
The Buckman Act also consolidated the colleges and schools into three institutions segregated by race and gender—the University of the State of Florida for white men, the Florida Female College for white women, and the State Normal School for Colored Students for African-American men and women.
The City of Gainesville, led by its Mayor William Reuben Thomas, campaigned to be home to the new university. On July 6, 1905, the Board of Control selected Gainesville for the new university campus. Andrew Sledd, president of the pre-existing University of Florida at Lake City, was selected to be the first president of the new University of the State of Florida. The 1905-1906 academic year was a year of transition; the new University of the State of Florida was legally created, but operated on the campus of the old University of Florida in Lake City until the first buildings on the new campus in Gainesville were completed. Architect William A. Edwards designed the first official campus buildings in the Collegiate Gothic style. Classes began on the new Gainesville campus on September 26, 1906, with 102 students enrolled.
In 1909, the name of the school was officially simplified from the "University of the State of Florida" to the "University of Florida."
The alligator was incidentally chosen as the school mascot in 1911, after a local vendor ordered and sold school pennants with an alligator emblem imprinted on them. The school colors, orange and blue, are believed to be derived from the blue and white school colors of the Florida Agricultural College in Lake City and the orange and black colors of the East Florida Seminary at Gainesville.
College reorganization.
In 1909, Albert Murphree was appointed the second president of the university, and organized several of the colleges of the university, increased enrollment from under 200 to over 2,000, and he was instrumental in the founding of the Florida Blue Key leadership society. Murphree is the only University of Florida president honored with a statue on the campus.
In 1924, the Florida Legislature mandated that women of a "mature age" (at least twenty-one years old) who had completed sixty semester hours from a "reputable educational institution" would be allowed to enroll during regular semesters at the University of Florida in programs that were unavailable at Florida State College for Women. Before this, only the summer semester was coeducational, to accommodate women teachers who wanted to further their education during the summer break. Lassie Goodbread-Black from Lake City became the first woman to enroll at the University of Florida, in the College of Agriculture in 1925.
John J. Tigert became the third university president in 1928. Disgusted by the under-the-table payments being made by universities to athletes, Tigert established the grant-in-aid athletic scholarship program in the early 1930s, which was the genesis of the modern athletic scholarship plan that is currently used by the National Collegiate Athletic Association.
Post World War II.
Beginning in 1946, there was dramatically increased interest among male applicants who wanted to attend the University of Florida, mostly returning World War II veterans who could attend college under the GI Bill of Rights (Servicemen's Readjustment Act). Unable to immediately accommodate this increased demand, the Florida Board of Control opened the Tallahassee Branch of the University of Florida on the campus of Florida State College for Women in Tallahassee. By the end of the 1946–47 school year, 954 men were enrolled at the Tallahassee Branch. The following semester, the Florida Legislature returned the Florida State College for Women to coeducational status and renamed it Florida State University. This sequence of events also opened up all of the colleges that comprise the University of Florida to female students. African-American students were allowed to enroll starting in 1958. Shands Hospital first opened in 1958 along with the University of Florida College of Medicine to join the already established College of Pharmacy. Rapid campus expansion began in the 1950s and continues to the present day.
The University of Florida is one of two Florida public universities, along with Florida State University, to be designated as a "preeminent university" by Florida senate bill 1076, enacted by the Florida legislature and signed into law by the governor in 2013. As a result of this legislation, the preeminent universities now receive additional funding that is intended to improve the academics and national reputation of higher education within the state of Florida.
National and international prominence.
In 1985, the University of Florida was invited to become a member of the Association of American Universities (AAU), an organization composed of sixty-two academically prominent public and private research universities in the United States and Canada. Florida is one of the seventeen public, land-grant universities that belong to the AAU. In 2009, President Bernie Machen and the University of Florida Board of Trustees announced a major policy transition for the university. The Board of Trustees supported the reduction in the number of undergraduates and the shift of financial and other academic resources to graduate education and research in the future.
Academics.
Tuition.
For the 2008-2009 academic year, annual tuition was:
For the 2009-2010 academic year, annual tuition was:
 In 2012, the University of Florida had the 6th-lowest undergraduate tuition and fees for in-state students.
Demographics.
University of Florida students, numbering 51,413 in Fall 2008, come from more than 130 countries, and all 50 states. The ratio of women to men is 54:46, and 32 percent are graduate and professional students. Professional degree programs include architecture, dentistry, law, medicine, pharmacy and veterinary medicine. Minority populations constitute 33.5 percent of the student body, with 10.0 percent African-Americans, 15.0 percent Hispanics, 0.5 percent Native American, and 8.0 percent Asian-Americans or Pacific Islanders.
During the 2008-2009 academic year the University of Florida had the 12th highest enrollment for International Students in the United States. In total 4,731 international students enrolled at the university and this equates to about 9 percent of the total enrollment. This was more than any other university in Florida. Also confirmed by Peterson's the International Student populations accounts for roughly 9.0% of the entire student body.
The University of Florida is ranked second overall in the United States for the number of bachelor's degrees awarded to African-Americans, and third overall for Hispanics. The university ranks fifth overall in the number of doctoral degrees awarded to African-Americans, and second overall for Hispanics, and third overall in number of professional degrees awarded to African-Americans, and second overall for Hispanics. The university offers many graduate programs—-including engineering, business, law and medicine—-on one contiguous campus, and coordinates 123 master's degree programs and 76 doctoral degree programs in 87 schools and departments.
Rankings.
In 2014, "U.S. News & World Report" ranked the University of Florida as the 14th-best public university in the United States, and 48th overall among all national universities, public and private. In addition, "U.S. News & World Report" ranked the University of Florida 21st in the country based on "yield rates", the percentages of students who actually enroll after being accepted.
Many of the University of Florida's graduate programs have received top-50 rankings from "U.S. News & World Report". In 2013, "U.S. News" ranked Florida's Hough school of business 36th nationally, the school of education education 40th, Florida's medical school (research) 45th, and the Levin college of law 46th.
In 2013, "U.S. News & World Report" ranked Florida's programs in audiology 7th, analytical chemistry 8th, occupational therapy 10th, physical therapy 12th, veterinary medicine 12th, criminology 12th, pharmacy 14th, statistics 27th, healthcare management 32nd, chemistry 36th, physics 36th, clinical psychology 37th, nursing 44th, biological sciences 46th, history 46th, economics 48th, and political science 50th.
In 2013, "U.S. News & World Report" ranked the engineering school 38th nationally, with its programs in biological engineering ranked 3rd, materials engineering 11th, industrial engineering 13th, aerospace engineering 26th, chemical engineering 28th, environmental engineering 30th, computer engineering 31st, civil engineering 32nd, electrical engineering 34th, mechanical engineering 44th.
The 2013 "Academic Ranking of World Universities" list assessed the University of Florida as 71st among world universities and 44th in the United States based on overall research output and faculty awards. In 2013, "Washington Monthly" ranked the University of Florida 24th among national universities, with criteria based on research, community service, and social mobility. The lowest ranking received by the university from a major publication comes from Forbes which ranked the university 74th in the nation (and 21st best public university) in July 2013. This ranking focuses mainly on net positive financial impact, in contrast to other rankings, and generally ranks liberal arts colleges above most research universities.
In 2013, Florida Governor Rick Scott publicly announced his support for the University of Florida to ascend into the top ten among public universities, as measured by "U.S. News & World Report". He called for additional funding to decrease the student-faculty ratio at the university.
Florida was ranked 6th in "The Princeton Review"'s 2014 list of top party schools. It also was named the number one vegan-friendly school for 2014, according to a survey conducted by PETA.
Admissions.
For the Class of 2016 (enrolled fall 2012), Florida received 27,419 applications and accepted 12,092 (44.1%). The number enrolling was 6,289; the yield rate (the percentage of accepted students who enroll) was 52.0%. In terms of class rank, 77% of enrolled freshmen were in the top 10% of their high school classes; 98% ranked in the top quarter. The middle 50% range of SAT scores were 580-670 for critical reading, 590-690 for math, and 570-670 for writing. The middle 50% ACT Composite score range was 26-31.
For fall 2014, the middle 50 percent of admitted freshman applicants had high school GPAs of 4.1-4.5, SAT scores of 1810-2060, and ACT scores of 27-31.
Ending early decision.
In 2007, the University of Florida joined the University of Virginia, Harvard University, the University of North Carolina at Chapel Hill, and Princeton University when they announced that they were discontinuing their early decision admissions in an effort to help foster economic diversity in their student bodies. These universities assert that early decision admissions forces students to accept an offer of admission before evaluating the financial aid offers from multiple universities. The university's single application deadline has been set for November 1.
Honors program.
The University of Florida has a nationally recognized honors program. After gaining acceptance to the university, students must apply separately to the Honors Program and demonstrate significant academic achievement to be accepted. There are over 100 courses offered exclusively to students in this program.
To be invited to apply to the program, freshmen must have a weighted GPA of at least 4.0 and an SAT score of 2070 out of 2400 or an ACT score of 33. In 2011, more than 1900 students applied for 700 available seats. The Honors Program also offers housing for freshman in the Honors Residential College at Hume Hall. The Honors Program also offers special scholarships, internships, research, and study abroad opportunities.
Scholarships.
The Lombardi Scholars Program, created in 2002 and named in honor of the university's ninth president John V. Lombardi, is a significant merit scholarship for Florida students. The scholarship offers $2,700 a semester for a total of eight to ten semesters.
The J. Wayne Reitz Scholars Program, created in 1997 and named in honor of the university's fifth president J. Wayne Reitz, is a leadership and merit-based scholarship for Florida students. The scholarship offers a yearly $2,500 stipend that may be renewed for up to three years.
Sustainability.
In 2005, the University of Florida became a Certified Audubon Cooperative Sanctuary for environmental and wildlife management, resource conservation, environmental education, waste management, and outreach.
Through long-term environmental initiatives, the University of Florida created an Office of Sustainability in 2006. Their mission is to continue to improve environmental sustainability in many different areas on campus. They have stated that their future goals are to produce zero waste by 2015, and to achieve Carbon Neutrality by 2025. Recently the university appointed Anna Prizzia as the University's new Sustainability Director. Florida received a "B+" grade on the 2009 College Sustainability Report Card for its environmental and sustainability initiatives. In 2009 "B+" was the second highest grade awarded by the Sustainable Endowments Institute.
Colleges and academic divisions.
The University of Florida is divided into 16 colleges and more than 150 research, service and education centers, bureaus and institutes, offering more than 100 undergraduate majors and 200 graduate degrees.
These colleges include:
Satellite facilities.
The university also maintains a number of facilities apart from its main campus. The J. Hillis Miller Health Science Center also has a teaching hospital located at UF Health at Jacksonville, which serves as the Jacksonville campus for the University's College of Medicine, College of Nursing, and College of Pharmacy. A number of residencies are also offered at this facility. The University's College of Pharmacy also maintains campuses in Orlando, Jacksonville, and St. Petersburg. The College of Dentistry maintains clinics in Hialeah, Naples, and St. Petersburg.
The university's Warrington College of Business established programs in South Florida in 2004, and recently built a 6100 sqft facility in Sunrise, Florida. The Institute of Food and Agricultural Sciences has extensions in each of the 67 counties in Florida, and 13 research and education centers with a total of 19 locations throughout the state. In 2005, the university established the Beijing Center for International Studies in Beijing that offers research facilities, offices, and degree opportunities.
Research.
The University of Florida is one of the largest research universities in the nation. According to a 2011 study by the university's Institute of Food and Agricultural Sciences, the university contributed $8.76 billion to Florida's economy and was responsible for over 100,000 jobs in the 2009–2010 fiscal year. The Milken Institute named Florida one of the top-five U.S. institutions in the transfer of biotechnology research to the marketplace (2006). Some 50 biotechnology companies have resulted from faculty research programs. Florida consistently ranks among the top-10 universities in licensing. Royalty and licensing income includes the glaucoma drug Trusopt, the sports drink Gatorade, and the Sentricon termite elimination system. The Institute of Food and Agricultural Sciences is ranked No. 1 by the NSF in Research and Development; its current Vice President is Dr. Larry Arrington. Florida currently ranks seventh among all private and public universities for the total number of patents awarded for 2005.
The University of Florida was awarded $678 million in total research expenditures, more than all the other Florida universities combined, in sponsored research in 2009-2010. Research includes diverse areas such as health-care and citrus production (the world's largest citrus research center). In 2002, Florida began leading six other universities under a $15 million NASA grant to work on a variety of space-related research during a five-year period. The university has a partnership with Spain that helped to create the world's largest single-aperture optical telescope in the Canary Islands (the total cost was $93 million). Plans are also under way for the University of Florida to construct a new 50000 sqft research facility in collaboration with the Burnham Institute for Medical Research that will ultimately be located in the center of University of Central Florida's Health Sciences Campus in Orlando, Florida. Research will include the areas of diabetes, aging, genetics and cancer.
The University of Florida has made great strides in the space sciences over the last decade. The Astronomy Department's focus on the development of image-detection devices has led to increases in funding, telescope time, and significant scholarly achievements. Faculty members in organic chemistry have made notable discoveries in astrobiology, while faculty members in physics have participated actively in the Laser Interferometer Gravitational-Wave Observatory project, the largest and most ambitious project ever funded by the NSF. Through the Department of Mechanical and Aerospace Engineering, the University of Florida is the lead institution on the NASA University Research, Engineering, and Technology Institute (URETI) for Future Space Transport project to develop the next generation space shuttle. In addition, the university also performs diabetes research in a statewide screening program that has been sponsored by a $10 million grant from the American Diabetes Association. The University of Florida also houses one of the world's leading lightning research teams. University scientists have started up a biofuels pilot plant that has been specifically designed to test ethanol-producing technology. UF is also host to a nuclear research reactor which is known for its Neutron Activation Analysis Laboratory. In addition, the University of Florida is the first American university to receive a European Union grant to house a Jean Monnet Centre of Excellence.
The University of Florida has more than $750 million in new research facilities recently completed or under construction, including the Nanoscale Research Facility, the Pathogens Research Facility and the Biomedical Sciences Building. Additionally, Innovation Square, a 24/7 live/work/play research environment being developed along Southwest Second Avenue between the University of Florida campus and downtown Gainesville, recently broke ground and plans to open next fall. The university's Office of Technology Licensing will relocate to Innovation Square, joining Florida Innovation Hub, a business "super-incubator designed to promote the development of new high-tech companies based on the university's research progtrams. Innovation Square also will include retail space, restaurants and local businesses, as well as residential space for people to live.
The International Center for Lightning Research and Testing.
Florida has more lightning than any other state in the U.S. The University of Florida houses one of the world's leading international lightning research teams. The International Center for Lightning Research and Testing (ICLRT) are run by the University of Florida at the Camp Blanding Florida Army National Guard Base. The ICLRT Center occupies over 100 acre (40 ha) at Camp Blanding, located about 25 miles (45 km) north-east of Gainesville, Florida. One of their primary research tools is lightning initiation from overhead thunderclouds using the triggered lightning rocket-and-wire technique. Small sounding rockets connected to long copper wires are fired into likely lightning storm cumulonimbus clouds. When the rocket or its wire is struck by lightning, the passing of the high current lightning strike down the wire vaporizes it as the lightning travels to the ground. Undergraduate and graduate research in the Department of Electrical and Computer Engineering's Lightning Research Group is used to increase new fundamental knowledge about lightning-based phenomena.
UF Health.
University of Florida Health has two main campuses in Gainesville and Jacksonville. Its mission is to promote health through high-quality patient care; education in the health professions and biomedical sciences; and research across the spectrum of basic, translational and clinical investigation. UF Health includes two teaching hospitals and two specialty hospitals, as well as the colleges of Dentistry, Medicine, Nursing, Pharmacy, Public Health and Health Professions, and Veterinary Medicine, which includes both a large animal hospital and a small animal hospital. The system also encompasses six UF research institutes: the Clinical and Translational Science Institute, the Evelyn F. and William L. McKnight Brain Institute, the Genetics Institute, the UF Health Cancer Center, the Institute on Aging and the Emerging Pathogens Institute. UF Health is the only academic health center in the United States with six health-related colleges located on a single, contiguous campus.
Patient-care services are provided through the private, not-for-profit UF Health Shands family of hospitals and programs. UF Health Shands Hospital in Gainesville includes UF Health Shands Children's Hospital and UF Health Shands Cancer Hospital. The specialty hospitals, UF Health Shands Rehab Hospital and UF Health Shands Psychiatric Hospital, are also located in Gainesville. UF Health Jacksonville is the system's northeast Florida academic medical center.
UF Health has a network of outpatient rehabilitation centers, UF Health Rehab Centers, and two home-health agencies, UF Health Shands HomeCare; as well as more than 80 UF physician outpatient practices located throughout north central and northeast Florida.
UF Health is also affiliated with the Veterans Affairs hospitals in Gainesville and North Florida/South Georgia. In all 6,159 total students are enrolled in all six of the colleges. is also part of the Health Science Center and is the most comprehensive program of its kind in the world. The Institute comprises 300 faculty members from 10 colleges, and 51 departments campus-wide.
The University of Florida is a winner of the National Institutes of Health Clinical and Translational Science Award and member of the prestigious NIH national consortium of medical research institutions.
UF Health Jacksonville.
 is an academic health center with three UF colleges, Medicine, Nursing and Pharmacy, as well as a network of primary and specialty care centers throughout northeast Florida and southeast Georgia.
Orlando Health.
In 2010, Orlando Health and UF Health teamed up to form joint clinical programs in the areas of pediatrics, neuroscience, oncology, women's health, transplantation and cardiovascular medicine. The partnership provides undergraduate and graduate medical residency and fellowship training opportunities at Orlando Health, and will allow Orlando Health physicians and patients to be part of clinical trials through UF's clinical research program.
UF Health Cancer Center at Orlando Health.
UF Health Cancer Center at Orlando Health launched in January 2014. The center focuses on developing safe, individualized molecular-based targeted oncology therapies to improve patient outcomes in Florida. The joint oncology program offers clinical trial collaborations and comprehensive cancer services customized to the patient by combining physicians and the collective strengths of UF Health and Orlando Health.
Participation in the Large Hadron Collider.
A team of UF physicists has a leading role in one of the two major experiments planned for the Large Hadron Collider, a 17 mi-long, $5 billion, super-cooled underground tunnel outside Geneva, Switzerland. More than 30 UF physicists, postdoctoral associates, graduate students and now undergraduates are involved in the collider's Compact Muon Solenoid (CMS) experiment, one of its two major experiments. About 10 are stationed in Geneva. The group is the largest from any university in the U.S. to participate in the CMS experiment. The UF team designed and oversaw development of a major detector within the CMS. The detector, the Muon system, is intended to capture subatomic particles called muons, which are heavier cousins of electrons. Among other efforts, UF scientists analyzed about 100 of the 400 detector chambers placed within the Muon system to be sure they were functioning properly. The bulk of the UF research was funded by the U.S. Department of Energy.
Partnership with Zhejiang University.
In July 2008, the University of Florida teamed up with the Zhejiang University to research sustainable solutions to the Earth's energy issues. Overall a Joint Research Center of Clean Sustainable Energy among the Florida Institute for Sustainable Energy, at UF, and the State Key Lab of Clean Energy Utilization and the Institute for Thermal Power Engineering, at Zhejiang University will collaborate to work on this pressing issue.
SECU: SEC Academic Initiative.
The University of Florida is a member of the SEC Academic Consortium. Now renamed the SECU, the initiative was a collaborative endeavor designed to promote research, scholarship and achievement amongst the member universities in the Southeastern conference. Along with the University of Georgia, University of Florida, Vanderbilt University and other SEC institutions, SECU formed its mission to serve as a means to bolster collaborative academic endeavors of Southeastern Conference universities. Its goals include highlighting the endeavors and achievements of SEC faculty, students and its universities and advancing the academic reputation of SEC universities.
In 2013, the University of Florida participated in the SEC Symposium in Atlanta, Georgia which was organized and led by the University of Georgia and the UGA Bioenergy Systems Research Institute. The topic of the Symposium was titled, the "Impact of the Southeast in the World's Renewable Energy Future."
Libraries.
The University of Florida's George A. Smathers Libraries, is one of the largest university library systems in the United States. In total, the University of Florida has ten libraries, and over 5.3 million volumes of books and journals and 7 million microfilms. Collections cover virtually all disciplines and include a wide array of formats – from books and journals to manuscripts, maps, and recorded music. Increasingly collections are digital and are accessible on the Internet via the library web page or the library catalog.
The numerous libraries provide primary support to all academic programs except those served by the and the Lawton Chiles Legal Information Center. In 2006, Library West went through a $30 million renovation that doubled capacity. This facility is now better equipped to handle the information technology necessities that students need to complete their studies. Such progress is represented by its state-of-the-art Information Commons, which offers production studios, digital media computing areas, and a presentation area.
Campus.
In total the University of Florida campus encompasses over 2,000 acre. The campus is home to many notable structures, such as Century Tower, a 157 ft tall carillon tower in the center of the historic district. Other notable facilities include the Health Science Center, Ben Hill Griffin Stadium, Reitz Student Union, Smathers Library, Phillips Center for the Performing Arts, Harn Museum, University Auditorium, O'Connell Center, and The Hub.
Historic sites.
A number of the University of Florida's buildings are historically significant. The University of Florida Campus Historic District comprises 19 buildings and encompasses approximately 650 acre. Two buildings outside the historic district, the old WRUF radio station (now the university police station) and Norman Hall (formerly the P. K. Yonge Laboratory School), are also listed on the historic register. The buildings listed on the U.S. National Register of Historic Places for their architectural or historic significance are:
Student life.
Fraternities and sororities.
Approximately 5,200 undergraduate students (or approximately 15%) are members of either a sorority or fraternity. Sorority and Fraternity Affairs (formerly known as Greek Life) at the University of Florida is separated into four divisions: Interfraternity Council (IFC), National Panhellenic Conference (NPC), Multicultural Greek Council (MGC), and the National Pan-Hellenic Council (NPHC). The Order of Omega has a chapter at the university.
The Interfraternity Council (IFC) comprises 25 fraternities, and the Panhellenic Council is made up of 16 sororities. Some of the fraternity chapters on campus are older than the university itself, with the first chapters being chartered in 1884 and founded on the campus of one of the university's predecessor institutions in Lake City.
The Multicultural Greek Council consists of 12 cultural organizations (Latino, Asian, South Asian, etc.), seven fraternities and five sororities. The National Pan-Hellenic Council comprises nine historically black organizations, five fraternities and four sororities.
There are now also four university recognized organizations for Christian students, Beta Upsilon Chi and Kappa Phi Epsilon fraternities as well as Sigma Phi Lambda and Theta Alpha sororities.
Dance Marathon at UF.
Dance Marathon at UF is an annual 26.2-hour event benefiting the patients of University of Florida Health Shands Children's Hospital in Gainesville, Florida. Each year, more than 800 students stay awake and on their feet to raise money and awareness for Children's Miracle Network Hospitals. In the 21 years of Dance Marathon at UF's existence, more than $10 million has been donated, making it the most successful student-run philanthropy in the Southeastern United States. In 2015, DM at UF raised a record total of $2,015,307.17 for UF Health Shands Children's Hospital and becoming the second most successful Dance Marathon in the nation.
Reserve Officer Training Corps.
The University of Florida Reserve Officer Training Corps is the official officer training and commissioning program at the University of Florida. Officially founded in 1905, it is one of the oldest such programs in the nation.
The Reserve Officer Training Corps offers commissions for the United States Army, United States Navy, United States Marine Corps, and the United States Air Force. The unit is one of the oldest in the nation, and is currently located at Van Fleet Hall.
The Reserve Officer Training Corps at the University of Florida offers training in the military sciences to students who desire to perform military service after they graduate. The Departments of the Army, Air Force, and Navy each maintain a Reserve Officers Training Corps and each individual department has a full staff of military personnel.
Housing.
The University of Florida provides over 9,200 students with housing in residence halls and complexes on the eastern and western sides of campus. Facilities vary in the cost of rent and privacy. Housing plans also offer students access to dining facilities. The university also provides housing to a number of graduate students and their families. As of 2014, the University is currently building a new residence hall on campus that will be more accessible to students with disabilities.
Recreation.
Many recreational activities available for students include indoor and outdoor sports, outdoor courts and playing fields on campus, in the O'Connell Center, University Golf Course, Plaza of the Americas, the Student Recreation and Fitness Center, the Southwest Recreation Center, and the Florida Gymnasium for indoor sports. Florida offers intramural and club sports ranging from archery to weightlifting. Near the campus are many recreational lakes and rivers, including university-owned Lake Alice. In addition, student have access to the J. Wayne Reitz Union which is equipped with a bowling alley, pool tables, an arcade, and numerous other activities. South of Gainesville is Lake Wauburg, which also provides recreational activities for students, faculty, and staff. To the northwest of campus is the Devil's Millhopper Geological State Park.
The campus also contains open spaces, small ponds, picnic areas, shady nooks and an 81 acre wildlife sanctuary that provide opportunities to enjoy Florida's year-round sunshine activity life.
Lastly, the University of Florida has more than eight hundred organizations and clubs for students to join. They range from cultural and athletic to subjects pertaining to philanthropy. Some of the most popular organizations are Florida Blue Key, Theatre Strike Force, the Marching Band, Florida Competitive Cheerleading, Dazzlers, the Gatorettes, Hillel at UF, Gator Growl, Progressive Black Journalists, Miss University of Florida, and the Speakers Bureau. If students wish they can create their own registered student organization if the current interest or concern is not addressed by the previously established entities.
Student affairs rankings.
The University of Florida received the following rankings by The Princeton Review in its 2012 "Best 376 Colleges" Rankings:
Student government.
The University of Florida Student Government is the governing body of students who attend the University of Florida, representing the university's nearly 50,000 undergraduate, graduate and professional students. The university's student government currently operates on a yearly $18.7 million budget, one of the largest student government budgets in the United States, and the money is allocated by the Budget Committee of the Student Senate.
The student government was established in 1909 and consists of executive, judicial and unicameral legislative branches. The executive branch includes the student government president, vice president and treasurer elected by the student body during the spring semester, as well as nine agencies and forty-one cabinet members.
The Student Senate is the legislative branch, and is composed of 100 senators who serve one-year terms. The student body elects fifty senators during each spring semester and the remaining fifty during the fall semester. The senators elect a Senate President and Senate President Pro Tempore twice a year, after each semester's elections, to lead the Student Senate. During student government elections students may also vote on referendums, such as the renewable energy referendum, which was approved by 78% of voting students in the spring of 2007. This referendum proposed a fifty-cents-per-credit-hour increase to student activity fees to fund renewable energy and efficiency on campus.
The student government judicial branch has two major components: the Supreme Court of the Student Body (headed by a Chief Justice) and all elections related officials (the Supervisor of Elections and the Elections Commission). The Supreme Court consists of seven second or third-year law students nominated by the Student Body President and confirmed by the Student Senate. Each justice serves a "life-time" term, which extends through the individual justice's graduation and insulates the court from the politics of student government. The Chief Justice may appoint a marshal and clerk. The election commission is also composed of law students and it adjudicates all student government election complaints. The commission has six members, one of whom also serves as the commission chairman.
The student government executive branch is led by the Student Body President and includes the Student Body Vice President, Student Body Treasurer, twelve agencies, twelve executive secretaries, nineteen cabinet directors, and three cabinet chairs.
Alma mater.
The alma mater for the University of Florida was composed by Milton Yeats in 1925.
Campus and area transportation.
The UF campus is served by nine bus routes of the Gainesville Regional Transit System (RTS), which had over ten million riders in 2011. Students, faculty, and staff with university-issued ID cards are able to use the system at no extra cost. The RTS also provides other campus services, including Gator Aider (during football games), S.N.A.P, and Later Gator nighttime service.
University of Florida is also served by the Gainesville Regional Airport, which is located in the Northeast portion of Gainesville and has daily services to Miami, Atlanta, and Charlotte.
Student media.
The University of Florida community includes six major student-run media outlets.
Various other journals and magazines are published by the university's academic units and student groups, including the literary journal "Subtropics".
Career placement.
The University of Florida Career Resource Center is located in the Reitz Student Union. Its mission is to assist students and alumni who are seeking career development, career experiences, and employment opportunities. These services involve on and off-campus job interviews, career planning, assistance in applying to graduate and professional schools, and internship and co-op placements. The Career Resource Center offers workshops, information sessions, career fairs, and advisement on future career options. Staff also counsel students and alumni regarding resumes and portfolios, interviewing tactics, cover letters, job strategies and other potential leads for finding employment in the corporate, academic and government sectors.
The Princeton Review ranked the Career Resource Center as the best among 368 ranked universities in career and job placement services in 2010, and fourth overall in 2011.
Museums.
The Florida Museum of Natural History, established in 1891, is one of the oldest natural history museums in the country and was officially chartered by the State of Florida. This facility is dedicated to understanding, preserving and interpreting biological diversity and cultural heritage. In over 100 years of operations the Florida Museum of Natural History has been housed in several buildings, from the Seagle Building to facilities at Dickinson Hall, Powell Hall, and the Randell Research Center. In 2000 the McGuire Center for Lepidoptera and Biodiversity was opened after a generous donation from University of Florida benefactors. The McGuire Center houses a collection of more than six million butterfly and moth specimens, making it one of the largest collections of Lepidoptera in the world, rivaling that of the Natural History Museum in London, England.
The Samuel P. Harn Museum of Art, established in 1990, is also located at the University of Florida on the southwest part of campus. This facility is one of the largest university art museums in the South, the Harn has more than 7,000 works in its permanent collection and an array of temporary exhibitions. The museum's permanent collections are focused on Asian, African, modern and contemporary art, as well as photography. The university sponsors educational programs at the museum including films, lectures, interactive activities, and school and family offerings. In October 2005 the Harn expanded by more than 18000 sqft with the opening of the Mary Ann Harn Cofrin Pavilion, which includes new educational and meeting areas and the Camellia Court Cafe, the first eatery for visitors of the Cultural Plaza.
Performing arts and music.
Performing arts venues at the University of Florida consist of the Curtis M. Phillips Center for the Performing Arts, the University Auditorium, Constans Theatre, the Baughman Center, and performances at the O'Connell Center. The mission is to provide an unparalleled experience where the performing artists create and share knowledge to serve the student body, faculty, and staff at the university; Gainesville residents; and visitors to North Central Florida.
The University Auditorium was founded in the mid-1920s and is home to the Anderson Memorial Organ. The auditorium has a concert stage and can seat up to 843 patrons. The venue is suitable for musical concerts, special lectures, convocations, dance concerts, and pageants.
The Phillips Center for the Performing Arts was founded in 1992 and is a performing arts theatre. The Phillips Center is located on the western side of campus, and hosts established and emerging national and international artists on the main stage, as well as the annual Miss University of Florida pageant and performances by the University of Florida's original student-run dance company, Floridance. In all, the Phillips Center consists of a 1,700-seat proscenium hall and the 200-seat Squitieri Studio Theatre.
Constans Theatre was founded in 1967 and is a performing arts venue located next to the J. Wayne Reitz Union. Constans Theatre serves as a venue for musical concerts, theater, dance, and lectures, and is a sub-venue of the Nadine McGuire Pavilion and Dance Pavilion.
The Baughman Center was founded in 2000 and serves as a venue for small musical and performing arts events. The facility consists of two buildings located next to Lake Alice on the western portion of campus. The main building is a 1500 sqft pavilion, while the other is a 1000 sqft administrative building. Overall the Baughman Center can accommodate up to 96 patrons.
In popular culture.
The University of Florida has been portrayed in several books, movies and television shows. In addition, the University of Florida campus has been the backdrop for a number of different books and movies. Robert Cade, a professor in the university's College of Medicine, was the leader of the research team that invented the ubiquitous sports drink Gatorade as a hydration supplement for the Florida Gators football team in 1965–66, and was later featured in a series of television commercials, "The Legend of Gatorade," which have prominently featured the university and the Gators.
Athletics.
The University of Florida's intercollegiate sports teams, known as the "Florida Gators," compete in National Collegiate Athletic Association (NCAA) Division I and the Southeastern Conference (SEC). The Gators compete in nine men's sports and twelve women's sports, including:
For the 2013–14 school year, the University Athletic Association budgeted more $100 million for its sports teams and facilities. Since 1987–88, the Gators have won twenty-three of the last twenty-six SEC All-Sports Trophies, recognizing Florida as the best overall athletics program in the SEC. Florida is the only program in the nation to finish among the nation's top ten in each of the last thirty national all-sports standings and is the only SEC school to place 100 or more student-athletes on the Academic Honor Roll each of the last fifteen years.
The Florida Gators have won a total of thirty-three national team championships, twenty-eight of which are NCAA championships. Florida Gators athletes have also won 267 NCAA championships in individual sports events. Florida is one of only two Division I FBS universities to win multiple national championships in each of the two most popular NCAA sports: football (1996, 2006, 2008) and men's basketball (2006, 2007).
Olympics.
The University of Florida has a long history of producing athletes who compete in the Olympic Games. Since 1968, 145 Gator athletes and 13 Florida coaches have represented 37 countries in the Games, winning 50 Olympic gold medals, 29 silver medals and 30 bronze medals through the 2012 Summer Olympics. The list of University of Florida alumni who are Olympic gold medalists includes Brad Wilkerson (baseball); Delisha Milton-Jones (basketball); Steve Mesler (bobsled); Heather Mitts and Abby Wambach (soccer); Theresa Andrews, Catie Ball, Tracy Caulkins, Matt Cetlinski, Conor Dwyer, Geoff Gaberino, Nicole Haislett, Mike Heath, David Larson, Ryan Lochte, Anthony Nesty, Dara Torres, Mary Wayte and Martin Zubero (swimming); and Kerron Clement, Dennis Mitchell, Frank Shorter, Christian Taylor and Bernard Williams (track and field).
Football.
The University of Florida fielded its first official varsity football team in the fall of 1906, when the university held its first classes on its new Gainesville campus. Since then, the Florida Gators football team has played in 40 bowl games, won three consensus national championships and seven Southeastern Conference (SEC) championships, produced 89 first-team All-Americans, 45 National Football League (NFL) first-round draft choices, and three Heisman Trophy winners.
The Gators won their first post-season game on January 1, 1953, beating Tulsa 14-13 in Jacksonville, Florida. The Gators' first major bowl win was the 1967 Orange Bowl in which coach Ray Graves and Heisman Trophy quarterback Steve Spurrier led the Gators to a 27–12 victory over the Georgia Tech Yellow Jackets.
In 1990, Spurrier returned to his alma mater as its new head coach, and spurred the Gators to their first six official SEC football championships. The Gators, quarterbacked by their second Heisman Trophy winner, Danny Wuerffel, won their first national championship in 1996 with a 52–20 victory over Florida State Seminoles in the Sugar Bowl. In 2006, Urban Meyer coached the Gators to a 13–1 record, capturing their seventh SEC Championship, and defeating the top-ranked Ohio State Buckeyes 41–14 for the BCS National Championship. In 2008, the Gators' third Heisman-winning quarterback, Tim Tebow, led them in a 24–14 BCS Championship Game victory over the Oklahoma Sooners for the team's third national championship.
Since 1930, the Gators' home field has been Florida Field at Ben Hill Griffin Stadium, which seats 88,548 fans. The stadium is popularly known as "The Swamp."
Basketball.
The Florida Gators men's basketball team has also gained national recognition over the past twenty years. The Gators went to the Final Four of the 1994 NCAA tournament under coach Lon Kruger, and coach Billy Donovan led the Gators back to the NCAA Final Four in 2000, losing to the Michigan State Spartans in the final. Under Donovan, the Gators won their first Southeastern Conference (SEC) tournament championship in 2005, beating the Kentucky Wildcats. After repeating as SEC tournament champions in 2006, the Gators won their first basketball national championship, defeating the UCLA Bruins 73–57 in the final game of the NCAA basketball tournament.
The Gators beat the Arkansas Razorbacks 77–56 to win their third consecutive SEC tournament title in 2007. Florida defeated Ohio State 84–75 to again win the NCAA basketball tournament championship.
The Gators play their home games in the O'Connell Center. The 11,548-seat multi-purpose indoor arena was completed in 1980, and is popularly known as the "O'Dome."
Notable alumni.
The University of Florida has more than 330,000 alumni. In total 57,000 are dues-paying members of the University of Florida Alumni Association. Florida alumni can be found in every state and more than 100 foreign countries. Florida alumni account for multiple Nobel Prize winners, ten U.S. Senators, forty U.S. Representatives, eleven state governors, and eight U.S. ambassadors, multiple state supreme court judges, and various federal courts judges. Florida graduates have served as the executive leaders of such diverse institutions as the United States Marine Corps and the National Organization for Women.
Notable faculty.
Individual awards won by UF faculty include a Fields Medal, numerous Pulitzer Prizes, and NASA's top award for research and Smithsonian Institution's conservation award. There are currently more than 60 Eminent Scholar chairs, and nearly 60 faculty elections to the National Academy of Sciences, Engineering, or Arts and Sciences, the Institute of Medicine or a counterpart in a foreign nation. More than two dozen faculty are members of the National Academies of Science and Engineering and the Institute of Medicine or counterpart in a foreign nation.
University benefactors.
The University of Florida has had many financial supporters, but some stand out by the magnitude of their contributions.
Among those who have made large donations commemorated at the university are:

</doc>
<doc id="60613" url="http://en.wikipedia.org/wiki?curid=60613" title="Jacksonville, Florida">
Jacksonville, Florida

Jacksonville is the largest city by population in the U.S. state of Florida, and the largest city by area in the contiguous United States. It is the county seat of Duval County, with which the city government consolidated in 1968. Consolidation gave Jacksonville its great size and placed most of its metropolitan population within the city limits; with an estimated population in 2013 of 842,583, it is the most populous city proper in Florida and the Southeast, and the 13th most populous in the United States. Jacksonville is the principal city in the Jacksonville metropolitan area, with a population of 1,345,596 in 2010.
Jacksonville is in the First Coast region of northeast Florida and is centered on the banks of the St. Johns River, about 25 mi south of the Georgia state line and about 340 mi north of Miami. The Jacksonville Beaches communities are along the adjacent Atlantic coast. The area was originally inhabited by the Timucua people, and in 1564 was the site of the French colony of Fort Caroline, one of the earliest European settlements in what is now the continental United States. Under British rule, settlement grew at the narrow point in the river where cattle crossed, known as "Wacca Pilatka" to the Seminole and the Cow Ford to the British. A platted town was established there in 1822, a year after the United States gained Florida from Spain; it was named after Andrew Jackson, the first military governor of the Florida Territory and seventh President of the United States.
Harbor improvements since the late 19th century have made Jacksonville a major military and civilian deep-water port. Its riverine location facilitates two U.S. Navy bases and the Port of Jacksonville, Florida's third largest seaport. Significant factors in the local economy include services such as banking, insurance, healthcare and logistics. As with much of Florida, tourism is also important to the Jacksonville area, particularly tourism related to golf. In 2012, Jacksonville was listed as a "sufficiency" world city in the World Cities Study Group’s inventory, ranking alongside cities such as Abuja and Tulsa. People from Jacksonville may be called "Jacksonvillians" or "Jaxsons" (also spelled "Jaxons").
History.
Early history.
The area of the modern city of Jacksonville has been inhabited for thousands of years. On Black Hammock Island in the national Timucuan Ecological and Historic Preserve, a University of North Florida team discovered some of the oldest remnants of pottery in the United States, dating to 2500 BC. In the 16th century, the beginning of the historical era, the region was inhabited by the Mocama, a coastal subgroup of the Timucua people. At the time of contact with Europeans, all Mocama villages in present-day Jacksonville were part of the powerful chiefdom known as the Saturiwa, centered around the mouth of the St. Johns River. One early map shows a village called "Ossachite" at the site of what is now downtown Jacksonville; this may be the earliest recorded name for that area.
European explorers first arrived in the area 1562, when French Huguenot explorer Jean Ribault charted the St. Johns River. In 1564, René Goulaine de Laudonnière established the first European settlement, Fort Caroline, on the St. Johns near the main village of the Saturiwa. On September 20, 1565, a Spanish force from the nearby Spanish settlement of St. Augustine attacked Fort Caroline, and killed nearly all the French soldiers defending it. The Spanish renamed the fort "San Mateo", and following the ejection of the French, St. Augustine's position as the most important settlement in Florida was solidified. The location of Fort Caroline is subject to debate but a reconstruction of the fort was established on the St. Johns River in 1964.
Spain ceded Florida to the British in 1763 after the French and Indian War, and the British soon constructed the King's Road connecting St. Augustine to Georgia. The road crossed the St. Johns River at a narrow point, which the Seminole called "Wacca Pilatka" and the British called the Cow Ford or Cowford; these names ostensibly reflect the fact that cattle were brought across the river there. The British introduced the cultivation of sugar cane, indigo and fruits as well the export of lumber. As a result, the northeastern Florida area prospered economically more than it had under the Spanish. Britain ceded control of the territory back to Spain in 1783, after its defeat in the American Revolutionary War, and the settlement at the Cow Ford continued to grow. After Spain ceded the Florida Territory to the United States in 1821, American settlers on the north side of the Cow Ford decided to plan a town, laying out the streets and plats. They soon named the town Jacksonville, after Andrew Jackson. Led by Isaiah D. Hart, residents wrote a charter for a town government, which was approved by the Florida Legislative Council on February 9, 1832.
Civil War and the Gilded Age.
During the American Civil War, Jacksonville was a key supply point for hogs and cattle being shipped from Florida to aid the Confederate cause. The city was blockaded by Union forces, who gained control of the nearby Fort Clinch. Though no battles were fought in Jacksonville proper, the city changed hands several times between Union and Confederate forces. In 1864 Union forces left Jacksonville and confronted a Confederate Army at the Battle of Olustee resulting in a Confederate victory. Union forces then retreated to Jacksonville and held the city for the remainder of the war. Warfare and the long occupation left the city disrupted after the war.
During Reconstruction and the Gilded Age, Jacksonville and nearby St. Augustine became popular winter resorts for the rich and famous. Visitors arrived by steamboat and later by railroad. President Grover Cleveland attended the Sub-Tropical Exposition in the city on February 22, 1888 during his trip to Florida. This highlighted the visibility of the state as a worthy place for tourism. The city's tourism, however, was dealt major blows in the late 19th century by yellow fever outbreaks. In addition, extension of the Florida East Coast Railway further south drew visitors to other areas. From 1893 to 1938 Jacksonville was the site of the Florida Old Confederate Soldiers and Sailors Home with a nearby cemetery.
The Great Fire of 1901.
On May 3, 1901, downtown Jacksonville was ravaged by a fire that started at a fiber factory in LaVilla. Known as the "Great Fire of 1901", it was one of the worst disasters in Florida history and the largest urban fire in the southeastern United States. In just eight hours, it swept through 146 city blocks, destroyed over 2,000 buildings, left about 10,000 homeless and killed 7 residents. The Confederate Monument in Hemming Park was one of the only landmarks to survive the fire. Governor Jennings declare martial law and sent the state militia to maintain order. It is said the glow from the flames could be seen in Savannah, Georgia, and the smoke plumes seen in Raleigh, North Carolina. Architect Henry John Klutho was a primary figure in the reconstruction of the city.
Modern Jacksonville.
In the 1910s, New York–based filmmakers were attracted to Jacksonville's warm climate, exotic locations, excellent rail access, and cheap labor. Over the course of the decade, more than 30 silent film studios were established, earning Jacksonville the title of "Winter Film Capital of the World". However, the emergence of Hollywood as a major film production center ended the city's film industry. One converted movie studio site, Norman Studios, remains in Arlington; It has been converted to the Jacksonville Silent Film Museum at Norman Studios.
During this time, Jacksonville also became a banking and insurance center, with companies such as Barnett Bank, Atlantic National Bank, Florida National Bank, Prudential, Gulf Life, Afro-American Insurance, Independent Life and American Heritage Life thriving in the business district. The U.S. Navy also became a major employer and economic force during the 1940s, with the construction of three naval bases in the city.
Jacksonville, like most large cities in the United States, suffered from negative effects of rapid urban sprawl after World War II. The construction of highways led residents to move to newer housing in the suburbs. After World War II, the government of the city of Jacksonville began to increase spending to fund new public building projects in the boom that occurred after the war. Mayor W. Haydon Burns' "Jacksonville Story" resulted in the construction of a new city hall, civic auditorium, public library and other projects that created a dynamic sense of civic pride. However, the development of suburbs and a subsequent wave of middle class "white flight" left Jacksonville with a much poorer population than before. The city's most populous ethnic group, non-Hispanic white, declined from 75.8% in 1970 to 55.1% by 2010.
Much of the city's tax base dissipated, leading to problems with funding education, sanitation, and traffic control within the city limits. In addition, residents in unincorporated suburbs had difficulty obtaining municipal services, such as sewage and building code enforcement. In 1958, a study recommended that the city of Jacksonville begin annexing outlying communities in order to create the needed tax base to improve services throughout the county. Voters outside the city limits rejected annexation plans in six referendums between 1960 and 1965.
In the mid-1960s, corruption scandals began to arise among many of the city's officials, who were mainly elected through the traditional old boy network. After a grand jury was convened to investigate, 11 officials were indicted and more were forced to resign. Jacksonville Consolidation, led by J. J. Daniel and Claude Yates, began to win more support during this period, from both inner city blacks, who wanted more involvement in government, and whites in the suburbs, who wanted more services and more control over the central city. In 1964 all 15 of Duval County's public high schools lost their accreditation. This added momentum to proposals for government reform. Lower taxes, increased economic development, unification of the community, better public spending and effective administration by a more central authority were all cited as reasons for a new consolidated government.
When a consolidation referendum was held in 1967, voters approved the plan. On October 1, 1968, the governments merged to create the Consolidated City of Jacksonville. Fire, police, health & welfare, recreation, public works, and housing & urban development were all combined under the new government. In honor of the occasion, then-Mayor Hans Tanzler posed with actress Lee Meredith behind a sign marking the new border of the "Bold New City of the South" at Florida 13 and Julington Creek.
The Better Jacksonville Plan, promoted as a "blueprint for Jacksonville's future" and approved by Jacksonville voters in 2000, authorized a half-penny sales tax. This would generate most of the revenue required for the $2.25 billion package of major projects that included road & infrastructure improvements, environmental preservation, targeted economic development and new or improved public facilities.
Geography.
Jacksonville is located at (30.3194, −81.6600).
Cityscape.
Jacksonville skyline
Jacksonville skyline at dusk
Topography.
According to the United States Census Bureau, the city has a total area of 874.3 sqmi, making Jacksonville the largest city in land area in the contiguous United States; of this, 86.66% (757.7 sqmi) is land and ; 13.34% (116.7 sqmi) is water. Jacksonville completely encircles the town of Baldwin. Nassau County lies to the north, Baker County lies to the west, and Clay and St. Johns County lie to the south; the Atlantic Ocean lies to the east, along with the Jacksonville Beaches. The St. Johns River divides the city. The Trout River, a major tributary of the St. Johns River, is located entirely within Jacksonville.
The state of Florida, including Jacksonville, is a huge flat plateau with a high water table, and surface lakes are very shallow.
The United States Geological Survey states that the highest point in Jacksonville is only 40 feet (12.2 meters) above sea level, making the area susceptible to flooding and storm surge.
Soil composition is primarily sand and clay rather than limestone, so very few sinkholes develop; however deep, large diameter sinkholes do occur.
Neighborhoods.
There are more than 500 neighborhoods within Jacksonville's vast area. These include Downtown Jacksonville and its surrounding neighborhoods, including LaVilla, Brooklyn, Riverside and Avondale, Springfield, Eastside, and San Marco. Additionally, greater Jacksonville is traditionally divided into several amorphous areas, comprising large parts of Duval County. These are Northside, Westside, Southside, and Arlington, as well as the Jacksonville Beaches.
There are four municipalities that have retained their own governments since consolidation; these are Baldwin and the three Jacksonville Beaches towns of Atlantic Beach, Neptune Beach, and Jacksonville Beach. Four of Jacksonville's neighborhoods, Avondale, Ortega, Springfield, and Riverside, have been identified as U.S. historic districts and are in the National Register of Historic Places.
Landmarks.
The tallest building in Downtown Jacksonville's skyline is the Bank of America Tower, constructed in 1990 as the Barnett Center. It has a height of 617 ft and includes 42 floors. Other notable structures include the 37-story Wells Fargo Center (with its distinctive flared base making it the defining building in the Jacksonville skyline), originally built in 1972-74 by the Independent Life and Accident Insurance Company, and the 28 floor Riverplace Tower which, when completed in 1967, was the tallest precast, post-tensioned concrete structure in the world.
Jacksonville is interesting from an architectural view with fourteen buildings on the document, "Florida Architecture: 100 places, 100 years", compiled by the Florida chapter of the American Institute of Architects.
Climate.
Like much of the south Atlantic region of the United States, Jacksonville has a humid subtropical climate (Köppen "Cfa"), with mild weather during winters and hot and humid weather during summers. Seasonal rainfall is concentrated in the warmest months from May through September, while the driest months are from November through April. Due to Jacksonville's low latitude and coastal location, the city sees very little cold weather, and winters are typically mild and sunny. Summers can be hot and wet, and summer thunderstorms with torrential but brief downpours are common.
Mean monthly temperatures range from around 53 F in January to 82 F in July. High temperatures average 64 to throughout the year. High heat indices are not uncommon for the summer months in the area, with indices above 110 °F possible. The highest temperature recorded was 104 °F on July 11, 1879 and July 28, 1872. It is common for thunderstorms to erupt during a typical summer afternoon. These are caused by the rapid heating of the land relative to the water, combined with extremely high humidity.
During winter, there can be hard freezes during the night. Such cold weather is usually short lived, as the city averages only 10 to 15 nights at or below freezing and around 5 days where the high does not rise above 50 °F. The coldest temperature recorded at Jacksonville International Airport was 7 °F on January 21, 1985. Jacksonville has recorded three days with measurable snow since 1911, most recently a one-inch snowfall in December 1989.
Jacksonville has suffered less damage from hurricanes than most other east coast cities, although the threat does exist for a direct hit by a major hurricane. The city has only received one direct hit from a hurricane since 1871; however, Jacksonville has experienced hurricane or near-hurricane conditions more than a dozen times due to storms crossing the state from the Gulf of Mexico to the Atlantic Ocean, or passing to the north or south in the Atlantic and brushing past the area. The strongest effect on Jacksonville was from Hurricane Dora in 1964, the only recorded storm to hit the First Coast with sustained hurricane force winds. The eye crossed St. Augustine with winds that had just barely diminished to 110 mi/h, making it a strong Category 2 on the Saffir-Simpson Scale. Jacksonville also suffered damage from 2008's Tropical Storm Fay which crisscrossed the state, bringing parts of Jacksonville under darkness for four days. Similarly, four years prior to this, Jacksonville was inundated by Hurricane Frances and Hurricane Jeanne, which made landfall south of the area. These tropical cyclones were the costliest indirect hits to Jacksonville. Hurricane Floyd in 1999 caused damage mainly to Jacksonville Beach. During Floyd, the Jacksonville Beach pier was severely damaged, and later demolished. The rebuilt pier was later damaged by Fay, but not destroyed. Tropical Storm Bonnie would cause minor damage in 2004, spawning a minor tornado in the process. On May 28, 2012, Jacksonville was hit by Tropical Storm Beryl, packing winds up to 70 mph which made landfall near Jacksonville Beach.
Rainfall averages around 52 in a year, with the wettest months being June through September.
Demographics.
Jacksonville is the most populous city in Florida, and the twelfth most populous city in the United States. As of 2010, there were 821,784 people and 366,273 households in the city. The largest ancestries include: German (9.6%), American (9.3%), Irish (9.0%), English (8.5%), and Italian (3.5%). Jacksonville has the country's tenth-largest Arab population, with a total population of 5,751 according to the 2000 United States Census. Jacksonville has Florida's largest Filipino American community, with 25,033 in the metropolitan area as of the 2010 Census. Much of Jacksonville's Filipino community served in or has ties to the United States Navy. Jacksonville also has a large and growing Puerto Rican population.
As of 2010, there were 366,273 households out of which 11.8% were vacant. As of 2000, 33.9% of households had children under the age of 18 living with them, 46.7% were married couples living together, 16.0% had a female householder with no husband present, and 33.0% were non-families. 26.2% of all households were made up of individuals and 7.7% had someone living alone who was 65 years of age or older. The average household size was 2.53 and the average family size was 3.07. In the city, the population was spread out with 26.7% under the age of 18, 9.7% from 18 to 24, 32.3% from 25 to 44, 21.0% from 45 to 64, and 10.3% who were 65 years of age or older. The median age was 34 years. For every 100 females there were 93.9 males. For every 100 females age 18 and over, there were 90.6 males.
In 2000, the median income for a household in the city was $40,316, and the median income for a family was $47,243. Males had a median income of $32,547 versus $25,886 for females. The per capita income for the city was $20,337. About 9.4% of families and 12.2% of the population were below the poverty line, including 16.7% of those under age 18 and 12.0% of those age 65 or over.
As of the 2006–2008 American Community Survey, 88.1% of Jacksonville's population age five and over spoke only English at home while 5.2% of the population spoke Spanish at home. About 3.2% spoke other Indo-European languages at home. About 2.5% spoke an Asian language at home. The remaining 0.9% of the population spoke other languages at home.
As of 2000, speakers of English as a first language accounted for 90.60% of all residents, while those who spoke Spanish made up 4.13%, Tagalog 1.00%, French 0.47%, Arabic 0.44%, German 0.43%, Vietnamese at 0.31%, Russian was 0.21% and Italian made up 0.17% of the population.

</doc>
<doc id="60621" url="http://en.wikipedia.org/wiki?curid=60621" title="Dobro">
Dobro

The word Dobro is, in popular usage, the generic term for a wood-bodied, single cone resonator guitar. It is also an American brand of resonator guitar, currently owned by the Gibson Guitar Corporation. The Dobro was originally made by the Dopyera brothers when they formed the Dobro Manufacturing Company. Their design, with a single inverted resonator, was introduced in competition to the patented Tricone and biscuit designs produced by the National String Instrument Corporation. The Dobro name appeared on other instruments, notably electric lap steel guitars and solid body electric guitars and on other resonator instruments such as Safari resonator mandolins.
Gibson Guitar Corporation acquired the Dobro trademark in 1994. Although the name Dobro is generically associated with the single-inverted-cone design, Gibson has announced that it would defend its right to exclusively use the name.
History.
The name originated in 1928 when the Dopyera brothers, John and Emil (Ed), formed the Dobro Manufacturing Company. "Dobro" is both a contraction of "Dopyera brothers" and a word meaning "goodness" or goodwill in their native Slovak (and also in most Slavic languages). An early company motto was "Dobro means good in any language."
The Dobro was the third resonator guitar design by John Dopyera, the inventor of the resonator guitar, but the second to enter production. Unlike his earlier tricone design, the Dobro had a single resonator cone and it was inverted, with its concave surface facing up. The Dobro company described this as a bowl shaped resonator.
The Dobro was louder than the tricone and cheaper to produce. In Dopyera's opinion, the cost of manufacture had priced the resonator guitar beyond the reach of many players. His failure to convince his fellow directors at the National String Instrument Corporation to produce a single-cone version was part of his motivation for leaving.
Since National had applied for a patent on the single cone (U.S. Patent ), Dopyera had to develop an alternative design. He did this by inverting the cone so that, rather than having the strings rest on the apex of the cone as the National method did, they rested on a cast aluminum spider that had eight legs sitting on the perimeter of the downward-pointing cone (U.S. Patent ).
In the following years both Dobro and National built a wide variety of metal- and wood-bodied single-cone guitars, while National also continued with the Tricone for a time. Both companies sourced many components from National director Adolph Rickenbacher, and John Dopyera remained a major shareholder in National. By 1934, the Dopyera brothers had gained control of both National and Dobro, and they merged the companies to form the National-Dobro Corporation.
From the outset, wooden bodies had been sourced from existing guitar manufacturers, particularly the plywood student guitar bodies made by the Regal Musical Instrument Company. Dobro had granted Regal a license to manufacture resonator instruments. By 1937, it was the only manufacturer, and the license was officially made exclusive. Regal continued to manufacture and sell resonator instruments under many names, including Regal, Dobro, Old Kraftsman, and Ward. However, they ceased all resonator guitar production following the United States entry into World War II in 1941.
Emil Dopyera (also known as Ed Dopera) manufactured Dobros from 1959 under the brand name Dopera's Original before selling the company and name to Semie Moseley. Moseley merged it with his Mosrite guitar company and manufactured Dobros for a time. Meanwhile, in 1967, Rudy and Emil Dopyera formed the Original Musical Instrument Company (OMI) to manufacture resonator guitars, which they at first branded Hound Dog. However, in 1970, they again acquired the Dobro name—Mosrite having gone into temporary liquidation.
The Gibson Guitar Corporation acquired OMI in 1993, along with the Dobro name. They renamed the company Original Acoustic Instruments and moved production to Nashville. Gibson now uses the name Dobro only for models with the inverted-cone design that the original Dobro Manufacturing Company used. Gibson also carries biscuit-style single-resonator guitars, but it sells them under names such as "Hound Dog" (through its subsidiary Epiphone). The Dobro was first introduced to country music by Roy Acuff.
Generic usage.
The name Dobro is generically associated with the single-inverted-cone resonator design, as opposed to the tricone and biscuit designs, which are both similarly associated with the National brand.
Gibson now restricts the use of the name Dobro to its own product line. The name is still used generically for any resonator guitar, particularly before 1993 or from outside the US. "Dobro" and "dobroist" may not necessarily refer to a Gibson Dobro in such songs as "The Ballad of Curtis Loew" by Lynyrd Skynyrd, "Valium Waltz" by the Old 97's, "When Papa Played the Dobro" by Johnny Cash on the "Ride This Train" album, or "Gold Dust Woman" by Fleetwood Mac from the album "Rumours".
Modern instruments.
s of 2006[ [update]], many makers, including Gibson, were manufacturing resonator guitars similar to the original inverted-cone design. Gibson also manufactures biscuit-style resonator guitars, but reserves the Dobro name for its inverted-cone models. These "biscuit" guitars are often used for blues and are played vertically instead of horizontally like a "spider" bridge.
In addition to modern versions of tricones and single cone resonators, National Resophonic also produce Dobro-style guitars. This company made the Model D during the latter part of the 2000s. Production of the Model D guitar has now ceased, but a few dealers in the UK and USA have stock available. National Resophonic are now producing their Smith & Young "Spider Cone" models and the Model 11 is built on traditional Dobro lines. Also, Goldtone, Paul Beard and a number of custom builders are producing good guitars.
As well as recreating the traditional sounds and look, resonator guitars have also become the foundation for even further developments in the world of guitars. Many Dobro-style guitars are now hybrid electric guitars, and some manufacturers add strings to create seven and eight-string resonator-style guitars.

</doc>
<doc id="60622" url="http://en.wikipedia.org/wiki?curid=60622" title="Sextus Varius Marcellus">
Sextus Varius Marcellus

Sextus Varius Marcellus (c.165 – c.215) was a Roman aristocrat and politician from the province of Syria.
Family and career.
Little is known on the origins of Marcellus, as he was born and raised in the ancient Greek city of Apamea in Syria. Marcellus was a Roman citizen from the Equestrian order.
Marcellus had a long, distinguished political career in which he had various responsible tasks to do. He was present at the Secular Games in Rome in 204. From 200 to 205, like Gaius Julius Avitus Alexianus, Marcellus didn’t serve in a Roman military nor political position, probably due to Roman emperor Lucius Septimius Severus’ hostilities from the Praetorian prefect Gaius Fulvius Plautianus. When Plautianus was killed in 205, the career of Marcellus had changed.
From 205 at least until 207, Marcellus was promoted in becoming a Procurator for the Roman aqueducts in Rome, as this position was usually given to a Roman of Senatorial rank, not from the Equestrian class. As a beginner into a Roman political career, Marcellus was paid about 100,000 sesterces per year.
Marcellus proved his worth and capabilities in his position to Lucius Septimius Severus and his family. The emperor in 208 promoted him as Procurator of Roman Britain and in this position, he was responsible in gathering taxes for Rome. He was earning 200,000 sesterces in this role. He was promoted again, by the emperor in generally managing the finances of Roman Britain; was now in charge of the private finances of the emperor and earning 300,000 sesterces.
In 211 after the death of Lucius Septimius Severus, his sons Caracalla and Publius Septimius Geta succeeded their father on the Roman throne. Caracalla recalled Marcellus from Roman Britain to Rome and promoted him to the roles of Praefectus urbi and Praetorian prefect in which he briefly took over the positions. He was later admitted into the Roman Senate with the rank of a former Praetor and almost immediately, Marcellus became Prefect of the military treasury. He was later became a Roman governor of Numidia, either dying in Numidia or immediately after his return to Rome. Although he missed out, Marcellus was in reached in serving a Roman consulship. Marcellus in his political career served in some very significant positions, but unfortunately died before his merits were rewarded.
Marriage and children.
Marcellus married the Syrian Roman noblewoman Julia Soaemias Bassiana being the first daughter of the powerful Syrian nobles Julia Maesa and Gaius Julius Avitus Alexianus. The maternal aunt of Soaemias was the Roman empress Julia Domna; her maternal uncle-in-marriage was the Roman emperor Lucius Septimius Severus; her maternal cousins were the Roman emperors Caracalla and Publius Septimius Geta and was the maternal aunt of the Roman emperor Alexander Severus. Through marriage, Marcellus was a relation to the Severan dynasty of the Roman Empire and the Royal family of Emesa, Syria.
Their marriage may have taken place in 192 or 194 even perhaps around 200. Marcellus and Soaemias’ marriage may have occurred to strengthened Lucius Septimius Severus’ position in the Roman East and owed his political career to his wife.
Soaemias and Marcellus bore the following children who were born and raised in Rome:
Archaeological evidence.
Inscriptional evidence has survived on Marcellus. After his death in c. 215 his wife Julia Soaemias Bassiana and their two sons, dedicated to him a tombstone which was found in Velletri, not far from Rome. The tombstone has two preserved bilingual inscriptions in Latin and Greek, which was first published at Rome in 1765. The inscriptions reveals his political career, his various titles, designations and distinctions he received. The tombstone of Marcellus is known to scholars as CIL 10.6569 which can be found in the Octagonal Court in the Vatican Museums and reads:
Marcellus was known in dedicating an inscription to Bel in Vasio (Vaison) in Gaul. The bilingual inscription which is in Greek and Latin on an altar, dedicated by him is honoring Bel in remembrance of the oracles given to him in Apamea.
Posthumous honor.
The Thermal Bath "Thermae Varianae" also known as the "Baths of Varius" located in Rome was named in honor of Marcellus and his second son. Their namesake baths were bestowed upon the place, by the Legio XIII Gemina.

</doc>
<doc id="60623" url="http://en.wikipedia.org/wiki?curid=60623" title="Marcus Aurelius Antoninus">
Marcus Aurelius Antoninus

Marcus Aurelius Antoninus :

</doc>
<doc id="60626" url="http://en.wikipedia.org/wiki?curid=60626" title="Lester Flatt">
Lester Flatt

Lester Raymond Flatt (June 19, 1914 – May 11, 1979) was a bluegrass guitarist and mandolinist, best known for his collaboration with banjo picker Earl Scruggs in the The Foggy Mountain Boys (popularly known as "Flatt and Scruggs").
Flatt's career spanned multiple decades, breaking out as a member of Bill Monroe's band during the 1940s and including multiple solo and collaboration works exclusive of Scruggs. He first reached a mainstream audience through his performance on "The Ballad of Jed Clampett", the theme for the network television hit "The Beverly Hillbillies", in the early 1960s.
Biography.
Flatt was born in Duncan's Chapel, Overton County, Tennessee, to Nannie Mae Haney and Isaac Columbus Flatt. A singer and guitarist, he first came to prominence as a member of Bill Monroe's Blue Grass Boys in 1945. In 1948 he started a band with fellow Monroe alumnus Earl Scruggs, and for the next twenty years Flatt and Scruggs and the Foggy Mountain Boys were one of the most successful bands in bluegrass. When they parted ways in 1969, Flatt formed a new group, the Nashville Grass, hiring most of the Foggy Mountain Boys. His role as lead singer and rhythm guitar player in each of these seminal ensembles helped define the sound of traditional bluegrass music. He created a role in the Bluegrass Boys later filled by the likes of Jimmy Martin, Mac Wiseman, Peter Rowan and Del McCoury. His rich lead voice is unmistakable in hundreds of bluegrass standards. 
He is also remembered for his library of compositions. The Flatt songbook looms titanic for any student of American acoustic music. He continued to record and perform with that group until his death in 1979 of heart failure, after a prolonged period of ill health. Flatt was posthumously inducted into the Country Music Hall of Fame in 1985 with Scruggs. He was posthumously made an inaugural inductee into the International Bluegrass Music Hall of Honor in 1991. His hometown of Sparta, Tennessee, held a bluegrass festival in his honor for a number of years, before being discontinued a few years prior to the death of the traditional host, resident Everette Paul England; Lester Flatt Memorial Bluegrass Day is part of the annual Liberty Square Celebration held in Sparta.
Flatt and Scruggs were ranked No. 24 on "CMT's 40 Greatest Men of Country Music" in 2003. They performed "The Ballad of Jed Clampett", which was used as the theme for the television show "The Beverly Hillbillies".

</doc>
<doc id="60627" url="http://en.wikipedia.org/wiki?curid=60627" title="Earl Scruggs">
Earl Scruggs

Earl Eugene Scruggs (January 6, 1924 – March 28, 2012) was an American musician noted for perfecting and popularizing a three-finger banjo-picking style (now called "Scruggs style") that is a defining characteristic of bluegrass music.
Although other musicians had played in three-finger style before him, Scruggs shot to prominence when he was hired by Bill Monroe to fill the banjo slot in his group, The Blue Grass Boys. He later reached a mainstream audience through his performance of "The Ballad of Jed Clampett", the theme for the network television hit "The Beverly Hillbillies", in the early 1960s.
Early life.
Scruggs was born and grew up in the Flint Hill community in Cleveland County, North Carolina, to Georgia Lula Ruppe and George Elam Scruggs, a farmer and bookkeeper, who played banjo and died when Scruggs was four years old. His older brothers, Junie and Horace, plus his two older sisters, Eula Mae and Ruby, all played banjo and guitar. Scruggs' mother played the organ.
Career.
Scruggs joined Bill Monroe's Blue Grass Boys in late 1945, and quickly popularized his syncopated, three-finger picking style. In 1948 Scruggs and guitarist Lester Flatt left Monroe's band and formed the Foggy Mountain Boys, also later known simply as Flatt and Scruggs. Flatt and Scruggs became members of the Grand Ole Opry in the 1950s. In 1969, they broke up, and he started a new band, the Earl Scruggs Revue, featuring two of his three sons.
On September 24, 1962, singer Jerry Scoggins, Lester Flatt, and Scruggs recorded "The Ballad of Jed Clampett" for the TV show "The Beverly Hillbillies", which was released October 12, 1962. The theme song became an immediate country music hit and was played at the beginning and end of each episode. Flatt and Scruggs appeared in several episodes as family friends of the Clampetts in the following years. In their first appearance (season 1 episode 20), they portray themselves in the show and perform both the theme song and "Pearl, Pearl, Pearl".
On November 15, 1969, Scruggs played his Grammy-winning "Foggy Mountain Breakdown" on an open-air stage in Washington, D.C., at the Moratorium to End the War in Vietnam, becoming one of the very few bluegrass or country-western artists to give support to the anti-war movement. In an interview after his performance, Scruggs said:
I think the people in the South is just as concerned as the people that's walkin' the streets here today ... I'm sincere about bringing our boys back home. I'm disgusted and in sorrow about the boys we've lost over there. And if I could see a good reason to continue, I wouldn't be here today.
In January 1973, a tribute concert was held for Scruggs in Manhattan, Kansas. Among the artists playing were Joan Baez, David Bromberg, The Byrds, Ramblin' Jack Elliott, The Nitty Gritty Dirt Band, and Doc and Merle Watson. The concert was filmed and turned into the 1975 documentary film "Banjoman".
Awards and honors.
Flatt and Scruggs won a Grammy Award in 1969 for Scruggs' instrumental "Foggy Mountain Breakdown". They were inducted together into the Country Music Hall of Fame in 1985. In 1989, Scruggs was awarded a National Heritage Fellowship. He was an inaugural inductee into the International Bluegrass Music Hall of Honor in 1991. In 1992, he was awarded the National Medal of Arts. In 1994, Scruggs teamed up with Randy Scruggs and Doc Watson to contribute the song "Keep on the Sunny Side" to the AIDS benefit album "Red Hot + Country" produced by the Red Hot Organization.
In 2002 Scruggs won a second Grammy award for the 2001 recording of "Foggy Mountain Breakdown", which featured artists such as Steve Martin on 2nd banjo solo (Martin played the banjo tune on his 1970s stand-up comic acts), Vince Gill and Albert Lee on electric guitar solos, Paul Shaffer on piano, Leon Russell on organ, and Marty Stuart on mandolin. The album, "Earl Scruggs and Friends", also featured artists such as John Fogerty, Elton John, Sting, Johnny Cash, Don Henley, Travis Tritt, and Billy Bob Thornton. It includes the song 'Passin' Thru', written by Johnny Cash and Randy Scruggs, with the refrain 'It's a mighty world we live in but the truth is we're only passin' thru'.
On February 13, 2003, Scruggs received a star on the Hollywood Walk of Fame. That same year, he and Flatt were ranked No. 24 on "CMT's 40 Greatest Men of Country Music".
Still actively touring at age 80, Scruggs performed at the Toronto, Ontario, Bluesfest in 2004.
On September 13, 2006, Scruggs was honored at Turner Field in Atlanta as part of the pre-game show for an Atlanta Braves home game. Organizers set a world record for the most banjo players (239) playing one tune together (Scruggs' "Foggy Mountain Breakdown"). On February 10, 2008, Scruggs was awarded the Lifetime Achievement Award at the 50th Annual Grammy Awards.
Scruggs was inducted into the North Carolina Music Hall of Fame in 2009.
Personal life.
Scruggs' wife and manager, Louise, died on February 2, 2006, aged 78, at Nashville's Baptist Hospital following a lengthy illness.
He is the father of Randy Scruggs, Gary Scruggs and Steve Scruggs.
Death and funeral.
Scruggs died from natural causes on the morning of March 28, 2012, in a Nashville hospital.
His funeral was held on Sunday, April 1, 2012, at the Ryman Auditorium, former home of the Grand Ole Opry in Nashville, Tennessee, at 2pm, and was open to the public. He was buried at Spring Hill Cemetery in a private service.
Legacy.
At an 80th birthday party for Scruggs in 2004, country singer Porter Wagoner said, “Earl is to the five-string banjo what Babe Ruth was to baseball. He is the best there ever was”, Wagoner said, “and the best there ever will be.”
The Earl Scruggs Center.
The Earl Scruggs Center--"Music & Stories from the American South" opened January 11, 2014, in the historic court square of Cleveland County, in uptown Shelby, North Carolina. The Scruggs Center showcases the history and cultural traditions of the American South, and the unique musical contributions of Earl Scruggs, the region’s most pre-eminent ambassador of music. Envisioned as a cornerstone for regional, cultural, and economic development, the Center serves as a cultural crossroads for visitors, students, and residents.
DVDs.
Earl Scruggs, Doc Watson and Ricky Skaggs
Flatt and Scruggs

</doc>
<doc id="60628" url="http://en.wikipedia.org/wiki?curid=60628" title="Gniezno">
Gniezno

Gniezno (German: "Gnesen") is a city in central-western Poland, some 50 km east of Poznań, inhabited by about 70,000 people. One of the Piast dynasty's chief cities, it was mentioned by AD 10th century sources, including the Dagome Iudex, as the capital of Piast Poland. The Roman Catholic archbishop of Gniezno is the primate of Poland. These circumstances give it in relation to Polish history a similar status to Esztergom, Canterbury or Rheims.
Gniezno is located in the Greater Poland Voivodeship (since 1999), previously in Poznań Voivodeship. The city is the administrative capital of the Gniezno County ("powiat").
History.
There are archaeological traces of human settlement since the late Paleolithic. Early Slavonic settlements on the Lech Hill and the Maiden Hill are dated to 8th century. At the beginning of the 10th century this was the site of several places sacred to the Slavic religion. The ducal stronghold was founded just before AD 940 on the Lech Hill, and surrounded with some fortified suburbs and open settlements.
Legend of Lech, Czech and Rus.
According to the Polish version of legends, "Three brothers Lech, Czech and Rus were exploring the wilderness to find a place to settle. Suddenly they saw a hill with an old oak and an eagle on top. Lech said, 'This white eagle I will adopt as an emblem of my people, and around this oak I will build my stronghold, and because of the eagle nest ["gniazdo" in Polish] I will call it Gniezdno [modern: Gniezno].' The other brothers went further on to find a place for their people. Czech went to the South" (to found the Czech Lands) "and Rus went to the East" (to create the Rus' (region)).
Cradle of the Polish state.
Around 940 AD Gniezno, being an important pagan cult center, became one of the main fortresses of the early Piast rulers, along with aforementioned fortresses at Giecz, Kruszwica, Poznań, Kalisz, Łęczyca, Ostrów Lednicki, Płock, Włocławek others. Mieszko I might have moved the capital to Gniezno from Poznań after his own and his realm's baptism, but actual move of the capital to Gniezno might have coincided with a growing German menace of the late 10th century and early 11th century depositing the remains of Saint Adalbert in a newly built church, to underline Gniezno's importance as the religious centre and capital of Bolesław I Chrobry's kingdom.
Congress of Gniezno.
It is here that the Congress of Gniezno took place in the year 1000 AD, during which Bolesław I the Brave, Duke of Poland, received Holy Roman Emperor Otto III. The emperor and the Polish duke celebrated the foundation of the Polish ecclesiastical province (archbishopric) in Gniezno, with newly established bishopric in Kołobrzeg for Pomerania; Wrocław for Silesia; Kraków for Lesser Poland and later also already existing since 968 bishopric in Poznań for western Greater Poland.
Royal coronation site.
The 10th century Gniezno cathedral witnessed royal coronations of Bolesław I in 1024 and his son Mieszko II Lambert in 1025. The cities of Gniezno and nearby Poznań were captured, plundered and destroyed in 1038 by the Bohemian duke Bretislav I, which pushed the next Polish rulers to move the Polish capital to Kraków. The archiepiscopal cathedral was reconstructed by the next ruler, Bolesław II the Generous, who was crowned king here in 1076.
In the next centuries Gniezno evolved as a regional seat of the eastern part of Greater Poland, and in 1238 municipal autonomy was granted by the duke Władysław Odonic. Gniezno was again the coronation site in 1295 and 1300.
Regional site of Greater Poland.
The city was destroyed again by the Teutonic Knights' invasion in 1331, and after an administrative reform became a county within the Kalisz Voivodeship (since the 14th century till 1768). Gniezno was hit by heavy fires in 1515, 1613, was destroyed during the Swedish invasion wars of the 17th-18th centuries and by a plague in 1708-1710. All this caused depopulation and economic decline, but the city was soon revived during the 18th century to become the Gniezno Voivodeship in 1768.
Prussia.
Gniezno was annexed by the Kingdom of Prussia in the 1793 Second Partition of Poland and became part of the province of South Prussia. During the Kościuszko Uprising Polish army under general Jan Henryk Dąbrowski liberated the town in September 1794 and defeated a Prussian Army north of Gniezno near Łabiszyn. During the Napoleonic Wars an uprising against Prussian rule happened. French appeared in Gniezno in November 1806, and following general Jan Henryk Dabrowski's order issued to all town and cities and country property owners to provide recruits for the organizing Polish forces, Gniezno initially provided 60 recruits who participated in the battles of 1806-07. Consequently the town was included within the Duchy of Warsaw, but upon defeat of Napoleon in Russian in 1812 was occupied by the Russian army and was returned to Prussia in the 1815 Congress of Vienna. Gniezno was subsequently governed within Kreis Gnesen of the Grand Duchy of Posen and the later Province of Posen. Following the Greater Poland Uprising (1918–1919) and the Treaty of Versailles Gniezno became part of the Second Polish Republic. Its citizen-soldiers joined the Polish army fighting the Bolsheviks during the Polish–Soviet War.
World War II.
Gniezno was occupied by German troops in 11 September 1939 and annexed into Nazi Germany on 26 October 1939 after the invasion of Poland and made part of Reichsgau Wartheland. The town was liberated by the Red Army in 21 January 1945 and restored to Poland.
Archbishops of Gniezno.
Gniezno's Roman Catholic archbishop is traditionally the Primate of Poland ("Prymas Polski"). After the partitions of Poland the see was often combined with others, first with Poznań and then with Warsaw. In 1992 Pope John Paul II reorganized the Polish hierarchy and the city once again had a separate bishop. Cardinal Józef Glemp, who had been archbishop of Gniezno and Warsaw and retained Warsaw, was designated to remain Primate until his retirement, but afterward the Archbishop of Gniezno, at present Józef Kowalczyk, would again be Primate of Poland.
Twin towns — sister cities.
Gniezno is twinned with: 
 Saint-Malo, France

</doc>
<doc id="60630" url="http://en.wikipedia.org/wiki?curid=60630" title="Country Music Hall of Fame and Museum">
Country Music Hall of Fame and Museum

The Country Music Hall of Fame and Museum identifies and preserves the evolving history and traditions of country music and educates its audiences. Functioning as a local history museum and as an international arts organization, the CMF, located at 222 Fifth Avenue South in Nashville, Tennessee, United States, serves visiting and non-visiting tractor including fans, students, scholars, members of the music industry, and the general public.
History and first museum.
In 1961, the CMA announced the creation of the Country Music Hall of Fame. The first three inductees, Jimmie Rodgers, Fred Rose and Hank Williams, were announced at a CMA banquet in November. Bronze plaques, with the facial likeness and a thumbnail biography of each new member, were cast in bas relief. They were unveiled on the Grand Ole Opry by Ernest Tubb. These plaques, and those for subsequent Hall of Fame inductees, were displayed in the Tennessee State Museum in Nashville until 1967.
In 1963, the CMA announced that a Country Music Hall of Fame and Museum was to be built on Music Row in Nashville. In that same year, Tennessee chartered the Country Music Foundation (CMF) as a nonprofit, educational organization to operate the museum.
The original Country Music Hall of Fame and Museum opened on Music Row (Music Square East and Division Street) on April 1, 1967. Operations of the museum came to include educational programs, the CMF Press and CMF Records, the Country Music Foundation Library (1968), and the historic sites RCA Studio B (1977) and Hatch Show Print (1986). The Music Row location of the Country Music Hall of Fame and Museum was closed December 31, 2000. The building was later razed and a private parking lot for employees of music licensing firm BMI now occupies the site. Before they went on to become major stars in the country music recording industry, Kathy Mattea and Trisha Yearwood worked as tour guides at the Music Row museum.
Current museum.
On May 17, 2001, the CMF held the grand opening of its new $37,000,000 facility ten blocks away in downtown Nashville. Inside, the museum presents its collection to illustrate country music's story as told through the turns of two centuries. Included are historic country video clips and recorded music, as well as a regular menu of live performances and public programs, a museum store, and on-site dining.
The new building's exterior is laced with symbolic images of music. The most obvious are the windows that mirror the configuration of piano keys. More conspicuous images include the diamond-shaped radio mast, which is a miniaturized replica of the WSM tower located a few miles south of Nashville. The round discs surrounding the tower symbolize the different size records and CDs used to record country music. When viewed from the air , the building is in the shape of a bass clef. The northwest corner of the building juts out like the tail fin of a 1950s Cadillac. The Country Music Hall of Fame was designed by local architecture firm and museum design firm Ralph Appelbaum Associates.
The Country Music Hall of Fame and Museum is accredited by the American Alliance of Museums, certifying that the museum operates according to the highest standards, manages its collection and provides quality service to the public. Of the 8,000 museums nationwide, only some 750 are accredited.
Releases.
In 2010 Shout! Factory, in partnership with the Country Music Hall of Fame, released two double DVD sets named for the TV special "Country's Greatest Stars Live". "Volume 1" covers the first three hours of the star-studded event (hosted by Glen Campbell, Roy Clark and Dolly Parton), including live performances by Gene Autry, Carlene Carter, Loretta Lynn and others. "Volume 2" features the last four hours (hosted by Eddy Arnold, Tennessee Ernie Ford, Crystal Gayle and Charley Pride), including live performances by Asleep At The Wheel, Freddy Fender, Anne Murray and more.

</doc>
<doc id="60633" url="http://en.wikipedia.org/wiki?curid=60633" title="Dmitri Mendeleev">
Dmitri Mendeleev

Dmitri Ivanovich Mendeleev (; Russian: Дми́трий Ива́нович Менделе́ев; ]; 8 February 1834 – 2 February 1907 ) was a Russian chemist and inventor. He formulated the Periodic Law, created his own version of the periodic table of elements, and used it to correct the properties of some already discovered elements and also to predict the properties of eight elements yet to be discovered.
Early life.
Mendeleev was born in the village of Verkhnie Aremzyani, near Tobolsk in Siberia, to Ivan Pavlovich Mendeleev and Maria Dmitrievna Mendeleeva (née Kornilieva). His grandfather was Pavel Maximovich Sokolov, a priest of the Russian Orthodox Church from the Tver region. Ivan, along with his brothers and sisters, obtained new family names while attending the theological seminary. Mendeleev was raised as an Orthodox Christian, his mother encouraging him to "patiently search divine and scientific truth." His son would later inform that he departed from the Church and embraced a form of deism.
Mendeleev is thought to be the youngest of either 11, 13, 14 or 17 siblings; the exact number differs among sources. His father was a teacher of fine arts, politics and philosophy. Unfortunately for the family's financial well being, his father became blind and lost his teaching position. His mother was forced to work and she restarted her family's abandoned glass factory. At the age of 13, after the passing of his father and the destruction of his mother's factory by fire, Mendeleev attended the Gymnasium in Tobolsk.
In 1849, his mother took Mendeleev across the entire state of Russia from Siberia to Moscow with the aim of getting Mendeleev a higher education. The university in Moscow did not accept him. The mother and son continued to St. Petersburg to the father’s alma mater. The now poor Mendeleev family relocated to Saint Petersburg, where he entered the Main Pedagogical Institute in 1850. After graduation, he contracted tuberculosis, causing him to move to the Crimean Peninsula on the northern coast of the Black Sea in 1855. While there he became a science master of the Simferopol gymnasium №1. In 1857, he returned to Saint Petersburg with fully restored health.
Later life.
Between 1859 and 1861, he worked on the capillarity of liquids and the workings of the spectroscope in Heidelberg. In late August 1861 he wrote his first book on the spectroscope. On 4 April 1862 he became engaged to Feozva Nikitichna Leshcheva, and they married on 27 April 1862 at Nikolaev Engineering Institute's church in Saint Petersburg (where he taught). Mendeleev became a professor at the Saint Petersburg Technological Institute and Saint Petersburg State University in 1864 and 1865, respectively. In 1865 he became Doctor of Science for his dissertation "On the Combinations of Water with Alcohol". He achieved tenure in 1867, and by 1871 had transformed Saint Petersburg into an internationally recognized center for chemistry research. In 1876, he became obsessed with Anna Ivanova Popova and began courting her; in 1881 he proposed to her and threatened suicide if she refused. His divorce from Leshcheva was finalized one month after he had married Popova (on 2 April) in early 1882. Even after the divorce, Mendeleev was technically a bigamist; the Russian Orthodox Church required at least seven years before lawful remarriage. His divorce and the surrounding controversy contributed to his failure to be admitted to the Russian Academy of Sciences (despite his international fame by that time). His daughter from his second marriage, Lyubov, became the wife of the famous Russian poet Alexander Blok. His other children were son Vladimir (a sailor, he took part in the notable Eastern journey of Nicholas II) and daughter Olga, from his first marriage to Feozva, and son Ivan and twins from Anna.
Though Mendeleev was widely honored by scientific organizations all over Europe, including (in 1882) the Davy Medal from the Royal Society of London (which later also awarded him the Copley Medal in 1905), he resigned from Saint Petersburg University on 17 August 1890.
Mendeleev also investigated the composition of petroleum, and helped to found the first oil refinery in Russia. He recognized the importance of petroleum as a feedstock for petrochemicals. He is credited with a remark that burning petroleum as a fuel "would be akin to firing up a kitchen stove with bank notes."
In 1905, Mendeleev was elected a member of the Royal Swedish Academy of Sciences. The following year the Nobel Committee for Chemistry recommended to the Swedish Academy to award the Nobel Prize in Chemistry for 1906 to Mendeleev for his discovery of the periodic system. The Chemistry Section of the Swedish Academy supported this recommendation. The Academy was then supposed to approve the Committee's choice, as it has done in almost every case. Unexpectedly, at the full meeting of the Academy, a dissenting member of the Nobel Committee, Peter Klason, proposed the candidacy of Henri Moissan whom he favored. Svante Arrhenius, although not a member of the Nobel Committee for Chemistry, had a great deal of influence in the Academy and also pressed for the rejection of Mendeleev, arguing that the periodic system was too old to acknowledge its discovery in 1906. According to the contemporaries, Arrhenius was motivated by the grudge he held against Mendeleev for his critique of Arrhenius's dissociation theory. After heated arguments, the majority of the Academy voted for Moissan. The attempts to nominate Mendeleev in 1907 were again frustrated by the absolute opposition of Arrhenius.
In 1907, Mendeleev died at the age of 72 in Saint Petersburg from influenza. The crater Mendeleev on the Moon, as well as element number 101, the radioactive mendelevium, are named after him.
Periodic table.
In 1863 there were 56 known elements with a new element being discovered at a rate of approximately one per year. Other scientists had previously identified periodicity of elements. John Newlands described a Law of Octaves, noting their periodicity according to relative atomic weight in 1864, publishing it in 1865. His proposal identified the potential for new elements such as germanium. The concept was criticized and his innovation was not recognized by the Society of Chemists until 1887. Another person to propose a periodic table was Lothar Meyer, who published a paper in 1864 describing 28 elements classified by their valence, but with no prediction of new elements. 
After becoming a teacher, Mendeleev wrote the definitive textbook of his time: "Principles of Chemistry" (two volumes, 1868–1870). As he attempted to classify the elements according to their chemical properties, he noticed patterns that led him to postulate his periodic table; he claimed to have envisioned the complete arrangement of the elements in a dream:
"I saw in a dream a table where all elements fell into place as required. Awakening, I immediately wrote it down on a piece of paper, only in one place did a correction later seem necessary."—Mendeleev, as quoted by Inostrantzev
Unaware of the earlier work on periodic tables going on in the 1860s, he made the following table: 
By adding additional elements following this pattern, Dmitri developed his extended version of the periodic table. On 6 March 1869, Mendeleev made a formal presentation to the Russian Chemical Society, entitled "The Dependence between the Properties of the Atomic Weights of the Elements", which described elements according to both atomic weight and valence. This presentation stated that
Mendeleev published his periodic table of all known elements and predicted several new elements to complete the table. Only a few months after, Meyer published a virtually identical table. Some consider Meyer and Mendeleev the co-creators of the periodic table. Mendeleev has the distinction of accurately predicting of the qualities of what he called ekasilicon, ekaaluminium and ekaboron (germanium, gallium and scandium, respectively). 
For his predicted eight elements, he used the prefixes of eka, dvi, and tri (Sanskrit one, two, three) in their naming. Mendeleev questioned some of the currently accepted atomic weights (they could be measured only with a relatively low accuracy at that time), pointing out that they did not correspond to those suggested by his Periodic Law. He noted that tellurium has a higher atomic weight than iodine, but he placed them in the right order, incorrectly predicting that the accepted atomic weights at the time were at fault. He was puzzled about where to put the known lanthanides, and predicted the existence of another row to the table which were the actinides which were some of the heaviest in atomic mass. Some people dismissed Mendeleev for predicting that there would be more elements, but he was proven to be correct when Ga (gallium) and Ge (germanium) were found in 1875 and 1886 respectively, fitting perfectly into the two missing spaces.
By giving Sanskrit names to his "missing" elements, Mendeleev showed his appreciation and debt to the Sanskrit grammarians of ancient India, who had created sophisticated theories of language based on their discovery of the two-dimensional patterns in basic sounds. Mendeleev was a friend and colleague of the Sanskritist Böhtlingk, who was preparing the second edition of his book on Pāṇini at about this time, and Mendeleev wished to honor Pāṇini with his nomenclature. Noting that there are striking similarities between the periodic table and the introductory Śiva Sūtras in Pāṇini's grammar, Prof. Kiparsky says:
"The analogies between the two systems are striking. Just as Panini found that the phonological patterning of sounds in the language is a function of their articulatory properties, so Mendeleev found that the chemical properties of elements are a function of their atomic weights. Like Panini, Mendeleev arrived at his discovery through a search for the "grammar" of the elements..."
The original draft made by Mendeleev would be found years later and published under the name "Tentative System of Elements."
Other achievements.
Mendeleev made other important contributions to chemistry. The Russian chemist and science historian Lev Chugaev has characterized him as "a chemist of genius, first-class physicist, a fruitful researcher in the fields of hydrodynamics, meteorology, geology, certain branches of chemical technology (explosives, petroleum, and fuels, for example) and other disciplines adjacent to chemistry and physics, a thorough expert of chemical industry and industry in general, and an original thinker in the field of economy." Mendeleev was one of the founders, in 1869, of the Russian Chemical Society. He worked on the theory and practice of protectionist trade and on agriculture.
In an attempt at a chemical conception of the Aether, he put forward a hypothesis that there existed two inert chemical elements of lesser atomic weight than hydrogen. Of these two proposed elements, he thought the lighter to be an all-penetrating, all-pervasive gas, and the slightly heavier one to be a proposed element, "coronium".
Mendeleev devoted much study and made important contributions to the determination of the nature of such indefinite compounds as solutions.
In another department of physical chemistry, he investigated the expansion of liquids with heat, and devised a formula similar to Gay-Lussac's law of the uniformity of the expansion of gases, while in 1861 he anticipated Thomas Andrews' conception of the critical temperature of gases by defining the absolute boiling-point of a substance as the temperature at which cohesion and heat of vaporization become equal to zero and the liquid changes to vapor, irrespective of the pressure and volume.
Mendeleev is given credit for the introduction of the metric system to the Russian Empire.
He invented "pyrocollodion", a kind of smokeless powder based on nitrocellulose. This work had been commissioned by the Russian Navy, which however did not adopt its use. In 1892 Mendeleev organized its manufacture.
Mendeleev studied petroleum origin and concluded hydrocarbons are abiogenic and form deep within the earth – see Abiogenic petroleum origin.
He wrote: "The capital fact to note is that petroleum was born in the depths of the earth, and it is only there that we must seek its origin." (Dmitri Mendeleev, 1877)
The vodka myth.
A very popular Russian story is that it was Mendeleev who came up with the 40% standard strength of vodka in 1894, after having been appointed Director of the Bureau of Weights and Measures with the assignment to formulate new state standards for the production of vodka. This story has, for instance, been used in marketing claims by the Russian Standard vodka brand that, "In 1894, Dmitri Mendeleev, the greatest scientist in all Russia, received the decree to set the Imperial quality standard for Russian vodka and the 'Russian Standard' was born", or that the vodka is "compliant with the highest quality of Russian vodka approved by the royal government commission headed by Mendeleev in 1894."
While it's true that Mendeleev in 1892 became head of the Archive of Weights and Measures in St Petersburg, and evolved it into a government bureau the following year, that institution was never involved in setting any production quality standards, but was issued with standardising Russian trade weights and measuring instruments. Furthermore, the 40% standard strength was introduced by the Russian government already in 1843, when Mendeleev was nine years old.
The basis for the whole story is a popular myth that Mendeleev's 1865 doctoral dissertation "A Discourse on the combination of alcohol and water" contained a statement that 38% is the ideal strength of vodka, and that this number was later rounded to 40% to simplify the calculation of alcohol tax. However, Mendeleev's dissertation was about alcohol concentrations over 70% and he never wrote anything about vodka.
Commemoration.
A number of places and objects are associated with the name and achievements of the scientist.
In Saint Petersburg his name was given to the National Metrology Institute dealing with establishing and supporting national and worldwide standards for precise measurements. Next to it there is a monument to him pictured above that consists of his sitting statue and a depiction of his periodic table on the wall of the establishment.
In the Twelve Collegia building, now being the centre of Saint Petersburg State University and in Mendeleev's time – Head Pedagogical Institute – there is Dmitry Mendeleev's Memorial Museum Apartment with his archives. The street in front of these is named after him as Mendeleevskaya liniya (Mendeleev Line).
In Moscow, there is the D. Mendeleyev University of Chemical Technology of Russia.
After him was also named mendelevium, which is a synthetic chemical element with the symbol Md (formerly Mv) and the atomic number 101. It is a metallic radioactive transuranic element in the actinide series, usually synthesized by bombarding einsteinium with alpha particles.
A large lunar impact crater Mendeleev that is located on the far side of the Moon, as seen from the Earth, also bears the name of the scientist.
Russian Academy of Sciences yearly awards since 1998 Mendeleev Golden Medal. 

</doc>
