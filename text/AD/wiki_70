<doc id="55012" url="http://en.wikipedia.org/wiki?curid=55012" title="Abenaki">
Abenaki

The Abenaki (Abnaki, Wabanaki, Waponahki) are a Native American tribe and a First Nations band government. They are one of the Algonquian-speaking peoples of northeastern North America. The Abenaki live in Quebec and the Maritimes of Canada and in the New England region of the United States, a region called "Wabanaki" ("Dawn Land") in the Eastern Algonquian languages. The Abenaki are one of the five members of the Wabanaki Confederacy. "Abenaki" is a linguistic and geographic grouping; historically there was not a strong central authority, but as listed below a large number of smaller bands and tribes who shared many cultural traits.
Name.
The word "Abenaki" means “people of the dawnlands". The Abenaki people call themselves Alnôbak, meaning "Real People" (c.f., Lenape language: "Lenapek"). They also use the autonym Alnanbal, meaning "men". In addition, when compared to the more interior Algonquian peoples, they call themselves Wôbanuok, meaning "Easterners" (c.f. Massachusett language: Wôpanâak). They also refer to themselves as Abenaki or with syncope: Abnaki. Both forms are derived from Wabanaki or the Wabanaki Confederacy, as they were once a member of this confederacy they called Wôbanakiak, meaning "People of the Dawn Land" in the Abenaki language—from "wôban" ("dawn" or "east") and "aki" ("land") (compare Proto-Algonquian "*wa·pan" and "*axkyi")—the aboriginal name of the area broadly corresponding to New England and the Maritimes. It is sometimes used to refer to all the Algonquian-speaking peoples of the area—Western Abenaki, Eastern Abenaki, Wolastoqiyik-Passamaquoddy, and Mi'kmaq—as a single group.
Subdivisions.
Historically, ethnologists have classified the Abenaki as groups: Western Abenaki and Eastern Abenaki. Within these groups are the Abenaki bands:
Due to erroneous use of the word "Abenaki" to mean "Wabanaki," all the Abenaki together with the Penobscot people are often described as "Western 'Wabenaki'" peoples, while the Mi'kmaq, Maliseet and Passamaquoddy are described as "Eastern 'Wabenaki'" peoples.
Location.
The homeland of the Abenaki, which they call "Ndakinna" (our land), extended across most of northern New England, southern Quebec, and the southern Canadian Maritimes. The Eastern Abenaki population was concentrated in portions of Maine east of New Hampshire's White Mountains. The other major tribe, the Western Abenaki, lived in the Connecticut River valley in Vermont, New Hampshire and Massachusetts. The Missiquoi lived along the eastern shore of Lake Champlain. The Pennacook lived along the Merrimack River in southern New Hampshire. The maritime Abenaki lived around the St. Croix and Wolastoq (Saint John River) valleys near the boundary line between Maine and New Brunswick.
The English settlement of New England and frequent wars forced many Abenaki to retreat to Quebec. The Abenaki settled in the Sillery region of Quebec between 1676 and 1680, and subsequently, for about twenty years, lived on the banks of the Chaudière River near the falls, before settling in Odanak and Wôlinak in the early eighteenth century. The name "Abenaki" was derived from the terms "w8bAn" (light) and "Aki" (land), which mean "people in the rising sun" or "people of the East". In those days, the Abenaki practiced a subsistence economy based on hunting, fishing, trapping, berry picking and on growing corn, beans, squash, potatoes and tobacco. They also produced baskets, made of ash and sweet grass, for picking wild berries, and boiled maple sap to make syrup. Basket weaving remains a traditional activity for members of both communities.
During the Anglo-French wars, the Abenaki were allies of France, having been displaced from Ndakinna by immigrating English people. An anecdote from this period tells the story of a warrior named Nescambuit, who killed more than 140 enemies of King Louis XIV of France and received the rank of knight. Not all Abenaki natives fought on the side of the French, however; many remained on their native lands in the northern colonies. Much of the trapping was done by the people, and traded to the English colonists for durable goods. These contributions by native American Abenaki peoples went largely unreported.
Two tribal communities formed in Canada, one once known as Saint-Francois-du-lac near Pierreville, Quebec (now called Odanak, Abenaki for "coming home"), and the other near Bécancour (now known as Wôlinak) on the south shore of the Saint Lawrence River, directly across the river from Trois-Rivières. These two Abenaki reserves continue to grow and develop. Since the year 2000, the total Abenaki population (on and off reserve) has doubled to 2,101 members in 2011. Approximately 400 Abenaki reside on these two reserves, which cover a total area of less than 7 km2. The unrecognized majority are off-reserve members, living in various cities and towns across Canada and the United States.
There are about 3,200 Abenaki living in Vermont and New Hampshire, without reservations, chiefly around Lake Champlain. The remaining Abenaki people live in multi-racial towns and cities across Canada and the U.S.A., mainly in Ontario, Quebec, New Brunswick, and northern New England.
Four Abenaki tribes are located in Vermont. On April 22, 2011, Vermont officially recognized two Abenaki tribes: the Nulhegan Band of the Coosuk-Abenaki and the Elnu Abenaki Tribe. On May 7, 2012, the Abenaki Nation at Missisquoi and the Koasek Traditional Band of the Koas Abenaki Nation received recognition by the State of Vermont. The Nulhegan are located in the Northeast Kingdom of Vermont, with tribal headquarters in Brownington, and the Elnu Abenaki are located in southeastern Vermont with tribal headquarters in Jamaica, Vermont. The Sokoki (the Abenaki Nation at Missisquoi) are located along the Missisquoi River ("Masipskiwibi") in northwestern Vermont, with tribal headquarters in Swanton. Their traditional land is along the river, extending to its outlet at Lake Champlain.
In December, 2012, Vermont's Nulhegan Abanaki Tribe created a tribal forest in the Town of Barton. This forest was established with assistance from the Vermont Sierra Club and the Vermont Land Trust. It contains a hunting camp and maple sugaring facilities which are administered cooperatively by the Nulhegan. The forest contains 70 acres.
The St Francis Missisquoi Tribe owns forest land in the Town of Brunswick, centered around the Brunswick Springs. These springs are believed to be a sacred traditional religious site of the Abanaki. Together these Vermont forests are the only Abanaki held lands outside of the existing reservations in Quebec and Maine.
Language.
The Abenaki language is closely related to the Panawahpskek (Penobscot) language. Other neighboring Wabanaki tribes, the Mi'kmaq, Wolastoqiyik (Maliseet), and Pestomuhkati (Passamaquoddy), and other Eastern Algonquian languages share many linguistic similarities. It has come close to extinction as a spoken language. Tribal members are working to revive the Abenaki language at Odanak (means "in the village"), a First Nations Abenaki reserve near Pierreville, Quebec, and throughout New Hampshire, Vermont and New York state.
History.
In "Reflections in Bullough's Pond", historian Diana Muir argues that Abenaki neighbors, pre-contact Iroquois, were an imperialist, expansionist culture whose cultivation of the corn/beans/squash agricultural complex enabled them to support a large population. They made war primarily against neighboring Algonquian peoples, including the Abenaki. Muir uses archaeological data to argue that the Iroquois expansion onto Algonquian lands was checked by the Algonquian adoption of agriculture. This enabled them to support their own populations large enough to have sufficient warriors to defend against the threat of Iroquois conquest.
In 1614, Thomas Hunt captured 24 young Abenaki people and took them to England. During the European colonization of North America, the land occupied by the Abenaki was in the area between the new colonies of England in Massachusetts and the French in Quebec. Since no party agreed to territorial boundaries, there was regular conflict among them. The Abenaki were traditionally allied with the French; during the reign of Louis XIV, Chief Assacumbuit was designated a member of the French nobility for his service.
Facing annihilation from English attacks and epidemics of new infectious diseases, the Abenaki started to emigrate to Quebec around 1669. The governor of New France allocated two seigneuries (large self-administered areas similar to feudal fiefs). The first was on the Saint Francis River and is now known as the "Odanak" Indian Reservation; the second was founded near Bécancour and is called the "Wolinak" Indian Reservation.
Abenaki wars.
When the Wampanoag people under King Philip (Metacomet) fought the English colonists in New England in 1675 in King Philip's War, the Abenaki joined the Wampanoag. For three years there was fighting along the Maine frontier in the First Abenaki War. The Abenaki pushed back the line of white settlement by devastating raids on scattered farmhouses and small villages. The war was settled by a peace treaty in 1678.
During Queen Anne's War in 1702, the Abenaki were allied with the French; they raided numerous small villages in Maine, Wells to Casco, killing about 300 settlers over ten years. The raids stopped when the war ended. Some captives were adopted into the Mohawk and Abenaki tribes; older captives were generally ransomed, and the colonies carried on a brisk trade.
The Third Abenaki War (1722–25), called Father Rale's War, erupted when the French Jesuit missionary Sébastien Rale (or Rasles, 1657?-1724) encouraged the Abenaki to halt the spread of Yankee settlements. When the Massachusetts militia tried to seize Rasles, the Abenaki raided the settlements at Brunswick, Arrowsick, and Merry-Meeting Bay. The Massachusetts government then declared war and bloody battles were fought at Norridgewock (1724), where Rasles was killed, and at a daylong battle at the Indian village near present-day Fryeburg, Maine, on the upper Saco River (1725). Peace conferences at Boston and Casco Bay brought an end to the war. After Rale died the Abenaki moved to a settlement on the St. Francis River.
The Abenaki from St. Francois continued to raid British settlements in their former homelands along the New England frontier during Father Le Loutre's War (see Northeast Coast Campaign (1750)) and the French and Indian War.
Canada.
The development of tourism projects has allowed the Canadian Abenaki to develop a modern economy, while preserving their culture and traditions. For example, since 1960, the Odanak Historical Society has managed the first and one of the largest aboriginal museums in Quebec, a few miles from the Quebec-Montreal axis. Over 5,000 people visit the Abenaki Museum annually. Several Abenaki companies include: in Wôlinak, General Fiberglass Engineering employs a dozen natives, with annual sales of more than $3 million Canadian dollars. Odanak is now active in transportation and distribution. Notable Abenaki from this area include the documentary filmmaker Alanis Obomsawin (National Film Board of Canada).
United States.
The Penobscot Indian Nation and the Passamaquoddy People have been federally recognized as tribes in the United States.
Vermont.
In 2006, the state of Vermont officially recognized the Abenaki as a People, but not a Tribe. The state noted that many Abenaki had been assimilated, and only small remnants remained on reservations during and after the French and Indian War, later eugenics projects further decimated the Abenaki people of America through forced sterilization and questionable 'miscarriages' at birth. As noted above, facing annihilation, many Abenaki had begun emigrating to Canada, then under French control, around 1669.
The Sokoki-St. Francis Band of the Abenaki Nation organized a tribal council in 1976 at Swanton, Vermont. Vermont granted recognition of the council the same year, but later withdrew it. In 1982, the band applied for federal recognition, which is still pending. Four Abenaki communities are located in Vermont. On April 22, 2011, Vermont officially recognized two Abenaki bands: the Nulhegan Band of the Coosuk-Abenaki and the El Nu Abenaki Tribe. On May 7, 2012, the Abenaki Nation at Missisquoi and the Koasek of the Koas Abenaki Traditional Band received recognition by the State of Vermont.
The Abenaki who chose to remain in the United States did not fare as well as their Canadian counterparts. Tribal connections were lost as those Abenaki who were tolerated by the Anglo population were assimilated into colonial society. What familial groups remained were often eradicated, in the early 20th century, through forced sterilization and pregnancy termination policies in Vermont. There were over 3,400 reported cases of sterilization of Abenaki having been performed, many of which involved termination of an unborn fetus. No documentation of informed consent for these procedures was found. After this period the only Abenaki that remained in the United States were those who could pass for white, or avoid capture and subsequent dissolution of their families through forced interment in "schools" after their sterilization. At the time, many of the children who were sterilized were not even aware of what the physicians had done to them. This was performed under the auspices of the Brandon School of the Feeble-Minded, and the Vermont Reform School. It was documented in the 1911 "Preliminary Report of the Committee of the Eugenic Section of the American Breeder's Association to Study and to Report on the Best Practical Means for Cutting Off the Defective Germ-Plasm in the Human Population."
Official state tribal recognition.
The Vermont Elnu (Jamaica) and Nulhegan (Brownington) bands' application for official recognition was recommended and referred to the Vermont General Assembly by the on January 19, 2011, as a result of a process established by the Vermont legislature in 2010. Recognition allows applicants to seek scholarship funds reserved for American Indians and to receive federal "native made" designation for the bands' arts and crafts.
On April 22, 2011, Vermont officially recognized two Abenaki bands: the Nulhegan Band of the Coosuk-Abenaki and the El Nu Abenaki Tribe. On May 7, 2012, the Abenaki Nation at Missisquoi and the Koasek Traditional Band of the Koas Abenaki Nation received recognition by the State of Vermont.
New Hampshire and minority recognition.
In New Hampshire the Abenaki, along with other Native American groups, have proposed legislation for recognition as a minority group. This bill was debated in 2010 in the state legislature. The bill would create a state commission on Native American relations, which would act as an advisory group to the governor and the state government in general. The Abenaki want to gain formal state recognition as a people.
Some people have opposed the bill, as they fear it may lead to Abenaki land claims for property now owned and occupied by European Americans. Others worry that the Abenaki may use recognition as a step toward opening a casino. But, the bill specifically says that "this act shall not be interpreted to provide any Native American or Abenaki person with any other special rights or privileges that the state does not confer on or grant to other state residents." New Hampshire has considered expanding gambling separate from the Native Americans.
The council would be under the Department of Cultural Resources, so it would be in the same department as the State Council on the Arts. The bill would allow for the creation and sale of goods to be labeled as Native-made, to create a source of income for the Natives in New Hampshire.
The numerous groups of Natives in the state have created a New Hampshire Inter-tribal Council, which holds statewide meetings and powwows. Dedicated to preserving the culture of the Natives in New Hampshire, the group is one of the chief supporters of the HB 1610; the Abenaki, the main tribe in the state, are the only people named specifically in the bill.
Culture.
There are a dozen variations of the name "Abenaki", such as Abenaquiois, Abakivis, Quabenakionek, Wabenakies and others.
The Abenaki were described in the "Jesuit Relations" as not cannibals, and as docile, ingenious, temperate in the use of liquor, and not profane.
All Abenaki tribes lived a lifestyle similar to the Algonquian-speaking peoples of southern New England. They cultivated crops for food, and located their villages on or near fertile river floodplains. Other less major, but still important, parts of their diet included game and fish from hunting and fishing, and wild plants.
They lived in scattered bands of extended families for most of the year. Each man had different hunting territories inherited through his father. Unlike the Iroquois, the Abenaki were patrilineal. Bands came together during the spring and summer at temporary villages near rivers, or somewhere along the seacoast for planting and fishing. These villages occasionally had to be fortified, depending on the alliances and enemies of other tribes or of Europeans near the village. Abenaki villages were quite small when compared to those of the Iroquois; the average number of people was about 100.
Most Abenaki crafted dome-shaped, bark-covered wigwams for housing, though a few preferred oval-shaped long houses. During the winter, the Abenaki lived in small groups further inland. The homes there were bark-covered wigwams shaped in a way similar to the teepees of the Great Plains Indians. During the winter, the Abenaki lined the inside of their conical wigwams with bear and deer skins for warmth. The Abenaki also built long houses similar to those of the Iroquois.
The Abenaki hold on to their traditions and ways of life in several ways. The Sokoki do so in the current constitution for their government. It has a chief, a council of elders, and methods and means for election to the council and chieftainship, as well as requirements for citizenship in the tribe. They also list many of the different traditions they uphold, such as the different dances they perform and what those dances mean. During several of these dances there is no photography allowed, out of respect for the culture. For several, there are instructions such as "All stand while it is sung" or "All Stand to Show Respect."
Hair style and other marriage traditions.
Traditionally, Abenaki men kept their hair long and loose. When a man would find a girlfriend, he would tie his hair. When he married, he would attach the hair of the scalp with a piece of leather and shave all but the ponytail. The modernized spiritual version has the man with a girlfriend tying his hair and braiding it. When he marries, he keeps all his hair in a braid, shaving only the side and back of the head. The spiritual meaning surrounding this cut is most importantly to indicate betrothal or fidelity as a married Abenaki man. In much the same way as the Christian marriage tradition, there is an (optional) exchange and blessing of wedding rings. These rings are the outward and visible sign of the unity of this couple.
Changes in the hair style were symbolic of a complex courtship process. The man would give the woman a box made of a fine wood, which was decorated with the virtues of the woman; the woman would give a similar box to the man. Everyone in the tribe must agree to the marriage. They erect a pole planted in the earth, and if anyone disagrees, he strikes the pole. The disagreement must be resolved or the marriage does not happen.
Gender, food, division of labor, and other cultural traits.
The Abenaki were a farming society that supplemented agriculture with hunting and gathering. Generally the men were the hunters. The women tended the fields and grew the crops. In their fields, they planted the crops in groups of "sisters". The three sisters were grown together: the stalk of corn supported the beans, and squash or pumpkins provided ground cover and reduced weeds. The men would hunt bears, deer, fish, & birds.
The Abenaki were a patrilineal society, which was common among New England tribes. In this they differed from the six Iroquois tribes to the west in New York, and from many other North American Indian tribes who had matrilineal societies. In those systems, women controlled property and hereditary leadership was passed through the women's line. Children born to a married couple belonged to the mother's clan, and her eldest brother was an important mentor, especially for boys. The biological father had a lesser role.
Group decision-making was done by a consensus method. The idea is that every group (family, band, tribe, etc.) must have equal say, so each group would elect a spokesperson. Each smaller group would send the decision of the group to an impartial facilitator. If there was a disagreement, the facilitator would tell the groups to discuss again. In addition to the debates, there was a goal of total understanding for all members. If there was not total understanding, the debate would stop until there was understanding.
When the tribal members debate issues, they consider the Three Truths:
These truths guide all group deliberations, and the goal is to reach a consensus. If there is no consensus for change, they agree to keep the status quo.
Storytelling.
Storytelling is a major part of Abenaki culture. It is used not only as entertainment but also as a teaching method. The Abenaki view stories as having lives of their own and being aware of how they are used. Stories were used as a means of teaching children behavior. Children were not to be mistreated, and so instead of punishing the child, they would be told a story.
One of the stories is of Azban the Raccoon. This is a story about a proud raccoon that challenges a waterfall to a shouting contest. When the waterfall does not respond, Azban dives into the waterfall to try to outshout it; he is swept away because of his pride. This story would be used to show a child the pitfalls of pride.
Population and epidemics.
Before the Abenaki—except the Pennacook and Mi'kmaq—had contact with the European world, their population may have numbered as many as 40,000. Around 20,000 would have been Eastern Abenaki, another 10,000 would have been Western Abenaki, and the last 10,000 would have been Maritime Abenaki. Early contacts with European fishermen resulted in two major epidemics that affected Abenaki during the 16th century. The first epidemic was an unknown sickness occurring sometime between 1564 and 1570, and the second one was typhus in 1586. Multiple epidemics arrived a decade prior to the English settlement of Massachusetts in 1620, when three separate sicknesses swept across New England and the Canadian Maritimes. Maine was hit very hard during the year of 1617, with a fatality rate of 75%, and the population of the Eastern Abenaki fell to about 5,000. The more isolated Western Abenaki suffered fewer fatalities, losing about half of their original population of 10,000.
The new diseases continued to strike in epidemics, starting with smallpox in 1631, 1633, and 1639. Seven years later, an unknown epidemic struck, with influenza passing through the following year. Smallpox affected the Abenaki again in 1649, and diphtheria came through 10 years later. Smallpox struck in 1670, and influenza in 1675. Smallpox affected the Native Americans in 1677, 1679, 1687, along with measles, 1691, 1729, 1733, 1755, and finally in 1758.
The Abenaki population continued to decline, but in 1676, they took in thousands of refugees from many southern New England tribes displaced by settlement and King Philip's War. Because of this, descendants of nearly every southern New England Algonquian tribe can be found among the Abenaki people. A century later, fewer than 1,000 Abenaki remained after the American Revolution.
In the 1990 U.S. Census, 1,549 people identified themselves as Abenaki. So did 2,544 people in the 2000 U.S census, with 6,012 people claiming Abenaki heritage. In 1991 Canadian Abenaki numbered 945; by 2006 they numbered 2,164.
Fiction.
Lydia Maria Child wrote of the Abenaki in her short story, "The Church in the Wilderness" (1828). Several Abenaki characters and much about their 18th-century culture are featured in the Kenneth Roberts novel "Arundel" (1930). The film "Northwest Passage" (1940) is based on a novel of the same name by Roberts.
The Abenaki are featured in Charles McCarry's historical novel "Bride of the Wilderness" (1988), and James Archibald Houston's novel "Ghost Fox" (1977), both of which are set in the eighteenth century; and in Jodi Picoult's "Second Glance" (2003) and "Lone Wolf" (2012) novels, set in the contemporary world. Books for younger readers both have historical settings: Joseph Bruchac's "The Arrow Over the Door" (1998) (grades 4-6) is set in 1777; and Beth Kanell's young adult novel, "The Darkness Under the Water" (2008), concerns a young Abenaki-French Canadian girl during the time of the Vermont Eugenics Project, 1931-1936.
Non-fiction.
Accounts of life with the Abenaki can be found in the captivity narratives written by women taken captive by the Abenaki from the early New England settlements: Mary Rowlandson (1682), Hannah Duston (1702); Elizabeth Hanson (1728); Susannah Willard Johnson (1754); and Jemima Howe (1792).
Maps.
Maps showing the approximate locations of areas occupied by members of the Wabanaki Confederacy (from north to south):
Further reading.
Other grammar books and dictionaries include:

</doc>
<doc id="55013" url="http://en.wikipedia.org/wiki?curid=55013" title="Bauhaus (band)">
Bauhaus (band)

Bauhaus were an English post-punk band, formed in Northampton, England in 1978. The group consisted of Peter Murphy (vocals, occasional instruments), Daniel Ash (guitar), Kevin Haskins (drums) and David J (bass). The band was originally named "Bauhaus 1919"; they dropped the numerical portion within a year of formation. With their dark and gloomy sound and image, Bauhaus are generally considered the first gothic rock group.
Bauhaus broke up in 1983. Peter Murphy began a solo career while Ash and Haskins continued as Tones on Tail and, later, reunited with David J to form Love and Rockets. Both enjoyed greater commercial success in the United States than Bauhaus had, but disappeared from the charts in their homeland. Bauhaus eventually reunited for a 1998 tour and again from 2005–2008.
History.
Daniel Ash, his friend David J. Haskins and Haskins' younger brother Kevin had played together in various bands since childhood. One of the longer-lived of these was a band called The Craze, which performed a few times around Northampton in 1978. However, The Craze still split up fairly quickly, and Ash once again tried to convince his old school friend Peter Murphy to join him, simply because Ash thought he had the right look for a band. Murphy, who was working in a printing factory, decided to give it a try, despite never having written any lyrics or music. During their first rehearsal, he co-wrote the song "In the Flat Field".
Ash's old bandmate Kevin Haskins joined as the drummer. Ash made a point of not inviting David J, the driving force in their previous bands, because he wanted a band he could control. After only a few weeks though, Ash reconsidered and invited David J to replace original bassist Chris Barber. David J. had already agreed to tour American airbases with another band, but decided that joining his friends' group was "the right thing to do". With their line-up complete, the unnamed band played their first gig at the Cromwell pub in Wellingborough on New Year's Eve 1978.
The band chose the name Bauhaus 1919, a reference to the German Bauhaus art movement of the 1920s, because of its "stylistic implications and associations", according to David J. The band also chose to use the same typeface used on the Bauhaus college building in Dessau, Germany. Bauhaus associate Graham Bentley said that the group was unlike any Northampton band of the time, most of which played predominantly cover songs. Bentley videotaped a performance by the group, which was sent to several record labels in the hope of obtaining a contract. This approach was hindered partly because many record companies at the time did not have home video equipment or Bentley had to provide it himself, so the group decided to record a demo.
"Bela Lugosi's Dead" and 4AD.
Together for only six weeks, Bauhaus entered the studio for the first time at Beck Studios in Wellingborough to record a demo. The band recorded five songs; one of the tracks from the session, "Bela Lugosi's Dead", running more than nine minutes, was released as the group's debut single in August 1979 on Small Wonder Records as Bauhaus (the 1919 abandoned). The single received a positive review in "Sounds" and stayed on the British independent charts for two years. The song received crucial airplay on BBC Radio 1 and DJ John Peel's evening show, and Bauhaus was subsequently asked to record a session for Peel's show, which was broadcast on 3 January 1980.
The band released three more singles, "Dark Entries", "Terror Couple Kill Colonel" and "Telegram Sam" – originally written by glam rock pioneers T. Rex – before the debut of their first album, "In the Flat Field", in 1980 on 4AD. "NME" described it as "Gothick-Romantick pseudo-decadence". Despite negative reviews, "In the Flat Field" topped the indie charts and made headway onto the British pop charts, peaking for one week at number 72.
Beggars Banquet and breakup.
Bauhaus' growing success outstripped 4AD's resources, so the band moved to 4AD's parent label Beggars Banquet Records. Bauhaus released "Kick in the Eye" as its debut release on the label. The single reached number 59 on the charts. The following single, "The Passion of Lovers", peaked at number 56. Bauhaus released its second album, "Mask", in October 1981. The band employed more keyboards and a variety of other instruments to add to the diversity of the record. In an unconventional move, the group shot a video for the album's title track as a promotional tool for the band as a whole and not any specific song from the record.
Bauhaus followed with the single "Spirit", produced by Hugh Jones and intended to break into the Top 30. However, "Spirit" only reached number 42. The band was displeased with the single and re-recorded it for their third album "The Sky's Gone Out" in 1982. In the same year, Bauhaus scored their biggest hit with a cover of David Bowie's "Ziggy Stardust", which was recorded during a BBC session. The song reached number 15 on the British charts and earned the band an appearance on the television show "Top of the Pops". Thanks to the success of the single, the album also became the band's biggest hit, peaking at number 4. That same year, Bauhaus made an appearance in the horror film "The Hunger", where they performed "Bela Lugosi's Dead" during the opening credits. The final cut of the scene focused on Murphy; this, coupled with the singer's modelling work in a popular ad campaign for Maxell, caused resentment among the rest of the group.
Prior to the recording of their fourth album, "Burning from the Inside" (1983), Peter Murphy was stricken with pneumonia, which prevented him from contributing much to the album. Daniel Ash and David J took the reins and became the driving forces behind the record, and even performed lead vocals on a few tracks. The album's lead single, "She's in Parties", reached number 26 on the charts and earned Bauhaus their third and final "Top of the Pops" appearance. Bauhaus then embarked on an international promotional tour for the album, with dates in Europe and the Far East. David J recalled that the night before they were supposed to perform two shows at Hammersmith Palais in London the group decided to disband.
The band played their farewell show on 5 July 1983 at the Hammersmith Palais; dedicated fans had been warned by the band's crew not to miss the show without telling them it was the last. After a long encore consisting of some of their early songs, David J left the stage with the words "rest in peace". "Burning from the Inside" was released a week later. The album received largely positive reviews and reached number 13 on the charts. Bauhaus released the single "Sanity Assassin" in limited quantities as a farewell gift for those who joined the group's fanclub.
Post-breakup.
After Bauhaus disbanded, the members of the band did various solo work. Peter Murphy worked briefly with bassist Mick Karn of Japan in the band Dalis Car before going solo with such albums as 1988's "Love Hysteria" and 1989's "Deep". Daniel Ash had already started Tones on Tail with Bauhaus roadie Glen Campling as a side-project in 1981; after Bauhaus broke up, Kevin Haskins joined the group, and the group released an album and several EPs before breaking up following a 1984 American tour. During this time, David J released two solo albums and collaborated with other musicians, recording two albums with The Jazz Butcher, and also with comics writer/spoken-word artist Alan Moore in the short-lived band The Sinister Ducks.
During a discussion about the state of their projects at the time, Ash and David J began talking about reforming Bauhaus. All four band members arranged a rehearsal, but Murphy failed to show up the day it was scheduled. The other three band members rehearsed regardless, and were inspired by the chemistry they had as a trio. As a result, Ash and the Haskins brothers formed Love and Rockets in 1985. Love and Rockets scored a US hit four years later with "So Alive". The band broke up after seven albums in 1999. Both Daniel Ash and David J released solo albums during the Love and Rockets years; Peter Murphy contributed backing vocals to David J's 1992 single "Candy on the Cross".
Reunions.
Bauhaus reunited for the "Resurrection Tour" in 1998, which featured a new song, "The Dog's a Vapour", which was also included in the "Heavy Metal 2000" film soundtrack. A live album was recorded during the tour, "Gotham", which was released the following year and included a studio recording of Dead Can Dance-cover "Severance".
Bauhaus reunited again in 2005, playing that year's Coachella Festival, Indio, CA, USA—opening their set, Peter Murphy was lowered upside-down, to the stage, singing "Bela Lugosi's Dead". Following Peter Murphy's 2005 tour, Bauhaus embarked on a full tour beginning in North America and Mexico, in autumn 2005, and ending in Europe in February 2006. The band also mentioned that they hoped to record new music following the tour. In May, the band was the opening slot of Nine Inch Nails on the summer leg of their US tour.
In 2008, Bauhaus released their first new studio album since 1983, "Go Away White". It marked the band's end and the album had no promotional tour. In late-2007, drummer Kevin Haskins said: "We were getting along really well, but there was an incident that occurred". As a result, "some of us just felt that we didn't want to carry on as a working unit." In early-2008, Peter Murphy claimed that he "was most satisfied with the bonding on an emotional level. It was good to be working together and to put the past behind us and it was very positive. The result was coming out really fast, so it was exciting and it was very enjoyable", but in the end "that rocky character worked and I think it was a bit right to finish it, really." The same year, bassist David J commented on the breakup: "You have a test tube, and you pour in one chemical, and you pour in another chemical, and something happens. It starts to bubble. Pour in another chemical, and it starts to bubble a bit more. You pour in a fourth chemical, and it bubbles really violently, and then explodes. That's my answer."
Musical style.
Bauhaus' influences included: punk rock (e.g. Devo, The Stooges and Sex Pistols), glam rock (e.g. David Bowie, Gary Glitter and T. Rex), art rock/experimental music (e.g. Brian Eno, Pere Ubu, Roxy Music, Suicide and The Velvet Underground), krautrock (e.g. Kraftwerk, Can and Neu!), funk (e.g. James Brown, Bobby Byrd, Sly and the Family Stone) and dub reggae (e.g. Lee Scratch Perry, Errol Thompson and King Tubby). During their 2006 tour reunion, Bauhaus covered Joy Division's "Transmission", one of their contemporary influences.
Bauhaus combined these influences to create a gloomy, earnest and introspective version of post-punk which appealed to many music fans who were left disillusioned in the wake of punk's collapse. Its crucial elements included Peter Murphy's deep and sonorous voice, Daniel Ash's jagged guitar playing, and David J's dub-influenced bass. Their sound and gloomy style would eventually come to be known as gothic rock.
Legacy and influence.
Although the band was short-lived, their music was influential upon many bands and artists that followed. They have had an impact on gothic and deathrock groups including: Christian Death, Type O Negative and Glenn Danzig. The Mission's Wayne Hussey sang with Peter Murphy on stage in 2013.
Bauhaus has inspired many industrial rock groups like Marilyn Manson, Nine Inch Nails, Nitzer Ebb and Skinny Puppy. The band has been cited as an influence by electronic act Carl Craig. Bauhaus has also been hailed by several alternative/indie rock groups including Jane's Addiction, Soundgarden, A Neon Rome, AFI, Hole, Interpol, My Chemical Romance, She Wants Revenge, Elliott Smith, The Dresden Dolls, The Flaming Lips and The Horrors. According to Courtney Love's not officially authorized biography, Kurt Cobain was a "closet deathrocker" and his Bauhaus' records were "scratched up".
The group have been namechecked by several other front-men and musicians, including: Steve Albini (of Big Black), Ian Curtis (of Joy Division), Jello Biafra of Dead Kennedys Al Jourgensen of Ministry, Fred Durst (of Limp Bizkit), Jonathan Davis (of Korn), Duff McKagan (of Guns N' Roses), Stuart Braithwaite (of Mogwai), Stephen Malkmus (of Pavement) and Jarvis Cocker (of Pulp).
Their song, "All We Ever Wanted Was Everything", was covered by artists and bands, including: John Frusciante (former guitarist of Red Hot Chili Peppers), MGMT
 and Xiu Xiu. Xiu Xiu recorded it in 2006 for their "Tu Mi Piaci" EP. Billy Corgan of Smashing Pumpkins sang T. Rex's "Telegram Sam" and "All We Ever Wanted Was Everything" (from the album "The Sky's Gone Out") live on stage with Bauhaus in 1998. Bauhaus' signature song, "Bela Lugosi's Dead", was covered by several acts, including: Massive Attack, Trent Reznor, and Chris Cornell (former singer of Soundgarden).
Their fan base extends beyond music: comic book writer Alan Moore wrote on the sleeve notes of "Mask", and contributed to an anonymous review on them called "Phantoms of the Teenage Opera" for "Sounds".
Popular culture.
Bauhaus's influence on popular culture is visible. In the "Beavis and Butt-head" season 3 (1993) episode "Meet God, Part II" they are viewing and commenting on a music video for Bauhaus' David Bowie cover "Ziggy Stardust". In the episode "Raisins" of South Park, Henrietta Biggle (one of the "goth kids") had a bedroom poster of "Blauhaus", a parody version of the band. In James O'Barr's comic book, "The Crow", the main character, Eric, was heavily based on Peter Murphy when O'Barr saw the band in Berlin, Germany. In Neil Gaiman's series "The Sandman", Dream's face and appearance is based on Bauhaus frontman Peter Murphy. In fact, Gaiman explained that Murphy was the original model for Morpheus. Gaiman also stated that Sandman artist, Dave McKean, based Dream's face in the cover of Sandman #1 on Murphy.
References.
 

</doc>
<doc id="55014" url="http://en.wikipedia.org/wiki?curid=55014" title="Leslie Nielsen">
Leslie Nielsen

Leslie William Nielsen, OC (11 February 1926 – 28 November 2010) was a Canadian-American actor and comedian. He appeared in more than 100 films and 150 television programs, portraying more than 220 characters.
Nielsen was born in Regina, Saskatchewan, Canada. He enlisted in the Royal Canadian Air Force and later worked as a disc jockey before receiving a scholarship to study theatre at the Neighborhood Playhouse. Making his acting debut in 1948, he made more than 50 television appearances two years later. Nielsen later made his film debut in 1956, with supporting roles in several drama, western, and romance films produced between the 1950s and the 1970s, with Nielsen crossing genres in both television and films.
Although his notable performances in the films "Forbidden Planet" and "The Poseidon Adventure" gave him standing as a serious actor, Nielsen eventually gained enduring recognition for his deadpan comedy roles during the 1980s and the early 1990s, after being cast against type for the Zucker, Abrahams, and Zucker comedy film "Airplane!". Nielsen specialized in his portrayal of characters oblivious to and complicit in their absurd surroundings, which gave him a reputation as a comedian. "Airplane!" marked Nielsen's turning point, which made him "the Olivier of spoofs" according to film critic Roger Ebert; his work on the film led to more further success in the genre with "The Naked Gun" film series, based on their earlier short-lived television series "Police Squad!", in which he also starred. Nielsen received a variety of awards and was inducted into the Canada and Hollywood Walks of Fame.
Early life.
Nielsen was born on 11 February 1926 in Regina, Saskatchewan. His mother, Mabel Elizabeth (née Davies), was a Welsh immigrant, and his father, Ingvard Eversen Nielsen, was a Danish-born constable in the Royal Canadian Mounted Police. Nielsen had two brothers; the elder, Erik Nielsen (1924–2008), was deputy prime minister of Canada from 1984 to 1986.
His half-uncle, Jean Hersholt, was an actor known for his portrayal of Dr. Christian in a radio series of that name and the subsequent television series and films. In a 1994 "Boston Globe" article, Nielsen explained, "I did learn very early that when I would mention my uncle, people would look at me as if I were the biggest liar in the world. Then I would take them home and show them 8-by-10 glossies, and things changed quite drastically. So I began to think that maybe this acting business was not a bad idea, much as I was very shy about it and certainly without courage regarding it. My uncle died not too long after I was in a position to know him. I regret that I had not a chance to know him better."
Nielsen lived for several years in Fort Norman (now Tulita), Northwest Territories where his father was with the Royal Canadian Mounted Police. Ingvard was a troubled man who beat his wife and sons, and Leslie longed to escape. When he graduated from high school at 17, he joined the Royal Canadian Air Force even though he was legally deaf (he wore hearing aids most of his life). Following graduation from Victoria School of Performing and Visual Arts in Edmonton, Nielsen enlisted in the Royal Canadian Air Force and trained as an aerial gunner during World War II. He was too young to be fully trained or sent overseas. He worked briefly as a disc jockey at a Calgary, Alberta, radio station, before enrolling at the Lorne Greene Academy of Radio Arts, Toronto. While studying in Toronto, Nielsen received a scholarship to the Neighborhood Playhouse. He noted, "I couldn't refuse, but I must say when you come from the land of the snow goose, the moose and wool to New York, you're bringing every ton of hayseed and country bumpkin that you packed. As long as I didn't open my mouth, I felt a certain security. But I always thought I was going to be unmasked: 'OK, pack your stuff.' 'Well, what's the matter?' 'We've discovered you have no talent; we're shipping you back to Canada.'" He moved to New York City for his scholarship, studying theater and music at the Neighborhood Playhouse, while performing in summer stock theatre. Afterward, he attended the Actors Studio, until making his first television appearance in 1948 on an episode of "Studio One", alongside Charlton Heston, for which he was paid US$75.
Career.
Early career.
"It was a strange era, the tail end of the golden age. A time when the Tiffany's of filmmakers was burying its head in the sand and trying to pretend that this new medium (television) was not happening."
Nielsen reflecting on the era when he started acting.
Nielsen's career began in dramatic roles on television during "Television's Golden Age", appearing in almost 50 live programs in 1950 alone. He said there "was very little gold, we only got $75 or $100 per show." He narrated documentaries and commercials and most of his early work as a dramatic actor was uneventful. Hal Erickson of Allmovie noted that "much of Nielsen's early work was undistinguished; he was merely a handsome leading man in an industry overstocked with handsome leading men." In 1956 he made his feature film debut in the Michael Curtiz-directed musical film "The Vagabond King". In the "Seattle Post-Intelligencer", Nielsen remembered Curtiz as "a sadist, a charming sadist, but a sadist". Nielsen called this film "The Vagabond Turkey". Though the film was not a success, producer Nicholas Nayfack offered him an audition for the science fiction film "Forbidden Planet", resulting in Nielsen's taking a long contract with Metro-Goldwyn-Mayer (MGM).
"Forbidden Planet" became an instant success, and roles in other MGM films such as "Ransom!" (1956), "The Opposite Sex" (1956) and "Hot Summer Night" (1957) followed. In 1957 he won the lead role opposite Debbie Reynolds in the romantic comedy "Tammy and the Bachelor", which, as a "Chicago Tribune" critic wrote in 1998, made people consider Nielsen a dramatic actor and handsome romantic lead. However, dissatisfied with the films he was offered, calling the studios "a Tiffany, which had forgotten how to make silver", Nielsen left MGM after auditioning for Messala in the 1959 "Ben-Hur". Stephen Boyd got the role. After leaving the studios, Nielsen landed the lead role in the Disney miniseries "The Swamp Fox", as American Revolutionary War hero Francis Marion. In a 1988 interview he reflected on the series, saying, "That was a great experience, because the Disney people didn't do their shows like everyone else, knocking out an episode a week. ... We only had to do an episode a month, and the budgets were extremely high for TV at that time. We had location shooting rather than cheap studio backdrops, and very authentic costumes." Eight episodes were produced and aired between 1959 and 1961.
His television appearances include "Justice", "Alfred Hitchcock Presents", "The Virginian", and "The Wild Wild West". In 1961, he was the lead in a Los Angeles police drama called "The New Breed". He guest-starred in a 1964 episode of "Daniel Boone" with Fess Parker and, in a minor but credited role, Jay Silverheels. In 1968, he had a major role in the pilot for the police series "Hawaii Five-O", and appeared in one of the seventh-season episodes. In 1969, he had the leading role as a police officer in "".
In 1972, Nielsen appeared as the ship's captain in the "The Poseidon Adventure". He also starred in the William Girdler's 1977 action film, "Project: Kill". His last dramatic role before mainly comedy roles was the 1979 Canadian disaster film "City on Fire", in which he played a corrupt mayor. In 1980, he guest-starred as Sinclair on the CBS miniseries "The Chisholms".
"Airplane!" and "The Naked Gun".
Nielsen's supporting role of Dr. Rumack in Zucker, Abrahams and Zucker's 1980's "Airplane!" was a watershed in his career. The film, a parody of disaster films such as "Zero Hour!" and "Airport", was based on building a comedy around actors known for dramatic roles. Other stars included Robert Stack, Peter Graves, and Lloyd Bridges. Nielsen's deadpan delivery contrasted with the absurdity surrounding him. When asked, "Surely you can't be serious?", he responded with a curt, "I am serious. And don't call me Shirley." In several interviews he reflected on the line: "I thought it was amusing, but it never occurred to me that it was going to become a trademark. It's such a surprise...the thing comes out, people say, 'What did he say?!'" Nielsen said he was "...pleased and honored that [he] had a chance to deliver that line." The comedic exchange was at #79 on the American Film Institute's AFI's 100 Years...100 Movie Quotes. The American Film Institute included the film in its list of the top ten comedy films of all time in 2008, and a 2007 survey in the United Kingdom judged it the second greatest comedy film of all time, while in 2012 "Empire" magazine voted it No. 1 in "The 50 Funniest Comedies Ever" poll. Critics praised the film, which also proved a long-term success with audiences. In 2010 Airplane! was selected for preservation in the National Film Registry by the Library of Congress.
The directors cast Nielsen for his ability to play like "a fish in water", saying "You could have cast funny people and done it with everybody winking, goofing off, and silly... we wanted people to be oblivious to the comedy." For Nielsen, "Airplane!" marked a shift from dramatic roles to deadpan comedy. When it was suggested his role in "Airplane!" was against type, Nielsen protested that he had "always been cast against type before," and that comedy was what he always wanted to do. The same directors cast Nielsen in a similar style, in their TV series "Police Squad!". The series introduced Nielsen as Frank Drebin, the stereotypical police officer modeled after serious characters in earlier police series.
"Police Squad"'s opening sequence was based on the 1950s show "M Squad", which starred Lee Marvin, which opened with footage of a police car roving through a dark urban setting with a big band playing a jazz song in the background. The voice-over and the show's organization into acts with an epilogue was homage to Quinn Martin police dramas including "The Fugitive", "The Streets of San Francisco", "Barnaby Jones", "The F.B.I.", and "Cannon". Nielsen portrayed a serious character whose one-liners appeared accidental next to the pratfalls and sight gags around him. Although the show lasted only six episodes Nielsen received an "Emmy Award" nomination for Outstanding Lead Actor in a Comedy Series.
Six years after cancellation of "Police Squad!", the film "" returned Nielsen to his role as Frank Drebin. It involved a ruthless drug king trying hypnosis to assassinate Queen Elizabeth II. Drebin, like the doctor in "Airplane!", seemed unaware of the absurdity around him even when contributing to it. Nielsen did many of his own stunts: "You have an idea of how you're going to do something, and it's your vision... unless you do it, it really doesn't stand a chance." This movie grossed over $78 million and was well received by critics. Ebert's 3½–star review (out of four) noted, "You laugh, and then you laugh at yourself for laughing."
' spawned two sequels: ' (1991) and "" (1994). "Naked Gun 2½" grossed more than the original, with $86,930,400, while "Naked Gun 33⅓" grossed $51,132,600. Nielsen remained open to a fourth "Naked Gun" film, although he doubted that it would be produced — "I don't think so," he said in 2005. "If there hasn't been one by now, I doubt it. I think it would be wonderful."
Nielsen briefly appeared on the World Wrestling Federation program in the summer of 1994 on "WWF Monday Night Raw"; capitalizing on Frank Drebin. Nielsen (and George Kennedy) were hired as sleuths to unravel the mystery of The Undertaker who had disappeared at January's Royal Rumble event. At SummerSlam 1994, in a "Naked Gun" parody, they were hot on the case (in fact, they were standing on a case). Although they did not find The Undertaker, the case had been closed (the literal case had been shut) and thus, they solved the mystery. In 1990, Nielsen appeared as a Frank Drebin character in advertisements in the United Kingdom for Red Rock Cider.
Non-comedic roles after Airplane! included "Prom Night" (1980) and "Creepshow" (1982), both horror films, and as a dramatic and unsympathetic character in the 1986 comedy "Soul Man". His last dramatic role was as Allen Green, a violent client of a prostitute killed in self-defense by Barbra Streisand's character, Claudia Draper, in Martin Ritt's courtroom drama "Nuts" (1987).
Later comedies.
Subsequent to "Airplane!" and "The Naked Gun", Nielsen portrayed similar styled roles in a number of other films. These mostly emulated the style of "The Naked Gun" with varying success and often targeted specific films: many were panned by critics and most performed poorly. "Repossessed" (1990) and ' (2001), parodies of "The Exorcist" and ', respectively. Both attempted absurd comedy but were poorly received. Even a leading role in a Mel Brooks comic horror, "", failed to generate much box office excitement, although it did gain a following later release to video. Both 1996's "Spy Hard" and 1998's "Wrongfully Accused", a parody of James Bond films and "The Fugitive", were popular on video but not well received by critics.
His attempt at children's comedies met additional criticism. "Surf Ninjas" (1993) and "Mr. Magoo" (1997) had scathing reviews. Several critics were disappointed that Nielsen's role in "Surf Ninjas" was only "an extended cameo" and Chris Hicks recommended that viewers "avoid any comedy that features Leslie Nielsen outside of the "Naked Gun" series." Jeff Miller of the "Houston Chronicle" panned "Mr. Magoo", a live action remake of the 1950s cartoon, by saying, "I'm supposed to suggest how the film might be better but I can't think of anything to say other than to make the film again."
Nielsen's first major success since "The Naked Gun" came in a supporting role in "Scary Movie 3" (2003). His appearance as President Harris led to a second appearance in its sequel, "Scary Movie 4" (2006). This was the first time Nielsen had reprised a character since Frank Drebin. In one scene, Nielsen appeared almost nude, and one critic referred to the scene as putting "the 'scary' in "Scary Movie 4"."
Video, stage, and celebrity productions.
Nielsen also produced instructional golf videos, which were not presented in a serious style, beginning with 1993's "Bad Golf Made Easier". The videos combined comedy with golf techniques. The series spawned two additional sequels, "Bad Golf My Way" (1994) and "Stupid Little Golf Video" (1997). Nielsen also co-wrote a fictional autobiography titled "The Naked Truth". The book portrayed Nielsen as a popular actor with a long history of prestigious films.
In his eighties, Nielsen performed serious roles on screen and stage (such as his one-man theatre show "Darrow", in which he played Clarence Darrow), as well as providing voice-overs and appearances for commercials; cartoons like "Zeroman" where he had the leading role/voice; children's shows, such as "Pumper Pups", which he narrated, in addition to comedic film roles. The sibling relationship with his elder brother, the Honourable Erik Nielsen, a former Deputy Prime Minister of Canada, served as the premise of an HBO mockumentary entitled "The Canadian Conspiracy" in which Leslie Nielsen appeared, along with other prominent Canadian-born media personalities. He was a celebrity contestant on CBS's "Gameshow Marathon", where he played "The Price Is Right", "Let's Make a Deal", "Beat the Clock", and "Press Your Luck" for charity.
Final acting years.
Beginning in February 2007, Nielsen began playing a small role as a doctor in the humorous yet educational television show "Doctor*Ology". The show chronicles real-life medical techniques and technology, on the Discovery Channel. Nielsen said: "There are any number of things that you think about when you ponder if you hadn't been an actor, what would you be, and I've always said I'd like to be an astronaut or a doctor. I have such admiration for doctors. I just don't know how you go around to thank them enough for coming up with the world's most remarkable new discoveries."
In 2007, Nielsen starred in the drama "Music Within". In 2008, he portrayed a version of Uncle Ben for "Superhero Movie", a spoof of superhero films. He then appeared in the 2008 parody "An American Carol", which David Zucker directed, produced and co-wrote. He appeared in the 2009 parody "Stan Helsing". Nielsen portrayed the Doctor in the Spanish horror comedy "Spanish Movie", a spoof comedy like "Scary Movie", but making fun of popular Spanish films.
Nielsen appeared in more than 100 films and 1,500 television programs, portraying more than 220 characters.
Personal life.
"I'm afraid if I don't keep moving, they're going to catch me ... I am 81 years old and I want to see what's around the corner, and I don't see any reason in the world not to keep working. But I am starting to value my down time a great deal because I am realizing there might be other things to do that I am overlooking."
—Nielsen reflecting on his career in 2007
Nielsen married four times: nightclub singer Monica Boyar (1950–1956), Alisande Ullman (1958–1973), Brooks Oliver (1981–1983) and Barbaree Earl (2001–2010). Nielsen had two daughters from his second marriage, Maura and Thea Nielsen.
Nielsen often played golf. He joked, "I have no goals or ambition. I do, however, wish to work enough to maintain whatever celebrity status I have so that they will continue to invite me to golf tournaments." His interest in the sport led him to comedic instructional films.
Nielsen was a practical joker, and known for pranking people with a portable hand-controlled fart machine: "he always had that fart machine with him." His epitaph read: "Let 'er rip", a final reference to his favorite practical joke.
Nielsen had a hearing impairment. He was legally deaf and wore hearing aids for most of his life. Because of this impairment, he supported the Better Hearing Institute. Later in life, Nielsen had knee osteoarthritis. He participated in an educational video from The Arthritis Research Centre of Canada (ARC), demonstrating the physical examination of a patient with knee osteoarthritis.
Death.
In November 2010, Nielsen was admitted to a Fort Lauderdale, Florida, hospital with pneumonia. On 28 November, Doug Nielsen, Nielsen's nephew, told the CJOB radio station that Nielsen had died in his sleep from pneumonia around 5:30 pm EST surrounded by family and friends. He was interred in Fort Lauderdale's Evergreen Cemetery. As a final bit of humor, Nielsen chose "Let 'er rip" as his epitaph.
Achievements.
Among his awards, in 1995 Nielsen received UCLA's Jack Benny Award. In 1988, he became the 1,884th personality to receive a star on the Hollywood Walk of Fame at 6541 Hollywood Blvd. In 2001 he was inducted into Canada's Walk of Fame. The following year he was made an Officer of the Order of Canada, although he was also a naturalized U.S. citizen. With his American status, he maintained his Canadian heritage: "There's no way you can be a Canadian and think you can lose it ... Canadians are a goodly group. They are very aware of caring and helping." On 19 May 2005, during the centennial gala of his birth province, Saskatchewan, Leslie Nielsen was introduced to HM Queen Elizabeth II.
In 1997, a Golden Palm Star on the Palm Springs, California, Walk of Stars was dedicated to him.
On 20 February 2002, Nielsen was named an honorary citizen of West Virginia and an Ambassador of Mountain State Goodwill. Nielsen visited the state many times to speak and visit friends. In 2003, in honor of Nielsen, Grant MacEwan College named its school of communications after him. Also in 2003, the Alliance of Canadian Cinema, Television and Radio Artists awarded him the ACTRA Award of Excellence.

</doc>
<doc id="55016" url="http://en.wikipedia.org/wiki?curid=55016" title="Ivo Andrić">
Ivo Andrić

Ivan "Ivo" Andrić (]) (9 October 1892 – 13 March 1975) was a Yugoslav novelist, short story writer, and the 1961 winner of the Nobel Prize in Literature. His writings dealt mainly with life in his native Bosnia under the Ottoman Empire.
Biography.
Ivan Andrić was born on 9 October 1892, to Bosnian Croat parents in Dolac, a small town near Travnik, in the Condominium of Bosnia and Herzegovina. He was born as Ivan, but became known by the diminutive Ivo. When Andrić was two years old, his father Antun died. Because his mother Katarina was too poor to support him, he was raised by his mother's family in the town of Višegrad on the river Drina in eastern Bosnia, where he saw the 16th-century Mehmed Paša Sokolović Bridge, later made famous in his novel "The Bridge on the Drina" ("Na Drini ćuprija").
Andrić attended the Jesuit gymnasium in Travnik, followed by Sarajevo's gymnasium and later he studied philosophy and history at the Universities of Zagreb (1912 and 1918), Vienna (1913), Kraków (1914), and Graz (PhD, 1924). Because of his political activities, Andrić was imprisoned by the Austrian government during World War I (first in Maribor and later in the Doboj detention camp) alongside other pro-Yugoslav civilians.
Andrić started his literary career as a poet. In 1914 he was one of the contributors to Hrvatska mlada lirika (Young Croatian Lyrics).
Under the newly formed Kingdom of Serbs, Croats, and Slovenes (later Kingdom of Yugoslavia) Andrić became a civil servant, first in the Ministry of Faiths and then the Ministry of Foreign Affairs, where he pursued a successful diplomatic career reaching as high as Deputy Foreign Minister.
During his diplomatic service, he worked in embassy at Holy See (1920), consulates in Bucharest, Trieste and Graz (1924), consulates in Paris and Marseilles (1927), and embassy in Madrid (1928). In 1939 he was appointed ambassador in Germany. He was also a delegate of the Kingdom of Yugoslavia at the 19th, 21st, 23rd and 24th sessions of the League of Nations in Geneva in the period 1930–1934. Andrić greatly opposed the movement of Stjepan Radić, the president of the Croatian Peasant Party. His ambassadorship ended in 1941 after the German invasion of Yugoslavia. During World War II, Andrić lived quietly in Belgrade, completing three of his most famous novels which were published in 1945, including "The Bridge on the Drina".
After the war, Andrić spent most of his time in his home in Belgrade and held a number of ceremonial posts in the new Communist government of Yugoslavia, and was also a member of the Parliament of Bosnia and Herzegovina. In 1961, he was awarded the Nobel Prize for Literature "for the epic force with which he has traced themes and depicted human destinies drawn from the history of his country". He donated all of the prize money for the improvement of libraries in Bosnia and Herzegovina. He was member of the Serbian Academy of Sciences and Arts.
Following the death of his second wife, Milica Babić, in 1968, he began reducing his public activities. In 1969 he was elected an honorary member of the Academy of Sciences and Arts of Bosnia and Herzegovina and in 1972 the University of Belgrade awarded him an honorary doctorate. As time went by, he grew increasingly ill and eventually died on 13 March 1975, in Belgrade, SR Serbia, SFR Yugoslavia.
He was buried in the Belgrade New Cemetery, in the Alley of Distinguished Citizens.
Works.
The material for his works was mainly drawn from the history, folklore, and culture of his native Bosnia.
Those were all released in 1945 and written during World War II while Andrić was living quietly in Belgrade. They are often referred to as the"Bosnian trilogy" as they were released simultaneously and had been written in the same period. However, they are connected only thematically—they are indeed three completely different works.
Some of his other popular works include:
His manuscripts and literary legacy are in the custody of the foundation he founded (Fondacija Ive Andrića) and Serbian Academy of Sciences and Arts. Some of his manuscripts and literary legacy are in custody of the Croatian Academy of Sciences and Arts, the Institute for the History of Croatian Literature, Theater and Music in Zagreb.
Some claim that the works of Andrić, particularly his thesis "The Development of Spiritual Life in Bosnia under the Influence of Turkish Rule" have resurfaced as a source of anti-Muslim prejudice in Serbian cultural discourse.
Legacy.
Because of Andrić's unique circumstances (born in Bosnia to Croat parents, later living and working in Serbia), he is claimed as part of Serbian literature, Croatian literature, and Bosnian literature. Throughout his life, he worked in all three countries and contributed material to their various publications. In terms of what language or dialect he wrote in, he wrote in Serbo-Croatian, which was officially considered one language in Yugoslavia; he had been a believer in Yugoslav unity and Pan-slavism. However, it must be mentioned that Serbo-Croatian used to have two different subtypes – the Eastern standardization spread in Montenegro, Serbia and partly in Bosnia and Herzegovina), and Western standardization that is common in Croatia and partly in Bosnia and Herzegovina. Andrić first used its Croatian form (ijekavian accent of the Shtokavian dialect) and later its Serbian form (ekavian accent of Shtokavian dialect).
There was also a more specific, and more fundamental, divide—that between ekavian and ijekavian standards of then-Serbo-Croat – Andrić wrote in the ijekavian form (standard in both Western standard Croatia, middle-of-the-road standard Bosnia-Herzegovina, and Eastern standard Montenegro) only in his youth. As a mature writer, he wrote and published exclusively in ekavian (the official standard only in Serbia), even when depicting characters who live in Bosnia and who are quoted as speaking ijekavian accent in the dialogues, that stand out in otherwise ekavian text.
Andrić never used the translated equivalents of foreign words, as used to be common in Western, Croat standard, but international words, as is the rule in Serbian, Eastern standard.
Bosnians celebrate Andrić as a native son, as he was born and raised in Bosnia and set most of his stories in his native land. His doctoral thesis was on the cultural history of Bosnia under Turkish rule titled "The Development of Spiritual Life in Bosnia under the Influence of Turkish Rule", critical of Ottoman rule, an example of one of his many writings dealing with Bosnia.
Croatians point to his Croat heritage—both of his parents were Roman Catholic Croats in Bosnia. He declared himself a Croat while studying in Kraków in 1914, and had his work published in various Croatian publications. Andrić wrote in the Serbo-Croatian language's ijekavian accent until the formation of the Kingdom of the Serbs, Croats, and Slovenes (later the Kingdom of Yugoslavia) and his move to Belgrade, where he began writing in ekavian and embraced the Yugoslav cause.
Serbian sources claim him as a Serbian writer, saying that he mainly wrote in the ekavian standard that exists only in the Serbian language. Andrić self-declared as a Serb when he married Milica Babić in 1958 in Belgrade. He also became a member of the Serbian Academy of Science and Arts.
A house in Travnik, which resembles his original house in Dolac, has been transformed into a Museum, and his Belgrade flat on Andrićev Venac hosts the Museum of Ivo Andrić, and Ivo Andrić Foundation.
References.
</dl>

</doc>
<doc id="55017" url="http://en.wikipedia.org/wiki?curid=55017" title="Fusion power">
Fusion power

Fusion power is the generation of energy by nuclear fusion. Fusion reactions are high energy reactions in which two lighter atomic nuclei fuse to form a heavier nucleus. When they combine, some of the mass is lost. This is converted into energy through formula_1. Fusion power is a research effort to try and harness this energy to power large scale cleaner energy. It is also a major part of plasma physics research.
In large scale commercial proposals, heat from the fusion reaction is used to operate a steam turbine that drives electrical generators, as in existing fossil fuel and nuclear fission power stations. Many different fusion concepts have come in and out of vogue over the years. The current leading designs are the tokamak and inertial confinement fusion (laser) approaches.
Background.
Mechanism.
Fusion happens when two (or more) nuclei come close enough for the strong nuclear force to exceed the electrostatic force and pull them together. This process takes light nuclei and forms a heavier one, through a nuclear reaction. For nuclei lighter than iron-56 this is exothermic and releases energy. For nuclei heavier than iron-56 this is endothermic and requires an external source of energy. Hence, nuclei smaller than iron-56 are more likely to fuse while those heavier than iron-56 are more likely to break apart.
To fuse, nuclei must overcome the repulsive Coulomb force. This is a force caused by the nuclei containing positively charged protons that repel via the electromagnetic force. To overcome this "Coulomb barrier", the atoms must have a high kinetic energy. There are several ways of doing this, including heating or acceleration. Once an atom is heated above its ionization energy, its electrons are stripped away, leaving just the bare nucleus: the ion. Most fusion experiments use a hot cloud of ions and electrons. This cloud is known as a plasma. Most fusion reactions produce neutrons, which can be detected and degrade materials.
Theoretically, any atom could be fused, if enough pressure and temperature was applied., and studies have been made of the required conditions to create fusion conditions for a range of atoms. For a power plant, however, we are currently limited to only the lightest elements. Hydrogen is ideal: because of its small charge, it is the easiest atom to fuse. This reaction produces helium.
Cross section.
A reaction's cross section, (denoted σ) is the measure of how likely a fusion reaction will happen. It is a probability, and it depends on the velocity of the two nuclei when they strike one another. If the atoms move faster, fusion is more likely. If the atoms hit head on, fusion is more likely. Cross sections for many different fusion reactions were measured mainly in the 1970s using particle beams. A beam of species A was fired at species B at different speeds, and the amount of neutrons coming off was measured. Neutrons are a key product of fusion reactions. These nuclei are flying around in a hot cloud, with some distribution of velocities. If the plasma is thermalized, then the distribution looks like a bell curve, or maxwellian distribution. In this case, it is useful to take the average cross section over the velocity distribution. This is entered into the volumetric fusion rate:
where:
Lawson criterion.
This equation shows that energy varies with the temperature, density, speed of collision, and fuel used. This equation was central to John Lawsons' analysis of fusion power plants working with a hot plasma. Lawson assumed an energy balance, shown below.
Net Power = Efficiency *(Fusion - Radiation Loss - Conduction Loss)
Plasma clouds lose energy through conduction and radiation. Conduction is when ions, electrons or neutrals hit a surface and transfer a portion of their kinetic energy to the atoms of the surface. Radiation is when energy leaves the cloud as light. This can be in the visible, UV, IR or X-Ray light. Radiation increases as the temperature rises. To get net power from fusion, you must overcome these losses.
Triple Product: Density, temperature, time.
The Lawson criterion argues that a machine holding in a hot, thermalized and quasi-neutral plasma, has to meet basic criteria to overcome the radiation losses, conduction losses and a power plant efficiency of 30 percent. This became known as the "triple product": the plasma density and temperature and how long it is held in. For many years, work has been focused on reaching the highest triple product possible. This emphasis on formula_6 as a metric of success, has hurt other considerations like cost, size, complexity and efficiency. This has led to larger, more complicated and more expensive machines like ITER and NIF.
Plasma Behavior.
Plasma can be made by fully ionizing a gas. Plasma is a fluid which conducts electricity. In bulk, it is modeled using Magnetohydrodynamics which is a combination of the Navier-Stokes equations governing fluids and Maxwell's equations governing how magnetic and electric fields behave. Fusion exploits several plasma properties, including:
Self-Organization Plasma conducts electric and magnetic fields. This means that is can self-organize. Its motions can generate fields which can, in turn, self-contain it.
Diamagnetic Plasma Plasma can generate its own internal magnetic field. This can reject an externally applied magnetic field, making it diagmagnetic.
Magnetic mirrors Plasma can be reflected when it moves from a low to high density magnetic field.
Energy capture.
There are several proposals for energy capture. The simplest is using a heat cycle to heat a fluid with fusion reactions. It has been proposed to use the neutrons generated by fusion to re-generate a spent fission fuel. In addition, direct energy conversion, has been developed (at LLNL in the 1980s) as a method to maintain a voltage using the products of a fusion reaction. This has demonstrated an energy capture efficiency of 48 percent.
Possible approaches.
Magnetic confinement fusion.
Tokamak The most well developed and well funded approach to fusion energy. As of April 2012 there were an estimated 215 tokamaks either planned, decommissioned or currently operating (35 tokamaks), worldwide. This method races hot plasma around in a magnetically confined ring, with an internal current. When completed, ITER will be the world's largest tokamak.
Spherical tokamak A variation on the tokamak with a spherical shape.
Stellarator These are twisted rings of hot plasma. The stellarator attempts to create a natural twist plasma path, using external magnets; while Tokamaks create those magnetic fields using an internal current. Stellarators were developed by Lyman Spitzer in 1950 and have four designs: Torsatron, Heliotron, Heliac and Helias.
Levitated Dipole Experiment (LDX) These use a solid superconducting torus. This is magnetically levitated inside the reactor chamber. The superconductor forms an axisymmetric magnetic field that contains the plasma. The LDX was developed between MIT and Columbia University after 2000 by Jay Kesner and Michael E. Mauel.
Magnetic mirror Developed by Richard F. Post and teams at LLNL in the 1960s. Magnetic mirrors reflected hot plasma back and forth in a line. Variations included the magnetic bottle and the biconic cusp. A series of well-funded, large, mirror machines were built by the US government in the 1970s and 1980s.
Field-reversed configuration This device traps plasma in a self-organized quasi-stable structure; where the particle motion makes an internal magnetic field which then traps itself.
Reversed field pinch Here the plasma moves inside a ring. It has an internal magnetic field. As you move out from the center of this ring, the magnetic field reverses direction.
Inertial confinement fusion.
Direct drive In this technique, lasers directly blast a pellet of fuel. The goal is to start ignition, a fusion chain reaction. Ignition was first suggested by John Nuckolls, in 1972. Notable direct drive experiments have been conducted at the Laboratory for Laser Energetics, Laser Mégajoule and the GEKKO XII facilities. Good implosions require fuel pellets with close to a perfect shape in order to generate an symmetrical inward shock wave and to produce the high-density plasma.
Fast ignition This method uses two laser blasts. The first blast compresses the fusion fuel, while the second high energy pulse ignites it. Experiments have been conducted at the Laboratory for Laser Energetics using the Omega and Omega EP systems and at the GEKKO XII laser at the institute for laser engineering in Osaka Japan.
Indirect drive In this technique, lasers blasts a structure around the pellet of fuel. This structure is known as a Hohlraum. As it disintegrates the pellet is bathed in a more uniform x-ray light, creating better compression. The largest system using this method is the National Ignition Facility.
Magneto-inertial fusion or Magnetized Liner Inertial Fusion This combines a laser pulse with a magnetic pinch. The pinch community refers to it as Magnetized Liner Inertial Fusion while the ICF community refers to it as Magneto-inertial fusion.
Heavy Ion Beams There are also proposal to do inertial confinement fusion with ion beams instead of laser beams. The main difference is the mass of the beam has momentum, whereas lasers do not.
Magnetic or Electric pinches.
Z-Pinch This method sends a strong current (in the z-direction) through the plasma. The current generates a magnetic field that squeezes the plasma to fusion conditions. Pinches were the first method for man-made controlled fusion. Some examples include the Dense plasma focus and the Z machine at Sandia National Laboratories.
Theta-Pinch This method sends a current inside a plasma, in the theta direction.
Screw Pinch This method combines a theta and z-pinch for improved stabilization.
Inertial electrostatic confinement.
Fusor This method uses an electric field to heat ions to fusion conditions. The machine typically uses two spherical cages, a cathode inside the anode, inside a vacuum. These machines are not considered a viable approach to net power due to their high conduction and radiation losses. They are simple enough to build that amateurs have fused atoms using them.
Polywell This designs attempts to combine magnetic confinement with electrostatic fields, to avoid the conduction losses generated by the cage. This research, however, is immature and under developed.
Other.
Magnetized target fusion This method confines hot plasma using a magnetic field and squeezes it using inertia. Examples include LANL FRX-L machine and General Fusion device.
Uncontrolled Fusion has been initiated by man, using uncontrolled fission explosions. Early proposals for fusion power included using bombs to initiate reactions.
Beam fusion A beam of high energy particles can be fired at another beam or target and fusion will occur. This was used in the 1970s and 1980s to study the cross sections of high energy fusion reactions.
Bubble fusion This was a supposed fusion reaction that was supposed to occur inside extraordinarily large collapsing gas bubbles, created during acoustic liquid cavitation. This approach was discredited.
Cold fusion This is a hypothetical type of nuclear reaction that would occur at, or near, room temperature. Cold fusion has gained a reputation as Pathological science.
Muon-catalyzed fusion Muons allow atoms to get much closer and thus reduce the kinetic energy required to initiate fusion. Muons require more energy to produce than can be obtained from muon-catalysed fusion, making this approach impractical for the generation of power.
Common Tools.
Heating.
Gas must be first heated to form a plasma. This then needs to be hot enough to start fusion reactions. A number of heating schemes have been explored:
Radiofrequency Heating A radio wave is applied to the plasma, causing it to oscillate.
Electrostatic Heating An electric field can do work on charged ions or electrons, heating them.
Neutral Beam Injection Gas is heated and injected into the fusion device. It may be heated using an electric field and then neutralized. After injection, it collides with particles the imparting energy.
Magnetic Oscillations
Diagnostics.
Thomson Scattering Certain wavelengths of light will scatter off a plasma. This light can be detected and used to reconstruct the plasmas' behavior. This technique can be used to find its density and temperature. It is common in Inertial confinement fusion, Tokamaks and fusors. In ICF systems, this can be done by firing a second beam into a gold foil adjacent to the target. This makes x-rays that scatter or traverse the plasma. In Tokamaks, this can be done using mirrors and detectors to reflect light across a plane (two dimensions) or in a line (one dimension).
Langmuir probe This is a metal object placed in a plasma. A potential is applied to it, giving it a positive or negative voltage against the surrounding plasma. The metal collects charged particles, drawing a current. As the voltage changes, the current changes. This makes a IV Curve. The IV-curve can be used to determine the local plasma density, potential and temperature.
Geiger counter Deuterium or tritium fusion produces neutrons. Geiger counters record the rate of neutron production, so they are an essential tool for demonstrating success.
Flux Loop A loop of wire is inserted into the magnetic field. As the field passes through the loop, a current is made. The current is measured and used to find the total magnetic flux through that loop. This has been used on the National Compact Stellarator Experiment, the polywell and the LDX machines.
X-ray detector All plasma loses energy by emitting light. This covers the whole spectrum: visible, IR, UV, and X-rays. This occurs anytime a particle changes speed, for any reason. If the reason is deflection by a magnetic field, the radiation is Cyclotron radiation at low speeds and Synchrotron radiation at high speeds. If the reason is deflection by another particle, plasma radiates X-rays, known as Bremsstrahlung radiation. X-rays are termed in both hard and soft, based on their energy.
Power Production.
Steam turbines It has been proposed that steam turbines be used to convert the heat from the fusion chamber into electricity. The heat is transferred into a working fluid that turns into steam, driving electric generators.
Neutron blankets Deuterium and tritium fusion generates neutrons. This varies by technique (NIF has a record of 3E14 neutrons per second while a typical fusor produces 1E5 - 1E9 neutrons per second). It has been proposed to use these neutrons as a way to regenerate spent fission fuel or as a way to breed tritium from a liquid lithium blanket.
Direct conversion This is a method where the kinetic energy of a particle is converted into voltage. It was first suggested by Richard F. Post in conjunction with magnetic mirrors, in the late sixties. It has also been suggested for Field-Reversed Configurations. The process takes the plasma, expands it, and converts a large fraction of the random energy of the fusion products into directed motion. The particles are then collected on electrodes at various large electrical potentials. This method has demonstrated an experimental efficiency of 48 percent.
Confinement.
Confinement refers to all the conditions necessary to keep a plasma dense and hot long enough to undergo fusion. Here are some general principles.
To produce self-sustaining fusion, the energy released by the reaction (or at least a fraction of it) must be used to heat new reactant nuclei and keep them hot long enough that they also undergo fusion reactions.
Unconfined.
The first human-made, large-scale fusion reaction was the test of the hydrogen bomb, Ivy Mike, in 1952. As part of the PACER project, it was once proposed to use hydrogen bombs as a source of power by detonating them in underground caverns and then generating electricity from the heat produced, but such a power plant is unlikely ever to be constructed.
Magnetic confinement.
At the temperatures required for fusion, the fuel is heated to a plasma state. In this state it has a very good electrical conductivity. This opens the possibility of confining the plasma with magnetic fields. This is the case of magnetized plasma, where the magnetic fields and plasma intermix. This is generally known as magnetic confinement. The field lines put a Lorentz force on the plasma. The force works perpendicular to the magnetic fields, so one problem in magnetic confinement is preventing the plasma from leaking out the ends of the field lines. A general measure of magnetic trapping in fusion is the beta ratio:
formula_7 
This is the ratio of the externally applied field to the internal pressure of the plasma. A value of 1 is ideal trapping. Some examples of beta vales include:
Magnetic Mirror One example of magnetic confinement is with the magnetic mirror effect. If a particle follows the field line and enters a region of higher field strength, the particles can be reflected. There are several devices that try to use this effect. The most famous was the magnetic mirror machines, which was a series of large, expensive devices built at the Lawrence Livermore National Laboratory from the 1960s to mid 1980s. Some other examples include the magnetic bottles and Biconic cusp. Because the mirror machines were straight, they had some advantages over a ring shape. First, mirrors would easier to construct and maintain and second direct conversion energy capture, was easier to implement. As the confinement achieved in experiments was poor, this approach was abandoned.
Magnetic Loops Another example of magnetic confinement is to bend the field lines back on themselves, either in circles or more commonly in nested toroidal surfaces. The most highly developed system of this type is the "tokamak", with the "stellarator" being next most advanced, followed by the Reversed field pinch. Compact toroids, especially the "Field-Reversed Configuration" and the spheromak, attempt to combine the advantages of toroidal magnetic surfaces with those of a simply connected (non-toroidal) machine, resulting in a mechanically simpler and smaller confinement area.
Inertial confinement.
Inertial confinement is the use of rapidly imploding shell to heat and confine plasma. The shell is imploded using a direct laser blast (direct drive) or a secondary x-ray blast (indirect drive) or heavy ion beams. Theoretically, fusion using lasers would be done using tiny pellets of fuel that explode several times a second. To induce the explosion, the pellet must be compressed to about 30 times solid density with energetic beams. If direct drive is used - the beams are focused directly on the pellet - it can in principle be very efficient, but in practice is difficult to obtain the needed uniformity. The alternative approach, indirect drive, uses beams to heat a shell, and then the shell radiates x-rays, which then implode the pellet. The beams are commonly laser beams, but heavy and light ion beams and electron beams have all been investigated.
Electrostatic confinement.
There are also electrostatic confinement fusion devices. These devices confine ions using electrostatic fields. The best known is the Fusor. This device has an cathode inside an anode wire cage. Positive ions fly towards the negative inner cage, and are heated by the electric field in the process. If they miss the inner cage they can collide and fuse. Ions typically hit the cathode, however, creating prohibitory high conduction losses. Also, fusion rates in fusors are very low due to competing physical effects, such as energy loss in the form of light radiation. Designs have been proposed to avoid the problems associated with the cage, by generating the field using a non-neutral cloud. These include a plasma oscillating device, a penning trap and the polywell. The technology is relatively immature, however, and many scientific and engineering questions remain.
History of research.
1920s.
Research into nuclear fusion started in the early part of the 20th century. In 1920 the British physicist Francis William Aston discovered that the total mass equivalent of four hydrogen atoms (two protons and two neutrons) are heavier than the total mass of one helium atom (He-4), which implied that net energy can be released by combining hydrogen atoms together to form helium, and provided the first hints of a mechanism by which stars could produce energy in the quantities being measured. Through the 1920s, Arthur Stanley Eddington became a major proponent of the proton–proton chain reaction (PP reaction) as the primary system running the Sun.
1930s.
A theory was verified by Hans Bethe in 1939 showing that beta decay and quantum tunneling in the Sun's core might convert one of the protons into a neutron and thereby producing deuterium rather than a diproton. The deuterium would then fuse through other reactions to further increase the energy output. For this work, Bethe won the Nobel Prize in Physics.
1940s.
In 1942, nuclear fusion research was subsumed into the Manhattan Project and the science became obscured by the secrecy surrounding the field. The first patent related to a fusion reactor was registered in 1946 by the United Kingdom Atomic Energy Authority, the inventors being Sir George Paget Thomson and Moses Blackman. This was the first detailed examination of the Z-pinch concept, and small efforts to experiment with it started at several sites in the UK.
Pinch was first developed in the UK in the immediate post-war era. Starting in 1947 small experiments were carried out and plans were laid to build a much larger machine. Two teams were quickly formed and began a series of ever-larger experiments. When the Huemul results hit the news, James L. Tuck, a UK physicist working at Los Alamos, introduced the pinch concept in the US and produced a series of machines known as the Perhapsatron. In the Soviet Union, unbeknownst to the west, a series of similar machines were being built. All of these devices quickly demonstrated a series of instabilities when the pinch was applied, which broke up the plasma column long before it reached the densities and temperatures required for fusion. In 1953 Tuck and others suggested a number of solutions to these problems.
A major area of study in early fusion power research is the "pinch" concept. Pinch is based on the fact that plasmas are electrically conducting. By running a current through the plasma, a magnetic field will be generated around the plasma. This field will, according to Lenz's law, create an inward directed force that causes the plasma to collapse inward, raising its density. Denser plasmas generate denser magnetic fields, increasing the inward force, leading to a chain reaction. If the conditions are correct, this can lead to the densities and temperatures needed for fusion. The difficulty is getting the current into the plasma, which would normally melt any sort of mechanical electrode. A solution emerges again due to the conducting nature of the plasma; by placing the plasma in the middle of an electromagnet, induction can be used to generate the current.
1950s.
The first successful man-made fusion device was the boosted fission weapon tested in 1951 in the Greenhouse Item test. This was followed by true fusion weapons in 1952's Ivy Mike, and the first practical examples in 1954's Castle Bravo. This was uncontrolled fusion. In these devices, the energy released by the fission explosion is used to compress and heat fusion fuel, starting a fusion reaction. Fusion releases neutrons. These neutrons hit the surrounding fission fuel, causing the atoms to split apart much faster than normal fission processes - almost instantly by comparison. This increases the effectiveness of bombs: normal fission weapons blow themselves apart before all their fuel is used; fusion/fission weapons do not have this practical upper limit.
In 1951, Lyman Spitzer began work on a stellarator under the code name Project Matterhorn. His work led to the creation of the Princeton Plasma Physics Laboratory. Spitzer planned an aggressive development project of four machines, A, B, C, and D. A and B were small research devices, C would be the prototype of a power-producing machine, and D would be the prototype of a commercial device. A worked without issue, but even by the time B was being used it was clear the stellarator was also suffering from instabilities and plasma leakage. Progress on C slowed as attempts were made to correct for these problems.
Around the same time, an expatriate German Ronald Richter proposed the Huemul Project in Argentina, announcing positive results in 1951. Although these results turned out to be false, it sparked off intense interest around the world. The UK pinch programs were greatly expanded, culminating in the ZETA and Sceptre devices. In the US, pinch experiments like those in the UK started at the Los Alamos National Laboratory. Similar devices were built in the USSR after data on the UK program was passed to them by Klaus Fuchs. At Princeton University a new approach developed as the stellarator, and the research establishment formed there continues to this day as the Princeton Plasma Physics Laboratory.
By the mid-1950s it was clear that the simple theoretical tools being used to calculate the performance of all fusion machines were simply not predicting their actual behavior. Machines invariably leaked their plasma from their confinement area at rates far higher than predicted.
In 1954, Edward Teller held a gathering of fusion researchers at the Princeton Gun Club, near the Project Matterhorn (now known as Project Sherwood) grounds. Teller started by pointing out the problems that everyone was having, and suggested that any system where the plasma was confined within concave fields was doomed to fail. Attendees remember him saying something to the effect that the fields were like rubber bands, and they would attempt to snap back to a straight configuration whenever the power was increased, ejecting the plasma. He went on to say that it appeared the only way to confine the plasma in a stable configuration would be to use convex fields, a "cusp" configuration.
When the meeting concluded, most of the researchers quickly turned out papers saying why Teller's concerns did not apply to their particular device. The pinch machines did not use magnetic fields in this way at all, while the mirror and stellarator seemed to have various ways out. This was soon followed by a paper by Martin David Kruskal and Martin Schwarzschild discussing pinch machines, however, which demonstrated instabilities in those devices were inherent to the design.
The largest "classic" pinch device was the ZETA, including all of these suggested upgrades, starting operations in the UK in 1957. In early 1958, John Cockcroft announced that fusion had been achieved in the ZETA, an announcement that made headlines around the world. When physicists in the US expressed concerns about the claims they were initially dismissed. US experiments soon demonstrated the same neutrons, although temperature measurements suggested these could not be from fusion reactions. The neutrons seen in the UK were later demonstrated to be from different versions of the same instability processes that plagued earlier machines. Cockcroft was forced to retract the fusion claims, and the entire field was tainted for years. ZETA ended its experiments in 1968.
The first controlled fusion experiment was accomplished using Scylla I at the Los Alamos National Laboratory in 1958. This was a pinch machine, with a cylinder full of deuterium. Electric current shot down the sides of the cylinder. The current made magnetic fields that compressed the plasma to 15 million degrees Celsius, squeezed the gas, fused it and produced neutrons.
In 1950–1951 I.E. Tamm and A.D. Sakharov in the Soviet Union, first discussed a tokamak-like approach. Experimental research on those designs began in 1956 at the Kurchatov Institute in Moscow by a group of Soviet scientists led by Lev Artsimovich. The tokamak essentially combined a low-power pinch device with a low-power simple stellarator. The key was to combine the fields in such a way that the particles orbited within the reactor a particular number of times, today known as the "safety factor". The combination of these fields dramatically improved confinement times and densities, resulting in huge improvements over existing devices.
1960s.
A key plasma physics text was published by Lyman Spitzer at Princeton in 1963. Spitzer took the ideal gas laws and adopted them to an ionized plasma, developing many of the fundamental equations used to model a plasma.
Laser fusion was suggested in 1962 by scientists at Lawrence Livermore National Laboratory, shortly after the invention of the laser itself in 1960. At the time, Lasers were low power machines, but low-level research began as early as 1965. Laser fusion, formally known as inertial confinement fusion, involves imploding a target by using laser beams. There are two ways to do this: indirect drive and direct drive. In direct drive, the laser blasts a pellet of fuel. In indirect drive, the lasers blast a structure around the fuel. This makes x-rays that squeeze the fuel. Both methods compress the fuel so that fusion can take place.
At the 1964 World's Fair, the public was given its first demonstration of nuclear fusion. The device was a θ-pinch from General Electric. This was similar to the Scylla machine developed earlier at Los Alamos.
The magnetic mirror was first published in 1967 by Richard F. Post and many others at the Lawrence Livermore National Laboratory. The mirror consisted of two large magnets arranged so they had strong fields within them, and a weaker, but connected, field between them. Plasma introduced in the area between the two magnets would "bounce back" from the stronger fields in the middle.
The A.D. Sakharov group constructed the first tokamaks, the most successful being the T-3 and its larger version T-4. T-4 was tested in 1968 in Novosibirsk, producing the world's first quasistationary fusion reaction. When this were first announced, the international community was highly skeptical. A British team was invited to see T-3, however, and after measuring it in depth they released their results that confirmed the Soviet claims. A burst of activity followed as many planned devices were abandoned and new tokamaks were introduced in their place — the C model stellarator, then under construction after many redesigns, was quickly converted to the Symmetrical Tokamak.
In his work with vacuum tubes, Philo Farnsworth observed that electric charge would accumulate in regions of the tube. Today, this effect is known as the Multipactor effect. Farnsworth reasoned that if ions were concentrated high enough they could collide and fuse. In 1962, he filed a patent on a design using a positive inner cage to concentrate plasma, in order to achieve nuclear fusion. During this time, Robert L. Hirsch joined the Farnsworth Television labs and began work on what became the fusor. Hirsch patented the design in 1966 and published the design in 1967.
1970s.
In 1972, John Nuckolls outlined the idea of ignition. This is a fusion chain reaction. Hot helium made during fusion reheats the fuel and starts more reactions. John argued that ignition would require lasers of about 1 kJ. This turned out to be wrong. Nuckolls's paper started a major development effort. Several laser systems were built at LLNL. These included the argus, the Cyclops, the Janus, the long path, the Shiva laser and the Nova in 1984. This prompted the UK to build the Central Laser Facility in 1976.
During this time, great strides in understanding the tokamak system were made. A number of improvements to the design are now part of the "advanced tokamak" concept, which includes non-circular plasma, internal diverters and limiters, often superconducting magnets, and operate in the so-called "H-mode" island of increased stability. Two other designs have also become fairly well studied; the compact tokamak is wired with the magnets on the inside of the vacuum chamber, while the spherical tokamak reduces its cross section as much as possible.
In 1974 a study of the ZETA results demonstrated an interesting side-effect; after an experimental run ended, the plasma would enter a short period of stability. This led to the reversed field pinch concept, which has seen some level of development since. On May 1, 1974, the KMS fusion company (founded by Kip Siegel) achieves the world's first laser induced fusion in a deuterium-tritium pellet.
In the mid-1970s, Project PACER, carried out at Los Alamos National Laboratory (LANL) explored the possibility of a fusion power system that would involve exploding small hydrogen bombs (fusion bombs) inside an underground cavity. As an energy source, the system is the only fusion power system that could be demonstrated to work using existing technology. It would also require a large, continuous supply of nuclear bombs, however, making the economics of such a system rather questionable.
In 1976, the two beam Argus laser becomes operational at livermore. In 1977, The 20 beam Shiva laser at Livermore is completed, capable of delivering 10.2 kilojoules of infrared energy on target. At a price of $25 million and a size approaching that of a football field, Shiva is the first of the megalasers . That same year, the JET project is approved by the European Commission and a site is selected.
1980s.
As a result of advocacy, the cold war, and the 1970s energy crisis a massive magnetic mirror program was funded by the US federal government in the late 1970s and early 1980s. This program resulted in a series of large magnetic mirror devices including: 2X, Baseball I, Baseball II, the Tandem Mirror Experiment, the Tandem mirror experiment upgrade, the Mirror Fusion Test Facility and the MFTF-B. These machines were built and tested at Livermore from the late 1960s to the mid 1980s. A number of institutions collaborated on these machines, conducting experiments. These included the Institute for Advanced Study and the University of Wisconsin–Madison. The last machine, the Mirror Fusion Test Facility cost 372 million dollars and was, at that time, the most expensive project in Livermore history. It opened on February 21, 1986 and was promptly shut down. The reason given was to balance the United States federal budget. This program was supported from within the Carter and early Reagan administrations by Edwin E. Kintner, a US Navy captain, under Alvin Trivelpiece.
In Laser fusion progressed: in 1983, the NOVETTE laser was completed. The following December 1984, the ten beam NOVA laser was finished. Five years later, NOVA would produce a maximum of 120 kilojoules of infrared light, during a nanosecond pulse . Meanwhile, efforts focused on either fast delivery or beam smoothness. Both tried to deliver the energy uniformly to implode the target. One early problem was that the light in the infrared wavelength, lost lots of energy before hitting the fuel. Breakthroughs were made at the Laboratory for Laser Energetics at the University of Rochester. Rochester scientists used frequency-tripling crystals to transform the infrared laser beams into ultraviolet beams. In 1985, Donna Strickland and Gérard Mourou invented a method to amplify lasers pulses by "chirping". This method changes a single wavelength into a full spectrum. The system then amplifies the laser at each wavelength and then reconstitutes the beam into one color. Chirp pulsed amplification became instrumental in building the National Ignition Facility and the Omega EP system. Most research into ICF was towards weapons research, because the implosion is relevant to nuclear weapons.
During this time Los Alamos National Laboratory constructed a series of laser facilities. This included Gemini (a two beam system), Helios (eight beams), Antares (24 beams) and Aurora (96 beams). The program ended in the early nineties with a cost on the order of one billion dollars.
In 1987, Akira Hasegawa noticed that in a dipolar magnetic field, fluctuations tended compress the plasma without energy loss. This effect was noticed in data taken by Voyager 2, when it encountered Uranus. This observation would become the basis for a fusion approach known as the Levitated dipole.
In Tokamaks, the Tore Supra was under construction over the middle of the eighthies (1983 to 1988). This was a Tokamak built in Cadarache, France. In 1983, the JET was completed and first plasmas achieved. In 1985, the Japanese tokamak, JT-60 was completed. In 1988, the T-15 a Soviet tokamak was completed. It was the first industrial fusion reactor to use superconducting magnets to control the plasma. These were Helium cooled.
In 1989, Pons and Fleischmann submitted papers to the "Journal of Electroanalytical Chemistry" claiming that they had observed fusion in a room temperature device and disclosing their work in a press release. Some scientists reported excess heat, neutrons, tritium, helium and other nuclear effects in so-called cold fusion systems, which for a time gained interest as showing promise. Hopes fell when replication failures were weighed in view of several reasons cold fusion is not likely to occur, the discovery of possible sources of experimental error, and finally the discovery that Fleischmann and Pons had not actually detected nuclear reaction byproducts. By late 1989, most scientists considered cold fusion claims dead, and cold fusion subsequently gained a reputation as pathological science. However, a small community of researchers continues to investigate cold fusion claiming to replicate Fleishmann and Pons' results including nuclear reaction byproducts. Claims related to cold fusion are largely disbelieved in the mainstream scientific community. In 1989, the majority of a review panel organized by the US Department of Energy (DOE) found that the evidence for the discovery of a new nuclear process was not persuasive. A second DOE review, convened in 2004 to look at new research, reached conclusions similar to the first.
In 1984, Martin Peng of ORNL proposed an alternate arrangement of the magnet coils that would greatly reduce the aspect ratio while avoiding the erosion issues of the compact tokamak: a Spherical tokamak. Instead of wiring each magnet coil separately, he proposed using a single large conductor in the center, and wiring the magnets as half-rings off of this conductor. What was once a series of individual rings passing through the hole in the center of the reactor was reduced to a single post, allowing for aspect ratios as low as 1.2. The ST concept appeared to represent an enormous advance in tokamak design. However, it was being proposed during a period when US fusion research budgets were being dramatically scaled back. ORNL was provided with funds to develop a suitable central column built out of a high-strength copper alloy called "Glidcop". However, they were unable to secure funding to build a demonstration machine, "STX". Failing to build an ST at ORNL, Peng began a worldwide effort to interest other teams in the ST concept and get a test machine built. One way to do this quickly would be to convert a spheromak machine to the Spherical tokamak layout. Peng's advocacy also caught the interest of Derek Robinson, of the United Kingdom Atomic Energy Authority fusion center at Culham. Robinson was able to gather together a team and secure funding on the order of 100,000 pounds to build an experimental machine, the Small Tight Aspect Ratio Tokamak, or START. Several parts of the machine were recycled from earlier projects, while others were loaned from other labs, including a 40 keV neutral beam injector from ORNL. Construction of START began in 1990, it was assembled rapidly and started operation in January 1991.
1990s.
In 1991 the Preliminary Tritium Experiment at the Joint European Torus in England achieved the world’s first controlled release of fusion power.
In 1992, a major article was published in Physics Today by Robert McCory at the Laboratory for laser energetics outlying the current state of ICF and advocating for a national ignition facility. This was followed up by a major review article, from John Lindl in 1995, advocating for NIF. During this time a number of ICF subsystems were developing, including target manufacturing, cryogenic handling systems, new laser designs (notably the NIKE laser at NRL) and improved diagnostics like time of flight analyzers and Thomson scattering. This work was done at the NOVA laser system, General Atomics, Laser Mégajoule and the GEKKO XII system in Japan. Through this work and lobbying by groups like the fusion power associates and John Sethian at NRL, a vote was made in congress, authorizing funding for the NIF project in the late nineties.
In the early nineties, theory and experimental work regarding fusors and polywells was published. In response, Todd Rider at MIT developed general models of these devices. Rider argued that all plasma systems at thermodynamic equilibrium were fundamentally limited. In 1995, William Nevins published a criticism arguing that the particles inside fusors and polywells would build up angular momentum, causing the dense core to degrade.
In 1995, the University of Wisconsin–Madison built a large fusor, known as HOMER, which is still in operation. Meanwhile, Dr George H. Miley at Illinois, built a small fusor that has produced neutrons using deuterium gas and discovered the "star mode" of fusor operation. The following year, the first "US-Japan Workshop on IEC Fusion", was conducted. At this time in Europe, an IEC device was developed as a commercial neutron source by Daimler-Chrysler and NSD Fusion.
In 1996, the Z-machine was upgraded and opened to the public by the US Army in August 1998 in Scientific American. The key attributes of Sandia’s Z machine are its 18 million amperes and a discharge time of less than 100 nanoseconds. This generates a magnetic pulse, inside a large oil tank, this strikes an array of tungsten wires called a "liner". Firing the Z-machine has become a way to test very high energy, high temperature (2 billion degrees) conditions. In 1996, the Tore Supra creates a plasma for two minutes with a current of almost 1 million amperes driven non-inductively by 2.3 MW of lower hybrid frequency waves. This is 280 MJ of injected and extracted energy. This result was possible due to the actively cooled plasma-facing components 
In 1997, JET produced a peak of 16.1MW of fusion power (65% of input power), with fusion power of over 10MW sustained for over 0.5 sec. Its successor, the International Thermonuclear Experimental Reactor (ITER), was officially announced as part of a seven-party consortium (six countries and the EU). ITER is designed to produce ten times more fusion power than the power put into the plasma. ITER is currently under construction in Cadarache, France.
In the late nineties, a team at Columbia University and MIT developed the Levitated dipole a fusion device which consisted of a superconducting electromagnet, floating in a saucer shaped vacuum chamber. Plasma swirled around this donut and fused along the center axis.
2000s.
In the March 8, 2002 issue of the peer-reviewed journal "Science", Rusi P. Taleyarkhan and colleagues at the Oak Ridge National Laboratory (ORNL) reported that acoustic cavitation experiments conducted with deuterated acetone (C3D6O) showed measurements of tritium and neutron output consistent with the occurrence of fusion. Taleyarkhan was later found guilty of misconduct, the Office of Naval Research debarred him for 28 months from receiving Federal Funding, and his name was listed in the 'Excluded Parties List'.
"Fast ignition" was developed in the late nineties, and was part of a push by the Laboratory for Laser Energetics for building the Omega EP system. This system was finished in 2008. Fast ignition showed such dramatic power savings that ICF appears to be a useful technique for energy production. There are even proposals to build an experimental facility dedicated to the fast ignition approach, known as HiPER.
In April 2005, a team from UCLA announced it had devised a way of producing fusion using a machine that "fits on a lab bench", using lithium tantalate to generate enough voltage to smash deuterium atoms together. The process, however, does not generate net power (see Pyroelectric fusion). Such a device would be useful in the same sort of roles as the fusor. In 2006, China's EAST test reactor is completed. This was the first tokamak to use superconducting magnets to generate both the toroidal and poloidal fields.
In the early 2000s, Researchers at LANL reasoned that a plasma oscillating could be at local thermodynamic equilibrium. This prompted the POPS and Penning trap designs. At this time, researchers at MIT became interested in fusors for space propulsion and powering space vehicles. Specifically, researchers developed fusors with multiple inner cages. Greg Piefer graduated from Madison and founded Phoenix Nuclear Labs, a company that developed the fusor into a neutron source for the mass production of medical isotopes. Robert Bussard began speaking openly about the Polywell in 2006. He attempted to generate interest in the research, before his death. In 2008, Taylor Wilson achieved notoriety for achieving nuclear fusion at 14, with a homemade fusor.
In 2009, a high-energy laser system, the National Ignition Facility (NIF), was finished in the US, which can heat hydrogen atoms to temperatures only existing in nature in the cores of stars. The new laser is expected to have the ability to produce, for the first time, more energy from controlled, inertially confined nuclear fusion than was required to initiate the reaction.
2010s.
In 2010, NIF researchers were conducting a series of "tuning" shots to determine the optimal target design and laser parameters for high-energy ignition experiments with fusion fuel in the following months. Two firing tests were performed on 31 October 2010 and 2 November 2010. In early 2012, NIF director Mike Dunne expected the laser system to generate fusion with net energy gain by the end of 2012. Nonetheless, it was not achieved by that date due to delays.
Inertial (laser) confinement is being developed at the United States National Ignition Facility (NIF) based at Lawrence Livermore National Laboratory in California, the French Laser Mégajoule, and the planned European Union High Power laser Energy Research (HiPER) facility. NIF reached initial operational status in 2010 and has been in the process of increasing the power and energy of its "shots", with fusion ignition tests to follow. A three-year goal announced in 2009 to produce net energy from fusion by 2012 was missed; in September 2013, however, the facility announced a significant milestone from an August 2013 test that produced more energy from the fusion reaction than had been provided to the fuel pellet. This was reported as the first time this had been accomplished in fusion power research. The facility reported that their next step involved improving the system to prevent the hohlraum breaking up asymmetrically or too soon.
A 2012 paper demonstrated that a dense plasma focus had achieved temperatures of 1.8 billion degrees C, sufficient for boron fusion, and that fusion reactions were occurring primarily within the contained plasmoid, a necessary condition for net power. The focus consists of two coaxial cylindrical electrodes made from copper or beryllium and housed in a vacuum chamber containing a low-pressure fusible gas. An electrical pulse is applied across the electrodes, heating the gas into a plasma. The current forms into a minuscule vortex along the axis of the machine, which then kinks into a cage of current with an associated magnetic field. The cage of current and magnetic field entrapped plasma is called a plasmoid. The acceleration of the electrons about the magnetic field lines heats the nuclei within the plasmoid to fusion temperatures.
In September 2013 the NIF was widely acclaimed to have achieved a milestone in controlled fusion, by successfully initiating a reaction that resulted in the release of more energy than the fuel absorbed — even if only for a fraction of a second. However, it was still far short of creating a self-sustaining reaction. The process will need to be made more efficient to yield commercially viable amounts of energy.
In April 2014, Lawrence Livermore National Laboratory ended the Laser Inertial Fusion Energy (LIFE) program and redirected their efforts towards NIF. In August 2014, Phoenix Nuclear Labs announced the sale of a high yield neutron generator. Costing on the order of a millions, this device could sustain 5E+11 deuterium fusion reactions per second over a 24-hour period. In October 2014, Lockheed Martin's Skunk Works announced the development of a high beta fusion reactor they expect to yield a functioning 100 megawatt prototype by 2017 and to be ready for regular operation by 2022.
Deep space exploration as well as higher-velocity lower-cost space transport services in general would be enabled by this compact fusion reactor technology.
In January 2015, the polywell was presented at Microsoft Research.
Fuels.
By firing particle beams at targets, many fusion reactions have been tested, while the fuels considered for power have all been light elements like the isotopes of hydrogen—deuterium and tritium. Other reactions like the deuterium and Helium3 reaction or the Helium3 and Helium3 reactions, would require a supply of Helium3. This can either come from other nuclear reactions or from extraterrestrial sources. Finally, researchers hope to do the p-11B reaction, because it does not directly produce neutrons, though side reactions can.
Deuterium, tritium.
The easiest nuclear reaction, at the lowest energy, is:
This reaction is common in research, industrial and military applications, usually as a convenient source of neutrons. Deuterium is a naturally occurring isotope of hydrogen and is commonly available. The large mass ratio of the hydrogen isotopes makes their separation easy compared to the difficult uranium enrichment process. Tritium is a natural isotope of hydrogen, but due to its short half-life of 12.32 years, is hard to find, store, produce, and is expensive. Consequently, the deuterium-tritium fuel cycle requires the breeding of tritium from lithium using one of the following reactions:
The reactant neutron is supplied by the D-T fusion reaction shown above, and the one that has the greatest yield of energy. The reaction with 6Li is exothermic, providing a small energy gain for the reactor. The reaction with 7Li is endothermic but does not consume the neutron. At least some 7Li reactions are required to replace the neutrons lost to absorption by other elements. Most reactor designs use the naturally occurring mix of lithium isotopes.
Several drawbacks are commonly attributed to D-T fusion power:
The neutron flux expected in a commercial D-T fusion reactor is about 100 times that of current fission power reactors, posing problems for material design. After a series of D-T tests at JET, the vacuum vessel was sufficiently radioactive that remote handling was required for the year following the tests.
In a production setting, the neutrons would be used to react with lithium in order to create more tritium. This also deposits the energy of the neutrons in the lithium, which would then be transferred to drive electrical production. The lithium neutron absorption reaction protects the outer portions of the reactor from the neutron flux. Newer designs, the advanced tokamak in particular, also use lithium inside the reactor core as a key element of the design. The plasma interacts directly with the lithium, preventing a problem known as "recycling". The advantage of this design was demonstrated in the Lithium Tokamak Experiment.
Deuterium,.
This fuel is commonly used by amateurs who fuse. This is second easiest fusion reaction, fusing of deuterium with itself. This reaction has two branches that occur with nearly equal probability:
This reaction is also common in research. The optimum energy to initiate this reaction is 15 keV, only slightly higher than the optimum for the D-T reaction. The first branch does not produce neutrons, but it does produce tritium, so that a D-D reactor will not be completely tritium-free, even though it does not require an input of tritium or lithium. Unless the tritons can be quickly removed, most of the tritium produced would be burned before leaving the reactor, which would reduce the handling of tritium, but would produce more neutrons, some of which are very energetic. The neutron from the second branch has an energy of only 2.45 MeV, whereas the neutron from the D-T reaction has an energy of 14.1 MeV, resulting in a wider range of isotope production and material damage. When the tritons are removed quickly while allowing the 3He to react, the fuel cycle is called "tritium suppressed fusion" The removed tritium decays to 3He with a 12.5 year half life. By recycling the 3He produced from the decay of tritium back into the fusion reactor, the fusion reactor does not require materials resistant to fast 14.1 MeV neutrons.
Assuming complete tritium burn-up, the reduction in the fraction of fusion energy carried by neutrons would be only about 18%, so that the primary advantage of the D-D fuel cycle is that tritium breeding would not be required. Other advantages are independence from scarce lithium resources and a somewhat softer neutron spectrum. The disadvantage of D-D compared to D-T is that the energy confinement time (at a given pressure) must be 30 times longer and the power produced (at a given pressure and volume) would be 68 times less .
Assuming complete removal of tritium and recycling of 3He, only 6% of the fusion energy is carried by neutrons. The tritium-suppressed D-D fusion requires an energy confinement that is 10 times longer compared to D-T and a plasma temperature that is twice as high.
Deuterium, helium 3.
A second-generation approach to controlled fusion power involves combining helium-3 (3He) and deuterium (2H):
This reaction produces a helium-4 nucleus (4He) and a high-energy proton. As with the p-11B aneutronic fusion fuel cycle, most of the reaction energy is released as charged particles, reducing activation of the reactor housing and potentially allowing more efficient energy harvesting (via any of several speculative technologies). In practice, D-D side reactions produce a significant number of neutrons, resulting in p-11B being the preferred cycle for aneutronic fusion.
Proton, boron 11.
If aneutronic fusion is the goal, then the most promising candidate may be the Hydrogen-1 (proton)/boron reaction, which releases alpha (helium) particles, but does not rely on neutron scattering for energy transfer.
Under reasonable assumptions, side reactions will result in about 0.1% of the fusion power being carried by neutrons. At 123 keV, the optimum temperature for this reaction is nearly ten times higher than that for the pure hydrogen reactions, the energy confinement must be 500 times better than that required for the D-T reaction, and the power density will be 2500 times lower than for D-T.
Since the confinement properties of conventional approaches to fusion such as the tokamak and laser pellet fusion are marginal, most proposals for aneutronic fusion are based on radically different confinement concepts, such as the Polywell and the Dense Plasma Focus. Results have been extremely promising:
Material selection.
Considerations.
Any power plant using hot plasma, is going to have plasma facing walls. In even the simplest plasma approaches, the material will get blasted with matter and energy. This leads to a minimum list of considerations, including dealing with:
Depending on the approach, these effects may be higher or lower than typical fission reactors like the pressurized water reactor (PWR). One estimate put the radiation at 100 times the (PWR). Materials need to be selected or developed that can withstand these basic conditions. Depending on the approach, however, there may be other considerations such as Electrical conductivity, magnetic permeability and mechanical strength. There is also a need for materials whose primary components and impurities do not result in long-lived radioactive wastes.
Durability.
For long term use, each atom in the wall is expected to be hit by a neutron and displaced about a hundred times before the material is replaced. High-energy neutrons will produce hydrogen and helium by way of various nuclear reactions that tends to form bubbles at grain boundaries and result in swelling, blistering or embrittlement.
Selection.
One can choose either a low-Z material, such as graphite or beryllium, or a high-Z material, usually tungsten with molybdenum as a second choice. Use of liquid metals (lithium, gallium, tin) has also been proposed, e.g., by injection of 1–5 mm thick streams flowing at 10 m/s on solid substrates.
If graphite is used, the gross erosion rates due to physical and chemical sputtering would be many meters per year, so one must rely on redeposition of the sputtered material. The location of the redeposition will not exactly coincide with the location of the sputtering, so one is still left with erosion rates that may be prohibitive. An even larger problem is the tritium co-deposited with the redeposited graphite. The tritium inventory in graphite layers and dust in a reactor could quickly build up to many kilograms, representing a waste of resources and a serious radiological hazard in case of an accident. The consensus of the fusion community seems to be that graphite, although a very attractive material for fusion experiments, cannot be the primary PFC material in a commercial reactor.
The sputtering rate of tungsten by the plasma fuel ions is orders of magnitude smaller than that of carbon, and tritium is much less incorporated into redeposited tungsten, making this a more attractive choice. On the other hand, tungsten impurities in a plasma are much more damaging than carbon impurities, and self-sputtering of tungsten can be high, so it will be necessary to ensure that the plasma in contact with the tungsten is not too hot (a few tens of eV rather than hundreds of eV). Tungsten also has disadvantages in terms of eddy currents and melting in off-normal events, as well as some radiological issues.
Safety and the environment.
Nuclear island.
A fusion power plant may be designed with a nuclear island and the balance of plant. This is common in typical fission reactors. The nuclear island has a plasma chamber with an associated vacuum system, surrounded by plasma-facing components (first wall and divertor) maintaining the vacuum and absorbing the heat coming from the plasma. If magnetic confinement is used, a magnet system made from superconducting magnets will be needed, as well as systems for heating and refueling the plasma. If inertial confinement is used, it will require a driver (laser or accelerator) and a focusing system, as well as place to manufacture and position the target. The balance of plant converts heat into electricity via steam turbines.
Accident potential.
There is no possibility of a catastrophic accident in a fusion reactor resulting in major release of radioactivity to the environment or injury to non-staff, unlike modern fission reactors. The primary reason is that the requirements for nuclear fusion differ greatly from nuclear fission: fusion requires extremely precise and controlled temperature, pressure, and magnetic field parameters for any net energy to be produced, and a far smaller amount of fuel. If the reactor suffered damage or lost even a small degree of required control, fusion reactions and heat generation would rapidly cease.
Therefore fusion reactors are considered extremely safe in this sense, making them favorable over fission reactors, which, in contrast, continue to generate heat through beta-decay for several months after reactor shut-down, meaning that melting of fuel rods is possible even after the reactor has been stopped due to continued accumulation of heat.
There is also no risk of a runaway reaction in a fusion reactor. The plasma is burnt at optimal conditions, and any significant change will render it unable to react or to produce excess heat. In fusion reactors the reaction process is so delicate that this level of safety is inherent; no elaborate failsafe mechanism is required. Although the plasma in a fusion power plant will have a volume of 1000 cubic meters or more, the density of the plasma is extremely low, and the total amount of fusion fuel in the vessel is very small, typically a few grams. If the fuel supply is closed, the reaction stops within seconds. In comparison, a fission reactor is typically loaded with enough fuel for several years, and no additional fuel is necessary to keep the reaction going.
In the magnetic approach, strong fields are developed in coils that are held in place mechanically by the reactor structure. Failure of this structure could release this tension and allow the magnet to "explode" outward. The severity of this event would be similar to any other industrial accident or an MRI machine quench/explosion, and could be effectively stopped with a containment building similar to those used in existing (fission) nuclear generators. The laser-driven inertial approach is generally lower-stress. Although failure of the reaction chamber is possible, simply stopping fuel delivery would prevent any sort of catastrophic failure.
Most reactor designs rely on the use of liquid lithium as both a coolant and a method for converting stray neutrons from the reaction into tritium, which is fed back into the reactor as fuel. Lithium is highly flammable, and in the case of a fire it is possible that the lithium stored on-site could be burned up and escape. In this case, the tritium contents of the lithium would be released into the atmosphere, posing a radiation risk. Calculations suggest that at about 1 kg the total amount of tritium and other radioactive gases in a typical power plant would be so small that they would have diluted to legally acceptable limits by the time they blew as far as the plant's perimeter fence.
The likelihood of "small industrial" accidents including the local release of radioactivity and injury to staff cannot be estimated yet. These would include accidental releases of lithium, tritium, or mis-handling of decommissioned radioactive components of the reactor itself.
Effluents during normal operation.
The natural product of the fusion reaction is a small amount of helium, which is completely harmless to life. Of more concern is tritium, which, like other isotopes of hydrogen, is difficult to retain completely. During normal operation, some amount of tritium will be continually released. There would be no acute danger, but the cumulative effect on the world's population from a fusion economy could be a matter of concern.
Although tritium is volatile and biologically active the health risk posed by a release is much lower than that of most radioactive contaminants, due to tritium's short half-life (12.32 years), very low decay energy (~14.95 keV), and the fact that it does not bioaccumulate (instead being cycled out of the body as water, with a biological half-life of 7 to 14 days). Current ITER designs are investigating total containment facilities for any tritium.
Waste management.
The large flux of high-energy neutrons in a reactor will make the structural materials radioactive. The radioactive inventory at shut-down may be comparable to that of a fission reactor, but there are important differences.
The half-life of the radioisotopes produced by fusion tends to be less than those from fission, so that the inventory decreases more rapidly. Unlike fission reactors, whose waste remains radioactive for thousands of years, most of the radioactive material in a fusion reactor would be the reactor core itself, which would be dangerous for about 50 years, and low-level waste another 100. Although this waste will be considerably more radioactive during those 50 years than fission waste, the very short half-life makes the process very attractive, as the waste management is fairly straightforward. By 500 years the material would have the same radiotoxidity as coal ash.
Additionally, the choice of materials used in a fusion reactor is less constrained than in a fission design, where many materials are required for their specific neutron cross-sections. This allows a fusion reactor to be designed using materials that are selected specifically to be "low activation", materials that do not easily become radioactive. Vanadium, for example, would become much less radioactive than stainless steel. Carbon fiber materials are also low-activation, as well as being strong and light, and are a promising area of study for laser-inertial reactors where a magnetic field is not required.
In general terms, fusion reactors would create far less radioactive material than a fission reactor, the material it would create is less damaging biologically, and the radioactivity "burns off" within a time period that is well within existing engineering capabilities for safe long-term waste storage.
Nuclear proliferation.
Although fusion power uses nuclear technology, the overlap with nuclear weapons would be limited. A huge amount of tritium could be produced by a fusion power plant. Tritium is used in the trigger of hydrogen bombs and in a modern boosted fission weapon. But tritium can be also produced by nuclear fission. The energetic neutrons from a fusion reactor could be used to breed weapons-grade plutonium or uranium for an atomic bomb (for example by transmutation of U238 to Pu239, or Th232 to U233).
A study conducted 2011 assessed the risk of three scenarios:
Another study concludes that "[..]large fusion reactors – even if not designed for fissile material breeding – could easily produce several hundred kg Pu per year with high weapon quality and very low source material requirements." It was emphasized that the implementation of features for intrinsic proliferation resistance might only be possible at this phase of research and development. The theoretical and computational tools needed for hydrogen bomb design are closely related to those needed for inertial confinement fusion, but have very little in common with the more scientifically developed magnetic confinement fusion.
As a sustainable energy source.
Large-scale reactors using neutronic fuels (e.g. ITER) and thermal power production (turbine based) are most comparable to fission power from an engineering and economics viewpoint. Both fission and fusion power plants involve a relatively compact heat source powering a conventional steam turbine-based power plant, while producing enough neutron radiation to make activation of the plant materials problematic. The main distinction is that fusion power produces no high-level radioactive waste (though activated plant materials still need to be disposed of). There are some power plant ideas that may significantly lower the cost or size of such plants; however, research in these areas is nowhere near as advanced as in tokamaks.
Fusion power commonly proposes the use of deuterium, an isotope of hydrogen, as fuel and in many current designs also use lithium. Assuming a fusion energy output equal to the 1995 global power output of about 100 EJ/yr (= 1 × 1020 J/yr) and that this does not increase in the future, which is unlikely, then the known current lithium reserves would last 3000 years. Lithium from sea water would last 60 million years, however, and a more complicated fusion process using only deuterium from sea water would have fuel for 150 billion years. To put this in context, 150 billion years is close to 30 times the remaining lifespan of the sun, and more than 10 times the estimated age of the universe.
Economics.
While fusion power is still in early stages of development, substantial sums have been and continue to be invested in research. In the EU almost €10 billion was spent on fusion research up to the end of the 1990s, and the new ITER reactor alone is budgeted at €6.6 billion total for the timeframe between 2008 and 2020.
It is estimated that up to the point of possible implementation of electricity generation by nuclear fusion, R&D will need further promotion totalling around €60–80 billion over a period of 50 years or so (of which €20–30 billion within the EU) based on a report from 2002. Nuclear fusion research receives €750 million (excluding ITER funding) from the European Union, compared with €810 million for sustainable energy research, putting research into fusion power well ahead of that of any single rivaling technology. Indeed, the size of the investments and time frame of the expected results mean that fusion research is almost exclusively publicly funded, while research in other forms of energy can be done by the private sector.
Advantages.
Fusion power would provide more energy for a given weight of fuel than any fuel-consuming energy source currently in use, and the fuel itself (primarily deuterium) exists abundantly in the Earth's ocean: about 1 in 6500 hydrogen atoms in seawater is deuterium. Although this may seem a low proportion (about 0.015%), because nuclear fusion reactions are so much more energetic than chemical combustion and seawater is easier to access and more plentiful than fossil fuels, fusion could potentially supply the world's energy needs for millions of years.
Despite being technically non-renewable, fusion power has many of the benefits of renewable energy sources (such as being a long-term energy supply and emitting no greenhouse gases) as well as some of the benefits of the resource-limited energy sources as hydrocarbons and nuclear fission (without reprocessing). Like these currently dominant energy sources, fusion could provide very high power-generation density and uninterrupted power delivery (due to the fact that it is not dependent on the weather, unlike wind and solar power).
Another aspect of fusion energy is that the cost of production does not suffer from diseconomies of scale. The cost of water and wind energy, for example, goes up as the optimal locations are developed first, while further generators must be sited in less ideal conditions. With fusion energy the production cost will not increase much even if large numbers of plants are built, because the raw resource (seawater) is abundant and widespread.
Some problems that are expected to be an issue in this century, such as fresh water shortages, can alternatively be regarded as problems of energy supply. For example, in desalination plants, seawater can be purified through distillation or reverse osmosis. Nonetheless, these processes are energy intensive. Even if the first fusion plants are not competitive with alternative sources, fusion could still become competitive if large-scale desalination requires more power than the alternatives are able to provide.
A scenario has been presented of the effect of the commercialization of fusion power on the future of human civilization. ITER and later Demo are envisioned to bring online the first commercial nuclear fusion energy reactor by 2050. Using this as the starting point and the history of the uptake of nuclear fission reactors as a guide, the scenario depicts a rapid take up of nuclear fusion energy starting after the middle of this century.
Fusion power could be used in interstellar space, where solar energy is not available.

</doc>
<doc id="55020" url="http://en.wikipedia.org/wiki?curid=55020" title="Jin dynasty (265–420)">
Jin dynasty (265–420)

The Jin dynasty (, ];) was a dynasty in Chinese history, lasting between the years 265 and 420 AD. There are two main divisions in the history of the dynasty, the first being Western Jin (西晉, 265–316) and the second Eastern Jin (東晉, 317–420). Western Jin was founded by Sima Yan, with its capital at Luoyang, while Eastern Jin was begun by Sima Rui, with its capital at Jiankang. The two periods are also known as "Liang Jin" (兩晉; literally: two Jin) and "Sima Jin" (司馬晉) by scholars, to distinguish this dynasty from other dynasties that use the same Chinese character, such as the Later Jin dynasty (後晉).
Foundation.
The Sima clan was initially subordinate to the Wei dynasty, but the clan's influence and power grew greatly after the incident at Gaoping tombs in 249. In 263, Sima Zhao unified the lands of Shu and captured Liu Shan. In 264, Zhong Hui rebelled against Sima Zhao. In 265, Sima Yan forced emperor Cao Huan of Wei to abdicate the throne to him, ending Wei and starting Jin (as Emperor Wu). He named his dynasty after the state of Jin of the Spring and Autumn Period that once ruled the Sima clan's home county of Wen in Henei (present day Wen County, Henan). In 280, the Jin conquered Eastern Wu and unified China, but internal conflicts, corruption and political turmoil quickly weakened the dynasty, and the unification lasted only ten years. Upon the advent of the second Jin emperor, Emperor Hui, various imperial princes tried to grab power in the devastating War of the Eight Princes. The Wu Hu uprising followed, during which large numbers of refugees fled south while the north was occupied by various nomadic groups. This marked the end of the Western Jin dynasty in 316 when the Jin court evacuated to the region south of the Huai River, and the beginning of the Eastern Jin and the Sixteen Kingdoms period.
Sima Rui founded the Eastern Jin at Jiankang in 317, with its territory stretching across most of today's southern China. The combination of the Eastern Jin and Sixteen Kingdoms period is sometimes called the, "Eastern Jin Sixteen Kingdoms" (東晉十六國). During this period, huge numbers of people moved south from the central plain, stimulating the development of Southern China. The Emperors of Eastern Jin had limited power, owing to their dependence on the support of both local and refugee noble families which possessed military power. These families included the Wang family, including the chancellor Wang Dao, and the Xie family of Xie An and Xie Xuan. Many fangzhen (方鎮; literally: military county) started to have ambitions which resulted in military revolts, like the rebellions of Wang Dun, Su Jun, and the dictatorship of Huan Wen. Even though there was the stated goal of getting back the "northern lost lands", paranoia within the royal family and a constant string of disruptions to the throne caused the loss of support of many officials.
In 383, Former Qin mobilized its troops and intended to conquer Eastern Jin. Faced by the threat of invasion, many Jin officials cooperated hoping to repel the attack. After the battle of Fei river, Xie An, Xie Xuan, and other generals were able to push back the Qin's assault and seized back a huge amount of territory from their enemy. However, more internal political battles from different groups of officials followed Huan Xuan's usurpation of the throne. As civilian administration suffered, more revolts from , , and the declaration of a new kingdom called Western Shu by the militarist Qiao zong in Eastern Jin's Shu region. Ultimately, Liu Yu's rise ended major chaos and later he took the throne for himself, marking the ending of the Jin dynasty and the start of the Liu Song dynasty, and the Southern and Northern Dynasties period of Chinese history.
History.
The Western Jin dynasty (西晉, 265–316) was founded by Emperor Wu, better known as Sima Yan. Although it provided a brief period of unity after conquering Eastern Wu in 280, the Jin suffered a devastating civil war, War of the Eight Princes, after which they could not contain the revolt of nomadic tribes known as the Wu Hu. The capital, Luoyang was captured in 311, and Emperor Huai was captured. His successor, Emperor Min was also captured in Chang'an in 316.
The remnants of the Jin court fled to the east and reestablished the government at Jiankang, near modern-day Nanjing, under a member of the royal family named the Prince of Langye. The prince was proclaimed the Emperor Yuan of the Eastern Jin dynasty (東晉, 317–420) when news of the fall of Chang'an reached the south. (The rival Wu Hu states in the north, which did not recognize the legitimacy of Jin, would sometimes refer to it as "Langye".)
Military crises, such as the rebellions of generals Wang Dun and Su Jun, plagued the Eastern Jin throughout its 104 years of existence. However, the Battle of Fei River turned out to be a major Jin victory, due to the short-lived cooperation of Huan Chong, brother of a great general Huan Wen, and Prime Minister Xie An. Later, Huan Xuan, son of Huan Wen, usurped the throne and changed the dynasty's name to Chu. He, in turn, was toppled by Liu Yu, who after reinstating Emperor An, ordered him strangled and installed his brother, Emperor Gong, in 419.
Emperor Gong abdicated in 420 in favor of Liu Yu, ushering in the Liu Song dynasty the first of the Southern dynasties. The Jin Dynasty thus came to an end.
Meanwhile, North China was ruled by the Sixteen Kingdoms, many of which were founded by the Wu Hu. The last of these, Northern Liang, was conquered by the Northern Wei dynasty in 439, ushering in the Northern dynasties period.
Jin ceramics.
The Jin dynasty is well known for the quality of its greenish celadon porcelain wares, which immediately followed the development of proto-celadon. Jar designs often incorporated animal, as well as Buddhist, figures.
Examples of Yue ware are also known from the Jin dynasty.
Imperial Family.
Sima Fei 司馬朏 was a descendant of Jin dynasty royalty who fled north to the Xianbei Northern Wei in exile and married the Xianbei Princes Huayang 華陽公主, the daughter of Emperor Xiaowen of Northern Wei.
The Song dynasty chancellor Sima Guang (1019–1086) was descended from the Jin Imperial family.

</doc>
<doc id="55021" url="http://en.wikipedia.org/wiki?curid=55021" title="Josquin des Prez">
Josquin des Prez

Josquin des Prez (]; c. 1450/1455 – 27 August 1521), often referred to simply as Josquin, was a Franco-Flemish composer of the Renaissance. His original name is sometimes given as Josquin Lebloitte and his later name is given under a wide variety of spellings in French, Italian, and Latin, including Josquinus Pratensis and Jodocus a Prato. His motet "Illibata Dei virgo nutrix" includes an acrostic of his name, where he spelled it "Josquin des Prez". He was the most famous European composer between Guillaume Dufay and Palestrina, and is usually considered to be the central figure of the Franco-Flemish School. Josquin is widely considered by music scholars to be the first master of the high Renaissance style of polyphonic vocal music that was emerging during his lifetime.
During the 16th century, Josquin gradually acquired the reputation as the greatest composer of the age, his mastery of technique and expression universally imitated and admired. Writers as diverse as Baldassare Castiglione and Martin Luther wrote about his reputation and fame; theorists such as Heinrich Glarean and Gioseffo Zarlino held his style as that best representing perfection. He was so admired that many anonymous compositions were attributed to him by copyists, probably to increase their sales. More than 370 works are attributed to him; it was only after the advent of modern analytical scholarship that some of these mistaken attributions have been challenged, on the basis of stylistic features and manuscript evidence. Yet in spite of Josquin's colossal reputation, which endured until the beginning of the Baroque era and was revived in the 20th century, his biography is shadowy, and next to nothing is known about his personality. The only surviving work which may be in his own hand is a graffito on the wall of the Sistine Chapel, and only one contemporary mention of his character is known, in a letter to Duke Ercole I of Ferrara. The lives of dozens of minor composers of the Renaissance are better documented than the life of Josquin.
Josquin wrote both sacred and secular music, and in all of the significant vocal forms of the age, including masses, motets, chansons and frottole. During the 16th century, he was praised for both his supreme melodic gift and his use of ingenious technical devices. In modern times, scholars have attempted to ascertain the basic details of his biography, and have tried to define the key characteristics of his style to correct misattributions, a task that has proved difficult, as Josquin liked to solve compositional problems in different ways in successive compositions—sometimes he wrote in an austere style devoid of ornamentation, and at other times he wrote music requiring considerable virtuosity. Heinrich Glarean wrote in 1547 that Josquin was not only a "magnificent virtuoso" (the Latin can be translated also as "show-off") but capable of being a "mocker", using satire effectively. While the focus of scholarship in recent years has been to remove music from the "Josquin canon" (including some of his most famous pieces) and to reattribute it to his contemporaries, the remaining music represents some of the most famous and enduring of the Renaissance.
Life.
Birth and early career.
Little is known for certain of Josquin's early life. Much is inferential and speculative, though numerous clues have emerged from his works and the writings of contemporary composers, theorists, and writers of the next several generations. Josquin was born in the area controlled by the Dukes of Burgundy, and was possibly born either in Hainaut (modern-day Belgium), or immediately across the border in modern-day France, since several times in his life he was classified legally as a Frenchman (for instance, when he made his will). Josquin was long mistaken for a man with a similar name, Josquin de Kessalia, born around the year 1440, who sang in Milan from 1459 to 1474, dying in 1498. More recent scholarship has shown that Josquin des Prez was born around 1450 or a few years later, and did not go to Italy until the early 1480s.
Around 1466, perhaps on the death of his father, Josquin was named by his uncle and aunt, Gille Lebloitte dit Desprez and Jacque Banestonne, as their heir. Their will gives Josquin's actual surname as Lebloitte. According to Matthews and Merkley, "des Prez" was a nickname.
According to an account by Claude Hémeré, a friend and librarian of Cardinal Richelieu whose evidence dates as late as 1633, and who used the records of the collegiate church of Saint-Quentin, Josquin became a choirboy with his friend and colleague the Franco Flemish composer Jean Mouton at Saint-Quentin's royal church, probably around 1460. Doubt has been cast on the accuracy of Hémeré's account, however. He may have studied counterpoint under Ockeghem, whom he greatly admired throughout his life: this is suggested both by the testimony of Gioseffo Zarlino and Lodovico Zacconi, writing later in the 16th century, and by Josquin's eloquent lament on the death of Ockeghem in 1497, "Nymphes des bois/Requiem aeternam", based on the poem by Jean Molinet. All records from Saint-Quentin were destroyed in 1669; however the collegiate chapel there was a center of music-making for the entire area, and in addition was an important center of royal patronage. Both Jean Mouton and Loyset Compère were buried there and it is certainly possible that Josquin acquired his later connections with the French royal chapel through early experiences at Saint-Quentin.
The first definite record of his employment is dated 19 April 1477, and it shows that he was a singer at the chapel of René, Duke of Anjou, in Aix-en-Provence. He remained there at least until 1478. No certain records of his movements exist for the period from March 1478 until 1483, but if he remained in the employ of René he would have transferred to Paris in 1481 along with the rest of the chapel. One of Josquin's early motets, "Misericordias Domini in aeternum cantabo", suggests a direct connection with Louis XI, who was king during this time. In 1483 Josquin returned to Condé to claim his inheritance from his aunt and uncle, who may have been killed by the army of Louis XI in May 1478, when they besieged the town, locked the population into the church, and burned them alive.
Milan.
The period of 1480 to 1482 has puzzled biographers: some contradictory evidence exists, suggesting either that Josquin was still in France, or was already in the service of the Sforza family, specifically with Ascanio Sforza, who had been banished from Milan and resided temporarily in Ferrara or Naples. Residence in Ferrara in the early 1480s could explain the "Missa Hercules dux Ferrariae", composed for Ercole d'Este, but which stylistically does not fit with the usual date of 1503–4 when Josquin was known to be in Ferrara. Alternatively it has been suggested that Josquin spent some of that time in Hungary, based on a mid-16th-century Roman document describing the Hungarian court in those years, and including Josquin as one of the musicians present.
In either 1483 or 1484 Josquin is known to have been in the service of the Sforza family in Milan. While in their employ, he made one or more trips to Rome, and possibly also to Paris; while in Milan he made the acquaintance of Franchinus Gaffurius, who was "maestro di cappella" of the cathedral there. He was in Milan again in 1489, after a possible period of travel; but he left that year.
Rome.
From 1489 to 1495 Josquin was a member of the papal choir, first under Pope Innocent VIII, and later under the Borgia pope Alexander VI. He may have gone there as part of a singer exchange with Gaspar van Weerbeke, who went back to Milan at the same time. While there, he may have been the one who carved his name into the wall of the Sistine Chapel; a "JOSQUINJ" was recently revealed by workers restoring the chapel. Since it was traditional for singers to carve their names into the walls, and hundreds of names were inscribed there during the period from the 15th to the 18th centuries, it is considered highly likely that the graffiti is by Josquin – and if so, it would be his only surviving autograph.
Josquin's mature style evolved during this period; as in Milan he had absorbed the influence of light Italian secular music, in Rome he refined his techniques of sacred music. Several of his motets have been dated to the years he spent at the papal chapel.
Departure from Rome; Milan and France.
Around 1498 Josquin most likely re-entered the service of the Sforza family, on the evidence of a pair of letters between the Gonzaga and Sforza families. He probably did not stay in Milan long, for in 1499 Louis XII captured Milan in his invasion of northern Italy and imprisoned Josquin's former employers. Around this time Josquin most likely returned to France, although documented details of his career around the turn of the 16th century are lacking. Prior to departing Italy he most likely wrote one of his most famous secular compositions, the frottola "El grillo" (the Cricket), as well as "In te Domine speravi" ("I have placed my hope in you, Lord"), based on Psalm 30. The latter composition may have been a veiled reference to the religious reformer Girolamo Savonarola, who had been burned at the stake in Florence in 1498, and for whom Josquin seems to have had a special reverence; the text was the Dominican friar's favorite psalm, a meditation on which he left incomplete in prison prior to his execution.
Some of Josquin's compositions, such as the instrumental "Vive le roy", have been tentatively dated to the period around 1500 when he was in France. A motet, "Memor esto verbi tui servo tuo" ("Remember thy promise unto thy servant"), was, according to Heinrich Glarean writing in the "Dodecachordon" of 1547, composed as a gentle reminder to the king to keep his promise of a benefice to Josquin, which he had forgotten to keep. According to Glarean's story, it worked: the court applauded, and the king gave Josquin his benefice. Upon receiving it, Josquin reportedly wrote a motet on the text "Benefecisti servo tuo, Domine" ("Lord, thou hast dealt graciously with thy servant") to show his gratitude to the king.
Ferrara.
Josquin probably remained in the service of Louis XII until 1503, when Duke Ercole I of Ferrara hired him for the chapel there. One of the rare mentions of Josquin's personality survives from this time. Prior to hiring Josquin, one of Duke Ercole's assistants recommended that he hire Heinrich Isaac instead, since Isaac was easier to get along with, more companionable, was more willing to compose on demand, and would cost significantly less (120 ducats vs. 200). Ercole, however, chose Josquin.
While in Ferrara, Josquin wrote some of his most famous compositions, including the austere, Savonarola-influenced "Miserere", which became one of the most widely distributed motets of the 16th century; the utterly contrasting, virtuoso motet "Virgo salutiferi"; and possibly the "Missa Hercules Dux Ferrariae", which is written on a "cantus firmus" derived from the musical letters in the Duke's name, a technique known as "soggetto cavato".
Josquin did not stay in Ferrara long. An outbreak of the plague in the summer of 1503 prompted the evacuation of the Duke and his family, as well as two-thirds of the citizens, and Josquin left by April of the next year, possibly also to escape the plague. His replacement, Jacob Obrecht, died of the plague in the summer of 1505, to be replaced by Antoine Brumel in 1506, who stayed until the disbanding of the chapel in 1510.
Retirement to Condé-sur-l'Escaut.
Josquin went directly from Ferrara to his home region of Condé-sur-l'Escaut, southeast of Lille on the present-day border between Belgium and France, becoming provost of the collegiate church of Notre-Dame on 3 May 1504, a large musical establishment that he headed for the rest of his life. While the chapter at Bourges Cathedral asked him to become master of the choirboys there in 1508, it is not known how he responded, and there is no record of his having been employed there; most scholars presume he remained in Condé. In 1509, he held concurrently provost and choir master offices at Saint Quentin collegiate church.
During the last two decades of his life, Josquin's fame spread abroad along with his music. The newly developed technology of printing made wide dissemination of his music possible, and Josquin was the favorite of the first printers: one of Petrucci's first publications, and the earliest surviving print of music by a single composer, was a book of Josquin's masses which he printed in Venice in 1502. This publication was successful enough that Petrucci published two further volumes of Josquin's masses, in 1504 and 1514, and reissued them several times.
On his death-bed Josquin asked that he be listed on the rolls as a foreigner, so that his property would not pass to the Lords and Ladies of Condé. This bit of evidence has been used to show that he was French by birth. Additionally, he left an endowment for the performance of his late motet, "Pater noster", at all general processions in the town when they passed in front of his house, stopping to place a wafer on the marketplace altar to the Holy Virgin. "Pater noster" may have been his last work.
Music.
Overview.
Josquin lived during a transitional stage in music history. Musical styles were changing rapidly, in part owing to the movement of musicians between different regions of Europe. Many northern musicians moved to Italy, the heart of the Renaissance, attracted by the Italian nobility's patronage of the arts; while in Italy, these composers were influenced by the native Italian styles, and often brought those ideas with them back to their homelands. The sinuous musical lines of the Ockeghem generation, the contrapuntal complexity of the Netherlanders, and the homophonic textures of the Italian lauda and secular music began to merge into a unified style; indeed Josquin was to be the leading figure in this musical process, which eventually resulted in the formation of an international musical language, of which the most famous composers included Palestrina and Lassus.
Josquin likely learned his craft in his home region in the North, in France, and then in Italy when he went to Milan and Rome. His early sacred works emulate the contrapuntal complexity and ornamented, melismatic lines of Ockeghem and his contemporaries, but at the same time he was learning his contrapuntal technique he was acquiring an Italianate idiom for his secular music: after all, he was surrounded by Italian popular music in Milan. By the end of his long creative career, which spanned approximately 50 productive years, he had developed a simplified style in which each voice of a polyphonic composition exhibited free and smooth motion, and close attention was paid to clear setting of text as well as clear alignment of text with musical motifs. While other composers were influential on the development of Josquin's style, especially in the late 15th century, he himself became the most influential composer in Europe, especially after the development of music printing, which was concurrent with the years of his maturity and peak output. This event made his influence even more decisive than it might otherwise have been.
Many "modern" musical compositional practices were being born in the era around 1500. Josquin made extensive use of "motivic cells" in his compositions, short, easily recognizable melodic fragments which passed from voice to voice in a contrapuntal texture, giving it an inner unity. This is a basic organizational principle in music which has been practiced continuously from approximately 1500 until the present day.
Josquin wrote in all of the important forms current at the time, including masses, motets, chansons, and frottole. He even contributed to the development of a new form, the motet-chanson, of which he left at least three examples. In addition, some of his pieces were probably intended for instrumental performance.
Each area of his output can be further subdivided by form or by hypothetical period of composition. Since dating Josquin's compositions is particularly problematic, with scholarly consensus only achieved on a minority of works, discussion here is by type.
Masses.
Josquin wrote towards the end of the period in which the mass was the predominant form of sacred composition in Europe. The mass, as it had developed through the 15th century, was a long, multi-section form, with opportunities for large-scale structure and organization not possible in the other forms such as the motet. Josquin wrote some of the most famous examples of the genre, most using some kind of cyclic organization.
He wrote masses using the following general techniques, although there is considerable overlap between techniques in individual compositions:
Most of these techniques, particularly paraphrase and parody, became standardized during the first half of the 16th century; Josquin was very much a pioneer, and what was perceived by later observers as the mixing of these techniques was actually the process by which they were created.
Cantus-firmus masses.
Prior to Josquin's mature period, the most common technique for writing masses was the cantus firmus, a technique which had been in use already for most of the 15th century. It was the technique that Josquin used earliest in his career, with the "Missa L'ami Baudichon", possibly his first mass. This mass is based on a secular – indeed ribald – tune similar to "Three Blind Mice". That basing a mass on such a source was an accepted procedure is evident from the existence of the mass in Sistine Chapel part-books copied during the papacy of Julius II (1503 to 1513).
Josquin's most famous cantus-firmus masses are the two based on the L'homme armé tune, which was the favorite tune for mass composition of the entire Renaissance. The earlier of the two, "Missa L'homme armé super voces musicales", is a technical tour-de-force on the tune, containing numerous mensuration canons and contrapuntal display. It was by far the most famous of all his masses. The second, "Missa L'homme armé sexti toni", is a "fantasia on the theme of the armed man." While based on a cantus firmus, it is also a paraphrase mass, for fragments of the tune appear in all voices. Technically it is almost restrained, compared to the other "L'homme armé" mass, until the closing Agnus Dei, which contains a complex canonic structure including a rare retrograde canon, around which other voices are woven.
Paraphrase masses.
The paraphrase technique differs from the cantus-firmus technique in that the source material, though it still consists of a monophonic original, is embellished, often with ornaments. As in the cantus-firmus technique, the source tune may appear in many voices of the mass.
Several of Josquin's masses feature the paraphrase technique, and they include some of his most famous work. The relatively early "Missa Ave maris stella", which probably dates from his years in the Sistine Chapel choir, paraphrases the Marian antiphon of the same name; it is also one of his shortest masses. The late "Missa de Beata Virgine" paraphrases plainchants in praise of the Virgin Mary; it is a Lady Mass, a votive mass for Saturday performance, and was his most popular mass in the 16th century.
By far the most famous of Josquin's masses using the technique, and one of the most famous mass settings of the entire era, was the "Missa pange lingua", based on the hymn by Thomas Aquinas for the Vespers of Corpus Christi. It was probably the last mass that Josquin composed. This mass is an extended fantasia on the tune, using the melody in all voices and in all parts of the mass, in elaborate and ever-changing polyphony. One of the high points of the mass is the "et incarnatus est" section of the Credo, where the texture becomes homophonic, and the tune appears in the topmost voice; here the portion which would normally set "Sing, O my tongue, of the mystery of the divine body" is instead given the words "And he became incarnate by the Holy Ghost from the Virgin Mary, and was made man."
Parody masses, masses on popular songs.
In parody masses, the source material was not a single line, but an entire texture, often of a popular song. Several works by Josquin fall loosely into this category, including the "Missa Fortuna desperata", based on the three-voice song "Fortuna desperata" (possibly by Antoine Busnois); the "Missa Malheur me bat" (based on a chanson variously ascribed to Obrecht, Ockeghem, or, most likely, Abertijne Malcourt); and the "Missa Mater Patris", based on a three-voice motet by Antoine Brumel. The "Missa Mater Patris" is probably the first true parody mass to be composed, for it no longer contains any hint of a cantus firmus. Parody technique was to become the most usual means of mass composition for the remainder of the 16th century, although the mass gradually fell out of favor as the motet grew in esteem.
Masses on solmization syllables.
The earliest known mass by any composer using this method of composition – the "soggetto cavato" – is the "Missa Hercules Dux Ferrariae", which Josquin probably wrote in the early 1480s for the powerful Ercole I, Duke of Ferrara. The notes of the cantus firmus are drawn from the musical syllables of the Duke's name in the following way: "Ercole, Duke of Ferrara" in Latin is "Hercules Dux Ferrarie". Taking the solmization syllables with the same vowels gives: Re–Ut–Re–Ut–Re–Fa–Mi–Re (in modern nomenclature: D–C–D–C–D–F–E–D). Another mass using this technique is the "Missa La sol fa re mi", based on the musical syllables contained in "Lascia fare mi" ("leave me alone!"). The story, as told by Glareanus in 1547, was that an unknown aristocrat used to order suitors away with this phrase, and Josquin immediately wrote an "exceedingly elegant" mass on it as a jab at him.
Canonic masses.
Canonic masses came into increasing prominence in the latter part of the 15th century. Early examples include Ockeghem's famous "Missa prolationum", consisting entirely of mensuration canons, the "Missa L'homme armé" of Guillaume Faugues, whose cantus firmus is presented in canon at the descending fifth, and the "Missa" ["Ad fugam"] of Marbrianus de Orto, based on freely composed canons at the fifth between superius and tenor. Josquin makes use of canon in the Osanna and Agnus Dei III of the "Missa L'homme armé sexti toni", throughout the "Missa Sine nomine", and in the final three movements of the "Missa De beata virgine". The "Missa L'homme armé super voces musicales" incorporates mensuration canons in the Kyrie, Benedictus, and Agnus Dei II.
Motets.
Josquin's motet style varied from almost strictly homophonic settings with block chords and syllabic text declamation to highly ornate contrapuntal fantasias, to the psalm settings which combined these extremes with the addition of rhetorical figures and text-painting that foreshadowed the later development of the madrigal. He wrote many of his motets for four voices, an ensemble size which had become the compositional norm around 1500, and he also was a considerable innovator in writing motets for five and six voices. No motets of more than six voices have been reliably attributed to Josquin.
Almost all of Josquin's motets use some kind of compositional constraint on the process; they are not freely composed. Some of them use a cantus firmus as a unifying device; some are canonic; some use a motto which repeats throughout; some use several of these methods. The motets that use canon can be roughly divided into two groups: those in which the canon is plainly designed to be heard and appreciated as such, and another group in which a canon is present, but almost impossible to hear, and seemingly written to be appreciated by the eye, and by connoisseurs.
Josquin frequently used imitation, especially paired imitation, in writing his motets, with sections akin to fugal expositions occurring on successive lines of the text he was setting. An example is his setting of "Dominus regnavit" (Psalm 93), for four voices; each of the lines of the psalm begins with a voice singing a new tune alone, quickly followed by entries of other three voices in imitation.
In writing polyphonic settings of psalms, Josquin was a pioneer, and psalm settings form a large proportion of the motets of his later years. Few composers prior to Josquin had written polyphonic psalm settings. Some of Josquin's settings include the famous "Miserere", written in Ferrara in 1503 or 1504 and most likely inspired by the recent execution of the reformist monk Girolamo Savonarola, "Memor esto verbi tui", based on Psalm 119, and two settings of "De profundis" (Psalm 130), both of which are often considered to be among his most significant accomplishments.
Chansons and instrumental compositions.
In the domain of secular music, Josquin left numerous French chansons, for from three to six voices, as well as a handful of Italian secular songs known as frottole, as well as some pieces which were probably intended for instrumental performance. Problems of attribution are even more acute with the chansons than they are with other portions of his output: while about 70 three and four-voice chansons were published under his name during his lifetime, only six of the more than thirty five- and six-voice chansons attributed to him were circulated under his name during the same time. Many of the attributions added after his death are considered to be unreliable, and much work has been done in the last decades of the 20th century to correct attributions on stylistic grounds.
Josquin's earliest chansons were probably composed in northern Europe, under the influence of composers such as Ockeghem and Busnois. Unlike them, however, he never adhered strictly to the conventions of the "formes fixes" – the rigid and complex repetition patterns of the rondeau, virelai, and ballade – instead he often wrote his early chansons in strict imitation, a feature they shared with many of his sacred works. He was one of the first composers of chansons to make all voices equal parts of the texture; and many of his chansons contain points of imitation, in the manner of motets. However he did use melodic repetition, especially where the lines of text rhymed, and many of his chansons had a lighter texture, as well as a faster tempo, than his motets.
Inside of his chansons, he often used a cantus firmus, sometimes a popular song whose origin can no longer be traced, as in "Si j'avoye Marion". Other times he used a tune originally associated with a separate text; and still other times he freely composed an entire song, using no apparent external source material. Another technique he sometimes used was to take a popular song and write it as a canon with itself, in two inner voices, and write new melodic material above and around it, to a new text: he used this technique in one of his most famous chansons, "Faulte d'argent" ("The problem with money"), a song sung by a man who wakes in bed with a prostitute, broke and unable to pay her.
Some of his chansons were doubtless designed to be performed instrumentally. That Petrucci published many of them without text is strong evidence of this; additionally, some of the pieces (for example, the fanfare-like "Vive le roy") contain writing more idiomatic for instruments than voices.
Josquin's most famous chansons circulated widely in Europe. Some of the better known include his lament on the death of Ockeghem, "Nymphes des bois/Requiem aeternam"; "Mille regretz" (the attribution of which has recently been questioned); "Plus nulz regretz"; and "Je me complains".
In addition to his French chansons, he wrote at least three pieces in the manner of the Italian frottola, a popular Italian song form which he would have encountered during his years in Milan. These songs include "Scaramella", "El grillo", and "In te domine speravi". They are even simpler in texture than his French chansons, being almost uniformly syllabic and homophonic, and they remain among the most frequently sung portions of his output.
Motet-chansons.
While in Milan, Josquin wrote several examples of a new type of piece developed by the composers there, the motet-chanson. These compositions were texturally very similar to 15th century chansons in the "formes fixes" mold, except that unlike those completely secular works, they contained a chant-derived Latin cantus-firmus in the lowest of the three voices. The other voices, in French, sang a secular text which had either a symbolic relationship to the sacred Latin text, or commented on it. Josquin's three known motet-chansons, "Que vous madame/In pace", "A la mort/Monstra te esse matrem", and "Fortune destrange plummaige/Pauper sum ego", are similar stylistically to those by the other composers of the Milan chapel, such as Loyset Compère and Alexander Agricola.
Influence.
Josquin's fame lasted throughout the 16th century, and indeed increased for several decades after his death. Zarlino, writing in the 1580s, was still using examples from Josquin in his treatises on composition; and Josquin's fame was only eclipsed after the beginning of the Baroque era, with the decline of the pre-tonal polyphonic style. During the 18th and 19th centuries Josquin's fame was overshadowed by later Roman School composer Palestrina, whose music was seen as the summit of polyphonic refinement, and codified into a system of composition by theorists such as Johann Fux; however, during the 20th century, Josquin's reputation has grown steadily, to the point where scholars again consider him "the greatest and most successful composer of the age." According to Richard Sherr, writing in the introduction to the "Josquin Companion", addressing specifically the shrinking of Josquin's canon due to correction of misattributions, "Josquin will survive because his best music really is as magnificent as everybody has always said it was."
Since the 1950s Josquin's reputation has been boosted by the increasing availability of recordings, of which there are many, and the rise of ensembles specializing in the performance of 16th century vocal music, many of which place Josquin's output at the heart of their repertoire.
Works list.
The difficulties in compiling a works list for Josquin cannot be overstated. Because of his immense prestige in the early sixteenth century, many scribes and publishers did not resist the temptation of attributing anonymous or otherwise spurious works to Josquin. The German editor Georg Forster summed up the situation admirably in 1540 when he wrote, "Now that Josquin is dead, he is putting out more works than when he was alive." Thus, the authenticity of many of the works listed below is disputed.
Masses.
Doubtful works:
Mass fragments.
Of questionable authenticity, with the exception of the "Credo De tous biens playne:
References and further reading.
</dl>

</doc>
<doc id="55022" url="http://en.wikipedia.org/wiki?curid=55022" title="Gait">
Gait

Gait is the pattern of movement of the limbs of animals, including humans, during locomotion over a solid substrate. Most animals use a variety of gaits, selecting gait based on speed, terrain, the need to maneuver, and energetic efficiency. Different animal species may use different gaits due to differences in anatomy that prevent use of certain gaits, or simply due to evolved innate preferences as a result of habitat differences. While various gaits are given specific names, the complexity of biological systems and interacting with the environment make these distinctions 'fuzzy' at best. Gaits are typically classified according to footfall patterns, but recent studies often prefer definitions based on mechanics. The term typically does not refer to limb-based propulsion through fluid mediums such as water or air, but rather to propulsion across a solid substrate by generating reactive forces against it (which can apply to walking while underwater as well as on land).
Due to the rapidity of animal movement, simple direct observation is rarely sufficient to give any insight into the pattern of limb movement. In spite of early attempts to classify gaits based on footprints or the sound of footfalls, it wasn't until Eadweard Muybridge and Étienne-Jules Marey began taking rapid series of photographs that proper scientific examination of gaits could begin.
Overview.
Milton Hildebrand pioneered the contemporary scientific analysis and the classification of gaits. The movement of each limb was partitioned into a stance phase, where the foot was in contact with the ground, and a swing phase, where the foot was lifted and moved forwards. Each limb must complete a cycle in the same length of time, otherwise one limb's relationship to the others can change with time, and a steady pattern cannot occur. Thus, any gait can completely be described in terms of the beginning and end of stance phase of three limbs relative to a cycle of a reference limb, usually the left hindlimb.
Variables.
Gaits are generally classed as "symmetrical" and "asymmetrical" based on limb movement. It is important to note that these terms have nothing to do with left-right symmetry. In a symmetrical gait, the left and right limbs of a pair alternate, while in an asymmetrical gait, the limbs move together. Asymmetrical gaits are sometimes termed "leaping gaits", due to the presence of a suspended phase.
The key variables for gait are the duty factor and the forelimb-hindlimb phase relationship. Duty factor is simply the percent of the total cycle which a given foot is on the ground. This value will usually be the same for forelimbs and hindlimbs unless the animal is moving with a specially trained gait or is accelerating or decelerating. Duty factors over 50% are considered a "walk", while those less than 50% are considered a run. Forelimb-hindlimb phase is the temporal relationship between the limb pairs. If the same-side forelimbs and hindlimbs initiate stance phase at the same time, the phase is 0 (or 100%). If the same-side forelimb contacts the ground half of the cycle later than the hindlimb, the phase is 50%.
Differences between species.
Any given animal uses a relatively restricted set of gaits, and different species use different gaits. Almost all animals are capable of symmetrical gaits, while asymmetrical gaits are largely confined to mammals, who are capable of enough spinal flexion to increase stride length (though small crocodilians are capable of using a bounding gait). Lateral sequence gaits during walking and running are most common in mammals, but arboreal mammals such as monkeys, some possums, and kinkajous use diagonal sequence walks for enhanced stability. Diagonal sequence walks and runs (aka trots) are most frequently used by sprawling tetrapods such as salamanders and lizards, due to the lateral oscillations of their bodies during movement. Bipeds are a unique case, and most bipeds will display only three gaits - walking, running, and hopping - during natural locomotion. Other gaits, such as human skipping, are not used without deliberate effort.
Physiological effects of gait.
Gait choice can have effects beyond immediate changes in limb movement and speed, notably in terms of ventilation. Because they lack a diaphragm, lizards and salamanders must expand and contract their body wall in order to force air in and out of their lungs, but these are the same muscles used to laterally undulate the body during locomotion. Thus, they cannot move and breathe at the same time, a situation called Carrier's constraint, though some, such as monitor lizards, can circumvent this restriction via buccal pumping. In contrast, the spinal flexion of a galloping mammal causes the abdominal viscera to act as a piston, inflating and deflating the lungs as the animal's spine flexes and extends, increasing ventilation and allowing greater oxygen exchange.
Energy-based gait classification.
While gaits can be classified by footfall, new work involving whole-body kinematics and force-plate records has given rise to an alternative classification scheme, based on the mechanics of the movement. In this scheme, movements are divided into walking and running. Walking gaits are all characterized by a 'vaulting' movement of the body over the legs, frequently described as in inverted pendulum (displaying fluctuations in kinetic and potential energy which are perfectly out of phase). In running, the kinetic and potential energy fluctuate in-phase, and the energy change is passed on to muscles, bones, tendons and ligaments acting as springs (thus it is described by the spring-mass model).
Energetics.
Speed generally governs gait selection, with quadrupedal mammals moving from a walk to a run to a gallop as speed increases. Each of these gaits has an optimum speed, at which the minimum calories per meter are consumed, and costs increase at slower or faster speeds. Gait transitions occur near the speed where the cost of a fast walk becomes higher than the cost of a slow run. Unrestrained animals will typically move at the optimum speed for their gait to minimize energy cost. The cost of transport is used to compare the energetics of different gaits, as well as the gaits of different animals.
Non-tetrapod gaits.
In spite of the differences in leg number shown in terrestrial vertebrates, according to the inverted pendulum model of walking and spring-mass model of running, "walks" and "runs" are seen in animals with 2, 4, 6, or more legs. The term 'gait' has even been applied to flying and swimming organisms that produce distinct patterns of wake vortices.

</doc>
<doc id="55023" url="http://en.wikipedia.org/wiki?curid=55023" title="Jin dynasty (1115–1234)">
Jin dynasty (1115–1234)

The Jin dynasty (Jurchen: Anchun Gurun; , ]); Manchu: Aisin Gurun; Khitan language: Nik, Niku; Mongolian: Altan Ulus; 1115–1234), officially the Great Jin (), also known as the Jurchen dynasty, was founded by the Wanyan clan of the Jurchen people, the ancestors of the Manchu people who established the Qing dynasty some 500 years later. The name is sometimes written as Kin to differentiate it from an earlier Jìn dynasty of China whose name is identically spelled using the Latin alphabet.
The Jurchen tribes were united by the chieftain and later first Jin emperor, Wanyan Aguda, who overthrew the Khitan Liao dynasty. During the reign of Aguda's successor, the Jin declared war against the Song dynasty and conquered much of northern China. The Song were forced to flee south of Yangtze River. The Jin dynasty fell after their defeat against the rising Mongol Empire, a steppe confederation that had formerly been a Jurchen vassal.
Name.
The Jin Emperors equated their state with the concept of China(中國) like other non-Han dynasties did such as the Yuan. Non-Han rulers expanded the definition of "China" to include non-Han peoples in addition to Han people, whenever they ruled China. Yuan, Jin, and Northern Wei documents indicate the usage of "China" by dynasties to refer to themselves began earlier than previously thought.
History.
The Jin dynasty was created in what would become northern Manchuria by the Jurchen tribal chieftain Wanyan Aguda (完顏阿骨打) in 1115. Aguda adopted for his state the Chinese name for gold, itself a translation of "Anchuhu" River, which meant "golden" in Jurchen. The Jurchens' early rival was the Liao dynasty, which had held sway over northern China, including Manchuria and part of the Mongol region, for several centuries. In 1121, the Jurchens entered into the Alliance on the Sea with the Song dynasty and agreed to jointly invade the Liao. While the Song armies faltered, the Jurchens succeeded in driving the Liao to Central Asia. In 1125, after the death of Aguda, the Jin broke the alliance with the Song and Jin campaigns against the Song dynasty|invaded North China. When the Song reclaimed the southern part of the Liao where Han Chinese lived, they were "fiercely resisted" by the Han Chinese population there who had previously been under Liao rule, while when the Jurchens invaded that area, the Han Chinese did not oppose them at all and handed over the Southern Capital (modern day Beijing, then known as Yanjing) to them. On January 9, 1127, Jin forces ransacked Kaifeng, capital of the Northern Song dynasty, capturing both Emperor Qinzong and his father, Emperor Huizong, who had abdicated in panic in the face of Jin forces. Following the fall of Kaifeng, the succeeding Southern Song dynasty continued to fight the Jin for over a decade, eventually signing the Treaty of Shaoxing in 1141, which called for the cession of all Song land north of the Huai River to the Jin and the execution of Song General Yue Fei in return for peace. The peace treaty was formally ratified on 11 October 1142 when a Jin envoy visited the Song court.
The migration south.
After taking over Northern China, the Jin dynasty became increasingly Sinicized. About three million people, half of them Jurchens, migrated south into northern China over two decades, and this minority governed about thirty million people. The Jurchens were given land grants and organized into hereditary military units: 300 households formed a "mou-ke" (company) and 7-10 "mouke"s formed a "meng-an" (battalion). Many married Hans, although the ban on Jurchen nobles marrying Hans was not lifted until 1191. After Jin Emperor Tàizōng died in 1135, the next three Jin emperors were grandsons of Wányán Āgǔdǎ by three different princes. Young Jin Emperor Xīzōng (r. 1135–1149) studied the classics and wrote Chinese poetry. He adopted Han cultural traditions, but the Jurchen nobles had the top positions.
Later in life, Emperor Xīzōng became an alcoholic and executed many officials for criticizing him. He also had Jurchen leaders who opposed him murdered, even those in his own Wanyan family clan. In 1149 he was murdered by a cabal of relatives and nobles, who made his cousin Wányán Liàng the next Jin emperor. Because of the brutality of both his domestic and foreign policy, Wanyan Liang was posthumously demoted from the position of emperor. Consequently, historians have commonly referred to him by the posthumous name of King Hǎilíng.
Rebellions in the north.
Having usurped the throne, Wanyan Liang embarked on the program of legitimizing his rule as an emperor of China. In 1153, he moved the empire's main capital from Huining Fu in northern Manchuria (south of present-day Harbin) to the former Liao capital, Yanjing (now Beijing).
Four years later, in 1157, to emphasize the permanence of the move, he razed the nobles’ residences in Huining.
Hǎilíng also reconstructed the former Song capital, Bianjing (now Kaifeng), which had been sacked in 1127, making it the Jin's southern capital.
Prince Hǎilíng also tried to suppress dissent by killing Jurchen nobles, executing 155 princes. To fulfill his dream of becoming the ruler of all China, Prince Hǎilíng attacked the Southern Song in 1161. Meanwhile, two simultaneous rebellions erupted in Manchuria: one of Jurchen nobles, led by Hǎilíng's cousin, soon-to-be crowned Wányán Yōng (完顏雍), and the other of Khitan tribesmen. Hǎilíng had to withdraw Jin troops from southern China to quell the uprisings. The Jin were defeated in the Battle of Caishi and Battle of Tangdao. With a depleted military force, Prince Hǎilíng failed to make headway in his attempted invasion of the Southern Song. Finally he was assassinated by his own generals in December of 1161, due to his defeats. His son and heir was also assassinated in the capital.
Although crowned in October, Wányán Yōng was not officially recognized as Jin Emperor Shìzōng (世宗) until the murder of Prince Hǎilíng's heir. The Khitan uprising was not suppressed until 1164; their horses were confiscated so that the rebels had to take up farming. Other Khitan and Xi cavalry units had been incorporated into the Jin army. Because these internal uprisings had severely weakened the Jin's capacity to confront the Southern Song militarily, the Jin court under Emperor Shizong began negotiating for peace. The Treaty of Lóngxīng (隆興和議) was signed in 1164 and ushered over 40 years of peace between the two empires.
In the early 1180s Emperor Shìzōng instituted a restructuring of 200 "meng'an" units to remove tax abuses and help Jurchens. Communal farming was encouraged. The Jin empire prospered and had a large surplus of grain in reserve. Although learned in Chinese classics, Shizong was also known as a promoter of Jurchen language and culture; during his reign, a number of Chinese classics were translated into Jurchen, the Imperial Jurchen Academy was founded, and the Imperial examinations started to be offered in the Jurchen language. Shizong's reign (1161–1189) was remembered by the posterity as the time of comparative peace and prosperity, and the emperor himself was compared to the legendary Yao and Shun
Shìzōng's grandson, Emperor Zhāngzōng (章宗) (r. 1189–1208) venerated Jurchen values, but he also immersed himself in Chinese culture and married an ethnic Han woman. The "Taihe Code of law" was promulgated in 1201 and was based mostly on the Tang Code. In 1207 the Song tried to invade, but the Jin forces effectively repulsed them. In the peace agreement the Song had to pay higher annual indemnities and behead Hán Tūozhòu (韩侂胄), the leader of their war party.
Fall of Jin.
Starting from the early 13th century the Jin dynasty began to feel the pressure of Mongols from the north. Genghis Khan first led the Mongols into Western Xia territory in 1205 and ravaged it four years later. In 1211 about 50,000 Mongols on horses invaded the Jin Empire and began absorbing Khitan and Jurchen rebels. The Jin army had a half million men with 150,000 cavalry but abandoned the “western capital” Datong (see also Badger's Mount Campaign). The next year the Mongols went north and looted the Jin "eastern capital", and in 1213 they besieged the "central capital", Zhongdu (Beijing). In 1214 the Jin made a humiliating treaty but retained the capital. That summer, Jin Emperor Xuānzōng (宣宗) abandoned the central capital and moved the government to the "southern capital" of Kaifeng, making it the official seat of Jin dynasty power. In 1216 a war faction persuaded Xuānzōng to attack the Song, but in 1219 they were defeated at the same place by the Yangtze River where Prince Hǎilíng had been defeated in 1161. The Jin now faced a two front war that they could not afford. Furthermore, the Jin Emperor Āizōng (哀宗) won a succession struggle against his brother and then quickly ended the war and went back to the capital. He made peace with the Tanguts, who had been allied with the Mongols.
Many Han Chinese and Khitan defected to the Mongols to fight against the Jin. Two Han Chinese leaders, Shi Tianze, Liu Heima 劉黑馬 (Liu Ni), and the Khitan Xiao Zhala defected and commanded the 3 Tumens in the Mongol army. Liu Heima and Shi Tianze served Ogödei Khan. Liu Heima and Shi Tianxiang led armies against Western Xia for the Mongols. There were 4 Han Tumens and 3 Khitan Tumens, with each Tumen consisting of 10,000 troops.
Shi Tianze was a Han Chinese who lived in the Jin dynasty (1115–1234). Interethnic marriage between Han and Jurchen became common at this time. His father was Shi Bingzhi (Shih Ping-chih) 史秉直. Shi Bingzhi was married to a Jurchen woman (surname Na-ho) and a Han Chinese woman (surname Chang), it is unknown which of them was Shi Tianze's mother. Shi Tianze was married to two Jurchen women, a Han Chinese woman, and a Korean woman, and his son Shi Gang was born to one of his Jurchen wives. His Jurchen wive's surnames were Mo-nien and Na-ho, his Koan wife's surname was Li, and his Han Chinese wife's surname was Shi. Shi Tianze defected to the Mongol Empire's forces upon their invasion of the Jin dynasty. His son Shi Gang married married a Kerait woman, the Kerait were Mongolified Turkic people and considered as part of the "Mongol nation".
The Yuan dynasty created a "Han Army" out of defected Jin troops.
Genghis Khan died in 1227 while his armies were conquering the Western Xia dynasty. His son Ögedei Khan invaded the Jin Empire in 1232 with assistance from the Southern Song. The Jurchens tried to resist; but when the Mongols besieged Kaifeng in 1233, Āizōng fled south to the city of Caizhou. An allied army of Song and Mongols looted the capital, and the next year Āizōng committed suicide to avoid being captured when the Mongols besieged Caizhou, ending the Jin dynasty in 1234. The territory of the Jin was to be divided between the Mongols and the Song. However, due to lingering territorial disputes, the Song and the Mongols eventually went to war with one another over these territories.
In "Empire of The Steppes", René Grousset reports that the Mongols were always amazed at the valor of the Jin warriors, who held out until seven years after the death of Genghis Khan.
Military.
Contemporary Chinese writers ascribed Jurchen success in overwhelming the Liao and Northern Song mainly to their cavalry. Already during Aguda's rebellion against the Liao, all Jurchen fighters were mounted. It was said that the Jurchen cavalry tactics were a carryover from their hunting skills.
Jurchen horsemen were provided with heavy armor; on occasions, they would use a team of horses attached to each other with chains (拐子马, "guaizi ma")
As the Liao Empire fell apart and the Song retreated beyond the Yangtze, the army of the new Jin dynasty absorbed many soldiers who formerly fought for the Liao or Song. The new Jin empire adopted many of the Song's weapons, including various machines for siege warfare and artillery. In fact, the Jin use of cannons, grenades, and even rockets to defend besieged Kaifeng against the Mongols in 1233 is considered the first ever battle in human history in which gunpowder was used effectively, even though it failed to prevent the eventual Jin defeat.
On the other hand, the Jin was not particularly good at naval warfare. Both in 1129–30 and in 1161 Jin forces were defeated by the Southern Song navies when trying to cross the Yangtze River into the core Southern Song territory (see Battle of Tangdao and Battle of Caishi), even though for the latter campaign the Jin had equipped a large navy of their own, using Chinese shipbuildiers and even Chinese captains who had defected from the Southern Song.
In 1130 the Jin army reached Hangzhou and Ningbo in southern China. But heavy Chinese resistance and the geography of the area halted the Jin advance, and they were forced retreat and withdraw, and they had not been able to escape the Song navy when trying to return until they were directed by a Chinese defector who helped them escape in Chenkiang. Southern China was then cleared of the Jurchen forces.
The Jin Great Wall.
In order to prevent incursion from the Mongols, a large construction program was launched. The records show that two important sections of the Great wall were completed by the Jurchen Jin dynasty.
The Great Wall as constructed by the Jurchens differed from the previous dynasties. Known as the Border Fortress or the Boundary Ditch of the Jin, it was formed by digging ditches within which lengths of wall were built. In some places subsidiary walls and ditches were added for extra strength. The construction was started in about 1123 and completed by about 1198. The two sections attributable to the Jin Dynasty are known as the Old Mingchang Walls and New Great Walls, together stretching more than 2,000 kilometers in length.
Government.
The government of the Jin dynasty merged Jurchen customs with institutions adopted from the Liao and Song dynasties. The predynastic Jurchen government was based on the quasi-egalitarian tribal council. Jurchen society at the time did not have a strong political hierarchy. The "Shuo Fu" (說郛) records that the Jurchen tribes were not ruled by central authority and locally elected their chieftains. Tribal customs were retained after Aguda united the Jurchen tribes and formed the Jin dynasty, coexisting alongside more centralized institutions. The Jin dynasty had five capitals, a practice they adopted from the Balhae and the Liao. The Jin had to overcome the difficulties of controlling a multi-cultural empire composed of territories once ruled by the Liao and Northern Song. The solution of the early Jin government was to establish separate government structures for different ethnic groups.
Legacy.
In the 17th century, the Jurchen chief Nurhaci combined the three Jurchen tribes after thirty years of struggle and founded the Later Jin dynasty (1616–1636). Nurhaci's eighth son and heir, Hung Taiji, later changed the name of his people from Jurchen to Manchu in 1635. The next year, he changed the name of the Later Jin to Qing in 1636. However, the Qing Imperial family, the Aisin Gioro, are unrelated to the Jin Jurchen Imperial family, the Wanyan.
List of emperors.
(1) Quite long and thus not used when referring to this sovereign.<br>
(2) Did not exist

</doc>
<doc id="55028" url="http://en.wikipedia.org/wiki?curid=55028" title="Frederick Douglas">
Frederick Douglas

Frederick Douglas may refer to:

</doc>
<doc id="55029" url="http://en.wikipedia.org/wiki?curid=55029" title="Larry Bird">
Larry Bird

Larry Joe Bird (born December 7, 1956) is an American retired professional basketball player who played for the Boston Celtics of the National Basketball Association (NBA). Since retiring as a player, he has been a mainstay in the Indiana Pacers organization, currently serving as team president. Drafted into the NBA sixth overall by the Boston Celtics in 1978, Bird started at small forward and power forward for thirteen seasons, spearheading one of the NBA's most formidable frontcourts that included center Robert Parish and forward Kevin McHale. Bird was a 12-time NBA All-Star and was named the league's Most Valuable Player (MVP) three consecutive times (1984–1986). He played his entire professional career for Boston, winning three NBA championships and two NBA Finals MVP awards.
He was a member of the 1992 United States men's Olympic basketball team ("The Dream Team") that won the gold medal at the 1992 Summer Olympics. Bird was voted to the NBA's 50th Anniversary All-Time Team in 1996 and inducted into the Naismith Memorial Basketball Hall of Fame in 1998 (and was inducted again 2010 as a member of the "Dream Team").
He served as head coach of the Indiana Pacers from 1997 to 2000. In 2003, he assumed the role of president of basketball operations for the Pacers, holding the position until retiring in 2012. After a year away from the position, he announced he would return to the Pacers as president of basketball operations in 2013. In addition to being part of the 50–40–90 club, he is the only person in NBA history to be named Most Valuable Player, Coach of the Year, and Executive of the Year.
Early life.
Bird was born in West Baden, Indiana to Georgia (née Kerns) and Claude Joseph "Joe" Bird. He was raised in nearby French Lick, where his mother worked two jobs to support Larry and his five siblings. Bird has said that being poor as a child still motivates him "to this day". Georgia and Joe divorced when Larry was in high school, and Joe committed suicide about a year later. Larry used basketball as an escape from his family troubles, starring for Springs Valley High School and averaging 31 points, 21 rebounds, and 4 assists as a senior on his way to becoming the school's all-time scoring leader.
College career.
Bird received a scholarship to play college basketball for the Indiana Hoosiers in 1974. After less than a month on campus, he dropped out of school, finding the adjustment between his small hometown and the large student population of Bloomington to be overwhelming. He returned to French Lick, enrolling in a community college and working municipal jobs for a year before enrolling at Indiana State University in 1975. He had a successful three-year career with the Sycamores, helping them reach the NCAA tournament for the first time in school history and leading them to the championship game against Michigan State in 1979. Indiana State would lose the game 75–64, with Bird scoring 19 points but making only 7 of 21 shots for 33.3 percent shooting rate. The game achieved the highest ever rating for a college basketball game in large part because of the match-up between Bird and Spartans' point guard Earvin "Magic" Johnson, a rivalry that lasted throughout their professional careers. Despite failing to win the championship, Bird earned a slew of year-end awards and honors for his outstanding play including the Naismith College Player of the Year Award. After the conclusion of the championship basketball season, Bird appeared in an Indiana State baseball doubleheader against Kentucky Wesleyan, going 1-for-2 with two RBI. He was pulled from the second game by coach Bob Warn after colliding with the Sycamore catcher, thus ending his baseball career. For his college basketball career, he averaged 30.3 points, 13.3 rebounds, and 4.6 assists per game, leading the Sycamores to an 81–13 record during his tenure.
Professional career.
Joining the Celtics (1978–79).
Bird was selected by the Boston Celtics with the sixth overall pick in the 1978 NBA draft. Bird did not sign with the Celtics immediately; instead, he played out his final season at Indiana State and then inked a five-year, $3.25 million contract with the team, making him the highest paid rookie in league history at the time. Shortly afterwards, NBA draft eligibility rules were changed to prevent teams from drafting players before they were ready to sign, a rule known as the Bird Collegiate Rule.
Early success (1979–83).
Bird immediately transformed the Celtics into a title contender, helping them improve their win total by 32 games from the year before he was drafted and finish first in the Eastern Conference. With averages of 21.3 points, 10.4 rebounds, 4.5 assists, and 1.7 steals per game for the season, he was selected to the All-Star Team and named Rookie of the Year. In the Conference Finals, Boston was eliminated by the Philadelphia 76ers.
Before the 1980–81 season, the Celtics selected forward Kevin McHale in the draft and acquired center Robert Parish from the Golden State Warriors, forming a Hall of Fame trio for years to come. Behind Bird's leadership and Boston's upgraded roster, the Celtics again advanced to the Conference Finals for a rematch with the 76ers. Boston fell behind 3–1 to start the series but won the next three games to advance to the Finals against the Houston Rockets, winning in six games and earning Bird his first championship. He averaged 21.9 points, 14 rebounds, 6.1 assists, and 2.3 steals per game for the postseason and 15.3 points, 15.3 rebounds, and 7 assists per game for the Finals but lost out on the Finals MVP Award to teammate Cedric Maxwell.
At the 1982 All-Star Game, Bird scored 19 points en route to winning the All-Star Game MVP Award. At the conclusion of the season, he earned his first All-Defensive Team selection. He eventually finished runner-up in Most Valuable Player Award voting to Moses Malone. In the Conference Finals, the Celtics faced the 76ers for the third consecutive year, losing in seven games. Boston's misfortunes continued into the next season, with Bird again finishing second in MVP voting to Malone and the team losing in the Conference Semifinals to the Milwaukee Bucks.
Battles with the Lakers and MVP tenure (1983–87).
Bird was named MVP of the 1983–84 season with averages of 24.2 points, 10.1 rebounds, 6.6 assists, and 1.8 steals per game. In the playoffs, the Celtics avenged their loss from the year before to the Bucks, winning in five games in the Conference Finals to advance to the Finals against the Los Angeles Lakers. The Lakers, led by Bird's college rival Magic Johnson, were on the verge of putting the series away in Game 4 before a flagrant foul was committed on Kurt Rambis that resulted in a brawl and caused Los Angeles to lose their composure. Boston came back to win the game, eventually winning the series in seven. Bird was named Finals MVP behind 27.4 points, 14 rebounds, and 3.6 assists per game.
On March 12 of the 1984–85 season, Bird scored a career-high and franchise record 60 points in a game against the Atlanta Hawks. The performance came just nine days after Kevin McHale set the previous Celtics record for points in a game with 56. At the conclusion of the year, Bird was named MVP for the second consecutive season behind averages of 28.7 points, 10.5 rebounds, and 6.6 assists per game. Boston advanced through the playoffs to earn a rematch with the Lakers, this time losing in six games.
Before the start of the 1985–86 season, the Celtics made a daring trade for Bill Walton, an All-Star center with a history of injury. The risk paid off; Walton's acquisition helped Boston win a league best 67 games. One of Bird's career highlights occurred at the 1986 NBA All-Star Weekend when he walked into the locker room at the inaugural Three-Point Shootout and asked who was going to finish second before winning the shootout. With averages of 25.8 points, 9.8 rebounds, and 6.8 assists, and 2 steals per game, Bird became just the third player in NBA history to win three consecutive MVP Awards. In the playoffs, the Celtics lost only one game through the first three rounds en route to a match-up against the Rockets in the Finals. Bird averaged 24 points, 9.7 rebounds, and 9.5 assists per game for the series, leading Boston to victory in six games. The '86 Celtics are commonly ranked as one of the greatest basketball teams of all-time, with the "Boston Globe"'s Peter May and Grantland's Bill Simmons listing them at number one.
In 1987, the Celtics made their last Finals appearance of Bird's career, fighting through difficult series against the Milwaukee Bucks and Detroit Pistons but as they reached the NBA Finals, the Celtics, hampered by devastating injuries, lost to a dominant Lakers team which had won 65 games during the season. The Celtics ended up losing to the Lakers in six games, with Bird averaging 24.2 points on .445 shooting, 10 rebounds and 5.5 assists per game in the championship series. The Celtics would fall short in 1988 losing to the Detroit Pistons in 6 games in the Eastern Conference Finals as the Pistons made up from the heartbreak the previous season. Between them, Bird and Johnson captured eight NBA championships during the 1980s, with Magic getting five and Bird three. During the 1980s, either Boston or Los Angeles appeared in every NBA Finals.
Throughout the 1980s, contests between the Celtics and the Lakers—both during the regular season and in the Finals—attracted enormous television audiences. The first regular season game between the Celtics and the Lakers in the 1987–88 season proved to be a classic with Magic Johnson banking in an off balance shot from near the three-point line at the buzzer for a 115–114 Lakers win at Boston Garden. The historical rift between the teams, which faced each other several times in championship series of the 1960s, fueled fan interest in the rivalry. Not since Bill Russell squared off against Wilt Chamberlain had professional basketball enjoyed such a marquee matchup. The apparent contrast between the two players and their respective teams seemed scripted for television: Bird, the introverted small-town hero with the blue-collar work ethic, fit perfectly with the throwback, hard-nosed style of the Celtics, while the stylish, gregarious Johnson ran the Lakers' fast-paced Showtime offense amidst the bright lights and celebrities of Los Angeles. A 1980s Converse commercial for its "Weapon" line of basketball shoes (endorsed by both Bird and Johnson) reflected the perceived dichotomy between the two players. In the commercial, Bird is practicing alone on a rural basketball court when Johnson pulls up in a sleek limousine and challenges him to a one-on-one match.
Despite the intensity of their rivalry, Bird and Johnson became friends off the court. Their friendship blossomed when the two players worked together to film the Converse commercial, which depicted them as archenemies. Johnson appeared at Bird's retirement ceremony on February 4, 1993 and emotionally described Bird as a "friend forever".
Waning years (1988–92).
In 1988, Bird had the best statistical season of his career, but the Celtics failed to reach the NBA Finals for the first time in five years, losing to the Pistons in six games during the Eastern Conference Finals. Bird started the 1988–89 season, but ended his season after six games to have bone spurs surgically removed from both of his heels. He returned to the Celtics in 1989, but debilitating back problems and an aging Celtic roster prevented him from regaining his mid-1980s form. Nonetheless, through the final years of his career, Bird maintained his status as one of the premier players in the game. He averaged over 20 points, 9 rebounds and 7 assists a game in his last three seasons with the Celtics, and shot better than 45% from the field in each. Bird led the Celtics to playoff appearances in each of those three seasons.
Bird's body, however, continued to break down. He had been bothered by back problems for years, and his back became progressively worse. After leading the Celtics to a 29–5 start to the 1990–91 season, he missed 22 games due to a compressed nerve root in his back, a condition that would eventually lead to his retirement. He had off-season surgery to remove a disc from his back, but his back problems continued and he missed 37 games during the 1991–92 season. His past glory would be briefly rekindled, however, in a game that season in which he scored 49 points in a double-overtime victory over the Portland Trail Blazers. During the 1992 Eastern Conference semi-finals against the Cleveland Cavaliers, Bird missed four of the seven games in the series due to those recurring back problems.
In the summer of 1992, Bird joined Magic Johnson, Michael Jordan and other NBA stars to play for the United States basketball team in that year's Olympics in Barcelona, Spain. It was the first time in America's Olympic history that the country sent professional basketball players to compete. The "Dream Team" won the men's basketball gold medal.
Following his Olympic experience, on August 18, 1992, Bird announced his retirement as an NBA player. He finished his career with averages of more than 24 points, 10 rebounds and 6 assists per game, while shooting 49.6% from the field, 88.6% from the free throw line and 37.6% from three-point range. Following Bird's departure, the Celtics promptly retired his jersey number 33.
In 1989, Bird published his autobiography, "" with Bob Ryan. The book chronicles his life and career up to the 1989 NBA season.
Post-retirement career.
The Celtics employed Bird as a special assistant in the team's front office from 1992 until 1997. In 1997, Bird accepted the position of coach of the Indiana Pacers and said he would be on the job for no more than three years. Despite having no previous coaching experience, Bird led the Pacers to a 58–24 record—the franchise's best as an NBA team at the time—in the 1997–98 season, and pushed the Bulls to seven games in the Eastern Conference finals. He was named the NBA Coach of the Year for his efforts, becoming the only man in NBA history to have won both the MVP and Coach of the Year awards. He then led the Pacers to two consecutive Central Division titles in 1999 and 2000, and a berth in the 2000 NBA Finals.
Bird resigned as Pacers coach shortly after the end of the 2000 season, following through on his initial promise to coach for only three years. In 2003, he returned as the Pacers' President of Basketball Operations, overseeing team personnel and coaching moves, as well as the team's draft selections. Bird promoted David Morway to general manager in 2008, but Bird still had the final say in basketball matters. After the 2011–2012 NBA season, Bird was named NBA Executive of the Year.
On June 27, 2012, a day before the 2012 NBA Draft, Bird and the Pacers announced that they would be parting ways later that summer. Bird said health issues were among the reasons for his leaving. Donnie Walsh was named to replace him.
On June 26, 2013, almost exactly a year later, it was announced that Bird would be returning to the Pacers as president of basketball operations. Pacers owner Herb Simon briefly addressed Bird's prior health concerns, stating that "He's got his energy back, his health back and he's raring to go."
Awards and honors.
As player:
As coach:
As executive:
Personal life.
Bird married Dinah Mattingly in 1989. They have two adopted children, Connor and Mariah. Bird also has a biological daughter, Corrie, from his first marriage. He has four brothers, Mike, Mark, Jeff, and Eddie, and a sister, Linda. Eddie also played basketball at Indiana State from 1986 to 1990 and today is the city park superintendent at Terre Haute.
In the 1980s and 1990s, Bird co-owned Larry Bird's Boston Connection, a hotel and restaurant in downtown Terre Haute. The property is now a Quality Inn.
Legacy.
"Larry, you only told me one lie. You said there will be another Larry Bird. Larry, there will never, ever be another Larry Bird."—Magic Johnson, as quoted at Bird's retirement party.
In 1999, Bird ranked No. 30 in "ESPN's ".
For the 2008 NBA Finals, which featured a rematch of the Celtics-Lakers rivalry, Bird appeared in a split-screen advertisement with Magic Johnson (as part of the "There Can Only Be One" campaign which had played throughout the 2008 NBA Playoffs but to that point only featured players from the two teams competing in a given series) discussing the meaning of rivalries.
Bird was widely considered one of Red Auerbach's favorite players. He considered Bird to be the greatest basketball player of all time. Auerbach was so enamored with the player that he drafted him out of Indiana State and waited a year before Bird was eligible to suit up for the Celtics. During his introductory press conference, after Auerbach's contentious negotiations with agent Bob Woolf, Bird announced he "would have played for free." This was after Woolf asked for the most lucrative contract in NBA history, to which Auerbach was quick to point out that Bird had not played a game in the NBA yet.
Bird is the only man to be named an MVP, Coach of the Year, and Executive of the Year in the NBA.
Player profile.
Bird, a versatile wing man who played the power forward and small forward positions, is considered one of the greatest players of all time, to which his twelve All-Star team nominations are a testament. The sharpshooting Bird made his name stepping up his performance in critical situations, and is credited with a long list of dominating games, buzzer beaters and clutch defensive plays. He won two NBA Finals MVP and three regular-season MVP awards. He won them all in a row, a feat only shared by Bill Russell and Wilt Chamberlain.
Bird possessed an uncanny and unparalleled ability to anticipate and react to the strategies of his opponents. His talent for recognizing the moves of opponents and teammates prompted his first coach with the Celtics, Bill Fitch, to nickname him "Kodak", because he seemed to formulate mental pictures of every play that took place on the court.
Bird scored 24.3 points per game in his career on a high .496 field goal average, a stellar .886 free throw average (9th best all-time) and a 37.6 percentage on three-point shots. Bird was also a good rebounder (10.0 rebound career average) and an excellent playmaker (6.3 assist career average). His multidimensional game made him a consistent triple-double threat; Bird currently ranks fifth all-time in triple-doubles with 59, not including the 10 he recorded in the playoffs. Bird's lifetime player efficiency rating (PER) is 23.5, 18th all-time, a further testament to his all around game. Additionally, he is the only 20, 10, 5 player in NBA history (points, rebounds, assists per game) with a lifetime PRA rating (points + rebounds + assists per game) of 40.6, which is 8th all-time. Bird was the first player in NBA history to shoot 50% or better on field goals, 40% on three-pointers, and 90% on free-throws in a single NBA season while achieving the league minimum for makes in each category. Bird accomplished this feat twice and is second only to Steve Nash for seasons in the 50–40–90 club.
Bird is also remembered as an excellent defender. While he was neither fast nor quick-footed, and could not always shut down an individual player one-on-one, he consistently displayed a knack for anticipating the moves of his opponent, allowing him to intercept passes and create turnovers. His 1,556 career steals ranks 27th all-time. Unspectacular but effective defensive moves, such as jumping into a passing lane to make a steal or allowing his man to step past and drive to the hoop, then blocking the opponent's shot from behind, were staples of Bird's defensive game. In recognition of his defensive abilities, Bird was named to three All-Defensive Second Teams.
Bird's humble roots were the source of his most frequently used moniker, "The Hick From French Lick". Other observers called him "The Great White Hope". He has also acquired the nickname "Larry Legend".
Trash-talking.
Bird's competitive nature often emerged in nearly constant trash-talking on the court. Some notable examples follow:
Memorable moments.
Bird is remembered as one of the foremost clutch performers in the history of the NBA. Few players have performed as brilliantly in critical moments of games.

</doc>
<doc id="55030" url="http://en.wikipedia.org/wiki?curid=55030" title="Ogonek">
Ogonek

The ogonek (Polish: , "little tail", the diminutive of "ogon"; Lithuanian: "nosinė") is a diacritic hook placed under the lower right corner of a vowel in the Latin alphabet used in several European languages, and directly under a vowel in several Native American languages.
Use.
Example in Polish:
Example in Cayuga:
Example in Dogrib:
Example in Lithuanian:
Example in Elfdalian:
Values.
Nasalization.
The use of the ogonek to indicate nasality is common in the transcription of the indigenous languages of the Americas. This usage originated in the orthographies created by Christian missionaries to transcribe these languages. Later, the practice was continued by Americanist anthropologists and linguists who still follow this convention in phonetic transcription to the present day (see Americanist phonetic notation).
The ogonek is also used in academic transliteration of Old Church Slavonic. In Polish, Old Church Slavonic, Navajo, Western Apache, Chiricahua, Tłįchǫ Yatiì, Slavey, Dëne Sųłiné and Elfdalian it indicates that the vowel is nasalized. Even if "ę" is nasalized "e" in Polish, "ą" is nasalized "o" not "a" (this is so because of the vowel change — "ą" was a long nasal "a", which turned into short nasal "o", when the vowel quantity distinction disappeared).
Length.
In Lithuanian, it formerly indicated nasalization but is no longer distinctive and indicates that a vowel is long. The Lithuanian word for "ogonek" is "nosinė", which literally means "nasal".
Openness.
In Rheinische Dokumenta, it marks vowels which are more open than those denoted by their base letters Ää, Oo, Öö. Here it can be combined with umlaut marks in two cases.
Similar diacritics.
E caudata and o caudata.
The "E caudata" ("ę"), a symbol similar to an "e" with ogonek, evolved from a ligature of "a" and "e" in medieval scripts, in Latin and Irish palaeography. The "O caudata" of Old Norse (letter "ǫ", with "ǫ́") is used to write the open-mid back rounded vowel, /ɔ/. Medieval Nordic manuscripts show this "hook" in both directions, in combination with several vowels. Despite this distinction, the term "ogonek" is sometimes used in discussions of typesetting and encoding Norse texts, as "o caudata" is typographically identical to o with ogonek.
Cedilla and comma.
The ogonek is functionally equivalent to the cedilla and comma diacritics. If two of these three are used within the same orthography their respective use is restricted to certain classes of letters, i.e. usually the ogonek is used with vowels whereas the cedilla is applied to consonants. In handwritten text the marks may even look the same.
Typographical notes.
The ogonek should be almost the same size as a descender (in larger type sizes may be relatively quite shorter) and should not be confused with the cedilla or comma diacritic marks used in other languages.
When used for Native American languages, the ogonek should be placed directly under the letter rather than to the side as is the norm for European languages. European-style placement is acceptable when no other alternatives are available.
LaTeX2e.
In LaTeX2e, macro codice_1 will typeset a letter with ogonek, if it is supported by the font encoding, e.g. codice_2 will typeset "ą". (The default LaTeX OT1 encoding does not support it, but the newer T1 one does. It may be enabled by saying codice_3 in the preamble.)
However, codice_4 rather places the diacritic "right-aligned" with the carrying "e" (ę), suitably for Polish, while codice_5 horizontally "centers" the diacritic with respect to the carrier, suitably for Native American Languages as well as for e caudata and o caudata. So codice_6 better fits the latter purposes. Actually, codice_7 (for ǫ) is defined to result in codice_8, and codice_9 is defined to result in codice_10.
The package TIPA, activated by using the command "codice_11", offers a different way: "codice_12" will produce "ą".

</doc>
<doc id="55032" url="http://en.wikipedia.org/wiki?curid=55032" title="Outline of agriculture">
Outline of agriculture

The following outline is provided as an overview of and topical guide to agriculture:
Agriculture – cultivation of animals, plants, fungi and other life forms for food, fiber, and other products used to sustain life.
What "type" of thing is agriculture?
Agriculture can be described as all of the following:
Branches of agriculture.
By industry.
Farming.
Farming equipment.
Farm equipment – any kind of machinery used on a farm to help with farming.
Fishing.
Fishing – activity of trying to catch fish. Fish are normally caught in the wild. Techniques for catching fish include hand gathering, spearing, netting, angling and trapping.
Forestry.
Forestry – interdisciplinary profession embracing the science, art, and craft of creating, managing, using, and conserving forests and associated resources in a sustainable manner to meet desired goals, needs, and values for human benefit.
Ranching.
Ranching – practice of raising grazing livestock such as cattle or sheep for meat or wool.
Whaling.
Whaling – hunting of whales mainly for meat and oil.
Agricultural Disciplines.
Agricultural chemistry.
Agricultural chemistry – study of both chemistry and biochemistry which are important in agricultural production, the processing of raw products into foods and beverages, and in environmental monitoring and remediation.
Agricultural communication.
Agricultural communication – field of study and work that focuses on communication about agricultural related information among agricultural stakeholders and between agricultural and non-agricultural stakeholders.
Agricultural economics.
Agricultural economics – originally applied the principles of economics to the production of crops and livestock — a discipline known as agronomics. Agronomics was a branch of economics that specifically dealt with land usage. It focused on maximizing the crop yield while maintaining a good soil ecosystem. Throughout the 20th century the discipline expanded and the current scope of the discipline is much broader. Agricultural economics today includes a variety of applied areas, having considerable overlap with conventional economics.
Agricultural education.
Agricultural education – instruction about crop production, livestock management, soil and water conservation, and various other aspects of agriculture.Farmers acquire adequate knowledge required on the correct amount use of agrochemicals and other agriculture related technologies.
Agricultural universities and colleges – tertiary agricultural educational institutions around the world
currently edited by Mwita Raphael, student in the UoN.
Agricultural engineering.
Agricultural engineering – engineering discipline that applies engineering science and technology to agricultural production and processing.
Agricultural philosophy.
Agricultural philosophy – discipline devoted to the systematic critique of the philosophical frameworks (or ethical world views) that are the foundation for decisions regarding agriculture.
Agricultural policy.
Agricultural policy – set of laws relating to domestic agriculture and imports of foreign agricultural products. 
Agronomy.
Agronomy – science and technology of producing and using plants for food, fuel, feed, fiber, and reclamation.
Horticulture.
Horticulture – art, science, technology and business of intensive plant cultivation for human use.
Agricultural soil science.
Agricultural soil science – branch of soil science that deals with the study of edaphic conditions as they relate to the production of food and fiber.
Agroecology.
Agroecology – application of ecological principles to the production of food, fuel, fiber, and pharmaceuticals and the management of agroecosystems.
History of agriculture.
History of agriculture – developed at least 10,000 years ago, although some forms of agriculture such as forest gardening and fire-stick farming date back even earlier to prehistoric times.
Agriculturally based manufacturing industries.
Food industry.
Food industry – complex, global collective of diverse businesses that together supply much of the food energy consumed by the world population.
Pulp and paper industry.
Pulp and paper industry – comprises companies that use wood as raw material and produce pulp, paper, board and other cellulose-based products.

</doc>
<doc id="55033" url="http://en.wikipedia.org/wiki?curid=55033" title="Great Dividing Range">
Great Dividing Range

The Great Dividing Range, or the Eastern Highlands, is Australia's most substantial mountain range and the third longest land-based range in the world. The range stretches more than 3500 km from Dauan Island off the northeastern tip of Queensland, running the entire length of the eastern coastline through New South Wales, then into Victoria and turning west, before finally fading into the central plain at the Grampians in western Victoria. The width of the range varies from about 160 km to over 300 km.
The sharp rise between the coastal lowlands and the eastern uplands has affected Australia's climate, mainly due to orographic precipitation, and these areas of highest relief have revealed an impressive gorge country.
Terminology.
The Dividing Range does not consist of a single mountain range. It consists of a complex of mountain ranges, plateaus, upland areas and escarpments with an ancient and complex geological history. The physiographic division name for the landmass is called the "East Australian Cordillera". In some places the terrain is relatively flat, consisting of very low hills. Typically the highlands range from 300 m to 1,600 m in height.
The mountains and plateaus, which consist of limestones, sandstone, quartzite, schists and dolomite, have been created by faulting and folding processes.
The crest of the range is defined by the watershed or boundary between the drainage basins of rivers which drain directly eastward into the Pacific Ocean, or southward into Bass Strait, and those rivers which drain into the Murray–Darling river system towards the west and south. In the north, the rivers on the west side of the range drain towards the Gulf of Carpentaria.
The higher and more rugged parts of the "range" do not necessarily form part of the crest of the range, but may be branches and offshoots from it. The term "Great Dividing Range" may refer specifically to the watershed crest of the range, or to the entire upland complex including all of the hills and mountains between the east coast of Australia and the central plains and lowlands. At some places it can be up to 400 km wide. Notable ranges and other features which form part of the range complex have their own distinctive names.
History.
The Great Dividing Range was formed during the Carboniferous period—some 300 million years ago—when Australia collided with what is now parts of South America and New Zealand. The range has experienced significant erosion since. (See Geology of Australia.)
Prior to white settlement the ranges were home to Aboriginal Australian tribes. Evidence remains in some places of their occupation by decorated caves, campsites and trails used to travel between the coastal and inland regions.
After European settlement in 1788, the ranges were an obstacle to exploration and settlement by the British settlers. Although not high, parts of the highlands were very rugged. Crossing the Blue Mountains was particularly challenging due to the mistaken idea that the creeks should be followed rather than the ridges, and almost impenetrable, labyrinthine, sandstone mountains.
In 1813, a usable route was finally discovered directly westward from Sydney across the Blue Mountains to Bathurst by an expedition jointly led by Gregory Blaxland, William Lawson and William Charles Wentworth. They found a passage by following the top of a ridge. Towns in the Blue Mountains were later named after each of these men. This was the start of the development of the agricultural districts of inland New South Wales. A road was built to Blaxland by convicts within six months. Easier routes to inland New South Wales were discovered towards Goulburn to the southwest, and westwards from Newcastle.
Subsequent explorations were made across and around the ranges by Allan Cunningham, John Oxley, Hamilton Hume, Paul Edmund Strzelecki, Ludwig Leichhardt and Thomas Mitchell. These explorers were mainly concerned with finding good agricultural land.
By the late 1830s the most fertile rangelands adjacent to the mountains ranges had been explored and some settled. These included the Gippsland and Riverina regions in the south, up to the Liverpool Plains and the Darling Downs in the north.
Various road and railway routes were subsequently established through many parts of the ranges, although many areas remain remote to this day. For example, in eastern Victoria there is only one major road crossing the highlands from north to south.
Notable components.
Parts of the highlands consisting of relatively flat and, by Australian standards, well-watered land were developed for agricultural and pastoral uses. Such areas include the Atherton Tableland and Darling Downs in Queensland, and the Northern Tablelands, Southern Highlands and Southern Tablelands in New South Wales. Other parts of the highlands are too rugged for agriculture and have been used for forestry. Many parts of the highlands which were not developed are now included in National Parks.
All of mainland Australia's alpine areas, including its highest mountain, Mount Kosciuszko (2228 m AHD), are part of this range, called the Main Range. The highest areas in southern New South Wales and eastern Victoria are known as the Australian Alps.
The central core of the Great Dividing Range is dotted with hundreds of peaks and is surrounded by many smaller mountain ranges or spurs, canyons, valleys and plains of regional significance. Some of the major plains include the High Plains of South-Eastern Australia, the Southern Highlands the Central Highlands and Bogong High Plains of Victoria. Other tablelands considered part of the Great dividing range are the Atherton Tableland, Canberra wine region and the Southern Tablelands.
The Dandenong Ranges, Barrington Tops, Bunya Mountains, Blue Mountains, Liverpool Range, McPherson Ranges and the Moonbi Range are some of the smaller spurs and ranges that make up the greater dividing range. Other notable ranges and tablelands which form part of the Great Dividing Range include the Liverpool Range, Mount Royal Range and the Monaro District. Whilst some of the peaks of the highlands reach respectable heights of a little over 2,000 metres, the age of the range and its erosion mean that most of the mountains are not very steep, and virtually all peaks can be reached without mountaineering equipment.
In some areas, such as the Snowy Mountains, Victorian Alps, the Scenic Rim and the eastern escarpments of the New England region, the highlands form a significant barrier. The eastern escarpment is the site of many spectacular waterfalls which were formed by rivers plunging off the tablelands. In other areas the slopes are gentle and in places the range is barely perceptible.
Well known passes on the range include Coxs Gap, Cunninghams Gap, Dead Horse Gap, Nowlands Gap, and Spicers Gap.
Major cities located on the upland areas of the range include Canberra, Toowoomba and the outer suburbs of Sydney, Melbourne, Brisbane and Cairns in north Queensland. Many towns and cities are located on the range, and also in lowland areas and foothills adjacent to the highlands. There is a strong natural history and cultural attachment to the Dividing Range region in towns and on many, sometimes remote landholdings.
Some of the towns/cities located on the range include:
Water catchments.
The lower reaches are used for forestry, an activity that causes friction with conservationists. The ranges is also the source of virtually all of eastern Australia's water supply, both through runoff caught in dams, and throughout much of Queensland, through the Great Artesian Basin.
Valleys along the chain of mountains have yielded a water source for important reservoirs and water supply projects such as the Upper Nepean Scheme, Snowy Mountains Scheme and Warragamba Dam. The Bradfield Scheme has been mooted as a way to transport water from the tropics in coastal Queensland south to dryer regions.
The Great Dividing Range creates the drainage basins of the Australian south-east coast drainage division and the Australian north-east coast drainage division, whose water flows to the east coast and into the Pacific Ocean, Tasman Sea, and Bass Strait with the westerly Murray–Darling basin which flow inland, away from the coast into the interior plains.
Some of the rivers which flow west of the ranges includes the Condamine River, Flinders River, Herbert River, Lachlan River, Macdonald River, Macintyre River and Namoi River. Rivers that flow north into the Murray–Darling Basin from Victoria include the Goulburn, Mitta Mitta, Kiewa, Ovens, King, Loddon and Campaspe rivers. Rivers that flow east into the Pacific Ocean include the Brisbane River, Burdekin River, Clarence River, Hastings River, Hawkesbury River, Hunter River, Macleay River, Mary River, Richmond River, Shoalhaven River and the Snowy River. Those that flow south to the ocean in Victoria include the Snowy, Cann, Tambo, Mitchell, Latrobe, Thomson, Yarra, Werribee, Hopkins and Glenelg rivers.
Features.
At some high hill passes the range provides cool sites appropriate for vineyards.
Railways.
The engineers of early rail passages across the Great Dividing Range needed to find low sections of the range to cross, as well as suitable, low gradient paths up the mountains on either side. Rail passages include:
Road transport.
Many of Australia's highways such as the Alpine Way, Great Alpine Road, Hume Highway, Great Western Highway, Capricorn Highway, Cunningham Highway, New England Highway, Oxley Highway, Warrego Highway, Waterfall Way, Thunderbolts Way, the Calder Highway, the Western Highway, and the Murray Valley Highway traverse parts of the range.
Protected areas.
Much of the range lies within a succession of national parks and other reserves, most of the national parks are listed below, there are almost double the amount of state forests;

</doc>
<doc id="55034" url="http://en.wikipedia.org/wiki?curid=55034" title="Spine">
Spine

Spine or Spinal may refer to:

</doc>
<doc id="55036" url="http://en.wikipedia.org/wiki?curid=55036" title="Fragaria">
Fragaria

Fragaria is a genus of flowering plants in the rose family, Rosaceae, commonly known as strawberries for their edible fruits. There are more than 20 described species and many hybrids and cultivars. The most common strawberries grown commercially are cultivars of the garden strawberry, a hybrid known as "Fragaria" × "ananassa". Strawberries have a taste that varies by cultivar, and ranges from quite sweet to rather tart. Strawberries are an important commercial fruit crop, widely grown in all temperate regions of the world.
Description.
Strawberries are not true berries. The fleshy and edible part of the fruit is a receptacle, and the parts that are sometimes mistakenly called "seeds" are achenes.
Although it is commonly thought that strawberries get their name from straw being used as a mulch in cultivating the plants, the etymology of the word is uncertain.
Classification.
There are more than 20 different "Fragaria" species worldwide. Numbers of other species have been proposed, some of which are now recognized as subspecies. Key to the classification of strawberry species is recognizing that they vary in the number of chromosomes. There are seven basic "types" of chromosomes that they all have in common. However, they exhibit different polyploidy. Some species are diploid, having two sets of the seven chromosomes (14 chromosomes total). Others are tetraploid (four sets, 28 chromosomes total), hexaploid (six sets, 42 chromosomes total), octoploid (eight sets, 56 chromosomes total), or decaploid (ten sets, 70 chromosomes total).
As a rough rule (with exceptions), strawberry species with more chromosomes tend to be more robust and produce larger plants with larger berries.
Uncategorized hybrids.
"F. var. ‘Lipstick’", red-flowered runnering ornamental, sparse small globular fruits.
Ecology.
A number of species of butterflies and moths feed on strawberry plants: see list of Lepidoptera that feed on strawberry plants.
References.
Hogan, Sean (chief consultant), "Flora" (subtitle) "A Gardener’s Encyclopedia", (Portland, Oregon USA) Timber Press, 2003. ISBN 0-88192-538-1.

</doc>
<doc id="55037" url="http://en.wikipedia.org/wiki?curid=55037" title="Shellfish">
Shellfish

Shellfish is a culinary and fisheries term for exoskeleton-bearing aquatic invertebrates used as food, including various species of molluscs, crustaceans, and echinoderms. Although most kinds of shellfish are harvested from saltwater environments, some kinds are found in freshwater. In addition a few species of land crabs are eaten, for example "Cardisoma guanhumi" in the Caribbean.
Despite the name, shellfish are not a kind of fish, but are simply water-dwelling animals. Many varieties of shellfish (crustaceans in particular) are actually closely related to insects and arachnids, making up one of the main classes of the phylum Arthropoda. Cephalopods (squid, octopus, cuttlefish) and bivalves (clams, oysters) are molluscs, as are snails and slugs.
Familiar marine molluscs enjoyed as a food source by humans include many species of clams, mussels, oysters, winkles, and scallops. Some crustaceans commonly eaten are shrimp, lobster, crayfish, and crabs. Echinoderms are not as frequently harvested for food as molluscs and crustaceans, however sea urchin roe is quite popular in many parts of the world.
Most shellfish eat a diet composed primarily of phytoplankton and zooplankton.
Shellfish are among the most common food allergens.
Terminology.
The term "shellfish" is used both broadly and specifically. In common parlance, as in having "shellfish" for dinner, it can refer to anything from clams and oysters to lobster and shrimp. For regulatory purposes it is often narrowly defined as "filter-feeding molluscs" such as clams, mussels, and oyster to the exclusion of crustaceans and all else.
Although the term is primarily applied to marine species, edible freshwater invertebrates such as crayfish and river mussels are also sometimes grouped under the umbrella of "shellfish".
Although their shells may differ, all shellfish are invertebrates. As non-mammalian animals that spend their entire lives in water they are "fish" in an informal sense; however the term "finfish" is sometimes used to distinguish fish as animals "defined by having vertebrae" from shellfish in modern terminology.
The word "shellfish" is both singular and plural; the rarely used "shellfishes" is sometimes employed to distinguish among various types of shellfish.
Shellfish in various cuisines.
Archaeological finds has shown that humans have been making use of shellfish as a food item for hundreds of thousands of years. In the present, shellfish dishes are a feature of almost all the cuisines of the world, providing an important source of protein in many cuisines around the world, especially in the countries with coastal areas.
In Japan.
In the Japanese cuisine, chefs often use shellfish and their roe in different dishes. Sushi (vinegared rice, topped with other ingredients, including shellfish, fish, meat and vegetables) features both raw and cooked shellfish. Sashimi primarily consists of very fresh raw seafood, sliced into thin pieces. Both sushi and sashimi are served with soy sauce and wasabi paste (a Japanese horseradish root, a spice with extremely strong hot flavor), thinly-sliced pickled ginger root, and a simple garnish such as shiso (a kitchen herb, member of the mint family) or finely shredded daikon radish, or both.
In the United States.
Lobster in particular is a great delicacy in the United States, where families in the Northeast region make them into the centerpiece of a clam bake, usually for special occasions. Lobsters are eaten on much of the East Coast; the American lobster ranges from Newfoundland down to about the Carolinas, but is most often associated with Maine. A typical meal involves boiling the lobster with some slight seasoning and then serving it with drawn butter, baked potato, and corn on the cob.
Clamming is done both commercially and recreationally along the Northeast coastline of the US. Various type of clams are incorporated into the cuisine of New England. The soft-shelled clam is eaten either fried or steamed (and then called "steamers"). Many types of clams can be used for clam chowder, but the quahog, a hard shelled clam also known as a chowder clam, is often used because the long cooking time softens its tougher meat.
The Chesapeake Bay and Maryland region has generally been associated more with crabs, but in recent years the area has been trying to reduce its catch of blue crabs, as wild populations have been depleted. This has not, however, stemmed the demand: Maryland-style crabcakes are still a well known treat in crabhouses all over the bay, though the catch now comes from points farther south.
In the Southeast, and particularly the gulf states, shrimping is an important industry. Copious amounts of shrimp are harvested each year in the Gulf of Mexico and the Atlantic Ocean to satisfy a national demand for shrimp. Locally, prawns and shrimp are often deep fried; in the Cajun and Creole kitchens of Louisiana, shrimp and prawns are a common addition to traditional recipes like jambalaya and certain stews. Crawfish are a well known and much eaten delicacy here, often boiled in huge pots and heavily spiced.
In many major cities with active fishing ports, raw oyster bars are also a feature of shellfish consumption. When served freshly shucked (opened) and iced, one may find a liquid inside the shell, called the liquor. Some believe that oysters have the properties of an aphrodisiac.
Inter-tidal herbivorous shellfish such as mussels and clams can help people reach a healthy balance of omega-3 and omega-6 fats in their diets, instead of the current Western diets. For this reason, the eating of shellfish is often encouraged by dietitians.
Shellfish, however, are a rich source of the amino acid taurine.
Around the world.
Shellfish is a common part of indigenous cuisines throughout the globe.
Some popular dishes using shellfish:
Religious dietary restrictions.
The Bible forbids the consumption of shellfish in the Old Testament, particularly the books of Leviticus and Deuteronomy.
Toxic content.
Some shellfish, such as whelk, contain arsenic. A sample of whelk was found to have a total content of arsenic at 15.42 mg/kg of which 1% is inorganic arsenic.

</doc>
<doc id="55040" url="http://en.wikipedia.org/wiki?curid=55040" title="Reconstruction Era">
Reconstruction Era

In the history of the United States, the term Reconstruction Era has two senses: the first covers the complete history of the entire country from 1865 to 1877 following the Civil War; the second sense focuses on the transformation of the Southern United States from 1863 to 1877, as directed by Congress, with the reconstruction of state and society.
From 1863 to 1865, Presidents Abraham Lincoln and Andrew Johnson took moderate positions designed to bring the South back to normal as quickly as possible, while the Radical Republicans (as they called themselves) used Congress to block any moderate approaches, impose harsh terms, and upgrade the rights of the freedmen (former slaves). Johnson followed a lenient policy toward ex-Confederates much like Lincoln's. Lincoln's last speeches show that he was leaning toward supporting the enfranchisement of some freedmen, whereas Johnson was opposed to this.
Johnson's interpretations of Lincoln's policies prevailed until the Congressional elections of 1866 in the North, which enabled the Radicals to take control of policy, remove former Confederates from power, and enfranchise the freedmen. A Republican coalition came to power in nearly all the southern states and set out to transform the society by setting up a free labor economy, using the U.S. Army and the Freedmen's Bureau. The Bureau protected the legal rights of freedmen, negotiated labor contracts, and set up schools and even churches for them. Thousands of Northerners came South, as missionaries, teachers, businessmen and politicians; hostile elements called them "Carpetbaggers". Rebuilding the rundown railroad system was a major strategy, but it collapsed when a nationwide depression (called the Panic of 1873) struck the economy in 1873. The Radicals, frustrated by Johnson's opposition to Congressional Reconstruction, filed impeachment charges but the action failed by one vote in the Senate.
President Ulysses S. Grant supported Radical Reconstruction and enforced the protection of African Americans in the South through the use of the Force Acts passed by Congress. Grant suppressed the Ku Klux Klan, but was unable to resolve the escalating tensions inside the Republican party between the Carpetbaggers and the Scalawags (native whites in the South). Meanwhile self-styled Conservatives (in close cooperation with Democratic Party) strongly opposed Republican rule. They alleged widespread corruption by the Carpetbaggers, excessive state spending and ruinous taxes. The opposition violently counterattacked and regained power in each "redeemed" Southern state by 1877. Meanwhile public support for Reconstruction policies faded in the North, as voters decided the Civil War was over and slavery was dead. The Democrats, who strongly opposed Reconstruction, regained control of the House of Representatives in 1874; the presidential electoral vote in 1876 was very close and confused, forcing Congress to make the final decision. The deployment of the U.S. Army was central to the survival of Republican state governments; they collapsed when the Army was removed in 1877 as part of a Congressional bargain to elect Republican Rutherford B. Hayes as president.
Reconstruction was a significant chapter in the history of civil rights in the United States, but most historians consider it a failure because the South became a poverty-stricken backwater attached to agriculture, white Democrats re-established dominance through violence, intimidation and discrimination, forcing freedmen into second class with limited rights and utterly excluding them from politics. Historian Eric Foner argues, "What remains certain is that Reconstruction failed, and that for blacks its failure was a disaster whose magnitude cannot be obscured by the genuine accomplishments that did endure."
Dating the Reconstruction era.
In the different states Reconstruction began and ended at different times; federal Reconstruction finally ended with the Compromise of 1877. In recent decades most historians follow Foner (1988) in dating the Reconstruction of the South as starting in 1863 (with emancipation) rather than 1865; the usual ending has always been 1877. Reconstruction policies were debated in the North when the war began, and commenced in earnest after Lincoln's Emancipation Proclamation, issued on January 1, 1863.
Overview.
As Confederate states came back under control of the US Army, President Abraham Lincoln set up reconstructed governments in Tennessee, Arkansas, and Louisiana during the war. He experimented by giving land to former slaves in South Carolina. By fall 1865, the new President Andrew Johnson declared the war goals of national unity and the ending of slavery achieved and reconstruction completed. Republicans in Congress, refusing to accept Johnson's terms, rejected new members of Congress, some of whom had been high Confederate officials a few months before. Johnson broke with the Republicans after vetoing two key bills that supported the Freedman's Bureau and provided federal civil rights to the Freedmen. The 1866 Congressional elections turned on the issue of Reconstruction, and produced a sweeping Republican victory in the North. It gave the Radical Republicans enough control of Congress to override Johnson's vetoes and began what is called "Radical Reconstruction" in 1867.
Congress removed civilian governments in the South in 1867 and put the former Confederacy under the rule of the U.S. Army. The army conducted new elections in which the freed slaves could vote, while whites who had held leading positions under the Confederacy were temporarily denied the vote and were not permitted to run for office.
In ten states, coalitions of freedmen, recent black and white arrivals from the North (carpetbaggers), and white Southerners who supported Reconstruction (scalawags) cooperated to form Republican biracial state governments. They introduced various reconstruction programs including: funding public schools, establishing charitable institutions, raising taxes, and offering massive aid to support improved railroad transportation and shipping. Conservative opponents called the Republican regimes corrupt and instigated violence toward freedmen and whites who supported Reconstruction. Much of the violence was carried out by members of the Ku Klux Klan (KKK), a secret terrorist organization; this led to federal intervention by President Ulysses S. Grant in 1871 that suppressed the Klan. White Democrats, calling themselves "Redeemers", regained control state by state, sometimes using fraud and violence to control state elections. A deep national economic depression following the Panic of 1873 led to major Democratic gains in the North, the collapse of many railroad schemes in the South, and a growing sense of frustration in the North.
The end of Reconstruction was a staggered process, and the period of Republican control ended at different times in different states. With the Compromise of 1877, Army intervention in the South ceased and Republican control collapsed in the last three state governments in the South. This was followed by a period that white Southerners labeled Redemption, in which white-dominated state legislatures enacted Jim Crow laws and after 1890 disenfranchised most blacks and many poor whites through a combination of constitutional amendments and electoral laws. The white Democrat Southerners' memory of Reconstruction played a major role in imposing the system of white supremacy and second-class citizenship for blacks, known as the age of Jim Crow.
Purpose.
Reconstruction addressed how the eleven seceding states would regain what the Constitution calls a "republican form of government" and be reseated in Congress, the civil status of the former leaders of the Confederacy, and the Constitutional and legal status of freedmen, especially their civil rights and whether they should be given the right to vote. Intense controversy erupted throughout the South over these issues.
The laws and constitutional amendments that laid the foundation for the most radical phase of Reconstruction were adopted from 1866 to 1871. By the 1870s, Reconstruction had officially provided freedmen with equal rights under the constitution, and blacks were voting and taking political office. Republican legislatures, coalitions of whites and blacks, established the first public school systems and numerous charitable institutions in the South. White paramilitary organizations, especially the Ku Klux Klan and also the White League and Red Shirts formed with the political aim of driving out the Republicans. They also disrupted political organizing and terrorized blacks to bar them from the polls. President Grant used federal power to effectively shut down the KKK in the early 1870s, though the other, smaller, groups continued to operate. From 1873 to 1877, conservative whites (calling themselves "Redeemers") regained power in the Southern states. They joined the Bourbon wing of the national Democratic Party.
In the 1860s and 1870s the terms "radical" and "conservative" had distinctive meanings. "Conservative" was the name of a faction, often led by the planter class. Leaders who had been Whigs were committed to economic modernization, built around railroads, factories, banks and cities. Most of the "radical" Republicans in the North were men who believed in free enterprise and industrialization; most were also modernizers and former Whigs. The "Liberal Republicans" of 1872 shared the same outlook except they were especially opposed to the corruption they saw around President Grant, and believed that the goals of the Civil War had been achieved so that the federal military intervention could now end.
Passage of the 13th, 14th, and 15th Amendments is the constitutional legacy of Reconstruction. These Reconstruction Amendments established the rights that led to Supreme Court rulings in the mid-20th century that struck down school segregation. A "Second Reconstruction", sparked by the Civil Rights Movement, led to civil rights laws in 1964 and 1965 that ended segregation and opened the polls to blacks.
Most historians consider Reconstruction to be a failure. However, historian Mark Summers argues that:
Material devastation of the South in 1865.
Reconstruction played out against an economy in ruin. The Confederacy in 1861 had 297 towns and cities with a total population of 835,000 people; of these 162 with 681,000 people were at one point occupied by Union forces. Eleven were destroyed or severely damaged by war action, including Atlanta (with an 1860 population of 9,600), Charleston, Columbia, and Richmond (with prewar populations of 40,500, 8,100, and 37,900, respectively); the eleven contained 115,900 people in the 1860 census, or 14% of the urban South. The number of people who lived in the destroyed towns represented just over 1% of the Confederacy's combined urban and rural populations. The rate of damage in smaller towns was much lower—only 45 courthouses were burned out of a total of 830.
Farms were in disrepair, and the prewar stock of horses, mules and cattle was much depleted; two-fifths, or 40%, of the South's livestock had been killed. The South's farms were not highly mechanized, but the value of farm implements and machinery in the 1860 Census was $81 million and was reduced by two-fifths, or 40%, by 1870. The transportation infrastructure lay in ruins, with little railroad or riverboat service available to move crops and animals to market. Railroad mileage was located mostly in rural areas and over two-thirds of the South's rails, bridges, rail yards, repair shops and rolling stock were in areas reached by Union armies, which systematically destroyed what they could. Even in untouched areas, the lack of maintenance and repair, the absence of new equipment, the heavy over-use, and the deliberate relocation of equipment by the Confederates from remote areas to the war zone ensured the system would be ruined at war's end. Restoring the infrastructure — especially the railroad system — became a high priority for Reconstruction state governments.
The enormous cost of the Confederate war effort took a high toll on the South's economic infrastructure. The direct costs to the Confederacy in human capital, government expenditures, and physical destruction from the war totaled $3.3 billion. By 1865, the Confederate dollar was worthless due to high inflation, and people in the South had to resort to bartering services for goods, or else use scarce Union dollars. With the emancipation of the southern slaves, the entire economy of the South had to be rebuilt. Having lost their enormous investment in slaves, white planters had minimal capital to pay freedmen workers to bring in crops. As a result, a system of sharecropping was developed where landowners broke up large plantations and rented small lots to the freedmen and their families. The South was transformed from an elite minority of landed gentry slaveholders into a tenant farming agriculture system.
The end of the Civil War was accompanied by a large migration of new freed people to the cities. In the cities, African Americans were relegated to the lowest paying jobs such as unskilled and service labor. Men worked as rail workers, rolling and lumber mills workers, and hotel workers. The large population of slave artisans during the antebellum period had not been translated into a large number of freemen artisans during Reconstruction. Black women were largely confined to domestic work employed as cooks, maids, and child nurses. Others worked in hotels. A large number became laundresses. The dislocations had a severe negative impact on the black population, with a large amount of sickness and death. 
Over a quarter of Southern white men of military age — the backbone of the South's white workforce — died during the war, leaving countless families destitute. Per capita income for white southerners declined from $125 in 1857 to a low of $80 in 1879. By the end of the 19th century and well into the 20th century, the South was locked into a system of poverty. How much of this failure was caused by the war and by previous reliance on agriculture remains the subject of debate among economists and historians.
Restoring the South to the Union.
During the Civil War, the Radical Republican leaders argued that slavery and the Slave Power had to be permanently destroyed, and that all forms of Confederate nationalism had to be suppressed. Moderates said this could be easily accomplished as soon as Confederate armies surrendered and the Southern states repealed secession and accepted the 13th Amendment – most of which happened by December 1865.
President Lincoln was the leader of the moderate Republicans and wanted to speed up Reconstruction and reunite the nation painlessly and quickly. Lincoln formally began Reconstruction in late 1863 with his Ten percent plan, which went into operation in several states but which Radical Republicans opposed. Lincoln pocket vetoed the Radical plan, the Wade–Davis Bill of 1864, which was much more strict than the Ten-Percent Plan.
The opposing faction of Radical Republicans was skeptical of Southern intentions and demanded stringent federal action. Congressman Thaddeus Stevens of Pennsylvania and Senator Charles Sumner of Massachusetts led the Radicals. Sumner argued that secession had destroyed statehood but the Constitution still extended its authority and its protection over individuals, as in existing U.S. territories. Stevens and his followers viewed secession as having left the states in a status like new territories. The Republicans sought to prevent Southern politicians from "restoring the historic subordination of Negroes". Since slavery was abolished, the three-fifths compromise no longer applied to counting the population of blacks. After the 1870 census, the South would gain numerous additional representatives in Congress, based on the population of freedmen. One Illinois Republican expressed a common fear that if the South were allowed to simply restore its previous established powers, that the "reward of treason will be an increased representation".
Upon Lincoln's assassination in April 1865, Andrew Johnson of Tennessee, who had been elected with Lincoln in 1864 as vice president, became president. Johnson rejected the Radical program of Reconstruction and instead appointed his own governors and tried to finish reconstruction by the end of 1865. Thaddeus Stevens vehemently opposed President Johnson's plans for an abrupt end to Reconstruction, insisting that Reconstruction must "revolutionize Southern institutions, habits, and manners ... The foundations of their institutions ... must be broken up and relaid, or all our blood and treasure have been spent in vain." Johnson broke decisively with the Republicans in Congress when he vetoed the Civil Right Bill in early 1865. While Democrats cheered, the Republicans pulled together, passed the bill again, and overturned Johnson's repeat veto. Full-scale political warfare now existed between Johnson (now allied with the Democrats) and the Radical Republicans.
Congress rejected Johnson's argument that he had the war power to decide what to do, since the war was over. Congress decided it had the primary authority to decide how Reconstruction should proceed, because the Constitution stated the United States had to guarantee each state a republican form of government. The Radicals insisted that meant Congress decided how Reconstruction should be achieved. The issues were multiple: who should decide, Congress or the president? How should republicanism operate in the South? What was the status of the Confederate states? What was the citizenship status of the leaders of the Confederacy? What was the citizenship and suffrage status of freedmen?
The election of 1866 decisively changed the balance of power, giving the Republicans two-thirds majorities in both houses of Congress, and enough votes to overcome Johnson's vetoes. They moved to impeach Johnson because of his constant attempts to thwart Radical Reconstruction measures, by using the Tenure of Office Act. Johnson was acquitted by one vote, but he lost the influence to shape Reconstruction policy.
The Republican Congress established military districts in the South and used Army personnel to administer the region until new governments loyal to the Union could be established. Congress temporarily suspended the ability to vote of approximately 10,000 to 15,000 white men who had been Confederate officials or senior officers, while constitutional amendments gave full citizenship and suffrage to former slaves.
With the power to vote, freedmen started participating in politics. While many slaves were illiterate, educated blacks (including escaped slaves) moved down from the North to aid them, and natural leaders also stepped forward. They elected white and black men to represent them in constitutional conventions. A Republican coalition of freedmen, southerners supportive of the Union (derisively called scalawags by white Democrats), and northerners who had migrated to the South (derisively called carpetbaggers) — some of whom were returning natives, but were mostly Union veterans – organized to create constitutional conventions. They created new state constitutions to set new directions for southern states.
Loyalty.
The issue of loyalty emerged in the debates over the Wade–Davis Bill of 1864. The bill required voters to take the "ironclad oath", swearing they had never supported the Confederacy or been one of its soldiers. Pursuing a policy of "malice toward none" announced in his second inaugural address, Lincoln asked voters only to support the Union. The Radicals lost support following Lincoln's veto of the Wade–Davis Bill but regained strength after Lincoln's assassination in April 1865.
Suffrage.
Congress had to consider how to restore to full status and representation within the Union those southern states that had declared their independence from the United States and had withdrawn their representation. Suffrage for former Confederates was one of two main concerns. A decision needed to be made whether to allow just some or all former Confederates to vote (and to hold office). The moderates wanted virtually all of them to vote, but the Radicals resisted. They repeatedly tried to impose the ironclad oath, which would effectively have allowed no former Confederates to vote. Radical Republican leader Thaddeus Stevens proposed, unsuccessfully, that all former Confederates lose the right to vote for five years. The compromise that was reached disenfranchised many Confederate civil and military leaders. No one knows how many temporarily lost the vote, but one estimate was that it was as high as 10,000 to 15,000 out of a total white population of roughly eight million.
Second, and closely related, was the issue of whether the roughly four million freedmen should be allowed to vote. The issue was how to receive the four million former slaves as citizens. If they were to be fully counted as citizens, some sort of representation for apportionment of seats in Congress had to be determined. Before the war, the population of slaves had been counted as three-fifths of a corresponding number of free whites. By having four million freedmen counted as full citizens, the South would gain additional seats in Congress. If blacks were denied the vote and the right to hold office, then only whites would represent them. Many conservatives, including most white southerners, northern Democrats, and some northern Republicans, opposed black voting. Some northern states that had referenda on the subject limited the ability of their own small populations of blacks to vote.
Lincoln had supported a middle position to allow some black men to vote, especially army veterans. Johnson also believed that such service should be rewarded with citizenship. Lincoln proposed giving the vote to "the very intelligent, and especially those who have fought gallantly in our ranks." In 1864, Governor Johnson said, "The better class of them will go to work and sustain themselves, and that class ought to be allowed to vote, on the ground that a loyal negro is more worthy than a disloyal white man." As President in 1865, Johnson wrote to the man he appointed as governor of Mississippi, recommending, "If you could extend the elective franchise to all persons of color who can read the Constitution in English and write their names, and to all persons of color who own real estate valued at least two hundred and fifty dollars, and pay taxes thereon, you would completely disarm the adversary [Radicals in Congress], and set an example the other states will follow."
Charles Sumner and Thaddeus Stevens, leaders of the Radical Republicans, were initially hesitant to enfranchise the largely illiterate former slave population. Sumner preferred at first impartial requirements that would have imposed literacy restrictions on blacks and whites. He believed that he would not succeed in passing legislation to disfranchise illiterate whites who already had the vote.
In the South, many poor whites were illiterate as there was almost no public education before the war. In 1880, for example, the white illiteracy rate was about 25% in Tennessee, Kentucky, Alabama, South Carolina, and Georgia; and as high as 33% in North Carolina. This compares with the 9% national rate, and a black rate of illiteracy that was over 70% in the South. By 1900, however, with emphasis within the black community on education, the majority of blacks had achieved literacy.
Sumner soon concluded that "there was no substantial protection for the freedman except in the franchise." This was necessary, he stated, "(1) For his own protection; (2) For the protection of the white Unionist; and (3) For the peace of the country. We put the musket in his hands because it was necessary; for the same reason we must give him the franchise." The support for voting rights was a compromise between moderate and Radical Republicans.
The Republicans believed that the best way for men to get political experience was to be able to vote and to participate in the political system. They passed laws allowing all male freedmen to vote. In 1867, black men voted for the first time. Over the course of Reconstruction, more than 1,500 African Americans held public office in the South; some of them were men who had escaped to the North and gained educations, and returned to the South. They did not hold office in numbers representative of their proportion in the population, but often elected whites to represent them. The question of women's suffrage was also debated but was rejected.
From 1890 to 1908, southern states passed new constitutions and laws that disfranchised most blacks and tens of thousands of poor whites with new voter registration and electoral rules. When establishing new requirements such as subjectively administered literacy tests, in some states, they used "grandfather clauses" to enable illiterate whites to vote.
Southern Treaty Commission.
The Five Civilized Tribes that had been relocated to Indian Territory (now part of Oklahoma) held black slaves and signed treaties supporting the Confederacy. During the war, a war among pro- and anti-Union Indians had raged. Congress passed a statute that gave the President the authority to suspend the appropriations of any tribe if the tribe is "in a state of actual hostility to the government of the United States ... and, by proclamation, to declare all treaties with such tribe to be abrogated by such tribe"(25 USC Sec. 72).
As a component of Reconstruction, the Interior Department ordered a meeting of representatives from all Indian tribes which had affiliated with the Confederacy. The Council, the Southern Treaty Commission, was first held in Ft. Smith, Arkansas in September 1865, was attended by hundreds of Indians representing dozens of tribes. Over the next several years the commission negotiated treaties with tribes that resulted in additional relocations to Indian Territory and the de facto creation (initially by treaty) of an unorganized Oklahoma Territory.
Lincoln's presidential Reconstruction.
Preliminary events.
President Lincoln signed two Confiscation Acts into law, the first on August 6, 1861, and the second on July 17, 1862, safeguarding fugitive slaves from the Confederacy that came over into Union lines and giving them indirect emancipation if their masters continued insurrection against the United States. The laws allowed the confiscation of lands for colonization from those who aided and supported the rebellion. However, these laws had limited effect as they were poorly funded by Congress and poorly enforced by Attorney General Edward Bates.
In August 1861, Maj. Gen. John C. Frémont, Union commander of the Western Department, declared martial law in Missouri, confiscated Confederate property, and emancipated their slaves. President Lincoln immediately ordered Frémont to rescind his emancipation declaration stating, "I think there is great danger that ... the liberating slaves of traitorous owners, will alarm our Southern Union friends, and turn them against us – perhaps ruin our fair prospect for Kentucky." After Frémont refused to rescind the emancipation order, President Lincoln terminated him from active duty on November 2, 1861. Lincoln was concerned that border states would bolt from the Union if slaves were given their freedom. On May 26, 1862, Union Maj. Gen. David Hunter emancipated slaves in South Carolina, Georgia, and Florida stated all "persons ... heretofore held as slaves ... forever free." Lincoln, embarrassed by the order, rescinded Hunter's declaration and canceled the emancipations.
On April 16, 1862 Lincoln signed a bill into law outlawing slavery in Washington D.C. and freeing the estimated 3,500 slaves in the city and on June 19, 1862 he signed legislation outlawing slavery in all U.S. territories. In July 1862, under the authority of the Confiscation Acts and an amended Force Bill of 1795, he authorized the recruitment of freed slaves into the Union army and seizure of any Confederate property for military purposes.
Gradual emancipation and compensation.
In an effort to keep border states in the Union, President Lincoln as early as 1861 designed gradual compensated emancipation programs paid for by government bonds. Lincoln desired Delaware, Maryland, Kentucky, and Missouri to "adopt a system of gradual emancipation which should work the extinction of slavery in twenty years." On March 26, 1862 Lincoln met with Senator Charles Sumner and recommended that a special joint session of Congress be conveyed to discuss giving financial aid to any border states who initiated a gradual emancipation plan. In April 1862, the joint session of Congress met, however, the border states were not interested and did not make any response to Lincoln or any Congressional emancipation proposal. Lincoln advocated compensated emancipation during the 1865 River Queen steamer conference.
Colonization.
In August 1862, President Lincoln met with African-American leaders and urged them to colonize some place in Central America. Lincoln planned to free the Southern slaves in the Emancipation Proclamation and he was concerned that freedmen would not be well treated in the United States by Whites in both the North and South. Although Lincoln gave assurances that the United States government would support and protect any colonies, the leaders declined the offer of colonization. Many free blacks had been opposed to colonization plans in the past and wanted to remain in the United States. President Lincoln persisted in his colonization plan believing that emancipation and colonization were part of the same program. Lincoln was successful by April 1863 at sending black colonists to Haiti and 453 to Chiriqui in Central America; however, none of the colonies was able to remain self-sufficient. Frederick Douglass, a prominent 19th-century American civil rights activist, criticized that Lincoln was "showing all his inconsistencies, his pride of race and blood, his contempt for Negroes and his canting hypocrisy." African Americans, according to Douglass, wanted citizen rights rather than to be colonized. Historians debate if Lincoln gave up on African-American colonization at the end of 1863 or if he actually planned to continue this policy up until 1865.
Military governors installed.
Starting in March 1862, in an effort to forestall Reconstruction by the Radicals in Congress, President Lincoln installed military governors in certain rebellious states under Union military control. Although the states would not be recognized by the Radicals until an undetermined time, installation of military governors kept the administration of Reconstruction under Presidential control, rather than that of the increasingly unsympathetic Radical Congress. On March 3, 1862, Lincoln installed a loyalist Democrat Senator Andrew Johnson, as Military Governor with the rank of Brigadier General in his home state of Tennessee. In May 1862, Lincoln appointed Edward Stanly Military Governor of the coastal region of North Carolina with the rank of Brigadier General. Stanly resigned almost a year later when he angered Lincoln by closing two schools for black children in New Bern. After Lincoln installed Brigadier General George F. Sheply as Military Governor of Louisiana in May 1862, Sheply sent two anti-slavery representatives, Benjamin Flanders and Michael Hahn, elected in December 1862, to the House which capitulated and voted to seat them. In July 1862, Lincoln installed Colonel John S. Phelps as Military Governor of Arkansas, though he resigned soon after due to poor health.
Emancipation Proclamation.
In July 1862, President Lincoln became convinced that "a military necessity" was needed to strike at slavery in order to win the Civil War for the Union. The Confiscation Acts were only having a minimal effect to end slavery. On July 22, he wrote a first draft of the Emancipation Proclamation that freed the slaves in states in rebellion. After he showed his cabinet the document, slight alterations were made in the wording. Lincoln decided that the defeat of the Confederate invasion of the North at Antietam was enough of a battlefield victory to enable him to release the preliminary Emancipation Proclamation that gave the rebels 100 days to return to the Union or the actual Proclamation would be issued.
On January 1, 1863, the actual Emancipation Proclamation was issued, specifically naming ten states in which slaves would be "forever free". The proclamation did not name the states of Tennessee, Kentucky, Missouri, Maryland, and Delaware, and specifically excluded numerous counties in some other states. Eventually, as the Union Armies advanced into the Confederacy millions of slaves were set free. Many of these freedmen joined the Union army and fought in battles against the Confederate forces. Yet hundreds of thousands of freed slaves died during emancipation from illness that devastated army regiments. Freed slaves suffered from smallpox, yellow fever, and malnutrition.
Louisiana 10% electorate plan.
President Abraham Lincoln was concerned to effect a speedy restoration of the Confederate states to the Union after the Civil War. In 1863, President Lincoln proposed a moderate plan for the Reconstruction of the captured Confederate State of Louisiana. The plan granted amnesty to Rebels who took an oath of loyalty to the Union. Black Freedmen workers were tied to labor on plantations for one year at $10 a month pay. Only 10% of the state's electorate had to take the loyalty oath in order for the state to be readmitted into U.S. Congress. The state was required to abolish slavery in its new constitution. Identical Reconstruction plans would be adopted in Arkansas and Tennessee. By December 1864, the Lincoln plan of Reconstruction had been enacted in Louisiana and the legislature sent two Senators and five Representatives to take their seats in Washington. However, Congress refused to count any of the votes from Louisiana, Arkansas, and Tennessee, in essence rejecting Lincoln's moderate Reconstruction plan. Congress, at this time controlled by the Radicals, proposed the Wade–Davis Bill that required a majority of the state electorates to take the oath of loyalty to be admitted to Congress. Lincoln pocket-vetoed the bill and the rift widened between the moderates, who wanted to save the Union and win the war, and the Radicals, who wanted to effect a more complete change within Southern society. Frederick Douglass denounced Lincoln's 10% electorate plan as undemocratic since state admission and loyalty only depended on a minority vote.
Legalization of slave unions.
Before 1864, slave marriages had not been recognized legally; emancipation did not affect them. When freed, many former slaves made official marriages. Before emancipation, slaves could not enter into contracts, including the marriage contract. After emancipation, former slaves and whites both began to view the lack of officially recognized marriage for their unions as problematic. Not all free people formalized their unions. Some continued to have common-law marriages or community-recognized relationships. The acknowledgement of marriage by the state increased the state's recognition of freedpeople as legal actors and eventually helped make the case for parental rights for freedpeople against the practice of apprenticeship of black children. These children were legally taken away from their families under the guise of "providing them with guardianship and 'good' homes until they reached the age of consent at twenty-one" under acts such as the Georgia 1866 Apprentice Act. Such children were generally used as sources of unpaid labor.
Freedmen's Bureau.
On March 3, 1865 the Freedmen's Bureau Bill became law, sponsored by the Republicans to aid freedmen and white refugees. A federal Bureau was created to provide food, clothing, fuel, and advice on negotiating labor contracts. It attempted to oversee new relations between freedmen and their former masters in a free labor market. The Act, without deference to a person's color, authorized the Bureau to lease confiscated land for a period of three years and to sell it in portions of up to 40 acres per buyer. The Bureau was to expire one year after the termination of the War. Lincoln was assassinated before he could appoint a commissioner of the Bureau. A popular myth was that the Act offered 40 acres and a mule, or that slaves had been promised this.
With the help of the Bureau, the recently freed slaves began voting, forming political parties, and assuming the control of labor in many areas. The Bureau helped to start a change of power in the South that drew national attention from the Republicans in the North to the conservative Democrats in the South. This is especially evident in the election between Grant and Seymour (Johnson did not get the Democratic nomination), where almost 700,000 black voters voted and swayed the election 300,000 votes in Grant's favor.
Even with the benefits that it gave to the freedmen, the Freedmen's Bureau failed to protect and take care of former slaves in certain areas. Because the Bureau only provided help with labor, food, and housing, medical attention for the former slaves was severely lacking. Furthermore, neither the Bureau nor other government institutions were able to protect the slaves from groups like the KKK. Terrorizing freedmen for trying to vote, hold a political office, or own land, the KKK was the antithesis to the Freedmen's Bureau. Sadly, the Bureau seemed to be unable to address the issue of hate groups which permeated the South.
Bans color discrimination.
Other legislation was signed that broadened equality and rights for African Americans. Lincoln outlawed discrimination on account of color, in carrying U.S. mail, in riding on public street cars in Washington D.C., and in pay for soldiers.
February 1865 peace conference.
Lincoln and Secretary of State William H. Seward met with three southern representatives to discuss the peaceful reconstruction of the Union and the Confederacy on February 3, 1865 in Hampton Roads, Virginia. The southern delegation included Confederate vice-president, Alexander H. Stephens, John A. Campbell, and Robert M. T. Hunter. The southerners proposed the Union recognition of the Confederacy, a joint Union-Confederate attack on Mexico to oust dictator Maximillian, and an alternative subordinate status of servitude for blacks rather than slavery. Lincoln flatly denied recognition of the Confederacy, and said that the slaves covered by his Emancipation Proclamation would not be re-enslaved. He said that the Union States were about to pass the Thirteenth Amendment outlawing slavery. Lincoln urged the governor of Georgia to remove Confederate troops and "ratify this Constitutional Amendment "prospectively", so as to take effect—say in five years ... Slavery is doomed." Lincoln also urged compensated emancipation for the slaves as he thought the North should be willing to share the costs of freedom. Although the meeting was cordial, the parties did not settle on agreements.
Historical legacy debated.
Lincoln continued to advocate his Louisiana Plan as a model for all states up until his assassination on April 14, 1865. The plan successfully started the Reconstruction process of ratifying the Thirteenth Amendment in all states. Lincoln is typically portrayed as taking the moderate position and fighting the Radical positions. There is considerable debate on how well Lincoln, had he lived, would have handled Congress during the Reconstruction process that took place after the Civil War ended. One historical camp argues that Lincoln's flexibility, pragmatism, and superior political skills with Congress would have solved Reconstruction with far less difficulty. The other camp believes the Radicals would have attempted to impeach Lincoln, just as they did to his successor, Andrew Johnson, in 1868.
Johnson's presidential Reconstruction.
Northern anger over the assassination of Lincoln and the immense human cost of the war led to demands for punitive policies. Vice President Andrew Johnson had taken a hard line and spoke of hanging rebel Confederates, but when he succeeded Lincoln as President, Johnson took a much softer line, pardoning many Confederate leaders and former Confederates. Jefferson Davis was held in prison for two years, but other Confederate leaders were not. There were no treason trials. Only one person—Captain Henry Wirz, the commandant of the prison camp in Andersonville, Georgia—was executed for war crimes. Andrew Johnson's conservative view of Reconstruction did not include blacks or former slaves involvement in government and he refused to heed Northern concerns when southern state legislatures implemented Black Codes that set the status of the freedmen much lower than that of citizens.
Smith argues that, "Johnson attempted to carry forward what he considered to be Lincoln's plans for Reconstruction." McKitrick says that in 1865 Johnson had strong support in the Republican Party, "It was naturally from the great moderate sector of Unionist opinion in the North that Johnson could draw his greatest comfort." Billington says, " One faction, the Moderate Republicans under the leadership of Presidents Abraham Lincoln and Andrew Johnson, favored a mild policy toward the South." Lincoln biographers Randall and Current argued that:
Historians agree that President Johnson was an inept politician who lost all his advantages by his clumsy moves. He broke with Congress in early 1866 and then became defiant and tried to block enforcement of Reconstruction laws passed by the U.S. Congress. He was in constant conflict constitutionally with the Radicals in Congress over the status of freedmen and whites in the defeated South. Although resigned to the abolition of slavery, many former Confederates were unwilling to accept both social changes and political domination by former slaves. In the words of Benjamin F. Perry, President Johnson's choice as the provisional governor of South Carolina: "First, the Negro is to be invested with all political power, and then the antagonism of interest between capital and labor is to work out the result."
The fears, however, of the mostly conservative planter elite and other leading white citizens were partly assuaged by the actions of President Johnson, who ensured that a wholesale land redistribution from the planters to the freedman did not occur. President Johnson ordered that confiscated or abandoned lands administered by the Freedmen's Bureau would not be redistributed to the freedmen but be returned to pardoned owners. Land was returned that would have been forfeited under the Confiscation Acts passed by Congress in 1861 and 1862.
Freedmen and the enactment of Black Codes.
Southern state governments quickly enacted the restrictive "black codes". However, they were abolished in 1866 and seldom had effect, because the Freedmen's Bureau (not the local courts) handled the legal affairs of freedmen.
The Black Codes indicated the plans of the southern whites for the former slaves. The freedmen would have more rights than did free blacks before the war, but they still had only a limited set of second-class civil rights, no voting rights and no citizenship. They could not own firearms, serve on a jury in a lawsuit involving whites or move about without employment. The Black Codes outraged northern opinion. They were overthrown by the Civil Rights Act of 1866 that gave the freedmen full legal equality (except for the right to vote).
The freedmen, with the strong backing of the Freedmen's Bureau, rejected gang-labor work patterns that had been used in slavery. Instead of gang labor, freedpeople preferred family-based labor groups. They forced planters to bargain for their labor. Such bargaining soon led to the establishment of the system of sharecropping, which gave the freedmen greater economic independence and social autonomy than gang labor. However, because they lacked capital and the planters continued to own the means of production (tools, draft animals and land), the freedmen were forced into producing cash crops (mainly cotton) for the land-owners and merchants, and they entered into a crop-lien system. Widespread poverty, disruption to an agricultural economy too dependent on cotton, and the falling price of cotton, led within decades to the routine indebtedness of the majority of the freedmen, and poverty by many planters.
Northern officials gave varying reports on conditions for the freedmen in the South. One harsh assessment came from Carl Schurz, who reported on the situation in the states along the Gulf Coast. His report documented dozens of extra-judicial killings and claimed that hundreds or thousands more African Americans were killed.
The number of murders and assaults perpetrated upon Negroes is very great; we can form only an approximative estimate of what is going on in those parts of the South which are not closely garrisoned, and from which no regular reports are received, by what occurs under the very eyes of our military authorities. As to my personal experience, I will only mention that during my two days sojourn at Atlanta, one Negro was stabbed with fatal effect on the street, and three were poisoned, one of whom died. While I was at Montgomery, one negro was cut across the throat evidently with intent to kill, and another was shot, but both escaped with their lives. Several papers attached to this report give an account of the number of capital cases that occurred at certain places during a certain period of time. It is a sad fact that the perpetration of those acts is not confined to that class of people which might be called the rabble.
The report included sworn testimony from soldiers and officials of the Freedmen's Bureau. In Selma, Alabama, Major J.P. Houston noted that whites who killed twelve African Americans in his district never came to trial. Many more killings never became official cases. Captain Poillon described white patrols in southwestern Alabama
who board some of the boats; after the boats leave they hang, shoot, or drown the victims they may find on them, and all those found on the roads or coming down the rivers are almost invariably murdered. The bewildered and terrified freedmen know not what to do—to leave is death; to remain is to suffer the increased burden imposed upon them by the cruel taskmaster, whose only interest is their labor, wrung from them by every device an inhuman ingenuity can devise; hence the lash and murder is resorted to intimidate those whom fear of an awful death alone cause to remain, while patrols, Negro dogs and spies, disguised as Yankees, keep constant guard over these unfortunate people.
Much of the violence that was perpetrated against African Americans was shaped by gendered prejudices regarding African Americans. Black women were in a particularly vulnerable situation. To convict a white man of sexually assaulting black women in this period was exceedingly difficult. Black women were socially constructed as sexually avaricious and since they were portrayed as having little virtue, society held that they could not be raped. One report indicates two freedwomen, Frances Thompson and Lucy Smith, describe their violent sexual assault during the Memphis Riots of 1866. However, black women were vulnerable even in times of relative normalcy. Sexual assaults on African-American women were so pervasive, particularly on the part of their white employers, that black men sought to reduce the contact between white males and black females by having the women in their family avoid doing work that was closely overseen by whites. Black men were construed as being extremely sexually aggressive and their supposed or rumored threats to white women were often used as a pretext for lynching and castrations.
Moderate responses.
During fall 1865, out of response to the Black codes and worrisome signs of Southern recalcitrance, the Radical Republicans blocked the readmission of the former rebellious states to the Congress. Johnson, however, was content with allowing former Confederate states into the Union as long as their state governments adopted the 13th Amendment abolishing slavery. By December 6, 1865, the amendment was ratified and Johnson considered Reconstruction over. Johnson was following the moderate Lincoln Presidential Reconstruction policy to get the states readmitted as soon as possible.
Congress, however, controlled by the Radicals, had other plans. The Radicals were led by Charles Sumner in the Senate and Thaddeus Stevens in the House of Representatives. Congress, on December 4, 1865, rejected Johnson's moderate Presidential Reconstruction, and organized the Joint Committee on Reconstruction, a 15-member panel to devise reconstruction requirements for the Southern states to be restored to the Union.
In January 1866, Congress renewed the Freedmen's Bureau; however, Johnson vetoed the Freedmen's Bureau Bill in February 1866. Although Johnson had sympathies for the plights of the freedmen, he was against federal assistance. An attempt to override the veto failed on February 20, 1866. This veto shocked the Congressional Radicals. In response, both the Senate and House passed a joint resolution not to allow any Senator or Representative seat admittance until Congress decided when Reconstruction was finished.
Senator Lyman Trumbull of Illinois, leader of the moderate Republicans, took affront at the black codes. He proposed the first Civil Rights Law, because the abolition of slavery was empty if
laws are to be enacted and enforced depriving persons of African descent of privileges which are essential to freemen ... A law that does not allow a colored person to go from one county to another, and one that does not allow him to hold property, to teach, to preach, are certainly laws in violation of the rights of a freeman ... The purpose of this bill is to destroy all these discriminations.
The key to the bill was the opening section:
All persons born in the United States ... are hereby declared to be citizens of the United States; and such citizens of every race and color, without regard to any previous condition of slavery ... shall have the same right in every State ... to make and enforce contracts, to sue, be parties, and give evidence, to inherit, purchase, lease, sell, hold, and convey real and personal property, and to full and equal benefit of all laws and proceedings for the security of person and property, as is enjoyed by white citizens, and shall be subject to like punishment, pains, and penalties and to none other, any law, statute, ordinance, regulation, or custom to the Contrary notwithstanding.
The bill did not give Freedmen the right to vote. Congress quickly passed the Civil Rights bill; the Senate on February 2 voted 33–12; the House on March 13 voted 111–38.
Johnson's vetoes.
Although strongly urged by moderates in Congress to sign the Civil Rights bill, Johnson broke decisively with them by vetoing it on March 27, 1866. His veto message objected to the measure because it conferred citizenship on the freedmen at a time when eleven out of thirty-six states were unrepresented and attempted to fix by Federal law "a perfect equality of the white and black races in every State of the Union." Johnson said it was an invasion by Federal authority of the rights of the States; it had no warrant in the Constitution and was contrary to all precedents. It was a "stride toward centralization and the concentration of all legislative power in the national government."
The Democratic Party, proclaiming itself the party of white men, north and south, supported Johnson. However the Republicans in Congress overrode his veto (the Senate by the close vote of 33:15, the House by 122:41) and the Civil Rights bill became law. Congress also passed a toned-down Freedmen's Bureau Bill; Johnson quickly vetoed as he had done to the previous bill. Once again, however, Congress had enough support and overrode Johnson's veto.
The last moderate proposal was the Fourteenth Amendment, whose principal drafter was Representative John Bingham. It was designed to put the key provisions of the Civil Rights Act into the Constitution, but it went much further. It extended citizenship to everyone born in the United States (except visitors and Indians on reservations), penalized states that did not give the vote to freedmen, and most importantly, created new federal civil rights that could be protected by federal courts. It guaranteed the Federal war debt would be paid (and promised the Confederate debt would never be paid). Johnson used his influence to block the amendment in the states since three-fourths of the states were required for ratification (the amendment was later ratified.). The moderate effort to compromise with Johnson had failed, and a political fight broke out between the Republicans (both Radical and moderate) on one side, and on the other side, Johnson and his allies in the Democratic Party in the North, and the conservative groupings (which used different names) in each southern state.
Congress imposes Radical Reconstruction.
Concerned that President Johnson viewed Congress as an "illegal body" and wanted to overthrow the government, Republicans in Congress took control of Reconstruction policies after the election of 1866. Johnson ignored the policy mandate, and he openly encouraged southern states to deny ratification of the 14th Amendment (except for Tennessee, all former Confederate states did refuse to ratify, as did the border states of Delaware, Maryland and Kentucky). Radical Republicans in Congress, led by Stevens and Sumner, opened the way to suffrage for male freedmen. They were generally in control, although they had to compromise with the moderate Republicans (the Democrats in Congress had almost no power). Historians generally refer to this period as "Radical Reconstruction."
The South's white leaders, who held power in the immediate postwar era before the vote was granted to the freedmen, renounced secession and slavery, but not white supremacy. People who had previously held power were angered in 1867 when new elections were held. New Republican lawmakers were elected by a coalition of white Unionists, freedmen and northerners who had settled in the South. Some leaders in the South tried to accommodate to new conditions.
Constitutional amendments.
Three Constitutional amendments, known as the Reconstruction Amendments, were adopted. The 13th Amendment abolishing slavery was ratified in 1865. The 14th Amendment was proposed in 1866 and ratified in 1868, guaranteeing United States citizenship to all persons born or naturalized in the United States and granting them federal civil rights. The 15th Amendment, proposed in late February 1869 and passed in early February 1870, decreed that the right to vote could not be denied because of "race, color, or previous condition of servitude". The amendment did not declare the vote an unconditional right; it prohibited these types of discrimination. States would still determine voter registration and electoral laws. The amendments were directed at ending slavery and providing full citizenship to freedmen. Northern Congressmen believed that providing black men with the right to vote would be the most rapid means of political education and training.
Many blacks took an active part in voting and political life, and rapidly continued to build churches and community organizations. Following Reconstruction, white Democrats and insurgent groups used force to regain power in the state legislatures, and pass laws that effectively disfranchised most blacks and many poor whites in the South. Around the start of the 20th century, from 1890 to 1910, southern states passed new constitutions that completed disfranchisement of blacks. U.S. Supreme Court rulings on these provisions upheld many of these new southern constitutions and laws, and most blacks were prevented from voting in the South until the 1960s. Full federal enforcement of the Fourteenth and Fifteenth Amendments did not occur until after passage of legislation in the mid-1960s as a result of the African-American Civil Rights Movement (1955–1968).
For details, see:
Statutes.
The Reconstruction Acts as originally passed, were initially called the legislation was enacted by the 39th Congress, on March 2, 1867. It was vetoed by President Johnson, and the veto overridden by two-thirds majority, in both the House and the Senate, the same day. Congress also clarified the scope of the federal writ of habeas corpus to allow federal courts to vacate unlawful state court convictions or sentences in 1867 (28 U.S.C. §2254).
Military reconstruction.
With the Radicals in control, Congress passed the Reconstruction Acts on July 19, 1867. The first Reconstruction Act, authored by Oregon Sen. George H. Williams, a Radical Republican, placed ten Confederate states under military control, grouping them into five military districts:
20,000 U.S. troops were deployed to enforce the Act.
Tennessee was not made part of a military district (having already been readmitted to the Union), and therefore federal controls did not apply.
The ten Southern state governments were re-constituted under the direct control of the United States Army. One major purpose was to recognize and protect the right of African Americans to vote. There was little or no combat, but rather a state of martial law in which the military closely supervised local government, supervised elections, and tried to protect office holders and freedmen from violence. Blacks were enrolled as voters; former Confederate leaders were excluded for a limited period. No one state was entirely representative. Randolph Campbell describes what happened in Texas:
The first critical step ... was the registration of voters according to guidelines established by Congress and interpreted by Generals Sheridan and Charles Griffin. The Reconstruction Acts called for registering all adult males, white and black, except those who had ever sworn an oath to uphold the Constitution of the United States and then engaged in rebellion ... Sheridan interpreted these restrictions stringently, barring from registration not only all pre-1861 officials of state and local governments who had supported the Confederacy but also all city officeholders and even minor functionaries such as sextons of cemeteries. In May Griffin ... appointed a three-man board of registrars for each county, making his choices on the advice of known scalawags and local Freedmen's Bureau agents. In every county where practicable a freedman served as one of the three registrars ... Final registration amounted to approximately 59,633 whites and 49,479 blacks. It is impossible to say how many whites were rejected or refused to register (estimates vary from 7,500 to 12,000), but blacks, who constituted only about 30 percent of the state's population, were significantly overrepresented at 45 percent of all voters.
All Southern states were readmitted to representation in Congress by the end of 1870, the last being Georgia. All but 500 top Confederate leaders were pardoned when President Grant signed the Amnesty Act of 1872.
Politics.
Grant: the Radical President.
During the Civil War, many in the North believed that fighting for the Union was a noble cause – for the preservation of the Union and the end of slavery. After the war ended, with the North victorious, the fear among Radicals was that President Johnson too quickly assumed that slavery and Confederate nationalism were dead and that the southern states could return. The Radicals sought out a candidate for President who represented their viewpoint.
In 1868, the Republicans unanimously chose Ulysses S. Grant to be the Republican Presidential candidate. Grant won favor with the Radicals after he allowed Edwin M. Stanton, a Radical, to be reinstated as Secretary of War. As early as 1862, during the Civil War, Grant had appointed the Ohio military chaplain John Eaton to protect and gradually incorporate refugee slaves in west Tennessee and northern Mississippi into the Union War effort, and pay them for their labor. It was the beginning of his vision for the Freedmen's Bureau. Grant opposed President Johnson by supporting the Reconstruction Acts passed by the Radicals.
Immediately upon Inauguration in 1869, Grant bolstered Reconstruction by prodding Congress to readmit Virginia, Mississippi, and Texas into the Union, while ensuring their constitutions protected every citizen's voting rights. Grant met with prominent black leaders for consultation, and signed a bill into law that guaranteed equal rights to both blacks and whites in Washington D.C. In Grant's two terms he strengthened Washington's legal capabilities. He worked with Congress to create the Department of Justice and Office of Solicitor General, led by Attorney General Amos Akerman and the first Solicitor General Benjamin Bristow, who both prosecuted thousands of Klansmen under the Force Acts. Grant sent additional federal troops to nine South Carolina counties to suppress Klan violence in 1871. In 1872, Grant was the first American President to legally recognize an African-American governor, P. B. S. Pinchback of Louisiana. Grant also used military pressure to ensure that African Americans could maintain their new electoral status; won passage of the Fifteenth Amendment giving African Americans the right to vote; and signed the Civil Rights Act of 1875 giving people access to public facilities regardless of race. To counter vote fraud in the Democratic stronghold of New York City, Grant sent in tens of thousands of armed, uniformed federal marshals and other election officials to regulate the 1870 and subsequent elections. Democrats across the North then mobilized to defend their base and attacked Grant's entire set of policies. On October 21, 1876 President Grant deployed troops to protect black and white Republican voters in Petersburg, Virginia.
Grant's support from Congress and the nation declined due to scandals within his administration and the political resurgence of the Democrats in the North and South. By 1870, most Republicans felt the war goals had been achieved, and they turned their attention to other issues such as economic policies.
Congressional investigation (1871–1872).
On April 20, 1871, the U.S. Congress launched a 21-member investigation committee on the status of the Southern Reconstruction states: North Carolina, South Carolina, Georgia, Mississippi, Alabama, and Florida. Congressional members on the committee included Rep. Benjamin Butler, Sen. Zachariah Chandler, and Sen. Francis P. Blair. Subcommittee members traveled into the South to interview the people living in their respective states. Those interviewed included top-ranking officials, such as Wade Hampton, former South Carolina Gov. James L. Orr, and Nathan B. Forrest, a former Confederate general and (alleged) prominent Ku Klux Klan leader (Forrest denied in his Congressional testimony being a member). Others southerners interviewed included farmers, doctors, merchants, teachers, and clergymen. The committee heard numerous reports of white violence against blacks, while many whites denied Klan membership or knowledge of violent activities. The majority report by Republicans concluded that the government would not tolerate any Southern "conspiracy" to resist violently the Congressional Reconstruction. The committee completed its 13-volume report in February 1872. While Grant had been able to suppress the KKK through the Force Acts, other paramilitary insurgents organized, including the White League in 1874, active in Louisiana; and the Red Shirts, with chapters active in Mississippi and the Carolinas. They used intimidation and outright attacks to run Republicans out of office and repress voting by blacks, leading to white Democrats regaining power by the elections of the mid-to-late 1870s.
African-American officeholders.
Republicans took control of all Southern state governorships and state legislatures, except for Virginia. The Republican coalition elected numerous African Americans to local, state, and national offices; though they did not dominate any electoral offices, black men as representatives voting in state and federal legislatures marked a drastic social change. At the beginning of 1867, no African American in the South held political office, but within three or four years "about 15 percent of the officeholders in the South were black—a larger proportion than in 1990." In 1860 blacks were the majority of the population in Mississippi and South Carolina, 47% in Louisiana, 45% in Alabama, and 44% in Georgia and Florida, so their political influence was still far less than their percentage of the population.
About 137 black officeholders had lived outside the South before the Civil War. Some who had escaped from slavery to the North and had become educated returned to help the South advance in the postwar era. Others were free blacks before the war, who had achieved education and positions of leadership elsewhere. Other African-American men who served were already leaders in their communities, including a number of preachers. As happened in white communities, not all leadership depended upon wealth and literacy.
There were few African Americans elected or appointed to national office. African Americans voted for both white and black candidates. The Fifteenth Amendment to the United States Constitution guaranteed only that voting could not be restricted on the basis of race, color or previous condition of servitude. From 1868 on, campaigns and elections were surrounded by violence as white insurgents and paramilitary tried to suppress the black vote, and fraud was rampant. Many Congressional elections in the South were contested. Even states with majority African-American population often elected only one or two African-American representatives to Congress. Exceptions included South Carolina; at the end of Reconstruction, four of its five Congressmen were African American.
Social and economic factors.
Organized religion.
Freedmen were very active in forming their own churches, mostly Baptist or Methodist, and giving their ministers both moral and political leadership roles. In a process of self-segregation, practically all blacks left white churches so that few racially integrated congregations remained (apart from some Catholic churches in Louisiana). Four main groups competed with each other across the South to form new Methodist churches composed of freedmen. They were the African Methodist Episcopal Church; the African Methodist Episcopal Zion Church; the Colored Methodist Episcopal Church (which was sponsored by the white Methodist Episcopal Church, South) and the well-funded Methodist Episcopal Church (Northern white Methodists). By 1871 the Northern Methodists had 88,000 black members in the South, and had opened numerous schools for them.
Blacks in the South were a core element of the Republican Party and their ministers had powerful political roles that were distinctive since they did not depend on white support, in contrast to teachers, politicians, businessmen, and tenant farmers. Acting on the principle as stated by Charles H. Pearce, an AME minister in Florida: "A man in this State cannot do his whole duty as a minister except he looks out for the political interests of his people," over 100 black ministers were elected to state legislatures during Reconstruction, as well as several to Congress and one, Hiram Revels, to the U.S. Senate.
In a highly controversial move, the Northern Methodists used the Army to seize control of Methodist churches in large cities, over the vehement protests of the Southern Methodists. Historian Ralph Morrow reports:
Across the North most evangelical denominations, especially the Methodists, Congregationalists and Presbyterians, as well as the Quakers, were strong supporters of Radical policies. The focus on social problems paved the way for the Social Gospel movement. Matthew Simpson, a Methodist Bishop, played a leading role in mobilizing the Northern Methodists for the cause. His biographer calls him the "High Priest of the Radical Republicans." The Methodist Ministers Association of Boston, meeting two weeks after Lincoln's assassination, called for a hard line against the Confederate leadership:
The denominations all sent missionaries, teachers and activists to the South to help the Freedmen. Only the Methodists made many converts, however. Activists sponsored by Northern Methodist Church played a major role in the Freedmen's Bureau, notably in such key educational roles as the Bureau's state superintendent or assistant superintendent of education for Virginia, Florida, Alabama and South Carolina.
Many Americans interpreted great events in religious terms. Historian Wilson Fallin contrasts the interpretation of Civil War and Reconstruction in white versus black Baptist sermons in Alabama. White Baptists expressed the view that:
In sharp contrast, Black Baptists interpreted the Civil War, emancipation and Reconstruction as:
Public schools.
Historian James D. Anderson argues that the freed slaves were the first Southerners "to campaign for universal, state-supported public education." Blacks in the Republican coalition played a critical role in establishing the principle in state constitutions for the first time during congressional Reconstruction. Some slaves had learned to read from white playmates or work colleagues before formal education was allowed by law; African Americans started "native schools" before the end of the war; Sabbath schools were another widespread means that freedmen developed to teach literacy. When they gained suffrage, black politicians took this commitment to public education to state constitutional conventions.
The Republicans created a system of public schools, which were segregated by race everywhere except New Orleans. Generally, elementary and a few secondary schools were built in most cities, and occasionally in the countryside, but the South had few cities.
The rural areas faced many difficulties opening and maintaining public schools. In the country, the public school was often a one-room affair that attracted about half the younger children. The teachers were poorly paid, and their pay was often in arrears. Conservatives contended the rural schools were too expensive and unnecessary for a region where the vast majority of people were cotton or tobacco farmers. They had no vision of a better future for their residents. One historian found that the schools were less effective than they might have been because "poverty, the inability of the states to collect taxes, and inefficiency and corruption in many places prevented successful operation of the schools." After Reconstruction ended and the whites disfranchised the blacks and imposed Jim Crow, they consistently underfunded black institutions, including the schools.
After the war, northern missionaries founded numerous private academies and colleges across the South for freedmen. In addition, every state founded state colleges for freedmen, such as Alcorn State University in Mississippi. The normal schools and state colleges produced generations of teachers who were integral to the education of African-American children under the segregated system. By the end of the century, the majority of African Americans were literate.
In the late 19th century, the federal government established land grant legislation to provide funding for higher education across the United States. Learning that blacks were excluded from land grant colleges in the South, in 1890, the federal government insisted that southern states establish black state institutions as land grant colleges to provide for black higher education, in order to continue to receive funds for their already established white schools. Some states classified their black state colleges as land grant institutions. Former Congressman John Roy Lynch wrote, "there are very many liberal, fair-minded and influential Democrats in the State [Mississippi] who are strongly in favor of having the State provide for the liberal education of both races."
Railroad subsidies and payoffs.
Every Southern state subsidized railroads, which modernizers felt could haul the South out of isolation and poverty. Millions of dollars in bonds and subsidies were fraudulently pocketed. One ring in North Carolina spent $200,000 in bribing the legislature and obtained millions in state money for its railroads. Instead of building new track, however, it used the funds to speculate in bonds, reward friends with extravagant fees, and enjoy lavish trips to Europe. Taxes were quadrupled across the South to pay off the railroad bonds and the school costs. There were complaints among taxpayers, because taxes had historically been low, since there was so little commitment to public works or public education. Taxes historically had been much lower than in the North, reflecting a lack of government investment by the communities. Nevertheless thousands of miles of lines were built as the Southern system expanded from 11,000 miles (17,700 km) in 1870 to 29,000 miles (46,700 km) in 1890. The lines were owned and directed overwhelmingly by Northerners. Railroads helped create a mechanically skilled group of craftsmen and broke the isolation of much of the region. Passengers were few, however, and apart from hauling the cotton crop when it was harvested, there was little freight traffic. As Franklin explains, "numerous railroads fed at the public trough by bribing legislators ... and through the use and misuse of state funds." The effect, according to one businessman, "was to drive capital from the State, paralyze industry, and demoralize labor."
Taxation during Reconstruction.
Reconstruction changed the means of taxation in the South. In the U.S. from the earliest days until today, a major source of state revenue was the property tax. In the South, wealthy landowners were allowed to self-assess the value of their own land. These fraudulent assessments were almost valueless, and pre-war property tax collections were lacking due to property value misrepresentation. State revenues came from fees and from sales taxes on slave auctions. Some states assessed property owners by a combination of land value and a capitation tax, a tax on each worker employed. This tax was often assessed in a way to discourage a free labor market, where a slave was assessed at 75 cents, while a free white was assessed at a dollar or more, and a free African American at $3 or more. Some revenue also came from poll taxes. These taxes were more than poor people could pay, with the designed and inevitable consequence that they did not vote.
During Reconstruction, the state legislature mobilized to provide for public need more than had previous governments: establishing public schools and investing in infrastructure, as well as charitable institutions such as hospitals and asylums. The needed to increase taxes which were abnormally low. The planters had provided privately for their own needs. There was some fraudulent spending in the postwar years; a collapse in state credit because of huge deficits, forced the states to increase property tax rates. In places, the rate went up to ten times higher—despite the poverty of the region. The planters had not invested in infrastructure and much had been destroyed during the war. In part, the new tax system was designed to force owners of large plantations with huge tracts of uncultivated land either to sell or to have it confiscated for failure to pay taxes. The taxes would serve as a market-based system for redistributing the land to the landless freedmen and white poor. Mississippi, for instance, was mostly frontier, with 90% of the bottomlands in the interior undeveloped.
The following table shows property tax rates for South Carolina and Mississippi. Note that many local town and county assessments effectively doubled the tax rates reported in the table. These taxes were still levied upon the landowners' own sworn testimony as to the value of their land, which remained the dubious and exploitable system used by wealthy landholders in the South well into the 20th century.
Called upon to pay taxes on their property, essentially for the first time, angry plantation owners revolted. The conservatives shifted their focus away from race to taxes. Former Congressman John R. Lynch, a black Republican leader from Mississippi, later wrote, 
Ending Reconstruction.
Southern Democrats.
While the "Scalawag" element of Republican whites supported measures for black civil rights, the conservative whites typically opposed these measures. Some supported armed attacks to suppress black power. They self-consciously defended their own actions within the framework of an Anglo-American discourse of resistance against tyrannical government, and they broadly succeeded in convincing many fellow white citizens says Steedman.
The opponents of Reconstruction formed state political parties, affiliated with the national Democratic party and often named the "Conservative party." They supported or tolerated violent paramilitary groups, such as the White League in Louisiana and the Red Shirts in Mississippi and the Carolinas, that assassinated and intimidated both black and white Republican leaders at election time. Historian George C. Rable called such groups the "military arm of the Democratic Party." By the mid-1870s, the Conservatives and Democrats had aligned with the national Democratic Party, which enthusiastically supported their cause even as the national Republican Party was losing interest in Southern affairs. Historian Walter Lynwood Fleming, associated with the Dunning School, describes mounting anger of Southern whites:
The Negro troops, even at their best, were everywhere considered offensive by the native whites ... The Negro soldier, impudent by reason of his new freedom, his new uniform, and his new gun, was more than Southern temper could tranquilly bear, and race conflicts were frequent.
Often, these white Southerners identified as the "Conservative Party" or the "Democratic and Conservative Party" in order to distinguish themselves from the national Democratic Party and to obtain support from former Whigs. These parties sent delegates to the 1868 Democratic National Convention and abandoned their separate names by 1873 or 1874.
Most [white] members of both the planter/business class and common farmer class of the South opposed black power, carpetbaggers and military rule, and sought white supremacy. Democrats nominated blacks for political office and tried to steal other blacks from the Republican side. When these attempts to combine with the blacks failed, the planters joined the common farmers in simply trying to displace the Republican governments. The planters and their business allies dominated the self-styled "conservative" coalition that finally took control in the South. They were paternalistic toward the blacks but feared they would use power to raise taxes and slow business development.
Fleming described the first results of the insurgent movement as "good," and the later ones as "both good and bad." According to Fleming (1907), the KKK "quieted the Negroes, made life and property safer, gave protection to women, stopped burnings, forced the Radical leaders to be more moderate, made the Negroes work better, drove the worst of the Radical leaders from the country and started the whites on the way to gain political supremacy." The evil result, Fleming said, was that lawless elements "made use of the organization as a cloak to cover their misdeeds ... the lynching habits of today [1907] are largely due to conditions, social and legal, growing out of Reconstruction." Historians have noted that the peak of lynchings took place years after Reconstruction ended as whites were imposing Jim Crow laws and that they were more often used to keep black men down, with a rate associated with settlement of sharecropper accounts at the end of the season, than for any other reason.
Ellis Paxson Oberholtzer (a northern scholar) in 1917 explained:
Outrages upon the former slaves in the South there were in plenty. Their sufferings were many. But white men, too, were victims of lawless violence, and in all portions of the North and the late "rebel" states. Not a political campaign passed without the exchange of bullets, the breaking of skulls with sticks and stones, the firing of rival club-houses. Republican clubs marched the streets of Philadelphia, amid revolver shots and brickbats, to save the negroes from the "rebel" savages in Alabama ... The project to make voters out of black men was not so much for their social elevation as for the further punishment of the Southern white people—for the capture of offices for Radical scamps and the entrenchment of the Radical party in power for a long time to come in the South and in the country at large.
As Reconstruction continued, whites accompanied elections with increased violence in an attempt to run Republicans out of office and suppress black voting. The victims of this violence were overwhelmingly African American, as in the Colfax Massacre of 1873. After federal suppression of the Klan in the early 1870s, white insurgent groups tried to avoid open conflict with federal forces. In 1874 in the Battle of Liberty Place, the White League entered New Orleans with 5,000 members and defeated the police and militia, to occupy federal offices for three days in an attempt to overturn the disputed government of William Kellogg, but retreated before federal troops reached the city. None were prosecuted. Their election-time tactics included violent intimidation of African-American and Republican voters prior to elections while avoiding conflict with the U.S. Army or the state militias and then withdrawing completely on election day. Conservative reaction continued in both the north and south; the "white liners" movement to elect candidates dedicated to white supremacy reached as far as Ohio in 1875.
Redemption 1873–77.
Republicans split nationally: election of 1872.
As early as 1868 Supreme Court Chief Justice Salmon P. Chase, a leading Radical during the war, concluded that:
Congress was right in not limiting, by its reconstruction acts, the right of suffrage to whites; but wrong in the exclusion from suffrage of certain classes of citizens and all unable to take its prescribed retrospective oath, and wrong also in the establishment of despotic military governments for the States and in authorizing military commissions for the trial of civilians in time of peace. There should have been as little military government as possible; no military commissions; no classes excluded from suffrage; and no oath except one of faithful obedience and support to the Constitution and laws, and of sincere attachment to the constitutional Government of the United States.
By 1872, President Ulysses S. Grant had alienated large numbers of leading Republicans, including many Radicals by the corruption of his administration and his use of federal soldiers to prop up Radical state regimes in the South. The opponents, called "Liberal Republicans", included founders of the party who expressed dismay that the party had succumbed to corruption. They were further wearied by the continued insurgent violence of whites against blacks in the South, especially around every election cycle, which demonstrated the war was not over and changes were fragile. Leaders included editors of some of the nation's most powerful newspapers. Charles Sumner, embittered by the corruption of the Grant administration, joined the new party, which nominated editor Horace Greeley. The badly organized Democratic party also supported Greeley.
Grant made up for the defections by new gains among Union veterans and by strong support from the "Stalwart" faction of his party (which depended on his patronage), and the Southern Republican parties. Grant won with 55.6% of the vote to Greeley's 43.8%. The Liberal Republican party vanished and many former supporters—even former abolitionists—abandoned the cause of Reconstruction.
Republican coalition splinters in South.
In the South, political–racial tensions built up inside the Republican party as they were attacked by the Democrats. In 1868, Georgia Democrats, with support from some Republicans, expelled all 28 black Republican members from the state house, arguing blacks were eligible to vote but not to hold office. In several states, the more conservative scalawags fought for control with the more radical carpetbaggers and usually lost. In Mississippi, the conservative faction led by scalawag James Lusk Alcorn was decisively defeated by the radical faction led by carpetbagger Adelbert Ames. The party lost support steadily as many scalawags left it; few recruits were acquired. Meanwhile, the freedmen were demanding a bigger share of the offices and patronage, squeezing out carpetbagger allies but never commanding the numbers equivalent to their population proportion. By the mid-1870s, "The hard realities of Southern political life had taught the lesson that black constituents needed to be represented by black officials." The financial depression increased the pressure on Reconstruction governments, dissolving progress.
Finally, some of the more prosperous freedmen were joining the Democrats, as they were angered at the failure of the Republicans to help them acquire land. The South was "sparsely settled"; only 10% of Louisiana was cultivated, and 90% of Mississippi bottomland were undeveloped in areas away from the riverfronts, but freedmen often did not have the stake to get started. They hoped government would help them acquire land which they would work. Only South Carolina created any land redistribution, establishing a land commission and resettling about 14,000 freedmen families and some poor whites on land purchased by the state.
Although historians such as W. E. B. Du Bois celebrated a cross-racial coalition of poor whites and blacks, such coalitions rarely formed in these years. Writing in 1915, former Congressman Lynch, recalling his experience as a black leader in Mississippi, explained that,
While the colored men did not look with favor upon a political alliance with the poor whites, it must be admitted that, with very few exceptions, that class of whites did not seek, and did not seem to desire such an alliance.
Lynch reported that poor whites resented the job competition from freedmen. Furthermore, the poor whites
with a few exceptions, were less efficient, less capable, and knew less about matters of state and governmental administration than many of the former slaves ... As a rule, therefore, the whites that came into the leadership of the Republican party between 1872 and 1875 were representatives of the most substantial families of the land.
Democrats try a "New Departure".
By 1870, the Democratic–Conservative leadership across the South decided it had to end its opposition to Reconstruction and black suffrage to survive and move on to new issues. The Grant administration had proven by its crackdown on the Ku Klux Klan that it would use as much federal power as necessary to suppress open anti-black violence. Democrats in the North concurred with these Southern Democrats. They wanted to fight the Republican Party on economic grounds rather than race. The New Departure offered the chance for a clean slate without having to re-fight the Civil War every election. Furthermore, many wealthy Southern landowners thought they could control part of the newly enfranchised black electorate to their own advantage.
Not all Democrats agreed; an insurgent element continued to resist Reconstruction no matter what. Eventually, a group called "Redeemers" took control of the party in the Southern states. They formed coalitions with conservative Republicans, including scalawags and carpetbaggers, emphasizing the need for economic modernization. Railroad building was seen as a panacea since northern capital was needed. The new tactics were a success in Virginia where William Mahone built a winning coalition. In Tennessee, the Redeemers formed a coalition with Republican governor DeWitt Senter. Across the South, some Democrats switched from the race issue to taxes and corruption, charging that Republican governments were corrupt and inefficient. With continuing decrease in cotton prices, taxes squeezed cash-poor farmers who rarely saw $20 in currency a year but had to pay taxes in currency or lose their farm. But major planters, who had never paid taxes before, often recovered their property even after confiscation.
In North Carolina, Republican Governor William Woods Holden used state troops against the Klan, but the prisoners were released by federal judges. Holden became the first governor in American history to be impeached and removed from office. Republican political disputes in Georgia split the party and enabled the Redeemers to take over.
In the lower South, violence increased as new insurgent groups arose, including the Red Shirts in Mississippi and the Carolinas, and the White League in Louisiana. The disputed election in Louisiana in 1872 found both Republican and Democratic candidates holding inaugural balls while returns were reviewed. Both certified their own slates for local parish offices in many places, causing local tensions to rise. Finally, Federal support helped certify the Republican as governor.
Slates for local offices were certified by each candidate. In rural Grant Parish in Red River Valley, freedmen fearing a Democratic attempt to take over the parish government reinforced defenses at the small Colfax courthouse in late March. White militias gathered from the area a few miles outside the settlement. Rumors and fears abounded on both sides. William Ward, an African-American Union veteran and militia captain, mustered his company in Colfax and went to the courthouse. On Easter Sunday, April 13, 1873, the whites attacked the defenders at the courthouse. There was confusion about who shot one of the white leaders after an offer by the defenders to surrender. It was a catalyst to mayhem. In the end, three whites died and 120–150 blacks were killed, some 50 that evening while being held as prisoners. The disproportionate numbers of black to white fatalities and documentation of brutalized bodies are why contemporary historians call it the Colfax Massacre rather than the Colfax Riot, as it was known locally.
This marked the beginning of heightened insurgency and attacks on Republican officeholders and freedmen in Louisiana and other Deep South states. In Louisiana, Judge T. S. Crawford and District Attorney P. H. Harris of the 12th Judicial District were shot off their horses and killed from ambush October 8, 1873, while going to court. One widow wrote to the Department of Justice that her husband was killed because he was a Union man and "... of the efforts made to screen those who committed a crime ..."
In the North, a live-and-let-live attitude made elections more like a sporting contest. But in the Deep South, many white citizens had not reconciled with the defeat of the war or the granting of citizenship to freedmen. As an Alabama scalawag explained,
Panic of 1873.
The Panic of 1873 (a depression) hit the Southern economy hard and disillusioned many Republicans who had gambled that railroads would pull the South out of its poverty. The price of cotton fell by half; many small landowners, local merchants and cotton factors (wholesalers) went bankrupt. Sharecropping for black and white farmers became more common as a way to spread the risk of owning land. The old abolitionist element in the North was aging away, or had lost interest, and was not replenished. Many carpetbaggers returned to the North or joined the Redeemers. Blacks had an increased voice in the Republican Party, but across the South it was divided by internal bickering and was rapidly losing its cohesion. Many local black leaders started emphasizing individual economic progress in cooperation with white elites, rather than racial political progress in opposition to them, a conservative attitude that foreshadowed Booker T. Washington.
Nationally, President Grant was blamed for the depression; the Republican Party lost 96 seats in all parts of the country in the 1874 elections. The Bourbon Democrats took control of the House and were confident of electing Samuel J. Tilden president in 1876. President Grant was not running for re-election and seemed to be losing interest in the South. States fell to the Redeemers, with only four in Republican hands in 1873, Arkansas, Louisiana, Mississippi and South Carolina; Arkansas then fell after the violent Brooks–Baxter War in 1874 ripped apart the Republican party there.
Violence.
Political violence was endemic in Louisiana. In 1874 the white militias coalesced into paramilitary organizations such as the White League, first in parishes of the Red River Valley. The new organization operated openly and had political goals: the violent overthrow of Republican rule and suppression of black voting. White League chapters soon rose in many rural parishes, receiving financing for advanced weaponry from wealthy men. In the Coushatta Massacre in 1874, the White League assassinated six white Republican officeholders and five to twenty black witnesses outside Coushatta, Red River Parish. Four of the white men were related to the Republican representative of the parish, who was married to a local woman; three were native to the region.
Later in 1874 the White League mounted a serious attempt to unseat the Republican governor of Louisiana, in a dispute that had simmered since the 1872 election. It brought 5000 troops to New Orleans to engage and overwhelm forces of the Metropolitan Police and state militia to turn Republican Governor William P. Kellogg out of office and seat John McEnery. The White League took over and held the state house and city hall, but they retreated before the arrival of reinforcing Federal troops. Kellogg had asked for reinforcements before, and Grant finally responded, sending additional troops to try to quell violence throughout plantation areas of the Red River Valley, although 2,000 troops were already in the state.
Similarly, the Red Shirts, another paramilitary group, arose in 1875 in Mississippi and the Carolinas. Like the White League and White Liner rifle clubs, to which 20,000 men belonged in North Carolina alone, these groups operated as a "military arm of the Democratic Party", to restore white supremacy.
Democrats and many northern Republicans agreed that Confederate nationalism and slavery were dead—the war goals were achieved—and further federal military interference was an undemocratic violation of historic Republican values. The victory of Rutherford Hayes in the hotly contested Ohio gubernatorial election of 1875 indicated his "let alone" policy toward the South would become Republican policy, as happened when he won the 1876 Republican nomination for president.
An explosion of violence accompanied the campaign for the Mississippi's 1875 election, in which Red Shirts and Democratic rifle clubs, operating in the open, threatened or shot enough Republicans to decide the election for the Democrats. Hundreds of black men were killed. Republican Governor Adelbert Ames asked Grant for federal troops to fight back; Grant initially refused, saying public opinion was "tired out" of the perpetual troubles in the South. Ames fled the state as the Democrats took over Mississippi.
The campaigns and elections of 1876 were marked by additional murders and attacks on Republicans in Louisiana, North and South Carolina, and Florida. In South Carolina the campaign season of 1876 was marked by murderous outbreaks and fraud against freedmen. Red Shirts paraded with arms behind Democratic candidates; they killed blacks in the Hamburg and Ellenton SC massacres; and one historian estimated 150 blacks were killed in the weeks before the 1876 election across South Carolina. Red Shirts prevented almost all black voting in two majority-black counties. The Red Shirts were also active in North Carolina.
Election of 1876.
Reconstruction continued in South Carolina, Louisiana and Florida until 1877. The elections of 1876 were accompanied by heightened violence across the Deep South. A combination of ballot stuffing and intimidating blacks suppressed their vote even in majority black counties. The White League was active in Louisiana. After Republican Rutherford Hayes won the disputed 1876 presidential election, the national Compromise of 1877 was reached.
The white Democrats in the South agreed to accept Hayes's victory if he withdrew the last Federal troops. By this point, the North was weary of insurgency. White Democrats controlled most of the Southern legislatures and armed militias controlled small towns and rural areas. Blacks considered Reconstruction a failure because the Federal government withdrew from enforcing their ability to exercise their rights as citizens.
Hayes ends Reconstruction.
 On January 29, 1877 President Grant signed the Electoral Commission Act that set up a 15-member commission to settle the disputed 1876 election of 8 Republicans and 7 Democrats. The Electoral Commission awarded Rutherford B. Hayes the electoral votes he needed; Congress certified he had won by one electoral vote. The Democrats had little leverage—they could delay block Hayes' election but they could not put their man (Tilden) in the White House. However they agreed not to block Hayes' inauguration based on a "back room" deal. Key to this deal was the understanding that federal troops would no longer interfere in southern politics despite substantial election-associated violence against blacks. The Southern states indicated that they would protect the lives of African Americans although this obviously turned out to be far from reliable. Hayes's friends also let it be known that he would promote Federal aid for internal improvements, including help for a railroad in Texas (this never happened) and name a Southerner to his cabinet (this did happen). With the end to the political role of Northern troops, the President had no method to enforce Reconstruction, thus this "back room" deal signaled the end of American Reconstruction.
After assuming office on March 4, 1877, President Hayes removed troops from the capitals of the remaining Reconstruction states, Louisiana and South Carolina, allowing the Redeemers to have full control of these states. President Grant had already removed troops from Florida, before Hayes was inaugurated, and troops from the other Reconstruction states had long since been withdrawn. Hayes appointed David M. Key from Tennessee, a Southern Democrat, to the position of Postmaster General. By 1879, thousands of African-American "exodusters" packed up and headed to new opportunities in Kansas.
The Democrats gained control of the Senate, and had complete control of Congress, having taken over the House in 1875. Hayes vetoed bills from the Democrats that outlawed the Republican Force Acts; however, with the military underfunded, Hayes could not adequately enforce these laws. Blacks remained involved in Southern politics, particularly in Virginia, which was run by the biracial Readjuster Party.
Numerous blacks were elected to local office through the 1880s, and in the 1890s in some states, biracial coalitions of Populists and Republicans briefly held control of state legislatures. In the last decade of the 19th century, southern states elected five black US Congressmen before disfranchising constitutions were passed throughout the former Confederacy.
Legacy and historiography.
The interpretation of Reconstruction has been a topic of controversy. Nearly all historians hold that Reconstruction ended in failure but for different reasons.
The first generation of Northern historians believed that the former Confederates were traitors and Johnson was their ally who threatened to undo the Union's constitutional achievements. By the 1880s, however, Northern historians argued that Johnson and his allies were not traitors but had blundered badly in rejecting the 14th Amendment and setting the stage for Radical Reconstruction.
The black leader Booker T. Washington, who grew up in West Virginia during Reconstruction, concluded later that, "the Reconstruction experiment in racial democracy failed because it began at the wrong end, emphasizing political means and civil rights acts rather than economic means and self-determination." His solution was to concentrate on building the economic infrastructure of the black community, in part by his leadership and the southern Tuskegee Institute.
Dunning School: 1900 to 1920s.
The Dunning School of scholars were trained at the history department of Columbia University under Professor William A. Dunning analyzed Reconstruction as a failure after 1866 for different reasons. They claimed that Congress took freedoms and rights from qualified whites and gave them to unqualified blacks who were being duped by corrupt "carpetbaggers and scalawags." As T. Harry Williams (who was a sharp critic of the Dunning school) notes, the Dunningites portrayed the era in stark terms:
Reconstruction was a battle between two extremes: the Democrats, as the group which included the vast majority of the whites, standing for decent government and racial supremacy, versus the Republicans, the Negroes, alien carpetbaggers, and renegade scalawags, standing for dishonest government and alien ideals. These historians wrote literally in terms of white and black.
Revisionists and Beardians, 1930s–1940s.
In the 1930s, "revisionism" became popular among scholars. As disciples of Charles A. Beard, revisionists focused on economics, downplaying politics and constitutional issues. the central figure was a young scholar at the University Wisconsin, Howard K. Beale, who in his PhD dissertation, finished in 1924, developed a complex new interpretation of Reconstruction. The Dunning School portrayed Freedmen as mere pawns in the hands of the Carpetbaggers. Beale argued that the Carpetbaggers themselves were pawns in the hands of northern industrialists, who were the real villains of Reconstruction. These industrialists had taken control of the nation during the Civil War, and set up high tariffs to protect their profits, as well as a lucrative national banking system and a railroad network fueled by government subsidies and secret payoffs. The return to power of the southern whites would seriously threaten all their gains, and so the ex-Confederates had to be kept out of power. The tool used by the industrialists was the combination of the Northern Republican Party and sufficient Southern support using Carpetbaggers and black voters. The rhetoric of civil rights for blacks, and the dream of equality, was rhetoric designed to fool idealistic voters. Beale called it "claptrap," arguing, "Constitutional discussions of the rights of the negro, the status of Southern states, the legal position of ex-rebels, and the powers of Congress and the president determined nothing. They were pure sham."
President Andrew Johnson had tried, and failed, to stop the juggernaut of the industrialists. The Dunning school had praised Johnson for upholding the rights of the white men in the South and endorsing white supremacy. Beale was not a racist, and indeed was one of the most vigorous historians working for black civil rights in the 1930s and 1940s. In his view, Johnson was not a hero for his racism, but rather for his forlorn battle against the industrialists.Charles A. Beard and Mary Beard had already published "The Rise of American Civilization" (1927) three years before Beale, and had given very wide publicity to a similar theme. The Beard-Beale interpretation of Reconstruction became known as "revisionism," and replaced the Dunning school for most historians, until the 1950s.
The Beardian interpretation of the causes of the Civil War downplayed slavery, abolitionism, and issues of morality. It ignored constitutional issues of states rights and even ignored American nationalism as the force that finally led to victory in the war. Indeed the ferocious combat itself was passed over as merely an ephemeral event. Much more important was the calculus of class conflict, as the Beards explained in "The Rise of American Civilization" (1927), the Civil War was really a:
The Beards were especially interested in the Reconstruction era, as the industrialists of the Northeast and the farmers of the West cashed in on their great victory over the southern aristocracy. Historian Richard Hofstadter paraphrases the Beards as arguing that in victory:
Wisconsin historian William Hesseltine added the point that the Northeastern businessmen wanted to control the Southern economy directly, which they did through ownership of the railroads. The Beard-Beale interpretation of the monolithic Northern industrialists fell apart in the 1950s when it was closely examined by numerous historians, including Robert P. Sharkey, Irwin Unger, and Stanley Coben. The younger scholars conclusively demonstrated that there was no unified economic policy on the part of the dominant Republican Party. Some wanted high tariffs and some low. Some wanted Greenbacks and others wanted gold. There was no conspiracy to use Reconstruction to impose any such unified economic policy on the nation. Northern businessmen were widely divergent on monetary or tariff policy, and seldom paid attention to Reconstruction issues. Furthermore, the rhetoric on behalf of the rights of the Freedman was not claptrap but deeply held and very serious political philosophy.
Black historians.
The black scholar W. E. B. Du Bois, in his "", published in 1935, compared results across the states to show achievements by the Reconstruction legislatures and to refute claims about wholesale African-American control of governments. He showed black contributions, as in the establishment of universal public education, charitable and social institutions and universal suffrage as important results, and he noted their collaboration with whites. He also pointed out that whites benefited most by the financial deals made, and he put excesses in the perspective of the war's aftermath. He noted that despite complaints, several states kept their Reconstruction constitutions for nearly a quarter of a century. Despite receiving favorable reviews, his work was largely ignored by white historians of his time.
Neo-Abolitionists.
In the 1960s neoabolitionist historians emerged, led by John Hope Franklin, Kenneth Stampp, Leon Litwack, and Eric Foner. Influenced by the Civil Rights Movement, they rejected the Dunning school and found a great deal to praise in Radical Reconstruction. Foner, the primary advocate of this view, argued that it was never truly completed, and that a Second Reconstruction was needed in the late 20th century to complete the goal of full equality for African Americans. The neo-abolitionists followed the revisionists in minimizing the corruption and waste created by Republican state governments, saying it was no worse than Boss Tweed's ring in New York City.
Instead, they emphasized that suppression of the rights of African Americans was a worse scandal and a grave corruption of America's republican ideals. They argued that the tragedy of Reconstruction was not that it failed because blacks were incapable of governing, especially as they did not dominate any state government, but that it failed because whites raised an insurgent movement to restore white supremacy. White elite-dominated state legislatures passed disfranchising constitutions from 1890 to 1908 that effectively barred most blacks and many poor whites from voting. This disfranchisement affected millions of people for decades into the 20th century, and closed African Americans and poor whites out of the political process in the South.
Re-establishment of white supremacy meant that within a decade African Americans were excluded from virtually all local, state and federal governance in all states of the South." Lack of representation meant that they were treated as second-class citizens, with schools and services consistently underfunded in segregated societies, no representation on juries or in law enforcement, and bias in other legislation. It was not until the Civil Rights Movement and the passage in 1964 and 1965 of Federal legislation that outlawed segregation and restored the suffrage under what is sometimes referred to as the "Second Reconstruction."
In 1990 Eric Foner concluded that from the black point of view, "Reconstruction must be judged a failure." Foner stated Reconstruction was "a noble if flawed experiment, the first attempt to introduce a genuine inter-racial democracy in the United States". The many factors contributing to the failure included: lack of a permanent federal agency "specifically" designed for the enforcement of civil rights; the Morrison R. Waite Supreme Court decisions that dismantled previous congressional civil rights legislation; and the economic reestablishment of conservative white planters in the South by 1877. Historian William McFeely explained that although the constitutional amendments and civil rights legislation on their own merit were remarkable achievements, no permanent government agency whose specific purpose was civil rights enforcement had been created.
More recent work by Nina Silber, David W. Blight, Cecelia O'Leary, Laura Edwards, LeeAnn Whites and Edward J. Blum, has encouraged greater attention to race, religion and issues of gender while at the same time pushing the "end" of Reconstruction to the end of the 19th century, while monographs by Charles Reagan Wilson, Gaines Foster, W. Scott Poole and Bruce Baker have offered new views of the Southern "Lost Cause".
Dating the end of the Reconstruction era.
While 1877 is the usual date given for the end of Reconstruction, some historians extend the era to the 1890s.
The "failure" issue.
Reconstruction is unanimously considered a failure, though the reason for this is a matter of controversy.
Historian Donald R. Shaffer maintained that the gains during Reconstruction for African Americans were not entirely extinguished. The legalization of African-American marriage and family and the independence of black churches from white denominations were a source of strength during the Jim Crow era. Reconstruction was never forgotten among the black community and remained as a source of inspiration. The system of share-cropping allowed blacks a considerable amount of freedom as compared to slavery.
In popular culture.
As a journalist writing as Joe Harris for the "Atlanta Constitution", mostly after Reconstruction, Joel Chandler Harris tried to advance racial and sectional reconciliation in the late 19th century. He supported the editor Henry Grady's vision of a New South, while Grady was editor from 1880 to 1889. Harris wrote many editorials encouraging southern acceptance of the changed conditions and some Northern influence, although he also asserted his belief that it should proceed under white supremacy.
In popular literature two early 20th-century novels by Thomas Dixon—"The Clansman" (1905) and "The Leopard's Spots: A Romance of the White Man's Burden – 1865–1900" (1902)— romanticized white resistance to Northern/black coercion, hailing vigilante action by the KKK. Dixon's "The Clansmen" was adapted for the screen in D. W. Griffith's anti-Republican movie "The Birth of a Nation" (1915), considered to contribute to the 20th-century revival of the KKK. Many other authors romanticized the benevolence of slavery and the elite world of the antebellum plantations in memoirs and histories published in the late nineteenth and early twentieth centuries, and the United Daughters of the Confederacy promoted influential works by women in these genres.
Reconstruction state-by-state – significant dates.
Only Georgia has a separate article about its experiences under Reconstruction. The other state names below link to a specific section in the state history article about the Reconstruction era.
Bibliography.
Secondary sources.
For much more detail see 
Newspapers and magazines.
</dl>

</doc>
<doc id="55042" url="http://en.wikipedia.org/wiki?curid=55042" title="Bo Hansson">
Bo Hansson

Bo Hansson (April 10, 1943 – April 23, 2010) was a Swedish musician best known for his four instrumental albums released in the 1970s.
Early life and musical career.
He spent his early life in a remote village in the pine forests of northern Sweden, but a change in his parents' fortunes forced a move to Stockholm and they were forced to leave the young Hansson behind, in the care of family friends. As a teenager he joined his parents in Stockholm, where he soon became interested in the burgeoning rock and roll scene and taught himself to play the guitar, before joining the band, Rock-Olga.
After the rock and roll craze gave way to jazz and blues in the late fifties, he joined 'Slim' Notini's Blues Gang as a guitarist. Hansson was able to move on and form his own blues group The Merrymen, who supported The Rolling Stones on an early Scandinavian tour.
In 1966, Hansson saw American jazz organist Jack McDuff perform at Stockholm's Gyllene Cirkeln Club, and was so captivated by the performance that he decided to leave The Merrymen to expand his musical horizons. Encouraged by fellow Merryman Bill Öhrström, he eventually acquired his own Hammond organ. Öhrström became an A&R man and producer at Polydor Sweden, and introduced Hansson to other musicians, one of whom was drummer Janne Carlsson. Hansson and Carlsson immediately hit it off and were signed by Polydor under the band name Hansson & Karlsson, playing up-tempo Hammond organ based music and releasing three albums between 1967 and 1969. They became immensely popular in their home country and some parts of Europe, and even reached the ear of Jimi Hendrix, who took time out from his tour to jam with the duo, along with George Clemons on drums and Georg Wadenius on guitar, at the Klub Filips in Stockholm in late 1967. Hendrix went on to record a Hansson song, "Tax Free".
Solo debut.
By 1969, Janne Carlsson had become a successful comedian and TV host, and Hansson decide to break up the partnership. Entranced by a copy of J.R.R. Tolkien's "The Lord of the Rings", which he had purloined from his girlfriend, he moved into a friend's vacant apartment and started writing. When the unfortunate friend returned, he found that he had been evicted from his apartment after numerous complaints about the noise Hansson was creating. Hansson retreated to a remote cottage on an island off Stockholm where he, drummer Rune Carlsson and engineer Anders Lind, who had worked previously with Hansson & Karlsson, spent the winter of 1969 recording what was to become Hansson's debut solo album on a borrowed four track recorder. The resourceful Lind was even able to gain use of the only eight track recorder in Sweden at that time at the Swedish National Radio station, on the pretext that he was interested in buying one himself and wanted to test it. Once there, he persuaded session musicians Gunnar Bergsten and Sten Bergman to flesh out the recordings.
"Sagan Om Ringen" was released on Silence Records (Sweden's first independent record label which was set up by Anders Lind) in autumn 1970 and became a huge hit. Copies of the album began to filter across to Britain where it came to the attention of Tony Stratton-Smith, who was so impressed that he released the album as "Music Inspired by Lord of the Rings" on his own Famous Charisma label in September 1972. The album peaked at #34 on the UK Album Chart and became Bo's only UK Top 40 album.
Further musical career.
Encouraged by the success of his first album, Hansson was booked into Stockholm's Studio Decibel where he began work on the follow-up. Using the same team, along with guitarist Kenny Håkansson, the new recordings benefitted from the superior equipment and "Ur Trollkarlens Hatt" was released on Silence Records in late 1972, and on Charisma in the UK as "Magician's Hat" in October 1973. Although critically acclaimed, it failed to reach the popularity of the earlier work, and did not chart in the UK.
Popularity in Sweden, however, put pressure on Hansson to tour, and a touring band was hastily assembled. The tour was cancelled by the reclusive keyboard player, however, citing a lack of motivation. Instead, he returned to Studio Decibel and started work on his third album. Using the tried and trusted backing musicians the recordings continued the progression of the previous album, and "Mellanväsen" was issued on Silence Records in October 1975, and as "Attic Thoughts" on Charisma in the UK in February 1976. Despite being the most accomplished record of Hansson's career, it did not find the success it deserved, although it did feature the song "Rabbit Music" which would point the way to Hansson's next album.
In 1976 Hansson and Silence Records parted company, and he was able to negotiate a worldwide deal with Charisma. He returned once again to Studio Decibel and began work on recordings that were inspired by another book; Richard Adams' "Watership Down". Using the same session musicians but with a new producer, Pontus Olssen, the recordings were issued in September 1977 as "El 'Ahrairah" (after the novel's rabbit god) and "Music Inspired by Watership Down" on Charisma in the UK, and on Sire Records in the US. Another disappointing chart performance led to Hansson's withdrawal from the popular music scene, and though he worked on a number of projects with friends, little was heard from him until 1985 when he released, in Sweden only, the album "Mitt I Livet" (In the Middle of Life) on Silence Records (SRS 4700). He then again dropped off the radar.
Later years.
Hansson found a new following amongst Swedish DJs in recent years, who sampled his music – something which apparently pleased him enormously. Although the better known "Music Inspired by Lord of the Rings" made it onto CD in 1988, in a remixed version accompanied by selected tracks from "Magician's Hat" and "Attic Thoughts", his other 1970s albums remained unavailable in full until 2005 when Silence Records (through EMI) re-issued them on CD, digitally re-mastered and with previously unreleased extra material.
In 1998 Hansson & Karlsson reunited for some live concerts and a compilation album.
Due to his pioneering work and the mysteries surrounding Hansson & Karlsson's rise and fall, Hansson received the status of a living legend among the independent musical community in Sweden. He occasionally performed live sets with fellow organist Eric Malmberg who has been greatly inspired by Hansson's work.
Bo Hansson died in Stockholm on April 23, 2010.
Discography.
As Bo Hansson.
Compilation.
The CD reissues of the first three solo records are distributed internationally by the original company, Silence Records.

</doc>
<doc id="55044" url="http://en.wikipedia.org/wiki?curid=55044" title="Transition">
Transition

Transition or transitional may refer to:

</doc>
<doc id="55051" url="http://en.wikipedia.org/wiki?curid=55051" title="Capparales">
Capparales

Capparales is a botanical name of an order of flowering plants. It was used in the Cronquist system for an order in subclass Dilleniidae and in the Kubitzki system, nowadays. In the 1981 version of this system it included :
The APG II system includes all the plants involved in the (expanded) order Brassicales. For names above the rank of family the principle of priority is not obligatory, hence the difference between the two names.

</doc>
<doc id="55052" url="http://en.wikipedia.org/wiki?curid=55052" title="Batales">
Batales

Batales is a botanical name of an order of flowering plants. This name was used in several systems, sometimes in the spelling Batidales. Often this order consisted of the genus "Batis" only. In the 1981 version of the Cronquist system it was an order placed in subclass Dilleniidae with the following circumscription:
The APG II system, used here, includes all the plants involved in the (expanded) order "Brassicales".

</doc>
<doc id="55054" url="http://en.wikipedia.org/wiki?curid=55054" title="Nepenthales">
Nepenthales

Nepenthales (Nepenthales Bercht. & J.Presl) is an order of flowering plants in the Cronquist system of plant classification. Plant systematists currently favor the APG III system of 2009 over the older Cronquist for classifying flowering plants. The order was placed in the subclass Dilleniidae, which in the 1981 version of this system included: 
The APG II system assigns the first two families to the order Caryophyllales and the last family to the order Ericales. 
All three families are carnivorous plant families. The Droseraceae contains three extant genera: "Drosera" (sundews), which catch insects with adhesive droplets; and "Dionaea" (Venus flytrap) and "Aldrovanda" (waterwheel plant), which capture them in leaves with interlocking teeth. The other two families include pitcher plants, which drown their prey.

</doc>
<doc id="55058" url="http://en.wikipedia.org/wiki?curid=55058" title="Primulales">
Primulales

Primulales is the botanical name of an order of flowering plants. This name was used in several systems with little variation in circumscription (see Bentham & Hooker, Engler and Wettstein system). In the 1981 version of the Cronquist system it was an order placed in subclass Dilleniidae with the following circumscription:
The APG III system includes all the plants involved in the (expanded) order Ericales.

</doc>
<doc id="55063" url="http://en.wikipedia.org/wiki?curid=55063" title="China proper">
China proper

China proper, Inner China, or the Eighteen Provinces was a term used by Western writers on the Qing dynasty to express a distinction between the core and frontier regions of China. There is no fixed extent for China proper, as many administrative, cultural, and linguistic shifts have occurred in Chinese history. One definition refers to the original area of Chinese civilization, the North China Plain; another to the "Eighteen Provinces" system of the Qing dynasty. There is no direct translation for "China proper" in the Chinese language due to differences in terminology used by the Qing to refer to the regions and the expression is controversial among scholars, particularly in China, partly because it implies the frontier regions outside China proper are in some way separate or even illegitimate territories of China.
Origin of the concept.
It is not clear when the concept of "China proper" in the Western world appeared. However, it is plausible that historians during the age of empires and the fast changing borders in the eighteenth century, applied it to distinguish China's 18-provinces from its newly acquired properties. This would also apply to Great Britain proper versus the British Empire, which would encompass vast lands overseas. The same would apply to France proper in contrast to the French Empire of the time, which Napoleon managed to expand all the way to Moscow.
According to Harry Harding, the concept can date back to 1827. But as early as in 1795, William Winterbotham adopted this concept in his book. When describing the Chinese Empire under the Qing Dynasty, Winterbotham divided it into three parts: China proper, Chinese Tartary, and the States Tributary to China. He adopted the opinions of Du Halde and Grosier and suspected that the name of "China" came from Qin Dynasty. He then said: "China, properly so called... comprehends from north to south eighteen degrees; its extent from east to west being somewhat less..."
However, to introduce China proper, Winterbotham still used the outdated 15-province system of the Ming Dynasty, which the Qing Dynasty used until 1662. Although Ming Dynasty also had 15 basic local divisions, Winterbotham uses the name of Kiang-nan (江南, Jiāngnán) province, which had been called Nan-Zhili (南直隶, Nán-Zhílì) in Ming Dynasty and was renamed to Kiang-nan (i.e., Jiangnan) in 1645, the second year after the Qing Dynasty overthrew the Ming Dynasty. This 15-province system was gradually replaced by the 18-province system between 1662 to 1667. Using the 15-province system and the name of Kiang-nan Province indicates that the concept of China proper probably had appeared between 1645 and 1662 and this concept may reflect the idea that identifies China as the territory of the former Ming Dynasty after the Manchu conquest of Ming.
The concept of "China proper" also appeared before this 1795 book. It can be found in "The Gentleman's Magazine", published in 1790, and "The Monthly Review", published in 1749. In the nineteenth century, the term "China proper" was sometimes used by Chinese officials when they were communicating in foreign languages. For instance, the Qing ambassador to Britain Zeng Jize used it in an English language article, which he published in 1887.
Dulimbai Gurun is the Manchu name for China (中國, Zhongguo; "Middle Kingdom"). After conquering the Ming, the Manchu Qing identified their state as "China" (Zhongguo), and referred to it as "Dulimbai Gurun" in Manchu. The Manchu Qing Emperors equated the lands of the Qing state (including both "China proper" and present day Manchuria, Xinjiang, Mongolia, Tibet and other areas as "China" in both the Chinese and Manchu languages, defining China as a multi ethnic state, rejecting the idea that China only meant Han areas in "China proper", proclaiming that both Han and non-Han peoples were part of "China", using "China" to refer to the Qing in official documents, international treaties, and foreign affairs, and the "Chinese language" (Dulimbai gurun i bithe) referred to Chinese, Manchu, and Mongol languages, and the term "Chinese people" (中國人 Zhongguo ren ; Manchu: Dulimbai gurun i niyalma) referred to all Han, Manchus, and Mongol subjects of the Qing.
When the Qing conquered Dzungaria in 1759, they proclaimed that the new land was absorbed into "China" (Dulimbai Gurun) in a Manchu language memorial. The Qing expounded on their ideology that they were bringing together the "outer" non-Han Chinese like the Inner Mongols, Eastern Mongols, Oirat Mongols, and Tibetans together with the "inner" Han Chinese, into "one family" united in the Qing state, showing that the diverse subjects of the Qing were all part of one family, the Qing used the phrase "Zhong Wai Yi Jia" 中外一家 or "Nei Wai Yi Jia" 內外一家 ("interior and exterior as one family"), to convey this idea of "unification" of the different peoples. A Manchu language version of a treaty with the Russian Empire concerning criminal jurisdiction over bandits called people from the Qing as "people of the Central Kingdom (Dulimbai Gurun)". In the Manchu official Tulisen's Manchu language account of his meeting with the Torghut Mongol leader Ayuki Khan, it was mentioned that while the Torghuts were unlike the Russians, the "people of the Central Kingdom" (dulimba-i gurun 中國, Zhongguo) were like the Torghut Mongols, and the "people of the Central Kingdom" referred to the Manchus.
While the Manchu Qing sought used China (Zhongguo) 中國 to describe non-Han areas, however some Han scholar-officials opposed the Qing Manchu Emperor's use of Zhongguo to refer to non-Han areas, using Zhongguo to mark a distinction between the culturally Han Chinese areas and the territory newly brought into the Manchu Qing empire. In the early 19th century, Wei Yuan’s "Shengwuji" (Military History of the Qing Dynasty) calls the inner Asian polities "guo", while the seventeen provinces of the traditional heartland, that is, "China proper," and three eastern provinces of Manchuria are called ""Zhongguo"." Some Han Chinese Ming loyalists refused to use Zhongguo to refer to areas outside the borders of the Ming Empire such as outer Mongolia, in effect refusing to acknowledge the Qing state.
The Manchu Qing referred to the Han Chinese inhabited 18 provinces as "內地十八省" (nèidì shíbā shěng), which meant the "interior region eighteen provinces", or abbreviated it as 內地 (nèidì), "interior region" and also as jùnxiàn 郡县, while they referred to the non-Han areas of China such as the Northeast, Outer Mongolia, Inner Mongolia, Xinjiang, and Tibet as 外藩 (wàifān) which means "outer feudatories" or "outer vassals", or as fānbù 藩部, "feudatory region". These waifan were fully subjected to and governed the Qing government and considered part of the China (中國) unlike wàiguó 外國 "outer countries" like Korea, Vietnam, and the Ryukyus, who paid tribute to the Qing but were not part of China.
Modern.
Today, China proper is a controversial concept in China itself, since the current official paradigm does not contrast the core and the periphery of China. There is no single widely used term corresponding to it in the Mandarin language.
The separation of China into a "China proper" dominated by Han Chinese and one or more "Other Chinas" of ethnic minorities impugns on the legitimacy of China's current borders, which is based on the succession of states principle. According to Sinologist Colin Mackerras, foreign governments have generally accepted Chinese claims over its minority areas, because to redefine a country's territory every time it underwent a change of regime would cause endless instability and warfare. Also, he asks, "if the boundaries of the Qing were considered illegitimate, why should it go back to the much smaller Ming in preference to the quite extensive Tang dynasty boundaries?"
Extent.
There is no fixed extent for China proper, as it is used to express the contrast between the core and frontier regions of China from multiple perspectives: historical, administrative, cultural, and linguistic.
Historical perspective.
One way of thinking about China proper is to refer to ancient Han Chinese dynasties. Chinese civilization developed from a core region in the North China Plain, and expanded outwards over several millennia, conquering and assimilating surrounding peoples, or being conquered and influenced in turn. Some dynasties, such as the Han and Tang dynasties, were particularly expansionist, extending far into Central Asia, while others, such as the Jin and Song dynasties, were forced to relinquish the North China Plain itself to rivals from Northeastern and Central Asia.
The Ming Dynasty was the last Han Chinese dynasty and second-last imperial dynasty to rule China. It governed fifteen administrative entities, which included thirteen provinces (Chinese: 布政使司; Pinyin: Bùzhèngshǐ Sī) and two "directly-governed" areas. After the Manchu-founded Qing Dynasty conquered the Ming Dynasty, the Qing court decided to continue to use the Ming administrative system to rule over former Ming lands, without applying it to other domains within the Qing Dynasty, namely Manchuria, Mongolia, Xinjiang, and Tibet. The 15 administrative units of the Ming Dynasty underwent minor reforms to become the Eighteen Provinces (一十八行省 Pinyin: "Yīshíbā Xíngshěng", or 十八省 "Shíbā Shěng") of China proper under the Qing Dynasty. It was these eighteen provinces that early Western sources referred to as China proper.
There are some minor differences between the extent of Ming China and the extent of the eighteen provinces of Qing China: for example, some parts of Manchuria were a Ming possession belonging to the Ming province of Liaodong (now Liaoning); however, the Qing conquered it before the rest of China and did not put the region back into the provinces of China proper. On the other hand, Taiwan was a new acquisition of the Qing Dynasty, and it was put into Fujian, one of the provinces of China proper. Eastern Kham in Greater Tibet was added to Sichuan, while much of what now constitutes northern Burma was added to Yunnan.
Near the end of the Qing Dynasty, there was an effort to extend the province system of China proper to the rest of the empire. Taiwan was made into a separate province in 1885; however it was ceded to Japan in 1895. Xinjiang was reorganized into a province in 1884. Manchuria was split into the three provinces of Fengtian, Jilin and Heilongjiang in 1907. There was discussion to do the same in Tibet, Kokonor, Inner Mongolia, and Outer Mongolia, but these proposals were not put to practice, and these areas were outside the province system of China proper when the Qing Dynasty fell in 1912.
The Provinces of the Qing Dynasty were:
Some of the revolutionaries who sought to overthrow Qing rule desired to establish a state independent of the Qing Dynasty within the bounds of the Eighteen Provinces, as evinced by the Eighteen-Star Flag they used. Others favoured the replacement of the entire Qing Dynasty by a new republic, as evinced by the Five-Striped Flag they used. Some revolutionaries, such as Zou Rong, used the term "Zhongguo Benbu" (中国本部) which roughly identifies the Eighteen Provinces. When the Qing Dynasty fell, the abdication decree of the Qing Emperor bequeathed the entire Empire to the newborn Republic of China, and the latter idea was therefore adopted by the new republic as the principle of Five Races Under One Union, with Five Races referring to the Han Chinese, Manchus, Mongols, Muslims (Uyghurs, Hui etc.) and Tibetans. The Five-Striped Flag was adopted as the national flag, and the Republic of China viewed itself as a single state encompassing all five regions handed down by the Qing Dynasty. The People's Republic of China, which was founded in 1949 and replaced the Republic of China on the mainland, has continued to claim essentially the same borders, with the only major exception being the recognition of independent Mongolia. As a result, the concept of China proper fell out of favour in China.
The Eighteen Provinces of the Qing Dynasty still exist, but their boundaries have changed. Beijing and Tianjin were eventually split from Hebei (renamed from Zhili), Shanghai from Jiangsu, Chongqing from Sichuan, Ningxia autonomous region from Gansu, and Hainan from Guangdong. Guangxi is now an autonomous region. The provinces that the late Qing Dynasty set up have also been kept: Xinjiang became an autonomous region under the People's Republic of China, while the three provinces of Manchuria now have somewhat different borders, with Fengtian renamed as Liaoning.
When the Qing Dynasty fell, Republican Chinese control of Qing territory, including of those generally considered to be in "China proper", was tenuous, and practically nonexistent in Tibet and Outer Mongolia (since 1922), which were controlled by governments that declared independence. The Republic of China subdivided Inner Mongolia in its time on the mainland, although the People's Republic of China later joined Mongol-inhabited territory into a single autonomous region. The PRC joined the Qamdo area into the Tibet area (later the Tibet Autonomous Region). Nationalist China was forced to acknowledge the independence of Mongolia (former Outer Mongolia) and Tannu Uriankhai (now part of Russia as The Tyva Republic), in 1945.
Ethnic perspective.
China proper is often associated with the Han Chinese, the majority ethnic group of China and with the extent of the Chinese language(s), an important unifying element of the Han Chinese ethnicity.
However, Han Chinese areas in the present day do not correspond well to the Eighteen Provinces of the Qing Dynasty. Much of southwestern China, such as areas in the provinces of Yunnan, Guangxi, and Guizhou, was part of successive Han Chinese dynasties, including the Ming Dynasty and the Eighteen Provinces of the Qing Dynasty. However, these areas were and continue to be populated by various non-Han Chinese minority groups, such as the Zhuang, the Miao people, and the Bouyei. Conversely, today Han Chinese form the majority in most of Manchuria, much of Inner Mongolia, many areas in Xinjiang and scattered parts of Tibet, not least due to the expansion of Han Chinese settlement encouraged by the late Qing Dynasty, the Republic of China, and the People's Republic of China.
Ethnic Han Chinese is not synonymous with speakers of the Chinese language. Many non-Han Chinese ethnicities, such as the Hui and Manchu, are essentially monolingual in Chinese, but do not identify as Han Chinese. The Chinese language itself is also a complex entity, and should be described as a family of related languages rather than a single language if the criterion of mutual intelligibility is used to classify its subdivisions.
In polls a slim majority of the people of Taiwan call themselves "Taiwanese" only with the rest identifying as "Taiwanese and Chinese" or "Chinese" only. 98% are descendants of immigrants from China since the 1600s, a large number of which also have aboriginal ancestry, but the inclusion of Taiwan in Greater China, or let alone from China proper, is still a controversial subject. See History of Taiwan for more information.

</doc>
<doc id="55064" url="http://en.wikipedia.org/wiki?curid=55064" title="Inner Mongolia">
Inner Mongolia

Inner Mongolia (Mongolian: ᠦᠪᠦᠷᠮᠤᠩᠭᠤᠯ "Öbür Monggol" and Өвөр Монгол, "Övör Mongol"; ), officially Inner Mongolia Autonomous Region or Nei Mongol Autonomous Region, is an autonomous region of the People's Republic of China, located in the north of the country, containing most of China's border with Mongolia (the rest of the China-Mongolia border is taken up by the Xinjang and Gansu provinces) and a small section of the border with Russia. Its capital is Hohhot, and other major cities include Baotou, Chifeng, and Ordos.
The Autonomous Region was established in 1947, incorporating the areas of the former Republic of China provinces of Suiyuan, Chahar, Rehe, Liaobei and Xing'an, along with the northern parts of Gansu and Ningxia.
It is the third largest subdivision of China, spanning approximately 1,200,000 km2 or 12% of China's total land area. It had a population of 24,706,321 at the 2010 census, accounting for 1.84% of Mainland China's total population. Inner Mongolia is the country's 23rd most populous province-level division. The majority of the population in the region are Han Chinese, with a substantial Mongol minority. The official languages are Chinese and Mongolian, the latter written in the traditional Mongolian script, as opposed to the Mongolian Cyrillic alphabet used in the state of Mongolia.
Name.
In Chinese, the region is known as "Inner Mongolia", where the terms of "Inner/Outer" are derived from Manchu "dorgi"/"tulergi" (cf. Mongolian "dotugadu"/"gadagadu"). Inner Mongolia is distinct from Outer Mongolia, which was a term used by the Republic of China and previous governments to refer to what is now the independent state of Mongolia plus the Republic of Tuva in Russia. In Mongolian, the region was called "Dotugadu monggol" during Qing rule and was renamed into "Öbür Monggol" in 1947, "öbür" meaning the southern side of a mountain, while the Chinese term "nei menggu" was retained. In recent years, some Mongols began to call Inner Mongolia "Nan Menggu" and with it came the change of English translation from Inner Mongolia to Southern Mongolia.
History.
Much of what is known about the history of Greater Mongolia, including Inner Mongolia, is known through Chinese chronicles and historians. Before the rise of the Mongols in the 13th century, what is now central and western Inner Mongolia, especially the Hetao region, alternated in control between Chinese agriculturalists in the south and Xiongnu, Xianbei, Khitan, Jurchen, Tujue, and nomadic Mongol of the north. The historical narrative of what is now Eastern Inner Mongolia mostly consists of alternations between different Tungusic and Mongol tribes, rather than the struggle between nomads and Chinese agriculturalists.
Early History.
Slab Grave cultural monuments are found in northern, central and eastern Mongolia, Inner Mongolia, north-western China, southern, central-eastern and southern Baikal territory. Mongolian scholars prove that this culture related to the Proto-Mongols.
During the Zhou Dynasty, central and western Inner Mongolia (the Hetao region and surrounding areas) were inhabited by nomadic peoples such as the Loufan, Linhu, and Dí, while eastern Inner Mongolia was inhabited by the Donghu. During the Warring States period, King Wuling (340–295 BC) of the state of Zhao based in what is now Hebei and Shanxi provinces pursued an expansionist policy towards the region. After destroying the Dí state of Zhongshan in what is now Hebei province, he defeated the Linhu and Loufan and created the commandery of Yunzhong near modern Hohhot. King Wuling of Zhao also built a long wall stretching through the Hetao region. After Qin Shihuang created the first unified Chinese empire in 221 BC, he sent the general Meng Tian to drive the Xiongnu from the region, and incorporated the old Zhao wall into the Qin Dynasty Great Wall of China. He also maintained two commanderies in the region: Jiuyuan and Yunzhong, and moved 30,000 households there to solidify the region. After the Qin Dynasty collapsed in 206 BC, these efforts were abandoned.
During the Western Han Dynasty, Emperor Wu sent the general Wei Qing to reconquer the Hetao region from the Xiongnu in 127 BC. After the conquest, Emperor Wu continued the policy of building settlements in Hetao to defend against the Xiong-Nu. In that same year he established the commanderies of Shuofang and Wuyuan in Hetao. At the same time, what is now eastern Inner Mongolia was controlled by the Xianbei, who would later on eclipse the Xiongnu in power and influence.
During the Eastern Han Dynasty (25–220 AD), Xiongnu who surrendered to the Han Dynasty began to be settled in Hetao, and intermingled with the Han immigrants in the area. Later on during the Western Jin Dynasty, it was a Xiongnu noble from Hetao, Liu Yuan, who established the Han Zhao kingdom in the region, thereby beginning the Sixteen Kingdoms period that saw the disintegration of northern China under a variety of Han and non-Han (including Xiongnu and Xianbei) regimes.
The Sui Dynasty (581–618) and Tang Dynasty (618–907) re-established a unified Chinese empire, and like their predecessors they conquered and settled people into Hetao, though once again these efforts were aborted when the Tang empire began to collapse. Hetao (along with the rest of what now consists Inner Mongolia) was then taken over by the Khitan Empire (Liao Dynasty), founded by the Khitans, a nomadic people originally from what is now the southern part of Manchuria and eastern Inner Mongolia. They were followed by the Western Xia of the Tanguts, who took control of what is now the western part of Inner Mongolia (including western Hetao) . The Khitans were later replaced by the Jurchens, precursors to the modern Manchus, who established the Jin Dynasty over Manchuria and northern China.
Mongol Period.
After Genghis Khan unified the Mongol tribes in 1206 and founded the Mongol Empire, the Tangut Western Xia empire was ultimately conquered in 1227, and the Jurchen Jin Dynasty fell in 1234. In 1271, Genghis Khan's grandson Khubilai established the Yuan Dynasty. Khubilai's summer capital Shangdu (aka Xanadu) was located near present-day Dolonnor. During that time Ongud and Khunggirad peoples dominated the area of what is now Inner Mongolia. After the Yuan Dynasty was defeated by the Han-led Ming Dynasty in 1368, the Ming rebuilt the Great Wall of China at its present location, which roughly follows the southern border of the modern Inner Mongolia Autonomous Region (though it deviates significantly at the Hebei-Inner Mongolia border). The Ming established the Three Guards composed of the Mongols there. Soon after the Tumu incident in 1449, when the Oirat ruler Esen taishi captured the Chinese emperor, Mongols flooded south from Northern Mongolia to Southern Mongolia. Thus from then on until 1635, Inner Mongolia was the political and cultural center of the Mongols during the Post-Imperial Mongolia.
Qing Period.
The eastern Mongol tribes near and in Manchuria, particularly the Khorchin and Southern Khalkha in today's Inner Mongolia intermarried, formed alliances with, and fought against the Jurchen tribes until Nurhaci, the founder of the new Jin Dynasty, consolidated his control over all groups in the area in 1593. The Manchus gained far-reaching control of the Inner Mongolian tribes in 1635, when Ligden Khan's son surrendered the Chakhar Mongol tribes to the Manchus. The Manchus subsequently invaded Ming China in 1644, bringing it under the control of their newly established Qing Dynasty. Under the Qing Dynasty (1636–1912), Greater Mongolia was administered in a different way for each region:
The Inner Mongolian Chahar leader Ligdan Khan, a descendant of Genghis Khan, opposed and fought against the Qing until he died of smallpox in 1634. Thereafter, the Inner Mongols under his son Ejei Khan surrendered to the Qing and was given the title of Prince (Qin Wang, 親王), and Inner Mongolian nobility became closely tied to the Qing royal family and intermarried with them extensively. Ejei Khan died in 1661 and was succeeded by his brother Abunai. After Abunai showed disaffection with Manchu Qing rule, he was placed under house arrested in 1669 in Shenyang and the Kangxi Emperor gave his title to his son Borni. Abunai then bid his time and then he and his brother Lubuzung revolted against the Qing in 1675 during the Revolt of the Three Feudatories, with 3,000 Chahar Mongol followers joining in on the revolt. The revolt was put down within two months, the Qing then crushed the rebels in a battle on April 20, 1675, killing Abunai and all his followers. Their title was abolished, all Chahar Mongol royal males were executed even if they were born to Manchu Qing princesses, and all Chahar Mongol royal females were sold into slavery except the Manchu Qing princesses. The Chahar Mongols were then put under the direct control of the Qing Emperor unlike the other Inner Mongol leagues which maintained their autonomy.
Despite officially prohibiting Han Chinese settlement on the Manchu and Mongol lands, by the 18th century the Qing decided to settle Han refugees from northern China who were suffering from famine, floods, and drought into Manchuria and Inner Mongolia so that Han Chinese farmed 500,000 hectares in Manchuria and tens of thousands of hectares in Inner Mongolia by the 1780s.
Ordinary Mongols were not allowed to travel outside their own leagues. During the eighteenth century, growing numbers of Han Chinese settlers had illegally begun to move into the Inner Mongolian steppe. By 1791 there had been so many Han Chinese settlers in the Front Gorlos Banner that the jasak had petitioned the Qing government to legalize the status of the peasants who had already settled there.
During the nineteenth century, the Manchus were becoming increasingly sinicized, and faced with the Russian threat, they began to encourage Han Chinese farmers to settle in both Mongolia and Manchuria. This policy was followed by subsequent governments. The railroads that were being built in these regions were especially useful to the Han Chinese settlers. Land was either sold by Mongol Princes, or leased to Han Chinese farmers, or simply taken away from the nomads and given to Han Chinese farmers. The Jindandao Incident, a rebellion by an ethnic Chinese secret society called Jindandao occurred in Inner Mongolia in November 1891 and massacred 150,000 Mongols before being suppressed by government troops in late December.
Republic of China period.
Outer Mongolia gained independence from the Qing Dynasty in 1911, when the Jebtsundamba Khutugtu of the Khalkha was declared the Bogd Khan of Mongolia. Although almost all banners of Inner Mongolia recognized the Bogd Khan as the supreme ruler of Mongols, the internal strife within the region prevented a full reunification. The Mongol rebellions in Inner Mongolia were counterbalanced by princes who hoped to see a restored Qing dynasty in Manchuria and Mongolia, as they considered the theocratic rule of the Bogd Khan would be against their modernizing objectives for Mongolia. Eventually, the newly formed Republic of China promised a new nation of five races (Han, Manchu, Mongol, Tibetan and Uyghur), and suppressed the Mongol rebellions in the area, forcing the Inner Mongolian princes to recognize the Republic of China.
The Republic of China reorganized Inner Mongolia into provinces:
Some Republic of China maps still show this structure.
Mengjiang period.
Mengjiang was an autonomous area of Reorganized National Government of China, which was a puppet regime of Japan.
In 1931 Manchuria came under the control of the Japanese puppet state Manchukuo, taking the Mongol areas in the Manchurian provinces (i.e. Hulunbuir and Jirim leagues) along. Rehe was also incorporated into Manchukuo in 1933, taking Juu Uda and Josutu leagues along with it. These areas were administered by Manchukuo until the end of World War II in 1945.
In 1937, open war broke out between the Republic of China and the Empire of Japan. On December 8, 1937, Mongolian Prince De Wang declared the independence of the remaining parts of Inner Mongolia (i.e. the Suiyuan and Chahar provinces) as Mengkiang or Mengkukuo, and signed close agreements with Manchukuo and Japan. The capital was established at Zhangbei (now in Hebei province), with the puppet government's control extending as far west as the Hohhot region. In August 1945, Mengkiang was taken by Soviet and Outer Mongolian troops during Manchurian Strategic Offensive Operation. Despite a considerable movement among Inner Mongolia's Mongols(who comprised then around 15% of Inner Mongolia's population, while Han Chinese around 83%) for unification with Outer Mongolia, Inner Mongolia remained part of China.
Communist era.
The Communist movement gradually gained momentum as part of the Third Communist International in Inner Mongolia during the Japanese period. By the end of WWII, the Inner Mongolian faction of the ComIntern had a functional militia, and actively opposed the attempts at independence by De Wang's Chinggisid princes on the grounds of fighting feudalism. Following the end of World War II, the Chinese Communists gained control of Manchuria as well as the Inner Mongolian Communists with decisive Soviet support, and established the Inner Mongolia Autonomous Region in 1947. The Comintern army was absorbed into the People's Liberation Army. Initially the autonomous region included just the Hulunbuir region. Over the next decade, as the communists established the People's Republic of China and consolidated control over mainland China, Inner Mongolia was expanded westwards to include five of the six original leagues (except Josutu League, which remains in Liaoning province), the northern part of the Chahar region, by then a league as well (southern Chahar remains in Hebei province), the Hetao region, and the Alashan and Ejine banners. Eventually, near all areas with sizeable Mongol populations were incorporated into the region, giving present-day Inner Mongolia its elongated shape. The leader of Inner Mongolia during that time, as both regional CPC secretary and head of regional government, was Ulanhu.
During the Cultural Revolution, the administration of Ulanhu was purged, and a wave of repressions was initiated against the Mongol population of the autonomous region. In 1969 much of Inner Mongolia was distributed among surrounding provinces, with Hulunbuir divided between Heilongjiang and Jilin, Jirim going to Jilin, Juu Uda to Liaoning, and the Alashan and Ejine region divided among Gansu and Ningxia. This was reversed in 1979.
Inner Mongolia has seen considerable development since Deng Xiaoping instituted Chinese economic reform in 1978. For about ten years since 2000, Inner Mongolia's GDP growth has been the highest in the country, (along with Guangdong) largely owing to the success of natural resource industries in the region. GDP growth has continually been over 10%, even 15% and connections with the Wolf Economy to the north has helped development. However, growth has come at a cost with huge amounts of pollution and degradation to the grasslands. Attempts to attract ethnic Chinese to migrate from other regions, as well as ubranise those rural nomads and peasants has led to huge amounts of corruption and waste in public spending, such as Ordos City. Acute uneven wealth distribution has further exacerbated etnhic tensions, many indigenous Mongolians feeling they are increasingly marginalised in their own homeland, leading to riots in 2011 and 2013.
Geography.
Officially Inner Mongolia is classified as one of the provincial-level divisions of North China, but its great stretch means that parts of it belong to Northeast China and Northwest China as well. It borders eight provincial-level divisions in all three of the aforementioned regions (Heilongjiang, Jilin, Liaoning, Hebei, Shanxi, Shaanxi, Ningxia, and Gansu), tying with Shaanxi for the greatest number of bordering provincial-level divisions. Most of its international border is with Mongolia, which, in Chinese, is sometimes called “Outer Mongolia” (外蒙古), while a small portion is with Russia.
Inner Mongolia largely consists of the northern side of the North China Craton, a tilted and sedimented Precambrian block. In the extreme southwest is the edge of the Tibetan Plateau where the autonomous region’s highest peak, Main Peak in the Helan Mountains reaches 3556 m, and is still being pushed up today in short bursts. Most of Inner Mongolia is a plateau averaging around 1200 m in altitude and covered by extensive loess and sand deposits. The northern part consists of the Mesozoic era Khingan Mountains, and is owing to the cooler climate more forested, chiefly with Manchurian elm, ash, birch, Mongolian oak and a number of pine and spruce species. Where discontinuous permafrost is present north of Hailar District, forests are almost exclusively coniferous. In the south the natural vegetation is grassland in the east and very sparse in the arid west, and grazing is the dominant economic activity.
Owing to the ancient, weathered rocks lying under its deep sedimentary cover, Inner Mongolia is a major mining district, possessing large reserves of coal, iron ore and rare earth minerals, which have made it a major industrial region today.
Climate.
Due to its elongated shape, Inner Mongolia has a wide variety of regional climates. Throughout the province, the climate is based off a four-season, monsoon climate. The winters in Inner Mongolia are very long, cold, and dry with frequent blizzards, though snowfall is so light that Inner Mongolia has no modern glaciers even on the highest Helan peaks. The spring is short, mild and arid, with large, dangerous sandstorms, whilst the summer is very warm to hot and relatively humid except in the west where it remains dry. Autumn is brief and sees a steady cooling, with temperatures below 0 C reached in October in the north and November in the south.
Officially, most of Inner Mongolia is classified as either a cold arid or steppe regime (Köppen "BWk, BSk", respectively). The small portion besides these are classified as humid continental (Köppen "Dwb") in the northeast, or subarctic (Köppen "Dwc") in the far north near Hulunbuir.
Administrative divisions.
Inner Mongolia is divided into twelve prefecture-level divisions. Until the late 1990s, most of Inner Mongolia's prefectural regions were known as "Leagues" (), a usage retained from Mongol divisions of the Qing Dynasty. Similarly, county-level divisions are often known as "Banners" (). Since the 1990s, numerous Leagues have converted into prefecture-level cities, although Banners remain. The restructuring led to the conversion of primate cities in most leagues to convert to districts administratively (i.e.: Hailar, Jining and Dongsheng). Some newly founded prefecture-level cities have chosen to retain the original name of League (i.e.: Hulunbuir, Bayannur and Ulanqab), some have adopted the Chinese name of their primate city (Chifeng, Tongliao), and one League (Yekejuu) simply renamed itself Ordos. Despite these recent administrative changes, there is no indication that the Alxa, Hinggan, and Xilingol Leagues will convert to prefecture-level cities in the near future.
Many of the prefecture-level cities were converted very recently from leagues.
The twelve prefecture-level divisions of Inner Mongolia are subdivided into 101 county-level divisions, including twenty-one districts, eleven county-level cities, seventeen counties, forty-nine banners, and three autonomous banners. Those are in turn divided into 1425 township-level divisions, including 532 towns, 407 townships, 277 sumu, eighteen ethnic townships, one ethnic sumu, and 190 subdistricts.
Economy.
Farming of crops such as wheat takes precedence along the river valleys. In the more arid grasslands, herding of goats, sheep and so on is a traditional method of subsistence. Forestry and hunting are somewhat important in the Greater Khingan ranges in the east. Reindeer herding is carried out by Evenks in the Evenk Autonomous Banner. More recently, growing grapes and winemaking have become an economic factor in the Wuhai area.
Inner Mongolia has abundance of resources especially coal, cashmere, natural gas, rare earth elements, and has more deposits of naturally occurring niobium, zirconium and beryllium than any other province-level region in China. However in the past, the exploitation and utilisation of resources were rather inefficient, which resulted in poor returns from rich resources. Inner Mongolia is also an important coal production base, with more than a quarter of the world's coal reserves located in the province. It plans to double annual coal output by 2010 (from the 2005 volume of 260 million tons) to 500 million tons of coal a year.
Industry in Inner Mongolia has grown up mainly around coal, power generation, forestry-related industries, and related industries.
Inner Mongolia now encourages six competitive industries: energy, chemicals, metallurgy, equipment manufacturing, processing of farm (including dairy) produce, and high technology. Well-known Inner Mongolian enterprises include companies such as ERDOS, Yili, and Mengniu.
The nominal GDP of Inner Mongolia in 2010 was 1.16 trillion yuan (US$172.1 billion), a growth of 16.9% from 2008, with an average annual increase of 20% from the period 2003-2007. Its per capita GDP reached 37,287 yuan (US$5,460) in 2009. In 2008, Inner Mongolia's primary, secondary, and tertiary industries were worth 90.7 billion yuan, 427.1 billion yuan, and 258.4 billion yuan respectively. The urban per capita disposable income and rural per capita net income were 14,431 yuan and 4,656 yuan, up 16.6% and 17.8% respectively.
As with much of China, economic growth has led to a boom in construction, including new commercial development and large apartment complexes.
In addition to its large reserves of natural resources, Inner Mongolia also has the largest usable wind power capacity in China thanks to strong winds which develop in the province's grasslands. Some private companies have set up wind parks in parts of Inner Mongolia such as Bailingmiao, Hutengliang and Zhouzi.
Economic and Technological Development Zones.
Hohhot Export Processing Zone was established on June 21, 2002, by the State Council, which is located in the west of the Hohhot, with a planning area of 2.2 km2. Industries encouraged in the export processing zone include Electronics Assembly & Manufacturing, Telecommunications Equipment, Garment and Textiles Production, Trading and Distribution, Biotechnology/Pharmaceuticals, Food/Beverage Processing, Instruments & Industrial Equipment Production, Medical Equipment and Supplies, Shipping/Warehousing/Logistics, Heavy Industry.
Government and politics.
Under the Constitution of the People's Republic of China, articles 112-122, autonomous regions have limited autonomy in both the political and economic arena. Autonomous regions have more discretion in administering economic policy in the region in accordance with national guidelines. Structurally, the Chairman—who legally must be an ethnic minority and is usually ethnic Mongolian—is always kept in check by the Communist Party Regional Committee Secretary, who is usually from a different part of China (to reduce corruption) and Han Chinese. The current party secretary is Wang Jun. The Inner Mongolian government and its subsidiaries follow roughly the same structure as that of a Chinese province. With regards to economic policy, as a part of increased federalism characteristics in China, Inner Mongolia has become more independent in implementing its own economic roadmap.
Demographics.
When the autonomous region was established in 1947, Han Chinese comprised 83.6% of the population, while the Mongols comprised 14.8% of the population. By 2000, the percentage of Han Chinese had fallen to 79.2%. While the Hetao region along the Yellow River has always alternated between farmers from the south and nomads from the north, the most recent episode of Han Chinese migration began in the early 18th century with encouragement from the Qing Dynasty, and continued into the 20th century. Han Chinese live mostly in the Hetao region as well as various population centres in central and eastern Inner Mongolia. Over 70% of Mongols are concentrated in less than 18% of Inner Mongolia's territory (Hinggan League, and prefectures Tongliao and Chifeng).
Mongols are the second largest ethnic group, comprising 17.11% of the population. They include many diverse Mongolian-speaking groups; groups such as the Buryats and the Oirats are also officially considered to be Mongols in China. Many of the traditionally nomadic Mongols have settled in permanent homes as their pastoral economy was collectivized during the Maoist Era.
Other ethnic groups include the Daur, the Evenks, the Oroqen, the Hui, the Manchus, and the Koreans.
Excludes members of the People's Liberation Army in active service.
Language and culture.
The Han Chinese of Inner Mongolia speak a variety of dialects, depending on the region. The eastern parts tend to speak Northeastern Mandarin, which belongs to the Mandarin group of dialects; those in the central parts, such as the Huang He valley, speak varieties of Jin, another subdivision of Chinese, due to its proximity to other Jin-speaking areas in China such as the Shanxi province. Cities such as Hohhot and Baotou both have their unique brand of Jin Chinese such as the Zhangjiakou–Hohhot dialect which are sometimes incomprehensible with dialects spoken in northeastern regions such as Hailar.
Mongols in Inner Mongolia speak Mongolian dialects such as Chakhar, Xilingol, Baarin, Khorchin and Kharchin Mongolian and, depending on definition and analysis, further dialects or closely related independent Central Mongolic languages such as Ordos, Khamnigan, Barghu Buryat and the arguably Oirat dialect Alasha. The standard pronunciation of Mongolian in China is based on the Chakhar dialect of the Plain Blue Banner, located in central Inner Mongolia, while the grammar is based on all Southern Mongolian dialects. This is different from the Mongolian state, where the standard pronunciation is based on the closely related Khalkha dialect. There are a number of independent languages spoken in Hulunbuir such as the somewhat more distant Mongolic language Dagur and the Tungusic language Evenki. Officially, even the Evenki dialect Oroqin is considered a language.
By law, all street signs, commercial outlets, and government documents must be bilingual, written in Mongolian and Chinese. There are three Mongolian TV channels in the Inner Mongolia Satellite TV network. In public transportation, all announcements are to be bilingual. Many ethnic Mongols, especially the young, speak fluent Chinese; Mongolian use is receding in urban areas. But rural ethnic Mongols have kept more of their traditions. In terms of written language, Inner Mongolia has retained the classic Mongol written script as opposed to Mongolia's adoption of Cyrillic.
The vast grasslands have long symbolised Inner Mongolia. Mongolian art often depicts the grassland in an uplifting fashion and emphasizes Mongolian nomadic traditions. The Mongols of Inner Mongolia still practice their traditional arts. Inner Mongolian cuisine has Mongol roots and consists of dairy-related products and "hand-held lamb" (手扒肉). In recent years, franchises based on Hot pot have appeared Inner Mongolia, the best known of which is "Xiaofeiyang" (小肥羊). Notable Inner Mongolian commercial brand names include Mengniu and Yili, both of which began as dairy product and ice cream producers.
Among the Han Chinese of Inner Mongolia, Jinju (晉劇) or Shanxi Opera is a popular traditional form of entertainment. See also: Shanxi.
A popular career in Inner Mongolia is circus acrobatics. The internationally known Inner Mongolia Acrobatic Troupe travels and performs with the renowned Ringling Bros. and Barnum and Bailey Circus.
Religion.
According to researches conducted by the Religious Studies Department of Minzu University of China, adherents of the five officially recognised religions of the state (Buddhism, Taoism, Protestantism, Catholicism and Islam) constitute only 3.7% of the population of Inner Mongolia.
At the same time, 80% of the inhabitants of the region declare to worship "Tian" and "aobao", features of both Chinese folk religion and Mongolian shamanism.
The cult of Genghis Khan, present in the form of various Genghis Khan temples, is a tradition of Mongolian shamanism, in which he is considered a cultural hero and divine ancestor, an embodiment of the "Tenger" (Heaven, God of Heaven). His worship in special temples, greatly developed in Inner Mongolia since the 1980s, is also shared by the Han Chinese, claiming his spirit as the founding principle of the Yuan dynasty.
Tibetan Buddhism (Mongolian Buddhism) is the dominant form of Buddhism in Inner Mongolia, also practiced by many Han Chinese, and its influence may be far larger than what the official adherents statistics would testify. Another form of Buddhism, practiced by the Chinese, are the schools of Chinese Buddhism.
Tourism.
In the capital city Hohhot:
Elsewhere in Inner Mongolia:
Chinese space program.
One of China's space vehicle launch facilities, Jiuquan Satellite Launch Center (JSLC) (), is located in the extreme west of Inner Mongolia, in the Alxa League's Ejin Banner. It was founded in 1958, making it the PRC's first launch facility. More Chinese launches have occurred at Jiuquan than anywhere else. As with all Chinese launch facilities, it is remote and generally closed to the public. It is named as such since Jiuquan is the nearest urban center, although Jiuquan is in the nearby province of Gansu. Many space vehicles have also made their touchdowns in Inner Mongolia. For example, the crew of Shenzhou 6 landed in Siziwang Banner, near Hohhot.
Education.
Colleges and universities.
All of the above are under the authority of the autonomous region government. Institutions without full-time bachelor programs are not listed.

</doc>
<doc id="55066" url="http://en.wikipedia.org/wiki?curid=55066" title="Nanking Massacre">
Nanking Massacre

The Nanking Massacre or Nanjing Massacre, also known as the Rape of Nanking or Rape of Nanjing, was an episode during the Second Sino-Japanese War of mass murder and mass rape by Japanese troops against the residents of Nanjing (then spelled "Nanking"), the capital of the Republic of China. The massacre occurred over six weeks starting December 13, 1937, the day that the Japanese captured Nanjing. During this period, soldiers of the Imperial Japanese Army murdered an estimated 40,000 to over 300,000 Chinese civilians and disarmed combatants, and perpetrated widespread rape and looting. Several key perpetrators were tried and found guilty at the International Military Tribunal for the Far East and the Nanjing War Crimes Tribunal, and were executed. A key perpetrator, Prince Asaka of the Imperial Family, escaped prosecution by having earlier been granted immunity by the Allies.
Since most Japanese military records on the killings were kept secret or destroyed shortly after the surrender of Japan in 1945, historians have not been able to accurately estimate the death toll of the massacre. The International Military Tribunal for the Far East estimated in 1948 that over 200,000 Chinese were killed in the incident. China's official estimate is more than 300,000 dead based on the evaluation of the Nanjing War Crimes Tribunal in 1947. The death toll has been actively contested among scholars since the 1980s.
The event remains a contentious political issue, as aspects of it have been disputed by historical negationists and Japanese nationalists who assert that the massacre has been either exaggerated or fabricated for propaganda purposes. The controversy surrounding the massacre remains a stumbling block in Sino-Japanese relations and in Japanese relations with other Asia-Pacific nations such as South Korea and the Philippines.
Although the Japanese government has admitted to the killing of a large number of non-combatants, looting, and other violence committed by the Imperial Japanese Army after the fall of Nanking, and Japanese veterans who served there have confirmed that a massacre took place, a small but vocal minority within both the Japanese government and society have argued that the death toll was military in nature and that no such crimes ever occurred. Denial of the massacre and revisionist accounts of the killings have become a staple of Japanese nationalism. In Japan, public opinion of the massacres varies, but few deny outright that it happened.
Military situation.
In August 1937, the Japanese army invaded Shanghai where they met strong resistance and suffered heavy casualties. The battle was bloody as both sides faced attrition in urban hand-to-hand combat. By mid-November the Japanese had captured Shanghai with the help of naval bombardment. The General Staff Headquarters in Tokyo initially decided not to expand the war due to heavy casualties and low troop morale. Nevertheless, on December 1, headquarters ordered the Central China Area Army and the 10th Army to capture Nanjing, then-capital of the Republic of China.
Relocation of the capital.
After losing the Battle of Shanghai, Chiang Kai-shek knew that the fall of Nanjing was a matter of time. He and his staff realized that they could not risk the annihilation of their elite troops in a symbolic but hopeless defense of the capital. To preserve the army for future battles, most of it was withdrawn. Chiang's strategy was to follow the suggestion of his German advisers to draw the Japanese army deep into China and use China's vast territory as a defensive strength. Chiang planned to fight a protracted war of attrition to wear down the Japanese in the hinterland of China.
Leaving General Tang Shengzhi in charge of the city for the Battle of Nanking, Chiang and many of his advisors flew to Wuhan, where they stayed until it was attacked in 1938.
Strategy for the defense of Nanking.
In a press release to foreign reporters, Tang Shengzhi announced the city would not surrender and would fight to the death. Tang gathered about 100,000 soldiers, largely untrained, including Chinese troops who had participated in the Battle of Shanghai. To prevent civilians from fleeing the city, he ordered troops to guard the port, as instructed by Chiang Kai-shek. The defense force blocked roads, destroyed boats, and burnt nearby villages, preventing widespread evacuation.
The Chinese government left for relocation on December 1, and the president left on December 7, leaving the fate of Nanking to an International Committee led by John Rabe.
The defense plan fell apart quickly. Those defending the city encountered Chinese troops fleeing from previous defeats such as the Battle of Shanghai, running from the advancing Japanese army. This did nothing to help the morale of the defenders, many of whom were killed during the defense of the city and subsequent Japanese occupation.
Approach of the Imperial Japanese Army.
Japanese war crimes on the march to Nanking.
Although the massacre is generally described as having occurred over a six-week period after the fall of Nanjing, the crimes committed by the Japanese army were not limited to that period. Many atrocities were reported to have been committed as the Japanese army advanced from Shanghai to Nanjing.
According to one Japanese journalist embedded with Imperial forces at the time, "The reason that the [10th Army] is advancing to Nanking quite rapidly is due to the tacit consent among the officers and men that they could loot and rape as they wish."
Novelist Tatsuzō Ishikawa vividly described how the 16th Division of the Shanghai Expeditionary Force committed atrocities on the march between Shanghai and Nanjing in his novel "Ikiteiru Heitai" (Living Soldiers), which was based on interviews that Ishikawa conducted with troops in Nanjing in January 1938.
Perhaps the most notorious atrocity was a killing contest between two Japanese officers as reported in the "Tokyo Nichi Nichi Shimbun" and the English language "Japan Advertiser". The contest — a race between the two officers to see which could kill 100 people first using only a sword — was covered much like a sporting event with regular updates on the score over a series of days. In Japan, the veracity of the newspaper article about the contest was the subject of ferocious debate for several decades starting in 1967.
In 2000, a historian concurred with certain Japanese scholars who had argued that the contest was a concocted story, with the collusion of the soldiers themselves for the purpose of raising the national fighting spirit. In 2005, a Tokyo district judge dismissed a suit by the families of the lieutenants, stating that "the lieutenants admitted the fact that they raced to kill 100 people" and that the story cannot be proven to be clearly false. The judge also ruled against the civil claim of the plaintiffs because the original article was more than 60 years old. The historicity of the event remains disputed in Japan.
Flight of Chinese civilians.
As the Japanese army drew closer to Nanjing, panicked Chinese civilians fled in droves, not only because of the dangers of the anticipated battle but also because they feared the deprivation inherent in the scorched earth strategy that the Chinese troops were implementing in the area surrounding the city.
The Nanjing garrison force set fire to buildings and houses in the areas close to Xiakuan to the north as well as in the environs of the eastern and southern city gates. Targets within and outside of the city walls—such as military barracks, private homes, the Chinese Ministry of Communication, forests and even entire villages—were burnt to cinders, at an estimated value of 20 to 30 million (1937) US dollars.
Establishment of the Nanking Safety Zone.
Many Westerners were living in the city at that time, conducting trade or on missionary trips. As the Japanese army approached Nanking, most of them fled the city, leaving 27 foreigners. Five of these were journalists who remained in the city a few days after it was captured, leaving the city on December 16. Fifteen of the remaining 22 foreigners formed a committee, called the International Committee for the Nanking Safety Zone in the western quarter of the city. German businessman John Rabe was elected as its leader, in part because of his status as a member of the Nazi Party and the existence of the German-Japanese bilateral Anti-Comintern Pact.
The Japanese government had previously agreed not to attack parts of the city that did not contain Chinese military forces, and the members of the Committee managed to persuade the Chinese government to move their troops out of the area.
On December 1, 1937, Nanking Mayor Ma Chao-chun ordered all Chinese citizens remaining in Nanking to move into the "Safety Zone". Many fled the city on December 7, and the International Committee took over as the "de facto" government of Nanking.
Prince Asaka appointed as commander.
In a memorandum for the palace rolls, Hirohito singled Prince Yasuhiko Asaka out for censure as the one imperial kinsman whose attitude was "not good". He assigned Asaka to Nanjing as an opportunity to make amends. It appears that Hirohito never learned of, or refused to admit, Asaka's role in the ensuing massacre.
On December 5, Asaka left Tokyo by plane and arrived at the front three days later. He met with division commanders, lieutenant-generals Kesago Nakajima and Heisuke Yanagawa, who informed him that the Japanese troops had almost completely surrounded 300,000 Chinese troops in the vicinity of Nanjing and that preliminary negotiations suggested that the Chinese were ready to surrender.
Prince Asaka is alleged to have issued an order to "kill all captives", thus providing official sanction for the crimes which took place during and after the battle. Some authors record that Prince Asaka signed the order for Japanese soldiers in Nanking to "kill all captives". Others assert that lieutenant colonel Isamu Chō, Asaka's aide-de-camp, sent this order under the Prince's sign manual without the Prince's knowledge or assent. Nevertheless, even if Chō took the initiative, Asaka was nominally the officer in charge and gave no orders to stop the carnage. When General Matsui arrived four days after it had begun, he issued strict orders that resulted in its eventual end.
While the extent of Prince Asaka's responsibility for the massacre remains a matter of debate, the ultimate sanction for the massacre and the crimes committed during the invasion of China were issued in Emperor Hirohito's ratification of the Japanese army's proposition to remove the constraints of international law on the treatment of Chinese prisoners on August 5, 1937.
Battle of Nanking.
Siege of the city.
The Japanese military continued to move forward, breaching the last lines of Chinese resistance, and arriving outside the walled city of Nanking on December 9.
Demand for surrender.
At noon on December 9, the military dropped leaflets into the city, urging the surrender of Nanking within 24 hours, promising annihilation if refused.
Meanwhile, members of the Committee contacted Tang and suggested a plan for three-day cease-fire, during which the Chinese troops could withdraw without fighting while the Japanese troops would stay in their present position.
General Tang agreed with this proposal if the International Committee could acquire permission of Generalissimo Chiang Kai-shek, who had already fled to Hankow to which he had temporarily shifted the military headquarters two days earlier.
John Rabe boarded the U.S. gunboat "Panay" on December 9 and sent two telegrams, one to Chiang Kai-shek by way of the American ambassador in Hankow, and one to the Japanese military authority in Shanghai. The next day he was informed that Chiang Kai-shek, who had ordered that Nanking be defended "to the last man," had refused to accept the proposal.
Assault and capture of Nanking.
The Japanese awaited an answer to their demand for surrender but no response was received from the Chinese by the deadline on December 10. General Iwane Matsui waited another hour before issuing the command to take Nanking by force. The Japanese army mounted its assault on the Nanking walls from multiple directions; the SEF’s 16th Division attacked three gates on the eastern side, the 6th Division of the 10A launched its offensive on the western walls, and the SEF’s 9th Division advanced into the area in-between.
On December 12, under heavy artillery fire and aerial bombardment, General Tang Sheng-chi ordered his men to retreat. What followed was nothing short of chaos. Some Chinese soldiers stripped civilians of their clothing in a desperate attempt to blend in, and many others were shot by the Chinese supervisory unit as they tried to flee.
On 13 December, the 6th and the 116th Divisions of the Japanese Army were the first to enter the city, facing little military resistance. Simultaneously, the 9th Division entered nearby Guanghua Gate, and the 16th Division entered the Zhongshan and Taiping gates. That same afternoon, two small Japanese Navy fleets arrived on both sides of the Yangtze River.
Pursuit and mopping-up operations.
Japanese troops pursued the retreating Chinese army units, primarily in the Xiakuan area to the north of the city walls and around the Zijin Mountain in the east. Although most sources suggest that the final phase of the battle consisted of a one-sided slaughter of Chinese troops by the Japanese, some Japanese historians maintain that the remaining Chinese military still posed a serious threat to the Japanese. Prince Yasuhiko Asaka told a war correspondent later that he was in a very perilous position when his headquarters was ambushed by Chinese forces that were in the midst of fleeing from Nanking east of the city. On the other side of the city, the 11th Company of the 45th Regiment encountered some 20,000 Chinese soldiers who were making their way from Xiakuan.
The Japanese army conducted its mopping-up operation both inside and outside the Nanking Safety Zone. Since the area outside the safety zone had been almost completely evacuated, the mopping-up effort was concentrated in the safety zone. The safety zone, an area of 3.85 square kilometres, was packed with the remaining population of Nanking. The Japanese army leadership assigned sections of the safety zone to some units to separate alleged plain-clothed soldiers from the civilians.
Massacre.
Eyewitness accounts of Westerners and Chinese present at Nanking in the weeks after the fall of the city say that over the course of six weeks following the fall of Nanking, Japanese troops engaged in rape, murder, theft, arson, and other war crimes. Some of these accounts came from foreigners who opted to stay behind in order to protect Chinese civilians from harm, including the diaries of John Rabe and American Minnie Vautrin. Other accounts include first-person testimonies of Nanking Massacre survivors, eyewitness reports of journalists (both Western and Japanese), as well as the field diaries of military personnel. American missionary John Magee stayed behind to provide a 16 mm film documentary and first-hand photographs of the Nanking Massacre.
A group of foreign expatriates headed by Rabe had formed the 15-man International Committee on November 22 and mapped out the Nanking Safety Zone in order to safeguard civilians in the city, where the population numbered from 200,000 to 250,000. Rabe and American missionary Lewis S. C. Smythe, secretary of the International Committee and a professor of sociology at the University of Nanking, recorded the actions of the Japanese troops and filed complaints to the Japanese embassy.
Massacre contest.
In 1937, the "Osaka Mainichi Shimbun" and its sister newspaper the "Tokyo Nichi Nichi Shimbun" covered a "contest" between two Japanese officers, Toshiaki Mukai and Tsuyoshi Noda, both from Island troops, the Japanese 16th Division, in which the two men were described as vying with one another to be the first to kill 100 people with a sword before the capture of Nanking. From Jurong to Tangshan (two cities in Jiangshu Province, China), Toshiaki Mukai had killed 89 people while Tsuyoshi Noda had killed 78 people. The contest continued because neither of them had killed 100 people. When they got to Zijin Mountain, Tsuyoshi Noda had killed 105 people while Toshiaki Mukai killed 106 people. Both officers supposedly surpassed their goal during the heat of battle, making it impossible to determine which officer had actually won the contest. Therefore (according to the journalists Asami Kazuo and Suzuki Jiro, writing in the Tokyo Nichi-Nichi Shimbun of December 13), they decided to begin another contest, with the aim being 150 kills. The "Nichi Nichi" headline of the story of December 13 read "'Incredible Record' [in the Contest to] Behead 100 People—Mukai 106 – 105 Noda—Both 2nd Lieutenants Go Into Extra Innings".
After Japan surrendered, Toshiaki Mukai and Tsuyoshi Noda were arrested and executed by shooting in Nanking with the criminal charge “Civilized Public Enemy”.
Rape.
The International Military Tribunal for the Far East estimated that 20,000 women were raped, including infants and the elderly. A large portion of these rapes were systematized in a process where soldiers would search door-to-door for young girls, with many women taken captive and gang raped. The women were often killed immediately after being raped, often through explicit mutilation or by stabbing a bayonet, long stick of bamboo, or other objects into the vagina. Young children were not exempt from these atrocities, and were cut open to allow Japanese soldiers to rape them.
On 19 December 1937, the Reverend James M. McCallum wrote in his diary:
I know not where to end. Never I have heard or read such brutality. Rape! Rape! Rape! We estimate at least 1,000 cases a night, and many by day. In case of resistance or anything that seems like disapproval, there is a bayonet stab or a bullet ... People are hysterical ... Women are being carried off every morning, afternoon and evening. The whole Japanese army seems to be free to go and come as it pleases, and to do whatever it pleases.
On March 7, 1938, Robert O. Wilson, a surgeon at the American-administered University Hospital in the Safety Zone, wrote in a letter to his family, "a conservative estimate of people slaughtered in cold blood is somewhere about 100,000, including of course thousands of soldiers that had thrown down their arms".
Here are two excerpts from his letters of 15 and 18 December 1937 to his family:
The slaughter of civilians is appalling. I could go on for pages telling of cases of rape and brutality almost beyond belief. Two bayoneted corpses are the only survivors of seven street cleaners who were sitting in their headquarters when Japanese soldiers came in without warning or reason and killed five of their number and wounded the two that found their way to the hospital. 
Let me recount some instances occurring in the last two days. Last night the house of one of the Chinese staff members of the university was broken into and two of the women, his relatives, were raped. Two girls, about 16, were raped to death in one of the refugee camps. In the University Middle School where there are 8,000 people the Japs came in ten times last night, over the wall, stole food, clothing, and raped until they were satisfied. They bayoneted one little boy of eight who have ["sic"] five bayonet wounds including one that penetrated his stomach, a portion of omentum was outside the abdomen. I think he will live. 
In his diary kept during the aggression against the city and its occupation by the Imperial Japanese Army, the leader of the Safety Zone, John Rabe, wrote many comments about Japanese atrocities. For 17 December:
Two Japanese soldiers have climbed over the garden wall and are about to break into our house. When I appear they give the excuse that they saw two Chinese soldiers climb over the wall. When I show them my party badge, they return the same way. In one of the houses in the narrow street behind my garden wall, a woman was raped, and then wounded in the neck with a bayonet. I managed to get an ambulance so we can take her to Kulou Hospital ... Last night up to 1,000 women and girls are said to have been raped, about 100 girls at Ginling College Girls alone. You hear nothing but rape. If husbands or brothers intervene, they're shot. What you hear and see on all sides is the brutality and bestiality of the Japanese soldiers. 
There are also accounts of Japanese troops forcing families to commit acts of incest. Sons were forced to rape their mothers, fathers were forced to rape daughters. One pregnant woman who was gang-raped by Japanese soldiers gave birth only a few hours later; although the baby appeared to be physically unharmed (Robert B. Edgerton, "Warriors of the Rising Sun"). Monks who had declared a life of celibacy were also forced to rape women.
Massacre of civilians.
Following the capture of Nanking, a massacre was perpetrated by the Japanese army which led to the deaths of up to 60,000 residents in the city, a figure difficult to calculate precisely due to the many bodies deliberately burnt, buried in mass graves, or deposited in the Yangtze River by the IJA. Japanese ultra-nationalists have strongly disputed such death tolls, with some stating that only several hundred civilians were killed during the massacre. B. Campbell, in an article published in the journal "Sociological Theory", has described the Nanking Massacre as a genocide considering the fact that the residents were still unilaterally killed in masses during the aftermath, despite the successful and certain outcome in battle. On 13 December 1937, John Rabe wrote in his diary:
It is not until we tour the city that we learn the extent of destruction. We come across corpses every 100 to 200 yards. The bodies of civilians that I examined had bullet holes in their backs. These people had presumably been fleeing and were shot from behind. The Japanese march through the city in groups of ten to twenty soldiers and loot the shops ... I watched with my own eyes as they looted the café of our German baker Herr Kiessling. Hempel's hotel was broken into as well, as almost every shop on Chung Shang and Taiping Road.
On 10 February 1938, Legation Secretary of the German Embassy, Rosen, wrote to his Foreign Ministry about a film made in December by Reverend John Magee to recommend its purchase. Here is an excerpt from his letter and a description of some of its shots, kept in the Political Archives of the Foreign Ministry in Berlin.
During the Japanese reign of terror in Nanking – which, by the way, continues to this day to a considerable degree – the Reverend John Magee, a member of the American Episcopal Church Mission who has been here for almost a quarter of a century, took motion pictures that eloquently bear witness to the atrocities committed by the Japanese ... One will have to wait and see whether the highest officers in the Japanese army succeed, as they have indicated, in stopping the activities of their troops, which continue even today.
On December 13, about 30 soldiers came to a Chinese house at #5 Hsing Lu Koo in the southeastern part of Nanking, and demanded entrance. The door was open by the landlord, a Mohammedan named Ha. They killed him immediately with a revolver and also Mrs. Ha, who knelt before them after Ha's death, begging them not to kill anyone else. Mrs. Ha asked them why they killed her husband and they shot her. Mrs. Hsia was dragged out from under a table in the guest hall where she had tried to hide with her 1 year old baby. After being stripped and raped by one or more men, she was bayoneted in the chest, and then had a bottle thrust into her vagina. The baby was killed with a bayonet. Some soldiers then went to the next room, where Mrs. Hsia's parents, aged 76 and 74, and her two daughters aged 16 and 14. They were about to rape the girls when the grandmother tried to protect them. The soldiers killed her with a revolver. The grandfather grasped the body of his wife and was killed. The two girls were then stripped, the elder being raped by 2–3 men, and the younger by 3. The older girl was stabbed afterwards and a cane was rammed in her vagina. The younger girl was bayoneted also but was spared the horrible treatment that had been meted out to her sister and mother. The soldiers then bayoneted another sister of between 7–8, who was also in the room. The last murders in the house were of Ha's two children, aged 4 and 2 respectively. The older was bayoneted and the younger split down through the head with a sword. 
Pregnant women were a target of murder, as they would often be bayoneted in the stomach, sometimes after rape. Tang Junshan, survivor and witness to one of the Japanese army’s systematic mass killings, testified:
The seventh and last person in the first row was a pregnant woman. The soldier thought he might as well rape her before killing her, so he pulled her out of the group to a spot about ten meters away. As he was trying to rape her, the woman resisted fiercely ... The soldier abruptly stabbed her in the belly with a bayonet. She gave a final scream as her intestines spilled out. Then the soldier stabbed the fetus, with its umbilical cord clearly visible, and tossed it aside.
According to Navy veteran Sho Mitani, "The Army used a trumpet sound that meant 'Kill all Chinese who run away'". Thousands were led away and mass-executed in an excavation known as the "Ten-Thousand-Corpse Ditch", a trench measuring about 300 m long and 5 m wide. Since records were not kept, estimates regarding the number of victims buried in the ditch range from 4,000 to 20,000. However, most scholars and historians consider the number to be more than 12,000 victims.
The Hui people, a minority Chinese group who are mainly Muslim, also suffered from the massacres. After the massacre one mosque was found destroyed and others were found to be "filled with dead bodies". Hui volunteers and imams buried over 100 Hui following Muslim ritual.
Extrajudicial killing of Chinese prisoners of war.
On August 6, 1937, Hirohito had personally ratified his army's proposition to remove the constraints of international law on the treatment of Chinese prisoners. This directive also advised staff officers to stop using the term "prisoner of war" (POW).
Immediately after the fall of the city, Japanese troops embarked on a determined search for former soldiers, in which thousands of young men were captured. Many were taken to the Yangtze River, where they were machine-gunned. What was probably the single largest massacre of Chinese troops occurred along the banks of the Yangtze River on December 18 in what is called the Straw String Gorge Massacre. Japanese soldiers took most of the morning tying all of the POWs hands together and in the dusk divided them into 4 columns, and opened fire at them. Unable to escape, the POWs could only scream and thrash in desperation. It took an hour for the sounds of death to stop, and even longer for the Japanese to bayonet each individual. Most were dumped into the Yangtze. It is estimated that at least 57,500 Chinese POWs were killed.
The Japanese troops gathered 1,300 Chinese soldiers and civilians at Taiping Gate and killed them. The victims were blown up with landmines, then doused with petrol before being set on fire. Those that were left alive afterward were killed with bayonets. F. Tillman Durdin and Archibald Steele, American news correspondents, reported that they had seen bodies of killed Chinese soldiers forming mounds six feet high at the Nanking Yijiang gate in the north. Durdin, who was working for "The New York Times", made a tour of Nanking before his departure from the city. He heard waves of machine-gun fire and witnessed the Japanese soldiers gun down some two hundred Chinese within ten minutes. Two days later, in his report to "The New York Times", he stated that the alleys and street were filled with civilian bodies, including women and children.
According to a testimony delivered by missionary Ralph L. Phillips to the U.S. State Assembly Investigating Committee, he was "forced to watch while the Japs disembowled a Chinese soldier" and "roasted his heart and liver and ate them".
Theft and arson.
One-third of the city was destroyed as a result of arson. According to reports, Japanese troops torched newly built government buildings as well as the homes of many civilians. There was considerable destruction to areas outside the city walls. Soldiers pillaged from the poor and the wealthy alike. The lack of resistance from Chinese troops and civilians in Nanking meant that the Japanese soldiers were free to divide up the city's valuables as they saw fit. This resulted in the widespread looting and burglary.
On 17 December, John Rabe wrote as chairman a complaint to Kiyoshi Fukui, second secretary of the Japanese Embassy. The following is an excerpt:
In other words, on the 13th when your troops entered the city, we had nearly all the civilian population gathered in a Zone in which there had been very little destruction by stray shells and no looting by Chinese soldiers even in full retreat ... All 27 Occidentals in the city at that time and our Chinese population were totally surprised by the reign of robbery, raping and killing initiated by your soldiers on the 14th. All we are asking in our protest is that you restore order among your troops and get the normal city life going as soon as possible. In the latter process we are glad to cooperate in any way we can. But even last night between 8 and 9 p.m. when five Occidentals members of our staff and Committee toured the Zone to observe conditions, we did not find any single Japanese patrol either in the Zone or at the entrances! 
Nanking Safety Zone and the role of foreigners.
The Japanese troops did respect the Zone to an extent; no shells entered that part of the city leading up to the Japanese occupation except a few stray shots. During the chaos following the attack of the city, some were killed in the Safety Zone, but the crimes that took place in the rest of the city were far greater by all accounts.
The Japanese soldiers committed actions in the Safety Zone that were part of the larger Nanking Massacre. The International Committee appealed a number of times to the Japanese army, with John Rabe using his credentials as a Nazi Party member, but to no avail. Rabe wrote that from time to time the Japanese would enter the Safety Zone at will, carry off a few hundred men and women, and either summarily execute them or rape and then kill them.
By February 5, 1938, the International Committee had forwarded to the Japanese embassy a total of 450 cases of murder, rape, and general disorder by Japanese soldiers that had been reported after the American, British and German diplomats had returned to their embassies.
It is said that Rabe rescued between 200,000 and 250,000 Chinese people.
Causes.
Jonathan Spence writes "there is no obvious explanation for this grim event, nor can one be found. The Japanese soldiers, who had expected easy victory, instead had been fighting hard for months and had taken infinitely higher casualties than anticipated. They were bored, angry, frustrated, tired. The Chinese women were undefended, their menfolk powerless or absent. The war, still undeclared, had no clear-cut goal or purpose. Perhaps all Chinese, regardless of sex or age, seemed marked out as victims."
Matsui's reaction to the massacre.
On December 18, 1937, as General Iwane Matsui began to comprehend the full extent of the rape, murder, and looting in the city, he grew increasingly dismayed. He reportedly told one of his civilian aides: "I now realize that we have unknowingly wrought a most grievous effect on this city. When I think of the feelings and sentiments of many of my Chinese friends who have fled from Nanking and of the future of the two countries, I cannot but feel depressed. I am very lonely and can never get in a mood to rejoice about this victory." He even let a tinge of regret flavor the statement he released to the press that morning: "I personally feel sorry for the tragedies to the people, but the Army must continue unless China repents. Now, in the winter, the season gives time to reflect. I offer my sympathy, with deep emotion, to a million innocent people." On New Year's Day, Matsui was still upset about the behavior of the Japanese soldiers at Nanking. Over a toast he confided to a Japanese diplomat: "My men have done something very wrong and extremely regrettable."
End of the massacre.
In late January 1938, the Japanese army forced all refugees in the Safety Zone to return home, immediately claiming to have "restored order".
After the establishment of the "weixin zhengfu" (the collaborating government) in 1938, order was gradually restored in Nanking and atrocities by Japanese troops lessened considerably.
On February 18, 1938, the Nanking Safety Zone International Committee was forcibly renamed "Nanking International Rescue Committee", and the Safety Zone effectively ceased to function. The last refugee camps were closed in May 1938.
Recall of Matsui and Asaka.
In February 1938 both Prince Asaka and General Matsui were recalled to Japan. Matsui returned to retirement, but Prince Asaka remained on the Supreme War Council until the end of the war in August 1945. He was promoted to the rank of general in August 1939, though he held no further military commands.
Death toll estimates.
Estimates of the number of victims vary based on the definitions of the geographical range and the duration of the event.
The extent of the atrocities is debated, with numbers ranging from some Japanese claims of several hundred, to the Chinese claim of a non-combatant death toll of 300,000. Historian Tokushi Kasahara states "more than 100,000 and close to 200,000, or maybe more", referring to his own book. This estimation includes the surrounding area outside of the city of Nanking, which is objected by a Chinese researcher (the same book, p. 146). Hiroshi Yoshida concludes "more than 200,000" in his book. Tomio Hora writes of 50,000–100,000 deaths.
Mainstream scholars consider figures from 40,000 to over 300,000 to be an accurate estimate. According to the International Military Tribunal for the Far East, estimates made at a later date indicate that the total number of civilians and prisoners of war murdered in Nanking and its vicinity during the first six weeks of the Japanese occupation was up to 200,000. These estimates are borne out by the figures of burial societies and other organizations, which testify to over 155,000 buried bodies. These figures do not take into account those persons whose bodies were destroyed by burning, drowning or by other means, or whose bodies were interred in mass graves.
According to the verdict of the Nanjing War Crimes Tribunal on 10 March 1947, there are "more than 190,000 mass slaughtered civilians and Chinese soldiers killed by machine gun by the Japanese army, whose corpses have been burned to destroy proof. Besides, we count more than 150,000 victims of barbarian acts buried by the charity organizations. We thus have a total of more than 300,000 victims." However, this estimate includes an accusation that the Japanese Army murdered 57,418 Chinese POWs at Mufushan, though the latest research indicates that between 4,000 and 20,000 were massacred, and it also includes the 112,266 corpses allegedly buried by the Chongshantang, a charitable association, though today mainstream historians agree that the Chongshantang's records were at least greatly exaggerated if not entirely fabricated. Bob Wakabayashi concludes from this that estimates over 200,000 are not credible. Ikuhiko Hata considers the number of 300,000 to be a "symbolic figure" representative of China's wartime suffering and not a figure to be taken literally.
Some researchers estimate that between 40,000 and 60,000 people were killed, which corresponds to the figures from three sources; one is the Red Army's official journal of the time, Hangdibao and another is that of Miner Searle Bates of the International Safety Zone Committee, and the third is the aforementioned figure written by John Rabe in a letter.John Rabe, Chairman of the International Committee and Nanking Safety Zone, estimated that between 50,000 and 60,000 (civilians) were killed. However, Erwin Wickert, the editor of "The diaries of John Rabe", points out that "It is likely that Rabe's estimate is too low, since he could not have had an overview of the entire municipal area during the period of the worst atrocities. Moreover, many troops of captured Chinese soldiers were led out of the city and down to the Yangtze, where they were summarily executed. But, as noted, no one actually counted the dead."
The casualty count of 300,000 was first promulgated in January 1938 by Harold Timperley, a journalist in China during the Japanese invasion, based on reports from contemporary eyewitnesses. Other sources, including Iris Chang's "The Rape of Nanking", also conclude that the death toll reached 300,000. In December 2007, newly declassified U.S. government archive documents revealed that a telegraph by the U.S. ambassador to Germany in Berlin sent one day after the Japanese army occupied Nanking, stated that he heard the Japanese Ambassador in Germany boasting that Japanese army killed 500,000 Chinese people as the Japanese army advanced from Shanghai to Nanking. According to the archives research "The telegrams sent by the U.S. diplomats [in Berlin] pointed to the massacre of an estimated half a million people in Shanghai, Suzhou, Jiaxing, Hangzhou, Shaoxing, Wuxi and Changzhou".
Range and duration.
The most conservative viewpoint is that the geographical area of the incident should be limited to the few km2 of the city known as the Safety Zone, where the civilians gathered after the invasion. Many Japanese historians seized upon the fact that during the Japanese invasion there were only 200,000–250,000 citizens in Nanking as reported by John Rabe, to argue that the PRC's estimate of 300,000 deaths is a vast exaggeration.
However, many historians include a much larger area around the city. Including the Xiaguan district (the suburbs north of Nanking, about 31 km2 in size) and other areas on the outskirts of the city, the population of greater Nanking was running between 535,000 and 635,000 civilians and soldiers just prior to the Japanese occupation. Some historians also include six counties around Nanking, known as the Nanking Special Municipality.
The duration of the incident is naturally defined by its geography: the earlier the Japanese entered the area, the longer the duration. The Battle of Nanking ended on December 13, when the divisions of the Japanese Army entered the walled city of Nanking. The Tokyo War Crime Tribunal defined the period of the massacre to the ensuing six weeks. More conservative estimates say that the massacre started on December 14, when the troops entered the Safety Zone, and that it lasted for six weeks. Historians who define the Nanking Massacre as having started from the time that the Japanese Army entered Jiangsu province push the beginning of the massacre to around mid-November to early December (Suzhou fell on November 19), and stretch the end of the massacre to late March 1938.
Various estimates.
Japanese historians, depending on their definition of the geographical and time duration of the killings, give wide-ranging estimates for the number of massacred civilians, from several thousand to upwards of 200,000. The lowest estimate by a Japanese historian is 40,000.
Chinese language sources tend to place the figure of massacred civilians upwards of 200,000. For example, a postwar investigation by the Nanking District Court put the number of dead during the incident as 295,525, 76% of them men, 22% women and 2% children.
A 42-part Taiwanese documentary produced from 1995 to 1997, entitled "An Inch of Blood For An Inch of Land" (一寸河山一寸血), asserts that 340,000 Chinese civilians died in Nanking City as a result of the Japanese invasion: 150,000 through bombing and crossfire in the five-day battle, and 190,000 in the massacre, based on the evidence presented at the Tokyo Trials.
War crimes tribunals.
Shortly after the surrender of Japan, the primary officers in charge of the Japanese troops at Nanking were put on trial. General Matsui was indicted before the International Military Tribunal for the Far East for "deliberately and recklessly" ignoring his legal duty "to take adequate steps to secure the observance and prevent breaches" of the Hague Convention. Hisao Tani, the lieutenant general of the 6th Division of the Japanese army in Nanking, was tried by the Nanjing War Crimes Tribunal.
Other Japanese military leaders in charge at the time of the Nanking Massacre were not tried. Prince Kan'in, chief of staff of the Imperial Japanese Army during the massacre, had died before the end of the war in May 1945. Prince Asaka was granted immunity because of his status as a member of the imperial family. Isamu Chō, the aide of Prince Asaka, and whom some historians believe issued the "kill all captives" memo, had committed suicide during the defense of Okinawa.
Grant of immunity to Prince Asaka.
On May 1, 1946, SCAP officials interrogated Prince Asaka, who was the ranking officer in the city at the height of the atrocities, about his involvement in the Nanking Massacre and the deposition was submitted to the International Prosecution Section of the Tokyo tribunal. Asaka denied the existence of any massacre and claimed never to have received complaints about the conduct of his troops. Whatever his culpability may have been, Asaka was not prosecuted before the International Military Tribunal for the Far East at least in part because under the pact concluded between General MacArthur and Hirohito, the Emperor himself and all the members of the imperial family were granted immunity from prosecution.
Evidence and testimony.
The prosecution began the Nanking phase of its case in July 1946. Dr. Robert O. Wilson, a surgeon and a member of the International Committee for the Nanking Safety Zone, took the witness stand first.
Other members of the International Committee for the Nanking Safety Zone who took the witness stand included Miner Searle Bates and John Magee. George A. Fitch, Lewis Smythe and James McCallum filed affidavits with their diaries and letters.
Another piece of evidence that was submitted to the tribunal was Harold Timperley's telegram regarding the Nanking Massacre which had been intercepted and decoded by the Americans on January 17, 1938.
One of the books by Hsü, Documents of the Nanking Safety Zone, was also adduced in court.
According to Matsui's own diary, one day after he made the ceremonial triumphal entry into the city on December 17, 1937, he instructed the chiefs of staff from each division to tighten military discipline and try to eradicate the sense of disdain for Chinese people among their soldiers.
On February 7, 1938, Matsui delivered a speech at a memorial service for the Japanese officers and men of the Shanghai Expeditionary Force who were killed in action. In front of the high-ranking officers, Domei News Agency reported, he emphasized the necessity to "put an end to various reports affecting the prestige of the Japanese troops."
The entry for the same day in Matsui's diary read, "I could only feel sadness and responsibility today, which has been overwhelmingly piercing my heart. This is caused by the Army's misbehaviors after the fall of Nanking and failure to proceed with the autonomous government and other political plans."
Matsui's defense.
Matsui's defence varied between denying the mass-scale atrocities and evading his responsibility for what had happened. Eventually he ended up making numerous conflicting statements.
In the interrogation in Sugamo prison preceding the trial Matsui admitted that he heard about the many outrages committed by his troops from Japanese diplomats when he entered Nanking on December 17, 1937.
In court, he contradicted the earlier testimony and told the judges that he was not "officially" briefed at the consulate about the evildoings, presumably to avoid admitting any contact with the consulate officials such as Second Secretary (later Acting Consul-General) Fukui Kiyoshi and Attaché Fukuda Tokuyasu who received and dealt with the protests filed by the International Committee.
In the same interrogation session before the trial Matsui said one officer and three low-ranking soldiers were court-martialled because of their misbehavior in Nanking and the officer was sentenced to death.
In his affidavit Matsui said he ordered his officers to investigate the massacre and to take necessary action. In court, however, Matsui said that he did not have jurisdiction over the soldiers' misconduct since he was not in the position of supervising military discipline and morals.
Matsui asserted that he had never ordered the execution of Chinese POWs. He further argued that he had directed his army division commanders to discipline their troops for criminal acts, and was not responsible for their failure to carry out his directives. At trial, Matsui went out of his way to protect Prince Asaka by shifting blame to lower ranking division commanders.
Verdict.
In the end the Tribunal convicted only two defendants to the Rape of Nanking.
Matsui was convicted of count 55, which charged him with being one of the senior officers who "deliberately and recklessly disregarded their legal duty [by virtue of their respective offices] to take adequate steps to secure the observance [of the Laws and Customs of War] and prevent breaches thereof, and thereby violated the laws of war."
Kōki Hirota, who had been the Foreign Minister when Japan conquered Nanking, was convicted of participating in "the formulation or execution of a common plan or conspiracy" (count 1), waging "a war of aggression and a war in violation of international laws, treaties, agreements and assurances against the Republic of China" (count 27) and count 55.
Matsui was convicted by a majority of the judges at the Tokyo tribunal who ruled that he bore ultimate responsibility for the "orgy of crime" at Nanking because, "He did nothing, or nothing effective, to abate these horrors."
Organized and wholesale murder of male civilians was conducted with the apparent sanction of the commanders on the pretext that Chinese soldiers had removed their uniforms and were mingling with the population. Groups of Chinese civilians were formed, bound with their hands behind their backs, and marched outside the walls of the city where they were killed in groups by machine gun fire and with bayonets. --- From Judgment of the International Military Tribunal
Radhabinod Pal, the member of the tribunal from India, dissented from the conviction arguing that the commander-in-chief must rely on his subordinate officers to enforce soldier discipline. "The name of Justice," Pal wrote in his dissent, "should not be allowed to be invoked only for ... vindictive retaliation."
Sentence.
On November 12, 1948, Matsui and Hirota, along with five other convicted Class-A war criminals, were sentenced to death by hanging. Eighteen others received lesser sentences. The death sentence imposed on Hirota, a six-to-five decision by the eleven judges, shocked the general public and prompted a petition on his behalf, which soon gathered over 300,000 signatures but did not succeed in commuting the Minister's sentence.
General Hisao Tani was sentenced to death by the Nanking War Crimes Tribunal.
Memorials.
In 1985, the Nanjing Massacre Memorial Hall was built by the Nanking Municipal Government in remembrance of the victims and to raise awareness of the Nanking Massacre. It is located near a site where thousands of bodies were buried, called the "pit of ten thousand corpses" ("wàn rén kēng").
In 1995, Daniel Kwan held a photograph exhibit in Los Angeles titled, "The Forgotten Holocaust".
In 2005, John Rabe's former residence in Nanking was renovated and now accommodates the "John Rabe and International Safety Zone Memorial Hall", which opened in 2006.
On December 13, 2014, China held its first Nanjing Massacre memorial day.
Controversy.
China and Japan have both acknowledged the occurrence of wartime atrocities. Disputes over the historical portrayal of these events continue to cause tensions between Japan on one side and China and other East Asian countries on the other side.
Cold War.
Before the 1970s, China did relatively little to draw attention to the Nanking massacre. In her book "Rape of Nanking" Iris Chang asserted that the politics of the Cold War encouraged Mao to stay relatively silent about Nanking in order to keep a trade relationship with Japan. In turn, China and Japan occasionally used Nanking as an opportunity to demonize one another.
Debate in Japan.
The major waves of Japanese treatment of these events have ranged from total cover-up during the war, confessions and documentation by the Japanese soldiers during the 1950s and 1960s, minimization of the extent of the Nanking Massacre during the 1970s and 1980s, official Japanese government distortion and rewriting of history during the 1980s, and total denial of the occurrence of the Nanking Massacre by some government officials in 1990.
The debate concerning the massacre took place mainly in the 1970s. During this time, the Chinese government's statements about the event were attacked by the Japanese because they were said to rely too heavily on personal testimonies and anecdotal evidence. Aspersions were cast regarding the authenticity and accuracy of burial records and photographs presented in the Tokyo War Crime Court, which were said to be fabrications by the Chinese government, artificially manipulated or incorrectly attributed to the Nanking Massacre.
During the 1970s, Katsuichi Honda wrote a series of articles for the "Asahi Shimbun" on war crimes committed by Japanese soldiers during World War II (such as the Nanking Massacre). The publication of these articles triggered a vehement response from Japanese right-wingers regarding the Japanese treatment of the war crimes. In response, Shichihei Yamamoto and Akira Suzuki wrote two controversial yet influential articles which sparked the negationist movement.
In 1984, in an attempt to refute the allegations of war crimes in Nanking, the Japanese Army Veterans Association (Kaikosha) interviewed former Japanese soldiers who had served in the Nanking area from 1937 to 1938. Instead of refuting the allegations, the interviewed veterans confirmed that a massacre had taken place and openly described and admitted to taking part in the atrocities. The results of the survey were published in the association's magazine, "Kaiko", in 1985 along with an admission and apology that read, "Whatever the severity of war or special circumstances of war psychology, we just lose words faced with this mass illegal killing. As those who are related to the prewar military, we simply apologize deeply to the people of China. It was truly a regrettable act of barbarity."
Apology and condolences by the Prime Minister and Emperor of Japan.
On August 15, 1995, the fiftieth anniversary of the Surrender of Japan, the Japanese prime minister Tomiichi Murayama gave the first clear and formal apology for Japanese actions during the war. He apologized for Japan's wrongful aggression and the great suffering that it inflicted in Asia. He offered his heartfelt apology to all survivors and to the relatives and friends of the victims. That day, the prime minister and the Japanese Emperor Akihito pronounced statements of mourning at Tokyo's Nippon Budokan. The emperor offered his condolences and expressed the hope that such atrocities would never be repeated. Iris Chang, author of "The Rape of Nanking", criticized Murayama for not providing the written apology that had been expected. She said that the people of China "don't believe that an... unequivocal and sincere apology has ever been made by Japan to China" and that a written apology from Japan would send a better message to the international community.
Denials of the massacre by public officials in Japan.
In May 1994, Justice Minister Shigeto Nagano called the Nanjing Massacre a "fabrication".
On June 19, 2007, a group of around 100 Liberal Democratic Party (LDP) lawmakers again denounced the Nanjing Massacre as a fabrication, arguing that there was no evidence to prove the allegations of mass killings by Japanese soldiers. They accused Beijing of using the alleged incident as a "political advertisement".
On February 20, 2012, Takashi Kawamura, mayor of Nagoya, told a visiting delegation from Nanjing that the massacre "probably never happened". Two days later he defended his remarks, saying, "Even since I was a national Diet representative, I have said [repeatedly] there was no [Nanjing] massacre that resulted in murders of several hundred thousands of people." On April 1, 2013, Kawamura said his position remained unchanged when the issue came up during an election debate.
On February 24, 2012, Tokyo governor Shintaro Ishihara said that he also believes that the Nanjing massacre never happened. He reportedly claims it would have been impossible to kill so many people in such a short period of time. He believes the actual death toll was 10,000.
On February 3, 2014, Naoki Hyakuta, a member of the board of governors of Japan's public broadcasting company, NHK, was quoted as saying the massacre never occurred. He said that there were isolated incidents of brutality but no widespread atrocity, and criticized the Tokyo Trials figure of 200,000.
Legacy.
Effect on international relations.
The memory of the Nanking Massacre has been a stumbling block in Sino-Japanese relations since the early 1970s. Bilateral exchanges on trade, culture and education have increased greatly since the two countries normalized their bilateral relations and Japan became China’s most important trading partner. Trade between the two nations is worth over $200 billion annually. Despite this, many Chinese people still have a strong sense of mistrust and animosity toward Japan that originates from the memory of Japanese war crimes such as the Nanking Massacre. This sense of mistrust is strengthened by the belief that Japan is unwilling to admit to and apologize for the atrocities.
Takashi Yoshida described how changing political concerns and perceptions of the "national interest" in Japan, China, and Western countries have shaped collective memory of the Nanking massacre. Yoshida asserted that over time the event has acquired different meanings to different people.
Many Japanese prime ministers have visited the Yasukuni Shrine, a shrine for dead Japanese soldiers of World War II, including some war criminals of the Nanking Massacre. In the museum adjacent to the shrine, a panel informs visitors that there was no massacre in Nanjing, but that Chinese soldiers in plain clothes were "dealt with severely". In 2006 former Japanese prime minister Junichiro Koizumi made a pilgrimage to the shrine despite warnings from China and South Korea. His decision to visit the shrine regardless sparked international outrage. Although Koizumi denied that he was trying to glorify war or historical Japanese militarism, The Chinese Foreign Ministry accused Koizumi of "wrecking the political foundations of China-Japan relations". An official from South Korea said they would summon the Tokyo ambassador to protest.
As a component of national identity.
Takashi Yoshida asserts that, "Nanking has figured in the attempts of all three nations [China, Japan and the United States] to preserve and redefine national and ethnic pride and identity, assuming different kinds of significance based on each country's changing internal and external enemies."
Japan.
In Japan, the Nanking Massacre touches upon national identity and notions of "pride, honor and shame". Yoshida argues that "Nanking crystallizes a much larger conflict over what should constitute the ideal perception of the nation: Japan, as a nation, acknowledges its past and apologizes for its wartime wrongdoings; or ... stands firm against foreign pressures and teaches Japanese youth about the benevolent and courageous martyrs who fought a just war to save Asia from Western aggression." Recognizing the Nanking Massacre as such can be viewed in some circles in Japan as "Japan bashing" (in the case of foreigners) or "self-flagellation" (in the case of Japanese).
The majority of Japanese acknowledge that Japanese troops committed atrocities during the Nanking Massacre. Some Japanese officials and writers have openly denied the incident, claiming it to be propaganda designed to spark an anti-Japan movement. In many ways, how "atrocious" the massacre was is the touchstone of left–right divide in Japan; i.e., leftists feel this is a defining moment of the Imperial Japanese Army; rightists believe Perry's opening of Japan and the atomic bombings are far more significant events.
China.
The Nanking massacre has emerged as a fundamental keystone in the construction of the modern Chinese national identity. Modern Chinese (including citizens of the PRC, Taiwan, and overseas) will refer to the Nanking Massacre to explain certain stances they hold or ideas they have; this 'national unifying event' holds true to middle-school educated peasants and to senior government officials alike.
Popular media.
Records.
In December 2007, the PRC government published the names of 13,000 people who were killed by Japanese troops in the Nanking Massacre. According to Xinhua News Agency, it is the most complete record to date. The report consists of eight volumes and was released to mark the 70th anniversary of the start of the massacre. It also lists the Japanese army units that were responsible for each of the deaths and states the way in which the victims were killed. Zhang Xianwen, editor-in-chief of the report, states that the information collected was based on "a combination of Chinese, Japanese and Western raw materials, which is objective and just and is able to stand the trial of history." This report formed part of a 55-volume series (Collection of Historical Materials of Nanjing Massacre () about the massacre.
References.
</dl>
Further reading.
</dl>

</doc>
<doc id="55072" url="http://en.wikipedia.org/wiki?curid=55072" title="Puyi">
Puyi

Puyi (; 7 February 1906 – 17 October 1967), of the Manchu Aisin Gioro clan, commonly known as Henry Pu Yi (Pu-yi; ), was the last Emperor of China and the twelfth and final ruler of the Qing dynasty.
Still a child, he ruled as the Xuantong Emperor () from 1908 until his abdication on 12 February 1912, after the successful Xinhai Revolution. From 1 to 12 July 1917, he was briefly restored to the throne as a nominal emperor by the warlord Zhang Xun. In 1932, after the occupation of Manchuria and Manchukuo was established by Japan, he was chosen in assuming the title of Chief Executive of the new state using the era name of Datong (Ta-tung). In 1934, he was declared the Kangde Emperor (Kang-te Emperor) of the puppet state of Manchukuo by the Empire of Japan, and he ruled until the end of the Second Sino-Japanese War in 1945.
After the People's Republic of China was established in 1949, Puyi was imprisoned as a war criminal for ten years, wrote his memoirs, and became a member of the Chinese People's Political Consultative Conference.
Names and titles.
Name.
Puyi's name is romanised in English as either "Puyi" or "Pu-yi". This naming is in accordance with the Manchu tradition of avoiding the use of a person's clan name and given name together, but is in complete contravention of Chinese tradition, whereby the given name of a ruler was considered taboo and ineffable. Using a former emperor's personal name (or even using a Chinese character from the name) was a punishable offence under traditional Chinese law. However after Puyi lost his imperial title in 1924, he was officially styled "Mr. Puyi" (Mr. Pu-yi; ) in Chinese and "Mr. Fugi" (溥儀先生; "Fugi Sensei") in Japanese. His clan name "Aisin Gioro" () was seldom used.
Puyi also adopted other names — his "zi" (字; courtesy name) was "Yaozhi" (), and his "hao" (號; pseudonym) was "Haoran" ().
Puyi is also known to have used a Western given name, "Henry," which was chosen by his English-language teacher, a Scotsman named Reginald Johnston.
Titles.
When he ruled as Emperor of the Qing Dynasty from 1908 to 1912 and during his brief restoration in 1917, Puyi's era name was "Xuantong", so he was known as the "Xuantong Emperor" () during those two periods of time.
As Puyi was also the last ruling Emperor of China, he is widely known as "The Last Emperor" () in China and throughout the rest of the world. Some refer to him as "The Last Emperor of the Qing Dynasty" ().
Due to his abdication, Puyi is also known as "Xun Di" () or "Fei Di" (). Sometimes a "Qing" () is added in front of the two titles to indicate his affiliation with the Qing Dynasty.
When Puyi ruled the puppet state of Manchukuo and assuming the title of Chief Executive of the new state, his era name was "Datong" (Ta-tung). And he became the emperor from 1934 to 1945, his era name was "Kangde" (Kang-te), so he was known as the "Kangde Emperor" (, Japanese: Kōtoku Kōtei) during that period of time.
Ancestry.
Paternal side.
Puyi's great-grandfather was the Daoguang Emperor (r. 1820–1850), who was succeeded by his fourth son, the Xianfeng Emperor (r. 1850–1861).
Puyi's paternal grandfather was Yixuan, Prince Chun (1840–1891), the seventh son of the Daoguang Emperor and a younger half-brother of the Xianfeng Emperor. The Xianfeng Emperor was succeeded by his only son, who became the Tongzhi Emperor (r. 1861–1875).
The Tongzhi Emperor died at the age of 18 without a son, and was succeeded by the Guangxu Emperor (r. 1875–1908), son of 1st Prince Chun and Lady Yehenara Wanzhen (younger sister of Empress Dowager Cixi). The Guangxu Emperor died without an heir.
Puyi, who succeeded the Guangxu Emperor, was the eldest son of Zaifeng, Prince Chun, who was born to Yixuan, Prince Chun and his second concubine Lady Lingiya (1866–1925). Lady Lingiya used to be a maid in the residence of Yixuan. Born to a Han Bannerman family, her original family name was Liu (劉), and this was changed to the Manchu clan name Lingiya when she became the concubine of Yixuan and was transferred to a Manchu banner. Zaifeng was therefore a younger half-brother of the Guangxu Emperor and the first in line to succession after Guangxu.
Puyi was in a branch of the Aisin Gioro clan with close ties to Empress Dowager Cixi, who was from the Yehenara clan. Cixi's niece, who later became Empress Dowager Longyu (1868–1913), was married to the Guangxu Emperor.
Puyi had a younger full brother, Pujie (1907–1994), who married a cousin of Emperor Hirohito, Lady Hiro Saga. The rules of succession were changed to allow Pujie to succeed Puyi, who had no children.
Puyi's last surviving younger half-brother Puren (b. 1918) has adopted the Chinese name Jin Youzhi and currently still lives in China. In 2006 Jin Youzhi filed a lawsuit in regards to the rights to Puyi's image and privacy. The lawsuit claimed that those rights were violated by the exhibit "China's Last Monarch and His Family".
Puyi's second cousin, Pu Xuezhai (溥雪齋), was a musician who played the guqin, and an artist of Chinese painting.
Maternal side.
Puyi's mother was Youlan (1884–1921), the daughter of Ronglu (1836–1903), a statesman and general from the Guwalgiya clan. Ronglu was one of the leaders of the conservative faction in the Qing court, and a staunch supporter of Empress Dowager Cixi; Cixi rewarded his support by marrying his daughter, Puyi's mother, into the imperial family.
The Guwalgiya clan was regarded as one of the most powerful Manchu clans in the Qing Dynasty. Oboi, an influential military commander and statesman who was a regent during the Kangxi Emperor's reign, was from the Guwalgiya clan.
Biography.
Emperor of China (1908–1912).
Chosen by Empress Dowager Cixi on her deathbed, Puyi became emperor at the age of 2 years and 10 months in December 1908 after the Guangxu Emperor died on 14 November. Titled the Xuantong Emperor (Wade-Giles: Hsuan-tung Emperor), Puyi's introduction to the life of an emperor began when palace officials arrived at his family residence to take him. The toddler Puyi screamed and resisted as the officials ordered the eunuch attendants to pick him up. His father, Prince Chun, became Prince-Regent (摄政王). During Puyi's coronation in the Hall of Supreme Harmony, the young emperor was carried onto the throne by his father. Puyi was so frightened by the scene before him and the deafening sounds of ceremonial drums and music that he started crying. His father could do nothing except to quietly comfort him, "Don't cry, it'll be over soon."
Puyi's wet nurse, Wen-Chao Wang, was the only one who could console him, and therefore she accompanied him to the Forbidden City. Puyi did not see his biological mother, Princess Consort Chun, for the next seven years. He developed a special bond with Wen-Chao Wang and credited her with being the only person who could control him. She was sent away when he was eight years old. After Puyi married, he would occasionally bring her to the Forbidden City, and later Manchukuo, to visit him. After his special government pardon in 1959, he visited her adopted son and only then learned of her personal sacrifices to be his nurse.
Puyi's upbringing was hardly conducive to the raising of a healthy, well-balanced child. Overnight, he was treated as a god and unable to behave as a child. The adults in his life, except for his wet-nurse Wen-Chao Wang, were all strangers, remote, distant, and unable to discipline him. Wherever he went, grown men would kneel down in a ritual kowtow, averting their eyes until he passed. Soon the young Puyi discovered the absolute power he wielded over the eunuchs, and he frequently had them beaten for small transgressions.
Eunuchs and the Household Department.
Quotation of Puyi:
After his marriage, Puyi began to take control of the palace. He described "an orgy of looting" taking place that involved "everyone from the highest to the lowest". According to Puyi, by the end of his wedding ceremony, the pearls and jade in the empress's crown had been stolen. Locks were broken, areas ransacked, and on June 27, 1923, a fire destroyed the area around the Palace of Established Happiness. Puyi suspected it was arson to cover theft. The emperor overheard conversations among the eunuchs that made him fear for his life. In response, he evicted the eunuchs from the palace. His own brother, Pujie was rumored to steal treasures and art collections and sell to wealthy collectors in the black market. His next plan of action was to reform the Household Department. In this period, he brought in more outsiders to replace the traditionally aristocratic officers in order to improve the accountability. He appointed Zheng Xiaoxu as the minister of Household Department and Zheng Xiaoxu hired Tong Jixu, a former Air Force officer from the Beiyang Military, as his chief of staff to clean up the act. However, the reform did not last long before Puyi was forced out of the Forbidden City by Feng Yuxiang.
Abdication.
Puyi's father, Prince Chun, served as a regent until 6 December 1911 when Empress Dowager Longyu took over following the Xinhai Revolution.
Empress Dowager Longyu endorsed the "Imperial Edict of the Abdication of the Qing Emperor" (清帝退位詔書) on 12 February 1912 under a deal brokered by Yuan Shikai (a general of the Beiyang Army) with the imperial court in Beijing and the Republicans in southern China. Signed with the new Republic of China, Puyi was to retain his imperial title and be treated by the government of the Republic with the protocol attached to a foreign monarch. This was similar to Italy's Law of Guarantees (1870) which accorded the Pope certain honors and privileges similar to those enjoyed by the King of Italy. Puyi and the imperial court were allowed to remain in the northern half of the Forbidden City (the Private Apartments) as well as in the Summer Palace. A hefty annual subsidy of four million silver taels was granted by the Republic to the imperial household, although it was never fully paid and was abolished after just a few years.
The Articles of Favourable Treatment of the Great Qing Emperor after his Abdication.
The document is dated 26 December 1914.
Brief restoration (1917).
In 1917 the warlord Zhang Xun restored Puyi to the throne from July 1 to July 12. Zhang Xun ordered his army to keep their queues to display loyalty to the emperor. During that period of time, a small bomb was dropped over the Forbidden City by a Republican plane, causing minor damage. This is considered the first aerial bombardment ever in East Asia. The restoration failed due to extensive opposition across China, and the decisive intervention of another warlord, Duan Qirui.
The "Articles of Favourable Treatment of the Great Qing Emperor after his Abdication" (清帝退位 優待條件) were revised on November 5, 1924, after the coup by General Feng Yuxiang: the revised articles stated that Puyi was losing his imperial title and henceforth becoming a regular citizen of the Republic of China. Puyi was expelled from the Forbidden City that same day.
Life in the Forbidden City.
Reginald Johnston was appointed as Puyi's English tutor in 1919. Puyi could not speak Manchu; he only knew a single word in the language, "Yili," which meant arise. Despite studying Manchu for years, he admitted that it was his "worst" subject among everything he studied. According to the journalist S. M. Ali, Puyi spoke Mandarin when interviewed but Ali believed that he could understand English.
Reginald Johnston arranged for the Marquis of Extended Grace Zhu Yuxun, a descendant of the Ming dynasty Imperial family, to visit Puyi in the Forbidden City in September 1924, which was the first time the heirs of both the deposed Ming and Qing dynasties came face to face.
Residence in Tianjin (1925–1931).
Following his expulsion from the Forbidden City, Puyi spent a few days at the house of his father Prince Chun, and then temporarily resided in the Japanese embassy in Beijing. In February 1925, he moved to the Japanese Concession of Tianjin, first into the Zhang Garden (張園), and in 1927 into the former residence of Lu Zongyu known as the Garden of Serenity (). During this period, Puyi and his advisers Chen Baochen, Zheng Xiaoxu and Luo Zhenyu discussed plans to restore Puyi as Emperor. Zheng and Luo favoured enlisting assistance from external parties, while Chen opposed the idea. In September 1931 Puyi sent a letter to Jirō Minami, the Japanese Minister of War, expressing his desire to be restored to the throne. He was visited by Kenji Doihara, head of the espionage office of the Japanese Kwantung Army, who proposed establishing Puyi as head of a Manchurian state. In the Tientsin Incident during November 1931, Puyi and Zheng Xiaoxu traveled to Manchuria to complete plans for the puppet state of Manchukuo. The Chinese government ordered Puyi's arrest for treason, but was unable to breach the Japanese protection. Chen Baochen returned to Beijing where he died in 1935.
Ruler of Manchukuo (1932–1945).
On 1 March 1932, Puyi was installed by the Japanese as the Chief Executive of Manchukuo, a puppet state of the Empire of Japan, under the reign title Datong (Wade-Giles: Ta-tung; 大同). In 1934, he was officially crowned the emperor of Manchukuo under the reign title Kangde (Wade-Giles: Kang-te; 康德). He was constantly at odds with the Japanese in private, though submissive in public. He resented being "Head of State" and then "Emperor of Manchukuo" rather than being fully restored as a Qing Emperor. Puyi lived in a palace (now the Museum of the Imperial Palace of the Manchu State) in this period. At his enthronement he clashed with Japan over dress; they wanted him to wear a Manchukuo-style uniform whereas he considered it an insult to wear anything but traditional Manchu robes. In a typical compromise, he wore a Western military uniform to his enthronement (the only Chinese emperor ever to do so) and a dragon robe to the announcement of his accession at the Temple of Heaven.
Puyi's younger full brother Pujie, who married Lady Hiro Saga, a distant cousin to the Japanese Emperor Hirohito, was proclaimed heir apparent. The marriage had been politically arranged by Shigeru Honjō, a general of the Kwantung Army. Puyi thereafter would not speak candidly in front of his brother and refused to eat any food provided by Hiro Saga. Puyi was forced to sign an agreement that if he himself had a male heir, the child would be sent to Japan to be raised by the Japanese.
From 1935 to 1945 Kwantung Army senior staff officer Yoshioka Yasunori (吉岡安則) was assigned to Puyi as Attaché to the Imperial Household in Manchukuo. He acted as a spy for the Japanese government, controlling Puyi through fear, intimidation, and direct orders. There were many attempts on Puyi's life during this period, including a 1937 stabbing by a palace servant. During Puyi's reign as Emperor of Manchukuo, his household was closely watched by the Japanese, who increasingly took steps toward the full Japanisation of Manchuria, to prevent him from becoming too independent. He was feted by the Japanese populace during his visits there, but had to remain subservient to Emperor Hirohito. It is unclear whether the adoption of ancient Chinese styles and rites, such as using "His Majesty" instead of his real name, was the product of Puyi's interest or a Japanese imposition of their own imperial house rules.
During these years, Puyi began taking a greater interest in traditional Chinese law and religion (such as Confucianism and Buddhism), but this was disallowed by the Japanese. Gradually his old supporters were eliminated and pro-Japanese ministers put in their place. During this period Puyi's life consisted mostly of signing laws prepared by Japan, reciting prayers, consulting oracles, and making formal visits throughout his state.
By 1940, the Japanisation of Manchuria had become extreme, and an altar to the Shinto goddess Amaterasu was built on the grounds of Puyi's palace. The origins of the altar are unclear, with the postwar Japanese claiming that Puyi aimed for a closer connection to the Japanese Emperor as a means of resisting the political machinations of the Manchukuo elites, while Puyi in his Chinese Communist-published autobiography claims that he was forced to submit to this by the Japanese. In any case, Puyi's wartime duties came to include sitting through Chinese-language Shinto prayers. Hirohito was surprised when he heard of this, asking why a Temple of Heaven had not been built instead.
Later life (1945–1967).
At the end of World War II, Puyi was captured by the Soviet Red Army on 16 August 1945 while he was in an aeroplane fleeing to Japan. The Soviets took him to the Siberian town of Chita. He lived in a sanatorium, then later in Khabarovsk near the Chinese border.
In 1946, he testified at the International Military Tribunal for the Far East in Tokyo, detailing his resentment of how he had been treated by the Japanese.
When the Chinese Communist Party under Mao Zedong came to power in 1949, Puyi was repatriated to China after negotiations between the Soviet Union and China. Except for a period during the Korean War, when he was moved to Harbin, Puyi spent ten years in the Fushun War Criminals Management Centre in Liaoning province until he was declared reformed. Puyi came to Peking in 1959 with special permission from Chairman Mao Zedong and lived the next six months in an ordinary Peking residence with his sister before being transferred to a government-sponsored hotel. He voiced his support for the Communists and worked at the Peking Botanical Gardens. At the age of 56, he married Li Shuxian, a hospital nurse, on 30 April 1962, in a ceremony held at the Banquet Hall of the Consultative Conference. From 1964 until his death he worked as an editor for the literary department of the Chinese People's Political Consultative Conference, where his monthly salary was around 100 yuan.
With encouragement from Chairman Mao Zedong and Premier Zhou Enlai, and openly endorsed by the Chinese government, Puyi wrote his autobiography "Wo De Qian Ban Sheng" (; translated in English as "From Emperor to Citizen") in the 1960s together with Li Wenda, an editor of Peking's People Publishing Bureau. In the Oxford University edition of the book, in the chapter "I Refuse to Admit My Guilt", he made this statement regarding his testimony at the Tokyo war crimes trial:
Death and burial.
Mao Zedong started the Cultural Revolution in 1966, and the youth militia known as the Red Guards saw Puyi, who symbolised Imperial China, as an easy target of attack. Puyi was placed under protection by the local public security bureau and, although his food rations, salary, and various luxuries, including his sofa and desk, were removed, he was not publicly humiliated as was common at the time. But by now, Puyi had aged and began to decline. He died in Beijing of complications arising from kidney cancer and heart disease on 17 October 1967 at the age of 61.
In accordance with the laws of the People's Republic of China at the time, Puyi's body was cremated. His ashes were first placed at the Babaoshan Revolutionary Cemetery, alongside those of other party and state dignitaries. (This was the burial ground of imperial concubines and eunuchs prior to the establishment of the People's Republic of China.)
In 1995, as a part of a commercial arrangement, Puyi's widow transferred his ashes to a new commercial cemetery in return for monetary support. The cemetery is located near the Western Qing Tombs, 120 km southwest of Peking, where four of the nine Qing emperors preceding him are interred, along with three empresses and 69 princes, princesses and imperial concubines.
Family.
Quotation of Puyi:
"The Pedigree of the Qing House" flow chart can be found in Puyi's autobiography.
Siblings.
Puyi had three younger brothers:
Puyi had seven younger sisters, only the first three were his full sisters:
Spouses.
Quotation of Puyi (referring only to his first four wives):
In 1921, it was decided by the Dowager Consorts (the four widows of the emperors before Puyi) that it was time for the 15 year old Puyi to be married, although court politics dragged the complete process (from selecting the bride, up through the wedding ceremony) out for almost two years. Puyi saw marriage as his coming of age benchmark, when others would no longer control him. He was given four photographs to choose from. Puyi stated they all looked alike to him, with the exception of different clothing. He chose Wenxiu. Political factions within the palace made the actual choice as to whom Puyi would marry. The selection process alone took an entire year.
Wanrong.
Puyi's second choice for his wife was Wanrong, a Daur. She married Puyi in 1922 and became his Empress. Her father, Rong Yuan (榮源), was a Minister of Domestic Affairs. She was considered beautiful and came from a wealthy family. By Puyi's own account, he abandoned Wanrong in the bridal chamber and went back to his own room. He maintained that she was willing to be a wife in name only, in order to carry the title of Empress. The couple's relationship was good initially, and Puyi showed preference over Wenxiu for Wanrong and displayed trust in her. However after Wenxiu left in 1931, Puyi blamed Wanrong and stopped speaking to her and ignored her presence. She became addicted to opium, and eventually died in a prison in Yanji, Jilin after being arrested by Chinese Communist soldiers.
Wenxiu.
Puyi's first choice for his wife was Wenxiu, from the Erdet (鄂爾德特) clan. She married Puyi in 1922. Although she was Puyi's first choice, the Four Dowager Consorts felt that Wenxiu came from an unacceptable impoverished family and was not beautiful enough to be Empress, so they told the court officials to ask Puyi to choose again. The second time Puyi chose Wanrong, who became Empress, while Wenxiu was designated as Consort Shu (淑妃). Puyi and Wenxiu divorced in 1931. Puyi awarded her a house in Beijing and $300,000 in alimony, to be provided by the Japanese. In his autobiography, Puyi stated her reason for the divorce was the emptiness of life with him in exile, her desire for an ordinary family life, and his own inability to see women as anything but slaves and tools of men. According to Puyi, she worked as a school teacher for some years after the divorce. She married Major Liu Zhendong in 1947.
Tan Yuling.
Puyi's third wife, Tan Yuling, was a Manchu of the Tatara (他他拉) clan. She married Puyi in 1937 at the age of 16 on the recommendation of the daughter of Yulang (毓朗), a "beile". She was designated as Puyi's Concubine Xiang (祥貴人). Puyi married her as "punishment" for Wanrong, and, "...because a second wife was as essential as palace furniture." She was also a wife in name only. She became ill in 1942 with typhoid, which the Japanese doctor said would not be fatal. After the doctor's consultation with Attaché to the Imperial Household Yasunori Yoshioka, Tan Yuling suddenly died. Puyi became suspicious of the circumstances when the Japanese immediately offered him photographs of Japanese girls for marriage. Puyi posthumously granted her the title Noble Consort Mingxian (明賢貴妃).
Li Yuqin.
In 1943 Puyi married his fourth wife, a 15-year-old student named Li Yuqin, who was a Han Chinese from Changchun, Jilin. She was designated as Puyi's Concubine Fu (福貴人). In February 1943, school principal Kobayashi and teacher Fujii of the Nan-Ling Girls Academy took ten girl students to a photography studio for portraits. Three weeks later, the school teacher and the principal visited Li Yuqin's home and told her Puyi ordered her to go to the Manchukuo palace to study. She was first taken directly to Yasunori Yoshioka who thoroughly questioned her. Yoshioka then drove her back to her parents and told them Puyi ordered her to study at the palace. Money was promised to the parents. She was subjected to a medical examination and then taken to Puyi's sister Yunhe and instructed in palace protocol.
 Two years later when Manchukuo collapsed, Li Yuqin shared a train with Empress Wanrong, who was experiencing opium withdrawal symptoms at the time. They were both arrested by the Soviets and sent to a prison in Changchun. Li Yuqin was released in 1946 and sent back home. She worked in a textile factory while she studied the works of Karl Marx and Vladimir Lenin. In 1955 she began visiting Puyi in prison. After applying to the Chinese authorities for a divorce, the government responded on her next prison visit by showing her to a room with a double bed and ordered her to reconcile with Puyi, and she said the couple obeyed the order. She divorced Puyi in May 1957. She later married a technician, and had two sons. During the Cultural Revolution she became a target for attack by the Red Guards because she used to be Puyi's concubine. She died of liver problems in 2001.
Li Shuxian.
In 1962 under an arrangement with premier Zhou Enlai, Puyi married his fifth and last wife, Li Shuxian, a nurse of Han Chinese ethnicity. They had no children. She died of lung cancer in 1997. Li Shuxian recounted that they dated for six months before the marriage, and she found him to be, "...a man who desperately needed my love and was ready to give me as much love as he could."
Notes.
¹ Aisin-Gioro is the clan's name in Manchu, pronounced Àixīn Juéluó in Mandarin; Pǔyí is the Chinese given name as pronounced in Mandarin.

</doc>
<doc id="55074" url="http://en.wikipedia.org/wiki?curid=55074" title="Long March">
Long March

The Long March (October 1934 – October 1935) was a military retreat undertaken by the Red Army of the Communist Party of China, the forerunner of the People's Liberation Army, to evade the pursuit of the Kuomintang (KMT or Chinese Nationalist Party) army. There was not one Long March, but a series of marches, as various Communist armies in the south escaped to the north and west. The best known is the march from Jiangxi province which began in October 1934. The First Front Army of the Chinese Soviet Republic, led by an inexperienced military commission, was on the brink of annihilation by Generalissimo Chiang Kai-shek's troops in their stronghold in Jiangxi province. The Communists, under the eventual command of Mao Zedong and Zhou Enlai, escaped in a circling retreat to the west and north, which reportedly traversed over 9,000 kilometers (6,000 miles) over 370 days. The route passed through some of the most difficult terrain of western China by traveling west, then north, to Shaanxi.
The Long March began Mao Zedong's ascent to power, whose leadership during the retreat gained him the support of the members of the party. The bitter struggles of the Long March, which was completed by only about one-tenth of the force that left Jiangxi, would come to represent a significant episode in the history of the Communist Party of China, and would seal the personal prestige of Mao and his supporters as the new leaders of the party in the following decades. 
Background.
The Red Army in 1934.
Although the literal translation of the Chinese "Cháng Zhēng" is “Long March”, official publications of the People's Republic of China refer to "The Long March of the Red Army" (Chinese traditional: 紅軍長征, Chinese simplified: 红军长征, pinyin: Hóngjūn Chángzhēng). The Long March most commonly refers to the transfer of the main group of the First (or Central) Red Army, which included the leaders of the Communist Party of China, from Yudu in the province of Jiangxi, to Yan'an in Shaanxi. In this sense, the Long March lasted from October 16, 1934 to October 19, 1935. In a broader view, the Long March included two other forces retreating under pressure from the Kuomintang: the Second Red Army and the Fourth Red Army. The retreat of all the Red Armies was not complete until October 22, 1935, when the three forces linked up in Shaanxi.
The divisions of the "Chinese Workers' and Peasants' Red Army" (紅軍) were named according to historical circumstances, sometimes in a nonconsecutive way. Early Communist units often formed by defection from existing Kuomintang forces, keeping their original designations. By the time of the Long March, numerous small units had been organized into three unified groups, the First Red Army (紅一方面軍/红一方面军/Hóng Yī Fāngmiàn Jūn), the Second Red Army (紅二方面軍/红二方面军/Hóng Èr Fāngmiàn Jūn) and the Fourth Red Army (紅四方面軍/红四方面军/Hóng Sì Fāngmiàn Jūn). Some translations refer to these same units as the “First Front Red Army", “Second Front Red Army” and “Fourth Front Red Army" to distinguish them from the earlier organizational divisions. The First Red Army formed from the First, Third and Fifth Army Groups in southern Jiangxi under command of Bo Gu and Otto Braun. When the Fourth Red Army under Zhang Guotao was formed in the Sichuan-Shaanxi border area from several smaller units, no standard nomenclature of the armies of the Communist Party existed; moreover, during the Chinese Civil War central control of separate Communist-controlled enclaves within China was limited. After the organization of these first two main forces, the Second Red Army formed in eastern Guizhou by unifying the Second and Sixth Army Groups under He Long and Xiao Ke. A “Third Red Army" was led by He Long who established his base area in the Hunan-Hubei border; by 1932 his forces were soundly defeated and in October 1934 merged with the 6th Army Corps led by Xiao Ke to form the Second Red Army. The three armies would maintain their historical designation as the First, Second and Fourth Red Armies until Communist military forces were nominally integrated into the National Revolutionary Army, forming the Eighth Route Army and the New Fourth Army, during the Second Sino-Japanese War from 1937 to 1945.
Civil war.
The Communist Party of China (CCP), founded in 1921, by Chen Duxiu with Soviet support, initially collaborated with the Chinese Nationalist Party or Kuomintang (KMT), founded by the revolutionary republican Sun Yat-sen. After the unexpected death of Sun in March 1925, a power struggle within the KMT favored Chiang Kai-shek, whose Northern Expedition forces succeeded in wresting control of large areas of China from local warlords, establishing a unified government in Nanjing in April 1927. Unlike other nationalist leaders, like Wang Jingwei, Chiang was hostile to continued collaboration with the Communists. This initial period of cooperation to unify China and end the unequal treaties broke up in April 1927 when Chiang Kai-shek struck out against the Communists. Unsuccessful urban insurrections (in Nanchang, Wuhan and Guangzhou) and the suppression of the Communist Party in Shanghai and other cities drove many party supporters to rural strongholds such as the Jiangxi Soviet organized by Mao Zedong. By 1928, deserters and defecting Kuomintang army units, supplemented by peasants from the Communist rural soviets, formed the Chinese Workers' and Peasants' Red Army. The ideological confrontation between the CCP and the KMT soon evolved into the first phase of the Chinese Civil War.
The Jiangxi Soviet.
By 1930, the Communist Red Army had established the Chinese Soviet Republic in the provinces of Jiangxi and Fujian around the city of Ruijin, including industrial facilities.
After the establishment of the Jiangxi Soviet, Mao's status within the Party declined. In 1930, Mao claimed a need to eliminate alleged KMT spies and Anti-Bolsheviks operating inside the Jiangxi Soviet and began an ideological campaign featuring torture and guilt by association, in order to eliminate his enemies. The campaign continued until the end of 1931, killing approximately 100,000 people and reducing the size of the Red Army from 40,000 to less than 10,000. The "de facto" leader of the party at the time, Zhou Enlai, originally supported Mao's purges as necessary to eliminate KMT spies. After Zhou arrived in Jiangxi in December 1931, he criticized Mao's campaigns for being directed more against anti-Maoists than legitimate threats to the Party, for the campaign's general senselessness, and for the widespread use of torture to extract confessions. During 1932, following Zhou's efforts to end Mao's ideological persecutions, the campaigns gradually subsided.
In December, of 1931 Zhou replaced Mao Zedong as Secretary of the First Front Army and political commissar of the Red Army. Liu Bocheng, Lin Biao and Peng Dehuai all criticized Mao's tactics at the August 1932 Ningdu Conference. The most senior leaders to support Mao in 1932 were Zhou Enlai, who had become disillusioned with the strategic leadership of other senior leaders in the Party, and Mao's old comrade, Zhu De. Zhou's support was not enough, and Mao was demoted to being a figurehead in the Soviet government, until he regained his position later, during the Long March.
Chiang's Encirclement Campaigns.
In early 1933, Bo Gu arrived in Jiangxi with the German Comintern adviser Otto Braun (Li De) and took control of Party affairs. Zhou at this time, apparently with strong support from Party and military colleagues, reorganized and standardized the Red Army. Under Zhou, Bo, and Braun, the Red Army defeated four attacks by Chiang Kai-shek's Nationalist troops.
Chiang's fifth campaign was much more difficult to contain. In September 1933, the National Revolutionary Army under Chiang Kai-shek eventually completely encircled Jiangxi, with the advice and tactical assistance of his German adviser, Hans von Seeckt. A fortified perimeter was established by Chiang's forces, and Jiangxi was besieged in an attempt to destroy the Communist forces trapped within. In July 1934, the leaders of the Party, dominated by the "Twenty-Eight Bolsheviks", a militant group formed in Moscow by Wang Ming and Bo Gu, forced Mao from the Politburo of the Communist Party in Ruijin and placed him briefly under house arrest. Mao was replaced by Zhou Enlai as leader of the military commission.
Chiang's strategy of slowly constructing a series of interlinking blockhouses (resembling medieval castles) was successful, and Chiang's army was able to capture several major Communist strongholds within months. Between January and March 1934, the Nationalists advanced slowly. Bo and Braun continued to employ orthodox military tactics, resulting in a series of defeats and heavy Communist casualties. In October 1934 KMT troops won a decisive battle and drove deep into the heart of the Central Soviet Area. When Ruijin became exposed to KMT attack, Party leaders faced the choice of either remaining and perishing or of abandoning the base area and attempting to break through the enemy encirclement.
In August 1934, with the Red Army depleted by the prolonged conflict, a spy, Mo Xiong, who had been placed by Zhou Enlai in the KMT army headquarters in Nanchang, brought news that Chiang Kai-shek was preparing a major offensive against the Communist capital, Ruijin. The Communist leadership decided on a strategic retreat to regroup with other Communist units, and to avoid annihilation. The original plan was to link up with the Second Red Army commanded by He Long, thought to be in Hubei to the west and north. Communications between divided groups of the Red Army had been disrupted by the Kuomintang campaign. During the planning to evacuate Jiangxi, the First Red Army was unaware that these other Communist forces were also retreating westward.
The Long March.
Escape from Jiangxi.
Since the Central Base Area could not be held, The Standing Committee appointed Bo (responsible for politics), Braun (responsible for military strategy), and Zhou (responsible for the implementation of military planning) to organize the evacuation. Since the enemy was close, Zhou, in charge of logistics, made his plans in complete secrecy. It was not disclosed who was to leave or when: even senior leaders were only at the last moments told of the Army's movements. It is not known what criteria were used to determine who would stay and who would go, but 16,000 troops and some of the Communists' most notable commanders at the time (including Xiang Ying, Chen Yi, Tan Zhenlin, and Qu Qiubai) were left to form a rear guard, to divert the main force of Nationalist troops from noticing, and preventing, the general withdrawal.
The first movements to screen the retreat were undertaken by forces led by Fang Zhimin, breaking through Kuomintang lines in June 1934. Although Fang Zhimin's troops were soon destroyed, these movements surprised the Kuomintang, who were numerically superior to the Communists at the time and did not expect an attack on their fortified perimeter.
The early troop movements were actually a diversion to allow the retreat of more important leaders from Jiangxi. On October 16, 1934, a force of about 130,000 soldiers and civilians under Bo Gu and Li De attacked the line of Kuomintang positions near Yudu. More than 86,000 troops, 11,000 administrative personnel and thousands of civilian porters actually completed the breakout; the remainder, largely wounded or ill soldiers, continued to fight a delaying action after the main force had left, and then dispersed into the countryside. Several prominent members of the Chinese Soviet who remained behind were captured and executed by the Kuomintang after the fall of Ruijin in November 1934, including Qu Qiubai and the youngest brother of Mao Zedong, Mao Zetan.
The withdrawal began in early October 1934. Zhou's intelligence agents were successful in identifying a large section of Chiang's blockhouse lines that were manned by troops under General Chen Jitang, a Guangdong warlord who Zhou identified as being likely to prefer preserving the strength of his troops over fighting. Zhou sent Pan Hannian to negotiate for safe passage with General Chen, who subsequently allowed the Red Army to pass through the territory that he controlled without fighting. The Red army successfully crossed the Xinfeng River and marched through the province of Guangdong and into Hunan before encountering the last of Chiang's fortifications at the Xiang River.
After passing through three of the four blockhouse fortifications needed to escape Chiang's encirclement, the Red Army was finally intercepted by regular Nationalist troops, and suffered heavy casualties. Of the 86,000 Communists who attempted to break out of Jiangxi with the First Red Army, only 36,000 successfully escaped. Due to the low morale within the Red Army at the time, it is not possible to know what proportion of these losses were due to military casualties, and which proportion were due to desertion. The conditions of the Red Army's forced withdrawal demoralized some Communist leaders (particularly Bo Gu and Otto Braun), but Zhou remained calm and retained his command. Most Communist losses occurred over only two days of heavy fighting, from November 30 to December 1, 1934.
Determining the direction of the Red Army.
After escaping Chiang's encirclement, it was obvious to Party leaders that Chiang was intent on intercepting what remained of the Red Army in Hunan, and the direction of the Red Army's movements had to be reconsidered. The plan to rendezvous and join He Long's army in Hunan had become too risky. Mao suggested to Zhou that the Red Army change direction, towards Guizhou, where Mao expected enemy defenses to be weak.
A meeting at Tongdao, close to the border of Hunan and Guizhou, was convened to discuss the direction of the Red Army on December 12, 1934. Zhou endorsed Mao's proposal, encouraging other leaders to overrule the objections of Bo and Braun. Another dispute of the direction of the Red Army occurred soon after, once the Red Army reached Liping, in the mountains of southeast Guizhou. Braun believed that they should travel to eastern Guizhou, but Mao wanted to go to western Guizhou, where he expected KMT forces to be lighter and which borders Sichuan, and to establish a base area there. In a meeting to decide the army's direction, Zhou sided with Mao, making Braun "fly into a rage because he was overruled in the debate." At the meeting it was decided that the Red Army would travel towards Zunyi, in western Guizhou.
On January 1, 1935, the Red Army reached the Wu River. Bo and Braun again insisted the Red Army move back to western Hunan to join other Communist troops in the area, but their prestige had considerably declined by that point, and their suggestion was rejected. Even Zhou had become impatient, and proposed a new rule which was put into effect immediately: that all military plans had to be submitted to the Politburo for approval. The movement passed, clearly depriving Braun of the right to direct military affairs. On January 15 the Red Army captured Zunyi, the second largest city in Guizhou. As Mao had predicted, the city was weakly defended, and was too far from Nationalist forces to be under immediate threat of attack. By the time the Red Army occupied Zunyi, it was highly depleted, and counted little more than 10,000 men. Zhou used the peace afforded in Zunyi to call an enlarged Politburo meeting, in order to examine the causes of the Communists' repeated defeats.
The Zunyi Conference.
The Communists' Zunyi Conference lasted from January 15–17, 1935, and resulted in a reshuffling of the Party politburo. Zhou intended the conference to draw lessons from the Red Army's past failures, and to develop strategies for the future. Much of the discussion revolved around whether the defeats of the Red Army were due to unavoidable circumstances, or inadequacies of leadership. Bo Gu, the first speaker, attributed the Red Army's losses to "objective" causes, particularly the enemy's overwhelming numerical superiority, and poor coordination of Communist forces. Braun's interpreter, Wu Xiuquan, later recalled that Bo's arguments did not impress his audience, and that Bo came across as someone attempting to avoid responsibility.
Zhou Enlai was the next to speak. Zhou blamed the Red Army's failures on poor decisions at the leadership level, and blamed himself as one of the three people most responsible. Zhou's willingness to accept responsibility was well received. Zhang Wentian, basing many of his conclusions on recent discussions with Mao, attacked Bo and Braun directly, criticizing them for numerous strategic and tactical errors.
After Zhang, Mao gave a speech in which he analyzed the poor tactics and strategies of the two leaders. With Zhou's explicit backing, Mao won over the meeting. Seventeen of the meeting's twenty participants (with the exception of Bo, Braun, and He Kequan) argued in his favor.
Of the three leaders who had controlled the Party before the Zunyi Conference, only Zhou Enlai's political career survived. Zhou was held partially responsible for the Red Army's defeat, but was retained at the top level of Party leadership because of his differences with Bo and Braun at Ningdu, his successful tactics in defeating Chiang's fourth Encirclement Campaign, and his resolute support of Mao. Although the failed leadership of Bo Gu and Li De was denounced, Mao was not able to win the support of a sufficient number of Party leaders to gain outright power at the conference.
A major shift in the Party's leadership occurred two months later, in March 1935. Mao was passed over for the position of General Secretary by Zhang Wentian, but gained enough influence to be elected one of three members of Military Affairs Commission. The other two members were Zhou Enlai, who retained his position as Director of the Commission, and Wang Jiaxiang, whose support Mao had enlisted earlier. Within this group, Zhou was empowered to make the final decisions on military matters, while Mao was Zhou's assistant. Wang was in charge of Party affairs.
Escaping Chiang's pursuit.
When the army resumed its march northward, the direct route to Sichuan was blocked by Chiang's forces. Mao's forces spent the next several months maneuvering to avoid direct confrontation with hostile forces, but still attempting to move north to join Zhang Guotao's Fourth Red Army. During this period, in February 1935, Mao's wife, He Zizhen, gave birth to a daughter. Given the harsh conditions of the retreat, the infant was left with a local family (Two Europeans retracing the Long March route in 2003 met a woman in rural Yunnan province, said by local officials to be Mao and He Zizhen's long-lost daughter).
The Communist forces were harassed by both the Kuomintang and its local warlord allies. To avoid a fatal confrontation with the enemy, Zhou and Mao maneuvered the Red army south and west, through Guizhou, Sichuan, and Yunnan, feigning attacks on Guiyang and Kunming to disguise their movements. The First Red Army crossed the Yangtze on May 9, 1935, finally escaping determined enemy pursuit, but still had to deal with dangerous mountain passes at heights of up to 4,000 meters, rough climatic conditions, shortages of food, clothing, and equipment, and tribes of local ethnic groups hostile to Chinese encroachment. The Red Army had to cross mountains and rivers, often capturing river crossings heavily defended by hostile warlords and Nationalist troops, the most famous of which was Luding Bridge (although many historians believe that the battle at Luding Bridge was exaggerated or even entirely fabricated for propaganda purposes).
Conflict with ethnic warlords.
Warlords often refused to help out the Kuomintang against the Communist Red Army, preferring to save their own forces.
300 "Khampa bandits" were enlisted into the Kuomintang's Consolatory Commission military in Sichuan, where they were part of the effort of the central government of China to penetrate and destabilize the local Han warlords such as Liu Wenhui. The Chinese government sought to exercise full control over frontier areas against the warlords. Liu had refused to do battle against the Red Army, to save his own military from destruction. The Consoltary Commission forces were used to battle the Communist Red Army, but were defeated when their religious leader was captured by Communist forces.
Communist forces on the Long March clashed against Kham rebels in the 1934 Khamba Rebellion, who were fleeing from Tibetan government forces.
The Fourth Red Army.
In June–July 1935, the troops under Mao united with the Fourth Red Army, led by Zhang Guotao, which had retreated west from Henan. Zhang had taken a different route of evacuation, and arrived at Lianghekou with 84,000 troops in relatively good condition. The fact that he had control of superior forces gave him the power to challenge the authority of Zhou and Mao, whose power was based largely on the Party's support. Zhang demanded that one of his own generals, Chen Changhao, take over Zhou's position as political commissar of the entire Red Army, and suggested that Zhang himself replace Zhu De on the Military Commission. Zhang argued that such a reorganization would create a more "equal" army organization. On July 18, Zhou relinquished his position as political commissar, and several leading positions were taken over by generals of the Fourth Red Army.
These changes had no long-term significance because Zhang and Mao disagreed with the direction of the army. Zhang insisted on going southwest, while Mao insisted on going northwards, towards Shaanxi. No agreement was reached, and the two armies eventually split, each going their separate ways.
Zhang Guotao's Fourth Red Army took a different route than Mao travelling south, then west, and finally north through China. On the way Zhang's forces were largely destroyed by the forces of Chiang Kai-shek and his Chinese Muslim allies, the Ma clique. The remnants of Zhang's forces later rejoined elements of the Second Red Army before eventually linking up with Mao's forces in Shaanxi.
The Second Red Army.
The Second Red Army began its own withdrawal west from Hubei in November 1935, led by He Long, who commanded the KMT Twentieth Army in 1923 before joining the Communist Party of China (CPC). For retribution Chiang Kai-Shek had He Long's relatives executed, including three sisters and a brother. In 1932 he established a soviet in the Hunan-Jiangxi border area, and in August 1934 received command of the Second Red Army, establishing a base in Hubei. An advance party of the First Red Army called the Sixth Group, commanded by Xiao Ke, was sent towards the Second Red Army two months before the beginning of the Long March. Xiao Ke's force would link up with He Long and his army, but lost communication with the First Army that came behind.
On November 19, 1935, the Second Red Army set out on its own Long March. He Long's force was driven further west than the First Red Army, all the way to Lijiang in Yunnan province, then across the Jade Dragon Snow Mountain massif and through the Tibetan highlands of western Sichuan. He Long and Xiao Ke were married to sisters who also accompanied the army. He Long's wife, Jian Xianren, carried the baby daughter she had given birth to three weeks before the retreat began. Jian Xianfo gave birth to a son in the desolate swamps of northern Sichuan. Forces of the Second Army detained two European missionaries, Rudolf Bosshardt and Arnolis Hayman, for 16 months. Bosshardt later related his account of the details of daily life on the Long March in a book.
Union of the three armies.
Mao's First Red Army traversed several swamps and was attacked by Muslim Hui Ma Clique forces under Generals Ma Bufang and Ma Buqing. Finally, in October 1935, Mao's army reached Shaanxi province and joined with local Communist forces there, led by Liu Zhidan, Gao Gang, and Xu Haidong, who had already established a Soviet base in northern Shaanxi. The remnants of Zhang's Fourth Red Army eventually rejoined Mao in Shaanxi, but with his army destroyed, Zhang, even as a founding member of the CPC, was never able to challenge Mao's authority. After an expedition of almost a year, the Second Red Army reached Bao'an (Shaanxi) on October 22, 1935, known in China as the “union of the three armies”, and the end of the Long March.
All along the way, the Communist Army confiscated property and weapons from local warlords and landlords, while recruiting peasants and the poor. Nevertheless, only some 8,000 troops under Mao's command, the First Front Army, ultimately made it to the final destination of Yan'an in 1935. Of these, less than 7,000 were among the original 100,000 soldiers who had started the march. A variety of factors contributed to the losses including fatigue, hunger and cold, sickness, desertion, and military casualties. During the retreat, membership in the party fell from 300,000 to around 40,000.
In November 1935, shortly after settling in northern Shaanxi, Mao officially took over Zhou Enlai's leading position in the Red Army. Following a major reshuffling of official roles, Mao became the chairman of the Military Commission, with Zhou and Deng Xiaoping as vice-chairmen. (After Zhang Gutao reached Shaanxi, Deng was replaced by Zhang). This marked Mao's position as the pre-eminent leader of the Party, with Zhou in a position second to Mao. Both Mao and Zhou would retain their positions until their deaths, in 1976.
Aftermath.
While costly, the Long March gave the Communist Party of China (CCP) the isolation it needed, allowing its army to recuperate and rebuild in the north of China. It also was vital in helping the CCP to gain a positive reputation among the peasants due to the determination and dedication of the surviving participants of the Long March. Mao wrote in 1935:
In addition, policies ordered by Mao for all soldiers to follow, the Eight Points of Attention, instructed the army to avoid harm to or disrespect for the peasants, in spite of the desperate need for food and supplies. This policy won support for the Communists among the rural peasants.
Hostilities ceased while the Nationalists and Chinese Communists formed a nominal alliance during the Second Sino-Japanese War from 1937 until 1945. During these years, the Chinese Communist Party persevered and strengthened its influence. The Red Army fought a disciplined and organized guerilla campaign against superior Japanese forces, allowing it to gain experience. Following the end of World War II, the resurgent Communist Eighth Route Army, later called the People's Liberation Army, returned to drive the Kuomintang out of Mainland China to the island of Taiwan. Since the establishment of the People's Republic of China in 1949, the Long March has been glorified as an example of the Communist Party's strength and resilience. The Long March solidified Mao's status as the undisputed leader of the CPC. Other participants in the March also went on to become prominent party leaders, including Zhu De, Lin Biao, Liu Shaoqi, Dong Biwu, Ye Jianying, Li Xiannian, Yang Shangkun, Zhou Enlai and Deng Xiaoping.
The Chinese government produced a movie in 2006, "My Long March", relating personal experiences of a fictional participant in the Long March.
Myths.
The Long March is surrounded by controversial and conflicting accounts of what actually occurred. The myths of the march are difficult to uncover because the Chinese government has prevented independent historians from exploring the topic. The few that were able to perform research into the myths of the march have only done so recently and struggle with the fact that many years have gone by since the march took place, hence many of the survivors are no longer alive or able to accurately recall events.
Length.
In 2003, controversy arose about the distance covered by Mao's First Front Army in the Long March. The figure of 25,000 li (12,500 kilometres or about 8,000 miles) was Mao's estimate, quoted by his biographer Edgar Snow in "Red Star Over China", published not long after the end of the Long March in 1938. In 2003, two British researchers, Ed Jocelyn and Andrew McEwen, retraced the route in 384 days, and in their 2006 book "The Long March" estimated the March actually covered about 6,000 km (3,700 miles). Jocelyn and McEwen conclude in their book that "Mao and his followers twisted the tale of the Long March for their own ends. Mao's role was mythologized to the point where ... it seemed he had single-handedly saved the Red Army and defeated Chiang Kai-shek". Mao exaggerated, perhaps even doubled, the length of the march, they believe. Their report has been disputed by the Chinese media, citing "The 25,000 li of the Red Army's Long March are a historic fact and not open to doubt." However, even at the time that Edgar Snow's account was written, there were estimates that the distance traveled was closer to 18,000 li (9,375 km).
Luding Bridge.
The battle for Luding Bridge has been portrayed as a glorious and heroic moment in Chinese Communist history, analogous to the U.S. Battle of the Alamo. The official account of the battle depicts exhausted and depleted Communist forces in a desperate situation, where they must fight across a bridge that is guarded by the numerically superior forces of Chiang Kai-shek and his warlord allies. The Communists send a small volunteer force that braves a hail of gunfire to climb across the bridge on underlying chains and assault the enemy positions on the other side, hence securing the bridgehead for the rest of the army to cross.
However, there is evidence that differs from the official account of the battle. This suggests that much of the fighting was dramatized, by Communist leaders, for propaganda purposes. Authors Andrew McEwen and Ed Jocelyn who retraced the route of the Long March, interviewing survivors along the way, said that a woman in her early 80s recalled that local people led the way across the bridge and were all shot and killed. Author Sun Shuyun quotes a witness who said that there was a small enemy force on the other side armed with guns that could “only fire a few metres”. They panicked and fled.
Use as propaganda.
- Sun Shuyun
The Long March has been depicted as a pillar of the Chinese Communist Revolution and has been a constant theme of communist propaganda since its completion, in 1935. It has been used as an example to depict the nationalistic fighting spirit of the Chinese people and the rallying call to communism. As a propaganda theme, many facts about the Long March have been altered from historical truth. For example, the battle at Xiang River “which the official history of the Long March identifies as the longest and most heroic battle of the entire campaign, was in fact a major defeat for the Communists, with casualties and desertions reducing the First Army from 86,000 to 30,000 people.”
October 2006 marked the 70th anniversary of the end of the Long March. Dozens of newly released, government approved books were proudly displayed in bookstores, with the intention of showing the heroic actions and drama of the Long March. Meanwhile Chinese television presented, “a feast of Long March-themed entertainment, including a 20-part drama series, documentaries, and even a song-and-dance extravaganza.”
Western scholars, when examining the Long March, choose to focus on aspects of the Long March rarely portrayed by Chinese propaganda. Omitted aspects of the Long March include instances of the Red Army desperately recruiting local people through kidnapping and blackmail. Sun Shuyun, while researching a book on the Long March, interviewed one-man who said he was barely into his teens when he was forced to join the Red Army. This veteran only joined the Red Army because his father was arrested by the communists and would not be released until the man agreed to join the army. The man later thought of deserting, but stayed on because he feared being caught and executed. In order to escape starvation, the Red Army often stole food from villagers in the remote locations it traveled through. Driven by desperation and hunger, communist armies during the Long March sometimes took hostages for ransom.

</doc>
<doc id="55076" url="http://en.wikipedia.org/wiki?curid=55076" title="Slaughterhouse">
Slaughterhouse

A slaughterhouse, abattoir or meatworks is a facility where animals are killed for consumption as food. Slaughterhouses that process meat not intended for human consumption are sometimes referred to as knacker's yards or knackeries, used for animals that aren't fit for consumption or can no longer work on a farm such as horses that can no longer work
Slaughtering animals on a large scale poses significant logistical problems and public health requirements and public aversion in many cultures influences the location of slaughterhouses. 
Animal welfare and animal rights groups frequently raise concerns about the methods of transport, preparation, herding, and killing within some slaughterhouses under the example of animal rights activists such as Howard Lyman and Ric O’Barry. 
Productivity.
Typically 45–50% of the animal can be turned into edible products (meat). About 5-15% is waste, and the remaining 40–45% of the animal is turned into byproducts such as leather, soaps, candles (tallow), and animal glue.
History.
Until modern times, the slaughter of animals generally took place in a haphazard and unregulated manner in diverse places. Early maps of London show numerous stockyards in the periphery of the city, where slaughter occurred in the open air. A term for such open-air slaughterhouses was "shambles", and there are streets named "The Shambles" in some English towns (e.g. Worcester, York) which got their name from having been the site on which butchers killed and prepared animals for consumption.
Reform movement.
The slaughterhouse emerged as a coherent institution in the nineteenth century. A combination of health and social concerns, exacerbated by the rapid urbanisation experienced during the Industrial Revolution, led social reformers to call for the isolation, sequester and regulation of animal slaughter. As well as the concerns raised regarding hygiene and disease, there were also criticisms of the practice on the grounds that the effect that killing had, both on the butchers and the observers, "educate[d] the men in the practice of violence and cruelty, so that they seem to have no restraint on the use of it." An additional motivation for eliminating private slaughter was to impose a careful system of regulation for the "morally dangerous" task of putting animals to death.
As a result of this tension, meat markets within the city were closed and abattoirs built outside city limits. An early framework for the establishment of public slaughterhouses was put in place in Paris in 1810, under the reign of the Emperor Napoleon. Five areas were set aside on the outskirts of the city and the feudal privileges of the guilds were curtailed.
As the meat requirements of the growing number of residents in London steadily expanded, 
the meat markets within the city attracted increasing levels of opprobrium. Meat had been traded at Smithfield Market as early as the 10th century. By 1726, it was regarded as "without question, the greatest in the world", by Daniel Defoe. By the middle of the 19th century, in the course of a single year 220,000 head of cattle and 1,500,000 sheep would be "violently forced into an area of five acres, in the very heart of London, through its narrowest and most crowded thoroughfares".
By the early 19th century, pamphlets were being circulated arguing in favour of the removal of the livestock market and its relocation outside of the city due to the extremely poor hygienic conditions as well as the brutal treatment of the cattle. In 1843, the "Farmer's Magazine" published a petition signed by bankers, salesmen, aldermen, butchers and local residents against the expansion of the livestock market.
An Act of Parliament was finally passed in 1852. Under its provisions, a new cattle-market was constructed in Copenhagen Fields, Islington. The new Metropolitan Cattle Market was also opened in 1855, and West Smithfield was left as waste ground for about one decade, until the construction of the new market began in the 1860s under the authority of the 1860 Metropolitan Meat and Poultry Market Act. The market was designed by architect Sir Horace Jones and was completed in 1868.
A cut and cover railway tunnel was constructed beneath the market to create a triangular junction with the railway between Blackfriars and Kings Cross. This allowed animals to be transported into the slaughterhouse by train and the subsequent transfer of animal carcasses to the Cold Store building, or direct to the meat market via lifts.
At the same time, the first large and centralized slaughterhouse in Paris was constructed in 1867 under the orders of Napoleon III at the Parc de la Villette and heavily influenced the subsequent development of the institution throughout Europe.
Regulation and expansion.
These slaughterhouses were regulated by law to ensure good standards of hygiene, the prevention of the spread of disease and the minimization of needless animal cruelty. The slaughterhouse had to be equipped with a specialized water supply system to effectively clean the operating area of blood and offal. Veterinary scientists, notably George Fleming and John Gamgee, campaigned for stringent levels of inspection to ensure that epizootics such as rinderpest (a devastating outbreak of the disease covered all of Britain in 1865) would not be able to spread. By 1874, three meat inspectors were appointed for the London area, and the Public Health Act 1875 required local authorities to provide central slaughterhouses (they were only given powers to close insanitary slaughterhouses in 1890). 
Attempts were also made at reforming the practice of slaughter itself, as the methods used came under increasing criticism for causing undue pain to the animals. The eminent physician, Benjamin Ward Richardson, spent many years in developing more humane methods of slaughter. He brought into use no less than fourteen possible anesthetics for use in the slaughterhouse and even experimented with the use of electric current at the Royal Polytechnic Institution. As early as 1853, he designed a lethal chamber that would gas animals to death relatively painlessly, and he founded the Model Abattoir Society in 1882 to investigate and campaign for humane methods of slaughter.
The invention of refrigeration and the expansion of transportation networks by sea and rail allowed for the safe exportation of meat around the world. Additionally, Meat-packing millionaire Philip Danforth Armour’s invention of the 'disassembly line' greatly increased the productivity and profit margin of industrial meatpacking businesses: "according to some, animal slaughtering became the first mass-production industry in the United States." This expansion has been accompanied by increased concern about the physical and mental conditions of the workers along with controversy over the ethical and environmental implications of slaughtering animals for meat.
Design.
In the latter part of the 20th century, the layout and design of most U.S. slaughterhouses was influenced by the work of Dr. Temple Grandin. She suggested that reducing the stress of animals being led to slaughter may help slaughterhouse operators improve efficiency and profit. In particular she applied an understanding of animal psychology to design pens and corrals which funnel a herd of animals arriving at a slaughterhouse into a single file ready for slaughter. Her corrals employ long sweeping curves so that each animal is prevented from seeing what lies ahead and just concentrates on the hind quarters of the animal in front of it. This design – along with the design elements of solid sides, solid crowd gate, and reduced noise at the end point – work together to encourage animals forward in the chute and to not reverse direction.
As of 2011, Grandin claimed to have designed over 54% of the slaughterhouses in the United States as well as many others around the world.
Mobile design.
By 2010 a mobile facility the Modular Harvest System had received USDA approval. It can be moved from ranch to ranch. It consists of three trailers, one for slaughtering, one for consumable body parts and one for other body parts. Preparation of individual cuts is done at a butchery or other meat preparation facility.
International variations.
The standards and regulations governing slaughterhouses vary considerably around the world. In many countries the slaughter of animals is regulated by custom and tradition rather than by law. In the non-Western world, including the Arab world, the Indian sub-continent, etc., both forms of meat are available: one which is produced in modern mechanized slaughterhouses, and the other from local butcher shops.
In some communities animal slaughter may be controlled by religious laws, most notably halal for Muslims and kashrut for Jewish communities. These both require that the animals being slaughtered should be conscious at the point of death, and as such animals cannot be stunned prior to killing. This can cause conflicts with national regulations when a slaughterhouse adhering to the rules of religious preparation is located in some Western countries. In Jewish law, captive bolts and other methods of pre-slaughter paralysis are generally not permissible, due to it being forbidden for an animal to be stunned prior to slaughter. Various halal food authorities have more recently permitted the use of a recently developed fail-safe system of head-only stunning where the shock is less painful and non-fatal, and where it is possible to reverse the procedure and revive the animal after the shock. The use of electronarcosis and other methods of dulling the sensing has been approved by the Egyptian Fatwa Committee. This allows these entities to continue their religious techniques while keeping accordance to the national regulations.
In many societies, traditional cultural and religious aversion to slaughter led to prejudice against the people involved. In Japan, where the ban on slaughter of livestock for food was lifted only in the late 19th century, the newly found slaughter industry drew workers primarily from villages of "burakumin", who traditionally worked in occupations relating to death (such as executioners and undertakers). In some parts of western Japan, prejudice faced by current and former residents of such areas ("burakumin" "hamlet people") is still a sensitive issue. Because of this, even the Japanese word for "slaughter" (屠殺 "tosatsu") is deemed politically incorrect by some pressure groups as its inclusion of the kanji for "kill" (殺) supposedly portrays those who practice it in a negative manner.
Some countries have laws that exclude specific animal species or grades of animal from being slaughtered for human consumption, especially those that are taboo food. The former Indian Prime Minister Atal Bihari Vajpayee suggested in 2004 introducing legislation banning the slaughter of cows throughout India, as Hinduism holds cows as sacred and considers their slaughter unthinkable and offensive. This was often opposed on grounds of religious freedom. The slaughter of cows and the importation of beef into the nation of Nepal are strictly forbidden.
Freezing Works.
Refrigeration technology allowed meat from the slaughterhouse to be preserved for longer periods. This led to the concept as the slaughterhouse as a freezing works. Prior to this, canning was an option. Freezing works are common in New Zealand, Australia and South Africa.
The countries where meat is exported for a substantial profit the freezing works were built near docks, or near transport infrastructure. 
Law.
Most countries have laws in regard to the treatment of animals at slaughterhouses. In the United States, there is the Humane Slaughter Act of 1958, a law requiring that all swine, sheep, cattle, and horses be stunned unconscious with application of a stunning device by a trained person before being hoisted up on the line. There is some debate over the enforcement of this act. This act, like those in many countries, exempts slaughter in accordance to religious law, such as kosher shechita and dhabiha halal. Most strict interpretations of kashrut require that the animal be fully sensible when its carotid artery is cut.
The novel "The Jungle" detailed unsanitary conditions in slaughterhouses and the meatpacking industry during the 1800s. This led directly to an investigation commissioned directly by President Theodore Roosevelt, and to the passage of the Meat Inspection Act and the Pure Food and Drug Act of 1906, which established the Food and Drug Administration. A much larger body of regulation deals with the public health and worker safety regulation and inspection.
Animal welfare concerns.
In the year 1997 Gail Eisnitz, chief investigator for the Humane Farming Association (HFA), released a book "Slaughterhouse". Within, she unveils the interviews of slaughterhouse workers in the U.S. who say that, because of the speed with which they are required to work, animals are routinely skinned while apparently alive, and still blinking, kicking, and shrieking. Eisnitz argues that this is not only cruel to the animals, but also dangerous for the human workers, as cows weighing several thousands of pounds thrashing around in pain are likely to kick out and debilitate anyone working near them.
This would imply that certain slaughter houses throughout the country are not following the guidelines and regulations spelled out by the Humane Slaughter Act, requiring all animals to be put down and thus insusceptible to pain by some form, typically electronarcosis, before undergoing any form of violent action.
According to the HFA, Eiznitz interviewed slaughterhouse workers representing over two million hours of experience, who, without exception, told her that they have beaten, strangled, boiled, and dismembered animals alive, or have failed to report those who do. The workers described the effects the violence has had on their personal lives, with several admitting to being physically abusive or taking to alcohol and other drugs.
The HFA alleges that workers are required to kill up to 1,100 hogs an hour, and end up taking their frustration out on the animals. Eisnitz interviewed one worker, who had worked in ten slaughterhouses, about pig production. He told her:
Hogs get stressed out pretty easy. If you prod them too much, they have heart attacks. If you get a hog in the chute that's had the shit prodded out of him and has a heart attack or refuses to move, you take a meat hook and hook it into his bunghole. You try to do this by clipping the hipbone. Then you drag him backwards. You're dragging these hogs alive, and a lot of times the meat hook rips out of the bunghole. I've seen hams — thighs — completely ripped open. I've also seen intestines come out. If the hog collapses near the front of the chute, you shove the meat hook into his cheek and drag him forward.
Fish.
Historically, some doubted that fish could experience pain. However, laboratory experiments have shown that fish do react to painful stimuli (e.g. injections of bee venom) in a similar way to mammals. The expansion of fish farming as well as animal welfare concerns in society has led to research into more humane and faster ways of killing fish. In large-scale operations like fish farms, stunning fish with electricity or putting them into water saturated with nitrogen so that they cannot breathe, results in death more rapidly than just taking them out of the water. For sport fishing, it is recommended that fish be killed soon after catching them by hitting them on the head followed by bleeding out, or by stabbing the brain with a sharp object (called pithing or ike jime in Japanese).

</doc>
<doc id="55077" url="http://en.wikipedia.org/wiki?curid=55077" title="Chen Shui-bian">
Chen Shui-bian

Chen Shui-bian (born October 12, 1950) is a Taiwanese politician who served as President of the Republic of China (Taiwan) from 2000 to 2008. Chen's election ended more than fifty years of Kuomintang (KMT) control of the Executive Yuan in Taiwan. A native-born Taiwanese, he is colloquially referred to as A-Bian (阿扁; Ābiǎn; Taiwanese: 阿扁仔 A-píⁿ-à).
A lawyer, Chen entered politics in 1980 during the Kaohsiung Incident as a member of the Tangwai movement and was elected to the Taipei City Council in 1981. He was jailed in 1985 for libel as the editor of the weekly pro-democracy magazine "Neo-Formosa", following publication of an article critical of Elmer Feng, a college philosophy professor who was later elected a Kuomintang legislator. After being released, Chen helped found the Democratic Progressive Party (DPP) in 1986 and was elected a member of the Legislative Yuan in 1989, and Mayor of Taipei in 1994.
Chen won the 2000 presidential election on March 18 with 39% of the vote as a result of a split of factions within the Kuomintang, when James Soong ran for the presidency as an independent against the party nominee Lien Chan, becoming the only non-member of the Kuomintang to hold the office of president. Although Chen received high approval ratings during the first few weeks of his term, his popularity sharply dropped due to alleged corruption within his administration and the inability to pass legislation against the opposition KMT, who controlled the Legislative Yuan. In 2004, he won reelection by a narrow margin after surviving a shooting while campaigning the day before the election. Opponents suspected him of staging the incident for political purposes. However, the case was officially closed in 2005 with all evidence pointing to a single deceased suspect, Chen Yi-hsiung.
Convicted, along with his wife Wu Shu-chen, on two bribery charges, Chen was sentenced to 19 years in Taipei Prison, reduced from a life sentence, but was granted medical parole on 5 January 2015. C Supporters have insisted that his trial was an unfair and politically motivated retribution by the Kuomintang for his years in power.
Early years.
Chen was born to an impoverished tenant farming family in Guantian Township of Tainan County (now part of Tainan City) on the second day of the ninth lunar month in 1950 but was not formally issued a birth certificate until February 18, 1951 because of doubts that he would survive.
Chen was educated in Mandarin Chinese, which had replaced Japanese as the national language following the end of the Japanese occupation of Taiwan. Academically bright from a young age he graduated from the prestigious National Tainan First Senior High School with honors. In June 1969, he was admitted to National Taiwan University. Initially a Business Administration major, he switched to Law in his first year and became editor of the school's law review. He passed the bar exams before the completion of his junior year with the highest score becoming Taiwan's youngest lawyer. He graduated in 1974 with an LL.B. in Commercial Law.
In 1975, he married Wu Shu-chen, the daughter of a physician. The couple have a daughter, Chen Hsing-yu, who is a dentist; and a son, Chen Chih-chung, who, having received a law degree in Taiwan, gained a Master of Laws from the University of California, Berkeley in 2005.
From 1976 to 1989, Chen was a partner in Formosa International Marine and Commercial Law, specializing in maritime insurance. He held the firm's portfolio for Evergreen Marine Corporation.
Entry into politics.
Chen became involved in politics in 1980 when he defended the participants of the Kaohsiung Incident in a military court. While his client Huang Hsin-chieh, the leading opposition dissident, and seven co-defendants, including his future Vice President Annette Lu, were found guilty, Chen came to be known for his forceful and colorful arguments. He has stated that it was during this period that he realized the unfairness of the political system in Taiwan and became politically active as a member of the Tangwai movement.
Chen won a seat in the Taipei City Council as a Tangwai candidate in 1981 and served until 1985. In 1984, he founded the pro-opposition Civil Servant Public Policy Research Association, which published a magazine called "Neo-Formosa".
On January 12, 1985, Chen was sentenced to a year in prison for libel as a result of his editorship of "Neo-Formosa," following the publication of an article critical of Elmer Fung, then a college philosophy professor who was later elected a Kuomintang (KMT) legislator. While appealing the sentence, he returned to Tainan to run for county magistrate in November 1985. Three days after losing the election, his wife, Wu Shu-chen was hit twice by a hand tractor driven by Chang Jong-tsai as Chen and Wu were thanking their supporters. She was left paralyzed from the waist down. His supporters believed this was part of a government campaign to intimidate him, although another theory says it was a simple traffic accident. Chen writes in his autobiography that he harbors guilt towards his late father-in-law for this incident because of his failure to keep his promise that his involvement in politics would not harm his family and for ignoring repeated death threats from his opponents.
Chen lost his appeal in May 1986 and began serving eight months in the Tucheng Penitentiary (土城看守所) along with Huang Tien-fu (黃天福) and Lee I-yang (李逸洋), two other defendants in the case. While he was in prison, his wife campaigned and was elected to the Legislative Yuan. Chen also reflects how the various visits his wife made to him in prison overwhelmed him as she often fell from the wheelchair with no one to assist her. Upon his release, Chen served as her legislative assistant and practiced law.
In 1989, Chen was elected to the Legislative Yuan and served as the executive director of the Democratic Progressive Party Congress. With the support of some KMT colleagues, Chen was also elected convener of the National Defense Committee. He was instrumental in laying out and moderating many of the DPP's positions on Taiwan independence, including the four ifs. He was reelected to another three-year term in 1992, but resigned in two years to become mayor.
Taipei mayoralty, 1994–1998.
Chen was elected as the mayor of Taipei in 1994, largely as the result of a vote split between the KMT incumbent Huang Ta-chou and the KMT-spin-off New Party (NP) candidate Jaw Shaw-kong. Unable to find experienced bureaucrats from his own party, Chen and his inner circle of young law school graduates retained many of the KMT administrators and delegated considerable authority.
During his term, Chen received accolades for his campaigns to drive illegal gambling and prostitution rackets out of Taipei. He levied large fines on polluters and reformed public works contracts. Chen renamed many of the roads in Taipei, most notably the road which runs between KMT Headquarters to the Presidential Palace from "Chieh-shou Road" (介壽路 jiè shòu lù; "Longevity for Chiang Kai-shek Road") to "Ketagalan Boulevard" (凱達格蘭大道) in an effort to acknowledge the aboriginal people of the Taipei basin. Chen also made highly publicized evictions of longtime KMT squatters on municipal land, and ordered Chiang Wei-kuo's estate demolished. Chen was also named one of Asia's rising stars, and Taipei became one of the top 50 cities in Asia according to Time Magazine's Asia version.
Despite receiving more votes both in absolute and in percentage terms than his 1994 campaign, Chen lost this position in 1998 to the KMT's Ma Ying-jeou in large part because the KMT was able to gain the support of New Party supporters. In his first autobiography, "The Son of Taiwan", Chen wrote that he was not entirely upset about losing the reelection as it gave him opportunity to find out what areas in his political career he could improve. For example, he wrote that Mainlanders generally approved of his social and economic improvements in Taipei, but they ultimately voted for Ma because of ethnic tensions.
He also traveled extensively nationwide and abroad. In South Korea, he met with President Kim Dae Jung, who presented him with an award. He also met with Japanese Prime Minister Yoshiro Mori, who promised that he would celebrate if he won the 2000 presidential elections. Due to political complications, this promise was not fulfilled until late 2003. 
Presidency, 2000–2008.
First term.
In an election similar to Taipei's in 1994, Chen won the 2000 presidential election on 18 March 2000 with 39% of the vote as a result of a split of factions within the Kuomintang, when James Soong ran for the presidency as an independent against the party nominee Lien Chan.
Lacking a clear mandate and inheriting a bureaucracy largely loyal to the KMT, Chen tried to reach out to his opposition. He appointed the KMT conservative mainlander Tang Fei, a former general and the incumbent defense minister, as his first Premier. Only about half of Chen's original cabinet were DPP members, as few DPP politicians had risen above the local level. Although a supporter of Taiwan independence, Chen moderated his stance during his campaign and pledged the Four Noes and One Without in his inaugural address—that as long as the People's Republic of China has no intention to use military force against Taiwan, he would not declare independence nor change the national symbols of the Republic of China. He also promised to be, "President of all the people" and resigned his chairmanship from the DPP. His approval rating reached around 70%.
Chen's administration ran into many problems, and its policies were constantly blocked by the Pan-Blue Coalition-controlled legislature. The stock market lost over half its value within a year and unemployment reached 4.5% in part because of the Asian stock market crash. While Chen's detractors blamed Chen's poor leadership for the economic crisis, the administration blamed the legislature for blocking its relief efforts.
More troublesome for Chen was the political showdown over the construction of the Number Four Nuclear Power Facility. This multibillion dollar project in Gongliao District was already one-third completed and favored by the pro-business KMT as a means of avoiding an energy shortage. However, the environmentalist DPP strongly objected to the expansion of nuclear power. Premier Tang had threatened to resign if the project were canceled, and Chen accepted his resignation on October 3, 2000, only four and a half months after both had taken office. Chen appointed his political ally Chang Chun-hsiung as Tang's replacement. On October 27, Chang announced that the government would halt construction. But less than an hour before, President Chen had met with Lien Chan to reconcile differences. Lien had asked Chen to leave the matter for the Legislative Yuan to decide and Chen seemed receptive to the suggestion. When Chang's announcement came out, Lien was furious and the KMT began an effort to recall the President. The Council of Grand Justices intervened and declared that it was the legislature and not the cabinet that had the power to decide on the issue. This was widely seen as the end of Chen's attempts to face the pan-blue groups head on. By the end of his first year in office, Chen's approval ratings had dropped to 25%.
During summer of 2001, Chen flew to Los Angeles, Houston, and New York City, where he met with members of the U.S. Congress. The mayor of Houston presented Chen with a key to the city and gave him cowboy clothing. His trip to New York was a first for a head of state from Taiwan as there was unwritten agreement between the US and China that no head of state from Taiwan would be permitted to visit either New York or Washington, D.C.
After his first year in office, Chen moved away from sending conciliatory gestures. In the summer of 2002, Chen again became the chairman of the DPP. During his tenure, images of Chiang Kai-shek and Chiang Ching-kuo disappeared from public buildings. The word "TAIWAN" is now printed on new ROC passports. Also continuing a trend from the previous administration, the Education Ministry revised the school curriculum to be more Taiwan-centered. Government websites have also tended to promote the notion that China is synonymous with the PRC instead of the ROC as was mandated by the KMT. The "Free China Review" was renamed the Taiwan Review and Who's Who in the ROC was renamed Who's Who in Taiwan. In January 2003, a new Taiwan-Tibet Exchange Foundation was formed but the Cabinet-level Mongolian and Tibetan Affairs Commission was not abolished. Though Chen has proposed talks with the PRC, relations remain deadlocked as Chen refused to pledge to the One-China policy, as required by the PRC for talks to begin. Such a pledge seemed unlikely for Chen since there remained strong opposition within his own party. Despite these symbolic gestures, Chen moved away from "no haste, be patient" policy and opened the three mini links.
Re-election campaign.
In late 2003, he signed a controversial referendum bill, which he had supported but was heavily watered down by the Pan-Blue majority legislature. One concession that the legislature made was to include a provision for an emergency defensive referendum and during the legislative debates it was widely believed that this clause would only be invoked if Taiwan was under imminent threat of attack from China as has been so often threatened. Within a day of the passage of the referendum bill, Chen stated his intention to invoke this provision, citing PRC's over 450 missiles aimed directly at the Taiwanese. Pan-Blue believed that his bill was only intended to benefit Chen in the coming election, as whether PRC removes the missiles would not be pressured or decided by referendum result.
In October 2003, Chen flew to New York City for a second time. At the Waldorf-Astoria Hotel, he was presented with the Human Rights Award by the International League of Human Rights. In the subsequent leg of the trip to Panama, he met with US Secretary of State Colin Powell and shook hands with him. This high profile trip raised Chen's opinion polls ahead of his opponent Lien Chan for the first time at 35%, according to Agence France Presse.
His use of the referendum in combination with his talk of a new constitution lead many among his reunification critics to believe that he would attempt to achieve Taiwan independence in his second term by invoking a referendum to create a new constitution that would formally separate Taiwan from any interpretation of China. This caused the government of the United States to follow the lead of Chen's political critics and issue a rare rebuke of Chen's actions.
Chen was reportedly shot in the stomach while campaigning in the city of Tainan on Friday, March 19, 2004, the day before polls opened on Saturday. According to Chen, the bullet left a flesh wound that was 11 cm long and 2 cm deep and was found in his clothes. He left the hospital on the same day with 14 stitches. His Vice President Annette Lu was also reportedly shot in the leg in the same incident. After the election, video from the hospital Chen and Lu were taken to showed Chen walking into the hospital after the Presidential Office Secretary General said that he had been taken in. The opposition made many allegations into the conduct of the security and hospital procedures requiring Chen and Lu to change parts of their stories in order for it to make sense. While many theories were put forth, the opposition had no access to the physical evidence so the Criminal Investigation Bureau refuted them.
The following day, Chen narrowly won the election with a margin of less than 30,000 votes out of 12.9 million votes counted. Both of his referendum proposals were rejected due to insufficient turnout, in part by the Pan-Blue boycott. Those that did vote for the referendum overwhelmingly favored it. Due to the activation of the so-called National Security Mechanism which prevented military officers from voting, and island-wide reports of election fraud, Pan-Blue candidate Lien Chan refused to concede and sued both for a recount and for a nullification of the outcome while supporters held a week-long protest led by the Pan-Blues front of the presidential office in Taipei. He also claimed that the shooting was staged by Chen to win sympathy votes. Chen claimed that the shooting could not have been staged, because it would be too dangerous to have himself shot in a moving jeep and also challenged Lien and vice-presidential candidate James Soong to try their luck with a shooter in a stationary jeep. This challenge was based on the assumption that his belly wound was inflicted while he was in the moving jeep and not before or afterwards.
The opposition also raised the fact that Chen had faked a food poisoning incident while running for Tainan County Commissioner in 1985. Chen arrived at a debate on a stretcher accusing the KMT of poisoning his tea earlier. Later that night after the debate, Chen was seen as having no ill-effects from the apparent incident which prompted the opposing candidate to accuse him of staging the incident to garner sympathy.
The Criminal Investigation Bureau hired renowned forensic scientist Henry Lee (forensic scientist) to examine the physical evidence. Dr. Henry Lee was famous for defending O.J. Simpson in the murder of his wife and lover, and helped acquit Simpson based on the LAPD's lack of professionalism and possibility of planted evidence at the murder site. Dr. Henry Lee and his team of Americans had previously established the belly wound was in fact a gunshot wound, and then claimed the windshield hole had been struck from the outside based on the lack of windshield powder outside the jeep. Despite widespread speculation that the casings were planted on the street, Lee expressed no concern regarding the origin of the evidence even though the casings had been found some 3½ hours after the incident occurred and street cleaning had cleaned up the firecracker debris. Dr. Lee was also not critical of the local police and National Security Bureau's inability to secure the scene of the incident afterwards until the casings were found.
Several months later, Dr. Lee released a report on the evidence and suggested to the Criminal Investigation Bureau to trace the suspect according to the casings and bullets. In March 2005, Chen Yi-hsiung, a local Tainan resident, was the main suspect for the shooting but allegedly committed suicide 8 days after the election. The Criminal Investigation Bureau closed the case in August 2005 implicating him as the shooter. But in 2006, James Chun-i Lee, a professor at National Taiwan University's Graduate Institute of Forensic Medicine, led an investigation and concluded that Chen Yi-hsiung was most likely murdered, because his body, wrapped in a fishing net, was dumped into the water only after he died. Another report reached by the Criminal Investigation Bureau task force concludes that the two bullets could not have come from the same pistol because a 9.1 mm bullet would not fit into a 9 mm pistol that the police said was used by the suspect. The KMT continues to claim that it was all engineered by Chen to this day.
Throughout the election, Chen planned to hold a referendum in 2006 on a new constitution to be enacted upon the accession of the 12th-term president in May 2008. After the election, he sought to reassure critics and moderate supporters that the new constitution would not address the issue of sovereignty, and that the current constitution was in need of comprehensive reform after more than a decade of patchwork revision.
There have been two interpretations of Chen's actions during the election in terms of independence politics. The first is that he is ideologically committed to advancing Taiwan independence and that his actions are intended to systematically remove the constraints which prevent this from occurring. Seen in this light, his actions are intended to provoke a crisis in which the PRC must either start a war or accept independence, with the expectation that the PRC would back down. Ironically, this interpretation of his actions is shared both among his most fervent supporters (who think it is a good thing) and his most bitter opponents (who think that it is a bad thing). It is largely to counter this possibility that the PRC has issued statements that it will definitely go to war if certain red lines are crossed. However, they in reality carry little meaning, as Beijing has made such statements warning against electing former President Lee and Chen in the 1996 and 2000 elections, which both failed to materialize. Some people regard these statements now as reverse psychology, as Lee and Chen may help to weaken ROC and advance the unification process.
The second interpretation is that Chen's actions were primarily intended to placate his core supporters rather than provoke a crisis. People who subscribe to this interpretation point out that Chen's early efforts to moderate his pro-independence position did not create a positive reaction either from the PRC or from his anti-independence opponents on Taiwan. He also alienated some pro-independence supporters. Therefore Chen was forced to take a more assertive approach both as a negotiation tactic with the PRC and to keep support from his core supporters. This strategy is consistent with the oft-stated position that Taiwan would only seek independence as a "preemptive" measure in the face of evidence of PRC military aggression. However, even this interpretation provokes unease among many people, especially among policy makers in the PRC and the United States. The first problem is that this interpretation makes Chen seem like an old-style Taiwan politician that seems to say whatever pleases people. The second, more serious problem is the fear that through misunderstanding and misinterpretation, Chen may have provoked a war without intending to do so, as the PRC has repeatedly claimed that any progress towards independence would provoke war.
Second term.
On May 20, 2004, Chen was sworn in for his second term as President amid continued mass protests by the pan-blue alliance over the validity of his re-election. Having heard protests from pro-independence figures in Taiwan, he did not explicitly re-state the Four Noes and One Without but did state that he reaffirmed the commitments made in his first inaugural. He defended his proposals to change the constitution, but asked for constitutional reform to be undertaken through existing procedures instead of calling for a referendum for an entirely new constitution which was proposed by former president Lee Teng-hui. This would require approval by a three-fourths majority of the National Assembly which could authorize a referendum. This has two major implications. First, by going through existing constitutional amendment procedures, this has the symbolic effect of maintaining continuity with the existing constitution which was originally written in China. Second, this has the practical effect of requiring the Chen administration to get the consent of the opposition Pan-Blue coalition to pass any amendments, and while the opposition is willing to consider constitutional reforms that would increase governmental efficiency, they are unlikely to support anything that would imply a "de jure" declaration of independence.
However, even these seemingly conciliatory gestures did not quell unease by his critics at his election. Some have pointed out that he qualified his statements on the constitution with the statement that this is a personal suggestion. Furthermore, it is widely believed in Taiwan that some of these gestures were essentially forced on him again by pressure from the United States and the PRC. The PRC has stated many times that it cares little about what Chen says, but will watch closely in the next few months to see what he does, a standard sentence that Communist China continues to quote.
Three days before Chen's inauguration, the Taiwan Affairs Office of the PRC issued what has become known as the May 17 Declaration. In that declaration, China accused Chen of continuing with a creep toward independence, having merely paid lip service to his commitments in his first term of office, and reiterated that there would be consequences if Chen did not halt policies toward Taiwan independence, but at the same time offered major concessions if Chen would accept the One China Principle.
In late 2004, in effort to maintain the balance of power in the region, Chen began eagerly pushing for an US$18 billion arms purchase from the United States, but the Pan-Blue Coalition repeatedly blocked the deal in the legislature. Criticism has been made of this, citing contradictory arguments used, such as that the weapons were not what Taiwan needed, or that the weapons were a good idea but too expensive. By late 2006, the KMT had signalled it would support some of the arms sale being approved, but failed to pass a revised arms bill by the end of the legislative session in early 2007, despite promises by then KMT Chairman, Ma Ying-jeou, to do that.
Chen announced on December 5 that state-owned or private enterprises and foreign offices bearing the name "China", such as China Airlines, the China Steel Corporation, and Chinese Petroleum Corporation, would be renamed to bear the name "Taiwan." On December 14, 2004, following the failure of the Pan-Green coalition to gain a majority of seats in the ROC legislative election, 2004 (as many had expected to occur), Chen resigned as chairman of the DPP. This dashed hopes that the stalemate that plagued Chen's first term would end.
In 2005 Chen became the first ROC president to visit Europe, when he attended the funeral of Pope John Paul II in the Vatican City (the Holy See continues to maintain diplomatic relations with the ROC). In order to shore up diplomatic support, it is common for the ROC president to visit the ROC's remaining diplomatic allies; however past presidents had been prevented from visiting the Vatican because such a visit would require passage through Italy, which maintains relations with the PRC. Under agreement with the Vatican, Italy permitted all guests to the funeral passage without hindrance and Chen was received at Rome's airport in his capacity as a foreign head of state. In this religious ceremony where U.S. President George W. Bush greeted Iranian President Khatami, Chen did not seem to attempt making a high profile of himself by reaching out to other heads of states such as Bush or British Prime Minister Tony Blair. Chen was named one of the Time 100 for 2005.
Later in the year, Chen traveled to Miami in stopover for a forum in the Caribbean. He met with members of the U.S. Congress through video conference and was invited to visit Washington, D.C. On his way back, he was originally scheduled to fly through San Francisco. However, he changed course and stopped-over at the United Arab Emirates. The head of state greeted him and hosted a formal state dinner, infuriating the Chinese officials. Chen made his way back after making a stopover at Jakarta. His request for a pitstop at Singapore was denied; authorities cited weather problems.
On May 3, 2006, Chen canceled plans to pass through the United States on his way to Latin America. He was hoping to stop by either San Francisco or New York City to refuel and stay overnight, but the US refused his request instead limiting him to a brief refuelling stopover in Anchorage, Alaska where Chen would not be allowed to step off the plane. Chen and Taiwan saw this as a snub and led to Chen's cancellation. The trip to Latin America will continue, however, without a US stopover. The US State Department claimed that the Alaska stopover offer was consistent with its previous accommodations. However, former Taiwan president Lee Teng-hui was granted a visit to Cornell University eleven years ago. More recently, in addition, Taiwan's leaders have in general been granted permission to stopover in the United States for brief periods before continuing on to other countries. This recent American stance is interpreted by Taiwan to be an expression of the increasing irritation the United States feels towards Taiwan and Chen's seemingly pro-independence gestures. Chen attended the inauguration of Óscar Arias, the president of Costa Rica, one of the few countries that recognized the Republic of China at that time. Laura Bush was also present to represent U.S. president George W. Bush. Chen seized the opportunity, approached her and shook her hands, while Chen's aide produced a camera immediately for an impromptu photo-op. Chen's supporters saw this act as a step forward in Taiwan's struggle for diplomatic recognition, while his detractors claimed that it was a grave breach of international etiquette and put Taiwan to shame.
On May 12, 2007, Premier Su Tseng-Chang resigned his position, and Chen soon appointed Chang Chun-hsiung to fill the vacant premiership. During Chen's tenure, beginning in 2000, the country has seen six different premiers in the past seven years. During the same period of time, from 2000 onward, the Democratic Progressive Party has also seen seven different chairmen.
Chen's tenure as President expired on May 20, 2008, yielding to successor Ma Ying-Jeou. From his election to his first term to his last days as President, Chen's approval ratings fell from 79% to just 21%.
Family scandals.
In May 2006, his approval rating, as determined by the TSU, fell to 5.8%, after a series of scandals centered on his wife and son-in-law. Additional sources showed his approval rating at around 20%. Support from his own party has also dropped with a few members calling for his dismissal as he had a bad influence on his party and has already caused them to lose the Republic of China presidential election, 2008 .
On May 24, 2006, his son-in-law, Chao Chien-ming, was taken into custody by the Taipei police on charges of insider trading and embezzlement by the opposition party. This was a setback for the Chen Shui-bian administration. In related charges, there were accusations from the opposition party that Chen Shui-bian's wife was involved in trading stocks and obtaining Pacific Sogo Department Store's gift certificates illegally in exchange for settling the disputed ownership.
On June 1, 2006, Chen declared that he was handing control of governmental matters to Premier Su Tseng-chang and announced he would not be involved in campaigning. He also stated that he was retaining authority on matters that the Constitution required him to retain authority over, presumably foreign affairs and defense policy, as well as relations with the PRC.
On July 20, 2006, Opposition politicians accused that Chen used a total of NT$10.2 million (US$310,000) worth of "fake invoices" to claim expenses after the National Audit Office found irregularities in Presidential Office accounts. The Taiwan High Court Prosecutors' Office is currently investigating over this accusation.
In a press release issued by the Presidential Office responded that the president assured the investigators that he did not pocket a single cent of the fund. During questioning at the Presidential Office on the afternoon of August 7, 2006, the president detailed to the prosecutor how he spent the fund and presented relevant receipts and bank remittance statements.
President Chen also lost a libel case brought on successfully by PFP Chairman James Soong. Soong sued the President after Chen repeatedly accused him of secretly meeting the director of the People's Republic of China's Taiwan Affairs Office. Soong successfully sued Chen for NT$3 million.
On November 3, 2006, Chen's wife Wu Shu-chen and three other high-ranking officials of the Presidential Office were indicted of corruption of NT$14.8 million (US$450,000) of government funds using faked documents. Due to the protection from the Constitution against prosecution of the sitting president, Chen could not be prosecuted until he left office, and he was not indicted, but was alleged to be an accomplice on his wife's indictment.
The prosecutor of the case indicated that once Chen left office, his office would start the procedures to press charges against Chen. His wife Wu became the only sitting First Lady of the Republic of China to face criminal charges since the foundation of the Republic in 1911.
The indictment filed by prosecutors states that the indicted persons obtained government funds earmarked for secret foreign affairs, yet of six supposed secret diplomatic missions, there was sufficient evidence presented for only two. Of the remaining four, it was concluded that one did not exist, and in the case of the other three, the invoices presented were not found to be related to the secret missions.
The Pan-Blue coalition, after receiving the news, demanded to call for another recall motion unless Chen resigned immediately. Another small party that backed Chen previously, Taiwan Solidarity Union, said Friday they would likely to support the upcoming recall measure. If the recall passed, it would be up to the voters to decide Chen's fate in an island-wide referendum.
Leaders of the Democratic Progressive Party met together to discuss the unfavorable charges. The meeting ended when party leaders demanded Chen to explain the accusation within three days. There has long been crumbling inside the DPP that Chen has become their liability and should recall him before the presidential election. If Chen resigned, he would be the first Taiwanese president to step down and the vice-president, Annette Lu, would likely take power.
After the prosecutor announced the indictment news, the campaign leader Shih proclaimed that the indictment was the historical high point in Taiwan and the month-long campaign was a success.
In a press conference November 5, 2006, Chen rebutted the charges against his wife and members of his Presidential office. He said that Taiwan government offices advised him to prepare the receipts in such a fashion, and that after six years of doing so, it is strange that they would never mention an irregularity if it was not the right way to do it. He promised that all of the money actually went to diplomatic missions and did not go into any private pockets. Furthermore, he mentioned that when he took office, he thought his salary was so excessive that he cut his own salary in half, and that reduction is more than the amount he is accused of embezzling, so there is no need for him to take that money. In addition, he said that if the charges against his wife were proven in a court of law just as they were charged, then he would at that time step down as President of the Republic of China.
In defense of Chen, journalist Therese Shaheen of "The Wall Street Journal Asia" pointed out that controversy surrounding Chen can be in part attributed to the radical reforms he has tried to implement since stepping into power.
Recall motion.
In mid-June 2007, opposition pan-blue camp lawmakers initiated a recall motion that would allow the voters to remove Chen from power via a public referendum. On June 20, President Chen addressed the nation by television, denying any involvement of the first family or himself (other than his son-in-law) in any of the alleged scandals, or "directly" accepting the department's gift certificates. The motion was not passed. Of 221 lawmakers in the Legislature, all 119 pan-blue and independent legislators voted in favor of the measure, 29 votes short of the two-thirds majority needed to pass the motion. Pan-green legislators from the president's own party, the DPP, refused to receive ballots. Pan-Green legislators from the allied TSU cast abstaining ballots. No legislator voted against the recall motion.
After Wu was indicted, the Pan-Blue parties renewed calls to recall Chen, and TSU at first indicated that it would support the recall this time, but then said it would only support the new recall motion if "concrete evidence concerning corruption is presented."
On September 1, 2006, political activist Shih Ming-te launched an "anti-corruption campaign". The movement accused Chen of corruption and asked for his resignation. By September 7, more than one million signatures were collected, each with a donation of NT$100 (approximately US$3.00). On September 9, tens of thousands of people demonstrated in the streets of Taiwan, wearing red. According to organisers, around 200,000 to 300,000 people joined the protest outside the presidential offices, but the police used aerial photography crowd counting techniques to put the number at about 90,000. Shih Ming-teh confirmed that most of his supporters are from the Pan-Blue Coalition in a September interview in "The New York Times".
2008 elections.
In the Republic of China legislative election in 2008, Chen's party suffered a clear defeat, and Chen subsequently resigned as party chairman. With Chen's resignation and Frank Hsieh's ascension as the party's new chairman, the DPP has changed chairmen seven times since Chen took office in 2000.
In the presidential election on March 22, 2008, Kuomintang candidate Ma Ying-jeou defeated DPP candidate Frank Hsieh.
After the presidency.
Chen stepped down on May 20, 2008, the same day that Ma Ying-jeou took office as the new President of the Republic of China No longer bearing the title of President, Chen left the Presidential Office Building, his presidential immunity was removed. He was placed under restrictions, such as confinement to Taiwan, by prosecutors as a result of allegations of corruption and abuse of authority, both of which he was later charged guilty of. One fraud case involved the handling of a special presidential fund used to pursue Taiwan's foreign diplomacy.
President Ma Ying-jeou declassified government documents which aided the investigation into Chen's usage of special government funds. Chen's lawyers responded by suing Ma, on August 6, 2008, alleging Ma's declassification of the documents that were initially classified by Chen to be "politically motivated." The documents consisted mainly of receipts and other records of special expenses, which according to Ma's chief aide assured pose no danger to the country's interests once declassified.
On September 11, 2009, Chen received a life sentence and was fined NT$200 million (US$6.13 million) for embezzlement, bribery and money laundering involving a total of US$15 million (NT$490 million) in funds while in office from 2000 to 2008. Supporters of Chen contended that the prosecution was politically motivated. Chen is the first ROC president to receive a prison sentence.
On June 8, 2010, the Taipei District Court found Chen not guilty of embezzling diplomatic funds. On June 11, 2010, the decided to reduce the former president Chen's life sentence to 20 years. Through several court cases and pleads for bail, the High Court rejected his request for bail and continued to detain him in jail for another 5 months. The detention led Chen's supporters to protest that the detention of Chen for more than 600 days without proving him guilty was illegal, inhumane and unjust, and a result of political revenge by the part of the Kuomintang (KMT). The Yellow Ribbon Movement took to demonstration over alleged exploitation of justice and political revenge.
Meanwhile, on August 17, 2010, both the Taipei District Court and the High Court found ex-deputy military minister, Cheng-Hen Ke (柯承亨), not guilty of revealing non-military secrets to former president Chen Shui-Bian.
The parliament with a KMT and pan-blue coalition majority passed an amendment to the Act Governing Preferential Treatment for Retired Presidents and Vice Presidents (卸任總統副總統禮遇條例) on August 19, 2010. Introduced by the KMT, the amendment stipulated that former presidents and vice presidents will be stripped of courtesy treatment, including their monthly allowance and annual expenses, if convicted by a court of grave offense(s), such as sedition and graft. The number of bodyguards assigned to former presidents and vice presidents who are convicted of corruption in a first trial will also be reduced. Former president Chen's son stated the act was created to target the now imprisoned former president (陳水扁條款).
Health.
Chen had been admitted to hospital after refusing to eat. He suffers from paranoia of food poisoning, but he was diagnosed with serious sleep apnea.
He attempted suicide on Sunday, June 2, 2013, but was unsuccessful.
Political positions.
Chen's and the Democratic Progressive Party position on Taiwan's political status is that Taiwan is already an independent, sovereign nation named the Republic of China. This has the implication that a declaration of independence is unnecessary as Taiwan is already independent. This view point, however, is subject to change in each election campaign. At the same time, it also has the implication that the pledge by Chen to preserve the status quo or not change Taiwan's sovereign status would not preclude a declaration of independence but would preclude acceptance of the one China policy.
Some said that Chen's position on this issue was intended and to some degree succeeded in placating his pro-independence supporters without crossing any red lines that could trigger war with the PRC. His supporters saw these positions as creative and indicative of a willingness to compromise. However, it was also common among his opponents in Taiwan, as well as among policy makers in China and the pro-PRC United States politicians to see his statements in their own much darker terms. Many among his critics (especially those from the Pan-Blue coalition) believed that his positions and actions showed that his seemingly conciliatory statements were merely a smokescreen to advance a hidden agenda of advancing "de facto" Taiwan independence. These suspicions appeared to arise from the actions of his KMT predecessor Lee Teng-hui who now readily admits to secretly trying to advance "de facto" Taiwan independence during his presidential terms.
President Chen admitted that he leans towards independence but his main position is opposition to adopting the One China principle since it prevents Taiwanese people from being able to decide upon their own future.
In an interview in July 2005, Chen explicitly repudiated the position of Lee Teng-Hui that Taiwan / Republic of China and China / People's Republic of China are two different countries. He said, "The Republic of China on Taiwan and the People's Republic of China on the mainland are two separate countries with divided rule and do not exercise sovereignty over each other," he said. "Under the principle of popular sovereignty and self determination, we consider that the question of whether Taiwan should be united with China should be the decision of the 23 million people of Taiwan."
On February 28, 2006, Chen announced the National Unification Council, set up in 1990, and its guidelines, which had committed Taiwan to unification if China adopts democracy, would "cease to function". He took care to use the phrase "ceased to exist" rather than abolish when he made the announcement because he had promised in 2000 that he would not abolish the council or its guidelines. Newspapers on both sides of the Taiwan strait criticized Chen severely for scrapping the unification council although others reported that Chen may have acted in reaction towards China's Anti Secession Law.
On March 2, 2006 in a stern announcement, Adam Ereli, Deputy Spokesman of the US state department, said that the US expected the Taiwan authorities to publicly correct the record that there is no distinction between "abolish" and "ceasing activity" and unambiguously affirm that the February 27 announcement did not abolish the National Unification Council and did not change the status quo and that the assurances remain in effect.

</doc>
<doc id="55078" url="http://en.wikipedia.org/wiki?curid=55078" title="Lee Teng-hui">
Lee Teng-hui

Lee Teng-hui (born 15 January 1923), sometimes called the "father of Taiwan's democracy", is a Taiwanese politician. He was the President of the Republic of China and Chairman of the Kuomintang (KMT) from 1988 to 2000. He presided over major advancements in democratic reforms including his own re-election which marked the first direct presidential election for Taiwan. The first Hakka person to become ROC president and KMT chairman, Lee promoted the Taiwanese localization movement and led an aggressive foreign policy to gain diplomatic allies. Critics accused him of betraying the party he headed, secret support of Taiwanese independence, and involvement in corruption (black gold politics).
After leaving office Lee was expelled from the KMT for his role in founding the pro-independence Taiwan Solidarity Union (TSU), which forms part of the Pan-Green Coalition alongside Taiwan's Democratic Progressive Party. Lee is considered the "spiritual leader" of the TSU, and has recruited for the party in the past. Lee has been outspoken in support for Taiwanese independence though not necessarily a formal declaration. In 2013, a first trial cleared him for his hypothetical involvement in a corruption scandal.
Early life and education.
Lee was born to a Hakka family in the rural farming community of Sanshi Village, Taihoku Prefecture, Japanese Formosa. As a child, he often dreamed of traveling abroad, and became an avid stamp collector. Growing up under Japanese colonial rule, he developed a strong interest for Japan. His father was a middle-level Japanese police aide, and his brother joined police academy and soon volunteered as for the Imperial Japanese Navy and died in Manila. Lee—one of only four Taiwanese students in class—graduated with honors and was given a scholarship to Japan's Kyoto Imperial University. During his school days, he learned kendo and bushido. A lifelong collector of books, Lee was heavily influenced by Japanese thinkers like Nitobe Inazō and Kitaro Nishida in Kyoto. In 1944 he too volunteered for service in the Imperial Japanese Army and became a second lieutenant officer of an anti-aircraft gun in Taiwan. He was ordered back to Japan in 1945 and participated in the clean-up after the great Tokyo firebombing of March 1945. Lee stayed in Japan after the surrender and graduated from Kyoto Imperial University in 1946.
After World War II ended, and the Republic of China took over Taiwan, Lee enrolled in the National Taiwan University, where in 1948 he earned a bachelor's degree in agricultural science. Lee joined the Communist Party of China (CPC) for two stints, in September 1946 and October or November 1947, both times briefly. Lee began the New Democracy Association with four others. This group was absorbed by the CPC, and Lee officially left the party in September 1948. In a 2002 interview Lee himself admitted that he had been a communist. In that same interview Lee said that he has strongly opposed communism for a long time because he understands the theory well and knows that it is doomed to fail. Lee stated that he joined the Communists out of hatred for the KMT.
In 1953, Lee received a master's degree in agricultural economics from the Iowa State University in the United States. Lee returned to Taiwan in 1957 as an economist with the Joint Commission on Rural Reconstruction (JCRR), an organization sponsored by the U.S. which aimed at modernizing Taiwan's agricultural system and at land reform. During this period, he also worked as an adjunct professor in the Department of Economics at National Taiwan University and taught at the Graduate School of East Asian Studies at National Chengchi University.
In the mid-1960s Lee returned to the United States, and earned a PhD in agricultural economics from Cornell University in 1968. Lee's doctoral dissertation, "Intersectoral Capital Flows in the Economic Development of Taiwan, 1895–1960" (published as a book under the same name) was honored as the year's best doctoral thesis by the American Association of Agricultural Economics and remains an influential work on Taiwan's economy during the Japanese and early KMT periods.
Lee encountered Christianity as a young man and in 1961 was baptised. For most of the rest of his political career, despite holding high office, Lee has made a habit of giving sermons at churches around Taiwan, mostly on apolitical themes of service and humility.
Lee speaks Mandarin Chinese, Taiwanese Hokkien, English, and Japanese. Lee speaks Japanese fluently. As of 1996, he was more proficient in Japanese than he is in Mandarin.
Rise to power.
Shortly after returning to Taiwan, Lee joined the KMT in 1971 and was made a cabinet minister without portfolio responsible for agriculture.
In 1978 Lee was appointed Mayor of Taipei, where he solved water shortages and improved the city's irrigation problems. In 1981, he became governor of Taiwan Province and made further irrigation improvements.
As a skilled technocrat, Lee soon caught the eye of President Chiang Ching-kuo as a strong candidate to serve as Vice President. Chiang sought to move more authority to the "bensheng ren" (residents on Taiwan before 1949 and their descendants) instead of continuing to promote "waisheng ren" (mainland Chinese immigrants who arrived in Taiwan after 1949 and their descendants) as his father had. President Chiang nominated Lee to become his Vice President. Lee was formally elected by the National Assembly in 1984.
Presidency.
Chiang Ching-kuo died in January 1988 and Lee succeeded him as President. The "Palace Faction" of the KMT, a group of conservative mainlanders headed by General Hau Pei-tsun, Premier Yu Kuo-hwa, and Education Minister Lee Huan, was deeply distrustful of Lee Teng-hui and sought to block his accession to the KMT chairmanship and sideline him as a figurehead. With the help of James Soong—himself a member of the Palace Faction—who quieted the hardliners with the famous plea "Each day of delay is a day of disrespect to Ching-kuo," Lee was allowed to ascend to the chairmanship unobstructed. At the 13th National Congress of Kuomintang on July 1988, Lee named 31 members of the Central Committee, 16 of whom were --"bensheng ren": for the first time, "bensheng ren" held a majority in what was then a powerful policy-making body.
As he consolidated power during the early years of his presidency, Lee allowed his rivals within the KMT to occupy positions of influence: when Yu Guo-hwa retired as premier in 1989, he was replaced by Lee Huan, who was succeeded by Hau Pei-tsun in 1990. At the same time, Lee made a major reshuffle of the Executive Yuan, as he had done with the KMT Central Committee, replacing several elderly "waisheng ren" with younger "bensheng ren", mostly of technical backgrounds. Fourteen of these new appointees, like Lee, received PhDs in the United States. Prominent among the appointments were Lien Chan as foreign minister and Shirley Kuo as finance minister.
1990 saw the arrival of the Wild Lily student movement on behalf of full democracy for Taiwan. Thousands of Taiwanese students demonstrated for democratic reforms. The demonstrations culminated in a sit-in demonstration by over 300,000 students at Memorial Square in Taipei. Students called for direct elections of the national president and vice president and for a new election for all legislative seats. On 21 March Lee welcomed some of the students to the Presidential Building. He expressed his support of their goals and pledged his commitment to full democracy in Taiwan. The moment is regarded by supporters of democracy in Taiwan as perhaps his finest moment in office. Gatherings recalling the student movement are regularly held around Taiwan every 21 March.
In May 1991 Lee spearheaded a drive to eliminate the Temporary Provisions Effective During the Period of Communist Rebellion, laws put in place following the KMT arrival in 1949 that suspended the democratic functions of the government. In December 1991, the original members of the Legislative Yuan, elected to represent mainland China constituencies in 1948, were forced to resign and new elections were held to apportion more seats to the bensheng ren. The elections forced Hau Pei-tsun from the premiership, a position he was given in exchange for his tacit support of Lee. He was replaced by Lien Chan, then an ally of Lee.
The prospect of the first island-wide democratic election the next year, together with Lee's June 1995 visit to Cornell University, sparked the Third Taiwan Strait Crisis. The previous eight presidents and vice presidents of the ROC had been elected by the members of the National Assembly. For the first time the President of the ROC would be elected by majority vote of Taiwan's population. The People's Republic of China conducted a series of missile tests in the waters surrounding Taiwan and other military maneuvers off the coast of Fujian in response to what Communist Party leaders described as moves by Lee to "split the motherland." The PRC government launched another set of tests just days before the election, sending missiles over the island to express its dissatisfaction should the Taiwanese people vote for Lee. The military actions disrupted trade and shipping lines and caused a temporary dip in the Asian stock market. Ironically, the 1996 missile launches boosted support for Lee instead.
On 23 March 1996, Lee became the first popularly elected ROC president with 54% of the vote. Many people who worked or resided in other countries made special trips back to the island to vote. In addition to the president, the governor of Taiwan Province and the mayors of Taipei and Kaohsiung (as leaders of provincial level divisions they were formerly appointed by the president) became popularly elected.
Lee, in an interview that same year, expressed his view that a special state-to-state relationship existed between Taiwan and mainland China that all negotiations between the two sides of the Strait needed to observe.
Lee, observing constitutional term limits he had helped enact, stepped down from the presidency at the end of his term in 2000. That year Democratic Progressive Party candidate Chen Shui-bian won the national election with 39% of the vote in a three-way race. Chen's victory marked an end to KMT rule and the first peaceful transfer of power in Taiwan's new democratic system.
Supporters of rival candidates Lien Chan and James Soong accused Lee of setting up the split in the KMT that had enabled Chen to win. Lee had promoted the uncharismatic Lien over the popular Soong as the KMT candidate. Soong had subsequently run as an independent and was expelled from the KMT. The number of votes garnered by both Soong and Lien would have accounted for approximately 60% of the vote while individually the candidates placed behind Chen. Protests were staged in front of the KMT party headquarters in Taipei. Fuelling this anger were the persistent suspicions following Lee throughout his presidency that he secretly supported Taiwan independence and that he was intentionally sabotaging the Kuomintang from above. Lee resigned his chairmanship on 24 March.
Since leaving office Lee and the new party he went on to found, the TSU, have generally supported "green" causes in Taiwan. Lee continues to travel, make speeches, campaign for TSU candidates, and offer independent-minded commentary on Taiwan politics. "Lee Teng-Hui University" in Taiwan is named after him. KMT officials expressed dissatisfaction with efforts to "localize" the KMT and his tacit support of the new Chen administration.
Taiwanization.
Lee Teng-hui, during his term as president, supported Taiwanization. The Taiwanization movement has its roots in the home rule and independence groups founded during the Japanese era and sought to put emphasis on Taiwan as the center of people's lives as opposed to China or Japan. During the Chiang regime, China was promoted as the center of an ideology that would build a Chinese national outlook in a people who had once considered themselves Japanese subjects. Taiwan was often relegated to a backwater province of China in the KMT-supported history books. People were discouraged from studying local Taiwanese customs, which were to be replaced by mainstream Chinese customs. Lee sought to turn Taiwan into a center rather than an appendage. This shift was widely supported in Taiwan and found expression in Taiwanese literature movement. He further stated that he believed a Chinese identity and a Taiwanese identity were ultimately incompatible, a notion controversial in the KMT, even among those members who generally supported Taiwanization.
After the presidency.
Since resigning the chairmanship of the KMT, Lee has campaigned actively on behalf of pan-green coalition candidates and opposed candidates of his former party who took pro-unification positions since the 2004 presidential elections. He has stated a number of political positions and ideas which he did not mention while he was President, but which he appeared to have privately maintained. Lee was expelled from KMT on 21 September 2001.
Lee has publicly supported the Name Rectification Campaigns in Taiwan and proposed changing the name of the country from the Republic of China to the Republic of Taiwan. He generally opposes unlimited economic ties with mainland China, though he supports free trade.
Lee has also stated that he believes that Taiwan cannot avoid being assimilated into the People's Republic of China unless it completely rejects its historical 
Chinese identity and that he believes that it is essential that Taiwanese unite and develop a unified and separate identity other than the Chinese one. Furthermore, in reference to Mainlanders, he believes that to be truly Taiwanese, one must assume a "New Taiwanese" identity.
He dismisses both the notion that the strategy will trigger an invasion by the Chinese government and the notion that Taiwan benefits economically by developing economic ties with China. He argues the People's Republic of China is a paper tiger and both its military strength and economic strength have been far overestimated. Lee asserts that when presented with a united and assertive Taiwan, Taiwan will receive support from the international community and also from the United States and that the PRC will be obliged to back down. He also believes that the PRC economy is doomed to collapse and that unlimited integration with the PRC economy, on the part of Taiwan or any country, is unwise.
During the 2004 Presidential campaign, President Chen Shui-bian publicly campaigned with Lee Teng-hui and developed a campaign platform, including a call for a new constitution adopted by referendum, which could be interpreted as an opportunity to make the symbolic changes which Lee supports. There was concern in the United States and in the People's Republic of China that Chen would be supportive of Lee's positions, a belief which was reinforced by Lee's own actions while President and by Lee's public statements that Chen Shui-bian agreed with him.
The concern shared between the United States and the People's Republic of China was the possible unilateral change of the cross-strait status quo by President Chen, leading to a public rebuke of Chen from the United States President George W. Bush in December 2003. It is believed that this rebuke in part was intended to challenge the notion, which Lee had advanced, that American support of Taiwan was unconditional. After his close election in March 2004, Chen moved to distance himself from Lee, by stating explicitly that his regime's constitutional reforms would not rename "The Republic of China" to Taiwan. The difference in the two leader's positions was further highlighted by Chen's stated intent to establish greater economic links with China.
In February 2007 Lee shocked the media when he announced that he has never backed Taiwanese independence, when he was widely seen as the spiritual leader of the movement. Lee also said that he supported opening up trade and tourism with China, a position he had opposed before. Lee later explained that Taiwan already enjoys "de facto" independence and that political maneuvering over details of expressing it is counterproductive. He maintains that "Taiwan should seek 'normalization' by changing its name and amending its constitution."
Japanese support.
Lee enjoys a warm relationship with the people and culture of Japan. Lee often assures Taiwanese audiences that Japan will support Taiwan if it formally announces its Taiwan independence. Taiwan was colonized by Japan from 1895 to 1945 and natives of the island who grew up in that period, such as Lee, attended schools where Japanese language, songs, and stories were taught. Lee's father was a middle-level Japanese police aide; his older brother died serving in the Imperial Japanese Navy in World War II and is listed in the Yasukuni Shrine in Tokyo. During his youth Lee had a Japanese name, Iwasato Masao (巖里政男). Lee speaks fondly of his upbringing and his teachers and has been welcomed in visits to Japan since leaving office. Lee's admiration and enjoyment of all things Japanese has been the target of criticism from both the Pan-Green Coalition and Pan-Blue Coalition in Taiwan, as well as from China, due to the anti-Japanese sentiment formed during and after World War II.
In August 2001, Lee said of Junichiro Koizumi's controversial visit to Yasukuni Shrine, "It is natural for a premier of a country to commemorate the souls of people who lost their lives for their country". In a May 2007 trip to Japan, Lee visited the shrine himself to pay tribute to his older brother. Controversy rose because the shrine also enshrines World War II Class A criminals among the other soldiers.
During the 2012 China anti-Japanese demonstrations, on 13 September 2012, Lee remarked "The Senkaku islands were Japanese territory in the past and are still so at present." Ten years previously, he had stated, "The Senkaku Islands are the territory of Japan."
Indictment.
On 30 June 2011, Lee, along with former KMT financier Liu Tai-Ying were indicted on graft and money-laundering charges and accused of embezzling US$7.79 million in public funds. He was acquitted by the Taipei District Court on 15 November 2013. Prosecutors appealed the ruling, but on 20 August 2014, Lee was cleared of the charges again.
Cancer.
In late 2011, Lee underwent surgery to remove stage II colon adenocarcinoma, the most common form of colon cancer.

</doc>
<doc id="55079" url="http://en.wikipedia.org/wiki?curid=55079" title="Mainland China">
Mainland China

Mainland China, Chinese mainland or simply the mainland, is a geographical and political term to describe the geopolitical area under the direct jurisdiction of the People's Republic of China (PRC). It generally excludes the Special Administrative Regions of Hong Kong and Macau however usually includes Hainan. The term "mainland China", which avoids calling the area simply "China" and thereby recognizing the founding of the PRC as "the" "China", was coined by the Kuomintang (KMT) after it took control of Taiwan, particularly after 1949, when the KMT-led Republic of China (ROC) government was defeated in the Chinese Civil War on the mainland and fled to Taiwan, and pledged to "retake the Mainland". The KMT considers both sides of the Taiwan Strait, i.e. including Taiwan, as (one) "China" and one country; whereas Taiwan's Democratic Progressive Party (DPP) considers only mainland China as "China" and Taiwan (ROC) as "Taiwan" and that they are different countries.
There are two terms in Chinese for "mainland". Namely, Dalu (), which means "continent", and Neidi (内地 / 內地), literally "inland" or "inner land". In the PRC, the usage of the two terms are generally interchangeable and there is no prescribed method of reference in any jurisdiction. To emphasize "equal footing" in cross-strait relations, the term is used in official contexts with reference to Taiwan, with the PRC referring to itself as "the mainland side" (as opposed to "the Taiwan side"). But in its relations with Hong Kong and Macau, the PRC government refers to itself as "the Central People's Government".
"Mainland" area is the opposing term to "Free area of the Republic of China" used in the ROC Constitution, as amended in April, 2000, which treats the "mainland" as part of ROC's territory despite lack of control.
Background.
By 1949, the Communist Party of China's (CPC) People's Liberation Army had largely defeated the Kuomintang (KMT)'s National Revolutionary Army in the Chinese Civil War on the mainland. This forced the Kuomintang to relocate the Government and institutions of the Republic of China to the relative safety of Taiwan, an island which was placed under the control of the Republic of China after the surrender of Japan at the end of World War II in 1945. With the establishment of the People's Republic of China on October 1, 1949, the CPC-controlled government saw itself as the sole legitimate government of China, competing with the claims of the Republic of China, whose authority is now limited to Taiwan and other islands. This has resulted in a situation in which two co-existing governments compete for international legitimacy and recognition as the "government of China".
The phrase "mainland China" emerged as a politically neutral term to refer to the area under control of the Communist Party of China, and later to the administration of the PRC itself. Until the late 1970s, both the PRC and ROC envisioned a military takeover of the other. During this time the ROC referred to the PRC government as "Communist Bandits" (共匪) while the PRC referred to the ROC as "Chiang Bandits" (蔣匪). Later, as a military solution became less feasible, the ROC referred to the PRC as "Communist China"" (中共). With the democratization of Taiwan in the 1990s, the phrase "mainland China" soon grew to mean not only the area under the control of the Communist Party of China, but also a more neutral means to refer to the People's Republic of China government; this usage remains prevalent by the KMT today.
Due to their status as colonies of foreign states during the establishment of the People's Republic of China in 1949, the phrase "mainland China" excludes Hong Kong and Macau. Since the return of Hong Kong and Macau to Chinese sovereignty in 1997 and 1999, respectively, the two territories have retained their legal, political, and economic systems. The territories also have their distinct identities. Therefore "mainland China" generally continues to exclude these territories, because of the "One country, two systems" policy adopted by the PRC central government towards the regions. The term is also used in economic indicators, such as the IMD Competitiveness Report. International news media often use "China" to refer only to mainland China or the People's Republic of China.
Political use.
In Taiwan.
In Taiwan, the term "mainland" is typically used to refer to mainland China, i.e. territory of the PRC (Hong Kong and Macau excluded), by the Kuomintang (KMT, "Chinese Nationalist Party") and its supporters, who share the view that "China" encompasses both sides of the Taiwan Strait. Since the KMT was the long-time ruling and only party in Taiwan until 2000, and had set up the educational system and taught children the term since its takeover in 1945, the term has been in mainstream use and usually has no particular political connotations, since generations born after the takeover were taught that Taiwan is part of Republic of China, and so is mainland China, and that they are "Chinese". Government organizations and official and legal documents in Taiwan, including the Republic of China Constitution also use "the mainland" to refer to mainland China, since the ROC government has never recognized the founding of the PRC and because its Constitution does not allow the existence of another state within its territory, constitutional amendments made in the 1990s had to refer to the area occupied by PRC as "mainland", since it is officially considered still part of the ROC territory but just enemy occupied. In contrast, the pro-Taiwan independence Democratic Progressive Party (DPP) prefer to use the term "China" instead, referring to the PRC, to imply that Taiwan (ROC) is separate from China. Related to this naming and broader national identity issue, the DPP would also like to amend the ROC constitution to limit its scope and territorial description to the Free area of the Republic of China only and rectify the ROC country name to "Republic of Taiwan" instead, thereby eliminating the need to refer to the "mainland area" and "Free Area" altogether.
In 1992, a high level political meeting between the ROC and PRC was held in Hong Kong where what became called the "1992 Consensus" developed. This "consensus" essentially reaffirmed that both the ROC (then under KMT administration) and the PRC agree there is only "one China" in a definition that covers both sides of Taiwan Strait, but they differ on their own interpretation of what that "China" means. Each interprets and believes "it" is the China and has a claim on the territories held by the other. In this context, the term "Mainland China" is agreeable to both sides since they both conceive "China" as including mainland and Taiwan, and therefore need this term to distinguish the two areas. However since it was the KMT who came to this consensus with China, the Pan Green Coalition does not embrace this term as the Pan Blue Coalition does.
In Taiwan, under the concept of "Mainlander" another comparative term often used is "waishengren" (), which are the people who immigrated to Taiwan from mainland China with the Kuomintang (KMT) around the end of the Chinese Civil War in 1949, as well as their descendants born in Taiwan. The status of "waishengren" in Taiwan is a divisive political issue. For many years certain groups of mainlanders were given special treatment by the KMT government which had imposed martial law on Taiwan. More recently, pro-Taiwan independence politicians calling into question their loyalty and devotion to Taiwan and pro-Chinese reunification politicians accusing the pro-independence politicians of playing identity politics. The term "Mainlander" mostly refers to "daluren" (), meaning people who live in mainland China.
After the Republic of China's relocation to Taiwan, the Kuomintang party-state embued the term "dalu" with nostalgic overtones, associating it with "the land of the utopian past [and] childhood". Schoolchildren were taught slogans like "Counterattack the mainland!" (反攻大陸！) and "Save our mainland compatriots from the deepest water and hottest fire!" (拯救大陸同胞于水深火熱之中！). The Taiwanese were also told that they were the guardians of traditional Chinese culture until political reunification. However, democratization on Taiwan has led to the rise of voices which denounced traditional attitudes towards the mainland and the ancestral home system, pressing for Taiwanization, Desinicization, and "Taiwan cultural independence" (文化台獨). Concurrently, the mainland Chinese economic reform changed the connotation of "mainland China" to one of "primitiveness, nativeness, and raw cultural material for economic gain", as well as condescention because of Taiwan's comparatively advanced economy. Warlike phrases like "Counterattack the mainland!" saw a revival, but in reference to the economic expansion of Taiwanese businesses. Despite the re-branding of the Kuomintang in the 1990s as a party "native" to Taiwan, Kuomintang continues to produced a variety of mainland-related media such as the television program "Searching for the Strange on the Mainland" (大陸尋奇).
In Hong Kong and Macau.
In Hong Kong and Macau, the terms "mainland China" and "mainlander" are frequently used for people from China mainland. This usage is not geographically accurate, however, as much of the land area of both Hong Kong and Macau are peninsulas connected to the continent. The Chinese term 內地, meaning the "inland" but still translated "mainland" in English, is commonly applied by SAR governments to represent non-SAR areas of PRC, including Hainan Island (the smallest and southernmost province of the People's Republic of China) and coastal regions of mainland China, such as "Constitutional and Mainland Affairs" (政制及內地事務局) and Immigration Departments.
In the Mainland and Hong Kong Closer Economic Partnership Arrangement (as well as the Mainland and Macau Closer Economic Partnership Arrangement) the CPG also uses the Chinese characters 内地 "inner land", with the note that they refer to the "customs territory of China".
In mainland China.
In the PRC, the term 内地 ("Inland") is often contrasted with the term 境外 ("outside of the border") for things outside of the mainland region. Examples include "Administration of Foreign-funded Banks" (中華人民共和國外資銀行管理條例) or the "Measures on Administration of Representative Offices of Foreign Insurance Institutions" (外國保險機構駐華代表機構管理辦法).
Hainan is an offshore island, therefore geographically not part of the continental mainland. Nevertheless, politically it is common practice to consider it part of the mainland because its government, legal and political systems do not differ from the rest of the People's Republic in the geographical mainland. Nonetheless, Hainanese people still refer to the geographic mainland as "the mainland" and call its residents "mainlanders".
In some coastal provinces such as Guangdong, Fujian and Jiangsu, people often call the area of non-coastal provinces in of Mainland China as "Inland" (内地).
Others.
In the United States' Taiwan Relations Act, the ROC-controlled islands of Quemoy and Matsu were excluded from the definition of "Taiwan", and are regarded as parts of mainland China. The House Foreign Affairs Committee justified this exclusion on the grounds that "Quemoy and Matsu are considered by both Taipei and by Peking to be part of mainland China." Quemoy and Matsu are geologically part of the continental mainland.
Other terms.
Other use of geography-related terms are also often used where neutrality is required.

</doc>
<doc id="55084" url="http://en.wikipedia.org/wiki?curid=55084" title="Cultural genocide">
Cultural genocide

Cultural genocide is a concept that lawyer Raphael Lemkin distinguished in 1944 as a component to genocide. The term was considered in the 2007 United Nations Declaration on the Rights of Indigenous Peoples juxtaposed next to the term "ethnocide," but it was removed in the final document, replaced with simply "genocide." The precise definition of "cultural genocide" remains unclear. Some ethnologists, such as Robert Jaulin, use the term "ethnocide" for "cultural genocide", although this usage has been criticized as engendering a risk of confusion between ethnicity and culture.
Usage.
As early as 1944, lawyer Raphael Lemkin distinguished a cultural component to genocide, which since then has become known as "cultural genocide". The term has since acquired rhetorical value as a phrase that is used to protest against the destruction of cultural heritage. It is also often misused as a catchphrase to condemn any destruction the speaker disapproves of, without regard for the criterion of intent to destroy an affected group as such.
Proposed usage.
The drafters of the 1948 Genocide Convention considered the use of the term, but dropped it from their consideration. The legal definition of genocide is left unspecific about the exact nature in which genocide is done only that it is destruction with intent to destroy a racial, religious, ethnic or national group as such.
Article 7 of a 1994 draft of the United Nations Declaration on the Rights of Indigenous Peoples uses the phrase "cultural genocide" but does not define what it means. The complete article reads as follows:
This declaration only appeared in a draft. The United Nations Declaration on the Rights of Indigenous Peoples was adopted by the United Nations General Assembly during its 62nd session at UN Headquarters in New York City on 13 September 2007, but only mentions "genocide", not "cultural genocide", although the article is otherwise unchanged.
Examples of the term's usage.
The term was used for describing destruction of cultural heritage in connection with various events:

</doc>
<doc id="55091" url="http://en.wikipedia.org/wiki?curid=55091" title="Theales">
Theales

Theales is a botanical name at the rank of order. The name was used by the Cronquist system for an order placed in subclass Dilleniidae, in the 1981 version of the system the circumscription was:
In the APG II system (used here) the taxa involved are assigned to many different orders, among which are Ericales, Malvales, and Malpighiales.

</doc>
<doc id="55092" url="http://en.wikipedia.org/wiki?curid=55092" title="Scythians">
Scythians

The Scythians ( or ; from Greek Σκύθης, Σκύθοι), also known as Scyth, Saka, Sakae, Sai, Iskuzai, or Askuzai, were a large group of Iranian nomads who were mentioned by the literate peoples surrounding them as inhabiting large areas in the central Eurasian steppes from about the 9th century BC up until the 4th century AD. Their Scythian languages probably belonged to the Eastern branch of the Iranian languages. The "classical Scythians" known to ancient Greek historians were located in the northern Black Sea and fore-Caucasus region. Other Scythian groups documented by Assyrian, Achaemenid and Chinese sources show that they also existed in Central Asia, where they were referred to as the "Iskuzai"/"Askuzai", "Saka" (Old Persian: "Sakā"; New Persian/Pashto: ساکا‎; Sanskrit: शक "Śaka"; Greek: Σάκαι; Latin: "Sacae"), and "Sai" (), respectively.
The relationships between the peoples living in these widely separated regions remains unclear. The term "Scythian" is used by modern scholars in an archaeological context for finds perceived to display attributes of the "Scytho-Siberian" culture, usually without implying an ethnic or linguistic connotation. The term Scythic may also be used in a similar way, "to describe a special phase that followed the widespread diffusion of mounted nomadism, characterized by the presence of special weapons, horse gear, and animal art in the form of metal plaques". Their westernmost territories during the Iron Age were known to classical Greek sources as Scythia.
The Scythians were among the earliest peoples to master mounted warfare. In the 8th century BC they possibly raided Zhou China. Soon after they expanded westwards and dislodged the Cimmerians from power on the Pontic Steppe. At their peak, Scythians came to dominate the entire steppe zone, stretching from the Carpathian Mountains in the west to the central China (Ordos culture) and the south Siberia (Tagar culture) in the east, creating what has been referred to as the first Central Asian nomadic empire.
Based in Crimea the western Scythians were ruled by a wealthy class known as the Royal Scyths. The Scythians established and controlled a vast trade network (Silk Road) connecting Ancient Greece, Persia, India and China, perhaps contributing to the contemporary flourishing of those civilizations. The Scythians and settled metalworkers producing for them made portable decorative objects, which survive mainly in metal forming a distinctive Scythian art. In the 7th century BC they crossed the Caucasus and frequently raided the Middle East along with the Cimmerians, playing an important role in the political developments of the region. Around 650-630 BC, Scythians briefly dominated the Medes of the Iranian Plateau, stretching their power all the away to the borders Egypt. After losing control over Media the Scythians continued intermedling in Middle Eastern affairs, playing a leading role in the destruction of the Assyrian Empire in the Sack of Nineveh in 612 BC. The Scythians subsequently engaged in frequent conflicts with the Achaemenid Empire. The western Scythians suffered a major defeat against Macedonia in the 4th century BC, and were subsequently gradually conquered by the Sarmatians, a related Iranian people from Central Asia. The Scythians of the Asian Steppe (Saka) were attacked by the Yuezhi, Wusun and Xiongnu in the 2nd century BC, promting many of them to migrate into South Asia, where they became known as Indo-Scythians. During the 3rd century AD, after demise of the Han dynasty and the Xiongnu, remaining Scythians mounted down the Pamir Mountains and settled down in the western Tarim Basin, where the Scythian languages Khotanese and Tymshuqese are attested in Brahmi scripture from the 10th and 11th centuries AD.
Names.
Sulimirski views the "Histories" of Herodotus as the most important literary source relating to ancient Scyths. Herodotus provides a depiction that can be related to the results of archaeological research, but apparently knew little of the eastern part of Scythia. He did say that the ancient Persians called all the Scyths "Σάκαι" (Sacae, Herodotus 7.64). Their principal tribe, the "Royal Scyths", ruled the vast lands occupied by the nation as a whole (Herodotus 4.20), calling themselves "Σκώλοτοι" (Scōloti, Herodotus 4.6). Oswald Szemerényi devotes a thorough discussion to the etymologies of ancient ethnic words for the Scythians in his work "Four old Iranian ethnic names: Scythian – Skudra – Sogdian – Saka". In it, the names of Herodotus and the names of his title, except Saka, as well as many other words for "Scythian," such as Assyrian "Aškuz" and Greek "Skuthēs", descend from *skeud-, an ancient Indo-European root meaning "propel, shoot" (cf. English shoot). *skud- is the zero-grade; that is, a variant in which the -e- is not present. The restored Scythian name is *Skuda (archer), which among the Pontic or Royal Scythians became *Skula, in which the d has been regularly replaced by an l.
Saka, on the other hand, Szemerényi relates to an Iranian verbal root, sak-, "go, roam", and hypothesizes that the Achaemenids used "nomad" to refer to the northern tribes, rather than their endonym. The name does appear somewhat further east than the Achaemenid Empire, as the Chinese knew the Asian Scythians as Sai (Chinese character: 塞, Old Sinitic "*sək"). Whether they adopted the Achaemenid name, or "Saka" came to be an endonym, it is not clear. The modern region of Sistan in eastern Iran and southern Afghanistan takes its name from the classical Sakastan ("land of the Sakas").
Sakastan was not the only province of Scythian origin on the eastern margin of the Persian Empire. According to Szemerényi, Sogdiana was named from the Skuda form. Starting from the names of the province given in Old Persian inscriptions, Sugda and Suguda, and the knowledge derived from Middle Sogdian that Old Persian -gd- applied to Sogdian was pronounced as voiced fricatives, -γδ-, Szemerényi arrives at *Suγδa as an Old Sogdian endonym. Applying sound changes apparent in other Sogdian words and inherent in Indo-European he traces the development of *Suγδa from Skuda, "archer," as follows: Skuda > *Sukuda by anaptyxis > *Sukuδa > *Sukδa (syncope) > *Suγδa (assimilation).
Origins.
Literary evidence.
The Scythians first appeared in the historical record in the 8th century BC. Herodotus reported three contradictory versions as to the origins of the Scythians, but placed greatest faith in this version:
There is also another different story, now to be related, in which I am more inclined to put faith than in any other. It is that the wandering Scythians once dwelt in Asia, and there warred with the Massagetae, but with ill success; they therefore quitted their homes, crossed the Araxes, and entered the land of Cimmeria.
Accounts by Herodotus of Scythian origins has been discounted recently; although his accounts of Scythian raiding activities contemporary to his writings have been deemed more reliable. Moreover, the term Scythian, like Cimmerian, was used to refer to a variety of groups from the Black Sea to southern Siberia and central Asia. "They were not a specific people", but rather variety of peoples "referred to at variety of times in history, and in several places, none of which was their original homeland" The Bible includes a single reference to Scythians in Colossians 3:11, immediately after mentioning barbarians, possibly as an extreme example of a barbarian.
Archaeology.
Modern interpretation of historical, archaeological and anthropological evidence has proposed two broad hypotheses. The first, formerly more espoused by Soviet and then Russian researchers, roughly followed Herodotus' (third) account, holding that the Scythians were an Eastern Iranian group who arrived from Inner Asia, i.e. from the area of Turkestan and western Siberia.
An alternative view explains the origin of the Scythian cultural complex to have emerged from local groups of the "Timber Grave" (or "Srubna") culture (although this is also associated with the Cimmerians). This second theory is supported by anthropological evidence which has found that Scythian skulls are similar to preceding findings from the Timber Grave culture, and distinct from those of the Central Asian "Sacae".
Others have further stressed that "Scythian" was a very broad term used by both ancient and modern scholars to describe a whole host of otherwise unrelated peoples sharing only certain similarities in lifestyle (nomadism), cultural practices and language. The 1st millennium BC ushered a period of unprecedented cultural and economic connectivity amongst disparate and wide-ranging communities. A mobile, broadly similar lifestyle would have facilitated contacts amongst disparate ethnic groupings along the expansive Eurasian steppe from the Danube to Manchuria, leading to many cultural similarities. From the viewpoint of Greek and Persian ancient observers, they were all lumped together under the "etic" category "Scythians".
Genetics.
Early physical analyses have unanimously concluded that the Scythians, even those in the east (e.g. the Pazyryk region), possessed predominantly "Europioid" features, although mixed 'Euro-mongoloid" phenotypes also occur, depending on site and period.
Numerous ancient mitochondrial DNA samples have now been recovered from Bronze and Iron Age communities in the Eurasian steppe and Siberian forest zone, the putative 'ancestors' of the historical Scythians. Compared to Y-DNA, mtDNA is easier to extract and amplify from ancient specimens due to numerous copies of mtDNA per cell.
The earliest studies could only analyze segments of mtDNA, thus providing only broad correlations of affinity to modern 'West Eurasian' or 'East Eurasian' populations. For example, a 2002 study, the mitochondrial DNA of Saka period male and female skeletal remains from a double inhumation kurgan at the Beral site in Kazakhstan was analysed. The two individuals were found to be not closely related. The HV1 mitochondrial sequence of the male was similar to the Anderson sequence which is most frequent in European populations. On the other hand the HV1 sequence of the female suggested a greater likelihood of Asian origins.
More recent studies have been able to type for specific mtDNA lineages. For example a 2004 study studied the HV1 sequence obtained from a male "Scytho-Siberian" at the Kizil site in the Altai Republic. It belonged to the N1a maternal lineage, a geographically "west Eurasian lineage" Another study by the same team, again from two Scytho-Siberian skeletons found in the Altai Republic, were phenotypically males "of mixed Euro-Mongoloid origin". One of the individuals was found to carry the F2a maternal lineage, and the other the D lineage, both of which are characteristic of "East Eurasian" populations.
These early studies have been elaborated by an increasing number of studies by Russian scholars. Conclusions which might be drawn thus far, from an mtDNA perspective, are (i) an early, Bronze Age mixture of both west and east Eurasian lineages, with western lineages being found far to the East, but not vice-versa; (ii) an apparent reversal by Iron Age times, with increasing presence of East Eurasian lineages in the western steppe; (iii) the possible role of migrations from the sedentary south: the Balkano-Danubian and Iranian regions toward the steppe.
Ancient Y-DNA data was finally provided by Keyser "et al" in 2009. They studied the haplotypes and haplogroups of 26 ancient human specimens from the Krasnoyarsk area in Siberia were dated from between the middle of the 2nd millennium BC and the 4th century AD (Scythian and Sarmatian timeframe). Nearly all subjects belong to haplogroup R-M17. The authors suggest that their data shows that between Bronze and Iron Ages the constellation of populations known variously as Scythians, Andronovians, etc. were blue- (or green-) eyed, fair-skinned and light-haired people who might have played a role in the early development of the Tarim Basin civilization. Moreover, this study found that they were genetically more closely related to modern populations of eastern Europe than those of central and southern Asia. The ubiquity and utter dominance of R1a Y-DNA lineage contrasts markedly with the diversity seen in the mtDNA profiles.
However, this comparison was made on the basis of STRs. Since the 2009 study by Keyser "et al", population and geographic specific SNPs have been discovered which can accurately distinguish between "European" R1a (M458, Z280) and "South Asian" R1a (Z93)(Pamjav 2012 . Re-analyzing ancient Scytho-Siberian samples for these more specific subclades will further elucidate if the Eurasian steppe populations have an ultimate Eastern European or EurAsian origin, or perhaps, both. This, in turn, might also depend on which population is studied, i.e. Herodotus' European "classical' Scythians, the Central Asian "Sakae" or un-named nomadic groups in the far east (Altai region) who also bore a 'Scythian" cultural tradition.
History.
Classical Antiquity (600 BC to AD 300).
Herodotus provides the first detailed description of the Scythians. He classes the Cimmerians as a distinct autochthonous tribe, expelled by the Scythians from the northern Black Sea coast ("Hist." 4.11–12). Herodotus also states (4.6) that the Scythians consisted of the Auchatae, Catiaroi, Traspians, and Paralatae or "Royal Scythians". For Herodotus, the Scythians were outlandish barbarians living north of the Black Sea in what are now Moldova, Ukraine and Crimea.—Michael Kulikowski, "Rome's Gothic Wars from the Third Century to Alaric", pg. 14
Modern scholars have surmised that the sack of the Western Zhou capital Haojing in 770 BC might have been connected to a Scythian raid from the Altai before their westward expansion.
In 512 BC, when King Darius the Great of Persia attacked the Scythians, he allegedly penetrated into their land after crossing the Danube. Herodotus relates that the nomadic Scythians frustrated the Persian army by letting it march through the entire country without an engagement. According to Herodotus, Darius in this manner came as far as the Volga River.
During the 5th to 3rd centuries BC, the Scythians evidently prospered. When Herodotus wrote his "Histories" in the 5th century BC, Greeks distinguished Scythia Minor, in present-day Romania and Bulgaria, from a Greater Scythia that extended eastwards for a 20-day ride from the Danube River, across the steppes of today's East Ukraine to the lower Don basin. The Don, then known as "Tanaïs", has served as a major trading route ever since. The Scythians apparently obtained their wealth from their control over the slave trade from the north to Greece through the Greek Black Sea colonial ports of Olbia, Chersonesos, Cimmerian Bosporus, and Gorgippia. They also grew grain, and shipped wheat, flocks, and cheese to Greece.
Strabo (c. 63 BC – 24 AD) reports that King Ateas united under his power the Scythian tribes living between the Maeotian marshes and the Danube. His westward expansion brought him into conflict with Philip II of Macedon (reigned 359 to 336 BC), who took military action against the Scythians in 339 BC. Ateas died in battle, and his empire disintegrated. In the aftermath of this defeat, the Celts seem to have displaced the Scythians from the Balkans; while in south Russia, a kindred tribe, the Sarmatians, gradually overwhelmed them. In 329 BC Philip's son, Alexander the Great, came into conflict with the Scythians at the Battle of Jaxartes. A Scythian army sought to take revenge against the Macedonians for the death of Ateas, as they pushed the borders of their empire north and east, and to take advantage of a revolt by the local Sogdian satrap. However, the Scythian army was defeated by Alexander at the Battle of Jaxartes. Alexander did not intend to subdue the nomads: he wanted to go to the south, where a far more serious crisis demanded his attention. He could do so now without loss of face; and in order to make the outcome acceptable to the Saccae, he released the Scythian prisoners of war without ransom in order to broker a peace agreement. This policy was successful, and the Scythians no longer harassed Alexander's empire. The Olanesti treasure is unique in Europe. Discovered in the 1960 the artefacts are dated to the 5th century BC. The treasure contain six helmets, five greaves and an oil lamp. All the pieces are from the army of the Alexander The Great under Zopyrion command
By the time of Strabo's account (the first decades AD), the Crimean Scythians had created a new kingdom extending from the lower Dnieper to the Crimea. The kings Skilurus and Palakus waged wars with Mithridates the Great (reigned 120–63 BC) for control of the Crimean littoral, including Chersonesos Taurica and the Cimmerian Bosporus. Their capital city, Scythian Neapolis, stood on the outskirts of modern Simferopol. The Goths destroyed it later, in the mid-3rd century AD.
Sakas and Indo-Scythians.
For Indo-Scythians and other central and southern Asian nomadic groups, see 
Late Antiquity (AD 300 to 600).
In Late Antiquity, the notion of a Scythian ethnicity grew more vague and outsiders might dub any people inhabiting the Pontic-Caspian steppe as "Scythians", regardless of their language. Thus, Priscus, a Byzantine emissary to Attila, repeatedly referred to the latter's followers as "Scythians". But Eunapius, Claudius Cladianus and Olympiodorus usually mean "Goths" when they write "Scythians".
The Goths had displaced the Sarmatians in the 2nd century from most areas near the Roman frontier, and by early medieval times, the Turkic migration marginalized Eastern Iranian dialects, and assimilated the Saka linguistically.
Archaeology.
Archaeological remains of the Scythians include kurgan tombs (ranging from simple exemplars to elaborate "Royal kurgans" containing the "Scythian triad" of weapons, horse-harness, and Scythian-style wild-animal art), gold, silk, and animal sacrifices, in places also with suspected human sacrifices. Mummification techniques and permafrost have aided in the relative preservation of some remains. Scythian archaeology also examines the remains of North Pontic Scythian cities and fortifications.
The spectacular Scythian grave-goods from Arzhan, and others in Tuva have been dated from about 900 BC onward. One grave find on the lower Volga gave a similar date, and one of the Steblev graves from the East European end of the Scythian area was dated to the late 8th century BC.
Archaeologists can distinguish three periods of ancient Scythian archaeological remains:
From the 8th to the 2nd centuries BC, archaeology records a split into two distinct settlement areas: the older in the Sayan-Altai area in Central Asia, and the younger in the North Pontic area in Eastern Europe.
Kurgans.
Large burial mounds (some over 20 metres high), provide the most valuable archaeological remains associated with the Scythians. They dot the Eurasian steppe belt, from Mongolia to Balkans, through Ukrainian and south Russian steppes, extending in great chains for many kilometers along ridges and watersheds. From them archaeologists have learned much about Scythian life and art. Some Scythian tombs reveal traces of Greek, Chinese, and Indian craftsmanship, suggesting a process of Hellenization, Sinification, and other local influences among the Scythians.
The Ukrainian term for such a burial mound, "kurhan" (Ukrainian: Курган) as well as the Russian term "kurgan", derives from a Turkic word for "castle".
Some Scythian-Sarmatian cultures may have given rise to Greek stories of Amazons. Graves of armed females have been found in southern Ukraine and Russia. David Anthony notes, "About 20% of Scythian-Sarmatian "warrior graves" on the lower Don and lower Volga contained females dressed for battle as if they were men, a style that may have inspired the Greek tales about the Amazons."
Pazyryk culture.
Some of the first Bronze Age Scythian burials documented by modern archaeologists include the kurgans at Pazyryk in the Ulagan (Red) district of the Altai Republic, south of Novosibirsk in the Altai Mountains of southern Siberia (near Mongolia). Archaeologists have extrapolated the Pazyryk culture from these finds: five large burial mounds and several smaller ones between 1925 and 1949, one opened in 1947 by Russian archaeologist Sergei Rudenko. The burial mounds concealed chambers of larch-logs covered over with large cairns of boulders and stones.
The Pazyryk culture flourished between the 7th and 3rd century BC in the area associated with the "Sacae".
Ordinary Pazyryk graves contain only common utensils, but in one, among other treasures, archaeologists found the famous , the oldest surviving wool-pile oriental rug. Another striking find, , survived superbly preserved from the 5th century BC.
Although some scholars sought to connect the Pazyryk nomads with indigenous ethnic groups of the Altaic, Rudenko summed up the cultural context in the following dictum:
All that is known to us at the present time about the culture of the population of the High Altai, who have left behind them the large cairns, permits us to refer them to the Scythian period, and the Pazyryk group in particular to the 5th century BC. This is supported by radiocarbon dating.
Bilsk excavations.
Recent digs(see:Gelonus) in a village Bilsk near Poltava (Ukraine) have uncovered a "vast city", with the largest area of any city in the world at that time (). It has been tentatively identified by a team of archaeologists led by Boris Shramko as the site of Gelonus, the purported capital of Scythia. The city's commanding ramparts and vast area of 40 square kilometers exceed even the outlandish size reported by Herodotus. Its location at the northern edge of the Ukrainian steppe would have allowed strategic control of the north-south trade-route. Judging by the finds dated to the 5th and 4th centuries BC, craft workshops and Greek pottery abounded.
Tillia Tepe treasure.
A site found in 1968 in Tillia Tepe (literally "the golden hill") in northern Afghanistan (former Bactria) near Shebergan consisted of the graves of five women and one man with extremely rich jewelry, dated to around the 1st century BC, and probably related to that of Scythian tribes normally living slightly to the north. Altogether the graves yielded several thousands of pieces of fine jewelry, usually made from combinations of gold, turquoise and lapis-lazuli.
A high degree of cultural syncretism pervades the findings, however. Hellenistic cultural and artistic influences appear in many of the forms and human depictions (from amorini to rings with the depiction of Athena and her name inscribed in Greek), attributable to the existence of the Seleucid empire and Greco-Bactrian kingdom in the same area until around 140 BC, and the continued existence of the Indo-Greek kingdom in the northwestern Indian sub-continent until the beginning of our era. This testifies to the richness of cultural influences in the area of Bactria at that time.
Physical appearance.
In artworks, the Scythians are portrayed exhibiting Europoid traits. In Histories, the 5th-century Greek historian Herodotus describes the Budini of Scythia as red-haired and grey-eyed. In the 5th century BC, Greek physician Hippocrates argued that the Scythians have purron (ruddy) skin. In the 3rd century BC, the Greek poet Callimachus described the Arismapes (Arimaspi) of Scythia as fair-haired. The 2nd century BC Han Chinese envoy Zhang Qian described the Sai (Scythians) as having yellow and blue eyes. In Natural History, the 1st century AD Roman author Pliny the Elder characterizes the Seres, sometimes identified as Iranians (Scythians) or Tocharians, as red-haired and blue-eyed. In the late 2nd century AD, the Christian theologian Clement of Alexandria says that the Scythians are fair-haired. The 2nd century Greek philosopher Polemon includes the Scythians among the northern peoples characterized by red hair and blue-grey eyes. In the late 2nd or early 3rd century AD, the Greek physician Galen declares that Sarmatians, Scythians and other northern peoples have reddish hair. The fourth-century Roman historian Ammianus Marcellinus wrote that the Alans, a people closely related to the Scythians, were tall, blond and light-eyed. The 4th century bishop of Nyssa Gregory of Nyssa wrote that the Scythians were fair skinned and blond haired. The 5th-century physician Adamantius, who often follow Polemon, describes the Scythians are fair-haired. It is possible that the later physical descriptions by Adamantius and Gregory of Scythians refer to East Germanic tribes, as the latter were frequently referred to as "Scythians" in Roman sources at that time.
Culture and society.
Tribal divisions.
Scythians lived in confederated tribes, a political form of voluntary association which regulated pastures and organized a common defence against encroaching neighbors for the pastoral tribes of mostly equestrian herdsmen. While the productivity of domesticated animal-breeding greatly exceeded that of the settled agricultural societies, the pastoral economy also needed supplemental agricultural produce, and stable nomadic confederations developed either symbiotic or forced alliances with sedentary peoples – in exchange for animal produce and military protection.
Herodotus relates that three main tribes of the Scythians descended from three brothers, Lipoxais, Arpoxais, and Colaxais:
In their reign a plough, a yoke, an axe, and a bowl, all made of gold, fell from heaven upon the Scythian territory. The oldest of the brothers wished to take them away, but as he drew near the gold began to burn. The second brother approached them, but with the like result. The third and youngest then approached, upon which the fire went out, and he was enabled to carry away the golden gifts. The two eldest then made the youngest king, and henceforth the golden gifts were watched by the king with the greatest care, and annually approached with magnificent sacrifices.
Herodotus also mentions a royal tribe or clan, an elite which dominated the other Scythians:
Then on the other side of the Gerros we have those parts which are called the "Royal" lands and those Scythians who are the bravest and most numerous and who esteem the other Scythians their slaves.
The elder brothers then, acknowledging the significance of this thing, delivered the whole of the kingly power to the youngest. From Lixopais, they say, are descended those Scythians who are called the race of the Auchatai; from the middle brother Arpoxais those who are called Catiaroi and Traspians, and from the youngest of them the "Royal" tribe, who are called Paralatai: and the whole together are called, they say, Scolotoi, after the name of their king; but the Hellenes gave them the name of Scythians. Thus the Scythians say they were produced; and from the time of their origin, that is to say from the first king Targitaos, to the passing over of Dareios [the Persian Emperor Darius I] against them [512 BC], they say that there is a period of a thousand years and no more.
This royal clan is also named in other classical sources the "Royal Dahae". The rich burials of Scythian kings in (kurgans) is independent evidence for the existence of this powerful royal elite.
Although scholars have traditionally treated the three tribes as geographically distinct, Georges Dumézil interpreted the divine gifts as the symbols of social occupations, illustrating his trifunctional vision of early Indo-European societies: the plough and yoke symbolised the farmers, the axe – the warriors, the bowl – the priests.
According to Dumézil, "the fruitless attempts of Arpoxais and Lipoxais, in contrast to the success of Colaxais, may explain why the highest strata was not that of farmers or magicians, but rather that of warriors."
Warfare.
The Scythians were notoriously aggressive warriors. They "fought to live and lived to fight" and "drank the blood of their enemies and used the scalps as napkins" 
Ruled by small numbers of closely allied élites, Scythians had a reputation for their archers, and many gained employment as mercenaries. Scythian élites had kurgan tombs: high barrows heaped over chamber-tombs of larch-wood – a deciduous conifer that may have had special significance as a tree of life-renewal, for it stands bare in winter. Burials at Pazyryk in the Altay Mountains have included some spectacularly preserved Scythians of the "Pazyryk culture" – including the Ice Maiden of the 5th century BC.
The Ziwiye hoard, a treasure of gold and silver metalwork and ivory found near the town of Sakiz south of Lake Urmia and dated to between 680 and 625 BC, includes objects with Scythian "animal style" features. One silver dish from this find bears some inscriptions, as yet undeciphered and so possibly representing a form of Scythian writing.
Scythians also had a reputation for the use of barbed and poisoned arrows of several types, for a nomadic life centered on horses – "fed from horse-blood" according to Herodotus – and for skill in guerrilla warfare.
Clothing.
According to Herodotus, Scythian costume consisted of padded and quilted leather trousers tucked into boots, and open tunics. They rode with no stirrups or saddles, just saddle-cloths. Herodotus reports that Scythians used cannabis, both to weave their clothing and to cleanse themselves in its smoke (Hist. 4.73–75); archaeology has confirmed the use of cannabis in funeral rituals.
Scythian women dressed in much the same fashion as men. A Pazyryk burial, discovered in the 1990s, contained the skeletons of a man and a woman, each with weapons, arrowheads, and an axe.
Men and women dressed differently. Herodotus mentioned that Sakas had "high caps and ... wore trousers." Clothing was sewn from plain-weave wool, hemp cloth, silk fabrics, felt, leather and hides.
Pazyryk findings give the most number of almost fully preserved garments and clothing worn by the Scythian/Saka peoples. Ancient Persian bas-relief – Apadana or Behistun inscription, ancient Greek pottery, archaeological findings from Ukraine, Russia, Kazakhstan, China et al. give visual representations of these garments.
Herodotus says Sakas had "high caps tapering to a point and stiffly upright." Asian Saka headgear is clearly visible on the Persepolis Apadana staircase bas-relief – high pointed hat with flaps over ears and the nape of the neck. From China to the Danube delta, men seemed to have worn a variety of soft headgear – either conical like the one described by Herodotus, or rounder, more like a Phrygian cap.
Women wore a variety of different headdresses, some conical in shape others more like flattened cylinders, also adorned with metal (golden) plaques.
Based on the Pazyryk findings (can be seen also in the south Siberian, Uralic and Kazakhstan rock drawings) some caps were topped with zoomorphic wooden sculptures firmly attached to a cap and forming an integral part of the headgear, similar to the surviving nomad helmets from northern China.
Men and warrior women wore tunics, often embroidered, adorned with felt applique work, or metal (golden) plaques.
Persepolis Apadana again serves a good starting point to observe tunics of the Sakas. They appear to be a sewn, long sleeve garment that extended to the knees and belted with a belt while owner's weapons were fastened to the belt (sword or dagger, gorytos, battleax, whetstone etc.). Based on numerous archeological findings in Ukraine, southern Russian and Kazakhstan men and warrior women wore long sleeve tunics that were always belted, often with richly ornamented belts. The Kazakhstan Saka (e.g. Issyk Golden Man/Maiden) wore shorter tunics and more close fitting tunics than the Pontic steppe Scythians. Some Pazyryk culture Saka wore short belted tunic with a lapel on a right side, upright collar, 'puffed' sleeves narrowing at a wrist and bound in narrow cuffs of a color different from the rest of the tunic.
Scythian women wore long, loose robes, ornamented with metal plaques (gold). Women wore shawls, often richly decorated with metal (golden) plaques.
Men and women wore coats, e.g. Pazyryk Saka had many varieties, from fur to felt. They could have worn a riding coat that later was known as a Median robe or Kantus. Long sleeved, and open, it seems that on the Persepolis Apadana Skudrian delegation is perhaps shown wearing such coat. The Pazyryk felt tapestry shows a rider wearing a billowing cloak.
Men and women wore long trousers, often adorned with metal plaques and often embroidered or adorned with felt appliqués; trousers could have been wider or tight fitting depending on the area. Materials used depended on the wealth, climate and necessity.
Men and women warriors wore variations of long and shorter boots, wool-leather-felt gaiter-boots and moccasin-like shoes. They were either of a laced or simple slip on type.
Women wore also soft shoes with metal (gold) plaques.
Men and women wore belts. Warrior belts were made of leather, often with gold or other metal adornments and had many attached leather thongs for fastening of the owner's gorytos, sword, whet stone, whip etc. Belts were fastened with metal or horn belt-hooks, leather thongs and metal (often golden) or horn belt-plates.
Art.
Scythian contacts with craftsmen in Greek colonies along the northern shores of the Black Sea resulted in the famous Scythian gold adornments that feature among the most glamorous artifacts of world museums. Ethnographically extremely useful as well, the gold depicts Scythian men as bearded, long-haired Caucasoids. "Greco-Scythian" works depicting Scythians within a much more Hellenic style date from a later period, when Scythians had already adopted elements of Greek culture, and the most elaborate royal pieces are assumed to have been made by Greek goldsmiths for this lucrative market. Other metalwork pieces from across the whole Eurasian steppe use an animal style, showing animals, often in combat and often with their legs folded beneath them. This origins of this style remain debated, but it probably both received and gave influences in the art of the neighbouring settled peoples, and acted as a fast route for transmission of motifs across the width of Eurasia.
Surviving Scythian objects are mostly small portable pieces of metalwork: elaborate personal jewelry, weapon-ornaments and horse-trappings. But finds from sites with permafrost show rich and brightly coloured textiles, leatherwork and woodwork, not to mention tatooing. The western royal pieces executed Central-Asian animal motifs with Greek realism: winged gryphons attacking horses, battling stags, deer, and eagles, combined with everyday motifs like milking ewes.
In 2000, the touring exhibition 'Scythian Gold' introduced the North American public to the objects made for Scythian nomads by Greek craftsmen north of the Black Sea, and buried with their Scythian owners under burial mounds on the flat plains of present-day Ukraine. In 2001, the discovery of an undisturbed royal Scythian burial-barrow illustrated Scythian animal-style gold that lacks the direct influence of Greek styles. Forty-four pounds of gold weighed down the royal couple in this burial, discovered near Kyzyl, capital of the Siberian republic of Tuva.
Ancient influences from Central Asia became identifiable in China following contacts of metropolitan China with nomadic western and northwestern border territories from the 8th century BC. The Chinese adopted the Scythian-style animal art of the steppes (descriptions of animals locked in combat), particularly the rectangular belt-plaques made of gold or bronze, and created their own versions in jade and steatite.
Following their expulsion by the Yuezhi, some Scythians may also have migrated to the area of Yunnan in southern China. Scythian warriors could also have served as mercenaries for the various kingdoms of ancient China. Excavations of the prehistoric art of the Dian civilization of Yunnan have revealed hunting scenes of Caucasoid horsemen in Central Asian clothing.
Scythian influences have been identified as far as Korea and Japan. Various Korean artifacts, such as the royal crowns of the kingdom of Silla, are said to be of Scythian design. Similar crowns, brought through contacts with the continent, can also be found in Kofun era Japan.
Religion.
The religious beliefs of the Scythians was a type of Pre-Zoroastrian Iranian religion and differed from the post-Zoroastrian Iranian thoughts. Foremost in the Scythian pantheon stood Tabiti, who was later replaced by Atar, the fire-pantheon of Iranian tribes, and Agni, the fire deity of Indo-Aryans. The Scythian belief was a more archaic stage than the Zoroastrian and Hindu systems. The use of cannabis to induce trance and divination by soothsayers was a characteristic of the Scythian belief system.
Language.
The "Scythian languages" are essentially unattested, and their internal divergence is difficult to judge. They belonged to the Eastern Iranian family of languages.
The Scythian languages may have formed a dialect continuum: "Scytho-Sarmatian" in the west and "Scytho-Khotanese" or Saka in the east. They were mostly marginalized and assimilated as a consequence of the late antiquity and early Middle Ages Slavic and Turkic expansion. Some remnants of the eastern groups have survived as modern Pashto and Pamiri languages in Central Asia. The western (Sarmatian) group of Scythian survived as the language of the Alans and eventually gave rise to the modern Ossetian language.
Historiography.
Herodotus.
Herodotus wrote about an enormous city, Gelonus, in the northern part of Scythia
Herodotus and other classical historians listed quite a number of tribes who lived near the Scythians, and presumably shared the same general milieu and nomadic steppe culture, often called "Scythian culture", even though scholars may have difficulties in determining their exact relationship to the "linguistic Scythians". A partial list of these tribes includes the Agathyrsi, Geloni, Budini, and Neuri.
Herodotus presented four different versions of Scythian origins:
Persians and other peoples in Asia referred to the Scythians living in Asia as Sakas. Herodotus (IV.64) describes them as Scythians, although they figure under a different name:
The Sacae, or Scyths, were clad in trousers, and had on their heads tall stiff caps rising to a point. They bore the bow of their country and the dagger; besides which they carried the battle-axe, or "sagaris". They were in truth Amyrgian (Western) Scythians, but the Persians called them Sacae, since that is the name which they gave to all Scythians.
Strabo.
In the 1st century BC, the Greek-Roman geographer Strabo gave an extensive description of the eastern Scythians, whom he located in north-eastern Asia beyond Bactria and Sogdiana:
Then comes Bactriana, and Sogdiana, and finally the Scythian nomads.
Strabo went on to list the names of the various tribes among the Scythians, probably making an amalgam with some of the tribes of eastern Central Asia (such as the Tocharians):
Now the greater part of the Scythians, beginning at the Caspian Sea, are called Daheans, but those who are situated more to the east than these are named Massageteans and Saceans, whereas all the rest are given the general name of Scythians, though each people is given a separate name of its own. They are all for the most part nomads. But the best known of the nomads are those who took away Bactriana from the Greeks (i.e. Greco-Bactrians), I mean the Asians, Pasians, Tocharians, and Sacarauls, who originally came from the country on the other side of the Jaxartes River that adjoins that of the Sacae and the Sogdians and was occupied by the Sacae. And as for the Daëans, some of them are called Aparns, some Xanthians, and some Pissures. Now of these the Aparni are situated closest to Hyrcania and the part of the sea that borders on it, but the remainder extend even as far as the country that stretches parallel to Aria.
Indian sources.
Sakas receive numerous mentions in Indian texts, including the Puranas, the Manusmriti, the Ramayana, the Mahabharata, the Mahabhashya of Patanjali.
Post-classical "Scythians".
Migration period.
Although the classical Scythians may have largely disappeared by the 1st century BC, Eastern Romans continued to speak conventionally of "Scythians" to designate Germanic tribes and confederations or mounted Eurasian nomadic barbarians in general: in 448 AD two mounted "Scythians" led the emissary Priscus to Attila's encampment in Pannonia. The Byzantines in this case carefully distinguished the Scythians from the Goths and Huns who also followed Attila.
The Sarmatians (including the Alans and finally the Ossetians) counted as Scythians in the broadest sense of the word – as speakers of Eastern Iranian languages, and are considered mostly of Indo-Iranian descent.
Byzantine sources also refer to the Rus raiders who attacked Constantinople around 860 AD in contemporary accounts as "Tauroscythians", because of their geographical origin, and despite their lack of any ethnic relation to Scythians. Patriarch Photius may have first applied the term to them during the Siege of Constantinople (860).
Early Modern usage.
Owing to their reputation as established by Greek historians, the Scythians long served as the epitome of savagery and barbarism.
In the Bible, Paul uses "Scythian" as an example of people whom some label pejoratively, but who are, in Christ, acceptable to God:
 Here there is no Greek or Jew. There is no difference between those who are circumcised and those who are not. There is no rude outsider, or even a Scythian. There is no slave or free person. But Christ is everything. And he is in everything.
Shakespeare, for instance, alluded to the legend that Scythians ate their children in his play "King Lear":
The barbarous Scythian
Or he that makes his generation messes
To gorge his appetite, shall to my bosom¨
Be as well neighbour'd, pitied, and relieved,
As thou my sometime daughter.
Characteristically, early modern English discourse on Ireland frequently resorted to comparisons with Scythians in order to confirm that the indigenous population of Ireland descended from these ancient "bogeymen", and showed themselves as barbaric as their alleged ancestors. Edmund Spenser wrote that
the Chiefest [nation that settled in Ireland] I Suppose to be Scithians ... which firste inhabitinge and afterwarde stretchinge themselves forthe into the lande as theire numbers increased named it all of themselues Scuttenlande which more brieflye is Called Scuttlande or Scotlande.
As proofs for this origin Spenser cites the alleged Irish customs of blood-drinking, nomadic lifestyle, the wearing of mantles and certain haircuts and
Cryes allsoe vsed amongeste the Irishe which savor greatlye of the "Scythyan" Barbarisme.
William Camden, one of Spenser's main sources, comments on this legend of origin that
to derive descent from a Scythian stock, cannot be thought any waies dishonourable, seeing that the Scythians, as they are most ancient, so they have been the Conquerours of most Nations, themselves alwaies invincible, and never subject to the Empire of others.
The 15th-century Polish chronicler Jan Długosz was the first to connect the prehistory of Poland with Sarmatians, and the connection was taken up by other historians and chroniclers, such as Marcin Bielski, Marcin Kromer and Maciej Miechowita. Other Europeans depended for their view of Polish Sarmatism on Miechowita's "Tractatus de Duabus Sarmatiis", a work which provided a substantial source of information about the territories and peoples of the Polish-Lithuanian Commonwealth in a language of international currency.
Tradition specified that the Sarmatians themselves were descended from Japheth, son of Noah.
In the 17th and 18th centuries, foreigners regarded the Russians as descendants of Scythians. It became conventional to refer to Russians as Scythians in 18th-century poetry, and Alexander Blok drew on this tradition sarcastically in his last major poem, "The Scythians" (1920). In the 19th century, romantic revisionists in the West transformed the "barbarian" Scyths of literature into the wild and free, hardy and democratic ancestors of all blond Indo-Europeans.
Descent claims.
A number of groups have claimed possible descent from the Scythians, including the Ossetians, Pashtuns (in particular, the Sakzai tribe) and the Parthians (whose homelands lay to the east of the Caspian Sea and who were thought to have come there from north of the Caspian). Some legends of the Poles, the Picts, the Gaels, the Hungarians (in particular, the Jassics), the Serbs, Bosniaks and the Croats, among others, also include mention of Scythian origins. Some writers claim that Scythians figured in the formation of the empire of the Medes and likewise of Caucasian Albania.
The Scythians also feature in some national origin-legends of the Celts. In the second paragraph of the 1320 Declaration of Arbroath, the élite of Scotland claim Scythia as a former homeland of the Scots. According to the 11th-century Lebor Gabála Érenn ("The Book of the Taking of Ireland"), the 14th-century Auraicept na n-Éces and other Irish folklore, the Irish originated in Scythia and were descendants of Fénius Farsaid, a Scythian prince who created the Ogham alphabet and who was one of the principal architects of the Gaelic language.
The Carolingian kings of the Franks traced Merovingian ancestry to the Germanic tribe of the Sicambri. Gregory of Tours documents in his "History of the Franks" that when Clovis was baptised, he was referred to as a Sicamber with the words "Mitis depone colla, Sicamber, adora quod incendisti, incendi quod adorasti.". The Chronicle of Fredegar in turn reveals that the Franks believed the Sicambri to be a tribe of Scythian or Cimmerian descent, who had changed their name to Franks in honour of their chieftain Franco in 11 BC.
Tadeusz Sulimirski notes that the Sacae also invaded parts of Northern India, where it is theorised that a number of groups may have encountered historical Scythian influence.
Based on such accounts of Scythian founders of certain Germanic as well as Celtic tribes, British historiography in the British Empire period such as
Sharon Turner in his "History of the Anglo-Saxons", made them the ancestors of the Anglo-Saxons.
The idea was taken up in the British Israelism of John Wilson, who adopted and promoted the "idea that the "European Race, in particular the Anglo-Saxons, were descended from certain Scythian tribes, and these Scythian tribes (as many had previously stated from the Middle Ages onward) were in turn descended from the ten Lost Tribes of Israel." Tudor Parfitt, author of The Lost Tribes of Israel and Professor of Modern Jewish Studies, points out that the proof cited by adherents of British Israelism is "of a feeble composition even by the low standards of the genre."
According to Patrick J. Geary, many of the peoples once known as the Scythians of Antiquity were amalgamated into the various Slavic peoples of eastern and southeastern Europe.
Linguistically, only modern-day Ossetian and Pashto as well as Yaghnobi and Pamiri languages are similar to old Eastern Iranian languages once spoken by Scythians.
References.
Bibliography.
</dl>
Further reading.
</dl>

</doc>
<doc id="55095" url="http://en.wikipedia.org/wiki?curid=55095" title="Marihuana Tax Act of 1937">
Marihuana Tax Act of 1937

 
The Marihuana Tax Act of 1937, Pub. 238, 75th Congress, 50 Stat. 551 (Aug. 2, 1937) was a United States Act that placed a tax on the sale of cannabis. The H.R. 6385 act was drafted by Harry Anslinger and introduced by Rep. Robert L. Doughton of North Carolina, on April 14, 1937. The seventy-fifth Congress held hearings on April 27, 28, 29th, 30th, and May 4, 1937. Upon the congressional hearings confirmation, the H.R. 6385 act was redrafted as H.R. 6906 and introduced with House Report 792. The Act is now commonly referred to, using the modern spelling, as the 1937 Marihuana Tax Act. This act was overturned in 1969 in "Leary v. United States", and was repealed by Congress the next year.
Background.
Regulations and restrictions on the sale of cannabis sativa as a drug began as early as 1860 (see Legal history of cannabis in the United States). The head of the Federal Bureau of Narcotics (FBN), Harry J. Anslinger, argued that, in the 1930s, the FBN had noticed an increase of reports of people smoking marijuana. He had also, in 1935, received support from president Franklin D. Roosevelt for adoption of the Uniform State Narcotic Act, state laws that included regulations of cannabis.
The total production of hemp fiber in the United States had in 1933 decreased to around 500 tons/year. Cultivation of hemp began to increase in 1934 and 1935 but production remained at very low volume compared with other fibers.
Some parties have argued that the aim of the Act was to reduce the size of the hemp industry largely as an effort of businessmen Andrew Mellon, Randolph Hearst, and the Du Pont family. The same parties have argued that with the invention of the decorticator, hemp had become a very cheap substitute for the paper pulp that was used in the newspaper industry. These parties argue that Hearst felt that this was a threat to his extensive timber holdings. Mellon, Secretary of the Treasury and the wealthiest man in America, had invested heavily in the Du Pont family's new synthetic fiber, nylon, a fiber that was competing with hemp. In 1916, United States Department of Agriculture (USDA) chief scientists Jason L. Merrill and Lyster H. Dewey created a paper, USDA Bulletin No. 404 "Hemp Hurds as Paper-Making Material", in which they concluded that paper from the woody inner portion of the hemp stem broken into pieces, so called hemp hurds, was "favorable in comparison with those used with pulp wood". Dewey and Merrill believed that hemp hurds were a suitable source for paper production. However, later research does not confirm this. The concentration of cellulose in hemp hurds is only between 32% and 38% (not 77%, a number often repeated by Jack Herer and others on the Internet). Manufacture of paper with hemp as a raw material has shown that hemp lacks the qualities needed to become a major competitor to the traditional paper industry, which still uses wood or waste paper as raw material. In 2003, 95% of the hemp hurds in the EU were used for animal bedding, almost 5% were used as building material. The DuPont Company and many industrial historians dispute a link between nylon and hemp. They argue that the purpose of developing the nylon was to produce a fiber that could compete with silk and rayon.
The American Medical Association (AMA) opposed the act because the tax was imposed on physicians prescribing cannabis, retail pharmacists selling cannabis, and medical cannabis cultivation/manufacturing. The AMA proposed that cannabis instead be added to the Harrison Narcotics Tax Act. The bill was passed over the last-minute objections of the American Medical Association. Dr. William Creighton Woodward, legislative counsel for the AMA objected to the bill on the grounds that the bill had been prepared in secret without giving proper time to prepare their opposition to the bill. He doubted their claims about marijuana addiction, violence, and overdosage; he further asserted that because the word "Marijuana" was largely unknown at the time, the medical profession did not realize they were losing cannabis. "Marijuana is not the correct term... Yet the burden of this bill is placed heavily on the doctors and pharmacists of this country." 
The bill was passed on the grounds of different reports and hearings. Anslinger also referred to the International Opium Convention that from 1928 included cannabis as a drug not a medicine, and that all states had some kind of laws against improper use of cannabis (for ex. the Uniform State Narcotic Act). Today, it is generally accepted that the hearings included incorrect, excessive or unfounded arguments. By 1951, however, new justifications had emerged, and the Boggs Act that superseded the Marihuana Tax Act of 1937 was passed. In August 1954, the Internal Revenue Code of 1954 was enacted, and the Marihuana Tax Act was included in Subchapter A of Chapter 39 of the 1954 Code.
Operation of the act.
Shortly after the 1937 Marihuana Tax Act went into effect on October 1, 1937, the Federal Bureau of Narcotics and Denver City police arrested Moses Baca for possession and Samuel Caldwell for dealing. Baca and Caldwell's arrest made them the first marijuana convictions under U.S. federal law for not paying the marijuana tax. Judge Foster Symes sentenced Baca to 18 months and Caldwell to four years in Leavenworth Penitentiary for violating the 1937 Marihuana Tax Act.
After the Philippines fell to Japanese forces in 1942, the Department of Agriculture and the US Army urged farmers to grow fiber hemp. Tax stamps for cultivation of fiber hemp began to be issued to farmers. Without any change in the Marihuana Tax Act, 400,000 acre were cultivated with hemp between 1942 and 1945. The last commercial hemp fields were planted in Wisconsin in 1957.
In 1967, President Johnson's Commission on Law Enforcement and Administration of Justice opened, "The Act raises an insignificant amount of revenue and exposes an insignificant number of marijuana transactions to public view, since only a handful of people are registered under the Act. It has become, in effect, solely- a criminal law, imposing sanctions upon persons who sell, acquire, or possess marijuana."
In 1969 in "Leary v. United States", part of the Act was ruled to be unconstitutional as a violation of the Fifth Amendment, since a person seeking the tax stamp would have to incriminate him/herself. In response the Congress passed the Controlled Substances Act as Title II of the Comprehensive Drug Abuse Prevention and Control Act of 1970. The 1937 Act was repealed by the 1970 Act.
Etymology.
Although the spelling "marijuana" is more common in current usage, the actual spelling used in the Marihuana Tax Act is "marihuana". "Marihuana" was the spelling most commonly used in Federal Government documents at the time.
In addition, the Marihuana Tax Act of 1937 legitimized the use of the term "marijuana" as a label for hemp and cannabis plants and products in the US and around the world. Prior to 1937, "marijuana" was slang; it was not included in any official dictionaries. The word "marijuana" is probably of Mexican origin. Mexico itself had passed prohibition for export to the US in 1925, following the International Opium Convention. In the years leading up to the tax act, it was in common use in the United States, "smoked like tobacco", and called "ganjah", or "ganja". Considerable issues existed involving illegal immigration of Mexicans into the United States, and the one thing Mexicans were identified as being in possession of was cannabis or "marijuana". The southern border states called for action. After the enactment, illegal immigrants and US citizens could be arrested for possession of cannabis.
The La Guardia Committee Report.
The only authoritative voice that opposed Anslinger's campaign against cannabis was the one of the Mayor of New York Fiorello La Guardia, who appointed in 1938 a commission of investigation, and in 1944 strongly objected to Anslinger's campaign with the famous La Guardia Committee.

</doc>
<doc id="55097" url="http://en.wikipedia.org/wiki?curid=55097" title="U.S. Securities and Exchange Commission">
U.S. Securities and Exchange Commission

The U.S. Securities and Exchange Commission (SEC) is an agency of the United States federal government. It holds primary responsibility for enforcing the federal securities laws, proposing securities rules, and regulating the securities industry, the nation's stock and options exchanges, and other activities and organizations, including the electronic securities markets in the United States.
In addition to the Securities Exchange Act of 1934, which created it, the SEC enforces the Securities Act of 1933, the Trust Indenture Act of 1939, the Investment Company Act of 1940, the Investment Advisers Act of 1940, the Sarbanes–Oxley Act of 2002, and other statutes. The SEC was created by Section 4 of the Securities Exchange Act of 1934 (now codified as #redirect and commonly referred to as the Exchange Act or the 1934 Act).
Overview.
The SEC has a three-part mission: to protect investors; maintain fair, orderly, and efficient markets; and facilitate capital formation. 
The enforcement authority it received from Congress enables the SEC to bring civil enforcement actions against individuals or companies alleged to have committed accounting fraud, provided false information, or engaged in insider trading or other violations of the securities law. The SEC also works with criminal law enforcement agencies to prosecute individuals and companies alike for offenses that include a criminal violation.
To achieve its mandate, the SEC enforces the statutory requirement that public companies submit quarterly and annual reports, as well as other periodic reports. In addition to annual financial reports, company executives must provide a narrative account, called the "management discussion and analysis" (MD&A), that outlines the previous year of operations and explains how the company fared in that time period. MD&A will usually also touch on the upcoming year, outlining future goals and approaches to new projects. In an attempt to level the playing field for all investors, the SEC maintains an online database called EDGAR (the Electronic Data Gathering, Analysis, and Retrieval system) online from which investors can access this and other information filed with the agency.
Quarterly and semiannual reports from public companies are crucial for investors to make sound decisions when investing in the capital markets. Unlike banking, investment in the capital markets is not guaranteed by the federal government. The potential for big gains needs to be weighed against equally likely losses. Mandatory disclosure of financial and other information about the issuer and the security itself gives private individuals as well as large institutions the same basic facts about the public companies they invest in, thereby increasing public scrutiny while reducing insider trading and fraud.
The SEC makes reports available to the public through the EDGAR system. The SEC also offers publications on investment-related topics for public education. The same online system also takes tips and complaints from investors to help the SEC track down violators of the securities laws. The SEC adheres to a strict policy of never commenting on the existence or status of an ongoing investigation.
History.
Prior to the enactment of the federal securities laws and the creation of the SEC, there existed so-called blue sky laws. They were enacted and enforced at the state level, and regulated the offering and sale of securities to protect the public from fraud. Though the specific provisions of these laws varied among states, they all required the registration of all securities offerings and sales, as well as of every U.S. stockbroker and brokerage firm.
However, these blue sky laws were generally found to be ineffective. For example, the Investment Bankers Association told its members as early as 1915 that they could "ignore" blue sky laws by making securities offerings across state lines through the mail. After holding hearings on abuses on interstate frauds (commonly known as the Pecora Commission), Congress passed the Securities Act of 1933 (#redirect ), which regulates interstate sales of securities (original issues) at the federal level. The subsequent Securities Exchange Act of 1934 (#redirect ) regulates sales of securities in the secondary market. Section 4 of the 1934 act created the U.S. Securities and Exchange Commission to enforce the federal securities laws; both laws are considered parts of Franklin D. Roosevelt's New Deal raft of legislation.
The Securities Act of 1933 is also known as the "Truth in Securities Act" and the "Federal Securities Act”, or just the "1933 Act." Its goal was to increase public trust in the capital markets by requiring uniform disclosure of information about public securities offerings. The primary drafters of 1933 Act were Huston Thompson, a former Federal Trade Commission (FTC) chairman, and Walter Miller and Ollie Butler, two attorneys in the Commerce Department's Foreign Service Division, with input from Supreme Court Justice Louis Brandeis. For the first year of the law's enactment, the enforcement of the statute rested with the Federal Trade Commission, but this power was transferred to the SEC following its creation in 1934. (Interestingly, the first, rejected draft of the Securities Act written by Samuel Untermyer vested these powers in the U.S. Post Office, because Untermyer believed that only by vesting enforcement powers with the postal service could the constitutionality of the act be assured.) The law requires that issuing companies register distributions of securities with the SEC prior to interstate sales of these securities, so that investors may have access to basic financial information about issuing companies and risks involved in investing in the securities in question. Since 1994, most registration statements (and associated materials) filed with the SEC can be accessed via the SEC’s online system, EDGAR.
The Securities Exchange Act of 1934 is also known as "the Exchange Act" or "the 1934 Act". This act regulates secondary trading between individuals and companies which are often unrelated to the original issuers of securities. Entities under the SEC’s authority include securities exchanges with physical trading floors such as the New York Stock Exchange (NYSE), self-regulatory organizations (SROs) such as the National Association of Securities Dealers (NASD), the Municipal Securities Rulemaking Board (MSRB), online trading platforms such as the NASDAQ Stock Market (NASDAQ) and alternative trading systems (ATSs), and any other persons ("e.g.", securities brokers) engaged in transactions for the accounts of others.
President Roosevelt appointed Joseph P. Kennedy, Sr., father of President John F. Kennedy, to serve as the first Chairman of the SEC, along with James M. Landis (one of the architects of the 1934 Act and other New Deal legislation) and Ferdinand Pecora (Chief Counsel to the United States Senate Committee on Banking and Currency during its investigation of Wall Street banking and stock brokerage practices). Other prominent SEC commissioners and chairmen include William O. Douglas (who went on to be a U.S. Supreme Court justice), Jerome Frank (one of the leaders of the legal realism movement), and William J. Casey (who later headed the Central Intelligence Agency under President Ronald Reagan).
Organizational structure.
Commission members.
Non-partisan, no more than three Commissioners may belong to the same political party. The President also designates one of the Commissioners as Chairman, the SEC's top executive. However, the President does not possess the power to fire the appointed Commissioners, a provision that was made to ensure the independence of the SEC. This issue arose during the 2008 Presidential Election in connection with the ensuing Financial Crises.
Currently, the SEC Commissioners are:
Mary L. Schapiro served as the 29th Chairman of the SEC from January 2009 through December 2012. She was succeeded by Elisse B. Walter, and on January 24, 2013, President Obama nominated Mary Jo White to replace Walter as Chairman. Mary Jo White was sworn in as Chairman on April 10, 2013.
Divisions.
Within the SEC, there are five divisions. Headquartered in Washington, D.C., the SEC has 11 regional offices throughout the US.
The SEC's divisions are:
Corporation Finance is the division that oversees the disclosure made by public companies, as well as the registration of transactions, such as mergers, made by companies. The division is also responsible for operating EDGAR.
The Trading and Markets division oversees self-regulatory organizations such as the Financial Industry Regulatory Authority (FINRA) and Municipal Securities Rulemaking Board (MSRB) and all broker-dealer firms and investment houses. This division also interprets proposed changes to regulations and monitors operations of the industry. In practice, the SEC delegates most of its enforcement and rulemaking authority to FINRA. In fact, all trading firms not regulated by other SROs must register as a member of FINRA. Individuals trading securities must pass exams administered by FINRA to become registered representatives.
The Investment Management Division oversees registered investment companies, which include mutual funds, as well as registered investment advisors. These entities are subject to extensive regulation under various federals securities laws. The Division of Investment Management administers various federal securities laws, in particular the Investment Company Act of 1940 and Investment Advisers Act of 1940. This division's responsibilities include:
The Enforcement Division works with the other three divisions, and other Commission offices, to investigate violations of the securities laws and regulations and to bring actions against alleged violators. The SEC generally conducts investigations in private. The SEC's staff may seek voluntary production of documents and testimony, or may seek a formal order of investigation from the SEC, which allows the staff to compel the production of documents and witness testimony. The SEC can bring a civil action in a U.S. District Court, or an administrative proceeding which is heard by an independent administrative law judge (ALJ). The SEC does not have criminal authority, but may refer matters to state and federal prosecutors. The director of the SEC's Enforcement Division Robert Khuzami left the office in February 2013.
Among the SEC's offices are:
SEC communications.
Comment letters.
Comment letters are letters by the SEC to a public company raising issues and requested comments. For example, in October 2001 the SEC wrote to CA, Inc., covering 15 items, mostly about CA's accounting, including 5 about revenue recognition. The chief financial officer of CA, to whom the letter was addressed, pleaded guilty to fraud at CA in 2004.
In June 2004, the SEC announced that it would publicly post all comment letters, to give investors access to the information in them. An analysis of regulatory filings in May 2006 over the prior 12 months indicated, that the SEC had not accomplished what it said it would do. The analysis found 212 companies that had reported receiving comment letters from the SEC, but only 21 letters for these companies were posted on the SEC's website. John W. White, the head of the Division of Corporation Finance, told the "New York Times" in 2006: "We have now resolved the hurdles of posting the information... We expect a significant number of new postings in the coming months."
No-action letters.
No-action letters are letters by the SEC staff indicating that the staff will not recommend to the Commission that the SEC undertake enforcement action against a person or company if that entity engages in a particular action. These letters are sent in response to requests made when the legal status of an activity is not clear. These letters are publicly released and increase the body of knowledge on what exactly is and is not allowed. They represent the staff's interpretations of the securities laws and, while persuasive, are not binding on the courts.
One such use, from 1975 to 2007, was with the nationally recognized statistical rating organization (NRSRO), a credit rating agency that issues credit ratings that the SEC permits other financial firms to use for certain regulatory purposes.
Operations.
List of major SEC enforcement actions (2009–12).
The SEC's Enforcement Division brought a number of major actions in 2009–12.
Regulatory action in the credit crunch.
The SEC announced on September 17, 2008, strict new rules to prohibit all forms of "naked short selling" as a measure to reduce volatility in turbulent markets.
The SEC investigated cases involving individuals attempting to manipulate the market by passing false rumors about certain financial institutions. The Commission has also investigated trading irregularities and abusive short-selling practices. Hedge fund managers, broker-dealers, and institutional investors were also asked to disclose under oath certain information pertaining to their positions in credit default swaps. The Commission also negotiated the largest settlements in the history of the SEC (approximately $51 billion in all) on behalf of investors who purchased auction rate securities from six different financial institutions.
Regulatory failures.
The SEC has been criticized "for being too 'tentative and fearful' in confronting wrongdoing on Wall Street", and for doing "an especially poor job of holding executives accountable".
Christopher Cox, the former SEC chairman, has recognized the organization's multiple failures in relation to the Bernard Madoff fraud. Starting with an investigation in 1992 into a Madoff feeder fund that only invested with Madoff, and which, according to the SEC, promised "curiously steady" returns, the SEC did not investigate indications that something was amiss in Madoff's investment firm. The SEC has been accused of missing numerous red flags and ignoring tips on Madoff's alleged fraud.
As a result, Cox said that an investigation would ensue into "all staff contact and relationships with the Madoff family and firm, and their impact, if any, on decisions by staff regarding the firm". SEC Assistant Director of the Office of Compliance Investigations Eric Swanson had met Madoff's niece, Shana Madoff, when Swanson was conducting an SEC examination of whether Bernard Madoff was running a Ponzi scheme because she was the firm's compliance attorney. The investigation was closed, and Swanson subsequently left the SEC, and married Shana Madoff.
Approximately 45 per cent of institutional investors thought that better oversight by the SEC could have prevented the Madoff fraud. Harry Markopolos complained to the SEC's Boston office in 2000, telling the SEC staff they should investigate Madoff because it was impossible to legally make the profits Madoff claimed using the investment strategies that he said he used.
A similar failure occurred in the case of Allen Stanford, who sold fake certificates of deposit to tens of thousands of people, many of them working-class retirees. In 1997, the SEC's own examiners spotted the fraud and warned about it. But the Enforcement division would not pursue Stanford, despite repeated warnings by SEC examiners over the years. After the Madoff fraud emerged, the SEC finally took action against Stanford in 2009.
In June 2010, the SEC settled a wrongful termination lawsuit with former SEC enforcement lawyer Gary J. Aguirre, who was terminated in September 2005 following his attempt to subpoena Wall Street figure John J. Mack in an insider trading case involving hedge fund Pequot Capital Management; Mary Jo White, who was at the time representing Morgan Stanley later nominated as chair of the SEC, was involved in this case. While the insider case was dropped at the time, a month prior to the SEC's settlement with Aguirre the SEC filed charges against Pequot. The Senate released a report in August 2007 detailing the issue and calling for reform of the SEC.
Others have criticized the SEC for taking an overly rule-based and enforcement-focused approach to regulation, rather than an approach that emphasizes industry-wide safety and learning and thus ensures the reliability of the national securities trading system.
Inspector General office failures.
In 2009, the Project on Government Oversight, a government watchdog group, sent a letter to Congress criticizing the SEC for failing to implement more than half of the recommendations made to it by its Inspector General. According to POGO, in the prior two years, the SEC had taken no action on 27 out of 52 recommended reforms suggested in Inspector General reports, and still had a "pending" status on 197 of the 312 recommendations made in audit reports. Some of the recommendations included imposing disciplinary action on SEC employees who receive improper gifts or other favors from financial companies, and investigating and reporting the causes of the failures to detect the Madoff ponzi scheme.
In a 2011 article by Matt Taibbi in "Rolling Stone", former SEC employees were interviewed and commented negatively on the SEC's Office of the Inspector General (OIG). Going to the OIG was "well-known to be a career-killer".
Because of concerns raised by David P. Weber, former SEC Chief Investigator, regarding conduct by SEC Inspector General H. David Kotz, Inspector General David C. Williams of the U.S. Postal Service was brought in to conduct an independent, outside review of Kotz's alleged improper conduct in 2012. Williams concluded in his 66-page Report that Kotz violated ethics rules by overseeing probes that involved people with whom he had conflicts of interest due to “personal relationships.” The report questioned Kotz’s work on the Madoff investigation, among others, because Kotz was a "very good friend" with Markopolos. It concluded that while it was unclear when Kotz and Markopolos became friends, it would have violated U.S. ethics rules if their relationship began before or during Kotz’s Madoff investigation. The report also found that Kotz himself "appeared to have a conflict of interest" and should not have opened his Standford investigation, because he was friends with a female attorney who represented victims of the fraud.
Destruction of documents.
According to former SEC employee and whistleblower Darcy Flynn, also reported by Taibbi, the agency routinely destroyed thousands of documents related to preliminary investigations of alleged crimes committed by Deutsche Bank, Goldman Sachs, Lehman Brothers, SAC Capital, and other financial companies involved in the Great Recession that the SEC was supposed to have been regulating. The documents included those relating to "Matters Under Inquiry", or MUI, the name the SEC gives to the first stages of the investigation process. The tradition of destruction began as early as the 1990s. This SEC activity eventually caused a conflict with the National Archives and Records Administration when it was revealed to them in 2010 by Flynn. Flynn also described a meeting at the SEC in which top staff discussed "refusing to admit the destruction had taken place, because it was possibly illegal".
Iowa Republican Senator Charles Grassley, among others, took note of Flynn's call for protection as a whistleblower, and the story of the agency's document-handling procedures. The SEC issued a statement defending its procedures. NPR quoted University of Denver Sturm College of Law professor Jay Brown as saying: "My initial take on this is it's a tempest in a teapot," and Jacob Frenkel, a securities lawyer in the Washington, D.C., area, as saying in effect "there's no allegation the SEC tossed sensitive documents from banks it got under subpoena in high-profile cases that investors and lawmakers care about". NPR concluded its report:
The debate boils down to this: What does an investigative record mean to Congress? And the courts? Under the law, those investigative records must be kept for 25 years. But federal officials say no judge has ruled that papers related to early-stage SEC inquiries are investigative records. The SEC's inspector general says he's conducting a thorough investigation into the allegations. [Kotz] tells NPR that he'll issue a report by the end of September.
Relationship to other agencies.
In addition to working with various self-regulatory organizations such as the Financial Industry Regulatory Authority (FINRA), the Securities Investor Protection Corporation (SIPC), and Municipal Securities Rulemaking Board (MSRB), the SEC also works with other federal agencies, state securities regulators, international securities agencies, and law enforcement agencies.
In 1988 Executive Order 12631 established the President's Working Group on Financial Markets. The Working Group is chaired by the Secretary of the Treasury and includes the Chairman of the SEC, the Chairman of the Federal Reserve and the Chairman of the Commodity Futures Trading Commission. The goal of the Working Group is to enhance the integrity, efficiency, orderliness, and competitiveness of the financial markets while maintaining investor confidence.
The Securities Act of 1933 was originally administered by the Federal Trade Commission. The Securities Exchange Act of 1934 transferred this responsibility from the FTC to the SEC. The main mission of the FTC is to promote consumer protection and to eradicate anti-competitive business practices. The FTC regulates general business practices, while the SEC focuses on the securities markets.
The Temporary National Economic Committee was established by joint resolution of Congress 52 Stat. 705 on June 16, 1938. It was in charge of reporting to Congress on abuses of monopoly power. The committee was defunded in 1941, but its records are still under seal by order of the SEC.
The Municipal Securities Rulemaking Board (MSRB) was established in 1975 by Congress to develop rules for companies involved in underwriting and trading municipal securities. The MSRB is monitored by the SEC, but the MSRB does not have the authority to enforce its rules.
While most violations of securities laws are enforced by the SEC and the various SROs it monitors, state securities regulators can also enforce statewide securities blue sky laws. States may require securities to be registered in the state before they can be sold there. National Securities Markets Improvement Act of 1996 (NSMIA) addressed this dual system of federal-state regulation by amending Section 18 of the 1933 Act to exempt nationally traded securities from state registration, thereby pre-empting state law in this area. However, NSMIA preserves the states' anti-fraud authority over all securities traded in the state.
The SEC also works with federal and state law enforcement agencies to carry out actions against actors alleged to be in violation of the securities laws.
The SEC is a member of International Organization of Securities Commissions (IOSCO), and uses the IOSCO Multilateral Memorandum of Understanding as well as direct bilateral agreements with other countries' securities commissions to deal with cross-border misconduct in securities markets.

</doc>
<doc id="55103" url="http://en.wikipedia.org/wiki?curid=55103" title="Carnarvon National Park">
Carnarvon National Park

Carnarvon National Park is located in the Southern Brigalow Belt bioregion in Central Queensland (Australia), 593 km northwest of Brisbane. It began life as a 26,304-hectare reserve gazetted in 1932 to protect Carnarvon Gorge for its outstanding scenic values, its indigenous and non-indigenous cultural heritage, and its geological significance.
Rocks and landscapes.
Situated within the Central Queensland Sandstone Belt, and straddling the Great Dividing Range, Carnarvon National Park preserves and presents significant elements of Queensland's geological history including two sedimentary basins, the Bowen and the Surat, and the Buckland Volcanic Province. The youngest rocks in the area are the igneous basalt rocks of the Buckland volcanic Province, which were laid down between 35 and 27 million years ago. Since that time, water and wind have eroded the park's landscapes into a network of sandy plains, valleys, and gorges separated by basalt-capped tablelands and ranges.
The park is rich in groundwater, numerous springs. The elevated areas protected within Carnarvon National Park have high value for above-ground catchments as well. Five major river systems rise within the park's boundary: the Comet, Dawson, Maranoa, Nogoa, and Warrego. The Warrego and Maranoa lie inland of the Great Dividing Range on the northern boundary of the Murray-Darling Basin.
Flora.
Forty regional ecosystems are known to exist within the park and nine of them are listed as endangered, due to large-scale land clearing within the region. Twenty-three species of flora listed as rare and threatened (Under Queensland legislation) have been found in the park, including the iconic "Livistona nitida" (Carnarvon Fan Palm, Carnarvon Gorge section), "Cadellia pentastylis" (Ooline, Moolayember section), and "Stemmacantha australis" (Austral Cornflower, Mount Moffatt section).
Several plants occur in disjunct populations, or reach the limits of their distribution, within the Park such as the isolated colony of "Angiopteris evecta" (King Fern) found in Wards Canyon, Carnarvon Gorge. Artesian springs in the Salvator Rosa section of the park are considered amongst the most biodiverse in the state.
There are 
The macrozamia
The kings ferns And
Moss
Fauna.
Over 210 bird species have been recorded within Carnarvon National Park, along with about 60 species of mammals. This park is particularly rich in species of bats with at least twenty known to be there. The "Ornithorhyncus anatinus", the platypus, is at its western limit of habitation in Queensland within this National Park, along with most of the park's gliding possums. Carnarvon Gorge has commercial night tours that take visitors into the park in search of gliders and other nocturnal life.
At least 90 species of reptiles call this park home, over half of which are either skinks or geckoes, and 35 species have their State distributional limits here. Twenty-two species of amphibians have been found in the park, including isolated populations of "Litoria fallax" (eastern Sedgefrog) and "Adelotus brevis" (Tusked Frog).
Over ten species of fish inhabit the park's waterways, the largest of which is "Anguilla reinhardtii" (long-finned eel). The park's invertebrate fauna is thought to be extremely diverse, and at least nine species are considered to be endemic to the Carnarvon Range, including two species of dragonfly, two species of stonefly, a dobson fly, and four species of land snail.
Feral animals are present within the National Park, the ones presenting the most serious problems being brumbies and pigs. In 2007, culling of both species began by riflemen in helicopters or airplanes. In 2008 the third phase of an aerial culling of Brumbies took place, by shooting 700 horses from a helicopter, in Carnarvon National Park. Such aerial culling is a contentious issue to some members of the public. However, there is little doubt that both species cause considerable alteration to the values the park is designed to protect. Through their grazing and their repetitious patterns of movement, feral horses alter the composition of the ground cover, and this can accelerate erosion through over-grazing and excessive hoof traffic. Feral pigs are thought to be responsible for the localised extinction of the Australian brush-turkey from some areas of this National Park.
History.
Carnarvon National Park has grown significantly since its inception, and Carnarvon Gorge is now but one of its seven sections.
In expanding the National Park, the Queensland National Parks and Wildlife Service have sought to enhance the reserves catchment value and increase the diversity of regional ecosystems protected within its boundaries. The park's regional conservation importance is significant as its 298,000 hectares represents over half the total landmass of protected areas within the Southern Brigalow Belt bioregion.
Human history.
Carnarvon National Park is significant to Bidjara, Karingbal, and Kara Kara people of Central Queensland. The park contains many reminders of indigenous cultural connection in rock art sites, burial places and occupation sites. Kenniff Cave, in the Mount Moffatt section, was the first Australian archaeological site to return carbon dates on occupational evidence that pushed human occupation of the continent into the Late Pleistocene at 19,500 years before present. Prior to D.J. Mulvaney's excavation of Kenniff Cave, it was thought that Australia had only been occupied during the Holocene, less than 10,000 years before present.
The indigenous stencil artists of Central Queensland, such as those who created sites such as the Art Gallery and Cathedral Cave in Carnarvon Gorge, are regarded by some researchers as the best in the world. It appears they developed complex stencilling techniques that have not been replicated elsewhere. Only one full adult body stencil is known to exist in the world; it can be seen publicly at the Tombs site in the Mount Moffatt section of the park. It is the largest known stencil, and a good example of the heights to which this form of human expression was taken in Central Queensland.
Contemporary indigenous culture in the park is much changed from that of pre-colonial Central Queensland; however strong Indigenous links to the landscapes within Carnarvon National Park are maintained through traditional owner involvement in the protection and preservation of the Park's cultural sites.
The first European to traverse the future park was Thomas Mitchell, in the 1840s. He named the Carnarvon Range after a location in Wales. Settlers followed in the footsteps of the explorers, lured by reports of the region's permanent water. Altercations with local Indigenous groups soon broke out and escalated into a state of mutual aggression that was maintained until the 1870s.
The remoteness of the area during early settlement attracted some interesting local characters, some of whom came to the area to avoid unwanted official scrutiny. The Ward brothers hunted fur in the Carnarvons year round at a time when there were restricted open seasons, and the Kenniff brothers (Kenniff Cave's namesakes) became notorious local horse thieves, and later murderers.
Today, tourism, recreation, and conservation are the main human activities conducted on the park. The most popular section of the park is the Carnarvon Gorge section which receives an estimated 65,000 visitors per year. Mount Moffatt is the next most visited section, followed by Salvator Rosa and Ka Ka Mundi. The remaining sections of the park receive virtually no visitation at all, and are consequently high in wilderness values.
Carnarvon National Park offers a variety of recreational activities including four-wheel driving, wildlife watching, hiking along maintained tracks, and bush walking into remote areas. A ninety-kilometre-long trail is currently underway that will allow bush walkers to circumnavigate Carnarvon Gorge in around five days.
Access.
The Carnarvon Gorge section is accessible from either Rolleston or Injune along the Carnarvon Highway. The Mount Moffatt section is accessible from either Injune or Mitchell. The Salvator Rosa and Ka Ka Mundi sections are accessible via the Tambo Road from either Tambo or Springsure.

</doc>
<doc id="55104" url="http://en.wikipedia.org/wiki?curid=55104" title="Pierre Schaeffer">
Pierre Schaeffer

Pierre Henri Marie Schaeffer ( , ]; 14 August 1910 – 19 August 1995) was a French composer, writer, broadcaster, engineer, musicologist and acoustician. His innovative work in both the sciences—particularly communications and acoustics—and the various arts of music, literature and radio presentation after the end of World War II, as well as his anti-nuclear activism and cultural criticism garnered him widespread recognition in his lifetime.
Amongst the vast range of works and projects he undertook, Schaeffer is most widely and currently recognized for his accomplishments in electronic and experimental music, at the core of which stands his role as the chief developer of a unique and early form of avant-garde music known as musique concrète. The genre emerged in Europe from the utilization of new music technology developed in the post-Nazi Germany era, following the advance of electroacoustic and acousmatic music.
Schaeffer's writings (which include written and radio-narrated essays, biographies, short novels, a number of musical treatises and several plays) are often oriented towards his development of the genre, as well as the theoretics and philosophy of music in general.
Today, Schaeffer is considered one of the most influential experimental, electroacoustic and subsequently electronic musicians, having been the first composer to utilize a number of contemporary recording and sampling techniques that are now used worldwide by nearly all record production companies. His collaborative endeavors are considered milestones in the histories of electronic and experimental music.
Life.
Early life and education.
Schaeffer was born in Nancy in 1910. His parents were both musicians (his father a violinist; his mother, a singer), and at first it seemed that Pierre would also take on music as a career. However his parents discouraged his musical pursuits from childhood and had him educated in engineering. He studied at several universities in this inclination, the first of which was Lycée Saint-Sigisbert located in his hometown of Nancy. Afterwards he moved westwards in 1929 to the École Polytechnique in Paris and finally completed his education in the capital at the École supérieure d'électricité, in 1934.
Schaeffer received a diploma in radio broadcasting from the École Polytechnique. He may have also received a similar qualification from the École nationale supérieure des télécommunications, although it is not verifiable as to whether or not he ever actually attended this university.
First experimentations and work in broadcasting and engineering; marriage and fatherhood.
Later in 1934 Schaeffer entered his first employment as an engineer, briefly working in telecommunications in Strasbourg. In 1935 he began a relationship with a woman named Elisabeth Schmitt, and later in the year married her and with her had his first child, Marie-Claire Schaeffer. He and his new family then officially relocated to Paris where he joined the Radiodiffusion Française (now called Radiodiffusion-Télévision Française; French for "French Radio and Television Broadcasting") in 1936 and began his work in radio broadcasting and presentation. It was there that he began to move away from his initial interests in telecommunications and to pursue music instead, combining his abilities as an engineer with his passion for sound. In his work at the station, Schaeffer experimented with records and an assortment of other devices—the sounds they made and the applications of those sounds—after convincing the radio station's management to allow him to use their equipment. This period of experimentation was significant for Schaeffer's development, bringing forward many fundamental questions he had on the limits of modern musical expression.
In these experiments, Pierre tried playing sounds backwards, slowing them down, speeding them up and juxtaposing them with other sounds, all techniques which were virtually unknown at that time. He had begun working with new contemporaries whom he had met through RTF, and as such his experimentation deepened. Schaeffer's work gradually became more avant-garde, as he challenged traditional musical style with the use of various devices and practices. A unique variety of electronic instruments—ones which Schaeffer and his colleagues created, using their own engineering skills—came into play in his work, like the chromatic, sliding and universal phonogenes, Francois Bayle's Acousmonium and a host of other devices such as gramaphones and some of the earliest tape recorders.
Beginnings of writing career.
In 1938 Schaeffer began his career as a writer, penning various articles and essays for the "Revue Musicale", a French journal of music. His first column, "Basic Truths", provided a critical examination of musical aspects of the time.
A known ardent Catholic, Schaeffer began to write minor religiously-based pieces, and in the same year as his "Basic Truths" he published his first novel: "Chlothar Nicole" — a short Christian novel.
Club d'essai and the origin of musique concrète.
By that time in his life, Schaeffer had co-founded "La Jeune France", which had interests in theatre and the visual arts, as well as in music and certain aspects of mysticism. In 1942, he created the "Studio d'Essai" (later known as the "Club d'Essai"), which played a role in the activities of the French resistance during World War II, and later became a center of musical activity. It was from "d'Essai" that he successfully recorded his first work, which itself appeared on "Dix ans d'essais radiophoniques du Studio au Club d'Essai: 1942–1952", a compilation of his personal "concrète", along with many other artists' experimental pieces, released later in his life—1953. The compilation has since become valued as a notable publication of the experimental music genre.
With the rise of nuclear power after World War II, Schaeffer became a notable activist in the anti-nuclear movement, one of the main factors associated with his personal life other than his work in the field of music.
Groupe de Recherche de Musique Concrète.
In 1949, Schaeffer met the percussionist-composer Pierre Henry, with whom he collaborated on many different musical compositions, and in 1951, he founded the "Groupe de Recherche de Musique Concrète" (GRMC) in the French Radio Institution. This gave him a new studio, which included a tape recorder. This was a significant development for Schaeffer, who previously had to work with phonographs and turntables to produce music. Schaeffer is generally acknowledged as being the first composer to make music using magnetic tape. His continued experimentation led him to publish "À la Recherche d'une Musique Concrète" (French for ""In Search of a Concrete Music") in 1952, which was a summation of his working methods up to that point. His only opera, "Orphée 53" ("Orpheus 53""), premiered in 1953.
Schaeffer left the GRMC in 1953 and reformed the group in 1958 as the "Groupe de Recherche Musicale[s]" (GRM) (at first without "s", then with "s"), where he briefly mentored the young Jean Michel Jarre, among other students. His last ""etude" ("study") came in 1959: the "Study of Objects"" ("Etudes aux Objets").
In 1954 Schaeffer founded traditional music label Ocora ("Office de Coopération Radiophonique") alongside composer, pianist and musicologist Charles Duvelle, with a worldwide coverage in order to preserve African rural soundscapes. Ocora also served as a facility to train technicians in African national broadcasting services. Today, it is still run by Duvelle.
In 1988, Schaeffer appeared in a New York Times article on the 1988 Spitak earthquake. Schaeffer had led a 498-member rescue team in Leninakan to help find survivors in the aftermath of the quake.
Later life and death.
Schaeffer became an associate professor at the Paris Conservatoire from 1968 to 1980 after creating a "class of fundamental music and application to the audiovisual." He suffered from Alzheimer's disease later in his life, and died from the condition in Aix-en-Provence in 1995. He was 85 years old. He is burried in Delincourt in the very nice and green Vexin region (55 minutes from Paris) where he used to have his countryside property.
Schaeffer was thereafter remembered by many of his colleagues with the title, "Musician of Sounds".
Legacy.
Musique concrète.
The term musique concrète (French for "real music", literally "concrete music"), was coined by Schaeffer in 1948. Schaeffer believed traditionally classical (or as he called it, "serious") music begins as an abstraction (musical notation) that is later produced as audible music. Musique concrète, by contrast, strives to start with the "concrete" sounds that emanate from base phenomena and then abstracts them into a composition. The term musique concrète is then, in essence, the breaking down of the structured production of traditional instruments, harmony, rhythm, and even music theory itself, in an attempt to reconstruct music from the bottom up.
From the contemporary point of view, the importance of Schaeffer's musique concrète is threefold. He developed the concept of including any and all sounds into the vocabulary of music. At first he concentrated on working with sounds other than those produced by traditional musical instruments. Later on, he found it was possible to remove the familiarity of musical instrument sounds and abstract them further by techniques such as removing the attack of the recorded sound. He was among the first musicians to manipulate recorded sound for the purpose of using it in conjunction with other sounds in order to compose a musical piece. Techniques such as tape looping and tape splicing were used in his research, often comparing to sound collage. The advent of Schaeffer's manipulation of recorded sound became possible only with technologies that were developed after World War II had ended in Europe. His work is recognized today as an essential precursor to contemporary sampling practices. Schaeffer was among the first to use recording technology in a creative and specifically musical way, harnessing the power of electronic and experimental instruments in a manner similar to Luigi Russolo, whom he admired and from whose work he drew inspiration.
Furthermore, he emphasized the importance of "playing" (in his terms, "jeu") in the creation of music. Schaeffer's idea of "jeu" comes from the French verb "jouer", which carries the same double meaning as the English verb play: 'to enjoy oneself by interacting with one's surroundings', as well as 'to operate a musical instrument'. This notion is at the core of the concept of musique concrète, and reflects on freely improvised sound, or perhaps more specifically electroacoustic improvisation, from the standpoint of Schaeffer's work and research.
Influences on music.
Pierre's aforementioned student in GRM, Jean Michel Jarre, went on to great international success in his own musical career. Jarre's 1997 album, Oxygene 7-13, is dedicated to Schaeffer. Pierre Henry also made a tribute to the man, composing his "Écho d'Orphée, Pour P. Schaeffer" alongside him for Schaeffer's last work and second compilation, "L'Œuvre Musicale". His other notable pupils include Joanna Bruzdowicz, Bernard Parmegiani, Micheline Coulombe Saint-Marcoux, Armando Santiago, Elzbieta Sikora.
Many rap albums, such as "It Takes A Nation of Millions To Hold Us Back" by Public Enemy and "3 Feet High And Rising" by De La Soul take ordinary sounds and use them to create a finished product.
Research legacy.
The writers Martial Robert and Carlos Palombini have mentioned Schaeffer frequently in their works, and have penned a number of books on or referring to his life and legacy. Schaeffer being a writer himself, he coauthored several works with a number of his colleagues, such as Sophie Brunet, Marc Pierret and Michel Chion, among others. Today Schaeffer's work is still being published.
Many of Schaeffer's works have become rarities. As recently as 2006 a coauthored work of his, "Sur les traces de Pierre Schaeffer", was published post-mortem.
Other.
Today, in his honor, the Qwartz Electronic Music Awards has named several of its past events after Schaeffer. Pierre himself was a prize winner at the awards more than once.
Works.
Music.
All of Schaeffer's musical compositions ("concrète" or otherwise) were recorded before the advent of the CD, either on cassettes or a more archaic form of magnetic tape (therefore the term "discography" cannot be appropriately used here; rather his music in general). Mass-production for his work was limited at best, and each piece was, by Schaeffer's terms, intended to be released foremost as an exposé to the masses of what he believed was a new and somewhat revolutionizing form of music. The original production of his marketed work was done by the "Groupe de Recherches Musicales" (a.k.a. GRM; now owned and operated by INA or the "Institut national de l'audiovisuel"), the company which he initially had formed around his creations. Other music was broadcast live (Pierre himself being notable on French radio at the time) and/or done in live "concert". Some individual tracks even found their way into the use of other artists, with Pierre's work being fronted in mime performances and ballets. Now after his death, various musical production companies, such as "Disques Adès" and "Phonurgia Nova" have been given rights to distribute his work.
Below is a list of Schaeffer's musical works, showing his compositions and the year(s) they were recorded.
Broadcast narratives.
Apart from his published and publicized music, Schaeffer conducted several musical (and specifically musique concrète-related) presentations via French radio. Although these broadcasts contained musical pieces by Schaeffer they cannot be adequately described as part of his main line of musical output. This is because the radio "essays", as they were appropriately named, were mainly narration on Schaeffer's musical theories philosophies rather than compositions in and of themselves.
Schaeffer's radio narratives include the following:
Selected writings.
Schaeffer's literary works span a range of genres, both in terms of fiction and non-fiction. He predominantly wrote treatises and essays, but also penned a film review and two plays. An ardent Catholic, Schaeffer wrote "Chlothar Nicole" (French: "Clotaire Nicole"; published 1938)—a Christian novel or short story—and "Tobias" (French: "Tobie"; published 1939) a religiously-based play.

</doc>
<doc id="55105" url="http://en.wikipedia.org/wiki?curid=55105" title="World Brain">
World Brain

World Brain is a collection of essays and addresses by the English science fiction pioneer, social reformer, evolutionary biologist and historian H. G. Wells, dating from the period of 1936–38. Throughout the book, Wells describes his vision of the World Brain: a new, free, synthetic, authoritative, permanent "World Encyclopaedia" that could help world citizens make the best use of universal information resources and make the best contribution to world peace.
Development of the idea.
World Encyclopedia.
The Wellsian dream of a World Brain was first expressed in a lecture delivered at the , Weekly Evening Meeting, Friday, 20 November 1936. He began with his motivation:
 My particular line of country has always been generalization of synthesis. I dislike isolated events and disconnected details. I really hate statements, views, prejudices and beliefs that jump at you suddenly out of mid-air. I like my world as coherent and consistent as possible. So far at any rate my temperament is that of a scientific man. And that is why I have spent a few score thousand hours of my particular allotment of vitality in making outlines of history, short histories of the world, general accounts of the science of life, attempts to bring economic, financial and social life into one conspectus and even, still more desperate, struggles to estimate the possible consequences of this or that set of operating causes upon the future of mankind. All these attempts had profound and conspicuous faults and weaknesses; even my friends are apt to mention them with an apologetic smile; presumptuous and preposterous they were, I admit, but I look back upon them, completely unabashed. Somebody had to break the ice. Somebody had to try out such summaries on the general mind. My reply to the superior critic has always been ... "Damn you, do it better." (pp. 3–4)
He wished the world to be such a whole "as coherent and consistent as possible". He wished that wise world citizens would ensure world peace. He was a communalist and contextualist and ended his lecture as follows:
 [W]hat I am saying ... is this, that without a World Encyclopaedia to hold men's minds together in something like a common interpretation of reality, there is no hope whatever of anything but an accidental and transitory alleviation of any of our world troubles. (pp. 34–5)
The Brain Organization of the Modern World.
This lecture lays out Wells's vision for "a sort of mental clearing house for the mind, a depot where knowledge and ideas are received, sorted, summarized, digested, clarified and compared". Wells felt that technological advances such as microfilm could be used towards this end so that "any student, in any part of the world, will be able to sit with his projector in his own study at his or her convenience to examine "any" book, "any" document, in an exact replica".
A Permanent World Encyclopedia.
In this essay, Wells explains how then-current encyclopaedias failed to adapt to both the growing increase in recorded knowledge and the expansion of people requiring information that was accurate and readily accessible. He asserted that these 19th-century encyclopaedias continued to follow the 18th-century pattern, organisation and scale. "Our contemporary encyclopedias are still in the coach-and-horse phase of development," he argued, "rather than in the phase of the automobile and the aeroplane."
Wells saw the potential for world-altering impacts this technology could bring. He felt that the creation of the encyclopaedia could bring about the peaceful days of the past, "with a common understanding and the conception of a common purpose, and of a commonwealth such as now we hardly dream of".
Influence of Wells's World Brain idea.
1930s: World Congress of Universal Documentation.
One of the stated goals of this Congress, held in Paris, France, in 1937, was to discuss ideas and methods for implementing Wells's ideas of the World Brain. Wells himself gave a lecture at the Congress.
1960s: The World Brain as a Supercomputer.
From World Library to World Brain.
In his 1962 book "Profiles of the Future", Arthur C. Clarke predicted that the construction of what H. G. Wells called the World Brain would take place in two stages. He identified the first stage as the construction of the "World Library", which is basically Wells's concept of a universal encyclopaedia accessible to everyone from their home on computer terminals. He predicted this phase would be established (at least in the developed countries) by the year 2000. The second stage, the "World Brain", would be a superintelligent artificially intelligent supercomputer that humans would be able to mutually interact with to solve various world problems. The "World Library" would be incorporated into the "World Brain" as a subsection of it. He suggested that this supercomputer should be installed in the former war rooms of the United States and the Soviet Union once the superpowers had matured enough to agree to co-operate rather than conflict with each other. Clarke predicted the construction of the "World Brain" would be completed by the year 2100.
1990s: World Wide Web of documents.
World Wide Web as a World Brain.
Brian R. Gaines in his "Convergence to the Information Highway", sees the World Wide Web as an extension of the "World Brain" that individuals can access using personal computers. Francis Heylighen, Joel de Rosnay and Ben Goertzel envisaged the further development of the World Wide Web into a Global brain, i.e. an intelligent network of people and computers at the planetary level. The difference between "global brain" and "world brain" is that the latter, as envisaged by Wells, is centrally controlled, while the former is fully decentralised and self-organizing.
Wikipedia as a World Brain.
A number of commentators have suggested that Wikipedia represents the World Brain as described by Wells.

</doc>
<doc id="55106" url="http://en.wikipedia.org/wiki?curid=55106" title="LZ 129 Hindenburg">
LZ 129 Hindenburg

LZ 129 "Hindenburg" (Luftschiff Zeppelin #129; Registration: D-LZ 129) was a large German commercial passenger-carrying rigid airship, the lead ship of the "Hindenburg" class, the longest class of flying machine and the largest airship by envelope volume. It was designed and built by the Zeppelin Company ("Luftschiffbau Zeppelin GmbH") on the shores of Lake Constance in Friedrichshafen and was operated by the German Zeppelin Airline Company ("Deutsche Zeppelin-Reederei"). The airship flew from March 1936 until it was destroyed by fire 14 months later on May 6, 1937, at the end of the first North American transatlantic journey of its second season of service. Thirty-six people died in the accident, which occurred while landing at Lakehurst Naval Air Station in Manchester Township, New Jersey, United States. This was the last of the great airship disasters; it was preceded by the crashes of the British R38 in 1921 (44 dead), the US airship Roma in 1922 (34 dead), the French Dixmude in 1923 (52 dead), the British R101 in 1930 (48 dead), and the USS "Akron" in 1933 (73 dead).
"Hindenburg" was named after the late Field Marshal Paul von Hindenburg, President of Germany from 1925 until his death in 1934.
Design and development.
The "Hindenburg" had a duralumin structure, incorporating 15 Ferris wheel-like bulkheads along its length, with 16 cotton gas bags fitted between them. The bulkheads were braced to each other by longitudinal girders placed around their circumferences. The airship's outer skin was of cotton doped with a mixture of reflective materials intended to protect the gas bags within from radiation, both ultraviolet (which would damage them) and infrared (which might cause them to overheat). The gas cells were made by a new method pioneered by Goodyear using multiple layers of gelatinized latex rather than the previous goldbeater's skins. In 1931 the Zeppelin Company purchased 5000 kg of duralumin salvaged from the wreckage of the October 1930 crash of the British airship R101, which might have been re-cast and used in the construction of the "Hindenburg".
The interior furnishings of the "Hindenburg" were designed by Fritz August Breuhaus, whose design experience included Pullman coaches, ocean liners, and warships of the German Navy. The upper "A" Deck contained small passenger quarters in the middle flanked by large public rooms: a dining room to port and a lounge and writing room to starboard. Paintings on the dining room walls portrayed the "Graf Zeppelin"‍ '​s trips to South America. A stylized world map covered the wall of the lounge. Long slanted windows ran the length of both decks. The passengers were expected to spend most of their time in the public areas, rather than their cramped cabins.
The lower "B" Deck contained washrooms, a mess hall for the crew, and a smoking lounge. Harold G. Dick, an American representative from the Goodyear Zeppelin Company, recalled "The only entrance to the smoking room, which was pressurized to prevent the admission of any leaking hydrogen, was via the bar, which had a swiveling air lock door, and all departing passengers were scrutinized by the bar steward to make sure they were not carrying out a lit cigarette or pipe."
Use of hydrogen instead of helium.
Helium was initially selected for the lifting gas because it was the safest to use in airships, as it is not flammable. At the time, however, helium was also relatively rare and extremely expensive as the gas was only available as a byproduct of mined natural gas reserves found in the United States. Hydrogen, by comparison, could be cheaply produced by any industrialized nation and being lighter than helium also provided more lift. Because of its expense and rarity, American rigid airships using helium were forced to conserve the gas at all costs and this hampered their operation.
Despite a U.S. ban on the export of helium under the Helium Control Act of 1927, the Germans designed the airship to use the far safer gas in the belief that they could convince the US government to license its export. When the designers learned that the National Munitions Control Board would refuse to lift the export ban, they were forced to re-engineer the Hindenburg to use hydrogen for lift. Despite the danger of using flammable hydrogen, no alternative lighter-than-air gases could provide sufficient lift. One beneficial side effect of employing hydrogen was that more passenger cabins could be added. The Germans' long history of flying hydrogen-filled passenger airships without a single injury or fatality engendered a widely held belief they had mastered the safe use of hydrogen. The "Hindenburg"‍ '​s first season performance appeared to demonstrate this.
Operational history.
Launching and trial flights.
Five years after construction began in 1931, the "Hindenburg" made its maiden test flight from the Zeppelin dockyards at Friedrichshafen on March 4, 1936, with 87 passengers and crew aboard. These included the Zeppelin Company chairman, Dr. Hugo Eckener, as commander, former World War I Zeppelin commander Lt. Col. Joachim Breithaupt representing the German Air Ministry, the Zeppelin company's eight airship captains, 47 other crew members, and 30 dockyard employees who flew as passengers. Although the name "Hindenburg" had been quietly selected by Eckener over a year earlier, only the airship's formal registration number (D-LZ129) and the five Olympic rings (promoting the 1936 Summer Olympics to be held in Berlin that August) were displayed on the hull during its six trial flights. As the airship passed over Munich on its second trial flight the next afternoon, that city's Lord Mayor, Karl Fiehler, asked Eckener by radio the LZ129's name, to which he replied "Hindenburg".
Although the name "Hindenburg" lettered in 6 ft red script was added to its hull three weeks later, no formal naming ceremony for the airship was ever held.
The airship was operated commercially by the Deutsche Zeppelin Reederei GmbH (DZR), which had been established by Hermann Göring in March 1935 to increase Nazi influence over zeppelin operations. The DZR was jointly owned by the Luftschiffbau Zeppelin (the airship's builder), the Reichsluftfahrtministerium (German Air Ministry), and Deutsche Lufthansa A.G. (Germany's national airline at that time), and also operated the LZ 127 "Graf Zeppelin" during its last two years of commercial service to South America from 1935 to 1937. The "Hindenburg" and its sister ship, the LZ 130 "Graf Zeppelin II" (launched in September 1938), were the only two airships ever purpose-built for regular commercial transatlantic passenger operations, although the latter never entered passenger service before being scrapped in 1940.
After a total of six trial flights made over a three-week period from the Zeppelin dockyards where the airship had been built, the "Hindenburg" was ready for its formal public debut with a 4,100-mile (6,598 km) propaganda flight around Germany ("Die Deutschlandfahrt") made jointly with the "Graf Zeppelin" from March 26 to 29. This was to be followed by its first commercial passenger flight, a four-day transatlantic voyage to Rio de Janeiro that departed from the Friedrichshafen Airport in nearby Löwenthal on March 31. After again departing from Löwenthal on May 6 on its first of ten round trips to North America made in 1936, all subsequent transatlantic operations flown by the "Hindenburg" to both North and South America originated at the airport at Frankfurt am Main.
"Die Deutschlandfahrt".
Although designed and built for commercial transatlantic passenger, air freight, and mail service, at the behest of the Reich Ministry for Public Enlightenment and Propaganda ("Reichsministerium für Volksaufklärung und Propaganda" or "Propagandaministerium"), the "Hindenburg" was first impressed into use by the Air Ministry (its DLZ co-operator) as a vehicle for the delivery of Nazi propaganda. On March 7, 1936, ground forces of the German Reich had entered and occupied the Rhineland, a region bordering the Netherlands, Luxembourg, Belgium, and France, which had been designated in the 1920 Treaty of Versailles as a de-militarized zone established to provide a buffer between Germany and those neighboring countries.
In order to justify its remilitarization—which was also a violation of the 1925 Locarno Pact, — a "post hoc" plebiscite (or referendum) was quickly called by Hitler for March 29 to "ask the German people" to both ratify the Rhineland’s occupation by the German Army, and to approve a single party list composed exclusively of Nazi candidates to sit in the new Reichstag. The "Hindenburg" and the "Graf Zeppelin" were designated by the government as a key part of the process.
As a public relations ploy, Propaganda Minister Goebbels demanded that the Zeppelin Company make the two airships available to fly "in tandem" around Germany over the four-day period prior to the voting with a joint departure from Löwenthal on the morning of March 26. While gusty wind conditions that morning would prove to make the process of safely launching the new airship a difficult one, the "Hindenburg"‍ '​s commander, Captain Ernst Lehmann, was determined to impress the politicians, Nazi party officials, and press present at the airfield with an "on time" departure and thus proceeded with its launch despite the adverse conditions. As the massive airship began to rise under full engine power it was caught by a 35-degree crosswind gust, causing its lower vertical tail fin to strike and be dragged across the ground, resulting in significant damage to the bottom portion of the airfoil and its attached rudder.
Zeppelin Company Chairman Eckener, who had opposed the joint flight both because it politicized the airships and had forced the cancellation of an essential final endurance test for the "Hindenburg", was furious and rebuked Lehmann:
"How could you, Mr. Lehmann, order the ship to be brought out in such windy conditions? You had the best excuse in the world for postponing this idiotic flight; instead, you risk the ship, merely to avoid annoying Mr. Goebbels. Do you call this showing a sense of responsibility towards our enterprise?"
The "Graf Zeppelin", which had been hovering above the airfield waiting for the "Hindenburg" to join it, thus had to start off on the propaganda mission alone while the LZ 129 was returned to its hangar. There temporary repairs were quickly made to its empennage before joining up with the smaller airship several hours later. As millions of Germans watched from below, the two giants of the sky sailed over Germany for the next four days and three nights, dropping propaganda leaflets, blaring martial music and slogans from large loudspeakers, and broadcasting political speeches from a makeshift radio studio on board the "Hindenburg".
First commercial passenger flight.
With the completion of voting on the referendum (which the Government claimed had been approved by a "98.79% 'Yes' vote"), the "Hindenburg" returned to Löwenthal on March 29 to prepare for its first commercial passenger flight, a transatlantic passage to Rio de Janeiro scheduled to depart from there on March 31. Hugo Eckener was not to be the commander of the flight, however, but was instead relegated to being a "supervisor" with no operational control over the "Hindenburg" while Ernst Lehmann had command of the airship. To add insult to injury, Eckener learned from an Associated Press reporter upon the "Hindenburg's" arrival in Rio that Goebbels had also followed through on his month-old threat to decree that Eckener's name would "no longer be mentioned in German newspapers and periodicals" and "no pictures nor articles about him shall be printed." This action was taken because of Eckener's opposition to using the "Hindenburg" and "Graf Zeppelin" for political purposes during the "Deutschlandfahrt", and his "refusal to give a special appeal during the Reichstag election campaign endorsing Chancellor Adolf Hitler and his policies." The existence of the ban was never publicly acknowledged by Goebbels, and it was quietly lifted a month later.
On the first South America flight one of the airship's four Daimler-Benz 16-cylinder diesel engines suffered a wrist pin breakage during the outbound leg, and although repairs were made at Recife the engine could no longer deliver full power. A similar problem developed on the return journey when another engine failed off the African Gold Coast near Morocco, and as mechanics were attempting to repair it a second stalled and could not be restarted. By then running on just two of its four engines, the "Hindenburg" was in danger of drifting into the Sahara Desert, where a forced landing made without a ground crew and mooring mast available would have likely resulted in the airship having to be written off as damaged beyond repair. To avoid such a catastrophe, the crew raised the airship in search of counter-trade winds usually found above 5000 ft, well beyond the airship's pressure altitude. Unexpectedly, the crew found such a wind at the lower altitude of 3600 ft which permitted them to guide the airship safely back to Germany after getting emergency permission from France to fly a more direct route over the Rhone Valley. The nine-day flight covered 12756 mi in 203 hours and 32 minutes of flight time. All four engines were later overhauled and no further problems were encountered on later flights.
The 1936 transatlantic season.
The "Hindenburg" made 17 round trips across the Atlantic in 1936, its first and only full year of service, with ten trips to the United States and seven to Brazil. The first passenger trip across the North Atlantic left Frankfurt on 6 May with 56 crew and 50 passengers, arriving in Lakehurst on May 9. As the elevation at Rhein-Main's airfield lies at 364 ft above sea level, the airship could lift 13,200 lb more at take off there than it could from Friedrichshafen which was situated at 1,367 ft. The ten westward trips that season took 53 to 78 hours and eastward took 43 to 61 hours. The last eastward trip of the year left Lakehurst on October 10; the first North Atlantic trip of 1937 ended in the Hindenburg disaster.
In May and June 1936 the "Hindenburg" made surprise visits to England. In May the "Hindenburg" was on a flight from America to Germany when it flew low over the West Yorkshire town of Keighley. A parcel was then thrown overboard and landed in the High Street. Two boys retrieved it and found the contents to be a bouquet of carnations, a small silver cross and a letter on official note paper dated May 22, 1936. The letter read: 'To the finder of this letter, please deposit these flowers and cross on the grave of my dear brother, Lt. Franz Shulte, 1 Garde Regt, zu fuss, POW in Skipton cemetery in Keighley near Leeds. Many thanks for your kindness. John P. Shulte, the first flying priest'. The June visit was more sinister as it has been suggested by the historian Oliver Denton, in his book 'The Rose and The Swastika', that the "Hindenburg" was on a spying mission to observe the industrial heartlands of Northern England.
In July 1936 it completed a record Atlantic double crossing in five days, 19 hours and 51 minutes. Among the famous passengers was German heavyweight boxing champion Max Schmeling, who returned home on the "Hindenburg" to a hero's welcome after knocking out Joe Louis in New York on June 19, 1936. In the 1936 season the airship flew 191583 mi and carried 2,798 passengers and 160 tons of freight and mail, encouraging the Luftschiffbau Zeppelin Company to plan the expansion of its airship fleet and transatlantic service.
The airship was said to be so stable that a pen or pencil could be balanced on end atop a tablet without falling. Its launches were so smooth that passengers often missed them, believing that the airship was still docked to its mooring mast. A one way fare between Germany and the United States was US$400 (<br>{Inflation} - Amount must not have "" prefix: 400.  equivalent to US$ in 2015 using CPI inflation ); Hindenburg passengers were affluent, including public figures, entertainers, noted sportsmen, political figures, and leaders of industry.
The "Hindenburg" was used again for propaganda when it flew over the Olympic Stadium in Berlin on August 1 during the opening ceremonies of the 1936 Summer Olympic Games. Shortly before the arrival of Adolf Hitler to declare the Games open, the airship crossed low over the packed stadium while trailing the Olympic flag on a long weighted line suspended from its gondola.
During 1936 the "Hindenburg" had a Blüthner aluminium grand piano placed on board in the music salon, though the instrument was removed after the first year to save weight. Over the winter of 1936–37, several alterations were made to the airship's structures. The greater lift capacity allowed ten passenger cabins to be added, nine with two beds and one with four, increasing passenger capacity to 72. Gutters were installed to collect rain for water ballast: taking on rainwater ballast to compensate for the weight of fuel consumed during a voyage was more economical than venting hydrogen.
Another addition was an experimental aircraft hook-on trapeze similar to the one on the U.S. Navy Goodyear-Zeppelin built airships "Akron" and "Macon". This was intended to allow customs officials to be flown out to the "Hindenburg" to process passengers before landing and to retrieve mail from the ship for early delivery. Experimental hook-ons and takeoffs were attempted on March 11 and April 27, 1937, but were not very successful, owing to turbulence around the hook-up trapeze. The loss of the ship ended all prospects of further testing.
The final flight: May 3–6, 1937.
 After making the first South American flight of the 1937 season in late March, "Hindenburg" left Frankfurt for Lakehurst on the evening of May 3, on its first scheduled round trip between Europe and North America that season. Although strong headwinds slowed the crossing, the flight had otherwise proceeded routinely as it approached for a landing three days later.
The "Hindenburg's" arrival on May 6 was delayed for several hours to avoid a line of thunderstorms passing over Lakehurst, but around 7:00 pm the airship was cleared for its final approach to the Naval Air Station, which it made at an altitude of 650 ft with Captain Max Pruss at the helm. Four minutes after ground handlers grabbed hold of a pair of landing lines dropped from the nose of the ship at 7:21 pm, the "Hindenburg" suddenly burst into flames and dropped to the ground in a little over half a minute. Of the 36 passengers and 61 crew on board, 13 passengers and 22 crew died, as well as one member of the ground crew, making a total of 36 lives lost in the disaster. Herbert Morrison's commentary of the incident became a classic of audio history.
The exact location of the initial fire, its source of ignition, and the initial source of fuel remain subjects of debate. The cause of the accident has never been determined conclusively, although many hypotheses have been proposed. Sabotage theories notwithstanding, one historically prevalent scenario put forth over the years by some experts involves a combination of gas leakage and atmospheric static conditions. Escaping hydrogen gas (in this specific case from incomplete or damaged vents along the top of the vessel and especially near the rear upper tail fin) will typically burn after mixing with air and will explode when mixed with air in the right proportions. This, along with the high static collected from flying within stormy conditions could have combined to ignite the leaking gas and down the airship. In addition, a certain amount of gas may have been inexplicably lost out the top of the vessel for, at the same time, water ballast was noticeably released to slow the rate of descent. The initial explosion would therefore have been the result of the quickening fire reaching the gas bags themselves via the compromised aft-most vent at the vessel's stern. Another more recent theory involves the airship's outer covering. The silvery cloth covering contained material (such as cellulose nitrate and aluminum flakes) which Addison Bain and other experts claim are highly flammable when ignited. This theory is highly controversial and has been rejected by other researchers because the outer skin burns too slowly to account for the rapid flame propagation and hydrogen fires had previously destroyed many other airships. The duralumin framework of "Hindenburg" was salvaged and shipped back to Germany. There the scrap was recycled and used in the construction of military aircraft for the "Luftwaffe", as were the frames of "Graf Zeppelin" and "Graf Zeppelin II" when they were scrapped in 1940.
Specifications.
"Data from" "Airships: A Hindenburg and Zeppelin History site"
References.
</dl>

</doc>
<doc id="55109" url="http://en.wikipedia.org/wiki?curid=55109" title="Alpine National Park">
Alpine National Park

The Alpine National Park is a national park located in the Central Highlands and Alpine regions of Victoria, Australia. The 646000 ha national park is located northeast of Melbourne and covers much of the higher areas of the Great Dividing Range in Victoria, including Victoria's highest point, Mount Bogong at 1986 m and the associated subalpine woodland and grassland of the Bogong High Plains. The park's north-eastern boundary is along the border with New South Wales, where it abuts the Kosciuszko National Park. On 7 November 2008 the Alpine National Park was added to the Australian National Heritage List as one of eleven areas constituting the Australian Alps National Parks and Reserves.
Ecology.
Ecologically, alpine refers to areas where the environment is such that trees are unable to grow and vegetation is restricted to dwarfed shrubs, alpine grasses and ground-hugging herbs. In Victoria this is roughly those areas above 1800 m  . Below this is the sub-alpine zone, an area of open forest dominated by snow-gums, with significant areas of grasslands. This zone includes basins where cold air settles, restricting tree growth. In wetter areas these basins form Sphagnum bogs, which play an important role in the water cycle.
Water enters the alps as snow or rain. Bogs and frost hollows collect the water as snow melt and run off. A key element of these bogs is Sphagnum Moss, which acts as a sponge, absorbing up to twenty times its weight in water. These bogs then release the water over summer, ensuring creeks flow throughout most of the year maintaining the alps’ creeks and streams. The greatest risk to this system is damage to the Sphagnum bogs. Trampling by feral animals (pigs, cattle, horses, humans) reduces their ability to absorb and then release water; instead of a steady release, water flows increase significantly in spring, leading to erosion and scouring of river beds, and ceases over summer and autumn, leading to localised drought. Fire can remove riparian vegetation, also increasing run-off and erosion.
Below the sub-alpine zone is the montane zone. On the alps southern fall, this exists as wet forest and rainforest, a consequence of the higher rainfall on this side of the park. Tall forests of Alpine Ash and Mountain Ash grow in deep soils while species like Mountain Gum are found in shallower soils or drier sites. The understory is usually shrubby, with a dense ground-layer of grasses, lilies, ferns and the like.
Rainforests are areas where the canopy cover is high, greater than 70%. The tree species are often specialists, such as Myrtle Beech in Cool Temperate Rainforest and Lilly Pilly in Warm Temperate Rainforest. Rainforest species are shade tolerant and able to regenerate below an undisturbed canopy or in small gaps created when a tree falls. Rainforest often merges with the surrounding, usually damp or wet, eucalypt forests. These forests are home to a diverse bird life and many mammals, some of which are restricted to a particular ecological niche within the ecosystem. This can include particular vegetation for foraging, or the presence of older trees with their larger hollows, a requirement for some arboreal mammals and birds. Rainforest species regenerate without fire and may be intolerant to fire, while other eucalypt species require fire. Fire can also affect the breeding of some mammals. Fire in Spring, for example, is considered to put juvenile Spot-tailed Quolls at risk. The montane zone on the alps drier, northern fall consists of dry forest and woodland with eucalypt species such as stringybarks, boxes and peppermints. Dry forest and woodlands also surround the wet forests on the southern side of the alps. These forests provide habitat for a wide range of species.
Dry forest and woodland abut private land in many areas and as a consequence have been subject to clearing, modification and fragmentation. Thus, the major threat in these areas is fire management (protection of private assets is a key objective and so past fire regimes may not reflect environmental needs), weed invasion and lack of connectivity between patches.
Fauna.
The national park protects many threatened species, including the Spotted Tree Frog, She-oak Skink, Smoky mouse, Broad-toothed mouse and Mountain Pygmy-possum.
Alpine Bogs and Associated Fens have now been listed as a threatened ecological community by the Australian government.
Bushfires.
The park has been increasingly affected by bushfires with lightning strikes starting large fires in January 2003 and again in December 2006, each fire burning over 10000 km2 over a number of weeks. The largest fire previously was the Black Friday fires of 1939. While fire is a feature of most Australian ecosystems, some alpine ecosystems, such as Alpine Bogs and Fens, are susceptible due to the sensitivity of the component species. The 2003 fires created a mosaic of burnt and unburnt areas. In some areas where the 2006-07 fires burnt over the same ground, species and communities have struggled to recover. A lightning strike on the slopes of Mount Feathertop near Harrietville in January 2013 started a 35000 ha bushfire which burnt for around two months.
Agriculture.
For much of the European history of the national park, agricultural activity was conducted in the park, with quotas of cattle allowed to graze on the High Plains during summer. Australia’s alpine area was first used for grazing around the 1840s. Concerns about the environmental effects led various governments to remove grazing from parts of the alps over the next century. Grazing was temporarily halted in Mount Buffalo National Park in the 1920s and stopped altogether in 1952. Cattle were taken out of Kosciuszko National Park in NSW during the 1950s and 1960s due to concerns about the effect of grazing on water quality for the Snowy River Scheme. Grazing was also removed from Mounts Feathertop, Hotham and Bogong around this time, from around Mount Howitt in the 1980s, and from the northern Bogong High Plains, the Bluff and part of Davies Plains in the early 1990s, leaving about one third of the Alpine National Park – over 200000 ha – available for grazing. In 2005, the Victorian Government made the decision that cattle grazing would be banned in the remaining area of the Alpine National Park; although allowing grazing in adjacent state forest areas. When the Bracks Labor Victorian Government announced plans to end this grazing, the Howard coalition Federal Government floated the idea of using national cultural heritage powers to preserve grazing on the basis of the cultural place given to the mountain cattleman, notably through "The Man from Snowy River".
For a period of over five years cattle were banned from the park, a decision which angered representative bodies of the graziers. As of January 2011 a group of cattlemen was permitted by Parks Victoria to return small numbers of cattle to fenced areas in the Alpine National Park. By 2013, fuel loads and weeds in the high plains had increased significantly and the Victorian Government sought Federal Government approval to remove the bans and commence a three-year trial to reinstate alpine grazing.
Attractions.
This area is popular in summer for bushwalking, mountain biking, four wheel driving and fishing. The major drawcards are the cooler alpine weather and the stunning scenery created by the highest peaks in Victoria. Walking tracks lead to most peaks and many extended walks are possible. The Australian Alps Walking Track, which begins in Walhalla and extends 650 km north to Canberra, traverses the park. Bush camping is permitted within the park subject to Parks Victoria guidelines and seasonal restrictions.
In winter much of the area is snow-covered and only accessible on skis. Mount Hotham and Falls Creek are ski resorts adjacent to the national park from where back-country skiers journey into the park to areas such as the Bogong High Plains and Mount Bogong.
Hunting is a popular winter activity, with the park open to stalking (hunting without dogs) of Sambar deer from mid-February to mid-December.
Major peaks.
The following major peaks are located within the Alpine National Park, in order of descending elevation above sea level:

</doc>
<doc id="55111" url="http://en.wikipedia.org/wiki?curid=55111" title="Sremski Karlovci">
Sremski Karlovci

Sremski Karlovci (Serbian Cyrillic: Сремски Карловци, ]) is a town and municipality in Serbia, in the autonomous province of Vojvodina, situated on the bank of the river Danube, 8 km from Novi Sad. The population in 2011 was 8,722. The town has traditionally been known as the seat of Serbian Orthodox Church in the Habsburg Monarchy, as well as political and cultural capital of Serbian Vojvodina after the May Assembly and during the Revolution in 1848.
Name.
In Serbian, the town is known as "Sremski Karlovci" (Сремски Карловци), in Croatian as "Srijemski Karlovci", in German as "Karlowitz" or "Carlowitz", in Hungarian as "Karlóca", in Polish as "Karłowice", in Romanian as "Carloviț" and in Turkish as "Karlofça". The former Serbian name used for the town was "Karlovci" (Карловци) - it is used today as well, but unofficially.
Geography.
The town is situated in the geographical region of Syrmia, but it is part of South Bačka District. Town of Sremski Karlovci is the only settlement in municipality.
History.
Ancient, medieval and early modern history.
In ancient times, a small Roman fortress existed at this location. The town was first mentioned in historical documents in 1308 with the name "Karom". The fortress of Karom was built on the ruins of the ancient Roman one. Until 1521, the Karom was a possession of the Hungarian noble families, of which the most well known were Báthory and Morović.
Turkish military commander Bali-beg conquered Karom in 1521, and in the next 170 years, the town was part of the Ottoman Empire. The Slavic name for the town - "Karlovci", was first recorded in 1532/33. During the Ottoman rule, the town was mostly populated by Serbs, with the smaller part of population composed of Muslims. According to the Ottoman defterler from 1545, the population of Karlovci numbered 547 Christian (Serb) houses, thus it was the largest city with a Serb majority in the whole Ottoman Empire. The city also had three Orthodox churches and a monastery.
Habsburg Monarchy.
Between 16 November 1698 and 26 January 1699, the town of Karlovci was the site of a congress that ended the hostilities between the Ottoman Empire and the Holy League, a coalition of various European powers including Habsburg Monarchy, Poland, Venice and Russia; the congress produced the Treaty of Karlowitz. It was the first time a round table was used in international politics.
After this peace treaty, the town was part of the Habsburg Monarchy and was included into the Military Frontier. According to the 1702 data, the population of the town was composed of 215 Orthodox and 13 Catholic houses, while according to the 1753 data, the population of the town numbered 3,843 people, of which 3,110 were ethnic Serbs.
The town was also the spiritual, political and cultural centre of the Serbs in the Habsburg Monarchy. The Metropolitan of the Serb Orthodox Church resided in the town. To this day, the Serb Orthodox Patriarch retains the title of Metropolitan of Karlovci. The town also featured the earliest Serb (and Slavic in general) gymnasium (Serbian: "gimnazija/гимназија", French: "lycée") founded on 3 August 1791. Three years after this, an Orthodox seminary was also founded in the town: it was the second oldest Orthodox seminary in the world (after the Spiritual Academy in Kiev), and it is still in existence.
At the Serb National Assembly in Karlovci in May 1848, Serbs declared the unification of the regions of Srem, Banat, Bačka, and Baranja (including parts of the Military Frontier) into the province of Serbian Vojvodina. The first capital of Serbian Vojvodina was in Karlovci, until it was latter moved to Zemun, Veliki Bečkerek, and Temišvar. In the same time the title of the Orthodox Metropolitan of Karlovci was raised to that of Patriarch, which thus established an Orthodox Patriarchate of Karlovci that existed until 1920 when it was joined with the Metropolitanate of Belgrade to form the new Patriarchate of Serbia.
When Serbian Vojvodina was in 1849 transformed into the new province named Voivodeship of Serbia and Banat of Temeschwar, town of Karlovci was not included into this province, but was returned under the administration of the Military Frontier (Petrovaradin regiment that was part of Slavonian Krajina). With the abolishment of the Military Frontier in 1881, the town was included into Syrmia County of Croatia-Slavonia, the autonomous kingdom within Kingdom of Hungary and Austria-Hungary.
After 1918.
In 1918, the town became part of the Kingdom of Serbs, Croats and Slovenes. In the 1920s, it became the headquarters of Russian White émigrés of General Wrangel whose monument remains to this day. It was also an early home to the Holy Synod of the Russian Orthodox Church Outside Russia. (Critics labeled this church the "Karlovtsy Synod" in its early days in an attempt to belittle its importance as an international Orthodox body.)
Between 1929 and 1941, the town was part of Danube Banovina, a province of the Kingdom of Yugoslavia. During World War 2 (1941–1944), the town was occupied by the Axis Powers and it was attached to the Independent State of Croatia. During that time its name was changed to "Hrvatski Karlovci". Since the end of the war, the town has been part of the Autonomous Province of Vojvodina.
Between 1980 and 1989, Sremski Karlovci was one of the seven municipalities of Novi Sad City. Today, the municipality is not part of Novi Sad City, but a separate administrative unit of South Bačka District.
Most recently, the government of Serbia announced its decision to move the Constitutional Court of Serbia to this town as part of the national strategy for decentralization. Furthermore the government decided to make this move because of the historic importance of this town in Serbian history as well because of its relative proximity to the capital, Belgrade. The court will probably occupy the building of the magistrate some time during 2010. In this way the government plans to symbolically, amongst other things, crown the reform of the judicial system and mark the separation of the three branches of government and emphasize their mutual independence.
Ethnic groups (2002 census).
The population of the Sremski Karlovci municipality:
Politics.
Until 1989 Sremski Karlovci formed one of the urban municipalities of the city of Novi Sad. After Novi Sad merged six of its municipalities into one "Novi Sad municipality", the municipality of Sremski Karlovci held a referendum to separate from Novi Sad, and established a separate municipality independent from Novi Sad. Although Sremski Karlovci lies in Syrmia region, the municipality belongs in South Bačka District, and not in the Syrmia District, because of its close proximity to Novi Sad.
In the Serbian local elections held on 11 May 2008, Sremski Karlovci elected a new municipality parliament, ending the rule of the Serbian Radical Party in the town. Milenko Filipović, from DS (part of the For a European Sremski Karlovci coalition), was elected as the new mayor of the municipal parliament.
International relations.
Twin towns – Sister cities.
Sremski Karlovci is twinned with:

</doc>
<doc id="55112" url="http://en.wikipedia.org/wiki?curid=55112" title="Little Desert National Park">
Little Desert National Park

The Little Desert National Park is a national park in the Western District of Victoria, Australia. The 132647 ha national park is situated near Dimboola, approximately 375 km west of Melbourne and extends from the Wimmera River in the east to near Naracoorte over the South Australian border in the west.
The Little Desert National Park is divided into three sections: Western Block, Central Block and Eastern Block.
Roads within the park are only accessible by four-wheel-drive vehicles and most tracks in the Central and Western Blocks are closed from 1 June to 31 October or after wet weather because four-wheel-drives can damage the extraordinarily fragile ecosystems under wet conditions. Organised tours are available to the Eastern Block – the oldest and most accessible part of the park – from Melbourne and Dimboola, the nearest town in Victoria.
History.
The park was established in the late 1960s after the Victorian state government announced an intention to subdivide eighty thousand hectares of Crown Land in the region for agriculture. The area in question held a great deal of relatively undisturbed mallee bushland, and was rich in wildflowers and fauna, including a number of threatened species.
The Little Desert receives an annual rainfall of approximately 480 mm, though there is a gradient from 400 mm in the east to 600 mm near Naracoorte. This is about the same as the dry farming country surrounding the park, but the Little Desert has very deep sandy soils, which are much lower in essential nutrients than the ("only moderately fertile") clay soils used for agriculture. These sandy soils have extraordinarily low contents of available nutrients and hold water very poorly, reducing the availability of water to plants. Thus, farming of the area proved quite impossible until deficiencies of zinc, copper and molybdenum were identified in the 1940s.
Even after fertilizers containing these elements became available, studies made by the Victorian government during the 1950s and 1960s showed that the Little Desert was not capable of becoming productive farmland and would fetch only low prices if cleared for agriculture. Local opposition to selling the land for farming was intense, and quickly gathered support around Victoria. The Bolte Government was initially unmoved by environmental concerns. Public outrage over the proposed subdivision resulted in the responsible minister losing his safe seat in a by-election. The Little Desert debate galvanised Victoria's conservation movement into forming a peak body, the Conservation Council of Victoria and the conservative Victorian government of Henry Bolte to adopt environmental policies, such as establishing the Land Conservation Council to systematically and independently review all future public land use across the state. The architect of the Land Conservation Council was the newly appointed Minister of Lands, Conservation and Soldier Settlement, William Borthwick who supported retaining the area as a nature reserve.
Over time, the Little Desert became a national park, beginning in 1968 with the eastern third. After the region was finally investigated by the Land Conservation Council in 1986 two more blocks to the west were added, thus covering all the sandy areas up to the South Australian border.
Flora and fauna.
The vegetation of the park ranges from pure mallee heathland in the Eastern Block to cypress pine and casuarina woodlands in the moister Western Block. In the Western Block, there are large areas of seasonal swampland formed over claypans. Laterites are scattered throughout the sandy areas of the park and characterised by broombush. Brush-tailed possums and Grey kangaroos are common throughout the park, and lizards can be observed basking in the sun.
Birds.
The most famous animal in the park is the unusual Malleefowl, the only mound-building bird to live in an arid region. There is also the solitary insectivorous Southern Scrub-robin. The Little Desert has been identified by BirdLife International as an Important Bird Area (IBA) because it supports populations of Malleefowl and Diamond Firetails.

</doc>
<doc id="55115" url="http://en.wikipedia.org/wiki?curid=55115" title="Cabbage">
Cabbage

Cabbage ("Brassica oleracea" or variants) is a leafy green or purple biennial plant, grown as an annual vegetable crop for its dense-leaved heads. Closely related to other cole crops, such as broccoli, cauliflower, and brussels sprouts, it descends from "B. oleracea" var. "oleracea", a wild field cabbage. Cabbage heads generally range from 0.5 to, and can be green, purple and white. Smooth-leafed firm-headed green cabbages are the most common, with smooth-leafed red and crinkle-leafed savoy cabbages of both colors seen more rarely. It is a multi-layered vegetable. Under conditions of long sunlit days such as are found at high northern latitudes in summer, cabbages can grow much larger. Some records are discussed at the end of the history section.
It is difficult to trace the exact history of cabbage, but it was most likely domesticated somewhere in Europe before 1000 BC, although savoys were not developed until the 16th century. By the Middle Ages, it had become a prominent part of European cuisine. Cabbage heads are generally picked during the first year of the plant's life cycle, but plants intended for seed are allowed to grow a second year, and must be kept separated from other cole crops to prevent cross-pollination. Cabbage is prone to several nutrient deficiencies, as well as multiple pests, bacteria and fungal diseases.
The Food and Agriculture Organization of the United Nations (FAO) reports that world production of cabbage and other brassicas for 2011 was almost 69 million metric tons (68 million long tons; 75 million short tons). Almost half of these crops were grown in China, where Chinese cabbage is the most popular "Brassica" vegetable. Cabbages are prepared in many different ways for eating. They can be pickled, fermented for dishes such as sauerkraut, steamed, stewed, sautéed, braised, or eaten raw. Cabbage is a good source of vitamin K, vitamin C and dietary fiber. Contaminated cabbage has been linked to cases of food-borne illness in humans.
Taxonomy and etymology.
Cabbage ("Brassica oleracea" or "B. oleracea" var. "capitata", var. "tuba", var. "sabauda" or var. "acephala") is a member of the genus "Brassica" and the mustard family, Brassicaceae. Several other cruciferous vegetables (sometimes known as "cole crops") are considered cultivars of "B. oleracea", including broccoli, collard greens, brussels sprouts, kohlrabi and sprouting broccoli. All of these developed from the wild cabbage "B. oleracea" var. "oleracea", also called colewort or field cabbage. This original species evolved over thousands of years into those seen today, as selection resulted in cultivars having different characteristics, such as large heads for cabbage, large leaves for kale and thick stems with flower buds for broccoli. The varietal epithet "capitata" is derived from the Latin word for "having a head". "B. oleracea" and its derivatives have hundreds of common names throughout the world.
"Cabbage" was originally used to refer to multiple forms of "B. oleracea", including those with loose or non-existent heads. A related species, "Brassica rapa", is commonly named Chinese, napa or celery cabbage, and has many of the same uses. It is also a part of common names for several unrelated species. These include cabbage bark or cabbage tree (a member of the genus "Andira") and cabbage palms, which include several genera of palms such as "Mauritia", "Roystonea oleracea", "Acrocomia" and "Euterpe oenocarpus".
The original family name of brassicas was "Cruciferae", which derived from the flower petal pattern thought by medieval Europeans to resemble a crucifix. The word "brassica" derives from "bresic", a Celtic word for cabbage. Many European and Asiatic names for cabbage are derived from the Celto-Slavic root "cap" or "kap", meaning "head". The late Middle English word "cabbage" derives from the word "caboche" ("head"), from the Picard dialect of Old French. This in turn is a variant of the Old French "caboce". Through the centuries, "cabbage" and its derivatives have been used as slang for numerous items, occupations and activities. Cash and tobacco have both been described by the slang "cabbage", while "cabbage-head" means a fool or stupid person and "cabbaged" means to be exhausted or, vulgarly, in a vegetative state.
Description.
Cabbage seedlings have a thin taproot and cordate (heart-shaped) cotyledons. The first leaves produced are ovate (egg-shaped) with a lobed petiole. Plants are 40 – tall in their first year at the mature vegetative stage, and 1.5 – tall when flowering in the second year. Heads average between 1 and, with fast-growing, earlier-maturing varieties producing smaller heads. Most cabbages have thick, alternating leaves, with margins that range from wavy or lobed to highly dissected; some varieties have a waxy bloom on the leaves. Plants have root systems that are fibrous and shallow. About 90 percent of the root mass is in the upper 20 – of soil; some lateral roots can penetrate up to 2 m deep.
The inflorescence is an unbranched and indeterminate terminal raceme measuring 50 – tall, with flowers that are yellow or white. Each flower has four petals set in a perpendicular pattern, as well as four sepals, six stamens, and a superior ovary that is two-celled and contains a single stigma and style. Two of the six stamens have shorter filaments. The fruit is a silique that opens at maturity through dehiscence to reveal brown or black seeds that are small and round in shape. Self-pollination is impossible, and plants are cross-pollinated by insects. The initial leaves form a rosette shape comprising 7 to 15 leaves, each measuring 25 – by 20 –; after this, leaves with shorter petioles develop and heads form through the leaves cupping inward.
Many shapes, colors and leaf textures are found in various cultivated varieties of cabbage. Leaf types are generally divided between crinkled-leaf, loose-head savoys and smooth-leaf firm-head cabbages, while the color spectrum includes white and a range of greens and purples. Oblate, round and pointed shapes are found.
Cabbage has been selectively bred for head weight and morphological characteristics, frost hardiness, fast growth and storage ability. The appearance of the cabbage head has been given importance in selective breeding, with varieties being chosen for shape, color, firmness and other physical characteristics. Breeding objectives are now focused on increasing resistance to various insects and diseases and improving the nutritional content of cabbage. Scientific research into the genetic modification of "B. oleracea" crops, including cabbage, has included European Union and United States explorations of greater insect and herbicide resistance. Genetically modified "B. oleracea" crops are not currently used in commercial agriculture.
History.
Although cabbage has an extensive history, it is difficult to trace its exact origins owing to the many varieties of leafy greens classified as "brassicas". The wild ancestor of cabbage, "Brassica oleracea", originally found in Britain and continental Europe, is tolerant of salt but not encroachment by other plants and consequently inhabits rocky cliffs in cool damp coastal habitats, retaining water and nutrients in its slightly thickened, turgid leaves. According to the triangle of U theory of the evolution and relationships between "Brassica" species, "B. oleracea" and other closely related kale vegetables (cabbages, kale, broccoli, Brussels sprouts, and cauliflower) represent one of three ancestral lines from which all other brassicas originated.
Cabbage was probably domesticated later in history than Near Eastern crops such as lentils and summer wheat. Because of the wide range of crops developed from the wild "B. oleracea", multiple broadly contemporaneous domestications of cabbage may have occurred throughout Europe. Nonheading cabbages and kale were probably the first to be domesticated, before 1000 BC, by the Celts of central and western Europe.
Unidentified brassicas were part of the highly conservative unchanging Mesopotamian garden repertory.
It is believed that the ancient Egyptians did not cultivate cabbage, which is not native to the Nile valley, though a word "shaw't" in Papyrus Harris of the time of Ramesses III, has been interpreted as "cabbage". Ptolemaic Egyptians knew the cole crops as "gramb", under the influence of Greek "krambe", which had been a familiar plant to the Macedonian antecedents of the Ptolemies; By early Roman times Egyptian artisans and children were eating cabbage and turnips among a wide variety of other pulses and vegetables.
The ancient Greeks had some varieties of cabbage, as mentioned by Theophrastus, although whether they were more closely related to today's cabbage or to one of the other "Brassica" crops is unknown. The headed cabbage variety was known to Greeks as "krambe" and to Romans as "brassica" or "olus"; the open, leafy variety (kale) was known in Greek as "raphanos" and in Latin as "caulis". In the fourth century Diogenes ate nothing but cabbage and drank nothing but water, and Chrysippus of Cnidos wrote a treatise on cabbage, which Pliny knew, but has not survived. The Greeks were convinced that cabbages and grapevines were inimical, and that cabbage planted too near the vine would impart its unwelcome odor to the grapes; this Mediterranean sense of antipathy survives today.
"Brassica" was considered by some Romans a table luxury, although Lucullus considered it unfit for the senatorial table. The more traditionalist Cato the Elder, espousing a simple, Republican life, ate his cabbage cooked or raw and dressed with vinegar; he said it surpassed all other vegetables, gave directions for its medicinal use, which extended to the cabbage-eater's urine, in which infants might be rinsed. and approvingly distinguished three varieties. Pliny the Elder listed seven, including Pompeii cabbage, Cumae cabbage and Sabellian cabbage. According to Pliny, the Pompeii cabbage, which could not stand cold, is "taller, and has a thick stock near the root, but grows thicker between the leaves, these being scantier and narrower, but their tenderness is a valuable quality". The Pompeii cabbage was also mentioned by Columella in "De Re Rustica". Apicius gives several recipes for "cauliculi", tender cabbage shoots. The Greeks and Romans claimed medicinal usages for their cabbage variety that included relief from gout, headaches and the symptoms of poisonous mushroom ingestion. The antipathy towards the vine made it seem that eating cabbage would avoid drunkenness. Cabbage continued to figure in the "materia medica" of Antiquity as well as at table: in the first century AD Dioscorides mentions two kinds of coleworts with medical uses, the cultivated and the wild, and his opinions continued to be paraphrased in herbals right through the 17th century.
At the end of Antiquity cabbage is mentioned in "De observatione ciborum" ("On the Observance of Foods") of Anthemis, a Greek doctor at the court of Theodoric the Great, and cabbage appears among vegetables directed to be cultivated in the "Capitulare de villis", composed c. 771-800 that guided the governance of the royal estates of Charlemagne.
In Britain the Anglo-Saxon cultivated "cawel". When round-headed cabbages appeared in 14th-century England they were called "cabaches" and "caboches", words drawn from Old French and applied at first to refer to the ball of unopened leaves, the contemporaneous recipe that commences "Take cabbages and quarter them, and seethe them in good broth", also suggests the tightly headed cabbage.
Manuscript illuminations show the prominence of cabbage in the cuisine of the High Middle Ages, and cabbage seeds feature among the seed list of purchases for the use of King John II of France when captive in England in 1360, but cabbages were also a familiar staple of the poor: in the lean year of 1420 the "Bourgeois of Paris" noted that "poor people ate no bread, nothing but cabbages and turnips and such dishes, without any bread or salt". French naturalist Jean Ruel made what is considered the first explicit mention of head cabbage in his 1536 botanical treatise "De Natura Stirpium", referring to it as "capucos coles" ("head-coles"), Sir Anthony Ashley, 1st Baronet, did not disdain to have a cabbage at the foot of his monument in Wimborne St Giles.
In Istanbul Sultan Selim III penned a tongue-in-cheek ode to cabbage: without cabbage the halva feast was not complete. Cabbages spread from Europe into Mesopotamia and Egypt as a winter vegetable, and later followed trade routes throughout Asia and the Americas. The absence of Sanskrit or other ancient Eastern language names for cabbage suggests that it was introduced to South Asia relatively recently. In India, cabbage was one of several vegetable crops introduced by colonizing traders from Portugal, who established trade routes from the 14th to 17th centuries. Carl Peter Thunberg reported that cabbage was not yet known in Japan in 1775.
Many cabbage varieties—including some still commonly grown—were introduced in Germany, France, and the Low Countries. During the 16th century, German gardeners developed the savoy cabbage. During the 17th and 18th centuries, cabbage was a food staple in such countries as Germany, England, Ireland and Russia, and pickled cabbage was frequently seen. Sauerkraut was used by Dutch, Scandinavian and German sailors to prevent scurvy during long ship voyages.
Jacques Cartier first brought cabbage to the Americas in 1541–42, and it was probably planted by the early English colonists, despite the lack of written evidence of its existence there until the mid-17th century. By the 18th century, it was commonly planted by both colonists and native American Indians. Cabbage seeds traveled to Australia in 1788 with the First Fleet, and were planted the same year on Norfolk Island. It became a favorite vegetable of Australians by the 1830s and was frequently seen at the Sydney Markets.
There are several "Guinness Book of World Records" entries related to cabbage. These include the heaviest cabbage, at 57.61 kg, heaviest red cabbage, at 19.05 kg, longest cabbage roll, at 15.37 m, and the largest cabbage dish, at 925.4 kg. In 2012, Scott Robb of Palmer, Alaska, broke the world record for heaviest cabbage at 138.25 lbs.
Cultivation.
Cabbage is generally grown for its densely leaved heads, produced during the first year of its biennial cycle. Plants perform best when grown in well-drained soil in a location that receives full sun. Different varieties prefer different soil types, ranging from lighter sand to heavier clay, but all prefer fertile ground with a pH between 6.0 and 6.8. For optimal growth, there must be adequate levels of nitrogen in the soil, especially during the early head formation stage, and sufficient phosphorus and potassium during the early stages of expansion of the outer leaves. Temperatures between 4 and prompt the best growth, and extended periods of higher or lower temperatures may result in premature bolting (flowering). Flowering induced by periods of low temperatures (a process called vernalization) only occurs if the plant is past the juvenile period. The transition from a juvenile to adult state happens when the stem diameter is about 6 mm. Vernalization allows the plant to grow to an adequate size before flowering. In certain climates, cabbage can be planted at the beginning of the cold period and survive until a later warm period without being induced to flower, a practice that was common in the eastern US.
Plants are generally started in protected locations early in the growing season before being transplanted outside, although some are seeded directly into the ground from which they will be harvested. Seedlings typically emerge in about 4–6 days from seeds planted 0.5 in deep at a soil temperature between 20 and. Growers normally place plants 12 to apart. Closer spacing reduces the resources available to each plant (especially the amount of light) and increases the time taken to reach maturity. Some varieties of cabbage have been developed for ornamental use; these are generally called "flowering cabbage". They do not produce heads and feature purple or green outer leaves surrounding an inner grouping of smaller leaves in white, red, or pink. Early varieties of cabbage take about 70 days from planting to reach maturity, while late varieties take about 120 days. Cabbages are mature when they are firm and solid to the touch. They are harvested by cutting the stalk just below the bottom leaves with a blade. The outer leaves are trimmed, and any diseased, damaged, or necrotic leaves are removed. Delays in harvest can result in the head splitting as a result of expansion of the inner leaves and continued stem growth. Factors that contribute to reduced head weight include: growth in the compacted soils that result from no-till farming practices, drought, waterlogging, insect and disease incidence, and shading and nutrient stress caused by weeds.
When being grown for seed, cabbages must be isolated from other "B. oleracea" subspecies, including the wild varieties, by 0.5 to to prevent cross-pollination. Other "Brassica" species, such as "B. rapa", "B. juncea", "B. nigra", "B. napus" and "Raphanus sativus", do not readily cross-pollinate.
Cultivars.
There are several cultivar groups of cabbage, each including many cultivars:
Some sources only delineate three cultivars: savoy, red and white, with spring greens and green cabbage being subsumed into the latter.
Cultivation problems.
Due to its high level of nutrient requirements, cabbage is prone to nutrient deficiencies, including boron, calcium, phosphorus and potassium. There are several physiological disorders that can affect the postharvest appearance of cabbage. Internal tip burn occurs when the margins of inside leaves turn brown, but the outer leaves look normal. Necrotic spot is where there are oval sunken spots a few millimeters across that are often grouped around the midrib. In pepper spot, tiny black spots occur on the areas between the veins, which can increase during storage.
Fungal diseases include wirestem, which causes weak or dying transplants; "Fusarium" yellows, which result in stunted and twisted plants with yellow leaves; and blackleg (see "Leptosphaeria maculans"), which leads to sunken areas on stems and gray-brown spotted leaves. The fungi "Alternaria brassicae" and "A. brassicicola" cause dark leaf spots in affected plants. They are both seedborne and airborne, and typically propagate from spores in infected plant debris left on the soil surface for up to twelve weeks after harvest. "Rhizoctonia solani" causes the post-emergence disease wirestem, resulting in killed seedlings ("damping-off"), root rot or stunted growth and smaller heads.
One of the most common bacterial diseases to affect cabbage is black rot, caused by "Xanthomonas campestris", which causes chlorotic and necrotic lesions that start at the leaf margins, and wilting of plants. Clubroot, caused by the soilborne slime mold-like organism "Plasmodiophora brassicae", results in swollen, club-like roots. Downy mildew, a parasitic disease caused by the oomycete "Peronospora parasitica", produces pale leaves with white, brownish or olive mildew on the lower leaf surfaces; this is often confused with the fungal disease powdery mildew.
Pests include root-knot nematodes and cabbage maggots, which produce stunted and wilted plants with yellow leaves; aphids, which induce stunted plants with curled and yellow leaves; harlequin bugs, which cause white and yellow leaves; thrips, which lead to leaves with white-bronze spots; striped flea beetles, which riddle leaves with small holes; and caterpillars, which leave behind large, ragged holes in leaves. The caterpillar stage of the "small cabbage white butterfly" ("Pieris rapae"), commonly known in the United States as the "imported cabbage worm", is a major cabbage pest in most countries. The large white butterfly ("Pieris brassicae") is prevalent in eastern European countries. The diamondback moth ("Plutella xylostella") and the cabbage moth ("Mamestra brassicae") thrive in the higher summer temperatures of continental Europe, where they cause considerable damage to cabbage crops. In India, the diamondback moth has caused losses up to 90 percent in crops that were not treated with insecticide. Destructive soil insects include the cabbage root fly ("Delia radicum") and the cabbage maggot ("Hylemya brassicae"), whose larvae can burrow into the part of plant consumed by humans.
Planting near other members of the cabbage family, or where these plants have been placed in previous years, can prompt the spread of pests and disease. Excessive water and excessive heat can also cause cultivation problems.
Production.
The Food and Agriculture Organization of the United Nations (FAO) combines cabbage and other brassicas for reporting purposes. Total world production of all brassicas for calendar year 2012 was 70,104,972 MT. The nations with the largest production were China, which produced 47 percent of the world total, and India, which produced 12 percent. China and India used a surface area of 980000 ha and 375000 ha, respectively, to grow these crops; the total global surface area used for cabbage and related "Brassica" crops in 2012 was 2391747 ha. The largest yields were from South Korea, which harvested 71,188.6 kilograms per hectare, Ireland (68,888.9 kg/ha), and Japan (67,647.1 kg/ha).
Top ten cabbage and other brassica producersin 2012
Cabbages sold for market are generally smaller, and different varieties are used for those sold immediately upon harvest and those stored before sale. Those used for processing, especially sauerkraut, are larger and have a lower percentage of water. Both hand and mechanical harvesting are used, with hand-harvesting generally used for cabbages destined for market sales. In commercial-scale operations, hand-harvested cabbages are trimmed, sorted, and packed directly in the field to increase efficiency. Vacuum cooling rapidly refrigerates the vegetable, allowing for earlier shipping and a fresher product. Cabbage can be stored the longest at -1 to with a humidity of 90–100 percent; these conditions will result in up to six months of longevity. When stored under less ideal conditions, cabbage can still last up to four months.
Culinary use.
Cabbage consumption varies widely around the world: Russia has the highest annual per capita consumption at 20 kg, followed by Belgium at 4.7 kg, the Netherlands at 4.0 kg, and Spain at 1.9 kg. Americans consume 8.6 lbs annually per capita.
Cabbage is prepared and consumed in many ways. The simplest options include eating the vegetable raw or steaming it, though many cuisines pickle, stew, sautée or braise cabbage. Pickling is one of the most popular ways of preserving cabbage, creating dishes such as sauerkraut and kimchi, although kimchi is more often made from Chinese cabbage ("B. rapa"). Savoy cabbages are usually used in salads, while smooth-leaf types are utilized for both market sales and processing. Bean curd and cabbage is a staple of Chinese cooking, while the British dish bubble and squeak is made primarily with leftover potato and boiled cabbage and eaten with cold meat. In Poland, cabbage is one of the main food crops, and it features prominently in Polish cuisine. Sauerkraut is a frequent dish, either eaten on its own or as a stuffing for other dishes such as golabki (stuffed cabbage) and pierogi (filled pasta). Other eastern European countries, such as Hungary and Romania, also have traditional dishes that feature cabbage as a main ingredient. In India and Ethiopia, cabbage is often included in spicy salads and braises. In the United States, cabbage is used primarily for the production of coleslaw, followed by market use and sauerkraut production.
The characteristic flavor of cabbage is caused by glucosinolates, a class of sulfur-containing glucosides. Although found throughout the plant, these compounds are concentrated in the highest quantities in the seeds; lesser quantities are found in young vegetative tissue, and they decrease as the tissue ages. Cooked cabbage is often criticized for its pungent, unpleasant odor and taste. These develop when cabbage is overcooked and hydrogen sulfide gas is produced.
Nutrients and phytochemicals.
Cabbage is an excellent source of vitamin C and vitamin K, containing more than 20% of the Daily Value (DV) for each of these nutrients per serving (right table of USDA nutrient values). Cabbage is also a good source (10–19% DV) of dietary fiber, vitamin B6 and folate, with no other nutrients having significant content per 100 gram serving (table).
Basic research on cabbage phytochemicals is ongoing to discern if certain cabbage compounds may affect health or have anti-disease effects. Such compounds include sulforaphane and other glucosinolates which may stimulate the production of detoxifying enzymes during metabolism. Studies suggest that cruciferous vegetables, including cabbage, may have protective effects against colon cancer.
Purple cabbage contains anthocyanins which are under preliminary research for potential anti-carcinogenic properties. Cabbage is also a source of indole-3-carbinol, a chemical under basic research for its possible properties.
Herbal medicine.
In addition to its usual purpose as an edible vegetable, cabbage has been used historically as a medicinal herb for a variety of purported health benefits. The Ancient Greeks recommended consuming the vegetable as a laxative, and used cabbage juice as an antidote for mushroom poisoning, for eye salves, and for liniments used to help bruises heal. In Cato the Elder's work "De Agri Cultura" ("On Agriculture"), he suggested that women could prevent diseases by bathing in urine obtained from those who had frequently eaten cabbage. The ancient Roman nobleman Pliny the Elder described both culinary and medicinal properties of the vegetable, recommending it for drunkenness—both preventatively to counter the effects of alcohol, and to cure hangovers. Similarly, the Ancient Egyptians ate cooked cabbage at the beginning of meals to reduce the intoxicating effects of wine. This traditional usage persisted in European literature until the mid-20th century.
The cooling properties of the leaves were used in Britain as a treatment for trench foot in World War I, and as compresses for ulcers and breast abscesses. Accumulated scientific evidence corroborates that cabbage leaf treatment can reduce the pain and hardness of engorged breasts, and increase the duration of breast feeding. Other medicinal uses recorded in Europe folk medicine include treatments for rheumatism, sore throat, hoarseness, colic, and melancholy. In the United States, cabbage has been used as a hangover cure, to treat abscesses, to prevent sunstroke, or to cool body parts affected by fevers. The leaves have also been used to soothe sore feet and, when tied around the neck of children, to relieve croup. Both mashed cabbage and cabbage juice have been used in poultices to remove boils and treat warts, pneumonia, appendicitis, and ulcers.
Disadvantages.
Bloating.
Excessive consumption of cabbage may lead to increased intestinal gas which causes bloating and flatulence due to the trisaccharide raffinose, which the human small intestine cannot digest.
Food-borne illness.
Cabbage has been linked to outbreaks of some food-borne illnesses, including "Listeria monocytogenes" and "Clostridium botulinum". The latter toxin has been traced to pre-made, packaged coleslaw mixes, while the spores were found on whole cabbages that were otherwise acceptable in appearance. "Shigella" species are able to survive in shredded cabbage. Two outbreaks of "E. coli" in the United States have been linked to cabbage consumption. Biological risk assessments have concluded that there is the potential for further outbreaks linked to uncooked cabbage, due to contamination at many stages of the growing, harvesting and packaging processes. Contaminants from water, humans, animals and soil have the potential to be transferred to cabbage, and from there to the end consumer.
Goiter and iodine intake.
Cabbage and other cruciferous vegetables contain small amounts of thiocyanate, a compound associated with goiter formation when iodine intake is deficient.

</doc>
<doc id="55116" url="http://en.wikipedia.org/wiki?curid=55116" title="Dubrovnik">
Dubrovnik

Dubrovnik (]; Italian: "Ragusa") is a Croatian city on the Adriatic Sea, in the region of Dalmatia. It is one of the most prominent tourist destinations in the Mediterranean, a seaport and the center of Dubrovnik-Neretva County. Its total population is 42,615 (census 2011). In 1979, the city of Dubrovnik joined the UNESCO list of World Heritage Sites.
The prosperity of the city was historically based on maritime trade; as the capital of the maritime Republic of Ragusa, it achieved a high level of development, particularly during the 15th and 16th centuries, as it became notable for its wealth and skilled diplomacy.
The beginning of modern tourism is associated with the construction of the Hotel Imperial in Dubrovnik in 1897. According to CNNGo, Dubrovnik is among the 10 best preserved medieval walled cities in the world. Although it was demilitarised in the 1970s to protect it from war, in 1991, after the breakup of Yugoslavia, it was besieged by the Serb and Montenegrin soldiers gathered in still called Yugoslav People's Army (JNA) for seven months and suffered significant damage from shelling.
Name.
The historical Latin and Dalmatian name of Dubrovnik is "Ragusa" (]), or "Ragusium" in older form; it might also be related to the Albanian word "rrush" meaning "grapes".
The current name was officially adopted in 1918 after the fall of the Austro-Hungarian Empire, but was in use from the Middle Ages. It is also referred to as Dubrovnik in the Charter of Ban Kulin in 1189. See also: .
The name is from "dubrava", which means "oak grove". "dub" in many Slavic languages means "oak", compare Russian:дуб and дубрава.
History.
Origins.
Historical lore indicates that Dubrovnik was founded in the 7th century on a rocky island named Laus, which is said to have provided shelter for refugees from the nearby city of Epidaurum.
Another theory by Tibor Živković appeared in 2007, based on new archaeological excavations. New findings (a Byzantine basilica from the 8th century and parts of the city walls) contradict the traditional theory. The size of the old basilica clearly indicates that there was quite a large settlement at the time. There is also increasing support in the scientific community for the theory that major construction of Dubrovnik took place before the Common Era. This "Greek theory" has been boosted by recent findings of numerous Greek artifacts during excavations in the Port of Dubrovnik. Also, drilling below the main city road has revealed natural sand, contradicting the theory of Laus (Lausa) island.
Dr Antun Ničetić, in his book "Povijest dubrovačke luke" ("History of the Port of Dubrovnik"), expounds the theory that Dubrovnik was established by Greek sailors. A key element in this theory is the fact that ships in ancient times travelled about 45 - per day, and required a sandy shore to pull out of water for the rest period during the night. The ideal rest site would have fresh water sources in its vicinity. Dubrovnik has both, and is situated roughly halfway between the two known Greek settlements of Budva and Korčula, 95 nmi apart from each other.
Republic of Ragusa.
After the fall of the Ostrogothic Kingdom, the town came under the protection of the Byzantine Empire. Dubrovnik in those medieval centuries had a population of Latinized Illyrians. After the Crusades, Dubrovnik came under the sovereignty of Venice (1205–1358), which would give its institutions to the Dalmatian city. After a fire destroyed almost the whole city in the night of August 16, 1296, a new urban plan was developed. By the Peace Treaty of Zadar in 1358, Dubrovnik achieved relative independence as a vassal-state of the Kingdom of Hungary. During the 14th century it became the main port where Serbian Empire and Venice transacted their products.
Between the 14th century and 1808, Dubrovnik ruled itself as a free state, although it was a vassal from 1440 to 1804 of the Ottoman Empire and paid an annual tribute to its sultan. The Republic reached its peak in the 15th and 16th centuries, when its thalassocracy rivalled that of the Republic of Venice and other Italian maritime republics.
For centuries, Dubrovnik was an ally of Ancona, the other Adriatic maritime republic rival of Venice, which was the Ottoman Empire's chief rival for control of the Adriatic. This alliance enabled the two towns set on opposite sides of the Adriatic to resist attempts by the Venetians to make the Adriatic a "Venetian Bay", also said to control directly or indirectly all the Adriatic ports. Ancona and Dubrovnik developed an alternative trade route to the Venetian (Venice-Austria-Germany): starting in Dubrovnik it went on to Ancona, through Florence and ended in Flanders .
The Republic of Ragusa received its own Statutes as early as 1272, statutes which, among other things, codified Roman practice and local customs. The Statutes included prescriptions for town planning and the regulation of quarantine (for sanitary reasons).
The Republic was an early adopter of what are now regarded as modern laws and institutions: a medical service was introduced in 1301, with the first pharmacy, still operating to this day, being opened in 1317. An almshouse was opened in 1347, and the first quarantine hospital (Lazarete) was established in 1377. Slave trading was abolished in 1418, and an orphanage opened in 1432. A 20 km water supply system was constructed in 1436.
The city was ruled by the local aristocracy which was of Latin-Dalmatian extraction and formed two city councils. As usual for the time, they maintained a strict system of social classes. The republic abolished the slave trade early in the 15th century and valued liberty highly. The city successfully balanced its sovereignty between the interests of Venice and the Ottoman Empire for centuries.
The languages spoken by the people were the Romance Dalmatian and late-common Slavic. The latter started to replace Dalmatian little by little since the 11th century among the common people who inhabited the city. Italian and Venetian would become important languages of culture and trade in Dubrovnik. At the same time, Dubrovnik became a cradle of Croatian literature.
The economic wealth of the Republic was partially the result of the land it developed, but especially of seafaring trade. With the help of skilled diplomacy, Dubrovnik merchants travelled lands freely and on the sea the city had a huge fleet of merchant ships (argosy) that travelled all over the world. From these travels they founded some settlements, from India to America, and brought parts of their culture and flora home with them. One of its keys to success was not conquering, but trading and sailing under a white flag with the word Latin: "Libertas"(freedom) prominently featured on it. The flag was adopted when slave trading was abolished in 1418.
Many Conversos, Jews from Spain and Portugal, were attracted to the city. In May 1544, a ship landed there filled exclusively with Portuguese refugees, as Balthasar de Faria reported to King John. During this time there worked in the city one of the most famous cannon and bell founders of his time: Ivan Rabljanin (Magister Johannes Baptista Arbensis de la Tolle). Already in 1571 Dubrovnik sold its protectorate over some Christian settlements in other parts of the Ottoman Empire to France and Venice. At that time there was also a colony of Dubrovnik in Fes in Morocco. The bishop of Dubrovnik was a Cardinal protector in 1571. Cardinal protectors were only in 16 other countries, too, in 1571, namely in France, Spain, Austria, Portugal, Poland, England, Scotland, Ireland, Naples, Sicily, Sardinia, Savoy, Lucca, Greece, Illyria, Armenia and Lebanon.
The Republic gradually declined after a crisis in Mediterranean shipping and the catastrophic earthquake of 1667 killed over 5,000 citizens and levelled most of the public buildings, ruining the well-being of the Republic. In 1699, the Republic sold two mainland patches of its territory to the Ottomans in order to avoid being caught in the clash with advancing Venetian forces. Today this strip of land belongs to Bosnia and Herzegovina and is that country's only direct access to the Adriatic. A highlight of Dubrovnik's diplomacy was the involvement in the American Revolution.
In 1806, the city surrendered to the Napoleonic army, as that was the only way to end a month-long siege by the Russian-Montenegrin fleets (during which 3,000 cannonballs fell on the city). At first, Napoleon demanded only free passage for his troops, promising not to occupy the territory and stressing that the French were friends of Dubrovnik. Later, however, French forces blockaded the harbours, forcing the government to give in and let French troops enter the city. On this day, all flags and coats of arms above the city walls were painted black as a sign of mourning. In 1808, Marshal Auguste de Marmont abolished the republic and integrated its territory first into Napoleon's Kingdom of Italy and later into the Illyrian provinces under French rule. This was to last until the 28th January 1814 when the city surrendered to Captain Sir William Hoste leading a body of British and Austrian troops who were besieging the fortress.
Languages.
The official language until 1472 was Latin. Later, the Senate of the Republic decided that the official language of the Republic would be the Dubrovnik dialect of the Romance Dalmatian language, and forbade the use of the Slavic language in senatorial debate. "The Gospari" (the Aristocracy) held on to their language for many centuries, while it slowly disappeared.
Although the Latin language was in official use, inhabitants of the republic were mostly native speakers of Slavic languages (as confirmed by count Pyotr Andreyevich Tolstoy in 1698, when he noted "In Dalmatia ... Ragusans ... call themselves Croats"). The Dalmatian dialect was also spoken in the city.
The Italian language as spoken in the republic was heavily influenced by the Venetian language and the Tuscan dialect. Italian took root among the Dalmatian Romance-speaking merchant upper classes, as a result of Venetian influence.
Austrian rule.
When the Habsburg Empire annexed these provinces after the 1815 Congress of Vienna, the new authorities implemented a bureaucratic administration, established the Kingdom of Dalmatia, which had its own Sabor (Diet) or Parliament, based in the city of Zadar, and political parties such as the Autonomist Party and the People's Party. They introduced a series of modifications intended to slowly centralize the bureaucratic, tax, religious, educational, and trade structure. Unfortunately for the local residents, these steps largely failed, despite the intention of wanting to stimulate the economy. And once the personal, political and economic damage of the Napoleonic Wars had been overcome, new movements began to form in the region, calling for a political reorganization of the Adriatic along the national lines. 
The combination of these two forces—a flawed Habsburg administrative system and new national movement claiming ethnicity as the founding block toward a community—posed a particularly perplexing problem; since Dalmatia was a province ruled by the German-speaking Habsburg monarchy, with bilingual (Slavic- and Italian-speaking) elites that dominated the general population consisting of a Slavic Catholic majority (and a Slavic Orthodox minority of not more than 300 people). 
In 1815, the former Dubrovnik Government (its noble assembly) met for the last time in Ljetnikovac in Mokošica. Once again, extreme measures were taken to re-establish the Republic, but it was all in vain. After the fall of the Republic most of the aristocracy was recognized by the Austrian Empire.
In 1832, Baron Šišmundo Getaldić-Gundulić ("Sigismondo Ghetaldi-Gondola") was (1795–1860) was elected Mayor of Dubrovnik, serving for 13 years; the Austrian government granted him the title of "Baron".
Count Rafael Pucić ("Raffaele Pozza"), Dr. Jur., (1828–90) was elected for first time Podestà of Dubrovnik in the year 1869 after this was re-elected in 1872, 1875, 1882, 1884) and elected twice into the Dalmatian Council, 1870, 1876. The victory of the Nationalists in Split in 1882 strongly affected in the areas of Korčula and Dubrovnik. It was greeted by the mayor (podestà) of Dubrovnik Rafael Pucić, the National Reading Club of Dubrovnik, the Workers Association of Dubrovnik and the review "Slovinac"; by the communities of Kuna and Orebić, the latter one getting the nationalist government even before Split.
In 1889, the Serb-Catholics circle supported Baron Francesco Ghetaldi-Gondola, the candidate of the Autonomous Party, vs the candidate of Popular Party Vlaho de Giulli, in the 1890 election to the Dalmatian Diet. The following year, during the local government election, the Autonomous Party won the municipal re-election with Francesco Gondola, who died in power in 1899. The alliance won the election again on 27 May 1894. Frano Getaldić-Gundulić founded the "Società Philately" on 4 December 1890.
In 1905, the Committee for establishing electric tram service, headed by m. Luko Bunić – certainly one of the most deserving persons who contributed to the realisation of the project - was established. Other members of the Committee were: Ivo Papi, Dr. Miho Papi, Dr. Artur Saraka, Mato Šarić, Dr. Antun Pugliesi, Dr. Mato Gracić, Dr. Ivo Degiulli, Ernest Katić and Antun Milić.
Pero Čingrija (1837–1921), one of the leaders of the People's Party in Dalmatia, played the main role in the merger of the People's Party and the Party of Right into a single Croatian Party in 1905.
1918–1991.
With the fall of Austria–Hungary in 1918, the city was incorporated into the new Kingdom of Serbs, Croats, and Slovenes (later the Kingdom of Yugoslavia). Dubrovnik became one of the 33 "oblast" of the Kingdom. In 1929 Yugoslavia was divided among 9 Banovina the city became part of the Zeta Banovina. In 1939 Dubrivnik became part of the newly created Banovina of Croatia.
During World War II, Dubrovnik became part of the Nazi-puppet Independent State of Croatia, occupied by the Italian army first, and by the German army after 8 September 1943. In October 1944 Tito's partisans liberated Dubrovnik, and it became consequently part of Socialist Republic of Croatia and Socialist Federal Republic of Yugoslavia. Soon after their arrival into the city, partisans executed approximately 78 influential and well known citizens without a trial, including Catholic priests, on the nearby island of Daksa. Communist leadership during the next several years continued political prosecutions which culminated on 12 April 1947 with the capture and imprisonment of more than 90 citizens of Dubrovnik.
In 1979, the city of Dubrovnik joined the UNESCO list of World Heritage Sites.
Break-up of Yugoslavia.
In 1991 Croatia and Slovenia, which at that time were republics within Socialist Federal Republic of Yugoslavia, declared their independence. At that event, Socialist Republic of Croatia was renamed Republic of Croatia.
Despite demilitarization of the old town in early 1970s in an attempt to prevent it from ever becoming a casualty of war, following Croatia's independence in 1991, Yugoslavia's Yugoslav People's Army (JNA), by then composed primarily of Serbs, attacked the Croatian military in the city. The new Croatian government set up military outpost in the city itself. Montenegro, led by president Momir Bulatović, and prime minister Milo Đukanović, coming to power in the Anti-bureaucratic revolution and allied to Slobodan Milošević in Serbia, declared that Dubrovnik would not remain in Croatia because they claimed it historically had never been part of Croatia. This was in spite of the large Croat majority in the city and that very few Montenegrins resided there, though Serbs accounted for 6.8 percent of the population.
On October 1, 1991 Dubrovnik was attacked by JNA with a siege of Dubrovnik that lasted for seven months. The heaviest artillery attack was on December 6 with 19 people killed and 60 wounded. The number of casualties in the conflict according to Croatian Red Cross was 114 killed civilians, among them poet Milan Milišić. Foreign newspapers were criticised for placing heavier attention on the damage suffered by the old town than on human casualties. Nonetheless, the artillery attacks on Dubrovnik damaged 56% of its buildings to some degree, as the historic walled city, a UNESCO world heritage site, sustained 650 hits by artillery rounds. The Croatian Army lifted the siege in May 1992, and liberated Dubrovnik's surroundings by the end of October, but the danger of sudden attacks by the JNA lasted for another three years.
Following the end of the war, damage caused by the shelling of the Old Town was repaired. Adhering to UNESCO guidelines, repairs were performed in the original style. Most of the reconstruction work has been done between 1995 and 1999. The inflicted damage can be seen on a chart near the city gate, showing all artillery hits during the siege, and is clearly visible from high points around the city in the form of the more brightly coloured new roofs. ICTY indictments were issued for JNA generals and officers involved in the bombing.
General Pavle Strugar, who coordinated the attack on the city, was sentenced to an seven-and-a-half-year prison term by the International Criminal Tribunal for the former Yugoslavia for his role in the attack.
The 1996 Croatia USAF CT-43 crash, near Dubrovnik Airport, killed everyone on a United States Air Force jet with United States Secretary of Commerce Ron Brown, "The New York Times" Frankfurt Bureau chief Nathaniel C. Nash and 33 other people.
Heritage.
The annual Dubrovnik Summer Festival is a 45-day-long cultural event with live plays, concerts, and games. It has been awarded a Gold International Trophy for Quality (2007) by the Editorial Office in collaboration with the Trade Leaders Club.
The patron saint of the city is Sveti Vlaho (Saint Blaise), whose statues are seen around the city. He has an importance similar to that of St. Mark the Evangelist to Venice. One of the larger churches in city is named after Saint Blaise.
February 3 is the feast of Sveti Vlaho (Saint Blaise), who is the city's patron saint. Every year the city of Dubrovnik celebrates the holiday with Mass, parades, and festivities that last for several days.
The Old Town of Dubrovnik is depicted on the reverse of the Croatian 50 kuna banknote, issued in 1993 and 2002.
The city boasts of many old buildings, such as the Arboretum Trsteno, the oldest arboretum in the world, dating back to before 1492. Also, the third oldest European pharmacy is located in the city, which dates back to 1317 (and is the only one still in operation today). It is located at Little Brothers monastery in Dubrovnik.
In history, many Conversos (Marranos) were attracted to Dubrovnik, formerly a considerable seaport. In May 1544, a ship landed there filled exclusively with Portuguese refugees, as Balthasar de Faria reported to King John. Another admirer of Dubrovnik, George Bernard Shaw, visited the city in 1929 and said: "If you want to see heaven on earth, come to Dubrovnik."
In the bay of Dubrovnik is the 72-hectare wooded island of Lokrum, where according to legend, Richard the Lionheart was cast ashore after being shipwrecked in 1192. The island includes a fortress, botanical garden, monastery and naturist beach.
Among the many tourist destinations are a few beaches. Banje, Dubrovnik's main public beach, is home to the Eastwest Beach Club. There is also Copacabana Beach, a stony beach on the Lapad peninsula, named after the popular beach in Rio de Janeiro.
Dubrovnik has also been mentioned in popular film and theatre. In the film "20,000 Leagues Under the Sea" with Michael Caine, one of the characters said to have been dreaming of fairy from Dubrovnik (motive known from local legends and literature).
Important monuments.
Few of Dubrovnik's Renaissance buildings survived the earthquake of 1667 but fortunately enough remained to give an idea of the city's architectural heritage. The finest Renaissance highlight is the Sponza Palace which dates from the 16th century and is currently used to house the National Archives. The Rector's Palace is a Gothic-Renaissance structure that displays finely carved capitals and an ornate staircase. It now houses a museum. Its façade is depicted on the reverse of the Croatian 50 kuna banknote, issued in 1993 and 2002. The St. Saviour Church is another remnant of the Renaissance period, next to the much-visited Franciscan Monastery. The Franciscan monastery's library possesses 30,000 volumes, 216 incunabula, 1,500 valuable handwritten documents. Exhibits include a 15th-century silver-gilt cross and silver thurible, an 18th-century crucifix from Jerusalem, a martyrology (1541) by Bemardin Gucetic and illuminated psalters.
Dubrovnik's most beloved church is St Blaise's church, built in the 18th century in honour of Dubrovnik's patron saint. Dubrovnik's baroque Cathedral was built in the 18th century and houses an impressive Treasury with relics of Saint Blaise. The city's Dominican Monastery resembles a fortress on the outside but the interior contains an art museum and a Gothic-Romanesque church. A special treasure of the Dominican monastery is its library with 216 incunabula, numerous illustrated manuscripts, a rich archive with precious manuscripts and documents and an extensive art collection.
Walls of Dubrovnik.
A feature of Dubrovnik is its walls that run almost 2 km around the city. The walls run from four to six meters (13.2 to 19.8 feet) thick on the landward side but are much thinner on the seaward side. The system of turrets and towers were intended to protect the vulnerable city. The walls of Dubrovnik have also been a popular filming site for the fictional city of King's Landing in the HBO television series, "Game of Thrones".
Demographics.
The total population of the city is 42,615 (census 2011), in the following settlements:
The population was 42,615 in 2011, down from 49,728 in 1991 In the 2011 census, 90.34% of the population was Croat.
Transport.
Dubrovnik has an international airport of its own. It is located approximately 20 km southeast of Dubrovnik city centre, near Čilipi. Buses connect the airport with the Dubrovnik old main bus station in Gruž. In addition, a network of modern, local buses connects all Dubrovnik neighbourhoods running frequently from dawn to midnight. However, Dubrovnik, unlike Croatia's other major centres, is not accessible by rail; until 1975 Dubrovnik was connected to Mostar and Sarajevo by a narrow gauge railway (760 mm) built during the Austro-Hungarian rule of Bosnia.
The A1 highway, in use between Zagreb and Ploče, is planned to be extended all the way to Dubrovnik. Because the area around the city is disconnected from the rest of Croatian territory, the highway will either cross the Pelješac Bridge whose construction is currently stalled, or run through Neum in Bosnia and Herzegovina and continue to Dubrovnik.
Education.
Dubrovnik has a number of educational institutions. These include Dubrovnik International University, the University of Dubrovnik, a Nautical College, a Tourism College, a University Centre for Postgraduate Studies of the University of Zagreb, American College of Management and Technology, Diocesan Classical Gymnasium "Ruđer Bošković" in Dubrovnik and an Institute of History of the Croatian Academy of Sciences and Arts.
Climate.
Dubrovnik has a borderline humid subtropical ("Cfa") and Mediterranean climate ("Csa") in the Köppen climate classification, since only two summer months have less than 40 mm of rainfall, preventing it from being classified as solely humid subtropical or Mediterranean. It has hot, moderately dry summers and mild, wet winters. The Bura wind blows uncomfortably cold gusts down the Adriatic coast between October and April, and thundery conditions are common all the year round, even in summer, when they interrupt the warm, sunny days. The air temperatures can slightly vary, depending on the area or region. Typically, in July and August daytime maximum temperatures reach 28 C, and at night drop to around 23 C. More comfortable, perhaps, is the climate in Spring and Autumn when maximum temperatures are typically between 20 C and 28 C.
International relations.
Twin towns – sister cities.
Dubrovnik is twinned with:
Gallery.
Panorama.
Panoramic view of the Old Town of Dubrovnik
Panoramic view from the Old Harbour
In popular culture.
Dubrovnik is also currently being used to represent the city of King's Landing and the locations of Daenerys Targaryen in the HBO series "Game of Thrones". Locations used in filming include St. Dominic Street, Lokrum Island, The Knežev dvor and Sponza palaces, Lovrijenac (Fort of St. Lawrence), and Fort Bokar and the Minčeta tower.
Bibliography.
</dl>

</doc>
<doc id="55117" url="http://en.wikipedia.org/wiki?curid=55117" title="Juliette Binoche">
Juliette Binoche

Juliette Binoche (]; born 9 March 1964) is a French actress, artist and dancer. She has appeared in more than 40 feature films, been recipient of numerous international accolades, is a published author and has appeared on stage across the world. Coming from an artistic background, she began taking acting lessons during adolescence. After performing in several stage productions, she was propelled into the world of auteurs Jean-Luc Godard ("Hail Mary", 1985), Jacques Doillon ("Family Life", 1985) and André Téchiné, who made her a star in France with the leading role in his 1985 drama "Rendez-vous". Her sensual performance in her English-language debut "The Unbearable Lightness of Being" (1988), directed by Philip Kaufman, launched her international career.
She sparked the interest of Steven Spielberg, who offered her several parts including a role in "Jurassic Park" which she declined, choosing instead to join Krzysztof Kieślowski on the set of "" (1993), a performance for which she won the Venice Film Festival Award for Best Actress and a César. Three years later Binoche gained further acclaim in Anthony Minghella's "The English Patient" (1996), for which she was awarded an Academy Award and a BAFTA for Best Supporting Actress in addition to the Best Actress Award at the 1997 Berlin Film Festival. For her performance in Lasse Hallström's romantic comedy "Chocolat" (2000), Binoche was nominated for an Academy Award for Best Actress.
During the 2000s she maintained a successful, critically acclaimed career, alternating between French and English language roles in both mainstream and art-house productions. In 2010, she won the Best Actress Award at the Cannes Film Festival for her role in Abbas Kiarostami's "Certified Copy" making her the first actress to win the European "Best Actress triple crown" (for the Berlin, Cannes and Venice film festivals).
Throughout her career Binoche has intermittently appeared on stage, most notably in a 1998 London production of Luigi Pirandello's "Naked" and in a 2000 production of Harold Pinter's "Betrayal" on Broadway for which she was nominated for a Tony Award. In 2008 she began a world tour with a modern dance production "in-i" devised in collaboration with Akram Khan. Often referred to as "La Binoche" by the press, her other notable performances include: "Mauvais Sang" (1986), "Les Amants du Pont-Neuf" (1991), "Damage" (1992), "The Horseman on the Roof" (1995), "Code Unknown" (2000), "Caché" (2005), "Breaking and Entering" (2006), "Flight of the Red Balloon" (2007) and "Camille Claudel 1915" (2013).
Early life.
Binoche was born in Paris, the daughter of Jean-Marie Binoche, a director, actor, and sculptor, and Monique Yvette Stalens, a teacher, director, and actress. Her father, who is French, also has one eighth Portuguese-Brazilian ancestry; he was raised partly in Morocco by his French-born parents. Juliette's mother was born in Częstochowa, Poland. Binoche's maternal grandfather, Andre Stalens, was born in Poland, of Belgian (Walloon) and French descent, and Binoche's maternal grandmother, Julia Helena Młynarczyk, was of Polish origin. Both of them were actors who were born in Częstochowa; they were imprisoned at Auschwitz, because they were considered to be intellectuals by the German Nazi occupiers.
When Binoche's parents divorced in 1968, four-year-old Binoche and her sister Marion were sent to a provincial boarding school. During their teens, the Binoche sisters spent their school holidays with their maternal grandmother, not seeing either parent for months at a time. Binoche has stated that this perceived parental abandonment had a profound effect on her.
She was not particularly academic and in her teenage years she began acting at school in amateur stage productions. At 17, she directed and starred in a student production of the Eugène Ionesco play, "Exit the King". She studied acting at the "Conservatoire National Supérieur d'Art Dramatique" (CNSAD), but quit after a short time as she disliked the curriculum. In the early 1980s, she found an agent through a friend and joined a theater troupe with which she toured France, Belgium and Switzerland under the pseudonym "Juliette Adrienne". Around this time she began lessons with the famed acting coach Vera Gregh.
Her first professional screen experience was as an extra in the three part TF1 television series "Dorothée, danseuse de corde" (1983) directed by Jacques Fensten, which was followed by a similarly small role in the provincial television film "Fort bloque" directed by Pierrick Guinnard. Following this Binoche secured her first feature film appearance with a minor role in Pascal Kané's "Liberty Belle" (1983). Her role required just two days on set, but was enough to inspire Binoche to pursue a career in film.
Career.
1984–1991.
Binoche's early films would see her established as a French star of some renown. In 1983, she auditioned for the female lead in Jean-Luc Godard's' controversial "Hail Mary", a modern retelling of the Virgin birth. Godard requested a meeting with Binoche having seen a photo of her taken by her boyfriend of the time. She has said that she spent six months on the set of the film in Geneva, although her role in the final cut is contained to only a few scenes. Further supporting roles followed in a variety of French films: Annick Lanoë's "Les Nanas" was to give Binoche her most noteworthy role to date, playing opposite established stars Marie-France Pisier and Macha Meril, in a mainstream comedy. However, she has stated that the experience was not particularly memorable or influential. She gained more significant exposure in Jacques Doillon's critically acclaimed "Family Life", which cast her as the volatile teenage step-daughter of Sami Frey's central character. This film was to set the tone of her early career. Doillon has commented that in the original screenplay her character was written to be 14 years old, he was so impressed with Binoche's audition he changed the character's age to 17 to allow her take the role. In April 1985, Binoche followed this with another supporting role in Bob Decout's "Adieu Blaireau", a "policier" thriller starring Philippe Léotard and Annie Girardot. "Adieu Blaireau" failed to have much impact with critics or audiences.
It was to be later in 1985 that Binoche would fully emerge as a leading actress with her role in André Téchiné's "Rendez-vous". She was cast at short notice when Sandrine Bonnaire had to abandon the film due to a scheduling conflict. "Rendez-vous" premiered at the 1985 Cannes Film Festival, winning Best Director. The film was a sensation and Binoche became the darling of the festival. "Rendez-Vous" is the story of a provincial actress, Nina (Binoche), who arrives in Paris and embarks on a series of dysfunctional liaisons with several men, including the moody, suicidal Quentin (Lambert Wilson). However it is her collaboration with theatre director Scrutzler, played by Jean-Louis Trintignant, which comes to define Nina. In a review of "Rendez-Vous" in Film Comment, Armond White described it as "Juliette Binoche's career defining performance". In 1986, Binoche was nominated for her first César for Best Actress in a Leading Role for her performance in the film. Following "Rendez-Vous", she was unsure of what role to take next. She auditioned unsuccessfully for Yves Boisset's "Bleu comme l'enfer" and Robin Davis's "Hors la loi", but was eventually cast in "My Brother-in-law Killed My Sister" (1986) by Jacques Rouffio opposite the popular French stars Michel Serrault and Michel Piccoli. This film was a critical and commercial failure. Binoche has commented that Rouffio's film is very significant to her career as it taught her to judge roles based on the quality of the screenplay and her connection with a director, not on the reputation of other cast members. Later in 1986, she again starred opposite Michel Piccoli in Leos Carax's "Mauvais Sang". This film was a critical and commercial success, leading to Binoche's second César nomination. "Mauvais Sang" is an avant-garde thriller in which she plays Anna the vastly younger lover of Marc (Piccoli) who falls in love with Alex (Denis Lavant), a young thief. Binoche has stated that she, "discovered the camera", while shooting this film.
In August 1986, Binoche began filming Philip Kaufman's adaptation of Milan Kundera's novel "The Unbearable Lightness of Being", portraying the young and innocent Tereza. Released in 1988, this was Binoche's first English language role and was a worldwide success with critics and audiences alike Set against the USSR's invasion of Prague in 1968, the film tells the story of the relationships a Czech surgeon, Tomas (Daniel Day-Lewis), has with his wife Tereza and his lover Sabina (Lena Olin). Binoche has stated that at the time her English was very limited and that she relied on a French translation to fully grasp her role. After this success, Binoche decided to return to France rather than pursue an international career. In 1988, she filmed the lead in Pierre Pradinas's "Un tour de manège", a little-seen French film opposite François Cluzet. She has stated that her attraction to this film was that it gave her the opportunity to work with close friends and family. Pradinas is the husband of her sister Marion Stalens who was set photographer on the film and appeared in a cameo role. In the summer of 1988, Binoche returned to the stage in an acclaimed production of Anton Chekhov's "The Seagull" directed by Russian director Andrei Konchalovsky at Théâtre De L'odéon in Paris. Later that year she began work on Léos Carax's "Les Amants du Pont-Neuf". The film was beset by problems and took three years to complete, requiring investment from three producers and funds from the French government. When finally released in 1991, "Les Amants du Pont-Neuf" was a critical success. Binoche won a European Film Award as well as securing her third César nomination for her performance. In the film Binoche portrays an artist who lives rough on the famous Parisian bridge where she meets another young vagrant (Denis Lavant). This iconic part of the city becomes the backdrop for a wildly passionate love story and some of the most visually arresting images of the city ever created. The paintings featured in the film were Binoche's own work. She also designed the French poster for the film which features an ink drawing of the eponymous lovers locked in embrace. During a break in filming in 1990, Binoche spent five days shooting "Mara" for Mike Figgis, based on Henry Miller's "Quiet Days in Clichy". This 30 minute film was part of HBO's anthology series "Women & Men 2". The film became somewhat contentious when, according to Mike Figgis, HBO altered it once he had completed it. The film premiered on HBO in the U.S. on 18 August 1991.
At this point, Binoche seemed to be at a crossroads in her career. She was recognized as one of the most significant French actresses of her generation. However, the long production of "Les Amants du Pont-Neuf" had forced her to turn down several significant roles in international productions including "The Double Life of Véronique" by Krzysztof Kieślowski, Cyrano de Bergerac by Jean-Paul Rappeneau, "Night and Day" by Chantal Akerman and "Beyond the Aegean" an aborted project with Elia Kazan. Now Binoche chose to pursue an international career outside France.
1992–2000.
The 1990s saw Juliette Binoche inaugurated as a European leading lady in a series of international films that were critical and commercial successes winning Binoche much praise and numerous awards for her performances. This period saw her persona develop from that of a young gamine to a more melancholic, tragic presence. Critics suggested that many of her roles were notable for her almost passive intensity in the face of tragedy and despair. In fact Binoche has nicknamed her characters from this period as her "sorrowful sisters". Following the long shoot of "Les Amants du Pont-Neuf", Binoche relocated to London for the 1992 productions of "Emily Brontë's Wuthering Heights" and "Damage", both of which considerably enhanced her international reputation. Yet, from a professional and personal point of view, both films were significant challenges for Binoche; her casting opposite Ralph Fiennes's Heathcliff in "Wuthering Heights", instead of English actresses Helena Bonham Carter and Kate Beckinsale, was immediately contentious and drew derision from the British press, unimpressed that a uniquely English role had gone to a French actress. The film had its world premiere at the 1992 Edinburgh International Film Festival. Reviews were poor, with Binoche being cynically dubbed "Cathy Clouseau" and being derided for her "franglais" accent. Both Binoche and director Peter Kosminsky distanced themselves from the film, with Binoche refusing to do any promotion for the film or to redub it into French. "Damage", a UK and French co-production, is the story of a British conservative minister played by Jeremy Irons who embarks on a torrid affair with his son's fiancée (Binoche). Based on the novel by Josephine Hart and directed by veteran French director Louis Malle, "Damage" seemed to be the ideal international vehicle for Binoche; however the production was wrought with difficulties and dogged by rumours of serious conflict. In an on-set interview, Louis Malle stated that it was the "most difficult" film he had ever made, while Binoche commented that "the first day was one big argument". "Damage" opened in the UK late in 1992 and debuted early in 1993 on US screens. Reviews were somewhat mixed. For her performance, Juliette Binoche received her fourth César nomination.
In 1993, she appeared in Krzysztof Kieślowski's ' to much critical acclaim. The first film in a trilogy inspired by the ideals of the French republic and the colors of its flag, "Three Colors: Blue" is the story of a young woman who loses her composer husband and daughter in a car accident. Though devastated she learns to cope by rejecting her previous life in favour of conscious "nothing"; rejecting all people, belongings and emotions. "Three Colors: Blue" premiered at the 1993 Venice Film Festival, landing Binoche the Best Actress Prize. She also won a César, and a nomination for the Golden Globe. Binoche has said her inspirations for the role were her friend and coach Vernice Klier who suffered a similar tragedy, and the book "The Black Veil" by Anny Duperey which deals with the author's grief at losing her parents at a young age. Binoche made cameo appearances in the other two films in Kieślowski's trilogy, ' and "". Around this time, Steven Spielberg offered her roles in "Jurassic Park" and "Schindler's List". She turned down both parts. After the success of "Three Colors: Blue", Binoche took a short sabbatical during which she gave birth to her son Raphaël in September 1993.
In 1995, Binoche returned to the screen in a big-budget adaptation of Jean Giono's "The Horseman on the Roof" directed by Jean-Paul Rappeneau. The film was particularly significant in France as it was at the time the most expensive film in the history of French cinema. The film was a box-office success around the world and Binoche was again nominated for a César for Best Actress. This role, as a romantic heroine, was to color the direction of many of her subsequent roles in the late 1990s. In 1996, Binoche appeared in her first comedic role since "My Brother-in-Law Killed My Sister" a decade before; "A Couch in New York" was directed by Chantal Akerman and co-starred William Hurt. This screw-ball comedy tells the story of a New York psychiatrist who swaps homes with a Parisian dancer. The film was a critical and commercial failure. "Three Colors: Blue", "The Horseman on the Roof" and "A Couch in New York" all gave Binoche the opportunity to work with prestigious directors she had turned down during the prolonged shoot of "Les Amants du Pont-Neuf". Her next role would significantly reinforce her position as a bona fide international movie star, "The English Patient", based on the prize winning novel by Michael Ondaatje and directed by Anthony Minghella, was a worldwide hit. Produced by Saul Zaentz, producer of "The Unbearable Lightness of Being", the film reunited Juliette Binoche with Ralph Fiennes, Heathcliff to her Cathy four years previously. Binoche has said that the shoot on location in Tuscany and at the famed Cinecittà in Rome was among the happiest professional experiences of her career. The film, which tells the story of a badly burned, mysterious man found in the wreckage of a plane during World War II, won nine Academy Awards, including Best Supporting Actress for Juliette Binoche. With this film, she became the second French actress to win an Oscar, following Simone Signoret's win for "Room at the Top" in 1960. After this international hit, Binoche returned to France and began work opposite Daniel Auteuil on Claude Berri's "Lucie Aubrac", the true story of a French Resistance heroine. Binoche was released from the film six weeks into the shoot due to differences with Berri regarding the authenticity of his script. Binoche has described this event as being like "an earthquake" to her.
Next Juliette Binoche was reunited with director André Téchiné for "Alice et Martin" (1998), the story of a relationship between an emotionally damaged Parisian musician and her younger lover who hides a dark family secret. The film failed to find an audience in France, although it was critically acclaimed in the UK. In February 1998 Binoche made her London stage debut in a new version of Luigi Pirandello's "Clothe the Naked " retitled "Naked" and adapted by Nicolas Wright. The production, directed by Jonathan Kent, was very favorably received. Following this acclaimed performance, she returned to French screens with "Children of the Century" (1999), a big budget romantic epic, in which she played 19th-century French proto-feminist author George Sand. The film depicted Sand's affair with the poet and dandy Alfred de Musset played by Benoit Magimel. This lavish costume drama was filmed on location in Paris and Venice and featured couture costumes by the renowned fashion designer Christian Lacroix. The following year saw Binoche in four contrasting roles, each of which enhanced her reputation. "La Veuve de Saint-Pierre" (2000) by Patrice Leconte, for which she was nominated for a César for Best Actress, was a period drama which saw Binoche appear opposite Daniel Auteuil in the role of a woman who attempts to save a condemned man from the guillotine. The film won favourable reviews, particularly in the U.S. where it was nominated for a Golden Globe for Best Foreign Language Film. Next she appeared in Michael Haneke's "Code Unknown", a film which was made following Binoche's approach to the Austrian director. The film premiered in competition at the 2000 Cannes Film Festival. This critically acclaimed role was a welcome change from playing the romantic heroine in a series of costume dramas. Later that year, Binoche made her Broadway debut in an adaptation of Harold Pinter's "Betrayal" for which she was nominated for a Tony Award. Staged by the Roundabout Theatre Company and directed by David Leveaux, the production also featured Liev Schreiber and John Slattery. Back on screen, Binoche was the heroine of the Lasse Hallström film "Chocolat" from the best selling novel by Joanne Harris. For her role Binoche won a European Film Audience Award for Best Actress and was nominated for an Academy Award and a BAFTA. "Chocolat" is the story of a mysterious stranger who opens a "chocolaterie" in a conservative French village in 1959. The film was a worldwide hit.
Between 1995 and 2000, Binoche was the advertising face of the Lancôme perfume "Poème", her image adorning print campaigns photographed by Richard Avedon and a television advertising campaign, including an advert directed by Anthony Minghella and scored by Gabriel Yared.
By the end of this period and following roles in a number of prestige productions, critics were wondering if Binoche was typecast as the tragic, despairing muse. In a feature article entitled "The Erotic Face" in the June 2000 edition of British film criticism magazine "Sight and Sound", Ginette Vincendeau pondered Binoche's persona; Vincendeau suggested that the fixation of numerous directors upon her face had led to an erasure of her body, and to her being perceived only as a romantic icon rather than a versatile actress.
2001–2006.
Following the success of "Chocolat", the early 2000s saw Juliette Binoche internationally recognized as an A-list movie star. However, her persona seemed to be somewhat fixed following a series of period roles where she played the always stoic heroine facing tragedy and desolation. Ever keen to try something new, Binoche returned to French cinema in 2002 in an unlikely role; "Jet Lag" opposite Jean Reno saw Binoche play a ditzy beautician. The film, directed by Daniele Thompson, was a box-office hit in France and saw Binoche once again nominated for a César for Best Actress. The film tells the story of a couple who meet at an airport during a strike. Initially the pair despises each other, but, over the course of one night, they find common ground and maybe even love. This playful spirit continued when Binoche featured in a 2003 Italian television commercial for the chocolates Ferrero Rocher. The advertisement played upon her "Chocolat" persona featuring Binoche handing out the chocolates to people on the streets of Paris.
In a more serious vein, Binoche travelled to South Africa to make John Boorman's "In My Country" (2004) opposite Samuel L. Jackson. Based on the book "Country of My Skull" by Antjie Krog, the film examines The Truth and Reconciliation Commission (TRC) hearings following the abolition of Apartheid in the mid-1990s. Although the film premiered at the 2004 Berlin Film Festival, it received much criticism for the inclusion of a fictional romantic liaison and for its depiction of black South Africans. Despite the negative reception, Binoche was extremely enthusiastic about the film and her connection with Boorman. Her sister, Marion Stalens, also travelled to South Africa to shoot a documentary, "La reconciliation?", which explores the TRC process and follows Binoche's progress as she acts in Boorman's film. Next, Binoche re-teamed with Michael Haneke for "Caché". The film was an immediate success, winning best director for Haneke at the 2005 Cannes Film Festival, while Binoche was nominated for a European Film Award for Best Actress for her role. The film tells the story of a bourgeois Parisian couple, played by Binoche and Daniel Auteuil, who begin to receive anonymous videotapes containing footage shot over long periods, surveying the outside of their home. "Caché" went on to feature in the number one position on the "Top 10 of the 2000s" list published by The Times at the end of the decade. Binoche's next film, "Bee Season", based on the celebrated novel by Myla Goldberg, cast her opposite Richard Gere. The film was not a success at the box office taking less than $5 million worldwide. For many critics the film, although intelligent, was "distant and diffuse". "Bee Season" depicts the emotional disintegration of a family just as their daughter begins to win national spelling bees. "Mary" (2005) featured Binoche in a somewhat unlikely collaboration with the controversial American director Abel Ferrara for an investigation of modern faith and Mary Magdalene's position within the Catholic Church. Featuring Forest Whittaker, Matthew Modine and Marion Cotillard, "Mary" was an immediate success, winning the Grand Prix at the 2005 Venice Film Festival. Despite these accolades and favorable reviews, particularly from the influential cultural magazine Les Inrockuptibles, "Mary" failed to secure a distributor in key markets such as the US and the UK
The Cannes Film Festival in 2006 saw Binoche feature in the anthology film "Paris, je t'aime" appearing in a section directed by the Japanese director Nobuhiro Suwa. Suwa's "Place des Victoires" is the story of a grief-stricken mother who manages to have a final brief moment with her dead son. The segment also features Willem Dafoe and Hippolyte Girardot. "Paris, je t'aime" was a popular success, taking over $17 million, at the world box-office. In September 2006, Binoche appeared at the Venice Film Festival to launch "A Few Days in September", written and directed by Santiago Amigorena. Despite an impressive cast including John Turturro, Nick Nolte and up-coming French star Sara Forestier, the film was a failure. "A Few Days in September" is a thriller set between 5 and 11 September 2001, in which Binoche plays a French secret service agent, who may, or may not, have information relating to impending attacks on the U.S. The film was the recipient of harsh criticism from the press for its perceived trivialization of the events of 11 September 2001. While promoting the film in the UK, Binoche told an interviewer she believed the CIA and other government agencies must have had foreknowledge of the 11 September attacks, as depicted in the film. Next Binoche traveled to the 2006 Toronto Film Festival for the premiere of "Breaking and Entering", her second film with Anthony Minghella in the director's chair, based on his first original screenplay since his break-through film "Truly, Madly, Deeply" (1991). In "Breaking and Entering", Binoche played a Bosnian refugee living in London, while Jude Law co-starred as a well-to-do businessman drawn into her life via an act of deception. In preparation for her role, Binoche travelled to Sarajevo where she met women who had survived the war of the 1990s. Lushly photographed by Benoît Delhomme, "Breaking and Entering" portrays intersecting lives amongst the flux of urban renewal in inner-city London. Despite the fact that Binoche was praised for her performance, the film did not ring true for critics and failed to find an audience. In a review in Variety, Todd McCarthy writes that, "Binoche, physically unchanged as ever, plays Amira's controlled anguish with skill". Breaking and Entering also featured Robin Wright, Vera Farmiga, Juliet Stevenson, Rafi Gavron and Martin Freeman.
Although Binoche began the decade on a professional high with an Academy Award nomination for "Chocolat", she struggled at the beginning of the 2000s to secure roles that did not confine her to the tragic, melancholic persona developed in the 1990s. Despite the huge success of "Caché", other high profile films such as "In My Country", "Bee Season" and "Breaking and Entering" failed critically and commercially, Binoche seemed to be at a crossroads in her career.
2007–2012.
2007 was the start of a particularly busy period for Juliette Binoche, one that would see her take on diverse roles in a series of critically acclaimed international movies giving her film career a new impetus, as she shed the restrictions that seemed to have stifled her career in the early part of the decade. The Cannes Film Festival saw the premiere of "Flight of the Red Balloon" (2007) by the widely acclaimed Taiwanese director Hou Hsiao-Hsien. It was originally conceived as a short film to form part of a 20th anniversary tribute to the Musée D'Orsay, to be produced by president of the museum. When that idea failed to find sufficient funding, Hou developed it into a feature-length film and secured the necessary financing. The film was well received by international critics and went on to debut around the world early in 2008. Paying homage to Albert Lamorisse's 1957 short "The Red Balloon", Hou's film tells the story of a woman's efforts to juggle her responsibilities as a single mother with her commitment to her career as a voice artist. Shot on location in Paris, the film was entirely improvised by the cast. The film was number one on the influential critic J. Hoberman's "Top 10 List" for 2008 published in The Village Voice.
"Disengagement" by Amos Gitai premiered out-of-competition at the 2007 Venice Film Festival. Co-starring Liron Levo and Jeanne Moreau, "Disengagement" is a political drama charting the story of a French woman, of Dutch/Palestinian origin, who goes in search of a daughter she abandoned 20 years previously on the Gaza strip. She arrives in Gaza during the 2005 Israeli disengagement. The film won the prestigious Premio Roberto Rossellini and was critically acclaimed, particularly by the eminent "Cahiers du Cinema". However the film proved more controversial in Israel where state television station Channel 1 withdrew financial support for the film citing the "left-wing nature of Gitai's films".
In stark contrast, Peter Hedges co-wrote and directed the Disney-produced "Dan in Real Life", a romantic comedy featuring Binoche alongside Steve Carell. It was released in October 2007, becoming a popular commercial success in the US, before debuting around the world in 2008. The film grossed over $65 million at the worldwide box-office. "Dan in Real Life" is the story of a widowed man (Carell) who meets, and instantly falls for, a woman (Binoche), only to discover she is the new girlfriend of his brother. The film also features Dane Cook, Emily Blunt and Diane Weist
Back in France, Binoche was seen to popular and critical success in "Paris" directed by Cédric Klapisch. "Paris" is Klapisch's personal ode to the French capital and features an impressive ensemble of French talent, including Romain Duris, Fabrice Luchini and Mélanie Laurent. "Paris" was one of the most successful French films internationally in recent years, having grossed over $22 million at the world box office. Binoche and Klapisch had originally met on the set of "Mauvais Sang" in 1986, where Klapisch was working as a set electrician.
Also in France, "Summer Hours" (2008), directed by Olivier Assayas, is the critically acclaimed story of three siblings who struggle with the responsibility of disposing of their late mother's valuable art collection. The film premiered in France in March 2008 and had its U.S. debut at the 2008 New York Film Festival, before going on general release in the U.S. on 19 May 2009. Widely acclaimed, the film was nominated for the Prix Louis Delluc in France and appeared on numerous U.S. "Top 10 lists", including first place on David Edelstein's "Top 10 of 2009" list in New York Magazine, and J.R. Jones's list in the Chicago Reader. "Summer Hours" also features Charles Berling, Jérémie Renier and Édith Scob.
In the autumn of 2008, Binoche starred in a theatrical dance production titled "in-i", co-created with renowned choreographer Akram Khan. The show, a love story told through dance and dialogue, featured stage design by Anish Kapoor and music by Philip Sheppard. It premiered at the National Theatre in London before embarking on a world tour. Writing in "The Australian", John McCallum wrote that, "Binoche has radiant presence as an actor, her dancing is relaxed and naturalistic", while "The Sunday Times" in the UK commented that, "Binoche's physical achievement is incredible: Khan is a master mover". The production was part of a 'Binoche Season' titled "Ju'Bi'lations", also featuring a retrospective of her film work and an exhibition of her paintings, which were also published in a bilingual book "Portraits in Eyes". The book featured ink portraits of Binoche as each of her characters and of each director she had worked with up to that time. She also penned a few lines to each director.
In April 2006 and again in December 2007, Binoche travelled to Tehran at the invitation of Abbas Kiarostami. While there in 2007, she shot a cameo appearance in his film "Shirin" (2008) which he was shooting at the time. Binoche's visit proved controversial when two Iranian MPs raised the matter in parliament, advising more caution be exercised in granting visas to foreign celebrities which might lead to "cultural destruction". In June 2009 Binoche began work on "Certified Copy" directed by Kiarostami. The film was an Official Selection in competition at the 2010 Cannes Film Festival. Binoche won the Best Actress Award at the festival for her performance. The film went on general release in France on 19 May 2010 to very positive reviews. Her win at the 2010 Cannes Film festival makes Binoche the first actress to win the European "best actress triple crown": Best Actress at Venice for "Three Colors: Blue", Best Actress at Berlin for "The English Patient" and Best Actress at Cannes for "Certified Copy". The September 2010 UK release of the film was overshadowed when French actor Gérard Depardieu made disparaging comments about Binoche to the Austrian magazine "Profil", "Please can you explain to me what the mystery of Juliette Binoche is meant to be?" he said. "I would really like to know why she has been so esteemed for so many years. She has nothing – absolutely nothing". In response, while promoting "Certified Copy", Binoche spoke to movie magazine "Empire" saying, "I don't know him. I understand you don't have to like everyone and you can dislike someone's work. But I don't understand the violence [of his statements]... I do not understand why he is behaving like this. It is his problem." "Certified Copy" proved to be controversial in Kiarostami's homeland when Iranian authorities announced on 27 May 2010 that the film was to be banned in Iran, apparently due to Binoche's attire; Deputy Culture Minister Javad Shamaqdari is quoted as saying, "If Juliette Binoche were better clad it could have been screened but due to her attire there will not be a general screening."
Following the success of "Certified Copy", Binoche appeared in a brief supporting role in "The Son of No One" for American writer and director Dito Montiel. The film also stars Channing Tatum, Al Pacino and Ray Liotta. "The Son of No One" premiered at the 2011 Sundance Film Festival to fairly negative reaction. It was acquired by Anchor Bay Entertainment for distribution in the US and other key territories arriving in selected US cinemas on 4 November 2011. As of December 2011, according to film review aggregator "Rotten Tomatoes", "The Son of No One" is Juliette Binoche's least critically successful film, with only 18% of critics giving it a positive review.
In June 2010, Binoche started work on "Elles" for Polish director Malgorzata Szumowska. "Elles", produced under the working title "Sponsoring", is an examination of teenage prostitution with Juliette Binoche playing a journalist for "ELLE". The film was released in France on 1 February 2012. On 12 January 2011, Variety announced that Juliette Binoche would star in "Another Woman's Life" loosely based on the novel "La Vie d'une Autre" by Frédérique Deghelt. Released in France on 15 February 2012, the film is the directorial debut of the French actress Sylvie Testud and co-stars actor/director Mathieu Kassovitz. "Another Woman's Life" is the story of Marie (Binoche) a young woman who meets and spends the night with Paul (Kassovitz). When she wakes up, she discovers that 15 years have passed. Withs no memory of these years she learns she has acquired an impressive career, a son and a marriage to Paul which seems headed for divorce. The film met with generally mixed reviews in France.
On 17 February 2011, Screendaily announced that Binoche had been cast in David Cronenberg's film "Cosmopolis" with Robert Pattinson, Paul Giamatti, Mathieu Amalric, and Samantha Morton. Binoche appeared in a supporting role as a New York art dealer, Didi Fancher, who is having an affair with Pattinson's Eric Packer. The film, produced by Paulo Branco, began principal photography on 24 May 2011 and was released in 2012, following a competition slot at the 2012 Cannes Film Festival. "Cosmopolis" received mixed reviews from critics. August 2012 saw the French release of "An Open Heart" opposite Edgar Ramirez and directed by Marion Laine. Based on the novel "Remonter l’Orénoque" by Mathias Énard, the film is the story of the obsessive relationship between two highly successful surgeons. The film depicts the impact of an unexpected pregnancy and alcoholism on their relationship. The second film directed by Laine, "An Open Heart" met with tepid reviews in France and poor box office receipts.
2013–present.
The 2013 Berlin Film Festival saw the release of Bruno Dumont's "Camille Claudel 1915", a drama which recounts three days during the thirty years French artist Camille Claudel (Binoche) spent in a mental asylum despite the fact that she had not been diagnosed with any malady. The film examines Claudel's fight to maintain her sanity and find creative inspiration while awaiting a visit from her brother, the poet Paul Claudel. The film received excellent reviews with Binoche in particular gaining excellent reviews for her performance.
Following this Binoche has completed work on "A Thousand Times Good Night" for director "Erik Poppe" in which she plays a war photographer, the romantic drama "Words and Pictures" with Clive Owen from veteran director Fred Schepisi. She co-starred in Gareth Edwards' "Godzilla", which was theatrically released in May 2014. August 2013 saw Binoche reunite with Olivier Assayas for "Clouds of Sils Maria". The film written especially for Binoche also featured Kristen Stewart and Chloë Grace Moretz. The film had its debut at Cannes 2014. Following this role Binoche is slated to appear in "Nobody Wants the Night" by Isabel Coixet which was due to begin shooting late in 2013.
In 2015, Binoche is set to play on stage in a new English language translation of Antigone. Directed by Ivo van Hove, the production will have a world premier in Luxembourg at the end of February. Then, it will embark an international tour to London, Antwerp, Amsterdam, Edinburgh, Paris, Recklinghausen and New York. 
Personal life.
Binoche has two children: a son Raphaël (born on 2 September 1993), whose father is André Halle, a professional scuba diver, and a daughter Hana (born on 16 December 1999), whose father is actor Benoît Magimel, with whom Binoche starred in the 1999 film "Children of the Century". Her sister, Marion Stalens, born 1960, is a professional photographer with Corbis, as well as a director of documentary films, including; "La réconciliation?", a documentary shot on the set of John Boorman's film "In My Country", "The Actress and the Dancer", exploring the genesis of Binoche's dance show "in-i" and "Juliette Binoche - Sketches for a Portrait" a documentary which follows Binoche as she paints the portraits that would later appear in her book "Portraits in Eyes".
Her half-brother Camille Humeau (born 1978) is an acclaimed musician and has been part of the line-up of Oncle Strongle, before top-lining the group Artichaut Orkestra. In 2007, he appeared in a stage production of "Cabaret" directed by Sam Mendes. Stage director Pierre Pradinas is married to her sister Marion.
Charitable work.
Since 1992 Binoche is a patron of the French Cambodian charity "Enfants d'Asie" (previously ASPECA). Through this charity she is godmother to five Cambodian orphans, and has funded the construction of a children's home in Battambang. Starting in 2000, Juliette Binoche has been involved with the organization Reporters Without Borders. In 2002, she presided over "Photos of Stars" with Thierry Ardisson. Nearly 100 French stars were given disposable cameras, which were then auctioned, the buyer then having the exclusive photos taken by the star developed.
Political views and activism.
In April 2002, Binoche and several other French stars including Catherine Deneuve and Mathieu Kassovitz attended a "protest picnic" to object to the firing of Canal+ chairman Pierre Lescure by the Vivendi Universal company.
On 7 February 2006, Binoche attended a high profile demonstration organised by Reporters Without Borders in support of Jill Carroll and two Iraqi journalists who had been abducted in Baghdad.
She supported José Bové in the 2007 French presidential elections which were won by Nicolas Sarkozy. She disclosed on a number of occasions that she did not approve of the Sarkozy administration, stating that the president was creating a monarchic republic.
Binoche and numerous other French personalities including Isabelle Adjani, Yvan Attal, Jane Birkin and Josiane Balasko joined Réseau Education Sans Frontieres (RESF) on 7 January 2010 with a symbolic "cake of solidarity" to highlight the taxation and legitimacy issues being faced by undocumented workers in France.
Binoche was a signatory to a June 2010 petition organized by Reporters Without Borders and Shirin Ebadi to protest against the detention of numerous people, including members of the press, who were protesting the occasion of the first anniversary of the disputed re-election of Iran's president Mahmoud Ahmadinejad.
At the 2010 Cannes Film Festival Binoche spoke out against the detention of Iranian director Jafar Panahi, incarcerated in Teheran's Evin Prison since 1 March 2010 without charge or conviction. At the press conference following the press screening of "Copie Conforme", Binoche was informed that Panahi had begun a hunger strike. The following day Binoche attended a press conference called especially to demand the release of Panahi. Also in attendance were Abbas Kiarostami, Mohsen Makhmalbaf, Gilles Jacob. Binoche read a letter which pointed out that Panahi's detention was "unwarranted and intolerable". When Binoche was awarded the Best Actress award at the festival, brandishing his name on a placard, she used her speech as an opportunity to raise Panahi's plight once again. On 25 May it was announced that Panahi had been released on bail. It was generally agreed that the publicity Binoche and Kiarostami elicited for his case was a strong factor in his release. On 20 December 2010 Panahi, after being prosecuted for "assembly and colluding with the intention to commit crimes against the country's national security and propaganda against the Islamic Republic," was handed a six-year jail sentence and a 20-year ban on making or directing any movies, writing screenplays, giving any form of interview with Iranian or foreign media as well as leaving the country. Binoche continues to lobby on his behalf.

</doc>
<doc id="55118" url="http://en.wikipedia.org/wiki?curid=55118" title="Juggernaut">
Juggernaut

A juggernaut (  ), in current English usage, is a literal or metaphorical force regarded as mercilessly destructive and unstoppable. This usage originated in the mid-nineteenth century as an allegorical reference to the Hindu "Ratha Yatra" temple car, which apocryphally was reputed to crush devotees under its wheels.
Overview.
The figurative sense of the word has ground in mechanics comparable to figurative uses of steamroller or battering ram to mean something overwhelming. Its ground in social behavior is similar to that of bandwagon, but with overtones of devotional sacrifice. Its British English meaning of a large heavy truck or articulated lorry dates from the second half of the twentieth century.
The word is derived from the Sanskrit "Jagannātha" (Devanagari जगन्नाथ) "world-lord", where jagath means the world and nath means lord, one of the names of Krishna found in the Sanskrit epics.
The English loanword "juggernaut" in the sense of "a huge wagon bearing an image of a Hindu god" is from the 17th century, inspired by the Jagannath Temple in Puri, Odisha, which has the "Ratha Yatra" ("chariot procession"), an annual procession of chariots carrying the murtis (statues) of "Jagannâth", Subhadra and Balabhadra (Krishna's elder brother).
The first European description of this festival is found in the 14th-century "The Travels of Sir John Mandeville", which apocryphally describes Hindus, as a religious sacrifice, casting themselves under the wheels of these huge chariots and being crushed to death. Others have suggested more prosaically that the deaths, if any, were accidental and caused by the press of the crowd and the general commotion.
The term is used literally in "Jane Eyre", where one character describes her as "worse than many a little heathen who says its prayers to Brahma and kneels before Juggernaut", suggesting that it would have been fairly widely understood when it was published in 1847.
The figurative sense of the English word, with the idea of "something that demands blind devotion or merciless sacrifice" became common in the mid-nineteenth century. For example, it was used to describe the out-of-control character Hyde in Robert Louis Stevenson's "Dr. Jekyll and Mr. Hyde". Other notable writers to have used the word this way range from H.G. Wells and Longfellow to Joe Klein.
Many speakers and writers apply the term to a large machine, or collectively to a team or group of people working together (such as a highly successful sports team or corporation), or even a growing political movement led by a charismatic leader—and it often bears an association with being crushingly destructive, with one early use of the word construing it as a synonym for Moloch.
In popular culture.
In fiction and games, the name "juggernaut" is often used to refer to some great and powerful creature, machine or vehicle. One example occurs in the popular e-sports game DOTA 2 where one of the heroes is classed as a "Juggernaut" and whose power is derived from using attacks which provide invulnerability, such as unstoppable force implies.
It is sometimes spelled "juggernaught", possibly due to a conflation with the word "dreadnaught"/"dreadnought", which can be used with a similar meaning.

</doc>
<doc id="55120" url="http://en.wikipedia.org/wiki?curid=55120" title="Treaty of Passarowitz">
Treaty of Passarowitz

The Treaty of Passarowitz or Treaty of Požarevac was the peace treaty signed in Požarevac (Serbian Cyrillic: Пожаревац, German: "Passarowitz", Turkish: "Pasarofça", Hungarian: "Pozsarevác"), a town in Ottoman Empire (today Serbia), on 21 July 1718 between the Ottoman Empire on one side and the Habsburg Monarchy of Austria and the Republic of Venice on the other.
During the years 1714–18, the Ottomans had been successful against Venice in Greece and Crete, in the Ottoman–Venetian War. But, in the Austro-Turkish War of 1716–1718, they had been defeated at Petrovaradin (1716) by the Austrian troops of Prince Eugene of Savoy.
The treaty reflected the military situation. The Ottoman Empire lost the Banat and southeastern Syrmia, central part of present-day Serbia (from Belgrade to south of Kruševac), a tiny strip of northern Bosnia and Lesser Wallachia (Oltenia) to Austria. Venice renounced the Peloponnese peninsula (known as the Morea at the time), gained by the Treaty of Karlowitz, as well as its last remaining outposts in Crete, retaining only the Ionian Islands (with Ottoman-occupied Kythera added to them) and the cities of Preveza and Arta on the Epirote mainland. In Dalmatia, it made some small advances, taking the areas of Sinj, Imotski and Vrgorac in the hinterland.
The result of the treaty was the restoration of Habsburg administration over much of the territory of present-day Serbia, which they had temporarily occupied during the Great Turkish War between 1688 and 1699, and the effective establishment of the Kingdom of Serbia as a crown land. Following Passarowitz, a Habsburg crown land known as the Banat of Temeswar was also established.
After another Austro-Turkish war, in the 1739 Treaty of Belgrade the Ottoman Empire regained northern Bosnia, Habsburg Serbia (including Belgrade), southern parts of the Banat of Temeswar and Lesser Wallachia.

</doc>
<doc id="55123" url="http://en.wikipedia.org/wiki?curid=55123" title="David Gunn">
David Gunn

David Gunn may refer to:

</doc>
<doc id="55125" url="http://en.wikipedia.org/wiki?curid=55125" title="Long March (rocket family)">
Long March (rocket family)

A Long March rocket () or Changzheng rocket in Chinese pinyin is any rocket in a family of expendable launch systems operated by the People's Republic of China. Development and design falls under the auspices of the China Academy of Launch Vehicle Technology. In English, the rockets are abbreviated as LM- for export and CZ- within China, as "Chang Zheng" means "Long March" in Chinese pinyin. The rockets are named after the Long March of Chinese communist history.
History.
China launched its first satellite, known as Dong Fang Hong 1 ("the East is Red"), into Earth orbit on its Long March space rocket on April 24, 1970, becoming the fifth nation to achieve independent launch capability. Early launches had a spotty record, focusing on launching of Chinese satellites. Starting in 1990, the Long March rocket entered the international market. However, several setbacks occurred during the early 1990s. On January 26, 1995, a Long March 2E rocket veered off course two seconds after take-off from Xichang space center and exploded, killing at least six on the ground. On February 14, 1996, a similar failure during the launch of Intelsat 708. The rocket veered severely off course immediately after clearing the launch tower and crashed into a village. Following the disaster, foreign media were sequestered in a bunker for five hours while, some have alleged, the Chinese military attempted to 'clean up' the damage. Officials later blamed the failure on an "unexpected gust of wind" Xinhua News Agency initially reported 6 deaths and 57 injuries.
In the aftermath of the explosion, U.S. satellite makers shared information that allowed the Chinese to determine that the problem was in the welds. This sharing of information was later deemed illegal by the United States, and U.S. satellite maker Loral Space and Communications was fined $14 million by the U.S. government.
For thirteen years, between August 1996 and August 2009, 75 consecutive successful launches were conducted, ending with the launch of Palapa-D on August 31, 2009, which partially failed due to a third stage malfunction. On October 15, 2003, the Long March 2F rocket successfully launched the "Shenzhou 5" spacecraft/orbiter carrying China's first astronaut into space; China thus became the third nation to send a person in space independently, after the Soviet Union/Russia and the United States. A Long March 2F launched the "Shenzhou 6" with two astronauts on October 12, 2005. On June 1, 2007, Long March rockets completed the 100th launch. On October 24, 2007, the Long March 3A successfully launched (18:05 GMT+8) the "Chang'e 1" lunar orbiting spacecraft from the Xichang Satellite Launch Center. On September 25, 2008, a Long March 2F launched "Shenzhou 7", China's first three-man mission and first EVA mission.
On the June 11, 2013, a Long March 2F, launched from the Jiuquan Satellite Launch Center, put three astronauts into orbit for the Shenzhou 10 mission.
As of 2015, there have been at least 200 Long March missions.
Payloads.
The Long March is China's primary expendable launch system family. The Shenzhou spacecraft and Chang'e lunar orbiters are also launched on the Long March rocket. The maximum payload for LEO is 12,000 kg (CZ-3B), the maximum payload for GTO is 5,500 kg (CZ-3B/E). The next generation rocket – Long March 5 variants will offer more payload in the future.
Propellants.
Long March 1's 1st and 2nd stage uses nitric acid and UDMH propellants, and its upper stage uses a spin-stabilized solid rocket engine.
Long March 2, Long March 3, Long March 4, the main stages and associated liquid rocket boosters use dinitrogen tetroxide as the oxidizing agent and UDMH as the fuel. The upper stages (third stage) of Long March 3 rockets use YF-73 and YF-75 engines, using Liquid hydrogen (LH2) as the fuel and Liquid oxygen (LOX) as the oxidizer.
The new generation of Long March rocket family, Long March 5, and its derivations Long March 6, Long March 7 will use LOX and kerosene as core stage and liquid booster propellant, with LOX and LH2 in upper stages.
Variants.
The Long March rockets are organized into several series:
Long March 8.
A new series of launch vehicles in study, which is geared towards SSO launches.
Long March 9.
"Long March 9" ("LM-9", "CZ-9", or "Changzheng 9", Chinese: 长征九号) is a Chinese super-heavy carrier rocket that is currently in study. It is planned for a maximum payload capacity of at least 130,000 kg to LEO or at least 50,000 kg to Lunar Transfer Orbit.
Long March 11.
The "Long March 11" is a planned solid-fuel rocket being developed by China. It will apply China's largest solid-fuel rocket engine and was designed to meet the need to rapidly launch satellites in case of emergencies or disasters. Its first launch is planned before 2016.
Origins.
The Long March 1 rocket is derived from earlier Chinese 2-stage IRBM DF-4, or Dong Feng 4 missile, and Long March 2, Long March 3, Long March 4 rocket families are derivatives of the Chinese 2-stage ICBMs DF-5, or Dong Feng 5 missile. However, like its counterparts in both the United States and in Russia, the differing needs of space rockets and strategic missiles have caused the development of space rockets and missiles to diverge. The main goal of a space rocket is to maximize payload, while for strategic missiles increased throw weight is much less important than the ability to launch quickly and to survive a first strike. This divergence has become clear in the next generation of Long March rockets, which use cryogenic propellants in sharp contrast to the next generation of strategic missiles, which are mobile and solid fuelled.
The next generation of Long March rocket, Long March 5 rocket family will be a brand new design, while Long March 6 and Long March 7 can be seen as derivations because they use the liquid rocket booster design of Long March 5 to build small-to-mid capacity launch vehicles.
Launch sites.
There are four launch centers in China. They are:
Most of the commercial satellite launches of Long March vehicles have been from Xichang Satellite Launch Center, located in Xichang, Sichuan province. Wenchang Satellite Launch Center in Hainan province is under expansion and will be the main launch center for future commercial satellite launches. Long March launches also take place from the more military oriented Jiuquan Satellite Launch Center in Gansu province from which the manned Shenzhou spacecraft also launches. Taiyuan Satellite Launch Center is located in Shanxi province and focuses on the launches of Sun-synchronous orbit satellites.
Commercial launch services.
China markets launch services under the China Great Wall Industry Corporation. Its efforts to launch communications satellites were dealt a blow in the mid-1990s after the United States stopped issuing export licenses to companies to allow them to launch on Chinese launch vehicles out of fear that this would help China's military. In the face of this, Thales Alenia Space built the Chinasat-6B satellite with no components from the United States whatsoever. This allowed it to be launched on a Chinese launch vehicle without violating U.S. ITAR restrictions. The launch, on a Long March 3B rocket, was successfully conducted on July 5, 2007.
A Chinese Long March 2D launched Venezuela's VRSS-1 (Venezuelan Remote Sensing Satellite 1) "Francisco de Miranda" on September 29, 2012.

</doc>
<doc id="55126" url="http://en.wikipedia.org/wiki?curid=55126" title="Dongfeng (missile)">
Dongfeng (missile)

The Dongfeng () missile is a series of intermediate and intercontinental ballistic missiles operated by the People's Republic of China. Typically, the word Dongfeng is shortened to "DF", so Dongfeng 9 is written as DF-9.
History.
After the signing of Sino-Soviet Treaty of Friendship, Alliance, and Mutual Assistance in 1950, the Soviet Union assisted China's military R&D with training, technical documentation, manufacturing equipment, and license-production of Soviet weapons. In the area of ballistic missiles, the Soviets transferred R-1 (SS-1), R-2 (SS-2), and R-11F to China. The first Chinese ballistic missiles were based on Russian design. Since then, China has made many advances in its ballistic missile and rocket technology. The space-launch vehicle Long March (rocket family) has its roots in the Dong Feng missile.
Dongfeng missiles.
Dongfeng 1 (SS-2).
First of the Dong Feng missiles, the DF-1 was a licensed copy of the Soviet R-2 (SS-2 Sibling) missile. The DF-1 had a single RD-101 rocket engine, and used alcohol for fuel with liquid oxygen (LOX) as an oxidizer. The missile had max range of 550 km and 500 kg payload. Limited numbers of DF-1 were produced in the 1960s, and have since been retired.
Dongfeng 2 (CSS-1).
The DF-2 is China's first medium-range ballistic missile, with 1,250 km range and 15-20 kt nuclear warhead. It received the western designation of CSS-1, for China Surface-to-Surface (missile). It was long noted by the western observers that the DF-2 could be a copy of the Soviet R-5 Pobeda (SS-3 Shyster), as they have identical look, range, engine and payload. Now it is known that the whole documentation for R-5 had been delivered from Soviet Union to China in the late 1950s. But some western authors are still attribute the entire design to Chinese specialists Xie Guangxuan, Liang Sili, Liu Chuanru, Liu Yuanwei, Lin Shuangwei, and Ren Xinmin. The first DF-2 failed in its launch test in 1962, leading to the improved DF-2A. The DF-2A was used to carry out China's first nuclear ballistic missile test at Lop Nor in 1966, and was in operational service since late 1960s. All DF-2 were retired from active duty in the 1980s.
Dongfeng 3 (CSS-2).
The DF-3 is often considered China's first "domestic" intermediate-range ballistic missile (IRBM). The common ICBM design was greatly influenced by soviet R-14 Chusovaya missile and the first stage engine itself was a direct copy of С.2.1100/С.2.1150 La-350 booster engine developed by Isayev OKB-2 (NII-88). The responsibility for the development guidance has been attributed to both Tu Shou'e (屠守锷) and Sun Jiadong (孙家栋), and the missile as produced at Factory 211 (Capital Astronautics Co., (首都航天机械公司), also known as Capital Machine Shop, (首都机械厂). The 2,500 km DF-3 was originally designed with 2,000 kg payload to carry an atomic (later thermonuclear) payload. A further improved DF-3A with 3,000 km range (~4,000 km with reduced payload) was developed in 1981, and exported to Saudi Arabia with conventional high-explosive warhead. Their range of 2,810 km means they fall just short of being able to target Guam, although the 2012 DOD report on China's military power states that they have a range of 3,300 km, which would be enough to target Guam. The 2013 Pentagon report on China's military power confirms the DF-3's 3,300 km range, and its maps show Guam being within the DF-3's range. All DF-3/DF-3A's were retired by the mid-2010s and replaced by the DF-21.
Dongfeng 4 (CSS-3).
The DF-4 "Chingyu" is China's first two-stage ballistic missile, with 5,550-7,000 km range and 2,200 kg payload (3 Mt nuclear warhead). It was developed in late 1960s to provide strike capability against Moscow and Guam. The DF-4 missile also served as basis for China's first space launch vehicle, Chang Zeng 1 (Long March 1). Approx. 20 DF-4's remain in service, and are scheduled to be replaced by DF-31 by 2010-2015.
Dongfeng 5 (CSS-4).
The DF-5 is an intercontinental ballistic missile (ICBM), designed to carry a 3 megaton (Mt) nuclear warhead to distance up to 12,000 km. The DF-5 is a silo-based, two-stage missile, and its rocket served as the basis for the space-launch vehicle Fengbao-Tempest (FB-1) used to launch satellites. The missile was developed in the 1960s, but did not enter service until 1981. An improved variant, the DF-5A, was produced in the mid 1990s with improved range (>13,000 km). Currently, an estimated 24-36 DF-5A's are in service as China's primary ICBM force.
Dongfeng 11 (CSS-7).
Also known as the M-11 (export), the DF-11 is a road-mobile short-range ballistic missile (SRBM) designed by Wang Zhenhua at the Sanjiang Missile Corporation (also known as the 066 Base) in the late 1970s. Unlike previous Chinese ballistic missiles, the DF-11 use solid fuel, which greatly reduces launch preparation time (15-30 min). Liquid-fueled missiles such as the DF-5 require up to 2 hours of pre-launch preparation. The DF-11 has range of 300 km and 800 kg payload. An improved DF-11A version has increased range of >825 km. The range of the M-11 does not violate the limits set by the Missile Technology Control Regime (MTCR). Estimates on the number of DF-11s in service vary between 500 to 600.
Dongfeng 12 (CSS-X-15).
The DF-12 is a SRBM formerly known as the M20. The change in designation signaled a shift in fielding to the Second Artillery Corps, making it possible the missile could be armed with a tactical nuclear warhead. Images of it bear a resemblance to the Russian 9K720 Iskander missile which, although not purchased by China from Russia, could have been acquired from former Soviet states. Like the Iskander, the DF-12 reportedly has built-in countermeasures including terminal maneuverability to survive against missile defense systems. Range is reportedly 280 km with accurate guidance provided by inertial navigation and Beidou. The DF-12 has an 880 lb warhead that can deliver cluster, high explosive fragmentation, penetration, or high-explosive incendiary payloads.
Dongfeng 15 (CSS-6).
Also known as the M-9 (export), the DF-15 was developed by the CASC China Academy of Rocket Motor Technology (ARMT), previously known as the 5th Aerospace Academy. The missile is a single-stage, solid-fuel SRBM with 600 km range and 500 kg payload. During the 1995-1996 Taiwan strait crisis, the PLA launched 6 DF-15's in an "exercise" to demonstrate the missile's capability. Although the DF-15 is marketed for export, its range would violate the Missile Technology Control Regime (MTCR) agreement, and thus no DF-15 has been exported to date. Approximately 300-350 DF-15's are in service with the PLA Second Artillery Corps today.
Dongfeng 16.
The DF-16 is a missile that is newer and has a longer range than the DF-15 (between 800  km and 1,000 km). A Taiwan official announced on March 16, 2011 that Taiwan believed China had begun deploying the missiles. The DF-16 represents an increased threat to Taiwan because it is more difficult for anti-ballistic missiles systems, such as the MIM-104 Patriot PAC-3, to intercept. Due to its increased range, the missile has to climb to higher altitudes before descending, giving more time for gravity to accelerate it on re-entry faster than a PAC-3 could effectively engage it.
Dongfeng 21 (CSS-5).
The DF-21 is a two-stage, solid-fuel, medium-range ballistic missile (MRBM) developed by the 2nd Aerospace Academy (now China Changfeng Mechanics and Electronics Technology Academy) in late 1970s. It was the first solid-fueled ballistic missile deployed by the Second Artillery Corp. The missile carries a single 500 kt nuclear warhead, up to 2,500 km range. The DF-21 also served as the basis for the submarine-launched ballistic missile (SLBM) JL-1 (CSS-N-3), used on the XIA-Class SSBN. In 1996, an improved variant, the DF-21A, was introduced. As of 2010, 60-80 DF-21/DF-21A were estimated to be in service; this number may have increased since then.
Dongfeng 25.
The mobile-launch DF-25 was a two-stage solid-fuel missile with a range of 3,200 kilometers. Development was allegedly cancelled in 1996. The U.S. Department of Defense in its 2013 report to Congress on China's military developments made no mention of the DF-25 as a missile in service.
Dongfeng 26C.
The DF-26C is an IRBM with a range of at least 2,200 mi, far enough to reach U.S. bases in Guam. Few details are known, but it is believed to be solid-fueled and road mobile, allowing it to be stored in underground bunkers and fired at short notice, making it difficult to counter. It is possible that the DF-26C is a follow-up version of the DF-21. Possible warheads include conventional, nuclear, or even maneuverable anti-ship and hypersonic warheads.
Dongfeng 31 (CSS-10).
The DF-31 is China's newest road-mobile, solid-fuel ICBM developed by the 4th Aerospace Academy (now Academy of Rocket Motor Technology / ARMT). The DF-31 has range of 8,000+ km, and can carry a single 1,000 kt warhead, or up to three 20-150 kt MIRV warheads. An improved version, the DF-31A, has range of 11,000+ km. The DF-31 was developed to replace many of China's older ballistic missiles, and served as basis to the new JL-2 (CSS-NX-4/CSS-NX-5) SLBM. In 2009, approx. 30 DF-31/DF-31A are estimated to be in service; it is possible this number may have increased since then. 12 were displayed at the 2009 military parade in Beijing commemorating the 60th anniversary of the PRC's founding.
Dongfeng 41 (CSS-X-10).
Western analysts speculate that China may be developing a next-generation ICBM, known as the DF-41, with 12,000-14,000 km range, armed with single, 3, 6, or even 10 MIRV warheads.

</doc>
<doc id="55127" url="http://en.wikipedia.org/wiki?curid=55127" title="Jefferson County, New York">
Jefferson County, New York

Jefferson County is a county located in the U.S. state of New York. As of the 2010 census, the population was 116,229. Its county seat is Watertown. The county is named after Thomas Jefferson, third President of the United States of America. It is adjacent to Lake Ontario, southeast from the Canadian border of Ontario.
Jefferson County comprises the Watertown-Fort Drum, NY Metropolitan Statistical Area.
The U.S. Tenth Mountain Division is based at Fort Drum.
History.
When counties were established in the Province of New York in 1683, the present Jefferson County was part of Albany County. This was an enormous county, including the northern part of New York State as well as all of the present State of Vermont and, in theory, extending westward to the Pacific Ocean. This county was reduced in size on July 3, 1766 by the creation of Cumberland County, and further on March 16, 1770 by the creation of Gloucester County, both containing territory now in Vermont.
On March 12, 1772, what was left of Albany County was split into three parts, one remaining under the name Albany County. One of the other pieces, Tryon County, contained the western portion (and thus, since no western boundary was specified, theoretically still extended west to the Pacific). The eastern boundary of Tryon County was approximately 5 mi west of the present city of Schenectady, and the county included the western part of the Adirondack Mountains and the area west of the West Branch of the Delaware River. The area then designated as Tryon County now includes 37 counties of New York State. The county was named for William Tryon, colonial governor of New York.
In the years subsequent to 1776, most of the Loyalists in Tryon County fled to Canada. In 1784, following the peace treaty that ended the American Revolutionary War, the name of Tryon County was changed to Montgomery County to honor the general, Richard Montgomery, who had captured several places in Canada and died attempting to capture the city of Quebec, replacing the name of the hated British governor.
In 1789, the size of Montgomery County was reduced by the splitting off of Ontario County from Montgomery. The actual area split off from Montgomery County was much larger than the present county, also including the present Allegany, Cattaraugus, Chautauqua, Erie, Genesee, Livingston, Monroe, Niagara, Orleans, Steuben, Wyoming, Yates, and part of Schuyler and Wayne Counties.
Jefferson County is part of Macomb's Purchase of 1791.
In 1791, Herkimer County was one of three counties split off from Montgomery (the other two being Otsego, and Tioga County). This was much larger than the present county, however, and was reduced by a number of subsequent splits. The first one of these, in 1794, produced Onondaga County. This county was larger than the current Onondaga County, including the present Cayuga, Cortland, and part of Oswego Counties.
Oneida County (as well as a part of Chenango County), was split off from Herkimer County in 1798.
Jefferson County was split off from Oneida County in 1805. In 1817, Carleton Island, captured from the British in the War of 1812, was annexed to the county.
Geography.
According to the U.S. Census Bureau, the county has a total area of 1857 sqmi, of which 1269 sqmi is land and 589 sqmi (32%) is water. It is the fourth-largest county in New York by total area.
Jefferson County is in northeastern New York State, adjacent to the area where the Saint Lawrence River exits Lake Ontario. It is northeast of Syracuse, and northwest of Utica. The county is at the international border with Canada.
The Black River, which empties into Lake Ontario, is an important waterway in the county. Part of the Tug Hill Plateau is in the southern part of the county. The county contains part of the Thousand Islands in the St. Lawrence River, including such large islands as Carleton Island, Grindstone Island, and Wellesley Island.
Government.
Legislative authority is vested in the county Board of Legislators which consists of 15 members each elected from single member districts. As of 2014, there are 14 Republicans and 1 Democrat.
County Board of Legislators
Demographics.
As of the census of 2000, there were 111,738 people, 40,068 households, and 28,127 families residing in the county. The population density was 88 people per square mile (34/km²). There were 54,070 housing units at an average density of 42 per square mile (16/km²). The racial makeup of the county was 88.71% White, 5.83% Black or African American, 0.53% Native American, 0.92% Asian, 0.14% Pacific Islander, 2.05% from other races, and 1.82% from two or more races. 4.19% of the population were Hispanic or Latino of any race. 93.2% spoke English and 3.5% Spanish as their first language.
21.9% were of English, 14.1% Irish, 12.8% German, 8.5% French and 8.5% Italian ancestry according to the 2010 American Community Survey.
There were 40,068 households out of which 37.20% had children under the age of 18 living with them, 55.60% were married couples living together, 10.40% had a female householder with no husband present, and 29.80% were non-families. 24.40% of all households were made up of individuals and 10.10% had someone living alone who was 65 years of age or older. The average household size was 2.58 and the average family size was 3.07.
In the county the population was spread out with 26.50% under the age of 18, 11.80% from 18 to 24, 31.30% from 25 to 44, 19.10% from 45 to 64, and 11.30% who were 65 years of age or older. The median age was 32 years. For every 100 females there were 107.30 males. For every 100 females age 18 and over, there were 108.50 males.
The median income for a household in the county was $34,006, and the median income for a family was $39,296. Males had a median income of $28,727 versus $21,787 for females. The per capita income for the county was $16,202. About 10.00% of families and 13.30% of the population were below the poverty line, including 16.80% of those under age 18 and 9.20% of those age 65 or over.
Education.
Jefferson Community College in Watertown provides higher education within the county.

</doc>
<doc id="55128" url="http://en.wikipedia.org/wiki?curid=55128" title="Herkimer County, New York">
Herkimer County, New York

Herkimer County is a county located in the U.S. state of New York. As of the 2010 census, the population was 64,519. Its county seat is Herkimer. The county was created in 1791 north of the Mohawk River out of part of Montgomery County. It is named after General Nicholas Herkimer, who died from battle wounds in 1777 after taking part in the Battle of Oriskany during the Revolutionary War.
Herkimer County is part of the Utica-Rome, NY Metropolitan Statistical Area.
History.
In 1791, Herkimer County was created as one of three counties split off from Montgomery (the other two being Otsego and Tioga counties) as New York State was developed after the American Revolutionary War. Its area was much larger than the present county, however, and was reduced subsequently as more counties were organized.
Part of Herkimer County was included in the Macomb's Purchase of 1791, during the wide-scale sale of public lands after the state forced Iroquois tribes allied with the British during the war to cede their territory. Suddenly the state was selling 5 e6acre of land in upstate, central and western New York.
In 1794, Onondaga County was split off from Herkimer County. This county was larger than the current Onondaga County, and included the present Cayuga, Cortland, and part of Oswego counties.
In 1798, portions of Herkimer and Tioga counties were taken to form Chenango County.
Another part of Herkimer was split off to form Oneida County. It was then larger than the current Oneida County, including the present Jefferson, Lewis, and part of Oswego counties.
In 1802, parts of Herkimer, Clinton and Montgomery counties were combined to form the new St. Lawrence County.
During the American Civil War, Herkimer contributed five companies to the 34th New York Volunteer Infantry Regiment, leading to the unit's nickname "The Herkimer Regiment".
Geography.
According to the U.S. Census Bureau, the county has a total area of 1458 sqmi, of which 1411 sqmi is land and 46 sqmi (3.2%) is water.
Herkimer County is in central New York State, northwest of Albany, and east of Syracuse. The northern part of the county is in the Adirondack Park. The Mohawk River flows across the south part of the county.
Demographics.
As of the census of 2000, there were 64,427 people, 25,734 households, and 17,113 families residing in the county. The population density was 46 people per square mile (18/km²). There were 32,026 housing units at an average density of 23 per square mile (9/km²). The racial makeup of the county was 97.83% White, 0.51% Black or African American, 0.22% Native American, 0.41% Asian, 0.02% Pacific Islander, 0.18% from other races, and 0.84% from two or more races. 0.90% of the population were Hispanic or Latino of any race. 20.6% were of Italian, 16.3% German, 13.9% Irish, 9.3% English, 7.7% Polish, 6.2% American and 5.2% French ancestry according to Census 2000. 95.2% spoke English, 1.2% Spanish and 1.1% Italian as their first language.
There were 25,734 households out of which 30.60% had children under the age of 18 living with them, 51.20% were married couples living together, 10.30% had a female householder with no husband present, and 33.50% were non-families. 27.60% of all households were made up of individuals and 13.70% had someone living alone who was 65 years of age or older. The average household size was 2.46 and the average family size was 2.99.
In the county the population was spread out with 24.40% under the age of 18, 8.30% from 18 to 24, 26.60% from 25 to 44, 24.00% from 45 to 64, and 16.80% who were 65 years of age or older. The median age was 39 years. For every 100 females there were 94.20 males. For every 100 females age 18 and over, there were 91.70 males.
The median income for a household in the county was $32,924, and the median income for a family was $40,570. Males had a median income of $29,908 versus $21,518 for females. The per capita income for the county was $16,141. About 8.90% of families and 12.50% of the population were below the poverty line, including 15.60% of those under age 18 and 10.40% of those age 65 or over.
Government and politics.
The Herkimer County Legislature consists of 17 members each elected from single member districts.
Herkimer County is one of the most politically conservative counties in New York. In 2010, it was one of the few counties outside of Western New York to vote for Carl Paladino over Andrew Cuomo in the gubernatorial election.
The county is currently located in New York's 24th congressional district, represented by Richard L. Hanna; future redistricting will place the county in the future 21st district (along with most of the territory of the current 23rd district, represented by Bill Owens).
Economy.
Herkimer County is known for producing unusual clear, doubly terminated quartz crystals, marketed as Herkimer diamonds.
Ilion in Herkimer County has one of two production sites of the Remington Arms Company, where many of the company's firearms are produced.
Transportation.
Airport.
The following public use airport is located in the county:

</doc>
<doc id="55129" url="http://en.wikipedia.org/wiki?curid=55129" title="Treaty of Belgrade">
Treaty of Belgrade

The Treaty of Belgrade (Russian: Белградский мир, Turkish: "Belgrad antlaşması", Serbian: Beogradski mir) was the peace treaty signed on September 18, 1739 in Belgrade, Habsburg Kingdom of Serbia (today Republic of Serbia), by the Ottoman Empire on one side and the Habsburg Monarchy on the other.
This treaty ended the hostilities of the two-year Austro-Russian–Turkish War (1735–39), in which the Habsburgs joined Imperial Russia in its fight against the Ottomans. With the Treaty of Belgrade, the Habsburgs ceded the Kingdom of Serbia with Belgrade, the southern part of the Banat of Temeswar and northern Bosnia to the Ottomans, and Oltenia, gained by the Treaty of Passarowitz in 1718, to Wallachia (an Ottoman subject), and set the demarcation line to the rivers Sava and Danube. The Habsburg withdrawal forced Russia to accept peace at the Russo-Turkish War, 1735-1739 with the Treaty of Niš, whereby it was allowed to build a port at Azov, gaining a foothold on the Black Sea.
The Treaty of Belgrade effectively ended the Kingdom of Serbia which had existed since 1718. This territory would await the next Habsburg-Ottoman war to be temporarily again included into the Habsburg Monarchy in 1788 with the help of Koča Anđelković.

</doc>
<doc id="55130" url="http://en.wikipedia.org/wiki?curid=55130" title="Peak District">
Peak District

The Peak District is an upland area in England, most of which lies in northern Derbyshire but also includes parts of Cheshire, Greater Manchester, Staffordshire and Yorkshire. 
An area of great diversity, it is split into the northern Dark Peak, where most of the moorland is found and whose geology is gritstone, and the southern White Peak, where most of the population lives and whose geology is mainly limestone.
The Peak District National Park became the first national park in the United Kingdom in 1951. With its proximity to the cities of Manchester and Sheffield and easy access by road and rail, it attracts millions of visitors every year.
Geography.
The Peak District forms the southern end of the Pennines and much of the area is uplands above 1000 ft, with a high point on Kinder Scout of 2087 ft. Despite its name, the landscape generally lacks sharp peaks, being characterised by rounded hills and gritstone escarpments (the "edges"). The area is surrounded by major conurbations, including Huddersfield, Manchester, Sheffield, Derby and Stoke-on-Trent.
The National Park covers 555 sqmi of Derbyshire, Staffordshire, Cheshire, Greater Manchester and South and West Yorkshire, including the majority of the area commonly referred to as the Peak. Its northern limits lie along the A62 road between Marsden and Meltham, north east of Oldham, while its southernmost point is on the A52 road on the outskirts of Ashbourne in Derbyshire. The Park boundaries were drawn to exclude large built-up areas and industrial sites from the park; in particular, the town of Buxton and the adjacent quarries are located at the end of the Peak Dale corridor, surrounded on three sides by the Park. The town of Bakewell and numerous villages are, however, included within the boundaries, as is much of the (non-industrial) west of Sheffield. As of 2010, it is the fifth largest National Park in England and Wales. In the UK, the designation "National Park" means that there are planning restrictions to protect the area from inappropriate development and a Park Authority to look after it, but does not imply that the land is owned by the government, or that it is uninhabited. 
12% of the Peak District National Park is owned by the National Trust, a charity which aims to conserve historic and natural landscapes. It does not receive government funding. The three Trust estates (High Peak, South Peak and Longshaw) include the ecologically or geologically significant areas of Bleaklow, Derwent Edge, Hope Woodlands, Kinder Scout, Leek and Manifold, Mam Tor, Dovedale, Milldale and Winnats Pass. The Peak District National Park Authority directly owns around 5%, and other major landowners include several water companies.
Geology.
The Peak District is formed almost exclusively from sedimentary rocks dating from the Carboniferous period. They comprise the Carboniferous Limestone, the overlying Gritstone and finally the Coal Measures, though the latter occur only on the extreme margins of the area. In addition there are infrequent outcrops of igneous rocks including lavas, tuffs and volcanic vent agglomerates.'
The general geological structure of the Peak District is that of a broad dome (see image below), whose western margins have been most intensely faulted and folded. Uplift and erosion have effectively sliced the top off the dome to reveal a concentric outcrop pattern with Coal Measures rocks on the eastern and western margins, Carboniferous Limestone at the core and with rocks of Millstone Grit outcropping between these two. The southern edge of the dome is overlain by sandstones of Triassic age though these barely impinge upon the National Park.
The central and southern section of the Peak District, where the Carboniferous Limestone is found at or near the surface, is known as the White Peak in contrast to the Dark Peak, which is characterised by Millstone Grit outcrops and broad swathes of moorland.
Earth movements both during and after the Carboniferous period resulted in the up-doming of the area and, particularly in the west, the folding of the rock strata along north–south axes. The region was raised in a north–south line which resulted in this dome-like shape and the shale and sandstone were worn away until limestone was exposed. At the end of this period, the Earth's crust sank here which led to the area being covered by sea, depositing a variety of new rocks.
Some time after its deposition, mineral veins were formed in the limestone. These veins and rakes have been mined for lead since Roman times.
The Peak District was overrun by ice during at least one of the ice ages of the last 2 million years (probably the Anglian glaciation of around 450,000 years ago) as evidenced by the patches of glacial till or boulder clay that can be found across the area. It was not, however, covered by ice during the last glacial period, which peaked around 20,000–22,000 years ago. However a mix of Irish Sea and Lake District ice did butt up against its western margins. Glacial meltwaters eroded a complex of sinuous channels along this margin of the Peak District during this period. Glacial meltwaters also contributed to the formation and development of many of the caves in the limestone area. Wild animal herds roamed the area, and their remains have been found in several of the local caves.
The different types of rock that lie beneath the soil strongly influence the landscape; they determine the type of vegetation that will grow, and ultimately the type of animal that will inhabit the area. Limestone has fissures and is soluble in water, therefore rivers have been able to carve deep, narrow valleys. These rivers then often find a route underground, creating cave systems. Millstone Grit on the other hand is insoluble but porous, so it absorbs water which often seeps through the grits, until it meets the less porous shales beneath, creating springs when it reaches the surface again. The shales are friable and easily attacked by frost, so they form areas that are vulnerable to landslides, as on Mam Tor.
Rivers.
The high moorland plateau of the Dark Peak and the high ridges of the White Peak are the sources of many rivers. In a report for the Manchester Corporation, the engineer John Frederick Bateman wrote in 1846:
Within ten or twelve miles of Manchester, and six or seven miles from the existing reservoirs at Gorton, there is this tract of mountain land abounding with springs of the purest quality. Its physical and geological features offer such peculiar features for the collection, storage and supply of water for the use of the towns in the plains below that I am surprised that they have been overlooked.—John Frederick Bateman, 
He was referring to Longdendale, and the upper valley of the River Etherow. The western side of the Peak District is drained by the rivers Etherow, Goyt, and Tame, which are tributaries of the River Mersey. The north east is drained by tributaries of the River Don, itself a tributary of the Yorkshire Ouse. Of the tributaries of the River Trent, that drain the south and east, the River Derwent is the most prominent. It rises in the Peak District on Bleaklow just east of Glossop and flows through the Upper Derwent Valley with its three reservoirs, the Howden Reservoir, Derwent Reservoir and Ladybower Reservoir. The River Noe and the River Wye are tributaries. The River Manifold and River Dove, rivers of the south west whose sources are on Axe Edge Moor, also flow into the Trent, while the River Dane flows into the River Weaver.
Ecology.
The gritstone and shale of the Dark Peak supports heather moorland and blanket bog environments, with rough sheep pasture and grouse shooting being the main land uses. The limestone plateaux of the White Peak are more intensively farmed, with mainly dairy usage of improved pastures. Some sources also recognise the South West Peak (near Macclesfield) as a third type of area, with intermediate characteristics.
Woodland forms around 8% of the Peak National Park. Natural broad-leaved woodland is found in the steep-sided, narrow dales of the White Peak and the deep cloughs of the Dark Peak, while reservoir margins often have coniferous plantations.
Lead rakes, the spoil heaps of ancient mines, form another distinctive habitat in the White Peak, supporting a range of rare metallophyte plants, including Spring Sandwort ("Minuartia verna"; also known as leadwort), Alpine Pennycress ("Thlaspi caerulescens") and Mountain Pansy ("Viola lutea").
Climate.
With the majority of the area being in excess of 1000 ft above sea level, and being situated to the west of the country with a latitude of 53 degrees, the Peak District experiences a relatively high amount of rainfall each year compared to the rest of England and Wales, averaging 40.35 in in 1999. The Dark Peak tends to receive more rainfall each year in comparison to the White Peak as it is higher in altitude. This higher rainfall, however, does not seem to affect the area's temperature, as it averages the same as England and Wales at 10.3 °C. During the 1970s, the Dark Peak regularly recorded over 70 days of snowfall each year. Since then, though, this number has decreased markedly. Despite this, frost cover is still seen for 20–30% of the winter on the moors of the Dark Peak but for only 10% on the White Peak, and the hills of the National Park still see periods of long continuous snow cover in some winters. For example, a snowfall in mid-December 2009 on the summits of some of the hills created snow patches that lasted in some cases until May 2010. In that same winter, some of the area's passes, such as the A635 (Saddleworth Moor) and A57 (Snake Pass), were closed because of lying snow for almost a month. 
The Moorland Indicators of Climate Change Initiative was set up in 2008 to collect data on climate change in the area. Students investigated the interaction between people and the moorlands, and their overall effect on climate change, to discover whether the moorlands are a net carbon sink or source, based on the fact that upland areas of Britain are a significant global carbon store in the form of peat. Human interaction in terms of direct erosion and fire as well as the effects of global warming are the major variables that they considered.
Economy.
Tourism is the major local employment for Park residents (24%), with manufacturing industries (19%) and quarrying (12%) also being important; only 12% are employed in agriculture. The cement works at Hope is the largest single employer within the Park. Tourism is estimated to provide 500 full-time jobs, 350 part-time jobs and 100 seasonal jobs. 
Limestone is the most important mineral quarried, mainly for roads and cement; shale is extracted for cement at Hope, and several gritstone quarries are worked for housing. Lead mining is no longer economic, but fluorite, baryte and calcite are extracted from lead veins, and small-scale Blue John mining occurs at Castleton.
The springs at Buxton and Ashbourne are exploited to produce bottled mineral water, and many of the plantations are managed for timber. Other manufacturing industries of the area are varied; they include David Mellor's cutlery factory in Hathersage, Ferodo brake linings in Chapel-en-le-Frith and electronic equipment in Castleton. There are approximately 2,700 farms in the National Park, most of them under 40 ha in area. 60% of farms are believed to be run on a part-time basis where the farmer has a second job. 
History.
Early history.
The Peak District has been inhabited from the earliest periods of human activity, as is evidenced by occasional finds of Mesolithic flint artefacts and by palaeoenvironmental evidence from caves in Dovedale and elsewhere. There is also evidence of Neolithic activity, including some monumental earthworks or barrows (burial mounds) such as that at Margery Hill. In the Bronze Age the area was well populated and farmed, and evidence of these people survives in henges such as Arbor Low near Youlgreave, or the Nine Ladies Stone Circle at Stanton Moor. In the same period, and on into the Iron Age, a number of significant hillforts such as that at Mam Tor were created. Roman occupation was sparse but the Romans certainly exploited the rich mineral veins of the area, exporting lead from the Buxton area along well-used routes. There were Roman settlements, including one at Buxton which was known to them as "Aquae Arnemetiae" in recognition of its spring, dedicated to the local goddess.
Theories as to the derivation of the Peak District name include the idea that it came from the Pecsaetan or peaklanders, an Anglo-Saxon tribe who inhabited the central and northern parts of the area from the 6th century AD when it fell within the large Anglian kingdom of Mercia.
Mining and quarrying.
In medieval and early modern times the land was mainly agricultural, as it still is today, with sheep farming, rather than arable, the main activity in these upland holdings. However, from the 16th century onwards the mineral and geological wealth of the Peak became increasingly significant. Not only lead, but also coal, fluorite, copper (at Ecton), zinc, iron, manganese and silver have all been mined here. Celia Fiennes, describing her journey through the Peak in 1697, wrote of
... those craggy hills whose bowells are full of mines of all kinds off black and white and veined marbles, and some have mines of copper, others tinn and leaden mines, in w[hi]ch is a great deale of silver.—Celia Fiennes
Coal measures occur on the western and the eastern fringes of the Peak District, and evidence of past workings can be found from Glossop down to The Roaches, and from Stocksbridge to Baslow. Mining started in medieval times and was at its most productive in the 18th and early 19th centuries, in some cases continuing into the early 20th century. The earliest mining took place at and close to outcrops and miners eventually followed the seams deeper underground as the beds dipped beneath hillsides. At Goyt's Moss and Axe Edge, deep seams were worked and steam engines raised the coal and dewatered the mines. Coal from the eastern mines was used in lead smelting, and coal from the western mines for lime burning.
Lead mining peaked in the 17th and 18th centuries; high concentrations of lead have been found in the area dating back from this period, as well as discovering peat on Kinder Scout suggesting that lead smelting occurred. Lead mining began to decline from the mid-19th century, with the last major mine closing in 1939, though lead remains a by-product of fluorite, baryte and calcite mining. Not all mines were deep underground; Bell pits were a cheap and easy way at getting at an ore that lay close to the surface of flat land. A shaft was sunk into the ore and enlarged at the bottom for extraction. The pit was then enlarged further until it became unsafe or worked out, then another pit would be sunk adjacent to the existing one. 
Fluorite or fluorspar is called Blue John in the Peak District, the name allegedly coming from the French "Bleu et Jaune" which describes the colour of the bandings. Blue John is now scarce, and only a few hundred kilograms are mined each year for ornamental and lapidary use. The Blue John Cavern in Castleton is a show cave; mining still takes place in the nearby Treak Cliff Cavern.
Industrial limestone quarrying for the manufacture of soda ash started in the Buxton area as early as 1874. In 1926 this operation became part of ICI. Large-scale limestone and gritstone quarries flourished as lead mining declined, and remain an important if contentious industry in the Peak. Twelve large limestone quarries operate in the Peak; Tunstead near Buxton is one of the largest quarries in Europe. Total limestone output was substantial: at the 1990 peak, 8.5 million tonnes was quarried.
Introduction of textiles.
Textiles have been exported from the Peak for hundreds of years. Even as early as the 14th century, the area traded in unprocessed wool. There was a number of skilled hand spinners and weavers in the area. By the 1780s, inventors such as Richard Arkwright developed machinery to produce textiles more quickly and to a higher standard. The early mills were narrow and low in height, of light construction, powered by water wheels and containing small machines. Interior lighting was by daylight, and ceiling height was only 6–8 ft. These Arkwright type mills are about 9 ft wide. The Peak District was the ideal location, with its rivers and humid atmosphere. The local pool of labour was quickly exhausted and the new mills such as Litton Mill and Cressbrook Mill in Millers Dale brought in children as young as four from the workhouses of London as apprentices.
With the advance of technology, the narrow Derbyshire valleys became unsuited to the larger steam driven mill, but the Derbyshire mills remained, and continued to trade in finishing and niche products. The market town of Glossop benefitted from the textile industry. The town's economy was linked closely with a spinning and weaving tradition which had evolved from developments in textile manufacture during the Industrial Revolution. Until the First World War, Glossop had the headquarters of the largest textile printworks in the world. In the 1920s, the firm was refloated on the easily available share capital; thus it was victim of the Stock Market Crash of 1929. Their product lines becoming vulnerable to the new economic conditions, and resulted in the industry's decline.
Waterways.
The streams of the Peak District have been dammed to provide headwater for numerous water driven mills; weirs have been built across the rivers for the same purpose.
There are no canals within the National Park boundary (though the Standedge Tunnels on the Huddersfield Narrow Canal run underneath the extreme north of the park). Waters from the Dark Peak fed the Ashton Canal, and Huddersfield Narrow Canal, and waters from the White Peak fed the Macclesfield Canal. Outside the National Park, but within the general area, the Peak Forest Canal was built to bring lime from the quarries at Dove Holes for the construction industry. The canal terminated at Bugsworth and the journey was completed using the Peak Forest Tramway. Southeast of the National Park, the disused Cromford Canal ran from Cromford to the Erewash Canal and formerly served the lead mines at Wirksworth and cotton mills of Sir Richard Arkwright.
The large reservoirs along the Longdendale valley known as the Longdendale Chain were designed in the 1840s and completed in February 1877. They provided compensation water to ensure a continuous flow along the River Etherow which was essential for local industry, and provided pure water for Manchester. The Upper Derwent Valley reservoirs were built from the mid 20th century onward to supply drinking water to the East Midlands and South Yorkshire.
Development of tourism.
The area has been a tourist destination for centuries, with an early tourist description of the area, "De Mirabilibus Pecci" or "The Seven Wonders of the Peak" by Thomas Hobbes, being published in 1636. Much scorn was poured on these seven wonders by subsequent visitors, including the journalist Daniel Defoe who described the moors by Chatsworth as "a waste and houling wilderness" and was particularly contemptuous of the cavern near Castleton known as the 'Devil's Arse' or Peak Cavern. Visitor numbers did not increase significantly until the Victorian era, with railway construction providing ease of access and a growing cultural appreciation of the Picturesque and Romantic. Guides such as John Mawe's "Mineralogy of Derbyshire" (1802) and William Adam's "Gem of the Peak" (1843) generated interest in the area's unique geology.
Buxton has a long history as a spa town due to its geothermal spring which rises at a constant temperature of 28 °C. It was initially developed by the Romans around AD 78, when the settlement was known as Aquae Arnemetiae, or the spa of the goddess of the grove. It is known that Bess of Hardwick and her husband the Earl of Shrewsbury, "took the waters" at Buxton in 1569, and brought Mary, Queen of Scots, there in 1573. The town largely grew in importance in the late 18th century when it was developed by the 5th Duke of Devonshire in style of the spa of Bath. A second resurgence a century later attracted the eminent Victorians such as Dr. Erasmus Darwin and Josiah Wedgwood, who were drawn by the reputed healing properties of the waters. The railway reached Buxton in 1863.
Buxton has many notable buildings such as 'The Crescent' (1780–1784), modelled on Bath's Royal Crescent, by John Carr, 'The Devonshire' (1780–1789), 'The Natural Baths', and 'The Pump Room' by Henry Currey. The Pavilion Gardens were opened in 1871. Buxton Opera House was designed by Frank Matcham in 1903 and is the highest opera house in the country. Matcham was the theatrical architect who designed the London Palladium, the London Coliseum, and the Hackney Empire. 
There is a great tradition of public access and outdoor recreation in the area. The Peak District formed a natural hinterland and rural escape for the populations of industrial Manchester and Sheffield, and remains a valuable leisure resource in a largely post-industrial economy.
Modern history.
The Kinder Trespass in 1932 was a landmark in the campaign for national parks and open access to moorland in Britain. At the time, such open moors were closed to all; they were strongly identified with the game-keeping interests of landed gentry who used them only 12 days a year. The Peak District National Park became the United Kingdom's first national park on 17 April 1951. The first long-distance footpath in the United Kingdom was the Pennine Way, which opened in 1965 and starts at the Nags Head Inn, in Grindsbook Booth, part of Edale village.
The northern moors of Saddleworth and Wessenden, above Meltham, gained notoriety in the 1960s as the burial site of several children murdered by Ian Brady and Myra Hindley.
Transport.
History.
The first roads in the Peak were constructed by the Romans, although they may have followed existing tracks. The Roman network is thought to have linked the settlements and forts of Aquae Arnemetiae (Buxton), Chesterfield, Ardotalia (Glossop) and Navio (Brough and Shatton), and extended outwards to Danum (Doncaster), Mamucium (Manchester) and Derventio (Little Chester, near Derby). Parts of the modern A515 and A53 roads south of Buxton are believed to run along Roman roads.
Packhorse routes criss-crossed the Peak in the Medieval era, and some paved causeways are believed to date from this period, such as the Long Causeway along Stanage Edge. However, no highways were marked on Christopher Saxton's map of Derbyshire, published in 1579. Bridge-building improved the transport network; a surviving early example is the three-arched gritstone bridge over the River Derwent at Baslow, which dates from 1608 and has an adjacent toll-shelter. Although the introduction of turnpike roads (toll roads) from 1731 reduced journey times, the journey from Sheffield to Manchester in 1800 still took 16 hours, prompting Samuel Taylor Coleridge to remark that "a tortoise could outgallop us!" From around 1815 onwards, turnpike roads both increased in length and improved in quality. An example is the Snake Pass, which now forms part of the A57, built under the direction of Thomas Telford in 1819–21; the name refers to the crest of the Duke of Devonshire. The Cromford Canal opened in 1794, carrying coal, lead and iron ore to the Erewash Canal.
Within several years, the improved roads and the Cromford Canal both saw competition from new railways, with work on the first railway in the Peak commencing in 1825. Although the Cromford and High Peak Railway (from the Cromford Canal at High Peak Junction to Whaley Bridge) was an industrial railway, passenger services soon followed, including the Woodhead Line (Sheffield to Manchester via Longdendale) and the Manchester, Buxton, Matlock and Midlands Junction Railway. Not everyone regarded the railways as an improvement:
You enterprised a railroad through the valley, you blasted its rocks away, heaped thousands of tons of shale into its lovely stream. The valley is gone, and the gods with it; and now, every fool in Buxton can be at Bakewell in half-an-hour, and every fool in Bakewell at Buxton.—John Ruskin
By the second half of the 20th century, the pendulum had swung back towards road transport. The Cromford Canal was largely abandoned in 1944, and several of the rail lines passing through the Peak were closed as uneconomic in the 1960s as part of the Beeching Axe. The Woodhead Line was closed between Hadfield and Penistone; parts of the trackbed are now used for the Trans Pennine Trail, the stretch between Hadfield and Woodhead being known specifically as the Longdendale Trail. The Manchester, Buxton, Matlock and Midlands Junction Railway is now closed between Rowsley and Buxton where the trackbed forms part of the Monsal Trail. The Cromford and High Peak Railway is now completely shut, with part of the trackbed open to the public as the High Peak Trail. Another disused rail line between Buxton and Ashbourne now forms the Tissington Trail.
Road network.
The main roads through the Peak District are the A57 (Snake Pass) between Sheffield and Manchester, the A628 (Woodhead Pass) between Barnsley and Manchester via Longdendale, the A6 from Derby to Manchester via Buxton, the Cat and Fiddle road from Macclesfield to Buxton, and in the extreme north of the Park the A635 (Saddleworth Moor) running from Manchester to Barnsley and the A62 from Manchester to Leeds, which forms the northernmost border of the National Park at Standedge. These major roads, together with other minor roads and lanes in the area, are attractive to drivers, but the Peak's popularity makes road congestion and the availability of parking spaces a significant problem, especially during summer. This led to the proposal of a congestion charge in 2005, but this was later rejected.
Public transport.
The Peak District is readily accessible by public transport, which reaches even central areas. Train services into the area are along the Hope Valley Line from Sheffield and Manchester, the Derwent Valley Line from Derby to Matlock, the Huddersfield Line from Manchester to Huddersfield, the Buxton Line and Glossop Line, linking those towns to Manchester. Coach (long-distance bus) services provide access to Matlock, Bakewell and Buxton from Derby, Nottingham and Manchester through TransPeak and National Express, and there are regular buses from the nearby towns of Sheffield, Glossop, Stoke, Leek and Chesterfield. The nearest airport is Manchester.
For such a rural area, the smaller villages of the Peak are relatively well served by internal transport links. There are many minibuses operating from the main towns (Bakewell, Matlock, Hathersage, Castleton, Tideswell and Ashbourne) out to the small villages. The Hope Valley and Buxton Line trains also serve many local stations (including Hathersage, Hope and Edale).
The National Park Authority announced, in October 2009, that Cycle England will be investing £1.25 million, to be spent by 2011, to build and improve cycle routes within the National Park for use by leisure and commuting cyclists. It is hoped that this investment will help reduce traffic congestion and environmental pollution, as well as giving commuters and visitors a viable alternative to travelling around the National Park by car.
Activities.
The Peak District provides opportunities for many types of outdoor activity. An extensive network of public footpaths and numerous long-distance trails, over 1800 mi in total, as well as large open-access areas, are available for hillwalking and hiking. The Pennine Way traverses the Dark Peak from Edale to the Park's northern boundary just south of Standedge. Bridleways are commonly used by mountain bikers, as well as horse riders. Some of the long-distance trails in the White Peak, such as the Tissington Trail and High Peak Trail, re-use former railway lines; they are well used by walkers, horse riders and cyclists. The local authorities run cycle hire centres at Ashbourne, Parsley Hay, Middleton Top and the Upper Derwent Valley. Wheelchair access is possible at several places on the former railway trails, and cycle hire centres offer vehicles adapted to wheelchair users. There is a programme to make footpaths more accessible to less-agile walkers by replacing climbing stiles with walkers' gates.
The many gritstone outcrops, such as Stanage Edge and The Roaches, are recognised as some of the finest rock climbing sites in the world (see rock climbing in the Peak District); they were the first to be climbed. The Peak District's limestone was then 'discovered' by climbers. It is more unstable but provides many testing climbs. For example Thor's Cave was explored in the early 1950s by Joe Brown and others. Eleven limestone routes there are listed by the BMC, ranging in grade from Very Severe to E7, and several more have been claimed since the guidebook's publication; a few routes are bolted.
Beneath the ground, the potholer enjoys natural caves, the potholes and old mine workings found in the limestone of the Peak. Peak Cavern is the largest and most important cave system which is even linked to the Speedwell system at Winnats. The only significant potholes are Eldon Hole and Nettle Pot. There are many old mine workings, which often were extensions of natural cave systems. Systems can be found at Castleton, Winnats, Matlock, Stoney Middleton, Eyam, Monyash and Buxton.
Some of the area's large reservoirs, for example Carsington Water, have become centres for water sports, including sailing, fishing and canoeing, in this most landlocked part of the UK. Other activities include air sports such as hang gliding and paragliding, birdwatching, fell running, off-roading, and orienteering.
Visitor attractions.
The spa town of Buxton was developed by the Dukes of Devonshire as a genteel health resort in the 18th century; now the largest town in the Peak District, it has an opera house with a theatre, museum and art gallery. Another spa town is Matlock Bath, popularised in the Victorian era. Bakewell is the largest settlement within the National Park; its five-arched bridge over the River Wye dates from the 13th century. Buxton, Matlock and Matlock Bath, Bakewell, Leek and the small towns of Ashbourne and Wirksworth, on the fringes of the Park, all offer a range of tourist amenities. To the north the village of Hayfield sits at the foot of Kinder Scout, the highest summit in the area.
Historic buildings include Chatsworth House, seat of the Dukes of Devonshire and among Britain's finest stately homes; the medieval Haddon Hall, seat of the Dukes of Rutland; Hardwick Hall, built by powerful Elizabethan Bess of Hardwick; and Lyme Park, an Elizabethan manor house transformed by an Italianate front. Many of the Peak's villages and towns have fine parish churches, with a particularly magnificent example being the 14th century Church of St John the Baptist at Tideswell, sometimes dubbed the 'Cathedral of the Peak'. 'Little John's Grave' can be seen in the Hathersage churchyard.
The picturesque village of Castleton, overshadowed by the Norman Peveril Castle, has four show caves, the Peak, Blue John, Treak Cliff, and Speedwell, and is the centre of production of the unique semi-precious mineral, Blue John. Other show caves and mines include the Heights of Abraham, reached by cable car, at Matlock Bath, and Poole's Cavern in Buxton. The small village of Eyam is known for its self-imposed quarantine during the Black Death of 1665.
The Mining Museum at Matlock Bath, which includes tours of the Temple Lead Mine, and the Derwent Valley Mills World Heritage Site and Brindley Water Mill at Leek give insight into the Peak's industrial heritage. The preserved steam railway between Matlock and Rowsley, the National Tramway Museum at Crich and the Cromford Canal chart the area's transport history. The Life in a Lens Museum of Photography & Old Times in Matlock Bath presents the history of photography from 1839. 
Well dressing ceremonies are held in most of the villages during the spring and summer months, in a tradition said to date from pagan times. Other local customs include Castleton's annual Garland Festival and Ashbourne's Royal Shrovetide Football, played annually since the 12th century. Buxton hosts two opera festivals, the Buxton Festival and the International Gilbert and Sullivan Festival, as well as the Buxton Festival Fringe, and the Peak Literary Festival is held at various locations twice a year.
Peak District food specialities include the dessert Bakewell pudding, very different from the nationally available Bakewell tart, and until 2009 the famous cheese Stilton and other local cheeses were produced in the village of Hartington.
Conservation issues.
The proximity of the Peak to major conurbations (an estimated 20 million people live within an hour's drive) poses unique challenges to managing the area. The Peak District National Park Authority and the National Trust, with other landowners, attempt to balance keeping the upland landscape accessible to visitors for recreation, whilst protecting it from intensive farming, erosion and pressure from visitors themselves. An inevitable tension exists between the needs of the 38,000 residents of the Peak District National Park, the many millions of people who visit it annually, and the conservation requirements of the area.
The uneven distribution of visitors creates further stresses. Dovedale alone receives an estimated two million visitors annually; other highly visited areas include Bakewell, Castleton and the Hope Valley, Chatsworth, Hartington and the reservoirs of the Upper Derwent Valley. Over 60% of visits are concentrated in the period May–September, with Sunday being the busiest day.
Footpath erosion.
The number of footpath users on the more popular walking areas in the Peak District has contributed to serious erosion problems, particularly on the fragile peat moorlands of the Dark Peak. The recent use of some paths by mountain bikers is believed by some to have exacerbated an existing problem. Measures taken to contain the damage have included the permanent diversion of the official route of the Pennine Way out of Edale, which now goes up Jacob's Ladder rather than following the Grindsbrook, and the surfacing of many moorland footpaths with expensive natural stone paving.
Quarrying.
Large-scale limestone quarrying has been a particular area of contention. Most of the mineral extraction licences were issued by national government for 90 years in the 1950s, and remain legally binding. The Peak District National Park Authority has a policy of considering all new quarrying and licence renewal applications within the area of the National Park in terms of the local and national need for the mineral and the uniqueness of the source, in conjunction with the effects on traffic, local residents and the environment. Some licenses have not been renewed; for example, the RMC Aggregates quarry at Eldon Hill was forced to close in 1999, and landscaping is ongoing. The proposals dating from 1999 from Stancliffe Stone Ltd to re-open dormant gritstone quarries at Stanton Moor have been seen as a test case. They are hotly contested by ecological protesters and local residents on grounds that the development would threaten nearby Bronze Age remains, in particular the Nine Ladies Stone Circle, as well as the natural landscape locally. As of 2007, negotiations are ongoing to shift the development to the nearby Dale View quarry, a less sensitive area.
Peak District in literature and arts.
The landscapes of the Peak have formed an inspiration to writers for centuries. Various places in the Peak District have been identified by Ralph Elliott and others as locations in the 14th-century poem "Sir Gawain and the Green Knight"; Lud's Church for example, is thought to be the Green Chapel.
Key scenes in Jane Austen's 1813 novel "Pride and Prejudice" are set in the Derbyshire Peak District.
"Peveril of the Peak" (1823) by Sir Walter Scott is a historical novel set at Peveril Castle, Castleton during the reign of Charles II. William Wordsworth was a frequent visitor to Matlock; the Peak inspired several of his poems, including an 1830 sonnet to Chatsworth House. The village of Morton in Charlotte Brontë's 1847 novel "Jane Eyre" is based on Hathersage, where Brontë stayed in 1845, and Thornfield Hall might have been inspired by nearby North Lees Hall. Snowfield in George Eliot's first novel "Adam Bede" (1859) is believed to be based on Wirksworth, where her uncle managed a mill; Ellastone (as Hayslope) and Ashbourne (as Oakbourne) are also featured.
Beatrix Potter, the author of Peter Rabbit, used to visit her uncle Edmund Potter at his printworks in Dinting Vale. She used cloth patterns from his Pattern Sample book to dress her characters. Mrs Tiggywinkle's shawl, in The Tale of Mrs. Tiggy-Winkle, is based on pattern number 222714.
Children's author Alison Uttley (1884–1976) was born at Cromford; her well-known novel "A Traveller in Time", set in Dethick, recounts the Babington Plot to free Mary, Queen of Scots, from imprisonment. Crichton Porteous (1901–91) set several books in specific locations in the Peak; "Toad Hole", "Lucky Columbell" and "Broken River", for example, are set in the Derwent Valley. More recently, Geraldine Brooks's first novel, "Year of Wonders" (2001), blends fact and fiction to tell the story of the plague village of Eyam, which also inspired "Children of Winter" by children's novelist Berlie Doherty (b. 1943). Doherty has set several other works in the Peak, including "Deep Secret", based on the drowning of the villages of Derwent and Ashopton by the Ladybower Reservoir, and "Blue John", inspired by the Blue John Cavern at Castleton.
Many works of crime and horror have been set in the Peak. "The Terror of Blue John Gap" by Sir Arthur Conan Doyle (1859–1930) recounts terrible events at the Blue John mines, and Sherlock Holmes investigates the kidnapping of a child in the region in "The Adventure of the Priory School". Many of the horror stories of local author Robert Murray Gilchrist (1878–1916) feature Peak settings. More recently, Stephen Booth has written a series of crime novels set in various real and imagined Peak locations, while "In Pursuit of the Proper Sinner", an Inspector Lynley mystery by Elizabeth George, is set on the fictional Calder Moor.
 Other writers and poets who lived in or visited the Peak include Samuel Johnson, William Congreve, Anna Seward, Jean-Jacques Rousseau, Lord Byron, Thomas Moore, Richard Furness, D. H. Lawrence, Vera Brittain, Richmal Crompton and Nat Gould. 
The landscapes and historic houses of the Peak are also popular settings for film and television. The classic 1955 film "The Dam Busters" was filmed at the Upper Derwent Valley reservoirs, where practice flights for the bombing raids on the Ruhr dams had been made during the Second World War. In recent adaptations of "Pride and Prejudice", Longnor has featured as Lambton, while Lyme Park and Chatsworth House have stood in for Pemberley. Haddon Hall not only doubled as Thornfield Hall in two different adaptations of "Jane Eyre", but has also appeared in several other films including "Elizabeth", "The Princess Bride" and "The Other Boleyn Girl". The long-running television medical drama "Peak Practice" is set in the fictional village of Cardale in the Derbyshire Peak District; it was filmed in Crich, Matlock and other Peak locations.

</doc>
<doc id="55133" url="http://en.wikipedia.org/wiki?curid=55133" title="Treaty of Niš (1739)">
Treaty of Niš (1739)

The Treaty of Niš was a peace treaty signed on 3 October 1739 in Niš (East Serbia), by the Ottoman Empire and Russian Empire. The Russo-Turkish War, 1735-1739 was the result of the Russian effort to gain Azov and Crimea as a first step towards dominating the Black Sea. The Habsburg Monarchy entered the war in 1737 on the Russian side, but was forced to make peace with Ottomans at the separate Treaty of Belgrade, surrendering Northern Serbia, Northern Bosnia and Oltenia, and allowing the Ottomans to resist the Russian push toward Constantinople. In return, the Sultan acknowledged the Habsburg Emperor as the official protector of all Ottoman Christian subjects ("see Ottoman millet"), a position also claimed by Russia. The Austrian peace treaty compelled Russia to accept peace at Niš', forcing them to give up their claim to Crimea and Moldavia, but allowing them to build a port at Azov without fortifications or have any fleet in the Black Sea.

</doc>
<doc id="55134" url="http://en.wikipedia.org/wiki?curid=55134" title="Rock climbing in the Peak District">
Rock climbing in the Peak District

Rock climbing is a popular activity in the Peak District; particularly on edges such as Stanage or Froggatt. Generally the climbing style is free climbing (as opposed to aid climbing) and the rock is either gritstone or limestone. Climbing has been practised in the Peak District since the late 19th century; James W. Puttrell is generally credited with starting the sport. The first climbing guidebook to the area was 'Some Gritstone Climbs', by John Laycock, published in 1913.
There are over 10,000 routes in the Peak District.
One of the most famous Peak District climbers, and a pioneer of many new routes, is Ron Fawcett. The climb known as "Master's Edge", on Millstone Edge, near Hathersage, is a testament to his skill and strength. The climb is graded E7 6c and rises 19m up the near vertical edge.
Gritstone.
The gritstone crags include:
Western Grit (Staffordshire, Kinder, Bleaklow, and the Chew Valley)
Eastern Grit (Derwent Valley, Sheffield, Derbyshire)
Limestone.
In-situ bolts and pitons are more acceptable on limestone and some crags are almost exclusively bolted.

</doc>
<doc id="55136" url="http://en.wikipedia.org/wiki?curid=55136" title="Shambles">
Shambles

A shambles is a mess. 
Shambles or The Shambles may also refer to:

</doc>
<doc id="55138" url="http://en.wikipedia.org/wiki?curid=55138" title="Lewis County, New York">
Lewis County, New York

Lewis County is a county located in the U.S. state of New York. As of the 2010 census, the population was 27,087, making it the fourth-least populous county in New York. Its county seat is Lowville. The county is named after Morgan Lewis, the Governor of New York when the county was established.
History.
When counties were established in New York State in 1683, the present Lewis County was part of Albany County. This was an enormous county, including the northern part of New York State as well as all of the present State of Vermont and, in theory, extending westward to the Pacific Ocean. This county was reduced in size on July 3, 1766 by the creation of Cumberland County, and further on March 16, 1770 by the creation of Gloucester County, both containing territory now in Vermont.
On March 12, 1772, what was left of Albany County was split into three parts, one remaining under the name Albany County. One of the other pieces, Tryon County, contained the western portion (and thus, since no western boundary was specified, theoretically still extended west to the Pacific). The eastern boundary of Tryon County was approximately five miles west of the present city of Schenectady, and the county included the western part of the Adirondack Mountains and the area west of the West Branch of the Delaware River. The area then designated as Tryon County now includes 37 counties of New York State. The county was named for William Tryon, colonial governor of New York.
In the years prior to 1776, most of the Loyalists in Tryon County fled to Canada. In 1784, following the peace treaty that ended the American Revolutionary War, the name of Tryon County was changed to Montgomery County to honor the general, Richard Montgomery, who had captured several places in Canada and died attempting to capture the city of Quebec, replacing the name of the hated British governor.
In 1789, the size of Montgomery County was reduced by the splitting off of Ontario County from Montgomery. The actual area split off from Montgomery County was much larger than the present county, also including the present Allegany, Cattaraugus, Chautauqua, Erie, Genesee, Livingston, Monroe, Niagara, Orleans, Steuben, Wyoming, Yates, and part of Schuyler and Wayne Counties.
Lewis County is part of Macomb's Purchase of 1791.
In 1791, Herkimer County was one of three counties split off from Montgomery (the other two being Otsego, and Tioga County). This was much larger than the present county, however, and was reduced by a number of subsequent splits. The first one of these, in 1794, produced Onondaga County. This county was larger than the current Onondaga County, including the present Cayuga, Cortland, and part of Oswego Counties.
Oneida County (as well as a part of Chenango County), was split off from Herkimer County in 1798.
Lewis County was split off from Oneida County in 1805.
In January 1997, much of the county was socked in a world record-breaking snowburst, with nearly 6.5 ft of snow in just a 24-hour period.
Lewis County, once organized, adopted five towns; Leyden, Turin, Martinsburg, Lowville, and Harrisburg. Today there are seventeen and they are Croghan, Denmark, Diana, Greig, Harrisburg, Highmarket, Lewis, Leyden, Lowville, Martinsburg, Montague, New Bremen, Osceola, Pinckney, Turin, Watson, and West Turin. Croghan was adopted in 1841, Denmark was in 1807, Diana in 1830, Greig 1828, Harrisburg 1803, Highmarket 1852, Lewis 1852, Leyden 1797, Lowville 1800, Martinsburg 1803, Montague 1850, New Bremen 1848, Osceola 1844, Pinckney 1808, Turin 1800, Watson 1821, and West Turin in 1830. These towns were adopted in a very short time span of about 55 years.
Geography.
According to the U.S. Census Bureau, the county has a total area of 1290 sqmi, of which 1275 sqmi is land and 15 sqmi (1.2%) is water.
Lewis County is located in northwestern New York State, slightly east of due north from Syracuse. The eastern part of the county is in the Adirondack Park. A good portion of the Tug Hill Plateau is in the western part of the county. The county is home to the Black River Valley.
Demographics.
As of the census of 2000, there were 26,944 people, 10,040 households, and 7,309 families residing in the county. The population density was 21 people per square mile (8/km²). There were 15,134 housing units at an average density of 12 per square mile (5/km²). The racial makeup of the county was 98.17% White, 0.39% African American, 0.28% Native American, 0.23% Asian, 0.05% Pacific Islander, 0.28% from other races, and 0.59% from two or more races. Hispanic or Latino of any race were 0.64% of the population. 28.8% were of German, 13.8% French, 13.1% Irish, 9.2% English, 6.5% American and 5.3% Polish ancestry according to Census 2000. 97.3% spoke English and 1.0% Spanish as their first language.
There were 10,040 households out of which 35.30% had children under the age of 18 living with them, 59.40% were married couples living together, 8.40% had a female householder with no husband present, and 27.20% were non-families. 22.60% of all households were made up of individuals and 10.80% had someone living alone who was 65 years of age or older. The average household size was 2.66 and the average family size was 3.12.
In the county the population was spread out with 27.80% under the age of 18, 7.70% from 18 to 24, 28.20% from 25 to 44, 22.50% from 45 to 64, and 13.80% who were 65 years of age or older. The median age was 37 years. For every 100 females there were 98.60 males. For every 100 females age 18 and over, there were 97.60 males.
The median income for a household in the county was $34,361, and the median income for a family was $39,287. Males had a median income of $30,479 versus $21,115 for females. The per capita income for the county was $14,971. About 10.10% of families and 13.20% of the population were below the poverty line, including 16.40% of those under age 18 and 14.00% of those age 65 or over.
Notable residents.
Child actor and veterinarian Peter Ostrum (born November 1957) settled in Lowville, Lewis County to practice veterinary medicine.
Judge Fred A. Young (August 27, 1904 – October 16, 1973) was a prominent Republican politician, lawyer, state legislator, and state judge, who was born in, and lived most of his life in, Lowville.
Florence Augusta Merriam Bailey (August 8, 1863 – September 22, 1948) was an American ornithologist and nature writer. She was born in Locust Grove, New York. The third child in her family, she was the younger sister of Clinton Hart Merriam. Florence Augusta Merriam Bailey was born in Locust Grove, New York. Bailey grew up at her family's estate, "Homewood", in the town of Leyden, whose fields and forests in the Black River Valley between the Tug Hill Plateau and Adirondack Mountains provided an ideal environment for the study of natural history. She was encouraged in her interest in nature by her brother as well as her father. Her father was interested in scientific matters and was in correspondence with John Muir after he had met him at Yosemite in the summer of 1871. Born in during the Civil War, Florence devoted her life to the study and protection of birds. From her work in ornithology she authored over ten books, including several field guides to birds, and close to one hundred articles. Though interested in birds as a child, she gained recognition as a naturalist while at Smith College. Disgusted by the use of feathers and whole birds in fashion, she started the Smith College Audubon Society.
Clinton Hart Merriam (December 5, 1855 – March 19, 1942) was an American zoologist, ornithologist, entomologist, ethnographer, and naturalist. In 1886, he became the first chief of the Division of Economic Ornithology and Mammalogy of the United States Department of Agriculture, predecessor to the National Wildlife Research Center and the United States Fish and Wildlife Service. In 1883, he was a founding member of the American Ornithologists' Union. He was one of the original founders of the National Geographic Society in 1888. He developed the concept of "life zones" to classify biomes found in North America along an altitudinal sequence corresponding to the zonal latitudinal sequence from Equator to Pole. In mammalogy, he is known as an excessive splitter, proposing, for example, tens of different species of North American brown bears in several genera. Later in life, funded by the Harriman family, Merriam's focus shifted to studying and assisting the Native American tribes in the western United States. His contributions on the myths of central California and on ethnogeography were particularly noteworthy.

</doc>
<doc id="55139" url="http://en.wikipedia.org/wiki?curid=55139" title="Livingston County, New York">
Livingston County, New York

Livingston County is a county located in the U.S. state of New York. As of the 2010 census, the population was 65,393. Its county seat is Geneseo. The county is named after Robert R. Livingston, a member of the committee that drafted the Declaration of Independence.
Livingston County is part of the Rochester Metropolitan Statistical Area.
History.
When counties were established in New York State in 1683, the present Livingston County was part of Albany County. This was an enormous county, including the northern part of New York State as well as all of the present State of Vermont and, in theory, extending westward to the Pacific Ocean. This county was reduced in size on July 3, 1766 by the creation of Cumberland County, and further on March 16, 1770 by the creation of Gloucester County, both containing territory now in Vermont.
On March 12, 1772, what was left of Albany County was split into three parts, one remaining under the name Albany County. One of the other pieces, Tryon County, contained the western portion (and thus, since no western boundary was specified, theoretically still extended west to the Pacific). The eastern boundary of Tryon County was approximately five miles west of the present city of Schenectady, and the county included the western part of the Adirondack Mountains and the area west of the West Branch of the Delaware River. The area then designated as Tryon County now includes 37 counties of New York State. The county was named for William Tryon, colonial governor of New York.
In the years prior to 1776, most of the Loyalists in Tryon County fled to Canada. In 1784, following the peace treaty that ended the American Revolutionary War, the name of Tryon County was changed to Montgomery County in order to honor the general, Richard Montgomery, who had captured several places in Canada and died attempting to capture the city of Quebec, replacing the name of the hated British governor.
In 1789, Ontario County was split off from Montgomery. The actual area split off from Montgomery County was much larger than the present county, also including the present Allegany, Cattaraugus, Chautauqua, Erie, Genesee, Livingston, Monroe, Niagara, Orleans, Steuben, Wyoming, Yates, and part of Schuyler and Wayne Counties.
Genesee County was created by a splitting of Ontario County in 1802. This was much larger than the present Genesee County, however. It contained the present Allegany, Cattaraugus, Chautauqua, Erie, Niagara, Orleans, Wyoming, and portions of Livingston and Monroe Counties.
Livingston County was formed from Genesee and Ontario Counties in 1821.
Livingston County is home to the State University of New York, College at Geneseo (now SUNY Geneseo)
Geography.
According to the U.S. Census Bureau, the county has a total area of 640 sqmi, of which 632 sqmi is land and 8.5 sqmi (1.3%) is water.
Livingston County is located in the Finger Lakes region, south of Rochester and east of Buffalo.
Letchworth State Park in partly in the western part of the county. The Genesee River flows northward through the county.
The Rochester and Southern Railroad (RSR) traverses the county from Greigsville south through Mount Morris to Dansville.
Government and politics.
Livingston County is governed by a 17–member legislature headed by a chairman.
Representation at other levels of government.
Livingston County is part of:
Demographics.
As of the census of 2000, there were 64,328 people, 22,150 households, and 15,349 families residing in the county. The population density was 102 people per square mile (39/km²). There were 24,023 housing units at an average density of 38 per square mile (15/km²). The racial makeup of the county was 94.04% White, 3.01% African American, 0.27% Native American, 0.76% Asian, 0.03% Pacific Islander, 0.85% from other races, and 1.04% from two or more races. Hispanic or Latino of any race were 2.27% of the population. 22.5% were of German, 17.7% Irish, 14.3% Italian, 12.8% English and 7.0% American ancestry according to Census 2000. 95.8% spoke English and 2.0% Spanish as their first language.
There were 22,150 households out of which 34.00% had children under the age of 18 living with them, 54.80% were married couples living together, 10.00% had a female householder with no husband present, and 30.70% were non-families. 23.10% of all households were made up of individuals and 9.40% had someone living alone who was 65 years of age or older. The average household size was 2.60 and the average family size was 3.05.
In the county the population was spread out with 23.40% under the age of 18, 14.20% from 18 to 24, 28.90% from 25 to 44, 22.10% from 45 to 64, and 11.40% who were 65 years of age or older. The median age was 35 years. For every 100 females there were 100.70 males. For every 100 females age 18 and over, there were 99.00 males.
The median income for a household in the county was $42,066, and the median income for a family was $50,513. Males had a median income of $36,599 versus $25,228 for females. The per capita income for the county was $18,062. About 5.80% of families and 10.40% of the population were below the poverty line, including 9.70% of those under age 18 and 6.50% of those age 65 or over.

</doc>
<doc id="55140" url="http://en.wikipedia.org/wiki?curid=55140" title="Madison County, New York">
Madison County, New York

Madison County is a county located in the U.S. state of New York. As of the 2010 census, the population was 73,442. Its county seat is Wampsville. The county is named after James Madison, fourth President of the United States of America, and was first formed in 1806.
Madison County is part of the Syracuse, NY Metropolitan Statistical Area.
History.
Indigenous peoples had occupied areas around Oneida Lake for thousands of years. The historic Oneida Nation was an Iroquoian-speaking people who emerged as a culture in this area about the fourteenth century and dominated the territory. They were one of the Five Nations who originally comprised the Iroquois Confederacy or "Haudenosaunee".
English colonists established counties in eastern present-day New York State in 1683; at the time, the territory of the present Madison County was considered part of Albany County, with the city of Albany located on the Hudson River. This was an enormous county, including the northern part of New York State around Albany as well as all of the present State of Vermont and, in theory, extending westward to the Pacific Ocean. It was claimed by the English but largely occupied by the Oneida, Onondaga, Seneca, Cayuga and Mohawk, who had the territory in the central Mohawk Valley, as well as Mahican near the Hudson River. On July 3, 1766 the English organized Cumberland County, and on March 16, 1770 they organized Gloucester County, both containing territory now included in the state of Vermont.
On March 12, 1772, what was left of Albany County was split into three parts, one remaining under the name Albany County. One of the other pieces, Tryon County, contained the western portion (and thus, since no western boundary was specified, theoretically still extended west to the Pacific). The eastern boundary of Tryon County was approximately five miles west of the present city of Schenectady, and the county included the western part of the Adirondack Mountains and the area west of the West Branch of the Delaware River. The area then designated as Tryon County includes 37 current counties of New York State. The county was named for William Tryon, the colonial governor of New York.
In the years prior to the outbreak of revolution in 1776, tensions rose in the frontier areas upstate and most of the Loyalists in Tryon County fled to Canada. In 1784, following the peace treaty that ended the American Revolutionary War, New York changed the name of Tryon County to Montgomery County, in honor of the general, Richard Montgomery, who had captured several places in Canada and died attempting to capture the city of Quebec. 
As allies of the Patriots, the Oneida Nation was allocated land by the United States in the postwar settlement for a reservation near Oneida Lake, in their traditional homeland. In the postwar treaty, the four Iroquois nations who had been allies of the British were forced to cede their lands; most of their peoples had already migrated to Canada to escape the worst of the fighting on the frontier after Sullivan's Raid. This expedition through Indian country had destroyed dwellings, crops and winter stores; many Iroquois who did not migrate died of starvation that winter. 
But settlers were hungry for land, and in 1788 Governor Clinton's representatives persuaded the Oneida to cede some of their territory to the state for sale to European-American settlers. This was called the "Clinton Purchase", after Governor George Clinton. The land comprised the southern portion of the Oneida reservation. It has also been called the Twenty Townships, as these were the number organized after New York controlled the land. 
As this sale was never ratified by the United States Senate, it was declared unconstitutional in a ruling by the United States Supreme Court in the late twentieth century. New York State had no legal authority after the Revolution and the formation of the United States to negotiate separately with American Indian tribes.
In 1789, Montgomery County was reduced in size by the splitting off of Ontario County. This was later divided to form the present Allegany, Cattaraugus, Chautauqua, Erie, Genesee, Livingston, Monroe, Niagara, Orleans, Steuben, Wyoming, Yates, and part of Schuyler and Wayne counties.
In 1791, Herkimer and Tioga counties were two of three counties split off from Montgomery County (the other being Otsego County).
Chenango County was formed in 1798 from parts of Tioga and Herkimer counties. Finally, Madison County was created from Chenango County in 1806.
About 1802, the Oneida agreed to allocate about 22,000 acres of their land to the Stockbridge and Munsee (Lenape), who were seeking refuge from anti-Native American conflicts by American settlers after the Revolution. Both were Christianized: the Stockbridge had migrated from western Massachusetts and the Lenape from New York and New Jersey. The two peoples were pressured to leave New York for Wisconsin in the 1820s, to make more land available for European-American settlement.
In the late twentieth century, the three recognized Oneida tribes: of Wisconsin, New York, and the Thames reserve in Canada, filed suit in a land claim against New York State for its treaty and forced purchase of their ancestral lands after the American Revolutionary War, seeking return of thousands of acres. The US Supreme Court has ruled the purchase was unconstitutional, as New York did not have the treaty ratified by the US Senate, and had no authority under the US Constitution to deal directly with the Oneida, a right reserved to the federal government. In 2010 the state offered the Oneida Tribe of Wisconsin more than 300 acres in Sullivan County in the Catskill Mountains, with permission to construct a gambling casino, and 2 acres in Madison County, to settle their part of the suit. Several private and public interests oppose the deal, including other federally recognized tribes in New York.
Geography.
According to the U.S. Census Bureau, the county has a total area of 661 sqmi, of which 655 sqmi is land and 6.4 sqmi (1.0%) is water.
Madison County is located in central New York State, east of Syracuse, north of Binghamton, and slightly north of due west from Albany. Madison County contains the geographic center of the state at Pratts Hollow in the Town of Eaton.
Oneida Lake and Oneida Creek define part of the northern boundary. The Great Swamp, formerly located south of the lake, was a rich wetlands habitat important to many species of birds and wildlife. This was drained by local and state construction projects in the early decades of the twentieth century, chiefly by Italian immigrants. The fertile soil supported high production of onions and other commodity crops, and the Italian families grew wealthy from their work. The area was known as "Black Beach" for its mucklands. Chittenango Creek defines part of the western boundary.
Adjacent counties and areas.
Chenango County is across the southern border. Onondaga and Cortland counties form the western border. Otsego County forms a short boundary in the southeast corner of Madison County. Oneida County shares a long northeast border with Madison County. Oneida Lake is the northern border with part of Oswego County on the opposite shore.
Demographics.
As of the census of 2000, there were 69,441 people, 25,368 households, and 17,580 families residing in the county. The population density was 106 people per square mile (41/km²). There were 28,646 housing units at an average density of 44 per square mile (17/km²). The racial makeup of the county was 96.49% White, 1.32% African American, 0.52% Native American, 0.56% Asian, 0.01% Pacific Islander, 0.26% from other races, and 0.84% from two or more races. Hispanic or Latino of any race were 1.06% of the population; 16.1% were of German, 15.6% English, 15.5% Irish, 12.1% Italian, and 8.0% American ancestry according to Census 2000. Of these 95.6% spoke English and 1.9% Spanish as their first language.
There were 25,368 households out of which 33.60% had children under the age of 18 living with them, 55.10% were married couples living together, 9.70% had a female householder with no husband present, and 30.70% were non-families. Of all households 24.50% were made up of individuals and 10.30% had someone living alone who was 65 years of age or older. The average household size was 2.55 and the average family size was 3.04.
In the county the population was spread out with 24.90% under the age of 18, 12.00% from 18 to 24, 27.60% from 25 to 44, 23.00% from 45 to 64, and 12.50% who were 65 years of age or older. The median age was 36 years. For every 100 females there were 96.30 males. For every 100 females age 18 and over, there were 93.80 males.
The median income for a household in the county was $40,184, and the median income for a family was $47,889. Males had a median income of $33,069 versus $25,026 for females. The per capita income for the county was $19,105. About 6.30% of families and 9.80% of the population were below the poverty line, including 10.50% of those under age 18 and 8.80% of those age 65 or over.
Much of Madison County is rural. However, Oneida and the other towns along NY Route 5 are suburbs of Syracuse and Utica, as is Cazenovia.
Communities.
Towns.
The towns in southern Madison County originated from the Twenty Townships ceded by the Oneida tribe to the State of New York.

</doc>
<doc id="55141" url="http://en.wikipedia.org/wiki?curid=55141" title="Monroe County, New York">
Monroe County, New York

Monroe County is a county located in the U.S. state of New York. As of 2013, the population was 749,857. Its county seat is the city of Rochester. The county is named after James Monroe, fifth President of the United States of America.
Monroe County is part of the Rochester, NY Metropolitan Statistical Area. Monroe County is located in Western New York.
History.
When counties were established in the Province of New York in 1683, the present Monroe County was part of Albany County. This was an enormous county, including the northern part of New York State as well as all of the present State of Vermont and, in theory, extending westward to the Pacific Ocean. This county was reduced in size on July 3, 1766 by the creation of Cumberland County, and further on March 16, 1770 by the creation of Gloucester County, both containing territory now in Vermont.
On March 12, 1772, what was left of Albany County was split into three parts, one remaining under the name Albany County. One of the other pieces, Tryon County, contained the western portion (and thus, since no western boundary was specified, theoretically still extended west to the Pacific). The eastern boundary of Tryon County was approximately five miles west of the present city of Schenectady, and the county included the western part of the Adirondack Mountains and the area west of the West Branch of the Delaware River. The area then designated as Tryon County now includes 37 counties of New York State. The county was named for William Tryon, colonial governor of New York.
In the years prior to 1776, most of the Loyalists in Tryon County fled to Canada. In 1784, following the peace treaty that ended the American Revolutionary War, the name of Tryon County was changed to Montgomery County in order to honor the general, Richard Montgomery, who had captured several places in Canada and died attempting to capture the city of Quebec, replacing the name of the hated British governor.
In 1789, Ontario County was split off from Montgomery. The actual area split off from Montgomery County was much larger than the present county, also including the present Allegany, Cattaraugus, Chautauqua, Erie, Genesee, Livingston, Monroe, Niagara, Orleans, Steuben, Wyoming, Yates, and part of Schuyler and Wayne counties.
Genesee County was created by a splitting of Ontario County in 1802. This was much larger than the present Genesee County, however. It contained the present Allegany, Cattaraugus, Chautauqua, Erie, Niagara, Orleans, Wyoming, and portions of Livingston and Monroe counties.
Finally, Monroe County was formed from parts of Genesee and Ontario counties in 1821.
Geography.
According to the U.S. Census Bureau, the county has a total area of 1367 sqmi, of which 657 sqmi is land and 710 sqmi (52%) is water.
Monroe County is in the northern tier of western New York State, northeast of Buffalo and northwest of Syracuse. The northern county line is also the state line and the border of the United States, marked by Lake Ontario. Monroe County is north of the Finger Lakes.
Government and politics.
Monroe County was chartered as a municipal corporation by the New York State Legislature in 1892 and re-chartered under New York's Municipal Home Rule Law in 1965.
Executive branch.
The county's executive branch is headed by the County Executive, Maggie Brooks. The executive's office is located on the first floor of the County Office Building on West Main Street in Rochester.
The county was exclusively governed by a Board of Supervisors for the first 114 years of its history. In 1935, the position of County Manager, appointed by the Board, was approved by popular referendum. In 1983, the position was replaced by a County Executive, directly elected by popular vote, with expanded powers (e.g., veto). In 1993, the legislature enacted term limits for the executive office of 12 consecutive years to start in 1996.
Legislative branch.
The county's legislative branch consists of a 29-member County Legislature which replaced the earlier 43-member Board of Supervisors on January 1, 1967. It meets in the Legislative Chambers on the fourth floor of the County Office Building. All 29 members of the legislature are elected from districts. Currently, there are 18 Republicans and 11 Democrats. In 1993, the legislature enacted term limits of 10 consecutive years to start in 1996.
Representation at the federal level.
After redistricting based on the 2010 United States Census, Monroe County was split between two congressional districts:
Representation at the state level.
New York State Senate.
After redistricting based on the 2010 United States Census, Monroe County was split between six state senate districts:
New York State Assembly.
After redistricting based on the 2010 United States Census, Monroe County was split between seven state assembly districts:
Courts.
Monroe County is part of
Economy.
Monroe County is a home to a number of international businesses, including Eastman Kodak, Bausch & Lomb, Paychex, and Pictometry International, all of which make Monroe County world headquarters. Xerox, while no longer headquartered in Rochester, has its principal offices and manufacturing facilities in Monroe County.
Because of the prevalence of imaging and optical science among the industry and the universities, Rochester is known as the world capital of imaging. The University of Rochester's Institute of Optics doctoral program was ranked in 2004 as number one in the country by the National Research Council in number of publications published per faculty member.
Monroe County is also home to regional businesses such as Wegmans, Roberts Communications, Inc., PAETEC Holding Corp., and major fashion label Hickey Freeman.
Demographics.
As of the census of 2000, there were 735,343 people, 286,512 households, and 184,513 families residing in the county. The population density was 1,115 people per square mile (431/km²). There were 304,388 housing units at an average density of 462 per square mile (178/km²). The racial makeup of the county was 79.14% White, 13.75% African American, 0.27% Native American, 2.44% Asian, 0.03% Pacific Islander, 2.44% from other races, and 1.94% from two or more races. Hispanic or Latino of any race were 5.31% of the population. 18.6% were of Italian, 15.3% German, 11.3% Irish and 8.3% English ancestry according to Census 2000. 4.64% of the population reported speaking Spanish at home, while 1.43% speak Italian.
There were 286,512 households out of which 31.80% had children under the age of 18 living with them, 47.40% were married couples living together, 13.40% had a female householder with no husband present, and 35.60% were non-families. 28.60% of all households were made up of individuals and 9.90% had someone living alone who was 65 years of age or older. The average household size was 2.47 and the average family size was 3.08.
In the county the population was spread out with 25.60% under the age of 18, 9.50% from 18 to 24, 29.30% from 25 to 44, 22.60% from 45 to 64, and 13.00% who were 65 years of age or older. The median age was 36 years. For every 100 females there were 93.00 males. For every 100 females age 18 and over, there were 89.20 males.
The median income for a household in the county was $44,891, and the median income for a family was $55,900. Males had a median income of $41,279 versus $29,553 for females. The per capita income for the county was $22,821. About 8.20% of families and 11.20% of the population were below the poverty line, including 15.50% of those under age 18 and 7.40% of those age 65 or over.
Education.
Primary and secondary education.
The overwhelming majority of children in Monroe County are educated by the public school system. The schools operated by the Roman Catholic Diocese of Rochester or Roman Catholic religious orders educate the next largest segment of children, although collectively, these are a distant second.
Public schools.
There are some 26 public school districts that serve Monroe County, including the Rochester City School District, 10 suburban school districts in Monroe #1 BOCES, seven in Monroe #2–Orleans BOCES, and several primarily serving other counties (Avon, Byron–Bergen, Caledonia–Mumford, Holley, Wayne, Williamson and Victor central school districts).
Private schools.
There are three private schools that serve more than 200 students each:
There is one small, but historically significant school: Rochester School for the Deaf in the city
Colleges and universities.
The county is home to nine colleges and universities:
Additionally, four colleges maintain satellite campuses in Monroe County:

</doc>
<doc id="55166" url="http://en.wikipedia.org/wiki?curid=55166" title="Ontario County, New York">
Ontario County, New York

Ontario County is a county located in the U.S. state of New York. As of the 2010 census, the population was 107,931. The county seat is Canandaigua.
Ontario County is part of the Rochester, NY Metropolitan Statistical Area.
In 2006, "Progressive Farmer" rated Ontario County as the "Best Place to Live" in the U.S., for its "great schools, low crime, excellent health care" and its proximity to Rochester.
History.
When counties were established in New York State in 1683, the present Ontario County was part of Albany County. This was an enormous county, including the northern part of New York State as well as all of the present State of Vermont and, in theory, extending westward to the Pacific Ocean. This county was reduced in size on July 3, 1766 by the creation of Cumberland County, and further on March 16, 1770 by the creation of Gloucester County, both containing territory now in Vermont.
On March 12, 1772, what was left of Albany County was split into three parts, one remaining under the name Albany County. One of the other pieces, Tryon County, contained the western portion (and thus, since no western boundary was specified, theoretically still extended west to the Pacific). The eastern boundary of Tryon County was approximately five miles west of the present city of Schenectady, cutting through the Mohawk River valley. The county included the western part of the Adirondack Mountains and the area west of the West Branch of the Delaware River. The area then designated as Tryon County was later organized as 37 counties of New York State. The county was named for William Tryon, colonial governor of New York.
In the years shortly before 1776, most of the Loyalists in Tryon County fled to Canada, as tensions and physical conflicts were rising in central New York. In 1784, following the peace treaty that ended the American Revolutionary War, the name of Tryon County was changed to honor the Continental general, Richard Montgomery. He had captured several places in Canada and died trying to capture the city of Quebec. It replaced the name of the hated British governor. Seth Reed, a Colonel in the Battle of Bunker Hill, moved here with his family as a pioneer between 1787 and 1795. see also Geneva (town), New York
Land-hungry settlers from New England swept into upstate and western New York after the Revolution, as nearly five million acres of new lands were available for purchase since the Iroquois had been forced to cede most of their territories to the United States. Four tribes had allied with the British and were mostly resettled in Canada: the Mohawk, Onondaga, and Seneca.
In 1789, Ontario County was split off from Montgomery. The territory first organized as Ontario County was much larger than at present and lay along the shore of Lake Ontario. As the area was settled, new counties were organized. At first it included what are currently twelve other counties and parts of two more: Allegany, Cattaraugus, Chautauqua, Erie, Genesee, Livingston, Monroe, Niagara, Orleans, Steuben, Wyoming, and Yates counties, and parts of Schuyler and Wayne counties.
In 1796, Ontario County was divided and Steuben County was organized.
In 1802, Ontario County was reduced when Genesee County was split off. The new county was originally very large, including the present Allegany, Cattaraugus, Chautauqua, Erie, Niagara, Orleans and Wyoming Counties and parts of Livingston and Monroe counties.
In 1821, portions of Genesee County were combined with portions of Ontario County to create Livingston and Monroe counties.
In 1823, a portion of Seneca County was combined with a portion of Ontario County to create Wayne County. The same year, a portion of Steuben County was combined with a portion of Ontario County to create Yates County.
Great Awakening.
This frontier area was part of the center of evangelistic activities during the Second Great Awakening, when Baptist, Methodist and Congregational preachers traveled and organized revivals and camp meetings. In addition, independent sects developed in central and western New York during this period, including the Shakers.
Latter Day Saint movement.
Joseph Smith, Jr., founder of the Latter Day Saint movement, lived in Manchester in the 1820s on the border with Palmyra. Several events in the early history of the movement occurred in Ontario County. Hill Cumorah in Manchester is where Smith said he discovered the Golden plates which contained the writings later known as the "Book of Mormon". Smith visited the hill each year on the fall equinox (September 22) between 1823 and 1827, and claimed to be instructed by the Angel Moroni. Smith said he was finally permitted to take the record on September 22, 1827. He published the "Book of Mormon" in Palmyra in 1830. The 110 ft hill (which was then unnamed) is on the main road toward Canandaigua from Palmyra to Manchester (modern State Route 21); it was a few miles from Joseph Smith's home.
Since the 1930s The Church of Jesus Christ of Latter-day Saints has held the Hill Cumorah Pageant annually at the hill. It regularly attracts thousands to its performances. The church also maintains a visitors' center at the hill, the Palmyra New York Temple, and the former Smith property and homes. The latter property straddles the border between Ontario and Wayne counties.
Geography.
According to the U.S. Census Bureau, the county has a total area of 663 sqmi, of which 644 sqmi is land and 18 sqmi (2.8%) is water.
Ontario County is in western New York State, east of Buffalo, southeast of Rochester, and northwest of Ithaca. The county is within the Finger Lakes Region of the state.
Government and politics.
The county is governed by a "Board of Supervisors", and uses the "Board-Administrator" system with a County Administrator. The Board of Supervisors has twenty-one members, one from each town, two from the city of Canandaigua, and three from the city of Geneva. As of 2004, the county government has over 800 full-time employees (augmented by another 360 seasonal or available part-time workers), and a budget of $136 million.
The county is similar to much of the rest of rural Upstate New York by being a Republican leaning county. In 1996, the county voted Democratic for the first time since 1964. In 2008, John McCain narrowly edged a victory over Barack Obama by less than 1%.
State and federal government.
Ontario County is part of:
Demographics.
As of the census of 2000, there were 100,224 people, 38,370 households, and 26,360 families residing in the county. The population density was 156 people per square mile (60/km²). There were 42,647 housing units at an average density of 66 per square mile (26/km²). According to respondents' self-identification, the racial makeup of the county was 95.04% White, 2.06% African American, 0.22% Native American, 0.69% Asian, 0.02% Pacific Islander, 0.70% from other races, and 1.26% from two or more races. Hispanic or Latino of any race were 2.14% of the population. Based on self-identification, 17.9% were of German, 14.9% Irish, 14.8% English, 13.8% Italian, 7.3% American and 5.1% Dutch ancestry according to Census 2000. 95.6% spoke English and 2.3% Spanish as their first language.
There were 38,370 households out of which 32.80% had children under the age of 18 living with them, 55.00% were married couples living together, 9.90% had a female householder with no husband present, and 31.30% were non-families. 24.70% of all households were made up of individuals and 10.10% had someone living alone who was 65 years of age or older. The average household size was 2.53 and the average family size was 3.03.
In the county the population was spread out with 25.40% under the age of 18, 8.30% from 18 to 24, 28.40% from 25 to 44, 24.80% from 45 to 64, and 13.20% who were 65 years of age or older. The median age was 38 years. For every 100 females there were 95.60 males. For every 100 females age 18 and over, there were 92.70 males.
The median income for a household in the county was $44,579, and the median income for a family was $52,698. Males had a median income of $36,732 versus $26,139 for females. The per capita income for the county was $21,533. About 4.90% of families and 7.30% of the population were below the poverty line, including 9.10% of those under age 18 and 6.40% of those age 65 or over.

</doc>
<doc id="55167" url="http://en.wikipedia.org/wiki?curid=55167" title="André Breton">
André Breton

André Breton (]; 19 February 1896 – 28 September 1966) was a French writer and poet. He is known best as the founder of Surrealism. His writings include the first "Surrealist Manifesto" ("Manifeste du surréalisme") of 1924, in which he defined surrealism as "pure psychic automatism".
Biography.
Born to a family of modest means in Tinchebray (Orne) in Normandy, he studied medicine and psychiatry. During World War I he worked in a neurological ward in Nantes, where he met the devotee of Alfred Jarry, Jacques Vaché, whose anti-social attitude and disdain for established artistic tradition influenced Breton considerably. Vaché committed suicide at age 24, and his war-time letters to Breton and others were published in a volume entitled "Lettres de guerre" (1919), for which Breton wrote four introductory essays.
Breton married his first wife, Simone Kahn, on 15 September 1921. The couple relocated to rue Fontaine # 42 in Paris on 1 January 1922. The apartment on rue Fontaine (in the Pigalle district) became home to Breton's collection of more than 5,300 items: modern paintings, drawings, sculptures, photographs, books, art catalogs, journals, manuscripts, and works of popular and Oceanic art.
From Dada to Surrealism.
In 1919 Breton launched the review "Littérature" with Louis Aragon and Philippe Soupault. He also associated with Dadaist Tristan Tzara. In 1924 he was instrumental in the founding of the Bureau of Surrealist Research.
In a publication "The Magnetic Fields" ("Les Champs Magnétiques"), a collaboration with Soupault, he implemented the principle of automatic writing. He published the "Surrealist Manifesto" in 1924, and was editor of the magazine "La Révolution surréaliste" from 1924. A group of writers became associated with him: Philippe Soupault, Louis Aragon, Paul Éluard, René Crevel, Michel Leiris, Benjamin Péret, Antonin Artaud, and Robert Desnos.
Anxious to combine the themes of personal transformation found in the works of Arthur Rimbaud with the politics of Karl Marx, Breton joined the French Communist Party in 1927, from which he was expelled in 1933. During this time, he survived mostly by the sale of paintings from his art gallery.
In 1935, there was a conflict between Breton and the Soviet writer and journalist Ilya Ehrenburg during the first "International Congress of Writers for the Defense of Culture" which opened in Paris in June. Breton had been insulted by Ehrenburg—along with all fellow surrealists—in a pamphlet which said, among other things, that surrealists were "pederasts". Breton slapped Ehrenburg several times on the street, which resulted in surrealists being expelled from the Congress. Crevel, who according to Salvador Dalí, was "the only serious communist among surrealists" was isolated from Breton and other surrealists, who were unhappy with Crevel because of his homosexuality and annoyed with communists in general.
In 1938, Breton accepted a cultural commission from the French government to travel to Mexico. After a conference at the National Autonomous University of Mexico about surrealism, Breton stated after getting lost in Mexico City (as no one was waiting for him at the airport) "I don't know why I came here. Mexico is the most surrealist country in the world".
However, visiting Mexico provided the opportunity to meet Leon Trotsky. Breton and other surrealists traveled via a long boat ride from Patzcuaro to the town of Erongaricuaro. Diego Rivera and Frida Kahlo were among the visitors to the hidden community of intellectuals and artists. Together, Breton and Trotsky wrote a manifesto "Pour un art révolutionnaire indépendent" (published under the names of Breton and Diego Rivera) calling for "complete freedom of art", which was becoming increasingly difficult with the world situation of the time.
1940s.
In 1942, Breton collaborated with artist Wifredo Lam on the publication of Breton's poem "Fata Morgana", which was illustrated by Lam.
Breton was again in the medical corps of the French Army at the start of World War II. The Vichy government banned his writings as "the very negation of the national revolution" and Breton escaped, with the help of the American Varian Fry and Harry Bingham, to the United States and the Caribbean during 1941. Breton got to know Martinican writer Aimé Césaire, and later composed the introduction to the 1947 edition of Césaire's "Cahier d'un retour au pays natal". During his exile in New York City he met Elisa, the Chilean woman who would become his third wife.
In 1944, he and Elisa traveled to the Gaspé Peninsula in Québec, where he wrote "Arcane 17", a book which expresses his fears of World War II, describes the marvels of the Rocher Percé and the extreme northeastern part of North America, and celebrates his new romance with Elisa.
Later life.
Breton returned to Paris in 1946, where he opposed French colonialism (for example as a signatory of the "Manifesto of the 121" against the Algerian war) and continued, until his death, to foster a second group of surrealists in the form of expositions or reviews ("La Brèche", 1961–1965). In 1959, he organized an exhibit in Paris.
By the end of World War II André Breton decided to embrace anarchism explicitly. In 1952 Breton wrote "It was in the black mirror of anarchism that surrealism first recognised itself." "Breton was consistent in his support for the francophone Anarchist Federation and he continued to offer his solidarity after the Platformists around Fontenis transformed the FA into the Federation Communiste Libertaire.
He was one of the few intellectuals who continued to offer his support to the FCL during the Algerian war when the FCL suffered severe repression and was forced underground. He sheltered Fontenis whilst he was in hiding. He refused to take sides on the splits in the French anarchist movement and both he and Peret expressed solidarity as well with the new FA set up by the synthesist anarchists and worked in the Antifascist Committees of the 60s alongside the FA."
André Breton died in 1966 at the age of 70 and was buried in the Cimetière des Batignolles in Paris.
Breton as a collector.
Breton was an avid collector of art, ethnographic material, and unusual trinkets. He was particularly interested in materials from the northwest coast of North America. During a financial crisis he experienced in 1931, most of his collection (along with his friend Paul Éluard's) was auctioned. He subsequently rebuilt the collection in his studio and home at 42 rue Fontaine. The collection grew to over 5,300 items: modern paintings, drawings, sculptures, photographs, books, art catalogs, journals, manuscripts, and works of popular and Oceanic art.
The famous French anthropologist Claude Lévi-Strauss, in an interview in 1971, spoke about Breton's skill in determining the authenticity of objects. Strauss even described their friendship while the two were living in New York: 'We lived in New York between 1941 and 1945 in a great friendship, running museums and antiquarians together. I owe him a lot about the knowledge and appreciation of objects. I've never seen him [Breton] doing a mistake on exotic and unusual objects. When I say a mistake, I mean about its authenticity but also its quality. He [Breton] had a sense, almost of divination.'
After Breton's death on 28 September 1966, Breton's third wife, Elisa, and his daughter, Aube, allowed students and researchers access to Breton's archive and collection. After thirty-six years, when attempts to establish a surrealist foundation to protect the collection were opposed, the collection was auctioned by Calmels Cohen at Drouot-Richelieu. A wall of the apartment is preserved at the Centre Georges Pompidou.
Nine previously unpublished manuscripts, including the "Manifeste du surréalisme", were auctioned by Sotheby's in May 2008.
Marriages.
Breton married three times: 
Works.
His works include the case studies "Nadja" (1928) and "L'Amour fou" (Mad Love) (1937).
Selected works:

</doc>
<doc id="55169" url="http://en.wikipedia.org/wiki?curid=55169" title="Corporal punishment">
Corporal punishment

Corporal punishment is a form of physical punishment that involves the deliberate infliction of pain in order to punish a person convicted of a crime or as retribution for a perceived offence, including physical chastisement such as spanking, paddling, or caning of minors by parents, guardians, or school or other officials. 
Official punishment by the infliction of pain or injury, including flogging, branding, and amputation, was practised in most civilisations since ancient times. However, with the growth of humanitarian ideals since the Enlightenment, such punishments were increasingly viewed as inhumane, a barbaric relic of bygone times. By the late 20th century, corporal punishment had been eliminated from the legal systems of most developed countries.
Corporal punishment in the twenty-first century may be divided into three main types:
The legality of various forms of corporal punishment differs by jurisdiction. Corporal punishment has traditionally been considered in many cultures an acceptable way of correction of children by adults with direct authority over them, but has fallen into disfavor in recent decades, especially in Western countries. It has been banned in an increasing number of jurisdictions:
"Corporal punishment of minors within domestic settings" has been officially outlawed in 46 countries as of April 2015.
"Corporal punishment in schools" has been outlawed in many countries, including Canada, Kenya, South Africa, New Zealand and nearly all of Europe.
"Judicial corporal punishment" has long disappeared from European countries, including former states of the Soviet Union. However, it remains lawful in parts of Africa, Asia and Latin America. Corporal punishment is also allowed in some military settings in a few jurisdictions.
There are campaigns against corporal punishment in several Western countries as well as internationally. These campaigns usually aim to bring about legal reform to ban the use of corporal punishment against minors by adults.
History.
Corporal punishment was recorded as early as c. 10th Century BC in Book of Proverbs attributed to Solomon:He that spareth the rod hateth his son: but he that loveth him correcteth him betimes.<br>Withhold not correction from a child: for if thou strike him with the rod, he shall not die. Thou shalt beat him with the rod, and deliver his soul from hell. It was certainly present in classical civilisations, being used in Greece, Rome, and Egypt for both judicial and educational discipline. Some states gained a reputation for using such punishments cruelly; Sparta, in particular, used them as part of a disciplinary regime designed to build willpower and physical strength. Although the Spartan example was extreme, corporal punishment was possibly the most frequent type of punishment. In the Roman Empire, the maximum penalty that a Roman citizen could receive under the law was 40 "lashes" or "strokes" with a whip applied to the back and shoulders, or with the "fasces" (similar to a birch rod, but consisting of 8–10 lengths of willow rather than birch) applied to the buttocks. Such punishments could draw blood, and were frequently inflicted in public.
Quintilian's (c. 35 – c. 100) early and complete opposition to corporal punishment is notable. According to McCole Wilson, probably no more lucid indictment of it has been made in the succeeding two thousand years.
By that boys should suffer corporal punishment, though it is received by custom, and Chrysippus makes no objection to it, I by no means approve; first, because it is a disgrace, and a punishment fit for slaves, and in reality (as will be evident if you imagine the age change) an affront; secondly, because, if a boy's disposition be so abject as not to be amended by reproof, he will be hardened, like the worst of slaves, even to stripes; and lastly, because, if one who regularly exacts his tasks be with him, there will not be the need of any chastisement...<br> Besides, after you have coerced a boy with stripes, how will you treat him when he becomes a young man, to whom such terror cannot be held out, and by whom more difficult studies must be pursued? Add to these considerations, that many things unpleasant to be mentioned, and likely afterwards to cause shame, often happen to boys while being whipped, under the influence of pain or fear; and such shame enervates and depresses the mind, and makes them shun people's sight and feel constant uneasiness ... scandalously unworthy men may abuse the privilege of punishing, and what opportunity also the terror of the unhappy children may sometimes afford others. (Quintilian, Institutes of Oratory, 1856 edition, I, III)
Plutarch, also in the first century, says something similar:
This also I assert, that children ought to be led to honourable practices by means of encouragement and reasoning, and most certainly not by blows or ill-treatment, for it surely is agreed that these are fitting rather for slaves than for the free-born; for so they grow numb and shudder at their tasks, partly from the pain of the blows, partly from the degradation. Praise and reproof are more helpful for the free-born than any sort of ill-usage, since the praise incites them toward what is honourable, and reproof keeps them from what is disgraceful.
In Medieval Europe, corporal punishment was encouraged by the attitudes of the medieval church towards the human body, flagellation being a common means of self-discipline. This had an influence on the use of corporal punishment in schools, as educational establishments were closely attached to the church during this period. Nevertheless, corporal punishment was not used uncritically; as early as the eleventh century Saint Anselm, Archbishop of Canterbury was speaking out against what he saw as the excessive use of corporal punishment in the treatment of children.
From the 16th century onwards, new trends were seen in corporal punishment. Judicial punishments were increasingly turned into public spectacles, with public beatings of criminals intended as a deterrent to other would-be offenders. Meanwhile, early writers on education, such as Roger Ascham, complained of the arbitrary manner in which children were punished.
Peter Newell assumes that perhaps the most influential writer on the subject was the English philosopher John Locke, whose "Some Thoughts Concerning Education" explicitly criticised the central role of corporal punishment in education. Locke's work was highly influential, and may have helped influence Polish legislators to ban corporal punishment from Poland's schools in 1783, the first country in the world to do so.
During the 18th century, the concept of corporal punishment was attacked by some philosophers and legal reformers. Merely inflicting pain on miscreants was seen as inefficient, influencing the subject only for a short period of time and effecting no permanent change in their behaviour. Some believed that the purpose of punishment should be reformation, not retribution. This is perhaps best expressed in Jeremy Bentham's idea of a "panoptic" prison, in which prisoners were controlled and surveyed at all times, perceived to be advantageous in that this system supposedly reduced the need of measures such as corporal punishment.
A consequence of this mode of thinking was a reduction in the use of corporal punishment in the 19th century in Europe and North America. In some countries this was encouraged by scandals involving individuals seriously hurt during acts of corporal punishment. For instance, in Britain, popular opposition to punishment was encouraged by two significant cases, the death of Private Frederick John White, who died after a military flogging in 1846, and the death of Reginald Cancellor, killed by his schoolmaster in 1860. Events such as these mobilised public opinion and, by the late nineteenth century, the extent of corporal punishment's use in state schools was unpopular with many parents in England. Authorities in Britain and some other countries introduced more detailed rules for the infliction of corporal punishment in government institutions such as schools, prisons and reformatories. By the First World War, parents' complaints about disciplinary excesses in England had died down, and corporal punishment was established as an expected form of school discipline.
In the 1870s, courts in the United States overruled the common-law principle that a husband had the right to "physically chastise an errant wife". In the UK the traditional right of a husband to inflict moderate corporal punishment on his wife in order to keep her "within the bounds of duty" was similarly removed in 1891. See Domestic violence for more information.
In the United Kingdom, the use of judicial corporal punishment declined during the first half of the 20th century and it was abolished altogether in the Criminal Justice Act, 1948 (zi & z2 GEo. 6. CH. 58.), whereby whipping and flogging were outlawed except for use in very serious internal prison discipline cases, while most other European countries had abolished it earlier. Meanwhile in many schools, the use of the cane, paddle or tawse remained commonplace in the UK and the United States until the 1980s. In several other countries, it still is: see School corporal punishment.
International law.
Human rights.
Key developments related to corporal punishment happen only in the late 20th century. Years with particular significance to the prohibition of corporal punishment are emphasised.
Children's rights.
Breakthroughs regarding children’s rights were made in the early 20th century, but the condemnation of corporal punishment in specific happens only in the late 20th century. Years with particular significance to the prohibition of corporal punishment are emphasised.
Modern use.
Legal status.
The earliest recorded attempt to prohibit corporal punishment of children by a state dates back to Poland in 1783. However, its prohibition in all spheres of life – in homes, schools, the penal system and alternative care settings – occurred first in 1979 in Sweden. The new Swedish Parental Code reads: "Children are entitled to care, security and a good upbringing. Children are to be treated with respect for their person and individuality and may not be subjected to corporal punishment or any other humiliating treatment." As of 2014, corporal punishment is outlawed in 44 countries. States that have completely prohibited corporal punishment of children by law are, in chronological order:
For a more detailed overview of the global use and prohibition of the corporal punishment of children, see the following table.
Corporal punishment in the home.
Domestic corporal punishment, i.e. of children by their parents, is often referred to colloquially as "spanking", "smacking" or "slapping."
In an increasing number of countries it has been outlawed, starting with Sweden in 1979. In some other countries, corporal punishment is legal, but restricted (e.g. blows to the head are outlawed and implements may not be used, and/or only children within a certain age range may be spanked).
In all states of the United States, and most African and Asian nations, corporal punishment by parents is currently legal; it is also legal to use certain implements such as a belt or paddle.
In Canada, spanking by parents or legal guardians (but nobody else) is legal, as long as the child is not under 2 years or over 12 years of age, and no implement other than an open, bare hand is used (belts, paddles, etc. are strictly prohibited).
In the UK, spanking or smacking is legal, but it must not leave a mark on the body; in Scotland since October 2003 it has been illegal to use any implement when disciplining a child.
In Pakistan, Section 89 of Pakistan Penal Code allows corporal punishment.
Corporal punishment in schools.
Corporal punishment of school students for misbehaviour has been outlawed in many countries. It involves striking the student on the buttocks or the palm of the hand in a premeditated ceremony with an implement specially kept for the purpose such as a rattan cane or spanking paddle, or with the open hand. There may be restrictions in some jurisdictions, e.g. in Singapore caning is permitted for boys only.
Judicial or quasi-judicial punishment.
Some 33 countries retain judicial corporal punishment, including a number of former British territories such as Botswana, Malaysia, Singapore and Tanzania. In Malaysia and Singapore, for certain specified offences, males are routinely sentenced to caning in addition to a prison term. The Singaporean practice of caning became much discussed around the world in 1994 when American teenager Michael P. Fay was caned for vandalism.
A number of countries with an Islamic legal system, such as Saudi Arabia, Iran, Sudan and some northern states in Nigeria, employ judicial whipping for a range of offences. s of 2009[ [update]], some regions of Pakistan are experiencing a breakdown of law and government, leading to a reintroduction of corporal punishment by "ad hoc" Islamicist courts. As well as corporal punishment, some Islamic countries such as Saudi Arabia and Iran use other kinds of physical penalties such as amputation or mutilation. However, the term "corporal punishment" has since the 19th century usually meant caning, flagellation or bastinado rather than those other types of physical penalty.
Differing views about corporal punishment.
If we really wanted to punish people, we could sentence drug offenders to join gangs and fear for their lives; we could punish child abusers to torture followed by death; we could force straight men to have semiconsensual prison-gay sex… All these things already happen, but we just sweep them under the rug and look the other way.
”
- Peter Moskos talking about the American prison system
In the book "In Defense of Flogging", Peter Moskos, an assistant professor of law and former police officer, suggests that a long prison sentence can be more inhumane than a flogging. Moskos believes that many criminals would elect to receive a few lashes (under medical supervision), and questions whether flogging should ever be an option. As reasons to consider such corporal punishment, Moskos cites studies showing that higher rates of incarceration have little effect on decreasing crime (e.g. the deterrence argument), and that the United States' incarceration rate is five times the world's average. He further worries that most criminals are not the kinds who will need to be kept out of society for the rest of their lives, and that prisons and sentences rarely focus on realistic rehabilitation methods. One reviewer for "The Economist" writes, about Moskos's book, that "Perhaps the most damning evidence of the broken American prison system is that it makes a proposal to reinstate flogging appear almost reasonable. Almost."
Anatomical target.
Different parts of the anatomy may be targeted:
Ritual and punishment.
Corporal punishment in official settings, such as prisons, reformatories and schools, has typically been carried out in a formal ceremony, with a predefined procedure, emphasizing the severity of the occasion. It may even be staged in a ritual manner in front of other inmates or students, in order to act as a deterrent to others.
In the case of prison or judicial punishments, the formal procedure might begin with the offender stripped of some or all of their clothing and restrained to a piece of furniture, such as a trestle or frame, (X-cross), punishment horse, plank or bench. In some cases the nature of the offence is read out before the punishment (usually consisting of a predetermined number of strokes) is formally imposed. A variety of implements may be used to inflict strokes on the offender. The terms used to describe these are not fixed, varying by country and by context. There are, however, a number of common types that are encountered when reading about corporal punishment. These include:
In some instances the offender is required to prepare the implement himself. For instance, sailors were employed in preparing the cat o' nine tails that would be used upon their own back, while school students were sometimes sent out to cut a switch or rod.
In contrast, informal punishments, particularly in domestic settings, tend to lack this ritual nature and are often administered with whatever object comes to hand. It is common, for instance, for belts, wooden spoons, slippers, hairbrushes or coathangers to be used in domestic punishment, while rulers and other classroom equipment have been used in schools.
In parts of England, boys were once beaten under the old tradition of "Beating the Bounds" whereby a boy was paraded around the edge of a city or parish and would be spanked with a switch or cane to mark the boundary. One famous "Beating the Bounds" took place around the boundary of St Giles and the area where Tottenham Court Road now stands in central London. The actual stone that separated the boundary is now underneath the Centre Point office tower.

</doc>
<doc id="55170" url="http://en.wikipedia.org/wiki?curid=55170" title="Genomics">
Genomics

Genomics is a discipline in genetics that applies recombinant DNA, DNA sequencing methods, and bioinformatics to sequence, assemble, and analyze the function and structure of genomes (the "complete" set of DNA within a single cell of an organism). Advances in genomics have triggered a revolution in discovery-based research to understand even the most complex biological systems such as the brain. The field includes efforts to determine the entire DNA sequence of organisms and fine-scale genetic mapping. The field also includes studies of intragenomic phenomena such as heterosis, epistasis, pleiotropy and other interactions between loci and alleles within the genome. In contrast, the investigation of the roles and functions of single genes is a primary focus of molecular biology or genetics and is a common topic of modern medical and biological research. Research of single genes does not fall into the definition of genomics unless the aim of this genetic, pathway, and functional information analysis is to elucidate its effect on, place in, and response to the entire genome's networks.
History.
Etymology.
From the Greek ΓΕΝ "gen", "gene" (gamma, epsilon, nu, epsilon) meaning "become, create, creation, birth", and subsequent variants: genealogy, genesis, genetics, genic, genomere, genotype, genus etc.
While the word "genome" (from the German "Genom", attributed to Hans Winkler) was in use in English as early as 1926, the term "genomics" was coined by Tom Roderick, a geneticist at the Jackson Laboratory (Bar Harbor, Maine), over beer at a meeting held in Maryland on the mapping of the human genome in 1986.
Early sequencing efforts.
Following Rosalind Franklin's confirmation of the helical structure of DNA, James D. Watson and Francis Crick's publication of the structure of DNA in 1953 and Fred Sanger's publication of the Amino acid sequence of insulin in 1955, nucleic acid sequencing became a major target of early molecular biologists. In 1964, Robert W. Holley and colleagues published the first nucleic acid sequence ever determined, the ribonucleotide sequence of alanine transfer RNA. Extending this work, Marshall Nirenberg and Philip Leder revealed the triplet nature of the genetic code and were able to determine the sequences of 54 out of 64 codons in their experiments. In 1972, Walter Fiers and his team at the Laboratory of Molecular Biology of the University of Ghent (Ghent, Belgium) were the first to determine the sequence of a gene: the gene for Bacteriophage MS2 coat protein. Fiers' group expanded on their MS2 coat protein work, determining the complete nucleotide-sequence of bacteriophage MS2-RNA (whose genome encodes just four genes in 3569 base pairs [bp]) and Simian virus 40 in 1976 and 1978, respectively.
DNA sequencing technology developed.
In addition to his seminal work on the amino acid sequence of insulin, Frederick Sanger and his colleagues played a key role in the development of DNA sequencing techniques that enabled the establishment of comprehensive genome sequencing projects. In 1975, he and Alan Coulson published a sequencing procedure using DNA polymerase with radiolabelled nucleotides that he called the "Plus and Minus technique". This involved two closely related methods that generated short oligonucleotides with defined 3' termini. These could be fractionated by electrophoresis on a polyacrylamide gel and visualised using autoradiography. The procedure could sequence up to 80 nucleotides in one go and was a big improvement, but was still very laborious. Nevertheless, in 1977 his group was able to sequence most of the 5,386 nucleotides of the single-stranded bacteriophage φX174, completing the first fully sequenced DNA-based genome. The refinement of the "Plus and Minus" method resulted in the chain-termination, or Sanger method (see below), which formed the basis of the techniques of DNA sequencing, genome mapping, data storage, and bioinformatic analysis most widely used in the following quarter-century of research. In the same year Walter Gilbert and Allan Maxam of Harvard University independently developed the Maxam-Gilbert method (also known as the "chemical method") of DNA sequencing, involving the preferential cleavage of DNA at known bases, a less efficient method. For their groundbreaking work in the sequencing of nucleic acids, Gilbert and Sanger shared half the 1980 Nobel Prize in chemistry with Paul Berg (recombinant DNA).
Complete genomes.
The advent of these technologies resulted in a rapid intensification in the scope and speed of completion of genome sequencing projects. The first complete genome sequence of an eukaryotic organelle, the human mitochondrion (16,568 bp, about 16.6 kb [kilobase]), was reported in 1981, and the first chloroplast genomes followed in 1986. In 1992, the first eukaryotic chromosome, chromosome III of brewer's yeast "Saccharomyces cerevisiae" (315 kb) was sequenced. The first free-living organism to be sequenced was that of "Haemophilus influenzae" (1.8 Mb [megabase]) in 1995. The following year a consortium of researchers from laboratories across North America, Europe, and Japan announced the completion of the first complete genome sequence of a eukaryote, "S. cerevisiae" (12.1 Mb), and since then genomes have continued being sequenced at an exponentially growing pace. s of October 2011[ [update]], the complete sequences are available for: 2,719 viruses, 1,115 archaea and bacteria, and 36 eukaryotes, of which about half are fungi.
Most of the microorganisms whose genomes have been completely sequenced are problematic pathogens, such as "Haemophilus influenzae", which has resulted in a pronounced bias in their phylogenetic distribution compared to the breadth of microbial diversity. Of the other sequenced species, most were chosen because they were well-studied model organisms or promised to become good models. Yeast ("Saccharomyces cerevisiae") has long been an important model organism for the eukaryotic cell, while the fruit fly "Drosophila melanogaster" has been a very important tool (notably in early pre-molecular genetics). The worm "Caenorhabditis elegans" is an often used simple model for multicellular organisms. The zebrafish "Brachydanio rerio" is used for many developmental studies on the molecular level, and the flower "Arabidopsis thaliana" is a model organism for flowering plants. The Japanese pufferfish ("Takifugu rubripes") and the spotted green pufferfish ("Tetraodon nigroviridis") are interesting because of their small and compact genomes, which contain very little noncoding DNA compared to most species. The mammals dog ("Canis familiaris"), brown rat ("Rattus norvegicus"), mouse ("Mus musculus"), and chimpanzee ("Pan troglodytes") are all important model animals in medical research.
A rough draft of the human genome was completed by the Human Genome Project in early 2001, creating much fanfare. This project, completed in 2003, sequenced the entire genome for one specific person, and by 2007 this sequence was declared "finished" (less than one error in 20,000 bases and all chromosomes assembled). In the years since then, the genomes of many other individuals have been sequenced, partly under the auspices of the 1000 Genomes Project, which announced the sequencing of 1,092 genomes in October 2012. Completion of this project was made possible by the development of dramatically more efficient sequencing technologies and required the commitment of significant bioinformatics resources from a large international collaboration. The continued analysis of human genomic data has profound political and social repercussions for human societies.
The "omics" revolution.
The English-language neologism omics informally refers to a field of study in biology ending in "-omics", such as genomics, proteomics or metabolomics. The related suffix -ome is used to address the objects of study of such fields, such as the genome, proteome or metabolome respectively. The suffix "-ome" as used in molecular biology refers to a "totality" of some sort; similarly omics has come to refer generally to the study of large, comprehensive biological data sets. While the growth in the use of the term has led some scientists (Jonathan Eisen, among others) to claim that it has been oversold, it reflects the change in orientation towards the quantitative analysis of complete or near-complete assortment of all the constituents of a system. In the study of symbioses, for example, researchers which were once limited to the study of a single gene product can now simultaneously compare the total complement of several types of biological molecules.
Genome analysis.
After an organism has been selected, genome projects involve three components: the sequencing of DNA, the assembly of that sequence to create a representation of the original chromosome, and the annotation and analysis of that representation.
Sequencing.
Historically, sequencing was done in "sequencing centers", centralized facilities (ranging from large independent institutions such as Joint Genome Institute which sequence dozens of terabases a year, to local molecular biology core facilities) which contain research laboratories with the costly instrumentation and technical support necessary. As sequencing technology continues to improve, however, a new generation of effective fast turnaround benchtop sequencers has come within reach of the average academic laboratory. On the whole, genome sequencing approaches fall into two broad categories, "shotgun" and "high-throughput" (aka "next-generation") sequencing.
Shotgun sequencing.
Shotgun sequencing (Sanger sequencing is used interchangeably) is a sequencing method designed for analysis of DNA sequences longer than 1000 base pairs, up to and including entire chromosomes. It is named by analogy with the rapidly expanding, quasi-random firing pattern of a shotgun. Since the chain termination method of DNA sequencing can only be used for fairly short strands (100 to 1000 basepairs), longer DNA sequences must be broken into random small segments which are then sequenced to obtain "reads". Multiple overlapping reads for the target DNA are obtained by performing several rounds of this fragmentation and sequencing. Computer programs then use the overlapping ends of different reads to assemble them into a continuous sequence. Shotgun sequencing is a random sampling process, requiring over-sampling to ensure a given nucleotide is represented in the reconstructed sequence; the average number of reads by which a genome is over-sampled is referred to as coverage.
For much of its history, the technology underlying shotgun sequencing was the classical chain-termination method, which is based on the selective incorporation of chain-terminating dideoxynucleotides by DNA polymerase during in vitro DNA replication. Developed by Frederick Sanger and colleagues in 1977, it was the most widely used sequencing method for approximately 25 years. More recently, Sanger sequencing has been supplanted by "Next-Gen" sequencing methods, especially for large-scale, automated genome analyses. However, the Sanger method remains in wide use in 2013, primarily for smaller-scale projects and for obtaining especially long contiguous DNA sequence reads (>500 nucleotides). Chain-termination methods require a single-stranded DNA template, a DNA primer, a DNA polymerase, normal deoxynucleosidetriphosphates (dNTPs), and modified nucleotides (dideoxyNTPs) that terminate DNA strand elongation. These chain-terminating nucleotides lack a 3'-OH group required for the formation of a phosphodiester bond between two nucleotides, causing DNA polymerase to cease extension of DNA when a ddNTP is incorporated. The ddNTPs may be radioactively or fluorescently labelled for detection in automated sequencing machines. Typically, these automated DNA-sequencing instruments (DNA sequencers) can sequence up to 96 DNA samples in a single batch (run) in up to 48 runs a day.
High-throughput sequencing.
The high demand for low-cost sequencing has driven the development of high-throughput sequencing (or next-generation sequencing [NGS]) technologies that parallelize the sequencing process, producing thousands or millions of sequences at once. High-throughput sequencing technologies are intended to lower the cost of DNA sequencing beyond what is possible with standard dye-terminator methods. In ultra-high-throughput sequencing as many as 500,000 sequencing-by-synthesis operations may be run in parallel.
Illumina (Solexa) sequencing.
Solexa, now part of Illumina, developed a sequencing method based on reversible dye-terminators technology acquired from Manteia Predictive Medicine in 2004. This technology had been invented and developed in late 1996 at Glaxo-Welcome's Geneva Biomedical Research Institute (GBRI), by Dr. Pascal Mayer and Dr Laurent Farinelli. In this method, DNA molecules and primers are first attached on a slide and amplified with polymerase so that local clonal colonies, initially coined "DNA colonies", are formed. To determine the sequence, four types of reversible terminator bases (RT-bases) are added and non-incorporated nucleotides are washed away. Unlike pyrosequencing, the DNA chains are extended one nucleotide at a time and image acquisition can be performed at a delayed moment, allowing for very large arrays of DNA colonies to be captured by sequential images taken from a single camera.
Decoupling the enzymatic reaction and the image capture allows for optimal throughput and theoretically unlimited sequencing capacity. With an optimal configuration, the ultimately reachable instrument throughput is thus dictated solely by the analogic-to-digital conversion rate of the camera, multiplied by the number of cameras and divided by the number of pixels per DNA colony required for visualizing them optimally (approximately 10 pixels/colony). In 2012, with cameras operating at more than 10 MHz A/D conversion rates and available optics, fluidics and enzymatics, throughput can be multiples of 1 million nucleotides/second, corresponding roughly to 1 human genome equivalent at 1x coverage per hour per instrument, and 1 human genome re-sequenced (at approx. 30x) per day per instrument (equipped with a single camera). The camera takes images of the fluorescently labeled nucleotides, then the dye along with the terminal 3' blocker is chemically removed from the DNA, allowing the next cycle.
Ion Torrent.
Ion Torrent Systems Inc. developed a sequencing approach based on standard DNA replication chemistry. This technology measures the release of a hydrogen ion each time a base is incorporated. A microwell containing template DNA is flooded with a single nucleotide, if the nucleotide is complementary to the template strand it will be incorporated and a hydrogen ion will be released. This release triggers an ISFET ion sensor. If a homopolymer is present in the template sequence multiple nucleotides will be incorporated in a single flood cycle, and the detected electrical signal will be proportionally higher.
Assembly.
Sequence assembly refers to aligning and merging fragments of a much longer DNA sequence in order to reconstruct the original sequence. This is needed as current DNA sequencing technology cannot read whole genomes as a continuous sequence, but rather reads small pieces of between 20 and 1000 bases, depending on the technology used. Typically the short fragments, called reads, result from shotgun sequencing genomic DNA, or gene transcripts (ESTs).
Assembly approaches.
Assembly can be broadly categorized into two approaches: "de novo" assembly, for genomes which are not similar to any sequenced in the past, and comparative assembly which use the existing sequence of a closely related organism as a reference during assembly. Relative to comparative assembly, "de novo" assembly is computationally difficult (NP-hard), making it less favorable for short-read NGS technologies.
Finishing.
Finished genomes are defined as having a single contiguous sequence with no ambiguities representing each replicon.
Annotation.
The DNA sequence assembly alone is of little value without additional analysis. Genome annotation is the process of attaching biological information to sequences, and consists of three main steps:
Automatic annotation tools try to perform these steps "in silico", as opposed to manual annotation (a.k.a. curation) which involves human expertise and potential experimental verification. Ideally, these approaches co-exist and complement each other in the same annotation pipeline (also see below).
Traditionally, the basic level of annotation is using BLAST for finding similarities, and then annotating genomes based on homolouges. More recently, additional information is added to the annotation platform. The additional information allows manual annotators to deconvolute discrepancies between genes that are given the same annotation. Some databases use genome context information, similarity scores, experimental data, and integrations of other resources to provide genome annotations through their Subsystems approach. Other databases (e.g. Ensembl) rely on both curated data sources as well as a range of software tools in their automated genome annotation pipeline. "Structural annotation" consists of the identification of genomic elements, primarily ORFs and their localisation, or gene structure. "Functional annotation" consists of attaching biological information to genomic elements.
Sequencing pipelines and databases.
The need for reproducibility and efficient management of the large amount of data associated with genome projects mean that computational pipelines have important applications in genomics.
Research areas.
Functional genomics.
Functional genomics is a field of molecular biology that attempts to make use of the vast wealth of data produced by genomic projects (such as genome sequencing projects) to describe gene (and protein) functions and interactions. Functional genomics focuses on the dynamic aspects such as gene transcription, translation, and protein–protein interactions, as opposed to the static aspects of the genomic information such as DNA sequence or structures. Functional genomics attempts to answer questions about the function of DNA at the levels of genes, RNA transcripts, and protein products. A key characteristic of functional genomics studies is their genome-wide approach to these questions, generally involving high-throughput methods rather than a more traditional “gene-by-gene” approach.
A major branch of genomics is still concerned with sequencing the genomes of various organisms, but the knowledge of full genomes has created the possibility for the field of functional genomics, mainly concerned with patterns of gene expression during various conditions. The most important tools here are microarrays and bioinformatics.
Structural genomics.
Structural genomics seeks to describe the 3-dimensional structure of every protein encoded by a given genome. This genome-based approach allows for a high-throughput method of structure determination by a combination of experimental and modeling approaches. The principal difference between structural genomics and traditional structural prediction is that structural genomics attempts to determine the structure of every protein encoded by the genome, rather than focusing on one particular protein. With full-genome sequences available, structure prediction can be done more quickly through a combination of experimental and modeling approaches, especially because the availability of large number of sequenced genomes and previously solved protein structures allows scientists to model protein structure on the structures of previously solved homologs. Structural genomics involves taking a large number of approaches to structure determination, including experimental methods using genomic sequences or modeling-based approaches based on sequence or structural homology to a protein of known structure or based on chemical and physical principles for a protein with no homology to any known structure. As opposed to traditional structural biology, the determination of a protein structure through a structural genomics effort often (but not always) comes before anything is known regarding the protein function. This raises new challenges in structural bioinformatics, i.e. determining protein function from its 3D structure.
Epigenomics.
Epigenomics is the study of the complete set of epigenetic modifications on the genetic material of a cell, known as the epigenome. Epigenetic modifications are reversible modifications on a cell’s DNA or histones that affect gene expression without altering the DNA sequence (Russell 2010 p. 475). Two of the most characterized epigenetic modifications are DNA methylation and histone modification. Epigenetic modifications play an important role in gene expression and regulation, and are involved in numerous cellular processes such as in differentiation/development and tumorigenesis. The study of epigenetics on a global level has been made possible only recently through the adaptation of genomic high-throughput assays.
Metagenomics.
Metagenomics is the study of "metagenomes", genetic material recovered directly from environmental samples. The broad field may also be referred to as environmental genomics, ecogenomics or community genomics. While traditional microbiology and microbial genome sequencing rely upon cultivated clonal cultures, early environmental gene sequencing cloned specific genes (often the 16S rRNA gene) to produce a profile of diversity in a natural sample. Such work revealed that the vast majority of microbial biodiversity had been missed by cultivation-based methods. Recent studies use "shotgun" Sanger sequencing or massively parallel pyrosequencing to get largely unbiased samples of all genes from all the members of the sampled communities. Because of its power to reveal the previously hidden diversity of microscopic life, metagenomics offers a powerful lens for viewing the microbial world that has the potential to revolutionize understanding of the entire living world.
Study systems.
Viruses and bacteriophages.
Bacteriophages have played and continue to play a key role in bacterial genetics and molecular biology. Historically, they were used to define gene structure and gene regulation. Also the first genome to be sequenced was a bacteriophage. However, bacteriophage research did not lead the genomics revolution, which is clearly dominated by bacterial genomics. Only very recently has the study of bacteriophage genomes become prominent, thereby enabling researchers to understand the mechanisms underlying phage evolution. Bacteriophage genome sequences can be obtained through direct sequencing of isolated bacteriophages, but can also be derived as part of microbial genomes. Analysis of bacterial genomes has shown that a substantial amount of microbial DNA consists of prophage sequences and prophage-like elements. A detailed database mining of these sequences offers insights into the role of prophages in shaping the bacterial genome.
Cyanobacteria.
At present there are 24 cyanobacteria for which a total genome sequence is available. 15 of these cyanobacteria come from the marine environment. These are six "Prochlorococcus" strains, seven marine "Synechococcus" strains, "Trichodesmium erythraeum" IMS101 and "Crocosphaera watsonii" WH8501. Several studies have demonstrated how these sequences could be used very successfully to infer important ecological and physiological characteristics of marine cyanobacteria. However, there are many more genome projects currently in progress, amongst those there are further "Prochlorococcus" and marine "Synechococcus" isolates, "Acaryochloris" and "Prochloron", the N2-fixing filamentous cyanobacteria "Nodularia spumigena", "Lyngbya aestuarii" and "Lyngbya majuscula", as well as bacteriophages infecting marine cyanobaceria. Thus, the growing body of genome information can also be tapped in a more general way to address global problems by applying a comparative approach. Some new and exciting examples of progress in this field are the identification of genes for regulatory RNAs, insights into the evolutionary origin of photosynthesis, or estimation of the contribution of horizontal gene transfer to the genomes that have been analyzed.
Applications of genomics.
Genomics has provided applications in many fields, including medicine, biotechnology, anthropology and other social sciences.
Genomic medicine.
Next-generation genomic technologies allow clinicians and biomedical researchers to drastically increase the amount of genomic data collected on large study populations. When combined with new informatics approaches that integrate many kinds of data with genomic data in disease research, allowing researchers to better understand the genetic bases of drug response and disease.
Synthetic biology and bioengineering.
The growth of genomic knowledge has enabled increasingly sophisticated applications of synthetic biology. In 2010 researchers at the J. Craig Venter Institute announced the creation of a partially synthetic species of bacterium, "Mycoplasma laboratorium", derived from the genome of "Mycoplasma genitalium".

</doc>
